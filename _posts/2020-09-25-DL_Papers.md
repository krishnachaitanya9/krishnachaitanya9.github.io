---
title: Latest Deep Learning Papers
date: 2021-02-08 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (298 Articles)</h1>
<h2>Reproducibility in Evolutionary Computation. (arXiv:2102.03380v1 [cs.AI])</h2>
<h3>Manuel L&#xf3;pez-Ib&#xe1;&#xf1;ez (University of M&#xe1;laga, Spain), Juergen Branke (University of Warwick, UK), Lu&#xed;s Paquete (University of Coimbra, Portugal)</h3>
<p>Experimental studies are prevalent in Evolutionary Computation (EC), and
concerns about the reproducibility and replicability of such studies have
increased in recent times, reflecting similar concerns in other scientific
fields. In this article, we suggest a classification of different types of
reproducibility that refines the badge system of the Association of Computing
Machinery (ACM) adopted by TELO. We discuss, within the context of EC, the
different types of reproducibility as well as the concepts of artifact and
measurement, which are crucial for claiming reproducibility. We identify
cultural and technical obstacles to reproducibility in the EC field. Finally,
we provide guidelines and suggest tools that may help to overcome some of these
reproducibility obstacles.
</p>
<a href="http://arxiv.org/abs/2102.03380" target="_blank">arXiv:2102.03380</a> [<a href="http://arxiv.org/pdf/2102.03380" target="_blank">pdf</a>]

<h2>Robust Single-step Adversarial Training with Regularizer. (arXiv:2102.03381v1 [cs.LG])</h2>
<h3>Lehui Xie, Yaopeng Wang, Jia-Li Yin, Ximeng Liu</h3>
<p>High cost of training time caused by multi-step adversarial example
generation is a major challenge in adversarial training. Previous methods try
to reduce the computational burden of adversarial training using single-step
adversarial example generation schemes, which can effectively improve the
efficiency but also introduce the problem of catastrophic overfitting, where
the robust accuracy against Fast Gradient Sign Method (FGSM) can achieve nearby
100\% whereas the robust accuracy against Projected Gradient Descent (PGD)
suddenly drops to 0\% over a single epoch. To address this problem, we propose
a novel Fast Gradient Sign Method with PGD Regularization (FGSMPR) to boost the
efficiency of adversarial training without catastrophic overfitting. Our core
idea is that single-step adversarial training can not learn robust internal
representations of FGSM and PGD adversarial examples. Therefore, we design a
PGD regularization term to encourage similar embeddings of FGSM and PGD
adversarial examples. The experiments demonstrate that our proposed method can
train a robust deep network for L$_\infty$-perturbations with FGSM adversarial
training and reduce the gap to multi-step adversarial training.
</p>
<a href="http://arxiv.org/abs/2102.03381" target="_blank">arXiv:2102.03381</a> [<a href="http://arxiv.org/pdf/2102.03381" target="_blank">pdf</a>]

<h2>Projection Robust Wasserstein Barycenter. (arXiv:2102.03390v1 [cs.LG])</h2>
<h3>Minhui Huang, Shiqian Ma, Lifeng Lai</h3>
<p>Collecting and aggregating information from several probability measures or
histograms is a fundamental task in machine learning. One of the popular
solution methods for this task is to compute the barycenter of the probability
measures under the Wasserstein metric. However, approximating the Wasserstein
barycenter is numerically challenging because of the curse of dimensionality.
This paper proposes the projection robust Wasserstein barycenter (PRWB) that
mitigates the curse of dimensionality. This new model projects the probability
measures onto a lower-dimensional subspace that maximizes the Wasserstein
barycenter objective. The resulting problem is a max-min problem over the
Stiefel manifold, which is numerically challenging in practice. Combining the
iterative Bregman projection algorithm and Riemannian optimization, we propose
two new algorithms for computing the PRWB. The complexity of arithmetic
operations of the proposed algorithms for obtaining an $\epsilon$-stationary
solution is analyzed. We incorporate the PRWB into a discrete distribution
clustering algorithm, and the numerical results on real text datasets confirm
that our PRWB model helps improve the clustering performance significantly.
</p>
<a href="http://arxiv.org/abs/2102.03390" target="_blank">arXiv:2102.03390</a> [<a href="http://arxiv.org/pdf/2102.03390" target="_blank">pdf</a>]

<h2>Single Run Action Detector over Video Stream -- A Privacy Preserving Approach. (arXiv:2102.03391v1 [cs.CV])</h2>
<h3>Anbumalar Saravanan, Justin Sanchez, Hassan Ghasemzadeh, Aurelia Macabasco-O&#x27;Connell, Hamed Tabkhi</h3>
<p>This paper takes initial strides at designing and evaluating a vision-based
system for privacy ensured activity monitoring. The proposed technology
utilizing Artificial Intelligence (AI)-empowered proactive systems offering
continuous monitoring, behavioral analysis, and modeling of human activities.
To this end, this paper presents Single Run Action Detector (S-RAD) which is a
real-time privacy-preserving action detector that performs end-to-end action
localization and classification. It is based on Faster-RCNN combined with
temporal shift modeling and segment based sampling to capture the human
actions. Results on UCF-Sports and UR Fall dataset present comparable accuracy
to State-of-the-Art approaches with significantly lower model size and
computation demand and the ability for real-time execution on edge embedded
device (e.g. Nvidia Jetson Xavier).
</p>
<a href="http://arxiv.org/abs/2102.03391" target="_blank">arXiv:2102.03391</a> [<a href="http://arxiv.org/pdf/2102.03391" target="_blank">pdf</a>]

<h2>MudrockNet: Semantic Segmentation of Mudrock SEM Images through Deep Learning. (arXiv:2102.03393v1 [cs.CV])</h2>
<h3>Abhishek Bihani, Hugh Daigle, Javier E. Santos, Christopher Landry, Masa Prodanovic, Kitty Milliken</h3>
<p>Segmentation and analysis of individual pores and grains of mudrocks from
scanning electron microscope images is non-trivial because of noise, imaging
artifacts, variation in pixel grayscale values across images, and overlaps in
grayscale values among different physical features such as silt grains, clay
grains, and pores in an image, which make their identification difficult.
Moreover, because grains and pores often have overlapping grayscale values,
direct application of threshold-based segmentation techniques is not
sufficient. Recent advances in the field of computer vision have made it easier
and faster to segment images and identify multiple occurrences of such features
in an image, provided that ground-truth data for training the algorithm is
available. Here, we propose a deep learning SEM image segmentation model,
MudrockNet based on Google's DeepLab-v3+ architecture implemented with the
TensorFlow library. The ground-truth data was obtained from an image-processing
workflow applied to scanning electron microscope images of uncemented muds from
the Kumano Basin offshore Japan at depths &lt; 1.1 km. The trained deep learning
model obtained a pixel-accuracy about 90%, and predictions for the test data
obtained a mean intersection over union (IoU) of 0.6591 for silt grains and
0.6642 for pores. We also compared our model with the random forest classifier
using trainable Weka segmentation in ImageJ, and it was observed that
MudrockNet gave better predictions for both silt grains and pores. The size,
concentration, and spatial arrangement of the silt and clay grains can affect
the petrophysical properties of a mudrock, and an automated method to
accurately identify the different grains and pores in mudrocks can help improve
reservoir and seal characterization for petroleum exploration and anthropogenic
waste sequestration.
</p>
<a href="http://arxiv.org/abs/2102.03393" target="_blank">arXiv:2102.03393</a> [<a href="http://arxiv.org/pdf/2102.03393" target="_blank">pdf</a>]

<h2>Confidence-Budget Matching for Sequential Budgeted Learning. (arXiv:2102.03400v1 [cs.LG])</h2>
<h3>Yonathan Efroni, Nadav Merlis, Aadirupa Saha, Shie Mannor</h3>
<p>A core element in decision-making under uncertainty is the feedback on the
quality of the performed actions. However, in many applications, such feedback
is restricted. For example, in recommendation systems, repeatedly asking the
user to provide feedback on the quality of recommendations will annoy them. In
this work, we formalize decision-making problems with querying budget, where
there is a (possibly time-dependent) hard limit on the number of reward queries
allowed. Specifically, we consider multi-armed bandits, linear bandits, and
reinforcement learning problems. We start by analyzing the performance of
`greedy' algorithms that query a reward whenever they can. We show that in
fully stochastic settings, doing so performs surprisingly well, but in the
presence of any adversity, this might lead to linear regret. To overcome this
issue, we propose the Confidence-Budget Matching (CBM) principle that queries
rewards when the confidence intervals are wider than the inverse square root of
the available budget. We analyze the performance of CBM based algorithms in
different settings and show that they perform well in the presence of adversity
in the contexts, initial states, and budgets.
</p>
<a href="http://arxiv.org/abs/2102.03400" target="_blank">arXiv:2102.03400</a> [<a href="http://arxiv.org/pdf/2102.03400" target="_blank">pdf</a>]

<h2>Robust Principal Component Analysis: A Median of Means Approach. (arXiv:2102.03403v1 [stat.ML])</h2>
<h3>Debolina Paul, Saptarshi Chakraborty, Swagatam Das</h3>
<p>Principal Component Analysis (PCA) is a fundamental tool for data
visualization, denoising, and dimensionality reduction. It is widely popular in
Statistics, Machine Learning, Computer Vision, and related fields. However, PCA
is well known to fall prey to the presence of outliers and often fails to
detect the true underlying low-dimensional structure within the dataset. Recent
supervised learning methods, following the Median of Means (MoM) philosophy,
have shown great success in dealing with outlying observations without much
compromise to their large sample theoretical properties. In this paper, we
propose a PCA procedure based on the MoM principle. Called the Median of Means
Principal Component Analysis (MoMPCA), the proposed method is not only
computationally appealing but also achieves optimal convergence rates under
minimal assumptions. In particular, we explore the non-asymptotic error bounds
of the obtained solution via the aid of Vapnik-Chervonenkis theory and
Rademacher complexity, while granting absolutely no assumption on the outlying
observations. The efficacy of the proposal is also thoroughly showcased through
simulations and real data applications.
</p>
<a href="http://arxiv.org/abs/2102.03403" target="_blank">arXiv:2102.03403</a> [<a href="http://arxiv.org/pdf/2102.03403" target="_blank">pdf</a>]

<h2>Symbolic Behaviour in Artificial Intelligence. (arXiv:2102.03406v1 [cs.AI])</h2>
<h3>Adam Santoro, Andrew Lampinen, Kory Mathewson, Timothy Lillicrap, David Raposo</h3>
<p>The ability to use symbols is the pinnacle of human intelligence, but has yet
to be fully replicated in machines. Here we argue that the path towards
symbolically fluent artificial intelligence (AI) begins with a reinterpretation
of what symbols are, how they come to exist, and how a system behaves when it
uses them. We begin by offering an interpretation of symbols as entities whose
meaning is established by convention. But crucially, something is a symbol only
for those who demonstrably and actively participate in this convention. We then
outline how this interpretation thematically unifies the behavioural traits
humans exhibit when they use symbols. This motivates our proposal that the
field place a greater emphasis on symbolic behaviour rather than particular
computational mechanisms inspired by more restrictive interpretations of
symbols. Finally, we suggest that AI research explore social and cultural
engagement as a tool to develop the cognitive machinery necessary for symbolic
behaviour to emerge. This approach will allow for AI to interpret something as
symbolic on its own rather than simply manipulate things that are only symbols
to human onlookers, and thus will ultimately lead to AI with more human-like
symbolic fluency.
</p>
<a href="http://arxiv.org/abs/2102.03406" target="_blank">arXiv:2102.03406</a> [<a href="http://arxiv.org/pdf/2102.03406" target="_blank">pdf</a>]

<h2>Machine Learning in Precision Medicine to Preserve Privacy via Encryption. (arXiv:2102.03412v1 [cs.LG])</h2>
<h3>William Briguglio, Parisa Moghaddam, Waleed A. Yousef, Issa Traore, Mohammad Mamun</h3>
<p>Precision medicine is an emerging approach for disease treatment and
prevention that delivers personalized care to individual patients by
considering their genetic makeups, medical histories, environments, and
lifestyles. Despite the rapid advancement of precision medicine and its
considerable promise, several underlying technological challenges remain
unsolved. One such challenge of great importance is the security and privacy of
precision health-related data, such as genomic data and electronic health
records, which stifle collaboration and hamper the full potential of
machine-learning (ML) algorithms. To preserve data privacy while providing ML
solutions, this article makes three contributions. First, we propose a generic
machine learning with encryption (MLE) framework, which we used to build an ML
model that predicts cancer from one of the most recent comprehensive genomics
datasets in the field. Second, our framework's prediction accuracy is slightly
higher than that of the most recent studies conducted on the same dataset, yet
it maintains the privacy of the patients' genomic data. Third, to facilitate
the validation, reproduction, and extension of this work, we provide an
open-source repository that contains the design and implementation of the
framework, all the ML experiments and code, and the final predictive model
deployed to a free cloud service.
</p>
<a href="http://arxiv.org/abs/2102.03412" target="_blank">arXiv:2102.03412</a> [<a href="http://arxiv.org/pdf/2102.03412" target="_blank">pdf</a>]

<h2>Exploring the Limits of Few-Shot Link Prediction in Knowledge Graphs. (arXiv:2102.03419v1 [cs.AI])</h2>
<h3>Dora Jambor, Komal Teru, Joelle Pineau, William L. Hamilton</h3>
<p>Real-world knowledge graphs are often characterized by low-frequency
relations - a challenge that has prompted an increasing interest in few-shot
link prediction methods. These methods perform link prediction for a set of new
relations, unseen during training, given only a few example facts of each
relation at test time. In this work, we perform a systematic study on a
spectrum of models derived by generalizing the current state of the art for
few-shot link prediction, with the goal of probing the limits of learning in
this few-shot setting. We find that a simple zero-shot baseline - which ignores
any relation-specific information - achieves surprisingly strong performance.
Moreover, experiments on carefully crafted synthetic datasets show that having
only a few examples of a relation fundamentally limits models from using
fine-grained structural information and only allows for exploiting the
coarse-grained positional information of entities. Together, our findings
challenge the implicit assumptions and inductive biases of prior work and
highlight new directions for research in this area.
</p>
<a href="http://arxiv.org/abs/2102.03419" target="_blank">arXiv:2102.03419</a> [<a href="http://arxiv.org/pdf/2102.03419" target="_blank">pdf</a>]

<h2>Learning Audio-Visual Correlations from Variational Cross-Modal Generation. (arXiv:2102.03424v1 [cs.CV])</h2>
<h3>Ye Zhu, Yu Wu, Hugo Latapie, Yi Yang, Yan Yan</h3>
<p>People can easily imagine the potential sound while seeing an event. This
natural synchronization between audio and visual signals reveals their
intrinsic correlations. To this end, we propose to learn the audio-visual
correlations from the perspective of cross-modal generation in a
self-supervised manner, the learned correlations can be then readily applied in
multiple downstream tasks such as the audio-visual cross-modal localization and
retrieval. We introduce a novel Variational AutoEncoder (VAE) framework that
consists of Multiple encoders and a Shared decoder (MS-VAE) with an additional
Wasserstein distance constraint to tackle the problem. Extensive experiments
demonstrate that the optimized latent representation of the proposed MS-VAE can
effectively learn the audio-visual correlations and can be readily applied in
multiple audio-visual downstream tasks to achieve competitive performance even
without any given label information during training.
</p>
<a href="http://arxiv.org/abs/2102.03424" target="_blank">arXiv:2102.03424</a> [<a href="http://arxiv.org/pdf/2102.03424" target="_blank">pdf</a>]

<h2>Advanced Stationary and Non-Stationary Kernel Designs for Domain-Aware Gaussian Processes. (arXiv:2102.03432v1 [stat.ML])</h2>
<h3>Marcus M. Noack, James A. Sethian</h3>
<p>Gaussian process regression is a widely-applied method for function
approximation and uncertainty quantification. The technique has gained
popularity recently in the machine learning community due to its robustness and
interpretability. The mathematical methods we discuss in this paper are an
extension of the Gaussian-process framework. We are proposing advanced kernel
designs that only allow for functions with certain desirable characteristics to
be elements of the reproducing kernel Hilbert space (RKHS) that underlies all
kernel methods and serves as the sample space for Gaussian process regression.
These desirable characteristics reflect the underlying physics; two obvious
examples are symmetry and periodicity constraints. In addition, non-stationary
kernel designs can be defined in the same framework to yield flexible
multi-task Gaussian processes. We will show the impact of advanced kernel
designs on Gaussian processes using several synthetic and two scientific data
sets. The results show that including domain knowledge, communicated through
advanced kernel designs, has a significant impact on the accuracy and relevance
of the function approximation.
</p>
<a href="http://arxiv.org/abs/2102.03432" target="_blank">arXiv:2102.03432</a> [<a href="http://arxiv.org/pdf/2102.03432" target="_blank">pdf</a>]

<h2>Custom Object Detection via Multi-Camera Self-Supervised Learning. (arXiv:2102.03442v1 [cs.CV])</h2>
<h3>Yan Lu, Yuanchao Shu</h3>
<p>This paper proposes MCSSL, a self-supervised learning approach for building
custom object detection models in multi-camera networks. MCSSL associates
bounding boxes between cameras with overlapping fields of view by leveraging
epipolar geometry and state-of-the-art tracking and reID algorithms, and
prudently generates two sets of pseudo-labels to fine-tune backbone and
detection networks respectively in an object detection model. To train
effectively on pseudo-labels,a powerful reID-like pretext task with consistency
loss is constructed for model customization. Our evaluation shows that compared
with legacy selftraining methods, MCSSL improves average mAP by 5.44% and 6.76%
on WildTrack and CityFlow dataset, respectively.
</p>
<a href="http://arxiv.org/abs/2102.03442" target="_blank">arXiv:2102.03442</a> [<a href="http://arxiv.org/pdf/2102.03442" target="_blank">pdf</a>]

<h2>LION: Lidar-Inertial Observability-Aware Navigator for Vision-Denied Environments. (arXiv:2102.03443v1 [cs.RO])</h2>
<h3>Andrea Tagliabue, Jesus Tordesillas, Xiaoyi Cai, Angel Santamaria-Navarro, Jonathan P. How, Luca Carlone, Ali-akbar Agha-mohammadi</h3>
<p>State estimation for robots navigating in GPS-denied and
perceptually-degraded environments, such as underground tunnels, mines and
planetary subsurface voids, remains challenging in robotics. Towards this goal,
we present LION (Lidar-Inertial Observability-Aware Navigator), which is part
of the state estimation framework developed by the team CoSTAR for the DARPA
Subterranean Challenge, where the team achieved second and first places in the
Tunnel and Urban circuits in August 2019 and February 2020, respectively. LION
provides high-rate odometry estimates by fusing high-frequency inertial data
from an IMU and low-rate relative pose estimates from a lidar via a fixed-lag
sliding window smoother. LION does not require knowledge of relative
positioning between lidar and IMU, as the extrinsic calibration is estimated
online. In addition, LION is able to self-assess its performance using an
observability metric that evaluates whether the pose estimate is geometrically
ill-constrained. Odometry and confidence estimates are used by HeRO, a
supervisory algorithm that provides robust estimates by switching between
different odometry sources. In this paper we benchmark the performance of LION
in perceptually-degraded subterranean environments, demonstrating its high
technology readiness level for deployment in the field.
</p>
<a href="http://arxiv.org/abs/2102.03443" target="_blank">arXiv:2102.03443</a> [<a href="http://arxiv.org/pdf/2102.03443" target="_blank">pdf</a>]

<h2>Scalable Robust Graph and Feature Extraction for Arbitrary Vessel Networks in Large Volumetric Datasets. (arXiv:2102.03444v1 [cs.CV])</h2>
<h3>Dominik Drees, Aaron Scherzinger, Ren&#xe9; H&#xe4;gerling, Friedemann Kiefer, Xiaoyi Jiang</h3>
<p>Recent advances in 3D imaging technologies provide novel insights to
researchers and reveal finer and more detail of examined specimen, especially
in the biomedical domain, but also impose huge challenges regarding scalability
for automated analysis algorithms due to rapidly increasing dataset sizes. In
particular, existing research towards automated vessel network analysis does
not consider memory requirements of proposed algorithms and often generates a
large number of spurious branches for structures consisting of many voxels.
Additionally, very often these algorithms have further restrictions such as the
limitation to tree topologies or relying on the properties of specific image
modalities. We present a scalable pipeline (in terms of computational cost,
required main memory and robustness) that extracts an annotated abstract graph
representation from the foreground segmentation of vessel networks of arbitrary
topology and vessel shape. Only a single, dimensionless, a-priori determinable
parameter is required. By careful engineering of individual pipeline stages and
a novel iterative refinement scheme we are, for the first time, able to analyze
the topology of volumes of roughly 1TB on commodity hardware. An implementation
of the presented pipeline is publicly available in version 5.1 of the volume
rendering and processing engine Voreen (https://www.uni-muenster.de/Voreen/).
</p>
<a href="http://arxiv.org/abs/2102.03444" target="_blank">arXiv:2102.03444</a> [<a href="http://arxiv.org/pdf/2102.03444" target="_blank">pdf</a>]

<h2>Federated Reconstruction: Partially Local Federated Learning. (arXiv:2102.03448v1 [cs.LG])</h2>
<h3>Karan Singhal, Hakim Sidahmed, Zachary Garrett, Shanshan Wu, Keith Rush, Sushant Prakash</h3>
<p>Personalization methods in federated learning aim to balance the benefits of
federated and local training for data availability, communication cost, and
robustness to client heterogeneity. Approaches that require clients to
communicate all model parameters can be undesirable due to privacy and
communication constraints. Other approaches require always-available or
stateful clients, impractical in large-scale cross-device settings. We
introduce Federated Reconstruction, the first model-agnostic framework for
partially local federated learning suitable for training and inference at
scale. We motivate the framework via a connection to model-agnostic meta
learning, empirically demonstrate its performance over existing approaches for
collaborative filtering and next word prediction, and release an open-source
library for evaluating approaches in this setting. We also describe the
successful deployment of this approach at scale for federated collaborative
filtering in a mobile keyboard application.
</p>
<a href="http://arxiv.org/abs/2102.03448" target="_blank">arXiv:2102.03448</a> [<a href="http://arxiv.org/pdf/2102.03448" target="_blank">pdf</a>]

<h2>Wasserstein diffusion on graphs with missing attributes. (arXiv:2102.03450v1 [cs.LG])</h2>
<h3>Zhixian Chen, Tengfei Ma, Yangqiu Song, Yang Wang</h3>
<p>Missing node attributes is a common problem in real-world graphs. Graph
neural networks have been demonstrated powerful in graph representation
learning, however, they rely heavily on the completeness of graph information.
Few of them consider the incomplete node attributes, which can bring great
damage to the performance in practice. In this paper, we propose an innovative
node representation learning framework, Wasserstein graph diffusion (WGD), to
mitigate the problem. Instead of feature imputation, our method directly learns
node representations from the missing-attribute graphs. Specifically, we extend
the message passing schema in general graph neural networks to a Wasserstein
space derived from the decomposition of attribute matrices. We test WGD in node
classification tasks under two settings: missing whole attributes on some nodes
and missing only partial attributes on all nodes. In addition, we find WGD is
suitable to recover missing values and adapt it to tackle matrix completion
problems with graphs of users and items. Experimental results on both tasks
demonstrate the superiority of our method.
</p>
<a href="http://arxiv.org/abs/2102.03450" target="_blank">arXiv:2102.03450</a> [<a href="http://arxiv.org/pdf/2102.03450" target="_blank">pdf</a>]

<h2>BinaryCoP: Binary Neural Network-based COVID-19 Face-Mask Wear and Positioning Predictor on Edge Devices. (arXiv:2102.03456v1 [cs.CV])</h2>
<h3>Nael Fasfous, Manoj-Rohit Vemparala, Alexander Frickenstein, Lukas Frickenstein, Walter Stechele</h3>
<p>Face masks have long been used in many areas of everyday life to protect
against the inhalation of hazardous fumes and particles. They also offer an
effective solution in healthcare for bi-directional protection against
air-borne diseases. Wearing and positioning the mask correctly is essential for
its function. Convolutional neural networks (CNNs) offer an excellent solution
for face recognition and classification of correct mask wearing and
positioning. In the context of the ongoing COVID-19 pandemic, such algorithms
can be used at entrances to corporate buildings, airports, shopping areas, and
other indoor locations, to mitigate the spread of the virus. These application
scenarios impose major challenges to the underlying compute platform. The
inference hardware must be cheap, small and energy efficient, while providing
sufficient memory and compute power to execute accurate CNNs at a reasonably
low latency. To maintain data privacy of the public, all processing must remain
on the edge-device, without any communication with cloud servers. To address
these challenges, we present a low-power binary neural network classifier for
correct facial-mask wear and positioning. The classification task is
implemented on an embedded FPGA, performing high-throughput binary operations.
Classification can take place at up to ~6400 frames-per-second, easily enabling
multi-camera, speed-gate settings or statistics collection in crowd settings.
When deployed on a single entrance or gate, the idle power consumption is
reduced to 1.6W, improving the battery-life of the device. We achieve an
accuracy of up to 98% for four wearing positions of the MaskedFace-Net dataset.
To maintain equivalent classification accuracy for all face structures,
skin-tones, hair types, and mask types, the algorithms are tested for their
ability to generalize the relevant features over all subjects using the
Grad-CAM approach.
</p>
<a href="http://arxiv.org/abs/2102.03456" target="_blank">arXiv:2102.03456</a> [<a href="http://arxiv.org/pdf/2102.03456" target="_blank">pdf</a>]

<h2>Improving Model and Search for Computer Go. (arXiv:2102.03467v1 [cs.AI])</h2>
<h3>Tristan Cazenave</h3>
<p>The standard for Deep Reinforcement Learning in games, following Alpha Zero,
is to use residual networks and to increase the depth of the network to get
better results. We propose to improve mobile networks as an alternative to
residual networks and experimentally show the playing strength of the networks
according to both their width and their depth. We also propose a generalization
of the PUCT search algorithm that improves on PUCT.
</p>
<a href="http://arxiv.org/abs/2102.03467" target="_blank">arXiv:2102.03467</a> [<a href="http://arxiv.org/pdf/2102.03467" target="_blank">pdf</a>]

<h2>Hyperparameter Tricks in Multi-Agent Reinforcement Learning: An Empirical Study. (arXiv:2102.03479v1 [cs.LG])</h2>
<h3>Jian Hu, Haibin Wu, Seth Austin Harding, Shih-wei Liao</h3>
<p>In recent years, multi-agent deep reinforcement learning has been
successfully applied to various complicated scenarios such as computer games
and robot swarms. We thoroughly study and compare the state-of-the-art
cooperative multi-agent deep reinforcement learning algorithms. Specifically,
we investigate the consequences of the "hyperparameter tricks" of QMIX and its
improved variants. Our results show that: (1) The significant performance
improvements of these variant algorithms come from hyperparameter-level
optimizations in their open-source codes (2) After modest tuning and with no
changes to the network architecture, QMIX can attain extraordinarily high win
rates in all hard and super hard scenarios of StarCraft Multi-Agent Challenge
(SMAC) and achieve state-of-the-art (SOTA). In this work, we proposed a
reliable QMIX benchmark, which will be of great benefit to subsequent research.
Besides, we proposed a hypothesis to explain the excellent performance of QMIX.
</p>
<a href="http://arxiv.org/abs/2102.03479" target="_blank">arXiv:2102.03479</a> [<a href="http://arxiv.org/pdf/2102.03479" target="_blank">pdf</a>]

<h2>Understanding the Interaction of Adversarial Training with Noisy Labels. (arXiv:2102.03482v1 [cs.LG])</h2>
<h3>Jianing Zhu, Jingfeng Zhang, Bo Han, Tongliang Liu, Gang Niu, Hongxia Yang, Mohan Kankanhalli, Masashi Sugiyama</h3>
<p>Noisy labels (NL) and adversarial examples both undermine trained models, but
interestingly they have hitherto been studied independently. A recent
adversarial training (AT) study showed that the number of projected gradient
descent (PGD) steps to successfully attack a point (i.e., find an adversarial
example in its proximity) is an effective measure of the robustness of this
point. Given that natural data are clean, this measure reveals an intrinsic
geometric property -- how far a point is from its class boundary. Based on this
breakthrough, in this paper, we figure out how AT would interact with NL.
Firstly, we find if a point is too close to its noisy-class boundary (e.g., one
step is enough to attack it), this point is likely to be mislabeled, which
suggests to adopt the number of PGD steps as a new criterion for sample
selection for correcting NL. Secondly, we confirm AT with strong smoothing
effects suffers less from NL (without NL corrections) than standard training
(ST), which suggests AT itself is an NL correction. Hence, AT with NL is
helpful for improving even the natural accuracy, which again illustrates the
superiority of AT as a general-purpose robust learning criterion.
</p>
<a href="http://arxiv.org/abs/2102.03482" target="_blank">arXiv:2102.03482</a> [<a href="http://arxiv.org/pdf/2102.03482" target="_blank">pdf</a>]

<h2>Corner Case Generation and Analysis for Safety Assessment of Autonomous Vehicles. (arXiv:2102.03483v1 [cs.AI])</h2>
<h3>Haowei Sun, Shuo Feng, Xintao Yan, Henry X. Liu</h3>
<p>Testing and evaluation is a crucial step in the development and deployment of
Connected and Automated Vehicles (CAVs). To comprehensively evaluate the
performance of CAVs, it is of necessity to test the CAVs in safety-critical
scenarios, which rarely happen in naturalistic driving environment. Therefore,
how to purposely and systematically generate these corner cases becomes an
important problem. Most existing studies focus on generating adversarial
examples for perception systems of CAVs, whereas limited efforts have been put
on the decision-making systems, which is the highlight of this paper. As the
CAVs need to interact with numerous background vehicles (BVs) for a long
duration, variables that define the corner cases are usually high dimensional,
which makes the generation a challenging problem. In this paper, a unified
framework is proposed to generate corner cases for the decision-making systems.
To address the challenge brought by high dimensionality, the driving
environment is formulated based on Markov Decision Process, and the deep
reinforcement learning techniques are applied to learn the behavior policy of
BVs. With the learned policy, BVs will behave and interact with the CAVs more
aggressively, resulting in more corner cases. To further analyze the generated
corner cases, the techniques of feature extraction and clustering are utilized.
By selecting representative cases of each cluster and outliers, the valuable
corner cases can be identified from all generated corner cases. Simulation
results of a highway driving environment show that the proposed methods can
effectively generate and identify the valuable corner cases.
</p>
<a href="http://arxiv.org/abs/2102.03483" target="_blank">arXiv:2102.03483</a> [<a href="http://arxiv.org/pdf/2102.03483" target="_blank">pdf</a>]

<h2>IC Networks: Remodeling the Basic Unit for Convolutional Neural Networks. (arXiv:2102.03495v1 [cs.CV])</h2>
<h3>Junyi An, Fengshan Liu, Jian Zhao, Furao Shen</h3>
<p>Convolutional neural network (CNN) is a class of artificial neural networks
widely used in computer vision tasks. Most CNNs achieve excellent performance
by stacking certain types of basic units. In addition to increasing the depth
and width of the network, designing more effective basic units has become an
important research topic. Inspired by the elastic collision model in physics,
we present a general structure which can be integrated into the existing CNNs
to improve their performance. We term it the "Inter-layer Collision" (IC)
structure. Compared to the traditional convolution structure, the IC structure
introduces nonlinearity and feature recalibration in the linear convolution
operation, which can capture more fine-grained features. In addition, a new
training method, namely weak logit distillation (WLD), is proposed to speed up
the training of IC networks by extracting knowledge from pre-trained basic
models. In the ImageNet experiment, we integrate the IC structure into
ResNet-50 and reduce the top-1 error from 22.38% to 21.75%, which also catches
up the top-1 error of ResNet-100 (21.75%) with nearly half of FLOPs.
</p>
<a href="http://arxiv.org/abs/2102.03495" target="_blank">arXiv:2102.03495</a> [<a href="http://arxiv.org/pdf/2102.03495" target="_blank">pdf</a>]

<h2>The Implicit Biases of Stochastic Gradient Descent on Deep Neural Networks with Batch Normalization. (arXiv:2102.03497v1 [cs.LG])</h2>
<h3>Ziquan Liu, Yufei Cui, Jia Wan, Yu Mao, Antoni B. Chan</h3>
<p>Deep neural networks with batch normalization (BN-DNNs) are invariant to
weight rescaling due to their normalization operations. However, using weight
decay (WD) benefits these weight-scale-invariant networks, which is often
attributed to an increase of the effective learning rate when the weight norms
are decreased. In this paper, we demonstrate the insufficiency of the previous
explanation and investigate the implicit biases of stochastic gradient descent
(SGD) on BN-DNNs to provide a theoretical explanation for the efficacy of
weight decay. We identity two implicit biases of SGD on BN-DNNs: 1) the weight
norms in SGD training remain constant in the continuous-time domain and keep
increasing in the discrete-time domain; 2) SGD optimizes weight vectors in
fully-connected networks or convolution kernels in convolution neural networks
by updating components lying in the input feature span, while leaving those
components orthogonal to the input feature span unchanged. Thus, SGD without WD
accumulates weight noise orthogonal to the input feature span, and cannot
eliminate such noise. Our empirical studies corroborate the hypothesis that
weight decay suppresses weight noise that is left untouched by SGD.
Furthermore, we propose to use weight rescaling (WRS) instead of weight decay
to achieve the same regularization effect, while avoiding performance
degradation of WD on some momentum-based optimizers. Our empirical results on
image recognition show that regardless of optimization methods and network
architectures, training BN-DNNs using WRS achieves similar or better
performance compared with using WD. We also show that training with WRS
generalizes better compared to WD, on other computer vision tasks.
</p>
<a href="http://arxiv.org/abs/2102.03497" target="_blank">arXiv:2102.03497</a> [<a href="http://arxiv.org/pdf/2102.03497" target="_blank">pdf</a>]

<h2>Two-Step Image Dehazing with Intra-domain and Inter-domain Adaption. (arXiv:2102.03501v1 [cs.CV])</h2>
<h3>Xin Yi, Bo Ma, Yulin Zhang, Longyao Liu, JiaHao Wu</h3>
<p>Recently, image dehazing task has achieved remarkable progress by
convolutional neural network. However, those approaches mostly treat haze
removal as a one-to-one problem and ignore the intra-domain gap. Therefore,
haze distribution shift of the same scene images is not handled well. Also,
dehazing models trained on the labeled synthetic datasets mostly suffer from
performance degradation when tested on the unlabeled real datasets due to the
inter-domain gap. Although some previous works apply translation network to
bridge the synthetic domain and the real domain, the intra-domain gap still
exists and affects the inter-domain adaption. In this work, we propose a novel
Two-Step Dehazing Network (TSDN) to minimize the intra-domain gap and the
inter-domain gap. First, we propose a multi-to-one dehazing network to
eliminate the haze distribution shift of images within the synthetic domain.
Then, we conduct an inter-domain adaption between the synthetic domain and the
real domain based on the aligned synthetic features. Extensive experimental
results demonstrate that our framework performs favorably against the
state-of-the-art algorithms both on the synthetic datasets and the real
datasets.
</p>
<a href="http://arxiv.org/abs/2102.03501" target="_blank">arXiv:2102.03501</a> [<a href="http://arxiv.org/pdf/2102.03501" target="_blank">pdf</a>]

<h2>Template-Free Try-on Image Synthesis via Semantic-guided Optimization. (arXiv:2102.03503v1 [cs.CV])</h2>
<h3>Chien-Lung Chou, Chieh-Yun Chen, Chia-Wei Hsieh, Hong-Han Shuai, Jiaying Liu, Wen-Huang Cheng</h3>
<p>The virtual try-on task is so attractive that it has drawn considerable
attention in the field of computer vision. However, presenting the
three-dimensional (3D) physical characteristic (e.g., pleat and shadow) based
on a 2D image is very challenging. Although there have been several previous
studies on 2D-based virtual try-on work, most 1) required user-specified target
poses that are not user-friendly and may not be the best for the target
clothing, and 2) failed to address some problematic cases, including facial
details, clothing wrinkles and body occlusions. To address these two
challenges, in this paper, we propose an innovative template-free try-on image
synthesis (TF-TIS) network. The TF-TIS first synthesizes the target pose
according to the user-specified in-shop clothing. Afterward, given an in-shop
clothing image, a user image, and a synthesized pose, we propose a novel model
for synthesizing a human try-on image with the target clothing in the best
fitting pose. The qualitative and quantitative experiments both indicate that
the proposed TF-TIS outperforms the state-of-the-art methods, especially for
difficult cases.
</p>
<a href="http://arxiv.org/abs/2102.03503" target="_blank">arXiv:2102.03503</a> [<a href="http://arxiv.org/pdf/2102.03503" target="_blank">pdf</a>]

<h2>Robust normalizing flows using Bernstein-type polynomials. (arXiv:2102.03509v1 [cs.LG])</h2>
<h3>Sameera Ramasinghe, Kasun Fernando, Salman Khan, Nick Barnes</h3>
<p>Normalizing flows (NFs) are a class of generative models that allows exact
density evaluation and sampling. We propose a framework to construct NFs based
on increasing triangular maps and Bernstein-type polynomials. Compared to the
existing (universal) NF frameworks, our method provides compelling advantages
like theoretical upper bounds for the approximation error, robustness, higher
interpretability, suitability for compactly supported densities, and the
ability to employ higher degree polynomials without training instability.
Moreover, we provide a constructive universality proof, which gives analytic
expressions of the approximations for known transformations. We conduct a
thorough theoretical analysis and empirically demonstrate the efficacy of the
proposed technique using experiments on both real-world and synthetic datasets.
</p>
<a href="http://arxiv.org/abs/2102.03509" target="_blank">arXiv:2102.03509</a> [<a href="http://arxiv.org/pdf/2102.03509" target="_blank">pdf</a>]

<h2>MOTS R-CNN: Cosine-margin-triplet loss for multi-object tracking. (arXiv:2102.03512v1 [cs.CV])</h2>
<h3>Amit Satish Unde, Renu M. Rameshan</h3>
<p>One of the central tasks of multi-object tracking involves learning a
distance metric that is consistent with the semantic similarities of objects.
The design of an appropriate loss function that encourages discriminative
feature learning is among the most crucial challenges in deep neural
network-based metric learning. Despite significant progress, slow convergence
and a poor local optimum of the existing contrastive and triplet loss based
deep metric learning methods necessitates a better solution. In this paper, we
propose cosine-margin-contrastive (CMC) and cosine-margin-triplet (CMT) loss by
reformulating both contrastive and triplet loss functions from the perspective
of cosine distance. The proposed reformulation as a cosine loss is achieved by
feature normalization which distributes the learned features on a hypersphere.
We then propose the MOTS R-CNN framework for joint multi-object tracking and
segmentation, particularly targeted at improving the tracking performance.
Specifically, the tracking problem is addressed through deep metric learning
based on the proposed loss functions. We propose a scale-invariant tracking by
using a multi-layer feature aggregation scheme to make the model robust against
object scale variations and occlusions. The MOTS R-CNN achieves the
state-of-the-art tracking performance on the KITTI MOTS dataset. We show that
the MOTS R-CNN reduces the identity switching by $62\%$ and $61\%$ on cars and
pedestrians, respectively in comparison to Track R-CNN.
</p>
<a href="http://arxiv.org/abs/2102.03512" target="_blank">arXiv:2102.03512</a> [<a href="http://arxiv.org/pdf/2102.03512" target="_blank">pdf</a>]

<h2>Video-based Hierarchical Species Classification for Longline Fishing Monitoring. (arXiv:2102.03520v1 [cs.CV])</h2>
<h3>Jie Mei, Jenq-Neng Hwang, Suzanne Romain, Craig Rose, Braden Moore, Kelsey Magrane</h3>
<p>The goal of electronic monitoring (EM) of longline fishing is to monitor the
fish catching activities on fishing vessels, either for the regulatory
compliance or catch counting. Hierarchical classification based on videos
allows for inexpensive and efficient fish species identification of catches
from longline fishing, where fishes are under severe deformation and
self-occlusion during the catching process. More importantly, the flexibility
of hierarchical classification mitigates the laborious efforts of human reviews
by providing confidence scores in different hierarchical levels. Some related
works either use cascaded models for hierarchical classification or make
predictions per image or predict one overlapping hierarchical data structure of
the dataset in advance. However, with a known non-overlapping hierarchical data
structure provided by fisheries scientists, our method enforces the
hierarchical data structure and introduces an efficient training and inference
strategy for video-based fisheries data. Our experiments show that the proposed
method outperforms the classic flat classification system significantly and our
ablation study justifies our contributions in CNN model design, training
strategy, and the video-based inference schemes for the hierarchical fish
species classification task.
</p>
<a href="http://arxiv.org/abs/2102.03520" target="_blank">arXiv:2102.03520</a> [<a href="http://arxiv.org/pdf/2102.03520" target="_blank">pdf</a>]

<h2>Haptic-enabled Mixed Reality System for Mixed-initiative Remote Robot Control. (arXiv:2102.03521v1 [cs.RO])</h2>
<h3>Yuan Tian, Lianjun Li, Andrea Fumagalli, Yonas Tanesse, Balakrishnan Prabhakaran</h3>
<p>Robots assist in many areas that are considered unsafe for humans to operate.
For instance, in handling pandemic diseases such as the recent Covid-19
outbreak and other outbreaks like Ebola, robots can assist in reaching areas
dangerous for humans and do simple tasks such as pick up the correct medicine
(among a set of bottles prescribed) and deliver to patients. In such cases, it
might not be good to rely on the fully autonomous operation of robots. Since
many mobile robots are fully functional with low-level tasks such as grabbing
and moving, we consider the mixed-initiative control where the user can guide
the robot remotely to finish such tasks. For this mixed-initiative control, the
user controlling the robot needs to visualize a 3D scene as seen by the robot
and guide it. Mixed reality can virtualize reality and immerse users in the 3D
scene that is reconstructed from the real-world environment. This technique
provides the user more freedom such as choosing viewpoints at view time. In
recent years, benefiting from the high-quality data from Light Detection and
Ranging (LIDAR) and RGBD cameras, mixed reality is widely used to build
networked platforms to improve the performance of robot teleoperations and
robot-human collaboration, and enhanced feedback for mixed-initiative control.
In this paper, we proposed a novel haptic-enabled mixed reality system, that
provides haptic interfaces to interact with the virtualized environments and
give remote guidance for mobile robots towards high-level tasks. The
experimental results show the effectiveness and flexibility of the proposed
haptic enabled mixed reality system.
</p>
<a href="http://arxiv.org/abs/2102.03521" target="_blank">arXiv:2102.03521</a> [<a href="http://arxiv.org/pdf/2102.03521" target="_blank">pdf</a>]

<h2>Exclusive Topic Modeling. (arXiv:2102.03525v1 [stat.ML])</h2>
<h3>Hao Lei, Ying Chen</h3>
<p>We propose an Exclusive Topic Modeling (ETM) for unsupervised text
classification, which is able to 1) identify the field-specific keywords though
less frequently appeared and 2) deliver well-structured topics with exclusive
words. In particular, a weighted Lasso penalty is imposed to reduce the
dominance of the frequently appearing yet less relevant words automatically,
and a pairwise Kullback-Leibler divergence penalty is used to implement topics
separation. Simulation studies demonstrate that the ETM detects the
field-specific keywords, while LDA fails. When applying to the benchmark NIPS
dataset, the topic coherence score on average improves by 22% and 10% for the
model with weighted Lasso penalty and pairwise Kullback-Leibler divergence
penalty, respectively.
</p>
<a href="http://arxiv.org/abs/2102.03525" target="_blank">arXiv:2102.03525</a> [<a href="http://arxiv.org/pdf/2102.03525" target="_blank">pdf</a>]

<h2>Open-World Semi-Supervised Learning. (arXiv:2102.03526v1 [cs.LG])</h2>
<h3>Kaidi Cao, Maria Brbic, Jure Leskovec</h3>
<p>Supervised and semi-supervised learning methods have been traditionally
designed for the closed-world setting based on the assumption that unlabeled
test data contains only classes previously encountered in the labeled training
data. However, the real world is inherently open and dynamic, and thus novel,
previously unseen classes may appear in the test data or during the model
deployment. Here, we introduce a new open-world semi-supervised learning
setting in which the model is required to recognize previously seen classes, as
well as to discover novel classes never seen in the labeled dataset. To tackle
the problem, we propose ORCA, an approach that learns to simultaneously
classify and cluster the data. ORCA classifies examples from the unlabeled
dataset to previously seen classes, or forms a novel class by grouping similar
examples together. The key idea in ORCA is in introducing uncertainty based
adaptive margin that effectively circumvents the bias caused by the imbalance
of variance between seen and novel classes/clusters. We demonstrate that ORCA
accurately discovers novel classes and assigns samples to previously seen
classes on benchmark image classification datasets, including CIFAR and
ImageNet. Remarkably, despite solving the harder task ORCA outperforms
semi-supervised methods on seen classes, as well as novel class discovery
methods on novel classes, achieving 7% and 151% improvements on seen and novel
classes in the ImageNet dataset.
</p>
<a href="http://arxiv.org/abs/2102.03526" target="_blank">arXiv:2102.03526</a> [<a href="http://arxiv.org/pdf/2102.03526" target="_blank">pdf</a>]

<h2>Vampire With a Brain Is a Good ITP Hammer. (arXiv:2102.03529v1 [cs.AI])</h2>
<h3>Martin Suda</h3>
<p>Vampire has been for a long time the strongest first-order automated theorem
prover, widely used for hammer-style proof automation in ITPs such as Mizar,
Isabelle, HOL and Coq. In this work, we considerably improve the performance of
Vampire in hammering over the full Mizar library by enhancing its saturation
procedure with efficient neural guidance. In particular, we employ a recursive
neural network classifying the generated clauses based only on their derivation
history. Compared to previous neural methods based on considering the logical
content of the clauses, this leads to large real-time speedup of the neural
guidance. The resulting system shows good learning capability and achieves
state-of-the-art performance on the Mizar library, while proving many theorems
that the related ENIGMA system could not prove in a similar hammering
evaluation.
</p>
<a href="http://arxiv.org/abs/2102.03529" target="_blank">arXiv:2102.03529</a> [<a href="http://arxiv.org/pdf/2102.03529" target="_blank">pdf</a>]

<h2>Feedback-based Digital Higher-order Terminal Sliding Mode for 6-DOF Industrial Manipulators. (arXiv:2102.03531v1 [cs.RO])</h2>
<h3>Zhian Kuang, Xiang Zhang, Liting Sun, Huijun Gao, Masayoshi Tomizuka</h3>
<p>The precise motion control of a multi-degree of freedom~(DOF) robot
manipulator is always challenging due to its nonlinear dynamics, disturbances,
and uncertainties. Because most manipulators are controlled by digital signals,
a novel higher-order sliding mode controller in the discrete-time form with
time delay estimation is proposed in this paper. The dynamic model of the
manipulator used in the design allows proper handling of nonlinearities,
uncertainties and disturbances involved in the problem. Specifically,
parametric uncertainties and disturbances are handled by the time delay
estimation and the nonlinearity of the manipulator is addressed by the feedback
structure of the controller. The combination of terminal sliding mode surface
and higher-order control scheme in the controller guarantees a fast response
with a small chattering amplitude. Moreover, the controller is designed with a
modified sliding mode surface and variable-gain structure, so that the
performance of the controller is further enhanced. We also analyze the
condition to guarantee the stability of the closed-loop system in this paper.
Finally, the simulation and experimental results prove that the proposed
control scheme has a precise performance in a robot manipulator system.
</p>
<a href="http://arxiv.org/abs/2102.03531" target="_blank">arXiv:2102.03531</a> [<a href="http://arxiv.org/pdf/2102.03531" target="_blank">pdf</a>]

<h2>Sill-Net: Feature Augmentation with Separated Illumination Representation. (arXiv:2102.03539v1 [cs.CV])</h2>
<h3>Haipeng Zhang, Zhong Cao, Ziang Yan, Changshui Zhang</h3>
<p>For visual object recognition tasks, the illumination variations can cause
distinct changes in object appearance and thus confuse the deep neural network
based recognition models. Especially for some rare illumination conditions,
collecting sufficient training samples could be time-consuming and expensive.
To solve this problem, in this paper we propose a novel neural network
architecture called Separating-Illumination Network (Sill-Net). Sill-Net learns
to separate illumination features from images, and then during training we
augment training samples with these separated illumination features in the
feature space. Experimental results demonstrate that our approach outperforms
current state-of-the-art methods in several object classification benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.03539" target="_blank">arXiv:2102.03539</a> [<a href="http://arxiv.org/pdf/2102.03539" target="_blank">pdf</a>]

<h2>UniFuse: Unidirectional Fusion for 360$^{\circ}$ Panorama Depth Estimation. (arXiv:2102.03550v1 [cs.CV])</h2>
<h3>Hualie Jiang, Zhe Sheng, Siyu Zhu, Zilong Dong, Rui Huang</h3>
<p>Learning depth from spherical panoramas is becoming a popular research topic
because a panorama has a full field-of-view of the environment and provides a
relatively complete description of a scene. However, applying well-studied CNNs
for perspective images to the standard representation of spherical panoramas,
i.e., the equirectangular projection, is suboptimal, as it becomes distorted
towards the poles. Another representation is the cubemap projection, which is
distortion-free but discontinued on edges and limited in the field-of-view.
This paper introduces a new framework to fuse features from the two
projections, unidirectionally feeding the cubemap features to the
equirectangular features only at the decoding stage. Unlike the recent
bidirectional fusion approach operating at both the encoding and decoding
stages, our fusion scheme is much more efficient. Besides, we also designed a
more effective fusion module for our fusion scheme. Experiments verify the
effectiveness of our proposed fusion strategy and module, and our model
achieves state-of-the-art performance on four popular datasets. Additional
experiments show that our model also has the advantages of model complexity and
generalization capability.
</p>
<a href="http://arxiv.org/abs/2102.03550" target="_blank">arXiv:2102.03550</a> [<a href="http://arxiv.org/pdf/2102.03550" target="_blank">pdf</a>]

<h2>Scheduling Plans of Tasks. (arXiv:2102.03555v1 [cs.AI])</h2>
<h3>Davide Andrea Guastella</h3>
<p>We present a heuristic algorithm for solving the problem of scheduling plans
of tasks. The plans are ordered vectors of tasks, and tasks are basic
operations carried out by resources. Plans are tied by temporal, precedence and
resource constraints that makes the scheduling problem hard to solve in
polynomial time. The proposed heuristic, that has a polynomial worst-case time
complexity, searches for a feasible schedule that maximize the number of plans
scheduled, along a fixed time window, with respect to temporal, precedence and
resource constraints.
</p>
<a href="http://arxiv.org/abs/2102.03555" target="_blank">arXiv:2102.03555</a> [<a href="http://arxiv.org/pdf/2102.03555" target="_blank">pdf</a>]

<h2>SM+: Refined Scale Match for Tiny Person Detection. (arXiv:2102.03558v1 [cs.CV])</h2>
<h3>Nan Jiang, Xuehui Yu, Xiaoke Peng, Yuqi Gong, Zhenjun Han</h3>
<p>Detecting tiny objects ( e.g., less than 20 x 20 pixels) in large-scale
images is an important yet open problem. Modern CNN-based detectors are
challenged by the scale mismatch between the dataset for network pre-training
and the target dataset for detector training. In this paper, we investigate the
scale alignment between pre-training and target datasets, and propose a new
refined Scale Match method (termed SM+) for tiny person detection. SM+ improves
the scale match from image level to instance level, and effectively promotes
the similarity between pre-training and target dataset. Moreover, considering
SM+ possibly destroys the image structure, a new probabilistic structure
inpainting (PSI) method is proposed for the background processing. Experiments
conducted across various detectors show that SM+ noticeably improves the
performance on TinyPerson, and outperforms the state-of-the-art detectors with
a significant margin.
</p>
<a href="http://arxiv.org/abs/2102.03558" target="_blank">arXiv:2102.03558</a> [<a href="http://arxiv.org/pdf/2102.03558" target="_blank">pdf</a>]

<h2>Standard and Event Cameras Fusion for Dense Mapping. (arXiv:2102.03567v1 [cs.RO])</h2>
<h3>Yan Dong</h3>
<p>Event cameras are a kind of bio-inspired sensors that generate data when the
brightness changes. Because of the advantages of low-latency and high dynamic
range (HDR), they are widely used in the field of mobile robots. However, due
to the nature of the sparse event stream, event-based mapping can only obtain
sparse or semi-dense edge 3D maps. By contrast, standard cameras provide
complete frames. To leverage the complementarity of event-based and standard
frame-based cameras, we propose a fusion strategy for dense mapping in this
paper. We first generate an edge map from events, and then fill the map using
frames to obtain the dense depth map.
</p>
<a href="http://arxiv.org/abs/2102.03567" target="_blank">arXiv:2102.03567</a> [<a href="http://arxiv.org/pdf/2102.03567" target="_blank">pdf</a>]

<h2>Scalable Inference of Sparsely-changing Markov Random Fields with Strong Statistical Guarantees. (arXiv:2102.03585v1 [cs.LG])</h2>
<h3>Salar Fattahi, Andres Gomez</h3>
<p>In this paper, we study the problem of inferring time-varying Markov random
fields (MRF), where the underlying graphical model is both sparse and changes
sparsely over time. Most of the existing methods for the inference of
time-varying MRFs rely on the regularized maximum likelihood estimation (MLE),
that typically suffer from weak statistical guarantees and high computational
time. Instead, we introduce a new class of constrained optimization problems
for the inference of sparsely-changing MRFs. The proposed optimization problem
is formulated based on the exact $\ell_0$ regularization, and can be solved in
near-linear time and memory. Moreover, we show that the proposed estimator
enjoys a provably small estimation error. As a special case, we derive sharp
statistical guarantees for the inference of sparsely-changing Gaussian MRFs
(GMRF) in the high-dimensional regime, showing that such problems can be
learned with as few as one sample per time. Our proposed method is extremely
efficient in practice: it can accurately estimate sparsely-changing graphical
models with more than 500 million variables in less than one hour.
</p>
<a href="http://arxiv.org/abs/2102.03585" target="_blank">arXiv:2102.03585</a> [<a href="http://arxiv.org/pdf/2102.03585" target="_blank">pdf</a>]

<h2>CMS-LSTM: Context-Embedding and Multi-Scale Spatiotemporal-Expression LSTM for Video Prediction. (arXiv:2102.03586v1 [cs.CV])</h2>
<h3>Zenghao Chai, Chun Yuan, Zhihui Lin, Yunpeng Bai</h3>
<p>Extracting variation and spatiotemporal features via limited frames remains
as an unsolved and challenging problem in video prediction. Inherent
uncertainty among consecutive frames exacerbates the difficulty in long-term
prediction. To tackle the problem, we focus on capturing context correlations
and multi-scale spatiotemporal flows, then propose CMS-LSTM by integrating two
effective and lightweight blocks, namely Context-Embedding (CE) and
Spatiotemporal-Expression (SE) block, into ConvLSTM backbone. CE block is
designed for abundant context interactions, while SE block focuses on
multi-scale spatiotemporal expression in hidden states. The newly introduced
blocks also facilitate other spatiotemporal models (e.g., PredRNN, SA-ConvLSTM)
to produce representative implicit features for video prediction. Qualitative
and quantitative experiments demonstrate the effectiveness and flexibility of
our proposed method. We use fewer parameters to reach markedly state-of-the-art
results on Moving MNIST and TaxiBJ datasets in numbers of metrics. All source
code is available at https://github.com/czh-98/CMS-LSTM.
</p>
<a href="http://arxiv.org/abs/2102.03586" target="_blank">arXiv:2102.03586</a> [<a href="http://arxiv.org/pdf/2102.03586" target="_blank">pdf</a>]

<h2>An Autonomous Negotiating Agent Framework with Reinforcement Learning Based Strategies and Adaptive Strategy Switching Mechanism. (arXiv:2102.03588v1 [cs.AI])</h2>
<h3>Ayan Sengupta, Yasser Mohammad, Shinji Nakadai</h3>
<p>Despite abundant negotiation strategies in literature, the complexity of
automated negotiation forbids a single strategy from being dominant against all
others in different negotiation scenarios. To overcome this, one approach is to
use mixture of experts, but at the same time, one problem of this method is the
selection of experts, as this approach is limited by the competency of the
experts selected. Another problem with most negotiation strategies is their
incapability of adapting to dynamic variation of the opponent's behaviour
within a single negotiation session resulting in poor performance. This work
focuses on both, solving the problem of expert selection and adapting to the
opponent's behaviour with our Autonomous Negotiating Agent Framework. This
framework allows real-time classification of opponent's behaviour and provides
a mechanism to select, switch or combine strategies within a single negotiation
session. Additionally, our framework has a reviewer component which enables
self-enhancement capability by deciding to include new strategies or replace
old ones with better strategies periodically. We demonstrate an instance of our
framework by implementing maximum entropy reinforcement learning based
strategies with a deep learning based opponent classifier. Finally, we evaluate
the performance of our agent against state-of-the-art negotiators under varied
negotiation scenarios.
</p>
<a href="http://arxiv.org/abs/2102.03588" target="_blank">arXiv:2102.03588</a> [<a href="http://arxiv.org/pdf/2102.03588" target="_blank">pdf</a>]

<h2>Gated3D: Monocular 3D Object Detection From Temporal Illumination Cues. (arXiv:2102.03602v1 [cs.CV])</h2>
<h3>Frank Julca-Aguilar, Jason Taylor, Mario Bijelic, Fahim Mannan, Ethan Tseng, Felix Heide</h3>
<p>Today's state-of-the-art methods for 3D object detection are based on lidar,
stereo, or monocular cameras. Lidar-based methods achieve the best accuracy,
but have a large footprint, high cost, and mechanically-limited angular
sampling rates, resulting in low spatial resolution at long ranges. Recent
approaches based on low-cost monocular or stereo cameras promise to overcome
these limitations but struggle in low-light or low-contrast regions as they
rely on passive CMOS sensors. In this work, we propose a novel 3D object
detection modality that exploits temporal illumination cues from a low-cost
monocular gated imager. We propose a novel deep detector architecture, Gated3D,
that is tailored to temporal illumination cues from three gated images. Gated
images allow us to exploit mature 2D object feature extractors that guide the
3D predictions through a frustum segment estimation. We assess the proposed
method on a novel 3D detection dataset that includes gated imagery captured in
over 10,000 km of driving data. We validate that our method outperforms
state-of-the-art monocular and stereo approaches at long distances. We will
release our code and dataset, opening up a new sensor modality as an avenue to
replace lidar in autonomous driving.
</p>
<a href="http://arxiv.org/abs/2102.03602" target="_blank">arXiv:2102.03602</a> [<a href="http://arxiv.org/pdf/2102.03602" target="_blank">pdf</a>]

<h2>Bootstrapping Statistical Inference for Off-Policy Evaluation. (arXiv:2102.03607v1 [stat.ML])</h2>
<h3>Botao Hao, Xiang (Jack)Ji, Yaqi Duan, Hao Lu, Csaba Szepesv&#xe1;ri, Mengdi Wang</h3>
<p>Bootstrapping provides a flexible and effective approach for assessing the
quality of batch reinforcement learning, yet its theoretical property is less
understood. In this paper, we study the use of bootstrapping in off-policy
evaluation (OPE), and in particular, we focus on the fitted Q-evaluation (FQE)
that is known to be minimax-optimal in the tabular and linear-model cases. We
propose a bootstrapping FQE method for inferring the distribution of the policy
evaluation error and show that this method is asymptotically efficient and
distributionally consistent for off-policy statistical inference. To overcome
the computation limit of bootstrapping, we further adapt a subsampling
procedure that improves the runtime by an order of magnitude. We numerically
evaluate the bootrapping method in classical RL environments for confidence
interval estimation, estimating the variance of off-policy evaluator, and
estimating the correlation between multiple off-policy evaluators.
</p>
<a href="http://arxiv.org/abs/2102.03607" target="_blank">arXiv:2102.03607</a> [<a href="http://arxiv.org/pdf/2102.03607" target="_blank">pdf</a>]

<h2>Understanding Higher-order Structures in Evolving Graphs: A Simplicial Complex based Kernel Estimation Approach. (arXiv:2102.03609v1 [cs.LG])</h2>
<h3>Manohar Kaul, Masaaki Imaizumi</h3>
<p>Dynamic graphs are rife with higher-order interactions, such as co-authorship
relationships and protein-protein interactions in biological networks, that
naturally arise between more than two nodes at once. In spite of the ubiquitous
presence of such higher-order interactions, limited attention has been paid to
the higher-order counterpart of the popular pairwise link prediction problem.
Existing higher-order structure prediction methods are mostly based on
heuristic feature extraction procedures, which work well in practice but lack
theoretical guarantees. Such heuristics are primarily focused on predicting
links in a static snapshot of the graph. Moreover, these heuristic-based
methods fail to effectively utilize and benefit from the knowledge of latent
substructures already present within the higher-order structures. In this
paper, we overcome these obstacles by capturing higher-order interactions
succinctly as \textit{simplices}, model their neighborhood by face-vectors, and
develop a nonparametric kernel estimator for simplices that views the evolving
graph from the perspective of a time process (i.e., a sequence of graph
snapshots). Our method substantially outperforms several baseline higher-order
prediction methods. As a theoretical achievement, we prove the consistency and
asymptotic normality in terms of the Wasserstein distance of our estimator
using Stein's method.
</p>
<a href="http://arxiv.org/abs/2102.03609" target="_blank">arXiv:2102.03609</a> [<a href="http://arxiv.org/pdf/2102.03609" target="_blank">pdf</a>]

<h2>Multi-Tier Federated Learning for Vertically Partitioned Data. (arXiv:2102.03620v1 [cs.LG])</h2>
<h3>Anirban Das, Stacy Patterson</h3>
<p>We consider decentralized model training in tiered communication networks.
Our network model consists of a set of silos, each holding a vertical partition
of the data. Each silo contains a hub and a set of clients, with the silo's
vertical data shard partitioned horizontally across its clients. We propose
Tiered Decentralized Coordinate Descent (TDCD), a communication-efficient
decentralized training algorithm for such two-tiered networks. To reduce
communication overhead, the clients in each silo perform multiple local
gradient steps before sharing updates with their hub. Each hub adjusts its
coordinates by averaging its workers' updates, and then hubs exchange
intermediate updates with one another. We present a theoretical analysis of our
algorithm and show the dependence of the convergence rate on the number of
vertical partitions, the number of local updates, and the number of clients in
each hub. We further validate our approach empirically via simulation-based
experiments using a variety of datasets and both convex and non-convex
objectives.
</p>
<a href="http://arxiv.org/abs/2102.03620" target="_blank">arXiv:2102.03620</a> [<a href="http://arxiv.org/pdf/2102.03620" target="_blank">pdf</a>]

<h2>Deep Semi-Supervised Learning for Time Series Classification. (arXiv:2102.03622v1 [cs.LG])</h2>
<h3>Jann Goschenhofer, Rasmus Hvingelby, David R&#xfc;gamer, Janek Thomas, Moritz Wagner, Bernd Bischl</h3>
<p>While Semi-supervised learning has gained much attention in computer vision
on image data, yet limited research exists on its applicability in the time
series domain. In this work, we investigate the transferability of
state-of-the-art deep semi-supervised models from image to time series
classification. We discuss the necessary model adaptations, in particular an
appropriate model backbone architecture and the use of tailored data
augmentation strategies. Based on these adaptations, we explore the potential
of deep semi-supervised learning in the context of time series classification
by evaluating our methods on large public time series classification problems
with varying amounts of labelled samples. We perform extensive comparisons
under a decidedly realistic and appropriate evaluation scheme with a unified
reimplementation of all algorithms considered, which is yet lacking in the
field. We find that these transferred semi-supervised models show significant
performance gains over strong supervised, semi-supervised and self-supervised
alternatives, especially for scenarios with very few labelled samples.
</p>
<a href="http://arxiv.org/abs/2102.03622" target="_blank">arXiv:2102.03622</a> [<a href="http://arxiv.org/pdf/2102.03622" target="_blank">pdf</a>]

<h2>Extremal learning: extremizing the output of a neural network in regression problems. (arXiv:2102.03626v1 [cs.LG])</h2>
<h3>Zakaria Patel, Markus Rummel</h3>
<p>Neural networks allow us to model complex relationships between variables. We
show how to efficiently find extrema of a trained neural network in regression
problems. Finding the extremizing input of an approximated model is formulated
as the training of an additional neural network with a loss function that
minimizes when the extremizing input is achieved. We further show how to
incorporate additional constraints on the input vector such as limiting the
extrapolation of the extremizing input vector from the original training data
set. An instructional example of this approach using TensorFlow is included.
</p>
<a href="http://arxiv.org/abs/2102.03626" target="_blank">arXiv:2102.03626</a> [<a href="http://arxiv.org/pdf/2102.03626" target="_blank">pdf</a>]

<h2>A surgical dataset from the da Vinci Research Kit for task automation and recognition. (arXiv:2102.03643v1 [cs.RO])</h2>
<h3>Irene Rivas-Blanco, Carlos J. P&#xe9;rez-del-Pulgar, Andrea Mariani, Claudio Quaglia, Giuseppe Tortora, Arianna Menciassi, V&#xed;ctor F. Mu&#xf1;oz</h3>
<p>The use of datasets is getting more relevance in surgical robotics since they
can be used to recognise and automate tasks. Also, this allows to use common
datasets to compare different algorithms and methods. The objective of this
work is to provide a complete dataset of three common training surgical tasks
that surgeons perform to improve their skills. For this purpose, 12 subjects
teleoperated the da Vinci Research Kit to perform these tasks. The obtained
dataset includes all the kinematics and dynamics information provided by the da
Vinci robot (both master and slave side) together with the associated video
from the camera. All the information has been carefully timestamped and
provided in a readable csv format. A MATLAB interface integrated with ROS for
using and replicating the data is also provided.
</p>
<a href="http://arxiv.org/abs/2102.03643" target="_blank">arXiv:2102.03643</a> [<a href="http://arxiv.org/pdf/2102.03643" target="_blank">pdf</a>]

<h2>Neural SDEs as Infinite-Dimensional GANs. (arXiv:2102.03657v1 [cs.LG])</h2>
<h3>Patrick Kidger, James Foster, Xuechen Li, Harald Oberhauser, Terry Lyons</h3>
<p>Stochastic differential equations (SDEs) are a staple of mathematical
modelling of temporal dynamics. However, a fundamental limitation has been that
such models have typically been relatively inflexible, which recent work
introducing Neural SDEs has sought to solve. Here, we show that the current
classical approach to fitting SDEs may be approached as a special case of
(Wasserstein) GANs, and in doing so the neural and classical regimes may be
brought together. The input noise is Brownian motion, the output samples are
time-evolving paths produced by a numerical solver, and by parameterising a
discriminator as a Neural Controlled Differential Equation (CDE), we obtain
Neural SDEs as (in modern machine learning parlance) continuous-time generative
time series models. Unlike previous work on this problem, this is a direct
extension of the classical approach without reference to either prespecified
statistics or density functions. Arbitrary drift and diffusions are admissible,
so as the Wasserstein loss has a unique global minima, in the infinite data
limit \textit{any} SDE may be learnt.
</p>
<a href="http://arxiv.org/abs/2102.03657" target="_blank">arXiv:2102.03657</a> [<a href="http://arxiv.org/pdf/2102.03657" target="_blank">pdf</a>]

<h2>Emergency Department Optimization and Load Prediction in Hospitals. (arXiv:2102.03672v1 [cs.LG])</h2>
<h3>Karthik K. Padthe, Vikas Kumar, Carly M. Eckert, Nicholas M. Mark, Anam Zahid, Muhammad Aurangzeb Ahmad, Ankur Teredesai</h3>
<p>Over the past several years, across the globe, there has been an increase in
people seeking care in emergency departments (EDs). ED resources, including
nurse staffing, are strained by such increases in patient volume. Accurate
forecasting of incoming patient volume in emergency departments (ED) is crucial
for efficient utilization and allocation of ED resources. Working with a
suburban ED in the Pacific Northwest, we developed a tool powered by machine
learning models, to forecast ED arrivals and ED patient volume to assist
end-users, such as ED nurses, in resource allocation. In this paper, we discuss
the results from our predictive models, the challenges, and the learnings from
users' experiences with the tool in active clinical deployment in a real world
setting.
</p>
<a href="http://arxiv.org/abs/2102.03672" target="_blank">arXiv:2102.03672</a> [<a href="http://arxiv.org/pdf/2102.03672" target="_blank">pdf</a>]

<h2>Unsupervised Audio-Visual Subspace Alignment for High-Stakes Deception Detection. (arXiv:2102.03673v1 [cs.CV])</h2>
<h3>Leena Mathur, Maja J Matari&#x107;</h3>
<p>Automated systems that detect deception in high-stakes situations can enhance
societal well-being across medical, social work, and legal domains. Existing
models for detecting high-stakes deception in videos have been supervised, but
labeled datasets to train models can rarely be collected for most real-world
applications. To address this problem, we propose the first multimodal
unsupervised transfer learning approach that detects real-world, high-stakes
deception in videos without using high-stakes labels. Our subspace-alignment
(SA) approach adapts audio-visual representations of deception in
lab-controlled low-stakes scenarios to detect deception in real-world,
high-stakes situations. Our best unsupervised SA models outperform models
without SA, outperform human ability, and perform comparably to a number of
existing supervised models. Our research demonstrates the potential for
introducing subspace-based transfer learning to model high-stakes deception and
other social behaviors in real-world contexts with a scarcity of labeled
behavioral data.
</p>
<a href="http://arxiv.org/abs/2102.03673" target="_blank">arXiv:2102.03673</a> [<a href="http://arxiv.org/pdf/2102.03673" target="_blank">pdf</a>]

<h2>Decentralized Ability-Aware Adaptive Control for Multi-robot Collaborative Manipulation. (arXiv:2102.03689v1 [cs.RO])</h2>
<h3>Lei Yan, Theodoros Stouraitis, Sethu Vijayakumar</h3>
<p>Multi-robot teams can achieve more dexterous, complex and heavier payload
tasks than a single robot, yet effective collaboration is required. Multi-robot
collaboration is extremely challenging due to the different kinematic and
dynamics capabilities of the robots, the limited communication between them,
and the uncertainty of the system parameters. In this paper, a Decentralized
Ability-Aware Adaptive Control is proposed to address these challenges based on
two key features. Firstly, the common manipulation task is represented by the
proposed nominal task ellipsoid, which is used to maximize each robot force
capability online via optimizing its configuration. Secondly, a decentralized
adaptive controller is designed to be Lyapunov stable in spite of heterogeneous
actuation constraints of the robots and uncertain physical parameters of the
object and environment. In the proposed framework, decentralized coordination
and load distribution between the robots is achieved without communication,
while only the control deficiency is broadcast if any of the robots reaches its
force limits. In this case, the object reference trajectory is modified in a
decentralized manner to guarantee stable interaction. Finally, we perform
several numerical and physical simulations to analyse and verify the proposed
method with heterogeneous multi-robot teams in collaborative manipulation
tasks.
</p>
<a href="http://arxiv.org/abs/2102.03689" target="_blank">arXiv:2102.03689</a> [<a href="http://arxiv.org/pdf/2102.03689" target="_blank">pdf</a>]

<h2>What's in a Name? -- Gender Classification of Names with Character Based Machine Learning Models. (arXiv:2102.03692v1 [cs.LG])</h2>
<h3>Yifan Hu, Changwei Hu, Thanh Tran, Tejaswi Kasturi, Elizabeth Joseph, Matt Gillingham</h3>
<p>Gender information is no longer a mandatory input when registering for an
account at many leading Internet companies. However, prediction of demographic
information such as gender and age remains an important task, especially in
intervention of unintentional gender/age bias in recommender systems. Therefore
it is necessary to infer the gender of those users who did not to provide this
information during registration. We consider the problem of predicting the
gender of registered users based on their declared name. By analyzing the first
names of 100M+ users, we found that genders can be very effectively classified
using the composition of the name strings. We propose a number of character
based machine learning models, and demonstrate that our models are able to
infer the gender of users with much higher accuracy than baseline models.
Moreover, we show that using the last names in addition to the first names
improves classification performance further.
</p>
<a href="http://arxiv.org/abs/2102.03692" target="_blank">arXiv:2102.03692</a> [<a href="http://arxiv.org/pdf/2102.03692" target="_blank">pdf</a>]

<h2>A procedure for automated tree pruning suggestion using LiDAR scans of fruit trees. (arXiv:2102.03700v1 [cs.CV])</h2>
<h3>Fredrik Westling, James Underwood, Mitch Bryson</h3>
<p>In fruit tree growth, pruning is an important management practice for
preventing overcrowding, improving canopy access to light and promoting
regrowth. Due to the slow nature of agriculture, decisions in pruning are
typically made using tradition or rules of thumb rather than data-driven
analysis. Many existing algorithmic, simulation-based approaches rely on
high-fidelity digital captures or purely computer-generated fruit trees, and
are unable to provide specific results on an orchard scale. We present a
framework for suggesting pruning strategies on LiDAR-scanned commercial fruit
trees using a scoring function with a focus on improving light distribution
throughout the canopy. A scoring function to assess the quality of the tree
shape based on its light availability and size was developed for comparative
analysis between trees, and was validated against yield characteristics,
demonstrating a reasonable correlation against fruit count with an $R^2$ score
of 0.615 for avocado and 0.506 for mango. A tool was implemented for simulating
pruning by algorithmically estimating which parts of a tree point cloud would
be removed given specific cut points using structural analysis of the tree,
validated experimentally with an average F1 score of 0.78 across 144
experiments. Finally, new pruning locations were suggested and we used the
previous two stages to estimate the improvement of the tree given these
suggestions. The light distribution was improved by up to 25.15\%,
demonstrating a 16\% improvement over commercial pruning on a real tree, and
certain cut points were discovered which improved light distribution with a
smaller negative impact on tree volume. The final results suggest value in the
framework as a decision making tool for commercial growers, or as a starting
point for automated pruning since the entire process can be performed with
little human intervention.
</p>
<a href="http://arxiv.org/abs/2102.03700" target="_blank">arXiv:2102.03700</a> [<a href="http://arxiv.org/pdf/2102.03700" target="_blank">pdf</a>]

<h2>An Analytic Layer-wise Deep Learning Framework with Applications to Robotics. (arXiv:2102.03705v1 [cs.RO])</h2>
<h3>Huu-Thiet Nguyen, Chien Chern Cheah, Kar-Ann Toh</h3>
<p>Deep learning has achieved great success in many applications, but it has
been less well analyzed from the theoretical perspective. To deploy deep
learning algorithms in a predictable and stable manner is particularly
important in robotics, as robots are active agents that need to interact safely
with the physical world. This paper presents an analytic deep learning
framework for fully connected neural networks, which can be applied for both
regression problems and classification problems. Examples for regression and
classification problems include online robot control and robot vision. We
present two layer-wise learning algorithms such that the convergence of the
learning systems can be analyzed. Firstly, an inverse layer-wise learning
algorithm for multilayer networks with convergence analysis for each layer is
presented to understand the problems of layer-wise deep learning. Secondly, a
forward progressive learning algorithm where the deep networks are built
progressively by using single hidden layer networks is developed to achieve
better accuracy. It is shown that the progressive learning method can be used
for fine-tuning of weights from convergence point of view. The effectiveness of
the proposed framework is illustrated based on classical benchmark recognition
tasks using the MNIST and CIFAR-10 datasets and the results show a good balance
between performance and explainability. The proposed method is subsequently
applied for online learning of robot kinematics and experimental results on
kinematic control of UR5e robot with unknown model are presented.
</p>
<a href="http://arxiv.org/abs/2102.03705" target="_blank">arXiv:2102.03705</a> [<a href="http://arxiv.org/pdf/2102.03705" target="_blank">pdf</a>]

<h2>Classification based on Topological Data Analysis. (arXiv:2102.03709v1 [cs.LG])</h2>
<h3>Rolando Kindelan, Jos&#xe9; Fr&#xed;as, Mauricio Cerda, Nancy Hitschfeld</h3>
<p>Topological Data Analysis (TDA) is an emergent field that aims to discover
topological information hidden in a dataset. TDA tools have been commonly used
to create filters and topological descriptors to improve Machine Learning (ML)
methods. This paper proposes an algorithm that applies TDA directly to
multi-class classification problems, even imbalanced datasets, without any
further ML stage. The proposed algorithm built a filtered simplicial complex on
the dataset. Persistent homology is then applied to guide choosing a
sub-complex where unlabeled points obtain the label with most votes from
labeled neighboring points. To assess the proposed method, 8 datasets were
selected with several degrees of class entanglement, variability on the samples
per class, and dimensionality. On average, the proposed TDABC method was
capable of overcoming baseline classifiers (wk-NN and k-NN) in each of the
computed metrics, especially on classifying entangled and minority classes.
</p>
<a href="http://arxiv.org/abs/2102.03709" target="_blank">arXiv:2102.03709</a> [<a href="http://arxiv.org/pdf/2102.03709" target="_blank">pdf</a>]

<h2>HGAN: Hybrid Generative Adversarial Network. (arXiv:2102.03710v1 [cs.CV])</h2>
<h3>Seyed Mehdi Iranmanesh, Nasser M. Nasrabadi</h3>
<p>In this paper, we present a simple approach to train Generative Adversarial
Networks (GANs) in order to avoid a \textit {mode collapse} issue. Implicit
models such as GANs tend to generate better samples compared to explicit models
that are trained on tractable data likelihood. However, GANs overlook the
explicit data density characteristics which leads to undesirable quantitative
evaluations and mode collapse. To bridge this gap, we propose a hybrid
generative adversarial network (HGAN) for which we can enforce data density
estimation via an autoregressive model and support both adversarial and
likelihood framework in a joint training manner which diversify the estimated
density in order to cover different modes. We propose to use an adversarial
network to \textit {transfer knowledge} from an autoregressive model (teacher)
to the generator (student) of a GAN model. A novel deep architecture within the
GAN formulation is developed to adversarially distill the autoregressive model
information in addition to simple GAN training approach. We conduct extensive
experiments on real-world datasets (i.e., MNIST, CIFAR-10, STL-10) to
demonstrate the effectiveness of the proposed HGAN under qualitative and
quantitative evaluations. The experimental results show the superiority and
competitiveness of our method compared to the baselines.
</p>
<a href="http://arxiv.org/abs/2102.03710" target="_blank">arXiv:2102.03710</a> [<a href="http://arxiv.org/pdf/2102.03710" target="_blank">pdf</a>]

<h2>SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation. (arXiv:2102.03716v1 [cs.LG])</h2>
<h3>Wuxinlin Cheng, Chenhui Deng, Zhiqiang Zhao, Yaohui Cai, Zhiru Zhang, Zhuo Feng</h3>
<p>A black-box spectral method is introduced for evaluating the adversarial
robustness of a given machine learning (ML) model. Our approach, named SPADE,
exploits bijective distance mapping between the input/output graphs constructed
for approximating the manifolds corresponding to the input/output data. By
leveraging the generalized Courant-Fischer theorem, we propose a SPADE score
for evaluating the adversarial robustness of a given model, which is proved to
be an upper bound of the best Lipschitz constant under the manifold setting. To
reveal the most non-robust data samples highly vulnerable to adversarial
attacks, we develop a spectral graph embedding procedure leveraging dominant
generalized eigenvectors. This embedding step allows assigning each data sample
a robustness score that can be further harnessed for more effective adversarial
training. Our experiments show the proposed SPADE method leads to promising
empirical results for neural network models adversarially trained with the
MNIST and CIFAR-10 data sets.
</p>
<a href="http://arxiv.org/abs/2102.03716" target="_blank">arXiv:2102.03716</a> [<a href="http://arxiv.org/pdf/2102.03716" target="_blank">pdf</a>]

<h2>Assessing Fairness in Classification Parity of Machine Learning Models in Healthcare. (arXiv:2102.03717v1 [cs.LG])</h2>
<h3>Ming Yuan, Vikas Kumar, Muhammad Aurangzeb Ahmad, Ankur Teredesai</h3>
<p>Fairness in AI and machine learning systems has become a fundamental problem
in the accountability of AI systems. While the need for accountability of AI
models is near ubiquitous, healthcare in particular is a challenging field
where accountability of such systems takes upon additional importance, as
decisions in healthcare can have life altering consequences. In this paper we
present preliminary results on fairness in the context of classification parity
in healthcare. We also present some exploratory methods to improve fairness and
choosing appropriate classification algorithms in the context of healthcare.
</p>
<a href="http://arxiv.org/abs/2102.03717" target="_blank">arXiv:2102.03717</a> [<a href="http://arxiv.org/pdf/2102.03717" target="_blank">pdf</a>]

<h2>An Analysis of Frame-skipping in Reinforcement Learning. (arXiv:2102.03718v1 [cs.LG])</h2>
<h3>Shivaram Kalyanakrishnan, Siddharth Aravindan, Vishwajeet Bagdawat, Varun Bhatt, Harshith Goka, Archit Gupta, Kalpesh Krishna, Vihari Piratla</h3>
<p>In the practice of sequential decision making, agents are often designed to
sense state at regular intervals of $d$ time steps, $d &gt; 1$, ignoring state
information in between sensing steps. While it is clear that this practice can
reduce sensing and compute costs, recent results indicate a further benefit. On
many Atari console games, reinforcement learning (RL) algorithms deliver
substantially better policies when run with $d &gt; 1$ -- in fact with $d$ even as
high as $180$. In this paper, we investigate the role of the parameter $d$ in
RL; $d$ is called the "frame-skip" parameter, since states in the Atari domain
are images. For evaluating a fixed policy, we observe that under standard
conditions, frame-skipping does not affect asymptotic consistency. Depending on
other parameters, it can possibly even benefit learning. To use $d &gt; 1$ in the
control setting, one must first specify which $d$-step open-loop action
sequences can be executed in between sensing steps. We focus on
"action-repetition", the common restriction of this choice to $d$-length
sequences of the same action. We define a task-dependent quantity called the
"price of inertia", in terms of which we upper-bound the loss incurred by
action-repetition. We show that this loss may be offset by the gain brought to
learning by a smaller task horizon. Our analysis is supported by experiments on
different tasks and learning algorithms.
</p>
<a href="http://arxiv.org/abs/2102.03718" target="_blank">arXiv:2102.03718</a> [<a href="http://arxiv.org/pdf/2102.03718" target="_blank">pdf</a>]

<h2>State-Aware Variational Thompson Sampling for Deep Q-Networks. (arXiv:2102.03719v1 [cs.LG])</h2>
<h3>Siddharth Aravindan, Wee Sun Lee</h3>
<p>Thompson sampling is a well-known approach for balancing exploration and
exploitation in reinforcement learning. It requires the posterior distribution
of value-action functions to be maintained; this is generally intractable for
tasks that have a high dimensional state-action space. We derive a variational
Thompson sampling approximation for DQNs which uses a deep network whose
parameters are perturbed by a learned variational noise distribution. We
interpret the successful NoisyNets method \cite{fortunato2018noisy} as an
approximation to the variational Thompson sampling method that we derive.
Further, we propose State Aware Noisy Exploration (SANE) which seeks to improve
on NoisyNets by allowing a non-uniform perturbation, where the amount of
parameter perturbation is conditioned on the state of the agent. This is done
with the help of an auxiliary perturbation module, whose output is state
dependent and is learnt end to end with gradient descent. We hypothesize that
such state-aware noisy exploration is particularly useful in problems where
exploration in certain \textit{high risk} states may result in the agent
failing badly. We demonstrate the effectiveness of the state-aware exploration
method in the off-policy setting by augmenting DQNs with the auxiliary
perturbation module.
</p>
<a href="http://arxiv.org/abs/2102.03719" target="_blank">arXiv:2102.03719</a> [<a href="http://arxiv.org/pdf/2102.03719" target="_blank">pdf</a>]

<h2>Object Removal Attacks on LiDAR-based 3D Object Detectors. (arXiv:2102.03722v1 [cs.CV])</h2>
<h3>Zhongyuan Hau, Kenneth T. Co, Soteris Demetriou, Emil C. Lupu</h3>
<p>LiDARs play a critical role in Autonomous Vehicles' (AVs) perception and
their safe operations. Recent works have demonstrated that it is possible to
spoof LiDAR return signals to elicit fake objects. In this work we demonstrate
how the same physical capabilities can be used to mount a new, even more
dangerous class of attacks, namely Object Removal Attacks (ORAs). ORAs aim to
force 3D object detectors to fail. We leverage the default setting of LiDARs
that record a single return signal per direction to perturb point clouds in the
region of interest (RoI) of 3D objects. By injecting illegitimate points behind
the target object, we effectively shift points away from the target objects'
RoIs. Our initial results using a simple random point selection strategy show
that the attack is effective in degrading the performance of commonly used 3D
object detection models.
</p>
<a href="http://arxiv.org/abs/2102.03722" target="_blank">arXiv:2102.03722</a> [<a href="http://arxiv.org/pdf/2102.03722" target="_blank">pdf</a>]

<h2>SR-Affine: High-quality 3D hand model reconstruction from UV Maps. (arXiv:2102.03725v1 [cs.CV])</h2>
<h3>Ping Chen, Dong Yang, Fangyin Wu, Qin Li, Qingpei Xia, Yong Tan</h3>
<p>Under various poses and heavy occlusions,3D hand model reconstruction based
on a single monocular RGB image has been a challenging problem in computer
vision field for many years. In this paper, we propose a SR-Affine approach for
high-quality 3D hand model reconstruction. First, we propose an encoder-decoder
network architecture (AffineNet) for MANO hand reconstruction. Since MANO hand
is not detailed, we further propose SRNet to up-sampling point-clouds by image
super-resolution on the UV map. Many experiments demonstrate that our approach
is robust and outperforms the state-of-the-art methods on standard benchmarks,
including the FreiHAND and HO3D datasets.
</p>
<a href="http://arxiv.org/abs/2102.03725" target="_blank">arXiv:2102.03725</a> [<a href="http://arxiv.org/pdf/2102.03725" target="_blank">pdf</a>]

<h2>Adversarial example generation with AdaBelief Optimizer and Crop Invariance. (arXiv:2102.03726v1 [cs.CV])</h2>
<h3>Bo Yang, Hengwei Zhang, Yuchen Zhang, Kaiyong Xu, Jindong Wang</h3>
<p>Deep neural networks are vulnerable to adversarial examples, which are
crafted by applying small, human-imperceptible perturbations on the original
images, so as to mislead deep neural networks to output inaccurate predictions.
Adversarial attacks can thus be an important method to evaluate and select
robust models in safety-critical applications. However, under the challenging
black-box setting, most existing adversarial attacks often achieve relatively
low success rates on adversarially trained networks and advanced defense
models. In this paper, we propose AdaBelief Iterative Fast Gradient Method
(ABI-FGM) and Crop-Invariant attack Method (CIM) to improves the
transferability of adversarial examples. ABI-FGM and CIM can be readily
integrated to build a strong gradient-based attack to further boost the success
rates of adversarial examples for black-box attacks. Moreover, our method can
also be naturally combined with other gradient-based attack methods to build a
more robust attack to generate more transferable adversarial examples against
the defense models. Extensive experiments on the ImageNet dataset demonstrate
the method's effectiveness. Whether on adversarially trained networks or
advanced defense models, our method has higher success rates than
state-of-the-art gradient-based attack methods.
</p>
<a href="http://arxiv.org/abs/2102.03726" target="_blank">arXiv:2102.03726</a> [<a href="http://arxiv.org/pdf/2102.03726" target="_blank">pdf</a>]

<h2>Adversarial Imaging Pipelines. (arXiv:2102.03728v1 [cs.CV])</h2>
<h3>Buu Phan, Fahim Mannan, Felix Heide</h3>
<p>Adversarial attacks play an essential role in understanding deep neural
network predictions and improving their robustness. Existing attack methods aim
to deceive convolutional neural network (CNN)-based classifiers by manipulating
RGB images that are fed directly to the classifiers. However, these approaches
typically neglect the influence of the camera optics and image processing
pipeline (ISP) that produce the network inputs. ISPs transform RAW measurements
to RGB images and traditionally are assumed to preserve adversarial patterns.
However, these low-level pipelines can, in fact, destroy, introduce or amplify
adversarial patterns that can deceive a downstream detector. As a result,
optimized patterns can become adversarial for the classifier after being
transformed by a certain camera ISP and optic but not for others. In this work,
we examine and develop such an attack that deceives a specific camera ISP while
leaving others intact, using the same down-stream classifier. We frame
camera-specific attacks as a multi-task optimization problem, relying on a
differentiable approximation for the ISP itself. We validate the proposed
method using recent state-of-the-art automotive hardware ISPs, achieving 92%
fooling rate when attacking a specific ISP. We demonstrate physical optics
attacks with 90% fooling rate for a specific camera lenses.
</p>
<a href="http://arxiv.org/abs/2102.03728" target="_blank">arXiv:2102.03728</a> [<a href="http://arxiv.org/pdf/2102.03728" target="_blank">pdf</a>]

<h2>Regret Minimization in Heavy-Tailed Bandits. (arXiv:2102.03734v1 [cs.LG])</h2>
<h3>Shubhada Agrawal, Sandeep Juneja, Wouter M. Koolen</h3>
<p>We revisit the classic regret-minimization problem in the stochastic
multi-armed bandit setting when the arm-distributions are allowed to be
heavy-tailed. Regret minimization has been well studied in simpler settings of
either bounded support reward distributions or distributions that belong to a
single parameter exponential family. We work under the much weaker assumption
that the moments of order $(1+\epsilon)$ are uniformly bounded by a known
constant B, for some given $\epsilon &gt; 0$. We propose an optimal algorithm that
matches the lower bound exactly in the first-order term. We also give a
finite-time bound on its regret. We show that our index concentrates faster
than the well known truncated or trimmed empirical mean estimators for the mean
of heavy-tailed distributions. Computing our index can be computationally
demanding. To address this, we develop a batch-based algorithm that is optimal
up to a multiplicative constant depending on the batch size. We hence provide a
controlled trade-off between statistical optimality and computational cost.
</p>
<a href="http://arxiv.org/abs/2102.03734" target="_blank">arXiv:2102.03734</a> [<a href="http://arxiv.org/pdf/2102.03734" target="_blank">pdf</a>]

<h2>Infinite-channel deep stable convolutional neural networks. (arXiv:2102.03739v1 [stat.ML])</h2>
<h3>Daniele Bracale, Stefano Favaro, Sandra Fortini, Stefano Peluchetti</h3>
<p>The interplay between infinite-width neural networks (NNs) and classes of
Gaussian processes (GPs) is well known since the seminal work of Neal (1996).
While numerous theoretical refinements have been proposed in the recent years,
the interplay between NNs and GPs relies on two critical distributional
assumptions on the NN's parameters: A1) finite variance; A2) independent and
identical distribution (iid). In this paper, we consider the problem of
removing A1 in the general context of deep feed-forward convolutional NNs. In
particular, we assume iid parameters distributed according to a stable
distribution and we show that the infinite-channel limit of a deep feed-forward
convolutional NNs, under suitable scaling, is a stochastic process with
multivariate stable finite-dimensional distributions. Such a limiting
distribution is then characterized through an explicit backward recursion for
its parameters over the layers. Our contribution extends results of Favaro et
al. (2020) to convolutional architectures, and it paves the way to expand
exciting recent lines of research that rely on classes of GP limits.
</p>
<a href="http://arxiv.org/abs/2102.03739" target="_blank">arXiv:2102.03739</a> [<a href="http://arxiv.org/pdf/2102.03739" target="_blank">pdf</a>]

<h2>A Bayesian nonparametric approach to count-min sketch under power-law data streams. (arXiv:2102.03743v1 [stat.ML])</h2>
<h3>Emanuele Dolera, Stefano Favaro, Stefano Peluchetti</h3>
<p>The count-min sketch (CMS) is a randomized data structure that provides with
estimates of tokens' frequencies in a large data stream using a compressed
representation of the data by random hashing. In this paper, we rely on a
recent Bayesian nonparametric (BNP) view on the CMS to develop a novel
learning-augmented CMS under power-law data streams. We assume that tokens in
the stream are drawn from an unknown discrete distribution, which is endowed
with a normalized inverse Gaussian process (NIGP) prior. Then, using
distributional properties of the NIGP, we compute the posterior distribution of
a token's frequency in the stream, given the hashed data, and in turn
corresponding BNP estimates. Applications to synthetic and real data show that
our approach achieves a remarkable performance in the estimation of
low-frequency tokens. This is known to be a desirable feature in the context of
natural language processing, where it is indeed common in the context of the
power-law behaviour of the data.
</p>
<a href="http://arxiv.org/abs/2102.03743" target="_blank">arXiv:2102.03743</a> [<a href="http://arxiv.org/pdf/2102.03743" target="_blank">pdf</a>]

<h2>DPointNet: A Density-Oriented PointNet for 3D Object Detection in Point Clouds. (arXiv:2102.03747v1 [cs.CV])</h2>
<h3>Jie Li, Yu Hu</h3>
<p>For current object detectors, the scale of the receptive field of feature
extraction operators usually increases layer by layer. Those operators are
called scale-oriented operators in this paper, such as the convolution layer in
CNN, and the set abstraction layer in PointNet++. The scale-oriented operators
are appropriate for 2D images with multi-scale objects, but not natural for 3D
point clouds with multi-density but scale-invariant objects. In this paper, we
put forward a novel density-oriented PointNet (DPointNet) for 3D object
detection in point clouds, in which the density of points increases layer by
layer. In experiments for object detection, the DPointNet is applied to
PointRCNN, and the results show that the model with the new operator can
achieve better performance and higher speed than the baseline PointRCNN, which
verify the effectiveness of the proposed DPointNet.
</p>
<a href="http://arxiv.org/abs/2102.03747" target="_blank">arXiv:2102.03747</a> [<a href="http://arxiv.org/pdf/2102.03747" target="_blank">pdf</a>]

<h2>PAC-Bayes Bounds for Meta-learning with Data-Dependent Prior. (arXiv:2102.03748v1 [cs.LG])</h2>
<h3>Tianyu Liu, Jie Lu, Zheng Yan, Guangquan Zhang</h3>
<p>By leveraging experience from previous tasks, meta-learning algorithms can
achieve effective fast adaptation ability when encountering new tasks. However
it is unclear how the generalization property applies to new tasks. Probably
approximately correct (PAC) Bayes bound theory provides a theoretical framework
to analyze the generalization performance for meta-learning. We derive three
novel generalisation error bounds for meta-learning based on PAC-Bayes relative
entropy bound. Furthermore, using the empirical risk minimization (ERM) method,
a PAC-Bayes bound for meta-learning with data-dependent prior is developed.
Experiments illustrate that the proposed three PAC-Bayes bounds for
meta-learning guarantee a competitive generalization performance guarantee, and
the extended PAC-Bayes bound with data-dependent prior can achieve rapid
convergence ability.
</p>
<a href="http://arxiv.org/abs/2102.03748" target="_blank">arXiv:2102.03748</a> [<a href="http://arxiv.org/pdf/2102.03748" target="_blank">pdf</a>]

<h2>Non-stationary Online Learning with Memory and Non-stochastic Control. (arXiv:2102.03758v1 [cs.LG])</h2>
<h3>Peng Zhao, Yu-Xiang Wang, Zhi-Hua Zhou</h3>
<p>We study the problem of Online Convex Optimization (OCO) with memory, which
allows loss functions to depend on past decisions and thus captures temporal
effects of learning problems. In this paper, we introduce dynamic policy regret
as the performance measure to design algorithms robust to non-stationary
environments, which competes algorithms' decisions with a sequence of changing
comparators. We propose a novel algorithm for OCO with memory that provably
enjoys an optimal dynamic policy regret. The key technical challenge is how to
control the switching cost, the cumulative movements of player's decisions,
which is neatly addressed by a novel decomposition of dynamic policy regret and
an appropriate meta-expert structure. Furthermore, we generalize the results to
the problem of online non-stochastic control, i.e., controlling a linear
dynamical system with adversarial disturbance and convex loss functions. We
derive a novel gradient-based controller with dynamic policy regret guarantees,
which is the first controller competitive to a sequence of changing policies.
</p>
<a href="http://arxiv.org/abs/2102.03758" target="_blank">arXiv:2102.03758</a> [<a href="http://arxiv.org/pdf/2102.03758" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning with Dynamic Optimism. (arXiv:2102.03765v1 [cs.LG])</h2>
<h3>Ted Moskovitz, Jack Parker-Holder, Aldo Pacchiano, Michael Arbel</h3>
<p>In recent years, deep off-policy actor-critic algorithms have become a
dominant approach to reinforcement learning for continuous control. This comes
after a series of breakthroughs to address function approximation errors, which
previously led to poor performance. These insights encourage the use of
pessimistic value updates. However, this discourages exploration and runs
counter to theoretical support for the efficacy of optimism in the face of
uncertainty. So which approach is best? In this work, we show that the optimal
degree of optimism can vary both across tasks and over the course of learning.
Inspired by this insight, we introduce a novel deep actor-critic algorithm,
Dynamic Optimistic and Pessimistic Estimation (DOPE) to switch between
optimistic and pessimistic value learning online by formulating the selection
as a multi-arm bandit problem. We show in a series of challenging continuous
control tasks that DOPE outperforms existing state-of-the-art methods, which
rely on a fixed degree of optimism. Since our changes are simple to implement,
we believe these insights can be extended to a number of off-policy algorithms.
</p>
<a href="http://arxiv.org/abs/2102.03765" target="_blank">arXiv:2102.03765</a> [<a href="http://arxiv.org/pdf/2102.03765" target="_blank">pdf</a>]

<h2>MULLS: Versatile LiDAR SLAM via Multi-metric Linear Least Square. (arXiv:2102.03771v1 [cs.RO])</h2>
<h3>Yue Pan, Pengchuan Xiao, Yujie He, Zhenlei Shao, Zesong Li</h3>
<p>The rapid development of autonomous driving and mobile mapping calls for
off-the-shelf LiDAR SLAM solutions that are adaptive to LiDARs of different
specifications on various complex scenarios. To this end, we propose MULLS, an
efficient, low-drift, and versatile 3D LiDAR SLAM system. For the front-end,
roughly classified feature points (ground, facade, pillar, beam, etc.) are
extracted from each frame using dual-threshold ground filtering and principal
components analysis. Then the registration between the current frame and the
local submap is accomplished efficiently by the proposed multi-metric linear
least square iterative closest point algorithm. Point-to-point (plane, line)
error metrics within each point class are jointly optimized with a linear
approximation to estimate the ego-motion. Static feature points of the
registered frame are appended into the local map to keep it updated. For the
back-end, hierarchical pose graph optimization is conducted among regularly
stored history submaps to reduce the drift resulting from dead reckoning.
Extensive experiments are carried out on three datasets with more than 100,000
frames collected by six types of LiDAR on various outdoor and indoor scenarios.
On the KITTI benchmark, MULLS ranks among the top LiDAR-only SLAM systems with
real-time performance.
</p>
<a href="http://arxiv.org/abs/2102.03771" target="_blank">arXiv:2102.03771</a> [<a href="http://arxiv.org/pdf/2102.03771" target="_blank">pdf</a>]

<h2>SeReNe: Sensitivity based Regularization of Neurons for Structured Sparsity in Neural Networks. (arXiv:2102.03773v1 [cs.LG])</h2>
<h3>Enzo Tartaglione, Andrea Bragagnolo, Francesco Odierna, Attilio Fiandrotti, Marco Grangetto</h3>
<p>Deep neural networks include millions of learnable parameters, making their
deployment over resource-constrained devices problematic. SeReNe
(Sensitivity-based Regularization of Neurons) is a method for learning sparse
topologies with a structure, exploiting neural sensitivity as a regularizer. We
define the sensitivity of a neuron as the variation of the network output with
respect to the variation of the activity of the neuron. The lower the
sensitivity of a neuron, the less the network output is perturbed if the neuron
output changes. By including the neuron sensitivity in the cost function as a
regularization term, we areable to prune neurons with low sensitivity. As
entire neurons are pruned rather then single parameters, practical network
footprint reduction becomes possible. Our experimental results on multiple
network architectures and datasets yield competitive compression ratios with
respect to state-of-the-art references.
</p>
<a href="http://arxiv.org/abs/2102.03773" target="_blank">arXiv:2102.03773</a> [<a href="http://arxiv.org/pdf/2102.03773" target="_blank">pdf</a>]

<h2>Hyperparameter Optimization with Differentiable Metafeatures. (arXiv:2102.03776v1 [cs.LG])</h2>
<h3>Hadi S. Jomaa, Lars Schmidt-Thieme, Josif Grabocka</h3>
<p>Metafeatures, or dataset characteristics, have been shown to improve the
performance of hyperparameter optimization (HPO). Conventionally, metafeatures
are precomputed and used to measure the similarity between datasets, leading to
a better initialization of HPO models. In this paper, we propose a cross
dataset surrogate model called Differentiable Metafeature-based Surrogate
(DMFBS), that predicts the hyperparameter response, i.e. validation loss, of a
model trained on the dataset at hand. In contrast to existing models, DMFBS i)
integrates a differentiable metafeature extractor and ii) is optimized using a
novel multi-task loss, linking manifold regularization with a dataset
similarity measure learned via an auxiliary dataset identification meta-task,
effectively enforcing the response approximation for similar datasets to be
similar. We compare DMFBS against several recent models for HPO on three large
meta-datasets and show that it consistently outperforms all of them with an
average 10% improvement. Finally, we provide an extensive ablation study that
examines the different components of our approach.
</p>
<a href="http://arxiv.org/abs/2102.03776" target="_blank">arXiv:2102.03776</a> [<a href="http://arxiv.org/pdf/2102.03776" target="_blank">pdf</a>]

<h2>Adversarial Training of Variational Auto-encoders for Continual Zero-shot Learning. (arXiv:2102.03778v1 [cs.CV])</h2>
<h3>Subhankar Ghosh</h3>
<p>Most of the existing artificial neural networks(ANNs) fail to learn
continually due to catastrophic forgetting, while humans can do the same by
maintaining previous tasks' performances. Although storing all the previous
data can alleviate the problem, it takes a large memory, infeasible in
real-world utilization. We propose a continual zero-shot learning model that is
more suitable in real-case scenarios to address the issue that can learn
sequentially and distinguish classes the model has not seen during training. We
present a hybrid network that consists of a shared VAE module to hold
information of all tasks and task-specific private VAE modules for each task.
The model's size grows with each task to prevent catastrophic forgetting of
task-specific skills, and it includes a replay approach to preserve shared
skills. We demonstrate our hybrid model is effective on several datasets, i.e.,
CUB, AWA1, AWA2, and aPY. We show our method is superior on class sequentially
learning with ZSL(Zero-Shot Learning) and GZSL(Generalized Zero-Shot Learning).
</p>
<a href="http://arxiv.org/abs/2102.03778" target="_blank">arXiv:2102.03778</a> [<a href="http://arxiv.org/pdf/2102.03778" target="_blank">pdf</a>]

<h2>Design of Dynamic Experiments for Black-Box Model Discrimination. (arXiv:2102.03782v1 [cs.LG])</h2>
<h3>Simon Olofsson, Eduardo S. Schultz, Adel Mhamdi, Alexander Mitsos, Marc Peter Deisenroth, Ruth Misener</h3>
<p>Diverse domains of science and engineering require and use mechanistic
mathematical models, e.g. systems of differential algebraic equations. Such
models often contain uncertain parameters to be estimated from data. Consider a
dynamic model discrimination setting where we wish to chose: (i) what is the
best mechanistic, time-varying model and (ii) what are the best model parameter
estimates. These tasks are often termed model
discrimination/selection/validation/verification. Typically, several rival
mechanistic models can explain data, so we incorporate available data and also
run new experiments to gather more data. Design of dynamic experiments for
model discrimination helps optimally collect data. For rival mechanistic models
where we have access to gradient information, we extend existing methods to
incorporate a wider range of problem uncertainty and show that our proposed
approach is equivalent to historical approaches when limiting the types of
considered uncertainty. We also consider rival mechanistic models as dynamic
black boxes that we can evaluate, e.g. by running legacy code, but where
gradient or other advanced information is unavailable. We replace these
black-box models with Gaussian process surrogate models and thereby extend the
model discrimination setting to additionally incorporate rival black-box model.
We also explore the consequences of using Gaussian process surrogates to
approximate gradient-based methods.
</p>
<a href="http://arxiv.org/abs/2102.03782" target="_blank">arXiv:2102.03782</a> [<a href="http://arxiv.org/pdf/2102.03782" target="_blank">pdf</a>]

<h2>Robust Explanations for Private Support Vector Machines. (arXiv:2102.03785v1 [cs.LG])</h2>
<h3>Rami Mochaourab, Sugandh Sinha, Stanley Greenstein, Panagiotis Papapetrou</h3>
<p>We consider counterfactual explanations for private support vector machines
(SVM), where the privacy mechanism that publicly releases the classifier
guarantees differential privacy. While privacy preservation is essential when
dealing with sensitive data, there is a consequent degradation in the
classification accuracy due to the introduced perturbations in the classifier
weights. For such classifiers, counterfactual explanations need to be robust
against the uncertainties in the SVM weights in order to ensure, with high
confidence, that the classification of the data instance to be explained is
different than its explanation. We model the uncertainties in the SVM weights
through a random vector, and formulate the explanation problem as an
optimization problem with probabilistic constraint. Subsequently, we
characterize the problem's deterministic equivalent and study its solution. For
linear SVMs, the problem is a convex second-order cone program. For non-linear
SVMs, the problem is non-convex. Thus, we propose a sub-optimal solution that
is based on the bisection method. The results show that, contrary to non-robust
explanations, the quality of explanations from the robust solution degrades
with increasing privacy in order to guarantee a prespecified confidence level
for correct classifications.
</p>
<a href="http://arxiv.org/abs/2102.03785" target="_blank">arXiv:2102.03785</a> [<a href="http://arxiv.org/pdf/2102.03785" target="_blank">pdf</a>]

<h2>Tilting the playing field: Dynamical loss functions for machine learning. (arXiv:2102.03793v1 [cs.LG])</h2>
<h3>Miguel Ruiz-Garcia, Ge Zhang, Samuel S. Schoenholz, Andrea J. Liu</h3>
<p>We show that learning can be improved by using loss functions that evolve
cyclically during training to emphasize one class at a time. In
underparameterized networks, such dynamical loss functions can lead to
successful training for networks that fail to find a deep minima of the
standard cross-entropy loss. In overparameterized networks, dynamical loss
functions can lead to better generalization. Improvement arises from the
interplay of the changing loss landscape with the dynamics of the system as it
evolves to minimize the loss. In particular, as the loss function oscillates,
instabilities develop in the form of bifurcation cascades, which we study using
the Hessian and Neural Tangent Kernel. Valleys in the landscape widen and
deepen, and then narrow and rise as the loss landscape changes during a cycle.
As the landscape narrows, the learning rate becomes too large and the network
becomes unstable and bounces around the valley. This process ultimately pushes
the system into deeper and wider regions of the loss landscape and is
characterized by decreasing eigenvalues of the Hessian. This results in better
regularized models with improved generalization performance.
</p>
<a href="http://arxiv.org/abs/2102.03793" target="_blank">arXiv:2102.03793</a> [<a href="http://arxiv.org/pdf/2102.03793" target="_blank">pdf</a>]

<h2>A self-adaptive and robust fission clustering algorithm via heat diffusion and maximal turning angle. (arXiv:2102.03794v1 [cs.LG])</h2>
<h3>Yu Han, Shizhan Lu, Haiyan Xu</h3>
<p>Cluster analysis, which focuses on the grouping and categorization of similar
elements, is widely used in various fields of research. A novel and fast
clustering algorithm, fission clustering algorithm, is proposed in recent year.
In this article, we propose a robust fission clustering (RFC) algorithm and a
self-adaptive noise identification method. The RFC and the self-adaptive noise
identification method are combine to propose a self-adaptive robust fission
clustering (SARFC) algorithm. Several frequently-used datasets were applied to
test the performance of the proposed clustering approach and to compare the
results with those of other algorithms. The comprehensive comparisons indicate
that the proposed method has advantages over other common methods.
</p>
<a href="http://arxiv.org/abs/2102.03794" target="_blank">arXiv:2102.03794</a> [<a href="http://arxiv.org/pdf/2102.03794" target="_blank">pdf</a>]

<h2>Intensity-SLAM: Intensity Assisted Localization and Mapping for Large Scale Environment. (arXiv:2102.03798v1 [cs.RO])</h2>
<h3>Han Wang, Chen Wang, Lihua Xie</h3>
<p>Simultaneous Localization And Mapping (SLAM) is a task to estimate the robot
location and to reconstruct the environment based on observation from sensors
such as LIght Detection And Ranging (LiDAR) and camera. It is widely used in
robotic applications such as autonomous driving and drone delivery. Traditional
LiDAR-based SLAM algorithms mainly leverage the geometric features from the
scene context, while the intensity information from LiDAR is ignored. Some
recent deep-learning-based SLAM algorithms consider intensity features and
train the pose estimation network in an end-to-end manner. However, they
require significant data collection effort and their generalizability to
environments other than the trained one remains unclear. In this paper we
introduce intensity features to a SLAM system. And we propose a novel full SLAM
framework that leverages both geometry and intensity features. The proposed
SLAM involves both intensity-based front-end odometry estimation and
intensity-based back-end optimization. Thorough experiments are performed
including both outdoor autonomous driving and indoor warehouse robot
manipulation. The results show that the proposed method outperforms existing
geometric-only LiDAR SLAM methods.
</p>
<a href="http://arxiv.org/abs/2102.03798" target="_blank">arXiv:2102.03798</a> [<a href="http://arxiv.org/pdf/2102.03798" target="_blank">pdf</a>]

<h2>Online Limited Memory Neural-Linear Bandits with Likelihood Matching. (arXiv:2102.03799v1 [cs.LG])</h2>
<h3>Ofir Nabati, Tom Zahavy, Shie Mannor</h3>
<p>We study neural-linear bandits for solving problems where both exploration
and representation learning play an important role. Neural-linear bandits
leverage the representation power of Deep Neural Networks (DNNs) and combine it
with efficient exploration mechanisms designed for linear contextual bandits on
top of the last hidden layer. A recent analysis of DNNs in the "infinite-width"
regime suggests that when these models are trained with gradient descent the
optimal solution is close to the initialization point and the DNN can be viewed
as a kernel machine. As a result, it is possible to exploit linear exploration
algorithms on top of a DNN via the kernel construction. The problem is that in
practice the kernel changes during the learning process and the agent's
performance degrades. This can be resolved by recomputing new uncertainty
estimations with stored data. Nevertheless, when the buffer's size is limited,
a phenomenon called catastrophic forgetting emerges. Instead, we propose a
likelihood matching algorithm that is resilient to catastrophic forgetting and
is completely online. We perform simulations on a variety of datasets and
observe that our algorithm achieves comparable performance to the unlimited
memory approach while exhibits resilience to catastrophic forgetting.
</p>
<a href="http://arxiv.org/abs/2102.03799" target="_blank">arXiv:2102.03799</a> [<a href="http://arxiv.org/pdf/2102.03799" target="_blank">pdf</a>]

<h2>Lightweight 3-D Localization and Mapping for Solid-State LiDAR. (arXiv:2102.03800v1 [cs.RO])</h2>
<h3>Han Wang, Chen Wang, Lihua Xie</h3>
<p>The LIght Detection And Ranging (LiDAR) sensor has become one of the most
important perceptual devices due to its important role in simultaneous
localization and mapping (SLAM). Existing SLAM methods are mainly developed for
mechanical LiDAR sensors, which are often adopted by large scale robots.
Recently, the solid-state LiDAR is introduced and becomes popular since it
provides a cost-effective and lightweight solution for small scale robots.
Compared to mechanical LiDAR, solid-state LiDAR sensors have higher update
frequency and angular resolution, but also have smaller field of view (FoV),
which is very challenging for existing LiDAR SLAM algorithms. Therefore, it is
necessary to have a more robust and computationally efficient SLAM method for
this new sensing device. To this end, we propose a new SLAM framework for
solid-state LiDAR sensors, which involves feature extraction, odometry
estimation, and probability map building. The proposed method is evaluated on a
warehouse robot and a hand-held device. In the experiments, we demonstrate both
the accuracy and efficiency of our method using an Intel L515 solid-state
LiDAR. The results show that our method is able to provide precise localization
and high quality mapping. We made the source codes public at
\url{https://github.com/wh200720041/SSL_SLAM}.
</p>
<a href="http://arxiv.org/abs/2102.03800" target="_blank">arXiv:2102.03800</a> [<a href="http://arxiv.org/pdf/2102.03800" target="_blank">pdf</a>]

<h2>Dimension Free Generalization Bounds for Non Linear Metric Learning. (arXiv:2102.03802v1 [cs.LG])</h2>
<h3>Mark Kozdoba, Shie Mannor</h3>
<p>In this work we study generalization guarantees for the metric learning
problem, where the metric is induced by a neural network type embedding of the
data. Specifically, we provide uniform generalization bounds for two regimes --
the sparse regime, and a non-sparse regime which we term \emph{bounded
amplification}. The sparse regime bounds correspond to situations where
$\ell_1$-type norms of the parameters are small. Similarly to the situation in
classification, solutions satisfying such bounds can be obtained by an
appropriate regularization of the problem. On the other hand, unregularized SGD
optimization of a metric learning loss typically does not produce sparse
solutions. We show that despite this lack of sparsity, by relying on a
different, new property of the solutions, it is still possible to provide
dimension free generalization guarantees. Consequently, these bounds can
explain generalization in non sparse real experimental situations. We
illustrate the studied phenomena on the MNIST and 20newsgroups datasets.
</p>
<a href="http://arxiv.org/abs/2102.03802" target="_blank">arXiv:2102.03802</a> [<a href="http://arxiv.org/pdf/2102.03802" target="_blank">pdf</a>]

<h2>Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v1 [cs.LG])</h2>
<h3>Uri Sherman, Tomer Koren</h3>
<p>We study a variant of online convex optimization where the player is
permitted to switch decisions at most $S$ times in expectation throughout $T$
rounds. Similar problems have been addressed in prior work for the discrete
decision set setting, and more recently in the continuous setting but only with
an adaptive adversary. In this work, we aim to fill the gap and present
computationally efficient algorithms in the more prevalent oblivious setting,
establishing a regret bound of $O(T/S)$ for general convex losses and
$\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic
i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches
with only a multiplicative $\log T$ factor overhead in its regret in both the
general and strongly convex settings. Finally, we complement our algorithms
with lower bounds that match our upper bounds in some of the cases we consider.
</p>
<a href="http://arxiv.org/abs/2102.03803" target="_blank">arXiv:2102.03803</a> [<a href="http://arxiv.org/pdf/2102.03803" target="_blank">pdf</a>]

<h2>Embedding manifold structures into Kalman filters. (arXiv:2102.03804v1 [cs.RO])</h2>
<h3>Dongjiao He, Wei Xu, Fu Zhang</h3>
<p>Error-state Kalman filter is an elegant and effective filtering technique for
robotic systems operating on manifolds. To avoid the tedious and repetitive
derivations for implementing an error-state Kalman filter for a certain system,
this paper proposes a generic symbolic representation for error-state Kalman
filters on manifolds. Utilizing the $\boxplus\backslash\boxminus$ operations
and further defining a $\oplus$ operation on the respective manifold, we
propose a canonical representation of the robotic system, which enables us to
separate the manifold structures from the system descriptions in each step of
the Kalman filter, ultimately leading to a generic, symbolic and
manifold-embedding Kalman filter framework. This proposed Kalman filter
framework can be used by only casting the system model into the canonical form
without going through the cumbersome hand-derivation of the on-manifold Kalman
filter. This is particularly useful when the robotic system is of high
dimension. Furthermore, the manifold-embedding Kalman filter is implemented as
a toolkit in $C$++, with which an user needs only to define the system, and
call the respective filter steps (e.g., propagation, update) according to the
events (e.g., reception of input, reception of measurement). The existing
implementation supports full iterated Kalman filtering for systems on manifold
$\mathcal{S} = \mathbb{R}^m \times SO(3) \times \cdots \times SO(3) \times
\mathbb{S}^2 \times \cdots \times \mathbb{S}^2 $ or any of its sub-manifolds,
and is extendable to other types of manifold when necessary. The proposed
symbolic Kalman filter and the developed toolkit are verified by implementing a
tightly-coupled lidar-inertial navigation system. Results show superior
filtering performances and computation efficiency comparable to hand-engineered
counterparts. Finally, the toolkit is opened sourced at
https://github.com/hku-mars/IKFoM.
</p>
<a href="http://arxiv.org/abs/2102.03804" target="_blank">arXiv:2102.03804</a> [<a href="http://arxiv.org/pdf/2102.03804" target="_blank">pdf</a>]

<h2>Bandits for Learning to Explain from Explanations. (arXiv:2102.03815v1 [cs.LG])</h2>
<h3>Freya Behrens, Stefano Teso, Davide Mottin</h3>
<p>We introduce Explearn, an online algorithm that learns to jointly output
predictions and explanations for those predictions. Explearn leverages Gaussian
Processes (GP)-based contextual bandits. This brings two key benefits. First,
GPs naturally capture different kinds of explanations and enable the system
designer to control how explanations generalize across the space by virtue of
choosing a suitable kernel. Second, Explearn builds on recent results in
contextual bandits which guarantee convergence with high probability. Our
initial experiments hint at the promise of the approach.
</p>
<a href="http://arxiv.org/abs/2102.03815" target="_blank">arXiv:2102.03815</a> [<a href="http://arxiv.org/pdf/2102.03815" target="_blank">pdf</a>]

<h2>Neural Termination Analysis. (arXiv:2102.03824v1 [cs.LG])</h2>
<h3>Mirco Giacobbe, Daniel Kroening, Julian Parsert</h3>
<p>We introduce a novel approach to the automated termination analysis of
computer programs: we train neural networks to act as ranking functions.
Ranking functions map program states to values that are bounded from below and
decrease as the program runs. The existence of a valid ranking function proves
that the program terminates. While in the past ranking functions were usually
constructed using static analysis, our method learns them from sampled
executions. We train a neural network so that its output decreases along
execution traces as a ranking function would; then, we use formal reasoning to
verify whether it generalises to all possible executions. We present a custom
loss function for learning lexicographic ranking functions and use
satisfiability modulo theories for verification. Thanks to the ability of
neural networks to generalise well, our method succeeds over a wide variety of
programs. This includes programs that use data structures from standard
libraries. We built a prototype analyser for Java bytecode and show the
efficacy of our method over a standard dataset of benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.03824" target="_blank">arXiv:2102.03824</a> [<a href="http://arxiv.org/pdf/2102.03824" target="_blank">pdf</a>]

<h2>Generalization of Model-Agnostic Meta-Learning Algorithms: Recurring and Unseen Tasks. (arXiv:2102.03832v1 [cs.LG])</h2>
<h3>Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar</h3>
<p>In this paper, we study the generalization properties of Model-Agnostic
Meta-Learning (MAML) algorithms for supervised learning problems. We focus on
the setting in which we train the MAML model over $m$ tasks, each with $n$ data
points, and characterize its generalization error from two points of view:
First, we assume the new task at test time is one of the training tasks, and we
show that, for strongly convex objective functions, the expected excess
population loss is bounded by $\mathcal{O}(1/mn)$. Second, we consider the MAML
algorithm's generalization to an unseen task and show that the resulting
generalization error depends on the total variation distance between the
underlying distributions of the new task and the tasks observed during the
training process. Our proof techniques rely on the connections between
algorithmic stability and generalization bounds of algorithms. In particular,
we propose a new definition of stability for meta-learning algorithms, which
allows us to capture the role of both the number of tasks $m$ and number of
samples per task $n$ on the generalization error of MAML.
</p>
<a href="http://arxiv.org/abs/2102.03832" target="_blank">arXiv:2102.03832</a> [<a href="http://arxiv.org/pdf/2102.03832" target="_blank">pdf</a>]

<h2>Damage detection using in-domain and cross-domain transfer learning. (arXiv:2102.03858v1 [cs.CV])</h2>
<h3>Zaharah A. Bukhsh, Nils Jansen, Aaqib Saeed</h3>
<p>We investigate the capabilities of transfer learning in the area of
structural health monitoring. In particular, we are interested in damage
detection for concrete structures. Typical image datasets for such problems are
relatively small, calling for the transfer of learned representation from a
related large-scale dataset. Past efforts of damage detection using images have
mainly considered cross-domain transfer learning approaches using pre-trained
ImageNet models that are subsequently fine-tuned for the target task. However,
there are rising concerns about the generalizability of ImageNet
representations for specific target domains, such as for visual inspection and
medical imaging. We, therefore, propose a combination of in-domain and
cross-domain transfer learning strategies for damage detection in bridges. We
perform comprehensive comparisons to study the impact of cross-domain and
in-domain transfer, with various initialization strategies, using six publicly
available visual inspection datasets. The pre-trained models are also evaluated
for their ability to cope with the extremely low-data regime. We show that the
combination of cross-domain and in-domain transfer persistently shows superior
performance even with tiny datasets. Likewise, we also provide visual
explanations of predictive models to enable algorithmic transparency and
provide insights to experts about the intrinsic decision-logic of typically
black-box deep models.
</p>
<a href="http://arxiv.org/abs/2102.03858" target="_blank">arXiv:2102.03858</a> [<a href="http://arxiv.org/pdf/2102.03858" target="_blank">pdf</a>]

<h2>Dynamic Movement Primitives in Robotics: A Tutorial Survey. (arXiv:2102.03861v1 [cs.RO])</h2>
<h3>Matteo Saveriano, Fares J. Abu-Dakka, Aljaz Kramberger, Luka Peternel</h3>
<p>Biological systems, including human beings, have the innate ability to
perform complex tasks in versatile and agile manner. Researchers in
sensorimotor control have tried to understand and formally define this innate
property. The idea, supported by several experimental findings, that biological
systems are able to combine and adapt basic units of motion into complex tasks
finally lead to the formulation of the motor primitives theory. In this
respect, Dynamic Movement Primitives (DMPs) represent an elegant mathematical
formulation of the motor primitives as stable dynamical systems, and are well
suited to generate motor commands for artificial systems like robots. In the
last decades, DMPs have inspired researchers in different robotic fields
including imitation and reinforcement learning, optimal control,physical
interaction, and human-robot co-working, resulting a considerable amount of
published papers. The goal of this tutorial survey is two-fold. On one side, we
present the existing DMPs formulations in rigorous mathematical terms,and
discuss advantages and limitations of each approach as well as practical
implementation details. In the tutorial vein, we also search for existing
implementations of presented approaches and release several others. On the
other side, we provide a systematic and comprehensive review of existing
literature and categorize state of the art work on DMP. The paper concludes
with a discussion on the limitations of DMPs and an outline of possible
research directions.
</p>
<a href="http://arxiv.org/abs/2102.03861" target="_blank">arXiv:2102.03861</a> [<a href="http://arxiv.org/pdf/2102.03861" target="_blank">pdf</a>]

<h2>Towards a mathematical framework to inform Neural Network modelling via Polynomial Regression. (arXiv:2102.03865v1 [stat.ML])</h2>
<h3>Pablo Morala (1), Jenny Alexandra Cifuentes (1), Rosa E. Lillo (1 and 2), I&#xf1;aki Ucar (1) ((1) uc3m-Santander Big Data Institute, Universidad Carlos III de Madrid., (2) Department of Statistics, Universidad Carlos III de Madrid.)</h3>
<p>Even when neural networks are widely used in a large number of applications,
they are still considered as black boxes and present some difficulties for
dimensioning or evaluating their prediction error. This has led to an
increasing interest in the overlapping area between neural networks and more
traditional statistical methods, which can help overcome those problems. In
this article, a mathematical framework relating neural networks and polynomial
regression is explored by building an explicit expression for the coefficients
of a polynomial regression from the weights of a given neural network, using a
Taylor expansion approach. This is achieved for single hidden layer neural
networks in regression problems. The validity of the proposed method depends on
different factors like the distribution of the synaptic potentials or the
chosen activation function. The performance of this method is empirically
tested via simulation of synthetic data generated from polynomials to train
neural networks with different structures and hyperparameters, showing that
almost identical predictions can be obtained when certain conditions are met.
Lastly, when learning from polynomial generated data, the proposed method
produces polynomials that approximate correctly the data locally.
</p>
<a href="http://arxiv.org/abs/2102.03865" target="_blank">arXiv:2102.03865</a> [<a href="http://arxiv.org/pdf/2102.03865" target="_blank">pdf</a>]

<h2>Model-Augmented Q-learning. (arXiv:2102.03866v1 [cs.LG])</h2>
<h3>Youngmin Oh, Jinwoo Shin, Eunho Yang, Sung Ju Hwang</h3>
<p>In recent years, $Q$-learning has become indispensable for model-free
reinforcement learning (MFRL). However, it suffers from well-known problems
such as under- and overestimation bias of the value, which may adversely affect
the policy learning. To resolve this issue, we propose a MFRL framework that is
augmented with the components of model-based RL. Specifically, we propose to
estimate not only the $Q$-values but also both the transition and the reward
with a shared network. We further utilize the estimated reward from the model
estimators for $Q$-learning, which promotes interaction between the estimators.
We show that the proposed scheme, called Model-augmented $Q$-learning (MQL),
obtains a policy-invariant solution which is identical to the solution obtained
by learning with true reward. Finally, we also provide a trick to prioritize
past experiences in the replay buffer by utilizing model-estimation errors. We
experimentally validate MQL built upon state-of-the-art off-policy MFRL
methods, and show that MQL largely improves their performance and convergence.
The proposed scheme is simple to implement and does not require additional
training cost.
</p>
<a href="http://arxiv.org/abs/2102.03866" target="_blank">arXiv:2102.03866</a> [<a href="http://arxiv.org/pdf/2102.03866" target="_blank">pdf</a>]

<h2>Structured Sparsity Inducing Adaptive Optimizers for Deep Learning. (arXiv:2102.03869v1 [cs.LG])</h2>
<h3>Tristan Deleu, Yoshua Bengio</h3>
<p>The parameters of a neural network are naturally organized in groups, some of
which might not contribute to its overall performance. To prune out unimportant
groups of parameters, we can include some non-differentiable penalty to the
objective function, and minimize it using proximal gradient methods. In this
paper, we derive the weighted proximal operator, which is a necessary component
of these proximal methods, of two structured sparsity inducing penalties.
Moreover, they can be approximated efficiently with a numerical solver, and
despite this approximation, we prove that existing convergence guarantees are
preserved when these operators are integrated as part of a generic adaptive
proximal method. Finally, we show that this adaptive method, together with the
weighted proximal operators derived here, is indeed capable of finding
solutions with structure in their sparsity patterns, on representative examples
from computer vision and natural language processing.
</p>
<a href="http://arxiv.org/abs/2102.03869" target="_blank">arXiv:2102.03869</a> [<a href="http://arxiv.org/pdf/2102.03869" target="_blank">pdf</a>]

<h2>A Note on Argumentative Topology: Circularity and Syllogisms as Unsolved Problems. (arXiv:2102.03874v1 [cs.AI])</h2>
<h3>Wlodek W. Zadrozny</h3>
<p>In the last couple of years there were a few attempts to apply topological
data analysis to text, and in particular to natural language inference. A
recent work by Tymochko et al. suggests the possibility of capturing `the
notion of logical shape in text,' using `topological delay embeddings,' a
technique derived from dynamical systems, applied to word embeddings.

In this note we reconstruct their argument and show, using several old and
new examples, that the problem of connecting logic, topology and text is still
very much unsolved. We conclude that there is no clear answer to the question:
``Can we find a circle in a circular argument?'' We point out some possible
avenues of exploration. The code used in our experiment is also shown.
</p>
<a href="http://arxiv.org/abs/2102.03874" target="_blank">arXiv:2102.03874</a> [<a href="http://arxiv.org/pdf/2102.03874" target="_blank">pdf</a>]

<h2>Few-shot time series segmentation using prototype-defined infinite hidden Markov models. (arXiv:2102.03885v1 [cs.LG])</h2>
<h3>Yazan Qarout, Yordan P. Raykov, Max A. Little</h3>
<p>We propose a robust framework for interpretable, few-shot analysis of
non-stationary sequential data based on flexible graphical models to express
the structured distribution of sequential events, using prototype radial basis
function (RBF) neural network emissions. A motivational link is demonstrated
between prototypical neural network architectures for few-shot learning and the
proposed RBF network infinite hidden Markov model (RBF-iHMM). We show that RBF
networks can be efficiently specified via prototypes allowing us to express
complex nonstationary patterns, while hidden Markov models are used to infer
principled high-level Markov dynamics. The utility of the framework is
demonstrated on biomedical signal processing applications such as automated
seizure detection from EEG data where RBF networks achieve state-of-the-art
performance using a fraction of the data needed to train long-short-term memory
variational autoencoders.
</p>
<a href="http://arxiv.org/abs/2102.03885" target="_blank">arXiv:2102.03885</a> [<a href="http://arxiv.org/pdf/2102.03885" target="_blank">pdf</a>]

<h2>Black-Box Optimization via Generative Adversarial Nets. (arXiv:2102.03888v1 [cs.LG])</h2>
<h3>Minfang Lu, Fengyang Sun, Lin Wang, Bo Yang, Shuangrong Liu</h3>
<p>Black-box optimization (BBO) algorithms are concerned with finding the best
solutions for the problems with missing analytical details. Most classical
methods for such problems are based on strong and fixed \emph{a priori}
assumptions such as Gaussian distribution. However, lots of complex real-world
problems are far from the \emph{a priori} distribution, bringing some
unexpected obstacles to these methods. In this paper, we present an optimizer
using generative adversarial nets (OPT-GAN) to guide search on black-box
problems via estimating the distribution of optima. The method learns the
extensive distribution of the optimal region dominated by selective candidates.
Experiments demonstrate that OPT-GAN outperforms other classical BBO
algorithms, in particular the ones with Gaussian assumptions.
</p>
<a href="http://arxiv.org/abs/2102.03888" target="_blank">arXiv:2102.03888</a> [<a href="http://arxiv.org/pdf/2102.03888" target="_blank">pdf</a>]

<h2>Machine Learning Methods for Histopathological Image Analysis: A Review. (arXiv:2102.03889v1 [cs.CV])</h2>
<h3>Jonathan de Matos, Steve Tsham Mpinda Ataky, Alceu de Souza Britto Jr., Luiz Eduardo Soares de Oliveira, Alessandro Lameiras Koerich</h3>
<p>Histopathological images (HIs) are the gold standard for evaluating some
types of tumors for cancer diagnosis. The analysis of such images is not only
time and resource consuming, but also very challenging even for experienced
pathologists, resulting in inter- and intra-observer disagreements. One of the
ways of accelerating such an analysis is to use computer-aided diagnosis (CAD)
systems. In this paper, we present a review on machine learning methods for
histopathological image analysis, including shallow and deep learning methods.
We also cover the most common tasks in HI analysis, such as segmentation and
feature extraction. In addition, we present a list of publicly available and
private datasets that have been used in HI research.
</p>
<a href="http://arxiv.org/abs/2102.03889" target="_blank">arXiv:2102.03889</a> [<a href="http://arxiv.org/pdf/2102.03889" target="_blank">pdf</a>]

<h2>Functional Optimal Transport: Mapping Estimation and Domain Adaptation for Functional data. (arXiv:2102.03895v1 [stat.ML])</h2>
<h3>Jiacheng Zhu, Aritra Guha, Mengdi Xu, Yingchen Ma, Rayleigh Lei, Vincenzo Loffredo, XuanLong Nguyen, Ding Zhao</h3>
<p>Optimal transport (OT) has generated much recent interest by its capability
of finding mappings that transport mass from one distribution to another, and
found useful roles in machine learning tasks such as unsupervised learning,
domain adaptation and transfer learning. On the other hand, in many
applications data are generated by complex mechanisms involving convoluted
spaces of functions, curves and surfaces in high dimensions. Functional data
analysis provides a useful framework of treatment for such domains. In this
paper we introduce a novel formulation of optimal transport problem in
functional spaces and develop an efficient learning algorithm for finding the
stochastic map between functional domains. We apply our method to synthetic
datasets and study the geometric properties of the transport map. Experiments
on real-world datasets of robot arm trajectories and digit numbers further
demonstrate the effectiveness of our method on applications of domain
adaptation and generative modeling.
</p>
<a href="http://arxiv.org/abs/2102.03895" target="_blank">arXiv:2102.03895</a> [<a href="http://arxiv.org/pdf/2102.03895" target="_blank">pdf</a>]

<h2>Consequences of Misaligned AI. (arXiv:2102.03896v1 [cs.AI])</h2>
<h3>Simon Zhuang, Dylan Hadfield-Menell</h3>
<p>AI systems often rely on two key components: a specified goal or reward
function and an optimization algorithm to compute the optimal behavior for that
goal. This approach is intended to provide value for a principal: the user on
whose behalf the agent acts. The objectives given to these agents often refer
to a partial specification of the principal's goals. We consider the cost of
this incompleteness by analyzing a model of a principal and an agent in a
resource constrained world where the $L$ attributes of the state correspond to
different sources of utility for the principal. We assume that the reward
function given to the agent only has support on $J &lt; L$ attributes. The
contributions of our paper are as follows: 1) we propose a novel model of an
incomplete principal-agent problem from artificial intelligence; 2) we provide
necessary and sufficient conditions under which indefinitely optimizing for any
incomplete proxy objective leads to arbitrarily low overall utility; and 3) we
show how modifying the setup to allow reward functions that reference the full
state or allowing the principal to update the proxy objective over time can
lead to higher utility solutions. The results in this paper argue that we
should view the design of reward functions as an interactive and dynamic
process and identifies a theoretical scenario where some degree of
interactivity is desirable.
</p>
<a href="http://arxiv.org/abs/2102.03896" target="_blank">arXiv:2102.03896</a> [<a href="http://arxiv.org/pdf/2102.03896" target="_blank">pdf</a>]

<h2>Self-supervised driven consistency training for annotation efficient histopathology image analysis. (arXiv:2102.03897v1 [cs.CV])</h2>
<h3>Chetan L. Srinidhi, Seung Wook Kim, Fu-Der Chen, Anne L. Martel</h3>
<p>Training a neural network with a large labeled dataset is still a dominant
paradigm in computational histopathology. However, obtaining such exhaustive
manual annotations is often expensive, laborious, and prone to inter and
Intra-observer variability. While recent self-supervised and semi-supervised
methods can alleviate this need by learn-ing unsupervised feature
representations, they still struggle to generalize well to downstream tasks
when the number of labeled instances is small. In this work, we overcome this
challenge by leveraging both task-agnostic and task-specific unlabeled data
based on two novel strategies: i) a self-supervised pretext task that harnesses
the underlying multi-resolution contextual cues in histology whole-slide images
to learn a powerful supervisory signal for unsupervised representation
learning; ii) a new teacher-student semi-supervised consistency paradigm that
learns to effectively transfer the pretrained representations to downstream
tasks based on prediction consistency with the task-specific un-labeled data.
We carry out extensive validation experiments on three histopathology benchmark
datasets across two classification and one regression-based tasks, i.e., tumor
metastasis detection, tissue type classification, and tumor cellularity
quantification. Under limited-label data, the proposed method yields tangible
improvements, which is close or even outperforming other state-of-the-art
self-supervised and supervised baselines. Furthermore, we empirically show that
the idea of bootstrapping the self-supervised pretrained features is an
effective way to improve the task-specific semi-supervised learning on standard
benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.03897" target="_blank">arXiv:2102.03897</a> [<a href="http://arxiv.org/pdf/2102.03897" target="_blank">pdf</a>]

<h2>AttributeNet: Attribute Enhanced Vehicle Re-Identification. (arXiv:2102.03898v1 [cs.CV])</h2>
<h3>Rodolfo Quispe, Cuiling Lan, Wenjun Zeng, Helio Pedrini</h3>
<p>Vehicle Re-Identification (V-ReID) is a critical task that associates the
same vehicle across images from different camera viewpoints. Many works explore
attribute clues to enhance V-ReID; however, there is usually a lack of
effective interaction between the attribute-related modules and final V-ReID
objective. In this work, we propose a new method to efficiently explore
discriminative information from vehicle attributes (e.g., color and type). We
introduce AttributeNet (ANet) that jointly extracts identity-relevant features
and attribute features. We enable the interaction by distilling the
ReID-helpful attribute feature and adding it into the general ReID feature to
increase the discrimination power. Moreover, we propose a constraint, named
Amelioration Constraint (AC), which encourages the feature after adding
attribute features onto the general ReID feature to be more discriminative than
the original general ReID feature. We validate the effectiveness of our
framework on three challenging datasets. Experimental results show that our
method achieves state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2102.03898" target="_blank">arXiv:2102.03898</a> [<a href="http://arxiv.org/pdf/2102.03898" target="_blank">pdf</a>]

<h2>Causal version of Principle of Insufficient Reason and MaxEnt. (arXiv:2102.03906v1 [stat.ML])</h2>
<h3>Dominik Janzing</h3>
<p>The Principle of insufficient Reason (PIR) assigns equal probabilities to
each alternative of a random experiment whenever there is no reason to prefer
one over the other. Maximum Entropy (MaxEnt) generalizes PIR to the case where
statistical information like expectations are given. It is known that both
principles result in paradox probability updates for joint distributions of
cause and effect. This is because constraints on the conditional P(effect |
cause) result in changes of P(cause) that assign higher probability to those
values of the cause that offer more options for the effect, suggesting
'intentional behaviour'. Earlier work therefore suggested sequentially
maximizing (conditional) entropy according to the causal order, but without
further justification apart from plausibility for toy examples. We justify
causal modifications of PIR and MaxEnt by separating constraints into
restrictions for the cause and restrictions for the mechanism that generates
the effect from the cause. We further sketch why Causal PIR also entails
'Information Geometric Causal Inference'.

We briefly discuss problems of generalizing the causal version of MaxEnt to
arbitrary causal DAGs.
</p>
<a href="http://arxiv.org/abs/2102.03906" target="_blank">arXiv:2102.03906</a> [<a href="http://arxiv.org/pdf/2102.03906" target="_blank">pdf</a>]

<h2>Meta-Learning with Neural Tangent Kernels. (arXiv:2102.03909v1 [cs.LG])</h2>
<h3>Yufan Zhou, Zhenyi Wang, Jiayi Xian, Changyou Chen, Jinhui Xu</h3>
<p>Model Agnostic Meta-Learning (MAML) has emerged as a standard framework for
meta-learning, where a meta-model is learned with the ability of fast adapting
to new tasks. However, as a double-looped optimization problem, MAML needs to
differentiate through the whole inner-loop optimization path for every
outer-loop training step, which may lead to both computational inefficiency and
sub-optimal solutions. In this paper, we generalize MAML to allow meta-learning
to be defined in function spaces, and propose the first meta-learning paradigm
in the Reproducing Kernel Hilbert Space (RKHS) induced by the meta-model's
Neural Tangent Kernel (NTK). Within this paradigm, we introduce two
meta-learning algorithms in the RKHS, which no longer need a sub-optimal
iterative inner-loop adaptation as in the MAML framework. We achieve this goal
by 1) replacing the adaptation with a fast-adaptive regularizer in the RKHS;
and 2) solving the adaptation analytically based on the NTK theory. Extensive
experimental studies demonstrate advantages of our paradigm in both efficiency
and quality of solutions compared to related meta-learning algorithms. Another
interesting feature of our proposed methods is that they are demonstrated to be
more robust to adversarial attacks and out-of-distribution adaptation than
popular baselines, as demonstrated in our experiments.
</p>
<a href="http://arxiv.org/abs/2102.03909" target="_blank">arXiv:2102.03909</a> [<a href="http://arxiv.org/pdf/2102.03909" target="_blank">pdf</a>]

<h2>Mitigating belief projection in explainable artificial intelligence via Bayesian Teaching. (arXiv:2102.03919v1 [cs.AI])</h2>
<h3>Scott Cheng-Hsin Yang, Wai Keen Vong, Ravi B. Sojitra, Tomas Folke, Patrick Shafto</h3>
<p>State-of-the-art deep-learning systems use decision rules that are
challenging for humans to model. Explainable AI (XAI) attempts to improve human
understanding but rarely accounts for how people typically reason about
unfamiliar agents. We propose explicitly modeling the human explainee via
Bayesian Teaching, which evaluates explanations by how much they shift
explainees' inferences toward a desired goal. We assess Bayesian Teaching in a
binary image classification task across a variety of contexts. Absent
intervention, participants predict that the AI's classifications will match
their own, but explanations generated by Bayesian Teaching improve their
ability to predict the AI's judgements by moving them away from this prior
belief. Bayesian Teaching further allows each case to be broken down into
sub-examples (here saliency maps). These sub-examples complement whole examples
by improving error detection for familiar categories, whereas whole examples
help predict correct AI judgements of unfamiliar cases.
</p>
<a href="http://arxiv.org/abs/2102.03919" target="_blank">arXiv:2102.03919</a> [<a href="http://arxiv.org/pdf/2102.03919" target="_blank">pdf</a>]

<h2>Sparsely ensembled convolutional neural network classifiers via reinforcement learning. (arXiv:2102.03921v1 [cs.LG])</h2>
<h3>Roman Malashin ((1) Pavlov institute of Physiology RAS, (2) State University of Aerospace Instrumentation, Saint-Petersburg, Russia)</h3>
<p>We consider convolutional neural network (CNN) ensemble learning with the
objective function inspired by least action principle; it includes resource
consumption component. We teach an agent to perceive images through the set of
pre-trained classifiers and want the resulting dynamically configured system to
unfold the computational graph with the trajectory that refers to the minimal
number of operations and maximal expected accuracy. The proposed agent's
architecture implicitly approximates the required classifier selection function
with the help of reinforcement learning. Our experimental results prove, that
if the agent exploits the dynamic (and context-dependent) structure of
computations, it outperforms conventional ensemble learning.
</p>
<a href="http://arxiv.org/abs/2102.03921" target="_blank">arXiv:2102.03921</a> [<a href="http://arxiv.org/pdf/2102.03921" target="_blank">pdf</a>]

<h2>DroneTrap: Drone Catching in Midair by Soft Robotic Hand with Color-Based Force Detection and Hand Gesture Recognition. (arXiv:2102.03923v1 [cs.RO])</h2>
<h3>Aleksey Fedoseev, Valerii Serpiva, Ekaterina Karmanova, Miguel Altamirano Cabrera, Vladimir Shirokun, Iakov Vasilev, Stanislav Savushkin, Dzmitry Tsetserukou</h3>
<p>The paper proposes a novel concept of docking drones to make this process as
safe and fast as possible. The idea behind the project is that a robot with the
gripper grasps the drone in midair. The human operator navigates the robotic
arm with the ML-based gesture recognition interface. The 3-finger robot hand
with soft fingers and integrated touch-sensors is pneumatically actuated. This
allows achieving safety while catching to not destroying the drone's mechanical
structure, fragile propellers, and motors.

Additionally, the soft hand has a unique technology of providing force
information through the color of the fingers to the remote computer vision (CV)
system. In this case, not only the control system can understand the force
applied but also the human operator. The operator has full control of robot
motion and task execution without additional programming by wearing a mocap
glove with gesture recognition, which was developed and applied for the
high-level control of DroneTrap.

The experimental results revealed that the developed color-based force
estimation can be applied for rigid object capturing with high precision
(95.3\%). The proposed technology can potentially revolutionize the landing and
deployment of drones for parcel delivery on uneven ground, structure
inspections, risque operations, etc.
</p>
<a href="http://arxiv.org/abs/2102.03923" target="_blank">arXiv:2102.03923</a> [<a href="http://arxiv.org/pdf/2102.03923" target="_blank">pdf</a>]

<h2>Domain Adversarial Neural Networks for Domain Generalization: When It Works and How to Improve. (arXiv:2102.03924v1 [cs.LG])</h2>
<h3>Anthony Sicilia, Xingchen Zhao, Seong Jae Hwang</h3>
<p>Theoretically, domain adaptation is a well-researched problem. Further, this
theory has been well-used in practice. In particular, we note the bound on
target error given by Ben-David et al. (2010) and the well-known
domain-aligning algorithm based on this work using Domain Adversarial Neural
Networks (DANN) presented by Ganin and Lempitsky (2015). Recently, multiple
variants of DANN have been proposed for the related problem of domain
generalization, but without much discussion of the original motivating bound.
In this paper, we investigate the validity of DANN in domain generalization
from this perspective. We investigate conditions under which application of
DANN makes sense and further consider DANN as a dynamic process during
training. Our investigation suggests that the application of DANN to domain
generalization may not be as straightforward as it seems. To address this, we
design an algorithmic extension to DANN in the domain generalization case. Our
experimentation validates both theory and algorithm.
</p>
<a href="http://arxiv.org/abs/2102.03924" target="_blank">arXiv:2102.03924</a> [<a href="http://arxiv.org/pdf/2102.03924" target="_blank">pdf</a>]

<h2>Lower Bounds and Accelerated Algorithms for Bilevel Optimization. (arXiv:2102.03926v1 [cs.LG])</h2>
<h3>Kaiyi Ji, Yingbin Liang</h3>
<p>Bilevel optimization has recently attracted growing interests due to its wide
applications in modern machine learning problems. Although recent studies have
characterized the convergence rate for several such popular algorithms, it is
still unclear how much further these convergence rates can be improved. In this
paper, we address this fundamental question from two perspectives. First, we
provide the first-known lower complexity bounds of
$\widetilde{\Omega}(\frac{1}{\sqrt{\mu_x}\mu_y})$ and $\widetilde
\Omega\big(\frac{1}{\sqrt{\epsilon}}\min\{\frac{1}{\mu_y},\frac{1}{\sqrt{\epsilon^{3}}}\}\big)$
respectively for strongly-convex-strongly-convex and convex-strongly-convex
bilevel optimizations. Second, we propose an accelerated bilevel optimizer
named AccBiO, whose complexity improves the existing upper bounds orderwisely
under strongly-convex-strongly-convex, convex-strongly-convex and
nonconvex-strongly-convex geometries. We further show that AccBiO achieves the
optimal results (i.e., the upper and lower bounds match) under certain
conditions up to logarithmic factors. Interestingly, our lower bounds under
both geometries are larger than the corresponding optimal complexities of
minimax optimization, establishing that bilevel optimization is provably more
challenging than minimax optimization. We finally discuss the extensions and
applications of our results to other problems such as minimax optimization.
</p>
<a href="http://arxiv.org/abs/2102.03926" target="_blank">arXiv:2102.03926</a> [<a href="http://arxiv.org/pdf/2102.03926" target="_blank">pdf</a>]

<h2>Latent Map Gaussian Processes for Mixed Variable Metamodeling. (arXiv:2102.03935v1 [stat.ML])</h2>
<h3>Nicholas Oune, Ramin Bostanabad</h3>
<p>Gaussian processes (GPs) are ubiquitously used in sciences and engineering as
metamodels. Standard GPs, however, can only handle numerical or quantitative
variables. In this paper, we introduce latent map Gaussian processes (LMGPs)
that inherit the attractive properties of GPs but are also applicable to mixed
data that have both quantitative and qualitative inputs. The core idea behind
LMGPs is to learn a low-dimensional manifold where all qualitative inputs are
represented by some quantitative features. To learn this manifold, we first
assign a unique prior vector representation to each combination of qualitative
inputs. We then use a linear map to project these priors on a manifold that
characterizes the posterior representations. As the posteriors are
quantitative, they can be straightforwardly used in any standard correlation
function such as the Gaussian. Hence, the optimal map and the corresponding
manifold can be efficiently learned by maximizing the Gaussian likelihood
function. Through a wide range of analytical and real-world examples, we
demonstrate the advantages of LMGPs over state-of-the-art methods in terms of
accuracy and versatility. In particular, we show that LMGPs can handle
variable-length inputs and provide insights into how qualitative inputs affect
the response or interact with each other. We also provide a neural network
interpretation of LMGPs and study the effect of prior latent representations on
their performance.
</p>
<a href="http://arxiv.org/abs/2102.03935" target="_blank">arXiv:2102.03935</a> [<a href="http://arxiv.org/pdf/2102.03935" target="_blank">pdf</a>]

<h2>Single-Shot Cuboids: Geodesics-based End-to-end Manhattan Aligned Layout Estimation from Spherical Panoramas. (arXiv:2102.03939v1 [cs.CV])</h2>
<h3>Nikolaos Zioulis, Federico Alvarez, Dimitrios Zarpalas, Petros Daras</h3>
<p>It has been shown that global scene understanding tasks like layout
estimation can benefit from wider field of views, and specifically spherical
panoramas. While much progress has been made recently, all previous approaches
rely on intermediate representations and postprocessing to produce
Manhattan-aligned estimates. In this work we show how to estimate full room
layouts in a single-shot, eliminating the need for postprocessing. Our work is
the first to directly infer Manhattan-aligned outputs. To achieve this, our
data-driven model exploits direct coordinate regression and is supervised
end-to-end. As a result, we can explicitly add quasi-Manhattan constraints,
which set the necessary conditions for a homography-based Manhattan alignment
module. Finally, we introduce the geodesic heatmaps and loss and a
boundary-aware center of mass calculation that facilitate higher quality
keypoint estimation in the spherical domain. Our models and code are publicly
available at https://vcl3d.github.io/SingleShotCuboids/.
</p>
<a href="http://arxiv.org/abs/2102.03939" target="_blank">arXiv:2102.03939</a> [<a href="http://arxiv.org/pdf/2102.03939" target="_blank">pdf</a>]

<h2>Iconographic Image Captioning for Artworks. (arXiv:2102.03942v1 [cs.CV])</h2>
<h3>Eva Cetinic</h3>
<p>Image captioning implies automatically generating textual descriptions of
images based only on the visual input. Although this has been an extensively
addressed research topic in recent years, not many contributions have been made
in the domain of art historical data. In this particular context, the task of
image captioning is confronted with various challenges such as the lack of
large-scale datasets of image-text pairs, the complexity of meaning associated
with describing artworks and the need for expert-level annotations. This work
aims to address some of those challenges by utilizing a novel large-scale
dataset of artwork images annotated with concepts from the Iconclass
classification system designed for art and iconography. The annotations are
processed into clean textual description to create a dataset suitable for
training a deep neural network model on the image captioning task. Motivated by
the state-of-the-art results achieved in generating captions for natural
images, a transformer-based vision-language pre-trained model is fine-tuned
using the artwork image dataset. Quantitative evaluation of the results is
performed using standard image captioning metrics. The quality of the generated
captions and the model's capacity to generalize to new data is explored by
employing the model on a new collection of paintings and performing an analysis
of the relation between commonly generated captions and the artistic genre. The
overall results suggest that the model can generate meaningful captions that
exhibit a stronger relevance to the art historical context, particularly in
comparison to captions obtained from models trained only on natural image
datasets.
</p>
<a href="http://arxiv.org/abs/2102.03942" target="_blank">arXiv:2102.03942</a> [<a href="http://arxiv.org/pdf/2102.03942" target="_blank">pdf</a>]

<h2>Additive Feature Hashing. (arXiv:2102.03943v1 [cs.LG])</h2>
<h3>M. Andrecut</h3>
<p>The hashing trick is a machine learning technique used to encode categorical
features into a numerical vector representation of pre-defined fixed length. It
works by using the categorical hash values as vector indices, and updating the
vector values at those indices. Here we discuss a different approach based on
additive-hashing and the "almost orthogonal" property of high-dimensional
random vectors. That is, we show that additive feature hashing can be performed
directly by adding the hash values and converting them into high-dimensional
numerical vectors. We show that the performance of additive feature hashing is
similar to the hashing trick, and we illustrate the results numerically using
synthetic, language recognition, and SMS spam detection data.
</p>
<a href="http://arxiv.org/abs/2102.03943" target="_blank">arXiv:2102.03943</a> [<a href="http://arxiv.org/pdf/2102.03943" target="_blank">pdf</a>]

<h2>Determinantal consensus clustering. (arXiv:2102.03948v1 [stat.ML])</h2>
<h3>Serge Vicente, Alejandro Murua</h3>
<p>Random restart of a given algorithm produces many partitions to yield a
consensus clustering. Ensemble methods such as consensus clustering have been
recognized as more robust approaches for data clustering than single clustering
algorithms. We propose the use of determinantal point processes or DPP for the
random restart of clustering algorithms based on initial sets of center points,
such as k-medoids or k-means. The relation between DPP and kernel-based methods
makes DPPs suitable to describe and quantify similarity between objects. DPPs
favor diversity of the center points within subsets. So, subsets with more
similar points have less chances of being generated than subsets with very
distinct points. The current and most popular sampling technique is sampling
center points uniformly at random. We show through extensive simulations that,
contrary to DPP, this technique fails both to ensure diversity, and to obtain a
good coverage of all data facets. These two properties of DPP are key to make
DPPs achieve good performance with small ensembles. Simulations with artificial
datasets and applications to real datasets show that determinantal consensus
clustering outperform classical algorithms such as k-medoids and k-means
consensus clusterings which are based on uniform random sampling of center
points.
</p>
<a href="http://arxiv.org/abs/2102.03948" target="_blank">arXiv:2102.03948</a> [<a href="http://arxiv.org/pdf/2102.03948" target="_blank">pdf</a>]

<h2>Doubly Residual Neural Decoder: Towards Low-Complexity High-Performance Channel Decoding. (arXiv:2102.03959v1 [cs.LG])</h2>
<h3>Siyu Liao, Chunhua Deng, Miao Yin, Bo Yuan</h3>
<p>Recently deep neural networks have been successfully applied in channel
coding to improve the decoding performance. However, the state-of-the-art
neural channel decoders cannot achieve high decoding performance and low
complexity simultaneously. To overcome this challenge, in this paper we propose
doubly residual neural (DRN) decoder. By integrating both the residual input
and residual learning to the design of neural channel decoder, DRN enables
significant decoding performance improvement while maintaining low complexity.
Extensive experiment results show that on different types of channel codes, our
DRN decoder consistently outperform the state-of-the-art decoders in terms of
decoding performance, model sizes and computational cost.
</p>
<a href="http://arxiv.org/abs/2102.03959" target="_blank">arXiv:2102.03959</a> [<a href="http://arxiv.org/pdf/2102.03959" target="_blank">pdf</a>]

<h2>Double Momentum SGD for Federated Learning. (arXiv:2102.03970v1 [cs.LG])</h2>
<h3>An Xu, Heng Huang</h3>
<p>Communication efficiency is crucial in federated learning. Conducting many
local training steps in clients to reduce the communication frequency between
clients and the server is a common method to address this issue. However, the
client drift problem arises as the non-i.i.d. data distributions in different
clients can severely deteriorate the performance of federated learning. In this
work, we propose a new SGD variant named as DOMO to improve the model
performance in federated learning, where double momentum buffers are
maintained. One momentum buffer tracks the server update direction, while the
other tracks the local update direction. We introduce a novel server momentum
fusion technique to coordinate the server and local momentum SGD. We also
provide the first theoretical analysis involving both the server and local
momentum SGD. Extensive experimental results show a better model performance of
DOMO than FedAvg and existing momentum SGD variants in federated learning
tasks.
</p>
<a href="http://arxiv.org/abs/2102.03970" target="_blank">arXiv:2102.03970</a> [<a href="http://arxiv.org/pdf/2102.03970" target="_blank">pdf</a>]

<h2>Solid Texture Synthesis using Generative Adversarial Networks. (arXiv:2102.03973v1 [cs.CV])</h2>
<h3>Xin Zhao, Lin Wang, Jifeng Guo, Bo Yang, Junteng Zheng, Fanqi Li</h3>
<p>Solid texture synthesis, as an effective way to extend 2D texture to 3D solid
texture, exhibits advantages in numerous application domains. However, existing
methods generally suffer from synthesis distortion due to the underutilization
of texture information. In this paper, we proposed a novel neural network-based
approach for the solid texture synthesis based on generative adversarial
networks, namely STS-GAN, in which the generator composed of multi-scale
modules learns the internal distribution of 2D exemplar and further extends it
to a 3D solid texture. In addition, the discriminator evaluates the similarity
between 2D exemplar and slices, promoting the generator to synthesize realistic
solid texture. Experiment results demonstrate that the proposed method can
synthesize high-quality 3D solid texture with similar visual characteristics to
the exemplar.
</p>
<a href="http://arxiv.org/abs/2102.03973" target="_blank">arXiv:2102.03973</a> [<a href="http://arxiv.org/pdf/2102.03973" target="_blank">pdf</a>]

<h2>Reconstruction of Sparse Signals under Gaussian Noise and Saturation. (arXiv:2102.03975v1 [cs.LG])</h2>
<h3>Shuvayan Banerjee, Radhe Srivastava, Ajit Rajwade</h3>
<p>Most compressed sensing algorithms do not account for the effect of
saturation in noisy compressed measurements, though saturation is an important
consequence of the limited dynamic range of existing sensors. The few
algorithms that handle saturation effects either simply discard saturated
measurements, or impose additional constraints to ensure consistency of the
estimated signal with the saturated measurements (based on a known saturation
threshold) given uniform-bounded noise. In this paper, we instead propose a new
data fidelity function which is directly based on ensuring a certain form of
consistency between the signal and the saturated measurements, and can be
expressed as the negative logarithm of a certain carefully designed likelihood
function. Our estimator works even in the case of Gaussian noise (which is
unbounded) in the measurements. We prove that our data fidelity function is
convex. We moreover, show that it satisfies the condition of Restricted Strong
Convexity and thereby derive an upper bound on the performance of the
estimator. We also show that our technique experimentally yields results
superior to the state of the art under a wide variety of experimental settings,
for compressive signal recovery from noisy and saturated measurements.
</p>
<a href="http://arxiv.org/abs/2102.03975" target="_blank">arXiv:2102.03975</a> [<a href="http://arxiv.org/pdf/2102.03975" target="_blank">pdf</a>]

<h2>Learning to Generate Fair Clusters from Demonstrations. (arXiv:2102.03977v1 [stat.ML])</h2>
<h3>Sainyam Galhotra, Sandhya Saisubramanian, Shlomo Zilberstein</h3>
<p>Fair clustering is the process of grouping similar entities together, while
satisfying a mathematically well-defined fairness metric as a constraint. Due
to the practical challenges in precise model specification, the prescribed
fairness constraints are often incomplete and act as proxies to the intended
fairness requirement, leading to biased outcomes when the system is deployed.
We examine how to identify the intended fairness constraint for a problem based
on limited demonstrations from an expert. Each demonstration is a clustering
over a subset of the data.

We present an algorithm to identify the fairness metric from demonstrations
and generate clusters using existing off-the-shelf clustering techniques, and
analyze its theoretical properties. To extend our approach to novel fairness
metrics for which clustering algorithms do not currently exist, we present a
greedy method for clustering. Additionally, we investigate how to generate
interpretable solutions using our approach. Empirical evaluation on three
real-world datasets demonstrates the effectiveness of our approach in quickly
identifying the underlying fairness and interpretability constraints, which are
then used to generate fair and interpretable clusters.
</p>
<a href="http://arxiv.org/abs/2102.03977" target="_blank">arXiv:2102.03977</a> [<a href="http://arxiv.org/pdf/2102.03977" target="_blank">pdf</a>]

<h2>Grab the Reins of Crowds: Estimating the Effects of Crowd Movement Guidance Using Causal Inference. (arXiv:2102.03980v1 [cs.LG])</h2>
<h3>Koh Takeuchi: Ryo Nishida: Hisashi Kashima: Masaki Onishi</h3>
<p>Crowd movement guidance has been a fascinating problem in various fields,
such as easing traffic congestion in unusual events and evacuating people from
an emergency-affected area. To grab the reins of crowds, there has been
considerable demand for a decision support system that can answer a typical
question: ``what will be the outcomes of each of the possible options in the
current situation. In this paper, we consider the problem of estimating the
effects of crowd movement guidance from past data. To cope with limited amount
of available data biased by past decision-makers, we leverage two recent
techniques in deep representation learning for spatial data analysis and causal
inference. We use a spatial convolutional operator to extract effective spatial
features of crowds from a small amount of data and use balanced representation
learning based on the integral probability metrics to mitigate the selection
bias and missing counterfactual outcomes. To evaluate the performance on
estimating the treatment effects of possible guidance, we use a multi-agent
simulator to generate realistic data on evacuation scenarios in a crowded
theater, since there are no available datasets recording outcomes of all
possible crowd movement guidance. The results of three experiments demonstrate
that our proposed method reduces the estimation error by at most 56% from
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.03980" target="_blank">arXiv:2102.03980</a> [<a href="http://arxiv.org/pdf/2102.03980" target="_blank">pdf</a>]

<h2>Subjective and Objective Visual Quality Assessment of Textured 3D Meshes. (arXiv:2102.03982v1 [cs.CV])</h2>
<h3>Jinjiang Guo, Vincent Vidal, Irene Cheng, Anup Basu, Atilla Baskurt, Guillaume Lavoue</h3>
<p>Objective visual quality assessment of 3D models is a fundamental issue in
computer graphics. Quality assessment metrics may allow a wide range of
processes to be guided and evaluated, such as level of detail creation,
compression, filtering, and so on. Most computer graphics assets are composed
of geometric surfaces on which several texture images can be mapped to 11 make
the rendering more realistic. While some quality assessment metrics exist for
geometric surfaces, almost no research has been conducted on the evaluation of
texture-mapped 3D models. In this context, we present a new subjective study to
evaluate the perceptual quality of textured meshes, based on a paired
comparison protocol. We introduce both texture and geometry distortions on a
set of 5 reference models to produce a database of 136 distorted models,
evaluated using two rendering protocols. Based on analysis of the results, we
propose two new metrics for visual quality assessment of textured mesh, as
optimized linear combinations of accurate geometry and texture quality
measurements. These proposed perceptual metrics outperform their counterparts
in terms of correlation with human opinion. The database, along with the
associated subjective scores, will be made publicly available online.
</p>
<a href="http://arxiv.org/abs/2102.03982" target="_blank">arXiv:2102.03982</a> [<a href="http://arxiv.org/pdf/2102.03982" target="_blank">pdf</a>]

<h2>Partial Is Better Than All: Revisiting Fine-tuning Strategy for Few-shot Learning. (arXiv:2102.03983v1 [cs.CV])</h2>
<h3>Zhiqiang Shen, Zechun Liu, Jie Qin, Marios Savvides, Kwang-Ting Cheng</h3>
<p>The goal of few-shot learning is to learn a classifier that can recognize
unseen classes from limited support data with labels. A common practice for
this task is to train a model on the base set first and then transfer to novel
classes through fine-tuning (Here fine-tuning procedure is defined as
transferring knowledge from base to novel data, i.e. learning to transfer in
few-shot scenario.) or meta-learning. However, as the base classes have no
overlap to the novel set, simply transferring whole knowledge from base data is
not an optimal solution since some knowledge in the base model may be biased or
even harmful to the novel class. In this paper, we propose to transfer partial
knowledge by freezing or fine-tuning particular layer(s) in the base model.
Specifically, layers will be imposed different learning rates if they are
chosen to be fine-tuned, to control the extent of preserved transferability. To
determine which layers to be recast and what values of learning rates for them,
we introduce an evolutionary search based method that is efficient to
simultaneously locate the target layers and determine their individual learning
rates. We conduct extensive experiments on CUB and mini-ImageNet to demonstrate
the effectiveness of our proposed method. It achieves the state-of-the-art
performance on both meta-learning and non-meta based frameworks. Furthermore,
we extend our method to the conventional pre-training + fine-tuning paradigm
and obtain consistent improvement.
</p>
<a href="http://arxiv.org/abs/2102.03983" target="_blank">arXiv:2102.03983</a> [<a href="http://arxiv.org/pdf/2102.03983" target="_blank">pdf</a>]

<h2>One-shot Face Reenactment Using Appearance Adaptive Normalization. (arXiv:2102.03984v1 [cs.CV])</h2>
<h3>Guangming Yao, Yi Yuan, Tianjia Shao, Shuang Li, Shanqi Liu, Yong Liu, Mengmeng Wang, Kun Zhou</h3>
<p>The paper proposes a novel generative adversarial network for one-shot face
reenactment, which can animate a single face image to a different
pose-and-expression (provided by a driving image) while keeping its original
appearance. The core of our network is a novel mechanism called appearance
adaptive normalization, which can effectively integrate the appearance
information from the input image into our face generator by modulating the
feature maps of the generator using the learned adaptive parameters.
Furthermore, we specially design a local net to reenact the local facial
components (i.e., eyes, nose and mouth) first, which is a much easier task for
the network to learn and can in turn provide explicit anchors to guide our face
generator to learn the global appearance and pose-and-expression. Extensive
quantitative and qualitative experiments demonstrate the significant efficacy
of our model compared with prior one-shot methods.
</p>
<a href="http://arxiv.org/abs/2102.03984" target="_blank">arXiv:2102.03984</a> [<a href="http://arxiv.org/pdf/2102.03984" target="_blank">pdf</a>]

<h2>Multisource AI Scorecard Table for System Evaluation. (arXiv:2102.03985v1 [cs.AI])</h2>
<h3>Erik Blasch, James Sung, Tao Nguyen</h3>
<p>The paper describes a Multisource AI Scorecard Table (MAST) that provides the
developer and user of an artificial intelligence (AI)/machine learning (ML)
system with a standard checklist focused on the principles of good analysis
adopted by the intelligence community (IC) to help promote the development of
more understandable systems and engender trust in AI outputs. Such a scorecard
enables a transparent, consistent, and meaningful understanding of AI tools
applied for commercial and government use. A standard is built on compliance
and agreement through policy, which requires buy-in from the stakeholders.
While consistency for testing might only exist across a standard data set, the
community requires discussion on verification and validation approaches which
can lead to interpretability, explainability, and proper use. The paper
explores how the analytic tradecraft standards outlined in Intelligence
Community Directive (ICD) 203 can provide a framework for assessing the
performance of an AI system supporting various operational needs. These include
sourcing, uncertainty, consistency, accuracy, and visualization. Three use
cases are presented as notional examples that support security for comparative
analysis.
</p>
<a href="http://arxiv.org/abs/2102.03985" target="_blank">arXiv:2102.03985</a> [<a href="http://arxiv.org/pdf/2102.03985" target="_blank">pdf</a>]

<h2>DEFT: Distilling Entangled Factors. (arXiv:2102.03986v1 [cs.LG])</h2>
<h3>Jiantao Wu, Lin Wang, Chunxiuzi Liu</h3>
<p>Disentanglement is a highly desirable property of representation due to its
similarity with human understanding and reasoning. However, the performance of
current disentanglement approaches is still unreliable and largely depends on
the hyperparameter selection. Inspired by fractional distillation in chemistry,
we propose DEFT, a disentanglement framework, to raise the lower limit of
disentanglement approaches based on variational autoencoder. It applies a
multi-stage training strategy, including multi-group encoders with different
learning rates and piecewise disentanglement pressure, to stage by stage
distill entangled factors. Furthermore, we provide insight into identifying the
hyperparameters according to the information thresholds. We evaluate DEFT on
three variants of dSprite and SmallNORB, showing robust and high-level
disentanglement scores.
</p>
<a href="http://arxiv.org/abs/2102.03986" target="_blank">arXiv:2102.03986</a> [<a href="http://arxiv.org/pdf/2102.03986" target="_blank">pdf</a>]

<h2>Machine Learning-based Classification of Active Walking Tasks in Older Adults using fNIRS. (arXiv:2102.03987v1 [cs.LG])</h2>
<h3>Dongning Ma, Meltem Izzetoglu, Roee Holtzer, Xun Jiao</h3>
<p>Decline in gait features is common in older adults and an indicator of
disability and mortality. Cortical control of gait, specifically in the
pre-frontal cortex as measured by functional near infrared spectroscopy
(fNIRS), during dual task walking has shown to be moderated by age, gender,
cognitive status, and various age-related disease conditions. In this study, we
develop classification models using machine learning methods to classify active
walking tasks in older adults based on fNIRS signals into either
Single-Task-Walk (STW) or Dual-Task-Walk (DTW) conditions. In this study, we
develop classification models using machine learning methods to classify active
walking tasks in older adults based on fNIRS signals into either single-task
walking (STW) or dual-task walking (DTW). The fNIRS measurements included
oxyhemoglobin (HbO2) and deoxyhemoglobin (Hb) signals obtained from prefrontal
cortex (PFC) of the subject performing on the ground active walking tasks with
or without a secondary cognitive task. We extract the fNIRS-related features by
calculating the minimum, maximum, mean, skewness and kurtosis values of Hb and
Hbo2 signals. We then use feature encoding to map the values into binary space.
Using these features, we apply and evaluate various machine learning methods
including logistic regression (LR), decision tree (DT), support vector machine
(SVM), k-nearest neighbors (kNN), multilayer perceptron (MLP), and Random
Forest (RF). Results showed that the machine learning models can achieve around
97\% classification accuracy.
</p>
<a href="http://arxiv.org/abs/2102.03987" target="_blank">arXiv:2102.03987</a> [<a href="http://arxiv.org/pdf/2102.03987" target="_blank">pdf</a>]

<h2>Ising Model Selection Using $\ell_{1}$-Regularized Linear Regression. (arXiv:2102.03988v1 [cs.LG])</h2>
<h3>Xiangming Meng, Tomoyuki Obuchi, Yoshiyuki Kabashima</h3>
<p>We theoretically investigate the performance of $\ell_{1}$-regularized linear
regression ($\ell_1$-LinR) for the problem of Ising model selection using the
replica method from statistical mechanics. The regular random graph is
considered under paramagnetic assumption. Our results show that despite model
misspecification, the $\ell_1$-LinR estimator can successfully recover the
graph structure of the Ising model with $N$ variables using
$M=\mathcal{O}\left(\log N\right)$ samples, which is of the same order as that
of $\ell_{1}$-regularized logistic regression. Moreover, we provide a
computationally efficient method to accurately predict the non-asymptotic
performance of the $\ell_1$-LinR estimator with moderate $M$ and $N$.
Simulations show an excellent agreement between theoretical predictions and
experimental results, which supports our findings.
</p>
<a href="http://arxiv.org/abs/2102.03988" target="_blank">arXiv:2102.03988</a> [<a href="http://arxiv.org/pdf/2102.03988" target="_blank">pdf</a>]

<h2>DeEPCA: Decentralized Exact PCA with Linear Convergence Rate. (arXiv:2102.03990v1 [cs.LG])</h2>
<h3>Haishan Ye, Tong Zhang</h3>
<p>Due to the rapid growth of smart agents such as weakly connected
computational nodes and sensors, developing decentralized algorithms that can
perform computations on local agents becomes a major research direction. This
paper considers the problem of decentralized Principal components analysis
(PCA), which is a statistical method widely used for data analysis. We
introduce a technique called subspace tracking to reduce the communication
cost, and apply it to power iterations. This leads to a decentralized PCA
algorithm called \texttt{DeEPCA}, which has a convergence rate similar to that
of the centralized PCA, while achieving the best communication complexity among
existing decentralized PCA algorithms. \texttt{DeEPCA} is the first
decentralized PCA algorithm with the number of communication rounds for each
power iteration independent of target precision. Compared to existing
algorithms, the proposed method is easier to tune in practice, with an improved
overall communication cost. Our experiments validate the advantages of
\texttt{DeEPCA} empirically.
</p>
<a href="http://arxiv.org/abs/2102.03990" target="_blank">arXiv:2102.03990</a> [<a href="http://arxiv.org/pdf/2102.03990" target="_blank">pdf</a>]

<h2>Identifying the Origin of Finger Vein Samples Using Texture Descriptors. (arXiv:2102.03992v1 [cs.CV])</h2>
<h3>Babak Maser, Andreas Uhl</h3>
<p>Identifying the origin of a sample image in biometric systems can be
beneficial for data authentication in case of attacks against the system and
for initiating sensor-specific processing pipelines in sensor-heterogeneous
environments. Motivated by shortcomings of the photo response non-uniformity
(PRNU) based method in the biometric context, we use a texture classification
approach to detect the origin of finger vein sample images. Based on eight
publicly available finger vein datasets and applying eight classical yet simple
texture descriptors and SVM classification, we demonstrate excellent sensor
model identification results for raw finger vein samples as well as for the
more challenging region of interest data. The observed results establish
texture descriptors as effective competitors to PRNU in finger vein sensor
model identification.
</p>
<a href="http://arxiv.org/abs/2102.03992" target="_blank">arXiv:2102.03992</a> [<a href="http://arxiv.org/pdf/2102.03992" target="_blank">pdf</a>]

<h2>Active learning for distributionally robust level-set estimation. (arXiv:2102.04000v1 [stat.ML])</h2>
<h3>Yu Inatsu, Shogo Iwazaki, Ichiro Takeuchi</h3>
<p>Many cases exist in which a black-box function $f$ with high evaluation cost
depends on two types of variables $\bm x$ and $\bm w$, where $\bm x$ is a
controllable \emph{design} variable and $\bm w$ are uncontrollable
\emph{environmental} variables that have random variation following a certain
distribution $P$. In such cases, an important task is to find the range of
design variables $\bm x$ such that the function $f(\bm x, \bm w)$ has the
desired properties by incorporating the random variation of the environmental
variables $\bm w$. A natural measure of robustness is the probability that
$f(\bm x, \bm w)$ exceeds a given threshold $h$, which is known as the
\emph{probability threshold robustness} (PTR) measure in the literature on
robust optimization. However, this robustness measure cannot be correctly
evaluated when the distribution $P$ is unknown. In this study, we addressed
this problem by considering the \textit{distributionally robust PTR} (DRPTR)
measure, which considers the worst-case PTR within given candidate
distributions. Specifically, we studied the problem of efficiently identifying
a reliable set $H$, which is defined as a region in which the DRPTR measure
exceeds a certain desired probability $\alpha$, which can be interpreted as a
level set estimation (LSE) problem for DRPTR. We propose a theoretically
grounded and computationally efficient active learning method for this problem.
We show that the proposed method has theoretical guarantees on convergence and
accuracy, and confirmed through numerical experiments that the proposed method
outperforms existing methods.
</p>
<a href="http://arxiv.org/abs/2102.04000" target="_blank">arXiv:2102.04000</a> [<a href="http://arxiv.org/pdf/2102.04000" target="_blank">pdf</a>]

<h2>Meta Discovery: Learning to Discover Novel Classes given Very Limited Data. (arXiv:2102.04002v1 [cs.LG])</h2>
<h3>Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Gang Niu, Bo Han</h3>
<p>In learning to discover novel classes(L2DNC), we are given labeled data from
seen classes and unlabeled data from unseen classes, and we need to train
clustering models for the unseen classes. Since L2DNC is a new problem, its
application scenario and implicit assumption are unclear. In this paper, we
analyze and improve it by linking it to meta-learning: although there are no
meta-training and meta-test phases, the underlying assumption is exactly the
same, namely high-level semantic features are shared among the seen and unseen
classes. Under this assumption, L2DNC is not only theoretically solvable, but
also can be empirically solved by meta-learning algorithms slightly modified to
fit our proposed framework. This L2DNC methodology significantly reduces the
amount of unlabeled data needed for training and makes it more practical, as
demonstrated in experiments. The use of very limited data is also justified by
the application scenario of L2DNC: since it is unnatural to label only
seen-class data, L2DNC is causally sampling instead of labeling. The
unseen-class data should be collected on the way of collecting seen-class data,
which is why they are novel and first need to be clustered.
</p>
<a href="http://arxiv.org/abs/2102.04002" target="_blank">arXiv:2102.04002</a> [<a href="http://arxiv.org/pdf/2102.04002" target="_blank">pdf</a>]

<h2>Discovering conservation laws from trajectories via machine learning. (arXiv:2102.04008v1 [cs.LG])</h2>
<h3>Seungwoong Ha, Hawoong Jeong</h3>
<p>Invariants and conservation laws convey critical information about the
underlying dynamics of a system, yet it is generally infeasible to find them
without any prior knowledge. We propose ConservNet to achieve this goal, a
neural network that extracts a conserved quantity from grouped data where the
members of each group share invariants. As a neural network trained with a
novel and intuitive loss function called noise-variance loss, ConservNet learns
the hidden invariants in each group of multi-dimensional observables in a
data-driven, end-to-end manner. We demonstrate the capability of our model with
simulated systems having invariants as well as a real-world double pendulum
trajectory. ConservNet successfully discovers underlying invariants from the
systems from a small number of data points, namely less than several thousand.
Since the model is robust to noise and data conditions compared to baseline,
our approach is directly applicable to experimental data for discovering hidden
conservation laws and relationships between variables.
</p>
<a href="http://arxiv.org/abs/2102.04008" target="_blank">arXiv:2102.04008</a> [<a href="http://arxiv.org/pdf/2102.04008" target="_blank">pdf</a>]

<h2>Learning N:M Fine-grained Structured Sparse Neural Networks From Scratch. (arXiv:2102.04010v1 [cs.CV])</h2>
<h3>Aojun Zhou, Yukun Ma, Junnan Zhu, Jianbo Liu, Zhijie Zhang, Kun Yuan, Wenxiu Sun, Hongsheng Li</h3>
<p>Sparsity in Deep Neural Networks (DNNs) has been widely studied to compress
and accelerate the models on resource-constrained environments. It can be
generally categorized into unstructured fine-grained sparsity that zeroes out
multiple individual weights distributed across the neural network, and
structured coarse-grained sparsity which prunes blocks of sub-networks of a
neural network. Fine-grained sparsity can achieve a high compression ratio but
is not hardware friendly and hence receives limited speed gains. On the other
hand, coarse-grained sparsity cannot concurrently achieve both apparent
acceleration on modern GPUs and decent performance. In this paper, we are the
first to study training from scratch an N:M fine-grained structured sparse
network, which can maintain the advantages of both unstructured fine-grained
sparsity and structured coarse-grained sparsity simultaneously on specifically
designed GPUs. Specifically, a 2:4 sparse network could achieve 2x speed-up
without performance drop on Nvidia A100 GPUs. Furthermore, we propose a novel
and effective ingredient, sparse-refined straight-through estimator (SR-STE),
to alleviate the negative influence of the approximated gradients computed by
vanilla STE during optimization. We also define a metric, Sparse Architecture
Divergence (SAD), to measure the sparse network's topology change during the
training process. Finally, We justify SR-STE's advantages with SAD and
demonstrate the effectiveness of SR-STE by performing comprehensive experiments
on various tasks. Source codes and models are available at
https://github.com/NM-sparsity/NM-sparsity.
</p>
<a href="http://arxiv.org/abs/2102.04010" target="_blank">arXiv:2102.04010</a> [<a href="http://arxiv.org/pdf/2102.04010" target="_blank">pdf</a>]

<h2>Point-set Distances for Learning Representations of 3D Point Clouds. (arXiv:2102.04014v1 [cs.CV])</h2>
<h3>Trung Nguyen, Quang-Hieu Pham, Tam Le, Tung Pham, Nhat Ho, Binh-Son Hua</h3>
<p>Learning an effective representation of 3D point clouds requires a good
metric to measure the discrepancy between two 3D point sets, which is
non-trivial due to their irregularity. Most of the previous works resort to
using the Chamfer discrepancy or Earth Mover's distance, but those metrics are
either ineffective in measuring the differences between point clouds or
computationally expensive. In this paper, we conduct a systematic study with
extensive experiments on distance metrics for 3D point clouds. From this study,
we propose to use a variant of the Wasserstein distance, named the sliced
Wasserstein distance, for learning representations of 3D point clouds.
Experiments show that the sliced Wasserstein distance allows the neural network
to learn a more efficient representation compared to the Chamfer discrepancy.
We demonstrate the efficiency of the sliced Wasserstein metric on several tasks
in 3D computer vision including training a point cloud autoencoder, generative
modeling, transfer learning, and point cloud registration.
</p>
<a href="http://arxiv.org/abs/2102.04014" target="_blank">arXiv:2102.04014</a> [<a href="http://arxiv.org/pdf/2102.04014" target="_blank">pdf</a>]

<h2>An Efficient Framework for Zero-Shot Sketch-Based Image Retrieval. (arXiv:2102.04016v1 [cs.CV])</h2>
<h3>Osman Tursun, Simon Denman, Sridha Sridharan, Ethan Goan, Clinton Fookes</h3>
<p>Recently, Zero-shot Sketch-based Image Retrieval (ZS-SBIR) has attracted the
attention of the computer vision community due to it's real-world applications,
and the more realistic and challenging setting than found in SBIR. ZS-SBIR
inherits the main challenges of multiple computer vision problems including
content-based Image Retrieval (CBIR), zero-shot learning and domain adaptation.
The majority of previous studies using deep neural networks have achieved
improved results through either projecting sketch and images into a common
low-dimensional space or transferring knowledge from seen to unseen classes.
However, those approaches are trained with complex frameworks composed of
multiple deep convolutional neural networks (CNNs) and are dependent on
category-level word labels. This increases the requirements on training
resources and datasets. In comparison, we propose a simple and efficient
framework that does not require high computational training resources, and can
be trained on datasets without semantic categorical labels. Furthermore, at
training and inference stages our method only uses a single CNN. In this work,
a pre-trained ImageNet CNN (e.g., ResNet50) is fine-tuned with three proposed
learning objects: domain-aware quadruplet loss, semantic classification loss,
and semantic knowledge preservation loss. The domain-aware quadruplet and
semantic classification losses are introduced to learn discriminative, semantic
and domain invariant features through considering ZS-SBIR as object detection
and verification problem. ...
</p>
<a href="http://arxiv.org/abs/2102.04016" target="_blank">arXiv:2102.04016</a> [<a href="http://arxiv.org/pdf/2102.04016" target="_blank">pdf</a>]

<h2>Analysis of Latent-Space Motion for Collaborative Intelligence. (arXiv:2102.04018v1 [cs.CV])</h2>
<h3>Mateen Ulhaq, Ivan V. Baji&#x107;</h3>
<p>When the input to a deep neural network (DNN) is a video signal, a sequence
of feature tensors is produced at the intermediate layers of the model. If
neighboring frames of the input video are related through motion, a natural
question is, "what is the relationship between the corresponding feature
tensors?" By analyzing the effect of common DNN operations on optical flow, we
show that the motion present in each channel of a feature tensor is
approximately equal to the scaled version of the input motion. The analysis is
validated through experiments utilizing common motion models. %These results
will be useful in collaborative intelligence applications where sequences of
feature tensors need to be compressed or further analyzed.
</p>
<a href="http://arxiv.org/abs/2102.04018" target="_blank">arXiv:2102.04018</a> [<a href="http://arxiv.org/pdf/2102.04018" target="_blank">pdf</a>]

<h2>Towards Hierarchical Task Decomposition using Deep Reinforcement Learning for Pick and Place Subtasks. (arXiv:2102.04022v1 [cs.RO])</h2>
<h3>Luca Marzari, Ameya Pore, Diego Dall&#x27;Alba, Gerardo Aragon-Camarasa, Alessandro Farinelli, Paolo Fiorini</h3>
<p>Robotic automation for pick and place task has vast applications. Deep
Reinforcement Learning (DRL) is one of the leading robotic automation technique
that has been able to achieve dexterous manipulation and locomotion robotics
skills. However, a major drawback of using DRL is the Data hungry training
regime of DRL that requires millions of trial and error attempts, impractical
in real robotic hardware. We propose a multi-subtask reinforcement learning
method where complex tasks can be decomposed into low-level subtasks. These
subtasks can be parametrised as expert networks and learnt via existing DRL
methods. The trained subtasks can be choreographed by a high-level synthesizer.
As a test bed, we use a pick and place robotic simulator, and transfer the
learnt behaviour in a real robotic system. We show that our method outperforms
imitation learning based method and reaches high success rate compared to an
end-to-end learning approach. Furthermore, we investigate the trained subtasks
to demonstrate a adaptive behaviour by fine-tuning a subset of subtasks on a
different task. Our approach deviates from the end-to-end learning strategy and
provide an initial direction towards learning modular task representations that
can generate robust behaviours.
</p>
<a href="http://arxiv.org/abs/2102.04022" target="_blank">arXiv:2102.04022</a> [<a href="http://arxiv.org/pdf/2102.04022" target="_blank">pdf</a>]

<h2>IDOL: Inertial Deep Orientation-Estimation and Localization. (arXiv:2102.04024v1 [cs.RO])</h2>
<h3>Scott Sun, Dennis Melamed, Kris Kitani</h3>
<p>Many smartphone applications use inertial measurement units (IMUs) to sense
movement, but the use of these sensors for pedestrian localization can be
challenging due to their noise characteristics. Recent data-driven inertial
odometry approaches have demonstrated the increasing feasibility of inertial
navigation. However, they still rely upon conventional smartphone orientation
estimates that they assume to be accurate, while in fact these orientation
estimates can be a significant source of error. To address the problem of
inaccurate orientation estimates, we present a two-stage, data-driven pipeline
using a commodity smartphone that first estimates device orientations and then
estimates device position. The orientation module relies on a recurrent neural
network and Extended Kalman Filter to obtain orientation estimates that are
used to then rotate raw IMU measurements into the appropriate reference frame.
The position module then passes those measurements through another recurrent
network architecture to perform localization. Our proposed method outperforms
state-of-the-art methods in both orientation and position error on a large
dataset we constructed that contains 20 hours of pedestrian motion across 3
buildings and 15 subjects.
</p>
<a href="http://arxiv.org/abs/2102.04024" target="_blank">arXiv:2102.04024</a> [<a href="http://arxiv.org/pdf/2102.04024" target="_blank">pdf</a>]

<h2>A Hybrid Bandit Model with Visual Priors for Creative Ranking in Display Advertising. (arXiv:2102.04033v1 [cs.CV])</h2>
<h3>Shiyao Wang, Qi Liu, Tiezheng Ge, Defu Lian, Zhiqiang Zhang</h3>
<p>Creative plays a great important role in e-commerce for exhibiting products.
Sellers usually create multiple creatives for comprehensive demonstrations,
thus it is crucial to display the most appealing design to maximize the
Click-Through Rate~(CTR). For this purpose, modern recommender systems
dynamically rank creatives when a product is proposed for a user. However, this
task suffers more cold-start problem than conventional products recommendation
In this paper, we propose a hybrid bandit model with visual priors which first
makes predictions with a visual evaluation, and then naturally evolves to focus
on the specialities through the hybrid bandit model. Our contributions are
three-fold: 1) We present a visual-aware ranking model (called VAM) that
incorporates a list-wise ranking loss for ordering the creatives according to
the visual appearance. 2) Regarding visual evaluations as a prior, the hybrid
bandit model (called HBM) is proposed to evolve consistently to make better
posteriori estimations by taking more observations into consideration for
online scenarios. 3) A first large-scale creative dataset, CreativeRanking, is
constructed, which contains over 1.7M creatives of 500k products as well as
their real impression and click data. Extensive experiments have also been
conducted on both our dataset and public Mushroom dataset, demonstrating the
effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.04033" target="_blank">arXiv:2102.04033</a> [<a href="http://arxiv.org/pdf/2102.04033" target="_blank">pdf</a>]

<h2>The Autonomous Siemens Tram. (arXiv:2102.04034v1 [cs.RO])</h2>
<h3>Andrew W. Palmer, Albi Sema, Wolfram Martens, Peter Rudolph, Wolfgang Waizenegger</h3>
<p>This paper presents the Autonomous Siemens Tram that was publicly
demonstrated in Potsdam, Germany during the InnoTrans 2018 exhibition. The
system was built on a Siemens Combino tram and used a multi-modal sensor suite
to localize the vehicle, and to detect and respond to traffic signals and
obstacles. An overview of the hardware and the developed localization, signal
handling, and obstacle handling components is presented, along with a summary
of their performance.
</p>
<a href="http://arxiv.org/abs/2102.04034" target="_blank">arXiv:2102.04034</a> [<a href="http://arxiv.org/pdf/2102.04034" target="_blank">pdf</a>]

<h2>In-game Residential Home Planning via Visual Context-aware Global Relation Learning. (arXiv:2102.04035v1 [cs.CV])</h2>
<h3>Lijuan Liu, Yin Yang, Yi Yuan, Tianjia Shao, He Wang, Kun Zhou</h3>
<p>In this paper, we propose an effective global relation learning algorithm to
recommend an appropriate location of a building unit for in-game customization
of residential home complex. Given a construction layout, we propose a visual
context-aware graph generation network that learns the implicit global
relations among the scene components and infers the location of a new building
unit. The proposed network takes as input the scene graph and the corresponding
top-view depth image. It provides the location recommendations for a
newly-added building units by learning an auto-regressive edge distribution
conditioned on existing scenes. We also introduce a global graph-image matching
loss to enhance the awareness of essential geometry semantics of the site.
Qualitative and quantitative experiments demonstrate that the recommended
location well reflects the implicit spatial rules of components in the
residential estates, and it is instructive and practical to locate the building
units in the 3D scene of the complex construction.
</p>
<a href="http://arxiv.org/abs/2102.04035" target="_blank">arXiv:2102.04035</a> [<a href="http://arxiv.org/pdf/2102.04035" target="_blank">pdf</a>]

<h2>Datasets and Evaluation for Simultaneous Localization and Mapping Related Problems: A Comprehensive Survey. (arXiv:2102.04036v1 [cs.RO])</h2>
<h3>Yuanzhi Liu, Yujia Fu, Fengdong Chen, Bart Goossens, Wei Tao, Hui Zhao</h3>
<p>Simultaneous Localization and Mapping (SLAM) has found an increasing
utilization lately, such as self-driving cars, robot navigation, 3D mapping,
virtual reality (VR) and augmented reality (AR), etc., empowering both industry
and daily life. Although the state-of-the-art algorithms where developers have
spared no effort are source of intelligence, it is the datasets that dedicate
behind and raise us higher. The employment of datasets is essentially a kind of
simulation but profits many aspects - capacity of drilling algorithm hourly,
exemption of costly hardware and ground truth system, and equitable benchmark
for evaluation. However, as a branch of great significance, still the datasets
have not drawn wide attention nor been reviewed thoroughly. Hence in this
article, we strive to give a comprehensive and open access review of SLAM
related datasets and evaluation, which are scarcely surveyed while highly
demanded by researchers and engineers, looking forward to serving as not only a
dictionary but also a development proposal. The paper starts with the
methodology of dataset collection, and a taxonomy of SLAM related tasks. Then
followed with the main portion - comprehensively survey the existing SLAM
related datasets by category with our considerate introductions and insights.
Furthermore, we talk about the evaluation criteria, which are necessary to
quantify the algorithm performance on the dataset and inspect the defects. At
the end, we summarize the weakness of datasets and evaluation - which could
well result in the weakness of topical algorithms - to promote bridging the gap
fundamentally.
</p>
<a href="http://arxiv.org/abs/2102.04036" target="_blank">arXiv:2102.04036</a> [<a href="http://arxiv.org/pdf/2102.04036" target="_blank">pdf</a>]

<h2>Towards Accurate RGB-D Saliency Detection with Complementary Attention and Adaptive Integration. (arXiv:2102.04046v1 [cs.CV])</h2>
<h3>Hong-Bo Bi, Zi-Qi Liu, Kang Wang, Bo Dong, Geng Chen, Ji-Quan Ma</h3>
<p>Saliency detection based on the complementary information from RGB images and
depth maps has recently gained great popularity. In this paper, we propose
Complementary Attention and Adaptive Integration Network (CAAI-Net), a novel
RGB-D saliency detection model that integrates complementary attention based
feature concentration and adaptive cross-modal feature fusion into a unified
framework for accurate saliency detection. Specifically, we propose a
context-aware complementary attention (CCA) module, which consists of a feature
interaction component, a complementary attention component, and a
global-context component. The CCA module first utilizes the feature interaction
component to extract rich local context features. The resulting features are
then fed into the complementary attention component, which employs the
complementary attention generated from adjacent levels to guide the attention
at the current layer so that the mutual background disturbances are suppressed
and the network focuses more on the areas with salient objects. Finally, we
utilize a specially-designed adaptive feature integration (AFI) module, which
sufficiently considers the low-quality issue of depth maps, to aggregate the
RGB and depth features in an adaptive manner. Extensive experiments on six
challenging benchmark datasets demonstrate that CAAI-Net is an effective
saliency detection model and outperforms nine state-of-the-art models in terms
of four widely-used metrics. In addition, extensive ablation studies confirm
the effectiveness of the proposed CCA and AFI modules.
</p>
<a href="http://arxiv.org/abs/2102.04046" target="_blank">arXiv:2102.04046</a> [<a href="http://arxiv.org/pdf/2102.04046" target="_blank">pdf</a>]

<h2>A Constant Approximation Algorithm for Sequential No-Substitution k-Median Clustering under a Random Arrival Order. (arXiv:2102.04050v1 [cs.LG])</h2>
<h3>Tom Hess, Michal Moshkovitz, Sivan Sabato</h3>
<p>We study k-median clustering under the sequential no-substitution setting. In
this setting, a data stream is sequentially observed, and some of the points
are selected by the algorithm as cluster centers. However, a point can be
selected as a center only immediately after it is observed, before observing
the next point. In addition, a selected center cannot be substituted later. We
give a new algorithm for this setting that obtains a constant approximation
factor on the optimal risk under a random arrival order. This is the first such
algorithm that holds without any assumptions on the input data and selects a
non-trivial number of centers. The number of selected centers is quasi-linear
in k. Our algorithm and analysis are based on a careful risk estimation that
avoids outliers, a new concept of a linear bin division, and repeated
calculations using an offline clustering algorithm.
</p>
<a href="http://arxiv.org/abs/2102.04050" target="_blank">arXiv:2102.04050</a> [<a href="http://arxiv.org/pdf/2102.04050" target="_blank">pdf</a>]

<h2>Sensor Planning for Large Numbers of Robots. (arXiv:2102.04054v1 [cs.RO])</h2>
<h3>Micah Corah</h3>
<p>*The following abbreviates the abstract. Please refer to the thesis for the
full abstract.*

After a disaster, locating and extracting victims quickly is critical because
mortality rises rapidly after the first two days. To assist search and rescue
teams and improve response times, teams of camera-equipped aerial robots can
engage in tasks such as mapping buildings and locating victims.

These sensing tasks encapsulate difficult (NP-Hard) problems. One way to
simplify planning for these tasks is to focus on maximizing sensing performance
over a short time horizon. Specifically, consider the problem of how to select
motions for a team of robots to maximize a notion of sensing quality (the
sensing objective) over the near future, say by maximizing the amount of
unknown space in a map that robots will observe over the next several seconds.
By repeating this process regularly, the team can react quickly to new
observations as they work to complete the sensing task. In technical terms,
this planning and control process forms an example of receding-horizon control.
Fortunately, common sensing objectives benefit from well-known monotonicity
properties (e.g. submodularity), and greedy algorithms can exploit these
monotonicity properties to solve the receding-horizon optimization problems
that we study near-optimally.

However, greedy algorithms typically force robots to make decisions
sequentially so that planning time grows with the number of robots. Further,
recent works that investigate sequential greedy planning, have demonstrated
that reducing the number of sequential steps while retaining suboptimality
guarantees can be hard or impossible.

We demonstrate that halting growth in planning time is sometimes possible. To
do so, we introduce novel greedy algorithms involving fixed numbers of
sequential steps.
</p>
<a href="http://arxiv.org/abs/2102.04054" target="_blank">arXiv:2102.04054</a> [<a href="http://arxiv.org/pdf/2102.04054" target="_blank">pdf</a>]

<h2>Improving filling level classification with adversarial training. (arXiv:2102.04057v1 [cs.CV])</h2>
<h3>Apostolos Modas, Alessio Xompero, Ricardo Sanchez-Matilla, Pascal Frossard, Andrea Cavallaro</h3>
<p>We investigate the problem of classifying - from a single image - the level
of content in a cup or a drinking glass. This problem is made challenging by
several ambiguities caused by transparencies, shape variations and partial
occlusions, and by the availability of only small training datasets. In this
paper, we tackle this problem with an appropriate strategy for transfer
learning. Specifically, we use adversarial training in a generic source dataset
and then refine the training with a task-specific dataset. We also discuss and
experimentally evaluate several training strategies and their combination on a
range of container types of the CORSMAL Containers Manipulation dataset. We
show that transfer learning with adversarial training in the source domain
consistently improves the classification accuracy on the test set and limits
the overfitting of the classifier to specific features of the training data.
</p>
<a href="http://arxiv.org/abs/2102.04057" target="_blank">arXiv:2102.04057</a> [<a href="http://arxiv.org/pdf/2102.04057" target="_blank">pdf</a>]

<h2>OV$^{2}$SLAM : A Fully Online and Versatile Visual SLAM for Real-Time Applications. (arXiv:2102.04060v1 [cs.CV])</h2>
<h3>Maxime Ferrera, Alexandre Eudes, Julien Moras, Martial Sanfourche, Guy Le Besnerais</h3>
<p>Many applications of Visual SLAM, such as augmented reality, virtual reality,
robotics or autonomous driving, require versatile, robust and precise
solutions, most often with real-time capability. In this work, we describe
OV$^{2}$SLAM, a fully online algorithm, handling both monocular and stereo
camera setups, various map scales and frame-rates ranging from a few Hertz up
to several hundreds. It combines numerous recent contributions in visual
localization within an efficient multi-threaded architecture. Extensive
comparisons with competing algorithms shows the state-of-the-art accuracy and
real-time performance of the resulting algorithm. For the benefit of the
community, we release the source code:
\url{https://github.com/ov2slam/ov2slam}.
</p>
<a href="http://arxiv.org/abs/2102.04060" target="_blank">arXiv:2102.04060</a> [<a href="http://arxiv.org/pdf/2102.04060" target="_blank">pdf</a>]

<h2>Enhance Information Propagation for Graph Neural Network by Heterogeneous Aggregations. (arXiv:2102.04064v1 [cs.LG])</h2>
<h3>Dawei Leng, Jinjiang Guo, Lurong Pan, Jie Li, Xinyu Wang</h3>
<p>Graph neural networks are emerging as continuation of deep learning success
w.r.t. graph data. Tens of different graph neural network variants have been
proposed, most following a neighborhood aggregation scheme, where the node
features are updated via aggregating features of its neighboring nodes from
layer to layer. Though related research surges, the power of GNNs are still not
on-par-with their counterpart CNNs in computer vision and RNNs in natural
language processing. We rethink this problem from the perspective of
information propagation, and propose to enhance information propagation among
GNN layers by combining heterogeneous aggregations. We argue that as richer
information are propagated from shallow to deep layers, the discriminative
capability of features formulated by GNN can benefit from it. As our first
attempt in this direction, a new generic GNN layer formulation and upon this a
new GNN variant referred as HAG-Net is proposed. We empirically validate the
effectiveness of HAG-Net on a number of graph classification benchmarks, and
elaborate all the design options and criterions along with.
</p>
<a href="http://arxiv.org/abs/2102.04064" target="_blank">arXiv:2102.04064</a> [<a href="http://arxiv.org/pdf/2102.04064" target="_blank">pdf</a>]

<h2>Learning Curve Theory. (arXiv:2102.04074v1 [cs.LG])</h2>
<h3>Marcus Hutter</h3>
<p>Recently a number of empirical "universal" scaling law papers have been
published, most notably by OpenAI. `Scaling laws' refers to power-law decreases
of training or test error w.r.t. more data, larger neural networks, and/or more
compute. In this work we focus on scaling w.r.t. data size $n$. Theoretical
understanding of this phenomenon is largely lacking, except in
finite-dimensional models for which error typically decreases with $n^{-1/2}$
or $n^{-1}$, where $n$ is the sample size. We develop and theoretically analyse
the simplest possible (toy) model that can exhibit $n^{-\beta}$ learning curves
for arbitrary power $\beta&gt;0$, and determine whether power laws are universal
or depend on the data distribution.
</p>
<a href="http://arxiv.org/abs/2102.04074" target="_blank">arXiv:2102.04074</a> [<a href="http://arxiv.org/pdf/2102.04074" target="_blank">pdf</a>]

<h2>Reliable Probabilistic Face Embeddings in the Wild. (arXiv:2102.04075v1 [cs.CV])</h2>
<h3>Kai Chen, Qi Lv, Taihe Yi, Zhengming Yi</h3>
<p>Probabilistic Face Embeddings (PFE) can improve face recognition performance
in unconstrained scenarios by integrating data uncertainty into the feature
representation. However, existing PFE methods tend to be over-confident in
estimating uncertainty and is too slow to apply to large-scale face matching.
This paper proposes a regularized probabilistic face embedding method to
improve the robustness and speed of PFE. Specifically, the mutual likelihood
score (MLS) metric used in PFE is simplified to speedup the matching of face
feature pairs. Then, an output-constraint loss is proposed to penalize the
variance of the uncertainty output, which can regularize the output of the
neural network. In addition, an identification preserving loss is proposed to
improve the discriminative of the MLS metric, and a multi-layer feature fusion
module is proposed to improve the neural network's uncertainty estimation
ability. Comprehensive experiments show that the proposed method can achieve
comparable or better results in 8 benchmarks than the state-of-the-art methods,
and can improve the performance of risk-controlled face recognition. The code
of ProbFace is publicly available in GitHub
(https://github.com/KaenChan/ProbFace).
</p>
<a href="http://arxiv.org/abs/2102.04075" target="_blank">arXiv:2102.04075</a> [<a href="http://arxiv.org/pdf/2102.04075" target="_blank">pdf</a>]

<h2>Online Clustering-based Multi-Camera Vehicle Tracking in Scenarios with overlapping FOVs. (arXiv:2102.04091v1 [cs.CV])</h2>
<h3>Elena Luna, Juan C. SanMiguel, Jose M. Mart&#xed;nez, Marcos Escudero-Vi&#xf1;olo</h3>
<p>Multi-Target Multi-Camera (MTMC) vehicle tracking is an essential task of
visual traffic monitoring, one of the main research fields of Intelligent
Transportation Systems. Several offline approaches have been proposed to
address this task; however, they are not compatible with real-world
applications due to their high latency and post-processing requirements. In
this paper, we present a new low-latency online approach for MTMC tracking in
scenarios with partially overlapping fields of view (FOVs), such as road
intersections. Firstly, the proposed approach detects vehicles at each camera.
Then, the detections are merged between cameras by applying cross-camera
clustering based on appearance and location. Lastly, the clusters containing
different detections of the same vehicle are temporally associated to compute
the tracks on a frame-by-frame basis. The experiments show promising
low-latency results while addressing real-world challenges such as the a priori
unknown and time-varying number of targets and the continuous state estimation
of them without performing any post-processing of the trajectories.
</p>
<a href="http://arxiv.org/abs/2102.04091" target="_blank">arXiv:2102.04091</a> [<a href="http://arxiv.org/pdf/2102.04091" target="_blank">pdf</a>]

<h2>A Knowledge Compilation Map for Conditional Preference Statements-based Languages. (arXiv:2102.04107v1 [cs.AI])</h2>
<h3>H&#xe9;l&#xe8;ne Fargier (IRIT-ADRIA), J&#xe9;r&#xf4;me Mengin (IRIT-ADRIA)</h3>
<p>Conditional preference statements have been used to compactly represent
preferences over combinatorial domains. They are at the core of CP-nets and
their generalizations, and lexicographic preference trees. Several works have
addressed the complexity of some queries (optimization, dominance in
particular). We extend in this paper some of these results, and study other
queries which have not been addressed so far, like equivalence, thereby
contributing to a knowledge compilation map for languages based on conditional
preference statements. We also introduce a new parameterised family of
languages, which enables to balance expressiveness against the complexity of
some queries.
</p>
<a href="http://arxiv.org/abs/2102.04107" target="_blank">arXiv:2102.04107</a> [<a href="http://arxiv.org/pdf/2102.04107" target="_blank">pdf</a>]

<h2>Dynamic Sasvi: Strong Safe Screening for Norm-Regularized Least Squares. (arXiv:2102.04108v1 [stat.ML])</h2>
<h3>Hiroaki Yamada, Makoto Yamada</h3>
<p>A recently introduced technique for a sparse optimization problem called
"safe screening" allows us to identify irrelevant variables in the early stage
of optimization. In this paper, we first propose a flexible framework for safe
screening based on the Fenchel-Rockafellar duality and then derive a strong
safe screening rule for norm-regularized least squares by the framework. We
call the proposed screening rule for norm-regularized least squares "dynamic
Sasvi" because it can be interpreted as a generalization of Sasvi. Unlike the
original Sasvi, it does not require the exact solution of a more strongly
regularized problem; hence, it works safely in practice. We show that our
screening rule can eliminate more features and increase the speed of the solver
in comparison with other screening rules both theoretically and experimentally.
</p>
<a href="http://arxiv.org/abs/2102.04108" target="_blank">arXiv:2102.04108</a> [<a href="http://arxiv.org/pdf/2102.04108" target="_blank">pdf</a>]

<h2>Relaxed Wasserstein with Applications to GANs. (arXiv:1705.07164v7 [stat.ML] UPDATED)</h2>
<h3>Xin Guo, Johnny Hong, Tianyi Lin, Nan Yang</h3>
<p>Wasserstein Generative Adversarial Networks (WGANs) provide a versatile class
of models, which have attracted great attention in various applications.
However, this framework has two main drawbacks: (i) Wasserstein-1 (or
Earth-Mover) distance is restrictive such that WGANs cannot always fit data
geometry well; (ii) It is difficult to achieve fast training of WGANs. In this
paper, we propose a new class of \textit{Relaxed Wasserstein} (RW) distances by
generalizing Wasserstein-1 distance with Bregman cost functions. We show that
RW distances achieve nice statistical properties while not sacrificing the
computational tractability. Combined with the GANs framework, we develop
Relaxed WGANs (RWGANs) which are not only statistically flexible but can be
approximated efficiently using heuristic approaches. Experiments on real images
demonstrate that the RWGAN with Kullback-Leibler (KL) cost function outperforms
other competing approaches, e.g., WGANs, even with gradient penalty.
</p>
<a href="http://arxiv.org/abs/1705.07164" target="_blank">arXiv:1705.07164</a> [<a href="http://arxiv.org/pdf/1705.07164" target="_blank">pdf</a>]

<h2>Target Robust Discriminant Analysis. (arXiv:1806.09463v2 [stat.ML] UPDATED)</h2>
<h3>Wouter M. Kouw, Marco Loog</h3>
<p>In practice, the data distribution at test time often differs, to a smaller
or larger extent, from that of the original training data. Consequentially, the
so-called source classifier, trained on the available labelled data,
deteriorates on the test, or target, data. Domain adaptive classifiers aim to
combat this problem, but typically assume some particular form of domain shift.
Most are not robust to violations of domain shift assumptions and may even
perform worse than their non-adaptive counterparts. We construct robust
parameter estimators for discriminant analysis that guarantee performance
improvements of the adaptive classifier over the non-adaptive source
classifier.
</p>
<a href="http://arxiv.org/abs/1806.09463" target="_blank">arXiv:1806.09463</a> [<a href="http://arxiv.org/pdf/1806.09463" target="_blank">pdf</a>]

<h2>Deep Neural Network Approximation Theory. (arXiv:1901.02220v3 [cs.LG] UPDATED)</h2>
<h3>Dennis Elbr&#xe4;chter, Dmytro Perekrestenko, Philipp Grohs, Helmut B&#xf6;lcskei</h3>
<p>This paper develops fundamental limits of deep neural network learning by
characterizing what is possible if no constraints are imposed on the learning
algorithm and on the amount of training data. Concretely, we consider
Kolmogorov-optimal approximation through deep neural networks with the guiding
theme being a relation between the complexity of the function (class) to be
approximated and the complexity of the approximating network in terms of
connectivity and memory requirements for storing the network topology and the
associated quantized weights. The theory we develop establishes that deep
networks are Kolmogorov-optimal approximants for markedly different function
classes, such as unit balls in Besov spaces and modulation spaces. In addition,
deep networks provide exponential approximation accuracy - i.e., the
approximation error decays exponentially in the number of nonzero weights in
the network - of the multiplication operation, polynomials, sinusoidal
functions, and certain smooth functions. Moreover, this holds true even for
one-dimensional oscillatory textures and the Weierstrass function - a fractal
function, neither of which has previously known methods achieving exponential
approximation accuracy. We also show that in the approximation of sufficiently
smooth functions finite-width deep networks require strictly smaller
connectivity than finite-depth wide networks.
</p>
<a href="http://arxiv.org/abs/1901.02220" target="_blank">arXiv:1901.02220</a> [<a href="http://arxiv.org/pdf/1901.02220" target="_blank">pdf</a>]

<h2>KTBoost: Combined Kernel and Tree Boosting. (arXiv:1902.03999v5 [cs.LG] UPDATED)</h2>
<h3>Fabio Sigrist</h3>
<p>We introduce a novel boosting algorithm called `KTBoost' which combines
kernel boosting and tree boosting. In each boosting iteration, the algorithm
adds either a regression tree or reproducing kernel Hilbert space (RKHS)
regression function to the ensemble of base learners. Intuitively, the idea is
that discontinuous trees and continuous RKHS regression functions complement
each other, and that this combination allows for better learning of functions
that have parts with varying degrees of regularity such as discontinuities and
smooth parts. We empirically show that KTBoost significantly outperforms both
tree and kernel boosting in terms of predictive accuracy in a comparison on a
wide array of data sets.
</p>
<a href="http://arxiv.org/abs/1902.03999" target="_blank">arXiv:1902.03999</a> [<a href="http://arxiv.org/pdf/1902.03999" target="_blank">pdf</a>]

<h2>An LBP-HOG Descriptor Based on Matrix Projection For Mammogram Classification. (arXiv:1904.00187v4 [cs.CV] UPDATED)</h2>
<h3>Zainab Alhakeem, Se-In Jang</h3>
<p>In image based feature descriptor design, local information from image
patches are extracted using iterative scanning operations which cause high
computational costs. In order to avoid such scanning operations, we present
matrix multiplication based local feature descriptors, namely a Matrix
projection based Local Binary Pattern (M-LBP) descriptor and a Matrix
projection based Histogram of Oriented Gradients (M-HOG) descriptor.
Additionally, an integrated formulation of M-LBP and M-HOG (M-LBP-HOG) is also
proposed to perform the two descriptors together in a single step. The proposed
descriptors are evaluated using a publicly available mammogram database. The
results show promising performances in terms of classification accuracy and
computational efficiency.
</p>
<a href="http://arxiv.org/abs/1904.00187" target="_blank">arXiv:1904.00187</a> [<a href="http://arxiv.org/pdf/1904.00187" target="_blank">pdf</a>]

<h2>Transferrable Operative Difficulty Assessment in Robot-assisted Teleoperation: A Domain Adaptation Approach. (arXiv:1906.04934v2 [cs.RO] UPDATED)</h2>
<h3>Ziheng Wang, Cong Feng, Jie Zhang, Ann Majewicz Fey</h3>
<p>Providing an accurate and efficient assessment of operative difficulty is
important for designing robot-assisted teleoperation interfaces that are easy
and natural for human operators to use. In this paper, we aim to develop a
data-driven approach to numerically characterize the operative difficulty
demand of complex teleoperation. In effort to provide an entirely
task-independent assessment, we consider using only data collected from the
human user including: (1) physiological response, and (2) movement kinematics.
By leveraging an unsupervised domain adaptation technique, our approach learns
the user information that defines task difficulty in a well-known source,
namely, a Fitt's target reaching task, and generalizes that knowledge to a more
complex human motor control scenario, namely, the teleoperation of a robotic
system. Our approach consists of two main parts: (1) The first part accounts
for the inherent variances of user physiological and kinematic response between
these cross-domain motor control scenarios that are vastly different. (2) A
stacked two-layer learner is designed to improve the overall modeling
performance, yielding a 96.6% accuracy in predicting the known difficulty of a
Fitts' reaching task when using movement kinematic features. We then validate
the effectiveness of our model by investigating teleoperated robotic needle
steering as a case study. Compared with a standard NASA TLX user survey, our
results indicate significant differences in the difficulty demand for various
choices of needle steering control algorithms, p&lt;0.05, as well as the
difficulty of steering the needle to different targets, p&lt;0.05. The results
highlight the potential of our approach to be used as a design tool to create
more intuitive and natural teleoperation interfaces in robot-assisted systems.
</p>
<a href="http://arxiv.org/abs/1906.04934" target="_blank">arXiv:1906.04934</a> [<a href="http://arxiv.org/pdf/1906.04934" target="_blank">pdf</a>]

<h2>Learning Causal State Representations of Partially Observable Environments. (arXiv:1906.10437v2 [cs.LG] UPDATED)</h2>
<h3>Amy Zhang, Zachary C. Lipton, Luis Pineda, Kamyar Azizzadenesheli, Anima Anandkumar, Laurent Itti, Joelle Pineau, Tommaso Furlanello</h3>
<p>Intelligent agents can cope with sensory-rich environments by learning
task-agnostic state abstractions. In this paper, we propose an algorithm to
approximate causal states, which are the coarsest partition of the joint
history of actions and observations in partially-observable Markov decision
processes (POMDP). Our method learns approximate causal state representations
from RNNs trained to predict subsequent observations given the history. We
demonstrate that these learned state representations are useful for learning
policies efficiently in reinforcement learning problems with rich observation
spaces. We connect causal states with causal feature sets from the causal
inference literature, and also provide theoretical guarantees on the optimality
of the continuous version of this causal state representation under Lipschitz
assumptions by proving equivalence to bisimulation, a relation between
behaviorally equivalent systems. This allows for lower bounds on the optimal
value function of the learned representation, which is tight given certain
assumptions. Finally, we empirically evaluate causal state representations
using multiple partially observable tasks and compare with prior methods.
</p>
<a href="http://arxiv.org/abs/1906.10437" target="_blank">arXiv:1906.10437</a> [<a href="http://arxiv.org/pdf/1906.10437" target="_blank">pdf</a>]

<h2>Bayesian Batch Active Learning as Sparse Subset Approximation. (arXiv:1908.02144v4 [stat.ML] UPDATED)</h2>
<h3>Robert Pinsler, Jonathan Gordon, Eric Nalisnick, Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</h3>
<p>Leveraging the wealth of unlabeled data produced in recent years provides
great potential for improving supervised models. When the cost of acquiring
labels is high, probabilistic active learning methods can be used to greedily
select the most informative data points to be labeled. However, for many
large-scale problems standard greedy procedures become computationally
infeasible and suffer from negligible model change. In this paper, we introduce
a novel Bayesian batch active learning approach that mitigates these issues.
Our approach is motivated by approximating the complete data posterior of the
model parameters. While naive batch construction methods result in correlated
queries, our algorithm produces diverse batches that enable efficient active
learning at scale. We derive interpretable closed-form solutions akin to
existing active learning procedures for linear models, and generalize to
arbitrary models using random projections. We demonstrate the benefits of our
approach on several large-scale regression and classification tasks.
</p>
<a href="http://arxiv.org/abs/1908.02144" target="_blank">arXiv:1908.02144</a> [<a href="http://arxiv.org/pdf/1908.02144" target="_blank">pdf</a>]

<h2>Sensor-Based Estimation of Dim Light Melatonin Onset (DLMO) Using Features of Two Time Scales. (arXiv:1908.07483v4 [cs.LG] UPDATED)</h2>
<h3>Cheng Wan, Andrew W. McHill, Elizabeth Klerman, Akane Sano</h3>
<p>Circadian rhythms influence multiple essential biological activities
including sleep, performance, and mood. The dim light melatonin onset (DLMO) is
the gold standard for measuring human circadian phase (i.e., timing). The
collection of DLMO is expensive and time-consuming since multiple saliva or
blood samples are required overnight in special conditions, and the samples
must then be assayed for melatonin. Recently, several computational approaches
have been designed for estimating DLMO. These methods collect daily sampled
data (e.g., sleep onset/offset times) or frequently sampled data (e.g., light
exposure/skin temperature/physical activity collected every minute) to train
learning models for estimating DLMO. One limitation of these studies is that
they only leverage one time-scale data. We propose a two-step framework for
estimating DLMO using data from both time scales. The first step summarizes
data from before the current day, while the second step combines this summary
with frequently sampled data of the current day. We evaluate three moving
average models that input sleep timing data as the first step and use recurrent
neural network models as the second step. The results using data from 207
undergraduates show that our two-step model with two time-scale features has
statistically significantly lower root-mean-square errors than models that use
either daily sampled data or frequently sampled data.
</p>
<a href="http://arxiv.org/abs/1908.07483" target="_blank">arXiv:1908.07483</a> [<a href="http://arxiv.org/pdf/1908.07483" target="_blank">pdf</a>]

<h2>Mixed Dimension Embeddings with Application to Memory-Efficient Recommendation Systems. (arXiv:1909.11810v3 [cs.LG] UPDATED)</h2>
<h3>Antonio Ginart, Maxim Naumov, Dheevatsa Mudigere, Jiyan Yang, James Zou</h3>
<p>Embedding representations power machine intelligence in many applications,
including recommendation systems, but they are space intensive -- potentially
occupying hundreds of gigabytes in large-scale settings. To help manage this
outsized memory consumption, we explore mixed dimension embeddings, an
embedding layer architecture in which a particular embedding vector's dimension
scales with its query frequency. Through theoretical analysis and systematic
experiments, we demonstrate that using mixed dimensions can drastically reduce
the memory usage, while maintaining and even improving the ML performance.
Empirically, we show that the proposed mixed dimension layers improve accuracy
by 0.1% using half as many parameters or maintain it using 16X fewer parameters
for click-through rate prediction task on the Criteo Kaggle dataset.
</p>
<a href="http://arxiv.org/abs/1909.11810" target="_blank">arXiv:1909.11810</a> [<a href="http://arxiv.org/pdf/1909.11810" target="_blank">pdf</a>]

<h2>Weighted boxes fusion: Ensembling boxes from different object detection models. (arXiv:1910.13302v3 [cs.CV] UPDATED)</h2>
<h3>Roman Solovyev, Weimin Wang, Tatiana Gabruseva</h3>
<p>In this work, we present a novel method for combining predictions of object
detection models: weighted boxes fusion. Our algorithm utilizes confidence
scores of all proposed bounding boxes to constructs the averaged boxes. We
tested method on several datasets and evaluated it in the context of the Open
Images and COCO Object Detection tracks, achieving top results in these
challenges. The source code is publicly available at
https://github.com/ZFTurbo/Weighted-Boxes-Fusion
</p>
<a href="http://arxiv.org/abs/1910.13302" target="_blank">arXiv:1910.13302</a> [<a href="http://arxiv.org/pdf/1910.13302" target="_blank">pdf</a>]

<h2>Macro F1 and Macro F1. (arXiv:1911.03347v3 [cs.LG] UPDATED)</h2>
<h3>Juri Opitz, Sebastian Burst</h3>
<p>The 'macro F1' metric is frequently used to evaluate binary, multi-class and
multi-label classification problems. Yet, we find that there exist two
different formulas to calculate this quantity. In this note, we show that only
under rare circumstances the two computations can be considered equivalent.
More specifically, one formula well 'rewards' classifiers which produce a
skewed error type distribution. In fact, the difference in outcome of the two
computations can be as high as 0.5. The two computations may not only diverge
in their scalar result but can also lead to different classifier rankings.
</p>
<a href="http://arxiv.org/abs/1911.03347" target="_blank">arXiv:1911.03347</a> [<a href="http://arxiv.org/pdf/1911.03347" target="_blank">pdf</a>]

<h2>Learning and Planning for Time-Varying MDPs Using Maximum Likelihood Estimation. (arXiv:1911.12976v2 [cs.LG] UPDATED)</h2>
<h3>Melkior Ornik, Ufuk Topcu</h3>
<p>This paper proposes a formal approach to online learning and planning for
agents operating in a priori unknown, time-varying environments. The proposed
method computes the maximally likely model of the environment, given the
observations about the environment made by an agent earlier in the system run
and assuming knowledge of a bound on the maximal rate of change of system
dynamics. Such an approach generalizes the estimation method commonly used in
learning algorithms for unknown Markov decision processes with time-invariant
transition probabilities, but is also able to quickly and correctly identify
the system dynamics following a change. Based on the proposed method, we
generalize the exploration bonuses used in learning for time-invariant Markov
decision processes by introducing a notion of uncertainty in a learned
time-varying model, and develop a control policy for time-varying Markov
decision processes based on the exploitation and exploration trade-off. We
demonstrate the proposed methods on four numerical examples: a patrolling task
with a change in system dynamics, a two-state MDP with periodically changing
outcomes of actions, a wind flow estimation task, and a multi-armed bandit
problem with periodically changing probabilities of different rewards.
</p>
<a href="http://arxiv.org/abs/1911.12976" target="_blank">arXiv:1911.12976</a> [<a href="http://arxiv.org/pdf/1911.12976" target="_blank">pdf</a>]

<h2>Improving Non-Intrusive Load Disaggregation through an Attention-Based Deep Neural Network. (arXiv:1912.00759v3 [cs.LG] UPDATED)</h2>
<h3>Veronica Piccialli, Antonio M. Sudoso</h3>
<p>Energy disaggregation, known in the literature as Non-Intrusive Load
Monitoring (NILM), is the task of inferring the power demand of the individual
appliances given the aggregate power demand recorded by a single smart meter
which monitors multiple appliances. In this paper, we propose a deep neural
network that combines a regression subnetwork with a classification subnetwork
for solving the NILM problem. Specifically, we improve the generalization
capability of the overall architecture by including an encoder-decoder with a
tailored attention mechanism in the regression subnetwork. The attention
mechanism is inspired by the temporal attention that has been successfully
applied in neural machine translation, text summarization, and speech
recognition. The experiments conducted on two publicly available datasets--REDD
and UK-DALE--show that our proposed deep neural network outperforms the
state-of-the-art in all the considered experimental conditions. We also show
that modeling attention translates into the network's ability to correctly
detect the turning on or off an appliance and to locate signal sections with
high power consumption, which are of extreme interest in the field of energy
disaggregation.
</p>
<a href="http://arxiv.org/abs/1912.00759" target="_blank">arXiv:1912.00759</a> [<a href="http://arxiv.org/pdf/1912.00759" target="_blank">pdf</a>]

<h2>SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments. (arXiv:1912.05510v4 [cs.LG] UPDATED)</h2>
<h3>Glen Berseth, Daniel Geng, Coline Devin, Nicholas Rhinehart, Chelsea Finn, Dinesh Jayaraman, Sergey Levine</h3>
<p>Every living organism struggles against disruptive environmental forces to
carve out and maintain an orderly niche. We propose that such a struggle to
achieve and preserve order might offer a principle for the emergence of useful
behaviors in artificial agents. We formalize this idea into an unsupervised
reinforcement learning method called surprise minimizing reinforcement learning
(SMiRL). SMiRL alternates between learning a density model to evaluate the
surprise of a stimulus, and improving the policy to seek more predictable
stimuli. The policy seeks out stable and repeatable situations that counteract
the environment's prevailing sources of entropy. This might include avoiding
other hostile agents, or finding a stable, balanced pose for a bipedal robot in
the face of disturbance forces. We demonstrate that our surprise minimizing
agents can successfully play Tetris, Doom, control a humanoid to avoid falls,
and navigate to escape enemies in a maze without any task-specific reward
supervision. We further show that SMiRL can be used together with standard task
rewards to accelerate reward-driven learning.
</p>
<a href="http://arxiv.org/abs/1912.05510" target="_blank">arXiv:1912.05510</a> [<a href="http://arxiv.org/pdf/1912.05510" target="_blank">pdf</a>]

<h2>Signatory: differentiable computations of the signature and logsignature transforms, on both CPU and GPU. (arXiv:2001.00706v2 [cs.LG] UPDATED)</h2>
<h3>Patrick Kidger, Terry Lyons</h3>
<p>Signatory is a library for calculating and performing functionality related
to the signature and logsignature transforms. The focus is on machine learning,
and as such includes features such as CPU parallelism, GPU support, and
backpropagation. To our knowledge it is the first GPU-capable library for these
operations. Signatory implements new features not available in previous
libraries, such as efficient precomputation strategies. Furthermore, several
novel algorithmic improvements are introduced, producing substantial real-world
speedups even on the CPU without parallelism. The library operates as a Python
wrapper around C++, and is compatible with the PyTorch ecosystem. It may be
installed directly via \texttt{pip}. Source code, documentation, examples,
benchmarks and tests may be found at
\texttt{\url{https://github.com/patrick-kidger/signatory}}. The license is
Apache-2.0.
</p>
<a href="http://arxiv.org/abs/2001.00706" target="_blank">arXiv:2001.00706</a> [<a href="http://arxiv.org/pdf/2001.00706" target="_blank">pdf</a>]

<h2>Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain. (arXiv:2001.11137v3 [cs.LG] UPDATED)</h2>
<h3>Yigit Alparslan, Ken Alparslan, Jeremy Keim-Shenk, Shweta Khade, Rachel Greenstadt</h3>
<p>Numerous recent studies have demonstrated how Deep Neural Network (DNN)
classifiers can be fooled by adversarial examples, in which an attacker adds
perturbations to an original sample, causing the classifier to misclassify the
sample. Adversarial attacks that render DNNs vulnerable in real life represent
a serious threat in autonomous vehicles, malware filters, or biometric
authentication systems. In this paper, we apply Fast Gradient Sign Method to
introduce perturbations to a facial image dataset and then test the output on a
different classifier that we trained ourselves, to analyze transferability of
this method. Next, we craft a variety of different black-box attack algorithms
on a facial image dataset assuming minimal adversarial knowledge, to further
assess the robustness of DNNs in facial recognition. While experimenting with
different image distortion techniques, we focus on modifying single optimal
pixels by a large amount, or modifying all pixels by a smaller amount, or
combining these two attack approaches. While our single-pixel attacks achieved
about a 15% average decrease in classifier confidence level for the actual
class, the all-pixel attacks were more successful and achieved up to an 84%
average decrease in confidence, along with an 81.6% misclassification rate, in
the case of the attack that we tested with the highest levels of perturbation.
Even with these high levels of perturbation, the face images remained
identifiable to a human. Understanding how these noised and perturbed images
baffle the classification algorithms can yield valuable advances in the
training of DNNs against defense-aware adversarial attacks, as well as adaptive
noise reduction techniques. We hope our research may help to advance the study
of adversarial attacks on DNNs and defensive mechanisms to counteract them,
particularly in the facial recognition domain.
</p>
<a href="http://arxiv.org/abs/2001.11137" target="_blank">arXiv:2001.11137</a> [<a href="http://arxiv.org/pdf/2001.11137" target="_blank">pdf</a>]

<h2>Learning Test-time Data Augmentation for Image Retrieval with Reinforcement Learning. (arXiv:2002.01642v3 [cs.CV] UPDATED)</h2>
<h3>Osman Tursun, Simon Denman, Sridha Sridharan, Clinton Fookes</h3>
<p>Off-the-shelf convolutional neural network features achieve outstanding
results in many image retrieval tasks. However, their invariance is pre-defined
by the network architecture and training data. Existing image retrieval
approaches require fine-tuning or modification of the pre-trained networks to
adapt to the variations in the target data. In contrast, our method enhances
the invariance of off-the-shelf features by aggregating features extracted from
images augmented with learned test-time augmentations. The optimal ensemble of
test-time augmentations is learned automatically through reinforcement
learning. Our training is time and resources efficient, and learns a diverse
test-time augmentations. Experiment results on trademark retrieval (METU
trademark dataset) and landmark retrieval (Oxford5k and Paris6k scene datasets)
tasks show the learned ensemble of transformations is effective and
transferable. We also achieve state-of-the-art MAP@100 results on the METU
trademark dataset.
</p>
<a href="http://arxiv.org/abs/2002.01642" target="_blank">arXiv:2002.01642</a> [<a href="http://arxiv.org/pdf/2002.01642" target="_blank">pdf</a>]

<h2>From Data to Actions in Intelligent Transportation Systems: a Prescription of Functional Requirements for Model Actionability. (arXiv:2002.02210v3 [cs.AI] UPDATED)</h2>
<h3>Ibai Lana, Javier J. Sanchez-Medina, Eleni I. Vlahogianni, Javier Del Ser</h3>
<p>Advances in Data Science permeate every field of Transportation Science and
Engineering, resulting in developments in the transportation sector that {are}
data-driven. Nowadays, Intelligent Transportation Systems (ITS) could be
arguably approached as a ``story'' intensively producing and consuming large
amounts of data. A~diversity of sensing devices densely spread over the
infrastructure, vehicles or the travelers' personal devices act as sources of
data flows that are eventually fed {into} software running on automatic
devices, actuators or control systems producing, in~turn, complex information
flows {among} users, traffic managers, data analysts, traffic modeling
scientists, etc. These~information flows provide enormous opportunities to
improve model development and decision-making. This work aims to describe how
data, coming from diverse ITS sources, can be used to learn and adapt
data-driven models for efficiently operating ITS assets, systems and processes;
in~other words, for data-based models to fully become \emph{actionable}.
Grounded in this described data modeling pipeline for ITS, we~define the
characteristics, engineering requisites and challenges intrinsic to its three
compounding stages, namely, data fusion, adaptive learning and model
evaluation. We~deliberately generalize model learning to be adaptive, since,
in~the core of our paper is the firm conviction that most learners will have to
adapt to the ever-changing phenomenon scenario underlying the majority of ITS
applications. Finally, we~provide a prospect of current research lines within
Data Science that can bring notable advances to data-based ITS modeling, which
will eventually bridge the gap towards the practicality and actionability of
such models.
</p>
<a href="http://arxiv.org/abs/2002.02210" target="_blank">arXiv:2002.02210</a> [<a href="http://arxiv.org/pdf/2002.02210" target="_blank">pdf</a>]

<h2>Learning Stochastic Behaviour from Aggregate Data. (arXiv:2002.03513v4 [cs.LG] UPDATED)</h2>
<h3>Shaojun Ma, Shu Liu, Hongyuan Zha, Haomin Zhou</h3>
<p>Learning nonlinear dynamics from aggregate datais a challenging problem
because the full trajectory of each individual is not available, namely, the
individual observed at one time may not beobserved at the next time point, or
the identity ofindividual is unavailable. This is in sharp contrastto learning
dynamics with full trajectory data, on which the majority of existing methods
are based. We propose a novel method using the weak form of Fokker Planck
Equation(FPE) -- a partial differential equation -- to describe the density
evolution of data in a sampled form, which is then combined with Wasserstein
generative adversarial network (WGAN) in the training process. Insuch a sample
based framework we are able to learn the nonlinear dynamics from aggregate data
without explicitly solving FPE. More importantly, our model can also readily
handle high dimensional cases by leveraging deep neural networks. We
demonstrate our approach in the context of aseries of synthetic and real-world
data sets.
</p>
<a href="http://arxiv.org/abs/2002.03513" target="_blank">arXiv:2002.03513</a> [<a href="http://arxiv.org/pdf/2002.03513" target="_blank">pdf</a>]

<h2>Semi-Structured Deep Distributional Regression: Combining Structured Additive Models and Deep Learning. (arXiv:2002.05777v4 [stat.ML] UPDATED)</h2>
<h3>David R&#xfc;gamer, Chris Kolb, Nadja Klein</h3>
<p>Combining additive models and neural networks allows to broaden the scope of
statistical regression and extends deep learning-based approaches by
interpretable structured additive predictors at the same time. Existing
approaches uniting the two modeling approaches are, however, limited to very
specific combinations and, more importantly, involve an identifiability issue.
As a consequence, interpretability and stable estimation is typically lost. We
propose a general framework to combine structured regression models and deep
neural networks into a unifying network architecture. To overcome the inherent
identifiability issues between different model parts, we construct an
orthogonalization cell that projects the deep neural network into the
orthogonal complement of the statistical model predictor. This enables proper
estimation of structured model parts and thereby interpretability. We
demonstrate the framework's efficacy in numerical experiments and illustrate
its special merits in benchmarks and real-world applications.
</p>
<a href="http://arxiv.org/abs/2002.05777" target="_blank">arXiv:2002.05777</a> [<a href="http://arxiv.org/pdf/2002.05777" target="_blank">pdf</a>]

<h2>Fast Loop Closure Detection via Binary Content. (arXiv:2002.10622v2 [cs.CV] UPDATED)</h2>
<h3>Han Wang, Juncheng Li, Maopeng Ran, Lihua Xie</h3>
<p>Loop closure detection plays an important role in reducing localization drift
in Simultaneous Localization And Mapping (SLAM). It aims to find repetitive
scenes from historical data to reset localization. To tackle the loop closure
problem, existing methods often leverage on the matching of visual features,
which achieve good accuracy but require high computational resources. However,
feature point based methods ignore the patterns of image, i.e., the shape of
the objects as well as the distribution of objects in an image. It is believed
that this information is usually unique for a scene and can be utilized to
improve the performance of traditional loop closure detection methods. In this
paper we leverage and compress the information into a binary image to
accelerate an existing fast loop closure detection method via binary content.
The proposed method can greatly reduce the computational cost without
sacrificing recall rate. It consists of three parts: binary content
construction, fast image retrieval and precise loop closure detection. No
offline training is required. Our method is compared with the state-of-the-art
loop closure detection methods and the results show that it outperforms the
traditional methods at both recall rate and speed.
</p>
<a href="http://arxiv.org/abs/2002.10622" target="_blank">arXiv:2002.10622</a> [<a href="http://arxiv.org/pdf/2002.10622" target="_blank">pdf</a>]

<h2>Feasible Computationally Efficient Path Planning for UAV Collision Avoidance. (arXiv:2002.10623v2 [cs.RO] UPDATED)</h2>
<h3>Han Wang, Muqing Cao, Hao Jiang, Lihua Xie</h3>
<p>This paper presents a robust computationally efficient real-time collision
avoidance algorithm for Unmanned Aerial Vehicle (UAV), namely Memory-based Wall
Following-Artificial Potential Field (MWF-APF) method. The new algorithm
switches between Wall-Following Method (WFM) and Artificial Potential Field
method (APF) with improved situation awareness capability. Historical
trajectory is taken into account to avoid repetitive wrong decision.
Furthermore, it can be effectively applied to platform with low computing
capability. As an example, a quad-rotor equipped with limited number of
Time-of-Flight (TOF) rangefinders is adopted to validate the effectiveness and
efficiency of this algorithm. Both software simulation and physical flight test
have been conducted to demonstrate the capability of the MWF-APF method in
complex scenarios.
</p>
<a href="http://arxiv.org/abs/2002.10623" target="_blank">arXiv:2002.10623</a> [<a href="http://arxiv.org/pdf/2002.10623" target="_blank">pdf</a>]

<h2>NeuralSens: Sensitivity Analysis of Neural Networks. (arXiv:2002.11423v2 [cs.LG] UPDATED)</h2>
<h3>J. Pizarroso, J. Portela, A. Mu&#xf1;oz</h3>
<p>Neural networks are important tools for data-intensive analysis and are
commonly applied to model non-linear relationships between dependent and
independent variables. However, neural networks are usually seen as "black
boxes" that offer minimal information about how the input variables are used to
predict the response in a fitted model. This article describes the
\pkg{NeuralSens} package that can be used to perform sensitivity analysis of
neural networks using the partial derivatives method. Functions in the package
can be used to obtain the sensitivities of the output with respect to the input
variables, evaluate variable importance based on sensitivity measures and
characterize relationships between input and output variables. Methods to
calculate sensitivities are provided for objects from common neural network
packages in \proglang{R}, including \pkg{neuralnet}, \pkg{nnet}, \pkg{RSNNS},
\pkg{h2o}, \pkg{neural}, \pkg{forecast} and \pkg{caret}. The article presents
an overview of the techniques for obtaining information from neural network
models, a theoretical foundation of how are calculated the partial derivatives
of the output with respect to the inputs of a multi-layer perceptron model, a
description of the package structure and functions, and applied examples to
compare \pkg{NeuralSens} functions with analogous functions from other
available \proglang{R} packages.
</p>
<a href="http://arxiv.org/abs/2002.11423" target="_blank">arXiv:2002.11423</a> [<a href="http://arxiv.org/pdf/2002.11423" target="_blank">pdf</a>]

<h2>First Order Methods take Exponential Time to Converge to Global Minimizers of Non-Convex Functions. (arXiv:2002.12911v2 [cs.LG] UPDATED)</h2>
<h3>Krishna Reddy Kesari, Jean Honorio</h3>
<p>Machine learning algorithms typically perform optimization over a class of
non-convex functions. In this work, we provide bounds on the fundamental
hardness of identifying the global minimizer of a non convex function.
Specifically, we design a family of parametrized non-convex functions and
employ statistical lower bounds for parameter estimation. We show that the
parameter estimation problem is equivalent to the problem of function
identification in the given family. We then claim that non convex optimization
is at least as hard as function identification. Jointly, we prove that any
first order method can take exponential time to converge to a global minimizer.
</p>
<a href="http://arxiv.org/abs/2002.12911" target="_blank">arXiv:2002.12911</a> [<a href="http://arxiv.org/pdf/2002.12911" target="_blank">pdf</a>]

<h2>Image Matching across Wide Baselines: From Paper to Practice. (arXiv:2003.01587v4 [cs.CV] UPDATED)</h2>
<h3>Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuk, Jiri Matas, Pascal Fua, Kwang Moo Yi, Eduard Trulls</h3>
<p>We introduce a comprehensive benchmark for local features and robust
estimation algorithms, focusing on the downstream task -- the accuracy of the
reconstructed camera pose -- as our primary metric. Our pipeline's modular
structure allows easy integration, configuration, and combination of different
methods and heuristics. This is demonstrated by embedding dozens of popular
algorithms and evaluating them, from seminal works to the cutting edge of
machine learning research. We show that with proper settings, classical
solutions may still outperform the perceived state of the art.

Besides establishing the actual state of the art, the conducted experiments
reveal unexpected properties of Structure from Motion (SfM) pipelines that can
help improve their performance, for both algorithmic and learned methods. Data
and code are online https://github.com/vcg-uvic/image-matching-benchmark,
providing an easy-to-use and flexible framework for the benchmarking of local
features and robust estimation methods, both alongside and against
top-performing methods. This work provides a basis for the Image Matching
Challenge https://vision.uvic.ca/image-matching-challenge.
</p>
<a href="http://arxiv.org/abs/2003.01587" target="_blank">arXiv:2003.01587</a> [<a href="http://arxiv.org/pdf/2003.01587" target="_blank">pdf</a>]

<h2>RODNet: Radar Object Detection Using Cross-Modal Supervision. (arXiv:2003.01816v2 [cs.CV] UPDATED)</h2>
<h3>Yizhou Wang, Zhongyu Jiang, Xiangyu Gao, Jenq-Neng Hwang, Guanbin Xing, Hui Liu</h3>
<p>Radar is usually more robust than the camera in severe driving scenarios,
e.g., weak/strong lighting and bad weather. However, unlike RGB images captured
by a camera, the semantic information from the radar signals is noticeably
difficult to extract. In this paper, we propose a deep radar object detection
network (RODNet), to effectively detect objects purely from the carefully
processed radar frequency data in the format of range-azimuth frequency
heatmaps (RAMaps). Three different 3D autoencoder based architectures are
introduced to predict object confidence distribution from each snippet of the
input RAMaps. The final detection results are then calculated using our
post-processing method, called location-based non-maximum suppression (L-NMS).
Instead of using burdensome human-labeled ground truth, we train the RODNet
using the annotations generated automatically by a novel 3D localization method
using a camera-radar fusion (CRF) strategy. To train and evaluate our method,
we build a new dataset -- CRUW, containing synchronized videos and RAMaps in
various driving scenarios. After intensive experiments, our RODNet shows
favorable object detection performance without the presence of the camera.
</p>
<a href="http://arxiv.org/abs/2003.01816" target="_blank">arXiv:2003.01816</a> [<a href="http://arxiv.org/pdf/2003.01816" target="_blank">pdf</a>]

<h2>Slice Tuner: A Selective Data Acquisition Framework for Accurate and Fair Machine Learning Models. (arXiv:2003.04549v2 [cs.LG] UPDATED)</h2>
<h3>Ki Hyun Tae, Steven Euijong Whang</h3>
<p>As machine learning becomes democratized in the era of Software 2.0, a
serious bottleneck is acquiring enough data to ensure accurate and fair models.
Recent techniques including crowdsourcing provide cost-effective ways to gather
such data. However, simply acquiring data as much as possible is not
necessarily an effective strategy for optimizing accuracy and fairness. For
example, if an online app store has enough training data for certain slices of
data (say American customers), but not for others, obtaining more American
customer data will only bias the model training. Instead, we contend that one
needs to selectively acquire data and propose Slice Tuner, which acquires
possibly-different amounts of data per slice such that the model accuracy and
fairness on all slices are optimized. This problem is different than labeling
existing data (as in active learning or weak supervision) because the goal is
obtaining the right amounts of new data. At its core, Slice Tuner maintains
learning curves of slices that estimate the model accuracies given more data
and uses convex optimization to find the best data acquisition strategy. The
key challenges of estimating learning curves are that they may be inaccurate if
there is not enough data, and there may be dependencies among slices where
acquiring data for one slice influences the learning curves of others. We solve
these issues by iteratively and efficiently updating the learning curves as
more data is acquired. We evaluate Slice Tuner on real datasets using
crowdsourcing for data acquisition and show that Slice Tuner significantly
outperforms baselines in terms of model accuracy and fairness, even when the
learning curves cannot be reliably estimated.
</p>
<a href="http://arxiv.org/abs/2003.04549" target="_blank">arXiv:2003.04549</a> [<a href="http://arxiv.org/pdf/2003.04549" target="_blank">pdf</a>]

<h2>A Graph Convolutional Topic Model for Short and Noisy Text Streams. (arXiv:2003.06112v3 [cs.LG] UPDATED)</h2>
<h3>Ngo Van Linh, Tran Xuan Bach, Khoat Than</h3>
<p>Learning hidden topics from data streams has become absolutely necessary but
posed challenging problems such as concept drift as well as short and noisy
data. Using prior knowledge to enrich a topic model is one of potential
solutions to cope with these challenges. Prior knowledge that is derived from
human knowledge (e.g. Wordnet) or a pre-trained model (e.g. Word2vec) is very
valuable and useful to help topic models work better. However, in a streaming
environment where data arrives continually and infinitely, existing studies are
limited to exploiting these resources effectively. Especially, a knowledge
graph, that contains meaningful word relations, is ignored. In this paper, to
aim at exploiting a knowledge graph effectively, we propose a novel graph
convolutional topic model (GCTM) which integrates graph convolutional networks
(GCN) into a topic model and a learning method which learns the networks and
the topic model simultaneously for data streams. In each minibatch, our method
not only can exploit an external knowledge graph but also can balance the
external and old knowledge to perform well on new data. We conduct extensive
experiments to evaluate our method with both a human knowledge graph (Wordnet)
and a graph built from pre-trained word embeddings (Word2vec). The experimental
results show that our method achieves significantly better performances than
state-of-the-art baselines in terms of probabilistic predictive measure and
topic coherence. In particular, our method can work well when dealing with
short texts as well as concept drift. The implementation of GCTM is available
at \url{https://github.com/bachtranxuan/GCTM.git}.
</p>
<a href="http://arxiv.org/abs/2003.06112" target="_blank">arXiv:2003.06112</a> [<a href="http://arxiv.org/pdf/2003.06112" target="_blank">pdf</a>]

<h2>Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay. (arXiv:2003.09908v2 [cs.LG] UPDATED)</h2>
<h3>Fan Zhou, Chengtai Cao</h3>
<p>Graph Neural Networks (GNNs) have recently received significant research
attention due to their superior performance on a variety of graph-related
learning tasks. Most of the current works focus on either static or dynamic
graph settings, addressing a single particular task, e.g., node/graph
classification, link prediction. In this work, we investigate the question: can
GNNs be applied to continuously learning a sequence of tasks? Towards that, we
explore the Continual Graph Learning (CGL) paradigm and present the Experience
Replay based framework ER-GNN for CGL to alleviate the catastrophic forgetting
problem in existing GNNs. ER-GNN stores knowledge from previous tasks as
experiences and replays them when learning new tasks to mitigate the
catastrophic forgetting issue. We propose three experience node selection
strategies: mean of feature, coverage maximization, and influence maximization,
to guide the process of selecting experience nodes. Extensive experiments on
three benchmark datasets demonstrate the effectiveness of our ER-GNN and shed
light on the incremental graph (non-Euclidean) structure learning.
</p>
<a href="http://arxiv.org/abs/2003.09908" target="_blank">arXiv:2003.09908</a> [<a href="http://arxiv.org/pdf/2003.09908" target="_blank">pdf</a>]

<h2>SOAR: Second-Order Adversarial Regularization. (arXiv:2004.01832v2 [cs.LG] UPDATED)</h2>
<h3>Avery Ma, Fartash Faghri, Nicolas Papernot, Amir-massoud Farahmand</h3>
<p>Adversarial training is a common approach to improving the robustness of deep
neural networks against adversarial examples. In this work, we propose a novel
regularization approach as an alternative. To derive the regularizer, we
formulate the adversarial robustness problem under the robust optimization
framework and approximate the loss function using a second-order Taylor series
expansion. Our proposed second-order adversarial regularizer (SOAR) is an upper
bound based on the Taylor approximation of the inner-max in the robust
optimization objective. We empirically show that the proposed method
significantly improves the robustness of networks against the $\ell_\infty$ and
$\ell_2$ bounded perturbations generated using cross-entropy-based PGD on
CIFAR-10 and SVHN.
</p>
<a href="http://arxiv.org/abs/2004.01832" target="_blank">arXiv:2004.01832</a> [<a href="http://arxiv.org/pdf/2004.01832" target="_blank">pdf</a>]

<h2>ConsciousControlFlow(CCF): A Demonstration for conscious Artificial Intelligence. (arXiv:2004.04376v2 [cs.AI] UPDATED)</h2>
<h3>Hongzhi Wang, Bozhou Chen, Yueyang Xu, Kaixin Zhang, Shengwen Zheng</h3>
<p>In this demo, we present ConsciousControlFlow(CCF), a prototype system to
demonstrate conscious Artificial Intelligence (AI). The system is based on the
computational model for consciousness and the hierarchy of needs. CCF supports
typical scenarios to show the behaviors and the mental activities of conscious
AI. We demonstrate that CCF provides a useful tool for effective machine
consciousness demonstration and human behavior study assistance.
</p>
<a href="http://arxiv.org/abs/2004.04376" target="_blank">arXiv:2004.04376</a> [<a href="http://arxiv.org/pdf/2004.04376" target="_blank">pdf</a>]

<h2>D4RL: Datasets for Deep Data-Driven Reinforcement Learning. (arXiv:2004.07219v4 [cs.LG] UPDATED)</h2>
<h3>Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine</h3>
<p>The offline reinforcement learning (RL) setting (also known as full batch
RL), where a policy is learned from a static dataset, is compelling as progress
enables RL methods to take advantage of large, previously-collected datasets,
much like how the rise of large datasets has fueled results in supervised
learning. However, existing online RL benchmarks are not tailored towards the
offline setting and existing offline RL benchmarks are restricted to data
generated by partially-trained agents, making progress in offline RL difficult
to measure. In this work, we introduce benchmarks specifically designed for the
offline setting, guided by key properties of datasets relevant to real-world
applications of offline RL. With a focus on dataset collection, examples of
such properties include: datasets generated via hand-designed controllers and
human demonstrators, multitask datasets where an agent performs different tasks
in the same environment, and datasets collected with mixtures of policies. By
moving beyond simple benchmark tasks and data collected by partially-trained RL
agents, we reveal important and unappreciated deficiencies of existing
algorithms. To facilitate research, we have released our benchmark tasks and
datasets with a comprehensive evaluation of existing algorithms, an evaluation
protocol, and open-source examples. This serves as a common starting point for
the community to identify shortcomings in existing offline RL methods and a
collaborative route for progress in this emerging area.
</p>
<a href="http://arxiv.org/abs/2004.07219" target="_blank">arXiv:2004.07219</a> [<a href="http://arxiv.org/pdf/2004.07219" target="_blank">pdf</a>]

<h2>TPNet: Trajectory Proposal Network for Motion Prediction. (arXiv:2004.12255v2 [cs.CV] UPDATED)</h2>
<h3>Liangji Fang, Qinhong Jiang, Jianping Shi, Bolei Zhou</h3>
<p>Making accurate motion prediction of the surrounding traffic agents such as
pedestrians, vehicles, and cyclists is crucial for autonomous driving. Recent
data-driven motion prediction methods have attempted to learn to directly
regress the exact future position or its distribution from massive amount of
trajectory data. However, it remains difficult for these methods to provide
multimodal predictions as well as integrate physical constraints such as
traffic rules and movable areas. In this work we propose a novel two-stage
motion prediction framework, Trajectory Proposal Network (TPNet). TPNet first
generates a candidate set of future trajectories as hypothesis proposals, then
makes the final predictions by classifying and refining the proposals which
meets the physical constraints. By steering the proposal generation process,
safe and multimodal predictions are realized. Thus this framework effectively
mitigates the complexity of motion prediction problem while ensuring the
multimodal output. Experiments on four large-scale trajectory prediction
datasets, i.e. the ETH, UCY, Apollo and Argoverse datasets, show that TPNet
achieves the state-of-the-art results both quantitatively and qualitatively.
</p>
<a href="http://arxiv.org/abs/2004.12255" target="_blank">arXiv:2004.12255</a> [<a href="http://arxiv.org/pdf/2004.12255" target="_blank">pdf</a>]

<h2>Evaluation Metrics for Conditional Image Generation. (arXiv:2004.12361v2 [cs.CV] UPDATED)</h2>
<h3>Yaniv Benny, Tomer Galanti, Sagie Benaim, Lior Wolf</h3>
<p>We present two new metrics for evaluating generative models in the
class-conditional image generation setting. These metrics are obtained by
generalizing the two most popular unconditional metrics: the Inception Score
(IS) and the Fre'chet Inception Distance (FID). A theoretical analysis shows
the motivation behind each proposed metric and links the novel metrics to their
unconditional counterparts. The link takes the form of a product in the case of
IS or an upper bound in the FID case. We provide an extensive empirical
evaluation, comparing the metrics to their unconditional variants and to other
metrics, and utilize them to analyze existing generative models, thus providing
additional insights about their performance, from unlearned classes to mode
collapse.
</p>
<a href="http://arxiv.org/abs/2004.12361" target="_blank">arXiv:2004.12361</a> [<a href="http://arxiv.org/pdf/2004.12361" target="_blank">pdf</a>]

<h2>CARRADA Dataset: Camera and Automotive Radar with Range-Angle-Doppler Annotations. (arXiv:2005.01456v3 [cs.CV] UPDATED)</h2>
<h3>A. Ouaknine, A. Newson, J. Rebut, F. Tupin, P. P&#xe9;rez</h3>
<p>High quality perception is essential for autonomous driving (AD) systems. To
reach the accuracy and robustness that are required by such systems, several
types of sensors must be combined. Currently, mostly cameras and laser scanners
(lidar) are deployed to build a representation of the world around the vehicle.
While radar sensors have been used for a long time in the automotive industry,
they are still under-used for AD despite their appealing characteristics
(notably, their ability to measure the relative speed of obstacles and to
operate even in adverse weather conditions). To a large extent, this situation
is due to the relative lack of automotive datasets with real radar signals that
are both raw and annotated. In this work, we introduce CARRADA, a dataset of
synchronized camera and radar recordings with range-angle-Doppler annotations.
We also present a semi-automatic annotation approach, which was used to
annotate the dataset, and a radar semantic segmentation baseline, which we
evaluate on several metrics. Both our code and dataset are available online.
</p>
<a href="http://arxiv.org/abs/2005.01456" target="_blank">arXiv:2005.01456</a> [<a href="http://arxiv.org/pdf/2005.01456" target="_blank">pdf</a>]

<h2>Synthesizing Safe Policies under Probabilistic Constraints with Reinforcement Learning and Bayesian Model Checking. (arXiv:2005.03898v2 [cs.AI] UPDATED)</h2>
<h3>Lenz Belzner, Martin Wirsing</h3>
<p>We propose to leverage epistemic uncertainty about constraint satisfaction of
a reinforcement learner in safety critical domains. We introduce a framework
for specification of requirements for reinforcement learners in constrained
settings, including confidence about results. We show that an agent's
confidence in constraint satisfaction provides a useful signal for balancing
optimization and safety in the learning process.
</p>
<a href="http://arxiv.org/abs/2005.03898" target="_blank">arXiv:2005.03898</a> [<a href="http://arxiv.org/pdf/2005.03898" target="_blank">pdf</a>]

<h2>Decoder Modulation for Indoor Depth Completion. (arXiv:2005.08607v2 [cs.CV] UPDATED)</h2>
<h3>Dmitry Senushkin, Mikhail Romanov, Ilia Belikov, Anton Konushin, Nikolay Patakin</h3>
<p>Depth completion recovers a dense depth map from sensor measurements. Current
methods are mostly tailored for very sparse depth measurements from LiDARs in
outdoor settings, while for indoor scenes Time-of-Flight (ToF) or structured
light sensors are mostly used. These sensors provide semi-dense maps, with
dense measurements in some regions and almost empty in others. We propose a new
model that takes into account the statistical difference between such regions.
Our main contribution is a new decoder modulation branch added to the
encoder-decoder architecture. The encoder extracts features from the
concatenated RGB image and raw depth. Given the mask of missing values as
input, the proposed modulation branch controls the decoding of a dense depth
map from these features differently for different regions. This is implemented
by modifying the spatial distribution of output signals inside the decoder via
Spatially-Adaptive Denormalization (SPADE) blocks. Our second contribution is a
novel training strategy that allows us to train on a semi-dense sensor data
when the ground truth depth map is not available. Our model achieves the state
of the art results on indoor Matterport3D dataset. Being designed for
semi-dense input depth, our model is still competitive with LiDAR-oriented
approaches on the KITTI dataset. Our training strategy significantly improves
prediction quality with no dense ground truth available, as validated on the
NYUv2 dataset.
</p>
<a href="http://arxiv.org/abs/2005.08607" target="_blank">arXiv:2005.08607</a> [<a href="http://arxiv.org/pdf/2005.08607" target="_blank">pdf</a>]

<h2>A Generalised Signature Method for Multivariate Time Series Feature Extraction. (arXiv:2006.00873v2 [cs.LG] UPDATED)</h2>
<h3>James Morrill, Adeline Fermanian, Patrick Kidger, Terry Lyons</h3>
<p>The 'signature method' refers to a collection of feature extraction
techniques for multivariate time series, derived from the theory of controlled
differential equations. There is a great deal of flexibility as to how this
method can be applied. On the one hand, this flexibility allows the method to
be tailored to specific problems, but on the other hand, can make precise
application challenging. This paper makes two contributions. First, the
variations on the signature method are unified into a general approach, the
\emph{generalised signature method}, of which previous variations are special
cases. A primary aim of this unifying framework is to make the signature method
more accessible to any machine learning practitioner, whereas it is now mostly
used by specialists. Second, and within this framework, we derive a canonical
collection of choices that provide a domain-agnostic starting point. We derive
these choices as a result of an extensive empirical study on 26 datasets and go
on to show competitive performance against current benchmarks for multivariate
time series classification. Finally, to ease practical application, we make our
techniques available as part of the open-source [redacted] project.
</p>
<a href="http://arxiv.org/abs/2006.00873" target="_blank">arXiv:2006.00873</a> [<a href="http://arxiv.org/pdf/2006.00873" target="_blank">pdf</a>]

<h2>Generalization Bounds in the Presence of Outliers: a Median-of-Means Study. (arXiv:2006.05240v2 [stat.ML] UPDATED)</h2>
<h3>Pierre Laforgue, Guillaume Staerman, Stephan Cl&#xe9;men&#xe7;on</h3>
<p>In contrast to the empirical mean, the Median-of-Means (MoM) is an estimator
of the mean $\theta$ of a square integrable r.v. $Z$, around which accurate
nonasymptotic confidence bounds can be built, even when $Z$ does not exhibit a
sub-Gaussian tail behavior. Thanks to the high confidence it achieves on
heavy-tailed data, MoM has found various applications in machine learning,
where it is used to design training procedures that are not sensitive to
atypical observations. More recently, a new line of work is now trying to
characterize and leverage MoM's ability to deal with corrupted data. In this
context, the present work proposes a general study of MoM's concentration
properties under the contamination regime, that provides a clear understanding
of the impact of the outlier proportion and the number of blocks chosen. The
analysis is extended to (multisample) $U$-statistics, i.e. averages over tuples
of observations, that raise additional challenges due to the dependence
induced. Finally, we show that the latter bounds can be used in a
straightforward fashion to derive generalization guarantees for pairwise
learning in a contaminated setting, and propose an algorithm to compute
provably reliable decision functions.
</p>
<a href="http://arxiv.org/abs/2006.05240" target="_blank">arXiv:2006.05240</a> [<a href="http://arxiv.org/pdf/2006.05240" target="_blank">pdf</a>]

<h2>Approximating Lipschitz continuous functions with GroupSort neural networks. (arXiv:2006.05254v2 [stat.ML] UPDATED)</h2>
<h3>Ugo Tanielian, Maxime Sangnier, Gerard Biau</h3>
<p>Recent advances in adversarial attacks and Wasserstein GANs have advocated
for use of neural networks with restricted Lipschitz constants. Motivated by
these observations, we study the recently introduced GroupSort neural networks,
with constraints on the weights, and make a theoretical step towards a better
understanding of their expressive power. We show in particular how these
networks can represent any Lipschitz continuous piecewise linear functions. We
also prove that they are well-suited for approximating Lipschitz continuous
functions and exhibit upper bounds on both the depth and size. To conclude, the
efficiency of GroupSort networks compared with more standard ReLU networks is
illustrated in a set of synthetic experiments.
</p>
<a href="http://arxiv.org/abs/2006.05254" target="_blank">arXiv:2006.05254</a> [<a href="http://arxiv.org/pdf/2006.05254" target="_blank">pdf</a>]

<h2>Sequential Density Ratio Estimation for Simultaneous Optimization of Speed and Accuracy. (arXiv:2006.05587v3 [cs.LG] UPDATED)</h2>
<h3>Akinori F. Ebihara, Taiki Miyagawa, Kazuyuki Sakurai, Hitoshi Imaoka</h3>
<p>Classifying sequential data as early and as accurately as possible is a
challenging yet critical problem, especially when a sampling cost is high. One
algorithm that achieves this goal is the sequential probability ratio test
(SPRT), which is known as Bayes-optimal: it can keep the expected number of
data samples as small as possible, given the desired error upper-bound.
However, the original SPRT makes two critical assumptions that limit its
application in real-world scenarios: (i) samples are independently and
identically distributed, and (ii) the likelihood of the data being derived from
each class can be calculated precisely. Here, we propose the SPRT-TANDEM, a
deep neural network-based SPRT algorithm that overcomes the above two
obstacles. The SPRT-TANDEM sequentially estimates the log-likelihood ratio of
two alternative hypotheses by leveraging a novel Loss function for
Log-Likelihood Ratio estimation (LLLR) while allowing correlations up to $N
(\in \mathbb{N})$ preceding samples. In tests on one original and two public
video databases, Nosaic MNIST, UCF101, and SiW, the SPRT-TANDEM achieves
statistically significantly better classification accuracy than other baseline
classifiers, with a smaller number of data samples. The code and Nosaic MNIST
are publicly available at https://github.com/TaikiMiyagawa/SPRT-TANDEM.
</p>
<a href="http://arxiv.org/abs/2006.05587" target="_blank">arXiv:2006.05587</a> [<a href="http://arxiv.org/pdf/2006.05587" target="_blank">pdf</a>]

<h2>Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning. (arXiv:2006.06119v6 [cs.CV] UPDATED)</h2>
<h3>Ruozi Huang, Huang Hu, Wei Wu, Kei Sawada, Mi Zhang, Daxin Jiang</h3>
<p>Dancing to music is one of human's innate abilities since ancient times. In
machine learning research, however, synthesizing dance movements from music is
a challenging problem. Recently, researchers synthesize human motion sequences
through autoregressive models like recurrent neural network (RNN). Such an
approach often generates short sequences due to an accumulation of prediction
errors that are fed back into the neural network. This problem becomes even
more severe in the long motion sequence generation. Besides, the consistency
between dance and music in terms of style, rhythm and beat is yet to be taken
into account during modeling. In this paper, we formalize the music-driven
dance generation as a sequence-to-sequence learning problem and devise a novel
seq2seq architecture to efficiently process long sequences of music features
and capture the fine-grained correspondence between music and dance.
Furthermore, we propose a novel curriculum learning strategy to alleviate error
accumulation of autoregressive models in long motion sequence generation, which
gently changes the training process from a fully guided teacher-forcing scheme
using the previous ground-truth movements, towards a less guided autoregressive
scheme mostly using the generated movements instead. Extensive experiments show
that our approach significantly outperforms the existing state-of-the-arts on
automatic metrics and human evaluation. We also make a demo video in the
supplementary material to demonstrate the superior performance of our proposed
approach.
</p>
<a href="http://arxiv.org/abs/2006.06119" target="_blank">arXiv:2006.06119</a> [<a href="http://arxiv.org/pdf/2006.06119" target="_blank">pdf</a>]

<h2>Revisiting Explicit Regularization in Neural Networks for Well-Calibrated Predictive Uncertainty. (arXiv:2006.06399v3 [cs.LG] UPDATED)</h2>
<h3>Taejong Joo, Uijung Chung</h3>
<p>From the statistical learning perspective, complexity control via explicit
regularization is a necessity for improving the generalization of
over-parameterized models. However, the impressive generalization performance
of neural networks with only implicit regularization may be at odds with this
conventional wisdom. In this work, we revisit the importance of explicit
regularization for obtaining well-calibrated predictive uncertainty.
Specifically, we introduce a probabilistic measure of calibration performance,
which is lower bounded by the log-likelihood. We then explore explicit
regularization techniques for improving the log-likelihood on unseen samples,
which provides well-calibrated predictive uncertainty. Our findings present a
new direction to improve the predictive probability quality of deterministic
neural networks, which can be an efficient and scalable alternative to Bayesian
neural networks and ensemble methods.
</p>
<a href="http://arxiv.org/abs/2006.06399" target="_blank">arXiv:2006.06399</a> [<a href="http://arxiv.org/pdf/2006.06399" target="_blank">pdf</a>]

<h2>Projection Robust Wasserstein Distance and Riemannian Optimization. (arXiv:2006.07458v7 [cs.LG] UPDATED)</h2>
<h3>Tianyi Lin, Chenyou Fan, Nhat Ho, Marco Cuturi, Michael I. Jordan</h3>
<p>Projection robust Wasserstein (PRW) distance, or Wasserstein projection
pursuit (WPP), is a robust variant of the Wasserstein distance. Recent work
suggests that this quantity is more robust than the standard Wasserstein
distance, in particular when comparing probability measures in high-dimensions.
However, it is ruled out for practical application because the optimization
model is essentially non-convex and non-smooth which makes the computation
intractable. Our contribution in this paper is to revisit the original
motivation behind WPP/PRW, but take the hard route of showing that, despite its
non-convexity and lack of nonsmoothness, and even despite some hardness results
proved by~\citet{Niles-2019-Estimation} in a minimax sense, the original
formulation for PRW/WPP \textit{can} be efficiently computed in practice using
Riemannian optimization, yielding in relevant cases better behavior than its
convex relaxation. More specifically, we provide three simple algorithms with
solid theoretical guarantee on their complexity bound (one in the appendix),
and demonstrate their effectiveness and efficiency by conducing extensive
experiments on synthetic and real data. This paper provides a first step into a
computational theory of the PRW distance and provides the links between optimal
transport and Riemannian optimization.
</p>
<a href="http://arxiv.org/abs/2006.07458" target="_blank">arXiv:2006.07458</a> [<a href="http://arxiv.org/pdf/2006.07458" target="_blank">pdf</a>]

<h2>Adversarial representation learning for synthetic replacement of private attributes. (arXiv:2006.08039v5 [cs.LG] UPDATED)</h2>
<h3>John Martinsson, Edvin Listo Zec, Daniel Gillblad, Olof Mogren</h3>
<p>Data privacy is an increasingly important aspect of many real-world Data
sources that contain sensitive information may have immense potential which
could be unlocked using the right privacy enhancing transformations, but
current methods often fail to produce convincing output. Furthermore, finding
the right balance between privacy and utility is often a tricky trade-off. In
this work, we propose a novel approach for data privatization, which involves
two steps: in the first step, it removes the sensitive information, and in the
second step, it replaces this information with an independent random sample.
Our method builds on adversarial representation learning which ensures strong
privacy by training the model to fool an increasingly strong adversary. While
previous methods only aim at obfuscating the sensitive information, we find
that adding new random information in its place strengthens the provided
privacy and provides better utility at any given level of privacy. The result
is an approach that can provide stronger privatization on image data, and yet
be preserving both the domain and the utility of the inputs, entirely
independent of the downstream task.
</p>
<a href="http://arxiv.org/abs/2006.08039" target="_blank">arXiv:2006.08039</a> [<a href="http://arxiv.org/pdf/2006.08039" target="_blank">pdf</a>]

<h2>Optimal Complexity in Decentralized Training. (arXiv:2006.08085v2 [cs.LG] UPDATED)</h2>
<h3>Yucheng Lu, Christopher De Sa</h3>
<p>Decentralization is a promising method of scaling up parallel machine
learning systems. In this paper, we provide a tight lower bound on the
iteration complexity for such methods in a stochastic non-convex setting. Our
lower bound reveals a theoretical gap in known convergence rates of many
existing decentralized training algorithms. We prove by construction this lower
bound is tight and achievable. Motivated by our insights, we further propose
DeTAG, a practical gossip-style decentralized algorithm that achieves the lower
bound with only a logarithm gap. Empirically, we compare DeTAG with other
decentralized algorithms on image classification tasks, and we show DeTAG
enjoys faster convergence compared to baselines, especially on unshuffled data
and in sparse networks.
</p>
<a href="http://arxiv.org/abs/2006.08085" target="_blank">arXiv:2006.08085</a> [<a href="http://arxiv.org/pdf/2006.08085" target="_blank">pdf</a>]

<h2>MetaCURE: Meta Reinforcement Learning with Empowerment-Driven Exploration. (arXiv:2006.08170v2 [cs.AI] UPDATED)</h2>
<h3>Jin Zhang, Jianhao Wang, Hao Hu, Tong Chen, Yingfeng Chen, Changjie Fan, Chongjie Zhang</h3>
<p>Meta reinforcement learning (meta-RL) extracts knowledge from previous tasks
and achieves fast adaptation to new tasks. Despite recent progress, efficient
exploration in meta-RL remains a key challenge in sparse-reward tasks, as it
requires quickly finding informative task-relevant experiences in both
meta-training and adaptation. To address this challenge, we explicitly model an
exploration policy learning problem for meta-RL, which is separated from
exploitation policy learning, and introduce a novel empowerment-driven
exploration objective, which aims to maximize information gain for task
identification. We derive a corresponding intrinsic reward and develop a new
off-policy meta-RL framework, which efficiently learns separate context-aware
exploration and exploitation policies by sharing the knowledge of task
inference. Experimental evaluation shows that our meta-RL method significantly
outperforms state-of-the-art baselines on various sparse-reward MuJoCo
locomotion tasks and more complex sparse-reward Meta-World tasks.
</p>
<a href="http://arxiv.org/abs/2006.08170" target="_blank">arXiv:2006.08170</a> [<a href="http://arxiv.org/pdf/2006.08170" target="_blank">pdf</a>]

<h2>Overparameterization and generalization error: weighted trigonometric interpolation. (arXiv:2006.08495v2 [cs.LG] UPDATED)</h2>
<h3>Yuege Xie, Hung-Hsu Chou, Holger Rauhut, Rachel Ward</h3>
<p>Motivated by surprisingly good generalization properties of learned deep
neural networks in overparameterized scenarios and by the related double
descent phenomenon, this paper analyzes the relation between smoothness and low
generalization error in an overparameterized linear learning problem. We study
a random Fourier series model, where the task is to estimate the unknown
Fourier coefficients from equidistant samples. We derive exact expressions for
the generalization error of both plain and weighted least squares estimators.
We show precisely how a bias towards smooth interpolants, in the form of
weighted trigonometric interpolation, can lead to smaller generalization error
in the overparameterized regime compared to the underparameterized regime. This
provides insight into the power of overparameterization, which is common in
modern machine learning.
</p>
<a href="http://arxiv.org/abs/2006.08495" target="_blank">arXiv:2006.08495</a> [<a href="http://arxiv.org/pdf/2006.08495" target="_blank">pdf</a>]

<h2>Zero-Shot Learning with Common Sense Knowledge Graphs. (arXiv:2006.10713v2 [cs.LG] UPDATED)</h2>
<h3>Nihal V. Nayak, Stephen H. Bach</h3>
<p>Zero-shot learning relies on semantic class representations such as
hand-engineered attributes or learned embeddings to predict classes without any
labeled examples. We propose to learn class representations from common sense
knowledge graphs. Common sense knowledge graphs are an untapped source of
explicit high-level knowledge that requires little human effort to apply to a
range of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a
general-purpose framework with a novel transformer graph convolutional network
(TrGCN) for generating class representations. Our proposed TrGCN architecture
computes non-linear combinations of the node neighbourhood and shows
improvements on zero-shot learning tasks in language and vision. Our results
show ZSL-KG outperforms the best performing graph-based zero-shot learning
framework by an average of 2.1 accuracy points with improvements as high as 3.4
accuracy points. Our ablation study on ZSL-KG with alternate graph neural
networks shows that our TrGCN adds up to 1.2 accuracy points improvement on
these tasks.
</p>
<a href="http://arxiv.org/abs/2006.10713" target="_blank">arXiv:2006.10713</a> [<a href="http://arxiv.org/pdf/2006.10713" target="_blank">pdf</a>]

<h2>Reliable Categorical Variational Inference with Mixture of Discrete Normalizing Flows. (arXiv:2006.15568v2 [cs.LG] UPDATED)</h2>
<h3>Tomasz Ku&#x15b;mierczyk, Arto Klami</h3>
<p>Variational approximations are increasingly based on gradient-based
optimization of expectations estimated by sampling. Handling discrete latent
variables is then challenging because the sampling process is not
differentiable. Continuous relaxations, such as the Gumbel-Softmax for
categorical distribution, enable gradient-based optimization, but do not define
a valid probability mass for discrete observations. In practice, selecting the
amount of relaxation is difficult and one needs to optimize an objective that
does not align with the desired one, causing problems especially with models
having strong meaningful priors. We provide an alternative differentiable
reparameterization for categorical distribution by composing it as a mixture of
discrete normalizing flows. It defines a proper discrete distribution, allows
directly optimizing the evidence lower bound, and is less sensitive to the
hyperparameter controlling relaxation.
</p>
<a href="http://arxiv.org/abs/2006.15568" target="_blank">arXiv:2006.15568</a> [<a href="http://arxiv.org/pdf/2006.15568" target="_blank">pdf</a>]

<h2>Adai: Separating the Effects of Adaptive Learning Rate and Momentum Inertia. (arXiv:2006.15815v9 [cs.LG] UPDATED)</h2>
<h3>Zeke Xie, Xinrui Wang, Huishuai Zhang, Issei Sato, Masashi Sugiyama</h3>
<p>Adaptive Momentum Estimation (Adam), which combines Adaptive Learning Rate
and Momentum, is the most popular stochastic optimizer for accelerating the
training of deep neural networks. However, empirically Adam often generalizes
worse than Stochastic Gradient Descent (SGD). We unveil the mystery of this
behavior based on the diffusion theoretical framework. Specifically, we
disentangle the effects of Adaptive Learning Rate and Momentum of the Adam
dynamics on saddle-point escaping and minima selection. We prove that Adaptive
Learning Rate can escape saddle points efficiently, but cannot select flat
minima as SGD does. In contrast, Momentum provides a drift effect to help the
training process pass through saddle points, and almost does not affect flat
minima selection. This theoretically explains why SGD (with Momentum)
generalizes better, while Adam generalizes worse but converges faster.
Furthermore, motivated by the analysis, we design a novel adaptive optimization
framework named Adaptive Inertia, which uses parameter-wise adaptive inertia to
accelerate the training and provably favors flat minima as well as SGD. Our
extensive experiments demonstrate that the proposed adaptive inertia method can
generalize significantly better than SGD and conventional adaptive gradient
methods.
</p>
<a href="http://arxiv.org/abs/2006.15815" target="_blank">arXiv:2006.15815</a> [<a href="http://arxiv.org/pdf/2006.15815" target="_blank">pdf</a>]

<h2>Convex Regularization in Monte-Carlo Tree Search. (arXiv:2007.00391v2 [cs.LG] UPDATED)</h2>
<h3>Tuan Dam, Carlo D&#x27;Eramo, Jan Peters, Joni Pajarinen</h3>
<p>Monte-Carlo planning and Reinforcement Learning (RL) are essential to
sequential decision making. The recent AlphaGo and AlphaZero algorithms have
shown how to successfully combine these two paradigms in order to solve large
scale sequential decision problems. These methodologies exploit a variant of
the well-known UCT algorithm to trade off exploitation of good actions and
exploration of unvisited states, but their empirical success comes at the cost
of poor sample-efficiency and high computation time. In this paper, we overcome
these limitations by considering convex regularization in Monte-Carlo Tree
Search (MCTS), which has been successfully used in RL to efficiently drive
exploration. First, we introduce a unifying theory on the use of generic convex
regularizers in MCTS, deriving the regret analysis and providing guarantees of
exponential convergence rate. Second, we exploit our theoretical framework to
introduce novel regularized backup operators for MCTS, based on the relative
entropy of the policy update, and on the Tsallis entropy of the policy.
Finally, we empirically evaluate the proposed operators in AlphaGo and
AlphaZero on problems of increasing dimensionality and branching factor, from a
toy problem to several Atari games, showing their superiority w.r.t.
representative baselines.
</p>
<a href="http://arxiv.org/abs/2007.00391" target="_blank">arXiv:2007.00391</a> [<a href="http://arxiv.org/pdf/2007.00391" target="_blank">pdf</a>]

<h2>Expected Eligibility Traces. (arXiv:2007.01839v2 [cs.LG] UPDATED)</h2>
<h3>Hado van Hasselt, Sephora Madjiheurem, Matteo Hessel, David Silver, Andr&#xe9; Barreto, Diana Borsa</h3>
<p>The question of how to determine which states and actions are responsible for
a certain outcome is known as the credit assignment problem and remains a
central research question in reinforcement learning and artificial
intelligence. Eligibility traces enable efficient credit assignment to the
recent sequence of states and actions experienced by the agent, but not to
counterfactual sequences that could also have led to the current state. In this
work, we introduce expected eligibility traces. Expected traces allow, with a
single update, to update states and actions that could have preceded the
current state, even if they did not do so on this occasion. We discuss when
expected traces provide benefits over classic (instantaneous) traces in
temporal-difference learning, and show that sometimes substantial improvements
can be attained. We provide a way to smoothly interpolate between instantaneous
and expected traces by a mechanism similar to bootstrapping, which ensures that
the resulting algorithm is a strict generalisation of TD($\lambda$). Finally,
we discuss possible extensions and connections to related ideas, such as
successor features.
</p>
<a href="http://arxiv.org/abs/2007.01839" target="_blank">arXiv:2007.01839</a> [<a href="http://arxiv.org/pdf/2007.01839" target="_blank">pdf</a>]

<h2>AnchorFace: An Anchor-based Facial Landmark Detector Across Large Poses. (arXiv:2007.03221v3 [cs.CV] UPDATED)</h2>
<h3>Zixuan Xu, Banghuai Li, Miao Geng, Ye Yuan</h3>
<p>Facial landmark localization aims to detect the predefined points of human
faces, and the topic has been rapidly improved with the recent development of
neural network based methods. However, it remains a challenging task when
dealing with faces in unconstrained scenarios, especially with large pose
variations. In this paper, we target the problem of facial landmark
localization across large poses and address this task based on a
split-and-aggregate strategy. To split the search space, we propose a set of
anchor templates as references for regression, which well addresses the large
variations of face poses. Based on the prediction of each anchor template, we
propose to aggregate the results, which can reduce the landmark uncertainty due
to the large poses. Overall, our proposed approach, named AnchorFace, obtains
state-of-the-art results with extremely efficient inference speed on four
challenging benchmarks, i.e. AFLW, 300W, Menpo, and WFLW dataset. Code will be
available at https://github.com/nothingelse92/AnchorFace.
</p>
<a href="http://arxiv.org/abs/2007.03221" target="_blank">arXiv:2007.03221</a> [<a href="http://arxiv.org/pdf/2007.03221" target="_blank">pdf</a>]

<h2>A Constraint-Based Algorithm for the Structural Learning of Continuous-Time Bayesian Networks. (arXiv:2007.03248v2 [cs.AI] UPDATED)</h2>
<h3>Alessandro Bregoli, Marco Scutari, Fabio Stella</h3>
<p>Dynamic Bayesian networks have been well explored in the literature as
discrete-time models: however, their continuous-time extensions have seen
comparatively little attention. In this paper, we propose the first
constraint-based algorithm for learning the structure of continuous-time
Bayesian networks. We discuss the different statistical tests and the
underlying hypotheses used by our proposal to establish conditional
independence. Furthermore, we analyze and discuss the computational complexity
of the best and worst cases for the proposed algorithm. Finally, we validate
its performance using synthetic data, and we discuss its strengths and
limitations comparing it with the score-based structure learning algorithm from
Nodelman et al. (2003).

We find the latter to be more accurate in learning networks with binary
variables, while our constraint-based approach is more accurate with variables
assuming more than two values.

Numerical experiments confirm that score-based and constraint-based
algorithms are comparable in terms of computation time.
</p>
<a href="http://arxiv.org/abs/2007.03248" target="_blank">arXiv:2007.03248</a> [<a href="http://arxiv.org/pdf/2007.03248" target="_blank">pdf</a>]

<h2>Interval Universal Approximation for Neural Networks. (arXiv:2007.06093v4 [cs.LG] UPDATED)</h2>
<h3>Zi Wang, Aws Albarghouthi, Gautam Prakriya, Somesh Jha</h3>
<p>To certify safety and robustness of neural networks, researchers have
successfully applied abstract interpretation, primarily using interval bound
propagation (IBP). IBP is an incomplete calculus that over-approximates the set
of possible predictions of a neural network. In this paper, we introduce the
interval universal approximation (IUA) theorem, which sheds light on the power
and limits of IBP.

First, IUA shows that neural networks not only can approximate any continuous
function $f$ (universal approximation) as we have known for decades, but we can
find a neural network, using any well-behaved activation function, whose
interval bounds are an arbitrary close approximation of the set semantics of
$f$ (the result of applying $f$ to a set of inputs). We call this notion of
approximation interval approximation. Our result (1) extends the recent result
of Baader et al. (2020) from ReLUs to a rich class of activation functions that
we call squashable functions, and (2) implies that we can construct certifiably
robust neural networks under $\ell_\infty$-norm using almost any practical
activation function.

Our construction and that of Baader et al. (2020) are exponential in the size
of the function's domain. The IUA theorem additionally establishes a limit on
the capabilities of IBP. Specifically, we show that there is no efficient
construction of a neural network that interval-approximates any $f$, unless
P=NP. To do so, we present a novel reduction from 3SAT to
interval-approximation of neural networks. It implies that it is hard to
construct an IBP-certifiably robust network, even if we have a robust network
to start with.
</p>
<a href="http://arxiv.org/abs/2007.06093" target="_blank">arXiv:2007.06093</a> [<a href="http://arxiv.org/pdf/2007.06093" target="_blank">pdf</a>]

<h2>Whitening for Self-Supervised Representation Learning. (arXiv:2007.06346v4 [cs.LG] UPDATED)</h2>
<h3>Aleksandr Ermolov, Aliaksandr Siarohin, Enver Sangineto, Nicu Sebe</h3>
<p>Most of the current self-supervised representation learning methods are based
on the contrastive loss and the instance-discrimination task, where augmented
versions of the same image instance ("positives") are contrasted with instances
extracted from other images ("negatives"). For the learning to be effective,
many negatives should be compared with a positive pair, which is
computationally demanding. In this paper, we propose a different direction and
a new loss function for self-supervised representation learning which is based
on the whitening of the latent-space features. The whitening operation has a
"scattering" effect on the batch samples, which compensates the use of
negatives, avoiding degenerate solutions where all the sample representations
collapse to a single point. Our Whitening MSE (W-MSE) loss does not require
additional momentum networks and it is conceptually simple. Moreover, since
negatives are not needed, we can extract multiple positive pairs from the same
image instance. We empirically show that W-MSE is competitive with respect to
popular, more complex self-supervised methods. The source code of the method
and of all the experiments is available at
https://github.com/htdt/self-supervised.
</p>
<a href="http://arxiv.org/abs/2007.06346" target="_blank">arXiv:2007.06346</a> [<a href="http://arxiv.org/pdf/2007.06346" target="_blank">pdf</a>]

<h2>Self-supervised Auxiliary Learning with Meta-paths for Heterogeneous Graphs. (arXiv:2007.08294v5 [cs.LG] UPDATED)</h2>
<h3>Dasol Hwang, Jinyoung Park, Sunyoung Kwon, Kyung-Min Kim, Jung-Woo Ha, Hyunwoo J. Kim</h3>
<p>Graph neural networks have shown superior performance in a wide range of
applications providing a powerful representation of graph-structured data.
Recent works show that the representation can be further improved by auxiliary
tasks. However, the auxiliary tasks for heterogeneous graphs, which contain
rich semantic information with various types of nodes and edges, have less
explored in the literature. In this paper, to learn graph neural networks on
heterogeneous graphs we propose a novel self-supervised auxiliary learning
method using meta-paths, which are composite relations of multiple edge types.
Our proposed method is learning to learn a primary task by predicting
meta-paths as auxiliary tasks. This can be viewed as a type of meta-learning.
The proposed method can identify an effective combination of auxiliary tasks
and automatically balance them to improve the primary task. Our methods can be
applied to any graph neural networks in a plug-in manner without manual
labeling or additional data. The experiments demonstrate that the proposed
method consistently improves the performance of link prediction and node
classification on heterogeneous graphs.
</p>
<a href="http://arxiv.org/abs/2007.08294" target="_blank">arXiv:2007.08294</a> [<a href="http://arxiv.org/pdf/2007.08294" target="_blank">pdf</a>]

<h2>Towards Evaluating Driver Fatigue with Robust Deep Learning Models. (arXiv:2007.08453v4 [cs.CV] UPDATED)</h2>
<h3>Ken Alparslan, Yigit Alparslan, Matthew Burlick</h3>
<p>In this paper, we explore different deep learning based approaches to detect
driver fatigue. Drowsy driving results in approximately 72,000 crashes and
44,000 injuries every year in the US and detecting drowsiness and alerting the
driver can save many lives. There have been many approaches to detect fatigue,
of which eye closedness detection is one. We propose a framework to detect eye
closedness in a captured camera frame as a gateway for detecting drowsiness. We
explore two different datasets to detect eye closedness. We develop an eye
model by using new Eye-blink dataset and a face model by using the Closed Eyes
in the Wild (CEW). We also explore different techniques to make the models more
robust by adding noise. We achieve 95.84% accuracy on our eye model and 80.01%
accuracy on our face model. We also see that we can improve our accuracy on the
face model by 6% via adversarial training and data augmentation. We hope that
our work will be useful to the field of driver fatigue detection to avoid
potential vehicle accidents related to drowsy driving.
</p>
<a href="http://arxiv.org/abs/2007.08453" target="_blank">arXiv:2007.08453</a> [<a href="http://arxiv.org/pdf/2007.08453" target="_blank">pdf</a>]

<h2>SOCRATES: Towards a Unified Platform for Neural Network Analysis. (arXiv:2007.11206v2 [cs.LG] UPDATED)</h2>
<h3>Long H. Pham, Jiaying Li, Jun Sun</h3>
<p>Studies show that neural networks, not unlike traditional programs, are
subject to bugs, e.g., adversarial samples that cause classification errors and
discriminatory instances that demonstrate the lack of fairness. Given that
neural networks are increasingly applied in critical applications (e.g.,
self-driving cars, face recognition systems and personal credit rating
systems), it is desirable that systematic methods are developed to analyze
(e.g., test or verify) neural networks against desirable properties. Recently,
a number of approaches have been developed for analyzing neural networks. These
efforts are however scattered (i.e., each approach tackles some restricted
classes of neural networks against certain particular properties), incomparable
(i.e., each approach has its own assumptions and input format) and thus hard to
apply, reuse or extend. In this project, we aim to build a unified framework
for developing techniques to analyze neural networks. Towards this goal, we
develop a platform called SOCRATES which supports a standardized format for a
variety of neural network models, an assertion language for property
specification as well as multiple neural network analysis algorithms including
two novel ones for falsifying and probabilistic verification of neural network
models. SOCRATES is extensible and thus existing approaches can be easily
integrated. Experiment results show that our platform can handle a wide range
of networks models and properties. More importantly, it provides a platform for
synergistic research on neural network analysis.
</p>
<a href="http://arxiv.org/abs/2007.11206" target="_blank">arXiv:2007.11206</a> [<a href="http://arxiv.org/pdf/2007.11206" target="_blank">pdf</a>]

<h2>Adversarial Attacks against Face Recognition: A Comprehensive Study. (arXiv:2007.11709v3 [cs.CV] UPDATED)</h2>
<h3>Fatemeh Vakhshiteh, Ahmad Nickabadi, Raghavendra Ramachandra</h3>
<p>Face recognition (FR) systems have demonstrated outstanding verification
performance, suggesting suitability for real-world applications ranging from
photo tagging in social media to automated border control (ABC). In an advanced
FR system with deep learning-based architecture, however, promoting the
recognition efficiency alone is not sufficient, and the system should also
withstand potential kinds of attacks designed to target its proficiency. Recent
studies show that (deep) FR systems exhibit an intriguing vulnerability to
imperceptible or perceptible but natural-looking adversarial input images that
drive the model to incorrect output predictions. In this article, we present a
comprehensive survey on adversarial attacks against FR systems and elaborate on
the competence of new countermeasures against them. Further, we propose a
taxonomy of existing attack and defense methods based on different criteria. We
compare attack methods on the orientation and attributes and defense approaches
on the category. Finally, we explore the challenges and potential research
direction.
</p>
<a href="http://arxiv.org/abs/2007.11709" target="_blank">arXiv:2007.11709</a> [<a href="http://arxiv.org/pdf/2007.11709" target="_blank">pdf</a>]

<h2>The Salted Kalman Filter: Kalman Filtering on Hybrid Dynamical Systems. (arXiv:2007.12233v2 [cs.RO] UPDATED)</h2>
<h3>Nathan J. Kong, J. Joe Payne, George Council, Aaron M. Johnson</h3>
<p>Many state estimation and control algorithms require knowledge of how
probability distributions propagate through dynamical systems. However, despite
hybrid dynamical systems becoming increasingly important in many fields, there
has been little work on utilizing the knowledge of how probability
distributions map through hybrid transitions. Here, we make use of a
propagation law that employs the saltation matrix (a first-order update to the
sensitivity equation) to create the Salted Kalman Filter (SKF), a natural
extension of the Kalman Filter and Extended Kalman Filter to hybrid dynamical
systems. Away from hybrid events, the SKF is a standard Kalman filter. When a
hybrid event occurs, the saltation matrix plays an analogous role as that of
the system dynamics, subsequently inducing a discrete modification to both the
prediction and update steps. The SKF outperforms a naive variational update -
the Jacobian of the reset map - by having a reduced mean squared error in state
estimation, especially immediately after a hybrid transition event. Compared a
hybrid particle filter, the particle filter outperforms the SKF in mean squared
error only when a large number of particles are used, likely due to a more
accurate accounting of the split distribution near a hybrid transition.
</p>
<a href="http://arxiv.org/abs/2007.12233" target="_blank">arXiv:2007.12233</a> [<a href="http://arxiv.org/pdf/2007.12233" target="_blank">pdf</a>]

<h2>Dynamic Emotion Modeling with Learnable Graphs and Graph Inception Network. (arXiv:2008.02661v2 [cs.CV] UPDATED)</h2>
<h3>A. Shirian, S. Tripathi, T. Guha</h3>
<p>Human emotion is expressed, perceived and captured using a variety of dynamic
data modalities, such as speech (verbal), videos (facial expressions) and
motion sensors (body gestures). We propose a generalized approach to emotion
recognition that can adapt across modalities by modeling dynamic data as
structured graphs. The motivation behind the graph approach is to build compact
models without compromising on performance. To alleviate the problem of optimal
graph construction, we cast this as a joint graph learning and classification
task. To this end, we present the Learnable Graph Inception Network (L-GrIN)
that jointly learns to recognize emotion and to identify the underlying graph
structure in the dynamic data. Our architecture comprises multiple novel
components: a new graph convolution operation, a graph inception layer,
learnable adjacency, and a learnable pooling function that yields a graph-level
embedding. We evaluate the proposed architecture on five benchmark emotion
recognition databases spanning three different modalities (video, audio, motion
capture), where each database captures one of the following emotional cues:
facial expressions, speech and body gestures. We achieve state-of-the-art
performance on all five databases outperforming several competitive baselines
and relevant existing methods. Our graph architecture shows superior
performance with significantly fewer parameters (compared to convolutional or
recurrent neural networks) promising its applicability to resource-constrained
devices.
</p>
<a href="http://arxiv.org/abs/2008.02661" target="_blank">arXiv:2008.02661</a> [<a href="http://arxiv.org/pdf/2008.02661" target="_blank">pdf</a>]

<h2>Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation. (arXiv:2008.07146v3 [cs.LG] UPDATED)</h2>
<h3>Yuta Saito, Shunsuke Aihara, Megumi Matsutani, Yusuke Narita</h3>
<p>Off-policy evaluation (OPE) aims to estimate the performance of hypothetical
policies using data generated by a different policy. Because of its huge
potential impact, there has been growing research interest in OPE. There is,
however, no real-world public dataset that enables the evaluation of OPE,
making its experimental studies unrealistic and irreproducible. With the goal
of enabling realistic and reproducible OPE research, we publicize the Open
Bandit Dataset collected on a large-scale fashion e-commerce platform,
ZOZOTOWN. Our dataset is unique in that it contains a set of multiple logged
bandit feedback datasets collected by running different policies on the same
platform. This enables realistic and reproducible experimental comparisons of
different OPE estimators for the first time. We also develop Python software
called the Open Bandit Pipeline to streamline and standardize the
implementations of bandit algorithms and OPE. Our open data and pipeline will
contribute to the fair and transparent OPE research and help the community
identify fruitful research directions. Finally, we provide extensive benchmark
experiments of existing OPE estimators using our data and pipeline. Our
experiments open up essential challenges and new avenues for future OPE
research. Our pipeline and example data are available at
https://github.com/st-tech/zr-obp.
</p>
<a href="http://arxiv.org/abs/2008.07146" target="_blank">arXiv:2008.07146</a> [<a href="http://arxiv.org/pdf/2008.07146" target="_blank">pdf</a>]

<h2>Feature Clustering for Support Identification in Extreme Regions. (arXiv:2008.07365v2 [stat.ML] UPDATED)</h2>
<h3>Hamid Jalalzai, R&#xe9;mi Leluc</h3>
<p>Understanding the complex structure of multivariate extremes is a major
challenge in various fields from portfolio monitoring and environmental risk
management to insurance. In the framework of multivariate Extreme Value Theory,
a common characterization of extremes' dependence structure is the angular
measure. It is a suitable measure to work in extreme regions as it provides
meaningful insights concerning the subregions where extremes tend to
concentrate their mass. The present paper develops a novel optimization-based
approach to assess the dependence structure of extremes. This support
identification scheme rewrites as estimating clusters of features which best
capture the support of extremes. The dimension reduction technique we provide
is applied to statistical learning tasks such as feature clustering and anomaly
detection. Numerical experiments provide strong empirical evidence of the
relevance of our approach.
</p>
<a href="http://arxiv.org/abs/2008.07365" target="_blank">arXiv:2008.07365</a> [<a href="http://arxiv.org/pdf/2008.07365" target="_blank">pdf</a>]

<h2>Whitening and second order optimization both make information in the dataset unusable during training, and can reduce or prevent generalization. (arXiv:2008.07545v3 [cs.LG] UPDATED)</h2>
<h3>Neha S. Wadia, Daniel Duckworth, Samuel S. Schoenholz, Ethan Dyer, Jascha Sohl-Dickstein</h3>
<p>Machine learning is predicated on the concept of generalization: a model
achieving low error on a sufficiently large training set should also perform
well on novel samples from the same distribution. We show that both data
whitening and second order optimization can harm or entirely prevent
generalization. In general, model training harnesses information contained in
the sample-sample second moment matrix of a dataset. For a general class of
models, namely models with a fully connected first layer, we prove that the
information contained in this matrix is the \emph{only information} which can
be used to generalize. Models trained using whitened data, or with certain
second order optimization schemes, have less access to this information,
resulting in reduced or nonexistent generalization ability. We experimentally
verify these predictions for several architectures, and further demonstrate
that generalization continues to be harmed even when theoretical requirements
are relaxed. However, we also show experimentally that {\em regularized} second
order optimization can provide a practical tradeoff, where training is
accelerated but less information is lost, and generalization can in some
circumstances even improve.
</p>
<a href="http://arxiv.org/abs/2008.07545" target="_blank">arXiv:2008.07545</a> [<a href="http://arxiv.org/pdf/2008.07545" target="_blank">pdf</a>]

<h2>Multi-kernel Passive Stochastic Gradient Algorithms and Transfer Learning. (arXiv:2008.10020v2 [cs.LG] UPDATED)</h2>
<h3>Vikram Krishnamurthy, George Yin</h3>
<p>This paper develops a novel passive stochastic gradient algorithm. In passive
stochastic approximation, the stochastic gradient algorithm does not have
control over the location where noisy gradients of the cost function are
evaluated. Classical passive stochastic gradient algorithms use a kernel that
approximates a Dirac delta to weigh the gradients based on how far they are
evaluated from the desired point. In this paper we construct a multi-kernel
passive stochastic gradient algorithm. The algorithm performs substantially
better in high dimensional problems and incorporates variance reduction. We
analyze the weak convergence of the multi-kernel algorithm and its rate of
convergence. In numerical examples, we study the multi-kernel version of the
passive least mean squares (LMS) algorithm for transfer learning to compare the
performance with the classical passive version.
</p>
<a href="http://arxiv.org/abs/2008.10020" target="_blank">arXiv:2008.10020</a> [<a href="http://arxiv.org/pdf/2008.10020" target="_blank">pdf</a>]

<h2>Path Planning using Neural A* Search. (arXiv:2009.07476v2 [cs.LG] UPDATED)</h2>
<h3>Ryo Yonetani, Tatsunori Taniai, Mohammadamin Barekatain, Mai Nishimura, Asako Kanezaki</h3>
<p>We present Neural A*, a novel data-driven search method for path planning
problems. Despite the recent increasing attention to data-driven path planning,
a machine learning approach to search-based planning is still challenging due
to the discrete nature of search algorithms. In this work, we reformulate a
canonical A* search algorithm to be differentiable and couple it with a
convolutional encoder to form an end-to-end trainable neural network planner.
Neural A* solves a path planning problem by encoding a problem instance to a
guidance map and then performing the differentiable A* search with the guidance
map. By learning to match the search results with ground-truth paths provided
by experts, Neural A* can produce a path consistent with the ground truth
accurately and efficiently. Our extensive experiments confirmed that Neural A*
outperformed state-of-the-art data-driven planners in terms of the search
optimality and efficiency trade-off, and furthermore, successfully predicted
realistic human trajectories by directly performing search-based planning on
natural image inputs.
</p>
<a href="http://arxiv.org/abs/2009.07476" target="_blank">arXiv:2009.07476</a> [<a href="http://arxiv.org/pdf/2009.07476" target="_blank">pdf</a>]

<h2>Reconstructing Actions To Explain Deep Reinforcement Learning. (arXiv:2009.08507v2 [cs.AI] UPDATED)</h2>
<h3>Xuan Chen, Zifan Wang, Yucai Fan, Bonan Jin, Piotr Mardziel, Carlee Joe-Wong, Anupam Datta</h3>
<p>Feature attribution has been a foundational building block for explaining the
input feature importance in supervised learning with Deep Neural Network
(DNNs), but face new challenges when applied to deep Reinforcement Learning
(RL).We propose a new approach to explaining deep RL actions by defining a
class of \emph{action reconstruction} functions that mimic the behavior of a
network in deep RL. This approach allows us to answer more complex
explainability questions than direct application of DNN attribution methods,
which we adapt to \emph{behavior-level attributions} in building our action
reconstructions. It also allows us to define \emph{agreement}, a metric for
quantitatively evaluating the explainability of our methods. Our experiments on
a variety of Atari games suggest that perturbation-based attribution methods
are significantly more suitable in reconstructing actions to explain the deep
RL agent than alternative attribution methods, and show greater
\emph{agreement} than existing explainability work utilizing attention. We
further show that action reconstruction allows us to demonstrate how a deep
agent learns to play Pac-Man game.
</p>
<a href="http://arxiv.org/abs/2009.08507" target="_blank">arXiv:2009.08507</a> [<a href="http://arxiv.org/pdf/2009.08507" target="_blank">pdf</a>]

<h2>Towards Fast, Accurate and Stable 3D Dense Face Alignment. (arXiv:2009.09960v2 [cs.CV] UPDATED)</h2>
<h3>Jianzhu Guo, Xiangyu Zhu, Yang Yang, Fan Yang, Zhen Lei, Stan Z. Li</h3>
<p>Existing methods of 3D dense face alignment mainly concentrate on accuracy,
thus limiting the scope of their practical applications. In this paper, we
propose a novel regression framework named 3DDFA-V2 which makes a balance among
speed, accuracy and stability. Firstly, on the basis of a lightweight backbone,
we propose a meta-joint optimization strategy to dynamically regress a small
set of 3DMM parameters, which greatly enhances speed and accuracy
simultaneously. To further improve the stability on videos, we present a
virtual synthesis method to transform one still image to a short-video which
incorporates in-plane and out-of-plane face moving. On the premise of high
accuracy and stability, 3DDFA-V2 runs at over 50fps on a single CPU core and
outperforms other state-of-the-art heavy models simultaneously. Experiments on
several challenging datasets validate the efficiency of our method. Pre-trained
models and code are available at https://github.com/cleardusk/3DDFA_V2.
</p>
<a href="http://arxiv.org/abs/2009.09960" target="_blank">arXiv:2009.09960</a> [<a href="http://arxiv.org/pdf/2009.09960" target="_blank">pdf</a>]

<h2>A Unifying Review of Deep and Shallow Anomaly Detection. (arXiv:2009.11732v3 [cs.LG] UPDATED)</h2>
<h3>Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, Gr&#xe9;goire Montavon, Wojciech Samek, Marius Kloft, Thomas G. Dietterich, Klaus-Robert M&#xfc;ller</h3>
<p>Deep learning approaches to anomaly detection have recently improved the
state of the art in detection performance on complex datasets such as large
collections of images or text. These results have sparked a renewed interest in
the anomaly detection problem and led to the introduction of a great variety of
new methods. With the emergence of numerous such methods, including approaches
based on generative models, one-class classification, and reconstruction, there
is a growing need to bring methods of this field into a systematic and unified
perspective. In this review we aim to identify the common underlying principles
as well as the assumptions that are often made implicitly by various methods.
In particular, we draw connections between classic 'shallow' and novel deep
approaches and show how this relation might cross-fertilize or extend both
directions. We further provide an empirical assessment of major existing
methods that is enriched by the use of recent explainability techniques, and
present specific worked-through examples together with practical advice.
Finally, we outline critical open challenges and identify specific paths for
future research in anomaly detection.
</p>
<a href="http://arxiv.org/abs/2009.11732" target="_blank">arXiv:2009.11732</a> [<a href="http://arxiv.org/pdf/2009.11732" target="_blank">pdf</a>]

<h2>A Sharp Analysis of Model-based Reinforcement Learning with Self-Play. (arXiv:2010.01604v2 [cs.LG] UPDATED)</h2>
<h3>Qinghua Liu, Tiancheng Yu, Yu Bai, Chi Jin</h3>
<p>Model-based algorithms -- algorithms that explore the environment through
building and utilizing an estimated model -- are widely used in reinforcement
learning practice and theoretically shown to achieve optimal sample efficiency
for single-agent reinforcement learning in Markov Decision Processes (MDPs).
However, for multi-agent reinforcement learning in Markov games, the current
best known sample complexity for model-based algorithms is rather suboptimal
and compares unfavorably against recent model-free approaches. In this paper,
we present a sharp analysis of model-based self-play algorithms for multi-agent
Markov games. We design an algorithm -- Optimistic Nash Value Iteration
(Nash-VI) for two-player zero-sum Markov games that is able to output an
$\epsilon$-approximate Nash policy in $\tilde{\mathcal{O}}(H^3SAB/\epsilon^2)$
episodes of game playing, where $S$ is the number of states, $A,B$ are the
number of actions for the two players respectively, and $H$ is the horizon
length. This significantly improves over the best known model-based guarantee
of $\tilde{\mathcal{O}}(H^4S^2AB/\epsilon^2)$, and is the first that matches
the information-theoretic lower bound $\Omega(H^3S(A+B)/\epsilon^2)$ except for
a $\min\{A,B\}$ factor. In addition, our guarantee compares favorably against
the best known model-free algorithm if $\min \{A,B\}=o(H^3)$, and outputs a
single Markov policy while existing sample-efficient model-free algorithms
output a nested mixture of Markov policies that is in general non-Markov and
rather inconvenient to store and execute. We further adapt our analysis to
designing a provably efficient task-agnostic algorithm for zero-sum Markov
games, and designing the first line of provably sample-efficient algorithms for
multi-player general-sum Markov games.
</p>
<a href="http://arxiv.org/abs/2010.01604" target="_blank">arXiv:2010.01604</a> [<a href="http://arxiv.org/pdf/2010.01604" target="_blank">pdf</a>]

<h2>Towards Generalized and Distributed Privacy-Preserving Representation Learning. (arXiv:2010.01792v3 [cs.LG] UPDATED)</h2>
<h3>Sheikh Shams Azam, Taejin Kim, Seyyedali Hosseinalipour, Christopher Brinton, Carlee Joe-Wong, Saurabh Bagchi</h3>
<p>Privacy-preserving representation learning (PPRL) aims to learn a data
encoding that obfuscates sensitive information and retains target information.
We develop the Exclusion-Inclusion Generative Adversarial Network (EIGAN),
which generalizes existing adversarial PPRL approaches to account for multiple,
potentially overlapping ally and adversary objectives in a dataset. We further
extend EIGAN to the case where the data is distributed and cannot be centrally
aggregated for training due to privacy constraints. In doing so, we introduce
D-EIGAN, the first distributed PPRL method, which decentralizes EIGAN training
based on federated learning with fractional parameter sharing. We theoretically
analyze the convergence of EIGAN and behavior of adversaries under the optimal
EIGAN and D-EIGAN encoders, considering the impact of dependencies among target
and sensitive objectives on the encoder performance. Our experiments
demonstrate the advantages of EIGAN encodings in terms of accuracy, robustness,
and scalability; EIGAN outperforms the previous state-of-the-art in centralized
PPRL by a significant margin (47%). The experiments further reveal that
D-EIGAN's performance is consistent with that of EIGAN under different node
data distributions and is resilient to communication constraints.
</p>
<a href="http://arxiv.org/abs/2010.01792" target="_blank">arXiv:2010.01792</a> [<a href="http://arxiv.org/pdf/2010.01792" target="_blank">pdf</a>]

<h2>Interpretable Machine Learning for COVID-19: An Empirical Study on Severity Prediction Task. (arXiv:2010.02006v5 [cs.LG] UPDATED)</h2>
<h3>Han Wu, Wenjie Ruan, Jiangtao Wang, Dingchang Zheng, Bei Liu, Yayuan Gen, Shaolin Li, Jian Chen, Kunwei Li, Xiangfei Chai, Sumi Helal</h3>
<p>The black-box nature of machine learning models hinders the deployment of
some high-accuracy models in medical diagnosis. It is risky to put one's life
in the hands of models that medical researchers do not fully understand.
However, through model interpretation, black-box models can promptly reveal
significant biomarkers that medical practitioners may have overlooked due to
the surge of infected patients in the COVID-19 pandemic.

This research leverages a database of 92 patients with confirmed SARS-CoV-2
laboratory tests between 18th Jan. 2020 and 5th Mar. 2020, in Zhuhai, China, to
identify biomarkers indicative of severity prediction. Through the
interpretation of four machine learning models, decision tree, random forests,
gradient boosted trees, and neural networks using permutation feature
importance, Partial Dependence Plot (PDP), Individual Conditional Expectation
(ICE), Accumulated Local Effects (ALE), Local Interpretable Model-agnostic
Explanations (LIME), and Shapley Additive Explanation (SHAP), we identify an
increase in N-Terminal pro-Brain Natriuretic Peptide (NTproBNP), C-Reaction
Protein (CRP), and lactic dehydrogenase (LDH), a decrease in lymphocyte (LYM)
is associated with severe infection and an increased risk of death, which is
consistent with recent medical research on COVID-19 and other research using
dedicated models. We further validate our methods on a large open dataset with
5644 confirmed patients from the Hospital Israelita Albert Einstein, at S\~ao
Paulo, Brazil from Kaggle, and unveil leukocytes, eosinophils, and platelets as
three indicative biomarkers for COVID-19.
</p>
<a href="http://arxiv.org/abs/2010.02006" target="_blank">arXiv:2010.02006</a> [<a href="http://arxiv.org/pdf/2010.02006" target="_blank">pdf</a>]

<h2>Specialized federated learning using a mixture of experts. (arXiv:2010.02056v3 [cs.LG] UPDATED)</h2>
<h3>Edvin Listo Zec, Olof Mogren, John Martinsson, Leon Ren&#xe9; S&#xfc;tfeld, Daniel Gillblad</h3>
<p>In federated learning, clients share a global model that has been trained on
decentralized local client data. Although federated learning shows significant
promise as a key approach when data cannot be shared or centralized, current
methods show limited privacy properties and have shortcomings when applied to
common real-world scenarios, especially when client data is heterogeneous. In
this paper, we propose an alternative method to learn a personalized model for
each client in a federated setting, with greater generalization abilities than
previous methods. To achieve this personalization we propose a federated
learning framework using a mixture of experts to combine the specialist nature
of a locally trained model with the generalist knowledge of a global model. We
evaluate our method on a variety of datasets with different levels of data
heterogeneity, and our results show that the mixture of experts model is better
suited as a personalized model for devices in these settings, outperforming
both fine-tuned global models and local specialists.
</p>
<a href="http://arxiv.org/abs/2010.02056" target="_blank">arXiv:2010.02056</a> [<a href="http://arxiv.org/pdf/2010.02056" target="_blank">pdf</a>]

<h2>Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v3 [cs.LG] UPDATED)</h2>
<h3>Colin Wei, Kendrick Shen, Yining Chen, Tengyu Ma</h3>
<p>Self-training algorithms, which train a model to fit pseudolabels predicted
by another previously-learned model, have been very successful for learning
with unlabeled data using neural networks. However, the current theoretical
understanding of self-training only applies to linear models. This work
provides a unified theoretical analysis of self-training with deep networks for
semi-supervised learning, unsupervised domain adaptation, and unsupervised
learning. At the core of our analysis is a simple but realistic ``expansion''
assumption, which states that a low-probability subset of the data must expand
to a neighborhood with large probability relative to the subset. We also assume
that neighborhoods of examples in different classes have minimal overlap. We
prove that under these assumptions, the minimizers of population objectives
based on self-training and input-consistency regularization will achieve high
accuracy with respect to ground-truth labels. By using off-the-shelf
generalization bounds, we immediately convert this result to sample complexity
guarantees for neural nets that are polynomial in the margin and Lipschitzness.
Our results help explain the empirical successes of recently proposed
self-training algorithms which use input consistency regularization.
</p>
<a href="http://arxiv.org/abs/2010.03622" target="_blank">arXiv:2010.03622</a> [<a href="http://arxiv.org/pdf/2010.03622" target="_blank">pdf</a>]

<h2>Online and Distribution-Free Robustness: Regression and Contextual Bandits with Huber Contamination. (arXiv:2010.04157v2 [cs.LG] UPDATED)</h2>
<h3>Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau</h3>
<p>In this work we revisit two classic high-dimensional online learning
problems, namely regression and linear contextual bandits, from the perspective
of adversarial robustness. Existing works in algorithmic robust statistics make
strong distributional assumptions that ensure that the input data is evenly
spread out or comes from a nice generative model. Is it possible to achieve
strong robustness guarantees even without distributional assumptions
altogether, where the sequence of tasks we are asked to solve is adaptively and
adversarially chosen?

We answer this question in the affirmative for both regression and linear
contextual bandits. In fact our algorithms succeed where convex surrogates fail
in the sense that we show strong lower bounds for the existing approaches. Our
approach is based on a novel alternating minimization scheme that interleaves
ordinary least-squares with a semidefinite program for finding appropriate
reweightings of the distribution. Moreover we give extensions of our main
results to infinite dimensional settings where the feature vectors are
represented implicitly via a kernel map.
</p>
<a href="http://arxiv.org/abs/2010.04157" target="_blank">arXiv:2010.04157</a> [<a href="http://arxiv.org/pdf/2010.04157" target="_blank">pdf</a>]

<h2>Accelerate CNNs from Three Dimensions: A Comprehensive Pruning Framework. (arXiv:2010.04879v2 [cs.CV] UPDATED)</h2>
<h3>Wenxiao Wang, Minghao Chen, Shuai Zhao, Long Chen, Jinming Hu, Haifeng Liu, Deng Cai, Xiaofei He, Wei Liu</h3>
<p>Neural network pruning is one of the most popular methods for model
acceleration. Most pruning methods, such as filter-level or layer-level
pruning, prune the model along one single dimension (depth, width, or
resolution) to meet a computational cost requirement. However, such pruning
policy often leads to excessive reduction of that dimension, thus inducing a
huge accuracy loss. To alleviate this issue, we argue that pruning should be
done along three dimensions comprehensively. For this purpose, our pruning
framework formulates pruning as an optimization problem. Specifically, it first
fits the relations between the model's accuracy and depth/width/resolution via
polynomial regression and then maximizes the polynomial to acquire optimal
values for three dimensions. Finally, the model is pruned along three
dimensions accordingly. In this framework, since collecting too much data used
for the regression is very time-costly, we propose two approaches to lower the
cost: (1) specializing the polynomial to ensure an accurate regression even
with less data; (2) employing iterative pruning and fine-tuning to collect data
faster. Extensive experiments show that our algorithm outperforms
state-of-the-art pruning and even NAS-based algorithms.
</p>
<a href="http://arxiv.org/abs/2010.04879" target="_blank">arXiv:2010.04879</a> [<a href="http://arxiv.org/pdf/2010.04879" target="_blank">pdf</a>]

<h2>Scaling Guarantees for Nearest Counterfactual Explanations. (arXiv:2010.04965v2 [cs.LG] UPDATED)</h2>
<h3>Kiarash Mohammadi, Amir-Hossein Karimi, Gilles Barthe, Isabel Valera</h3>
<p>Counterfactual explanations (CFE) are being widely used to explain
algorithmic decisions, especially in consequential decision-making contexts
(e.g., loan approval or pretrial bail). In this context, CFEs aim to provide
individuals affected by an algorithmic decision with the most similar
individual (i.e., nearest individual) with a different outcome. However, while
an increasing number of works propose algorithms to compute CFEs, such
approaches either lack in optimality of distance (i.e., they do not return the
nearest individual) and perfect coverage (i.e., they do not provide a CFE for
all individuals); or they cannot handle complex models, such as neural
networks. In this work, we provide a framework based on Mixed-Integer
Programming (MIP) to compute nearest counterfactual explanations with provable
guarantees and with runtimes comparable to gradient-based approaches. Our
experiments on the Adult, COMPAS, and Credit datasets show that, in contrast
with previous methods, our approach allows for efficiently computing diverse
CFEs with both distance guarantees and perfect coverage.
</p>
<a href="http://arxiv.org/abs/2010.04965" target="_blank">arXiv:2010.04965</a> [<a href="http://arxiv.org/pdf/2010.04965" target="_blank">pdf</a>]

<h2>A Recursive Markov Blanket-Based Approach to Causal Structure Learning. (arXiv:2010.04992v2 [cs.LG] UPDATED)</h2>
<h3>Ehsan Mokhtarian, Sina Akbari, AmirEmad Ghassami, Negar Kiyavash</h3>
<p>Constraint-based methods are one of the main approaches for causal structure
learning. These methods are particularly valued as they are guaranteed to
asymptotically find a structure that is statistically equivalent to the ground
truth. On the other hand, they may require an exponentially large number of
conditional independence (CI) tests in the number of variables of the system.
We propose a novel non-parametric recursive constraint-based method for causal
structure learning that significantly reduces the required number of CI tests
compared to the existing literature. The key idea of the proposed approach is
to recursively use Markov blanket information in order to identify a variable
that can be removed from the set of variables without changing the statistical
dependencies among the remaining variables. We further provide a lower bound on
the number of CI tests required by any constraint-based method. Comparing this
lower bound to our achievable bound demonstrates the efficiency of the proposed
approach. Our experimental results show that the proposed algorithm outperforms
the state of the art both on synthetic and real-world structures.
</p>
<a href="http://arxiv.org/abs/2010.04992" target="_blank">arXiv:2010.04992</a> [<a href="http://arxiv.org/pdf/2010.04992" target="_blank">pdf</a>]

<h2>Robust Fairness under Covariate Shift. (arXiv:2010.05166v3 [cs.LG] UPDATED)</h2>
<h3>Ashkan Rezaei, Anqi Liu, Omid Memarrast, Brian Ziebart</h3>
<p>Making predictions that are fair with regard to protected group membership
(race, gender, age, etc.) has become an important requirement for
classification algorithms. Existing techniques derive a fair model from sampled
labeled data relying on the assumption that training and testing data are
identically and independently drawn (iid) from the same distribution. In
practice, distribution shift can and does occur between training and testing
datasets as the characteristics of individuals interacting with the machine
learning system change. We investigate fairness under covariate shift, a
relaxation of the iid assumption in which the inputs or covariates change while
the conditional label distribution remains the same. We seek fair decisions
under these assumptions on target data with unknown labels. We propose an
approach that obtains the predictor that is robust to the worst-case in terms
of target performance while satisfying target fairness requirements and
matching statistical properties of the source data. We demonstrate the benefits
of our approach on benchmark prediction tasks.
</p>
<a href="http://arxiv.org/abs/2010.05166" target="_blank">arXiv:2010.05166</a> [<a href="http://arxiv.org/pdf/2010.05166" target="_blank">pdf</a>]

<h2>What causes the test error? Going beyond bias-variance via ANOVA. (arXiv:2010.05170v2 [stat.ML] UPDATED)</h2>
<h3>Licong Lin, Edgar Dobriban</h3>
<p>Modern machine learning methods are often overparametrized, allowing
adaptation to the data at a fine level. This can seem puzzling; in the worst
case, such models do not need to generalize. This puzzle inspired a great
amount of work, arguing when overparametrization reduces test error, in a
phenomenon called "double descent". Recent work aimed to understand in greater
depth why overparametrization is helpful for generalization. This leads to
discovering the unimodality of variance as a function of the level of
parametrization, and to decomposing the variance into that arising from label
noise, initialization, and randomness in the training data to understand the
sources of the error.

In this work we develop a deeper understanding of this area. Specifically, we
propose using the analysis of variance (ANOVA) to decompose the variance in the
test error in a symmetric way, for studying the generalization performance of
certain two-layer linear and non-linear networks. The advantage of the analysis
of variance is that it reveals the effects of initialization, label noise, and
training data more clearly than prior approaches. Moreover, we also study the
monotonicity and unimodality of the variance components. While prior work
studied the unimodality of the overall variance, we study the properties of
each term in variance decomposition.

One key insight is that in typical settings, the interaction between training
samples and initialization can dominate the variance; surprisingly being larger
than their marginal effect. Also, we characterize "phase transitions" where the
variance changes from unimodal to monotone. On a technical level, we leverage
advanced deterministic equivalent techniques for Haar random matrices,
that---to our knowledge---have not yet been used in the area. We also verify
our results in numerical simulations and on empirical data examples.
</p>
<a href="http://arxiv.org/abs/2010.05170" target="_blank">arXiv:2010.05170</a> [<a href="http://arxiv.org/pdf/2010.05170" target="_blank">pdf</a>]

<h2>Learning Robust Models Using The Principle of Independent Causal Mechanisms. (arXiv:2010.07167v2 [cs.LG] UPDATED)</h2>
<h3>Jens M&#xfc;ller, Robert Schmier, Lynton Ardizzone, Carsten Rother, Ullrich K&#xf6;the</h3>
<p>Standard supervised learning breaks down under data distribution shift.
However, the principle of independent causal mechanisms (ICM, Peters et al.
(2017)) can turn this weakness into an opportunity: one can take advantage of
distribution shift between different environments during training in order to
obtain more robust models. We propose a new gradient-based learning framework
whose objective function is derived from the ICM principle. We show
theoretically and experimentally that neural networks trained in this framework
focus on relations remaining invariant across environments and ignore unstable
ones. Moreover, we prove that the recovered stable relations correspond to the
true causal mechanisms under certain conditions. In both regression and
classification, the resulting models generalize well to unseen scenarios where
traditionally trained models fail.
</p>
<a href="http://arxiv.org/abs/2010.07167" target="_blank">arXiv:2010.07167</a> [<a href="http://arxiv.org/pdf/2010.07167" target="_blank">pdf</a>]

<h2>Rapid Robust Principal Component Analysis: CUR Accelerated Inexact Low Rank Estimation. (arXiv:2010.07422v3 [stat.ML] UPDATED)</h2>
<h3>HanQin Cai, Keaton Hamm, Longxiu Huang, Jiaqi Li, Tao Wang</h3>
<p>Robust principal component analysis (RPCA) is a widely used tool for
dimension reduction. In this work, we propose a novel non-convex algorithm,
coined Iterated Robust CUR (IRCUR), for solving RPCA problems, which
dramatically improves the computational efficiency in comparison with the
existing algorithms. IRCUR achieves this acceleration by employing CUR
decomposition when updating the low rank component, which allows us to obtain
an accurate low rank approximation via only three small submatrices.
Consequently, IRCUR is able to process only the small submatrices and avoid
expensive computing on the full matrix through the entire algorithm. Numerical
experiments establish the computational advantage of IRCUR over the
state-of-art algorithms on both synthetic and real-world datasets.
</p>
<a href="http://arxiv.org/abs/2010.07422" target="_blank">arXiv:2010.07422</a> [<a href="http://arxiv.org/pdf/2010.07422" target="_blank">pdf</a>]

<h2>Robot Design With Neural Networks, MILP Solvers and Active Learning. (arXiv:2010.09842v4 [cs.AI] UPDATED)</h2>
<h3>Sanjai Narain, Emily Mak, Dana Chee, Todd Huster, Jeremy Cohen, Kishore Pochiraju, Brendan Englot, Niraj K. Jha, Karthik Narayan</h3>
<p>Central to the design of many robot systems and their controllers is solving
a constrained blackbox optimization problem. This paper presents CNMA, a new
method of solving this problem that is conservative in the number of
potentially expensive blackbox function evaluations; allows specifying complex,
even recursive constraints directly rather than as hard-to-design penalty or
barrier functions; and is resilient to the non-termination of function
evaluations. CNMA leverages the ability of neural networks to approximate any
continuous function, their transformation into equivalent mixed integer linear
programs (MILPs) and their optimization subject to constraints with industrial
strength MILP solvers. A new learning-from-failure step guides the learning to
be relevant to solving the constrained optimization problem. Thus, the amount
of learning is orders of magnitude smaller than that needed to learn functions
over their entire domains. CNMA is illustrated with the design of several
robotic systems: wave-energy propelled boat, lunar lander, hexapod, cartpole,
acrobot and parallel parking. These range from 6 real-valued dimensions to 36.
We show that CNMA surpasses the Nelder-Mead, Gaussian and Random Search
optimization methods against the metric of number of function evaluations.
</p>
<a href="http://arxiv.org/abs/2010.09842" target="_blank">arXiv:2010.09842</a> [<a href="http://arxiv.org/pdf/2010.09842" target="_blank">pdf</a>]

<h2>Conditional Mutual Information-Based Generalization Bound for Meta Learning. (arXiv:2010.10886v2 [cs.LG] UPDATED)</h2>
<h3>Arezou Rezazadeh, Sharu Theresa Jose, Giuseppe Durisi, Osvaldo Simeone</h3>
<p>Meta-learning optimizes an inductive bias---typically in the form of the
hyperparameters of a base-learning algorithm---by observing data from a finite
number of related tasks. This paper presents an information-theoretic bound on
the generalization performance of any given meta-learner, which builds on the
conditional mutual information (CMI) framework of Steinke and Zakynthinou
(2020). In the proposed extension to meta-learning, the CMI bound involves a
training \textit{meta-supersample} obtained by first sampling $2N$ independent
tasks from the task environment, and then drawing $2M$ independent training
samples for each sampled task. The meta-training data fed to the meta-learner
is modelled as being obtained by randomly selecting $N$ tasks from the
available $2N$ tasks and $M$ training samples per task from the available $2M$
training samples per task. The resulting bound is explicit in two CMI terms,
which measure the information that the meta-learner output and the base-learner
output provide about which training data are selected, given the entire
meta-supersample. Finally, we present a numerical example that illustrates the
merits of the proposed bound in comparison to prior information-theoretic
bounds for meta-learning.
</p>
<a href="http://arxiv.org/abs/2010.10886" target="_blank">arXiv:2010.10886</a> [<a href="http://arxiv.org/pdf/2010.10886" target="_blank">pdf</a>]

<h2>On the Power of Deep but Naive Partial Label Learning. (arXiv:2010.11600v2 [cs.LG] UPDATED)</h2>
<h3>Junghoon Seo, Joon Suk Huh</h3>
<p>Partial label learning (PLL) is a class of weakly supervised learning where
each training instance consists of a data and a set of candidate labels
containing a unique ground truth label. To tackle this problem, a majority of
current state-of-the-art methods employs either label disambiguation or
averaging strategies. So far, PLL methods without such techniques have been
considered impractical. In this paper, we challenge this view by revealing the
hidden power of the oldest and naivest PLL method when it is instantiated with
deep neural networks. Specifically, we show that, with deep neural networks,
the naive model can achieve competitive performances against the other
state-of-the-art methods, suggesting it as a strong baseline for PLL. We also
address the question of how and why such a naive model works well with deep
neural networks. Our empirical results indicate that deep neural networks
trained on partially labeled examples generalize very well even in the
over-parametrized regime and without label disambiguations or regularizations.
We point out that existing learning theories on PLL are vacuous in the
over-parametrized regime. Hence they cannot explain why the deep naive method
works. We propose an alternative theory on how deep learning generalize in PLL
problems.
</p>
<a href="http://arxiv.org/abs/2010.11600" target="_blank">arXiv:2010.11600</a> [<a href="http://arxiv.org/pdf/2010.11600" target="_blank">pdf</a>]

<h2>Generative Neurosymbolic Machines. (arXiv:2010.12152v2 [cs.LG] UPDATED)</h2>
<h3>Jindong Jiang, Sungjin Ahn</h3>
<p>Reconciling symbolic and distributed representations is a crucial challenge
that can potentially resolve the limitations of current deep learning.
Remarkable advances in this direction have been achieved recently via
generative object-centric representation models. While learning a recognition
model that infers object-centric symbolic representations like bounding boxes
from raw images in an unsupervised way, no such model can provide another
important ability of a generative model, i.e., generating (sampling) according
to the structure of learned world density. In this paper, we propose Generative
Neurosymbolic Machines, a generative model that combines the benefits of
distributed and symbolic representations to support both structured
representations of symbolic components and density-based generation. These two
crucial properties are achieved by a two-layer latent hierarchy with the global
distributed latent for flexible density modeling and the structured symbolic
latent map. To increase the model flexibility in this hierarchical structure,
we also propose the StructDRAW prior. In experiments, we show that the proposed
model significantly outperforms the previous structured representation models
as well as the state-of-the-art non-structured generative models in terms of
both structure accuracy and image generation quality. Our code, datasets, and
trained models are available at https://github.com/JindongJiang/GNM
</p>
<a href="http://arxiv.org/abs/2010.12152" target="_blank">arXiv:2010.12152</a> [<a href="http://arxiv.org/pdf/2010.12152" target="_blank">pdf</a>]

<h2>GraphSpeech: Syntax-Aware Graph Attention Network For Neural Speech Synthesis. (arXiv:2010.12423v2 [cs.LG] UPDATED)</h2>
<h3>Rui Liu, Berrak Sisman, Haizhou Li</h3>
<p>Attention-based end-to-end text-to-speech synthesis (TTS) is superior to
conventional statistical methods in many ways. Transformer-based TTS is one of
such successful implementations. While Transformer TTS models the speech frame
sequence well with a self-attention mechanism, it does not associate input text
with output utterances from a syntactic point of view at sentence level. We
propose a novel neural TTS model, denoted as GraphSpeech, that is formulated
under graph neural network framework. GraphSpeech encodes explicitly the
syntactic relation of input lexical tokens in a sentence, and incorporates such
information to derive syntactically motivated character embeddings for TTS
attention mechanism. Experiments show that GraphSpeech consistently outperforms
the Transformer TTS baseline in terms of spectrum and prosody rendering of
utterances.
</p>
<a href="http://arxiv.org/abs/2010.12423" target="_blank">arXiv:2010.12423</a> [<a href="http://arxiv.org/pdf/2010.12423" target="_blank">pdf</a>]

<h2>Neural Network Approximation: Three Hidden Layers Are Enough. (arXiv:2010.14075v2 [cs.LG] UPDATED)</h2>
<h3>Zuowei Shen, Haizhao Yang, Shijun Zhang</h3>
<p>A three-hidden-layer neural network with super approximation power is
introduced. This network is built with the Floor function ($\lfloor x\rfloor$),
the exponential function ($2^x$), the step function
(${1\hspace{-3.6pt}1}_{x\geq 0}$), or their compositions as the activation
function in each neuron and hence we call such networks as
Floor-Exponential-Step (FLES) networks. For any width hyper-parameter
$N\in\mathbb{N}^+$, it is shown that FLES networks with width $\max\{d,N\}$ and
three hidden layers can uniformly approximate a H\"older continuous function
$f$ on $[0,1]^d$ with an exponential approximation rate $3\lambda
(2\sqrt{d})^{\alpha} 2^{-\alpha N}$, where $\alpha \in(0,1]$ and $\lambda&gt;0$
are the H\"older order and constant, respectively. More generally for an
arbitrary continuous function $f$ on $[0,1]^d$ with a modulus of continuity
$\omega_f(\cdot)$, the constructive approximation rate is
$2\omega_f(2\sqrt{d}){2^{-N}}+\omega_f(2\sqrt{d}\,2^{-N})$. Moreover, we extend
such a result to general continuous functions on a bounded set
$E\subseteq\mathbb{R}^d$. As a consequence, this new class of networks
overcomes the curse of dimensionality in approximation power when the variation
of $\omega_f(r)$ as $r\rightarrow 0$ is moderate (e.g., $\omega_f(r)\lesssim
r^\alpha$ for H\"older continuous functions), since the major term to be
concerned in our approximation rate is essentially $\sqrt{d}$ times a function
of $N$ independent of $d$ within the modulus of continuity. Finally, we extend
our analysis to derive similar approximation results in the $L^p$-norm for
$p\in[1,\infty)$ via replacing Floor-Exponential-Step activation functions by
continuous activation functions.
</p>
<a href="http://arxiv.org/abs/2010.14075" target="_blank">arXiv:2010.14075</a> [<a href="http://arxiv.org/pdf/2010.14075" target="_blank">pdf</a>]

<h2>Online Learning in Unknown Markov Games. (arXiv:2010.15020v2 [cs.LG] UPDATED)</h2>
<h3>Yi Tian, Yuanhao Wang, Tiancheng Yu, Suvrit Sra</h3>
<p>We study online learning in unknown Markov games, a problem that arises in
episodic multi-agent reinforcement learning where the actions of the opponents
are unobservable. We show that in this challenging setting, achieving sublinear
regret against the best response in hindsight is statistically hard. We then
consider a weaker notion of regret by competing with the \emph{minimax value}
of the game, and present an algorithm that achieves a sublinear
$\tilde{\mathcal{O}}(K^{2/3})$ regret after $K$ episodes. This is the first
sublinear regret bound (to our knowledge) for online learning in unknown Markov
games. Importantly, our regret bound is independent of the size of the
opponents' action spaces. As a result, even when the opponents' actions are
fully observable, our regret bound improves upon existing analysis (e.g., (Xie
et al., 2020)) by an exponential factor in the number of opponents.
</p>
<a href="http://arxiv.org/abs/2010.15020" target="_blank">arXiv:2010.15020</a> [<a href="http://arxiv.org/pdf/2010.15020" target="_blank">pdf</a>]

<h2>LandmarkGAN: Synthesizing Faces from Landmarks. (arXiv:2011.00269v2 [cs.CV] UPDATED)</h2>
<h3>Pu Sun, Yuezun Li, Honggang Qi, Siwei Lyu</h3>
<p>Face synthesis is an important problem in computer vision with many
applications. In this work, we describe a new method, namely LandmarkGAN, to
synthesize faces based on facial landmarks as input. Facial landmarks are a
natural, intuitive, and effective representation for facial expressions and
orientations, which are independent from the target's texture or color and
background scene. Our method is able to transform a set of facial landmarks
into new faces of different subjects, while retains the same facial expression
and orientation. Experimental results on face synthesis and reenactments
demonstrate the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2011.00269" target="_blank">arXiv:2011.00269</a> [<a href="http://arxiv.org/pdf/2011.00269" target="_blank">pdf</a>]

<h2>A Survey on Contrastive Self-supervised Learning. (arXiv:2011.00362v3 [cs.CV] UPDATED)</h2>
<h3>Ashish Jaiswal, Ashwin Ramesh Babu, Mohammad Zaki Zadeh, Debapriya Banerjee, Fillia Makedon</h3>
<p>Self-supervised learning has gained popularity because of its ability to
avoid the cost of annotating large-scale datasets. It is capable of adopting
self-defined pseudo labels as supervision and use the learned representations
for several downstream tasks. Specifically, contrastive learning has recently
become a dominant component in self-supervised learning methods for computer
vision, natural language processing (NLP), and other domains. It aims at
embedding augmented versions of the same sample close to each other while
trying to push away embeddings from different samples. This paper provides an
extensive review of self-supervised methods that follow the contrastive
approach. The work explains commonly used pretext tasks in a contrastive
learning setup, followed by different architectures that have been proposed so
far. Next, we have a performance comparison of different methods for multiple
downstream tasks such as image classification, object detection, and action
recognition. Finally, we conclude with the limitations of the current methods
and the need for further techniques and future directions to make substantial
progress.
</p>
<a href="http://arxiv.org/abs/2011.00362" target="_blank">arXiv:2011.00362</a> [<a href="http://arxiv.org/pdf/2011.00362" target="_blank">pdf</a>]

<h2>A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning. (arXiv:2011.00382v3 [cs.LG] UPDATED)</h2>
<h3>Dong-Ki Kim, Miao Liu, Matthew Riemer, Chuangchuang Sun, Marwa Abdulhai, Golnaz Habibi, Sebastian Lopez-Cot, Gerald Tesauro, Jonathan P. How</h3>
<p>A fundamental challenge in multiagent reinforcement learning is to learn
beneficial behaviors in a shared environment with other simultaneously learning
agents. In particular, each agent perceives the environment as effectively
non-stationary due to the changing policies of other agents. Moreover, each
agent is itself constantly learning, leading to natural non-stationarity in the
distribution of experiences encountered. In this paper, we propose a novel
meta-multiagent policy gradient theorem that directly accounts for the
non-stationary policy dynamics inherent to multiagent learning settings. This
is achieved by modeling our gradient updates to consider both an agent's own
non-stationary policy dynamics and the non-stationary policy dynamics of other
agents in the environment. We show that our theoretically grounded approach
provides a general solution to the multiagent learning problem, which
inherently comprises all key aspects of previous state of the art approaches on
this topic. We test our method on a diverse suite of multiagent benchmarks and
demonstrate a more efficient ability to adapt to new agents as they learn than
baseline methods across the full spectrum of mixed incentive, competitive, and
cooperative domains.
</p>
<a href="http://arxiv.org/abs/2011.00382" target="_blank">arXiv:2011.00382</a> [<a href="http://arxiv.org/pdf/2011.00382" target="_blank">pdf</a>]

<h2>Robustness and Diversity Seeking Data-Free Knowledge Distillation. (arXiv:2011.03749v2 [cs.LG] UPDATED)</h2>
<h3>Pengchao Han, Jihong Park, Shiqiang Wang, Yejun Liu</h3>
<p>Knowledge distillation (KD) has enabled remarkable progress in model
compression and knowledge transfer. However, KD requires a large volume of
original data or their representation statistics that are not usually available
in practice. Data-free KD has recently been proposed to resolve this problem,
wherein teacher and student models are fed by a synthetic sample generator
trained from the teacher. Nonetheless, existing data-free KD methods rely on
fine-tuning of weights to balance multiple losses, and ignore the diversity of
generated samples, resulting in limited accuracy and robustness. To overcome
this challenge, we propose robustness and diversity seeking data-free KD
(RDSKD) in this paper. The generator loss function is crafted to produce
samples with high authenticity, class diversity, and inter-sample diversity.
Without real data, the objectives of seeking high sample authenticity and class
diversity often conflict with each other, causing frequent loss fluctuations.
We mitigate this by exponentially penalizing loss increments. With MNIST,
CIFAR-10, and SVHN datasets, our experiments show that RDSKD achieves higher
accuracy with more robustness over different hyperparameter settings, compared
to other data-free KD methods such as DAFL, MSKD, ZSKD, and DeepInversion.
</p>
<a href="http://arxiv.org/abs/2011.03749" target="_blank">arXiv:2011.03749</a> [<a href="http://arxiv.org/pdf/2011.03749" target="_blank">pdf</a>]

<h2>Scaling Wide Residual Networks for Panoptic Segmentation. (arXiv:2011.11675v2 [cs.CV] UPDATED)</h2>
<h3>Liang-Chieh Chen, Huiyu Wang, Siyuan Qiao</h3>
<p>The Wide Residual Networks (Wide-ResNets), a shallow but wide model variant
of the Residual Networks (ResNets) by stacking a small number of residual
blocks with large channel sizes, have demonstrated outstanding performance on
multiple dense prediction tasks. However, since proposed, the Wide-ResNet
architecture has barely evolved over the years. In this work, we revisit its
architecture design for the recent challenging panoptic segmentation task,
which aims to unify semantic segmentation and instance segmentation. A baseline
model is obtained by incorporating the simple and effective
Squeeze-and-Excitation and Switchable Atrous Convolution to the Wide-ResNets.
Its network capacity is further scaled up or down by adjusting the width (i.e.,
channel size) and depth (i.e., number of layers), resulting in a family of
SWideRNets (short for Scaling Wide Residual Networks). We demonstrate that such
a simple scaling scheme, coupled with grid search, identifies several
SWideRNets that significantly advance state-of-the-art performance on panoptic
segmentation datasets in both the fast model regime and strong model regime.
</p>
<a href="http://arxiv.org/abs/2011.11675" target="_blank">arXiv:2011.11675</a> [<a href="http://arxiv.org/pdf/2011.11675" target="_blank">pdf</a>]

<h2>Meshless physics-informed deep learning method for three-dimensional solid mechanics. (arXiv:2012.01547v2 [cs.LG] UPDATED)</h2>
<h3>Diab W. Abueidda, Qiyue Lu, Seid Koric</h3>
<p>Deep learning and the collocation method are merged and used to solve partial
differential equations describing structures' deformation. We have considered
different types of materials: linear elasticity, hyperelasticity (neo-Hookean)
with large deformation, and von Mises plasticity with isotropic and kinematic
hardening. The performance of this deep collocation method (DCM) depends on the
architecture of the neural network and the corresponding hyperparameters. The
presented DCM is meshfree and avoids any spatial discretization, which is
usually needed for the finite element method (FEM). We show that the DCM can
capture the response qualitatively and quantitatively, without the need for any
data generation using other numerical methods such as the FEM. Data generation
usually is the main bottleneck in most data-driven models. The deep learning
model is trained to learn the model's parameters yielding accurate approximate
solutions. Once the model is properly trained, solutions can be obtained almost
instantly at any point in the domain, given its spatial coordinates. Therefore,
the deep collocation method is potentially a promising standalone technique to
solve partial differential equations involved in the deformation of materials
and structural systems as well as other physical phenomena.
</p>
<a href="http://arxiv.org/abs/2012.01547" target="_blank">arXiv:2012.01547</a> [<a href="http://arxiv.org/pdf/2012.01547" target="_blank">pdf</a>]

<h2>Forming Human-Robot Cooperation for Tasks with General Goal using Evolutionary Value Learning. (arXiv:2012.10773v2 [cs.RO] UPDATED)</h2>
<h3>Lingfeng Tao, Michael Bowman, Jiucai Zhang, Xiaoli Zhang</h3>
<p>In human-robot cooperation, the robot cooperates with the human to accomplish
the task together. Existing approaches assume the human has a specific goal
during the cooperation, and the robot infers and acts toward it. However, in
real-world environments, a human usually only has a general goal (e.g., general
direction or area in motion planning) at the beginning of the cooperation which
needs to be clarified to a specific goal (e.g., an exact position) during
cooperation. The specification process is interactive and dynamic, which
depends on the environment and the behavior of the partners. The robot that
does not consider the goal specification process may cause frustration to the
human partner, elongate the time to come to an agreement, and compromise or
fail team performance. We present Evolutionary Value Learning (EVL) approach
which uses a State-based Multivariate Bayesian Inference method to model the
dynamics of goal specification process in HRC, and an Evolutionary Value
Updating method to actively enhance the process of goal specification and
cooperation formation. This enables the robot to simultaneously help the human
to specify the goal and learn a cooperative policy in a Reinforcement Learning
manner. In experiments with real human subjects, the robot equipped with EVL
outperforms existing methods with faster goal specification processes and
better team performance.
</p>
<a href="http://arxiv.org/abs/2012.10773" target="_blank">arXiv:2012.10773</a> [<a href="http://arxiv.org/pdf/2012.10773" target="_blank">pdf</a>]

<h2>LieTransformer: Equivariant self-attention for Lie Groups. (arXiv:2012.10885v2 [cs.LG] UPDATED)</h2>
<h3>Michael Hutchinson, Charline Le Lan, Sheheryar Zaidi, Emilien Dupont, Yee Whye Teh, Hyunjik Kim</h3>
<p>Group equivariant neural networks are used as building blocks of group
invariant neural networks, which have been shown to improve generalisation
performance and data efficiency through principled parameter sharing. Such
works have mostly focused on group equivariant convolutions, building on the
result that group equivariant linear maps are necessarily convolutions. In this
work, we extend the scope of the literature to self-attention, that is emerging
as a prominent building block of deep learning models. We propose the
LieTransformer, an architecture composed of LieSelfAttention layers that are
equivariant to arbitrary Lie groups and their discrete subgroups. We
demonstrate the generality of our approach by showing experimental results that
are competitive to baseline methods on a wide range of tasks: shape counting on
point clouds, molecular property regression and modelling particle trajectories
under Hamiltonian dynamics.
</p>
<a href="http://arxiv.org/abs/2012.10885" target="_blank">arXiv:2012.10885</a> [<a href="http://arxiv.org/pdf/2012.10885" target="_blank">pdf</a>]

<h2>Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud. (arXiv:2012.10921v3 [cs.CV] UPDATED)</h2>
<h3>Mutian Xu, Junhao Zhang, Zhipeng Zhou, Mingye Xu, Xiaojuan Qi, Yu Qiao</h3>
<p>In 2D image processing, some attempts decompose images into high and low
frequency components for describing edge and smooth parts respectively.
Similarly, the contour and flat area of 3D objects, such as the boundary and
seat area of a chair, describe different but also complementary geometries.
However, such investigation is lost in previous deep networks that understand
point clouds by directly treating all points or local patches equally. To solve
this problem, we propose Geometry-Disentangled Attention Network (GDANet).
GDANet introduces Geometry-Disentangle Module to dynamically disentangle point
clouds into the contour and flat part of 3D objects, respectively denoted by
sharp and gentle variation components. Then GDANet exploits Sharp-Gentle
Complementary Attention Module that regards the features from sharp and gentle
variation components as two holistic representations, and pays different
attentions to them while fusing them respectively with original point cloud
features. In this way, our method captures and refines the holistic and
complementary 3D geometric semantics from two distinct disentangled components
to supplement the local information. Extensive experiments on 3D object
classification and segmentation benchmarks demonstrate that GDANet achieves the
state-of-the-arts with fewer parameters. Code is released on
https://github.com/mutianxu/GDANet.
</p>
<a href="http://arxiv.org/abs/2012.10921" target="_blank">arXiv:2012.10921</a> [<a href="http://arxiv.org/pdf/2012.10921" target="_blank">pdf</a>]

<h2>On Success and Simplicity: A Second Look at Transferable Targeted Attacks. (arXiv:2012.11207v2 [cs.LG] UPDATED)</h2>
<h3>Zhengyu Zhao, Zhuoran Liu, Martha Larson</h3>
<p>There is broad consensus among researchers studying adversarial examples that
it is extremely difficult to achieve transferable targeted attacks. Currently,
existing research strives for transferable targeted attacks by resorting to
complex losses and even massive training. In this paper, we take a second look
at transferable targeted attacks and show that their difficulty has been
overestimated due to a blind spot in the conventional evaluation procedures.
Specifically, current work has unreasonably restricted attack optimization to a
few iterations. Here, we show that targeted attacks converge slowly to optimal
transferability and improve considerably when given more iterations. We also
demonstrate that an attack that simply maximizes the target logit performs
surprisingly well, remarkably surpassing more complex losses and even achieving
performance comparable to the state of the art, which requires massive training
with a sophisticated multi-term loss. We provide further validation of our
logit attack in a realistic ensemble setting and in a real-world attack against
the Google Cloud Vision API. The logit attack produces perturbations that
reflect the target semantics, which we demonstrate allows us to create targeted
universal adversarial perturbations without additional training images.
</p>
<a href="http://arxiv.org/abs/2012.11207" target="_blank">arXiv:2012.11207</a> [<a href="http://arxiv.org/pdf/2012.11207" target="_blank">pdf</a>]

<h2>Understanding Frank-Wolfe Adversarial Training. (arXiv:2012.12368v2 [cs.LG] UPDATED)</h2>
<h3>Theodoros Tsiligkaridis, Jay Roberts</h3>
<p>Deep neural networks are easily fooled by small perturbations known as
adversarial attacks. Adversarial Training (AT) is a technique that
approximately solves a robust optimization problem to minimize the worst-case
loss and is widely regarded as the most effective defense against such attacks.
While projected gradient descent (PGD) has received most attention for
approximately solving the inner maximization of AT, Frank-Wolfe (FW)
optimization is projection-free and can be adapted to any $\ell_p$ norm. A
Frank-Wolfe adversarial training approach is presented and is shown to provide
as competitive level of robustness as PGD-AT for a variety of architectures,
attacks, and datasets. Exploiting a representation of the FW attack we are able
to derive the geometric insight that: The larger the $\ell_2$ norm of an
$\ell_\infty$ attack is, the less loss gradient variation there is. It is then
experimentally demonstrated that $\ell_\infty$ attacks against robust models
achieve near the maximal possible $\ell_2$ distortion, providing a new lens
into the specific type of regularization that AT bestows. Using FW optimization
in conjunction with robust models, we are able to generate sparse
human-interpretable counterfactual explanations without relying on expensive
$\ell_1$ projections.
</p>
<a href="http://arxiv.org/abs/2012.12368" target="_blank">arXiv:2012.12368</a> [<a href="http://arxiv.org/pdf/2012.12368" target="_blank">pdf</a>]

<h2>Deep Stock Trading: A Hierarchical Reinforcement Learning Framework for Portfolio Optimization and Order Execution. (arXiv:2012.12620v2 [cs.AI] UPDATED)</h2>
<h3>Rundong Wang, Hongxin Wei, Bo An, Zhouyan Feng, Jun Yao</h3>
<p>Portfolio management via reinforcement learning is at the forefront of
fintech research, which explores how to optimally reallocate a fund into
different financial assets over the long term by trial-and-error. Existing
methods are impractical since they usually assume each reallocation can be
finished immediately and thus ignoring the price slippage as part of the
trading cost. To address these issues, we propose a hierarchical reinforced
stock trading system for portfolio management (HRPM). Concretely, we decompose
the trading process into a hierarchy of portfolio management over trade
execution and train the corresponding policies. The high-level policy gives
portfolio weights at a lower frequency to maximize the long term profit and
invokes the low-level policy to sell or buy the corresponding shares within a
short time window at a higher frequency to minimize the trading cost. We train
two levels of policies via pre-training scheme and iterative training scheme
for data efficiency. Extensive experimental results in the U.S. market and the
China market demonstrate that HRPM achieves significant improvement against
many state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2012.12620" target="_blank">arXiv:2012.12620</a> [<a href="http://arxiv.org/pdf/2012.12620" target="_blank">pdf</a>]

<h2>Exploring Instance-Level Uncertainty for Medical Detection. (arXiv:2012.12880v3 [cs.CV] UPDATED)</h2>
<h3>Jiawei Yang, Yuan Liang, Yao Zhang, Weinan Song, Kun Wang, Lei He</h3>
<p>The ability of deep learning to predict with uncertainty is recognized as key
for its adoption in clinical routines. Moreover, performance gain has been
enabled by modelling uncertainty according to empirical evidence. While
previous work has widely discussed the uncertainty estimation in segmentation
and classification tasks, its application on bounding-box-based detection has
been limited, mainly due to the challenge of bounding box aligning. In this
work, we explore to augment a 2.5D detection CNN with two different
bounding-box-level (or instance-level) uncertainty estimates, i.e., predictive
variance and Monte Carlo (MC) sample variance. Experiments are conducted for
lung nodule detection on LUNA16 dataset, a task where significant semantic
ambiguities can exist between nodules and non-nodules. Results show that our
method improves the evaluating score from 84.57% to 88.86% by utilizing a
combination of both types of variances. Moreover, we show the generated
uncertainty enables superior operating points compared to using the probability
threshold only, and can further boost the performance to 89.52%. Example nodule
detections are visualized to further illustrate the advantages of our method.
</p>
<a href="http://arxiv.org/abs/2012.12880" target="_blank">arXiv:2012.12880</a> [<a href="http://arxiv.org/pdf/2012.12880" target="_blank">pdf</a>]

<h2>High Precision Medicine Bottles Vision Online Inspection System and Classification Based on Multi-Features and Ensemble Learning via Independence Test. (arXiv:2101.01362v2 [cs.CV] UPDATED)</h2>
<h3>Le Ma, Xiaoyue Wu, Zhiwei Li</h3>
<p>To address the problem of online automatic inspection of drug liquid bottles
in production line, an implantable visual inspection system is designed and the
ensemble learning algorithm for detection is proposed based on multi-features
fusion. A tunnel structure is designed for visual inspection system, which
allows bottles inspection to be automated without changing original
</p>
<a href="http://arxiv.org/abs/2101.01362" target="_blank">arXiv:2101.01362</a> [<a href="http://arxiv.org/pdf/2101.01362" target="_blank">pdf</a>]

<h2>A Convergence Theory Towards Practical Over-parameterized Deep Neural Networks. (arXiv:2101.04243v2 [cs.LG] UPDATED)</h2>
<h3>Asaf Noy, Yi Xu, Yonathan Aflalo, Lihi Zelnik-Manor, Rong Jin</h3>
<p>Deep neural networks' remarkable ability to correctly fit training data when
optimized by gradient-based algorithms is yet to be fully understood. Recent
theoretical results explain the convergence for ReLU networks that are wider
than those used in practice by orders of magnitude. In this work, we take a
step towards closing the gap between theory and practice by significantly
improving the known theoretical bounds on both the network width and the
convergence time. We show that convergence to a global minimum is guaranteed
for networks with widths quadratic in the sample size and linear in their depth
at a time logarithmic in both. Our analysis and convergence bounds are derived
via the construction of a surrogate network with fixed activation patterns that
can be transformed at any time to an equivalent ReLU network of a reasonable
size. This construction can be viewed as a novel technique to accelerate
training, while its tight finite-width equivalence to Neural Tangent Kernel
(NTK) suggests it can be utilized to study generalization as well.
</p>
<a href="http://arxiv.org/abs/2101.04243" target="_blank">arXiv:2101.04243</a> [<a href="http://arxiv.org/pdf/2101.04243" target="_blank">pdf</a>]

<h2>MC-LSTM: Mass-Conserving LSTM. (arXiv:2101.05186v2 [cs.LG] UPDATED)</h2>
<h3>Pieter-Jan Hoedt, Frederik Kratzert, Daniel Klotz, Christina Halmich, Markus Holzleitner, Grey Nearing, Sepp Hochreiter, G&#xfc;nter Klambauer</h3>
<p>The success of Convolutional Neural Networks (CNNs) in computer vision is
mainly driven by their strong inductive bias, which is strong enough to allow
CNNs to solve vision-related tasks with random weights, meaning without
learning. Similarly, Long Short-Term Memory (LSTM) has a strong inductive bias
towards storing information over time. However, many real-world systems are
governed by conservation laws, which lead to the redistribution of particular
quantities -- e.g. in physical and economical systems. Our novel
Mass-Conserving LSTM (MC-LSTM) adheres to these conservation laws by extending
the inductive bias of LSTM to model the redistribution of those stored
quantities. MC-LSTMs set a new state-of-the-art for neural arithmetic units at
learning arithmetic operations, such as addition tasks, which have a strong
conservation law, as the sum is constant over time. Further, MC-LSTM is applied
to traffic forecasting, modelling a pendulum, and a large benchmark dataset in
hydrology, where it sets a new state-of-the-art for predicting peak flows. In
the hydrology example, we show that MC-LSTM states correlate with real-world
processes and are therefore interpretable.
</p>
<a href="http://arxiv.org/abs/2101.05186" target="_blank">arXiv:2101.05186</a> [<a href="http://arxiv.org/pdf/2101.05186" target="_blank">pdf</a>]

<h2>Deep Learning for Moving Blockage Prediction using Real Millimeter Wave Measurements. (arXiv:2101.06886v3 [cs.LG] UPDATED)</h2>
<h3>Shunyao Wu, Muhammad Alrabeiah, Andrew Hredzak, Chaitali Chakrabarti, Ahmed Alkhateeb</h3>
<p>Millimeter wave (mmWave) communication is a key component of 5G and beyond.
Harvesting the gains of the large bandwidth and low latency at mmWave systems,
however, is challenged by the sensitivity of mmWave signals to blockages; a
sudden blockage in the line of sight (LOS) link leads to abrupt disconnection,
which affects the reliability of the network. In addition, searching for an
alternative base station to re-establish the link could result in needless
latency overhead. In this paper, we address these challenges collectively by
utilizing machine learning to anticipate dynamic blockages proactively. The
proposed approach sees a machine learning algorithm learning to predict future
blockages by observing what we refer to as the pre-blockage signature. To
evaluate our proposed approach, we build a mmWave communication setup with a
moving blockage and collect a dataset of received power sequences. Simulation
results on a real dataset show that blockage occurrence could be predicted with
more than 85% accuracy and the exact time instance of blockage occurrence can
be obtained with low error. This highlights the potential of the proposed
solution for dynamic blockage prediction and proactive hand-off, which enhances
the reliability and latency of future wireless networks.
</p>
<a href="http://arxiv.org/abs/2101.06886" target="_blank">arXiv:2101.06886</a> [<a href="http://arxiv.org/pdf/2101.06886" target="_blank">pdf</a>]

<h2>What Do Deep Nets Learn? Class-wise Patterns Revealed in the Input Space. (arXiv:2101.06898v2 [cs.CV] UPDATED)</h2>
<h3>Shihao Zhao, Xingjun Ma, Yisen Wang, James Bailey, Bo Li, Yu-Gang Jiang</h3>
<p>Deep neural networks (DNNs) are increasingly deployed in different
applications to achieve state-of-the-art performance. However, they are often
applied as a black box with limited understanding of what knowledge the model
has learned from the data. In this paper, we focus on image classification and
propose a method to visualize and understand the class-wise knowledge
(patterns) learned by DNNs under three different settings including natural,
backdoor and adversarial. Different to existing visualization methods, our
method searches for a single predictive pattern in the pixel space to represent
the knowledge learned by the model for each class. Based on the proposed
method, we show that DNNs trained on natural (clean) data learn abstract shapes
along with some texture, and backdoored models learn a suspicious pattern for
the backdoored class. Interestingly, the phenomenon that DNNs can learn a
single predictive pattern for each class indicates that DNNs can learn a
backdoor even from clean data, and the pattern itself is a backdoor trigger. In
the adversarial setting, we show that adversarially trained models tend to
learn more simplified shape patterns. Our method can serve as a useful tool to
better understand the knowledge learned by DNNs on different datasets under
different settings.
</p>
<a href="http://arxiv.org/abs/2101.06898" target="_blank">arXiv:2101.06898</a> [<a href="http://arxiv.org/pdf/2101.06898" target="_blank">pdf</a>]

<h2>Handling Non-ignorably Missing Features in Electronic Health Records Data Using Importance-Weighted Autoencoders. (arXiv:2101.07357v2 [cs.LG] UPDATED)</h2>
<h3>David K. Lim, Naim U. Rashid, Junier B. Oliva, Joseph G. Ibrahim</h3>
<p>Electronic Health Records (EHRs) are commonly used to investigate
relationships between patient health information and outcomes. Deep learning
methods are emerging as powerful tools to learn such relationships, given the
characteristic high dimension and large sample size of EHR datasets. The
Physionet 2012 Challenge involves an EHR dataset pertaining to 12,000 ICU
patients, where researchers investigated the relationships between clinical
measurements, and in-hospital mortality. However, the prevalence and complexity
of missing data in the Physionet data present significant challenges for the
application of deep learning methods, such as Variational Autoencoders (VAEs).
Although a rich literature exists regarding the treatment of missing data in
traditional statistical models, it is unclear how this extends to deep learning
architectures. To address these issues, we propose a novel extension of VAEs
called Importance-Weighted Autoencoders (IWAEs) to flexibly handle Missing Not
At Random (MNAR) patterns in the Physionet data. Our proposed method models the
missingness mechanism using an embedded neural network, eliminating the need to
specify the exact form of the missingness mechanism a priori. We show that the
use of our method leads to more realistic imputed values relative to the
state-of-the-art, as well as significant differences in fitted downstream
models for mortality.
</p>
<a href="http://arxiv.org/abs/2101.07357" target="_blank">arXiv:2101.07357</a> [<a href="http://arxiv.org/pdf/2101.07357" target="_blank">pdf</a>]

<h2>UPDeT: Universal Multi-agent Reinforcement Learning via Policy Decoupling with Transformers. (arXiv:2101.08001v3 [cs.LG] UPDATED)</h2>
<h3>Siyi Hu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang</h3>
<p>Recent advances in multi-agent reinforcement learning have been largely
limited in training one model from scratch for every new task. The limitation
is due to the restricted model architecture related to fixed input and output
dimensions. This hinders the experience accumulation and transfer of the
learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs
6 multi-agent games). In this paper, we make the first attempt to explore a
universal multi-agent reinforcement learning pipeline, designing one single
architecture to fit tasks with the requirement of different observation and
action configurations. Unlike previous RNN-based models, we utilize a
transformer-based model to generate a flexible policy by decoupling the policy
distribution from the intertwined input observation with an importance weight
measured by the merits of the self-attention mechanism. Compared to a standard
transformer block, the proposed model, named as Universal Policy Decoupling
Transformer (UPDeT), further relaxes the action restriction and makes the
multi-agent task's decision process more explainable. UPDeT is general enough
to be plugged into any multi-agent reinforcement learning pipeline and equip
them with strong generalization abilities that enables the handling of multiple
tasks at a time. Extensive experiments on large-scale SMAC multi-agent
competitive games demonstrate that the proposed UPDeT-based multi-agent
reinforcement learning achieves significant results relative to
state-of-the-art approaches, demonstrating advantageous transfer capability in
terms of both performance and training speed (10 times faster).
</p>
<a href="http://arxiv.org/abs/2101.08001" target="_blank">arXiv:2101.08001</a> [<a href="http://arxiv.org/pdf/2101.08001" target="_blank">pdf</a>]

<h2>Anti-UAV: A Large Multi-Modal Benchmark for UAV Tracking. (arXiv:2101.08466v3 [cs.CV] UPDATED)</h2>
<h3>Nan Jiang, Kuiran Wang, Xiaoke Peng, Xuehui Yu, Qiang Wang, Junliang Xing, Guorong Li, Jian Zhao, Guodong Guo, Zhenjun Han</h3>
<p>Unmanned Aerial Vehicle (UAV) offers lots of applications in both commerce
and recreation. With this, monitoring the operation status of UAVs is crucially
important. In this work, we consider the task of tracking UAVs, providing rich
information such as location and trajectory. To facilitate research on this
topic, we propose a dataset, Anti-UAV, with more than 300 video pairs
containing over 580k manually annotated bounding boxes. The releasing of such a
large-scale dataset could be a useful initial step in research of tracking
UAVs. Furthermore, the advancement of addressing research challenges in
Anti-UAV can help the design of anti-UAV systems, leading to better
surveillance of UAVs. Besides, a novel approach named dual-flow semantic
consistency (DFSC) is proposed for UAV tracking. Modulated by the semantic flow
across video sequences, the tracker learns more robust class-level semantic
information and obtains more discriminative instance-level features.
Experimental results demonstrate that Anti-UAV is very challenging, and the
proposed method can effectively improve the tracker's performance. The Anti-UAV
benchmark and the code of the proposed approach will be publicly available at
https://github.com/ucas-vg/Anti-UAV.
</p>
<a href="http://arxiv.org/abs/2101.08466" target="_blank">arXiv:2101.08466</a> [<a href="http://arxiv.org/pdf/2101.08466" target="_blank">pdf</a>]

<h2>Hessian-Aware Pruning and Optimal Neural Implant. (arXiv:2101.08940v2 [cs.CV] UPDATED)</h2>
<h3>Shixing Yu, Zhewei Yao, Amir Gholami, Zhen Dong, Michael W Mahoney, Kurt Keutzer</h3>
<p>Pruning is an effective method to reduce the memory footprint and FLOPs
associated with neural network models. However, existing structured-pruning
methods often result in significant accuracy degradation for moderate pruning
levels. To address this problem, we introduce a new Hessian Aware Pruning (HAP)
method coupled with a Neural Implant approach that uses second-order
sensitivity as a metric for structured pruning. The basic idea is to prune
insensitive components and to use a Neural Implant for moderately sensitive
components, instead of completely pruning them. For the latter approach, the
moderately sensitive components are replaced with with a low rank implant that
is smaller and less computationally expensive than the original component. We
use the relative Hessian trace to measure sensitivity, as opposed to the
magnitude based sensitivity metric commonly used in the literature. We test HAP
on multiple models on CIFAR-10/ImageNet, and we achieve new state-of-the-art
results. Specifically, HAP achieves 94.3\% accuracy ($&lt;0.1\%$ degradation) on
PreResNet29 (CIFAR-10), with more than 70\% of parameters pruned. Moreover, for
ResNet50 HAP achieves 75.1\% top-1 accuracy (0.5\% degradation) on ImageNet,
after pruning more than half of the parameters. The framework has been open
sourced and available online.
</p>
<a href="http://arxiv.org/abs/2101.08940" target="_blank">arXiv:2101.08940</a> [<a href="http://arxiv.org/pdf/2101.08940" target="_blank">pdf</a>]

<h2>3D Underactuated Bipedal Walking via H-LIP based Gait Synthesis and Stepping Stabilization. (arXiv:2101.09588v2 [cs.RO] UPDATED)</h2>
<h3>Xiaobin Xiong, Aaron Ames</h3>
<p>In this paper, we present a Hybrid-Linear Inverted Pendulum (H-LIP) based
approach for synthesizing and stabilizing 3D underactuated bipedal walking. The
H-LIP model is proposed to capture the essential components of the
underactuated part and actuated part of the robotic walking. The walking gait
of the robot is then synthesized based on the H-LIP. We comprehensively
characterize the periodic orbits of the H-LIP and provably derive their
stepping stabilization. The step-to-step (S2S) dynamics of the H-LIP is then
utilized to approximate the S2S dynamics of the horizontal state of the center
of mass (COM) of the robotic walking, which results in a H-LIP based stepping
controller to provide desired step sizes to stabilize the robotic walking. By
realizing the desired step sizes, the robot achieves dynamic and stable
walking. The approach is evaluated in both simulation and experiment on the 3D
underactuated bipedal robot Cassie, which demonstrate dynamic walking behaviors
with both versatility and robustness.
</p>
<a href="http://arxiv.org/abs/2101.09588" target="_blank">arXiv:2101.09588</a> [<a href="http://arxiv.org/pdf/2101.09588" target="_blank">pdf</a>]

<h2>Learning Synthetic Environments for Reinforcement Learning with Evolution Strategies. (arXiv:2101.09721v3 [cs.LG] UPDATED)</h2>
<h3>Fabio Ferreira, Thomas Nierhoff, Frank Hutter</h3>
<p>This work explores learning agent-agnostic synthetic environments (SEs) for
Reinforcement Learning. SEs act as a proxy for target environments and allow
agents to be trained more efficiently than when directly trained on the target
environment. We formulate this as a bi-level optimization problem and represent
an SE as a neural network. By using Natural Evolution Strategies and a
population of SE parameter vectors, we train agents in the inner loop on
evolving SEs while in the outer loop we use the performance on the target task
as a score for meta-updating the SE population. We show empirically that our
method is capable of learning SEs for two discrete-action-space tasks
(CartPole-v0 and Acrobot-v1) that allow us to train agents more robustly and
with up to 60% fewer steps. Not only do we show in experiments with 4000
evaluations that the SEs are robust against hyperparameter changes such as the
learning rate, batch sizes and network sizes, we also show that SEs trained
with DDQN agents transfer in limited ways to a discrete-action-space version of
TD3 and very well to Dueling DDQN.
</p>
<a href="http://arxiv.org/abs/2101.09721" target="_blank">arXiv:2101.09721</a> [<a href="http://arxiv.org/pdf/2101.09721" target="_blank">pdf</a>]

<h2>Annealed Stein Variational Gradient Descent. (arXiv:2101.09815v2 [cs.LG] UPDATED)</h2>
<h3>Francesco D&#x27;Angelo, Vincent Fortuin</h3>
<p>Particle based optimization algorithms have recently been developed as
sampling methods that iteratively update a set of particles to approximate a
target distribution. In particular Stein variational gradient descent has
gained attention in the approximate inference literature for its flexibility
and accuracy. We empirically explore the ability of this method to sample from
multi-modal distributions and focus on two important issues: (i) the inability
of the particles to escape from local modes and (ii) the inefficacy in
reproducing the density of the different regions. We propose an annealing
schedule to solve these issues and show, through various experiments, how this
simple solution leads to significant improvements in mode coverage, without
invalidating any theoretical properties of the original algorithm.
</p>
<a href="http://arxiv.org/abs/2101.09815" target="_blank">arXiv:2101.09815</a> [<a href="http://arxiv.org/pdf/2101.09815" target="_blank">pdf</a>]

<h2>Complementary Pseudo Labels For Unsupervised Domain Adaptation On Person Re-identification. (arXiv:2101.12521v2 [cs.CV] UPDATED)</h2>
<h3>Hao Feng, Minghao Chen, Jinming Hu, Dong Shen, Haifeng Liu, Deng Cai</h3>
<p>In recent years, supervised person re-identification (re-ID) models have
received increasing studies. However, these models trained on the source domain
always suffer dramatic performance drop when tested on an unseen domain.
Existing methods are primary to use pseudo labels to alleviate this problem.
One of the most successful approaches predicts neighbors of each unlabeled
image and then uses them to train the model. Although the predicted neighbors
are credible, they always miss some hard positive samples, which may hinder the
model from discovering important discriminative information of the unlabeled
domain. In this paper, to complement these low recall neighbor pseudo labels,
we propose a joint learning framework to learn better feature embeddings via
high precision neighbor pseudo labels and high recall group pseudo labels. The
group pseudo labels are generated by transitively merging neighbors of
different samples into a group to achieve higher recall. However, the merging
operation may cause subgroups in the group due to imperfect neighbor
predictions. To utilize these group pseudo labels properly, we propose using a
similarity-aggregating loss to mitigate the influence of these subgroups by
pulling the input sample towards the most similar embeddings. Extensive
experiments on three large-scale datasets demonstrate that our method can
achieve state-of-the-art performance under the unsupervised domain adaptation
re-ID setting.
</p>
<a href="http://arxiv.org/abs/2101.12521" target="_blank">arXiv:2101.12521</a> [<a href="http://arxiv.org/pdf/2101.12521" target="_blank">pdf</a>]

<h2>No-Regret Caching via Online Mirror Descent. (arXiv:2101.12588v3 [cs.LG] UPDATED)</h2>
<h3>Tareq Si Salem, Giovanni Neglia, Stratis Ioannidis</h3>
<p>We study an online caching problem in which requests can be served by a local
cache to avoid retrieval costs from a remote server. The cache can update its
state after a batch of requests and store an arbitrarily small fraction of each
content. We study no-regret algorithms based on Online Mirror Descent (OMD)
strategies. We show that the optimal OMD strategy depends on the request
diversity present in a batch. We also prove that, when the cache must store the
entire content, rather than a fraction, OMD strategies can be coupled with a
randomized rounding scheme that preserves regret guarantees.
</p>
<a href="http://arxiv.org/abs/2101.12588" target="_blank">arXiv:2101.12588</a> [<a href="http://arxiv.org/pdf/2101.12588" target="_blank">pdf</a>]

<h2>NeoRL: A Near Real-World Benchmark for Offline Reinforcement Learning. (arXiv:2102.00714v2 [cs.LG] UPDATED)</h2>
<h3>Rongjun Qin, Songyi Gao, Xingyuan Zhang, Zhen Xu, Shengkai Huang, Zewen Li, Weinan Zhang, Yang Yu</h3>
<p>Offline reinforcement learning (RL) aims at learning a good policy from a
batch of collected data, without extra interactions with the environment during
training. However, current offline RL benchmarks commonly have a large reality
gap, because they involve large datasets collected by highly exploratory
policies, and the trained policy is directly evaluated in the environment. In
real-world situations, running a highly exploratory policy is prohibited to
ensure system safety, the data is commonly very limited, and a trained policy
should be well validated before deployment. In this paper, we present a near
real-world offline RL benchmark, named NeoRL, which contains datasets from
various domains with controlled sizes, and extra test datasets for policy
validation. We evaluate existing offline RL algorithms on NeoRL and argue that
the performance of a policy should also be compared with the deterministic
version of the behavior policy, instead of the dataset reward. The empirical
results demonstrate that the tested offline RL algorithms become less
competitive to the deterministic policy on many datasets, and the offline
policy evaluation hardly helps. The NeoRL suit can be found at
this http URL We hope this work will shed some light on
future research and draw more attention when deploying RL in real-world
systems.
</p>
<a href="http://arxiv.org/abs/2102.00714" target="_blank">arXiv:2102.00714</a> [<a href="http://arxiv.org/pdf/2102.00714" target="_blank">pdf</a>]

<h2>Tight Integration of Feature-Based Relocalization in Monocular Direct Visual Odometry. (arXiv:2102.01191v2 [cs.CV] UPDATED)</h2>
<h3>Mariia Gladkova, Rui Wang, Niclas Zeller, Daniel Cremers</h3>
<p>In this paper we propose a framework for integrating map-based relocalization
into online direct visual odometry. To achieve map-based relocalization for
direct methods, we integrate image features into Direct Sparse Odometry (DSO)
and rely on feature matching to associate online visual odometry (VO) with a
previously built map. The integration of the relocalization poses is threefold.
Firstly, they are treated as pose priors and tightly integrated into the direct
image alignment of the front-end tracking. Secondly, they are also tightly
integrated into the back-end bundle adjustment. An online fusion module is
further proposed to combine relative VO poses and global relocalization poses
in a pose graph to estimate keyframe-wise smooth and globally accurate poses.
We evaluate our method on two multi-weather datasets showing the benefits of
integrating different handcrafted and learned features and demonstrating
promising improvements on camera tracking accuracy.
</p>
<a href="http://arxiv.org/abs/2102.01191" target="_blank">arXiv:2102.01191</a> [<a href="http://arxiv.org/pdf/2102.01191" target="_blank">pdf</a>]

<h2>AURSAD: Universal Robot Screwdriving Anomaly Detection Dataset. (arXiv:2102.01409v2 [cs.LG] UPDATED)</h2>
<h3>B&#x142;a&#x17c;ej Leporowski, Daniella Tola, Casper Hansen, Alexandros Iosifidis</h3>
<p>Screwdriving is one of the most popular industrial processes. As such, it is
increasingly common to automate that procedure by using various robots. Even
though the automation increases the efficiency of the screwdriving process, if
the process is not monitored correctly, faults may occur during operation,
which can impact the effectiveness and quality of assembly. Machine Learning
(ML) has the potential to detect those undesirable events and limit their
impact. In order to do so, first a dataset that fully describes the operation
of an industrial robot performing automated screwdriving must be available.

This report describes a dataset created using a UR3e series robot and OnRobot
Screwdriver. We create different scenarios and introduce 4 types of anomalies
to the process while all available robot and screwdriver sensors are
continuously recorded. The resulting data contains 2042 samples of normal and
anomalous robot operation. Brief ML benchmarks using this data are also
provided, showcasing the data's suitability and potential for further analysis
and experimentation.
</p>
<a href="http://arxiv.org/abs/2102.01409" target="_blank">arXiv:2102.01409</a> [<a href="http://arxiv.org/pdf/2102.01409" target="_blank">pdf</a>]

<h2>Occluded Video Instance Segmentation. (arXiv:2102.01558v3 [cs.CV] UPDATED)</h2>
<h3>Jiyang Qi, Yan Gao, Yao Hu, Xinggang Wang, Xiaoyu Liu, Xiang Bai, Serge Belongie, Alan Yuille, Philip H.S. Torr, Song Bai</h3>
<p>Can our video understanding systems perceive objects when a heavy occlusion
exists in a scene?

To answer this question, we collect a large scale dataset called OVIS for
occluded video instance segmentation, that is, to simultaneously detect,
segment, and track instances in occluded scenes. OVIS consists of 296k
high-quality instance masks from 25 semantic categories, where object
occlusions usually occur. While our human vision systems can understand those
occluded instances by contextual reasoning and association, our experiments
suggest that current video understanding systems are not satisfying. On the
OVIS dataset, the highest AP achieved by state-of-the-art algorithms is only
14.4, which reveals that we are still at a nascent stage for understanding
objects, instances, and videos in a real-world scenario. Moreover, to
complement missing object cues caused by occlusion, we propose a plug-and-play
module called temporal feature calibration. Built upon MaskTrack R-CNN and
SipMask, we report an AP of 15.2 and 15.0 respectively. The OVIS dataset is
released at this http URL , and the project code will be available
soon.
</p>
<a href="http://arxiv.org/abs/2102.01558" target="_blank">arXiv:2102.01558</a> [<a href="http://arxiv.org/pdf/2102.01558" target="_blank">pdf</a>]

<h2>Learning Diverse-Structured Networks for Adversarial Robustness. (arXiv:2102.01886v3 [cs.LG] UPDATED)</h2>
<h3>Xuefeng Du, Jingfeng Zhang, Bo Han, Tongliang Liu, Yu Rong, Gang Niu, Junzhou Huang, Masashi Sugiyama</h3>
<p>In adversarial training (AT), the main focus has been the objective and
optimizer while the model has been less studied, so that the models being used
are still those classic ones in standard training (ST). Classic network
architectures (NAs) are generally worse than searched NAs in ST, which should
be the same in AT. In this paper, we argue that NA and AT cannot be handled
independently, since given a dataset, the optimal NA in ST would be no longer
optimal in AT. That being said, AT is time-consuming itself; if we directly
search NAs in AT over large search spaces, the computation will be practically
infeasible. Thus, we propose a diverse-structured network (DS-Net), to
significantly reduce the size of the search space: instead of low-level
operations, we only consider predefined atomic blocks, where an atomic block is
a time-tested building block like the residual block. There are only a few
atomic blocks and thus we can weight all atomic blocks rather than find the
best one in a searched block of DS-Net, which is an essential trade-off between
exploring diverse structures and exploiting the best structures. Empirical
results demonstrate the advantages of DS-Net, i.e., weighting the atomic
blocks.
</p>
<a href="http://arxiv.org/abs/2102.01886" target="_blank">arXiv:2102.01886</a> [<a href="http://arxiv.org/pdf/2102.01886" target="_blank">pdf</a>]

<h2>A Deep Learning-Based Approach to Extracting Periosteal and Endosteal Contours of Proximal Femur in Quantitative CT Images. (arXiv:2102.01990v2 [cs.CV] UPDATED)</h2>
<h3>Yu Deng, Ling Wang, Chen Zhao, Shaojie Tang, Xiaoguang Cheng, Hong-Wen Deng, Weihua Zhou</h3>
<p>Automatic CT segmentation of proximal femur is crucial for the diagnosis and
risk stratification of orthopedic diseases; however, current methods for the
femur CT segmentation mainly rely on manual interactive segmentation, which is
time-consuming and has limitations in both accuracy and reproducibility. In
this study, we proposed an approach based on deep learning for the automatic
extraction of the periosteal and endosteal contours of proximal femur in order
to differentiate cortical and trabecular bone compartments. A three-dimensional
(3D) end-to-end fully convolutional neural network, which can better combine
the information between neighbor slices and get more accurate segmentation
results, was developed for our segmentation task. 100 subjects aged from 50 to
87 years with 24,399 slices of proximal femur CT images were enrolled in this
study. The separation of cortical and trabecular bone derived from the QCT
software MIAF-Femur was used as the segmentation reference. We randomly divided
the whole dataset into a training set with 85 subjects for 10-fold
cross-validation and a test set with 15 subjects for evaluating the performance
of models. Two models with the same network structures were trained and they
achieved a dice similarity coefficient (DSC) of 97.87% and 96.49% for the
periosteal and endosteal contours, respectively. To verify the excellent
performance of our model for femoral segmentation, we measured the volume of
different parts of the femur and compared it with the ground truth and the
relative errors between predicted result and ground truth are all less than 5%.
It demonstrated a strong potential for clinical use, including the hip fracture
risk prediction and finite element analysis.
</p>
<a href="http://arxiv.org/abs/2102.01990" target="_blank">arXiv:2102.01990</a> [<a href="http://arxiv.org/pdf/2102.01990" target="_blank">pdf</a>]

<h2>Horizontally Fused Training Array: An Effective Hardware Utilization Squeezer for Training Novel Deep Learning Models. (arXiv:2102.02344v2 [cs.LG] UPDATED)</h2>
<h3>Shang Wang, Peiming Yang, Yuxuan Zheng, Xin Li, Gennady Pekhimenko</h3>
<p>Driven by the tremendous effort in researching novel deep learning (DL)
algorithms, the training cost of developing new models increases staggeringly
in recent years. To reduce this training cost and optimize the cluster-wide
hardware resource usage, we analyze GPU cluster usage statistics from a
well-known research institute. Our study reveals that single-accelerator
training jobs can dominate the cluster-wide resource consumption when launched
repetitively (e.g., for hyper-parameter tuning) while severely underutilizing
the hardware. This is because DL researchers and practitioners often lack the
required expertise to independently optimize their own workloads. Fortunately,
we observe that such workloads have the following unique characteristics: (i)
the models among jobs often have the same types of operators with the same
shapes, and (ii) the inter-model horizontal fusion of such operators is
mathematically equivalent to other already well-optimized operators. Thus, to
help DL researchers and practitioners effectively and easily improve the
hardware utilization of their novel DL training workloads, we propose
Horizontally Fused Training Array (HFTA). HFTA is a new DL framework extension
library that horizontally fuses the models from different repetitive jobs
deeply down to operators, and then trains those models simultaneously on a
shared accelerator. On three emerging DL training workloads and
state-of-the-art accelerators (GPUs and TPUs), HFTA demonstrates strong
effectiveness in squeezing out hardware utilization and achieves up to $15.1
\times$ higher training throughput vs. the standard practice of running each
job on a separate accelerator.
</p>
<a href="http://arxiv.org/abs/2102.02344" target="_blank">arXiv:2102.02344</a> [<a href="http://arxiv.org/pdf/2102.02344" target="_blank">pdf</a>]

<h2>MeInGame: Create a Game Character Face from a Single Portrait. (arXiv:2102.02371v2 [cs.CV] UPDATED)</h2>
<h3>Jiangke Lin, Yi Yuan, Zhengxia Zou</h3>
<p>Many deep learning based 3D face reconstruction methods have been proposed
recently, however, few of them have applications in games. Current game
character customization systems either require players to manually adjust
considerable face attributes to obtain the desired face, or have limited
freedom of facial shape and texture. In this paper, we propose an automatic
character face creation method that predicts both facial shape and texture from
a single portrait, and it can be integrated into most existing 3D games.
Although 3D Morphable Face Model (3DMM) based methods can restore accurate 3D
faces from single images, the topology of 3DMM mesh is different from the
meshes used in most games. To acquire fidelity texture, existing methods
require a large amount of face texture data for training, while building such
datasets is time-consuming and laborious. Besides, such a dataset collected
under laboratory conditions may not generalized well to in-the-wild situations.
To tackle these problems, we propose 1) a low-cost facial texture acquisition
method, 2) a shape transfer algorithm that can transform the shape of a 3DMM
mesh to games, and 3) a new pipeline for training 3D game face reconstruction
networks. The proposed method not only can produce detailed and vivid game
characters similar to the input portrait, but can also eliminate the influence
of lighting and occlusions. Experiments show that our method outperforms
state-of-the-art methods used in games.
</p>
<a href="http://arxiv.org/abs/2102.02371" target="_blank">arXiv:2102.02371</a> [<a href="http://arxiv.org/pdf/2102.02371" target="_blank">pdf</a>]

<h2>Adversarial Attacks and Defenses in Physiological Computing: A Systematic Review. (arXiv:2102.02729v2 [cs.LG] UPDATED)</h2>
<h3>Dongrui Wu, Weili Fang, Yi Zhang, Liuqing Yang, Hanbin Luo, Lieyun Ding, Xiaodong Xu, Xiang Yu</h3>
<p>Physiological computing uses human physiological data as system inputs in
real time. It includes, or significantly overlaps with, brain-computer
interfaces, affective computing, adaptive automation, health informatics, and
physiological signal based biometrics. Physiological computing increases the
communication bandwidth from the user to the computer, but is also subject to
various types of adversarial attacks, in which the attacker deliberately
manipulates the training and/or test examples to hijack the machine learning
algorithm output, leading to possibly user confusion, frustration, injury, or
even death. However, the vulnerability of physiological computing systems has
not been paid enough attention to, and there does not exist a comprehensive
review on adversarial attacks to it. This paper fills this gap, by providing a
systematic review on the main research areas of physiological computing,
different types of adversarial attacks and their applications to physiological
computing, and the corresponding defense strategies. We hope this review will
attract more research interests on the vulnerability of physiological computing
systems, and more importantly, defense strategies to make them more secure.
</p>
<a href="http://arxiv.org/abs/2102.02729" target="_blank">arXiv:2102.02729</a> [<a href="http://arxiv.org/pdf/2102.02729" target="_blank">pdf</a>]

<h2>Undecidability of Underfitting in Learning Algorithms. (arXiv:2102.02850v2 [cs.LG] UPDATED)</h2>
<h3>Sonia Sehra, David Flores, George D. Montanez</h3>
<p>Using recent machine learning results that present an information-theoretic
perspective on underfitting and overfitting, we prove that deciding whether an
encodable learning algorithm will always underfit a dataset, even if given
unlimited training time, is undecidable. We discuss the importance of this
result and potential topics for further research, including
information-theoretic and probabilistic strategies for bounding learning
algorithm fit.
</p>
<a href="http://arxiv.org/abs/2102.02850" target="_blank">arXiv:2102.02850</a> [<a href="http://arxiv.org/pdf/2102.02850" target="_blank">pdf</a>]

<h2>Learning High Dimensional Wasserstein Geodesics. (arXiv:2102.02992v2 [cs.LG] UPDATED)</h2>
<h3>Shu Liu, Shaojun Ma, Yongxin Chen, Hongyuan Zha, Haomin Zhou</h3>
<p>We propose a new formulation and learning strategy for computing the
Wasserstein geodesic between two probability distributions in high dimensions.
By applying the method of Lagrange multipliers to the dynamic formulation of
the optimal transport (OT) problem, we derive a minimax problem whose saddle
point is the Wasserstein geodesic. We then parametrize the functions by deep
neural networks and design a sample based bidirectional learning algorithm for
training. The trained networks enable sampling from the Wasserstein geodesic.
As by-products, the algorithm also computes the Wasserstein distance and OT map
between the marginal distributions. We demonstrate the performance of our
algorithms through a series of experiments with both synthetic and realistic
data.
</p>
<a href="http://arxiv.org/abs/2102.02992" target="_blank">arXiv:2102.02992</a> [<a href="http://arxiv.org/pdf/2102.02992" target="_blank">pdf</a>]

<h2>Achieving Explainability for Plant Disease Classification with Disentangled Variational Autoencoders. (arXiv:2102.03082v2 [cs.CV] UPDATED)</h2>
<h3>Harshana Habaragamuwa, Yu Oishi, Kenichi Tanaka</h3>
<p>Agricultural image recognition tasks are becoming increasingly dependent on
deep learning (DL). Despite its excellent performance, it is difficult to
comprehend what type of logic or features DL uses in its decision making. This
has become a roadblock for the implementation and development of DL-based image
recognition methods because knowing the logic or features used in decision
making, such as in a classification task, is very important for verification,
algorithm improvement, training data improvement, knowledge extraction, etc. To
mitigate such problems, we developed a classification method based on a
variational autoencoder architecture that can show not only the location of the
most important features but also what variations of that particular feature are
used. Using the PlantVillage dataset, we achieved an acceptable level of
explainability without sacrificing the accuracy of the classification. Although
the proposed method was tested for disease diagnosis in some crops, the method
can be extended to other crops as well as other image classification tasks. In
the future, we hope to use this explainable artificial intelligence algorithm
in disease identification tasks, such as the identification of potato blackleg
disease and potato virus Y (PVY), and other image classification tasks.
</p>
<a href="http://arxiv.org/abs/2102.03082" target="_blank">arXiv:2102.03082</a> [<a href="http://arxiv.org/pdf/2102.03082" target="_blank">pdf</a>]

<h2>Equivariant message passing for the prediction of tensorial properties and molecular spectra. (arXiv:2102.03150v2 [cs.LG] UPDATED)</h2>
<h3>Kristof T. Sch&#xfc;tt, Oliver T. Unke, Michael Gastegger</h3>
<p>Message passing neural networks have become a method of choice for learning
on graphs, in particular the prediction of chemical properties and the
acceleration of molecular dynamics studies. While they readily scale to large
training data sets, previous approaches have proven to be less data efficient
than kernel methods. We identify limitations of invariant representations as a
major reason and extend the message passing formulation to rotationally
equivariant representations. On this basis, we propose the polarizable atom
interaction neural network (PaiNN) and improve on common molecule benchmarks
over previous networks, while reducing model size and inference time. We
leverage the equivariant atomwise representations obtained by PaiNN for the
prediction of tensorial properties. Finally, we apply this to the simulation of
molecular spectra, achieving speedups of 4-5 orders of magnitude compared to
the electronic structure reference.
</p>
<a href="http://arxiv.org/abs/2102.03150" target="_blank">arXiv:2102.03150</a> [<a href="http://arxiv.org/pdf/2102.03150" target="_blank">pdf</a>]

<h2>Active Slices for Sliced Stein Discrepancy. (arXiv:2102.03159v2 [cs.LG] UPDATED)</h2>
<h3>Wenbo Gong, Kaibo Zhang, Yingzhen Li, Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</h3>
<p>Sliced Stein discrepancy (SSD) and its kernelized variants have demonstrated
promising successes in goodness-of-fit tests and model learning in high
dimensions. Despite their theoretical elegance, their empirical performance
depends crucially on the search of optimal slicing directions to discriminate
between two distributions. Unfortunately, previous gradient-based optimisation
approaches for this task return sub-optimal results: they are computationally
expensive, sensitive to initialization, and they lack theoretical guarantees
for convergence. We address these issues in two steps. First, we provide
theoretical results stating that the requirement of using optimal slicing
directions in the kernelized version of SSD can be relaxed, validating the
resulting discrepancy with finite random slicing directions. Second, given that
good slicing directions are crucial for practical performance, we propose a
fast algorithm for finding such slicing directions based on ideas of active
sub-space construction and spectral decomposition. Experiments on
goodness-of-fit tests and model learning show that our approach achieves both
improved performance and faster convergence. Especially, we demonstrate a
14-80x speed-up in goodness-of-fit tests when comparing with gradient-based
alternatives.
</p>
<a href="http://arxiv.org/abs/2102.03159" target="_blank">arXiv:2102.03159</a> [<a href="http://arxiv.org/pdf/2102.03159" target="_blank">pdf</a>]

<h2>Model Rectification via Unknown Unknowns Extraction from Deployment Samples. (arXiv:2102.04145v1 [cs.LG])</h2>
<h3>Bruno Abrahao, Zheng Wang, Haider Ahmed, Yuchen Zhu</h3>
<p>Model deficiency that results from incomplete training data is a form of
structural blindness that leads to costly errors, oftentimes with high
confidence. During the training of classification tasks, underrepresented
class-conditional distributions that a given hypothesis space can recognize
results in a mismatch between the model and the target space. To mitigate the
consequences of this discrepancy, we propose Random Test Sampling and
Cross-Validation (RTSCV) as a general algorithmic framework that aims to
perform a post-training model rectification at deployment time in a supervised
way. RTSCV extracts unknown unknowns (u.u.s), i.e., examples from the
class-conditional distributions that a classifier is oblivious to, and works in
combination with a diverse family of modern prediction models. RTSCV augments
the training set with a sample of the test set (or deployment data) and uses
this redefined class layout to discover u.u.s via cross-validation, without
relying on active learning or budgeted queries to an oracle. We contribute a
theoretical analysis that establishes performance guarantees based on the
design bases of modern classifiers. Our experimental evaluation demonstrates
RTSCV's effectiveness, using 7 benchmark tabular and computer vision datasets,
by reducing a performance gap as large as 41% from the respective
pre-rectification models. Last we show that RTSCV consistently outperforms
state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2102.04145" target="_blank">arXiv:2102.04145</a> [<a href="http://arxiv.org/pdf/2102.04145" target="_blank">pdf</a>]

<h2>EigenGame Unloaded: When playing games is better than optimizing. (arXiv:2102.04152v1 [stat.ML])</h2>
<h3>Ian Gemp, Brian McWilliams, Claire Vernade, Thore Graepel</h3>
<p>We build on the recently proposed EigenGame that views eigendecomposition as
a competitive game. EigenGame's updates are biased if computed using
minibatches of data, which hinders convergence and more sophisticated
parallelism in the stochastic setting. In this work, we propose an unbiased
stochastic update that is asymptotically equivalent to EigenGame, enjoys
greater parallelism allowing computation on datasets of larger sample sizes,
and outperforms EigenGame in experiments. We present applications to finding
the principal components of massive datasets and performing spectral clustering
of graphs. We analyze and discuss our proposed update in the context of
EigenGame and the shift in perspective from optimization to games.
</p>
<a href="http://arxiv.org/abs/2102.04152" target="_blank">arXiv:2102.04152</a> [<a href="http://arxiv.org/pdf/2102.04152" target="_blank">pdf</a>]

<h2>Efficient Certified Defenses Against Patch Attacks on Image Classifiers. (arXiv:2102.04154v1 [cs.LG])</h2>
<h3>Jan Hendrik Metzen, Maksym Yatsura</h3>
<p>Adversarial patches pose a realistic threat model for physical world attacks
on autonomous systems via their perception component. Autonomous systems in
safety-critical domains such as automated driving should thus contain a
fail-safe fallback component that combines certifiable robustness against
patches with efficient inference while maintaining high performance on clean
inputs. We propose BagCert, a novel combination of model architecture and
certification procedure that allows efficient certification. We derive a loss
that enables end-to-end optimization of certified robustness against patches of
different sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in
43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy
against 5x5 patches.
</p>
<a href="http://arxiv.org/abs/2102.04154" target="_blank">arXiv:2102.04154</a> [<a href="http://arxiv.org/pdf/2102.04154" target="_blank">pdf</a>]

<h2>Contrastive Embeddings for Neural Architectures. (arXiv:2102.04208v1 [cs.LG])</h2>
<h3>Daniel Hesslow, Iacopo Poli</h3>
<p>The performance of algorithms for neural architecture search strongly depends
on the parametrization of the search space. We use contrastive learning to
identify networks across different initializations based on their data
Jacobians, and automatically produce the first architecture embeddings
independent from the parametrization of the search space. Using our contrastive
embeddings, we show that traditional black-box optimization algorithms, without
modification, can reach state-of-the-art performance in Neural Architecture
Search. As our method provides a unified embedding space, we perform for the
first time transfer learning between search spaces. Finally, we show the
evolution of embeddings during training, motivating future studies into using
embeddings at different training stages to gain a deeper understanding of the
networks in a search space.
</p>
<a href="http://arxiv.org/abs/2102.04208" target="_blank">arXiv:2102.04208</a> [<a href="http://arxiv.org/pdf/2102.04208" target="_blank">pdf</a>]

<h2>Concentration of Non-Isotropic Random Tensors with Applications to Learning and Empirical Risk Minimization. (arXiv:2102.04259v1 [stat.ML])</h2>
<h3>Mathieu Even, Laurent Massouli&#xe9;</h3>
<p>Dimension is an inherent bottleneck to some modern learning tasks, where
optimization methods suffer from the size of the data. In this paper, we study
non-isotropic distributions of data and develop tools that aim at reducing
these dimensional costs by a dependency on an effective dimension rather than
the ambient one. Based on non-asymptotic estimates of the metric entropy of
ellipsoids -- that prove to generalize to infinite dimensions -- and on a
chaining argument, our uniform concentration bounds involve an effective
dimension instead of the global dimension, improving over existing results. We
show the importance of taking advantage of non-isotropic properties in learning
problems with the following applications: i) we improve state-of-the-art
results in statistical preconditioning for communication-efficient distributed
optimization, ii) we introduce a non-isotropic randomized smoothing for
non-smooth optimization. Both applications cover a class of functions that
encompasses empirical risk minization (ERM) for linear models.
</p>
<a href="http://arxiv.org/abs/2102.04259" target="_blank">arXiv:2102.04259</a> [<a href="http://arxiv.org/pdf/2102.04259" target="_blank">pdf</a>]

<h2>Constrained Ensemble Langevin Monte Carlo. (arXiv:2102.04279v1 [stat.ML])</h2>
<h3>Zhiyan Ding, Qin Li</h3>
<p>The classical Langevin Monte Carlo method looks for i.i.d. samples from a
target distribution by descending along the gradient of the target
distribution. It is popular partially due to its fast convergence rate.
However, the numerical cost is sometimes high because the gradient can be hard
to obtain. One approach to eliminate the gradient computation is to employ the
concept of "ensemble", where a large number of particles are evolved together
so that the neighboring particles provide gradient information to each other.
In this article, we discuss two algorithms that integrate the ensemble feature
into LMC, and the associated properties. There are two sides of our discovery:

1. By directly surrogating the gradient using the ensemble approximation, we
develop Ensemble Langevin Monte Carlo. We show that this method is unstable due
to a potentially small denominator that induces high variance. We provide a
counterexample to explicitly show this instability.

2. We then change the strategy and enact the ensemble approximation to the
gradient only in a constrained manner, to eliminate the unstable points. The
algorithm is termed Constrained Ensemble Langevin Monte Carlo. We show that,
with a proper tuning, the surrogation takes place often enough to bring the
reasonable numerical saving, while the induced error is still low enough for us
to maintain the fast convergence rate, up to a controllable discretization and
ensemble error.

Such combination of ensemble method and LMC shed light on inventing
gradient-free algorithms that produce i.i.d. samples almost exponentially fast.
</p>
<a href="http://arxiv.org/abs/2102.04279" target="_blank">arXiv:2102.04279</a> [<a href="http://arxiv.org/pdf/2102.04279" target="_blank">pdf</a>]

<h2>Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise. (arXiv:2102.04297v1 [cs.LG])</h2>
<h3>Xingyu Wang, Sewoong Oh, Chang-Han Rhee</h3>
<p>The empirical success of deep learning is often attributed to SGD's
mysterious ability to avoid sharp local minima in the loss landscape, which is
well known to lead to poor generalization. Recently, empirical evidence of
heavy-tailed gradient noise was reported in many deep learning tasks; under the
presence of such heavy-tailed noise, it can be shown that SGD can escape sharp
local minima, providing a partial solution to the mystery. In this work, we
analyze a popular variant of SGD where gradients are truncated above a fixed
threshold. We show that it achieves a stronger notion of avoiding sharp minima;
it can effectively eliminate sharp local minima entirely from its training
trajectory. We characterize the dynamics of truncated SGD driven by
heavy-tailed noises. First, we show that the truncation threshold and width of
the attraction field dictate the order of the first exit time from the
associated local minimum. Moreover, when the objective function satisfies
appropriate structural conditions, we prove that as the learning rate decreases
the dynamics of the heavy-tailed SGD closely resemble that of a special
continuous-time Markov chain which never visits any sharp minima. We verify our
theoretical results with numerical experiments and discuss the implications on
the generalizability of SGD in deep learning.
</p>
<a href="http://arxiv.org/abs/2102.04297" target="_blank">arXiv:2102.04297</a> [<a href="http://arxiv.org/pdf/2102.04297" target="_blank">pdf</a>]

<h2>The Limits of Computation in Solving Equity Trade-Offs in Machine Learning and Justice System Risk Assessment. (arXiv:2102.04342v1 [stat.ML])</h2>
<h3>Jesse Russell</h3>
<p>This paper explores how different ideas of racial equity in machine learning,
in justice settings in particular, can present trade-offs that are difficult to
solve computationally. Machine learning is often used in justice settings to
create risk assessments, which are used to determine interventions, resources,
and punitive actions. Overall aspects and performance of these machine
learning-based tools, such as distributions of scores, outcome rates by levels,
and the frequency of false positives and true positives, can be problematic
when examined by racial group. Models that produce different distributions of
scores or produce a different relationship between level and outcome are
problematic when those scores and levels are directly linked to the restriction
of individual liberty and to the broader context of racial inequity. While
computation can help highlight these aspects, data and computation are unlikely
to solve them. This paper explores where values and mission might have to fill
the spaces computation leaves.
</p>
<a href="http://arxiv.org/abs/2102.04342" target="_blank">arXiv:2102.04342</a> [<a href="http://arxiv.org/pdf/2102.04342" target="_blank">pdf</a>]

<h2>Adversarially Guided Actor-Critic. (arXiv:2102.04376v1 [cs.LG])</h2>
<h3>Yannis Flet-Berliac, Johan Ferret, Olivier Pietquin, Philippe Preux, Matthieu Geist</h3>
<p>Despite definite success in deep reinforcement learning problems,
actor-critic algorithms are still confronted with sample inefficiency in
complex environments, particularly in tasks where efficient exploration is a
bottleneck. These methods consider a policy (the actor) and a value function
(the critic) whose respective losses are built using different motivations and
approaches. This paper introduces a third protagonist: the adversary. While the
adversary mimics the actor by minimizing the KL-divergence between their
respective action distributions, the actor, in addition to learning to solve
the task, tries to differentiate itself from the adversary predictions. This
novel objective stimulates the actor to follow strategies that could not have
been correctly predicted from previous trajectories, making its behavior
innovative in tasks where the reward is extremely rare. Our experimental
analysis shows that the resulting Adversarially Guided Actor-Critic (AGAC)
algorithm leads to more exhaustive exploration. Notably, AGAC outperforms
current state-of-the-art methods on a set of various hard-exploration and
procedurally-generated tasks.
</p>
<a href="http://arxiv.org/abs/2102.04376" target="_blank">arXiv:2102.04376</a> [<a href="http://arxiv.org/pdf/2102.04376" target="_blank">pdf</a>]

<h2>The Optimality of Polynomial Regression for Agnostic Learning under Gaussian Marginals. (arXiv:2102.04401v1 [cs.LG])</h2>
<h3>Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis</h3>
<p>We study the problem of agnostic learning under the Gaussian distribution. We
develop a method for finding hard families of examples for a wide class of
problems by using LP duality. For Boolean-valued concept classes, we show that
the $L^1$-regression algorithm is essentially best possible, and therefore that
the computational difficulty of agnostically learning a concept class is
closely related to the polynomial degree required to approximate any function
from the class in $L^1$-norm. Using this characterization along with additional
analytic tools, we obtain optimal SQ lower bounds for agnostically learning
linear threshold functions and the first non-trivial SQ lower bounds for
polynomial threshold functions and intersections of halfspaces. We also develop
an analogous theory for agnostically learning real-valued functions, and as an
application prove near-optimal SQ lower bounds for agnostically learning ReLUs
and sigmoids.
</p>
<a href="http://arxiv.org/abs/2102.04401" target="_blank">arXiv:2102.04401</a> [<a href="http://arxiv.org/pdf/2102.04401" target="_blank">pdf</a>]

<h2>Analysis of the Effectiveness of Face-Coverings on the Death Rate of COVID-19 Using Machine Learning. (arXiv:2102.04419v1 [stat.ML])</h2>
<h3>Ali Lafzi, Miad Boodaghi, Siavash Zamani, Niyousha Mohammadshafie</h3>
<p>The recent outbreak of the COVID-19 shocked humanity leading to the death of
millions of people worldwide. To stave off the spread of the virus, the
authorities in the US, employed different strategies including the mask mandate
(MM) order issued by the states' governors. Although most of the previous
studies pointed in the direction that MM can be effective in hindering the
spread of viral infections, the effectiveness of MM in reducing the degree of
exposure to the virus and, consequently, death rates remains indeterminate.
Indeed, the extent to which the degree of exposure to COVID-19 takes part in
the lethality of the virus remains unclear. In the current work, we defined a
parameter called the average death ratio as the monthly average of the ratio of
the number of daily deaths to the total number of daily cases. We utilized
survey data provided by New York Times to quantify people's abidance to the MM
order. Additionally, we implicitly addressed the extent to which people abide
by the MM order that may depend on some parameters like population, income, and
political inclination. Using different machine learning classification
algorithms we investigated how the decrease or increase in death ratio for the
counties in the US West Coast correlates with the input parameters. Our results
showed a promising score as high as 0.94 with algorithms like XGBoost, Random
Forest, and Naive Bayes. To verify the model, the best performing algorithms
were then utilized to analyze other states (Arizona, New Jersey, New York and
Texas) as test cases. The findings show an acceptable trend, further confirming
usability of the chosen features for prediction of similar cases.
</p>
<a href="http://arxiv.org/abs/2102.04419" target="_blank">arXiv:2102.04419</a> [<a href="http://arxiv.org/pdf/2102.04419" target="_blank">pdf</a>]

