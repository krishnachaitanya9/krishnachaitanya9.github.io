---
title: Latest Deep Learning Papers
date: 2020-09-27 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>GANs with Variational Entropy Regularizers: Applications in Mitigating the Mode-Collapse Issue. (arXiv:2009.11921v1 [cs.LG])</h2>
<h3>Pirazh Khorramshahi, Hossein Souri, Rama Chellappa, Soheil Feizi</h3>
<p>Building on the success of deep learning, Generative Adversarial Networks
(GANs) provide a modern approach to learn a probability distribution from
observed samples. GANs are often formulated as a zero-sum game between two sets
of functions; the generator and the discriminator. Although GANs have shown
great potentials in learning complex distributions such as images, they often
suffer from the mode collapse issue where the generator fails to capture all
existing modes of the input distribution. As a consequence, the diversity of
generated samples is lower than that of the observed ones. To tackle this
issue, we take an information-theoretic approach and maximize a variational
lower bound on the entropy of the generated samples to increase their
diversity. We call this approach GANs with Variational Entropy Regularizers
(GAN+VER). Existing remedies for the mode collapse issue in GANs can be easily
coupled with our proposed variational entropy regularization. Through extensive
experimentation on standard benchmark datasets, we show all the existing
evaluation metrics highlighting difference of real and generated samples are
significantly improved with GAN+VER.
</p>
<a href="http://arxiv.org/abs/2009.11921">arXiv:2009.11921</a> [<a href="http://arxiv.org/pdf/2009.11921">pdf</a>]

<h2>Event-Driven Receding Horizon Control for Distributed Estimation in Network Systems. (arXiv:2009.11958v1 [eess.SY])</h2>
<h3>Shirantha Welikala, Christos G. Cassandras</h3>
<p>This paper considers the multi-agent persistent monitoring problem defined on
a network (graph) of nodes (targets) with uncertain states. The agent team's
goal is to persistently observe the target states so that an overall measure of
estimation error covariance evaluated over a finite period is minimized. Each
agent's trajectory is fully defined by the sequence of targets it visits and
the corresponding dwell times spent at each visited target. To find the optimal
set of agent trajectories, we propose a distributed and on-line estimation
process that requires each agent to solve a sequence of receding horizon
control problems (RHCPs) in an event-driven manner. We use a novel objective
function form for these RHCPs to optimize the effectiveness of this distributed
estimation process and establish its unimodality under certain conditions.
Moreover, we show how agents can use machine learning to efficiently and
accurately solve a significant portion of each RHCP they face. Finally,
extensive numerical results are provided, indicating significant improvements
compared to other agent control methods.
</p>
<a href="http://arxiv.org/abs/2009.11958">arXiv:2009.11958</a> [<a href="http://arxiv.org/pdf/2009.11958">pdf</a>]

<h2>A physics-informed operator regression framework for extracting data-driven continuum models. (arXiv:2009.11992v1 [physics.comp-ph])</h2>
<h3>Ravi G. Patel, Nathaniel A. Trask, Mitchell A. Wood, Eric C. Cyr</h3>
<p>The application of deep learning toward discovery of data-driven models
requires careful application of inductive biases to obtain a description of
physics which is both accurate and robust. We present here a framework for
discovering continuum models from high fidelity molecular simulation data. Our
approach applies a neural network parameterization of governing physics in
modal space, allowing a characterization of differential operators while
providing structure which may be used to impose biases related to symmetry,
isotropy, and conservation form. We demonstrate the effectiveness of our
framework for a variety of physics, including local and nonlocal diffusion
processes and single and multiphase flows. For the flow physics we demonstrate
this approach leads to a learned operator that generalizes to system
characteristics not included in the training sets, such as variable particle
sizes, densities, and concentration.
</p>
<a href="http://arxiv.org/abs/2009.11992">arXiv:2009.11992</a> [<a href="http://arxiv.org/pdf/2009.11992">pdf</a>]

<h2>Half-Space Proximal Stochastic Gradient Method for Group-Sparsity Regularized Problem. (arXiv:2009.12078v1 [math.OC])</h2>
<h3>Tianyi Chen, Guanyi Wang, Tianyu Ding, Bo Ji, Sheng Yi, Zhihui Zhu</h3>
<p>Optimizing with group-sparsity is significant in enhancing model
interpretation in machining learning applications, e.g., model compression.
However, for large-scale training problems, fast convergence and effective
group-sparsity exploration are hard to achieved simultaneously in stochastic
settings. Particularly, existing state-of-the-art methods, e.g., Prox-SG, RDA,
Prox-SVRG and Prox-Spider, usually generate merely dense solutions. To overcome
this shortage, we propose a novel stochastic method -- Half-Space Proximal
Stochastic Gradient Method (HSProx-SG) to promote the group sparsity of the
solutions and maintain the convergence guarantee. In general, the HSProx-SG
method contains two steps: (i) the proximal stochastic gradient step searches a
near-optimal non-sparse solution estimate; and (ii) the half-space step
substantially boosts the sparsity level. Numerically, HSProx-SG demonstrates
its superiority in both convex settings and non-convex deep neural networks,
e.g., VGG16 and ResNet18, by achieving solutions of much higher group sparsity
and competitive objective values or generalization accuracy.
</p>
<a href="http://arxiv.org/abs/2009.12078">arXiv:2009.12078</a> [<a href="http://arxiv.org/pdf/2009.12078">pdf</a>]

<h2>Spectral Fundamentals and Characterizations of Signed Directed Graphs. (arXiv:2009.12181v1 [math.CO])</h2>
<h3>Pepijn Wissing, Edwin R. van Dam</h3>
<p>The field of signed directed graphs, which is a natural marriage of the
well-known fields concerning signed graphs and directed graphs, has thus far
received little attention. To characterize such signed directed graphs, we
formulate a Hermitian adjacency matrix, whose entries are the unit Eisenstein
integers $\exp(k\pi i/3),$ $k\in \mathbb{Z}_6.$ Many well-known results, such
as (diagonal) switching and eigenvalue interlacing, naturally carry over to
this paradigm. We show that non-empty signed directed graphs whose spectra
occur uniquely, up to isomorphism, do not exist, but we provide several
infinite families whose spectra occur uniquely up to (diagonal) switching
equivalence. Intermediate results include a classification of all signed
digraphs with rank $2,3$, and a deep discussion of signed digraphs with
extremely few (1 or 2) non-negative (eq. non-positive) eigenvalues.
</p>
<a href="http://arxiv.org/abs/2009.12181">arXiv:2009.12181</a> [<a href="http://arxiv.org/pdf/2009.12181">pdf</a>]

<h2>Nonparametric estimation of the fragmentation kernel based on a PDE stationary distribution approximation. (arXiv:1710.09172v3 [math.ST] UPDATED)</h2>
<h3>Van Ha Hoang (1), Thanh Mai Pham Ngoc (2), Vincent Rivoirard (3), Viet Chi Tran (4) ((1) HCMC, (2) LM-Orsay, (3) CEREMADE, (4) LAMA)</h3>
<p>We consider a stochastic individual-based model in continuous time to
describe a size-structured population for cell divisions. This model is
motivated by the detection of cellular aging in biology. We address here the
problem of nonparametric estimation of the kernel ruling the divisions based on
the eigenvalue problem related to the asymptotic behavior in large population.
This inverse problem involves a multiplicative deconvolution operator. Using
Fourier technics we derive a nonparametric estimator whose consistency is
studied. The main difficulty comes from the non-standard equations connecting
the Fourier transforms of the kernel and the parameters of the model. A
numerical study is carried out and we pay special attention to the derivation
of bandwidths by using resampling.
</p>
<a href="http://arxiv.org/abs/1710.09172">arXiv:1710.09172</a> [<a href="http://arxiv.org/pdf/1710.09172">pdf</a>]

<h2>ERM and RERM are optimal estimators for regression problems when malicious outliers corrupt the labels. (arXiv:1910.10923v2 [math.ST] UPDATED)</h2>
<h3>Geoffrey Chinot</h3>
<p>We study Empirical Risk Minimizers (ERM) and Regularized Empirical Risk
Minimizers (RERM) for regression problems with convex and $L$-Lipschitz loss
functions. We consider a setting where $|\cO|$ malicious outliers contaminate
the labels. In that case, under a local Bernstein condition, we show that the
$L_2$-error rate is bounded by $ r_N + AL |\cO|/N$, where $N$ is the total
number of observations, $r_N$ is the $L_2$-error rate in the non-contaminated
setting and $A$ is a parameter coming from the local Bernstein condition. When
$r_N$ is minimax-rate-optimal in a non-contaminated setting, the rate $r_N +
AL|\cO|/N$ is also minimax-rate-optimal when $|\cO|$ outliers contaminate the
label. The main results of the paper can be used for many non-regularized and
regularized procedures under weak assumptions on the noise. We present results
for Huber's M-estimators (without penalization or regularized by the
$\ell_1$-norm) and for general regularized learning problems in reproducible
kernel Hilbert spaces when the noise can be heavy-tailed.
</p>
<a href="http://arxiv.org/abs/1910.10923">arXiv:1910.10923</a> [<a href="http://arxiv.org/pdf/1910.10923">pdf</a>]

<h2>Intelligent Reflecting Surface Aided Multiple Access Over Fading Channels. (arXiv:2006.07090v2 [cs.IT] UPDATED)</h2>
<h3>Yiyu Guo, Zhijin Qin, Yuanwei Liu, Naofal Al-Dhahir</h3>
<p>This paper considers a two-user downlink transmission in intelligent
reflecting surface (IRS) aided network over fading channels. Particularly,
non-orthogonal multiple access (NOMA) and two orthogonal multiple access (OMA)
schemes, namely, time division multiple access (TDMA) and frequency division
multiple access (FDMA), are studied. The objective is to maximize the system
average sum rate for the delay-tolerant transmission. We propose two adjustment
schemes, namely, dynamic phase adjustment and one-time phase adjustment. The
power budget, minimum average data rate, and discrete unit modulus reflection
coefficient are considered as constrains. To solve the problem, two phase
shifters adjustment algorithms with low complexity are proposed to obtain near
optimal solutions. With given phase shifters and satisfaction of time-sharing
condition, the optimal resource allocations are obtained using the Lagrangian
dual decomposition. The numerical results reveal that: i) the average sum rate
of proposed NOMA network aided by IRS outperforms the conventional NOMA network
over fading channels; ii) with continuous IRS adjustment in the fading block,
the proposed TDMA scheme performs better than the FDMA scheme; iii) increasing
the minimum average user rate requirement has less impact on the proposed
IRS-NOMA system than on the IRS-OMA system.
</p>
<a href="http://arxiv.org/abs/2006.07090">arXiv:2006.07090</a> [<a href="http://arxiv.org/pdf/2006.07090">pdf</a>]

<h2>Finite mixture models do not reliably learn the number of components. (arXiv:2007.04470v2 [math.ST] UPDATED)</h2>
<h3>Diana Cai, Trevor Campbell, Tamara Broderick</h3>
<p>Scientists and engineers are often interested in learning the number of
subpopulations (or components) present in a data set. A common suggestion is to
use a finite mixture model (FMM) with a prior on the number of components. Past
work has shown the resulting FMM component-count posterior is consistent; that
is, the posterior concentrates on the true generating number of components. But
existing results crucially depend on the assumption that the component
likelihoods are perfectly specified. In practice, this assumption is
unrealistic, and empirical evidence suggests that the FMM posterior on the
number of components is sensitive to the likelihood choice. In this paper, we
add rigor to data-analysis folk wisdom by proving that under even the slightest
model misspecification, the FMM component-count posterior diverges: the
posterior probability of any particular finite number of latent components
converges to 0 in the limit of infinite data. We illustrate practical
consequences of our theory on simulated and real data sets.
</p>
<a href="http://arxiv.org/abs/2007.04470">arXiv:2007.04470</a> [<a href="http://arxiv.org/pdf/2007.04470">pdf</a>]

<h2>Fast Global Convergence of Natural Policy Gradient Methods with Entropy Regularization. (arXiv:2007.06558v4 [stat.ML] UPDATED)</h2>
<h3>Shicong Cen, Chen Cheng, Yuxin Chen, Yuting Wei, Yuejie Chi</h3>
<p>Natural policy gradient (NPG) methods are among the most widely used policy
optimization algorithms in contemporary reinforcement learning. This class of
methods is often applied in conjunction with entropy regularization -- an
algorithmic scheme that encourages exploration -- and is closely related to
soft policy iteration and trust region policy optimization. Despite the
empirical success, the theoretical underpinnings for NPG methods remain limited
even for the tabular setting. This paper develops $\textit{non-asymptotic}$
convergence guarantees for entropy-regularized NPG methods under softmax
parameterization, focusing on discounted Markov decision processes (MDPs).
Assuming access to exact policy evaluation, we demonstrate that the algorithm
converges linearly -- or even quadratically once it enters a local region
around the optimal policy -- when computing optimal value functions of the
regularized MDP. Moreover, the algorithm is provably stable vis-\`a-vis
inexactness of policy evaluation. Our convergence results accommodate a wide
range of learning rates, and shed light upon the role of entropy regularization
in enabling fast convergence.
</p>
<a href="http://arxiv.org/abs/2007.06558">arXiv:2007.06558</a> [<a href="http://arxiv.org/pdf/2007.06558">pdf</a>]

<h2>Queueing Network Controls via Deep Reinforcement Learning. (arXiv:2008.01644v5 [math.OC] UPDATED)</h2>
<h3>J. G. Dai, Mark Gluzman</h3>
<p>Novel advanced policy gradient (APG) methods, such as Trust Region policy
optimization and Proximal policy optimization (PPO), have become the dominant
reinforcement learning algorithms because of their ease of implementation and
good practical performance. A conventional setup for notoriously difficult
queueing network control problems is a Markov decision problem (MDP) that has
three features: infinite state space, unbounded costs, and long-run average
cost objective. We extend the theoretical framework of these APG methods for
such MDP problems. The resulting PPO algorithm is tested on a parallel-server
system and large-size multiclass queueing networks. The algorithm consistently
generates control policies that outperform state-of-art heuristics in
literature in a variety of load conditions from light to heavy traffic. These
policies are demonstrated to be near-optimal when the optimal policy can be
computed.

A key to the successes of our PPO algorithm is the use of three variance
reduction techniques in estimating the relative value function via sampling.
First, we use a discounted relative value function as an approximation of the
relative value function. Second, we propose regenerative simulation to estimate
the discounted relative value function. Finally, we incorporate the
approximating martingale-process method into the regenerative estimator.
</p>
<a href="http://arxiv.org/abs/2008.01644">arXiv:2008.01644</a> [<a href="http://arxiv.org/pdf/2008.01644">pdf</a>]

<h2>PK-GCN: Prior Knowledge Assisted Image Classification using Graph Convolution Networks. (arXiv:2009.11892v1 [cs.CV])</h2>
<h3>Xueli Xiao, Chunyan Ji, Thosini Bamunu Mudiyanselage, Yi Pan</h3>
<p>Deep learning has gained great success in various classification tasks.
Typically, deep learning models learn underlying features directly from data,
and no underlying relationship between classes are included. Similarity between
classes can influence the performance of classification. In this article, we
propose a method that incorporates class similarity knowledge into
convolutional neural networks models using a graph convolution layer. We
evaluate our method on two benchmark image datasets: MNIST and CIFAR10, and
analyze the results on different data and model sizes. Experimental results
show that our model can improve classification accuracy, especially when the
amount of available data is small.
</p>
<a href="http://arxiv.org/abs/2009.11892">arXiv:2009.11892</a> [<a href="http://arxiv.org/pdf/2009.11892">pdf</a>]

<h2>Bootstrapped Q-learning with Context Relevant Observation Pruning to Generalize in Text-based Games. (arXiv:2009.11896v1 [cs.LG])</h2>
<h3>Subhajit Chaudhury, Daiki Kimura, Kartik Talamadupula, Michiaki Tatsubori, Asim Munawar, Ryuki Tachibana</h3>
<p>We show that Reinforcement Learning (RL) methods for solving Text-Based Games
(TBGs) often fail to generalize on unseen games, especially in small data
regimes. To address this issue, we propose Context Relevant Episodic State
Truncation (CREST) for irrelevant token removal in observation text for
improved generalization. Our method first trains a base model using Q-learning,
which typically overfits the training games. The base model's action token
distribution is used to perform observation pruning that removes irrelevant
tokens. A second bootstrapped model is then retrained on the pruned observation
text. Our bootstrapped agent shows improved generalization in solving unseen
TextWorld games, using 10x-20x fewer training games compared to previous
state-of-the-art methods despite requiring less number of training episodes.
</p>
<a href="http://arxiv.org/abs/2009.11896">arXiv:2009.11896</a> [<a href="http://arxiv.org/pdf/2009.11896">pdf</a>]

<h2>A Comparative Study of Feature Types for Age-Based Text Classification. (arXiv:2009.11898v1 [cs.CL])</h2>
<h3>Anna Glazkova, Yury Egorov, Maksim Glazkov</h3>
<p>The ability to automatically determine the age audience of a novel provides
many opportunities for the development of information retrieval tools. Firstly,
developers of book recommendation systems and electronic libraries may be
interested in filtering texts by the age of the most likely readers. Further,
parents may want to select literature for children. Finally, it will be useful
for writers and publishers to determine which features influence whether the
texts are suitable for children. In this article, we compare the empirical
effectiveness of various types of linguistic features for the task of age-based
classification of fiction texts. For this purpose, we collected a text corpus
of book previews labeled with one of two categories -- children's or adult. We
evaluated the following types of features: readability indices, sentiment,
lexical, grammatical and general features, and publishing attributes. The
results obtained show that the features describing the text at the document
level can significantly increase the quality of machine learning models.
</p>
<a href="http://arxiv.org/abs/2009.11898">arXiv:2009.11898</a> [<a href="http://arxiv.org/pdf/2009.11898">pdf</a>]

<h2>An Incentive-Based Mechanism for Volunteer Computing using Blockchain. (arXiv:2009.11901v1 [cs.CY])</h2>
<h3>Ismaeel Al Ridhawi, Moayad Aloqaily, Yaser Jararweh</h3>
<p>The rise of fast communication media both at the core and at the edge has
resulted in unprecedented numbers of sophisticated and intelligent wireless IoT
devices. Tactile Internet has enabled the interaction between humans and
machines within their environment to achieve revolutionized solutions both on
the move and in real-time. Many applications such as intelligent autonomous
self-driving, smart agriculture and industrial solutions, and self-learning
multimedia content filtering and sharing have become attainable through
cooperative, distributed and decentralized systems, namely, volunteer
computing. This article introduces a blockchain-enabled resource sharing and
service composition solution through volunteer computing. Device resource,
computing, and intelligence capabilities are advertised in the environment to
be made discoverable and available for sharing with the aid of blockchain
technology. Incentives in the form of on-demand service availability are given
to resource and service providers to ensure fair and balanced cooperative
resource usage. Blockchains are formed whenever a service request is initiated
with the aid of fog and mobile edge computing (MEC) devices to ensure secure
communication and service delivery for the participants. Using both volunteer
computing techniques and tactile internet architectures, we devise a fast and
reliable service provisioning framework that relies on a reinforcement learning
technique. Simulation results show that the proposed solution can achieve high
reward distribution, increased number of blockchain formations, reduced delays,
and balanced resource usage among participants, under the premise of high IoT
device availability.
</p>
<a href="http://arxiv.org/abs/2009.11901">arXiv:2009.11901</a> [<a href="http://arxiv.org/pdf/2009.11901">pdf</a>]

<h2>A New Approach for Tactical Decision Making in Lane Changing: Sample Efficient Deep Q Learning with a Safety Feedback Reward. (arXiv:2009.11905v1 [cs.AI])</h2>
<h3>M. Ugur Yavas, N. Kemal Ure, Tufan Kumbasar</h3>
<p>Automated lane change is one of the most challenging task to be solved of
highly automated vehicles due to its safety-critical, uncertain and multi-agent
nature. This paper presents the novel deployment of the state of art Q learning
method, namely Rainbow DQN, that uses a new safety driven rewarding scheme to
tackle the issues in an dynamic and uncertain simulation environment. We
present various comparative results to show that our novel approach of having
reward feedback from the safety layer dramatically increases both the agent's
performance and sample efficiency. Furthermore, through the novel deployment of
Rainbow DQN, it is shown that more intuition about the agent's actions is
extracted by examining the distributions of generated Q values of the agents.
The proposed algorithm shows superior performance to the baseline algorithm in
the challenging scenarios with only 200000 training steps (i.e. equivalent to
55 hours driving).
</p>
<a href="http://arxiv.org/abs/2009.11905">arXiv:2009.11905</a> [<a href="http://arxiv.org/pdf/2009.11905">pdf</a>]

<h2>Adversarial Examples in Deep Learning for Multivariate Time Series Regression. (arXiv:2009.11911v1 [cs.LG])</h2>
<h3>Gautam Raj Mode, Khaza Anuarul Hoque</h3>
<p>Multivariate time series (MTS) regression tasks are common in many real-world
data mining applications including finance, cybersecurity, energy, healthcare,
prognostics, and many others. Due to the tremendous success of deep learning
(DL) algorithms in various domains including image recognition and computer
vision, researchers started adopting these techniques for solving MTS data
mining problems, many of which are targeted for safety-critical and
cost-critical applications. Unfortunately, DL algorithms are known for their
susceptibility to adversarial examples which also makes the DL regression
models for MTS forecasting also vulnerable to those attacks. To the best of our
knowledge, no previous work has explored the vulnerability of DL MTS regression
models to adversarial time series examples, which is an important step,
specifically when the forecasting from such models is used in safety-critical
and cost-critical applications. In this work, we leverage existing adversarial
attack generation techniques from the image classification domain and craft
adversarial multivariate time series examples for three state-of-the-art deep
learning regression models, specifically Convolutional Neural Network (CNN),
Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). We evaluate our
study using Google stock and household power consumption dataset. The obtained
results show that all the evaluated DL regression models are vulnerable to
adversarial attacks, transferable, and thus can lead to catastrophic
consequences in safety-critical and cost-critical domains, such as energy and
finance.
</p>
<a href="http://arxiv.org/abs/2009.11911">arXiv:2009.11911</a> [<a href="http://arxiv.org/pdf/2009.11911">pdf</a>]

<h2>Learning in a Small/Big World. (arXiv:2009.11917v1 [econ.TH])</h2>
<h3>Benson Tsz Kin Leung</h3>
<p>Savage (1972) lays down the foundation of Bayesian decision theory, but
asserts that it is not applicable in big worlds where the environment is
complex. Using the theory of finite automaton to model belief formation, this
paper studies the characteristics of optimal learning behavior in small and big
worlds, where the complexity of the environment is low and high, respectively,
relative to the cognitive ability of the decision maker. Confirming Savage's
claim, optimal learning behavior is closed to Bayesian in small worlds but
significantly different in big worlds. In addition, I show that in big worlds,
the optimal learning behavior could exhibit a wide range of well-documented
non-Bayesian learning behavior, including the use of heuristic, correlation
neglect, persistent over-confidence, inattentive learning, and other behaviors
of model simplification or misspecification. These results establish a clear
and testable relationship between the prominence of non-Bayesian learning
behavior, complexity and cognitive ability.
</p>
<a href="http://arxiv.org/abs/2009.11917">arXiv:2009.11917</a> [<a href="http://arxiv.org/pdf/2009.11917">pdf</a>]

<h2>Image-Based Sorghum Head Counting When You Only Look Once. (arXiv:2009.11929v1 [cs.CV])</h2>
<h3>Lawrence Mosley, Hieu Pham, Yogesh Bansal, Eric hare</h3>
<p>Modern trends in digital agriculture have seen a shift towards artificial
intelligence for crop quality assessment and yield estimation. In this work, we
document how a parameter tuned single-shot object detection algorithm can be
used to identify and count sorghum head from aerial drone images. Our approach
involves a novel exploratory analysis that identified key structural elements
of the sorghum images and motivated the selection of parameter-tuned anchor
boxes that contributed significantly to performance. These insights led to the
development of a deep learning model that outperformed the baseline model and
achieved an out-of-sample mean average precision of 0.95.
</p>
<a href="http://arxiv.org/abs/2009.11929">arXiv:2009.11929</a> [<a href="http://arxiv.org/pdf/2009.11929">pdf</a>]

<h2>A Computer Vision Approach to Combat Lyme Disease. (arXiv:2009.11931v1 [cs.CV])</h2>
<h3>Sina Akbarian, Tania Cawston, Laurent Moreno, Samir Patel, Vanessa Allen, Elham Dolatabadi</h3>
<p>Lyme disease is an infectious disease transmitted to humans by a bite from an
infected Ixodes species (blacklegged ticks). It is one of the fastest growing
vector-borne illness in North America and is expanding its geographic
footprint. Lyme disease treatment is time-sensitive, and can be cured by
administering an antibiotic (prophylaxis) to the patient within 72 hours after
a tick bite by the Ixodes species. However, the laboratory-based identification
of each tick that might carry the bacteria is time-consuming and labour
intensive and cannot meet the maximum turn-around-time of 72 hours for an
effective treatment. Early identification of blacklegged ticks using computer
vision technologies is a potential solution in promptly identifying a tick and
administering prophylaxis within a crucial window period. In this work, we
build an automated detection tool that can differentiate blacklegged ticks from
other ticks species using advanced deep learning and computer vision
approaches. We demonstrate the classification of tick species using Convolution
Neural Network (CNN) models, trained end-to-end from tick images directly.
Advanced knowledge transfer techniques within teacher-student learning
frameworks are adopted to improve the performance of classification of tick
species. Our best CNN model achieves 92% accuracy on test set. The tool can be
integrated with the geography of exposure to determine the risk of Lyme disease
infection and need for prophylaxis treatment.
</p>
<a href="http://arxiv.org/abs/2009.11931">arXiv:2009.11931</a> [<a href="http://arxiv.org/pdf/2009.11931">pdf</a>]

<h2>daVinciNet: Joint Prediction of Motion and Surgical State in Robot-Assisted Surgery. (arXiv:2009.11937v1 [cs.CV])</h2>
<h3>Yidan Qin, Seyedshams Feyzabadi, Max Allan, Joel W. Burdick, Mahdi Azizian</h3>
<p>This paper presents a technique to concurrently and jointly predict the
future trajectories of surgical instruments and the future state(s) of surgical
subtasks in robot-assisted surgeries (RAS) using multiple input sources. Such
predictions are a necessary first step towards shared control and supervised
autonomy of surgical subtasks. Minute-long surgical subtasks, such as suturing
or ultrasound scanning, often have distinguishable tool kinematics and visual
features, and can be described as a series of fine-grained states with
transition schematics. We propose daVinciNet - an end-to-end dual-task model
for robot motion and surgical state predictions. daVinciNet performs concurrent
end-effector trajectory and surgical state predictions using features extracted
from multiple data streams, including robot kinematics, endoscopic vision, and
system events. We evaluate our proposed model on an extended Robotic
Intra-Operative Ultrasound (RIOUS+) imaging dataset collected on a da Vinci Xi
surgical system and the JHU-ISI Gesture and Skill Assessment Working Set
(JIGSAWS). Our model achieves up to 93.85% short-term (0.5s) and 82.11%
long-term (2s) state prediction accuracy, as well as 1.07mm short-term and
5.62mm long-term trajectory prediction error.
</p>
<a href="http://arxiv.org/abs/2009.11937">arXiv:2009.11937</a> [<a href="http://arxiv.org/pdf/2009.11937">pdf</a>]

<h2>Deep Multi-Scale Feature Learning for Defocus Blur Estimation. (arXiv:2009.11939v1 [cs.CV])</h2>
<h3>Ali Karaali, Naomi Harte, Claudio Rosito Jung</h3>
<p>This paper presents an edge-based defocus blur estimation method from a
single defocused image. We first distinguish edges that lie at depth
discontinuities (called depth edges, for which the blur estimate is ambiguous)
from edges that lie at approximately constant depth regions (called pattern
edges, for which the blur estimate is well-defined). Then, we estimate the
defocus blur amount at pattern edges only, and explore an interpolation scheme
based on guided filters that prevents data propagation across the detected
depth edges to obtain a dense blur map with well-defined object boundaries.
Both tasks (edge classification and blur estimation) are performed by deep
convolutional neural networks (CNNs) that share weights to learn meaningful
local features from multi-scale patches centered at edge locations. Experiments
on naturally defocused images show that the proposed method presents
qualitative and quantitative results that outperform state-of-the-art (SOTA)
methods, with a good compromise between running time and accuracy.
</p>
<a href="http://arxiv.org/abs/2009.11939">arXiv:2009.11939</a> [<a href="http://arxiv.org/pdf/2009.11939">pdf</a>]

<h2>Online Learning With Adaptive Rebalancing in Nonstationary Environments. (arXiv:2009.11942v1 [cs.LG])</h2>
<h3>Kleanthis Malialis, Christos G. Panayiotou, Marios M. Polycarpou</h3>
<p>An enormous and ever-growing volume of data is nowadays becoming available in
a sequential fashion in various real-world applications. Learning in
nonstationary environments constitutes a major challenge, and this problem
becomes orders of magnitude more complex in the presence of class imbalance. We
provide new insights into learning from nonstationary and imbalanced data in
online learning, a largely unexplored area. We propose the novel Adaptive
REBAlancing (AREBA) algorithm that selectively includes in the training set a
subset of the majority and minority examples that appeared so far, while at its
heart lies an adaptive mechanism to continually maintain the class balance
between the selected examples. We compare AREBA with strong baselines and other
state-of-the-art algorithms and perform extensive experimental work in
scenarios with various class imbalance rates and different concept drift types
on both synthetic and real-world data. AREBA significantly outperforms the rest
with respect to both learning speed and learning quality. Our code is made
publicly available to the scientific community.
</p>
<a href="http://arxiv.org/abs/2009.11942">arXiv:2009.11942</a> [<a href="http://arxiv.org/pdf/2009.11942">pdf</a>]

<h2>N-BEATS neural network for mid-term electricity load forecasting. (arXiv:2009.11961v1 [cs.LG])</h2>
<h3>Boris N. Oreshkin, Grzegorz Dudek, Pawe&#x142; Pe&#x142;ka</h3>
<p>We address the mid-term electricity load forecasting (MTLF) problem. This
problem is relevant and challenging. On the one hand, MTLF supports high-level
(e.g. country level) decision-making at distant planning horizons (e.g. month,
quarter, year). Therefore, financial impact of associated decisions may be
significant and it is desirable that they be made based on accurate forecasts.
On the other hand, the country level monthly time-series typically associated
with MTLF are very complex and stochastic -- including trends, seasonality and
significant random fluctuations. In this paper we show that our proposed deep
neural network modelling approach based on the N-BEATS neural architecture is
very effective at solving MTLF problem. N-BEATS has high expressive power to
solve non-linear stochastic forecasting problems. At the same time, it is
simple to implement and train, it does not require signal preprocessing. We
compare our approach against the set of ten baseline methods, including
classical statistical methods, machine learning and hybrid approaches on 35
monthly electricity demand time series for European countries. We show that in
terms of the MAPE error metric our method provides statistically significant
relative gain of 25% with respect to the classical statistical methods, 28%
with respect to classical machine learning methods and 14% with respect to the
advanced state-of-the-art hybrid methods combining machine learning and
statistical approaches.
</p>
<a href="http://arxiv.org/abs/2009.11961">arXiv:2009.11961</a> [<a href="http://arxiv.org/pdf/2009.11961">pdf</a>]

<h2>Bayesian Topological Learning for Classifying the Structure of Biological Networks. (arXiv:2009.11974v1 [stat.ML])</h2>
<h3>Vasileios Maroulas, Cassie Putman Micucci, Farzana Nasrin</h3>
<p>Actin cytoskeleton networks generate local topological signatures due to the
natural variations in the number, size, and shape of holes of the networks.
Persistent homology is a method that explores these topological properties of
data and summarizes them as persistence diagrams. In this work, we analyze and
classify these filament networks by transforming them into persistence diagrams
whose variability is quantified via a Bayesian framework on the space of
persistence diagrams. The proposed generalized Bayesian framework adopts an
independent and identically distributed cluster point process characterization
of persistence diagrams and relies on a substitution likelihood argument. This
framework provides the flexibility to estimate the posterior cardinality
distribution of points in a persistence diagram and the posterior spatial
distribution simultaneously. We present a closed form of the posteriors under
the assumption of Gaussian mixtures and binomials for prior intensity and
cardinality respectively. Using this posterior calculation, we implement a
Bayes factor algorithm to classify the actin filament networks and benchmark it
against several state-of-the-art classification methods.
</p>
<a href="http://arxiv.org/abs/2009.11974">arXiv:2009.11974</a> [<a href="http://arxiv.org/pdf/2009.11974">pdf</a>]

<h2>An original framework for Wheat Head Detection using Deep, Semi-supervised and Ensemble Learning within Global Wheat Head Detection (GWHD) Dataset. (arXiv:2009.11977v1 [cs.CV])</h2>
<h3>Fares Fourati, Wided Souidene, Rabah Attia</h3>
<p>In this paper, we propose an original object detection methodology applied to
Global Wheat Head Detection (GWHD) Dataset. We have been through two major
architectures of object detection which are FasterRCNN and EfficientDet, in
order to design a novel and robust wheat head detection model. We emphasize on
optimizing the performance of our proposed final architectures. Furthermore, we
have been through an extensive exploratory data analysis and adapted best data
augmentation techniques to our context. We use semi supervised learning to
boost previous supervised models of object detection. Moreover, we put much
effort on ensemble to achieve higher performance. Finally we use specific
post-processing techniques to optimize our wheat head detection results. Our
results have been submitted to solve a research challenge launched on the GWHD
Dataset which is led by nine research institutes from seven countries. Our
proposed method was ranked within the top 6% in the above mentioned challenge.
</p>
<a href="http://arxiv.org/abs/2009.11977">arXiv:2009.11977</a> [<a href="http://arxiv.org/pdf/2009.11977">pdf</a>]

<h2>Going to Extremes: Weakly Supervised Medical Image Segmentation. (arXiv:2009.11988v1 [cs.CV])</h2>
<h3>Holger R Roth, Dong Yang, Ziyue Xu, Xiaosong Wang, Daguang Xu</h3>
<p>Medical image annotation is a major hurdle for developing precise and robust
machine learning models. Annotation is expensive, time-consuming, and often
requires expert knowledge, particularly in the medical field. Here, we suggest
using minimal user interaction in the form of extreme point clicks to train a
segmentation model which, in effect, can be used to speed up medical image
annotation. An initial segmentation is generated based on the extreme points
utilizing the random walker algorithm. This initial segmentation is then used
as a noisy supervision signal to train a fully convolutional network that can
segment the organ of interest, based on the provided user clicks. Through
experimentation on several medical imaging datasets, we show that the
predictions of the network can be refined using several rounds of training with
the prediction from the same weakly annotated data. Further improvements are
shown utilizing the clicked points within a custom-designed loss and attention
mechanism. Our approach has the potential to speed up the process of generating
new training datasets for the development of new machine learning and deep
learning-based models for, but not exclusively, medical image analysis.
</p>
<a href="http://arxiv.org/abs/2009.11988">arXiv:2009.11988</a> [<a href="http://arxiv.org/pdf/2009.11988">pdf</a>]

<h2>Continual Model-Based Reinforcement Learning with Hypernetworks. (arXiv:2009.11997v1 [cs.LG])</h2>
<h3>Yizhou Huang, Kevin Xie, Homanga Bharadhwaj, Florian Shkurti</h3>
<p>Effective planning in model-based reinforcement learning (MBRL) and
model-predictive control (MPC) relies on the accuracy of the learned dynamics
model. In many instances of MBRL and MPC, this model is assumed to be
stationary and is periodically re-trained from scratch on state transition
experience collected from the beginning of environment interactions. This
implies that the time required to train the dynamics model - and the pause
required between plan executions - grows linearly with the size of the
collected experience. We argue that this is too slow for lifelong robot
learning and propose HyperCRL, a method that continually learns the encountered
dynamics in a sequence of tasks using task-conditional hypernetworks. Our
method has three main attributes: first, it enables constant-time dynamics
learning sessions between planning and only needs to store the most recent
fixed-size portion of the state transition experience; second, it uses
fixed-capacity hypernetworks to represent non-stationary and task-aware
dynamics; third, it outperforms existing continual learning alternatives that
rely on fixed-capacity networks, and does competitively with baselines that
remember an ever increasing coreset of past experience. We show that HyperCRL
is effective in continual model-based reinforcement learning in robot
locomotion and manipulation scenarios, such as tasks involving pushing and door
opening. Our project website with code and videos is at this link
this http URL
</p>
<a href="http://arxiv.org/abs/2009.11997">arXiv:2009.11997</a> [<a href="http://arxiv.org/pdf/2009.11997">pdf</a>]

<h2>A Meta-learning based Distribution System Load Forecasting Model Selection Framework. (arXiv:2009.12001v1 [eess.SY])</h2>
<h3>Yiyan Li, Si Zhang, Rongxing Hu, Ning Lu</h3>
<p>This paper presents a meta-learning based, automatic distribution system load
forecasting model selection framework. The framework includes the following
processes: feature extraction, candidate model labeling, offline training, and
online model recommendation. Using user load forecasting needs as input
features, multiple meta-learners are used to rank the available load forecast
models based on their forecasting accuracy. Then, a scoring-voting mechanism
weights recommendations from each meta-leaner to make the final
recommendations. Heterogeneous load forecasting tasks with different temporal
and technical requirements at different load aggregation levels are set up to
train, validate, and test the performance of the proposed framework. Simulation
results demonstrate that the performance of the meta-learning based approach is
satisfactory in both seen and unseen forecasting tasks.
</p>
<a href="http://arxiv.org/abs/2009.12001">arXiv:2009.12001</a> [<a href="http://arxiv.org/pdf/2009.12001">pdf</a>]

<h2>MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems. (arXiv:2009.12005v1 [cs.CL])</h2>
<h3>Zhaojiang Lin, Andrea Madotto, Genta Indra Winata, Pascale Fung</h3>
<p>In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify
the system design process of task-oriented dialogue systems and alleviate the
over-dependency on annotated data. MinTL is a simple yet effective transfer
learning framework, which allows us to plug-and-play pre-trained seq2seq
models, and jointly learn dialogue state tracking and dialogue response
generation. Unlike previous approaches, which use a copy mechanism to
"carryover" the old dialogue states to the new one, we introduce Levenshtein
belief spans (Lev), that allows efficient dialogue state tracking with a
minimal generation length. We instantiate our learning framework with two
pre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive
experiments demonstrate that: 1) our systems establish new state-of-the-art
results on end-to-end response generation, 2) MinTL-based systems are more
robust than baseline methods in the low resource setting, and they achieve
competitive results with only 20\% training data, and 3) Lev greatly improves
the inference efficiency.
</p>
<a href="http://arxiv.org/abs/2009.12005">arXiv:2009.12005</a> [<a href="http://arxiv.org/pdf/2009.12005">pdf</a>]

<h2>G-SimCLR : Self-Supervised Contrastive Learning with Guided Projection via Pseudo Labelling. (arXiv:2009.12007v1 [cs.LG])</h2>
<h3>Souradip Chakraborty, Aritra Roy Gosthipaty, Sayak Paul</h3>
<p>In the realms of computer vision, it is evident that deep neural networks
perform better in a supervised setting with a large amount of labeled data. The
representations learned with supervision are not only of high quality but also
helps the model in enhancing its accuracy. However, the collection and
annotation of a large dataset are costly and time-consuming. To avoid the same,
there has been a lot of research going on in the field of unsupervised visual
representation learning especially in a self-supervised setting. Amongst the
recent advancements in self-supervised methods for visual recognition, in
SimCLR Chen et al. shows that good quality representations can indeed be
learned without explicit supervision. In SimCLR, the authors maximize the
similarity of augmentations of the same image and minimize the similarity of
augmentations of different images. A linear classifier trained with the
representations learned using this approach yields 76.5% top-1 accuracy on the
ImageNet ILSVRC-2012 dataset. In this work, we propose that, with the
normalized temperature-scaled cross-entropy (NT-Xent) loss function (as used in
SimCLR), it is beneficial to not have images of the same category in the same
batch. In an unsupervised setting, the information of images pertaining to the
same category is missing. We use the latent space representation of a denoising
autoencoder trained on the unlabeled dataset and cluster them with k-means to
obtain pseudo labels. With this apriori information we batch images, where no
two images from the same category are to be found. We report comparable
performance enhancements on the CIFAR10 dataset and a subset of the ImageNet
dataset. We refer to our method as G-SimCLR.
</p>
<a href="http://arxiv.org/abs/2009.12007">arXiv:2009.12007</a> [<a href="http://arxiv.org/pdf/2009.12007">pdf</a>]

<h2>Revealing the Myth of Higher-Order Inference in Coreference Resolution. (arXiv:2009.12013v1 [cs.CL])</h2>
<h3>Liyan Xu, Jinho D. Choi</h3>
<p>This paper analyzes the impact of higher-order inference (HOI) on the task of
coreference resolution. HOI has been adapted by almost all recent coreference
resolution models without taking much investigation on its true effectiveness
over representation learning. To make a comprehensive analysis, we implement an
end-to-end coreference system as well as four HOI approaches, attended
antecedent, entity equalization, span clustering, and cluster merging, where
the latter two are our original methods. We find that given a high-performing
encoder such as SpanBERT, the impact of HOI is negative to marginal, providing
a new perspective of HOI to this task. Our best model using cluster merging
shows the Avg-F1 of 80.2 on the CoNLL 2012 shared task dataset in English.
</p>
<a href="http://arxiv.org/abs/2009.12013">arXiv:2009.12013</a> [<a href="http://arxiv.org/pdf/2009.12013">pdf</a>]

<h2>Influence of segmentation accuracy in structural MR head scans on electric field computation for TMS and tES. (arXiv:2009.12015v1 [physics.med-ph])</h2>
<h3>Essam A. Rashed, Jose Gomez-Tames, Akimasa Hirata</h3>
<p>In several diagnosis and therapy procedures based on electrostimulation
effect, the internal physical quantity related to the stimulation is the
induced electric field. To estimate the induced electric field in an individual
human model, the segmentation of anatomical imaging, such as (magnetic
resonance image (MRI) scans, of the corresponding body parts into tissues is
required. Then, electrical properties associated with different annotated
tissues are assigned to the digital model to generate a volume conductor. An
open question is how segmentation accuracy of different tissues would influence
the distribution of the induced electric field. In this study, we applied
parametric segmentation of different tissues to exploit the segmentation of
available MRI to generate different quality of head models using deep learning
neural network architecture, named ForkNet. Then, the induced electric field
are compared to assess the effect of model segmentation variations.
Computational results indicate that the influence of segmentation error is
tissue-dependent. In brain, sensitivity to segmentation accuracy is relatively
high in cerebrospinal fluid (CSF), moderate in gray matter (GM) and low in
white matter for transcranial magnetic stimulation (TMS) and transcranial
electrical stimulation (tES). A CSF segmentation accuracy reduction of 10% in
terms of Dice coefficient (DC) lead to decrease up to 4% in normalized induced
electric field in both applications. However, a GM segmentation accuracy
reduction of 5.6% DC leads to increase of normalized induced electric field up
to 6%. Opposite trend of electric field variation was found between CSF and GM
for both TMS and tES. The finding obtained here would be useful to quantify
potential uncertainty of computational results.
</p>
<a href="http://arxiv.org/abs/2009.12015">arXiv:2009.12015</a> [<a href="http://arxiv.org/pdf/2009.12015">pdf</a>]

<h2>A Unified Plug-and-Play Framework for Effective Data Denoising and Robust Abstention. (arXiv:2009.12027v1 [cs.LG])</h2>
<h3>Krishanu Sarker, Xiulong Yang, Yang Li, Saeid Belkasim, Shihao Ji</h3>
<p>The success of Deep Neural Networks (DNNs) highly depends on data quality.
Moreover, predictive uncertainty makes high performing DNNs risky for
real-world deployment. In this paper, we aim to address these two issues by
proposing a unified filtering framework leveraging underlying data density,
that can effectively denoise training data as well as avoid predicting
uncertain test data points. Our proposed framework leverages underlying data
distribution to differentiate between noise and clean data samples without
requiring any modification to existing DNN architectures or loss functions.
Extensive experiments on multiple image classification datasets and multiple
CNN architectures demonstrate that our simple yet effective framework can
outperform the state-of-the-art techniques in denoising training data and
abstaining uncertain test data.
</p>
<a href="http://arxiv.org/abs/2009.12027">arXiv:2009.12027</a> [<a href="http://arxiv.org/pdf/2009.12027">pdf</a>]

<h2>Deep Adversarial Transition Learning using Cross-Grafted Generative Stacks. (arXiv:2009.12028v1 [cs.CV])</h2>
<h3>Jinyong Hou, Xuejie Ding, Stephen Cranefield, Jeremiah D. Deng</h3>
<p>Current deep domain adaptation methods used in computer vision have mainly
focused on learning discriminative and domain-invariant features across
different domains. In this paper, we present a novel "deep adversarial
transition learning" (DATL) framework that bridges the domain gap by projecting
the source and target domains into intermediate, transitional spaces through
the employment of adjustable, cross-grafted generative network stacks and
effective adversarial learning between transitions. Specifically, we construct
variational auto-encoders (VAE) for the two domains, and form bidirectional
transitions by cross-grafting the VAEs' decoder stacks. Furthermore, generative
adversarial networks (GAN) are employed for domain adaptation, mapping the
target domain data to the known label space of the source domain. The overall
adaptation process hence consists of three phases: feature representation
learning by VAEs, transitions generation, and transitions alignment by GANs.
Experimental results demonstrate that our method outperforms the state-of-the
art on a number of unsupervised domain adaptation benchmarks.
</p>
<a href="http://arxiv.org/abs/2009.12028">arXiv:2009.12028</a> [<a href="http://arxiv.org/pdf/2009.12028">pdf</a>]

<h2>AutoETER: Automated Entity Type Representation for Knowledge Graph Embedding. (arXiv:2009.12030v1 [cs.CL])</h2>
<h3>Guanglin Niu, Bo Li, Yongfei Zhang, Shiliang Pu, Jingyang Li</h3>
<p>Recent advances in Knowledge Graph Embed-ding (KGE) allow for representing
entities and relations in continuous vector spaces. Some traditional KGE models
leveraging additional type information can improve the representation of
entities which however totally rely on the explicit types or neglect the
diverse type representations specific to various relations. Besides, none of
the existing methods is capable of inferring all the relation patterns of
symmetry, inversion and composition as well as the complex properties of 1-N,
N-1 and N-N relations, simultaneously. To explore the type information for any
KG, we develop a novel KGE framework with Automated Entity TypE Representation
(AutoETER), which learns the latent type embedding of each entity by regarding
each relation as a translation operation between the types of two entities with
a relation-aware projection mechanism. Particularly, our designed automated
type representation learning mechanism is a pluggable module which can be
easily incorporated with any KGE model. Besides, our approach could model and
infer all the relation patterns and complex relations. Experiments on four
datasets demonstrate the superior performance of our model compared to
state-of-the-art baselines on link prediction tasks, and the visualization of
type clustering explains the similarity of type embeddings and verify the
effectiveness of our model.
</p>
<a href="http://arxiv.org/abs/2009.12030">arXiv:2009.12030</a> [<a href="http://arxiv.org/pdf/2009.12030">pdf</a>]

<h2>Fairness in Semi-supervised Learning: Unlabeled Data Help to Reduce Discrimination. (arXiv:2009.12040v1 [cs.LG])</h2>
<h3>Tao Zhang, Tianqing Zhu, Jing Li, Mengde Han, Wanlei Zhou, Philip S. Yu</h3>
<p>A growing specter in the rise of machine learning is whether the decisions
made by machine learning models are fair. While research is already underway to
formalize a machine-learning concept of fairness and to design frameworks for
building fair models with sacrifice in accuracy, most are geared toward either
supervised or unsupervised learning. Yet two observations inspired us to wonder
whether semi-supervised learning might be useful to solve discrimination
problems. First, previous study showed that increasing the size of the training
set may lead to a better trade-off between fairness and accuracy. Second, the
most powerful models today require an enormous of data to train which, in
practical terms, is likely possible from a combination of labeled and unlabeled
data. Hence, in this paper, we present a framework of fair semi-supervised
learning in the pre-processing phase, including pseudo labeling to predict
labels for unlabeled data, a re-sampling method to obtain multiple fair
datasets and lastly, ensemble learning to improve accuracy and decrease
discrimination. A theoretical decomposition analysis of bias, variance and
noise highlights the different sources of discrimination and the impact they
have on fairness in semi-supervised learning. A set of experiments on
real-world and synthetic datasets show that our method is able to use unlabeled
data to achieve a better trade-off between accuracy and discrimination.
</p>
<a href="http://arxiv.org/abs/2009.12040">arXiv:2009.12040</a> [<a href="http://arxiv.org/pdf/2009.12040">pdf</a>]

<h2>Deep Autoencoding GMM-based Unsupervised Anomaly Detection in Acoustic Signals and its Hyper-parameter Optimization. (arXiv:2009.12042v1 [eess.AS])</h2>
<h3>Harsh Purohit, Ryo Tanabe, Takashi Endo, Kaori Suefusa, Yuki Nikaido, Yohei Kawaguchi</h3>
<p>Failures or breakdowns in factory machinery can be costly to companies, so
there is an increasing demand for automatic machine inspection. Existing
approaches to acoustic signal-based unsupervised anomaly detection, such as
those using a deep autoencoder (DA) or Gaussian mixture model (GMM), have poor
anomaly-detection performance. In this work, we propose a new method based on a
deep autoencoding Gaussian mixture model with hyper-parameter optimization
(DAGMM-HO). In our method, the DAGMM-HO applies the conventional DAGMM to the
audio domain for the first time, with the idea that its total optimization on
reduction of dimensions and statistical modelling will improve the
anomaly-detection performance. In addition, the DAGMM-HO solves the
hyper-parameter sensitivity problem of the conventional DAGMM by performing
hyper-parameter optimization based on the gap statistic and the cumulative
eigenvalues. Our evaluation of the proposed method with experimental data of
the industrial fans showed that it significantly outperforms previous
approaches and achieves up to a 20% improvement based on the standard AUC
score.
</p>
<a href="http://arxiv.org/abs/2009.12042">arXiv:2009.12042</a> [<a href="http://arxiv.org/pdf/2009.12042">pdf</a>]

<h2>Controllable Text Generation with Focused Variation. (arXiv:2009.12046v1 [cs.CL])</h2>
<h3>Lei Shu, Alexandros Papangelis, Yi-Chia Wang, Gokhan Tur, Hu Xu, Zhaleh Feizollahi, Bing Liu, Piero Molino</h3>
<p>This work introduces Focused-Variation Network (FVN), a novel model to
control language generation. The main problems in previous controlled language
generation models range from the difficulty of generating text according to the
given attributes, to the lack of diversity of the generated texts. FVN
addresses these issues by learning disjoint discrete latent spaces for each
attribute inside codebooks, which allows for both controllability and
diversity, while at the same time generating fluent text. We evaluate FVN on
two text generation datasets with annotated content and style, and show
state-of-the-art performance as assessed by automatic and human evaluations.
</p>
<a href="http://arxiv.org/abs/2009.12046">arXiv:2009.12046</a> [<a href="http://arxiv.org/pdf/2009.12046">pdf</a>]

<h2>DPN: Detail-Preserving Network with High Resolution Representation for Efficient Segmentation of Retinal Vessels. (arXiv:2009.12053v1 [eess.IV])</h2>
<h3>Song Guo</h3>
<p>Retinal vessels are important biomarkers for many ophthalmological and
cardiovascular diseases. It is of great significance to develop an accurate and
fast vessel segmentation model for computer-aided diagnosis. Existing methods,
such as U-Net follows the encoder-decoder pipeline, where detailed information
is lost in the encoder in order to achieve a large field of view. Although
detailed information could be recovered in the decoder via multi-scale fusion,
it still contains noise. In this paper, we propose a deep segmentation model,
called detail-preserving network (DPN) for efficient vessel segmentation. To
preserve detailed spatial information and learn structural information at the
same time, we designed the detail-preserving block (DP-Block). Further, we
stacked eight DP-Blocks together to form the DPN. More importantly, there are
no down-sampling operations among these blocks. As a result, the DPN could
maintain a high resolution during the processing, which is helpful to locate
the boundaries of thin vessels. To illustrate the effectiveness of our method,
we conducted experiments over three public datasets. Experimental results show,
compared to state-of-the-art methods, our method shows competitive/better
performance in terms of segmentation accuracy, segmentation speed,
extensibility and the number of parameters. Specifically, 1) the AUC of our
method ranks first/second/third on the STARE/CHASE_DB1/DRIVE datasets,
respectively. 2) Only one forward pass is required of our method to generate a
vessel segmentation map, and the segmentation speed of our method is over
20-160x faster than other methods on the DRIVE dataset. 3) We conducted
cross-training experiments to demonstrate the extensibility of our method, and
results revealed that our method shows superior performance. 4) The number of
parameters of our method is only around 96k, less then all comparison methods.
</p>
<a href="http://arxiv.org/abs/2009.12053">arXiv:2009.12053</a> [<a href="http://arxiv.org/pdf/2009.12053">pdf</a>]

<h2>An Unsupervised Sentence Embedding Method byMutual Information Maximization. (arXiv:2009.12061v1 [cs.CL])</h2>
<h3>Yan Zhang, Ruidan He, Zuozhu Liu, Kwan Hui Lim, Lidong Bing</h3>
<p>BERT is inefficient for sentence-pair tasks such as clustering or semantic
search as it needs to evaluate combinatorially many sentence pairs which is
very time-consuming. Sentence BERT (SBERT) attempted to solve this challenge by
learning semantically meaningful representations of single sentences, such that
similarity comparison can be easily accessed. However, SBERT is trained on
corpus with high-quality labeled sentence pairs, which limits its application
to tasks where labeled data is extremely scarce. In this paper, we propose a
lightweight extension on top of BERT and a novel self-supervised learning
objective based on mutual information maximization strategies to derive
meaningful sentence embeddings in an unsupervised manner. Unlike SBERT, our
method is not restricted by the availability of labeled data, such that it can
be applied on different domain-specific corpus. Experimental results show that
the proposed method significantly outperforms other unsupervised sentence
embedding baselines on common semantic textual similarity (STS) tasks and
downstream supervised tasks. It also outperforms SBERT in a setting where
in-domain labeled data is not available, and achieves performance competitive
with supervised methods on various tasks.
</p>
<a href="http://arxiv.org/abs/2009.12061">arXiv:2009.12061</a> [<a href="http://arxiv.org/pdf/2009.12061">pdf</a>]

<h2>In-sample Contrastive Learning and Consistent Attention for Weakly Supervised Object Localization. (arXiv:2009.12063v1 [cs.CV])</h2>
<h3>Minsong Ki, Youngjung Uh, Wonyoung Lee, Hyeran Byun</h3>
<p>Weakly supervised object localization (WSOL) aims to localize the target
object using only the image-level supervision. Recent methods encourage the
model to activate feature maps over the entire object by dropping the most
discriminative parts. However, they are likely to induce excessive extension to
the backgrounds which leads to over-estimated localization. In this paper, we
consider the background as an important cue that guides the feature activation
to cover the sophisticated object region and propose contrastive attention
loss. The loss promotes similarity between foreground and its dropped version,
and, dissimilarity between the dropped version and background. Furthermore, we
propose foreground consistency loss that penalizes earlier layers producing
noisy attention regarding the later layer as a reference to provide them with a
sense of backgroundness. It guides the early layers to activate on objects
rather than locally distinctive backgrounds so that their attentions to be
similar to the later layer. For better optimizing the above losses, we use the
non-local attention blocks to replace channel-pooled attention leading to
enhanced attention maps considering the spatial similarity. Last but not least,
we propose to drop background regions in addition to the most discriminative
region. Our method achieves state-of-theart performance on CUB-200-2011 and
ImageNet benchmark datasets regarding top-1 localization accuracy and
MaxBoxAccV2, and we provide detailed analysis on our individual components. The
code will be publicly available online for reproducibility.
</p>
<a href="http://arxiv.org/abs/2009.12063">arXiv:2009.12063</a> [<a href="http://arxiv.org/pdf/2009.12063">pdf</a>]

<h2>Attention Meets Perturbations: Robust and Interpretable Attention with Adversarial Training. (arXiv:2009.12064v1 [cs.CL])</h2>
<h3>Shunsuke Kitada, Hitoshi Iyatomi</h3>
<p>In recent years, deep learning models have placed more emphasis on the
interpretability and robustness of models. The attention mechanism is an
important technique that contributes to these elements and is widely used,
especially in the natural language processing (NLP) field. Adversarial training
(AT) is a powerful regularization technique for enhancing the robustness of
neural networks and has been successful in many applications. The application
of AT to the attention mechanism is expected to be highly effective, but there
is little research on this. In this paper, we propose a new general training
technique for NLP tasks, using AT for attention (Attention AT) and more
interpretable adversarial training for attention (Attention iAT). Our proposals
improved both the prediction performance and interpretability of the model by
applying AT to the attention mechanisms. In particular, Attention iAT enhances
those advantages by introducing adversarial perturbation, which differentiates
the attention of sentences where it is unclear which words are important. We
performed various NLP tasks on ten open datasets and compared the performance
of our techniques to a recent model using attention mechanisms. Our experiments
revealed that AT for attention mechanisms, especially Attention iAT,
demonstrated (1) the best prediction performance in nine out of ten tasks and
(2) more interpretable attention (i.e., the resulting attention correlated more
strongly with gradient-based word importance) for all tasks. Additionally, our
techniques are (3) much less dependent on perturbation size in AT. Our code and
more results are available at
https://github.com/shunk031/attention-meets-perturbation
</p>
<a href="http://arxiv.org/abs/2009.12064">arXiv:2009.12064</a> [<a href="http://arxiv.org/pdf/2009.12064">pdf</a>]

<h2>Deep Reinforcement Learning with Stage Incentive Mechanism for Robotic Trajectory Planning. (arXiv:2009.12068v1 [cs.AI])</h2>
<h3>Jin Yang, Gang Peng</h3>
<p>To improve the efficiency of deep reinforcement learning (DRL) based methods
for robot manipulator trajectory planning in random working environment.
Different from the traditional sparse reward function, we present three dense
reward functions in this paper. Firstly, posture reward function is proposed to
accelerate the learning process with a more reasonable trajectory by modeling
the distance and direction constraints, which can reduce the blindness of
exploration. Secondly, to improve the stability, a reward function at stride
reward is proposed by modeling the distance and movement distance of joints
constraints, it can make the learning process more stable. In order to further
improve learning efficiency, we are inspired by the cognitive process of human
behavior and propose a stage incentive mechanism, including hard stage
incentive reward function and soft stage incentive reward function. Extensive
experiments show that the soft stage incentive reward function proposed is able
to improve convergence rate by up to 46.9% with the state-of-the-art DRL
methods. The percentage increase in convergence mean reward is 4.4%~15.5% and
the percentage decreases with respect to standard deviation by 21.9%~63.2%. In
the evaluation, the success rate of trajectory planning for robot manipulator
is up to 99.6%.
</p>
<a href="http://arxiv.org/abs/2009.12068">arXiv:2009.12068</a> [<a href="http://arxiv.org/pdf/2009.12068">pdf</a>]

<h2>Training CNNs in Presence of JPEG Compression: Multimedia Forensics vs Computer Vision. (arXiv:2009.12088v1 [cs.CV])</h2>
<h3>Sara Mandelli, Nicol&#xf2; Bonettini, Paolo Bestagini, Stefano Tubaro</h3>
<p>Convolutional Neural Networks (CNNs) have proved very accurate in multiple
computer vision image classification tasks that required visual inspection in
the past (e.g., object recognition, face detection, etc.). Motivated by these
astonishing results, researchers have also started using CNNs to cope with
image forensic problems (e.g., camera model identification, tampering
detection, etc.). However, in computer vision, image classification methods
typically rely on visual cues easily detectable by human eyes. Conversely,
forensic solutions rely on almost invisible traces that are often very subtle
and lie in the fine details of the image under analysis. For this reason,
training a CNN to solve a forensic task requires some special care, as common
processing operations (e.g., resampling, compression, etc.) can strongly hinder
forensic traces. In this work, we focus on the effect that JPEG has on CNN
training considering different computer vision and forensic image
classification problems. Specifically, we consider the issues that rise from
JPEG compression and misalignment of the JPEG grid. We show that it is
necessary to consider these effects when generating a training dataset in order
to properly train a forensic detector not losing generalization capability,
whereas it is almost possible to ignore these effects for computer vision
tasks.
</p>
<a href="http://arxiv.org/abs/2009.12088">arXiv:2009.12088</a> [<a href="http://arxiv.org/pdf/2009.12088">pdf</a>]

<h2>Resource-Constrained On-Device Learning by Dynamic Averaging. (arXiv:2009.12098v1 [cs.LG])</h2>
<h3>Lukas Heppe, Michael Kamp, Linara Adilova, Danny Heinrich, Nico Piatkowski, Katharina Morik</h3>
<p>The communication between data-generating devices is partially responsible
for a growing portion of the world's power consumption. Thus reducing
communication is vital, both, from an economical and an ecological perspective.
For machine learning, on-device learning avoids sending raw data, which can
reduce communication substantially. Furthermore, not centralizing the data
protects privacy-sensitive data. However, most learning algorithms require
hardware with high computation power and thus high energy consumption. In
contrast, ultra-low-power processors, like FPGAs or micro-controllers, allow
for energy-efficient learning of local models. Combined with
communication-efficient distributed learning strategies, this reduces the
overall energy consumption and enables applications that were yet impossible
due to limited energy on local devices. The major challenge is then, that the
low-power processors typically only have integer processing capabilities. This
paper investigates an approach to communication-efficient on-device learning of
integer exponential families that can be executed on low-power processors, is
privacy-preserving, and effectively minimizes communication. The empirical
evaluation shows that the approach can reach a model quality comparable to a
centrally learned regular model with an order of magnitude less communication.
Comparing the overall energy consumption, this reduces the required energy for
solving the machine learning task by a significant amount.
</p>
<a href="http://arxiv.org/abs/2009.12098">arXiv:2009.12098</a> [<a href="http://arxiv.org/pdf/2009.12098">pdf</a>]

<h2>With Whom to Communicate: Learning Efficient Communication for Multi-Robot Collision Avoidance. (arXiv:2009.12106v1 [cs.RO])</h2>
<h3>&#xc1;lvaro Serra-G&#xf3;mez, Bruno Brito, Hai Zhu, Jen Jen Chung, Javier Alonso-Mora</h3>
<p>Decentralized multi-robot systems typically perform coordinated motion
planning by constantly broadcasting their intentions as a means to cope with
the lack of a central system coordinating the efforts of all robots. Especially
in complex dynamic environments, the coordination boost allowed by
communication is critical to avoid collisions between cooperating robots.
However, the risk of collision between a pair of robots fluctuates through
their motion and communication is not always needed. Additionally, constant
communication makes much of the still valuable information shared in previous
time steps redundant. This paper presents an efficient communication method
that solves the problem of "when" and with "whom" to communicate in multi-robot
collision avoidance scenarios. In this approach, every robot learns to reason
about other robots' states and considers the risk of future collisions before
asking for the trajectory plans of other robots. We evaluate and verify the
proposed communication strategy in simulation with four quadrotors and compare
it with three baseline strategies: non-communicating, broadcasting and a
distance-based method broadcasting information with quadrotors within a
predefined distance.
</p>
<a href="http://arxiv.org/abs/2009.12106">arXiv:2009.12106</a> [<a href="http://arxiv.org/pdf/2009.12106">pdf</a>]

<h2>Enhancing MRI Brain Tumor Segmentation with an Additional Classification Network. (arXiv:2009.12111v1 [eess.IV])</h2>
<h3>Hieu T. Nguyen, Tung T. Le, Thang V. Nguyen, Nhan T. Nguyen</h3>
<p>Brain tumor segmentation plays an essential role in medical image analysis.
In recent studies, deep convolution neural networks (DCNNs) are extremely
powerful to tackle tumor segmentation tasks. We propose in this paper a novel
training method that enhances the segmentation results by adding an additional
classification branch to the network. The whole network was trained end-to-end
on the Multimodal Brain Tumor Segmentation Challenge (BraTS) 2020 training
dataset. On the BraTS's validation set, it achieved an average Dice score of
78.43%, 89.99%, and 84.22% respectively for the enhancing tumor, the whole
tumor, and the tumor core.
</p>
<a href="http://arxiv.org/abs/2009.12111">arXiv:2009.12111</a> [<a href="http://arxiv.org/pdf/2009.12111">pdf</a>]

<h2>Towards the Automation of a Chemical Sulphonation Process with Machine Learning. (arXiv:2009.12125v1 [cs.LG])</h2>
<h3>Enrique Garcia-Ceja, &#xc5;smund Hugo, Brice Morin, Per-Olav Hansen, Espen Martinsen, An Ngoc Lam, &#xd8;ystein Haugen</h3>
<p>Nowadays, the continuous improvement and automation of industrial processes
has become a key factor in many fields, and in the chemical industry, it is no
exception. This translates into a more efficient use of resources, reduced
production time, output of higher quality and reduced waste. Given the
complexity of today's industrial processes, it becomes infeasible to monitor
and optimize them without the use of information technologies and analytics. In
recent years, machine learning methods have been used to automate processes and
provide decision support. All of this, based on analyzing large amounts of data
generated in a continuous manner. In this paper, we present the results of
applying machine learning methods during a chemical sulphonation process with
the objective of automating the product quality analysis which currently is
performed manually. We used data from process parameters to train different
models including Random Forest, Neural Network and linear regression in order
to predict product quality values. Our experiments showed that it is possible
to predict those product quality values with good accuracy, thus, having the
potential to reduce time. Specifically, the best results were obtained with
Random Forest with a mean absolute error of 0.089 and a correlation of 0.978.
</p>
<a href="http://arxiv.org/abs/2009.12125">arXiv:2009.12125</a> [<a href="http://arxiv.org/pdf/2009.12125">pdf</a>]

<h2>GEFA: Early Fusion Approach in Drug-Target Affinity Prediction. (arXiv:2009.12146v1 [cs.LG])</h2>
<h3>Tri Minh Nguyen, Thin Nguyen, Thao Minh Le, Truyen Tran</h3>
<p>Predicting the interaction between a compound and a target is crucial for
rapid drug repurposing. Deep learning has been successfully applied in
drug-target affinity (DTA) problem. However, previous deep learning-based
methods ignore modeling the direct interactions between drug and protein
residues. This would lead to inaccurate learning of target representation which
may change due to the drug binding effects. In addition, previous DTA methods
learn protein representation solely based on a small number of protein
sequences in DTA datasets while neglecting the use of proteins outside of the
DTA datasets. We propose GEFA (Graph Early Fusion Affinity), a novel
graph-in-graph neural network with attention mechanism to address the changes
in target representation because of the binding effects. Specifically, a drug
is modeled as a graph of atoms, which then serves as a node in a larger graph
of residues-drug complex. The resulting model is an expressive deep nested
graph neural network. We also use pre-trained protein representation powered by
the recent effort of learning contextualized protein representation. The
experiments are conducted under different settings to evaluate scenarios such
as novel drugs or targets. The results demonstrate the effectiveness of the
pre-trained protein embedding and the advantages our GEFA in modeling the
nested graph for drug-target interaction.
</p>
<a href="http://arxiv.org/abs/2009.12146">arXiv:2009.12146</a> [<a href="http://arxiv.org/pdf/2009.12146">pdf</a>]

<h2>Adaptive Online Multi-modal Hashing via Hadamard Matrix. (arXiv:2009.12148v1 [cs.MM])</h2>
<h3>Jun Yu, Xiao-JunWu, Donglin Zhang, Josef Kittler</h3>
<p>Hashing plays an important role in information retrieval, due to its low
storage and high speed of processing. Among the techniques available in the
literature, multi-modal hashing, which can encode heterogeneous multi-modal
features into compact hash codes, has received particular attention. Existing
multi-modal hashing methods introduce hyperparameters to balance many
regularization terms designed to make the models more robust in the hash
learning process. However, it is time-consuming and labor-intensive to set them
proper values. In this paper, we propose a simple, yet effective method that is
inspired by the Hadamard matrix, which captures the multi-modal feature
information in an adaptive manner and preserves the discriminative semantic
information in the hash codes. Our framework is flexible and involves a very
few hyper-parameters. Extensive experimental results show the method is
effective and achieves superior performance compared to state-of-the-art
algorithms.
</p>
<a href="http://arxiv.org/abs/2009.12148">arXiv:2009.12148</a> [<a href="http://arxiv.org/pdf/2009.12148">pdf</a>]

<h2>A Survey on Model Watermarking Neural Networks. (arXiv:2009.12153v1 [cs.CR])</h2>
<h3>Franziska Boenisch</h3>
<p>Machine learning (ML) models are applied in an increasing variety of domains.
The availability of large amounts of data and computational resources
encourages the development of ever more complex and valuable models. These
models are considered intellectual property of the legitimate parties who have
trained them, which makes their protection against stealing, illegitimate
redistribution, and unauthorized application an urgent need. Digital
watermarking presents a strong mechanism for marking model ownership and,
thereby, offers protection against those threats. The emergence of numerous
watermarking schemes and attacks against them is pushed forward by both
academia and industry, which motivates a comprehensive survey on this field.
This document at hand provides the first extensive literature review on ML
model watermarking schemes and attacks against them. It offers a taxonomy of
existing approaches and systemizes general knowledge around them. Furthermore,
it assembles the security requirements to watermarking approaches and evaluates
schemes published by the scientific community according to them in order to
present systematic shortcomings and vulnerabilities. Thus, it can not only
serve as valuable guidance in choosing the appropriate scheme for specific
scenarios, but also act as an entry point into developing new mechanisms that
overcome presented shortcomings, and thereby contribute in advancing the field.
</p>
<a href="http://arxiv.org/abs/2009.12153">arXiv:2009.12153</a> [<a href="http://arxiv.org/pdf/2009.12153">pdf</a>]

<h2>Spatial-Temporal Demand Forecasting and Competitive Supply via Graph Convolutional Networks. (arXiv:2009.12157v1 [cs.DB])</h2>
<h3>Bolong Zheng, Qi Hu, Lingfeng Ming, Jilin Hu, Lu Chen, Kai Zheng, Christian S. Jensen</h3>
<p>We consider a setting with an evolving set of requests for transportation
from an origin to a destination before a deadline and a set of agents capable
of servicing the requests. In this setting, an assignment authority is to
assign agents to requests such that the average idle time of the agents is
minimized. An example is the scheduling of taxis (agents) to meet incoming
requests for trips while ensuring that the taxis are empty as little as
possible. In this paper, we study the problem of spatial-temporal demand
forecasting and competitive supply (SOUP). We address the problem in two steps.
First, we build a granular model that provides spatial-temporal predictions of
requests. Specifically, we propose a Spatial-Temporal Graph Convolutional
Sequential Learning (ST-GCSL) algorithm that predicts the service requests
across locations and time slots. Second, we provide means of routing agents to
request origins while avoiding competition among the agents. In particular, we
develop a demand-aware route planning (DROP) algorithm that considers both the
spatial-temporal predictions and the supplydemand state. We report on extensive
experiments with realworld and synthetic data that offer insight into the
performance of the solution and show that it is capable of outperforming the
state-of-the-art proposals.
</p>
<a href="http://arxiv.org/abs/2009.12157">arXiv:2009.12157</a> [<a href="http://arxiv.org/pdf/2009.12157">pdf</a>]

<h2>Delay Characterization of Mobile Edge Computing for 6G Time-Sensitive Services. (arXiv:2009.12170v1 [eess.SP])</h2>
<h3>Jianyu Cao, Wei Feng, Ning Ge, Jianhua Lu</h3>
<p>Time-sensitive services (TSSs) have been widely envisioned for future sixth
generation (6G) wireless communication networks. Due to its inherent
low-latency advantage, mobile edge computing (MEC) will be an indispensable
enabler for TSSs. The random characteristics of the delay experienced by users
are key metrics reflecting the quality of service (QoS) of TSSs. Most existing
studies on MEC have focused on the average delay. Only a few research efforts
have been devoted to other random delay characteristics, such as the delay
bound violation probability and the probability distribution of the delay, by
decoupling the transmission and computation processes of MEC. However, if these
two processes could not be decoupled, the coupling will bring new challenges to
analyzing the random delay characteristics. In this paper, an MEC system with a
limited computation buffer at the edge server is considered. In this system,
the transmission process and computation process form a feedback loop and could
not be decoupled. We formulate a discrete-time two-stage tandem queueing
system. Then, by using the matrix-geometric method, we obtain the estimation
methods for the random delay characteristics, including the probability
distribution of the delay, the delay bound violation probability, the average
delay and the delay standard deviation. The estimation methods are verified by
simulations. The random delay characteristics are analyzed by numerical
experiments, which unveil the coupling relationship between the transmission
process and computation process for MEC. These results will largely facilitate
elaborate allocation of communication and computation resources to improve the
QoS of TSSs.
</p>
<a href="http://arxiv.org/abs/2009.12170">arXiv:2009.12170</a> [<a href="http://arxiv.org/pdf/2009.12170">pdf</a>]

<h2>Tuning Word2vec for Large Scale Recommendation Systems. (arXiv:2009.12192v1 [cs.IR])</h2>
<h3>Benjamin P. Chamberlain, Emanuele Rossi, Dan Shiebler, Suvash Sedhain, Michael M. Bronstein</h3>
<p>Word2vec is a powerful machine learning tool that emerged from Natural
Lan-guage Processing (NLP) and is now applied in multiple domains, including
recom-mender systems, forecasting, and network analysis. As Word2vec is often
used offthe shelf, we address the question of whether the default
hyperparameters are suit-able for recommender systems. The answer is
emphatically no. In this paper, wefirst elucidate the importance of
hyperparameter optimization and show that un-constrained optimization yields an
average 221% improvement in hit rate over thedefault parameters. However,
unconstrained optimization leads to hyperparametersettings that are very
expensive and not feasible for large scale recommendationtasks. To this end, we
demonstrate 138% average improvement in hit rate with aruntime
budget-constrained hyperparameter optimization. Furthermore, to
makehyperparameter optimization applicable for large scale recommendation
problemswhere the target dataset is too large to search over, we investigate
generalizinghyperparameters settings from samples. We show that applying
constrained hy-perparameter optimization using only a 10% sample of the data
still yields a 91%average improvement in hit rate over the default parameters
when applied to thefull datasets. Finally, we apply hyperparameters learned
using our method of con-strained optimization on a sample to the Who To Follow
recommendation serviceat Twitter and are able to increase follow rates by 15%.
</p>
<a href="http://arxiv.org/abs/2009.12192">arXiv:2009.12192</a> [<a href="http://arxiv.org/pdf/2009.12192">pdf</a>]

<h2>Style-invariant Cardiac Image Segmentation with Test-time Augmentation. (arXiv:2009.12193v1 [eess.IV])</h2>
<h3>Xiaoqiong Huang, Zejian Chen, Xin Yang, Zhendong Liu, Yuxin Zou, Mingyuan Luo, Wufeng Xue, Dong Ni</h3>
<p>Deep models often suffer from severe performance drop due to the appearance
shift in the real clinical setting. Most of the existing learning-based methods
rely on images from multiple sites/vendors or even corresponding labels.
However, collecting enough unknown data to robustly model segmentation cannot
always hold since the complex appearance shift caused by imaging factors in
daily application. In this paper, we propose a novel style-invariant method for
cardiac image segmentation. Based on the zero-shot style transfer to remove
appearance shift and test-time augmentation to explore diverse underlying
anatomy, our proposed method is effective in combating the appearance shift.
Our contribution is three-fold. First, inspired by the spirit of universal
style transfer, we develop a zero-shot stylization for content images to
generate stylized images that appearance similarity to the style images.
Second, we build up a robust cardiac segmentation model based on the U-Net
structure. Our framework mainly consists of two networks during testing: the ST
network for removing appearance shift and the segmentation network. Third, we
investigate test-time augmentation to explore transformed versions of the
stylized image for prediction and the results are merged. Notably, our proposed
framework is fully test-time adaptation. Experiment results demonstrate that
our methods are promising and generic for generalizing deep segmentation
models.
</p>
<a href="http://arxiv.org/abs/2009.12193">arXiv:2009.12193</a> [<a href="http://arxiv.org/pdf/2009.12193">pdf</a>]

<h2>Isolation Distributional Kernel: A New Tool for Point & Group Anomaly Detection. (arXiv:2009.12196v1 [cs.LG])</h2>
<h3>Kai Ming Ting, Bi-Cun Xu, Takashi Washio, Zhi-Hua Zhou</h3>
<p>We introduce Isolation Distributional Kernel as a new way to measure the
similarity between two distributions. Existing approaches based on kernel mean
embedding, which convert a point kernel to a distributional kernel, have two
key issues: the point kernel employed has a feature map with intractable
dimensionality; and it is {\em data independent}. This paper shows that
Isolation Distributional Kernel (IDK), which is based on a {\em data dependent}
point kernel, addresses both key issues. We demonstrate IDK's efficacy and
efficiency as a new tool for kernel based anomaly detection for both point and
group anomalies. Without explicit learning, using IDK alone outperforms
existing kernel based point anomaly detector OCSVM and other kernel mean
embedding methods that rely on Gaussian kernel. For group anomaly detection,we
introduce an IDK based detector called IDK$^2$. It reformulates the problem of
group anomaly detection in input space into the problem of point anomaly
detection in Hilbert space, without the need for learning. IDK$^2$ runs orders
of magnitude faster than group anomaly detector OCSMM.We reveal for the first
time that an effective kernel based anomaly detector based on kernel mean
embedding must employ a characteristic kernel which is data dependent.
</p>
<a href="http://arxiv.org/abs/2009.12196">arXiv:2009.12196</a> [<a href="http://arxiv.org/pdf/2009.12196">pdf</a>]

<h2>End-to-End Prediction of Parcel Delivery Time with Deep Learning for Smart-City Applications. (arXiv:2009.12197v1 [eess.SP])</h2>
<h3>Arthur Cruz de Araujo, Ali Etemad</h3>
<p>The acquisition of massive data on parcel delivery motivates postal operators
to foster the development of predictive systems to improve customer service.
Predicting delivery times successive to being shipped out of the final depot,
referred to as last-mile prediction, deals with complicating factors such as
traffic, drivers' behaviors, and weather. This work studies the use of deep
learning for solving a real-world case of last-mile parcel delivery time
prediction. We present our solution under the IoT paradigm and discuss its
feasibility on a cloud-based architecture as a smart city application. We focus
on a large-scale parcel dataset provided by Canada Post, covering the Greater
Toronto Area (GTA). We utilize an origin-destination (OD) formulation, in which
routes are not available, but only the start and end delivery points. We
investigate three categories of convolutional-based neural networks and assess
their performances on the task. We further demonstrate how our modeling
outperforms several baselines, from classical machine learning models to
referenced OD solutions. Specifically, we show that a ResNet architecture with
8 residual blocks displays the best trade-off between performance and
complexity. We perform a thorough error analysis across the data and visualize
the deep features learned to better understand the model behavior, making
interesting remarks on data predictability. Our work provides an end-to-end
neural pipeline that leverages parcel OD data as well as weather to accurately
predict delivery durations. We believe that our system has the potential not
only to improve user experience by better modeling their anticipation but also
to aid last-mile postal logistics as a whole.
</p>
<a href="http://arxiv.org/abs/2009.12197">arXiv:2009.12197</a> [<a href="http://arxiv.org/pdf/2009.12197">pdf</a>]

<h2>Explaining Chemical Toxicity using Missing Features. (arXiv:2009.12199v1 [q-bio.QM])</h2>
<h3>Kar Wai Lim, Bhanushee Sharma, Payel Das, Vijil Chenthamarakshan, Jonathan S. Dordick</h3>
<p>Chemical toxicity prediction using machine learning is important in drug
development to reduce repeated animal and human testing, thus saving cost and
time. It is highly recommended that the predictions of computational toxicology
models are mechanistically explainable. Current state of the art machine
learning classifiers are based on deep neural networks, which tend to be
complex and harder to interpret. In this paper, we apply a recently developed
method named contrastive explanations method (CEM) to explain why a chemical or
molecule is predicted to be toxic or not. In contrast to popular methods that
provide explanations based on what features are present in the molecule, the
CEM provides additional explanation on what features are missing from the
molecule that is crucial for the prediction, known as the pertinent negative.
The CEM does this by optimizing for the minimum perturbation to the model using
a projected fast iterative shrinkage-thresholding algorithm (FISTA). We
verified that the explanation from CEM matches known toxicophores and findings
from other work.
</p>
<a href="http://arxiv.org/abs/2009.12199">arXiv:2009.12199</a> [<a href="http://arxiv.org/pdf/2009.12199">pdf</a>]

<h2>Grain Surface Classification via Machine Learning Methods. (arXiv:2009.12200v1 [eess.SP])</h2>
<h3>H&#xfc;seyin Duysak, Umut &#xd6;zkaya, Enes Yi&#x11f;it</h3>
<p>In this study, radar signals were analyzed to classify grain surface types by
using machine learning methods. Radar backscatter signals were recorded using a
vector network analyzer between 18-40 GHz. A total of 5681 measurements of A
scan signals were collected. The proposed method framework consists of two
parts. First Order Statistical features are obtained by applying Fast Fourier
Transform (FFT), Discrete Cosine Transform (DCT), Discrete Wavelet Transform
(DWT) on backscatter signals in the first part of the framework. Classification
process of these features was carried out with Support Vector Machine (SVM). In
the second part of the proposed framework, two dimensional matrices in complex
form were obtained by applying Short Time Fourier Transform (STFT) on the
signals. Gray-Level Co-Occurrence Matrix (GLCM) and Gray-Level Run-Length
Matrix (GLRLM) were obtained and feature extraction process was completed.
Classification process was carried out with DVM. 10-k cross validation was
applied. The highest performance was achieved with STFT+GLCM+SVM.
</p>
<a href="http://arxiv.org/abs/2009.12200">arXiv:2009.12200</a> [<a href="http://arxiv.org/pdf/2009.12200">pdf</a>]

<h2>How Much Does It Hurt: A Deep Learning Framework for Chronic Pain Score Assessment. (arXiv:2009.12202v1 [eess.SP])</h2>
<h3>Yun Zhao, Franklin Ly, Qinghang Hong, Zhuowei Cheng, Tyler Santander, Henry T. Yang, Paul K. Hansma, Linda Petzold</h3>
<p>Chronic pain is defined as pain that lasts or recurs for more than 3 to 6
months, often long after the injury or illness that initially caused the pain
has healed. The "gold standard" for chronic pain assessment remains self report
and clinical assessment via a biopsychosocial interview, since there has been
no device that can measure it. A device to measure pain would be useful not
only for clinical assessment, but potentially also as a biofeedback device
leading to pain reduction. In this paper we propose an end-to-end deep learning
framework for chronic pain score assessment. Our deep learning framework splits
the long time-course data samples into shorter sequences, and uses Consensus
Prediction to classify the results. We evaluate the performance of our
framework on two chronic pain score datasets collected from two iterations of
prototype Pain Meters that we have developed to help chronic pain subjects
better understand their health condition.
</p>
<a href="http://arxiv.org/abs/2009.12202">arXiv:2009.12202</a> [<a href="http://arxiv.org/pdf/2009.12202">pdf</a>]

<h2>Deep Learning of Individual Aesthetics. (arXiv:2009.12216v1 [cs.NE])</h2>
<h3>Jon McCormack, Andy Lomas</h3>
<p>Accurate evaluation of human aesthetic preferences represents a major
challenge for creative evolutionary and generative systems research. Prior work
has tended to focus on feature measures of the artefact, such as symmetry,
complexity and coherence. However, research models from Psychology suggest that
human aesthetic experiences encapsulate factors beyond the artefact, making
accurate computational models very difficult to design. The interactive genetic
algorithm (IGA) circumvents the problem through human-in-the-loop, subjective
evaluation of aesthetics, but is limited due to user fatigue and small
population sizes. In this paper we look at how recent advances in deep learning
can assist in automating personal aesthetic judgement. Using a leading artist's
computer art dataset, we investigate the relationship between image measures,
such as complexity, and human aesthetic evaluation. We use dimension reduction
methods to visualise both genotype and phenotype space in order to support the
exploration of new territory in a generative system. Convolutional Neural
Networks trained on the artist's prior aesthetic evaluations are used to
suggest new possibilities similar or between known high quality
genotype-phenotype mappings. We integrate this classification and discovery
system into a software tool for evolving complex generative art and design.
</p>
<a href="http://arxiv.org/abs/2009.12216">arXiv:2009.12216</a> [<a href="http://arxiv.org/pdf/2009.12216">pdf</a>]

<h2>Pebble-Depth. (arXiv:2009.12225v1 [cs.CC])</h2>
<h3>Liam Jordon, Philippe Moser</h3>
<p>In this paper we introduce a new formulation of Bennett's logical depth based
on pebble transducers. This notion is defined based on the difference between
the minimal length descriptional complexity of strings from the perspective of
finite-state transducers and pebble transducers. Our notion of pebble-depth
satisfies the three fundamental properties of depth: i.e. easy sequences and
random sequences are not deep, and the existence of a slow growth law. We also
compare pebble-depth to other depth notions based on finite-state transducers,
pushdown compressors and the Lempel-Ziv $78$ compression algorithm. We first
demonstrate how there exists a normal pebble-deep sequence even though there is
no normal finite-state-deep sequence. We next build a sequence which has a
pebble-depth level of roughly $1$, a pushdown-depth level of roughly $1/2$ and
a finite-state-depth level of roughly $0$. We then build a sequence which has
pebble-depth level of roughly $1/2$ and Lempel-Ziv-depth level of roughly $0$.
</p>
<a href="http://arxiv.org/abs/2009.12225">arXiv:2009.12225</a> [<a href="http://arxiv.org/pdf/2009.12225">pdf</a>]

<h2>From Pixel to Patch: Synthesize Context-aware Features for Zero-shot Semantic Segmentation. (arXiv:2009.12232v1 [cs.CV])</h2>
<h3>Zhangxuan Gu, Siyuan Zhou, Li Niu, Zihan Zhao, Liqing Zhang</h3>
<p>Zero-shot learning has been actively studied for image classification task to
relieve the burden of annotating image labels. Interestingly, semantic
segmentation task requires more labor-intensive pixel-wise annotation, but
zero-shot semantic segmentation has only attracted limited research interest.
Thus, we focus on zero-shot semantic segmentation, which aims to segment unseen
objects with only category-level semantic representations provided for unseen
categories. In this paper, we propose a novel Context-aware feature Generation
Network (CaGNet), which can synthesize context-aware pixel-wise visual features
for unseen categories based on category-level semantic representations and
pixel-wise contextual information. The synthesized features are used to
finetune the classifier to enable segmenting unseen objects. Furthermore, we
extend pixel-wise feature generation and finetuning to patch-wise feature
generation and finetuning, which additionally considers inter-pixel
relationship. Experimental results on Pascal-VOC, Pascal-Context, and
COCO-stuff show that our method significantly outperforms the existing
zero-shot semantic segmentation methods.
</p>
<a href="http://arxiv.org/abs/2009.12232">arXiv:2009.12232</a> [<a href="http://arxiv.org/pdf/2009.12232">pdf</a>]

<h2>EEG Channel Interpolation Using Deep Encoder-decoder Netwoks. (arXiv:2009.12244v1 [eess.SP])</h2>
<h3>Sari Saba-Sadiya, Tuka Alhanai, Taosheng Liu, Mohammad M. Ghassemi</h3>
<p>Electrode "pop" artifacts originate from the spontaneous loss of connectivity
between a surface and an electrode. Electroencephalography (EEG) uses a dense
array of electrodes, hence "popped" segments are among the most pervasive type
of artifact seen during the collection of EEG data. In many cases, the
continuity of EEG data is critical for downstream applications (e.g. brain
machine interface) and requires that popped segments be accurately
interpolated. In this paper we frame the interpolation problem as a
self-learning task using a deep encoder-decoder network. We compare our
approach against contemporary interpolation methods on a publicly available EEG
data set. Our approach exhibited a minimum of ~15% improvement over
contemporary approaches when tested on subjects and tasks not used during model
training. We demonstrate how our model's performance can be enhanced further on
novel subjects and tasks using transfer learning. All code and data associated
with this study is open-source to enable ease of extension and practical use.
To our knowledge, this work is the first solution to the EEG interpolation
problem that uses deep learning.
</p>
<a href="http://arxiv.org/abs/2009.12244">arXiv:2009.12244</a> [<a href="http://arxiv.org/pdf/2009.12244">pdf</a>]

<h2>Database Annotation with few Examples: An Atlas-based Framework using Diffeomorphic Registration of 3D Trees. (arXiv:2009.12252v1 [cs.CV])</h2>
<h3>Pierre-Louis Antonsanti, Thomas Benseghir, Vincent Jugnon, Joan Glaun&#xe8;s</h3>
<p>Automatic annotation of anatomical structures can help simplify workflow
during interventions in numerous clinical applications but usually involves a
large amount of annotated data. The complexity of the labeling task, together
with the lack of representative data, slows down the development of robust
solutions. In this paper, we propose a solution requiring very few annotated
cases to label 3D pelvic arterial trees of patients with benign prostatic
hyperplasia. We take advantage of Large Deformation Diffeomorphic Metric
Mapping (LDDMM) to perform registration based on meaningful deformations from
which we build an atlas. Branch pairing is then computed from the atlas to new
cases using optimal transport to ensure one-to-one correspondence during the
labeling process. To tackle topological variations in the tree, which usually
degrades the performance of atlas-based techniques, we propose a simple
bottom-up label assignment adapted to the pelvic anatomy. The proposed method
achieves 97.6\% labeling precision with only 5 cases for training, while in
comparison learning-based methods only reach 82.2\% on such small training
sets.
</p>
<a href="http://arxiv.org/abs/2009.12252">arXiv:2009.12252</a> [<a href="http://arxiv.org/pdf/2009.12252">pdf</a>]

<h2>Flexible Performant GEMM Kernels on GPU. (arXiv:2009.12263v1 [cs.MS])</h2>
<h3>Thomas Faingnaert, Tim Besard, Bjorn De Sutter</h3>
<p>General Matrix Multiplication or GEMM kernels take center place in high
performance computing and machine learning. Recent NVIDIA GPUs include GEMM
accelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by
the two-language problem: it requires either low-level programming which
implies low programmer productivity or using libraries that only offer a
limited set of components. Because rephrasing algorithms in terms of
established components often introduces overhead, the libraries' lack of
flexibility limits the freedom to explore new algorithms. Researchers using
GEMMs can hence not enjoy programming productivity, high performance, and
research flexibility at once.

In this paper we solve this problem. We present three sets of abstractions
and interfaces to program GEMMs within the scientific Julia programming
language. The interfaces and abstractions are co-designed for researchers'
needs and Julia's features to achieve sufficient separation of concerns and
flexibility to easily extend basic GEMMs in many different ways without paying
a performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS
and CUTLASS, we demonstrate that our performance is mostly on par with, and in
some cases even exceeds, the libraries, without having to write a single line
of code in CUDA C++ or assembly, and without facing flexibility limitations.
</p>
<a href="http://arxiv.org/abs/2009.12263">arXiv:2009.12263</a> [<a href="http://arxiv.org/pdf/2009.12263">pdf</a>]

<h2>Persian Keyphrase Generation Using Sequence-to-Sequence Models. (arXiv:2009.12271v1 [cs.CL])</h2>
<h3>Ehsan Doostmohammadi, Mohammad Hadi Bokaei, Hossein Sameti</h3>
<p>Keyphrases are a very short summary of an input text and provide the main
subjects discussed in the text. Keyphrase extraction is a useful upstream task
and can be used in various natural language processing problems, for example,
text summarization and information retrieval, to name a few. However, not all
the keyphrases are explicitly mentioned in the body of the text. In real-world
examples there are always some topics that are discussed implicitly. Extracting
such keyphrases requires a generative approach, which is adopted here. In this
paper, we try to tackle the problem of keyphrase generation and extraction from
news articles using deep sequence-to-sequence models. These models
significantly outperform the conventional methods such as Topic Rank, KPMiner,
and KEA in the task of keyphrase extraction.
</p>
<a href="http://arxiv.org/abs/2009.12271">arXiv:2009.12271</a> [<a href="http://arxiv.org/pdf/2009.12271">pdf</a>]

<h2>Locally orderless tensor networks for classifying two- and three-dimensional medical images. (arXiv:2009.12280v1 [cs.CV])</h2>
<h3>Raghavendra Selvan, Silas &#xd8;rting, Erik B Dam</h3>
<p>Tensor networks are factorisations of high rank tensors into networks of
lower rank tensors and have primarily been used to analyse quantum many-body
problems. Tensor networks have seen a recent surge of interest in relation to
supervised learning tasks with a focus on image classification. In this work,
we improve upon the matrix product state (MPS) tensor networks that can operate
on one-dimensional vectors to be useful for working with 2D and 3D medical
images. We treat small image regions as orderless, squeeze their spatial
information into feature dimensions and then perform MPS operations on these
locally orderless regions. These local representations are then aggregated in a
hierarchical manner to retain global structure. The proposed locally orderless
tensor network (LoTeNet) is compared with relevant methods on three datasets.
The architecture of LoTeNet is fixed in all experiments and we show it requires
lesser computational resources to attain performance on par or superior to the
compared methods.
</p>
<a href="http://arxiv.org/abs/2009.12280">arXiv:2009.12280</a> [<a href="http://arxiv.org/pdf/2009.12280">pdf</a>]

<h2>robosuite: A Modular Simulation Framework and Benchmark for Robot Learning. (arXiv:2009.12293v1 [cs.RO])</h2>
<h3>Yuke Zhu, Josiah Wong, Ajay Mandlekar, Roberto Mart&#xed;n-Mart&#xed;n</h3>
<p>robosuite is a simulation framework for robot learning powered by the MuJoCo
physics engine. It offers a modular design for creating robotic tasks as well
as a suite of benchmark environments for reproducible research. This paper
discusses the key system modules and the benchmark environments of our new
release robosuite v1.0.
</p>
<a href="http://arxiv.org/abs/2009.12293">arXiv:2009.12293</a> [<a href="http://arxiv.org/pdf/2009.12293">pdf</a>]

<h2>Towards Debiasing NLU Models from Unknown Biases. (arXiv:2009.12303v1 [cs.CL])</h2>
<h3>Prasetya Ajie Utama, Nafise Sadat Moosavi, Iryna Gurevych</h3>
<p>NLU models often exploit biases to achieve high dataset-specific performance
without properly learning the intended task. Recently proposed debiasing
methods are shown to be effective in mitigating this tendency. However, these
methods rely on a major assumption that the types of bias are \emph{known}
a-priori, which limits their application to many NLU tasks and datasets. In
this work, we present the first step to bridge this gap by introducing a
self-debiasing framework that prevents models from mainly utilizing biases
without knowing them in advance. The proposed framework is general and
complementary to the existing debiasing methods. We show that it allows these
existing methods to retain the improvement on the challenge datasets (i.e.,
sets of examples designed to expose models' reliance on biases) without
specifically targeting certain biases. Furthermore, the evaluation suggests
that applying the framework results in improved overall robustness. We include
the code in the supplementary material.
</p>
<a href="http://arxiv.org/abs/2009.12303">arXiv:2009.12303</a> [<a href="http://arxiv.org/pdf/2009.12303">pdf</a>]

<h2>CAD2Real: Deep learning with domain randomization of CAD data for 3D pose estimation of electronic control unit housings. (arXiv:2009.12312v1 [cs.CV])</h2>
<h3>Simon Baeuerle, Jonas Barth, Elton Renato Tavares de Menezes, Andreas Steimer, Ralf Mikut</h3>
<p>Electronic control units (ECUs) are essential for many automobile components,
e.g. engine, anti-lock braking system (ABS), steering and airbags. For some
products, the 3D pose of each single ECU needs to be determined during series
production. Deep learning approaches can not easily be applied to this problem,
because labeled training data is not available in sufficient numbers. Thus, we
train state-of-the-art artificial neural networks (ANNs) on purely synthetic
training data, which is automatically created from a single CAD file. By
randomizing parameters during rendering of training images, we enable inference
on RGB images of a real sample part. In contrast to classic image processing
approaches, this data-driven approach poses only few requirements regarding the
measurement setup and transfers to related use cases with little development
effort.
</p>
<a href="http://arxiv.org/abs/2009.12312">arXiv:2009.12312</a> [<a href="http://arxiv.org/pdf/2009.12312">pdf</a>]

<h2>ML-based Visualization Recommendation: Learning to Recommend Visualizations from Data. (arXiv:2009.12316v1 [cs.IR])</h2>
<h3>Xin Qian, Ryan A. Rossi, Fan Du, Sungchul Kim, Eunyee Koh, Sana Malik, Tak Yeon Lee, Joel Chan</h3>
<p>Visualization recommendation seeks to generate, score, and recommend to users
useful visualizations automatically, and are fundamentally important for
exploring and gaining insights into a new or existing dataset quickly. In this
work, we propose the first end-to-end ML-based visualization recommendation
system that takes as input a large corpus of datasets and visualizations,
learns a model based on this data. Then, given a new unseen dataset from an
arbitrary user, the model automatically generates visualizations for that new
dataset, derive scores for the visualizations, and output a list of recommended
visualizations to the user ordered by effectiveness. We also describe an
evaluation framework to quantitatively evaluate visualization recommendation
models learned from a large corpus of visualizations and datasets. Through
quantitative experiments, a user study, and qualitative analysis, we show that
our end-to-end ML-based system recommends more effective and useful
visualizations compared to existing state-of-the-art rule-based systems.
Finally, we observed a strong preference by the human experts in our user study
towards the visualizations recommended by our ML-based system as opposed to the
rule-based system (5.92 from a 7-point Likert scale compared to only 3.45).
</p>
<a href="http://arxiv.org/abs/2009.12316">arXiv:2009.12316</a> [<a href="http://arxiv.org/pdf/2009.12316">pdf</a>]

<h2>Predicting COVID-19 cases using Bidirectional LSTM on multivariate time series. (arXiv:2009.12325v1 [cs.SI])</h2>
<h3>Ahmed Ben Said, Abdelkarim Erradi, Hussein Aly, Abdelmonem Mohamed</h3>
<p>Background: To assist policy makers in taking adequate decisions to stop the
spread of COVID-19 pandemic, accurate forecasting of the disease propagation is
of paramount importance. Materials and Methods: This paper presents a deep
learning approach to forecast the cumulative number of COVID-19 cases using
Bidirectional Long Short-Term Memory (Bi-LSTM) network applied to multivariate
time series. Unlike other forecasting techniques, our proposed approach first
groups the countries having similar demographic and socioeconomic aspects and
health sector indicators using K-Means clustering algorithm. The cumulative
cases data for each clustered countries enriched with data related to the
lockdown measures are fed to the Bidirectional LSTM to train the forecasting
model. Results: We validate the effectiveness of the proposed approach by
studying the disease outbreak in Qatar. Quantitative evaluation, using multiple
evaluation metrics, shows that the proposed technique outperforms state-of-art
forecasting approaches. Conclusion: Using data of multiple countries in
addition to lockdown measures improve accuracy of the forecast of daily
cumulative COVID-19 cases.
</p>
<a href="http://arxiv.org/abs/2009.12325">arXiv:2009.12325</a> [<a href="http://arxiv.org/pdf/2009.12325">pdf</a>]

<h2>SuPEr-SAM: Using the Supervision Signal from a Pose Estimator to Train a Spatial Attention Module for Personal Protective Equipment Recognition. (arXiv:2009.12339v1 [cs.CV])</h2>
<h3>Adrian Sandru, Georgian-Emilian Duta, Mariana-Iuliana Georgescu, Radu Tudor Ionescu</h3>
<p>We propose a deep learning method to automatically detect personal protective
equipment (PPE), such as helmets, surgical masks, reflective vests, boots and
so on, in images of people. Typical approaches for PPE detection based on deep
learning are (i) to train an object detector for items such as those listed
above or (ii) to train a person detector and a classifier that takes the
bounding boxes predicted by the detector and discriminates between people
wearing and people not wearing the corresponding PPE items. We propose a novel
and accurate approach that uses three components: a person detector, a body
pose estimator and a classifier. Our novelty consists in using the pose
estimator only at training time, to improve the prediction performance of the
classifier. We modify the neural architecture of the classifier by adding a
spatial attention mechanism, which is trained using supervision signal from the
pose estimator. In this way, the classifier learns to focus on PPE items, using
knowledge from the pose estimator with almost no computational overhead during
inference.
</p>
<a href="http://arxiv.org/abs/2009.12339">arXiv:2009.12339</a> [<a href="http://arxiv.org/pdf/2009.12339">pdf</a>]

<h2>Developing FB Chatbot Based on Deep Learning Using RASA Framework for University Enquiries. (arXiv:2009.12341v1 [cs.CL])</h2>
<h3>Yurio Windiatmoko, Ahmad Fathan Hidayatullah, Ridho Rahmadi</h3>
<p>Smart systems for Universities powered by Artificial Intelligence have been
massively developed to help humans in various tasks. The chatbot concept is not
something new in today society which is developing with recent technology.
College students or candidates of college students often need actual
information like asking for something to customer service, especially during
this pandemic, when it is difficult to have an immediate face-to-face meeting.
Chatbots are functionally helping in several things such as curriculum
information, admission for new students, schedule info for any lecture courses,
students grade information, and some adding features for Muslim worships
schedule, also weather forecast information. This Chatbot is developed by Deep
Learning models, which was adopted by an artificial intelligence model that
replicates human intelligence with some specific training schemes. This kind of
Deep Learning is based on RNN which has some specific memory savings scheme for
the Deep Learning Model, specifically this chatbot using LSTM which already
integrates by RASA framework. LSTM is also known as Long Short Term Memory
which efficiently saves some required memory but will remove some memory that
is not needed. This Chatbot uses the FB platform because of the FB users have
already reached up to 60.8% of its entire population in Indonesia. Here's the
chatbot only focuses on case studies at campus of the Magister Informatics FTI
University of Islamic Indonesia. This research is a first stage development
within fairly sufficient simulate data.
</p>
<a href="http://arxiv.org/abs/2009.12341">arXiv:2009.12341</a> [<a href="http://arxiv.org/pdf/2009.12341">pdf</a>]

<h2>Sequence-to-Sequence Load Disaggregation Using Multi-Scale Residual Neural Network. (arXiv:2009.12355v1 [cs.LG])</h2>
<h3>Gan Zhou, Zhi Li, Meng Fu, Yanjun Feng, Xingyao Wang, Chengwei Huang</h3>
<p>With the increased demand on economy and efficiency of measurement
technology, Non-Intrusive Load Monitoring (NILM) has received more and more
attention as a cost-effective way to monitor electricity and provide feedback
to users. Deep neural networks has been shown a great potential in the field of
load disaggregation. In this paper, firstly, a new convolutional model based on
residual blocks is proposed to avoid the degradation problem which traditional
networks more or less suffer from when network layers are increased in order to
learn more complex features. Secondly, we propose dilated convolution to
curtail the excessive quantity of model parameters and obtain bigger receptive
field, and multi-scale structure to learn mixed data features in a more
targeted way. Thirdly, we give details about generating training and test set
under certain rules. Finally, the algorithm is tested on real-house public
dataset, UK-DALE, with three existing neural networks. The results are compared
and analysed, the proposed model shows improvements on F1 score, MAE as well as
model complexity across different appliances.
</p>
<a href="http://arxiv.org/abs/2009.12355">arXiv:2009.12355</a> [<a href="http://arxiv.org/pdf/2009.12355">pdf</a>]

<h2>Deep Learning based Covert Attack Identification for Industrial Control Systems. (arXiv:2009.12360v1 [cs.LG])</h2>
<h3>Dan Li, Paritosh Ramanan, Nagi Gebraeel, Kamran Paynabar</h3>
<p>Cybersecurity of Industrial Control Systems (ICS) is drawing significant
concerns as data communication increasingly leverages wireless networks. A lot
of data-driven methods were developed for detecting cyberattacks, but few are
focused on distinguishing them from equipment faults. In this paper, we develop
a data-driven framework that can be used to detect, diagnose, and localize a
type of cyberattack called covert attacks on smart grids. The framework has a
hybrid design that combines an autoencoder, a recurrent neural network (RNN)
with a Long-Short-Term-Memory (LSTM) layer, and a Deep Neural Network (DNN).
This data-driven framework considers the temporal behavior of a generic
physical system that extracts features from the time series of the sensor
measurements that can be used for detecting covert attacks, distinguishing them
from equipment faults, as well as localize the attack/fault. We evaluate the
performance of the proposed method through a realistic simulation study on the
IEEE 14-bus model as a typical example of ICS. We compare the performance of
the proposed method with the traditional model-based method to show its
applicability and efficacy.
</p>
<a href="http://arxiv.org/abs/2009.12360">arXiv:2009.12360</a> [<a href="http://arxiv.org/pdf/2009.12360">pdf</a>]

<h2>Generate Novel Molecules With Target Properties Using Conditional Generative Models. (arXiv:2009.12368v1 [q-bio.BM])</h2>
<h3>Abhinav Sagar</h3>
<p>Drug discovery using deep learning has attracted a lot of attention of late
as it has obvious advantages like higher efficiency, less manual guessing and
faster process time. In this paper, we present a novel neural network for
generating small molecules similar to the ones in the training set. Our network
consists of an encoder made up of bi-GRU layers for converting the input
samples to a latent space, predictor for enhancing the capability of encoder
made up of 1D-CNN layers and a decoder comprised of uni-GRU layers for
reconstructing the samples from the latent space representation. Condition
vector in latent space is used for generating molecules with the desired
properties. We present the loss functions used for training our network,
experimental details and property prediction metrics. Our network outperforms
previous methods using Molecular weight, LogP and Quantitative Estimation of
Drug-likeness as the evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2009.12368">arXiv:2009.12368</a> [<a href="http://arxiv.org/pdf/2009.12368">pdf</a>]

<h2>On Two-Handed Planar Assembly Partitioning. (arXiv:2009.12369v1 [cs.CG])</h2>
<h3>Pankaj K. Agarwal, Boris Aronov, Tzvika Geft, Dan Halperin</h3>
<p>Assembly planning, which is a fundamental problem in robotics and automation,
aims to design a sequence of motions that will bring the separate constituent
parts of a product into their final placement in the product. It is convenient
to study assembly planning in reverse order, where the following key problem,
assembly partitioning, arises: Given a set of parts in their final placement in
a product, partition them into two sets, each regarded as a rigid body, which
we call a subassembly, such that these two subassemblies can be moved
sufficiently far away from each other, without colliding with one another. The
basic assembly planning problem is further complicated by practical
consideration such as how to hold the parts in a subassembly together.
Therefore, a desired property of a valid assembly partition is that each of the
two subassemblies will be connected.

We show that even an utterly simple case of the
connected-assembly-partitioning problem is hard: Given a connected set $A$ of
unit squares in the plane, each forming a distinct cell of the uniform integer
grid, find a subset $S\subset A$ such that $S$ can be rigidly translated to
infinity along a prescribed direction without colliding with $A\setminus S$,
and both subassemblies $S$ and $A\setminus S$ are each connected. We show that
this problem is NP-Complete, and by that settle an open problem posed by Wilson
et al. (1995) a quarter of a century ago.

We complement the hardness result with two positive results for the
aforementioned problem variant of grid squares. First, we show that it is fixed
parameter tractable and give an $O(2^k n^2)$-time algorithm, where $n=|A|$ and
$k=|S|$. Second, we describe a special case of this variant where a connected
partition can always be found in linear time. Each of the positive results
sheds further light on the special geometric structure of the problem at hand.
</p>
<a href="http://arxiv.org/abs/2009.12369">arXiv:2009.12369</a> [<a href="http://arxiv.org/pdf/2009.12369">pdf</a>]

<h2>Deep Echo State Network (DeepESN): A Brief Survey. (arXiv:1712.04323v4 [cs.LG] UPDATED)</h2>
<h3>Claudio Gallicchio, Alessio Micheli</h3>
<p>The study of deep recurrent neural networks (RNNs) and, in particular, of
deep Reservoir Computing (RC) is gaining an increasing research attention in
the neural networks community. The recently introduced Deep Echo State Network
(DeepESN) model opened the way to an extremely efficient approach for designing
deep neural networks for temporal data. At the same time, the study of DeepESNs
allowed to shed light on the intrinsic properties of state dynamics developed
by hierarchical compositions of recurrent layers, i.e. on the bias of depth in
RNNs architectural design. In this paper, we summarize the advancements in the
development, analysis and applications of DeepESNs.
</p>
<a href="http://arxiv.org/abs/1712.04323">arXiv:1712.04323</a> [<a href="http://arxiv.org/pdf/1712.04323">pdf</a>]

<h2>Reductive Clustering: An Efficient Linear-time Graph-based Divisive Cluster Analysis Approach. (arXiv:1806.08245v3 [cs.AI] UPDATED)</h2>
<h3>Ching Tarn, Yinan Zhang, Ye Feng</h3>
<p>We propose an efficient linear-time graph-based divisive cluster analysis
approach called Reductive Clustering. The approach tries to reveal the
hierarchical structural information through reducing the graph into a more
concise one repeatedly. With the reductions, the original graph can be divided
into subgraphs recursively, and a lite informative dendrogram is constructed
based on the divisions. The reduction consists of three steps: selection,
connection, and partition. First a subset of vertices of the graph are selected
as representatives to build a concise graph. The representatives are
re-connected to maintain a consistent structure with the previous graph. If
possible, the concise graph is divided into subgraphs, and each subgraph is
further reduced recursively until the termination condition is met. We discuss
the approach, along with several selection and connection methods, in detail
both theoretically and experimentally in this paper. Our implementations run in
linear time and achieve outstanding performance on various types of datasets.
Experimental results show that they outperform state-of-the-art clustering
algorithms with significantly less computing resource requirements.
</p>
<a href="http://arxiv.org/abs/1806.08245">arXiv:1806.08245</a> [<a href="http://arxiv.org/pdf/1806.08245">pdf</a>]

<h2>High-dimensional Bayesian optimization using low-dimensional feature spaces. (arXiv:1902.10675v7 [stat.ML] UPDATED)</h2>
<h3>Riccardo Moriconi, Marc P. Deisenroth, K. S. Sesh Kumar</h3>
<p>Bayesian optimization (BO) is a powerful approach for seeking the global
optimum of expensive black-box functions and has proven successful for fine
tuning hyper-parameters of machine learning models. However, BO is practically
limited to optimizing 10--20 parameters. To scale BO to high dimensions, we
usually make structural assumptions on the decomposition of the objective
and\slash or exploit the intrinsic lower dimensionality of the problem, e.g. by
using linear projections. We could achieve a higher compression rate with
nonlinear projections, but learning these nonlinear embeddings typically
requires much data. This contradicts the BO objective of a relatively small
evaluation budget. To address this challenge, we propose to learn a
low-dimensional feature space jointly with (a) the response surface and (b) a
reconstruction mapping. Our approach allows for optimization of BO's
acquisition function in the lower-dimensional subspace, which significantly
simplifies the optimization problem. We reconstruct the original parameter
space from the lower-dimensional subspace for evaluating the black-box
function. For meaningful exploration, we solve a constrained optimization
problem.
</p>
<a href="http://arxiv.org/abs/1902.10675">arXiv:1902.10675</a> [<a href="http://arxiv.org/pdf/1902.10675">pdf</a>]

<h2>Learning Your Way Without Map or Compass: Panoramic Target Driven Visual Navigation. (arXiv:1909.09295v2 [cs.RO] UPDATED)</h2>
<h3>David Watkins-Valls, Jingxi Xu, Nicholas Waytowich, Peter Allen</h3>
<p>We present a robot navigation system that uses an imitation learning
framework to successfully navigate in complex environments. Our framework takes
a pre-built 3D scan of a real environment and trains an agent from
pre-generated expert trajectories to navigate to any position given a panoramic
view of the goal and the current visual input without relying on map, compass,
odometry, or relative position of the target at runtime. Our end-to-end trained
agent uses RGB and depth (RGBD) information and can handle large environments
(up to $1031m^2$) across multiple rooms (up to $40$) and generalizes to unseen
targets. We show that when compared to several baselines our method (1)
requires fewer training examples and less training time, (2) reaches the goal
location with higher accuracy, and (3) produces better solutions with shorter
paths for long-range navigation tasks.
</p>
<a href="http://arxiv.org/abs/1909.09295">arXiv:1909.09295</a> [<a href="http://arxiv.org/pdf/1909.09295">pdf</a>]

<h2>ALET (Automated Labeling of Equipment and Tools): A Dataset, a Baseline and a Usecase for Tool Detection in the Wild. (arXiv:1910.11713v2 [cs.CV] UPDATED)</h2>
<h3>Fatih Can Kurnaz, Burak Hocao&#x11f;lu, Mert Kaan Y&#x131;lmaz, &#x130;dil S&#xfc;lo, Sinan Kalkan (KOVAN Research Lab, Dept. of Computer Engineering, Middle East Technical University, Ankara, Turkey)</h3>
<p>Robots collaborating with humans in realistic environments will need to be
able to detect the tools that can be used and manipulated. However, there is no
available dataset or study that addresses this challenge in real settings. In
this paper, we fill this gap by providing an extensive dataset (METU-ALET) for
detecting farming, gardening, office, stonemasonry, vehicle, woodworking and
workshop tools. The scenes correspond to sophisticated environments with or
without humans using the tools. The scenes we consider introduce several
challenges for object detection, including the small scale of the tools, their
articulated nature, occlusion, inter-class invariance, etc. Moreover, we train
and compare several state of the art deep object detectors (including Faster
R-CNN, YOLO and RetinaNet) on our dataset. We observe that the detectors have
difficulty in detecting especially small-scale tools or tools that are visually
similar to parts of other tools. This in turn supports the importance of our
dataset and paper. With the dataset, the code and the trained models, our work
provides a basis for further research into tools and their use in robotics
applications.
</p>
<a href="http://arxiv.org/abs/1910.11713">arXiv:1910.11713</a> [<a href="http://arxiv.org/pdf/1910.11713">pdf</a>]

<h2>Disentangle, align and fuse for multimodal and semi-supervised image segmentation. (arXiv:1911.04417v4 [cs.CV] UPDATED)</h2>
<h3>Agisilaos Chartsias, Giorgos Papanastasiou, Chengjia Wang, Scott Semple, David E. Newby, Rohan Dharmakumar, Sotirios A. Tsaftaris</h3>
<p>Magnetic resonance (MR) protocols rely on several sequences to assess
pathology and organ status properly. Despite advances in image analysis, we
tend to treat each sequence, here termed modality, in isolation. Taking
advantage of the common information shared between modalities (an organ's
anatomy) is beneficial for multi-modality processing and learning. However, we
must overcome inherent anatomical misregistrations and disparities in signal
intensity across the modalities to obtain this benefit. We present a method
that offers improved segmentation accuracy of the modality of interest (over a
single input model), by learning to leverage information present in other
modalities, even if few (semi-supervised) or no (unsupervised) annotations are
available for this specific modality. Core to our method is learning a
disentangled decomposition into anatomical and imaging factors. Shared
anatomical factors from the different inputs are jointly processed and fused to
extract more accurate segmentation masks. Image misregistrations are corrected
with a Spatial Transformer Network, which non-linearly aligns the anatomical
factors. The imaging factor captures signal intensity characteristics across
different modality data and is used for image reconstruction, enabling
semi-supervised learning. Temporal and slice pairing between inputs are learned
dynamically. We demonstrate applications in Late Gadolinium Enhanced (LGE) and
Blood Oxygenation Level Dependent (BOLD) cardiac segmentation, as well as in T2
abdominal segmentation.
</p>
<a href="http://arxiv.org/abs/1911.04417">arXiv:1911.04417</a> [<a href="http://arxiv.org/pdf/1911.04417">pdf</a>]

<h2>Secure Quantum Extraction Protocols. (arXiv:1911.07672v2 [quant-ph] UPDATED)</h2>
<h3>Prabhanjan Ananth, Rolando L. La Placa</h3>
<p>Knowledge extraction, typically studied in the classical setting, is at the
heart of several cryptographic protocols. We introduce the notion of secure
quantum extraction protocols. A secure quantum extraction protocol for an NP
relation $\mathcal{R}$ is a classical interactive protocol between a sender and
a receiver, where the sender gets the instance $z$ and a witness $w$, while the
receiver only gets the instance $z$. For any efficient quantum adversarial
sender (who follows the protocol but can choose its own randomness), there
exists a quantum extractor that can extract a witness $w'$ such that $(z,w')
\in \mathcal{R}$ while a malicious receiver should not be able to output any
valid witness. We study and construct two types of secure quantum extraction
protocols.

(1) Quantum extraction protocols secure against quantum malicious receivers
based on quantum fully homomorphic encryption satisfying some mild properties
and quantum hardness of learning with errors. In this construction, we
introduce a non black box technique in the quantum setting. All previous
extraction techniques in the quantum setting were solely based on quantum
rewinding.

(2) Quantum extraction protocols secure against classical malicious receivers
based on quantum hardness of learning with errors.

As an application, based on the quantum hardness of learning with errors, we
present a construction of constant round quantum zero-knowledge argument
systems for NP that guarantee security even against quantum malicious
verifiers; however, our soundness only holds against classical probabilistic
polynomial time adversaries. Prior to our work, such protocols were known
based, additionally, on the assumptions of decisional Diffie-Hellman (or other
cryptographic assumptions that do not hold against polynomial time quantum
algorithms).
</p>
<a href="http://arxiv.org/abs/1911.07672">arXiv:1911.07672</a> [<a href="http://arxiv.org/pdf/1911.07672">pdf</a>]

<h2>Managing Machine Learning Workflow Components. (arXiv:1912.05665v2 [cs.LG] UPDATED)</h2>
<h3>Marcio Moreno, V&#xed;tor Louren&#xe7;o, Sandro Rama Fiorini, Polyana Costa, Rafael Brand&#xe3;o, Daniel Civitarese, Renato Cerqueira</h3>
<p>Machine Learning Workflows (MLWfs) have become essential and a disruptive
approach in problem-solving over several industries. However, the development
process of MLWfs may be complicated, hard to achieve, time-consuming, and
error-prone. To handle this problem, in this paper, we introduce machine
learning workflow management (MLWfM) as a technique to aid the development and
reuse of MLWfs and their components through three aspects: representation,
execution, and creation. More precisely, we discuss our approach to structure
the MLWfs' components and their metadata to aid retrieval and reuse of
components in new MLWfs. Also, we consider the execution of these components
within a tool. The hybrid knowledge representation, called Hyperknowledge,
frames our methodology, supporting the three MLWfM's aspects. To validate our
approach, we show a practical use case in the Oil &amp; Gas industry.
</p>
<a href="http://arxiv.org/abs/1912.05665">arXiv:1912.05665</a> [<a href="http://arxiv.org/pdf/1912.05665">pdf</a>]

<h2>Targeted transfer learning to improve performance in small medical physics datasets. (arXiv:1912.06761v2 [cs.LG] UPDATED)</h2>
<h3>Miguel Romero, Yannet Interian, Timothy Solberg, Gilmer Valdes</h3>
<p>The growing use of Machine Learning has produced significant advances in many
fields. For image-based tasks, however, the use of deep learning remains
challenging in small datasets. In this article, we review, evaluate and compare
the current state-of-the-art techniques in training neural networks to
elucidate which techniques work best for small datasets. We further propose a
path forward for the improvement of model accuracy in medical imaging
applications. We observed best results from one cycle training, discriminative
learning rates with gradual freezing and parameter modification after transfer
learning. We also established that when datasets are small, transfer learning
plays an important role beyond parameter initialization by reusing previously
learned features. Surprisingly we observed that there is little advantage in
using pre-trained networks in images from another part of the body compared to
Imagenet. On the contrary, if images from the same part of the body are
available then transfer learning can produce a significant improvement in
performance with as little as 50 images in the training data.
</p>
<a href="http://arxiv.org/abs/1912.06761">arXiv:1912.06761</a> [<a href="http://arxiv.org/pdf/1912.06761">pdf</a>]

<h2>Knowledge and Social Relatedness Shape Research Portfolio Diversification. (arXiv:2002.06419v2 [physics.soc-ph] UPDATED)</h2>
<h3>Giorgio Tripodi, Francesca Chiaromonte, Fabrizio Lillo</h3>
<p>Scientific discovery is shaped by scientists' choices and thus by their
career patterns. The increasing knowledge required to work at the frontier of
science makes it harder for an individual to embark on unexplored paths. Yet
collaborations can reduce learning costs -- albeit at the expense of increased
coordination costs. In this article, we use data on the publication histories
of a very large sample of physicists to measure the effects of knowledge and
social relatedness on their diversification strategies. Using bipartite
networks, we compute a measure of topics similarity and a measure of social
proximity. We find that scientists' strategies are not random, and that they
are significantly affected by both. Knowledge relatedness across topics
explains $\approx 10\%$ of logistic regression deviances and social relatedness
as much as $\approx 30\%$, suggesting that science is an eminently social
enterprise: when scientists move out of their core specialization, they do so
through collaborations. Interestingly, we also find a significant negative
interaction between knowledge and social relatedness, suggesting that the
farther scientists move from their specialization, the more they rely on
collaborations. Our results provide a starting point for broader quantitative
analyses of scientific diversification strategies, which could also be extended
to the domain of technological innovation -- offering insights from a
comparative and policy perspective.
</p>
<a href="http://arxiv.org/abs/2002.06419">arXiv:2002.06419</a> [<a href="http://arxiv.org/pdf/2002.06419">pdf</a>]

<h2>ARMA Nets: Expanding Receptive Field for Dense Prediction. (arXiv:2002.11609v2 [cs.CV] UPDATED)</h2>
<h3>Jiahao Su, Shiqi Wang, Furong Huang</h3>
<p>Global information is essential for dense prediction problems, whose goal is
to compute a discrete or continuous label for each pixel in the images.
Traditional convolutional layers in neural networks, initially designed for
image classification, are restrictive in these problems since the filter size
limits their receptive fields. In this work, we propose to replace any
traditional convolutional layer with an autoregressive moving-average (ARMA)
layer, a novel module with an adjustable receptive field controlled by the
learnable autoregressive coefficients. Compared with traditional convolutional
layers, our ARMA layer enables explicit interconnections of the output neurons
and learns its receptive field by adapting the autoregressive coefficients of
the interconnections. ARMA layer is adjustable to different types of tasks: for
tasks where global information is crucial, it is capable of learning relatively
large autoregressive coefficients to allow for an output neuron's receptive
field covering the entire input; for tasks where only local information is
required, it can learn small or near zero autoregressive coefficients and
automatically reduces to a traditional convolutional layer. We show both
theoretically and empirically that the effective receptive field of networks
with ARMA layers (named as ARMA networks) expands with larger autoregressive
coefficients. We also provably solve the instability problem of learning and
prediction in the ARMA layer through a re-parameterization mechanism.
Additionally, we demonstrate that ARMA networks substantially improve their
baselines on challenging dense prediction tasks including video prediction and
semantic segmentation.
</p>
<a href="http://arxiv.org/abs/2002.11609">arXiv:2002.11609</a> [<a href="http://arxiv.org/pdf/2002.11609">pdf</a>]

<h2>Vector symbolic architectures for context-free grammars. (arXiv:2003.05171v2 [cs.CL] UPDATED)</h2>
<h3>Peter beim Graben, Markus Huber, Werner Meyer, Ronald R&#xf6;mer, Matthias Wolff</h3>
<p>Background / introduction. Vector symbolic architectures (VSA) are a viable
approach for the hyperdimensional representation of symbolic data, such as
documents, syntactic structures, or semantic frames. Methods. We present a
rigorous mathematical framework for the representation of phrase structure
trees and parse trees of context-free grammars (CFG) in Fock space, i.e.
infinite-dimensional Hilbert space as being used in quantum field theory. We
define a novel normal form for CFG by means of term algebras. Using a recently
developed software toolbox, called FockBox, we construct Fock space
representations for the trees built up by a CFG left-corner (LC) parser.
Results. We prove a universal representation theorem for CFG term algebras in
Fock space and illustrate our findings through a low-dimensional principal
component projection of the LC parser states. Conclusions. Our approach could
leverage the development of VSA for explainable artificial intelligence (XAI)
by means of hyperdimensional deep neural computation. It could be of
significance for the improvement of cognitive user interfaces and other
applications of VSA in machine learning.
</p>
<a href="http://arxiv.org/abs/2003.05171">arXiv:2003.05171</a> [<a href="http://arxiv.org/pdf/2003.05171">pdf</a>]

<h2>Certified Defenses for Adversarial Patches. (arXiv:2003.06693v2 [cs.CR] UPDATED)</h2>
<h3>Ping-Yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph Studer, Tom Goldstein</h3>
<p>Adversarial patch attacks are among one of the most practical threat models
against real-world computer vision systems. This paper studies certified and
empirical defenses against patch attacks. We begin with a set of experiments
showing that most existing defenses, which work by pre-processing input images
to mitigate adversarial patches, are easily broken by simple white-box
adversaries. Motivated by this finding, we propose the first certified defense
against patch attacks, and propose faster methods for its training.
Furthermore, we experiment with different patch shapes for testing, obtaining
surprisingly good robustness transfer across shapes, and present preliminary
results on certified defense against sparse attacks. Our complete
implementation can be found on:
https://github.com/Ping-C/certifiedpatchdefense.
</p>
<a href="http://arxiv.org/abs/2003.06693">arXiv:2003.06693</a> [<a href="http://arxiv.org/pdf/2003.06693">pdf</a>]

<h2>Cross-lingual Supervision Improves Unsupervised Neural Machine Translation. (arXiv:2004.03137v2 [cs.CL] UPDATED)</h2>
<h3>Mingxuan Wang, Hongxiao Bai, Hai Zhao, Lei Li</h3>
<p>Neural machine translation~(NMT) is ineffective for zero-resource languages.
Recent works exploring the possibility of unsupervised neural machine
translation (UNMT) with only monolingual data can achieve promising results.
However, there are still big gaps between UNMT and NMT with parallel
supervision. In this work, we introduce a multilingual unsupervised NMT
(\method) framework to leverage weakly supervised signals from high-resource
language pairs to zero-resource translation directions. More specifically, for
unsupervised language pairs \texttt{En-De}, we can make full use of the
information from parallel dataset \texttt{En-Fr} to jointly train the
unsupervised translation directions all in one model. \method is based on
multilingual models which require no changes to the standard unsupervised NMT.
Empirical results demonstrate that \method significantly improves the
translation quality by more than 3 BLEU score on six benchmark unsupervised
translation directions.
</p>
<a href="http://arxiv.org/abs/2004.03137">arXiv:2004.03137</a> [<a href="http://arxiv.org/pdf/2004.03137">pdf</a>]

<h2>VGGSound: A Large-scale Audio-Visual Dataset. (arXiv:2004.14368v2 [cs.CV] UPDATED)</h2>
<h3>Honglie Chen, Weidi Xie, Andrea Vedaldi, Andrew Zisserman</h3>
<p>Our goal is to collect a large-scale audio-visual dataset with low label
noise from videos in the wild using computer vision techniques. The resulting
dataset can be used for training and evaluating audio recognition models. We
make three contributions. First, we propose a scalable pipeline based on
computer vision techniques to create an audio dataset from open-source media.
Our pipeline involves obtaining videos from YouTube; using image classification
algorithms to localize audio-visual correspondence; and filtering out ambient
noise using audio verification. Second, we use this pipeline to curate the
VGGSound dataset consisting of more than 210k videos for 310 audio classes.
Third, we investigate various Convolutional Neural Network~(CNN) architectures
and aggregation approaches to establish audio recognition baselines for our new
dataset. Compared to existing audio datasets, VGGSound ensures audio-visual
correspondence and is collected under unconstrained conditions. Code and the
dataset are available at this http URL
</p>
<a href="http://arxiv.org/abs/2004.14368">arXiv:2004.14368</a> [<a href="http://arxiv.org/pdf/2004.14368">pdf</a>]

<h2>Explainable Link Prediction for Emerging Entities in Knowledge Graphs. (arXiv:2005.00637v2 [cs.CL] UPDATED)</h2>
<h3>Rajarshi Bhowmik, Gerard de Melo</h3>
<p>Despite their large-scale coverage, cross-domain knowledge graphs invariably
suffer from inherent incompleteness and sparsity. Link prediction can alleviate
this by inferring a target entity, given a source entity and a query relation.
Recent embedding-based approaches operate in an uninterpretable latent semantic
vector space of entities and relations, while path-based approaches operate in
the symbolic space, making the inference process explainable. However, these
approaches typically consider static snapshots of the knowledge graphs,
severely restricting their applicability for evolving knowledge graphs with
newly emerging entities. To overcome this issue, we propose an inductive
representation learning framework that is able to learn representations of
previously unseen entities. Our method finds reasoning paths between source and
target entities, thereby making the link prediction for unseen entities
interpretable and providing support evidence for the inferred link.
</p>
<a href="http://arxiv.org/abs/2005.00637">arXiv:2005.00637</a> [<a href="http://arxiv.org/pdf/2005.00637">pdf</a>]

<h2>Adversarial Learning for Supervised and Semi-supervised Relation Extraction in Biomedical Literature. (arXiv:2005.04277v2 [cs.CL] UPDATED)</h2>
<h3>Peng Su, K. Vijay-Shanker</h3>
<p>Adversarial training is a technique of improving model performance by
involving adversarial examples in the training process. In this paper, we
investigate adversarial training with multiple adversarial examples to benefit
the relation extraction task. We also apply adversarial training technique in
semi-supervised scenarios to utilize unlabeled data. The evaluation results on
protein-protein interaction and protein subcellular localization task
illustrate adversarial training provides improvement on the supervised model,
and is also effective on involving unlabeled data in the semi-supervised
training case. In addition, our method achieves state-of-the-art performance on
two benchmarking datasets.
</p>
<a href="http://arxiv.org/abs/2005.04277">arXiv:2005.04277</a> [<a href="http://arxiv.org/pdf/2005.04277">pdf</a>]

<h2>Aortic Pressure Forecasting with Deep Sequence Learning. (arXiv:2005.05502v2 [cs.LG] UPDATED)</h2>
<h3>Rui Wang, Eliza Huang, Uma Chandrasekaran, Rose Yu</h3>
<p>Mean aortic pressure (MAP) is a major determinant of perfusion in all organs
systems. The ability to forecast MAP would enhance the ability of physicians to
estimate prognosis of the patient and assist in early detection of hemodynamic
instability. However, forecasting MAP is challenging because the blood pressure
(BP) time series is noisy and can be highly non-stationary. The aim of this
study was to forecast the mean aortic pressure five minutes in advance, using
the 25 Hz time series data of previous five minutes as input. We provide a
benchmark study of different deep learning models for BP forecasting. We
investigate a left ventricular dwelling transvalvular micro-axial device, the
Impella, in patients undergoing high-risk percutaneous intervention. The
Impella provides hemodynamic support, thus aiding in native heart function
recovery. It is also equipped with pressure sensors to capture high frequency
MAP measurements at origin, instead of peripherally. Our dataset and the
clinical application is novel in the BP forecasting field. We performed a
comprehensive study on time series with increasing, decreasing, and stationary
trends. The experiments show that recurrent neural networks with Legendre
Memory Unit achieve the best performance with an overall forecasting error of
1.8 mmHg.
</p>
<a href="http://arxiv.org/abs/2005.05502">arXiv:2005.05502</a> [<a href="http://arxiv.org/pdf/2005.05502">pdf</a>]

<h2>Cross-Domain Imitation Learning with a Dual Structure. (arXiv:2006.01494v3 [cs.LG] UPDATED)</h2>
<h3>Sungho Choi, Seungyul Han, Woojun Kim, Youngchul Sung</h3>
<p>In this paper, we consider cross-domain imitation learning (CDIL) in which an
agent in a target domain learns a policy to perform well in the target domain
by observing expert demonstrations in a source domain without accessing any
reward function. In order to overcome the domain difference for imitation
learning, we propose a dual-structured learning method. The proposed learning
method extracts two feature vectors from each input observation such that one
vector contains domain information and the other vector contains policy
expertness information, and then enhances feature vectors by synthesizing new
feature vectors containing both target-domain and policy expertness
information. The proposed CDIL method is tested on several MuJoCo tasks where
the domain difference is determined by image angles or colors. Numerical
results show that the proposed method shows superior performance in CDIL to
other existing algorithms and achieves almost the same performance as imitation
learning without domain difference.
</p>
<a href="http://arxiv.org/abs/2006.01494">arXiv:2006.01494</a> [<a href="http://arxiv.org/pdf/2006.01494">pdf</a>]

<h2>From Federated Learning to Fog Learning: Towards Large-Scale Distributed Machine Learning in Heterogeneous Wireless Networks. (arXiv:2006.03594v2 [cs.DC] UPDATED)</h2>
<h3>Seyyedali Hosseinalipour, Christopher G. Brinton, Vaneet Aggarwal, Huaiyu Dai, Mung Chiang</h3>
<p>Machine learning (ML) tasks are becoming ubiquitous in today's network
applications. Federated learning has emerged recently as a technique for
training ML models at the network edge by leveraging processing capabilities
across the nodes that collect the data. There are several challenges with
employing conventional federated learning in contemporary networks, due to the
significant heterogeneity in compute and communication capabilities that exist
across devices. To address this, we advocate a new learning paradigm called fog
learning which will intelligently distribute ML model training across the
continuum of nodes from edge devices to cloud servers. Fog learning enhances
federated learning along three major dimensions: network, heterogeneity, and
proximity. It considers a multi-layer hybrid learning framework consisting of
heterogeneous devices with various proximities. It accounts for the topology
structures of the local networks among the heterogeneous nodes at each network
layer, orchestrating them for collaborative/cooperative learning through
device-to-device (D2D) communications. This migrates from star network
topologies used for parameter transfers in federated learning to more
distributed topologies at scale. We discuss several open research directions to
realizing fog learning.
</p>
<a href="http://arxiv.org/abs/2006.03594">arXiv:2006.03594</a> [<a href="http://arxiv.org/pdf/2006.03594">pdf</a>]

<h2>DcardNet: Diabetic Retinopathy Classification at Multiple Levels Based on Structural and Angiographic Optical Coherence Tomography. (arXiv:2006.05480v2 [eess.IV] UPDATED)</h2>
<h3>Pengxiao Zang, Liqin Gao, Tristan T. Hormel, Jie Wang, Qisheng You, Thomas S. Hwang, Yali Jia</h3>
<p>Objective: Optical coherence tomography (OCT) and its angiography (OCTA) have
several advantages for the early detection and diagnosis of diabetic
retinopathy (DR). However, automated, complete DR classification frameworks
based on both OCT and OCTA data have not been proposed. In this study, a
convolutional neural network (CNN) based method is proposed to fulfill a DR
classification framework using en face OCT and OCTA. Methods: A densely and
continuously connected neural network with adaptive rate dropout (DcardNet) is
designed for the DR classification. In addition, adaptive label smoothing was
proposed and used to suppress overfitting. Three separate classification levels
are generated for each case based on the International Clinical Diabetic
Retinopathy scale. At the highest level the network classifies scans as
referable or non-referable for DR. The second level classifies the eye as
non-DR, non-proliferative DR (NPDR), or proliferative DR (PDR). The last level
classifies the case as no DR, mild and moderate NPDR, severe NPDR, and PDR.
Results: We used 10-fold cross-validation with 10% of the data to assess the
networks performance. The overall classification accuracies of the three levels
were 95.7%, 85.0%, and 71.0% respectively. Conclusion/Significance: A reliable,
sensitive and specific automated classification framework for referral to an
ophthalmologist can be a key technology for reducing vision loss related to DR.
</p>
<a href="http://arxiv.org/abs/2006.05480">arXiv:2006.05480</a> [<a href="http://arxiv.org/pdf/2006.05480">pdf</a>]

<h2>A Primer on Large Intelligent Surface (LIS) for Wireless Sensing in an Industrial Setting. (arXiv:2006.06563v2 [eess.SP] UPDATED)</h2>
<h3>Cristian J. Vaca-Rubio, Pablo Ramirez-Espinosa, Robin Jess Williams, Kimmo Kansanen, Zheng-Hua Tan, Elisabeth de Carvalho, Petar Popovski</h3>
<p>One of the beyond-5G developments that is often highlighted is the
integration of wireless communication and radio sensing. This paper addresses
the potential of communication-sensing integration of Large Intelligent
Surfaces (LIS) in an exemplary Industry 4.0 scenario. Besides the potential for
high throughput and efficient multiplexing of wireless links, an LIS can offer
a high-resolution rendering of the propagation environment. This is because, in
an indoor setting, it can be placed in proximity to the sensed phenomena, while
the high resolution is offered by densely spaced tiny antennas deployed over a
large area. By treating an LIS as a radio image of the environment, we develop
sensing techniques that leverage the usage of computer vision combined with
machine learning. We test these methods for a scenario where we need to detect
whether an industrial robot deviates from a predefined route. The results show
that the LIS-based sensing offers high precision and has a high application
potential in indoor industrial environments.
</p>
<a href="http://arxiv.org/abs/2006.06563">arXiv:2006.06563</a> [<a href="http://arxiv.org/pdf/2006.06563">pdf</a>]

<h2>MSMD-Net: Deep Stereo Matching with Multi-scale and Multi-dimension Cost Volume. (arXiv:2006.12797v2 [cs.CV] UPDATED)</h2>
<h3>Zhelun Shen, Yuchao Dai, Zhibo Rao</h3>
<p>Deep end-to-end learning based stereo matching methods have achieved great
success as witnessed by the leaderboards across different benchmarking datasets
(KITTI, Middlebury, ETH3D, etc). However, real scenarios not only require
approaches to have state-of-the-art performance but also real-time speed and
domain-across generalization, which cannot be satisfied by existing methods. In
this paper, we propose MSMD-Net (Multi-Scale and Multi-Dimension) to construct
multi-scale and multi-dimension cost volume. At the multi-scale level, we
generate four 4D combination volumes at different scales and integrate them
with an encoder-decoder process to predict an initial disparity estimation. At
the multi-dimension level, we additionally construct a 3D warped correlation
volume and use it to refine the initial disparity map with residual learning.
These two dimensional cost volumes are complementary to each other and can
boost the performance of disparity estimation. Additionally, we propose a
switch training strategy to alleviate the overfitting issue appeared in the
pre-training process and further improve the generalization ability and
accuracy of final disparity estimation. Our proposed method was evaluated on
several benchmark datasets and ranked first on KITTI 2012 leaderboard and
second on KITTI 2015 leaderboard as of September 9. In addition, our method
shows strong domain-across generalization and outperforms best prior work by a
noteworthy margin with three or even five times faster speed. The code of
MSMD-Net is available at https://github.com/gallenszl/MSMD-Net.
</p>
<a href="http://arxiv.org/abs/2006.12797">arXiv:2006.12797</a> [<a href="http://arxiv.org/pdf/2006.12797">pdf</a>]

<h2>flexgrid2vec: Learning Efficient Visual Representations Vectors. (arXiv:2007.15444v4 [cs.CV] UPDATED)</h2>
<h3>Ali Hamdi, Du Yong Kim, Flora D. Salim</h3>
<p>We propose flexgrid2vec, a novel approach for image representation learning.
Existing visual representation methods suffer from several issues, including
the need for highly intensive computation, the risk of losing in-depth
structural information, and the specificity of the method to certain shapes or
objects. flexgrid2vec converts an image to a low-dimensional feature vector. We
represent each image with a graph of flexible, unique node locations and edge
distances. flexgrid2vec is a multi-channel Graph Convolutional Network (GCN)
that learns features of the most representative image patches. We have
investigated both spectral and non-spectral implementations of the GCN
node-embedding. Specifically, we compare different node aggregation methods
based on vector summation, concatenation, and normalisation with node's
eigenvector centrality. We compare the performance of flexgrid2vec with a set
of state-of-the-art visual representation learning models on binary and
multi-class image classification tasks. Although we utilise imbalanced,
low-size datasets, flexgrid2vec shows stable and outstanding results against
well-known base classifiers.
</p>
<a href="http://arxiv.org/abs/2007.15444">arXiv:2007.15444</a> [<a href="http://arxiv.org/pdf/2007.15444">pdf</a>]

<h2>Variable Compliance Control for Robotic Peg-in-Hole Assembly: A Deep Reinforcement Learning Approach. (arXiv:2008.10224v2 [cs.RO] UPDATED)</h2>
<h3>Beltran-Hernandez Cristian Camilo, Damien Petit, Ixchel G. Ramirez-Alpizar, Kensuke Harada</h3>
<p>Industrial robot manipulators are playing a more significant role in modern
manufacturing industries. Though peg-in-hole assembly is a common industrial
task which has been extensively researched, safely solving complex high
precision assembly in an unstructured environment remains an open problem.
Reinforcement Learning (RL) methods have been proven successful in solving
manipulation tasks autonomously. However, RL is still not widely adopted on
real robotic systems because working with real hardware entails additional
challenges, especially when using position-controlled manipulators. The main
contribution of this work is a learning-based method to solve peg-in-hole tasks
with position uncertainty of the hole. We proposed the use of an off-policy
model-free reinforcement learning method and bootstrap the training speed by
using several transfer learning techniques (sim2real) and domain randomization.
Our proposed learning framework for position-controlled robots was extensively
evaluated on contact-rich insertion tasks on a variety of environments.
</p>
<a href="http://arxiv.org/abs/2008.10224">arXiv:2008.10224</a> [<a href="http://arxiv.org/pdf/2008.10224">pdf</a>]

<h2>SeqROCTM: A Matlab toolbox for the analysis of Sequence of Random Objects driven by Context Tree Models. (arXiv:2009.06371v2 [cs.AI] UPDATED)</h2>
<h3>Noslen Hern&#xe1;ndez, Aline Duarte</h3>
<p>In several research problems we face probabilistic sequences of inputs (e.g.,
sequence of stimuli) from which an agent generates a corresponding sequence of
responses and it is of interest to model/discover some kind of relation between
them. To model such relation in the context of statistical learning in
neuroscience, a new class of stochastic process have been introduced [5],
namely sequences of random objects driven by context tree models. In this paper
we introduce a freely available Matlab toolbox (SeqROCTM) that implements three
model selection methods to make inference about the parameters of this kind of
stochastic process.
</p>
<a href="http://arxiv.org/abs/2009.06371">arXiv:2009.06371</a> [<a href="http://arxiv.org/pdf/2009.06371">pdf</a>]

<h2>Neither Private Nor Fair: Impact of Data Imbalance on Utility and Fairness in Differential Privacy. (arXiv:2009.06389v2 [cs.LG] UPDATED)</h2>
<h3>Tom Farrand, Fatemehsadat Mireshghallah, Sahib Singh, Andrew Trask</h3>
<p>Deployment of deep learning in different fields and industries is growing day
by day due to its performance, which relies on the availability of data and
compute. Data is often crowd-sourced and contains sensitive information about
its contributors, which leaks into models that are trained on it. To achieve
rigorous privacy guarantees, differentially private training mechanisms are
used. However, it has recently been shown that differential privacy can
exacerbate existing biases in the data and have disparate impacts on the
accuracy of different subgroups of data. In this paper, we aim to study these
effects within differentially private deep learning. Specifically, we aim to
study how different levels of imbalance in the data affect the accuracy and the
fairness of the decisions made by the model, given different levels of privacy.
We demonstrate that even small imbalances and loose privacy guarantees can
cause disparate impacts.
</p>
<a href="http://arxiv.org/abs/2009.06389">arXiv:2009.06389</a> [<a href="http://arxiv.org/pdf/2009.06389">pdf</a>]

<h2>Efficient multi-descriptor fusion for non-intrusive appliance recognition. (arXiv:2009.08210v2 [cs.CY] UPDATED)</h2>
<h3>Yassine Himeur, Abdullah Alsalemi, Faycal Bensaali, Abbes Amira</h3>
<p>Consciousness about power consumption at the appliance level can assist user
in promoting energy efficiency in households. In this paper, a superior
non-intrusive appliance recognition method that can provide particular
consumption footprints of each appliance is proposed. Electrical devices are
well recognized by the combination of different descriptors via the following
steps: (a) investigating the applicability along with performance comparability
of several time-domain (TD) feature extraction schemes; (b) exploring their
complementary features; and (c) making use of a new design of the ensemble
bagging tree (EBT) classifier. Consequently, a powerful feature extraction
technique based on the fusion of TD features is proposed, namely fTDF, aimed at
improving the feature discrimination ability and optimizing the recognition
task. An extensive experimental performance assessment is performed on two
different datasets called the GREEND and WITHED, where power consumption
signatures were gathered at 1 Hz and 44000 Hz sampling frequencies,
respectively. The obtained results revealed prime efficiency of the proposed
fTDF based EBT system in comparison with other TD descriptors and machine
learning classifiers.
</p>
<a href="http://arxiv.org/abs/2009.08210">arXiv:2009.08210</a> [<a href="http://arxiv.org/pdf/2009.08210">pdf</a>]

<h2>Multimodal Safety-Critical Scenarios Generation for Decision-Making Algorithms Evaluation. (arXiv:2009.08311v2 [cs.LG] UPDATED)</h2>
<h3>Wenhao Ding, Baiming Chen, Bo Li, Kim Ji Eun, Ding Zhao</h3>
<p>Existing neural network-based autonomous systems are shown to be vulnerable
against adversarial attacks, therefore sophisticated evaluation on their
robustness is of great importance. However, evaluating the robustness only
under the worst-case scenarios based on known attacks is not comprehensive, not
to mention that some of them even rarely occur in the real world. In addition,
the distribution of safety-critical data is usually multimodal, while most
traditional attacks and evaluation methods focus on a single modality. To solve
the above challenges, we propose a flow-based multimodal safety-critical
scenario generator for evaluating decisionmaking algorithms. The proposed
generative model is optimized with weighted likelihood maximization and a
gradient-based sampling procedure is integrated to improve the sampling
efficiency. The safety-critical scenarios are generated by querying the task
algorithms and the log-likelihood of the generated scenarios is in proportion
to the risk level. Experiments on a self-driving task demonstrate our
advantages in terms of testing efficiency and multimodal modeling capability.
We evaluate six Reinforcement Learning algorithms with our generated traffic
scenarios and provide empirical conclusions about their robustness.
</p>
<a href="http://arxiv.org/abs/2009.08311">arXiv:2009.08311</a> [<a href="http://arxiv.org/pdf/2009.08311">pdf</a>]

<h2>DISPATCH: Design Space Exploration of Cyber-Physical Systems. (arXiv:2009.10214v2 [cs.LG] UPDATED)</h2>
<h3>Prerit Terway, Kenza Hamidouche, Niraj K. Jha</h3>
<p>Design of cyber-physical systems (CPSs) is a challenging task that involves
searching over a large search space of various CPS configurations and possible
values of components composing the system. Hence, there is a need for
sample-efficient CPS design space exploration to select the system architecture
and component values that meet the target system requirements. We address this
challenge by formulating CPS design as a multi-objective optimization problem
and propose DISPATCH, a two-step methodology for sample-efficient search over
the design space. First, we use a genetic algorithm to search over discrete
choices of system component values for architecture search and component
selection or only component selection and terminate the algorithm even before
meeting the system requirements, thus yielding a coarse design. In the second
step, we use an inverse design to search over a continuous space to fine-tune
the component values and meet the diverse set of system requirements. We use a
neural network as a surrogate function for the inverse design of the system.
The neural network, converted into a mixed-integer linear program, is used for
active learning to sample component values efficiently in a continuous search
space. We illustrate the efficacy of DISPATCH on electrical circuit benchmarks:
two-stage and three-stage transimpedence amplifiers. Simulation results show
that the proposed methodology improves sample efficiency by 5-14x compared to a
prior synthesis method that relies on reinforcement learning. It also
synthesizes circuits with the best performance (highest bandwidth/lowest area)
compared to designs synthesized using reinforcement learning, Bayesian
optimization, or humans.
</p>
<a href="http://arxiv.org/abs/2009.10214">arXiv:2009.10214</a> [<a href="http://arxiv.org/pdf/2009.10214">pdf</a>]

<h2>Diesel Generator Model Parameterization for Microgrid Simulation Using Hybrid Box-Constrained Levenberg-Marquardt Algorithm. (arXiv:2009.10425v2 [eess.SY] UPDATED)</h2>
<h3>Qian Long, Hui Yu, Fuhong Xie, Ning Lu, David Lubkeman</h3>
<p>Existing generator parameterization methods, typically developed for large
turbine generator units, are difficult to apply to small kW-level diesel
generators in microgrid applications. This paper presents a model
parameterization method that estimates a complete set of kW-level diesel
generator parameters simultaneously using only load-step-change tests with
limited measurement points. This method provides a more cost-efficient and
robust approach to achieve high-fidelity modeling of diesel generators for
microgrid dynamic simulation. A two-stage hybrid box-constrained
Levenberg-Marquardt (H-BCLM) algorithm is developed to search the optimal
parameter set given the parameter bounds. A heuristic algorithm, namely
Generalized Opposition-based Learning Genetic Algorithm (GOL-GA), is applied to
identify proper initial estimates at the first stage, followed by a modified
Levenberg-Marquardt algorithm designed to fine tune the solution based on the
first-stage result. The proposed method is validated against dynamic simulation
of a diesel generator model and field measurements from a 16kW diesel generator
unit.
</p>
<a href="http://arxiv.org/abs/2009.10425">arXiv:2009.10425</a> [<a href="http://arxiv.org/pdf/2009.10425">pdf</a>]

<h2>An Intuitive Tutorial to Gaussian Processes Regression. (arXiv:2009.10862v2 [stat.ML] UPDATED)</h2>
<h3>Jie Wang</h3>
<p>This introduction aims to provide readers an intuitive understanding of
Gaussian processes regression. Gaussian processes regression (GPR) models have
been widely used in machine learning applications because their representation
flexibility and inherently uncertainty measures over predictions. The paper
starts with explaining mathematical basics that Gaussian processes built on
including multivariate normal distribution, kernels, non-parametric models,
joint and conditional probability. The Gaussian processes regression is then
described in an accessible way by balancing showing unnecessary mathematical
derivation steps and missing key conclusive results. An illustrative
implementation of a standard Gaussian processes regression algorithm is
provided. Beyond the standard Gaussian processes regression, existing software
packages to implement state-of-the-art Gaussian processes algorithms are
reviewed. Lastly, more advanced Gaussian processes regression models are
specified. The paper is written in an accessible way, thus undergraduate
science and engineering background will find no difficulties in following the
content.
</p>
<a href="http://arxiv.org/abs/2009.10862">arXiv:2009.10862</a> [<a href="http://arxiv.org/pdf/2009.10862">pdf</a>]

<h2>Exploiting Vietnamese Social Media Characteristics for Textual Emotion Recognition in Vietnamese. (arXiv:2009.11005v2 [cs.CL] UPDATED)</h2>
<h3>Khang Phuoc-Quy Nguyen, Kiet Van Nguyen</h3>
<p>Textual emotion recognition has been a promising research topic in recent
years. Many researchers were trying to build a perfect automated system capable
of detecting correct human emotion from text data. In this paper, we conducted
several experiments to indicate how the data pre-processing affects a machine
learning method on textual emotion recognition. These experiments were
performed on the benchmark dataset Vietnamese Social Media Emotion Corpus
(UIT-VSMEC). We explored Vietnamese social media characteristics to proposed
different pre-processing techniques, and key-clause extraction with emotional
context to improve the machine performance on UIT-VSMEC. Our experimental
evaluation shows that with appropriate pre-processing techniques, Multinomial
Logistic Regression (MLR) achieves the best F1-score of 64.40\%, a significant
improvement of 4.66\% over the CNN model built by the authors of UIT-VSMEC
(59.74\%).
</p>
<a href="http://arxiv.org/abs/2009.11005">arXiv:2009.11005</a> [<a href="http://arxiv.org/pdf/2009.11005">pdf</a>]

<h2>EXP4-DFDC: A Non-Stochastic Multi-Armed Bandit for Cache Replacement. (arXiv:2009.11330v2 [cs.LG] UPDATED)</h2>
<h3>Farzana Beente Yusuf, Camilo Valdes, Vitalii Stebliankin, Giuseppe Vietri, Giri Narasimhan</h3>
<p>In this work we study a variant of the well-known multi-armed bandit (MAB)
problem, which has the properties of a delay in feedback, and a loss that
declines over time. We introduce an algorithm, EXP4-DFDC, to solve this MAB
variant, and demonstrate that the regret vanishes as the time increases. We
also show that LeCaR, a previously published machine learning-based cache
replacement algorithm, is an instance of EXP4-DFDC. Our results can be used to
provide insight on the choice of hyperparameters, and optimize future LeCaR
instances.
</p>
<a href="http://arxiv.org/abs/2009.11330">arXiv:2009.11330</a> [<a href="http://arxiv.org/pdf/2009.11330">pdf</a>]

<h2>Revisiting Graph Convolutional Network on Semi-Supervised Node Classification from an Optimization Perspective. (arXiv:2009.11469v2 [cs.LG] UPDATED)</h2>
<h3>Hongwei Zhang, Tijin Yan, Zenjun Xie, Yuanqing Xia, Yuan Zhang</h3>
<p>Graph convolutional networks (GCNs) have achieved promising performance on
various graph-based tasks. However they suffer from over-smoothing when
stacking more layers. In this paper, we present a quantitative study on this
observation and develop novel insights towards the deeper GCN. First, we
interpret the current graph convolutional operations from an optimization
perspective and argue that over-smoothing is mainly caused by the naive
first-order approximation of the solution to the optimization problem.
Subsequently, we introduce two metrics to measure the over-smoothing on
node-level tasks. Specifically, we calculate the fraction of the pairwise
distance between connected and disconnected nodes to the overall distance
respectively. Based on our theoretical and empirical analysis, we establish a
universal theoretical framework of GCN from an optimization perspective and
derive a novel convolutional kernel named GCN+ which has lower parameter amount
while relieving the over-smoothing inherently. Extensive experiments on
real-world datasets demonstrate the superior performance of GCN+ over
state-of-the-art baseline methods on the node classification tasks.
</p>
<a href="http://arxiv.org/abs/2009.11469">arXiv:2009.11469</a> [<a href="http://arxiv.org/pdf/2009.11469">pdf</a>]

<h2>Improving Query Efficiency of Black-box Adversarial Attack. (arXiv:2009.11508v2 [cs.LG] UPDATED)</h2>
<h3>Yang Bai, Yuyuan Zeng, Yong Jiang, Yisen Wang, Shu-Tao Xia, Weiwei Guo</h3>
<p>Deep neural networks (DNNs) have demonstrated excellent performance on
various tasks, however they are under the risk of adversarial examples that can
be easily generated when the target model is accessible to an attacker
(white-box setting). As plenty of machine learning models have been deployed
via online services that only provide query outputs from inaccessible models
(e.g. Google Cloud Vision API2), black-box adversarial attacks (inaccessible
target model) are of critical security concerns in practice rather than
white-box ones. However, existing query-based black-box adversarial attacks
often require excessive model queries to maintain a high attack success rate.
Therefore, in order to improve query efficiency, we explore the distribution of
adversarial examples around benign inputs with the help of image structure
information characterized by a Neural Process, and propose a Neural Process
based black-box adversarial attack (NP-Attack) in this paper. Extensive
experiments show that NP-Attack could greatly decrease the query counts under
the black-box setting.
</p>
<a href="http://arxiv.org/abs/2009.11508">arXiv:2009.11508</a> [<a href="http://arxiv.org/pdf/2009.11508">pdf</a>]

<h2>Game theory to enhance stock management of personal protective equipment (PPE) during the COVID-19 outbreak. (arXiv:2009.11838v2 [cs.CY] UPDATED)</h2>
<h3>Khaled Abedrabboh, Matthias Pilz, Zaid Al-Fagih, Othman S. Al-Fagih, Jean-Christophe Nebel, Luluwah Al-Fagih</h3>
<p>Since the outbreak of the COVID-19 pandemic, many healthcare facilities have
suffered from shortages in medical resources, particularly in Personal
Protective Equipment (PPE). In this paper, we propose a game-theoretic approach
to schedule PPE orders among healthcare facilities. In this PPE game, each
independent healthcare facility optimises its own storage utilisation in order
to keep its PPE cost at a minimum. Such a model can reduce peak demand
considerably when applied to a variable PPE consumption profile. Experiments
conducted for NHS England regions using actual data confirm that the challenge
of securing PPE supply during disasters such as COVID-19 can be eased if proper
stock management procedures are adopted. These procedures can include early
stockpiling, increasing storage capacities and implementing measures that can
prolong the time period between successive infection waves, such as social
distancing measures. Simulation results suggest that the provision of PPE
dedicated storage space can be a viable solution to avoid straining PPE supply
chains in case a second wave of COVID-19 infections occurs.
</p>
<a href="http://arxiv.org/abs/2009.11838">arXiv:2009.11838</a> [<a href="http://arxiv.org/pdf/2009.11838">pdf</a>]

<h2>Stock Price Prediction Using Convolutional Neural Networks on a Multivariate Timeseries. (arXiv:2001.09769v1 [q-fin.ST] CROSS LISTED)</h2>
<h3>Sidra Mehtab, Jaydip Sen</h3>
<p>Prediction of future movement of stock prices has been a subject matter of
many research work. In this work, we propose a hybrid approach for stock price
prediction using machine learning and deep learning-based methods. We select
the NIFTY 50 index values of the National Stock Exchange of India, over a
period of four years, from January 2015 till December 2019. Based on the NIFTY
data during the said period, we build various predictive models using machine
learning approaches, and then use those models to predict the Close value of
NIFTY 50 for the year 2019, with a forecast horizon of one week. For predicting
the NIFTY index movement patterns, we use a number of classification methods,
while for forecasting the actual Close values of NIFTY index, various
regression models are built. We, then, augment our predictive power of the
models by building a deep learning-based regression model using Convolutional
Neural Network with a walk-forward validation. The CNN model is fine-tuned for
its parameters so that the validation loss stabilizes with increasing number of
iterations, and the training and validation accuracies converge. We exploit the
power of CNN in forecasting the future NIFTY index values using three
approaches which differ in number of variables used in forecasting, number of
sub-models used in the overall models and, size of the input data for training
the models. Extensive results are presented on various metrics for all
classification and regression models. The results clearly indicate that
CNN-based multivariate forecasting model is the most effective and accurate in
predicting the movement of NIFTY index values with a weekly forecast horizon.
</p>
<a href="http://arxiv.org/abs/2001.09769">arXiv:2001.09769</a> [<a href="http://arxiv.org/pdf/2001.09769">pdf</a>]

<h2>Robust Phase Unwrapping via Deep Image Prior for Quantitative Phase Imaging. (arXiv:2009.11554v1 [eess.IV] CROSS LISTED)</h2>
<h3>Fangshu Yang, Thanh-an Pham, Nathalie Brandenberg, Matthias P. Lutolf, Jianwei Ma, Michael Unser</h3>
<p>Quantitative phase imaging (QPI) is an emerging label-free technique that
produces images containing morphological and dynamical information without
contrast agents. Unfortunately, the phase is wrapped in most imaging system.
Phase unwrapping is the computational process that recovers a more informative
image. It is particularly challenging with thick and complex samples such as
organoids. Recent works that rely on supervised training show that deep
learning is a powerful method to unwrap the phase; however, supervised
approaches require large and representative datasets which are difficult to
obtain for complex biological samples. Inspired by the concept of deep image
priors, we propose a deep-learning-based method that does not need any training
set. Our framework relies on an untrained convolutional neural network to
accurately unwrap the phase while ensuring the consistency of the measurements.
We experimentally demonstrate that the proposed method faithfully recovers the
phase of complex samples on both real and simulated data. Our work paves the
way to reliable phase imaging of thick and complex samples with QPI.
</p>
<a href="http://arxiv.org/abs/2009.11554">arXiv:2009.11554</a> [<a href="http://arxiv.org/pdf/2009.11554">pdf</a>]

<h2>Learning Equality Constraints for Motion Planning on Manifolds. (arXiv:2009.11852v1 [cs.RO] CROSS LISTED)</h2>
<h3>Giovanni Sutanto, Isabel M. Rayas Fern&#xe1;ndez, Peter Englert, Ragesh K. Ramachandran, Gaurav S. Sukhatme</h3>
<p>Constrained robot motion planning is a widely used technique to solve complex
robot tasks. We consider the problem of learning representations of constraints
from demonstrations with a deep neural network, which we call Equality
Constraint Manifold Neural Network (ECoMaNN). The key idea is to learn a
level-set function of the constraint suitable for integration into a
constrained sampling-based motion planner. Learning proceeds by aligning
subspaces in the network with subspaces of the data. We combine both learned
constraints and analytically described constraints into the planner and use a
projection-based strategy to find valid points. We evaluate ECoMaNN on its
representation capabilities of constraint manifolds, the impact of its
individual loss terms, and the motions produced when incorporated into a
planner.
</p>
<a href="http://arxiv.org/abs/2009.11852">arXiv:2009.11852</a> [<a href="http://arxiv.org/pdf/2009.11852">pdf</a>]

<h2>A Parsimonious Tour of Bayesian Model Uncertainty. (arXiv:1902.05539v2 [stat.ME] UPDATED)</h2>
<h3>Pierre-Alexandre Mattei</h3>
<p>Modern statistical software and machine learning libraries are enabling
semi-automated statistical inference. Within this context, it appears easier
and easier to try and fit many models to the data at hand, reversing thereby
the Fisherian way of conducting science by collecting data after the scientific
hypothesis (and hence the model) has been determined. The renewed goal of the
statistician becomes to help the practitioner choose within such large and
heterogeneous families of models, a task known as model selection. The Bayesian
paradigm offers a systematized way of assessing this problem. This approach,
launched by Harold Jeffreys in his 1935 book Theory of Probability, has
witnessed a remarkable evolution in the last decades, that has brought about
several new theoretical and methodological advances. Some of these recent
developments are the focus of this survey, which tries to present a unifying
perspective on work carried out by different communities. In particular, we
focus on non-asymptotic out-of-sample performance of Bayesian model selection
and averaging techniques, and draw connections with penalized maximum
likelihood. We also describe recent extensions to wider classes of
probabilistic frameworks including high-dimensional, unidentifiable, or
likelihood-free models.
</p>
<a href="http://arxiv.org/abs/1902.05539">arXiv:1902.05539</a> [<a href="http://arxiv.org/pdf/1902.05539">pdf</a>]

<h2>To BAN or not to BAN: Bayesian Attention Networks for Reliable Hate Speech Detection. (arXiv:2007.05304v5 [stat.AP] UPDATED)</h2>
<h3>Kristian Miok, Blaz Skrlj, Daniela Zaharie, Marko Robnik-Sikonja</h3>
<p>Hate speech is an important problem in the management of user-generated
content. In order to remove offensive content or ban misbehaving users, content
moderators need reliable hate speech detectors. Recently, deep neural networks
based on transformer architecture, such as (multilingual) BERT model, achieve
superior performance in many natural language classification tasks, including
hate speech detection. So far, these methods have not been able to quantify
their output in terms of reliability. We propose a Bayesian method using Monte
Carlo Dropout within the attention layers of the transformer models to provide
well-calibrated reliability estimates. We evaluate and visualize the introduced
approach on hate speech detection problems in several languages. From the
experiments performed it was observed that our approach significantly improve
the hate speech detection that can not be trusted. Our approach not only
improves classification performance of the state-of-the-art multilingual BERT
model, but the computed reliability scores also significantly reduce the
workload in the inspection of offending cases and in reannotation campaigns.
The provided visualization helps to understand the borderline outcomes.
</p>
<a href="http://arxiv.org/abs/2007.05304">arXiv:2007.05304</a> [<a href="http://arxiv.org/pdf/2007.05304">pdf</a>]

