---
title: Latest Deep Learning Papers
date: 2020-11-14 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (177 Articles)</h1>
<h2>Dirichlet Pruning for Neural Network Compression. (arXiv:2011.05985v1 [cs.LG])</h2>
<h3>Kamil Adamczewski, Mijung Park</h3>
<p>We introduce Dirichlet pruning, a novel post-processing technique to
transform a large neural network model into a compressed one. Dirichlet pruning
is a form of structured pruning which assigns the Dirichlet distribution over
each layer's channels in convolutional layers (or neurons in fully-connected
layers), and estimates the parameters of the distribution over these units
using variational inference. The learned distribution allows us to remove
unimportant units, resulting in a compact architecture containing only crucial
features for a task at hand. Our method is extremely fast to train. The number
of newly introduced Dirichlet parameters is only linear in the number of
channels, which allows for rapid training, requiring as little as one epoch to
converge. We perform extensive experiments, in particular on larger
architectures such as VGG and WideResNet (45% and 52% compression rate,
respectively) where our method achieves the state-of-the-art compression
performance and provides interpretable features as a by-product.
</p>
<a href="http://arxiv.org/abs/2011.05985" target="_blank">arXiv:2011.05985</a> [<a href="http://arxiv.org/pdf/2011.05985" target="_blank">pdf</a>]

<h2>Physics-constrained Deep Learning of Multi-zone Building Thermal Dynamics. (arXiv:2011.05987v1 [cs.LG])</h2>
<h3>Jan Drgona, Aaron R. Tuor, Vikas Chandan, Draguna L. Vrabie</h3>
<p>We present a physics-constrained control-oriented deep learning method for
modeling building thermal dynamics. The proposed method is based on the
systematic encoding of physics-based prior knowledge into a structured
recurrent neural architecture. Specifically, our method incorporates structural
priors from traditional physics-based building modeling into the neural network
thermal dynamics model structure. Further, we leverage penalty methods to
provide inequality constraints, thereby bounding predictions within physically
realistic and safe operating ranges. Observing that stable eigenvalues
accurately characterize the dissipativeness of the system, we additionally use
a constrained matrix parameterization based on the Perron-Frobenius theorem to
bound the dominant eigenvalues of the building thermal model parameter
matrices. We demonstrate the proposed data-driven modeling approach's
effectiveness and physical interpretability on a dataset obtained from a
real-world office building with 20 thermal zones. Using only 10 days'
measurements for training, we demonstrate generalization over 20 consecutive
days, significantly improving the accuracy compared to prior state-of-the-art
results reported in the literature.
</p>
<a href="http://arxiv.org/abs/2011.05987" target="_blank">arXiv:2011.05987</a> [<a href="http://arxiv.org/pdf/2011.05987" target="_blank">pdf</a>]

<h2>Linear Dilation-Erosion Perceptron for Binary Classification. (arXiv:2011.05989v1 [cs.LG])</h2>
<h3>Angelica Louren&#xe7;o Oliveira, Marcos Eduardo Valle</h3>
<p>In this work, we briefly revise the reduced dilation-erosion perceptron
(r-DEP) models for binary classification tasks. Then, we present the so-called
linear dilation-erosion perceptron (l-DEP), in which a linear transformation is
applied before the application of the morphological operators. Furthermore, we
propose to train the l-DEP classifier by minimizing a regularized hinge-loss
function subject to concave-convex restrictions. A simple example is given for
illustrative purposes.
</p>
<a href="http://arxiv.org/abs/2011.05989" target="_blank">arXiv:2011.05989</a> [<a href="http://arxiv.org/pdf/2011.05989" target="_blank">pdf</a>]

<h2>Solving high-dimensional parameter inference: marginal posterior densities & Moment Networks. (arXiv:2011.05991v1 [stat.ML])</h2>
<h3>Niall Jeffrey, Benjamin D. Wandelt</h3>
<p>High-dimensional probability density estimation for inference suffers from
the "curse of dimensionality". For many physical inference problems, the full
posterior distribution is unwieldy and seldom used in practice. Instead, we
propose direct estimation of lower-dimensional marginal distributions,
bypassing high-dimensional density estimation or high-dimensional Markov chain
Monte Carlo (MCMC) sampling. By evaluating the two-dimensional marginal
posteriors we can unveil the full-dimensional parameter covariance structure.
We additionally propose constructing a simple hierarchy of fast neural
regression models, called Moment Networks, that compute increasing moments of
any desired lower-dimensional marginal posterior density; these reproduce exact
results from analytic posteriors and those obtained from Masked Autoregressive
Flows. We demonstrate marginal posterior density estimation using
high-dimensional LIGO-like gravitational wave time series and describe
applications for problems of fundamental cosmology.
</p>
<a href="http://arxiv.org/abs/2011.05991" target="_blank">arXiv:2011.05991</a> [<a href="http://arxiv.org/pdf/2011.05991" target="_blank">pdf</a>]

<h2>Towards NNGP-guided Neural Architecture Search. (arXiv:2011.06006v1 [cs.LG])</h2>
<h3>Daniel S. Park, Jaehoon Lee, Daiyi Peng, Yuan Cao, Jascha Sohl-Dickstein</h3>
<p>The predictions of wide Bayesian neural networks are described by a Gaussian
process, known as the Neural Network Gaussian Process (NNGP). Analytic forms
for NNGP kernels are known for many models, but computing the exact kernel for
convolutional architectures is prohibitively expensive. One can obtain
effective approximations of these kernels through Monte-Carlo estimation using
finite networks at initialization. Monte-Carlo NNGP inference is
orders-of-magnitude cheaper in FLOPs compared to gradient descent training when
the dataset size is small. Since NNGP inference provides a cheap measure of
performance of a network architecture, we investigate its potential as a signal
for neural architecture search (NAS). We compute the NNGP performance of
approximately 423k networks in the NAS-bench 101 dataset on CIFAR-10 and
compare its utility against conventional performance measures obtained by
shortened gradient-based training. We carry out a similar analysis on 10k
randomly sampled networks in the mobile neural architecture search (MNAS) space
for ImageNet. We discover comparative advantages of NNGP-based metrics, and
discuss potential applications. In particular, we propose that NNGP performance
is an inexpensive signal independent of metrics obtained from training that can
either be used for reducing big search spaces, or improving training-based
performance measures.
</p>
<a href="http://arxiv.org/abs/2011.06006" target="_blank">arXiv:2011.06006</a> [<a href="http://arxiv.org/pdf/2011.06006" target="_blank">pdf</a>]

<h2>GANMEX: One-vs-One Attributions using GAN-based Model Explainability. (arXiv:2011.06015v1 [cs.LG])</h2>
<h3>Sheng-Min Shih, Pin-Ju Tien, Zohar Karnin</h3>
<p>Attribution methods have been shown as promising approaches for identifying
key features that led to learned model predictions. While most existing
attribution methods rely on a baseline input for performing feature
perturbations, limited research has been conducted to address the baseline
selection issues. Poor choices of baselines limit the ability of one-vs-one
explanations for multi-class classifiers, which means the attribution methods
were not able to explain why an input belongs to its original class but not the
other specified target class. Achieving one-vs-one explanation is crucial when
certain classes are more similar than others, e.g. two bird types among
multiple animals, by focusing on key differentiating features rather than
shared features across classes. In this paper, we present GANMEX, a novel
approach applying Generative Adversarial Networks (GAN) by incorporating the
to-be-explained classifier as part of the adversarial networks. Our approach
effectively selects the baseline as the closest realistic sample belong to the
target class, which allows attribution methods to provide true one-vs-one
explanations. We showed that GANMEX baselines improved the saliency maps and
led to stronger performance on perturbation-based evaluation metrics over the
existing baselines. Existing attribution results are known for being
insensitive to model randomization, and we demonstrated that GANMEX baselines
led to better outcome under the cascading randomization of the model.
</p>
<a href="http://arxiv.org/abs/2011.06015" target="_blank">arXiv:2011.06015</a> [<a href="http://arxiv.org/pdf/2011.06015" target="_blank">pdf</a>]

<h2>Machine Learning Based Path Planning for Improved Rover Navigation (Pre-Print Version). (arXiv:2011.06022v1 [cs.RO])</h2>
<h3>Neil Abcouwer, Shreyansh Daftry, Siddarth Venkatraman, Tyler del Sesto, Olivier Toupet, Ravi Lanka, Jialin Song, Yisong Yue, Masahiro Ono</h3>
<p>Enhanced AutoNav (ENav), the baseline surface navigation software for NASA's
Perseverance rover, sorts a list of candidate paths for the rover to traverse,
then uses the Approximate Clearance Evaluation (ACE) algorithm to evaluate
whether the most highly ranked paths are safe. ACE is crucial for maintaining
the safety of the rover, but is computationally expensive. If the most
promising candidates in the list of paths are all found to be infeasible, ENav
must continue to search the list and run time-consuming ACE evaluations until a
feasible path is found. In this paper, we present two heuristics that, given a
terrain heightmap around the rover, produce cost estimates that more
effectively rank the candidate paths before ACE evaluation. The first heuristic
uses Sobel operators and convolution to incorporate the cost of traversing
high-gradient terrain. The second heuristic uses a machine learning (ML) model
to predict areas that will be deemed untraversable by ACE. We used physics
simulations to collect training data for the ML model and to run Monte Carlo
trials to quantify navigation performance across a variety of terrains with
various slopes and rock distributions. Compared to ENav's baseline performance,
integrating the heuristics can lead to a significant reduction in ACE
evaluations and average computation time per planning cycle, increase path
efficiency, and maintain or improve the rate of successful traverses. This
strategy of targeting specific bottlenecks with ML while maintaining the
original ACE safety checks provides an example of how ML can be infused into
planetary science missions and other safety-critical software.
</p>
<a href="http://arxiv.org/abs/2011.06022" target="_blank">arXiv:2011.06022</a> [<a href="http://arxiv.org/pdf/2011.06022" target="_blank">pdf</a>]

<h2>Rediscovering alignment relations with Graph Convolutional Networks. (arXiv:2011.06023v1 [cs.LG])</h2>
<h3>Pierre Monnin, Chedy Ra&#xef;ssi, Amedeo Napoli, Adrien Coulet</h3>
<p>Knowledge graphs are concurrently published and edited in the Web of data.
Hence they may overlap, which makes key the task that consists in matching
their content. This task encompasses the identification, within and across
knowledge graphs, of nodes that are equivalent, more specific, or weakly
related. In this article, we propose to match nodes of a knowledge graph by (i)
learning node embeddings with Graph Convolutional Networks such that similar
nodes have low distances in the embedding space, and (ii) clustering nodes
based on their embeddings. We experimented this approach on a biomedical
knowledge graph and particularly investigated the interplay between formal
semantics and GCN models with the two following main focuses. Firstly, we
applied various inference rules associated with domain knowledge, independently
or combined, before learning node embeddings, and we measured the improvements
in matching results. Secondly, while our GCN model is agnostic to the exact
alignment relations (e.g., equivalence, weak similarity), we observed that
distances in the embedding space are coherent with the "strength" of these
different relations (e.g., smaller distances for equivalences), somehow
corresponding to their rediscovery by the model.
</p>
<a href="http://arxiv.org/abs/2011.06023" target="_blank">arXiv:2011.06023</a> [<a href="http://arxiv.org/pdf/2011.06023" target="_blank">pdf</a>]

<h2>FastPathology: An open-source platform for deep learning-based research and decision support in digital pathology. (arXiv:2011.06033v1 [cs.LG])</h2>
<h3>Andr&#xe9; Pedersen, Marit Valla, Anna M. Bofin, Javier P&#xe9;rez de Frutos, Ingerid Reinertsen, Erik Smistad</h3>
<p>Deep convolutional neural networks (CNNs) are the current state-of-the-art
for digital analysis of histopathological images. The large size of whole-slide
microscopy images (WSIs) requires advanced memory handling to read, display and
process these images. There are several open-source platforms for working with
WSIs, but few support deployment of CNN models. These applications use
third-party solutions for inference, making them less user-friendly and
unsuitable for high-performance image analysis. To make deployment of CNNs
user-friendly and feasible on low-end machines, we have developed a new
platform, FastPathology, using the FAST framework and C++. It minimizes memory
usage for reading and processing WSIs, deployment of CNN models, and real-time
interactive visualization of results. Runtime experiments were conducted on
four different use cases, using different architectures, inference engines,
hardware configurations and operating systems. Memory usage for reading,
visualizing, zooming and panning a WSI were measured, using FastPathology and
three existing platforms. FastPathology performed similarly in terms of memory
to the other C++ based application, while using considerably less than the two
Java-based platforms. The choice of neural network model, inference engine,
hardware and processors influenced runtime considerably. Thus, FastPathology
includes all steps needed for efficient visualization and processing of WSIs in
a single application, including inference of CNNs with real-time display of the
results. Source code, binary releases and test data can be found online on
GitHub at https://github.com/SINTEFMedtek/FAST-Pathology/.
</p>
<a href="http://arxiv.org/abs/2011.06033" target="_blank">arXiv:2011.06033</a> [<a href="http://arxiv.org/pdf/2011.06033" target="_blank">pdf</a>]

<h2>Unsupervised Video Representation Learning by Bidirectional Feature Prediction. (arXiv:2011.06037v1 [cs.CV])</h2>
<h3>Nadine Behrmann, Juergen Gall, Mehdi Noroozi</h3>
<p>This paper introduces a novel method for self-supervised video representation
learning via feature prediction. In contrast to the previous methods that focus
on future feature prediction, we argue that a supervisory signal arising from
unobserved past frames is complementary to one that originates from the future
frames. The rationale behind our method is to encourage the network to explore
the temporal structure of videos by distinguishing between future and past
given present observations. We train our model in a contrastive learning
framework, where joint encoding of future and past provides us with a
comprehensive set of temporal hard negatives via swapping. We empirically show
that utilizing both signals enriches the learned representations for the
downstream task of action recognition. It outperforms independent prediction of
future and past.
</p>
<a href="http://arxiv.org/abs/2011.06037" target="_blank">arXiv:2011.06037</a> [<a href="http://arxiv.org/pdf/2011.06037" target="_blank">pdf</a>]

<h2>Testing for Typicality with Respect to an Ensemble of Learned Distributions. (arXiv:2011.06041v1 [cs.LG])</h2>
<h3>Forrest Laine, Claire Tomlin</h3>
<p>Methods of performing anomaly detection on high-dimensional data sets are
needed, since algorithms which are trained on data are only expected to perform
well on data that is similar to the training data. There are theoretical
results on the ability to detect if a population of data is likely to come from
a known base distribution, which is known as the goodness-of-fit problem.
One-sample approaches to this problem offer significant computational
advantages for online testing, but require knowing a model of the base
distribution. The ability to correctly reject anomalous data in this setting
hinges on the accuracy of the model of the base distribution. For high
dimensional data, learning an accurate-enough model of the base distribution
such that anomaly detection works reliably is very challenging, as many
researchers have noted in recent years. Existing methods for the one-sample
goodness-of-fit problem do not account for the fact that a model of the base
distribution is learned. To address that gap, we offer a theoretically
motivated approach to account for the density learning procedure. In
particular, we propose training an ensemble of density models, considering data
to be anomalous if the data is anomalous with respect to any member of the
ensemble. We provide a theoretical justification for this approach, proving
first that a test on typicality is a valid approach to the goodness-of-fit
problem, and then proving that for a correctly constructed ensemble of models,
the intersection of typical sets of the models lies in the interior of the
typical set of the base distribution. We present our method in the context of
an example on synthetic data in which the effects we consider can easily be
seen.
</p>
<a href="http://arxiv.org/abs/2011.06041" target="_blank">arXiv:2011.06041</a> [<a href="http://arxiv.org/pdf/2011.06041" target="_blank">pdf</a>]

<h2>Clustering of Big Data with Mixed Features. (arXiv:2011.06043v1 [stat.ML])</h2>
<h3>Joshua Tobin, Mimi Zhang</h3>
<p>Clustering large, mixed data is a central problem in data mining. Many
approaches adopt the idea of k-means, and hence are sensitive to
initialisation, detect only spherical clusters, and require a priori the
unknown number of clusters. We here develop a new clustering algorithm for
large data of mixed type, aiming at improving the applicability and efficiency
of the peak-finding technique. The improvements are threefold: (1) the new
algorithm is applicable to mixed data; (2) the algorithm is capable of
detecting outliers and clusters of relatively lower density values; (3) the
algorithm is competent at deciding the correct number of clusters. The
computational complexity of the algorithm is greatly reduced by applying a fast
k-nearest neighbors method and by scaling down to component sets. We present
experimental results to verify that our algorithm works well in practice.
Keywords: Clustering; Big Data; Mixed Attribute; Density Peaks;
Nearest-Neighbor Graph; Conductance.
</p>
<a href="http://arxiv.org/abs/2011.06043" target="_blank">arXiv:2011.06043</a> [<a href="http://arxiv.org/pdf/2011.06043" target="_blank">pdf</a>]

<h2>Multi-Hypothesis Interactions in Game-Theoretic Motion Planning. (arXiv:2011.06047v1 [cs.RO])</h2>
<h3>Forrest Laine, David Fridovich-Keil, Chih-Yuan Chiu, Claire Tomlin</h3>
<p>We present a novel method for handling uncertainty about the intentions of
non-ego players in dynamic games, with application to motion planning for
autonomous vehicles. Equilibria in these games explicitly account for
interaction among other agents in the environment, such as drivers and
pedestrians. Our method models the uncertainty about the intention of other
agents by constructing multiple hypotheses about the objectives and constraints
of other agents in the scene. For each candidate hypothesis, we associate a
Bernoulli random variable representing the probability of that hypothesis,
which may or may not be independent of the probability of other hypotheses. We
leverage constraint asymmetries and feedback information patterns to
incorporate the probabilities of hypotheses in a natural way. Specifically,
increasing the probability associated with a given hypothesis from $0$ to $1$
shifts the responsibility of collision avoidance from the hypothesized agent to
the ego agent. This method allows the generation of interactive trajectories
for the ego agent, where the level of assertiveness or caution that the ego
exhibits is directly related to the easy-to-model uncertainty it maintains
about the scene.
</p>
<a href="http://arxiv.org/abs/2011.06047" target="_blank">arXiv:2011.06047</a> [<a href="http://arxiv.org/pdf/2011.06047" target="_blank">pdf</a>]

<h2>Comparing Piezoresistive Substrates for Tactile Sensing in Dexterous Hands. (arXiv:2011.06048v1 [cs.RO])</h2>
<h3>Rebecca Miles, Martin Matak, Mohanraj Devendran Shanthi, Darrin Young, Tucker Hermans</h3>
<p>While tactile skins have been shown to be useful for detecting collisions
between a robotic arm and its environment, they have not been extensively used
for improving robotic grasping and in-hand manipulation. We propose a novel
sensor design for use in covering existing multi-fingered robot hands. We
analyze the performance of four different piezoresistive materials using both
fabric and anti-static foam substrates in benchtop experiments. We find that
although the piezoresistive foam was designed as packing material and not for
use as a sensing substrate, it performs comparably with fabrics specifically
designed for this purpose. While these results demonstrate the potential of
piezoresistive foams for tactile sensing applications, they do not fully
characterize the efficacy of these sensors for use in robot manipulation. As
such, we use a high density foam substrate to develop a scalable tactile skin
that can be attached to the palm of a robotic hand. We demonstrate several
robotic manipulation tasks using this sensor to show its ability to reliably
detect and localize contact, as well as analyze contact patterns during
grasping and transport tasks.
</p>
<a href="http://arxiv.org/abs/2011.06048" target="_blank">arXiv:2011.06048</a> [<a href="http://arxiv.org/pdf/2011.06048" target="_blank">pdf</a>]

<h2>Global Position Control on Underactuated Bipedal Robots: Step-to-step Dynamics Approximation for Step Planning. (arXiv:2011.06050v1 [cs.RO])</h2>
<h3>Xiaobin Xiong, Jenna Reher, Aaron Ames</h3>
<p>Global position control for underactuated bipedal walking is a challenging
problem due to the lack of actuation on the feet of the robots. In this paper,
we apply the Hybrid-Linear Inverted Pendulum (H-LIP) based stepping on 3D
underactuated bipedal robots for global position control. The step-to-step
(S2S) dynamics of the H-LIP walking approximates the actual S2S dynamics of the
walking of the robot, where the step size is considered as the input. Thus the
feedback controller based on the H-LIP approximately controls the robot to
behave like the H-LIP, the differences between which stay in an error invariant
set. Model Predictive Control (MPC) is applied to the H-LIP for global position
control in 3D. The H-LIP stepping then generates desired step sizes for the
robot to track. Moreover, turning behavior is integrated with the step
planning. The proposed framework is verified on the 3D underactuated bipedal
robot Cassie in simulation together with a proof-of-concept experiment.
</p>
<a href="http://arxiv.org/abs/2011.06050" target="_blank">arXiv:2011.06050</a> [<a href="http://arxiv.org/pdf/2011.06050" target="_blank">pdf</a>]

<h2>Forecasting Emergency Department Capacity Constraints for COVID Isolation Beds. (arXiv:2011.06058v1 [cs.LG])</h2>
<h3>Erik Drysdale, Devin Singh, Anna Goldenberg</h3>
<p>Predicting patient volumes in a hospital setting is a well-studied
application of time series forecasting. Existing tools usually make forecasts
at the daily or weekly level to assist in planning for staffing requirements.
Prompted by new COVID-related capacity constraints placed on our pediatric
hospital's emergency department, we developed an hourly forecasting tool to
make predictions over a 24 hour window. These forecasts would give our hospital
sufficient time to be able to martial resources towards expanding capacity and
augmenting staff (e.g. transforming wards or bringing in physicians on call).
Using Gaussian Process Regressions (GPRs), we obtain strong performance for
both point predictions (average R-squared: 82%) as well as classification
accuracy when predicting the ordinal tiers of our hospital's capacity (average
precision/recall: 82%/74%). Compared to traditional regression approaches, GPRs
not only obtain consistently higher performance, but are also robust to the
dataset shifts that have occurred throughout 2020. Hospital stakeholders are
encouraged by the strength of our results, and we are currently working on
moving our tool to a real-time setting with the goal of augmenting the
capabilities of our healthcare workers.
</p>
<a href="http://arxiv.org/abs/2011.06058" target="_blank">arXiv:2011.06058</a> [<a href="http://arxiv.org/pdf/2011.06058" target="_blank">pdf</a>]

<h2>Ecole: A Gym-like Library for Machine Learning in Combinatorial Optimization Solvers. (arXiv:2011.06069v1 [cs.LG])</h2>
<h3>Antoine Prouvost, Justin Dumouchelle, Lara Scavuzzo, Maxime Gasse, Didier Ch&#xe9;telat, Andrea Lodi</h3>
<p>We present Ecole, a new library to simplify machine learning research for
combinatorial optimization. Ecole exposes several key decision tasks arising in
general-purpose combinatorial optimization solvers as control problems over
Markov decision processes. Its interface mimics the popular OpenAI Gym library
and is both extensible and intuitive to use. We aim at making this library a
standardized platform that will lower the bar of entry and accelerate
innovation in the field. Documentation and code can be found at
https://www.ecole.ai.
</p>
<a href="http://arxiv.org/abs/2011.06069" target="_blank">arXiv:2011.06069</a> [<a href="http://arxiv.org/pdf/2011.06069" target="_blank">pdf</a>]

<h2>Quantifying and Learning Disentangled Representations with Limited Supervision. (arXiv:2011.06070v1 [cs.LG])</h2>
<h3>Loek Tonnaer, Luis A. P&#xe9;rez Rey, Vlado Menkovski, Mike Holenderski, Jacobus W. Portegies</h3>
<p>Learning low-dimensional representations that disentangle the underlying
factors of variation in data has been posited as an important step towards
interpretable machine learning with good generalization. To address the fact
that there is no consensus on what disentanglement entails, Higgins et al.
(2018) propose a formal definition for Linear Symmetry-Based Disentanglement,
or LSBD, arguing that underlying real-world transformations give exploitable
structure to data.

Although several works focus on learning LSBD representations, none of them
provide a metric to quantify disentanglement. Moreover, such methods require
supervision on the underlying transformations for the entire dataset, and
cannot deal with unlabeled data.

We propose a metric to quantify LSBD representations that is easy to compute
under certain well-defined assumptions. Furthermore, we present a method that
can leverage unlabeled data, such that LSBD representations can be learned with
limited supervision on transformations. Using our LSBD metric, our results show
that limited supervision is indeed sufficient to learn LSBD representations.
</p>
<a href="http://arxiv.org/abs/2011.06070" target="_blank">arXiv:2011.06070</a> [<a href="http://arxiv.org/pdf/2011.06070" target="_blank">pdf</a>]

<h2>Statistical learning for change point and anomaly detection in graphs. (arXiv:2011.06080v1 [cs.LG])</h2>
<h3>Anna Malinovskaya, Philipp Otto, Torben Peters</h3>
<p>Complex systems which can be represented in the form of static and dynamic
graphs arise in different fields, e.g. communication, engineering and industry.
One of the interesting problems in analysing dynamic network structures is to
monitor changes in their development. Statistical learning, which encompasses
both methods based on artificial intelligence and traditional statistics, can
be used to progress in this research area. However, the majority of approaches
apply only one or the other framework. In this paper, we discuss the
possibility of bringing together both disciplines in order to create enhanced
network monitoring procedures focussing on the example of combining statistical
process control and deep learning algorithms. Together with the presentation of
change point and anomaly detection in network data, we propose to monitor the
response times of ambulance services, applying jointly the control chart for
quantile function values and a graph convolutional network.
</p>
<a href="http://arxiv.org/abs/2011.06080" target="_blank">arXiv:2011.06080</a> [<a href="http://arxiv.org/pdf/2011.06080" target="_blank">pdf</a>]

<h2>Continuous Perception for Classifying Shapes and Weights of Garmentsfor Robotic Vision Applications. (arXiv:2011.06089v1 [cs.RO])</h2>
<h3>Li Duan, Gerardo Aragon-Camarasa</h3>
<p>We present an approach to continuous perception for robotic laundry tasks.
Our assumption is that the visual prediction of a garment's shapes and weights
is possible via a neural network that learns the dynamic changes of garments
from video sequences. Continuous perception is leveraged during training by
inputting consecutive frames, of which the network learns how a garment
deforms. To evaluate our hypothesis, we captured a dataset of 40K RGB and 40K
depth video sequences while a garment is being manipulated. We also conducted
ablation studies to understand whether the neural network learns the physical
and dynamic properties of garments. Our findings suggest that a modified
AlexNet-LSTM architecture has the best classification performance for the
garment's shape and weights. To further provide evidence that continuous
perception facilitates the prediction of the garment's shapes and weights, we
evaluated our network on unseen video sequences and computed the 'Moving
Average' over a sequence of predictions. We found that our network has a
classification accuracy of 48% and 60% for shapes and weights of garments,
respectively.
</p>
<a href="http://arxiv.org/abs/2011.06089" target="_blank">arXiv:2011.06089</a> [<a href="http://arxiv.org/pdf/2011.06089" target="_blank">pdf</a>]

<h2>Improving Multimodal Accuracy Through Modality Pre-training and Attention. (arXiv:2011.06102v1 [cs.AI])</h2>
<h3>Aya Abdelsalam Ismail, Mahmudul Hasan, Faisal Ishtiaq</h3>
<p>Training a multimodal network is challenging and it requires complex
architectures to achieve reasonable performance. We show that one reason for
this phenomena is the difference between the convergence rate of various
modalities. We address this by pre-training modality-specific sub-networks in
multimodal architectures independently before end-to-end training of the entire
network. Furthermore, we show that the addition of an attention mechanism
between sub-networks after pre-training helps identify the most important
modality during ambiguous scenarios boosting the performance. We demonstrate
that by performing these two tricks a simple network can achieve similar
performance to a complicated architecture that is significantly more expensive
to train on multiple tasks including sentiment analysis, emotion recognition,
and speaker trait recognition.
</p>
<a href="http://arxiv.org/abs/2011.06102" target="_blank">arXiv:2011.06102</a> [<a href="http://arxiv.org/pdf/2011.06102" target="_blank">pdf</a>]

<h2>FS-HGR: Few-shot Learning for Hand Gesture Recognition via ElectroMyography. (arXiv:2011.06104v1 [cs.LG])</h2>
<h3>Elahe Rahimian, Soheil Zabihi, Amir Asif, Dario Farina, Seyed Farokh Atashzar, Arash Mohammadi</h3>
<p>This work is motivated by the recent advances in Deep Neural Networks (DNNs)
and their widespread applications in human-machine interfaces. DNNs have been
recently used for detecting the intended hand gesture through processing of
surface electromyogram (sEMG) signals. The ultimate goal of these approaches is
to realize high-performance controllers for prosthetic. However, although DNNs
have shown superior accuracy than conventional methods when large amounts of
data are available for training, their performance substantially decreases when
data are limited. Collecting large datasets for training may be feasible in
research laboratories, but it is not a practical approach for real-life
applications. Therefore, there is an unmet need for the design of a modern
gesture detection technique that relies on minimal training data while
providing high accuracy. Here we propose an innovative and novel "Few-Shot
Learning" framework based on the formulation of meta-learning, referred to as
the FS-HGR, to address this need. Few-shot learning is a variant of domain
adaptation with the goal of inferring the required output based on just one or
a few training examples. More specifically, the proposed FS-HGR quickly
generalizes after seeing very few examples from each class. The proposed
approach led to 85.94% classification accuracy on new repetitions with few-shot
observation (5-way 5-shot), 81.29% accuracy on new subjects with few-shot
observation (5-way 5-shot), and 73.36% accuracy on new gestures with few-shot
observation (5-way 5-shot).
</p>
<a href="http://arxiv.org/abs/2011.06104" target="_blank">arXiv:2011.06104</a> [<a href="http://arxiv.org/pdf/2011.06104" target="_blank">pdf</a>]

<h2>A Data-Driven Reinforcement Learning Solution Framework for Optimal and Adaptive Personalization of a Hip Exoskeleton. (arXiv:2011.06116v1 [cs.RO])</h2>
<h3>Xikai Tu, Minhan Li, Ming Liu, Jennie Si (Fellow, IEEE), He (Helen) Huang (Senior Member, IEEE)</h3>
<p>Robotic exoskeletons are exciting technologies for augmenting human mobility.
However, designing such a device for seamless integration with the human user
and to assist human movement still is a major challenge. This paper aims at
developing a novel data-driven solution framework based on reinforcement
learning (RL), without first modeling the human-robot dynamics, to provide
optimal and adaptive personalized torque assistance for reducing human efforts
during walking. Our automatic personalization solution framework includes the
assistive torque profile with two control timing parameters (peak and offset
timings), the least square policy iteration (LSPI) for learning the parameter
tuning policy, and a cost function based on transferred work ratio. The
proposed controller was successfully validated on a healthy human subject to
assist unilateral hip extension in walking. The results showed that the optimal
and adaptive RL controller as a new approach was feasible for tuning assistive
torque profile of the hip exoskeleton that coordinated with human actions and
reduced activation level of hip extensor muscle in human.
</p>
<a href="http://arxiv.org/abs/2011.06116" target="_blank">arXiv:2011.06116</a> [<a href="http://arxiv.org/pdf/2011.06116" target="_blank">pdf</a>]

<h2>I Know What You Meant: Learning Human Objectives by (Under)estimating Their Choice Set. (arXiv:2011.06118v1 [cs.RO])</h2>
<h3>Ananth Jonnavittula, Dylan P. Losey</h3>
<p>Assistive robots have the potential to help people perform everyday tasks.
However, these robots first need to learn what it is their user wants them to
do. Teaching assistive robots is hard for inexperienced users, elderly users,
and users living with physical disabilities, since often these individuals are
unable to teleoperate the robot along their desired behavior. We know that
inclusive learners should give human teachers credit for what they cannot
demonstrate. But today's robots do the opposite: they assume every user is
capable of providing any demonstration. As a result, these robots learn to
mimic the demonstrated behavior, even when that behavior isn't what the human
really meant! We propose an alternate approach to reward learning: robots that
reason about the user's demonstrations in the context of similar or simpler
alternatives. Unlike prior works -- which err towards overestimating the
human's capabilities -- here we err towards underestimating what the human can
input (i.e., their choice set). Our theoretical analysis proves that
underestimating the human's choice set is risk-averse, with better worst-case
performance than overestimating. We formalize three properties to generate
similar and simpler alternatives: across simulations and a user study, our
algorithm better enables robots to extrapolate the human's objective. See our
user study here: https://youtu.be/RgbH2YULVRo
</p>
<a href="http://arxiv.org/abs/2011.06118" target="_blank">arXiv:2011.06118</a> [<a href="http://arxiv.org/pdf/2011.06118" target="_blank">pdf</a>]

<h2>Deep learning and hand-crafted features for virus image classification. (arXiv:2011.06123v1 [cs.CV])</h2>
<h3>Loris Nanni, Eugenio De Luca, Marco Ludovico Facin</h3>
<p>In this work, we present an ensemble of descriptors for the classification of
transmission electron microscopy images of viruses. We propose to combine
handcrafted and deep learning approaches for virus image classification. The
set of handcrafted is mainly based on Local Binary Pattern variants, for each
descriptor a different Support Vector Machine is trained, then the set of
classifiers is combined by sum rule. The deep learning approach is a
densenet201 pretrained on ImageNet and then tuned in the virus dataset, the net
is used as features extractor for feeding another Support Vector Machine, in
particular the last average pooling layer is used as feature extractor.
Finally, classifiers trained on handcrafted features and classifier trained on
deep learning features are combined by sum rule. The proposed fusion strongly
boosts the performance obtained by each stand-alone approach, obtaining state
of the art performance.
</p>
<a href="http://arxiv.org/abs/2011.06123" target="_blank">arXiv:2011.06123</a> [<a href="http://arxiv.org/pdf/2011.06123" target="_blank">pdf</a>]

<h2>Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v1 [cs.LG])</h2>
<h3>L&#xe9;onard Boussioux, Cynthia Zeng, Th&#xe9;o Gu&#xe9;nais, Dimitris Bertsimas</h3>
<p>This paper describes a machine learning (ML) framework for tropical cyclone
intensity and track forecasting, combining multiple distinct ML techniques and
utilizing diverse data sources. Our framework, which we refer to as Hurricast
(HURR), is built upon the combination of distinct data processing techniques
using gradient-boosted trees and novel encoder-decoder architectures, including
CNN, GRU and Transformers components. We propose a deep-feature extractor
methodology to mix spatial-temporal data with statistical data efficiently. Our
multimodal framework unleashes the potential of making forecasts based on a
wide range of data sources, including historical storm data, reanalysis
atmospheric images, and operational forecasts. Evaluating our models with
current operational forecasts in North Atlantic and Eastern Pacific basins on
the last years of available data, results show our models consistently
outperform statistical-dynamical models and, albeit less accurate than the best
dynamical models, our framework computes forecasts in seconds. Furthermore, the
inclusion of Hurricast into an operational forecast consensus model leads to a
significant improvement of 5% - 15% over NHC's official forecast, thus
highlighting the complementary properties with existing approaches. In summary,
our work demonstrates that combining different data sources and distinct
machine learning methodologies can lead to superior tropical cyclone
forecasting.
</p>
<a href="http://arxiv.org/abs/2011.06125" target="_blank">arXiv:2011.06125</a> [<a href="http://arxiv.org/pdf/2011.06125" target="_blank">pdf</a>]

<h2>Deep Sketch-Based Modeling: Tips and Tricks. (arXiv:2011.06133v1 [cs.CV])</h2>
<h3>Yue Zhong, Yulia Gryaditskaya, Honggang Zhang, Yi-Zhe Song</h3>
<p>Deep image-based modeling received lots of attention in recent years, yet the
parallel problem of sketch-based modeling has only been briefly studied, often
as a potential application. In this work, for the first time, we identify the
main differences between sketch and image inputs: (i) style variance, (ii)
imprecise perspective, and (iii) sparsity. We discuss why each of these
differences can pose a challenge, and even make a certain class of image-based
methods inapplicable. We study alternative solutions to address each of the
difference. By doing so, we drive out a few important insights: (i) sparsity
commonly results in an incorrect prediction of foreground versus background,
(ii) diversity of human styles, if not taken into account, can lead to very
poor generalization properties, and finally (iii) unless a dedicated sketching
interface is used, one can not expect sketches to match a perspective of a
fixed viewpoint. Finally, we compare a set of representative deep single-image
modeling solutions and show how their performance can be improved to tackle
sketch input by taking into consideration the identified critical differences.
</p>
<a href="http://arxiv.org/abs/2011.06133" target="_blank">arXiv:2011.06133</a> [<a href="http://arxiv.org/pdf/2011.06133" target="_blank">pdf</a>]

<h2>I-POST: Intelligent Point of Sale and Transaction System. (arXiv:2011.06144v1 [cs.LG])</h2>
<h3>Farid Khan</h3>
<p>We propose a novel solution for the cashier problem. Current cashier
system/Point of Sale (POS) terminals can be inefficient, cumbersome and
time-consuming for the users. There is a need for a solution dependent on
modern technology and ubiquitous computing resources. We present I-POST
(Intelligent Point of Sale and Transaction) as a software system that uses
smart devices, mobile phone and state of the art machine learning algorithms to
process the user transactions in automated and real time manner. I-POST is an
automated checkout system that allows the user to walk in a store, collect his
items and exit the store. There is no need to stand and wait in a queue. The
system uses object detection and facial recognition algorithm to process the
authentication of the client and the state of the object. At point of exit, the
classifier sends the data to the backend server which execute the payments. The
system uses Convolution Neural Network (CNN) for the image recognition and
processing. CNN is a supervised learning model that has found major application
in pattern recognition problem. The current implementation uses two classifiers
that work intrinsically to authenticate the user and track the items. The model
accuracy for object recognition is 97%, the loss is 9.3%. We expect that such
systems can bring efficiency to the market and has the potential for broad and
diverse applications.
</p>
<a href="http://arxiv.org/abs/2011.06144" target="_blank">arXiv:2011.06144</a> [<a href="http://arxiv.org/pdf/2011.06144" target="_blank">pdf</a>]

<h2>Ensuring Actionable Recourse via Adversarial Training. (arXiv:2011.06146v1 [cs.LG])</h2>
<h3>Alexis Ross, Himabindu Lakkaraju, Osbert Bastani</h3>
<p>As machine learning models are increasingly deployed in high-stakes domains
such as legal and financial decision-making, there has been growing interest in
post-hoc methods for generating counterfactual explanations. Such explanations
provide individuals adversely impacted by predicted outcomes (e.g., an
applicant denied a loan) with "recourse" ---i.e., a description of how they can
change their features to obtain a positive outcome. We propose a novel
algorithm that leverages adversarial training and PAC confidence sets to learn
models that theoretically guarantee recourse to affected individuals with high
probability without sacrificing accuracy. To the best of our knowledge, our
approach is the first to learn models for which recourses are guaranteed with
high probability. Extensive experimentation with real world datasets spanning
various applications including recidivism prediction, bail outcomes, and
lending demonstrate the efficacy of the proposed framework.
</p>
<a href="http://arxiv.org/abs/2011.06146" target="_blank">arXiv:2011.06146</a> [<a href="http://arxiv.org/pdf/2011.06146" target="_blank">pdf</a>]

<h2>Generalized Constraints as A New Mathematical Problem in Artificial Intelligence: A Review and Perspective. (arXiv:2011.06156v1 [cs.AI])</h2>
<h3>Bao-Gang Hu, Han-Bing Qu</h3>
<p>In this comprehensive review, we describe a new mathematical problem in
artificial intelligence (AI) from a mathematical modeling perspective,
following the philosophy stated by Rudolf E. Kalman that "Once you get the
physics right, the rest is mathematics". The new problem is called "Generalized
Constraints (GCs)", and we adopt GCs as a general term to describe any type of
prior information in modelings. To understand better about GCs to be a general
problem, we compare them with the conventional constraints (CCs) and list their
extra challenges over CCs. In the construction of AI machines, we basically
encounter more often GCs for modeling, rather than CCs with well-defined forms.
Furthermore, we discuss the ultimate goals of AI and redefine transparent,
interpretable, and explainable AI in terms of comprehension levels about
machines. We review the studies in relation to the GC problems although most of
them do not take the notion of GCs. We demonstrate that if AI machines are
simplified by a coupling with both knowledge-driven submodel and data-driven
submodel, GCs will play a critical role in a knowledge-driven submodel as well
as in the coupling form between the two submodels. Examples are given to show
that the studies in view of a generalized constraint problem will help us
perceive and explore novel subjects in AI, or even in mathematics, such as
generalized constraint learning (GCL).
</p>
<a href="http://arxiv.org/abs/2011.06156" target="_blank">arXiv:2011.06156</a> [<a href="http://arxiv.org/pdf/2011.06156" target="_blank">pdf</a>]

<h2>Intermittent Visual Servoing: Efficiently Learning Policies Robust to Instrument Changes for High-precision Surgical Manipulation. (arXiv:2011.06163v1 [cs.RO])</h2>
<h3>Samuel Paradis, Minho Hwang, Brijen Thananjeyan, Jeffrey Ichnowski, Daniel Seita, Danyal Fer, Thomas Low, Joseph E. Gonzalez, Ken Goldberg</h3>
<p>Automation of surgical tasks using cable-driven robots is challenging due to
backlash, hysteresis, and cable tension, and these issues are exacerbated as
surgical instruments must often be changed during an operation. In this work,
we propose a framework for automation of high-precision surgical tasks by
learning sample efficient, accurate, closed-loop policies that operate directly
on visual feedback instead of robot encoder estimates. This framework, which we
call intermittent visual servoing (IVS), intermittently switches to a learned
visual servo policy for high-precision segments of repetitive surgical tasks
while relying on a coarse open-loop policy for the segments where precision is
not necessary. To compensate for cable-related effects, we apply imitation
learning to rapidly train a policy that maps images of the workspace and
instrument from a top-down RGB camera to small corrective motions. We train the
policy using only 180 human demonstrations that are roughly 2 seconds each.
Results on a da Vinci Research Kit suggest that combining the coarse policy
with half a second of corrections from the learned policy during each
high-precision segment improves the success rate on the Fundamentals of
Laparoscopic Surgery peg transfer task from 72.9% to 99.2%, 31.3% to 99.2%, and
47.2% to 100.0% for 3 instruments with differing cable-related effects. In the
contexts we studied, IVS attains the highest published success rates for
automated surgical peg transfer and is significantly more reliable than
previous techniques when instruments are changed. Supplementary material is
available at https://tinyurl.com/ivs-icra.
</p>
<a href="http://arxiv.org/abs/2011.06163" target="_blank">arXiv:2011.06163</a> [<a href="http://arxiv.org/pdf/2011.06163" target="_blank">pdf</a>]

<h2>Universal Embeddings for Spatio-Temporal Tagging of Self-Driving Logs. (arXiv:2011.06165v1 [cs.CV])</h2>
<h3>Sean Segal, Eric Kee, Wenjie Luo, Abbas Sadat, Ersin Yumer, Raquel Urtasun</h3>
<p>In this paper, we tackle the problem of spatio-temporal tagging of
self-driving scenes from raw sensor data. Our approach learns a universal
embedding for all tags, enabling efficient tagging of many attributes and
faster learning of new attributes with limited data. Importantly, the embedding
is spatio-temporally aware, allowing the model to naturally output
spatio-temporal tag values. Values can then be pooled over arbitrary regions,
in order to, for example, compute the pedestrian density in front of the SDV,
or determine if a car is blocking another car at a 4-way intersection. We
demonstrate the effectiveness of our approach on a new large scale self-driving
dataset, SDVScenes, containing 15 attributes relating to vehicle and pedestrian
density, the actions of each actor, the speed of each actor, interactions
between actors, and the topology of the road map.
</p>
<a href="http://arxiv.org/abs/2011.06165" target="_blank">arXiv:2011.06165</a> [<a href="http://arxiv.org/pdf/2011.06165" target="_blank">pdf</a>]

<h2>When Does Uncertainty Matter?: Understanding the Impact of Predictive Uncertainty in ML Assisted Decision Making. (arXiv:2011.06167v1 [cs.LG])</h2>
<h3>Sean McGrath, Parth Mehta, Alexandra Zytek, Isaac Lage, Himabindu Lakkaraju</h3>
<p>As machine learning (ML) models are increasingly being employed to assist
human decision makers, it becomes critical to provide these decision makers
with relevant inputs which can help them decide if and how to incorporate model
predictions into their decision making. For instance, communicating the
uncertainty associated with model predictions could potentially be helpful in
this regard. However, there is little to no research that systematically
explores if and how conveying predictive uncertainty impacts decision making.
In this work, we carry out user studies to systematically assess how people
respond to different types of predictive uncertainty i.e., posterior predictive
distributions with different shapes and variances, in the context of ML
assisted decision making. To the best of our knowledge, this work marks one of
the first attempts at studying this question. Our results demonstrate that
people are more likely to agree with a model prediction when they observe the
corresponding uncertainty associated with the prediction. This finding holds
regardless of the properties (shape or variance) of predictive uncertainty
(posterior predictive distribution), suggesting that uncertainty is an
effective tool for persuading humans to agree with model predictions.
Furthermore, we also find that other factors such as domain expertise and
familiarity with ML also play a role in determining how someone interprets and
incorporates predictive uncertainty into their decision making.
</p>
<a href="http://arxiv.org/abs/2011.06167" target="_blank">arXiv:2011.06167</a> [<a href="http://arxiv.org/pdf/2011.06167" target="_blank">pdf</a>]

<h2>Robust and Stable Black Box Explanations. (arXiv:2011.06169v1 [cs.LG])</h2>
<h3>Himabindu Lakkaraju, Nino Arsov, Osbert Bastani</h3>
<p>As machine learning black boxes are increasingly being deployed in real-world
applications, there has been a growing interest in developing post hoc
explanations that summarize the behaviors of these black boxes. However,
existing algorithms for generating such explanations have been shown to lack
stability and robustness to distribution shifts. We propose a novel framework
for generating robust and stable explanations of black box models based on
adversarial training. Our framework optimizes a minimax objective that aims to
construct the highest fidelity explanation with respect to the worst-case over
a set of adversarial perturbations. We instantiate this algorithm for
explanations in the form of linear models and decision sets by devising the
required optimization procedures. To the best of our knowledge, this work makes
the first attempt at generating post hoc explanations that are robust to a
general class of adversarial perturbations that are of practical interest.
Experimental evaluation with real-world and synthetic datasets demonstrates
that our approach substantially improves robustness of explanations without
sacrificing their fidelity on the original data distribution.
</p>
<a href="http://arxiv.org/abs/2011.06169" target="_blank">arXiv:2011.06169</a> [<a href="http://arxiv.org/pdf/2011.06169" target="_blank">pdf</a>]

<h2>Deep Partial Multi-View Learning. (arXiv:2011.06170v1 [cs.LG])</h2>
<h3>Changqing Zhang, Yajie Cui, Zongbo Han, Joey Tianyi Zhou, Huazhu Fu, Qinghua Hu</h3>
<p>Although multi-view learning has made signifificant progress over the past
few decades, it is still challenging due to the diffificulty in modeling
complex correlations among different views, especially under the context of
view missing. To address the challenge, we propose a novel framework termed
Cross Partial Multi-View Networks (CPM-Nets), which aims to fully and
flflexibly take advantage of multiple partial views. We fifirst provide a
formal defifinition of completeness and versatility for multi-view
representation and then theoretically prove the versatility of the learned
latent representations. For completeness, the task of learning latent
multi-view representation is specififically translated to a degradation process
by mimicking data transmission, such that the optimal tradeoff between
consistency and complementarity across different views can be implicitly
achieved. Equipped with adversarial strategy, our model stably imputes missing
views, encoding information from all views for each sample to be encoded into
latent representation to further enhance the completeness. Furthermore, a
nonparametric classifification loss is introduced to produce structured
representations and prevent overfifitting, which endows the algorithm with
promising generalization under view-missing cases. Extensive experimental
results validate the effectiveness of our algorithm over existing state of the
arts for classifification, representation learning and data imputation.
</p>
<a href="http://arxiv.org/abs/2011.06170" target="_blank">arXiv:2011.06170</a> [<a href="http://arxiv.org/pdf/2011.06170" target="_blank">pdf</a>]

<h2>Optimizing Large-Scale Fleet Management on a Road Network using Multi-Agent Deep Reinforcement Learning with Graph Neural Network. (arXiv:2011.06175v1 [cs.LG])</h2>
<h3>Juhyeon Kim</h3>
<p>Optimizing fleet management is an important issue in ride-hailing service in
terms of customer's satisfaction and increased revenue for drivers. However
finding an optimal strategy in a real environment that demand and supply are
changing in real time, is a challenging problem. In this paper, we try to solve
this problem by using multi-agent reinforcement learning. Instead of grid which
was used in existing works, we use a graph to represent road network more
realistically. We model the problem using Markov game and adopt stochastic
policy update which can resolve the problem of greedy policy update in
multi-agent scheme. We use modified DQN to fit our problem. To approximate Q
values on the graph, we use two basic graph neural networks, GCN and GAT. We
design a simulator using real taxi call data and evaluate the algorithms under
various conditions. The result demonstrates effectiveness of the proposed
stochastic policy update model with graph neural network.
</p>
<a href="http://arxiv.org/abs/2011.06175" target="_blank">arXiv:2011.06175</a> [<a href="http://arxiv.org/pdf/2011.06175" target="_blank">pdf</a>]

<h2>LIAF-Net: Leaky Integrate and Analog Fire Network for Lightweight and Efficient Spatiotemporal Information Processing. (arXiv:2011.06176v1 [cs.LG])</h2>
<h3>Zhenzhi Wu, Hehui Zhang, Yihan Lin, Guoqi Li, Meng Wang, Ye Tang</h3>
<p>Spiking neural networks (SNNs) based on Leaky Integrate and Fire (LIF) model
have been applied to energy-efficient temporal and spatiotemporal processing
tasks. Thanks to the bio-plausible neuronal dynamics and simplicity, LIF-SNN
benefits from event-driven processing, however, usually faces the embarrassment
of reduced performance. This may because in LIF-SNN the neurons transmit
information via spikes. To address this issue, in this work, we propose a Leaky
Integrate and Analog Fire (LIAF) neuron model, so that analog values can be
transmitted among neurons, and a deep network termed as LIAF-Net is built on it
for efficient spatiotemporal processing. In the temporal domain, LIAF follows
the traditional LIF dynamics to maintain its temporal processing capability. In
the spatial domain, LIAF is able to integrate spatial information through
convolutional integration or fully-connected integration. As a spatiotemporal
layer, LIAF can also be used with traditional artificial neural network (ANN)
layers jointly. Experiment results indicate that LIAF-Net achieves comparable
performance to Gated Recurrent Unit (GRU) and Long short-term memory (LSTM) on
bAbI Question Answering (QA) tasks, and achieves state-of-the-art performance
on spatiotemporal Dynamic Vision Sensor (DVS) datasets, including MNIST-DVS,
CIFAR10-DVS and DVS128 Gesture, with much less number of synaptic weights and
computational overhead compared with traditional networks built by LSTM, GRU,
Convolutional LSTM (ConvLSTM) or 3D convolution (Conv3D). Compared with
traditional LIF-SNN, LIAF-Net also shows dramatic accuracy gain on all these
experiments. In conclusion, LIAF-Net provides a framework combining the
advantages of both ANNs and SNNs for lightweight and efficient spatiotemporal
information processing.
</p>
<a href="http://arxiv.org/abs/2011.06176" target="_blank">arXiv:2011.06176</a> [<a href="http://arxiv.org/pdf/2011.06176" target="_blank">pdf</a>]

<h2>Bi-tuning of Pre-trained Representations. (arXiv:2011.06182v1 [cs.LG])</h2>
<h3>Jincheng Zhong, Ximei Wang, Zhi Kou, Jianmin Wang, Mingsheng Long</h3>
<p>It is common within the deep learning community to first pre-train a deep
neural network from a large-scale dataset and then fine-tune the pre-trained
model to a specific downstream task. Recently, both supervised and unsupervised
pre-training approaches to learning representations have achieved remarkable
advances, which exploit the discriminative knowledge of labels and the
intrinsic structure of data, respectively. It follows natural intuition that
both discriminative knowledge and intrinsic structure of the downstream task
can be useful for fine-tuning, however, existing fine-tuning methods mainly
leverage the former and discard the latter. A question arises: How to fully
explore the intrinsic structure of data for boosting fine-tuning? In this
paper, we propose Bi-tuning, a general learning framework to fine-tuning both
supervised and unsupervised pre-trained representations to downstream tasks.
Bi-tuning generalizes the vanilla fine-tuning by integrating two heads upon the
backbone of pre-trained representations: a classifier head with an improved
contrastive cross-entropy loss to better leverage the label information in an
instance-contrast way, and a projector head with a newly-designed categorical
contrastive learning loss to fully exploit the intrinsic structure of data in a
category-consistent way. Comprehensive experiments confirm that Bi-tuning
achieves state-of-the-art results for fine-tuning tasks of both supervised and
unsupervised pre-trained models by large margins (e.g. 10.7\% absolute rise in
accuracy on CUB in low-data regime).
</p>
<a href="http://arxiv.org/abs/2011.06182" target="_blank">arXiv:2011.06182</a> [<a href="http://arxiv.org/pdf/2011.06182" target="_blank">pdf</a>]

<h2>Towards Optimal Problem Dependent Generalization Error Bounds in Statistical Learning Theory. (arXiv:2011.06186v1 [stat.ML])</h2>
<h3>Yunbei Xu, Assaf Zeevi</h3>
<p>We study problem-dependent rates, i.e., generalization errors that scale
near-optimally with the variance, the effective loss, or the gradient norms
evaluated at the "best hypothesis." We introduce a principled framework dubbed
"uniform localized convergence," and characterize sharp problem-dependent rates
for central statistical learning problems. From a methodological viewpoint, our
framework resolves several fundamental limitations of existing uniform
convergence and localization analysis approaches. It also provides improvements
and some level of unification in the study of localized complexities, one-sided
uniform inequalities, and sample-based iterative algorithms. In the so-called
"slow rate" regime, we provides the first (moment-penalized) estimator that
achieves the optimal variance-dependent rate for general "rich" classes; we
also establish improved loss-dependent rate for standard empirical risk
minimization. In the "fast rate" regime, we establish finite-sample
problem-dependent bounds that are comparable to precise asymptotics. In
addition, we show that efficient algorithms like gradient descent and
first-order Expectation-Maximization can achieve optimal generalization error
in several representative problems across the areas of non-convex learning,
stochastic optimization, and learning with missing data.
</p>
<a href="http://arxiv.org/abs/2011.06186" target="_blank">arXiv:2011.06186</a> [<a href="http://arxiv.org/pdf/2011.06186" target="_blank">pdf</a>]

<h2>Evaluating Curriculum Learning Strategies in Neural Combinatorial Optimization. (arXiv:2011.06188v1 [cs.LG])</h2>
<h3>Michal Lisicki, Arash Afkanpour, Graham W. Taylor</h3>
<p>Neural combinatorial optimization (NCO) aims at designing problem-independent
and efficient neural network-based strategies for solving combinatorial
problems. The field recently experienced growth by successfully adapting
architectures originally designed for machine translation. Even though the
results are promising, a large gap still exists between NCO models and classic
deterministic solvers, both in terms of accuracy and efficiency. One of the
drawbacks of current approaches is the inefficiency of training on multiple
problem sizes. Curriculum learning strategies have been shown helpful in
increasing performance in the multi-task setting. In this work, we focus on
designing a curriculum learning-based training procedure that can help existing
architectures achieve competitive performance on a large range of problem sizes
simultaneously. We provide a systematic investigation of several training
procedures and use the insights gained to motivate application of a
psychologically-inspired approach to improve upon the classic curriculum
method.
</p>
<a href="http://arxiv.org/abs/2011.06188" target="_blank">arXiv:2011.06188</a> [<a href="http://arxiv.org/pdf/2011.06188" target="_blank">pdf</a>]

<h2>Gaussian RAM: Lightweight Image Classification via Stochastic Retina-Inspired Glimpse and Reinforcement Learning. (arXiv:2011.06190v1 [cs.CV])</h2>
<h3>Dongseok Shim, H. Jin Kim</h3>
<p>Previous studies on image classification have mainly focused on the
performance of the networks, not on real-time operation or model compression.
We propose a Gaussian Deep Recurrent visual Attention Model (GDRAM)- a
reinforcement learning based lightweight deep neural network for large scale
image classification that outperforms the conventional CNN (Convolutional
Neural Network) which uses the entire image as input. Highly inspired by the
biological visual recognition process, our model mimics the stochastic location
of the retina with Gaussian distribution. We evaluate the model on Large
cluttered MNIST, Large CIFAR-10 and Large CIFAR-100 datasets which are resized
to 128 in both width and height.
</p>
<a href="http://arxiv.org/abs/2011.06190" target="_blank">arXiv:2011.06190</a> [<a href="http://arxiv.org/pdf/2011.06190" target="_blank">pdf</a>]

<h2>Motion Generation Using Bilateral Control-Based Imitation Learning with Autoregressive Learning. (arXiv:2011.06192v1 [cs.RO])</h2>
<h3>Ayumu Sasagawa, Sho Sakaino, Toshiaki Tsuji</h3>
<p>Robots that can execute various tasks automatically on behalf of humans are
becoming an increasingly important focus of research in the field of robotics.
Imitation learning has been studied as an efficient and high-performance
method, and imitation learning based on bilateral control has been proposed as
a method that can realize fast motion. However, because this method cannot
implement autoregressive learning, this method may not generate desirable
long-term behavior. Therefore, in this paper, we propose a method of
autoregressive learning for bilateral control-based imitation learning. A new
neural network model for implementing autoregressive learning is proposed. In
this study, three types of experiments are conducted to verify the
effectiveness of the proposed method. The performance is improved compared to
conventional approaches; the proposed method has the highest rate of success.
Owing to the structure and autoregressive learning of the proposed model, the
proposed method can generate the desirable motion for successful tasks and have
a high generalization ability for environmental changes.
</p>
<a href="http://arxiv.org/abs/2011.06192" target="_blank">arXiv:2011.06192</a> [<a href="http://arxiv.org/pdf/2011.06192" target="_blank">pdf</a>]

<h2>A Factor-Graph Approach for Optimization Problems with Dynamics Constraints. (arXiv:2011.06194v1 [cs.RO])</h2>
<h3>Mandy Xie, Alejandro Escontrela, Frank Dellaert</h3>
<p>In this paper, we introduce dynamics factor graphs as a graphical framework
to solve dynamics problems and kinodynamic motion planning problems with full
consideration of whole-body dynamics and contacts. A factor graph
representation of dynamics problems provides an insightful visualization of
their mathematical structure and can be used in conjunction with sparse
nonlinear optimizers to solve challenging, high-dimensional optimization
problems in robotics. We can easily formulate kinodynamic motion planning as a
trajectory optimization problem with factor graphs. We demonstrate the
flexibility and descriptive power of dynamics factor graphs by applying them to
control various dynamical systems, ranging from a simple cart pole to a 12-DoF
quadrupedal robot.
</p>
<a href="http://arxiv.org/abs/2011.06194" target="_blank">arXiv:2011.06194</a> [<a href="http://arxiv.org/pdf/2011.06194" target="_blank">pdf</a>]

<h2>Domain Generalization in Biosignal Classification. (arXiv:2011.06207v1 [cs.CV])</h2>
<h3>Theekshana Dissanayake, Tharindu Fernando, Simon Denman, Houman Ghaemmaghami, Sridha Sridharan, Clinton Fookes</h3>
<p>Objective: When training machine learning models, we often assume that the
training data and evaluation data are sampled from the same distribution.
However, this assumption is violated when the model is evaluated on another
unseen but similar database, even if that database contains the same classes.
This problem is caused by domain-shift and can be solved using two approaches:
domain adaptation and domain generalization. Simply, domain adaptation methods
can access data from unseen domains during training; whereas in domain
generalization, the unseen data is not available during training. Hence, domain
generalization concerns models that perform well on inaccessible,
domain-shifted data. Method: Our proposed domain generalization method
represents an unseen domain using a set of known basis domains, afterwhich we
classify the unseen domain using classifier fusion. To demonstrate our system,
we employ a collection of heart sound databases that contain normal and
abnormal sounds (classes). Results: Our proposed classifier fusion method
achieves accuracy gains of up to 16% for four completely unseen domains.
Conclusion: Recognizing the complexity induced by the inherent temporal nature
of biosignal data, the two-stage method proposed in this study is able to
effectively simplify the whole process of domain generalization while
demonstrating good results on unseen domains and the adopted basis domains.
Significance: To our best knowledge, this is the first study that investigates
domain generalization for biosignal data. Our proposed learning strategy can be
used to effectively learn domain-relevant features while being aware of the
class differences in the data.
</p>
<a href="http://arxiv.org/abs/2011.06207" target="_blank">arXiv:2011.06207</a> [<a href="http://arxiv.org/pdf/2011.06207" target="_blank">pdf</a>]

<h2>A Transfer Learning Framework for Anomaly Detection Using Model of Normality. (arXiv:2011.06210v1 [cs.LG])</h2>
<h3>Sulaiman Aburakhia, Tareq Tayeh, Ryan Myers, Abdallah Shami</h3>
<p>Convolutional Neural Network (CNN) techniques have proven to be very useful
in image-based anomaly detection applications. CNN can be used as deep features
extractor where other anomaly detection techniques are applied on these
features. For this scenario, using transfer learning is common since pretrained
models provide deep feature representations that are useful for anomaly
detection tasks. Consequentially, anomaly can be detected by applying similarly
measure between extracted features and a defined model of normality. A key
factor in such approaches is the decision threshold used for detecting anomaly.
While most of the proposed methods focus on the approach itself, slight
attention has been paid to address decision threshold settings. In this paper,
we tackle this problem and propose a welldefined method to set the
working-point decision threshold that improves detection accuracy. We introduce
a transfer learning framework for anomaly detection based on similarity measure
with a Model of Normality (MoN) and show that with the proposed threshold
settings, a significant performance improvement can be achieved. Moreover, the
framework has low complexity with relaxed computational requirements.
</p>
<a href="http://arxiv.org/abs/2011.06210" target="_blank">arXiv:2011.06210</a> [<a href="http://arxiv.org/pdf/2011.06210" target="_blank">pdf</a>]

<h2>Unimodal Cyclic Regularization for Training Multimodal Image Registration Networks. (arXiv:2011.06214v1 [cs.CV])</h2>
<h3>Zhe Xu, Jiangpeng Yan, Jie Luo, William Wells, Xiu Li, Jayender Jagadeesan</h3>
<p>The loss function of an unsupervised multimodal image registration framework
has two terms, i.e., a metric for similarity measure and regularization. In the
deep learning era, researchers proposed many approaches to automatically learn
the similarity metric, which has been shown effective in improving registration
performance. However, for the regularization term, most existing multimodal
registration approaches still use a hand-crafted formula to impose artificial
properties on the estimated deformation field. In this work, we propose a
unimodal cyclic regularization training pipeline, which learns task-specific
prior knowledge from simpler unimodal registration, to constrain the
deformation field of multimodal registration. In the experiment of abdominal
CT-MR registration, the proposed method yields better results over conventional
regularization methods, especially for severely deformed local regions.
</p>
<a href="http://arxiv.org/abs/2011.06214" target="_blank">arXiv:2011.06214</a> [<a href="http://arxiv.org/pdf/2011.06214" target="_blank">pdf</a>]

<h2>Unsupervised Multimodal Image Registration with Adaptative Gradient Guidance. (arXiv:2011.06216v1 [cs.CV])</h2>
<h3>Zhe Xu, Jiangpeng Yan, Jie Luo, Xiu Li, Jayender Jagadeesan</h3>
<p>Multimodal image registration (MIR) is a fundamental procedure in many
image-guided therapies. Recently, unsupervised learning-based methods have
demonstrated promising performance over accuracy and efficiency in deformable
image registration. However, the estimated deformation fields of the existing
methods fully rely on the to-be-registered image pair. It is difficult for the
networks to be aware of the mismatched boundaries, resulting in unsatisfactory
organ boundary alignment. In this paper, we propose a novel multimodal
registration framework, which leverages the deformation fields estimated from
both: (i) the original to-be-registered image pair, (ii) their corresponding
gradient intensity maps, and adaptively fuses them with the proposed gated
fusion module. With the help of auxiliary gradient-space guidance, the network
can concentrate more on the spatial relationship of the organ boundary.
Experimental results on two clinically acquired CT-MRI datasets demonstrate the
effectiveness of our proposed approach.
</p>
<a href="http://arxiv.org/abs/2011.06216" target="_blank">arXiv:2011.06216</a> [<a href="http://arxiv.org/pdf/2011.06216" target="_blank">pdf</a>]

<h2>Accessible Torque Bandwidth of a Series Elastic Actuator Considering the Thermodynamic Limitations. (arXiv:2011.06217v1 [cs.RO])</h2>
<h3>Bhanuka Silva, Navinda Kottege</h3>
<p>Within the scope of the paper, electromechanical and thermodynamic models are
derived for a series elastic actuator and open loop and closed loop torque
bandwidth parameters are analysed considering the thermodynamic behaviour of
the actuator. It was observed that the closed loop torque bandwidth of the
electromechanical subsystem of the actuator was not accessible in the entire
torque reference amplitude range due to thermodynamic limitations. Therefore, a
stator winding temperature estimation based adaptive controller is utilised and
analysed to improve the accessibility of the controller based torque bandwidth.
This paper implements the methodology on a HEBI Robotics X5-9 actuator as a
case study.
</p>
<a href="http://arxiv.org/abs/2011.06217" target="_blank">arXiv:2011.06217</a> [<a href="http://arxiv.org/pdf/2011.06217" target="_blank">pdf</a>]

<h2>Adding Knowledge to Unsupervised Algorithms for the Recognition of Intent. (arXiv:2011.06219v1 [cs.CV])</h2>
<h3>Stuart Synakowski, Qianli Feng, Aleix Martinez</h3>
<p>Computer vision algorithms performance are near or superior to humans in the
visual problems including object recognition (especially those of fine-grained
categories), segmentation, and 3D object reconstruction from 2D views. Humans
are, however, capable of higher-level image analyses. A clear example,
involving theory of mind, is our ability to determine whether a perceived
behavior or action was performed intentionally or not. In this paper, we derive
an algorithm that can infer whether the behavior of an agent in a scene is
intentional or unintentional based on its 3D kinematics, using the knowledge of
self-propelled motion, Newtonian motion and their relationship. We show how the
addition of this basic knowledge leads to a simple, unsupervised algorithm. To
test the derived algorithm, we constructed three dedicated datasets from
abstract geometric animation to realistic videos of agents performing
intentional and non-intentional actions. Experiments on these datasets show
that our algorithm can recognize whether an action is intentional or not, even
without training data. The performance is comparable to various supervised
baselines quantitatively, with sensible intentionality segmentation
qualitatively.
</p>
<a href="http://arxiv.org/abs/2011.06219" target="_blank">arXiv:2011.06219</a> [<a href="http://arxiv.org/pdf/2011.06219" target="_blank">pdf</a>]

<h2>Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting. (arXiv:2011.06220v1 [cs.LG])</h2>
<h3>Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, Dacheng Tao, Masashi Sugiyama</h3>
<p>Deep learning is often criticized by two serious issues which rarely exist in
natural nervous systems: overfitting and catastrophic forgetting. It can even
memorize randomly labelled data, which has little knowledge behind the
instance-label pairs. When a deep network continually learns over time by
accommodating new tasks, it usually quickly overwrites the knowledge learned
from previous tasks. Referred to as the neural variability, it is well-known in
neuroscience that human brain reactions exhibit substantial variability even in
response to the same stimulus. This mechanism balances accuracy and
plasticity/flexibility in the motor learning of natural nervous systems. Thus
it motivates us to design a similar mechanism named artificial neural
variability (ANV), which helps artificial neural networks learn some advantages
from "natural" neural networks. We rigorously prove that ANV plays as an
implicit regularizer of the mutual information between the training data and
the learned model. This result theoretically guarantees ANV a strictly improved
generalizability, robustness to label noise, and robustness to catastrophic
forgetting. We then devise a neural variable risk minimization (NVRM) framework
and neural variable optimizers to achieve ANV for conventional network
architectures in practice. The empirical studies demonstrate that NVRM can
effectively relieve overfitting, label noise memorization, and catastrophic
forgetting at negligible costs.
</p>
<a href="http://arxiv.org/abs/2011.06220" target="_blank">arXiv:2011.06220</a> [<a href="http://arxiv.org/pdf/2011.06220" target="_blank">pdf</a>]

<h2>A Review of Uncertainty Quantification in Deep Learning: Techniques, Applications and Challenges. (arXiv:2011.06225v1 [cs.LG])</h2>
<h3>Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Abbas Khosravi, U Rajendra Acharya, Vladimir Makarenkov, Saeid Nahavandi</h3>
<p>Uncertainty quantification (UQ) plays a pivotal role in reduction of
uncertainties during both optimization and decision making processes. It can be
applied to solve a variety of real-world applications in science and
engineering. Bayesian approximation and ensemble learning techniques are two
most widely-used UQ methods in the literature. In this regard, researchers have
proposed different UQ methods and examined their performance in a variety of
applications such as computer vision (e.g., self-driving cars and object
detection), image processing (e.g., image restoration), medical image analysis
(e.g., medical image classification and segmentation), natural language
processing (e.g., text classification, social media texts and recidivism
risk-scoring), bioinformatics, etc.This study reviews recent advances in UQ
methods used in deep learning. Moreover, we also investigate the application of
these methods in reinforcement learning (RL). Then, we outline a few important
applications of UQ methods. Finally, we briefly highlight the fundamental
research challenges faced by UQ methods and discuss the future research
directions in this field.
</p>
<a href="http://arxiv.org/abs/2011.06225" target="_blank">arXiv:2011.06225</a> [<a href="http://arxiv.org/pdf/2011.06225" target="_blank">pdf</a>]

<h2>Autonomous Obstacle Legipulation with a Hexapod Robot. (arXiv:2011.06227v1 [cs.RO])</h2>
<h3>Bethany Lu, Benjamin Tam, Navinda Kottege</h3>
<p>Legged robots traversing in confined environments could find their only path
is blocked by obstacles. In circumstances where the obstacles are movable, a
multilegged robot can manipulate the obstacles using its legs to allow it to
continue on its path. We present a method for a hexapod robot to autonomously
generate manipulation trajectories for detected obstacles. Using a RGB-D sensor
as input, the obstacle is extracted from the environment and filtered to
provide key contact points for the manipulation algorithm to calculate a
trajectory to move the obstacle out of the path. Experiments on a 30 degree of
freedom hexapod robot show the effectiveness of the algorithm in manipulating a
range of obstacles in a 3D environment using its front legs.
</p>
<a href="http://arxiv.org/abs/2011.06227" target="_blank">arXiv:2011.06227</a> [<a href="http://arxiv.org/pdf/2011.06227" target="_blank">pdf</a>]

<h2>DSAM: A Distance Shrinking with Angular Marginalizing Loss for High Performance Vehicle Re-identificatio. (arXiv:2011.06228v1 [cs.CV])</h2>
<h3>Jiangtao Kong, Yu Cheng, Kai Li, Junliang Xing</h3>
<p>Vehicle Re-identification (ReID) is an important yet challenging problem in
computer vision. Compared to other visual objects like faces and persons,
vehicles simultaneously exhibit much larger intraclass viewpoint variations and
interclass visual similarities, making most exiting loss functions designed for
face recognition and person ReID unsuitable for vehicle ReID. To obtain a
high-performance vehicle ReID model, we present a novel Distance Shrinking with
Angular Marginalizing (DSAM) loss function to perform hybrid learning in both
the Original Feature Space (OFS) and the Feature Angular Space (FAS) using the
local verification and the global identification information. Specifically, it
shrinks the distance between samples of the same class locally in the Original
Feature Space while keeps samples of different classes far away in the Feature
Angular Space. The shrinking and marginalizing operations are performed during
each iteration of the training process and are suitable for different SoftMax
based loss functions. We evaluate the DSAM loss function on three large vehicle
ReID datasets with detailed analyses and extensive comparisons with many
competing vehicle ReID methods. Experimental results show that our DSAM loss
enhances the SoftMax loss by a large margin on the PKU-VD1-Large dataset:
10.41% for mAP, 5.29% for cmc1, and 4.60% for cmc5. Moreover, the mAP is
increased by 9.34% on the PKU-VehicleID dataset and 8.73% on the VeRi-776
dataset. Source code will be released to facilitate further studies in this
research direction.
</p>
<a href="http://arxiv.org/abs/2011.06228" target="_blank">arXiv:2011.06228</a> [<a href="http://arxiv.org/pdf/2011.06228" target="_blank">pdf</a>]

<h2>Automated Model Compression by Jointly Applied Pruning and Quantization. (arXiv:2011.06231v1 [cs.CV])</h2>
<h3>Wenting Tang, Xingxing Wei, Bo Li</h3>
<p>In the traditional deep compression framework, iteratively performing network
pruning and quantization can reduce the model size and computation cost to meet
the deployment requirements. However, such a step-wise application of pruning
and quantization may lead to suboptimal solutions and unnecessary time
consumption. In this paper, we tackle this issue by integrating network pruning
and quantization as a unified joint compression problem and then use AutoML to
automatically solve it. We find the pruning process can be regarded as the
channel-wise quantization with 0 bit. Thus, the separate two-step pruning and
quantization can be simplified as the one-step quantization with mixed
precision. This unification not only simplifies the compression pipeline but
also avoids the compression divergence. To implement this idea, we propose the
automated model compression by jointly applied pruning and quantization (AJPQ).
AJPQ is designed with a hierarchical architecture: the layer controller
controls the layer sparsity, and the channel controller decides the bit-width
for each kernel. Following the same importance criterion, the layer controller
and the channel controller collaboratively decide the compression strategy.
With the help of reinforcement learning, our one-step compression is
automatically achieved. Compared with the state-of-the-art automated
compression methods, our method obtains a better accuracy while reducing the
storage considerably. For fixed precision quantization, AJPQ can reduce more
than five times model size and two times computation with a slight performance
increase for Skynet in remote sensing object detection. When mixed-precision is
allowed, AJPQ can reduce five times model size with only 1.06% top-5 accuracy
decline for MobileNet in the classification task.
</p>
<a href="http://arxiv.org/abs/2011.06231" target="_blank">arXiv:2011.06231</a> [<a href="http://arxiv.org/pdf/2011.06231" target="_blank">pdf</a>]

<h2>Anticipatory Navigation in Crowds by Probabilistic Prediction of Pedestrian Future Movements. (arXiv:2011.06235v1 [cs.RO])</h2>
<h3>Weiming Zhi, Tin Lai, Lionel Ott, Fabio Ramos</h3>
<p>Critical for the coexistence of humans and robots in dynamic environments is
the capability for agents to understand each other's actions, and anticipate
their movements. This paper presents Stochastic Process Anticipatory Navigation
(SPAN), a framework that enables nonholonomic robots to navigate in
environments with crowds, while anticipating and accounting for the motion
patterns of pedestrians. To this end, we learn a predictive model to predict
continuous-time stochastic processes to model future movement of pedestrians.
Anticipated pedestrian positions are used to conduct chance constrained
collision-checking, and are incorporated into a time-to-collision control
problem. An occupancy map is also integrated to allow for probabilistic
collision-checking with static obstacles. We demonstrate the capability of SPAN
in crowded simulation environments, as well as with a real-world pedestrian
dataset.
</p>
<a href="http://arxiv.org/abs/2011.06235" target="_blank">arXiv:2011.06235</a> [<a href="http://arxiv.org/pdf/2011.06235" target="_blank">pdf</a>]

<h2>Adaptive Force-based Control for Legged Robots. (arXiv:2011.06236v1 [cs.RO])</h2>
<h3>Mohsen Sombolestan, Yiyu Chen, Quan Nguyen</h3>
<p>In this paper, we present a novel methodology to introduce adaptive control
for force-based control systems, with application to legged robots. In our
approach, the reference model is based on the quadratic program force control.
We evaluate our proposed control design on a high-fidelity physical simulation
of LASER, a dynamic quadruped robot. Our proposed method guarantees
input-to-state stability and is successfully validated for the problem of
quadruped robots walking on rough terrain while carrying unknown and
time-varying loads.
</p>
<a href="http://arxiv.org/abs/2011.06236" target="_blank">arXiv:2011.06236</a> [<a href="http://arxiv.org/pdf/2011.06236" target="_blank">pdf</a>]

<h2>PoseTrackReID: Dataset Description. (arXiv:2011.06243v1 [cs.CV])</h2>
<h3>Andreas Doering, Di Chen, Shanshan Zhang, Bernt Schiele, Juergen Gall</h3>
<p>Current datasets for video-based person re-identification (re-ID) do not
include structural knowledge in form of human pose annotations for the persons
of interest. Nonetheless, pose information is very helpful to disentangle
useful feature information from background or occlusion noise. Especially
real-world scenarios, such as surveillance, contain a lot of occlusions in
human crowds or by obstacles. On the other hand, video-based person re-ID can
benefit other tasks such as multi-person pose tracking in terms of robust
feature matching. For that reason, we present PoseTrackReID, a large-scale
dataset for multi-person pose tracking and video-based person re-ID. With
PoseTrackReID, we want to bridge the gap between person re-ID and multi-person
pose tracking. Additionally, this dataset provides a good benchmark for current
state-of-the-art methods on multi-frame person re-ID.
</p>
<a href="http://arxiv.org/abs/2011.06243" target="_blank">arXiv:2011.06243</a> [<a href="http://arxiv.org/pdf/2011.06243" target="_blank">pdf</a>]

<h2>VCE: Variational Convertor-Encoder for One-Shot Generalization. (arXiv:2011.06246v1 [cs.CV])</h2>
<h3>Chengshuai Li, Shuai Han, Jianping Xing</h3>
<p>Variational Convertor-Encoder (VCE) converts an image to various styles; we
present this novel architecture for the problem of one-shot generalization and
its transfer to new tasks not seen before without additional training. We also
improve the performance of variational auto-encoder (VAE) to filter those
blurred points using a novel algorithm proposed by us, namely large margin VAE
(LMVAE). Two samples with the same property are input to the encoder, and then
a convertor is required to processes one of them from the noisy outputs of the
encoder; finally, the noise represents a variety of transformation rules and is
used to convert new images. The algorithm that combines and improves the
condition variational auto-encoder (CVAE) and introspective VAE, we propose
this new framework aim to transform graphics instead of generating them; it is
used for the one-shot generative process. No sequential inference algorithmic
is needed in training. Compared to recent Omniglot datasets, the results show
that our model produces more realistic and diverse images.
</p>
<a href="http://arxiv.org/abs/2011.06246" target="_blank">arXiv:2011.06246</a> [<a href="http://arxiv.org/pdf/2011.06246" target="_blank">pdf</a>]

<h2>SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater Robots. (arXiv:2011.06252v1 [cs.CV])</h2>
<h3>Md Jahidul Islam, Ruobing Wang, Karin de Langis, Junaed Sattar</h3>
<p>This paper presents a holistic approach to saliency-guided visual attention
modeling (SVAM) for use by autonomous underwater robots. Our proposed model,
named SVAM-Net, integrates deep visual features at various scales and semantics
for effective salient object detection (SOD) in natural underwater images. The
SVAM-Net architecture is configured in a unique way to jointly accommodate
bottom-up and top-down learning within two separate branches of the network
while sharing the same encoding layers. We design dedicated spatial attention
modules (SAMs) along these learning pathways to exploit the coarse-level and
fine-level semantic features for SOD at four stages of abstractions. The
bottom-up branch performs a rough yet reasonably accurate saliency estimation
at a fast rate, whereas the deeper top-down branch incorporates a residual
refinement module (RRM) that provides fine-grained localization of the salient
objects. Extensive performance evaluation of SVAM-Net on benchmark datasets
clearly demonstrates its effectiveness for underwater SOD. We also validate its
generalization performance by several ocean trials' data that include test
images of diverse underwater scenes and waterbodies, and also images with
unseen natural objects. Moreover, we analyze its computational feasibility for
robotic deployments and demonstrate its utility in several important use cases
of visual attention modeling.
</p>
<a href="http://arxiv.org/abs/2011.06252" target="_blank">arXiv:2011.06252</a> [<a href="http://arxiv.org/pdf/2011.06252" target="_blank">pdf</a>]

<h2>Learning to Segment Dynamic Objects using SLAM Outliers. (arXiv:2011.06259v1 [cs.CV])</h2>
<h3>Adrian Bojko, Romain Dupont, Mohamed Tamaazousti, Herv&#xe9; Le Borgne</h3>
<p>We present a method to automatically learn to segment dynamic objects using
SLAM outliers. It requires only one monocular sequence per dynamic object for
training and consists in localizing dynamic objects using SLAM outliers,
creating their masks, and using these masks to train a semantic segmentation
network. We integrate the trained network in ORB-SLAM 2 and LDSO. At runtime we
remove features on dynamic objects, making the SLAM unaffected by them. We also
propose a new stereo dataset and new metrics to evaluate SLAM robustness. Our
dataset includes consensus inversions, i.e., situations where the SLAM uses
more features on dynamic objects that on the static background. Consensus
inversions are challenging for SLAM as they may cause major SLAM failures. Our
approach performs better than the State-of-the-Art on the TUM RGB-D dataset in
monocular mode and on our dataset in both monocular and stereo modes.
</p>
<a href="http://arxiv.org/abs/2011.06259" target="_blank">arXiv:2011.06259</a> [<a href="http://arxiv.org/pdf/2011.06259" target="_blank">pdf</a>]

<h2>Performance of Bounded-Rational Agents With the Ability to Self-Modify. (arXiv:2011.06275v1 [cs.AI])</h2>
<h3>Jakub T&#x11b;tek, Marek Sklenka, Tom&#xe1;&#x161; Gaven&#x10d;iak</h3>
<p>Self-modification of agents embedded in complex environments is hard to
avoid, whether it happens via direct means (e.g. own code modification) or
indirectly (e.g. influencing the operator, exploiting bugs or the environment).
While it has been argued that intelligent agents have an incentive to avoid
modifying their utility function so that their future instances will work
towards the same goals, it is not clear whether this also applies in
non-dualistic scenarios, where the agent is embedded in the environment. The
problem of self-modification safety is raised by Bostrom in Superintelligence
(2014) in the context of safe AGI deployment. In contrast to Everitt et al.
(2016), who formally show that providing an option to self-modify is harmless
for perfectly rational agents, we show that for agents with bounded
rationality, self-modification may cause exponential deterioration in
performance and gradual misalignment of a previously aligned agent. We
investigate how the size of this effect depends on the type and magnitude of
imperfections in the agent's rationality (1-4 below). We also discuss model
assumptions and the wider problem and framing space. Specifically, we introduce
several types of a bounded-rational agent, which either (1) doesn't always
choose the optimal action, (2) is not perfectly aligned with human values, (3)
has an innacurate model of the environment, or (4) uses the wrong temporal
discounting factor. We show that while in the cases (2)-(4) the misalignment
caused by the agent's imperfection does not worsen over time, with (1) the
misalignment may grow exponentially.
</p>
<a href="http://arxiv.org/abs/2011.06275" target="_blank">arXiv:2011.06275</a> [<a href="http://arxiv.org/pdf/2011.06275" target="_blank">pdf</a>]

<h2>On Designing Computing Systems for Autonomous Vehicles: a PerceptIn Case Study. (arXiv:2011.06277v1 [cs.RO])</h2>
<h3>Bo Yu, Jie Tang, Shaoshan Liu</h3>
<p>PerceptIn develops and commercializes autonomous vehicles for micromobility
around the globe. This paper makes a holistic summary of PerceptIn's
development and operating experiences. This paper provides the business tale
behind our product, and presents the development of the computing system for
our vehicles. We illustrate the design decision made for the computing system,
and show the advantage of offloading localization workloads onto an FPGA
platform.
</p>
<a href="http://arxiv.org/abs/2011.06277" target="_blank">arXiv:2011.06277</a> [<a href="http://arxiv.org/pdf/2011.06277" target="_blank">pdf</a>]

<h2>Fed-Focal Loss for imbalanced data classification in Federated Learning. (arXiv:2011.06283v1 [cs.LG])</h2>
<h3>Dipankar Sarkar, Ankur Narang, Sumit Rai</h3>
<p>The Federated Learning setting has a central server coordinating the training
of a model on a network of devices. One of the challenges is variable training
performance when the dataset has a class imbalance. In this paper, we address
this by introducing a new loss function called Fed-Focal Loss. We propose to
address the class imbalance by reshaping cross-entropy loss such that it
down-weights the loss assigned to well-classified examples along the lines of
focal loss. Additionally, by leveraging a tunable sampling framework, we take
into account selective client model contributions on the central server to
further focus the detector during training and hence improve its robustness.
Using a detailed experimental analysis with the VIRTUAL (Variational Federated
Multi-Task Learning) approach, we demonstrate consistently superior performance
in both the balanced and unbalanced scenarios for MNIST, FEMNIST, VSN and HAR
benchmarks. We obtain a more than 9% (absolute percentage) improvement in the
unbalanced MNIST benchmark. We further show that our technique can be adopted
across multiple Federated Learning algorithms to get improvements.
</p>
<a href="http://arxiv.org/abs/2011.06283" target="_blank">arXiv:2011.06283</a> [<a href="http://arxiv.org/pdf/2011.06283" target="_blank">pdf</a>]

<h2>Parameter Optimization for Loop Closure Detection in Closed Environments. (arXiv:2011.06286v1 [cs.RO])</h2>
<h3>Nils Rottmann, Ralf Bruder, Honghu Xue, Achim Schweikard, Elmar Rueckert</h3>
<p>Tuning parameters is crucial for the performance of localization and mapping
algorithms. In general, the tuning of the parameters requires expert knowledge
and is sensitive to information about the structure of the environment. In
order to design truly autonomous systems the robot has to learn the parameters
automatically. Therefore, we propose a parameter optimization approach for loop
closure detection in closed environments which requires neither any prior
information, e.g. robot model parameters, nor expert knowledge. It relies on
several path traversals along the boundary line of the closed environment. We
demonstrate the performance of our method in challenging real world scenarios
with limited sensing capabilities. These scenarios are exemplary for a wide
range of practical applications including lawn mowers and household robots.
</p>
<a href="http://arxiv.org/abs/2011.06286" target="_blank">arXiv:2011.06286</a> [<a href="http://arxiv.org/pdf/2011.06286" target="_blank">pdf</a>]

<h2>Image Anomaly Detection by Aggregating Deep Pyramidal Representations. (arXiv:2011.06288v1 [cs.CV])</h2>
<h3>Pankaj Mishra, Claudio Piciarelli, Gian Luca Foresti</h3>
<p>Anomaly detection consists in identifying, within a dataset, those samples
that significantly differ from the majority of the data, representing the
normal class. It has many practical applications, e.g. ranging from defective
product detection in industrial systems to medical imaging. This paper focuses
on image anomaly detection using a deep neural network with multiple pyramid
levels to analyze the image features at different scales. We propose a network
based on encoding-decoding scheme, using a standard convolutional autoencoders,
trained on normal data only in order to build a model of normality. Anomalies
can be detected by the inability of the network to reconstruct its input.
Experimental results show a good accuracy on MNIST, FMNIST and the recent MVTec
Anomaly Detection dataset
</p>
<a href="http://arxiv.org/abs/2011.06288" target="_blank">arXiv:2011.06288</a> [<a href="http://arxiv.org/pdf/2011.06288" target="_blank">pdf</a>]

<h2>RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation. (arXiv:2011.06294v1 [cs.CV])</h2>
<h3>Zhewei Huang, Tianyuan Zhang, Wen Heng, Boxin Shi, Shuchang Zhou</h3>
<p>We propose a real-time intermediate flow estimation algorithm (RIFE) for
video frame interpolation (VFI). Most existing methods first estimate the
bi-directional optical flows, and then linearly combine them to approximate
intermediate flows, leading to artifacts around motion boundaries. We design an
intermediate flow model named IFNet that can directly estimate the intermediate
flows from coarse to fine. We then warp the input frames according to the
estimated intermediate flows and employ a fusion process to compute final
results. Based on our proposed leakage distillation, RIFE can be trained
end-to-end and achieve excellent performance. Experiments demonstrate that RIFE
is significantly faster than existing flow-based VFI methods and achieves
state-of-the-art index on several benchmarks. The code is available at
https://github.com/hzwer/RIFE.
</p>
<a href="http://arxiv.org/abs/2011.06294" target="_blank">arXiv:2011.06294</a> [<a href="http://arxiv.org/pdf/2011.06294" target="_blank">pdf</a>]

<h2>When deep learning models on GPU can be accelerated by taking advantage of unstructured sparsity. (arXiv:2011.06295v1 [cs.LG])</h2>
<h3>Marcin Pietro&#x144; Dominik &#x17b;urek</h3>
<p>This paper is focused on the improvement the efficiency of the sparse
convolutional neural networks (CNNs) layers on graphic processing units (GPU).
The Nvidia deep neural network (cuDnn) library provides the most effective
implementation of deep learning (DL) algorithms for GPUs. GPUs are one of the
most efficient and commonly used accelerators for deep learning computations.
The modern CNN models need megabytes of coefficients and needed millions MAC
operations to perform convolution. One of the most common techniques for
compressing CNN models is weight pruning. There are two main types of pruning:
structural (based on removing whole weight channels) and non-structural
(removing individual weights). The first enables much easier acceleration, but
with this type it is difficult to achieve a sparsity level and accuracy as high
as that obtained with the second type. Non-structural pruning with retraining
can generate a matrix-weight up to $\sim90\%$ or more of sparsity in some deep
CNN models. This work shows when is worth using a direct sparse operation to
speed-up the calculation of the convolution layers. The VGG-16, CNN-non-static
and 1x1 layers from ResNet models were used as a benchmarks. In addition, we
present the impact of using reduced precision on time efficiency.
</p>
<a href="http://arxiv.org/abs/2011.06295" target="_blank">arXiv:2011.06295</a> [<a href="http://arxiv.org/pdf/2011.06295" target="_blank">pdf</a>]

<h2>Real-World Anomaly Detection by using Digital Twin Systems and Weakly-Supervised Learning. (arXiv:2011.06296v1 [cs.LG])</h2>
<h3>Andrea Castellani, Sebastian Schmitt, Stefano Squartini</h3>
<p>The continuously growing amount of monitored data in the Industry 4.0 context
requires strong and reliable anomaly detection techniques. The advancement of
Digital Twin technologies allows for realistic simulations of complex
machinery, therefore, it is ideally suited to generate synthetic datasets for
the use in anomaly detection approaches when compared to actual measurement
data. In this paper, we present novel weakly-supervised approaches to anomaly
detection for industrial settings. The approaches make use of a Digital Twin to
generate a training dataset which simulates the normal operation of the
machinery, along with a small set of labeled anomalous measurement from the
real machinery. In particular, we introduce a clustering-based approach, called
Cluster Centers (CC), and a neural architecture based on the Siamese
Autoencoders (SAE), which are tailored for weakly-supervised settings with very
few labeled data samples. The performance of the proposed methods is compared
against various state-of-the-art anomaly detection algorithms on an application
to a real-world dataset from a facility monitoring system, by using a multitude
of performance measures. Also, the influence of hyper-parameters related to
feature extraction and network architecture is investigated. We find that the
proposed SAE based solutions outperform state-of-the-art anomaly detection
approaches very robustly for many different hyper-parameter settings on all
performance measures.
</p>
<a href="http://arxiv.org/abs/2011.06296" target="_blank">arXiv:2011.06296</a> [<a href="http://arxiv.org/pdf/2011.06296" target="_blank">pdf</a>]

<h2>A Knowledge Representation Approach to Automated Mathematical Modelling. (arXiv:2011.06300v1 [cs.AI])</h2>
<h3>Bahadorreza Ofoghi, Vicky Mak, John Yearwood</h3>
<p>Mathematicians formulate complex mathematical models based on user
requirements to solve a diverse range of problems in different domains. These
models are, in most cases, represented through several mathematical equations
and constraints. This modelling task comprises several time-intensive processes
that require both mathematical expertise and (problem) domain knowledge. In an
attempt to automate these processes, we have developed an ontology for Mixed
Integer Linear Programming (MILP) problems to formulate expert mathematician
knowledge and in this paper, we show how this new ontology can be utilized for
modelling a relatively straightforward MILP problem, a Machine Scheduling
example. We also show that more complex MILP problems, such as the Asymmetric
Travelling Salesman Problem (ATSP), however, are not readily amenable to simple
elicitation of user requirements and the utilization of the proposed
mathematical model ontology. Therefore, an automatic mathematical modelling
framework is proposed for such complex MILP problems, which includes a problem
(requirement) elicitation module connected to a model extraction module through
a translation engine that bridges between the non-expert problem domain and the
expert mathematical model domain. This framework is argued to have the
necessary components to effectively tackle the automation of modelling task of
the more intricate MILP problems such as the ATSP.
</p>
<a href="http://arxiv.org/abs/2011.06300" target="_blank">arXiv:2011.06300</a> [<a href="http://arxiv.org/pdf/2011.06300" target="_blank">pdf</a>]

<h2>Learning Inter-Modal Correspondence and Phenotypes from Multi-Modal Electronic Health Records. (arXiv:2011.06301v1 [cs.LG])</h2>
<h3>Kejing Yin, William K. Cheung, Benjamin C. M. Fung, Jonathan Poon</h3>
<p>Non-negative tensor factorization has been shown a practical solution to
automatically discover phenotypes from the electronic health records (EHR) with
minimal human supervision. Such methods generally require an input tensor
describing the inter-modal interactions to be pre-established; however, the
correspondence between different modalities (e.g., correspondence between
medications and diagnoses) can often be missing in practice. Although heuristic
methods can be applied to estimate them, they inevitably introduce errors, and
leads to sub-optimal phenotype quality. This is particularly important for
patients with complex health conditions (e.g., in critical care) as multiple
diagnoses and medications are simultaneously present in the records. To
alleviate this problem and discover phenotypes from EHR with unobserved
inter-modal correspondence, we propose the collective hidden interaction tensor
factorization (cHITF) to infer the correspondence between multiple modalities
jointly with the phenotype discovery. We assume that the observed matrix for
each modality is marginalization of the unobserved inter-modal correspondence,
which are reconstructed by maximizing the likelihood of the observed matrices.
Extensive experiments conducted on the real-world MIMIC-III dataset demonstrate
that cHITF effectively infers clinically meaningful inter-modal correspondence,
discovers phenotypes that are more clinically relevant and diverse, and
achieves better predictive performance compared with a number of
state-of-the-art computational phenotyping models.
</p>
<a href="http://arxiv.org/abs/2011.06301" target="_blank">arXiv:2011.06301</a> [<a href="http://arxiv.org/pdf/2011.06301" target="_blank">pdf</a>]

<h2>Learning causal representations for robust domain adaptation. (arXiv:2011.06317v1 [cs.LG])</h2>
<h3>Shuai Yang, Kui Yu, Fuyuan Cao, Lin Liu, Hao Wang, Jiuyong Li</h3>
<p>Domain adaptation solves the learning problem in a target domain by
leveraging the knowledge in a relevant source domain. While remarkable advances
have been made, almost all existing domain adaptation methods heavily require
large amounts of unlabeled target domain data for learning domain invariant
representations to achieve good generalizability on the target domain. In fact,
in many real-world applications, target domain data may not always be
available. In this paper, we study the cases where at the training phase the
target domain data is unavailable and only well-labeled source domain data is
available, called robust domain adaptation. To tackle this problem, under the
assumption that causal relationships between features and the class variable
are robust across domains, we propose a novel Causal AutoEncoder (CAE), which
integrates deep autoencoder and causal structure learning into a unified model
to learn causal representations only using data from a single source domain.
Specifically, a deep autoencoder model is adopted to learn low-dimensional
representations, and a causal structure learning model is designed to separate
the low-dimensional representations into two groups: causal representations and
task-irrelevant representations. Using three real-world datasets the extensive
experiments have validated the effectiveness of CAE compared to eleven
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2011.06317" target="_blank">arXiv:2011.06317</a> [<a href="http://arxiv.org/pdf/2011.06317" target="_blank">pdf</a>]

<h2>Improving Model Accuracy for Imbalanced Image Classification Tasks by Adding a Final Batch Normalization Layer: An Empirical Study. (arXiv:2011.06319v1 [cs.CV])</h2>
<h3>Veysel Kocaman, Ofer M. Shir, Thomas B&#xe4;ck</h3>
<p>Some real-world domains, such as Agriculture and Healthcare, comprise
early-stage disease indications whose recording constitutes a rare event, and
yet, whose precise detection at that stage is critical. In this type of highly
imbalanced classification problems, which encompass complex features, deep
learning (DL) is much needed because of its strong detection capabilities. At
the same time, DL is observed in practice to favor majority over minority
classes and consequently suffer from inaccurate detection of the targeted
early-stage indications. To simulate such scenarios, we artificially generate
skewness (99% vs. 1%) for certain plant types out of the PlantVillage dataset
as a basis for classification of scarce visual cues through transfer learning.
By randomly and unevenly picking healthy and unhealthy samples from certain
plant types to form a training set, we consider a base experiment as
fine-tuning ResNet34 and VGG19 architectures and then testing the model
performance on a balanced dataset of healthy and unhealthy images. We
empirically observe that the initial F1 test score jumps from 0.29 to 0.95 for
the minority class upon adding a final Batch Normalization (BN) layer just
before the output layer in VGG19. We demonstrate that utilizing an additional
BN layer before the output layer in modern CNN architectures has a considerable
impact in terms of minimizing the training time and testing error for minority
classes in highly imbalanced data sets. Moreover, when the final BN is
employed, minimizing the loss function may not be the best way to assure a high
F1 test score for minority classes in such problems. That is, the network might
perform better even if it is not confident enough while making a prediction;
leading to another discussion about why softmax output is not a good
uncertainty measure for DL models.
</p>
<a href="http://arxiv.org/abs/2011.06319" target="_blank">arXiv:2011.06319</a> [<a href="http://arxiv.org/pdf/2011.06319" target="_blank">pdf</a>]

<h2>Joint Space Control via Deep Reinforcement Learning. (arXiv:2011.06332v1 [cs.RO])</h2>
<h3>Visak Kumar, David Hoeller, Balakumar Sundaralingam, Jonathan Tremblay, Stan Birchfield</h3>
<p>The dominant way to control a robot manipulator uses hand-crafted
differential equations leveraging some form of inverse kinematics / dynamics.
We propose a simple, versatile joint-level controller that dispenses with
differential equations entirely. A deep neural network, trained via model-free
reinforcement learning, is used to map from task space to joint space.
Experiments show the method capable of achieving similar error to traditional
methods, while greatly simplifying the process by automatically handling
redundancy, joint limits, and acceleration / deceleration profiles. The basic
technique is extended to avoid obstacles by augmenting the input to the network
with information about the nearest obstacles. Results are shown both in
simulation and on a real robot via sim-to-real transfer of the learned policy.
We show that it is possible to achieve sub-centimeter accuracy, both in
simulation and the real world, with a moderate amount of training.
</p>
<a href="http://arxiv.org/abs/2011.06332" target="_blank">arXiv:2011.06332</a> [<a href="http://arxiv.org/pdf/2011.06332" target="_blank">pdf</a>]

<h2>Hierarchical reinforcement learning for efficient exploration and transfer. (arXiv:2011.06335v1 [cs.LG])</h2>
<h3>Lorenzo Steccanella, Simone Totaro, Damien Allonsius, Anders Jonsson</h3>
<p>Sparse-reward domains are challenging for reinforcement learning algorithms
since significant exploration is needed before encountering reward for the
first time. Hierarchical reinforcement learning can facilitate exploration by
reducing the number of decisions necessary before obtaining a reward. In this
paper, we present a novel hierarchical reinforcement learning framework based
on the compression of an invariant state space that is common to a range of
tasks. The algorithm introduces subtasks which consist of moving between the
state partitions induced by the compression. Results indicate that the
algorithm can successfully solve complex sparse-reward domains, and transfer
knowledge to solve new, previously unseen tasks more quickly.
</p>
<a href="http://arxiv.org/abs/2011.06335" target="_blank">arXiv:2011.06335</a> [<a href="http://arxiv.org/pdf/2011.06335" target="_blank">pdf</a>]

<h2>Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting Bootstrap Aggregation. (arXiv:2011.06337v1 [cs.CV])</h2>
<h3>Gyutaek Oh, Jeong Eun Lee, Jong Chul Ye</h3>
<p>Recently, deep learning approaches for MR motion artifact correction have
been extensively studied. Although these approaches have shown high performance
and reduced computational complexity compared to classical methods, most of
them require supervised training using paired artifact-free and
artifact-corrupted images, which may prohibit its use in many important
clinical applications. For example, transient severe motion (TSM) due to acute
transient dyspnea in Gd-EOB-DTPA-enhanced MR is difficult to control and model
for paired data generation. To address this issue, here we propose a novel
unsupervised deep learning scheme through outlier-rejecting bootstrap
subsampling and aggregation. This is inspired by the observation that motions
usually cause sparse k-space outliers in the phase encoding direction, so
k-space subsampling along the phase encoding direction can remove some outliers
and the aggregation step can further improve the results from the
reconstruction network. Our method does not require any paired data because the
training step only requires artifact-free images. Furthermore, to address the
smoothing from potential bias to the artifact-free images, the network is
trained in an unsupervised manner using optimal transport driven cycleGAN. We
verify that our method can be applied for artifact correction from simulated
motion as well as real motion from TSM successfully, outperforming existing
state-of-the-art deep learning methods.
</p>
<a href="http://arxiv.org/abs/2011.06337" target="_blank">arXiv:2011.06337</a> [<a href="http://arxiv.org/pdf/2011.06337" target="_blank">pdf</a>]

<h2>Cross Layer Optimization and Distributed Reinforcement Learning Approach for Tile-Based 360 Degree Wireless Video Streaming. (arXiv:2011.06356v1 [cs.LG])</h2>
<h3>Mounssif Krouka, Anis Elgabli, Mohammed S. Elbamby, Cristina Perfecto, Mehdi Bennis, Vaneet Aggarwal</h3>
<p>Wirelessly streaming high quality 360 degree videos is still a challenging
problem. When there are many users watching different 360 degree videos and
competing for the computing and communication resources, the streaming
algorithm at hand should maximize the average quality of experience (QoE) while
guaranteeing a minimum rate for each user. In this paper, we propose a
\emph{cross layer} optimization approach that maximizes the available rate to
each user and efficiently uses it to maximize users' QoE. Particularly, we
consider a tile based 360 degree video streaming, and we optimize a QoE metric
that balances the tradeoff between maximizing each user's QoE and ensuring
fairness among users. We show that the problem can be decoupled into two
interrelated subproblems: (i) a physical layer subproblem whose objective is to
find the download rate for each user, and (ii) an application layer subproblem
whose objective is to use that rate to find a quality decision per tile such
that the user's QoE is maximized. We prove that the physical layer subproblem
can be solved optimally with low complexity and an actor-critic deep
reinforcement learning (DRL) is proposed to leverage the parallel training of
multiple independent agents and solve the application layer subproblem.
Extensive experiments reveal the robustness of our scheme and demonstrate its
significant performance improvement compared to several baseline algorithms.
</p>
<a href="http://arxiv.org/abs/2011.06356" target="_blank">arXiv:2011.06356</a> [<a href="http://arxiv.org/pdf/2011.06356" target="_blank">pdf</a>]

<h2>Griddly: A platform for AI research in games. (arXiv:2011.06363v1 [cs.AI])</h2>
<h3>Chris Bamford, Shengyi Huang, Simon Lucas</h3>
<p>In recent years, there have been immense breakthroughs in Game AI research,
particularly with Reinforcement Learning (RL). Despite their success, the
underlying games are usually implemented with their own preset environments and
game mechanics, thus making it difficult for researchers to prototype different
game environments. However, testing the RL agents against a variety of game
environments is critical for recent effort to study generalization in RL and
avoid the problem of overfitting that may otherwise occur. In this paper, we
present Griddly as a new platform for Game AI research that provides a unique
combination of highly configurable games, different observer types and an
efficient C++ core engine. Additionally, we present a series of baseline
experiments to study the effect of different observation configurations and
generalization ability of RL agents.
</p>
<a href="http://arxiv.org/abs/2011.06363" target="_blank">arXiv:2011.06363</a> [<a href="http://arxiv.org/pdf/2011.06363" target="_blank">pdf</a>]

<h2>R-TOD: Real-Time Object Detector with Minimized End-to-End Delay for Autonomous Driving. (arXiv:2011.06372v1 [cs.CV])</h2>
<h3>Wonseok Jang, Hansaem Jeong, Kyungtae Kang, Nikil Dutt, Jong-Chan Kim</h3>
<p>For realizing safe autonomous driving, the end-to-end delays of real-time
object detection systems should be thoroughly analyzed and minimized. However,
despite recent development of neural networks with minimized inference delays,
surprisingly little attention has been paid to their end-to-end delays from an
object's appearance until its detection is reported. With this motivation, this
paper aims to provide more comprehensive understanding of the end-to-end delay,
through which precise best- and worst-case delay predictions are formulated,
and three optimization methods are implemented: (i) on-demand capture, (ii)
zero-slack pipeline, and (iii) contention-free pipeline. Our experimental
results show a 76% reduction in the end-to-end delay of Darknet YOLO (You Only
Look Once) v3 (from 1070 ms to 261 ms), thereby demonstrating the great
potential of exploiting the end-to-end delay analysis for autonomous driving.
Furthermore, as we only modify the system architecture and do not change the
neural network architecture itself, our approach incurs no penalty on the
detection accuracy.
</p>
<a href="http://arxiv.org/abs/2011.06372" target="_blank">arXiv:2011.06372</a> [<a href="http://arxiv.org/pdf/2011.06372" target="_blank">pdf</a>]

<h2>An improved spectral clustering method for community detection under the degree-corrected stochastic blockmodel. (arXiv:2011.06374v1 [stat.ML])</h2>
<h3>Huan Qing, Jingli Wang</h3>
<p>For community detection problem, spectral clustering is a widely used method
for detecting clusters in networks. In this paper, we propose an improved
spectral clustering (ISC) approach under the degree corrected stochastic block
model (DCSBM). ISC is designed based on the k-means clustering algorithm on the
weighted leading K + 1 eigenvectors of a regularized Laplacian matrix where the
weights are their corresponding eigenvalues. Theoretical analysis of ISC shows
that under mild conditions the ISC yields stable consistent community
detection. Numerical results show that ISC outperforms classical spectral
clustering methods for community detection on both simulated and eight
empirical networks. Especially, ISC provides a significant improvement on two
weak signal networks Simmons and Caltech, with error rates of 121/1137 and
96/590, respectively.
</p>
<a href="http://arxiv.org/abs/2011.06374" target="_blank">arXiv:2011.06374</a> [<a href="http://arxiv.org/pdf/2011.06374" target="_blank">pdf</a>]

<h2>Iterative Surface Mapping Using Local Geometry Approximation with Sparse Measurements During Robotic Tooling Tasks. (arXiv:2011.06375v1 [cs.RO])</h2>
<h3>Manuel Amersdorfer, Thomas Meurer</h3>
<p>We present a method to map an unknown 3D freeform surface using only sparse
measurements while the end-effector of a robotic manipulator moves along the
surface. The geometry is locally approximated by a plane, which is defined by
measured points on the surface. The method relies on linear Kalman filters,
estimating the height of each point on a 2D grid. Therefore, the approximation
covariance for each grid point is determined by the projected distance to the
measured points' positions. We propose different update strategies for the grid
points, where the approximation is valid to consider the locality of the planar
approximation. We experimentally validate the approach by tracking the surface
with a robotic manipulator. Three laser distance sensors mounted on the
end-effector continuously measure points on the surface during the motion.
These points determine the approximation plane, which updates the mapping. It
is shown that the surface geometry can be mapped reasonably accurate with a
mean absolute error below 1 mm. The mapping error mainly depends on the size of
the approximation area and the curvature of the surface.
</p>
<a href="http://arxiv.org/abs/2011.06375" target="_blank">arXiv:2011.06375</a> [<a href="http://arxiv.org/pdf/2011.06375" target="_blank">pdf</a>]

<h2>Online Influence Maximization under Linear Threshold Model. (arXiv:2011.06378v1 [cs.LG])</h2>
<h3>Shuai Li, Fang Kong, Kejie Tang, Qizhi Li, Wei Chen</h3>
<p>Online influence maximization (OIM) is a popular problem in social networks
to learn influence propagation model parameters and maximize the influence
spread at the same time. Most previous studies focus on the independent cascade
(IC) model under the edge-level feedback. In this paper, we address OIM in the
linear threshold (LT) model. Because node activations in the LT model are due
to the aggregated effect of all active neighbors, it is more natural to model
OIM with the node-level feedback. And this brings new challenge in online
learning since we only observe aggregated effect from groups of nodes and the
groups are also random. Based on the linear structure in node activations, we
incorporate ideas from linear bandits and design an algorithm LT-LinUCB that is
consistent with the observed feedback. By proving group observation modulated
(GOM) bounded smoothness property, a novel result of the influence difference
in terms of the random observations, we provide a regret of order
$\tilde{O}(\mathrm{poly}(m)\sqrt{T})$, where $m$ is the number of edges and $T$
is the number of rounds. This is the first theoretical result in such order for
OIM under the LT model. In the end, we also provide an algorithm OIM-ETC with
regret bound $O(\mathrm{poly}(m)\ T^{2/3})$, which is model-independent, simple
and has less requirement on online feedback and offline computation.
</p>
<a href="http://arxiv.org/abs/2011.06378" target="_blank">arXiv:2011.06378</a> [<a href="http://arxiv.org/pdf/2011.06378" target="_blank">pdf</a>]

<h2>FusedMM: A Unified SDDMM-SpMM Kernel for Graph Embedding and Graph Neural Networks. (arXiv:2011.06391v1 [cs.LG])</h2>
<h3>Md. Khaledur Rahman, Majedul Haque Sujon, Ariful Azad</h3>
<p>We develop a fused matrix multiplication kernel that unifies sampled
dense-dense matrix multiplication and sparse-dense matrix multiplication under
a single operation called FusedMM. By using user-defined functions, FusedMM can
capture almost all computational patterns needed by popular graph embedding and
GNN approaches. FusedMM is an order of magnitude faster than its equivalent
kernels in Deep Graph Library. The superior performance of FusedMM comes from
the low-level vectorized kernels, a suitable load balancing scheme and an
efficient utilization of the memory bandwidth. FusedMM can tune its performance
using a code generator and perform equally well on Intel, AMD and ARM
processors. FusedMM speeds up an end-to-end graph embedding algorithm by up to
28x on different processors.
</p>
<a href="http://arxiv.org/abs/2011.06391" target="_blank">arXiv:2011.06391</a> [<a href="http://arxiv.org/pdf/2011.06391" target="_blank">pdf</a>]

<h2>Heterogeneous Data-Aware Federated Learning. (arXiv:2011.06393v1 [cs.LG])</h2>
<h3>Lixuan Yang, Cedric Beliard, Dario Rossi</h3>
<p>Federated learning (FL) is an appealing concept to perform distributed
training of Neural Networks (NN) while keeping data private. With the
industrialization of the FL framework, we identify several problems hampering
its successful deployment, such as presence of non i.i.d data, disjoint
classes, signal multi-modality across datasets. In this work, we address these
problems by proposing a novel method that not only (1) aggregates generic model
parameters (e.g. a common set of task generic NN layers) on server (e.g. in
traditional FL), but also (2) keeps a set of parameters (e.g, a set of task
specific NN layer) specific to each client. We validate our method on the
traditionally used public benchmarks (e.g., Femnist) as well as on our
proprietary collected dataset (i.e., traffic classification). Results show the
benefit of our method, with significant advantage on extreme cases.
</p>
<a href="http://arxiv.org/abs/2011.06393" target="_blank">arXiv:2011.06393</a> [<a href="http://arxiv.org/pdf/2011.06393" target="_blank">pdf</a>]

<h2>Fast robust peg-in-hole insertion with continuous visual servoing. (arXiv:2011.06399v1 [cs.RO])</h2>
<h3>Rasmus Laurvig Haugaard, Jeppe Langaa, Christoffer Sloth, Anders Glent Buch</h3>
<p>This paper demonstrates a visual servoing method which is robust towards
uncertainties related to system calibration and grasping, while significantly
reducing the peg-in-hole time compared to classical methods and recent attempts
based on deep learning. The proposed visual servoing method is based on peg and
hole point estimates from a deep neural network in a multi-cam setup, where the
model is trained on purely synthetic data. Empirical results show that the
learnt model generalizes to the real world, allowing for higher success rates
and lower cycle times than existing approaches.
</p>
<a href="http://arxiv.org/abs/2011.06399" target="_blank">arXiv:2011.06399</a> [<a href="http://arxiv.org/pdf/2011.06399" target="_blank">pdf</a>]

<h2>StrObe: Streaming Object Detection from LiDAR Packets. (arXiv:2011.06425v1 [cs.CV])</h2>
<h3>Davi Frossard, Simon Suo, Sergio Casas, James Tu, Rui Hu, Raquel Urtasun</h3>
<p>Many modern robotics systems employ LiDAR as their main sensing modality due
to its geometrical richness. Rolling shutter LiDARs are particularly common, in
which an array of lasers scans the scene from a rotating base. Points are
emitted as a stream of packets, each covering a sector of the 360{\deg}
coverage. Modern perception algorithms wait for the full sweep to be built
before processing the data, which introduces an additional latency. For typical
10Hz LiDARs this will be 100ms. As a consequence, by the time an output is
produced, it no longer accurately reflects the state of the world. This poses a
challenge, as robotics applications require minimal reaction times, such that
maneuvers can be quickly planned in the event of a safety-critical situation.
In this paper we propose StrObe, a novel approach that minimizes latency by
ingesting LiDAR packets and emitting a stream of detections without waiting for
the full sweep to be built. StrObe reuses computations from previous packets
and iteratively updates a latent spatial representation of the scene, which
acts as a memory, as new evidence comes in, resulting in accurate low-latency
perception. We demonstrate the effectiveness of our approach on a large scale
real-world dataset, showing that StrObe far outperforms the state-of-the-art
when latency is taken into account, and matches the performance in the
traditional setting.
</p>
<a href="http://arxiv.org/abs/2011.06425" target="_blank">arXiv:2011.06425</a> [<a href="http://arxiv.org/pdf/2011.06425" target="_blank">pdf</a>]

<h2>Discriminative, Generative and Self-Supervised Approaches for Target-Agnostic Learning. (arXiv:2011.06428v1 [cs.LG])</h2>
<h3>Yuan Jin, Wray Buntine, Francois Petitjean, Geoffrey I. Webb</h3>
<p>Supervised learning, characterized by both discriminative and generative
learning, seeks to predict the values of single (or sometimes multiple)
predefined target attributes based on a predefined set of predictor attributes.
For applications where the information available and predictions to be made may
vary from instance to instance, we propose the task of target-agnostic learning
where arbitrary disjoint sets of attributes can be used for each of predictors
and targets for each to-be-predicted instance. For this task, we survey a wide
range of techniques available for handling missing values, self-supervised
training and pseudo-likelihood training, and adapt them to a suite of
algorithms that are suitable for the task. We conduct extensive experiments on
this suite of algorithms on a large collection of categorical, continuous and
discretized datasets, and report their performance in terms of both
classification and regression errors. We also report the training and
prediction time of these algorithms when handling large-scale datasets. Both
generative and self-supervised learning models are shown to perform well at the
task, although their characteristics towards the different types of data are
quite different. Nevertheless, our derived theorem for the pseudo-likelihood
theory also shows that they are related for inferring a joint distribution
model based on the pseudo-likelihood training.
</p>
<a href="http://arxiv.org/abs/2011.06428" target="_blank">arXiv:2011.06428</a> [<a href="http://arxiv.org/pdf/2011.06428" target="_blank">pdf</a>]

<h2>Same Object, Different Grasps: Data and Semantic Knowledge for Task-Oriented Grasping. (arXiv:2011.06431v1 [cs.RO])</h2>
<h3>Adithyavairavan Murali, Weiyu Liu, Kenneth Marino, Sonia Chernova, Abhinav Gupta</h3>
<p>Despite the enormous progress and generalization in robotic grasping in
recent years, existing methods have yet to scale and generalize task-oriented
grasping to the same extent. This is largely due to the scale of the datasets
both in terms of the number of objects and tasks studied. We address these
concerns with the TaskGrasp dataset which is more diverse both in terms of
objects and tasks, and an order of magnitude larger than previous datasets. The
dataset contains 250K task-oriented grasps for 56 tasks and 191 objects along
with their RGB-D information. We take advantage of this new breadth and
diversity in the data and present the GCNGrasp framework which uses the
semantic knowledge of objects and tasks encoded in a knowledge graph to
generalize to new object instances, classes and even new tasks. Our framework
shows a significant improvement of around 12% on held-out settings compared to
baseline methods which do not use semantics. We demonstrate that our dataset
and model are applicable for the real world by executing task-oriented grasps
on a real robot on unknown objects. Code, data and supplementary video could be
found at https://sites.google.com/view/taskgrasp
</p>
<a href="http://arxiv.org/abs/2011.06431" target="_blank">arXiv:2011.06431</a> [<a href="http://arxiv.org/pdf/2011.06431" target="_blank">pdf</a>]

<h2>How to Measure Gender Bias in Machine Translation: Optimal Translators, Multiple Reference Points. (arXiv:2011.06445v1 [stat.ML])</h2>
<h3>Anna Farkas, Ren&#xe1;ta N&#xe9;meth</h3>
<p>In this paper, as a case study, we present a systematic study of gender bias
in machine translation with Google Translate. We translated sentences
containing names of occupations from Hungarian, a language with gender-neutral
pronouns, into English. Our aim was to present a fair measure for bias by
comparing the translations to an optimal non-biased translator. When assessing
bias, we used the following reference points: (1) the distribution of men and
women among occupations in both the source and the target language countries,
as well as (2) the results of a Hungarian survey that examined if certain jobs
are generally perceived as feminine or masculine. We also studied how expanding
sentences with adjectives referring to occupations effect the gender of the
translated pronouns. As a result, we found bias against both genders, but
biased results against women are much more frequent. Translations are closer to
our perception of occupations than to objective occupational statistics.
Finally, occupations have a greater effect on translation than adjectives.
</p>
<a href="http://arxiv.org/abs/2011.06445" target="_blank">arXiv:2011.06445</a> [<a href="http://arxiv.org/pdf/2011.06445" target="_blank">pdf</a>]

<h2>Sensors for expert grip force profiling: towards benchmarking manual control of a robotic device for surgical tool movements. (arXiv:2011.06449v1 [cs.RO])</h2>
<h3>Michel de Mathelin, Florent Nageotte, Philippe Zanne, Birgitta Dresp-Langley</h3>
<p>STRAS (Single access Transluminal Robotic Assistant for Surgeons) is a new
robotic system for application to intraluminal surgical procedures. Preclinical
testing of STRAS has recently permitted to demonstrate major advantages of the
system in comparison with classic procedures. Benchmark methods permitting to
establish objective criteria for expertise need to be worked out now to
effectively train surgeons on this new system in the near future. STRAS
consists of three cable driven subsystems, one endoscope serving as guide, and
two flexible instruments. The flexible instruments have three degrees of
freedom and can be teleoperated by a single user via two specially designed
master interfaces. In this study here, small force sensors sewn into a wearable
glove to ergonomically fit the master handles of the robotic system were
employed for monitoring the forces applied by an expert and a trainee who was a
complete novice during all the steps of surgical task execution in a simulator
task, a four step pick and drop. Analysis of gripforce profiles is performed
sensor by sensor to bring to the fore specific differences in handgrip force
profiles in specific sensor locations on anatomically relevant parts of the
fingers and hand controlling the master slave system.
</p>
<a href="http://arxiv.org/abs/2011.06449" target="_blank">arXiv:2011.06449</a> [<a href="http://arxiv.org/pdf/2011.06449" target="_blank">pdf</a>]

<h2>A deep Q-Learning based Path Planning and Navigation System for Firefighting Environments. (arXiv:2011.06450v1 [cs.AI])</h2>
<h3>Manish Bhattarai, Manel Martinez-Ramon</h3>
<p>Live fire creates a dynamic, rapidly changing environment that presents a
worthy challenge for deep learning and artificial intelligence methodologies to
assist firefighters with scene comprehension in maintaining their situational
awareness, tracking and relay of important features necessary for key decisions
as they tackle these catastrophic events. We propose a deep Q-learning based
agent who is immune to stress induced disorientation and anxiety and thus able
to make clear decisions for navigation based on the observed and stored facts
in live fire environments. As a proof of concept, we imitate structural fire in
a gaming engine called Unreal Engine which enables the interaction of the agent
with the environment. The agent is trained with a deep Q-learning algorithm
based on a set of rewards and penalties as per its actions on the environment.
We exploit experience replay to accelerate the learning process and augment the
learning of the agent with human-derived experiences. The agent trained under
this deep Q-learning approach outperforms agents trained through alternative
path planning systems and demonstrates this methodology as a promising
foundation on which to build a path planning navigation assistant capable of
safely guiding fire fighters through live fire environments.
</p>
<a href="http://arxiv.org/abs/2011.06450" target="_blank">arXiv:2011.06450</a> [<a href="http://arxiv.org/pdf/2011.06450" target="_blank">pdf</a>]

<h2>Correlating grip force signals from multiple sensors highlights prehensile control strategies in a complex task-user system. (arXiv:2011.06452v1 [cs.RO])</h2>
<h3>Birgitta Dresp-Langley, Florent Nageotte, Philippe Zanne, Michel de Mathelin</h3>
<p>Wearable sensor systems with transmitting capabilities are currently employed
for the biometric screening of exercise activities and other performance data.
Such technology is generally wireless and enables the noninvasive monitoring of
signals to track and trace user behaviors in real time. Examples include
signals relative to hand and finger movements or force control reflected by
individual grip force data. As will be shown here, these signals directly
translate into task, skill, and hand specific, dominant versus non dominant
hand, grip force profiles for different measurement loci in the fingers and
palm of the hand. The present study draws from thousands of such sensor data
recorded from multiple spatial locations. The individual grip force profiles of
a highly proficient left handed exper, a right handed dominant hand trained
user, and a right handed novice performing an image guided, robot assisted
precision task with the dominant or the non dominant hand are analyzed. The
step by step statistical approach follows Tukeys detective work principle,
guided by explicit functional assumptions relating to somatosensory receptive
field organization in the human brain. Correlation analyses in terms of Person
Product Moments reveal skill specific differences in covariation patterns in
the individual grip force profiles. These can be functionally mapped to from
global to local coding principles in the brain networks that govern grip force
control and its optimization with a specific task expertise. Implications for
the real time monitoring of grip forces and performance training in complex
task user systems are brought forward.
</p>
<a href="http://arxiv.org/abs/2011.06452" target="_blank">arXiv:2011.06452</a> [<a href="http://arxiv.org/pdf/2011.06452" target="_blank">pdf</a>]

<h2>Kernel k-Means, By All Means: Algorithms and Strong Consistency. (arXiv:2011.06461v1 [stat.ML])</h2>
<h3>Debolina Paul, Saptarshi Chakraborty, Swagatam Das, Jason Xu</h3>
<p>Kernel $k$-means clustering is a powerful tool for unsupervised learning of
non-linearly separable data. Since the earliest attempts, researchers have
noted that such algorithms often become trapped by local minima arising from
non-convexity of the underlying objective function. In this paper, we
generalize recent results leveraging a general family of means to combat
sub-optimal local solutions to the kernel and multi-kernel settings. Called
Kernel Power $k$-Means, our algorithm makes use of majorization-minimization
(MM) to better solve this non-convex problem. We show the method implicitly
performs annealing in kernel feature space while retaining efficient,
closed-form updates, and we rigorously characterize its convergence properties
both from computational and statistical points of view. In particular, we
characterize the large sample behavior of the proposed method by establishing
strong consistency guarantees. Its merits are thoroughly validated on a suite
of simulated datasets and real data benchmarks that feature non-linear and
multi-view separation.
</p>
<a href="http://arxiv.org/abs/2011.06461" target="_blank">arXiv:2011.06461</a> [<a href="http://arxiv.org/pdf/2011.06461" target="_blank">pdf</a>]

<h2>3D-OES: Viewpoint-Invariant Object-Factorized Environment Simulators. (arXiv:2011.06464v1 [cs.RO])</h2>
<h3>Hsiao-Yu Fish Tung, Zhou Xian, Mihir Prabhudesai, Shamit Lal, Katerina Fragkiadaki</h3>
<p>We propose an action-conditioned dynamics model that predicts scene changes
caused by object and agent interactions in a viewpoint-invariant 3D neural
scene representation space, inferred from RGB-D videos. In this 3D feature
space, objects do not interfere with one another and their appearance persists
over time and across viewpoints. This permits our model to predict future
scenes long in the future by simply "moving" 3D object features based on
cumulative object motion predictions. Object motion predictions are computed by
a graph neural network that operates over the object features extracted from
the 3D neural scene representation. Our model's simulations can be decoded by a
neural renderer into2D image views from any desired viewpoint, which aids the
interpretability of our latent 3D simulation space. We show our model
generalizes well its predictions across varying number and appearances of
interacting objects as well as across camera viewpoints, outperforming existing
2D and 3D dynamics models. We further demonstrate sim-to-real transfer of the
learnt dynamics by applying our model trained solely in simulation to
model-based control for pushing objects to desired locations under clutter on a
real robotic setup
</p>
<a href="http://arxiv.org/abs/2011.06464" target="_blank">arXiv:2011.06464</a> [<a href="http://arxiv.org/pdf/2011.06464" target="_blank">pdf</a>]

<h2>Fairness and Robustness in Invariant Learning: A Case Study in Toxicity Classification. (arXiv:2011.06485v1 [cs.LG])</h2>
<h3>Robert Adragna (1), Elliot Creager (1), David Madras (1), Richard Zemel (1) ((1) University of Toronto)</h3>
<p>Robustness is of central importance in machine learning and has given rise to
the fields of domain generalization and invariant learning, which are concerned
with improving performance on a test distribution distinct from but related to
the training distribution. In light of recent work suggesting an intimate
connection between fairness and robustness, we investigate whether algorithms
from robust ML can be used to improve the fairness of classifiers that are
trained on biased data and tested on unbiased data. We apply Invariant Risk
Minimization (IRM), a domain generalization algorithm that employs a causal
discovery inspired method to find robust predictors, to the task of fairly
predicting the toxicity of internet comments. We show that IRM achieves better
out-of-distribution accuracy and fairness than Empirical Risk Minimization
(ERM) methods, and analyze both the difficulties that arise when applying IRM
in practice and the conditions under which IRM will likely be effective in this
scenario. We hope that this work will inspire further studies of how robust
machine learning methods relate to algorithmic fairness.
</p>
<a href="http://arxiv.org/abs/2011.06485" target="_blank">arXiv:2011.06485</a> [<a href="http://arxiv.org/pdf/2011.06485" target="_blank">pdf</a>]

<h2>Content-based Image Retrieval and the Semantic Gap in the Deep Learning Era. (arXiv:2011.06490v1 [cs.CV])</h2>
<h3>Bj&#xf6;rn Barz, Joachim Denzler</h3>
<p>Content-based image retrieval has seen astonishing progress over the past
decade, especially for the task of retrieving images of the same object that is
depicted in the query image. This scenario is called instance or object
retrieval and requires matching fine-grained visual patterns between images.
Semantics, however, do not play a crucial role. This brings rise to the
question: Do the recent advances in instance retrieval transfer to more generic
image retrieval scenarios? To answer this question, we first provide a brief
overview of the most relevant milestones of instance retrieval. We then apply
them to a semantic image retrieval task and find that they perform inferior to
much less sophisticated and more generic methods in a setting that requires
image understanding. Following this, we review existing approaches to closing
this so-called semantic gap by integrating prior world knowledge. We conclude
that the key problem for the further advancement of semantic image retrieval
lies in the lack of a standardized task definition and an appropriate benchmark
dataset.
</p>
<a href="http://arxiv.org/abs/2011.06490" target="_blank">arXiv:2011.06490</a> [<a href="http://arxiv.org/pdf/2011.06490" target="_blank">pdf</a>]

<h2>Distributed Sparse SGD with Majority Voting. (arXiv:2011.06495v1 [cs.LG])</h2>
<h3>Kerem Ozfatura, Emre Ozfatura, Deniz Gunduz</h3>
<p>Distributed learning, particularly variants of distributed stochastic
gradient descent (DSGD), are widely employed to speed up training by leveraging
computational resources of several workers. However, in practise, communication
delay becomes a bottleneck due to the significant amount of information that
needs to be exchanged between the workers and the parameter server. One of the
most efficient strategies to mitigate the communication bottleneck is top-K
sparsification. However, top-K sparsification requires additional communication
load to represent the sparsity pattern, and the mismatch between the sparsity
patterns of the workers prevents exploitation of efficient communication
protocols. To address these issues, we introduce a novel majority voting based
sparse communication strategy, in which the workers first seek a consensus on
the structure of the sparse representation. This strategy provides a
significant reduction in the communication load and allows using the same
sparsity level in both communication directions. Through extensive simulations
on the CIFAR-10 dataset, we show that it is possible to achieve up to x4000
compression without any loss in the test accuracy.
</p>
<a href="http://arxiv.org/abs/2011.06495" target="_blank">arXiv:2011.06495</a> [<a href="http://arxiv.org/pdf/2011.06495" target="_blank">pdf</a>]

<h2>On the Performance of Convolutional Neural Networks under High and Low Frequency Information. (arXiv:2011.06496v1 [cs.CV])</h2>
<h3>Roshan Reddy Yedla, Shiv Ram Dubey</h3>
<p>Convolutional neural networks (CNNs) have shown very promising performance in
recent years for different problems, including object recognition, face
recognition, medical image analysis, etc. However, generally the trained CNN
models are tested over the test set which is very similar to the trained set.
The generalizability and robustness of the CNN models are very important
aspects to make it to work for the unseen data. In this letter, we study the
performance of CNN models over the high and low frequency information of the
images. We observe that the trained CNN fails to generalize over the high and
low frequency images. In order to make the CNN robust against high and low
frequency images, we propose the stochastic filtering based data augmentation
during training. A satisfactory performance improvement has been observed in
terms of the high and low frequency generalization and robustness with the
proposed stochastic filtering based data augmentation approach. The
experimentations are performed using ResNet50 model over the CIFAR-10 dataset
and ResNet101 model over Tiny-ImageNet dataset.
</p>
<a href="http://arxiv.org/abs/2011.06496" target="_blank">arXiv:2011.06496</a> [<a href="http://arxiv.org/pdf/2011.06496" target="_blank">pdf</a>]

<h2>Fit2Form: 3D Generative Model for Robot Gripper Form Design. (arXiv:2011.06498v1 [cs.RO])</h2>
<h3>Huy Ha, Shubham Agrawal, Shuran Song</h3>
<p>The 3D shape of a robot's end-effector plays a critical role in determining
it's functionality and overall performance. Many industrial applications rely
on task-specific gripper designs to ensure the system's robustness and
accuracy. However, the process of manual hardware design is both costly and
time-consuming, and the quality of the resulting design is dependent on the
engineer's experience and domain expertise, which can easily be out-dated or
inaccurate. The goal of this work is to use machine learning algorithms to
automate the design of task-specific gripper fingers. We propose Fit2Form, a 3D
generative design framework that generates pairs of finger shapes to maximize
design objectives (i.e., grasp success, stability, and robustness) for target
grasp objects. We model the design objectives by training a Fitness network to
predict their values for pairs of gripper fingers and their corresponding grasp
objects. This Fitness network then provides supervision to a 3D Generative
network that produces a pair of 3D finger geometries for the target grasp
object. Our experiments demonstrate that the proposed 3D generative design
framework generates parallel jaw gripper finger shapes that achieve more stable
and robust grasps compared to other general-purpose and task-specific gripper
design algorithms. Video can be found at https://youtu.be/utKHP3qb1bg.
</p>
<a href="http://arxiv.org/abs/2011.06498" target="_blank">arXiv:2011.06498</a> [<a href="http://arxiv.org/pdf/2011.06498" target="_blank">pdf</a>]

<h2>Quality4.0 -- Transparent product quality supervision in the age of Industry 4.0. (arXiv:2011.06502v1 [cs.AI])</h2>
<h3>Jens Brandenburger, Christoph Schirm, Josef Melcher, Edgar Hancke, Marco Vannucci, Valentina Colla, Silvia Cateni, Rami Sellami, S&#xe9;bastien Dupont, Annick Majchrowski, Asier Arteaga</h3>
<p>Progressive digitalization is changing the game of many industrial sectors.
Focus-ing on product quality the main profitability driver of this so-called
Industry 4.0 will be the horizontal integration of information over the
complete supply chain. Therefore, the European RFCS project 'Quality4.0' aims
in developing an adap-tive platform, which releases decisions on product
quality and provides tailored information of high reliability that can be
individually exchanged with customers. In this context Machine Learning will be
used to detect outliers in the quality data. This paper discusses the
intermediate project results and the concepts developed so far for this
horizontal integration of quality information.
</p>
<a href="http://arxiv.org/abs/2011.06502" target="_blank">arXiv:2011.06502</a> [<a href="http://arxiv.org/pdf/2011.06502" target="_blank">pdf</a>]

<h2>Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian. (arXiv:2011.06505v1 [cs.LG])</h2>
<h3>Jack Parker-Holder, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam Lerer, Alistair Letcher, Alex Peysakhovich, Aldo Pacchiano, Jakob Foerster</h3>
<p>Over the last decade, a single algorithm has changed many facets of our lives
- Stochastic Gradient Descent (SGD). In the era of ever decreasing loss
functions, SGD and its various offspring have become the go-to optimization
tool in machine learning and are a key component of the success of deep neural
networks (DNNs). While SGD is guaranteed to converge to a local optimum (under
loose assumptions), in some cases it may matter which local optimum is found,
and this is often context-dependent. Examples frequently arise in machine
learning, from shape-versus-texture-features to ensemble methods and zero-shot
coordination. In these settings, there are desired solutions which SGD on
'standard' loss functions will not find, since it instead converges to the
'easy' solutions. In this paper, we present a different approach. Rather than
following the gradient, which corresponds to a locally greedy direction, we
instead follow the eigenvectors of the Hessian, which we call "ridges". By
iteratively following and branching amongst the ridges, we effectively span the
loss surface to find qualitatively different solutions. We show both
theoretically and experimentally that our method, called Ridge Rider (RR),
offers a promising direction for a variety of challenging problems.
</p>
<a href="http://arxiv.org/abs/2011.06505" target="_blank">arXiv:2011.06505</a> [<a href="http://arxiv.org/pdf/2011.06505" target="_blank">pdf</a>]

<h2>Reinforcement Learning with Videos: Combining Offline Observations with Interaction. (arXiv:2011.06507v1 [cs.LG])</h2>
<h3>Karl Schmeckpeper, Oleh Rybkin, Kostas Daniilidis, Sergey Levine, Chelsea Finn</h3>
<p>Reinforcement learning is a powerful framework for robots to acquire skills
from experience, but often requires a substantial amount of online data
collection. As a result, it is difficult to collect sufficiently diverse
experiences that are needed for robots to generalize broadly. Videos of humans,
on the other hand, are a readily available source of broad and interesting
experiences. In this paper, we consider the question: can we perform
reinforcement learning directly on experience collected by humans? This problem
is particularly difficult, as such videos are not annotated with actions and
exhibit substantial visual domain shift relative to the robot's embodiment. To
address these challenges, we propose a framework for reinforcement learning
with videos (RLV). RLV learns a policy and value function using experience
collected by humans in combination with data collected by robots. In our
experiments, we find that RLV is able to leverage such videos to learn
challenging vision-based skills with less than half as many samples as RL
methods that learn from scratch.
</p>
<a href="http://arxiv.org/abs/2011.06507" target="_blank">arXiv:2011.06507</a> [<a href="http://arxiv.org/pdf/2011.06507" target="_blank">pdf</a>]

<h2>Linear Dilation-Erosion Perceptron Trained Using a Convex-Concave Procedure. (arXiv:2011.06512v1 [cs.LG])</h2>
<h3>Angelica Louren&#xe7;o Oliveira, Marcos Eduardo Valle</h3>
<p>Mathematical morphology (MM) is a theory of non-linear operators used for the
processing and analysis of images. Morphological neural networks (MNNs) are
neural networks whose neurons compute morphological operators. Dilations and
erosions are the elementary operators of MM. From an algebraic point of view, a
dilation and an erosion are operators that commute respectively with the
supremum and infimum operations. In this paper, we present the \textit{linear
dilation-erosion perceptron} ($\ell$-DEP), which is given by applying linear
transformations before computing a dilation and an erosion. The decision
function of the $\ell$-DEP model is defined by adding a dilation and an
erosion. Furthermore, training a $\ell$-DEP can be formulated as a
convex-concave optimization problem. We compare the performance of the
$\ell$-DEP model with other machine learning techniques using several
classification problems. The computational experiments support the potential
application of the proposed $\ell$-DEP model for binary classification tasks.
</p>
<a href="http://arxiv.org/abs/2011.06512" target="_blank">arXiv:2011.06512</a> [<a href="http://arxiv.org/pdf/2011.06512" target="_blank">pdf</a>]

<h2>Image analysis for Alzheimer's disease prediction: Embracing pathological hallmarks for model architecture design. (arXiv:2011.06531v1 [cs.LG])</h2>
<h3>Sarah C. Br&#xfc;ningk, Felix Hensel, Catherine R. Jutzeler, Bastian Rieck</h3>
<p>Alzheimer's disease (AD) is associated with local (e.g. brain tissue atrophy)
and global brain changes (loss of cerebral connectivity), which can be detected
by high-resolution structural magnetic resonance imaging. Conventionally, these
changes and their relation to AD are investigated independently. Here, we
introduce a novel, highly-scalable approach that simultaneously captures
$\textit{local}$ and $\textit{global}$ changes in the diseased brain. It is
based on a neural network architecture that combines patch-based,
high-resolution 3D-CNNs with global topological features, evaluating
multi-scale brain tissue connectivity. Our local-global approach reached
competitive results with an average precision score of $0.95\pm0.03$ for the
classification of cognitively normal subjects and AD patients (prevalence
$\approx 55\%$).
</p>
<a href="http://arxiv.org/abs/2011.06531" target="_blank">arXiv:2011.06531</a> [<a href="http://arxiv.org/pdf/2011.06531" target="_blank">pdf</a>]

<h2>Shared Prior Learning of Energy-Based Models for Image Reconstruction. (arXiv:2011.06539v1 [cs.CV])</h2>
<h3>Thomas Pinetz, Erich Kobler, Thomas Pock, Alexander Effland</h3>
<p>We propose a novel learning-based framework for image reconstruction
particularly designed for training without ground truth data, which has three
major building blocks: energy-based learning, a patch-based Wasserstein loss
functional, and shared prior learning. In energy-based learning, the parameters
of an energy functional composed of a learned data fidelity term and a
data-driven regularizer are computed in a mean-field optimal control problem.
In the absence of ground truth data, we change the loss functional to a
patch-based Wasserstein functional, in which local statistics of the output
images are compared to uncorrupted reference patches. Finally, in shared prior
learning, both aforementioned optimal control problems are optimized
simultaneously with shared learned parameters of the regularizer to further
enhance unsupervised image reconstruction. We derive several time
discretization schemes of the gradient flow and verify their consistency in
terms of Mosco convergence. In numerous numerical experiments, we demonstrate
that the proposed method generates state-of-the-art results for various image
reconstruction applications--even if no ground truth images are available for
training.
</p>
<a href="http://arxiv.org/abs/2011.06539" target="_blank">arXiv:2011.06539</a> [<a href="http://arxiv.org/pdf/2011.06539" target="_blank">pdf</a>]

<h2>Self-supervised reinforcement learning for speaker localisation with the iCub humanoid robot. (arXiv:2011.06544v1 [cs.RO])</h2>
<h3>Jonas Gonzalez-Billandon, Lukas Grasse, Matthew Tata, Alessandra Sciutti, Francesco Rea</h3>
<p>In the future robots will interact more and more with humans and will have to
communicate naturally and efficiently. Automatic speech recognition systems
(ASR) will play an important role in creating natural interactions and making
robots better companions. Humans excel in speech recognition in noisy
environments and are able to filter out noise. Looking at a person's face is
one of the mechanisms that humans rely on when it comes to filtering speech in
such noisy environments. Having a robot that can look toward a speaker could
benefit ASR performance in challenging environments. To this aims, we propose a
self-supervised reinforcement learning-based framework inspired by the early
development of humans to allow the robot to autonomously create a dataset that
is later used to learn to localize speakers with a deep learning network.
</p>
<a href="http://arxiv.org/abs/2011.06544" target="_blank">arXiv:2011.06544</a> [<a href="http://arxiv.org/pdf/2011.06544" target="_blank">pdf</a>]

<h2>Implicit bias of gradient-descent: fast convergence rate. (arXiv:2011.06550v1 [stat.ML])</h2>
<h3>Elvis Dohmatob</h3>
<p>We consider gradient-flow (GF) and gradient-descent (GD) on linear
classification problems in possibly infinite-dimensional and non-hilbertian
Banach spaces. For exponential-tailed loss functions, including the usual
exponential and logistic loss functions, we establish $\mathcal O (\log (n)/
t)$ convergence rate for the bias in case of GF, and $\widetilde{\mathcal
O}(\log (n)/\sqrt{t})$ in case of GD. This is a net improvement on best known
rates, namely $\mathcal O(\log (n) / \log (t))$. See Ji and Telgarsky (2019),
for example. Upto logarithmic factors, our GD rate matches the very recent
parallel work from Ji and Telgarsky (2020) which uses an agressive stepsize
schedule. Finally, using the aggressive stepsize schedule proposed py Ji and
Telgarsky (2020), we are able to obtain a convergence rate of $\mathcal O(\log
(n)/t)$ for the bias. Our methods of analysis are quite general and radically
different from the usual techniques used in the literature: we use nonlinear
error analysis for convex functions, in the spirit of Kurdyka-\L{}ojasiewicz
theory. One major advantage of our method is that it allows us to convert any
convergence rate for the margin, to a convergence rate on the bias, which is at
least as good as the former. We believe our work will provide an alternative
approach for analyzing the implicit bias of gradient-flow / gradient-descent in
very general settings.
</p>
<a href="http://arxiv.org/abs/2011.06550" target="_blank">arXiv:2011.06550</a> [<a href="http://arxiv.org/pdf/2011.06550" target="_blank">pdf</a>]

<h2>Stress Testing Method for Scenario Based Testing of Automated Driving Systems. (arXiv:2011.06553v1 [cs.RO])</h2>
<h3>Demin Nalic, Hexuan Li, Arno Eichberger, Christoph Wellershaus, Aleksa Pandurevic, Branko Rogic</h3>
<p>Classical approaches and procedures for testing of automated vehicles of SAE
levels 1 and 2 were based on defined scenarios with specific maneuvers,
depending on the function under test. For automated driving systems (ADS) of
SAE level 3+, the scenario space is infinite and calling for virtual testing
and verification. However, even in simulation, the generation of
safety-relevant scenarios for ADS is expensive and time-consuming. This leads
to a demand for stochastic and realistic traffic simulation. Therefore,
microscopic traffic flow simulation models (TFSM) are becoming a crucial part
of scenario-based testing of ADS. In this paper, a co-simulation between the
multi-body simulation software IPG CarMaker and the microscopic traffic flow
simulation software (TFSS) PTV Vissim is used. Although the TFSS could provide
realistic and stochastic behavior of the traffic participants, safety-critical
scenarios (SCS) occur rarely. In order to avoid this, a novel Stress Testing
Method (STM) is introduced. With this method, traffic participants are
manipulated via external driver DLL interface from PTV Vissim in the vicinity
of the vehicle under test in order to provoke defined critical maneuvers
derived from statistical accident data on highways in Austria. These external
driver models imitate human driving errors, resulting in an increase of
safety-critical scenarios. As a result, the presented STM method contributes to
an increase of safety-relevant scenarios for verification, testing and
assessment of ADS.
</p>
<a href="http://arxiv.org/abs/2011.06553" target="_blank">arXiv:2011.06553</a> [<a href="http://arxiv.org/pdf/2011.06553" target="_blank">pdf</a>]

<h2>A partition-based similarity for classification distributions. (arXiv:2011.06557v1 [stat.ML])</h2>
<h3>Hayden S. Helm, Ronak D. Mehta, Brandon Duderstadt, Weiwei Yang, Christoper M. White, Ali Geisa, Joshua T. Vogelstein, Carey E. Priebe</h3>
<p>Herein we define a measure of similarity between classification distributions
that is both principled from the perspective of statistical pattern recognition
and useful from the perspective of machine learning practitioners. In
particular, we propose a novel similarity on classification distributions,
dubbed task similarity, that quantifies how an optimally-transformed optimal
representation for a source distribution performs when applied to inference
related to a target distribution. The definition of task similarity allows for
natural definitions of adversarial and orthogonal distributions. We highlight
limiting properties of representations induced by (universally) consistent
decision rules and demonstrate in simulation that an empirical estimate of task
similarity is a function of the decision rule deployed for inference. We
demonstrate that for a given target distribution, both transfer efficiency and
semantic similarity of candidate source distributions correlate with empirical
task similarity.
</p>
<a href="http://arxiv.org/abs/2011.06557" target="_blank">arXiv:2011.06557</a> [<a href="http://arxiv.org/pdf/2011.06557" target="_blank">pdf</a>]

<h2>Sparse PCA: Algorithms, Adversarial Perturbations and Certificates. (arXiv:2011.06585v1 [cs.LG])</h2>
<h3>Tommaso d&#x27;Orsi, Pravesh K. Kothari, Gleb Novikov, David Steurer</h3>
<p>We study efficient algorithms for Sparse PCA in standard statistical models
(spiked covariance in its Wishart form). Our goal is to achieve optimal
recovery guarantees while being resilient to small perturbations. Despite a
long history of prior works, including explicit studies of perturbation
resilience, the best known algorithmic guarantees for Sparse PCA are fragile
and break down under small adversarial perturbations.

We observe a basic connection between perturbation resilience and
\emph{certifying algorithms} that are based on certificates of upper bounds on
sparse eigenvalues of random matrices. In contrast to other techniques, such
certifying algorithms, including the brute-force maximum likelihood estimator,
are automatically robust against small adversarial perturbation.

We use this connection to obtain the first polynomial-time algorithms for
this problem that are resilient against additive adversarial perturbations by
obtaining new efficient certificates for upper bounds on sparse eigenvalues of
random matrices. Our algorithms are based either on basic semidefinite
programming or on its low-degree sum-of-squares strengthening depending on the
parameter regimes. Their guarantees either match or approach the best known
guarantees of \emph{fragile} algorithms in terms of sparsity of the unknown
vector, number of samples and the ambient dimension.

To complement our algorithmic results, we prove rigorous lower bounds
matching the gap between fragile and robust polynomial-time algorithms in a
natural computational model based on low-degree polynomials (closely related to
the pseudo-calibration technique for sum-of-squares lower bounds) that is known
to capture the best known guarantees for related statistical estimation
problems. The combination of these results provides formal evidence of an
inherent price to pay to achieve robustness.
</p>
<a href="http://arxiv.org/abs/2011.06585" target="_blank">arXiv:2011.06585</a> [<a href="http://arxiv.org/pdf/2011.06585" target="_blank">pdf</a>]

<h2>On the Existence of a Projective Reconstruction. (arXiv:1608.05518v2 [cs.CV] UPDATED)</h2>
<h3>Hon-Leung Lee</h3>
<p>In this note we study the connection between the existence of a projective
reconstruction and the existence of a fundamental matrix satisfying the
epipolar constraints.
</p>
<a href="http://arxiv.org/abs/1608.05518" target="_blank">arXiv:1608.05518</a> [<a href="http://arxiv.org/pdf/1608.05518" target="_blank">pdf</a>]

<h2>Data augmentation instead of explicit regularization. (arXiv:1806.03852v5 [cs.CV] UPDATED)</h2>
<h3>Alex Hern&#xe1;ndez-Garc&#xed;a, Peter K&#xf6;nig</h3>
<p>Contrary to most machine learning models, modern deep artificial neural
networks typically include multiple components that contribute to
regularization. Despite the fact that some (explicit) regularization
techniques, such as weight decay and dropout, require costly fine-tuning of
sensitive hyperparameters, the interplay between them and other elements that
provide implicit regularization is not well understood yet. Shedding light upon
these interactions is key to efficiently using computational resources and may
contribute to solving the puzzle of generalization in deep learning. Here, we
first provide formal definitions of explicit and implicit regularization that
help understand essential differences between techniques. Second, we contrast
data augmentation with weight decay and dropout. Our results show that visual
object categorization models trained with data augmentation alone achieve the
same performance or higher than models trained also with weight decay and
dropout, as is common practice. We conclude that the contribution on
generalization of weight decay and dropout is not only superfluous when
sufficient implicit regularization is provided, but also such techniques can
dramatically deteriorate the performance if the hyperparameters are not
carefully tuned for the architecture and data set. In contrast, data
augmentation systematically provides large generalization gains and does not
require hyperparameter re-tuning. In view of our results, we suggest to
optimize neural networks without weight decay and dropout to save computational
resources, hence carbon emissions, and focus more on data augmentation and
other inductive biases to improve performance and robustness.
</p>
<a href="http://arxiv.org/abs/1806.03852" target="_blank">arXiv:1806.03852</a> [<a href="http://arxiv.org/pdf/1806.03852" target="_blank">pdf</a>]

<h2>Efficient Tensor Decomposition with Boolean Factors. (arXiv:1810.04754v2 [cs.LG] UPDATED)</h2>
<h3>Sung-En Chang, Xun Zheng, Ian E.H. Yen, Pradeep Ravikumar, Rose Yu</h3>
<p>Tensor decomposition has been extensively used as a tool for exploratory
analysis. Motivated by neuroscience applications, we study tensor decomposition
with Boolean factors. The resulting optimization problem is challenging due to
the non-convex objective and the combinatorial constraints. We propose Binary
Matching Pursuit (BMP), a novel generalization of the matching pursuit strategy
to decompose the tensor efficiently. BMP iteratively searches for atoms in a
greedy fashion. The greedy atom search step is solved efficiently via a
MAXCUT-like boolean quadratic program. We prove that BMP is guaranteed to
converge sublinearly to the optimal solution and recover the factors under mild
identifiability conditions. Experiments demonstrate the superior performance of
our method over baselines on synthetic and real datasets. We also showcase the
application of BMP in quantifying neural interactions underlying
high-resolution spatiotemporal ECoG recordings.
</p>
<a href="http://arxiv.org/abs/1810.04754" target="_blank">arXiv:1810.04754</a> [<a href="http://arxiv.org/pdf/1810.04754" target="_blank">pdf</a>]

<h2>A micro Lie theory for state estimation in robotics. (arXiv:1812.01537v8 [cs.RO] UPDATED)</h2>
<h3>Joan Sol&#xe0;, Jeremie Deray, Dinesh Atchuthan</h3>
<p>A Lie group is an old mathematical abstract object dating back to the XIX
century, when mathematician Sophus Lie laid the foundations of the theory of
continuous transformation groups. As it often happens, its usage has spread
over diverse areas of science and technology many years later. In robotics, we
are recently experiencing an important trend in its usage, at least in the
fields of estimation, and particularly in motion estimation for navigation. Yet
for a vast majority of roboticians, Lie groups are highly abstract
constructions and therefore difficult to understand and to use. This may be due
to the fact that most of the literature on Lie theory is written by and for
mathematicians and physicists, who might be more used than us to the deep
abstractions this theory deals with.

In estimation for robotics it is often not necessary to exploit the full
capacity of the theory, and therefore an effort of selection of materials is
required. In this paper, we will walk through the most basic principles of the
Lie theory, with the aim of conveying clear and useful ideas, and leave a
significant corpus of the Lie theory behind. Even with this mutilation, the
material included here has proven to be extremely useful in modern estimation
algorithms for robotics, especially in the fields of SLAM, visual odometry, and
the like.

Alongside this micro Lie theory, we provide a chapter with a few application
examples, and a vast reference of formulas for the major Lie groups used in
robotics, including most jacobian matrices and the way to easily manipulate
them. We also present a new C++ template-only library implementing all the
functionality described here.
</p>
<a href="http://arxiv.org/abs/1812.01537" target="_blank">arXiv:1812.01537</a> [<a href="http://arxiv.org/pdf/1812.01537" target="_blank">pdf</a>]

<h2>High Frame Rate Video Reconstruction based on an Event Camera. (arXiv:1903.06531v3 [cs.CV] UPDATED)</h2>
<h3>Liyuan Pan, Richard Hartley, Cedric Scheerlinck, Miaomiao Liu, Xin Yu, Yuchao Dai</h3>
<p>Event-based cameras measure intensity changes (called `events') with
microsecond accuracy under high-speed motion and challenging lighting
conditions. With the `active pixel sensor' (APS), the `Dynamic and Active-pixel
Vision Sensor' (DAVIS) allows the simultaneous output of intensity frames and
events. However, the output images are captured at a relatively low frame rate
and often suffer from motion blur. A blurred image can be regarded as the
integral of a sequence of latent images, while events indicate changes between
the latent images. Thus, we are able to model the blur-generation process by
associating event data to a latent sharp image. Based on the abundant event
data alongside a low frame rate, easily blurred images, we propose a simple yet
effective approach to reconstruct high-quality and high frame rate sharp
videos. Starting with a single blurred frame and its event data from DAVIS, we
propose the Event-based Double Integral (EDI) model and solve it by adding
regularization terms. Then, we extend it to multiple Event-based Double
Integral (mEDI) model to get more smooth results based on multiple images and
their events. Furthermore, we provide a new and more efficient solver to
minimize the proposed energy model. By optimizing the energy function, we
achieve significant improvements in removing blur and the reconstruction of a
high temporal resolution video. The video generation is based on solving a
simple non-convex optimization problem in a single scalar variable.
Experimental results on both synthetic and real datasets demonstrate the
superiority of our mEDI model and optimization method compared to the
state-of-the-art.
</p>
<a href="http://arxiv.org/abs/1903.06531" target="_blank">arXiv:1903.06531</a> [<a href="http://arxiv.org/pdf/1903.06531" target="_blank">pdf</a>]

<h2>Characterizing the implicit bias via a primal-dual analysis. (arXiv:1906.04540v3 [cs.LG] UPDATED)</h2>
<h3>Ziwei Ji, Matus Telgarsky</h3>
<p>This paper shows that the implicit bias of gradient descent on linearly
separable data is exactly characterized by the optimal solution of a dual
optimization problem given by a smoothed margin, even for general losses. This
is in contrast to prior results, which are often tailored to
exponentially-tailed losses. For the exponential loss specifically, with $n$
training examples and $t$ gradient descent steps, our dual analysis further
allows us to prove an $O(\ln(n)/\ln(t))$ convergence rate to the $\ell_2$
maximum margin direction, when a constant step size is used. This rate is tight
in both $n$ and $t$, which has not been presented by prior work. On the other
hand, with a properly chosen but aggressive step size schedule, we prove
$O(1/t)$ rates for both $\ell_2$ margin maximization and implicit bias, whereas
prior work (including all first-order methods for the general hard-margin
linear SVM problem) proved $\widetilde{O}(1/\sqrt{t})$ margin rates, or
$O(1/t)$ margin rates to a suboptimal margin, with an implied (slower) bias
rate. Our key observations include that gradient descent on the primal variable
naturally induces a mirror descent update on the dual variable, and that the
dual objective in this setting is smooth enough to give a faster rate.
</p>
<a href="http://arxiv.org/abs/1906.04540" target="_blank">arXiv:1906.04540</a> [<a href="http://arxiv.org/pdf/1906.04540" target="_blank">pdf</a>]

<h2>Tensor Canonical Correlation Analysis with Convergence and Statistical Guarantees. (arXiv:1906.05358v4 [stat.ML] UPDATED)</h2>
<h3>You-Lin Chen, Mladen Kolar, Ruey S. Tsay</h3>
<p>In many applications, such as classification of images or videos, it is of
interest to develop a framework for tensor data instead of an ad-hoc way of
transforming data to vectors due to the computational and under-sampling
issues. In this paper, we study convergence and statistical properties of
two-dimensional canonical correlation analysis \citep{Lee2007Two} under an
assumption that data come from a probabilistic model. We show that carefully
initialized the power method converges to the optimum and provide a finite
sample bound. Then we extend this framework to tensor-valued data and propose
the higher-order power method, which is commonly used in tensor decomposition,
to extract the canonical directions. Our method can be used effectively in a
large-scale data setting by solving the inner least squares problem with a
stochastic gradient descent, and we justify convergence via the theory of
Lojasiewicz's inequalities without any assumption on data generating process
and initialization. For practical applications, we further develop (a) an
inexact updating scheme which allows us to use the state-of-the-art stochastic
gradient descent algorithm, (b) an effective initialization scheme which
alleviates the problem of local optimum in non-convex optimization, and (c) a
deflation procedure for extracting several canonical components. Empirical
analyses on challenging data including gene expression and air pollution
indexes in Taiwan, show the effectiveness and efficiency of the proposed
methodology. Our results fill a missing, but crucial, part in the literature on
tensor data.
</p>
<a href="http://arxiv.org/abs/1906.05358" target="_blank">arXiv:1906.05358</a> [<a href="http://arxiv.org/pdf/1906.05358" target="_blank">pdf</a>]

<h2>Recurrent Independent Mechanisms. (arXiv:1909.10893v5 [cs.LG] UPDATED)</h2>
<h3>Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey Levine, Yoshua Bengio, Bernhard Sch&#xf6;lkopf</h3>
<p>Learning modular structures which reflect the dynamics of the environment can
lead to better generalization and robustness to changes which only affect a few
of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a
new recurrent architecture in which multiple groups of recurrent cells operate
with nearly independent transition dynamics, communicate only sparingly through
the bottleneck of attention, and are only updated at time steps where they are
most relevant. We show that this leads to specialization amongst the RIMs,
which in turn allows for dramatically improved generalization on tasks where
some factors of variation differ systematically between training and
evaluation.
</p>
<a href="http://arxiv.org/abs/1909.10893" target="_blank">arXiv:1909.10893</a> [<a href="http://arxiv.org/pdf/1909.10893" target="_blank">pdf</a>]

<h2>Pretraining boosts out-of-domain robustness for pose estimation. (arXiv:1909.11229v2 [cs.CV] UPDATED)</h2>
<h3>Alexander Mathis, Thomas Biasi, Steffen Schneider, Mert Y&#xfc;ksekg&#xf6;n&#xfc;l, Byron Rogers, Matthias Bethge, Mackenzie W. Mathis</h3>
<p>Neural networks are highly effective tools for pose estimation. However, as
in other computer vision tasks, robustness to out-of-domain data remains a
challenge, especially for small training sets that are common for real-world
applications. Here, we probe the generalization ability with three architecture
classes (MobileNetV2s, ResNets, and EfficientNets) for pose estimation. We
developed a dataset of 30 horses that allowed for both "within-domain" and
"out-of-domain" (unseen horse) benchmarking - this is a crucial test for
robustness that current human pose estimation benchmarks do not directly
address. We show that better ImageNet-performing architectures perform better
on both within- and out-of-domain data if they are first pretrained on
ImageNet. We additionally show that better ImageNet models generalize better
across animal species. Furthermore, we introduce Horse-C, a new benchmark for
common corruptions for pose estimation, and confirm that pretraining increases
performance in this domain shift context as well. Overall, our results
demonstrate that transfer learning is beneficial for out-of-domain robustness.
</p>
<a href="http://arxiv.org/abs/1909.11229" target="_blank">arXiv:1909.11229</a> [<a href="http://arxiv.org/pdf/1909.11229" target="_blank">pdf</a>]

<h2>Task-Relevant Adversarial Imitation Learning. (arXiv:1910.01077v2 [cs.LG] UPDATED)</h2>
<h3>Konrad Zolna, Scott Reed, Alexander Novikov, Sergio Gomez Colmenarejo, David Budden, Serkan Cabi, Misha Denil, Nando de Freitas, Ziyu Wang</h3>
<p>We show that a critical vulnerability in adversarial imitation is the
tendency of discriminator networks to learn spurious associations between
visual features and expert labels. When the discriminator focuses on
task-irrelevant features, it does not provide an informative reward signal,
leading to poor task performance. We analyze this problem in detail and propose
a solution that outperforms standard Generative Adversarial Imitation Learning
(GAIL). Our proposed method, Task-Relevant Adversarial Imitation Learning
(TRAIL), uses constrained discriminator optimization to learn informative
rewards. In comprehensive experiments, we show that TRAIL can solve challenging
robotic manipulation tasks from pixels by imitating human operators without
access to any task rewards, and clearly outperforms comparable baseline
imitation agents, including those trained via behaviour cloning and
conventional GAIL.
</p>
<a href="http://arxiv.org/abs/1910.01077" target="_blank">arXiv:1910.01077</a> [<a href="http://arxiv.org/pdf/1910.01077" target="_blank">pdf</a>]

<h2>New and Explicit Constructions of Unbalanced Ramanujan Bipartite Graphs. (arXiv:1910.03937v2 [stat.ML] UPDATED)</h2>
<h3>Shantanu Prasad Burnwal, Kaneenika Sinha, Mathukumalli Vidyasagar</h3>
<p>The objectives of this article are three-fold. Firstly, we present for the
first time explicit constructions of an infinite family of \textit{unbalanced}
Ramanujan bigraphs. Secondly, we revisit some of the known methods for
constructing Ramanujan graphs and discuss the computational work required in
actually implementing the various construction methods. The third goal of this
article is to address the following question: can we construct a bipartite
Ramanujan graph with specified degrees, but with the restriction that the edge
set of this graph must be distinct from a given set of "prohibited" edges? We
provide an affirmative answer in many cases, as long as the set of prohibited
edges is not too large.
</p>
<a href="http://arxiv.org/abs/1910.03937" target="_blank">arXiv:1910.03937</a> [<a href="http://arxiv.org/pdf/1910.03937" target="_blank">pdf</a>]

<h2>Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering Approach for Action Recognition. (arXiv:1910.09616v3 [cs.CV] UPDATED)</h2>
<h3>Siddharth Roheda, Hamid Krim</h3>
<p>The importance of inference in Machine Learning (ML) has led to an explosive
number of different proposals in ML, and particularly in Deep Learning. In an
attempt to reduce the complexity of Convolutional Neural Networks, we propose a
Volterra filter-inspired Network architecture. This architecture introduces
controlled non-linearities in the form of interactions between the delayed
input samples of data. We propose a cascaded implementation of Volterra
Filtering so as to significantly reduce the number of parameters required to
carry out the same classification task as that of a conventional Neural
Network. We demonstrate an efficient parallel implementation of this Volterra
Neural Network (VNN), along with its remarkable performance while retaining a
relatively simpler and potentially more tractable structure. Furthermore, we
show a rather sophisticated adaptation of this network to nonlinearly fuse the
RGB (spatial) information and the Optical Flow (temporal) information of a
video sequence for action recognition. The proposed approach is evaluated on
UCF-101 and HMDB-51 datasets for action recognition, and is shown to outperform
state of the art CNN approaches.
</p>
<a href="http://arxiv.org/abs/1910.09616" target="_blank">arXiv:1910.09616</a> [<a href="http://arxiv.org/pdf/1910.09616" target="_blank">pdf</a>]

<h2>On the convergence of projective-simulation-based reinforcement learning in Markov decision processes. (arXiv:1910.11914v3 [cs.LG] UPDATED)</h2>
<h3>Walter L. Boyajian, Jens Clausen, Lea M. Trenkwalder, Vedran Dunjko, Hans J. Briegel</h3>
<p>In recent years, the interest in leveraging quantum effects for enhancing
machine learning tasks has significantly increased. Many algorithms speeding up
supervised and unsupervised learning were established. The first framework in
which ways to exploit quantum resources specifically for the broader context of
reinforcement learning were found is projective simulation. Projective
simulation presents an agent-based reinforcement learning approach designed in
a manner which may support quantum walk-based speed-ups. Although classical
variants of projective simulation have been benchmarked against common
reinforcement learning algorithms, very few formal theoretical analyses have
been provided for its performance in standard learning scenarios. In this
paper, we provide a detailed formal discussion of the properties of this model.
Specifically, we prove that one version of the projective simulation model,
understood as a reinforcement learning approach, converges to optimal behavior
in a large class of Markov decision processes. This proof shows that a
physically-inspired approach to reinforcement learning can guarantee to
converge.
</p>
<a href="http://arxiv.org/abs/1910.11914" target="_blank">arXiv:1910.11914</a> [<a href="http://arxiv.org/pdf/1910.11914" target="_blank">pdf</a>]

<h2>Asymptotics of Reinforcement Learning with Neural Networks. (arXiv:1911.07304v2 [cs.LG] UPDATED)</h2>
<h3>Justin Sirignano, Konstantinos Spiliopoulos</h3>
<p>We prove that a single-layer neural network trained with the Q-learning
algorithm converges in distribution to a random ordinary differential equation
as the size of the model and the number of training steps become large.
Analysis of the limit differential equation shows that it has a unique
stationary solution which is the solution of the Bellman equation, thus giving
the optimal control for the problem. In addition, we study the convergence of
the limit differential equation to the stationary solution. As a by-product of
our analysis, we obtain the limiting behavior of single-layer neural networks
when trained on i.i.d. data with stochastic gradient descent under the
widely-used Xavier initialization.
</p>
<a href="http://arxiv.org/abs/1911.07304" target="_blank">arXiv:1911.07304</a> [<a href="http://arxiv.org/pdf/1911.07304" target="_blank">pdf</a>]

<h2>A Unified Framework for Random Forest Prediction Error Estimation. (arXiv:1912.07435v4 [stat.ML] UPDATED)</h2>
<h3>Benjamin Lu, Johanna Hardin</h3>
<p>We introduce a unified framework for random forest prediction error
estimation based on a novel estimator of the conditional prediction error
distribution function. Our framework enables immediate estimation of key
prediction uncertainty metrics, including conditional mean squared prediction
errors, conditional biases, and conditional quantiles, by a straightforward
plug-in routine. Our approach is particularly well-adapted for prediction
interval estimation, which has received less attention in the random forest
literature despite its practical utility; we show via simulations that our
proposed prediction intervals are competitive with, and in some settings
outperform, existing methods. To establish theoretical grounding for our
framework, we prove pointwise uniform consistency of a more stringent version
of our estimator of the conditional prediction error distribution. In addition
to providing a suite of measures of prediction uncertainty, our general
framework is applicable to many variants of the random forest algorithm. The
estimators introduced here are implemented in the R package forestError.
</p>
<a href="http://arxiv.org/abs/1912.07435" target="_blank">arXiv:1912.07435</a> [<a href="http://arxiv.org/pdf/1912.07435" target="_blank">pdf</a>]

<h2>Adversarial symmetric GANs: bridging adversarial samples and adversarial networks. (arXiv:1912.09670v4 [cs.CV] UPDATED)</h2>
<h3>Faqiang Liu, Mingkun Xu, Guoqi Li, Jing Pei, Luping Shi, Rong Zhao</h3>
<p>Generative adversarial networks have achieved remarkable performance on
various tasks but suffer from training instability. Despite many training
strategies proposed to improve training stability, this issue remains as a
challenge. In this paper, we investigate the training instability from the
perspective of adversarial samples and reveal that adversarial training on fake
samples is implemented in vanilla GANs, but adversarial training on real
samples has long been overlooked. Consequently, the discriminator is extremely
vulnerable to adversarial perturbation and the gradient given by the
discriminator contains non-informative adversarial noises, which hinders the
generator from catching the pattern of real samples. Here, we develop
adversarial symmetric GANs (AS-GANs) that incorporate adversarial training of
the discriminator on real samples into vanilla GANs, making adversarial
training symmetrical. The discriminator is therefore more robust and provides
more informative gradient with less adversarial noise, thereby stabilizing
training and accelerating convergence. The effectiveness of the AS-GANs is
verified on image generation on CIFAR-10 , CelebA, and LSUN with varied network
architectures. Not only the training is more stabilized, but the FID scores of
generated samples are consistently improved by a large margin compared to the
baseline. The bridging of adversarial samples and adversarial networks provides
a new approach to further develop adversarial networks.
</p>
<a href="http://arxiv.org/abs/1912.09670" target="_blank">arXiv:1912.09670</a> [<a href="http://arxiv.org/pdf/1912.09670" target="_blank">pdf</a>]

<h2>Learning Variable Ordering Heuristics for Solving Constraint Satisfaction Problems. (arXiv:1912.10762v2 [cs.AI] UPDATED)</h2>
<h3>Wen Song, Zhiguang Cao, Jie Zhang, Andrew Lim</h3>
<p>Backtracking search algorithms are often used to solve the Constraint
Satisfaction Problem (CSP). The efficiency of backtracking search depends
greatly on the variable ordering heuristics. Currently, the most commonly used
heuristics are hand-crafted based on expert knowledge. In this paper, we
propose a deep reinforcement learning based approach to automatically discover
new variable ordering heuristics that are better adapted for a given class of
CSP instances. We show that directly optimizing the search cost is hard for
bootstrapping, and propose to optimize the expected cost of reaching a leaf
node in the search tree. To capture the complex relations among the variables
and constraints, we design a representation scheme based on Graph Neural
Network that can process CSP instances with different sizes and constraint
arities. Experimental results on random CSP instances show that the learned
policies outperform classical hand-crafted heuristics in terms of minimizing
the search tree size, and can effectively generalize to instances that are
larger than those used in training.
</p>
<a href="http://arxiv.org/abs/1912.10762" target="_blank">arXiv:1912.10762</a> [<a href="http://arxiv.org/pdf/1912.10762" target="_blank">pdf</a>]

<h2>Statistical stability indices for LIME: obtaining reliable explanations for Machine Learning models. (arXiv:2001.11757v2 [cs.LG] UPDATED)</h2>
<h3>Giorgio Visani, Enrico Bagli, Federico Chesani, Alessandro Poluzzi, Davide Capuzzo</h3>
<p>Nowadays we are witnessing a transformation of the business processes towards
a more computation driven approach. The ever increasing usage of Machine
Learning techniques is the clearest example of such trend.

This sort of revolution is often providing advantages, such as an increase in
prediction accuracy and a reduced time to obtain the results. However, these
methods present a major drawback: it is very difficult to understand on what
grounds the algorithm took the decision.

To address this issue we consider the LIME method. We give a general
background on LIME then, we focus on the stability issue: employing the method
repeated times, under the same conditions, may yield to different explanations.

Two complementary indices are proposed, to measure LIME stability. It is
important for the practitioner to be aware of the issue, as well as to have a
tool for spotting it. Stability guarantees LIME explanations to be reliable,
therefore a stability assessment, made through the proposed indices, is
crucial.

As a case study, we apply both Machine Learning and classical statistical
techniques to Credit Risk data. We test LIME on the Machine Learning algorithm
and check its stability. Eventually, we examine the goodness of the
explanations returned.
</p>
<a href="http://arxiv.org/abs/2001.11757" target="_blank">arXiv:2001.11757</a> [<a href="http://arxiv.org/pdf/2001.11757" target="_blank">pdf</a>]

<h2>De-randomized PAC-Bayes Margin Bounds: Applications to Non-convex and Non-smooth Predictors. (arXiv:2002.09956v3 [cs.LG] UPDATED)</h2>
<h3>Arindam Banerjee, Tiancong Chen, Yingxue Zhou</h3>
<p>In spite of several notable efforts, explaining the generalization of
deterministic non-smooth deep nets, e.g., ReLU-nets, has remained challenging.
Existing approaches for deterministic non-smooth deep nets typically need to
bound the Lipschitz constant of such deep nets but such bounds are quite large,
may even increase with the training set size yielding vacuous generalization
bounds. In this paper, we present a new family of de-randomized PAC-Bayes
margin bounds for deterministic non-convex and non-smooth predictors, e.g.,
ReLU-nets. Unlike PAC-Bayes, which applies to Bayesian predictors, the
de-randomized bounds apply to deterministic predictors like ReLU-nets. A
specific instantiation of the bound depends on a trade-off between the
(weighted) distance of the trained weights from the initialization and the
effective curvature (`flatness') of the trained predictor.

To get to these bounds, we first develop a de-randomization argument for
non-convex but smooth predictors, e.g., linear deep networks (LDNs), which
connects the performance of the deterministic predictor with a Bayesian
predictor. We then consider non-smooth predictors which for any given input
realized as a smooth predictor, e.g., ReLU-nets become some LDNs for any given
input, but the realized smooth predictors can be different for different
inputs. For such non-smooth predictors, we introduce a new PAC-Bayes analysis
which takes advantage of the smoothness of the realized predictors, e.g., LDN,
for a given input, and avoids dependency on the Lipschitz constant of the
non-smooth predictor. After careful de-randomization, we get a bound for the
deterministic non-smooth predictor. We also establish non-uniform sample
complexity results based on such bounds. Finally, we present extensive
empirical results of our bounds over changing training set size and randomness
in labels.
</p>
<a href="http://arxiv.org/abs/2002.09956" target="_blank">arXiv:2002.09956</a> [<a href="http://arxiv.org/pdf/2002.09956" target="_blank">pdf</a>]

<h2>PoseNet3D: Learning Temporally Consistent 3D Human Pose via Knowledge Distillation. (arXiv:2003.03473v2 [cs.CV] UPDATED)</h2>
<h3>Shashank Tripathi, Siddhant Ranade, Ambrish Tyagi, Amit Agrawal</h3>
<p>Recovering 3D human pose from 2D joints is a highly unconstrained problem. We
propose a novel neural network framework, PoseNet3D, that takes 2D joints as
input and outputs 3D skeletons and SMPL body model parameters. By casting our
learning approach in a student-teacher framework, we avoid using any 3D data
such as paired/unpaired 3D data, motion capture sequences, depth images or
multi-view images during training. We first train a teacher network that
outputs 3D skeletons, using only 2D poses for training. The teacher network
distills its knowledge to a student network that predicts 3D pose in SMPL
representation. Finally, both the teacher and the student networks are jointly
fine-tuned in an end-to-end manner using temporal, self-consistency and
adversarial losses, improving the accuracy of each individual network. Results
on Human3.6M dataset for 3D human pose estimation demonstrate that our approach
reduces the 3D joint prediction error by 18% compared to previous unsupervised
methods. Qualitative results on in-the-wild datasets show that the recovered 3D
poses and meshes are natural, realistic, and flow smoothly over consecutive
frames.
</p>
<a href="http://arxiv.org/abs/2003.03473" target="_blank">arXiv:2003.03473</a> [<a href="http://arxiv.org/pdf/2003.03473" target="_blank">pdf</a>]

<h2>Real Time Multi-Class Object Detection and Recognition Using Vision Augmentation Algorithm. (arXiv:2003.07442v4 [cs.CV] UPDATED)</h2>
<h3>Al-Akhir Nayan, Joyeta Saha, Ahamad Nokib Mozumder, Khan Raqib Mahmud, Abul Kalam Al Azad</h3>
<p>The aim of this research is to detect small objects with low resolution and
noise. The existing real time object detection algorithm is based on the deep
neural network of convolution need to perform multilevel convolution and
pooling operations on the entire image to extract a deep semantic
characteristic of the image. The detection models perform better for large
objects. The features of existing models do not fully represent the essential
features of small objects after repeated convolution operations. We have
introduced a novel real time detection algorithm which employs upsampling and
skip connection to extract multiscale features at different convolution levels
in a learning task resulting a remarkable performance in detecting small
objects. The detection precision of the model is shown to be higher and faster
than that of the state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2003.07442" target="_blank">arXiv:2003.07442</a> [<a href="http://arxiv.org/pdf/2003.07442" target="_blank">pdf</a>]

<h2>ParKCa: Causal Inference with Partially Known Causes. (arXiv:2003.07952v4 [cs.LG] UPDATED)</h2>
<h3>Raquel Aoki, Martin Ester</h3>
<p>Methods for causal inference from observational data are an alternative for
scenarios where collecting counterfactual data or realizing a randomized
experiment is not possible. Adopting a stacking approach, our proposed method
ParKCA combines the results of several causal inference methods to learn new
causes in applications with some known causes and many potential causes. We
validate ParKCA in two Genome-wide association studies, one real-world and one
simulated dataset. Our results show that ParKCA can infer more causes than
existing methods.
</p>
<a href="http://arxiv.org/abs/2003.07952" target="_blank">arXiv:2003.07952</a> [<a href="http://arxiv.org/pdf/2003.07952" target="_blank">pdf</a>]

<h2>Counterfactual Policy Evaluation for Decision-Making in Autonomous Driving. (arXiv:2003.11919v3 [cs.LG] UPDATED)</h2>
<h3>Patrick Hart, Alois Knoll</h3>
<p>Learning-based approaches, such as reinforcement and imitation learning are
gaining popularity in decision-making for autonomous driving. However, learned
policies often fail to generalize and cannot handle novel situations well.
Asking and answering questions in the form of "Would a policy perform well if
the other agents had behaved differently?" can shed light on whether a policy
has seen similar situations during training and generalizes well. In this work,
a counterfactual policy evaluation is introduced that makes use of
counterfactual worlds - worlds in which the behaviors of others are non-actual.
If a policy can handle all counterfactual worlds well, it either has seen
similar situations during training or it generalizes well and is deemed to be
fit enough to be executed in the actual world. Additionally, by performing the
counterfactual policy evaluation, causal relations and the influence of
changing vehicle's behaviors on the surrounding vehicles becomes evident. To
validate the proposed method, we learn a policy using reinforcement learning
for a lane merging scenario. In the application-phase, the policy is only
executed after the counterfactual policy evaluation has been performed and if
the policy is found to be safe enough. We show that the proposed approach
significantly decreases the collision-rate whilst maintaining a high
success-rate.
</p>
<a href="http://arxiv.org/abs/2003.11919" target="_blank">arXiv:2003.11919</a> [<a href="http://arxiv.org/pdf/2003.11919" target="_blank">pdf</a>]

<h2>Learning Dense Visual Correspondences in Simulation to Smooth and Fold Real Fabrics. (arXiv:2003.12698v2 [cs.RO] UPDATED)</h2>
<h3>Aditya Ganapathi, Priya Sundaresan, Brijen Thananjeyan, Ashwin Balakrishna, Daniel Seita, Jennifer Grannen, Minho Hwang, Ryan Hoque, Joseph E. Gonzalez, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg</h3>
<p>Robotic fabric manipulation is challenging due to the infinite dimensional
configuration space, self-occlusion, and complex dynamics of fabrics. There has
been significant prior work on learning policies for specific deformable
manipulation tasks, but comparatively less focus on algorithms which can
efficiently learn many different tasks. In this paper, we learn visual
correspondences for deformable fabrics across different configurations in
simulation and show that this representation can be used to design policies for
a variety of tasks. Given a single demonstration of a new task from an initial
fabric configuration, the learned correspondences can be used to compute
geometrically equivalent actions in a new fabric configuration. This makes it
possible to robustly imitate a broad set of multi-step fabric smoothing and
folding tasks on multiple physical robotic systems. The resulting policies
achieve 80.3% average task success rate across 10 fabric manipulation tasks on
two different robotic systems, the da Vinci surgical robot and the ABB YuMi.
Results also suggest robustness to fabrics of various colors, sizes, and
shapes. See https://tinyurl.com/fabric-descriptors for supplementary material
and videos.
</p>
<a href="http://arxiv.org/abs/2003.12698" target="_blank">arXiv:2003.12698</a> [<a href="http://arxiv.org/pdf/2003.12698" target="_blank">pdf</a>]

<h2>Measuring Human and Economic Activity from Satellite Imagery to Support City-Scale Decision-Making during COVID-19 Pandemic. (arXiv:2004.07438v4 [cs.CV] UPDATED)</h2>
<h3>Rodrigo Minetto, Mauricio Pamplona Segundo, Gilbert Rotich, Sudeep Sarkar</h3>
<p>The COVID-19 outbreak forced governments worldwide to impose lockdowns and
quarantines to prevent virus transmission. As a consequence, there are
disruptions in human and economic activities all over the globe. The recovery
process is also expected to be rough. Economic activities impact social
behaviors, which leave signatures in satellite images that can be automatically
detected and classified. Satellite imagery can support the decision-making of
analysts and policymakers by providing a different kind of visibility into the
unfolding economic changes. In this work, we use a deep learning approach that
combines strategic location sampling and an ensemble of lightweight
convolutional neural networks (CNNs) to recognize specific elements in
satellite images that could be used to compute economic indicators based on it,
automatically. This CNN ensemble framework ranked third place in the US
Department of Defense xView challenge, the most advanced benchmark for object
detection in satellite images. We show the potential of our framework for
temporal analysis using the US IARPA Function Map of the World (fMoW) dataset.
We also show results on real examples of different sites before and after the
COVID-19 outbreak to illustrate different measurable indicators. Our code and
annotated high-resolution aerial scenes before and after the outbreak are
available on GitHub (https://github.com/maups/covid19-satellite-analysis).
</p>
<a href="http://arxiv.org/abs/2004.07438" target="_blank">arXiv:2004.07438</a> [<a href="http://arxiv.org/pdf/2004.07438" target="_blank">pdf</a>]

<h2>A Compressive Classification Framework for High-Dimensional Data. (arXiv:2005.04383v2 [stat.ML] UPDATED)</h2>
<h3>Muhammad Naveed Tabassum, Esa Ollila</h3>
<p>We propose a compressive classification framework for settings where the data
dimensionality is significantly higher than the sample size. The proposed
method, referred to as compressive regularized discriminant analysis (CRDA) is
based on linear discriminant analysis and has the ability to select significant
features by using joint-sparsity promoting hard thresholding in the
discriminant rule. Since the number of features is larger than the sample size,
the method also uses state-of-the-art regularized sample covariance matrix
estimators. Several analysis examples on real data sets, including image,
speech signal and gene expression data illustrate the promising improvements
offered by the proposed CRDA classifier in practise. Overall, the proposed
method gives fewer misclassification errors than its competitors, while at the
same time achieving accurate feature selection results. The open-source R
package and MATLAB toolbox of the proposed method (named compressiveRDA) is
freely available.
</p>
<a href="http://arxiv.org/abs/2005.04383" target="_blank">arXiv:2005.04383</a> [<a href="http://arxiv.org/pdf/2005.04383" target="_blank">pdf</a>]

<h2>Continual Learning for Affective Computing. (arXiv:2006.06113v2 [cs.CV] UPDATED)</h2>
<h3>Nikhil Churamani</h3>
<p>Real-world application requires affect perception models to be sensitive to
individual differences in expression. As each user is different and expresses
differently, these models need to personalise towards each individual to
adequately capture their expressions and thus, model their affective state.
Despite high performance on benchmarks, current approaches fall short in such
adaptation. In this work, we propose the use of Continual Learning (CL) for
affective computing as a paradigm for developing personalised affect
perception.
</p>
<a href="http://arxiv.org/abs/2006.06113" target="_blank">arXiv:2006.06113</a> [<a href="http://arxiv.org/pdf/2006.06113" target="_blank">pdf</a>]

<h2>How Many Samples is a Good Initial Point Worth in Low-rank Matrix Recovery?. (arXiv:2006.06915v2 [cs.LG] UPDATED)</h2>
<h3>Gavin Zhang, Richard Y. Zhang</h3>
<p>Given a sufficiently large amount of labeled data, the non-convex low-rank
matrix recovery problem contains no spurious local minima, so a local
optimization algorithm is guaranteed to converge to a global minimum starting
from any initial guess. However, the actual amount of data needed by this
theoretical guarantee is very pessimistic, as it must prevent spurious local
minima from existing anywhere, including at adversarial locations. In contrast,
prior work based on good initial guesses have more realistic data requirements,
because they allow spurious local minima to exist outside of a neighborhood of
the solution. In this paper, we quantify the relationship between the quality
of the initial guess and the corresponding reduction in data requirements.
Using the restricted isometry constant as a surrogate for sample complexity, we
compute a sharp threshold number of samples needed to prevent each specific
point on the optimization landscape from becoming a spurious local minimum.
Optimizing the threshold over regions of the landscape, we see that for initial
points around the ground truth, a linear improvement in the quality of the
initial guess amounts to a constant factor improvement in the sample
complexity.
</p>
<a href="http://arxiv.org/abs/2006.06915" target="_blank">arXiv:2006.06915</a> [<a href="http://arxiv.org/pdf/2006.06915" target="_blank">pdf</a>]

<h2>GAN Memory with No Forgetting. (arXiv:2006.07543v2 [cs.CV] UPDATED)</h2>
<h3>Yulai Cong, Miaoyun Zhao, Jianqiao Li, Sijia Wang, Lawrence Carin</h3>
<p>As a fundamental issue in lifelong learning, catastrophic forgetting is
directly caused by inaccessible historical data; accordingly, if the data
(information) were memorized perfectly, no forgetting should be expected.
Motivated by that, we propose a GAN memory for lifelong learning, which is
capable of remembering a stream of datasets via generative processes, with
\emph{no} forgetting. Our GAN memory is based on recognizing that one can
modulate the "style" of a GAN model to form perceptually-distant targeted
generation. Accordingly, we propose to do sequential style modulations atop a
well-behaved base GAN model, to form sequential targeted generative models,
while simultaneously benefiting from the transferred base knowledge. The GAN
memory -- that is motivated by lifelong learning -- is therefore itself
manifested by a form of lifelong learning, via forward transfer and modulation
of information from prior tasks. Experiments demonstrate the superiority of our
method over existing approaches and its effectiveness in alleviating
catastrophic forgetting for lifelong classification problems. Code is available
at https://github.com/MiaoyunZhao/GANmemory_LifelongLearning.
</p>
<a href="http://arxiv.org/abs/2006.07543" target="_blank">arXiv:2006.07543</a> [<a href="http://arxiv.org/pdf/2006.07543" target="_blank">pdf</a>]

<h2>Global Attention Improves Graph Networks Generalization. (arXiv:2006.07846v2 [cs.LG] UPDATED)</h2>
<h3>Omri Puny, Heli Ben-Hamu, Yaron Lipman</h3>
<p>This paper advocates incorporating a Low-Rank Global Attention (LRGA) module,
a computation and memory efficient variant of the dot-product attention
(Vaswani et al., 2017), to Graph Neural Networks (GNNs) for improving their
generalization power. To theoretically quantify the generalization properties
granted by adding the LRGA module to GNNs, we focus on a specific family of
expressive GNNs and show that augmenting it with LRGA provides algorithmic
alignment to a powerful graph isomorphism test, namely the 2-Folklore
Weisfeiler-Lehman (2-FWL) algorithm. In more detail we: (i) consider the recent
Random Graph Neural Network (RGNN) (Sato et al., 2020) framework and prove that
it is universal in probability; (ii) show that RGNN augmented with LRGA aligns
with 2-FWL update step via polynomial kernels; and (iii) bound the sample
complexity of the kernel's feature map when learned with a randomly initialized
two-layer MLP. From a practical point of view, augmenting existing GNN layers
with LRGA produces state of the art results in current GNN benchmarks. Lastly,
we observe that augmenting various GNN architectures with LRGA often closes the
performance gap between different models.
</p>
<a href="http://arxiv.org/abs/2006.07846" target="_blank">arXiv:2006.07846</a> [<a href="http://arxiv.org/pdf/2006.07846" target="_blank">pdf</a>]

<h2>Classifier-independent Lower-Bounds for Adversarial Robustness. (arXiv:2006.09989v6 [stat.ML] UPDATED)</h2>
<h3>Elvis Dohmatob</h3>
<p>We theoretically analyse the limits of robustness to test-time adversarial
and noisy examples in classification. Our work focuses on deriving bounds which
uniformly apply to all classifiers (i.e all measurable functions from features
to labels) for a given problem. Our contributions are two-fold. (1) We use
optimal transport theory to derive variational formulae for the Bayes-optimal
error a classifier can make on a given classification problem, subject to
adversarial attacks. The optimal adversarial attack is then an optimal
transport plan for a certain binary cost-function induced by the specific
attack model, and can be computed via a simple algorithm based on maximal
matching on bipartite graphs. (2) We derive explicit lower-bounds on the
Bayes-optimal error in the case of the popular distance-based attacks. These
bounds are universal in the sense that they depend on the geometry of the
class-conditional distributions of the data, but not on a particular
classifier. Our results are in sharp contrast with the existing literature,
wherein adversarial vulnerability of classifiers is derived as a consequence of
nonzero ordinary test error.
</p>
<a href="http://arxiv.org/abs/2006.09989" target="_blank">arXiv:2006.09989</a> [<a href="http://arxiv.org/pdf/2006.09989" target="_blank">pdf</a>]

<h2>Video Semantic Segmentation with Distortion-Aware Feature Correction. (arXiv:2006.10380v2 [cs.CV] UPDATED)</h2>
<h3>Jiafan Zhuang, Zilei Wang, Bingke Wang</h3>
<p>Video semantic segmentation is active in recent years benefited from the
great progress of image semantic segmentation. For such a task, the per-frame
image segmentation is generally unacceptable in practice due to high
computation cost. To tackle this issue, many works use the flow-based feature
propagation to reuse the features of previous frames. However, the optical flow
estimation inevitably suffers inaccuracy and then causes the propagated
features distorted. In this paper, we propose distortion-aware feature
correction to alleviate the issue, which improves video segmentation
performance by correcting distorted propagated features. To be specific, we
firstly propose to transfer distortion patterns from feature into image space
and conduct effective distortion map prediction. Benefited from the guidance of
distortion maps, we proposed Feature Correction Module (FCM) to rectify
propagated features in the distorted areas. Our proposed method can
significantly boost the accuracy of video semantic segmentation at a low price.
The extensive experimental results on Cityscapes and CamVid show that our
method outperforms the recent state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2006.10380" target="_blank">arXiv:2006.10380</a> [<a href="http://arxiv.org/pdf/2006.10380" target="_blank">pdf</a>]

<h2>SS-CAM: Smoothed Score-CAM for Sharper Visual Feature Localization. (arXiv:2006.14255v3 [cs.CV] UPDATED)</h2>
<h3>Haofan Wang, Rakshit Naidu, Joy Michael, Soumya Snigdha Kundu</h3>
<p>Interpretation of the underlying mechanisms of Deep Convolutional Neural
Networks has become an important aspect of research in the field of deep
learning due to their applications in high-risk environments. To explain these
black-box architectures there have been many methods applied so the internal
decisions can be analyzed and understood. In this paper, built on the top of
Score-CAM, we introduce an enhanced visual explanation in terms of visual
sharpness called SS-CAM, which produces centralized localization of object
features within an image through a smooth operation. We evaluate our method on
the ILSVRC 2012 Validation dataset, which outperforms Score-CAM on both
faithfulness and localization tasks.
</p>
<a href="http://arxiv.org/abs/2006.14255" target="_blank">arXiv:2006.14255</a> [<a href="http://arxiv.org/pdf/2006.14255" target="_blank">pdf</a>]

<h2>Object Files and Schemata: Factorizing Declarative and Procedural Knowledge in Dynamical Systems. (arXiv:2006.16225v4 [cs.LG] UPDATED)</h2>
<h3>Anirudh Goyal, Alex Lamb, Phanideep Gampa, Philippe Beaudoin, Sergey Levine, Charles Blundell, Yoshua Bengio, Michael Mozer</h3>
<p>Modeling a structured, dynamic environment like a video game requires keeping
track of the objects and their states declarative knowledge) as well as
predicting how objects behave (procedural knowledge). Black-box models with a
monolithic hidden state often fail to apply procedural knowledge consistently
and uniformly, i.e., they lack systematicity. For example, in a video game,
correct prediction of one enemy's trajectory does not ensure correct prediction
of another's. We address this issue via an architecture that factorizes
declarative and procedural knowledge and that imposes modularity within each
form of knowledge. The architecture consists of active modules called object
files that maintain the state of a single object and invoke passive external
knowledge sources called schemata that prescribe state updates. To use a video
game as an illustration, two enemies of the same type will share schemata but
will have separate object files to encode their distinct state (e.g., health,
position). We propose to use attention to determine which object files to
update, the selection of schemata, and the propagation of information between
object files. The resulting architecture is a drop-in replacement conforming to
the same input-output interface as normal recurrent networks (e.g., LSTM, GRU)
yet achieves substantially better generalization on environments that have
multiple object tokens of the same type, including a challenging intuitive
physics benchmark.
</p>
<a href="http://arxiv.org/abs/2006.16225" target="_blank">arXiv:2006.16225</a> [<a href="http://arxiv.org/pdf/2006.16225" target="_blank">pdf</a>]

<h2>Pseudo-Rehearsal for Continual Learning with Normalizing Flows. (arXiv:2007.02443v2 [stat.ML] UPDATED)</h2>
<h3>Jary Pomponi, Simone Scardapane, Aurelio Uncini</h3>
<p>Catastrophic forgetting (CF) happens whenever a neural network overwrites
past knowledge while being trained on new tasks. Common techniques to handle CF
include regularization of the weights (using, e.g., their importance on past
tasks), and rehearsal strategies, where the network is constantly re-trained on
past data. Generative models have also been applied for the latter, in order to
have endless sources of data. In this paper, we propose a novel method that
combines the strengths of regularization and generative-based rehearsal
approaches. Our generative model consists of a normalizing flow (NF), a
probabilistic and invertible neural network, trained on the internal embeddings
of the network. By keeping a single NF conditioned on the task, we show that
our memory overhead remains constant. In addition, exploiting the invertibility
of the NF, we propose a simple approach to regularize the network's embeddings
with respect to past tasks. We show that our method performs favorably with
respect to state-of-the-art approaches in the literature, with bounded
computational power and memory overheads.
</p>
<a href="http://arxiv.org/abs/2007.02443" target="_blank">arXiv:2007.02443</a> [<a href="http://arxiv.org/pdf/2007.02443" target="_blank">pdf</a>]

<h2>La-MAML: Look-ahead Meta Learning for Continual Learning. (arXiv:2007.13904v2 [cs.LG] UPDATED)</h2>
<h3>Gunshi Gupta, Karmesh Yadav, Liam Paull</h3>
<p>The continual learning problem involves training models with limited capacity
to perform well on a set of an unknown number of sequentially arriving tasks.
While meta-learning shows great potential for reducing interference between old
and new tasks, the current training procedures tend to be either slow or
offline, and sensitive to many hyper-parameters. In this work, we propose
Look-ahead MAML (La-MAML), a fast optimisation-based meta-learning algorithm
for online-continual learning, aided by a small episodic memory. Our proposed
modulation of per-parameter learning rates in our meta-learning update allows
us to draw connections to prior work on hypergradients and meta-descent. This
provides a more flexible and efficient way to mitigate catastrophic forgetting
compared to conventional prior-based methods. La-MAML achieves performance
superior to other replay-based, prior-based and meta-learning based approaches
for continual learning on real-world visual classification benchmarks. Source
code can be found here: https://github.com/montrealrobotics/La-MAML
</p>
<a href="http://arxiv.org/abs/2007.13904" target="_blank">arXiv:2007.13904</a> [<a href="http://arxiv.org/pdf/2007.13904" target="_blank">pdf</a>]

<h2>Optimal Probabilistic Motion Planning with Partially Infeasible LTL Constraints. (arXiv:2007.14325v2 [cs.RO] UPDATED)</h2>
<h3>Mingyu Cai, Hongbo Gao, Shaoping Xiao, Zhijun Li, Zhen Kan</h3>
<p>This paper studies optimal probabilistic motion planning of a mobile agent
with potentially infeasible task specifications subject to motion and
environment uncertainties. Instead of the traditional Rabin automata,
limit-deterministic B\"uchi automata are applied and a relaxed product MDP
between PL-MDP (i.e., probabilistic labeled Markov decision process) and LDBA
is developed, which allows the agent to revise its motion plan whenever the
task is not fully feasible. A multi-objective optimization problem is then
formulated to jointly consider the probability of the task satisfaction , the
violation cost, and the implementation costs, which is solved via coupled
linear programs. To the best of our knowledge, it is the first work that
bridges the gap between planning revision and optimal control synthesis of both
prefix and suffix of the agent trajectory. Simulation results are provided to
demonstrate the effectiveness of the proposed framework.
</p>
<a href="http://arxiv.org/abs/2007.14325" target="_blank">arXiv:2007.14325</a> [<a href="http://arxiv.org/pdf/2007.14325" target="_blank">pdf</a>]

<h2>CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations. (arXiv:2008.02792v2 [cs.CV] UPDATED)</h2>
<h3>Davis Rempe, Tolga Birdal, Yongheng Zhao, Zan Gojcic, Srinath Sridhar, Leonidas J. Guibas</h3>
<p>We propose CaSPR, a method to learn object-centric Canonical Spatiotemporal
Point Cloud Representations of dynamically moving or evolving objects. Our goal
is to enable information aggregation over time and the interrogation of object
state at any spatiotemporal neighborhood in the past, observed or not.
Different from previous work, CaSPR learns representations that support
spacetime continuity, are robust to variable and irregularly spacetime-sampled
point clouds, and generalize to unseen object instances. Our approach divides
the problem into two subtasks. First, we explicitly encode time by mapping an
input point cloud sequence to a spatiotemporally-canonicalized object space. We
then leverage this canonicalization to learn a spatiotemporal latent
representation using neural ordinary differential equations and a generative
model of dynamically evolving shapes using continuous normalizing flows. We
demonstrate the effectiveness of our method on several applications including
shape reconstruction, camera pose estimation, continuous spatiotemporal
sequence reconstruction, and correspondence estimation from irregularly or
intermittently sampled observations.
</p>
<a href="http://arxiv.org/abs/2008.02792" target="_blank">arXiv:2008.02792</a> [<a href="http://arxiv.org/pdf/2008.02792" target="_blank">pdf</a>]

<h2>COVID-19 in differential diagnosis of online symptom assessments. (arXiv:2008.03323v2 [cs.AI] UPDATED)</h2>
<h3>Anitha Kannan, Richard Chen, Vignesh Venkataraman, Geoffrey J. Tso, Xavier Amatriain</h3>
<p>The COVID-19 pandemic has magnified an already existing trend of people
looking for healthcare solutions online. One class of solutions are symptom
checkers, which have become very popular in the context of COVID-19.
Traditional symptom checkers, however, are based on manually curated expert
systems that are inflexible and hard to modify, especially in a quickly
changing situation like the one we are facing today. That is why all COVID-19
existing solutions are manual symptom checkers that can only estimate the
probability of this disease and cannot contemplate alternative hypothesis or
come up with a differential diagnosis. While machine learning offers an
alternative, the lack of reliable data does not make it easy to apply to
COVID-19 either. In this paper we present an approach that combines the
strengths of traditional AI expert systems and novel deep learning models. In
doing so we can leverage prior knowledge as well as any amount of existing data
to quickly derive models that best adapt to the current state of the world and
latest scientific knowledge. We use the approach to train a COVID-19 aware
differential diagnosis model that can be used for medical decision support both
for doctors or patients. We show that our approach is able to accurately model
new incoming data about COVID-19 while still preserving accuracy on conditions
that had been modeled in the past. While our approach shows evident and clear
advantages for an extreme situation like the one we are currently facing, we
also show that its flexibility generalizes beyond this concrete, but very
important, example.
</p>
<a href="http://arxiv.org/abs/2008.03323" target="_blank">arXiv:2008.03323</a> [<a href="http://arxiv.org/pdf/2008.03323" target="_blank">pdf</a>]

<h2>PLACE: Proximity Learning of Articulation and Contact in 3D Environments. (arXiv:2008.05570v4 [cs.CV] UPDATED)</h2>
<h3>Siwei Zhang, Yan Zhang, Qianli Ma, Michael J. Black, Siyu Tang</h3>
<p>High fidelity digital 3D environments have been proposed in recent years,
however, it remains extremely challenging to automatically equip such
environment with realistic human bodies. Existing work utilizes images, depth
or semantic maps to represent the scene, and parametric human models to
represent 3D bodies. While being straightforward, their generated human-scene
interactions are often lack of naturalness and physical plausibility. Our key
observation is that humans interact with the world through body-scene contact.
To synthesize realistic human-scene interactions, it is essential to
effectively represent the physical contact and proximity between the body and
the world. To that end, we propose a novel interaction generation method, named
PLACE (Proximity Learning of Articulation and Contact in 3D Environments),
which explicitly models the proximity between the human body and the 3D scene
around it. Specifically, given a set of basis points on a scene mesh, we
leverage a conditional variational autoencoder to synthesize the minimum
distances from the basis points to the human body surface. The generated
proximal relationship exhibits which region of the scene is in contact with the
person. Furthermore, based on such synthesized proximity, we are able to
effectively obtain expressive 3D human bodies that interact with the 3D scene
naturally. Our perceptual study shows that PLACE significantly improves the
state-of-the-art method, approaching the realism of real human-scene
interaction. We believe our method makes an important step towards the fully
automatic synthesis of realistic 3D human bodies in 3D scenes. The code and
model are available for research at
https://sanweiliti.github.io/PLACE/PLACE.html.
</p>
<a href="http://arxiv.org/abs/2008.05570" target="_blank">arXiv:2008.05570</a> [<a href="http://arxiv.org/pdf/2008.05570" target="_blank">pdf</a>]

<h2>Deep Samplable Observation Model for Global Localization and Kidnapping. (arXiv:2009.00211v2 [cs.RO] UPDATED)</h2>
<h3>Runjian Chen, Yue Wang, Huan Yin, Yanmei Jiao, Gamini Dissanayake, Rong Xiong</h3>
<p>Global localization and kidnapping are two challenging problems in robot
localization. The popular method, Monte Carlo Localization (MCL) addresses the
problem by iteratively updating a set of particles with a "sampling-weighting"
loop. Sampling is decisive to the performance of MCL [1]. However, traditional
MCL can only sample from a uniform distribution over the state space. Although
variants of MCL propose different sampling models, they fail to provide an
accurate distribution or generalize across scenes. To better deal with these
problems, we present a distribution proposal model, named Deep Samplable
Observation Model (DSOM). DSOM takes a map and a 2D laser scan as inputs and
outputs a conditional multimodal probability distribution of the pose, making
the samples more focusing on the regions with higher likelihood. With such
samples, the convergence is expected to be more effective and efficient.
Considering that the learning-based sampling model may fail to capture the true
pose sometimes, we furthermore propose the Adaptive Mixture MCL (AdaM MCL),
which deploys a trusty mechanism to adaptively select updating mode for each
particle to tolerate this situation. Equipped with DSOM, AdaM MCL can achieve
more accurate estimation, faster convergence and better scalability compared to
previous methods in both synthetic and real scenes. Even in real environments
with long-term changing, AdaM MCL is able to localize the robot using DSOM
trained only by simulation observations from a SLAM map or a blueprint map.
</p>
<a href="http://arxiv.org/abs/2009.00211" target="_blank">arXiv:2009.00211</a> [<a href="http://arxiv.org/pdf/2009.00211" target="_blank">pdf</a>]

<h2>A Game Theoretic Analysis of Additive Adversarial Attacks and Defenses. (arXiv:2009.06530v2 [cs.LG] UPDATED)</h2>
<h3>Ambar Pal, Ren&#xe9; Vidal</h3>
<p>Research in adversarial learning follows a cat and mouse game between
attackers and defenders where attacks are proposed, they are mitigated by new
defenses, and subsequently new attacks are proposed that break earlier
defenses, and so on. However, it has remained unclear as to whether there are
conditions under which no better attacks or defenses can be proposed. In this
paper, we propose a game-theoretic framework for studying attacks and defenses
which exist in equilibrium. Under a locally linear decision boundary model for
the underlying binary classifier, we prove that the Fast Gradient Method attack
and the Randomized Smoothing defense form a Nash Equilibrium. We then show how
this equilibrium defense can be approximated given finitely many samples from a
data-generating distribution, and derive a generalization bound for the
performance of our approximation.
</p>
<a href="http://arxiv.org/abs/2009.06530" target="_blank">arXiv:2009.06530</a> [<a href="http://arxiv.org/pdf/2009.06530" target="_blank">pdf</a>]

<h2>Learning a Lie Algebra from Unlabeled Data Pairs. (arXiv:2009.09321v3 [cs.LG] UPDATED)</h2>
<h3>Christopher Ick, Vincent Lostanlen</h3>
<p>Deep convolutional networks (convnets) show a remarkable ability to learn
disentangled representations. In recent years, the generalization of deep
learning to Lie groups beyond rigid motion in $\mathbb{R}^n$ has allowed to
build convnets over datasets with non-trivial symmetries, such as patterns over
the surface of a sphere. However, one limitation of this approach is the need
to explicitly define the Lie group underlying the desired invariance property
before training the convnet. Whereas rotations on the sphere have a well-known
symmetry group ($\mathrm{SO}(3)$), the same cannot be said of many real-world
factors of variability. For example, the disentanglement of pitch, intensity
dynamics, and playing technique remains a challenging task in music information
retrieval.

This article proposes a machine learning method to discover a nonlinear
transformation of the space $\mathbb{R}^n$ which maps a collection of
$n$-dimensional vectors $(\boldsymbol{x}_i)_i$ onto a collection of target
vectors $(\boldsymbol{y}_i)_i$. The key idea is to approximate every target
$\boldsymbol{y}_i$ by a matrix--vector product of the form
$\boldsymbol{\widetilde{y}}_i = \boldsymbol{\phi}(t_i) \boldsymbol{x}_i$, where
the matrix $\boldsymbol{\phi}(t_i)$ belongs to a one-parameter subgroup of
$\mathrm{GL}_n (\mathbb{R})$. Crucially, the value of the parameter $t_i \in
\mathbb{R}$ may change between data pairs $(\boldsymbol{x}_i,
\boldsymbol{y}_i)$ and does not need to be known in advance.
</p>
<a href="http://arxiv.org/abs/2009.09321" target="_blank">arXiv:2009.09321</a> [<a href="http://arxiv.org/pdf/2009.09321" target="_blank">pdf</a>]

<h2>Lip-reading with Densely Connected Temporal Convolutional Networks. (arXiv:2009.14233v2 [cs.CV] UPDATED)</h2>
<h3>Pingchuan Ma, Yujiang Wang, Jie Shen, Stavros Petridis, Maja Pantic</h3>
<p>In this work, we present the Densely Connected Temporal Convolutional Network
(DC-TCN) for lip-reading of isolated words. Although Temporal Convolutional
Networks (TCN) have recently demonstrated great potential in many vision tasks,
its receptive fields are not dense enough to model the complex temporal
dynamics in lip-reading scenarios. To address this problem, we introduce dense
connections into the network to capture more robust temporal features.
Moreover, our approach utilises the Squeeze-and-Excitation block, a
light-weight attention mechanism, to further enhance the model's classification
power. Without bells and whistles, our DC-TCN method has achieved 88.36%
accuracy on the Lip Reading in the Wild (LRW) dataset and 43.65% on the
LRW-1000 dataset, which has surpassed all the baseline methods and is the new
state-of-the-art on both datasets.
</p>
<a href="http://arxiv.org/abs/2009.14233" target="_blank">arXiv:2009.14233</a> [<a href="http://arxiv.org/pdf/2009.14233" target="_blank">pdf</a>]

<h2>Online Knowledge Distillation via Multi-branch Diversity Enhancement. (arXiv:2010.00795v2 [cs.CV] UPDATED)</h2>
<h3>Zheng Li, Ying Huang, Defang Chen, Tianren Luo, Ning Cai, Zhigeng Pan</h3>
<p>Knowledge distillation is an effective method to transfer the knowledge from
the cumbersome teacher model to the lightweight student model. Online knowledge
distillation uses the ensembled prediction results of multiple student models
as soft targets to train each student model. However, the homogenization
problem will lead to difficulty in further improving model performance. In this
work, we propose a new distillation method to enhance the diversity among
multiple student models. We introduce Feature Fusion Module (FFM), which
improves the performance of the attention mechanism in the network by
integrating rich semantic information contained in the last block of multiple
student models. Furthermore, we use the Classifier Diversification(CD) loss
function to strengthen the differences between the student models and deliver a
better ensemble result. Extensive experiments proved that our method
significantly enhances the diversity among student models and brings better
distillation performance. We evaluate our method on three image classification
datasets: CIFAR-10/100 and CINIC-10. The results show that our method achieves
state-of-the-art performance on these datasets.
</p>
<a href="http://arxiv.org/abs/2010.00795" target="_blank">arXiv:2010.00795</a> [<a href="http://arxiv.org/pdf/2010.00795" target="_blank">pdf</a>]

<h2>Interpretable Machine Learning for COVID-19: An Empirical Study on Severity Prediction Task. (arXiv:2010.02006v3 [cs.LG] UPDATED)</h2>
<h3>Han Wu, Wenjie Ruan, Jiangtao Wang, Dingchang Zheng, Shaolin Li, Jian Chen, Kunwei Li, Xiangfei Chai, Sumi Helal</h3>
<p>Black-box nature hinders the deployment of many high-accuracy models in
medical diagnosis. It is risky to put one's life in the hands of models that
medical researchers do not trust. However, to understand the mechanism of a new
virus, such as COVID-19, machine learning models may catch important symptoms
that medical practitioners do not notice due to the surge of infected patients
during a pandemic.

In this work, the interpretation of machine learning models reveals that a
high C-reactive protein (CRP) corresponds to severe infection, and severe
patients usually go through a cardiac injury, which is consistent with
well-established medical knowledge. Additionally, through the interpretation of
machine learning models, we find phlegm and diarrhea are two important
symptoms, without which indicate a high risk of turning severe. These two
symptoms are not recognized at the early stage of the outbreak, whereas our
findings are corroborated by later autopsies of COVID-19 patients. We find
patients with a high N-terminal pro B-type natriuretic peptide (NTproBNP) have
a significantly increased risk of death which does not receive much attention
initially but proves true by the following-up study. Thus, we suggest
interpreting machine learning models can offer help to diagnosis at the early
stage of an outbreak.
</p>
<a href="http://arxiv.org/abs/2010.02006" target="_blank">arXiv:2010.02006</a> [<a href="http://arxiv.org/pdf/2010.02006" target="_blank">pdf</a>]

<h2>Using Social Robots to Teach Language Skills to Immigrant Children in an Oslo City District. (arXiv:2010.05491v2 [cs.RO] UPDATED)</h2>
<h3>Trenton Schulz, Till Halbach, Ivar Solheim</h3>
<p>Social robots have been shown to help in language education for children.
This can be good aid for immigrant children that need additional help to learn
a second language their parents do not understand to attend school. We present
the setup for a long-term study that is being carried out in blinded to aid
immigrant children with poor skills in the Norwegian language to improve their
vocabulary. This includes additional tools to help parents follow along and
provide additional help at home.
</p>
<a href="http://arxiv.org/abs/2010.05491" target="_blank">arXiv:2010.05491</a> [<a href="http://arxiv.org/pdf/2010.05491" target="_blank">pdf</a>]

<h2>Tensor-based Intrinsic Subspace Representation Learning for Multi-view Clustering. (arXiv:2010.09193v6 [cs.LG] UPDATED)</h2>
<h3>Qinghai Zheng, Jihua Zhu, Zhongyu Li, Haoyu Tang, Shuangxun Ma</h3>
<p>As a hot research topic, many multi-view clustering approaches are proposed
over the past few years. Nevertheless, most existing algorithms merely take the
consensus information among different views into consideration for clustering.
Actually, it may hinder the multi-view clustering performance in real-life
applications, since different views usually contain diverse statistic
properties. To address this problem, we propose a novel Tensor-based Intrinsic
Subspace Representation Learning (TISRL) for multi-view clustering in this
paper. Concretely, the rank preserving decomposition is proposed firstly to
effectively deal with the diverse statistic information contained in different
views. Then, to achieve the intrinsic subspace representation, the
tensor-singular value decomposition based low-rank tensor constraint is also
utilized in our method. It can be seen that specific information contained in
different views is fully investigated by the rank preserving decomposition, and
the high-order correlations of multi-view data are also mined by the low-rank
tensor constraint. The objective function can be optimized by an augmented
Lagrangian multiplier based alternating direction minimization algorithm.
Experimental results on nine common used real-world multi-view datasets
illustrate the superiority of TISRL.
</p>
<a href="http://arxiv.org/abs/2010.09193" target="_blank">arXiv:2010.09193</a> [<a href="http://arxiv.org/pdf/2010.09193" target="_blank">pdf</a>]

<h2>MonoComb: A Sparse-to-Dense Combination Approach for Monocular Scene Flow. (arXiv:2010.10842v2 [cs.CV] UPDATED)</h2>
<h3>Ren&#xe9; Schuster, Christian Unger, Didier Stricker</h3>
<p>Contrary to the ongoing trend in automotive applications towards usage of
more diverse and more sensors, this work tries to solve the complex scene flow
problem under a monocular camera setup, i.e. using a single sensor. Towards
this end, we exploit the latest achievements in single image depth estimation,
optical flow, and sparse-to-dense interpolation and propose a monocular
combination approach (MonoComb) to compute dense scene flow. MonoComb uses
optical flow to relate reconstructed 3D positions over time and interpolates
occluded areas. This way, existing monocular methods are outperformed in
dynamic foreground regions which leads to the second best result among the
competitors on the challenging KITTI 2015 scene flow benchmark.
</p>
<a href="http://arxiv.org/abs/2010.10842" target="_blank">arXiv:2010.10842</a> [<a href="http://arxiv.org/pdf/2010.10842" target="_blank">pdf</a>]

<h2>Neural Star Domain as Primitive Representation. (arXiv:2010.11248v2 [cs.CV] UPDATED)</h2>
<h3>Yuki Kawana, Yusuke Mukuta, Tatsuya Harada</h3>
<p>Reconstructing 3D objects from 2D images is a fundamental task in computer
vision. Accurate structured reconstruction by parsimonious and semantic
primitive representation further broadens its application. When reconstructing
a target shape with multiple primitives, it is preferable that one can
instantly access the union of basic properties of the shape such as collective
volume and surface, treating the primitives as if they are one single shape.
This becomes possible by primitive representation with unified implicit and
explicit representations. However, primitive representations in current
approaches do not satisfy all of the above requirements at the same time. To
solve this problem, we propose a novel primitive representation named neural
star domain (NSD) that learns primitive shapes in the star domain. We show that
NSD is a universal approximator of the star domain and is not only parsimonious
and semantic but also an implicit and explicit shape representation. We
demonstrate that our approach outperforms existing methods in image
reconstruction tasks, semantic capabilities, and speed and quality of sampling
high-resolution meshes.
</p>
<a href="http://arxiv.org/abs/2010.11248" target="_blank">arXiv:2010.11248</a> [<a href="http://arxiv.org/pdf/2010.11248" target="_blank">pdf</a>]

<h2>Algorithms for Causal Reasoning in Probability Trees. (arXiv:2010.12237v2 [cs.AI] UPDATED)</h2>
<h3>Tim Genewein, Tom McGrath, Gr&#xe9;goire D&#xe9;letang, Vladimir Mikulik, Miljan Martic, Shane Legg, Pedro A. Ortega</h3>
<p>Probability trees are one of the simplest models of causal generative
processes. They possess clean semantics and -- unlike causal Bayesian networks
-- they can represent context-specific causal dependencies, which are necessary
for e.g. causal induction. Yet, they have received little attention from the AI
and ML community. Here we present concrete algorithms for causal reasoning in
discrete probability trees that cover the entire causal hierarchy (association,
intervention, and counterfactuals), and operate on arbitrary propositional and
causal events. Our work expands the domain of causal reasoning to a very
general class of discrete stochastic processes.
</p>
<a href="http://arxiv.org/abs/2010.12237" target="_blank">arXiv:2010.12237</a> [<a href="http://arxiv.org/pdf/2010.12237" target="_blank">pdf</a>]

<h2>Tele-operative Robotic Lung Ultrasound Scanning Platform for Triage of COVID-19 Patients. (arXiv:2010.12335v3 [cs.RO] UPDATED)</h2>
<h3>Ryosuke Tsumura, John W. Hardin, Keshav Bimbraw, Olushola S. Odusanya, Yihao Zheng, Jeffrey C. Hill, Beatrice Hoffmann, Winston Soboyejo, Haichong K. Zhang</h3>
<p>Novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has become
a pandemic of epic proportions and a global response to prepare health systems
worldwide is of utmost importance. In addition to its cost-effectiveness in a
resources-limited setting, lung ultrasound (LUS) has emerged as a rapid
noninvasive imaging tool for the diagnosis of COVID-19 infected patients.
Concerns surrounding LUS include the disparity of infected patients and
healthcare providers, relatively small number of physicians and sonographers
capable of performing LUS, and most importantly, the requirement for
substantial physical contact between the patient and operator, increasing the
risk of transmission. Mitigation of the spread of the virus is of paramount
importance. A 2-dimensional (2D) tele-operative robotic platform capable of
performing LUS in for COVID-19 infected patients may be of significant benefit.
The authors address the aforementioned issues surrounding the use of LUS in the
application of COVID- 19 infected patients. In addition, first time
application, feasibility and safety were validated in three healthy subjects,
along with 2D image optimization and comparison for overall accuracy.
Preliminary results demonstrate that the proposed platform allows for
successful acquisition and application of LUS in humans.
</p>
<a href="http://arxiv.org/abs/2010.12335" target="_blank">arXiv:2010.12335</a> [<a href="http://arxiv.org/pdf/2010.12335" target="_blank">pdf</a>]

<h2>Malicious Requests Detection with Improved Bidirectional Long Short-term Memory Neural Networks. (arXiv:2010.13285v4 [cs.LG] UPDATED)</h2>
<h3>Wenhao Li, Bincheng Zhang, Jiajie Zhang</h3>
<p>Detecting and intercepting malicious requests are one of the most widely used
ways against attacks in the network security. Most existing detecting
approaches, including matching blacklist characters and machine learning
algorithms have all shown to be vulnerable to sophisticated attacks. To address
the above issues, a more general and rigorous detection method is required. In
this paper, we formulate the problem of detecting malicious requests as a
temporal sequence classification problem, and propose a novel deep learning
model namely Convolutional Neural Network-Bidirectional Long Short-term
Memory-Convolutional Neural Network (CNN-BiLSTM-CNN). By connecting the shadow
and deep feature maps of the convolutional layers, the malicious feature
extracting ability is improved on more detailed functionality. Experimental
results on HTTP dataset CSIC 2010 have demonstrated the effectiveness of the
proposed method when compared with the state-of-the-arts.
</p>
<a href="http://arxiv.org/abs/2010.13285" target="_blank">arXiv:2010.13285</a> [<a href="http://arxiv.org/pdf/2010.13285" target="_blank">pdf</a>]

<h2>Scalable Gaussian Process Variational Autoencoders. (arXiv:2010.13472v2 [stat.ML] UPDATED)</h2>
<h3>Metod Jazbec, Vincent Fortuin, Michael Pearce, Stephan Mandt, Gunnar R&#xe4;tsch</h3>
<p>Conventional variational autoencoders fail in modeling correlations between
data points due to their use of factorized priors. Amortized Gaussian process
inference through GP-VAEs has led to significant improvements in this regard,
but is still inhibited by the intrinsic complexity of exact GP inference. We
improve the scalability of these methods through principled sparse inference
approaches. We propose a new scalable GP-VAE model that outperforms existing
approaches in terms of runtime and memory footprint, is easy to implement, and
allows for joint end-to-end optimization of all components.
</p>
<a href="http://arxiv.org/abs/2010.13472" target="_blank">arXiv:2010.13472</a> [<a href="http://arxiv.org/pdf/2010.13472" target="_blank">pdf</a>]

<h2>Unsupervised Domain Adaptation for Visual Navigation. (arXiv:2010.14543v2 [cs.LG] UPDATED)</h2>
<h3>Shangda Li, Devendra Singh Chaplot, Yao-Hung Hubert Tsai, Yue Wu, Louis-Philippe Morency, Ruslan Salakhutdinov</h3>
<p>Advances in visual navigation methods have led to intelligent embodied
navigation agents capable of learning meaningful representations from raw RGB
images and perform a wide variety of tasks involving structural and semantic
reasoning. However, most learning-based navigation policies are trained and
tested in simulation environments. In order for these policies to be
practically useful, they need to be transferred to the real-world. In this
paper, we propose an unsupervised domain adaptation method for visual
navigation. Our method translates the images in the target domain to the source
domain such that the translation is consistent with the representations learned
by the navigation policy. The proposed method outperforms several baselines
across two different navigation tasks in simulation. We further show that our
method can be used to transfer the navigation policies learned in simulation to
the real world.
</p>
<a href="http://arxiv.org/abs/2010.14543" target="_blank">arXiv:2010.14543</a> [<a href="http://arxiv.org/pdf/2010.14543" target="_blank">pdf</a>]

<h2>Probabilistic Transformers. (arXiv:2010.15583v3 [cs.LG] UPDATED)</h2>
<h3>Javier R. Movellan</h3>
<p>We show that Transformers are Maximum Posterior Probability estimators for
Mixtures of Gaussian Models. This brings a probabilistic point of view to
Transformers and suggests extensions to other probabilistic cases.
</p>
<a href="http://arxiv.org/abs/2010.15583" target="_blank">arXiv:2010.15583</a> [<a href="http://arxiv.org/pdf/2010.15583" target="_blank">pdf</a>]

<h2>No more 996: Understanding Deep Learning Inference Serving with an Automatic Benchmarking System. (arXiv:2011.02327v2 [cs.LG] UPDATED)</h2>
<h3>Huaizheng Zhang, Yizheng Huang, Yonggang Wen, Jianxiong Yin, Kyle Guan</h3>
<p>Deep learning (DL) models have become core modules for many applications.
However, deploying these models without careful performance benchmarking that
considers both hardware and software's impact often leads to poor service and
costly operational expenditure. To facilitate DL models' deployment, we
implement an automatic and comprehensive benchmark system for DL developers. To
accomplish benchmark-related tasks, the developers only need to prepare a
configuration file consisting of a few lines of code. Our system, deployed to a
leader server in DL clusters, will dispatch users' benchmark jobs to follower
workers. Next, the corresponding requests, workload, and even models can be
generated automatically by the system to conduct DL serving benchmarks.
Finally, developers can leverage many analysis tools and models in our system
to gain insights into the trade-offs of different system configurations. In
addition, a two-tier scheduler is incorporated to avoid unnecessary
interference and improve average job compilation time by up to 1.43x
(equivalent of 30\% reduction). Our system design follows the best practice in
DL clusters operations to expedite day-to-day DL service evaluation efforts by
the developers. We conduct many benchmark experiments to provide in-depth and
comprehensive evaluations. We believe these results are of great values as
guidelines for DL service configuration and resource allocation.
</p>
<a href="http://arxiv.org/abs/2011.02327" target="_blank">arXiv:2011.02327</a> [<a href="http://arxiv.org/pdf/2011.02327" target="_blank">pdf</a>]

<h2>Monitoring the Impact of Wildfires on Tree Species with Deep Learning. (arXiv:2011.02514v2 [cs.CV] UPDATED)</h2>
<h3>Wang Zhou, Levente Klein</h3>
<p>One of the impacts of climate change is the difficulty of tree regrowth after
wildfires over areas that traditionally were covered by certain tree species.
Here a deep learning model is customized to classify land covers from four-band
aerial imagery before and after wildfires to study the prolonged consequences
of wildfires on tree species. The tree species labels are generated from
manually delineated maps for five land cover classes: Conifer, Hardwood, Shrub,
ReforestedTree and Barren land. With an accuracy of $92\%$ on the test split,
the model is applied to three wildfires on data from 2009 to 2018. The model
accurately delineates areas damaged by wildfires, changes in tree species and
rebound of burned areas. The result shows clear evidence of wildfires impacting
the local ecosystem and the outlined approach can help monitor reforested
areas, observe changes in forest composition and track wildfire impact on tree
species.
</p>
<a href="http://arxiv.org/abs/2011.02514" target="_blank">arXiv:2011.02514</a> [<a href="http://arxiv.org/pdf/2011.02514" target="_blank">pdf</a>]

<h2>Detecting Human-Object Interaction with Mixed Supervision. (arXiv:2011.04971v2 [cs.CV] UPDATED)</h2>
<h3>Suresh Kirthi Kumaraswamy (1), Miaojing Shi (2), Ewa Kijak (3) ((1) Univ Le Mans, CNRS, IRISA, (2) Kings College London, (3) Univ Rennes, Inria, CNRS, IRISA)</h3>
<p>Human object interaction (HOI) detection is an important task in image
understanding and reasoning. It is in a form of HOI triplet &lt;human; verb;
object&gt;, requiring bounding boxes for human and object, and action between them
for the task completion. In other words, this task requires strong supervision
for training that is however hard to procure. A natural solution to overcome
this is to pursue weakly-supervised learning, where we only know the presence
of certain HOI triplets in images but their exact location is unknown. Most
weakly-supervised learning methods do not make provision for leveraging data
with strong supervision, when they are available; and indeed a na\"ive
combination of this two paradigms in HOI detection fails to make contributions
to each other. In this regard we propose a mixed-supervised HOI detection
pipeline: thanks to a specific design of momentum-independent learning that
learns seamlessly across these two types of supervision. Moreover, in light of
the annotation insufficiency in mixed supervision, we introduce an HOI element
swapping technique to synthesize diverse and hard negatives across images and
improve the robustness of the model. Our method is evaluated on the challenging
HICO-DET dataset. It performs close to or even better than many
fully-supervised methods by using a mixed amount of strong and weak
annotations; furthermore, it outperforms representative state of the art weakly
and fully-supervised methods under the same supervision.
</p>
<a href="http://arxiv.org/abs/2011.04971" target="_blank">arXiv:2011.04971</a> [<a href="http://arxiv.org/pdf/2011.04971" target="_blank">pdf</a>]

<h2>Sparse within Sparse Gaussian Processes using Neighbor Information. (arXiv:2011.05041v2 [stat.ML] UPDATED)</h2>
<h3>Gia-Lac Tran, Dimitrios Milios, Pietro Michiardi, Maurizio Filippone</h3>
<p>Approximations to Gaussian processes based on inducing variables, combined
with variational inference techniques, enable state-of-the-art sparse
approaches to infer GPs at scale through mini batch-based learning. In this
work, we address one limitation of sparse GPs, which is due to the challenge in
dealing with a large number of inducing variables without imposing a special
structure on the inducing inputs. In particular, we introduce a novel
hierarchical prior, which imposes sparsity on the set of inducing variables. We
treat our model variationally, and we experimentally show considerable
computational gains compared to standard sparse GPs when sparsity on the
inducing variables is realized considering the nearest inducing inputs of a
random mini-batch of the data. We perform an extensive experimental validation
that demonstrates the effectiveness of our approach compared to the
state-of-the-art. Our approach enables the possibility to use sparse GPs using
a large number of inducing points without incurring a prohibitive computational
cost.
</p>
<a href="http://arxiv.org/abs/2011.05041" target="_blank">arXiv:2011.05041</a> [<a href="http://arxiv.org/pdf/2011.05041" target="_blank">pdf</a>]

<h2>Decoupled Appearance and Motion Learning for Efficient Anomaly Detection in Surveillance Video. (arXiv:2011.05054v2 [cs.CV] UPDATED)</h2>
<h3>Bo Li, Sam Leroux, Pieter Simoens</h3>
<p>Automating the analysis of surveillance video footage is of great interest
when urban environments or industrial sites are monitored by a large number of
cameras. As anomalies are often context-specific, it is hard to predefine
events of interest and collect labelled training data. A purely unsupervised
approach for automated anomaly detection is much more suitable. For every
camera, a separate algorithm could then be deployed that learns over time a
baseline model of appearance and motion related features of the objects within
the camera viewport. Anything that deviates from this baseline is flagged as an
anomaly for further analysis downstream. We propose a new neural network
architecture that learns the normal behavior in a purely unsupervised fashion.
In contrast to previous work, we use latent code predictions as our anomaly
metric. We show that this outperforms reconstruction-based and frame
prediction-based methods on different benchmark datasets both in terms of
accuracy and robustness against changing lighting and weather conditions. By
decoupling an appearance and a motion model, our model can also process 16 to
45 times more frames per second than related approaches which makes our model
suitable for deploying on the camera itself or on other edge devices.
</p>
<a href="http://arxiv.org/abs/2011.05054" target="_blank">arXiv:2011.05054</a> [<a href="http://arxiv.org/pdf/2011.05054" target="_blank">pdf</a>]

<h2>Two-stage Training of Graph Neural Networks for Graph Classification. (arXiv:2011.05097v2 [cs.LG] UPDATED)</h2>
<h3>Manh Tuan Do, Noseong Park, Kijung Shin</h3>
<p>Graph Neural Networks (GNNs) have received massive attention in the field of
machine learning on graphs. Inspired by the success of neural networks, a line
of research has been conducted to train GNNs to deal with various tasks, such
as node classification, graph classification, and link prediction. In this
work, our task of interest is graph classification. Several GNN models have
been proposed and shown great accuracy in this task. However, the question is
whether usual training methods fully realizes the power of the GNN models.

In this work, we propose a two-stage training framework based on triplet
loss. In the first stage, GNN is trained to map each graph to a Euclidean-space
vector so that graphs of the same class are close while those of different
classes are mapped far apart. Once graphs are well-separated based on labels, a
classifier can be trained to distinguish between different classes. This method
is generic in the sense that it is compatible with any GNN model. By adapting
five GNN models to our method, we demonstrate the consistent improvement in
accuracy over the original training method of each model up to 5.4% points in
12 datasets.
</p>
<a href="http://arxiv.org/abs/2011.05097" target="_blank">arXiv:2011.05097</a> [<a href="http://arxiv.org/pdf/2011.05097" target="_blank">pdf</a>]

<h2>Self-supervised Graph Representation Learning via Bootstrapping. (arXiv:2011.05126v2 [cs.LG] UPDATED)</h2>
<h3>Feihu Che, Guohua Yang, Dawei Zhang, Jianhua Tao, Pengpeng Shao, Tong Liu</h3>
<p>Graph neural networks~(GNNs) apply deep learning techniques to
graph-structured data and have achieved promising performance in graph
representation learning. However, existing GNNs rely heavily on enough labels
or well-designed negative samples. To address these issues, we propose a new
self-supervised graph representation method: deep graph bootstrapping~(DGB).
DGB consists of two neural networks: online and target networks, and the input
of them are different augmented views of the initial graph. The online network
is trained to predict the target network while the target network is updated
with a slow-moving average of the online network, which means the online and
target networks can learn from each other. As a result, the proposed DGB can
learn graph representation without negative examples in an unsupervised manner.
In addition, we summarize three kinds of augmentation methods for
graph-structured data and apply them to the DGB. Experiments on the benchmark
datasets show the DGB performs better than the current state-of-the-art methods
and how the augmentation methods affect the performances.
</p>
<a href="http://arxiv.org/abs/2011.05126" target="_blank">arXiv:2011.05126</a> [<a href="http://arxiv.org/pdf/2011.05126" target="_blank">pdf</a>]

<h2>Relation-weighted Link Prediction for Disease Gene Identification. (arXiv:2011.05138v2 [cs.LG] UPDATED)</h2>
<h3>Srivamshi Pittala, William Koehler, Jonathan Deans, Daniel Salinas, Martin Bringmann, Katharina Sophia Volz, Berk Kapicioglu</h3>
<p>Identification of disease genes, which are a set of genes associated with a
disease, plays an important role in understanding and curing diseases. In this
paper, we present a biomedical knowledge graph designed specifically for this
problem, propose a novel machine learning method that identifies disease genes
on such graphs by leveraging recent advances in network biology and graph
representation learning, study the effects of various relation types on
prediction performance, and empirically demonstrate that our algorithms
outperform its closest state-of-the-art competitor in disease gene
identification by 24.1%. We also show that we achieve higher precision than
Open Targets, the leading initiative for target identification, with respect to
predicting drug targets in clinical trials for Parkinson's disease.
</p>
<a href="http://arxiv.org/abs/2011.05138" target="_blank">arXiv:2011.05138</a> [<a href="http://arxiv.org/pdf/2011.05138" target="_blank">pdf</a>]

<h2>Biomedical Information Extraction for Disease Gene Prioritization. (arXiv:2011.05188v2 [cs.LG] UPDATED)</h2>
<h3>Jupinder Parmar, William Koehler, Martin Bringmann, Katharina Sophia Volz, Berk Kapicioglu</h3>
<p>We introduce a biomedical information extraction (IE) pipeline that extracts
biological relationships from text and demonstrate that its components, such as
named entity recognition (NER) and relation extraction (RE), outperform
state-of-the-art in BioNLP. We apply it to tens of millions of PubMed abstracts
to extract protein-protein interactions (PPIs) and augment these extractions to
a biomedical knowledge graph that already contains PPIs extracted from STRING,
the leading structured PPI database. We show that, despite already containing
PPIs from an established structured source, augmenting our own IE-based
extractions to the graph allows us to predict novel disease-gene associations
with a 20% relative increase in hit@30, an important step towards developing
drug targets for uncured diseases.
</p>
<a href="http://arxiv.org/abs/2011.05188" target="_blank">arXiv:2011.05188</a> [<a href="http://arxiv.org/pdf/2011.05188" target="_blank">pdf</a>]

<h2>ATCN: Agile Temporal Convolutional Networks for Processing of Time Series on Edge. (arXiv:2011.05260v2 [cs.LG] UPDATED)</h2>
<h3>Mohammadreza Baharani, Steven Furgurson, Babak Parkhideh, Hamed Tabkhi</h3>
<p>This paper presents a scalable deep learning model called Agile Temporal
Convolutional Network (ATCN) for high-accurate fast classification and time
series prediction in resource-constrained embedded systems. ATCN is primarily
designed for mobile embedded systems with performance and memory constraints
such as wearable biomedical devices and real-time reliability monitoring
systems. It makes fundamental improvements over the mainstream temporal
convolutional neural networks, including the incorporation of separable
depth-wise convolution to reduce the computational complexity of the model and
residual connections as time attention machines, increase the network depth and
accuracy. The result of this configurability makes the ATCN a family of compact
networks with formalized hyper-parameters that allow the model architecture to
be configurable and adjusted based on the application requirements. We
demonstrate the capabilities of our proposed ATCN on accuracy and performance
trade-off on three embedded applications, including transistor reliability
monitoring, heartbeat classification of ECG signals, and digit classification.
Our comparison results against state-of-the-art approaches demonstrate much
lower computation and memory demand for faster processing with better
prediction and classification accuracy. The source code of the ATCN model is
publicly available at https://github.com/TeCSAR-UNCC/ATCN.
</p>
<a href="http://arxiv.org/abs/2011.05260" target="_blank">arXiv:2011.05260</a> [<a href="http://arxiv.org/pdf/2011.05260" target="_blank">pdf</a>]

<h2>Scribble-Supervised Semantic Segmentation by Random Walk on Neural Representation and Self-Supervision on Neural Eigenspace. (arXiv:2011.05621v2 [cs.CV] UPDATED)</h2>
<h3>Zhiyi Pan, Peng Jiang, Changhe Tu</h3>
<p>Scribble-supervised semantic segmentation has gained much attention recently
for its promising performance without high-quality annotations. Many approaches
have been proposed. Typically, they handle this problem to either introduce a
well-labeled dataset from another related task, turn to iterative refinement
and post-processing with the graphical model, or manipulate the scribble label.
This work aims to achieve semantic segmentation supervised by scribble label
directly without auxiliary information and other intermediate manipulation.
Specifically, we impose diffusion on neural representation by random walk and
consistency on neural eigenspace by self-supervision, which forces the neural
network to produce dense and consistent predictions over the whole dataset. The
random walk embedded in the network will compute a probabilistic transition
matrix, with which the neural representation diffused to be uniform. Moreover,
given the probabilistic transition matrix, we apply the self-supervision on its
eigenspace for consistency in the image's main parts. In addition to comparing
the common scribble dataset, we also conduct experiments on the modified
datasets that randomly shrink and even drop the scribbles on image objects. The
results demonstrate the superiority of the proposed method and are even
comparable to some full-label supervised ones. The code and datasets are
available at https://github.com/panzhiyi/RW-SS.
</p>
<a href="http://arxiv.org/abs/2011.05621" target="_blank">arXiv:2011.05621</a> [<a href="http://arxiv.org/pdf/2011.05621" target="_blank">pdf</a>]

<h2>Exploratory Grasping: Asymptotically Optimal Algorithms for Grasping Challenging Polyhedral Objects. (arXiv:2011.05632v2 [cs.RO] UPDATED)</h2>
<h3>Michael Danielczuk, Ashwin Balakrishna, Daniel S. Brown, Shivin Devgon, Ken Goldberg</h3>
<p>There has been significant recent work on data-driven algorithms for learning
general-purpose grasping policies. However, these policies can consistently
fail to grasp challenging objects which are significantly out of the
distribution of objects in the training data or which have very few high
quality grasps. Motivated by such objects, we propose a novel problem setting,
Exploratory Grasping, for efficiently discovering reliable grasps on an unknown
polyhedral object via sequential grasping, releasing, and toppling. We
formalize Exploratory Grasping as a Markov Decision Process, study the
theoretical complexity of Exploratory Grasping in the context of reinforcement
learning and present an efficient bandit-style algorithm, Bandits for Online
Rapid Grasp Exploration Strategy (BORGES), which leverages the structure of the
problem to efficiently discover high performing grasps for each object stable
pose. BORGES can be used to complement any general-purpose grasping algorithm
with any grasp modality (parallel-jaw, suction, multi-fingered, etc) to learn
policies for objects in which they exhibit persistent failures. Simulation
experiments suggest that BORGES can significantly outperform both
general-purpose grasping pipelines and two other online learning algorithms and
achieves performance within 5% of the optimal policy within 1000 and 8000
timesteps on average across 46 challenging objects from the Dex-Net adversarial
and EGAD! object datasets, respectively. Initial physical experiments suggest
that BORGES can improve grasp success rate by 45% over a Dex-Net baseline with
just 200 grasp attempts in the real world. See https://tinyurl.com/exp-grasping
for supplementary material and videos.
</p>
<a href="http://arxiv.org/abs/2011.05632" target="_blank">arXiv:2011.05632</a> [<a href="http://arxiv.org/pdf/2011.05632" target="_blank">pdf</a>]

