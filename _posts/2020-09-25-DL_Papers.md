---
title: Latest Deep Learning Papers
date: 2020-10-20 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Remarks on multivariate Gaussian Process. (arXiv:2010.09830v1 [math.ST])</h2>
<h3>Zexun Chen, Jun Fan, Kuo Wang</h3>
<p>Gaussian process occupies one of the leading places in modern Statistics and
Probability due to its importance and wealth of results. The common use of GP
is to connect with problems related to estimation, detection, and even many
statistical or machine learning models. With the fast development of Gaussian
process applications, it is necessary to consolidate the fundamentals of
vector-valued stochastic process, in particular, multivariate Gaussian process,
which is the essential theory for many application problems with multiple
correlated responses. In this paper, we proposed a proper definition of
multivariate Gaussian process based on Gaussian measure on vector-valued
function space and provided its proof of existence. In addition, several
fundamental properties of multivariate Gaussian process such as strict
stationarity and independence are introduced. We further derived multivariate
pre-Brownian motion as a special case of multivariate Gaussian process and
presented a brief introduction of multivariate Gaussian process regression as a
useful statistical learning method for multi-output prediction problems.
</p>
<a href="http://arxiv.org/abs/2010.09830" target="_blank">arXiv:2010.09830</a> [<a href="http://arxiv.org/pdf/2010.09830" target="_blank">pdf</a>]

<h2>On the Sample Complexity of Privately Learning Unbounded High-Dimensional Gaussians. (arXiv:2010.09929v1 [stat.ML])</h2>
<h3>Ishaq Aden-Ali, Hassan Ashtiani, Gautam Kamath</h3>
<p>We provide sample complexity upper bounds for agnostically learning
multivariate Gaussians under the constraint of approximate differential
privacy. These are the first finite sample upper bounds for general Gaussians
which do not impose restrictions on the parameters of the distribution. Our
bounds are near-optimal in the case when the covariance is known to be the
identity, and conjectured to be near-optimal in the general case. From a
technical standpoint, we provide analytic tools for arguing the existence of
global "locally small" covers from local covers of the space. These are
exploited using modifications of recent techniques for differentially private
hypothesis selection. Our techniques may prove useful for privately learning
other distribution classes which do not possess a finite cover.
</p>
<a href="http://arxiv.org/abs/2010.09929" target="_blank">arXiv:2010.09929</a> [<a href="http://arxiv.org/pdf/2010.09929" target="_blank">pdf</a>]

<h2>Robust Asynchronous and Network-Independent Cooperative Learning. (arXiv:2010.09993v1 [math.OC])</h2>
<h3>Eduardo Mojica-Nava, David Yanguas-Rojas, C&#xe9;sar A. Uribe</h3>
<p>We consider the model of cooperative learning via distributed non-Bayesian
learning, where a network of agents tries to jointly agree on a hypothesis that
best described a sequence of locally available observations. Building upon
recently proposed weak communication network models, we propose a robust
cooperative learning rule that allows asynchronous communications, message
delays, unpredictable message losses, and directed communication among nodes.
We show that our proposed learning dynamics guarantee that all agents in the
network will have an asymptotic exponential decay of their beliefs on the wrong
hypothesis, indicating that the beliefs of all agents will concentrate on the
optimal hypotheses. Numerical experiments provide evidence on a number of
network setups.
</p>
<a href="http://arxiv.org/abs/2010.09993" target="_blank">arXiv:2010.09993</a> [<a href="http://arxiv.org/pdf/2010.09993" target="_blank">pdf</a>]

<h2>Blind Federated Edge Learning. (arXiv:2010.10030v1 [cs.IT])</h2>
<h3>Mohammad Mohammadi Amiri, Tolga M. Duman, Deniz Gunduz, Sanjeev R. Kulkarni, H. Vincent Poor</h3>
<p>We study federated edge learning (FEEL), where wireless edge devices, each
with its own dataset, learn a global model collaboratively with the help of a
wireless access point acting as the parameter server (PS). At each iteration,
wireless devices perform local updates using their local data and the most
recent global model received from the PS, and send their local updates to the
PS over a wireless fading multiple access channel (MAC). The PS then updates
the global model according to the signal received over the wireless MAC, and
shares it with the devices. Motivated by the additive nature of the wireless
MAC, we propose an analog `over-the-air' aggregation scheme, in which the
devices transmit their local updates in an uncoded fashion. Unlike recent
literature on over-the-air edge learning, here we assume that the devices do
not have channel state information (CSI), while the PS has imperfect CSI.
Instead, the PS is equipped multiple antennas to alleviate the destructive
effect of the channel, exacerbated due to the lack of perfect CSI. We design a
receive beamforming scheme at the PS, and show that it can compensate for the
lack of perfect CSI when the PS has a sufficient number of antennas. We also
derive the convergence rate of the proposed algorithm highlighting the impact
of the lack of perfect CSI, as well as the number of PS antennas. Both the
experimental results and the convergence analysis illustrate the performance
improvement of the proposed algorithm with the number of PS antennas, where the
wireless fading MAC becomes deterministic despite the lack of perfect CSI when
the PS has a sufficiently large number of antennas.
</p>
<a href="http://arxiv.org/abs/2010.10030" target="_blank">arXiv:2010.10030</a> [<a href="http://arxiv.org/pdf/2010.10030" target="_blank">pdf</a>]

<h2>Fourier restriction for smooth hyperbolic 2-surfaces. (arXiv:2010.10449v1 [math.CA])</h2>
<h3>Stefan Buschenhenke, Detlef M&#xfc;ller, Ana Vargas</h3>
<p>We prove Fourier restriction estimates by means of the polynomial
partitioning method for compact subsets of any sufficiently smooth hyperbolic
hypersurface in threedimensional euclidean space. Our approach exploits in a
crucial way the underlying hyperbolic geometry, which leads to a novel notion
of strong transversality and corresponding "exceptional" sets. For the division
of these exceptional sets we make crucial and perhaps surprising use of a lemma
on level sets for sufficiently smooth one-variate functions from a previous
article of ours.
</p>
<a href="http://arxiv.org/abs/2010.10449" target="_blank">arXiv:2010.10449</a> [<a href="http://arxiv.org/pdf/2010.10449" target="_blank">pdf</a>]

<h2>Dual Averaging is Surprisingly Effective for Deep Learning Optimization. (arXiv:2010.10502v1 [cs.LG])</h2>
<h3>Samy Jelassi, Aaron Defazio</h3>
<p>First-order stochastic optimization methods are currently the most widely
used class of methods for training deep neural networks. However, the choice of
the optimizer has become an ad-hoc rule that can significantly affect the
performance. For instance, SGD with momentum (SGD+M) is typically used in
computer vision (CV) and Adam is used for training transformer models for
Natural Language Processing (NLP). Using the wrong method can lead to
significant performance degradation. Inspired by the dual averaging algorithm,
we propose Modernized Dual Averaging (MDA), an optimizer that is able to
perform as well as SGD+M in CV and as Adam in NLP. Our method is not adaptive
and is significantly simpler than Adam. We show that MDA induces a decaying
uncentered $L_2$-regularization compared to vanilla SGD+M and hypothesize that
this may explain why it works on NLP problems where SGD+M fails.
</p>
<a href="http://arxiv.org/abs/2010.10502" target="_blank">arXiv:2010.10502</a> [<a href="http://arxiv.org/pdf/2010.10502" target="_blank">pdf</a>]

<h2>Learning Whenever Learning is Possible: Universal Learning under General Stochastic Processes. (arXiv:1706.01418v2 [stat.ML] UPDATED)</h2>
<h3>Steve Hanneke</h3>
<p>This work initiates a general study of learning and generalization without
the i.i.d. assumption, starting from first principles. While the traditional
approach to statistical learning theory typically relies on standard
assumptions from probability theory (e.g., i.i.d. or stationary ergodic), in
this work we are interested in developing a theory of learning based only on
the most fundamental and necessary assumptions implicit in the requirements of
the learning problem itself. We specifically study universally consistent
function learning, where the objective is to obtain low long-run average loss
for any target function, when the data follow a given stochastic process. We
are then interested in the question of whether there exist learning rules
guaranteed to be universally consistent given only the assumption that
universally consistent learning is possible for the given data process. The
reasoning that motivates this criterion emanates from a kind of optimist's
decision theory, and so we refer to such learning rules as being optimistically
universal. We study this question in three natural learning settings:
inductive, self-adaptive, and online. Remarkably, as our strongest positive
result, we find that optimistically universal learning rules do indeed exist in
the self-adaptive learning setting. Establishing this fact requires us to
develop new approaches to the design of learning algorithms. Along the way, we
also identify concise characterizations of the family of processes under which
universally consistent learning is possible in the inductive and self-adaptive
settings. We additionally pose a number of enticing open problems, particularly
for the online learning setting.
</p>
<a href="http://arxiv.org/abs/1706.01418" target="_blank">arXiv:1706.01418</a> [<a href="http://arxiv.org/pdf/1706.01418" target="_blank">pdf</a>]

<h2>Robust and Adaptive Sequential Submodular Optimization. (arXiv:1909.11783v2 [math.OC] UPDATED)</h2>
<h3>Vasileios Tzoumas, Ali Jadbabaie, George J. Pappas</h3>
<p>Emerging applications of control, estimation, and machine learning, ranging
from target tracking to decentralized model fitting, pose resource constraints
that limit which of the available sensors, actuators, or data can be
simultaneously used across time. Therefore, many researchers have proposed
solutions within discrete optimization frameworks where the optimization is
performed over finite sets. By exploiting notions of discrete convexity, such
as submodularity, the researchers have been able to provide scalable algorithms
with provable suboptimality bounds. In this paper, we consider such problems
but in adversarial environments, where in every step a number of the chosen
elements in the optimization is removed due to failures/attacks. Specifically,
we consider for the first time a sequential version of the problem that allows
us to observe the failures and adapt, while the attacker also adapts to our
response. We call the novel problem Robust Sequential submodular Maximization
(RSM). Generally, the problem is computationally hard and no scalable algorithm
is known for its solution. However, in this paper we propose Robust and
Adaptive Maximization (RAM), the first scalable algorithm. RAM runs in an
online fashion, adapting in every step to the history of failures. Also, it
guarantees a near-optimal performance, even against any number of failures
among the used elements. Particularly, RAM has both provable per-instance a
priori bounds and tight and/or optimal a posteriori bounds. Finally, we
demonstrate RAM's near-optimality in simulations across various application
scenarios, along with its robustness against several failure types, from
worst-case to random.
</p>
<a href="http://arxiv.org/abs/1909.11783" target="_blank">arXiv:1909.11783</a> [<a href="http://arxiv.org/pdf/1909.11783" target="_blank">pdf</a>]

<h2>A Decentralized Parallel Algorithm for Training Generative Adversarial Nets. (arXiv:1910.12999v6 [math.OC] UPDATED)</h2>
<h3>Mingrui Liu, Wei Zhang, Youssef Mroueh, Xiaodong Cui, Jerret Ross, Tianbao Yang, Payel Das</h3>
<p>Generative Adversarial Networks (GANs) are a powerful class of generative
models in the deep learning community. Current practice on large-scale GAN
training utilizes large models and distributed large-batch training strategies,
and is implemented on deep learning frameworks (e.g., TensorFlow, PyTorch,
etc.) designed in a centralized manner. In the centralized network topology,
every worker needs to either directly communicate with the central node or
indirectly communicate with all other workers in every iteration. However, when
the network bandwidth is low or network latency is high, the performance would
be significantly degraded. Despite recent progress on decentralized algorithms
for training deep neural networks, it remains unclear whether it is possible to
train GANs in a decentralized manner. The main difficulty lies at handling the
nonconvex-nonconcave min-max optimization and the decentralized communication
simultaneously. In this paper, we address this difficulty by designing the
\textbf{first gradient-based decentralized parallel algorithm} which allows
workers to have multiple rounds of communications in one iteration and to
update the discriminator and generator simultaneously, and this design makes it
amenable for the convergence analysis of the proposed decentralized algorithm.
Theoretically, our proposed decentralized algorithm is able to solve a class of
non-convex non-concave min-max problems with provable non-asymptotic
convergence to first-order stationary point. Experimental results on GANs
demonstrate the effectiveness of the proposed algorithm.
</p>
<a href="http://arxiv.org/abs/1910.12999" target="_blank">arXiv:1910.12999</a> [<a href="http://arxiv.org/pdf/1910.12999" target="_blank">pdf</a>]

<h2>Asymptotic Guarantees for Generative Modeling Based on the Smooth Wasserstein Distance. (arXiv:2002.01012v4 [math.ST] UPDATED)</h2>
<h3>Ziv Goldfeld, Kristjan Greenewald, Kengo Kato</h3>
<p>Minimum distance estimation (MDE) gained recent attention as a formulation of
(implicit) generative modeling. It considers minimizing, over model parameters,
a statistical distance between the empirical data distribution and the model.
This formulation lends itself well to theoretical analysis, but typical results
are hindered by the curse of dimensionality. To overcome this and devise a
scalable finite-sample statistical MDE theory, we adopt the framework of smooth
1-Wasserstein distance (SWD) $\mathsf{W}_1^{(\sigma)}$. The SWD was recently
shown to preserve the metric and topological structure of classic Wasserstein
distances, while enjoying dimension-free empirical convergence rates. In this
work, we conduct a thorough statistical study of the minimum smooth Wasserstein
estimators (MSWEs), first proving the estimator's measurability and asymptotic
consistency. We then characterize the limit distribution of the optimal model
parameters and their associated minimal SWD. These results imply an
$O(n^{-1/2})$ generalization bound for generative modeling based on MSWE, which
holds in arbitrary dimension. Our main technical tool is a novel
high-dimensional limit distribution result for empirical
$\mathsf{W}_1^{(\sigma)}$. The characterization of a nondegenerate limit stands
in sharp contrast with the classic empirical 1-Wasserstein distance, for which
a similar result is known only in the one-dimensional case. The validity of our
theory is supported by empirical results, posing the SWD as a potent tool for
learning and inference in high dimensions.
</p>
<a href="http://arxiv.org/abs/2002.01012" target="_blank">arXiv:2002.01012</a> [<a href="http://arxiv.org/pdf/2002.01012" target="_blank">pdf</a>]

<h2>Using Deep Learning to Improve Ensemble Smoother: Applications to Subsurface Characterization. (arXiv:2002.09100v2 [math.OC] UPDATED)</h2>
<h3>Jiangjiang Zhang, Qiang Zheng, Laosheng Wu, Lingzao Zeng</h3>
<p>Ensemble smoother (ES) has been widely used in various research fields to
reduce the uncertainty of the system-of-interest. However, the commonly-adopted
ES method that employs the Kalman formula, that is, ES$_\text{(K)}$, does not
perform well when the probability distributions involved are non-Gaussian. To
address this issue, we suggest to use deep learning (DL) to derive an
alternative update scheme for ES in complex data assimilation applications.
Here we show that the DL-based ES method, that is, ES$_\text{(DL)}$, is more
general and flexible. In this new update scheme, a high volume of training data
are generated from a relatively small-sized ensemble of model parameters and
simulation outputs, and possible non-Gaussian features can be preserved in the
training data and captured by an adequate DL model. This new variant of ES is
tested in two subsurface characterization problems with or without Gaussian
assumptions. Results indicate that ES$_\text{(DL)}$ can produce similar (in the
Gaussian case) or even better (in the non-Gaussian case) results compared to
those from ES$_\text{(K)}$. The success of ES$_\text{(DL)}$ comes from the
power of DL in extracting complex (including non-Gaussian) features and
learning nonlinear relationships from massive amounts of training data.
Although in this work we only apply the ES$_\text{(DL)}$ method in parameter
estimation problems, the proposed idea can be conveniently extended to analysis
of model structural uncertainty and state estimation in real-time forecasting
studies.
</p>
<a href="http://arxiv.org/abs/2002.09100" target="_blank">arXiv:2002.09100</a> [<a href="http://arxiv.org/pdf/2002.09100" target="_blank">pdf</a>]

<h2>Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework. (arXiv:2002.09169v2 [cs.LG] UPDATED)</h2>
<h3>Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, Qiang Liu</h3>
<p>Randomized classifiers have been shown to provide a promising approach for
achieving certified robustness against adversarial attacks in deep learning.
However, most existing methods only leverage Gaussian smoothing noise and only
work for $\ell_2$ perturbation. We propose a general framework of adversarial
certification with non-Gaussian noise and for more general types of attacks,
from a unified functional optimization perspective. Our new framework allows us
to identify a key trade-off between accuracy and robustness via designing
smoothing distributions, helping to design new families of non-Gaussian
smoothing distributions that work more efficiently for different $\ell_p$
settings, including $\ell_1$, $\ell_2$ and $\ell_\infty$ attacks. Our proposed
methods achieve better certification results than previous works and provide a
new perspective on randomized smoothing certification.
</p>
<a href="http://arxiv.org/abs/2002.09169" target="_blank">arXiv:2002.09169</a> [<a href="http://arxiv.org/pdf/2002.09169" target="_blank">pdf</a>]

<h2>Joint Device-Edge Inference over Wireless Links with Pruning. (arXiv:2003.02027v2 [cs.IT] UPDATED)</h2>
<h3>Mikolaj Jankowski, Deniz Gunduz, Krystian Mikolajczyk</h3>
<p>We propose a joint feature compression and transmission scheme for efficient
inference at the wireless network edge. Our goal is to enable efficient and
reliable inference at the edge server assuming limited computational resources
at the edge device. Previous work focused mainly on feature compression,
ignoring the computational cost of channel coding. We incorporate the recently
proposed deep joint source-channel coding (DeepJSCC) scheme, and combine it
with novel filter pruning strategies aimed at reducing the redundant complexity
from neural networks. We evaluate our approach on a classification task, and
show improved results in both end-to-end reliability and workload reduction at
the edge device. This is the first work that combines DeepJSCC with network
pruning, and applies it to image classification over the wireless edge.
</p>
<a href="http://arxiv.org/abs/2003.02027" target="_blank">arXiv:2003.02027</a> [<a href="http://arxiv.org/pdf/2003.02027" target="_blank">pdf</a>]

<h2>Provably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning. (arXiv:2003.06898v3 [cs.LG] UPDATED)</h2>
<h3>Fei Feng, Ruosong Wang, Wotao Yin, Simon S. Du, Lin F. Yang</h3>
<p>Motivated by the prevailing paradigm of using unsupervised learning for
efficient exploration in reinforcement learning (RL) problems
[tang2017exploration,bellemare2016unifying], we investigate when this paradigm
is provably efficient. We study episodic Markov decision processes with rich
observations generated from a small number of latent states. We present a
general algorithmic framework that is built upon two components: an
unsupervised learning algorithm and a no-regret tabular RL algorithm.
Theoretically, we prove that as long as the unsupervised learning algorithm
enjoys a polynomial sample complexity guarantee, we can find a near-optimal
policy with sample complexity polynomial in the number of latent states, which
is significantly smaller than the number of observations. Empirically, we
instantiate our framework on a class of hard exploration problems to
demonstrate the practicality of our theory.
</p>
<a href="http://arxiv.org/abs/2003.06898" target="_blank">arXiv:2003.06898</a> [<a href="http://arxiv.org/pdf/2003.06898" target="_blank">pdf</a>]

<h2>Optimization and Generalization Analysis of Transduction through Gradient Boosting and Application to Multi-scale Graph Neural Networks. (arXiv:2006.08550v2 [cs.LG] UPDATED)</h2>
<h3>Kenta Oono, Taiji Suzuki</h3>
<p>It is known that the current graph neural networks (GNNs) are difficult to
make themselves deep due to the problem known as over-smoothing. Multi-scale
GNNs are a promising approach for mitigating the over-smoothing problem.
However, there is little explanation of why it works empirically from the
viewpoint of learning theory. In this study, we derive the optimization and
generalization guarantees of transductive learning algorithms that include
multi-scale GNNs. Using the boosting theory, we prove the convergence of the
training error under weak learning-type conditions. By combining it with
generalization gap bounds in terms of transductive Rademacher complexity, we
show that a test error bound of a specific type of multi-scale GNNs that
decreases corresponding to the number of node aggregations under some
conditions. Our results offer theoretical explanations for the effectiveness of
the multi-scale structure against the over-smoothing problem. We apply boosting
algorithms to the training of multi-scale GNNs for real-world node prediction
tasks. We confirm that its performance is comparable to existing GNNs, and the
practical behaviors are consistent with theoretical observations. Code is
available at https://github.com/delta2323/GB-GNN.
</p>
<a href="http://arxiv.org/abs/2006.08550" target="_blank">arXiv:2006.08550</a> [<a href="http://arxiv.org/pdf/2006.08550" target="_blank">pdf</a>]

<h2>Multipole Graph Neural Operator for Parametric Partial Differential Equations. (arXiv:2006.09535v2 [cs.LG] UPDATED)</h2>
<h3>Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, Anima Anandkumar</h3>
<p>One of the main challenges in using deep learning-based methods for
simulating physical systems and solving partial differential equations (PDEs)
is formulating physics-based data in the desired structure for neural networks.
Graph neural networks (GNNs) have gained popularity in this area since graphs
offer a natural way of modeling particle interactions and provide a clear way
of discretizing the continuum models. However, the graphs constructed for
approximating such tasks usually ignore long-range interactions due to
unfavorable scaling of the computational complexity with respect to the number
of nodes. The errors due to these approximations scale with the discretization
of the system, thereby not allowing for generalization under mesh-refinement.
Inspired by the classical multipole methods, we propose a novel multi-level
graph neural network framework that captures interaction at all ranges with
only linear complexity. Our multi-level formulation is equivalent to
recursively adding inducing points to the kernel matrix, unifying GNNs with
multi-resolution matrix factorization of the kernel. Experiments confirm our
multi-graph network learns discretization-invariant solution operators to PDEs
and can be evaluated in linear time.
</p>
<a href="http://arxiv.org/abs/2006.09535" target="_blank">arXiv:2006.09535</a> [<a href="http://arxiv.org/pdf/2006.09535" target="_blank">pdf</a>]

<h2>Hybrid Models for Learning to Branch. (arXiv:2006.15212v2 [cs.LG] UPDATED)</h2>
<h3>Prateek Gupta, Maxime Gasse, Elias B. Khalil, M. Pawan Kumar, Andrea Lodi, Yoshua Bengio</h3>
<p>A recent Graph Neural Network (GNN) approach for learning to branch has been
shown to successfully reduce the running time of branch-and-bound algorithms
for Mixed Integer Linear Programming (MILP). While the GNN relies on a GPU for
inference, MILP solvers are purely CPU-based. This severely limits its
application as many practitioners may not have access to high-end GPUs. In this
work, we ask two key questions. First, in a more realistic setting where only a
CPU is available, is the GNN model still competitive? Second, can we devise an
alternate computationally inexpensive model that retains the predictive power
of the GNN architecture? We answer the first question in the negative, and
address the second question by proposing a new hybrid architecture for
efficient branching on CPU machines. The proposed architecture combines the
expressive power of GNNs with computationally inexpensive multi-layer
perceptrons (MLP) for branching. We evaluate our methods on four classes of
MILP problems, and show that they lead to up to 26% reduction in solver running
time compared to state-of-the-art methods without a GPU, while extrapolating to
harder problems than it was trained on. The code for this project is publicly
available at https://github.com/pg2455/Hybrid-learn2branch.
</p>
<a href="http://arxiv.org/abs/2006.15212" target="_blank">arXiv:2006.15212</a> [<a href="http://arxiv.org/pdf/2006.15212" target="_blank">pdf</a>]

<h2>Ensemble Kalman Inversion for Sparse Learning of Dynamical Systems from Time-Averaged Data. (arXiv:2007.06175v2 [math.OC] UPDATED)</h2>
<h3>Tapio Schneider, Andrew M. Stuart, Jin-Long Wu</h3>
<p>Enforcing sparse structure within learning has led to significant advances in
the field of data-driven discovery of dynamical systems. However, such methods
require access not only to time-series of the state of the dynamical system,
but also to the time derivative. In many applications, the data are available
only in the form of time-averages such as moments and autocorrelation
functions. We propose a sparse learning methodology to discover the vector
fields defining a (possibly stochastic or partial) differential equation, using
only time-averaged statistics. Such a formulation of sparse learning naturally
leads to a nonlinear inverse problem to which we apply the methodology of
ensemble Kalman inversion (EKI). EKI is chosen because it may be formulated in
terms of the iterative solution of quadratic optimization problems; sparsity is
then easily imposed. We then apply the EKI-based sparse learning methodology to
various examples governed by stochastic differential equations (a noisy Lorenz
63 system), ordinary differential equations (Lorenz 96 system and coalescence
equations), and a partial differential equation (the Kuramoto-Sivashinsky
equation). The results demonstrate that time-averaged statistics can be used
for data-driven discovery of differential equations using sparse EKI. The
proposed sparse learning methodology extends the scope of data-driven discovery
of differential equations to previously challenging applications and
data-acquisition scenarios.
</p>
<a href="http://arxiv.org/abs/2007.06175" target="_blank">arXiv:2007.06175</a> [<a href="http://arxiv.org/pdf/2007.06175" target="_blank">pdf</a>]

<h2>Uncertainty quantification for Markov Random Fields. (arXiv:2009.00038v2 [stat.ML] UPDATED)</h2>
<h3>Panagiota Birmpa, Markos A. Katsoulakis</h3>
<p>We present an information-based uncertainty quantification method for general
Markov Random Fields. Markov Random Fields (MRF) are structured, probabilistic
graphical models over undirected graphs, and provide a fundamental unifying
modeling tool for statistical mechanics, probabilistic machine learning, and
artificial intelligence. Typically MRFs are complex and high-dimensional with
nodes and edges (connections) built in a modular fashion from simpler,
low-dimensional probabilistic models and their local connections; in turn, this
modularity allows to incorporate available data to MRFs and efficiently
simulate them by leveraging their graph-theoretic structure. Learning graphical
models from data and/or constructing them from physical modeling and
constraints necessarily involves uncertainties inherited from data, modeling
choices, or numerical approximations. These uncertainties in the MRF can be
manifested either in the graph structure or the probability distribution
functions, and necessarily will propagate in predictions for quantities of
interest. Here we quantify such uncertainties using tight, information based
bounds on the predictions of quantities of interest; these bounds take
advantage of the graphical structure of MRFs and are capable of handling the
inherent high-dimensionality of such graphical models. We demonstrate our
methods in MRFs for medical diagnostics and statistical mechanics models. In
the latter, we develop uncertainty quantification bounds for finite size
effects and phase diagrams, which constitute two of the typical predictions
goals of statistical mechanics modeling.
</p>
<a href="http://arxiv.org/abs/2009.00038" target="_blank">arXiv:2009.00038</a> [<a href="http://arxiv.org/pdf/2009.00038" target="_blank">pdf</a>]

<h2>$X$-Secure $T$-Private Federated Submodel Learning. (arXiv:2010.01059v2 [cs.IT] UPDATED)</h2>
<h3>Zhuqing Jia, Syed A. Jafar</h3>
<p>The problem of (information-theoretic) $X$-secure $T$-private federated
submodel learning represents a setting where a large scale machine learning
model is partitioned into $K$ submodels and stored across $N$ distributed
servers according to an $X$-secure threshold secret sharing scheme. Various
users wish to successively train (update) the submodel that is most relevant to
their local data while keeping the identity of their relevant submodel private
from any set of up to $T$ colluding servers. Inspired by the idea of
cross-subspace alignment (CSA) for $X$-secure $T$-private information
retrieval, we propose a novel CSA-RW (read-write) scheme for efficiently (in
terms of communication cost) and privately reading from and writing to a
distributed database. CSA-RW is shown to be asymptotically/approximately
optimal in download/upload communication cost, and improves significantly upon
available baselines from prior work. It also answers in the affirmative an open
question by Kairouz et al. by exploiting synergistic gains from the joint
design of private read and write operations.
</p>
<a href="http://arxiv.org/abs/2010.01059" target="_blank">arXiv:2010.01059</a> [<a href="http://arxiv.org/pdf/2010.01059" target="_blank">pdf</a>]

<h2>Group-like small cancellation theory for rings. (arXiv:2010.02836v3 [math.RA] UPDATED)</h2>
<h3>A. Atkarskaya (Department of Mathematics, The Hebrew University of Jerusalem, Israel), A. Kanel-Belov (Department of Mathematics, Bar-Ilan University, Israel and College of Mathematics and Statistics, Shenzhen University, China), E. Plotkin (Department of Mathematics, Bar-Ilan University, Israel), E. Rips (Department of Mathematics, The Hebrew University of Jerusalem, Israel)</h3>
<p>In the present paper we develop a small cancellation theory for associative
algebras with a basis of invertible elements. Namely, we study quotients of a
group algebra of a free group and introduce three axioms for the corresponding
defining relations. We show that the obtained ring is non-trivial. Moreover, we
show that this ring enjoys a global filtration that agrees with relations, find
a basis of the ring as a vector space and establish the corresponding structure
theorems. We also provide a revision of a concept of Gr\"{o}bner basis for our
rings and establish a greedy algorithm for the Ideal Membership Problem.
</p>
<a href="http://arxiv.org/abs/2010.02836" target="_blank">arXiv:2010.02836</a> [<a href="http://arxiv.org/pdf/2010.02836" target="_blank">pdf</a>]

<h2>Information-Theoretic Bounds on Transfer Generalization Gap Based on Jensen-Shannon Divergence. (arXiv:2010.09484v2 [cs.LG] UPDATED)</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>In transfer learning, training and testing data sets are drawn from different
data distributions. The transfer generalization gap is the difference between
the population loss on the target data distribution and the training loss. The
training data set generally includes data drawn from both source and target
distributions. This work presents novel information-theoretic upper bounds on
the average transfer generalization gap that capture (i) the domain shift
between the target data distribution $P'_Z$ and and the source distribution
$P_Z$ through Nielsen's family of $\alpha$-Jensen-Shannon (JS) divergences
$D_{JS}^{\alpha}(P'_Z || P_Z)$; and (ii) the sensitivity of the transfer
learner output $W$ to each individual sample of the data set $Z_i$ via the
mutual information $I(W;Z_i)$. The $\alpha$-JS divergence is bounded even when
the support of $P_Z$ is not included in that of $P'_Z$ . This contrasts the
Kullback- Leibler (KL) divergence $D_{KL}(P_Z||P'_Z)$-based bounds of Wu et al.
[1], which are vacuous under this assumption. Moreover, the obtained bounds
hold for unbounded loss functions with bounded cumulant generating functions,
unlike the $\phi$-divergence based bound of Wu et al. [1]. We also obtain new
upper bounds on the average transfer excess risk in terms of the $\alpha$-JS
divergence for empirical weighted risk minimization (EWRM), which minimizes the
weighted average training losses over source and target data sets. Finally, we
provide a numerical example to illustrate the merits of the introduced bounds.
</p>
<a href="http://arxiv.org/abs/2010.09484" target="_blank">arXiv:2010.09484</a> [<a href="http://arxiv.org/pdf/2010.09484" target="_blank">pdf</a>]

<h2>No-regret learning and mixed Nash equilibria: They do not mix. (arXiv:2010.09514v2 [cs.GT] UPDATED)</h2>
<h3>Lampros Flokas, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Thanasis Lianeas, Panayotis Mertikopoulos, Georgios Piliouras</h3>
<p>Understanding the behavior of no-regret dynamics in general $N$-player games
is a fundamental question in online learning and game theory. A folk result in
the field states that, in finite games, the empirical frequency of play under
no-regret learning converges to the game's set of coarse correlated equilibria.
By contrast, our understanding of how the day-to-day behavior of the dynamics
correlates to the game's Nash equilibria is much more limited, and only partial
results are known for certain classes of games (such as zero-sum or congestion
games). In this paper, we study the dynamics of "follow-the-regularized-leader"
(FTRL), arguably the most well-studied class of no-regret dynamics, and we
establish a sweeping negative result showing that the notion of mixed Nash
equilibrium is antithetical to no-regret learning. Specifically, we show that
any Nash equilibrium which is not strict (in that every player has a unique
best response) cannot be stable and attracting under the dynamics of FTRL. This
result has significant implications for predicting the outcome of a learning
process as it shows unequivocally that only strict (and hence, pure) Nash
equilibria can emerge as stable limit points thereof.
</p>
<a href="http://arxiv.org/abs/2010.09514" target="_blank">arXiv:2010.09514</a> [<a href="http://arxiv.org/pdf/2010.09514" target="_blank">pdf</a>]

<h2>FLAP -- A Federated Learning Framework for Attribute-based Access Control Policies. (arXiv:2010.09767v1 [cs.CR])</h2>
<h3>Amani Abu Jabal, Elisa Bertino, Jorge Lobo, Dinesh Verma, Seraphin Calo, Alessandra Russo</h3>
<p>Technology advances in areas such as sensors, IoT, and robotics, enable new
collaborative applications (e.g., autonomous devices). A primary requirement
for such collaborations is to have a secure system which enables information
sharing and information flow protection. Policy-based management system is a
key mechanism for secure selective sharing of protected resources. However,
policies in each party of such a collaborative environment cannot be static as
they have to adapt to different contexts and situations. One advantage of
collaborative applications is that each party in the collaboration can take
advantage of knowledge of the other parties for learning or enhancing its own
policies. We refer to this learning mechanism as policy transfer. The design of
a policy transfer framework has challenges, including policy conflicts and
privacy issues. Policy conflicts typically arise because of differences in the
obligations of the parties, whereas privacy issues result because of data
sharing constraints for sensitive data. Hence, the policy transfer framework
should be able to tackle such challenges by considering minimal sharing of data
and support policy adaptation to address conflict. In the paper we propose a
framework that aims at addressing such challenges. We introduce a formal
definition of the policy transfer problem for attribute-based policies. We then
introduce the transfer methodology that consists of three sequential steps.
Finally we report experimental results.
</p>
<a href="http://arxiv.org/abs/2010.09767" target="_blank">arXiv:2010.09767</a> [<a href="http://arxiv.org/pdf/2010.09767" target="_blank">pdf</a>]

<h2>Every Hidden Unit Maximizing Output Weights Maximizes The Global Reward. (arXiv:2010.09770v1 [cs.LG])</h2>
<h3>Stephen Chung</h3>
<p>For a network of stochastic units trained on a reinforcement learning task,
one biologically plausible way of learning is to treat each unit as a
reinforcement learning unit and train each unit by REINFORCE using the same
global reward signal. In this case, only a global reward signal has to be
broadcast to all units, and the learning rule given is local. Although this
learning rule follows the gradient of return in expectation, it suffers from
high variance and cannot be used to train a deep network in practice. In this
paper, we propose an algorithm called Weight Maximization, which can
significantly improve the speed of applying REINFORCE to all units.
Essentially, we replace the global reward to each hidden unit with the change
in the norm of output weights, such that each hidden unit in the network is
trying to maximize the norm of output weights instead of the global reward. We
found that the new algorithm can solve simple reinforcement learning tasks
significantly faster than the baseline model. We also prove that the resulting
learning rule is approximately following gradient ascent on the reward in
expectation when applied to a multi-layer network of Bernoulli logistic unit.
It illustrates an example of intelligent behavior arising from a population of
self-interested hedonistic neurons, which corresponds to Klopf's hedonistic
neuron hypothesis.
</p>
<a href="http://arxiv.org/abs/2010.09770" target="_blank">arXiv:2010.09770</a> [<a href="http://arxiv.org/pdf/2010.09770" target="_blank">pdf</a>]

<h2>GAMesh: Guided and Augmented Meshing for Deep Point Networks. (arXiv:2010.09774v1 [cs.CV])</h2>
<h3>Nitin Agarwal, M Gopi</h3>
<p>We present a new meshing algorithm called guided and augmented meshing,
GAMesh, which uses a mesh prior to generate a surface for the output points of
a point network. By projecting the output points onto this prior and
simplifying the resulting mesh, GAMesh ensures a surface with the same topology
as the mesh prior but whose geometric fidelity is controlled by the point
network. This makes GAMesh independent of both the density and distribution of
the output points, a common artifact in traditional surface reconstruction
algorithms. We show that such a separation of geometry from topology can have
several advantages especially in single-view shape prediction, fair evaluation
of point networks and reconstructing surfaces for networks which output sparse
point clouds. We further show that by training point networks with GAMesh, we
can directly optimize the vertex positions to generate adaptive meshes with
arbitrary topologies.
</p>
<a href="http://arxiv.org/abs/2010.09774" target="_blank">arXiv:2010.09774</a> [<a href="http://arxiv.org/pdf/2010.09774" target="_blank">pdf</a>]

<h2>SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for Autonomous Driving. (arXiv:2010.09776v1 [cs.MA])</h2>
<h3>Ming Zhou, Jun Luo, Julian Villela, Yaodong Yang, David Rusu, Jiayu Miao, Weinan Zhang, Montgomery Alban, Iman Fadakar, Zheng Chen, Aurora Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Dong Chen, Zhengbang Zhu, Nhat Nguyen, Mohamed Elsayed, Kun Shao, Sanjeevan Ahilan, Baokuan Zhang, Jiannan Wu, Zhengang Fu, Kasra Rezaee, Peyman Yadmellat, Mohsen Rohani, Nicolas Perez Nieves, Yihan Ni, Seyedershad Banijamali, Alexander Cowen Rivers, Zheng Tian, Daniel Palenicek, Haitham bou Ammar, Hongbo Zhang, Wulong Liu, Jianye Hao, Jun Wang</h3>
<p>Multi-agent interaction is a fundamental aspect of autonomous driving in the
real world. Despite more than a decade of research and development, the problem
of how to competently interact with diverse road users in diverse scenarios
remains largely unsolved. Learning methods have much to offer towards solving
this problem. But they require a realistic multi-agent simulator that generates
diverse and competent driving interactions. To meet this need, we develop a
dedicated simulation platform called SMARTS (Scalable Multi-Agent RL Training
School). SMARTS supports the training, accumulation, and use of diverse
behavior models of road users. These are in turn used to create increasingly
more realistic and diverse interactions that enable deeper and broader research
on multi-agent interaction. In this paper, we describe the design goals of
SMARTS, explain its basic architecture and its key features, and illustrate its
use through concrete multi-agent experiments on interactive scenarios. We
open-source the SMARTS platform and the associated benchmark tasks and
evaluation metrics to encourage and empower research on multi-agent learning
for autonomous driving.
</p>
<a href="http://arxiv.org/abs/2010.09776" target="_blank">arXiv:2010.09776</a> [<a href="http://arxiv.org/pdf/2010.09776" target="_blank">pdf</a>]

<h2>Technical Question Answering across Tasks and Domains. (arXiv:2010.09780v1 [cs.CL])</h2>
<h3>Wenhao Yu, Lingfei Wu, Yu Deng, Qingkai Zeng, Ruchi Mahindru, Sinem Guven, Meng Jiang</h3>
<p>Building automatic technical support system is an important yet challenge
task. Conceptually, to answer a user question on a technical forum, a human
expert has to first retrieve relevant documents, and then read them carefully
to identify the answer snippet. Despite huge success the researchers have
achieved in coping with general domain question answering (QA), much less
attentions have been paid for investigating technical QA. Specifically,
existing methods suffer from several unique challenges (i) the question and
answer rarely overlaps substantially and (ii) very limited data size. In this
paper, we propose a novel framework of deep transfer learning to effectively
address technical QA across tasks and domains. To this end, we present an
adjustable joint learning approach for document retrieval and reading
comprehension tasks. Our experiments on the TechQA demonstrates superior
performance compared with state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.09780" target="_blank">arXiv:2010.09780</a> [<a href="http://arxiv.org/pdf/2010.09780" target="_blank">pdf</a>]

<h2>ABC-Di: Approximate Bayesian Computation for Discrete Data. (arXiv:2010.09790v1 [stat.ML])</h2>
<h3>Ilze Amanda Auzina, Jakub M. Tomczak</h3>
<p>Many real-life problems are represented as a black-box, i.e., the internal
workings are inaccessible or a closed-form mathematical expression of the
likelihood function cannot be defined. For continuous random variables
likelihood-free inference problems can be solved by a group of methods under
the name of Approximate Bayesian Computation (ABC). However, a similar approach
for discrete random variables is yet to be formulated. Here, we aim to fill
this research gap. We propose to use a population-based MCMC ABC framework.
Further, we present a valid Markov kernel, and propose a new kernel that is
inspired by Differential Evolution. We assess the proposed approach on a
problem with the known likelihood function, namely, discovering the underlying
diseases based on a QMR-DT Network, and three likelihood-free inference
problems: (i) the QMR-DT Network with the unknown likelihood function, (ii)
learning binary neural network, and (iii) Neural Architecture Search. The
obtained results indicate the high potential of the proposed framework and the
superiority of the new Markov kernel.
</p>
<a href="http://arxiv.org/abs/2010.09790" target="_blank">arXiv:2010.09790</a> [<a href="http://arxiv.org/pdf/2010.09790" target="_blank">pdf</a>]

<h2>A Contour Stochastic Gradient Langevin Dynamics Algorithm for Simulations of Multi-modal Distributions. (arXiv:2010.09800v1 [stat.ML])</h2>
<h3>Wei Deng, Guang Lin, Faming Liang</h3>
<p>We propose an adaptively weighted stochastic gradient Langevin dynamics
algorithm (SGLD), so-called contour stochastic gradient Langevin dynamics
(CSGLD), for Bayesian learning in big data statistics. The proposed algorithm
is essentially a \emph{scalable dynamic importance sampler}, which
automatically \emph{flattens} the target distribution such that the simulation
for a multi-modal distribution can be greatly facilitated. Theoretically, we
prove a stability condition and establish the asymptotic convergence of the
self-adapting parameter to a {\it unique fixed-point}, regardless of the
non-convexity of the original energy function; we also present an error
analysis for the weighted averaging estimators. Empirically, the CSGLD
algorithm is tested on multiple benchmark datasets including CIFAR10 and
CIFAR100. The numerical results indicate its superiority over the existing
state-of-the-art algorithms in training deep neural networks.
</p>
<a href="http://arxiv.org/abs/2010.09800" target="_blank">arXiv:2010.09800</a> [<a href="http://arxiv.org/pdf/2010.09800" target="_blank">pdf</a>]

<h2>A Differentiable Newton Euler Algorithm for Multi-body Model Learning. (arXiv:2010.09802v1 [cs.RO])</h2>
<h3>Michael Lutter, Johannes Silberbauer, Joe Watson, Jan Peters</h3>
<p>In this work, we examine a spectrum of hybrid model for the domain of
multi-body robot dynamics. We motivate a computation graph architecture that
embodies the Newton Euler equations, emphasizing the utility of the Lie Algebra
form in translating the dynamical geometry into an efficient computational
structure for learning. We describe the used virtual parameters that enable
unconstrained physical plausible dynamics and the used actuator models. In the
experiments, we define a family of 26 grey-box models and evaluate them for
system identification of the simulated and physical Furuta Pendulum and
Cartpole. The comparison shows that the kinematic parameters, required by
previous white-box system identification methods, can be accurately inferred
from data. Furthermore, we highlight that models with guaranteed bounded energy
of the uncontrolled system generate non-divergent trajectories, while more
general models have no such guarantee, so their performance strongly depends on
the data distribution. Therefore, the main contributions of this work is the
introduction of a white-box model that jointly learns dynamic and kinematics
parameters and can be combined with black-box components. We then provide
extensive empirical evaluation on challenging systems and different datasets
that elucidates the comparative performance of our grey-box architecture with
comparable white- and black-box models.
</p>
<a href="http://arxiv.org/abs/2010.09802" target="_blank">arXiv:2010.09802</a> [<a href="http://arxiv.org/pdf/2010.09802" target="_blank">pdf</a>]

<h2>Adversarial Training for Code Retrieval with Question-Description Relevance Regularization. (arXiv:2010.09803v1 [cs.CL])</h2>
<h3>Jie Zhao, Huan Sun</h3>
<p>Code retrieval is a key task aiming to match natural and programming
languages. In this work, we propose adversarial learning for code retrieval,
that is regularized by question-description relevance. First, we adapt a simple
adversarial learning technique to generate difficult code snippets given the
input question, which can help the learning of code retrieval that faces
bi-modal and data-scarce challenges. Second, we propose to leverage
question-description relevance to regularize adversarial learning, such that a
generated code snippet should contribute more to the code retrieval training
loss, only if its paired natural language description is predicted to be less
relevant to the user given question. Experiments on large-scale code retrieval
datasets of two programming languages show that our adversarial learning method
is able to improve the performance of state-of-the-art models. Moreover, using
an additional duplicate question prediction model to regularize adversarial
learning further improves the performance, and this is more effective than
using the duplicated questions in strong multi-task learning baselines
</p>
<a href="http://arxiv.org/abs/2010.09803" target="_blank">arXiv:2010.09803</a> [<a href="http://arxiv.org/pdf/2010.09803" target="_blank">pdf</a>]

<h2>Imitation with Neural Density Models. (arXiv:2010.09808v1 [cs.LG])</h2>
<h3>Kuno Kim, Akshat Jindal, Yang Song, Jiaming Song, Yanan Sui, Stefano Ermon</h3>
<p>We propose a new framework for Imitation Learning (IL) via density estimation
of the expert's occupancy measure followed by Maximum Occupancy Entropy
Reinforcement Learning (RL) using the density as a reward. Our approach
maximizes a non-adversarial model-free RL objective that provably lower bounds
reverse Kullback-Leibler divergence between occupancy measures of the expert
and imitator. We present a practical IL algorithm, Neural Density Imitation
(NDI), which obtains state-of-the-art demonstration efficiency on benchmark
control tasks.
</p>
<a href="http://arxiv.org/abs/2010.09808" target="_blank">arXiv:2010.09808</a> [<a href="http://arxiv.org/pdf/2010.09808" target="_blank">pdf</a>]

<h2>Connections between Relational Event Model and Inverse Reinforcement Learning for Characterizing Group Interaction Sequences. (arXiv:2010.09810v1 [cs.LG])</h2>
<h3>Congyu Wu</h3>
<p>In this paper we explore previously unidentified connections between
relational event model (REM) from the field of network science and inverse
reinforcement learning (IRL) from the field of machine learning with respect to
their ability to characterize sequences of directed social interaction events
in group settings. REM is a conventional approach to tackle such a problem
whereas the application of IRL is a largely unbeaten path. We begin by
examining the mathematical components of both REM and IRL and find
straightforward analogies between the two methods as well as unique
characteristics of the IRL approach. We demonstrate the special utility of IRL
in characterizing group social interactions with an empirical experiment, in
which we use IRL to infer individual behavioral preferences based on a sequence
of directed communication events from a group of virtual-reality game players
interacting and cooperating to accomplish a shared goal. Our comparison and
experiment introduce fresh perspectives for social behavior analytics and help
inspire new research opportunities at the nexus of social network analysis and
machine learning.
</p>
<a href="http://arxiv.org/abs/2010.09810" target="_blank">arXiv:2010.09810</a> [<a href="http://arxiv.org/pdf/2010.09810" target="_blank">pdf</a>]

<h2>Dream and Search to Control: Latent Space Planning for Continuous Control. (arXiv:2010.09832v1 [cs.LG])</h2>
<h3>Anurag Koul, Varun V. Kumar, Alan Fern, Somdeb Majumdar</h3>
<p>Learning and planning with latent space dynamics has been shown to be useful
for sample efficiency in model-based reinforcement learning (MBRL) for discrete
and continuous control tasks. In particular, recent work, for discrete action
spaces, demonstrated the effectiveness of latent-space planning via Monte-Carlo
Tree Search (MCTS) for bootstrapping MBRL during learning and at test time.
However, the potential gains from latent-space tree search have not yet been
demonstrated for environments with continuous action spaces. In this work, we
propose and explore an MBRL approach for continuous action spaces based on
tree-based planning over learned latent dynamics. We show that it is possible
to demonstrate the types of bootstrapping benefits as previously shown for
discrete spaces. In particular, the approach achieves improved sample
efficiency and performance on a majority of challenging continuous-control
benchmarks compared to the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2010.09832" target="_blank">arXiv:2010.09832</a> [<a href="http://arxiv.org/pdf/2010.09832" target="_blank">pdf</a>]

<h2>Topology-Aware Graph Pooling Networks. (arXiv:2010.09834v1 [cs.LG])</h2>
<h3>Hongyang Gao, Yi Liu, Shuiwang Ji</h3>
<p>Pooling operations have shown to be effective on computer vision and natural
language processing tasks. One challenge of performing pooling operations on
graph data is the lack of locality that is not well-defined on graphs. Previous
studies used global ranking methods to sample some of the important nodes, but
most of them are not able to incorporate graph topology. In this work, we
propose the topology-aware pooling (TAP) layer that explicitly considers graph
topology. Our TAP layer is a two-stage voting process that selects more
important nodes in a graph. It first performs local voting to generate scores
for each node by attending each node to its neighboring nodes. The scores are
generated locally such that topology information is explicitly considered. In
addition, graph topology is incorporated in global voting to compute the
importance score of each node globally in the entire graph. Altogether, the
final ranking score for each node is computed by combining its local and global
voting scores. To encourage better graph connectivity in the sampled graph, we
propose to add a graph connectivity term to the computation of ranking scores.
Results on graph classification tasks demonstrate that our methods achieve
consistently better performance than previous methods.
</p>
<a href="http://arxiv.org/abs/2010.09834" target="_blank">arXiv:2010.09834</a> [<a href="http://arxiv.org/pdf/2010.09834" target="_blank">pdf</a>]

<h2>New Properties of the Data Distillation Method When Working With Tabular Data. (arXiv:2010.09839v1 [cs.LG])</h2>
<h3>Dmitry Medvedev, Alexander D&#x27;yakonov</h3>
<p>Data distillation is the problem of reducing the volume oftraining data while
keeping only the necessary information. With thispaper, we deeper explore the
new data distillation algorithm, previouslydesigned for image data. Our
experiments with tabular data show thatthe model trained on distilled samples
can outperform the model trainedon the original dataset. One of the problems of
the considered algorithmis that produced data has poor generalization on models
with differenthyperparameters. We show that using multiple architectures during
distillation can help overcome this problem.
</p>
<a href="http://arxiv.org/abs/2010.09839" target="_blank">arXiv:2010.09839</a> [<a href="http://arxiv.org/pdf/2010.09839" target="_blank">pdf</a>]

<h2>Robot Design With Neural Networks, MILP Solvers and Active Learning. (arXiv:2010.09842v1 [cs.AI])</h2>
<h3>Sanjai Narain, Emily Mak, Dana Chee, Todd Huster, Jeremy Cohen, Kishore Pochiraju, Brendan Englot, Niraj K. Jha, Karthik Narayan</h3>
<p>Central to the design of many robot systems and their controllers is solving
a constrained blackbox optimization problem. This paper presents CNMA, a new
method of solving this problem that is conservative in the number of
potentially expensive blackbox function evaluations; allows specifying complex,
even recursive constraints directly rather than as hard-to-design penalty or
barrier functions; and is resilient to the non-termination of function
evaluations. CNMA leverages the ability of neural networks to approximate any
continuous function, their transformation into equivalent mixed integer linear
programs (MILPs) and their optimization subject to constraints with industrial
strength MILP solvers. A new learning-from-failure step guides the learning to
be relevant to solving the constrained optimization problem. Thus, the amount
of learning is orders of magnitude smaller than that needed to learn functions
over their entire domains. CNMA is illustrated with the design of several
robotic systems: wave-energy propelled boat, lunar lander, hexapod, cartpole,
acrobot and parallel parking. These range from 6 real-valued dimensions to 36.
We show that CNMA surpasses the Nelder-Mead, Gaussian and Random Search
optimization methods against the metric of number of function evaluations.
</p>
<a href="http://arxiv.org/abs/2010.09842" target="_blank">arXiv:2010.09842</a> [<a href="http://arxiv.org/pdf/2010.09842" target="_blank">pdf</a>]

<h2>What breach? Measuring online awareness of security incidents by studying real-world browsing behavior. (arXiv:2010.09843v1 [cs.CR])</h2>
<h3>Sruti Bhagavatula, Lujo Bauer, Apu Kapadia</h3>
<p>Awareness about security and privacy risks is important for developing good
security habits. Learning about real-world security incidents and data breaches
can alert people to the ways in which their information is vulnerable online,
thus playing a significant role in encouraging safe security behavior. This
paper examines 1) how often people read about security incidents online, 2) of
those people, whether and to what extent they follow up with an action, e.g.,
by trying to read more about the incident, and 3) what influences the
likelihood that they will read about an incident and take some action. We study
this by quantitatively examining real-world internet-browsing data from 303
participants.

Our findings present a bleak view of awareness of security incidents. Only
17% of participants visited any web pages related to six widely publicized
large-scale security incidents; few read about one even when an incident was
likely to have affected them (e.g., the Equifax breach almost universally
affected people with Equifax credit reports). We further found that more severe
incidents as well as articles that constructively spoke about the incident
inspired more action. We conclude with recommendations for specific future
research and for enabling useful security incident information to reach more
people.
</p>
<a href="http://arxiv.org/abs/2010.09843" target="_blank">arXiv:2010.09843</a> [<a href="http://arxiv.org/pdf/2010.09843" target="_blank">pdf</a>]

<h2>Idle Vehicle Relocation Strategy through Deep Learning for Shared Autonomous Electric Vehicle System Optimization. (arXiv:2010.09847v1 [cs.LG])</h2>
<h3>Seongsin Kim, Ungki Lee, Ikjin Lee, Namwoo Kang</h3>
<p>In optimization of a shared autonomous electric vehicle (SAEV) system, idle
vehicle relocation strategies are important to reduce operation costs and
customers' wait time. However, for an on-demand service, continuous
optimization for idle vehicle relocation is computationally expensive, and
thus, not effective. This study proposes a deep learning-based algorithm that
can instantly predict the optimal solution to idle vehicle relocation problems
under various traffic conditions. The proposed relocation process comprises
three steps. First, a deep learning-based passenger demand prediction model
using taxi big data is built. Second, idle vehicle relocation problems are
solved based on predicted demands, and optimal solution data are collected.
Finally, a deep learning model using the optimal solution data is built to
estimate the optimal strategy without solving relocation. In addition, the
proposed idle vehicle relocation model is validated by applying it to optimize
the SAEV system. We present an optimal service system including the design of
SAEV vehicles and charging stations. Further, we demonstrate that the proposed
strategy can drastically reduce operation costs and wait times for on-demand
services.
</p>
<a href="http://arxiv.org/abs/2010.09847" target="_blank">arXiv:2010.09847</a> [<a href="http://arxiv.org/pdf/2010.09847" target="_blank">pdf</a>]

<h2>Facial Emotion Recognition with Noisy Multi-task Annotations. (arXiv:2010.09849v1 [cs.CV])</h2>
<h3>Siwei Zhang, Zhiwu Huang, Danda Pani Paudel, Luc Van Gool</h3>
<p>Human emotions can be inferred from facial expressions. However, the
annotations of facial expressions are often highly noisy in common emotion
coding models, including categorical and dimensional ones. To reduce human
labelling effort on multi-task labels, we introduce a new problem of facial
emotion recognition with noisy multi-task annotations. For this new problem, we
suggest a formulation from the point of joint distribution match view, which
aims at learning more reliable correlations among raw facial images and
multi-task labels, resulting in the reduction of noise influence. In our
formulation, we exploit a new method to enable the emotion prediction and the
joint distribution learning in a unified adversarial learning game. Evaluation
throughout extensive experiments studies the real setups of the suggested new
problem, as well as the clear superiority of the proposed method over the
state-of-the-art competing methods on either the synthetic noisy labeled
CIFAR-10 or practical noisy multi-task labeled RAF and AffectNet.
</p>
<a href="http://arxiv.org/abs/2010.09849" target="_blank">arXiv:2010.09849</a> [<a href="http://arxiv.org/pdf/2010.09849" target="_blank">pdf</a>]

<h2>Anomaly Detection on X-Rays Using Self-Supervised Aggregation Learning. (arXiv:2010.09856v1 [cs.CV])</h2>
<h3>Behzad Bozorgtabar, Dwarikanath Mahapatra, Guillaume Vray, Jean-Philippe Thiran</h3>
<p>Deep anomaly detection models using a supervised mode of learning usually
work under a closed set assumption and suffer from overfitting to previously
seen rare anomalies at training, which hinders their applicability in a real
scenario. In addition, obtaining annotations for X-rays is very time consuming
and requires extensive training of radiologists. Hence, training anomaly
detection in a fully unsupervised or self-supervised fashion would be
advantageous, allowing a significant reduction of time spent on the report by
radiologists. In this paper, we present SALAD, an end-to-end deep
self-supervised methodology for anomaly detection on X-Ray images. The proposed
method is based on an optimization strategy in which a deep neural network is
encouraged to represent prototypical local patterns of the normal data in the
embedding space. During training, we record the prototypical patterns of normal
training samples via a memory bank. Our anomaly score is then derived by
measuring similarity to a weighted combination of normal prototypical patterns
within a memory bank without using any anomalous patterns. We present extensive
experiments on the challenging NIH Chest X-rays and MURA dataset, which
indicate that our algorithm improves state-of-the-art methods by a wide margin.
</p>
<a href="http://arxiv.org/abs/2010.09856" target="_blank">arXiv:2010.09856</a> [<a href="http://arxiv.org/pdf/2010.09856" target="_blank">pdf</a>]

<h2>The STDyn-SLAM: A stereo vision and semantic segmentation approach for SLAM in dynamic outdoor environments. (arXiv:2010.09857v1 [cs.RO])</h2>
<h3>Daniela Esparza, Gerardo Flores</h3>
<p>Commonly, SLAM algorithms are focused on a static environment, however, there
are several scenes where dynamic objects are present. This work presents the
STDyn-SLAM an image feature-based SLAM system working on dynamic environments
using a series of sub-systems, like optic flow, orb features extraction, visual
odometry, and convolutional neural networks to discern moving objects in the
scene. The neural network is used to support object detection and segmentation
to avoid erroneous maps and wrong system localization. The STDyn-SLAM employs a
stereo pair and is developed for outdoor environments. Moreover, the processing
time of the proposed system is fast enough to run in real-time as it was
demonstrated through the experiments given in real dynamic outdoor
environments. Further, we compare our SLAM with state-of-the-art methods
achieving promising results.
</p>
<a href="http://arxiv.org/abs/2010.09857" target="_blank">arXiv:2010.09857</a> [<a href="http://arxiv.org/pdf/2010.09857" target="_blank">pdf</a>]

<h2>Failure Prediction by Confidence Estimation of Uncertainty-Aware Dirichlet Networks. (arXiv:2010.09865v1 [cs.LG])</h2>
<h3>Theodoros Tsiligkaridis</h3>
<p>Reliably assessing model confidence in deep learning and predicting errors
likely to be made are key elements in providing safety for model deployment, in
particular for applications with dire consequences. In this paper, it is first
shown that uncertainty-aware deep Dirichlet neural networks provide an improved
separation between the confidence of correct and incorrect predictions in the
true class probability (TCP) metric. Second, as the true class is unknown at
test time, a new criterion is proposed for learning the true class probability
by matching prediction confidence scores while taking imbalance and TCP
constraints into account for correct predictions and failures. Experimental
results show our method improves upon the maximum class probability (MCP)
baseline and predicted TCP for standard networks on several image
classification tasks with various network architectures.
</p>
<a href="http://arxiv.org/abs/2010.09865" target="_blank">arXiv:2010.09865</a> [<a href="http://arxiv.org/pdf/2010.09865" target="_blank">pdf</a>]

<h2>DeepApple: Deep Learning-based Apple Detection using a Suppression Mask R-CNN. (arXiv:2010.09870v1 [cs.CV])</h2>
<h3>Pengyu Chu, Zhaojian Li, Kyle Lammers, Renfu Lu, Xiaoming Liu</h3>
<p>Robotic apple harvesting has received much research attention in the past few
years due to growing shortage and rising cost in labor. One key enabling
technology towards automated harvesting is accurate and robust apple detection,
which poses great challenges as a result of the complex orchard environment
that involves varying lighting conditions and foliage/branch occlusions. This
letter reports on the development of a novel deep learning-based apple
detection framework named DeepApple. Specifically, we first collect a
comprehensive apple orchard dataset for 'Gala' and 'Blondee' apples, using a
color camera, under different lighting conditions (sunny vs. overcast and front
lighting vs. back lighting). We then develop a novel suppression Mask R-CNN for
apple detection, in which a suppression branch is added to the standard Mask
R-CNN to suppress non-apple features generated by the original network.
Comprehensive evaluations are performed, which show that the developed
suppression Mask R-CNN network outperforms state-of-the-art models with a
higher F1-score of 0.905 and a detection time of 0.25 second per frame on a
standard desktop computer.
</p>
<a href="http://arxiv.org/abs/2010.09870" target="_blank">arXiv:2010.09870</a> [<a href="http://arxiv.org/pdf/2010.09870" target="_blank">pdf</a>]

<h2>ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction. (arXiv:2010.09885v1 [cs.LG])</h2>
<h3>Seyone Chithrananda, Gabe Grand, Bharath Ramsundar</h3>
<p>GNNs and chemical fingerprints are the predominant approaches to representing
molecules for property prediction. However, in NLP, transformers have become
the de-facto standard for representation learning thanks to their strong
downstream task transfer. In parallel, the software ecosystem around
transformers is maturing rapidly, with libraries like HuggingFace and BertViz
enabling streamlined training and introspection. In this work, we make one of
the first attempts to systematically evaluate transformers on molecular
property prediction tasks via our ChemBERTa model. ChemBERTa scales well with
pretraining dataset size, offering competitive downstream performance on
MoleculeNet and useful attention-based visualization modalities. Our results
suggest that transformers offer a promising avenue of future work for molecular
representation learning and property prediction. To facilitate these efforts,
we release a curated dataset of 77M SMILES from PubChem suitable for
large-scale self-supervised pretraining.
</p>
<a href="http://arxiv.org/abs/2010.09885" target="_blank">arXiv:2010.09885</a> [<a href="http://arxiv.org/pdf/2010.09885" target="_blank">pdf</a>]

<h2>How much progress have we made in neural network training? A New Evaluation Protocol for Benchmarking Optimizers. (arXiv:2010.09889v1 [cs.LG])</h2>
<h3>Yuanhao Xiong, Xuanqing Liu, Li-Cheng Lan, Yang You, Si Si, Cho-Jui Hsieh</h3>
<p>Many optimizers have been proposed for training deep neural networks, and
they often have multiple hyperparameters, which make it tricky to benchmark
their performance. In this work, we propose a new benchmarking protocol to
evaluate both end-to-end efficiency (training a model from scratch without
knowing the best hyperparameter) and data-addition training efficiency (the
previously selected hyperparameters are used for periodically re-training the
model with newly collected data). For end-to-end efficiency, unlike previous
work that assumes random hyperparameter tuning, which over-emphasizes the
tuning time, we propose to evaluate with a bandit hyperparameter tuning
strategy. A human study is conducted to show that our evaluation protocol
matches human tuning behavior better than the random search. For data-addition
training, we propose a new protocol for assessing the hyperparameter
sensitivity to data shift. We then apply the proposed benchmarking framework to
7 optimizers and various tasks, including computer vision, natural language
processing, reinforcement learning, and graph mining. Our results show that
there is no clear winner across all the tasks.
</p>
<a href="http://arxiv.org/abs/2010.09889" target="_blank">arXiv:2010.09889</a> [<a href="http://arxiv.org/pdf/2010.09889" target="_blank">pdf</a>]

<h2>Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration. (arXiv:2010.09890v1 [cs.AI])</h2>
<h3>Xavier Puig, Tianmin Shu, Shuang Li, Zilin Wang, Joshua B. Tenenbaum, Sanja Fidler, Antonio Torralba</h3>
<p>In this paper, we introduce Watch-And-Help (WAH), a challenge for testing
social intelligence in agents. In WAH, an AI agent needs to help a human-like
agent perform a complex household task efficiently. To succeed, the AI agent
needs to i) understand the underlying goal of the task by watching a single
demonstration of the human-like agent performing the same task (social
perception), and ii) coordinate with the human-like agent to solve the task in
an unseen environment as fast as possible (human-AI collaboration). For this
challenge, we build VirtualHome-Social, a multi-agent household environment,
and provide a benchmark including both planning and learning based baselines.
We evaluate the performance of AI agents with the human-like agent as well as
with real humans using objective metrics and subjective user ratings.
Experimental results demonstrate that the proposed challenge and virtual
environment enable a systematic evaluation on the important aspects of machine
social intelligence at scale.
</p>
<a href="http://arxiv.org/abs/2010.09890" target="_blank">arXiv:2010.09890</a> [<a href="http://arxiv.org/pdf/2010.09890" target="_blank">pdf</a>]

<h2>Understanding YouTube Communities via Subscription-based Channel Embeddings. (arXiv:2010.09892v1 [cs.LG])</h2>
<h3>Sam Clark, Anna Zaitsev</h3>
<p>YouTube is an important source of news and entertainment worldwide, but the
scale makes it challenging to study the ideas and topics being discussed on the
platform. This paper presents new methods to discover and classify YouTube
channels which enable the analysis of communities and categories on the
platform using orders of magnitude more channels than have been used in
previous studies. Instead of using channel and video data as features for
classification as other researchers have, these methods use a self-supervised
learning approach that leverages the public subscription pages of commenters.
We test the classification method on the task of predicting the political lean
of YouTube news channels and find that it outperforms the previous best model
on the task. Further experiments also show that there are important advantages
to using commenter subscriptions to discover channels. The subscription data,
along with an iterative approach, is applied to discover, to our current
understanding, the most comprehensive set of English language socio-political
YouTube channels yet to be analyzed. We experiment with predicting more fine
grained political tags for channels using a previously annotated dataset and
find that our model performs better than the average individual human reviewer
for most of the top tags. This fine grained political tag model is then applied
to the newly discovered English language socio-political channels to create a
new dataset to analyze the amount of traffic going to different political
content. The data shows that some tags, such as "Partisan Right" and
"Conspiracy", are significantly under represented when looking only at the most
popular socio-political channels. Through the use of our methods, we are able
to get a much more accurate picture of the size of these communities on
YouTube.
</p>
<a href="http://arxiv.org/abs/2010.09892" target="_blank">arXiv:2010.09892</a> [<a href="http://arxiv.org/pdf/2010.09892" target="_blank">pdf</a>]

<h2>LT-GAN: Self-Supervised GAN with Latent Transformation Detection. (arXiv:2010.09893v1 [cs.CV])</h2>
<h3>Parth Patel, Nupur Kumari, Mayank Singh, Balaji Krishnamurthy</h3>
<p>Generative Adversarial Networks (GANs) coupled with self-supervised tasks
have shown promising results in unconditional and semi-supervised image
generation. We propose a self-supervised approach (LT-GAN) to improve the
generation quality and diversity of images by estimating the GAN-induced
transformation (i.e. transformation induced in the generated images by
perturbing the latent space of generator). Specifically, given two pairs of
images where each pair comprises of a generated image and its transformed
version, the self-supervision task aims to identify whether the latent
transformation applied in the given pair is same to that of the other pair.
Hence, this auxiliary loss encourages the generator to produce images that are
distinguishable by the auxiliary network, which in turn promotes the synthesis
of semantically consistent images with respect to latent transformations. We
show the efficacy of this pretext task by improving the image generation
quality in terms of FID on state-of-the-art models for both conditional and
unconditional settings on CIFAR-10, CelebA-HQ and ImageNet datasets. Moreover,
we empirically show that LT-GAN helps in improving controlled image editing for
CelebA-HQ and ImageNet over baseline models. We experimentally demonstrate that
our proposed LT self-supervision task can be effectively combined with other
state-of-the-art training techniques for added benefits. Consequently, we show
that our approach achieves the new state-of-the-art FID score of 9.8 on
conditional CIFAR-10 image generation.
</p>
<a href="http://arxiv.org/abs/2010.09893" target="_blank">arXiv:2010.09893</a> [<a href="http://arxiv.org/pdf/2010.09893" target="_blank">pdf</a>]

<h2>Multi-Window Data Augmentation Approach for Speech Emotion Recognition. (arXiv:2010.09895v1 [cs.SD])</h2>
<h3>Sarala Padi, Dinesh Manocha, Ram D.Sriram</h3>
<p>We present a novel, Multi-window Data Augmentation (MWA-SER), approach for
speech emotion recognition. MWA-SER is a unimodal approach that focuses on two
key concepts; designing the speech augmentation method to generate additional
data samples and building the deep learning models to recognize the underlying
emotion of an audio signal. We propose a novel multi-window augmentation method
to extract more audio features from the speech signal by employing multiple
window sizes into the audio feature extraction process. We show that our
proposed augmentation method with minimally extracted features combined with a
deep learning model improves the performance of speech emotion recognition. We
demonstrate the performance of our MWA-SER approach on the IEMOCAP corpus and
show that our approach outperforms previous methods, exhibiting 65% accuracy
and 73% weighted average precision, a 6% and a 9% absolute improvements on
accuracy and weighted average precision, respectively. We also demonstrate that
with the minimum number of features (34), our model outperforms other models
that use more than 900 features with higher modeling complexity. Furthermore,
we also evaluate our model by replacing the "happy" category of emotion with
"excited". To the best of our knowledge, our approach achieves state-of-the-art
results with 66% accuracy and 68% weighted average precision, which is an 11%
and a 14% absolute improvement on accuracy and weighted average precision,
respectively.
</p>
<a href="http://arxiv.org/abs/2010.09895" target="_blank">arXiv:2010.09895</a> [<a href="http://arxiv.org/pdf/2010.09895" target="_blank">pdf</a>]

<h2>DQN-AF: Deep Q-Network based Adaptive Forwarding Strategy for Named Data Networking. (arXiv:2010.09897v1 [cs.NI])</h2>
<h3>Ygor Amaral B. L. de Sena, Kelvin Lopes Dias, Cleber Zanchettin</h3>
<p>NDN has gained significant attention due to the appearance of several
unforeseen design flaws that became evident with new communication scenarios.
Among its many features, the two standard NDN forwarding strategies are not
adaptive, causing performance degradation in several scenarios. This paper
proposes an adaptive forwarding strategy based on deep reinforcement learning
with Deep Q-Network, which analyzes the NDN router interface metrics without
creating signaling overhead or harming the design principles from the NDN
architecture, besides showing significant performance gains compared to the
standard strategies.
</p>
<a href="http://arxiv.org/abs/2010.09897" target="_blank">arXiv:2010.09897</a> [<a href="http://arxiv.org/pdf/2010.09897" target="_blank">pdf</a>]

<h2>Robust & Asymptotically Locally Optimal UAV-Trajectory Generation Based on Spline Subdivision. (arXiv:2010.09904v1 [cs.RO])</h2>
<h3>Ruiqi Ni, Teseo Schneider, Daniele Panozzo, Zherong Pan, Xifeng Gao</h3>
<p>Generating locally optimal UAV-trajectories is challenging due to the
non-convex constraints of collision avoidance and actuation limits. We present
the first local, optimization-based UAV-trajectory generator that
simultaneously guarantees validity and asymptotic optimality.
\textit{Validity:} Given a feasible initial guess, our algorithm guarantees the
satisfaction of all constraints throughout the process of optimization.
\textit{Asymptotic Optimality:} We use a conservative piecewise approximation
of the trajectory with automatically adjustable resolution of its
discretization. The trajectory converges under refinement to the first-order
stationary point of the exact non-convex programming problem. Our method has
additional practical advantages including joint optimality in terms of
trajectory and time-allocation, and robustness to challenging environments as
demonstrated in our experiments.
</p>
<a href="http://arxiv.org/abs/2010.09904" target="_blank">arXiv:2010.09904</a> [<a href="http://arxiv.org/pdf/2010.09904" target="_blank">pdf</a>]

<h2>SmartTriage: A system for personalized patient data capture, documentation generation, and decision support. (arXiv:2010.09905v1 [cs.CL])</h2>
<h3>Ilya Valmianski, Ian M. Finn, Nave Frost, Yang Wang, Baodong Liu, James J. Zhu, Sunil Karumuri, Daniel S. Zisook</h3>
<p>Symptom checkers have emerged as an important tool for collecting symptoms
and diagnosing patients, minimizing the involvement of clinical personnel. We
developed a machine-learning-backed system, SmartTriage, which goes beyond
conventional symptom checking through a tight bi-directional integration with
the electronic medical record (EMR). Conditioned on EMR-derived patient
history, our system identifies the patient's chief complaint from a free-text
entry and then asks a series of discrete questions to obtain relevant
symptomatology. The patient-specific data are used to predict detailed
ICD-10-CM codes as well as medication, laboratory, and imaging orders. Patient
responses and clinical decision support (CDS) predictions are then inserted
back into the EMR. To train the machine learning components of SmartTriage, we
employed novel data sets of over 25 million primary care encounters and 1
million patient free-text reason-for-visit entries. These data sets were used
to construct: (1) a long short-term memory (LSTM) based patient history
representation, (2) a fine-tuned transformer model for chief complaint
extraction, (3) a random forest model for question sequencing, and (4) a
feed-forward network for CDS predictions. We also present the full production
architecture for the pilot deployment of SmartTriage that covers 337 patient
chief complaints.
</p>
<a href="http://arxiv.org/abs/2010.09905" target="_blank">arXiv:2010.09905</a> [<a href="http://arxiv.org/pdf/2010.09905" target="_blank">pdf</a>]

<h2>Color Image Segmentation Metrics. (arXiv:2010.09907v1 [cs.CV])</h2>
<h3>Majid Harouni, Hadi Yazdani Baghmaleki</h3>
<p>An automatic image segmentation procedure is an inevitable part of many image
analyses and computer vision which deeply affect the rest of the system;
therefore, a set of interactive segmentation evaluation methods can
substantially simplify the system development process. This entry presents the
state of the art of quantitative evaluation metrics for color image
segmentation methods by performing an analytical and comparative review of the
measures. The decision-making process in selecting a suitable evaluation metric
is still very serious because each metric tends to favor a different
segmentation method for each benchmark dataset. Furthermore, a conceptual
comparison of these metrics is provided at a high level of abstraction and is
discussed for understanding the quantitative changes in different image
segmentation results.
</p>
<a href="http://arxiv.org/abs/2010.09907" target="_blank">arXiv:2010.09907</a> [<a href="http://arxiv.org/pdf/2010.09907" target="_blank">pdf</a>]

<h2>Product Manifold Learning. (arXiv:2010.09908v1 [cs.LG])</h2>
<h3>Sharon Zhang, Amit Moscovich, Amit Singer</h3>
<p>We consider problems of dimensionality reduction and learning data
representations for continuous spaces with two or more independent degrees of
freedom. Such problems occur, for example, when observing shapes with several
components that move independently. Mathematically, if the parameter space of
each continuous independent motion is a manifold, then their combination is
known as a product manifold. In this paper, we present a new paradigm for
non-linear independent component analysis called manifold factorization. Our
factorization algorithm is based on spectral graph methods for manifold
learning and the separability of the Laplacian operator on product spaces.
Recovering the factors of a manifold yields meaningful lower-dimensional
representations and provides a new way to focus on particular aspects of the
data space while ignoring others. We demonstrate the potential use of our
method for an important and challenging problem in structural biology: mapping
the motions of proteins and other large molecules using cryo-electron
microscopy datasets.
</p>
<a href="http://arxiv.org/abs/2010.09908" target="_blank">arXiv:2010.09908</a> [<a href="http://arxiv.org/pdf/2010.09908" target="_blank">pdf</a>]

<h2>The Role of Robotics in Infectious Disease Crises. (arXiv:2010.09909v1 [cs.RO])</h2>
<h3>Gregory Hager, Vijay Kumar, Robin Murphy, Daniela Rus, Russell Taylor</h3>
<p>The recent coronavirus pandemic has highlighted the many challenges faced by
the healthcare, public safety, and economic systems when confronted with a
surge in patients that require intensive treatment and a population that must
be quarantined or shelter in place. The most obvious and pressing challenge is
taking care of acutely ill patients while managing spread of infection within
the care facility, but this is just the tip of the iceberg if we consider what
could be done to prepare in advance for future pandemics. Beyond the obvious
need for strengthening medical knowledge and preparedness, there is a
complementary need to anticipate and address the engineering challenges
associated with infectious disease emergencies. Robotic technologies are
inherently programmable, and robotic systems have been adapted and deployed, to
some extent, in the current crisis for such purposes as transport, logistics,
and disinfection. As technical capabilities advance and as the installed base
of robotic systems increases in the future, they could play a much more
significant role in future crises. This report is the outcome of a virtual
workshop co-hosted by the National Academy of Engineering (NAE) and the
Computing Community Consortium (CCC) held on July 9-10, 2020. The workshop
consisted of over forty participants including representatives from the
engineering/robotics community, clinicians, critical care workers, public
health and safety experts, and emergency responders. It identifies key
challenges faced by healthcare responders and the general population and then
identifies robotic/technological responses to these challenges. Then it
identifies the key research/knowledge barriers that need to be addressed in
developing effective, scalable solutions. Finally, the report ends with the
following recommendations on how to implement this strategy.
</p>
<a href="http://arxiv.org/abs/2010.09909" target="_blank">arXiv:2010.09909</a> [<a href="http://arxiv.org/pdf/2010.09909" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Adaptive Network Slicing in 5G for Intelligent Vehicular Systems and Smart Cities. (arXiv:2010.09916v1 [cs.NI])</h2>
<h3>Almuthanna Nassar, Yasin Yilmaz</h3>
<p>Intelligent vehicular systems and smart city applications are the fastest
growing Internet of things (IoT) implementations at a compound annual growth
rate of 30%. In view of the recent advances in IoT devices and the emerging new
breed of IoT applications driven by artificial intelligence (AI), fog radio
access network (F-RAN) has been recently introduced for the fifth generation
(5G) wireless communications to overcome the latency limitations of cloud-RAN
(C-RAN). We consider the network slicing problem of allocating the limited
resources at the network edge (fog nodes) to vehicular and smart city users
with heterogeneous latency and computing demands in dynamic environments. We
develop a network slicing model based on a cluster of fog nodes (FNs)
coordinated with an edge controller (EC) to efficiently utilize the limited
resources at the network edge. For each service request in a cluster, the EC
decides which FN to execute the task, i.e., locally serve the request at the
edge, or to reject the task and refer it to the cloud. We formulate the problem
as infinite-horizon Markov decision process (MDP) and propose a deep
reinforcement learning (DRL) solution to adaptively learn the optimal slicing
policy. The performance of the proposed DRL-based slicing method is evaluated
by comparing it with other slicing approaches in dynamic environments and for
different scenarios of design objectives. Comprehensive simulation results
corroborate that the proposed DRL-based EC quickly learns the optimal policy
through interaction with the environment, which enables adaptive and automated
network slicing for efficient resource allocation in dynamic vehicular and
smart city environments.
</p>
<a href="http://arxiv.org/abs/2010.09916" target="_blank">arXiv:2010.09916</a> [<a href="http://arxiv.org/pdf/2010.09916" target="_blank">pdf</a>]

<h2>Optimal Decision Lists using SAT. (arXiv:2010.09919v1 [cs.AI])</h2>
<h3>Jinqiang Yu, Alexey Ignatiev, Pierre Le Bodic, Peter J. Stuckey</h3>
<p>Decision lists are one of the most easily explainable machine learning
models. Given the renewed emphasis on explainable machine learning decisions,
this machine learning model is increasingly attractive, combining small size
and clear explainability. In this paper, we show for the first time how to
construct optimal "perfect" decision lists which are perfectly accurate on the
training data, and minimal in size, making use of modern SAT solving
technology. We also give a new method for determining optimal sparse decision
lists, which trade off size and accuracy. We contrast the size and test
accuracy of optimal decisions lists versus optimal decision sets, as well as
other state-of-the-art methods for determining optimal decision lists. We also
examine the size of average explanations generated by decision sets and
decision lists.
</p>
<a href="http://arxiv.org/abs/2010.09919" target="_blank">arXiv:2010.09919</a> [<a href="http://arxiv.org/pdf/2010.09919" target="_blank">pdf</a>]

<h2>Anti-Distillation: Improving reproducibility of deep networks. (arXiv:2010.09923v1 [cs.LG])</h2>
<h3>Gil I. Shamir, Lorenzo Coviello</h3>
<p>Deep networks have been revolutionary in improving performance of machine
learning and artificial intelligence systems. Their high prediction accuracy,
however, comes at a price of \emph{model irreproducibility\/} in very high
levels that do not occur with classical linear models. Two models, even if they
are supposedly identical, with identical architecture and identical trained
parameter sets, and that are trained on the same set of training examples,
while possibly providing identical average prediction accuracies, may predict
very differently on individual, previously unseen, examples. \emph{Prediction
differences\/} may be as large as the order of magnitude of the predictions
themselves. Ensembles have been shown to somewhat mitigate this behavior, but
without an extra push, may not be utilizing their full potential. In this work,
a novel approach, \emph{Anti-Distillation\/}, is proposed to address
irreproducibility in deep networks, where ensemble models are used to generate
predictions. Anti-Distillation forces ensemble components away from one another
by techniques like de-correlating their outputs over mini-batches of examples,
forcing them to become even more different and more diverse. Doing so enhances
the benefit of ensembles, making the final predictions more reproducible.
Empirical results demonstrate substantial prediction difference reductions
achieved by Anti-Distillation on benchmark and real datasets.
</p>
<a href="http://arxiv.org/abs/2010.09923" target="_blank">arXiv:2010.09923</a> [<a href="http://arxiv.org/pdf/2010.09923" target="_blank">pdf</a>]

<h2>Hierarchical Paired Channel Fusion Network for Street Scene Change Detection. (arXiv:2010.09925v1 [cs.CV])</h2>
<h3>Yinjie Lei, Duo Peng, Pingping Zhang, Qiuhong Ke, Haifeng Li</h3>
<p>Street Scene Change Detection (SSCD) aims to locate the changed regions
between a given street-view image pair captured at different times, which is an
important yet challenging task in the computer vision community. The intuitive
way to solve the SSCD task is to fuse the extracted image feature pairs, and
then directly measure the dissimilarity parts for producing a change map.
Therefore, the key for the SSCD task is to design an effective feature fusion
method that can improve the accuracy of the corresponding change maps. To this
end, we present a novel Hierarchical Paired Channel Fusion Network (HPCFNet),
which utilizes the adaptive fusion of paired feature channels. Specifically,
the features of a given image pair are jointly extracted by a Siamese
Convolutional Neural Network (SCNN) and hierarchically combined by exploring
the fusion of channel pairs at multiple feature levels. In addition, based on
the observation that the distribution of scene changes is diverse, we further
propose a Multi-Part Feature Learning (MPFL) strategy to detect diverse
changes. Based on the MPFL strategy, our framework achieves a novel approach to
adapt to the scale and location diversities of the scene change regions.
Extensive experiments on three public datasets (i.e., PCD, VL-CMU-CD and
CDnet2014) demonstrate that the proposed framework achieves superior
performance which outperforms other state-of-the-art methods with a
considerable margin.
</p>
<a href="http://arxiv.org/abs/2010.09925" target="_blank">arXiv:2010.09925</a> [<a href="http://arxiv.org/pdf/2010.09925" target="_blank">pdf</a>]

<h2>Smooth activations and reproducibility in deep networks. (arXiv:2010.09931v1 [cs.LG])</h2>
<h3>Gil I. Shamir, Dong Lin, Lorenzo Coviello</h3>
<p>Deep networks are gradually penetrating almost every domain in our lives due
to their amazing success. However, with substantive performance accuracy
improvements comes the price of \emph{irreproducibility}. Two identical models,
trained on the exact same training dataset may exhibit large differences in
predictions on individual examples even when average accuracy is similar,
especially when trained on highly distributed parallel systems. The popular
Rectified Linear Unit (ReLU) activation has been key to recent success of deep
networks. We demonstrate, however, that ReLU is also a catalyzer to
irreproducibility in deep networks. We show that not only can activations
smoother than ReLU provide better accuracy, but they can also provide better
accuracy-reproducibility tradeoffs. We propose a new family of activations;
Smooth ReLU (\emph{SmeLU}), designed to give such better tradeoffs, while also
keeping the mathematical expression simple, and thus training speed fast and
implementation cheap. SmeLU is monotonic, mimics ReLU, while providing
continuous gradients, yielding better reproducibility. We generalize SmeLU to
give even more flexibility and then demonstrate that SmeLU and its generalized
form are special cases of a more general methodology of REctified Smooth
Continuous Unit (RESCU) activations. Empirical results demonstrate the superior
accuracy-reproducibility tradeoffs with smooth activations, SmeLU in
particular.
</p>
<a href="http://arxiv.org/abs/2010.09931" target="_blank">arXiv:2010.09931</a> [<a href="http://arxiv.org/pdf/2010.09931" target="_blank">pdf</a>]

<h2>Proximal Policy Gradient: PPO with Policy Gradient. (arXiv:2010.09933v1 [cs.LG])</h2>
<h3>Ju-Seung Byun, Byungmoon Kim, Huamin Wang</h3>
<p>In this paper, we propose a new algorithm PPG (Proximal Policy Gradient),
which is close to both VPG (vanilla policy gradient) and PPO (proximal policy
optimization). The PPG objective is a partial variation of the VPG objective
and the gradient of the PPG objective is exactly same as the gradient of the
VPG objective. To increase the number of policy update iterations, we introduce
the advantage-policy plane and design a new clipping strategy. We perform
experiments in OpenAI Gym and Bullet robotics environments for ten random
seeds. The performance of PPG is comparable to PPO, and the entropy decays
slower than PPG. Thus we show that performance similar to PPO can be obtained
by using the gradient formula from the original policy gradient theorem.
</p>
<a href="http://arxiv.org/abs/2010.09933" target="_blank">arXiv:2010.09933</a> [<a href="http://arxiv.org/pdf/2010.09933" target="_blank">pdf</a>]

<h2>Object Permanence Through Audio-Visual Representations. (arXiv:2010.09948v1 [cs.RO])</h2>
<h3>Fanjun Bu, Chien-Ming Huang</h3>
<p>As robots perform manipulation tasks and interact with objects, it is
probable that they accidentally drop objects that subsequently bounce out of
their visual fields (e.g., due to an inadequate grasp of an unfamiliar object).
To enable robots to recover from such errors, we draw upon the concept of
object permanence---objects remain in existence even when they are not being
sensed (e.g., seen) directly. In particular, we developed a multimodal neural
network model---using a partial, observed bounce trajectory and the audio
resulting from drop impact as its inputs---to predict the full bounce
trajectory and the end location of a dropped object. We empirically show that:
(1) our multimodal method predicted end locations close in proximity (i.e.,
within the visual field of the robot's wrist camera) to the actual locations
and (2) the robot was able to retrieve dropped objects by applying minimal
vision-based pick-up adjustments. Additionally, we show that our multimodal
method outperformed the vision-only and audio-only baselines in retrieving
dropped objects. Our results provide insights in enabling object permanence for
robots and offer foundations for ensuring robust robot autonomy in task
execution.
</p>
<a href="http://arxiv.org/abs/2010.09948" target="_blank">arXiv:2010.09948</a> [<a href="http://arxiv.org/pdf/2010.09948" target="_blank">pdf</a>]

<h2>Probabilistic Character Motion Synthesis using a Hierarchical Deep Latent Variable Model. (arXiv:2010.09950v1 [cs.GR])</h2>
<h3>Saeed Ghorbani, Calden Wloka, Ali Etemad, Marcus A. Brubaker, Nikolaus F. Troje</h3>
<p>We present a probabilistic framework to generate character animations based
on weak control signals, such that the synthesized motions are realistic while
retaining the stochastic nature of human movement. The proposed architecture,
which is designed as a hierarchical recurrent model, maps each sub-sequence of
motions into a stochastic latent code using a variational autoencoder extended
over the temporal domain. We also propose an objective function which respects
the impact of each joint on the pose and compares the joint angles based on
angular distance. We use two novel quantitative protocols and human qualitative
assessment to demonstrate the ability of our model to generate convincing and
diverse periodic and non-periodic motion sequences without the need for strong
control signals.
</p>
<a href="http://arxiv.org/abs/2010.09950" target="_blank">arXiv:2010.09950</a> [<a href="http://arxiv.org/pdf/2010.09950" target="_blank">pdf</a>]

<h2>Region-specific Dictionary Learning-based Low-dose Thoracic CT Reconstruction. (arXiv:2010.09953v1 [physics.med-ph])</h2>
<h3>Qiong Xu, Jeff Wang, Hiroki Shirato, Lei Xing</h3>
<p>This paper presents a dictionary learning-based method with region-specific
image patches to maximize the utility of the powerful sparse data processing
technique for CT image reconstruction. Considering heterogeneous distributions
of image features and noise in CT, region-specific customization of
dictionaries is utilized in iterative reconstruction. Thoracic CT images are
partitioned into several regions according to their structural and noise
characteristics. Dictionaries specific to each region are then learned from the
segmented thoracic CT images and applied to subsequent image reconstruction of
the region. Parameters for dictionary learning and sparse representation are
determined according to the structural and noise properties of each region. The
proposed method results in better performance than the conventional
reconstruction based on a single dictionary in recovering structures and
suppressing noise in both simulation and human CT imaging. Quantitatively, the
simulation study shows maximum improvement of image quality for the whole
thorax can achieve 4.88% and 11.1% in terms of the Structure-SIMilarity (SSIM)
and Root-Mean-Square Error (RMSE) indices, respectively. For human imaging
data, it is found that the structures in the lungs and heart can be better
recovered, while simultaneously decreasing noise around the vertebra
effectively. The proposed strategy takes into account inherent regional
differences inside of the reconstructed object and leads to improved images.
The method can be readily extended to CT imaging of other anatomical regions
and other applications.
</p>
<a href="http://arxiv.org/abs/2010.09953" target="_blank">arXiv:2010.09953</a> [<a href="http://arxiv.org/pdf/2010.09953" target="_blank">pdf</a>]

<h2>Survivable Hyper-Redundant Robotic Arm with Bayesian Policy Morphing. (arXiv:2010.09964v1 [cs.RO])</h2>
<h3>Sayyed Jaffar Ali Raza, Apan Dastider, Mingjie Lin</h3>
<p>In this paper we present a Bayesian reinforcement learning framework that
allows robotic manipulators to adaptively recover from random mechanical
failures autonomously, hence being survivable. To this end, we formulate the
framework of Bayesian Policy Morphing (BPM) that enables a robot agent to
self-modify its learned policy after the diminution of its maneuvering
dimensionality. We build upon existing actor-critic framework, and extend it to
perform policy gradient updates as posterior learning, taking past policy
updates as prior distributions. We show that policy search, in the direction
biased by prior experience, significantly improves learning efficiency in terms
of sampling requirements. We demonstrate our results on an 8-DOF robotic arm
with our algorithm of BPM, while intentionally disabling random joints with
different damage types like unresponsive joints, constant offset errors and
angular imprecision. Our results have shown that, even with physical damages,
the robotic arm can still successfully maintain its functionality to accurately
locate and grasp a given target object.
</p>
<a href="http://arxiv.org/abs/2010.09964" target="_blank">arXiv:2010.09964</a> [<a href="http://arxiv.org/pdf/2010.09964" target="_blank">pdf</a>]

<h2>Calliope: Automatic Visual Data Story Generation from a Spreadsheet. (arXiv:2010.09975v1 [cs.HC])</h2>
<h3>Danqing Shi, Xinyue Xu, Fuling Sun, Yang Shi, Nan Cao</h3>
<p>Visual data stories shown in the form of narrative visualizations such as a
poster or a data video, are frequently used in data-oriented storytelling to
facilitate the understanding and memorization of the story content. Although
useful, technique barriers, such as data analysis, visualization, and
scripting, make the generation of a visual data story difficult. Existing
authoring tools rely on users' skills and experiences, which are usually
inefficient and still difficult. In this paper, we introduce a novel visual
data story generating system, Calliope, which creates visual data stories from
an input spreadsheet through an automatic process and facilities the easy
revision of the generated story based on an online story editor. Particularly,
Calliope incorporates a new logic-oriented Monte Carlo tree search algorithm
that explores the data space given by the input spreadsheet to progressively
generate story pieces (i.e., data facts) and organize them in a logical order.
The importance of data facts is measured based on information theory, and each
data fact is visualized in a chart and captioned by an automatically generated
description. We evaluate the proposed technique through three example stories,
two controlled experiments, and a series of interviews with 10 domain experts.
Our evaluation shows that Calliope is beneficial to efficient visual data story
generation.
</p>
<a href="http://arxiv.org/abs/2010.09975" target="_blank">arXiv:2010.09975</a> [<a href="http://arxiv.org/pdf/2010.09975" target="_blank">pdf</a>]

<h2>Stronger, Faster and More Explainable: A Graph Convolutional Baseline for Skeleton-based Action Recognition. (arXiv:2010.09978v1 [cs.CV])</h2>
<h3>Yi-Fan Song, Zhang Zhang, Caifeng Shan, Liang Wang</h3>
<p>One essential problem in skeleton-based action recognition is how to extract
discriminative features over all skeleton joints. However, the complexity of
the State-Of-The-Art (SOTA) models of this task tends to be exceedingly
sophisticated and over-parameterized, where the low efficiency in model
training and inference has obstructed the development in the field, especially
for large-scale action datasets. In this work, we propose an efficient but
strong baseline based on Graph Convolutional Network (GCN), where three main
improvements are aggregated, i.e., early fused Multiple Input Branches (MIB),
Residual GCN (ResGCN) with bottleneck structure and Part-wise Attention
(PartAtt) block. Firstly, an MIB is designed to enrich informative skeleton
features and remain compact representations at an early fusion stage. Then,
inspired by the success of the ResNet architecture in Convolutional Neural
Network (CNN), a ResGCN module is introduced in GCN to alleviate computational
costs and reduce learning difficulties in model training while maintain the
model accuracy. Finally, a PartAtt block is proposed to discover the most
essential body parts over a whole action sequence and obtain more explainable
representations for different skeleton action sequences. Extensive experiments
on two large-scale datasets, i.e., NTU RGB+D 60 and 120, validate that the
proposed baseline slightly outperforms other SOTA models and meanwhile requires
much fewer parameters during training and inference procedures, e.g., at most
34 times less than DGNN, which is one of the best SOTA methods.
</p>
<a href="http://arxiv.org/abs/2010.09978" target="_blank">arXiv:2010.09978</a> [<a href="http://arxiv.org/pdf/2010.09978" target="_blank">pdf</a>]

<h2>Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition. (arXiv:2010.09982v1 [cs.CV])</h2>
<h3>Yuqian Fu, Li Zhang, Junke Wang, Yanwei Fu, Yu-Gang Jiang</h3>
<p>Humans can easily recognize actions with only a few examples given, while the
existing video recognition models still heavily rely on the large-scale labeled
data inputs. This observation has motivated an increasing interest in few-shot
video action recognition, which aims at learning new actions with only very few
labeled samples. In this paper, we propose a depth guided Adaptive Meta-Fusion
Network for few-shot video recognition which is termed as AMeFu-Net.
Concretely, we tackle the few-shot recognition problem from three aspects:
firstly, we alleviate this extremely data-scarce problem by introducing depth
information as a carrier of the scene, which will bring extra visual
information to our model; secondly, we fuse the representation of original RGB
clips with multiple non-strictly corresponding depth clips sampled by our
temporal asynchronization augmentation mechanism, which synthesizes new
instances at feature-level; thirdly, a novel Depth Guided Adaptive Instance
Normalization (DGAdaIN) fusion module is proposed to fuse the two-stream
modalities efficiently. Additionally, to better mimic the few-shot recognition
process, our model is trained in the meta-learning way. Extensive experiments
on several action recognition benchmarks demonstrate the effectiveness of our
model.
</p>
<a href="http://arxiv.org/abs/2010.09982" target="_blank">arXiv:2010.09982</a> [<a href="http://arxiv.org/pdf/2010.09982" target="_blank">pdf</a>]

<h2>ivadomed: A Medical Imaging Deep Learning Toolbox. (arXiv:2010.09984v1 [cs.CV])</h2>
<h3>Charley Gros, Andreanne Lemay, Olivier Vincent, Lucas Rouhier, Anthime Bucquet, Joseph Paul Cohen, Julien Cohen-Adad</h3>
<p>ivadomed is an open-source Python package for designing, end-to-end training,
and evaluating deep learning models applied to medical imaging data. The
package includes APIs, command-line tools, documentation, and tutorials.
ivadomed also includes pre-trained models such as spinal tumor segmentation and
vertebral labeling. Original features of ivadomed include a data loader that
can parse image metadata (e.g., acquisition parameters, image contrast,
resolution) and subject metadata (e.g., pathology, age, sex) for custom data
splitting or extra information during training and evaluation. Any dataset
following the Brain Imaging Data Structure (BIDS) convention will be compatible
with ivadomed without the need to manually organize the data, which is
typically a tedious task. Beyond the traditional deep learning methods,
ivadomed features cutting-edge architectures, such as FiLM and HeMis, as well
as various uncertainty estimation methods (aleatoric and epistemic), and losses
adapted to imbalanced classes and non-binary predictions. Each step is
conveniently configurable via a single file. At the same time, the code is
highly modular to allow addition/modification of an architecture or
pre/post-processing steps. Example applications of ivadomed include MRI object
detection, segmentation, and labeling of anatomical and pathological
structures. Overall, ivadomed enables easy and quick exploration of the latest
advances in deep learning for medical imaging applications. ivadomed's main
project page is available at https://ivadomed.org.
</p>
<a href="http://arxiv.org/abs/2010.09984" target="_blank">arXiv:2010.09984</a> [<a href="http://arxiv.org/pdf/2010.09984" target="_blank">pdf</a>]

<h2>Power pooling: An adaptive pooling function for weakly labelled sound event detection. (arXiv:2010.09985v1 [cs.SD])</h2>
<h3>Yuzhuo Liu, Hangting Chen, YunWang, Pengyuan Zhang</h3>
<p>Access to large corpora with strongly labelled sound events is expensive and
difficult in engineering applications. Much research turns to address the
problem of how to detect both the types and the timestamps of sound events with
weak labels that only specify the types. This task can be treated as a multiple
instance learning (MIL) problem, and the key to it is the design of a pooling
function. In this paper, we propose an adaptive power pooling function which
can automatically adapt to various sound sources. On two public datasets, the
proposed power pooling function outperforms the state-of-the-art linear softmax
pooling on both coarsegrained and fine-grained metrics. Notably, it improves
the event-based F1 score (which evaluates the detection of event onsets and
offsets) by 11.4% and 10.2% relative on the two datasets. While this paper
focuses on sound event detection applications, the proposed method can be
applied to MIL tasks in other domains.
</p>
<a href="http://arxiv.org/abs/2010.09985" target="_blank">arXiv:2010.09985</a> [<a href="http://arxiv.org/pdf/2010.09985" target="_blank">pdf</a>]

<h2>L-RED: Efficient Post-Training Detection of Imperceptible Backdoor Attacks without Access to the Training Set. (arXiv:2010.09987v1 [cs.CV])</h2>
<h3>Zhen Xiang, David J. Miller, George Kesidis</h3>
<p>Backdoor attacks (BAs) are an emerging form of adversarial attack typically
against deep neural network image classifiers. The attacker aims to have the
classifier learn to classify to a target class when test images from one or
more source classes contain a backdoor pattern, while maintaining high accuracy
on all clean test images. Reverse-Engineering-based Defenses (REDs) against BAs
do not require access to the training set but only to an independent clean
dataset. Unfortunately, most existing REDs rely on an unrealistic assumption
that all classes except the target class are source classes of the attack. REDs
that do not rely on this assumption often require a large set of clean images
and heavy computation. In this paper, we propose a Lagrangian-based RED against
imperceptible BAs that does not require knowledge of the number of source
classes (or whether an attack is present). Our defense requires very few clean
images to effectively detect BAs and is computationally efficient. Notably, we
detect 56 out of 60 BAs using only two clean image per class in our
experiments.
</p>
<a href="http://arxiv.org/abs/2010.09987" target="_blank">arXiv:2010.09987</a> [<a href="http://arxiv.org/pdf/2010.09987" target="_blank">pdf</a>]

<h2>The Open Catalyst 2020 (OC20) Dataset and Community Challenges. (arXiv:2010.09990v1 [cond-mat.mtrl-sci])</h2>
<h3>Lowik Chanussot, Abhishek Das, Siddharth Goyal, Thibaut Lavril, Muhammed Shuaibi, Morgane Riviere, Kevin Tran, Javier Heras-Domingo, Caleb Ho, Weihua Hu, Aini Palizhati, Anuroop Sriram, Brandon Wood, Junwoong Yoon, Devi Parikh, C. Lawrence Zitnick, Zachary Ulissi</h3>
<p>Catalyst discovery and optimization is key to solving many societal and
energy challenges including solar fuels synthesis, long-term energy storage,
and renewable fertilizer production. Despite considerable effort by the
catalysis community to apply machine learning models to the computational
catalyst discovery process, it remains an open challenge to build models that
can generalize across both elemental compositions of surfaces and adsorbate
identity/configurations, perhaps because datasets have been smaller in
catalysis than related fields. To address this we developed the OC20 dataset,
consisting of 1,281,121 Density Functional Theory (DFT) relaxations
(264,900,500 single point evaluations) across a wide swath of materials,
surfaces, and adsorbates (nitrogen, carbon, and oxygen chemistries). We
supplemented this dataset with randomly perturbed structures, short timescale
molecular dynamics, and electronic structure analyses. The dataset comprises
three central tasks indicative of day-to-day catalyst modeling and comes with
pre-defined train/validation/test splits to facilitate direct comparisons with
future model development efforts. We applied three state-of-the-art graph
neural network models (SchNet, Dimenet, CGCNN) to each of these tasks as
baseline demonstrations for the community to build on. In almost every task, no
upper limit on model size was identified, suggesting that even larger models
are likely to improve on initial results. The dataset and baseline models are
both provided as open resources, as well as a public leader board to encourage
community contributions to solve these important tasks.
</p>
<a href="http://arxiv.org/abs/2010.09990" target="_blank">arXiv:2010.09990</a> [<a href="http://arxiv.org/pdf/2010.09990" target="_blank">pdf</a>]

<h2>Explorable Tone Mapping Operators. (arXiv:2010.10000v1 [cs.CV])</h2>
<h3>Chien-Chuan Su, Ren Wang, Hung-Jin Lin, Yu-Lun Liu, Chia-Ping Chen, Yu-Lin Chang, Soo-Chang Pei</h3>
<p>Tone-mapping plays an essential role in high dynamic range (HDR) imaging. It
aims to preserve visual information of HDR images in a medium with a limited
dynamic range. Although many works have been proposed to provide tone-mapped
results from HDR images, most of them can only perform tone-mapping in a single
pre-designed way. However, the subjectivity of tone-mapping quality varies from
person to person, and the preference of tone-mapping style also differs from
application to application. In this paper, a learning-based multimodal
tone-mapping method is proposed, which not only achieves excellent visual
quality but also explores the style diversity. Based on the framework of
BicycleGAN, the proposed method can provide a variety of expert-level
tone-mapped results by manipulating different latent codes. Finally, we show
that the proposed method performs favorably against state-of-the-art
tone-mapping algorithms both quantitatively and qualitatively.
</p>
<a href="http://arxiv.org/abs/2010.10000" target="_blank">arXiv:2010.10000</a> [<a href="http://arxiv.org/pdf/2010.10000" target="_blank">pdf</a>]

<h2>Contextual Heterogeneous Graph Network for Human-Object Interaction Detection. (arXiv:2010.10001v1 [cs.CV])</h2>
<h3>Hai Wang, Wei-Shi Zheng, Ling Yingbiao</h3>
<p>Human-object interaction(HOI) detection is an important task for
understanding human activity. Graph structure is appropriate to denote the HOIs
in the scene. Since there is an subordination between human and object---human
play subjective role and object play objective role in HOI, the relations
between homogeneous entities and heterogeneous entities in the scene should
also not be equally the same. However, previous graph models regard human and
object as the same kind of nodes and do not consider that the messages are not
equally the same between different entities. In this work, we address such a
problem for HOI task by proposing a heterogeneous graph network that models
humans and objects as different kinds of nodes and incorporates intra-class
messages between homogeneous nodes and inter-class messages between
heterogeneous nodes. In addition, a graph attention mechanism based on the
intra-class context and inter-class context is exploited to improve the
learning. Extensive experiments on the benchmark datasets V-COCO and HICO-DET
demonstrate that the intra-class and inter-class messages are very important in
HOI detection and verify the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2010.10001" target="_blank">arXiv:2010.10001</a> [<a href="http://arxiv.org/pdf/2010.10001" target="_blank">pdf</a>]

<h2>Convolutional-LSTM for Multi-Image to Single Output Medical Prediction. (arXiv:2010.10004v1 [cs.CV])</h2>
<h3>Luis Leal, Marvin Castillo, Fernando Juarez, Erick Ramirez, Mildred Aspuac, Diana Letona</h3>
<p>Medical head CT-scan imaging has been successfully combined with deep
learning for medical diagnostics of head diseases and lesions[1]. State of the
art classification models and algorithms for this task usually are based on 3d
convolution layers for volumetric data on a supervised learning setting (1
input volume, 1 prediction per patient) or 2d convolution layers in a
supervised setting (1 input image, 1 prediction per image). However a very
common scenario in developing countries is to have the volume metadata lost due
multiple reasons for example formatting conversion in images (for example
.dicom to jpg), in this scenario the doctor analyses the collection of images
and then emits a single diagnostic for the patient (with possibly an unfixed
and variable number of images per patient) , this prevents it from being
possible to use state of the art 3d models, but also is not possible to convert
it to a supervised problem in a (1 image,1 diagnostic) setting because
different angles or positions of the images for a single patient may not
contain the disease or lesion. In this study we propose a solution for this
scenario by combining 2d convolutional[2] models with sequence models which
generate a prediction only after all images have been processed by the model
for a given patient \(i\), this creates a multi-image to single-diagnostic
setting \(y^i=f(x_1,x_2,..,x_n)\) where \(n\) may be different between
patients. The experimental results demonstrate that it is possible to get a
multi-image to single diagnostic model which mimics human doctor diagnostic
process: evaluate the collection of patient images and then use important
information in memory to decide a single diagnostic for the patient.
</p>
<a href="http://arxiv.org/abs/2010.10004" target="_blank">arXiv:2010.10004</a> [<a href="http://arxiv.org/pdf/2010.10004" target="_blank">pdf</a>]

<h2>SWIPENET: Object detection in noisy underwater images. (arXiv:2010.10006v1 [cs.CV])</h2>
<h3>Long Chen, Feixiang Zhou, Shengke Wang, Junyu Dong, Ning Li, Haiping Ma, Xin Wang, Huiyu Zhou</h3>
<p>In recent years, deep learning based object detection methods have achieved
promising performance in controlled environments. However, these methods lack
sufficient capabilities to handle underwater object detection due to these
challenges: (1) images in the underwater datasets and real applications are
blurry whilst accompanying severe noise that confuses the detectors and (2)
objects in real applications are usually small. In this paper, we propose a
novel Sample-WeIghted hyPEr Network (SWIPENET), and a robust training paradigm
named Curriculum Multi-Class Adaboost (CMA), to address these two problems at
the same time. Firstly, the backbone of SWIPENET produces multiple high
resolution and semantic-rich Hyper Feature Maps, which significantly improve
small object detection. Secondly, a novel sample-weighted detection loss
function is designed for SWIPENET, which focuses on learning high weight
samples and ignore learning low weight samples. Moreover, inspired by the human
education process that drives the learning from easy to hard concepts, we here
propose the CMA training paradigm that first trains a clean detector which is
free from the influence of noisy data. Then, based on the clean detector,
multiple detectors focusing on learning diverse noisy data are trained and
incorporated into a unified deep ensemble of strong noise immunity. Experiments
on two underwater robot picking contest datasets (URPC2017 and URPC2018) show
that the proposed SWIPENET+CMA framework achieves better accuracy in object
detection against several state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2010.10006" target="_blank">arXiv:2010.10006</a> [<a href="http://arxiv.org/pdf/2010.10006" target="_blank">pdf</a>]

<h2>Algodynamics: Teaching Algorithms using Interactive Transition Systems. (arXiv:2010.10015v1 [cs.CY])</h2>
<h3>Venkatesh Choppella, Viswanath Kasturi, Mrityunjay Kumar, Ojas Mohril</h3>
<p>The importance of algorithms and data structures in computer science
curricula has been amply recognized. For many students, however, gaining a good
understanding of algorithms remains a challenge.

Because of the automated nature of sequential algorithms. there is an
inherent tension in directly applying the `learning by doing' approach. This
partly explains the limitations of efforts like algorithm animation and code
tracing.

Algodynamics, the approach we propose and advocate, situates algorithms
within the framework of transition systems and their dynamics and offers an
attractive approach for teaching algorithms. Algodynamics starts with the
premise that the key ideas underlying an algorithm can be identified and
packaged into interactive transition systems. The algorithm when `opened up',
reveals a transition system, shorn of most control aspects, enriched instead
with interaction. The design of an algorithm can be carried out by constructing
a series of interactive systems, progressively trading interactivity with
automation. These transition systems constitute a family of notional machines.

We illustrate the algodynamics approach by considering Bubblesort. A sequence
of five interactive transition systems culminate in the classic Bubblesort
algorithm. The exercise of constructing the individual systems also pays off
when coding Bubblesort: a highly modular implementation whose primitives are
borrowed from the transition systems. The transition systems used for
Bubblesort have been implemented as interactive experiments. These web based
implementations are easy to build. The simplicity and flexibility afforded by
the algodynamics framework makes it an attractive option to teach algorithms in
an interactive way.
</p>
<a href="http://arxiv.org/abs/2010.10015" target="_blank">arXiv:2010.10015</a> [<a href="http://arxiv.org/pdf/2010.10015" target="_blank">pdf</a>]

<h2>Early Anomaly Detection by Learning and Forecasting Behavior. (arXiv:2010.10016v1 [cs.LG])</h2>
<h3>Tong Zhao, Bo Ni, Wenhao Yu, Meng Jiang</h3>
<p>Graph anomaly detection systems aim at identifying suspicious accounts or
behaviors on social networking sites and e-commercial platforms. Detecting
anomalous users at an early stage is crucial to minimize financial loss. When a
great amount of observed behavior data are available, existing methods perform
effectively though it may have been too late to avoid the loss. However, their
performance would become unsatisfactory when the observed data are quite
limited at the early stage. In this work, we propose Eland, a novel framework
that uses behavior data augmentation for early anomaly detection. It has a
Seq2Seq-based behavior predictor that predicts (i) whether a user will adopt a
new item or an item that has been historically adopted and (ii) which item will
be adopted. Eland exploits the mutual enhancement between behavior prediction
and graph anomaly detection. The behavior graph is augmented with the predicted
behaviors such that the graph-based anomaly detection methods can achieve
better performance, and the detection results can support the behavior
predictor in return. Experiments show that Eland improves the performance of a
variety of graph-based anomaly detection methods. With the augmented methods in
Eland, the performance of anomaly detection at an earlier stage is comparable
with or better than non-augmented methods on a greater amount of observation.
</p>
<a href="http://arxiv.org/abs/2010.10016" target="_blank">arXiv:2010.10016</a> [<a href="http://arxiv.org/pdf/2010.10016" target="_blank">pdf</a>]

<h2>Neural Architecture Performance Prediction Using Graph Neural Networks. (arXiv:2010.10024v1 [cs.CV])</h2>
<h3>Jovita Lukasik, David Friede, Heiner Stuckenschmidt, Margret Keuper</h3>
<p>In computer vision research, the process of automating architecture
engineering, Neural Architecture Search (NAS), has gained substantial interest.
Due to the high computational costs, most recent approaches to NAS as well as
the few available benchmarks only provide limited search spaces. In this paper
we propose a surrogate model for neural architecture performance prediction
built upon Graph Neural Networks (GNN). We demonstrate the effectiveness of
this surrogate model on neural architecture performance prediction for
structurally unknown architectures (i.e. zero shot prediction) by evaluating
the GNN on several experiments on the NAS-Bench-101 dataset.
</p>
<a href="http://arxiv.org/abs/2010.10024" target="_blank">arXiv:2010.10024</a> [<a href="http://arxiv.org/pdf/2010.10024" target="_blank">pdf</a>]

<h2>An Investigation of Feature Selection and Transfer Learning for Writer-Independent Offline Handwritten Signature Verification. (arXiv:2010.10025v1 [cs.CV])</h2>
<h3>Victor L. F. Souza, Adriano L. I. Oliveira, Rafael M. O. Cruz, Robert Sabourin</h3>
<p>SigNet is a state of the art model for feature representation used for
handwritten signature verification (HSV). This representation is based on a
Deep Convolutional Neural Network (DCNN) and contains 2048 dimensions. When
transposed to a dissimilarity space generated by the dichotomy transformation
(DT), related to the writer-independent (WI) approach, these features may
include redundant information. This paper investigates the presence of
overfitting when using Binary Particle Swarm Optimization (BPSO) to perform the
feature selection in a wrapper mode. We proposed a method based on a global
validation strategy with an external archive to control overfitting during the
search for the most discriminant representation. Moreover, an investigation is
also carried out to evaluate the use of the selected features in a transfer
learning context. The analysis is carried out on a writer-independent approach
on the CEDAR, MCYT and GPDS datasets. The experimental results showed the
presence of overfitting when no validation is used during the optimization
process and the improvement when the global validation strategy with an
external archive is used. Also, the space generated after feature selection can
be used in a transfer learning context.
</p>
<a href="http://arxiv.org/abs/2010.10025" target="_blank">arXiv:2010.10025</a> [<a href="http://arxiv.org/pdf/2010.10025" target="_blank">pdf</a>]

<h2>Fast Video Salient Object Detection via Spatiotemporal Knowledge Distillation. (arXiv:2010.10027v1 [cs.CV])</h2>
<h3>Tang Yi, Li Yuan</h3>
<p>Since the wide employment of deep learning frameworks in video salient object
detection, the accuracy of the recent approaches has made stunning progress.
These approaches mainly adopt the sequential modules, based on optical flow or
recurrent neural network (RNN), to learn robust spatiotemporal features. These
modules are effective but significantly increase the computational burden of
the corresponding deep models. In this paper, to simplify the network and
maintain the accuracy, we present a lightweight network tailored for video
salient object detection through the spatiotemporal knowledge distillation.
Specifically, in the spatial aspect, we combine a saliency guidance feature
embedding structure and spatial knowledge distillation to refine the spatial
features. In the temporal aspect, we propose a temporal knowledge distillation
strategy, which allows the network to learn the robust temporal features
through the infer-frame feature encoding and distilling information from
adjacent frames. The experiments on widely used video datasets (e.g., DAVIS,
DAVSOD, SegTrack-V2) prove that our approach achieves competitive performance.
Furthermore, without the employment of the complex sequential modules, the
proposed network can obtain high efficiency with 0.01s per frame.
</p>
<a href="http://arxiv.org/abs/2010.10027" target="_blank">arXiv:2010.10027</a> [<a href="http://arxiv.org/pdf/2010.10027" target="_blank">pdf</a>]

<h2>Towards and Ethical Framework in the Complex Digital Era. (arXiv:2010.10028v1 [cs.CY])</h2>
<h3>David Pastor-Escuredo, Ricardo Vinuesa</h3>
<p>Since modernity, ethic has been progressively fragmented into specific
communities of practice. The digital revolution enabled by AI and Data is
bringing ethical wicked problems in the crossroads of technology and behavior.
However, the need of a comprehensive and constructive ethical framework is
emerging as digital platforms connect us globally. The unequal structure of the
global system makes that dynamic changes and systemic problems impact more on
those that are most vulnerable. Ethical frameworks based only on the
individual-level are not longer sufficient. A new ethical vision must comprise
the understanding of the scales and complex interconnections of social systems.
Many of these systems are internally fragile and very sensitive to external
factors and threats, which turns into unethical situations that require
systemic solutions. The high scale nature of digital technology that expands
globally has also an impact at the individual level having the risk to make
humans beings more homogeneous, predictable and ultimately controllable. To
preserve the core of humanity ethic must take a stand to preserve and keep
promoting individual rights and uniqueness and cultural heterogeneity tackling
the negative trends and impact of digitalization. Only combining human-centered
and collectiveness-oriented digital development it will be possible to
construct new social models and human-machine interactions that are ethical.
This vision requires science to enhance ethical frameworks and principles with
the actionable insights of relationships and properties of the social systems
that may not be evident and need to be quantified and understood to be solved.
Artificial Intelligence is both a risk and and opportunity for an ethical
development, thus we need a conceptual construct that drives towards a better
digitalizated world.
</p>
<a href="http://arxiv.org/abs/2010.10028" target="_blank">arXiv:2010.10028</a> [<a href="http://arxiv.org/pdf/2010.10028" target="_blank">pdf</a>]

<h2>Connecting Weighted Automata, Tensor Networks and Recurrent Neural Networks through Spectral Learning. (arXiv:2010.10029v1 [cs.LG])</h2>
<h3>Tianyu Li, Doina Precup, Guillaume Rabusseau</h3>
<p>In this paper, we present connections between three models used in different
research fields: weighted finite automata~(WFA) from formal languages and
linguistics, recurrent neural networks used in machine learning, and tensor
networks which encompasses a set of optimization techniques for high-order
tensors used in quantum physics and numerical analysis. We first present an
intrinsic relation between WFA and the tensor train decomposition, a particular
form of tensor network. This relation allows us to exhibit a novel low rank
structure of the Hankel matrix of a function computed by a WFA and to design an
efficient spectral learning algorithm leveraging this structure to scale the
algorithm up to very large Hankel matrices. We then unravel a fundamental
connection between WFA and second-order recurrent neural networks~(2-RNN): in
the case of sequences of discrete symbols, WFA and 2-RNN with linear activation
functions are expressively equivalent. Furthermore, we introduce the first
provable learning algorithm for linear 2-RNN defined over sequences of
continuous input vectors. This algorithm relies on estimating low rank
sub-blocks of the Hankel tensor, from which the parameters of a linear 2-RNN
can be provably recovered. The performances of the proposed learning algorithm
are assessed in a simulation study on both synthetic and real-world data.
</p>
<a href="http://arxiv.org/abs/2010.10029" target="_blank">arXiv:2010.10029</a> [<a href="http://arxiv.org/pdf/2010.10029" target="_blank">pdf</a>]

<h2>TTPLA: An Aerial-Image Dataset for Detection and Segmentation of Transmission Towers and Power Lines. (arXiv:2010.10032v1 [cs.CV])</h2>
<h3>Rabab Abdelfattah, Xiaofeng Wang, Song Wang</h3>
<p>Accurate detection and segmentation of transmission towers~(TTs) and power
lines~(PLs) from aerial images plays a key role in protecting power-grid
security and low-altitude UAV safety. Meanwhile, aerial images of TTs and PLs
pose a number of new challenges to the computer vision researchers who work on
object detection and segmentation -- PLs are long and thin, and may show
similar color as the background; TTs can be of various shapes and most likely
made up of line structures of various sparsity; The background scene, lighting,
and object sizes can vary significantly from one image to another. In this
paper we collect and release a new TT/PL Aerial-image (TTPLA) dataset,
consisting of 1,100 images with the resolution of 3,840$\times$2,160 pixels, as
well as manually labeled 8,987 instances of TTs and PLs. We develop novel
policies for collecting, annotating, and labeling the images in TTPLA.
Different from other relevant datasets, TTPLA supports evaluation of instance
segmentation, besides detection and semantic segmentation. To build a baseline
for detection and segmentation tasks on TTPLA, we report the performance of
several state-of-the-art deep learning models on our dataset. TTPLA dataset is
publicly available at https://github.com/r3ab/ttpla_dataset
</p>
<a href="http://arxiv.org/abs/2010.10032" target="_blank">arXiv:2010.10032</a> [<a href="http://arxiv.org/pdf/2010.10032" target="_blank">pdf</a>]

<h2>SOrT-ing VQA Models : Contrastive Gradient Learning for Improved Consistency. (arXiv:2010.10038v1 [cs.CV])</h2>
<h3>Sameer Dharur, Purva Tendulkar, Dhruv Batra, Devi Parikh, Ramprasaath R. Selvaraju</h3>
<p>Recent research in Visual Question Answering (VQA) has revealed
state-of-the-art models to be inconsistent in their understanding of the world
-- they answer seemingly difficult questions requiring reasoning correctly but
get simpler associated sub-questions wrong. These sub-questions pertain to
lower level visual concepts in the image that models ideally should understand
to be able to answer the higher level question correctly. To address this, we
first present a gradient-based interpretability approach to determine the
questions most strongly correlated with the reasoning question on an image, and
use this to evaluate VQA models on their ability to identify the relevant
sub-questions needed to answer a reasoning question. Next, we propose a
contrastive gradient learning based approach called Sub-question Oriented
Tuning (SOrT) which encourages models to rank relevant sub-questions higher
than irrelevant questions for an &lt;$image, reasoning-question$&gt; pair. We show
that SOrT improves model consistency by upto 6.5% points over existing
baselines, while also improving visual grounding.
</p>
<a href="http://arxiv.org/abs/2010.10038" target="_blank">arXiv:2010.10038</a> [<a href="http://arxiv.org/pdf/2010.10038" target="_blank">pdf</a>]

<h2>Improving Factual Completeness and Consistency of Image-to-Text Radiology Report Generation. (arXiv:2010.10042v1 [cs.CL])</h2>
<h3>Yasuhide Miura, Yuhao Zhang, Curtis P. Langlotz, Dan Jurafsky</h3>
<p>Neural image-to-text radiology report generation systems offer the potential
to accelerate clinical processes by saving radiologists from the repetitive
labor of drafting radiology reports and preventing medical errors. However,
existing report generation systems, despite achieving high performances on
natural language generation metrics such as CIDEr or BLEU, still suffer from
incomplete and inconsistent generations, rendering these systems unusable in
practice. In this work, we aim to overcome this problem by proposing two new
metrics that encourage the factual completeness and consistency of generated
radiology reports. The first metric, the Exact Entity Match score, evaluates a
generation by its coverage of radiology domain entities against the references.
The second metric, the Entailing Entity Match score, augments the first metric
by introducing a natural language inference model into the entity match process
to encourage consistent generations that can be entailed from the references.
To achieve this, we also developed an in-domain NLI model via weak supervision
to improve its performance on radiology text. We further propose a report
generation system that optimizes these two new metrics via reinforcement
learning. On two open radiology report datasets, our system not only achieves
the best performance on these two metrics compared to baselines, but also leads
to as much as +2.0 improvement on the F1 score of a clinical finding metric. We
show via analysis and examples that our system leads to generations that are
more complete and consistent compared to the baselines.
</p>
<a href="http://arxiv.org/abs/2010.10042" target="_blank">arXiv:2010.10042</a> [<a href="http://arxiv.org/pdf/2010.10042" target="_blank">pdf</a>]

<h2>Line Graph Neural Networks for Link Prediction. (arXiv:2010.10046v1 [cs.LG])</h2>
<h3>Lei Cai, Jundong Li, Jie Wang, Shuiwang Ji</h3>
<p>We consider the graph link prediction task, which is a classic graph
analytical problem with many real-world applications. With the advances of deep
learning, current link prediction methods commonly compute features from
subgraphs centered at two neighboring nodes and use the features to predict the
label of the link between these two nodes. In this formalism, a link prediction
problem is converted to a graph classification task. In order to extract
fixed-size features for classification, graph pooling layers are necessary in
the deep learning model, thereby incurring information loss. To overcome this
key limitation, we propose to seek a radically different and novel path by
making use of the line graphs in graph theory. In particular, each node in a
line graph corresponds to a unique edge in the original graph. Therefore, link
prediction problems in the original graph can be equivalently solved as a node
classification problem in its corresponding line graph, instead of a graph
classification task. Experimental results on fourteen datasets from different
applications demonstrate that our proposed method consistently outperforms the
state-of-the-art methods, while it has fewer parameters and high training
efficiency.
</p>
<a href="http://arxiv.org/abs/2010.10046" target="_blank">arXiv:2010.10046</a> [<a href="http://arxiv.org/pdf/2010.10046" target="_blank">pdf</a>]

<h2>Robust Neural Networks inspired by Strong Stability Preserving Runge-Kutta methods. (arXiv:2010.10047v1 [cs.CV])</h2>
<h3>Byungjoo Kim, Bryce Chudomelka, Jinyoung Park, Jaewoo Kang, Youngjoon Hong, Hyunwoo J. Kim</h3>
<p>Deep neural networks have achieved state-of-the-art performance in a variety
of fields. Recent works observe that a class of widely used neural networks can
be viewed as the Euler method of numerical discretization. From the numerical
discretization perspective, Strong Stability Preserving (SSP) methods are more
advanced techniques than the explicit Euler method that produce both accurate
and stable solutions. Motivated by the SSP property and a generalized
Runge-Kutta method, we propose Strong Stability Preserving networks (SSP
networks) which improve robustness against adversarial attacks. We empirically
demonstrate that the proposed networks improve the robustness against
adversarial examples without any defensive methods. Further, the SSP networks
are complementary with a state-of-the-art adversarial training scheme. Lastly,
our experiments show that SSP networks suppress the blow-up of adversarial
perturbations. Our results open up a way to study robust architectures of
neural networks leveraging rich knowledge from numerical discretization
literature.
</p>
<a href="http://arxiv.org/abs/2010.10047" target="_blank">arXiv:2010.10047</a> [<a href="http://arxiv.org/pdf/2010.10047" target="_blank">pdf</a>]

<h2>Deep Low-Shot Learning for Biological Image Classification and Visualization from Limited Training Samples. (arXiv:2010.10050v1 [cs.LG])</h2>
<h3>Lei Cai, Zhengyang Wang, Rob Kulathinal, Sudhir Kumar, Shuiwang Ji</h3>
<p>Predictive modeling is useful but very challenging in biological image
analysis due to the high cost of obtaining and labeling training data. For
example, in the study of gene interaction and regulation in Drosophila
embryogenesis, the analysis is most biologically meaningful when in situ
hybridization (ISH) gene expression pattern images from the same developmental
stage are compared. However, labeling training data with precise stages is very
time-consuming even for evelopmental biologists. Thus, a critical challenge is
how to build accurate computational models for precise developmental stage
classification from limited training samples. In addition, identification and
visualization of developmental landmarks are required to enable biologists to
interpret prediction results and calibrate models. To address these challenges,
we propose a deep two-step low-shot learning framework to accurately classify
ISH images using limited training images. Specifically, to enable accurate
model training on limited training samples, we formulate the task as a deep
low-shot learning problem and develop a novel two-step learning approach,
including data-level learning and feature-level learning. We use a deep
residual network as our base model and achieve improved performance in the
precise stage prediction task of ISH images. Furthermore, the deep model can be
interpreted by computing saliency maps, which consist of pixel-wise
contributions of an image to its prediction result. In our task, saliency maps
are used to assist the identification and visualization of developmental
landmarks. Our experimental results show that the proposed model can not only
make accurate predictions, but also yield biologically meaningful
interpretations. We anticipate our methods to be easily generalizable to other
biological image classification tasks with small training datasets.
</p>
<a href="http://arxiv.org/abs/2010.10050" target="_blank">arXiv:2010.10050</a> [<a href="http://arxiv.org/pdf/2010.10050" target="_blank">pdf</a>]

<h2>Tracking from Patterns: Learning Corresponding Patterns in Point Clouds for 3D Object Tracking. (arXiv:2010.10051v1 [cs.CV])</h2>
<h3>Jieqi Shi, Peiliang Li, Shaojie Shen</h3>
<p>A robust 3D object tracker which continuously tracks surrounding objects and
estimates their trajectories is key for self-driving vehicles. Most existing
tracking methods employ a tracking-by-detection strategy, which usually
requires complex pair-wise similarity computation and neglects the nature of
continuous object motion. In this paper, we propose to directly learn 3D object
correspondences from temporal point cloud data and infer the motion information
from correspondence patterns. We modify the standard 3D object detector to
process two lidar frames at the same time and predict bounding box pairs for
the association and motion estimation tasks. We also equip our pipeline with a
simple yet effective velocity smoothing module to estimate consistent object
motion. Benifiting from the learned correspondences and motion refinement, our
method exceeds the existing 3D tracking methods on both the KITTI and larger
scale Nuscenes dataset.
</p>
<a href="http://arxiv.org/abs/2010.10051" target="_blank">arXiv:2010.10051</a> [<a href="http://arxiv.org/pdf/2010.10051" target="_blank">pdf</a>]

<h2>Video Reconstruction by Spatio-Temporal Fusion of Blurred-Coded Image Pair. (arXiv:2010.10052v1 [cs.CV])</h2>
<h3>Anupama S, Prasan Shedligeri, Abhishek Pal, Kaushik Mitra</h3>
<p>Learning-based methods have enabled the recovery of a video sequence from a
single motion-blurred image or a single coded exposure image. Recovering video
from a single motion-blurred image is a very ill-posed problem and the
recovered video usually has many artifacts. In addition to this, the direction
of motion is lost and it results in motion ambiguity. However, it has the
advantage of fully preserving the information in the static parts of the scene.
The traditional coded exposure framework is better-posed but it only samples a
fraction of the space-time volume, which is at best 50% of the space-time
volume. Here, we propose to use the complementary information present in the
fully-exposed (blurred) image along with the coded exposure image to recover a
high fidelity video without any motion ambiguity. Our framework consists of a
shared encoder followed by an attention module to selectively combine the
spatial information from the fully-exposed image with the temporal information
from the coded image, which is then super-resolved to recover a non-ambiguous
high-quality video. The input to our algorithm is a fully-exposed and coded
image pair. Such an acquisition system already exists in the form of a
Coded-two-bucket (C2B) camera. We demonstrate that our proposed deep learning
approach using blurred-coded image pair produces much better results than those
from just a blurred image or just a coded image.
</p>
<a href="http://arxiv.org/abs/2010.10052" target="_blank">arXiv:2010.10052</a> [<a href="http://arxiv.org/pdf/2010.10052" target="_blank">pdf</a>]

<h2>Real-time Localized Photorealistic Video Style Transfer. (arXiv:2010.10056v1 [cs.CV])</h2>
<h3>Xide Xia, Tianfan Xue, Wei-sheng Lai, Zheng Sun, Abby Chang, Brian Kulis, Jiawen Chen</h3>
<p>We present a novel algorithm for transferring artistic styles of semantically
meaningful local regions of an image onto local regions of a target video while
preserving its photorealism. Local regions may be selected either fully
automatically from an image, through using video segmentation algorithms, or
from casual user guidance such as scribbles. Our method, based on a deep neural
network architecture inspired by recent work in photorealistic style transfer,
is real-time and works on arbitrary inputs without runtime optimization once
trained on a diverse dataset of artistic styles. By augmenting our video
dataset with noisy semantic labels and jointly optimizing over style, content,
mask, and temporal losses, our method can cope with a variety of imperfections
in the input and produce temporally coherent videos without visual artifacts.
We demonstrate our method on a variety of style images and target videos,
including the ability to transfer different styles onto multiple objects
simultaneously, and smoothly transition between styles in time.
</p>
<a href="http://arxiv.org/abs/2010.10056" target="_blank">arXiv:2010.10056</a> [<a href="http://arxiv.org/pdf/2010.10056" target="_blank">pdf</a>]

<h2>Real-Time Optimisation for Online Learning in Auctions. (arXiv:2010.10070v1 [cs.LG])</h2>
<h3>Lorenzo Croissant, Marc Abeille, Cl&#xe9;ment Calauz&#xe8;nes</h3>
<p>In display advertising, a small group of sellers and bidders face each other
in up to 10 12 auctions a day. In this context, revenue maximisation via
monopoly price learning is a high-value problem for sellers. By nature, these
auctions are online and produce a very high frequency stream of data. This
results in a computational strain that requires algorithms be real-time.
Unfortunately, existing methods inherited from the batch setting suffer
O($\sqrt t$) time/memory complexity at each update, prohibiting their use. In
this paper, we provide the first algorithm for online learning of monopoly
prices in online auctions whose update is constant in time and memory.
</p>
<a href="http://arxiv.org/abs/2010.10070" target="_blank">arXiv:2010.10070</a> [<a href="http://arxiv.org/pdf/2010.10070" target="_blank">pdf</a>]

<h2>RDIS: Random Drop Imputation with Self-Training for Incomplete Time Series Data. (arXiv:2010.10075v1 [cs.LG])</h2>
<h3>Tae-Min Choi, Ji-Su Kang, Jong-Hwan Kim</h3>
<p>It is common that time-series data with missing values are encountered in
many fields such as in finance, meteorology, and robotics. Imputation is an
intrinsic method to handle such missing values. In the previous research, most
of imputation networks were trained implicitly for the incomplete time series
data because missing values have no ground truth. This paper proposes Random
Drop Imputation with Self-training (RDIS), a novel training method for
imputation networks for the incomplete time-series data. In RDIS, there are
extra missing values by applying a random drop on the given incomplete data
such that the imputation network can explicitly learn by imputing the random
drop values. Also, self-training is introduced to exploit the original missing
values without ground truth. To verify the effectiveness of our RDIS on
imputation tasks, we graft RDIS to a bidirectional GRU and achieve
state-of-the-art results on two real-world datasets, an air quality dataset and
a gas sensor dataset with 7.9% and 5.8% margin, respectively.
</p>
<a href="http://arxiv.org/abs/2010.10075" target="_blank">arXiv:2010.10075</a> [<a href="http://arxiv.org/pdf/2010.10075" target="_blank">pdf</a>]

<h2>Neural Approximate Sufficient Statistics for Implicit Models. (arXiv:2010.10079v1 [stat.ML])</h2>
<h3>Yanzhi Chen, Dinghuai Zhang, Michael Gutmann, Aaron Courville, Zhanxing Zhu</h3>
<p>We consider the fundamental problem of how to automatically construct summary
statistics for implicit generative models where the evaluation of likelihood
function is intractable but sampling / simulating data from the model is
possible. The idea is to frame the task of constructing sufficient statistics
as learning mutual information maximizing representation of the data. This
representation is computed by a deep neural network trained by a joint
statistic-posterior learning strategy. We apply our approach to both
traditional approximate Bayesian computation (ABC) and recent neural likelihood
approaches, boosting their performance on a range of tasks.
</p>
<a href="http://arxiv.org/abs/2010.10079" target="_blank">arXiv:2010.10079</a> [<a href="http://arxiv.org/pdf/2010.10079" target="_blank">pdf</a>]

<h2>BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues. (arXiv:2010.10095v1 [cs.CV])</h2>
<h3>Hung Le, Doyen Sahoo, Nancy F. Chen, Steven C.H. Hoi</h3>
<p>Video-grounded dialogues are very challenging due to (i) the complexity of
videos which contain both spatial and temporal variations, and (ii) the
complexity of user utterances which query different segments and/or different
objects in videos over multiple dialogue turns. However, existing approaches to
video-grounded dialogues often focus on superficial temporal-level visual cues,
but neglect more fine-grained spatial signals from videos. To address this
drawback, we propose Bi-directional Spatio-Temporal Learning (BiST), a
vision-language neural framework for high-resolution queries in videos based on
textual cues. Specifically, our approach not only exploits both spatial and
temporal-level information, but also learns dynamic information diffusion
between the two feature spaces through spatial-to-temporal and
temporal-to-spatial reasoning. The bidirectional strategy aims to tackle the
evolving semantics of user queries in the dialogue setting. The retrieved
visual cues are used as contextual information to construct relevant responses
to the users. Our empirical results and comprehensive qualitative analysis show
that BiST achieves competitive performance and generates reasonable responses
on a large-scale AVSD benchmark. We also adapt our BiST models to the Video QA
setting, and substantially outperform prior approaches on the TGIF-QA
benchmark.
</p>
<a href="http://arxiv.org/abs/2010.10095" target="_blank">arXiv:2010.10095</a> [<a href="http://arxiv.org/pdf/2010.10095" target="_blank">pdf</a>]

<h2>Two-Stage Generative Adversarial Networks for Document Image Binarization with Color Noise and Background Removal. (arXiv:2010.10103v1 [cs.CV])</h2>
<h3>Sungho Suh, Jihun Kim, Paul Lukowicz, Yong Oh Lee</h3>
<p>Document image enhancement and binarization methods are often used to improve
the accuracy and efficiency of document image analysis tasks such as text
recognition. Traditional non-machine-learning methods are constructed on
low-level features in an unsupervised manner but have difficulty with
binarization on documents with severely degraded backgrounds. Convolutional
neural network-based methods focus only on grayscale images and on local
textual features. In this paper, we propose a two-stage color document image
enhancement and binarization method using generative adversarial neural
networks. In the first stage, four color-independent adversarial networks are
trained to extract color foreground information from an input image for
document image enhancement. In the second stage, two independent adversarial
networks with global and local features are trained for image binarization of
documents of variable size. For the adversarial neural networks, we formulate
loss functions between a discriminator and generators having an encoder-decoder
structure. Experimental results show that the proposed method achieves better
performance than many classical and state-of-the-art algorithms over the
Document Image Binarization Contest (DIBCO) datasets, the LRDE Document
Binarization Dataset (LRDE DBD), and our shipping label image dataset.
</p>
<a href="http://arxiv.org/abs/2010.10103" target="_blank">arXiv:2010.10103</a> [<a href="http://arxiv.org/pdf/2010.10103" target="_blank">pdf</a>]

<h2>University Operations During a Pandemic: A Flexible Decision Analysis Toolkit. (arXiv:2010.10112v1 [eess.SY])</h2>
<h3>Himanshu Kharkwal, Dakota Olson, Jiali Huang, Abhiraj Mohan, Ankur Mani, Jaideep Srivastava</h3>
<p>Modeling infection spread during pandemics is not new, with models using past
data to tune simulation parameters for predictions. These help understand the
healthcare burden posed by a pandemic and respond accordingly. However, the
problem of how college/university campuses should function during a pandemic is
new for the following reasons:(i) social contact in colleges are structured and
can be engineered for chosen objectives, (ii) the last pandemic to cause such
societal disruption was over 100 years ago, when higher education was not a
critical part of society, (ii) not much was known about causes of pandemics,
and hence effective ways of safe operations were not known, and (iii) today
with distance learning, remote operation of an academic institution is
possible. Our approach is unique in presenting a flexible simulation system,
containing a suite of model libraries, one for each major component. The system
integrates agent based modeling (ABM) and stochastic network approach, and
models the interactions among individual entities, e.g., students, instructors,
classrooms, residences, etc. in great detail. For each decision to be made, the
system can be used to predict the impact of various choices, and thus enable
the administrator to make informed decisions. While current approaches are good
for infection modeling, they lack accuracy in social contact modeling. Our ABM
approach, combined with ideas from Network Science, presents a novel approach
to contact modeling. A detailed case study of the University of Minnesota's
Sunrise Plan is presented. For each decisions made, its impact was assessed,
and results used to get a measure of confidence. We believe this flexible tool
can be a valuable asset for various kinds of organizations to assess their
infection risks in pandemic-time operations, including middle and high schools,
factories, warehouses, and small/medium sized businesses.
</p>
<a href="http://arxiv.org/abs/2010.10112" target="_blank">arXiv:2010.10112</a> [<a href="http://arxiv.org/pdf/2010.10112" target="_blank">pdf</a>]

<h2>Towards an Automatic Analysis of CHO-K1 Suspension Growth in Microfluidic Single-cell Cultivation. (arXiv:2010.10124v1 [cs.LG])</h2>
<h3>Dominik Stallmann, Jan P. G&#xf6;pfert, Julian Schmitz, Alexander Gr&#xfc;nberger, Barbara Hammer</h3>
<p>Motivation: Innovative microfluidic systems carry the promise to greatly
facilitate spatio-temporal analysis of single cells under well-defined
environmental conditions, allowing novel insights into population heterogeneity
and opening new opportunities for fundamental and applied biotechnology.
Microfluidics experiments, however, are accompanied by vast amounts of data,
such as time series of microscopic images, for which manual evaluation is
infeasible due to the sheer number of samples. While classical image processing
technologies do not lead to satisfactory results in this domain, modern deep
learning technologies such as convolutional networks can be sufficiently
versatile for diverse tasks, including automatic cell tracking and counting as
well as the extraction of critical parameters, such as growth rate. However,
for successful training, current supervised deep learning requires label
information, such as the number or positions of cells for each image in a
series; obtaining these annotations is very costly in this setting. Results: We
propose a novel Machine Learning architecture together with a specialized
training procedure, which allows us to infuse a deep neural network with
human-powered abstraction on the level of data, leading to a high-performing
regression model that requires only a very small amount of labeled data.
Specifically, we train a generative model simultaneously on natural and
synthetic data, so that it learns a shared representation, from which a target
variable, such as the cell count, can be reliably estimated.
</p>
<a href="http://arxiv.org/abs/2010.10124" target="_blank">arXiv:2010.10124</a> [<a href="http://arxiv.org/pdf/2010.10124" target="_blank">pdf</a>]

<h2>a-Tucker: Input-Adaptive and Matricization-Free Tucker Decomposition for Dense Tensors on CPUs and GPUs. (arXiv:2010.10131v1 [cs.DC])</h2>
<h3>Min Li, Chuanfu Xiao, Chao Yang</h3>
<p>Tucker decomposition is one of the most popular models for analyzing and
compressing large-scale tensorial data. Existing Tucker decomposition
algorithms usually rely on a single solver to compute the factor matrices and
core tensor, and are not flexible enough to adapt with the diversities of the
input data and the hardware. Moreover, to exploit highly efficient GEMM
kernels, most Tucker decomposition implementations make use of explicit
matricizations, which could introduce extra costs in terms of data conversion
and memory usage. In this paper, we present a-Tucker, a new framework for
input-adaptive and matricization-free Tucker decomposition of dense tensors. A
mode-wise flexible Tucker decomposition algorithm is proposed to enable the
switch of different solvers for the factor matrices and core tensor, and a
machine-learning adaptive solver selector is applied to automatically cope with
the variations of both the input data and the hardware. To further improve the
performance and enhance the memory efficiency, we implement a-Tucker in a fully
matricization-free manner without any conversion between tensors and matrices.
Experiments with a variety of synthetic and real-world tensors show that
a-Tucker can substantially outperform existing works on both CPUs and GPUs.
</p>
<a href="http://arxiv.org/abs/2010.10131" target="_blank">arXiv:2010.10131</a> [<a href="http://arxiv.org/pdf/2010.10131" target="_blank">pdf</a>]

<h2>Integrating LEO Satellites and Multi-UAV Reinforcement Learning for Hybrid FSO/RF Non-Terrestrial Networks. (arXiv:2010.10138v1 [cs.NI])</h2>
<h3>Ju-Hyung Lee, Jihong Park, Mehdi Bennis, Young-Chai Ko</h3>
<p>A mega-constellation of low-altitude earth orbit (LEO) satellites (SATs) and
burgeoning unmanned aerial vehicles (UAVs) are promising enablers for
high-speed and long-distance communications in beyond fifth-generation (5G)
systems. Integrating SATs and UAVs within a non-terrestrial network (NTN), in
this article we investigate the problem of forwarding packets between two
faraway ground terminals through SAT and UAV relays using either
millimeter-wave (mmWave) radio-frequency (RF) or free-space optical (FSO) link.
Towards maximizing the communication efficiency, the real-time associations
with orbiting SATs and the moving trajectories of UAVs should be optimized with
suitable FSO/RF links, which is challenging due to the time-varying network
topology and a huge number of possible control actions. To overcome the
difficulty, we lift this problem to multi-agent deep reinforcement learning
(MARL) with a novel action dimensionality reduction technique. Simulation
results corroborate that our proposed SAT-UAV integrated scheme achieves 1.99x
higher end-to-end sum throughput compared to a benchmark scheme with fixed
ground relays. While improving the throughput, our proposed scheme also aims to
reduce the UAV control energy, yielding 2.25x higher energy efficiency than a
baseline method only maximizing the throughput. Lastly, thanks to utilizing
hybrid FSO/RF links, the proposed scheme achieves up to 62.56x higher peak
throughput and 21.09x higher worst-case throughput than the cases utilizing
either RF or FSO links, highlighting the importance of co-designing SAT-UAV
associations, UAV trajectories, and hybrid FSO/RF links in beyond-5G NTNs.
</p>
<a href="http://arxiv.org/abs/2010.10138" target="_blank">arXiv:2010.10138</a> [<a href="http://arxiv.org/pdf/2010.10138" target="_blank">pdf</a>]

<h2>Image Obfuscation for Privacy-Preserving Machine Learning. (arXiv:2010.10139v1 [cs.CR])</h2>
<h3>Mathilde Raynal, Radhakrishna Achanta, Mathias Humbert</h3>
<p>Privacy becomes a crucial issue when outsourcing the training of machine
learning (ML) models to cloud-based platforms offering machine-learning
services. While solutions based on cryptographic primitives have been
developed, they incur a significant loss in accuracy or training efficiency,
and require modifications to the backend architecture. A key challenge we
tackle in this paper is the design of image obfuscation schemes that provide
enough privacy without significantly degrading the accuracy of the ML model and
the efficiency of the training process. In this endeavor, we address another
challenge that has persisted so far: quantifying the degree of privacy provided
by visual obfuscation mechanisms. We compare the ability of state-of-the-art
full-reference quality metrics to concur with human subjects in terms of the
degree of obfuscation introduced by a range of techniques. By relying on user
surveys and two image datasets, we show that two existing image quality metrics
are also well suited to measure the level of privacy in accordance with human
subjects as well as AI-based recognition, and can therefore be used for
quantifying privacy resulting from obfuscation. With the ability to quantify
privacy, we show that we can provide adequate privacy protection to the
training image set at the cost of only a few percentage points loss in
accuracy.
</p>
<a href="http://arxiv.org/abs/2010.10139" target="_blank">arXiv:2010.10139</a> [<a href="http://arxiv.org/pdf/2010.10139" target="_blank">pdf</a>]

<h2>Constructing feature variation coefficients to evaluate feature learning capabilities of convolutional layers in steganographic detection algorithms of spatial domain. (arXiv:2010.10140v1 [cs.CR])</h2>
<h3>Ru Zhang (1), Sheng Zou (1), Jianyi Liu (1), Bingjie Lin (2), Dazhuang Liu (1) ((1) Beijing University of Posts and Telecommunications, (2) State Grid Information &amp; Telecommunication Branch)</h3>
<p>Traditional steganalysis methods generally include two steps: feature
extraction and classification.A variety of steganalysis algorithms based on CNN
(Convolutional Neural Network) have appeared in recent years. Among them, the
convolutional layer of the CNN model is usually used to extract steganographic
features, and the fully connected layer is used for classification. Because the
effectiveness of feature extraction seriously influences the accuracy of
classification, designers generally improve the accuracy of steganographic
detection by improving the convolutional layer. For example, common optimizing
methods in convolutional layer include the improvement of convolution kernel,
activation functions, pooling functions, network structures, etc. However, due
to the complexity and unexplainability of convolutional layers, it is difficult
to quantitatively analyze and compare the effectiveness of feature extraction.
Therefore, this paper proposes the variation coefficient to evaluate the
feature learning ability of convolutional layers. We select four typical image
steganalysis models based CNN in spatial domain, such as Ye-Net, Yedroudj-Net,
Zhu-Net, and SR-Net as use cases, and verify the validity of the variation
coefficient through experiments. Moreover, according to the variation
coefficient , a features modification layer is used to optimize the features
before the fully connected layer of the CNN model , and the experimental
results show that the detection accuracy of the four algorithms were improved
differently.
</p>
<a href="http://arxiv.org/abs/2010.10140" target="_blank">arXiv:2010.10140</a> [<a href="http://arxiv.org/pdf/2010.10140" target="_blank">pdf</a>]

<h2>Language Inference with Multi-head Automata through Reinforcement Learning. (arXiv:2010.10141v1 [cs.LG])</h2>
<h3>Alper &#x15e;ekerci, &#xd6;zlem Salehi</h3>
<p>The purpose of this paper is to use reinforcement learning to model learning
agents which can recognize formal languages. Agents are modeled as simple
multi-head automaton, a new model of finite automaton that uses multiple heads,
and six different languages are formulated as reinforcement learning problems.
Two different algorithms are used for optimization. First algorithm is
Q-learning which trains gated recurrent units to learn optimal policies. The
second one is genetic algorithm which searches for the optimal solution by
using evolution inspired operations. The results show that genetic algorithm
performs better than Q-learning algorithm in general but Q-learning algorithm
finds solutions faster for regular languages.
</p>
<a href="http://arxiv.org/abs/2010.10141" target="_blank">arXiv:2010.10141</a> [<a href="http://arxiv.org/pdf/2010.10141" target="_blank">pdf</a>]

<h2>Don't Drone Yourself in Work: Discussing DronOS as a Framework for Human-Drone Interaction. (arXiv:2010.10148v1 [cs.HC])</h2>
<h3>Matthias Hoppe, Yannick Wei&#xdf;, Marinus Burger, Thomas Kosch</h3>
<p>More and more off-the-shelf drones provide frameworks that enable the
programming of flight paths. These frameworks provide vendor-dependent
programming and communication interfaces that are intended for flight path
definitions. However, they are often limited to outdoor and GPS-based use only.
A key disadvantage of such a solution is that they are complicated to use and
require readjustments when changing the drone model. This is time-consuming
since it requires redefining the flight path for the new framework. This
workshop paper proposes additional features for DronOS, a community-driven
framework that enables model-independent automatisation and programming of
drones. We enhanced DronOS to include additional functions to account for the
specific design constraints in human-drone-interaction. This paper provides a
starting point for discussing the requirements involved in designing a drone
system with other researchers within the human-drone interaction community. We
envision DronOS as a community-driven framework that can be applied to generic
drone models, hence enabling the automatisation for any commercially available
drone. Our goal is to build DronOS as a software tool that can be easily used
by researchers and practitioners to prototype novel drone-based systems.
</p>
<a href="http://arxiv.org/abs/2010.10148" target="_blank">arXiv:2010.10148</a> [<a href="http://arxiv.org/pdf/2010.10148" target="_blank">pdf</a>]

<h2>Feature Inference Attack on Model Predictions in Vertical Federated Learning. (arXiv:2010.10152v1 [cs.LG])</h2>
<h3>Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, Beng Chin Ooi</h3>
<p>Federated learning (FL) is an emerging paradigm for facilitating multiple
organizations' data collaboration without revealing their private data to each
other. Recently, vertical FL, where the participating organizations hold the
same set of samples but with disjoint features and only one organization owns
the labels, has received increased attention. This paper presents several
feature inference attack methods to investigate the potential privacy leakages
in the model prediction stage of vertical FL. The attack methods consider the
most stringent setting that the adversary controls only the trained vertical FL
model and the model predictions, relying on no background information. We first
propose two specific attacks on the logistic regression (LR) and decision tree
(DT) models, according to individual prediction output. We further design a
general attack method based on multiple prediction outputs accumulated by the
adversary to handle complex models, such as neural networks (NN) and random
forest (RF) models. Experimental evaluations demonstrate the effectiveness of
the proposed attacks and highlight the need for designing private mechanisms to
protect the prediction outputs in vertical FL.
</p>
<a href="http://arxiv.org/abs/2010.10152" target="_blank">arXiv:2010.10152</a> [<a href="http://arxiv.org/pdf/2010.10152" target="_blank">pdf</a>]

<h2>Federated Bayesian Optimization via Thompson Sampling. (arXiv:2010.10154v1 [cs.LG])</h2>
<h3>Zhongxiang Dai, Kian Hsiang Low, Patrick Jaillet</h3>
<p>Bayesian optimization (BO) is a prominent approach to optimizing
expensive-to-evaluate black-box functions. The massive computational capability
of edge devices such as mobile phones, coupled with privacy concerns, has led
to a surging interest in federated learning (FL) which focuses on collaborative
training of deep neural networks (DNNs) via first-order optimization
techniques. However, some common machine learning tasks such as hyperparameter
tuning of DNNs lack access to gradients and thus require zeroth-order/black-box
optimization. This hints at the possibility of extending BO to the FL setting
(FBO) for agents to collaborate in these black-box optimization tasks. This
paper presents federated Thompson sampling (FTS) which overcomes a number of
key challenges of FBO and FL in a principled way: We (a) use random Fourier
features to approximate the Gaussian process surrogate model used in BO, which
naturally produces the parameters to be exchanged between agents, (b) design
FTS based on Thompson sampling, which significantly reduces the number of
parameters to be exchanged, and (c) provide a theoretical convergence guarantee
that is robust against heterogeneous agents, which is a major challenge in FL
and FBO. We empirically demonstrate the effectiveness of FTS in terms of
communication efficiency, computational efficiency, and practical performance.
</p>
<a href="http://arxiv.org/abs/2010.10154" target="_blank">arXiv:2010.10154</a> [<a href="http://arxiv.org/pdf/2010.10154" target="_blank">pdf</a>]

<h2>Claw U-Net: A Unet-based Network with Deep Feature Concatenation for Scleral Blood Vessel Segmentation. (arXiv:2010.10163v1 [cs.CV])</h2>
<h3>Chang Yao, Jingyu Tang, Menghan Hu, Yue Wu, Wenyi Guo, Qingli Li, Xiao-Ping Zhang</h3>
<p>Sturge-Weber syndrome (SWS) is a vascular malformation disease, and it may
cause blindness if the patient's condition is severe. Clinical results show
that SWS can be divided into two types based on the characteristics of scleral
blood vessels. Therefore, how to accurately segment scleral blood vessels has
become a significant problem in computer-aided diagnosis. In this research, we
propose to continuously upsample the bottom layer's feature maps to preserve
image details, and design a novel Claw UNet based on UNet for scleral blood
vessel segmentation. Specifically, the residual structure is used to increase
the number of network layers in the feature extraction stage to learn deeper
features. In the decoding stage, by fusing the features of the encoding,
upsampling, and decoding parts, Claw UNet can achieve effective segmentation in
the fine-grained regions of scleral blood vessels. To effectively extract small
blood vessels, we use the attention mechanism to calculate the attention
coefficient of each position in images. Claw UNet outperforms other UNet-based
networks on scleral blood vessel image dataset.
</p>
<a href="http://arxiv.org/abs/2010.10163" target="_blank">arXiv:2010.10163</a> [<a href="http://arxiv.org/pdf/2010.10163" target="_blank">pdf</a>]

<h2>Sparse Gaussian Process Variational Autoencoders. (arXiv:2010.10177v1 [stat.ML])</h2>
<h3>Matthew Ashman, Jonathan So, William Tebbutt, Vincent Fortuin, Michael Pearce, Richard E. Turner</h3>
<p>Large, multi-dimensional spatio-temporal datasets are omnipresent in modern
science and engineering. An effective framework for handling such data are
Gaussian process deep generative models (GP-DGMs), which employ GP priors over
the latent variables of DGMs. Existing approaches for performing inference in
GP-DGMs do not support sparse GP approximations based on inducing points, which
are essential for the computational efficiency of GPs, nor do they handle
missing data -- a natural occurrence in many spatio-temporal datasets -- in a
principled manner. We address these shortcomings with the development of the
sparse Gaussian process variational autoencoder (SGP-VAE), characterised by the
use of partial inference networks for parameterising sparse GP approximations.
Leveraging the benefits of amortised variational inference, the SGP-VAE enables
inference in multi-output sparse GPs on previously unobserved data with no
additional training. The SGP-VAE is evaluated in a variety of experiments where
it outperforms alternative approaches including multi-output GPs and structured
VAEs.
</p>
<a href="http://arxiv.org/abs/2010.10177" target="_blank">arXiv:2010.10177</a> [<a href="http://arxiv.org/pdf/2010.10177" target="_blank">pdf</a>]

<h2>PIXEL: Interactive Light System Design Based On Simple Gesture Recognition. (arXiv:2010.10180v1 [cs.HC])</h2>
<h3>Xuedan Zou</h3>
<p>In this project, by utilizing the real-time human gestures captured by
Kinect, we attempted to provide a self-made interactive light system PIXEL for
interacting with the visitor to play a simple SNAKE game. By paralleling the
low power single color LED lights and lighting up them separately or together,
we provided a big LED board with multiple colors while at the time safe enough
without using high tension electricity. We analysed the factors that influence
the final visual effect of the light pixel, the novel gestures that can be
recognized well by current computer vision algorithms and did several
experiments to decide the final interactive method. We also believe this
project provides a way to help people reconsider the relationship between the
old and the new and the possibility to bring old things reborn by the new
technologies.
</p>
<a href="http://arxiv.org/abs/2010.10180" target="_blank">arXiv:2010.10180</a> [<a href="http://arxiv.org/pdf/2010.10180" target="_blank">pdf</a>]

<h2>Robust Imitation Learning from Noisy Demonstrations. (arXiv:2010.10181v1 [stat.ML])</h2>
<h3>Voot Tangkaratt, Nontawat Charoenphakdee, Masashi Sugiyama</h3>
<p>Learning from noisy demonstrations is a practical but highly challenging
problem in imitation learning. In this paper, we first theoretically show that
robust imitation learning can be achieved by optimizing a classification risk
with a symmetric loss. Based on this theoretical finding, we then propose a new
imitation learning method that optimizes the classification risk by effectively
combining pseudo-labeling with co-training. Unlike existing methods, our method
does not require additional labels or strict assumptions about noise
distributions. Experimental results on continuous-control benchmarks show that
our method is more robust compared to state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.10181" target="_blank">arXiv:2010.10181</a> [<a href="http://arxiv.org/pdf/2010.10181" target="_blank">pdf</a>]

<h2>The Elliptical Potential Lemma Revisited. (arXiv:2010.10182v1 [stat.ML])</h2>
<h3>Alexandra Carpentier, Claire Vernade, Yasin Abbasi-Yadkori</h3>
<p>This note proposes a new proof and new perspectives on the so-called
Elliptical Potential Lemma. This result is important in online learning,
especially for linear stochastic bandits. The original proof of the result,
however short and elegant, does not give much flexibility on the type of
potentials considered and we believe that this new interpretation can be of
interest for future research in this field.
</p>
<a href="http://arxiv.org/abs/2010.10182" target="_blank">arXiv:2010.10182</a> [<a href="http://arxiv.org/pdf/2010.10182" target="_blank">pdf</a>]

<h2>Action-Conditional Recurrent Kalman Networks For Forward and Inverse Dynamics Learning. (arXiv:2010.10201v1 [cs.RO])</h2>
<h3>Vaisakh Shaj, Philipp Becker, Dieter Buchler, Harit Pandya, Niels van Duijkeren, C. James Taylor, Marc Hanheide, Gerhard Neumann</h3>
<p>Estimating accurate forward and inverse dynamics models is a crucial
component of model-based control for sophisticated robots such as robots driven
by hydraulics, artificial muscles, or robots dealing with different contact
situations. Analytic models to such processes are often unavailable or
inaccurate due to complex hysteresis effects, unmodelled friction and stiction
phenomena,and unknown effects during contact situations. A promising approach
is to obtain spatio-temporal models in a data-driven way using recurrent neural
networks, as they can overcome those issues. However, such models often do not
meet accuracy demands sufficiently, degenerate in performance for the required
high sampling frequencies and cannot provide uncertainty estimates. We adopt a
recent probabilistic recurrent neural network architecture, called Re-current
Kalman Networks (RKNs), to model learning by conditioning its transition
dynamics on the control actions. RKNs outperform standard recurrent networks
such as LSTMs on many state estimation tasks. Inspired by Kalman filters, the
RKN provides an elegant way to achieve action conditioning within its recurrent
cell by leveraging additive interactions between the current latent state and
the action variables. We present two architectures, one for forward model
learning and one for inverse model learning. Both architectures significantly
outperform exist-ing model learning frameworks as well as analytical models in
terms of prediction performance on a variety of real robot dynamics models.
</p>
<a href="http://arxiv.org/abs/2010.10201" target="_blank">arXiv:2010.10201</a> [<a href="http://arxiv.org/pdf/2010.10201" target="_blank">pdf</a>]

<h2>SoccerMap: A Deep Learning Architecture for Visually-Interpretable Analysis in Soccer. (arXiv:2010.10202v1 [cs.LG])</h2>
<h3>Javier Fern&#xe1;ndez (1 and 2), Luke Bornn (3) ((1) Polytechnic University of Catalonia, (2) FC Barcelona, (3) Simon Fraser University)</h3>
<p>We present a fully convolutional neural network architecture that is capable
of estimating full probability surfaces of potential passes in soccer, derived
from high-frequency spatiotemporal data. The network receives layers of
low-level inputs and learns a feature hierarchy that produces predictions at
different sampling levels, capturing both coarse and fine spatial details. By
merging these predictions, we can produce visually-rich probability surfaces
for any game situation that allows coaches to develop a fine-grained analysis
of players' positioning and decision-making, an as-yet little-explored area in
sports. We show the network can perform remarkably well in the estimation of
pass success probability, and present how it can be adapted easily to approach
two other challenging problems: the estimation of pass-selection likelihood and
the prediction of the expected value of a pass. Our approach provides a novel
solution for learning a full prediction surface when there is only a
single-pixel correspondence between ground-truth outcomes and the predicted
probability map. The flexibility of this architecture allows its adaptation to
a great variety of practical problems in soccer. We also present a set of
practical applications, including the evaluation of passing risk at a player
level, the identification of the best potential passing options, and the
differentiation of passing tendencies between teams.
</p>
<a href="http://arxiv.org/abs/2010.10202" target="_blank">arXiv:2010.10202</a> [<a href="http://arxiv.org/pdf/2010.10202" target="_blank">pdf</a>]

<h2>Learn to Navigate Maplessly with Varied LiDAR Configurations: A Support Point Based Approach. (arXiv:2010.10209v1 [cs.RO])</h2>
<h3>Wei Zhang, Ning Liu, Yunfeng Zhang</h3>
<p>Deep reinforcement learning (DRL) demonstrates great potential in mapless
navigation domain. However, such a navigation model is normally restricted to a
fixed configuration of the range sensor because its input format is fixed. In
this paper, we propose a DRL model that can address range data obtained from
different range sensors with different installation positions. Our model first
extracts the goal-directed features from each obstacle point. Subsequently, it
chooses global obstacle features from all point-feature candidates and uses
these features for the final decision. As only a few points are used to support
the final decision, we refer to these points as support points and our approach
as support-point based navigation (SPN). Our model can handle data from
different LiDAR setups and demonstrates good performance in simulation and
real-world experiments. It can also be used to guide the installation of range
sensors to enhance robot navigation performance.
</p>
<a href="http://arxiv.org/abs/2010.10209" target="_blank">arXiv:2010.10209</a> [<a href="http://arxiv.org/pdf/2010.10209" target="_blank">pdf</a>]

<h2>Quality of service based radar resource management using deep reinforcement learning. (arXiv:2010.10210v1 [eess.SP])</h2>
<h3>Sebastian Durst, Stefan Br&#xfc;ggenwirth</h3>
<p>An intelligent radar resource management is an essential milestone in the
development of a cognitive radar system. The quality of service based resource
allocation model (Q-RAM) is a framework allowing for intelligent decision
making but classical solutions seem insufficient for real-time application in a
modern radar system. In this paper, we present a solution for the Q-RAM radar
resource management problem using deep reinforcement learning considerably
improving on runtime performance.
</p>
<a href="http://arxiv.org/abs/2010.10210" target="_blank">arXiv:2010.10210</a> [<a href="http://arxiv.org/pdf/2010.10210" target="_blank">pdf</a>]

<h2>Simulated Chats for Task-oriented Dialog: Learning to Generate Conversations from Instructions. (arXiv:2010.10216v1 [cs.CL])</h2>
<h3>Biswesh Mohapatra, Gaurav Pandey, Danish Contractor, Sachindra Joshi</h3>
<p>Popular task-oriented dialog data sets such as MultiWOZ (Budzianowski et al.
2018) are created by providing crowd-sourced workers a goal instruction,
expressed in natural language, that describes the task to be accomplished.
Crowd-sourced workers play the role of a user and an agent to generate dialogs
to accomplish tasks involving booking restaurant tables, making train
reservations, calling a taxi etc. However, creating large crowd-sourced
datasets can be time consuming and expensive. To reduce the cost associated
with generating such dialog datasets, recent work has explored methods to
automatically create larger datasets from small samples.In this paper, we
present a data creation strategy that uses the pre-trained language model, GPT2
(Radford et al. 2018), to simulate the interaction between crowd-sourced
workers by creating a user bot and an agent bot. We train the simulators using
a smaller percentage of actual crowd-generated conversations and their
corresponding goal instructions. We demonstrate that by using the simulated
data, we achieve significant improvements in both low-resource setting as well
as in over-all task performance. To the best of our knowledge we are the first
to present a model for generating entire conversations by simulating the
crowd-sourced data collection process
</p>
<a href="http://arxiv.org/abs/2010.10216" target="_blank">arXiv:2010.10216</a> [<a href="http://arxiv.org/pdf/2010.10216" target="_blank">pdf</a>]

<h2>Quantum circuit architecture search: error mitigation and trainability enhancement for variational quantum solvers. (arXiv:2010.10217v1 [quant-ph])</h2>
<h3>Yuxuan Du, Tao Huang, Shan You, Min-Hsiu Hsieh, Dacheng Tao</h3>
<p>Quantum error mitigation techniques are at the heart of quantum computation.
Conventional quantum error correction codes are promising solutions, while they
become infeasible in the noisy intermediate scale quantum (NISQ) era, hurdled
by the required expensive resources. The variational quantum learning scheme
(VQLS), which is composed of trainable quantum circuits and a gradient-based
classical optimizer, could partially adapt the noise affect by tuning the
trainable parameters. However, both empirical and theoretical results have
shown that for most variational quantum algorithms, noise can deteriorate their
performances evidently when the problem size scales. Furthermore, VQLS suffers
from the barren plateau phenomenon. Here we devise a resource and runtime
efficient scheme, i.e., quantum architecture search scheme (QAS), to better
improve the robustness and trainability of VQLS. Particularly, given a learning
task, QAS actively seeks an optimal architecture among all possible circuit
architectures to balance benefits and side-effects brought by adding quantum
gates, where more quantum operations enable a stronger expressive power of the
quantum model but introduce a larger amount of noise and more serious barren
plateau scenario. To this end, QAS implicitly learns a rule that can well
suppress the influence of quantum noise and the barren plateau. We implement
QAS on both the numerical simulator and real quantum hardware via the IBM cloud
to accomplish the data classification and the quantum ground state
approximation tasks. Numerical and experimental results exhibit that QAS
outperforms conventional variational quantum algorithms with heuristic circuit
architectures. Our work provides guidance for developing advanced learning
based quantum error mitigation techniques on near-term quantum devices.
</p>
<a href="http://arxiv.org/abs/2010.10217" target="_blank">arXiv:2010.10217</a> [<a href="http://arxiv.org/pdf/2010.10217" target="_blank">pdf</a>]

<h2>Model-specific Data Subsampling with Influence Functions. (arXiv:2010.10218v1 [cs.LG])</h2>
<h3>Anant Raj, Cameron Musco, Lester Mackey, Nicolo Fusi</h3>
<p>Model selection requires repeatedly evaluating models on a given dataset and
measuring their relative performances. In modern applications of machine
learning, the models being considered are increasingly more expensive to
evaluate and the datasets of interest are increasing in size. As a result, the
process of model selection is time-consuming and computationally inefficient.
In this work, we develop a model-specific data subsampling strategy that
improves over random sampling whenever training points have varying influence.
Specifically, we leverage influence functions to guide our selection strategy,
proving theoretically, and demonstrating empirically that our approach quickly
selects high-quality models.
</p>
<a href="http://arxiv.org/abs/2010.10218" target="_blank">arXiv:2010.10218</a> [<a href="http://arxiv.org/pdf/2010.10218" target="_blank">pdf</a>]

<h2>Complete Multilingual Neural Machine Translation. (arXiv:2010.10239v1 [cs.CL])</h2>
<h3>Markus Freitag, Orhan Firat</h3>
<p>Multilingual Neural Machine Translation (MNMT) models are commonly trained on
a joint set of bilingual corpora which is acutely English-centric (i.e. English
either as the source or target language). While direct data between two
languages that are non-English is explicitly available at times, its use is not
common. In this paper, we first take a step back and look at the commonly used
bilingual corpora (WMT), and resurface the existence and importance of implicit
structure that existed in it: multi-way alignment across examples (the same
sentence in more than two languages). We set out to study the use of multi-way
aligned examples to enrich the original English-centric parallel corpora. We
reintroduce this direct parallel data from multi-way aligned corpora between
all source and target languages. By doing so, the English-centric graph expands
into a complete graph, every language pair being connected. We call MNMT with
such connectivity pattern complete Multilingual Neural Machine Translation
(cMNMT) and demonstrate its utility and efficacy with a series of experiments
and analysis. In combination with a novel training data sampling strategy that
is conditioned on the target language only, cMNMT yields competitive
translation quality for all language pairs. We further study the size effect of
multi-way aligned data, its transfer learning capabilities and how it eases
adding a new language in MNMT. Finally, we stress test cMNMT at scale and
demonstrate that we can train a cMNMT model with up to 111*112=12,432 language
pairs that provides competitive translation quality for all language pairs.
</p>
<a href="http://arxiv.org/abs/2010.10239" target="_blank">arXiv:2010.10239</a> [<a href="http://arxiv.org/pdf/2010.10239" target="_blank">pdf</a>]

<h2>BYOL works even without batch statistics. (arXiv:2010.10241v1 [stat.ML])</h2>
<h3>Pierre H. Richemond, Jean-Bastien Grill, Florent Altch&#xe9;, Corentin Tallec, Florian Strub, Andrew Brock, Samuel Smith, Soham De, Razvan Pascanu, Bilal Piot, Michal Valko</h3>
<p>Bootstrap Your Own Latent (BYOL) is a self-supervised learning approach for
image representation. From an augmented view of an image, BYOL trains an online
network to predict a target network representation of a different augmented
view of the same image. Unlike contrastive methods, BYOL does not explicitly
use a repulsion term built from negative pairs in its training objective. Yet,
it avoids collapse to a trivial, constant representation. Thus, it has recently
been hypothesized that batch normalization (BN) is critical to prevent collapse
in BYOL. Indeed, BN flows gradients across batch elements, and could leak
information about negative views in the batch, which could act as an implicit
negative (contrastive) term. However, we experimentally show that replacing BN
with a batch-independent normalization scheme (namely, a combination of group
normalization and weight standardization) achieves performance comparable to
vanilla BYOL ($73.9\%$ vs. $74.3\%$ top-1 accuracy under the linear evaluation
protocol on ImageNet with ResNet-$50$). Our finding disproves the hypothesis
that the use of batch statistics is a crucial ingredient for BYOL to learn
useful representations.
</p>
<a href="http://arxiv.org/abs/2010.10241" target="_blank">arXiv:2010.10241</a> [<a href="http://arxiv.org/pdf/2010.10241" target="_blank">pdf</a>]

<h2>Preventing Personal Data Theft in Images with Adversarial ML. (arXiv:2010.10242v1 [cs.CV])</h2>
<h3>Thomas Cilloni, Wei Wang, Charles Walter, Charles Fleming</h3>
<p>Facial recognition tools are becoming exceptionally accurate in identifying
people from images. However, this comes at the cost of privacy for users of
online services with photo management (e.g. social media platforms).
Particularly troubling is the ability to leverage unsupervised learning to
recognize faces even when the user has not labeled their images. This is made
simpler by modern facial recognition tools, such as FaceNet, that use encoders
to generate low dimensional embeddings that can be clustered to learn
previously unknown faces. In this paper, we propose a strategy to generate
non-invasive noise masks to apply to facial images for a newly introduced user,
yielding adversarial examples and preventing the formation of identifiable
clusters in the embedding space. We demonstrate the effectiveness of our method
by showing that various classification and clustering methods cannot reliably
cluster the adversarial examples we generate.
</p>
<a href="http://arxiv.org/abs/2010.10242" target="_blank">arXiv:2010.10242</a> [<a href="http://arxiv.org/pdf/2010.10242" target="_blank">pdf</a>]

<h2>MLCask: Efficient Management of Component Evolution in Collaborative Data Analytics Pipelines. (arXiv:2010.10246v1 [cs.SE])</h2>
<h3>Zhaojing Luo, Sai Ho Yeung, Meihui Zhang, Kaiping Zheng, Gang Chen, Feiyi Fan, Qian Lin, Kee Yuan Ngiam, Beng Chin Ooi</h3>
<p>With the ever-increasing adoption of machine learning for data analytics,
maintaining a machine learning pipeline is becoming more complex as both the
datasets and trained models evolve with time. In a collaborative environment,
the changes and updates due to pipeline evolution often cause cumbersome
coordination and maintenance work, raising the costs and making it hard to use.
Existing solutions, unfortunately, do not address the version evolution
problem, especially in a collaborative environment where non-linear version
control semantics are necessary to isolate operations made by different user
roles. The lack of version control semantics also incurs unnecessary storage
consumption and lowers efficiency due to data duplication and repeated data
pre-processing, which are avoidable. In this paper, we identify two main
challenges that arise during the deployment of machine learning pipelines, and
address them with the design of versioning for an end-to-end analytics system
MLCask. The system supports multiple user roles with the ability to perform
Git-like branching and merging operations in the context of the machine
learning pipelines. We define and accelerate the metric-driven merge operation
by pruning the pipeline search tree using reusable history records and pipeline
compatibility information. Further, we design and implement the prioritized
pipeline search, which gives preference to the pipelines that probably yield
better performance. The effectiveness of MLCask is evaluated through an
extensive study over several real-world deployment cases. The performance
evaluation shows that the proposed merge operation is up to 7.8x faster and
saves up to 11.9x storage space than the baseline method that does not utilize
history records.
</p>
<a href="http://arxiv.org/abs/2010.10246" target="_blank">arXiv:2010.10246</a> [<a href="http://arxiv.org/pdf/2010.10246" target="_blank">pdf</a>]

<h2>Spatio-Temporal Mobility Patterns of On-demand Ride-hailing Service Users. (arXiv:2010.10249v1 [cs.SI])</h2>
<h3>Jiechao Zhang, Samiul Hasan, Xuedong Yan, Xiaobing Liu</h3>
<p>Understanding individual mobility behavior is critical for modeling urban
transportation. It provides deeper insights on the generative mechanisms of
human movements. Emerging data sources such as mobile phone call detail
records, social media posts, GPS observations, and smart card transactions have
been used before to reveal individual mobility behavior. In this paper, we
report the spatio-temporal mobility behaviors using large-scale data collected
from a ride-hailing service platform. Based on passenger-level travel
information, we develop an algorithm to identify users' visited places and the
category of those places. To characterize temporal movement patterns, we reveal
the differences in trip generation characteristics between commuting and
non-commuting trips and the distribution of gap time between consecutive trips.
To understand spatial mobility patterns, we observe the distribution of the
number of visited places and their rank, the spatial distribution of residences
and workplaces, and the distributions of travel distance and travel time. Our
analysis highlights the differences in mobility patterns of the users of
ride-hailing services, compared to the findings of existing mobility studies
based on other data sources. It shows the potential of developing
high-resolution individual-level mobility models that can predict the demand of
emerging mobility services with high fidelity and accuracy.
</p>
<a href="http://arxiv.org/abs/2010.10249" target="_blank">arXiv:2010.10249</a> [<a href="http://arxiv.org/pdf/2010.10249" target="_blank">pdf</a>]

<h2>Synthesis of COVID-19 Chest X-rays using Unpaired Image-to-Image Translation. (arXiv:2010.10266v1 [eess.IV])</h2>
<h3>Hasib Zunair, A. Ben Hamza</h3>
<p>Motivated by the lack of publicly available datasets of chest radiographs of
positive patients with Coronavirus disease 2019 (COVID-19), we build the
first-of-its-kind open dataset of synthetic COVID-19 chest X-ray images of high
fidelity using an unsupervised domain adaptation approach by leveraging class
conditioning and adversarial training. Our contributions are twofold. First, we
show considerable performance improvements on COVID-19 detection using various
deep learning architectures when employing synthetic images as additional
training set. Second, we show how our image synthesis method can serve as a
data anonymization tool by achieving comparable detection performance when
trained only on synthetic data. In addition, the proposed data generation
framework offers a viable solution to the COVID-19 detection in particular, and
to medical image classification tasks in general. Our publicly available
benchmark dataset consists of 21,295 synthetic COVID-19 chest X-ray images. The
insights gleaned from this dataset can be used for preventive actions in the
fight against the COVID-19 pandemic.
</p>
<a href="http://arxiv.org/abs/2010.10266" target="_blank">arXiv:2010.10266</a> [<a href="http://arxiv.org/pdf/2010.10266" target="_blank">pdf</a>]

<h2>Pedestrian Intention Prediction: A Multi-task Perspective. (arXiv:2010.10270v1 [cs.CV])</h2>
<h3>Smail Ait Bouhsain, Saeed Saadatnejad, Alexandre Alahi</h3>
<p>In order to be globally deployed, autonomous cars must guarantee the safety
of pedestrians. This is the reason why forecasting pedestrians' intentions
sufficiently in advance is one of the most critical and challenging tasks for
autonomous vehicles. This work tries to solve this problem by jointly
predicting the intention and visual states of pedestrians. In terms of visual
states, whereas previous work focused on x-y coordinates, we will also predict
the size and indeed the whole bounding box of the pedestrian. The method is a
recurrent neural network in a multi-task learning approach. It has one head
that predicts the intention of the pedestrian for each one of its future
position and another one predicting the visual states of the pedestrian.
Experiments on the JAAD dataset show the superiority of the performance of our
method compared to previous works for intention prediction. Also, although its
simple architecture (more than 2 times faster), the performance of the bounding
box prediction is comparable to the ones yielded by much more complex
architectures. Our code is available online.
</p>
<a href="http://arxiv.org/abs/2010.10270" target="_blank">arXiv:2010.10270</a> [<a href="http://arxiv.org/pdf/2010.10270" target="_blank">pdf</a>]

<h2>Graph Fairing Convolutional Networks for Anomaly Detection. (arXiv:2010.10274v1 [cs.LG])</h2>
<h3>Mahsa Mesgaran, A. Ben Hamza</h3>
<p>Graph convolution is a fundamental building block for many deep neural
networks on graph-structured data. In this paper, we introduce a simple, yet
very effective graph convolutional network with skip connections for
semi-supervised anomaly detection. The proposed multi-layer network
architecture is theoretically motivated by the concept of implicit fairing in
geometry processing, and comprises a graph convolution module for aggregating
information from immediate node neighbors and a skip connection module for
combining layer-wise neighborhood representations. In addition to capturing
information from distant graph nodes through skip connections between the
network's layers, our approach exploits both the graph structure and node
features for learning discriminative node representations. The effectiveness of
our model is demonstrated through extensive experiments on five benchmark
datasets, achieving better or comparable anomaly detection results against
strong baseline methods.
</p>
<a href="http://arxiv.org/abs/2010.10274" target="_blank">arXiv:2010.10274</a> [<a href="http://arxiv.org/pdf/2010.10274" target="_blank">pdf</a>]

<h2>Leveraging the structure of musical preference in content-aware music recommendation. (arXiv:2010.10276v1 [cs.IR])</h2>
<h3>Paul Magron, C&#xe9;dric F&#xe9;votte</h3>
<p>State-of-the-art music recommendation systems are based on collaborative
filtering, which predicts a user's interest from his listening habits and
similarities with other users' profiles. These approaches are agnostic to the
song content, and therefore face the cold-start problem: they cannot recommend
novel songs without listening history. To tackle this issue, content-aware
recommendation incorporates information about the songs that can be used for
recommending new items. Most methods falling in this category exploit either
user-annotated tags, acoustic features or deeply-learned features.
Consequently, these content features do not have a clear musicological meaning,
thus they are not necessarily relevant from a musical preference perspective.
In this work, we propose instead to leverage a model of musical preference
which originates from the field of music psychology. From low-level acoustic
features we extract three factors (arousal, valence and depth), which
accurately describe musical taste. Then we integrate those into a collaborative
filtering framework for content-aware music recommendation. Experiments
conducted on large-scale data show that this approach is able to address the
cold-start problem, while using a compact and meaningful set of musical
features.
</p>
<a href="http://arxiv.org/abs/2010.10276" target="_blank">arXiv:2010.10276</a> [<a href="http://arxiv.org/pdf/2010.10276" target="_blank">pdf</a>]

<h2>RAN Cognitive Controller. (arXiv:2010.10278v1 [cs.NI])</h2>
<h3>Anubhab Banerjee, Stephen S. Mwanje, Georg Carle</h3>
<p>Cognitive Autonomous Networks (CAN) deploys learning based Cognitive
Functions (CF) instead of conventional rule-based SON Functions (SF) as Network
Automation Functions (NAF) to increase the system autonomy. These CFs work in
parallel sharing the same resources which give rise to conflicts among them
which cannot be resolved using conventional rule based approach. Our main
target is to design a Controller which can resolve any type of conflicts among
the CFs in a dynamic way.
</p>
<a href="http://arxiv.org/abs/2010.10278" target="_blank">arXiv:2010.10278</a> [<a href="http://arxiv.org/pdf/2010.10278" target="_blank">pdf</a>]

<h2>Anisotropic Graph Convolutional Network for Semi-supervised Learning. (arXiv:2010.10284v1 [cs.LG])</h2>
<h3>Mahsa Mesgaran, A. Ben Hamza</h3>
<p>Graph convolutional networks learn effective node embeddings that have proven
to be useful in achieving high-accuracy prediction results in semi-supervised
learning tasks, such as node classification. However, these networks suffer
from the issue of over-smoothing and shrinking effect of the graph due in large
part to the fact that they diffuse features across the edges of the graph using
a linear Laplacian flow. This limitation is especially problematic for the task
of node classification, where the goal is to predict the label associated with
a graph node. To address this issue, we propose an anisotropic graph
convolutional network for semi-supervised node classification by introducing a
nonlinear function that captures informative features from nodes, while
preventing oversmoothing. The proposed framework is largely motivated by the
good performance of anisotropic diffusion in image and geometry processing, and
learns nonlinear representations based on local graph structure and node
features. The effectiveness of our approach is demonstrated on three citation
networks and two image datasets, achieving better or comparable classification
accuracy results compared to the standard baseline methods.
</p>
<a href="http://arxiv.org/abs/2010.10284" target="_blank">arXiv:2010.10284</a> [<a href="http://arxiv.org/pdf/2010.10284" target="_blank">pdf</a>]

<h2>Bi-directional Cognitive Thinking Network for Machine Reading Comprehension. (arXiv:2010.10286v1 [cs.CL])</h2>
<h3>Wei Peng, Yue Hu, Luxi Xing, Yuqiang Xie, Jing Yu, Yajing Sun, Xiangpeng Wei</h3>
<p>We propose a novel Bi-directional Cognitive Knowledge Framework (BCKF) for
reading comprehension from the perspective of complementary learning systems
theory. It aims to simulate two ways of thinking in the brain to answer
questions, including reverse thinking and inertial thinking. To validate the
effectiveness of our framework, we design a corresponding Bi-directional
Cognitive Thinking Network (BCTN) to encode the passage and generate a question
(answer) given an answer (question) and decouple the bi-directional knowledge.
The model has the ability to reverse reasoning questions which can assist
inertial thinking to generate more accurate answers. Competitive improvement is
observed in DuReader dataset, confirming our hypothesis that bi-directional
knowledge helps the QA task. The novel framework shows an interesting
perspective on machine reading comprehension and cognitive science.
</p>
<a href="http://arxiv.org/abs/2010.10286" target="_blank">arXiv:2010.10286</a> [<a href="http://arxiv.org/pdf/2010.10286" target="_blank">pdf</a>]

<h2>Automatic multitrack mixing with a differentiable mixing console of neural audio effects. (arXiv:2010.10291v1 [eess.AS])</h2>
<h3>Christian J. Steinmetz, Jordi Pons, Santiago Pascual, Joan Serr&#xe0;</h3>
<p>Applications of deep learning to automatic multitrack mixing are largely
unexplored. This is partly due to the limited available data, coupled with the
fact that such data is relatively unstructured and variable. To address these
challenges, we propose a domain-inspired model with a strong inductive bias for
the mixing task. We achieve this with the application of pre-trained
sub-networks and weight sharing, as well as with a sum/difference stereo loss
function. The proposed model can be trained with a limited number of examples,
is permutation invariant with respect to the input ordering, and places no
limit on the number of input sources. Furthermore, it produces human-readable
mixing parameters, allowing users to manually adjust or refine the generated
mix. Results from a perceptual evaluation involving audio engineers indicate
that our approach generates mixes that outperform baseline approaches. To the
best of our knowledge, this work demonstrates the first approach in learning
multitrack mixing conventions from real-world data at the waveform level,
without knowledge of the underlying mixing parameters.
</p>
<a href="http://arxiv.org/abs/2010.10291" target="_blank">arXiv:2010.10291</a> [<a href="http://arxiv.org/pdf/2010.10291" target="_blank">pdf</a>]

<h2>A Federated Learning Approach to Anomaly Detection in Smart Buildings. (arXiv:2010.10293v1 [cs.LG])</h2>
<h3>Raed Abdel Sater, A. Ben Hamza</h3>
<p>Internet of Things (IoT) sensors in smart buildings are becoming increasingly
ubiquitous, making buildings more livable, energy efficient, and sustainable.
These devices sense the environment and generate multivariate temporal data of
paramount importance for detecting anomalies and improving the prediction of
energy usage in smart buildings. However, detecting these anomalies in
centralized systems is often plagued by a huge delay in response time. To
overcome this issue, we formulate the anomaly detection problem in a federated
learning setting by leveraging the multi-task learning paradigm, which aims at
solving multiple tasks simultaneously while taking advantage of the
similarities and differences across tasks. We propose a novel privacy-by-design
federated deep learning model based on a recurrent neural network architecture,
and we demonstrate that it is more than twice as fast during training
convergence compared to its centralized counterpart. The effectiveness of our
federated learning approach is demonstrated on simulated datasets generated by
following the distribution of real data from a General Electric Current smart
building, achieving state-of-the-art performance compared to baseline methods
in both classification and regression tasks.
</p>
<a href="http://arxiv.org/abs/2010.10293" target="_blank">arXiv:2010.10293</a> [<a href="http://arxiv.org/pdf/2010.10293" target="_blank">pdf</a>]

<h2>The Detection of Thoracic Abnormalities ChestX-Det10 Challenge Results. (arXiv:2010.10298v1 [eess.IV])</h2>
<h3>Jie Lian, Jingyu Liu, Yizhou Yu, Mengyuan Ding, Yaoci Lu, Yi Lu, Jie Cai, Deshou Lin, Miao Zhang, Zhe Wang, Kai He, Yijie Yu</h3>
<p>The detection of thoracic abnormalities challenge is organized by the
Deepwise AI Lab. The challenge is divided into two rounds. In this paper, we
present the results of 6 teams which reach the second round. The challenge
adopts the ChestX-Det10 dateset proposed by the Deepwise AI Lab. ChestX-Det10
is the first chest X-Ray dataset with instance-level annotations, including 10
categories of disease/abnormality of 3,543 images. We randomly split all data
into 3001 images for training and 542 images for testing.
</p>
<a href="http://arxiv.org/abs/2010.10298" target="_blank">arXiv:2010.10298</a> [<a href="http://arxiv.org/pdf/2010.10298" target="_blank">pdf</a>]

<h2>Interpretable Deep Learning for Automatic Diagnosis of 12-lead Electrocardiogram. (arXiv:2010.10328v1 [cs.LG])</h2>
<h3>Dongdong Zhang, Xiaohui Yuan, Ping Zhang</h3>
<p>Electrocardiogram (ECG) is a widely used reliable, non-invasive approach for
cardiovascular disease diagnosis. With the rapid growth of ECG examinations and
the insufficiency of cardiologists, accurate and automatic diagnosis of ECG
signals has become a hot research topic. Deep learning methods have
demonstrated promising results in predictive healthcare tasks. In this paper,
we developed a deep neural network for multi-label classification of cardiac
arrhythmias in 12-lead ECG recordings. Experiments on a public 12-lead ECG
dataset showed the effectiveness of our method. The proposed model achieved an
average area under the receiver operating characteristic curve (AUC) of 0.970
and an average F1 score of 0.813. The deep model showed superior performance
than 4 machine learning methods learned from extracted expert features.
Besides, the deep models trained on single-lead ECGs produce lower performance
than using all 12 leads simultaneously. The best-performing leads are lead I,
aVR, and V5 among 12 leads. Finally, we employed the SHapley Additive
exPlanations (SHAP) method to interpret the model's behavior at both patient
level and population level. Our code is freely available at
https://github.com/onlyzdd/ecg-diagnosis.
</p>
<a href="http://arxiv.org/abs/2010.10328" target="_blank">arXiv:2010.10328</a> [<a href="http://arxiv.org/pdf/2010.10328" target="_blank">pdf</a>]

<h2>DLWIoT: Deep Learning-based Watermarking for Authorized IoT Onboarding. (arXiv:2010.10334v1 [cs.CR])</h2>
<h3>Spyridon Mastorakis, Xin Zhong, Pei-Chi Huang, Reza Tourani</h3>
<p>The onboarding of IoT devices by authorized users constitutes both a
challenge and a necessity in a world, where the number of IoT devices and the
tampering attacks against them continuously increase. Commonly used onboarding
techniques today include the use of QR codes, pin codes, or serial numbers.
These techniques typically do not protect against unauthorized device access-a
QR code is physically printed on the device, while a pin code may be included
in the device packaging. As a result, any entity that has physical access to a
device can onboard it onto their network and, potentially, tamper it
(e.g.,install malware on the device). To address this problem, in this paper,
we present a framework, called Deep Learning-based Watermarking for authorized
IoT onboarding (DLWIoT), featuring a robust and fully automated image
watermarking scheme based on deep neural networks. DLWIoT embeds user
credentials into carrier images (e.g., QR codes printed on IoT devices), thus
enables IoT onboarding only by authorized users. Our experimental results
demonstrate the feasibility of DLWIoT, indicating that authorized users can
onboard IoT devices with DLWIoT within 2.5-3sec.
</p>
<a href="http://arxiv.org/abs/2010.10334" target="_blank">arXiv:2010.10334</a> [<a href="http://arxiv.org/pdf/2010.10334" target="_blank">pdf</a>]

<h2>Asynchronous Edge Learning using Cloned Knowledge Distillation. (arXiv:2010.10338v1 [cs.LG])</h2>
<h3>Sang-ho Lee, Kiyoon Yoo, Nojun Kwak</h3>
<p>With the increasing demand for more and more data, the federated learning
(FL) methods, which try to utilize highly distributed on-device local data in
the training process, have been proposed.However, fledgling services provided
by startup companies not only have limited number of clients, but also have
minimal resources for constant communications between the server and multiple
clients. In addition, in a real-world environment where the user pool changes
dynamically, the FL system must be able to efficiently utilize rapid inflow and
outflow of users, while at the same time experience minimal bottleneck due to
network delays of multiple users. In this respect, we amend the federated
learning scenario to a more flexible asynchronous edge learning. To solve the
aforementioned learning problems, we propose an asynchronous model-based
communication method with knowledge distillation. In particular, we dub our
knowledge distillation scheme as "cloned distillation" and explain how it is
different from other knowledge distillation method. In brief, we found that in
knowledge distillation between the teacher and the student there exist two
contesting traits in the student: to attend to the teacher's knowledge or to
retain its own knowledge exclusive to the teacher. And in this edge learning
scenario, the attending property should be amplified rather than the retaining
property, because teachers are dispatched to the users to learn from them and
recollected at the server to teach the core model. Our asynchronous edge
learning method can elastically handle the dynamic inflow and outflow of users
in a service with minimal communication cost, operate with essentially no
bottleneck due to user delay, and protect user's privacy. Also we found that it
is robust to users who behave abnormally or maliciously.
</p>
<a href="http://arxiv.org/abs/2010.10338" target="_blank">arXiv:2010.10338</a> [<a href="http://arxiv.org/pdf/2010.10338" target="_blank">pdf</a>]

<h2>Learning to Learn Variational Semantic Memory. (arXiv:2010.10341v1 [cs.LG])</h2>
<h3>Xiantong Zhen, Yingjun Du, Huan Xiong, Qiang Qiu, Cees G. M. Snoek, Ling Shao</h3>
<p>In this paper, we introduce variational semantic memory into meta-learning to
acquire long-term knowledge for few-shot learning. The variational semantic
memory accrues and stores semantic information for the probabilistic inference
of class prototypes in a hierarchical Bayesian framework. The semantic memory
is grown from scratch and gradually consolidated by absorbing information from
tasks it experiences. By doing so, it is able to accumulate long-term, general
knowledge that enables it to learn new concepts of objects. We formulate memory
recall as the variational inference of a latent memory variable from addressed
contents, which offers a principled way to adapt the knowledge to individual
tasks. Our variational semantic memory, as a new long-term memory module,
confers principled recall and update mechanisms that enable semantic
information to be efficiently accrued and adapted for few-shot learning.
Experiments demonstrate that the probabilistic modelling of prototypes achieves
a more informative representation of object classes compared to deterministic
vectors. The consistent new state-of-the-art performance on four benchmarks
shows the benefit of variational semantic memory in boosting few-shot
recognition.
</p>
<a href="http://arxiv.org/abs/2010.10341" target="_blank">arXiv:2010.10341</a> [<a href="http://arxiv.org/pdf/2010.10341" target="_blank">pdf</a>]

<h2>Deep Importance Sampling based on Regression for Model Inversion and Emulation. (arXiv:2010.10346v1 [stat.CO])</h2>
<h3>F. Llorente, L. Martino, D. Delgado, G. Camps-Valls</h3>
<p>Understanding systems by forward and inverse modeling is a recurrent topic of
research in many domains of science and engineering. In this context, Monte
Carlo methods have been widely used as powerful tools for numerical inference
and optimization. They require the choice of a suitable proposal density that
is crucial for their performance. For this reason, several adaptive importance
sampling (AIS) schemes have been proposed in the literature. We here present an
AIS framework called Regression-based Adaptive Deep Importance Sampling
(RADIS). In RADIS, the key idea is the adaptive construction via regression of
a non-parametric proposal density (i.e., an emulator), which mimics the
posterior distribution and hence minimizes the mismatch between proposal and
target densities. RADIS is based on a deep architecture of two (or more) nested
IS schemes, in order to draw samples from the constructed emulator. The
algorithm is highly efficient since employs the posterior approximation as
proposal density, which can be improved adding more support points. As a
consequence, RADIS asymptotically converges to an exact sampler under mild
conditions. Additionally, the emulator produced by RADIS can be in turn used as
a cheap surrogate model for further studies. We introduce two specific RADIS
implementations that use Gaussian Processes (GPs) and Nearest Neighbors (NN)
for constructing the emulator. Several numerical experiments and comparisons
show the benefits of the proposed schemes. A real-world application in remote
sensing model inversion and emulation confirms the validity of the approach.
</p>
<a href="http://arxiv.org/abs/2010.10346" target="_blank">arXiv:2010.10346</a> [<a href="http://arxiv.org/pdf/2010.10346" target="_blank">pdf</a>]

<h2>Resource Management Schemes for Cloud-Native Platforms with Computing Containers of Docker and Kubernetes. (arXiv:2010.10350v1 [cs.DC])</h2>
<h3>Ying Mao, Yuqi Fu, Suwen Gu, Sudip Vhaduri, Long Cheng, Qingzhi Liu</h3>
<p>Businesses have made increasing adoption and incorporation of cloud
technology into internal processes in the last decade. The cloud-based
deployment provides on-demand availability without active management. More
recently, the concept of cloud-native application has been proposed and
represents an invaluable step toward helping organizations develop software
faster and update it more frequently to achieve dramatic business outcomes.
Cloud-native is an approach to build and run applications that exploit the
cloud computing delivery model's advantages. It is more about how applications
are created and deployed than where. The container-based virtualization
technology, such as Docker and Kubernetes, serves as the foundation for
cloud-native applications. This paper investigates the performance of two
popular computational-intensive applications, big data, and deep learning, in a
cloud-native environment. We analyze the system overhead and resource usage for
these applications. Through extensive experiments, we show that the completion
time reduces by up to 79.4% by changing the default setting and increases by up
to 96.7% due to different resource management schemes on two platforms.
Additionally, the resource release is delayed by up to 116.7% across different
systems. Our work can guide developers, administrators, and researchers to
better design and deploy their applications by selecting and configuring a
hosting platform.
</p>
<a href="http://arxiv.org/abs/2010.10350" target="_blank">arXiv:2010.10350</a> [<a href="http://arxiv.org/pdf/2010.10350" target="_blank">pdf</a>]

<h2>Deep Learning for Surface Wave Identification in Distributed Acoustic Sensing Data. (arXiv:2010.10352v1 [eess.SP])</h2>
<h3>Vincent Dumont, Ver&#xf3;nica Rodr&#xed;guez Tribaldos, Jonathan Ajo-Franklin, Kesheng Wu</h3>
<p>Moving loads such as cars and trains are very useful sources of seismic
waves, which can be analyzed to retrieve information on the seismic velocity of
subsurface materials using the techniques of ambient noise seismology. This
information is valuable for a variety of applications such as geotechnical
characterization of the near-surface, seismic hazard evaluation, and
groundwater monitoring. However, for such processes to converge quickly, data
segments with appropriate noise energy should be selected. Distributed Acoustic
Sensing (DAS) is a novel sensing technique that enables acquisition of these
data at very high spatial and temporal resolution for tens of kilometers. One
major challenge when utilizing the DAS technology is the large volume of data
that is produced, thereby presenting a significant Big Data challenge to find
regions of useful energy. In this work, we present a highly scalable and
efficient approach to process real, complex DAS data by integrating physics
knowledge acquired during a data exploration phase followed by deep supervised
learning to identify "useful" coherent surface waves generated by anthropogenic
activity, a class of seismic waves that is abundant on these recordings and is
useful for geophysical imaging. Data exploration and training were done on
130~Gigabytes (GB) of DAS measurements. Using parallel computing, we were able
to do inference on an additional 170~GB of data (or the equivalent of 10 days'
worth of recordings) in less than 30 minutes. Our method provides interpretable
patterns describing the interaction of ground-based human activities with the
buried sensors.
</p>
<a href="http://arxiv.org/abs/2010.10352" target="_blank">arXiv:2010.10352</a> [<a href="http://arxiv.org/pdf/2010.10352" target="_blank">pdf</a>]

<h2>Automotive Radar Interference Mitigation with Unfolded Robust PCA based on Residual Overcomplete Auto-Encoder Blocks. (arXiv:2010.10357v1 [eess.SP])</h2>
<h3>Nicolae-C&#x103;t&#x103;lin Ristea, Andrei Anghel, Radu Tudor Ionescu, Yonina C. Eldar</h3>
<p>Deep learning methods for automotive radar interference mitigation can
succesfully estimate the amplitude of targets, but fail to recover the phase of
the respective targets. In this paper, we propose an efficient and effective
technique based on unfolded robust Principal Component Analysis (RPCA) that is
able to estimate both amplitude and phase in the presence of interference. Our
contribution consists in introducing residual overcomplete auto-encoder
(ROC-AE) blocks into the recurrent architecture of unfolded RPCA, which results
in a deeper model that significantly outperforms unfolded RPCA as well as other
deep learning models.
</p>
<a href="http://arxiv.org/abs/2010.10357" target="_blank">arXiv:2010.10357</a> [<a href="http://arxiv.org/pdf/2010.10357" target="_blank">pdf</a>]

<h2>Bootleg: Chasing the Tail with Self-Supervised Named Entity Disambiguation. (arXiv:2010.10363v1 [cs.CL])</h2>
<h3>Laurel Orr, Megan Leszczynski, Simran Arora, Sen Wu, Neel Guha, Xiao Ling, Christopher Re</h3>
<p>A challenge for named entity disambiguation (NED), the task of mapping
textual mentions to entities in a knowledge base, is how to disambiguate
entities that appear rarely in the training data, termed tail entities. Humans
use subtle reasoning patterns based on knowledge of entity facts, relations,
and types to disambiguate unfamiliar entities. Inspired by these patterns, we
introduce Bootleg, a self-supervised NED system that is explicitly grounded in
reasoning patterns for disambiguation. We define core reasoning patterns for
disambiguation, create a learning procedure to encourage the self-supervised
model to learn the patterns, and show how to use weak supervision to enhance
the signals in the training data. Encoding the reasoning patterns in a simple
Transformer architecture, Bootleg meets or exceeds state-of-the-art on three
NED benchmarks. We further show that the learned representations from Bootleg
successfully transfer to other non-disambiguation tasks that require
entity-based knowledge: we set a new state-of-the-art in the popular TACRED
relation extraction task by 1.0 F1 points and demonstrate up to 8% performance
lift in highly optimized production search and assistant tasks at a major
technology company
</p>
<a href="http://arxiv.org/abs/2010.10363" target="_blank">arXiv:2010.10363</a> [<a href="http://arxiv.org/pdf/2010.10363" target="_blank">pdf</a>]

<h2>A Flatter Loss for Bias Mitigation in Cross-dataset Facial Age Estimation. (arXiv:2010.10368v1 [cs.CV])</h2>
<h3>Ali Akbari, Muhammad Awais, Zhen-Hua Feng, Ammarah Farooq, Josef Kittler</h3>
<p>Existing studies in facial age estimation have mostly focused on
intra-dataset protocols that assume training and test images captured under
similar conditions. However, this is rarely valid in practical applications,
where training and test sets usually have different characteristics. In this
paper, we advocate a cross-dataset protocol for age estimation benchmarking. In
order to improve the cross-dataset age estimation performance, we mitigate the
inherent bias caused by the learning algorithm itself. To this end, we propose
a novel loss function that is more effective for neural network training. The
relative smoothness of the proposed loss function is its advantage with regards
to the optimisation process performed by stochastic gradient descent. Its lower
gradient, compared with existing loss functions, facilitates the discovery of
and convergence to a better optimum, and consequently a better generalisation.
The cross-dataset experimental results demonstrate the superiority of the
proposed method over the state-of-the-art algorithms in terms of accuracy and
generalisation capability.
</p>
<a href="http://arxiv.org/abs/2010.10368" target="_blank">arXiv:2010.10368</a> [<a href="http://arxiv.org/pdf/2010.10368" target="_blank">pdf</a>]

<h2>Convolutional neural networks for automatic detection of Focal Cortical Dysplasia. (arXiv:2010.10373v1 [cs.CV])</h2>
<h3>Ruslan Aliev, Ekaterina Kondrateva, Maxim Sharaev, Oleg Bronov, Alexey Marinets, Sergey Subbotin, Alexander Bernstein, Evgeny Burnaev</h3>
<p>Focal cortical dysplasia (FCD) is one of the most common epileptogenic
lesions associated with cortical development malformations. However, the
accurate detection of the FCD relies on the radiologist professionalism, and in
many cases, the lesion could be missed. In this work, we solve the problem of
automatic identification of FCD on magnetic resonance images (MRI). For this
task, we improve recent methods of Deep Learning-based FCD detection and apply
it for a dataset of 15 labeled FCD patients. The model results in the
successful detection of FCD on 11 out of 15 subjects.
</p>
<a href="http://arxiv.org/abs/2010.10373" target="_blank">arXiv:2010.10373</a> [<a href="http://arxiv.org/pdf/2010.10373" target="_blank">pdf</a>]

<h2>Negotiating Team Formation Using Deep Reinforcement Learning. (arXiv:2010.10380v1 [cs.LG])</h2>
<h3>Yoram Bachrach, Richard Everett, Edward Hughes, Angeliki Lazaridou, Joel Z. Leibo, Marc Lanctot, Michael Johanson, Wojciech M. Czarnecki, Thore Graepel</h3>
<p>When autonomous agents interact in the same environment, they must often
cooperate to achieve their goals. One way for agents to cooperate effectively
is to form a team, make a binding agreement on a joint plan, and execute it.
However, when agents are self-interested, the gains from team formation must be
allocated appropriately to incentivize agreement. Various approaches for
multi-agent negotiation have been proposed, but typically only work for
particular negotiation protocols. More general methods usually require human
input or domain-specific data, and so do not scale. To address this, we propose
a framework for training agents to negotiate and form teams using deep
reinforcement learning. Importantly, our method makes no assumptions about the
specific negotiation protocol, and is instead completely experience driven. We
evaluate our approach on both non-spatial and spatially extended team-formation
negotiation environments, demonstrating that our agents beat hand-crafted bots
and reach negotiation outcomes consistent with fair solutions predicted by
cooperative game theory. Additionally, we investigate how the physical location
of agents influences negotiation outcomes.
</p>
<a href="http://arxiv.org/abs/2010.10380" target="_blank">arXiv:2010.10380</a> [<a href="http://arxiv.org/pdf/2010.10380" target="_blank">pdf</a>]

<h2>Imitation Learning of Hierarchical Driving Model: from Continuous Intention to Continuous Trajectory. (arXiv:2010.10393v1 [cs.RO])</h2>
<h3>Yunkai Wang, Dongkun Zhang, Jingke Wang, Zexi Chen, Yue Wang, Rong Xiong</h3>
<p>One of the challenges to reduce the gap between the machine and the human
level driving is how to endow the system with the learning capacity to deal
with the coupled complexity of environments, intentions, and dynamics. In this
paper, we propose a hierarchical driving model with explicit model of
continuous intention and continuous dynamics, which decouples the complexity in
the observation-to-action reasoning in the human driving data. Specifically,
the continuous intention module takes the route planning and perception to
generate a potential map encoded with obstacles and goals being expressed as
grid based potentials. Then, the potential map is regarded as a condition,
together with the current dynamics, to generate the trajectory. The trajectory
is modeled by a network based continuous function approximator, which naturally
reserves the derivatives for high-order supervision without any additional
parameters. Finally, we validate our method on both datasets and simulators,
demonstrating superior performance. The method is also deployed on the real
vehicle with loop latency, validating its effectiveness.
</p>
<a href="http://arxiv.org/abs/2010.10393" target="_blank">arXiv:2010.10393</a> [<a href="http://arxiv.org/pdf/2010.10393" target="_blank">pdf</a>]

<h2>Variational Dynamic Mixtures. (arXiv:2010.10403v1 [cs.LG])</h2>
<h3>Chen Qiu, Stephan Mandt, Maja Rudolph</h3>
<p>Deep probabilistic time series forecasting models have become an integral
part of machine learning. While several powerful generative models have been
proposed, we provide evidence that their associated inference models are
oftentimes too limited and cause the generative model to predict mode-averaged
dynamics. Modeaveraging is problematic since many real-world sequences are
highly multi-modal, and their averaged dynamics are unphysical (e.g., predicted
taxi trajectories might run through buildings on the street map). To better
capture multi-modality, we develop variational dynamic mixtures (VDM): a new
variational family to infer sequential latent variables. The VDM approximate
posterior at each time step is a mixture density network, whose parameters come
from propagating multiple samples through a recurrent architecture. This
results in an expressive multi-modal posterior approximation. In an empirical
study, we show that VDM outperforms competing approaches on highly multi-modal
datasets from different domains.
</p>
<a href="http://arxiv.org/abs/2010.10403" target="_blank">arXiv:2010.10403</a> [<a href="http://arxiv.org/pdf/2010.10403" target="_blank">pdf</a>]

<h2>Where Is the Normative Proof? Assumptions and Contradictions in ML Fairness Research. (arXiv:2010.10407v1 [cs.CY])</h2>
<h3>A. Feder Cooper</h3>
<p>Across machine learning (ML) sub-disciplines researchers make mathematical
assumptions to facilitate proof-writing. While such assumptions are necessary
for providing mathematical guarantees for how algorithms behave, they also
necessarily limit the applicability of these algorithms to different problem
settings. This practice is known - in fact, obvious - and accepted in ML
research. However, similar attention is not paid to the normative assumptions
that ground this work. I argue such assumptions are equally as important,
especially in areas of ML with clear social impact, such as fairness. This is
because, similar to how mathematical assumptions constrain applicability,
normative assumptions also limit algorithm applicability to certain problem
domains. I show that, in existing papers published in top venues, once
normative assumptions are clarified, it is often possible to get muddled
results. While the mathematical assumptions and results are sound, the implicit
normative assumptions and accompanying normative results contraindicate using
these methods in practical fairness applications.
</p>
<a href="http://arxiv.org/abs/2010.10407" target="_blank">arXiv:2010.10407</a> [<a href="http://arxiv.org/pdf/2010.10407" target="_blank">pdf</a>]

<h2>ConjNLI: Natural Language Inference Over Conjunctive Sentences. (arXiv:2010.10418v1 [cs.CL])</h2>
<h3>Swarnadeep Saha, Yixin Nie, Mohit Bansal</h3>
<p>Reasoning about conjuncts in conjunctive sentences is important for a deeper
understanding of conjunctions in English and also how their usages and
semantics differ from conjunctive and disjunctive boolean logic. Existing NLI
stress tests do not consider non-boolean usages of conjunctions and use
templates for testing such model knowledge. Hence, we introduce ConjNLI, a
challenge stress-test for natural language inference over conjunctive
sentences, where the premise differs from the hypothesis by conjuncts removed,
added, or replaced. These sentences contain single and multiple instances of
coordinating conjunctions ("and", "or", "but", "nor") with quantifiers,
negations, and requiring diverse boolean and non-boolean inferences over
conjuncts. We find that large-scale pre-trained language models like RoBERTa do
not understand conjunctive semantics well and resort to shallow heuristics to
make inferences over such sentences. As some initial solutions, we first
present an iterative adversarial fine-tuning method that uses synthetically
created training data based on boolean and non-boolean heuristics. We also
propose a direct model advancement by making RoBERTa aware of predicate
semantic roles. While we observe some performance gains, ConjNLI is still
challenging for current methods, thus encouraging interesting future work for
better understanding of conjunctions. Our data and code are publicly available
at: https://github.com/swarnaHub/ConjNLI
</p>
<a href="http://arxiv.org/abs/2010.10418" target="_blank">arXiv:2010.10418</a> [<a href="http://arxiv.org/pdf/2010.10418" target="_blank">pdf</a>]

<h2>A Lane Merge Coordination Model for a V2X Scenario. (arXiv:2010.10426v1 [cs.LG])</h2>
<h3>Luis Sequeira, Adam Szefer, Jamie Slome, Toktam Mahmoodi</h3>
<p>Cooperative driving using connectivity services has been a promising avenue
for autonomous vehicles, with the low latency and further reliability support
provided by 5th Generation Mobile Network (5G). In this paper, we present an
application for lane merge coordination based on a centralised system, for
connected cars. This application delivers trajectory recommendations to the
connected vehicles on the road. The application comprises of a Traffic
Orchestrator as the main component. We apply machine learning and data analysis
to predict whether a connected vehicle can successfully complete the
cooperative manoeuvre of a lane merge. Furthermore, the acceleration and
heading parameters that are necessary for the completion of a safe merge are
elaborated. The results demonstrate the performance of several existing
algorithms and how their main parameters were selected to avoid over-fitting.
</p>
<a href="http://arxiv.org/abs/2010.10426" target="_blank">arXiv:2010.10426</a> [<a href="http://arxiv.org/pdf/2010.10426" target="_blank">pdf</a>]

<h2>BERT2DNN: BERT Distillation with Massive Unlabeled Data for Online E-Commerce Search. (arXiv:2010.10442v1 [cs.LG])</h2>
<h3>Yunjiang Jiang, Yue Shang, Ziyang Liu, Hongwei Shen, Yun Xiao, Wei Xiong, Sulong Xu, Weipeng Yan, Di Jin</h3>
<p>Relevance has significant impact on user experience and business profit for
e-commerce search platform. In this work, we propose a data-driven framework
for search relevance prediction, by distilling knowledge from BERT and related
multi-layer Transformer teacher models into simple feed-forward networks with
large amount of unlabeled data. The distillation process produces a student
model that recovers more than 97\% test accuracy of teacher models on new
queries, at a serving cost that's several magnitude lower (latency 150x lower
than BERT-Base and 15x lower than the most efficient BERT variant, TinyBERT).
The applications of temperature rescaling and teacher model stacking further
boost model accuracy, without increasing the student model complexity.

We present experimental results on both in-house e-commerce search relevance
data as well as a public data set on sentiment analysis from the GLUE
benchmark. The latter takes advantage of another related public data set of
much larger scale, while disregarding its potentially noisy labels. Embedding
analysis and case study on the in-house data further highlight the strength of
the resulting model. By making the data processing and model training source
code public, we hope the techniques presented here can help reduce energy
consumption of the state of the art Transformer models and also level the
playing field for small organizations lacking access to cutting edge machine
learning hardwares.
</p>
<a href="http://arxiv.org/abs/2010.10442" target="_blank">arXiv:2010.10442</a> [<a href="http://arxiv.org/pdf/2010.10442" target="_blank">pdf</a>]

<h2>Snap-and-Chat Protocols: System Aspects. (arXiv:2010.10447v1 [cs.CR])</h2>
<h3>Joachim Neu, Ertem Nusret Tas, David Tse</h3>
<p>The availability-finality dilemma says that blockchain protocols cannot be
both available under dynamic participation and safe under network partition.
Snap-and-chat protocols have recently been proposed as a resolution to this
dilemma. A snap-and-chat protocol produces an always available ledger
containing a finalized prefix ledger which is always safe and catches up with
the available ledger whenever network conditions permit. In contrast to
existing handcrafted finality gadget based designs like Ethereum 2.0's
consensus protocol Gasper, snap-and-chat protocols are constructed as a
black-box composition of off-the-shelf BFT and longest chain protocols. In this
paper, we consider system aspects of snap-and-chat protocols and show how they
can provide two important features: 1) accountability, 2) support of light
clients. Through this investigation, a deeper understanding of the strengths
and challenges of snap-and-chat protocols is gained.
</p>
<a href="http://arxiv.org/abs/2010.10447" target="_blank">arXiv:2010.10447</a> [<a href="http://arxiv.org/pdf/2010.10447" target="_blank">pdf</a>]

<h2>Tilting at windmills: Data augmentation for deep pose estimation does not help with occlusions. (arXiv:2010.10451v1 [cs.CV])</h2>
<h3>Rafal Pytel, Osman Semih Kayhan, Jan C. van Gemert</h3>
<p>Occlusion degrades the performance of human pose estimation. In this paper,
we introduce targeted keypoint and body part occlusion attacks. The effects of
the attacks are systematically analyzed on the best performing methods. In
addition, we propose occlusion specific data augmentation techniques against
keypoint and part attacks. Our extensive experiments show that human pose
estimation methods are not robust to occlusion and data augmentation does not
solve the occlusion problems.
</p>
<a href="http://arxiv.org/abs/2010.10451" target="_blank">arXiv:2010.10451</a> [<a href="http://arxiv.org/pdf/2010.10451" target="_blank">pdf</a>]

<h2>Modeling Content and Context with Deep Relational Learning. (arXiv:2010.10453v1 [cs.CL])</h2>
<h3>Maria Leonor Pacheco, Dan Goldwasser</h3>
<p>Building models for realistic natural language tasks requires dealing with
long texts and accounting for complicated structural dependencies.
Neural-symbolic representations have emerged as a way to combine the reasoning
capabilities of symbolic methods, with the expressiveness of neural networks.
However, most of the existing frameworks for combining neural and symbolic
representations have been designed for classic relational learning tasks that
work over a universe of symbolic entities and relations. In this paper, we
present DRaiL, an open-source declarative framework for specifying deep
relational models, designed to support a variety of NLP scenarios. Our
framework supports easy integration with expressive language encoders, and
provides an interface to study the interactions between representation,
inference and learning.
</p>
<a href="http://arxiv.org/abs/2010.10453" target="_blank">arXiv:2010.10453</a> [<a href="http://arxiv.org/pdf/2010.10453" target="_blank">pdf</a>]

<h2>Towards Scalable Distributed Training of Deep Learning on Public Cloud Clusters. (arXiv:2010.10458v1 [cs.DC])</h2>
<h3>Shaohuai Shi, Xianhao Zhou, Shutao Song, Xingyao Wang, Zilin Zhu, Xue Huang, Xinan Jiang, Feihu Zhou, Zhenyu Guo, Liqiang Xie, Rui Lan, Xianbin Ouyang, Yan Zhang, Jieqian Wei, Jing Gong, Weiliang Lin, Ping Gao, Peng Meng, Xiaomin Xu, Chenyang Guo, Bo Yang, Zhibo Chen, Yongjian Wu, Xiaowen Chu</h3>
<p>Distributed training techniques have been widely deployed in large-scale deep
neural networks (DNNs) training on dense-GPU clusters. However, on public cloud
clusters, due to the moderate inter-connection bandwidth between instances,
traditional state-of-the-art distributed training systems cannot scale well in
training large-scale models. In this paper, we propose a new computing and
communication efficient top-k sparsification communication library for
distributed training. To further improve the system scalability, we optimize
I/O by proposing a simple yet efficient multi-level data caching mechanism and
optimize the update operation by introducing a novel parallel tensor operator.
Experimental results on a 16-node Tencent Cloud cluster (each node with 8
Nvidia Tesla V100 GPUs) show that our system achieves 25%-40% faster than
existing state-of-the-art systems on CNNs and Transformer. We finally break the
record on DAWNBench on training ResNet-50 to 93% top-5 accuracy on ImageNet.
</p>
<a href="http://arxiv.org/abs/2010.10458" target="_blank">arXiv:2010.10458</a> [<a href="http://arxiv.org/pdf/2010.10458" target="_blank">pdf</a>]

<h2>Investigating Cross-Domain Losses for Speech Enhancement. (arXiv:2010.10468v1 [cs.SD])</h2>
<h3>Sherif Abdulatif, Karim Armanious, Jayasankar T. Sajeev, Karim Guirguis, Bin Yang</h3>
<p>Recent years have seen a surge in the number of available frameworks for
speech enhancement (SE) and recognition. Whether model-based or constructed via
deep learning, these frameworks often rely in isolation on either time-domain
signals or time-frequency (TF) representations of speech data. In this study,
we investigate the advantages of each set of approaches by separately examining
their impact on speech intelligibility and quality. Furthermore, we combine the
fragmented benefits of time-domain and TF speech representations by introducing
two new cross-domain SE frameworks. A quantitative comparative analysis against
recent model-based and deep learning SE approaches is performed to illustrate
the merit of the proposed frameworks.
</p>
<a href="http://arxiv.org/abs/2010.10468" target="_blank">arXiv:2010.10468</a> [<a href="http://arxiv.org/pdf/2010.10468" target="_blank">pdf</a>]

<h2>Learning To Retrieve: How to Train a Dense Retrieval Model Effectively and Efficiently. (arXiv:2010.10469v1 [cs.IR])</h2>
<h3>Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Min Zhang, Shaoping Ma</h3>
<p>Ranking has always been one of the top concerns in information retrieval
research. For decades, lexical matching signal has dominated the ad-hoc
retrieval process, but it also has inherent defects, such as the vocabulary
mismatch problem. Recently, Dense Retrieval (DR) technique has been proposed to
alleviate these limitations by capturing the deep semantic relationship between
queries and documents. The training of most existing Dense Retrieval models
relies on sampling negative instances from the corpus to optimize a pairwise
loss function. Through investigation, we find that this kind of training
strategy is biased and fails to optimize full retrieval performance effectively
and efficiently. To solve this problem, we propose a Learning To Retrieve
(LTRe) training technique. LTRe constructs the document index beforehand. At
each training iteration, it performs full retrieval without negative sampling
and then updates the query representation model parameters. Through this
process, it teaches the DR model how to retrieve relevant documents from the
entire corpus instead of how to rerank a potentially biased sample of
documents. Experiments in both passage retrieval and document retrieval tasks
show that: 1) in terms of effectiveness, LTRe significantly outperforms all
competitive sparse and dense baselines. It even gains better performance than
the BM25-BERT cascade system under reasonable latency constraints. 2) in terms
of training efficiency, compared with the previous state-of-the-art DR method,
LTRe provides more than 170x speed-up in the training process. Training with a
compressed index further saves computing resources with minor performance loss.
</p>
<a href="http://arxiv.org/abs/2010.10469" target="_blank">arXiv:2010.10469</a> [<a href="http://arxiv.org/pdf/2010.10469" target="_blank">pdf</a>]

<h2>FishNet: A Unified Embedding for Salmon Recognition. (arXiv:2010.10475v1 [cs.CV])</h2>
<h3>Bj&#xf8;rn Magnus Mathisen, Kerstin Bach, Espen Meidell, H&#xe5;kon M&#xe5;l&#xf8;y, Edvard Schreiner Sj&#xf8;blom</h3>
<p>Identifying individual salmon can be very beneficial for the aquaculture
industry as it enables monitoring and analyzing fish behavior and welfare. For
aquaculture researchers identifying individual salmon is imperative to their
research. The current methods of individual salmon tagging and tracking rely on
physical interaction with the fish. This process is inefficient and can cause
physical harm and stress for the salmon. In this paper we propose FishNet,
based on a deep learning technique that has been successfully used for
identifying humans, to identify salmon.We create a dataset of labeled fish
images and then test the performance of the FishNet architecture. Our
experiments show that this architecture learns a useful representation based on
images of salmon heads. Further, we show that good performance can be achieved
with relatively small neural network models: FishNet achieves a false positive
rate of 1\% and a true positive rate of 96\%.
</p>
<a href="http://arxiv.org/abs/2010.10475" target="_blank">arXiv:2010.10475</a> [<a href="http://arxiv.org/pdf/2010.10475" target="_blank">pdf</a>]

<h2>Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition. (arXiv:2010.10504v1 [eess.AS])</h2>
<h3>Yu Zhang, James Qin, Daniel S. Park, Wei Han, Chung-Cheng Chiu, Ruoming Pang, Quoc V. Le, Yonghui Wu</h3>
<p>We employ a combination of recent developments in semi-supervised learning
for automatic speech recognition to obtain state-of-the-art results on
LibriSpeech utilizing the unlabeled audio of the Libri-Light dataset. More
precisely, we carry out noisy student training with SpecAugment using giant
Conformer models pre-trained using wav2vec 2.0 pre-training. By doing so, we
are able to achieve word-error-rates (WERs) 1.4%/2.6% on the LibriSpeech
test/test-other sets against the current state-of-the-art WERs 1.7%/3.3%.
</p>
<a href="http://arxiv.org/abs/2010.10504" target="_blank">arXiv:2010.10504</a> [<a href="http://arxiv.org/pdf/2010.10504" target="_blank">pdf</a>]

<h2>SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images. (arXiv:2010.10505v1 [cs.CV])</h2>
<h3>Chen-Hsuan Lin, Chaoyang Wang, Simon Lucey</h3>
<p>Dense 3D object reconstruction from a single image has recently witnessed
remarkable advances, but supervising neural networks with ground-truth 3D
shapes is impractical due to the laborious process of creating paired
image-shape datasets. Recent efforts have turned to learning 3D reconstruction
without 3D supervision from RGB images with annotated 2D silhouettes,
dramatically reducing the cost and effort of annotation. These techniques,
however, remain impractical as they still require multi-view annotations of the
same object instance during training. As a result, most experimental efforts to
date have been limited to synthetic datasets. In this paper, we address this
issue and propose SDF-SRN, an approach that requires only a single view of
objects at training time, offering greater utility for real-world scenarios.
SDF-SRN learns implicit 3D shape representations to handle arbitrary shape
topologies that may exist in the datasets. To this end, we derive a novel
differentiable rendering formulation for learning signed distance functions
(SDF) from 2D silhouettes. Our method outperforms the state of the art under
challenging single-view supervision settings on both synthetic and real-world
datasets.
</p>
<a href="http://arxiv.org/abs/2010.10505" target="_blank">arXiv:2010.10505</a> [<a href="http://arxiv.org/pdf/2010.10505" target="_blank">pdf</a>]

<h2>Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy. (arXiv:1809.04430v2 [cs.CV] UPDATED)</h2>
<h3>Stanislav Nikolov, Sam Blackwell, Alexei Zverovitch, Ruheena Mendes, Michelle Livne, Jeffrey De Fauw, Yojan Patel, Clemens Meyer, Harry Askham, Bernardino Romera-Paredes, Christopher Kelly, Alan Karthikesalingam, Carlton Chu, Dawn Carnell, Cheng Boon, Derek D&#x27;Souza, Syed Ali Moinuddin, DeepMind Radiographer Consortium, Hugh Montgomery, Geraint Rees, Mustafa Suleyman, Trevor Back, C&#xed;an Hughes, Joseph R. Ledsam, Olaf Ronneberger</h3>
<p>Over half a million individuals are diagnosed with head and neck cancer each
year worldwide. Radiotherapy is an important curative treatment for this
disease, but it requires manual time consuming delineation of radio-sensitive
organs at risk (OARs). This planning process can delay treatment, while also
introducing inter-operator variability with resulting downstream radiation dose
differences. While auto-segmentation algorithms offer a potentially time-saving
solution, the challenges in defining, quantifying and achieving expert
performance remain. Adopting a deep learning approach, we demonstrate a 3D
U-Net architecture that achieves expert-level performance in delineating 21
distinct head and neck OARs commonly segmented in clinical practice. The model
was trained on a dataset of 663 deidentified computed tomography (CT) scans
acquired in routine clinical practice and with both segmentations taken from
clinical practice and segmentations created by experienced radiographers as
part of this research, all in accordance with consensus OAR definitions. We
demonstrate the model's clinical applicability by assessing its performance on
a test set of 21 CT scans from clinical practice, each with the 21 OARs
segmented by two independent experts. We also introduce surface Dice similarity
coefficient (surface DSC), a new metric for the comparison of organ
delineation, to quantify deviation between OAR surface contours rather than
volumes, better reflecting the clinical task of correcting errors in the
automated organ segmentations. The model's generalisability is then
demonstrated on two distinct open source datasets, reflecting different centres
and countries to model training. With appropriate validation studies and
regulatory approvals, this system could improve the efficiency, consistency,
and safety of radiotherapy pathways.
</p>
<a href="http://arxiv.org/abs/1809.04430" target="_blank">arXiv:1809.04430</a> [<a href="http://arxiv.org/pdf/1809.04430" target="_blank">pdf</a>]

<h2>Graph Neural Networks Exponentially Lose Expressive Power for Node Classification. (arXiv:1905.10947v4 [cs.LG] UPDATED)</h2>
<h3>Kenta Oono, Taiji Suzuki</h3>
<p>Graph Neural Networks (graph NNs) are a promising deep learning approach for
analyzing graph-structured data. However, it is known that they do not improve
(or sometimes worsen) their predictive performance as we pile up many layers
and add non-lineality. To tackle this problem, we investigate the expressive
power of graph NNs via their asymptotic behaviors as the layer size tends to
infinity. Our strategy is to generalize the forward propagation of a Graph
Convolutional Network (GCN), which is a popular graph NN variant, as a specific
dynamical system. In the case of a GCN, we show that when its weights satisfy
the conditions determined by the spectra of the (augmented) normalized
Laplacian, its output exponentially approaches the set of signals that carry
information of the connected components and node degrees only for
distinguishing nodes. Our theory enables us to relate the expressive power of
GCNs with the topological information of the underlying graphs inherent in the
graph spectra. To demonstrate this, we characterize the asymptotic behavior of
GCNs on the Erd\H{o}s -- R\'{e}nyi graph. We show that when the Erd\H{o}s --
R\'{e}nyi graph is sufficiently dense and large, a broad range of GCNs on it
suffers from the "information loss" in the limit of infinite layers with high
probability. Based on the theory, we provide a principled guideline for weight
normalization of graph NNs. We experimentally confirm that the proposed weight
scaling enhances the predictive performance of GCNs in real data. Code is
available at https://github.com/delta2323/gnn-asymptotics.
</p>
<a href="http://arxiv.org/abs/1905.10947" target="_blank">arXiv:1905.10947</a> [<a href="http://arxiv.org/pdf/1905.10947" target="_blank">pdf</a>]

<h2>Mind2Mind : transfer learning for GANs. (arXiv:1906.11613v2 [cs.LG] UPDATED)</h2>
<h3>Ya&#xeb;l Fr&#xe9;gier, Jean-Baptiste Gouray</h3>
<p>Training generative adversarial networks (GANs) on high quality (HQ) images
involves important computing resources. This requirement represents a
bottleneck for the development of applications of GANs. We propose a transfer
learning technique for GANs that significantly reduces training time. Our
approach consists of freezing the low-level layers of both the critic and
generator of the original GAN. We assume an autoencoder constraint in order to
ensure the compatibility of the internal representations of the critic and the
generator. This assumption explains the gain in training time as it enables us
to bypass the low-level layers during the forward and backward passes. We
compare our method to baselines and observe a significant acceleration of the
training. It can reach two orders of magnitude on HQ datasets when compared
with StyleGAN. We prove rigorously, within the framework of optimal transport,
a theorem ensuring the convergence of the learning of the transferred GAN. We
moreover provide a precise bound for the convergence of the training in terms
of the distance between the source and target dataset.
</p>
<a href="http://arxiv.org/abs/1906.11613" target="_blank">arXiv:1906.11613</a> [<a href="http://arxiv.org/pdf/1906.11613" target="_blank">pdf</a>]

<h2>DeepNC: Deep Generative Network Completion. (arXiv:1907.07381v5 [cs.SI] UPDATED)</h2>
<h3>Cong Tran, Won-Yong Shin, Andreas Spitz, Michael Gertz</h3>
<p>Most network data are collected from partially observable networks with both
missing nodes and missing edges, for example, due to limited resources and
privacy settings specified by users on social media. Thus, it stands to reason
that inferring the missing parts of the networks by performing network
completion should precede downstream applications. However, despite this need,
the recovery of missing nodes and edges in such incomplete networks is an
insufficiently explored problem due to the modeling difficulty, which is much
more challenging than link prediction that only infers missing edges. In this
paper, we present DeepNC, a novel method for inferring the missing parts of a
network based on a deep generative model of graphs. Specifically, our method
first learns a likelihood over edges via an autoregressive generative model,
and then identifies the graph that maximizes the learned likelihood conditioned
on the observable graph topology. Moreover, we propose a computationally
efficient DeepNC algorithm that consecutively finds individual nodes that
maximize the probability in each node generation step, as well as an enhanced
version using the expectation-maximization algorithm. The runtime complexities
of both algorithms are shown to be almost linear in the number of nodes in the
network. We empirically demonstrate the superiority of DeepNC over
state-of-the-art network completion approaches.
</p>
<a href="http://arxiv.org/abs/1907.07381" target="_blank">arXiv:1907.07381</a> [<a href="http://arxiv.org/pdf/1907.07381" target="_blank">pdf</a>]

<h2>Reinventing 2D Convolutions for 3D Images. (arXiv:1911.10477v3 [eess.IV] UPDATED)</h2>
<h3>Jiancheng Yang, Xiaoyang Huang, Yi He, Jingwei Xu, Canqian Yang, Guozheng Xu, Bingbing Ni</h3>
<p>There have been considerable debates over 2D and 3D representation learning
on 3D medical images. 2D approaches could benefit from large-scale 2D
pretraining, whereas they are generally weak in capturing large 3D contexts. 3D
approaches are natively strong in 3D contexts, however few publicly available
3D medical dataset is large and diverse enough for universal 3D pretraining.
Even for hybrid (2D + 3D) approaches, the intrinsic disadvantages within the 2D
/ 3D parts still exist. In this study, we bridge the gap between 2D and 3D
convolutions by reinventing the 2D convolutions. We propose ACS
(axial-coronal-sagittal) convolutions to perform natively 3D representation
learning, while utilizing the pretrained weights on 2D datasets. In ACS
convolutions, 2D convolution kernels are split by channel into three parts, and
convoluted separately on the three views (axial, coronal and sagittal) of 3D
representations. Theoretically, ANY 2D CNN (ResNet, DenseNet, or DeepLab) is
able to be converted into a 3D ACS CNN, with pretrained weight of a same
parameter size. Extensive experiments on proof-of-concept dataset and several
medical benchmarks validate the consistent superiority of the pretrained ACS
CNNs, over the 2D / 3D CNN counterparts with / without pretraining. Even
without pretraining, the ACS convolution can be used as a plug-and-play
replacement of standard 3D convolution, with smaller model size and less
computation.
</p>
<a href="http://arxiv.org/abs/1911.10477" target="_blank">arXiv:1911.10477</a> [<a href="http://arxiv.org/pdf/1911.10477" target="_blank">pdf</a>]

<h2>Contemporary Software Monitoring: A Systematic Mapping Study. (arXiv:1912.05878v2 [cs.SE] UPDATED)</h2>
<h3>Jeanderson Candido, Maur&#xed;cio Aniche, Arie van Deursen</h3>
<p>Modern software development and operations rely on monitoring to understand
how systems behave in production. Despite the rich ecosystem around
industry-ready log solutions, monitoring complex systems and getting insights
from log data remains a challenge. Researchers and practitioners have been
actively working to address several challenges related to logs, e.g., how to
effectively provide better tooling support for logging decisions to developers,
how to effectively process and store log data, and how to extract insights from
log data. In this paper, we provide a holistic view of the logging research
field to give directions and disseminate the state-of-the-art. We conduct a
systematic mapping study based on five popular data sources and derive a
classification schema based on the abstract keywording to structure the
research field in light to the life-cycle of log data (i.e., generation,
processing, and analysis of log data). We discovered 108 papers published in
highly ranked venues, spanning different communities (e.g., machine learning,
software engineering, and systems). In summary, 24 papers focus on the
development of effective logging code, 16 papers focus of parsing techniques
and efficient storage to enable log analysis, and 68 papers focus on extracting
insights from log data. We further subdivide those three categories according
to their use case (e.g., log analysis for failure prediction). Our analysis
shows that logging is challenge in open source and industry contexts, machine
learning is a promising approach to enable contextual analysis of source code
for log recommendation but requires further investigation to assess the
usability of those tools in practice, few studies approached efficient
persistence of log data, and there are open opportunities to analyse
application logs and to evaluate state-of-the-art log analysis techniques in a
DevOps context.
</p>
<a href="http://arxiv.org/abs/1912.05878" target="_blank">arXiv:1912.05878</a> [<a href="http://arxiv.org/pdf/1912.05878" target="_blank">pdf</a>]

<h2>A versatile anomaly detection method for medical images with a flow-based generative model in semi-supervision setting. (arXiv:2001.07847v3 [eess.IV] UPDATED)</h2>
<h3>H. Shibata (1), S. Hanaoka (2), Y. Nomura (1), T. Nakao (1), I. Sato (2 and 4 and 5), D. Sato (3), N. Hayashi (1), O. Abe (2 and 3) ((1) Department of Computational Diagnostic Radiology and Preventive Medicine, The University of Tokyo Hospital, (2) Department of Radiology, The University of Tokyo Hospital, (3) Division of Radiology and Biomedical Engineering, Graduate School of Medicine, The University of Tokyo, (4) Department of Computer Science, Graduate School of Information Science and Technology, The University of Tokyo, (5) Center for Advanced Intelligence Project, RIKEN)</h3>
<p>Oversight in medical images is a crucial problem, and timely reporting of
medical images is desired. Therefore, an all-purpose anomaly detection method
that can detect virtually all types of lesions/diseases in a given image is
strongly desired. However, few commercially available and versatile anomaly
detection methods for medical images have been provided so far. Recently,
anomaly detection methods built upon deep learning methods have been rapidly
growing in popularity, and these methods seem to provide reasonable solutions
to the problem. However, the workload to label the images necessary for
training in deep learning remains heavy. In this study, we present an anomaly
detection method based on two trained flow-based generative models. With this
method, the posterior probability can be computed as a normality metric for any
given image. The training of the generative models requires two sets of images:
a set containing only normal images and another set containing both normal and
abnormal images without any labels. In the latter set, each sample does not
have to be labeled as normal or abnormal; therefore, any mixture of images
(e.g., all cases in a hospital) can be used as the dataset without cumbersome
manual labeling. The method was validated with two types of medical images:
chest X-ray radiographs (CXRs) and brain computed tomographies (BCTs). The
areas under the receiver operating characteristic curves for logarithm
posterior probabilities of CXRs (0.868 for pneumonia-like opacities) and BCTs
(0.904 for infarction) were comparable to those in previous studies with other
anomaly detection methods. This result showed the versatility of our method.
</p>
<a href="http://arxiv.org/abs/2001.07847" target="_blank">arXiv:2001.07847</a> [<a href="http://arxiv.org/pdf/2001.07847" target="_blank">pdf</a>]

<h2>A Neural Approach to Ordinal Regression for the Preventive Assessment of Developmental Dyslexia. (arXiv:2002.02184v2 [cs.LG] UPDATED)</h2>
<h3>F.J. Martinez-Murcia, A. Ortiz, Marco A. Formoso, M. Lopez-Zamora, J.L. Luque, A. Gim&#xe9;nez</h3>
<p>Developmental Dyslexia (DD) is a learning disability related to the
acquisition of reading skills that affects about 5% of the population. DD can
have an enormous impact on the intellectual and personal development of
affected children, so early detection is key to implementing preventive
strategies for teaching language. Research has shown that there may be
biological underpinnings to DD that affect phoneme processing, and hence these
symptoms may be identifiable before reading ability is acquired, allowing for
early intervention. In this paper we propose a new methodology to assess the
risk of DD before students learn to read. For this purpose, we propose a mixed
neural model that calculates risk levels of dyslexia from tests that can be
completed at the age of 5 years. Our method first trains an auto-encoder, and
then combines the trained encoder with an optimized ordinal regression neural
network devised to ensure consistency of predictions. Our experiments show that
the system is able to detect unaffected subjects two years before it can assess
the risk of DD based mainly on phonological processing, giving a specificity of
0.969 and a correct rate of more than 0.92. In addition, the trained encoder
can be used to transform test results into an interpretable subject spatial
distribution that facilitates risk assessment and validates methodology.
</p>
<a href="http://arxiv.org/abs/2002.02184" target="_blank">arXiv:2002.02184</a> [<a href="http://arxiv.org/pdf/2002.02184" target="_blank">pdf</a>]

<h2>Weakly-Supervised Disentanglement Without Compromises. (arXiv:2002.02886v4 [cs.LG] UPDATED)</h2>
<h3>Francesco Locatello, Ben Poole, Gunnar R&#xe4;tsch, Bernhard Sch&#xf6;lkopf, Olivier Bachem, Michael Tschannen</h3>
<p>Intelligent agents should be able to learn useful representations by
observing changes in their environment. We model such observations as pairs of
non-i.i.d. images sharing at least one of the underlying factors of variation.
First, we theoretically show that only knowing how many factors have changed,
but not which ones, is sufficient to learn disentangled representations.
Second, we provide practical algorithms that learn disentangled representations
from pairs of images without requiring annotation of groups, individual
factors, or the number of factors that have changed. Third, we perform a
large-scale empirical study and show that such pairs of observations are
sufficient to reliably learn disentangled representations on several benchmark
data sets. Finally, we evaluate our learned representations and find that they
are simultaneously useful on a diverse suite of tasks, including generalization
under covariate shifts, fairness, and abstract reasoning. Overall, our results
demonstrate that weak supervision enables learning of useful disentangled
representations in realistic scenarios.
</p>
<a href="http://arxiv.org/abs/2002.02886" target="_blank">arXiv:2002.02886</a> [<a href="http://arxiv.org/pdf/2002.02886" target="_blank">pdf</a>]

<h2>PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees. (arXiv:2002.05551v3 [stat.ML] UPDATED)</h2>
<h3>Jonas Rothfuss, Vincent Fortuin, Andreas Krause</h3>
<p>Meta-learning can successfully acquire useful inductive biases from data,
especially when a large number of meta-tasks are available. Yet, its
generalization properties to unseen tasks are poorly understood. Particularly
if the number of meta-tasks is small, this raises concerns about overfitting.
We provide a theoretical analysis using the PAC-Bayesian framework and derive
novel generalization bounds for meta-learning with unbounded loss functions and
Bayesian base learners. Using these bounds, we develop a class of PAC-optimal
meta-learning algorithms with performance guarantees and a principled
meta-regularization. When instantiating our PAC-optimal hyper-posterior (PACOH)
with Gaussian processes as base learners, the resulting method consistently
outperforms several popular meta-learning methods, both in terms of predictive
accuracy and the quality of uncertainty estimates.
</p>
<a href="http://arxiv.org/abs/2002.05551" target="_blank">arXiv:2002.05551</a> [<a href="http://arxiv.org/pdf/2002.05551" target="_blank">pdf</a>]

<h2>On the Sensory Commutativity of Action Sequences for Embodied Agents. (arXiv:2002.05630v2 [cs.AI] UPDATED)</h2>
<h3>Hugo Caselles-Dupr&#xe9;, Michael Garcia-Ortiz, David Filliat</h3>
<p>We study perception in the scenario of an embodied agent equipped with
first-person sensors and a continuous motor space with multiple degrees of
freedom. We consider the commutative properties of action sequences with
respect to sensory information perceived by such an embodied agent. We
introduce the Sensory Commutativity Probability (SCP) criterion which measures
how much an agent's degree of freedom affects the environment in embodied
scenarios. We show how to compute this criterion in different environments,
including realistic robotic setups. We empirically illustrate how SCP and the
commutative properties of action sequences can be used to learn about objects
in the environment and improve sample-efficiency in Reinforcement Learning.
</p>
<a href="http://arxiv.org/abs/2002.05630" target="_blank">arXiv:2002.05630</a> [<a href="http://arxiv.org/pdf/2002.05630" target="_blank">pdf</a>]

<h2>A Minimax Theorem for Nonconcave-Nonconvex Games or: How I Learned to Stop Worrying about Mixed-Nash and Love Neural Nets. (arXiv:2002.05820v2 [stat.ML] UPDATED)</h2>
<h3>Gauthier Gidel, David Balduzzi, Wojciech Marian Czarnecki, Marta Garnelo, Yoram Bachrach</h3>
<p>Adversarial training, a special case of multi-objective optimization, is an
increasingly prevalent machine learning technique: some of its most notable
applications include GAN-based generative modeling and self-play techniques in
reinforcement learning which have been applied to complex games such as Go or
Poker. In practice, a \emph{single} pair of networks is typically trained in
order to find an approximate equilibrium of a highly nonconcave-nonconvex
adversarial problem. However, while a classic result in game theory states such
an equilibrium exists in concave-convex games, there is no analogous guarantee
if the payoff is nonconcave-nonconvex. Our main contribution is to provide an
approximate minimax theorem for a large class of games where the players pick
neural networks including WGAN, StarCraft II, and Blotto Game. Our findings
rely on the fact that despite being nonconcave-nonconvex with respect to the
neural networks parameters, these games are concave-convex with respect to the
actual models (e.g., functions or distributions) represented by these neural
networks.
</p>
<a href="http://arxiv.org/abs/2002.05820" target="_blank">arXiv:2002.05820</a> [<a href="http://arxiv.org/pdf/2002.05820" target="_blank">pdf</a>]

<h2>The Archimedean trap: Why traditional reinforcement learning will probably not yield AGI. (arXiv:2002.10221v2 [cs.LG] UPDATED)</h2>
<h3>Samuel Allen Alexander</h3>
<p>After generalizing the Archimedean property of real numbers in such a way as
to make it adaptable to non-numeric structures, we demonstrate that the real
numbers cannot be used to accurately measure non-Archimedean structures. We
argue that, since an agent with Artificial General Intelligence (AGI) should
have no problem engaging in tasks that inherently involve non-Archimedean
rewards, and since traditional reinforcement learning rewards are real numbers,
therefore traditional reinforcement learning probably will not lead to AGI. We
indicate two possible ways traditional reinforcement learning could be altered
to remove this roadblock.
</p>
<a href="http://arxiv.org/abs/2002.10221" target="_blank">arXiv:2002.10221</a> [<a href="http://arxiv.org/pdf/2002.10221" target="_blank">pdf</a>]

<h2>Exploiting Variable Impedance for Energy Efficient Sequential Movements. (arXiv:2002.12075v2 [cs.RO] UPDATED)</h2>
<h3>Fan Wu, Matthew Howard</h3>
<p>Compliant robotics have seen successful applications in energy efficient
locomotion and cyclic manipulation. However, exploitation of variable physical
impedance for energy efficient sequential movements has not been extensively
addressed. This work employs a hierarchical approach to encapsulate low-level
optimal control for sub-movement generation into an outer loop of iterative
policy improvement, thereby leveraging the benefits of both optimal control and
reinforcement learning. The framework enables optimizing efficiency trade-off
for minimal energy expenses in a model-free manner, by taking account of cost
function weighting, variable impedance exploitation, and transition timing --
which are associated with the skill of compliance. The effectiveness of the
proposed method is evaluated using two consecutive reaching tasks on a variable
impedance actuator. The results demonstrate significant energy saving by
improving the skill of compliance, with an electrical consumption reduction of
about 30% measured in a physical robot experiment.
</p>
<a href="http://arxiv.org/abs/2002.12075" target="_blank">arXiv:2002.12075</a> [<a href="http://arxiv.org/pdf/2002.12075" target="_blank">pdf</a>]

<h2>Domain Adaptation by Class Centroid Matching and Local Manifold Self-Learning. (arXiv:2003.09391v4 [cs.CV] UPDATED)</h2>
<h3>Lei Tian, Yongqiang Tang, Liangchen Hu, Zhida Ren, Wensheng Zhang</h3>
<p>Domain adaptation has been a fundamental technology for transferring
knowledge from a source domain to a target domain. The key issue of domain
adaptation is how to reduce the distribution discrepancy between two domains in
a proper way such that they can be treated indifferently for learning. In this
paper, we propose a novel domain adaptation approach, which can thoroughly
explore the data distribution structure of target domain.Specifically, we
regard the samples within the same cluster in target domain as a whole rather
than individuals and assigns pseudo-labels to the target cluster by class
centroid matching. Besides, to exploit the manifold structure information of
target data more thoroughly, we further introduce a local manifold
self-learning strategy into our proposal to adaptively capture the inherent
local connectivity of target samples. An efficient iterative optimization
algorithm is designed to solve the objective function of our proposal with
theoretical convergence guarantee. In addition to unsupervised domain
adaptation, we further extend our method to the semi-supervised scenario
including both homogeneous and heterogeneous settings in a direct but elegant
way. Extensive experiments on seven benchmark datasets validate the significant
superiority of our proposal in both unsupervised and semi-supervised manners.
</p>
<a href="http://arxiv.org/abs/2003.09391" target="_blank">arXiv:2003.09391</a> [<a href="http://arxiv.org/pdf/2003.09391" target="_blank">pdf</a>]

<h2>Classification of Handwritten Numbers with Labeled Projective Dictionary Pair Learning. (arXiv:2003.11700v2 [cs.CV] UPDATED)</h2>
<h3>Rasool Ameri, Ali Alameer, Saideh Ferdowsi, Kianoush Nazarpour, Vahid Abolghasemi</h3>
<p>Dictionary learning is a cornerstone of image classification. We set out to
address a longstanding challenge in using dictionary learning for
classification; that is to simultaneously maximise the discriminability and
sparse-representability power of the learned dictionaries. Upon this premise,
we designed class-specific dictionaries incorporating three factors:
discriminability, sparsity and classification error. We integrated these
metrics into a unified cost function and adopted a new feature space, i.e.,
histogram of oriented gradients (HOG), to generate the dictionary atoms. The
rationale of using HOG features for designing the dictionaries is their
strength in describing fine details of crowded images. The results of applying
this method in the classification of Chinese handwritten characters showed that
the proposed method leads to enhanced classification performance $(\sim98\%)$
compared to other methods such as SqueezeNet, GoogLeNet and MobileNetV2, but
with a fraction of parameters. Furthermore, the combination of the HOG features
with dictionary learning enhances the accuracy by $11\%$ compared to the case
where only pixel domain data are used.
</p>
<a href="http://arxiv.org/abs/2003.11700" target="_blank">arXiv:2003.11700</a> [<a href="http://arxiv.org/pdf/2003.11700" target="_blank">pdf</a>]

<h2>Environmental Adaptation of Robot Morphology and Control through Real-world Evolution. (arXiv:2003.13254v2 [cs.RO] UPDATED)</h2>
<h3>T&#xf8;nnes F. Nygaard, Charles P. Martin, David Howard, Jim Torresen, Kyrre Glette</h3>
<p>Robots operating in the real world will experience a range of different
environments and tasks. It is essential for the robot to have the ability to
adapt to its surroundings to work efficiently in changing conditions.
Evolutionary robotics aims to solve this by optimizing both the control and
body (morphology) of a robot, allowing adaptation to internal, as well as
external factors. Most work in this field has been done in physics simulators,
which are relatively simple and not able to replicate the richness of
interactions found in the real world. Solutions that rely on the complex
interplay between control, body, and environment are therefore rarely found. In
this paper, we rely solely on real-world evaluations and apply evolutionary
search to yield combinations of morphology and control for our mechanically
self-reconfiguring quadruped robot. We evolve solutions on two distinct
physical surfaces and analyze the results in terms of both control and
morphology. We then transition to two previously unseen surfaces to demonstrate
the generality of our method. We find that the evolutionary search finds
high-performing and diverse morphology-controller configurations by adapting
both control and body to the different properties of the physical environments.
We additionally find that morphology and control vary with statistical
significance between the environments. Moreover, we observe that our method
allows for morphology and control parameters to transfer to previously-unseen
terrains, demonstrating the generality of our approach.
</p>
<a href="http://arxiv.org/abs/2003.13254" target="_blank">arXiv:2003.13254</a> [<a href="http://arxiv.org/pdf/2003.13254" target="_blank">pdf</a>]

<h2>A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video. (arXiv:2003.14179v4 [cs.CV] UPDATED)</h2>
<h3>Junfa Liu, Juan Rojas, Zhijun Liang, Yihui Li, Yisheng Guan</h3>
<p>Spatio-temporal information is key to resolve occlusion and depth ambiguity
in 3D pose estimation. Previous methods have focused on either temporal
contexts or local-to-global architectures that embed fixed-length
spatio-temporal information. To date, there have not been effective proposals
to simultaneously and flexibly capture varying spatio-temporal sequences and
effectively achieves real-time 3D pose estimation. In this work, we improve the
learning of kinematic constraints in the human skeleton: posture, local
kinematic connections, and symmetry by modeling local and global spatial
information via attention mechanisms. To adapt to single- and multi-frame
estimation, the dilated temporal model is employed to process varying skeleton
sequences. Also, importantly, we carefully design the interleaving of spatial
semantics with temporal dependencies to achieve a synergistic effect. To this
end, we propose a simple yet effective graph attention spatio-temporal
convolutional network (GAST-Net) that comprises of interleaved temporal
convolutional and graph attention blocks. Experiments on two challenging
benchmark datasets (Human3.6M and HumanEva-I) and YouTube videos demonstrate
that our approach effectively mitigates depth ambiguity and self-occlusion,
generalizes to half upper body estimation, and achieves competitive performance
on 2D-to-3D video pose estimation. Code, video, and supplementary information
is available at:
\href{this http URL}{this http URL}
</p>
<a href="http://arxiv.org/abs/2003.14179" target="_blank">arXiv:2003.14179</a> [<a href="http://arxiv.org/pdf/2003.14179" target="_blank">pdf</a>]

<h2>Measuring Human and Economic Activity from Satellite Imagery to Support City-Scale Decision-Making during COVID-19 Pandemic. (arXiv:2004.07438v3 [cs.CV] UPDATED)</h2>
<h3>Rodrigo Minetto, Mauricio Pamplona Segundo, Gilbert Rotich, Sudeep Sarkar</h3>
<p>The COVID-19 outbreak forced governments worldwide to impose lockdowns and
quarantines to prevent virus transmission. As a consequence, there are
disruptions in human and economic activities all over the globe. The recovery
process is also expected to be rough. Economic activities impact social
behaviors, which leave signatures in satellite images that can be automatically
detected and classified. Satellite imagery can support the decision-making of
analysts and policymakers by providing a different kind of visibility into the
unfolding economic changes. In this work, we use a deep learning approach that
combines strategic location sampling and an ensemble of lightweight
convolutional neural networks (CNNs) to recognize specific elements in
satellite images that could be used to compute economic indicators based on it,
automatically. This CNN ensemble framework ranked third place in the US
Department of Defense xView challenge, the most advanced benchmark for object
detection in satellite images. We show the potential of our framework for
temporal analysis using the US IARPA Function Map of the World (fMoW) dataset.
We also show results on real examples of different sites before and after the
COVID-19 outbreak to illustrate different measurable indicators. Our code and
annotated high-resolution aerial scenes before and after the outbreak are
available on GitHub (https://github.com/maups/covid19-satellite-analysis).
</p>
<a href="http://arxiv.org/abs/2004.07438" target="_blank">arXiv:2004.07438</a> [<a href="http://arxiv.org/pdf/2004.07438" target="_blank">pdf</a>]

<h2>Investigating Efficient Learning and Compositionality in Generative LSTM Networks. (arXiv:2004.07754v2 [cs.LG] UPDATED)</h2>
<h3>Sarah Fabi, Sebastian Otte, Jonas Gregor Wiese, Martin V. Butz</h3>
<p>When comparing human with artificial intelligence, one major difference is
apparent: Humans can generalize very broadly from sparse data sets because they
are able to recombine and reintegrate data components in compositional manners.
To investigate differences in efficient learning, Joshua B. Tenenbaum and
colleagues developed the character challenge: First an algorithm is trained in
generating handwritten characters. In a next step, one version of a new type of
character is presented. An efficient learning algorithm is expected to be able
to re-generate this new character, to identify similar versions of this
character, to generate new variants of it, and to create completely new
character types. In the past, the character challenge was only met by complex
algorithms that were provided with stochastic primitives. Here, we tackle the
challenge without providing primitives. We apply a minimal recurrent neural
network (RNN) model with one feedforward layer and one LSTM layer and train it
to generate sequential handwritten character trajectories from one-hot encoded
inputs. To manage the re-generation of untrained characters, when presented
with only one example of them, we introduce a one-shot inference mechanism: the
gradient signal is backpropagated to the feedforward layer weights only,
leaving the LSTM layer untouched. We show that our model is able to meet the
character challenge by recombining previously learned dynamic substructures,
which are visible in the hidden LSTM states. Making use of the compositional
abilities of RNNs in this way might be an important step towards bridging the
gap between human and artificial intelligence.
</p>
<a href="http://arxiv.org/abs/2004.07754" target="_blank">arXiv:2004.07754</a> [<a href="http://arxiv.org/pdf/2004.07754" target="_blank">pdf</a>]

<h2>Stage-Wise Neural Architecture Search. (arXiv:2004.11178v2 [cs.CV] UPDATED)</h2>
<h3>Artur Jordao, Fernando Akio, Maiko Lie, William Robson Schwartz</h3>
<p>Modern convolutional networks such as ResNet and NASNet have achieved
state-of-the-art results in many computer vision applications. These
architectures consist of stages, which are sets of layers that operate on
representations in the same resolution. It has been demonstrated that
increasing the number of layers in each stage improves the prediction ability
of the network. However, the resulting architecture becomes computationally
expensive in terms of floating point operations, memory requirements and
inference time. Thus, significant human effort is necessary to evaluate
different trade-offs between depth and performance. To handle this problem,
recent works have proposed to automatically design high-performance
architectures, mainly by means of neural architecture search (NAS). Current NAS
strategies analyze a large set of possible candidate architectures and, hence,
require vast computational resources and take many GPUs days. Motivated by
this, we propose a NAS approach to efficiently design accurate and low-cost
convolutional architectures and demonstrate that an efficient strategy for
designing these architectures is to learn the depth stage-by-stage. For this
purpose, our approach increases depth incrementally in each stage taking into
account its importance, such that stages with low importance are kept shallow
while stages with high importance become deeper. We conduct experiments on the
CIFAR and different versions of ImageNet datasets, where we show that
architectures discovered by our approach achieve better accuracy and efficiency
than human-designed architectures. Additionally, we show that architectures
discovered on CIFAR-10 can be successfully transferred to large datasets.
Compared to previous NAS approaches, our method is substantially more
efficient, as it evaluates one order of magnitude fewer models and yields
architectures on par with the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2004.11178" target="_blank">arXiv:2004.11178</a> [<a href="http://arxiv.org/pdf/2004.11178" target="_blank">pdf</a>]

<h2>Stay Hungry, Stay Focused: Generating Informative and Specific Questions in Information-Seeking Conversations. (arXiv:2004.14530v2 [cs.CL] UPDATED)</h2>
<h3>Peng Qi, Yuhao Zhang, Christopher D. Manning</h3>
<p>We investigate the problem of generating informative questions in
information-asymmetric conversations. Unlike previous work on question
generation which largely assumes knowledge of what the answer might be, we are
interested in the scenario where the questioner is not given the context from
which answers are drawn, but must reason pragmatically about how to acquire new
information, given the shared conversation history. We identify two core
challenges: (1) formally defining the informativeness of potential questions,
and (2) exploring the prohibitively large space of potential questions to find
the good candidates. To generate pragmatic questions, we use reinforcement
learning to optimize an informativeness metric we propose, combined with a
reward function designed to promote more specific questions. We demonstrate
that the resulting pragmatic questioner substantially improves the
informativeness and specificity of questions generated over a baseline model,
as evaluated by our metrics as well as humans.
</p>
<a href="http://arxiv.org/abs/2004.14530" target="_blank">arXiv:2004.14530</a> [<a href="http://arxiv.org/pdf/2004.14530" target="_blank">pdf</a>]

<h2>Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems. (arXiv:2005.01643v2 [cs.LG] UPDATED)</h2>
<h3>Sergey Levine, Aviral Kumar, George Tucker, Justin Fu</h3>
<p>In this tutorial article, we aim to provide the reader with the conceptual
tools needed to get started on research on offline reinforcement learning
algorithms: reinforcement learning algorithms that utilize previously collected
data, without additional online data collection. Offline reinforcement learning
algorithms hold tremendous promise for making it possible to turn large
datasets into powerful decision making engines. Effective offline reinforcement
learning methods would be able to extract policies with the maximum possible
utility out of the available data, thereby allowing automation of a wide range
of decision-making domains, from healthcare and education to robotics. However,
the limitations of current algorithms make this difficult. We will aim to
provide the reader with an understanding of these challenges, particularly in
the context of modern deep reinforcement learning methods, and describe some
potential solutions that have been explored in recent work to mitigate these
challenges, along with recent applications, and a discussion of perspectives on
open problems in the field.
</p>
<a href="http://arxiv.org/abs/2005.01643" target="_blank">arXiv:2005.01643</a> [<a href="http://arxiv.org/pdf/2005.01643" target="_blank">pdf</a>]

<h2>IPN Hand: A Video Dataset and Benchmark for Real-Time Continuous Hand Gesture Recognition. (arXiv:2005.02134v2 [cs.CV] UPDATED)</h2>
<h3>Gibran Benitez-Garcia, Jesus Olivares-Mercado, Gabriel Sanchez-Perez, Keiji Yanai</h3>
<p>In this paper, we introduce a new benchmark dataset named IPN Hand with
sufficient size, variety, and real-world elements able to train and evaluate
deep neural networks. This dataset contains more than 4,000 gesture samples and
800,000 RGB frames from 50 distinct subjects. We design 13 different static and
dynamic gestures focused on interaction with touchless screens. We especially
consider the scenario when continuous gestures are performed without transition
states, and when subjects perform natural movements with their hands as
non-gesture actions. Gestures were collected from about 30 diverse scenes, with
real-world variation in background and illumination. With our dataset, the
performance of three 3D-CNN models is evaluated on the tasks of isolated and
continuous real-time HGR. Furthermore, we analyze the possibility of increasing
the recognition accuracy by adding multiple modalities derived from RGB frames,
i.e., optical flow and semantic segmentation, while keeping the real-time
performance of the 3D-CNN model. Our empirical study also provides a comparison
with the publicly available nvGesture (NVIDIA) dataset. The experimental
results show that the state-of-the-art ResNext-101 model decreases about 30%
accuracy when using our real-world dataset, demonstrating that the IPN Hand
dataset can be used as a benchmark, and may help the community to step forward
in the continuous HGR. Our dataset and pre-trained models used in the
evaluation are publicly available at https://github.com/GibranBenitez/IPN-hand.
</p>
<a href="http://arxiv.org/abs/2005.02134" target="_blank">arXiv:2005.02134</a> [<a href="http://arxiv.org/pdf/2005.02134" target="_blank">pdf</a>]

<h2>Context-Oriented Behavioral Programming. (arXiv:2005.02373v2 [cs.SE] UPDATED)</h2>
<h3>Achiya Elyasaf</h3>
<p>Modern systems require programmers to develop code that dynamically adapts to
different contexts, leading to the evolution of new context-oriented
programming languages. These languages introduce new software-engineering
challenges, such as: how to maintain and keep the separation of concerns of the
codebase? how to model the changing behaviors? how to verify the system
behavior? and more.

This paper introduces Context-Oriented Behavioral Programming(COBP) - a novel
paradigm for developing context-aware systems, centered on natural and
incremental specification of context-dependent behaviors. As the name suggests,
we combine behavioral-programming(BP) - a scenario-based modeling paradigm -
with context idioms that explicitly specify when scenarios are relevant and
what information they need. The core idea is to connect the behavioral model
with a data model that represents the context, allowing an intuitive connection
between the models via update and select queries. Combining
behavioral-programming with context-oriented programming brings the best of the
two worlds, solving issues that arise when using each of the approaches in
separation.

We begin with providing abstract semantics for COBP, laying the foundations
for applying reasoning algorithms to context-aware behavioral programs. We then
exemplify the semantics with formal specifications of systems, including a
variant of Conway's Game of Life. Finally, we present a JavaScript-based
implementation of the paradigm and provide two case studies of real-life
context-aware systems (one in robotics and another in IoT) that were developed
using this tool. Throughout the examples and case studies, we provide design
patterns and a methodology for coping with the above challenges.
</p>
<a href="http://arxiv.org/abs/2005.02373" target="_blank">arXiv:2005.02373</a> [<a href="http://arxiv.org/pdf/2005.02373" target="_blank">pdf</a>]

<h2>Dissipativity Tools for Convergence to Nash Equilibria in Population Games. (arXiv:2005.03797v2 [eess.SY] UPDATED)</h2>
<h3>Murat Arcak, Nuno C. Martins</h3>
<p>We analyze the stability of a nonlinear dynamical model describing the
noncooperative strategic interactions among the agents of a finite collection
of populations. Each agent selects one strategy at a time and revises it
repeatedly according to a protocol that typically prioritizes strategies whose
payoffs are either higher than that of the current strategy or exceed the
population average. The model is predicated on well-established research in
population and evolutionary games, and has two sub-components. The first is the
payoff dynamics model (PDM), which ascribes the payoff to each strategy
according to the proportions of every population adopting the available
strategies. The second sub-component is the evolutionary dynamics model (EDM)
that accounts for the revision process. In our model, the social state at
equilibrium is a best response to the payoff, and can be viewed as a Nash-like
solution that has predictive value when it is globally asymptotically stable
(GAS). We present a systematic methodology that ascertains GAS by checking
separately whether the EDM and PDM satisfy appropriately defined
system-theoretic dissipativity properties. Our work generalizes pioneering
methods based on notions of contractivity applicable to memoryless PDMs, and
more general system-theoretic passivity conditions. As demonstrated with
examples, the added flexibility afforded by our approach is particularly useful
when the contraction properties of the PDM are unequal across populations.
</p>
<a href="http://arxiv.org/abs/2005.03797" target="_blank">arXiv:2005.03797</a> [<a href="http://arxiv.org/pdf/2005.03797" target="_blank">pdf</a>]

<h2>Bridging the gap between Natural and Medical Images through Deep Colorization. (arXiv:2005.10589v2 [cs.CV] UPDATED)</h2>
<h3>Lia Morra, Luca Piano, Fabrizio Lamberti, Tatiana Tommasi</h3>
<p>Deep learning has thrived by training on large-scale datasets. However, in
many applications, as for medical image diagnosis, getting massive amount of
data is still prohibitive due to privacy, lack of acquisition homogeneity and
annotation cost. In this scenario, transfer learning from natural image
collections is a standard practice that attempts to tackle shape, texture and
color discrepancies all at once through pretrained model fine-tuning. In this
work, we propose to disentangle those challenges and design a dedicated network
module that focuses on color adaptation. We combine learning from scratch of
the color module with transfer learning of different classification backbones,
obtaining an end-to-end, easy-to-train architecture for diagnostic image
recognition on X-ray images. Extensive experiments showed how our approach is
particularly efficient in case of data scarcity and provides a new path for
further transferring the learned color information across multiple medical
datasets.
</p>
<a href="http://arxiv.org/abs/2005.10589" target="_blank">arXiv:2005.10589</a> [<a href="http://arxiv.org/pdf/2005.10589" target="_blank">pdf</a>]

<h2>Committee neural network potentials control generalization errors and enable active learning. (arXiv:2006.01541v2 [physics.chem-ph] UPDATED)</h2>
<h3>Christoph Schran, Krystof Brezina, Ondrej Marsalek</h3>
<p>It is well known in the field of machine learning that committee models
improve accuracy, provide generalization error estimates, and enable active
learning strategies. In this work, we adapt these concepts to interatomic
potentials based on artificial neural networks. Instead of a single model,
multiple models that share the same atomic environment descriptors yield an
average that outperforms its individual members as well as a measure of the
generalization error in the form of the committee disagreement. We not only use
this disagreement to identify the most relevant configurations to build up the
model's training set in an active learning procedure, but also monitor and bias
it during simulations to control the generalization error. This facilitates the
adaptive development of committee neural network potentials and their training
sets, while keeping the number of ab initio calculations to a minimum. To
illustrate the benefits of this methodology, we apply it to the development of
a committee model for water in the condensed phase. Starting from a single
reference ab initio simulation, we use active learning to expand into new state
points and to describe the quantum nature of the nuclei. The final model,
trained on 814 reference calculations, yields excellent results under a range
of conditions, from liquid water at ambient and elevated temperatures and
pressures to different phases of ice, and the air-water interface - all
including nuclear quantum effects. This approach to committee models will
enable the systematic development of robust machine learning models for a broad
range of systems.
</p>
<a href="http://arxiv.org/abs/2006.01541" target="_blank">arXiv:2006.01541</a> [<a href="http://arxiv.org/pdf/2006.01541" target="_blank">pdf</a>]

<h2>Adversarial Item Promotion: Vulnerabilities at the Core of Top-N Recommenders that Use Images to Address Cold Start. (arXiv:2006.01888v3 [cs.IR] UPDATED)</h2>
<h3>Zhuoran Liu, Martha Larson</h3>
<p>E-commerce platforms provide their customers with ranked lists of recommended
items matching the customers' preferences. Merchants on e-commerce platforms
would like their items to appear as high as possible in the top-N of these
ranked lists. In this paper, we demonstrate how unscrupulous merchants can
create item images that artificially promote their products, improving their
rankings. Recommender systems that use images to address the cold start problem
are vulnerable to this security risk. We describe a new type of attack,
Adversarial Item Promotion (AIP), that strikes directly at the core of Top-N
recommenders: the ranking mechanism itself. Existing work on adversarial images
in recommender systems investigates the implications of conventional attacks,
which target deep learning classifiers. In contrast, our AIP attacks are
embedding attacks that seek to push features representations in a way that
fools the ranker (not a classifier) and directly lead to item promotion. We
introduce three AIP attacks insider attack, expert attack, and semantic attack,
which are defined with respect to three successively more realistic attack
models. Our experiments evaluate the danger of these attacks when mounted
against three representative visually-aware recommender algorithms in a
framework that uses images to address cold start. We also evaluate potential
defenses, including adversarial training and find that common,
currently-existing, techniques do not eliminate the danger of AIP attacks. In
sum, we show that using images to address cold start opens recommender systems
to potential threats with clear practical implications.
</p>
<a href="http://arxiv.org/abs/2006.01888" target="_blank">arXiv:2006.01888</a> [<a href="http://arxiv.org/pdf/2006.01888" target="_blank">pdf</a>]

<h2>milliEgo: Single-chip mmWave Radar Aided Egomotion Estimation via Deep Sensor Fusion. (arXiv:2006.02266v2 [cs.RO] UPDATED)</h2>
<h3>Chris Xiaoxuan Lu, Muhamad Risqi U. Saputra, Peijun Zhao, Yasin Almalioglu, Pedro P. B. de Gusmao, Changhao Chen, Ke Sun, Niki Trigoni, Andrew Markham</h3>
<p>Robust and accurate trajectory estimation of mobile agents such as people and
robots is a key requirement for providing spatial awareness for emerging
capabilities such as augmented reality or autonomous interaction. Although
currently dominated by optical techniques e.g., visual-inertial odometry, these
suffer from challenges with scene illumination or featureless surfaces. As an
alternative, we propose milliEgo, a novel deep-learning approach to robust
egomotion estimation which exploits the capabilities of low-cost mmWave radar.
Although mmWave radar has a fundamental advantage over monocular cameras of
being metric i.e., providing absolute scale or depth, current single chip
solutions have limited and sparse imaging resolution, making existing
point-cloud registration techniques brittle. We propose a new architecture that
is optimized for solving this challenging pose transformation problem.
Secondly, to robustly fuse mmWave pose estimates with additional sensors, e.g.
inertial or visual sensors we introduce a mixed attention approach to deep
fusion. Through extensive experiments, we demonstrate our proposed system is
able to achieve 1.3% 3D error drift and generalizes well to unseen
environments. We also show that the neural architecture can be made highly
efficient and suitable for real-time embedded applications.
</p>
<a href="http://arxiv.org/abs/2006.02266" target="_blank">arXiv:2006.02266</a> [<a href="http://arxiv.org/pdf/2006.02266" target="_blank">pdf</a>]

<h2>Learning Long-Term Dependencies in Irregularly-Sampled Time Series. (arXiv:2006.04418v2 [cs.LG] UPDATED)</h2>
<h3>Mathias Lechner, Ramin Hasani</h3>
<p>Recurrent neural networks (RNNs) with continuous-time hidden states are a
natural fit for modeling irregularly-sampled time series. These models,
however, face difficulties when the input data possess long-term dependencies.
We prove that similar to standard RNNs, the underlying reason for this issue is
the vanishing or exploding of the gradient during training. This phenomenon is
expressed by the ordinary differential equation (ODE) representation of the
hidden state, regardless of the ODE solver's choice. We provide a solution by
designing a new algorithm based on the long short-term memory (LSTM) that
separates its memory from its time-continuous state. This way, we encode a
continuous-time dynamical flow within the RNN, allowing it to respond to inputs
arriving at arbitrary time-lags while ensuring a constant error propagation
through the memory path. We call these RNN models ODE-LSTMs. We experimentally
show that ODE-LSTMs outperform advanced RNN-based counterparts on non-uniformly
sampled data with long-term dependencies. All code and data is available at
https://github.com/mlech26l/learning-long-term-irregular-ts.
</p>
<a href="http://arxiv.org/abs/2006.04418" target="_blank">arXiv:2006.04418</a> [<a href="http://arxiv.org/pdf/2006.04418" target="_blank">pdf</a>]

<h2>Locally Private Graph Neural Networks. (arXiv:2006.05535v4 [cs.LG] UPDATED)</h2>
<h3>Sina Sajadmanesh, Daniel Gatica-Perez</h3>
<p>Graph Neural Networks (GNNs) have demonstrated superior performance in
learning graph representations for several subsequent downstream inference
tasks. However, learning over graph data can raise privacy concerns when nodes
represent people or human-related variables that involve personal information
about individuals. Previous works have presented various techniques for
privacy-preserving deep learning over non-relational data, such as image,
audio, video, and text, but there is less work addressing the privacy issues
involved in applying deep learning algorithms on graphs. As a result and for
the first time, in this paper, we develop a privacy-preserving GNN learning
algorithm with formal privacy guarantees based on Local Differential Privacy
(LDP) to tackle the problem of node-level privacy, where graph nodes have
potentially sensitive features that need to be kept private, but they could be
beneficial for an untrusted server to learn richer node representations.
Specifically, we propose an optimized LDP algorithm with an unbiased estimator,
using which a central server can communicate with the graph nodes to privately
collect their data and estimate the graph convolution layer of the GNN. To
further reduce the effect of the injected noise, we propose a simple graph
convolution layer based on the multi-hop aggregation of the nodes' features.
Extensive experiments conducted over real-world datasets demonstrate the
capability of our method in maintaining an appropriate privacy-accuracy
trade-off for privacy-preserving node classification.
</p>
<a href="http://arxiv.org/abs/2006.05535" target="_blank">arXiv:2006.05535</a> [<a href="http://arxiv.org/pdf/2006.05535" target="_blank">pdf</a>]

<h2>Learning to Incentivize Other Learning Agents. (arXiv:2006.06051v2 [cs.LG] UPDATED)</h2>
<h3>Jiachen Yang, Ang Li, Mehrdad Farajtabar, Peter Sunehag, Edward Hughes, Hongyuan Zha</h3>
<p>The challenge of developing powerful and general Reinforcement Learning (RL)
agents has received increasing attention in recent years. Much of this effort
has focused on the single-agent setting, in which an agent maximizes a
predefined extrinsic reward function. However, a long-term question inevitably
arises: how will such independent agents cooperate when they are continually
learning and acting in a shared multi-agent environment? Observing that humans
often provide incentives to influence others' behavior, we propose to equip
each RL agent in a multi-agent environment with the ability to give rewards
directly to other agents, using a learned incentive function. Each agent learns
its own incentive function by explicitly accounting for its impact on the
learning of recipients and, through them, the impact on its own extrinsic
objective. We demonstrate in experiments that such agents significantly
outperform standard RL and opponent-shaping agents in challenging general-sum
Markov games, often by finding a near-optimal division of labor. Our work
points toward more opportunities and challenges along the path to ensure the
common good in a multi-agent future.
</p>
<a href="http://arxiv.org/abs/2006.06051" target="_blank">arXiv:2006.06051</a> [<a href="http://arxiv.org/pdf/2006.06051" target="_blank">pdf</a>]

<h2>System to Integrate Fairness Transparently: An Industry Approach. (arXiv:2006.06082v2 [cs.CY] UPDATED)</h2>
<h3>Emily Dodwell, Cheryl Flynn, Balachander Krishnamurthy, Subhabrata Majumdar, Ritwik Mitra</h3>
<p>Numerous Machine Learning (ML) bias-related problems have generated
significant press in recent years. This has led to scrutiny of corporate
failure regarding how to incorporate human oversight in thorough evaluation and
prevention of bias. Companies have a responsibility to monitor ML processes for
bias and mitigate any bias detected, ensure business product integrity,
preserve customer loyalty, and protect brand image. In this paper, we propose
SIFT (System to Integrate Fairness Transparently) as a methodological approach
for integrating bias detection, mitigation, and documentation in ML projects at
various stages of the ML lifecycle. To this end, SIFT involves a combination of
mechanized and human-in-the-loop components. The human-in-the-loop components
are inserted at points in the ML lifecycle where project managers/practitioners
could benefit from guidance from experts within the company in areas such as
Human Resources, Public Relations, Legal, Privacy, and Compliance. To
demonstrate the value of SIFT, we present two industry use cases that may
require fairness scrutiny: (1) marketing and (2) hiring. We show how SIFT can
be used to identify potential biases and determine appropriate mitigation
strategies.
</p>
<a href="http://arxiv.org/abs/2006.06082" target="_blank">arXiv:2006.06082</a> [<a href="http://arxiv.org/pdf/2006.06082" target="_blank">pdf</a>]

<h2>A Class of Algorithms for General Instrumental Variable Models. (arXiv:2006.06366v2 [cs.LG] UPDATED)</h2>
<h3>Niki Kilbertus, Matt J. Kusner, Ricardo Silva</h3>
<p>Causal treatment effect estimation is a key problem that arises in a variety
of real-world settings, from personalized medicine to governmental policy
making. There has been a flurry of recent work in machine learning on
estimating causal effects when one has access to an instrument. However, to
achieve identifiability, they in general require one-size-fits-all assumptions
such as an additive error model for the outcome. An alternative is partial
identification, which provides bounds on the causal effect. Little exists in
terms of bounding methods that can deal with the most general case, where the
treatment itself can be continuous. Moreover, bounding methods generally do not
allow for a continuum of assumptions on the shape of the causal effect that can
smoothly trade off stronger background knowledge for more informative bounds.
In this work, we provide a method for causal effect bounding in continuous
distributions, leveraging recent advances in gradient-based methods for the
optimization of computationally intractable objective functions. We demonstrate
on a set of synthetic and real-world data that our bounds capture the causal
effect when additive methods fail, providing a useful range of answers
compatible with observation as opposed to relying on unwarranted structural
assumptions.
</p>
<a href="http://arxiv.org/abs/2006.06366" target="_blank">arXiv:2006.06366</a> [<a href="http://arxiv.org/pdf/2006.06366" target="_blank">pdf</a>]

<h2>Dataset-Level Attribute Leakage in Collaborative Learning. (arXiv:2006.07267v2 [cs.LG] UPDATED)</h2>
<h3>Wanrong Zhang, Shruti Tople, Olga Ohrimenko</h3>
<p>Secure multi-party machine learning allows several parties to build a model
on their pooled data to increase utility while not explicitly sharing data with
each other. We show that such multi-party computation can cause leakage of
global dataset properties between the parties even when parties obtain only
black-box access to the final model. In particular, a "curious" party can infer
the distribution of sensitive attributes in other parties' data with high
accuracy. This raises concerns regarding the confidentiality of properties
pertaining to the whole dataset as opposed to individual data records. We show
that our attack can leak population-level properties in datasets of different
types, including tabular, text, and graph data. To understand and measure the
source of leakage, we consider several models of correlation between a
sensitive attribute and the rest of the data. Using multiple machine learning
models, we show that leakage occurs even if the sensitive attribute is not
included in the training data and has a low correlation with other attributes
and the target variable.
</p>
<a href="http://arxiv.org/abs/2006.07267" target="_blank">arXiv:2006.07267</a> [<a href="http://arxiv.org/pdf/2006.07267" target="_blank">pdf</a>]

<h2>Using Reinforcement Learning to Allocate and Manage Service Function Chains in Cellular Networks. (arXiv:2006.07349v3 [cs.NI] UPDATED)</h2>
<h3>Guto Leoni Santos, Patricia Takako Endo</h3>
<p>It is expected that the next generation cellular networks provide a connected
society with fully mobility to empower the socio-economic transformation.
Several other technologies will benefits of this evolution, such as Internet of
Things, smart cities, smart agriculture, vehicular networks, healthcare
applications, and so on. Each of these scenarios presents specific requirements
and demands different network configurations. To deal with this heterogeneity,
virtualization technology is key technology. Indeed, the network function
virtualization (NFV) paradigm provides flexibility for the network manager,
allocating resources according to the demand, and reduces acquisition and
operational costs. In addition, it is possible to specify an ordered set of
network virtual functions (VNFs) for a given service, which is called as
service function chain (SFC). However, besides the advantages from service
virtualization, it is expected that network performance and availability do not
be affected by its usage. In this paper, we propose the use of reinforcement
learning to deploy a SFC of cellular network service and manage the VNFs
operation. We consider that the SFC is deployed by the reinforcement learning
agent considering a scenarios with distributed data centers, where the VNFs are
deployed in virtual machines in commodity servers. The NFV management is
related to create, delete, and restart the VNFs. The main purpose is to reduce
the number of lost packets taking into account the energy consumption of the
servers. We use the Proximal Policy Optimization (PPO) algorithm to implement
the agent and preliminary results show that the agent is able to allocate the
SFC and manage the VNFs, reducing the number of lost packets.
</p>
<a href="http://arxiv.org/abs/2006.07349" target="_blank">arXiv:2006.07349</a> [<a href="http://arxiv.org/pdf/2006.07349" target="_blank">pdf</a>]

<h2>Catplayinginthesnow: Impact of Prior Segmentation on a Model of Visually Grounded Speech. (arXiv:2006.08387v2 [cs.CL] UPDATED)</h2>
<h3>William N. Havard, Jean-Pierre Chevrot, Laurent Besacier</h3>
<p>The language acquisition literature shows that children do not build their
lexicon by segmenting the spoken input into phonemes and then building up words
from them, but rather adopt a top-down approach and start by segmenting
word-like units and then break them down into smaller units. This suggests that
the ideal way of learning a language is by starting from full semantic units.
In this paper, we investigate if this is also the case for a neural model of
Visually Grounded Speech trained on a speech-image retrieval task. We evaluated
how well such a network is able to learn a reliable speech-to-image mapping
when provided with phone, syllable, or word boundary information. We present a
simple way to introduce such information into an RNN-based model and
investigate which type of boundary is the most efficient. We also explore at
which level of the network's architecture such information should be introduced
so as to maximise its performances. Finally, we show that using multiple
boundary types at once in a hierarchical structure, by which low-level segments
are used to recompose high-level segments, is beneficial and yields better
results than using low-level or high-level segments in isolation.
</p>
<a href="http://arxiv.org/abs/2006.08387" target="_blank">arXiv:2006.08387</a> [<a href="http://arxiv.org/pdf/2006.08387" target="_blank">pdf</a>]

<h2>Higher-Order Quantum Reservoir Computing. (arXiv:2006.08999v2 [quant-ph] UPDATED)</h2>
<h3>Quoc Hoan Tran, Kohei Nakajima</h3>
<p>Quantum reservoir computing (QRC) is an emerging paradigm for harnessing the
natural dynamics of quantum systems as computational resources that can be used
for temporal machine learning tasks. In the current setup, QRC is difficult to
deal with high-dimensional data and has a major drawback of scalability in
physical implementations. We propose higher-order QRC, a hybrid
quantum-classical framework consisting of multiple but small quantum systems
that are mutually communicated via classical connections like linear feedback.
By utilizing the advantages of both classical and quantum techniques, our
framework enables an efficient implementation to boost the scalability and
performance of QRC. Furthermore, higher-order settings allow us to implement a
FORCE learning or an innate training scheme, which provides flexibility and
high operability to harness high-dimensional quantum dynamics and significantly
extends the application domain of QRC. We demonstrate the effectiveness of our
framework in emulating large-scale nonlinear dynamical systems, including
complex spatiotemporal chaos, which outperforms many of the existing machine
learning techniques in certain situations.
</p>
<a href="http://arxiv.org/abs/2006.08999" target="_blank">arXiv:2006.08999</a> [<a href="http://arxiv.org/pdf/2006.08999" target="_blank">pdf</a>]

<h2>UCSG-Net -- Unsupervised Discovering of Constructive Solid Geometry Tree. (arXiv:2006.09102v3 [cs.CV] UPDATED)</h2>
<h3>Kacper Kania, Maciej Zi&#x119;ba, Tomasz Kajdanowicz</h3>
<p>Signed distance field (SDF) is a prominent implicit representation of 3D
meshes. Methods that are based on such representation achieved state-of-the-art
3D shape reconstruction quality. However, these methods struggle to reconstruct
non-convex shapes. One remedy is to incorporate a constructive solid geometry
framework (CSG) that represents a shape as a decomposition into primitives. It
allows to embody a 3D shape of high complexity and non-convexity with a simple
tree representation of Boolean operations. Nevertheless, existing approaches
are supervised and require the entire CSG parse tree that is given upfront
during the training process. On the contrary, we propose a model that extracts
a CSG parse tree without any supervision - UCSG-Net. Our model predicts
parameters of primitives and binarizes their SDF representation through
differentiable indicator function. It is achieved jointly with discovering the
structure of a Boolean operators tree. The model selects dynamically which
operator combination over primitives leads to the reconstruction of high
fidelity. We evaluate our method on 2D and 3D autoencoding tasks. We show that
the predicted parse tree representation is interpretable and can be used in CAD
software.
</p>
<a href="http://arxiv.org/abs/2006.09102" target="_blank">arXiv:2006.09102</a> [<a href="http://arxiv.org/pdf/2006.09102" target="_blank">pdf</a>]

<h2>Time Series Extrinsic Regression. (arXiv:2006.12672v2 [cs.LG] UPDATED)</h2>
<h3>Chang Wei Tan, Christoph Bergmeir, Francois Petitjean, Geoffrey I. Webb</h3>
<p>This paper studies Time Series Extrinsic Regression (TSER): a regression task
of which the aim is to learn the relationship between a time series and a
continuous scalar variable; a task closely related to time series
classification (TSC), which aims to learn the relationship between a time
series and a categorical class label. This task generalizes time series
forecasting (TSF), relaxing the requirement that the value predicted be a
future value of the input series or primarily depend on more recent values.

In this paper, we motivate and study this task, and benchmark existing
solutions and adaptations of TSC algorithms on a novel archive of 19 TSER
datasets which we have assembled. Our results show that the state-of-the-art
TSC algorithm Rocket, when adapted for regression, achieves the highest overall
accuracy compared to adaptations of other TSC algorithms and state-of-the-art
machine learning (ML) algorithms such as XGBoost, Random Forest and Support
Vector Regression. More importantly, we show that much research is needed in
this field to improve the accuracy of ML models. We also find evidence that
further research has excellent prospects of improving upon these
straightforward baselines.
</p>
<a href="http://arxiv.org/abs/2006.12672" target="_blank">arXiv:2006.12672</a> [<a href="http://arxiv.org/pdf/2006.12672" target="_blank">pdf</a>]

<h2>Hermes Attack: Steal DNN Models with Lossless Inference Accuracy. (arXiv:2006.12784v2 [cs.CR] UPDATED)</h2>
<h3>Yuankun Zhu, Yueqiang Cheng, Husheng Zhou, Yantao Lu</h3>
<p>Deep Neural Networks (DNNs) models become one of the most valuable enterprise
assets due to their critical roles in all aspects of applications. With the
trend of privatization deployment of DNN models, the data leakage of the DNN
models is becoming increasingly serious and widespread. All existing
model-extraction attacks can only leak parts of targeted DNN models with low
accuracy or high overhead. In this paper, we first identify a new attack
surface -- unencrypted PCIe traffic, to leak DNN models. Based on this new
attack surface, we propose a novel model-extraction attack, namely Hermes
Attack, which is the first attack to fully steal the whole victim DNN model.
The stolen DNN models have the same hyper-parameters, parameters, and
semantically identical architecture as the original ones. It is challenging due
to the closed-source CUDA runtime, driver, and GPU internals, as well as the
undocumented data structures and the loss of some critical semantics in the
PCIe traffic. Additionally, there are millions of PCIe packets with numerous
noises and chaos orders. Our Hermes Attack addresses these issues by huge
reverse engineering efforts and reliable semantic reconstruction, as well as
skillful packet selection and order correction. We implement a prototype of the
Hermes Attack, and evaluate two sequential DNN models (i.e., MINIST and VGG)
and one consequential DNN model (i.e., ResNet) on three NVIDIA GPU platforms,
i.e., NVIDIA Geforce GT 730, NVIDIA Geforce GTX 1080 Ti, and NVIDIA Geforce RTX
2080 Ti. The evaluation results indicate that our scheme is able to efficiently
and completely reconstruct ALL of them with making inferences on any one image.
Evaluated with Cifar10 test dataset that contains 10,000 images, the experiment
results show that the stolen models have the same inference accuracy as the
original ones (i.e., lossless inference accuracy).
</p>
<a href="http://arxiv.org/abs/2006.12784" target="_blank">arXiv:2006.12784</a> [<a href="http://arxiv.org/pdf/2006.12784" target="_blank">pdf</a>]

<h2>Bit Error Robustness for Energy-Efficient DNN Accelerators. (arXiv:2006.13977v2 [cs.LG] UPDATED)</h2>
<h3>David Stutz, Nandhini Chandramoorthy, Matthias Hein, Bernt Schiele</h3>
<p>Deep neural network (DNN) accelerators received considerable attention in
past years due to saved energy compared to mainstream hardware. Low-voltage
operation of DNN accelerators allows to further reduce energy consumption
significantly, however, causes bit-level failures in the memory storing the
quantized DNN weights. In this paper, we show that a combination of robust
fixed-point quantization, weight clipping, and random bit error training
(RandBET) improves robustness against random bit errors in (quantized) DNN
weights significantly. This leads to high energy savings from both low-voltage
operation as well as low-precision quantization. Our approach generalizes
across operating voltages and accelerators, as demonstrated on bit errors from
profiled SRAM arrays. We also discuss why weight clipping alone is already a
quite effective way to achieve robustness against bit errors. Moreover, we
specifically discuss the involved trade-offs regarding accuracy, robustness and
precision: Without losing more than 1% in accuracy compared to a normally
trained 8-bit DNN, we can reduce energy consumption on CIFAR-10 by 20%. Higher
energy savings of, e.g., 30%, are possible at the cost of 2.5% accuracy, even
for 4-bit DNNs.
</p>
<a href="http://arxiv.org/abs/2006.13977" target="_blank">arXiv:2006.13977</a> [<a href="http://arxiv.org/pdf/2006.13977" target="_blank">pdf</a>]

<h2>A Loss Function for Generative Neural Networks Based on Watson's Perceptual Model. (arXiv:2006.15057v2 [cs.LG] UPDATED)</h2>
<h3>Steffen Czolbe, Oswin Krause, Ingemar Cox, Christian Igel</h3>
<p>To train Variational Autoencoders (VAEs) to generate realistic imagery
requires a loss function that reflects human perception of image similarity. We
propose such a loss function based on Watson's perceptual model, which computes
a weighted distance in frequency space and accounts for luminance and contrast
masking. We extend the model to color images, increase its robustness to
translation by using the Fourier Transform, remove artifacts due to splitting
the image into blocks, and make it differentiable. In experiments, VAEs trained
with the new loss function generated realistic, high-quality image samples.
Compared to using the Euclidean distance and the Structural Similarity Index,
the images were less blurry; compared to deep neural network based losses, the
new approach required less computational resources and generated images with
less artifacts.
</p>
<a href="http://arxiv.org/abs/2006.15057" target="_blank">arXiv:2006.15057</a> [<a href="http://arxiv.org/pdf/2006.15057" target="_blank">pdf</a>]

<h2>COVID-19 Screening Using Residual Attention Network an Artificial Intelligence Approach. (arXiv:2006.16106v3 [eess.IV] UPDATED)</h2>
<h3>Vishal Sharma, Curtis Dyreson</h3>
<p>Coronavirus Disease 2019 (COVID-19) is caused by severe acute respiratory
syndrome coronavirus 2 virus (SARS-CoV-2). The virus transmits rapidly; it has
a basic reproductive number R of 2.2-2.7. In March 2020, the World Health
Organization declared the COVID-19 outbreak a pandemic. COVID-19 is currently
affecting more than 200 countries with 6M active cases. An effective testing
strategy for COVID-19 is crucial to controlling the outbreak but the demand for
testing surpasses the availability of test kits that use Reverse Transcription
Polymerase Chain Reaction (RT-PCR). In this paper, we present a technique to
screen for COVID-19 using artificial intelligence. Our technique takes only
seconds to screen for the presence of the virus in a patient. We collected a
dataset of chest X-ray images and trained several popular deep convolution
neural network-based models (VGG, MobileNet, Xception, DenseNet,
InceptionResNet) to classify the chest X-rays. Unsatisfied with these models,
we then designed and built a Residual Attention Network that was able to screen
COVID-19 with a testing accuracy of 98% and a validation accuracy of 100%. A
feature maps visual of our model show areas in a chest X-ray which are
important for classification. Our work can help to increase the adaptation of
AI-assisted applications in clinical practice. The code and dataset used in
this project are available at
https://github.com/vishalshar/covid-19-screening-using-RAN-on-X-ray-images.
</p>
<a href="http://arxiv.org/abs/2006.16106" target="_blank">arXiv:2006.16106</a> [<a href="http://arxiv.org/pdf/2006.16106" target="_blank">pdf</a>]

<h2>Delayed Q-update: A novel credit assignment technique for deriving an optimal operation policy for the Grid-Connected Microgrid. (arXiv:2006.16659v3 [eess.SY] UPDATED)</h2>
<h3>Hyungjun Park, Daiki Min, Jong-hyun Ryu, Dong Gu Choi</h3>
<p>A microgrid is an innovative system that integrates distributed energy
resources to supply electricity demand within electrical boundaries. This study
proposes an approach for deriving a desirable microgrid operation policy that
enables sophisticated controls in the microgrid system using the proposed novel
credit assignment technique, delayed-Q update. The technique employs novel
features such as the ability to tackle and resolve the delayed effective
property of the microgrid, which prevents learning agents from deriving a
well-fitted policy under sophisticated controls. The proposed technique tracks
the history of the charging period and retroactively assigns an adjusted value
to the ESS charging control. The operation policy derived using the proposed
approach is well-fitted for the real effects of ESS operation because of the
process of the technique. Therefore, it supports the search for a near-optimal
operation policy under a sophisticatedly controlled microgrid environment. To
validate our technique, we simulate the operation policy under a real-world
grid-connected microgrid system and demonstrate the convergence to a
near-optimal policy by comparing performance measures of our policy with
benchmark policy and optimal policy.
</p>
<a href="http://arxiv.org/abs/2006.16659" target="_blank">arXiv:2006.16659</a> [<a href="http://arxiv.org/pdf/2006.16659" target="_blank">pdf</a>]

<h2>Cross-Scale Internal Graph Neural Network for Image Super-Resolution. (arXiv:2006.16673v2 [cs.CV] UPDATED)</h2>
<h3>Shangchen Zhou, Jiawei Zhang, Wangmeng Zuo, Chen Change Loy</h3>
<p>Non-local self-similarity in natural images has been well studied as an
effective prior in image restoration. However, for single image
super-resolution (SISR), most existing deep non-local methods (e.g., non-local
neural networks) only exploit similar patches within the same scale of the
low-resolution (LR) input image. Consequently, the restoration is limited to
using the same-scale information while neglecting potential high-resolution
(HR) cues from other scales. In this paper, we explore the cross-scale patch
recurrence property of a natural image, i.e., similar patches tend to recur
many times across different scales. This is achieved using a novel cross-scale
internal graph neural network (IGNN). Specifically, we dynamically construct a
cross-scale graph by searching k-nearest neighboring patches in the downsampled
LR image for each query patch in the LR image. We then obtain the corresponding
k HR neighboring patches in the LR image and aggregate them adaptively in
accordance to the edge label of the constructed graph. In this way, the HR
information can be passed from k HR neighboring patches to the LR query patch
to help it recover more detailed textures. Besides, these internal
image-specific LR/HR exemplars are also significant complements to the external
information learned from the training dataset. Extensive experiments
demonstrate the effectiveness of IGNN against the state-of-the-art SISR methods
including existing non-local networks on standard benchmarks.
</p>
<a href="http://arxiv.org/abs/2006.16673" target="_blank">arXiv:2006.16673</a> [<a href="http://arxiv.org/pdf/2006.16673" target="_blank">pdf</a>]

<h2>Provably Efficient Neural Estimation of Structural Equation Model: An Adversarial Approach. (arXiv:2007.01290v3 [stat.ML] UPDATED)</h2>
<h3>Luofeng Liao, You-Lin Chen, Zhuoran Yang, Bo Dai, Zhaoran Wang, Mladen Kolar</h3>
<p>Structural equation models (SEMs) are widely used in sciences, ranging from
economics to psychology, to uncover causal relationships underlying a complex
system under consideration and estimate structural parameters of interest. We
study estimation in a class of generalized SEMs where the object of interest is
defined as the solution to a linear operator equation. We formulate the linear
operator equation as a min-max game, where both players are parameterized by
neural networks (NNs), and learn the parameters of these neural networks using
the stochastic gradient descent. We consider both 2-layer and multi-layer NNs
with ReLU activation functions and prove global convergence in an
overparametrized regime, where the number of neurons is diverging. The results
are established using techniques from online learning and local linearization
of NNs, and improve in several aspects the current state-of-the-art. For the
first time we provide a tractable estimation procedure for SEMs based on NNs
with provable convergence and without the need for sample splitting.
</p>
<a href="http://arxiv.org/abs/2007.01290" target="_blank">arXiv:2007.01290</a> [<a href="http://arxiv.org/pdf/2007.01290" target="_blank">pdf</a>]

<h2>Program Synthesis with Pragmatic Communication. (arXiv:2007.05060v2 [cs.AI] UPDATED)</h2>
<h3>Yewen Pu, Kevin Ellis, Marta Kryven, Josh Tenenbaum, Armando Solar-Lezama</h3>
<p>Program synthesis techniques construct or infer programs from user-provided
specifications, such as input-output examples. Yet most specifications,
especially those given by end-users, leave the synthesis problem radically
ill-posed, because many programs may simultaneously satisfy the specification.
Prior work resolves this ambiguity by using various inductive biases, such as a
preference for simpler programs. This work introduces a new inductive bias
derived by modeling the program synthesis task as rational communication,
drawing insights from recursive reasoning models of pragmatics. Given a
specification, we score a candidate program both on its consistency with the
specification, and also whether a rational speaker would chose this particular
specification to communicate that program. We develop efficient algorithms for
such an approach when learning from input-output examples, and build a
pragmatic program synthesizer over a simple grid-like layout domain. A user
study finds that end-user participants communicate more effectively with the
pragmatic program synthesizer over a non-pragmatic one.
</p>
<a href="http://arxiv.org/abs/2007.05060" target="_blank">arXiv:2007.05060</a> [<a href="http://arxiv.org/pdf/2007.05060" target="_blank">pdf</a>]

<h2>Implicit Distributional Reinforcement Learning. (arXiv:2007.06159v2 [cs.LG] UPDATED)</h2>
<h3>Yuguang Yue, Zhendong Wang, Mingyuan Zhou</h3>
<p>To improve the sample efficiency of policy-gradient based reinforcement
learning algorithms, we propose implicit distributional actor-critic (IDAC)
that consists of a distributional critic, built on two deep generator networks
(DGNs), and a semi-implicit actor (SIA), powered by a flexible policy
distribution. We adopt a distributional perspective on the discounted
cumulative return and model it with a state-action-dependent implicit
distribution, which is approximated by the DGNs that take state-action pairs
and random noises as their input. Moreover, we use the SIA to provide a
semi-implicit policy distribution, which mixes the policy parameters with a
reparameterizable distribution that is not constrained by an analytic density
function. In this way, the policy's marginal distribution is implicit,
providing the potential to model complex properties such as covariance
structure and skewness, but its parameter and entropy can still be estimated.
We incorporate these features with an off-policy algorithm framework to solve
problems with continuous action space and compare IDAC with state-of-the-art
algorithms on representative OpenAI Gym environments. We observe that IDAC
outperforms these baselines in most tasks. Python code is provided.
</p>
<a href="http://arxiv.org/abs/2007.06159" target="_blank">arXiv:2007.06159</a> [<a href="http://arxiv.org/pdf/2007.06159" target="_blank">pdf</a>]

<h2>Learning Generalized Relational Heuristic Networks for Model-Agnostic Planning. (arXiv:2007.06702v2 [cs.LG] UPDATED)</h2>
<h3>Rushang Karia, Siddharth Srivastava</h3>
<p>Computing goal-directed behavior is essential to designing efficient AI
systems. Due to the computational complexity of planning, current approaches
rely primarily upon hand-coded symbolic action models and hand-coded
heuristic-function generators for efficiency. Learned heuristics for such
problems have been of limited utility as they are difficult to apply to
problems with objects and object quantities that are significantly different
from those in the training data. This paper develops a new approach for
learning generalized heuristics in the absence of symbolic action models using
deep neural networks that utilize an input predicate vocabulary but are
agnostic to object names and quantities. It uses an abstract state
representation to facilitate data efficient, generalizable learning. Empirical
evaluation on a range of benchmark domains show that in contrast to prior
approaches, generalized heuristics computed by this method can be transferred
easily to problems with different objects and with object quantities much
larger than those in the training data.
</p>
<a href="http://arxiv.org/abs/2007.06702" target="_blank">arXiv:2007.06702</a> [<a href="http://arxiv.org/pdf/2007.06702" target="_blank">pdf</a>]

<h2>Proof of Concept: Automatic Type Recognition. (arXiv:2007.07690v2 [cs.CV] UPDATED)</h2>
<h3>Vincent Christlein, Nikolaus Weichselbaumer, Saskia Limbach, Mathias Seuret</h3>
<p>The type used to print an early modern book can give scholars valuable
information about the time and place of its production as well as its producer.
Recognizing such type is currently done manually using both the character
shapes of `M' or `Qu' and the size of the total type to look it up in a large
reference work. This is a reliable method, but it is also slow and requires
specific skills. We investigate the performance of type classification and type
retrieval using a newly created dataset consisting of easy and difficult types
used in early printed books. For type classification, we rely on a deep
Convolutional Neural Network (CNN) originally used for font-group
classification while we use a common writer identification method for the
retrieval case. We show that in both scenarios, easy types can be
classified/retrieved with a high accuracy while difficult cases are indeed
difficult.
</p>
<a href="http://arxiv.org/abs/2007.07690" target="_blank">arXiv:2007.07690</a> [<a href="http://arxiv.org/pdf/2007.07690" target="_blank">pdf</a>]

<h2>Effective models and predictability of chaotic multiscale systems via machine learning. (arXiv:2007.08634v2 [nlin.AO] UPDATED)</h2>
<h3>Francesco Borra, Angelo Vulpiani, Massimo Cencini</h3>
<p>We scrutinize the use of machine learning, based on reservoir computing, to
build data-driven effective models of multiscale chaotic systems. We show that,
for a wide scale separation, machine learning generates effective models akin
to those obtained using multiscale asymptotic techniques and, remarkably,
remains effective in predictability also when the scale separation is reduced.
We also show that predictability can be improved by hybridizing the reservoir
with an imperfect model.
</p>
<a href="http://arxiv.org/abs/2007.08634" target="_blank">arXiv:2007.08634</a> [<a href="http://arxiv.org/pdf/2007.08634" target="_blank">pdf</a>]

<h2>Adversarial Immunization for Improving Certifiable Robustness on Graphs. (arXiv:2007.09647v3 [cs.LG] UPDATED)</h2>
<h3>Shuchang Tao, Huawei Shen, Qi Cao, Liang Hou, Xueqi Cheng</h3>
<p>Despite achieving strong performance in the semi-supervised node
classification task, graph neural networks (GNNs) are vulnerable to adversarial
attacks, similar to other deep learning models. Existing research works either
focus on developing robust GNN models or attack detection methods against
attacks on graphs. However, little research attention is paid to the potential
and practice of immunization to adversarial attacks on graphs. In this paper,
we formulate the problem of graph adversarial immunization as a bilevel
optimization problem, i.e., vaccinating an affordable fraction of node pairs,
connected or unconnected, to improve the certifiable robustness of the graph
against any admissible adversarial attack. We further propose an efficient
algorithm, called AdvImmune, which optimizes meta-gradient in a discrete way to
circumvent the computationally expensive combinatorial optimization when
solving the adversarial immunization problem. Experiments are conducted on two
citation networks and one social network. Experimental results demonstrate that
the proposed AdvImmune immunization method remarkably improves the fraction of
robust nodes by 12%, 42%, 65%, with an affordable immune budget of only 5%
edges.
</p>
<a href="http://arxiv.org/abs/2007.09647" target="_blank">arXiv:2007.09647</a> [<a href="http://arxiv.org/pdf/2007.09647" target="_blank">pdf</a>]

<h2>Complex Skill Acquisition Through Simple Skill Imitation Learning. (arXiv:2007.10281v4 [cs.LG] UPDATED)</h2>
<h3>Pranay Pasula</h3>
<p>Humans often think of complex tasks as combinations of simpler subtasks in
order to learn those complex tasks more efficiently. For example, a backflip
could be considered a combination of four subskills: jumping, tucking knees,
rolling backwards, and thrusting arms downwards. Motivated by this line of
reasoning, we propose a new algorithm that trains neural network policies on
simple, easy-to-learn skills in order to cultivate latent spaces that
accelerate imitation learning of complex, hard-to-learn skills. We focus on the
case in which the complex task comprises a concurrent (and possibly sequential)
combination of the simpler subtasks, and therefore our algorithm can be seen as
a novel approach to concurrent hierarchical imitation learning. We evaluate our
algorithm on difficult tasks in a high-dimensional environment and find that it
consistently outperforms a state-of-the-art baseline in training speed and
overall performance.
</p>
<a href="http://arxiv.org/abs/2007.10281" target="_blank">arXiv:2007.10281</a> [<a href="http://arxiv.org/pdf/2007.10281" target="_blank">pdf</a>]

<h2>Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Prediction. (arXiv:2008.01377v2 [cs.CL] UPDATED)</h2>
<h3>Stefan Heid, Marcel Wever, Eyke H&#xfc;llermeier</h3>
<p>Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a
key requirement for both linguistic research and subsequent automated natural
language processing (NLP) tasks. This problem is commonly tackled using machine
learning methods, i.e., by training a POS tagger on a sufficiently large corpus
of labeled data. While the problem of POS tagging can essentially be considered
as solved for modern languages, historical corpora turn out to be much more
difficult, especially due to the lack of native speakers and sparsity of
training data. Moreover, most texts have no sentences as we know them today,
nor a common orthography. These irregularities render the task of automated POS
tagging more difficult and error-prone. Under these circumstances, instead of
forcing the POS tagger to predict and commit to a single tag, it should be
enabled to express its uncertainty. In this paper, we consider POS tagging
within the framework of set-valued prediction, which allows the POS tagger to
express its uncertainty via predicting a set of candidate POS tags instead of
guessing a single one. The goal is to guarantee a high confidence that the
correct POS tag is included while keeping the number of candidates small. In
our experimental study, we find that extending state-of-the-art POS taggers to
set-valued prediction yields more precise and robust taggings, especially for
unknown words, i.e., words not occurring in the training data.
</p>
<a href="http://arxiv.org/abs/2008.01377" target="_blank">arXiv:2008.01377</a> [<a href="http://arxiv.org/pdf/2008.01377" target="_blank">pdf</a>]

<h2>A Learning-from-Observation Framework: One-Shot Robot Teaching for Grasp-Manipulation-Release Household Operations. (arXiv:2008.01513v4 [cs.RO] UPDATED)</h2>
<h3>Naoki Wake, Riku Arakawa, Iori Yanokura, Takuya Kiyokawa, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi</h3>
<p>A household robot is expected to perform various manipulative operations with
an understanding of the purpose of the task. To this end, a desirable robotic
application should provide an on-site robot teaching framework for non-experts.
Here we propose a Learning-from-Observation (LfO) framework for
grasp-manipulation-release class household operations (GMR-operations). The
framework maps human demonstrations to predefined task models through one-shot
teaching. Each task model contains both high-level knowledge regarding the
geometric constraints and low-level knowledge related to human postures. The
key idea is to design a task model that 1) covers various GMR-operations and 2)
includes human postures to achieve tasks. We verify the applicability of our
framework by testing an operational LfO system with a real robot. In addition,
we quantify the coverage of the task model by analyzing online videos of
household operations. In the context of one-shot robot teaching, the
contribution of this study is a framework that 1) covers various GMR-operations
and 2) mimics human postures during the operations.
</p>
<a href="http://arxiv.org/abs/2008.01513" target="_blank">arXiv:2008.01513</a> [<a href="http://arxiv.org/pdf/2008.01513" target="_blank">pdf</a>]

<h2>One for Many: Transfer Learning for Building HVAC Control. (arXiv:2008.03625v2 [eess.SY] UPDATED)</h2>
<h3>Shichao Xu, Yixuan Wang, Yanzhi Wang, Zheng O&#x27;Neill, Qi Zhu</h3>
<p>The design of building heating, ventilation, and air conditioning (HVAC)
system is critically important, as it accounts for around half of building
energy consumption and directly affects occupant comfort, productivity, and
health. Traditional HVAC control methods are typically based on creating
explicit physical models for building thermal dynamics, which often require
significant effort to develop and are difficult to achieve sufficient accuracy
and efficiency for runtime building control and scalability for field
implementations. Recently, deep reinforcement learning (DRL) has emerged as a
promising data-driven method that provides good control performance without
analyzing physical models at runtime. However, a major challenge to DRL (and
many other data-driven learning methods) is the long training time it takes to
reach the desired performance. In this work, we present a novel transfer
learning based approach to overcome this challenge. Our approach can
effectively transfer a DRL-based HVAC controller trained for the source
building to a controller for the target building with minimal effort and
improved performance, by decomposing the design of neural network controller
into a transferable front-end network that captures building-agnostic behavior
and a back-end network that can be efficiently trained for each specific
building. We conducted experiments on a variety of transfer scenarios between
buildings with different sizes, numbers of thermal zones, materials and
layouts, air conditioner types, and ambient weather conditions. The
experimental results demonstrated the effectiveness of our approach in
significantly reducing the training time, energy cost, and temperature
violations.
</p>
<a href="http://arxiv.org/abs/2008.03625" target="_blank">arXiv:2008.03625</a> [<a href="http://arxiv.org/pdf/2008.03625" target="_blank">pdf</a>]

<h2>A Self-supervised GAN for Unsupervised Few-shot Object Recognition. (arXiv:2008.06982v2 [cs.CV] UPDATED)</h2>
<h3>Khoi Nguyen, Sinisa Todorovic</h3>
<p>This paper addresses unsupervised few-shot object recognition, where all
training images are unlabeled, and test images are divided into queries and a
few labeled support images per object class of interest. The training and test
images do not share object classes. We extend the vanilla GAN with two loss
functions, both aimed at self-supervised learning. The first is a
reconstruction loss that enforces the discriminator to reconstruct the
probabilistically sampled latent code which has been used for generating the
"fake" image. The second is a triplet loss that enforces the discriminator to
output image encodings that are closer for more similar images. Evaluation,
comparisons, and detailed ablation studies are done in the context of few-shot
classification. Our approach significantly outperforms the state of the art on
the Mini-Imagenet and Tiered-Imagenet datasets.
</p>
<a href="http://arxiv.org/abs/2008.06982" target="_blank">arXiv:2008.06982</a> [<a href="http://arxiv.org/pdf/2008.06982" target="_blank">pdf</a>]

<h2>FIRM: An Intelligent Fine-Grained Resource Management Framework for SLO-Oriented Microservices. (arXiv:2008.08509v2 [cs.DC] UPDATED)</h2>
<h3>Haoran Qiu, Subho S. Banerjee, Saurabh Jha, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer</h3>
<p>Modern user-facing latency-sensitive web services include numerous
distributed, intercommunicating microservices that promise to simplify software
development and operation. However, multiplexing of compute resources across
microservices is still challenging in production because contention for shared
resources can cause latency spikes that violate the service-level objectives
(SLOs) of user requests. This paper presents FIRM, an intelligent fine-grained
resource management framework for predictable sharing of resources across
microservices to drive up overall utilization. FIRM leverages online telemetry
data and machine-learning methods to adaptively (a) detect/localize
microservices that cause SLO violations, (b) identify low-level resources in
contention, and (c) take actions to mitigate SLO violations via dynamic
reprovisioning. Experiments across four microservice benchmarks demonstrate
that FIRM reduces SLO violations by up to 16x while reducing the overall
requested CPU limit by up to 62%. Moreover, FIRM improves performance
predictability by reducing tail latencies by up to 11x.
</p>
<a href="http://arxiv.org/abs/2008.08509" target="_blank">arXiv:2008.08509</a> [<a href="http://arxiv.org/pdf/2008.08509" target="_blank">pdf</a>]

<h2>Reputation-driven Decision-making in Networks of Stochastic Agents. (arXiv:2008.11791v2 [cs.AI] UPDATED)</h2>
<h3>David Maoujoud, Gavin Rens</h3>
<p>This paper studies multi-agent systems that involve networks of
self-interested agents. We propose a Markov Decision Process-derived framework,
called RepNet-MDP, tailored to domains in which agent reputation is a key
driver of the interactions between agents. The fundamentals are based on the
principles of RepNet-POMDP, a framework developed by Rens et al. in 2018, but
addresses its mathematical inconsistencies and alleviates its intractability by
only considering fully observable environments. We furthermore use an online
learning algorithm for finding approximate solutions to RepNet-MDPs. In a
series of experiments, RepNet agents are shown to be able to adapt their own
behavior to the past behavior and reliability of the remaining agents of the
network. Finally, our work identifies a limitation of the framework in its
current formulation that prevents its agents from learning in circumstances in
which they are not a primary actor.
</p>
<a href="http://arxiv.org/abs/2008.11791" target="_blank">arXiv:2008.11791</a> [<a href="http://arxiv.org/pdf/2008.11791" target="_blank">pdf</a>]

<h2>Universal Approximation Property of Quantum Feature Map. (arXiv:2009.00298v2 [quant-ph] UPDATED)</h2>
<h3>Takahiro Goto, Quoc Hoan Tran, Kohei Nakajima</h3>
<p>Encoding classical inputs into quantum states is considered a quantum feature
map to map classical data into a quantum Hilbert space. This feature map
provides opportunities to incorporate quantum advantages into machine learning
algorithms to be performed on near-term intermediate-scale quantum computers.
While the quantum feature map has demonstrated its capability when combined
with linear classification models in some specific applications, its expressive
power from the theoretical perspective remains unknown. We prove that the
quantum feature map is a universal approximator of continuous functions under
its typical settings in many practical applications. We also study the
capability of the quantum feature map in the classification of disjoint
regions. Our work enables an important theoretical analysis to ensure that
quantum-enhanced machine learning algorithms based on quantum feature maps can
handle a broad class of machine learning tasks. In light of this, one can
design a quantum machine learning model with more powerful expressivity.
</p>
<a href="http://arxiv.org/abs/2009.00298" target="_blank">arXiv:2009.00298</a> [<a href="http://arxiv.org/pdf/2009.00298" target="_blank">pdf</a>]

<h2>Federated Learning for Breast Density Classification: A Real-World Implementation. (arXiv:2009.01871v3 [eess.IV] UPDATED)</h2>
<h3>Holger R. Roth, Ken Chang, Praveer Singh, Nir Neumark, Wenqi Li, Vikash Gupta, Sharut Gupta, Liangqiong Qu, Alvin Ihsani, Bernardo C. Bizzo, Yuhong Wen, Varun Buch, Meesam Shah, Felipe Kitamura, Matheus Mendon&#xe7;a, Vitor Lavor, Ahmed Harouni, Colin Compas, Jesse Tetreault, Prerna Dogra, Yan Cheng, Selnur Erdal, Richard White, Behrooz Hashemian, Thomas Schultz, Miao Zhang, Adam McCarthy, B. Min Yun, Elshaimaa Sharaf, Katharina V. Hoebel, Jay B. Patel, Bryan Chen, Sean Ko, Evan Leibovitz, Etta D. Pisano, Laura Coombs, Daguang Xu, Keith J. Dreyer, Ittai Dayan, Ram C. Naidu, Mona Flores, Daniel Rubin, Jayashree Kalpathy-Cramer</h3>
<p>Building robust deep learning-based models requires large quantities of
diverse training data. In this study, we investigate the use of federated
learning (FL) to build medical imaging classification models in a real-world
collaborative setting. Seven clinical institutions from across the world joined
this FL effort to train a model for breast density classification based on
Breast Imaging, Reporting &amp; Data System (BI-RADS). We show that despite
substantial differences among the datasets from all sites (mammography system,
class distribution, and data set size) and without centralizing data, we can
successfully train AI models in federation. The results show that models
trained using FL perform 6.3% on average better than their counterparts trained
on an institute's local data alone. Furthermore, we show a 45.8% relative
improvement in the models' generalizability when evaluated on the other
participating sites' testing data.
</p>
<a href="http://arxiv.org/abs/2009.01871" target="_blank">arXiv:2009.01871</a> [<a href="http://arxiv.org/pdf/2009.01871" target="_blank">pdf</a>]

<h2>Communication-efficient Decentralized Machine Learning over Heterogeneous Networks. (arXiv:2009.05766v2 [cs.DC] UPDATED)</h2>
<h3>Pan Zhou, Qian Lin, Dumitrel Loghin, Beng Chin Ooi, Yuncheng Wu, Hongfang Yu</h3>
<p>In the last few years, distributed machine learning has been usually executed
over heterogeneous networks such as a local area network within a multi-tenant
cluster or a wide area network connecting data centers and edge clusters. In
these heterogeneous networks, the link speeds among worker nodes vary
significantly, making it challenging for state-of-the-art machine learning
approaches to perform efficient training. Both centralized and decentralized
training approaches suffer from low-speed links. In this paper, we propose a
decentralized approach, namely NetMax, that enables worker nodes to communicate
via high-speed links and, thus, significantly speed up the training process.
NetMax possesses the following novel features. First, it consists of a novel
consensus algorithm that allows worker nodes to train model copies on their
local dataset asynchronously and exchange information via peer-to-peer
communication to synchronize their local copies, instead of a central master
node (i.e., parameter server). Second, each worker node selects one peer
randomly with a fine-tuned probability to exchange information per iteration.
In particular, peers with high-speed links are selected with high probability.
Third, the probabilities of selecting peers are designed to minimize the total
convergence time. Moreover, we mathematically prove the convergence of NetMax.
We evaluate NetMax on heterogeneous cluster networks and show that it achieves
speedups of 3.7X, 3.4X, and 1.9X in comparison with the state-of-the-art
decentralized training approaches Prague, Allreduce-SGD, and AD-PSGD,
respectively.
</p>
<a href="http://arxiv.org/abs/2009.05766" target="_blank">arXiv:2009.05766</a> [<a href="http://arxiv.org/pdf/2009.05766" target="_blank">pdf</a>]

<h2>AAG: Self-Supervised Representation Learning by Auxiliary Augmentation with GNT-Xent Loss. (arXiv:2009.07994v2 [cs.CV] UPDATED)</h2>
<h3>Yanlun Tu, Jianxing Feng, Yang Yang</h3>
<p>Self-supervised representation learning is an emerging research topic for its
powerful capacity in learning with unlabeled data. As a mainstream
self-supervised learning method, augmentation-based contrastive learning has
achieved great success in various computer vision tasks that lack manual
annotations. Despite current progress, the existing methods are often limited
by extra cost on memory or storage, and their performance still has large room
for improvement. Here we present a self-supervised representation learning
method, namely AAG, which is featured by an auxiliary augmentation strategy and
GNT-Xent loss. The auxiliary augmentation is able to promote the performance of
contrastive learning by increasing the diversity of images. The proposed
GNT-Xent loss enables a steady and fast training process and yields competitive
accuracy. Experiment results demonstrate the superiority of AAG to previous
state-of-the-art methods on CIFAR10, CIFAR100, and SVHN. Especially, AAG
achieves 94.5% top-1 accuracy on CIFAR10 with batch size 64, which is 0.5%
higher than the best result of SimCLR with batch size 1024.
</p>
<a href="http://arxiv.org/abs/2009.07994" target="_blank">arXiv:2009.07994</a> [<a href="http://arxiv.org/pdf/2009.07994" target="_blank">pdf</a>]

<h2>Deep N-ary Error Correcting Output Codes. (arXiv:2009.10465v2 [cs.CV] UPDATED)</h2>
<h3>Hao Zhang, Joey Tianyi Zhou, Tianying Wang, Ivor W. Tsang, Rick Siow Mong Goh</h3>
<p>Ensemble learning consistently improves the performance of multi-class
classification through aggregating a series of base classifiers. To this end,
data-independent ensemble methods like Error Correcting Output Codes (ECOC)
attract increasing attention due to its easiness of implementation and
parallelization. Specifically, traditional ECOCs and its general extension
N-ary ECOC decompose the original multi-class classification problem into a
series of independent simpler classification subproblems. Unfortunately,
integrating ECOCs, especially N-ary ECOC with deep neural networks, termed as
deep N-ary ECOC, is not straightforward and yet fully exploited in the
literature, due to the high expense of training base learners. To facilitate
the training of N-ary ECOC with deep learning base learners, we further propose
three different variants of parameter sharing architectures for deep N-ary
ECOC. To verify the generalization ability of deep N-ary ECOC, we conduct
experiments by varying the backbone with different deep neural network
architectures for both image and text classification tasks. Furthermore,
extensive ablation studies on deep N-ary ECOC show its superior performance
over other deep data-independent ensemble methods.
</p>
<a href="http://arxiv.org/abs/2009.10465" target="_blank">arXiv:2009.10465</a> [<a href="http://arxiv.org/pdf/2009.10465" target="_blank">pdf</a>]

<h2>Neural Identification for Control. (arXiv:2009.11782v2 [eess.SY] UPDATED)</h2>
<h3>Priyabrata Saha, Magnus Egerstedt, Saibal Mukhopadhyay</h3>
<p>We present a new method for learning control law that stabilizes an unknown
nonlinear dynamical system at an equilibrium point. We formulate a system
identification task in a self-supervised learning setting that jointly learns a
controller and corresponding stable closed-loop dynamics hypothesis. The
input-output behavior of the unknown dynamical system under random control
inputs is used as the supervising signal to train the neural network-based
system model and the controller. The method relies on the Lyapunov stability
theory to generate a stable closed-loop dynamics hypothesis and corresponding
control law. We demonstrate our method on various nonlinear control problems
such as n-Link pendulum balancing, pendulum on cart balancing, and wheeled
vehicle path following.
</p>
<a href="http://arxiv.org/abs/2009.11782" target="_blank">arXiv:2009.11782</a> [<a href="http://arxiv.org/pdf/2009.11782" target="_blank">pdf</a>]

<h2>Learned Fine-Tuner for Incongruous Few-Shot Learning. (arXiv:2009.13714v2 [cs.LG] UPDATED)</h2>
<h3>Pu Zhao, Sijia Liu, Parikshit Ram, Songtao Lu, Djallel Bouneffouf, Xue Lin</h3>
<p>Model-agnostic meta-learning (MAML) effectively meta-learns an initialization
of model parameters for few-shot learning where all learning problems share the
same format of model parameters -- congruous meta-learning. We extend MAML to
incongruous meta-learning where different yet related few-shot learning
problems may not share any model parameters. A Learned Fine Tuner (LFT) is used
to replace hand-designed optimizers such as SGD for the task-specific
fine-tuning. Here, MAML instead meta-learns the parameters of this LFT across
incongruous tasks leveraging the learning-to-optimize (L2O) framework such that
models fine-tuned with LFT (even from random initializations) adapt quickly to
new tasks. As novel contributions, we show that the use of LFT within MAML (i)
offers the capability to tackle few-shot learning tasks by meta-learning across
incongruous yet related problems (e.g., classification over images of different
sizes and model architectures), and (ii) can efficiently work with first-order
and derivative-free few-shot learning problems. Theoretically, we quantify the
difference between LFT (for MAML) and L2O. Empirically, we demonstrate the
effectiveness of LFT through both synthetic and real problems and a novel
application of generating universal adversarial attacks across different image
sources in the few-shot learning regime.
</p>
<a href="http://arxiv.org/abs/2009.13714" target="_blank">arXiv:2009.13714</a> [<a href="http://arxiv.org/pdf/2009.13714" target="_blank">pdf</a>]

<h2>A Review on Fact Extraction and VERification: The FEVER case. (arXiv:2010.03001v2 [cs.CL] UPDATED)</h2>
<h3>Giannis Bekoulis, Christina Papagiannopoulou, Nikos Deligiannis</h3>
<p>Fact Extraction and VERification (FEVER) is a recently introduced task which
aims to identify the veracity of a given claim based on Wikipedia documents. A
lot of methods have been proposed to address this problem which consists of the
subtasks of (i) retrieving the relevant documents (and sentences) from
Wikipedia and (ii) validating whether the information in the documents supports
or refutes a given claim. This task is essential since it can be the building
block of applications that require a deep understanding of the language such as
fake news detection and medical claim verification. In this paper, we aim to
get a better understanding of the challenges in the task by presenting the
literature in a structured and comprehensive way. In addition, we describe the
proposed methods by analyzing the technical perspectives of the different
approaches and discussing the performance results on the FEVER dataset.
</p>
<a href="http://arxiv.org/abs/2010.03001" target="_blank">arXiv:2010.03001</a> [<a href="http://arxiv.org/pdf/2010.03001" target="_blank">pdf</a>]

<h2>Decentralize the feedback infrastructure!. (arXiv:2010.03356v2 [cs.CY] UPDATED)</h2>
<h3>Pedro Garcia Lopez</h3>
<p>The decentralized architecture of Internet sparkled techno-utopian visions of
a virtual freedom space for humanity. Peer-to-peer systems, collaborative
creation (wikipedia), open source software (Linux), universal shared knowledge,
and the hopes for disintermediation contributed to this major vision.

However, the reality is bleak: centralization is reigning in the cyberspace,
with huge technological corporations controlling our data, and
re-intermediation and control are stronger than ever in the so-called "sharing"
economy. The Internet is also fragmented by countries, with many states
imposing heavy controls to information and communication services.

The XXI century will witness the major clash between centralization and
decentralization in human history. And the major struggle will be around the
communication and feedback technologies that will intermediate and govern every
interaction in our lives.

Unlike previous approaches that propose to socialize the feedback
infrastructure or to use anti-monopoly laws to break Big Tech companies, in
this article we advocate for the decentralization of the information and
communication infrastructure. And the key to this decentralization is the
creation of standards enabling interoperability between data platforms. This
will in turn produce a true disintermediation from well established
technological players and open competition to small third parties. In this
article, we sketch such a decentralized open infrastructure including
communication, sharing, matchmaking, and reputation services that can be
constructed over open source technologies and standards.
</p>
<a href="http://arxiv.org/abs/2010.03356" target="_blank">arXiv:2010.03356</a> [<a href="http://arxiv.org/pdf/2010.03356" target="_blank">pdf</a>]

<h2>An Audio-Video Deep and Transfer Learning Framework for Multimodal Emotion Recognition in the wild. (arXiv:2010.03692v2 [cs.LG] UPDATED)</h2>
<h3>Denis Dresvyanskiy, Elena Ryumina, Heysem Kaya, Maxim Markitantov, Alexey Karpov, Wolfgang Minker</h3>
<p>In this paper, we present our contribution to ABAW facial expression
challenge. We report the proposed system and the official challenge results
adhering to the challenge protocol. Using end-to-end deep learning and
benefiting from transfer learning approaches, we reached a test set challenge
performance measure of 42.10%.
</p>
<a href="http://arxiv.org/abs/2010.03692" target="_blank">arXiv:2010.03692</a> [<a href="http://arxiv.org/pdf/2010.03692" target="_blank">pdf</a>]

<h2>Leveraging Discourse Rewards for Document-Level Neural Machine Translation. (arXiv:2010.03732v2 [cs.CL] UPDATED)</h2>
<h3>Inigo Jauregi Unanue, Nazanin Esmaili, Gholamreza Haffari, Massimo Piccardi</h3>
<p>Document-level machine translation focuses on the translation of entire
documents from a source to a target language. It is widely regarded as a
challenging task since the translation of the individual sentences in the
document needs to retain aspects of the discourse at document level. However,
document-level translation models are usually not trained to explicitly ensure
discourse quality. Therefore, in this paper we propose a training approach that
explicitly optimizes two established discourse metrics, lexical cohesion (LC)
and coherence (COH), by using a reinforcement learning objective. Experiments
over four different language pairs and three translation domains have shown
that our training approach has been able to achieve more cohesive and coherent
document translations than other competitive approaches, yet without
compromising the faithfulness to the reference translation. In the case of the
Zh-En language pair, our method has achieved an improvement of 2.46 percentage
points (pp) in LC and 1.17 pp in COH over the runner-up, while at the same time
improving 0.63 pp in BLEU score and 0.47 pp in F_BERT.
</p>
<a href="http://arxiv.org/abs/2010.03732" target="_blank">arXiv:2010.03732</a> [<a href="http://arxiv.org/pdf/2010.03732" target="_blank">pdf</a>]

<h2>Learning to Evaluate Translation Beyond English: BLEURT Submissions to the WMT Metrics 2020 Shared Task. (arXiv:2010.04297v3 [cs.CL] UPDATED)</h2>
<h3>Thibault Sellam, Amy Pu, Hyung Won Chung, Sebastian Gehrmann, Qijun Tan, Markus Freitag, Dipanjan Das, Ankur P. Parikh</h3>
<p>The quality of machine translation systems has dramatically improved over the
last decade, and as a result, evaluation has become an increasingly challenging
problem. This paper describes our contribution to the WMT 2020 Metrics Shared
Task, the main benchmark for automatic evaluation of translation. We make
several submissions based on BLEURT, a previously published metric based on
transfer learning. We extend the metric beyond English and evaluate it on 14
language pairs for which fine-tuning data is available, as well as 4
"zero-shot" language pairs, for which we have no labelled examples.
Additionally, we focus on English to German and demonstrate how to combine
BLEURT's predictions with those of YiSi and use alternative reference
translations to enhance the performance. Empirical results show that the models
achieve competitive results on the WMT Metrics 2019 Shared Task, indicating
their promise for the 2020 edition.
</p>
<a href="http://arxiv.org/abs/2010.04297" target="_blank">arXiv:2010.04297</a> [<a href="http://arxiv.org/pdf/2010.04297" target="_blank">pdf</a>]

<h2>Anomaly detection of energy consumption in buildings: A review, current trends and new perspectives. (arXiv:2010.04560v3 [cs.CY] UPDATED)</h2>
<h3>Yassine Himeur, Khalida Ghanem, Abdullah Alsalemi, Faycal Bensaali, Abbes Amira</h3>
<p>Enormous amounts of data are being produced everyday by submeters and smart
sensors installed in different kinds of buildings. If leveraged properly, that
data could assist end-users, energy producers and utility companies in
detecting anomalous power consumption and understanding the causes of each
anomaly. Therefore, anomaly detection could stop a minor problem to become
widespread, costly and time-consuming issue. Moreover, this will help in better
decision-making to reduce wasted energy and promote sustainable and energy
efficiency behavior. In this regard, this paper is proposed to indepthly review
existing frameworks of anomaly detection in power consumption and provide a
critical analysis of existing solutions. Specifically, a comprehensive survey
is introduced, in which a novel taxonomy is introduced to classify existing
algorithms based on different factors adopted in their implementation, such as
the machine learning algorithm, feature extraction approach, detection level,
computing platform, application scenario and privacy preservation. To the best
of the authors' knowledge, this is the first review article that discusses the
anomaly detection in building energy consumption. Moving forward, important
findings along with domain-specific problems, difficulties and challenges that
remain unresolved are thoroughly discussed, including the absence of: (i)
precise definitions of anomalous power consumptions, (ii) annotated datasets,
(iii) unified metrics to assess the performance of existing solutions, and (iv)
platforms for reproducibility. Following, insights about current research
trends that anomaly detection technology needs to target for widespreading its
application and facilitate its implementation are described before deriving a
set of challenging future directions attracting significant research and
development attention.
</p>
<a href="http://arxiv.org/abs/2010.04560" target="_blank">arXiv:2010.04560</a> [<a href="http://arxiv.org/pdf/2010.04560" target="_blank">pdf</a>]

<h2>A Comprehensive Survey on Local Differential Privacy Toward Data Statistics and Analysis in Crowdsensing. (arXiv:2010.05253v2 [cs.CR] UPDATED)</h2>
<h3>Teng Wang, Xuefeng Zhang, Jingyu Feng, Xinyu Yang</h3>
<p>Collecting and analyzing massive data generated from smart devices have
become increasingly pervasive in crowdsensing, which are the building blocks
for data-driven decision-making. However, extensive statistics and analysis of
such data will seriously threaten the privacy of participating users. Local
differential privacy (LDP) has been proposed as an excellent and prevalent
privacy model with distributed architecture, which can provide strong privacy
guarantees for each user while collecting and analyzing data. LDP ensures that
each user's data is locally perturbed first in the client-side and then sent to
the server-side, thereby protecting data from privacy leaks on both the
client-side and server-side. This survey presents a comprehensive and
systematic overview of LDP with respect to privacy models, research tasks,
enabling mechanisms, and various applications. Specifically, we first provide a
theoretical summarization of LDP, including the LDP model, the variants of LDP,
and the basic framework of LDP algorithms. Then, we investigate and compare the
diverse LDP mechanisms for various data statistics and analysis tasks from the
perspectives of frequency estimation, mean estimation, and machine learning.
What's more, we also summarize practical LDP-based application scenarios.
Finally, we outline several future research directions under LDP.
</p>
<a href="http://arxiv.org/abs/2010.05253" target="_blank">arXiv:2010.05253</a> [<a href="http://arxiv.org/pdf/2010.05253" target="_blank">pdf</a>]

<h2>Back to the Future: Unsupervised Backprop-based Decoding for Counterfactual and Abductive Commonsense Reasoning. (arXiv:2010.05906v2 [cs.CL] UPDATED)</h2>
<h3>Lianhui Qin, Vered Shwartz, Peter West, Chandra Bhagavatula, Jena Hwang, Ronan Le Bras, Antoine Bosselut, Yejin Choi</h3>
<p>Abductive and counterfactual reasoning, core abilities of everyday human
cognition, require reasoning about what might have happened at time t, while
conditioning on multiple contexts from the relative past and future. However,
simultaneous incorporation of past and future contexts using generative
language models (LMs) can be challenging, as they are trained either to
condition only on the past context or to perform narrowly scoped
text-infilling. In this paper, we propose DeLorean, a new unsupervised decoding
algorithm that can flexibly incorporate both the past and future contexts using
only off-the-shelf, left-to-right language models and no supervision. The key
intuition of our algorithm is incorporating the future through
back-propagation, during which, we only update the internal representation of
the output while fixing the model parameters. By alternating between forward
and backward propagation, DeLorean can decode the output representation that
reflects both the left and right contexts. We demonstrate that our approach is
general and applicable to two nonmonotonic reasoning tasks: abductive text
generation and counterfactual story revision, where DeLorean outperforms a
range of unsupervised and some supervised methods, based on automatic and human
evaluation.
</p>
<a href="http://arxiv.org/abs/2010.05906" target="_blank">arXiv:2010.05906</a> [<a href="http://arxiv.org/pdf/2010.05906" target="_blank">pdf</a>]

<h2>Direct Federated Neural Architecture Search. (arXiv:2010.06223v3 [cs.LG] UPDATED)</h2>
<h3>Anubhav Garg, Amit Kumar Saha, Debo Dutta</h3>
<p>Neural Architecture Search (NAS) is a collection of methods to craft the way
neural networks are built. We apply this idea to Federated Learning (FL),
wherein predefined neural network models are trained on the client/device data.
This approach is not optimal as the model developers can't observe the local
data, and hence, are unable to build highly accurate and efficient models. NAS
is promising for FL which can search for global and personalized models
automatically for the non-IID data. Most NAS methods are computationally
expensive and require fine-tuning after the search, making it a two-stage
complex process with possible human intervention. Thus there is a need for
end-to-end NAS which can run on the heterogeneous data and resource
distribution typically seen in the FL scenario. In this paper, we present an
effective approach for direct federated NAS which is hardware agnostic,
computationally lightweight, and a one-stage method to search for
ready-to-deploy neural network models. Our results show an order of magnitude
reduction in resource consumption while edging out prior art in accuracy. This
opens up a window of opportunity to create optimized and computationally
efficient federated learning systems.
</p>
<a href="http://arxiv.org/abs/2010.06223" target="_blank">arXiv:2010.06223</a> [<a href="http://arxiv.org/pdf/2010.06223" target="_blank">pdf</a>]

<h2>A Generalized Zero-Shot Framework for Emotion Recognition from Body Gestures. (arXiv:2010.06362v2 [cs.CV] UPDATED)</h2>
<h3>Jinting Wu, Yujia Zhang, Xiaoguang Zhao, Wenbin Gao</h3>
<p>Although automatic emotion recognition from facial expressions and speech has
made remarkable progress, emotion recognition from body gestures has not been
thoroughly explored. People often use a variety of body language to express
emotions, and it is difficult to enumerate all emotional body gestures and
collect enough samples for each category. Therefore, recognizing new emotional
body gestures is critical for better understanding human emotions. However, the
existing methods fail to accurately determine which emotional state a new body
gesture belongs to. In order to solve this problem, we introduce a Generalized
Zero-Shot Learning (GZSL) framework, which consists of three branches to infer
the emotional state of the new body gestures with only their semantic
descriptions. The first branch is a Prototype-Based Detector (PBD) which is
used to determine whether an sample belongs to a seen body gesture category and
obtain the prediction results of the samples from the seen categories. The
second branch is a Stacked AutoEncoder (StAE) with manifold regularization,
which utilizes semantic representations to predict samples from unseen
categories. Note that both of the above branches are for body gesture
recognition. We further add an emotion classifier with a softmax layer as the
third branch in order to better learn the feature representations for this
emotion classification task. The input features for these three branches are
learned by a shared feature extraction network, i.e., a Bidirectional Long
Short-Term Memory Networks (BLSTM) with a self-attention module. We treat these
three branches as subtasks and use multi-task learning strategies for joint
training. The performance of our framework on an emotion recognition dataset is
significantly superior to the traditional method of emotion classification and
state-of-the-art zero-shot learning methods.
</p>
<a href="http://arxiv.org/abs/2010.06362" target="_blank">arXiv:2010.06362</a> [<a href="http://arxiv.org/pdf/2010.06362" target="_blank">pdf</a>]

<h2>Learned Greedy Method (LGM): A Novel Neural Architecture for Sparse Coding and Beyond. (arXiv:2010.07069v2 [cs.LG] UPDATED)</h2>
<h3>Rajaei Khatib, Dror Simon, Michael Elad</h3>
<p>The fields of signal and image processing have been deeply influenced by the
introduction of deep neural networks. These are successfully deployed in a wide
range of real-world applications, obtaining state of the art results and
surpassing well-known and well-established classical methods. Despite their
impressive success, the architectures used in many of these neural networks
come with no clear justification. As such, these are usually treated as "black
box" machines that lack any kind of interpretability. A constructive remedy to
this drawback is a systematic design of such networks by unfolding
well-understood iterative algorithms. A popular representative of this approach
is the Iterative Shrinkage-Thresholding Algorithm (ISTA) and its learned
version -- LISTA, aiming for the sparse representations of the processed
signals. In this paper we revisit this sparse coding task and propose an
unfolded version of a greedy pursuit algorithm for the same goal. More
specifically, we concentrate on the well-known Orthogonal-Matching-Pursuit
(OMP) algorithm, and introduce its unfolded and learned version. Key features
of our Learned Greedy Method (LGM) are the ability to accommodate a dynamic
number of unfolded layers, and a stopping mechanism based on representation
error, both adapted to the input. We develop several variants of the proposed
LGM architecture and test some of them in various experiments, demonstrating
their flexibility and efficiency.
</p>
<a href="http://arxiv.org/abs/2010.07069" target="_blank">arXiv:2010.07069</a> [<a href="http://arxiv.org/pdf/2010.07069" target="_blank">pdf</a>]

<h2>Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach. (arXiv:2010.07835v2 [cs.CL] UPDATED)</h2>
<h3>Yue Yu, Simiao Zuo, Haoming Jiang, Wendi Ren, Tuo Zhao, Chao Zhang</h3>
<p>Fine-tuned pre-trained language models (LMs) achieve enormous success in many
natural language processing (NLP) tasks, but they still require excessive
labeled data in the fine-tuning stage. We study the problem of fine-tuning
pre-trained LMs using only weak supervision, without any labeled data. This
problem is challenging because the high capacity of LMs makes them prone to
overfitting the noisy labels generated by weak supervision. To address this
problem, we develop a contrastive self-training framework, COSINE, to enable
fine-tuning LMs with weak supervision. Underpinned by contrastive
regularization and confidence-based reweighting, this contrastive self-training
framework can gradually improve model fitting while effectively suppressing
error propagation. Experiments on sequence, token, and sentence pair
classification tasks show that our model outperforms the strongest baseline by
large margins on 7 benchmarks in 6 tasks, and achieves competitive performance
with fully-supervised fine-tuning methods.
</p>
<a href="http://arxiv.org/abs/2010.07835" target="_blank">arXiv:2010.07835</a> [<a href="http://arxiv.org/pdf/2010.07835" target="_blank">pdf</a>]

<h2>Adaptive Feature Selection for End-to-End Speech Translation. (arXiv:2010.08518v2 [cs.CL] UPDATED)</h2>
<h3>Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich</h3>
<p>Information in speech signals is not evenly distributed, making it an
additional challenge for end-to-end (E2E) speech translation (ST) to learn to
focus on informative features. In this paper, we propose adaptive feature
selection (AFS) for encoder-decoder based E2E ST. We first pre-train an ASR
encoder and apply AFS to dynamically estimate the importance of each encoded
speech feature to SR. A ST encoder, stacked on top of the ASR encoder, then
receives the filtered features from the (frozen) ASR encoder. We take L0DROP
(Zhang et al., 2020) as the backbone for AFS, and adapt it to sparsify speech
features with respect to both temporal and feature dimensions. Results on
LibriSpeech En-Fr and MuST-C benchmarks show that AFS facilitates learning of
ST by pruning out ~84% temporal features, yielding an average translation gain
of ~1.3-1.6 BLEU and a decoding speedup of ~1.4x. In particular, AFS reduces
the performance gap compared to the cascade baseline, and outperforms it on
LibriSpeech En-Fr with a BLEU score of 18.56 (without data augmentation)
</p>
<a href="http://arxiv.org/abs/2010.08518" target="_blank">arXiv:2010.08518</a> [<a href="http://arxiv.org/pdf/2010.08518" target="_blank">pdf</a>]

<h2>Learning a Continuous Representation of 3D Molecular Structures with Deep Generative Models. (arXiv:2010.08687v2 [q-bio.QM] UPDATED)</h2>
<h3>Matthew Ragoza, Tomohide Masuda, David Ryan Koes</h3>
<p>Machine learning methods in drug discovery have primarily focused on virtual
screening of molecular libraries using discriminative models. Generative models
are an entirely different approach to drug discovery that learn to represent
and optimize molecules in a continuous latent space. These methods have already
been applied with increasing success to the generation of two dimensional
molecules as SMILES strings and molecular graphs. In this work, we describe
deep generative models for three dimensional molecular structures using atomic
density grids and a novel fitting algorithm that converts continuous grids to
discrete molecular structures. Our models jointly represent drug-like molecules
and their conformations in a latent space that can be explored through
interpolation. We are able to sample diverse sets of molecules based on a given
input compound and increase the probability of creating a valid, drug-like
molecule.
</p>
<a href="http://arxiv.org/abs/2010.08687" target="_blank">arXiv:2010.08687</a> [<a href="http://arxiv.org/pdf/2010.08687" target="_blank">pdf</a>]

<h2>Belief-Grounded Networks for Accelerated Robot Learning under Partial Observability. (arXiv:2010.09170v2 [cs.RO] UPDATED)</h2>
<h3>Hai Nguyen, Brett Daley, Xinchao Song, Chistopher Amato, Robert Platt</h3>
<p>Many important robotics problems are partially observable in the sense that a
single visual or force-feedback measurement is insufficient to reconstruct the
state. Standard approaches involve learning a policy over beliefs or
observation-action histories. However, both of these have drawbacks; it is
expensive to track the belief online, and it is hard to learn policies directly
over histories. We propose a method for policy learning under partial
observability called the Belief-Grounded Network (BGN) in which an auxiliary
belief-reconstruction loss incentivizes a neural network to concisely summarize
its input history. Since the resulting policy is a function of the history
rather than the belief, it can be executed easily at runtime. We compare BGN
against several baselines on classic benchmark tasks as well as three novel
robotic touch-sensing tasks. BGN outperforms all other tested methods and its
learned policies work well when transferred onto a physical robot.
</p>
<a href="http://arxiv.org/abs/2010.09170" target="_blank">arXiv:2010.09170</a> [<a href="http://arxiv.org/pdf/2010.09170" target="_blank">pdf</a>]

<h2>DBA bandits: Self-driving index tuning under ad-hoc, analytical workloads with safety guarantees. (arXiv:2010.09208v2 [cs.DB] UPDATED)</h2>
<h3>R. Malinga Perera, Bastian Oetomo, Benjamin I. P. Rubinstein, Renata Borovica-Gajic</h3>
<p>Automating physical database design has remained a long-term interest in
database research due to substantial performance gains afforded by optimised
structures. Despite significant progress, a majority of today's commercial
solutions are highly manual, requiring offline invocation by database
administrators (DBAs) who are expected to identify and supply representative
training workloads. Unfortunately, the latest advancements like query stores
provide only limited support for dynamic environments. This status quo is
untenable: identifying representative static workloads is no longer realistic;
and physical design tools remain susceptible to the query optimiser's cost
misestimates (stemming from unrealistic assumptions such as attribute value
independence and uniformity of data distribution). We propose a self-driving
approach to online index selection that eschews the DBA and query optimiser,
and instead learns the benefits of viable structures through strategic
exploration and direct performance observation. We view the problem as one of
sequential decision making under uncertainty, specifically within the bandit
learning setting. Multi-armed bandits balance exploration and exploitation to
provably guarantee average performance that converges to a fixed policy that is
optimal with perfect hindsight. Our comprehensive empirical results demonstrate
up to 75% speed-up on shifting and ad-hoc workloads and 28% speed-up on static
workloads compared against a state-of-the-art commercial tuning tool.
</p>
<a href="http://arxiv.org/abs/2010.09208" target="_blank">arXiv:2010.09208</a> [<a href="http://arxiv.org/pdf/2010.09208" target="_blank">pdf</a>]

<h2>Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems. (arXiv:2010.09301v2 [cs.LG] UPDATED)</h2>
<h3>Anh Tong, Jaesik Choi</h3>
<p>Recent advances in Deep Gaussian Processes (DGPs) show the potential to have
more expressive representation than that of traditional Gaussian Processes
(GPs). However, there exists a pathology of deep Gaussian processes that their
learning capacities reduce significantly when the number of layers increases.
In this paper, we present a new analysis in DGPs by studying its corresponding
nonlinear dynamic systems to explain the issue. Existing work reports the
pathology for the squared exponential kernel function. We extend our
investigation to four types of common stationary kernel functions. The
recurrence relations between layers are analytically derived, providing a
tighter bound and the rate of convergence of the dynamic systems. We
demonstrate our finding with a number of experimental results.
</p>
<a href="http://arxiv.org/abs/2010.09301" target="_blank">arXiv:2010.09301</a> [<a href="http://arxiv.org/pdf/2010.09301" target="_blank">pdf</a>]

<h2>A Two-stage Unsupervised Approach for Low light Image Enhancement. (arXiv:2010.09316v2 [cs.CV] UPDATED)</h2>
<h3>Junjie Hu, Xiyue Guo, Junfeng Chen, Guanqi Liang, Fuqin Deng, Tin lun Lam</h3>
<p>As vision based perception methods are usually built on the normal light
assumption, there will be a serious safety issue when deploying them into low
light environments. Recently, deep learning based methods have been proposed to
enhance low light images by penalizing the pixel-wise loss of low light and
normal light images. However, most of them suffer from the following problems:
1) the need of pairs of low light and normal light images for training, 2) the
poor performance for dark images, 3) the amplification of noise. To alleviate
these problems, in this paper, we propose a two-stage unsupervised method that
decomposes the low light image enhancement into a pre-enhancement and a
post-refinement problem. In the first stage, we pre-enhance a low light image
with a conventional Retinex based method. In the second stage, we use a
refinement network learned with adversarial training for further improvement of
the image quality. The experimental results show that our method outperforms
previous methods on four benchmark datasets. In addition, we show that our
method can significantly improve feature points matching and simultaneous
localization and mapping in low light conditions.
</p>
<a href="http://arxiv.org/abs/2010.09316" target="_blank">arXiv:2010.09316</a> [<a href="http://arxiv.org/pdf/2010.09316" target="_blank">pdf</a>]

<h2>Probabilistic selection of inducing points in sparse Gaussian processes. (arXiv:2010.09370v2 [cs.LG] UPDATED)</h2>
<h3>Anders Kirk Uhrenholt, Valentin Charvet, Bj&#xf8;rn Sand Jensen</h3>
<p>Sparse Gaussian processes and various extensions thereof are enabled through
inducing points, that simultaneously bottleneck the predictive capacity and act
as the main contributor towards model complexity. However, the number of
inducing points is generally not associated with uncertainty which prevents us
from applying the apparatus of Bayesian reasoning in identifying an appropriate
trade-off. In this work we place a point process prior on the inducing points
and approximate the associated posterior through stochastic variational
inference. By letting the prior encourage a moderate number of inducing points,
we enable the model to learn which and how many points to utilise. We
experimentally show that fewer inducing points are preferred by the model as
the points become less informative, and further demonstrate how the method can
be applied in deep Gaussian processes and latent variable modelling.
</p>
<a href="http://arxiv.org/abs/2010.09370" target="_blank">arXiv:2010.09370</a> [<a href="http://arxiv.org/pdf/2010.09370" target="_blank">pdf</a>]

<h2>Teacher-Student Competition for Unsupervised Domain Adaptation. (arXiv:2010.09572v2 [cs.CV] UPDATED)</h2>
<h3>Ruixin Xiao, Zhilei Liu, Baoyuan Wu</h3>
<p>With the supervision from source domain only in class-level, existing
unsupervised domain adaptation (UDA) methods mainly learn the domain-invariant
representations from a shared feature extractor, which causes the source-bias
problem. This paper proposes an unsupervised domain adaptation approach with
Teacher-Student Competition (TSC). In particular, a student network is
introduced to learn the target-specific feature space, and we design a novel
competition mechanism to select more credible pseudo-labels for the training of
student network. We introduce a teacher network with the structure of existing
conventional UDA method, and both teacher and student networks compete to
provide target pseudo-labels to constrain every target sample's training in
student network. Extensive experiments demonstrate that our proposed TSC
framework significantly outperforms the state-of-the-art domain adaptation
methods on Office-31 and ImageCLEF-DA benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.09572" target="_blank">arXiv:2010.09572</a> [<a href="http://arxiv.org/pdf/2010.09572" target="_blank">pdf</a>]

<h2>Multi-Stage Fusion for One-Click Segmentation. (arXiv:2010.09672v2 [cs.CV] UPDATED)</h2>
<h3>Soumajit Majumder, Ansh Khurana, Abhinav Rai, Angela Yao</h3>
<p>Segmenting objects of interest in an image is an essential building block of
applications such as photo-editing and image analysis. Under interactive
settings, one should achieve good segmentations while minimizing user input.
Current deep learning-based interactive segmentation approaches use early
fusion and incorporate user cues at the image input layer. Since segmentation
CNNs have many layers, early fusion may weaken the influence of user
interactions on the final prediction results. As such, we propose a new
multi-stage guidance framework for interactive segmentation. By incorporating
user cues at different stages of the network, we allow user interactions to
impact the final segmentation output in a more direct way. Our proposed
framework has a negligible increase in parameter count compared to early-fusion
frameworks. We perform extensive experimentation on the standard interactive
instance segmentation and one-click segmentation benchmarks and report
state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2010.09672" target="_blank">arXiv:2010.09672</a> [<a href="http://arxiv.org/pdf/2010.09672" target="_blank">pdf</a>]

<h2>An Introduction to Electrocatalyst Design using Machine Learning for Renewable Energy Storage. (arXiv:2010.09435v1 [cond-mat.mtrl-sci] CROSS LISTED)</h2>
<h3>C. Lawrence Zitnick, Lowik Chanussot, Abhishek Das, Siddharth Goyal, Javier Heras-Domingo, Caleb Ho, Weihua Hu, Thibaut Lavril, Aini Palizhati, Morgane Riviere, Muhammed Shuaibi, Anuroop Sriram, Kevin Tran, Brandon Wood, Junwoong Yoon, Devi Parikh, Zachary Ulissi</h3>
<p>Scalable and cost-effective solutions to renewable energy storage are
essential to addressing the world's rising energy needs while reducing climate
change. As we increase our reliance on renewable energy sources such as wind
and solar, which produce intermittent power, storage is needed to transfer
power from times of peak generation to peak demand. This may require the
storage of power for hours, days, or months. One solution that offers the
potential of scaling to nation-sized grids is the conversion of renewable
energy to other fuels, such as hydrogen or methane. To be widely adopted, this
process requires cost-effective solutions to running electrochemical reactions.
An open challenge is finding low-cost electrocatalysts to drive these reactions
at high rates. Through the use of quantum mechanical simulations (density
functional theory), new catalyst structures can be tested and evaluated.
Unfortunately, the high computational cost of these simulations limits the
number of structures that may be tested. The use of machine learning may
provide a method to efficiently approximate these calculations, leading to new
approaches in finding effective electrocatalysts. In this paper, we provide an
introduction to the challenges in finding suitable electrocatalysts, how
machine learning may be applied to the problem, and the use of the Open
Catalyst Project OC20 dataset for model training.
</p>
<a href="http://arxiv.org/abs/2010.09435" target="_blank">arXiv:2010.09435</a> [<a href="http://arxiv.org/pdf/2010.09435" target="_blank">pdf</a>]

<h2>Dynamical Landscape and Multistability of the Earth's Climate. (arXiv:2010.10374v1 [physics.ao-ph])</h2>
<h3>Georgios Margazoglou, Tobias Grafke, Alessandro Laio, Valerio Lucarini</h3>
<p>We apply two independent data analysis methodologies to locate stable climate
states in an intermediate complexity climate model. First, drawing from the
theory of quasipotentials, and viewing the state space as an energy landscape
with valleys and mountain ridges, we infer the relative likelihood of the
identified multistable climate states, and investigate the most likely
transition trajectories as well as the expected transition times between them.
Second, harnessing techniques from data science, specifically manifold
learning, we characterize the data landscape of the simulation data to find
climate states and basin boundaries within a fully agnostic and unsupervised
framework. Both approaches show remarkable agreement, and reveal, apart from
the well known warm and snowball earth states, a third intermediate stable
state in one of the two climate models we consider. The combination of our
approaches allows to identify how the negative feedback of ocean heat transport
and entropy production via the hydrological cycle drastically change the
topography of the dynamical landscape of Earth's climate.
</p>
<a href="http://arxiv.org/abs/2010.10374" target="_blank">arXiv:2010.10374</a> [<a href="http://arxiv.org/pdf/2010.10374" target="_blank">pdf</a>]

<h2>Distributed Learning of Finite Gaussian Mixtures. (arXiv:2010.10412v1 [stat.ME])</h2>
<h3>Qiong Zhang, Jiahua Chen</h3>
<p>Advances in information technology have led to extremely large datasets that
are often kept in different storage centers. Existing statistical methods must
be adapted to overcome the resulting computational obstacles while retaining
statistical validity and efficiency. Split-and-conquer approaches have been
applied in many areas, including quantile processes, regression analysis,
principal eigenspaces, and exponential families. We study split-and-conquer
approaches for the distributed learning of finite Gaussian mixtures. We
recommend a reduction strategy and develop an effective MM algorithm. The new
estimator is shown to be consistent and retains root-n consistency under some
general conditions. Experiments based on simulated and real-world data show
that the proposed split-and-conquer approach has comparable statistical
performance with the global estimator based on the full dataset, if the latter
is feasible. It can even slightly outperform the global estimator if the model
assumption does not match the real-world data. It also has better statistical
and computational performance than some existing methods.
</p>
<a href="http://arxiv.org/abs/2010.10412" target="_blank">arXiv:2010.10412</a> [<a href="http://arxiv.org/pdf/2010.10412" target="_blank">pdf</a>]

<h2>Robust variable selection in the framework of classification with label noise and outliers: applications to spectroscopic data in agri-food. (arXiv:2010.10415v1 [stat.AP])</h2>
<h3>Andrea Cappozzo, Ludovic Duponchel, Francesca Greselin, Thomas Brendan Murphy</h3>
<p>Classification of high-dimensional spectroscopic data is a common task in
analytical chemistry. Well-established procedures like support vector machines
(SVMs) and partial least squares discriminant analysis (PLS-DA) are the most
common methods for tackling this supervised learning problem. Nonetheless,
interpretation of these models remains sometimes difficult, and solutions based
on wavelength selection are often preferred as they lead to clearer
chemometrics interpretation. Unfortunately, for some delicate applications like
food authenticity, mislabeled and adulterated spectra occur both in the
calibration and/or validation sets, with dramatic effects on the model
development, its prediction accuracy and robustness. Motivated by these issues,
we propose to employ a robust model-based method for jointly performing
variable selection and label noise detection. We demonstrate the effectiveness
of our proposal in dealing with three agri-food spectroscopic studies, where
several forms of perturbations are considered. Our approach succeeds in
diminishing problem complexity, identifying anomalous spectra and attaining
competitive predictive accuracy considering a very low number of selected
wavelengths.
</p>
<a href="http://arxiv.org/abs/2010.10415" target="_blank">arXiv:2010.10415</a> [<a href="http://arxiv.org/pdf/2010.10415" target="_blank">pdf</a>]

<h2>Experimental Evaluation of Individualized Treatment Rules. (arXiv:1905.05389v4 [stat.AP] UPDATED)</h2>
<h3>Kosuke Imai, Michael Lingzhi Li</h3>
<p>In recent years, the increasing availability of individual-level data has led
to numerous applications of individualized (or personalized) treatment rules
(ITRs). Policy makers often wish to empirically evaluate ITRs and compare their
relative performance before implementing them in a target population. We
propose a new evaluation metric, the population average prescriptive effect
(PAPE). The PAPE compares the performance of ITR with that of
non-individualized treatment rule, which randomly treats the same proportion of
units. Averaging the PAPE over a range of budget constraints yields our second
evaluation metric, the area under the prescriptive effect curve (AUPEC). The
AUPEC represents an overall performance measure for evaluation, like the area
under the receiver and operating characteristic curve (AUROC) does for
classification.

We use the Neyman's repeated sampling framework to estimate the PAPE and
AUPEC and derive their exact finite-sample variances based on random sampling
of units and random assignment of treatment. We also extend our analytical
framework to a common evaluation setting, in which the same experimental data
is used to both estimate and evaluate ITRs. In this case, our variance
calculation incorporates the additional uncertainty due to random splits of
data used for cross-validation. Unlike some of the existing methods, the
proposed methodology does not require modeling assumptions, asymptotic
approximation, or resampling method. As a result, it is applicable to any ITR
including those based on complex machine learning algorithms. The open-source
software package is available for implementing the proposed methodology.
</p>
<a href="http://arxiv.org/abs/1905.05389" target="_blank">arXiv:1905.05389</a> [<a href="http://arxiv.org/pdf/1905.05389" target="_blank">pdf</a>]

<h2>Bayesian Group Learning for Shot Selection of Professional Basketball Players. (arXiv:2006.07513v3 [stat.AP] UPDATED)</h2>
<h3>Guanyu Hu, Hou-Cheng Yang, Yishu Xue</h3>
<p>In this paper, we develop a group learning approach to analyze the underlying
heterogeneity structure of shot selection among professional basketball players
in the NBA. We propose a mixture of finite mixtures (MFM) model to capture the
heterogeneity of shot selection among different players based on Log Gaussian
Cox process (LGCP). Our proposed method can simultaneously estimate the number
of groups and group configurations. An efficient Markov Chain Monte Carlo
(MCMC) algorithm is developed for our proposed model. Simulation studies have
been conducted to demonstrate its performance. Ultimately, our proposed
learning approach is further illustrated in analyzing shot charts of several
players in the NBA's 2017-2018 regular season.
</p>
<a href="http://arxiv.org/abs/2006.07513" target="_blank">arXiv:2006.07513</a> [<a href="http://arxiv.org/pdf/2006.07513" target="_blank">pdf</a>]

