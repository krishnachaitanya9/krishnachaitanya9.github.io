---
title: Latest Deep Learning Papers
date: 2020-12-24 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (138 Articles)</h1>
<h2>Learning by Self-Explanation, with Application to Neural Architecture Search. (arXiv:2012.12899v1 [cs.LG])</h2>
<h3>Ramtin Hosseini, Pengtao Xie</h3>
<p>Learning by self-explanation, where students explain a learned topic to
themselves for deepening their understanding of this topic, is a broadly used
methodology in human learning and shows great effectiveness in improving
learning outcome. We are interested in investigating whether this powerful
learning technique can be borrowed from humans to improve the learning
abilities of machines. We propose a novel learning approach called learning by
self-explanation (LeaSE). In our approach, an explainer model improves its
learning ability by trying to clearly explain to an audience model regarding
how a prediction outcome is made. We propose a multi-level optimization
framework to formulate LeaSE which involves four stages of learning: explainer
learns; explainer explains; audience learns; explainer and audience validate
themselves. We develop an efficient algorithm to solve the LeaSE problem. We
apply our approach to neural architecture search on CIFAR-100, CIFAR-10, and
ImageNet. The results demonstrate the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2012.12899" target="_blank">arXiv:2012.12899</a> [<a href="http://arxiv.org/pdf/2012.12899" target="_blank">pdf</a>]

<h2>On Using Classification Datasets to Evaluate Graph Outlier Detection: Peculiar Observations and New Insights. (arXiv:2012.12931v1 [cs.LG])</h2>
<h3>Lingxiao Zhao, Leman Akoglu</h3>
<p>It is common practice of the outlier mining community to repurpose
classification datasets toward evaluating various detection models. To that
end, often a binary classification dataset is used, where samples from
(typically, the larger) one of the classes is designated as the inlier samples,
and the other class is substantially down-sampled to create the (ground-truth)
outlier samples. In this study, we identify an intriguing issue with
repurposing graph classification datasets for graph outlier detection in this
manner. Surprisingly, the detection performance of outlier models depends
significantly on which class is down-sampled; put differently, accuracy often
flips from high to low depending on which of the classes is down-sampled to
represent the outlier samples. The problem is notably exacerbated particularly
for a certain family of propagation based outlier detection models. Through
careful analysis, we show that this issue mainly stems from disparate
within-class sample similarity - which is amplified by various propagation
based models - that impacts key characteristics of inlier/outlier distributions
and indirectly, the difficulty of the outlier detection task and hence
performance outcomes. With this study, we aim to draw attention to this (to our
knowledge) previously-unnoticed issue, as it has implications for fair and
effective evaluation of detection models, and hope that it will motivate the
design of better evaluation benchmarks for outlier detection. Finally, we
discuss the possibly overarching implications of using propagation based models
on datasets with disparate within-class sample similarity beyond outlier
detection, specifically for graph classification and graph-level clustering
tasks.
</p>
<a href="http://arxiv.org/abs/2012.12931" target="_blank">arXiv:2012.12931</a> [<a href="http://arxiv.org/pdf/2012.12931" target="_blank">pdf</a>]

<h2>Active Deep Learning on Entity Resolution by Risk Sampling. (arXiv:2012.12960v1 [cs.LG])</h2>
<h3>Youcef Nafa, Qun Chen, Zhaoqiang Chen, Xingyu Lu, Haiyang He, Tianyi Duan, Zhanhuai Li</h3>
<p>While the state-of-the-art performance on entity resolution (ER) has been
achieved by deep learning, its effectiveness depends on large quantities of
accurately labeled training data. To alleviate the data labeling burden, Active
Learning (AL) presents itself as a feasible solution that focuses on data
deemed useful for model training. Building upon the recent advances in risk
analysis for ER, which can provide a more refined estimate on label
misprediction risk than the simpler classifier outputs, we propose a novel AL
approach of risk sampling for ER. Risk sampling leverages misprediction risk
estimation for active instance selection. Based on the core-set
characterization for AL, we theoretically derive an optimization model which
aims to minimize core-set loss with non-uniform Lipschitz continuity. Since the
defined weighted K-medoids problem is NP-hard, we then present an efficient
heuristic algorithm. Finally, we empirically verify the efficacy of the
proposed approach on real data by a comparative study. Our extensive
experiments have shown that it outperforms the existing alternatives by
considerable margins. Using ER as a test case, we demonstrate that risk
sampling is a promising approach potentially applicable to other challenging
classification tasks.
</p>
<a href="http://arxiv.org/abs/2012.12960" target="_blank">arXiv:2012.12960</a> [<a href="http://arxiv.org/pdf/2012.12960" target="_blank">pdf</a>]

<h2>Detecting Hate Speech in Memes Using Multimodal Deep Learning Approaches: Prize-winning solution to Hateful Memes Challenge. (arXiv:2012.12975v1 [cs.AI])</h2>
<h3>Riza Velioglu, Jewgeni Rose</h3>
<p>Memes on the Internet are often harmless and sometimes amusing. However, by
using certain types of images, text, or combinations of both, the seemingly
harmless meme becomes a multimodal type of hate speech -- a hateful meme. The
Hateful Memes Challenge is a first-of-its-kind competition which focuses on
detecting hate speech in multimodal memes and it proposes a new data set
containing 10,000+ new examples of multimodal content. We utilize VisualBERT --
which meant to be the BERT of vision and language -- that was trained
multimodally on images and captions and apply Ensemble Learning. Our approach
achieves 0.811 AUROC with an accuracy of 0.765 on the challenge test set and
placed third out of 3,173 participants in the Hateful Memes Challenge.
</p>
<a href="http://arxiv.org/abs/2012.12975" target="_blank">arXiv:2012.12975</a> [<a href="http://arxiv.org/pdf/2012.12975" target="_blank">pdf</a>]

<h2>Awareness Logic: A Kripke-based Rendition of the Heifetz-Meier-Schipper Model. (arXiv:2012.12982v1 [cs.AI])</h2>
<h3>Gaia Belardinelli, Rasmus K. Rendsvig</h3>
<p>Heifetz, Meier and Schipper (HMS) present a lattice model of awareness. The
HMS model is syntax-free, which precludes the simple option to rely on formal
language to induce lattices, and represents uncertainty and unawareness with
one entangled construct, making it difficult to assess the properties of
either. Here, we present a model based on a lattice of Kripke models, induced
by atom subset inclusion, in which uncertainty and unawareness are separate. We
show the models to be equivalent by defining transformations between them which
preserve formula satisfaction, and obtain completeness through our and HMS'
results.
</p>
<a href="http://arxiv.org/abs/2012.12982" target="_blank">arXiv:2012.12982</a> [<a href="http://arxiv.org/pdf/2012.12982" target="_blank">pdf</a>]

<h2>Convolutional Neural Network for Elderly Wandering Prediction in Indoor Scenarios. (arXiv:2012.12987v1 [cs.CV])</h2>
<h3>Rafael F. C. Oliveira, Fabio Barreto, Raphael Abreu</h3>
<p>This work proposes a way to detect the wandering activity of Alzheimer's
patients from path data collected from non-intrusive indoor sensors around the
house. Due to the lack of adequate data, we've manually generated a dataset of
220 paths using our own developed application. Wandering patterns in the
literature are normally identified by visual features (such as loops or random
movement), thus our dataset was transformed into images and augmented.
Convolutional layers were used on the neural network model since they tend to
have good results finding patterns, especially on images. The Convolutional
Neural Network model was trained with the generated data and achieved an f1
score (relation between precision and recall) of 75%, recall of 60%, and
precision of 100% on our 10 sample validation slice
</p>
<a href="http://arxiv.org/abs/2012.12987" target="_blank">arXiv:2012.12987</a> [<a href="http://arxiv.org/pdf/2012.12987" target="_blank">pdf</a>]

<h2>SyNet: An Ensemble Network for Object Detection in UAV Images. (arXiv:2012.12991v1 [cs.CV])</h2>
<h3>Berat Mert Albaba, Sedat Ozer</h3>
<p>Recent advances in camera equipped drone applications and their widespread
use increased the demand on vision based object detection algorithms for aerial
images. Object detection process is inherently a challenging task as a generic
computer vision problem, however, since the use of object detection algorithms
on UAVs (or on drones) is relatively a new area, it remains as a more
challenging problem to detect objects in aerial images. There are several
reasons for that including: (i) the lack of large drone datasets including
large object variance, (ii) the large orientation and scale variance in drone
images when compared to the ground images, and (iii) the difference in texture
and shape features between the ground and the aerial images. Deep learning
based object detection algorithms can be classified under two main categories:
(a) single-stage detectors and (b) multi-stage detectors. Both single-stage and
multi-stage solutions have their advantages and disadvantages over each other.
However, a technique to combine the good sides of each of those solutions could
yield even a stronger solution than each of those solutions individually. In
this paper, we propose an ensemble network, SyNet, that combines a multi-stage
method with a single-stage one with the motivation of decreasing the high false
negative rate of multi-stage detectors and increasing the quality of the
single-stage detector proposals. As building blocks, CenterNet and Cascade
R-CNN with pretrained feature extractors are utilized along with an ensembling
strategy. We report the state of the art results obtained by our proposed
solution on two different datasets: namely MS-COCO and visDrone with \%52.1
$mAP_{IoU = 0.75}$ is obtained on MS-COCO $val2017$ dataset and \%26.2
$mAP_{IoU = 0.75}$ is obtained on VisDrone $test-set$.
</p>
<a href="http://arxiv.org/abs/2012.12991" target="_blank">arXiv:2012.12991</a> [<a href="http://arxiv.org/pdf/2012.12991" target="_blank">pdf</a>]

<h2>Using vis-NIRS and Machine Learning methods to diagnose sugarcane soil chemical properties. (arXiv:2012.12995v1 [cs.LG])</h2>
<h3>Diego A. Delgadillo-Duran, Cesar A. Vargas-Garc&#xed;a, Viviana M. Var&#xf3;n-Ram&#xed;rez, Francisco Calder&#xf3;n, Andrea C. Montenegro, Paula H. Reyes-Herrera</h3>
<p>Knowing chemical soil properties might be determinant in crop management and
total yield production. Traditional property estimation approaches are
time-consuming and require complex lab setups, refraining farmers from taking
steps towards optimal practices in their crops promptly. Property estimation
from spectral signals(vis-NIRS), emerged as a low-cost, non-invasive, and
non-destructive alternative. Current approaches use mathematical and
statistical techniques, avoiding machine learning framework. Here we propose
both regression and classification with machine learning techniques to assess
performance in the prediction and infer categories of common soil properties
(pH, soil organic matter, Ca, Na, K and Mg), evaluated by the most common
metrics. In sugarcane soils, we use regression to estimate properties and
classification to assess soil's property status and report the direct relation
between spectra bands and direct measure of certain properties. In both cases,
we achieved similar performance
</p>
<a href="http://arxiv.org/abs/2012.12995" target="_blank">arXiv:2012.12995</a> [<a href="http://arxiv.org/pdf/2012.12995" target="_blank">pdf</a>]

<h2>Semantic Segmentation on Swiss3DCities: A Benchmark Study on Aerial Photogrammetric 3D Pointcloud Dataset. (arXiv:2012.12996v1 [cs.CV])</h2>
<h3>G&#xfc;lcan Can, Dario Mantegazza, Gabriele Abbate, S&#xe9;bastien Chappuis, Alessandro Giusti</h3>
<p>We introduce a new outdoor urban 3D pointcloud dataset, covering a total area
of 2.7 $km^2$, sampled from three Swiss cities with different characteristics.
The dataset is manually annotated for semantic segmentation with per-point
labels, and is built using photogrammetry from images acquired by multirotors
equipped with high-resolution cameras. In contrast to datasets acquired with
ground LiDAR sensors, the resulting point clouds are uniformly dense and
complete, and are useful to disparate applications, including autonomous
driving, gaming and smart city planning. As a benchmark, we report quantitative
results of PointNet++, an established point-based deep 3D semantic segmentation
model; on this model, we additionally study the impact of using different
cities for model generalization.
</p>
<a href="http://arxiv.org/abs/2012.12996" target="_blank">arXiv:2012.12996</a> [<a href="http://arxiv.org/pdf/2012.12996" target="_blank">pdf</a>]

<h2>Low-latency Perception in Off-Road Dynamical Low Visibility Environments. (arXiv:2012.13014v1 [cs.CV])</h2>
<h3>Nelson Alves, Marco Ruiz, Marco Reis, Tiago Cajahyba, Davi Oliveira, Ana Barreto, Eduardo F. Simas Filho, Wagner L. A. de Oliveira, Leizer Schnitman, Roberto L. S. Monteiro</h3>
<p>This work proposes a perception system for autonomous vehicles and advanced
driver assistance specialized on unpaved roads and off-road environments. In
this research, the authors have investigated the behavior of Deep Learning
algorithms applied to semantic segmentation of off-road environments and
unpaved roads under differents adverse conditions of visibility. Almost 12,000
images of different unpaved and off-road environments were collected and
labeled. It was assembled an off-road proving ground exclusively for its
development. The proposed dataset also contains many adverse situations such as
rain, dust, and low light. To develop the system, we have used convolutional
neural networks trained to segment obstacles and areas where the car can pass
through. We developed a Configurable Modular Segmentation Network (CMSNet)
framework to help create different architectures arrangements and test them on
the proposed dataset. Besides, we also have ported some CMSNet configurations
by removing and fusing many layers using TensorRT, C++, and CUDA to achieve
embedded real-time inference and allow field tests. The main contributions of
this work are: a new dataset for unpaved roads and off-roads environments
containing many adverse conditions such as night, rain, and dust; a CMSNet
framework; an investigation regarding the feasibility of applying deep learning
to detect region where the vehicle can pass through when there is no clear
boundary of the track; a study of how our proposed segmentation algorithms
behave in different severity levels of visibility impairment; and an evaluation
of field tests carried out with semantic segmentation architectures ported for
real-time inference.
</p>
<a href="http://arxiv.org/abs/2012.13014" target="_blank">arXiv:2012.13014</a> [<a href="http://arxiv.org/pdf/2012.13014" target="_blank">pdf</a>]

<h2>Physics-based Shadow Image Decomposition for Shadow Removal. (arXiv:2012.13018v1 [cs.CV])</h2>
<h3>Hieu Le, Dimitris Samaras</h3>
<p>We propose a novel deep learning method for shadow removal. Inspired by
physical models of shadow formation, we use a linear illumination
transformation to model the shadow effects in the image that allows the shadow
image to be expressed as a combination of the shadow-free image, the shadow
parameters, and a matte layer. We use two deep networks, namely SP-Net and
M-Net, to predict the shadow parameters and the shadow matte respectively. This
system allows us to remove the shadow effects from images. We then employ an
inpainting network, I-Net, to further refine the results. We train and test our
framework on the most challenging shadow removal dataset (ISTD). Our method
improves the state-of-the-art in terms of root mean square error (RMSE) for the
shadow area by 20\%. Furthermore, this decomposition allows us to formulate a
patch-based weakly-supervised shadow removal method. This model can be trained
without any shadow-free images (that are cumbersome to acquire) and achieves
competitive shadow removal results compared to state-of-the-art methods that
are trained with fully paired shadow and shadow-free images. Last, we introduce
SBU-Timelapse, a video shadow removal dataset for evaluating shadow removal
methods.
</p>
<a href="http://arxiv.org/abs/2012.13018" target="_blank">arXiv:2012.13018</a> [<a href="http://arxiv.org/pdf/2012.13018" target="_blank">pdf</a>]

<h2>K-Means Kernel Classifier. (arXiv:2012.13021v1 [cs.LG])</h2>
<h3>M. Andrecut</h3>
<p>We combine K-means clustering with the least-squares kernel classification
method. K-means clustering is used to extract a set of representative vectors
for each class. The least-squares kernel method uses these representative
vectors as a training set for the classification task. We show that this
combination of unsupervised and supervised learning algorithms performs very
well, and we illustrate this approach using the MNIST dataset
</p>
<a href="http://arxiv.org/abs/2012.13021" target="_blank">arXiv:2012.13021</a> [<a href="http://arxiv.org/pdf/2012.13021" target="_blank">pdf</a>]

<h2>Self-Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs. (arXiv:2012.13023v1 [cs.LG])</h2>
<h3>Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian, Chandan K. Reddy</h3>
<p>Knowledge Graphs (KGs) are ubiquitous structures for information storagein
several real-world applications such as web search, e-commerce, social
networks, and biology. Querying KGs remains a foundational and challenging
problem due to their size and complexity. Promising approaches to tackle this
problem include embedding the KG units (e.g., entities and relations) in a
Euclidean space such that the query embedding contains the information relevant
to its results. These approaches, however, fail to capture the hierarchical
nature and semantic information of the entities present in the graph.
Additionally, most of these approaches only utilize multi-hop queries (that can
be modeled by simple translation operations) to learn embeddings and ignore
more complex operations such as intersection and union of simpler queries. To
tackle such complex operations, in this paper, we formulate KG representation
learning as a self-supervised logical query reasoning problem that utilizes
translation, intersection and union queries over KGs. We propose Hyperboloid
Embeddings (HypE), a novel self-supervised dynamic reasoning framework, that
utilizes positive first-order existential queries on a KG to learn
representations of its entities and relations as hyperboloids in a Poincar\'e
ball. HypE models the positive first-order queries as geometrical translation,
intersection, and union. For the problem of KG reasoning in real-world
datasets, the proposed HypE model significantly outperforms the state-of-the
art results. We also apply HypE to an anomaly detection task on a popular
e-commerce website product taxonomy as well as hierarchically organized web
articles and demonstrate significant performance improvements compared to
existing baseline methods. Finally, we also visualize the learned HypE
embeddings in a Poincar\'e ball to clearly interpret and comprehend the
representation space.
</p>
<a href="http://arxiv.org/abs/2012.13023" target="_blank">arXiv:2012.13023</a> [<a href="http://arxiv.org/pdf/2012.13023" target="_blank">pdf</a>]

<h2>Private-Shared Disentangled Multimodal VAE for Learning of Hybrid Latent Representations. (arXiv:2012.13024v1 [cs.CV])</h2>
<h3>Mihee Lee, Vladimir Pavlovic</h3>
<p>Multi-modal generative models represent an important family of deep models,
whose goal is to facilitate representation learning on data with multiple views
or modalities. However, current deep multi-modal models focus on the inference
of shared representations, while neglecting the important private aspects of
data within individual modalities. In this paper, we introduce a disentangled
multi-modal variational autoencoder (DMVAE) that utilizes disentangled VAE
strategy to separate the private and shared latent spaces of multiple
modalities. We specifically consider the instance where the latent factor may
be of both continuous and discrete nature, leading to the family of general
hybrid DMVAE models. We demonstrate the utility of DMVAE on a semi-supervised
learning task, where one of the modalities contains partial data labels, both
relevant and irrelevant to the other modality. Our experiments on several
benchmarks indicate the importance of the private-shared disentanglement as
well as the hybrid latent representation.
</p>
<a href="http://arxiv.org/abs/2012.13024" target="_blank">arXiv:2012.13024</a> [<a href="http://arxiv.org/pdf/2012.13024" target="_blank">pdf</a>]

<h2>Rethink AI-based Power Grid Control: Diving Into Algorithm Design. (arXiv:2012.13026v1 [cs.AI])</h2>
<h3>Xiren Zhou, Siqi Wang, Ruisheng Diao, Desong Bian, Jiahui Duan, Di Shi</h3>
<p>Recently, deep reinforcement learning (DRL)-based approach has shown
promisein solving complex decision and control problems in power engineering
domain.In this paper, we present an in-depth analysis of DRL-based voltage
control fromaspects of algorithm selection, state space representation, and
reward engineering.To resolve observed issues, we propose a novel imitation
learning-based approachto directly map power grid operating points to effective
actions without any interimreinforcement learning process. The performance
results demonstrate that theproposed approach has strong generalization ability
with much less training time.The agent trained by imitation learning is
effective and robust to solve voltagecontrol problem and outperforms the former
RL agents.
</p>
<a href="http://arxiv.org/abs/2012.13026" target="_blank">arXiv:2012.13026</a> [<a href="http://arxiv.org/pdf/2012.13026" target="_blank">pdf</a>]

<h2>General Domain Adaptation Through Proportional Progressive Pseudo Labeling. (arXiv:2012.13028v1 [cs.LG])</h2>
<h3>Mohammad J. Hashemi, Eric Keller</h3>
<p>Domain adaptation helps transfer the knowledge gained from a labeled source
domain to an unlabeled target domain. During the past few years, different
domain adaptation techniques have been published. One common flaw of these
approaches is that while they might work well on one input type, such as
images, their performance drops when applied to others, such as text or
time-series. In this paper, we introduce Proportional Progressive Pseudo
Labeling (PPPL), a simple, yet effective technique that can be implemented in a
few lines of code to build a more general domain adaptation technique that can
be applied on several different input types. At the beginning of the training
phase, PPPL progressively reduces target domain classification error, by
training the model directly with pseudo-labeled target domain samples, while
excluding samples with more likely wrong pseudo-labels from the training set
and also postponing training on such samples. Experiments on 6 different
datasets that include tasks such as anomaly detection, text sentiment analysis
and image classification demonstrate that PPPL can beat other baselines and
generalize better.
</p>
<a href="http://arxiv.org/abs/2012.13028" target="_blank">arXiv:2012.13028</a> [<a href="http://arxiv.org/pdf/2012.13028" target="_blank">pdf</a>]

<h2>Mesh Based Analysis of Low Fractal Dimension ReinforcementLearning Policies. (arXiv:2012.13032v1 [cs.RO])</h2>
<h3>Sean Gillen, Katie Byl</h3>
<p>In previous work, using a process we call meshing, the reachable state spaces
for various continuous and hybrid systems were approximated as a discrete set
of states which can then be synthesized into a Markov chain. One of the
applications for this approach has been to analyze locomotion policies obtained
by reinforcement learning, in a step towards making empirical guarantees about
the stability properties of the resulting system. In a separate line of
research, we introduced a modified reward function for on-policy reinforcement
learning algorithms that utilizes a "fractal dimension" of rollout
trajectories. This reward was shown to encourage policies that induce
individual trajectories which can be more compactly represented as a discrete
mesh. In this work we combine these two threads of research by building meshes
of the reachable state space of a system subject to disturbances and controlled
by policies obtained with the modified reward. Our analysis shows that the
modified policies do produce much smaller reachable meshes. This shows that
agents trained with the fractal dimension reward transfer their desirable
quality of having a more compact state space to a setting with external
disturbances. The results also suggest that the previous work using mesh based
tools to analyze RL policies may be extended to higher dimensional systems or
to higher resolution meshes than would have otherwise been possible.
</p>
<a href="http://arxiv.org/abs/2012.13032" target="_blank">arXiv:2012.13032</a> [<a href="http://arxiv.org/pdf/2012.13032" target="_blank">pdf</a>]

<h2>Assured RL: Reinforcement Learning with Almost Sure Constraints. (arXiv:2012.13036v1 [cs.LG])</h2>
<h3>Agustin Castellano, Juan Bazerque, Enrique Mallada</h3>
<p>We consider the problem of finding optimal policies for a Markov Decision
Process with almost sure constraints on state transitions and action triplets.
We define value and action-value functions that satisfy a barrier-based
decomposition which allows for the identification of feasible policies
independently of the reward process. We prove that, given a policy {\pi},
certifying whether certain state-action pairs lead to feasible trajectories
under {\pi} is equivalent to solving an auxiliary problem aimed at finding the
probability of performing an unfeasible transition. Using this
interpretation,we develop a Barrier-learning algorithm, based on Q-Learning,
that identifies such unsafe state-action pairs. Our analysis motivates the need
to enhance the Reinforcement Learning (RL) framework with an additional signal,
besides rewards, called here damage function that provides feasibility
information and enables the solution of RL problems with model-free
constraints. Moreover, our Barrier-learning algorithm wraps around existing RL
algorithms, such as Q-Learning and SARSA, giving them the ability to solve
almost-surely constrained problems.
</p>
<a href="http://arxiv.org/abs/2012.13036" target="_blank">arXiv:2012.13036</a> [<a href="http://arxiv.org/pdf/2012.13036" target="_blank">pdf</a>]

<h2>SPOTTER: Extending Symbolic Planning Operators through Targeted Reinforcement Learning. (arXiv:2012.13037v1 [cs.AI])</h2>
<h3>Vasanth Sarathy, Daniel Kasenberg, Shivam Goel, Jivko Sinapov, Matthias Scheutz</h3>
<p>Symbolic planning models allow decision-making agents to sequence actions in
arbitrary ways to achieve a variety of goals in dynamic domains. However, they
are typically handcrafted and tend to require precise formulations that are not
robust to human error. Reinforcement learning (RL) approaches do not require
such models, and instead learn domain dynamics by exploring the environment and
collecting rewards. However, RL approaches tend to require millions of episodes
of experience and often learn policies that are not easily transferable to
other tasks. In this paper, we address one aspect of the open problem of
integrating these approaches: how can decision-making agents resolve
discrepancies in their symbolic planning models while attempting to accomplish
goals? We propose an integrated framework named SPOTTER that uses RL to augment
and support ("spot") a planning agent by discovering new operators needed by
the agent to accomplish goals that are initially unreachable for the agent.
SPOTTER outperforms pure-RL approaches while also discovering transferable
symbolic knowledge and does not require supervision, successful plan traces or
any a priori knowledge about the missing planning operator.
</p>
<a href="http://arxiv.org/abs/2012.13037" target="_blank">arXiv:2012.13037</a> [<a href="http://arxiv.org/pdf/2012.13037" target="_blank">pdf</a>]

<h2>Union-net: A deep neural network model adapted to small data sets. (arXiv:2012.13044v1 [cs.CV])</h2>
<h3>Qingfang He, Guang Cheng, Zhiying Lin</h3>
<p>In real applications, generally small data sets can be obtained. At present,
most of the practical applications of machine learning use classic models based
on big data to solve the problem of small data sets. However, the deep neural
network model has complex structure, huge model parameters, and training
requires more advanced equipment, which brings certain difficulties to the
application. Therefore, this paper proposes the concept of union convolution,
designing a light deep network model union-net with a shallow network structure
and adapting to small data sets. This model combines convolutional network
units with different combinations of the same input to form a union module.
Each union module is equivalent to a convolutional layer. The serial input and
output between the 3 modules constitute a "3-layer" neural network. The output
of each union module is fused and added as the input of the last convolutional
layer to form a complex network with a 4-layer network structure. It solves the
problem that the deep network model network is too deep and the transmission
path is too long, which causes the loss of the underlying information
transmission. Because the model has fewer model parameters and fewer channels,
it can better adapt to small data sets. It solves the problem that the deep
network model is prone to overfitting in training small data sets. Use the
public data sets cifar10 and 17flowers to conduct multi-classification
experiments. Experiments show that the Union-net model can perform well in
classification of large data sets and small data sets. It has high practical
value in daily application scenarios. The model code is published at
https://github.com/yeaso/union-net
</p>
<a href="http://arxiv.org/abs/2012.13044" target="_blank">arXiv:2012.13044</a> [<a href="http://arxiv.org/pdf/2012.13044" target="_blank">pdf</a>]

<h2>Regret Bound Balancing and Elimination for Model Selection in Bandits and RL. (arXiv:2012.13045v1 [cs.LG])</h2>
<h3>Aldo Pacchiano, Christoph Dann, Claudio Gentile, Peter Bartlett</h3>
<p>We propose a simple model selection approach for algorithms in stochastic
bandit and reinforcement learning problems. As opposed to prior work that
(implicitly) assumes knowledge of the optimal regret, we only require that each
base algorithm comes with a candidate regret bound that may or may not hold
during all rounds. In each round, our approach plays a base algorithm to keep
the candidate regret bounds of all remaining base algorithms balanced, and
eliminates algorithms that violate their candidate bound. We prove that the
total regret of this approach is bounded by the best valid candidate regret
bound times a multiplicative factor. This factor is reasonably small in several
applications, including linear bandits and MDPs with nested function classes,
linear bandits with unknown misspecification, and LinUCB applied to linear
bandits with different confidence parameters. We further show that, under a
suitable gap-assumption, this factor only scales with the number of base
algorithms and not their complexity when the number of rounds is large enough.
Finally, unlike recent efforts in model selection for linear stochastic
bandits, our approach is versatile enough to also cover cases where the context
information is generated by an adversarial environment, rather than a
stochastic one.
</p>
<a href="http://arxiv.org/abs/2012.13045" target="_blank">arXiv:2012.13045</a> [<a href="http://arxiv.org/pdf/2012.13045" target="_blank">pdf</a>]

<h2>Learning from Crowds by Modeling Common Confusions. (arXiv:2012.13052v1 [cs.LG])</h2>
<h3>Zhendong Chu, Jing Ma, Hongning Wang</h3>
<p>Crowdsourcing provides a practical way to obtain large amounts of labeled
data at a low cost. However, the annotation quality of annotators varies
considerably, which imposes new challenges in learning a high-quality model
from the crowdsourced annotations. In this work, we provide a new perspective
to decompose annotation noise into common noise and individual noise and
differentiate the source of confusion based on instance difficulty and
annotator expertise on a per-instance-annotator basis. We realize this new
crowdsourcing model by an end-to-end learning solution with two types of noise
adaptation layers: one is shared across annotators to capture their commonly
shared confusions, and the other one is pertaining to each annotator to realize
individual confusion. To recognize the source of noise in each annotation, we
use an auxiliary network to choose the two noise adaptation layers with respect
to both instances and annotators. Extensive experiments on both synthesized and
real-world benchmarks demonstrate the effectiveness of our proposed common
noise adaptation solution.
</p>
<a href="http://arxiv.org/abs/2012.13052" target="_blank">arXiv:2012.13052</a> [<a href="http://arxiv.org/pdf/2012.13052" target="_blank">pdf</a>]

<h2>A Generalized A* Algorithm for Finding Globally Optimal Paths in Weighted Colored Graphs. (arXiv:2012.13057v1 [cs.RO])</h2>
<h3>Jaein Lim, Panagiotis Tsiotras</h3>
<p>Both geometric and semantic information of the search space is imperative for
a good plan. We encode those properties in a weighted colored graph (geometric
information in terms of edge weight and semantic information in terms of edge
and vertex color), and propose a generalized A* to find the shortest path among
the set of paths with minimal inclusion of low-ranked color edges. We prove the
completeness and optimality of this Class-Ordered A* (COA*) algorithm with
respect to the hereto defined notion of optimality. The utility of COA* is
numerically validated in a ternary graph with feasible, infeasible, and unknown
vertices and edges for the cases of a 2D mobile robot, a 3D robotic arm, and a
5D robotic arm with limited sensing capabilities. We compare the results of
COA* to that of the regular A* algorithm, the latter of which finds the
shortest path regardless of uncertainty, and we show that the COA* dominates
the A* solution in terms of finding less uncertain paths.
</p>
<a href="http://arxiv.org/abs/2012.13057" target="_blank">arXiv:2012.13057</a> [<a href="http://arxiv.org/pdf/2012.13057" target="_blank">pdf</a>]

<h2>Decentralized Federated Learning via Mutual Knowledge Transfer. (arXiv:2012.13063v1 [cs.LG])</h2>
<h3>Chengxi Li, Gang Li, Pramod K. Varshney</h3>
<p>In this paper, we investigate the problem of decentralized federated learning
(DFL) in Internet of things (IoT) systems, where a number of IoT clients train
models collectively for a common task without sharing their private training
data in the absence of a central server. Most of the existing DFL schemes are
composed of two alternating steps, i.e., gradient update and model averaging.
However, averaging of model parameters directly to fuse different models at the
local clients suffers from client-drift in the local updates especially when
the training data are heterogeneous across different clients. This leads to
slow convergence and degraded learning performance. As a possible solution, we
propose the decentralized federated learning via mutual knowledge transfer
(Def-KT) algorithm where local clients fuse models by transferring their learnt
knowledge to each other. Our experiments on the MNIST, Fashion-MNIST, and
CIFAR10 datasets reveal that the proposed Def-KT algorithm significantly
outperforms the baseline DFL methods with model averaging, i.e., Combo and
FullAvg, especially when the training data are not independent and identically
distributed (non-IID) across different clients.
</p>
<a href="http://arxiv.org/abs/2012.13063" target="_blank">arXiv:2012.13063</a> [<a href="http://arxiv.org/pdf/2012.13063" target="_blank">pdf</a>]

<h2>Task-Adaptive Negative Class Envision for Few-Shot Open-Set Recognition. (arXiv:2012.13073v1 [cs.CV])</h2>
<h3>Shiyuan Huang, Jiawei Ma, Guangxing Han, Shih-Fu Chang</h3>
<p>Recent works seek to endow recognition systems with the ability to handle the
open world. Few shot learning aims for fast learning of new classes from
limited examples, while open-set recognition considers unknown negative class
from the open world. In this paper, we study the problem of few-shot open-set
recognition (FSOR), which learns a recognition system robust to queries from
new sources with few examples and from unknown open sources. To achieve that,
we mimic human capability of envisioning new concepts from prior knowledge, and
propose a novel task-adaptive negative class envision method (TANE) to model
the open world. Essentially we use an external memory to estimate a negative
class representation. Moreover, we introduce a novel conjugate episode training
strategy that strengthens the learning process. Extensive experiments on four
public benchmarks show that our approach significantly improves the
state-of-the-art performance on few-shot open-set recognition. Besides, we
extend our method to generalized few-shot open-set recognition (GFSOR), where
we also achieve performance gains on MiniImageNet.
</p>
<a href="http://arxiv.org/abs/2012.13073" target="_blank">arXiv:2012.13073</a> [<a href="http://arxiv.org/pdf/2012.13073" target="_blank">pdf</a>]

<h2>AsymptoticNG: A regularized natural gradient optimization algorithm with look-ahead strategy. (arXiv:2012.13077v1 [cs.LG])</h2>
<h3>Zedong Tang, Fenlong Jiang, Maoguo Gong, Hao Li, Fan Yu, Zidong Wang, Min Wang</h3>
<p>Optimizers that further adjust the scale of gradient, such as Adam, Natural
Gradient (NG), etc., despite widely concerned and used by the community, are
often found poor generalization performance, compared with Stochastic Gradient
Descent (SGD). They tend to converge excellently at the beginning of training
but are weak at the end. An immediate idea is to complement the strengths of
these algorithms with SGD. However, a truncated replacement of optimizer often
leads to a crash of the update pattern, and new algorithms often require many
iterations to stabilize their search direction. Driven by this idea and to
address this problem, we design and present a regularized natural gradient
optimization algorithm with look-ahead strategy, named asymptotic natural
gradient (ANG). According to the total iteration step, ANG dynamic assembles NG
and Euclidean gradient, and updates parameters along the new direction using
the intensity of NG. Validation experiments on CIFAR10 and CIFAR100 data sets
show that ANG can update smoothly and stably at the second-order speed, and
achieve better generalization performance.
</p>
<a href="http://arxiv.org/abs/2012.13077" target="_blank">arXiv:2012.13077</a> [<a href="http://arxiv.org/pdf/2012.13077" target="_blank">pdf</a>]

<h2>Rotation Equivariant Siamese Networks for Tracking. (arXiv:2012.13078v1 [cs.CV])</h2>
<h3>Deepak K. Gupta, Devanshu Arya, Efstratios Gavves</h3>
<p>Rotation is among the long prevailing, yet still unresolved, hard challenges
encountered in visual object tracking. The existing deep learning-based
tracking algorithms use regular CNNs that are inherently translation
equivariant, but not designed to tackle rotations. In this paper, we first
demonstrate that in the presence of rotation instances in videos, the
performance of existing trackers is severely affected. To circumvent the
adverse effect of rotations, we present rotation-equivariant Siamese networks
(RE-SiamNets), built through the use of group-equivariant convolutional layers
comprising steerable filters. SiamNets allow estimating the change in
orientation of the object in an unsupervised manner, thereby facilitating its
use in relative 2D pose estimation as well. We further show that this change in
orientation can be used to impose an additional motion constraint in Siamese
tracking through imposing restriction on the change in orientation between two
consecutive frames. For benchmarking, we present Rotation Tracking Benchmark
(RTB), a dataset comprising a set of videos with rotation instances. Through
experiments on two popular Siamese architectures, we show that RE-SiamNets
handle the problem of rotation very well and out-perform their regular
counterparts. Further, RE-SiamNets can accurately estimate the relative change
in pose of the target in an unsupervised fashion, namely the in-plane rotation
the target has sustained with respect to the reference frame.
</p>
<a href="http://arxiv.org/abs/2012.13078" target="_blank">arXiv:2012.13078</a> [<a href="http://arxiv.org/pdf/2012.13078" target="_blank">pdf</a>]

<h2>Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks. (arXiv:2012.13085v1 [cs.LG])</h2>
<h3>Binghui Wang, Jinyuan Jia, Neil Zhenqiang Gong</h3>
<p>Semi-supervised node classification on graph-structured data has many
applications such as fraud detection, fake account and review detection, user's
private attribute inference in social networks, and community detection.
Various methods such as pairwise Markov Random Fields (pMRF) and graph neural
networks were developed for semi-supervised node classification. pMRF is more
efficient than graph neural networks. However, existing pMRF-based methods are
less accurate than graph neural networks, due to a key limitation that they
assume a heuristics-based constant edge potential for all edges. In this work,
we aim to address the key limitation of existing pMRF-based methods. In
particular, we propose to learn edge potentials for pMRF. Our evaluation
results on various types of graph datasets show that our optimized pMRF-based
method consistently outperforms existing graph neural networks in terms of both
accuracy and efficiency. Our results highlight that previous work may have
underestimated the power of pMRF for semi-supervised node classification.
</p>
<a href="http://arxiv.org/abs/2012.13085" target="_blank">arXiv:2012.13085</a> [<a href="http://arxiv.org/pdf/2012.13085" target="_blank">pdf</a>]

<h2>High-Dimensional Bayesian Optimization via Tree-Structured Additive Models. (arXiv:2012.13088v1 [stat.ML])</h2>
<h3>Eric Han, Ishank Arora, Jonathan Scarlett</h3>
<p>Bayesian Optimization (BO) has shown significant success in tackling
expensive low-dimensional black-box optimization problems. Many optimization
problems of interest are high-dimensional, and scaling BO to such settings
remains an important challenge. In this paper, we consider generalized additive
models in which low-dimensional functions with overlapping subsets of variables
are composed to model a high-dimensional target function. Our goal is to lower
the computational resources required and facilitate faster model learning by
reducing the model complexity while retaining the sample-efficiency of existing
methods. Specifically, we constrain the underlying dependency graphs to tree
structures in order to facilitate both the structure learning and optimization
of the acquisition function. For the former, we propose a hybrid graph learning
algorithm based on Gibbs sampling and mutation. In addition, we propose a novel
zooming-based algorithm that permits generalized additive models to be employed
more efficiently in the case of continuous domains. We demonstrate and discuss
the efficacy of our approach via a range of experiments on synthetic functions
and real-world datasets.
</p>
<a href="http://arxiv.org/abs/2012.13088" target="_blank">arXiv:2012.13088</a> [<a href="http://arxiv.org/pdf/2012.13088" target="_blank">pdf</a>]

<h2>P4Contrast: Contrastive Learning with Pairs of Point-Pixel Pairs for RGB-D Scene Understanding. (arXiv:2012.13089v1 [cs.CV])</h2>
<h3>Yunze Liu, Li Yi, Shanghang Zhang, Qingnan Fan, Thomas Funkhouser, Hao Dong</h3>
<p>Self-supervised representation learning is a critical problem in computer
vision, as it provides a way to pretrain feature extractors on large unlabeled
datasets that can be used as an initialization for more efficient and effective
training on downstream tasks. A promising approach is to use contrastive
learning to learn a latent space where features are close for similar data
samples and far apart for dissimilar ones. This approach has demonstrated
tremendous success for pretraining both image and point cloud feature
extractors, but it has been barely investigated for multi-modal RGB-D scans,
especially with the goal of facilitating high-level scene understanding. To
solve this problem, we propose contrasting "pairs of point-pixel pairs", where
positives include pairs of RGB-D points in correspondence, and negatives
include pairs where one of the two modalities has been disturbed and/or the two
RGB-D points are not in correspondence. This provides extra flexibility in
making hard negatives and helps networks to learn features from both
modalities, not just the more discriminating one of the two. Experiments show
that this proposed approach yields better performance on three large-scale
RGB-D scene understanding benchmarks (ScanNet, SUN RGB-D, and 3RScan) than
previous pretraining approaches.
</p>
<a href="http://arxiv.org/abs/2012.13089" target="_blank">arXiv:2012.13089</a> [<a href="http://arxiv.org/pdf/2012.13089" target="_blank">pdf</a>]

<h2>Auto-Agent-Distiller: Towards Efficient Deep Reinforcement Learning Agents via Neural Architecture Search. (arXiv:2012.13091v1 [cs.LG])</h2>
<h3>Yonggan Fu, Zhongzhi Yu, Yongan Zhang, Yingyan Lin</h3>
<p>AlphaGo's astonishing performance has ignited an explosive interest in
developing deep reinforcement learning (DRL) for numerous real-world
applications, such as intelligent robotics. However, the often prohibitive
complexity of DRL stands at the odds with the required real-time control and
constrained resources in many DRL applications, limiting the great potential of
DRL powered intelligent devices. While substantial efforts have been devoted to
compressing other deep learning models, existing works barely touch the surface
of compressing DRL. In this work, we first identify that there exists an
optimal model size of DRL that can maximize both the test scores and
efficiency, motivating the need for task-specific DRL agents. We therefore
propose an Auto-Agent-Distiller (A2D) framework, which to our best knowledge is
the first neural architecture search (NAS) applied to DRL to automatically
search for the optimal DRL agents for various tasks that optimize both the test
scores and efficiency. Specifically, we demonstrate that vanilla NAS can easily
fail in searching for the optimal agents, due to its resulting high variance in
DRL training stability, and then develop a novel distillation mechanism to
distill the knowledge from both the teacher agent's actor and critic to
stabilize the searching process and improve the searched agents' optimality.
Extensive experiments and ablation studies consistently validate our findings
and the advantages and general applicability of our A2D, outperforming manually
designed DRL in both the test scores and efficiency. All the codes will be
released upon acceptance.
</p>
<a href="http://arxiv.org/abs/2012.13091" target="_blank">arXiv:2012.13091</a> [<a href="http://arxiv.org/pdf/2012.13091" target="_blank">pdf</a>]

<h2>EDN: Salient Object Detection via Extremely-Downsampled Network. (arXiv:2012.13093v1 [cs.CV])</h2>
<h3>Yu-Huan Wu, Yun Liu, Le Zhang, Ming-Ming Cheng</h3>
<p>Recent progress on salient object detection (SOD) mainly benefits from
multi-scale learning, where the high-level and low-level features work
collaboratively in locating salient objects and discovering fine details,
respectively. However, most efforts are devoted to low-level feature learning
by fusing multi-scale features or enhancing boundary representations. In this
paper, we show another direction that improving high-level feature learning is
essential for SOD as well. To verify this, we introduce an
Extremely-Downsampled Network (EDN), which employs an extreme downsampling
technique to effectively learn a global view of the whole image, leading to
accurate salient object localization. A novel Scale-Correlated Pyramid
Convolution (SCPC) is also designed to build an elegant decoder for recovering
object details from the above extreme downsampling. Extensive experiments
demonstrate that EDN achieves \sArt performance with real-time speed. Hence,
this work is expected to spark some new thinking in SOD. The code will be
released.
</p>
<a href="http://arxiv.org/abs/2012.13093" target="_blank">arXiv:2012.13093</a> [<a href="http://arxiv.org/pdf/2012.13093" target="_blank">pdf</a>]

<h2>MobileSal: Extremely Efficient RGB-D Salient Object Detection. (arXiv:2012.13095v1 [cs.CV])</h2>
<h3>Yu-Huan Wu, Yun Liu, Jun Xu, Jia-Wang Bian, Yuchao Gu, Ming-Ming Cheng</h3>
<p>The high computational cost of neural networks has prevented recent successes
in RGB-D salient object detection (SOD) from benefiting real-world
applications. Hence, this paper introduces a novel network, \methodname, which
focuses on efficient RGB-D SOD by using mobile networks for deep feature
extraction. The problem is that mobile networks are less powerful in feature
representation than cumbersome networks. To this end, we observe that the depth
information of color images can strengthen the feature representation related
to SOD if leveraged properly. Therefore, we propose an implicit depth
restoration (IDR) technique to strengthen the feature representation capability
of mobile networks for RGB-D SOD. IDR is only adopted in the training phase and
is omitted during testing, so it is computationally free. Besides, we propose
compact pyramid refinement (CPR) for efficient multi-level feature aggregation
so that we can derive salient objects with clear boundaries. With IDR and CPR
incorporated, \methodname~performs favorably against \sArt methods on seven
challenging RGB-D SOD datasets with much faster speed (450fps) and fewer
parameters (6.5M). The code will be released.
</p>
<a href="http://arxiv.org/abs/2012.13095" target="_blank">arXiv:2012.13095</a> [<a href="http://arxiv.org/pdf/2012.13095" target="_blank">pdf</a>]

<h2>Learning with Retrospection. (arXiv:2012.13098v1 [cs.LG])</h2>
<h3>Xiang Deng, Zhongfei Zhang</h3>
<p>Deep neural networks have been successfully deployed in various domains of
artificial intelligence, including computer vision and natural language
processing. We observe that the current standard procedure for training DNNs
discards all the learned information in the past epochs except the current
learned weights. An interesting question is: is this discarded information
indeed useless? We argue that the discarded information can benefit the
subsequent training. In this paper, we propose learning with retrospection
(LWR) which makes use of the learned information in the past epochs to guide
the subsequent training. LWR is a simple yet effective training framework to
improve accuracies, calibration, and robustness of DNNs without introducing any
additional network parameters or inference cost, only with a negligible
training overhead. Extensive experiments on several benchmark datasets
demonstrate the superiority of LWR for training DNNs.
</p>
<a href="http://arxiv.org/abs/2012.13098" target="_blank">arXiv:2012.13098</a> [<a href="http://arxiv.org/pdf/2012.13098" target="_blank">pdf</a>]

<h2>Cooperative Policy Learning with Pre-trained Heterogeneous Observation Representations. (arXiv:2012.13099v1 [cs.LG])</h2>
<h3>Wenlei Shi, Xinran Wei, Jia Zhang, Xiaoyuan Ni, Arthur Jiang, Jiang Bian, Tie-Yan Liu</h3>
<p>Multi-agent reinforcement learning (MARL) has been increasingly explored to
learn the cooperative policy towards maximizing a certain global reward. Many
existing studies take advantage of graph neural networks (GNN) in MARL to
propagate critical collaborative information over the interaction graph, built
upon inter-connected agents. Nevertheless, the vanilla GNN approach yields
substantial defects in dealing with complex real-world scenarios since the
generic message passing mechanism is ineffective between heterogeneous vertices
and, moreover, simple message aggregation functions are incapable of accurately
modeling the combinational interactions from multiple neighbors. While adopting
complex GNN models with more informative message passing and aggregation
mechanisms can obviously benefit heterogeneous vertex representations and
cooperative policy learning, it could, on the other hand, increase the training
difficulty of MARL and demand more intense and direct reward signals compared
to the original global reward. To address these challenges, we propose a new
cooperative learning framework with pre-trained heterogeneous observation
representations. Particularly, we employ an encoder-decoder based graph
attention to learn the intricate interactions and heterogeneous representations
that can be more easily leveraged by MARL. Moreover, we design a pre-training
with local actor-critic algorithm to ease the difficulty in cooperative policy
learning. Extensive experiments over real-world scenarios demonstrate that our
new approach can significantly outperform existing MARL baselines as well as
operational research solutions that are widely-used in industry.
</p>
<a href="http://arxiv.org/abs/2012.13099" target="_blank">arXiv:2012.13099</a> [<a href="http://arxiv.org/pdf/2012.13099" target="_blank">pdf</a>]

<h2>Improving the Certified Robustness of Neural Networks via Consistency Regularization. (arXiv:2012.13103v1 [cs.LG])</h2>
<h3>Mengting Xu, Tao Zhang, Zhongnian Li, Wei Shao, Daoqiang Zhang</h3>
<p>A range of defense methods have been proposed to improve the robustness of
neural networks on adversarial examples, among which provable defense methods
have been demonstrated to be effective to train neural networks that are
certifiably robust to the attacker. However, most of these provable defense
methods treat all examples equally during training process, which ignore the
inconsistent constraint of certified robustness between correctly classified
(natural) and misclassified examples. In this paper, we explore this
inconsistency caused by misclassified examples and add a novel consistency
regularization term to make better use of the misclassified examples.
Specifically, we identified that the certified robustness of network can be
significantly improved if the constraint of certified robustness on
misclassified examples and correctly classified examples is consistent.
Motivated by this discovery, we design a new defense regularization term called
Misclassification Aware Adversarial Regularization (MAAR), which constrains the
output probability distributions of all examples in the certified region of the
misclassified example. Experimental results show that our proposed MAAR
achieves the best certified robustness and comparable accuracy on CIFAR-10 and
MNIST datasets in comparison with several state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.13103" target="_blank">arXiv:2012.13103</a> [<a href="http://arxiv.org/pdf/2012.13103" target="_blank">pdf</a>]

<h2>Exploring Adversarial Examples via Invertible Neural Networks. (arXiv:2012.13111v1 [cs.LG])</h2>
<h3>Ruqi Bai, Saurabh Bagchi, David I. Inouye</h3>
<p>Adversarial examples (AEs) are images that can mislead deep neural network
(DNN) classifiers via introducing slight perturbations into original images.
This security vulnerability has led to vast research in recent years because it
can introduce real-world threats into systems that rely on neural networks.
Yet, a deep understanding of the characteristics of adversarial examples has
remained elusive. We propose a new way of achieving such understanding through
a recent development, namely, invertible neural models with Lipschitz
continuous mapping functions from the input to the output. With the ability to
invert any latent representation back to its corresponding input image, we can
investigate adversarial examples at a deeper level and disentangle the
adversarial example's latent representation. Given this new perspective, we
propose a fast latent space adversarial example generation method that could
accelerate adversarial training. Moreover, this new perspective could
contribute to new ways of adversarial example detection.
</p>
<a href="http://arxiv.org/abs/2012.13111" target="_blank">arXiv:2012.13111</a> [<a href="http://arxiv.org/pdf/2012.13111" target="_blank">pdf</a>]

<h2>FracTrain: Fractionally Squeezing Bit Savings Both Temporally and Spatially for Efficient DNN Training. (arXiv:2012.13113v1 [cs.CV])</h2>
<h3>Yonggan Fu, Haoran You, Yang Zhao, Yue Wang, Chaojian Li, Kailash Gopalakrishnan, Zhangyang Wang, Yingyan Lin</h3>
<p>Recent breakthroughs in deep neural networks (DNNs) have fueled a tremendous
demand for intelligent edge devices featuring on-site learning, while the
practical realization of such systems remains a challenge due to the limited
resources available at the edge and the required massive training costs for
state-of-the-art (SOTA) DNNs. As reducing precision is one of the most
effective knobs for boosting training time/energy efficiency, there has been a
growing interest in low-precision DNN training. In this paper, we explore from
an orthogonal direction: how to fractionally squeeze out more training cost
savings from the most redundant bit level, progressively along the training
trajectory and dynamically per input. Specifically, we propose FracTrain that
integrates (i) progressive fractional quantization which gradually increases
the precision of activations, weights, and gradients that will not reach the
precision of SOTA static quantized DNN training until the final training stage,
and (ii) dynamic fractional quantization which assigns precisions to both the
activations and gradients of each layer in an input-adaptive manner, for only
"fractionally" updating layer parameters. Extensive simulations and ablation
studies (six models, four datasets, and three training settings including
standard, adaptation, and fine-tuning) validate the effectiveness of FracTrain
in reducing computational cost and hardware-quantified energy/latency of DNN
training while achieving a comparable or better (-0.12%~+1.87%) accuracy. For
example, when training ResNet-74 on CIFAR-10, FracTrain achieves 77.6% and
53.5% computational cost and training latency savings, respectively, compared
with the best SOTA baseline, while achieving a comparable (-0.07%) accuracy.
Our codes are available at: https://github.com/RICE-EIC/FracTrain.
</p>
<a href="http://arxiv.org/abs/2012.13113" target="_blank">arXiv:2012.13113</a> [<a href="http://arxiv.org/pdf/2012.13113" target="_blank">pdf</a>]

<h2>Upper Confidence Bounds for Combining Stochastic Bandits. (arXiv:2012.13115v1 [cs.LG])</h2>
<h3>Ashok Cutkosky, Abhimanyu Das, Manish Purohit</h3>
<p>We provide a simple method to combine stochastic bandit algorithms. Our
approach is based on a "meta-UCB" procedure that treats each of $N$ individual
bandit algorithms as arms in a higher-level $N$-armed bandit problem that we
solve with a variant of the classic UCB algorithm. Our final regret depends
only on the regret of the base algorithm with the best regret in hindsight.
This approach provides an easy and intuitive alternative strategy to the CORRAL
algorithm for adversarial bandits, without requiring the stability conditions
imposed by CORRAL on the base algorithms. Our results match lower bounds in
several settings, and we provide empirical validation of our algorithm on
misspecified linear bandit and model selection problems.
</p>
<a href="http://arxiv.org/abs/2012.13115" target="_blank">arXiv:2012.13115</a> [<a href="http://arxiv.org/pdf/2012.13115" target="_blank">pdf</a>]

<h2>Hausdorff Point Convolution with Geometric Priors. (arXiv:2012.13118v1 [cs.CV])</h2>
<h3>Pengdi Huang, Liqiang Lin, Fuyou Xue, Kai Xu, Danny Cohen-Or, Hui Huang</h3>
<p>Without a shape-aware response, it is hard to characterize the 3D geometry of
a point cloud efficiently with a compact set of kernels. In this paper, we
advocate the use of Hausdorff distance as a shape-aware distance measure for
calculating point convolutional responses. The technique we present, coined
Hausdorff Point Convolution (HPC), is shape-aware. We show that HPC constitutes
a powerful point feature learning with a rather compact set of only four types
of geometric priors as kernels. We further develop a HPC-based deep neural
network (HPC-DNN). Task-specific learning can be achieved by tuning the network
weights for combining the shortest distances between input and kernel point
sets. We also realize hierarchical feature learning by designing a multi-kernel
HPC for multi-scale feature encoding. Extensive experiments demonstrate that
HPC-DNN outperforms strong point convolution baselines (e.g., KPConv),
achieving 2.8% mIoU performance boost on S3DIS and 1.5% on SemanticKITTI for
semantic segmentation task.
</p>
<a href="http://arxiv.org/abs/2012.13118" target="_blank">arXiv:2012.13118</a> [<a href="http://arxiv.org/pdf/2012.13118" target="_blank">pdf</a>]

<h2>Memory-Gated Recurrent Networks. (arXiv:2012.13121v1 [cs.LG])</h2>
<h3>Yaquan Zhang, Qi Wu, Nanbo Peng, Min Dai, Jing Zhang, Hu Wang</h3>
<p>The essence of multivariate sequential learning is all about how to extract
dependencies in data. These data sets, such as hourly medical records in
intensive care units and multi-frequency phonetic time series, often time
exhibit not only strong serial dependencies in the individual components (the
"marginal" memory) but also non-negligible memories in the cross-sectional
dependencies (the "joint" memory). Because of the multivariate complexity in
the evolution of the joint distribution that underlies the data generating
process, we take a data-driven approach and construct a novel recurrent network
architecture, termed Memory-Gated Recurrent Networks (mGRN), with gates
explicitly regulating two distinct types of memories: the marginal memory and
the joint memory. Through a combination of comprehensive simulation studies and
empirical experiments on a range of public datasets, we show that our proposed
mGRN architecture consistently outperforms state-of-the-art architectures
targeting multivariate time series.
</p>
<a href="http://arxiv.org/abs/2012.13121" target="_blank">arXiv:2012.13121</a> [<a href="http://arxiv.org/pdf/2012.13121" target="_blank">pdf</a>]

<h2>MRDet: A Multi-Head Network for Accurate Oriented Object Detection in Aerial Images. (arXiv:2012.13135v1 [cs.CV])</h2>
<h3>Ran Qin, Qingjie Liu, Guangshuai Gao, Di Huang, Yunhong Wang</h3>
<p>Objects in aerial images usually have arbitrary orientations and are densely
located over the ground, making them extremely challenge to be detected. Many
recently developed methods attempt to solve these issues by estimating an extra
orientation parameter and placing dense anchors, which will result in high
model complexity and computational costs. In this paper, we propose an
arbitrary-oriented region proposal network (AO-RPN) to generate oriented
proposals transformed from horizontal anchors. The AO-RPN is very efficient
with only a few amounts of parameters increase than the original RPN.
Furthermore, to obtain accurate bounding boxes, we decouple the detection task
into multiple subtasks and propose a multi-head network to accomplish them.
Each head is specially designed to learn the features optimal for the
corresponding task, which allows our network to detect objects accurately. We
name it MRDet short for Multi-head Rotated object Detector for convenience. We
test the proposed MRDet on two challenging benchmarks, i.e., DOTA and HRSC2016,
and compare it with several state-of-the-art methods. Our method achieves very
promising results which clearly demonstrate its effectiveness.
</p>
<a href="http://arxiv.org/abs/2012.13135" target="_blank">arXiv:2012.13135</a> [<a href="http://arxiv.org/pdf/2012.13135" target="_blank">pdf</a>]

<h2>LCEval: Learned Composite Metric for Caption Evaluation. (arXiv:2012.13136v1 [cs.AI])</h2>
<h3>Naeha Sharif, Lyndon White, Mohammed Bennamoun, Wei Liu, Syed Afaq Ali Shah</h3>
<p>Automatic evaluation metrics hold a fundamental importance in the development
and fine-grained analysis of captioning systems. While current evaluation
metrics tend to achieve an acceptable correlation with human judgements at the
system level, they fail to do so at the caption level. In this work, we propose
a neural network-based learned metric to improve the caption-level caption
evaluation. To get a deeper insight into the parameters which impact a learned
metrics performance, this paper investigates the relationship between different
linguistic features and the caption-level correlation of the learned metrics.
We also compare metrics trained with different training examples to measure the
variations in their evaluation. Moreover, we perform a robustness analysis,
which highlights the sensitivity of learned and handcrafted metrics to various
sentence perturbations. Our empirical analysis shows that our proposed metric
not only outperforms the existing metrics in terms of caption-level correlation
but it also shows a strong system-level correlation against human assessments.
</p>
<a href="http://arxiv.org/abs/2012.13136" target="_blank">arXiv:2012.13136</a> [<a href="http://arxiv.org/pdf/2012.13136" target="_blank">pdf</a>]

<h2>WEmbSim: A Simple yet Effective Metric for Image Captioning. (arXiv:2012.13137v1 [cs.CV])</h2>
<h3>Naeha Sharif, Lyndon White, Mohammed Bennamoun, Wei Liu, Syed Afaq Ali Shah</h3>
<p>The area of automatic image caption evaluation is still undergoing intensive
research to address the needs of generating captions which can meet adequacy
and fluency requirements. Based on our past attempts at developing highly
sophisticated learning-based metrics, we have discovered that a simple cosine
similarity measure using the Mean of Word Embeddings(MOWE) of captions can
actually achieve a surprisingly high performance on unsupervised caption
evaluation. This inspires our proposed work on an effective metric WEmbSim,
which beats complex measures such as SPICE, CIDEr and WMD at system-level
correlation with human judgments. Moreover, it also achieves the best accuracy
at matching human consensus scores for caption pairs, against commonly used
unsupervised methods. Therefore, we believe that WEmbSim sets a new baseline
for any complex metric to be justified.
</p>
<a href="http://arxiv.org/abs/2012.13137" target="_blank">arXiv:2012.13137</a> [<a href="http://arxiv.org/pdf/2012.13137" target="_blank">pdf</a>]

<h2>A non-alternating graph hashing algorithm for large scale image search. (arXiv:2012.13138v1 [cs.CV])</h2>
<h3>Sobhan Hemati, Mohammad Hadi Mehdizavareh, Shojaeddin Chenouri, Hamid R Tizhoosh</h3>
<p>In the era of big data, methods for improving memory and computational
efficiency have become crucial for successful deployment of technologies.
Hashing is one of the most effective approaches to deal with computational
limitations that come with big data. One natural way for formulating this
problem is spectral hashing that directly incorporates affinity to learn binary
codes. However, due to binary constraints, the optimization becomes
intractable. To mitigate this challenge, different relaxation approaches have
been proposed to reduce the computational load of obtaining binary codes and
still attain a good solution. The problem with all existing relaxation methods
is resorting to one or more additional auxiliary variables to attain high
quality binary codes while relaxing the problem. The existence of auxiliary
variables leads to coordinate descent approach which increases the
computational complexity. We argue that introducing these variables is
unnecessary. To this end, we propose a novel relaxed formulation for spectral
hashing that adds no additional variables to the problem. Furthermore, instead
of solving the problem in original space where number of variables is equal to
the data points, we solve the problem in a much smaller space and retrieve the
binary codes from this solution. This trick reduces both the memory and
computational complexity at the same time. We apply two optimization
techniques, namely projected gradient and optimization on manifold, to obtain
the solution. Using comprehensive experiments on four public datasets, we show
that the proposed efficient spectral hashing (ESH) algorithm achieves highly
competitive retrieval performance compared with state of the art at low
complexity.
</p>
<a href="http://arxiv.org/abs/2012.13138" target="_blank">arXiv:2012.13138</a> [<a href="http://arxiv.org/pdf/2012.13138" target="_blank">pdf</a>]

<h2>On Radiation-Based Thermal Servoing: New Models, Controls and Experiments. (arXiv:2012.13147v1 [cs.RO])</h2>
<h3>Luyin Hu, David Navarro-Alarcon, Andrea Cherubini, Mengying Li</h3>
<p>In this paper, we introduce a new sensor-based control method that regulates
(by means of robot motions) the heat transfer between a radiative source and an
object of interest. This valuable sensorimotor capability is needed in many
industrial, dermatology and field robot applications, and it is an essential
component for creating machines with advanced thermo-motor intelligence. To
this end, we derive a geometric-thermal-motor model which describes the
relationship between the robot's active configuration and the produced dynamic
thermal response. We then use the model to guide the design of two new thermal
servoing controllers (one model-based and one adaptive), and analyze their
stability with Lyapunov theory. To validate our method, we report a detailed
experimental study with a robotic manipulator conducting autonomous thermal
servoing tasks. To the best of the authors' knowledge, this is the first time
that temperature regulation has been formulated as a motion control problem for
robots.
</p>
<a href="http://arxiv.org/abs/2012.13147" target="_blank">arXiv:2012.13147</a> [<a href="http://arxiv.org/pdf/2012.13147" target="_blank">pdf</a>]

<h2>Objective Class-based Micro-Expression Recognition through Simultaneous Action Unit Detection and Feature Aggregation. (arXiv:2012.13148v1 [cs.CV])</h2>
<h3>Ling Zhou, Qirong Mao, Ming Dong</h3>
<p>Micro-expression recognition (MER) has attracted lots of researchers'
attention due to its potential value in many practical applications. In this
paper, we investigate Micro-Expression Recognition (MER) is a challenging task
as the subtle changes occur over different action regions of a face. Changes in
facial action regions are formed as Action Units (AUs), and AUs in
micro-expressions can be seen as the actors in cooperative group activities. In
this paper, we propose a novel deep neural network model for objective
class-based MER, which simultaneously detects AUs and aggregates AU-level
features into micro-expression-level representation through Graph Convolutional
Networks (GCN). Specifically, we propose two new strategies in our AU detection
module for more effective AU feature learning: the attention mechanism and the
balanced detection loss function. With those two strategies, features are
learned for all the AUs in a unified model, eliminating the error-prune
landmark detection process and tedious separate training for each AU. Moreover,
our model incorporates a tailored objective class-based AU knowledge-graph,
which facilitates the GCN to aggregate the AU-level features into a
micro-expression-level feature representation. Extensive experiments on two
tasks in MEGC 2018 show that our approach significantly outperforms the current
state-of-the-arts in MER. Additionally, we also report our single model-based
micro-expression AU detection results.
</p>
<a href="http://arxiv.org/abs/2012.13148" target="_blank">arXiv:2012.13148</a> [<a href="http://arxiv.org/pdf/2012.13148" target="_blank">pdf</a>]

<h2>Unsupervised neural adaptation model based on optimal transport for spoken language identification. (arXiv:2012.13152v1 [cs.LG])</h2>
<h3>Xugang Lu, Peng Shen, Yu Tsao, Hisashi Kawai</h3>
<p>Due to the mismatch of statistical distributions of acoustic speech between
training and testing sets, the performance of spoken language identification
(SLID) could be drastically degraded. In this paper, we propose an unsupervised
neural adaptation model to deal with the distribution mismatch problem for
SLID. In our model, we explicitly formulate the adaptation as to reduce the
distribution discrepancy on both feature and classifier for training and
testing data sets. Moreover, inspired by the strong power of the optimal
transport (OT) to measure distribution discrepancy, a Wasserstein distance
metric is designed in the adaptation loss. By minimizing the classification
loss on the training data set with the adaptation loss on both training and
testing data sets, the statistical distribution difference between training and
testing domains is reduced. We carried out SLID experiments on the oriental
language recognition (OLR) challenge data corpus where the training and testing
data sets were collected from different conditions. Our results showed that
significant improvements were achieved on the cross domain test tasks.
</p>
<a href="http://arxiv.org/abs/2012.13152" target="_blank">arXiv:2012.13152</a> [<a href="http://arxiv.org/pdf/2012.13152" target="_blank">pdf</a>]

<h2>Adversarial Momentum-Contrastive Pre-Training. (arXiv:2012.13154v1 [cs.CV])</h2>
<h3>Cong Xu, Min Yang</h3>
<p>Deep neural networks are vulnerable to semantic invariant corruptions and
imperceptible artificial perturbations. Although data augmentation can improve
the robustness against the former, it offers no guarantees against the latter.
Adversarial training, on the other hand, is quite the opposite. Recent studies
have shown that adversarial self-supervised pre-training is helpful to extract
the invariant representations under both data augmentations and adversarial
perturbations. Based on the MoCo's idea, this paper proposes a novel
adversarial momentum-contrastive (AMOC) pre-training approach, which designs
two dynamic memory banks to maintain the historical clean and adversarial
representations respectively, so as to exploit the discriminative
representations that are consistent in a long period. Compared with the
existing self-supervised pre-training approaches, AMOC can use a smaller batch
size and fewer training epochs but learn more robust features. Empirical
results show that the developed approach further improves the current
state-of-the-art adversarial robustness.
</p>
<a href="http://arxiv.org/abs/2012.13154" target="_blank">arXiv:2012.13154</a> [<a href="http://arxiv.org/pdf/2012.13154" target="_blank">pdf</a>]

<h2>Tunnel Facility-based Vehicle Localization in Highway Tunnel using 3D LIDAR. (arXiv:2012.13168v1 [cs.RO])</h2>
<h3>Kyuwon Kim, Junhyuck Im, Gyuin Jee</h3>
<p>Vehicle localization in highway tunnels is a challenging issue for autonomous
vehicle navigation. Since GPS signals from satellites cannot be received inside
a highway tunnel, map-aided localization is essential. However, the environment
around the tunnel is composed mostly of an elliptical wall. Thereby, the unique
feature points for map matching are few unlike the case outdoors. As a result,
it is a very difficult condition to perform vehicle navigation in the tunnel
with existing map-aided localization. In this paper, we propose tunnel
facility-based precise vehicle localization in highway tunnels using 3D LIDAR.
For vehicle localization in a highway tunnel, a point landmark map that stores
the center points of tunnel facilities and a probability distribution map that
stores the probability distributions of the lane markings are used. Point
landmark-based localization is possible regardless of the number of feature
points, if only representative points of an object can be extracted. Therefore,
it is a suitable localization method for highway tunnels where the feature
points are few. The tunnel facility points were extracted using 3D LIDAR.
Position estimation is conducted using an EKF-based navigation filter. The
proposed localization algorithm is verified through experiments using actual
highway driving data. The experimental results verify that the tunnel
facility-based vehicle localization yields precise results in real time.
</p>
<a href="http://arxiv.org/abs/2012.13168" target="_blank">arXiv:2012.13168</a> [<a href="http://arxiv.org/pdf/2012.13168" target="_blank">pdf</a>]

<h2>SCC: an efficient deep reinforcement learning agent mastering the game of StarCraft II. (arXiv:2012.13169v1 [cs.LG])</h2>
<h3>Xiangjun Wang, Junxiao Song, Penghui Qi, Peng Peng, Zhenkun Tang, Wei Zhang, Weimin Li, Xiongjun Pi, Jujie He, Chao Gao, Haitao Long, Quan Yuan</h3>
<p>AlphaStar, the AI that reaches GrandMaster level in StarCraft II, is a
remarkable milestone demonstrating what deep reinforcement learning can achieve
in complex Real-Time Strategy (RTS) games. However, the complexities of the
game, algorithms and systems, and especially the tremendous amount of
computation needed are big obstacles for the community to conduct further
research in this direction. We propose a deep reinforcement learning agent,
StarCraft Commander (SCC). With order of magnitude less computation, it
demonstrates top human performance defeating GrandMaster players in test
matches and top professional players in a live event. Moreover, it shows strong
robustness to various human strategies and discovers novel strategies unseen
from human plays. In this paper, we will share the key insights and
optimizations on efficient imitation learning and reinforcement learning for
StarCraft II full game.
</p>
<a href="http://arxiv.org/abs/2012.13169" target="_blank">arXiv:2012.13169</a> [<a href="http://arxiv.org/pdf/2012.13169" target="_blank">pdf</a>]

<h2>Unveiling Real-Life Effects of Online Photo Sharing. (arXiv:2012.13180v1 [cs.CV])</h2>
<h3>Van-Khoa Nguyen, Adrian Popescu, Jerome Deshayes-Chossart</h3>
<p>Social networks give free access to their services in exchange for the right
to exploit their users' data. Data sharing is done in an initial context which
is chosen by the users. However, data are used by social networks and third
parties in different contexts which are often not transparent. We propose a new
approach which unveils potential effects of data sharing in impactful real-life
situations. Focus is put on visual content because of its strong influence in
shaping online user profiles. The approach relies on three components: (1) a
set of concepts with associated situation impact ratings obtained by
crowdsourcing, (2) a corresponding set of object detectors used to analyze
users' photos and (3) a ground truth dataset made of 500 visual user profiles
which are manually rated for each situation. These components are combined in
LERVUP, a method which learns to rate visual user profiles in each situation.
LERVUP exploits a new image descriptor which aggregates concept ratings and
object detections at user level. It also uses an attention mechanism to boost
the detections of highly-rated concepts to prevent them from being overwhelmed
by low-rated ones. Performance is evaluated per situation by measuring the
correlation between the automatic ranking of profile ratings and a manual
ground truth. Results indicate that LERVUP is effective since a strong
correlation of the two rankings is obtained. This finding indicates that
providing meaningful automatic situation-related feedback about the effects of
data sharing is feasible.
</p>
<a href="http://arxiv.org/abs/2012.13180" target="_blank">arXiv:2012.13180</a> [<a href="http://arxiv.org/pdf/2012.13180" target="_blank">pdf</a>]

<h2>Simulation of Vision-based Tactile Sensors using Physics based Rendering. (arXiv:2012.13184v1 [cs.RO])</h2>
<h3>Arpit Agarwal, Tim Man, Wenzhen Yuan</h3>
<p>Tactile sensing has seen rapid adoption with the advent of vision-based
tactile sensors. Vision-based tactile sensors provide high resolution, compact
and inexpensive data to perform precise in-hand manipulation and robot-human
interaction. However, the simulation of tactile sensors is still a challenge.
In this paper, we built the first fully general optical tactile simulation
system for GelSight using physics-based rendering techniques. We propose
physically accurate light models and show in-depth analysis of individual
components of our simulation pipeline. Our system outperforms previous
simulation techniques qualitatively and quantitative on image similarity
metrics.
</p>
<a href="http://arxiv.org/abs/2012.13184" target="_blank">arXiv:2012.13184</a> [<a href="http://arxiv.org/pdf/2012.13184" target="_blank">pdf</a>]

<h2>Control of computer pointer using hand gesture recognition in motion pictures. (arXiv:2012.13188v1 [cs.CV])</h2>
<h3>Yalda Foroutan, Ahmad Kalhor, Saeid Mohammadi Nejati, Samad Sheikhaei</h3>
<p>A user interface is designed to control the computer cursor by hand detection
and classification of its gesture. A hand dataset with 6720 image samples is
collected, including four classes: fist, palm, pointing to the left, and
pointing to the right. The images are captured from 15 persons in simple
backgrounds and different perspectives and light conditions. A CNN network is
trained on this dataset to predict a label for each captured image and measure
the similarity of them. Finally, commands are defined to click, right-click and
move the cursor. The algorithm has 91.88% accuracy and can be used in different
backgrounds.
</p>
<a href="http://arxiv.org/abs/2012.13188" target="_blank">arXiv:2012.13188</a> [<a href="http://arxiv.org/pdf/2012.13188" target="_blank">pdf</a>]

<h2>Appearance-Invariant 6-DoF Visual Localization using Generative Adversarial Networks. (arXiv:2012.13191v1 [cs.CV])</h2>
<h3>Yimin Lin, Jianfeng Huang, Shiguo Lian</h3>
<p>We propose a novel visual localization network when outside environment has
changed such as different illumination, weather and season. The visual
localization network is composed of a feature extraction network and pose
regression network. The feature extraction network is made up of an encoder
network based on the Generative Adversarial Network CycleGAN, which can capture
intrinsic appearance-invariant feature maps from unpaired samples of different
weathers and seasons. With such an invariant feature, we use a 6-DoF pose
regression network to tackle long-term visual localization in the presence of
outdoor illumination, weather and season changes. A variety of challenging
datasets for place recognition and localization are used to prove our visual
localization network, and the results show that our method outperforms
state-of-the-art methods in the scenarios with various environment changes.
</p>
<a href="http://arxiv.org/abs/2012.13191" target="_blank">arXiv:2012.13191</a> [<a href="http://arxiv.org/pdf/2012.13191" target="_blank">pdf</a>]

<h2>RBM-Flow and D-Flow: Invertible Flows with Discrete Energy Base Spaces. (arXiv:2012.13196v1 [cs.LG])</h2>
<h3>Daniel O&#x27;Connor, Walter Vinci</h3>
<p>Efficient sampling of complex data distributions can be achieved using
trained invertible flows (IF), where the model distribution is generated by
pushing a simple base distribution through multiple non-linear bijective
transformations. However, the iterative nature of the transformations in IFs
can limit the approximation to the target distribution. In this paper we seek
to mitigate this by implementing RBM-Flow, an IF model whose base distribution
is a Restricted Boltzmann Machine (RBM) with a continuous smoothing applied. We
show that by using RBM-Flow we are able to improve the quality of samples
generated, quantified by the Inception Scores (IS) and Frechet Inception
Distance (FID), over baseline models with the same IF transformations, but with
less expressive base distributions. Furthermore, we also obtain D-Flow, an IF
model with uncorrelated discrete latent variables. We show that D-Flow achieves
similar likelihoods and FID/IS scores to those of a typical IF with Gaussian
base variables, but with the additional benefit that global features are
meaningfully encoded as discrete labels in the latent space.
</p>
<a href="http://arxiv.org/abs/2012.13196" target="_blank">arXiv:2012.13196</a> [<a href="http://arxiv.org/pdf/2012.13196" target="_blank">pdf</a>]

<h2>Predicting Seminal Quality with the Dominance-Based Rough Sets Approach. (arXiv:2012.13204v1 [cs.AI])</h2>
<h3>Nassim Dehouche</h3>
<p>The paper relies on the clinical data of a previously published study. We
identify two very questionable assumptions of said work, namely confusing
evidence of absence and absence of evidence, and neglecting the ordinal nature
of attributes' domains. We then show that using an adequate ordinal methodology
such as the dominance-based rough sets approach (DRSA) can significantly
improve the predictive accuracy of the expert system, resulting in almost
complete accuracy for a dataset of 100 instances. Beyond the performance of
DRSA in solving the diagnosis problem at hand, these results suggest the
inadequacy and triviality of the underlying dataset. We provide links to open
data from the UCI machine learning repository to allow for an easy
verification/refutation of the claims made in this paper.
</p>
<a href="http://arxiv.org/abs/2012.13204" target="_blank">arXiv:2012.13204</a> [<a href="http://arxiv.org/pdf/2012.13204" target="_blank">pdf</a>]

<h2>Effective Deployment of CNNs for 3DoF Pose Estimation and Grasping in Industrial Settings. (arXiv:2012.13210v1 [cs.RO])</h2>
<h3>Daniele De Gregorio, Riccardo Zanella, Gianluca Palli, Luigi Di Stefano</h3>
<p>In this paper we investigate how to effectively deploy deep learning in
practical industrial settings, such as robotic grasping applications. When a
deep-learning based solution is proposed, usually lacks of any simple method to
generate the training data. In the industrial field, where automation is the
main goal, not bridging this gap is one of the main reasons why deep learning
is not as widespread as it is in the academic world. For this reason, in this
work we developed a system composed by a 3-DoF Pose Estimator based on
Convolutional Neural Networks (CNNs) and an effective procedure to gather
massive amounts of training images in the field with minimal human
intervention. By automating the labeling stage, we also obtain very robust
systems suitable for production-level usage. An open source implementation of
our solution is provided, alongside with the dataset used for the experimental
evaluation.
</p>
<a href="http://arxiv.org/abs/2012.13210" target="_blank">arXiv:2012.13210</a> [<a href="http://arxiv.org/pdf/2012.13210" target="_blank">pdf</a>]

<h2>Memory-Efficient Hierarchical Neural Architecture Search for Image Restoration. (arXiv:2012.13212v1 [cs.CV])</h2>
<h3>Haokui Zhang, Ying Li, Chengrong Gong, Hao Chen, Zongwen Bai, Chunhua Shen</h3>
<p>Recently, much attention has been spent on neural architecture search (NAS)
approaches, which often outperform manually designed architectures on highlevel
vision tasks. Inspired by this, we attempt to leverage NAS technique to
automatically design efficient network architectures for low-level image
restoration tasks. In this paper, we propose a memory-efficient hierarchical
NAS HiNAS (HiNAS) and apply to two such tasks: image denoising and image
super-resolution. HiNAS adopts gradient based search strategies and builds an
flexible hierarchical search space, including inner search space and outer
search space, which in charge of designing cell architectures and deciding cell
widths, respectively. For inner search space, we propose layerwise architecture
sharing strategy (LWAS), resulting in more flexible architectures and better
performance. For outer search space, we propose cell sharing strategy to save
memory, and considerably accelerate the search speed. The proposed HiNAS is
both memory and computation efficient. With a single GTX1080Ti GPU, it takes
only about 1 hour for searching for denoising network on BSD 500 and 3.5 hours
for searching for the super-resolution structure on DIV2K. Experimental results
show that the architectures found by HiNAS have fewer parameters and enjoy a
faster inference speed, while achieving highly competitive performance compared
with state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.13212" target="_blank">arXiv:2012.13212</a> [<a href="http://arxiv.org/pdf/2012.13212" target="_blank">pdf</a>]

<h2>Dynamic Facial Expression Recognition under Partial Occlusion with Optical Flow Reconstruction. (arXiv:2012.13217v1 [cs.CV])</h2>
<h3>Delphine Poux, Benjamin Allaert, Nacim Ihaddadene, Ioan Marius Bilasco, Chaabane Djeraba, Mohammed Bennamoun</h3>
<p>Video facial expression recognition is useful for many applications and
received much interest lately. Although some solutions give really good results
in a controlled environment (no occlusion), recognition in the presence of
partial facial occlusion remains a challenging task. To handle occlusions,
solutions based on the reconstruction of the occluded part of the face have
been proposed. These solutions are mainly based on the texture or the geometry
of the face. However, the similarity of the face movement between different
persons doing the same expression seems to be a real asset for the
reconstruction. In this paper we exploit this asset and propose a new solution
based on an auto-encoder with skip connections to reconstruct the occluded part
of the face in the optical flow domain. To the best of our knowledge, this is
the first proposition to directly reconstruct the movement for facial
expression recognition. We validated our approach in the controlled dataset CK+
on which different occlusions were generated. Our experiments show that the
proposed method reduce significantly the gap, in terms of recognition accuracy,
between occluded and non-occluded situations. We also compare our approach with
existing state-of-the-art solutions. In order to lay the basis of a
reproducible and fair comparison in the future, we also propose a new
experimental protocol that includes occlusion generation and reconstruction
evaluation.
</p>
<a href="http://arxiv.org/abs/2012.13217" target="_blank">arXiv:2012.13217</a> [<a href="http://arxiv.org/pdf/2012.13217" target="_blank">pdf</a>]

<h2>Towards a Formal Framework for Partial Compliance of Business Processes. (arXiv:2012.13219v1 [cs.AI])</h2>
<h3>Ho-Pun Lam, Mustafa Hashmi, Akhil Kumar</h3>
<p>Binary "YES-NO" notions of process compliance are not very helpful to
managers for assessing the operational performance of their company because a
large number of cases fall in the grey area of partial compliance. Hence, it is
necessary to have ways to quantify partial compliance in terms of metrics and
be able to classify actual cases by assigning a numeric value of compliance to
them. In this paper, we formulate an evaluation framework to quantify the level
of compliance of business processes across different levels of abstraction
(such as task,trace and process level) and across multiple dimensions of each
task (such as temporal, monetary, role-, data-, and quality-related) to provide
managers more useful information about their operations and to help them
improve their decision making processes. Our approach can also add social value
by making social services provided by local, state and federal governments more
flexible and improving the lives of citizens.
</p>
<a href="http://arxiv.org/abs/2012.13219" target="_blank">arXiv:2012.13219</a> [<a href="http://arxiv.org/pdf/2012.13219" target="_blank">pdf</a>]

<h2>On Batch Normalisation for Approximate Bayesian Inference. (arXiv:2012.13220v1 [cs.LG])</h2>
<h3>Jishnu Mukhoti, Puneet K. Dokania, Philip H.S. Torr, Yarin Gal</h3>
<p>We study batch normalisation in the context of variational inference methods
in Bayesian neural networks, such as mean-field or MC Dropout. We show that
batch-normalisation does not affect the optimum of the evidence lower bound
(ELBO). Furthermore, we study the Monte Carlo Batch Normalisation (MCBN)
algorithm, proposed as an approximate inference technique parallel to MC
Dropout, and show that for larger batch sizes, MCBN fails to capture epistemic
uncertainty. Finally, we provide insights into what is required to fix this
failure, namely having to view the mini-batch size as a variational parameter
in MCBN. We comment on the asymptotics of the ELBO with respect to this
variational parameter, showing that as dataset size increases towards infinity,
the batch-size must increase towards infinity as well for MCBN to be a valid
approximate inference technique.
</p>
<a href="http://arxiv.org/abs/2012.13220" target="_blank">arXiv:2012.13220</a> [<a href="http://arxiv.org/pdf/2012.13220" target="_blank">pdf</a>]

<h2>Path Planning of Unmanned System using Carrot-chasing Algorithm. (arXiv:2012.13227v1 [cs.RO])</h2>
<h3>Rahul Bhadani</h3>
<p>When an unmanned system is launched for a mission-critical task, it is
required to follow a predetermined path. It means the unmanned system requires
a path following algorithm for the completion of the mission. Since the
predetermined path is typically given by a set of data-points, not only the
curvature and derivative of the pre-determined path are absent, but also it
requires a large size of on-board memory. In this work, we study a simple path
following algorithm called Carrot-chasing algorithm that uses a simple
controller in the form of a proportional controller to control the movement of
an unmanned system.
</p>
<a href="http://arxiv.org/abs/2012.13227" target="_blank">arXiv:2012.13227</a> [<a href="http://arxiv.org/pdf/2012.13227" target="_blank">pdf</a>]

<h2>Pain Assessment based on fNIRS using Bidirectional LSTMs. (arXiv:2012.13231v1 [cs.LG])</h2>
<h3>Raul Fernandez Rojas, Julio Romero, Jehu Lopez-Aparicio, Keng-Liang Ou</h3>
<p>Assessing pain in patients unable to speak (also called non-verbal patients)
is extremely complicated and often is done by clinical judgement. However, this
method is not reliable since patients vital signs can fluctuate significantly
due to other underlying medical conditions. No objective diagnosis test exists
to date that can assist medical practitioners in the diagnosis of pain. In this
study we propose the use of functional near-infrared spectroscopy (fNIRS) and
deep learning for the assessment of human pain. The aim of this study is to
explore the use deep learning to automatically learn features from fNIRS raw
data to reduce the level of subjectivity and domain knowledge required in the
design of hand-crafted features. Four deep learning models were evaluated,
multilayer perceptron (MLP), forward and backward long short-term memory
net-works (LSTM), and bidirectional LSTM. The results showed that the Bi-LSTM
model achieved the highest accuracy (90.6%)and faster than the other three
models. These results advance knowledge in pain assessment using neuroimaging
as a method of diagnosis and represent a step closer to developing a
physiologically based diagnosis of human pain that will benefit vulnerable
populations who cannot self-report pain.
</p>
<a href="http://arxiv.org/abs/2012.13231" target="_blank">arXiv:2012.13231</a> [<a href="http://arxiv.org/pdf/2012.13231" target="_blank">pdf</a>]

<h2>Deep Semi-Supervised Embedded Clustering (DSEC) for Stratification of Heart Failure Patients. (arXiv:2012.13233v1 [cs.LG])</h2>
<h3>Oliver Carr, Stojan Jovanovic, Luca Albergante, Fernando Andreotti, Robert D&#xfc;richen, Nadia Lipunova, Janie Baxter, Rabia Khan, Benjamin Irving</h3>
<p>Determining phenotypes of diseases can have considerable benefits for
in-hospital patient care and to drug development. The structure of high
dimensional data sets such as electronic health records are often represented
through an embedding of the data, with clustering methods used to group data of
similar structure. If subgroups are known to exist within data, supervised
methods may be used to influence the clusters discovered. We propose to extend
deep embedded clustering to a semi-supervised deep embedded clustering
algorithm to stratify subgroups through known labels in the data. In this work
we apply deep semi-supervised embedded clustering to determine data-driven
patient subgroups of heart failure from the electronic health records of 4,487
heart failure and control patients. We find clinically relevant clusters from
an embedded space derived from heterogeneous data. The proposed algorithm can
potentially find new undiagnosed subgroups of patients that have different
outcomes, and, therefore, lead to improved treatments.
</p>
<a href="http://arxiv.org/abs/2012.13233" target="_blank">arXiv:2012.13233</a> [<a href="http://arxiv.org/pdf/2012.13233" target="_blank">pdf</a>]

<h2>Detecting Hateful Memes Using a Multimodal Deep Ensemble. (arXiv:2012.13235v1 [cs.LG])</h2>
<h3>Vlad Sandulescu</h3>
<p>While significant progress has been made using machine learning algorithms to
detect hate speech, important technical challenges still remain to be solved in
order to bring their performance closer to human accuracy. We investigate
several of the most recent visual-linguistic Transformer architectures and
propose improvements to increase their performance for this task. The proposed
model outperforms the baselines by a large margin and ranks 5$^{th}$ on the
leaderboard out of 3,100+ participants.
</p>
<a href="http://arxiv.org/abs/2012.13235" target="_blank">arXiv:2012.13235</a> [<a href="http://arxiv.org/pdf/2012.13235" target="_blank">pdf</a>]

<h2>Robotic Following of Flexible Extended Objects: Relevant Technical Facts on the Kinematics of a Moving Continuum. (arXiv:2012.13240v1 [cs.RO])</h2>
<h3>A.S. Matveev, V.V. Magerkin</h3>
<p>The paper offers general technical facts on the kinematics of a moving
continuum involved in research on robotic following of flexible extended
objects.
</p>
<a href="http://arxiv.org/abs/2012.13240" target="_blank">arXiv:2012.13240</a> [<a href="http://arxiv.org/pdf/2012.13240" target="_blank">pdf</a>]

<h2>Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder. (arXiv:2012.13253v1 [cs.LG])</h2>
<h3>Tal Daniel, Aviv Tamar</h3>
<p>The recently introduced introspective variational autoencoder (IntroVAE)
exhibits outstanding image generations, and allows for amortized inference
using an image encoder. The main idea in IntroVAE is to train a VAE
adversarially, using the VAE encoder to discriminate between generated and real
data samples. However, the original IntroVAE loss function relied on a
particular hinge-loss formulation that is very hard to stabilize in practice,
and its theoretical convergence analysis ignored important terms in the loss.
In this work, we take a step towards better understanding of the IntroVAE
model, its practical implementation, and its applications. We propose the
Soft-IntroVAE, a modified IntroVAE that replaces the hinge-loss terms with a
smooth exponential loss on generated samples. This change significantly
improves training stability, and also enables theoretical analysis of the
complete algorithm. Interestingly, we show that the IntroVAE converges to a
distribution that minimizes a sum of KL distance from the data distribution and
an entropy term. We discuss the implications of this result, and demonstrate
that it induces competitive image generation and reconstruction. Finally, we
describe two applications of Soft-IntroVAE to unsupervised image translation
and out-of-distribution detection, and demonstrate compelling results. Code and
additional information is available on the project website --
https://taldatech.github.io/soft-intro-vae-web
</p>
<a href="http://arxiv.org/abs/2012.13253" target="_blank">arXiv:2012.13253</a> [<a href="http://arxiv.org/pdf/2012.13253" target="_blank">pdf</a>]

<h2>Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning. (arXiv:2012.13255v1 [cs.LG])</h2>
<h3>Armen Aghajanyan, Luke Zettlemoyer, Sonal Gupta</h3>
<p>Although pretrained language models can be fine-tuned to produce
state-of-the-art results for a very wide range of language understanding tasks,
the dynamics of this process are not well understood, especially in the low
data regime. Why can we use relatively vanilla gradient descent algorithms
(e.g., without strong regularization) to tune a model with hundreds of millions
of parameters on datasets with only hundreds or thousands of labeled examples?
In this paper, we argue that analyzing fine-tuning through the lens of
intrinsic dimension provides us with empirical and theoretical intuitions to
explain this remarkable phenomenon. We empirically show that common pre-trained
models have a very low intrinsic dimension; in other words, there exists a low
dimension reparameterization that is as effective for fine-tuning as the full
parameter space. For example, by optimizing only 200 trainable parameters
randomly projected back into the full space, we can tune a RoBERTa model to
achieve 90\% of the full parameter performance levels on MRPC. Furthermore, we
empirically show that pre-training implicitly minimizes intrinsic dimension
and, perhaps surprisingly, larger models tend to have lower intrinsic dimension
after a fixed number of pre-training updates, at least in part explaining their
extreme effectiveness. Lastly, we connect intrinsic dimensionality with low
dimensional task representations and compression based generalization bounds to
provide intrinsic-dimension-based generalization bounds that are independent of
the full parameter count.
</p>
<a href="http://arxiv.org/abs/2012.13255" target="_blank">arXiv:2012.13255</a> [<a href="http://arxiv.org/pdf/2012.13255" target="_blank">pdf</a>]

<h2>Interpolating Points on a Non-Uniform Grid using a Mixture of Gaussians. (arXiv:2012.13257v1 [cs.CV])</h2>
<h3>Ivan Skorokhodov</h3>
<p>In this work, we propose an approach to perform non-uniform image
interpolation based on a Gaussian Mixture Model. Traditional image
interpolation methods, like nearest neighbor, bilinear, Hamming, Lanczos, etc.
assume that the coordinates you want to interpolate from, are positioned on a
uniform grid. However, it is not always the case in practice and we develop an
interpolation method that is able to generate an image from arbitrarily
positioned pixel values. We do this by representing each known pixel as a 2D
normal distribution and considering each output image pixel as a sample from
the mixture of all the known ones. Apart from the ability to reconstruct an
image from arbitrarily positioned set of pixels, this also allows us to
differentiate through the interpolation procedure, which might be helpful for
downstream applications. Our optimized CUDA kernel and the source code to
reproduce the benchmarks is located at
https://github.com/universome/non-uniform-interpolation.
</p>
<a href="http://arxiv.org/abs/2012.13257" target="_blank">arXiv:2012.13257</a> [<a href="http://arxiv.org/pdf/2012.13257" target="_blank">pdf</a>]

<h2>Seed Phenotyping on Neural Networks using Domain Randomization and Transfer Learning. (arXiv:2012.13259v1 [cs.CV])</h2>
<h3>Venkat Margapuri, Mitchell Neilsen</h3>
<p>Seed phenotyping is the idea of analyzing the morphometric characteristics of
a seed to predict the behavior of the seed in terms of development, tolerance
and yield in various environmental conditions. The focus of the work is the
application and feasibility analysis of the state-of-the-art object detection
and localization neural networks, Mask R-CNN and YOLO (You Only Look Once), for
seed phenotyping using Tensorflow. One of the major bottlenecks of such an
endeavor is the need for large amounts of training data. While the capture of a
multitude of seed images is taunting, the images are also required to be
annotated to indicate the boundaries of the seeds on the image and converted to
data formats that the neural networks are able to consume. Although tools to
manually perform the task of annotation are available for free, the amount of
time required is enormous. In order to tackle such a scenario, the idea of
domain randomization i.e. the technique of applying models trained on images
containing simulated objects to real-world objects, is considered. In addition,
transfer learning i.e. the idea of applying the knowledge obtained while
solving a problem to a different problem, is used. The networks are trained on
pre-trained weights from the popular ImageNet and COCO data sets. As part of
the work, experiments with different parameters are conducted on five different
seed types namely, canola, rough rice, sorghum, soy, and wheat.
</p>
<a href="http://arxiv.org/abs/2012.13259" target="_blank">arXiv:2012.13259</a> [<a href="http://arxiv.org/pdf/2012.13259" target="_blank">pdf</a>]

<h2>Learning Vehicle Routing Problems using Policy Optimisation. (arXiv:2012.13269v1 [cs.LG])</h2>
<h3>Nasrin Sultana, Jeffrey Chan, A. K. Qin, Tabinda Sarwar</h3>
<p>Deep reinforcement learning (DRL) has been used to learn effective heuristics
for solving complex combinatorial optimisation problem via policy networks and
have demonstrated promising performance. Existing works have focused on solving
(vehicle) routing problems as they have a nice balance between non-triviality
and difficulty. State-of-the-art approaches learn a policy using reinforcement
learning, and the learnt policy acts as a pseudo solver. These approaches have
demonstrated good performance in some cases, but given the large search space
typical combinatorial/routing problem, they can converge too quickly to poor
policy. To prevent this, in this paper, we propose an approach name entropy
regularised reinforcement learning (ERRL) that supports exploration by
providing more stochastic policies, which tends to improve optimisation.
Empirically, the low variance ERRL offers RL training fast and stable. We also
introduce a combination of local search operators during test time, which
significantly improves solution and complement ERRL. We qualitatively
demonstrate that for vehicle routing problems, a policy with higher entropy can
make the optimisation landscape smooth which makes it easier to optimise. The
quantitative evaluation shows that the performance of the model is comparable
with the state-of-the-art variants. In our evaluation, we experimentally
illustrate that the model produces state-of-the-art performance on variants of
Vehicle Routing problems such as Capacitated Vehicle Routing Problem (CVRP),
Multiple Routing with Fixed Fleet Problems (MRPFF) and Travelling Salesman
problem.
</p>
<a href="http://arxiv.org/abs/2012.13269" target="_blank">arXiv:2012.13269</a> [<a href="http://arxiv.org/pdf/2012.13269" target="_blank">pdf</a>]

<h2>Multi-fidelity Bayesian Neural Networks: Algorithms and Applications. (arXiv:2012.13294v1 [cs.LG])</h2>
<h3>Xuhui Meng, Hessam Babaee, George Em Karniadakis</h3>
<p>We propose a new class of Bayesian neural networks (BNNs) that can be trained
using noisy data of variable fidelity, and we apply them to learn function
approximations as well as to solve inverse problems based on partial
differential equations (PDEs). These multi-fidelity BNNs consist of three
neural networks: The first is a fully connected neural network, which is
trained following the maximum a posteriori probability (MAP) method to fit the
low-fidelity data; the second is a Bayesian neural network employed to capture
the cross-correlation with uncertainty quantification between the low- and
high-fidelity data; and the last one is the physics-informed neural network,
which encodes the physical laws described by PDEs. For the training of the last
two neural networks, we use the Hamiltonian Monte Carlo method to estimate
accurately the posterior distributions for the corresponding hyperparameters.
We demonstrate the accuracy of the present method using synthetic data as well
as real measurements. Specifically, we first approximate a one- and
four-dimensional function, and then infer the reaction rates in one- and
two-dimensional diffusion-reaction systems. Moreover, we infer the sea surface
temperature (SST) in the Massachusetts and Cape Cod Bays using satellite images
and in-situ measurements. Taken together, our results demonstrate that the
present method can capture both linear and nonlinear correlation between the
low- and high-fideilty data adaptively, identify unknown parameters in PDEs,
and quantify uncertainties in predictions, given a few scattered noisy
high-fidelity data. Finally, we demonstrate that we can effectively and
efficiently reduce the uncertainties and hence enhance the prediction accuracy
with an active learning approach, using as examples a specific one-dimensional
function approximation and an inverse PDE problem.
</p>
<a href="http://arxiv.org/abs/2012.13294" target="_blank">arXiv:2012.13294</a> [<a href="http://arxiv.org/pdf/2012.13294" target="_blank">pdf</a>]

<h2>Hierarchical Planning for Resource Allocation in Emergency Response Systems. (arXiv:2012.13300v1 [cs.AI])</h2>
<h3>Geoffrey Pettet, Ayan Mukhopadhyay, Mykel Kochenderfer, Abhishek Dubey</h3>
<p>A classical problem in city-scale cyber-physical systems (CPS) is resource
allocation under uncertainty. Spatial-temporal allocation of resources is
optimized to allocate electric scooters across urban areas, place charging
stations for vehicles, and design efficient on-demand transit. Typically, such
problems are modeled as Markov (or semi-Markov) decision processes. While
online, offline, and decentralized methodologies have been used to tackle such
problems, none of the approaches scale well for large-scale decision problems.
We create a general approach to hierarchical planning that leverages structure
in city-level CPS problems to tackle resource allocation under uncertainty. We
use emergency response as a case study and show how a large resource allocation
problem can be split into smaller problems. We then create a principled
framework for solving the smaller problems and tackling the interaction between
them. Finally, we use real-world data from a major metropolitan area in the
United States to validate our approach. Our experiments show that the proposed
approach outperforms state-of-the-art approaches used in the field of emergency
response.
</p>
<a href="http://arxiv.org/abs/2012.13300" target="_blank">arXiv:2012.13300</a> [<a href="http://arxiv.org/pdf/2012.13300" target="_blank">pdf</a>]

<h2>Leave Zero Out: Towards a No-Cross-Validation Approach for Model Selection. (arXiv:2012.13309v1 [cs.LG])</h2>
<h3>Weikai Li, Chuanxing Geng, Songcan Chen</h3>
<p>As the main workhorse for model selection, Cross Validation (CV) has achieved
an empirical success due to its simplicity and intuitiveness. However, despite
its ubiquitous role, CV often falls into the following notorious dilemmas. On
the one hand, for small data cases, CV suffers a conservatively biased
estimation, since some part of the limited data has to hold out for validation.
On the other hand, for large data cases, CV tends to be extremely cumbersome,
e.g., intolerant time-consuming, due to the repeated training procedures.
Naturally, a straightforward ambition for CV is to validate the models with far
less computational cost, while making full use of the entire given data-set for
training. Thus, instead of holding out the given data, a cheap and
theoretically guaranteed auxiliary/augmented validation is derived
strategically in this paper. Such an embarrassingly simple strategy only needs
to train models on the entire given data-set once, making the model-selection
considerably efficient. In addition, the proposed validation approach is
suitable for a wide range of learning settings due to the independence of both
augmentation and out-of-sample estimation on learning process. In the end, we
demonstrate the accuracy and computational benefits of our proposed method by
extensive evaluation on multiple data-sets, models and tasks.
</p>
<a href="http://arxiv.org/abs/2012.13309" target="_blank">arXiv:2012.13309</a> [<a href="http://arxiv.org/pdf/2012.13309" target="_blank">pdf</a>]

<h2>Variational Determinant Estimation with Spherical Normalizing Flows. (arXiv:2012.13311v1 [cs.LG])</h2>
<h3>Simon Passenheim, Emiel Hoogeboom</h3>
<p>This paper introduces the Variational Determinant Estimator (VDE), a
variational extension of the recently proposed determinant estimator discovered
by arXiv:2005.06553v2. Our estimator significantly reduces the variance even
for low sample sizes by combining (importance-weighted) variational inference
and a family of normalizing flows which allow density estimation on
hyperspheres.
</p>
<a href="http://arxiv.org/abs/2012.13311" target="_blank">arXiv:2012.13311</a> [<a href="http://arxiv.org/pdf/2012.13311" target="_blank">pdf</a>]

<h2>Generalization in portfolio-based algorithm selection. (arXiv:2012.13315v1 [cs.AI])</h2>
<h3>Maria-Florina Balcan, Tuomas Sandholm, Ellen Vitercik</h3>
<p>Portfolio-based algorithm selection has seen tremendous practical success
over the past two decades. This algorithm configuration procedure works by
first selecting a portfolio of diverse algorithm parameter settings, and then,
on a given problem instance, using an algorithm selector to choose a parameter
setting from the portfolio with strong predicted performance. Oftentimes, both
the portfolio and the algorithm selector are chosen using a training set of
typical problem instances from the application domain at hand. In this paper,
we provide the first provable guarantees for portfolio-based algorithm
selection. We analyze how large the training set should be to ensure that the
resulting algorithm selector's average performance over the training set is
close to its future (expected) performance. This involves analyzing three key
reasons why these two quantities may diverge: 1) the learning-theoretic
complexity of the algorithm selector, 2) the size of the portfolio, and 3) the
learning-theoretic complexity of the algorithm's performance as a function of
its parameters. We introduce an end-to-end learning-theoretic analysis of the
portfolio construction and algorithm selection together. We prove that if the
portfolio is large, overfitting is inevitable, even with an extremely simple
algorithm selector. With experiments, we illustrate a tradeoff exposed by our
theoretical analysis: as we increase the portfolio size, we can hope to include
a well-suited parameter setting for every possible problem instance, but it
becomes impossible to avoid overfitting.
</p>
<a href="http://arxiv.org/abs/2012.13315" target="_blank">arXiv:2012.13315</a> [<a href="http://arxiv.org/pdf/2012.13315" target="_blank">pdf</a>]

<h2>Person Re-Identification using Deep Learning Networks: A Systematic Review. (arXiv:2012.13318v1 [cs.CV])</h2>
<h3>Ankit Yadav, Dinesh Kumar Vishwakarma</h3>
<p>Person re-identification has received a lot of attention from the research
community in recent times. Due to its vital role in security based
applications, person re-identification lies at the heart of research relevant
to tracking robberies, preventing terrorist attacks and other security critical
events. While the last decade has seen tremendous growth in re-id approaches,
very little review literature exists to comprehend and summarize this progress.
This review deals with the latest state-of-the-art deep learning based
approaches for person re-identification. While the few existing re-id review
works have analysed re-id techniques from a singular aspect, this review
evaluates numerous re-id techniques from multiple deep learning aspects such as
deep architecture types, common Re-Id challenges (variation in pose, lightning,
view, scale, partial or complete occlusion, background clutter), multi-modal
Re-Id, cross-domain Re-Id challenges, metric learning approaches and video
Re-Id contributions. This review also includes several re-id benchmarks
collected over the years, describing their characteristics, specifications and
top re-id results obtained on them. The inclusion of the latest deep re-id
works makes this a significant contribution to the re-id literature. Lastly,
the conclusion and future directions are included.
</p>
<a href="http://arxiv.org/abs/2012.13318" target="_blank">arXiv:2012.13318</a> [<a href="http://arxiv.org/pdf/2012.13318" target="_blank">pdf</a>]

<h2>Evolutionary Gait Transfer of Multi-Legged Robots in Complex Terrains. (arXiv:2012.13320v1 [cs.RO])</h2>
<h3>Min Jiang, Guokun Chi, Geqiang Pan, Shihui Guo, Kay Chen Tan</h3>
<p>Robot gait optimization is the task of generating an optimal control
trajectory under various internal and external constraints. Given the high
dimensions of control space, this problem is particularly challenging for
multi-legged robots walking in complex and unknown environments. Existing
literatures often regard the gait generation as an optimization problem and
solve the gait optimization from scratch for robots walking in a specific
environment. However, such approaches do not consider the use of pre-acquired
knowledge which can be useful in improving the quality and speed of motion
generation in complex environments. To address the issue, this paper proposes a
transfer learning-based evolutionary framework for multi-objective gait
optimization, named Tr-GO. The idea is to initialize a high-quality population
by using the technique of transfer learning, so any kind of population-based
optimization algorithms can be seamlessly integrated into this framework. The
advantage is that the generated gait can not only dynamically adapt to
different environments and tasks, but also simultaneously satisfy multiple
design specifications (e.g., speed, stability). The experimental results show
the effectiveness of the proposed framework for the gait optimization problem
based on three multi-objective evolutionary algorithms: NSGA-II, RM-MEDA and
MOPSO. When transferring the pre-acquired knowledge from the plain terrain to
various inclined and rugged ones, the proposed Tr-GO framework accelerates the
evolution process by a minimum of 3-4 times compared with non-transferred
scenarios.
</p>
<a href="http://arxiv.org/abs/2012.13320" target="_blank">arXiv:2012.13320</a> [<a href="http://arxiv.org/pdf/2012.13320" target="_blank">pdf</a>]

<h2>Unsupervised deep clustering and reinforcement learning can accurately segment MRI brain tumors with very small training sets. (arXiv:2012.13321v1 [cs.CV])</h2>
<h3>Joseph Stember, Hrithwik Shalu</h3>
<p>Purpose: Lesion segmentation in medical imaging is key to evaluating
treatment response. We have recently shown that reinforcement learning can be
applied to radiological images for lesion localization. Furthermore, we
demonstrated that reinforcement learning addresses important limitations of
supervised deep learning; namely, it can eliminate the requirement for large
amounts of annotated training data and can provide valuable intuition lacking
in supervised approaches. However, we did not address the fundamental task of
lesion/structure-of-interest segmentation. Here we introduce a method combining
unsupervised deep learning clustering with reinforcement learning to segment
brain lesions on MRI.

Materials and Methods: We initially clustered images using unsupervised deep
learning clustering to generate candidate lesion masks for each MRI image. The
user then selected the best mask for each of 10 training images. We then
trained a reinforcement learning algorithm to select the masks. We tested the
corresponding trained deep Q network on a separate testing set of 10 images.
For comparison, we also trained and tested a U-net supervised deep learning
network on the same set of training/testing images.

Results: Whereas the supervised approach quickly overfit the training data
and predictably performed poorly on the testing set (16% average Dice score),
the unsupervised deep clustering and reinforcement learning achieved an average
Dice score of 83%.

Conclusion: We have demonstrated a proof-of-principle application of
unsupervised deep clustering and reinforcement learning to segment brain
tumors. The approach represents human-allied AI that requires minimal input
from the radiologist without the need for hand-traced annotation.
</p>
<a href="http://arxiv.org/abs/2012.13321" target="_blank">arXiv:2012.13321</a> [<a href="http://arxiv.org/pdf/2012.13321" target="_blank">pdf</a>]

<h2>An Active Learning Method for Diabetic Retinopathy Classification with Uncertainty Quantification. (arXiv:2012.13325v1 [cs.LG])</h2>
<h3>Muhammad Ahtazaz Ahsan, Adnan Qayyum, Junaid Qadir, Adeel Razi</h3>
<p>In recent years, deep learning (DL) techniques have provided state-of-the-art
performance on different medical imaging tasks. However, the availability of
good quality annotated medical data is very challenging due to involved time
constraints and the availability of expert annotators, e.g., radiologists. In
addition, DL is data-hungry and their training requires extensive computational
resources. Another problem with DL is their black-box nature and lack of
transparency on its inner working which inhibits causal understanding and
reasoning. In this paper, we jointly address these challenges by proposing a
hybrid model, which uses a Bayesian convolutional neural network (BCNN) for
uncertainty quantification, and an active learning approach for annotating the
unlabelled data. The BCNN is used as a feature descriptor and these features
are then used for training a model, in an active learning setting. We evaluate
the proposed framework for diabetic retinopathy classification problem and have
achieved state-of-the-art performance in terms of different metrics.
</p>
<a href="http://arxiv.org/abs/2012.13325" target="_blank">arXiv:2012.13325</a> [<a href="http://arxiv.org/pdf/2012.13325" target="_blank">pdf</a>]

<h2>A Tight Lower Bound for Uniformly Stable Algorithms. (arXiv:2012.13326v1 [cs.LG])</h2>
<h3>Qinghua Liu, Zhou Lu</h3>
<p>Leveraging algorithmic stability to derive sharp generalization bounds is a
classic and powerful approach in learning theory. Since Vapnik and Chervonenkis
[1974] first formalized the idea for analyzing SVMs, it has been utilized to
study many fundamental learning algorithms (e.g., $k$-nearest neighbors [Rogers
and Wagner, 1978], stochastic gradient method [Hardt et al., 2016], linear
regression [Maurer, 2017], etc). In a recent line of great works by Feldman and
Vondrak [2018, 2019] as well as Bousquet et al. [2020b], they prove a high
probability generalization upper bound of order $\widetilde{\mathcal{O}}(\gamma
+\frac{L}{\sqrt{n}})$ for any uniformly $\gamma$-stable algorithm and
$L$-bounded loss function. Although much progress was achieved in proving
generalization upper bounds for stable algorithms, our knowledge of lower
bounds is rather limited. In fact, there is no nontrivial lower bound known
ever since the study on uniform stability began [Bousquet and Elisseeff, 2002],
to the best of our knowledge. In this paper we fill the gap by proving a tight
generalization lower bound of order $\Omega(\gamma+\frac{L}{\sqrt{n}})$, which
matches the best known upper bound up to logarithmic factors
</p>
<a href="http://arxiv.org/abs/2012.13326" target="_blank">arXiv:2012.13326</a> [<a href="http://arxiv.org/pdf/2012.13326" target="_blank">pdf</a>]

<h2>Vector-output ReLU Neural Network Problems are Copositive Programs: Convex Analysis of Two Layer Networks and Polynomial-time Algorithms. (arXiv:2012.13329v1 [cs.LG])</h2>
<h3>Arda Sahiner, Tolga Ergen, John Pauly, Mert Pilanci</h3>
<p>We describe the convex semi-infinite dual of the two-layer vector-output ReLU
neural network training problem. This semi-infinite dual admits a finite
dimensional representation, but its support is over a convex set which is
difficult to characterize. In particular, we demonstrate that the non-convex
neural network training problem is equivalent to a finite-dimensional convex
copositive program. Our work is the first to identify this strong connection
between the global optima of neural networks and those of copositive programs.
We thus demonstrate how neural networks implicitly attempt to solve copositive
programs via semi-nonnegative matrix factorization, and draw key insights from
this formulation. We describe the first algorithms for provably finding the
global minimum of the vector output neural network training problem, which are
polynomial in the number of samples for a fixed data rank, yet exponential in
the dimension. However, in the case of convolutional architectures, the
computational complexity is exponential in only the filter size and polynomial
in all other parameters. We describe the circumstances in which we can find the
global optimum of this neural network training problem exactly with
soft-thresholded SVD, and provide a copositive relaxation which is guaranteed
to be exact for certain classes of problems, and which corresponds with the
solution of Stochastic Gradient Descent in practice.
</p>
<a href="http://arxiv.org/abs/2012.13329" target="_blank">arXiv:2012.13329</a> [<a href="http://arxiv.org/pdf/2012.13329" target="_blank">pdf</a>]

<h2>Physics guided machine learning using simplified theories. (arXiv:2012.13343v1 [cs.LG])</h2>
<h3>Suraj Pawar, Omer San, Burak Aksoylu, Adil Rasheed, Trond Kvamsdal</h3>
<p>Recent applications of machine learning, in particular deep learning,
motivate the need to address the generalizability of the statistical inference
approaches in physical sciences. In this letter, we introduce a modular physics
guided machine learning framework to improve the accuracy of such data-driven
predictive engines. The chief idea in our approach is to augment the knowledge
of the simplified theories with the underlying learning process. To emphasise
on their physical importance, our architecture consists of adding certain
features at intermediate layers rather than in the input layer. To demonstrate
our approach, we select a canonical airfoil aerodynamic problem with the
enhancement of the potential flow theory. We include features obtained by a
panel method that can be computed efficiently for an unseen configuration in
our training procedure. By addressing the generalizability concerns, our
results suggest that the proposed feature enhancement approach can be
effectively used in many scientific machine learning applications, especially
for the systems where we can use a theoretical, empirical, or simplified model
to guide the learning module.
</p>
<a href="http://arxiv.org/abs/2012.13343" target="_blank">arXiv:2012.13343</a> [<a href="http://arxiv.org/pdf/2012.13343" target="_blank">pdf</a>]

<h2>Generating Long-term Continuous Multi-type Generation Profiles using Generative Adversarial Network. (arXiv:2012.13344v1 [cs.LG])</h2>
<h3>Ming Dong</h3>
<p>Today, the adoption of new technologies has increased power system dynamics
significantly. Traditional long-term planning studies that most utility
companies perform based on discrete power levels such as peak or average values
cannot reflect system dynamics and often fail to accurately predict system
reliability deficiencies. As a result, long-term future continuous profiles
such as the 8760 hourly profiles are required to enable time-series based
long-term planning studies. However, unlike short-term profiles used for
operation studies, generating long-term continuous profiles that can reflect
both historical time-varying characteristics and future expected power
magnitude is very challenging. Current methods such as average profiling have
major drawbacks. To solve this challenge, this paper proposes a completely
novel approach to generate such profiles for multiple generation types using
Generative Adversarial Networks (GAN). A multi-level profile synthesis process
is proposed to capture time-varying characteristics at different time levels.
Both Single-type GAN and a modified Conditional GAN systems are developed.
Unique profile evaluation metrics are proposed. The proposed approach was
evaluated based on a public dataset and demonstrated great performance and
application value for generating long-term continuous multi-type generation
profiles.
</p>
<a href="http://arxiv.org/abs/2012.13344" target="_blank">arXiv:2012.13344</a> [<a href="http://arxiv.org/pdf/2012.13344" target="_blank">pdf</a>]

<h2>Parallel-beam X-ray CT datasets of apples with internal defects and label balancing for machine learning. (arXiv:2012.13346v1 [cs.LG])</h2>
<h3>Sophia Bethany Coban, Vladyslav Andriiashen, Poulami Somanya Ganguly, Maureen van Eijnatten, Kees Joost Batenburg</h3>
<p>We present three parallel-beam tomographic datasets of 94 apples with
internal defects along with defect label files. The datasets are prepared for
development and testing of data-driven, learning-based image reconstruction,
segmentation and post-processing methods. The three versions are a noiseless
simulation; simulation with added Gaussian noise, and with scattering noise.
The datasets are based on real 3D X-ray CT data and their subsequent volume
reconstructions. The ground truth images, based on the volume reconstructions,
are also available through this project. Apples contain various defects, which
naturally introduce a label bias. We tackle this by formulating the bias as an
optimization problem. In addition, we demonstrate solving this problem with two
methods: a simple heuristic algorithm and through mixed integer quadratic
programming. This ensures the datasets can be split into test, training or
validation subsets with the label bias eliminated. Therefore the datasets can
be used for image reconstruction, segmentation, automatic defect detection, and
testing the effects of (as well as applying new methodologies for removing)
label bias in machine learning.
</p>
<a href="http://arxiv.org/abs/2012.13346" target="_blank">arXiv:2012.13346</a> [<a href="http://arxiv.org/pdf/2012.13346" target="_blank">pdf</a>]

<h2>Machine learning with incomplete datasets using multi-objective optimization models. (arXiv:2012.13352v1 [cs.LG])</h2>
<h3>Hadi A. Khorshidi, Michael Kirley, Uwe Aickelin</h3>
<p>Machine learning techniques have been developed to learn from complete data.
When missing values exist in a dataset, the incomplete data should be
preprocessed separately by removing data points with missing values or
imputation. In this paper, we propose an online approach to handle missing
values while a classification model is learnt. To reach this goal, we develop a
multi-objective optimization model with two objective functions for imputation
and model selection. We also propose three formulations for imputation
objective function. We use an evolutionary algorithm based on NSGA II to find
the optimal solutions as the Pareto solutions. We investigate the reliability
and robustness of the proposed model using experiments by defining several
scenarios in dealing with missing values and classification. We also describe
how the proposed model can contribute to medical informatics. We compare the
performance of three different formulations via experimental results. The
proposed model results get validated by comparing with a comparable literature.
</p>
<a href="http://arxiv.org/abs/2012.13352" target="_blank">arXiv:2012.13352</a> [<a href="http://arxiv.org/pdf/2012.13352" target="_blank">pdf</a>]

<h2>Global Context Networks. (arXiv:2012.13375v1 [cs.CV])</h2>
<h3>Yue Cao, Jiarui Xu, Stephen Lin, Fangyun Wei, Han Hu</h3>
<p>The Non-Local Network (NLNet) presents a pioneering approach for capturing
long-range dependencies within an image, via aggregating query-specific global
context to each query position. However, through a rigorous empirical analysis,
we have found that the global contexts modeled by the non-local network are
almost the same for different query positions. In this paper, we take advantage
of this finding to create a simplified network based on a query-independent
formulation, which maintains the accuracy of NLNet but with significantly less
computation. We further replace the one-layer transformation function of the
non-local block by a two-layer bottleneck, which further reduces the parameter
number considerably. The resulting network element, called the global context
(GC) block, effectively models global context in a lightweight manner, allowing
it to be applied at multiple layers of a backbone network to form a global
context network (GCNet). Experiments show that GCNet generally outperforms
NLNet on major benchmarks for various recognition tasks. The code and network
configurations are available at https://github.com/xvjiarui/GCNet.
</p>
<a href="http://arxiv.org/abs/2012.13375" target="_blank">arXiv:2012.13375</a> [<a href="http://arxiv.org/pdf/2012.13375" target="_blank">pdf</a>]

<h2>A Physics-Informed Deep Learning Paradigm for Car-Following Models. (arXiv:2012.13376v1 [cs.LG])</h2>
<h3>Zhaobin Mo, Xuan Di, Rongye Shi</h3>
<p>Car-following behavior has been extensively studied using physics-based
models, such as the Intelligent Driver Model. These models successfully
interpret traffic phenomena observed in the real-world but may not fully
capture the complex cognitive process of driving. Deep learning models, on the
other hand, have demonstrated their power in capturing observed traffic
phenomena but require a large amount of driving data to train. This paper aims
to develop a family of neural network based car-following models that are
informed by physics-based models, which leverage the advantage of both
physics-based (being data-efficient and interpretable) and deep learning based
(being generalizable) models. We design physics-informed deep learning for
car-following (PIDL-CF) architectures encoded with two popular physics-based
models - IDM and OVM, on which acceleration is predicted for four traffic
regimes: acceleration, deceleration, cruising, and emergency braking. Two types
of PIDL-CFM problems are studied, one to predict acceleration only and the
other to jointly predict acceleration and discover model parameters. We also
demonstrate the superior performance of PIDL with the Next Generation
SIMulation (NGSIM) dataset over baselines, especially when the training data is
sparse. The results demonstrate the superior performance of neural networks
informed by physics over those without. The developed PIDL-CF framework holds
the potential for system identification of driving models and for the
development of driving-based controls for automated vehicles.
</p>
<a href="http://arxiv.org/abs/2012.13376" target="_blank">arXiv:2012.13376</a> [<a href="http://arxiv.org/pdf/2012.13376" target="_blank">pdf</a>]

<h2>A Regret bound for Non-stationary Multi-Armed Bandits with Fairness Constraints. (arXiv:2012.13380v1 [cs.LG])</h2>
<h3>Shaarad A. R, Ambedkar Dukkipati</h3>
<p>The multi-armed bandits' framework is the most common platform to study
strategies for sequential decision-making problems. Recently, the notion of
fairness has attracted a lot of attention in the machine learning community.
One can impose the fairness condition that at any given point of time, even
during the learning phase, a poorly performing candidate should not be
preferred over a better candidate. This fairness constraint is known to be one
of the most stringent and has been studied in the stochastic multi-armed
bandits' framework in a stationary setting for which regret bounds have been
established. The main aim of this paper is to study this problem in a
non-stationary setting. We present a new algorithm called Fair Upper Confidence
Bound with Exploration Fair-UCBe algorithm for solving a slowly varying
stochastic $k$-armed bandit problem. With this we present two results: (i)
Fair-UCBe indeed satisfies the above mentioned fairness condition, and (ii) it
achieves a regret bound of $O\left(k^{\frac{3}{2}} T^{1 - \frac{\alpha}{2}}
\sqrt{\log T}\right)$, for some suitable $\alpha \in (0, 1)$, where $T$ is the
time horizon. This is the first fair algorithm with a sublinear regret bound
applicable to non-stationary bandits to the best of our knowledge. We show that
the performance of our algorithm in the non-stationary case approaches that of
its stationary counterpart as the variation in the environment tends to zero.
</p>
<a href="http://arxiv.org/abs/2012.13380" target="_blank">arXiv:2012.13380</a> [<a href="http://arxiv.org/pdf/2012.13380" target="_blank">pdf</a>]

<h2>A Survey on Spatial and Spatiotemporal Prediction Methods. (arXiv:2012.13384v1 [cs.LG])</h2>
<h3>Zhe Jiang</h3>
<p>With the advancement of GPS and remote sensing technologies, large amounts of
geospatial and spatiotemporal data are being collected from various domains,
driving the need for effective and efficient prediction methods. Given spatial
data samples with explanatory features and targeted responses (categorical or
continuous) at a set of locations, the problem aims to learn a model that can
predict the response variable based on explanatory features. The problem is
important with broad applications in earth science, urban informatics,
geosocial media analytics and public health, but is challenging due to the
unique characteristics of spatiotemporal data, including spatial and temporal
autocorrelation, spatial heterogeneity, temporal non-stationarity, limited
ground truth, and multiple scales and resolutions. This paper provides a
systematic review on principles and methods in spatial and spatiotemporal
prediction. We provide a taxonomy of methods categorized by the key challenge
they address. For each method, we introduce its underlying assumption,
theoretical foundation, and discuss its advantages and disadvantages. Our goal
is to help interdisciplinary domain scientists choose techniques to solve their
problems, and more importantly, to help data mining researchers to understand
the main principles and methods in spatial and spatiotemporal prediction and
identify future research opportunities.
</p>
<a href="http://arxiv.org/abs/2012.13384" target="_blank">arXiv:2012.13384</a> [<a href="http://arxiv.org/pdf/2012.13384" target="_blank">pdf</a>]

<h2>Adaptive Summaries: A Personalized Concept-based Summarization Approach by Learning from Users' Feedback. (arXiv:2012.13387v1 [cs.AI])</h2>
<h3>Samira Ghodratnama, Mehrdad Zakershahrak, Fariborz Sobhanmanesh</h3>
<p>Exploring the tremendous amount of data efficiently to make a decision,
similar to answering a complicated question, is challenging with many
real-world application scenarios. In this context, automatic summarization has
substantial importance as it will provide the foundation for big data analytic.
Traditional summarization approaches optimize the system to produce a short
static summary that fits all users that do not consider the subjectivity aspect
of summarization, i.e., what is deemed valuable for different users, making
these approaches impractical in real-world use cases. This paper proposes an
interactive concept-based summarization model, called Adaptive Summaries, that
helps users make their desired summary instead of producing a single inflexible
summary. The system learns from users' provided information gradually while
interacting with the system by giving feedback in an iterative loop. Users can
choose either reject or accept action for selecting a concept being included in
the summary with the importance of that concept from users' perspectives and
confidence level of their feedback. The proposed approach can guarantee
interactive speed to keep the user engaged in the process. Furthermore, it
eliminates the need for reference summaries, which is a challenging issue for
summarization tasks. Evaluations show that Adaptive Summaries helps users make
high-quality summaries based on their preferences by maximizing the
user-desired content in the generated summaries.
</p>
<a href="http://arxiv.org/abs/2012.13387" target="_blank">arXiv:2012.13387</a> [<a href="http://arxiv.org/pdf/2012.13387" target="_blank">pdf</a>]

<h2>Deep Learning-Based Human Pose Estimation: A Survey. (arXiv:2012.13392v1 [cs.CV])</h2>
<h3>Ce Zheng, Wenhan Wu, Taojiannan Yang, Sijie Zhu, Chen Chen, Ruixu Liu, Ju Shen, Nasser Kehtarnavaz, Mubarak Shah</h3>
<p>Human pose estimation aims to locate the human body parts and build human
body representation (e.g., body skeleton) from input data such as images and
videos. It has drawn increasing attention during the past decade and has been
utilized in a wide range of applications including human-computer interaction,
motion analysis, augmented reality, and virtual reality. Although the recently
developed deep learning-based solutions have achieved high performance in human
pose estimation, there still remain challenges due to insufficient training
data, depth ambiguities, and occlusions. The goal of this survey paper is to
provide a comprehensive review of recent deep learning-based solutions for both
2D and 3D pose estimation via a systematic analysis and comparison of these
solutions based on their input data and inference procedures. More than 240
research papers since 2014 are covered in this survey. Furthermore, 2D and 3D
human pose estimation datasets and evaluation metrics are included.
Quantitative performance comparisons of the reviewed methods on popular
datasets are summarized and discussed. Finally, the challenges involved,
applications, and future research directions are concluded. We also provide a
regularly updated project page on: \url{https://github.com/zczcwh/DL-HPE}
</p>
<a href="http://arxiv.org/abs/2012.13392" target="_blank">arXiv:2012.13392</a> [<a href="http://arxiv.org/pdf/2012.13392" target="_blank">pdf</a>]

<h2>Leveraging GPT-2 for Classifying Spam Reviews with Limited Labeled Data via Adversarial Training. (arXiv:2012.13400v1 [cs.AI])</h2>
<h3>Athirai A. Irissappane, Hanfei Yu, Yankun Shen, Anubha Agrawal, Gray Stanton</h3>
<p>Online reviews are a vital source of information when purchasing a service or
a product. Opinion spammers manipulate these reviews, deliberately altering the
overall perception of the service. Though there exists a corpus of online
reviews, only a few have been labeled as spam or non-spam, making it difficult
to train spam detection models. We propose an adversarial training mechanism
leveraging the capabilities of Generative Pre-Training 2 (GPT-2) for
classifying opinion spam with limited labeled data and a large set of unlabeled
data. Experiments on TripAdvisor and YelpZip datasets show that the proposed
model outperforms state-of-the-art techniques by at least 7% in terms of
accuracy when labeled data is limited. The proposed model can also generate
synthetic spam/non-spam reviews with reasonable perplexity, thereby, providing
additional labeled data during training.
</p>
<a href="http://arxiv.org/abs/2012.13400" target="_blank">arXiv:2012.13400</a> [<a href="http://arxiv.org/pdf/2012.13400" target="_blank">pdf</a>]

<h2>Quantifying Exposure Bias for Neural Language Generation. (arXiv:1905.10617v6 [cs.LG] UPDATED)</h2>
<h3>Tianxing He, Jingzhao Zhang, Zhiming Zhou, James Glass</h3>
<p>The exposure bias problem refers to the training-generation discrepancy,
caused by teacher forcing, in maximum likelihood estimation (MLE) training for
auto-regressive neural network language models (LM). It has been regarded as a
central problem for neural language generation (NLG) model training. Although a
lot of algorithms have been proposed to avoid teacher forcing and therefore` to
alleviate exposure bias, there is little work showing how serious the exposure
bias problem actually is. In this work, we first identify the self-recovery
ability of MLE-trained LM, which casts doubt on the seriousness of exposure
bias. We then propose sequence-level (EB-bleu) and word-level (EB-C) metrics as
reasonable proxies to quantify the impact of exposure bias. We conduct
experiments for the LSTM/transformer model, in both real and synthetic
settings. In addition to the unconditional NLG task, we also include results
for a seq2seq machine translation task. Surprisingly, all our measurements
suggest that removing the training-generation discrepancy only brings very
little performance gain. In our analysis, we hypothesise that although there
exist a mismatch between the model distribution and the data distribution, the
mismatch is still in the model's "comfortable zone", and is not big enough to
induce significant performance loss.
</p>
<a href="http://arxiv.org/abs/1905.10617" target="_blank">arXiv:1905.10617</a> [<a href="http://arxiv.org/pdf/1905.10617" target="_blank">pdf</a>]

<h2>Deep Ancient Roman Republican Coin Classification via Feature Fusion and Attention. (arXiv:1908.09428v2 [cs.CV] UPDATED)</h2>
<h3>Hafeez Anwar, Saeed Anwar, Sebastian Zambanini, Fatih Porikli</h3>
<p>We perform the classification of ancient Roman Republican coins via
recognizing their reverse motifs where various objects, faces, scenes, animals,
and buildings are minted along with legends. Most of these coins are eroded due
to their age and varying degrees of preservation, thereby affecting their
informative attributes for visual recognition. Changes in the positions of
principal symbols on the reverse motifs also cause huge variations among the
coin types. Lastly, in-plane orientations, uneven illumination, and a moderate
background clutter further make the classification task non-trivial and
challenging.

To this end, we present a novel network model, CoinNet, that employs compact
bilinear pooling, residual groups, and feature attention layers. Furthermore,
we gathered the largest and most diverse image dataset of the Roman Republican
coins that contains more than 18,000 images belonging to 228 different reverse
motifs. On this dataset, our model achieves a classification accuracy of more
than \textbf{98\%} and outperforms the conventional bag-of-visual-words based
approaches and more recent state-of-the-art deep learning methods. We also
provide a detailed ablation study of our network and its generalization
capability. Models and Datasets available at
https://github.com/saeed-anwar/CoinNet
</p>
<a href="http://arxiv.org/abs/1908.09428" target="_blank">arXiv:1908.09428</a> [<a href="http://arxiv.org/pdf/1908.09428" target="_blank">pdf</a>]

<h2>Style Transfer by Rigid Alignment in Neural Net Feature Space. (arXiv:1909.13690v2 [cs.CV] UPDATED)</h2>
<h3>Suryabhan Singh Hada, Miguel &#xc1;. Carreira-Perpi&#xf1;&#xe1;n</h3>
<p>Arbitrary style transfer is an important problem in computer vision that aims
to transfer style patterns from an arbitrary style image to a given content
image. However, current methods either rely on slow iterative optimization or
fast pre-determined feature transformation, but at the cost of compromised
visual quality of the styled image; especially, distorted content structure. In
this work, we present an effective and efficient approach for arbitrary style
transfer that seamlessly transfers style patterns as well as keep content
structure intact in the styled image. We achieve this by aligning style
features to content features using rigid alignment; thus modifying style
features, unlike the existing methods that do the opposite. We demonstrate the
effectiveness of the proposed approach by generating high-quality stylized
images and compare the results with the current state-of-the-art techniques for
arbitrary style transfer.
</p>
<a href="http://arxiv.org/abs/1909.13690" target="_blank">arXiv:1909.13690</a> [<a href="http://arxiv.org/pdf/1909.13690" target="_blank">pdf</a>]

<h2>epBRM: Improving a Quality of 3D Object Detection using End Point Box Regression Module. (arXiv:1910.04853v2 [cs.CV] UPDATED)</h2>
<h3>Kiwoo Shin, Masayoshi Tomizuka</h3>
<p>We present an endpoint box regression module(epBRM), which is designed for
predicting precise 3D bounding boxes using raw LiDAR 3D point clouds. The
proposed epBRM is built with sequence of small networks and is computationally
lightweight. Our approach can improve a 3D object detection performance by
predicting more precise 3D bounding box coordinates. The proposed approach
requires 40 minutes of training to improve the detection performance. Moreover,
epBRM imposes less than 12ms to network inference time for up-to 20 objects.

The proposed approach utilizes a spatial transformation mechanism to simplify
the box regression task. Adopting spatial transformation mechanism into epBRM
makes it possible to improve the quality of detection with a small sized
network.

We conduct in-depth analysis of the effect of various spatial transformation
mechanisms applied on raw LiDAR 3D point clouds. We also evaluate the proposed
epBRM by applying it to several state-of-the-art 3D object detection systems.

We evaluate our approach on KITTI dataset, a standard 3D object detection
benchmark for autonomous vehicles. The proposed epBRM enhances the overlaps
between ground truth bounding boxes and detected bounding boxes, and improves
3D object detection. Our proposed method evaluated in KITTI test server
outperforms current state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/1910.04853" target="_blank">arXiv:1910.04853</a> [<a href="http://arxiv.org/pdf/1910.04853" target="_blank">pdf</a>]

<h2>Zero-shot generalization using cascaded system-representations. (arXiv:1912.05501v3 [cs.RO] UPDATED)</h2>
<h3>Ashish Malik</h3>
<p>Deep reinforcement learning has been applied to solve a variety of control
problems in isolation. However, the learned latent representations cannot be
optimally reused for other analogous tasks and/or control systems without
additional training or tuning. In this regard, we propose a novel framework
that can be used to learn a single control policy for a whole class of
analogous control systems. The framework is abbreviated as CASNET and it
leverages the similarities in the designs of analogous control-systems to learn
general-purpose abstract system-representations. The framework uses a cascade
of recurrent neural networks-based encoders to create these representations
which are then fed to a conventional policy network as input. A similar cascade
of decoders decodes the output of the policy network to generate
system-specific output. We illustrate the effectiveness of this framework on
arguably the most significant use-case of DRL: Robotics. In this paper, we use
CASNET to learn generalizable control policies for two separate classes of
robots: planer-manipulators and crawling robots, using 15+ and 55+
morphologically analogous simulated robots respectively. These robot models
encompass the most common design variations used in the real world. Our
empirical results using state of the art on and off policy learning algorithms
show that on average, CASNET agent achieves zero shot optimal performance
(performance equivalent to expert agents trained for individual robot models)
on unseen robot models. These results illustrate that the performance of the
learned policy is bound the learning algorithm rather than the framework
itself. The proposed framework serves a major step towards universal
controllers.
</p>
<a href="http://arxiv.org/abs/1912.05501" target="_blank">arXiv:1912.05501</a> [<a href="http://arxiv.org/pdf/1912.05501" target="_blank">pdf</a>]

<h2>Convex Geometry and Duality of Over-parameterized Neural Networks. (arXiv:2002.11219v3 [cs.LG] UPDATED)</h2>
<h3>Tolga Ergen, Mert Pilanci</h3>
<p>We develop a convex analytic approach to analyze finite width two-layer ReLU
networks. We first prove that an optimal solution to the regularized training
problem can be characterized as extreme points of a convex set, where simple
solutions are encouraged via its convex geometrical properties. We then
leverage this characterization to show that an optimal set of parameters yield
linear spline interpolation for regression problems involving one dimensional
or rank-one data. We also characterize the classification decision regions in
terms of a kernel matrix and minimum $\ell_1$-norm solutions. This is in
contrast to Neural Tangent Kernel which is unable to explain predictions of
finite width networks. Our convex geometric characterization also provides
intuitive explanations of hidden neurons as auto-encoders. In higher
dimensions, we show that the training problem can be cast as a finite
dimensional convex problem with infinitely many constraints. Then, we apply
certain convex relaxations and introduce a cutting-plane algorithm to globally
optimize the network. We further analyze the exactness of the relaxations to
provide conditions for the convergence to a global optimum. Our analysis also
shows that optimal network parameters can be also characterized as
interpretable closed-form formulas in some practically relevant special cases.
</p>
<a href="http://arxiv.org/abs/2002.11219" target="_blank">arXiv:2002.11219</a> [<a href="http://arxiv.org/pdf/2002.11219" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Combinatorial Optimization: A Survey. (arXiv:2003.03600v3 [cs.LG] UPDATED)</h2>
<h3>Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, Evgeny Burnaev</h3>
<p>Many traditional algorithms for solving combinatorial optimization problems
involve using hand-crafted heuristics that sequentially construct a solution.
Such heuristics are designed by domain experts and may often be suboptimal due
to the hard nature of the problems. Reinforcement learning (RL) proposes a good
alternative to automate the search of these heuristics by training an agent in
a supervised or self-supervised manner. In this survey, we explore the recent
advancements of applying RL frameworks to hard combinatorial problems. Our
survey provides the necessary background for operations research and machine
learning communities and showcases the works that are moving the field forward.
We juxtapose recently proposed RL methods, laying out the timeline of the
improvements for each problem, as well as we make a comparison with traditional
algorithms, indicating that RL models can become a promising direction for
solving combinatorial problems.
</p>
<a href="http://arxiv.org/abs/2003.03600" target="_blank">arXiv:2003.03600</a> [<a href="http://arxiv.org/pdf/2003.03600" target="_blank">pdf</a>]

<h2>On the Texture Bias for Few-Shot CNN Segmentation. (arXiv:2003.04052v3 [cs.CV] UPDATED)</h2>
<h3>Reza Azad, Abdur R Fayjie, Claude Kauffman, Ismail Ben Ayed, Marco Pedersoli, Jose Dolz</h3>
<p>Despite the initial belief that Convolutional Neural Networks (CNNs) are
driven by shapes to perform visual recognition tasks, recent evidence suggests
that texture bias in CNNs provides higher performing models when learning on
large labeled training datasets. This contrasts with the perceptual bias in the
human visual cortex, which has a stronger preference towards shape components.
Perceptual differences may explain why CNNs achieve human-level performance
when large labeled datasets are available, but their performance significantly
degrades in lowlabeled data scenarios, such as few-shot semantic segmentation.
To remove the texture bias in the context of few-shot learning, we propose a
novel architecture that integrates a set of Difference of Gaussians (DoG) to
attenuate high-frequency local components in the feature space. This produces a
set of modified feature maps, whose high-frequency components are diminished at
different standard deviation values of the Gaussian distribution in the spatial
domain. As this results in multiple feature maps for a single image, we employ
a bi-directional convolutional long-short-term-memory to efficiently merge the
multi scale-space representations. We perform extensive experiments on three
well-known few-shot segmentation benchmarks -- Pascal i5, COCO-20i and FSS-1000
-- and demonstrate that our method outperforms state-of-the-art approaches in
two datasets under the same conditions. The code is available at:
https://github.com/rezazad68/fewshot-segmentation
</p>
<a href="http://arxiv.org/abs/2003.04052" target="_blank">arXiv:2003.04052</a> [<a href="http://arxiv.org/pdf/2003.04052" target="_blank">pdf</a>]

<h2>Formation and Reconfiguration of Tight Multi-Lane Platoons. (arXiv:2003.08595v2 [cs.RO] UPDATED)</h2>
<h3>Roya Firoozi, Xiaojing Zhang, Francesco Borrelli</h3>
<p>Advances in vehicular communication technologies are expected to facilitate
cooperative driving. Connected and Automated Vehicles (CAVs) are able to
collaboratively plan and execute driving maneuvers by sharing their perceptual
knowledge and future plans. In this paper, an architecture for autonomous
navigation of tight multi-lane platoons travelling on public roads is
presented. Using the proposed approach, CAVs are able to form single or
multi-lane platoons of various geometrical configurations. They are able to
reshape and adjust their configurations according to changes in the
environment. The proposed architecture consists of two main components: an
offline motion planner system and an online hierarchical control system. The
motion planner uses an optimization-based approach for cooperative formation
and reconfiguration in tight spaces. A constrained optimization scheme is used
to plan smooth, dynamically feasible and collision-free trajectories for all
the vehicles within the platoon. The paper addresses online computation
limitations by employing a family of maneuvers precomputed offline and stored
on a look-up table on the vehicles. The online hierarchical control system is
composed of three levels: a traffic operation system (TOS), a decision-maker,
and a path-follower. The TOS determines the desired platoon reconfiguration.
The decision-maker checks the feasibility of the reconfiguration plan. The
reconfiguration maneuver is executed by a low-level path-following feedback
controller in real-time. The effectiveness of the approach is demonstrated
through simulations of three case studies: 1) formation reconfiguration 2)
obstacle avoidance, and 3) benchmarking against behavior-based planning in
which the desired formation is achieved using a sequence of motion primitives.
Videos and software can be found online
https://github.com/RoyaFiroozi/Centralized-Planning.
</p>
<a href="http://arxiv.org/abs/2003.08595" target="_blank">arXiv:2003.08595</a> [<a href="http://arxiv.org/pdf/2003.08595" target="_blank">pdf</a>]

<h2>EPSNet: Efficient Panoptic Segmentation Network with Cross-layer Attention Fusion. (arXiv:2003.10142v3 [cs.CV] UPDATED)</h2>
<h3>Chia-Yuan Chang, Shuo-En Chang, Pei-Yung Hsiao, Li-Chen Fu</h3>
<p>Panoptic segmentation is a scene parsing task which unifies semantic
segmentation and instance segmentation into one single task. However, the
current state-of-the-art studies did not take too much concern on inference
time. In this work, we propose an Efficient Panoptic Segmentation Network
(EPSNet) to tackle the panoptic segmentation tasks with fast inference speed.
Basically, EPSNet generates masks based on simple linear combination of
prototype masks and mask coefficients. The light-weight network branches for
instance segmentation and semantic segmentation only need to predict mask
coefficients and produce masks with the shared prototypes predicted by
prototype network branch. Furthermore, to enhance the quality of shared
prototypes, we adopt a module called "cross-layer attention fusion module",
which aggregates the multi-scale features with attention mechanism helping them
capture the long-range dependencies between each other. To validate the
proposed work, we have conducted various experiments on the challenging COCO
panoptic dataset, which achieve highly promising performance with significantly
faster inference speed (53ms on GPU).
</p>
<a href="http://arxiv.org/abs/2003.10142" target="_blank">arXiv:2003.10142</a> [<a href="http://arxiv.org/pdf/2003.10142" target="_blank">pdf</a>]

<h2>Gaussian Process Boosting. (arXiv:2004.02653v2 [cs.LG] UPDATED)</h2>
<h3>Fabio Sigrist</h3>
<p>We introduce a novel way to combine boosting with Gaussian process and mixed
effects models. This allows for relaxing, first, the linearity assumption for
the mean function in Gaussian process and mixed effects models in a flexible
non-parametric way and, second, the independence assumption made in most
boosting algorithms. The former is advantageous for predictive accuracy and for
avoiding model misspecifications. The latter is important for more efficient
learning of the mean function and for obtaining probabilistic predictions. In
addition, we present an extension that scales to large data using a Vecchia
approximation for the Gaussian process model relying on novel results for
covariance parameter inference. We obtain increased predictive accuracy
compared to existing approaches on several simulated and real-world data sets.
</p>
<a href="http://arxiv.org/abs/2004.02653" target="_blank">arXiv:2004.02653</a> [<a href="http://arxiv.org/pdf/2004.02653" target="_blank">pdf</a>]

<h2>Learning optimal environments using projected stochastic gradient ascent. (arXiv:2006.01738v2 [cs.LG] UPDATED)</h2>
<h3>Adrien Bolland, Ioannis Boukas, Fran&#xe7;ois Cornet, Mathias Berger, Damien Ernst</h3>
<p>In this work, we propose a new methodology for jointly sizing a dynamical
system and designing its control law. First, the problem is formalized by
considering parametrized reinforcement learning environments and parametrized
policies. The objective of the optimization problem is to jointly find a
control policy and an environment over the joint hypothesis space of parameters
such that the sum of rewards gathered by the policy in this environment is
maximal. The optimization problem is then addressed by generalizing the direct
policy search algorithms to an algorithm we call Direct Environment Search with
(projected stochastic) Gradient Ascent (DESGA). We illustrate the performance
of DESGA on two benchmarks. First, we consider a parametrized space of
Mass-Spring-Damper (MSD) environments and control policies. Then, we use our
algorithm for optimizing the size of the components and the operation of a
small-scale autonomous energy system, i.e. a solar off-grid microgrid, composed
of photovoltaic panels, batteries, etc. On both benchmarks, we compare the
results of the execution of DESGA with a theoretical upper-bound on the
expected return. Furthermore, the performance of DESGA is compared to an
alternative algorithm. The latter performs a grid discretization of the
environment's hypothesis space and applies the REINFORCE algorithm to identify
pairs of environments and policies resulting in a high expected return. The
choice of this algorithm is also discussed and motivated. On both benchmarks,
we show that DESGA and the alternative algorithm result in a set of parameters
for which the expected return is nearly equal to its theoretical upper-bound.
Nevertheless, the execution of DESGA is much less computationally costly.
</p>
<a href="http://arxiv.org/abs/2006.01738" target="_blank">arXiv:2006.01738</a> [<a href="http://arxiv.org/pdf/2006.01738" target="_blank">pdf</a>]

<h2>Model-Free Reinforcement Learning: from Clipped Pseudo-Regret to Sample Complexity. (arXiv:2006.03864v3 [cs.LG] UPDATED)</h2>
<h3>Zihan Zhang, Yuan Zhou, Xiangyang Ji</h3>
<p>In this paper we consider the problem of learning an $\epsilon$-optimal
policy for a discounted Markov Decision Process (MDP). Given an MDP with $S$
states, $A$ actions, the discount factor $\gamma \in (0,1)$, and an
approximation threshold $\epsilon &gt; 0$, we provide a model-free algorithm to
learn an $\epsilon$-optimal policy with sample complexity
$\tilde{O}(\frac{SA\ln(1/p)}{\epsilon^2(1-\gamma)^{5.5}})$ (where the notation
$\tilde{O}(\cdot)$ hides poly-logarithmic factors of $S,A,1/(1-\gamma)$, and
$1/\epsilon$) and success probability $(1-p)$. For small enough $\epsilon$, we
show an improved algorithm with sample complexity
$\tilde{O}(\frac{SA\ln(1/p)}{\epsilon^2(1-\gamma)^{3}})$. While the first bound
improves upon all known model-free algorithms and model-based ones with tight
dependence on $S$, our second algorithm beats all known sample complexity
bounds and matches the information theoretic lower bound up to logarithmic
factors.
</p>
<a href="http://arxiv.org/abs/2006.03864" target="_blank">arXiv:2006.03864</a> [<a href="http://arxiv.org/pdf/2006.03864" target="_blank">pdf</a>]

<h2>Modeling Shared Responses in Neuroimaging Studies through MultiView ICA. (arXiv:2006.06635v4 [stat.ML] UPDATED)</h2>
<h3>Hugo Richard, Luigi Gresele, Aapo Hyv&#xe4;rinen, Bertrand Thirion, Alexandre Gramfort, Pierre Ablin</h3>
<p>Group studies involving large cohorts of subjects are important to draw
general conclusions about brain functional organization. However, the
aggregation of data coming from multiple subjects is challenging, since it
requires accounting for large variability in anatomy, functional topography and
stimulus response across individuals. Data modeling is especially hard for
ecologically relevant conditions such as movie watching, where the experimental
setup does not imply well-defined cognitive operations.

We propose a novel MultiView Independent Component Analysis (ICA) model for
group studies, where data from each subject are modeled as a linear combination
of shared independent sources plus noise. Contrary to most group-ICA
procedures, the likelihood of the model is available in closed form. We develop
an alternate quasi-Newton method for maximizing the likelihood, which is robust
and converges quickly. We demonstrate the usefulness of our approach first on
fMRI data, where our model demonstrates improved sensitivity in identifying
common sources among subjects. Moreover, the sources recovered by our model
exhibit lower between-session variability than other methods.On
magnetoencephalography (MEG) data, our method yields more accurate source
localization on phantom data. Applied on 200 subjects from the Cam-CAN dataset
it reveals a clear sequence of evoked activity in sensor and source space.

The code is freely available at https://github.com/hugorichard/multiviewica.
</p>
<a href="http://arxiv.org/abs/2006.06635" target="_blank">arXiv:2006.06635</a> [<a href="http://arxiv.org/pdf/2006.06635" target="_blank">pdf</a>]

<h2>Refined bounds for algorithm configuration: The knife-edge of dual class approximability. (arXiv:2006.11827v2 [cs.AI] UPDATED)</h2>
<h3>Maria-Florina Balcan, Tuomas Sandholm, Ellen Vitercik</h3>
<p>Automating algorithm configuration is growing increasingly necessary as
algorithms come with more and more tunable parameters. It is common to tune
parameters using machine learning, optimizing performance metrics such as
runtime and solution quality. The training set consists of problem instances
from the specific domain at hand. We investigate a fundamental question about
these techniques: how large should the training set be to ensure that a
parameter's average empirical performance over the training set is close to its
expected, future performance? We answer this question for algorithm
configuration problems that exhibit a widely-applicable structure: the
algorithm's performance as a function of its parameters can be approximated by
a "simple" function. We show that if this approximation holds under the
L-infinity norm, we can provide strong sample complexity bounds. On the flip
side, if the approximation holds only under the L-p norm for p smaller than
infinity, it is not possible to provide meaningful sample complexity bounds in
the worst case. We empirically evaluate our bounds in the context of integer
programming, one of the most powerful tools in computer science. Via
experiments, we obtain sample complexity bounds that are up to 700 times
smaller than the previously best-known bounds.
</p>
<a href="http://arxiv.org/abs/2006.11827" target="_blank">arXiv:2006.11827</a> [<a href="http://arxiv.org/pdf/2006.11827" target="_blank">pdf</a>]

<h2>Off-Policy Exploitability-Evaluation in Two-Player Zero-Sum Markov Games. (arXiv:2007.02141v2 [cs.LG] UPDATED)</h2>
<h3>Kenshi Abe, Yusuke Kaneko</h3>
<p>Off-policy evaluation (OPE) is the problem of evaluating new policies using
historical data obtained from a different policy. In the recent OPE context,
most studies have focused on single-player cases, and not on multi-player
cases. In this study, we propose OPE estimators constructed by the doubly
robust and double reinforcement learning estimators in two-player zero-sum
Markov games. The proposed estimators project exploitability that is often used
as a metric for determining how close a policy profile (i.e., a tuple of
policies) is to a Nash equilibrium in two-player zero-sum games. We prove the
exploitability estimation error bounds for the proposed estimators. We then
propose the methods to find the best candidate policy profile by selecting the
policy profile that minimizes the estimated exploitability from a given policy
profile class. We prove the regret bounds of the policy profiles selected by
our methods. Finally, we demonstrate the effectiveness and performance of the
proposed estimators through experiments.
</p>
<a href="http://arxiv.org/abs/2007.02141" target="_blank">arXiv:2007.02141</a> [<a href="http://arxiv.org/pdf/2007.02141" target="_blank">pdf</a>]

<h2>State-of-the-art Techniques in Deep Edge Intelligence. (arXiv:2008.00824v3 [cs.AI] UPDATED)</h2>
<h3>Ahnaf Hannan Lodhi, Bar&#x131;&#x15f; Akg&#xfc;n, &#xd6;znur &#xd6;zkasap</h3>
<p>The potential held by the gargantuan volumes of data being generated across
networks worldwide has been truly unlocked by machine learning techniques and
more recently Deep Learning. The advantages offered by the latter have seen it
rapidly becoming a framework of choice for various applications. However, the
centralization of computational resources and the need for data aggregation
have long been limiting factors in the democratization of Deep Learning
applications. Edge Computing is an emerging paradigm that aims to utilize the
hitherto untapped processing resources available at the network periphery. Edge
Intelligence (EI) has quickly emerged as a powerful alternative to enable
learning using the concepts of Edge Computing. Deep Learning-based Edge
Intelligence or Deep Edge Intelligence (DEI) lies in this rapidly evolving
domain. In this article, we provide an overview of the major constraints in
operationalizing DEI. The major research avenues in DEI have been consolidated
under Federated Learning, Distributed Computation, Compression Schemes and
Conditional Computation. We also present some of the prevalent challenges and
highlight prospective research avenues.
</p>
<a href="http://arxiv.org/abs/2008.00824" target="_blank">arXiv:2008.00824</a> [<a href="http://arxiv.org/pdf/2008.00824" target="_blank">pdf</a>]

<h2>Explanation of Reinforcement Learning Model in Dynamic Multi-Agent System. (arXiv:2008.01508v2 [cs.AI] UPDATED)</h2>
<h3>Xinzhi Wang, Huao Li, Hui Zhang, Michael Lewis, Katia Sycara</h3>
<p>Recently, there has been increasing interest in transparency and
interpretability in Deep Reinforcement Learning (DRL) systems. Verbal
explanations, as the most natural way of communication in our daily life,
deserve more attention, since they allow users to gain a better understanding
of the system which ultimately could lead to a high level of trust and smooth
collaboration. This paper reports a novel work in generating verbal
explanations for DRL behaviors agent. A rule-based model is designed to
construct explanations using a series of rules which are predefined with prior
knowledge. A learning model is then proposed to expand the implicit logic of
generating verbal explanation to general situations by employing rule-based
explanations as training data. The learning model is shown to have better
flexibility and generalizability than the static rule-based model. The
performance of both models is evaluated quantitatively through objective
metrics. The results show that verbal explanation generated by both models
improve subjective satisfaction of users towards the interpretability of DRL
systems. Additionally, seven variants of the learning model are designed to
illustrate the contribution of input channels, attention mechanism, and
proposed encoder in improving the quality of verbal explanation.
</p>
<a href="http://arxiv.org/abs/2008.01508" target="_blank">arXiv:2008.01508</a> [<a href="http://arxiv.org/pdf/2008.01508" target="_blank">pdf</a>]

<h2>Adversary Agnostic Robust Deep Reinforcement Learning. (arXiv:2008.06199v2 [cs.LG] UPDATED)</h2>
<h3>Xinghua Qu, Yew-Soon Ong, Abhishek Gupta, Zhu Sun</h3>
<p>Deep reinforcement learning (DRL) policies have been shown to be deceived by
perturbations (e.g., random noise or intensional adversarial attacks) on state
observations that appear at test time but are unknown during training. To
increase the robustness of DRL policies, previous approaches assume that the
knowledge of adversaries can be added into the training process to achieve the
corresponding generalization ability on these perturbed observations. However,
such an assumption not only makes the robustness improvement more expensive but
may also leave a model less effective to other kinds of attacks in the wild. In
contrast, we propose an adversary agnostic robust DRL paradigm that does not
require learning from adversaries. To this end, we first theoretically derive
that robustness could indeed be achieved independently of the adversaries based
on a policy distillation setting. Motivated by this finding, we propose a new
policy distillation loss with two terms: 1) a prescription gap maximization
loss aiming at simultaneously maximizing the likelihood of the action selected
by the teacher policy and the entropy over the remaining actions; 2) a
corresponding Jacobian regularization loss that minimizes the magnitude of the
gradient with respect to the input state. The theoretical analysis shows that
our distillation loss guarantees to increase the prescription gap and the
adversarial robustness. Furthermore, experiments on five Atari games firmly
verify the superiority of our approach in terms of boosting adversarial
robustness compared to other state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2008.06199" target="_blank">arXiv:2008.06199</a> [<a href="http://arxiv.org/pdf/2008.06199" target="_blank">pdf</a>]

<h2>XNAP: Making LSTM-based Next Activity Predictions Explainable by Using LRP. (arXiv:2008.07993v3 [cs.AI] UPDATED)</h2>
<h3>Sven Weinzierl, Sandra Zilker, Jens Brunk, Kate Revoredo, Martin Matzner, J&#xf6;rg Becker</h3>
<p>Predictive business process monitoring (PBPM) is a class of techniques
designed to predict behaviour, such as next activities, in running traces. PBPM
techniques aim to improve process performance by providing predictions to
process analysts, supporting them in their decision making. However, the PBPM
techniques` limited predictive quality was considered as the essential obstacle
for establishing such techniques in practice. With the use of deep neural
networks (DNNs), the techniques` predictive quality could be improved for tasks
like the next activity prediction. While DNNs achieve a promising predictive
quality, they still lack comprehensibility due to their hierarchical approach
of learning representations. Nevertheless, process analysts need to comprehend
the cause of a prediction to identify intervention mechanisms that might affect
the decision making to secure process performance. In this paper, we propose
XNAP, the first explainable, DNN-based PBPM technique for the next activity
prediction. XNAP integrates a layer-wise relevance propagation method from the
field of explainable artificial intelligence to make predictions of a long
short-term memory DNN explainable by providing relevance values for activities.
We show the benefit of our approach through two real-life event logs.
</p>
<a href="http://arxiv.org/abs/2008.07993" target="_blank">arXiv:2008.07993</a> [<a href="http://arxiv.org/pdf/2008.07993" target="_blank">pdf</a>]

<h2>Seesaw Loss for Long-Tailed Instance Segmentation. (arXiv:2008.10032v3 [cs.CV] UPDATED)</h2>
<h3>Jiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong, Kai Chen, Ziwei Liu, Chen Change Loy, Dahua Lin</h3>
<p>Instance segmentation has witnessed a remarkable progress on class-balanced
benchmarks. However, they fail to perform as accurately in real-world
scenarios, where the category distribution of objects naturally comes with a
long tail. Instances of head classes dominate a long-tailed dataset and they
serve as negative samples of tail categories. The overwhelming gradients of
negative samples on tail classes lead to a biased learning process for
classifiers. Consequently, objects of tail categories are more likely to be
misclassified as backgrounds or head categories. To tackle this problem, we
propose Seesaw Loss to dynamically re-balance gradients of positive and
negative samples for each category, with two complementary factors, i.e.,
mitigation factor and compensation factor. The mitigation factor reduces
punishments to tail categories w.r.t. the ratio of cumulative training
instances between different categories. Meanwhile, the compensation factor
increases the penalty of misclassified instances to avoid false positives of
tail categories. We conduct extensive experiments on Seesaw Loss with
mainstream frameworks and different data sampling strategies. With a simple
end-to-end training pipeline, Seesaw Loss obtains significant gains over
Cross-Entropy Loss, and achieves state-of-the-art performance on LVIS dataset
without bells and whistles.
</p>
<a href="http://arxiv.org/abs/2008.10032" target="_blank">arXiv:2008.10032</a> [<a href="http://arxiv.org/pdf/2008.10032" target="_blank">pdf</a>]

<h2>Learning from Multiple Datasets with Heterogeneous and Partial Labels for Universal Lesion Detection in CT. (arXiv:2009.02577v2 [cs.CV] UPDATED)</h2>
<h3>Ke Yan, Jinzheng Cai, Youjing Zheng, Adam P. Harrison, Dakai Jin, You-Bao Tang, Yu-Xing Tang, Lingyun Huang, Jing Xiao, Le Lu</h3>
<p>Large-scale datasets with high-quality labels are desired for training
accurate deep learning models. However, due to the annotation cost, datasets in
medical imaging are often either partially-labeled or small. For example,
DeepLesion is such a large-scale CT image dataset with lesions of various
types, but it also has many unlabeled lesions (missing annotations). When
training a lesion detector on a partially-labeled dataset, the missing
annotations will generate incorrect negative signals and degrade the
performance. Besides DeepLesion, there are several small single-type datasets,
such as LUNA for lung nodules and LiTS for liver tumors. These datasets have
heterogeneous label scopes, i.e., different lesion types are labeled in
different datasets with other types ignored. In this work, we aim to develop a
universal lesion detection algorithm to detect a variety of lesions. The
problem of heterogeneous and partial labels is tackled. First, we build a
simple yet effective lesion detection framework named Lesion ENSemble (LENS).
LENS can efficiently learn from multiple heterogeneous lesion datasets in a
multi-task fashion and leverage their synergy by proposal fusion. Next, we
propose strategies to mine missing annotations from partially-labeled datasets
by exploiting clinical prior knowledge and cross-dataset knowledge transfer.
Finally, we train our framework on four public lesion datasets and evaluate it
on 800 manually-labeled sub-volumes in DeepLesion. Our method brings a relative
improvement of 49% compared to the current state-of-the-art approach in the
metric of average sensitivity. We have publicly released our manual 3D
annotations of DeepLesion in
https://github.com/viggin/DeepLesion_manual_test_set.
</p>
<a href="http://arxiv.org/abs/2009.02577" target="_blank">arXiv:2009.02577</a> [<a href="http://arxiv.org/pdf/2009.02577" target="_blank">pdf</a>]

<h2>Steering a Historical Disease Forecasting Model Under a Pandemic: Case of Flu and COVID-19. (arXiv:2009.11407v2 [cs.LG] UPDATED)</h2>
<h3>Alexander Rodr&#xed;guez, Nikhil Muralidhar, Bijaya Adhikari, Anika Tabassum, Naren Ramakrishnan, B. Aditya Prakash</h3>
<p>Forecasting influenza in a timely manner aids health organizations and
policymakers in adequate preparation and decision making. However, effective
influenza forecasting still remains a challenge despite increasing research
interest. It is even more challenging amidst the COVID pandemic, when the
influenza-like illness (ILI) counts are affected by various factors such as
symptomatic similarities with COVID-19 and shift in healthcare seeking patterns
of the general population. Under the current pandemic, historical influenza
models carry valuable expertise about the disease dynamics but face
difficulties adapting. Therefore, we propose CALI-Net, a neural transfer
learning architecture which allows us to 'steer' a historical disease
forecasting model to new scenarios where flu and COVID co-exist. Our framework
enables this adaptation by automatically learning when it should emphasize
learning from COVID-related signals and when it should learn from the
historical model. Thus, we exploit representations learned from historical ILI
data as well as the limited COVID-related signals. Our experiments demonstrate
that our approach is successful in adapting a historical forecasting model to
the current pandemic. In addition, we show that success in our primary goal,
adaptation, does not sacrifice overall performance as compared with
state-of-the-art influenza forecasting approaches.
</p>
<a href="http://arxiv.org/abs/2009.11407" target="_blank">arXiv:2009.11407</a> [<a href="http://arxiv.org/pdf/2009.11407" target="_blank">pdf</a>]

<h2>Sample Efficient Reinforcement Learning with REINFORCE. (arXiv:2010.11364v2 [cs.LG] UPDATED)</h2>
<h3>Junzi Zhang, Jongho Kim, Brendan O&#x27;Donoghue, Stephen Boyd</h3>
<p>Policy gradient methods are among the most effective methods for large-scale
reinforcement learning, and their empirical success has prompted several works
that develop the foundation of their global convergence theory. However, prior
works have either required exact gradients or state-action visitation measure
based mini-batch stochastic gradients with a diverging batch size, which limit
their applicability in practical scenarios. In this paper, we consider
classical policy gradient methods that compute an approximate gradient with a
single trajectory or a fixed size mini-batch of trajectories under soft-max
parametrization and log-barrier regularization, along with the widely-used
REINFORCE gradient estimation procedure. By controlling the number of "bad"
episodes and resorting to the classical doubling trick, we establish an anytime
sub-linear high probability regret bound as well as almost sure global
convergence of the average regret with an asymptotically sub-linear rate. These
provide the first set of global convergence and sample efficiency results for
the well-known REINFORCE algorithm and contribute to a better understanding of
its performance in practice.
</p>
<a href="http://arxiv.org/abs/2010.11364" target="_blank">arXiv:2010.11364</a> [<a href="http://arxiv.org/pdf/2010.11364" target="_blank">pdf</a>]

<h2>Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets. (arXiv:2010.14819v2 [cs.CV] UPDATED)</h2>
<h3>Kai Han, Yunhe Wang, Qiulin Zhang, Wei Zhang, Chunjing Xu, Tong Zhang</h3>
<p>To obtain excellent deep neural architectures, a series of techniques are
carefully designed in EfficientNets. The giant formula for simultaneously
enlarging the resolution, depth and width provides us a Rubik's cube for neural
networks. So that we can find networks with high efficiency and excellent
performance by twisting the three dimensions. This paper aims to explore the
twisting rules for obtaining deep neural networks with minimum model sizes and
computational costs. Different from the network enlarging, we observe that
resolution and depth are more important than width for tiny networks.
Therefore, the original method, i.e., the compound scaling in EfficientNet is
no longer suitable. To this end, we summarize a tiny formula for downsizing
neural architectures through a series of smaller models derived from the
EfficientNet-B0 with the FLOPs constraint. Experimental results on the ImageNet
benchmark illustrate that our TinyNet performs much better than the smaller
version of EfficientNets using the inversed giant formula. For instance, our
TinyNet-E achieves a 59.9% Top-1 accuracy with only 24M FLOPs, which is about
1.9% higher than that of the previous best MobileNetV3 with similar
computational cost. Code will be available at
https://github.com/huawei-noah/ghostnet/tree/master/tinynet_pytorch, and
https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/tinynet.
</p>
<a href="http://arxiv.org/abs/2010.14819" target="_blank">arXiv:2010.14819</a> [<a href="http://arxiv.org/pdf/2010.14819" target="_blank">pdf</a>]

<h2>Towards Optimal Problem Dependent Generalization Error Bounds in Statistical Learning Theory. (arXiv:2011.06186v4 [stat.ML] UPDATED)</h2>
<h3>Yunbei Xu, Assaf Zeevi</h3>
<p>We study problem-dependent rates, i.e., generalization errors that scale
near-optimally with the variance, the effective loss, or the gradient norms
evaluated at the "best hypothesis." We introduce a principled framework dubbed
"uniform localized convergence," and characterize sharp problem-dependent rates
for central statistical learning problems. From a methodological viewpoint, our
framework resolves several fundamental limitations of existing uniform
convergence and localization analysis approaches. It also provides improvements
and some level of unification in the study of localized complexities, one-sided
uniform inequalities, and sample-based iterative algorithms. In the so-called
"slow rate" regime, we provides the first (moment-penalized) estimator that
achieves the optimal variance-dependent rate for general "rich" classes; we
also establish improved loss-dependent rate for standard empirical risk
minimization. In the "fast rate" regime, we establish finite-sample
problem-dependent bounds that are comparable to precise asymptotics. In
addition, we show that iterative algorithms like gradient descent and
first-order Expectation-Maximization can achieve optimal generalization error
in several representative problems across the areas of non-convex learning,
stochastic optimization, and learning with missing data.
</p>
<a href="http://arxiv.org/abs/2011.06186" target="_blank">arXiv:2011.06186</a> [<a href="http://arxiv.org/pdf/2011.06186" target="_blank">pdf</a>]

<h2>Slender Object Detection: Diagnoses and Improvements. (arXiv:2011.08529v3 [cs.CV] UPDATED)</h2>
<h3>Zhaoyi Wan, Yimin Chen, Sutao Deng, Cong Yao, Jiebo Luo</h3>
<p>In this paper, we are concerned with the detection of a particular type of
objects with extreme aspect ratios, namely slender objects. In real-world
scenarios as well as widely-used datasets (such as COCO), slender objects are
actually very common. However, this type of object has been largely overlooked
by previous object detection algorithms. Upon our investigation, for a
classical object detection method, a drastic drop of 18.9% mAP on COCO is
observed, if solely evaluated on slender objects. Therefore, We systematically
study the problem of slender object detection in this work. Accordingly, an
analytical framework with carefully designed benchmark and evaluation protocols
is established, in which different algorithms and modules can be inspected and
compared. Our key findings include: 1) the essential role of anchors in label
assignment; 2) the descriptive capability of the 2-point representation; 3) the
crucial strategies for improving the detection of slender objects and regular
objects. Our work identifies and extends the insights of existing methods that
are previously underexploited. Furthermore, we propose a feature adaption
strategy that achieves clear and consistent improvements over current
representative object detection methods. In particular, a natural and effective
extension of the center prior, which leads to a significant improvement on
slender objects, is devised. We believe this work opens up new opportunities
and calibrates ablation standards for future research in the field of object
detection.
</p>
<a href="http://arxiv.org/abs/2011.08529" target="_blank">arXiv:2011.08529</a> [<a href="http://arxiv.org/pdf/2011.08529" target="_blank">pdf</a>]

<h2>Efficient Conditional Pre-training for Transfer Learning. (arXiv:2011.10231v3 [cs.CV] UPDATED)</h2>
<h3>Shuvam Chakraborty, Burak Uzkent, Kumar Ayush, Kumar Tanmay, Evan Sheehan, Stefano Ermon</h3>
<p>Almost all the state-of-the-art neural networks for computer vision tasks are
trained by (1) Pre-training on a large scale dataset and (2) finetuning on the
target dataset. This strategy helps reduce the dependency on the target dataset
and improves convergence rate and generalization on the target task. Although
pre-training on large scale datasets is very useful, its foremost disadvantage
is high training cost. To address this, we propose efficient target dataset
conditioned filtering methods to remove less relevant samples from the
pre-training dataset. Unlike prior work, we focus on efficiency, adaptability,
and flexibility in addition to performance. Additionally, we discover that
lowering image resolutions in the pre-training step offers a great trade-off
between cost and performance. We validate our techniques by pre-training on
ImageNet in both the unsupervised and supervised settings and finetuning on a
diverse collection of target datasets and tasks. Our proposed methods
drastically reduce pre-training cost and provide strong performance boosts.
</p>
<a href="http://arxiv.org/abs/2011.10231" target="_blank">arXiv:2011.10231</a> [<a href="http://arxiv.org/pdf/2011.10231" target="_blank">pdf</a>]

<h2>Exploring Contrastive Learning in Human Activity Recognition for Healthcare. (arXiv:2011.11542v2 [cs.LG] UPDATED)</h2>
<h3>Chi Ian Tang, Ignacio Perez-Pozuelo, Dimitris Spathis, Cecilia Mascolo</h3>
<p>Human Activity Recognition (HAR) constitutes one of the most important tasks
for wearable and mobile sensing given its implications in human well-being and
health monitoring. Motivated by the limitations of labeled datasets in HAR,
particularly when employed in healthcare-related applications, this work
explores the adoption and adaptation of SimCLR, a contrastive learning
technique for visual representations, to HAR. The use of contrastive learning
objectives causes the representations of corresponding views to be more
similar, and those of non-corresponding views to be more different. After an
extensive evaluation exploring 64 combinations of different signal
transformations for augmenting the data, we observed significant performance
differences owing to the order and the function thereof. In particular,
preliminary results indicated an improvement over supervised and unsupervised
learning methods when using fine-tuning and random rotation for augmentation,
however, future work should explore under which conditions SimCLR is beneficial
for HAR systems and other healthcare-related applications.
</p>
<a href="http://arxiv.org/abs/2011.11542" target="_blank">arXiv:2011.11542</a> [<a href="http://arxiv.org/pdf/2011.11542" target="_blank">pdf</a>]

<h2>Risk-Monotonicity in Statistical Learning. (arXiv:2011.14126v3 [cs.LG] UPDATED)</h2>
<h3>Zakaria Mhammedi, Hisham Husain</h3>
<p>Acquisition of data is a difficult task in many applications of machine
learning, and it is only natural that one hopes and expects the populating risk
to decrease (better performance) monotonically with increasing data points. It
turns out, somewhat surprisingly, that this is not the case even for the most
standard algorithms such as empirical risk minimization. Non-monotonic
behaviour of the risk and instability in training have manifested and appeared
in the popular deep learning paradigm under the description of double descent.
These problems highlight bewilderment in our understanding of learning
algorithms and generalization. It is, therefore, crucial to pursue this concern
and provide a characterization of such behaviour. In this paper, we derive the
first consistent and risk-monotonic algorithms for a general statistical
learning setting under weak assumptions, consequently resolving an open problem
(Viering et al. 2019) on how to avoid non-monotonic behaviour of risk curves.
Our work makes a significant contribution to the topic of risk-monotonicity,
which may be key in resolving empirical phenomena such as double descent.
</p>
<a href="http://arxiv.org/abs/2011.14126" target="_blank">arXiv:2011.14126</a> [<a href="http://arxiv.org/pdf/2011.14126" target="_blank">pdf</a>]

<h2>Kernel-convoluted Deep Neural Networks with Data Augmentation. (arXiv:2012.02521v2 [cs.LG] UPDATED)</h2>
<h3>Minjin Kim, Young-geun Kim, Dongha Kim, Yongdai Kim, Myunghee Cho Paik</h3>
<p>The Mixup method (Zhang et al. 2018), which uses linearly interpolated data,
has emerged as an effective data augmentation tool to improve generalization
performance and the robustness to adversarial examples. The motivation is to
curtail undesirable oscillations by its implicit model constraint to behave
linearly at in-between observed data points and promote smoothness. In this
work, we formally investigate this premise, propose a way to explicitly impose
smoothness constraints, and extend it to incorporate with implicit model
constraints. First, we derive a new function class composed of
kernel-convoluted models (KCM) where the smoothness constraint is directly
imposed by locally averaging the original functions with a kernel function.
Second, we propose to incorporate the Mixup method into KCM to expand the
domains of smoothness. In both cases of KCM and the KCM adapted with the Mixup,
we provide risk analysis, respectively, under some conditions for kernels. We
show that the upper bound of the excess risk is not slower than that of the
original function class. The upper bound of the KCM with the Mixup remains
dominated by that of the KCM if the perturbation of the Mixup vanishes faster
than \(O(n^{-1/2})\) where \(n\) is a sample size. Using CIFAR-10 and CIFAR-100
datasets, our experiments demonstrate that the KCM with the Mixup outperforms
the Mixup method in terms of generalization and robustness to adversarial
examples.
</p>
<a href="http://arxiv.org/abs/2012.02521" target="_blank">arXiv:2012.02521</a> [<a href="http://arxiv.org/pdf/2012.02521" target="_blank">pdf</a>]

<h2>The Neural Coding Framework for Learning Generative Models. (arXiv:2012.03405v2 [cs.LG] UPDATED)</h2>
<h3>Alexander Ororbia, Daniel Kifer</h3>
<p>Neural generative models can be used to learn complex probability
distributions from data, to sample from them, and to produce probability
density estimates. We propose a novel neural generative model inspired by the
theory of predictive processing in the brain. According to predictive
processing theory, the neurons in the brain form a hierarchy in which neurons
in one level form expectations about sensory inputs from another level. These
neurons update their local models based on differences between their
expectations and the observed signals. In a similar way, artificial neurons in
our generative model predict what neighboring neurons will do, and adjust their
parameters based on how well the predictions matched reality. This neural
generative model performs very well in practice. On a variety of benchmark
datasets and metrics, it either remains competitive with or significantly
outperforms other generative models with similar functionality (such as the
variational auto-encoder).
</p>
<a href="http://arxiv.org/abs/2012.03405" target="_blank">arXiv:2012.03405</a> [<a href="http://arxiv.org/pdf/2012.03405" target="_blank">pdf</a>]

<h2>Mapping Network States Using Connectivity Queries. (arXiv:2012.03413v3 [cs.LG] UPDATED)</h2>
<h3>Alexander Rodr&#xed;guez, Bijaya Adhikari, Andr&#xe9;s D. Gonz&#xe1;lez, Charles Nicholson, Anil Vullikanti, B. Aditya Prakash</h3>
<p>Can we infer all the failed components of an infrastructure network, given a
sample of reachable nodes from supply nodes? One of the most critical
post-disruption processes after a natural disaster is to quickly determine the
damage or failure states of critical infrastructure components. However, this
is non-trivial, considering that often only a fraction of components may be
accessible or observable after a disruptive event. Past work has looked into
inferring failed components given point probes, i.e. with a direct sample of
failed components. In contrast, we study the harder problem of inferring failed
components given partial information of some `serviceable' reachable nodes and
a small sample of point probes, being the first often more practical to obtain.
We formulate this novel problem using the Minimum Description Length (MDL)
principle, and then present a greedy algorithm that minimizes MDL cost
effectively. We evaluate our algorithm on domain-expert simulations of real
networks in the aftermath of an earthquake. Our algorithm successfully identify
failed components, especially the critical ones affecting the overall system
performance.
</p>
<a href="http://arxiv.org/abs/2012.03413" target="_blank">arXiv:2012.03413</a> [<a href="http://arxiv.org/pdf/2012.03413" target="_blank">pdf</a>]

<h2>A Single Iterative Step for Anytime Causal Discovery. (arXiv:2012.07513v2 [cs.AI] UPDATED)</h2>
<h3>Raanan Y. Rohekar, Yaniv Gurwicz, Shami Nisimov, Gal Novik</h3>
<p>We present a sound and complete algorithm for recovering causal graphs from
observed, non-interventional data, in the possible presence of latent
confounders and selection bias. We rely on the causal Markov and faithfulness
assumptions and recover the equivalence class of the underlying causal graph by
performing a series of conditional independence (CI) tests between observed
variables. We propose a single step that is applied iteratively, such that the
independence and causal relations entailed from the resulting graph, after any
iteration, is correct and becomes more informative with successive iteration.
Essentially, we tie the size of the CI condition set to its distance from the
tested nodes on the resulting graph. Each iteration refines the skeleton and
orientation by performing CI tests having condition sets that are larger than
in the preceding iteration. In an iteration, condition sets of CI tests are
constructed from nodes that are within a specified search distance, and the
sizes of these condition sets is equal to this search distance. The algorithm
then iteratively increases the search distance along with the condition set
sizes. Thus, each iteration refines a graph, that was recovered by previous
iterations having smaller condition sets -- having a higher statistical power.
We demonstrate that our algorithm requires significantly fewer CI tests and
smaller condition sets compared to the FCI algorithm. This is evident for both
recovering the true underlying graph using a perfect CI oracle, and accurately
estimating the graph using limited observed data.
</p>
<a href="http://arxiv.org/abs/2012.07513" target="_blank">arXiv:2012.07513</a> [<a href="http://arxiv.org/pdf/2012.07513" target="_blank">pdf</a>]

<h2>Predicting Events in MOBA Games: Dataset, Attribution, and Evaluation. (arXiv:2012.09424v3 [cs.AI] UPDATED)</h2>
<h3>Zelong Yang, Yan Wang, Piji Li, Shaobin Lin, Shuming Shi, Shao-Lun Huang</h3>
<p>The multiplayer online battle arena (MOBA) games have become increasingly
popular in recent years. Consequently, many efforts have been devoted to
providing pre-game or in-game predictions for them. However, these works are
limited in the following two aspects: 1) the lack of sufficient in-game
features; 2) the absence of interpretability in the prediction results. These
two limitations greatly restrict the practical performance and industrial
application of the current works. In this work, we collect and release a
large-scale dataset containing rich in-game features for the popular MOBA game
Honor of Kings. We then propose to predict four types of important events in an
interpretable way by attributing the predictions to the input features using
two gradient-based attribution methods: Integrated Gradients and SmoothGrad. To
evaluate the explanatory power of different models and attribution methods, a
fidelity-based evaluation metric is further proposed. Finally, we evaluate the
accuracy and Fidelity of several competitive methods on the collected dataset
to assess how well machines predict events in MOBA games.
</p>
<a href="http://arxiv.org/abs/2012.09424" target="_blank">arXiv:2012.09424</a> [<a href="http://arxiv.org/pdf/2012.09424" target="_blank">pdf</a>]

<h2>Exploring Motion Boundaries in an End-to-End Network for Vision-based Parkinson's Severity Assessment. (arXiv:2012.09890v2 [cs.CV] UPDATED)</h2>
<h3>Amirhossein Dadashzadeh, Alan Whone, Michal Rolinski, Majid Mirmehdi</h3>
<p>Evaluating neurological disorders such as Parkinson's disease (PD) is a
challenging task that requires the assessment of several motor and non-motor
functions. In this paper, we present an end-to-end deep learning framework to
measure PD severity in two important components, hand movement and gait, of the
Unified Parkinson's Disease Rating Scale (UPDRS). Our method leverages on an
Inflated 3D CNN trained by a temporal segment framework to learn spatial and
long temporal structure in video data. We also deploy a temporal attention
mechanism to boost the performance of our model. Further, motion boundaries are
explored as an extra input modality to assist in obfuscating the effects of
camera motion for better movement assessment. We ablate the effects of
different data modalities on the accuracy of the proposed network and compare
with other popular architectures. We evaluate our proposed method on a dataset
of 25 PD patients, obtaining 72.3% and 77.1% top-1 accuracy on hand movement
and gait tasks respectively.
</p>
<a href="http://arxiv.org/abs/2012.09890" target="_blank">arXiv:2012.09890</a> [<a href="http://arxiv.org/pdf/2012.09890" target="_blank">pdf</a>]

<h2>Centralized Information Interaction for Salient Object Detection. (arXiv:2012.11294v2 [cs.CV] UPDATED)</h2>
<h3>Jiang-Jiang Liu, Zhi-Ang Liu, Ming-Ming Cheng</h3>
<p>The U-shape structure has shown its advantage in salient object detection for
efficiently combining multi-scale features. However, most existing U-shape
based methods focused on improving the bottom-up and top-down pathways while
ignoring the connections between them. This paper shows that by centralizing
these connections, we can achieve the cross-scale information interaction among
them, hence obtaining semantically stronger and positionally more precise
features. To inspire the potential of the newly proposed strategy, we further
design a relative global calibration module that can simultaneously process
multi-scale inputs without spatial interpolation. Benefiting from the above
strategy and module, our proposed approach can aggregate features more
effectively while introducing only a few additional parameters. Our approach
can cooperate with various existing U-shape-based salient object detection
methods by substituting the connections between the bottom-up and top-down
pathways. Experimental results demonstrate that our proposed approach performs
favorably against the previous state-of-the-arts on five widely used benchmarks
with less computational complexity. The source code will be publicly available.
</p>
<a href="http://arxiv.org/abs/2012.11294" target="_blank">arXiv:2012.11294</a> [<a href="http://arxiv.org/pdf/2012.11294" target="_blank">pdf</a>]

<h2>Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for Deep ReLU Networks. (arXiv:2012.11654v2 [stat.ML] UPDATED)</h2>
<h3>Quynh Nguyen, Marco Mondelli, Guido Montufar</h3>
<p>A recent line of work has analyzed the theoretical properties of deep neural
networks via the Neural Tangent Kernel (NTK). In particular, the smallest
eigenvalue of the NTK has been related to memorization capacity, convergence of
gradient descent algorithms and generalization of deep nets. However, existing
results either provide bounds in the two-layer setting or assume that the
spectrum of the NTK is bounded away from 0 for multi-layer networks. In this
paper, we provide tight bounds on the smallest eigenvalue of NTK matrices for
deep ReLU networks, both in the limiting case of infinite widths and for finite
widths. In the finite-width setting, the network architectures we consider are
quite general: we require the existence of a wide layer with roughly order of
$N$ neurons, $N$ being the number of data samples; and the scaling of the
remaining widths is arbitrary (up to logarithmic factors). To obtain our
results, we analyze various quantities of independent interest: we give lower
bounds on the smallest singular value of feature matrices, and upper bounds on
the Lipschitz constant of input-output feature maps.
</p>
<a href="http://arxiv.org/abs/2012.11654" target="_blank">arXiv:2012.11654</a> [<a href="http://arxiv.org/pdf/2012.11654" target="_blank">pdf</a>]

<h2>RealFormer: Transformer Likes Residual Attention. (arXiv:2012.11747v2 [cs.LG] UPDATED)</h2>
<h3>Ruining He, Anirudh Ravula, Bhargav Kanagal, Joshua Ainslie</h3>
<p>Transformer is the backbone of modern NLP models. In this paper, we propose
RealFormer, a simple Residual Attention Layer Transformer architecture that
significantly outperforms canonical Transformers on a spectrum of tasks
including Masked Language Modeling, GLUE, and SQuAD. Qualitatively, RealFormer
is easy to implement and requires minimal hyper-parameter tuning. It also
stabilizes training and leads to models with sparser attentions. Code will be
open-sourced upon paper acceptance.
</p>
<a href="http://arxiv.org/abs/2012.11747" target="_blank">arXiv:2012.11747</a> [<a href="http://arxiv.org/pdf/2012.11747" target="_blank">pdf</a>]

<h2>Molecular CT: Unifying Geometry and Representation Learning for Molecules at Different Scales. (arXiv:2012.11816v2 [cs.LG] UPDATED)</h2>
<h3>Jun Zhang, Yaqiang Zhou, Yao-Kun Lei, Yi Isaac Yang, Yi Qin Gao</h3>
<p>Deep learning is changing many areas in molecular physics, and it has shown
great potential to deliver new solutions to challenging molecular modeling
problems. Along with this trend arises the increasing demand of expressive and
versatile neural network architectures which are compatible with molecular
systems. A new deep neural network architecture, Molecular Configuration
Transformer (Molecular CT), is introduced for this purpose. Molecular CT is
composed of a relation-aware encoder module and a computationally universal
geometry learning unit, thus able to account for the relational constraints
between particles meanwhile scalable to different particle numbers and
invariant w.r.t. the trans-rotational transforms. The computational efficiency
and universality make Molecular CT versatile for a variety of molecular
learning scenarios and especially appealing for transferable representation
learning across different molecular systems. As examples, we show that
Molecular CT enables representational learning for molecular systems at
different scales, and achieves comparable or improved results on common
benchmarks using a more light-weighted structure compared to baseline models.
</p>
<a href="http://arxiv.org/abs/2012.11816" target="_blank">arXiv:2012.11816</a> [<a href="http://arxiv.org/pdf/2012.11816" target="_blank">pdf</a>]

<h2>Unbiased Subdata Selection for Fair Classification: A Unified Framework and Scalable Algorithms. (arXiv:2012.12356v2 [stat.ML] UPDATED)</h2>
<h3>Qing Ye, Weijun Xie</h3>
<p>As an important problem in modern data analytics, classification has
witnessed varieties of applications from different domains. Different from
conventional classification approaches, fair classification concerns the issues
of unintentional biases against the sensitive features (e.g., gender, race).
Due to high nonconvexity of fairness measures, existing methods are often
unable to model exact fairness, which can cause inferior fair classification
outcomes. This paper fills the gap by developing a novel unified framework to
jointly optimize accuracy and fairness. The proposed framework is versatile and
can incorporate different fairness measures studied in literature precisely as
well as can be applicable to many classifiers including deep classification
models. Specifically, in this paper, we first prove Fisher consistency of the
proposed framework. We then show that many classification models within this
framework can be recast as mixed-integer convex programs, which can be solved
effectively by off-the-shelf solvers when the instance sizes are moderate and
can be used as benchmarks to compare the efficiency of approximation
algorithms. We prove that in the proposed framework, when the classification
outcomes are known, the resulting problem, termed "unbiased subdata selection,"
is strongly polynomial-solvable and can be used to enhance the classification
fairness by selecting more representative data points. This motivates us to
develop an iterative refining strategy (IRS) to solve the large-scale
instances, where we improve the classification accuracy and conduct the
unbiased subdata selection in an alternating fashion. We study the convergence
property of IRS and derive its approximation bound. More broadly, this
framework can be leveraged to improve classification models with unbalanced
data by taking F1 score into consideration.
</p>
<a href="http://arxiv.org/abs/2012.12356" target="_blank">arXiv:2012.12356</a> [<a href="http://arxiv.org/pdf/2012.12356" target="_blank">pdf</a>]

<h2>Augmenting Policy Learning with Routines Discovered from a Demonstration. (arXiv:2012.12469v2 [cs.LG] UPDATED)</h2>
<h3>Zelin Zhao, Chuang Gan, Jiajun Wu, Xiaoxiao Guo, Joshua B. Tenenbaum</h3>
<p>Humans can abstract prior knowledge from very little data and use it to boost
skill learning. In this paper, we propose routine-augmented policy learning
(RAPL), which discovers routines composed of primitive actions from a single
demonstration and uses discovered routines to augment policy learning. To
discover routines from the demonstration, we first abstract routine candidates
by identifying grammar over the demonstrated action trajectory. Then, the best
routines measured by length and frequency are selected to form a routine
library. We propose to learn policy simultaneously at primitive-level and
routine-level with discovered routines, leveraging the temporal structure of
routines. Our approach enables imitating expert behavior at multiple temporal
scales for imitation learning and promotes reinforcement learning exploration.
Extensive experiments on Atari games demonstrate that RAPL improves the
state-of-the-art imitation learning method SQIL and reinforcement learning
method A2C. Further, we show that discovered routines can generalize to unseen
levels and difficulties on the CoinRun benchmark.
</p>
<a href="http://arxiv.org/abs/2012.12469" target="_blank">arXiv:2012.12469</a> [<a href="http://arxiv.org/pdf/2012.12469" target="_blank">pdf</a>]

<h2>Towards Overcoming False Positives in Visual Relationship Detection. (arXiv:2012.12510v2 [cs.CV] UPDATED)</h2>
<h3>Daisheng Jin, Xiao Ma, Chongzhi Zhang, Yizhuo Zhou, Jiashu Tao, Mingyuan Zhang, Haiyu Zhao, Shuai Yi, Zhoujun Li, Xianglong Liu, Hongsheng Li</h3>
<p>In this paper, we investigate the cause of the high false positive rate in
Visual Relationship Detection (VRD). We observe that during training, the
relationship proposal distribution is highly imbalanced: most of the negative
relationship proposals are easy to identify, e.g., the inaccurate object
detection, which leads to the under-fitting of low-frequency difficult
proposals. This paper presents Spatially-Aware Balanced negative pRoposal
sAmpling (SABRA), a robust VRD framework that alleviates the influence of false
positives. To effectively optimize the model under imbalanced distribution,
SABRA adopts Balanced Negative Proposal Sampling (BNPS) strategy for mini-batch
sampling. BNPS divides proposals into 5 well defined sub-classes and generates
a balanced training distribution according to the inverse frequency. BNPS gives
an easier optimization landscape and significantly reduces the number of false
positives. To further resolve the low-frequency challenging false positive
proposals with high spatial ambiguity, we improve the spatial modeling ability
of SABRA on two aspects: a simple and efficient multi-head heterogeneous graph
attention network (MH-GAT) that models the global spatial interactions of
objects, and a spatial mask decoder that learns the local spatial
configuration. SABRA outperforms SOTA methods by a large margin on two
human-object interaction (HOI) datasets and one general VRD dataset.
</p>
<a href="http://arxiv.org/abs/2012.12510" target="_blank">arXiv:2012.12510</a> [<a href="http://arxiv.org/pdf/2012.12510" target="_blank">pdf</a>]

<h2>Superhuman Surgical Peg Transfer Using Depth-Sensing and Deep Recurrent Neural Networks. (arXiv:2012.12844v2 [cs.RO] UPDATED)</h2>
<h3>Minho Hwang, Brijen Thananjeyan, Daniel Seita, Jeffrey Ichnowski, Samuel Paradis, Danyal Fer, Thomas Low, Ken Goldberg</h3>
<p>We consider the automation of the well-known peg-transfer task from the
Fundamentals of Laparoscopic Surgery (FLS). While human surgeons teleoperate
robots to perform this task with great dexterity, it remains challenging to
automate. We present an approach that leverages emerging innovations in depth
sensing, deep learning, and Peiper's method for computing inverse kinematics
with time-minimized joint motion. We use the da Vinci Research Kit (dVRK)
surgical robot with a Zivid depth sensor, and automate three variants of the
peg-transfer task: unilateral, bilateral without handovers, and bilateral with
handovers. We use 3D-printed fiducial markers with depth sensing and a deep
recurrent neural network to improve the precision of the dVRK to less than 1
mm. We report experimental results for 1800 block transfer trials. Results
suggest that the fully automated system can outperform an experienced human
surgical resident, who performs far better than untrained humans, in terms of
both speed and success rate. For the most difficult variant of peg transfer
(with handovers) we compare the performance of the surgical resident with
performance of the automated system over 120 trials for each. The experienced
surgical resident achieves success rate 93.2 % with mean transfer time of 8.6
seconds. The automated system achieves success rate 94.1 % with mean transfer
time of 8.1 seconds. To our knowledge this is the first fully automated system
to achieve "superhuman" performance in both speed and success on peg transfer.
Supplementary material is available at
https://sites.google.com/view/surgicalpegtransfer.
</p>
<a href="http://arxiv.org/abs/2012.12844" target="_blank">arXiv:2012.12844</a> [<a href="http://arxiv.org/pdf/2012.12844" target="_blank">pdf</a>]

