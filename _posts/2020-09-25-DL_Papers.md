---
title: Latest Deep Learning Papers
date: 2021-02-13 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (155 Articles)</h1>
<h2>Novel Techniques to Assess Predictive Systems and Reduce Their Alarm Burden. (arXiv:2102.05691v1 [cs.LG])</h2>
<h3>Jonathan A. Handler, Craig F. Feied, Michael T. Gillam</h3>
<p>The performance of a binary classifier ("predictor") depends heavily upon the
context ("workflow") in which it operates. Classic measures of predictor
performance do not reflect the realized utility of predictors unless certain
implied workflow assumptions are met. Failure to meet these implied assumptions
results in suboptimal classifier implementations and a mismatch between
predicted or assessed performance and the actual performance obtained in
real-world deployments. The mismatch commonly arises when multiple predictions
can be made for the same event, the event is relatively rare, and redundant
true positive predictions for the same event add little value, e.g., a system
that makes a prediction each minute, repeatedly issuing interruptive alarms for
a predicted event that may never occur.

We explain why classic metrics do not correctly represent the performance of
predictors in such contexts, and introduce an improved performance assessment
technique ("u-metrics") using utility functions to score each prediction.
U-metrics explicitly account for variability in prediction utility arising from
temporal relationships. Compared to traditional performance measures, u-metrics
more accurately reflect the real-world benefits and costs of a predictor
operating in a workflow context. The difference can be significant.

We also describe the use of "snoozing," a method whereby predictions are
suppressed for a period of time, commonly improving predictor performance by
reducing false positives while retaining the capture of events. Snoozing is
especially useful when predictors generate interruptive alerts, as so often
happens in clinical practice. Utility-based performance metrics correctly
predict and track the performance benefits of snoozing, whereas traditional
performance metrics do not.
</p>
<a href="http://arxiv.org/abs/2102.05691" target="_blank">arXiv:2102.05691</a> [<a href="http://arxiv.org/pdf/2102.05691" target="_blank">pdf</a>]

<h2>UAV Localization Using Autoencoded Satellite Images. (arXiv:2102.05692v1 [cs.CV])</h2>
<h3>Mollie Bianchi, Timothy D. Barfoot</h3>
<p>We propose and demonstrate a fast, robust method for using satellite images
to localize an Unmanned Aerial Vehicle (UAV). Previous work using satellite
images has large storage and computation costs and is unable to run in real
time. In this work, we collect Google Earth (GE) images for a desired flight
path offline and an autoencoder is trained to compress these images to a
low-dimensional vector representation while retaining the key features. This
trained autoencoder is used to compress a real UAV image, which is then
compared to the precollected, nearby, autoencoded GE images using an
inner-product kernel. This results in a distribution of weights over the
corresponding GE image poses and is used to generate a single localization and
associated covariance to represent uncertainty. Our localization is computed in
1% of the time of the current standard and is able to achieve a comparable RMSE
of less than 3m in our experiments, where we robustly matched UAV images from
six runs spanning the lighting conditions of a single day to the same map of
satellite images.
</p>
<a href="http://arxiv.org/abs/2102.05692" target="_blank">arXiv:2102.05692</a> [<a href="http://arxiv.org/pdf/2102.05692" target="_blank">pdf</a>]

<h2>A Topological Approach for Motion Track Discrimination. (arXiv:2102.05705v1 [cs.CV])</h2>
<h3>Tegan Emerson, Sarah Tymochko, George Stantchev, Jason A. Edelberg, Michael Wilson, Colin C. Olson</h3>
<p>Detecting small targets at range is difficult because there is not enough
spatial information present in an image sub-region containing the target to use
correlation-based methods to differentiate it from dynamic confusers present in
the scene. Moreover, this lack of spatial information also disqualifies the use
of most state-of-the-art deep learning image-based classifiers. Here, we use
characteristics of target tracks extracted from video sequences as data from
which to derive distinguishing topological features that help robustly
differentiate targets of interest from confusers. In particular, we calculate
persistent homology from time-delayed embeddings of dynamic statistics
calculated from motion tracks extracted from a wide field-of-view video stream.
In short, we use topological methods to extract features related to target
motion dynamics that are useful for classification and disambiguation and show
that small targets can be detected at range with high probability.
</p>
<a href="http://arxiv.org/abs/2102.05705" target="_blank">arXiv:2102.05705</a> [<a href="http://arxiv.org/pdf/2102.05705" target="_blank">pdf</a>]

<h2>Derivative-Free Reinforcement Learning: A Review. (arXiv:2102.05710v1 [cs.LG])</h2>
<h3>Hong Qian, Yang Yu</h3>
<p>Reinforcement learning is about learning agent models that make the best
sequential decisions in unknown environments. In an unknown environment, the
agent needs to explore the environment while exploiting the collected
information, which usually forms a sophisticated problem to solve.
Derivative-free optimization, meanwhile, is capable of solving sophisticated
problems. It commonly uses a sampling-and-updating framework to iteratively
improve the solution, where exploration and exploitation are also needed to be
well balanced. Therefore, derivative-free optimization deals with a similar
core issue as reinforcement learning, and has been introduced in reinforcement
learning approaches, under the names of learning classifier systems and
neuroevolution/evolutionary reinforcement learning. Although such methods have
been developed for decades, recently, derivative-free reinforcement learning
exhibits attracting increasing attention. However, recent survey on this topic
is still lacking. In this article, we summarize methods of derivative-free
reinforcement learning to date, and organize the methods in aspects including
parameter updating, model selection, exploration, and parallel/distributed
methods. Moreover, we discuss some current limitations and possible future
directions, hoping that this article could bring more attentions to this topic
and serve as a catalyst for developing novel and efficient approaches.
</p>
<a href="http://arxiv.org/abs/2102.05710" target="_blank">arXiv:2102.05710</a> [<a href="http://arxiv.org/pdf/2102.05710" target="_blank">pdf</a>]

<h2>SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral Unmixing. (arXiv:2102.05713v1 [cs.LG])</h2>
<h3>Gurpreet Singh, Soumyajit Gupta, Matthew Lease, Clint Dawson</h3>
<p>Linear Mixture Model for hyperspectral datasets involves separating a mixed
pixel as a linear combination of its constituent endmembers and corresponding
fractional abundances. Both optimization and neural methods have attempted to
tackle this problem, with the current state of the art results achieved by
neural models on benchmark datasets. However, our review of these neural models
show that these networks are severely over-parameterized and consequently the
invariant endmember spectra extracted as decoder weights has a high variance
over multiple runs. All of these approaches require substantial post-processing
to satisfy LMM constraints. Furthermore, they also require an exact
specification of the number of endmembers and specialized initialization of
weights from other algorithms like VCA. Our work shows for the first time that
a two-layer autoencoder (SCA-Net), with $2FK$ parameters ($F$ features, $K$
endmembers), achieves error metrics that are scales apart ($10^{-5})$ from
previously reported values $(10^{-2})$. SCA-Net converges to this low error
solution starting from a random initialization of weights. We also show that
SCA-Net, based upon a bi-orthogonal representation, performs a self-correction
when the the number of endmembers are over-specified. We show that our network
formulation extracts a low-rank representation that is bounded below by a
tail-energy and can be computationally verified. Our numerical experiments on
Samson, Jasper, and Urban datasets demonstrate that SCA-Net outperforms
previously reported error metrics for all the cases while being robust to noise
and outliers.
</p>
<a href="http://arxiv.org/abs/2102.05713" target="_blank">arXiv:2102.05713</a> [<a href="http://arxiv.org/pdf/2102.05713" target="_blank">pdf</a>]

<h2>Domain Adaptation In Reinforcement Learning Via Latent Unified State Representation. (arXiv:2102.05714v1 [cs.LG])</h2>
<h3>Jinwei Xing, Takashi Nagata, Kexin Chen, Xinyun Zou, Emre Neftci, Jeffrey L. Krichmar</h3>
<p>Despite the recent success of deep reinforcement learning (RL), domain
adaptation remains an open problem. Although the generalization ability of RL
agents is critical for the real-world applicability of Deep RL, zero-shot
policy transfer is still a challenging problem since even minor visual changes
could make the trained agent completely fail in the new task. To address this
issue, we propose a two-stage RL agent that first learns a latent unified state
representation (LUSR) which is consistent across multiple domains in the first
stage, and then do RL training in one source domain based on LUSR in the second
stage. The cross-domain consistency of LUSR allows the policy acquired from the
source domain to generalize to other target domains without extra training. We
first demonstrate our approach in variants of CarRacing games with customized
manipulations, and then verify it in CARLA, an autonomous driving simulator
with more complex and realistic visual observations. Our results show that this
approach can achieve state-of-the-art domain adaptation performance in related
RL tasks and outperforms prior approaches based on latent-representation based
RL and image-to-image translation.
</p>
<a href="http://arxiv.org/abs/2102.05714" target="_blank">arXiv:2102.05714</a> [<a href="http://arxiv.org/pdf/2102.05714" target="_blank">pdf</a>]

<h2>Sparse-Push: Communication- & Energy-Efficient Decentralized Distributed Learning over Directed & Time-Varying Graphs with non-IID Datasets. (arXiv:2102.05715v1 [cs.LG])</h2>
<h3>Sai Aparna Aketi, Amandeep Singh, Jan Rabaey</h3>
<p>Current deep learning (DL) systems rely on a centralized computing paradigm
which limits the amount of available training data, increases system latency,
and adds privacy and security constraints. On-device learning, enabled by
decentralized and distributed training of DL models over peer-to-peer
wirelessly connected edge devices, not only alleviate the above limitations but
also enable next-gen applications that need DL models to continuously interact
and learn from their environment. However, this necessitates the development of
novel training algorithms that train DL models over time-varying and directed
peer-to-peer graph structures while minimizing the amount of communication
between the devices and also being resilient to non-IID data distributions. In
this work we propose, Sparse-Push, a communication efficient decentralized
distributed training algorithm that supports training over peer-to-peer,
directed, and time-varying graph topologies. The proposed algorithm enables
466x reduction in communication with only 1% degradation in performance when
training various DL models such as ResNet-20 and VGG11 over the CIFAR-10
dataset. Further, we demonstrate how communication compression can lead to
significant performance degradation in-case of non-IID datasets, and propose
Skew-Compensated Sparse Push algorithm that recovers this performance drop
while maintaining similar levels of communication compression.
</p>
<a href="http://arxiv.org/abs/2102.05715" target="_blank">arXiv:2102.05715</a> [<a href="http://arxiv.org/pdf/2102.05715" target="_blank">pdf</a>]

<h2>Sequential change-point detection for mutually exciting point processes over networks. (arXiv:2102.05724v1 [stat.ML])</h2>
<h3>Haoyun Wang, Liyan Xie, Yao Xie, Alex Cuozzo, Simon Mak</h3>
<p>We present a new CUSUM procedure for sequentially detecting change-point in
the self and mutual exciting processes, a.k.a. Hawkes networks using discrete
events data. Hawkes networks have become a popular model for statistics and
machine learning due to their capability in modeling irregularly observed data
where the timing between events carries a lot of information. The problem of
detecting abrupt changes in Hawkes networks arises from various applications,
including neuronal imaging, sensor network, and social network monitoring.
Despite this, there has not been a computationally and memory-efficient online
algorithm for detecting such changes from sequential data. We present an
efficient online recursive implementation of the CUSUM statistic for Hawkes
processes, both decentralized and memory-efficient, and establish the
theoretical properties of this new CUSUM procedure. We then show that the
proposed CUSUM method achieves better performance than existing methods,
including the Shewhart procedure based on count data, the generalized
likelihood ratio (GLR) in the existing literature, and the standard score
statistic. We demonstrate this via a simulated example and an application to
population code change-detection in neuronal networks.
</p>
<a href="http://arxiv.org/abs/2102.05724" target="_blank">arXiv:2102.05724</a> [<a href="http://arxiv.org/pdf/2102.05724" target="_blank">pdf</a>]

<h2>Speeding up Routing Schedules on Aisle-Graphs with Single Access. (arXiv:2102.05733v1 [cs.RO])</h2>
<h3>Francesco Betti Sorbelli, Stefano Carpin, Federico Coro, Sajal K. Das, Alfredo Navarra, Cristina M. Pinotti</h3>
<p>In this paper, we study the Orienteering Aisle-graphs Single-access Problem
(OASP), a variant of the orienteering problem for a robot moving in a so-called
single-access aisle-graph, i.e., a graph consisting of a set of rows that can
be accessed from one side only. Aisle-graphs model, among others, vineyards or
warehouses. Each aisle-graph vertex is associated with a reward that a robot
obtains when visits the vertex itself. As the robot's energy is limited, only a
subset of vertices can be visited with a fully charged battery. The objective
is to maximize the total reward collected by the robot with a battery charge.
We first propose an optimal algorithm that solves OASP in O(m^2 n^2) time for
aisle-graphs with a single access consisting of m rows, each with n vertices.
With the goal of designing faster solutions, we propose four greedy sub-optimal
algorithms that run in at most O(mn (m+n)) time. For two of them, we guarantee
an approximation ratio of 1/2(1-1/e), where e is the base of the natural
logarithm, on the total reward by exploiting the well-known submodularity
property. Experimentally, we show that these algorithms collect more than 80%
of the optimal reward.
</p>
<a href="http://arxiv.org/abs/2102.05733" target="_blank">arXiv:2102.05733</a> [<a href="http://arxiv.org/pdf/2102.05733" target="_blank">pdf</a>]

<h2>Emojis Predict Dropouts of Remote Workers: An Empirical Study of Emoji Usage on GitHub. (arXiv:2102.05737v1 [cs.LG])</h2>
<h3>Xuan Lu, Wei Ai, Zhenpeng Chen, Yanbin Cao, Xuanzhe Liu, Qiaozhu Mei</h3>
<p>Emotions at work have long been identified as critical signals of work
motivations, status, and attitudes, and as predictors of various work-related
outcomes. For example, harmonious passion increases commitment at work but
stress reduces sustainability and leads to burnouts. When more and more
employees work remotely, these emotional and mental health signals of workers
become harder to observe through daily, face-to-face communications.

The use of online platforms to communicate and collaborate at work provides
an alternative channel to monitor the emotions of workers. This paper studies
how emojis, as non-verbal cues in online communications, can be used for such
purposes. In particular, we study how the developers on GitHub use emojis in
their work-related activities. We show that developers have diverse patterns of
emoji usage, which highly correlate to their working status including activity
levels, types of work, types of communications, time management, and other
behavioral patterns. Developers who use emojis in their posts are significantly
less likely to dropout from the online work platform. Surprisingly, solely
using emoji usage as features, standard machine learning models can predict
future dropouts of developers at a satisfactory accuracy.
</p>
<a href="http://arxiv.org/abs/2102.05737" target="_blank">arXiv:2102.05737</a> [<a href="http://arxiv.org/pdf/2102.05737" target="_blank">pdf</a>]

<h2>Self-supervised learning for fast and scalable time series hyper-parameter tuning. (arXiv:2102.05740v1 [cs.LG])</h2>
<h3>Peiyi Zhang, Xiaodong Jiang, Ginger M Holt, Nikolay Pavlovich Laptev, Caner Komurlu, Peng Gao, Yang Yu</h3>
<p>Hyper-parameters of time series models play an important role in time series
analysis. Slight differences in hyper-parameters might lead to very different
forecast results for a given model, and therefore, selecting good
hyper-parameter values is indispensable. Most of the existing generic
hyper-parameter tuning methods, such as Grid Search, Random Search, Bayesian
Optimal Search, are based on one key component - search, and thus they are
computationally expensive and cannot be applied to fast and scalable
time-series hyper-parameter tuning (HPT). We propose a self-supervised learning
framework for HPT (SSL-HPT), which uses time series features as inputs and
produces optimal hyper-parameters. SSL-HPT algorithm is 6-20x faster at getting
hyper-parameters compared to other search based algorithms while producing
comparable accurate forecasting results in various applications.
</p>
<a href="http://arxiv.org/abs/2102.05740" target="_blank">arXiv:2102.05740</a> [<a href="http://arxiv.org/pdf/2102.05740" target="_blank">pdf</a>]

<h2>Development of Crop Yield Estimation Model using Soil and Environmental Parameters. (arXiv:2102.05755v1 [cs.LG])</h2>
<h3>Nisar Ahmed, Hafiz Muhammad Shahzad Asif, Gulshan Saleem, Muhammad Usman Younus</h3>
<p>Crop yield is affected by various soil and environmental parameters and can
vary significantly. Therefore, a crop yield estimation model which can predict
pre-harvest yield is required for food security. The study is conducted on tea
forms operating under National Tea Research Institute, Pakistan. The data is
recorded on monthly basis for ten years period. The parameters collected are
minimum and maximum temperature, humidity, rainfall, PH level of the soil,
usage of pesticide and labor expertise. The design of model incorporated all of
these parameters and identified the parameters which are most crucial for yield
predictions. Feature transformation is performed to obtain better performing
model. The designed model is based on an ensemble of neural networks and
provided an R-squared of 0.9461 and RMSE of 0.1204 indicating the usability of
the proposed model in yield forecasting based on surface and environmental
parameters.
</p>
<a href="http://arxiv.org/abs/2102.05755" target="_blank">arXiv:2102.05755</a> [<a href="http://arxiv.org/pdf/2102.05755" target="_blank">pdf</a>]

<h2>Risk-Averse Bayes-Adaptive Reinforcement Learning. (arXiv:2102.05762v1 [cs.LG])</h2>
<h3>Marc Rigter, Bruno Lacerda, Nick Hawes</h3>
<p>In this work, we address risk-averse Bayesadaptive reinforcement learning. We
pose the problem of optimising the conditional value at risk (CVaR) of the
total return in Bayes-adaptive Markov decision processes (MDPs). We show that a
policy optimising CVaR in this setting is risk-averse to both the parametric
uncertainty due to the prior distribution over MDPs, and the internal
uncertainty due to the inherent stochasticity of MDPs. We reformulate the
problem as a two-player stochastic game and propose an approximate algorithm
based on Monte Carlo tree search and Bayesian optimisation. Our experiments
demonstrate that our approach significantly outperforms baseline approaches for
this problem.
</p>
<a href="http://arxiv.org/abs/2102.05762" target="_blank">arXiv:2102.05762</a> [<a href="http://arxiv.org/pdf/2102.05762" target="_blank">pdf</a>]

<h2>Early Performance Prediction using Interpretable Patterns in Programming Process Data. (arXiv:2102.05765v1 [cs.LG])</h2>
<h3>Ge Gao, Samiha Marwan, Thomas W. Price</h3>
<p>Instructors have limited time and resources to help struggling students, and
these resources should be directed to the students who most need them. To
address this, researchers have constructed models that can predict students'
final course performance early in a semester. However, many predictive models
are limited to static and generic student features (e.g. demographics, GPA),
rather than computing-specific evidence that assesses a student's progress in
class. Many programming environments now capture complete time-stamped records
of students' actions during programming. In this work, we leverage this rich,
fine-grained log data to build a model to predict student course outcomes. From
the log data, we extract patterns of behaviors that are predictive of students'
success using an approach called differential sequence mining. We evaluate our
approach on a dataset from 106 students in a block-based, introductory
programming course. The patterns extracted from our approach can predict final
programming performance with 79% accuracy using only the first programming
assignment, outperforming two baseline methods. In addition, we show that the
patterns are interpretable and correspond to concrete, effective -- and
ineffective -- novice programming behaviors. We also discuss these patterns and
their implications for classroom instruction.
</p>
<a href="http://arxiv.org/abs/2102.05765" target="_blank">arXiv:2102.05765</a> [<a href="http://arxiv.org/pdf/2102.05765" target="_blank">pdf</a>]

<h2>Predicting Customer Lifetime Values -- ecommerce use case. (arXiv:2102.05771v1 [cs.LG])</h2>
<h3>Ziv Pollak</h3>
<p>Predicting customer future purchases and lifetime value is a key metrics for
managing marketing campaigns and optimizing marketing spend. This task is
specifically challenging when the relationships between the customer and the
firm are of a noncontractual nature and therefore the future purchases need to
be predicted based mostly on historical purchases. This work compares two
approaches to predict customer future purchases, first using a
'buy-till-you-die' statistical model to predict customer behavior and later
using a neural network on the same dataset and comparing the results. This
comparison will lead to both quantitative and qualitative analysis of those two
methods as well as recommendation on how to proceed in different cases and
opportunities for future research.
</p>
<a href="http://arxiv.org/abs/2102.05771" target="_blank">arXiv:2102.05771</a> [<a href="http://arxiv.org/pdf/2102.05771" target="_blank">pdf</a>]

<h2>Data-Driven MPC for Quadrotors. (arXiv:2102.05773v1 [cs.RO])</h2>
<h3>Guillem Torrente, Elia Kaufmann, Philipp Foehn, Davide Scaramuzza</h3>
<p>Aerodynamic forces render accurate high-speed trajectory tracking with
quadrotors extremely challenging. These complex aerodynamic effects become a
significant disturbance at high speeds, introducing large positional tracking
errors, and are extremely difficult to model. To fly at high speeds, feedback
control must be able to account for these aerodynamic effects in real-time.
This necessitates a modelling procedure that is both accurate and efficient to
evaluate. Therefore, we present an approach to model aerodynamic effects using
Gaussian Processes, which we incorporate into a Model Predictive Controller to
achieve efficient and precise real-time feedback control, leading to up to 70%
reduction in trajectory tracking error at high speeds. We verify our method by
extensive comparison to a state-of-the-art linear drag model in synthetic and
real-world experiments at speeds of up to 14m/s and accelerations beyond 4g.
</p>
<a href="http://arxiv.org/abs/2102.05773" target="_blank">arXiv:2102.05773</a> [<a href="http://arxiv.org/pdf/2102.05773" target="_blank">pdf</a>]

<h2>Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP). (arXiv:2102.05774v1 [cs.LG])</h2>
<h3>Vojt&#x11b;ch Van&#x10d;ura, Pavel Kord&#xed;k</h3>
<p>Recently introduced EASE algorithm presents a simple and elegant way, how to
solve the top-N recommendation task. In this paper, we introduce Neural EASE to
further improve the performance of this algorithm by incorporating techniques
for training modern neural networks. Also, there is a growing interest in the
recsys community to utilize variational autoencoders (VAE) for this task. We
introduce deep autoencoder FLVAE benefiting from multiple non-linear layers
without an information bottleneck while not overfitting towards the identity.
We show how to learn FLVAE in parallel with Neural EASE and achieve the state
of the art performance on the MovieLens 20M dataset and competitive results on
the Netflix Prize dataset.
</p>
<a href="http://arxiv.org/abs/2102.05774" target="_blank">arXiv:2102.05774</a> [<a href="http://arxiv.org/pdf/2102.05774" target="_blank">pdf</a>]

<h2>AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition. (arXiv:2102.05775v1 [cs.CV])</h2>
<h3>Yue Meng, Rameswar Panda, Chung-Ching Lin, Prasanna Sattigeri, Leonid Karlinsky, Kate Saenko, Aude Oliva, Rogerio Feris</h3>
<p>Temporal modelling is the key for efficient video action recognition. While
understanding temporal information can improve recognition accuracy for dynamic
actions, removing temporal redundancy and reusing past features can
significantly save computation leading to efficient action recognition. In this
paper, we introduce an adaptive temporal fusion network, called AdaFuse, that
dynamically fuses channels from current and past feature maps for strong
temporal modelling. Specifically, the necessary information from the historical
convolution feature maps is fused with current pruned feature maps with the
goal of improving both recognition accuracy and efficiency. In addition, we use
a skipping operation to further reduce the computation cost of action
recognition. Extensive experiments on Something V1 &amp; V2, Jester and
Mini-Kinetics show that our approach can achieve about 40% computation savings
with comparable accuracy to state-of-the-art methods. The project page can be
found at https://mengyuest.github.io/AdaFuse/
</p>
<a href="http://arxiv.org/abs/2102.05775" target="_blank">arXiv:2102.05775</a> [<a href="http://arxiv.org/pdf/2102.05775" target="_blank">pdf</a>]

<h2>Defense Against Reward Poisoning Attacks in Reinforcement Learning. (arXiv:2102.05776v1 [cs.LG])</h2>
<h3>Kiarash Banihashem, Adish Singla, Goran Radanovic</h3>
<p>We study defense strategies against reward poisoning attacks in reinforcement
learning. As a threat model, we consider attacks that minimally alter rewards
to make the attacker's target policy uniquely optimal under the poisoned
rewards, with the optimality gap specified by an attack parameter. Our goal is
to design agents that are robust against such attacks in terms of the
worst-case utility w.r.t. the true, unpoisoned, rewards while computing their
policies under the poisoned rewards. We propose an optimization framework for
deriving optimal defense policies, both when the attack parameter is known and
unknown. Moreover, we show that defense policies that are solutions to the
proposed optimization problems have provable performance guarantees. In
particular, we provide the following bounds with respect to the true,
unpoisoned, rewards: a) lower bounds on the expected return of the defense
policies, and b) upper bounds on how suboptimal these defense policies are
compared to the attacker's target policy. We conclude the paper by illustrating
the intuitions behind our formal results, and showing that the derived bounds
are non-trivial.
</p>
<a href="http://arxiv.org/abs/2102.05776" target="_blank">arXiv:2102.05776</a> [<a href="http://arxiv.org/pdf/2102.05776" target="_blank">pdf</a>]

<h2>Differentiable Implicit Soft-Body Physics. (arXiv:2102.05791v1 [cs.LG])</h2>
<h3>Junior Rojas, Eftychios Sifakis, Ladislav Kavan</h3>
<p>We present a differentiable soft-body physics simulator that can be composed
with neural networks as a differentiable layer. In contrast to other
differentiable physics approaches that use explicit forward models to define
state transitions, we focus on implicit state transitions defined via function
minimization. Implicit state transitions appear in implicit numerical
integration methods, which offer the benefits of large time steps and excellent
numerical stability, but require a special treatment to achieve
differentiability due to the absence of an explicit differentiable forward
pass. In contrast to other implicit differentiation approaches that require
explicit formulas for the force function and the force Jacobian matrix, we
present an energy-based approach that allows us to compute these derivatives
automatically and in a matrix-free fashion via reverse-mode automatic
differentiation. This allows for more flexibility and productivity when
defining physical models and is particularly important in the context of neural
network training, which often relies on reverse-mode automatic differentiation
(backpropagation). We demonstrate the effectiveness of our differentiable
simulator in policy optimization for locomotion tasks and show that it achieves
better sample efficiency than model-free reinforcement learning.
</p>
<a href="http://arxiv.org/abs/2102.05791" target="_blank">arXiv:2102.05791</a> [<a href="http://arxiv.org/pdf/2102.05791" target="_blank">pdf</a>]

<h2>Lenient Regret and Good-Action Identification in Gaussian Process Bandits. (arXiv:2102.05793v1 [stat.ML])</h2>
<h3>Xu Cai, Selwyn Gomes, Jonathan Scarlett</h3>
<p>In this paper, we study the problem of Gaussian process (GP) bandits under
relaxed optimization criteria stating that any function value above a certain
threshold is "good enough". On the theoretical side, we study various
\emph{\lenient regret} notions in which all near-optimal actions incur zero
penalty, and provide upper bounds on the lenient regret for GP-UCB and an
elimination algorithm, circumventing the usual $O(\sqrt{T})$ term (with time
horizon $T$) resulting from zooming extremely close towards the function
maximum. In addition, we complement these upper bounds with
algorithm-independent lower bounds. On the practical side, we consider the
problem of finding a single "good action" according to a known pre-specified
threshold, and introduce several good-action identification algorithms that
exploit knowledge of the threshold. We experimentally find that such algorithms
can often find a good action faster than standard optimization-based
approaches.
</p>
<a href="http://arxiv.org/abs/2102.05793" target="_blank">arXiv:2102.05793</a> [<a href="http://arxiv.org/pdf/2102.05793" target="_blank">pdf</a>]

<h2>Robust Policy Gradient against Strong Data Corruption. (arXiv:2102.05800v1 [cs.LG])</h2>
<h3>Xuezhou Zhang, Yiding Chen, Xiaojin Zhu, Wen Sun</h3>
<p>We study the problem of robust reinforcement learning under adversarial
corruption on both rewards and transitions. Our attack model assumes an
\textit{adaptive} adversary who can arbitrarily corrupt the reward and
transition at every step within an episode, for at most $\epsilon$-fraction of
the learning episodes. Our attack model is strictly stronger than those
considered in prior works. Our first result shows that no algorithm can find a
better than $O(\epsilon)$-optimal policy under our attack model. Next, we show
that surprisingly the natural policy gradient (NPG) method retains a natural
robustness property if the reward corruption is bounded, and can find an
$O(\sqrt{\epsilon})$-optimal policy. Consequently, we develop a Filtered Policy
Gradient (FPG) algorithm that can tolerate even unbounded reward corruption and
can find an $O(\epsilon^{1/4})$-optimal policy. We emphasize that FPG is the
first that can achieve a meaningful learning guarantee when a constant fraction
of episodes are corrupted. Complimentary to the theoretical results, we show
that a neural implementation of FPG achieves strong robust learning performance
on the MuJoCo continuous control benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.05800" target="_blank">arXiv:2102.05800</a> [<a href="http://arxiv.org/pdf/2102.05800" target="_blank">pdf</a>]

<h2>Audiovisual Highlight Detection in Videos. (arXiv:2102.05811v1 [cs.CV])</h2>
<h3>Karel Mundnich, Alexandra Fenster, Aparna Khare, Shiva Sundaram</h3>
<p>In this paper, we test the hypothesis that interesting events in unstructured
videos are inherently audiovisual. We combine deep image representations for
object recognition and scene understanding with representations from an
audiovisual affect recognition model. To this set, we include content agnostic
audio-visual synchrony representations and mel-frequency cepstral coefficients
to capture other intrinsic properties of audio. These features are used in a
modular supervised model. We present results from two experiments: efficacy
study of single features on the task, and an ablation study where we leave one
feature out at a time. For the video summarization task, our results indicate
that the visual features carry most information, and including audiovisual
features improves over visual-only information. To better study the task of
highlight detection, we run a pilot experiment with highlights annotations for
a small subset of video clips and fine-tune our best model on it. Results
indicate that we can transfer knowledge from the video summarization task to a
model trained specifically for the task of highlight detection.
</p>
<a href="http://arxiv.org/abs/2102.05811" target="_blank">arXiv:2102.05811</a> [<a href="http://arxiv.org/pdf/2102.05811" target="_blank">pdf</a>]

<h2>Anomaly Detection through Transfer Learning in Agriculture and Manufacturing IoT Systems. (arXiv:2102.05814v1 [cs.LG])</h2>
<h3>Mustafa Abdallah, Wo Jae Lee, Nithin Raghunathan, Charilaos Mousoulis, John W. Sutherland, Saurabh Bagchi</h3>
<p>IoT systems have been facing increasingly sophisticated technical problems
due to the growing complexity of these systems and their fast deployment
practices. Consequently, IoT managers have to judiciously detect failures
(anomalies) in order to reduce their cyber risk and operational cost. While
there is a rich literature on anomaly detection in many IoT-based systems,
there is no existing work that documents the use of ML models for anomaly
detection in digital agriculture and in smart manufacturing systems. These two
application domains pose certain salient technical challenges. In agriculture
the data is often sparse, due to the vast areas of farms and the requirement to
keep the cost of monitoring low. Second, in both domains, there are multiple
types of sensors with varying capabilities and costs. The sensor data
characteristics change with the operating point of the environment or machines,
such as, the RPM of the motor. The inferencing and the anomaly detection
processes therefore have to be calibrated for the operating point.

In this paper, we analyze data from sensors deployed in an agricultural farm
with data from seven different kinds of sensors, and from an advanced
manufacturing testbed with vibration sensors. We evaluate the performance of
ARIMA and LSTM models for predicting the time series of sensor data. Then,
considering the sparse data from one kind of sensor, we perform transfer
learning from a high data rate sensor. We then perform anomaly detection using
the predicted sensor data. Taken together, we show how in these two application
domains, predictive failure classification can be achieved, thus paving the way
for predictive maintenance.
</p>
<a href="http://arxiv.org/abs/2102.05814" target="_blank">arXiv:2102.05814</a> [<a href="http://arxiv.org/pdf/2102.05814" target="_blank">pdf</a>]

<h2>Representation Matters: Offline Pretraining for Sequential Decision Making. (arXiv:2102.05815v1 [cs.LG])</h2>
<h3>Mengjiao Yang, Ofir Nachum</h3>
<p>The recent success of supervised learning methods on ever larger offline
datasets has spurred interest in the reinforcement learning (RL) field to
investigate whether the same paradigms can be translated to RL algorithms. This
research area, known as offline RL, has largely focused on offline policy
optimization, aiming to find a return-maximizing policy exclusively from
offline data. In this paper, we consider a slightly different approach to
incorporating offline data into sequential decision-making. We aim to answer
the question, what unsupervised objectives applied to offline datasets are able
to learn state representations which elevate performance on downstream tasks,
whether those downstream tasks be online RL, imitation learning from expert
demonstrations, or even offline policy optimization based on the same offline
dataset? Through a variety of experiments utilizing standard offline RL
datasets, we find that the use of pretraining with unsupervised learning
objectives can dramatically improve the performance of policy learning
algorithms that otherwise yield mediocre performance on their own. Extensive
ablations further provide insights into what components of these unsupervised
objectives -- e.g., reward prediction, continuous or discrete representations,
pretraining or finetuning -- are most important and in which settings.
</p>
<a href="http://arxiv.org/abs/2102.05815" target="_blank">arXiv:2102.05815</a> [<a href="http://arxiv.org/pdf/2102.05815" target="_blank">pdf</a>]

<h2>Frame Difference-Based Temporal Loss for Video Stylization. (arXiv:2102.05822v1 [cs.CV])</h2>
<h3>Jianjin Xu, Zheyang Xiong, Xiaolin Hu</h3>
<p>Neural style transfer models have been used to stylize an ordinary video to
specific styles. To ensure temporal inconsistency between the frames of the
stylized video, a common approach is to estimate the optic flow of the pixels
in the original video and make the generated pixels match the estimated optical
flow. This is achieved by minimizing an optical flow-based (OFB) loss during
model training. However, optical flow estimation is itself a challenging task,
particularly in complex scenes. In addition, it incurs a high computational
cost. We propose a much simpler temporal loss called the frame difference-based
(FDB) loss to solve the temporal inconsistency problem. It is defined as the
distance between the difference between the stylized frames and the difference
between the original frames. The differences between the two frames are
measured in both the pixel space and the feature space specified by the
convolutional neural networks. A set of human behavior experiments involving 62
subjects with 25,600 votes showed that the performance of the proposed FDB loss
matched that of the OFB loss. The performance was measured by subjective
evaluation of stability and stylization quality of the generated videos on two
typical video stylization models. The results suggest that the proposed FDB
loss is a strong alternative to the commonly used OFB loss for video
stylization.
</p>
<a href="http://arxiv.org/abs/2102.05822" target="_blank">arXiv:2102.05822</a> [<a href="http://arxiv.org/pdf/2102.05822" target="_blank">pdf</a>]

<h2>Reproducibility Report: La-MAML: Look-ahead Meta Learning for Continual Learning. (arXiv:2102.05824v1 [cs.LG])</h2>
<h3>Joel Joseph, Alex Gu</h3>
<p>The Continual Learning (CL) problem involves performing well on a sequence of
tasks under limited compute. Current algorithms in the domain are either slow,
offline or sensitive to hyper-parameters. La-MAML, an optimization-based
meta-learning algorithm claims to be better than other replay-based,
prior-based and meta-learning based approaches. According to the MER paper [1],
metrics to measure performance in the continual learning arena are Retained
Accuracy (RA) and Backward Transfer-Interference (BTI). La-MAML claims to
perform better in these values when compared to the SOTA in the domain. This is
the main claim of the paper, which we shall be verifying in this report.
</p>
<a href="http://arxiv.org/abs/2102.05824" target="_blank">arXiv:2102.05824</a> [<a href="http://arxiv.org/pdf/2102.05824" target="_blank">pdf</a>]

<h2>Causal Inference for Time series Analysis: Problems, Methods and Evaluation. (arXiv:2102.05829v1 [cs.LG])</h2>
<h3>Raha Moraffah, Paras Sheth, Mansooreh Karami, Anchit Bhattacharya, Qianru Wang, Anique Tahir, Adrienne Raglin, Huan Liu</h3>
<p>Time series data is a collection of chronological observations which is
generated by several domains such as medical and financial fields. Over the
years, different tasks such as classification, forecasting, and clustering have
been proposed to analyze this type of data. Time series data has been also used
to study the effect of interventions over time. Moreover, in many fields of
science, learning the causal structure of dynamic systems and time series data
is considered an interesting task which plays an important role in scientific
discoveries. Estimating the effect of an intervention and identifying the
causal relations from the data can be performed via causal inference. Existing
surveys on time series discuss traditional tasks such as classification and
forecasting or explain the details of the approaches proposed to solve a
specific task. In this paper, we focus on two causal inference tasks, i.e.,
treatment effect estimation and causal discovery for time series data, and
provide a comprehensive review of the approaches in each task. Furthermore, we
curate a list of commonly used evaluation metrics and datasets for each task
and provide in-depth insight. These metrics and datasets can serve as
benchmarks for research in the field.
</p>
<a href="http://arxiv.org/abs/2102.05829" target="_blank">arXiv:2102.05829</a> [<a href="http://arxiv.org/pdf/2102.05829" target="_blank">pdf</a>]

<h2>Online Deterministic Annealing for Classification and Clustering. (arXiv:2102.05836v1 [cs.LG])</h2>
<h3>Christos Mavridis, John Baras</h3>
<p>We introduce an online prototype-based learning algorithm for clustering and
classification, based on the principles of deterministic annealing. We show
that the proposed algorithm constitutes a competitive-learning neural network,
the learning rule of which is formulated as an online stochastic approximation
algorithm. The annealing nature of the algorithm prevents poor local minima,
offers robustness with respect to the initial conditions, and provides a means
to progressively increase the complexity of the learning model as needed,
through an intuitive bifurcation phenomenon. As a result, the proposed approach
is interpretable, requires minimal hyper-parameter tuning, and offers online
control over the complexity-accuracy trade-off. Finally, Bregman divergences
are used as a family of dissimilarity measures that are shown to play an
important role in both the performance of the algorithm, and its computational
complexity. We illustrate the properties and evaluate the performance of the
proposed learning algorithm in artificial and real datasets.
</p>
<a href="http://arxiv.org/abs/2102.05836" target="_blank">arXiv:2102.05836</a> [<a href="http://arxiv.org/pdf/2102.05836" target="_blank">pdf</a>]

<h2>Driving Style Representation in Convolutional Recurrent Neural Network Model of Driver Identification. (arXiv:2102.05843v1 [cs.CV])</h2>
<h3>Sobhan Moosavi, Pravar D. Mahajan, Srinivasan Parthasarathy, Colleen Saunders-Chukwu, Rajiv Ramnath</h3>
<p>Identifying driving styles is the task of analyzing the behavior of drivers
in order to capture variations that will serve to discriminate different
drivers from each other. This task has become a prerequisite for a variety of
applications, including usage-based insurance, driver coaching, driver action
prediction, and even in designing autonomous vehicles; because driving style
encodes essential information needed by these applications. In this paper, we
present a deep-neural-network architecture, we term D-CRNN, for building
high-fidelity representations for driving style, that combine the power of
convolutional neural networks (CNN) and recurrent neural networks (RNN). Using
CNN, we capture semantic patterns of driver behavior from trajectories (such as
a turn or a braking event). We then find temporal dependencies between these
semantic patterns using RNN to encode driving style. We demonstrate the
effectiveness of these techniques for driver identification by learning driving
style through extensive experiments conducted on several large, real-world
datasets, and comparing the results with the state-of-the-art deep-learning and
non-deep-learning solutions. These experiments also demonstrate a useful
example of bias removal, by presenting how we preprocess the input data by
sampling dissimilar trajectories for each driver to prevent spatial
memorization. Finally, this paper presents an analysis of the contribution of
different attributes for driver identification; we find that engine RPM, Speed,
and Acceleration are the best combination of features.
</p>
<a href="http://arxiv.org/abs/2102.05843" target="_blank">arXiv:2102.05843</a> [<a href="http://arxiv.org/pdf/2102.05843" target="_blank">pdf</a>]

<h2>ZeroScatter: Domain Transfer for Long Distance Imaging and Vision through Scattering Media. (arXiv:2102.05847v1 [cs.CV])</h2>
<h3>Zheng Shi, Ethan Tseng, Mario Bijelic, Werner Ritter, Felix Heide</h3>
<p>Adverse weather conditions, including snow, rain, and fog pose a challenge
for both human and computer vision in outdoor scenarios. Handling these
environmental conditions is essential for safe decision making, especially in
autonomous vehicles, robotics, and drones. Most of today's supervised imaging
and vision approaches, however, rely on training data collected in the real
world that is biased towards good weather conditions, with dense fog, snow, and
heavy rain as outliers in these datasets. Without training data, let alone
paired data, existing autonomous vehicles often limit themselves to good
conditions and stop when dense fog or snow is detected. In this work, we tackle
the lack of supervised training data by combining synthetic and indirect
supervision. We present ZeroScatter, a domain transfer method for converting
RGB-only captures taken in adverse weather into clear daytime scenes.
ZeroScatter exploits model-based, temporal, multi-view, multi-modal, and
adversarial cues in a joint fashion, allowing us to train on unpaired, biased
data. We assess the proposed method using real-world captures, and the proposed
method outperforms existing monocular de-scattering approaches by 2.8 dB PSNR
on controlled fog chamber measurements.
</p>
<a href="http://arxiv.org/abs/2102.05847" target="_blank">arXiv:2102.05847</a> [<a href="http://arxiv.org/pdf/2102.05847" target="_blank">pdf</a>]

<h2>Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent. (arXiv:2102.05855v1 [stat.ML])</h2>
<h3>Rishav Chourasia, Jiayuan Ye, Reza Shokri</h3>
<p>We model the dynamics of privacy loss in Langevin diffusion and extend it to
the noisy gradient descent algorithm: we compute a tight bound on R\'enyi
differential privacy and the rate of its change throughout the learning
process. We prove that the privacy loss converges exponentially fast. This
significantly improves the prior privacy analysis of differentially private
(stochastic) gradient descent algorithms, where (R\'enyi) privacy loss
constantly increases over the training iterations. Unlike composition-based
methods in differential privacy, our privacy analysis does not assume that the
noisy gradients (or parameters) during the training could be revealed to the
adversary. Our analysis tracks the dynamics of privacy loss through the
algorithm's intermediate parameter distributions, thus allowing us to account
for privacy amplification due to convergence. We prove that our privacy
analysis is tight, and also provide a utility analysis for strongly convex,
smooth and Lipshitz loss functions.
</p>
<a href="http://arxiv.org/abs/2102.05855" target="_blank">arXiv:2102.05855</a> [<a href="http://arxiv.org/pdf/2102.05855" target="_blank">pdf</a>]

<h2>Predicting Clinical Deterioration in Hospitals. (arXiv:2102.05856v1 [cs.LG])</h2>
<h3>Laleh Jalali, Hsiu-Khuern Tang, Richard H. Goldstein, Joaqun Alvarez Rodrguez</h3>
<p>Responding rapidly to a patient who is demonstrating signs of imminent
clinical deterioration is a basic tenet of patient care. This gave rise to a
patient safety intervention philosophy known as a Rapid Response System (RRS),
whereby a patient who meets a pre-determined set of criteria for imminent
clinical deterioration is immediately assessed and treated, with the goal of
mitigating the deterioration and preventing intensive care unit (ICU) transfer,
cardiac arrest, or death. While RRSs have been widely adopted, multiple
systematic reviews have failed to find evidence of their effectiveness.
Typically, RRS criteria are simple, expert (consensus) defined rules that
identify significant physiologic abnormalities or are based on clinical
observation.

If one can find a pattern in the patient's data earlier than the onset of the
physiologic derangement manifest in the current criteria, intervention
strategies might be more effective. In this paper, we apply machine learning to
electronic medical records (EMR) to infer if patients are at risk for clinical
deterioration. Our models are more sensitive and offer greater advance
prediction time compared with existing rule-based methods that are currently
utilized in hospitals. Our results warrant further testing in the field; if
successful, hospitals can integrate our approach into their existing IT systems
and use the alerts generated by the model to prevent ICU transfer, cardiac
arrest, or death, or to reduce the ICU length of stay.
</p>
<a href="http://arxiv.org/abs/2102.05856" target="_blank">arXiv:2102.05856</a> [<a href="http://arxiv.org/pdf/2102.05856" target="_blank">pdf</a>]

<h2>Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic and Adversarial Linear Bandits Simultaneously. (arXiv:2102.05858v1 [cs.LG])</h2>
<h3>Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang, Xiaojin Zhang</h3>
<p>In this work, we develop linear bandit algorithms that automatically adapt to
different environments. By plugging a novel loss estimator into the
optimization problem that characterizes the instance-optimal strategy, our
first algorithm not only achieves nearly instance-optimal regret in stochastic
environments, but also works in corrupted environments with additional regret
being the amount of corruption, while the state-of-the-art (Li et al., 2019)
achieves neither instance-optimality nor the optimal dependence on the
corruption amount. Moreover, by equipping this algorithm with an adversarial
component and carefully-designed testings, our second algorithm additionally
enjoys minimax-optimal regret in completely adversarial environments, which is
the first of this kind to our knowledge. Finally, all our guarantees hold with
high probability, while existing instance-optimal guarantees only hold in
expectation.
</p>
<a href="http://arxiv.org/abs/2102.05858" target="_blank">arXiv:2102.05858</a> [<a href="http://arxiv.org/pdf/2102.05858" target="_blank">pdf</a>]

<h2>Adversarial Poisoning Attacks and Defense for General Multi-Class Models Based On Synthetic Reduced Nearest Neighbors. (arXiv:2102.05867v1 [cs.LG])</h2>
<h3>Pooya Tavallali, Vahid Behzadan, Peyman Tavallali, Mukesh Singhal</h3>
<p>State-of-the-art machine learning models are vulnerable to data poisoning
attacks whose purpose is to undermine the integrity of the model. However, the
current literature on data poisoning attacks is mainly focused on ad hoc
techniques that are only applicable to specific machine learning models.
Additionally, the existing data poisoning attacks in the literature are limited
to either binary classifiers or to gradient-based algorithms. To address these
limitations, this paper first proposes a novel model-free label-flipping attack
based on the multi-modality of the data, in which the adversary targets the
clusters of classes while constrained by a label-flipping budget. The
complexity of our proposed attack algorithm is linear in time over the size of
the dataset. Also, the proposed attack can increase the error up to two times
for the same attack budget. Second, a novel defense technique based on the
Synthetic Reduced Nearest Neighbor (SRNN) model is proposed. The defense
technique can detect and exclude flipped samples on the fly during the training
procedure. Through extensive experimental analysis, we demonstrate that (i) the
proposed attack technique can deteriorate the accuracy of several models
drastically, and (ii) under the proposed attack, the proposed defense technique
significantly outperforms other conventional machine learning models in
recovering the accuracy of the targeted model.
</p>
<a href="http://arxiv.org/abs/2102.05867" target="_blank">arXiv:2102.05867</a> [<a href="http://arxiv.org/pdf/2102.05867" target="_blank">pdf</a>]

<h2>ABOShips -- An Inshore and Offshore Maritime Vessel Detection Dataset with Precise Annotations. (arXiv:2102.05869v1 [cs.CV])</h2>
<h3>Bogdan Iancu, Valentin Soloviev, Luca Zelioli, Johan Lilius</h3>
<p>Availability of domain-specific datasets is an essential problem in object
detection. Maritime vessel detection of inshore and offshore datasets is no
exception, there is a limited number of studies addressing this need. For that
reason, we collected a dataset of images of maritime vessels taking into
account different factors: background variation, atmospheric conditions,
illumination, visible proportion, occlusion and scale variation. Vessel
instances (including 9 types of vessels), seamarks and miscellaneous floaters
were precisely annotated: we employed a first round of labelling and
subsequently, we used the CSRT [1] tracker to trace inconsistencies and relabel
inadequate label instances. Moreover, we evaluated the the out-of-the-box
performance of four prevalent object detection algorithms (Faster R-CNN [2],
R-FCN [3], SSD [4] and EfficientDet [5]). The algorithms were previously
trained on the Microsoft COCO dataset. We compare their accuracy based on
feature extractor and object size. Our experiments show that Faster R-CNN with
Inception-Resnet v2 outperforms the other algorithms, except in the large
object category where EfficientDet surpasses the latter.
</p>
<a href="http://arxiv.org/abs/2102.05869" target="_blank">arXiv:2102.05869</a> [<a href="http://arxiv.org/pdf/2102.05869" target="_blank">pdf</a>]

<h2>Explainability in CNN Models By Means of Z-Scores. (arXiv:2102.05874v1 [cs.CV])</h2>
<h3>David Malmgren-Hansen, Allan Aasbjerg Nielsen, Leif Toudal Pedersen</h3>
<p>This paper explores the similarities of output layers in Neural Networks
(NNs) with logistic regression to explain importance of inputs by Z-scores. The
network analyzed, a network for fusion of Synthetic Aperture Radar (SAR) and
Microwave Radiometry (MWR) data, is applied to prediction of arctic sea ice.
With the analysis the importance of MWR relative to SAR is found to favor MWR
components. Further, as the model represents image features at different
scales, the relative importance of these are as well analyzed. The suggested
methodology offers a simple and easy framework for analyzing output layer
components and can reduce the number of components for further analysis with
e.g. common NN visualization methods.
</p>
<a href="http://arxiv.org/abs/2102.05874" target="_blank">arXiv:2102.05874</a> [<a href="http://arxiv.org/pdf/2102.05874" target="_blank">pdf</a>]

<h2>Privacy-Preserving Self-Taught Federated Learning for Heterogeneous Data. (arXiv:2102.05883v1 [cs.LG])</h2>
<h3>Kai-Fung Chu, Lintao Zhang</h3>
<p>Many application scenarios call for training a machine learning model among
multiple participants. Federated learning (FL) was proposed to enable joint
training of a deep learning model using the local data in each party without
revealing the data to others. Among various types of FL methods, vertical FL is
a category to handle data sources with the same ID space and different feature
spaces. However, existing vertical FL methods suffer from limitations such as
restrictive neural network structure, slow training speed, and often lack the
ability to take advantage of data with unmatched IDs. In this work, we propose
an FL method called self-taught federated learning to address the
aforementioned issues, which uses unsupervised feature extraction techniques
for distributed supervised deep learning tasks. In this method, only latent
variables are transmitted to other parties for model training, while privacy is
preserved by storing the data and parameters of activations, weights, and
biases locally. Extensive experiments are performed to evaluate and demonstrate
the validity and efficiency of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.05883" target="_blank">arXiv:2102.05883</a> [<a href="http://arxiv.org/pdf/2102.05883" target="_blank">pdf</a>]

<h2>OpinionRank: Extracting Ground Truth Labels from Unreliable Expert Opinions with Graph-Based Spectral Ranking. (arXiv:2102.05884v1 [cs.LG])</h2>
<h3>Glenn Dawson, Robi Polikar</h3>
<p>As larger and more comprehensive datasets become standard in contemporary
machine learning, it becomes increasingly more difficult to obtain reliable,
trustworthy label information with which to train sophisticated models. To
address this problem, crowdsourcing has emerged as a popular, inexpensive, and
efficient data mining solution for performing distributed label collection.
However, crowdsourced annotations are inherently untrustworthy, as the labels
are provided by anonymous volunteers who may have varying, unreliable
expertise. Worse yet, some participants on commonly used platforms such as
Amazon Mechanical Turk may be adversarial, and provide intentionally incorrect
label information without the end user's knowledge. We discuss three
conventional models of the label generation process, describing their
parameterizations and the model-based approaches used to solve them. We then
propose OpinionRank, a model-free, interpretable, graph-based spectral
algorithm for integrating crowdsourced annotations into reliable labels for
performing supervised or semi-supervised learning. Our experiments show that
OpinionRank performs favorably when compared against more highly parameterized
algorithms. We also show that OpinionRank is scalable to very large datasets
and numbers of label sources, and requires considerably less computational
resources than previous approaches.
</p>
<a href="http://arxiv.org/abs/2102.05884" target="_blank">arXiv:2102.05884</a> [<a href="http://arxiv.org/pdf/2102.05884" target="_blank">pdf</a>]

<h2>Corner Cases for Visual Perception in Automated Driving: Some Guidance on Detection Approaches. (arXiv:2102.05897v1 [cs.CV])</h2>
<h3>Jasmin Breitenstein, Jan-Aike Term&#xf6;hlen, Daniel Lipinski, Tim Fingscheidt</h3>
<p>Automated driving has become a major topic of interest not only in the active
research community but also in mainstream media reports. Visual perception of
such intelligent vehicles has experienced large progress in the last decade
thanks to advances in deep learning techniques but some challenges still
remain. One such challenge is the detection of corner cases. They are
unexpected and unknown situations that occur while driving. Conventional visual
perception methods are often not able to detect them because corner cases have
not been witnessed during training. Hence, their detection is highly
safety-critical, and detection methods can be applied to vast amounts of
collected data to select suitable training data. A reliable detection of corner
cases will not only further automate the data selection procedure and increase
safety in autonomous driving but can thereby also affect the public acceptance
of the new technology in a positive manner. In this work, we continue a
previous systematization of corner cases on different levels by an extended set
of examples for each level. Moreover, we group detection approaches into
different categories and link them with the corner case levels. Hence, we give
directions to showcase specific corner cases and basic guidelines on how to
technically detect them.
</p>
<a href="http://arxiv.org/abs/2102.05897" target="_blank">arXiv:2102.05897</a> [<a href="http://arxiv.org/pdf/2102.05897" target="_blank">pdf</a>]

<h2>BoMb-OT: On Batch of Mini-batches Optimal Transport. (arXiv:2102.05912v1 [stat.ML])</h2>
<h3>Khai Nguyen, Quoc Nguyen, Nhat Ho, Tung Pham, Hung Bui, Dinh Phung, Trung Le</h3>
<p>Mini-batch optimal transport (m-OT) has been successfully used in practical
applications that involve probability measures with intractable density, or
probability measures with a very high number of supports. The m-OT solves
several sparser optimal transport problems and then returns the average of
their costs and transportation plans. Despite its scalability advantage, m-OT
is not a proper metric between probability measures since it does not satisfy
the identity property. To address this problem, we propose a novel
mini-batching scheme for optimal transport, named Batch of Mini-batches Optimal
Transport (BoMb-OT), that can be formulated as a well-defined distance on the
space of probability measures. Furthermore, we show that the m-OT is a limit of
the entropic regularized version of the proposed BoMb-OT when the regularized
parameter goes to infinity. We carry out extensive experiments to show that the
new mini-batching scheme can estimate a better transportation plan between two
original measures than m-OT. It leads to a favorable performance of BoMb-OT in
the matching and color transfer tasks. Furthermore, we observe that BoMb-OT
also provides a better objective loss than m-OT for doing approximate Bayesian
computation, estimating parameters of interest in parametric generative models,
and learning non-parametric generative models with gradient flow.
</p>
<a href="http://arxiv.org/abs/2102.05912" target="_blank">arXiv:2102.05912</a> [<a href="http://arxiv.org/pdf/2102.05912" target="_blank">pdf</a>]

<h2>PatchX: Explaining Deep Models by Intelligible Pattern Patches for Time-series Classification. (arXiv:2102.05917v1 [cs.LG])</h2>
<h3>Dominique Mercier, Andreas Dengel, Sheraz Ahmed</h3>
<p>The classification of time-series data is pivotal for streaming data and
comes with many challenges. Although the amount of publicly available datasets
increases rapidly, deep neural models are only exploited in a few areas.
Traditional methods are still used very often compared to deep neural models.
These methods get preferred in safety-critical, financial, or medical fields
because of their interpretable results. However, their performance and
scale-ability are limited, and finding suitable explanations for time-series
classification tasks is challenging due to the concepts hidden in the numerical
time-series data. Visualizing complete time-series results in a cognitive
overload concerning our perception and leads to confusion. Therefore, we
believe that patch-wise processing of the data results in a more interpretable
representation. We propose a novel hybrid approach that utilizes deep neural
networks and traditional machine learning algorithms to introduce an
interpretable and scale-able time-series classification approach. Our method
first performs a fine-grained classification for the patches followed by sample
level classification.
</p>
<a href="http://arxiv.org/abs/2102.05917" target="_blank">arXiv:2102.05917</a> [<a href="http://arxiv.org/pdf/2102.05917" target="_blank">pdf</a>]

<h2>Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v1 [cs.CV])</h2>
<h3>Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig</h3>
<p>Pre-trained representations are becoming crucial for many NLP and perception
tasks. While representation learning in NLP has transitioned to training on raw
text without human annotations, visual and vision-language representations
still rely heavily on curated training datasets that are expensive or require
expert knowledge. For vision applications, representations are mostly learned
using datasets with explicit class labels such as ImageNet or OpenImages. For
vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all
involve a non-trivial data collection (and cleaning) process. This costly
curation process limits the size of datasets and hence hinders the scaling of
trained models. In this paper, we leverage a noisy dataset of over one billion
image alt-text pairs, obtained without expensive filtering or post-processing
steps in the Conceptual Captions dataset. A simple dual-encoder architecture
learns to align visual and language representations of the image and text pairs
using a contrastive loss. We show that the scale of our corpus can make up for
its noise and leads to state-of-the-art representations even with such a simple
learning scheme. Our visual representation achieves strong performance when
transferred to classification tasks such as ImageNet and VTAB. The aligned
visual and language representations also set new state-of-the-art results on
Flickr30K and MSCOCO benchmarks, even when compared with more sophisticated
cross-attention models. The representations also enable cross-modality search
with complex text and text + image queries.
</p>
<a href="http://arxiv.org/abs/2102.05918" target="_blank">arXiv:2102.05918</a> [<a href="http://arxiv.org/pdf/2102.05918" target="_blank">pdf</a>]

<h2>Adversarially robust deepfake media detection using fused convolutional neural network predictions. (arXiv:2102.05950v1 [cs.CV])</h2>
<h3>Sohail Ahmed Khan, Alessandro Artusi, Hang Dai</h3>
<p>Deepfakes are synthetically generated images, videos or audios, which
fraudsters use to manipulate legitimate information. Current deepfake detection
systems struggle against unseen data. To address this, we employ three
different deep Convolutional Neural Network (CNN) models, (1) VGG16, (2)
InceptionV3, and (3) XceptionNet to classify fake and real images extracted
from videos. We also constructed a fusion of the deep CNN models to improve the
robustness and generalisation capability. The proposed technique outperforms
state-of-the-art models with 96.5% accuracy, when tested on publicly available
DeepFake Detection Challenge (DFDC) test data, comprising of 400 videos. The
fusion model achieves 99% accuracy on lower quality DeepFake-TIMIT dataset
videos and 91.88% on higher quality DeepFake-TIMIT videos. In addition to this,
we prove that prediction fusion is more robust against adversarial attacks. If
one model is compromised by an adversarial attack, the prediction fusion does
not let it affect the overall classification.
</p>
<a href="http://arxiv.org/abs/2102.05950" target="_blank">arXiv:2102.05950</a> [<a href="http://arxiv.org/pdf/2102.05950" target="_blank">pdf</a>]

<h2>The Benefit of the Doubt: Uncertainty Aware Sensing for Edge Computing Platforms. (arXiv:2102.05956v1 [cs.LG])</h2>
<h3>Lorena Qendro, Jagmohan Chauhan, Alberto Gil C. P. Ramos, Cecilia Mascolo</h3>
<p>Neural networks (NNs) lack measures of "reliability" estimation that would
enable reasoning over their predictions. Despite the vital importance,
especially in areas of human well-being and health, state-of-the-art
uncertainty estimation techniques are computationally expensive when applied to
resource-constrained devices. We propose an efficient framework for predictive
uncertainty estimation in NNs deployed on embedded edge systems with no need
for fine-tuning or re-training strategies. To meet the energy and latency
requirements of these embedded platforms the framework is built from the ground
up to provide predictive uncertainty based only on one forward pass and a
negligible amount of additional matrix multiplications with theoretically
proven correctness. Our aim is to enable already trained deep learning models
to generate uncertainty estimates on resource-limited devices at inference time
focusing on classification tasks. This framework is founded on theoretical
developments casting dropout training as approximate inference in Bayesian NNs.
Our layerwise distribution approximation to the convolution layer cascades
through the network, providing uncertainty estimates in one single run which
ensures minimal overhead, especially compared with uncertainty techniques that
require multiple forwards passes and an equal linear rise in energy and latency
requirements making them unsuitable in practice. We demonstrate that it yields
better performance and flexibility over previous work based on multilayer
perceptrons to obtain uncertainty estimates. Our evaluation with mobile
applications datasets shows that our approach not only obtains robust and
accurate uncertainty estimations but also outperforms state-of-the-art methods
in terms of systems performance, reducing energy consumption (up to 28x),
keeping the memory overhead at a minimum while still improving accuracy (up to
16%).
</p>
<a href="http://arxiv.org/abs/2102.05956" target="_blank">arXiv:2102.05956</a> [<a href="http://arxiv.org/pdf/2102.05956" target="_blank">pdf</a>]

<h2>AutoScore: An Automated Warning Score Model for the Early Prediction of Clinical Events. (arXiv:2102.05958v1 [cs.LG])</h2>
<h3>Ibrahim Hammoud, Prateek Prasanna, IV Ramakrishnan, Adam Singer, Mark Henry, Henry Thode</h3>
<p>Early prediction of patients at risk of clinical deterioration can help
physicians intervene and alter their clinical course towards better outcomes.
In addition to the accuracy requirement, early warning systems must make the
predictions early enough to give physicians enough time to intervene.
Interpretability is also one of the challenges when building such systems since
being able to justify the reasoning behind model decisions is desirable in
clinical practice. In this work, we built an interpretable model for the early
prediction of various adverse clinical events indicative of clinical
deterioration. The model is evaluated on two datasets and four clinical events.
The first dataset is collected in a predominantly COVID-19 positive population
at Stony Brook Hospital. The second dataset is the MIMIC III dataset. The model
was trained to provide early warning scores for ventilation, ICU transfer, and
mortality prediction tasks on the Stony Brook Hospital dataset and to predict
mortality and the need for vasopressors on the MIMIC III dataset. Our model
first separates each feature into multiple ranges and then uses logistic
regression with lasso penalization to select the subset of ranges for each
feature. The model training is completely automated and doesn't require expert
knowledge like other early warning scores. We compare our model to the Modified
Early Warning Score (MEWS) and quick SOFA (qSOFA), commonly used in hospitals.
We show that our model outperforms these models in the area under the receiver
operating characteristic curve (AUROC) while having a similar or better median
detection time on all clinical events, even when using fewer features. Unlike
MEWS and qSOFA, our model can be entirely automated without requiring any
manually recorded features. We also show that discretization improves model
performance by comparing our model to a baseline logistic regression model.
</p>
<a href="http://arxiv.org/abs/2102.05958" target="_blank">arXiv:2102.05958</a> [<a href="http://arxiv.org/pdf/2102.05958" target="_blank">pdf</a>]

<h2>Comparative Analysis of Machine Learning Approaches to Analyze and Predict the Covid-19 Outbreak. (arXiv:2102.05960v1 [stat.ML])</h2>
<h3>Muhammad Naeem, Jian Yu, Muhammad Aamir, Sajjad Ahmad Khan, Olayinka Adeleye, Zardad Khan</h3>
<p>Background. Forecasting the time of forthcoming pandemic reduces the impact
of diseases by taking precautionary steps such as public health messaging and
raising the consciousness of doctors. With the continuous and rapid increase in
the cumulative incidence of COVID-19, statistical and outbreak prediction
models including various machine learning (ML) models are being used by the
research community to track and predict the trend of the epidemic, and also in
developing appropriate strategies to combat and manage its spread. Methods. In
this paper, we present a comparative analysis of various ML approaches
including Support Vector Machine, Random Forest, K-Nearest Neighbor and
Artificial Neural Network in predicting the COVID-19 outbreak in the
epidemiological domain. We first apply the autoregressive distributed lag
(ARDL) method to identify and model the short and long-run relationships of the
time-series COVID-19 datasets. That is, we determine the lags between a
response variable and its respective explanatory time series variables as
independent variables. Then, the resulting significant variables concerning
their lags are used in the regression model selected by the ARDL for predicting
and forecasting the trend of the epidemic. Results. Statistical measures i.e.,
Root Mean Square Error (RMSE), Mean Absolute Error (MAE) and Mean Absolute
Percentage Error (MAPE) are used for model accuracy. The values of MAPE for the
best selected models for confirmed, recovered and deaths cases are 0.407, 0.094
and 0.124 respectively, which falls under the category of highly accurate
forecasts. In addition, we computed fifteen days ahead forecast for the daily
deaths, recover, and confirm patients and the cases fluctuated across time in
all aspects. Besides, the results reveal the advantages of ML algorithms for
supporting decision making of evolving short term policies.
</p>
<a href="http://arxiv.org/abs/2102.05960" target="_blank">arXiv:2102.05960</a> [<a href="http://arxiv.org/pdf/2102.05960" target="_blank">pdf</a>]

<h2>VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic Environments. (arXiv:2102.05965v1 [cs.RO])</h2>
<h3>Koji Minoda, Fabian Schilling, Valentin W&#xfc;est, Dario Floreano, Takehisa Yairi</h3>
<p>Dynamic environments such as urban areas are still challenging for popular
visual-inertial odometry (VIO) algorithms. Existing datasets typically fail to
capture the dynamic nature of these environments, therefore making it difficult
to quantitatively evaluate the robustness of existing VIO methods. To address
this issue, we propose three contributions: firstly, we provide the VIODE
benchmark, a novel dataset recorded from a simulated UAV that navigates in
challenging dynamic environments. The unique feature of the VIODE dataset is
the systematic introduction of moving objects into the scenes. It includes
three environments, each of which is available in four dynamic levels that
progressively add moving objects. The dataset contains synchronized stereo
images and IMU data, as well as ground-truth trajectories and instance
segmentation masks. Secondly, we compare state-of-the-art VIO algorithms on the
VIODE dataset and show that they display substantial performance degradation in
highly dynamic scenes. Thirdly, we propose a simple extension for visual
localization algorithms that relies on semantic information. Our results show
that scene semantics are an effective way to mitigate the adverse effects of
dynamic objects on VIO algorithms. Finally, we make the VIODE dataset publicly
available at https://github.com/kminoda/VIODE.
</p>
<a href="http://arxiv.org/abs/2102.05965" target="_blank">arXiv:2102.05965</a> [<a href="http://arxiv.org/pdf/2102.05965" target="_blank">pdf</a>]

<h2>L-SNet: from Region Localization to Scale Invariant Medical Image Segmentation. (arXiv:2102.05971v1 [cs.CV])</h2>
<h3>Jiahao Xie, Sheng Zhang, Jianwei Lu, Ye Luo</h3>
<p>Coarse-to-fine models and cascade segmentation architectures are widely
adopted to solve the problem of large scale variations in medical image
segmentation. However, those methods have two primary limitations: the
first-stage segmentation becomes a performance bottleneck; the lack of overall
differentiability makes the training process of two stages asynchronous and
inconsistent. In this paper, we propose a differentiable two-stage network
architecture to tackle these problems. In the first stage, a localization
network (L-Net) locates Regions of Interest (RoIs) in a detection fashion; in
the second stage, a segmentation network (S-Net) performs fine segmentation on
the recalibrated RoIs; a RoI recalibration module between L-Net and S-Net
eliminating the inconsistencies. Experimental results on the public dataset
show that our method outperforms state-of-the-art coarse-to-fine models with
negligible computation overheads.
</p>
<a href="http://arxiv.org/abs/2102.05971" target="_blank">arXiv:2102.05971</a> [<a href="http://arxiv.org/pdf/2102.05971" target="_blank">pdf</a>]

<h2>HyperPocket: Generative Point Cloud Completion. (arXiv:2102.05973v1 [cs.CV])</h2>
<h3>Przemys&#x142;aw Spurek, Artur Kasymov, Marcin Mazur, Diana Janik, S&#x142;awomir Tadeja, &#x141;ukasz Struski, Jacek Tabor, Tomasz Trzci&#x144;ski</h3>
<p>Scanning real-life scenes with modern registration devices typically give
incomplete point cloud representations, mostly due to the limitations of the
scanning process and 3D occlusions. Therefore, completing such partial
representations remains a fundamental challenge of many computer vision
applications. Most of the existing approaches aim to solve this problem by
learning to reconstruct individual 3D objects in a synthetic setup of an
uncluttered environment, which is far from a real-life scenario. In this work,
we reformulate the problem of point cloud completion into an object
hallucination task. Thus, we introduce a novel autoencoder-based architecture
called HyperPocket that disentangles latent representations and, as a result,
enables the generation of multiple variants of the completed 3D point clouds.
We split point cloud processing into two disjoint data streams and leverage a
hypernetwork paradigm to fill the spaces, dubbed pockets, that are left by the
missing object parts. As a result, the generated point clouds are not only
smooth but also plausible and geometrically consistent with the scene. Our
method offers competitive performances to the other state-of-the-art models,
and it enables a~plethora of novel applications.
</p>
<a href="http://arxiv.org/abs/2102.05973" target="_blank">arXiv:2102.05973</a> [<a href="http://arxiv.org/pdf/2102.05973" target="_blank">pdf</a>]

<h2>Investigating Trade-offs in Utility, Fairness and Differential Privacy in Neural Networks. (arXiv:2102.05975v1 [cs.LG])</h2>
<h3>Marlotte Pannekoek, Giacomo Spigler</h3>
<p>To enable an ethical and legal use of machine learning algorithms, they must
both be fair and protect the privacy of those whose data are being used.
However, implementing privacy and fairness constraints might come at the cost
of utility (Jayaraman &amp; Evans, 2019; Gong et al., 2020). This paper
investigates the privacy-utility-fairness trade-off in neural networks by
comparing a Simple (S-NN), a Fair (F-NN), a Differentially Private (DP-NN), and
a Differentially Private and Fair Neural Network (DPF-NN) to evaluate
differences in performance on metrics for privacy (epsilon, delta), fairness
(risk difference), and utility (accuracy). In the scenario with the highest
considered privacy guarantees (epsilon = 0.1, delta = 0.00001), the DPF-NN was
found to achieve better risk difference than all the other neural networks with
only a marginally lower accuracy than the S-NN and DP-NN. This model is
considered fair as it achieved a risk difference below the strict (0.05) and
lenient (0.1) thresholds. However, while the accuracy of the proposed model
improved on previous work from Xu, Yuan and Wu (2019), the risk difference was
found to be worse.
</p>
<a href="http://arxiv.org/abs/2102.05975" target="_blank">arXiv:2102.05975</a> [<a href="http://arxiv.org/pdf/2102.05975" target="_blank">pdf</a>]

<h2>Tackling Virtual and Real Concept Drifts: An Adaptive Gaussian Mixture Model. (arXiv:2102.05983v1 [cs.LG])</h2>
<h3>Gustavo Oliveira, Leandro Minku, Adriano Oliveira</h3>
<p>Real-world applications have been dealing with large amounts of data that
arrive over time and generally present changes in their underlying joint
probability distribution, i.e., concept drift. Concept drift can be subdivided
into two types: virtual drift, which affects the unconditional probability
distribution p(x), and real drift, which affects the conditional probability
distribution p(y|x). Existing works focuses on real drift. However, strategies
to cope with real drift may not be the best suited for dealing with virtual
drift, since the real class boundaries remain unchanged. We provide the first
in depth analysis of the differences between the impact of virtual and real
drifts on classifiers' suitability. We propose an approach to handle both
drifts called On-line Gaussian Mixture Model With Noise Filter For Handling
Virtual and Real Concept Drifts (OGMMF-VRD). Experiments with 7 synthetic and 3
real-world datasets show that OGMMF-VRD obtained the best results in terms of
average accuracy, G-mean and runtime compared to existing approaches. Moreover,
its accuracy over time suffered less performance degradation in the presence of
drifts.
</p>
<a href="http://arxiv.org/abs/2102.05983" target="_blank">arXiv:2102.05983</a> [<a href="http://arxiv.org/pdf/2102.05983" target="_blank">pdf</a>]

<h2>Modeling 3D Surface Manifolds with a Locally Conditioned Atlas. (arXiv:2102.05984v1 [cs.CV])</h2>
<h3>Przemys&#x142;aw Spurek, Sebastian Winczowski, Maciej Zi&#x119;ba, Tomasz Trzci&#x144;ski, Kacper Kania</h3>
<p>Recently proposed 3D object reconstruction methods represent a mesh with an
atlas - a set of planar patches approximating the surface. However, their
application in a real-world scenario is limited since the surfaces of
reconstructed objects contain discontinuities, which degrades the quality of
the final mesh. This is mainly caused by independent processing of individual
patches, and in this work, we postulate to mitigate this limitation by
preserving local consistency around patch vertices. To that end, we introduce a
Locally Conditioned Atlas (LoCondA), a framework for representing a 3D object
hierarchically in a generative model. Firstly, the model maps a point cloud of
an object into a sphere. Secondly, by leveraging a spherical prior, we enforce
the mapping to be locally consistent on the sphere and on the target object.
This way, we can sample a mesh quad on that sphere and project it back onto the
object's manifold. With LoCondA, we can produce topologically diverse objects
while maintaining quads to be stitched together. We show that the proposed
approach provides structurally coherent reconstructions while producing meshes
of quality comparable to the competitors.
</p>
<a href="http://arxiv.org/abs/2102.05984" target="_blank">arXiv:2102.05984</a> [<a href="http://arxiv.org/pdf/2102.05984" target="_blank">pdf</a>]

<h2>Robust Generalization and Safe Query-Specialization in Counterfactual Learning to Rank. (arXiv:2102.05990v1 [cs.LG])</h2>
<h3>Harrie Oosterhuis, Maarten de Rijke</h3>
<p>Existing work in counterfactual Learning to Rank (LTR) has focussed on
optimizing feature-based models that predict the optimal ranking based on
document features. LTR methods based on bandit algorithms often optimize
tabular models that memorize the optimal ranking per query. These types of
model have their own advantages and disadvantages. Feature-based models provide
very robust performance across many queries, including those previously unseen,
however, the available features often limit the rankings the model can predict.
In contrast, tabular models can converge on any possible ranking through
memorization. However, memorization is extremely prone to noise, which makes
tabular models reliable only when large numbers of user interactions are
available. Can we develop a robust counterfactual LTR method that pursues
memorization-based optimization whenever it is safe to do? We introduce the
Generalization and Specialization (GENSPEC) algorithm, a robust feature-based
counterfactual LTR method that pursues per-query memorization when it is safe
to do so. GENSPEC optimizes a single feature-based model for generalization:
robust performance across all queries, and many tabular models for
specialization: each optimized for high performance on a single query. GENSPEC
uses novel relative high-confidence bounds to choose which model to deploy per
query. By doing so, GENSPEC enjoys the high performance of successfully
specialized tabular models with the robustness of a generalized feature-based
model. Our results show that GENSPEC leads to optimal performance on queries
with sufficient click data, while having robust behavior on queries with little
or noisy data.
</p>
<a href="http://arxiv.org/abs/2102.05990" target="_blank">arXiv:2102.05990</a> [<a href="http://arxiv.org/pdf/2102.05990" target="_blank">pdf</a>]

<h2>Fairness Through Regularization for Learning to Rank. (arXiv:2102.05996v1 [cs.LG])</h2>
<h3>Nikola Konstantinov, Christoph H. Lampert</h3>
<p>Given the abundance of applications of ranking in recent years, addressing
fairness concerns around automated ranking systems becomes necessary for
increasing the trust among end-users. Previous work on fair ranking has mostly
focused on application-specific fairness notions, often tailored to online
advertising, and it rarely considers learning as part of the process. In this
work, we show how to transfer numerous fairness notions from binary
classification to a learning to rank context. Our formalism allows us to design
a method for incorporating fairness objectives with provable generalization
guarantees. An extensive experimental evaluation shows that our method can
improve ranking fairness substantially with no or only little loss of model
quality.
</p>
<a href="http://arxiv.org/abs/2102.05996" target="_blank">arXiv:2102.05996</a> [<a href="http://arxiv.org/pdf/2102.05996" target="_blank">pdf</a>]

<h2>Fairness-Aware Learning from Corrupted Data. (arXiv:2102.06004v1 [cs.LG])</h2>
<h3>Nikola Konstantinov, Christoph H. Lampert</h3>
<p>Addressing fairness concerns about machine learning models is a crucial step
towards their long-term adoption in real-world automated systems. While many
approaches have been developed for training fair models from data, little is
known about the effects of data corruption on these methods. In this work we
consider fairness-aware learning under arbitrary data manipulations. We show
that an adversary can force any learner to return a biased classifier, with or
without degrading accuracy, and that the strength of this bias increases for
learning problems with underrepresented protected groups in the data. We also
provide upper bounds that match these hardness results up to constant factors,
by proving that two natural learning algorithms achieve order-optimal
guarantees in terms of both accuracy and fairness under adversarial data
manipulations.
</p>
<a href="http://arxiv.org/abs/2102.06004" target="_blank">arXiv:2102.06004</a> [<a href="http://arxiv.org/pdf/2102.06004" target="_blank">pdf</a>]

<h2>Reinforcement Learning For Constraint Satisfaction Game Agents (15-Puzzle, Minesweeper, 2048, and Sudoku). (arXiv:2102.06019v1 [cs.LG])</h2>
<h3>Anav Mehta</h3>
<p>In recent years, reinforcement learning has seen interest because of deep
Q-Learning, where the model is a convolutional neural network. Deep Q-Learning
has shown promising results in games such as Atari and AlphaGo. Instead of
learning the entire Q-table, it learns an estimate of the Q function that
determines a state's policy action. We use Q-Learning and deep Q-learning, to
learn control policies of four constraint satisfaction games (15-Puzzle,
Minesweeper, 2048, and Sudoku). 15-Puzzle is a sliding permutation puzzle and
provides a challenge in addressing its large state space. Minesweeper and
Sudoku involve partially observable states and guessing. 2048 is also a sliding
puzzle but allows for easier state representation (compared to 15-Puzzle) and
uses interesting reward shaping to solve the game. These games offer unique
insights into the potential and limits of reinforcement learning. The Q agent
is trained with no rules of the game, with only the reward corresponding to
each state's action. Our unique contribution is in choosing the reward
structure, state representation, and formulation of the deep neural network.
For low shuffle, 15-Puzzle, achieves a 100% win rate, the medium and high
shuffle achieve about 43% and 22% win rates respectively. On a standard 16x16
Minesweeper board, both low and high-density boards achieve close to 45% win
rate, whereas medium density boards have a low win rate of 15%. For 2048, the
1024 win rate was achieved with significant ease (100%) with high win rates for
2048, 4096, 8192 and 16384 as 40%, 0.05%, 0.01% and 0.004% , respectively. The
easy Sudoku games had a win rate of 7%, while medium and hard games had 2.1%
and 1.2% win rates, respectively. This paper explores the environment
complexity and behavior of a subset of constraint games using reward structures
which can get us closer to understanding how humans learn.
</p>
<a href="http://arxiv.org/abs/2102.06019" target="_blank">arXiv:2102.06019</a> [<a href="http://arxiv.org/pdf/2102.06019" target="_blank">pdf</a>]

<h2>The Barrier of meaning in archaeological data science. (arXiv:2102.06022v1 [cs.CV])</h2>
<h3>Luca Casini, Marco Roccetti, Giovanni Delnevo, Nicolo&#x27; Marchetti, Valentina Orru&#x27;</h3>
<p>Archaeologists, like other scientists, are experiencing a data-flood in their
discipline, fueled by a surge in computing power and devices that enable the
creation, collection, storage and transfer of an increasingly complex (and
large) amount of data, such as remotely sensed imagery from a multitude of
sources. In this paper, we pose the preliminary question if this increasing
availability of information actually needs new computerized techniques, and
Artificial Intelligence methods, to make new and deeper understanding into
archaeological problems. Simply said, while it is a fact that Deep Learning
(DL) has become prevalent as a type of machine learning design inspired by the
way humans learn, and utilized to perform automatic actions people might
describe as intelligent, we want to anticipate, here, a discussion around the
subject whether machines, trained following this procedure, can extrapolate,
from archaeological data, concepts and meaning in the same way that humans
would do. Even prior to getting to technical results, we will start our
reflection with a very basic concept: Is a collection of satellite images with
notable archaeological sites informative enough to instruct a DL machine to
discover new archaeological sites, as well as other potential locations of
interest? Further, what if similar results could be reached with less
intelligent machines that learn by having people manually program them with
rules? Finally: If with barrier of meaning we refer to the extent to which
human-like understanding can be achieved by a machine, where should be posed
that barrier in the archaeological data science?
</p>
<a href="http://arxiv.org/abs/2102.06022" target="_blank">arXiv:2102.06022</a> [<a href="http://arxiv.org/pdf/2102.06022" target="_blank">pdf</a>]

<h2>Feature Selection for Multivariate Time Series via Network Pruning. (arXiv:2102.06024v1 [cs.LG])</h2>
<h3>Kang Gu, Soroush Vosoughi, Temiloluwa Prioleau</h3>
<p>In recent years, there has been an ever increasing amount of multivariate
time series (MTS) data in various domains, typically generated by a large
family of sensors such as wearable devices. This has led to the development of
novel learning methods on MTS data, with deep learning models dominating the
most recent advancements. Prior literature has primarily focused on designing
new network architectures for modeling temporal dependencies within MTS.
However, a less studied challenge is associated with high dimensionality of MTS
data. In this paper, we propose a novel neural component, namely Neural Feature
Se-lector (NFS), as an end-2-end solution for feature selection in MTS data.
Specifically, NFS is based on decomposed convolution design and includes two
modules: firstly each feature stream within MTS is processed by a temporal CNN
independently; then an aggregating CNN combines the processed streams to
produce input for other downstream networks. We evaluated the proposed NFS
model on four real-world MTS datasets and found that it achieves comparable
results with state-of-the-art methods while providing the benefit of feature
selection. Our paper also highlights the robustness and effectiveness of
feature selection with NFS compared to using recent autoencoder-based methods.
</p>
<a href="http://arxiv.org/abs/2102.06024" target="_blank">arXiv:2102.06024</a> [<a href="http://arxiv.org/pdf/2102.06024" target="_blank">pdf</a>]

<h2>Large-Scale Training System for 100-Million Classification at Alibaba. (arXiv:2102.06025v1 [cs.LG])</h2>
<h3>Liuyihan Song, Pan Pan, Kang Zhao, Hao Yang, Yiming Chen, Yingya Zhang, Yinghui Xu, Rong Jin</h3>
<p>In the last decades, extreme classification has become an essential topic for
deep learning. It has achieved great success in many areas, especially in
computer vision and natural language processing (NLP). However, it is very
challenging to train a deep model with millions of classes due to the memory
and computation explosion in the last output layer. In this paper, we propose a
large-scale training system to address these challenges. First, we build a
hybrid parallel training framework to make the training process feasible.
Second, we propose a novel softmax variation named KNN softmax, which reduces
both the GPU memory consumption and computation costs and improves the
throughput of training. Then, to eliminate the communication overhead, we
propose a new overlapping pipeline and a gradient sparsification method.
Furthermore, we design a fast continuous convergence strategy to reduce total
training iterations by adaptively adjusting learning rate and updating model
parameters. With the help of all the proposed methods, we gain 3.9$\times$
throughput of our training system and reduce almost 60\% of training
iterations. The experimental results show that using an in-house 256 GPUs
cluster, we could train a classifier of 100 million classes on Alibaba Retail
Product Dataset in about five days while achieving a comparable accuracy with
the naive softmax training process.
</p>
<a href="http://arxiv.org/abs/2102.06025" target="_blank">arXiv:2102.06025</a> [<a href="http://arxiv.org/pdf/2102.06025" target="_blank">pdf</a>]

<h2>Roughsets-based Approach for Predicting Battery Life in IoT. (arXiv:2102.06026v1 [cs.LG])</h2>
<h3>Rajesh Kaluri, Dharmendra Singh Rajput, Qin Xin, Kuruva Lakshmanna, Sweta Bhattacharya, Thippa Reddy Gadekallu, Praveen Kumar Reddy Maddikunta</h3>
<p>Internet of Things (IoT) and related applications have successfully
contributed towards enhancing the value of life in this planet. The advanced
wireless sensor networks and its revolutionary computational capabilities have
enabled various IoT applications become the next frontier, touching almost all
domains of life. With this enormous progress, energy optimization has also
become a primary concern with the need to attend to green technologies. The
present study focuses on the predictions pertinent to the sustainability of
battery life in IoT frameworks in the marine environment. The data used is a
publicly available dataset collected from the Chicago district beach water.
Firstly, the missing values in the data are replaced with the attribute mean.
Later, one-hot encoding technique is applied for achieving data homogeneity
followed by the standard scalar technique to normalize the data. Then, rough
set theory is used for feature extraction, and the resultant data is fed into a
Deep Neural Network (DNN) model for the optimized prediction results. The
proposed model is then compared with the state of the art machine learning
models and the results justify its superiority on the basis of performance
metrics such as Mean Squared Error, Mean Absolute Error, Root Mean Squared
Error, and Test Variance Score.
</p>
<a href="http://arxiv.org/abs/2102.06026" target="_blank">arXiv:2102.06026</a> [<a href="http://arxiv.org/pdf/2102.06026" target="_blank">pdf</a>]

<h2>STUaNet: Understanding uncertainty in spatiotemporal collective human mobility. (arXiv:2102.06027v1 [cs.LG])</h2>
<h3>Zhengyang Zhou, Yang Wang, Xike Xie, Lei Qiao, Yuantao Li</h3>
<p>The high dynamics and heterogeneous interactions in the complicated urban
systems have raised the issue of uncertainty quantification in spatiotemporal
human mobility, to support critical decision-makings in risk-aware web
applications such as urban event prediction where fluctuations are of
significant interests. Given the fact that uncertainty quantifies the potential
variations around prediction results, traditional learning schemes always lack
uncertainty labels, and conventional uncertainty quantification approaches
mostly rely upon statistical estimations with Bayesian Neural Networks or
ensemble methods. However, they have never involved any spatiotemporal
evolution of uncertainties under various contexts, and also have kept suffering
from the poor efficiency of statistical uncertainty estimation while training
models with multiple times. To provide high-quality uncertainty quantification
for spatiotemporal forecasting, we propose an uncertainty learning mechanism to
simultaneously estimate internal data quality and quantify external uncertainty
regarding various contextual interactions. To address the issue of lacking
labels of uncertainty, we propose a hierarchical data turbulence scheme where
we can actively inject controllable uncertainty for guidance, and hence provide
insights to both uncertainty quantification and weak supervised learning.
Finally, we re-calibrate and boost the prediction performance by devising a
gated-based bridge to adaptively leverage the learned uncertainty into
predictions. Extensive experiments on three real-world spatiotemporal mobility
sets have corroborated the superiority of our proposed model in terms of both
forecasting and uncertainty quantification.
</p>
<a href="http://arxiv.org/abs/2102.06027" target="_blank">arXiv:2102.06027</a> [<a href="http://arxiv.org/pdf/2102.06027" target="_blank">pdf</a>]

<h2>Feature Analyses and Modelling of Lithium-ion Batteries Manufacturing based on Random Forest Classification. (arXiv:2102.06029v1 [cs.LG])</h2>
<h3>Kailong Liu, Xiaosong Hu, Huiyu Zhou, Lei Tong, W. Dhammika Widanage, James Marco</h3>
<p>Lithium-ion battery manufacturing is a highly complicated process with
strongly coupled feature interdependencies, a feasible solution that can
analyse feature variables within manufacturing chain and achieve reliable
classification is thus urgently needed. This article proposes a random forest
(RF)-based classification framework, through using the out of bag (OOB)
predictions, Gini changes as well as predictive measure of association (PMOA),
for effectively quantifying the importance and correlations of battery
manufacturing features and their effects on the classification of electrode
properties. Battery manufacturing data containing three intermediate product
features from the mixing stage and one product parameter from the coating stage
are analysed by the designed RF framework to investigate their effects on both
the battery electrode active material mass load and porosity. Illustrative
results demonstrate that the proposed RF framework not only achieves the
reliable classification of electrode properties but also leads to the effective
quantification of both manufacturing feature importance and correlations. This
is the first time to design a systematic RF framework for simultaneously
quantifying battery production feature importance and correlations by three
various quantitative indicators including the unbiased feature importance (FI),
gain improvement FI and PMOA, paving a promising solution to reduce model
dimension and conduct efficient sensitivity analysis of battery manufacturing.
</p>
<a href="http://arxiv.org/abs/2102.06029" target="_blank">arXiv:2102.06029</a> [<a href="http://arxiv.org/pdf/2102.06029" target="_blank">pdf</a>]

<h2>An Ensemble Deep Convolutional Neural Network Model for Electricity Theft Detection in Smart Grids. (arXiv:2102.06039v1 [cs.LG])</h2>
<h3>Hossein Mohammadi Rouzbahani, Hadis Karimipour, Lei Lei</h3>
<p>Smart grids extremely rely on Information and Communications Technology (ICT)
and smart meters to control and manage numerous parameters of the network.
However, using these infrastructures make smart grids more vulnerable to cyber
threats especially electricity theft. Electricity Theft Detection (EDT)
algorithms are typically used for such purpose since this Non-Technical Loss
(NTL) may lead to significant challenges in the power system. In this paper, an
Ensemble Deep Convolutional Neural Network (EDCNN) algorithm for ETD in smart
grids has been proposed. As the first layer of the model, a random under
bagging technique is applied to deal with the imbalance data, and then Deep
Convolutional Neural Networks (DCNN) are utilized on each subset. Finally, a
voting system is embedded, in the last part. The evaluation results based on
the Area Under Curve (AUC), precision, recall, f1-score, and accuracy verify
the efficiency of the proposed method compared to the existing method in the
literature.
</p>
<a href="http://arxiv.org/abs/2102.06039" target="_blank">arXiv:2102.06039</a> [<a href="http://arxiv.org/pdf/2102.06039" target="_blank">pdf</a>]

<h2>Modeling the Interaction between Agents in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.06042v1 [cs.LG])</h2>
<h3>Xiaoteng Ma, Yiqin Yang, Chenghao Li, Yiwen Lu, Qianchuan Zhao, Yang Jun</h3>
<p>Value-based methods of multi-agent reinforcement learning (MARL), especially
the value decomposition methods, have been demonstrated on a range of
challenging cooperative tasks. However, current methods pay little attention to
the interaction between agents, which is essential to teamwork in games or real
life. This limits the efficiency of value-based MARL algorithms in the two
aspects: collaborative exploration and value function estimation. In this
paper, we propose a novel cooperative MARL algorithm named as interactive
actor-critic~(IAC), which models the interaction of agents from the
perspectives of policy and value function. On the policy side, a multi-agent
joint stochastic policy is introduced by adopting a collaborative exploration
module, which is trained by maximizing the entropy-regularized expected return.
On the value side, we use the shared attention mechanism to estimate the value
function of each agent, which takes the impact of the teammates into
consideration. At the implementation level, we extend the value decomposition
methods to continuous control tasks and evaluate IAC on benchmark tasks
including classic control and multi-agent particle environments. Experimental
results indicate that our method outperforms the state-of-the-art approaches
and achieves better performance in terms of cooperation.
</p>
<a href="http://arxiv.org/abs/2102.06042" target="_blank">arXiv:2102.06042</a> [<a href="http://arxiv.org/pdf/2102.06042" target="_blank">pdf</a>]

<h2>Artificial Intelligence based Autonomous Molecular Design for Medical Therapeutic: A Perspective. (arXiv:2102.06045v1 [cs.LG])</h2>
<h3>Rajendra P. Joshi, Neeraj Kumar</h3>
<p>Domain-aware machine learning (ML) models have been increasingly adopted for
accelerating small molecule therapeutic design in the recent years. These
models have been enabled by significant advancement in state-of-the-art
artificial intelligence (AI) and computing infrastructures. Several ML
architectures are pre-dominantly and independently used either for predicting
the properties of small molecules, or for generating lead therapeutic
candidates. Synergetically using these individual components along with robust
representation and data generation techniques autonomously in closed loops
holds enormous promise for accelerated drug design which is a time consuming
and expensive task otherwise. In this perspective, we present the most recent
breakthrough achieved by each of the components, and how such autonomous AI and
ML workflow can be realized to radically accelerate the hit identification and
lead optimization. Taken together, this could significantly shorten the
timeline for end-to-end antiviral discovery and optimization times to weeks
upon the arrival of a novel zoonotic transmission event. Our perspective serves
as a guide for researchers to practice autonomous molecular design in
therapeutic discovery.
</p>
<a href="http://arxiv.org/abs/2102.06045" target="_blank">arXiv:2102.06045</a> [<a href="http://arxiv.org/pdf/2102.06045" target="_blank">pdf</a>]

<h2>A fully automated method for 3D individual tooth identification and segmentation in dental CBCT. (arXiv:2102.06060v1 [cs.CV])</h2>
<h3>Tae Jun Jang, Kang Cheol Kim, Hyun Cheol Cho, Jin Keun Seo</h3>
<p>Accurate and automatic segmentation of three-dimensional (3D) individual
teeth from cone-beam computerized tomography (CBCT) images is a challenging
problem because of the difficulty in separating an individual tooth from
adjacent teeth and its surrounding alveolar bone. Thus, this paper proposes a
fully automated method of identifying and segmenting 3D individual teeth from
dental CBCT images. The proposed method addresses the aforementioned difficulty
by developing a deep learning-based hierarchical multi-step model. First, it
automatically generates upper and lower jaws panoramic images to overcome the
computational complexity caused by high-dimensional data and the curse of
dimensionality associated with limited training dataset. The obtained 2D
panoramic images are then used to identify 2D individual teeth and capture
loose- and tight- regions of interest (ROIs) of 3D individual teeth. Finally,
accurate 3D individual tooth segmentation is achieved using both loose and
tight ROIs. Experimental results showed that the proposed method achieved an
F1-score of 93.35% for tooth identification and a Dice similarity coefficient
of 94.79% for individual 3D tooth segmentation. The results demonstrate that
the proposed method provides an effective clinical and practical framework for
digital dentistry.
</p>
<a href="http://arxiv.org/abs/2102.06060" target="_blank">arXiv:2102.06060</a> [<a href="http://arxiv.org/pdf/2102.06060" target="_blank">pdf</a>]

<h2>On Deep Learning with Label Differential Privacy. (arXiv:2102.06062v1 [cs.LG])</h2>
<h3>Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi, Chiyuan Zhang</h3>
<p>In many machine learning applications, the training data can contain highly
sensitive personal information. Training large-scale deep models that are
guaranteed not to leak sensitive information while not compromising their
accuracy has been a significant challenge. In this work, we study the
multi-class classification setting where the labels are considered sensitive
and ought to be protected. We propose a new algorithm for training deep neural
networks with label differential privacy, and run evaluations on several
datasets. For Fashion MNIST and CIFAR-10, we demonstrate that our algorithm
achieves significantly higher accuracy than the state-of-the-art, and in some
regimes comes close to the non-private baselines. We also provide non-trivial
training results for the the challenging CIFAR-100 dataset. We complement our
algorithm with theoretical findings showing that in the setting of convex
empirical risk minimization, the sample complexity of training with label
differential privacy is dimension-independent, which is in contrast to vanilla
differential privacy.
</p>
<a href="http://arxiv.org/abs/2102.06062" target="_blank">arXiv:2102.06062</a> [<a href="http://arxiv.org/pdf/2102.06062" target="_blank">pdf</a>]

<h2>Uncertainty Propagation in Convolutional Neural Networks: Technical Report. (arXiv:2102.06064v1 [cs.LG])</h2>
<h3>Christos Tzelepis, Ioannis Patras</h3>
<p>In this technical report we study the problem of propagation of uncertainty
(in terms of variances of given uni-variate normal random variables) through
typical building blocks of a Convolutional Neural Network (CNN). These include
layers that perform linear operations, such as 2D convolutions,
fully-connected, and average pooling layers, as well as layers that act
non-linearly on their input, such as the Rectified Linear Unit (ReLU). Finally,
we discuss the sigmoid function, for which we give approximations of its first-
and second-order moments, as well as the binary cross-entropy loss function,
for which we approximate its expected value under normal random inputs.
</p>
<a href="http://arxiv.org/abs/2102.06064" target="_blank">arXiv:2102.06064</a> [<a href="http://arxiv.org/pdf/2102.06064" target="_blank">pdf</a>]

<h2>Search Planning of a UAV/UGV Team with Localization Uncertainty in a Subterranean Environment. (arXiv:2102.06069v1 [cs.RO])</h2>
<h3>Matteo De Petrillo, Jared Beard, Yu Gu, Jason N. Gross</h3>
<p>We present a waypoint planning algorithm for an unmanned aerial vehicle (UAV)
that is teamed with an unmanned ground vehicle (UGV) for the task of search and
rescue in a subterranean environment. The UAV and UGV are teamed such that the
localization of the UAV is conducted on the UGV via the multi-sensor fusion of
a fish-eye camera, 3D LIDAR, ranging radio, and a laser altimeter. Likewise,
the trajectory planning of the UAV is conducted on the UGV, which is assumed to
have a 3D map of the environment (e.g., from Simultaneous Localization and
Mapping). The goal of the planning algorithm is to satisfy the mission's
exploration criteria while reducing the localization error of the UAV by
evaluating the belief space for potential exploration routes. The presented
algorithm is evaluated in a relevant simulation environment where the planning
algorithm is shown to be effective at reducing the localization errors of the
UAV.
</p>
<a href="http://arxiv.org/abs/2102.06069" target="_blank">arXiv:2102.06069</a> [<a href="http://arxiv.org/pdf/2102.06069" target="_blank">pdf</a>]

<h2>SelfHAR: Improving Human Activity Recognition through Self-training with Unlabeled Data. (arXiv:2102.06073v1 [cs.LG])</h2>
<h3>Chi Ian Tang, Ignacio Perez-Pozuelo, Dimitris Spathis, Soren Brage, Nick Wareham, Cecilia Mascolo</h3>
<p>Machine learning and deep learning have shown great promise in mobile sensing
applications, including Human Activity Recognition. However, the performance of
such models in real-world settings largely depends on the availability of large
datasets that captures diverse behaviors. Recently, studies in computer vision
and natural language processing have shown that leveraging massive amounts of
unlabeled data enables performance on par with state-of-the-art supervised
models.

In this work, we present SelfHAR, a semi-supervised model that effectively
learns to leverage unlabeled mobile sensing datasets to complement small
labeled datasets. Our approach combines teacher-student self-training, which
distills the knowledge of unlabeled and labeled datasets while allowing for
data augmentation, and multi-task self-supervision, which learns robust
signal-level representations by predicting distorted versions of the input.

We evaluated SelfHAR on various HAR datasets and showed state-of-the-art
performance over supervised and previous semi-supervised approaches, with up to
12% increase in F1 score using the same number of model parameters at
inference. Furthermore, SelfHAR is data-efficient, reaching similar performance
using up to 10 times less labeled data compared to supervised approaches. Our
work not only achieves state-of-the-art performance in a diverse set of HAR
datasets, but also sheds light on how pre-training tasks may affect downstream
performance.
</p>
<a href="http://arxiv.org/abs/2102.06073" target="_blank">arXiv:2102.06073</a> [<a href="http://arxiv.org/pdf/2102.06073" target="_blank">pdf</a>]

<h2>Partially Observed Exchangeable Modeling. (arXiv:2102.06083v1 [cs.LG])</h2>
<h3>Yang Li, Junier B. Oliva</h3>
<p>Modeling dependencies among features is fundamental for many machine learning
tasks. Although there are often multiple related instances that may be
leveraged to inform conditional dependencies, typical approaches only model
conditional dependencies over individual instances. In this work, we propose a
novel framework, partially observed exchangeable modeling (POEx) that takes in
a set of related partially observed instances and infers the conditional
distribution for the unobserved dimensions over multiple elements. Our approach
jointly models the intra-instance (among features in a point) and
inter-instance (among multiple points in a set) dependencies in data. POEx is a
general framework that encompasses many existing tasks such as point cloud
expansion and few-shot generation, as well as new tasks like few-shot
imputation. Despite its generality, extensive empirical evaluations show that
our model achieves state-of-the-art performance across a range of applications.
</p>
<a href="http://arxiv.org/abs/2102.06083" target="_blank">arXiv:2102.06083</a> [<a href="http://arxiv.org/pdf/2102.06083" target="_blank">pdf</a>]

<h2>Sufficiently Accurate Model Learning for Planning. (arXiv:2102.06099v1 [cs.AI])</h2>
<h3>Clark Zhang, Santiago Paternain, Alejandro Ribeiro</h3>
<p>Data driven models of dynamical systems help planners and controllers to
provide more precise and accurate motions. Most model learning algorithms will
try to minimize a loss function between the observed data and the model's
predictions. This can be improved using prior knowledge about the task at hand,
which can be encoded in the form of constraints. This turns the unconstrained
model learning problem into a constrained one. These constraints allow models
with finite capacity to focus their expressive power on important aspects of
the system. This can lead to models that are better suited for certain tasks.
This paper introduces the constrained Sufficiently Accurate model learning
approach, provides examples of such problems, and presents a theorem on how
close some approximate solutions can be. The approximate solution quality will
depend on the function parameterization, loss and constraint function
smoothness, and the number of samples in model learning.
</p>
<a href="http://arxiv.org/abs/2102.06099" target="_blank">arXiv:2102.06099</a> [<a href="http://arxiv.org/pdf/2102.06099" target="_blank">pdf</a>]

<h2>SWAGAN: A Style-based Wavelet-driven Generative Model. (arXiv:2102.06108v1 [cs.CV])</h2>
<h3>Rinon Gal, Dana Cohen, Amit Bermano, Daniel Cohen-Or</h3>
<p>In recent years, considerable progress has been made in the visual quality of
Generative Adversarial Networks (GANs). Even so, these networks still suffer
from degradation in quality for high-frequency content, stemming from a
spectrally biased architecture, and similarly unfavorable loss functions. To
address this issue, we present a novel general-purpose Style and WAvelet based
GAN (SWAGAN) that implements progressive generation in the frequency domain.
SWAGAN incorporates wavelets throughout its generator and discriminator
architectures, enforcing a frequency-aware latent representation at every step
of the way. This approach yields enhancements in the visual quality of the
generated images, and considerably increases computational performance. We
demonstrate the advantage of our method by integrating it into the SyleGAN2
framework, and verifying that content generation in the wavelet domain leads to
higher quality images with more realistic high-frequency content. Furthermore,
we verify that our model's latent space retains the qualities that allow
StyleGAN to serve as a basis for a multitude of editing tasks, and show that
our frequency-aware approach also induces improved downstream visual quality.
</p>
<a href="http://arxiv.org/abs/2102.06108" target="_blank">arXiv:2102.06108</a> [<a href="http://arxiv.org/pdf/2102.06108" target="_blank">pdf</a>]

<h2>A Metamodel and Framework for Artificial General Intelligence From Theory to Practice. (arXiv:2102.06112v1 [cs.AI])</h2>
<h3>Hugo Latapie, Ozkan Kilic, Gaowen Liu, Yan Yan, Ramana Kompella, Pei Wang, Kristinn R. Thorisson, Adam Lawrence, Yuhong Sun, Jayanth Srinivasa</h3>
<p>This paper introduces a new metamodel-based knowledge representation that
significantly improves autonomous learning and adaptation. While interest in
hybrid machine learning / symbolic AI systems leveraging, for example,
reasoning and knowledge graphs, is gaining popularity, we find there remains a
need for both a clear definition of knowledge and a metamodel to guide the
creation and manipulation of knowledge. Some of the benefits of the metamodel
we introduce in this paper include a solution to the symbol grounding problem,
cumulative learning, and federated learning. We have applied the metamodel to
problems ranging from time series analysis, computer vision, and natural
language understanding and have found that the metamodel enables a wide variety
of learning mechanisms ranging from machine learning, to graph network analysis
and learning by reasoning engines to interoperate in a highly synergistic way.
Our metamodel-based projects have consistently exhibited unprecedented
accuracy, performance, and ability to generalize. This paper is inspired by the
state-of-the-art approaches to AGI, recent AGI-aspiring work, the granular
computing community, as well as Alfred Korzybski's general semantics. One
surprising consequence of the metamodel is that it not only enables a new level
of autonomous learning and optimal functioning for machine intelligences, but
may also shed light on a path to better understanding how to improve human
cognition.
</p>
<a href="http://arxiv.org/abs/2102.06112" target="_blank">arXiv:2102.06112</a> [<a href="http://arxiv.org/pdf/2102.06112" target="_blank">pdf</a>]

<h2>Deep Photo Scan: Semi-supervised learning for dealing with the real-world degradation in smartphone photo scanning. (arXiv:2102.06120v1 [cs.CV])</h2>
<h3>Man M. Ho, Jinjia Zhou</h3>
<p>Physical photographs now can be conveniently scanned by smartphones and
stored forever as a digital version, but the scanned photos are not restored
well. One solution is to train a supervised deep neural network on many digital
photos and the corresponding scanned photos. However, human annotation costs a
huge resource leading to limited training data. Previous works create training
pairs by simulating degradation using image processing techniques. Their
synthetic images are formed with perfectly scanned photos in latent space. Even
so, the real-world degradation in smartphone photo scanning remains unsolved
since it is more complicated due to real lens defocus, lighting conditions,
losing details via printing, various photo materials, and more. To solve these
problems, we propose a Deep Photo Scan (DPScan) based on semi-supervised
learning. First, we present the way to produce real-world degradation and
provide the DIV2K-SCAN dataset for smartphone-scanned photo restoration.
Second, by using DIV2K-SCAN, we adopt the concept of Generative Adversarial
Networks to learn how to degrade a high-quality image as if it were scanned by
a real smartphone, then generate pseudo-scanned photos for unscanned photos.
Finally, we propose to train on the scanned and pseudo-scanned photos
representing a semi-supervised approach with a cycle process as: high-quality
images --&gt; real-/pseudo-scanned photos --&gt; reconstructed images. The proposed
semi-supervised scheme can balance between supervised and unsupervised errors
while optimizing to limit imperfect pseudo inputs but still enhance
restoration. As a result, the proposed DPScan quantitatively and qualitatively
outperforms its baseline architecture, state-of-the-art academic research, and
industrial products in smartphone photo scanning.
</p>
<a href="http://arxiv.org/abs/2102.06120" target="_blank">arXiv:2102.06120</a> [<a href="http://arxiv.org/pdf/2102.06120" target="_blank">pdf</a>]

<h2>Meta-Thompson Sampling. (arXiv:2102.06129v1 [cs.LG])</h2>
<h3>Branislav Kveton, Mikhail Konobeev, Manzil Zaheer, Chih-wei Hsu, Martin Mladenov, Craig Boutilier, Csaba Szepesvari</h3>
<p>Efficient exploration in multi-armed bandits is a fundamental online learning
problem. In this work, we propose a variant of Thompson sampling that learns to
explore better as it interacts with problem instances drawn from an unknown
prior distribution. Our algorithm meta-learns the prior and thus we call it
Meta-TS. We propose efficient implementations of Meta-TS and analyze it in
Gaussian bandits. Our analysis shows the benefit of meta-learning the prior and
is of a broader interest, because we derive the first prior-dependent upper
bound on the Bayes regret of Thompson sampling. This result is complemented by
empirical evaluation, which shows that Meta-TS quickly adapts to the unknown
prior.
</p>
<a href="http://arxiv.org/abs/2102.06129" target="_blank">arXiv:2102.06129</a> [<a href="http://arxiv.org/pdf/2102.06129" target="_blank">pdf</a>]

<h2>A Compositional Atlas of Tractable Circuit Operations: From Simple Transformations to Complex Information-Theoretic Queries. (arXiv:2102.06137v1 [stat.ML])</h2>
<h3>Antonio Vergari, YooJung Choi, Anji Liu, Stefano Teso, Guy Van den Broeck</h3>
<p>Circuit representations are becoming the lingua franca to express and reason
about tractable generative and discriminative models. In this paper, we show
how complex inference scenarios for these models that commonly arise in machine
learning -- from computing the expectations of decision tree ensembles to
information-theoretic divergences of deep mixture models -- can be represented
in terms of tractable modular operations over circuits. Specifically, we
characterize the tractability of a vocabulary of simple transformations --
sums, products, quotients, powers, logarithms, and exponentials -- in terms of
sufficient structural constraints of the circuits they operate on, and present
novel hardness results for the cases in which these properties are not
satisfied. Building on these operations, we derive a unified framework for
reasoning about tractable models that generalizes several results in the
literature and opens up novel tractable inference scenarios.
</p>
<a href="http://arxiv.org/abs/2102.06137" target="_blank">arXiv:2102.06137</a> [<a href="http://arxiv.org/pdf/2102.06137" target="_blank">pdf</a>]

<h2>Variational Bayesian Sequence-to-Sequence Networks for Memory-Efficient Sign Language Translation. (arXiv:2102.06143v1 [stat.ML])</h2>
<h3>Harris Partaourides, Andreas Voskou, Dimitrios Kosmopoulos, Sotirios Chatzis, Dimitris N. Metaxas</h3>
<p>Memory-efficient continuous Sign Language Translation is a significant
challenge for the development of assisted technologies with real-time
applicability for the deaf. In this work, we introduce a paradigm of designing
recurrent deep networks whereby the output of the recurrent layer is derived
from appropriate arguments from nonparametric statistics. A novel variational
Bayesian sequence-to-sequence network architecture is proposed that consists of
a) a full Gaussian posterior distribution for data-driven memory compression
and b) a nonparametric Indian Buffet Process prior for regularization applied
on the Gated Recurrent Unit non-gate weights. We dub our approach
Stick-Breaking Recurrent network and show that it can achieve a substantial
weight compression without diminishing modeling performance.
</p>
<a href="http://arxiv.org/abs/2102.06143" target="_blank">arXiv:2102.06143</a> [<a href="http://arxiv.org/pdf/2102.06143" target="_blank">pdf</a>]

<h2>Ranking vs. Classifying: Measuring Knowledge Base Completion Quality. (arXiv:2102.06145v1 [cs.AI])</h2>
<h3>Marina Speranskaya, Martin Schmitt, Benjamin Roth</h3>
<p>Knowledge base completion (KBC) methods aim at inferring missing facts from
the information present in a knowledge base (KB) by estimating the likelihood
of candidate facts. In the prevailing evaluation paradigm, models do not
actually decide whether a new fact should be accepted or not but are solely
judged on the position of true facts in a likelihood ranking with other
candidates. We argue that consideration of binary predictions is essential to
reflect the actual KBC quality, and propose a novel evaluation paradigm,
designed to provide more transparent model selection criteria for a realistic
scenario. We construct the data set FB14k-QAQ where instead of single facts, we
use KB queries, i.e., facts where one entity is replaced with a variable, and
construct corresponding sets of entities that are correct answers. We randomly
remove some of these correct answers from the data set, simulating the
realistic scenario of real-world entities missing from a KB. This way, we can
explicitly measure a model's ability to handle queries that have more correct
answers in the real world than in the KB, including the special case of queries
without any valid answer. The latter especially contrasts the ranking setting.
We evaluate a number of state-of-the-art KB embeddings models on our new
benchmark. The differences in relative performance between ranking-based and
classification-based evaluation that we observe in our experiments confirm our
hypothesis that good performance on the ranking task does not necessarily
translate to good performance on the actual completion task. Our results
motivate future work on KB embedding models with better prediction separability
and, as a first step in that direction, we propose a simple variant of TransE
that encourages thresholding and achieves a significant improvement in
classification F1 score relative to the original TransE.
</p>
<a href="http://arxiv.org/abs/2102.06145" target="_blank">arXiv:2102.06145</a> [<a href="http://arxiv.org/pdf/2102.06145" target="_blank">pdf</a>]

<h2>EvoSplit: An evolutionary approach to split a multi-label data set into disjoint subset. (arXiv:2102.06154v1 [cs.LG])</h2>
<h3>Francisco Florez-Revuelta</h3>
<p>This paper presents a new evolutionary approach, EvoSplit, for the
distribution of multi-label data sets into disjoint subsets for supervised
machine learning. Currently, data set providers either divide a data set
randomly or using iterative stratification, a method that aims to maintain the
label (or label pair) distribution of the original data set into the different
subsets. Following the same aim, this paper first introduces a single-objective
evolutionary approach that tries to obtain a split that maximizes the
similarity between those distributions independently. Second, a new
multi-objective evolutionary algorithm is presented to maximize the similarity
considering simultaneously both distributions (label and label pair). Both
approaches are validated using well-known multi-label data sets as well as
large image data sets currently used in computer vision and machine learning
applications. EvoSplit improves the splitting of a data set in comparison to
the iterative stratification following different measures: Label Distribution,
Label Pair Distribution, Examples Distribution, folds and fold-label pairs with
zero positive examples.
</p>
<a href="http://arxiv.org/abs/2102.06154" target="_blank">arXiv:2102.06154</a> [<a href="http://arxiv.org/pdf/2102.06154" target="_blank">pdf</a>]

<h2>Defuse: Harnessing Unrestricted Adversarial Examples for Debugging Models Beyond Test Accuracy. (arXiv:2102.06162v1 [cs.LG])</h2>
<h3>Dylan Slack, Nathalie Rauschmayr, Krishnaram Kenthapadi</h3>
<p>We typically compute aggregate statistics on held-out test data to assess the
generalization of machine learning models. However, statistics on test data
often overstate model generalization, and thus, the performance of deployed
machine learning models can be variable and untrustworthy. Motivated by these
concerns, we develop methods to automatically discover and correct model errors
beyond those available in the data. We propose Defuse, a method that generates
novel model misclassifications, categorizes these errors into high-level model
bugs, and efficiently labels and fine-tunes on the errors to correct them. To
generate misclassified data, we propose an algorithm inspired by adversarial
machine learning techniques that uses a generative model to find naturally
occurring instances misclassified by a model. Further, we observe that the
generative models have regions in their latent space with higher concentrations
of misclassifications. We call these regions misclassification regions and find
they have several useful properties. Each region contains a specific type of
model bug; for instance, a misclassification region for an MNIST classifier
contains a style of skinny 6 that the model mistakes as a 1. We can also assign
a single label to each region, facilitating low-cost labeling. We propose a
method to learn the misclassification regions and use this insight to both
categorize errors and correct them. In practice, Defuse finds and corrects
novel errors in classifiers. For example, Defuse shows that a high-performance
traffic sign classifier mistakes certain 50km/h signs as 80km/h. Defuse
corrects the error after fine-tuning while maintaining generalization on the
test set.
</p>
<a href="http://arxiv.org/abs/2102.06162" target="_blank">arXiv:2102.06162</a> [<a href="http://arxiv.org/pdf/2102.06162" target="_blank">pdf</a>]

<h2>Sample Efficient Learning of Image-Based Diagnostic Classifiers Using Probabilistic Labels. (arXiv:2102.06164v1 [cs.CV])</h2>
<h3>Roberto Vega, Pouneh Gorji, Zichen Zhang, Xuebin Qin, Abhilash Rakkunedeth Hareendranathan, Jeevesh Kapur, Jacob L. Jaremko, Russell Greiner</h3>
<p>Deep learning approaches often require huge datasets to achieve good
generalization. This complicates its use in tasks like image-based medical
diagnosis, where the small training datasets are usually insufficient to learn
appropriate data representations. For such sensitive tasks it is also important
to provide the confidence in the predictions. Here, we propose a way to learn
and use probabilistic labels to train accurate and calibrated deep networks
from relatively small datasets. We observe gains of up to 22% in the accuracy
of models trained with these labels, as compared with traditional approaches,
in three classification tasks: diagnosis of hip dysplasia, fatty liver, and
glaucoma. The outputs of models trained with probabilistic labels are
calibrated, allowing the interpretation of its predictions as proper
probabilities. We anticipate this approach will apply to other tasks where few
training instances are available and expert knowledge can be encoded as
probabilities.
</p>
<a href="http://arxiv.org/abs/2102.06164" target="_blank">arXiv:2102.06164</a> [<a href="http://arxiv.org/pdf/2102.06164" target="_blank">pdf</a>]

<h2>Testing Framework for Black-box AI Models. (arXiv:2102.06166v1 [cs.LG])</h2>
<h3>Aniya Aggarwal, Samiulla Shaikh, Sandeep Hans, Swastik Haldar, Rema Ananthanarayanan, Diptikalyan Saha</h3>
<p>With widespread adoption of AI models for important decision making, ensuring
reliability of such models remains an important challenge. In this paper, we
present an end-to-end generic framework for testing AI Models which performs
automated test generation for different modalities such as text, tabular, and
time-series data and across various properties such as accuracy, fairness, and
robustness. Our tool has been used for testing industrial AI models and was
very effective to uncover issues present in those models. Demo video link:
https://youtu.be/984UCU17YZI
</p>
<a href="http://arxiv.org/abs/2102.06166" target="_blank">arXiv:2102.06166</a> [<a href="http://arxiv.org/pdf/2102.06166" target="_blank">pdf</a>]

<h2>High-Performance Large-Scale Image Recognition Without Normalization. (arXiv:2102.06171v1 [cs.CV])</h2>
<h3>Andrew Brock, Soham De, Samuel L. Smith, Karen Simonyan</h3>
<p>Batch normalization is a key component of most image classification models,
but it has many undesirable properties stemming from its dependence on the
batch size and interactions between examples. Although recent work has
succeeded in training deep ResNets without normalization layers, these models
do not match the test accuracies of the best batch-normalized networks, and are
often unstable for large learning rates or strong data augmentations. In this
work, we develop an adaptive gradient clipping technique which overcomes these
instabilities, and design a significantly improved class of Normalizer-Free
ResNets. Our smaller models match the test accuracy of an EfficientNet-B7 on
ImageNet while being up to 8.7x faster to train, and our largest models attain
a new state-of-the-art top-1 accuracy of 86.5%. In addition, Normalizer-Free
models attain significantly better performance than their batch-normalized
counterparts when finetuning on ImageNet after large-scale pre-training on a
dataset of 300 million labeled images, with our best models obtaining an
accuracy of 89.2%. Our code is available at https://github.com/deepmind/
deepmind-research/tree/master/nfnets
</p>
<a href="http://arxiv.org/abs/2102.06171" target="_blank">arXiv:2102.06171</a> [<a href="http://arxiv.org/pdf/2102.06171" target="_blank">pdf</a>]

<h2>Multi-Task Reinforcement Learning with Context-based Representations. (arXiv:2102.06177v1 [cs.LG])</h2>
<h3>Shagun Sodhani, Amy Zhang, Joelle Pineau</h3>
<p>The benefit of multi-task learning over single-task learning relies on the
ability to use relations across tasks to improve performance on any single
task. While sharing representations is an important mechanism to share
information across tasks, its success depends on how well the structure
underlying the tasks is captured. In some real-world situations, we have access
to metadata, or additional information about a task, that may not provide any
new insight in the context of a single task setup alone but inform relations
across multiple tasks. While this metadata can be useful for improving
multi-task learning performance, effectively incorporating it can be an
additional challenge. We posit that an efficient approach to knowledge transfer
is through the use of multiple context-dependent, composable representations
shared across a family of tasks. In this framework, metadata can help to learn
interpretable representations and provide the context to inform which
representations to compose and how to compose them. We use the proposed
approach to obtain state-of-the-art results in Meta-World, a challenging
multi-task benchmark consisting of 50 distinct robotic manipulation tasks.
</p>
<a href="http://arxiv.org/abs/2102.06177" target="_blank">arXiv:2102.06177</a> [<a href="http://arxiv.org/pdf/2102.06177" target="_blank">pdf</a>]

<h2>Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling. (arXiv:2102.06183v1 [cs.CV])</h2>
<h3>Jie Lei, Linjie Li, Luowei Zhou, Zhe Gan, Tamara L. Berg, Mohit Bansal, Jingjing Liu</h3>
<p>The canonical approach to video-and-language learning (e.g., video question
answering) dictates a neural model to learn from offline-extracted dense video
features from vision models and text features from language models. These
feature extractors are trained independently and usually on tasks different
from the target domains, rendering these fixed features sub-optimal for
downstream tasks. Moreover, due to the high computational overload of dense
video features, it is often difficult (or infeasible) to plug feature
extractors directly into existing approaches for easy finetuning. To provide a
remedy to this dilemma, we propose a generic framework ClipBERT that enables
affordable end-to-end learning for video-and-language tasks, by employing
sparse sampling, where only a single or a few sparsely sampled short clips from
a video are used at each training step. Experiments on text-to-video retrieval
and video question answering on six datasets demonstrate that ClipBERT
outperforms (or is on par with) existing methods that exploit full-length
videos, suggesting that end-to-end learning with just a few sparsely sampled
clips is often more accurate than using densely extracted offline features from
full-length videos, proving the proverbial less-is-more principle. Videos in
the datasets are from considerably different domains and lengths, ranging from
3-second generic domain GIF videos to 180-second YouTube human activity videos,
showing the generalization ability of our approach. Comprehensive ablation
studies and thorough analyses are provided to dissect what factors lead to this
success. Our code is publicly available at https://github.com/jayleicn/ClipBERT
</p>
<a href="http://arxiv.org/abs/2102.06183" target="_blank">arXiv:2102.06183</a> [<a href="http://arxiv.org/pdf/2102.06183" target="_blank">pdf</a>]

<h2>Quadric hypersurface intersection for manifold learning in feature space. (arXiv:2102.06186v1 [cs.LG])</h2>
<h3>Fedor Pavutnitskiy, Sergei O. Ivanov, Evgeny Abramov, Viacheslav Borovitskiy, Artem Klochkov, Viktor Vialov, Anatolii Zaikovskii, Aleksandr Petiushko</h3>
<p>The knowledge that data lies close to a particular submanifold of the ambient
Euclidean space may be useful in a number of ways. For instance, one may want
to automatically mark any point far away from the submanifold as an outlier, or
to use its geodesic distance to measure similarity between points. Classical
problems for manifold learning are often posed in a very high dimension, e.g.
for spaces of images or spaces of representations of words. Today, with deep
representation learning on the rise in areas such as computer vision and
natural language processing, many problems of this kind may be transformed into
problems of moderately high dimension, typically of the order of hundreds.
Motivated by this, we propose a manifold learning technique suitable for
moderately high dimension and large datasets. The manifold is learned from the
training data in the form of an intersection of quadric hypersurfaces -- simple
but expressive objects. At test time, this manifold can be used to introduce an
outlier score for arbitrary new points and to improve a given similarity metric
by incorporating learned geometric structure into it.
</p>
<a href="http://arxiv.org/abs/2102.06186" target="_blank">arXiv:2102.06186</a> [<a href="http://arxiv.org/pdf/2102.06186" target="_blank">pdf</a>]

<h2>Unsupervised Semantic Segmentation by Contrasting Object Mask Proposals. (arXiv:2102.06191v1 [cs.CV])</h2>
<h3>Wouter Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, Luc Van Gool</h3>
<p>Being able to learn dense semantic representations of images without
supervision is an important problem in computer vision. However, despite its
significance, this problem remains rather unexplored, with a few exceptions
that considered unsupervised semantic segmentation on small-scale datasets with
a narrow visual domain. In this paper, we make a first attempt to tackle the
problem on datasets that have been traditionally utilized for the supervised
case. To achieve this, we introduce a novel two-step framework that adopts a
predetermined prior in a contrastive optimization objective to learn pixel
embeddings. This marks a large deviation from existing works that relied on
proxy tasks or end-to-end clustering. Additionally, we argue about the
importance of having a prior that contains information about objects, or their
parts, and discuss several possibilities to obtain such a prior in an
unsupervised manner.

Extensive experimental evaluation shows that the proposed method comes with
key advantages over existing works. First, the learned pixel embeddings can be
directly clustered in semantic groups using K-Means. Second, the method can
serve as an effective unsupervised pre-training for the semantic segmentation
task. In particular, when fine-tuning the learned representations using just 1%
of labeled examples on PASCAL, we outperform supervised ImageNet pre-training
by 7.1% mIoU. The code is available at
https://github.com/wvangansbeke/Unsupervised-Semantic-Segmentation.
</p>
<a href="http://arxiv.org/abs/2102.06191" target="_blank">arXiv:2102.06191</a> [<a href="http://arxiv.org/pdf/2102.06191" target="_blank">pdf</a>]

<h2>Adversarial Segmentation Loss for Sketch Colorization. (arXiv:2102.06192v1 [cs.CV])</h2>
<h3>Samet Hicsonmez, Nermin Samet, Emre Akbas, Pinar Duygulu</h3>
<p>We introduce a new method for generating color images from sketches or edge
maps. Current methods either require some form of additional user-guidance or
are limited to the "paired" translation approach. We argue that segmentation
information could provide valuable guidance for sketch colorization. To this
end, we propose to leverage semantic image segmentation, as provided by a
general purpose panoptic segmentation network, to create an additional
adversarial loss function. Our loss function can be integrated to any baseline
GAN model. Our method is not limited to datasets that contain segmentation
labels, and it can be trained for "unpaired" translation tasks. We show the
effectiveness of our method on four different datasets spanning scene level
indoor, outdoor, and children book illustration images using qualitative,
quantitative and user study analysis. Our model improves its baseline up to 35
points on the FID metric. Our code and pretrained models can be found at
https://github.com/giddyyupp/AdvSegLoss.
</p>
<a href="http://arxiv.org/abs/2102.06192" target="_blank">arXiv:2102.06192</a> [<a href="http://arxiv.org/pdf/2102.06192" target="_blank">pdf</a>]

<h2>Shelf-Supervised Mesh Prediction in the Wild. (arXiv:2102.06195v1 [cs.CV])</h2>
<h3>Yufei Ye, Shubham Tulsiani, Abhinav Gupta</h3>
<p>We aim to infer 3D shape and pose of object from a single image and propose a
learning-based approach that can train from unstructured image collections,
supervised by only segmentation outputs from off-the-shelf recognition systems
(i.e. 'shelf-supervised'). We first infer a volumetric representation in a
canonical frame, along with the camera pose. We enforce the representation
geometrically consistent with both appearance and masks, and also that the
synthesized novel views are indistinguishable from image collections. The
coarse volumetric prediction is then converted to a mesh-based representation,
which is further refined in the predicted camera frame. These two steps allow
both shape-pose factorization from image collections and per-instance
reconstruction in finer details. We examine the method on both synthetic and
real-world datasets and demonstrate its scalability on 50 categories in the
wild, an order of magnitude more classes than existing works.
</p>
<a href="http://arxiv.org/abs/2102.06195" target="_blank">arXiv:2102.06195</a> [<a href="http://arxiv.org/pdf/2102.06195" target="_blank">pdf</a>]

<h2>Causal Discovery of a River Network from its Extremes. (arXiv:2102.06197v1 [stat.ML])</h2>
<h3>Ngoc Mai Tran, Johannes Buck, Claudia Kl&#xfc;ppelberg</h3>
<p>Causal inference for extremes aims to discover cause and effect relations
between large observed values of random variables. Over the last years, a
number of methods have been proposed for solving the Hidden River Problem, with
the Danube data set as benchmark. In this paper, we provide \QTree, a new and
simple algorithm to solve the Hidden River Problem that outperforms existing
methods. \QTree\ returns a directed graph and achieves almost perfect recovery
on the Danube as well as on new data from the Lower Colorado River. It can
handle missing data, has an automated parameter tuning procedure, and runs in
time $O(n |V|^2)$, where $n$ is the number of observations and $|V|$ the number
of nodes in the graph. \QTree\ relies on qualitative aspects of the max-linear
Bayesian network model.
</p>
<a href="http://arxiv.org/abs/2102.06197" target="_blank">arXiv:2102.06197</a> [<a href="http://arxiv.org/pdf/2102.06197" target="_blank">pdf</a>]

<h2>A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering. (arXiv:2102.06199v1 [cs.CV])</h2>
<h3>Shih-Yang Su, Frank Yu, Michael Zollhoefer, Helge Rhodin</h3>
<p>While deep learning has reshaped the classical motion capture pipeline,
generative, analysis-by-synthesis elements are still in use to recover fine
details if a high-quality 3D model of the user is available. Unfortunately,
obtaining such a model for every user a priori is challenging, time-consuming,
and limits the application scenarios. We propose a novel test-time optimization
approach for monocular motion capture that learns a volumetric body model of
the user in a self-supervised manner. To this end, our approach combines the
advantages of neural radiance fields with an articulated skeleton
representation. Our proposed skeleton embedding serves as a common reference
that links constraints across time, thereby reducing the number of required
camera views from traditionally dozens of calibrated cameras, down to a single
uncalibrated one. As a starting point, we employ the output of an off-the-shelf
model that predicts the 3D skeleton pose. The volumetric body shape and
appearance is then learned from scratch, while jointly refining the initial
pose estimate. Our approach is self-supervised and does not require any
additional ground truth labels for appearance, pose, or 3D shape. We
demonstrate that our novel combination of a discriminative pose estimation
technique with surface-free analysis-by-synthesis outperforms purely
discriminative monocular pose estimation approaches and generalizes well to
multiple views.
</p>
<a href="http://arxiv.org/abs/2102.06199" target="_blank">arXiv:2102.06199</a> [<a href="http://arxiv.org/pdf/2102.06199" target="_blank">pdf</a>]

<h2>Private Prediction Sets. (arXiv:2102.06202v1 [cs.LG])</h2>
<h3>Anastasios N. Angelopoulos, Stephen Bates, Tijana Zrnic, Michael I. Jordan</h3>
<p>In real-world settings involving consequential decision-making, the
deployment of machine learning systems generally requires both reliable
uncertainty quantification and protection of individuals' privacy. We present a
framework that treats these two desiderata jointly. Our framework is based on
conformal prediction, a methodology that augments predictive models to return
prediction sets that provide uncertainty quantification -- they provably cover
the true response with a user-specified probability, such as 90%. One might
hope that when used with privately-trained models, conformal prediction would
yield privacy guarantees for the resulting prediction sets; unfortunately this
is not the case. To remedy this key problem, we develop a method that takes any
pre-trained predictive model and outputs differentially private prediction
sets. Our method follows the general approach of split conformal prediction; we
use holdout data to calibrate the size of the prediction sets but preserve
privacy by using a privatized quantile subroutine. This subroutine compensates
for the noise introduced to preserve privacy in order to guarantee correct
coverage. We evaluate the method with experiments on the CIFAR-10, ImageNet,
and CoronaHack datasets.
</p>
<a href="http://arxiv.org/abs/2102.06202" target="_blank">arXiv:2102.06202</a> [<a href="http://arxiv.org/pdf/2102.06202" target="_blank">pdf</a>]

<h2>Proof Artifact Co-training for Theorem Proving with Language Models. (arXiv:2102.06203v1 [cs.AI])</h2>
<h3>Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W. Ayers, Stanislas Polu</h3>
<p>Labeled data for imitation learning of theorem proving in large libraries of
formalized mathematics is scarce as such libraries require years of
concentrated effort by human specialists to be built. This is particularly
challenging when applying large Transformer language models to tactic
prediction, because the scaling of performance with respect to model size is
quickly disrupted in the data-scarce, easily-overfitted regime. We propose PACT
({\bf P}roof {\bf A}rtifact {\bf C}o-{\bf T}raining), a general methodology for
extracting abundant self-supervised data from kernel-level proof terms for
co-training alongside the usual tactic prediction objective. We apply this
methodology to Lean, an interactive proof assistant which hosts some of the
most sophisticated formalized mathematics to date. We instrument Lean with a
neural theorem prover driven by a Transformer language model and show that PACT
improves theorem proving success rate on a held-out suite of test theorems from
32\% to 48\%.
</p>
<a href="http://arxiv.org/abs/2102.06203" target="_blank">arXiv:2102.06203</a> [<a href="http://arxiv.org/pdf/2102.06203" target="_blank">pdf</a>]

<h2>Disentangled Representations from Non-Disentangled Models. (arXiv:2102.06204v1 [cs.LG])</h2>
<h3>Valentin Khrulkov, Leyla Mirvakhabova, Ivan Oseledets, Artem Babenko</h3>
<p>Constructing disentangled representations is known to be a difficult task,
especially in the unsupervised scenario. The dominating paradigm of
unsupervised disentanglement is currently to train a generative model that
separates different factors of variation in its latent space. This separation
is typically enforced by training with specific regularization terms in the
model's objective function. These terms, however, introduce additional
hyperparameters responsible for the trade-off between disentanglement and
generation quality. While tuning these hyperparameters is crucial for proper
disentanglement, it is often unclear how to tune them without external
supervision.

This paper investigates an alternative route to disentangled representations.
Namely, we propose to extract such representations from the state-of-the-art
generative models trained without disentangling terms in their objectives. This
paradigm of post hoc disentanglement employs little or no hyperparameters when
learning representations while achieving results on par with existing
state-of-the-art, as shown by comparison in terms of established
disentanglement metrics, fairness, and the abstract reasoning task. All our
code and models are publicly available.
</p>
<a href="http://arxiv.org/abs/2102.06204" target="_blank">arXiv:2102.06204</a> [<a href="http://arxiv.org/pdf/2102.06204" target="_blank">pdf</a>]

<h2>Neural Re-rendering for Full-frame Video Stabilization. (arXiv:2102.06205v1 [cs.CV])</h2>
<h3>Yu-Lun Liu, Wei-Sheng Lai, Ming-Hsuan Yang, Yung-Yu Chuang, Jia-Bin Huang</h3>
<p>Existing video stabilization methods either require aggressive cropping of
frame boundaries or generate distortion artifacts on the stabilized frames. In
this work, we present an algorithm for full-frame video stabilization by first
estimating dense warp fields. Full-frame stabilized frames can then be
synthesized by fusing warped contents from neighboring frames. The core
technical novelty lies in our learning-based hybrid-space fusion that
alleviates artifacts caused by optical flow inaccuracy and fast-moving objects.
We validate the effectiveness of our method on the NUS and selfie video
datasets. Extensive experiment results demonstrate the merits of our approach
over prior video stabilization methods.
</p>
<a href="http://arxiv.org/abs/2102.06205" target="_blank">arXiv:2102.06205</a> [<a href="http://arxiv.org/pdf/2102.06205" target="_blank">pdf</a>]

<h2>Sequential Adaptive Design for Jump Regression Estimation. (arXiv:1904.01648v4 [stat.ML] UPDATED)</h2>
<h3>Chiwoo Park, Peihua Qiu, Jennifer Carpena-N&#xfa;&#xf1;ez, Rahul Rao, Michael Susner, Benji Maruyama</h3>
<p>Selecting input variables or design points for statistical models has been of
great interest in adaptive design and active learning. Motivated by two
scientific examples, this paper presents a strategy of selecting the design
points for a regression model when the underlying regression function is
discontinuous. The first example we undertook was for the purpose of
accelerating imaging speed in a high resolution material imaging; the second
was use of sequential design for the purpose of mapping a chemical phase
diagram. In both examples, the underlying regression functions have
discontinuities, so many of the existing design optimization approaches cannot
be applied because they mostly assume a continuous regression function.
Although some existing adaptive design strategies developed from treed
regression models can handle the discontinuities, the Bayesian approaches come
with computationally expensive Markov Chain Monte Carlo techniques for
posterior inferences and subsequent design point selections, which is not
appropriate for the first motivating example that requires computation at least
faster than the original imaging speed. In addition, the treed models are based
on the domain partitioning that are inefficient when the discontinuities occurs
over complex sub-domain boundaries. We propose a simple and effective adaptive
design strategy for a regression analysis with discontinuities: some
statistical properties with a fixed design will be presented first, and then
these properties will be used to propose a new criterion of selecting the
design points for the regression analysis. Sequential design with the new
criterion will be presented with comprehensive simulated examples, and its
application to the two motivating examples will be presented.
</p>
<a href="http://arxiv.org/abs/1904.01648" target="_blank">arXiv:1904.01648</a> [<a href="http://arxiv.org/pdf/1904.01648" target="_blank">pdf</a>]

<h2>Efficient Covariance Estimation from Temporal Data. (arXiv:1905.13276v2 [cs.LG] UPDATED)</h2>
<h3>Hrayr Harutyunyan, Daniel Moyer, Hrant Khachatrian, Greg Ver Steeg, Aram Galstyan</h3>
<p>Estimating the covariance structure of multivariate time series is a
fundamental problem with a wide-range of real-world applications -- from
financial modeling to fMRI analysis. Despite significant recent advances,
current state-of-the-art methods are still severely limited in terms of
scalability, and do not work well in high-dimensional undersampled regimes. In
this work we propose a novel method called Temporal Correlation Explanation, or
T-CorEx, that (a) has linear time and memory complexity with respect to the
number of variables, and can scale to very large temporal datasets that are not
tractable with existing methods; (b) gives state-of-the-art results in highly
undersampled regimes on both synthetic and real-world datasets; and (c) makes
minimal assumptions about the character of the dynamics of the system. T-CorEx
optimizes an information-theoretic objective function to learn a latent factor
graphical model for each time period and applies two regularization techniques
to induce temporal consistency of estimates. We perform extensive evaluation of
T-Corex using both synthetic and real-world data and demonstrate that it can be
used for detecting sudden changes in the underlying covariance matrix,
capturing transient correlations and analyzing extremely high-dimensional
complex multivariate time series such as high-resolution fMRI data.
</p>
<a href="http://arxiv.org/abs/1905.13276" target="_blank">arXiv:1905.13276</a> [<a href="http://arxiv.org/pdf/1905.13276" target="_blank">pdf</a>]

<h2>Policy Optimization Provably Converges to Nash Equilibria in Zero-Sum Linear Quadratic Games. (arXiv:1906.00729v4 [cs.LG] UPDATED)</h2>
<h3>Kaiqing Zhang, Zhuoran Yang, Tamer Ba&#x15f;ar</h3>
<p>We study the global convergence of policy optimization for finding the Nash
equilibria (NE) in zero-sum linear quadratic (LQ) games. To this end, we first
investigate the landscape of LQ games, viewing it as a nonconvex-nonconcave
saddle-point problem in the policy space. Specifically, we show that despite
its nonconvexity and nonconcavity, zero-sum LQ games have the property that the
stationary point of the objective function with respect to the linear feedback
control policies constitutes the NE of the game. Building upon this, we develop
three projected nested-gradient methods that are guaranteed to converge to the
NE of the game. Moreover, we show that all of these algorithms enjoy both
globally sublinear and locally linear convergence rates. Simulation results are
also provided to illustrate the satisfactory convergence properties of the
algorithms. To the best of our knowledge, this work appears to be the first one
to investigate the optimization landscape of LQ games, and provably show the
convergence of policy optimization methods to the Nash equilibria. Our work
serves as an initial step toward understanding the theoretical aspects of
policy-based reinforcement learning algorithms for zero-sum Markov games in
general.
</p>
<a href="http://arxiv.org/abs/1906.00729" target="_blank">arXiv:1906.00729</a> [<a href="http://arxiv.org/pdf/1906.00729" target="_blank">pdf</a>]

<h2>Efficient comparison of independence structures of log-linear models. (arXiv:1907.08892v2 [cs.LG] UPDATED)</h2>
<h3>Jan Strappa, Facundo Bromberg</h3>
<p>Log-linear models are a family of probability distributions which capture a
variety of relationships between variables, including context-specific
independencies. There are a number of approaches for automatic learning of
their independence structures from data, although to date, no efficient method
exists for evaluating these approaches directly in terms of the structures of
the models. The only known methods evaluate these approaches indirectly through
the complete model produced, that includes not only the structure but also the
model parameters, introducing potential distortions in the comparison. This
work presents such a method, that is, a measure for the direct comparison of
the independence structures of log-linear models, inspired by the Hamming
distance comparison method used in undirected graphical models. The measure
presented can be efficiently computed in terms of the number of variables of
the domain, and is proven to be a distance metric.
</p>
<a href="http://arxiv.org/abs/1907.08892" target="_blank">arXiv:1907.08892</a> [<a href="http://arxiv.org/pdf/1907.08892" target="_blank">pdf</a>]

<h2>Cylindrical Shape Decomposition for 3D Segmentation of Tubular Objects. (arXiv:1911.00571v3 [cs.CV] UPDATED)</h2>
<h3>Ali Abdollahzadeh, Alejandra Sierra, Jussi Tohka</h3>
<p>We develop a cylindrical shape decomposition (CSD) algorithm to decompose an
object, a union of several tubular structures, into its semantic components. We
decompose the object using its curve skeleton and restricted translational
sweeps. For that, CSD partitions the curve skeleton into maximal-length
sub-skeletons over an orientation cost, each sub-skeleton corresponds to a
semantic component. To find the intersection of the tubular components, CSD
translationally sweeps the object in decomposition intervals to identify
critical points at which the shape of the object changes substantially. CSD
cuts the object at critical points and assigns the same label to parts along
the same sub-skeleton, thereby constructing a semantic component. The proposed
method further reconstructs the acquired semantic components at the
intersection of object parts using generalized cylinders. We apply CSD for
segmenting axons in large 3D electron microscopy images and decomposing
vascular networks and synthetic objects. We show that our proposal is robust to
severe surface noise and outperforms state-of-the-art decomposition techniques
in its applications.
</p>
<a href="http://arxiv.org/abs/1911.00571" target="_blank">arXiv:1911.00571</a> [<a href="http://arxiv.org/pdf/1911.00571" target="_blank">pdf</a>]

<h2>Force-guided High-precision Grasping Control of Fragile and Deformable Objects using sEMG-based Force Prediction. (arXiv:2002.01791v2 [cs.RO] UPDATED)</h2>
<h3>Ruoshi Wen, Kai Yuan, Qiang Wang, Shuai Heng, Zhibin Li</h3>
<p>Regulating contact forces with high precision is crucial for grasping and
manipulating fragile or deformable objects. We aim to utilize the dexterity of
human hands to regulate the contact forces for robotic hands and exploit human
sensory-motor synergies in a wearable and non-invasive way. We extracted force
information from the electric activities of skeletal muscles during their
voluntary contractions through surface electromyography (sEMG). We built a
regression model based on a Neural Network to predict the gripping force from
the preprocessed sEMG signals and achieved high accuracy (R2 = 0.982). Based on
the force command predicted from human muscles, we developed a force-guided
control framework, where force control was realized via an admittance
controller that tracked the predicted gripping force reference to grasp
delicate and deformable objects. We demonstrated the effectiveness of the
proposed method on a set of representative fragile and deformable objects from
daily life, all of which were successfully grasped without any damage or
deformation.
</p>
<a href="http://arxiv.org/abs/2002.01791" target="_blank">arXiv:2002.01791</a> [<a href="http://arxiv.org/pdf/2002.01791" target="_blank">pdf</a>]

<h2>Adaptive Approximate Policy Iteration. (arXiv:2002.03069v4 [cs.LG] UPDATED)</h2>
<h3>Botao Hao, Nevena Lazic, Yasin Abbasi-Yadkori, Pooria Joulani, Csaba Szepesvari</h3>
<p>Model-free reinforcement learning algorithms combined with value function
approximation have recently achieved impressive performance in a variety of
application domains. However, the theoretical understanding of such algorithms
is limited, and existing results are largely focused on episodic or discounted
Markov decision processes (MDPs). In this work, we present adaptive approximate
policy iteration (AAPI), a learning scheme which enjoys a $\tilde{O}(T^{2/3})$
regret bound for undiscounted, continuing learning in uniformly ergodic MDPs.
This is an improvement over the best existing bound of $\tilde{O}(T^{3/4})$ for
the average-reward case with function approximation. Our algorithm and analysis
rely on online learning techniques, where value functions are treated as
losses. The main technical novelty is the use of a data-dependent adaptive
learning rate coupled with a so-called optimistic prediction of upcoming
losses. In addition to theoretical guarantees, we demonstrate the advantages of
our approach empirically on several environments.
</p>
<a href="http://arxiv.org/abs/2002.03069" target="_blank">arXiv:2002.03069</a> [<a href="http://arxiv.org/pdf/2002.03069" target="_blank">pdf</a>]

<h2>Human Perception of Intrinsically Motivated Autonomy in Human-Robot Interaction. (arXiv:2002.05936v3 [cs.RO] UPDATED)</h2>
<h3>Marcus M. Scheunemann, Christoph Salge, Daniel Polani, Kerstin Dautenhahn</h3>
<p>A challenge in using robots in human-inhabited environments is to design
behavior that is engaging, yet robust to the perturbations induced by human
interaction. Our idea is to imbue the robot with intrinsic motivation (IM) so
that it can handle new situations and appears as a genuine social other to
humans and thus be of more interest to a human interaction partner. Human-robot
interaction (HRI) experiments mainly focus on scripted or teleoperated robots,
that mimic characteristics such as IM to control isolated behavior factors.
This article presents a "robotologist" study design that allows comparing
autonomously generated behaviors with each other, and, for the first time,
evaluates the human perception of IM-based generated behavior in robots. We
conducted a within-subjects user study (N=24) where participants interacted
with a fully autonomous Sphero BB8 robot with different behavioral regimes: one
realizing an adaptive, intrinsically motivated behavior and the other being
reactive, but not adaptive. A quantitative analysis of post-interaction
questionnaires showed a significantly higher perception of the dimension
"Warmth" compared to the reactive baseline behavior. Warmth is considered a
primary dimension for social attitude formation in human social cognition. A
human perceived as warm (friendly, trustworthy) experiences more positive
social interactions.
</p>
<a href="http://arxiv.org/abs/2002.05936" target="_blank">arXiv:2002.05936</a> [<a href="http://arxiv.org/pdf/2002.05936" target="_blank">pdf</a>]

<h2>Uncertainty Estimation in Autoregressive Structured Prediction. (arXiv:2002.07650v5 [stat.ML] UPDATED)</h2>
<h3>Andrey Malinin, Mark Gales</h3>
<p>Uncertainty estimation is important for ensuring safety and robustness of AI
systems. While most research in the area has focused on un-structured
prediction tasks, limited work has investigated general uncertainty estimation
approaches for structured prediction. Thus, this work aims to investigate
uncertainty estimation for autoregressive structured prediction tasks within a
single unified and interpretable probabilistic ensemble-based framework. We
consider: uncertainty estimation for sequence data at the token-level and
complete sequence-level; interpretations for, and applications of, various
measures of uncertainty; and discuss both the theoretical and practical
challenges associated with obtaining them. This work also provides baselines
for token-level and sequence-level error detection, and sequence-level
out-of-domain input detection on the WMT'14 English-French and WMT'17
English-German translation and LibriSpeech speech recognition datasets.
</p>
<a href="http://arxiv.org/abs/2002.07650" target="_blank">arXiv:2002.07650</a> [<a href="http://arxiv.org/pdf/2002.07650" target="_blank">pdf</a>]

<h2>A survey on Semi-, Self- and Unsupervised Learning for Image Classification. (arXiv:2002.08721v4 [cs.CV] UPDATED)</h2>
<h3>Lars Schmarje, Monty Santarossa, Simon-Martin Schr&#xf6;der, Reinhard Koch</h3>
<p>While deep learning strategies achieve outstanding results in computer vision
tasks, one issue remains: The current strategies rely heavily on a huge amount
of labeled data. In many real-world problems, it is not feasible to create such
an amount of labeled training data. Therefore, it is common to incorporate
unlabeled data into the training process to reach equal results with fewer
labels. Due to a lot of concurrent research, it is difficult to keep track of
recent developments. In this survey, we provide an overview of often used ideas
and methods in image classification with fewer labels. We compare 33 methods in
detail based on their performance and their commonly used ideas rather than a
fine-grained taxonomy. In our analysis, we identify three major trends that
lead to future research opportunities. 1. State-of-the-art methods are
scaleable to real-world applications in theory but issues like class imbalance,
robustness, or fuzzy labels are not considered. 2. The degree of supervision
which is needed to achieve comparable results to the usage of all labels is
decreasing and therefore methods need to be extended to settings with a
variable number of classes. 3. All methods share some common ideas but we
identify clusters of methods that do not share many ideas. We show that
combining ideas from different clusters can lead to better performance.
</p>
<a href="http://arxiv.org/abs/2002.08721" target="_blank">arXiv:2002.08721</a> [<a href="http://arxiv.org/pdf/2002.08721" target="_blank">pdf</a>]

<h2>Image Matching across Wide Baselines: From Paper to Practice. (arXiv:2003.01587v5 [cs.CV] UPDATED)</h2>
<h3>Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuk, Jiri Matas, Pascal Fua, Kwang Moo Yi, Eduard Trulls</h3>
<p>We introduce a comprehensive benchmark for local features and robust
estimation algorithms, focusing on the downstream task -- the accuracy of the
reconstructed camera pose -- as our primary metric. Our pipeline's modular
structure allows easy integration, configuration, and combination of different
methods and heuristics. This is demonstrated by embedding dozens of popular
algorithms and evaluating them, from seminal works to the cutting edge of
machine learning research. We show that with proper settings, classical
solutions may still outperform the perceived state of the art.

Besides establishing the actual state of the art, the conducted experiments
reveal unexpected properties of Structure from Motion (SfM) pipelines that can
help improve their performance, for both algorithmic and learned methods. Data
and code are online https://github.com/vcg-uvic/image-matching-benchmark,
providing an easy-to-use and flexible framework for the benchmarking of local
features and robust estimation methods, both alongside and against
top-performing methods. This work provides a basis for the Image Matching
Challenge https://vision.uvic.ca/image-matching-challenge.
</p>
<a href="http://arxiv.org/abs/2003.01587" target="_blank">arXiv:2003.01587</a> [<a href="http://arxiv.org/pdf/2003.01587" target="_blank">pdf</a>]

<h2>Semantic interoperability based on the European Materials and Modelling Ontology and its ontological paradigm: Mereosemiotics. (arXiv:2003.11370v4 [cs.AI] UPDATED)</h2>
<h3>Martin Thomas Horsch, Silvia Chiacchiera, Bj&#xf6;rn Schembera, Michael A. Seaton, Ilian T. Todorov</h3>
<p>The European Materials and Modelling Ontology (EMMO) has recently been
advanced in the computational molecular engineering and multiscale modelling
communities as a top-level ontology, aiming to support semantic
interoperability and data integration solutions, e.g., for research data
infrastructures. The present work explores how top-level ontologies that are
based on the same paradigm - the same set of fundamental postulates - as the
EMMO can be applied to models of physical systems and their use in
computational engineering practice. This paradigm, which combines mereology (in
its extension as mereotopology) and semiotics (following Peirce's approach), is
here referred to as mereosemiotics. Multiple conceivable ways of implementing
mereosemiotics are compared, and the design space consisting of the possible
types of top-level ontologies following this paradigm is characterized.
</p>
<a href="http://arxiv.org/abs/2003.11370" target="_blank">arXiv:2003.11370</a> [<a href="http://arxiv.org/pdf/2003.11370" target="_blank">pdf</a>]

<h2>Convolution-Weight-Distribution Assumption: Rethinking the Criteria of Channel Pruning. (arXiv:2004.11627v2 [cs.LG] UPDATED)</h2>
<h3>Zhongzhan Huang, Wenqi Shao, Xinjiang Wang, Ping Luo</h3>
<p>Channel pruning is a popular technique for compressing convolutional neural
networks (CNNs), where various pruning criteria have been proposed to remove
the redundant filters. From our comprehensive experiments, we found two blind
spots in the study of pruning criteria: (1) Similarity: There are some strong
similarities among several primary pruning criteria that are widely cited and
compared. According to these criteria, the ranks of filters'Importance Score
are almost identical, resulting in similar pruned structures. (2)
Applicability: The filters'Importance Score measured by some pruning criteria
are too close to distinguish the network redundancy well. In this paper, we
analyze these two blind spots on different types of pruning criteria with
layer-wise pruning or global pruning. The analyses are based on the empirical
experiments and our assumption (Convolutional Weight Distribution Assumption)
that the well-trained convolutional filters each layer approximately follow a
Gaussian-alike distribution. This assumption has been verified through
systematic and extensive statistical tests.
</p>
<a href="http://arxiv.org/abs/2004.11627" target="_blank">arXiv:2004.11627</a> [<a href="http://arxiv.org/pdf/2004.11627" target="_blank">pdf</a>]

<h2>Underestimation Bias and Underfitting in Machine Learning. (arXiv:2005.09052v3 [cs.LG] UPDATED)</h2>
<h3>Padraig Cunningham, Sarah Jane Delany</h3>
<p>Often, what is termed algorithmic bias in machine learning will be due to
historic bias in the training data. But sometimes the bias may be introduced
(or at least exacerbated) by the algorithm itself. The ways in which algorithms
can actually accentuate bias has not received a lot of attention with
researchers focusing directly on methods to eliminate bias - no matter the
source. In this paper we report on initial research to understand the factors
that contribute to bias in classification algorithms. We believe this is
important because underestimation bias is inextricably tied to regularization,
i.e. measures to address overfitting can accentuate bias.
</p>
<a href="http://arxiv.org/abs/2005.09052" target="_blank">arXiv:2005.09052</a> [<a href="http://arxiv.org/pdf/2005.09052" target="_blank">pdf</a>]

<h2>Toward Automated Classroom Observation: Multimodal Machine Learning to Estimate CLASS Positive Climate and Negative Climate. (arXiv:2005.09525v2 [cs.CV] UPDATED)</h2>
<h3>Anand Ramakrishnan, Brian Zylich, Erin Ottmar, Jennifer LoCasale-Crouch, Jacob Whitehill</h3>
<p>In this work we present a multi-modal machine learning-based system, which we
call ACORN, to analyze videos of school classrooms for the Positive Climate
(PC) and Negative Climate (NC) dimensions of the CLASS observation protocol
that is widely used in educational research. ACORN uses convolutional neural
networks to analyze spectral audio features, the faces of teachers and
students, and the pixels of each image frame, and then integrates this
information over time using Temporal Convolutional Networks. The audiovisual
ACORN's PC and NC predictions have Pearson correlations of $0.55$ and $0.63$
with ground-truth scores provided by expert CLASS coders on the UVA Toddler
dataset (cross-validation on $n=300$ 15-min video segments), and a purely
auditory ACORN predicts PC and NC with correlations of $0.36$ and $0.41$ on the
MET dataset (test set of $n=2000$ videos segments). These numbers are similar
to inter-coder reliability of human coders. Finally, using Graph Convolutional
Networks we make early strides (AUC=$0.70$) toward predicting the specific
moments (45-90sec clips) when the PC is particularly weak/strong. Our findings
inform the design of automatic classroom observation and also more general
video activity recognition and summary recognition systems.
</p>
<a href="http://arxiv.org/abs/2005.09525" target="_blank">arXiv:2005.09525</a> [<a href="http://arxiv.org/pdf/2005.09525" target="_blank">pdf</a>]

<h2>Meta-Model-Based Meta-Policy Optimization. (arXiv:2006.02608v4 [cs.LG] UPDATED)</h2>
<h3>Takuya Hiraoka, Takahisa Imagawa, Voot Tangkaratt, Takayuki Osa, Takashi Onishi, Yoshimasa Tsuruoka</h3>
<p>Model-based meta-reinforcement learning (RL) methods have recently shown to
be a promising approach to improving the sample efficiency of RL in multi-task
settings. However, the theoretical understanding of those methods is yet to be
established, and there is currently no theoretical guarantee of their
performance in a real-world environment. In this paper, we analyze the
performance guarantee of model-based meta-RL methods by extending the theorems
proposed by Janner et al. (2019). On the basis of our theoretical results, we
propose Meta-Model-Based Meta-Policy Optimization (M3PO), a model-based meta-RL
method with a performance guarantee. We demonstrate that M3PO outperforms
existing meta-RL methods in continuous-control benchmarks.
</p>
<a href="http://arxiv.org/abs/2006.02608" target="_blank">arXiv:2006.02608</a> [<a href="http://arxiv.org/pdf/2006.02608" target="_blank">pdf</a>]

<h2>Newton-type Methods for Minimax Optimization. (arXiv:2006.14592v2 [cs.LG] UPDATED)</h2>
<h3>Guojun Zhang, Kaiwen Wu, Pascal Poupart, Yaoliang Yu</h3>
<p>Differential games, in particular two-player sequential zero-sum games
(a.k.a. minimax optimization), have been an important modeling tool in applied
science and received renewed interest in machine learning due to many recent
applications, such as adversarial training, generative models and reinforcement
learning. However, existing theory mostly focuses on convex-concave functions
with few exceptions. In this work, we propose two novel Newton-type algorithms
for nonconvex-nonconcave minimax optimization. We prove their local convergence
at strict local minimax points, which are surrogates of global solutions. We
argue that our Newton-type algorithms nicely complement existing ones in that
(a) they converge faster to strict local minimax points; (b) they are much more
effective when the problem is ill-conditioned; (c) their computational
complexity remains similar. We verify the effectiveness of our Newton-type
algorithms through experiments on training GANs which are intrinsically
nonconvex and ill-conditioned.
</p>
<a href="http://arxiv.org/abs/2006.14592" target="_blank">arXiv:2006.14592</a> [<a href="http://arxiv.org/pdf/2006.14592" target="_blank">pdf</a>]

<h2>Influence Functions in Deep Learning Are Fragile. (arXiv:2006.14651v2 [cs.LG] UPDATED)</h2>
<h3>Samyadeep Basu, Philip Pope, Soheil Feizi</h3>
<p>Influence functions approximate the effect of training samples in test-time
predictions and have a wide variety of applications in machine learning
interpretability and uncertainty estimation. A commonly-used (first-order)
influence function can be implemented efficiently as a post-hoc method
requiring access only to the gradients and Hessian of the model. For linear
models, influence functions are well-defined due to the convexity of the
underlying loss function and are generally accurate even across difficult
settings where model changes are fairly large such as estimating group
influences. Influence functions, however, are not well-understood in the
context of deep learning with non-convex loss functions. In this paper, we
provide a comprehensive and large-scale empirical study of successes and
failures of influence functions in neural network models trained on datasets
such as Iris, MNIST, CIFAR-10 and ImageNet. Through our extensive experiments,
we show that the network architecture, its depth and width, as well as the
extent of model parameterization and regularization techniques have strong
effects in the accuracy of influence functions. In particular, we find that (i)
influence estimates are fairly accurate for shallow networks, while for deeper
networks the estimates are often erroneous; (ii) for certain network
architectures and datasets, training with weight-decay regularization is
important to get high-quality influence estimates; and (iii) the accuracy of
influence estimates can vary significantly depending on the examined test
points. These results suggest that in general influence functions in deep
learning are fragile and call for developing improved influence estimation
methods to mitigate these issues in non-convex setups.
</p>
<a href="http://arxiv.org/abs/2006.14651" target="_blank">arXiv:2006.14651</a> [<a href="http://arxiv.org/pdf/2006.14651" target="_blank">pdf</a>]

<h2>A Le Cam Type Bound for Adversarial Learning and Applications. (arXiv:2007.00289v2 [stat.ML] UPDATED)</h2>
<h3>Qiuling Xu, Kevin Bello, Jean Honorio</h3>
<p>Robustness of machine learning methods is essential for modern practical
applications. Given the arms race between attack and defense methods, one may
be curious regarding the fundamental limits of any defense mechanism. In this
work, we focus on the problem of learning from noise-injected data, where the
existing literature falls short by either assuming a specific attack method or
by over-specifying the learning problem. We shed light on the
information-theoretic limits of adversarial learning without assuming a
particular learning process or attacker. Finally, we apply our general bounds
to a canonical set of non-trivial learning problems and provide examples of
common types of attacks.
</p>
<a href="http://arxiv.org/abs/2007.00289" target="_blank">arXiv:2007.00289</a> [<a href="http://arxiv.org/pdf/2007.00289" target="_blank">pdf</a>]

<h2>Descending through a Crowded Valley -- Benchmarking Deep Learning Optimizers. (arXiv:2007.01547v5 [cs.LG] UPDATED)</h2>
<h3>Robin M. Schmidt, Frank Schneider, Philipp Hennig</h3>
<p>Choosing the optimizer is considered to be among the most crucial design
decisions in deep learning, and it is not an easy one. The growing literature
now lists hundreds of optimization methods. In the absence of clear theoretical
guidance and conclusive empirical evidence, the decision is often made based on
anecdotes. In this work, we aim to replace these anecdotes, if not with a
conclusive ranking, then at least with evidence-backed heuristics. To do so, we
perform an extensive, standardized benchmark of fifteen particularly popular
deep learning optimizers while giving a concise overview of the wide range of
possible choices. Analyzing more than $50,000$ individual runs, we contribute
the following three points: (i) Optimizer performance varies greatly across
tasks. (ii) We observe that evaluating multiple optimizers with default
parameters works approximately as well as tuning the hyperparameters of a
single, fixed optimizer. (iii) While we cannot discern an optimization method
clearly dominating across all tested tasks, we identify a significantly reduced
subset of specific optimizers and parameter choices that generally lead to
competitive results in our experiments: Adam remains a strong contender, with
newer methods failing to significantly and consistently outperform it. Our
open-sourced results are available as challenging and well-tuned baselines for
more meaningful evaluations of novel optimization methods without requiring any
further computational efforts.
</p>
<a href="http://arxiv.org/abs/2007.01547" target="_blank">arXiv:2007.01547</a> [<a href="http://arxiv.org/pdf/2007.01547" target="_blank">pdf</a>]

<h2>Few-Shot One-Class Classification via Meta-Learning. (arXiv:2007.04146v2 [cs.LG] UPDATED)</h2>
<h3>Ahmed Frikha, Denis Krompa&#xdf;, Hans-Georg K&#xf6;pken, Volker Tresp</h3>
<p>Although few-shot learning and one-class classification (OCC), i.e., learning
a binary classifier with data from only one class, have been separately well
studied, their intersection remains rather unexplored. Our work addresses the
few-shot OCC problem and presents a method to modify the episodic data sampling
strategy of the model-agnostic meta-learning (MAML) algorithm to learn a model
initialization particularly suited for learning few-shot OCC tasks. This is
done by explicitly optimizing for an initialization which only requires few
gradient steps with one-class minibatches to yield a performance increase on
class-balanced test data. We provide a theoretical analysis that explains why
our approach works in the few-shot OCC scenario, while other meta-learning
algorithms fail, including the unmodified MAML. Our experiments on eight
datasets from the image and time-series domains show that our method leads to
better results than classical OCC and few-shot classification approaches, and
demonstrate the ability to learn unseen tasks from only few normal class
samples. Moreover, we successfully train anomaly detectors for a real-world
application on sensor readings recorded during industrial manufacturing of
workpieces with a CNC milling machine, by using few normal examples. Finally,
we empirically demonstrate that the proposed data sampling technique increases
the performance of more recent meta-learning algorithms in few-shot OCC and
yields state-of-the-art results in this problem setting.
</p>
<a href="http://arxiv.org/abs/2007.04146" target="_blank">arXiv:2007.04146</a> [<a href="http://arxiv.org/pdf/2007.04146" target="_blank">pdf</a>]

<h2>Who Left the Dogs Out? 3D Animal Reconstruction with Expectation Maximization in the Loop. (arXiv:2007.11110v2 [cs.CV] UPDATED)</h2>
<h3>Benjamin Biggs, Oliver Boyne, James Charles, Andrew Fitzgibbon, Roberto Cipolla</h3>
<p>We introduce an automatic, end-to-end method for recovering the 3D pose and
shape of dogs from monocular internet images. The large variation in shape
between dog breeds, significant occlusion and low quality of internet images
makes this a challenging problem. We learn a richer prior over shapes than
previous work, which helps regularize parameter estimation. We demonstrate
results on the Stanford Dog dataset, an 'in the wild' dataset of 20,580 dog
images for which we have collected 2D joint and silhouette annotations to split
for training and evaluation. In order to capture the large shape variety of
dogs, we show that the natural variation in the 2D dataset is enough to learn a
detailed 3D prior through expectation maximization (EM). As a by-product of
training, we generate a new parameterized model (including limb scaling) SMBLD
which we release alongside our new annotation dataset StanfordExtra to the
research community.
</p>
<a href="http://arxiv.org/abs/2007.11110" target="_blank">arXiv:2007.11110</a> [<a href="http://arxiv.org/pdf/2007.11110" target="_blank">pdf</a>]

<h2>Learning to Set Waypoints for Audio-Visual Navigation. (arXiv:2008.09622v3 [cs.CV] UPDATED)</h2>
<h3>Changan Chen, Sagnik Majumder, Ziad Al-Halah, Ruohan Gao, Santhosh Kumar Ramakrishnan, Kristen Grauman</h3>
<p>In audio-visual navigation, an agent intelligently travels through a complex,
unmapped 3D environment using both sights and sounds to find a sound source
(e.g., a phone ringing in another room). Existing models learn to act at a
fixed granularity of agent motion and rely on simple recurrent aggregations of
the audio observations. We introduce a reinforcement learning approach to
audio-visual navigation with two key novel elements: 1) waypoints that are
dynamically set and learned end-to-end within the navigation policy, and 2) an
acoustic memory that provides a structured, spatially grounded record of what
the agent has heard as it moves. Both new ideas capitalize on the synergy of
audio and visual data for revealing the geometry of an unmapped space. We
demonstrate our approach on two challenging datasets of real-world 3D scenes,
Replica and Matterport3D. Our model improves the state of the art by a
substantial margin, and our experiments reveal that learning the links between
sights, sounds, and space is essential for audio-visual navigation. Project:
this http URL
</p>
<a href="http://arxiv.org/abs/2008.09622" target="_blank">arXiv:2008.09622</a> [<a href="http://arxiv.org/pdf/2008.09622" target="_blank">pdf</a>]

<h2>FedCM: A Real-time Contribution Measurement Method for Participants in Federated Learning. (arXiv:2009.03510v2 [cs.LG] UPDATED)</h2>
<h3>Boyi Liu, Bingjie Yan, Yize Zhou, Zhixuan Liang, Cheng-Zhong Xu</h3>
<p>Federated Learning (FL) creates an ecosystem for multiple agents to
collaborate on building models with data privacy consideration. The method for
contribution measurement of each agent in the FL system is critical for fair
credits allocation but few are proposed. In this paper, we develop a real-time
contribution measurement method FedCM that is simple but powerful. The method
defines the impact of each agent, comprehensively considers the current round
and the previous round to obtain the contribution rate of each agent with
attention aggregation. Moreover, FedCM updates contribution every round, which
enable it to perform in real-time. Real-time is not considered by the existing
approaches, but it is critical for FL systems to allocate computing power,
communication resources, etc. Compared to the state-of-the-art method, the
experimental results show that FedCM is more sensitive to data quantity and
data quality under the premise of real-time. Furthermore, we developed
federated learning open-source software based on FedCM. The software has been
applied to identify COVID-19 based on medical images.
</p>
<a href="http://arxiv.org/abs/2009.03510" target="_blank">arXiv:2009.03510</a> [<a href="http://arxiv.org/pdf/2009.03510" target="_blank">pdf</a>]

<h2>Reinforcement Learning Approaches in Social Robotics. (arXiv:2009.09689v4 [cs.RO] UPDATED)</h2>
<h3>Neziha Akalin, Amy Loutfi</h3>
<p>This article surveys reinforcement learning approaches in social robotics.
Reinforcement learning is a framework for decision-making problems in which an
agent interacts through trial-and-error with its environment to discover an
optimal behavior. Since interaction is a key component in both reinforcement
learning and social robotics, it can be a well-suited approach for real-world
interactions with physically embodied social robots. The scope of the paper is
focused particularly on studies that include social physical robots and
real-world human-robot interactions with users. We present a thorough analysis
of reinforcement learning approaches in social robotics. In addition to a
survey, we categorize existent reinforcement learning approaches based on the
used method and the design of the reward mechanisms. Moreover, since
communication capability is a prominent feature of social robots, we discuss
and group the papers based on the communication medium used for reward
formulation. Considering the importance of designing the reward function, we
also provide a categorization of the papers based on the nature of the reward.
This categorization includes three major themes: interactive reinforcement
learning, intrinsically motivated methods, and task performance-driven methods.
The benefits and challenges of reinforcement learning in social robotics,
evaluation methods of the papers regarding whether or not they use subjective
and algorithmic measures, a discussion in the view of real-world reinforcement
learning challenges and proposed solutions, the points that remain to be
explored, including the approaches that have thus far received less attention
is also given in the paper. Thus, this paper aims to become a starting point
for researchers interested in using and applying reinforcement learning methods
in this particular research field.
</p>
<a href="http://arxiv.org/abs/2009.09689" target="_blank">arXiv:2009.09689</a> [<a href="http://arxiv.org/pdf/2009.09689" target="_blank">pdf</a>]

<h2>Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect. (arXiv:2009.12991v4 [cs.CV] UPDATED)</h2>
<h3>Kaihua Tang, Jianqiang Huang, Hanwang Zhang</h3>
<p>As the class size grows, maintaining a balanced dataset across many classes
is challenging because the data are long-tailed in nature; it is even
impossible when the sample-of-interest co-exists with each other in one
collectable unit, e.g., multiple visual instances in one image. Therefore,
long-tailed classification is the key to deep learning at scale. However,
existing methods are mainly based on re-weighting/re-sampling heuristics that
lack a fundamental theory. In this paper, we establish a causal inference
framework, which not only unravels the whys of previous methods, but also
derives a new principled solution. Specifically, our theory shows that the SGD
momentum is essentially a confounder in long-tailed classification. On one
hand, it has a harmful causal effect that misleads the tail prediction biased
towards the head. On the other hand, its induced mediation also benefits the
representation learning and head prediction. Our framework elegantly
disentangles the paradoxical effects of the momentum, by pursuing the direct
causal effect caused by an input sample. In particular, we use causal
intervention in training, and counterfactual reasoning in inference, to remove
the "bad" while keep the "good". We achieve new state-of-the-arts on three
long-tailed visual recognition benchmarks: Long-tailed CIFAR-10/-100,
ImageNet-LT for image classification and LVIS for instance segmentation.
</p>
<a href="http://arxiv.org/abs/2009.12991" target="_blank">arXiv:2009.12991</a> [<a href="http://arxiv.org/pdf/2009.12991" target="_blank">pdf</a>]

<h2>Active Feature Acquisition with Generative Surrogate Models. (arXiv:2010.02433v2 [cs.LG] UPDATED)</h2>
<h3>Yang Li, Junier B. Oliva</h3>
<p>Many real-world situations allow for the acquisition of additional relevant
information when making an assessment with limited or uncertain data. However,
traditional ML approaches either require all features to be acquired beforehand
or regard part of them as missing data that cannot be acquired. In this work,
we consider models that perform active feature acquisition (AFA) and query the
environment for unobserved features to improve the prediction assessments at
evaluation time. Our work reformulates the Markov decision process (MDP) that
underlies the AFA problem as a generative modeling task and optimizes a policy
via a novel model-based approach. We propose learning a generative surrogate
model (GSM) that captures the dependencies among input features to assess
potential information gain from acquisitions. The GSM is leveraged to provide
intermediate rewards and auxiliary information to aid the agent navigate a
complicated high-dimensional action space and sparse rewards. Furthermore, we
extend AFA in a task we coin active instance recognition (AIR) for the
unsupervised case where the target variables are the unobserved features
themselves and the goal is to collect information for a particular instance in
a cost-efficient way. Empirical results demonstrate that our approach achieves
considerably better performance than previous state of the art methods on both
supervised and unsupervised tasks.
</p>
<a href="http://arxiv.org/abs/2010.02433" target="_blank">arXiv:2010.02433</a> [<a href="http://arxiv.org/pdf/2010.02433" target="_blank">pdf</a>]

<h2>Super-Human Performance in Online Low-latency Recognition of Conversational Speech. (arXiv:2010.03449v3 [cs.CV] UPDATED)</h2>
<h3>Thai-Son Nguyen, Sebastian Stueker, Alex Waibel</h3>
<p>Achieving super-human performance in recognizing human speech has been a goal
for several decades, as researchers have worked on increasingly challenging
tasks. In the 1990's it was discovered, that conversational speech between two
humans turns out to be considerably more difficult than read speech as
hesitations, disfluencies, false starts and sloppy articulation complicate
acoustic processing and require robust handling of acoustic, lexical and
language context, jointly. Early attempts with statistical models could only
reach error rates over 50% and far from human performance (WER of around 5.5%).
Neural hybrid models and recent attention-based encoder-decoder models have
considerably improved performance as such contexts can now be learned in an
integral fashion. However, processing such contexts requires an entire
utterance presentation and thus introduces unwanted delays before a recognition
result can be output. In this paper, we address performance as well as latency.
We present results for a system that can achieve super-human performance (at a
WER of 5.0%, over the Switchboard conversational benchmark) at a word based
latency of only 1 second behind a speaker's speech. The system uses multiple
attention-based encoder-decoder networks integrated within a novel low latency
incremental inference approach.
</p>
<a href="http://arxiv.org/abs/2010.03449" target="_blank">arXiv:2010.03449</a> [<a href="http://arxiv.org/pdf/2010.03449" target="_blank">pdf</a>]

<h2>Transformers for Modeling Physical Systems. (arXiv:2010.03957v4 [cs.LG] UPDATED)</h2>
<h3>Nicholas Geneva, Nicholas Zabaras</h3>
<p>Transformers are widely used in natural language processing due to their
ability to model longer-term dependencies in text. Although these models
achieve state-of-the-art performance for many language related tasks, their
applicability outside of the natural language processing field has been
minimal. In this work, we propose the use of transformer models for the
prediction of dynamical systems representative of physical phenomena. The use
of Koopman based embeddings provide a unique and powerful method for projecting
any dynamical system into a vector representation which can then be predicted
by a transformer model. The proposed model is able to accurately predict
various dynamical systems and outperform classical methods that are commonly
used in the scientific machine learning literature.
</p>
<a href="http://arxiv.org/abs/2010.03957" target="_blank">arXiv:2010.03957</a> [<a href="http://arxiv.org/pdf/2010.03957" target="_blank">pdf</a>]

<h2>Probabilistic Surface Friction Estimation Based on Visual and Haptic Measurements. (arXiv:2010.08277v2 [cs.RO] UPDATED)</h2>
<h3>Tran Nguyen Le, Francesco Verdoja, Fares J. Abu-Dakka, Ville Kyrki</h3>
<p>Accurately modeling local surface properties of objects is crucial to many
robotic applications, from grasping to material recognition. Surface properties
like friction are however difficult to estimate, as visual observation of the
object does not convey enough information over these properties. In contrast,
haptic exploration is time consuming as it only provides information relevant
to the explored parts of the object. In this work, we propose a joint
visuo-haptic object model that enables the estimation of surface friction
coefficient over an entire object by exploiting the correlation of visual and
haptic information, together with a limited haptic exploration by a robotic
arm. We demonstrate the validity of the proposed method by showing its ability
to estimate varying friction coefficients on a range of real multi-material
objects. Furthermore, we illustrate how the estimated friction coefficients can
improve grasping success rate by guiding a grasp planner toward high friction
areas.
</p>
<a href="http://arxiv.org/abs/2010.08277" target="_blank">arXiv:2010.08277</a> [<a href="http://arxiv.org/pdf/2010.08277" target="_blank">pdf</a>]

<h2>Feature Selection for Huge Data via Minipatch Learning. (arXiv:2010.08529v2 [stat.ML] UPDATED)</h2>
<h3>Tianyi Yao, Genevera I. Allen</h3>
<p>Feature selection often leads to increased model interpretability, faster
computation, and improved model performance by discarding irrelevant or
redundant features. While feature selection is a well-studied problem with many
widely-used techniques, there are typically two key challenges: i) many
existing approaches become computationally intractable in huge-data settings
with millions of observations and features; and ii) the statistical accuracy of
selected features degrades in high-noise, high-correlation settings, thus
hindering reliable model interpretation. We tackle these problems by proposing
Stable Minipatch Selection (STAMPS) and Adaptive STAMPS (AdaSTAMPS). These are
meta-algorithms that build ensembles of selection events of base feature
selectors trained on many tiny, (adaptively-chosen) random subsets of both the
observations and features of the data, which we call minipatches. Our
approaches are general and can be employed with a variety of existing feature
selection strategies and machine learning techniques. In addition, we provide
theoretical insights on STAMPS and empirically demonstrate that our approaches,
especially AdaSTAMPS, dominate competing methods in terms of feature selection
accuracy and computational time.
</p>
<a href="http://arxiv.org/abs/2010.08529" target="_blank">arXiv:2010.08529</a> [<a href="http://arxiv.org/pdf/2010.08529" target="_blank">pdf</a>]

<h2>Multiple-view clustering for identifying subject clusters and brain sub-networks using functional connectivity matrices without vectorization. (arXiv:2010.09941v2 [stat.ML] UPDATED)</h2>
<h3>Tomoki Tokuda, Okito Yamashita, Junichiro Yoshimoto</h3>
<p>In neuroscience, the functional magnetic resonance imaging (fMRI) is a vital
tool to non-invasively access brain activity. Using fMRI, the functional
connectivity (FC) between brain regions can be inferred, which has contributed
to a number of findings of the fundamental properties of the brain. As an
important clinical application of FC, clustering of subjects based on FC
recently draws much attention, which can potentially reveal important
heterogeneity in subjects such as subtypes of psychiatric disorders. In
particular, a multiple-view clustering method is a powerful analytical tool,
which identifies clustering patterns of subjects depending on their FC in
specific brain areas. However, when one applies an existing multiple-view
clustering method to fMRI data, there is a need to simplify the data structure,
independently dealing with elements in a FC matrix, i.e., vectorizing a
correlation matrix. Such a simplification may distort the clustering results.
To overcome this problem, we propose a novel multiple-view clustering method
based on Wishart mixture models, which preserves the correlation matrix
structure without vectorization. The uniqueness of this method is that the
multiple-view clustering of subjects is based on particular networks of nodes
(or regions of interest, ROIs), optimized in a data-driven manner. Hence, it
can identify multiple underlying pairs of associations between a subject
cluster solution and a ROI sub-network. The key assumption of the method is
independence among sub-networks, which is effectively addressed by whitening
correlation matrices. We applied the proposed method to synthetic and fMRI
data, demonstrating the usefulness and power of the proposed method.
</p>
<a href="http://arxiv.org/abs/2010.09941" target="_blank">arXiv:2010.09941</a> [<a href="http://arxiv.org/pdf/2010.09941" target="_blank">pdf</a>]

<h2>Replacing Human Audio with Synthetic Audio for On-device Unspoken Punctuation Prediction. (arXiv:2010.10203v2 [cs.LG] UPDATED)</h2>
<h3>Daria Soboleva, Ondrej Skopek, M&#xe1;rius &#x160;ajgal&#xed;k, Victor C&#x103;rbune, Felix Weissenberger, Julia Proskurnia, Bogdan Prisacari, Daniel Valcarce, Justin Lu, Rohit Prabhavalkar, Balint Miklos</h3>
<p>We present a novel multi-modal unspoken punctuation prediction system for the
English language which combines acoustic and text features. We demonstrate for
the first time, that by relying exclusively on synthetic data generated using a
prosody-aware text-to-speech system, we can outperform a model trained with
expensive human audio recordings on the unspoken punctuation prediction
problem. Our model architecture is well suited for on-device use. This is
achieved by leveraging hash-based embeddings of automatic speech recognition
text output in conjunction with acoustic features as input to a quasi-recurrent
neural network, keeping the model size small and latency low.
</p>
<a href="http://arxiv.org/abs/2010.10203" target="_blank">arXiv:2010.10203</a> [<a href="http://arxiv.org/pdf/2010.10203" target="_blank">pdf</a>]

<h2>A Computationally Efficient Approach to Black-box Optimization using Gaussian Process Models. (arXiv:2010.13997v2 [stat.ML] UPDATED)</h2>
<h3>Sudeep Salgia, Sattar Vakili, Qing Zhao</h3>
<p>We consider sequential optimization of an unknown function under Gaussian
process models. We develop a computationally efficient algorithm that reduces
the complexity of the prevailing GP-UCB family of algorithms by a factor of
$O(T^{2d-1})$ (where $T$ is the time horizon and $d$ the dimension of the
function domain). The algorithm is also shown to have order-optimal regret
performance (up to a poly-logarithmic factor). The basic structure of the
proposed algorithm is a tree-based \emph{localized} search strategy guided by a
localized optimization procedure for finding function values exceeding an
iteratively updated threshold. More specifically, the global optimum is
approached through a sequence of localized searches in the domain of the
function guided by an iterative search in the range of the function.
</p>
<a href="http://arxiv.org/abs/2010.13997" target="_blank">arXiv:2010.13997</a> [<a href="http://arxiv.org/pdf/2010.13997" target="_blank">pdf</a>]

<h2>Socially-Compatible Behavior Design of Autonomous Vehicles with Verification on Real Human Data. (arXiv:2010.14712v4 [cs.RO] UPDATED)</h2>
<h3>Letian Wang, Liting Sun, Masayoshi Tomizuka, Wei Zhan</h3>
<p>As more and more autonomous vehicles (AVs) are being deployed on public
roads, designing socially compatible behaviors for them is becoming
increasingly important. In order to generate safe and efficient actions, AVs
need to not only predict the future behaviors of other traffic participants,
but also be aware of the uncertainties associated with such behavior
prediction. In this paper, we propose an uncertain-aware integrated prediction
and planning (UAPP) framework. It allows the AVs to infer the characteristics
of other road users online and generate behaviors optimizing not only their own
rewards, but also their courtesy to others, and their confidence regarding the
prediction uncertainties. We first propose the definitions for courtesy and
confidence. Based on that, their influences on the behaviors of AVs in
interactive driving scenarios are explored. Moreover, we evaluate the proposed
algorithm on naturalistic human driving data by comparing the generated
behavior against ground truth. Results show that the online inference can
significantly improve the human-likeness of the generated behaviors.
Furthermore, we find that human drivers show great courtesy to others, even for
those without right-of-way. We also find that such driving preferences vary
significantly in different cultures.
</p>
<a href="http://arxiv.org/abs/2010.14712" target="_blank">arXiv:2010.14712</a> [<a href="http://arxiv.org/pdf/2010.14712" target="_blank">pdf</a>]

<h2>Machine versus Human Attention in Deep Reinforcement Learning Tasks. (arXiv:2010.15942v2 [cs.LG] UPDATED)</h2>
<h3>Ruohan Zhang, Sihang Guo, Bo Liu, Yifeng Zhu, Mary Hayhoe, Dana Ballard, Peter Stone</h3>
<p>Deep reinforcement learning (RL) algorithms are powerful tools for solving
visuomotor decision tasks. However, the trained models are often difficult to
interpret, because they are represented as end-to-end deep neural networks. In
this paper, we shed light on the inner workings of such trained models by
analyzing the pixels that they attend to during task execution, and comparing
them with the pixels attended to by humans executing the same tasks. To this
end, we investigate the following two questions that, to the best of our
knowledge, have not been previously studied. 1) How similar are the visual
features learned by RL agents and humans when performing the same task? and, 2)
How do similarities and differences in these learned features explain RL
agents' performance on these tasks? Specifically, we compare the saliency maps
of RL agents against visual attention models of human experts when learning to
play Atari games. Further, we analyze how hyperparameters of the deep RL
algorithm affect the learned features and saliency maps of the trained agents.
The insights provided by our results have the potential to inform novel
algorithms for the purpose of closing the performance gap between human experts
and deep RL agents.
</p>
<a href="http://arxiv.org/abs/2010.15942" target="_blank">arXiv:2010.15942</a> [<a href="http://arxiv.org/pdf/2010.15942" target="_blank">pdf</a>]

<h2>Learning Barrier Functions with Memory for Robust Safe Navigation. (arXiv:2011.01899v2 [cs.RO] UPDATED)</h2>
<h3>Kehan Long, Cheng Qian, Jorge Cort&#xe9;s, Nikolay Atanasov</h3>
<p>Control barrier functions are widely used to enforce safety properties in
robot motion planning and control. However, the problem of constructing barrier
functions online and synthesizing safe controllers that can deal with the
associated uncertainty has received little attention. This paper investigates
safe navigation in unknown environments, using onboard range sensing to
construct control barrier functions online. To represent different objects in
the environment, we use the distance measurements to train neural network
approximations of the signed distance functions incrementally with replay
memory. This allows us to formulate a novel robust control barrier safety
constraint which takes into account the error in the estimated distance fields
and its gradient. Our formulation leads to a second-order cone program,
enabling safe and stable control synthesis in a priori unknown environments.
</p>
<a href="http://arxiv.org/abs/2011.01899" target="_blank">arXiv:2011.01899</a> [<a href="http://arxiv.org/pdf/2011.01899" target="_blank">pdf</a>]

<h2>Exploring Contrastive Learning in Human Activity Recognition for Healthcare. (arXiv:2011.11542v3 [cs.LG] UPDATED)</h2>
<h3>Chi Ian Tang, Ignacio Perez-Pozuelo, Dimitris Spathis, Cecilia Mascolo</h3>
<p>Human Activity Recognition (HAR) constitutes one of the most important tasks
for wearable and mobile sensing given its implications in human well-being and
health monitoring. Motivated by the limitations of labeled datasets in HAR,
particularly when employed in healthcare-related applications, this work
explores the adoption and adaptation of SimCLR, a contrastive learning
technique for visual representations, to HAR. The use of contrastive learning
objectives causes the representations of corresponding views to be more
similar, and those of non-corresponding views to be more different. After an
extensive evaluation exploring 64 combinations of different signal
transformations for augmenting the data, we observed significant performance
differences owing to the order and the function thereof. In particular,
preliminary results indicated an improvement over supervised and unsupervised
learning methods when using fine-tuning and random rotation for augmentation,
however, future work should explore under which conditions SimCLR is beneficial
for HAR systems and other healthcare-related applications.
</p>
<a href="http://arxiv.org/abs/2011.11542" target="_blank">arXiv:2011.11542</a> [<a href="http://arxiv.org/pdf/2011.11542" target="_blank">pdf</a>]

<h2>A robust solution of a statistical inverse problem in multiscale computational mechanics using an artificial neural network. (arXiv:2011.11761v2 [cs.LG] UPDATED)</h2>
<h3>Florent Pled (MSME), Christophe Desceliers (MSME), Tianyu Zhang (MSME)</h3>
<p>This work addresses the inverse identification of apparent elastic properties
of random heterogeneous materials using machine learning based on artificial
neural networks. The proposed neural network-based identification method
requires the construction of a database from which an artificial neural network
can be trained to learn the nonlinear relationship between the hyperparameters
of a prior stochastic model of the random compliance field and some relevant
quantities of interest of an ad hoc multiscale computational model. An initial
database made up with input and target data is first generated from the
computational model, from which a processed database is deduced by conditioning
the input data with respect to the target data using the nonparametric
statistics. Two-and three-layer feedforward artificial neural networks are then
trained from each of the initial and processed databases to construct an
algebraic representation of the nonlinear mapping between the hyperparameters
(network outputs) and the quantities of interest (network inputs). The
performances of the trained artificial neural networks are analyzed in terms of
mean squared error, linear regression fit and probability distribution between
network outputs and targets for both databases. An ad hoc probabilistic model
of the input random vector is finally proposed in order to take into account
uncertainties on the network input and to perform a robustness analysis of the
network output with respect to the input uncertainties level. The capability of
the proposed neural network-based identification method to efficiently solve
the underlying statistical inverse problem is illustrated through two numerical
examples developed within the framework of 2D plane stress linear elasticity,
namely a first validation example on synthetic data obtained through
computational simulations and a second application example on real experimental
data obtained through a physical experiment monitored by digital image
correlation on a real heterogeneous biological material (beef cortical bone).
</p>
<a href="http://arxiv.org/abs/2011.11761" target="_blank">arXiv:2011.11761</a> [<a href="http://arxiv.org/pdf/2011.11761" target="_blank">pdf</a>]

<h2>Scale-covariant and scale-invariant Gaussian derivative networks. (arXiv:2011.14759v7 [cs.CV] UPDATED)</h2>
<h3>Tony Lindeberg</h3>
<p>This paper presents a hybrid approach between scale-space theory and deep
learning, where a deep learning architecture is constructed by coupling
parameterized scale-space operations in cascade. By sharing the learnt
parameters between multiple scale channels, and by using the transformation
properties of the scale-space primitives under scaling transformations, the
resulting network becomes provably scale covariant. By in addition performing
max pooling over the multiple scale channels, a resulting network architecture
for image classification also becomes provably scale invariant. We investigate
the performance of such networks on the MNISTLargeScale dataset, which contains
rescaled images from original MNIST over a factor of 4 concerning training data
and over a factor of 16 concerning testing data. It is demonstrated that the
resulting approach allows for scale generalization, enabling good performance
for classifying patterns at scales not present in the training data.
</p>
<a href="http://arxiv.org/abs/2011.14759" target="_blank">arXiv:2011.14759</a> [<a href="http://arxiv.org/pdf/2011.14759" target="_blank">pdf</a>]

<h2>A Hypergradient Approach to Robust Regression without Correspondence. (arXiv:2012.00123v2 [cs.LG] UPDATED)</h2>
<h3>Yujia Xie, Yixiu Mao, Simiao Zuo, Hongteng Xu, Xiaojing Ye, Tuo Zhao, Hongyuan Zha</h3>
<p>We consider a variant of regression problem, where the correspondence between
input and output data is not available. Such shuffled data is commonly observed
in many real world problems. Taking flow cytometry as an example, the measuring
instruments may not be able to maintain the correspondence between the samples
and the measurements. Due to the combinatorial nature of the problem, most
existing methods are only applicable when the sample size is small, and limited
to linear regression models. To overcome such bottlenecks, we propose a new
computational framework -- ROBOT -- for the shuffled regression problem, which
is applicable to large data and complex nonlinear models. Specifically, we
reformulate the regression without correspondence as a continuous optimization
problem. Then by exploiting the interaction between the regression model and
the data correspondence, we develop a hypergradient approach based on
differentiable programming techniques. Such a hypergradient approach
essentially views the data correspondence as an operator of the regression, and
therefore allows us to find a better descent direction for the model parameter
by differentiating through the data correspondence. ROBOT can be further
extended to the inexact correspondence setting, where there may not be an exact
alignment between the input and output data. Thorough numerical experiments
show that ROBOT achieves better performance than existing methods in both
linear and nonlinear regression tasks, including real-world applications such
as flow cytometry and multi-object tracking.
</p>
<a href="http://arxiv.org/abs/2012.00123" target="_blank">arXiv:2012.00123</a> [<a href="http://arxiv.org/pdf/2012.00123" target="_blank">pdf</a>]

<h2>An Empirical Study of Assumptions in Bayesian Optimisation. (arXiv:2012.03826v2 [cs.LG] UPDATED)</h2>
<h3>Alexander I. Cowen-Rivers, Wenlong Lyu, Rasul Tutunov, Zhi Wang, Antoine Grosnit, Ryan Rhys Griffiths, Hao Jianye, Jun Wang, Haitham Bou Ammar</h3>
<p>Inspired by the increasing desire to efficiently tune machine learning
hyper-parameters, in this work we rigorously analyse conventional and
non-conventional assumptions inherent to Bayesian optimisation. Across an
extensive set of experiments we conclude that: 1) the majority of
hyper-parameter tuning tasks exhibit heteroscedasticity and non-stationarity,
2) multi-objective acquisition ensembles with Pareto-front solutions
significantly improve queried configurations, and 3) robust acquisition
maximisation affords empirical advantages relative to its non-robust
counterparts. We hope these findings may serve as guiding principles, both for
practitioners and for further research in the field.
</p>
<a href="http://arxiv.org/abs/2012.03826" target="_blank">arXiv:2012.03826</a> [<a href="http://arxiv.org/pdf/2012.03826" target="_blank">pdf</a>]

<h2>Taming Transformers for High-Resolution Image Synthesis. (arXiv:2012.09841v2 [cs.CV] UPDATED)</h2>
<h3>Patrick Esser, Robin Rombach, Bj&#xf6;rn Ommer</h3>
<p>Designed to learn long-range interactions on sequential data, transformers
continue to show state-of-the-art results on a wide variety of tasks. In
contrast to CNNs, they contain no inductive bias that prioritizes local
interactions. This makes them expressive, but also computationally infeasible
for long sequences, such as high-resolution images. We demonstrate how
combining the effectiveness of the inductive bias of CNNs with the expressivity
of transformers enables them to model and thereby synthesize high-resolution
images. We show how to (i) use CNNs to learn a context-rich vocabulary of image
constituents, and in turn (ii) utilize transformers to efficiently model their
composition within high-resolution images. Our approach is readily applied to
conditional synthesis tasks, where both non-spatial information, such as object
classes, and spatial information, such as segmentations, can control the
generated image. In particular, we present the first results on
semantically-guided synthesis of megapixel images with transformers. Project
page at https://compvis.github.io/taming-transformers/ .
</p>
<a href="http://arxiv.org/abs/2012.09841" target="_blank">arXiv:2012.09841</a> [<a href="http://arxiv.org/pdf/2012.09841" target="_blank">pdf</a>]

<h2>APEX-Net: Automatic Plot Extractor Network. (arXiv:2101.06217v3 [cs.CV] UPDATED)</h2>
<h3>Aalok Gangopadhyay, Prajwal Singh, Shanmuganathan Raman</h3>
<p>Automatic extraction of raw data from 2D line plot images is a problem of
great importance having many real-world applications. Several algorithms have
been proposed for solving this problem. However, these algorithms involve a
significant amount of human intervention. To minimize this intervention, we
propose APEX-Net, a deep learning based framework with novel loss functions for
solving the plot extraction problem. We introduce APEX-1M, a new large scale
dataset which contains both the plot images and the raw data. We demonstrate
the performance of APEX-Net on the APEX-1M test set and show that it obtains
impressive accuracy. We also show visual results of our network on unseen plot
images and demonstrate that it extracts the shape of the plots to a great
extent. Finally, we develop a GUI based software for plot extraction that can
benefit the community at large. For dataset and more information visit
https://sites.google.com/view/apexnetpaper/.
</p>
<a href="http://arxiv.org/abs/2101.06217" target="_blank">arXiv:2101.06217</a> [<a href="http://arxiv.org/pdf/2101.06217" target="_blank">pdf</a>]

<h2>HDIB1M -- Handwritten Document Image Binarization 1 Million Dataset. (arXiv:2101.11674v2 [cs.CV] UPDATED)</h2>
<h3>Kaustubh Sadekar, Prajwal Singh, Shanmuganathan Raman</h3>
<p>Handwritten document image binarization is a challenging task due to high
diversity in the content, page style, and condition of the documents. While the
traditional thresholding methods fail to generalize on such challenging
scenarios, deep learning based methods can generalize well however, require a
large training data. Current datasets for handwritten document image
binarization are limited in size and fail to represent several challenging
real-world scenarios. To solve this problem, we propose HDIB1M - a handwritten
document image binarization dataset of 1M images. We also present a novel
method used to generate this dataset. To show the effectiveness of our dataset
we train a deep learning model UNetED on our dataset and evaluate its
performance on other publicly available datasets. The dataset and the code will
be made available to the community.
</p>
<a href="http://arxiv.org/abs/2101.11674" target="_blank">arXiv:2101.11674</a> [<a href="http://arxiv.org/pdf/2101.11674" target="_blank">pdf</a>]

<h2>Recent Advances in Adversarial Training for Adversarial Robustness. (arXiv:2102.01356v2 [cs.LG] UPDATED)</h2>
<h3>Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen</h3>
<p>Adversarial training is one of the most effective approaches defending
against adversarial examples for deep learning models. Unlike other defenses
that are limited to specific tasks, adversarial training is more general and
can be extended easily. However, adversarial training is not perfect, many
problems of which remain to be solved. During the last few years, adversarial
training is being studied and discussed from various aspects, and many
improvements and developments are proposed. In this survey, we systematically
review the recent progress on adversarial training with novel taxonomy for the
first time. Then we discuss the generalization problems in adversarial training
from three perspectives. Finally, we highlight the challenges which are not
fully solved and present potential future directions.
</p>
<a href="http://arxiv.org/abs/2102.01356" target="_blank">arXiv:2102.01356</a> [<a href="http://arxiv.org/pdf/2102.01356" target="_blank">pdf</a>]

<h2>Adversarial Attacks and Defenses in Physiological Computing: A Systematic Review. (arXiv:2102.02729v3 [cs.LG] UPDATED)</h2>
<h3>Dongrui Wu, Weili Fang, Yi Zhang, Liuqing Yang, Xiaodong Xu, Hanbin Luo, Xiang Yu</h3>
<p>Physiological computing uses human physiological data as system inputs in
real time. It includes, or significantly overlaps with, brain-computer
interfaces, affective computing, adaptive automation, health informatics, and
physiological signal based biometrics. Physiological computing increases the
communication bandwidth from the user to the computer, but is also subject to
various types of adversarial attacks, in which the attacker deliberately
manipulates the training and/or test examples to hijack the machine learning
algorithm output, leading to possibly user confusion, frustration, injury, or
even death. However, the vulnerability of physiological computing systems has
not been paid enough attention to, and there does not exist a comprehensive
review on adversarial attacks to it. This paper fills this gap, by providing a
systematic review on the main research areas of physiological computing,
different types of adversarial attacks and their applications to physiological
computing, and the corresponding defense strategies. We hope this review will
attract more research interests on the vulnerability of physiological computing
systems, and more importantly, defense strategies to make them more secure.
</p>
<a href="http://arxiv.org/abs/2102.02729" target="_blank">arXiv:2102.02729</a> [<a href="http://arxiv.org/pdf/2102.02729" target="_blank">pdf</a>]

<h2>Feedback in Imitation Learning: The Three Regimes of Covariate Shift. (arXiv:2102.02872v2 [cs.LG] UPDATED)</h2>
<h3>Jonathan Spencer, Sanjiban Choudhury, Arun Venkatraman, Brian Ziebart, J. Andrew Bagnell</h3>
<p>Imitation learning practitioners have often noted that conditioning policies
on previous actions leads to a dramatic divergence between "held out" error and
performance of the learner in situ. Interactive approaches can provably address
this divergence but require repeated querying of a demonstrator. Recent work
identifies this divergence as stemming from a "causal confound" in predicting
the current action, and seek to ablate causal aspects of current state using
tools from causal inference. In this work, we argue instead that this
divergence is simply another manifestation of covariate shift, exacerbated
particularly by settings of feedback between decisions and input features. The
learner often comes to rely on features that are strongly predictive of
decisions, but are subject to strong covariate shift.

Our work demonstrates a broad class of problems where this shift can be
mitigated, both theoretically and practically, by taking advantage of a
simulator but without any further querying of expert demonstration. We analyze
existing benchmarks used to test imitation learning approaches and find that
these benchmarks are realizable and simple and thus insufficient for capturing
the harder regimes of error compounding seen in real-world decision making
problems. We find, in a surprising contrast with previous literature, but
consistent with our theory, that naive behavioral cloning provides excellent
results. We detail the need for new standardized benchmarks that capture the
phenomena seen in robotics problems.
</p>
<a href="http://arxiv.org/abs/2102.02872" target="_blank">arXiv:2102.02872</a> [<a href="http://arxiv.org/pdf/2102.02872" target="_blank">pdf</a>]

<h2>Instance and Panoptic Segmentation Using Conditional Convolutions. (arXiv:2102.03026v2 [cs.CV] UPDATED)</h2>
<h3>Zhi Tian, Bowen Zhang, Hao Chen, Chunhua Shen</h3>
<p>We propose a simple yet effective framework for instance and panoptic
segmentation, termed CondInst (conditional convolutions for instance and
panoptic segmentation). In the literature, top-performing instance segmentation
methods typically follow the paradigm of Mask R-CNN and rely on ROI operations
(typically ROIAlign) to attend to each instance. In contrast, we propose to
attend to the instances with dynamic conditional convolutions. Instead of using
instance-wise ROIs as inputs to the instance mask head of fixed weights, we
design dynamic instance-aware mask heads, conditioned on the instances to be
predicted. CondInst enjoys three advantages: 1.) Instance and panoptic
segmentation are unified into a fully convolutional network, eliminating the
need for ROI cropping and feature alignment. 2.) The elimination of the ROI
cropping also significantly improves the output instance mask resolution. 3.)
Due to the much improved capacity of dynamically-generated conditional
convolutions, the mask head can be very compact (e.g., 3 conv. layers, each
having only 8 channels), leading to significantly faster inference time per
instance and making the overall inference time almost constant, irrelevant to
the number of instances. We demonstrate a simpler method that can achieve
improved accuracy and inference speed on both instance and panoptic
segmentation tasks. On the COCO dataset, we outperform a few state-of-the-art
methods. We hope that CondInst can be a strong baseline for instance and
panoptic segmentation. Code is available at: https://git.io/AdelaiDet
</p>
<a href="http://arxiv.org/abs/2102.03026" target="_blank">arXiv:2102.03026</a> [<a href="http://arxiv.org/pdf/2102.03026" target="_blank">pdf</a>]

<h2>Hyperparameter Optimization Is Deceiving Us, and How to Stop It. (arXiv:2102.03034v2 [cs.LG] UPDATED)</h2>
<h3>A. Feder Cooper, Yucheng Lu, Christopher De Sa</h3>
<p>While hyperparameter optimization (HPO) is known to greatly impact learning
algorithm performance, it is often treated as an empirical afterthought. Recent
empirical works have highlighted the risk of this second-rate treatment of HPO.
They show that inconsistent performance results, based on choice of
hyperparameter subspace to search, are a widespread problem in ML research.
When comparing two algorithms, J and K searching one subspace can yield the
conclusion that J outperforms K, whereas searching another can entail the
opposite result. In short, your choice of hyperparameters can deceive you. We
provide a theoretical complement to this prior work: We analytically
characterize this problem, which we term hyperparameter deception, and show
that grid search is inherently deceptive. We prove a defense with guarantees
against deception, and demonstrate a defense in practice.
</p>
<a href="http://arxiv.org/abs/2102.03034" target="_blank">arXiv:2102.03034</a> [<a href="http://arxiv.org/pdf/2102.03034" target="_blank">pdf</a>]

<h2>Bayesian multiscale deep generative model for the solution of high-dimensional inverse problems. (arXiv:2102.03169v2 [stat.ML] UPDATED)</h2>
<h3>Yingzhi Xia, Nicholas Zabaras</h3>
<p>Estimation of spatially-varying parameters for computationally expensive
forward models governed by partial differential equations is addressed. A novel
multiscale Bayesian inference approach is introduced based on deep
probabilistic generative models. Such generative models provide a flexible
representation by inferring on each scale a low-dimensional latent encoding
while allowing hierarchical parameter generation from coarse- to fine-scales.
Combining the multiscale generative model with Markov Chain Monte Carlo (MCMC),
inference across scales is achieved enabling us to efficiently obtain posterior
parameter samples at various scales. The estimation of coarse-scale parameters
using a low-dimensional latent embedding captures global and notable parameter
features using an inexpensive but inaccurate solver. MCMC sampling of the
fine-scale parameters is enabled by utilizing the posterior information in the
immediate coarser-scale. In this way, the global features are identified in the
coarse-scale with inference of low-dimensional variables and inexpensive
forward computation, and the local features are refined and corrected in the
fine-scale. The developed method is demonstrated with two types of permeability
estimation for flow in heterogeneous media. One is a Gaussian random field
(GRF) with uncertain length scales, and the other is channelized permeability
with the two regions defined by different GRFs. The obtained results indicate
that the method allows high-dimensional parameter estimation while exhibiting
stability, efficiency and accuracy.
</p>
<a href="http://arxiv.org/abs/2102.03169" target="_blank">arXiv:2102.03169</a> [<a href="http://arxiv.org/pdf/2102.03169" target="_blank">pdf</a>]

<h2>A Bayesian nonparametric approach to count-min sketch under power-law data streams. (arXiv:2102.03743v2 [stat.ML] UPDATED)</h2>
<h3>Emanuele Dolera, Stefano Favaro, Stefano Peluchetti</h3>
<p>The count-min sketch (CMS) is a randomized data structure that provides
estimates of tokens' frequencies in a large data stream using a compressed
representation of the data by random hashing. In this paper, we rely on a
recent Bayesian nonparametric (BNP) view on the CMS to develop a novel
learning-augmented CMS under power-law data streams. We assume that tokens in
the stream are drawn from an unknown discrete distribution, which is endowed
with a normalized inverse Gaussian process (NIGP) prior. Then, using
distributional properties of the NIGP, we compute the posterior distribution of
a token's frequency in the stream, given the hashed data, and in turn
corresponding BNP estimates. Applications to synthetic and real data show that
our approach achieves a remarkable performance in the estimation of
low-frequency tokens. This is known to be a desirable feature in the context of
natural language processing, where it is indeed common in the context of the
power-law behaviour of the data.
</p>
<a href="http://arxiv.org/abs/2102.03743" target="_blank">arXiv:2102.03743</a> [<a href="http://arxiv.org/pdf/2102.03743" target="_blank">pdf</a>]

<h2>Enabling Binary Neural Network Training on the Edge. (arXiv:2102.04270v2 [cs.LG] UPDATED)</h2>
<h3>Erwei Wang, James J. Davis, Daniele Moro, Piotr Zielinski, Claudionor Coelho, Satrajit Chatterjee, Peter Y. K. Cheung, George A. Constantinides</h3>
<p>The ever-growing computational demands of increasingly complex machine
learning models frequently necessitate the use of powerful cloud-based
infrastructure for their training. Binary neural networks are known to be
promising candidates for on-device inference due to their extreme compute and
memory savings over higher-precision alternatives. In this paper, we
demonstrate that they are also strongly robust to gradient quantization,
thereby making the training of modern models on the edge a practical reality.
We introduce a low-cost binary neural network training strategy exhibiting
sizable memory footprint reductions and energy savings vs Courbariaux &amp;
Bengio's standard approach. Against the latter, we see coincident memory
requirement and energy consumption drops of 2--6$\times$, while reaching
similar test accuracy in comparable time, across a range of small-scale models
trained to classify popular datasets. We also showcase ImageNet training of
ResNetE-18, achieving a 3.12$\times$ memory reduction over the aforementioned
standard. Such savings will allow for unnecessary cloud offloading to be
avoided, reducing latency, increasing energy efficiency and safeguarding
privacy.
</p>
<a href="http://arxiv.org/abs/2102.04270" target="_blank">arXiv:2102.04270</a> [<a href="http://arxiv.org/pdf/2102.04270" target="_blank">pdf</a>]

<h2>More Is More -- Narrowing the Generalization Gap by Adding Classification Heads. (arXiv:2102.04924v2 [cs.LG] UPDATED)</h2>
<h3>Roee Cates, Daphna Weinshall</h3>
<p>Overfit is a fundamental problem in machine learning in general, and in deep
learning in particular. In order to reduce overfit and improve generalization
in the classification of images, some employ invariance to a group of
transformations, such as rotations and reflections. However, since not all
objects exhibit necessarily the same invariance, it seems desirable to allow
the network to learn the useful level of invariance from the data. To this end,
motivated by self-supervision, we introduce an architecture enhancement for
existing neural network models based on input transformations, termed
'TransNet', together with a training algorithm suitable for it. Our model can
be employed during training time only and then pruned for prediction, resulting
in an equivalent architecture to the base model. Thus pruned, we show that our
model improves performance on various data-sets while exhibiting improved
generalization, which is achieved in turn by enforcing soft invariance on the
convolutional kernels of the last layer in the base model. Theoretical analysis
is provided to support the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.04924" target="_blank">arXiv:2102.04924</a> [<a href="http://arxiv.org/pdf/2102.04924" target="_blank">pdf</a>]

<h2>Toward Safe and Efficient Human-Robot Interaction via Behavior-Driven Danger Signaling. (arXiv:2102.05144v2 [cs.RO] UPDATED)</h2>
<h3>Mehdi Hosseinzadeh, Bruno Sinopoli, Aaron F. Bobick</h3>
<p>This paper introduces the notion of danger awareness in the context of
Human-Robot Interaction (HRI), which decodes whether a human is aware of the
existence of the robot, and illuminates whether the human is willing to engage
in enforcing the safety. This paper also proposes a method to quantify this
notion as a single binary variable, so-called danger awareness coefficient. By
analyzing the effect of this coefficient on the human's actions, an online
Bayesian learning method is proposed to update the belief about the value of
the coefficient. It is shown that based upon the danger awareness coefficient
and the proposed learning method, the robot can build a predictive human model
to anticipate the human's future actions. In order to create a communication
channel between the human and the robot, to enrich the observations and get
informative data about the human, and to improve the efficiency of the robot,
the robot is equipped with a danger signaling system. A predictive planning
scheme, coupled with the predictive human model, is also proposed to provide an
efficient and Probabilistically safe plan for the robot. The effectiveness of
the proposed scheme is demonstrated through simulation studies on an
interaction between a self-driving car and a pedestrian.
</p>
<a href="http://arxiv.org/abs/2102.05144" target="_blank">arXiv:2102.05144</a> [<a href="http://arxiv.org/pdf/2102.05144" target="_blank">pdf</a>]

<h2>Transfer learning based few-shot classification using optimal transport mapping from preprocessed latent space of backbone neural network. (arXiv:2102.05176v2 [cs.LG] UPDATED)</h2>
<h3>Tom&#xe1;&#x161; Chobola, Daniel Va&#x161;ata, Pavel Kord&#xed;k</h3>
<p>MetaDL Challenge 2020 focused on image classification tasks in few-shot
settings. This paper describes second best submission in the competition. Our
meta learning approach modifies the distribution of classes in a latent space
produced by a backbone network for each class in order to better follow the
Gaussian distribution. After this operation which we call Latent Space
Transform algorithm, centers of classes are further aligned in an iterative
fashion of the Expectation Maximisation algorithm to utilize information in
unlabeled data that are often provided on top of few labelled instances. For
this task, we utilize optimal transport mapping using the Sinkhorn algorithm.
Our experiments show that this approach outperforms previous works as well as
other variants of the algorithm, using K-Nearest Neighbour algorithm, Gaussian
Mixture Models, etc.
</p>
<a href="http://arxiv.org/abs/2102.05176" target="_blank">arXiv:2102.05176</a> [<a href="http://arxiv.org/pdf/2102.05176" target="_blank">pdf</a>]

<h2>Transfer Reinforcement Learning across Homotopy Classes. (arXiv:2102.05207v2 [cs.RO] UPDATED)</h2>
<h3>Zhangjie Cao, Minae Kwon, Dorsa Sadigh</h3>
<p>The ability for robots to transfer their learned knowledge to new tasks --
where data is scarce -- is a fundamental challenge for successful robot
learning. While fine-tuning has been well-studied as a simple but effective
transfer approach in the context of supervised learning, it is not as
well-explored in the context of reinforcement learning. In this work, we study
the problem of fine-tuning in transfer reinforcement learning when tasks are
parameterized by their reward functions, which are known beforehand. We
conjecture that fine-tuning drastically underperforms when source and target
trajectories are part of different homotopy classes. We demonstrate that
fine-tuning policy parameters across homotopy classes compared to fine-tuning
within a homotopy class requires more interaction with the environment, and in
certain cases is impossible. We propose a novel fine-tuning algorithm,
Ease-In-Ease-Out fine-tuning, that consists of a relaxing stage and a
curriculum learning stage to enable transfer learning across homotopy classes.
Finally, we evaluate our approach on several robotics-inspired simulated
environments and empirically verify that the Ease-In-Ease-Out fine-tuning
method can successfully fine-tune in a sample-efficient way compared to
existing baselines.
</p>
<a href="http://arxiv.org/abs/2102.05207" target="_blank">arXiv:2102.05207</a> [<a href="http://arxiv.org/pdf/2102.05207" target="_blank">pdf</a>]

<h2>Simple Agent, Complex Environment: Efficient Reinforcement Learning with Agent State. (arXiv:2102.05261v2 [cs.LG] UPDATED)</h2>
<h3>Shi Dong, Benjamin Van Roy, Zhengyuan Zhou</h3>
<p>We design a simple reinforcement learning agent that, with a specification
only of agent state dynamics and a reward function, can operate with some
degree of competence in any environment. The agent maintains only visitation
counts and value estimates for each agent-state-action pair. The value function
is updated incrementally in response to temporal differences and optimistic
boosts that encourage exploration. The agent executes actions that are greedy
with respect to this value function. We establish a regret bound demonstrating
convergence to near-optimal per-period performance, where the time taken to
achieve near-optimality is polynomial in the number of agent states and
actions, as well as the reward mixing time of the best policy within the
reference policy class, which is comprised of those that depend on history only
through agent state. Notably, there is no further dependence on the number of
environment states or mixing times associated with other policies or statistics
of history. Our result sheds light on the potential benefits of (deep)
representation learning, which has demonstrated the capability to extract
compact and relevant features from high-dimensional interaction histories.
</p>
<a href="http://arxiv.org/abs/2102.05261" target="_blank">arXiv:2102.05261</a> [<a href="http://arxiv.org/pdf/2102.05261" target="_blank">pdf</a>]

