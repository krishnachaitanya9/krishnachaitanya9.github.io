---
title: Latest Deep Learning Papers
date: 2021-02-05 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (129 Articles)</h1>
<h2>DEFT: Detection Embeddings for Tracking. (arXiv:2102.02267v1 [cs.CV])</h2>
<h3>Mohamed Chaabane, Peter Zhang, J. Ross Beveridge, Stephen O&#x27;Hara</h3>
<p>Most modern multiple object tracking (MOT) systems follow the
tracking-by-detection paradigm, consisting of a detector followed by a method
for associating detections into tracks. There is a long history in tracking of
combining motion and appearance features to provide robustness to occlusions
and other challenges, but typically this comes with the trade-off of a more
complex and slower implementation. Recent successes on popular 2D tracking
benchmarks indicate that top-scores can be achieved using a state-of-the-art
detector and relatively simple associations relying on single-frame spatial
offsets -- notably outperforming contemporary methods that leverage learned
appearance features to help re-identify lost tracks. In this paper, we propose
an efficient joint detection and tracking model named DEFT, or "Detection
Embeddings for Tracking." Our approach relies on an appearance-based object
matching network jointly-learned with an underlying object detection network.
An LSTM is also added to capture motion constraints. DEFT has comparable
accuracy and speed to the top methods on 2D online tracking leaderboards while
having significant advantages in robustness when applied to more challenging
tracking data. DEFT raises the bar on the nuScenes monocular 3D tracking
challenge, more than doubling the performance of the previous top method. Code
is publicly available.
</p>
<a href="http://arxiv.org/abs/2102.02267" target="_blank">arXiv:2102.02267</a> [<a href="http://arxiv.org/pdf/2102.02267" target="_blank">pdf</a>]

<h2>Neural Recursive Belief States in Multi-Agent Reinforcement Learning. (arXiv:2102.02274v1 [cs.LG])</h2>
<h3>Pol Moreno, Edward Hughes, Kevin R. McKee, Bernardo Avila Pires, Th&#xe9;ophane Weber</h3>
<p>In multi-agent reinforcement learning, the problem of learning to act is
particularly difficult because the policies of co-players may be heavily
conditioned on information only observed by them. On the other hand, humans
readily form beliefs about the knowledge possessed by their peers and leverage
beliefs to inform decision-making. Such abilities underlie individual success
in a wide range of Markov games, from bluffing in Poker to conditional
cooperation in the Prisoner's Dilemma, to convention-building in Bridge.
Classical methods are usually not applicable to complex domains due to the
intractable nature of hierarchical beliefs (i.e. beliefs of other agents'
beliefs). We propose a scalable method to approximate these belief structures
using recursive deep generative models, and to use the belief models to obtain
representations useful to acting in complex tasks. Our agents trained with
belief models outperform model-free baselines with equivalent representational
capacity using common training paradigms. We also show that higher-order belief
models outperform agents with lower-order models.
</p>
<a href="http://arxiv.org/abs/2102.02274" target="_blank">arXiv:2102.02274</a> [<a href="http://arxiv.org/pdf/2102.02274" target="_blank">pdf</a>]

<h2>Echo-SyncNet: Self-supervised Cardiac View Synchronization in Echocardiography. (arXiv:2102.02287v1 [cs.CV])</h2>
<h3>Fatemeh Taheri Dezaki, Christina Luong, Tom Ginsberg, Robert Rohling, Ken Gin, Purang Abolmaesumi, Teresa Tsang</h3>
<p>In echocardiography (echo), an electrocardiogram (ECG) is conventionally used
to temporally align different cardiac views for assessing critical
measurements. However, in emergencies or point-of-care situations, acquiring an
ECG is often not an option, hence motivating the need for alternative temporal
synchronization methods. Here, we propose Echo-SyncNet, a self-supervised
learning framework to synchronize various cross-sectional 2D echo series
without any external input. The proposed framework takes advantage of both
intra-view and inter-view self supervisions. The former relies on
spatiotemporal patterns found between the frames of a single echo cine and the
latter on the interdependencies between multiple cines. The combined
supervisions are used to learn a feature-rich embedding space where multiple
echo cines can be temporally synchronized. We evaluate the framework with
multiple experiments: 1) Using data from 998 patients, Echo-SyncNet shows
promising results for synchronizing Apical 2 chamber and Apical 4 chamber
cardiac views; 2) Using data from 3070 patients, our experiments reveal that
the learned representations of Echo-SyncNet outperform a supervised deep
learning method that is optimized for automatic detection of fine-grained
cardiac phase; 3) We show the usefulness of the learned representations in a
one-shot learning scenario of cardiac keyframe detection. Without any
fine-tuning, keyframes in 1188 validation patient studies are identified by
synchronizing them with only one labeled reference study. We do not make any
prior assumption about what specific cardiac views are used for training and
show that Echo-SyncNet can accurately generalize to views not present in its
training set. Project repository: github.com/fatemehtd/Echo-SyncNet.
</p>
<a href="http://arxiv.org/abs/2102.02287" target="_blank">arXiv:2102.02287</a> [<a href="http://arxiv.org/pdf/2102.02287" target="_blank">pdf</a>]

<h2>Nearest Neighbor-based Importance Weighting. (arXiv:2102.02291v1 [cs.LG])</h2>
<h3>Marco Loog</h3>
<p>Importance weighting is widely applicable in machine learning in general and
in techniques dealing with data covariate shift problems in particular. A
novel, direct approach to determine such importance weighting is presented. It
relies on a nearest neighbor classification scheme and is relatively
straightforward to implement. Comparative experiments on various classification
tasks demonstrate the effectiveness of our so-called nearest neighbor weighting
(NNeW) scheme. Considering its performance, our procedure can act as a simple
and effective baseline method for importance weighting.
</p>
<a href="http://arxiv.org/abs/2102.02291" target="_blank">arXiv:2102.02291</a> [<a href="http://arxiv.org/pdf/2102.02291" target="_blank">pdf</a>]

<h2>Predicting the probability distribution of bus travel time to move towards reliable planning of public transport services. (arXiv:2102.02292v1 [cs.LG])</h2>
<h3>L&#xe9;a Ricard, Guy Desaulniers, Andrea Lodi, Louis-Martin Rousseau</h3>
<p>An important aspect of the quality of a public transport service is its
reliability, which is defined as the invariability of the service attributes.
Preventive measures taken during planning can reduce risks of unreliability
throughout operations. In order to tackle reliability during the service
planning phase, a key piece of information is the long-term prediction of the
density of the travel time, which conveys the uncertainty of travel times. We
introduce a reliable approach to one of the problems of service planning in
public transport, namely the Multiple Depot Vehicle Scheduling Problem (MDVSP),
which takes as input a set of trips and the probability density function
(p.d.f.) of the travel time of each trip in order to output delay-tolerant
vehicle schedules. This work empirically compares probabilistic models for the
prediction of the conditional p.d.f. of the travel time, as a first step
towards reliable MDVSP solutions. Two types of probabilistic models, namely
similarity-based density estimation models and a smoothed Logistic Regression
for probabilistic classification model, are compared on a dataset of more than
41,000 trips and 50 bus routes of the city of Montr\'eal. The result of a vast
majority of probabilistic models outperforms that of a Random Forests model,
which is not inherently probabilistic, thus highlighting the added value of
modeling the conditional p.d.f. of the travel time with probabilistic models. A
similarity-based density estimation model using a $k$ Nearest Neighbors method
and a Kernel Density Estimation predicted the best estimate of the true
conditional p.d.f. on this dataset.
</p>
<a href="http://arxiv.org/abs/2102.02292" target="_blank">arXiv:2102.02292</a> [<a href="http://arxiv.org/pdf/2102.02292" target="_blank">pdf</a>]

<h2>Parallax estimation for push-frame satellite imagery: application to super-resolution and 3D surface modeling from Skysat products. (arXiv:2102.02301v1 [cs.CV])</h2>
<h3>J&#xe9;r&#xe9;my Anger, Thibaud Ehret, Gabriele Facciolo</h3>
<p>Recent constellations of satellites, including the Skysat constellation, are
able to acquire bursts of images. This new acquisition mode allows for modern
image restoration techniques, including multi-frame super-resolution. As the
satellite moves during the acquisition of the burst, elevation changes in the
scene translate into noticeable parallax. This parallax hinders the results of
the restoration. To cope with this issue, we propose a novel parallax
estimation method. The method is composed of a linear Plane+Parallax
decomposition of the apparent motion and a multi-frame optical flow algorithm
that exploits all frames simultaneously. Using SkySat L1A images, we show that
the estimated per-pixel displacements are important for applying multi-frame
super-resolution on scenes containing elevation changes and that can also be
used to estimate a coarse 3D surface model.
</p>
<a href="http://arxiv.org/abs/2102.02301" target="_blank">arXiv:2102.02301</a> [<a href="http://arxiv.org/pdf/2102.02301" target="_blank">pdf</a>]

<h2>Cleora: A Simple, Strong and Scalable Graph Embedding Scheme. (arXiv:2102.02302v1 [cs.LG])</h2>
<h3>Barbara Rychalska, Piotr B&#x105;bel, Konrad Go&#x142;uchowski, Andrzej Micha&#x142;owski, Jacek D&#x105;browski</h3>
<p>The area of graph embeddings is currently dominated by contrastive learning
methods, which demand formulation of an explicit objective function and
sampling of positive and negative examples. This creates a conceptual and
computational overhead. Simple, classic unsupervised approaches like
Multidimensional Scaling (MSD) or the Laplacian eigenmap skip the necessity of
tedious objective optimization, directly exploiting data geometry.
Unfortunately, their reliance on very costly operations such as matrix
eigendecomposition make them unable to scale to large graphs that are common in
today's digital world. In this paper we present Cleora: an algorithm which gets
the best of two worlds, being both unsupervised and highly scalable. We show
that high quality embeddings can be produced without the popular step-wise
learning framework with example sampling. An intuitive learning objective of
our algorithm is that a node should be similar to its neighbors, without
explicitly pushing disconnected nodes apart. The objective is achieved by
iterative weighted averaging of node neigbors' embeddings, followed by
normalization across dimensions. Thanks to the averaging operation the
algorithm makes rapid strides across the embedding space and usually reaches
optimal embeddings in just a few iterations. Cleora runs faster than other
state-of-the-art CPU algorithms and produces embeddings of competitive quality
as measured on downstream tasks: link prediction and node classification. We
show that Cleora learns a data abstraction that is similar to contrastive
methods, yet at much lower computational cost. We open-source Cleora under the
MIT license allowing commercial use under https://github.com/Synerise/cleora.
</p>
<a href="http://arxiv.org/abs/2102.02302" target="_blank">arXiv:2102.02302</a> [<a href="http://arxiv.org/pdf/2102.02302" target="_blank">pdf</a>]

<h2>Causal Sufficiency and Actual Causation. (arXiv:2102.02311v1 [cs.AI])</h2>
<h3>Sander Beckers</h3>
<p>Pearl opened the door to formally defining actual causation using causal
models. His approach rests on two strategies: first, capturing the widespread
intuition that X=x causes Y=y iff X=x is a Necessary Element of a Sufficient
Set for Y=y, and second, showing that his definition gives intuitive answers on
a wide set of problem cases. This inspired dozens of variations of his
definition of actual causation, the most prominent of which are due to Halpern
&amp; Pearl. Yet all of them ignore Pearl's first strategy, and the second strategy
taken by itself is unable to deliver a consensus. This paper offers a way out
by going back to the first strategy: it offers six formal definitions of causal
sufficiency and two interpretations of necessity. Combining the two gives
twelve new definitions of actual causation. Several interesting results about
these definitions and their relation to the various Halpern &amp; Pearl definitions
are presented. Afterwards the second strategy is evaluated as well. In order to
maximize neutrality, the paper relies mostly on the examples and intuitions of
Halpern &amp; Pearl. One definition comes out as being superior to all others, and
is therefore suggested as a new definition of actual causation.
</p>
<a href="http://arxiv.org/abs/2102.02311" target="_blank">arXiv:2102.02311</a> [<a href="http://arxiv.org/pdf/2102.02311" target="_blank">pdf</a>]

<h2>Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap Time Simulation Using Machine Learning. (arXiv:2102.02315v1 [cs.RO])</h2>
<h3>Sam Garlick, Andrew Bradley</h3>
<p>The widespread development of driverless vehicles has led to the formation of
autonomous racing competitions, where the high speeds and fierce rivalry in
motorsport provide a testbed to accelerate technology development. A particular
challenge for an autonomous vehicle is that of identifying a target trajectory
- or in the case of a racing car, the ideal racing line. Many existing
approaches to identifying the racing line are either not the time-optimal
solutions, or have solution times which are computationally expensive, thus
rendering them unsuitable for real-time application using on-board processing
hardware. This paper describes a machine learning approach to generating an
accurate prediction of the racing line in real-time on desktop processing
hardware. The proposed algorithm is a dense feed-forward neural network,
trained using a dataset comprising racing lines for a large number of circuits
calculated via a traditional optimal control lap time simulation. The network
is capable of predicting the racing line with a mean absolute error of
+/-0.27m, meaning that the accuracy outperforms a human driver, and is
comparable to other parts of the autonomous vehicle control system. The system
generates predictions within 33ms, making it over 9,000 times faster than
traditional methods of finding the optimal racing line. Results suggest that a
data-driven approach may therefore be favourable for real-time generation of
near-optimal racing lines than traditional computational methods.
</p>
<a href="http://arxiv.org/abs/2102.02315" target="_blank">arXiv:2102.02315</a> [<a href="http://arxiv.org/pdf/2102.02315" target="_blank">pdf</a>]

<h2>One Label, One Billion Faces: Usage and Consistency of Racial Categories in Computer Vision. (arXiv:2102.02320v1 [cs.CV])</h2>
<h3>Zaid Khan, Yun Fu</h3>
<p>Computer vision is widely deployed, has highly visible, society altering
applications, and documented problems with bias and representation. Datasets
are critical for benchmarking progress in fair computer vision, and often
employ broad racial categories as population groups for measuring group
fairness. Similarly, diversity is often measured in computer vision datasets by
ascribing and counting categorical race labels. However, racial categories are
ill-defined, unstable temporally and geographically, and have a problematic
history of scientific use. Although the racial categories used across datasets
are superficially similar, the complexity of human race perception suggests the
racial system encoded by one dataset may be substantially inconsistent with
another. Using the insight that a classifier can learn the racial system
encoded by a dataset, we conduct an empirical study of computer vision datasets
supplying categorical race labels for face images to determine the
cross-dataset consistency and generalization of racial categories. We find that
each dataset encodes a substantially unique racial system, despite nominally
equivalent racial categories, and some racial categories are systemically less
consistent than others across datasets. We find evidence that racial categories
encode stereotypes, and exclude ethnic groups from categories on the basis of
nonconformity to stereotypes. Representing a billion humans under one racial
category may obscure disparities and create new ones by encoding stereotypes of
racial systems. The difficulty of adequately converting the abstract concept of
race into a tool for measuring fairness underscores the need for a method more
flexible and culturally aware than racial categories.
</p>
<a href="http://arxiv.org/abs/2102.02320" target="_blank">arXiv:2102.02320</a> [<a href="http://arxiv.org/pdf/2102.02320" target="_blank">pdf</a>]

<h2>Query Complexity of Least Absolute Deviation Regression via Robust Uniform Convergence. (arXiv:2102.02322v1 [cs.LG])</h2>
<h3>Xue Chen, Micha&#x142; Derezi&#x144;ski</h3>
<p>Consider a regression problem where the learner is given a large collection
of $d$-dimensional data points, but can only query a small subset of the
real-valued labels. How many queries are needed to obtain a $1+\epsilon$
relative error approximation of the optimum? While this problem has been
extensively studied for least squares regression, little is known for other
losses. An important example is least absolute deviation regression ($\ell_1$
regression) which enjoys superior robustness to outliers compared to least
squares. We develop a new framework for analyzing importance sampling methods
in regression problems, which enables us to show that the query complexity of
least absolute deviation regression is $\Theta(d/\epsilon^2)$ up to logarithmic
factors. We further extend our techniques to show the first bounds on the query
complexity for any $\ell_p$ loss with $p\in(1,2)$. As a key novelty in our
analysis, we introduce the notion of robust uniform convergence, which is a new
approximation guarantee for the empirical loss. While it is inspired by uniform
convergence in statistical learning, our approach additionally incorporates a
correction term to avoid unnecessary variance due to outliers. This can be
viewed as a new connection between statistical learning theory and variance
reduction techniques in stochastic optimization, which should be of independent
interest.
</p>
<a href="http://arxiv.org/abs/2102.02322" target="_blank">arXiv:2102.02322</a> [<a href="http://arxiv.org/pdf/2102.02322" target="_blank">pdf</a>]

<h2>Effects of Number of Filters of Convolutional Layers on Speech Recognition Model Accuracy. (arXiv:2102.02326v1 [cs.LG])</h2>
<h3>James Mou, Jun Li</h3>
<p>Inspired by the progress of the End-to-End approach [1], this paper
systematically studies the effects of Number of Filters of convolutional layers
on the model prediction accuracy of CNN+RNN (Convolutional Neural Networks
adding to Recurrent Neural Networks) for ASR Models (Automatic Speech
Recognition). Experimental results show that only when the CNN Number of
Filters exceeds a certain threshold value is adding CNN to RNN able to improve
the performance of the CNN+RNN speech recognition model, otherwise some
parameter ranges of CNN can render it useless to add the CNN to the RNN model.
Our results show a strong dependency of word accuracy on the Number of Filters
of convolutional layers. Based on the experimental results, the paper suggests
a possible hypothesis of Sound-2-Vector Embedding (Convolutional Embedding) to
explain the above observations.

Based on this Embedding hypothesis and the optimization of parameters, the
paper develops an End-to-End speech recognition system which has a high word
accuracy but also has a light model-weight. The developed LVCSR (Large
Vocabulary Continuous Speech Recognition) model has achieved quite a high word
accuracy of 90.2% only by its Acoustic Model alone, without any assistance from
intermediate phonetic representation and any Language Model. Its acoustic model
contains only 4.4 million weight parameters, compared to the 35~68 million
acoustic-model weight parameters in DeepSpeech2 [2] (one of the top
state-of-the-art LVCSR models) which can achieve a word accuracy of 91.5%. The
light-weighted model is good for improving the transcribing computing
efficiency and also useful for mobile devices, Driverless Vehicles, etc. Our
model weight is reduced to ~10% the size of DeepSpeech2, but our model accuracy
remains close to that of DeepSpeech2. If combined with a Language Model, our
LVCSR system is able to achieve 91.5% word accuracy.
</p>
<a href="http://arxiv.org/abs/2102.02326" target="_blank">arXiv:2102.02326</a> [<a href="http://arxiv.org/pdf/2102.02326" target="_blank">pdf</a>]

<h2>Modeling Complex Financial Products. (arXiv:2102.02329v1 [cs.LG])</h2>
<h3>Margret Bjarnadottir, Louiqa Raschid</h3>
<p>The objective of this paper is to explore how financial big data and machine
learning methods can be applied to model and understand complex financial
products. We focus on residential mortgage backed securities, resMBS, that were
at the heart of the 2008 US financial crisis. The securities are contained
within a prospectus and have a complex payoff structure. Multiple financial
institutions form a supply chain to create the prospectuses. We provide insight
into the performance of the resMBS securities through a series of increasingly
complex models. First, models at the security level directly identify salient
features of resMBS securities that impact their performance. Second, we extend
the model to include prospectus level features. We are the first to demonstrate
that the composition of the prospectus is associated with the performance of
securities. Finally, to develop a deeper understanding of the role of the
supply chain, we use unsupervised probabilistic methods, in particular, dynamic
topics models (DTM), to understand community formation and temporal evolution
along the chain. A comprehensive model provides insight into the impact of DTM
communities on the issuance and evolution of prospectuses, and eventually the
performance of resMBS securities.
</p>
<a href="http://arxiv.org/abs/2102.02329" target="_blank">arXiv:2102.02329</a> [<a href="http://arxiv.org/pdf/2102.02329" target="_blank">pdf</a>]

<h2>On the Approximation Power of Two-Layer Networks of Random ReLUs. (arXiv:2102.02336v1 [cs.LG])</h2>
<h3>Daniel Hsu, Clayton Sanford, Rocco A. Servedio, Emmanouil-Vasileios Vlatakis-Gkaragkounis</h3>
<p>This paper considers the following question: how well can depth-two ReLU
networks with randomly initialized bottom-level weights represent smooth
functions? We give near-matching upper- and lower-bounds for
$L_2$-approximation in terms of the Lipschitz constant, the desired accuracy,
and the dimension of the problem, as well as similar results in terms of
Sobolev norms. Our positive results employ tools from harmonic analysis and
ridgelet representation theory, while our lower-bounds are based on (robust
versions of) dimensionality arguments.
</p>
<a href="http://arxiv.org/abs/2102.02336" target="_blank">arXiv:2102.02336</a> [<a href="http://arxiv.org/pdf/2102.02336" target="_blank">pdf</a>]

<h2>Environment Predictive Coding for Embodied Agents. (arXiv:2102.02337v1 [cs.CV])</h2>
<h3>Santhosh K. Ramakrishnan, Tushar Nagarajan, Ziad Al-Halah, Kristen Grauman</h3>
<p>We introduce environment predictive coding, a self-supervised approach to
learn environment-level representations for embodied agents. In contrast to
prior work on self-supervised learning for images, we aim to jointly encode a
series of images gathered by an agent as it moves about in 3D environments. We
learn these representations via a zone prediction task, where we intelligently
mask out portions of an agent's trajectory and predict them from the unmasked
portions, conditioned on the agent's camera poses. By learning such
representations on a collection of videos, we demonstrate successful transfer
to multiple downstream navigation-oriented tasks. Our experiments on the
photorealistic 3D environments of Gibson and Matterport3D show that our method
outperforms the state-of-the-art on challenging tasks with only a limited
budget of experience.
</p>
<a href="http://arxiv.org/abs/2102.02337" target="_blank">arXiv:2102.02337</a> [<a href="http://arxiv.org/pdf/2102.02337" target="_blank">pdf</a>]

<h2>MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records. (arXiv:2102.02340v1 [cs.LG])</h2>
<h3>Zhen Xu, David R. So, Andrew M. Dai</h3>
<p>One important challenge of applying deep learning to electronic health
records (EHR) is the complexity of their multimodal structure. EHR usually
contains a mixture of structured (codes) and unstructured (free-text) data with
sparse and irregular longitudinal features -- all of which doctors utilize when
making decisions. In the deep learning regime, determining how different
modality representations should be fused together is a difficult problem, which
is often addressed by handcrafted modeling and intuition. In this work, we
extend state-of-the-art neural architecture search (NAS) methods and propose
MUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across
multimodal fusion strategies and modality-specific architectures for the first
time. We demonstrate empirically that our MUFASA method outperforms established
unimodal NAS on public EHR data with comparable computation costs. In addition,
MUFASA produces architectures that outperform Transformer and Evolved
Transformer. Compared with these baselines on CCS diagnosis code prediction,
our discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate
the ability to generalize to other EHR tasks. Studying our top architecture in
depth, we provide empirical evidence that MUFASA's improvements are derived
from its ability to both customize modeling for each data modality and find
effective fusion strategies.
</p>
<a href="http://arxiv.org/abs/2102.02340" target="_blank">arXiv:2102.02340</a> [<a href="http://arxiv.org/pdf/2102.02340" target="_blank">pdf</a>]

<h2>Horizontally Fused Training Array: An Effective Hardware Utilization Squeezer for Training Novel Deep Learning Models. (arXiv:2102.02344v1 [cs.LG])</h2>
<h3>Shang Wang, Peiming Yang, Yuxuan Zheng, Xin Li, Gennady Pekhimenko</h3>
<p>Driven by the tremendous effort in researching novel deep learning (DL)
algorithms, the training cost of developing new models increases staggeringly
in recent years. To reduce this training cost and optimize the cluster-wide
hardware resource usage, we analyze GPU cluster usage statistics from a
well-known research institute. Our study reveals that single-accelerator
training jobs can dominate the cluster-wide resource consumption when launched
repetitively (e.g., for hyper-parameter tuning) while severely underutilizing
the hardware. This is because DL researchers and practitioners often lack the
required expertise to independently optimize their own workloads. Fortunately,
we observe that such workloads have the following unique characteristics: (i)
the models among jobs often have the same types of operators with the same
shapes, and (ii) the inter-model horizontal fusion of such operators is
mathematically equivalent to other already well-optimized operators. Thus, to
help DL researchers and practitioners effectively and easily improve the
hardware utilization of their novel DL training workloads, we propose
Horizontally Fused Training Array (HFTA). HFTA is a new DL framework extension
library that horizontally fuses the models from different repetitive jobs
deeply down to operators, and then trains those models simultaneously on a
shared accelerator. On three emerging DL training workloads and
state-of-the-art accelerators (GPUs and TPUs), HFTA demonstrates strong
effectiveness in squeezing out hardware utilization and achieves up to $15.1
\times$ higher training throughput vs. the standard practice of running each
job on a separate accelerator.
</p>
<a href="http://arxiv.org/abs/2102.02344" target="_blank">arXiv:2102.02344</a> [<a href="http://arxiv.org/pdf/2102.02344" target="_blank">pdf</a>]

<h2>On Multi-Human Multi-Robot Remote Interaction: A Study of Transparency, Inter-Human Communication, and Information Loss in Remote Interaction. (arXiv:2102.02351v1 [cs.RO])</h2>
<h3>Jayam Patel, Prajankya Sonar, Carlo Pinciroli</h3>
<p>In this paper, we investigate how to design an effective interface for remote
multi-human multi-robot interaction. While significant research exists on
interfaces for individual human operators, little research exists for the
multi-human case. Yet, this is a critical problem to solve to make complex,
large-scale missions achievable in which direct human involvement is impossible
or undesirable, and robot swarms act as a semi-autonomous agents. This paper's
contribution is twofold. The first contribution is an exploration of the design
space of computer-based interfaces for multi-human multi-robot operations. In
particular, we focus on information transparency and on the factors that affect
inter-human communication in ideal conditions, i.e., without communication
issues. Our second contribution concerns the same problem, but considering
increasing degrees of information loss, defined as intermittent reception of
data with noticeable gaps between individual receipts. We derived a set of
design recommendations based on two user studies involving 48 participants.
</p>
<a href="http://arxiv.org/abs/2102.02351" target="_blank">arXiv:2102.02351</a> [<a href="http://arxiv.org/pdf/2102.02351" target="_blank">pdf</a>]

<h2>MeInGame: Create a Game Character Face from a Single Portrait. (arXiv:2102.02371v1 [cs.CV])</h2>
<h3>Jiangke Lin, Yi Yuan, Zhengxia Zou</h3>
<p>Many deep learning based 3D face reconstruction methods have been proposed
recently, however, few of them have applications in games. Current game
character customization systems either require players to manually adjust
considerable face attributes to obtain the desired face, or have limited
freedom of facial shape and texture. In this paper, we propose an automatic
character face creation method that predicts both facial shape and texture from
a single portrait, and it can be integrated into most existing 3D games.
Although 3D Morphable Face Model (3DMM) based methods can restore accurate 3D
faces from single images, the topology of 3DMM mesh is different from the
meshes used in most games. To acquire fidelity texture, existing methods
require a large amount of face texture data for training, while building such
datasets is time-consuming and laborious. Besides, such a dataset collected
under laboratory conditions may not generalized well to in-the-wild situations.
To tackle these problems, we propose 1) a low-cost facial texture acquisition
method, 2) a shape transfer algorithm that can transform the shape of a 3DMM
mesh to games, and 3) a new pipeline for training 3D game face reconstruction
networks. The proposed method not only can produce detailed and vivid game
characters similar to the input portrait, but can also eliminate the influence
of lighting and occlusions. Experiments show that our method outperforms
state-of-the-art methods used in games.
</p>
<a href="http://arxiv.org/abs/2102.02371" target="_blank">arXiv:2102.02371</a> [<a href="http://arxiv.org/pdf/2102.02371" target="_blank">pdf</a>]

<h2>Sampling in Combinatorial Spaces with SurVAE Flow Augmented MCMC. (arXiv:2102.02374v1 [cs.LG])</h2>
<h3>Priyank Jaini, Didrik Nielsen, Max Welling</h3>
<p>Hybrid Monte Carlo is a powerful Markov Chain Monte Carlo method for sampling
from complex continuous distributions. However, a major limitation of HMC is
its inability to be applied to discrete domains due to the lack of gradient
signal. In this work, we introduce a new approach based on augmenting Monte
Carlo methods with SurVAE Flows to sample from discrete distributions using a
combination of neural transport methods like normalizing flows and variational
dequantization, and the Metropolis-Hastings rule. Our method first learns a
continuous embedding of the discrete space using a surjective map and
subsequently learns a bijective transformation from the continuous space to an
approximately Gaussian distributed latent variable. Sampling proceeds by
simulating MCMC chains in the latent space and mapping these samples to the
target discrete space via the learned transformations. We demonstrate the
efficacy of our algorithm on a range of examples from statistics, computational
physics and machine learning, and observe improvements compared to alternative
algorithms.
</p>
<a href="http://arxiv.org/abs/2102.02374" target="_blank">arXiv:2102.02374</a> [<a href="http://arxiv.org/pdf/2102.02374" target="_blank">pdf</a>]

<h2>A survey of motion planning algorithms for intelligent robotics. (arXiv:2102.02376v1 [cs.RO])</h2>
<h3>Chengmin Zhou, Bingding Huang, Pasi Fr&#xe4;nti</h3>
<p>We investigate and analyze principles of typical motion planning algorithms.
These include traditional planning algorithms, supervised learning, optimal
value reinforcement learning, policy gradient reinforcement learning.
Traditional planning algorithms we investigated include graph search
algorithms, sampling-based algorithms, and interpolating curve algorithms.
Supervised learning algorithms include MSVM, LSTM, MCTS and CNN. Optimal value
reinforcement learning algorithms include Q learning, DQN, double DQN, dueling
DQN. Policy gradient algorithms include policy gradient method, actor-critic
algorithm, A3C, A2C, DPG, DDPG, TRPO and PPO. New general criteria are also
introduced to evaluate performance and application of motion planning
algorithms by analytical comparisons. Convergence speed and stability of
optimal value and policy gradient algorithms are specially analyzed. Future
directions are presented analytically according to principles and analytical
comparisons of motion planning algorithms. This paper provides researchers with
a clear and comprehensive understanding about advantages, disadvantages,
relationships, and future of motion planning algorithms in robotics, and paves
ways for better motion planning algorithms.
</p>
<a href="http://arxiv.org/abs/2102.02376" target="_blank">arXiv:2102.02376</a> [<a href="http://arxiv.org/pdf/2102.02376" target="_blank">pdf</a>]

<h2>A Possible Artificial Intelligence Ecosystem Avatar: the Moorea case (IDEA). (arXiv:2102.02384v1 [cs.AI])</h2>
<h3>Jean-Pierre Barriot, Neil Davies, Beno&#xee;t Stoll, S&#xe9;bastien Chabrier, Alban Gabillon</h3>
<p>High-throughput data collection techniques and largescale (cloud) computing
are transforming our understanding of ecosystems at all scales by allowing the
integration of multimodal data such as physics, chemistry, biology, ecology,
fishing, economics and other social sciences in a common computational
framework. We focus in this paper on a large scale data assimilation and
prediction backbone based on Deep Stacking Networks (DSN) in the frame of the
IDEA (Island Digital Ecosystem Avatars) project (Moorea Island), based on the
subdivision of the island in watersheds and lagoon units. We also describe
several kinds of raw data that can train and constrain such an ecosystem avatar
model, as well as second level data such as ecological or physical indexes /
indicators.
</p>
<a href="http://arxiv.org/abs/2102.02384" target="_blank">arXiv:2102.02384</a> [<a href="http://arxiv.org/pdf/2102.02384" target="_blank">pdf</a>]

<h2>Provably End-to-end Label-Noise Learning without Anchor Points. (arXiv:2102.02400v1 [cs.LG])</h2>
<h3>Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, Masashi Sugiyama</h3>
<p>In label-noise learning, the transition matrix plays a key role in building
statistically consistent classifiers. Existing consistent estimators for the
transition matrix have been developed by exploiting anchor points. However, the
anchor-point assumption is not always satisfied in real scenarios. In this
paper, we propose an end-to-end framework for solving label-noise learning
without anchor points, in which we simultaneously minimize two objectives: the
discrepancy between the distribution learned by the neural network and the
noisy class-posterior distribution, and the volume of the simplex formed by the
columns of the transition matrix. Our proposed framework can identify the
transition matrix if the clean class-posterior probabilities are sufficiently
scattered. This is by far the mildest assumption under which the transition
matrix is provably identifiable and the learned classifier is statistically
consistent. Experimental results on benchmark datasets demonstrate the
effectiveness and robustness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.02400" target="_blank">arXiv:2102.02400</a> [<a href="http://arxiv.org/pdf/2102.02400" target="_blank">pdf</a>]

<h2>A Local Convergence Theory for Mildly Over-Parameterized Two-Layer Neural Network. (arXiv:2102.02410v1 [cs.LG])</h2>
<h3>Mo Zhou, Rong Ge, Chi Jin</h3>
<p>While over-parameterization is widely believed to be crucial for the success
of optimization for the neural networks, most existing theories on
over-parameterization do not fully explain the reason -- they either work in
the Neural Tangent Kernel regime where neurons don't move much, or require an
enormous number of neurons. In practice, when the data is generated using a
teacher neural network, even mildly over-parameterized neural networks can
achieve 0 loss and recover the directions of teacher neurons. In this paper we
develop a local convergence theory for mildly over-parameterized two-layer
neural net. We show that as long as the loss is already lower than a threshold
(polynomial in relevant parameters), all student neurons in an
over-parameterized two-layer neural network will converge to one of teacher
neurons, and the loss will go to 0. Our result holds for any number of student
neurons as long as it is at least as large as the number of teacher neurons,
and our convergence rate is independent of the number of student neurons. A key
component of our analysis is the new characterization of local optimization
landscape -- we show the gradient satisfies a special case of Lojasiewicz
property which is different from local strong convexity or PL conditions used
in previous work.
</p>
<a href="http://arxiv.org/abs/2102.02410" target="_blank">arXiv:2102.02410</a> [<a href="http://arxiv.org/pdf/2102.02410" target="_blank">pdf</a>]

<h2>Learning Noise Transition Matrix from Only Noisy Labels via Total Variation Regularization. (arXiv:2102.02414v1 [stat.ML])</h2>
<h3>Yivan Zhang, Gang Niu, Masashi Sugiyama</h3>
<p>Many weakly supervised classification methods employ a noise transition
matrix to capture the class-conditional label corruption. To estimate the
transition matrix from noisy data, existing methods often need to estimate the
noisy class-posterior, which could be unreliable due to the overconfidence of
neural networks. In this work, we propose a theoretically grounded method that
can estimate the noise transition matrix and learn a classifier simultaneously,
without relying on the error-prone noisy class-posterior estimation.
Concretely, inspired by the characteristics of the stochastic label corruption
process, we propose total variation regularization, which encourages the
predicted probabilities to be more distinguishable from each other. Under mild
assumptions, the proposed method yields a consistent estimator of the
transition matrix. We show the effectiveness of the proposed method through
experiments on benchmark and real-world datasets.
</p>
<a href="http://arxiv.org/abs/2102.02414" target="_blank">arXiv:2102.02414</a> [<a href="http://arxiv.org/pdf/2102.02414" target="_blank">pdf</a>]

<h2>Graph Coding for Model Selection and Anomaly Detection in Gaussian Graphical Models. (arXiv:2102.02431v1 [cs.LG])</h2>
<h3>Mojtaba Abolfazli, Anders Host-Madsen, June Zhang, Andras Bratincsak</h3>
<p>A classic application of description length is for model selection with the
minimum description length (MDL) principle. The focus of this paper is to
extend description length for data analysis beyond simple model selection and
sequences of scalars. More specifically, we extend the description length for
data analysis in Gaussian graphical models. These are powerful tools to model
interactions among variables in a sequence of i.i.d Gaussian data in the form
of a graph. Our method uses universal graph coding methods to accurately
account for model complexity, and therefore provide a more rigorous approach
for graph model selection. The developed method is tested with synthetic and
electrocardiogram (ECG) data to find the graph model and anomaly in Gaussian
graphical models. The experiments show that our method gives better performance
compared to commonly used methods.
</p>
<a href="http://arxiv.org/abs/2102.02431" target="_blank">arXiv:2102.02431</a> [<a href="http://arxiv.org/pdf/2102.02431" target="_blank">pdf</a>]

<h2>Towards Decentralized Human-Swarm Interaction by Means of Sequential Hand Gesture Recognition. (arXiv:2102.02439v1 [cs.RO])</h2>
<h3>Zahi Kakish, Sritanay Vedartham, Spring Berman</h3>
<p>In this work, we present preliminary work on a novel method for Human-Swarm
Interaction (HSI) that can be used to change the macroscopic behavior of a
swarm of robots with decentralized sensing and control. By integrating a small
yet capable hand gesture recognition convolutional neural network (CNN) with
the next-generation Robot Operating System \emph{ros2}, which enables
decentralized implementation of robot software for multi-robot applications, we
demonstrate the feasibility of programming a swarm of robots to recognize and
respond to a sequence of hand gestures that capable of correspond to different
types of swarm behaviors. We test our approach using a sequence of gestures
that modifies the target inter-robot distance in a group of three Turtlebot3
Burger robots in order to prevent robot collisions with obstacles. The approach
is validated in three different Gazebo simulation environments and in a
physical testbed that reproduces one of the simulated environments.
</p>
<a href="http://arxiv.org/abs/2102.02439" target="_blank">arXiv:2102.02439</a> [<a href="http://arxiv.org/pdf/2102.02439" target="_blank">pdf</a>]

<h2>Persistent Rule-based Interactive Reinforcement Learning. (arXiv:2102.02441v1 [cs.AI])</h2>
<h3>Adam Bignold, Francisco Cruz, Richard Dazeley, Peter Vamplew, Cameron Foale</h3>
<p>Interactive reinforcement learning has allowed speeding up the learning
process in autonomous agents by including a human trainer providing extra
information to the agent in real-time. Current interactive reinforcement
learning research has been limited to interactions that offer relevant advice
to the current state only. Additionally, the information provided by each
interaction is not retained and instead discarded by the agent after a
single-use. In this work, we propose a persistent rule-based interactive
reinforcement learning approach, i.e., a method for retaining and reusing
provided knowledge, allowing trainers to give general advice relevant to more
than just the current state. Our experimental results show persistent advice
substantially improves the performance of the agent while reducing the number
of interactions required for the trainer. Moreover, rule-based advice shows
similar performance impact as state-based advice, but with a substantially
reduced interaction count.
</p>
<a href="http://arxiv.org/abs/2102.02441" target="_blank">arXiv:2102.02441</a> [<a href="http://arxiv.org/pdf/2102.02441" target="_blank">pdf</a>]

<h2>The Analysis from Nonlinear Distance Metric to Kernel-based Drug Prescription Prediction System. (arXiv:2102.02446v1 [cs.LG])</h2>
<h3>Der-Chen Chang, Ophir Frieder, Chi-Feng Hung, Hao-Ren Yao</h3>
<p>Distance metrics and their nonlinear variant play a crucial role in machine
learning based real-world problem solving. We demonstrated how Euclidean and
cosine distance measures differ not only theoretically but also in real-world
medical application, namely, outcome prediction of drug prescription. Euclidean
distance exhibits favorable properties in the local geometry problem. To this
regard, Euclidean distance can be applied under short-term disease with
low-variation outcome observation. Moreover, when presenting to highly variant
chronic disease, it is preferable to use cosine distance. These different
geometric properties lead to different submanifolds in the original embedded
space, and hence, to different optimizing nonlinear kernel embedding
frameworks. We first established the geometric properties that we needed in
these frameworks. From these properties interpreted their differences in
certain perspectives. Our evaluation on real-world, large-scale electronic
health records and embedding space visualization empirically validated our
approach.
</p>
<a href="http://arxiv.org/abs/2102.02446" target="_blank">arXiv:2102.02446</a> [<a href="http://arxiv.org/pdf/2102.02446" target="_blank">pdf</a>]

<h2>Hybrid Adversarial Inverse Reinforcement Learning. (arXiv:2102.02454v1 [cs.LG])</h2>
<h3>Mingqi Yuan, Man-On Pun, Yi Chen, Qi Cao</h3>
<p>In this paper, we investigate the problem of the inverse reinforcement
learning (IRL), especially the beyond-demonstrator (BD) IRL. The BD-IRL aims to
not only imitate the expert policy but also extrapolate BD policy based on
finite demonstrations of the expert. Currently, most of the BD-IRL algorithms
are two-stage, which first infer a reward function then learn the policy via
reinforcement learning (RL). Because of the two separate procedures, the
two-stage algorithms have high computation complexity and lack robustness. To
overcome these flaw, we propose a BD-IRL framework entitled hybrid adversarial
inverse reinforcement learning (HAIRL), which successfully integrates the
imitation and exploration into one procedure. The simulation results show that
the HAIRL is more efficient and robust when compared with other similar
state-of-the-art (SOTA) algorithms.
</p>
<a href="http://arxiv.org/abs/2102.02454" target="_blank">arXiv:2102.02454</a> [<a href="http://arxiv.org/pdf/2102.02454" target="_blank">pdf</a>]

<h2>Deep Face Fuzzy Vault: Implementation and Performance. (arXiv:2102.02458v1 [cs.CV])</h2>
<h3>Christian Rathgeb, Johannes Merkle, Johanna Scholz, Benjamin Tams, Vanessa Nesterowicz</h3>
<p>Deep convolutional neural networks have achieved remarkable improvements in
facial recognition performance. Similar kinds of developments, e.g.
deconvolutional neural networks, have shown impressive results for
reconstructing face images from their corresponding embeddings in the latent
space. This poses a severe security risk which necessitates the protection of
stored deep face embeddings in order to prevent from misuse, e.g. identity
fraud.

In this work, an unlinkable improved deep face fuzzy vault-based template
protection scheme is presented. To this end, a feature transformation method is
introduced which maps fixed-length real-valued deep face embeddings to
integer-valued feature sets. As part of said feature transformation, a detailed
analysis of different feature quantisation and binarisation techniques is
conducted using features extracted with a state-of-the-art deep convolutional
neural network trained with the additive angular margin loss (ArcFace). At key
binding, obtained feature sets are locked in an unlinkable improved fuzzy
vault. For key retrieval, the efficiency of different polynomial reconstruction
techniques is investigated. The proposed feature transformation method and
template protection scheme are agnostic of the biometric characteristic and,
thus, can be applied to virtually any biometric features computed by a deep
neural network.

For the best configuration, a false non-match rate below 1% at a false match
rate of 0.01%, is achieved in cross-database experiments on the FERET and
FRGCv2 face databases. On average, a security level of up to approximately 28
bits is obtained. This work presents the first effective face-based fuzzy vault
scheme providing privacy protection of facial reference data as well as digital
key derivation from face.
</p>
<a href="http://arxiv.org/abs/2102.02458" target="_blank">arXiv:2102.02458</a> [<a href="http://arxiv.org/pdf/2102.02458" target="_blank">pdf</a>]

<h2>Machine Learning-Based Generalized Model for Finite Element Analysis of Roll Deflection During the Austenitic Stainless Steel 316L Strip Rolling. (arXiv:2102.02470v1 [cs.LG])</h2>
<h3>Mahshad Lotfinia, Soroosh Tayebi Arasteh</h3>
<p>During the strip rolling process, a considerable amount of the forces of the
material pressure cause elastic deformation on the work-roll, i.e., the
deflection process. The uncontrollable amount of the work-roll deflection leads
to the high deviations in the permissible thickness of the plate along its
width. In the context of the Austenitic Stainless Steels (ASS), due to the
instability of the Austenite phase in a cold temperature, cold deformation
leads to the production of Strain-Induced Martensite (SIM), which improves the
mechanical properties. It leads to the hardening of the ASS 316L during the
cold deformation, which causes the Strain-Stress curve of the ASS 316L to
behave non-linearly, which distinguishes it from other categories of steels. To
account for this phenomenon, we propose to utilize a Machine Learning (ML)
method to predict more accurately the flow stress of the ASS 316L during the
cold rolling. Furthermore, we conduct various mechanical tensile tests in order
to obtain the required dataset, Stress316L, for training the neural network.
Moreover, instead of using a constant value of flow stress during the
multi-pass rolling process, we use a Finite Difference (FD) formulation of the
equilibrium equation in order to account for the dynamic behavior of the flow
stress, which leads to the estimation of the mean pressure, which the strip
enforces to the rolls during deformation. Finally, using the Finite Element
Analysis (FEA), the deflection of the work-roll tools will be calculated. As a
result, we end up with a generalized model for the calculation of the roll
deflection, specific to the ASS 316L. To the best of our knowledge, this is the
first model for ASS 316L which considers dynamic flow stress and SIM of the
rolled plate, using FEM and an ML approach, which could contribute to the
better design of the tolls.
</p>
<a href="http://arxiv.org/abs/2102.02470" target="_blank">arXiv:2102.02470</a> [<a href="http://arxiv.org/pdf/2102.02470" target="_blank">pdf</a>]

<h2>Transfer Learning in Bandits with Latent Continuity. (arXiv:2102.02472v1 [cs.LG])</h2>
<h3>Hyejin Park, Seiyun Shin, Kwang-Sung Jun, Jungseul Ok</h3>
<p>Structured stochastic multi-armed bandits provide accelerated regret rates
over the standard unstructured bandit problems. Most structured bandits,
however, assume the knowledge of the structural parameter such as Lipschitz
continuity, which is often not available. To cope with the latent structural
parameter, we consider a transfer learning setting in which an agent must learn
to transfer the structural information from the prior tasks to the next task,
which is inspired by practical problems such as rate adaptation in wireless
link. We propose a novel framework to provably and accurately estimate the
Lipschitz constant based on previous tasks and fully exploit it for the new
task at hand. We analyze the efficiency of the proposed framework in two folds:
(i) the sample complexity of our estimator matches with the
information-theoretic fundamental limit; and (ii) our regret bound on the new
task is close to that of the oracle algorithm with the full knowledge of the
Lipschitz constant under mild assumptions. Our analysis reveals a set of useful
insights on transfer learning for latent Lipschitzconstants such as the
fundamental challenge a learner faces. Our numerical evaluations confirm our
theoretical findings and show the superiority of the proposed framework
compared to baselines.
</p>
<a href="http://arxiv.org/abs/2102.02472" target="_blank">arXiv:2102.02472</a> [<a href="http://arxiv.org/pdf/2102.02472" target="_blank">pdf</a>]

<h2>Image Restoration by Deep Projected GSURE. (arXiv:2102.02485v1 [cs.CV])</h2>
<h3>Shady Abu-Hussein, Tom Tirer, Se Young Chun, Yonina C. Eldar, Raja Giryes</h3>
<p>Ill-posed inverse problems appear in many image processing applications, such
as deblurring and super-resolution. In recent years, solutions that are based
on deep Convolutional Neural Networks (CNNs) have shown great promise. Yet,
most of these techniques, which train CNNs using external data, are restricted
to the observation models that have been used in the training phase. A recent
alternative that does not have this drawback relies on learning the target
image using internal learning. One such prominent example is the Deep Image
Prior (DIP) technique that trains a network directly on the input image with a
least-squares loss. In this paper, we propose a new image restoration framework
that is based on minimizing a loss function that includes a "projected-version"
of the Generalized SteinUnbiased Risk Estimator (GSURE) and parameterization of
the latent image by a CNN. We demonstrate two ways to use our framework. In the
first one, where no explicit prior is used, we show that the proposed approach
outperforms other internal learning methods, such as DIP. In the second one, we
show that our GSURE-based loss leads to improved performance when used within a
plug-and-play priors scheme.
</p>
<a href="http://arxiv.org/abs/2102.02485" target="_blank">arXiv:2102.02485</a> [<a href="http://arxiv.org/pdf/2102.02485" target="_blank">pdf</a>]

<h2>From a Point Cloud to a Simulation Model: Bayesian Segmentation and Entropy based Uncertainty Estimation for 3D Modelling. (arXiv:2102.02488v1 [stat.ML])</h2>
<h3>Christina Petschnigg, Markus Spitzner, Lucas Weitzendorf, J&#xfc;rgen Pilz</h3>
<p>The 3D modelling of indoor environments and the generation of process
simulations play an important role in factory and assembly planning. In
brownfield planning cases existing data are often outdated and incomplete
especially for older plants, which were mostly planned in 2D. Thus, current
environment models cannot be generated directly on the basis of existing data
and a holistic approach on how to build such a factory model in a highly
automated fashion is mostly non-existent. Major steps in generating an
environment model in a production plant include data collection and
pre-processing, object identification as well as pose estimation. In this work,
we elaborate a methodical workflow, which starts with the digitalization of
large-scale indoor environments and ends with the generation of a static
environment or simulation model. The object identification step is realized
using a Bayesian neural network capable of point cloud segmentation. We
elaborate how the information on network uncertainty generated by a Bayesian
segmentation framework can be used in order to build up a more accurate
environment model. The steps of data collection and point cloud segmentation as
well as the resulting model accuracy are evaluated on a real-world data set
collected at the assembly line of a large-scale automotive production plant.
The segmentation network is further evaluated on the publicly available
Stanford Large-Scale 3D Indoor Spaces data set. The Bayesian segmentation
network clearly surpasses the performance of the frequentist baseline and
allows us to increase the accuracy of the model placement in a simulation scene
considerably.
</p>
<a href="http://arxiv.org/abs/2102.02488" target="_blank">arXiv:2102.02488</a> [<a href="http://arxiv.org/pdf/2102.02488" target="_blank">pdf</a>]

<h2>Keep it Simple: Data-efficient Learning for Controlling Complex Systems with Simple Models. (arXiv:2102.02493v1 [cs.RO])</h2>
<h3>Thomas Power, Dmitry Berenson</h3>
<p>When manipulating a novel object with complex dynamics, a state
representation is not always available, for example for deformable objects.
Learning both a representation and dynamics from observations requires large
amounts of data. We propose Learned Visual Similarity Predictive Control
(LVSPC), a novel method for data-efficient learning to control systems with
complex dynamics and high-dimensional state spaces from images. LVSPC leverages
a given simple model approximation from which image observations can be
generated. We use these images to train a perception model that estimates the
simple model state from observations of the complex system online. We then use
data from the complex system to fit the parameters of the simple model and
learn where this model is inaccurate, also online. Finally, we use Model
Predictive Control and bias the controller away from regions where the simple
model is inaccurate and thus where the controller is less reliable. We evaluate
LVSPC on two tasks; manipulating a tethered mass and a rope. We find that our
method performs comparably to state-of-the-art reinforcement learning methods
with an order of magnitude less data. LVSPC also completes the rope
manipulation task on a real robot with 80% success rate after only 10 trials,
despite using a perception system trained only on images from simulation.
</p>
<a href="http://arxiv.org/abs/2102.02493" target="_blank">arXiv:2102.02493</a> [<a href="http://arxiv.org/pdf/2102.02493" target="_blank">pdf</a>]

<h2>3D Surface Reconstruction From Multi-Date Satellite Images. (arXiv:2102.02502v1 [cs.CV])</h2>
<h3>Sebastian Bullinger, Christoph Bodensteiner, Michael Arens</h3>
<p>The reconstruction of accurate three-dimensional environment models is one of
the most fundamental goals in the field of photogrammetry. Since satellite
images provide suitable properties for obtaining large-scale environment
reconstructions, there exist a variety of Stereo Matching based methods to
reconstruct point clouds for satellite image pairs. Recently, the first
Structure from Motion (SfM) based approach has been proposed, which allows to
reconstruct point clouds from multiple satellite images. In this work, we
propose an extension of this SfM based pipeline that allows us to reconstruct
not only point clouds but watertight meshes including texture information. We
provide a detailed description of several steps that are mandatory to exploit
state-of-the-art mesh reconstruction algorithms in the context of satellite
imagery. This includes a decomposition of finite projective camera calibration
matrices, a skew correction of corresponding depth maps and input images as
well as the recovery of real-world depth maps from reparameterized depth
values. The paper presents an extensive quantitative evaluation on multi-date
satellite images demonstrating that the proposed pipeline combined with current
meshing algorithms outperforms state-of-the-art point cloud reconstruction
algorithms in terms of completeness and median error. We make the source code
of our pipeline publicly available.
</p>
<a href="http://arxiv.org/abs/2102.02502" target="_blank">arXiv:2102.02502</a> [<a href="http://arxiv.org/pdf/2102.02502" target="_blank">pdf</a>]

<h2>Meta-strategy for Learning Tuning Parameters with Guarantees. (arXiv:2102.02504v1 [stat.ML])</h2>
<h3>Dimitri Meunier, Pierre Alquier</h3>
<p>Online gradient methods, like the online gradient algorithm (OGA), often
depend on tuning parameters that are difficult to set in practice. We consider
an online meta-learning scenario, and we propose a meta-strategy to learn these
parameters from past tasks. Our strategy is based on the minimization of a
regret bound. It allows to learn the initialization and the step size in OGA
with guarantees. We provide a regret analysis of the strategy in the case of
convex losses. It suggests that, when there are parameters
$\theta_1,\dots,\theta_T$ solving well tasks $1,\dots,T$ respectively and that
are close enough one to each other, our strategy indeed improves on learning
each task in isolation.
</p>
<a href="http://arxiv.org/abs/2102.02504" target="_blank">arXiv:2102.02504</a> [<a href="http://arxiv.org/pdf/2102.02504" target="_blank">pdf</a>]

<h2>An Analysis of International Use of Robots for COVID-19. (arXiv:2102.02509v1 [cs.RO])</h2>
<h3>Robin R. Murphy, Vignesh B.M. Gandudi, Trisha Amin, Angela Clendenin, Jason Moats</h3>
<p>This article analyses data collected on 338 instances of robots used
explicitly in response to COVID-19 from 24 Jan, 2020, to 23 Jan, 2021, in 48
countries. The analysis was guided by four overarching questions: 1) What were
robots used for in the COVID-19 response? 2) When were they used? 3) How did
different countries innovate? and 4) Did having a national policy on robotics
influence a country's innovation and insertion of robotics for COVID-19? The
findings indicate that robots were used for six different sociotechnical work
domains and 29 discrete use cases. When robots were used varied greatly on the
country; although many countries did report an increase at the beginning of
their first surge. To understand the findings of how innovation occurred, the
data was examined through the lens of the technology's maturity according to
NASA's Technical Readiness Assessment metrics. Through this lens, findings note
that existing robots were used for more than 78% of the instances; slightly
modified robots made up 10%; and truly novel robots or novel use cases
constituted 12% of the instances. The findings clearly indicate that countries
with a national robotics initiative were more likely to use robotics more often
and for broader purposes. Finally, the dataset and analysis produces a broad
set of implications that warrant further study and investigation. The results
from this analysis are expected to be of value to the robotics and robotics
policy community in preparing robots for rapid insertion into future disasters.
</p>
<a href="http://arxiv.org/abs/2102.02509" target="_blank">arXiv:2102.02509</a> [<a href="http://arxiv.org/pdf/2102.02509" target="_blank">pdf</a>]

<h2>FedAUX: Leveraging Unlabeled Auxiliary Data in Federated Learning. (arXiv:2102.02514v1 [cs.LG])</h2>
<h3>Felix Sattler, Tim Korjakow, Roman Rischke, Wojciech Samek</h3>
<p>Federated Distillation (FD) is a popular novel algorithmic paradigm for
Federated Learning, which achieves training performance competitive to prior
parameter averaging based methods, while additionally allowing the clients to
train different model architectures, by distilling the client predictions on an
unlabeled auxiliary set of data into a student model. In this work we propose
FedAUX, an extension to FD, which, under the same set of assumptions,
drastically improves performance by deriving maximum utility from the unlabeled
auxiliary data. FedAUX modifies the FD training procedure in two ways: First,
unsupervised pre-training on the auxiliary data is performed to find a model
initialization for the distributed training. Second, $(\varepsilon,
\delta)$-differentially private certainty scoring is used to weight the
ensemble predictions on the auxiliary data according to the certainty of each
client model. Experiments on large-scale convolutional neural networks and
transformer models demonstrate, that the training performance of FedAUX exceeds
SOTA FL baseline methods by a substantial margin in both the iid and non-iid
regime, further closing the gap to centralized training performance. Code is
available at github.com/fedl-repo/fedaux.
</p>
<a href="http://arxiv.org/abs/2102.02514" target="_blank">arXiv:2102.02514</a> [<a href="http://arxiv.org/pdf/2102.02514" target="_blank">pdf</a>]

<h2>HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks. (arXiv:2102.02515v1 [cs.LG])</h2>
<h3>Yuanyuan Chen, Boyang Li, Han Yu, Pengcheng Wu, Chunyan Miao</h3>
<p>The behaviors of deep neural networks (DNNs) are notoriously resistant to
human interpretations. In this paper, we propose Hypergradient Data Relevance
Analysis, or HYDRA, which interprets the predictions made by DNNs as effects of
their training data. Existing approaches generally estimate data contributions
around the final model parameters and ignore how the training data shape the
optimization trajectory. By unrolling the hypergradient of test loss w.r.t. the
weights of training data, HYDRA assesses the contribution of training data
toward test data points throughout the training trajectory. In order to
accelerate computation, we remove the Hessian from the calculation and prove
that, under moderate conditions, the approximation error is bounded.
Corroborating this theoretical claim, empirical results indicate the error is
indeed small. In addition, we quantitatively demonstrate that HYDRA outperforms
influence functions in accurately estimating data contribution and detecting
noisy data labels. The source code is available at
https://github.com/cyyever/aaai_hydra_8686.
</p>
<a href="http://arxiv.org/abs/2102.02515" target="_blank">arXiv:2102.02515</a> [<a href="http://arxiv.org/pdf/2102.02515" target="_blank">pdf</a>]

<h2>ABCNet: Attentive Bilateral Contextual Network for Efficient Semantic Segmentation of Fine-Resolution Remote Sensing Images. (arXiv:2102.02531v1 [cs.CV])</h2>
<h3>Rui Li, Chenxi Duan</h3>
<p>Semantic segmentation of remotely sensed images plays a crucial role in
precision agriculture, environmental protection, and economic assessment. In
recent years, substantial fine-resolution remote sensing images are available
for semantic segmentation. However, due to the complicated information caused
by the increased spatial resolution, state-of-the-art deep learning algorithms
normally utilize complex network architectures for segmentation, which usually
incurs high computational complexity. Specifically, the high-caliber
performance of the convolutional neural network (CNN) heavily relies on
fine-grained spatial details (fine resolution) and sufficient contextual
information (large receptive fields), both of which trigger high computational
costs. This crucially impedes their practicability and availability in
real-world scenarios that require real-time processing. In this paper, we
propose an Attentive Bilateral Contextual Network (ABCNet), a convolutional
neural network (CNN) with double branches, with prominently lower computational
consumptions compared to the cutting-edge algorithms, while maintaining a
competitive accuracy. Code is available at https://github.com/lironui/ABCNet.
</p>
<a href="http://arxiv.org/abs/2102.02531" target="_blank">arXiv:2102.02531</a> [<a href="http://arxiv.org/pdf/2102.02531" target="_blank">pdf</a>]

<h2>Deep Learning Based Model Identification System Exploits the Modular Structure of a Bio-Inspired Posture Control Model for Humans and Humanoids. (arXiv:2102.02536v1 [cs.LG])</h2>
<h3>Vittorio Lippi</h3>
<p>This work presents a system identification procedure based on Convolutional
Neural Networks (CNN) for human posture control using the DEC (Disturbance
Estimation and Compensation) parametric model. The modular structure of the
proposed control model inspired the design of a modular identification
procedure, in the sense that the same neural network is used to identify the
parameters of the modules controlling different degrees of freedom. In this way
the presented examples of body sway induced by external stimuli provide several
training samples at once
</p>
<a href="http://arxiv.org/abs/2102.02536" target="_blank">arXiv:2102.02536</a> [<a href="http://arxiv.org/pdf/2102.02536" target="_blank">pdf</a>]

<h2>The Importance of Models in Data Analysis with Small Human Movement Datasets -- Inspirations from Neurorobotics Applied to Posture Control of Humanoids and Humans. (arXiv:2102.02543v1 [cs.RO])</h2>
<h3>Vittorio Lippi, Christoph Maurer, Thomas Mergner</h3>
<p>This work presents a system identification procedure based on Convolutional
Neural Networks (CNN) for human posture control using the DEC (Disturbance
Estimation and Compensation) parametric model. The modular structure of the
proposed control model inspired the design of a modular identification
procedure, in the sense that the same neural network is used to identify the
parameters of the modules controlling different degrees of freedom. In this way
the presented examples of body sway induced by external stimuli provide several
training samples at once.
</p>
<a href="http://arxiv.org/abs/2102.02543" target="_blank">arXiv:2102.02543</a> [<a href="http://arxiv.org/pdf/2102.02543" target="_blank">pdf</a>]

<h2>CHEF: Cross-modal Hierarchical Embeddings for Food Domain Retrieval. (arXiv:2102.02547v1 [cs.CV])</h2>
<h3>Hai X. Pham, Ricardo Guerrero, Jiatong Li, Vladimir Pavlovic</h3>
<p>Despite the abundance of multi-modal data, such as image-text pairs, there
has been little effort in understanding the individual entities and their
different roles in the construction of these data instances. In this work, we
endeavour to discover the entities and their corresponding importance in
cooking recipes automaticall} as a visual-linguistic association problem. More
specifically, we introduce a novel cross-modal learning framework to jointly
model the latent representations of images and text in the food image-recipe
association and retrieval tasks. This model allows one to discover complex
functional and hierarchical relationships between images and text, and among
textual parts of a recipe including title, ingredients and cooking
instructions. Our experiments show that by making use of efficient
tree-structured Long Short-Term Memory as the text encoder in our computational
cross-modal retrieval framework, we are not only able to identify the main
ingredients and cooking actions in the recipe descriptions without explicit
supervision, but we can also learn more meaningful feature representations of
food recipes, appropriate for challenging cross-modal retrieval and recipe
adaption tasks.
</p>
<a href="http://arxiv.org/abs/2102.02547" target="_blank">arXiv:2102.02547</a> [<a href="http://arxiv.org/pdf/2102.02547" target="_blank">pdf</a>]

<h2>Exploring Scale-Measures of Data Sets. (arXiv:2102.02576v1 [cs.AI])</h2>
<h3>Tom Hanika, Johannes Hirth</h3>
<p>Measurement is a fundamental building block of numerous scientific models and
their creation. This is in particular true for data driven science. Due to the
high complexity and size of modern data sets, the necessity for the development
of understandable and efficient scaling methods is at hand. A profound theory
for scaling data is scale-measures, as developed in the field of formal concept
analysis. Recent developments indicate that the set of all scale-measures for a
given data set constitutes a lattice and does hence allow efficient exploring
algorithms. In this work we study the properties of said lattice and propose a
novel scale-measure exploration algorithm that is based on the well-known and
proven attribute exploration approach. Our results motivate multiple
applications in scale recommendation, most prominently (semi-)automatic
scaling.
</p>
<a href="http://arxiv.org/abs/2102.02576" target="_blank">arXiv:2102.02576</a> [<a href="http://arxiv.org/pdf/2102.02576" target="_blank">pdf</a>]

<h2>Temporal Cascade and Structural Modelling of EHRs for Granular Readmission Prediction. (arXiv:2102.02586v1 [cs.LG])</h2>
<h3>Bhagya Hettige, Weiqing Wang, Yuan-Fang Li, Suong Le, Wray Buntine</h3>
<p>Predicting (1) when the next hospital admission occurs and (2) what will
happen in the next admission about a patient by mining electronic health record
(EHR) data can provide granular readmission predictions to assist clinical
decision making. Recurrent neural network (RNN) and point process models are
usually employed in modelling temporal sequential data. Simple RNN models
assume that sequences of hospital visits follow strict causal dependencies
between consecutive visits. However, in the real-world, a patient may have
multiple co-existing chronic medical conditions, i.e., multimorbidity, which
results in a cascade of visits where a non-immediate historical visit can be
most influential to the next visit. Although a point process (e.g., Hawkes
process) is able to model a cascade temporal relationship, it strongly relies
on a prior generative process assumption. We propose a novel model, MEDCAS, to
address these challenges. MEDCAS combines the strengths of RNN-based models and
point processes by integrating point processes in modelling visit types and
time gaps into an attention-based sequence-to-sequence learning model, which is
able to capture the temporal cascade relationships. To supplement the patients
with short visit sequences, a structural modelling technique with graph-based
methods is used to construct the markers of the point process in MEDCAS.
Extensive experiments on three real-world EHR datasets have been performed and
the results demonstrate that \texttt{MEDCAS} outperforms state-of-the-art
models in both tasks.
</p>
<a href="http://arxiv.org/abs/2102.02586" target="_blank">arXiv:2102.02586</a> [<a href="http://arxiv.org/pdf/2102.02586" target="_blank">pdf</a>]

<h2>Lookup subnet based Spatial Graph Convolutional neural Network. (arXiv:2102.02588v1 [cs.LG])</h2>
<h3>Jingzhao Hu, Xiaoqi Zhang, Qiaomei Jia, Chen Wang, Qirong Bu, Jun Feng</h3>
<p>Convolutional Neural Networks(CNNs) has achieved remarkable performance
breakthrough in Euclidean structure data. Recently, aggregation-transformation
based Graph Neural networks(GNNs) gradually produce a powerful performance on
non-Euclidean data. In this paper, we propose a cross-correlation based graph
convolution method allowing to naturally generalize CNNs to non-Euclidean
domains and inherit the excellent natures of CNNs, such as local filters,
parameter sharing, flexible receptive field, etc. Meanwhile, it leverages
dynamically generated convolution kernel and cross-correlation operators to
address the shortcomings of prior methods based on aggregation-transformation
or their approximations. Our method has achieved or matched popular
state-of-the-art results across three established graph benchmarks: the Cora,
Citeseer, and Pubmed citation network datasets.
</p>
<a href="http://arxiv.org/abs/2102.02588" target="_blank">arXiv:2102.02588</a> [<a href="http://arxiv.org/pdf/2102.02588" target="_blank">pdf</a>]

<h2>CKConv: Continuous Kernel Convolution For Sequential Data. (arXiv:2102.02611v1 [cs.LG])</h2>
<h3>David W. Romero, Anna Kuzina, Erik J. Bekkers, Jakub M. Tomczak, Mark Hoogendoorn</h3>
<p>Conventional neural architectures for sequential data present important
limitations. Recurrent networks suffer from exploding and vanishing gradients,
small effective memory horizons, and must be trained sequentially.
Convolutional networks are unable to handle sequences of unknown size and their
memory horizon must be defined a priori. In this work, we show that all these
problems can be solved by formulating convolutional kernels in CNNs as
continuous functions. The resulting Continuous Kernel Convolution (CKConv)
allows us to model arbitrarily long sequences in a parallel manner, within a
single operation, and without relying on any form of recurrence. We show that
Continuous Kernel Convolutional Networks (CKCNNs) obtain state-of-the-art
results in multiple datasets, e.g., permuted MNIST, and, thanks to their
continuous nature, are able to handle non-uniformly sampled datasets and
irregularly-sampled data natively. CKCNNs match or perform better than neural
ODEs designed for these purposes in a much faster and simpler manner.
</p>
<a href="http://arxiv.org/abs/2102.02611" target="_blank">arXiv:2102.02611</a> [<a href="http://arxiv.org/pdf/2102.02611" target="_blank">pdf</a>]

<h2>Optimised one-class classification performance. (arXiv:2102.02618v1 [cs.LG])</h2>
<h3>Oliver Urs Lenz, Daniel Peralta, Chris Cornelis</h3>
<p>We provide a thorough treatment of hyperparameter optimisation for three data
descriptors with a good track-record in the literature: Support Vector Machine
(SVM), Nearest Neighbour Distance (NND) and Average Localised Proximity (ALP).
The hyperparameters of SVM have to be optimised through cross-validation, while
NND and ALP allow the reuse of a single nearest-neighbour query and an
efficient form of leave-one-out validation. We experimentally evaluate the
effect of hyperparameter optimisation with 246 classification problems drawn
from 50 datasets. From a selection of optimisation algorithms, the recent
Malherbe-Powell proposal optimises the hyperparameters of all three data
descriptors most efficiently. We calculate the increase in test AUROC and the
amount of overfitting as a function of the number of hyperparameter
evaluations. After 50 evaluations, ALP and SVM both significantly outperform
NND. The performance of ALP and SVM is comparable, but ALP can be optimised
more efficiently, while a choice between ALP and SVM based on validation AUROC
gives the best overall result. This distils the many variables of one-class
classification with hyperparameter optimisation down to a clear choice with a
known trade-off, allowing practitioners to make informed decisions.
</p>
<a href="http://arxiv.org/abs/2102.02618" target="_blank">arXiv:2102.02618</a> [<a href="http://arxiv.org/pdf/2102.02618" target="_blank">pdf</a>]

<h2>Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency. (arXiv:2102.02629v1 [cs.CV])</h2>
<h3>Seokju Lee, Sunghoon Im, Stephen Lin, In So Kweon</h3>
<p>We present an end-to-end joint training framework that explicitly models
6-DoF motion of multiple dynamic objects, ego-motion and depth in a monocular
camera setup without supervision. Our technical contributions are three-fold.
First, we highlight the fundamental difference between inverse and forward
projection while modeling the individual motion of each rigid object, and
propose a geometrically correct projection pipeline using a neural forward
projection module. Second, we design a unified instance-aware photometric and
geometric consistency loss that holistically imposes self-supervisory signals
for every background and object region. Lastly, we introduce a general-purpose
auto-annotation scheme using any off-the-shelf instance segmentation and
optical flow models to produce video instance segmentation maps that will be
utilized as input to our training pipeline. These proposed elements are
validated in a detailed ablation study. Through extensive experiments conducted
on the KITTI and Cityscapes dataset, our framework is shown to outperform the
state-of-the-art depth and motion estimation methods. Our code, dataset, and
models are available at https://github.com/SeokjuLee/Insta-DM .
</p>
<a href="http://arxiv.org/abs/2102.02629" target="_blank">arXiv:2102.02629</a> [<a href="http://arxiv.org/pdf/2102.02629" target="_blank">pdf</a>]

<h2>Universal Approximation Theorems of Fully Connected Binarized Neural Networks. (arXiv:2102.02631v1 [cs.LG])</h2>
<h3>Mikail Yayla, Mario G&#xfc;nzel, Burim Ramosaj, Jian-Jia Chen</h3>
<p>Neural networks (NNs) are known for their high predictive accuracy in complex
learning problems. Beside practical advantages, NNs also indicate favourable
theoretical properties such as universal approximation (UA) theorems. Binarized
Neural Networks (BNNs) significantly reduce time and memory demands by
restricting the weight and activation domains to two values. Despite the
practical advantages, theoretical guarantees based on UA theorems of BNNs are
rather sparse in the literature. We close this gap by providing UA theorems for
fully connected BNNs under the following scenarios: (1) for binarized inputs,
UA can be constructively achieved under one hidden layer; (2) for inputs with
real numbers, UA can not be achieved under one hidden layer but can be
constructively achieved under two hidden layers for Lipschitz-continuous
functions. Our results indicate that fully connected BNNs can approximate
functions universally, under certain conditions.
</p>
<a href="http://arxiv.org/abs/2102.02631" target="_blank">arXiv:2102.02631</a> [<a href="http://arxiv.org/pdf/2102.02631" target="_blank">pdf</a>]

<h2>Big Data Analytics Applying the Fusion Approach of Multicriteria Decision Making with Deep Learning Algorithms. (arXiv:2102.02637v1 [cs.LG])</h2>
<h3>Swarajya Lakshmi V Papineni, Snigdha Yarlagadda, Harita Akkineni, A. Mallikarjuna Reddy</h3>
<p>Data is evolving with the rapid progress of population and communication for
various types of devices such as networks, cloud computing, Internet of Things
(IoT), actuators, and sensors. The increment of data and communication content
goes with the equivalence of velocity, speed, size, and value to provide the
useful and meaningful knowledge that helps to solve the future challenging
tasks and latest issues. Besides, multicriteria based decision making is one of
the key issues to solve for various issues related to the alternative effects
in big data analysis. It tends to find a solution based on the latest machine
learning techniques that include algorithms like decision making and deep
learning mechanism based on multicriteria in providing insights to big data. On
the other hand, the derivations are made for it to go with the approximations
to increase the duality of runtime and improve the entire system's potentiality
and efficacy. In essence, several fields, including business, agriculture,
information technology, and computer science, use deep learning and
multicriteria-based decision-making problems. This paper aims to provide
various applications that involve the concepts of deep learning techniques and
exploiting the multicriteria approaches for issues that are facing in big data
analytics by proposing new studies with the fusion approaches of data-driven
techniques.
</p>
<a href="http://arxiv.org/abs/2102.02637" target="_blank">arXiv:2102.02637</a> [<a href="http://arxiv.org/pdf/2102.02637" target="_blank">pdf</a>]

<h2>Autodidactic Neurosurgeon: Collaborative Deep Inference for Mobile Edge Intelligence via Online Learning. (arXiv:2102.02638v1 [cs.LG])</h2>
<h3>Letian Zhang, Lixing Chen, Jie Xu</h3>
<p>Recent breakthroughs in deep learning (DL) have led to the emergence of many
intelligent mobile applications and services, but in the meanwhile also pose
unprecedented computing challenges on resource-constrained mobile devices. This
paper builds a collaborative deep inference system between a
resource-constrained mobile device and a powerful edge server, aiming at
joining the power of both on-device processing and computation offloading. The
basic idea of this system is to partition a deep neural network (DNN) into a
front-end part running on the mobile device and a back-end part running on the
edge server, with the key challenge being how to locate the optimal partition
point to minimize the end-to-end inference delay. Unlike existing efforts on
DNN partitioning that rely heavily on a dedicated offline profiling stage to
search for the optimal partition point, our system has a built-in online
learning module, called Autodidactic Neurosurgeon (ANS), to automatically learn
the optimal partition point on-the-fly. Therefore, ANS is able to closely
follow the changes of the system environment by generating new knowledge for
adaptive decision making. The core of ANS is a novel contextual bandit learning
algorithm, called $\mu$LinUCB, which not only has provable theoretical learning
performance guarantee but also is ultra-lightweight for easy real-world
implementation. We implement our system on a video stream object detection
testbed to validate the design of ANS and evaluate its performance. The
experiments show that ANS significantly outperforms state-of-the-art benchmarks
in terms of tracking system changes and reducing the end-to-end inference
delay.
</p>
<a href="http://arxiv.org/abs/2102.02638" target="_blank">arXiv:2102.02638</a> [<a href="http://arxiv.org/pdf/2102.02638" target="_blank">pdf</a>]

<h2>Improving Reinforcement Learning with Human Assistance: An Argument for Human Subject Studies with HIPPO Gym. (arXiv:2102.02639v1 [cs.LG])</h2>
<h3>Matthew E. Taylor, Nicholas Nissen, Yuan Wang, Neda Navidi</h3>
<p>Reinforcement learning (RL) is a popular machine learning paradigm for game
playing, robotics control, and other sequential decision tasks. However, RL
agents often have long learning times with high data requirements because they
begin by acting randomly. In order to better learn in complex tasks, this
article argues that an external teacher can often significantly help the RL
agent learn.

OpenAI Gym is a common framework for RL research, including a large number of
standard environments and agents, making RL research significantly more
accessible. This article introduces our new open-source RL framework, the Human
Input Parsing Platform for Openai Gym (HIPPO Gym), and the design decisions
that went into its creation. The goal of this platform is to facilitate
human-RL research, again lowering the bar so that more researchers can quickly
investigate different ways that human teachers could assist RL agents,
including learning from demonstrations, learning from feedback, or curriculum
learning.
</p>
<a href="http://arxiv.org/abs/2102.02639" target="_blank">arXiv:2102.02639</a> [<a href="http://arxiv.org/pdf/2102.02639" target="_blank">pdf</a>]

<h2>Asymptotically Exact and Fast Gaussian Copula Models for Imputation of Mixed Data Types. (arXiv:2102.02642v1 [stat.ML])</h2>
<h3>Benjamin Christoffersen, Mark Clements, Keith Humphreys, Hedvig Kjellstr&#xf6;m</h3>
<p>Missing values with mixed data types is a common problem in a large number of
machine learning applications such as processing of surveys and in different
medical applications. Recently, Gaussian copula models have been suggested as a
means of performing imputation of missing values using a probabilistic
framework. While the present Gaussian copula models have shown to yield state
of the art performance, they have two limitations: they are based on an
approximation that is fast but may be imprecise and they do not support
unordered multinomial variables. We address the first limitation using direct
and arbitrarily precise approximations both for model estimation and imputation
by using randomized quasi-Monte Carlo procedures. The method we provide has
lower errors for the estimated model parameters and the imputed values,
compared to previously proposed methods. We also extend the previous Gaussian
copula models to include unordered multinomial variables in addition to the
present support of ordinal, binary, and continuous variables.
</p>
<a href="http://arxiv.org/abs/2102.02642" target="_blank">arXiv:2102.02642</a> [<a href="http://arxiv.org/pdf/2102.02642" target="_blank">pdf</a>]

<h2>Pick the Right Edge Device: Towards Power and Performance Estimation of CUDA-based CNNs on GPGPUs. (arXiv:2102.02645v1 [cs.LG])</h2>
<h3>Christopher A. Metz, Mehran Goli, Rolf Drechsler</h3>
<p>The emergence of Machine Learning (ML) as a powerful technique has been
helping nearly all fields of business to increase operational efficiency or to
develop new value propositions. Besides the challenges of deploying and
maintaining ML models, picking the right edge device (e.g., GPGPUs) to run
these models (e.g., CNN with the massive computational process) is one of the
most pressing challenges faced by organizations today. As the cost of renting
(on Cloud) or purchasing an edge device is directly connected to the cost of
final products or services, choosing the most efficient device is essential.
However, this decision making requires deep knowledge about performance and
power consumption of the ML models running on edge devices that must be
identified at the early stage of ML workflow.

In this paper, we present a novel ML-based approach that provides ML
engineers with the early estimation of both power consumption and performance
of CUDA-based CNNs on GPGPUs. The proposed approach empowers ML engineers to
pick the most efficient GPGPU for a given CNN model at the early stage of
development.
</p>
<a href="http://arxiv.org/abs/2102.02645" target="_blank">arXiv:2102.02645</a> [<a href="http://arxiv.org/pdf/2102.02645" target="_blank">pdf</a>]

<h2>Triadic Exploration and Exploration with Multiple Experts. (arXiv:2102.02654v1 [cs.AI])</h2>
<h3>Maximilian Felde, Gerd Stumme</h3>
<p>Formal Concept Analysis (FCA) provides a method called attribute exploration
which helps a domain expert discover structural dependencies in knowledge
domains that can be represented by a formal context (a cross table of objects
and attributes). Triadic Concept Analysis is an extension of FCA that
incorporates the notion of conditions. Many extensions and variants of
attribute exploration have been studied but only few attempts at incorporating
multiple experts have been made. In this paper we present triadic exploration
based on Triadic Concept Analysis to explore conditional attribute implications
in a triadic domain. We then adapt this approach to formulate attribute
exploration with multiple experts that have different views on a domain.
</p>
<a href="http://arxiv.org/abs/2102.02654" target="_blank">arXiv:2102.02654</a> [<a href="http://arxiv.org/pdf/2102.02654" target="_blank">pdf</a>]

<h2>Digital twins based on bidirectional LSTM and GAN for modelling COVID-19. (arXiv:2102.02664v1 [cs.LG])</h2>
<h3>C&#xe9;sar Quilodr&#xe1;n-Casas, Vinicius Santos Silva, Rossella Arcucci, Claire E. Heaney, Yike Guo, Christopher C. Pain</h3>
<p>The outbreak of the coronavirus disease 2019 (COVID-19) has now spread
throughout the globe infecting over 100 million people and causing the death of
over 2.2 million people. Thus, there is an urgent need to study the dynamics of
epidemiological models to gain a better understanding of how such diseases
spread. While epidemiological models can be computationally expensive, recent
advances in machine learning techniques have given rise to neural networks with
the ability to learn and predict complex dynamics at reduced computational
costs. Here we introduce two digital twins of a SEIRS model applied to an
idealised town. The SEIRS model has been modified to take account of spatial
variation and, where possible, the model parameters are based on official virus
spreading data from the UK. We compare predictions from a data-corrected
Bidirectional Long Short-Term Memory network and a predictive Generative
Adversarial Network. The predictions given by these two frameworks are accurate
when compared to the original SEIRS model data. Additionally, these frameworks
are data-agnostic and could be applied to towns, idealised or real, in the UK
or in other countries. Also, more compartments could be included in the SEIRS
model, in order to study more realistic epidemiological behaviour.
</p>
<a href="http://arxiv.org/abs/2102.02664" target="_blank">arXiv:2102.02664</a> [<a href="http://arxiv.org/pdf/2102.02664" target="_blank">pdf</a>]

<h2>Hybrid consistency and plausibility verification of product data according to FIC. (arXiv:2102.02665v1 [cs.LG])</h2>
<h3>Christian Schorr</h3>
<p>The labelling of food products in the EU is regulated by the Food Information
of Customers (FIC). Companies are required to provide the corresponding
information regarding nutrients and allergens among others. With the rise of
e-commerce more and more food products are sold online. There are often errors
in the online product descriptions regarding the FIC-relevant information due
to low data quality in the vendors' product data base. In this paper we propose
a hybrid approach of both rule-based and machine learning to verify nutrient
declaration and allergen labelling according to FIC requirements. Special focus
is given to the problem of false negatives in allergen prediction since this
poses a significant health risk to customers. Results show that a neural net
trained on a subset of the ingredients of a product is capable of predicting
the allergens contained with a high reliability.
</p>
<a href="http://arxiv.org/abs/2102.02665" target="_blank">arXiv:2102.02665</a> [<a href="http://arxiv.org/pdf/2102.02665" target="_blank">pdf</a>]

<h2>Disease Prediction with a Maximum Entropy Method. (arXiv:2102.02668v1 [cs.LG])</h2>
<h3>Michael Shub, Qing Xu, Xiaohua (Michael) Xuan</h3>
<p>In this paper, we propose a maximum entropy method for predicting disease
risks. It is based on a patient's medical history with diseases coded in ICD-10
which can be used in various cases. The complete algorithm with strict
mathematical derivation is given. We also present experimental results on a
medical dataset, demonstrating that our method performs well in predicting
future disease risks and achieves an accuracy rate twice that of the
traditional method. We also perform a comorbidity analysis to reveal the
intrinsic relation of diseases.
</p>
<a href="http://arxiv.org/abs/2102.02668" target="_blank">arXiv:2102.02668</a> [<a href="http://arxiv.org/pdf/2102.02668" target="_blank">pdf</a>]

<h2>Multimodal-Aware Weakly Supervised Metric Learning with Self-weighting Triplet Loss. (arXiv:2102.02670v1 [cs.LG])</h2>
<h3>Huiyuan Deng, Xiangzhu Meng, Lin Feng</h3>
<p>In recent years, we have witnessed a surge of interests in learning a
suitable distance metric from weakly supervised data. Most existing methods aim
to pull all the similar samples closer while push the dissimilar ones as far as
possible. However, when some classes of the dataset exhibit multimodal
distribution, these goals conflict and thus can hardly be concurrently
satisfied. Additionally, to ensure a valid metric, many methods require a
repeated eigenvalue decomposition process, which is expensive and numerically
unstable. Therefore, how to learn an appropriate distance metric from weakly
supervised data remains an open but challenging problem. To address this issue,
in this paper, we propose a novel weakly supervised metric learning algorithm,
named MultimoDal Aware weakly supervised Metric Learning (MDaML). MDaML
partitions the data space into several clusters and allocates the local cluster
centers and weight for each sample. Then, combining it with the weighted
triplet loss can further enhance the local separability, which encourages the
local dissimilar samples to keep a large distance from the local similar
samples. Meanwhile, MDaML casts the metric learning problem into an
unconstrained optimization on the SPD manifold, which can be efficiently solved
by Riemannian Conjugate Gradient Descent (RCGD). Extensive experiments
conducted on 13 datasets validate the superiority of the proposed MDaML.
</p>
<a href="http://arxiv.org/abs/2102.02670" target="_blank">arXiv:2102.02670</a> [<a href="http://arxiv.org/pdf/2102.02670" target="_blank">pdf</a>]

<h2>Directive Explanations for Actionable Explainability in Machine Learning Applications. (arXiv:2102.02671v1 [cs.LG])</h2>
<h3>Ronal Singh, Paul Dourish, Piers Howe, Tim Miller, Liz Sonenberg, Eduardo Velloso, Frank Vetere</h3>
<p>This paper investigates the prospects of using directive explanations to
assist people in achieving recourse of machine learning decisions. Directive
explanations list which specific actions an individual needs to take to achieve
their desired outcome. If a machine learning model makes a decision that is
detrimental to an individual (e.g. denying a loan application), then it needs
to both explain why it made that decision and also explain how the individual
could obtain their desired outcome (if possible). At present, this is often
done using counterfactual explanations, but such explanations generally do not
tell individuals how to act. We assert that counterfactual explanations can be
improved by explicitly providing people with actions they could use to achieve
their desired goal. This paper makes two contributions. First, we present the
results of an online study investigating people's perception of directive
explanations. Second, we propose a conceptual model to generate such
explanations. Our online study showed a significant preference for directive
explanations ($p&lt;0.001$). However, the participants' preferred explanation type
was affected by multiple factors, such as individual preferences, social
factors, and the feasibility of the directives. Our findings highlight the need
for a human-centred and context-specific approach for creating directive
explanations.
</p>
<a href="http://arxiv.org/abs/2102.02671" target="_blank">arXiv:2102.02671</a> [<a href="http://arxiv.org/pdf/2102.02671" target="_blank">pdf</a>]

<h2>Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection. (arXiv:2102.02680v1 [cs.AI])</h2>
<h3>Nguyen Vo, Kyumin Lee</h3>
<p>The widespread of fake news and misinformation in various domains ranging
from politics, economics to public health has posed an urgent need to
automatically fact-check information. A recent trend in fake news detection is
to utilize evidence from external sources. However, existing evidence-aware
fake news detection methods focused on either only word-level attention or
evidence-level attention, which may result in suboptimal performance. In this
paper, we propose a Hierarchical Multi-head Attentive Network to fact-check
textual claims. Our model jointly combines multi-head word-level attention and
multi-head document-level attention, which aid explanation in both word-level
and evidence-level. Experiments on two real-word datasets show that our model
outperforms seven state-of-the-art baselines. Improvements over baselines are
from 6\% to 18\%. Our source code and datasets are released at
\texttt{\url{https://github.com/nguyenvo09/EACL2021}}.
</p>
<a href="http://arxiv.org/abs/2102.02680" target="_blank">arXiv:2102.02680</a> [<a href="http://arxiv.org/pdf/2102.02680" target="_blank">pdf</a>]

<h2>Impossibility of Partial Recovery in the Graph Alignment Problem. (arXiv:2102.02685v1 [stat.ML])</h2>
<h3>Luca Ganassali, Laurent Massouli&#xe9;, Marc Lelarge</h3>
<p>Random graph alignment refers to recovering the underlying vertex
correspondence between two random graphs with correlated edges. This can be
viewed as an average-case and noisy version of the well-known NP-hard graph
isomorphism problem. For the correlated Erd\"os-R\'enyi model, we prove an
impossibility result for partial recovery in the sparse regime, with constant
average degree and correlation, as well as a general bound on the maximal
reachable overlap. Our bound is tight in the noiseless case (the graph
isomorphism problem) and we conjecture that it is still tight with noise. Our
proof technique relies on a careful application of the probabilistic method to
build automorphisms between tree components of a subcritical Erd\"os-R\'enyi
graph.
</p>
<a href="http://arxiv.org/abs/2102.02685" target="_blank">arXiv:2102.02685</a> [<a href="http://arxiv.org/pdf/2102.02685" target="_blank">pdf</a>]

<h2>Invertible DenseNets with Concatenated LipSwish. (arXiv:2102.02694v1 [stat.ML])</h2>
<h3>Yura Perugachi-Diaz, Jakub M. Tomczak, Sandjai Bhulai</h3>
<p>We introduce Invertible Dense Networks (i-DenseNets), a more parameter
efficient alternative to Residual Flows. The method relies on an analysis of
the Lipschitz continuity of the concatenation in DenseNets, where we enforce
invertibility of the network by satisfying the Lipschitz constant. We extend
this method by proposing a learnable concatenation, which not only improves the
model performance but also indicates the importance of the concatenated
representation. Additionally, we introduce the Concatenated LipSwish as
activation function, for which we show how to enforce the Lipschitz condition
and which boosts performance. The new architecture, i-DenseNet, out-performs
Residual Flow and other flow-based models on density estimation evaluated in
bits per dimension, where we utilize an equal parameter budget. Moreover, we
show that the proposed model out-performs Residual Flows when trained as a
hybrid model where the model is both a generative and a discriminative model.
</p>
<a href="http://arxiv.org/abs/2102.02694" target="_blank">arXiv:2102.02694</a> [<a href="http://arxiv.org/pdf/2102.02694" target="_blank">pdf</a>]

<h2>Active Boundary Loss for Semantic Segmentation. (arXiv:2102.02696v1 [cs.CV])</h2>
<h3>Chi Wang, Yunke Zhang, Miaomiao Cui, Jinlin Liu, Peiran Ren, Yin Yang, Xuansong Xie, XianSheng Hua, Hujun Bao, Weiwei Xu</h3>
<p>This paper proposes a novel active boundary loss for semantic segmentation.
It can progressively encourage the alignment between predicted boundaries and
ground-truth boundaries during end-to-end training, which is not explicitly
enforced in commonly used cross-entropy loss. Based on the predicted boundaries
detected from the segmentation results using current network parameters, we
formulate the boundary alignment problem as a differentiable direction vector
prediction problem to guide the movement of predicted boundaries in each
iteration. Our loss is model-agnostic and can be plugged into the training of
segmentation networks to improve the boundary details. Experimental results
show that training with the active boundary loss can effectively improve the
boundary F-score and mean Intersection-over-Union on challenging image and
video object segmentation datasets.
</p>
<a href="http://arxiv.org/abs/2102.02696" target="_blank">arXiv:2102.02696</a> [<a href="http://arxiv.org/pdf/2102.02696" target="_blank">pdf</a>]

<h2>EFloat: Entropy-coded Floating Point Format for Deep Learning. (arXiv:2102.02705v1 [cs.LG])</h2>
<h3>Rajesh Bordawekar, Bulent Abali, Ming-Hung Chen</h3>
<p>We describe the EFloat floating-point number format with 4 to 6 additional
bits of precision and a wider exponent range than the existing floating point
(FP) formats of any width including FP32, BFloat16, IEEE-Half precision,
DLFloat, TensorFloat, and 8-bit floats. In a large class of deep learning
models we observe that FP exponent values tend to cluster around few unique
values which presents entropy encoding opportunities. The EFloat format encodes
frequent exponent values and signs with Huffman codes to minimize the average
exponent field width. Saved bits then become available to the mantissa
increasing the EFloat numeric precision on average by 4 to 6 bits compared to
other FP formats of equal width. The proposed encoding concept may be
beneficial to low-precision formats including 8-bit floats. Training deep
learning models with low precision arithmetic is challenging. EFloat, with its
increased precision may provide an opportunity for those tasks as well. We
currently use the EFloat format for compressing and saving memory used in large
NLP deep learning models. A potential hardware implementation for improving
PCIe and memory bandwidth limitations of AI accelerators is also discussed.
</p>
<a href="http://arxiv.org/abs/2102.02705" target="_blank">arXiv:2102.02705</a> [<a href="http://arxiv.org/pdf/2102.02705" target="_blank">pdf</a>]

<h2>ProxyFAUG: Proximity-based Fingerprint Augmentation. (arXiv:2102.02706v1 [cs.CV])</h2>
<h3>Grigorios G. Anagnostopoulos, Alexandros Kalousis</h3>
<p>The proliferation of data-demanding machine learning methods has brought to
light the necessity for methodologies which can enlarge the size of training
datasets, with simple, rule-based methods. In-line with this concept, the
fingerprint augmentation scheme proposed in this work aims to augment
fingerprint datasets which are used to train positioning models. The proposed
method utilizes fingerprints which are recorded in spacial proximity, in order
to perform fingerprint augmentation, creating new fingerprints which combine
the features of the original ones. The proposed method of composing the new,
augmented fingerprints is inspired by the crossover and mutation operators of
genetic algorithms. The ProxyFAUG method aims to improve the achievable
positioning accuracy of fingerprint datasets, by introducing a rule-based,
stochastic, proximity-based method of fingerprint augmentation. The performance
of ProxyFAUG is evaluated in an outdoor Sigfox setting using a public dataset.
The best performing published positioning method on this dataset is improved by
40% in terms of median error and 6% in terms of mean error, with the use of the
augmented dataset. The analysis of the results indicate a systematic and
significant performance improvement at the lower error quartiles, as indicated
by the impressive improvement of the median error.
</p>
<a href="http://arxiv.org/abs/2102.02706" target="_blank">arXiv:2102.02706</a> [<a href="http://arxiv.org/pdf/2102.02706" target="_blank">pdf</a>]

<h2>RoI Tanh-polar Transformer Network for Face Parsing in the Wild. (arXiv:2102.02717v1 [cs.CV])</h2>
<h3>Yiming Lin, Jie Shen, Yujiang Wang, Maja Pantic</h3>
<p>Face parsing aims to predict pixel-wise labels for facial components of a
target face in an image. Existing approaches usually crop the target face from
the input image with respect to a bounding box calculated during
pre-processing, and thus can only parse inner facial Regions of Interest
(RoIs). Peripheral regions like hair are ignored and nearby faces that are
partially included in the bounding box can cause distractions. Moreover, these
methods are only trained and evaluated on near-frontal portrait images and thus
their performance for in-the-wild cases were unexplored. To address these
issues, this paper makes three contributions. First, we introduce iBugMask
dataset for face parsing in the wild containing 1,000 manually annotated images
with large variations in sizes, poses, expressions and background, and
Helen-LP, a large-pose training set containing 21,866 images generated using
head pose augmentation. Second, we propose RoI Tanh-polar transform that warps
the whole image to a Tanh-polar representation with a fixed ratio between the
face area and the context, guided by the target bounding box. The new
representation contains all information in the original image, and allows for
rotation equivariance in the convolutional neural networks (CNNs). Third, we
propose a hybrid residual representation learning block, coined HybridBlock,
that contains convolutional layers in both the Tanh-polar space and the
Tanh-Cartesian space, allowing for receptive fields of different shapes in
CNNs. Through extensive experiments, we show that the proposed method
significantly improves the state-of-the-art for face parsing in the wild.
</p>
<a href="http://arxiv.org/abs/2102.02717" target="_blank">arXiv:2102.02717</a> [<a href="http://arxiv.org/pdf/2102.02717" target="_blank">pdf</a>]

<h2>Adversarial Attacks and Defenses in Physiological Computing: A Systematic Review. (arXiv:2102.02729v1 [cs.LG])</h2>
<h3>Dongrui Wu, Weili Fang, Yi Zhang, Liuqing Yang, Hanbin Luo, Lieyun Ding, Xiaodong Xu, Xiang Yu</h3>
<p>Physiological computing uses human physiological data as system inputs in
real time. It includes, or significantly overlaps with, brain-computer
interfaces, affective computing, adaptive automation, health informatics, and
physiological signal based biometrics. Physiological computing increases the
communication bandwidth from the user to the computer, but is also subject to
various types of adversarial attacks, in which the attacker deliberately
manipulates the training and/or test examples to hijack the machine learning
algorithm output, leading to possibly user confusion, frustration, injury, or
even death. However, the vulnerability of physiological computing systems has
not been paid enough attention to, and there does not exist a comprehensive
review on adversarial attacks to it. This paper fills this gap, by providing a
systematic review on the main research areas of physiological computing,
different types of adversarial attacks and their applications to physiological
computing, and the corresponding defense strategies. We hope this review will
attract more research interests on the vulnerability of physiological computing
systems, and more importantly, defense strategies to make them more secure.
</p>
<a href="http://arxiv.org/abs/2102.02729" target="_blank">arXiv:2102.02729</a> [<a href="http://arxiv.org/pdf/2102.02729" target="_blank">pdf</a>]

<h2>Computational identification of significant actors in paintings through symbols and attributes. (arXiv:2102.02732v1 [cs.CV])</h2>
<h3>David G.Stork, Anthony Bourached, George H.Cann, Ryan-Rhys Griffiths</h3>
<p>The automatic analysis of fine art paintings presents a number of novel
technical challenges to artificial intelligence, computer vision, machine
learning, and knowledge representation quite distinct from those arising in the
analysis of traditional photographs. The most important difference is that many
realist paintings depict stories or episodes in order to convey a lesson,
moral, or meaning. One early step in automatic interpretation and extraction of
meaning in artworks is the identifications of figures (actors). In Christian
art, specifically, one must identify the actors in order to identify the
Biblical episode or story depicted, an important step in understanding the
artwork. We designed an automatic system based on deep convolutional neural
networks and simple knowledge database to identify saints throughout six
centuries of Christian art based in large part upon saints symbols or
attributes. Our work represents initial steps in the broad task of automatic
semantic interpretation of messages and meaning in fine art.
</p>
<a href="http://arxiv.org/abs/2102.02732" target="_blank">arXiv:2102.02732</a> [<a href="http://arxiv.org/pdf/2102.02732" target="_blank">pdf</a>]

<h2>Hawkes Processes on Graphons. (arXiv:2102.02741v1 [cs.LG])</h2>
<h3>Hongteng Xu, Dixin Luo, Hongyuan Zha</h3>
<p>We propose a novel framework for modeling multiple multivariate point
processes, each with heterogeneous event types that share an underlying space
and obey the same generative mechanism. Focusing on Hawkes processes and their
variants that are associated with Granger causality graphs, our model leverages
an uncountable event type space and samples the graphs with different sizes
from a nonparametric model called {\it graphon}. Given those graphs, we can
generate the corresponding Hawkes processes and simulate event sequences.
Learning this graphon-based Hawkes process model helps to 1) infer the
underlying relations shared by different Hawkes processes; and 2) simulate
event sequences with different event types but similar dynamics. We learn the
proposed model by minimizing the hierarchical optimal transport distance
between the generated event sequences and the observed ones, leading to a novel
reward-augmented maximum likelihood estimation method. We analyze the
properties of our model in-depth and demonstrate its rationality and
effectiveness in both theory and experiments.
</p>
<a href="http://arxiv.org/abs/2102.02741" target="_blank">arXiv:2102.02741</a> [<a href="http://arxiv.org/pdf/2102.02741" target="_blank">pdf</a>]

<h2>Semi-Supervised Action Recognition with Temporal Contrastive Learning. (arXiv:2102.02751v1 [cs.CV])</h2>
<h3>Ankit Singh, Omprakash Chakraborty, Ashutosh Varshney, Rameswar Panda, Rogerio Feris, Kate Saenko, Abir Das</h3>
<p>Learning to recognize actions from only a handful of labeled videos is a
challenging problem due to the scarcity of tediously collected activity labels.
We approach this problem by learning a two-pathway temporal contrastive model
using unlabeled videos at two different speeds leveraging the fact that
changing video speed does not change an action. Specifically, we propose to
maximize the similarity between encoded representations of the same video at
two different speeds as well as minimize the similarity between different
videos played at different speeds. This way we use the rich supervisory
information in terms of 'time' that is present in otherwise unsupervised pool
of videos. With this simple yet effective strategy of manipulating video
playback rates, we considerably outperform video extensions of sophisticated
state-of-the-art semi-supervised image recognition methods across multiple
diverse benchmark datasets and network architectures. Interestingly, our
proposed approach benefits from out-of-domain unlabeled videos showing
generalization and robustness. We also perform rigorous ablations and analysis
to validate our approach.
</p>
<a href="http://arxiv.org/abs/2102.02751" target="_blank">arXiv:2102.02751</a> [<a href="http://arxiv.org/pdf/2102.02751" target="_blank">pdf</a>]

<h2>Only a Matter of Style: Age Transformation Using a Style-Based Regression Model. (arXiv:2102.02754v1 [cs.CV])</h2>
<h3>Yuval Alaluf, Or Patashnik, Daniel Cohen-Or</h3>
<p>The task of age transformation illustrates the change of an individual's
appearance over time. Accurately modeling this complex transformation over an
input facial image is extremely challenging as it requires making convincing
and possibly large changes to facial features and head shape, while still
preserving the input identity. In this work, we present an image-to-image
translation method that learns to directly encode real facial images into the
latent space of a pre-trained unconditional GAN (e.g., StyleGAN) subject to a
given aging shift. We employ a pre-trained age regression network used to
explicitly guide the encoder in generating the latent codes corresponding to
the desired age. In this formulation, our method approaches the continuous
aging process as a regression task between the input age and desired target
age, providing fine-grained control over the generated image. Moreover, unlike
other approaches that operate solely in the latent space using a prior on the
path controlling age, our method learns a more disentangled, non-linear path.
Finally, we demonstrate that the end-to-end nature of our approach, coupled
with the rich semantic latent space of StyleGAN, allows for further editing of
the generated images. Qualitative and quantitative evaluations show the
advantages of our method compared to state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2102.02754" target="_blank">arXiv:2102.02754</a> [<a href="http://arxiv.org/pdf/2102.02754" target="_blank">pdf</a>]

<h2>Instance-based learning using the Half-Space Proximal Graph. (arXiv:2102.02755v1 [cs.LG])</h2>
<h3>Ariana Talamantes, Edgar Chavez</h3>
<p>The primary example of instance-based learning is the $k$-nearest neighbor
rule (kNN), praised for its simplicity and the capacity to adapt to new unseen
data and toss away old data. The main disadvantages often mentioned are the
classification complexity, which is $O(n)$, and the estimation of the parameter
$k$, the number of nearest neighbors to be used. The use of indexes at
classification time lifts the former disadvantage, while there is no conclusive
method for the latter.

This paper presents a parameter-free instance-based learning algorithm using
the {\em Half-Space Proximal} (HSP) graph. The HSP neighbors simultaneously
possess proximity and variety concerning the center node. To classify a given
query, we compute its HSP neighbors and apply a simple majority rule over them.
In our experiments, the resulting classifier bettered $KNN$ for any $k$ in a
battery of datasets. This improvement sticks even when applying weighted
majority rules to both kNN and HSP classifiers.

Surprisingly, when using a probabilistic index to approximate the HSP graph
and consequently speeding-up the classification task, our method could {\em
improve} its accuracy in stark contrast with the kNN classifier, which worsens
with a probabilistic index.
</p>
<a href="http://arxiv.org/abs/2102.02755" target="_blank">arXiv:2102.02755</a> [<a href="http://arxiv.org/pdf/2102.02755" target="_blank">pdf</a>]

<h2>On the computational and statistical complexity of over-parameterized matrix sensing. (arXiv:2102.02756v1 [cs.LG])</h2>
<h3>Jiacheng Zhuo, Jeongyeol Kwon, Nhat Ho, Constantine Caramanis</h3>
<p>We consider solving the low rank matrix sensing problem with Factorized
Gradient Descend (FGD) method when the true rank is unknown and over-specified,
which we refer to as over-parameterized matrix sensing. If the ground truth
signal $\mathbf{X}^* \in \mathbb{R}^{d*d}$ is of rank $r$, but we try to
recover it using $\mathbf{F} \mathbf{F}^\top$ where $\mathbf{F} \in
\mathbb{R}^{d*k}$ and $k&gt;r$, the existing statistical analysis falls short, due
to a flat local curvature of the loss function around the global maxima. By
decomposing the factorized matrix $\mathbf{F}$ into separate column spaces to
capture the effect of extra ranks, we show that $\|\mathbf{F}_t \mathbf{F}_t -
\mathbf{X}^*\|_{F}^2$ converges to a statistical error of $\tilde{\mathcal{O}}
({k d \sigma^2/n})$ after
$\tilde{\mathcal{O}}(\frac{\sigma_{r}}{\sigma}\sqrt{\frac{n}{d}})$ number of
iterations where $\mathbf{F}_t$ is the output of FGD after $t$ iterations,
$\sigma^2$ is the variance of the observation noise, $\sigma_{r}$ is the $r$-th
largest eigenvalue of $\mathbf{X}^*$, and $n$ is the number of sample. Our
results, therefore, offer a comprehensive picture of the statistical and
computational complexity of FGD for the over-parameterized matrix sensing
problem.
</p>
<a href="http://arxiv.org/abs/2102.02756" target="_blank">arXiv:2102.02756</a> [<a href="http://arxiv.org/pdf/2102.02756" target="_blank">pdf</a>]

<h2>Designing an Encoder for StyleGAN Image Manipulation. (arXiv:2102.02766v1 [cs.CV])</h2>
<h3>Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or</h3>
<p>Recently, there has been a surge of diverse methods for performing image
editing by employing pre-trained unconditional generators. Applying these
methods on real images, however, remains a challenge, as it necessarily
requires the inversion of the images into their latent space. To successfully
invert a real image, one needs to find a latent code that reconstructs the
input image accurately, and more importantly, allows for its meaningful
manipulation. In this paper, we carefully study the latent space of StyleGAN,
the state-of-the-art unconditional generator. We identify and analyze the
existence of a distortion-editability tradeoff and a distortion-perception
tradeoff within the StyleGAN latent space. We then suggest two principles for
designing encoders in a manner that allows one to control the proximity of the
inversions to regions that StyleGAN was originally trained on. We present an
encoder based on our two principles that is specifically designed for
facilitating editing on real images by balancing these tradeoffs. By evaluating
its performance qualitatively and quantitatively on numerous challenging
domains, including cars and horses, we show that our inversion method, followed
by common editing techniques, achieves superior real-image editing quality,
with only a small reconstruction accuracy drop.
</p>
<a href="http://arxiv.org/abs/2102.02766" target="_blank">arXiv:2102.02766</a> [<a href="http://arxiv.org/pdf/2102.02766" target="_blank">pdf</a>]

<h2>PHASER: a Robust and Correspondence-free Global Pointcloud Registration. (arXiv:2102.02767v1 [cs.RO])</h2>
<h3>Lukas Bernreiter, Lionel Ott, Juan Nieto, Roland Siegwart, Cesar Cadena</h3>
<p>We propose PHASER, a correspondence-free global registration of
sensor-centric pointclouds that is robust to noise, sparsity, and partial
overlaps. Our method can seamlessly handle multimodal information and does not
rely on keypoint nor descriptor preprocessing modules. By exploiting properties
of Fourier analysis, PHASER operates directly on the sensor's signal, fusing
the spectra of multiple channels and computing the 6-DoF transformation based
on correlation. Our registration pipeline starts by finding the most likely
rotation followed by computing the most likely translation. Both estimates are
distributed according to a probability distribution that takes the underlying
manifold into account, i.e., a Bingham and Gaussian distribution, respectively.
This further allows our approach to consider the periodic-nature of rotations
and naturally represent its uncertainty. We extensively compare PHASER against
several well-known registration algorithms on both simulated datasets, and
real-world data acquired using different sensor configurations. Our results
show that PHASER can globally align pointclouds in less than 100ms with an
average accuracy of 2cm and 0.5deg, is resilient against noise, and can handle
partial overlap.
</p>
<a href="http://arxiv.org/abs/2102.02767" target="_blank">arXiv:2102.02767</a> [<a href="http://arxiv.org/pdf/2102.02767" target="_blank">pdf</a>]

<h2>Mask guided attention for fine-grained patchy image classification. (arXiv:2102.02771v1 [cs.CV])</h2>
<h3>Jun Wang, Xiaohan Yu, Yongsheng Gao</h3>
<p>In this work, we present a novel mask guided attention (MGA) method for
fine-grained patchy image classification. The key challenge of fine-grained
patchy image classification lies in two folds, ultra-fine-grained
inter-category variances among objects and very few data available for
training. This motivates us to consider employing more useful supervision
signal to train a discriminative model within limited training samples.
Specifically, the proposed MGA integrates a pre-trained semantic segmentation
model that produces auxiliary supervision signal, i.e., patchy attention mask,
enabling a discriminative representation learning. The patchy attention mask
drives the classifier to filter out the insignificant parts of images (e.g.,
common features between different categories), which enhances the robustness of
MGA for the fine-grained patchy image classification. We verify the
effectiveness of our method on three publicly available patchy image datasets.
Experimental results demonstrate that our MGA method achieves superior
performance on three datasets compared with the state-of-the-art methods. In
addition, our ablation study shows that MGA improves the accuracy by 2.25% and
2% on the SoyCultivarVein and BtfPIS datasets, indicating its practicality
towards solving the fine-grained patchy image classification.
</p>
<a href="http://arxiv.org/abs/2102.02771" target="_blank">arXiv:2102.02771</a> [<a href="http://arxiv.org/pdf/2102.02771" target="_blank">pdf</a>]

<h2>Egalitarian Judgment Aggregation. (arXiv:2102.02785v1 [cs.AI])</h2>
<h3>Sirin Botan, Ronald de Haan, Marija Slavkovik, Zoi Terzopoulou</h3>
<p>Egalitarian considerations play a central role in many areas of social choice
theory. Applications of egalitarian principles range from ensuring everyone
gets an equal share of a cake when deciding how to divide it, to guaranteeing
balance with respect to gender or ethnicity in committee elections. Yet, the
egalitarian approach has received little attention in judgment aggregation -- a
powerful framework for aggregating logically interconnected issues. We make the
first steps towards filling that gap. We introduce axioms capturing two
classical interpretations of egalitarianism in judgment aggregation and situate
these within the context of existing axioms in the pertinent framework of
belief merging. We then explore the relationship between these axioms and
several notions of strategyproofness from social choice theory at large.
Finally, a novel egalitarian judgment aggregation rule stems from our analysis;
we present complexity results concerning both outcome determination and
strategic manipulation for that rule.
</p>
<a href="http://arxiv.org/abs/2102.02785" target="_blank">arXiv:2102.02785</a> [<a href="http://arxiv.org/pdf/2102.02785" target="_blank">pdf</a>]

<h2>Disambiguation of weak supervision with exponential convergence rates. (arXiv:2102.02789v1 [cs.LG])</h2>
<h3>Vivien Cabannes, Francis Bach, Alessandro Rudi</h3>
<p>Machine learning approached through supervised learning requires expensive
annotation of data. This motivates weakly supervised learning, where data are
annotated with incomplete yet discriminative information. In this paper, we
focus on partial labelling, an instance of weak supervision where, from a given
input, we are given a set of potential targets. We review a disambiguation
principle to recover full supervision from weak supervision, and propose an
empirical disambiguation algorithm. We prove exponential convergence rates of
our algorithm under classical learnability assumptions, and we illustrate the
usefulness of our method on practical examples.
</p>
<a href="http://arxiv.org/abs/2102.02789" target="_blank">arXiv:2102.02789</a> [<a href="http://arxiv.org/pdf/2102.02789" target="_blank">pdf</a>]

<h2>RECol: Reconstruction Error Columns for Outlier Detection. (arXiv:2102.02791v1 [cs.LG])</h2>
<h3>J&#xf6;rn Hees, Dayananda Herurkar, Mario Meier</h3>
<p>Detecting outliers or anomalies is a common data analysis task. As a
sub-field of unsupervised machine learning, a large variety of approaches
exist, but the vast majority treats the input features as independent and often
fails to recognize even simple (linear) relationships in the input feature
space. Hence, we introduce RECol, a generic data pre-processing approach to
generate additional columns in a leave-one-out-fashion: For each column, we try
to predict its values based on the other columns, generating reconstruction
error columns. We run experiments across a large variety of common baseline
approaches and benchmark datasets with and without our RECol pre-processing
method and show that the generated reconstruction error feature space generally
seems to support common outlier detection methods and often considerably
improves their ROC-AUC and PR-AUC values.
</p>
<a href="http://arxiv.org/abs/2102.02791" target="_blank">arXiv:2102.02791</a> [<a href="http://arxiv.org/pdf/2102.02791" target="_blank">pdf</a>]

<h2>Im2Vec: Synthesizing Vector Graphics without Vector Supervision. (arXiv:2102.02798v1 [cs.CV])</h2>
<h3>Pradyumna Reddy, Michael Gharbi, Michal Lukac, Niloy J. Mitra</h3>
<p>Vector graphics are widely used to represent fonts, logos, digital artworks,
and graphic designs. But, while a vast body of work has focused on generative
algorithms for raster images, only a handful of options exists for vector
graphics. One can always rasterize the input graphic and resort to image-based
generative approaches, but this negates the advantages of the vector
representation. The current alternative is to use specialized models that
require explicit supervision on the vector graphics representation at training
time. This is not ideal because large-scale high quality vector-graphics
datasets are difficult to obtain. Furthermore, the vector representation for a
given design is not unique, so models that supervise on the vector
representation are unnecessarily constrained. Instead, we propose a new neural
network that can generate complex vector graphics with varying topologies, and
only requires indirect supervision from readily-available raster training
images (i.e., with no vector counterparts). To enable this, we use a
differentiable rasterization pipeline that renders the generated vector shapes
and composites them together onto a raster canvas. We demonstrate our method on
a range of datasets, and provide comparison with state-of-the-art SVG-VAE and
DeepSVG, both of which require explicit vector graphics supervision. Finally,
we also demonstrate our approach on the MNIST dataset, for which no groundtruth
vector representation is available. Source code, datasets, and more results are
available at this http URL
</p>
<a href="http://arxiv.org/abs/2102.02798" target="_blank">arXiv:2102.02798</a> [<a href="http://arxiv.org/pdf/2102.02798" target="_blank">pdf</a>]

<h2>A Deeper Look into Convolutions via Pruning. (arXiv:2102.02804v1 [cs.CV])</h2>
<h3>Ilke Cugu, Emre Akbas</h3>
<p>Convolutional neural networks (CNNs) are able to attain better visual
recognition performance than fully connected neural networks despite having
much less parameters due to their parameter sharing principle. Hence, modern
architectures are designed to contain a very small number of fully-connected
layers, often at the end, after multiple layers of convolutions. It is
interesting to observe that we can replace large fully-connected layers with
relatively small groups of tiny matrices applied on the entire image. Moreover,
although this strategy already reduces the number of parameters, most of the
convolutions can be eliminated as well, without suffering any loss in
recognition performance. However, there is no solid recipe to detect this
hidden subset of convolutional neurons that is responsible for the majority of
the recognition work. Hence, in this work, we use the matrix characteristics
based on eigenvalues in addition to the classical weight-based importance
assignment approach for pruning to shed light on the internal mechanisms of a
widely used family of CNNs, namely residual neural networks (ResNets), for the
image classification problem using CIFAR-10, CIFAR-100 and Tiny ImageNet
datasets.
</p>
<a href="http://arxiv.org/abs/2102.02804" target="_blank">arXiv:2102.02804</a> [<a href="http://arxiv.org/pdf/2102.02804" target="_blank">pdf</a>]

<h2>Rethinking Quadratic Regularizers: Explicit Movement Regularization for Continual Learning. (arXiv:2102.02805v1 [cs.LG])</h2>
<h3>Ekdeep Singh Lubana, Puja Trivedi, Robert P. Dick</h3>
<p>Quadratic regularizers are often used for mitigating catastrophic forgetting
in deep neural networks (DNNs), but are unable to compete with recent continual
learning methods. To understand this behavior, we analyze parameter updates
under quadratic regularization and demonstrate such regularizers prevent
forgetting of past tasks by implicitly performing a weighted average between
current and previous values of model parameters. Our analysis shows the
inferior performance of quadratic regularizers arises from (a) dependence of
weighted averaging on training hyperparameters, which often results in unstable
training and (b) assignment of lower importance to deeper layers, which are
generally the cause for forgetting in DNNs. To address these limitations, we
propose Explicit Movement Regularization (EMR), a continual learning algorithm
that modifies quadratic regularization to remove the dependence of weighted
averaging on training hyperparameters and uses a relative measure for
importance to avoid problems caused by lower importance assignment to deeper
layers. Compared to quadratic regularization, EMR achieves 6.2% higher average
accuracy and 4.5% lower average forgetting.
</p>
<a href="http://arxiv.org/abs/2102.02805" target="_blank">arXiv:2102.02805</a> [<a href="http://arxiv.org/pdf/2102.02805" target="_blank">pdf</a>]

<h2>Multi-Stage Progressive Image Restoration. (arXiv:2102.02808v1 [cs.CV])</h2>
<h3>Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Ming-Hsuan Yang, Ling Shao</h3>
<p>Image restoration tasks demand a complex balance between spatial details and
high-level contextualized information while recovering images. In this paper,
we propose a novel synergistic design that can optimally balance these
competing goals. Our main proposal is a multi-stage architecture, that
progressively learns restoration functions for the degraded inputs, thereby
breaking down the overall recovery process into more manageable steps.
Specifically, our model first learns the contextualized features using
encoder-decoder architectures and later combines them with a high-resolution
branch that retains local information. At each stage, we introduce a novel
per-pixel adaptive design that leverages in-situ supervised attention to
reweight the local features. A key ingredient in such a multi-stage
architecture is the information exchange between different stages. To this end,
we propose a two-faceted approach where the information is not only exchanged
sequentially from early to late stages, but lateral connections between feature
processing blocks also exist to avoid any loss of information. The resulting
tightly interlinked multi-stage architecture, named as MPRNet, delivers strong
performance gains on ten datasets across a range of tasks including image
deraining, deblurring, and denoising. For example, on the Rain100L, GoPro and
DND datasets, we obtain PSNR gains of 4 dB, 0.81 dB and 0.21 dB, respectively,
compared to the state-of-the-art. The source code and pre-trained models are
available at https://github.com/swz30/MPRNet.
</p>
<a href="http://arxiv.org/abs/2102.02808" target="_blank">arXiv:2102.02808</a> [<a href="http://arxiv.org/pdf/2102.02808" target="_blank">pdf</a>]

<h2>SelfNorm and CrossNorm for Out-of-Distribution Robustness. (arXiv:2102.02811v1 [cs.CV])</h2>
<h3>Zhiqiang Tang, Yunhe Gao, Yi Zhu, Zhi Zhang, Mu Li, Dimitris Metaxas</h3>
<p>Normalization techniques are crucial in stabilizing and accelerating the
training of deep neural networks. However, they are mainly designed for the
independent and identically distributed (IID) data, not satisfying many
real-world out-of-distribution (OOD) situations. Unlike most previous works,
this paper presents two normalization methods, SelfNorm and CrossNorm, to
promote OOD generalization. SelfNorm uses attention to recalibrate statistics
(channel-wise mean and variance), while CrossNorm exchanges the statistics
between feature maps. SelfNorm and CrossNorm can complement each other in OOD
generalization, though exploring different directions in statistics usage.
Extensive experiments on different domains (vision and language), tasks
(classification and segmentation), and settings (supervised and
semi-supervised) show their effectiveness.
</p>
<a href="http://arxiv.org/abs/2102.02811" target="_blank">arXiv:2102.02811</a> [<a href="http://arxiv.org/pdf/2102.02811" target="_blank">pdf</a>]

<h2>FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference. (arXiv:1707.06315v9 [stat.ML] UPDATED)</h2>
<h3>Tianyu Wang, Marco Morucci, M. Usaid Awan, Yameng Liu, Sudeepa Roy, Cynthia Rudin, Alexander Volfovsky</h3>
<p>A classical problem in causal inference is that of matching, where treatment
units need to be matched to control units based on covariate information. In
this work, we propose a method that computes high quality almost-exact matches
for high-dimensional categorical datasets. This method, called FLAME (Fast
Large-scale Almost Matching Exactly), learns a distance metric for matching
using a hold-out training data set. In order to perform matching efficiently
for large datasets, FLAME leverages techniques that are natural for query
processing in the area of database management, and two implementations of FLAME
are provided: the first uses SQL queries and the second uses bit-vector
techniques. The algorithm starts by constructing matches of the highest quality
(exact matches on all covariates), and successively eliminates variables in
order to match exactly on as many variables as possible, while still
maintaining interpretable high-quality matches and balance between treatment
and control groups. We leverage these high quality matches to estimate
conditional average treatment effects (CATEs). Our experiments show that FLAME
scales to huge datasets with millions of observations where existing
state-of-the-art methods fail, and that it achieves significantly better
performance than other matching methods.
</p>
<a href="http://arxiv.org/abs/1707.06315" target="_blank">arXiv:1707.06315</a> [<a href="http://arxiv.org/pdf/1707.06315" target="_blank">pdf</a>]

<h2>Improving the accuracy of nearest-neighbor classification using principled construction and stochastic sampling of training-set centroids. (arXiv:1809.02599v3 [cs.LG] UPDATED)</h2>
<h3>Stephen Whitelam</h3>
<p>A conceptually simple way to classify images is to directly compare test-set
data and training-set data. The accuracy of this approach is limited by the
method of comparison used, and by the extent to which the training-set data
cover configuration space. Here we show that this coverage can be substantially
increased using coarse graining (replacing groups of images by their centroids)
and stochastic sampling (using distinct sets of centroids in combination). We
use the MNIST and Fashion-MNIST data sets to show that a principled
coarse-graining algorithm can convert training images into fewer image
centroids without loss of accuracy of classification of test-set images by
nearest-neighbor classification. Distinct batches of centroids can be used in
combination as a means of stochastically sampling configuration space, and can
classify test-set data more accurately than can the unaltered training set. On
the MNIST and Fashion-MNIST data sets this approach converts nearest-neighbor
classification from a mid-ranking- to an upper-ranking member of the set of
classical machine-learning techniques.
</p>
<a href="http://arxiv.org/abs/1809.02599" target="_blank">arXiv:1809.02599</a> [<a href="http://arxiv.org/pdf/1809.02599" target="_blank">pdf</a>]

<h2>First-order Newton-type Estimator for Distributed Estimation and Inference. (arXiv:1811.11368v2 [stat.ML] UPDATED)</h2>
<h3>Xi Chen, Weidong Liu, Yichen Zhang</h3>
<p>This paper studies distributed estimation and inference for a general
statistical problem with a convex loss that could be non-differentiable. For
the purpose of efficient computation, we restrict ourselves to stochastic
first-order optimization, which enjoys low per-iteration complexity. To
motivate the proposed method, we first investigate the theoretical properties
of a straightforward Divide-and-Conquer Stochastic Gradient Descent (DC-SGD)
approach. Our theory shows that there is a restriction on the number of
machines and this restriction becomes more stringent when the dimension $p$ is
large. To overcome this limitation, this paper proposes a new multi-round
distributed estimation procedure that approximates the Newton step only using
stochastic subgradient. The key component in our method is the proposal of a
computationally efficient estimator of $\Sigma^{-1} w$, where $\Sigma$ is the
population Hessian matrix and $w$ is any given vector. Instead of estimating
$\Sigma$ (or $\Sigma^{-1}$) that usually requires the second-order
differentiability of the loss, the proposed First-Order Newton-type Estimator
(FONE) directly estimates the vector of interest $\Sigma^{-1} w$ as a whole and
is applicable to non-differentiable losses. Our estimator also facilitates the
inference for the empirical risk minimizer. It turns out that the key term in
the limiting covariance has the form of $\Sigma^{-1} w$, which can be estimated
by FONE.
</p>
<a href="http://arxiv.org/abs/1811.11368" target="_blank">arXiv:1811.11368</a> [<a href="http://arxiv.org/pdf/1811.11368" target="_blank">pdf</a>]

<h2>Variational Federated Multi-Task Learning. (arXiv:1906.06268v2 [cs.LG] UPDATED)</h2>
<h3>Luca Corinzia, Ami Beuret, Joachim M. Buhmann</h3>
<p>In federated learning, a central server coordinates the training of a single
model on a massively distributed network of devices. This setting can be
naturally extended to a multi-task learning framework, to handle real-world
federated datasets that typically show strong statistical heterogeneity among
devices. Despite federated multi-task learning being shown to be an effective
paradigm for real-world datasets, it has been applied only on convex models. In
this work, we introduce VIRTUAL, an algorithm for federated multi-task learning
for general non-convex models. In VIRTUAL the federated network of the server
and the clients is treated as a star-shaped Bayesian network, and learning is
performed on the network using approximated variational inference. We show that
this method is effective on real-world federated datasets, outperforming the
current state-of-the-art for federated learning, and concurrently allowing
sparser gradient updates.
</p>
<a href="http://arxiv.org/abs/1906.06268" target="_blank">arXiv:1906.06268</a> [<a href="http://arxiv.org/pdf/1906.06268" target="_blank">pdf</a>]

<h2>Semantic Segmentation for Compound figures. (arXiv:1912.07142v3 [cs.CV] UPDATED)</h2>
<h3>Weixin Jiang, Eric Schwenker, Maria Chan, Oliver Cossairt</h3>
<p>Scientific literature contains large volumes of unstructured data,with over
30\% of figures constructed as a combination of multiple images, these compound
figures cannot be analyzed directly with existing information retrieval tools.
In this paper, we propose a semantic segmentation approach for compound figure
separation, decomposing the compound figures into "master images". Each master
image is one part of a compound figure governed by a subfigure label (typically
"(a), (b), (c), etc"). In this way, the separated subfigures can be easily
associated with the description information in the caption. In particular, we
propose an anchor-based master image detection algorithm, which leverages the
correlation between master images and subfigure labels and locates the master
images in a two-step manner. First, a subfigure label detector is built to
extract the global layout information of the compound figure. Second, the
layout information is combined with local features to locate the master images.
We validate the effectiveness of proposed method on our labeled testing dataset
both quantitatively and qualitatively.
</p>
<a href="http://arxiv.org/abs/1912.07142" target="_blank">arXiv:1912.07142</a> [<a href="http://arxiv.org/pdf/1912.07142" target="_blank">pdf</a>]

<h2>In Nomine Function: Naming Functions in Stripped Binaries with Neural Networks. (arXiv:1912.07946v3 [cs.LG] UPDATED)</h2>
<h3>Fiorella Artuso, Giuseppe Antonio Di Luna, Luca Massarelli, Leonardo Querzoni</h3>
<p>In this paper we investigate the problem of automatically naming pieces of
assembly code. Where by naming we mean assigning to an assembly function a
string of words that would likely be assigned by a human reverse engineer. We
formally and precisely define the framework in which our investigation takes
place. That is we define the problem, we provide reasonable justifications for
the choices that we made for the design of training and the tests. We performed
an analysis on a large real-world corpora constituted by nearly 9 millions of
functions taken from more than 22k softwares. In such framework we test
baselines coming from the field of Natural Language Processing (e.g., Seq2Seq
networks and Transformer). Interestingly, our evaluation shows promising
results beating the state-of-the-art and reaching good performance. We
investigate the applicability of tine-tuning (i.e., taking a model already
trained on a large generic corpora and retraining it for a specific task). Such
technique is popular and well-known in the NLP field. Our results confirm that
fine-tuning is effective even when neural networks are applied to binaries. We
show that a model, pre-trained on the aforementioned corpora, when fine-tuned
has higher performances on specific domains (such as predicting names in system
utilites, malware, etc).
</p>
<a href="http://arxiv.org/abs/1912.07946" target="_blank">arXiv:1912.07946</a> [<a href="http://arxiv.org/pdf/1912.07946" target="_blank">pdf</a>]

<h2>Bidirectional Trajectory Computation for Odometer-Aided Visual-Inertial SLAM. (arXiv:2002.00195v2 [cs.RO] UPDATED)</h2>
<h3>Jinxu Liu, Wei Gao, Zhanyi Hu</h3>
<p>Odometer-aided visual-inertial SLAM systems typically have a good performance
for navigation of wheeled platforms, while they usually suffer from degenerate
cases before the first turning. In this paper, firstly we perform an
observability analysis w.r.t. the extrinsic parameters before the first
turning, which is a complement of the existing results of observability
analyses. Secondly, inspired by the above observability analyses, we propose a
bidirectional trajectory computation method, by which the poses before the
first turning are refined in the backward computation thread, and the real-time
trajectory is adjusted accordingly. Experimental results prove that our
proposed method not only solves the problem of the unobservability of
accelerometer bias and extrinsic parameters before the first turning, but also
results in more accurate trajectories in comparison with the state-of-the-art
approaches.
</p>
<a href="http://arxiv.org/abs/2002.00195" target="_blank">arXiv:2002.00195</a> [<a href="http://arxiv.org/pdf/2002.00195" target="_blank">pdf</a>]

<h2>Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders. (arXiv:2004.02596v4 [cs.AI] UPDATED)</h2>
<h3>Bhushan Kotnis, Carolin Lawrence, Mathias Niepert</h3>
<p>Representation learning for knowledge graphs (KGs) has focused on the problem
of answering simple link prediction queries. In this work we address the more
ambitious challenge of predicting the answers of conjunctive queries with
multiple missing entities. We propose Bi-Directional Query Embedding (BIQE), a
method that embeds conjunctive queries with models based on bi-directional
attention mechanisms. Contrary to prior work, bidirectional self-attention can
capture interactions among all the elements of a query graph. We introduce a
new dataset for predicting the answer of conjunctive query and conduct
experiments that show BIQE significantly outperforming state of the art
baselines.
</p>
<a href="http://arxiv.org/abs/2004.02596" target="_blank">arXiv:2004.02596</a> [<a href="http://arxiv.org/pdf/2004.02596" target="_blank">pdf</a>]

<h2>Increasing-Margin Adversarial (IMA) Training to Improve Adversarial Robustness of Neural Networks. (arXiv:2005.09147v3 [cs.CV] UPDATED)</h2>
<h3>Linhai Ma, Liang Liang</h3>
<p>Convolutional neural network (CNN) has surpassed traditional methods for
med-ical image classification. However, CNN is vulnerable to adversarial
attacks which may lead to disastrous consequences in medical applications.
Although adversarial noises are usually generated by attack algorithms,
white-noise-induced adversarial samples can exist, and therefore the threats
are real. In this study, we propose a novel training method, named IMA, to
improve the robust-ness of CNN against adversarial noises. During training, the
IMA method in-creases the margins of training samples in the input space, i.e.,
moving CNN de-cision boundaries far away from the training samples to improve
robustness. The IMA method is evaluated on four publicly available datasets
under strong 100-PGD white-box adversarial attacks, and the results show that
the proposed meth-od significantly improved CNN classification accuracy on
noisy data while keep-ing a relatively high accuracy on clean data. We hope our
approach may facilitate the development of robust applications in medical
field.
</p>
<a href="http://arxiv.org/abs/2005.09147" target="_blank">arXiv:2005.09147</a> [<a href="http://arxiv.org/pdf/2005.09147" target="_blank">pdf</a>]

<h2>Interferobot: aligning an optical interferometer by a reinforcement learning agent. (arXiv:2006.02252v2 [cs.RO] UPDATED)</h2>
<h3>Dmitry Sorokin, Alexander Ulanov, Ekaterina Sazhina, Alexander Lvovsky</h3>
<p>Limitations in acquiring training data restrict potential applications of
deep reinforcement learning (RL) methods to the training of real-world robots.
Here we train an RL agent to align a Mach-Zehnder interferometer, which is an
essential part of many optical experiments, based on images of interference
fringes acquired by a monocular camera. The agent is trained in a simulated
environment, without any hand-coded features or a priori information about the
physics, and subsequently transferred to a physical interferometer. Thanks to a
set of domain randomizations simulating uncertainties in physical measurements,
the agent successfully aligns this interferometer without any fine tuning,
achieving a performance level of a human expert.
</p>
<a href="http://arxiv.org/abs/2006.02252" target="_blank">arXiv:2006.02252</a> [<a href="http://arxiv.org/pdf/2006.02252" target="_blank">pdf</a>]

<h2>Unifying Regularisation Methods for Continual Learning. (arXiv:2006.06357v2 [cs.LG] UPDATED)</h2>
<h3>Frederik Benzing</h3>
<p>Continual Learning addresses the challenge of learning a number of different
tasks sequentially. The goal of maintaining knowledge of earlier tasks without
re-accessing them starkly conflicts with standard SGD training for artificial
neural networks. An influential method to tackle this problem without storing
old data are so-called regularisation approaches. They measure the importance
of each parameter for solving a given task and subsequently protect important
parameters from large changes. In the literature, three ways to measure
parameter importance have been put forward and they have inspired a large body
of follow-up work. Here, we present strong theoretical and empirical evidence
that these three methods, Elastic Weight Consolidation (EWC), Synaptic
Intelligence (SI) and Memory Aware Synapses (MAS), are surprisingly similar and
are all linked to the same theoretical quantity. Concretely, we show that,
despite stemming from very different motivations, both SI and MAS approximate
the square root of the Fisher Information, with the Fisher being the
theoretically justified basis of EWC. Moreover, we show that for SI the
relation to the Fisher -- and in fact its performance -- is due to a previously
unknown bias. On top of uncovering unknown similarities and unifying
regularisation approaches, we also demonstrate that our insights enable
practical performance improvements for large batch training.
</p>
<a href="http://arxiv.org/abs/2006.06357" target="_blank">arXiv:2006.06357</a> [<a href="http://arxiv.org/pdf/2006.06357" target="_blank">pdf</a>]

<h2>Disentangled Representation Learning and Generation with Manifold Optimization. (arXiv:2006.07046v2 [cs.LG] UPDATED)</h2>
<h3>Arun Pandey, Michael Fanuel, Joachim Schreurs, Johan A. K. Suykens</h3>
<p>Disentanglement is a useful property in representation learning which
increases the interpretability of generative models such as Variational
Auto-Encoders (VAE), Generative Adversarial Models, and their many variants.
Typically in such models, an increase in disentanglement performance is
traded-off with generation quality. In the context of latent space models, this
work presents a representation learning framework that explicitly promotes
disentanglement by encouraging orthogonal directions of variations. The
proposed objective is the sum of an auto-encoder error term along with a
Principal Component Analysis reconstruction error in the feature space. This
has an interpretation of a Restricted Kernel Machine with an interconnection
matrix on the Stiefel manifold. Our analysis shows that such a construction
promotes disentanglement by matching the principal directions in latent space
with the directions of orthogonal variation in data space. The training
algorithm involves a stochastic optimization method on the Stiefel manifold,
which increases only marginally the computing time compared to an analogous
VAE. Our theoretical discussion and various experiments show that the proposed
model improves over many VAE variants in terms of both generation quality and
disentangled representation learning.
</p>
<a href="http://arxiv.org/abs/2006.07046" target="_blank">arXiv:2006.07046</a> [<a href="http://arxiv.org/pdf/2006.07046" target="_blank">pdf</a>]

<h2>Deep Implicit Coordination Graphs for Multi-agent Reinforcement Learning. (arXiv:2006.11438v2 [cs.LG] UPDATED)</h2>
<h3>Sheng Li, Jayesh K. Gupta, Peter Morales, Ross Allen, Mykel J. Kochenderfer</h3>
<p>Multi-agent reinforcement learning (MARL) requires coordination to
efficiently solve certain tasks. Fully centralized control is often infeasible
in such domains due to the size of joint action spaces. Coordination graph
based formalization allows reasoning about the joint action based on the
structure of interactions. However, they often require domain expertise in
their design. This paper introduces the deep implicit coordination graph (DICG)
architecture for such scenarios. DICG consists of a module for inferring the
dynamic coordination graph structure which is then used by a graph neural
network based module to learn to implicitly reason about the joint actions or
values. DICG allows learning the tradeoff between full centralization and
decentralization via standard actor-critic methods to significantly improve
coordination for domains with large number of agents. We apply DICG to both
centralized-training-centralized-execution and
centralized-training-decentralized-execution regimes. We demonstrate that DICG
solves the relative overgeneralization pathology in predatory-prey tasks as
well as outperforms various MARL baselines on the challenging StarCraft II
Multi-agent Challenge (SMAC) and traffic junction environments.
</p>
<a href="http://arxiv.org/abs/2006.11438" target="_blank">arXiv:2006.11438</a> [<a href="http://arxiv.org/pdf/2006.11438" target="_blank">pdf</a>]

<h2>Adaptive Discretization for Adversarial Lipschitz Bandits. (arXiv:2006.12367v2 [cs.LG] UPDATED)</h2>
<h3>Chara Podimata, Aleksandrs Slivkins</h3>
<p>Lipschitz bandits is a prominent version of multi-armed bandits that studies
large, structured action spaces such as the [0,1] interval, where similar
actions are guaranteed to have similar rewards. A central theme here is the
adaptive discretization of the action space, which gradually "zooms in" on the
more promising regions thereof. The goal is to take advantage of "nicer"
problem instances, while retaining near-optimal worst-case performance. While
the stochastic version of the problem is well-understood, the general version
with adversarial rewards is not.

We provide the first algorithm for adaptive discretization in the adversarial
version, and derive instance-dependent regret bounds. In particular, we recover
the worst-case optimal regret bound for the adversarial version, and the
instance-dependent regret bound for the stochastic version. Further, an
application of our algorithm to dynamic pricing (where a seller repeatedly
adjusts prices for a product) enjoys these regret bounds without any smoothness
assumptions.
</p>
<a href="http://arxiv.org/abs/2006.12367" target="_blank">arXiv:2006.12367</a> [<a href="http://arxiv.org/pdf/2006.12367" target="_blank">pdf</a>]

<h2>Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors. (arXiv:2006.15417v3 [cs.CV] UPDATED)</h2>
<h3>Ruihan Zhang, Prashan Madumal, Tim Miller, Krista A. Ehinger, Benjamin I. P. Rubinstein</h3>
<p>Convolutional neural network (CNN) models for computer vision are powerful
but lack explainability in their most basic form. This deficiency remains a key
challenge when applying CNNs in important domains. Recent work for explanations
through feature importance of approximate linear models has moved from
input-level features (pixels or segments) to features from mid-layer feature
maps in the form of concept activation vectors (CAVs). CAVs contain
concept-level information and could be learnt via clustering. In this work, we
rethink the ACE algorithm of Ghorbani et al., proposing an alternative
inevitable concept-based explanation (ICE) framework to overcome its
shortcomings. Based on the requirements of fidelity (approximate models to
target models) and interpretability (being meaningful to people), we design
measurements and evaluate a range of matrix factorization methods with our
framework. We find that \emph{non-negative concept activation vectors} (NCAVs)
from non-negative matrix factorization provide superior performance in
interpretability and fidelity based on computational and human subject
experiments. Our framework provides both local and global concept-level
explanations for pre-trained CNN models.
</p>
<a href="http://arxiv.org/abs/2006.15417" target="_blank">arXiv:2006.15417</a> [<a href="http://arxiv.org/pdf/2006.15417" target="_blank">pdf</a>]

<h2>Relaxed-Responsibility Hierarchical Discrete VAEs. (arXiv:2007.07307v2 [stat.ML] UPDATED)</h2>
<h3>Matthew Willetts, Xenia Miscouridou, Stephen Roberts, Chris Holmes</h3>
<p>Successfully training Variational Autoencoders (VAEs) with a hierarchy of
discrete latent variables remains an area of active research.

Vector-Quantised VAEs are a powerful approach to discrete VAEs, but naive
hierarchical extensions can be unstable when training. Leveraging insights from
classical methods of inference we introduce \textit{Relaxed-Responsibility
Vector-Quantisation}, a novel way to parameterise discrete latent variables, a
refinement of relaxed Vector-Quantisation that gives better performance and
more stable training. This enables a novel approach to hierarchical discrete
variational autoencoders with numerous layers of latent variables (here up to
32) that we train end-to-end. Within hierarchical probabilistic deep generative
models with discrete latent variables trained end-to-end, we achieve
state-of-the-art bits-per-dim results for various standard datasets. % Unlike
discrete VAEs with a single layer of latent variables, we can produce samples
by ancestral sampling: it is not essential to train a second autoregressive
generative model over the learnt latent representations to then sample from and
then decode. % Moreover, that latter approach in these deep hierarchical models
would require thousands of forward passes to generate a single sample. Further,
we observe different layers of our model become associated with different
aspects of the data.
</p>
<a href="http://arxiv.org/abs/2007.07307" target="_blank">arXiv:2007.07307</a> [<a href="http://arxiv.org/pdf/2007.07307" target="_blank">pdf</a>]

<h2>An Empirical Survey of Data Augmentation for Time Series Classification with Neural Networks. (arXiv:2007.15951v2 [cs.LG] UPDATED)</h2>
<h3>Brian Kenji Iwana, Seiichi Uchida</h3>
<p>In recent times, deep artificial neural networks have achieved many successes
in pattern recognition. Part of this success can be attributed to the reliance
on big data to increase generalization. However, in the field of time series
recognition, many datasets are often very small. One method of addressing this
problem is through the use of data augmentation. In this paper, we survey data
augmentation techniques for time series and their application to time series
classification with neural networks. We outline four families of time series
data augmentation, including transformation-based methods, pattern mixing,
generative models, and decomposition methods, and detail their taxonomy.
Furthermore, we empirically evaluate 12 time series data augmentation methods
on 128 time series classification datasets with 6 different types of neural
networks. Through the results, we are able to analyze the characteristics,
advantages and disadvantages, and recommendations of each data augmentation
method. This survey aims to help in the selection of time series data
augmentation for neural network applications.
</p>
<a href="http://arxiv.org/abs/2007.15951" target="_blank">arXiv:2007.15951</a> [<a href="http://arxiv.org/pdf/2007.15951" target="_blank">pdf</a>]

<h2>Noise-Response Analysis of Deep Neural Networks Quantifies Robustness and Fingerprints Structural Malware. (arXiv:2008.00123v2 [cs.LG] UPDATED)</h2>
<h3>N. Benjamin Erichson, Dane Taylor, Qixuan Wu, Michael W. Mahoney</h3>
<p>The ubiquity of deep neural networks (DNNs), cloud-based training, and
transfer learning is giving rise to a new cybersecurity frontier in which
unsecure DNNs have `structural malware' (i.e., compromised weights and
activation pathways). In particular, DNNs can be designed to have backdoors
that allow an adversary to easily and reliably fool an image classifier by
adding a pattern of pixels called a trigger. It is generally difficult to
detect backdoors, and existing detection methods are computationally expensive
and require extensive resources (e.g., access to the training data). Here, we
propose a rapid feature-generation technique that quantifies the robustness of
a DNN, `fingerprints' its nonlinearity, and allows us to detect backdoors (if
present). Our approach involves studying how a DNN responds to noise-infused
images with varying noise intensity, which we summarize with titration curves.
We find that DNNs with backdoors are more sensitive to input noise and respond
in a characteristic way that reveals the backdoor and where it leads (its
`target'). Our empirical results demonstrate that we can accurately detect
backdoors with high confidence orders-of-magnitude faster than existing
approaches (seconds versus hours).
</p>
<a href="http://arxiv.org/abs/2008.00123" target="_blank">arXiv:2008.00123</a> [<a href="http://arxiv.org/pdf/2008.00123" target="_blank">pdf</a>]

<h2>Accuracy and Fairness Trade-offs in Machine Learning: A Stochastic Multi-Objective Approach. (arXiv:2008.01132v2 [cs.LG] UPDATED)</h2>
<h3>Suyun Liu, Luis Nunes Vicente</h3>
<p>In the application of machine learning to real-life decision-making systems,
e.g., credit scoring and criminal justice, the prediction outcomes might
discriminate against people with sensitive attributes, leading to unfairness.
The commonly used strategy in fair machine learning is to include fairness as a
constraint or a penalization term in the minimization of the prediction loss,
which ultimately limits the information given to decision-makers. In this
paper, we introduce a new approach to handle fairness by formulating a
stochastic multi-objective optimization problem for which the corresponding
Pareto fronts uniquely and comprehensively define the accuracy-fairness
trade-offs. We have then applied a stochastic approximation-type method to
efficiently obtain well-spread and accurate Pareto fronts, and by doing so we
can handle training data arriving in a streaming way.
</p>
<a href="http://arxiv.org/abs/2008.01132" target="_blank">arXiv:2008.01132</a> [<a href="http://arxiv.org/pdf/2008.01132" target="_blank">pdf</a>]

<h2>Point Proposal Network: Accelerating Point Source Detection Through Deep Learning. (arXiv:2008.02093v2 [cs.CV] UPDATED)</h2>
<h3>Duncan Tilley, Christopher W. Cleghorn, Kshitij Thorat, Roger Deane</h3>
<p>Point source detection techniques are used to identify and localise point
sources in radio astronomical surveys. With the development of the Square
Kilometre Array (SKA) telescope, survey images will see a massive increase in
size from Gigapixels to Terapixels. Point source detection has already proven
to be a challenge in recent surveys performed by SKA pathfinder telescopes.
This paper proposes the Point Proposal Network (PPN): a point source detector
that utilises deep convolutional neural networks for fast source detection.
Results measured on simulated MeerKAT images show that, although less precise
when compared to leading alternative approaches, PPN performs source detection
faster and is able to scale to large images, unlike the alternative approaches.
</p>
<a href="http://arxiv.org/abs/2008.02093" target="_blank">arXiv:2008.02093</a> [<a href="http://arxiv.org/pdf/2008.02093" target="_blank">pdf</a>]

<h2>Semi-supervised Semantic Segmentation of Prostate and Organs-at-Risk on 3D Pelvic CT Images. (arXiv:2009.09571v3 [cs.CV] UPDATED)</h2>
<h3>Zhuangzhuang Zhang, Tianyu Zhao, Hiram Gay, Baozhou Sun, Weixiong Zhang</h3>
<p>Automated segmentation can assist radiotherapy treatment planning by saving
manual contouring efforts and reducing intra-observer and inter-observer
variations. The recent development of deep learning approaches has revoluted
medical data processing, including semantic segmentation, by dramatically
improving performance. However, training effective deep learning models usually
require a large amount of high-quality labeled data, which are often costly to
collect. We developed a novel semi-supervised adversarial deep learning
approach for 3D pelvic CT image semantic segmentation. Unlike supervised deep
learning methods, the new approach can utilize both annotated and un-annotated
data for training. It generates un-annotated synthetic data by a data
augmentation scheme using generative adversarial networks (GANs). We applied
the new approach to segmenting multiple organs in male pelvic CT images, where
CT images without annotations and GAN-synthesized un-annotated images were used
in semi-supervised learning. Experimental results, evaluated by three metrics
(Dice similarity coefficient, average Hausdorff distance, and average surface
Hausdorff distance), showed that the new method achieved either comparable
performance with substantially fewer annotated images or better performance
with the same amount of annotated data, outperforming the existing
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2009.09571" target="_blank">arXiv:2009.09571</a> [<a href="http://arxiv.org/pdf/2009.09571" target="_blank">pdf</a>]

<h2>Graph Neural Networks with Heterophily. (arXiv:2009.13566v2 [cs.LG] UPDATED)</h2>
<h3>Jiong Zhu, Ryan A. Rossi, Anup Rao, Tung Mai, Nedim Lipka, Nesreen K. Ahmed, Danai Koutra</h3>
<p>Graph Neural Networks (GNNs) have proven to be useful for many different
practical applications. However, many existing GNN models have implicitly
assumed homophily among the nodes connected in the graph, and therefore have
largely overlooked the important setting of heterophily, where most connected
nodes are from different classes. In this work, we propose a novel framework
called CPGNN that generalizes GNNs for graphs with either homophily or
heterophily. The proposed framework incorporates an interpretable compatibility
matrix for modeling the heterophily or homophily level in the graph, which can
be learned in an end-to-end fashion, enabling it to go beyond the assumption of
strong homophily. Theoretically, we show that replacing the compatibility
matrix in our framework with the identity (which represents pure homophily)
reduces to GCN. Our extensive experiments demonstrate the effectiveness of our
approach in more realistic and challenging experimental settings with
significantly less training data compared to previous works: CPGNN variants
achieve state-of-the-art results in heterophily settings with or without
contextual node features, while maintaining comparable performance in homophily
settings.
</p>
<a href="http://arxiv.org/abs/2009.13566" target="_blank">arXiv:2009.13566</a> [<a href="http://arxiv.org/pdf/2009.13566" target="_blank">pdf</a>]

<h2>Motion Generation Using Bilateral Control-Based Imitation Learning with Autoregressive Learning. (arXiv:2011.06192v5 [cs.RO] UPDATED)</h2>
<h3>Ayumu Sasagawa, Sho Sakaino, Toshiaki Tsuji</h3>
<p>Robots that can execute various tasks automatically on behalf of humans are
becoming an increasingly important focus of research in the field of robotics.
Imitation learning has been studied as an efficient and high-performance
method, and imitation learning based on bilateral control has been proposed as
a method that can realize fast motion. However, because this method cannot
implement autoregressive learning, this method may not generate desirable
long-term behavior. Therefore, in this paper, we propose a method of
autoregressive learning for bilateral control-based imitation learning. A new
neural network model for implementing autoregressive learning is proposed. In
this study, three types of experiments are conducted to verify the
effectiveness of the proposed method. The performance is improved compared to
conventional approaches; the proposed method has the highest rate of success.
Owing to the structure and autoregressive learning of the proposed model, the
proposed method can generate the desirable motion for successful tasks and have
a high generalization ability for environmental changes.
</p>
<a href="http://arxiv.org/abs/2011.06192" target="_blank">arXiv:2011.06192</a> [<a href="http://arxiv.org/pdf/2011.06192" target="_blank">pdf</a>]

<h2>Unified Multi-Modal Landmark Tracking for Tightly Coupled Lidar-Visual-Inertial Odometry. (arXiv:2011.06838v2 [cs.RO] UPDATED)</h2>
<h3>David Wisth, Marco Camurri, Sandipan Das, Maurice Fallon</h3>
<p>We present an efficient multi-sensor odometry system for mobile platforms
that jointly optimizes visual, lidar, and inertial information within a single
integrated factor graph. This runs in real-time at full framerate using fixed
lag smoothing. To perform such tight integration, a new method to extract 3D
line and planar primitives from lidar point clouds is presented. This approach
overcomes the suboptimality of typical frame-to-frame tracking methods by
treating the primitives as landmarks and tracking them over multiple scans.
True integration of lidar features with standard visual features and IMU is
made possible using a subtle passive synchronization of lidar and camera
frames. The lightweight formulation of the 3D features allows for real-time
execution on a single CPU. Our proposed system has been tested on a variety of
platforms and scenarios, including underground exploration with a legged robot
and outdoor scanning with a dynamically moving handheld device, for a total
duration of 96 min and 2.4 km traveled distance. In these test sequences, using
only one exteroceptive sensor leads to failure due to either underconstrained
geometry (affecting lidar) or textureless areas caused by aggressive lighting
changes (affecting vision). In these conditions, our factor graph naturally
uses the best information available from each sensor modality without any hard
switches.
</p>
<a href="http://arxiv.org/abs/2011.06838" target="_blank">arXiv:2011.06838</a> [<a href="http://arxiv.org/pdf/2011.06838" target="_blank">pdf</a>]

<h2>Risk-Constrained Thompson Sampling for CVaR Bandits. (arXiv:2011.08046v4 [cs.LG] UPDATED)</h2>
<h3>Joel Q. L. Chang, Qiuyu Zhu, Vincent Y. F. Tan</h3>
<p>The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem
that exemplifies the exploration-exploitation tradeoff. Standard formulations
exclude risk in decision making. Risk notably complicates the basic
reward-maximising objective, in part because there is no universally agreed
definition of it. In this paper, we consider a popular risk measure in
quantitative finance known as the Conditional Value at Risk (CVaR). We explore
the performance of a Thompson Sampling-based algorithm CVaR-TS under this risk
measure. We provide comprehensive comparisons between our regret bounds with
state-of-the-art L/UCB-based algorithms in comparable settings and demonstrate
their clear improvement in performance. We also include numerical simulations
to empirically verify that CVaR-TS outperforms other L/UCB-based algorithms.
</p>
<a href="http://arxiv.org/abs/2011.08046" target="_blank">arXiv:2011.08046</a> [<a href="http://arxiv.org/pdf/2011.08046" target="_blank">pdf</a>]

<h2>Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design. (arXiv:2012.02096v2 [cs.LG] UPDATED)</h2>
<h3>Michael Dennis, Natasha Jaques, Eugene Vinitsky, Alexandre Bayen, Stuart Russell, Andrew Critch, Sergey Levine</h3>
<p>A wide range of reinforcement learning (RL) problems - including robustness,
transfer learning, unsupervised RL, and emergent complexity - require
specifying a distribution of tasks or environments in which a policy will be
trained. However, creating a useful distribution of environments is error
prone, and takes a significant amount of developer time and effort. We propose
Unsupervised Environment Design (UED) as an alternative paradigm, where
developers provide environments with unknown parameters, and these parameters
are used to automatically produce a distribution over valid, solvable
environments. Existing approaches to automatically generating environments
suffer from common failure modes: domain randomization cannot generate
structure or adapt the difficulty of the environment to the agent's learning
progress, and minimax adversarial training leads to worst-case environments
that are often unsolvable. To generate structured, solvable environments for
our protagonist agent, we introduce a second, antagonist agent that is allied
with the environment-generating adversary. The adversary is motivated to
generate environments which maximize regret, defined as the difference between
the protagonist and antagonist agent's return. We call our technique
Protagonist Antagonist Induced Regret Environment Design (PAIRED). Our
experiments demonstrate that PAIRED produces a natural curriculum of
increasingly complex environments, and PAIRED agents achieve higher zero-shot
transfer performance when tested in highly novel environments.
</p>
<a href="http://arxiv.org/abs/2012.02096" target="_blank">arXiv:2012.02096</a> [<a href="http://arxiv.org/pdf/2012.02096" target="_blank">pdf</a>]

<h2>Model-agnostic Fits for Understanding Information Seeking Patterns in Humans. (arXiv:2012.04858v2 [cs.AI] UPDATED)</h2>
<h3>Soumya Chatterjee, Pradeep Shenoy</h3>
<p>In decision making tasks under uncertainty, humans display characteristic
biases in seeking, integrating, and acting upon information relevant to the
task. Here, we reexamine data from previous carefully designed experiments,
collected at scale, that measured and catalogued these biases in aggregate
form. We design deep learning models that replicate these biases in aggregate,
while also capturing individual variation in behavior. A key finding of our
work is that paucity of data collected from each individual subject can be
overcome by sampling large numbers of subjects from the population, while still
capturing individual differences. In addition, we can predict human behavior
with high accuracy without making any assumptions about task goals, reward
structure, or individual biases, thus providing a model-agnostic fit to human
behavior in the task. Such an approach can sidestep potential limitations in
modeler-specified inductive biases, and has implications for computational
modeling of human cognitive function in general, and of human-AI interfaces in
particular.
</p>
<a href="http://arxiv.org/abs/2012.04858" target="_blank">arXiv:2012.04858</a> [<a href="http://arxiv.org/pdf/2012.04858" target="_blank">pdf</a>]

<h2>FcaNet: Frequency Channel Attention Networks. (arXiv:2012.11879v3 [cs.CV] UPDATED)</h2>
<h3>Zequn Qin, Pengyi Zhang, Fei Wu, Xi Li</h3>
<p>Attention mechanism, especially channel attention, has gained great success
in the computer vision field. Many works focus on how to design efficient
channel attention mechanisms while ignoring a fundamental problem, i.e., using
global average pooling (GAP) as the unquestionable pre-processing method. In
this work, we start from a different view and rethink channel attention using
frequency analysis. Based on the frequency analysis, we mathematically prove
that the conventional GAP is a special case of the feature decomposition in the
frequency domain. With the proof, we naturally generalize the pre-processing of
channel attention mechanism in the frequency domain and propose FcaNet with
novel multi-spectral channel attention. The proposed method is simple but
effective. We can change only one line of code in the calculation to implement
our method within existing channel attention methods. Moreover, the proposed
method achieves state-of-the-art results compared with other channel attention
methods on image classification, object detection, and instance segmentation
tasks. Our method could improve by 1.8% in terms of Top-1 accuracy on ImageNet
compared with the baseline SENet-50, with the same number of parameters and the
same computational cost. Our code and models are publicly available at
https://github.com/cfzd/FcaNet.
</p>
<a href="http://arxiv.org/abs/2012.11879" target="_blank">arXiv:2012.11879</a> [<a href="http://arxiv.org/pdf/2012.11879" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Control of Valves. (arXiv:2012.14668v2 [cs.LG] UPDATED)</h2>
<h3>Rajesh Siraskar</h3>
<p>This paper is a study of reinforcement learning (RL) as an optimal-control
strategy for control of nonlinear valves. It is evaluated against the PID
(proportional-integral-derivative) strategy, using a unified framework. RL is
an autonomous learning mechanism that learns by interacting with its
environment. It is gaining increasing attention in the world of control systems
as a means of building optimal-controllers for challenging dynamic and
nonlinear processes. Published RL research often uses open-source tools (Python
and OpenAI Gym environments). We use MATLAB's recently launched (R2019a)
Reinforcement Learning Toolbox to develop the valve controller; trained using
the DDPG (Deep Deterministic Policy-Gradient) algorithm and Simulink to
simulate the nonlinear valve and create the experimental test-bench for
evaluation. Simulink allows industrial engineers to quickly adapt and
experiment with other systems of their choice. Results indicate that the RL
controller is extremely good at tracking the signal with speed and produces a
lower error with respect to the reference signal. The PID, however, is better
at disturbance rejection and hence provides a longer life for the valves.
Successful machine learning involves tuning many hyperparameters requiring
significant investment of time and efforts. We introduce "Graded Learning" as a
simplified, application oriented adaptation of the more formal and algorithmic
"Curriculum for Reinforcement Learning". It is shown via experiments that it
helps converge the learning task of complex non-linear real world systems.
Finally, experiential learnings gained from this research are corroborated
against published research.
</p>
<a href="http://arxiv.org/abs/2012.14668" target="_blank">arXiv:2012.14668</a> [<a href="http://arxiv.org/pdf/2012.14668" target="_blank">pdf</a>]

<h2>The joint role of geometry and illumination on material recognition. (arXiv:2101.02496v2 [cs.CV] UPDATED)</h2>
<h3>Manuel Lagunas, Ana Serrano, Diego Gutierrez, Belen Masia</h3>
<p>Observing and recognizing materials is a fundamental part of our daily life.
Under typical viewing conditions, we are capable of effortlessly identifying
the objects that surround us and recognizing the materials they are made of.
Nevertheless, understanding the underlying perceptual processes that take place
to accurately discern the visual properties of an object is a long-standing
problem. In this work, we perform a comprehensive and systematic analysis of
how the interplay of geometry, illumination, and their spatial frequencies
affects human performance on material recognition tasks. We carry out
large-scale behavioral experiments where participants are asked to recognize
different reference materials among a pool of candidate samples. In the
different experiments, we carefully sample the information in the frequency
domain of the stimuli. From our analysis, we find significant first-order
interactions between the geometry and the illumination, of both the reference
and the candidates. In addition, we observe that simple image statistics and
higher-order image histograms do not correlate with human performance.
Therefore, we perform a high-level comparison of highly non-linear statistics
by training a deep neural network on material recognition tasks. Our results
show that such models can accurately classify materials, which suggests that
they are capable of defining a meaningful representation of material appearance
from labeled proximal image data. Last, we find preliminary evidence that these
highly non-linear models and humans may use similar high-level factors for
material recognition tasks.
</p>
<a href="http://arxiv.org/abs/2101.02496" target="_blank">arXiv:2101.02496</a> [<a href="http://arxiv.org/pdf/2101.02496" target="_blank">pdf</a>]

<h2>Robustness of on-device Models: Adversarial Attack to Deep Learning Models on Android Apps. (arXiv:2101.04401v2 [cs.LG] UPDATED)</h2>
<h3>Yujin Huang, Han Hu, Chunyang Chen</h3>
<p>Deep learning has shown its power in many applications, including object
detection in images, natural-language understanding, and speech recognition. To
make it more accessible to end users, many deep learning models are now
embedded in mobile apps. Compared to offloading deep learning from smartphones
to the cloud, performing machine learning on-device can help improve latency,
connectivity, and power consumption. However, most deep learning models within
Android apps can easily be obtained via mature reverse engineering, while the
models' exposure may invite adversarial attacks. In this study, we propose a
simple but effective approach to hacking deep learning models using adversarial
attacks by identifying highly similar pre-trained models from TensorFlow Hub.
All 10 real-world Android apps in the experiment are successfully attacked by
our approach. Apart from the feasibility of the model attack, we also carry out
an empirical study that investigates the characteristics of deep learning
models used by hundreds of Android apps on Google Play. The results show that
many of them are similar to each other and widely use fine-tuning techniques to
pre-trained models on the Internet.
</p>
<a href="http://arxiv.org/abs/2101.04401" target="_blank">arXiv:2101.04401</a> [<a href="http://arxiv.org/pdf/2101.04401" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Active High Frequency Trading. (arXiv:2101.07107v2 [cs.LG] UPDATED)</h2>
<h3>Antonio Briola, Jeremy Turiel, Riccardo Marcaccioli, Tomaso Aste</h3>
<p>We introduce the first end-to-end Deep Reinforcement Learning (DRL) based
framework for active high frequency trading. We train DRL agents to trade one
unit of Intel Corporation stock by employing the Proximal Policy Optimization
algorithm. The training is performed on three contiguous months of high
frequency Limit Order Book data, of which the last month constitutes the
validation data. In order to maximise the signal to noise ratio in the training
data, we compose the latter by only selecting training samples with largest
price changes. The test is then carried out on the following month of data.
Hyperparameters are tuned using the Sequential Model Based Optimization
technique. We consider three different state characterizations, which differ in
their LOB-based meta-features. Analysing the agents' performances on test data,
we argue that the agents are able to create a dynamic representation of the
underlying environment. They identify occasional regularities present in the
data and exploit them to create long-term profitable trading strategies.
Indeed, agents learn trading strategies able to produce stable positive returns
in spite of the highly stochastic and non-stationary environment.
</p>
<a href="http://arxiv.org/abs/2101.07107" target="_blank">arXiv:2101.07107</a> [<a href="http://arxiv.org/pdf/2101.07107" target="_blank">pdf</a>]

<h2>TCLR: Temporal Contrastive Learning for Video Representation. (arXiv:2101.07974v2 [cs.CV] UPDATED)</h2>
<h3>Ishan Dave, Rohit Gupta, Mamshad Nayeem Rizve, Mubarak Shah</h3>
<p>Contrastive learning has nearly closed the gap between supervised and
self-supervised learning of image representations. Existing extensions of
contrastive learning to the domain of video data however do not explicitly
attempt to represent the internal distinctiveness across the temporal dimension
of video clips. We develop a new temporal contrastive learning framework
consisting of two novel losses to improve upon existing contrastive
self-supervised video representation learning methods. The first loss adds the
task of discriminating between non-overlapping clips from the same video,
whereas the second loss aims to discriminate between timesteps of the feature
map of an input clip in order to increase the temporal diversity of the
features. Temporal contrastive learning achieves significant improvement over
the state-of-the-art results in downstream video understanding tasks such as
action recognition, limited-label action classification, and nearest-neighbor
video retrieval on video datasets across multiple 3D CNN architectures. With
the commonly used 3D-ResNet-18 architecture, we achieve 82.4% (+5.1% increase
over the previous best) top-1 accuracy on UCF101 and 52.9% (+5.4% increase) on
HMDB51 action classification, and 56.2% (+11.7% increase) Top-1 Recall on
UCF101 nearest neighbor video retrieval.
</p>
<a href="http://arxiv.org/abs/2101.07974" target="_blank">arXiv:2101.07974</a> [<a href="http://arxiv.org/pdf/2101.07974" target="_blank">pdf</a>]

<h2>Few-shot Action Recognition with Prototype-centered Attentive Learning. (arXiv:2101.08085v2 [cs.CV] UPDATED)</h2>
<h3>Xiatian Zhu, Antoine Toisoul, Juan-Manuel Prez-Ra, Li Zhang, Brais Martinez, Tao Xiang</h3>
<p>Few-shot action recognition aims to recognize action classes with few
training samples. Most existing methods adopt a meta-learning approach with
episodic training. In each episode, the few samples in a meta-training task are
split into support and query sets. The former is used to build a classifier,
which is then evaluated on the latter using a query-centered loss for model
updating. There are however two major limitations: lack of data efficiency due
to the query-centered only loss design and inability to deal with the support
set outlying samples and inter-class distribution overlapping problems. In this
paper, we overcome both limitations by proposing a new Prototype-centered
Attentive Learning (PAL) model composed of two novel components. First, a
prototype-centered contrastive learning loss is introduced to complement the
conventional query-centered learning objective, in order to make full use of
the limited training samples in each episode. Second, PAL further integrates a
hybrid attentive learning mechanism that can minimize the negative impacts of
outliers and promote class separation. Extensive experiments on four standard
few-shot action benchmarks show that our method clearly outperforms previous
state-of-the-art methods, with the improvement particularly significant (10+\%)
on the most challenging fine-grained action recognition benchmark.
</p>
<a href="http://arxiv.org/abs/2101.08085" target="_blank">arXiv:2101.08085</a> [<a href="http://arxiv.org/pdf/2101.08085" target="_blank">pdf</a>]

<h2>Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments. (arXiv:2101.08152v2 [cs.LG] UPDATED)</h2>
<h3>Daochen Zha, Wenye Ma, Lei Yuan, Xia Hu, Ji Liu</h3>
<p>Exploration under sparse reward is a long-standing challenge of model-free
reinforcement learning. The state-of-the-art methods address this challenge by
introducing intrinsic rewards to encourage exploration in novel states or
uncertain environment dynamics. Unfortunately, methods based on intrinsic
rewards often fall short in procedurally-generated environments, where a
different environment is generated in each episode so that the agent is not
likely to visit the same state more than once. Motivated by how humans
distinguish good exploration behaviors by looking into the entire episode, we
introduce RAPID, a simple yet effective episode-level exploration method for
procedurally-generated environments. RAPID regards each episode as a whole and
gives an episodic exploration score from both per-episode and long-term views.
Those highly scored episodes are treated as good exploration behaviors and are
stored in a small ranking buffer. The agent then imitates the episodes in the
buffer to reproduce the past good exploration behaviors. We demonstrate our
method on several procedurally-generated MiniGrid environments, a
first-person-view 3D Maze navigation task from MiniWorld, and several sparse
MuJoCo tasks. The results show that RAPID significantly outperforms the
state-of-the-art intrinsic reward strategies in terms of sample efficiency and
final performance. The code is available at https://github.com/daochenzha/rapid
</p>
<a href="http://arxiv.org/abs/2101.08152" target="_blank">arXiv:2101.08152</a> [<a href="http://arxiv.org/pdf/2101.08152" target="_blank">pdf</a>]

<h2>NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation. (arXiv:2101.12378v3 [cs.CV] UPDATED)</h2>
<h3>Angtian Wang, Adam Kortylewski, Alan Yuille</h3>
<p>3D pose estimation is a challenging but important task in computer vision. In
this work, we show that standard deep learning approaches to 3D pose estimation
are not robust when objects are partially occluded or viewed from a previously
unseen pose. Inspired by the robustness of generative vision models to partial
occlusion, we propose to integrate deep neural networks with 3D generative
representations of objects into a unified neural architecture that we term
NeMo. In particular, NeMo learns a generative model of neural feature
activations at each vertex on a dense 3D mesh. Using differentiable rendering
we estimate the 3D object pose by minimizing the reconstruction error between
NeMo and the feature representation of the target image. To avoid local optima
in the reconstruction loss, we train the feature extractor to maximize the
distance between the individual feature representations on the mesh using
contrastive learning. Our extensive experiments on PASCAL3D+,
occluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to
partial occlusion and unseen pose compared to standard deep networks, while
retaining competitive performance on regular data. Interestingly, our
experiments also show that NeMo performs reasonably well even when the mesh
representation only crudely approximates the true object geometry with a
cuboid, hence revealing that the detailed 3D geometry is not needed for
accurate 3D pose estimation. The code is publicly available at
https://github.com/Angtian/NeMo.
</p>
<a href="http://arxiv.org/abs/2101.12378" target="_blank">arXiv:2101.12378</a> [<a href="http://arxiv.org/pdf/2101.12378" target="_blank">pdf</a>]

<h2>A Statistician Teaches Deep Learning. (arXiv:2102.01194v2 [stat.ML] UPDATED)</h2>
<h3>G. Jogesh Babu, David Banks, Hyunsoon Cho, David Han, Hailin Sang, Shouyi Wang</h3>
<p>Deep learning (DL) has gained much attention and become increasingly popular
in modern data science. Computer scientists led the way in developing deep
learning techniques, so the ideas and perspectives can seem alien to
statisticians. Nonetheless, it is important that statisticians become involved
-- many of our students need this expertise for their careers. In this paper,
developed as part of a program on DL held at the Statistical and Applied
Mathematical Sciences Institute, we address this culture gap and provide tips
on how to teach deep learning to statistics graduate students. After some
background, we list ways in which DL and statistical perspectives differ,
provide a recommended syllabus that evolved from teaching two iterations of a
DL graduate course, offer examples of suggested homework assignments, give an
annotated list of teaching resources, and discuss DL in the context of two
research areas.
</p>
<a href="http://arxiv.org/abs/2102.01194" target="_blank">arXiv:2102.01194</a> [<a href="http://arxiv.org/pdf/2102.01194" target="_blank">pdf</a>]

<h2>Gaussian Experts Selection using Graphical Models. (arXiv:2102.01496v2 [cs.LG] UPDATED)</h2>
<h3>Hamed Jalali, Martin Pawelczyk, Gjergji Kasneci</h3>
<p>Local approximations are popular methods to scale Gaussian processes (GPs) to
big data. Local approximations reduce time complexity by dividing the original
dataset into subsets and training a local expert on each subset. Aggregating
the experts' prediction is done assuming either conditional dependence or
independence between the experts. Imposing the \emph{conditional independence
assumption} (CI) between the experts renders the aggregation of different
expert predictions time efficient at the cost of poor uncertainty
quantification. On the other hand, modeling dependent experts can provide
precise predictions and uncertainty quantification at the expense of
impractically high computational costs. By eliminating weak experts via a
theory-guided expert selection step, we substantially reduce the computational
cost of aggregating dependent experts while ensuring calibrated uncertainty
quantification. We leverage techniques from the literature on undirected
graphical models, using sparse precision matrices that encode conditional
dependencies between experts to select the most important experts. Moreov
</p>
<a href="http://arxiv.org/abs/2102.01496" target="_blank">arXiv:2102.01496</a> [<a href="http://arxiv.org/pdf/2102.01496" target="_blank">pdf</a>]

<h2>On Query-efficient Planning in MDPs under Linear Realizability of the Optimal State-value Function. (arXiv:2102.02049v2 [cs.LG] UPDATED)</h2>
<h3>Gellert Weisz, Philip Amortila, Barnab&#xe1;s Janzer, Yasin Abbasi-Yadkori, Nan Jiang, Csaba Szepesv&#xe1;ri</h3>
<p>We consider the problem of local planning in fixed-horizon Markov Decision
Processes (MDPs) with a generative model under the assumption that the optimal
value function lies in the span of a feature map that is accessible through the
generative model. As opposed to previous work where linear realizability of all
policies was assumed, we consider the significantly relaxed assumption of a
single linearly realizable (deterministic) policy. A recent lower bound
established that the related problem when the action-value function of the
optimal policy is linearly realizable requires an exponential number of
queries, either in H (the horizon of the MDP) or d (the dimension of the
feature mapping). Their construction crucially relies on having an
exponentially large action set. In contrast, in this work, we establish that
poly$(H, d)$ learning is possible (with state value function realizability)
whenever the action set is small (i.e. O(1)). In particular, we present the
TensorPlan algorithm which uses poly$((dH/\delta)^A)$ queries to find a
$\delta$-optimal policy relative to any deterministic policy for which the
value function is linearly realizable with a parameter from a fixed radius ball
around zero. This is the first algorithm to give a polynomial query complexity
guarantee using only linear-realizability of a single competing value function.
Whether the computation cost is similarly bounded remains an interesting open
question. The upper bound is complemented by a lower bound which proves that in
the infinite-horizon episodic setting, planners that achieve constant
suboptimality need exponentially many queries, either in the dimension or the
number of actions.
</p>
<a href="http://arxiv.org/abs/2102.02049" target="_blank">arXiv:2102.02049</a> [<a href="http://arxiv.org/pdf/2102.02049" target="_blank">pdf</a>]

<h2>Federated Learning on Non-IID Data Silos: An Experimental Study. (arXiv:2102.02079v2 [cs.LG] UPDATED)</h2>
<h3>Qinbin Li, Yiqun Diao, Quan Chen, Bingsheng He</h3>
<p>Machine learning services have been emerging in many data-intensive
applications, and their effectiveness highly relies on large-volume
high-quality training data. However, due to the increasing privacy concerns and
data regulations, training data have been increasingly fragmented, forming
distributed databases of multiple data silos (e.g., within different
organizations and countries). To develop effective machine learning services,
there is a must to exploit data from such distributed databases without
exchanging the raw data. Recently, federated learning (FL) has been a solution
with growing interests, which enables multiple parties to collaboratively train
a machine learning model without exchanging their local data. A key and common
challenge on distributed databases is the heterogeneity of the data
distribution (i.e., non-IID) among the parties. There have been many FL
algorithms to address the learning effectiveness under non-IID data settings.
However, there lacks an experimental study on systematically understanding
their advantages and disadvantages, as previous studies have very rigid data
partitioning strategies among parties, which are hardly representative and
thorough. In this paper, to help researchers better understand and study the
non-IID data setting in federated learning, we propose comprehensive data
partitioning strategies to cover the typical non-IID data cases. Moreover, we
conduct extensive experiments to evaluate state-of-the-art FL algorithms. We
find that non-IID does bring significant challenges in learning accuracy of FL
algorithms, and none of the existing state-of-the-art FL algorithms outperforms
others in all cases. Our experiments provide insights for future studies of
addressing the challenges in data silos.
</p>
<a href="http://arxiv.org/abs/2102.02079" target="_blank">arXiv:2102.02079</a> [<a href="http://arxiv.org/pdf/2102.02079" target="_blank">pdf</a>]

<h2>BeFair: Addressing Fairness in the Banking Sector. (arXiv:2102.02137v2 [cs.LG] UPDATED)</h2>
<h3>Alessandro Castelnovo, Riccardo Crupi, Giulia Del Gamba, Greta Greco, Aisha Naseer, Daniele Regoli, Beatriz San Miguel Gonzalez</h3>
<p>Algorithmic bias mitigation has been one of the most difficult conundrums for
the data science community and Machine Learning (ML) experts. Over several
years, there have appeared enormous efforts in the field of fairness in ML.
Despite the progress toward identifying biases and designing fair algorithms,
translating them into the industry remains a major challenge. In this paper, we
present the initial results of an industrial open innovation project in the
banking sector: we propose a general roadmap for fairness in ML and the
implementation of a toolkit called BeFair that helps to identify and mitigate
bias. Results show that training a model without explicit constraints may lead
to bias exacerbation in the predictions.
</p>
<a href="http://arxiv.org/abs/2102.02137" target="_blank">arXiv:2102.02137</a> [<a href="http://arxiv.org/pdf/2102.02137" target="_blank">pdf</a>]

