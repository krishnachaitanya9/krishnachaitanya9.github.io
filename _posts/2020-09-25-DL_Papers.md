---
title: Latest Deep Learning Papers
date: 2020-10-06 01:49:47 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Data-Driven Assessment of Deep Neural Networks with Random Input Uncertainty. (arXiv:2010.01171v1 [cs.LG])</h2>
<h3>Brendon G. Anderson, Somayeh Sojoudi</h3>
<p>When using deep neural networks to operate safety-critical systems, assessing
the sensitivity of the network outputs when subject to uncertain inputs is of
paramount importance. Such assessment is commonly done using reachability
analysis or robustness certification. However, certification techniques
typically ignore localization information, while reachable set methods can fail
to issue robustness guarantees. Furthermore, many advanced methods are either
computationally intractable in practice or restricted to very specific models.
In this paper, we develop a data-driven optimization-based method capable of
simultaneously certifying the safety of network outputs and localizing them.
The proposed method provides a unified assessment framework, as it subsumes
state-of-the-art reachability analysis and robustness certification. The method
applies to deep neural networks of all sizes and structures, and to random
input uncertainty with a general distribution. We develop sufficient conditions
for the convexity of the underlying optimization, and for the number of data
samples to certify and localize the outputs with overwhelming probability. We
experimentally demonstrate the efficacy and tractability of the method on a
deep ReLU network.
</p>
<a href="http://arxiv.org/abs/2010.01171" target="_blank">arXiv:2010.01171</a> [<a href="http://arxiv.org/pdf/2010.01171" target="_blank">pdf</a>]

<h2>Deep FPF: Gain function approximation in high-dimensional setting. (arXiv:2010.01183v1 [cs.LG])</h2>
<h3>S. Yagiz Olmez, Amirhossein Taghvaei, Prashant G. Mehta</h3>
<p>In this paper, we present a novel approach to approximate the gain function
of the feedback particle filter (FPF). The exact gain function is the solution
of a Poisson equation involving a probability-weighted Laplacian. The numerical
problem is to approximate the exact gain function using only finitely many
particles sampled from the probability distribution.

Inspired by the recent success of the deep learning methods, we represent the
gain function as a gradient of the output of a neural network. Thereupon
considering a certain variational formulation of the Poisson equation, an
optimization problem is posed for learning the weights of the neural network. A
stochastic gradient algorithm is described for this purpose.

The proposed approach has two significant properties/advantages: (i) The
stochastic optimization algorithm allows one to process, in parallel, only a
batch of samples (particles) ensuring good scaling properties with the number
of particles; (ii) The remarkable representation power of neural networks means
that the algorithm is potentially applicable and useful to solve
high-dimensional problems. We numerically establish these two properties and
provide extensive comparison to the existing approaches.
</p>
<a href="http://arxiv.org/abs/2010.01183" target="_blank">arXiv:2010.01183</a> [<a href="http://arxiv.org/pdf/2010.01183" target="_blank">pdf</a>]

<h2>Machine-Learning the Sato--Tate Conjecture. (arXiv:2010.01213v1 [math.NT])</h2>
<h3>Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver</h3>
<p>We apply some of the latest techniques from machine-learning to the
arithmetic of hyperelliptic curves. More precisely we show that, with
impressive accuracy and confidence (between 99 and 100 percent precision), and
in very short time (matter of seconds on an ordinary laptop), a Bayesian
classifier can distinguish between Sato--Tate groups given a small number of
Euler factors for the L-function. Our observations are in keeping with the
Sato-Tate conjecture for curves of low genus. For elliptic curves, this amounts
to distinguishing generic curves (with Sato--Tate group SU(2)) from those with
complex multiplication. In genus 2, a principal component analysis is observed
to separate the generic Sato--Tate group USp(4) from the non-generic groups.
Furthermore in this case, for which there are many more non-generic
possibilities than in the case of elliptic curves, we demonstrate an accurate
characterisation of several Sato--Tate groups with the same identity component.
Throughout, our observations are verified using known results from the
literature and the data available in the LMFDB. The results in this paper
suggest that a machine can be trained to learn the Sato--Tate distributions and
may be able to classify curves much more efficiently than the methods available
in the literature.
</p>
<a href="http://arxiv.org/abs/2010.01213" target="_blank">arXiv:2010.01213</a> [<a href="http://arxiv.org/pdf/2010.01213" target="_blank">pdf</a>]

<h2>WeMix: How to Better Utilize Data Augmentation. (arXiv:2010.01267v1 [cs.LG])</h2>
<h3>Yi Xu, Asaf Noy, Ming Lin, Qi Qian, Hao Li, Rong Jin</h3>
<p>Data augmentation is a widely used training trick in deep learning to improve
the network generalization ability. Despite many encouraging results, several
recent studies did point out limitations of the conventional data augmentation
scheme in certain scenarios, calling for a better theoretical understanding of
data augmentation. In this work, we develop a comprehensive analysis that
reveals pros and cons of data augmentation. The main limitation of data
augmentation arises from the data bias, i.e. the augmented data distribution
can be quite different from the original one. This data bias leads to a
suboptimal performance of existing data augmentation methods. To this end, we
develop two novel algorithms, termed "AugDrop" and "MixLoss", to correct the
data bias in the data augmentation. Our theoretical analysis shows that both
algorithms are guaranteed to improve the effect of data augmentation through
the bias correction, which is further validated by our empirical studies.
Finally, we propose a generic algorithm "WeMix" by combining AugDrop and
MixLoss, whose effectiveness is observed from extensive empirical evaluations.
</p>
<a href="http://arxiv.org/abs/2010.01267" target="_blank">arXiv:2010.01267</a> [<a href="http://arxiv.org/pdf/2010.01267" target="_blank">pdf</a>]

<h2>Learning the Step-size Policy for the Limited-Memory Broyden-Fletcher-Goldfarb-Shanno Algorithm. (arXiv:2010.01311v1 [cs.LG])</h2>
<h3>Lucas N. Egidio, Anders Hansson, Bo Wahlberg</h3>
<p>We consider the problem of how to learn a step-size policy for the
Limited-Memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm. This is a
limited computational memory quasi-Newton method widely used for deterministic
unconstrained optimization but currently avoided in large-scale problems for
requiring step sizes to be provided at each iteration. Existing methodologies
for the step size selection for L-BFGS use heuristic tuning of design
parameters and massive re-evaluations of the objective function and gradient to
find appropriate step-lengths. We propose a neural network architecture with
local information of the current iterate as the input. The step-length policy
is learned from data of similar optimization problems, avoids additional
evaluations of the objective function, and guarantees that the output step
remains inside a pre-defined interval. The corresponding training procedure is
formulated as a stochastic optimization problem using the backpropagation
through time algorithm. The performance of the proposed method is evaluated on
the MNIST database for handwritten digits. The results show that the proposed
algorithm outperforms heuristically tuned optimizers such as ADAM and RMSprop
in terms of computational time. It performs comparably to more computationally
demanding L-BFGS with backtracking line search. The numerical results also show
that the learned policy generalizes better to high-dimensional problems as
compared to ADAM and RMSprop, highlighting its potential use in large-scale
optimization.
</p>
<a href="http://arxiv.org/abs/2010.01311" target="_blank">arXiv:2010.01311</a> [<a href="http://arxiv.org/pdf/2010.01311" target="_blank">pdf</a>]

<h2>Deep Learning algorithms for solving high dimensional nonlinear Backward Stochastic Differential Equations. (arXiv:2010.01319v1 [math.NA])</h2>
<h3>Lorenc Kapllani, Long Teng</h3>
<p>We study deep learning-based schemes for solving high dimensional nonlinear
backward stochastic differential equations (BSDEs). First we show how to
improve the performances of the proposed scheme in [W. E and J. Han and A.
Jentzen, Commun. Math. Stat., 5 (2017), pp.349-380] regarding computational
time and stability of numerical convergence by using the advanced neural
network architecture instead of the stacked deep neural networks. Furthermore,
the proposed scheme in that work can be stuck in local minima, especially for a
complex solution structure and longer terminal time. To solve this problem, we
investigate to reformulate the problem by including local losses and exploit
the Long Short Term Memory (LSTM) networks which are a type of recurrent neural
networks (RNN). Finally, in order to study numerical convergence and thus
illustrate the improved performances with the proposed methods, we provide
numerical results for several 100-dimensional nonlinear BSDEs including a
nonlinear pricing problem in finance.
</p>
<a href="http://arxiv.org/abs/2010.01319" target="_blank">arXiv:2010.01319</a> [<a href="http://arxiv.org/pdf/2010.01319" target="_blank">pdf</a>]

<h2>A Variational Information Bottleneck Based Method to Compress Sequential Networks for Human Action Recognition. (arXiv:2010.01343v1 [cs.CV])</h2>
<h3>Ayush Srivastava, Oshin Dutta, Prathosh AP, Sumeet Agarwal, Jigyasa Gupta</h3>
<p>In the last few years, compression of deep neural networks has become an
important strand of machine learning and computer vision research. Deep models
require sizeable computational complexity and storage, when used for instance
for Human Action Recognition (HAR) from videos, making them unsuitable to be
deployed on edge devices. In this paper, we address this issue and propose a
method to effectively compress Recurrent Neural Networks (RNNs) such as Gated
Recurrent Units (GRUs) and Long-Short-Term-Memory Units (LSTMs) that are used
for HAR. We use a Variational Information Bottleneck (VIB) theory-based pruning
approach to limit the information flow through the sequential cells of RNNs to
a small subset. Further, we combine our pruning method with a specific
group-lasso regularization technique that significantly improves compression.
The proposed techniques reduce model parameters and memory footprint from
latent representations, with little or no reduction in the validation accuracy
while increasing the inference speed several-fold. We perform experiments on
the three widely used Action Recognition datasets, viz. UCF11, HMDB51, and
UCF101, to validate our approach. It is shown that our method achieves over 70
times greater compression than the nearest competitor with comparable accuracy
for the task of action recognition on UCF11.
</p>
<a href="http://arxiv.org/abs/2010.01343" target="_blank">arXiv:2010.01343</a> [<a href="http://arxiv.org/pdf/2010.01343" target="_blank">pdf</a>]

<h2>An adaptive Hessian approximated stochastic gradient MCMC method. (arXiv:2010.01384v1 [math.NA])</h2>
<h3>Yating Wang, Wei Deng, Guang Lin</h3>
<p>Bayesian approaches have been successfully integrated into training deep
neural networks. One popular family is stochastic gradient Markov chain Monte
Carlo methods (SG-MCMC), which have gained increasing interest due to their
scalability to handle large datasets and the ability to avoid overfitting.
Although standard SG-MCMC methods have shown great performance in a variety of
problems, they may be inefficient when the random variables in the target
posterior densities have scale differences or are highly correlated. In this
work, we present an adaptive Hessian approximated stochastic gradient MCMC
method to incorporate local geometric information while sampling from the
posterior. The idea is to apply stochastic approximation to sequentially update
a preconditioning matrix at each iteration. The preconditioner possesses
second-order information and can guide the random walk of a sampler
efficiently. Instead of computing and saving the full Hessian of the log
posterior, we use limited memory of the sample and their stochastic gradients
to approximate the inverse Hessian-vector multiplication in the updating
formula. Moreover, by smoothly optimizing the preconditioning matrix, our
proposed algorithm can asymptotically converge to the target distribution with
a controllable bias under mild conditions. To reduce the training and testing
computational burden, we adopt a magnitude-based weight pruning method to
enforce the sparsity of the network. Our method is user-friendly and is
scalable to standard SG-MCMC updating rules by implementing an additional
preconditioner. The sparse approximation of inverse Hessian alleviates storage
and computational complexities for large dimensional models. The bias
introduced by stochastic approximation is controllable and can be analyzed
theoretically. Numerical experiments are performed on several problems.
</p>
<a href="http://arxiv.org/abs/2010.01384" target="_blank">arXiv:2010.01384</a> [<a href="http://arxiv.org/pdf/2010.01384" target="_blank">pdf</a>]

<h2>Orthogonal Multi-view Analysis by Successive Approximations via Eigenvectors. (arXiv:2010.01632v1 [cs.LG])</h2>
<h3>Li Wang, Leihong Zhang, Chungen Shen, Ren-cang Li</h3>
<p>We propose a unified framework for multi-view subspace learning to learn
individual orthogonal projections for all views. The framework integrates the
correlations within multiple views, supervised discriminant capacity, and
distance preservation in a concise and compact way. It not only includes
several existing models as special cases, but also inspires new novel models.
To demonstrate its versatility to handle different learning scenarios, we
showcase three new multi-view discriminant analysis models and two new
multi-view multi-label classification ones under this framework. An efficient
numerical method based on successive approximations via eigenvectors is
presented to solve the associated optimization problem. The method is built
upon an iterative Krylov subspace method which can easily scale up for
high-dimensional datasets. Extensive experiments are conducted on various
real-world datasets for multi-view discriminant analysis and multi-view
multi-label classification. The experimental results demonstrate that the
proposed models are consistently competitive to and often better than the
compared methods that do not learn orthogonal projections.
</p>
<a href="http://arxiv.org/abs/2010.01632" target="_blank">arXiv:2010.01632</a> [<a href="http://arxiv.org/pdf/2010.01632" target="_blank">pdf</a>]

<h2>Multivariate Quantile Bayesian Structural Time Series (MQBSTS) Model. (arXiv:2010.01654v1 [stat.ML])</h2>
<h3>Ning Ning</h3>
<p>In this paper, we propose the multivariate quantile Bayesian structural time
series (MQBSTS) model for the joint quantile time series forecast, which is the
first such model for correlated multivariate time series to the author's best
knowledge. The MQBSTS model also enables quantile based feature selection in
its regression component where each time series has its own pool of
contemporaneous external time series predictors, which is the first time that a
fully data-driven quantile feature selection technique applicable to time
series data to the author's best knowledge. Different from most machine
learning algorithms, the MQBSTS model has very few hyper-parameters to tune,
requires small datasets to train, converges fast, and is executable on ordinary
personal computers. Extensive examinations on simulated data and empirical data
confirmed that the MQBSTS model has superior performance in feature selection,
parameter estimation, and forecast.
</p>
<a href="http://arxiv.org/abs/2010.01654" target="_blank">arXiv:2010.01654</a> [<a href="http://arxiv.org/pdf/2010.01654" target="_blank">pdf</a>]

<h2>Learning Time Varying Risk Preferences from Investment Portfolios using Inverse Optimization with Applications on Mutual Funds. (arXiv:2010.01687v1 [q-fin.PM])</h2>
<h3>Shi Yu, Yuxin Chen, Chaosheng Dong</h3>
<p>The fundamental principle in Modern Portfolio Theory (MPT) is based on the
quantification of the portfolio's risk related to performance. Although MPT has
made huge impacts on the investment world and prompted the success and
prevalence of passive investing, it still has shortcomings in real-world
applications. One of the main challenges is that the level of risk an investor
can endure, known as \emph{risk-preference}, is a subjective choice that is
tightly related to psychology and behavioral science in decision making. This
paper presents a novel approach of measuring risk preference from existing
portfolios using inverse optimization on the mean-variance portfolio allocation
framework. Our approach allows the learner to continuously estimate real-time
risk preferences using concurrent observed portfolios and market price data. We
demonstrate our methods on real market data that consists of 20 years of asset
pricing and 10 years of mutual fund portfolio holdings. Moreover, the
quantified risk preference parameters are validated with two well-known risk
measurements currently applied in the field. The proposed methods could lead to
practical and fruitful innovations in automated/personalized portfolio
management, such as Robo-advising, to augment financial advisors' decision
intelligence in a long-term investment horizon.
</p>
<a href="http://arxiv.org/abs/2010.01687" target="_blank">arXiv:2010.01687</a> [<a href="http://arxiv.org/pdf/2010.01687" target="_blank">pdf</a>]

<h2>A Polynomial Time Algorithm for Learning Halfspaces with Tsybakov Noise. (arXiv:2010.01705v1 [cs.LG])</h2>
<h3>Ilias Diakonikolas, Daniel M. Kane, Vasilis Kontonis, Christos Tzamos, Nikos Zarifis</h3>
<p>We study the problem of PAC learning homogeneous halfspaces in the presence
of Tsybakov noise. In the Tsybakov noise model, the label of every sample is
independently flipped with an adversarially controlled probability that can be
arbitrarily close to $1/2$ for a fraction of the samples. {\em We give the
first polynomial-time algorithm for this fundamental learning problem.} Our
algorithm learns the true halfspace within any desired accuracy $\epsilon$ and
succeeds under a broad family of well-behaved distributions including
log-concave distributions. Prior to our work, the only previous algorithm for
this problem required quasi-polynomial runtime in $1/\epsilon$.

Our algorithm employs a recently developed reduction \cite{DKTZ20b} from
learning to certifying the non-optimality of a candidate halfspace. This prior
work developed a quasi-polynomial time certificate algorithm based on
polynomial regression. {\em The main technical contribution of the current
paper is the first polynomial-time certificate algorithm.} Starting from a
non-trivial warm-start, our algorithm performs a novel "win-win" iterative
process which, at each step, either finds a valid certificate or improves the
angle between the current halfspace and the true one. Our warm-start algorithm
for isotropic log-concave distributions involves a number of analytic tools
that may be of broader interest. These include a new efficient method for
reweighting the distribution in order to recenter it and a novel
characterization of the spectrum of the degree-$2$ Chow parameters.
</p>
<a href="http://arxiv.org/abs/2010.01705" target="_blank">arXiv:2010.01705</a> [<a href="http://arxiv.org/pdf/2010.01705" target="_blank">pdf</a>]

<h2>On the Universality of the Double Descent Peak in Ridgeless Regression. (arXiv:2010.01851v1 [stat.ML])</h2>
<h3>David Holzm&#xfc;ller</h3>
<p>We prove a non-asymptotic distribution-independent lower bound for the
expected mean squared generalization error caused by label noise in ridgeless
linear regression. In contrast to previous works, our analysis applies to a
broad class of input distributions with almost surely full-rank feature
matrices, which allows us to cover various types of deterministic or random
feature maps. Our lower bound implies that in the presence of label noise,
ridgeless linear regression does not perform well around the interpolation
threshold for any of these feature maps. We analyze the imposed assumptions in
detail and provide a theory for analytic (random) feature maps. Using this
theory, we can show that our assumptions are satisfied for input distributions
with a (Lebesgue) density and feature maps given by random deep neural networks
with analytic activation functions like sigmoid, tanh, softplus or GELU. As
further examples, we show that feature maps from random Fourier features and
polynomial kernels also satisfy our assumptions. We complement our theory with
further experimental and analytic results.
</p>
<a href="http://arxiv.org/abs/2010.01851" target="_blank">arXiv:2010.01851</a> [<a href="http://arxiv.org/pdf/2010.01851" target="_blank">pdf</a>]

<h2>Smaller generalization error derived for deep compared to shallow residual neural networks. (arXiv:2010.01887v1 [math.NA])</h2>
<h3>Aku Kammonen, Jonas Kiessling, Petr Plech&#xe1;&#x10d;, Mattias Sandberg, Anders Szepessy, Ra&#xfa;l Tempone</h3>
<p>Estimates of the generalization error are proved for a residual neural
network with $L$ random Fourier features layers

$\bar z_{\ell+1}=\bar z_\ell + \text{Re}\sum_{k=1}^K\bar b_{\ell k}e^{{\rm
i}\omega_{\ell k}\bar z_\ell}+ \text{Re}\sum_{k=1}^K\bar c_{\ell k}e^{{\rm
i}\omega'_{\ell k}\cdot x}$. An optimal distribution for the frequencies
$(\omega_{\ell k},\omega'_{\ell k})$ of the random Fourier features $e^{{\rm
i}\omega_{\ell k}\bar z_\ell}$ and $e^{{\rm i}\omega'_{\ell k}\cdot x}$ is
derived. The derivation is based on the corresponding generalization error to
approximate function values $f(x)$. The generalization error turns out to be
smaller than the estimate ${\|\hat f\|^2_{L^1(\mathbb{R}^d)}}/{(LK)}$ of the
generalization error for random Fourier features with one hidden layer and the
same total number of nodes $LK$, in the case the $L^\infty$-norm of $f$ is much
less than the $L^1$-norm of its Fourier transform $\hat f$. This understanding
of an optimal distribution for random features is used to construct a new
training method for a deep residual network that shows promising results.
</p>
<a href="http://arxiv.org/abs/2010.01887" target="_blank">arXiv:2010.01887</a> [<a href="http://arxiv.org/pdf/2010.01887" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Electric Vehicle Routing Problem with Time Windows. (arXiv:2010.02068v1 [cs.LG])</h2>
<h3>Bo Lin, Bissan Ghaddar, Jatin Nathwani</h3>
<p>The past decade has seen a rapid penetration of electric vehicles (EV) in the
market, more and more logistics and transportation companies start to deploy
EVs for service provision. In order to model the operations of a commercial EV
fleet, we utilize the EV routing problem with time windows (EVRPTW). In this
research, we propose an end-to-end deep reinforcement learning framework to
solve the EVRPTW. In particular, we develop an attention model incorporating
the pointer network and a graph embedding technique to parameterize a
stochastic policy for solving the EVRPTW. The model is then trained using
policy gradient with rollout baseline. Our numerical studies show that the
proposed model is able to efficiently solve EVRPTW instances of large sizes
that are not solvable with any existing approaches.
</p>
<a href="http://arxiv.org/abs/2010.02068" target="_blank">arXiv:2010.02068</a> [<a href="http://arxiv.org/pdf/2010.02068" target="_blank">pdf</a>]

<h2>Average-case Acceleration for Bilinear Games and Normal Matrices. (arXiv:2010.02076v1 [math.OC])</h2>
<h3>Carles Domingo-Enrich, Fabian Pedregosa, Damien Scieur</h3>
<p>Advances in generative modeling and adversarial learning have given rise to
renewed interest in smooth games. However, the absence of symmetry in the
matrix of second derivatives poses challenges that are not present in the
classical minimization framework. While a rich theory of average-case analysis
has been developed for minimization problems, little is known in the context of
smooth games. In this work we take a first step towards closing this gap by
developing average-case optimal first-order methods for a subset of smooth
games. We make the following three main contributions. First, we show that for
zero-sum bilinear games the average-case optimal method is the optimal method
for the minimization of the Hamiltonian. Second, we provide an explicit
expression for the optimal method corresponding to normal matrices, potentially
non-symmetric. Finally, we specialize it to matrices with eigenvalues located
in a disk and show a provable speed-up compared to worst-case optimal
algorithms. We illustrate our findings through benchmarks with a varying degree
of mismatch with our assumptions.
</p>
<a href="http://arxiv.org/abs/2010.02076" target="_blank">arXiv:2010.02076</a> [<a href="http://arxiv.org/pdf/2010.02076" target="_blank">pdf</a>]

<h2>AdaLead: A simple and robust adaptive greedy search algorithm for sequence design. (arXiv:2010.02141v1 [cs.LG])</h2>
<h3>Sam Sinai, Richard Wang, Alexander Whatley, Stewart Slocum, Elina Locane, Eric D. Kelsic</h3>
<p>Efficient design of biological sequences will have a great impact across many
industrial and healthcare domains. However, discovering improved sequences
requires solving a difficult optimization problem. Traditionally, this
challenge was approached by biologists through a model-free method known as
"directed evolution", the iterative process of random mutation and selection.
As the ability to build models that capture the sequence-to-function map
improves, such models can be used as oracles to screen sequences before running
experiments. In recent years, interest in better algorithms that effectively
use such oracles to outperform model-free approaches has intensified. These
span from approaches based on Bayesian Optimization, to regularized generative
models and adaptations of reinforcement learning. In this work, we implement an
open-source Fitness Landscape EXploration Sandbox (FLEXS:
github.com/samsinai/FLEXS) environment to test and evaluate these algorithms
based on their optimality, consistency, and robustness. Using FLEXS, we develop
an easy-to-implement, scalable, and robust evolutionary greedy algorithm
(AdaLead). Despite its simplicity, we show that AdaLead is a remarkably strong
benchmark that out-competes more complex state of the art approaches in a
variety of biologically motivated sequence design challenges.
</p>
<a href="http://arxiv.org/abs/2010.02141" target="_blank">arXiv:2010.02141</a> [<a href="http://arxiv.org/pdf/2010.02141" target="_blank">pdf</a>]

<h2>Diversity/Parallelism Trade-off in Distributed Systems with Redundancy. (arXiv:2010.02147v1 [cs.DC])</h2>
<h3>Pei Peng, Emina Soljanin, Philip Whiting</h3>
<p>As numerous machine learning and other algorithms increase in complexity and
data requirements, distributed computing becomes necessary to satisfy the
growing computational and storage demands, because it enables parallel
execution of smaller tasks that make up a large computing job. However, random
fluctuations in task service times lead to straggling tasks with long execution
times. Redundancy, in the form of task replication and erasure coding, provides
diversity that allows a job to be completed when only a subset of redundant
tasks is executed, thus removing the dependency on the straggling tasks. In
situations of constrained resources (here a fixed number of parallel servers),
increasing redundancy reduces the available resources for parallelism. In this
paper, we characterize the diversity vs. parallelism trade-off and identify the
optimal strategy, among replication, coding and splitting, which minimizes the
expected job completion time. We consider three common service time
distributions and establish three models that describe scaling of these
distributions with the task size. We find that different distributions with
different scaling models operate optimally at different levels of redundancy,
and thus may require very different code rates.
</p>
<a href="http://arxiv.org/abs/2010.02147" target="_blank">arXiv:2010.02147</a> [<a href="http://arxiv.org/pdf/2010.02147" target="_blank">pdf</a>]

<h2>Do the laws of physics prohibit counterfactual communication?. (arXiv:1806.01257v5 [quant-ph] UPDATED)</h2>
<h3>Hatim Salih, Will McCutcheon, Jonte Hance, John Rarity</h3>
<p>It has been conjectured that counterfactual communication is impossible, even
for post-selected quantum particles. We strongly challenge this by proposing
exactly such a counterfactual scheme where---unambiguously---none of Alice's
photons that make it has been to Bob. We demonstrate counterfactuality
theoretically and experimentally by means of weak measurements, as well as
conceptually using consistent histories. Importantly, the accuracy of Alice
learning Bob's bit can be made arbitrarily close to unity with no trace left by
Bob on Alice's photon.
</p>
<a href="http://arxiv.org/abs/1806.01257" target="_blank">arXiv:1806.01257</a> [<a href="http://arxiv.org/pdf/1806.01257" target="_blank">pdf</a>]

<h2>Diophantine approximation on curves. (arXiv:1902.02094v2 [math.NT] UPDATED)</h2>
<h3>Mumtaz Hussain, Johannes Schleischitz, David Simmons</h3>
<p>Let $g$ be a dimension function. The Generalised Baker-Schmidt Problem (1970)
concerns the $g$-dimensional Hausdorff measure ($\HH^g$-measure) of the set of
$\Psi$-approximable points on non-degenerate manifolds. The problem relates the
`size' of the set of $\Psi$-approximable points with the convergence or
divergence of a certain series. In the dual approximation setting, the
divergence case has been established by Beresnevich-Dickinson-Velani (2006) for
any non-degenerate manifold. The convergence case, however, represents the
major challenging open problem and progress thus far has been effectuated in
limited cases only. In this paper, we discuss and prove several results on
$\HH^g$-measure on Veronese curves in any dimension $n$. As a consequence of
one of our results we provide a generalisation of a recent result of Pezzoni
(arXiv:1809.09742) regarding $n=3$. This generalisation evolves from a deeper
investigation on general irreducibility considerations applicable in arbitrary
dimensions.

We further investigate the $\HH^g$-measure for convergence on planar curves
and prove two results. First is a slight generalisation of a recent result of
Huang and in the second result we show that the monotonicity assumption on a
multivariable approximating function cannot be removed for planar curves. The
latter result is in contrast to the problem on hypersurfaces, in dimensions
greater than $2$, where it has been recently proven to be unnecessary
[arXiv:1803.02314].
</p>
<a href="http://arxiv.org/abs/1902.02094" target="_blank">arXiv:1902.02094</a> [<a href="http://arxiv.org/pdf/1902.02094" target="_blank">pdf</a>]

<h2>On Maintaining Linear Convergence of Distributed Learning and Optimization under Limited Communication. (arXiv:1902.11163v4 [math.OC] UPDATED)</h2>
<h3>Sindri Magn&#xfa;sson, Hossein Shokri-Ghadikolaei, Na Li</h3>
<p>In distributed optimization and machine learning, multiple nodes coordinate
to solve large problems. To do this, the nodes need to compress important
algorithm information to bits so that it can be communicated over a digital
channel. The communication time of these algorithms follows a complex interplay
between a) the algorithm's convergence properties, b) the compression scheme,
and c) the transmission rate offered by the digital channel. We explore these
relationships for a general class of linearly convergent distributed
algorithms. In particular, we illustrate how to design quantizers for these
algorithms that compress the communicated information to a few bits while still
preserving the linear convergence. Moreover, we characterize the communication
time of these algorithms as a function of the available transmission rate. We
illustrate our results on learning algorithms using different communication
structures, such as decentralized algorithms where a single master coordinates
information from many workers and fully distributed algorithms where only
neighbours in a communication graph can communicate. We conclude that a
co-design of machine learning and communication protocols are mandatory to
flourish machine learning over networks.
</p>
<a href="http://arxiv.org/abs/1902.11163" target="_blank">arXiv:1902.11163</a> [<a href="http://arxiv.org/pdf/1902.11163" target="_blank">pdf</a>]

<h2>Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning. (arXiv:1905.11079v4 [cs.LG] UPDATED)</h2>
<h3>Yufei Wang, Ziju Shen, Zichao Long, Bin Dong</h3>
<p>Conservation laws are considered to be fundamental laws of nature. It has
broad applications in many fields, including physics, chemistry, biology,
geology, and engineering. Solving the differential equations associated with
conservation laws is a major branch in computational mathematics. The recent
success of machine learning, especially deep learning in areas such as computer
vision and natural language processing, has attracted a lot of attention from
the community of computational mathematics and inspired many intriguing works
in combining machine learning with traditional methods. In this paper, we are
the first to view numerical PDE solvers as an MDP and to use (deep) RL to learn
new solvers. As proof of concept, we focus on 1-dimensional scalar conservation
laws. We deploy the machinery of deep reinforcement learning to train a policy
network that can decide on how the numerical solutions should be approximated
in a sequential and spatial-temporal adaptive manner. We will show that the
problem of solving conservation laws can be naturally viewed as a sequential
decision-making process, and the numerical schemes learned in such a way can
easily enforce long-term accuracy. Furthermore, the learned policy network is
carefully designed to determine a good local discrete approximation based on
the current state of the solution, which essentially makes the proposed method
a meta-learning approach. In other words, the proposed method is capable of
learning how to discretize for a given situation mimicking human experts.
Finally, we will provide details on how the policy network is trained, how well
it performs compared with some state-of-the-art numerical solvers such as WENO
schemes, and supervised learning based approach L3D and PINN, and how well it
generalizes.
</p>
<a href="http://arxiv.org/abs/1905.11079" target="_blank">arXiv:1905.11079</a> [<a href="http://arxiv.org/pdf/1905.11079" target="_blank">pdf</a>]

<h2>The Impact of Complex and Informed Adversarial Behavior in Graphical Coordination Games. (arXiv:1909.02671v4 [eess.SY] UPDATED)</h2>
<h3>Keith Paarporn, Brian Canty, Philip N. Brown, Mahnoosh Alizadeh, Jason R. Marden</h3>
<p>How does system-level information impact the ability of an adversary to
degrade performance in a networked control system? How does the complexity of
an adversary's strategy affect its ability to degrade performance? This paper
focuses on these questions in the context of graphical coordination games where
an adversary can influence a given fraction of the agents in the system, and
the agents follow log-linear learning, a well-known distributed learning
algorithm. Focusing on a class of homogeneous ring graphs of various
connectivity, we begin by demonstrating that minimally connected ring graphs
are the most susceptible to adversarial influence. We then proceed to
characterize how both (i) the sophistication of the attack strategies (static
vs dynamic) and (ii) the informational awareness about the network structure
can be leveraged by an adversary to degrade system performance. Focusing on the
set of adversarial policies that induce stochastically stable states, our
findings demonstrate that the relative importance between sophistication and
information changes depending on the the influencing power of the adversary. In
particular, sophistication far outweighs informational awareness with regards
to degrading system-level damage when the adversary's influence power is
relatively weak. However, the opposite is true when an adversary's influence
power is more substantial.
</p>
<a href="http://arxiv.org/abs/1909.02671" target="_blank">arXiv:1909.02671</a> [<a href="http://arxiv.org/pdf/1909.02671" target="_blank">pdf</a>]

<h2>Dimension Formulae and Generalised Deep Holes of the Leech Lattice Vertex Operator Algebra. (arXiv:1910.04947v2 [math.QA] UPDATED)</h2>
<h3>Sven M&#xf6;ller, Nils R. Scheithauer</h3>
<p>We prove a dimension formula for the weight-1 subspace of a vertex operator
algebra $V^{\operatorname{orb}(g)}$ obtained by orbifolding a strongly
rational, holomorphic vertex operator algebra $V$ of central charge 24 with a
finite-order automorphism $g$. Based on an upper bound derived from this
formula we introduce the notion of a generalised deep hole in
$\operatorname{Aut}(V)$.

Then we show that the orbifold construction defines a bijection between the
generalised deep holes of the Leech lattice vertex operator algebra $V_\Lambda$
with non-trivial fixed-point Lie subalgebra and the strongly rational,
holomorphic vertex operator algebras of central charge 24 with non-vanishing
weight-1 space. This provides the first uniform construction of these vertex
operator algebras and naturally generalises the correspondence between the deep
holes of the Leech lattice $\Lambda$ and the 23 Niemeier lattices with
non-vanishing root system found by Conway, Parker and Sloane.
</p>
<a href="http://arxiv.org/abs/1910.04947" target="_blank">arXiv:1910.04947</a> [<a href="http://arxiv.org/pdf/1910.04947" target="_blank">pdf</a>]

<h2>Q-GADMM: Quantized Group ADMM for Communication Efficient Decentralized Machine Learning. (arXiv:1910.10453v6 [cs.LG] UPDATED)</h2>
<h3>Anis Elgabli, Jihong Park, Amrit S. Bedi, Chaouki Ben Issaid, Mehdi Bennis, Vaneet Aggarwal</h3>
<p>In this article, we propose a communication-efficient decentralized machine
learning (ML) algorithm, coined quantized group ADMM (Q-GADMM). To reduce the
number of communication links, every worker in Q-GADMM communicates only with
two neighbors, while updating its model via the group alternating direction
method of multipliers (GADMM). Moreover, each worker transmits the quantized
difference between its current model and its previously quantized model,
thereby decreasing the communication payload size. However, due to the lack of
centralized entity in decentralized ML, the spatial sparsity and payload
compression may incur error propagation, hindering model training convergence.
To overcome this, we develop a novel stochastic quantization method to
adaptively adjust model quantization levels and their probabilities, while
proving the convergence of Q-GADMM for convex objective functions. Furthermore,
to demonstrate the feasibility of Q-GADMM for non-convex and stochastic
problems, we propose quantized stochastic GADMM (Q-SGADMM) that incorporates
deep neural network architectures and stochastic sampling. Simulation results
corroborate that Q-GADMM significantly outperforms GADMM in terms of
communication efficiency while achieving the same accuracy and convergence
speed for a linear regression task. Similarly, for an image classification task
using DNN, Q-SGADMM achieves significantly less total communication cost with
identical accuracy and convergence speed compared to its counterpart without
quantization, i.e., stochastic GADMM (SGADMM).
</p>
<a href="http://arxiv.org/abs/1910.10453" target="_blank">arXiv:1910.10453</a> [<a href="http://arxiv.org/pdf/1910.10453" target="_blank">pdf</a>]

<h2>Minimum Time Learning Model Predictive Control. (arXiv:1911.09239v4 [eess.SY] UPDATED)</h2>
<h3>Ugo Rosolia, Francesco Borrelli</h3>
<p>In this paper we present a Learning Model Predictive Control (LMPC) strategy
for linear and nonlinear time optimal control problems. Our work builds on
existing LMPC methodologies and it guarantees finite time convergence
properties for the closed-loop system. We show how to construct a time varying
safe set and terminal cost function using closed-loop data. The resulting LMPC
policy is time varying and it guarantees recursive constraint satisfaction and
non-decreasing performance. Computational efficiency is obtained by convexifing
the safe set and terminal cost function. We demonstrate that, for a class of
nonlinear system and convex constraints, the convex LMPC formulation guarantees
recursive constraint satisfaction and non-decreasing performance. Finally, we
illustrate the effectiveness of the proposed strategies on minimum time
obstacle avoidance and racing examples.
</p>
<a href="http://arxiv.org/abs/1911.09239" target="_blank">arXiv:1911.09239</a> [<a href="http://arxiv.org/pdf/1911.09239" target="_blank">pdf</a>]

<h2>How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?. (arXiv:1911.12360v3 [cs.LG] UPDATED)</h2>
<h3>Zixiang Chen, Yuan Cao, Difan Zou, Quanquan Gu</h3>
<p>A recent line of research on deep learning focuses on the extremely
over-parameterized setting, and shows that when the network width is larger
than a high degree polynomial of the training sample size $n$ and the inverse
of the target error $\epsilon^{-1}$, deep neural networks learned by
(stochastic) gradient descent enjoy nice optimization and generalization
guarantees. Very recently, it is shown that under certain margin assumptions on
the training data, a polylogarithmic width condition suffices for two-layer
ReLU networks to converge and generalize (Ji and Telgarsky, 2019). However,
whether deep neural networks can be learned with such a mild
over-parameterization is still an open question. In this work, we answer this
question affirmatively and establish sharper learning guarantees for deep ReLU
networks trained by (stochastic) gradient descent. In specific, under certain
assumptions made in previous work, our optimization and generalization
guarantees hold with network width polylogarithmic in $n$ and $\epsilon^{-1}$.
Our results push the study of over-parameterized deep neural networks towards
more practical settings.
</p>
<a href="http://arxiv.org/abs/1911.12360" target="_blank">arXiv:1911.12360</a> [<a href="http://arxiv.org/pdf/1911.12360" target="_blank">pdf</a>]

<h2>Implicit regularization and momentum algorithms in nonlinear adaptive control and prediction. (arXiv:1912.13154v5 [math.OC] UPDATED)</h2>
<h3>Nicholas M. Boffi, Jean-Jacques E. Slotine</h3>
<p>Stable concurrent learning and control of dynamical systems is the subject of
adaptive control. Despite being an established field with many practical
applications and a rich theory, much of the development in adaptive control for
nonlinear systems revolves around a few key algorithms. By exploiting strong
connections between classical adaptive nonlinear control techniques and recent
progress in optimization and machine learning, we show that there exists
considerable untapped potential in algorithm development for both adaptive
nonlinear control and adaptive dynamics prediction. We first introduce
first-order adaptation laws inspired by natural gradient descent and mirror
descent. We prove that when there are multiple dynamics consistent with the
data, these non-Euclidean adaptation laws implicitly regularize the learned
model. Local geometry imposed during learning thus may be used to select
parameter vectors - out of the many that will achieve perfect tracking or
prediction - for desired properties such as sparsity. We apply this result to
regularized dynamics predictor and observer design, and as concrete examples
consider Hamiltonian systems, Lagrangian systems, and recurrent neural
networks. We subsequently develop a variational formalism based on the Bregman
Lagrangian to define adaptation laws with momentum applicable to linearly
parameterized systems and to nonlinearly parameterized systems satisfying
monotonicity or convexity requirements. We show that the Euler Lagrange
equations for the Bregman Lagrangian lead to natural gradient and mirror
descent-like adaptation laws with momentum, and we recover their first-order
analogues in the infinite friction limit. We illustrate our analyses with
simulations demonstrating our theoretical results.
</p>
<a href="http://arxiv.org/abs/1912.13154" target="_blank">arXiv:1912.13154</a> [<a href="http://arxiv.org/pdf/1912.13154" target="_blank">pdf</a>]

<h2>On the Information Plane of Autoencoders. (arXiv:2005.07783v2 [cs.LG] UPDATED)</h2>
<h3>Nicol&#xe1;s I. Tapia, Pablo A. Est&#xe9;vez</h3>
<p>The training dynamics of hidden layers in deep learning are poorly understood
in theory. Recently, the Information Plane (IP) was proposed to analyze them,
which is based on the information-theoretic concept of mutual information (MI).
The Information Bottleneck (IB) theory predicts that layers maximize relevant
information and compress irrelevant information. Due to the limitations in MI
estimation from samples, there is an ongoing debate about the properties of the
IP for the supervised learning case. In this work, we derive a theoretical
convergence for the IP of autoencoders. The theory predicts that ideal
autoencoders with a large bottleneck layer size do not compress input
information, whereas a small size causes compression only in the encoder
layers. For the experiments, we use a Gram-matrix based MI estimator recently
proposed in the literature. We propose a new rule to adjust its parameters that
compensates scale and dimensionality effects. Using our proposed rule, we
obtain experimental IPs closer to the theory. Our theoretical IP for
autoencoders could be used as a benchmark to validate new methods to estimate
MI in neural networks. In this way, experimental limitations could be
recognized and corrected, helping with the ongoing debate on the supervised
learning case.
</p>
<a href="http://arxiv.org/abs/2005.07783" target="_blank">arXiv:2005.07783</a> [<a href="http://arxiv.org/pdf/2005.07783" target="_blank">pdf</a>]

<h2>On the Impossibility of Global Convergence in Multi-Loss Optimization. (arXiv:2005.12649v2 [math.OC] UPDATED)</h2>
<h3>Alistair Letcher</h3>
<p>Under mild regularity conditions, gradient-based methods converge globally to
a critical point in the single-loss setting. This is known to break down for
vanilla gradient descent when moving to multi-loss optimization, but can we
hope to build some algorithm with global guarantees? We negatively resolve this
open problem by proving that desirable convergence properties cannot
simultaneously hold for any algorithm. Our result has more to do with the
existence of games with no satisfactory outcomes, than with algorithms per se.
More explicitly we construct a two-player game with zero-sum interactions whose
losses are both coercive and analytic, but whose only simultaneous critical
point is a strict maximum. Any 'reasonable' algorithm, defined to avoid strict
maxima, will therefore fail to converge. This is fundamentally different from
single losses, where coercivity implies existence of a global minimum.
Moreover, we prove that a wide range of existing gradient-based methods almost
surely have bounded but non-convergent iterates in a constructed zero-sum game
for suitably small learning rates. It nonetheless remains an open question
whether such behavior can arise in high-dimensional games of interest to ML
practitioners, such as GANs or multi-agent RL.
</p>
<a href="http://arxiv.org/abs/2005.12649" target="_blank">arXiv:2005.12649</a> [<a href="http://arxiv.org/pdf/2005.12649" target="_blank">pdf</a>]

<h2>Neural Jump Ordinary Differential Equation. (arXiv:2006.04727v2 [stat.ML] UPDATED)</h2>
<h3>Calypso Herrera, Florian Krach, Josef Teichmann</h3>
<p>Combinations of neural ODEs with recurrent neural networks (RNN), like
GRUODE-Bayes or ODE-RNN are well suited to model irregularly-sampled time
series. While those models outperform existing discrete-time approaches, no
theoretical guarantees for their predictive capabilities are available.
Assuming that the irregularly-sampled time series data originates from a
continuous stochastic processes, the optimal on-line prediction is the
conditional expectation given the currently available information. We introduce
the Neural Jump ODE (NJ-ODE) that provides a data-driven approach to learn,
continuously in time, the conditional expectation of a stochastic process. Our
approach models the conditional expectation between two observations with a
neural ODE and jumps whenever a new observation is made. We define a novel
training framework, which allows us to prove theoretical convergence guarantees
for the first time. In particular, we demonstrate the predictive capabilities
of our model by proving that, under some regularity assumptions, the output
process converges to the conditional expectation process. We provide
experiments showing that the theoretical results also hold empirically.
Moreover, we experimentally show that our model outperforms one state of the
art model in more complex learning tasks and give comparisons on a real-world
dataset.
</p>
<a href="http://arxiv.org/abs/2006.04727" target="_blank">arXiv:2006.04727</a> [<a href="http://arxiv.org/pdf/2006.04727" target="_blank">pdf</a>]

<h2>Making Non-Stochastic Control (Almost) as Easy as Stochastic. (arXiv:2006.05910v2 [cs.LG] UPDATED)</h2>
<h3>Max Simchowitz</h3>
<p>Recent literature has made much progress in understanding \emph{online LQR}:
a modern learning-theoretic take on the classical control problem in which a
learner attempts to optimally control an unknown linear dynamical system with
fully observed state, perturbed by i.i.d. Gaussian noise. It is now understood
that the optimal regret on time horizon $T$ against the optimal control law
scales as $\widetilde{\Theta}(\sqrt{T})$. In this paper, we show that the same
regret rate (against a suitable benchmark) is attainable even in the
considerably more general non-stochastic control model, where the system is
driven by \emph{arbitrary adversarial} noise (Agarwal et al. 2019). In other
words, \emph{stochasticity confers little benefit in online LQR}.

We attain the optimal $\widetilde{\mathcal{O}}(\sqrt{T})$ regret when the
dynamics are unknown to the learner, and $\mathrm{poly}(\log T)$ regret when
known, provided that the cost functions are strongly convex (as in LQR). Our
algorithm is based on a novel variant of online Newton step (Hazan et al.
2007), which adapts to the geometry induced by possibly adversarial
disturbances, and our analysis hinges on generic "policy regret" bounds for
certain structured losses in the OCO-with-memory framework (Anava et al. 2015).
Moreover, our results accomodate the full generality of the non-stochastic
control setting: adversarially chosen (possibly non-quadratic) costs, partial
state observation, and fully adversarial process and observation noise.
</p>
<a href="http://arxiv.org/abs/2006.05910" target="_blank">arXiv:2006.05910</a> [<a href="http://arxiv.org/pdf/2006.05910" target="_blank">pdf</a>]

<h2>Lipschitz Recurrent Neural Networks. (arXiv:2006.12070v2 [cs.LG] UPDATED)</h2>
<h3>N.Benjamin Erichson, Omri Azencot, Alejandro Queiruga, Liam Hodgkinson, Michael W. Mahoney</h3>
<p>Viewing recurrent neural networks (RNNs) as continuous-time dynamical
systems, we propose a recurrent unit that describes the hidden state's
evolution with two parts: a well-understood linear component plus a Lipschitz
nonlinearity. This particular functional form facilitates stability analysis of
the long-term behavior of the recurrent unit using tools from nonlinear systems
theory. In turn, this enables architectural design decisions before
experimentation. Sufficient conditions for global stability of the recurrent
unit are obtained, motivating a novel scheme for constructing hidden-to-hidden
matrices. Our experiments demonstrate that the Lipschitz RNN can outperform
existing recurrent units on a range of benchmark tasks, including computer
vision, language modeling and speech prediction tasks. Finally, through
Hessian-based analysis we demonstrate that our Lipschitz recurrent unit is more
robust with respect to input and parameter perturbations as compared to other
continuous-time RNNs.
</p>
<a href="http://arxiv.org/abs/2006.12070" target="_blank">arXiv:2006.12070</a> [<a href="http://arxiv.org/pdf/2006.12070" target="_blank">pdf</a>]

<h2>Deep Network with Approximation Error Being Reciprocal of Width to Power of Square Root of Depth. (arXiv:2006.12231v4 [cs.LG] UPDATED)</h2>
<h3>Zuowei Shen, Haizhao Yang, Shijun Zhang</h3>
<p>A new network with super approximation power is introduced. This network is
built with Floor ($\lfloor x\rfloor$) or ReLU ($\max\{0,x\}$) activation
function in each neuron and hence we call such networks Floor-ReLU networks.
{For any hyper-parameters $N\in\mathbb{N}^+$ and $L\in\mathbb{N}^+$,} it is
shown that Floor-ReLU networks with a width $\max\{d,\, 5N+13\}$ and a depth
$64dL+3$ can {uniformly approximate a H{\"o}lder function $f$ on $[0,1]^d$ with
an approximation rate $3\lambda d^{\alpha/2}N^{-\alpha\sqrt{L}}$, where $\alpha
\in(0,1]$ and $\lambda$ are the H{\"o}lder order and constant, respectively.}
More generally for an arbitrary continuous function $f$ on $[0,1]^d$ with a
modulus of continuity $\omega_f(\cdot)$, the constructive approximation rate is
$\omega_f(\sqrt{d}\,N^{-\sqrt{L}})+2\omega_f(\sqrt{d}){N^{-\sqrt{L}}}$. As a
consequence, this new {class of networks} overcome{s} the curse of
dimensionality in approximation power when the variation of $\omega_f(r)$ as
$r\rightarrow 0$ is moderate (e.g., $\omega_f(r){\lesssim} r^\alpha$ for
H{\"o}lder continuous functions), since the major term to be concerned in our
approximation rate is {essentially $\sqrt{d}$ times a function of $N$ and $L$
independent of $d$ within the modulus of continuity. }
</p>
<a href="http://arxiv.org/abs/2006.12231" target="_blank">arXiv:2006.12231</a> [<a href="http://arxiv.org/pdf/2006.12231" target="_blank">pdf</a>]

<h2>Universal Approximation Power of Deep Residual Neural Networks via Nonlinear Control Theory. (arXiv:2007.06007v2 [cs.LG] UPDATED)</h2>
<h3>Paulo Tabuada, Bahman Gharesifard</h3>
<p>In this paper, we explain the universal approximation capabilities of deep
residual neural networks through geometric nonlinear control. Inspired by
recent work establishing links between residual networks and control systems,
we provide a general sufficient condition for a residual network to have the
power of universal approximation by asking the activation function, or one of
its derivatives, to satisfy a quadratic differential equation. Many activation
functions used in practice satisfy this assumption, exactly or approximately,
and we show this property to be sufficient for an adequately deep neural
network with $2n$ states to approximate arbitrarily well, on a compact set and
with respect to the supremum norm, any continuous function from $\mathbb{R}^n$
to $\mathbb{R}^n$. We further show this result to hold for very simple
architectures for which the weights only need to assume two values. The first
key technical contribution consists of relating the universal approximation
problem to controllability of an ensemble of control systems corresponding to a
residual network and to leverage classical Lie algebraic techniques to
characterize controllability. The second technical contribution is to identify
monotonicity as the bridge between controllability of finite ensembles and
uniform approximability on compact sets.
</p>
<a href="http://arxiv.org/abs/2007.06007" target="_blank">arXiv:2007.06007</a> [<a href="http://arxiv.org/pdf/2007.06007" target="_blank">pdf</a>]

<h2>Tracy-Widom distribution for the edge eigenvalues of Gram type random matrices. (arXiv:2008.04166v2 [math.ST] UPDATED)</h2>
<h3>Xiucai Ding, Fan Yang</h3>
<p>Large dimensional Gram type matrices are common objects in high-dimensional
statistics and machine learning. In this paper, we study the limiting
distribution of the edge eigenvalues for a general class of high-dimensional
Gram type random matrices, including separable sample covariance matrices,
sparse sample covariance matrices, bipartite stochastic block model and random
Gram matrices with general variance profiles. Specifically, we prove that under
(almost) sharp moment conditions and certain tractable regularity assumptions,
the edge eigenvalues, i.e., the largest few eigenvalues of non-spiked Gram type
random matrices or the extremal bulk eigenvalues of spiked Gram type random
matrices, satisfy the Tracy-Widom distribution asymptotically. Our results can
be used to construct adaptive, accurate and powerful statistics for
high-dimensional statistical inference. In particular, we propose
data-dependent statistics to infer the number of signals under general noise
structure, test the one-sided sphericity of separable matrix, and test the
structure of bipartite stochastic block model. Numerical simulations show
strong support of our proposed statistics. The core of our proof is to
establish the edge universality and Tracy-Widom distribution for a rectangular
Dyson Brownian motion with regular initial data. This is a general strategy to
study the edge statistics for high-dimensional Gram type random matrices
without exploring the specific independence structure of the target matrices.
It has potential to be applied to more general random matrices that are beyond
the ones considered in this paper.
</p>
<a href="http://arxiv.org/abs/2008.04166" target="_blank">arXiv:2008.04166</a> [<a href="http://arxiv.org/pdf/2008.04166" target="_blank">pdf</a>]

<h2>On the number of point of given order on odd degree hyperelliptic curves. (arXiv:2008.05253v2 [math.NT] UPDATED)</h2>
<h3>John Boxall</h3>
<p>For integers $N\geq 3$ and $g\geq 1$, we study bounds on the cardinality of
the set of points of order dividing $N$ lying on a hyperelliptic curve of genus
$g$ embedded in its jacobian using a Weierstrass point as base point. This
leads us to revisit division polynomials introduced by Cantor in 1995 and
strengthen a divisibility result proved by him. Several examples are discussed.
</p>
<a href="http://arxiv.org/abs/2008.05253" target="_blank">arXiv:2008.05253</a> [<a href="http://arxiv.org/pdf/2008.05253" target="_blank">pdf</a>]

<h2>On the Suboptimality of Negative Momentum for Minimax Optimization. (arXiv:2008.07459v2 [math.OC] UPDATED)</h2>
<h3>Guodong Zhang, Yuanhao Wang</h3>
<p>Smooth game optimization has recently attracted great interest in machine
learning as it generalizes the single-objective optimization paradigm. However,
game dynamics is more complex due to the interaction between different players
and is therefore fundamentally different from minimization, posing new
challenges for algorithm design. Notably, it has been shown that negative
momentum is preferred due to its ability to reduce oscillation in game
dynamics. Nevertheless, existing analysis about negative momentum was
restricted to simple bilinear games. In this paper, we extend the analysis to
smooth and strongly-convex strongly-concave minimax games by taking the
variational inequality formulation. By connecting momentum method with
Chebyshev polynomials, we show that negative momentum accelerates convergence
of game dynamics locally, though with a suboptimal rate. To the best of our
knowledge, this is the \emph{first work} that provides an explicit convergence
rate for negative momentum in this setting.
</p>
<a href="http://arxiv.org/abs/2008.07459" target="_blank">arXiv:2008.07459</a> [<a href="http://arxiv.org/pdf/2008.07459" target="_blank">pdf</a>]

<h2>A Topological Framework for Deep Learning. (arXiv:2008.13697v6 [cs.LG] UPDATED)</h2>
<h3>Mustafa Hajij, Kyle Istvan</h3>
<p>We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.
</p>
<a href="http://arxiv.org/abs/2008.13697" target="_blank">arXiv:2008.13697</a> [<a href="http://arxiv.org/pdf/2008.13697" target="_blank">pdf</a>]

<h2>Action and Perception as Divergence Minimization. (arXiv:2009.01791v2 [cs.AI] UPDATED)</h2>
<h3>Danijar Hafner, Pedro A. Ortega, Jimmy Ba, Thomas Parr, Karl Friston, Nicolas Heess</h3>
<p>We introduce a unified objective for action and perception of intelligent
agents. Extending representation learning and control, we minimize the joint
divergence between the combined system of agent and environment and a target
distribution. Intuitively, such agents use perception to align their beliefs
with the world, and use actions to align the world with their beliefs.
Minimizing the joint divergence to an expressive target maximizes the mutual
information between the agent's representations and inputs, thus inferring
representations that are informative of past inputs and exploring future inputs
that are informative of the representations. This lets us explain intrinsic
objectives, such as representation learning, information gain, empowerment, and
skill discovery from minimal assumptions. Moreover, interpreting the target
distribution as a latent variable model suggests powerful world models as a
path toward highly adaptive agents that seek large niches in their
environments, rendering task rewards optional. The framework provides a common
language for comparing a wide range of objectives, advances the understanding
of latent variables for decision making, and offers a recipe for designing
novel objectives. We recommend deriving future agent objectives the joint
divergence to facilitate comparison, to point out the agent's target
distribution, and to identify the intrinsic objective terms needed to reach
that distribution.
</p>
<a href="http://arxiv.org/abs/2009.01791" target="_blank">arXiv:2009.01791</a> [<a href="http://arxiv.org/pdf/2009.01791" target="_blank">pdf</a>]

<h2>Ramifications of Approximate Posterior Inference for Bayesian Deep Learning in Adversarial and Out-of-Distribution Settings. (arXiv:2009.01798v2 [stat.ML] UPDATED)</h2>
<h3>John Mitros, Arjun Pakrashi, Brian Mac Namee</h3>
<p>Deep neural networks have been successful in diverse discriminative
classification tasks, although, they are poorly calibrated often assigning high
probability to misclassified predictions. Potential consequences could lead to
trustworthiness and accountability of the models when deployed in real
applications, where predictions are evaluated based on their confidence scores.
Existing solutions suggest the benefits attained by combining deep neural
networks and Bayesian inference to quantify uncertainty over the models'
predictions for ambiguous datapoints. In this work we propose to validate and
test the efficacy of likelihood based models in the task of out of distribution
detection (OoD). Across different datasets and metrics we show that Bayesian
deep learning models on certain occasions marginally outperform conventional
neural networks and in the event of minimal overlap between in/out distribution
classes, even the best models exhibit a reduction in AUC scores in detecting
OoD data. Preliminary investigations indicate the potential inherent role of
bias due to choices of initialisation, architecture or activation functions. We
hypothesise that the sensitivity of neural networks to unseen inputs could be a
multi-factor phenomenon arising from the different architectural design choices
often amplified by the curse of dimensionality. Furthermore, we perform a study
to find the effect of the adversarial noise resistance methods on in and
out-of-distribution performance, as well as, also investigate adversarial noise
robustness of Bayesian deep learners.
</p>
<a href="http://arxiv.org/abs/2009.01798" target="_blank">arXiv:2009.01798</a> [<a href="http://arxiv.org/pdf/2009.01798" target="_blank">pdf</a>]

<h2>OnsagerNet: Learning Stable and Interpretable Dynamics using a Generalized Onsager Principle. (arXiv:2009.02327v2 [math.DS] UPDATED)</h2>
<h3>Haijun Yu, Xinyuan Tian, Weinan E, Qianxiao Li</h3>
<p>We propose a systematic method for learning stable and interpretable
dynamical models using sampled trajectory data from physical processes based on
a generalized Onsager principle. The learned dynamics are autonomous ordinary
differential equations parameterized by neural networks that retain clear
physical structure information, such as free energy, dissipation, conservative
interaction and external force. The neural network representations for the
hidden dynamics are trained by minimizing the empirical risk based on an
embedded Runge-Kutta method. For high dimensional problems with a low
dimensional slow manifold, an autoencoder with isometric regularization is
introduced to find generalized coordinates on which we learn the Onsager
dynamics. We apply the method to learn reduced order models for the
Rayleigh-B\'{e}nard convection problem, where we obtain low dimensional
autonomous equations that capture both qualitative and quantitative properties
of the underlying dynamics. In particular, this validates the basic approach of
Lorenz, although we also discover that the dimension of the learned autonomous
model required for faithful representation increases with the Rayleigh number.
</p>
<a href="http://arxiv.org/abs/2009.02327" target="_blank">arXiv:2009.02327</a> [<a href="http://arxiv.org/pdf/2009.02327" target="_blank">pdf</a>]

<h2>Deep and shallow slice knots in 4-manifolds. (arXiv:2009.03053v2 [math.GT] UPDATED)</h2>
<h3>Michael Klug, Benjamin Ruppik</h3>
<p>We consider slice disks for knots in the boundary of a smooth compact
4-manifold $X^{4}$. We call a knot $K \subset \partial X$ deep slice in $X$ if
there is a smooth properly embedded 2-disk in $X$ with boundary $K$, but $K$ is
not concordant to the unknot in a collar neighborhood $\partial X \times I$ of
the boundary. We point out how this concept relates to various well-known
conjectures and give some criteria for the nonexistence of such deep slice
knots. Then we show, using the Wall self-intersection invariant and a result of
Rohlin, that every 4-manifold consisting of just one 0- and a nonzero number of
2-handles always has a deep slice knot in the boundary. We end by considering
4-manifolds where every knot in the boundary bounds an embedded disk in the
interior. A generalization of the Murasugi-Tristram inequality is used to show
that there does not exist a compact, oriented 4-manifold $V$ with spherical
boundary such that every knot $K \subset S^3 = \partial V$ is slice in $V$ via
a null-homologous disk.
</p>
<a href="http://arxiv.org/abs/2009.03053" target="_blank">arXiv:2009.03053</a> [<a href="http://arxiv.org/pdf/2009.03053" target="_blank">pdf</a>]

<h2>Federated Generalized Bayesian Learning via Distributed Stein Variational Gradient Descent. (arXiv:2009.06419v3 [cs.LG] UPDATED)</h2>
<h3>Rahif Kassab, Osvaldo Simeone</h3>
<p>This paper introduces Distributed Stein Variational Gradient Descent (DSVGD),
a non-parametric generalized Bayesian inference framework for federated
learning. DSVGD maintains a number of non-random and interacting particles at a
central server to represent the current iterate of the model global posterior.
The particles are iteratively downloaded and updated by one of the agents with
the end goal of minimizing the global free energy. By varying the number of
particles, DSVGD enables a flexible trade-off between per-iteration
communication load and number of communication rounds. DSVGD is shown to
compare favorably to benchmark frequentist and Bayesian federated learning
strategies, also scheduling a single device per iteration, in terms of accuracy
and scalability with respect to the number of agents, while also providing
well-calibrated, and hence trustworthy, predictions.
</p>
<a href="http://arxiv.org/abs/2009.06419" target="_blank">arXiv:2009.06419</a> [<a href="http://arxiv.org/pdf/2009.06419" target="_blank">pdf</a>]

<h2>QR and LQ Decomposition Matrix Backpropagation Algorithms for Square, Wide, and Deep Matrices and Their Software Implementation. (arXiv:2009.10071v2 [math.NA] UPDATED)</h2>
<h3>Denisa A.O. Roberts, Lucas R. Roberts</h3>
<p>This article presents matrix backpropagation algorithms for the QR
decomposition of matrices $A_{m, n}$, that are either square (m = n), wide (m &lt;
n), or deep (m &gt; n), with rank $k = min(m, n)$. Furthermore, we derive novel
matrix backpropagation results for the pivoted (full-rank) QR decomposition and
for the LQ decomposition of deep input matrices. Differentiable QR
decomposition offers a numerically stable, computationally efficient method to
solve least squares problems frequently encountered in machine learning and
computer vision. Software implementation across popular deep learning
frameworks (PyTorch, TensorFlow, MXNet) incorporate the methods for general use
within the deep learning community. Furthermore, this article aids the
practitioner in understanding the matrix backpropagation methodology as part of
larger computational graphs, and hopefully, leads to new lines of research.
</p>
<a href="http://arxiv.org/abs/2009.10071" target="_blank">arXiv:2009.10071</a> [<a href="http://arxiv.org/pdf/2009.10071" target="_blank">pdf</a>]

<h2>A Half-Space Stochastic Projected Gradient Method for Group Sparsity Regularization. (arXiv:2009.12078v2 [math.OC] UPDATED)</h2>
<h3>Tianyi Chen, Guanyi Wang, Tianyu Ding, Bo Ji, Sheng Yi, Zhihui Zhu</h3>
<p>Optimizing with group sparsity is significant in enhancing model
interpretability in machining learning applications, e.g., feature selection,
compressed sensing and model compression. However, for large-scale stochastic
training problems, effective group sparsity exploration are typically hard to
achieve. Particularly, the state-of-the-art stochastic optimization algorithms
usually generate merely dense solutions. To overcome this shortage, we propose
a stochastic method -- Half-space Stochastic Projected Gradient (HSPG) method
to search solutions of high group sparsity while maintain the convergence.
Initialized by a simple Prox-SG Step, the HSPG method relies on a novel
Half-Space Step to substantially boost the sparsity level. Numerically, HSPG
demonstrates its superiority in deep neural networks, e.g., VGG16, ResNet18 and
MobileNetV1, by computing solutions of higher group sparsity, competitive
objective values and generalization accuracy.
</p>
<a href="http://arxiv.org/abs/2009.12078" target="_blank">arXiv:2009.12078</a> [<a href="http://arxiv.org/pdf/2009.12078" target="_blank">pdf</a>]

<h2>A group-theorist's perspective on symmetry groups in physics. (arXiv:2009.14613v2 [math.GR] UPDATED)</h2>
<h3>Robert Arnott Wilson</h3>
<p>There are many Lie groups used in physics, including the Lorentz group of
special relativity, the spin groups (relativistic and non-relativistic) and the
gauge groups of quantum electrodynamics and the weak and strong nuclear forces.
Various grand unified theories use larger Lie groups in different attempts to
unify some of these groups into something more fundamental. There are also a
number of finite symmetry groups that are related to the finite number of
distinct elementary particle types. I offer a group-theorist's perspective on
these groups, and suggest some ways in which a deeper use of group theory might
in principle be useful. These suggestions include a number of options that seem
not to be under active investigation at present. I leave open the question of
whether they can be implemented in physical theories.
</p>
<a href="http://arxiv.org/abs/2009.14613" target="_blank">arXiv:2009.14613</a> [<a href="http://arxiv.org/pdf/2009.14613" target="_blank">pdf</a>]

<h2>Generalized Self-Concordant Analysis of Frank-Wolfe algorithms. (arXiv:2010.01009v2 [math.OC] UPDATED)</h2>
<h3>Pavel Dvurechensky, Kamil Safin, Shimrit Shtern, Mathias Staudigl</h3>
<p>Projection-free optimization via different variants of the Frank-Wolfe (FW)
method has become one of the cornerstones in large scale optimization for
machine learning and computational statistics. Numerous applications within
these fields involve the minimization of functions with self-concordance like
properties. Such generalized self-concordant (GSC) functions do not necessarily
feature a Lipschitz continuous gradient, nor are they strongly convex. Indeed,
in a number of applications, e.g. inverse covariance estimation or
distance-weighted discrimination problems in support vector machines, the loss
is given by a GSC function having unbounded curvature, implying absence of
theoretical guarantees for the existing FW methods. This paper closes this
apparent gap in the literature by developing provably convergent FW algorithms
with standard O(1/k) convergence rate guarantees. If the problem formulation
allows the efficient construction of a local linear minimization oracle, we
develop a FW method with linear convergence rate.
</p>
<a href="http://arxiv.org/abs/2010.01009" target="_blank">arXiv:2010.01009</a> [<a href="http://arxiv.org/pdf/2010.01009" target="_blank">pdf</a>]

<h2>A Hybrid Adaptive Educational eLearning Project based on Ontologies Matching and Recommendation System. (arXiv:2007.14771v2 [cs.IR] CROSS LISTED)</h2>
<h3>Vasiliki Demertzi, Konstantinos Demertzis</h3>
<p>The implementation of teaching interventions in learning needs has received
considerable attention, as the provision of the same educational conditions to
all students, is pedagogically ineffective. In contrast, more effectively
considered the pedagogical strategies that adapt to the real individual skills
of the students. An important innovation in this direction is the Adaptive
Educational Systems (AES) that support automatic modeling study and adjust the
teaching content on educational needs and students' skills. Effective
utilization of these educational approaches can be enhanced with Artificial
Intelligence (AI) technologies in order to the substantive content of the web
acquires structure and the published information is perceived by the search
engines. This study proposes a novel Adaptive Educational eLearning System
(AEeLS) that has the capacity to gather and analyze data from learning
repositories and to adapt these to the educational curriculum according to the
student skills and experience. It is a novel hybrid machine learning system
that combines a Semi-Supervised Classification method for ontology matching and
a Recommendation Mechanism that uses a hybrid method from neighborhood-based
collaborative and content-based filtering techniques, in order to provide a
personalized educational environment for each student.
</p>
<a href="http://arxiv.org/abs/2007.14771" target="_blank">arXiv:2007.14771</a> [<a href="http://arxiv.org/pdf/2007.14771" target="_blank">pdf</a>]

<h2>Semantics-Guided Clustering with Deep Progressive Learning for Semi-Supervised Person Re-identification. (arXiv:2010.01148v1 [cs.CV])</h2>
<h3>Chih-Ting Liu, Yu-Jhe Li, Shao-Yi Chien, Yu-Chiang Frank Wang</h3>
<p>Person re-identification (re-ID) requires one to match images of the same
person across camera views. As a more challenging task, semi-supervised re-ID
tackles the problem that only a number of identities in training data are fully
labeled, while the remaining are unlabeled. Assuming that such labeled and
unlabeled training data share disjoint identity labels, we propose a novel
framework of Semantics-Guided Clustering with Deep Progressive Learning
(SGC-DPL) to jointly exploit the above data. By advancing the proposed
Semantics-Guided Affinity Propagation (SG-AP), we are able to assign
pseudo-labels to selected unlabeled data in a progressive fashion, under the
semantics guidance from the labeled ones. As a result, our approach is able to
augment the labeled training data in the semi-supervised setting. Our
experiments on two large-scale person re-ID benchmarks demonstrate the
superiority of our SGC-DPL over state-of-the-art methods across different
degrees of supervision. In extension, the generalization ability of our SGC-DPL
is also verified in other tasks like vehicle re-ID or image retrieval with the
semi-supervised setting.
</p>
<a href="http://arxiv.org/abs/2010.01148" target="_blank">arXiv:2010.01148</a> [<a href="http://arxiv.org/pdf/2010.01148" target="_blank">pdf</a>]

<h2>Evaluating Progress on Machine Learning for Longitudinal Electronic Healthcare Data. (arXiv:2010.01149v1 [cs.LG])</h2>
<h3>David Bellamy, Leo Celi, Andrew L. Beam</h3>
<p>The Large Scale Visual Recognition Challenge based on the well-known Imagenet
dataset catalyzed an intense flurry of progress in computer vision. Benchmark
tasks have propelled other sub-fields of machine learning forward at an equally
impressive pace, but in healthcare it has primarily been image processing
tasks, such as in dermatology and radiology, that have experienced similar
benchmark-driven progress. In the present study, we performed a comprehensive
review of benchmarks in medical machine learning for structured data,
identifying one based on the Medical Information Mart for Intensive Care
(MIMIC-III) that allows the first direct comparison of predictive performance
and thus the evaluation of progress on four clinical prediction tasks:
mortality, length of stay, phenotyping, and patient decompensation. We find
that little meaningful progress has been made over a 3 year period on these
tasks, despite significant community engagement. Through our meta-analysis, we
find that the performance of deep recurrent models is only superior to logistic
regression on certain tasks. We conclude with a synthesis of these results,
possible explanations, and a list of desirable qualities for future benchmarks
in medical machine learning.
</p>
<a href="http://arxiv.org/abs/2010.01149" target="_blank">arXiv:2010.01149</a> [<a href="http://arxiv.org/pdf/2010.01149" target="_blank">pdf</a>]

<h2>Representational aspects of depth and conditioning in normalizing flows. (arXiv:2010.01155v1 [cs.LG])</h2>
<h3>Frederic Koehler, Viraj Mehta, Andrej Risteski</h3>
<p>Normalizing flows are among the most popular paradigms in generative
modeling, especially for images, primarily because we can efficiently evaluate
the likelihood of a data point. Normalizing flows also come with difficulties:
models which produce good samples typically need to be extremely deep -- which
comes with accompanying vanishing/exploding gradient problems. Relatedly, they
are often poorly conditioned since typical training data like images
intuitively are lower-dimensional, and the learned maps often have Jacobians
that are close to being singular. In our paper, we tackle representational
aspects around depth and conditioning of normalizing flows -- both for general
invertible architectures, and for a particular common architecture -- affine
couplings. For general invertible architectures, we prove that invertibility
comes at a cost in terms of depth: we show examples where a much deeper
normalizing flow model may need to be used to match the performance of a
non-invertible generator. For affine couplings, we first show that the choice
of partitions isn't a likely bottleneck for depth: we show that any invertible
linear map (and hence a permutation) can be simulated by a constant number of
affine coupling layers, using a fixed partition. This shows that the extra
flexibility conferred by 1x1 convolution layers, as in GLOW, can in principle
be simulated by increasing the size by a constant factor. Next, in terms of
conditioning, we show that affine couplings are universal approximators --
provided the Jacobian of the model is allowed to be close to singular. We
furthermore empirically explore the benefit of different kinds of padding -- a
common strategy for improving conditioning -- on both synthetic and real-life
datasets.
</p>
<a href="http://arxiv.org/abs/2010.01155" target="_blank">arXiv:2010.01155</a> [<a href="http://arxiv.org/pdf/2010.01155" target="_blank">pdf</a>]

<h2>MM-Hand: 3D-Aware Multi-Modal Guided Hand Generative Network for 3D Hand Pose Synthesis. (arXiv:2010.01158v1 [cs.CV])</h2>
<h3>Zhenyu Wu, Duc Hoang, Shih-Yao Lin, Yusheng Xie, Liangjian Chen, Yen-Yu Lin, Zhangyang Wang, Wei Fan</h3>
<p>Estimating the 3D hand pose from a monocular RGB image is important but
challenging. A solution is training on large-scale RGB hand images with
accurate 3D hand keypoint annotations. However, it is too expensive in
practice. Instead, we have developed a learning-based approach to synthesize
realistic, diverse, and 3D pose-preserving hand images under the guidance of 3D
pose information. We propose a 3D-aware multi-modal guided hand generative
network (MM-Hand), together with a novel geometry-based curriculum learning
strategy. Our extensive experimental results demonstrate that the 3D-annotated
images generated by MM-Hand qualitatively and quantitatively outperform
existing options. Moreover, the augmented data can consistently improve the
quantitative performance of the state-of-the-art 3D hand pose estimators on two
benchmark datasets. The code will be available at
https://github.com/ScottHoang/mm-hand.
</p>
<a href="http://arxiv.org/abs/2010.01158" target="_blank">arXiv:2010.01158</a> [<a href="http://arxiv.org/pdf/2010.01158" target="_blank">pdf</a>]

<h2>Machine learning approach to force reconstruction in photoelastic materials. (arXiv:2010.01163v1 [cs.CV])</h2>
<h3>Renat Sergazinov, Miroslav Kramar</h3>
<p>Photoelastic techniques have a long tradition in both qualitative and
quantitative analysis of the stresses in granular materials. Over the last two
decades, computational methods for reconstructing forces between particles from
their photoelastic response have been developed by many different experimental
teams. Unfortunately, all of these methods are computationally expensive. This
limits their use for processing extensive data sets that capture the time
evolution of granular ensembles consisting of a large number of particles. In
this paper, we present a novel approach to this problem which leverages the
power of convolutional neural networks to recognize complex spatial patterns.
The main drawback of using neural networks is that training them usually
requires a large labeled data set which is hard to obtain experimentally. We
show that this problem can be successfully circumvented by pretraining the
networks on a large synthetic data set and then fine-tuning them on much
smaller experimental data sets. Due to our current lack of experimental data,
we demonstrate the potential of our method by changing the size of the
considered particles which alters the exhibited photoelastic patterns more than
typical experimental errors.
</p>
<a href="http://arxiv.org/abs/2010.01163" target="_blank">arXiv:2010.01163</a> [<a href="http://arxiv.org/pdf/2010.01163" target="_blank">pdf</a>]

<h2>Manipulation of Articulated Objects using Dual-arm Robots via Answer Set Programming. (arXiv:2010.01164v1 [cs.AI])</h2>
<h3>Riccardo Bertolucci, Alessio Capitanelli, Carmine Dodaro, Nicola Leone, Marco Maratea, Fulvio Mastrogiovanni, Mauro Vallati</h3>
<p>The manipulation of articulated objects is of primary importance in Robotics,
and can be considered as one of the most complex manipulation tasks.
Traditionally, this problem has been tackled by developing ad-hoc approaches,
which lack flexibility and portability.

In this paper we present a framework based on Answer Set Programming (ASP)
for the automated manipulation of articulated objects in a robot control
architecture. In particular, ASP is employed for representing the configuration
of the articulated object, for checking the consistency of such representation
in the knowledge base, and for generating the sequence of manipulation actions.

The framework is exemplified and validated on the Baxter dual-arm manipulator
in a first, simple scenario. Then, we extend such scenario to improve the
overall setup accuracy, and to introduce a few constraints in robot actions
execution to enforce their feasibility. The extended scenario entails a high
number of possible actions that can be fruitfully combined together. Therefore,
we exploit macro actions from automated planning in order to provide more
effective plans. We validate the overall framework in the extended scenario,
thereby confirming the applicability of ASP also in more realistic Robotics
settings, and showing the usefulness of macro actions for the robot-based
manipulation of articulated objects. Under consideration in Theory and Practice
of Logic Programming (TPLP).
</p>
<a href="http://arxiv.org/abs/2010.01164" target="_blank">arXiv:2010.01164</a> [<a href="http://arxiv.org/pdf/2010.01164" target="_blank">pdf</a>]

<h2>Multi-domain Clinical Natural Language Processing with MedCAT: the Medical Concept Annotation Toolkit. (arXiv:2010.01165v1 [cs.CL])</h2>
<h3>Zeljko Kraljevic, Thomas Searle, Anthony Shek, Lukasz Roguski, Kawsar Noor, Daniel Bean, Aurelie Mascio, Leilei Zhu, Amos A Folarin, Angus Roberts, Rebecca Bendayan, Mark P Richardson, Robert Stewart, Anoop D Shah, Wai Keong Wong, Zina Ibrahim, James T Teo, Richard JB Dobson</h3>
<p>Electronic health records (EHR) contain large volumes of unstructured text,
requiring the application of Information Extraction (IE) technologies to enable
clinical analysis. We present the open source Medical Concept Annotation
Toolkit (MedCAT) that provides: a) a novel self-supervised machine learning
algorithm for extracting concepts using any concept vocabulary including
UMLS/SNOMED-CT; b) a feature-rich annotation interface for customizing and
training IE models; and c) integrations to the broader CogStack ecosystem for
vendor-agnostic health system deployment. We show improved performance in
extracting UMLS concepts from open datasets ( F1 0.467-0.791 vs 0.384-0.691).
Further real-world validation demonstrates SNOMED-CT extraction at 3 large
London hospitals with self-supervised training over ~8.8B words from ~17M
clinical records and further fine-tuning with ~6K clinician annotated examples.
We show strong transferability ( F1 &gt;0.94) between hospitals, datasets and
concept types indicating cross-domain EHR-agnostic utility for accelerated
clinical and research use cases.
</p>
<a href="http://arxiv.org/abs/2010.01165" target="_blank">arXiv:2010.01165</a> [<a href="http://arxiv.org/pdf/2010.01165" target="_blank">pdf</a>]

<h2>AI pptX: Robust Continuous Learning for Document Generation with AI Insights. (arXiv:2010.01169v1 [cs.CL])</h2>
<h3>Vineeth Ravi, Selim Amrouni, Andrea Stefanucci, Prashant Reddy, Manuela Veloso</h3>
<p>Business analysts create billions of slide decks, reports and documents
annually. Most of these documents have well-defined structure comprising of
similar content generated from data. We present 'AI pptX', a novel AI framework
for creating and modifying documents as well as extract insights in the form of
natural language sentences from data. AI pptX has three main components: (i) a
component that translates users' natural language input into 'skills' that
encapsulate content editing and formatting commands, (ii) a robust continuously
learning component that interacts with users, and (iii) a component that
automatically generates hierarchical insights in the form of natural language
sentences. We illustrate (i) and (ii) with a study of 18 human users tasked to
create a presentation deck and observe the learning capability from a decrease
in user-input commands by up to 45%. We demonstrate the robust learning
capability of AI pptX with experimental simulations of non-collaborative users.
We illustrate (i) and (iii) by automatically generating insights in natural
language using a data set from the Electricity Transmission Network of France
(RTE); we show that a complex statistical analysis of series can automatically
be distilled into easily interpretable explanations called AI Insights.
</p>
<a href="http://arxiv.org/abs/2010.01169" target="_blank">arXiv:2010.01169</a> [<a href="http://arxiv.org/pdf/2010.01169" target="_blank">pdf</a>]

<h2>Deep Expectation-Maximization for Semi-Supervised Lung Cancer Screening. (arXiv:2010.01173v1 [cs.LG])</h2>
<h3>Sumeet Menon, David Chapman, Phuong Nguyen, Yelena Yesha, Michael Morris, Babak Saboury</h3>
<p>We present a semi-supervised algorithm for lung cancer screening in which a
3D Convolutional Neural Network (CNN) is trained using the
Expectation-Maximization (EM) meta-algorithm. Semi-supervised learning allows a
smaller labelled data-set to be combined with an unlabeled data-set in order to
provide a larger and more diverse training sample. EM allows the algorithm to
simultaneously calculate a maximum likelihood estimate of the CNN training
coefficients along with the labels for the unlabeled training set which are
defined as a latent variable space. We evaluate the model performance of the
Semi-Supervised EM algorithm for CNNs through cross-domain training of the
Kaggle Data Science Bowl 2017 (Kaggle17) data-set with the National Lung
Screening Trial (NLST) data-set. Our results show that the Semi-Supervised EM
algorithm greatly improves the classification accuracy of the cross-domain lung
cancer screening, although results are lower than a fully supervised approach
with the advantage of additional labelled data from the unsupervised sample. As
such, we demonstrate that Semi-Supervised EM is a valuable technique to improve
the accuracy of lung cancer screening models using 3D CNNs.
</p>
<a href="http://arxiv.org/abs/2010.01173" target="_blank">arXiv:2010.01173</a> [<a href="http://arxiv.org/pdf/2010.01173" target="_blank">pdf</a>]

<h2>F2ED-Learning: Good Fences Make Good Neighbors. (arXiv:2010.01175v1 [cs.DC])</h2>
<h3>Lun Wang, Qi Pang, Shuai Wang, Dawn Song</h3>
<p>In this paper, we present F2ED-Learning, the first federated learning
protocol simultaneously defending against both a semi-honest server and
Byzantine malicious clients. Using a robust mean estimator called FilterL2,
F2ED-Learning is the first FL protocol providing dimension-free estimation
error against Byzantine malicious clients. Besides, F2ED-Learning leverages
secure aggregation to protect the clients from a semi-honest server who wants
to infer the clients' information from the legitimate updates. The main
challenge stems from the incompatibility between FilterL2 and secure
aggregation. Specifically, to run FilterL2, the server needs to access
individual updates from clients while secure aggregation hides those updates
from it. We propose to split the clients into shards, securely aggregate each
shard's updates and run FilterL2 on the updates from different shards. The
evaluation shows that F2ED-Learning consistently achieves optimal or
sub-optimal performance under three attacks among five robust FL protocols.
</p>
<a href="http://arxiv.org/abs/2010.01175" target="_blank">arXiv:2010.01175</a> [<a href="http://arxiv.org/pdf/2010.01175" target="_blank">pdf</a>]

<h2>The Surprising Power of Graph Neural Networks with Random Node Initialization. (arXiv:2010.01179v1 [cs.LG])</h2>
<h3>Ralph Abboud, &#x130;smail &#x130;lkan Ceylan, Martin Grohe, Thomas Lukasiewicz</h3>
<p>Graph neural networks (GNNs) are effective models for representation learning
on graph-structured data. However, standard GNNs are limited in their
expressive power, as they cannot distinguish graphs beyond the capability of
the Weisfeiler-Leman (1-WL) graph isomorphism heuristic. This limitation
motivated a large body of work, including higher-order GNNs, which are provably
more powerful models. To date, higher-order invariant and equivariant networks
are the only models with known universality results, but these results are
practically hindered by prohibitive computational complexity. Thus, despite
their limitations, standard GNNs are commonly used, due to their strong
practical performance. In practice, GNNs have shown a promising performance
when enhanced with random node initialization (RNI), where the idea is to train
and run the models with randomized initial node features. In this paper, we
analyze the expressive power of GNNs with RNI, and pose the following question:
are GNNs with RNI more expressive than GNNs? We prove that this is indeed the
case, by showing that GNNs with RNI are universal, a first such result for GNNs
not relying on computationally demanding higher-order properties. We then
empirically analyze the effect of RNI on GNNs, based on carefully constructed
datasets. Our empirical findings support the superior performance of GNNs with
RNI over standard GNNs. In fact, we demonstrate that the performance of GNNs
with RNI is often comparable with or better than that of higher-order GNNs,
while keeping the much lower memory requirements of standard GNNs. However,
this improvement typically comes at the cost of slower model convergence.
Somewhat surprisingly, we found that the convergence rate and the accuracy of
the models can be improved by using only a partial random initialization
regime.
</p>
<a href="http://arxiv.org/abs/2010.01179" target="_blank">arXiv:2010.01179</a> [<a href="http://arxiv.org/pdf/2010.01179" target="_blank">pdf</a>]

<h2>Reinforcement Learning of Simple Indirect Mechanisms. (arXiv:2010.01180v1 [cs.GT])</h2>
<h3>Gianluca Brero, Alon Eden, Matthias Gerstgrasser, David C. Parkes, Duncan Rheingans-Yoo</h3>
<p>We introduce the use of reinforcement learning for indirect mechanisms,
working with the existing class of {\em sequential price mechanisms}, which
generalizes both serial dictatorship and posted price mechanisms and
essentially characterizes all strongly obviously strategyproof mechanisms.
Learning an optimal mechanism within this class forms a partially-observable
Markov decision process. We provide rigorous conditions for when this class of
mechanisms is more powerful than simpler static mechanisms, for sufficiency or
insufficiency of observation statistics for learning, and for the necessity of
complex (deep) policies. We show that our approach can learn optimal or
near-optimal mechanisms in several experimental settings.
</p>
<a href="http://arxiv.org/abs/2010.01180" target="_blank">arXiv:2010.01180</a> [<a href="http://arxiv.org/pdf/2010.01180" target="_blank">pdf</a>]

<h2>Covariate Shift Adaptation in High-Dimensional and Divergent Distributions. (arXiv:2010.01184v1 [stat.ML])</h2>
<h3>Felipe Maia Polo, Renato Vicente</h3>
<p>In real world applications of supervised learning methods, training and test
sets are often sampled from the distinct distributions and we must resort to
domain adaptation techniques. One special class of techniques is Covariate
Shift Adaptation, which allows practitioners to obtain good generalization
performance in the distribution of interest when domains differ only by the
marginal distribution of features. Traditionally, Covariate Shift Adaptation is
implemented using Importance Weighting which may fail in high-dimensional
settings due to small Effective Sample Sizes (ESS). In this paper, we propose
(i) a connection between ESS, high-dimensional settings and generalization
bounds and (ii) a simple, general and theoretically sound approach to combine
feature selection and Covariate Shift Adaptation. The new approach yields good
performance with improved ESS.
</p>
<a href="http://arxiv.org/abs/2010.01184" target="_blank">arXiv:2010.01184</a> [<a href="http://arxiv.org/pdf/2010.01184" target="_blank">pdf</a>]

<h2>Neighbourhood Distillation: On the benefits of non end-to-end distillation. (arXiv:2010.01189v1 [cs.LG])</h2>
<h3>La&#xeb;titia Shao, Elad Eban, Yair Movshovitz-Attias</h3>
<p>End-to-end training with back propagation is the standard method for training
deep neural networks. However, as networks become deeper and bigger, end-to-end
training becomes more challenging: highly non-convex models gets stuck easily
in local optima, gradients signals are prone to vanish or explode during
back-propagation, training requires computational resources and time. In this
work, we propose to break away from the end-to-end paradigm in the context of
Knowledge Distillation. Instead of distilling a model end-to-end, we propose to
split it into smaller sub-networks - also called neighbourhoods - that are then
trained independently. We empirically show that distilling networks in a non
end-to-end fashion can be beneficial in a diverse range of use cases. First, we
show that it speeds up Knowledge Distillation by exploiting parallelism and
training on smaller networks. Second, we show that independently distilled
neighbourhoods may be efficiently re-used for Neural Architecture Search.
Finally, because smaller networks model simpler functions, we show that they
are easier to train with synthetic data than their deeper counterparts.
</p>
<a href="http://arxiv.org/abs/2010.01189" target="_blank">arXiv:2010.01189</a> [<a href="http://arxiv.org/pdf/2010.01189" target="_blank">pdf</a>]

<h2>Semantic MapNet: Building Allocentric SemanticMaps and Representations from Egocentric Views. (arXiv:2010.01191v1 [cs.CV])</h2>
<h3>Vincent Cartillier, Zhile Ren, Neha Jain, Stefan Lee, Irfan Essa, Dhruv Batra</h3>
<p>We study the task of semantic mapping - specifically, an embodied agent (a
robot or an egocentric AI assistant) is given a tour of a new environment and
asked to build an allocentric top-down semantic map ("what is where?") from
egocentric observations of an RGB-D camera with known pose (via localization
sensors). Towards this goal, we present SemanticMapNet (SMNet), which consists
of: (1) an Egocentric Visual Encoder that encodes each egocentric RGB-D frame,
(2) a Feature Projector that projects egocentric features to appropriate
locations on a floor-plan, (3) a Spatial Memory Tensor of size floor-plan
length x width x feature-dims that learns to accumulate projected egocentric
features, and (4) a Map Decoder that uses the memory tensor to produce semantic
top-down maps. SMNet combines the strengths of (known) projective camera
geometry and neural representation learning. On the task of semantic mapping in
the Matterport3D dataset, SMNet significantly outperforms competitive baselines
by 4.01-16.81% (absolute) on mean-IoU and 3.81-19.69% (absolute) on Boundary-F1
metrics. Moreover, we show how to use the neural episodic memories and
spatio-semantic allocentric representations build by SMNet for subsequent tasks
in the same space - navigating to objects seen during the tour("Find chair") or
answering questions about the space ("How many chairs did you see in the
house?").
</p>
<a href="http://arxiv.org/abs/2010.01191" target="_blank">arXiv:2010.01191</a> [<a href="http://arxiv.org/pdf/2010.01191" target="_blank">pdf</a>]

<h2>Correcting Experience Replay for Multi-Agent Communication. (arXiv:2010.01192v1 [cs.LG])</h2>
<h3>Sanjeevan Ahilan, Peter Dayan</h3>
<p>We consider the problem of learning to communicate using multi-agent
reinforcement learning (MARL). A common approach is to learn off-policy, using
data sampled from a replay buffer. However, messages received in the past may
not accurately reflect the current communication policy of each agent, and this
complicates learning. We therefore introduce a 'communication correction' which
accounts for the non-stationarity of observed communication induced by
multi-agent learning. It works by relabelling the received message to make it
likely under the communicator's current policy, and thus be a better reflection
of the receiver's current environment. To account for cases in which agents are
both senders and receivers, we introduce an ordered relabelling scheme. Our
correction is computationally efficient and can be integrated with a range of
off-policy algorithms. It substantially improves the ability of communicating
MARL systems to learn across a variety of cooperative and competitive tasks.
</p>
<a href="http://arxiv.org/abs/2010.01192" target="_blank">arXiv:2010.01192</a> [<a href="http://arxiv.org/pdf/2010.01192" target="_blank">pdf</a>]

<h2>Leveraging Semantic and Lexical Matching to Improve the Recall of Document Retrieval Systems: A Hybrid Approach. (arXiv:2010.01195v1 [cs.IR])</h2>
<h3>Saar Kuzi, Mingyang Zhang, Cheng Li, Michael Bendersky, Marc Najork</h3>
<p>Search engines often follow a two-phase paradigm where in the first stage
(the retrieval stage) an initial set of documents is retrieved and in the
second stage (the re-ranking stage) the documents are re-ranked to obtain the
final result list. While deep neural networks were shown to improve the
performance of the re-ranking stage in previous works, there is little
literature about using deep neural networks to improve the retrieval stage. In
this paper, we study the merits of combining deep neural network models and
lexical models for the retrieval stage. A hybrid approach, which leverages both
semantic (deep neural network-based) and lexical (keyword matching-based)
retrieval models, is proposed. We perform an empirical study, using a publicly
available TREC collection, which demonstrates the effectiveness of our approach
and sheds light on the different characteristics of the semantic approach, the
lexical approach, and their combination.
</p>
<a href="http://arxiv.org/abs/2010.01195" target="_blank">arXiv:2010.01195</a> [<a href="http://arxiv.org/pdf/2010.01195" target="_blank">pdf</a>]

<h2>Stock2Vec: A Hybrid Deep Learning Framework for Stock Market Prediction with Representation Learning and Temporal Convolutional Network. (arXiv:2010.01197v1 [q-fin.ST])</h2>
<h3>Xing Wang, Yijun Wang, Bin Weng, Aleksandr Vinel</h3>
<p>We have proposed to develop a global hybrid deep learning framework to
predict the daily prices in the stock market. With representation learning, we
derived an embedding called Stock2Vec, which gives us insight for the
relationship among different stocks, while the temporal convolutional layers
are used for automatically capturing effective temporal patterns both within
and across series. Evaluated on S&amp;P 500, our hybrid framework integrates both
advantages and achieves better performance on the stock price prediction task
than several popular benchmarked models.
</p>
<a href="http://arxiv.org/abs/2010.01197" target="_blank">arXiv:2010.01197</a> [<a href="http://arxiv.org/pdf/2010.01197" target="_blank">pdf</a>]

<h2>FPGA Implementation of Simplified Spiking Neural Network. (arXiv:2010.01200v1 [cs.NE])</h2>
<h3>Shikhar Gupta, Arpan Vyas, Gaurav Trivedi</h3>
<p>Spiking Neural Networks (SNN) are third-generation Artificial Neural Networks
(ANN) which are close to the biological neural system. In recent years SNN has
become popular in the area of robotics and embedded applications, therefore, it
has become imperative to explore its real-time and energy-efficient
implementations. SNNs are more powerful than their predecessors because they
encode temporal information and use biologically plausible plasticity rules. In
this paper, a simpler and computationally efficient SNN model using FPGA
architecture is described. The proposed model is validated on a Xilinx Virtex 6
FPGA and analyzes a fully connected network which consists of 800 neurons and
12,544 synapses in real-time.
</p>
<a href="http://arxiv.org/abs/2010.01200" target="_blank">arXiv:2010.01200</a> [<a href="http://arxiv.org/pdf/2010.01200" target="_blank">pdf</a>]

<h2>Background Adaptive Faster R-CNN for Semi-Supervised Convolutional Object Detection of Threats in X-Ray Images. (arXiv:2010.01202v1 [cs.CV])</h2>
<h3>John B. Sigman, Gregory P. Spell, Kevin J Liang, Lawrence Carin</h3>
<p>Recently, progress has been made in the supervised training of Convolutional
Object Detectors (e.g. Faster R-CNN) for threat recognition in carry-on luggage
using X-ray images. This is part of the Transportation Security
Administration's (TSA's) mission to protect air travelers in the United States.
While more training data with threats may reliably improve performance for this
class of deep algorithm, it is expensive to stage in realistic contexts. By
contrast, data from the real world can be collected quickly with minimal cost.
In this paper, we present a semi-supervised approach for threat recognition
which we call Background Adaptive Faster R-CNN. This approach is a training
method for two-stage object detectors which uses Domain Adaptation methods from
the field of deep learning. The data sources described earlier make two
"domains": a hand-collected data domain of images with threats, and a
real-world domain of images assumed without threats. Two domain discriminators,
one for discriminating object proposals and one for image features, are
adversarially trained to prevent encoding domain-specific information. Without
this penalty a Convolutional Neural Network (CNN) can learn to identify domains
based on superficial characteristics, and minimize a supervised loss function
without improving its ability to recognize objects. For the hand-collected
data, only object proposals and image features from backgrounds are used. The
losses for these domain-adaptive discriminators are added to the Faster R-CNN
losses of images from both domains. This can reduce threat detection false
alarm rates by matching the statistics of extracted features from
hand-collected backgrounds to real world data. Performance improvements are
demonstrated on two independently-collected datasets of labeled threats.
</p>
<a href="http://arxiv.org/abs/2010.01202" target="_blank">arXiv:2010.01202</a> [<a href="http://arxiv.org/pdf/2010.01202" target="_blank">pdf</a>]

<h2>$f$-GAIL: Learning $f$-Divergence for Generative Adversarial Imitation Learning. (arXiv:2010.01207v1 [cs.LG])</h2>
<h3>Xin Zhang, Yanhua Li, Ziming Zhang, Zhi-Li Zhang</h3>
<p>Imitation learning (IL) aims to learn a policy from expert demonstrations
that minimizes the discrepancy between the learner and expert behaviors.
Various imitation learning algorithms have been proposed with different
pre-determined divergences to quantify the discrepancy. This naturally gives
rise to the following question: Given a set of expert demonstrations, which
divergence can recover the expert policy more accurately with higher data
efficiency? In this work, we propose $f$-GAIL, a new generative adversarial
imitation learning (GAIL) model, that automatically learns a discrepancy
measure from the $f$-divergence family as well as a policy capable of producing
expert-like behaviors. Compared with IL baselines with various predefined
divergence measures, $f$-GAIL learns better policies with higher data
efficiency in six physics-based control tasks.
</p>
<a href="http://arxiv.org/abs/2010.01207" target="_blank">arXiv:2010.01207</a> [<a href="http://arxiv.org/pdf/2010.01207" target="_blank">pdf</a>]

<h2>Artificial Intelligence Enabled Traffic Monitoring System. (arXiv:2010.01217v1 [cs.CV])</h2>
<h3>Vishal Mandal, Abdul Rashid Mussah, Peng Jin, Yaw Adu-Gyamfi</h3>
<p>Manual traffic surveillance can be a daunting task as Traffic Management
Centers operate a myriad of cameras installed over a network. Injecting some
level of automation could help lighten the workload of human operators
performing manual surveillance and facilitate making proactive decisions which
would reduce the impact of incidents and recurring congestion on roadways. This
article presents a novel approach to automatically monitor real time traffic
footage using deep convolutional neural networks and a stand-alone graphical
user interface. The authors describe the results of research received in the
process of developing models that serve as an integrated framework for an
artificial intelligence enabled traffic monitoring system. The proposed system
deploys several state-of-the-art deep learning algorithms to automate different
traffic monitoring needs. Taking advantage of a large database of annotated
video surveillance data, deep learning-based models are trained to detect
queues, track stationary vehicles, and tabulate vehicle counts. A pixel-level
segmentation approach is applied to detect traffic queues and predict severity.
Real-time object detection algorithms coupled with different tracking systems
are deployed to automatically detect stranded vehicles as well as perform
vehicular counts. At each stages of development, interesting experimental
results are presented to demonstrate the effectiveness of the proposed system.
Overall, the results demonstrate that the proposed framework performs
satisfactorily under varied conditions without being immensely impacted by
environmental hazards such as blurry camera views, low illumination, rain, or
snow.
</p>
<a href="http://arxiv.org/abs/2010.01217" target="_blank">arXiv:2010.01217</a> [<a href="http://arxiv.org/pdf/2010.01217" target="_blank">pdf</a>]

<h2>Video Saliency Detection with Domain Adaption using Hierarchical Gradient Reversal Layers. (arXiv:2010.01220v1 [cs.CV])</h2>
<h3>Giovanni Bellitto, Federica Proietto Salanitri, Simone Palazzo, Francesco Rundo, Daniela Giordano, Concetto Spampinato</h3>
<p>In this work, we propose a 3D fully convolutional architecture for video
saliency detection that employs multi-head supervision on intermediate maps
(referred to as conspicuity maps) generated using features extracted at
different abstraction level. More specifically, the model employs a single
encoder and features extracted at different levels are then passed to multiple
decoders aiming at predicting multiple saliency instances that are finally
combined to obtain final output saliency maps. We also combine the hierarchical
features extracted from the model's encoder with a domain adaptation approach
based on gradient reversal at multiple scales in order to improve the
generalization capabilities on datasets for which no annotations are provided
during training. The results of our experiments on standard benchmarks, namely
DHF1K, Hollywood2 and UCF Sports, show that the proposed model outperforms
state-of-the-art methods on most metrics for supervised saliency prediction.
Moreover, when tested in an unsupervised settings, it is able to obtain
performance comparable to those achieved by supervised state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/2010.01220" target="_blank">arXiv:2010.01220</a> [<a href="http://arxiv.org/pdf/2010.01220" target="_blank">pdf</a>]

<h2>Stuttering Speech Disfluency Prediction using Explainable Attribution Vectors of Facial Muscle Movements. (arXiv:2010.01231v1 [cs.CV])</h2>
<h3>Arun Das, Jeffrey Mock, Henry Chacon, Farzan Irani, Edward Golob, Peyman Najafirad</h3>
<p>Speech disorders such as stuttering disrupt the normal fluency of speech by
involuntary repetitions, prolongations and blocking of sounds and syllables. In
addition to these disruptions to speech fluency, most adults who stutter (AWS)
also experience numerous observable secondary behaviors before, during, and
after a stuttering moment, often involving the facial muscles. Recent studies
have explored automatic detection of stuttering using Artificial Intelligence
(AI) based algorithm from respiratory rate, audio, etc. during speech
utterance. However, most methods require controlled environments and/or
invasive wearable sensors, and are unable explain why a decision (fluent vs
stuttered) was made. We hypothesize that pre-speech facial activity in AWS,
which can be captured non-invasively, contains enough information to accurately
classify the upcoming utterance as either fluent or stuttered. Towards this
end, this paper proposes a novel explainable AI (XAI) assisted convolutional
neural network (CNN) classifier to predict near future stuttering by learning
temporal facial muscle movement patterns of AWS and explains the important
facial muscles and actions involved. Statistical analyses reveal significantly
high prevalence of cheek muscles (p&lt;0.005) and lip muscles (p&lt;0.005) to predict
stuttering and shows a behavior conducive of arousal and anticipation to speak.
The temporal study of these upper and lower facial muscles may facilitate early
detection of stuttering, promote automated assessment of stuttering and have
application in behavioral therapies by providing automatic non-invasive
feedback in realtime.
</p>
<a href="http://arxiv.org/abs/2010.01231" target="_blank">arXiv:2010.01231</a> [<a href="http://arxiv.org/pdf/2010.01231" target="_blank">pdf</a>]

<h2>A Deep Genetic Programming based Methodology for Art Media Classification Robust to Adversarial Perturbations. (arXiv:2010.01238v1 [cs.CV])</h2>
<h3>Gustavo Olague, Gerardo Ibarra-Vazquez, Mariana Chan-Ley, Cesar Puente, Carlos Soubervielle-Montalvo, Axel Martinez</h3>
<p>Art Media Classification problem is a current research area that has
attracted attention due to the complex extraction and analysis of features of
high-value art pieces. The perception of the attributes can not be subjective,
as humans sometimes follow a biased interpretation of artworks while ensuring
automated observation's trustworthiness. Machine Learning has outperformed many
areas through its learning process of artificial feature extraction from images
instead of designing handcrafted feature detectors. However, a major concern
related to its reliability has brought attention because, with small
perturbations made intentionally in the input image (adversarial attack), its
prediction can be completely changed. In this manner, we foresee two ways of
approaching the situation: (1) solve the problem of adversarial attacks in
current neural networks methodologies, or (2) propose a different approach that
can challenge deep learning without the effects of adversarial attacks. The
first one has not been solved yet, and adversarial attacks have become even
more complex to defend. Therefore, this work presents a Deep Genetic
Programming method, called Brain Programming, that competes with deep learning
and studies the transferability of adversarial attacks using two artworks
databases made by art experts. The results show that the Brain Programming
method preserves its performance in comparison with AlexNet, making it robust
to these perturbations and competing to the performance of Deep Learning.
</p>
<a href="http://arxiv.org/abs/2010.01238" target="_blank">arXiv:2010.01238</a> [<a href="http://arxiv.org/pdf/2010.01238" target="_blank">pdf</a>]

<h2>Nonconvex Regularization for Network Slimming:Compressing CNNs Even More. (arXiv:2010.01242v1 [cs.CV])</h2>
<h3>Kevin Bui, Fredrick Park, Shuai Zhang, Yingyong Qi, Jack Xin</h3>
<p>In the last decade, convolutional neural networks (CNNs) have evolved to
become the dominant models for various computer vision tasks, but they cannot
be deployed in low-memory devices due to its high memory requirement and
computational cost. One popular, straightforward approach to compressing CNNs
is network slimming, which imposes an $\ell_1$ penalty on the
channel-associated scaling factors in the batch normalization layers during
training. In this way, channels with low scaling factors are identified to be
insignificant and are pruned in the models. In this paper, we propose replacing
the $\ell_1$ penalty with the $\ell_p$ and transformed $\ell_1$ (T$\ell_1$)
penalties since these nonconvex penalties outperformed $\ell_1$ in yielding
sparser satisfactory solutions in various compressed sensing problems. In our
numerical experiments, we demonstrate network slimming with $\ell_p$ and
T$\ell_1$ penalties on VGGNet and Densenet trained on CIFAR 10/100. The results
demonstrate that the nonconvex penalties compress CNNs better than $\ell_1$. In
addition, T$\ell_1$ preserves the model accuracy after channel pruning, and
$\ell_{1/2, 3/4}$ yield compressed models with similar accuracies as $\ell_1$
after retraining.
</p>
<a href="http://arxiv.org/abs/2010.01242" target="_blank">arXiv:2010.01242</a> [<a href="http://arxiv.org/pdf/2010.01242" target="_blank">pdf</a>]

<h2>Client Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies. (arXiv:2010.01243v1 [cs.LG])</h2>
<h3>Yae Jee Cho, Jianyu Wang, Gauri Joshi</h3>
<p>Federated learning is a distributed optimization paradigm that enables a
large number of resource-limited client nodes to cooperatively train a model
without data sharing. Several works have analyzed the convergence of federated
learning by accounting of data heterogeneity, communication and computation
limitations, and partial client participation. However, they assume unbiased
client participation, where clients are selected at random or in proportion of
their data sizes. In this paper, we present the first convergence analysis of
federated optimization for biased client selection strategies, and quantify how
the selection bias affects convergence speed. We reveal that biasing client
selection towards clients with higher local loss achieves faster error
convergence. Using this insight, we propose Power-of-Choice, a communication-
and computation-efficient client selection framework that can flexibly span the
trade-off between convergence speed and solution bias. Our experiments
demonstrate that Power-of-Choice strategies converge up to 3 $\times$ faster
and give $10$% higher test accuracy than the baseline random selection.
</p>
<a href="http://arxiv.org/abs/2010.01243" target="_blank">arXiv:2010.01243</a> [<a href="http://arxiv.org/pdf/2010.01243" target="_blank">pdf</a>]

<h2>Consensus Clustering with Unsupervised Representation Learning. (arXiv:2010.01245v1 [cs.CV])</h2>
<h3>Jayanth Reddy Regatti, Aniket Anand Deshmukh, Eren Manavoglu, Urun Dogan</h3>
<p>Recent advances in deep clustering and unsupervised representation learning
are based on the idea that different views of an input image (generated through
data augmentation techniques) must either be closer in the representation
space, or have a similar cluster assignment. In this work, we leverage this
idea together with ensemble learning to perform clustering and representation
learning. Ensemble learning is widely used in the supervised learning setting
but has not yet been practical in deep clustering. Previous works on ensemble
learning for clustering neither work on the feature space nor learn features.
We propose a novel ensemble learning algorithm dubbed Consensus Clustering with
Unsupervised Representation Learning (ConCURL) which learns representations by
creating a consensus on multiple clustering outputs. Specifically, we generate
a cluster ensemble using random transformations on the embedding space, and
define a consensus loss function that measures the disagreement among the
constituents of the ensemble. Thus, diverse ensembles minimize this loss
function in a synergistic way, which leads to better representations that work
with all cluster ensemble constituents. Our proposed method ConCURL is easy to
implement and integrate into any representation learning or deep clustering
block. ConCURL outperforms all state of the art methods on various computer
vision datasets. Specifically, we beat the closest state of the art method by
5.9 percent on the ImageNet-10 dataset, and by 18 percent on the ImageNet-Dogs
dataset in terms of clustering accuracy. We further shed some light on the
under-studied overfitting issue in clustering and show that our method does not
overfit as much as existing methods, and thereby generalizes better for new
data samples.
</p>
<a href="http://arxiv.org/abs/2010.01245" target="_blank">arXiv:2010.01245</a> [<a href="http://arxiv.org/pdf/2010.01245" target="_blank">pdf</a>]

<h2>CorrAttack: Black-box Adversarial Attack with Structured Search. (arXiv:2010.01250v1 [cs.LG])</h2>
<h3>Zhichao Huang, Yaowei Huang, Tong Zhang</h3>
<p>We present a new method for score-based adversarial attack, where the
attacker queries the loss-oracle of the target model. Our method employs a
parameterized search space with a structure that captures the relationship of
the gradient of the loss function. We show that searching over the structured
space can be approximated by a time-varying contextual bandits problem, where
the attacker takes feature of the associated arm to make modifications of the
input, and receives an immediate reward as the reduction of the loss function.
The time-varying contextual bandits problem can then be solved by a Bayesian
optimization procedure, which can take advantage of the features of the
structured action space. The experiments on ImageNet and the Google Cloud
Vision API demonstrate that the proposed method achieves the state of the art
success rates and query efficiencies for both undefended and defended models.
</p>
<a href="http://arxiv.org/abs/2010.01250" target="_blank">arXiv:2010.01250</a> [<a href="http://arxiv.org/pdf/2010.01250" target="_blank">pdf</a>]

<h2>UCP: Uniform Channel Pruning for Deep Convolutional Neural Networks Compression and Acceleration. (arXiv:2010.01251v1 [cs.CV])</h2>
<h3>Jingfei Chang, Yang Lu, Ping Xue, Xing Wei, Zhen Wei</h3>
<p>To apply deep CNNs to mobile terminals and portable devices, many scholars
have recently worked on the compressing and accelerating deep convolutional
neural networks. Based on this, we propose a novel uniform channel pruning
(UCP) method to prune deep CNN, and the modified squeeze-and-excitation blocks
(MSEB) is used to measure the importance of the channels in the convolutional
layers. The unimportant channels, including convolutional kernels related to
them, are pruned directly, which greatly reduces the storage cost and the
number of calculations. There are two types of residual blocks in ResNet. For
ResNet with bottlenecks, we use the pruning method with traditional CNN to trim
the 3x3 convolutional layer in the middle of the blocks. For ResNet with basic
residual blocks, we propose an approach to consistently prune all residual
blocks in the same stage to ensure that the compact network structure is
dimensionally correct. Considering that the network loses considerable
information after pruning and that the larger the pruning amplitude is, the
more information that will be lost, we do not choose fine-tuning but retrain
from scratch to restore the accuracy of the network after pruning. Finally, we
verified our method on CIFAR-10, CIFAR-100 and ILSVRC-2012 for image
classification. The results indicate that the performance of the compact
network after retraining from scratch, when the pruning rate is small, is
better than the original network. Even when the pruning amplitude is large, the
accuracy can be maintained or decreased slightly. On the CIFAR-100, when
reducing the parameters and FLOPs up to 82% and 62% respectively, the accuracy
of VGG-19 even improved by 0.54% after retraining.
</p>
<a href="http://arxiv.org/abs/2010.01251" target="_blank">arXiv:2010.01251</a> [<a href="http://arxiv.org/pdf/2010.01251" target="_blank">pdf</a>]

<h2>Attractor Selection in Nonlinear Energy Harvesting Using Deep Reinforcement Learning. (arXiv:2010.01255v1 [eess.SY])</h2>
<h3>Xue-She Wang, Brian P. Mann</h3>
<p>Recent research efforts demonstrate that the intentional use of nonlinearity
enhances the capabilities of energy harvesting systems. One of the primary
challenges that arise in nonlinear harvesters is that nonlinearities can often
result in multiple attractors with both desirable and undesirable responses
that may co-exist. This paper presents a nonlinear energy harvester which is
based on translation-to-rotational magnetic transmission and exhibits
coexisting attractors with different levels of electric power output. In
addition, a control method using deep reinforcement learning was proposed to
realize attractor switching between coexisting attractors with constrained
actuation.
</p>
<a href="http://arxiv.org/abs/2010.01255" target="_blank">arXiv:2010.01255</a> [<a href="http://arxiv.org/pdf/2010.01255" target="_blank">pdf</a>]

<h2>Cartographic Relief Shading with Neural Networks. (arXiv:2010.01256v1 [cs.GR])</h2>
<h3>Bernhard Jenny, Magnus Heitzler, Dilpreet Singh, Marianna Farmakis-Serebryakova, Jeffery Chieh Liu, Lorenz Hurni</h3>
<p>Shaded relief is an effective method for visualising terrain on topographic
maps, especially when the direction of illumination is adapted locally to
emphasise individual terrain features. However, digital shading algorithms are
unable to fully match the expressiveness of hand-crafted masterpieces, which
are created through a laborious process by highly specialised cartographers. We
replicate hand-drawn relief shading using U-Net neural networks. The deep
neural networks are trained with manual shaded relief images of the Swiss
topographic map series and terrain models of the same area. The networks
generate shaded relief that closely resemble hand-drawn shaded relief art. The
networks learn essential design principles from manual relief shading such as
removing unnecessary terrain details, locally adjusting the illumination
direction to accentuate individual terrain features, and varying brightness to
emphasise larger landforms. Neural network shadings are generated from digital
elevation models in a few seconds, and a study with 18 relief shading experts
found that they are of high quality.
</p>
<a href="http://arxiv.org/abs/2010.01256" target="_blank">arXiv:2010.01256</a> [<a href="http://arxiv.org/pdf/2010.01256" target="_blank">pdf</a>]

<h2>Multilevel Text Alignment with Cross-Document Attention. (arXiv:2010.01263v1 [cs.CL])</h2>
<h3>Xuhui Zhou, Nikolaos Pappas, Noah A. Smith</h3>
<p>Text alignment finds application in tasks such as citation recommendation and
plagiarism detection. Existing alignment methods operate at a single,
predefined level and cannot learn to align texts at, for example, sentence and
document levels. We propose a new learning approach that equips previously
established hierarchical attention encoders for representing documents with a
cross-document attention component, enabling structural comparisons across
different levels (document-to-document and sentence-to-document). Our component
is weakly supervised from document pairs and can align at multiple levels. Our
evaluation on predicting document-to-document relationships and
sentence-to-document relationships on the tasks of citation recommendation and
plagiarism detection shows that our approach outperforms previously established
hierarchical, attention encoders based on recurrent and transformer
contextualization that are unaware of structural correspondence between
documents.
</p>
<a href="http://arxiv.org/abs/2010.01263" target="_blank">arXiv:2010.01263</a> [<a href="http://arxiv.org/pdf/2010.01263" target="_blank">pdf</a>]

<h2>HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients. (arXiv:2010.01264v1 [cs.LG])</h2>
<h3>Enmao Diao, Jie Ding, Vahid Tarokh</h3>
<p>Federated Learning (FL) is a method of training machine learning models on
private data distributed over a large number of possibly heterogeneous clients
such as mobile phones and IoT devices. In this work, we propose a new federated
learning framework named HeteroFL to address heterogeneous clients equipped
with very different computation and communication capabilities. Our solution
can enable the training of heterogeneous local models with varying computation
complexities and still produce a single global inference model. For the first
time, our method challenges the underlying assumption of existing work that
local models have to share the same architecture as the global model. We
demonstrate several strategies to enhance FL training and conduct extensive
empirical evaluations, including five computation complexity levels of three
model architecture on three datasets. We show that adaptively distributing
subnetworks according to clients' capabilities is both computation and
communication efficient.
</p>
<a href="http://arxiv.org/abs/2010.01264" target="_blank">arXiv:2010.01264</a> [<a href="http://arxiv.org/pdf/2010.01264" target="_blank">pdf</a>]

<h2>DoubleEnsemble: A New Ensemble Method Based on Sample Reweighting and Feature Selection for Financial Data Analysis. (arXiv:2010.01265v1 [cs.LG])</h2>
<h3>Chuheng Zhang, Yuanqi Li, Xi Chen, Yifei Jin, Pingzhong Tang, Jian Li</h3>
<p>Modern machine learning models (such as deep neural networks and boosting
decision tree models) have become increasingly popular in financial market
prediction, due to their superior capacity to extract complex non-linear
patterns. However, since financial datasets have very low signal-to-noise ratio
and are non-stationary, complex models are often very prone to overfitting and
suffer from instability issues. Moreover, as various machine learning and data
mining tools become more widely used in quantitative trading, many trading
firms have been producing an increasing number of features (aka factors).
Therefore, how to automatically select effective features becomes an imminent
problem. To address these issues, we propose DoubleEnsemble, an ensemble
framework leveraging learning trajectory based sample reweighting and shuffling
based feature selection. Specifically, we identify the key samples based on the
training dynamics on each sample and elicit key features based on the ablation
impact of each feature via shuffling. Our model is applicable to a wide range
of base models, capable of extracting complex patterns, while mitigating the
overfitting and instability issues for financial market prediction. We conduct
extensive experiments, including price prediction for cryptocurrencies and
stock trading, using both DNN and gradient boosting decision tree as base
models. Our experiment results demonstrate that DoubleEnsemble achieves a
superior performance compared with several baseline methods.
</p>
<a href="http://arxiv.org/abs/2010.01265" target="_blank">arXiv:2010.01265</a> [<a href="http://arxiv.org/pdf/2010.01265" target="_blank">pdf</a>]

<h2>Partially-Aligned Data-to-Text Generation with Distant Supervision. (arXiv:2010.01268v1 [cs.CL])</h2>
<h3>Zihao Fu, Bei Shi, Wai Lam, Lidong Bing, Zhiyuan Liu</h3>
<p>The Data-to-Text task aims to generate human-readable text for describing
some given structured data enabling more interpretability. However, the typical
generation task is confined to a few particular domains since it requires
well-aligned data which is difficult and expensive to obtain. Using
partially-aligned data is an alternative way of solving the dataset scarcity
problem. This kind of data is much easier to obtain since it can be produced
automatically. However, using this kind of data induces the over-generation
problem posing difficulties for existing models, which tends to add unrelated
excerpts during the generation procedure. In order to effectively utilize
automatically annotated partially-aligned datasets, we extend the traditional
generation task to a refined task called Partially-Aligned Data-to-Text
Generation (PADTG) which is more practical since it utilizes automatically
annotated data for training and thus considerably expands the application
domains. To tackle this new task, we propose a novel distant supervision
generation framework. It firstly estimates the input data's supportiveness for
each target word with an estimator and then applies a supportiveness adaptor
and a rebalanced beam search to harness the over-generation problem in the
training and generation phases respectively. We also contribute a
partially-aligned dataset (The data and source code of this paper can be
obtained from https://github.com/fuzihaofzh/distant_supervision_nlg by sampling
sentences from Wikipedia and automatically extracting corresponding KB triples
for each sentence from Wikidata. The experimental results show that our
framework outperforms all baseline models as well as verify the feasibility of
utilizing partially-aligned data.
</p>
<a href="http://arxiv.org/abs/2010.01268" target="_blank">arXiv:2010.01268</a> [<a href="http://arxiv.org/pdf/2010.01268" target="_blank">pdf</a>]

<h2>TCLNet: Learning to Locate Typhoon Center Using Deep Neural Network. (arXiv:2010.01282v1 [cs.CV])</h2>
<h3>Chao Tan</h3>
<p>The task of typhoon center location plays an important role in typhoon
intensity analysis and typhoon path prediction. Conventional typhoon center
location algorithms mostly rely on digital image processing and mathematical
morphology operation, which achieve limited performance. In this paper, we
proposed an efficient fully convolutional end-to-end deep neural network named
TCLNet to automatically locate the typhoon center position. We design the
network structure carefully so that our TCLNet can achieve remarkable
performance base on its lightweight architecture. In addition, we also present
a brand new large-scale typhoon center location dataset (TCLD) so that the
TCLNet can be trained in a supervised manner. Furthermore, we propose to use a
novel TCL+ piecewise loss function to further improve the performance of
TCLNet. Extensive experimental results and comparison demonstrate the
performance of our model, and our TCLNet achieve a 14.4% increase in accuracy
on the basis of a 92.7% reduction in parameters compared with SOTA deep
learning based typhoon center location methods.
</p>
<a href="http://arxiv.org/abs/2010.01282" target="_blank">arXiv:2010.01282</a> [<a href="http://arxiv.org/pdf/2010.01282" target="_blank">pdf</a>]

<h2>Generating the Cloud Motion Winds Field from Satellite Cloud Imagery Using Deep Learning Approach. (arXiv:2010.01283v1 [cs.CV])</h2>
<h3>Chao Tan</h3>
<p>Cloud motion winds (CMW) are routinely derived by tracking features in
sequential geostationary satellite infrared cloud imagery. In this paper, we
explore the cloud motion winds algorithm based on data-driven deep learning
approach, and different from conventional hand-craft feature tracking and
correlation matching algorithms, we use deep learning model to automatically
learn the motion feature representations and directly output the field of cloud
motion winds. In addition, we propose a novel large-scale cloud motion winds
dataset (CMWD) for training deep learning models. We also try to use a single
cloud imagery to predict the cloud motion winds field in a fixed region, which
is impossible to achieve using traditional algorithms. The experimental results
demonstrate that our algorithm can predict the cloud motion winds field
efficiently, and even with a single cloud imagery as input.
</p>
<a href="http://arxiv.org/abs/2010.01283" target="_blank">arXiv:2010.01283</a> [<a href="http://arxiv.org/pdf/2010.01283" target="_blank">pdf</a>]

<h2>Differentially Private Representation for NLP: Formal Guarantee and An Empirical Study on Privacy and Fairness. (arXiv:2010.01285v1 [cs.LG])</h2>
<h3>Lingjuan Lyu, Xuanli He, Yitong Li</h3>
<p>It has been demonstrated that hidden representation learned by a deep model
can encode private information of the input, hence can be exploited to recover
such information with reasonable accuracy. To address this issue, we propose a
novel approach called Differentially Private Neural Representation (DPNR) to
preserve the privacy of the extracted representation from text. DPNR utilises
Differential Privacy (DP) to provide a formal privacy guarantee. Further, we
show that masking words via dropout can further enhance privacy. To maintain
utility of the learned representation, we integrate DP-noisy representation
into a robust training process to derive a robust target model, which also
helps for model fairness over various demographic variables. Experimental
results on benchmark datasets under various parameter settings demonstrate that
DPNR largely reduces privacy leakage without significantly sacrificing the main
task performance.
</p>
<a href="http://arxiv.org/abs/2010.01285" target="_blank">arXiv:2010.01285</a> [<a href="http://arxiv.org/pdf/2010.01285" target="_blank">pdf</a>]

<h2>Unsupervised Cross-lingual Image Captioning. (arXiv:2010.01288v1 [cs.CL])</h2>
<h3>Jiahui Gao, Yi Zhou, Philip L. H. Yu, Jiuxiang Gu</h3>
<p>Most recent image captioning works are conducted in English as the majority
of image-caption datasets are in English. However, there are a large amount of
non-native English speakers worldwide. Generating image captions in different
languages is worth exploring. In this paper, we present a novel unsupervised
method to generate image captions without using any caption corpus. Our method
relies on 1) a cross-lingual auto-encoding, which learns the scene graph
mapping function along with the scene graph encoders and sentence decoders on
machine translation parallel corpora, and 2) an unsupervised feature mapping,
which seeks to map the encoded scene graph features from image modality to
sentence modality. By leveraging cross-lingual auto-encoding, cross-modal
feature mapping, and adversarial learning, our method can learn an image
captioner to generate captions in different languages. We verify the
effectiveness of our proposed method on the Chinese image caption generation.
The comparisons against several baseline methods demonstrate the effectiveness
of our approach.
</p>
<a href="http://arxiv.org/abs/2010.01288" target="_blank">arXiv:2010.01288</a> [<a href="http://arxiv.org/pdf/2010.01288" target="_blank">pdf</a>]

<h2>MPC Without the Computational Pain: The Benefits of SLS and Layering in Distributed Control. (arXiv:2010.01292v1 [eess.SY])</h2>
<h3>Jing Shuang Li, Carmen Amo Alonso, John C. Doyle</h3>
<p>The System Level Synthesis (SLS) approach facilitates distributed control of
large cyberphysical networks in an easy-to-understand, computationally scalable
way. We present a case study motivated by the power grid, with communication
constraints, actuator saturation, disturbances, and changing setpoints. This
simple but challenging case study necessitates the use of model predictive
control (MPC); however, MPC incurs significant online computational cost and
often scales poorly to large systems. We overcome these challenges by combining
various SLS-based techniques, including SLS-based MPC, in a layered controller.
This controller achieves performance that is within 3% of the centralized MPC
performance, requires only 5% of the online computational resources of
distributed MPC, and scales to systems of arbitrary size. For the unfamiliar
reader, we also present a review of the SLS approach and its associated
extensions in nonlinear control, MPC, adaptive control, and learning for
control.
</p>
<a href="http://arxiv.org/abs/2010.01292" target="_blank">arXiv:2010.01292</a> [<a href="http://arxiv.org/pdf/2010.01292" target="_blank">pdf</a>]

<h2>Beyond Tabula-Rasa: a Modular Reinforcement Learning Approach for Physically Embedded 3D Sokoban. (arXiv:2010.01298v1 [cs.LG])</h2>
<h3>Peter Karkus, Mehdi Mirza, Arthur Guez, Andrew Jaegle, Timothy Lillicrap, Lars Buesing, Nicolas Heess, Theophane Weber</h3>
<p>Intelligent robots need to achieve abstract objectives using concrete,
spatiotemporally complex sensory information and motor control. Tabula rasa
deep reinforcement learning (RL) has tackled demanding tasks in terms of either
visual, abstract, or physical reasoning, but solving these jointly remains a
formidable challenge. One recent, unsolved benchmark task that integrates these
challenges is Mujoban, where a robot needs to arrange 3D warehouses generated
from 2D Sokoban puzzles. We explore whether integrated tasks like Mujoban can
be solved by composing RL modules together in a sense-plan-act hierarchy, where
modules have well-defined roles similarly to classic robot architectures.
Unlike classic architectures that are typically model-based, we use only
model-free modules trained with RL or supervised learning. We find that our
modular RL approach dramatically outperforms the state-of-the-art monolithic RL
agent on Mujoban. Further, learned modules can be reused when, e.g., using a
different robot platform to solve the same task. Together our results give
strong evidence for the importance of research into modular RL designs. Project
website: https://sites.google.com/view/modular-rl/
</p>
<a href="http://arxiv.org/abs/2010.01298" target="_blank">arXiv:2010.01298</a> [<a href="http://arxiv.org/pdf/2010.01298" target="_blank">pdf</a>]

<h2>Deep Convolutional Neural Network Based Facial Expression Recognition in the Wild. (arXiv:2010.01301v1 [cs.CV])</h2>
<h3>Hafiq Anas, Bacha Rehman, Wee Hong Ong</h3>
<p>This paper describes the proposed methodology, data used and the results of
our participation in the ChallengeTrack 2 (Expr Challenge Track) of the
Affective Behavior Analysis in-the-wild (ABAW) Competition 2020. In this
competition, we have used a proposed deep convolutional neural network (CNN)
model to perform automatic facial expression recognition (AFER) on the given
dataset. Our proposed model has achieved an accuracy of 50.77% and an F1 score
of 29.16% on the validation set.
</p>
<a href="http://arxiv.org/abs/2010.01301" target="_blank">arXiv:2010.01301</a> [<a href="http://arxiv.org/pdf/2010.01301" target="_blank">pdf</a>]

<h2>Personality Trait Detection Using Bagged SVM over BERT Word Embedding Ensembles. (arXiv:2010.01309v1 [cs.CL])</h2>
<h3>Amirmohammad Kazameini, Samin Fatehi, Yash Mehta, Sauleh Eetemadi, Erik Cambria</h3>
<p>Recently, the automatic prediction of personality traits has received
increasing attention and has emerged as a hot topic within the field of
affective computing. In this work, we present a novel deep learning-based
approach for automated personality detection from text. We leverage state of
the art advances in natural language understanding, namely the BERT language
model to extract contextualized word embeddings from textual data for automated
author personality detection. Our primary goal is to develop a computationally
efficient, high-performance personality prediction model which can be easily
used by a large number of people without access to huge computation resources.
Our extensive experiments with this ideology in mind, led us to develop a novel
model which feeds contextualized embeddings along with psycholinguistic
features toa Bagged-SVM classifier for personality trait prediction. Our model
outperforms the previous state of the art by 1.04% and, at the same time is
significantly more computationally efficient to train. We report our results on
the famous gold standard Essays dataset for personality detection.
</p>
<a href="http://arxiv.org/abs/2010.01309" target="_blank">arXiv:2010.01309</a> [<a href="http://arxiv.org/pdf/2010.01309" target="_blank">pdf</a>]

<h2>Gaussian Vector: An Efficient Solution for Facial Landmark Detection. (arXiv:2010.01318v1 [cs.CV])</h2>
<h3>Yilin Xiong, Zijian Zhou, Yuhao Dou, Zhizhong Su</h3>
<p>Significant progress has been made in facial landmark detection with the
development of Convolutional Neural Networks. The widely-used algorithms can be
classified into coordinate regression methods and heatmap based methods.
However, the former loses spatial information, resulting in poor performance
while the latter suffers from large output size or high post-processing
complexity. This paper proposes a new solution, Gaussian Vector, to preserve
the spatial information as well as reduce the output size and simplify the
post-processing. Our method provides novel vector supervision and introduces
Band Pooling Module to convert heatmap into a pair of vectors for each
landmark. This is a plug-and-play component which is simple and effective.
Moreover, Beyond Box Strategy is proposed to handle the landmarks out of the
face bounding box. We evaluate our method on 300W, COFW, WFLW and JD-landmark.
That the results significantly surpass previous works demonstrates the
effectiveness of our approach.
</p>
<a href="http://arxiv.org/abs/2010.01318" target="_blank">arXiv:2010.01318</a> [<a href="http://arxiv.org/pdf/2010.01318" target="_blank">pdf</a>]

<h2>Multi-Step Adversarial Perturbations on Recommender Systems Embeddings. (arXiv:2010.01329v1 [cs.IR])</h2>
<h3>Vito Walter Anelli, Alejandro Bellog&#xed;n, Yashar Deldjoo, Tommaso Di Noia, Felice Antonio Merra</h3>
<p>Recommender systems (RSs) have attained exceptional performance in learning
users' preferences and helping them in finding the most suitable products.
Recent advances in adversarial machine learning (AML) in the computer vision
domain have raised interests in the security of state-of-the-art model-based
recommenders. Recently, worrying deterioration of recommendation accuracy has
been acknowledged on several state-of-the-art model-based recommenders (e.g.,
BPR-MF) when machine-learned adversarial perturbations contaminate model
parameters. However, while the single-step fast gradient sign method (FGSM) is
the most explored perturbation strategy, multi-step (iterative) perturbation
strategies, that demonstrated higher efficacy in the computer vision domain,
have been highly under-researched in recommendation tasks.

In this work, inspired by the basic iterative method (BIM) and the projected
gradient descent (PGD) strategies proposed in the CV domain, we adapt the
multi-step strategies for the item recommendation task to study the possible
weaknesses of embedding-based recommender models under minimal adversarial
perturbations. Letting the magnitude of the perturbation be fixed, we
illustrate the highest efficacy of the multi-step perturbation compared to the
single-step one with extensive empirical evaluation on two widely adopted
recommender datasets. Furthermore, we study the impact of structural dataset
characteristics, i.e., sparsity, density, and size, on the performance
degradation issued by presented perturbations to support RS designer in
interpreting recommendation performance variation due to minimal variations of
model parameters. Our implementation and datasets are available at
https://anonymous.4open.science/r/9f27f909-93d5-4016-b01c-8976b8c14bc5/.
</p>
<a href="http://arxiv.org/abs/2010.01329" target="_blank">arXiv:2010.01329</a> [<a href="http://arxiv.org/pdf/2010.01329" target="_blank">pdf</a>]

<h2>End-to-End Training of CNN Ensembles for Person Re-Identification. (arXiv:2010.01342v1 [cs.CV])</h2>
<h3>Ayse Serbetci, Yusuf Sinan Akgul</h3>
<p>We propose an end-to-end ensemble method for person re-identification (ReID)
to address the problem of overfitting in discriminative models. These models
are known to converge easily, but they are biased to the training data in
general and may produce a high model variance, which is known as overfitting.
The ReID task is more prone to this problem due to the large discrepancy
between training and test distributions. To address this problem, our proposed
ensemble learning framework produces several diverse and accurate base learners
in a single DenseNet. Since most of the costly dense blocks are shared, our
method is computationally efficient, which makes it favorable compared to the
conventional ensemble models. Experiments on several benchmark datasets
demonstrate that our method achieves state-of-the-art results. Noticeable
performance improvements, especially on relatively small datasets, indicate
that the proposed method deals with the overfitting problem effectively.
</p>
<a href="http://arxiv.org/abs/2010.01342" target="_blank">arXiv:2010.01342</a> [<a href="http://arxiv.org/pdf/2010.01342" target="_blank">pdf</a>]

<h2>A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples. (arXiv:2010.01345v1 [cs.CL])</h2>
<h3>Zhao Meng, Roger Wattenhofer</h3>
<p>Generating adversarial examples for natural language is hard, as natural
language consists of discrete symbols, and examples are often of variable
lengths. In this paper, we propose a geometry-inspired attack for generating
natural language adversarial examples. Our attack generates adversarial
examples by iteratively approximating the decision boundary of Deep Neural
Networks (DNNs). Experiments on two datasets with two different models show
that our attack fools natural language models with high success rates, while
only replacing a few words. Human evaluation shows that adversarial examples
generated by our attack are hard for humans to recognize. Further experiments
show that adversarial training can improve model robustness against our attack.
</p>
<a href="http://arxiv.org/abs/2010.01345" target="_blank">arXiv:2010.01345</a> [<a href="http://arxiv.org/pdf/2010.01345" target="_blank">pdf</a>]

<h2>Disentangling causal effects for hierarchical reinforcement learning. (arXiv:2010.01351v1 [cs.AI])</h2>
<h3>Oriol Corcoll, Raul Vicente</h3>
<p>Exploration and credit assignment under sparse rewards are still challenging
problems. We argue that these challenges arise in part due to the intrinsic
rigidity of operating at the level of actions. Actions can precisely define how
to perform an activity but are ill-suited to describe what activity to perform.
Instead, causal effects are inherently composable and temporally abstract,
making them ideal for descriptive tasks. By leveraging a hierarchy of causal
effects, this study aims to expedite the learning of task-specific behavior and
aid exploration. Borrowing counterfactual and normality measures from causal
literature, we disentangle controllable effects from effects caused by other
dynamics of the environment. We propose CEHRL, a hierarchical method that
models the distribution of controllable effects using a Variational
Autoencoder. This distribution is used by a high-level policy to 1) explore the
environment via random effect exploration so that novel effects are
continuously discovered and learned, and to 2) learn task-specific behavior by
prioritizing the effects that maximize a given reward function. In comparison
to exploring with random actions, experimental results show that random effect
exploration is a more efficient mechanism and that by assigning credit to few
effects rather than many actions, CEHRL learns tasks more rapidly.
</p>
<a href="http://arxiv.org/abs/2010.01351" target="_blank">arXiv:2010.01351</a> [<a href="http://arxiv.org/pdf/2010.01351" target="_blank">pdf</a>]

<h2>Expectigrad: Fast Stochastic Optimization with Robust Convergence Properties. (arXiv:2010.01356v1 [cs.LG])</h2>
<h3>Brett Daley, Christopher Amato</h3>
<p>Many popular adaptive gradient methods such as Adam and RMSProp rely on an
exponential moving average (EMA) to normalize their stepsizes. While the EMA
makes these methods highly responsive to new gradient information, recent
research has shown that it also causes divergence on at least one convex
optimization problem. We propose a novel method called Expectigrad, which
adjusts stepsizes according to a per-component unweighted mean of all
historical gradients and computes a bias-corrected momentum term jointly
between the numerator and denominator. We prove that Expectigrad cannot diverge
on every instance of the optimization problem known to cause Adam to diverge.
We also establish a regret bound in the general stochastic nonconvex setting
that suggests Expectigrad is less susceptible to gradient variance than
existing methods are. Testing Expectigrad on several high-dimensional machine
learning tasks, we find it often performs favorably to state-of-the-art methods
with little hyperparameter tuning.
</p>
<a href="http://arxiv.org/abs/2010.01356" target="_blank">arXiv:2010.01356</a> [<a href="http://arxiv.org/pdf/2010.01356" target="_blank">pdf</a>]

<h2>Perplexity-free Parametric t-SNE. (arXiv:2010.01359v1 [cs.LG])</h2>
<h3>Francesco Crecchi, Cyril de Bodt, Michel Verleysen, John A. Lee, Davide Bacciu</h3>
<p>The t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm is a
ubiquitously employed dimensionality reduction (DR) method. Its non-parametric
nature and impressive efficacy motivated its parametric extension. It is
however bounded to a user-defined perplexity parameter, restricting its DR
quality compared to recently developed multi-scale perplexity-free approaches.
This paper hence proposes a multi-scale parametric t-SNE scheme, relieved from
the perplexity tuning and with a deep neural network implementing the mapping.
It produces reliable embeddings with out-of-sample extensions, competitive with
the best perplexity adjustments in terms of neighborhood preservation on
multiple data sets.
</p>
<a href="http://arxiv.org/abs/2010.01359" target="_blank">arXiv:2010.01359</a> [<a href="http://arxiv.org/pdf/2010.01359" target="_blank">pdf</a>]

<h2>COVID-19 Classification of X-ray Images Using Deep Neural Networks. (arXiv:2010.01362v1 [eess.IV])</h2>
<h3>Elisha Goldstein, Daphna Keidar, Daniel Yaron, Yair Shachar, Ayelet Blass, Leonid Charbinsky, Israel Aharony, Liza Lifshitz, Dimitri Lumelsky, Ziv Neeman, Matti Mizrachi, Majd Hajouj, Nethanel Eizenbach, Eyal Sela, Chedva S Weiss, Philip Levin, Ofer Benjaminov, Gil N Bachar, Shlomit Tamir, Yael Rapson, Dror Suhami, Amiel A Dror, Naama R Bogot, Ahuva Grubstein, Nogah Shabshin, Yishai M Elyada, Yonina C Eldar</h3>
<p>In the midst of the coronavirus disease 2019 (COVID-19) outbreak, chest X-ray
(CXR) imaging is playing an important role in the diagnosis and monitoring of
patients with COVID-19. Machine learning solutions have been shown to be useful
for X-ray analysis and classification in a range of medical contexts. The
purpose of this study is to create and evaluate a machine learning model for
diagnosis of COVID-19, and to provide a tool for searching for similar patients
according to their X-ray scans. In this retrospective study, a classifier was
built using a pre-trained deep learning model (ReNet50) and enhanced by data
augmentation and lung segmentation to detect COVID-19 in frontal CXR images
collected between January 2018 and July 2020 in four hospitals in Israel. A
nearest-neighbors algorithm was implemented based on the network results that
identifies the images most similar to a given image. The model was evaluated
using accuracy, sensitivity, area under the curve (AUC) of receiver operating
characteristic (ROC) curve and of the precision-recall (P-R) curve. The dataset
sourced for this study includes 2362 CXRs, balanced for positive and negative
COVID-19, from 1384 patients (63 +/- 18 years, 552 men). Our model achieved
89.7% (314/350) accuracy and 87.1% (156/179) sensitivity in classification of
COVID-19 on a test dataset comprising 15% (350 of 2326) of the original data,
with AUC of ROC 0.95 and AUC of the P-R curve 0.94. For each image we retrieve
images with the most similar DNN-based image embeddings; these can be used to
compare with previous cases.
</p>
<a href="http://arxiv.org/abs/2010.01362" target="_blank">arXiv:2010.01362</a> [<a href="http://arxiv.org/pdf/2010.01362" target="_blank">pdf</a>]

<h2>EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding. (arXiv:2010.01367v1 [cs.AI])</h2>
<h3>Jiaoyang Li, Wheeler Ruml, Sven Koenig</h3>
<p>Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for
multiple robots, is important for many applications where small runtimes are
important, including the kind of automated warehouses operated by Amazon. CBS
is a leading two-level search algorithm for solving MAPF optimally. ECBS is a
bounded-suboptimal variant of CBS that uses focal search to speed up CBS by
sacrificing optimality and instead guaranteeing that the costs of its solution
are within a given factor of optimal. In this paper, we study how to decrease
its runtime even further using inadmissible heuristics. Motivated by Explicit
Estimation Search (EES), we propose Explicit Estimation CBS (EECBS), a new
bounded-suboptimal variant of CBS, that uses online learning to inadmissibly
estimate the cost of the solution under each high-level node and uses EES to
choose which high-level node to expand next. We also investigate recent
improvements to CBS and adapt them to EECBS. We find that EECBS with the
improvements runs significantly faster than the MAPF algorithms ECBS, BCP-7,
and eMDD-SAT on a variety of MAPF instances. We hope that the scalability of
EECBS enables wider adoption of MAPF formulations in practical applications.
</p>
<a href="http://arxiv.org/abs/2010.01367" target="_blank">arXiv:2010.01367</a> [<a href="http://arxiv.org/pdf/2010.01367" target="_blank">pdf</a>]

<h2>Computational Separation Between Convolutional and Fully-Connected Networks. (arXiv:2010.01369v1 [cs.LG])</h2>
<h3>Eran Malach, Shai Shalev-Shwartz</h3>
<p>Convolutional neural networks (CNN) exhibit unmatched performance in a
multitude of computer vision tasks. However, the advantage of using
convolutional networks over fully-connected networks is not understood from a
theoretical perspective. In this work, we show how convolutional networks can
leverage locality in the data, and thus achieve a computational advantage over
fully-connected networks. Specifically, we show a class of problems that can be
efficiently solved using convolutional networks trained with gradient-descent,
but at the same time is hard to learn using a polynomial-size fully-connected
network.
</p>
<a href="http://arxiv.org/abs/2010.01369" target="_blank">arXiv:2010.01369</a> [<a href="http://arxiv.org/pdf/2010.01369" target="_blank">pdf</a>]

<h2>Lyapunov-guided Deep Reinforcement Learning for Stable Online Computation Offloading in Mobile-Edge Computing Networks. (arXiv:2010.01370v1 [cs.NI])</h2>
<h3>Suzhi Bi, Liang Huang, Hui Wang, Ying-Jun Angela Zhang</h3>
<p>Opportunistic computation offloading is an effective method to improve the
computation performance of mobile-edge computing (MEC) networks under dynamic
edge environment. In this paper, we consider a multi-user MEC network with
time-varying wireless channels and stochastic user task data arrivals in
sequential time frames. In particular, we aim to design an online computation
offloading algorithm to maximize the network data processing capability subject
to the long-term data queue stability and average power constraints. The online
algorithm is practical in the sense that the decisions for each time frame are
made without the assumption of knowing future channel conditions and data
arrivals. We formulate the problem as a multi-stage stochastic mixed integer
non-linear programming (MINLP) problem that jointly determines the binary
offloading (each user computes the task either locally or at the edge server)
and system resource allocation decisions in sequential time frames. To address
the coupling in the decisions of different time frames, we propose a novel
framework, named LyDROO, that combines the advantages of Lyapunov optimization
and deep reinforcement learning (DRL). Specifically, LyDROO first applies
Lyapunov optimization to decouple the multi-stage stochastic MINLP into
deterministic per-frame MINLP subproblems. By doing so, it guarantees to
satisfy all the long-term constraints by solving the per-frame subproblems that
are much smaller in size. Then, LyDROO integrates model-based optimization and
model-free DRL to solve the per-frame MINLP problems with low computational
complexity. Simulation results show that under various network setups, the
proposed LyDROO achieves optimal computation performance while stabilizing all
queues in the system. Besides, it induces very low execution latency that is
particularly suitable for real-time implementation in fast fading environments.
</p>
<a href="http://arxiv.org/abs/2010.01370" target="_blank">arXiv:2010.01370</a> [<a href="http://arxiv.org/pdf/2010.01370" target="_blank">pdf</a>]

<h2>Predicting traffic overflows on private peering. (arXiv:2010.01380v1 [cs.NI])</h2>
<h3>Elad Rapaport, Ingmar Poese, Polina Zilberman, Oliver Holschke, Rami Puzis</h3>
<p>Large content providers and content distribution network operators usually
connect with large Internet service providers (eyeball networks) through
dedicated private peering. The capacity of these private network interconnects
is provisioned to match the volume of the real content demand by the users.
Unfortunately, in case of a surge in traffic demand, for example due to a
content trending in a certain country, the capacity of the private interconnect
may deplete and the content provider/distributor would have to reroute the
excess traffic through transit providers. Although, such overflow events are
rare, they have significant negative impacts on content providers, Internet
service providers, and end-users. These include unexpected delays and
disruptions reducing the user experience quality, as well as direct costs paid
by the Internet service provider to the transit providers. If the traffic
overflow events could be predicted, the Internet service providers would be
able to influence the routes chosen for the excess traffic to reduce the costs
and increase user experience quality. In this article we propose a method based
on an ensemble of deep learning models to predict overflow events over a short
term horizon of 2-6 hours and predict the specific interconnections that will
ingress the overflow traffic. The method was evaluated with 2.5 years' traffic
measurement data from a large European Internet service provider resulting in a
true-positive rate of 0.8 while maintaining a 0.05 false-positive rate. The
lockdown imposed by the COVID-19 pandemic reduced the overflow prediction
accuracy. Nevertheless, starting from the end of April 2020 with the gradual
lockdown release, the old models trained before the pandemic perform equally
well.
</p>
<a href="http://arxiv.org/abs/2010.01380" target="_blank">arXiv:2010.01380</a> [<a href="http://arxiv.org/pdf/2010.01380" target="_blank">pdf</a>]

<h2>CardioXNet: A Novel Lightweight CRNN Framework for Classifying Cardiovascular Diseases from Phonocardiogram Recordings. (arXiv:2010.01392v1 [eess.AS])</h2>
<h3>Samiul Based Shuvo, Shams Nafisa Ali, Soham Irtiza Swapnil</h3>
<p>The alarmingly high mortality rate and increasing global prevalence of
cardiovascular diseases (CVDs) signify the crucial need for early detection
schemes. Phonocardiogram(PCG) signals has been historically applied in this
domain owing to its simplicity and cost-effectiveness. However, insufficiency
of expert physicians and human subjectivity affect the applicability of this
technique, especially in the low-resource settings. For resolving this issue,
in this paper, we introduce CardioXNet,a novel lightweight CRNN architecture
for automatic detection of five classes of cardiac auscultation namely normal,
aortic stenosis, mitral stenosis, mitral regurgitation and mitral valve
prolapse using raw PCG signal. The process has been automated by the
involvement of two learning phases namely, representation learning and sequence
residual learning. The first phase mainly focuses on automated feature
extraction and it has been implemented in a modular way with three parallel CNN
pathways i.e., frequency feature extractor (FFE), pattern extractor (PE) and
adaptive feature extractor (AFE). 1D-CNN based FFE and PE respectively learn
the coarse and fine-grained features from the PCG while AFE explores the
salient features from variable receptive fields involving 2D-CNN based
squeezeexpansion. Thus, in the representation learning phase, the network
extracts efficient time-invariant features and converges with great rapidity.
In the sequential residual learning phase,because of the bidirectional-LSTMs
and the skip connection, the network can proficiently extract temporal
features. The obtained results demonstrate that the proposed end-to-end
architecture yields outstanding performance in all the evaluation metrics
compared to the previous state-of-the-art methods with up to 99.6% accuracy,
99.6% precision, 99.6% recall and 99.4% F1-score on an average while being
computationally comparable.
</p>
<a href="http://arxiv.org/abs/2010.01392" target="_blank">arXiv:2010.01392</a> [<a href="http://arxiv.org/pdf/2010.01392" target="_blank">pdf</a>]

<h2>Automated Performance Tuning for Highly-Configurable Software Systems. (arXiv:2010.01397v1 [cs.SE])</h2>
<h3>Xue Han, Tingting Yu</h3>
<p>Performance is an important non-functional aspect of the software
requirement. Modern software systems are highly-configurable and
misconfigurations may easily cause performance issues. A software system that
suffers performance issues may exhibit low program throughput and long response
time. However, the sheer size of the configuration space makes it challenging
for administrators to manually select and adjust the configuration options to
achieve better performance. In this paper, we propose ConfRL, an approach to
tune software performance automatically. The key idea of ConfRL is to use
reinforcement learning to explore the configuration space by a trial-and-error
approach and to use the feedback received from the environment to tune
configuration option values to achieve better performance. To reduce the cost
of reinforcement learning, ConfRL employs sampling, clustering, and dynamic
state reduction techniques to keep states in a large configuration space
manageable. Our evaluation of four real-world highly-configurable server
programs shows that ConfRL can efficiently and effectively guide software
systems to achieve higher long-term performance.
</p>
<a href="http://arxiv.org/abs/2010.01397" target="_blank">arXiv:2010.01397</a> [<a href="http://arxiv.org/pdf/2010.01397" target="_blank">pdf</a>]

<h2>Joint Inference of Structure and Diffusion in Partially Observed Social Networks. (arXiv:2010.01400v1 [cs.SI])</h2>
<h3>Maryam Ramezani, Amirmohammad Ziaei, Hamid R. Rabiee</h3>
<p>Access to complete data in large scale networks is often infeasible.
Therefore, the problem of missing data is a crucial and unavoidable issue in
analysis and modeling of real-world social networks. However, most of the
research on different aspects of social networks do not consider this
limitation. One effective way to solve this problem is to recover the missing
data as a pre-processing step. The present paper tries to infer the unobserved
data from both diffusion network and network structure by learning a model from
the partially observed data. We develop a probabilistic generative model called
"DiffStru" to jointly discover the hidden links of network structure and the
omitted diffusion activities. The interrelations among links of nodes and
cascade processes are utilized in the proposed method via learning coupled low
dimensional latent factors. In addition to inferring the unseen data, the
learned latent factors may also help network classification problems such as
community detection. Simulation results on synthetic and real-world datasets
show the excellent performance of the proposed method in terms of link
prediction and discovering the identity and infection time of invisible social
behaviors.
</p>
<a href="http://arxiv.org/abs/2010.01400" target="_blank">arXiv:2010.01400</a> [<a href="http://arxiv.org/pdf/2010.01400" target="_blank">pdf</a>]

<h2>Unsupervised Monocular Depth Estimation for Night-time Images using Adversarial Domain Feature Adaptation. (arXiv:2010.01402v1 [cs.RO])</h2>
<h3>Madhu Vankadari, Sourav Garg, Anima Majumder, Swagat Kumar, Ardhendu Behera</h3>
<p>In this paper, we look into the problem of estimating per-pixel depth maps
from unconstrained RGB monocular night-time images which is a difficult task
that has not been addressed adequately in the literature. The state-of-the-art
day-time depth estimation methods fail miserably when tested with night-time
images due to a large domain shift between them. The usual photo metric losses
used for training these networks may not work for night-time images due to the
absence of uniform lighting which is commonly present in day-time images,
making it a difficult problem to solve. We propose to solve this problem by
posing it as a domain adaptation problem where a network trained with day-time
images is adapted to work for night-time images. Specifically, an encoder is
trained to generate features from night-time images that are indistinguishable
from those obtained from day-time images by using a PatchGAN-based adversarial
discriminative learning method. Unlike the existing methods that directly adapt
depth prediction (network output), we propose to adapt feature maps obtained
from the encoder network so that a pre-trained day-time depth decoder can be
directly used for predicting depth from these adapted features. Hence, the
resulting method is termed as "Adversarial Domain Feature Adaptation (ADFA)"
and its efficacy is demonstrated through experimentation on the challenging
Oxford night driving dataset. Also, The modular encoder-decoder architecture
for the proposed ADFA method allows us to use the encoder module as a feature
extractor which can be used in many other applications. One such application is
demonstrated where the features obtained from our adapted encoder network are
shown to outperform other state-of-the-art methods in a visual place
recognition problem, thereby, further establishing the usefulness and
effectiveness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2010.01402" target="_blank">arXiv:2010.01402</a> [<a href="http://arxiv.org/pdf/2010.01402" target="_blank">pdf</a>]

<h2>Policy Gradient with Expected Quadratic Utility Maximization: A New Mean-Variance Approach in Reinforcement Learning. (arXiv:2010.01404v1 [cs.LG])</h2>
<h3>Masahiro Kato, Kei Nakagawa</h3>
<p>In real-world decision-making problems, risk management is critical. Among
various risk management approaches, the mean-variance criterion is one of the
most widely used in practice. In this paper, we suggest expected quadratic
utility maximization (EQUM) as a new framework for policy gradient style
reinforcement learning (RL) algorithms with mean-variance control. The
quadratic utility function is a common objective of risk management in finance
and economics. The proposed EQUM framework has several interpretations, such as
reward-constrained variance minimization and regularization, as well as agent
utility maximization. In addition, the computation of the EQUM framework is
easier than that of existing mean-variance RL methods, which require double
sampling. In experiments, we demonstrate the effectiveness of the proposed
framework in the benchmarks of RL and financial data.
</p>
<a href="http://arxiv.org/abs/2010.01404" target="_blank">arXiv:2010.01404</a> [<a href="http://arxiv.org/pdf/2010.01404" target="_blank">pdf</a>]

<h2>Code to Comment "Translation": Data, Metrics, Baselining & Evaluation. (arXiv:2010.01410v1 [cs.SE])</h2>
<h3>David Gros, Hariharan Sezhiyan, Prem Devanbu, Zhou Yu</h3>
<p>The relationship of comments to code, and in particular, the task of
generating useful comments given the code, has long been of interest. The
earliest approaches have been based on strong syntactic theories of
comment-structures, and relied on textual templates. More recently, researchers
have applied deep learning methods to this task, and specifically, trainable
generative translation models which are known to work very well for Natural
Language translation (e.g., from German to English). We carefully examine the
underlying assumption here: that the task of generating comments sufficiently
resembles the task of translating between natural languages, and so similar
models and evaluation metrics could be used. We analyze several recent
code-comment datasets for this task: CodeNN, DeepCom, FunCom, and DocString. We
compare them with WMT19, a standard dataset frequently used to train state of
the art natural language translators. We found some interesting differences
between the code-comment data and the WMT19 natural language data. Next, we
describe and conduct some studies to calibrate BLEU (which is commonly used as
a measure of comment quality). using "affinity pairs" of methods, from
different projects, in the same project, in the same class, etc; Our study
suggests that the current performance on some datasets might need to be
improved substantially. We also argue that fairly naive information retrieval
(IR) methods do well enough at this task to be considered a reasonable
baseline. Finally, we make some suggestions on how our findings might be used
in future research in this area.
</p>
<a href="http://arxiv.org/abs/2010.01410" target="_blank">arXiv:2010.01410</a> [<a href="http://arxiv.org/pdf/2010.01410" target="_blank">pdf</a>]

<h2>Sharpness-Aware Minimization for Efficiently Improving Generalization. (arXiv:2010.01412v1 [cs.LG])</h2>
<h3>Pierre Foret, Ariel Kleiner, Hossein Mobahi, Behnam Neyshabur</h3>
<p>In today's heavily overparameterized models, the value of the training loss
provides few guarantees on model generalization ability. Indeed, optimizing
only the training loss value, as is commonly done, can easily lead to
suboptimal model quality. Motivated by the connection between geometry of the
loss landscape and generalization---including a generalization bound that we
prove here---we introduce a novel, effective procedure for instead
simultaneously minimizing loss value and loss sharpness. In particular, our
procedure, Sharpness-Aware Minimization (SAM), seeks parameters that lie in
neighborhoods having uniformly low loss; this formulation results in a min-max
optimization problem on which gradient descent can be performed efficiently. We
present empirical results showing that SAM improves model generalization across
a variety of benchmark datasets (e.g., CIFAR-{10, 100}, ImageNet, finetuning
tasks) and models, yielding novel state-of-the-art performance for several.
Additionally, we find that SAM natively provides robustness to label noise on
par with that provided by state-of-the-art procedures that specifically target
learning with noisy labels.
</p>
<a href="http://arxiv.org/abs/2010.01412" target="_blank">arXiv:2010.01412</a> [<a href="http://arxiv.org/pdf/2010.01412" target="_blank">pdf</a>]

<h2>Early Bird: Loop Closures from Opposing Viewpoints for Perceptually-Aliased Indoor Environments. (arXiv:2010.01421v1 [cs.CV])</h2>
<h3>Satyajit Tourani, Dhagash Desai, Udit Singh Parihar, Sourav Garg, Ravi Kiran Sarvadevabhatla, K. Madhava Krishna</h3>
<p>Significant advances have been made recently in Visual Place Recognition
(VPR), feature correspondence, and localization due to the proliferation of
deep-learning-based methods. However, existing approaches tend to address,
partially or fully, only one of two key challenges: viewpoint change and
perceptual aliasing. In this paper, we present novel research that
simultaneously addresses both challenges by combining deep-learned features
with geometric transformations based on reasonable domain assumptions about
navigation on a ground-plane, whilst also removing the requirement for
specialized hardware setup (e.g. lighting, downwards facing cameras). In
particular, our integration of VPR with SLAM by leveraging the robustness of
deep-learned features and our homography-based extreme viewpoint invariance
significantly boosts the performance of VPR, feature correspondence, and pose
graph submodules of the SLAM pipeline. For the first time, we demonstrate a
localization system capable of state-of-the-art performance despite perceptual
aliasing and extreme 180-degree-rotated viewpoint change in a range of
real-world and simulated experiments. Our system is able to achieve early loop
closures that prevent significant drifts in SLAM trajectories. We also compare
extensively several deep architectures for VPR and descriptor matching. We also
show that superior place recognition and descriptor matching across opposite
views results in a similar performance gain in back-end pose graph
optimization.
</p>
<a href="http://arxiv.org/abs/2010.01421" target="_blank">arXiv:2010.01421</a> [<a href="http://arxiv.org/pdf/2010.01421" target="_blank">pdf</a>]

<h2>Episodic Memory for Learning Subjective-Timescale Models. (arXiv:2010.01430v1 [cs.LG])</h2>
<h3>Alexey Zakharov, Matthew Crosby, Zafeirios Fountas</h3>
<p>In model-based learning, an agent's model is commonly defined over
transitions between consecutive states of an environment even though planning
often requires reasoning over multi-step timescales, with intermediate states
either unnecessary, or worse, accumulating prediction error. In contrast,
intelligent behaviour in biological organisms is characterised by the ability
to plan over varying temporal scales depending on the context. Inspired by the
recent works on human time perception, we devise a novel approach to learning a
transition dynamics model, based on the sequences of episodic memories that
define the agent's subjective timescale - over which it learns world dynamics
and over which future planning is performed. We implement this in the framework
of active inference and demonstrate that the resulting subjective-timescale
model (STM) can systematically vary the temporal extent of its predictions
while preserving the same computational efficiency. Additionally, we show that
STM predictions are more likely to introduce future salient events (for example
new objects coming into view), incentivising exploration of new areas of the
environment. As a result, STM produces more informative action-conditioned
roll-outs that assist the agent in making better decisions. We validate
significant improvement in our STM agent's performance in the Animal-AI
environment against a baseline system, trained using the environment's
objective-timescale dynamics.
</p>
<a href="http://arxiv.org/abs/2010.01430" target="_blank">arXiv:2010.01430</a> [<a href="http://arxiv.org/pdf/2010.01430" target="_blank">pdf</a>]

<h2>Decoy Selection for Protein Structure Prediction Via Extreme Gradient Boosting and Ranking. (arXiv:2010.01441v1 [q-bio.BM])</h2>
<h3>Nasrin Akhter, Gopinath Chennupati, Hristo Djidjev, Amarda Shehu</h3>
<p>Identifying one or more biologically-active/native decoys from millions of
non-native decoys is one of the major challenges in computational structural
biology. The extreme lack of balance in positive and negative samples (native
and non-native decoys) in a decoy set makes the problem even more complicated.
Consensus methods show varied success in handling the challenge of decoy
selection despite some issues associated with clustering large decoy sets and
decoy sets that do not show much structural similarity. Recent investigations
into energy landscape-based decoy selection approaches show promises. However,
lack of generalization over varied test cases remains a bottleneck for these
methods. We propose a novel decoy selection method, ML-Select, a machine
learning framework that exploits the energy landscape associated with the
structure space probed through a template-free decoy generation. The proposed
method outperforms both clustering and energy ranking-based methods, all the
while consistently offering better performance on varied test-cases. Moreover,
ML-Select shows promising results even for the decoy sets consisting of mostly
low-quality decoys. ML-Select is a useful method for decoy selection. This work
suggests further research in finding more effective ways to adopt machine
learning frameworks in achieving robust performance for decoy selection in
template-free protein structure prediction.
</p>
<a href="http://arxiv.org/abs/2010.01441" target="_blank">arXiv:2010.01441</a> [<a href="http://arxiv.org/pdf/2010.01441" target="_blank">pdf</a>]

<h2>Async-RED: A Provably Convergent Asynchronous Block Parallel Stochastic Method using Deep Denoising Priors. (arXiv:2010.01446v1 [eess.IV])</h2>
<h3>Yu Sun, Jiaming Liu, Yiran Sun, Brendt Wohlberg, Ulugbek S. Kamilov</h3>
<p>Regularization by denoising (RED) is a recently developed framework for
solving inverse problems by integrating advanced denoisers as image priors.
Recent work has shown its state-of-the-art performance when combined with
pre-trained deep denoisers. However, current RED algorithms are inadequate for
parallel processing on multicore systems. We address this issue by proposing a
new asynchronous RED (ASYNC-RED) algorithm that enables asynchronous parallel
processing of data, making it significantly faster than its serial counterparts
for large-scale inverse problems. The computational complexity of ASYNC-RED is
further reduced by using a random subset of measurements at every iteration. We
present complete theoretical analysis of the algorithm by establishing its
convergence under explicit assumptions on the data-fidelity and the denoiser.
We validate ASYNC-RED on image recovery using pre-trained deep denoisers as
priors.
</p>
<a href="http://arxiv.org/abs/2010.01446" target="_blank">arXiv:2010.01446</a> [<a href="http://arxiv.org/pdf/2010.01446" target="_blank">pdf</a>]

<h2>GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems. (arXiv:2010.01447v1 [cs.CL])</h2>
<h3>Shiquan Yang, Rui Zhang, Sarah Erfani</h3>
<p>End-to-end task-oriented dialogue systems aim to generate system responses
directly from plain text inputs. There are two challenges for such systems: one
is how to effectively incorporate external knowledge bases (KBs) into the
learning framework; the other is how to accurately capture the semantics of
dialogue history. In this paper, we address these two challenges by exploiting
the graph structural information in the knowledge base and in the dependency
parsing tree of the dialogue. To effectively leverage the structural
information in dialogue history, we propose a new recurrent cell architecture
which allows representation learning on graphs. To exploit the relations
between entities in KBs, the model combines multi-hop reasoning ability based
on the graph structure. Experimental results show that the proposed model
achieves consistent improvement over state-of-the-art models on two different
task-oriented dialogue datasets.
</p>
<a href="http://arxiv.org/abs/2010.01447" target="_blank">arXiv:2010.01447</a> [<a href="http://arxiv.org/pdf/2010.01447" target="_blank">pdf</a>]

<h2>Quickly Finding a Benign Region via Heavy Ball Momentum in Non-Convex Optimization. (arXiv:2010.01449v1 [cs.LG])</h2>
<h3>Jun-Kun Wang, Jacob Abernethy</h3>
<p>The Heavy Ball Method, proposed by Polyak over five decades ago, is a
first-order method for optimizing continuous functions. While its stochastic
counterpart has proven extremely popular in training deep networks, there are
almost no known functions where deterministic Heavy Ball is provably faster
than the simple and classical gradient descent algorithm in non-convex
optimization. The success of Heavy Ball has thus far eluded theoretical
understanding. Our goal is to address this gap, and in the present work we
identify two non-convex problems where we provably show that the Heavy Ball
momentum helps the iterate to enter a benign region that contains a global
optimal point faster. We show that Heavy Ball exhibits simple dynamics that
clearly reveal the benefit of using a larger value of momentum parameter for
the problems. The first of these optimization problems is the phase retrieval
problem, which has useful applications in physical science. The second of these
optimization problems is the cubic-regularized minimization, a critical
subroutine required by Nesterov-Polyak cubic-regularized method to find
second-order stationary points in general smooth non-convex problems.
</p>
<a href="http://arxiv.org/abs/2010.01449" target="_blank">arXiv:2010.01449</a> [<a href="http://arxiv.org/pdf/2010.01449" target="_blank">pdf</a>]

<h2>SumGNN: Multi-typed Drug Interaction Prediction via Efficient Knowledge Graph Summarization. (arXiv:2010.01450v1 [cs.LG])</h2>
<h3>Yue Yu, Kexin Huang, Chao Zhang, Lucas M. Glass, Jimeng Sun, Cao Xiao</h3>
<p>Thanks to the increasing availability of drug-drug interactions (DDI)
datasets and large biomedical knowledge graphs (KGs), accurate detection of
adverse DDI using machine learning models becomes possible. However, it remains
largely an open problem how to effectively utilize large and noisy biomedical
KG for DDI detection. Due to its sheer size and amount of noise in KGs, it is
often less beneficial to directly integrate KGs with other smaller but higher
quality data (e.g., experimental data). Most of existing approaches ignore KGs
altogether. Some tries to directly integrate KGs with other data via graph
neural networks with limited success. Furthermore most previous works focus on
binary DDI prediction whereas the multi-typed DDI pharmacological effect
prediction is more meaningful but harder task.

To fill the gaps, we propose a new method SumGNN:~{\it knowledge
summarization graph neural network}, which is enabled by a subgraph extraction
module that can efficiently anchor on relevant subgraphs from a KG, a
self-attention based subgraph summarization scheme to generate reasoning path
within the subgraph, and a multi-channel knowledge and data integration module
that utilizes massive external biomedical knowledge for significantly improved
multi-typed DDI predictions. SumGNN outperforms the best baseline by up to
5.54\%, and performance gain is particularly significant in low data relation
types. In addition, SumGNN provides interpretable prediction via the generated
reasoning paths for each prediction.
</p>
<a href="http://arxiv.org/abs/2010.01450" target="_blank">arXiv:2010.01450</a> [<a href="http://arxiv.org/pdf/2010.01450" target="_blank">pdf</a>]

<h2>MDReg-Net: Multi-resolution diffeomorphic image registration using fully convolutional networks with deep self-supervision. (arXiv:2010.01465v1 [cs.CV])</h2>
<h3>Hongming Li, Yong Fan</h3>
<p>We present a diffeomorphic image registration algorithm to learn spatial
transformations between pairs of images to be registered using fully
convolutional networks (FCNs) under a self-supervised learning setting. The
network is trained to estimate diffeomorphic spatial transformations between
pairs of images by maximizing an image-wise similarity metric between fixed and
warped moving images, similar to conventional image registration algorithms. It
is implemented in a multi-resolution image registration framework to optimize
and learn spatial transformations at different image resolutions jointly and
incrementally with deep self-supervision in order to better handle large
deformation between images. A spatial Gaussian smoothing kernel is integrated
with the FCNs to yield sufficiently smooth deformation fields to achieve
diffeomorphic image registration. Particularly, spatial transformations learned
at coarser resolutions are utilized to warp the moving image, which is
subsequently used for learning incremental transformations at finer
resolutions. This procedure proceeds recursively to the full image resolution
and the accumulated transformations serve as the final transformation to warp
the moving image at the finest resolution. Experimental results for registering
high resolution 3D structural brain magnetic resonance (MR) images have
demonstrated that image registration networks trained by our method obtain
robust, diffeomorphic image registration results within seconds with improved
accuracy compared with state-of-the-art image registration algorithms.
</p>
<a href="http://arxiv.org/abs/2010.01465" target="_blank">arXiv:2010.01465</a> [<a href="http://arxiv.org/pdf/2010.01465" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Delay-Oriented IoT Task Scheduling in Space-Air-Ground Integrated Network. (arXiv:2010.01471v1 [cs.LG])</h2>
<h3>Conghao Zhou, Wen Wu, Hongli He, Peng Yang, Feng Lyu, Nan Cheng, Xuemin (Sherman) Shen</h3>
<p>In this paper, we investigate a computing task scheduling problem in
space-air-ground integrated network (SAGIN) for delay-oriented Internet of
Things (IoT) services. In the considered scenario, an unmanned aerial vehicle
(UAV) collects computing tasks from IoT devices and then makes online
offloading decisions, in which the tasks can be processed at the UAV or
offloaded to the nearby base station or the remote satellite. Our objective is
to design a task scheduling policy that minimizes offloading and computing
delay of all tasks given the UAV energy capacity constraint. To this end, we
first formulate the online scheduling problem as an energy-constrained Markov
decision process (MDP). Then, considering the task arrival dynamics, we develop
a novel deep risk-sensitive reinforcement learning algorithm. Specifically, the
algorithm evaluates the risk, which measures the energy consumption that
exceeds the constraint, for each state and searches the optimal parameter
weighing the minimization of delay and risk while learning the optimal policy.
Extensive simulation results demonstrate that the proposed algorithm can reduce
the task processing delay by up to 30% compared to probabilistic configuration
methods while satisfying the UAV energy capacity constraint.
</p>
<a href="http://arxiv.org/abs/2010.01471" target="_blank">arXiv:2010.01471</a> [<a href="http://arxiv.org/pdf/2010.01471" target="_blank">pdf</a>]

<h2>New Insights on Learning Rules for Hopfield Networks: Memory and Objective Function Minimisation. (arXiv:2010.01472v1 [cs.NE])</h2>
<h3>Pavel Tolmachev, Jonathan H. Manton</h3>
<p>Hopfield neural networks are a possible basis for modelling associative
memory in living organisms. After summarising previous studies in the field, we
take a new look at learning rules, exhibiting them as descent-type algorithms
for various cost functions. We also propose several new cost functions suitable
for learning. We discuss the role of biases (the external inputs) in the
learning process in Hopfield networks. Furthermore, we apply Newtons method for
learning memories, and experimentally compare the performances of various
learning rules. Finally, to add to the debate whether allowing connections of a
neuron to itself enhances memory capacity, we numerically investigate the
effects of self coupling.

Keywords: Hopfield Networks, associative memory, content addressable memory,
learning rules, gradient descent, attractor networks
</p>
<a href="http://arxiv.org/abs/2010.01472" target="_blank">arXiv:2010.01472</a> [<a href="http://arxiv.org/pdf/2010.01472" target="_blank">pdf</a>]

<h2>Spatial Frequency Bias in Convolutional Generative Adversarial Networks. (arXiv:2010.01473v1 [cs.LG])</h2>
<h3>Mahyar Khayatkhoei, Ahmed Elgammal</h3>
<p>As the success of Generative Adversarial Networks (GANs) on natural images
quickly propels them into various real-life applications across different
domains, it becomes more and more important to clearly understand their
limitations. Specifically, understanding GANs' capability across the full
spectrum of spatial frequencies, i.e. beyond the low-frequency dominant
spectrum of natural images, is critical for assessing the reliability of GAN
generated data in any detail-sensitive application (e.g. denoising, filling and
super-resolution in medical and satellite images). In this paper, we show that
the ability of GANs to learn a distribution is significantly affected by the
spatial frequency of the underlying carrier signal, that is, GANs have a bias
against learning high spatial frequencies. Crucially, we show that this bias is
not merely a result of the scarcity of high frequencies in natural images,
rather, it is a systemic bias hindering the learning of high frequencies
regardless of their prominence in a dataset. Furthermore, we explain why
large-scale GANs' ability to generate fine details on natural images does not
exclude them from the adverse effects of this bias. Finally, we propose a
method for manipulating this bias with minimal computational overhead. This
method can be used to explicitly direct computational resources towards any
specific spatial frequency of interest in a dataset, thus extending the
flexibility of GANs.
</p>
<a href="http://arxiv.org/abs/2010.01473" target="_blank">arXiv:2010.01473</a> [<a href="http://arxiv.org/pdf/2010.01473" target="_blank">pdf</a>]

<h2>Improving Lesion Detection by exploring bias on Skin Lesion dataset. (arXiv:2010.01485v1 [eess.IV])</h2>
<h3>Anusua Trivedi, Sreya Muppalla, Shreyaan Pathak, Azadeh Mobasher, Pawel Janowski, Rahul Dodhia, Juan M. Lavista Ferres</h3>
<p>All datasets contain some biases, often unintentional, due to how they were
acquired and annotated. These biases distort machine-learning models'
performance, creating spurious correlations that the models can unfairly
exploit, or, contrarily destroying clear correlations that the models could
learn. With the popularity of deep learning models, automated skin lesion
analysis is starting to play an essential role in the early detection of
Melanoma. The ISIC Archive is one of the most used skin lesion sources to
benchmark deep learning-based tools. Bissoto et al. experimented with different
bounding-box based masks and showed that deep learning models could classify
skin lesion images without clinically meaningful information in the input data.
Their findings seem confounding since the ablated regions (random rectangular
boxes) are not significant. The shape of the lesion is a crucial factor in the
clinical characterization of a skin lesion. In that context, we performed a set
of experiments that generate shape-preserving masks instead of rectangular
bounding-box based masks. A deep learning model trained on these
shape-preserving masked images does not outperform models trained on images
without clinically meaningful information. That strongly suggests spurious
correlations guiding the models. We propose use of general adversarial network
(GAN) to mitigate the underlying bias.
</p>
<a href="http://arxiv.org/abs/2010.01485" target="_blank">arXiv:2010.01485</a> [<a href="http://arxiv.org/pdf/2010.01485" target="_blank">pdf</a>]

<h2>Learning Compositional Structures for Deep Learning: Why Routing-by-agreement is Necessary. (arXiv:2010.01488v1 [cs.LG])</h2>
<h3>Sai Raam Venkatraman, Ankit Anand, S. Balasubramanian, R. Raghunatha Sarma</h3>
<p>A formal description of the compositionality of neural networks is associated
directly with the formal grammar-structure of the objects it seeks to
represent. This formal grammar-structure specifies the kind of components that
make up an object, and also the configurations they are allowed to be in. In
other words, objects can be described as a parse-tree of its components -- a
structure that can be seen as a candidate for building connection-patterns
among neurons in neural networks. We present a formal grammar description of
convolutional neural networks and capsule networks that shows how capsule
networks can enforce such parse-tree structures, while CNNs do not.
Specifically, we show that the entropy of routing coefficients in the dynamic
routing algorithm controls this ability. Thus, we introduce the entropy of
routing weights as a loss function for better compositionality among capsules.
We show by experiments, on data with a compositional structure, that the use of
this loss enables capsule networks to better detect changes in
compositionality. Our experiments show that as the entropy of the routing
weights increases, the ability to detect changes in compositionality reduces.
We see that, without routing, capsule networks perform similar to convolutional
neural networks in that both these models perform badly at detecting changes in
compositionality. Our results indicate that routing is an important part of
capsule networks -- effectively answering recent work that has questioned its
necessity. We also, by experiments on SmallNORB, CIFAR-10, and FashionMNIST,
show that this loss keeps the accuracy of capsule network models comparable to
models that do not use it .
</p>
<a href="http://arxiv.org/abs/2010.01488" target="_blank">arXiv:2010.01488</a> [<a href="http://arxiv.org/pdf/2010.01488" target="_blank">pdf</a>]

<h2>PTUM: Pre-training User Model from Unlabeled User Behaviors via Self-supervision. (arXiv:2010.01494v1 [cs.IR])</h2>
<h3>Chuhan Wu, Fangzhao Wu, Tao Qi, Jianxun Lian, Yongfeng Huang, Xing Xie</h3>
<p>User modeling is critical for many personalized web services. Many existing
methods model users based on their behaviors and the labeled data of target
tasks. However, these methods cannot exploit useful information in unlabeled
user behavior data, and their performance may be not optimal when labeled data
is scarce. Motivated by pre-trained language models which are pre-trained on
large-scale unlabeled corpus to empower many downstream tasks, in this paper we
propose to pre-train user models from large-scale unlabeled user behaviors
data. We propose two self-supervision tasks for user model pre-training. The
first one is masked behavior prediction, which can model the relatedness
between historical behaviors. The second one is next $K$ behavior prediction,
which can model the relatedness between past and future behaviors. The
pre-trained user models are finetuned in downstream tasks to learn
task-specific user representations. Experimental results on two real-world
datasets validate the effectiveness of our proposed user model pre-training
method.
</p>
<a href="http://arxiv.org/abs/2010.01494" target="_blank">arXiv:2010.01494</a> [<a href="http://arxiv.org/pdf/2010.01494" target="_blank">pdf</a>]

<h2>Dialogue Generation on Infrequent Sentence Functions via Structured Meta-Learning. (arXiv:2010.01495v1 [cs.CL])</h2>
<h3>Yifan Gao, Piji Li, Wei Bi, Xiaojiang Liu, Michael R. Lyu, Irwin King</h3>
<p>Sentence function is an important linguistic feature indicating the
communicative purpose in uttering a sentence. Incorporating sentence functions
into conversations has shown improvements in the quality of generated
responses. However, the number of utterances for different types of
fine-grained sentence functions is extremely imbalanced. Besides a small number
of high-resource sentence functions, a large portion of sentence functions is
infrequent. Consequently, dialogue generation conditioned on these infrequent
sentence functions suffers from data deficiency. In this paper, we investigate
a structured meta-learning (SML) approach for dialogue generation on infrequent
sentence functions. We treat dialogue generation conditioned on different
sentence functions as separate tasks, and apply model-agnostic meta-learning to
high-resource sentence functions data. Furthermore, SML enhances meta-learning
effectiveness by promoting knowledge customization among different sentence
functions but simultaneously preserving knowledge generalization for similar
sentence functions. Experimental results demonstrate that SML not only improves
the informativeness and relevance of generated responses, but also can generate
responses consistent with the target sentence functions.
</p>
<a href="http://arxiv.org/abs/2010.01495" target="_blank">arXiv:2010.01495</a> [<a href="http://arxiv.org/pdf/2010.01495" target="_blank">pdf</a>]

<h2>Explaining Deep Neural Networks. (arXiv:2010.01496v1 [cs.CL])</h2>
<h3>Oana-Maria Camburu</h3>
<p>Deep neural networks are becoming more and more popular due to their
revolutionary success in diverse areas, such as computer vision, natural
language processing, and speech recognition. However, the decision-making
processes of these models are generally not interpretable to users. In various
domains, such as healthcare, finance, or law, it is critical to know the
reasons behind a decision made by an artificial intelligence system. Therefore,
several directions for explaining neural models have recently been explored.

In this thesis, I investigate two major directions for explaining deep neural
networks. The first direction consists of feature-based post-hoc explanatory
methods, that is, methods that aim to explain an already trained and fixed
model (post-hoc), and that provide explanations in terms of input features,
such as tokens for text and superpixels for images (feature-based). The second
direction consists of self-explanatory neural models that generate natural
language explanations, that is, models that have a built-in module that
generates explanations for the predictions of the model.
</p>
<a href="http://arxiv.org/abs/2010.01496" target="_blank">arXiv:2010.01496</a> [<a href="http://arxiv.org/pdf/2010.01496" target="_blank">pdf</a>]

<h2>A New Mask R-CNN Based Method for Improved Landslide Detection. (arXiv:2010.01499v1 [cs.CV])</h2>
<h3>Silvia Liberata Ullo, Amrita Mohan, Alessandro Sebastianelli, Shaik Ejaz Ahamed, Basant Kumar, Ramji Dwivedi, G. R. Sinha</h3>
<p>This paper presents a novel method of landslide detection by exploiting the
Mask R-CNN capability of identifying an object layout by using a pixel-based
segmentation, along with transfer learning used to train the proposed model. A
data set of 160 elements is created containing landslide and non-landslide
images. The proposed method consists of three steps: (i) augmenting training
image samples to increase the volume of the training data, (ii) fine tuning
with limited image samples, and (iii) performance evaluation of the algorithm
in terms of precision, recall and F1 measure, on the considered landslide
images, by adopting ResNet-50 and 101 as backbone models. The experimental
results are quite encouraging as the proposed method achieves Precision equals
to 1.00, Recall 0.93 and F1 measure 0.97, when ResNet-101 is used as backbone
model, and with a low number of landslide photographs used as training samples.
The proposed algorithm can be potentially useful for land use planners and
policy makers of hilly areas where intermittent slope deformations necessitate
landslide detection as prerequisite before planning.
</p>
<a href="http://arxiv.org/abs/2010.01499" target="_blank">arXiv:2010.01499</a> [<a href="http://arxiv.org/pdf/2010.01499" target="_blank">pdf</a>]

<h2>A Study for Universal Adversarial Attacks on Texture Recognition. (arXiv:2010.01506v1 [cs.CV])</h2>
<h3>Yingpeng Deng, Lina J. Karam</h3>
<p>Given the outstanding progress that convolutional neural networks (CNNs) have
made on natural image classification and object recognition problems, it is
shown that deep learning methods can achieve very good recognition performance
on many texture datasets. However, while CNNs for natural image
classification/object recognition tasks have been revealed to be highly
vulnerable to various types of adversarial attack methods, the robustness of
deep learning methods for texture recognition is yet to be examined. In our
paper, we show that there exist small image-agnostic/univesal perturbations
that can fool the deep learning models with more than 80\% of testing fooling
rates on all tested texture datasets. The computed perturbations using various
attack methods on the tested datasets are generally quasi-imperceptible,
containing structured patterns with low, middle and high frequency components.
</p>
<a href="http://arxiv.org/abs/2010.01506" target="_blank">arXiv:2010.01506</a> [<a href="http://arxiv.org/pdf/2010.01506" target="_blank">pdf</a>]

<h2>A Multi-task Learning Framework for Opinion Triplet Extraction. (arXiv:2010.01512v1 [cs.CL])</h2>
<h3>Chen Zhang, Qiuchi Li, Dawei Song, Benyou Wang</h3>
<p>The state-of-the-art Aspect-based Sentiment Analysis (ABSA) approaches are
mainly based on either detecting aspect terms and their corresponding sentiment
polarities, or co-extracting aspect and opinion terms. However, the extraction
of aspect-sentiment pairs lacks opinion terms as a reference, while
co-extraction of aspect and opinion terms would not lead to meaningful pairs
without determining their sentiment dependencies. To address the issue, we
present a novel view of ABSA as an opinion triplet extraction task, and propose
a multi-task learning framework to jointly extract aspect terms and opinion
terms, and simultaneously parses sentiment dependencies between them with a
biaffine scorer. At inference phase, the extraction of triplets is facilitated
by a triplet decoding method based on the above outputs. We evaluate the
proposed framework on four SemEval benchmarks for ASBA. The results demonstrate
that our approach significantly outperforms a range of strong baselines and
state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2010.01512" target="_blank">arXiv:2010.01512</a> [<a href="http://arxiv.org/pdf/2010.01512" target="_blank">pdf</a>]

<h2>RODE: Learning Roles to Decompose Multi-Agent Tasks. (arXiv:2010.01523v1 [cs.LG])</h2>
<h3>Tonghan Wang, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon Whiteson, Chongjie Zhang</h3>
<p>Role-based learning holds the promise of achieving scalable multi-agent
learning by decomposing complex tasks using roles. However, it is largely
unclear how to efficiently discover such a set of roles. To solve this problem,
we propose to first decompose joint action spaces into restricted role action
spaces by clustering actions according to their effects on the environment and
other agents. Learning a role selector based on action effects makes role
discovery much easier because it forms a bi-level learning hierarchy -- the
role selector searches in a smaller role space and at a lower temporal
resolution, while role policies learn in significantly reduced primitive
action-observation spaces. We further integrate information about action
effects into the role policies to boost learning efficiency and policy
generalization. By virtue of these advances, our method (1) outperforms the
current state-of-the-art MARL algorithms on 10 of the 14 scenarios that
comprise the challenging StarCraft II micromanagement benchmark and (2)
achieves rapid transfer to new environments with three times the number of
agents. Demonstrative videos are available at
https://sites.google.com/view/rode-marl .
</p>
<a href="http://arxiv.org/abs/2010.01523" target="_blank">arXiv:2010.01523</a> [<a href="http://arxiv.org/pdf/2010.01523" target="_blank">pdf</a>]

<h2>Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting. (arXiv:2010.01528v1 [cs.CV])</h2>
<h3>Sayna Ebrahimi, Suzanne Petryk, Akash Gokul, William Gan, Joseph E. Gonzalez, Marcus Rohrbach, Trevor Darrell</h3>
<p>The goal of continual learning (CL) is to learn a sequence of tasks without
suffering from the phenomenon of catastrophic forgetting. Previous work has
shown that leveraging memory in the form of a replay buffer can reduce
performance degradation on prior tasks. We hypothesize that forgetting can be
further reduced when the model is encouraged to remember the \textit{evidence}
for previously made decisions. As a first step towards exploring this
hypothesis, we propose a simple novel training paradigm, called Remembering for
the Right Reasons (RRR), that additionally stores visual model explanations for
each example in the buffer and ensures the model has "the right reasons" for
its predictions by encouraging its explanations to remain consistent with those
used to make decisions at training time. Without this constraint, there is a
drift in explanations and increase in forgetting as conventional continual
learning algorithms learn new tasks. We demonstrate how RRR can be easily added
to any memory or regularization-based approach and results in reduced
forgetting, and more importantly, improved model explanations. We have
evaluated our approach in the standard and few-shot settings and observed a
consistent improvement across various CL approaches using different
architectures and techniques to generate model explanations and demonstrated
our approach showing a promising connection between explainability and
continual learning. Our code is available at
https://github.com/SaynaEbrahimi/Remembering-for-the-Right-Reasons.
</p>
<a href="http://arxiv.org/abs/2010.01528" target="_blank">arXiv:2010.01528</a> [<a href="http://arxiv.org/pdf/2010.01528" target="_blank">pdf</a>]

<h2>Towards Cross-modality Medical Image Segmentation with Online Mutual Knowledge Distillation. (arXiv:2010.01532v1 [eess.IV])</h2>
<h3>Kang Li, Lequan Yu, Shujun Wang, Pheng-Ann Heng</h3>
<p>The success of deep convolutional neural networks is partially attributed to
the massive amount of annotated training data. However, in practice, medical
data annotations are usually expensive and time-consuming to be obtained.
Considering multi-modality data with the same anatomic structures are widely
available in clinic routine, in this paper, we aim to exploit the prior
knowledge (e.g., shape priors) learned from one modality (aka., assistant
modality) to improve the segmentation performance on another modality (aka.,
target modality) to make up annotation scarcity. To alleviate the learning
difficulties caused by modality-specific appearance discrepancy, we first
present an Image Alignment Module (IAM) to narrow the appearance gap between
assistant and target modality data.We then propose a novel Mutual Knowledge
Distillation (MKD) scheme to thoroughly exploit the modality-shared knowledge
to facilitate the target-modality segmentation. To be specific, we formulate
our framework as an integration of two individual segmentors. Each segmentor
not only explicitly extracts one modality knowledge from corresponding
annotations, but also implicitly explores another modality knowledge from its
counterpart in mutual-guided manner. The ensemble of two segmentors would
further integrate the knowledge from both modalities and generate reliable
segmentation results on target modality. Experimental results on the public
multi-class cardiac segmentation data, i.e., MMWHS 2017, show that our method
achieves large improvements on CT segmentation by utilizing additional MRI data
and outperforms other state-of-the-art multi-modality learning methods.
</p>
<a href="http://arxiv.org/abs/2010.01532" target="_blank">arXiv:2010.01532</a> [<a href="http://arxiv.org/pdf/2010.01532" target="_blank">pdf</a>]

<h2>Review4Repair: Code Review Aided AutomaticProgram Repairing. (arXiv:2010.01544v1 [cs.SE])</h2>
<h3>Faria Huq, Masum Hasan, Mahim Anzum Haque Pantho, Sazan Mahbub, Anindya Iqbal, Toufique Ahmed</h3>
<p>Context: Learning-based automatic program repair techniques are showing
promise to provide quality fix suggestions for detected bugs in the source code
of the software. These tools mostly exploit historical data of buggy and fixed
code changes and are heavily dependent on bug localizers while applying to a
new piece of code. With the increasing popularity of code review, dependency on
bug localizers can be reduced. Besides, the code review-based bug localization
is more trustworthy since reviewers' expertise and experience are reflected in
these suggestions.

Objective: The natural language instructions scripted on the review comments
are enormous sources of information about the bug's nature and expected
solutions. However, none of the learning-based tools has utilized the review
comments to fix programming bugs to the best of our knowledge. In this study,
we investigate the performance improvement of repair techniques using code
review comments.

Method: We train a sequence-to-sequence model on 55,060 code reviews and
associated code changes. We also introduce new tokenization and preprocessing
approaches that help to achieve significant improvement over state-of-the-art
learning-based repair techniques.

Results: We boost the top-1 accuracy by 20.33% and top-10 accuracy by 34.82%.
We could provide a suggestion for stylistics and non-code errors unaddressed by
prior techniques.

Conclusion: We believe that the automatic fix suggestions along with code
review generated by our approach would help developers address the review
comment quickly and correctly and thus save their time and effort.
</p>
<a href="http://arxiv.org/abs/2010.01544" target="_blank">arXiv:2010.01544</a> [<a href="http://arxiv.org/pdf/2010.01544" target="_blank">pdf</a>]

<h2>High level programming abstractions for leveraging hierarchical memories with micro-core architectures. (arXiv:2010.01548v1 [cs.DC])</h2>
<h3>Maurice Jamieson, Nick Brown</h3>
<p>Micro-core architectures combine many low memory, low power computing cores
together in a single package. These are attractive for use as accelerators but
due to limited on-chip memory and multiple levels of memory hierarchy, the way
in which programmers offload kernels needs to be carefully considered. In this
paper we use Python as a vehicle for exploring the semantics and abstractions
of higher level programming languages to support the offloading of
computational kernels to these devices. By moving to a pass by reference model,
along with leveraging memory kinds, we demonstrate the ability to easily and
efficiently take advantage of multiple levels in the memory hierarchy, even
ones that are not directly accessible to the micro-cores. Using a machine
learning benchmark, we perform experiments on both Epiphany-III and MicroBlaze
based micro-cores, demonstrating the ability to compute with data sets of
arbitrarily large size. To provide context of our results, we explore the
performance and power efficiency of these technologies, demonstrating that
whilst these two micro-core technologies are competitive within their own
embedded class of hardware, there is still a way to go to reach HPC class GPUs.
</p>
<a href="http://arxiv.org/abs/2010.01548" target="_blank">arXiv:2010.01548</a> [<a href="http://arxiv.org/pdf/2010.01548" target="_blank">pdf</a>]

<h2>Leveraging Multilingual News Websites for Building a Kurdish Parallel Corpus. (arXiv:2010.01554v1 [cs.CL])</h2>
<h3>Sina Ahmadi, Hossein Hassani, Daban Q. Jaff</h3>
<p>Machine translation has been a major motivation of development in natural
language processing. Despite the burgeoning achievements in creating more
efficient machine translation systems thanks to deep learning methods, parallel
corpora have remained indispensable for progress in the field. In an attempt to
create parallel corpora for the Kurdish language, in this paper, we describe
our approach in retrieving potentially-alignable news articles from
multi-language websites and manually align them across dialects and languages
based on lexical similarity and transliteration of scripts. We present a corpus
containing 12,327 translation pairs in the two major dialects of Kurdish,
Sorani and Kurmanji. We also provide 1,797 and 650 translation pairs in
English-Kurmanji and English-Sorani. The corpus is publicly available under the
CC BY-NC-SA 4.0 license.
</p>
<a href="http://arxiv.org/abs/2010.01554" target="_blank">arXiv:2010.01554</a> [<a href="http://arxiv.org/pdf/2010.01554" target="_blank">pdf</a>]

<h2>Reverse Operation based Data Augmentation for Solving Math Word Problems. (arXiv:2010.01556v1 [cs.CL])</h2>
<h3>Qianying Liu, Wenyu Guan, Sujian Li, Fei Cheng, Daisuke Kawahara, Sadao Kurohashi</h3>
<p>Automatically solving math word problems is a critical task in the field of
natural language processing. Recent models have reached their performance
bottleneck and require more high-quality data for training. Inspired by human
double-checking mechanism, we propose a reverse operation based data
augmentation method that makes use of mathematical logic to produce new
high-quality math problems and introduce new knowledge points that can give
supervision for new mathematical reasoning logic. We apply the augmented data
on two SOTA math word problem solving models. Experimental results show the
effectiveness of our approach\footnote{We will release our code and data after
the paper is accepted.}.
</p>
<a href="http://arxiv.org/abs/2010.01556" target="_blank">arXiv:2010.01556</a> [<a href="http://arxiv.org/pdf/2010.01556" target="_blank">pdf</a>]

<h2>The FaceChannelS: Strike of the Sequences for the AffWild 2 Challenge. (arXiv:2010.01557v1 [cs.CV])</h2>
<h3>Pablo Barros, Alessandra Sciutti</h3>
<p>Predicting affective information from human faces became a popular task for
most of the machine learning community in the past years. The development of
immense and dense deep neural networks was backed by the availability of
numerous labeled datasets. These models, most of the time, present
state-of-the-art results in such benchmarks, but are very difficult to adapt to
other scenarios. In this paper, we present one more chapter of benchmarking
different versions of the FaceChannel neural network: we demonstrate how our
little model can predict affective information from the facial expression on
the novel AffWild2 dataset.
</p>
<a href="http://arxiv.org/abs/2010.01557" target="_blank">arXiv:2010.01557</a> [<a href="http://arxiv.org/pdf/2010.01557" target="_blank">pdf</a>]

<h2>Facial gesture interfaces for expression and communication. (arXiv:2010.01567v1 [cs.HC])</h2>
<h3>Michael J. Lyons</h3>
<p>Considerable effort has been devoted to the automatic extraction of
information about action of the face from image sequences. Within the context
of human-computer interaction (HCI) we may distinguish systems that allow
expression from those which aim at recognition. Most of the work in facial
action processing has been directed at automatically recognizing affect from
facial actions. By contrast, facial gesture interfaces, which respond to
deliberate facial actions, have received comparatively little attention. This
paper reviews several projects on vision-based interfaces that rely on facial
action for intentional HCI. Applications to several domains are introduced,
including text entry, artistic and musical expression and assistive technology
for motor-impaired users.
</p>
<a href="http://arxiv.org/abs/2010.01567" target="_blank">arXiv:2010.01567</a> [<a href="http://arxiv.org/pdf/2010.01567" target="_blank">pdf</a>]

<h2>DNS Covert Channel Detection via Behavioral Analysis: a Machine Learning Approach. (arXiv:2010.01582v1 [cs.CR])</h2>
<h3>Salvatore Saeli, Federica Bisio, Pierangelo Lombardo, Danilo Massa</h3>
<p>Detecting covert channels among legitimate traffic represents a severe
challenge due to the high heterogeneity of networks. Therefore, we propose an
effective covert channel detection method, based on the analysis of DNS network
data passively extracted from a network monitoring system. The framework is
based on a machine learning module and on the extraction of specific anomaly
indicators able to describe the problem at hand. The contribution of this paper
is two-fold: (i) the machine learning models encompass network profiles
tailored to the network users, and not to the single query events, hence
allowing for the creation of behavioral profiles and spotting possible
deviations from the normal baseline; (ii) models are created in an unsupervised
mode, thus allowing for the identification of zero-days attacks and avoiding
the requirement of signatures or heuristics for new variants. The proposed
solution has been evaluated over a 15-day-long experimental session with the
injection of traffic that covers the most relevant exfiltration and tunneling
attacks: all the malicious variants were detected, while producing a low
false-positive rate during the same period.
</p>
<a href="http://arxiv.org/abs/2010.01582" target="_blank">arXiv:2010.01582</a> [<a href="http://arxiv.org/pdf/2010.01582" target="_blank">pdf</a>]

<h2>Deep kernel processes. (arXiv:2010.01590v1 [stat.ML])</h2>
<h3>Laurence Aitchison, Adam X. Yang, Sebastian W. Ober</h3>
<p>We define deep kernel processes in which positive definite Gram matrices are
progressively transformed by nonlinear kernel functions and by sampling from
(inverse) Wishart distributions. Remarkably, we find that deep Gaussian
processes (DGPs), Bayesian neural networks (BNNs), infinite BNNs, and infinite
BNNs with bottlenecks can all be written as deep kernel processes. For DGPs the
equivalence arises because the Gram matrix formed by the inner product of
features is Wishart distributed, and as we show, standard isotropic kernels can
be written entirely in terms of this Gram matrix -- we do not need knowledge of
the underlying features. We define a tractable deep kernel process, the deep
inverse Wishart process, and give a doubly-stochastic inducing-point
variational inference scheme that operates on the Gram matrices, not on the
features, as in DGPs. We show that the deep inverse Wishart process gives
superior performance to DGPs and infinite BNNs on standard fully-connected
baselines.
</p>
<a href="http://arxiv.org/abs/2010.01590" target="_blank">arXiv:2010.01590</a> [<a href="http://arxiv.org/pdf/2010.01590" target="_blank">pdf</a>]

<h2>Unknown Presentation Attack Detection against Rational Attackers. (arXiv:2010.01592v1 [cs.CV])</h2>
<h3>Ali Khodabakhsh</h3>
<p>Despite the impressive progress in the field of presentation attack detection
and multimedia forensics over the last decade, these systems are still
vulnerable to attacks in real-life settings. Some of the challenges for
existing solutions are the detection of unknown attacks, the ability to perform
in adversarial settings, few-shot learning, and explainability. In this study,
these limitations are approached by reliance on a game-theoretic view for
modeling the interactions between the attacker and the detector. Consequently,
a new optimization criterion is proposed and a set of requirements are defined
for improving the performance of these systems in real-life settings.
Furthermore, a novel detection technique is proposed using generator-based
feature sets that are not biased towards any specific attack species. To
further optimize the performance on known attacks, a new loss function coined
categorical margin maximization loss (C-marmax) is proposed which gradually
improves the performance against the most powerful attack. The proposed
approach provides a more balanced performance across known and unknown attacks
and achieves state-of-the-art performance in known and unknown attack detection
cases against rational attackers. Lastly, the few-shot learning potential of
the proposed approach is studied as well as its ability to provide pixel-level
explainability.
</p>
<a href="http://arxiv.org/abs/2010.01592" target="_blank">arXiv:2010.01592</a> [<a href="http://arxiv.org/pdf/2010.01592" target="_blank">pdf</a>]

<h2>TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly Sampled Time Series. (arXiv:2010.01596v1 [cs.LG])</h2>
<h3>Yang Jiao, Kai Yang, Shaoyu Dou, Pan Luo, Sijia Liu, Dongjin Song</h3>
<p>Multivariate time series (MTS) data are becoming increasingly ubiquitous in
diverse domains, e.g., IoT systems, health informatics, and 5G networks. To
obtain an effective representation of MTS data, it is not only essential to
consider unpredictable dynamics and highly variable lengths of these data but
also important to address the irregularities in the sampling rates of MTS.
Existing parametric approaches rely on manual hyperparameter tuning and may
cost a huge amount of labor effort. Therefore, it is desirable to learn the
representation automatically and efficiently. To this end, we propose an
autonomous representation learning approach for multivariate time series
(TimeAutoML) with irregular sampling rates and variable lengths. As opposed to
previous works, we first present a representation learning pipeline in which
the configuration and hyperparameter optimization are fully automatic and can
be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next,
a negative sample generation approach and an auxiliary classification task are
developed and integrated within TimeAutoML to enhance its representation
capability. Extensive empirical studies on real-world datasets demonstrate that
the proposed TimeAutoML outperforms competing approaches on various tasks by a
large margin. In fact, it achieves the best anomaly detection performance among
all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20%
performance improvement in terms of AUC score.
</p>
<a href="http://arxiv.org/abs/2010.01596" target="_blank">arXiv:2010.01596</a> [<a href="http://arxiv.org/pdf/2010.01596" target="_blank">pdf</a>]

<h2>A Sharp Analysis of Model-based Reinforcement Learning with Self-Play. (arXiv:2010.01604v1 [cs.LG])</h2>
<h3>Qinghua Liu, Tiancheng Yu, Yu Bai, Chi Jin</h3>
<p>Model-based algorithms---algorithms that decouple learning of the model and
planning given the model---are widely used in reinforcement learning practice
and theoretically shown to achieve optimal sample efficiency for single-agent
reinforcement learning in Markov Decision Processes (MDPs). However, for
multi-agent reinforcement learning in Markov games, the current best known
sample complexity for model-based algorithms is rather suboptimal and compares
unfavorably against recent model-free approaches. In this paper, we present a
sharp analysis of model-based self-play algorithms for multi-agent Markov
games. We design an algorithm \emph{Optimistic Nash Value Iteration} (Nash-VI)
for two-player zero-sum Markov games that is able to output an
$\epsilon$-approximate Nash policy in $\tilde{\mathcal{O}}(H^3SAB/\epsilon^2)$
episodes of game playing, where $S$ is the number of states, $A,B$ are the
number of actions for the two players respectively, and $H$ is the horizon
length. This is the first algorithm that matches the information-theoretic
lower bound $\Omega(H^3S(A+B)/\epsilon^2)$ except for a $\min\{A,B\}$ factor,
and compares favorably against the best known model-free algorithm if
$\min\{A,B\}=o(H^3)$. In addition, our Nash-VI outputs a single Markov policy
with optimality guarantee, while existing sample-efficient model-free
algorithms output a nested mixture of Markov policies that is in general
non-Markov and rather inconvenient to store and execute. We further adapt our
analysis to designing a provably efficient task-agnostic algorithm for zero-sum
Markov games, and designing the first line of provably sample-efficient
algorithms for multi-player general-sum Markov games.
</p>
<a href="http://arxiv.org/abs/2010.01604" target="_blank">arXiv:2010.01604</a> [<a href="http://arxiv.org/pdf/2010.01604" target="_blank">pdf</a>]

<h2>When in Doubt, Ask: Generating Answerable and Unanswerable Questions, Unsupervised. (arXiv:2010.01611v1 [cs.CL])</h2>
<h3>Liubov Nikolenko, Pouya Rezazadeh Kalehbasti</h3>
<p>Question Answering (QA) is key for making possible a robust communication
between human and machine. Modern language models used for QA have surpassed
the human-performance in several essential tasks; however, these models require
large amounts of human-generated training data which are costly and
time-consuming to create. This paper studies augmenting human-made datasets
with synthetic data as a way of surmounting this problem. A state-of-the-art
model based on deep transformers is used to inspect the impact of using
synthetic answerable and unanswerable questions to complement a well-known
human-made dataset. The results indicate a tangible improvement in the
performance of the language model (measured in terms of F1 and EM scores)
trained on the mixed dataset. Specifically, unanswerable question-answers prove
more effective in boosting the model: the F1 score gain from adding to the
original dataset the answerable, unanswerable, and combined question-answers
were 1.3\%, 5.0\%, and 6.7\%, respectively. [Link to the Github repository:
https://github.com/lnikolenko/EQA]
</p>
<a href="http://arxiv.org/abs/2010.01611" target="_blank">arXiv:2010.01611</a> [<a href="http://arxiv.org/pdf/2010.01611" target="_blank">pdf</a>]

<h2>AIFNet: Automatic Vascular Function Estimation for Perfusion Analysis Using Deep Learning. (arXiv:2010.01617v1 [eess.IV])</h2>
<h3>Ezequiel de la Rosa, Diana M. Sima, Bjoern Menze, Jan S. Kirschke, David Robben</h3>
<p>Perfusion imaging is crucial in acute ischemic stroke for quantifying the
salvageable penumbra and irreversibly damaged core lesions. As such, it helps
clinicians to decide on the optimal reperfusion treatment. In perfusion CT
imaging, deconvolution methods are used to obtain clinically interpretable
perfusion parameters that allow identifying brain tissue abnormalities.
Deconvolution methods require the selection of two reference vascular functions
as inputs to the model: the arterial input function (AIF) and the venous output
function, with the AIF as the most critical model input. When manually
performed, the vascular function selection is time demanding, suffers from poor
reproducibility and is subject to the professionals' experience. This leads to
potentially unreliable quantification of the penumbra and core lesions and,
hence, might harm the treatment decision process. In this work we automatize
the perfusion analysis with AIFNet, a fully automatic and end-to-end trainable
deep learning approach for estimating the vascular functions. Unlike previous
methods using clustering or segmentation techniques to select vascular voxels,
AIFNet is directly optimized at the vascular function estimation, which allows
to better recognise the time-curve profiles. Validation on the public ISLES18
stroke database shows that AIFNet reaches inter-rater performance for the
vascular function estimation and, subsequently, for the parameter maps and core
lesion quantification obtained through deconvolution. We conclude that AIFNet
has potential for clinical transfer and could be incorporated in perfusion
deconvolution software.
</p>
<a href="http://arxiv.org/abs/2010.01617" target="_blank">arXiv:2010.01617</a> [<a href="http://arxiv.org/pdf/2010.01617" target="_blank">pdf</a>]

<h2>Meta Sequence Learning and Its Applications. (arXiv:2010.01620v1 [cs.CL])</h2>
<h3>Cheng Zhang, Jie Wang</h3>
<p>We present a meta-sequence representation of sentences and demonstrate how to
use meta sequence learning to generate adequate question-answer pairs (QAPs)
over a given article. A meta sequence is a sequence of vectors of semantic and
syntactic tags. On a given declarative sentence, a trained model converts it to
a meta sequence, finds a matched meta sequence in its learned database, and
uses the corresponding meta sequence for interrogative sentence to generate
QAPs. We show that, trained on a small dataset, our method generates
efficiently, on the official SAT practice reading tests, a large number of
syntactically and semantically correct QAPs with high accuracy.
</p>
<a href="http://arxiv.org/abs/2010.01620" target="_blank">arXiv:2010.01620</a> [<a href="http://arxiv.org/pdf/2010.01620" target="_blank">pdf</a>]

<h2>Deep Just-In-Time Inconsistency Detection Between Comments and Source Code. (arXiv:2010.01625v1 [cs.SE])</h2>
<h3>Sheena Panthaplackel, Junyi Jessy Li, Milos Gligoric, Raymond J. Mooney</h3>
<p>Natural language comments convey key aspects of source code such as
implementation, usage, and pre- and post-conditions. Failure to update comments
accordingly when the corresponding code is modified introduces inconsistencies,
which is known to lead to confusion and software bugs. In this paper, we aim to
detect whether a comment becomes inconsistent as a result of changes to the
corresponding body of code, in order to catch potential inconsistencies
just-in-time, i.e., before they are committed to a version control system. To
achieve this, we develop a deep-learning approach that learns to correlate a
comment with code changes. By evaluating on a large corpus of comment/code
pairs spanning various comment types, we show that our model outperforms
multiple baselines by significant margins. For extrinsic evaluation, we show
the usefulness of our approach by combining it with a comment update model to
build a more comprehensive automatic comment maintenance system which can both
detect and resolve inconsistent comments based on code changes.
</p>
<a href="http://arxiv.org/abs/2010.01625" target="_blank">arXiv:2010.01625</a> [<a href="http://arxiv.org/pdf/2010.01625" target="_blank">pdf</a>]

<h2>Understanding How Over-Parametrization Leads to Acceleration: A case of learning a single teacher neuron. (arXiv:2010.01637v1 [cs.LG])</h2>
<h3>Jun-Kun Wang, Jacob Abernethy</h3>
<p>Over-parametrization has become a popular technique in deep learning. It is
observed that by over-parametrization, a larger neural network needs a fewer
training iterations than a smaller one to achieve a certain level of
performance -- namely, over-parametrization leads to acceleration in
optimization. However, despite that over-parametrization is widely used
nowadays, little theory is available to explain the acceleration due to
over-parametrization. In this paper, we propose understanding it by studying a
simple problem first. Specifically, we consider the setting that there is a
single teacher neuron with quadratic activation, where over-parametrization is
realized by having multiple student neurons learn the data generated from the
teacher neuron. We provably show that over-parametrization helps the iterate
generated by gradient descent to enter the neighborhood of a global optimal
solution that achieves zero testing error faster. On the other hand, we also
point out an issue regarding the necessity of over-parametrization and study
how the scaling of the output neurons affects the convergence time.
</p>
<a href="http://arxiv.org/abs/2010.01637" target="_blank">arXiv:2010.01637</a> [<a href="http://arxiv.org/pdf/2010.01637" target="_blank">pdf</a>]

<h2>Interface Design for HCI Classroom: From Learners' Perspective. (arXiv:2010.01651v1 [cs.HC])</h2>
<h3>Huyen N. Nguyen, Vinh T. Nguyen, Tommy Dang</h3>
<p>Having a good Human-Computer Interaction (HCI) design is challenging.
Previous works have contributed significantly to fostering HCI, including
design principle with report study from the instructor view. The questions of
how and to what extent students perceive the design principles are still left
open. To answer this question, this paper conducts a study of HCI adoption in
the classroom. The studio-based learning method was adapted to teach 83
graduate and undergraduate students in 16 weeks long with four activities. A
standalone presentation tool for instant online peer feedback during the
presentation session was developed to help students justify and critique
other's work. Our tool provides a sandbox, which supports multiple application
types, including Web-applications, Object Detection, Web-based Virtual Reality
(VR), and Augmented Reality (AR). After presenting one assignment and two
projects, our results showed that students acquired a better understanding of
the Golden Rules principle over time, which was demonstrated by the development
of visual interface design. The Wordcloud reveals the primary focus was on the
user interface and shed some light on students' interest in user experience.
The inter-rater score indicates the agreement among students that they have the
same level of understanding of the principles. The results show a high level of
guideline compliance with HCI principles, in which we witnessed variations in
visual cognitive styles. Regardless of diversity in visual preference, the
students presented high consistency and a similar perspective on adopting HCI
design principles. The results also elicited suggestions into the development
of the HCI curriculum in the future.
</p>
<a href="http://arxiv.org/abs/2010.01651" target="_blank">arXiv:2010.01651</a> [<a href="http://arxiv.org/pdf/2010.01651" target="_blank">pdf</a>]

<h2>FORK: A Forward-Looking Actor For Model-Free Reinforcement Learning. (arXiv:2010.01652v1 [cs.LG])</h2>
<h3>Honghao Wei, Lei Ying</h3>
<p>In this paper, we propose a new type of Actor, named forward-looking Actor or
FORK for short, for Actor-Critic algorithms. FORK can be easily integrated into
a model-free Actor-Critic algorithm. Our experiments on six Box2D and MuJoCo
environments with continuous state and action spaces demonstrate significant
performance improvement FORK can bring to the state-of-the-art algorithms. A
variation of FORK can further solve Bipedal-WalkerHardcore in as few as four
hours using a single GPU.
</p>
<a href="http://arxiv.org/abs/2010.01652" target="_blank">arXiv:2010.01652</a> [<a href="http://arxiv.org/pdf/2010.01652" target="_blank">pdf</a>]

<h2>An Empirical Study on Large-Scale Multi-Label Text Classification Including Few and Zero-Shot Labels. (arXiv:2010.01653v1 [cs.CL])</h2>
<h3>Ilias Chalkidis, Manos Fergadiotis, Sotiris Kotitsas, Prodromos Malakasiotis, Nikolaos Aletras, Ion Androutsopoulos</h3>
<p>Large-scale Multi-label Text Classification (LMTC) has a wide range of
Natural Language Processing (NLP) applications and presents interesting
challenges. First, not all labels are well represented in the training set, due
to the very large label set and the skewed label distributions of LMTC
datasets. Also, label hierarchies and differences in human labelling guidelines
may affect graph-aware annotation proximity. Finally, the label hierarchies are
periodically updated, requiring LMTC models capable of zero-shot
generalization. Current state-of-the-art LMTC models employ Label-Wise
Attention Networks (LWANs), which (1) typically treat LMTC as flat multi-label
classification; (2) may use the label hierarchy to improve zero-shot learning,
although this practice is vastly understudied; and (3) have not been combined
with pre-trained Transformers (e.g. BERT), which have led to state-of-the-art
results in several NLP benchmarks. Here, for the first time, we empirically
evaluate a battery of LMTC methods from vanilla LWANs to hierarchical
classification approaches and transfer learning, on frequent, few, and
zero-shot learning on three datasets from different domains. We show that
hierarchical methods based on Probabilistic Label Trees (PLTs) outperform
LWANs. Furthermore, we show that Transformer-based approaches outperform the
state-of-the-art in two of the datasets, and we propose a new state-of-the-art
method which combines BERT with LWANs. Finally, we propose new models that
leverage the label hierarchy to improve few and zero-shot learning, considering
on each dataset a graph-aware annotation proximity measure that we introduce.
</p>
<a href="http://arxiv.org/abs/2010.01653" target="_blank">arXiv:2010.01653</a> [<a href="http://arxiv.org/pdf/2010.01653" target="_blank">pdf</a>]

<h2>On higher order computations, rewiring the connectome, and non-von Neumann computer architecture. (arXiv:1603.02238v4 [cs.NE] UPDATED)</h2>
<h3>Stanislaw Ambroszkiewicz</h3>
<p>Structural plasticity in the brain (i.e. rewiring the connectome) may be
viewed as mechanisms for dynamic reconfiguration of neural circuits. First
order computations in the brain are done by static neural circuits, whereas
higher order computations are done by dynamic reconfigurations of the links
(synapses) between the neural circuits. Static neural circuits correspond to
first order computable functions. Synapse creation (activation) between them
correspond to the mathematical notion of function composition. Functionals are
higher order functions that take functions as their arguments. The construction
of functionals is based on dynamic reconfigurations of function compositions.
Perhaps the functionals correspond to rewiring mechanisms of the connectome.
The architecture of human mind is different than the von Neumann computer
architecture. Higher order computations in the human brain (based on
functionals) may suggest a non-von Neumann computer architecture, a challenge
posed by John Backus in 1977 \cite{Backus}. The presented work is a substantial
extension and revision of the paper published in Proc. ICANN2016.
</p>
<a href="http://arxiv.org/abs/1603.02238" target="_blank">arXiv:1603.02238</a> [<a href="http://arxiv.org/pdf/1603.02238" target="_blank">pdf</a>]

<h2>Cost-Sensitive Deep Learning with Layer-Wise Cost Estimation. (arXiv:1611.05134v2 [cs.CV] UPDATED)</h2>
<h3>Yu-An Chung, Shao-Wen Yang, Hsuan-Tien Lin</h3>
<p>While deep neural networks have succeeded in several visual applications,
such as object recognition, detection, and localization, by reaching very high
classification accuracies, it is important to note that many real-world
applications demand varying costs for different types of misclassification
errors, thus requiring cost-sensitive classification algorithms. Current models
of deep neural networks for cost-sensitive classification are restricted to
some specific network structures and limited depth. In this paper, we propose a
novel framework that can be applied to deep neural networks with any structure
to facilitate their learning of meaningful representations for cost-sensitive
classification problems. Furthermore, the framework allows end-to-end training
of deeper networks directly. The framework is designed by augmenting auxiliary
neurons to the output of each hidden layer for layer-wise cost estimation, and
including the total estimation loss within the optimization objective.
Experimental results on public benchmark visual data sets with two cost
information settings demonstrate that the proposed framework outperforms
state-of-the-art cost-sensitive deep learning models.
</p>
<a href="http://arxiv.org/abs/1611.05134" target="_blank">arXiv:1611.05134</a> [<a href="http://arxiv.org/pdf/1611.05134" target="_blank">pdf</a>]

<h2>RUR53: an Unmanned Ground Vehicle for Navigation, Recognition and Manipulation. (arXiv:1711.08764v2 [cs.RO] UPDATED)</h2>
<h3>Nicola Castaman, Elisa Tosello, Morris Antonello, Nicola Bagarello, Silvia Gandin, Marco Carraro, Matteo Munaro, Roberto Bortoletto, Stefano Ghidoni, Emanuele Menegatti, Enrico Pagello</h3>
<p>This paper proposes RUR53: an Unmanned Ground Vehicle able to autonomously
navigate through, identify, and reach areas of interest; and there recognize,
localize, and manipulate work tools to perform complex manipulation tasks. The
proposed contribution includes a modular software architecture where each
module solves specific sub-tasks and that can be easily enlarged to satisfy new
requirements. Included indoor and outdoor tests demonstrate the capability of
the proposed system to autonomously detect a target object (a panel) and
precisely dock in front of it while avoiding obstacles. They show it can
autonomously recognize and manipulate target work tools (i.e., wrenches and
valve stems) to accomplish complex tasks (i.e., use a wrench to rotate a valve
stem). A specific case study is described where the proposed modular
architecture lets easy switch to a semi-teleoperated mode. The paper
exhaustively describes description of both the hardware and software setup of
RUR53, its performance when tests at the 2017 Mohamed Bin Zayed International
Robotics Challenge, and the lessons we learned when participating at this
competition, where we ranked third in the Gran Challenge in collaboration with
the Czech Technical University in Prague, the University of Pennsylvania, and
the University of Lincoln (UK).
</p>
<a href="http://arxiv.org/abs/1711.08764" target="_blank">arXiv:1711.08764</a> [<a href="http://arxiv.org/pdf/1711.08764" target="_blank">pdf</a>]

<h2>Query-Efficient Black-Box Attack Against Sequence-Based Malware Classifiers. (arXiv:1804.08778v7 [cs.CR] UPDATED)</h2>
<h3>Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, Lior Rokach</h3>
<p>In this paper, we present a generic, query-efficient black-box attack against
API call-based machine learning malware classifiers. We generate adversarial
examples by modifying the malware's API call sequences and non-sequential
features (printable strings), and these adversarial examples will be
misclassified by the target malware classifier without affecting the malware's
functionality. In contrast to previous studies, our attack minimizes the number
of malware classifier queries required. In addition, in our attack, the
attacker must only know the class predicted by the malware classifier; attacker
knowledge of the malware classifier's confidence score is optional. We evaluate
the attack effectiveness when attacks are performed against a variety of
malware classifier architectures, including recurrent neural network (RNN)
variants, deep neural networks, support vector machines, and gradient boosted
decision trees. Our attack success rate is around 98% when the classifier's
confidence score is known and 64% when just the classifier's predicted class is
known. We implement four state-of-the-art query-efficient attacks and show that
our attack requires fewer queries and less knowledge about the attacked model's
architecture than other existing query-efficient attacks, making it practical
for attacking cloud-based malware classifiers at a minimal cost.
</p>
<a href="http://arxiv.org/abs/1804.08778" target="_blank">arXiv:1804.08778</a> [<a href="http://arxiv.org/pdf/1804.08778" target="_blank">pdf</a>]

<h2>Learning and Interpreting Multi-Multi-Instance Learning Networks. (arXiv:1810.11514v4 [cs.LG] UPDATED)</h2>
<h3>Alessandro Tibo, Manfred Jaeger, Paolo Frasconi</h3>
<p>We introduce an extension of the multi-instance learning problem where
examples are organized as nested bags of instances (e.g., a document could be
represented as a bag of sentences, which in turn are bags of words). This
framework can be useful in various scenarios, such as text and image
classification, but also supervised learning over graphs. As a further
advantage, multi-multi instance learning enables a particular way of
interpreting predictions and the decision function. Our approach is based on a
special neural network layer, called bag-layer, whose units aggregate bags of
inputs of arbitrary size. We prove theoretically that the associated class of
functions contains all Boolean functions over sets of sets of instances and we
provide empirical evidence that functions of this kind can be actually learned
on semi-synthetic datasets. We finally present experiments on text
classification, on citation graphs, and social graph data, which show that our
model obtains competitive results with respect to accuracy when compared to
other approaches such as convolutional networks on graphs, while at the same
time it supports a general approach to interpret the learnt model, as well as
explain individual predictions.
</p>
<a href="http://arxiv.org/abs/1810.11514" target="_blank">arXiv:1810.11514</a> [<a href="http://arxiv.org/pdf/1810.11514" target="_blank">pdf</a>]

<h2>Probabilistic Class-Specific Discriminant Analysis. (arXiv:1812.05980v5 [cs.LG] UPDATED)</h2>
<h3>Alexandros Iosifidis</h3>
<p>In this paper we formulate a probabilistic model for class-specific
discriminant subspace learning. The proposed model can naturally incorporate
the multi-modal structure of the negative class, which is neglected by existing
class-specific methods. Moreover, it can be directly used to define a
class-specific probabilistic classification rule in the discriminant subspace.
We show that existing class-specific discriminant analysis methods are special
cases of the proposed probabilistic model and, by casting them as probabilistic
models, they can be extended to class-specific classifiers. We illustrate the
performance of the proposed model in both verification and classification
problems.
</p>
<a href="http://arxiv.org/abs/1812.05980" target="_blank">arXiv:1812.05980</a> [<a href="http://arxiv.org/pdf/1812.05980" target="_blank">pdf</a>]

<h2>Successor Features Combine Elements of Model-Free and Model-based Reinforcement Learning. (arXiv:1901.11437v3 [cs.LG] UPDATED)</h2>
<h3>Lucas Lehnert, Michael L. Littman</h3>
<p>A key question in reinforcement learning is how an intelligent agent can
generalize knowledge across different inputs. By generalizing across different
inputs, information learned for one input can be immediately reused for
improving predictions for another input. Reusing information allows an agent to
compute an optimal decision-making strategy using less data. State
representation is a key element of the generalization process, compressing a
high-dimensional input space into a low-dimensional latent state space. This
article analyzes properties of different latent state spaces, leading to new
connections between model-based and model-free reinforcement learning.
Successor features, which predict frequencies of future observations, form a
link between model-based and model-free learning: Learning to predict future
expected reward outcomes, a key characteristic of model-based agents, is
equivalent to learning successor features. Learning successor features is a
form of temporal difference learning and is equivalent to learning to predict a
single policy's utility, which is a characteristic of model-free agents.
Drawing on the connection between model-based reinforcement learning and
successor features, we demonstrate that representations that are predictive of
future reward outcomes generalize across variations in both transitions and
rewards. This result extends previous work on successor features, which is
constrained to fixed transitions and assumes re-learning of the transferred
state representation.
</p>
<a href="http://arxiv.org/abs/1901.11437" target="_blank">arXiv:1901.11437</a> [<a href="http://arxiv.org/pdf/1901.11437" target="_blank">pdf</a>]

<h2>Performance Modeling of Microservice Platforms. (arXiv:1902.03387v2 [cs.DC] UPDATED)</h2>
<h3>Hamzeh Khazaei, Nima Mahmoudi, Cornel Barna, Marin Litoiu</h3>
<p>Microservice architecture has transformed the way developers are building and
deploying applications in the nowadays cloud computing centers. This new
approach provides increased scalability, flexibility, manageability, and
performance while reducing the complexity of the whole software development
life cycle. The increase in cloud resource utilization also benefits
microservice providers. Various microservice platforms have emerged to
facilitate the DevOps of containerized services by enabling continuous
integration and delivery. Microservice platforms deploy application containers
on virtual or physical machines provided by public/private cloud
infrastructures in a seamless manner. In this paper, we study and evaluate the
provisioning performance of microservice platforms by incorporating the details
of all layers (i.e., both micro and macro layers) in the modelling process. To
this end, we first build a microservice platform on top of Amazon EC2 cloud and
then leverage it to develop a comprehensive performance model to perform
what-if analysis and capacity planning for microservice platforms at scale. In
other words, the proposed performance model provides a systematic approach to
measure the elasticity of the microservice platform by analyzing the
provisioning performance at both the microservice platform and the back-end
macroservice infrastructures.
</p>
<a href="http://arxiv.org/abs/1902.03387" target="_blank">arXiv:1902.03387</a> [<a href="http://arxiv.org/pdf/1902.03387" target="_blank">pdf</a>]

<h2>Parametric inference with universal function approximators. (arXiv:1903.04209v4 [stat.ML] UPDATED)</h2>
<h3>Andreas Joseph</h3>
<p>Universal function approximators, such as artificial neural networks, can
learn a large variety of target functions arbitrarily well given sufficient
training data. This flexibility comes at the cost of the ability to perform
parametric inference. We address this gap by proposing a generic framework
based on the Shapley-Taylor decomposition of a model. A surrogate parametric
regression analysis is performed in the space spanned by the Shapley value
expansion of a model. This allows for the testing of standard hypotheses of
interest. At the same time, the proposed approach provides novel insights into
statistical learning processes themselves derived from the consistency and bias
properties of the nonparametric estimators. We apply the framework to the
estimation of heterogeneous treatment effects in simulated and real-world
randomised experiments. We introduce an explicit treatment function based on
higher-order Shapley-Taylor indices. This can be used to identify potentially
complex treatment channels and help the generalisation of findings from
experimental settings. More generally, the presented approach allows for a
standardised use and communication of results from machine learning models.
</p>
<a href="http://arxiv.org/abs/1903.04209" target="_blank">arXiv:1903.04209</a> [<a href="http://arxiv.org/pdf/1903.04209" target="_blank">pdf</a>]

<h2>Hypothesis Set Stability and Generalization. (arXiv:1904.04755v3 [cs.LG] UPDATED)</h2>
<h3>Dylan J. Foster, Spencer Greenberg, Satyen Kale, Haipeng Luo, Mehryar Mohri, Karthik Sridharan</h3>
<p>We present a study of generalization for data-dependent hypothesis sets. We
give a general learning guarantee for data-dependent hypothesis sets based on a
notion of transductive Rademacher complexity. Our main result is a
generalization bound for data-dependent hypothesis sets expressed in terms of a
notion of hypothesis set stability and a notion of Rademacher complexity for
data-dependent hypothesis sets that we introduce. This bound admits as special
cases both standard Rademacher complexity bounds and algorithm-dependent
uniform stability bounds. We also illustrate the use of these learning bounds
in the analysis of several scenarios.
</p>
<a href="http://arxiv.org/abs/1904.04755" target="_blank">arXiv:1904.04755</a> [<a href="http://arxiv.org/pdf/1904.04755" target="_blank">pdf</a>]

<h2>Stochastic Shared Embeddings: Data-driven Regularization of Embedding Layers. (arXiv:1905.10630v3 [cs.LG] UPDATED)</h2>
<h3>Liwei Wu, Shuqing Li, Cho-Jui Hsieh, James Sharpnack</h3>
<p>In deep neural nets, lower level embedding layers account for a large portion
of the total number of parameters. Tikhonov regularization, graph-based
regularization, and hard parameter sharing are approaches that introduce
explicit biases into training in a hope to reduce statistical complexity.
Alternatively, we propose stochastically shared embeddings (SSE), a data-driven
approach to regularizing embedding layers, which stochastically transitions
between embeddings during stochastic gradient descent (SGD). Because SSE
integrates seamlessly with existing SGD algorithms, it can be used with only
minor modifications when training large scale neural networks. We develop two
versions of SSE: SSE-Graph using knowledge graphs of embeddings; SSE-SE using
no prior information. We provide theoretical guarantees for our method and show
its empirical effectiveness on 6 distinct tasks, from simple neural networks
with one hidden layer in recommender systems, to the transformer and BERT in
natural languages. We find that when used along with widely-used regularization
methods such as weight decay and dropout, our proposed SSE can further reduce
overfitting, which often leads to more favorable generalization results.
</p>
<a href="http://arxiv.org/abs/1905.10630" target="_blank">arXiv:1905.10630</a> [<a href="http://arxiv.org/pdf/1905.10630" target="_blank">pdf</a>]

<h2>Derivative Manipulation for General Example Weighting. (arXiv:1905.11233v10 [cs.LG] UPDATED)</h2>
<h3>Xinshao Wang, Elyor Kodirov, Yang Hua, Neil M. Robertson</h3>
<p>Real-world large-scale datasets usually contain noisy labels and are
imbalanced. Therefore, we propose derivative manipulation (DM), a novel and
general example weighting approach for training robust deep models under these
adverse conditions.

DM has two main merits. First, loss function and example weighting are common
techniques in the literature. DM reveals their connection (a loss function does
example weighting) and is a replacement of both. Second, despite that a loss
defines an example weighting scheme by its derivative, in the loss design, we
need to consider whether it is differentiable. Instead, DM is more flexible by
directly modifying the derivative so that a loss can be a non-elementary format
too. Technically, DM defines an emphasis density function by a derivative
magnitude function. DM is generic in that diverse weighting schemes can be
derived.

Extensive experiments on both vision and language tasks prove DM's
effectiveness.
</p>
<a href="http://arxiv.org/abs/1905.11233" target="_blank">arXiv:1905.11233</a> [<a href="http://arxiv.org/pdf/1905.11233" target="_blank">pdf</a>]

<h2>Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee. (arXiv:1905.11368v4 [cs.LG] UPDATED)</h2>
<h3>Wei Hu, Zhiyuan Li, Dingli Yu</h3>
<p>Over-parameterized deep neural networks trained by simple first-order methods
are known to be able to fit any labeling of data. Such over-fitting ability
hinders generalization when mislabeled training examples are present. On the
other hand, simple regularization methods like early-stopping can often achieve
highly nontrivial performance on clean test data in these scenarios, a
phenomenon not theoretically understood. This paper proposes and analyzes two
simple and intuitive regularization methods: (i) regularization by the distance
between the network parameters to initialization, and (ii) adding a trainable
auxiliary variable to the network output for each training example.
Theoretically, we prove that gradient descent training with either of these two
methods leads to a generalization guarantee on the clean data distribution
despite being trained using noisy labels. Our generalization analysis relies on
the connection between wide neural network and neural tangent kernel (NTK). The
generalization bound is independent of the network size, and is comparable to
the bound one can get when there is no label noise. Experimental results verify
the effectiveness of these methods on noisily labeled datasets.
</p>
<a href="http://arxiv.org/abs/1905.11368" target="_blank">arXiv:1905.11368</a> [<a href="http://arxiv.org/pdf/1905.11368" target="_blank">pdf</a>]

<h2>Privacy-Preserving Deep Action Recognition: An Adversarial Learning Framework and A New Dataset. (arXiv:1906.05675v4 [cs.CV] UPDATED)</h2>
<h3>Zhenyu Wu, Haotao Wang, Zhaowen Wang, Hailin Jin, Zhangyang Wang</h3>
<p>We investigate privacy-preserving, video-based action recognition in deep
learning, a problem with growing importance in smart camera applications. A
novel adversarial training framework is formulated to learn an anonymization
transform for input videos such that the trade-off between target utility task
performance and the associated privacy budgets is explicitly optimized on the
anonymized videos. Notably, the privacy budget, often defined and measured in
task-driven contexts, cannot be reliably indicated using any single model
performance because strong protection of privacy should sustain against any
malicious model that tries to steal private information. To tackle this
problem, we propose two new optimization strategies of model restarting and
model ensemble to achieve stronger universal privacy protection against any
attacker models. Extensive experiments have been carried out and analyzed. On
the other hand, given few public datasets available with both utility and
privacy labels, the data-driven (supervised) learning cannot exert its full
power on this task. We first discuss an innovative heuristic of cross-dataset
training and evaluation, enabling the use of multiple single-task datasets (one
with target task labels and the other with privacy labels) in our problem. To
further address this dataset challenge, we have constructed a new dataset,
termed PA-HMDB51, with both target task labels (action) and selected privacy
attributes (skin color, face, gender, nudity, and relationship) annotated on a
per-frame basis. This first-of-its-kind video dataset and evaluation protocol
can greatly facilitate visual privacy research and open up other opportunities.
Our codes, models, and the PA-HMDB51 dataset are available at
https://github.com/VITA-Group/PA-HMDB51.
</p>
<a href="http://arxiv.org/abs/1906.05675" target="_blank">arXiv:1906.05675</a> [<a href="http://arxiv.org/pdf/1906.05675" target="_blank">pdf</a>]

<h2>Disentangling feature and lazy training in deep neural networks. (arXiv:1906.08034v4 [cs.LG] UPDATED)</h2>
<h3>Mario Geiger, Stefano Spigler, Arthur Jacot, Matthieu Wyart</h3>
<p>Two distinct limits for deep learning have been derived as the network width
$h\rightarrow \infty$, depending on how the weights of the last layer scale
with $h$. In the Neural Tangent Kernel (NTK) limit, the dynamics becomes linear
in the weights and is described by a frozen kernel $\Theta$. By contrast, in
the Mean-Field limit, the dynamics can be expressed in terms of the
distribution of the parameters associated with a neuron, that follows a partial
differential equation. In this work we consider deep networks where the weights
in the last layer scale as $\alpha h^{-1/2}$ at initialization. By varying
$\alpha$ and $h$, we probe the crossover between the two limits. We observe the
previously identified regimes of lazy training and feature training. In the
lazy-training regime, the dynamics is almost linear and the NTK barely changes
after initialization. The feature-training regime includes the mean-field
formulation as a limiting case and is characterized by a kernel that evolves in
time, and learns some features. We perform numerical experiments on MNIST,
Fashion-MNIST, EMNIST and CIFAR10 and consider various architectures. We find
that (i) The two regimes are separated by an $\alpha^*$ that scales as
$h^{-1/2}$. (ii) Network architecture and data structure play an important role
in determining which regime is better: in our tests, fully-connected networks
perform generally better in the lazy-training regime, unlike convolutional
networks. (iii) In both regimes, the fluctuations $\delta F$ induced on the
learned function by initial conditions decay as $\delta F\sim 1/\sqrt{h}$,
leading to a performance that increases with $h$. The same improvement can also
be obtained at an intermediate width by ensemble-averaging several networks.
(iv) In the feature-training regime we identify a time scale
$t_1\sim\sqrt{h}\alpha$, such that for $t\ll t_1$ the dynamics is linear.
</p>
<a href="http://arxiv.org/abs/1906.08034" target="_blank">arXiv:1906.08034</a> [<a href="http://arxiv.org/pdf/1906.08034" target="_blank">pdf</a>]

<h2>A Concise Model for Multi-Criteria Chinese Word Segmentation with Transformer Encoder. (arXiv:1906.12035v2 [cs.CL] UPDATED)</h2>
<h3>Xipeng Qiu, Hengzhi Pei, Hang Yan, Xuanjing Huang</h3>
<p>Multi-criteria Chinese word segmentation (MCCWS) aims to exploit the
relations among the multiple heterogeneous segmentation criteria and further
improve the performance of each single criterion. Previous work usually regards
MCCWS as different tasks, which are learned together under the multi-task
learning framework. In this paper, we propose a concise but effective unified
model for MCCWS, which is fully-shared for all the criteria. By leveraging the
powerful ability of the Transformer encoder, the proposed unified model can
segment Chinese text according to a unique criterion-token indicating the
output criterion. Besides, the proposed unified model can segment both
simplified and traditional Chinese and has an excellent transfer capability.
Experiments on eight datasets with different criteria show that our model
outperforms our single-criterion baseline model and other multi-criteria
models. Source codes of this paper are available on Github
https://github.com/acphile/MCCWS.
</p>
<a href="http://arxiv.org/abs/1906.12035" target="_blank">arXiv:1906.12035</a> [<a href="http://arxiv.org/pdf/1906.12035" target="_blank">pdf</a>]

<h2>A physics-informed reinforcement learning approach for the interfacial area transport in two-phase flow. (arXiv:1908.02750v2 [physics.comp-ph] UPDATED)</h2>
<h3>Zhuoran Dang, Mamoru Ishii</h3>
<p>The prediction of interfacial structure in two-phase flow systems is
difficult and challenging. In this paper, a novel physics-informed
reinforcement learning-aided framework (PIRLF) for the interfacial area
transport is proposed. A Markov Decision Process that describes the bubble
transport is established by assuming that the development of two-phase flow is
a stochastic process with Markov property. The framework aims to capture the
complexity of two-phase flow using the advantage of reinforcement learning (RL)
in discovering complex patterns with the help of the physical model
(Interfacial Area Transport Equation) as reference. The details of the
framework design are described including the design of the environment and the
algorithm used in solving the RL problem. The performance of the PIRLF is
tested through experiments using the experimental database for vertical upward
bubbly air-water flows. The result shows a good performance of PIRLF with rRMSE
of 6.556%. The case studies on the PIRLF performance also show that the type of
reward function that is related to the physical model can affect the framework
performance. Based on the study, the optimal reward function is established.
The approaches to extending the capability of PIRLF are discussed, which can be
a reference for the further development of this methodology.
</p>
<a href="http://arxiv.org/abs/1908.02750" target="_blank">arXiv:1908.02750</a> [<a href="http://arxiv.org/pdf/1908.02750" target="_blank">pdf</a>]

<h2>Delving into Robust Object Detection from Unmanned Aerial Vehicles: A Deep Nuisance Disentanglement Approach. (arXiv:1908.03856v2 [cs.CV] UPDATED)</h2>
<h3>Zhenyu Wu, Karthik Suresh, Priya Narayanan, Hongyu Xu, Heesung Kwon, Zhangyang Wang</h3>
<p>Object detection from images captured by Unmanned Aerial Vehicles (UAVs) is
becoming increasingly useful. Despite the great success of the generic object
detection methods trained on ground-to-ground images, a huge performance drop
is observed when they are directly applied to images captured by UAVs. The
unsatisfactory performance is owing to many UAV-specific nuisances, such as
varying flying altitudes, adverse weather conditions, dynamically changing
viewing angles, etc. Those nuisances constitute a large number of fine-grained
domains, across which the detection model has to stay robust. Fortunately, UAVs
will record meta-data that depict those varying attributes, which are either
freely available along with the UAV images, or can be easily obtained. We
propose to utilize those free meta-data in conjunction with associated UAV
images to learn domain-robust features via an adversarial training framework
dubbed Nuisance Disentangled Feature Transform (NDFT), for the specific
challenging problem of object detection in UAV images, achieving a substantial
gain in robustness to those nuisances. We demonstrate the effectiveness of our
proposed algorithm, by showing state-of-the-art performance (single model) on
two existing UAV-based object detection benchmarks. The code is available at
https://github.com/TAMU-VITA/UAV-NDFT.
</p>
<a href="http://arxiv.org/abs/1908.03856" target="_blank">arXiv:1908.03856</a> [<a href="http://arxiv.org/pdf/1908.03856" target="_blank">pdf</a>]

<h2>Robust Online Multi-target Visual Tracking using a HISP Filter with Discriminative Deep Appearance Learning. (arXiv:1908.03945v5 [cs.CV] UPDATED)</h2>
<h3>Nathanael L. Baisa</h3>
<p>We propose a novel online multi-target visual tracker based on the recently
developed Hypothesized and Independent Stochastic Population (HISP) filter. The
HISP filter combines advantages of traditional tracking approaches like MHT and
point-process-based approaches like PHD filter, and it has linear complexity
while maintaining track identities. We apply this filter for tracking multiple
targets in video sequences acquired under varying environmental conditions and
targets density using a tracking-by-detection approach. We also adopt deep CNN
appearance representation by training a verification-identification network
(VerIdNet) on large-scale person re-identification data sets. We construct an
augmented likelihood in a principled manner using this deep CNN appearance
features and spatio-temporal information. Furthermore, we solve the problem of
two or more targets having identical label considering the weight propagated
with each confirmed hypothesis. Extensive experiments on MOT16 and MOT17
benchmark data sets show that our tracker significantly outperforms several
state-of-the-art trackers in terms of tracking accuracy.
</p>
<a href="http://arxiv.org/abs/1908.03945" target="_blank">arXiv:1908.03945</a> [<a href="http://arxiv.org/pdf/1908.03945" target="_blank">pdf</a>]

<h2>Named Entity Recognition Only from Word Embeddings. (arXiv:1909.00164v2 [cs.IR] UPDATED)</h2>
<h3>Ying Luo, Hai Zhao, Junlang Zhan</h3>
<p>Deep neural network models have helped named entity (NE) recognition achieve
amazing performance without handcrafting features. However, existing systems
require large amounts of human annotated training data. Efforts have been made
to replace human annotations with external knowledge (e.g., NE dictionary,
part-of-speech tags), while it is another challenge to obtain such effective
resources. In this work, we propose a fully unsupervised NE recognition model
which only needs to take informative clues from pre-trained word embeddings. We
first apply Gaussian Hidden Markov Model and Deep Autoencoding Gaussian Mixture
Model on word embeddings for entity span detection and type prediction, and
then further design an instance selector based on reinforcement learning to
distinguish positive sentences from noisy sentences and refine these
coarse-grained annotations through neural networks. Extensive experiments on
CoNLL benchmark datasets demonstrate that our proposed light NE recognition
model achieves remarkable performance without using any annotated lexicon or
corpus.
</p>
<a href="http://arxiv.org/abs/1909.00164" target="_blank">arXiv:1909.00164</a> [<a href="http://arxiv.org/pdf/1909.00164" target="_blank">pdf</a>]

<h2>A Simple and Effective Model for Answering Multi-span Questions. (arXiv:1909.13375v4 [cs.CL] UPDATED)</h2>
<h3>Elad Segal, Avia Efrat, Mor Shoham, Amir Globerson, Jonathan Berant</h3>
<p>Models for reading comprehension (RC) commonly restrict their output space to
the set of all single contiguous spans from the input, in order to alleviate
the learning problem and avoid the need for a model that generates text
explicitly. However, forcing an answer to be a single span can be restrictive,
and some recent datasets also include multi-span questions, i.e., questions
whose answer is a set of non-contiguous spans in the text. Naturally, models
that return single spans cannot answer these questions. In this work, we
propose a simple architecture for answering multi-span questions by casting the
task as a sequence tagging problem, namely, predicting for each input token
whether it should be part of the output or not. Our model substantially
improves performance on span extraction questions from DROP and Quoref by 9.9
and 5.5 EM points respectively.
</p>
<a href="http://arxiv.org/abs/1909.13375" target="_blank">arXiv:1909.13375</a> [<a href="http://arxiv.org/pdf/1909.13375" target="_blank">pdf</a>]

<h2>Event-triggered Learning for Linear Quadratic Control. (arXiv:1910.07732v2 [eess.SY] UPDATED)</h2>
<h3>Henning Schl&#xfc;ter, Friedrich Solowjow, Sebastian Trimpe</h3>
<p>When models are inaccurate, the performance of model-based control will
degrade. For linear quadratic control, an event-triggered learning framework is
proposed that automatically detects inaccurate models and triggers the learning
of a new process model when needed. This is achieved by analyzing the
probability distribution of the linear quadratic cost and designing a learning
trigger that leverages Chernoff bounds. In particular, whenever empirically
observed cost signals are located outside the derived confidence intervals, we
can provably guarantee that this is with high probability due to a model
mismatch. With the aid of numerical and hardware experiments, we demonstrate
that the proposed bounds are tight and that the event-triggered learning
algorithm effectively distinguishes between inaccurate models and probabilistic
effects such as process noise. Thus, a structured approach is obtained that
decides when model learning is beneficial.
</p>
<a href="http://arxiv.org/abs/1910.07732" target="_blank">arXiv:1910.07732</a> [<a href="http://arxiv.org/pdf/1910.07732" target="_blank">pdf</a>]

<h2>Learning to Scaffold the Development of Robotic Manipulation Skills. (arXiv:1911.00969v3 [cs.RO] UPDATED)</h2>
<h3>Lin Shao, Toki Migimatsu, Jeannette Bohg</h3>
<p>Learning contact-rich, robotic manipulation skills is a challenging problem
due to the high-dimensionality of the state and action space as well as
uncertainty from noisy sensors and inaccurate motor control. To combat these
factors and achieve more robust manipulation, humans actively exploit contact
constraints in the environment. By adopting a similar strategy, robots can also
achieve more robust manipulation. In this paper, we enable a robot to
autonomously modify its environment and thereby discover how to ease
manipulation skill learning. Specifically, we provide the robot with fixtures
that it can freely place within the environment. These fixtures provide hard
constraints that limit the outcome of robot actions. Thereby, they funnel
uncertainty from perception and motor control and scaffold manipulation skill
learning. We propose a learning system that consists of two learning loops. In
the outer loop, the robot positions the fixture in the workspace. In the inner
loop, the robot learns a manipulation skill and after a fixed number of
episodes, returns the reward to the outer loop. Thereby, the robot is
incentivised to place the fixture such that the inner loop quickly achieves a
high reward. We demonstrate our framework both in simulation and in the real
world on three tasks: peg insertion, wrench manipulation and shallow-depth
insertion. We show that manipulation skill learning is dramatically sped up
through this way of scaffolding.
</p>
<a href="http://arxiv.org/abs/1911.00969" target="_blank">arXiv:1911.00969</a> [<a href="http://arxiv.org/pdf/1911.00969" target="_blank">pdf</a>]

<h2>Data Diversification: A Simple Strategy For Neural Machine Translation. (arXiv:1911.01986v4 [cs.CL] UPDATED)</h2>
<h3>Xuan-Phi Nguyen, Shafiq Joty, Wu Kui, Ai Ti Aw</h3>
<p>We introduce Data Diversification: a simple but effective strategy to boost
neural machine translation (NMT) performance. It diversifies the training data
by using the predictions of multiple forward and backward models and then
merging them with the original dataset on which the final NMT model is trained.
Our method is applicable to all NMT models. It does not require extra
monolingual data like back-translation, nor does it add more computations and
parameters like ensembles of models. Our method achieves state-of-the-art BLEU
scores of 30.7 and 43.7 in the WMT'14 English-German and English-French
translation tasks, respectively. It also substantially improves on 8 other
translation tasks: 4 IWSLT tasks (English-German and English-French) and 4
low-resource translation tasks (English-Nepali and English-Sinhala). We
demonstrate that our method is more effective than knowledge distillation and
dual learning, it exhibits strong correlation with ensembles of models, and it
trades perplexity off for better BLEU score. We have released our source code
at https://github.com/nxphi47/data_diversification
</p>
<a href="http://arxiv.org/abs/1911.01986" target="_blank">arXiv:1911.01986</a> [<a href="http://arxiv.org/pdf/1911.01986" target="_blank">pdf</a>]

<h2>The Threat of Adversarial Attacks on Machine Learning in Network Security -- A Survey. (arXiv:1911.02621v2 [cs.CR] UPDATED)</h2>
<h3>Olakunle Ibitoye, Rana Abou-Khamis, Ashraf Matrawy, M. Omair Shafiq</h3>
<p>Machine learning models have made many decision support systems to be faster,
more accurate and more efficient. However, applications of machine learning in
network security face more disproportionate threat of active adversarial
attacks compared to other domains. This is because machine learning
applications in network security such as malware detection, intrusion
detection, and spam filtering are by themselves adversarial in nature. In what
could be considered an arms race between attackers and defenders, adversaries
constantly probe machine learning systems with inputs which are explicitly
designed to bypass the system and induce a wrong prediction. In this survey, we
first provide a taxonomy of machine learning techniques, styles, and
algorithms. We then introduce a classification of machine learning in network
security applications. Next, we examine various adversarial attacks against
machine learning in network security and introduce two classification
approaches for adversarial attacks in network security. First, we classify
adversarial attacks in network security based on a taxonomy of network security
applications. Secondly, we categorize adversarial attacks in network security
into a problem space vs. feature space dimensional classification model. We
then analyze the various defenses against adversarial attacks on machine
learning-based network security applications. We conclude by introducing an
adversarial risk model and evaluate several existing adversarial attacks
against machine learning in network security using the risk model. We also
identify where each attack classification resides within the adversarial risk
model
</p>
<a href="http://arxiv.org/abs/1911.02621" target="_blank">arXiv:1911.02621</a> [<a href="http://arxiv.org/pdf/1911.02621" target="_blank">pdf</a>]

<h2>Time-Dynamic Estimates of the Reliability of Deep Semantic Segmentation Networks. (arXiv:1911.05075v2 [cs.CV] UPDATED)</h2>
<h3>Kira Maag, Matthias Rottmann, Hanno Gottschalk</h3>
<p>In the semantic segmentation of street scenes with neural networks, the
reliability of predictions is of highest interest. The assessment of neural
networks by means of uncertainties is a common ansatz to prevent safety issues.
As in applications like automated driving, video streams of images are
available, we present a time-dynamic approach to investigating uncertainties
and assessing the prediction quality of neural networks. We track segments over
time and gather aggregated metrics per segment, thus obtaining time series of
metrics from which we assess prediction quality. This is done by either
classifying between intersection over union equal to 0 and greater than 0 or
predicting the intersection over union directly. We study different models for
these two tasks and analyze the influence of the time series length on the
predictive power of our metrics.
</p>
<a href="http://arxiv.org/abs/1911.05075" target="_blank">arXiv:1911.05075</a> [<a href="http://arxiv.org/pdf/1911.05075" target="_blank">pdf</a>]

<h2>Density-based Object Detection: Learning Bounding Boxes without Ground Truth Assignment. (arXiv:1911.12721v3 [cs.CV] UPDATED)</h2>
<h3>Jaeyoung Yoo, Hojun Lee, Inseop Chung, Geonseok Seo, Nojun Kwak</h3>
<p>In multi-object detection using neural networks, most methods train a network
based on ground truth assignment, which makes the training too heuristic and
complicated. In this paper, we reformulate the multi-object detection task as a
problem of density estimation of bounding boxes. Instead of using a
ground-truth-assignment-based method, we train a network by estimating the
probability density of bounding boxes in an input image using a mixture model.
For this purpose, we propose a novel network for object detection called
Mixture Density Object Detector (MDOD), and the corresponding objective
function for the density-estimation-based training. Unlike the
ground-truth-assignment-based methods, our proposed method gets rid of the
cumbersome processes of matching between ground truth boxes and their
predictions as well as the heuristic anchor design. It is also free from the
problem of foreground-background imbalance. We applied MDOD to MS COCO dataset.
Our proposed method not only deals with multi-object detection problems in a
new approach, but also improves detection performances through MDOD. Code will
be available.
</p>
<a href="http://arxiv.org/abs/1911.12721" target="_blank">arXiv:1911.12721</a> [<a href="http://arxiv.org/pdf/1911.12721" target="_blank">pdf</a>]

<h2>Towards Understanding the Spectral Bias of Deep Learning. (arXiv:1912.01198v3 [cs.LG] UPDATED)</h2>
<h3>Yuan Cao, Zhiying Fang, Yue Wu, Ding-Xuan Zhou, Quanquan Gu</h3>
<p>An intriguing phenomenon observed during training neural networks is the
spectral bias, which states that neural networks are biased towards learning
less complex functions. The priority of learning functions with low complexity
might be at the core of explaining generalization ability of neural network,
and certain efforts have been made to provide theoretical explanation for
spectral bias. However, there is still no satisfying theoretical result
justifying the underlying mechanism of spectral bias. In this paper, we give a
comprehensive and rigorous explanation for spectral bias and relate it with the
neural tangent kernel function proposed in recent work. We prove that the
training process of neural networks can be decomposed along different
directions defined by the eigenfunctions of the neural tangent kernel, where
each direction has its own convergence rate and the rate is determined by the
corresponding eigenvalue. We then provide a case study when the input data is
uniformly distributed over the unit sphere, and show that lower degree
spherical harmonics are easier to be learned by over-parameterized neural
networks. Finally, we provide numerical experiments to demonstrate the
correctness of our theory. Our experimental results also show that our theory
can tolerate certain model misspecification in terms of the input data
distribution.
</p>
<a href="http://arxiv.org/abs/1912.01198" target="_blank">arXiv:1912.01198</a> [<a href="http://arxiv.org/pdf/1912.01198" target="_blank">pdf</a>]

<h2>Learning to Reach Goals via Iterated Supervised Learning. (arXiv:1912.06088v4 [cs.LG] UPDATED)</h2>
<h3>Dibya Ghosh, Abhishek Gupta, Ashwin Reddy, Justin Fu, Coline Devin, Benjamin Eysenbach, Sergey Levine</h3>
<p>Current reinforcement learning (RL) algorithms can be brittle and difficult
to use, especially when learning goal-reaching behaviors from sparse rewards.
Although supervised imitation learning provides a simple and stable
alternative, it requires access to demonstrations from a human supervisor. In
this paper, we study RL algorithms that use imitation learning to acquire goal
reaching policies from scratch, without the need for expert demonstrations or a
value function. In lieu of demonstrations, we leverage the property that any
trajectory is a successful demonstration for reaching the final state in that
same trajectory. We propose a simple algorithm in which an agent continually
relabels and imitates the trajectories it generates to progressively learn
goal-reaching behaviors from scratch. Each iteration, the agent collects new
trajectories using the latest policy, and maximizes the likelihood of the
actions along these trajectories under the goal that was actually reached, so
as to improve the policy. We formally show that this iterated supervised
learning procedure optimizes a bound on the RL objective, derive performance
bounds of the learned policy, and empirically demonstrate improved
goal-reaching performance and robustness over current RL algorithms in several
benchmark tasks.
</p>
<a href="http://arxiv.org/abs/1912.06088" target="_blank">arXiv:1912.06088</a> [<a href="http://arxiv.org/pdf/1912.06088" target="_blank">pdf</a>]

<h2>Theme-Matters: Fashion Compatibility Learning via Theme Attention. (arXiv:1912.06227v3 [cs.CV] UPDATED)</h2>
<h3>Jui-Hsin Lai, Bo Wu, Xin Wang, Dan Zeng, Tao Mei, Jingen Liu</h3>
<p>Fashion compatibility learning is important to many fashion markets such as
outfit composition and online fashion recommendation. Unlike previous work, we
argue that fashion compatibility is not only a visual appearance compatible
problem but also a theme-matters problem. An outfit, which consists of a set of
fashion items (e.g., shirt, suit, shoes, etc.), is considered to be compatible
for a "dating" event, yet maybe not for a "business" occasion. In this paper,
we aim at solving the fashion compatibility problem given specific themes. To
this end, we built the first real-world theme-aware fashion dataset comprising
14K around outfits labeled with 32 themes. In this dataset, there are more than
40K fashion items labeled with 152 fine-grained categories. We also propose an
attention model learning fashion compatibility given a specific theme. It
starts with a category-specific subspace learning, which projects compatible
outfit items in certain categories to be close in the subspace. Thanks to
strong connections between fashion themes and categories, we then build a
theme-attention model over the category-specific embedding space. This model
associates themes with the pairwise compatibility with attention, and thus
compute the outfit-wise compatibility. To the best of our knowledge, this is
the first attempt to estimate outfit compatibility conditional on a theme. We
conduct extensive qualitative and quantitative experiments on our new dataset.
Our method outperforms the state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/1912.06227" target="_blank">arXiv:1912.06227</a> [<a href="http://arxiv.org/pdf/1912.06227" target="_blank">pdf</a>]

<h2>Deep Graph Similarity Learning: A Survey. (arXiv:1912.11615v2 [cs.LG] UPDATED)</h2>
<h3>Guixiang Ma, Nesreen K. Ahmed, Theodore L. Willke, Philip S. Yu</h3>
<p>In many domains where data are represented as graphs, learning a similarity
metric among graphs is considered a key problem, which can further facilitate
various learning tasks, such as classification, clustering, and similarity
search. Recently, there has been an increasing interest in deep graph
similarity learning, where the key idea is to learn a deep learning model that
maps input graphs to a target space such that the distance in the target space
approximates the structural distance in the input space. Here, we provide a
comprehensive review of the existing literature of deep graph similarity
learning. We propose a systematic taxonomy for the methods and applications.
Finally, we discuss the challenges and future directions for this problem.
</p>
<a href="http://arxiv.org/abs/1912.11615" target="_blank">arXiv:1912.11615</a> [<a href="http://arxiv.org/pdf/1912.11615" target="_blank">pdf</a>]

<h2>Alpha Discovery Neural Network based on Prior Knowledge. (arXiv:1912.11761v6 [q-fin.ST] UPDATED)</h2>
<h3>Jie Fang, Shutao Xia, Jianwu Lin, Zhikang Xia, Xiang Liu, Yong Jiang</h3>
<p>Genetic programming (GP) is the state-of-the-art in financial automated
feature construction task. It employs reverse polish expression to represent
features and then conducts the evolution process. However, with the development
of deep learning, more powerful feature extraction tools are available. This
paper proposes Alpha Discovery Neural Network (ADNN), a tailored neural network
structure which can automatically construct diversified financial technical
indicators based on prior knowledge. We mainly made three contributions. First,
we use domain knowledge in quantitative trading to design the sampling rules
and object function. Second, pre-training and model pruning has been used to
replace genetic programming, because it can conduct more efficient evolution
process. Third, the feature extractors in ADNN can be replaced by different
feature extractors and produce different functions. The experiment results show
that ADNN can construct more informative and diversified features than GP,
which can effectively enriches the current factor pool. The fully-connected
network and recurrent network are better at extracting information from the
financial time series than the convolution neural network. In real practice,
features constructed by ADNN can always improve multi-factor strategies'
revenue, sharpe ratio, and max draw-down, compared with the investment
strategies without these factors.
</p>
<a href="http://arxiv.org/abs/1912.11761" target="_blank">arXiv:1912.11761</a> [<a href="http://arxiv.org/pdf/1912.11761" target="_blank">pdf</a>]

<h2>Sparse Weight Activation Training. (arXiv:2001.01969v2 [cs.LG] UPDATED)</h2>
<h3>Md Aamir Raihan, Tor M. Aamodt</h3>
<p>Neural network training is computationally and memory intensive. Sparse
training can reduce the burden on emerging hardware platforms designed to
accelerate sparse computations, but it can affect network convergence. In this
work, we propose a novel CNN training algorithm Sparse Weight Activation
Training (SWAT). SWAT is more computation and memory-efficient than
conventional training. SWAT modifies back-propagation based on the empirical
insight that convergence during training tends to be robust to the elimination
of (i) small magnitude weights during the forward pass and (ii) both small
magnitude weights and activations during the backward pass. We evaluate SWAT on
recent CNN architectures such as ResNet, VGG, DenseNet and WideResNet using
CIFAR-10, CIFAR-100 and ImageNet datasets. For ResNet-50 on ImageNet SWAT
reduces total floating-point operations (FLOPS) during training by 80%
resulting in a 3.3$\times$ training speedup when run on a simulated sparse
learning accelerator representative of emerging platforms while incurring only
1.63% reduction in validation accuracy. Moreover, SWAT reduces memory footprint
during the backward pass by 23% to 50% for activations and 50% to 90% for
weights.
</p>
<a href="http://arxiv.org/abs/2001.01969" target="_blank">arXiv:2001.01969</a> [<a href="http://arxiv.org/pdf/2001.01969" target="_blank">pdf</a>]

<h2>Learning credit assignment. (arXiv:2001.03354v2 [cs.LG] UPDATED)</h2>
<h3>Chan Li, Haiping Huang</h3>
<p>Deep learning has achieved impressive prediction accuracies in a variety of
scientific and industrial domains. However, the nested non-linear feature of
deep learning makes the learning highly non-transparent, i.e., it is still
unknown how the learning coordinates a huge number of parameters to achieve a
decision making. To explain this hierarchical credit assignment, we propose a
mean-field learning model by assuming that an ensemble of sub-networks, rather
than a single network, are trained for a classification task. Surprisingly, our
model reveals that apart from some deterministic synaptic weights connecting
two neurons at neighboring layers, there exist a large number of connections
that can be absent, and other connections can allow for a broad distribution of
their weight values. Therefore, synaptic connections can be classified into
three categories: very important ones, unimportant ones, and those of
variability that may partially encode nuisance factors. Therefore, our model
learns the credit assignment leading to the decision, and predicts an ensemble
of sub-networks that can accomplish the same task, thereby providing insights
toward understanding the macroscopic behavior of deep learning through the lens
of distinct roles of synaptic weights.
</p>
<a href="http://arxiv.org/abs/2001.03354" target="_blank">arXiv:2001.03354</a> [<a href="http://arxiv.org/pdf/2001.03354" target="_blank">pdf</a>]

<h2>A Multi-site Study of a Breast Density Deep Learning Model for Full-field Digital Mammography Images and Synthetic Mammography Images. (arXiv:2001.08383v2 [eess.IV] UPDATED)</h2>
<h3>Thomas P. Matthews (1), Sadanand Singh (1), Brent Mombourquette (1), Jason Su (1), Meet P. Shah (1), Stefano Pedemonte (1), Aaron Long (1), David Maffit (2), Jenny Gurney (2), Rodrigo Morales Hoil (1), Nikita Ghare (1), Douglas Smith (1), Stephen M. Moore (2), Susan C. Marks (3), Richard L. Wahl (2), ((1) Whiterabbit AI, Inc., Santa Clara, CA, (2) Mallinckrodt Institute of Radiology, Washington University School of Medicine, St. Louis, MO, (3) Peninsula Diagnostic Imaging, San Mateo, CA)</h3>
<p>Purpose: To develop a Breast Imaging Reporting and Data System (BI-RADS)
breast density deep learning (DL) model in a multi-site setting for synthetic
two-dimensional mammography (SM) images derived from digital breast
tomosynthesis exams using full-field digital mammography (FFDM) images and
limited SM data.

Materials and Methods: A DL model was trained to predict BI-RADS breast
density using FFDM images acquired from 2008 to 2017 (Site 1: 57492 patients,
187627 exams, 750752 images) for this retrospective study. The FFDM model was
evaluated using SM datasets from two institutions (Site 1: 3842 patients, 3866
exams, 14472 images, acquired from 2016 to 2017; Site 2: 7557 patients, 16283
exams, 63973 images, 2015 to 2019). Each of the three datasets were then split
into training, validation, and test datasets. Adaptation methods were
investigated to improve performance on the SM datasets and the effect of
dataset size on each adaptation method is considered. Statistical significance
was assessed using confidence intervals (CI), estimated by bootstrapping.

Results: Without adaptation, the model demonstrated substantial agreement
with the original reporting radiologists for all three datasets (Site 1 FFDM:
linearly-weighted $\kappa_w$ = 0.75 [95% CI: 0.74, 0.76]; Site 1 SM: $\kappa_w$
= 0.71 [95% CI: 0.64, 0.78]; Site 2 SM: $\kappa_w$ = 0.72 [95% CI: 0.70,
0.75]). With adaptation, performance improved for Site 2 (Site 1: $\kappa_w$ =
0.72 [95% CI: 0.66, 0.79], 0.71 vs 0.72, P = .80; Site 2: $\kappa_w$ = 0.79
[95% CI: 0.76, 0.81], 0.72 vs 0.79, P $&lt;$ .001) using only 500 SM images from
that site.

Conclusion: A BI-RADS breast density DL model demonstrated strong performance
on FFDM and SM images from two institutions without training on SM images and
improved using few SM images.
</p>
<a href="http://arxiv.org/abs/2001.08383" target="_blank">arXiv:2001.08383</a> [<a href="http://arxiv.org/pdf/2001.08383" target="_blank">pdf</a>]

<h2>Concept Whitening for Interpretable Image Recognition. (arXiv:2002.01650v3 [cs.LG] UPDATED)</h2>
<h3>Zhi Chen, Yijie Bei, Cynthia Rudin</h3>
<p>What does a neural network encode about a concept as we traverse through the
layers? Interpretability in machine learning is undoubtedly important, but the
calculations of neural networks are very challenging to understand. Attempts to
see inside their hidden layers can either be misleading, unusable, or rely on
the latent space to possess properties that it may not have. In this work,
rather than attempting to analyze a neural network posthoc, we introduce a
mechanism, called \textit{concept whitening} (CW), to alter a given layer of
the network to allow us to better understand the computation leading up to that
layer. When a concept whitening module is added to a CNN, the axes of the
latent space are aligned with known concepts of interest. By experiment, we
show that CW can provide us a much clearer understanding for how the network
gradually learns concepts over layers. CW is an alternative to a batch
normalization layer in that it normalizes, and also decorrelates (whitens) the
latent space. CW can be used in any layer of the network without hurting
predictive performance.
</p>
<a href="http://arxiv.org/abs/2002.01650" target="_blank">arXiv:2002.01650</a> [<a href="http://arxiv.org/pdf/2002.01650" target="_blank">pdf</a>]

<h2>Quasi-Equivalence of Width and Depth of Neural Networks. (arXiv:2002.02515v5 [cs.LG] UPDATED)</h2>
<h3>Feng-Lei Fan, Rongjie Lai, Ge Wang</h3>
<p>While classic studies proved that wide networks allow universal
approximation, recent research and successes of deep learning demonstrate the
power of the network depth. Based on a symmetric consideration, we investigate
if the design of artificial neural networks should have a directional
preference, and what the mechanism of interaction is between the width and
depth of a network. We address this fundamental question by establishing a
quasi-equivalence between the width and depth of ReLU networks. Specifically,
we formulate a transformation from an arbitrary ReLU network to a wide network
and a deep network for either regression or classification so that an
essentially same capability of the original network can be implemented. That
is, a deep regression/classification ReLU network has a wide equivalent, and
vice versa, subject to an arbitrarily small error. Interestingly, the
quasi-equivalence between wide and deep classification ReLU networks is a
data-driven version of the De Morgan law.
</p>
<a href="http://arxiv.org/abs/2002.02515" target="_blank">arXiv:2002.02515</a> [<a href="http://arxiv.org/pdf/2002.02515" target="_blank">pdf</a>]

<h2>BERT-of-Theseus: Compressing BERT by Progressive Module Replacing. (arXiv:2002.02925v4 [cs.CL] UPDATED)</h2>
<h3>Canwen Xu, Wangchunshu Zhou, Tao Ge, Furu Wei, Ming Zhou</h3>
<p>In this paper, we propose a novel model compression approach to effectively
compress BERT by progressive module replacing. Our approach first divides the
original BERT into several modules and builds their compact substitutes. Then,
we randomly replace the original modules with their substitutes to train the
compact modules to mimic the behavior of the original modules. We progressively
increase the probability of replacement through the training. In this way, our
approach brings a deeper level of interaction between the original and compact
models. Compared to the previous knowledge distillation approaches for BERT
compression, our approach does not introduce any additional loss function. Our
approach outperforms existing knowledge distillation approaches on GLUE
benchmark, showing a new perspective of model compression.
</p>
<a href="http://arxiv.org/abs/2002.02925" target="_blank">arXiv:2002.02925</a> [<a href="http://arxiv.org/pdf/2002.02925" target="_blank">pdf</a>]

<h2>Estimating Uncertainty Intervals from Collaborating Networks. (arXiv:2002.05212v2 [stat.ML] UPDATED)</h2>
<h3>Tianhui Zhou, Yitong Li, Yuan Wu, David Carlson</h3>
<p>Effective decision making requires understanding the uncertainty inherent in
a prediction. To estimate uncertainty in regression, one could modify a deep
neural network to predict coverage intervals, such as by predicting the mean
and standard deviation. Unfortunately, in our empirical evaluations the
predicted coverage from existing approaches is either overconfident or lacks
sharpness (gives imprecise intervals). To address this challenge, we propose a
novel method to estimate uncertainty based on two distinct neural networks with
two distinct loss functions in a similar vein to Generative Adversarial
Networks. Specifically, one network tries to learn the cumulative distribution
function, and the second network tries to learn its inverse. Theoretical
analysis demonstrates that the idealized solution is a fixed point and that
under certain conditions the approach is asymptotically consistent to ground
truth. We benchmark the approach on one synthetic and five real-world datasets,
including forecasting A1c values in diabetic patients from electronic health
records, where uncertainty is critical. In synthetic data, the proposed
approach essentially matches the theoretically optimal solution in all aspects.
In the real datasets, the proposed approach is empirically more faithful in its
coverage estimates and typically gives sharper intervals than competing
methods.
</p>
<a href="http://arxiv.org/abs/2002.05212" target="_blank">arXiv:2002.05212</a> [<a href="http://arxiv.org/pdf/2002.05212" target="_blank">pdf</a>]

<h2>Convolutional Tensor-Train LSTM for Spatio-temporal Learning. (arXiv:2002.09131v5 [cs.LG] UPDATED)</h2>
<h3>Jiahao Su, Wonmin Byeon, Jean Kossaifi, Furong Huang, Jan Kautz, Animashree Anandkumar</h3>
<p>Learning from spatio-temporal data has numerous applications such as
human-behavior analysis, object tracking, video compression, and physics
simulation.However, existing methods still perform poorly on challenging video
tasks such as long-term forecasting. This is because these kinds of challenging
tasks require learning long-term spatio-temporal correlations in the video
sequence. In this paper, we propose a higher-order convolutional LSTM model
that can efficiently learn these correlations, along with a succinct
representations of the history. This is accomplished through a novel tensor
train module that performs prediction by combining convolutional features
across time. To make this feasible in terms of computation and memory
requirements, we propose a novel convolutional tensor-train decomposition of
the higher-order model. This decomposition reduces the model complexity by
jointly approximating a sequence of convolutional kernels asa low-rank
tensor-train factorization. As a result, our model outperforms existing
approaches, but uses only a fraction of parameters, including the baseline
models.Our results achieve state-of-the-art performance in a wide range of
applications and datasets, including the multi-steps video prediction on the
Moving-MNIST-2and KTH action datasets as well as early activity recognition on
the Something-Something V2 dataset.
</p>
<a href="http://arxiv.org/abs/2002.09131" target="_blank">arXiv:2002.09131</a> [<a href="http://arxiv.org/pdf/2002.09131" target="_blank">pdf</a>]

<h2>Revealing the Structure of Deep Neural Networks via Convex Duality. (arXiv:2002.09773v2 [cs.LG] UPDATED)</h2>
<h3>Tolga Ergen, Mert Pilanci</h3>
<p>We study regularized deep neural networks (DNNs) and introduce a convex
analytic framework to characterize the structure of the hidden layers. We show
that a set of optimal hidden layer weights for a norm regularized DNN training
problem can be explicitly found as the extreme points of a convex set. For the
special case of deep linear networks with $K$ outputs, we prove that each
optimal weight matrix is rank-$K$ and aligns with the previous layers via
duality. More importantly, we apply the same characterization to deep ReLU
networks with whitened data and prove the same weight alignment holds. As a
corollary, we prove that norm regularized deep ReLU networks yield spline
interpolation for one-dimensional datasets which was previously known only for
two-layer networks. Furthermore, we provide closed-form solutions for the
optimal layer weights when data is rank-one or whitened. We then verify our
theory via numerical experiments.
</p>
<a href="http://arxiv.org/abs/2002.09773" target="_blank">arXiv:2002.09773</a> [<a href="http://arxiv.org/pdf/2002.09773" target="_blank">pdf</a>]

<h2>Zero-Shot Cross-Lingual Transfer with Meta Learning. (arXiv:2003.02739v4 [cs.CL] UPDATED)</h2>
<h3>Farhad Nooralahzadeh, Giannis Bekoulis, Johannes Bjerva, Isabelle Augenstein</h3>
<p>Learning what to share between tasks has been a topic of great importance
recently, as strategic sharing of knowledge has been shown to improve
downstream task performance. This is particularly important for multilingual
applications, as most languages in the world are under-resourced. Here, we
consider the setting of training models on multiple different languages at the
same time, when little or no data is available for languages other than
English. We show that this challenging setup can be approached using
meta-learning, where, in addition to training a source language model, another
model learns to select which training instances are the most beneficial to the
first. We experiment using standard supervised, zero-shot cross-lingual, as
well as few-shot cross-lingual settings for different natural language
understanding tasks (natural language inference, question answering). Our
extensive experimental setup demonstrates the consistent effectiveness of
meta-learning for a total of 15 languages. We improve upon the state-of-the-art
for zero-shot and few-shot NLI (on MultiNLI and XNLI) and QA (on the MLQA
dataset). A comprehensive error analysis indicates that the correlation of
typological features between languages can partly explain when parameter
sharing learned via meta-learning is beneficial.
</p>
<a href="http://arxiv.org/abs/2003.02739" target="_blank">arXiv:2003.02739</a> [<a href="http://arxiv.org/pdf/2003.02739" target="_blank">pdf</a>]

<h2>Adaptive Discretization for Continuous Control using Particle Filtering Policy Network. (arXiv:2003.06959v2 [cs.LG] UPDATED)</h2>
<h3>Pei Xu, Ioannis Karamouzas</h3>
<p>Controlling the movements of highly articulated agents and robots has been a
long-standing challenge to model-free deep reinforcement learning. In this
paper, we propose a simple, yet general, framework for improving the
performance of policy gradient algorithms by discretizing the continuous action
space. Instead of using a fixed set of predetermined atomic actions, we exploit
particle filtering to adaptively discretize actions during training and track
the posterior policy distribution represented as a mixture of Gaussians. The
resulting policy can replace the original continuous policy of any given policy
gradient algorithm without changing its underlying model architecture. We
demonstrate the applicability of our approach to state-of-the-art on-policy and
off-policy baselines in challenging control tasks. Baselines using our
particle-based policies achieve better final performance and speed of
convergence as compared to corresponding continuous implementations and
implementations that rely on fixed discretization schemes.
</p>
<a href="http://arxiv.org/abs/2003.06959" target="_blank">arXiv:2003.06959</a> [<a href="http://arxiv.org/pdf/2003.06959" target="_blank">pdf</a>]

<h2>Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images and Deep Convolutional Neural Networks. (arXiv:2003.10849v3 [eess.IV] UPDATED)</h2>
<h3>Ali Narin, Ceren Kaya, Ziynet Pamuk</h3>
<p>The 2019 novel coronavirus disease (COVID-19), with a starting point in
China, has spread rapidly among people living in other countries, and is
approaching approximately 34,986,502 cases worldwide according to the
statistics of European Centre for Disease Prevention and Control. There are a
limited number of COVID-19 test kits available in hospitals due to the
increasing cases daily. Therefore, it is necessary to implement an automatic
detection system as a quick alternative diagnosis option to prevent COVID-19
spreading among people. In this study, five pre-trained convolutional neural
network based models (ResNet50, ResNet101, ResNet152, InceptionV3 and
Inception-ResNetV2) have been proposed for the detection of coronavirus
pneumonia infected patient using chest X-ray radiographs. We have implemented
three different binary classifications with four classes (COVID-19, normal
(healthy), viral pneumonia and bacterial pneumonia) by using 5-fold cross
validation. Considering the performance results obtained, it has seen that the
pre-trained ResNet50 model provides the highest classification performance
(96.1% accuracy for Dataset-1, 99.5% accuracy for Dataset-2 and 99.7% accuracy
for Dataset-3) among other four used models.
</p>
<a href="http://arxiv.org/abs/2003.10849" target="_blank">arXiv:2003.10849</a> [<a href="http://arxiv.org/pdf/2003.10849" target="_blank">pdf</a>]

<h2>Interpretable Approach in the Classification of Sequences of Legal Texts. (arXiv:2003.11561v2 [cs.CL] UPDATED)</h2>
<h3>Felipe Maia Polo, Itamar Ciochetti, Emerson Bertolo</h3>
<p>Machine learning applications in the legal field are numerous and diverse. In
order to make contribution to both the machine learning community and the legal
community, we have made efforts to create a model compatible with the
classification of text sequences, valuing the interpretability of the results.
The purpose of this paper is to classify Brazilian legal proceedings in three
possible status classes, which are (i) archived proceedings, (ii) active
proceedings and (iii) suspended proceedings. Although working with portuguese
NLP, which can be hard due to lack of resources, our approach performed
remarkably well in the classification task. Furthermore, we were able to
extract and interpret the patterns learnt by the neural network besides
quantifying how those patterns relate to the classification task.
</p>
<a href="http://arxiv.org/abs/2003.11561" target="_blank">arXiv:2003.11561</a> [<a href="http://arxiv.org/pdf/2003.11561" target="_blank">pdf</a>]

<h2>Can Machine Learning Be Used to Recognize and Diagnose Coughs?. (arXiv:2004.01495v3 [eess.AS] UPDATED)</h2>
<h3>Charles Bales, Muhammad Nabeel, Charles N. John, Usama Masood, Haneya N. Qureshi, Hasan Farooq, Iryna Posokhova, Ali Imran</h3>
<p>Emerging wireless technologies, such as 5G and beyond, are bringing new use
cases to the forefront, one of the most prominent being machine learning
empowered health care. One of the notable modern medical concerns that impose
an immense worldwide health burden are respiratory infections. Since cough is
an essential symptom of many respiratory infections, an automated system to
screen for respiratory diseases based on raw cough data would have a multitude
of beneficial research and medical applications. In literature, machine
learning has already been successfully used to detect cough events in
controlled environments. In this paper, we present a low complexity, automated
recognition and diagnostic tool for screening respiratory infections that
utilizes Convolutional Neural Networks (CNNs) to detect cough within
environment audio and diagnose three potential illnesses (i.e., bronchitis,
bronchiolitis and pertussis) based on their unique cough audio features. Both
proposed detection and diagnosis models achieve an accuracy of over 89%, while
also remaining computationally efficient. Results show that the proposed system
is successfully able to detect and separate cough events from background noise.
Moreover, the proposed single diagnosis model is capable of distinguishing
between different illnesses without the need of separate models.
</p>
<a href="http://arxiv.org/abs/2004.01495" target="_blank">arXiv:2004.01495</a> [<a href="http://arxiv.org/pdf/2004.01495" target="_blank">pdf</a>]

<h2>Sub-Instruction Aware Vision-and-Language Navigation. (arXiv:2004.02707v2 [cs.CV] UPDATED)</h2>
<h3>Yicong Hong, Cristian Rodriguez-Opazo, Qi Wu, Stephen Gould</h3>
<p>Vision-and-language navigation requires an agent to navigate through a real
3D environment following natural language instructions. Despite significant
advances, few previous works are able to fully utilize the strong
correspondence between the visual and textual sequences. Meanwhile, due to the
lack of intermediate supervision, the agent's performance at following each
part of the instruction cannot be assessed during navigation. In this work, we
focus on the granularity of the visual and language sequences as well as the
traceability of agents through the completion of an instruction. We provide
agents with fine-grained annotations during training and find that they are
able to follow the instruction better and have a higher chance of reaching the
target at test time. We enrich the benchmark dataset Room-to-Room (R2R) with
sub-instructions and their corresponding paths. To make use of this data, we
propose effective sub-instruction attention and shifting modules that select
and attend to a single sub-instruction at each time-step. We implement our
sub-instruction modules in four state-of-the-art agents, compare with their
baseline models, and show that our proposed method improves the performance of
all four agents.

We release the Fine-Grained R2R dataset (FGR2R) and the code at
https://github.com/YicongHong/Fine-Grained-R2R.
</p>
<a href="http://arxiv.org/abs/2004.02707" target="_blank">arXiv:2004.02707</a> [<a href="http://arxiv.org/pdf/2004.02707" target="_blank">pdf</a>]

<h2>Energy Shaping Control of a CyberOctopus Soft Arm. (arXiv:2004.05747v2 [eess.SY] UPDATED)</h2>
<h3>Heng-Sheng Chang, Udit Halder, Chia-Hsien Shih, Arman Tekinalp, Tejaswin Parthasarathy, Ekaterina Gribkova, Girish Chowdhary, Rhanor Gillette, Mattia Gazzola, Prashant G. Mehta</h3>
<p>This paper entails application of the energy shaping methodology to control a
flexible, elastic Cosserat rod model. Recent interest in such continuum models
stems from applications in soft robotics, and from the growing recognition of
the role of mechanics and embodiment in biological control strategies:
octopuses are often regarded as iconic examples of this interplay. Here, the
dynamics of the Cosserat rod, modeling a single octopus arm, are treated as a
Hamiltonian system and the internal muscle actuators are modeled as distributed
forces and couples. The proposed energy shaping control design procedure
involves two steps: (1) a potential energy is designed such that its minimizer
is the desired equilibrium configuration; (2) an energy shaping control law is
implemented to reach the desired equilibrium. By interpreting the controlled
Hamiltonian as a Lyapunov function, asymptotic stability of the equilibrium
configuration is deduced. The energy shaping control law is shown to require
only the deformations of the equilibrium configuration. A forward-backward
algorithm is proposed to compute these deformations in an online iterative
manner. The overall control design methodology is implemented and demonstrated
in a dynamic simulation environment. Results of several bio-inspired numerical
experiments involving the control of octopus arms are reported.
</p>
<a href="http://arxiv.org/abs/2004.05747" target="_blank">arXiv:2004.05747</a> [<a href="http://arxiv.org/pdf/2004.05747" target="_blank">pdf</a>]

<h2>AmbigQA: Answering Ambiguous Open-domain Questions. (arXiv:2004.10645v2 [cs.CL] UPDATED)</h2>
<h3>Sewon Min, Julian Michael, Hannaneh Hajishirzi, Luke Zettlemoyer</h3>
<p>Ambiguity is inherent to open-domain question answering; especially when
exploring new topics, it can be difficult to ask questions that have a single,
unambiguous answer. In this paper, we introduce AmbigQA, a new open-domain
question answering task which involves finding every plausible answer, and then
rewriting the question for each one to resolve the ambiguity. To study this
task, we construct AmbigNQ, a dataset covering 14,042 questions from NQ-open,
an existing open-domain QA benchmark. We find that over half of the questions
in NQ-open are ambiguous, with diverse sources of ambiguity such as event and
entity references. We also present strong baseline models for AmbigQA which we
show benefit from weakly supervised learning that incorporates NQ-open,
strongly suggesting our new task and data will support significant future
research effort. Our data and baselines are available at
https://nlp.cs.washington.edu/ambigqa.
</p>
<a href="http://arxiv.org/abs/2004.10645" target="_blank">arXiv:2004.10645</a> [<a href="http://arxiv.org/pdf/2004.10645" target="_blank">pdf</a>]

<h2>Classifying Image Sequences of Astronomical Transients with Deep Neural Networks. (arXiv:2004.13877v2 [astro-ph.IM] UPDATED)</h2>
<h3>Catalina G&#xf3;mez, Mauricio Neira, Marcela Hern&#xe1;ndez Hoyos, Pablo Arbel&#xe1;ez, Jaime E. Forero-Romero</h3>
<p>Supervised classification of temporal sequences of astronomical images into
meaningful transient astrophysical phenomena has been considered a hard problem
because it requires the intervention of human experts. The classifier uses the
expert's knowledge to find heuristic features to process the images, for
instance, by performing image subtraction or by extracting sparse information
such as flux time series, also known as light curves. We present a successful
deep learning approach that learns directly from imaging data. Our method
models explicitly the spatio-temporal patterns with Deep Convolutional Neural
Networks and Gated Recurrent Units. We train these deep neural networks using
1.3 million real astronomical images from the Catalina Real-Time Transient
Survey to classify the sequences into five different types of astronomical
transient classes. The TAO-Net (for Transient Astronomical Objects Network)
architecture outperforms the results from random forest classification on light
curves by 10 percentage points as measured by the F1 score for each class; the
average F1 over classes goes from $45\%$ with random forest classification to
$55\%$ with TAO-Net. This achievement with TAO-Net opens the possibility to
develop new deep learning architectures for early transient detection. We make
available the training dataset and trained models of TAO-Net to allow for
future extensions of this work.
</p>
<a href="http://arxiv.org/abs/2004.13877" target="_blank">arXiv:2004.13877</a> [<a href="http://arxiv.org/pdf/2004.13877" target="_blank">pdf</a>]

<h2>Complementing Lexical Retrieval with Semantic Residual Embedding. (arXiv:2004.13969v2 [cs.IR] UPDATED)</h2>
<h3>Luyu Gao, Zhuyun Dai, Tongfei Chen, Zhen Fan, Benjamin Van Durme, Jamie Callan</h3>
<p>This paper presents DualRM, a Dual Retrieval Model that seeks to complement
lexical retrieval with neural embedding retrieval. DualRM uses a residual-based
embedding learning method, forcing the embedding to encode language structures
and semantics that lexical retrieval fails to capture. Empirical evaluation
demonstrates the advantages of DualRM over various lexical retrieval models and
a BERT-based embedding retrieval model, substantially narrowing the gap between
full-collection retrieval and costly reranking systems. We also provide results
showing how DualRM can be used in a zero-shot setting to build a strong
retrieval system for COVID-19 papers in the CORD-19 corpus.
</p>
<a href="http://arxiv.org/abs/2004.13969" target="_blank">arXiv:2004.13969</a> [<a href="http://arxiv.org/pdf/2004.13969" target="_blank">pdf</a>]

<h2>Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis. (arXiv:2004.14198v2 [cs.CL] UPDATED)</h2>
<h3>Yao-Hung Hubert Tsai, Martin Q. Ma, Muqiao Yang, Ruslan Salakhutdinov, Louis-Philippe Morency</h3>
<p>The human language can be expressed through multiple sources of information
known as modalities, including tones of voice, facial gestures, and spoken
language. Recent multimodal learning with strong performances on human-centric
tasks such as sentiment analysis and emotion recognition are often black-box,
with very limited interpretability. In this paper we propose Multimodal
Routing, which dynamically adjusts weights between input modalities and output
representations differently for each input sample. Multimodal routing can
identify relative importance of both individual modalities and cross-modality
features. Moreover, the weight assignment by routing allows us to interpret
modality-prediction relationships not only globally (i.e. general trends over
the whole dataset), but also locally for each single input sample, meanwhile
keeping competitive performance compared to state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2004.14198" target="_blank">arXiv:2004.14198</a> [<a href="http://arxiv.org/pdf/2004.14198" target="_blank">pdf</a>]

<h2>Leveraging Declarative Knowledge in Text and First-Order Logic for Fine-Grained Propaganda Detection. (arXiv:2004.14201v2 [cs.CL] UPDATED)</h2>
<h3>Ruize Wang, Duyu Tang, Nan Duan, Wanjun Zhong, Zhongyu Wei, Xuanjing Huang, Daxin Jiang, Ming Zhou</h3>
<p>We study the detection of propagandistic text fragments in news articles.
Instead of merely learning from input-output datapoints in training data, we
introduce an approach to inject declarative knowledge of fine-grained
propaganda techniques. Specifically, we leverage the declarative knowledge
expressed in both first-order logic and natural language. The former refers to
the logical consistency between coarse- and fine-grained predictions, which is
used to regularize the training process with propositional Boolean expressions.
The latter refers to the literal definition of each propaganda technique, which
is utilized to get class representations for regularizing the model parameters.
We conduct experiments on Propaganda Techniques Corpus, a large manually
annotated dataset for fine-grained propaganda detection. Experiments show that
our method achieves superior performance, demonstrating that leveraging
declarative knowledge can help the model to make more accurate predictions.
</p>
<a href="http://arxiv.org/abs/2004.14201" target="_blank">arXiv:2004.14201</a> [<a href="http://arxiv.org/pdf/2004.14201" target="_blank">pdf</a>]

<h2>Exploring Fine-tuning Techniques for Pre-trained Cross-lingual Models via Continual Learning. (arXiv:2004.14218v2 [cs.CL] UPDATED)</h2>
<h3>Zihan Liu, Genta Indra Winata, Andrea Madotto, Pascale Fung</h3>
<p>Recently, fine-tuning pre-trained language models (e.g., multilingual BERT)
to downstream cross-lingual tasks has shown promising results. However, the
fine-tuning process inevitably changes the parameters of the pre-trained model
and weakens its cross-lingual ability, which leads to sub-optimal performance.
To alleviate this problem, we leverage continual learning to preserve the
original cross-lingual ability of the pre-trained model when we fine-tune it to
downstream tasks. The experimental result shows that our fine-tuning methods
can better preserve the cross-lingual ability of the pre-trained model in a
sentence retrieval task. Our methods also achieve better performance than other
fine-tuning baselines on the zero-shot cross-lingual part-of-speech tagging and
named entity recognition tasks.
</p>
<a href="http://arxiv.org/abs/2004.14218" target="_blank">arXiv:2004.14218</a> [<a href="http://arxiv.org/pdf/2004.14218" target="_blank">pdf</a>]

<h2>Exploring Contextualized Neural Language Models for Temporal Dependency Parsing. (arXiv:2004.14577v2 [cs.CL] UPDATED)</h2>
<h3>Hayley Ross, Jonathon Cai, Bonan Min</h3>
<p>Extracting temporal relations between events and time expressions has many
applications such as constructing event timelines and time-related question
answering. It is a challenging problem which requires syntactic and semantic
information at sentence or discourse levels, which may be captured by deep
contextualized language models (LMs) such as BERT (Devlin et al., 2019). In
this paper, we develop several variants of BERT-based temporal dependency
parser, and show that BERT significantly improves temporal dependency parsing
(Zhang and Xue, 2018a). We also present a detailed analysis on why deep
contextualized neural LMs help and where they may fall short. Source code and
resources are made available at https://github.com/bnmin/tdp_ranking.
</p>
<a href="http://arxiv.org/abs/2004.14577" target="_blank">arXiv:2004.14577</a> [<a href="http://arxiv.org/pdf/2004.14577" target="_blank">pdf</a>]

<h2>MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer. (arXiv:2005.00052v2 [cs.CL] UPDATED)</h2>
<h3>Jonas Pfeiffer, Ivan Vuli&#x107;, Iryna Gurevych, Sebastian Ruder</h3>
<p>The main goal behind state-of-the-art pre-trained multilingual models such as
multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in
low-resource languages through zero-shot or few-shot cross-lingual transfer.
However, due to limited model capacity, their transfer performance is the
weakest exactly on such low-resource languages and languages unseen during
pre-training. We propose MAD-X, an adapter-based framework that enables high
portability and parameter-efficient transfer to arbitrary tasks and languages
by learning modular language and task representations. In addition, we
introduce a novel invertible adapter architecture and a strong baseline method
for adapting a pre-trained multilingual model to a new language. MAD-X
outperforms the state of the art in cross-lingual transfer across a
representative set of typologically diverse languages on named entity
recognition and causal commonsense reasoning, and achieves competitive results
on question answering.
</p>
<a href="http://arxiv.org/abs/2005.00052" target="_blank">arXiv:2005.00052</a> [<a href="http://arxiv.org/pdf/2005.00052" target="_blank">pdf</a>]

<h2>An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction. (arXiv:2005.00652v2 [cs.CL] UPDATED)</h2>
<h3>Bhargavi Paranjape, Mandar Joshi, John Thickstun, Hannaneh Hajishirzi, Luke Zettlemoyer</h3>
<p>Decisions of complex language understanding models can be rationalized by
limiting their inputs to a relevant subsequence of the original text. A
rationale should be as concise as possible without significantly degrading task
performance, but this balance can be difficult to achieve in practice. In this
paper, we show that it is possible to better manage this trade-off by
optimizing a bound on the Information Bottleneck (IB) objective. Our fully
unsupervised approach jointly learns an explainer that predicts sparse binary
masks over sentences, and an end-task predictor that considers only the
extracted rationale. Using IB, we derive a learning objective that allows
direct control of mask sparsity levels through a tunable sparse prior.
Experiments on ERASER benchmark tasks demonstrate significant gains over
norm-minimization techniques for both task performance and agreement with human
rationales. Furthermore, we find that in the semi-supervised setting, a modest
amount of gold rationales (25% of training examples) closes the gap with a
model that uses the full input.
</p>
<a href="http://arxiv.org/abs/2005.00652" target="_blank">arXiv:2005.00652</a> [<a href="http://arxiv.org/pdf/2005.00652" target="_blank">pdf</a>]

<h2>A Comprehensive Study on Challenges in Deploying Deep Learning Based Software. (arXiv:2005.00760v2 [cs.SE] UPDATED)</h2>
<h3>Zhenpeng Chen, Yanbin Cao, Yuanqiang Liu, Haoyu Wang, Tao Xie, Xuanzhe Liu</h3>
<p>Deep learning (DL) becomes increasingly pervasive, being used in a wide range
of software applications. These software applications, named as DL based
software (in short as DL software), integrate DL models trained using a large
data corpus with DL programs written based on DL frameworks such as TensorFlow
and Keras. A DL program encodes the network structure of a desirable DL model
and the process by which the model is trained using the training data. To help
developers of DL software meet the new challenges posed by DL, enormous
research efforts in software engineering have been devoted. Existing studies
focus on the development of DL software and extensively analyze faults in DL
programs. However, the deployment of DL software has not been comprehensively
studied. To fill this knowledge gap, this paper presents a comprehensive study
on understanding challenges in deploying DL software. We mine and analyze 3,023
relevant posts from Stack Overflow, a popular Q&amp;A website for developers, and
show the increasing popularity and high difficulty of DL software deployment
among developers. We build a taxonomy of specific challenges encountered by
developers in the process of DL software deployment through manual inspection
of 769 sampled posts and report a series of actionable implications for
researchers, developers, and DL framework vendors.
</p>
<a href="http://arxiv.org/abs/2005.00760" target="_blank">arXiv:2005.00760</a> [<a href="http://arxiv.org/pdf/2005.00760" target="_blank">pdf</a>]

<h2>BlackBox: Generalizable Reconstruction of Extremal Values from Incomplete Spatio-Temporal Data. (arXiv:2005.02140v2 [cs.LG] UPDATED)</h2>
<h3>Tomislav Ivek, Domagoj Vlah</h3>
<p>We describe our submission to the Extreme Value Analysis 2019 Data Challenge
in which teams were asked to predict extremes of sea surface temperature
anomaly within spatio-temporal regions of missing data. We present a
computational framework which reconstructs missing data using convolutional
deep neural networks. Conditioned on incomplete data, we employ
autoencoder-like models as multivariate conditional distributions from which
possible reconstructions of the complete dataset are sampled using imputed
noise. In order to mitigate bias introduced by any one particular model, a
prediction ensemble is constructed to create the final distribution of extremal
values. Our method does not rely on expert knowledge in order to accurately
reproduce dynamic features of a complex oceanographic system with minimal
assumptions. The obtained results promise reusability and generalization to
other domains.
</p>
<a href="http://arxiv.org/abs/2005.02140" target="_blank">arXiv:2005.02140</a> [<a href="http://arxiv.org/pdf/2005.02140" target="_blank">pdf</a>]

<h2>Learning programs by learning from failures. (arXiv:2005.02259v2 [cs.AI] UPDATED)</h2>
<h3>Andrew Cropper, Rolf Morel</h3>
<p>We describe an inductive logic programming (ILP) approach called learning
programs by learning from failures. In this approach, an ILP system (the
learner) decomposes the learning problem into three separate stages: generate,
test, and constrain. In the generate stage, the learner generates a hypothesis
(a logic program) that satisfies a set of hypothesis constraints (constraints
on the syntactic form of hypotheses). In the test stage, the learner tests the
hypothesis against training examples. A hypothesis fails when it does not
entail all the positive examples or entails a negative example. If a hypothesis
fails, then, in the constrain stage, the learner learns constraints from the
failed hypothesis to prune the hypothesis space, i.e. to constrain subsequent
hypothesis generation. For instance, if a failed hypothesis is too general
(entails a negative example), the constraints prune generalisations of the
hypothesis. If a failed hypothesis is too specific (does not entail all the
positive examples), the constraints prune specialisations of the hypothesis.
This loop repeats until either (i) the learner finds a hypothesis that entails
all the positive and none of the negative examples, or (ii) there are no more
hypotheses to test. We introduce Popper, an ILP system that implements this
approach by combining answer set programming and Prolog. Popper supports
infinite problem domains, reasoning about lists and numbers, learning optimal
(textually minimal) programs, and learning recursive programs. Our experimental
results on three domains (toy game problems, robot strategies, and list
transformations) show that (i) constraints drastically improve learning
performance, and (ii) Popper can outperform existing ILP systems, both in terms
of predictive accuracies and learning times.
</p>
<a href="http://arxiv.org/abs/2005.02259" target="_blank">arXiv:2005.02259</a> [<a href="http://arxiv.org/pdf/2005.02259" target="_blank">pdf</a>]

<h2>India nudges to contain COVID-19 pandemic: a reactive public policy analysis using machine-learning based topic modelling. (arXiv:2005.06619v2 [cs.CY] UPDATED)</h2>
<h3>Ramit Debnath, Ronita Bardhan</h3>
<p>India locked down 1.3 billion people on March 25, 2020 in the wake of
COVID-19 pandemic. The economic cost of it was estimated at USD 98 billion,
while the social costs are still unknown. This study investigated how
government formed reactive policies to fight coronavirus across its policy
sectors. Primary data was collected from the Press Information Bureau (PIB) in
the form press releases of government plans, policies, programme initiatives
and achievements. A text corpus of 260,852 words was created from 396 documents
from the PIB. An unsupervised machine-based topic modelling using Latent
Dirichlet Allocation (LDA) algorithm was performed on the text corpus. It was
done to extract high probability topics in the policy sectors. The
interpretation of the extracted topics was made through a nudge theoretic lens
to derive the critical policy heuristics of the government. Results showed that
most interventions were targeted to generate endogenous nudge by using external
triggers. Notably, the nudges from the Prime Minister of India was critical in
creating herd effect on lockdown and social distancing norms across the nation.
A similar effect was also observed around the public health (e.g., masks in
public spaces; Yoga and Ayurveda for immunity), transport (e.g., old trains
converted to isolation wards), micro, small and medium enterprises (e.g., rapid
production of PPE and masks), science and technology sector (e.g., diagnostic
kits, robots and nano-technology), home affairs (e.g., surveillance and
lockdown), urban (e.g. drones, GIS-tools) and education (e.g., online
learning). A conclusion was drawn on leveraging these heuristics are crucial
for lockdown easement planning.
</p>
<a href="http://arxiv.org/abs/2005.06619" target="_blank">arXiv:2005.06619</a> [<a href="http://arxiv.org/pdf/2005.06619" target="_blank">pdf</a>]

<h2>RED: Deep Recurrent Neural Networks for Sleep EEG Event Detection. (arXiv:2005.07795v2 [eess.SP] UPDATED)</h2>
<h3>Nicol&#xe1;s I. Tapia, Pablo A. Est&#xe9;vez</h3>
<p>The brain electrical activity presents several short events during sleep that
can be observed as distinctive micro-structures in the electroencephalogram
(EEG), such as sleep spindles and K-complexes. These events have been
associated with biological processes and neurological disorders, making them a
research topic in sleep medicine. However, manual detection limits their study
because it is time-consuming and affected by significant inter-expert
variability, motivating automatic approaches. We propose a deep learning
approach based on convolutional and recurrent neural networks for sleep EEG
event detection called Recurrent Event Detector (RED). RED uses one of two
input representations: a) the time-domain EEG signal, or b) a complex
spectrogram of the signal obtained with the Continuous Wavelet Transform (CWT).
Unlike previous approaches, a fixed time window is avoided and temporal context
is integrated to better emulate the visual criteria of experts. When evaluated
on the MASS dataset, our detectors outperform the state of the art in both
sleep spindle and K-complex detection with a mean F1-score of at least 80.9%
and 82.6%, respectively. Although the CWT-domain model obtained a similar
performance than its time-domain counterpart, the former allows in principle a
more interpretable input representation due to the use of a spectrogram. The
proposed approach is event-agnostic and can be used directly to detect other
types of sleep events.
</p>
<a href="http://arxiv.org/abs/2005.07795" target="_blank">arXiv:2005.07795</a> [<a href="http://arxiv.org/pdf/2005.07795" target="_blank">pdf</a>]

<h2>Global inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes. (arXiv:2005.08140v4 [stat.ML] UPDATED)</h2>
<h3>Sebastian W. Ober, Laurence Aitchison</h3>
<p>We derive the optimal approximate posterior over the top-layer weights in a
Bayesian neural network for regression, and show that it exhibits strong
dependencies on the lower-layer weights. We adapt this result to develop a
correlated approximate posterior over the weights at all layers in a Bayesian
neural network. We extend this approach to deep Gaussian processes, unifying
inference in the two model classes. Our approximate posterior uses learned
"global" inducing points, which are defined only at the input layer and
propagated through the network to obtain inducing inputs at subsequent layers.
By contrast, standard, "local", inducing point methods from the deep Gaussian
process literature optimize a separate set of inducing inputs at every layer,
and thus do not model correlations across layers. Our method gives
state-of-the-art performance for a variational Bayesian method, without data
augmentation or tempering, on CIFAR-10 of $86.7\%$.
</p>
<a href="http://arxiv.org/abs/2005.08140" target="_blank">arXiv:2005.08140</a> [<a href="http://arxiv.org/pdf/2005.08140" target="_blank">pdf</a>]

<h2>Fast Learning in Reproducing Kernel Krein Spaces via Generalized Measures. (arXiv:2006.00247v2 [cs.LG] UPDATED)</h2>
<h3>Fanghui Liu, Xiaolin Huang, Yingyi Chen, Johan A.K. Suykens</h3>
<p>In this paper, we attempt to solve a long-lasting open question in
non-positive definite (non-PD) kernels: does a given non-PD kernel can be
decomposed into the difference of two PD kernels (termed as positive
decomposition)? We consider this question in a distribution view by introducing
the \emph{signed measure}, which transforms positive decomposition to measure
decomposition: a series of non-PD kernels can be associated with the linear
combination of specific finite Borel measures. In this manner, our
distribution-based framework provides a sufficient and necessary condition to
answer this open question. And this answer is also computationally
implementable in practice to scale non-PD kernels in large sample cases, which
allows us to devise the first random features algorithm to obtain an unbiased
estimator. Interestingly, our framework shows that the popular neural tangent
kernel (NTK) of a two-layer ReLU network on the unit sphere is non-PD, which
expands the usage of classical non-PD kernels. Experimental results on several
benchmark datasets verify the effectiveness of our algorithm over the existing
methods.
</p>
<a href="http://arxiv.org/abs/2006.00247" target="_blank">arXiv:2006.00247</a> [<a href="http://arxiv.org/pdf/2006.00247" target="_blank">pdf</a>]

<h2>Towards Understanding Linear Value Decomposition in Cooperative Multi-Agent Q-Learning. (arXiv:2006.00587v3 [cs.LG] UPDATED)</h2>
<h3>Jianhao Wang, Zhizhou Ren, Beining Han, Jianing Ye, Chongjie Zhang</h3>
<p>Value decomposition is a popular and promising approach to scaling up
multi-agent reinforcement learning in cooperative settings. However, the
theoretical understanding of such methods is limited. In this paper, we
introduce a variant of the fitted Q-iteration framework for analyzing
multi-agent Q-learning with value decomposition. Based on this framework, we
derive a closed-form solution to the empirical Bellman error minimization with
linear value decomposition. With this novel solution, we further reveal two
interesting insights: 1) linear value decomposition implicitly implements a
classical multi-agent credit assignment called counterfactual difference
rewards; and 2) On-policy data distribution or richer Q function classes can
improve the training stability of multi-agent Q-learning. In the empirical
study, our experiments demonstrate the realizability of our theoretical
closed-form formulation and implications in the didactic examples and a broad
set of StarCraft II unit micromanagement tasks, respectively.
</p>
<a href="http://arxiv.org/abs/2006.00587" target="_blank">arXiv:2006.00587</a> [<a href="http://arxiv.org/pdf/2006.00587" target="_blank">pdf</a>]

<h2>Learning Irreducible Representations of Noncommutative Lie Groups. (arXiv:2006.00724v2 [cs.LG] UPDATED)</h2>
<h3>Noah Shutty, Casimir Wierzynski</h3>
<p>Recent work has constructed neural networks that are equivariant to
continuous symmetry groups such as 2D and 3D rotations. This is accomplished
using explicit group representations to derive the equivariant kernels and
nonlinearities. We present two contributions motivated by frontier applications
of equivariance beyond rotations and translations. First, we relax the
requirement for explicit Lie group representations, presenting a novel
algorithm that finds irreducible representations of noncommutative Lie groups
given only the structure constants of the associated Lie algebra. Second, we
demonstrate that Lorentz-equivariance is a useful prior for object-tracking
tasks and construct the first object-tracking model equivariant to the
Poincar\'e group.
</p>
<a href="http://arxiv.org/abs/2006.00724" target="_blank">arXiv:2006.00724</a> [<a href="http://arxiv.org/pdf/2006.00724" target="_blank">pdf</a>]

<h2>Consistent Estimators for Learning to Defer to an Expert. (arXiv:2006.01862v2 [cs.LG] UPDATED)</h2>
<h3>Hussein Mozannar, David Sontag</h3>
<p>Learning algorithms are often used in conjunction with expert decision makers
in practical scenarios, however this fact is largely ignored when designing
these algorithms. In this paper we explore how to learn predictors that can
either predict or choose to defer the decision to a downstream expert. Given
only samples of the expert's decisions, we give a procedure based on learning a
classifier and a rejector and analyze it theoretically. Our approach is based
on a novel reduction to cost sensitive learning where we give a consistent
surrogate loss for cost sensitive learning that generalizes the cross entropy
loss. We show the effectiveness of our approach on a variety of experimental
tasks.
</p>
<a href="http://arxiv.org/abs/2006.01862" target="_blank">arXiv:2006.01862</a> [<a href="http://arxiv.org/pdf/2006.01862" target="_blank">pdf</a>]

<h2>Meta-Model-Based Meta-Policy Optimization. (arXiv:2006.02608v3 [cs.LG] UPDATED)</h2>
<h3>Takuya Hiraoka, Takahisa Imagawa, Voot Tangkaratt, Takayuki Osa, Takashi Onishi, Yoshimasa Tsuruoka</h3>
<p>Model-based reinforcement learning (MBRL) has been applied to meta-learning
settings and has demonstrated its high sample efficiency. However, in previous
MBRL for meta-learning settings, policies are optimized via rollouts that fully
rely on a predictive model of an environment. Thus, its performance in a real
environment tends to degrade when the predictive model is inaccurate. In this
paper, we prove that performance degradation can be suppressed by using
branched meta-rollouts. On the basis of this theoretical analysis, we propose
Meta-Model-based Meta-Policy Optimization (M3PO), in which the branched
meta-rollouts are used for policy optimization. We demonstrate that M3PO
outperforms existing meta reinforcement learning methods in continuous-control
benchmarks.
</p>
<a href="http://arxiv.org/abs/2006.02608" target="_blank">arXiv:2006.02608</a> [<a href="http://arxiv.org/pdf/2006.02608" target="_blank">pdf</a>]

<h2>End-to-End Adversarial Text-to-Speech. (arXiv:2006.03575v2 [cs.SD] UPDATED)</h2>
<h3>Jeff Donahue, Sander Dieleman, Miko&#x142;aj Bi&#x144;kowski, Erich Elsen, Karen Simonyan</h3>
<p>Modern text-to-speech synthesis pipelines typically involve multiple
processing stages, each of which is designed or learnt independently from the
rest. In this work, we take on the challenging task of learning to synthesise
speech from normalised text or phonemes in an end-to-end manner, resulting in
models which operate directly on character or phoneme input sequences and
produce raw speech audio outputs. Our proposed generator is feed-forward and
thus efficient for both training and inference, using a differentiable
alignment scheme based on token length prediction. It learns to produce high
fidelity audio through a combination of adversarial feedback and prediction
losses constraining the generated audio to roughly match the ground truth in
terms of its total duration and mel-spectrogram. To allow the model to capture
temporal variation in the generated audio, we employ soft dynamic time warping
in the spectrogram-based prediction loss. The resulting model achieves a mean
opinion score exceeding 4 on a 5 point scale, which is comparable to the
state-of-the-art models relying on multi-stage training and additional
supervision.
</p>
<a href="http://arxiv.org/abs/2006.03575" target="_blank">arXiv:2006.03575</a> [<a href="http://arxiv.org/pdf/2006.03575" target="_blank">pdf</a>]

<h2>Online learning of both state and dynamics using ensemble Kalman filters. (arXiv:2006.03859v2 [stat.ML] UPDATED)</h2>
<h3>Marc Bocquet, Alban Farchi, Quentin Malartic</h3>
<p>The reconstruction of the dynamics of an observed physical system as a
surrogate model has been brought to the fore by recent advances in machine
learning. To deal with partial and noisy observations in that endeavor, machine
learning representations of the surrogate model can be used within a Bayesian
data assimilation framework. However, these approaches require to consider long
time series of observational data, meant to be assimilated all together. This
paper investigates the possibility to learn both the dynamics and the state
online, i.e. to update their estimates at any time, in particular when new
observations are acquired. The estimation is based on the ensemble Kalman
filter (EnKF) family of algorithms using a rather simple representation for the
surrogate model and state augmentation. We consider the implication of learning
dynamics online through (i) a global EnKF, (i) a local EnKF and (iii) an
iterative EnKF and we discuss in each case issues and algorithmic solutions. We
then demonstrate numerically the efficiency and assess the accuracy of these
methods using one-dimensional, one-scale and two-scale chaotic Lorenz models.
</p>
<a href="http://arxiv.org/abs/2006.03859" target="_blank">arXiv:2006.03859</a> [<a href="http://arxiv.org/pdf/2006.03859" target="_blank">pdf</a>]

<h2>Memory-Efficient Learning of Stable Linear Dynamical Systems for Prediction and Control. (arXiv:2006.03937v2 [cs.LG] UPDATED)</h2>
<h3>Giorgos Mamakoukas, Orest Xherija, T. D. Murphey</h3>
<p>Learning a stable Linear Dynamical System (LDS) from data involves creating
models that both minimize reconstruction error and enforce stability of the
learned representation. We propose a novel algorithm for learning stable LDSs.
Using a recent characterization of stable matrices, we present an optimization
method that ensures stability at every step and iteratively improves the
reconstruction error using gradient directions derived in this paper. When
applied to LDSs with inputs, our approach---in contrast to current methods for
learning stable LDSs---updates both the state and control matrices, expanding
the solution space and allowing for models with lower reconstruction error. We
apply our algorithm in simulations and experiments to a variety of problems,
including learning dynamic textures from image sequences and controlling a
robotic manipulator. Compared to existing approaches, our proposed method
achieves an orders-of-magnitude improvement in reconstruction error and
superior results in terms of control performance. In addition, it is provably
more memory-efficient, with an O(n^2) space complexity compared to O(n^4) of
competing alternatives, thus scaling to higher-dimensional systems when the
other methods fail.
</p>
<a href="http://arxiv.org/abs/2006.03937" target="_blank">arXiv:2006.03937</a> [<a href="http://arxiv.org/pdf/2006.03937" target="_blank">pdf</a>]

<h2>SALD: Sign Agnostic Learning with Derivatives. (arXiv:2006.05400v2 [cs.CV] UPDATED)</h2>
<h3>Matan Atzmon, Yaron Lipman</h3>
<p>Learning 3D geometry directly from raw data, such as point clouds, triangle
soups, or unoriented meshes is still a challenging task that feeds many
downstream computer vision and graphics applications.

In this paper, we introduce SALD: a method for learning implicit neural
representations of shapes directly from raw data. We generalize sign agnostic
learning (SAL) to include derivatives: given an unsigned distance function to
the input raw data, we advocate a novel sign agnostic regression loss,
incorporating both pointwise values and gradients of the unsigned distance
function. Optimizing this loss leads to a signed implicit function solution,
the zero level set of which is a high quality and valid manifold approximation
to the input 3D data. The motivation behind SALD is that incorporating
derivatives in a regression loss leads to a lower sample complexity, and
consequently better fitting. In addition, we prove that SAL enjoys a minimal
length property in 2D, favoring minimal length solutions. More importantly, we
are able to show that this property still holds for SALD, i.e., with
derivatives included.

We demonstrate the efficacy of SALD for shape space learning on two
challenging datasets: ShapeNet that contains inconsistent orientation and
non-manifold meshes, and D-Faust that contains raw 3D scans (triangle soups).
On both these datasets, we present state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2006.05400" target="_blank">arXiv:2006.05400</a> [<a href="http://arxiv.org/pdf/2006.05400" target="_blank">pdf</a>]

<h2>A Unified Framework to Learn Program Semantics with Graph Neural Networks. (arXiv:2006.05405v2 [cs.LG] UPDATED)</h2>
<h3>Shangqing Liu</h3>
<p>Program semantics learning is a vital problem in various AI for SE
applications i.g., clone detection, code summarization. Learning to represent
programs with Graph Neural Networks (GNNs) has achieved state-of-the-art
performance in many applications i.g, vulnerability identification, type
inference. However, currently, there is a lack of a unified framework with GNNs
for distinct applications. Furthermore, most existing GNN-based approaches
ignore global relations with nodes, limiting the model to learn rich semantics.
In this paper, we propose a unified framework to construct two types of graphs
to capture rich code semantics for various SE applications.
</p>
<a href="http://arxiv.org/abs/2006.05405" target="_blank">arXiv:2006.05405</a> [<a href="http://arxiv.org/pdf/2006.05405" target="_blank">pdf</a>]

<h2>Self-supervised Learning from a Multi-view Perspective. (arXiv:2006.05576v3 [cs.LG] UPDATED)</h2>
<h3>Yao-Hung Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, Louis-Philippe Morency</h3>
<p>As a subset of unsupervised representation learning, self-supervised
representation learning adopts self-defined signals as supervision and uses the
learned representation for downstream tasks, such as object detection and image
captioning. Many proposed approaches for self-supervised learning follow
naturally a multi-view perspective, where the input (e.g., original images) and
the self-supervised signals (e.g., augmented images) can be seen as two
redundant views of the data. Building from this multi-view perspective, this
paper provides an information-theoretical framework to better understand the
properties that encourage successful self-supervised learning. Specifically, we
demonstrate that self-supervised learned representations can extract
task-relevant information and discard task-irrelevant information. Our
theoretical framework paves the way to a larger space of self-supervised
learning objective design. In particular, we propose a composite objective that
bridges the gap between prior contrastive and predictive learning objectives,
and introduce an additional objective term to discard task-irrelevant
information. To verify our analysis, we conduct controlled experiments to
evaluate the impact of the composite objectives. We also explore our
framework's empirical generalization beyond the multi-view perspective, where
the cross-view redundancy may not be clearly observed.
</p>
<a href="http://arxiv.org/abs/2006.05576" target="_blank">arXiv:2006.05576</a> [<a href="http://arxiv.org/pdf/2006.05576" target="_blank">pdf</a>]

<h2>Dataset Condensation with Gradient Matching. (arXiv:2006.05929v2 [cs.CV] UPDATED)</h2>
<h3>Bo Zhao, Konda Reddy Mopuri, Hakan Bilen</h3>
<p>As the state-of-the-art machine learning methods in many fields rely on
larger datasets, storing them and training models on them becomes more
expensive. This paper proposes a training set synthesis technique for
\emph{data-efficient} learning, called \emph{Dataset Condensation}, that learns
to condense a large dataset into a small set of informative samples for
training deep neural networks from scratch. We formulate this goal as a
gradient matching problem between the gradients of a deep neural network
trained on the original data and our synthetic data. We rigorously evaluate its
performance in several computer vision benchmarks and demonstrate that it
significantly outperforms the state-of-the-art methods. Finally we explore the
use of our method in continual learning and neural architecture search and show
that it achieves promising gains on a tight budget of memory and computations.
</p>
<a href="http://arxiv.org/abs/2006.05929" target="_blank">arXiv:2006.05929</a> [<a href="http://arxiv.org/pdf/2006.05929" target="_blank">pdf</a>]

<h2>Empirical Time Complexity of Generic Dijkstra Algorithm. (arXiv:2006.06062v2 [cs.NI] UPDATED)</h2>
<h3>Piotr Jurkiewicz, Edyta Biernacka, Jerzy Dom&#x17c;a&#x142;, Robert W&#xf3;jcik</h3>
<p>Generic Dijkstra is a novel algorithm for finding the optimal shortest path
in both wavelength-division multiplexed networks (WDM) and elastic optical
networks (EON), claimed to outperform known algorithms considerably. Because of
its novelty, it has not been independently implemented and verified. Its time
complexity also remains unknown.

In this paper we perform run-time analysis and show that Generic Dijkstra
running time grows quadratically with the number of graph vertices and
logarithmically with the number of edge units. We also discover that the
running time of the Generic Dijkstra algorithm in function of network
utilization is not monotonic - peak running time is at approximately 0.25
network utilization. This is the first complexity analysis of Generic Dijkstra
algorithm.

Additionally, we provide an independent open source implementation of Generic
Dijkstra in the Python language. We confirm correctness of the algorithm and
its superior performance. In comparison to the Filtered Graphs algorithm,
Generic Dijkstra is approximately 3.5 times faster. In 95% of calls Generic
Dijkstra is faster than Filtered Graphs.
</p>
<a href="http://arxiv.org/abs/2006.06062" target="_blank">arXiv:2006.06062</a> [<a href="http://arxiv.org/pdf/2006.06062" target="_blank">pdf</a>]

<h2>Evaluation of Neural Architectures Trained with Square Loss vs Cross-Entropy in Classification Tasks. (arXiv:2006.07322v2 [cs.LG] UPDATED)</h2>
<h3>Like Hui, Mikhail Belkin</h3>
<p>Modern neural architectures for classification tasks are trained using the
cross-entropy loss, which is widely believed to be empirically superior to the
square loss. In this work we provide evidence indicating that this belief may
not be well-founded. We explore several major neural architectures and a range
of standard benchmark datasets for NLP, automatic speech recognition (ASR) and
computer vision tasks to show that these architectures, with the same
hyper-parameter settings as reported in the literature, perform comparably or
better when trained with the square loss, even after equalizing computational
resources. Indeed, we observe that the square loss produces better results in
the dominant majority of NLP and ASR experiments. Cross-entropy appears to have
a slight edge on computer vision tasks.

We argue that there is little compelling empirical or theoretical evidence
indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our
experiments, performance on nearly all non-vision tasks can be improved,
sometimes significantly, by switching to the square loss. Furthermore, training
with square loss appears to be less sensitive to the randomness in
initialization. We posit that training using the square loss for classification
needs to be a part of best practices of modern deep learning on equal footing
with cross-entropy.
</p>
<a href="http://arxiv.org/abs/2006.07322" target="_blank">arXiv:2006.07322</a> [<a href="http://arxiv.org/pdf/2006.07322" target="_blank">pdf</a>]

<h2>Adversarial representation learning for synthetic replacement of private attributes. (arXiv:2006.08039v3 [cs.LG] UPDATED)</h2>
<h3>John Martinsson, Edvin Listo Zec, Daniel Gillblad, Olof Mogren</h3>
<p>Data privacy is an increasingly important aspect of the analysis of big data
for many real-world tasks. Privacy enhancing transformations of data can help
unlocking the potential in data sources containing sensitive information, but
finding the right balance between privacy and utility is often a tricky
trade-off. In this work, we study how adversarial representation learning can
be used to ensure the privacy of users, and to obfuscate sensitive attributes
in existing datasets. While previous methods using this kind of approach only
aim at obfuscating the sensitive information, we find that adding new
information in its place strengthens the provided privacy. We propose a two
step data privatization method that builds on generative adversarial networks:
in the first step, sensitive data is removed from the representation, and in
the second step, a sample which is independent of the input data is inserted in
its place. The result is an approach that can provide stronger privatization on
image data, and yet be preserving both the domain and the utility of the
inputs.
</p>
<a href="http://arxiv.org/abs/2006.08039" target="_blank">arXiv:2006.08039</a> [<a href="http://arxiv.org/pdf/2006.08039" target="_blank">pdf</a>]

<h2>Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence. (arXiv:2006.08242v2 [cs.LG] UPDATED)</h2>
<h3>Thomas M. Sutter, Imant Daunhawer, Julia E. Vogt</h3>
<p>Learning from different data types is a long-standing goal in machine
learning research, as multiple information sources co-occur when describing
natural phenomena. However, existing generative models that approximate a
multimodal ELBO rely on difficult or inefficient training schemes to learn a
joint distribution and the dependencies between modalities. In this work, we
propose a novel, efficient objective function that utilizes the Jensen-Shannon
divergence for multiple distributions. It simultaneously approximates the
unimodal and joint multimodal posteriors directly via a dynamic prior. In
addition, we theoretically prove that the new multimodal JS-divergence (mmJSD)
objective optimizes an ELBO. In extensive experiments, we demonstrate the
advantage of the proposed mmJSD model compared to previous work in
unsupervised, generative learning tasks.
</p>
<a href="http://arxiv.org/abs/2006.08242" target="_blank">arXiv:2006.08242</a> [<a href="http://arxiv.org/pdf/2006.08242" target="_blank">pdf</a>]

<h2>Globally Injective ReLU Networks. (arXiv:2006.08464v2 [cs.LG] UPDATED)</h2>
<h3>Michael Puthawala, Konik Kothari, Matti Lassas, Ivan Dokmani&#x107;, Maarten de Hoop</h3>
<p>Injectivity plays an important role in generative models where it enables
inference; in inverse problems and compressed sensing with generative priors it
is a precursor to well posedness. We establish sharp characterizations of
injectivity of fully-connected and convolutional ReLU layers and networks.
First, through a layerwise analysis, we show that an expansivity factor of two
is necessary and sufficient for injectivity by constructing appropriate weight
matrices. We show that global injectivity with iid Gaussian matrices, a
commonly used tractable model, requires larger expansivity between 3.4 and 5.7.
We also characterize the stability of inverting an injective network via
worst-case Lipschitz constants of the inverse. We then use arguments from
differential topology to study injectivity of deep networks and prove that any
Lipschitz map can be approximated by an injective ReLU network. Finally, using
an argument based on random projections, we show that an end-to-end---rather
than layerwise---doubling of the dimension suffices for injectivity. Our
results establish a theoretical basis for the study of nonlinear inverse and
inference problems using neural networks.
</p>
<a href="http://arxiv.org/abs/2006.08464" target="_blank">arXiv:2006.08464</a> [<a href="http://arxiv.org/pdf/2006.08464" target="_blank">pdf</a>]

<h2>Extrapolatable Relational Reasoning With Comparators in Low-Dimensional Manifolds. (arXiv:2006.08698v2 [cs.LG] UPDATED)</h2>
<h3>Duo Wang, Mateja Jamnik, Pietro Lio</h3>
<p>While modern deep neural architectures generalise well when test data is
sampled from the same distribution as training data, they fail badly for cases
when the test data distribution differs from the training distribution even
along a few dimensions. This lack of out-of-distribution generalisation is
increasingly manifested when the tasks become more abstract and complex, such
as in relational reasoning. In this paper we propose a neuroscience-inspired
inductive-biased module that can be readily amalgamated with current neural
network architectures to improve out-of-distribution (o.o.d) generalisation
performance on relational reasoning tasks. This module learns to project
high-dimensional object representations to low-dimensional manifolds for more
efficient and generalisable relational comparisons. We show that neural nets
with this inductive bias achieve considerably better o.o.d generalisation
performance for a range of relational reasoning tasks. We finally analyse the
proposed inductive bias module to understand the importance of lower dimension
projection, and propose an augmentation to the algorithmic alignment theory to
better measure algorithmic alignment with generalisation.
</p>
<a href="http://arxiv.org/abs/2006.08698" target="_blank">arXiv:2006.08698</a> [<a href="http://arxiv.org/pdf/2006.08698" target="_blank">pdf</a>]

<h2>FCOS: A simple and strong anchor-free object detector. (arXiv:2006.09214v2 [cs.CV] UPDATED)</h2>
<h3>Zhi Tian, Chunhua Shen, Hao Chen, Tong He</h3>
<p>In computer vision, object detection is one of most important tasks, which
underpins a few instance-level recognition tasks and many downstream
applications. Recently one-stage methods have gained much attention over
two-stage approaches due to their simpler design and competitive performance.
Here we propose a fully convolutional one-stage object detector (FCOS) to solve
object detection in a per-pixel prediction fashion, analogue to other dense
prediction problems such as semantic segmentation. Almost all state-of-the-art
object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on
pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor box
free, as well as proposal free. By eliminating the pre-defined set of anchor
boxes, FCOS completely avoids the complicated computation related to anchor
boxes such as calculating the intersection over union (IoU) scores during
training. More importantly, we also avoid all hyper-parameters related to
anchor boxes, which are often sensitive to the final detection performance.
With the only post-processing non-maximum suppression (NMS), we demonstrate a
much simpler and flexible detection framework achieving improved detection
accuracy. We hope that the proposed FCOS framework can serve as a simple and
strong alternative for many other instance-level tasks. Code and pre-trained
models are available at: https://git.io/AdelaiDet
</p>
<a href="http://arxiv.org/abs/2006.09214" target="_blank">arXiv:2006.09214</a> [<a href="http://arxiv.org/pdf/2006.09214" target="_blank">pdf</a>]

<h2>The Recurrent Neural Tangent Kernel. (arXiv:2006.10246v2 [cs.LG] UPDATED)</h2>
<h3>Sina Alemohammad, Zichao Wang, Randall Balestriero, Richard Baraniuk</h3>
<p>The study of deep networks (DNs) in the infinite-width limit, via the
so-called Neural Tangent Kernel (NTK) approach, has provided new insights into
the dynamics of learning, generalization, and the impact of initialization. One
key DN architecture remains to be kernelized, namely, the Recurrent Neural
Network (RNN). In this paper we introduce and study the Recurrent Neural
Tangent Kernel (RNTK), which sheds new insights into the behavior of
overparametrized RNNs, including how different time steps are weighted by the
RNTK to form the output under different initialization parameters and
nonlinearity choices, and how inputs of different lengths are treated. We
demonstrate via a number of experiments that the RNTK offers significant
performance gains over other kernels, including standard NTKs across a range of
different data sets. A unique benefit of the RNTK is that it is agnostic to the
length of the input, in stark contrast to other kernels.
</p>
<a href="http://arxiv.org/abs/2006.10246" target="_blank">arXiv:2006.10246</a> [<a href="http://arxiv.org/pdf/2006.10246" target="_blank">pdf</a>]

<h2>Towards Understanding Label Smoothing. (arXiv:2006.11653v2 [cs.LG] UPDATED)</h2>
<h3>Yi Xu, Yuanhong Xu, Qi Qian, Hao Li, Rong Jin</h3>
<p>Label smoothing regularization (LSR) has a great success in training deep
neural networks by stochastic algorithms such as stochastic gradient descent
and its variants. However, the theoretical understanding of its power from the
view of optimization is still rare. This study opens the door to a deep
understanding of LSR by initiating the analysis. In this paper, we analyze the
convergence behaviors of stochastic gradient descent with label smoothing
regularization for solving non-convex problems and show that an appropriate LSR
can help to speed up the convergence by reducing the variance. More
interestingly, we proposed a simple yet effective strategy, namely Two-Stage
LAbel smoothing algorithm (TSLA), that uses LSR in the early training epochs
and drops it off in the later training epochs. We observe from the improved
convergence result of TSLA that it benefits from LSR in the first stage and
essentially converges faster in the second stage. To the best of our knowledge,
this is the first work for understanding the power of LSR via establishing
convergence complexity of stochastic methods with LSR in non-convex
optimization. We empirically demonstrate the effectiveness of the proposed
method in comparison with baselines on training ResNet models over benchmark
data sets.
</p>
<a href="http://arxiv.org/abs/2006.11653" target="_blank">arXiv:2006.11653</a> [<a href="http://arxiv.org/pdf/2006.11653" target="_blank">pdf</a>]

<h2>A Trainable Optimal Transport Embedding for Feature Aggregation. (arXiv:2006.12065v3 [cs.LG] UPDATED)</h2>
<h3>Gr&#xe9;goire Mialon, Dexiong Chen, Alexandre d&#x27;Aspremont, Julien Mairal</h3>
<p>We address the problem of learning on large sets of features, motivated by
the need of performing pooling operations in long biological sequences of
varying sizes, with long-range dependencies, and possibly few labeled data. To
address this challenging task, we introduce a parametrized embedding that
aggregates the features from a given set according to the optimal transport
plan between the set and a trainable reference. Our approach scales to large
datasets and allows end-to-end training of the reference, while also providing
a simple unsupervised learning mechanism with small computational cost. Our
aggregation technique admits two useful interpretations: it may be seen as a
mechanism related to attention layers in neural networks, yet that requires
less data, or it may be seen as a scalable surrogate of a classical optimal
transport-based kernel. We experimentally demonstrate the effectiveness of our
approach on biological sequences, achieving state-of-the-art results for
protein fold recognition and detection of chromatin profiles tasks, and, as a
proof of concept, we show promising results for processing natural language
sequences. We provide an open-source implementation of our embedding that can
be used alone or as a module in larger learning models. Our code is freely
available at https://github.com/claying/OTK.
</p>
<a href="http://arxiv.org/abs/2006.12065" target="_blank">arXiv:2006.12065</a> [<a href="http://arxiv.org/pdf/2006.12065" target="_blank">pdf</a>]

<h2>Improving Few-Shot Visual Classification with Unlabelled Examples. (arXiv:2006.12245v2 [cs.CV] UPDATED)</h2>
<h3>Peyman Bateni, Jarred Barber, Jan-Willem van de Meent, Frank Wood</h3>
<p>We propose a transductive meta-learning method that uses unlabelled instances
to improve few-shot image classification performance. Our approach combines a
regularized Mahalanobis-distance-based soft k-means clustering procedure with a
modified state of the art neural adaptive feature extractor to achieve improved
test-time classification accuracy using unlabelled data. We evaluate our method
on transductive few-shot learning tasks, in which the goal is to jointly
predict labels for query (test) examples given a set of support (training)
examples. We achieve new state of the art performance on Meta-Dataset, and
produce competitive results on mini- and tiered-ImageNet benchmarks.
</p>
<a href="http://arxiv.org/abs/2006.12245" target="_blank">arXiv:2006.12245</a> [<a href="http://arxiv.org/pdf/2006.12245" target="_blank">pdf</a>]

<h2>D2P-Fed: Differentially Private Federated Learning With Efficient Communication. (arXiv:2006.13039v2 [stat.ML] UPDATED)</h2>
<h3>Lun Wang, Ruoxi Jia, Dawn Song</h3>
<p>In this paper, we propose the discrete Gaussian based differentially private
federated learning (D2P-Fed), a unified scheme to achieve both differential
privacy (DP) and communication efficiency in federated learning (FL). In
particular, compared with the only prior work taking care of both aspects,
D2P-Fed provides stronger privacy guarantee, better composability and smaller
communication cost. The key idea is to apply the discrete Gaussian noise to the
private data transmission. We provide complete analysis of the privacy
guarantee, communication cost and convergence rate of D2P-Fed. We evaluated
D2P-Fed on INFIMNIST and CIFAR10. The results show that D2P-Fed outperforms
the-state-of-the-art by 6.7% to 9.75% in terms of model accuracy while saving
one third of the communication cost.
</p>
<a href="http://arxiv.org/abs/2006.13039" target="_blank">arXiv:2006.13039</a> [<a href="http://arxiv.org/pdf/2006.13039" target="_blank">pdf</a>]

<h2>Calibration of Shared Equilibria in General Sum Partially Observable Markov Games. (arXiv:2006.13085v3 [cs.MA] UPDATED)</h2>
<h3>Nelson Vadori, Sumitra Ganesh, Prashant Reddy, Manuela Veloso</h3>
<p>Training multi-agent systems (MAS) to achieve realistic equilibria gives us a
useful tool to understand and model real-world systems. We consider a general
sum partially observable Markov game where agents of different types share a
single policy network, conditioned on agent-specific information. This paper
aims at i) formally understanding equilibria reached by such agents, and ii)
matching emergent phenomena of such equilibria to real-world targets. Parameter
sharing with decentralized execution has been introduced as an efficient way to
train multiple agents using a single policy network. However, the nature of
resulting equilibria reached by such agents has not been yet studied: we
introduce the novel concept of \textit{Shared equilibrium} as a symmetric pure
Nash equilibrium of a certain Functional Form Game (FFG) and prove convergence
to the latter for a certain class of games using self-play. In addition, it is
important that such equilibria satisfy certain constraints so that MAS are
calibrated to real world data for practical use: we solve this problem by
introducing a novel dual-Reinforcement Learning based approach that fits
emergent behaviors of agents in a Shared equilibrium to externally-specified
targets, and apply our methods to a $n$-player market example. We do so by
calibrating parameters governing distributions of agent types rather than
individual agents, which allows both behavior differentiation among agents and
coherent scaling of the shared policy network to multiple agents.
</p>
<a href="http://arxiv.org/abs/2006.13085" target="_blank">arXiv:2006.13085</a> [<a href="http://arxiv.org/pdf/2006.13085" target="_blank">pdf</a>]

<h2>GMMLoc: Structure Consistent Visual Localization with Gaussian Mixture Models. (arXiv:2006.13670v2 [cs.RO] UPDATED)</h2>
<h3>Huaiyang Huang, Haoyang Ye, Yuxiang Sun, Ming Liu</h3>
<p>Incorporating prior structure information into the visual state estimation
could generally improve the localization performance. In this letter, we aim to
address the paradox between accuracy and efficiency in coupling visual factors
with structure constraints. To this end, we present a cross-modality method
that tracks a camera in a prior map modelled by the Gaussian Mixture Model
(GMM). With the pose estimated by the front-end initially, the local visual
observations and map components are associated efficiently, and the visual
structure from the triangulation is refined simultaneously. By introducing the
hybrid structure factors into the joint optimization, the camera poses are
bundle-adjusted with the local visual structure. By evaluating our complete
system, namely GMMLoc, on the public dataset, we show how our system can
provide a centimeter-level localization accuracy with only trivial
computational overhead. In addition, the comparative studies with the
state-of-the-art vision-dominant state estimators demonstrate the competitive
performance of our method.
</p>
<a href="http://arxiv.org/abs/2006.13670" target="_blank">arXiv:2006.13670</a> [<a href="http://arxiv.org/pdf/2006.13670" target="_blank">pdf</a>]

<h2>Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time. (arXiv:2006.14798v2 [cs.LG] UPDATED)</h2>
<h3>Tolga Ergen, Mert Pilanci</h3>
<p>We study training of Convolutional Neural Networks (CNNs) with ReLU
activations and introduce exact convex optimization formulations with a
polynomial complexity with respect to the number of data samples, the number of
neurons, and data dimension. More specifically, we develop a convex analytic
framework utilizing semi-infinite duality to obtain equivalent convex
optimization problems for several two- and three-layer CNN architectures. We
first prove that two-layer CNNs can be globally optimized via an $\ell_2$ norm
regularized convex program. We then show that three-layer CNN training problems
are equivalent to an $\ell_1$ regularized convex program that encourages
sparsity in the spectral domain. We also extend these results to multi-layer
CNN architectures including three-layer networks with two ReLU layers and
deeper circular convolutions with a single ReLU layer. Furthermore, we present
extensions of our approach to different pooling methods, which elucidates the
implicit architectural bias as convex regularizers.
</p>
<a href="http://arxiv.org/abs/2006.14798" target="_blank">arXiv:2006.14798</a> [<a href="http://arxiv.org/pdf/2006.14798" target="_blank">pdf</a>]

<h2>End-Effect Exploration Drive for Effective Motor Learning. (arXiv:2006.15960v2 [cs.AI] UPDATED)</h2>
<h3>Emmanuel Dauc&#xe9;</h3>
<p>Stemming on the idea that a key objective in reinforcement learning is to
invert a target distribution of effects, end-effect drives are proposed as an
effective way to implement goal-directed motor learning, in the absence of an
explicit forward model. An end-effect model relies on a simple statistical
recording of the effect of the current policy, here used as a substitute for
the more resource-demanding forward models. When combined with a reward
structure, it forms the core of a lightweight variational free energy
minimization setup. The main difficulty lies in the maintenance of this
simplified effect model together with the online update of the policy. When the
prior target distribution is uniform, it provides a ways to learn an efficient
exploration policy, consistently with the intrinsic curiosity principles. When
combined with an extrinsic reward, our approach is finally shown to provide a
faster training than traditional off-policy techniques.
</p>
<a href="http://arxiv.org/abs/2006.15960" target="_blank">arXiv:2006.15960</a> [<a href="http://arxiv.org/pdf/2006.15960" target="_blank">pdf</a>]

<h2>DOME: Recommendations for supervised machine learning validation in biology. (arXiv:2006.16189v2 [q-bio.OT] UPDATED)</h2>
<h3>Ian Walsh, Dmytro Fishman, Dario Garcia-Gasulla, Tiina Titma, The ELIXIR Machine Learning focus group, Jen Harrow, Fotis E. Psomopoulos, Silvio C.E. Tosatto</h3>
<p>Modern biology frequently relies on machine learning to provide predictions
and improve decision processes. There have been recent calls for more scrutiny
on machine learning performance and possible limitations. Here we present a set
of community-wide recommendations aiming to help establish standards of
supervised machine learning validation in biology. Adopting a structured
methods description for machine learning based on data, optimization, model,
evaluation (DOME) will allow both reviewers and readers to better understand
and assess the performance and limitations of a method or outcome. The
recommendations are formulated as questions to anyone wishing to pursue
implementation of a machine learning algorithm. Answers to these questions can
be easily included in the supplementary material of published papers.
</p>
<a href="http://arxiv.org/abs/2006.16189" target="_blank">arXiv:2006.16189</a> [<a href="http://arxiv.org/pdf/2006.16189" target="_blank">pdf</a>]

<h2>Approximating Network Centrality Measures Using Node Embedding and Machine Learning. (arXiv:2006.16392v3 [cs.SI] UPDATED)</h2>
<h3>Matheus R. F. Mendon&#xe7;a, Andr&#xe9; M. S. Barreto, Artur Ziviani</h3>
<p>Extracting information from real-world large networks is a key challenge
nowadays. Depending on the intended node centrality, it becomes unfeasible to
compute it for such large networks given the computational cost. One solution
is to develop fast methods capable of approximating network centralities. Here,
we propose an approach for efficiently approximating node centralities for
large networks using Neural Networks and Graph Embedding techniques. Our
proposed model, entitled Network Centrality Approximation using Graph Embedding
(NCA-GE), receives as input the adjacency matrix of a graph and a set of
features for each node (here, we use only the degree) and computes the
approximate desired centrality rank for every node. NCA-GE has a time
complexity of $O(|E|)$, $E$ being the set of edges of a graph, making it
suitable for large networks. NCA-GE also trains pretty fast, requiring only a
set of a thousand small synthetic scale-free graphs (ranging from 100 to 1000
nodes each), and it works well for different node centralities, network sizes,
and topologies. Finally, we show that NCA-GE outperforms, in a variety of
scenarios, the state-of-the-art method that approximates centrality ranks using
the degree and eigenvector centralities as input.
</p>
<a href="http://arxiv.org/abs/2006.16392" target="_blank">arXiv:2006.16392</a> [<a href="http://arxiv.org/pdf/2006.16392" target="_blank">pdf</a>]

<h2>Delayed Q-update: A novel credit assignment technique for deriving an optimal operation policy for the Grid-Connected Microgrid. (arXiv:2006.16659v2 [eess.SY] UPDATED)</h2>
<h3>Hyungjun Park, Daiki Min, Jong-hyun Ryu, Dong Gu Choi</h3>
<p>A microgrid is an innovative system that integrates distributed energy
resources to supply electricity demand within electrical boundaries. This study
proposes an approach for deriving a desirable microgrid operation policy that
enables sophisticated controls in the microgrid system using the proposed novel
credit assignment technique, delayed-Q update. The technique employs novel
features such as the ability to tackle and resolve the delayed effective
property of the microgrid, which prevents learning agents from deriving a
well-fitted policy under sophisticated controls. The proposed technique tracks
the history of the charging period and retroactively assigns an adjusted value
to the ESS charging control. The operation policy derived using the proposed
approach is well-fitted for the real effects of ESS operation because of the
process of the technique. Therefore, it supports the search for a near-optimal
operation policy under a sophisticatedly controlled microgrid environment. To
validate our technique, we simulate the operation policy under a real-world
grid-connected microgrid system and demonstrate the convergence to a
near-optimal policy by comparing performance measures of our policy with
benchmark policy and optimal policy.
</p>
<a href="http://arxiv.org/abs/2006.16659" target="_blank">arXiv:2006.16659</a> [<a href="http://arxiv.org/pdf/2006.16659" target="_blank">pdf</a>]

<h2>Provably More Efficient Q-Learning in the One-Sided-Feedback/Full-Feedback Settings. (arXiv:2007.00080v2 [cs.LG] UPDATED)</h2>
<h3>Xiao-Yue Gong, David Simchi-Levi</h3>
<p>Motivated by the episodic version of the classical inventory control problem,
we propose a new Q-learning-based algorithm, Elimination-Based Half-Q-Learning
(HQL), that enjoys improved efficiency over existing algorithms for a wide
variety of problems in the one-sided-feedback setting. We also provide a
simpler variant of the algorithm, Full-Q-Learning (FQL), for the full-feedback
setting. We establish that HQL incurs $ \tilde{\mathcal{O}}(H^3\sqrt{ T})$
regret and FQL incurs $\tilde{\mathcal{O}}(H^2\sqrt{ T})$ regret, where $H$ is
the length of each episode and $T$ is the total length of the horizon. The
regret bounds are not affected by the possibly huge state and action space. Our
numerical experiments demonstrate the superior efficiency of HQL and FQL, and
the potential to combine reinforcement learning with richer feedback models.
</p>
<a href="http://arxiv.org/abs/2007.00080" target="_blank">arXiv:2007.00080</a> [<a href="http://arxiv.org/pdf/2007.00080" target="_blank">pdf</a>]

<h2>Adaptive Procedural Task Generation for Hard-Exploration Problems. (arXiv:2007.00350v2 [cs.LG] UPDATED)</h2>
<h3>Kuan Fang, Yuke Zhu, Silvio Savarese, Li Fei-Fei</h3>
<p>We introduce Adaptive Procedural Task Generation (APT-Gen), an approach to
progressively generate a sequence of tasks as curricula to facilitate
reinforcement learning in hard-exploration problems. At the heart of our
approach, a task generator learns to create tasks from a parameterized task
space via a black-box procedural generation module. To enable curriculum
learning in the absence of a direct indicator of learning progress, we propose
to train the task generator by balancing the agent's performance in the
generated tasks and the similarity to the target tasks. Through adversarial
training, the task similarity is adaptively estimated by a task discriminator
defined on the agent's experiences, allowing the generated tasks to approximate
target tasks of unknown parameterization or outside of the predefined task
space. Our experiments on grid world and robotic manipulation task domains show
that APT-Gen achieves substantially better performance than various existing
baselines by generating suitable tasks of rich variations.
</p>
<a href="http://arxiv.org/abs/2007.00350" target="_blank">arXiv:2007.00350</a> [<a href="http://arxiv.org/pdf/2007.00350" target="_blank">pdf</a>]

<h2>Descending through a Crowded Valley -- Benchmarking Deep Learning Optimizers. (arXiv:2007.01547v4 [cs.LG] UPDATED)</h2>
<h3>Robin M. Schmidt, Frank Schneider, Philipp Hennig</h3>
<p>Choosing the optimizer is considered to be among the most crucial design
decisions in deep learning, and it is not an easy one. The growing literature
now lists hundreds of optimization methods. In the absence of clear theoretical
guidance and conclusive empirical evidence, the decision is often made based on
anecdotes. In this work, we aim to replace these anecdotes, if not with a
conclusive ranking, then at least with evidence-backed heuristics. To do so, we
perform an extensive, standardized benchmark of more than a dozen particularly
popular deep learning optimizers while giving a concise overview of the wide
range of possible choices. Analyzing almost 35,000 individual runs, we
contribute the following three points: (i) Optimizer performance varies greatly
across tasks. (ii) We observe that evaluating multiple optimizers with default
parameters works approximately as well as tuning the hyperparameters of a
single, fixed optimizer. (iii) While we can not discern an optimization method
clearly dominating across all tested tasks, we identify a significantly reduced
subset of specific algorithms and parameter choices that generally lead to
competitive results in our experiments. This subset includes popular favorites
and some lesser-known contenders. We have open-sourced all our experimental
results, making them directly available as challenging and well-tuned
baselines. This allows for more meaningful comparisons when evaluating novel
optimization methods without requiring any further computational efforts.
</p>
<a href="http://arxiv.org/abs/2007.01547" target="_blank">arXiv:2007.01547</a> [<a href="http://arxiv.org/pdf/2007.01547" target="_blank">pdf</a>]

<h2>Auxiliary Learning by Implicit Differentiation. (arXiv:2007.02693v2 [cs.CV] UPDATED)</h2>
<h3>Aviv Navon, Idan Achituve, Haggai Maron, Gal Chechik, Ethan Fetaya</h3>
<p>Training with multiple auxiliary tasks is a common practice used in deep
learning for improving the performance on the main task of interest. Two main
challenges arise in this multi-task learning setting: (i) Designing useful
auxiliary tasks; and (ii) Combining auxiliary tasks into a single coherent
loss. We propose a novel framework, AuxiLearn, that targets both challenges,
based on implicit differentiation. First, when useful auxiliaries are known, we
propose learning a network that combines all losses into a single coherent
objective function. This network can learn non-linear interactions between
auxiliary tasks. Second, when no useful auxiliary task is known, we describe
how to learn a network that generates a meaningful, novel auxiliary task. We
evaluate AuxiLearn in a series of tasks and domains, including image
segmentation and learning with attributes. We find that AuxiLearn consistently
improves accuracy compared with competing methods.
</p>
<a href="http://arxiv.org/abs/2007.02693" target="_blank">arXiv:2007.02693</a> [<a href="http://arxiv.org/pdf/2007.02693" target="_blank">pdf</a>]

<h2>Representations for Stable Off-Policy Reinforcement Learning. (arXiv:2007.05520v2 [cs.LG] UPDATED)</h2>
<h3>Dibya Ghosh, Marc G. Bellemare</h3>
<p>Reinforcement learning with function approximation can be unstable and even
divergent, especially when combined with off-policy learning and Bellman
updates. In deep reinforcement learning, these issues have been dealt with
empirically by adapting and regularizing the representation, in particular with
auxiliary tasks. This suggests that representation learning may provide a means
to guarantee stability. In this paper, we formally show that there are indeed
nontrivial state representations under which the canonical TD algorithm is
stable, even when learning off-policy. We analyze representation learning
schemes that are based on the transition matrix of a policy, such as
proto-value functions, along three axes: approximation error, stability, and
ease of estimation. In the most general case, we show that a Schur basis
provides convergence guarantees, but is difficult to estimate from samples. For
a fixed reward function, we find that an orthogonal basis of the corresponding
Krylov subspace is an even better choice. We conclude by empirically
demonstrating that these stable representations can be learned using stochastic
gradient descent, opening the door to improved techniques for representation
learning with deep networks.
</p>
<a href="http://arxiv.org/abs/2007.05520" target="_blank">arXiv:2007.05520</a> [<a href="http://arxiv.org/pdf/2007.05520" target="_blank">pdf</a>]

<h2>Data-Efficient Reinforcement Learning with Self-Predictive Representations. (arXiv:2007.05929v3 [cs.LG] UPDATED)</h2>
<h3>Max Schwarzer, Ankesh Anand, Rishab Goel, R Devon Hjelm, Aaron Courville, Philip Bachman</h3>
<p>While deep reinforcement learning excels at solving tasks where large amounts
of data can be collected through virtually unlimited interaction with the
environment, learning from limited interaction remains a key challenge. We
posit that an agent can learn more efficiently if we augment reward
maximization with self-supervised objectives based on structure in its visual
input and sequential interaction with the environment. Our method,
Self-Predictive Representations(SPR), trains an agent to predict its own latent
state representations multiple steps into the future. We compute target
representations for future states using an encoder which is an exponential
moving average of the agent's parameters and we make predictions using a
learned transition model. On its own, this future prediction objective
outperforms prior methods for sample-efficient deep RL from pixels. We further
improve performance by adding data augmentation to the future prediction loss,
which forces the agent's representations to be consistent across multiple views
of an observation. Our full self-supervised objective, which combines future
prediction and data augmentation, achieves a median human-normalized score of
0.415 on Atari in a setting limited to 100k steps of environment interaction,
which represents a 55% relative improvement over the previous state-of-the-art.
Notably, even in this limited data regime, SPR exceeds expert human scores on 7
out of 26 games. The code associated with this work is available at
https://github.com/mila-iqia/spr
</p>
<a href="http://arxiv.org/abs/2007.05929" target="_blank">arXiv:2007.05929</a> [<a href="http://arxiv.org/pdf/2007.05929" target="_blank">pdf</a>]

<h2>Blockchain for the Internet of Vehicles towards Intelligent Transportation Systems: A Survey. (arXiv:2007.06022v2 [cs.CR] UPDATED)</h2>
<h3>Muhammad Baqer Mollah, Jun Zhao, Dusit Niyato, Yong Liang Guan, Chau Yuen, Sumei Sun, Kwok-Yan Lam, Leong Hai Koh</h3>
<p>Internet of Vehicles (IoV) is an emerging concept that is believed to help
realise the vision of intelligent transportation systems (ITS). IoV has become
an important research area of impactful applications in recent years due to the
rapid advancements in vehicular technologies, high throughput satellite
communication, Internet of Things and cyber-physical systems. IoV enables the
integration of smart vehicles with the Internet and system components
attributing to their environment such as public infrastructures, sensors,
computing nodes, pedestrians and other vehicles. By allowing the development of
a common information exchange platform between vehicles and heterogeneous
vehicular networks, this integration aims to create a better environment and
public space to the people as well as to enhance safety for all road users.
Being a participatory data exchange and storage, the underlying information
exchange platform of IoV needs to be secure, transparent and immutable in order
to achieve the intended objectives of ITS. In this connection, the adoption of
blockchain as a system platform for supporting the information exchange needs
of IoV has been explored. Due to their decentralized and immutable nature, IoV
applications enabled by blockchain are believed to have a number of desirable
properties such as decentralization, security, transparency, immutability, and
automation. In this paper, we present a contemporary survey on the latest
advancement in blockchain for IoV. Particularly, we highlight the different
application scenarios of IoV after carefully reviewing the recent literatures.
We also investigate several key challenges where blockchain is applied in IoV.
Furthermore, we present the future opportunities and explore further research
directions of IoV as a key enabler of ITS.
</p>
<a href="http://arxiv.org/abs/2007.06022" target="_blank">arXiv:2007.06022</a> [<a href="http://arxiv.org/pdf/2007.06022" target="_blank">pdf</a>]

<h2>Whitening for Self-Supervised Representation Learning. (arXiv:2007.06346v2 [cs.LG] UPDATED)</h2>
<h3>Aleksandr Ermolov, Aliaksandr Siarohin, Enver Sangineto, Nicu Sebe</h3>
<p>Most of the self-supervised learning methods are based on the contrastive
loss, where image instances which share the same semantic content ("positives")
are contrasted with instances extracted from other images ("negatives"). For
the learning to be effective, a lot of negatives should be compared with a
positive pair, which is computationally demanding. In this paper, we propose a
different direction and a new loss function for self-supervised learning which
is based on the whitening of the latent-space features. The whitening operation
has a "scattering" effect on the batch samples, which compensates the use of
negatives, avoiding degenerate solutions where all the sample representations
collapse to a single point. Our Whitening MSE (W-MSE) loss does not require
special heuristics (e.g. additional networks) and it is conceptually simple.
Since negatives are not needed, we suggest obtaining multiple positive pairs
from one image in the batch. We show empirically that W-MSE is competitive with
respect to popular, more complex self-supervised methods. The source code of
the method and all the experiments is available at
https://github.com/htdt/self-supervised.
</p>
<a href="http://arxiv.org/abs/2007.06346" target="_blank">arXiv:2007.06346</a> [<a href="http://arxiv.org/pdf/2007.06346" target="_blank">pdf</a>]

<h2>Speech2Video Synthesis with 3D Skeleton Regularization and Expressive Body Poses. (arXiv:2007.09198v4 [cs.CV] UPDATED)</h2>
<h3>Sibo Zhang, Miao Liao, Peng Wang, Hao Zhu, Xinxin Zuo, Ruigang Yang</h3>
<p>In this paper, we propose a novel approach to convert given speech audio to a
photo-realistic speaking video of a specific person, where the output video has
synchronized, realistic, and expressive rich body dynamics. We achieve this by
first generating 3D skeleton movements from the audio sequence using a
recurrent neural network (RNN), and then synthesizing the output video via a
conditional generative adversarial network (GAN). To make the skeleton movement
realistic and expressive, we embed the knowledge of an articulated 3D human
skeleton and a learned dictionary of personal speech iconic gestures into the
generation process in both learning and testing pipelines. The former prevents
the generation of unreasonable body distortion, while the later helps our model
quickly learn meaningful body movement through a few recorded videos. To
produce photo-realistic and high-resolution video with motion details, we
propose to insert part attention mechanisms in the conditional GAN, where each
detailed part, e.g. head and hand, is automatically zoomed in to have their own
discriminators. To validate our approach, we collect a dataset with 20
high-quality videos from 1 male and 1 female model reading various documents
under different topics. Compared with previous SoTA pipelines handling similar
tasks, our approach achieves better results by a user study.
</p>
<a href="http://arxiv.org/abs/2007.09198" target="_blank">arXiv:2007.09198</a> [<a href="http://arxiv.org/pdf/2007.09198" target="_blank">pdf</a>]

<h2>MIX'EM: Unsupervised Image Classification using a Mixture of Embeddings. (arXiv:2007.09502v2 [cs.CV] UPDATED)</h2>
<h3>Ali Varamesh, Tinne Tuytelaars</h3>
<p>We present MIX'EM, a novel solution for unsupervised image classification.
MIX'EM generates representations that by themselves are sufficient to drive a
general-purpose clustering algorithm to deliver high-quality classification.
This is accomplished by building a mixture of embeddings module into a
contrastive visual representation learning framework in order to disentangle
representations at the category level. It first generates a set of embedding
and mixing coefficients from a given visual representation, and then combines
them into a single embedding. We introduce three techniques to successfully
train MIX'EM and avoid degenerate solutions; (i) diversify mixture components
by maximizing entropy, (ii) minimize instance conditioned component entropy to
enforce a clustered embedding space, and (iii) use an associative embedding
loss to enforce semantic separability. By applying (i) and (ii), semantic
categories emerge through the mixture coefficients, making it possible to apply
(iii). Subsequently, we run K-means on the representations to acquire semantic
classification. We conduct extensive experiments and analyses on STL10,
CIFAR10, and CIFAR100-20 datasets, achieving state-of-the-art classification
accuracy of 78\%, 82\%, and 44\%, respectively. To achieve robust and high
accuracy, it is essential to use the mixture components to initialize K-means.
Finally, we report competitive baselines (70\% on STL10) obtained by applying
K-means to the "normalized" representations learned using the contrastive loss.
</p>
<a href="http://arxiv.org/abs/2007.09502" target="_blank">arXiv:2007.09502</a> [<a href="http://arxiv.org/pdf/2007.09502" target="_blank">pdf</a>]

<h2>Off-Policy Multi-Agent Decomposed Policy Gradients. (arXiv:2007.12322v2 [cs.LG] UPDATED)</h2>
<h3>Yihan Wang, Beining Han, Tonghan Wang, Heng Dong, Chongjie Zhang</h3>
<p>Multi-agent policy gradient (MAPG) methods recently witness vigorous
progress. However, there is a significant performance discrepancy between MAPG
methods and state-of-the-art multi-agent value-based approaches. In this paper,
we investigate causes that hinder the performance of MAPG algorithms and
present a multi-agent decomposed policy gradient method (DOP). This method
introduces the idea of value function decomposition into the multi-agent
actor-critic framework. Based on this idea, DOP supports efficient off-policy
learning and addresses the issue of centralized-decentralized mismatch and
credit assignment in both discrete and continuous action spaces. We formally
show that DOP critics have sufficient representational capability to guarantee
convergence. In addition, empirical evaluations on the StarCraft II
micromanagement benchmark and multi-agent particle environments demonstrate
that DOP significantly outperforms both state-of-the-art value-based and
policy-based multi-agent reinforcement learning algorithms. Demonstrative
videos are available at https://sites.google.com/view/dop-mapg/.
</p>
<a href="http://arxiv.org/abs/2007.12322" target="_blank">arXiv:2007.12322</a> [<a href="http://arxiv.org/pdf/2007.12322" target="_blank">pdf</a>]

<h2>Visual Compositional Learning for Human-Object Interaction Detection. (arXiv:2007.12407v2 [cs.CV] UPDATED)</h2>
<h3>Zhi Hou, Xiaojiang Peng, Yu Qiao, Dacheng Tao</h3>
<p>Human-Object interaction (HOI) detection aims to localize and infer
relationships between human and objects in an image. It is challenging because
an enormous number of possible combinations of objects and verbs types forms a
long-tail distribution. We devise a deep Visual Compositional Learning (VCL)
framework, which is a simple yet efficient framework to effectively address
this problem. VCL first decomposes an HOI representation into object and verb
specific features, and then composes new interaction samples in the feature
space via stitching the decomposed features. The integration of decomposition
and composition enables VCL to share object and verb features among different
HOI samples and images, and to generate new interaction samples and new types
of HOI, and thus largely alleviates the long-tail distribution problem and
benefits low-shot or zero-shot HOI detection. Extensive experiments demonstrate
that the proposed VCL can effectively improve the generalization of HOI
detection on HICO-DET and V-COCO and outperforms the recent state-of-the-art
methods on HICO-DET. Code is available at https://github.com/zhihou7/VCL.
</p>
<a href="http://arxiv.org/abs/2007.12407" target="_blank">arXiv:2007.12407</a> [<a href="http://arxiv.org/pdf/2007.12407" target="_blank">pdf</a>]

<h2>Kernel Methods and their derivatives: Concept and perspectives for the Earth system sciences. (arXiv:2007.14706v2 [cs.LG] UPDATED)</h2>
<h3>J. Emmanuel Johnson, Valero Laparra, Adri&#xe1;n P&#xe9;rez-Suay, Miguel D. Mahecha, Gustau Camps-Valls</h3>
<p>Kernel methods are powerful machine learning techniques which implement
generic non-linear functions to solve complex tasks in a simple way. They Have
a solid mathematical background and exhibit excellent performance in practice.
However, kernel machines are still considered black-box models as the feature
mapping is not directly accessible and difficult to interpret.The aim of this
work is to show that it is indeed possible to interpret the functions learned
by various kernel methods is intuitive despite their complexity. Specifically,
we show that derivatives of these functions have a simple mathematical
formulation, are easy to compute, and can be applied to many different
problems. We note that model function derivatives in kernel machines is
proportional to the kernel function derivative. We provide the explicit
analytic form of the first and second derivatives of the most common kernel
functions with regard to the inputs as well as generic formulas to compute
higher order derivatives. We use them to analyze the most used supervised and
unsupervised kernel learning methods: Gaussian Processes for regression,
Support Vector Machines for classification, Kernel Entropy Component Analysis
for density estimation, and the Hilbert-Schmidt Independence Criterion for
estimating the dependency between random variables. For all cases we expressed
the derivative of the learned function as a linear combination of the kernel
function derivative. Moreover we provide intuitive explanations through
illustrative toy examples and show how to improve the interpretation of real
applications in the context of spatiotemporal Earth system data cubes. This
work reflects on the observation that function derivatives may play a crucial
role in kernel methods analysis and understanding.
</p>
<a href="http://arxiv.org/abs/2007.14706" target="_blank">arXiv:2007.14706</a> [<a href="http://arxiv.org/pdf/2007.14706" target="_blank">pdf</a>]

<h2>QPLEX: Duplex Dueling Multi-Agent Q-Learning. (arXiv:2008.01062v2 [cs.LG] UPDATED)</h2>
<h3>Jianhao Wang, Zhizhou Ren, Terry Liu, Yang Yu, Chongjie Zhang</h3>
<p>We explore value-based multi-agent reinforcement learning (MARL) in the
popular paradigm of centralized training with decentralized execution (CTDE).
CTDE has an important concept, Individual-Global-Max (IGM) principle, which
requires the consistency between joint and local action selections to support
efficient local decision-making. However, in order to achieve scalability,
existing MARL methods either limit representation expressiveness of their value
function classes or relax the IGM consistency, which may suffer from
instability risk or lead to poor performance. This paper presents a novel MARL
approach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a
duplex dueling network architecture to factorize the joint value function. This
duplex dueling structure encodes the IGM principle into the neural network
architecture and thus enables efficient value function learning. Theoretical
analysis shows that QPLEX achieves a complete IGM function class. Empirical
experiments on StarCraft II micromanagement tasks demonstrate that QPLEX
significantly outperforms state-of-the-art baselines in both online and offline
data collection settings, and also reveal that QPLEX achieves high sample
efficiency and can benefit from offline datasets without additional online
exploration.
</p>
<a href="http://arxiv.org/abs/2008.01062" target="_blank">arXiv:2008.01062</a> [<a href="http://arxiv.org/pdf/2008.01062" target="_blank">pdf</a>]

<h2>Data Cleansing with Contrastive Learning for Vocal Note Event Annotations. (arXiv:2008.02069v2 [cs.LG] UPDATED)</h2>
<h3>Gabriel Meseguer-Brocal, Rachel Bittner, Simon Durand, Brian Brost</h3>
<p>Data cleansing is a well studied strategy for cleaning erroneous labels in
datasets, which has not yet been widely adopted in Music Information Retrieval.
Previously proposed data cleansing models do not consider structured (e.g. time
varying) labels, such as those common to music data. We propose a novel data
cleansing model for time-varying, structured labels which exploits the local
structure of the labels, and demonstrate its usefulness for vocal note event
annotations in music. %Our model is trained in a contrastive learning manner by
automatically creating local deformations of likely correct labels. Our model
is trained in a contrastive learning manner by automatically contrasting likely
correct labels pairs against local deformations of them. We demonstrate that
the accuracy of a transcription model improves greatly when trained using our
proposed strategy compared with the accuracy when trained using the original
dataset. Additionally we use our model to estimate the annotation error rates
in the DALI dataset, and highlight other potential uses for this type of model.
</p>
<a href="http://arxiv.org/abs/2008.02069" target="_blank">arXiv:2008.02069</a> [<a href="http://arxiv.org/pdf/2008.02069" target="_blank">pdf</a>]

<h2>A Flow-Guided Mutual Attention Network for Video-Based Person Re-Identification. (arXiv:2008.03788v2 [cs.CV] UPDATED)</h2>
<h3>Madhu Kiran, Amran Bhuiyan, Louis-Antoine Blais-Morin, Mehrsan Javan, Ismail Ben Ayed, Eric Granger</h3>
<p>Person Re-Identification (ReID) is a challenging problem in many video
analytics and surveillance applications, where a person's identity must be
associated across a distributed non-overlapping network of cameras. Video-based
person ReID has recently gained much interest because it allows capturing
discriminant spatio-temporal information from video clips that is unavailable
for image-based ReID. Despite recent advances, deep learning (DL) models for
video ReID often fail to leverage this information to improve the robustness of
feature representations. In this paper, the motion pattern of a person is
explored as an additional cue for ReID. In particular, a flow-guided Mutual
Attention network is proposed for fusion of image and optical flow sequences
using any 2D-CNN backbone, allowing to encode temporal information along with
spatial appearance information. Our Mutual Attention network relies on the
joint spatial attention between image and optical flow features maps to
activate a common set of salient features across them. In addition to
flow-guided attention, we introduce a method to aggregate features from longer
input streams for better video sequence-level representation. Our extensive
experiments on three challenging video ReID datasets indicate that using the
proposed Mutual Attention network allows to improve recognition accuracy
considerably with respect to conventional gated-attention networks, and
state-of-the-art methods for video-based person ReID.
</p>
<a href="http://arxiv.org/abs/2008.03788" target="_blank">arXiv:2008.03788</a> [<a href="http://arxiv.org/pdf/2008.03788" target="_blank">pdf</a>]

<h2>Unsupervised Feature Learning by Cross-Level Discrimination between Instances and Groups. (arXiv:2008.03813v3 [cs.CV] UPDATED)</h2>
<h3>Xudong Wang, Ziwei Liu, Stella X. Yu</h3>
<p>Unsupervised feature learning has made great strides with invariant mapping
and instance-level discrimination, as benchmarked by classification on common
datasets. However, these datasets are curated to be distinctive and
class-balanced, whereas naturally collected data could be highly correlated
within the class (with repeats at the extreme) and long-tail distributed across
classes. The natural grouping of instances conflicts with the fundamental
assumption of instance-level discrimination. Contrastive feature learning is
thus unstable without grouping, whereas grouping without contrastive feature
learning is easily trapped into degeneracy.

We propose to integrate grouping into instance-level discrimination, not by
imposing group-level discrimination, but by imposing cross-level discrimination
between instances and groups. Our key insight is that grouping results from not
just attraction, but also repulsion. While invariant mapping is achieved by
local attraction between augmented instances, instance similarity emerges from
long-range repulsion against common instance groups. To further avoid the clash
between grouping and discrimination objectives, we also impose them on separate
features derived from the common feature.

Our extensive experimentation demonstrates not only significant gain on
datasets with high correlation and long-tail distributions, but also leading
performance on multiple self-supervision and semi-supervision benchmarks,
bringing unsupervised feature learning closer to real data applications.
</p>
<a href="http://arxiv.org/abs/2008.03813" target="_blank">arXiv:2008.03813</a> [<a href="http://arxiv.org/pdf/2008.03813" target="_blank">pdf</a>]

<h2>Neural Network-based Automatic Factor Construction. (arXiv:2008.06225v2 [q-fin.ST] UPDATED)</h2>
<h3>Jie Fang, Jianwu Lin, Shutao Xia, Yong Jiang, Zhikang Xia, Xiang Liu</h3>
<p>Instead of conducting manual factor construction based on traditional and
behavioural finance analysis, academic researchers and quantitative investment
managers have leveraged Genetic Programming (GP) as an automatic feature
construction tool in recent years, which builds reverse polish mathematical
expressions from trading data into new factors. However, with the development
of deep learning, more powerful feature extraction tools are available. This
paper proposes Neural Network-based Automatic Factor Construction (NNAFC), a
tailored neural network framework that can automatically construct diversified
financial factors based on financial domain knowledge and a variety of neural
network structures. The experiment results show that NNAFC can construct more
informative and diversified factors than GP, to effectively enrich the current
factor pool. For the current market, both fully connected and recurrent neural
network structures are better at extracting information from financial time
series than convolution neural network structures. Moreover, new factors
constructed by NNAFC can always improve the return, Sharpe ratio, and the max
draw-down of a multi-factor quantitative investment strategy due to their
introducing more information and diversification to the existing factor pool.
</p>
<a href="http://arxiv.org/abs/2008.06225" target="_blank">arXiv:2008.06225</a> [<a href="http://arxiv.org/pdf/2008.06225" target="_blank">pdf</a>]

<h2>From Lost to Found: Discover Missing UI Design Semantics through Recovering Missing Tags. (arXiv:2008.06895v2 [cs.HC] UPDATED)</h2>
<h3>Chunyang Chen, Sidong Feng, Zhengyang Liu, Zhenchang Xing, Shengdong Zhao</h3>
<p>Design sharing sites provide UI designers with a platform to share their
works and also an opportunity to get inspiration from others' designs. To
facilitate management and search of millions of UI design images, many design
sharing sites adopt collaborative tagging systems by distributing the work of
categorization to the community. However, designers often do not know how to
properly tag one design image with compact textual description, resulting in
unclear, incomplete, and inconsistent tags for uploaded examples which impede
retrieval, according to our empirical study and interview with four
professional designers. Based on a deep neural network, we introduce a novel
approach for encoding both the visual and textual information to recover the
missing tags for existing UI examples so that they can be more easily found by
text queries. We achieve 82.72% accuracy in the tag prediction. Through a
simulation test of 5 queries, our system on average returns hundreds more
results than the default Dribbble search, leading to better relatedness,
diversity and satisfaction.
</p>
<a href="http://arxiv.org/abs/2008.06895" target="_blank">arXiv:2008.06895</a> [<a href="http://arxiv.org/pdf/2008.06895" target="_blank">pdf</a>]

<h2>Transductive Information Maximization For Few-Shot Learning. (arXiv:2008.11297v2 [cs.LG] UPDATED)</h2>
<h3>Malik Boudiaf, Ziko Imtiaz Masud, J&#xe9;r&#xf4;me Rony, Jos&#xe9; Dolz, Pablo Piantanida, Ismail Ben Ayed</h3>
<p>We introduce Transductive Infomation Maximization (TIM) for few-shot
learning.Our method maximizes the mutual information between the query features
andpredictions of a few-shot task, subject to supervision constraints from the
supportset. Furthermore, we propose a new alternating direction solver for our
mutual-information loss, which substantially speeds up transductive-inference
convergenceover gradient-based optimization, while demonstrating similar
accuracy perfor-mance. Following standard few-shot settings, our comprehensive
experiments2demonstrate that TIM outperforms state-of-the-art methods
significantly acrossall datasets and networks, while using simple cross-entropy
training on the baseclasses, without resorting to complex meta-learning
schemes. It consistently bringsbetween2%to5%improvement in accuracy over the
best performing methods notonly on all the well-established few-shot
benchmarks, but also on more challengingscenarios, with domain shifts and
larger number of classes.
</p>
<a href="http://arxiv.org/abs/2008.11297" target="_blank">arXiv:2008.11297</a> [<a href="http://arxiv.org/pdf/2008.11297" target="_blank">pdf</a>]

<h2>A Survey of Evaluation Metrics Used for NLG Systems. (arXiv:2008.12009v2 [cs.CL] UPDATED)</h2>
<h3>Ananya B. Sai, Akash Kumar Mohankumar, Mitesh M. Khapra</h3>
<p>The success of Deep Learning has created a surge in interest in a wide a
range of Natural Language Generation (NLG) tasks. Deep Learning has not only
pushed the state of the art in several existing NLG tasks but has also
facilitated researchers to explore various newer NLG tasks such as image
captioning. Such rapid progress in NLG has necessitated the development of
accurate automatic evaluation metrics that would allow us to track the progress
in the field of NLG. However, unlike classification tasks, automatically
evaluating NLG systems in itself is a huge challenge. Several works have shown
that early heuristic-based metrics such as BLEU, ROUGE are inadequate for
capturing the nuances in the different NLG tasks. The expanding number of NLG
models and the shortcomings of the current metrics has led to a rapid surge in
the number of evaluation metrics proposed since 2014. Moreover, various
evaluation metrics have shifted from using pre-determined heuristic-based
formulae to trained transformer models. This rapid change in a relatively short
time has led to the need for a survey of the existing NLG metrics to help
existing and new researchers to quickly come up to speed with the developments
that have happened in NLG evaluation in the last few years. Through this
survey, we first wish to highlight the challenges and difficulties in
automatically evaluating NLG systems. Then, we provide a coherent taxonomy of
the evaluation metrics to organize the existing metrics and to better
understand the developments in the field. We also describe the different
metrics in detail and highlight their key contributions. Later, we discuss the
main shortcomings identified in the existing metrics and describe the
methodology used to evaluate evaluation metrics. Finally, we discuss our
suggestions and recommendations on the next steps forward to improve the
automatic evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2008.12009" target="_blank">arXiv:2008.12009</a> [<a href="http://arxiv.org/pdf/2008.12009" target="_blank">pdf</a>]

<h2>Sample-Efficient Automated Deep Reinforcement Learning. (arXiv:2009.01555v2 [cs.LG] UPDATED)</h2>
<h3>J&#xf6;rg K.H. Franke, Gregor K&#xf6;hler, Andr&#xe9; Biedenkapp, Frank Hutter</h3>
<p>Despite significant progress in challenging problems across various domains,
applying state-of-the-art deep reinforcement learning (RL) algorithms remains
challenging due to their sensitivity to the choice of hyperparameters. This
sensitivity can partly be attributed to the non-stationarity of the RL problem,
potentially requiring different hyperparameter settings at various stages of
the learning process. Additionally, in the RL setting, hyperparameter
optimization (HPO) requires a large number of environment interactions,
hindering the transfer of the successes in RL to real-world applications. In
this work, we tackle the issues of sample-efficient and dynamic HPO in RL. We
propose a population-based automated RL (AutoRL) framework to meta-optimize
arbitrary off-policy RL algorithms. In this framework, we optimize the
hyperparameters and also the neural architecture while simultaneously training
the agent. By sharing the collected experience across the population, we
substantially increase the sample efficiency of the meta-optimization. We
demonstrate the capabilities of our sample-efficient AutoRL approach in a case
study with the popular TD3 algorithm in the MuJoCo benchmark suite, where we
reduce the number of environment interactions needed for meta-optimization by
up to an order of magnitude compared to population-based training.
</p>
<a href="http://arxiv.org/abs/2009.01555" target="_blank">arXiv:2009.01555</a> [<a href="http://arxiv.org/pdf/2009.01555" target="_blank">pdf</a>]

<h2>Information Theoretic Meta Learning with Gaussian Processes. (arXiv:2009.03228v2 [cs.LG] UPDATED)</h2>
<h3>Michalis K. Titsias, Sotirios Nikoloutsopoulos, Alexandre Galashov</h3>
<p>We formulate meta learning using information theoretic concepts such as
mutual information and the information bottleneck. The idea is to learn a
stochastic representation or encoding of the task description, given by a
training or support set, that is highly informative about predicting the
validation set. By making use of variational approximations to the mutual
information, we derive a general and tractable framework for meta learning. We
particularly develop new memory-based meta learning algorithms based on
Gaussian processes and derive extensions that combine memory and gradient-based
meta learning. We demonstrate our method on few-shot regression and
classification by using standard benchmarks such as Omniglot, mini-Imagenet and
Augmented Omniglot.
</p>
<a href="http://arxiv.org/abs/2009.03228" target="_blank">arXiv:2009.03228</a> [<a href="http://arxiv.org/pdf/2009.03228" target="_blank">pdf</a>]

<h2>Systematic Generalization on gSCAN with Language Conditioned Embedding. (arXiv:2009.05552v2 [cs.AI] UPDATED)</h2>
<h3>Tong Gao, Qi Huang, Raymond J. Mooney</h3>
<p>Systematic Generalization refers to a learning algorithm's ability to
extrapolate learned behavior to unseen situations that are distinct but
semantically similar to its training data. As shown in recent work,
state-of-the-art deep learning models fail dramatically even on tasks for which
they are designed when the test set is systematically different from the
training data. We hypothesize that explicitly modeling the relations between
objects in their contexts while learning their representations will help
achieve systematic generalization. Therefore, we propose a novel method that
learns objects' contextualized embeddings with dynamic message passing
conditioned on the input natural language and end-to-end trainable with other
downstream deep learning modules. To our knowledge, this model is the first one
that significantly outperforms the provided baseline and reaches
state-of-the-art performance on grounded-SCAN (gSCAN), a grounded natural
language navigation dataset designed to require systematic generalization in
its test splits.
</p>
<a href="http://arxiv.org/abs/2009.05552" target="_blank">arXiv:2009.05552</a> [<a href="http://arxiv.org/pdf/2009.05552" target="_blank">pdf</a>]

<h2>Neither Private Nor Fair: Impact of Data Imbalance on Utility and Fairness in Differential Privacy. (arXiv:2009.06389v3 [cs.LG] UPDATED)</h2>
<h3>Tom Farrand, Fatemehsadat Mireshghallah, Sahib Singh, Andrew Trask</h3>
<p>Deployment of deep learning in different fields and industries is growing day
by day due to its performance, which relies on the availability of data and
compute. Data is often crowd-sourced and contains sensitive information about
its contributors, which leaks into models that are trained on it. To achieve
rigorous privacy guarantees, differentially private training mechanisms are
used. However, it has recently been shown that differential privacy can
exacerbate existing biases in the data and have disparate impacts on the
accuracy of different subgroups of data. In this paper, we aim to study these
effects within differentially private deep learning. Specifically, we aim to
study how different levels of imbalance in the data affect the accuracy and the
fairness of the decisions made by the model, given different levels of privacy.
We demonstrate that even small imbalances and loose privacy guarantees can
cause disparate impacts.
</p>
<a href="http://arxiv.org/abs/2009.06389" target="_blank">arXiv:2009.06389</a> [<a href="http://arxiv.org/pdf/2009.06389" target="_blank">pdf</a>]

<h2>The Importance of Pessimism in Fixed-Dataset Policy Optimization. (arXiv:2009.06799v2 [cs.AI] UPDATED)</h2>
<h3>Jacob Buckman, Carles Gelada, Marc G. Bellemare</h3>
<p>We study worst-case guarantees on the expected return of fixed-dataset policy
optimization algorithms. Our core contribution is a unified conceptual and
mathematical framework for the study of algorithms in this regime. This
analysis reveals that for naive approaches, the possibility of erroneous value
overestimation leads to a difficult-to-satisfy requirement: in order to
guarantee that we select a policy which is near-optimal, we may need the
dataset to be informative of the value of every policy. To avoid this,
algorithms can follow the pessimism principle, which states that we should
choose the policy which acts optimally in the worst possible world. We show why
pessimistic algorithms can achieve good performance even when the dataset is
not informative of every policy, and derive families of algorithms which follow
this principle. These theoretical findings are validated by experiments on a
tabular gridworld, and deep learning experiments on four MinAtar environments.
</p>
<a href="http://arxiv.org/abs/2009.06799" target="_blank">arXiv:2009.06799</a> [<a href="http://arxiv.org/pdf/2009.06799" target="_blank">pdf</a>]

<h2>Scaffold-constrained molecular generation. (arXiv:2009.07778v3 [q-bio.QM] UPDATED)</h2>
<h3>Maxime Langevin, Herve Minoux, Maximilien Levesque, Marc Bianciotto</h3>
<p>One of the major applications of generative models for drug Discovery targets
the lead-optimization phase. During the optimization of a lead series, it is
common to have scaffold constraints imposed on the structure of the molecules
designed. Without enforcing such constraints, the probability of generating
molecules with the required scaffold is extremely low and hinders the
practicality of generative models for de-novo drug design. To tackle this
issue, we introduce a new algorithm to perform scaffold-constrained in-silico
molecular design. We build on the well-known SMILES-based Recurrent Neural
Network (RNN) generative model, with a modified sampling procedure to achieve
scaffold-constrained generation. We directly benefit from the associated
reinforcement Learning methods, allowing to design molecules optimized for
different properties while exploring only the relevant chemical space. We
showcase the method's ability to perform scaffold-constrained generation on
various tasks: designing novel molecules around scaffolds extracted from
SureChEMBL chemical series, generating novel active molecules on the Dopamine
Receptor D2 (DRD2) target, and, finally, designing predicted actives on the
MMP-12 series, an industrial lead-optimization project.
</p>
<a href="http://arxiv.org/abs/2009.07778" target="_blank">arXiv:2009.07778</a> [<a href="http://arxiv.org/pdf/2009.07778" target="_blank">pdf</a>]

<h2>Finding Effective Security Strategies through Reinforcement Learning and Self-Play. (arXiv:2009.08120v2 [cs.LG] UPDATED)</h2>
<h3>Kim Hammar, Rolf Stadler</h3>
<p>We present a method to automatically find security strategies for the use
case of intrusion prevention. Following this method, we model the interaction
between an attacker and a defender as a Markov game and let attack and defense
strategies evolve through reinforcement learning and self-play without human
intervention. Using a simple infrastructure configuration, we demonstrate that
effective security strategies can emerge from self-play. This shows that
self-play, which has been applied in other domains with great success, can be
effective in the context of network security. Inspection of the converged
policies show that the emerged policies reflect common-sense knowledge and are
similar to strategies of humans. Moreover, we address known challenges of
reinforcement learning in this domain and present an approach that uses
function approximation, an opponent pool, and an autoregressive policy
representation. Through evaluations we show that our method is superior to two
baseline methods but that policy convergence in self-play remains a challenge.
</p>
<a href="http://arxiv.org/abs/2009.08120" target="_blank">arXiv:2009.08120</a> [<a href="http://arxiv.org/pdf/2009.08120" target="_blank">pdf</a>]

<h2>Review: Deep Learning in Electron Microscopy. (arXiv:2009.08328v3 [eess.IV] UPDATED)</h2>
<h3>Jeffrey M. Ede</h3>
<p>Deep learning is transforming most areas of science and technology, including
electron microscopy. This review paper offers a practical perspective aimed at
developers with limited familiarity. For context, we review popular
applications of deep learning in electron microscopy. Following, we discuss
hardware and software needed to get started with deep learning and interface
with electron microscopes. We then review neural network components, popular
architectures, and their optimization. Finally, we discuss future directions of
deep learning in electron microscopy.
</p>
<a href="http://arxiv.org/abs/2009.08328" target="_blank">arXiv:2009.08328</a> [<a href="http://arxiv.org/pdf/2009.08328" target="_blank">pdf</a>]

<h2>F^2-Softmax: Diversifying Neural Text Generation via Frequency Factorized Softmax. (arXiv:2009.09417v2 [cs.CL] UPDATED)</h2>
<h3>Byung-Ju Choi, Jimin Hong, David Keetae Park, Sang Wan Lee</h3>
<p>Despite recent advances in neural text generation, encoding the rich
diversity in human language remains elusive. We argue that the sub-optimal text
generation is mainly attributable to the imbalanced token distribution, which
particularly misdirects the learning model when trained with the
maximum-likelihood objective. As a simple yet effective remedy, we propose two
novel methods, F^2-Softmax and MefMax, for a balanced training even with the
skewed frequency distribution. MefMax assigns tokens uniquely to frequency
classes, trying to group tokens with similar frequencies and equalize frequency
mass between the classes. F^2-Softmax then decomposes a probability
distribution of the target token into a product of two conditional
probabilities of (i) frequency class, and (ii) token from the target frequency
class. Models learn more uniform probability distributions because they are
confined to subsets of vocabularies. Significant performance gains on seven
relevant metrics suggest the supremacy of our approach in improving not only
the diversity but also the quality of generated texts.
</p>
<a href="http://arxiv.org/abs/2009.09417" target="_blank">arXiv:2009.09417</a> [<a href="http://arxiv.org/pdf/2009.09417" target="_blank">pdf</a>]

<h2>Persian Ezafe Recognition Using Transformers and Its Role in Part-Of-Speech Tagging. (arXiv:2009.09474v2 [cs.CL] UPDATED)</h2>
<h3>Ehsan Doostmohammadi, Minoo Nassajian, Adel Rahimi</h3>
<p>Ezafe is a grammatical particle in some Iranian languages that links two
words together. Regardless of the important information it conveys, it is
almost always not indicated in Persian script, resulting in mistakes in reading
complex sentences and errors in natural language processing tasks. In this
paper, we experiment with different machine learning methods to achieve
state-of-the-art results in the task of ezafe recognition. Transformer-based
methods, BERT and XLMRoBERTa, achieve the best results, the latter achieving
2.68% F1-score more than the previous state-of-the-art. We, moreover, use ezafe
information to improve Persian part-of-speech tagging results and show that
such information will not be useful to transformer-based methods and explain
why that might be the case.
</p>
<a href="http://arxiv.org/abs/2009.09474" target="_blank">arXiv:2009.09474</a> [<a href="http://arxiv.org/pdf/2009.09474" target="_blank">pdf</a>]

<h2>Energy-based Surprise Minimization for Multi-Agent Value Factorization. (arXiv:2009.09842v3 [cs.LG] UPDATED)</h2>
<h3>Karush Suri, Xiao Qi Shi, Konstantinos Plataniotis, Yuri Lawryshyn</h3>
<p>Multi-Agent Reinforcement Learning (MARL) has demonstrated significant
success in training decentralised policies in a centralised manner by making
use of value factorization methods. However, addressing surprise across
spurious states and approximation bias remain open problems for multi-agent
settings. We introduce the Energy-based MIXer (EMIX), an algorithm which
minimizes surprise utilizing the energy across agents. Our contributions are
threefold; (1) EMIX introduces a novel surprise minimization technique across
multiple agents in the case of multi-agent partially-observable settings. (2)
EMIX highlights the first practical use of energy functions in MARL (to our
knowledge) with theoretical guarantees and experiment validations of the energy
operator. Lastly, (3) EMIX presents a novel technique for addressing
overestimation bias across agents in MARL. When evaluated on a range of
challenging StarCraft II micromanagement scenarios, EMIX demonstrates
consistent state-of-the-art performance for multi-agent surprise minimization.
Moreover, our ablation study highlights the necessity of the energy-based
scheme and the need for elimination of overestimation bias in MARL. Our
implementation of EMIX and videos of agents are available at
https://karush17.github.io/emix-web/.
</p>
<a href="http://arxiv.org/abs/2009.09842" target="_blank">arXiv:2009.09842</a> [<a href="http://arxiv.org/pdf/2009.09842" target="_blank">pdf</a>]

<h2>Learning a Contact-Adaptive Controller for Robust, Efficient Legged Locomotion. (arXiv:2009.10019v3 [cs.RO] UPDATED)</h2>
<h3>Xingye Da, Zhaoming Xie, David Hoeller, Byron Boots, Animashree Anandkumar, Yuke Zhu, Buck Babich, Animesh Garg</h3>
<p>We present a hierarchical framework that combines model-based control and
reinforcement learning (RL) to synthesize robust controllers for a quadruped
(the Unitree Laikago). The system consists of a high-level controller that
learns to choose from a set of primitives in response to changes in the
environment and a low-level controller that utilizes an established control
method to robustly execute the primitives. Our framework learns a controller
that can adapt to challenging environmental changes on the fly, including novel
scenarios not seen during training. The learned controller is up to 85~percent
more energy efficient and is more robust compared to baseline methods. We also
deploy the controller on a physical robot without any randomization or
adaptation scheme.
</p>
<a href="http://arxiv.org/abs/2009.10019" target="_blank">arXiv:2009.10019</a> [<a href="http://arxiv.org/pdf/2009.10019" target="_blank">pdf</a>]

<h2>The Ultimate DataFlow for Ultimate SuperComputers-on-a-Chips. (arXiv:2009.10593v2 [cs.DC] UPDATED)</h2>
<h3>Veljko Milutinovic, Milos Kotlar, Ivan Ratkovic, Nenad Korolija, Miljan Djordjevic, Kristy Yoshimoto, Erik Klem, Mateo Valero</h3>
<p>This article starts from the assumption that near future 100BTransistor
SuperComputers-on-a-Chip will include N big multi-core processors, 1000N small
many-core processors, a TPU-like fixed-structure systolic array accelerator for
the most frequently used Machine Learning algorithms needed in bandwidth-bound
applications and a flexible-structure reprogrammable accelerator for less
frequently used Machine Learning algorithms needed in latency-critical
applications.
</p>
<a href="http://arxiv.org/abs/2009.10593" target="_blank">arXiv:2009.10593</a> [<a href="http://arxiv.org/pdf/2009.10593" target="_blank">pdf</a>]

<h2>ReLeaSER: A Reinforcement Learning Strategy for Optimizing Utilization Of Ephemeral Cloud Resources. (arXiv:2009.11208v2 [cs.PF] UPDATED)</h2>
<h3>Mohamed Handaoui, Jean-Emile Dartois, Jalil Boukhobza, Olivier Barais, Laurent d&#x27;Orazio</h3>
<p>Cloud data center capacities are over-provisioned to handle demand peaks and
hardware failures which leads to low resources' utilization. One way to improve
resource utilization and thus reduce the total cost of ownership is to offer
the unused resources at a lower price. However, reselling resources needs to
meet the expectations of its customers in terms of Quality of Service. The goal
is so to maximize the amount of reclaimed resources while avoiding SLA
penalties. To achieve that, cloud providers have to estimate their future
utilization to provide availability guarantees. The prediction should consider
a safety margin of resources to react to unpredictable workloads. The challenge
is to find the safety margin that provides the best trade-off between the
amount of resources to reclaim and the risk of SLA violations. Most
state-of-the-art solutions consider a fixed safety margin for all types of
metrics (e.g., CPU, RAM). However, a unique fixed margin does not consider
various workloads variations over time which may lead to SLA violations or/and
poor utilization. In order to tackle these challenges, we propose ReLeaSER, a
Reinforcement Learning strategy for optimizing the ephemeral resources'
utilization in the cloud. ReLeaSER dynamically tunes the safety margin at the
host-level for each resource metric. The strategy learns from past prediction
errors (that caused SLA violations). Our solution reduces significantly the SLA
violation penalties on average by 2.7x and up to 3.4x. It also improves
considerably the CPs' potential savings by 27.6% on average and up to 43.6%.
</p>
<a href="http://arxiv.org/abs/2009.11208" target="_blank">arXiv:2009.11208</a> [<a href="http://arxiv.org/pdf/2009.11208" target="_blank">pdf</a>]

<h2>Deep multi-stations weather forecasting: explainable recurrent convolutional neural networks. (arXiv:2009.11239v3 [cs.LG] UPDATED)</h2>
<h3>Ismail Alaoui Abdellaoui, Siamak Mehrkanoon</h3>
<p>Deep learning applied to weather forecasting has started gaining popularity
because of the progress achieved by data-driven models. The present paper
compares four different deep learning architectures to perform weather
prediction on daily data gathered from 18 cities across Europe and spanned over
a period of 15 years. The four proposed models investigate the different type
of input representations (i.e. tensorial unistream vs. multi-stream matrices)
as well as the combination of convolutional neural networks and LSTM (i.e.
cascaded vs. ConvLSTM). In particular, we show that a model that uses a
multi-stream input representation and that processes each lag individually
combined with a cascaded convolution and LSTM is capable of better forecasting
than the other compared models. In addition, we show that visualization
techniques such as occlusion analysis and score maximization can give an
additional insight on the most important features and cities for predicting a
particular target feature and city.
</p>
<a href="http://arxiv.org/abs/2009.11239" target="_blank">arXiv:2009.11239</a> [<a href="http://arxiv.org/pdf/2009.11239" target="_blank">pdf</a>]

<h2>Task-Oriented Dialogue as Dataflow Synthesis. (arXiv:2009.11423v2 [cs.CL] UPDATED)</h2>
<h3>Semantic Machines, Jacob Andreas, John Bufe, David Burkett, Charles Chen, Josh Clausman, Jean Crawford, Kate Crim, Jordan DeLoach, Leah Dorner, Jason Eisner, Hao Fang, Alan Guo, David Hall, Kristin Hayes, Kellie Hill, Diana Ho, Wendy Iwaszuk, Smriti Jha, Dan Klein, Jayant Krishnamurthy, Theo Lanman, Percy Liang, Christopher H Lin, Ilya Lintsbakh, Andy McGovern, Aleksandr Nisnevich, Adam Pauls, Dmitrij Petters, Brent Read, Dan Roth, Subhro Roy, Jesse Rusak, Beth Short, Div Slomin, Ben Snyder, Stephon Striplin, Yu Su, Zachary Tellman, Sam Thomson, Andrei Vorobev, Izabela Witoszko, Jason Wolfe, Abby Wray, Yuchen Zhang, Alexander Zotov</h3>
<p>We describe an approach to task-oriented dialogue in which dialogue state is
represented as a dataflow graph. A dialogue agent maps each user utterance to a
program that extends this graph. Programs include metacomputation operators for
reference and revision that reuse dataflow fragments from previous turns. Our
graph-based state enables the expression and manipulation of complex user
intents, and explicit metacomputation makes these intents easier for learned
models to predict. We introduce a new dataset, SMCalFlow, featuring complex
dialogues about events, weather, places, and people. Experiments show that
dataflow graphs and metacomputation substantially improve representability and
predictability in these natural dialogues. Additional experiments on the
MultiWOZ dataset show that our dataflow representation enables an otherwise
off-the-shelf sequence-to-sequence model to match the best existing
task-specific state tracking model. The SMCalFlow dataset and code for
replicating experiments are available at
https://www.microsoft.com/en-us/research/project/dataflow-based-dialogue-semantic-machines.
</p>
<a href="http://arxiv.org/abs/2009.11423" target="_blank">arXiv:2009.11423</a> [<a href="http://arxiv.org/pdf/2009.11423" target="_blank">pdf</a>]

<h2>Privacy-preserving Transfer Learning via Secure Maximum Mean Discrepancy. (arXiv:2009.11680v2 [cs.LG] UPDATED)</h2>
<h3>Bin Zhang, Cen Chen, Li Wang</h3>
<p>The success of machine learning algorithms often relies on a large amount of
high-quality data to train well-performed models. However, data is a valuable
resource and are always held by different parties in reality. An effective
solution to such a data isolation problem is to employ federated learning,
which allows multiple parties to collaboratively train a model. In this paper,
we propose a Secure version of the widely used Maximum Mean Discrepancy (SMMD)
based on homomorphic encryption to enable effective knowledge transfer under
the data federation setting without compromising the data privacy. The proposed
SMMD is able to avoid the potential information leakage in transfer learning
when aligning the source and target data distribution. As a result, both the
source domain and target domain can fully utilize their data to build more
scalable models. Experimental results demonstrate that our proposed SMMD is
secure and effective.
</p>
<a href="http://arxiv.org/abs/2009.11680" target="_blank">arXiv:2009.11680</a> [<a href="http://arxiv.org/pdf/2009.11680" target="_blank">pdf</a>]

<h2>Joint coded aperture optimization and compressive hyperspectral image classification using 3D coded neural network. (arXiv:2009.11948v2 [eess.IV] UPDATED)</h2>
<h3>Hao Zhang</h3>
<p>Hyperspectral image classification (HIC) is an active research topic in
remote sensing. However, the huge volume of three-dimensional (3D)
hyperspectral images poses big challenges in data acquisition, storage,
transmission and processing. To overcome these limitations, this paper develops
a novel deep learning HIC approach based on the compressive measurements of
coded-aperture snapshot spectral imaging (CASSI) system, without reconstructing
the complete hyperspectral data cube. A new kind of deep learning strategy,
namely 3D coded convolutional neural network (3D-CCNN) is proposed to
efficiently solve for the HIC problem, where the hardware-based coded aperture
is regarded as a pixel-wise connected network layer. An end-to-end training
method is developed to jointly optimize the network parameters and the coded
aperture pattern with periodic structure. The accuracy of HIC approach is
effectively improved by involving the degrees of optimization freedom from the
coded aperture. The superiority of the proposed method is assessed on some
public hyperspectral datasets over the state-of-the-art HIC methods.
</p>
<a href="http://arxiv.org/abs/2009.11948" target="_blank">arXiv:2009.11948</a> [<a href="http://arxiv.org/pdf/2009.11948" target="_blank">pdf</a>]

<h2>Learning to Plan and Realize Separately for Open-Ended Dialogue Systems. (arXiv:2009.12506v2 [cs.CL] UPDATED)</h2>
<h3>Sashank Santhanam, Zhuo Cheng, Brodie Mather, Bonnie Dorr, Archna Bhatia, Bryanna Hebenstreit, Alan Zemel, Adam Dalton, Tomek Strzalkowski, Samira Shaikh</h3>
<p>Achieving true human-like ability to conduct a conversation remains an
elusive goal for open-ended dialogue systems. We posit this is because extant
approaches towards natural language generation (NLG) are typically construed as
end-to-end architectures that do not adequately model human generation
processes. To investigate, we decouple generation into two separate phases:
planning and realization. In the planning phase, we train two planners to
generate plans for response utterances. The realization phase uses response
plans to produce an appropriate response. Through rigorous evaluations, both
automated and human, we demonstrate that decoupling the process into planning
and realization performs better than an end-to-end approach.
</p>
<a href="http://arxiv.org/abs/2009.12506" target="_blank">arXiv:2009.12506</a> [<a href="http://arxiv.org/pdf/2009.12506" target="_blank">pdf</a>]

<h2>Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect. (arXiv:2009.12991v3 [cs.CV] UPDATED)</h2>
<h3>Kaihua Tang, Jianqiang Huang, Hanwang Zhang</h3>
<p>As the class size grows, maintaining a balanced dataset across many classes
is challenging because the data are long-tailed in nature; it is even
impossible when the sample-of-interest co-exists with each other in one
collectable unit, e.g., multiple visual instances in one image. Therefore,
long-tailed classification is the key to deep learning at scale. However,
existing methods are mainly based on re-weighting/re-sampling heuristics that
lack a fundamental theory. In this paper, we establish a causal inference
framework, which not only unravels the whys of previous methods, but also
derives a new principled solution. Specifically, our theory shows that the SGD
momentum is essentially a confounder in long-tailed classification. On one
hand, it has a harmful causal effect that misleads the tail prediction biased
towards the head. On the other hand, its induced mediation also benefits the
representation learning and head prediction. Our framework elegantly
disentangles the paradoxical effects of the momentum, by pursuing the direct
causal effect caused by an input sample. In particular, we use causal
intervention in training, and counterfactual reasoning in inference, to remove
the "bad" while keep the "good". We achieve new state-of-the-arts on three
long-tailed visual recognition benchmarks: Long-tailed CIFAR-10/-100,
ImageNet-LT for image classification and LVIS for instance segmentation.
</p>
<a href="http://arxiv.org/abs/2009.12991" target="_blank">arXiv:2009.12991</a> [<a href="http://arxiv.org/pdf/2009.12991" target="_blank">pdf</a>]

<h2>Addressing Class Imbalance in Scene Graph Parsing by Learning to Contrast and Score. (arXiv:2009.13331v2 [cs.CV] UPDATED)</h2>
<h3>He Huang, Shunta Saito, Yuta Kikuchi, Eiichi Matsumoto, Wei Tang, Philip S. Yu</h3>
<p>Scene graph parsing aims to detect objects in an image scene and recognize
their relations. Recent approaches have achieved high average scores on some
popular benchmarks, but fail in detecting rare relations, as the highly
long-tailed distribution of data biases the learning towards frequent labels.
Motivated by the fact that detecting these rare relations can be critical in
real-world applications, this paper introduces a novel integrated framework of
classification and ranking to resolve the class imbalance problem in scene
graph parsing. Specifically, we design a new Contrasting Cross-Entropy loss,
which promotes the detection of rare relations by suppressing incorrect
frequent ones. Furthermore, we propose a novel scoring module, termed as
Scorer, which learns to rank the relations based on the image features and
relation features to improve the recall of predictions. Our framework is simple
and effective, and can be incorporated into current scene graph models.
Experimental results show that the proposed approach improves the current
state-of-the-art methods, with a clear advantage of detecting rare relations.
</p>
<a href="http://arxiv.org/abs/2009.13331" target="_blank">arXiv:2009.13331</a> [<a href="http://arxiv.org/pdf/2009.13331" target="_blank">pdf</a>]

<h2>Graph Adversarial Networks: Protecting Information against Adversarial Attacks. (arXiv:2009.13504v2 [cs.LG] UPDATED)</h2>
<h3>Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon, Stefanie Jegelka, Ruslan Salakhutdinov</h3>
<p>We study the problem of protecting information when learning with graph
structured data. While the advent of Graph Neural Networks (GNNs) has greatly
improved node and graph representational learning in many applications, the
neighborhood aggregation paradigm exposes additional vulnerabilities to
attackers seeking to extract node-level information about sensitive attributes.
To counter this, we propose a minimax game between the desired GNN encoder and
the worst-case attacker. The resulting adversarial training creates a strong
defense against inference attacks, while only suffering small loss in task
performance. We analyze the effectiveness of our framework against a worst-case
adversary, and characterize the trade-off between predictive accuracy and
adversarial defense. Experiments across multiple datasets from recommender
systems, knowledge graphs and quantum chemistry demonstrate that the proposed
approach provides a robust defense across various graph structures and tasks,
while producing competitive GNN encoders.
</p>
<a href="http://arxiv.org/abs/2009.13504" target="_blank">arXiv:2009.13504</a> [<a href="http://arxiv.org/pdf/2009.13504" target="_blank">pdf</a>]

<h2>TEL: Low-Latency Failover Traffic Engineering in Data Plane. (arXiv:2009.13640v2 [cs.NI] UPDATED)</h2>
<h3>Habib Mostafaei, Mohammad Shojafar, Mauro Conti</h3>
<p>Modern network applications demand low-latency traffic engineering in the
presence of network failure while preserving the quality of service constraints
like delay, and capacity. The control plane reactions to the failure can be
slow compared to the data plane while supporting traffic demands for highly
sensitive applications. The control plane interaction requires to find an
alternative path for the failed one in the legacy approaches. In this paper, we
formulate failover traffic engineering as a max-min fair allocation problem
that maximizes the number of flows while minimizing their costs. We also
present TEL, a system with a linear algorithm, that uses the idea of backup
paths to avoid the control plane interaction to compute new paths. We use a
reinforcement learning-based algorithm to explore paths in the network. In
particular, our solution performs traffic engineering in the data plane. We
implement our approach in P4 and evaluate it on two real-world topologies,
namely, Goodnet and AttMpls. The simulation results confirm that TEL has
significant throughput improvement and lower flow completion time compared to
Open Shortest Path First (OSPF). Finally, we state the applicability of TEL in
the different modern network applications.
</p>
<a href="http://arxiv.org/abs/2009.13640" target="_blank">arXiv:2009.13640</a> [<a href="http://arxiv.org/pdf/2009.13640" target="_blank">pdf</a>]

<h2>SoK: On the Security Challenges and Risks of Multi-Tenant FPGAs in the Cloud. (arXiv:2009.13914v2 [cs.CR] UPDATED)</h2>
<h3>Shaza Zeitouni, Ghada Dessouky, Ahmad-Reza Sadeghi</h3>
<p>In their continuous growth and penetration into new markets, Field
Programmable Gate Arrays (FPGAs) have recently made their way into hardware
acceleration of machine learning among other specialized compute-intensive
services in cloud data centers, such as Amazon and Microsoft. To further
maximize their utilization in the cloud, several academic works propose the
spatial multi-tenant deployment model, where the FPGA fabric is simultaneously
shared among mutually mistrusting clients. This is enabled by leveraging the
partial reconfiguration property of FPGAs, which allows to split the FPGA
fabric into several logically isolated regions and reconfigure the
functionality of each region independently at runtime. In this paper, we survey
industrial and academic deployment models of multi-tenant FPGAs in the cloud
computing settings, and highlight their different adversary models and security
guarantees, while shedding light on their fundamental shortcomings from a
security standpoint. We further survey and classify existing academic works
that demonstrate a new class of remotely exploitable physical attacks on
multi-tenant FPGA devices, where these attacks are launched remotely by
malicious clients sharing physical resources with victim users. Through
investigating the problem of end-to-end multi-tenant FPGA deployment more
comprehensively, we reveal how these attacks actually represent only one
dimension of the problem, while various open security and privacy challenges
remain unaddressed. We conclude with our insights and a call for future
research to tackle these challenges.
</p>
<a href="http://arxiv.org/abs/2009.13914" target="_blank">arXiv:2009.13914</a> [<a href="http://arxiv.org/pdf/2009.13914" target="_blank">pdf</a>]

<h2>MARA-Net: Single Image Deraining Network with Multi-level connections and Adaptive Regional Attentions. (arXiv:2009.13990v2 [cs.CV] UPDATED)</h2>
<h3>Yeachan Park, Myeongho Jeon, Junho Lee, Myungjoo Kang</h3>
<p>Removing rain streaks from single images is an important problem in various
computer vision tasks because rain streaks can degrade outdoor images and
reduce their visibility. While recent convolutional neural network-based
deraining models have succeeded in capturing rain streaks effectively,
difficulties in recovering the details in rain-free images still remain. In
this paper, we present a multi-level connection and adaptive regional attention
network (MARA-Net) to properly restore the original background textures in
rainy images. The first main idea is a multi-level connection design that
repeatedly connects multi-level features of the encoder network to the decoder
network. Multi-level connections encourage the decoding process to use the
feature information of all levels. Channel attention is considered in
multi-level connections to learn which level of features is important in the
decoding process of the current level. The second main idea is a wide regional
non-local block (WRNL). As rain streaks primarily exhibit a vertical
distribution, we divide the grid of the image into horizontally-wide patches
and apply a non-local operation to each region to explore the rich rain-free
background information. Experimental results on both synthetic and real-world
rainy datasets demonstrate that the proposed model significantly outperforms
existing state-of-the-art models. Furthermore, the results of the joint
deraining and segmentation experiment prove that our model contributes
effectively to other vision tasks.
</p>
<a href="http://arxiv.org/abs/2009.13990" target="_blank">arXiv:2009.13990</a> [<a href="http://arxiv.org/pdf/2009.13990" target="_blank">pdf</a>]

<h2>Realistic Image Normalization for Multi-Domain Segmentation. (arXiv:2009.14024v3 [cs.LG] UPDATED)</h2>
<h3>Pierre-Luc Delisle, Benoit Anctil-Robitaille, Christian Desrosiers, Herve Lombaert</h3>
<p>Image normalization is a building block in medical image analysis.
Conventional approaches are customarily utilized on a per-dataset basis. This
strategy, however, prevents the current normalization algorithms from fully
exploiting the complex joint information available across multiple datasets.
Consequently, ignoring such joint information has a direct impact on the
performance of segmentation algorithms. This paper proposes to revisit the
conventional image normalization approach by instead learning a common
normalizing function across multiple datasets. Jointly normalizing multiple
datasets is shown to yield consistent normalized images as well as an improved
image segmentation. To do so, a fully automated adversarial and task-driven
normalization approach is employed as it facilitates the training of realistic
and interpretable images while keeping performance on-par with the
state-of-the-art. The adversarial training of our network aims at finding the
optimal transfer function to improve both the segmentation accuracy and the
generation of realistic images. We evaluated the performance of our normalizer
on both infant and adult brains images from the iSEG, MRBrainS and ABIDE
datasets. Results reveal the potential of our normalization approach for
segmentation, with Dice improvements of up to 57.5% over our baseline. Our
method can also enhance data availability by increasing the number of samples
available when learning from multiple imaging domains.
</p>
<a href="http://arxiv.org/abs/2009.14024" target="_blank">arXiv:2009.14024</a> [<a href="http://arxiv.org/pdf/2009.14024" target="_blank">pdf</a>]

<h2>RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior. (arXiv:2010.00029v2 [cs.LG] UPDATED)</h2>
<h3>Hong-Ye Hu, Dian Wu, Yi-Zhuang You, Bruno Olshausen, Yubei Chen</h3>
<p>Flow-based generative models have become an important class of unsupervised
learning approaches. In this work, we incorporate the key idea of
renormalization group (RG) and sparse prior distribution to design a
hierarchical flow-based generative model, called RG-Flow, which can separate
different scale information of images with disentangle representations at each
scale. We demonstrate our method mainly on the CelebA dataset and show that the
disentangled representation at different scales enables semantic manipulation
and style mixing of the images. To visualize the latent representation, we
introduce the receptive fields for flow-based models and find receptive fields
learned by RG-Flow are similar to convolutional neural networks. In addition,
we replace the widely adopted Gaussian prior distribution by sparse prior
distributions to further enhance the disentanglement of representations. From a
theoretical perspective, the proposed method has $O(\log L)$ complexity for
image inpainting compared to previous flow-based models with $O(L^2)$
complexity.
</p>
<a href="http://arxiv.org/abs/2010.00029" target="_blank">arXiv:2010.00029</a> [<a href="http://arxiv.org/pdf/2010.00029" target="_blank">pdf</a>]

<h2>Using Machine Learning to Augment Coarse-Grid Computational Fluid Dynamics Simulations. (arXiv:2010.00072v2 [physics.comp-ph] UPDATED)</h2>
<h3>Jaideep Pathak, Mustafa Mustafa, Karthik Kashinath, Emmanuel Motheau, Thorsten Kurth, Marcus Day</h3>
<p>Simulation of turbulent flows at high Reynolds number is a computationally
challenging task relevant to a large number of engineering and scientific
applications in diverse fields such as climate science, aerodynamics, and
combustion. Turbulent flows are typically modeled by the Navier-Stokes
equations. Direct Numerical Simulation (DNS) of the Navier-Stokes equations
with sufficient numerical resolution to capture all the relevant scales of the
turbulent motions can be prohibitively expensive. Simulation at
lower-resolution on a coarse-grid introduces significant errors. We introduce a
machine learning (ML) technique based on a deep neural network architecture
that corrects the numerical errors induced by a coarse-grid simulation of
turbulent flows at high-Reynolds numbers, while simultaneously recovering an
estimate of the high-resolution fields. Our proposed simulation strategy is a
hybrid ML-PDE solver that is capable of obtaining a meaningful high-resolution
solution trajectory while solving the system PDE at a lower resolution. The
approach has the potential to dramatically reduce the expense of turbulent flow
simulations. As a proof-of-concept, we demonstrate our ML-PDE strategy on a
two-dimensional turbulent (Rayleigh Number $Ra=10^9$) Rayleigh-B\'enard
Convection (RBC) problem.
</p>
<a href="http://arxiv.org/abs/2010.00072" target="_blank">arXiv:2010.00072</a> [<a href="http://arxiv.org/pdf/2010.00072" target="_blank">pdf</a>]

<h2>Deep matrix factorizations. (arXiv:2010.00380v2 [cs.LG] UPDATED)</h2>
<h3>Pierre De Handschutter, Nicolas Gillis, Xavier Siebert</h3>
<p>Constrained low-rank matrix approximations have been known for decades as
powerful linear dimensionality reduction techniques to be able to extract the
information contained in large data sets in a relevant way. However, such
low-rank approaches are unable to mine complex, interleaved features that
underlie hierarchical semantics. Recently, deep matrix factorization (deep MF)
was introduced to deal with the extraction of several layers of features and
has been shown to reach outstanding performances on unsupervised tasks. Deep MF
was motivated by the success of deep learning, as it is conceptually close to
some neural networks paradigms. In this paper, we present the main models,
algorithms, and applications of deep MF through a comprehensive literature
review. We also discuss theoretical questions and perspectives of research.
</p>
<a href="http://arxiv.org/abs/2010.00380" target="_blank">arXiv:2010.00380</a> [<a href="http://arxiv.org/pdf/2010.00380" target="_blank">pdf</a>]

<h2>Orbital Graph Convolutional Neural Network for Material Property Prediction. (arXiv:2008.06415v1 [physics.comp-ph] CROSS LISTED)</h2>
<h3>Mohammadreza Karamad, Rishikesh Magar, Yuting Shi, Samira Siahrostami, Ian D. Gates, Amir Barati Farimani</h3>
<p>Material representations that are compatible with machine learning models
play a key role in developing models that exhibit high accuracy for property
prediction. Atomic orbital interactions are one of the important factors that
govern the properties of crystalline materials, from which the local chemical
environments of atoms is inferred. Therefore, to develop robust machine
learningmodels for material properties prediction, it is imperative to include
features representing such chemical attributes. Here, we propose the Orbital
Graph Convolutional Neural Network (OGCNN), a crystal graph convolutional
neural network framework that includes atomic orbital interaction features that
learns material properties in a robust way. In addition, we embedded an
encoder-decoder network into the OGCNN enabling it to learn important features
among basic atomic (elemental features), orbital-orbital interactions, and
topological features. We examined the performance of this model on a broad
range of crystalline material data to predict different properties. We
benchmarked the performance of the OGCNN model with that of: 1) the crystal
graph convolutional neural network (CGCNN), 2) other state-of-the-art
descriptors for material representations including Many-body Tensor
Representation (MBTR) and the Smooth Overlap of Atomic Positions (SOAP), and 3)
other conventional regression machine learning algorithms where different
crystal featurization methods have been used. We find that OGCNN significantly
outperforms them. The OGCNN model with high predictive accuracy can be used to
discover new materials among the immense phase and compound spaces of materials
</p>
<a href="http://arxiv.org/abs/2008.06415" target="_blank">arXiv:2008.06415</a> [<a href="http://arxiv.org/pdf/2008.06415" target="_blank">pdf</a>]

<h2>Data-efficient Online Classification with Siamese Networks and Active Learning. (arXiv:2010.01659v1 [cs.LG])</h2>
<h3>Kleanthis Malialis, Christos G. Panayiotou, Marios M. Polycarpou</h3>
<p>An ever increasing volume of data is nowadays becoming available in a
streaming manner in many application areas, such as, in critical infrastructure
systems, finance and banking, security and crime and web analytics. To meet
this new demand, predictive models need to be built online where learning
occurs on-the-fly. Online learning poses important challenges that affect the
deployment of online classification systems to real-life problems. In this
paper we investigate learning from limited labelled, nonstationary and
imbalanced data in online classification. We propose a learning method that
synergistically combines siamese neural networks and active learning. The
proposed method uses a multi-sliding window approach to store data, and
maintains separate and balanced queues for each class. Our study shows that the
proposed method is robust to data nonstationarity and imbalance, and
significantly outperforms baselines and state-of-the-art algorithms in terms of
both learning speed and performance. Importantly, it is effective even when
only 1% of the labels of the arriving instances are available.
</p>
<a href="http://arxiv.org/abs/2010.01659" target="_blank">arXiv:2010.01659</a> [<a href="http://arxiv.org/pdf/2010.01659" target="_blank">pdf</a>]

<h2>Rank Position Forecasting in Car Racing. (arXiv:2010.01707v1 [cs.LG])</h2>
<h3>Bo Peng, Jiayu Li, Selahattin Akkas, Fugang Wang, Takuya Araki, Ohno Yoshiyuki, Judy Qiu</h3>
<p>Forecasting is challenging since uncertainty resulted from exogenous factors
exists. This work investigates the rank position forecasting problem in car
racing, which predicts the rank positions at the future laps for cars. Among
the many factors that bring changes to the rank positions, pit stops are
critical but irregular and rare. We found existing methods, including
statistical models, machine learning regression models, and state-of-the-art
deep forecasting model based on encoder-decoder architecture, all have
limitations in the forecasting. By elaborative analysis of pit stops events, we
propose a deep model, RankNet, with the cause effects decomposition that
modeling the rank position sequence and pit stop events separately. It also
incorporates probabilistic forecasting to model the uncertainty inside each
sub-model. Through extensive experiments, RankNet demonstrates a strong
performance improvement over the baselines, e.g., MAE improves more than 10%
consistently, and is also more stable when adapting to unseen new data. Details
of model optimization, performance profiling are presented. It is promising to
provide useful forecasting tools for the car racing analysis and shine a light
on solutions to similar challenging issues in general forecasting problems.
</p>
<a href="http://arxiv.org/abs/2010.01707" target="_blank">arXiv:2010.01707</a> [<a href="http://arxiv.org/pdf/2010.01707" target="_blank">pdf</a>]

<h2>A Generative Machine Learning Approach to Policy Optimization in Pursuit-Evasion Games. (arXiv:2010.01711v1 [cs.LG])</h2>
<h3>Shiva Navabi, Osonde A. Osoba</h3>
<p>We consider a pursuit-evasion game [11] played between two agents, 'Blue'
(the pursuer) and 'Red' (the evader), over $T$ time steps. Red aims to attack
Blue's territory. Blue's objective is to intercept Red by time $T$ and thereby
limit the success of Red's attack. Blue must plan its pursuit trajectory by
choosing parameters that determine its course of movement (speed and angle in
our setup) such that it intercepts Red by time $T$. We show that Blue's
path-planning problem in pursuing Red, can be posed as a sequential decision
making problem under uncertainty. Blue's unawareness of Red's action policy
renders the analytic dynamic programming approach intractable for finding the
optimal action policy for Blue. In this work, we are interested in exploring
data-driven approaches to the policy optimization problem that Blue faces. We
apply generative machine learning (ML) approaches to learn optimal action
policies for Blue. This highlights the ability of generative ML model to learn
the relevant implicit representations for the dynamics of simulated
pursuit-evasion games. We demonstrate the effectiveness of our modeling
approach via extensive statistical assessments. This work can be viewed as a
preliminary step towards further adoption of generative modeling approaches for
addressing policy optimization problems that arise in the context of
multi-agent learning and planning [1].
</p>
<a href="http://arxiv.org/abs/2010.01711" target="_blank">arXiv:2010.01711</a> [<a href="http://arxiv.org/pdf/2010.01711" target="_blank">pdf</a>]

<h2>Learning by Minimizing the Sum of Ranked Range. (arXiv:2010.01741v1 [cs.LG])</h2>
<h3>Shu Hu, Yiming Ying, Xin Wang, Siwei Lyu</h3>
<p>In forming learning objectives, one oftentimes needs to aggregate a set of
individual values to a single output. Such cases occur in the aggregate loss,
which combines individual losses of a learning model over each training sample,
and in the individual loss for multi-label learning, which combines prediction
scores over all class labels. In this work, we introduce the sum of ranked
range (SoRR) as a general approach to form learning objectives. A ranked range
is a consecutive sequence of sorted values of a set of real numbers. The
minimization of SoRR is solved with the difference of convex algorithm (DCA).
We explore two applications in machine learning of the minimization of the SoRR
framework, namely the AoRR aggregate loss for binary classification and the
TKML individual loss for multi-label/multi-class classification. Our empirical
results highlight the effectiveness of the proposed optimization framework and
demonstrate the applicability of proposed losses using synthetic and real
datasets.
</p>
<a href="http://arxiv.org/abs/2010.01741" target="_blank">arXiv:2010.01741</a> [<a href="http://arxiv.org/pdf/2010.01741" target="_blank">pdf</a>]

<h2>Policy Learning Using Weak Supervision. (arXiv:2010.01748v1 [cs.LG])</h2>
<h3>Jingkang Wang, Hongyi Guo, Zhaowei Zhu, Yang Liu</h3>
<p>Most existing policy learning solutions require the learning agents to
receive high-quality supervision signals, e.g., rewards in reinforcement
learning (RL) or high-quality expert's demonstrations in behavioral cloning
(BC). These quality supervisions are either infeasible or prohibitively
expensive to obtain in practice. We aim for a unified framework that leverages
the weak supervisions to perform policy learning efficiently. To handle this
problem, we treat the "weak supervisions" as imperfect information coming from
a peer agent, and evaluate the learning agent's policy based on a "correlated
agreement" with the peer agent's policy (instead of simple agreements). Our way
of leveraging peer agent's information offers us a family of solutions that
learn effectively from weak supervisions with theoretical guarantees. Extensive
evaluations on tasks including RL with noisy reward, BC with weak
demonstrations and standard policy co-training (RL + BC) show that the proposed
approach leads to substantial improvements, especially when the complexity or
the noise of the learning environments grows.
</p>
<a href="http://arxiv.org/abs/2010.01748" target="_blank">arXiv:2010.01748</a> [<a href="http://arxiv.org/pdf/2010.01748" target="_blank">pdf</a>]

<h2>Learning Manifold Implicitly via Explicit Heat-Kernel Learning. (arXiv:2010.01761v1 [cs.LG])</h2>
<h3>Yufan Zhou, Changyou Chen, Jinhui Xu</h3>
<p>Manifold learning is a fundamental problem in machine learning with numerous
applications. Most of the existing methods directly learn the low-dimensional
embedding of the data in some high-dimensional space, and usually lack the
flexibility of being directly applicable to down-stream applications. In this
paper, we propose the concept of implicit manifold learning, where manifold
information is implicitly obtained by learning the associated heat kernel. A
heat kernel is the solution of the corresponding heat equation, which describes
how "heat" transfers on the manifold, thus containing ample geometric
information of the manifold. We provide both practical algorithm and
theoretical analysis of our framework. The learned heat kernel can be applied
to various kernel-based machine learning models, including deep generative
models (DGM) for data generation and Stein Variational Gradient Descent for
Bayesian inference. Extensive experiments show that our framework can achieve
state-of-the-art results compared to existing methods for the two tasks.
</p>
<a href="http://arxiv.org/abs/2010.01761" target="_blank">arXiv:2010.01761</a> [<a href="http://arxiv.org/pdf/2010.01761" target="_blank">pdf</a>]

<h2>OLALA: Object-Level Active Learning Based Layout Annotation. (arXiv:2010.01762v1 [cs.LG])</h2>
<h3>Zejiang Shen, Jian Zhao, Melissa Dell, Yaoliang Yu, Weining Li</h3>
<p>In layout object detection problems, the ground-truth datasets are
constructed by annotating object instances individually. Yet active learning
for object detection is typically conducted at the image level, not at the
object level. Because objects appear with different frequencies across images,
image-level active learning may be subject to over-exposure to common objects.
This reduces the efficiency of human labeling. This work introduces an
Object-Level Active Learning based Layout Annotation framework, OLALA, which
includes an object scoring method and a prediction correction algorithm. The
object scoring method estimates the object prediction informativeness
considering both the object category and the location. It selects only the most
ambiguous object prediction regions within an image for users to label,
optimizing the use of the annotation budget. For the unselected model
predictions, we propose a correction algorithm to rectify two types of possible
errors with minor supervision from ground-truths. The human annotated and model
predicted objects are then merged as new image annotations for training the
object detection models. In simulated labeling experiments, we show that OLALA
helps to create the dataset more efficiently and report strong accuracy
improvements of the trained models compared to image-level active learning
baselines. The code is available at
https://github.com/lolipopshock/Detectron2_AL.
</p>
<a href="http://arxiv.org/abs/2010.01762" target="_blank">arXiv:2010.01762</a> [<a href="http://arxiv.org/pdf/2010.01762" target="_blank">pdf</a>]

<h2>How Effective is Task-Agnostic Data Augmentation for Pretrained Transformers?. (arXiv:2010.01764v1 [cs.LG])</h2>
<h3>Shayne Longpre, Yu Wang, Christopher DuBois</h3>
<p>Task-agnostic forms of data augmentation have proven widely effective in
computer vision, even on pretrained models. In NLP similar results are reported
most commonly for low data regimes, non-pretrained models, or situationally for
pretrained models. In this paper we ask how effective these techniques really
are when applied to pretrained transformers. Using two popular varieties of
task-agnostic data augmentation (not tailored to any particular task), Easy
Data Augmentation (Wei and Zou, 2019) and Back-Translation (Sennrichet al.,
2015), we conduct a systematic examination of their effects across 5
classification tasks, 6 datasets, and 3 variants of modern pretrained
transformers, including BERT, XLNet, and RoBERTa. We observe a negative result,
finding that techniques which previously reported strong improvements for
non-pretrained models fail to consistently improve performance for pretrained
transformers, even when training data is limited. We hope this empirical
analysis helps inform practitioners where data augmentation techniques may
confer improvements.
</p>
<a href="http://arxiv.org/abs/2010.01764" target="_blank">arXiv:2010.01764</a> [<a href="http://arxiv.org/pdf/2010.01764" target="_blank">pdf</a>]

<h2>Empirical Likelihood Inference in Randomized Controlled Trials with High-Dimensional Covariates. (arXiv:2010.01772v1 [stat.ME])</h2>
<h3>Wei Liang, Ying Yan</h3>
<p>In this paper, we propose a data-adaptive empirical likelihood approach for
treatment effect inference, which overcomes the obstacle of the traditional
empirical likelihood approaches in the high-dimensional setting by adopting
penalized regression and machine learning methods to model the
covariate-outcome relationship. In particular, we show that our procedure
successfully recovers the true variance of Zhang's treatment effect estimator
\citep{Zhang2018} by utilizing a data-splitting technique. Our proposed
estimator is proved to be asymptotically normal and semiparametric efficient
under mild regularity conditions. Simulation studies indicate that our
estimator is more efficient than the estimator proposed by \citet{Wager2016}
when random forest is employed to model the covariate-outcome relationship.
Moreover, when multiple machine learning models are imposed, our estimator is
at least as efficient as any regular estimator with a single machine learning
model. We compare our method to existing ones using the ACTG175 data and the
GSE118657 data, and confirm the outstanding performance of our approach.
</p>
<a href="http://arxiv.org/abs/2010.01772" target="_blank">arXiv:2010.01772</a> [<a href="http://arxiv.org/pdf/2010.01772" target="_blank">pdf</a>]

<h2>A Unified View on Graph Neural Networks as Graph Signal Denoising. (arXiv:2010.01777v1 [cs.LG])</h2>
<h3>Yao Ma, Xiaorui Liu, Tong Zhao, Yozen Liu, Jiliang Tang, Neil Shah</h3>
<p>Graph Neural Networks (GNNs) have risen to prominence in learning
representations for graph structured data. A single GNN layer typically
consists of a feature transformation and a feature aggregation operation. The
former normally uses feed-forward networks to transform features, while the
latter aggregates the transformed features over the graph. Numerous recent
works have proposed GNN models with different designs in the aggregation
operation. In this work, we establish mathematically that the aggregation
processes in a group of representative GNN models including GCN, GAT, PPNP, and
APPNP can be regarded as (approximately) solving a graph denoising problem with
a smoothness assumption. Such a unified view across GNNs not only provides a
new perspective to understand a variety of aggregation operations but also
enables us to develop a unified graph neural network framework UGNN. To
demonstrate its promising potential, we instantiate a novel GNN model,
ADA-UGNN, derived from UGNN, to handle graphs with adaptive smoothness across
nodes. Comprehensive experiments show the effectiveness of ADA-UGNN.
</p>
<a href="http://arxiv.org/abs/2010.01777" target="_blank">arXiv:2010.01777</a> [<a href="http://arxiv.org/pdf/2010.01777" target="_blank">pdf</a>]

<h2>Improving Relational Regularized Autoencoders with Spherical Sliced Fused Gromov Wasserstein. (arXiv:2010.01787v1 [stat.ML])</h2>
<h3>Khai Nguyen, Son Nguyen, Nhat Ho, Tung Pham, Hung Bui</h3>
<p>Relational regularized autoencoder (RAE) is a framework to learn the
distribution of data by minimizing a reconstruction loss together with a
relational regularization on the latent space. A recent attempt to reduce the
inner discrepancy between the prior and aggregated posterior distributions is
to incorporate sliced fused Gromov-Wasserstein (SFG) between these
distributions. That approach has a weakness since it treats every slicing
direction similarly, meanwhile several directions are not useful for the
discriminative task. To improve the discrepancy and consequently the relational
regularization, we propose a new relational discrepancy, named spherical sliced
fused Gromov Wasserstein (SSFG), that can find an important area of projections
characterized by a von Mises-Fisher distribution. Then, we introduce two
variants of SSFG to improve its performance. The first variant, named mixture
spherical sliced fused Gromov Wasserstein (MSSFG), replaces the vMF
distribution by a mixture of von Mises-Fisher distributions to capture multiple
important areas of directions that are far from each other. The second variant,
named power spherical sliced fused Gromov Wasserstein (PSSFG), replaces the vMF
distribution by a power spherical distribution to improve the sampling time in
high dimension settings. We then apply the new discrepancies to the RAE
framework to achieve its new variants. Finally, we conduct extensive
experiments to show that the new proposed autoencoders have favorable
performance in learning latent manifold structure, image generation, and
reconstruction.
</p>
<a href="http://arxiv.org/abs/2010.01787" target="_blank">arXiv:2010.01787</a> [<a href="http://arxiv.org/pdf/2010.01787" target="_blank">pdf</a>]

<h2>Towards Generalized and Distributed Privacy-Preserving Representation Learning. (arXiv:2010.01792v1 [cs.LG])</h2>
<h3>Sheikh Shams Azam, Taejin Kim, Seyyedali Hosseinalipour, Christopher Brinton, Carlee Joe-Wong, Saurabh Bagchi</h3>
<p>We study the problem of learning data representations that are private yet
informative, i.e., providing information about intended "ally" targets while
obfuscating sensitive "adversary" attributes. We propose a novel framework,
Exclusion-Inclusion Generative Adversarial Network (EIGAN), that generalizes
existing adversarial privacy-preserving representation learning (PPRL)
approaches to generate data encodings that account for multiple possibly
overlapping ally and adversary targets. Preserving privacy is even more
difficult when the data is collected across multiple distributed nodes, which
for privacy reasons may not wish to share their data even for PPRL training.
Thus, learning such data representations at each node in a distributed manner
(i.e., without transmitting source data) is of particular importance. This
motivates us to develop D-EIGAN, the first distributed PPRL method, based on
federated learning with fractional parameter sharing to account for
communication resource limitations. We theoretically analyze the behavior of
adversaries under the optimal EIGAN and D-EIGAN encoders and consider the
impact of dependencies among ally and adversary tasks on the encoder
performance. Our experiments on real-world and synthetic datasets demonstrate
the advantages of EIGAN encodings in terms of accuracy, robustness, and
scalability; in particular, we show that EIGAN outperforms the previous
state-of-the-art by a significant accuracy margin (47% improvement). The
experiments further reveal that D-EIGAN's performance is consistent with EIGAN
under different node data distributions and is resilient to communication
constraints.
</p>
<a href="http://arxiv.org/abs/2010.01792" target="_blank">arXiv:2010.01792</a> [<a href="http://arxiv.org/pdf/2010.01792" target="_blank">pdf</a>]

<h2>DCT-SNN: Using DCT to Distribute Spatial Information over Time for Learning Low-Latency Spiking Neural Networks. (arXiv:2010.01795v1 [cs.LG])</h2>
<h3>Isha Garg, Sayeed Shafayet Chowdhury, Kaushik Roy</h3>
<p>Spiking Neural Networks (SNNs) offer a promising alternative to traditional
deep learning frameworks, since they provide higher computational efficiency
due to event-driven information processing. SNNs distribute the analog values
of pixel intensities into binary spikes over time. However, the most widely
used input coding schemes, such as Poisson based rate-coding, do not leverage
the additional temporal learning capability of SNNs effectively. Moreover,
these SNNs suffer from high inference latency which is a major bottleneck to
their deployment. To overcome this, we propose a scalable time-based encoding
scheme that utilizes the Discrete Cosine Transform (DCT) to reduce the number
of timesteps required for inference. DCT decomposes an image into a weighted
sum of sinusoidal basis images. At each time step, the Hadamard product of the
DCT coefficients and a single frequency base, taken in order, is given to an
accumulator that generates spikes upon crossing a threshold. We use the
proposed scheme to learn DCT-SNN, a low-latency deep SNN with
leaky-integrate-and-fire neurons, trained using surrogate gradient descent
based backpropagation. We achieve top-1 accuracy of 89.94%, 68.3% and 52.43% on
CIFAR-10, CIFAR-100 and TinyImageNet, respectively using VGG architectures.
Notably, DCT-SNN performs inference with 2-14X reduced latency compared to
other state-of-the-art SNNs, while achieving comparable accuracy to their
standard deep learning counterparts. The dimension of the transform allows us
to control the number of timesteps required for inference. Additionally, we can
trade-off accuracy with latency in a principled manner by dropping the highest
frequency components during inference.
</p>
<a href="http://arxiv.org/abs/2010.01795" target="_blank">arXiv:2010.01795</a> [<a href="http://arxiv.org/pdf/2010.01795" target="_blank">pdf</a>]

<h2>Understanding Catastrophic Overfitting in Single-step Adversarial Training. (arXiv:2010.01799v1 [cs.LG])</h2>
<h3>Hoki Kim, Woojin Lee, Jaewook Lee</h3>
<p>Adversarial examples are perturbed inputs that are designed to deceive
machine-learning classifiers by adding adversarial perturbations to the
original data. Although fast adversarial training have demonstrated both
robustness and efficiency, the problem of "catastrophic overfitting" has been
observed. It is a phenomenon that, during single-step adversarial training, the
robust accuracy against projected gradient descent (PGD) suddenly decreases to
0% after few epochs, whereas the robustness against fast gradient sign method
(FGSM) increases to 100%. In this paper, we address three main topics. (i) We
demonstrate that catastrophic overfitting occurs in single-step adversarial
training because it trains adversarial images with maximum perturbation only,
not all adversarial examples in the adversarial direction, which leads to a
distorted decision boundary and a highly curved loss surface. (ii) We
experimentally prove this phenomenon by proposing a simple method using
checkpoints. This method not only prevents catastrophic overfitting, but also
overrides the belief that single-step adversarial training is hard to prevent
multi-step attacks. (iii) We compare the performance of the proposed method to
that obtained in recent works and demonstrate that it provides sufficient
robustness to different attacks even after hundreds of training epochs in less
time. All code for reproducing the experiments in this paper are at
https://github.com/Harry24k/catastrophic-overfitting.
</p>
<a href="http://arxiv.org/abs/2010.01799" target="_blank">arXiv:2010.01799</a> [<a href="http://arxiv.org/pdf/2010.01799" target="_blank">pdf</a>]

<h2>Graph Cross Networks with Vertex Infomax Pooling. (arXiv:2010.01804v1 [cs.LG])</h2>
<h3>Maosen Li, Siheng Chen, Ya Zhang, Ivor W. Tsang</h3>
<p>We propose a novel graph cross network (GXN) to achieve comprehensive feature
learning from multiple scales of a graph. Based on trainable hierarchical
representations of a graph, GXN enables the interchange of intermediate
features across scales to promote information flow. Two key ingredients of GXN
include a novel vertex infomax pooling (VIPool), which creates multiscale
graphs in a trainable manner, and a novel feature-crossing layer, enabling
feature interchange across scales. The proposed VIPool selects the most
informative subset of vertices based on the neural estimation of mutual
information between vertex features and neighborhood features. The intuition
behind is that a vertex is informative when it can maximally reflect its
neighboring information. The proposed feature-crossing layer fuses intermediate
features between two scales for mutual enhancement by improving information
flow and enriching multiscale features at hidden layers. The cross shape of the
feature-crossing layer distinguishes GXN from many other multiscale
architectures. Experimental results show that the proposed GXN improves the
classification accuracy by 1.96% and 1.15% on average for graph classification
and vertex classification, respectively. Based on the same network, the
proposed VIPool consistently outperforms other graph-pooling methods.
</p>
<a href="http://arxiv.org/abs/2010.01804" target="_blank">arXiv:2010.01804</a> [<a href="http://arxiv.org/pdf/2010.01804" target="_blank">pdf</a>]

<h2>Bigeminal Priors Variational auto-encoder. (arXiv:2010.01819v1 [cs.LG])</h2>
<h3>Xuming Ran, Mingkun Xu, Qi Xu, Huihui Zhou, Quanying Liu</h3>
<p>Variational auto-encoders (VAEs) are an influential and generally-used class
of likelihood-based generative models in unsupervised learning. The
likelihood-based generative models have been reported to be highly robust to
the out-of-distribution (OOD) inputs and can be a detector by assuming that the
model assigns higher likelihoods to the samples from the in-distribution (ID)
dataset than an OOD dataset. However, recent works reported a phenomenon that
VAE recognizes some OOD samples as ID by assigning a higher likelihood to the
OOD inputs compared to the one from ID. In this work, we introduce a new model,
namely Bigeminal Priors Variational auto-encoder (BPVAE), to address this
phenomenon. The BPVAE aims to enhance the robustness of the VAEs by combing the
power of VAE with the two independent priors that belong to the training
dataset and simple dataset, which complexity is lower than the training
dataset, respectively. BPVAE learns two datasets'features, assigning a higher
likelihood for the training dataset than the simple dataset. In this way, we
can use BPVAE's density estimate for detecting the OOD samples. Quantitative
experimental results suggest that our model has better generalization
capability and stronger robustness than the standard VAEs, proving the
effectiveness of the proposed approach of hybrid learning by collaborative
priors. Overall, this work paves a new avenue to potentially overcome the OOD
problem via multiple latent priors modeling.
</p>
<a href="http://arxiv.org/abs/2010.01819" target="_blank">arXiv:2010.01819</a> [<a href="http://arxiv.org/pdf/2010.01819" target="_blank">pdf</a>]

<h2>Quantifying Statistical Significance of Neural Network Representation-Driven Hypotheses by Selective Inference. (arXiv:2010.01823v1 [stat.ML])</h2>
<h3>Vo Nguyen Le Duy, Shogo Iwazaki, Ichiro Takeuchi</h3>
<p>In the past few years, various approaches have been developed to explain and
interpret deep neural network (DNN) representations, but it has been pointed
out that these representations are sometimes unstable and not reproducible. In
this paper, we interpret these representations as hypotheses driven by DNN
(called DNN-driven hypotheses) and propose a method to quantify the reliability
of these hypotheses in statistical hypothesis testing framework. To this end,
we introduce Selective Inference (SI) framework, which has received much
attention in the past few years as a new statistical inference framework for
data-driven hypotheses. The basic idea of SI is to make conditional inferences
on the selected hypotheses under the condition that they are selected. In order
to use SI framework for DNN representations, we develop a new SI algorithm
based on homotopy method which enables us to derive the exact (non-asymptotic)
conditional sampling distribution of the DNN-driven hypotheses. We conduct
experiments on both synthetic and real-world datasets, through which we offer
evidence that our proposed method can successfully control the false positive
rate, has decent performance in terms of computational efficiency, and provides
good results in practical applications.
</p>
<a href="http://arxiv.org/abs/2010.01823" target="_blank">arXiv:2010.01823</a> [<a href="http://arxiv.org/pdf/2010.01823" target="_blank">pdf</a>]

<h2>Deep Distributional Time Series Models and the Probabilistic Forecasting of Intraday Electricity Prices. (arXiv:2010.01844v1 [stat.ME])</h2>
<h3>Nadja Klein, Michael Stanley Smith, David J. Nott</h3>
<p>Recurrent neural networks (RNNs) with rich feature vectors of past values can
provide accurate point forecasts for series that exhibit complex serial
dependence. We propose two approaches to constructing deep time series
probabilistic models based on a variant of RNN called an echo state network
(ESN). The first is where the output layer of the ESN has stochastic
disturbances and a shrinkage prior for additional regularization. The second
approach employs the implicit copula of an ESN with Gaussian disturbances,
which is a deep copula process on the feature space. Combining this copula with
a non-parametrically estimated marginal distribution produces a deep
distributional time series model. The resulting probabilistic forecasts are
deep functions of the feature vector and also marginally calibrated. In both
approaches, Bayesian Markov chain Monte Carlo methods are used to estimate the
models and compute forecasts. The proposed deep time series models are suitable
for the complex task of forecasting intraday electricity prices. Using data
from the Australian National Electricity Market, we show that our models
provide accurate probabilistic price forecasts. Moreover, the models provide a
flexible framework for incorporating probabilistic forecasts of electricity
demand as additional features. We demonstrate that doing so in the deep
distributional time series model in particular, increases price forecast
accuracy substantially.
</p>
<a href="http://arxiv.org/abs/2010.01844" target="_blank">arXiv:2010.01844</a> [<a href="http://arxiv.org/pdf/2010.01844" target="_blank">pdf</a>]

<h2>Unbiased Gradient Estimation for Variational Auto-Encoders using Coupled Markov Chains. (arXiv:2010.01845v1 [cs.LG])</h2>
<h3>Francisco J. R. Ruiz, Michalis K. Titsias, Taylan Cemgil, Arnaud Doucet</h3>
<p>The variational auto-encoder (VAE) is a deep latent variable model that has
two neural networks in an autoencoder-like architecture; one of them
parameterizes the model's likelihood. Fitting its parameters via maximum
likelihood is challenging since the computation of the likelihood involves an
intractable integral over the latent space; thus the VAE is trained instead by
maximizing a variational lower bound. Here, we develop a maximum likelihood
training scheme for VAEs by introducing unbiased gradient estimators of the
log-likelihood. We obtain the unbiased estimators by augmenting the latent
space with a set of importance samples, similarly to the importance weighted
auto-encoder (IWAE), and then constructing a Markov chain Monte Carlo (MCMC)
coupling procedure on this augmented space. We provide the conditions under
which the estimators can be computed in finite time and have finite variance.
We demonstrate experimentally that VAEs fitted with unbiased estimators exhibit
better predictive performance on three image datasets.
</p>
<a href="http://arxiv.org/abs/2010.01845" target="_blank">arXiv:2010.01845</a> [<a href="http://arxiv.org/pdf/2010.01845" target="_blank">pdf</a>]

<h2>My Body is a Cage: the Role of Morphology in Graph-Based Incompatible Control. (arXiv:2010.01856v1 [cs.LG])</h2>
<h3>Vitaly Kurin, Maximilian Igl, Tim Rockt&#xe4;schel, Wendelin Boehmer, Shimon Whiteson</h3>
<p>Multitask Reinforcement Learning is a promising way to obtain models with
better performance, generalisation, data efficiency, and robustness. Most
existing work is limited to compatible settings, where the state and action
space dimensions are the same across tasks. Graph Neural Networks (GNN) are one
way to address incompatible environments, because they can process graphs of
arbitrary size. They also allow practitioners to inject biases encoded in the
structure of the input graph. Existing work in graph-based continuous control
uses the physical morphology of the agent to construct the input graph, i.e.,
encoding limb features as node labels and using edges to connect the nodes if
their corresponded limbs are physically connected. In this work, we present a
series of ablations on existing methods that show that morphological
information encoded in the graph does not improve their performance. Motivated
by the hypothesis that any benefits GNNs extract from the graph structure are
outweighed by difficulties they create for message passing, we also propose
Amorpheus, a transformer-based approach. Further results show that, while
Amorpheus ignores the morphological information that GNNs encode, it
nonetheless substantially outperforms GNN-based methods.
</p>
<a href="http://arxiv.org/abs/2010.01856" target="_blank">arXiv:2010.01856</a> [<a href="http://arxiv.org/pdf/2010.01856" target="_blank">pdf</a>]

<h2>Pointwise Binary Classification with Pairwise Confidence Comparisons. (arXiv:2010.01875v1 [cs.LG])</h2>
<h3>Lei Feng, Senlin Shu, Nan Lu, Bo Han, Miao Xu, Gang Niu, Bo An, Masashi Sugiyama</h3>
<p>Ordinary (pointwise) binary classification aims to learn a binary classifier
from pointwise labeled data. However, such pointwise labels may not be directly
accessible due to privacy, confidentiality, or security considerations. In this
case, can we still learn an accurate binary classifier? This paper proposes a
novel setting, namely pairwise comparison (Pcomp) classification, where we are
given only pairs of unlabeled data that we know one is more likely to be
positive than the other, instead of pointwise labeled data. Pcomp
classification is useful for private or subjective classification tasks. To
solve this problem, we present a mathematical formulation for the generation
process of pairwise comparison data, based on which we exploit an unbiased risk
estimator(URE) to train a binary classifier by empirical risk minimization and
establish an estimation error bound. We first prove that a URE can be derived
and improve it using correction functions. Then, we start from the noisy-label
learning perspective to introduce a progressive URE and improve it by imposing
consistency regularization. Finally, experiments validate the effectiveness of
our proposed solutions for Pcomp classification.
</p>
<a href="http://arxiv.org/abs/2010.01875" target="_blank">arXiv:2010.01875</a> [<a href="http://arxiv.org/pdf/2010.01875" target="_blank">pdf</a>]

<h2>Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation. (arXiv:2010.01916v1 [cs.LG])</h2>
<h3>Uchenna Akujuobi, Jun Chen, Mohamed Elhoseiny, Michael Spranger, Xiangliang Zhang</h3>
<p>Understanding the relationships between biomedical terms like viruses, drugs,
and symptoms is essential in the fight against diseases. Many attempts have
been made to introduce the use of machine learning to the scientific process of
hypothesis generation(HG), which refers to the discovery of meaningful implicit
connections between biomedical terms. However, most existing methods fail to
truly capture the temporal dynamics of scientific term relations and also
assume unobserved connections to be irrelevant (i.e., in a positive-negative
(PN) learning setting). To break these limits, we formulate this HG problem as
future connectivity prediction task on a dynamic attributed graph via
positive-unlabeled (PU) learning. Then, the key is to capture the temporal
evolution of node pair (term pair) relations from just the positive and
unlabeled data. We propose a variational inference model to estimate the
positive prior, and incorporate it in the learning of node pair embeddings,
which are then used for link prediction. Experiment results on real-world
biomedical term relationship datasets and case study analyses on a COVID-19
dataset validate the effectiveness of the proposed model.
</p>
<a href="http://arxiv.org/abs/2010.01916" target="_blank">arXiv:2010.01916</a> [<a href="http://arxiv.org/pdf/2010.01916" target="_blank">pdf</a>]

<h2>Multi-Loss Sub-Ensembles for Accurate Classification with Uncertainty Estimation. (arXiv:2010.01917v1 [cs.LG])</h2>
<h3>Omer Achrack, Ouriel Barzilay, Raizy Kellerman</h3>
<p>Deep neural networks (DNNs) have made a revolution in numerous fields during
the last decade. However, in tasks with high safety requirements, such as
medical or autonomous driving applications, providing an assessment of the
models reliability can be vital. Uncertainty estimation for DNNs has been
addressed using Bayesian methods, providing mathematically founded models for
reliability assessment. These model are computationally expensive and generally
impractical for many real-time use cases. Recently, non-Bayesian methods were
proposed to tackle uncertainty estimation more efficiently. We propose an
efficient method for uncertainty estimation in DNNs achieving high accuracy. We
simulate the notion of multi-task learning on single-task problems by producing
parallel predictions from similar models differing by their loss. This
multi-loss approach allows one-phase training for single-task learning with
uncertainty estimation. We keep our inference time relatively low by leveraging
the advantage proposed by the Deep-Sub-Ensembles method. The novelty of this
work resides in the proposed accurate variational inference with a simple and
convenient training procedure, while remaining competitive in terms of
computational time. We conduct experiments on SVHN, CIFAR10, CIFAR100 as well
as Image-Net using different architectures. Our results show improved accuracy
on the classification task and competitive results on several uncertainty
measures.
</p>
<a href="http://arxiv.org/abs/2010.01917" target="_blank">arXiv:2010.01917</a> [<a href="http://arxiv.org/pdf/2010.01917" target="_blank">pdf</a>]

<h2>$\xi$-torch: differentiable scientific computing library. (arXiv:2010.01921v1 [cs.LG])</h2>
<h3>Muhammad F. Kasim, Sam M. Vinko</h3>
<p>Physics-informed learning has shown to have a better generalization than
learning without physical priors.

However, training physics-informed deep neural networks requires some aspect
of physical simulations to be written in a differentiable manner.

Unfortunately, some operations and functionals commonly used in physical
simulations are scattered, hard to integrate, and lack higher order derivatives
which are needed in physical simulations.

In this work, we present $\xi$-torch, a library of differentiable functionals
for scientific simulations.

Example functionals are a root finder and an initial value problem solver,
among others.

The gradient of functionals in $\xi$-torch are written based on their
analytical expression to improve numerical stability and reduce memory
requirements.

$\xi$-torch also provides second and higher order derivatives of the
functionals which are rarely available in existing packages.

We show two applications of this library in optimizing parameters in physics
simulations.

The library and all test cases in this work can be found at
https://github.com/xitorch/xitorch/ and the documentation at
https://xitorch.readthedocs.io.
</p>
<a href="http://arxiv.org/abs/2010.01921" target="_blank">arXiv:2010.01921</a> [<a href="http://arxiv.org/pdf/2010.01921" target="_blank">pdf</a>]

<h2>BayesAdapter: Being Bayesian, Inexpensively and Robustly, via Bayeisan Fine-tuning. (arXiv:2010.01979v1 [cs.LG])</h2>
<h3>Zhijie Deng, Xiao Yang, Hao Zhang, Yinpeng Dong, Jun Zhu</h3>
<p>Despite their theoretical appealingness, Bayesian neural networks (BNNs) are
falling far behind in terms of adoption in real-world applications compared
with normal NNs, mainly due to their limited scalability in training, and low
fidelity in their uncertainty estimates. In this work, we develop a new
framework, named BayesAdapter, to address these issues and bring Bayesian deep
learning to the masses. The core notion of BayesAdapter is to adapt pre-trained
deterministic NNs to be BNNs via Bayesian fine-tuning. We implement Bayesian
fine-tuning with a plug-and-play instantiation of stochastic variational
inference, and propose exemplar reparameterization to reduce gradient variance
and stabilize the fine-tuning. Together, they enable training BNNs as if one
were training deterministic NNs with minimal added overheads. During Bayesian
fine-tuning, we further propose an uncertainty regularization to supervise and
calibrate the uncertainty quantification of learned BNNs at low cost. To
empirically evaluate BayesAdapter, we conduct extensive experiments on a
diverse set of challenging benchmarks, and observe significantly higher
training efficiency, better predictive performance, and more calibrated and
faithful uncertainty estimates than existing BNNs.
</p>
<a href="http://arxiv.org/abs/2010.01979" target="_blank">arXiv:2010.01979</a> [<a href="http://arxiv.org/pdf/2010.01979" target="_blank">pdf</a>]

<h2>Putting Theory to Work: From Learning Bounds to Meta-Learning Algorithms. (arXiv:2010.01992v1 [cs.LG])</h2>
<h3>Quentin Bouniot, Ievgen Redko, Romaric Audigier, Ang&#xe9;lique Loesch, Amaury Habrard</h3>
<p>Most of existing deep learning models rely on excessive amounts of labeled
training data in order to achieve state-of-the-art results, even though these
data can be hard or costly to get in practice. One attractive alternative is to
learn with little supervision, commonly referred to as few-shot learning (FSL),
and, in particular, meta-learning that learns to learn with few data from
related tasks. Despite the practical success of meta-learning, many of its
algorithmic solutions proposed in the literature are based on sound intuitions,
but lack a solid theoretical analysis of the expected performance on the test
task. In this paper, we review the recent advances in meta-learning theory and
show how they can be used in practice both to better understand the behavior of
popular meta-learning algorithms and to improve their generalization capacity.
This latter is achieved by integrating the theoretical assumptions ensuring
efficient meta-learning in the form of regularization terms into several
popular meta-learning algorithms for which we provide a large study of their
behavior on classic few-shot classification benchmarks. To the best of our
knowledge, this is the first contribution that puts the most recent learning
bounds of meta-learning theory into practice for the popular task of few-shot
classification.
</p>
<a href="http://arxiv.org/abs/2010.01992" target="_blank">arXiv:2010.01992</a> [<a href="http://arxiv.org/pdf/2010.01992" target="_blank">pdf</a>]

<h2>Immigration Document Classification and Automated Response Generation. (arXiv:2010.01997v1 [cs.LG])</h2>
<h3>Sourav Mukherjee, Tim Oates, Vince DiMascio, Huguens Jean, Rob Ares, David Widmark, Jaclyn Harder</h3>
<p>In this paper, we consider the problem of organizing supporting documents
vital to U.S. work visa petitions, as well as responding to Requests For
Evidence (RFE) issued by the U.S.~Citizenship and Immigration Services (USCIS).
Typically, both processes require a significant amount of repetitive manual
effort. To reduce the burden of mechanical work, we apply machine learning
methods to automate these processes, with humans in the loop to review and edit
output for submission. In particular, we use an ensemble of image and text
classifiers to categorize supporting documents. We also use a text classifier
to automatically identify the types of evidence being requested in an RFE, and
used the identified types in conjunction with response templates and extracted
fields to assemble draft responses. Empirical results suggest that our approach
achieves considerable accuracy while significantly reducing processing time.
</p>
<a href="http://arxiv.org/abs/2010.01997" target="_blank">arXiv:2010.01997</a> [<a href="http://arxiv.org/pdf/2010.01997" target="_blank">pdf</a>]

<h2>Boosted Semantic Embedding based Discriminative Feature Generation for Texture Analysis. (arXiv:2010.02002v1 [cs.LG])</h2>
<h3>Priyadarshini Kumari, Subhasis Chaudhuri</h3>
<p>Learning discriminative features is crucial for various robotic applications
such as object detection and classification. In this paper, we present a
general framework for the analysis of the discriminative properties of haptic
signals. Our focus is on two crucial components of a robotic perception system:
discriminative feature extraction and metric-based feature transformation to
enhance the separability of haptic signals in the projected space. We propose a
set of hand-crafted haptic features (generated only from acceleration data),
which enables discrimination of real-world textures. Since the Euclidean space
does not reflect the underlying pattern in the data, we propose to learn an
appropriate transformation function to project the feature onto the new space
and apply different pattern recognition algorithms for texture classification
and discrimination tasks. Unlike other existing methods, we use a triplet-based
method for improved discrimination in the embedded space. We further
demonstrate how to build a haptic vocabulary by selecting a compact set of the
most distinct and representative signals in the embedded space. The
experimental results show that the proposed features augmented with learned
embedding improves the performance of semantic discrimination tasks such as
classification and clustering and outperforms the related state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2010.02002" target="_blank">arXiv:2010.02002</a> [<a href="http://arxiv.org/pdf/2010.02002" target="_blank">pdf</a>]

<h2>Is AI Model Interpretable to Combat with COVID? An Empirical Study on Severity Prediction Task. (arXiv:2010.02006v1 [cs.LG])</h2>
<h3>Han Wu, Wenjie Ruan, Jiangtao Wang, Dingchang Zheng, Shaolin Li, Jian Chen, Kunwei Li, Xiangfei Chai, Sumi Helal</h3>
<p>Black-box nature hinders the deployment of many high-accuracy models in
medical diagnosis. Putting one's life in the hands of models that medical
researchers do not trust it's irresponsible. However, to understand the
mechanism of a new virus, such as COVID-19, machine learning models may catch
important symptoms that medical practitioners do not notice due to the surge of
infected patients caused by a pandemic. In this work, the interpretation of
machine learning models reveals a high CRP corresponds to severe infection, and
severe patients usually go through a cardiac injury, which is consistent with
medical knowledge. Additionally, through the interpretation of machine learning
models, we find phlegm and diarrhea are two important symptoms, without which
indicate a high risk of turning severe. These two symptoms are not recognized
at the early stage of the outbreak, but later our findings are corroborated by
autopsies of COVID-19 patients. And we find patients with a high NTproBNP have
a significantly increased risk of death which does not receive much attention
initially but proves true by the following-up study. Thus, we suggest
interpreting machine learning models can offer help to understanding a new
virus at the early stage of an outbreak.
</p>
<a href="http://arxiv.org/abs/2010.02006" target="_blank">arXiv:2010.02006</a> [<a href="http://arxiv.org/pdf/2010.02006" target="_blank">pdf</a>]

<h2>Deep Incomplete Multi-View Multiple Clusterings. (arXiv:2010.02024v1 [cs.LG])</h2>
<h3>Shaowei Wei, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang</h3>
<p>Multi-view clustering aims at exploiting information from multiple
heterogeneous views to promote clustering. Most previous works search for only
one optimal clustering based on the predefined clustering criterion, but
devising such a criterion that captures what users need is difficult. Due to
the multiplicity of multi-view data, we can have meaningful alternative
clusterings. In addition, the incomplete multi-view data problem is ubiquitous
in real world but has not been studied for multiple clusterings. To address
these issues, we introduce a deep incomplete multi-view multiple clusterings
(DiMVMC) framework, which achieves the completion of data view and multiple
shared representations simultaneously by optimizing multiple groups of decoder
deep networks. In addition, it minimizes a redundancy term to simultaneously
%uses Hilbert-Schmidt Independence Criterion (HSIC) to control the diversity
among these representations and among parameters of different networks. Next,
it generates an individual clustering from each of these shared
representations. Experiments on benchmark datasets confirm that DiMVMC
outperforms the state-of-the-art competitors in generating multiple clusterings
with high diversity and quality.
</p>
<a href="http://arxiv.org/abs/2010.02024" target="_blank">arXiv:2010.02024</a> [<a href="http://arxiv.org/pdf/2010.02024" target="_blank">pdf</a>]

<h2>Conditional Negative Sampling for Contrastive Learning of Visual Representations. (arXiv:2010.02037v1 [cs.LG])</h2>
<h3>Mike Wu, Milan Mosse, Chengxu Zhuang, Daniel Yamins, Noah Goodman</h3>
<p>Recent methods for learning unsupervised visual representations, dubbed
contrastive learning, optimize the noise-contrastive estimation (NCE) bound on
mutual information between two views of an image. NCE uses randomly sampled
negative examples to normalize the objective. In this paper, we show that
choosing difficult negatives, or those more similar to the current instance,
can yield stronger representations. To do this, we introduce a family of mutual
information estimators that sample negatives conditionally -- in a "ring"
around each positive. We prove that these estimators lower-bound mutual
information, with higher bias but lower variance than NCE. Experimentally, we
find our approach, applied on top of existing models (IR, CMC, and MoCo)
improves accuracy by 2-5% points in each case, measured by linear evaluation on
four standard image datasets. Moreover, we find continued benefits when
transferring features to a variety of new image distributions from the
Meta-Dataset collection and to a variety of downstream tasks such as object
detection, instance segmentation, and keypoint detection.
</p>
<a href="http://arxiv.org/abs/2010.02037" target="_blank">arXiv:2010.02037</a> [<a href="http://arxiv.org/pdf/2010.02037" target="_blank">pdf</a>]

<h2>A Simple Framework for Uncertainty in Contrastive Learning. (arXiv:2010.02038v1 [cs.LG])</h2>
<h3>Mike Wu, Noah Goodman</h3>
<p>Contrastive approaches to representation learning have recently shown great
promise. In contrast to generative approaches, these contrastive models learn a
deterministic encoder with no notion of uncertainty or confidence. In this
paper, we introduce a simple approach based on "contrasting distributions" that
learns to assign uncertainty for pretrained contrastive representations. In
particular, we train a deep network from a representation to a distribution in
representation space, whose variance can be used as a measure of confidence. In
our experiments, we show that this deep uncertainty model can be used (1) to
visually interpret model behavior, (2) to detect new noise in the input to
deployed models, (3) to detect anomalies, where we outperform 10 baseline
methods across 11 tasks with improvements of up to 14% absolute, and (4) to
classify out-of-distribution examples where our fully unsupervised model is
competitive with supervised methods.
</p>
<a href="http://arxiv.org/abs/2010.02038" target="_blank">arXiv:2010.02038</a> [<a href="http://arxiv.org/pdf/2010.02038" target="_blank">pdf</a>]

<h2>Learned Hardware/Software Co-Design of Neural Accelerators. (arXiv:2010.02075v1 [cs.LG])</h2>
<h3>Zhan Shi, Chirag Sakhuja, Milad Hashemi, Kevin Swersky, Calvin Lin</h3>
<p>The use of deep learning has grown at an exponential rate, giving rise to
numerous specialized hardware and software systems for deep learning. Because
the design space of deep learning software stacks and hardware accelerators is
diverse and vast, prior work considers software optimizations separately from
hardware architectures, effectively reducing the search space. Unfortunately,
this bifurcated approach means that many profitable design points are never
explored. This paper instead casts the problem as hardware/software co-design,
with the goal of automatically identifying desirable points in the joint design
space. The key to our solution is a new constrained Bayesian optimization
framework that avoids invalid solutions by exploiting the highly constrained
features of this design space, which are semi-continuous/semi-discrete. We
evaluate our optimization framework by applying it to a variety of neural
models, improving the energy-delay product by 18% (ResNet) and 40% (DQN) over
hand-tuned state-of-the-art systems, as well as demonstrating strong results on
other neural network architectures, such as MLPs and Transformers.
</p>
<a href="http://arxiv.org/abs/2010.02075" target="_blank">arXiv:2010.02075</a> [<a href="http://arxiv.org/pdf/2010.02075" target="_blank">pdf</a>]

<h2>Explaining The Efficacy of Counterfactually-Augmented Data. (arXiv:2010.02114v1 [cs.CL])</h2>
<h3>Divyansh Kaushik, Amrith Setlur, Eduard Hovy, Zachary C. Lipton</h3>
<p>In attempts to produce machine learning models less reliant on spurious
patterns in training data, researchers have recently proposed a
human-in-the-loop process for generating counterfactually augmented datasets.
As applied in NLP, given some documents and their (initial) labels, humans are
tasked with revising the text to make a (given) counterfactual label
applicable. Importantly, the instructions prohibit edits that are not necessary
to flip the applicable label. Models trained on the augmented (original and
revised) data have been shown to rely less on semantically irrelevant words and
to generalize better out-of-domain. While this work draws on causal thinking,
casting edits as interventions and relying on human understanding to assess
outcomes, the underlying causal model is not clear nor are the principles
underlying the observed improvements in out-of-domain evaluation. In this
paper, we explore a toy analog, using linear Gaussian models. Our analysis
reveals interesting relationships between causal models, measurement noise,
out-of-domain generalization, and reliance on spurious signals. Interestingly
our analysis suggests that data corrupted by adding noise to causal features
will degrade out-of-domain performance, while noise added to non-causal
features may make models more robust out-of-domain. This analysis yields
interesting insights that help to explain the efficacy of counterfactually
augmented data. Finally, we present a large-scale empirical study that supports
this hypothesis.
</p>
<a href="http://arxiv.org/abs/2010.02114" target="_blank">arXiv:2010.02114</a> [<a href="http://arxiv.org/pdf/2010.02114" target="_blank">pdf</a>]

<h2>Mastering Atari with Discrete World Models. (arXiv:2010.02193v1 [cs.LG])</h2>
<h3>Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, Jimmy Ba</h3>
<p>Intelligent agents need to generalize from past experience to achieve goals
in complex environments. World models facilitate such generalization and allow
learning behaviors from imagined outcomes to increase sample-efficiency. While
learning world models from image inputs has recently become feasible for some
tasks, modeling Atari games accurately enough to derive successful behaviors
has remained an open challenge for many years. We introduce DreamerV2, a
reinforcement learning agent that learns behaviors purely from predictions in
the compact latent space of a powerful world model. The world model uses
discrete representations and is trained separately from the policy. DreamerV2
constitutes the first agent that achieves human-level performance on the Atari
benchmark of 55 tasks by learning behaviors inside a separately trained world
model. With the same computational budget and wall-clock time, DreamerV2
reaches 200M frames and exceeds the final performance of the top single-GPU
agents IQN and Rainbow.
</p>
<a href="http://arxiv.org/abs/2010.02193" target="_blank">arXiv:2010.02193</a> [<a href="http://arxiv.org/pdf/2010.02193" target="_blank">pdf</a>]

<h2>Black-box sampling for weakly smooth Langevin Monte Carlo using p-generalized Gaussian smoothing. (arXiv:2002.10071v2 [stat.CO] UPDATED)</h2>
<h3>Anh Duc Doan, Xin Dang, Dao Nguyen</h3>
<p>Discretization of continuous-time diffusion processes is a widely recognized
method for sampling. However, the canonical Euler-Maruyama discretization of
the Langevin diffusion process, also named as Langevin Monte Carlo (LMC),
studied mostly in the context of smooth (gradient-Lipschitz) and strongly
log-concave densities, a significant constraint for its deployment in many
sciences, including computational statistics and statistical learning. In this
paper, we establish several theoretical contributions to the literature on such
sampling methods. Particularly, we generalize the Gaussian smoothing,
approximate the gradient using p-generalized Gaussian smoothing and take
advantage of it in the context of black-box sampling. We first present a
non-strongly concave and weakly smooth black-box LMC algorithm, ideal for
practical applicability of sampling challenges in a general setting.
</p>
<a href="http://arxiv.org/abs/2002.10071" target="_blank">arXiv:2002.10071</a> [<a href="http://arxiv.org/pdf/2002.10071" target="_blank">pdf</a>]

<h2>Towards a Computer Vision Particle Flow. (arXiv:2003.08863v2 [hep-ex] UPDATED)</h2>
<h3>Francesco Armando Di Bello, Sanmay Ganguly, Eilam Gross, Marumi Kado, Michael Pitt, Lorenzo Santi, Jonathan Shlomi</h3>
<p>In High Energy Physics experiments Particle Flow (PFlow) algorithms are
designed to provide an optimal reconstruction of the nature and kinematic
properties of the particles produced within the detector acceptance during
collisions. At the heart of PFlow algorithms is the ability to distinguish the
calorimeter energy deposits of neutral particles from those of charged
particles, using the complementary measurements of charged particle tracking
devices, to provide a superior measurement of the particle content and
kinematics. In this paper, a computer vision approach to this fundamental
aspect of PFlow algorithms, based on calorimeter images, is proposed. A
comparative study of the state of the art deep learning techniques is
performed. A significantly improved reconstruction of the neutral particle
calorimeter energy deposits is obtained in a context of large overlaps with the
deposits from charged particles. Calorimeter images with a finer granularity
than that of the input calorimeter image are also obtained using
super-resolution techniques.
</p>
<a href="http://arxiv.org/abs/2003.08863" target="_blank">arXiv:2003.08863</a> [<a href="http://arxiv.org/pdf/2003.08863" target="_blank">pdf</a>]

<h2>Sequential hypothesis testing in machine learning driven crude oil jump detection. (arXiv:2004.08889v2 [stat.ME] UPDATED)</h2>
<h3>Michael Roberts, Indranil SenGupta</h3>
<p>In this paper we present a sequential hypothesis test for the detection of
general jump size distrubution. Infinitesimal generators for the corresponding
log-likelihood ratios are presented and analyzed. Bounds for infinitesimal
generators in terms of super-solutions and sub-solutions are computed. This is
shown to be implementable in relation to various classification problems for a
crude oil price data set. Machine and deep learning algorithms are implemented
to extract a specific deterministic component from the crude oil data set, and
the deterministic component is implemented to improve the Barndorff-Nielsen and
Shephard model, a commonly used stochastic model for derivative and commodity
market analysis.
</p>
<a href="http://arxiv.org/abs/2004.08889" target="_blank">arXiv:2004.08889</a> [<a href="http://arxiv.org/pdf/2004.08889" target="_blank">pdf</a>]

<h2>Reflection on modern methods: Good practices for applied statistical learning in epidemiology. (arXiv:2006.07305v2 [stat.AP] UPDATED)</h2>
<h3>Yanelli Nunez, Elizabeth A. Gibson, Eva M. Tanner, Chris Gennings, Brent A.Coull, Jeff A. Goldsmith, Marianthi-Anna Kioumourtzoglou</h3>
<p>Statistical learning (SL) includes methods that extract knowledge from
complex data. SL methods beyond generalized linear models are being
increasingly implemented in public health research and epidemiology because
they can perform better in instances with complex or high-dimensional
data---settings when traditional statistical methods fail. These novel methods,
however, often include random sampling which may induce variability in results.
Best practices in data science can help to ensure robustness. As a case study,
we included four SL models that have been applied previously to analyze the
relationship between environmental mixtures and health outcomes. We ran each
model across 100 initializing values for random number generation, or "seeds,"
and assessed variability in resulting estimation and inference. All methods
exhibited some seed-dependent variability in results. The degree of variability
differed across methods and exposure of interest. Any SL method reliant on a
random seed will exhibit some degree of seed sensitivity. We recommend that
researchers repeat their analysis with various seeds as a sensitivity analysis
when implementing these methods to enhance interpretability and robustness of
results.
</p>
<a href="http://arxiv.org/abs/2006.07305" target="_blank">arXiv:2006.07305</a> [<a href="http://arxiv.org/pdf/2006.07305" target="_blank">pdf</a>]

<h2>Quantifying the impact of COVID-19 on the US stock market: An analysis from multi-source information. (arXiv:2008.10885v3 [q-fin.ST] UPDATED)</h2>
<h3>Asim Kumer Dey, Toufiqul Haq, Kumer Das, Irina Panovska</h3>
<p>We develop a novel temporal complex network approach to quantify the US
county level spread dynamics of COVID-19. The objective is to study the effects
of the local spread dynamics, COVID-19 cases and death, and Google search
activities on the US stock market. We use both conventional econometric and
Machine Learning (ML) models. The results suggest that COVID-19 cases and
deaths, its local spread, and Google searches have impacts on abnormal stock
prices between January 2020 to May 2020. In addition, incorporating information
about local spread significantly improves the performance of forecasting models
of the abnormal stock prices at longer forecasting horizons. On the other hand,
although a few COVID-19 related variables, e.g., US total deaths and US new
cases exhibit causal relationships on price volatility, COVID-19 cases and
deaths, local spread of COVID-19, and Google search activities do not have
impacts on price volatility.
</p>
<a href="http://arxiv.org/abs/2008.10885" target="_blank">arXiv:2008.10885</a> [<a href="http://arxiv.org/pdf/2008.10885" target="_blank">pdf</a>]

