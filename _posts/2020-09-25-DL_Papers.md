---
title: Latest Deep Learning Papers
date: 2021-01-20 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (117 Articles)</h1>
<h2>Machine learning applications for COVID-19: A state-of-the-art review. (arXiv:2101.07824v1 [cs.LG])</h2>
<h3>Firuz Kamalov, Aswani Cherukuri, Hana Sulieman, Fadi Thabtah, Akbar Hossain</h3>
<p>The COVID-19 pandemic has galvanized the machine learning community to create
new solutions that can help in the fight against the virus. The body of
literature related to applications of machine learning and artificial
intelligence to COVID-19 is constantly growing. The goal of this article is to
present the latest advances in machine learning research applied to COVID-19.
We cover four major areas of research: forecasting, medical diagnostics, drug
development, and contact tracing. We review and analyze the most successful
state of the art studies. In contrast to other existing surveys on the subject,
our article presents a high level overview of the current research that is
sufficiently detailed to provide an informed insight.
</p>
<a href="http://arxiv.org/abs/2101.07824" target="_blank">arXiv:2101.07824</a> [<a href="http://arxiv.org/pdf/2101.07824" target="_blank">pdf</a>]

<h2>Multi-Task Network Pruning and Embedded Optimization for Real-time Deployment in ADAS. (arXiv:2101.07831v1 [cs.CV])</h2>
<h3>Flora Dellinger, Thomas Boulay, Diego Mendoza Barrenechea, Said El-Hachimi, Isabelle Leang, Fabien B&#xfc;rger</h3>
<p>Camera-based Deep Learning algorithms are increasingly needed for perception
in Automated Driving systems. However, constraints from the automotive industry
challenge the deployment of CNNs by imposing embedded systems with limited
computational resources. In this paper, we propose an approach to embed a
multi-task CNN network under such conditions on a commercial prototype
platform, i.e. a low power System on Chip (SoC) processing four surround-view
fisheye cameras at 10 FPS.

The first focus is on designing an efficient and compact multi-task network
architecture. Secondly, a pruning method is applied to compress the CNN,
helping to reduce the runtime and memory usage by a factor of 2 without
lowering the performances significantly. Finally, several embedded optimization
techniques such as mixed-quantization format usage and efficient data transfers
between different memory areas are proposed to ensure real-time execution and
avoid bandwidth bottlenecks. The approach is evaluated on the hardware
platform, considering embedded detection performances, runtime and memory
bandwidth. Unlike most works from the literature that focus on classification
task, we aim here to study the effect of pruning and quantization on a compact
multi-task network with object detection, semantic segmentation and soiling
detection tasks.
</p>
<a href="http://arxiv.org/abs/2101.07831" target="_blank">arXiv:2101.07831</a> [<a href="http://arxiv.org/pdf/2101.07831" target="_blank">pdf</a>]

<h2>The Devils in the Point Clouds: Studying the Robustness of Point Cloud Convolutions. (arXiv:2101.07832v1 [cs.CV])</h2>
<h3>Xingyi Li, Wenxuan Wu, Xiaoli Z. Fern, Li Fuxin</h3>
<p>Recently, there has been a significant interest in performing convolution
over irregularly sampled point clouds. Since point clouds are very different
from regular raster images, it is imperative to study the generalization of the
convolution networks more closely, especially their robustness under variations
in scale and rotations of the input data. This paper investigates different
variants of PointConv, a convolution network on point clouds, to examine their
robustness to input scale and rotation changes. Of the variants we explored,
two are novel and generated significant improvements. The first is replacing
the multilayer perceptron based weight function with much simpler third degree
polynomials, together with a Sobolev norm regularization. Secondly, for 3D
datasets, we derive a novel viewpoint-invariant descriptor by utilizing 3D
geometric properties as the input to PointConv, in addition to the regular 3D
coordinates. We have also explored choices of activation functions,
neighborhood, and subsampling methods. Experiments are conducted on the 2D
MNIST &amp; CIFAR-10 datasets as well as the 3D SemanticKITTI &amp; ScanNet datasets.
Results reveal that on 2D, using third degree polynomials greatly improves
PointConv's robustness to scale changes and rotations, even surpassing
traditional 2D CNNs for the MNIST dataset. On 3D datasets, the novel
viewpoint-invariant descriptor significantly improves the performance as well
as robustness of PointConv. We achieve the state-of-the-art semantic
segmentation performance on the SemanticKITTI dataset, as well as comparable
performance with the current highest framework on the ScanNet dataset among
point-based approaches.
</p>
<a href="http://arxiv.org/abs/2101.07832" target="_blank">arXiv:2101.07832</a> [<a href="http://arxiv.org/pdf/2101.07832" target="_blank">pdf</a>]

<h2>Implicit Bias of Linear RNNs. (arXiv:2101.07833v1 [cs.LG])</h2>
<h3>Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Sundeep Rangan, Alyson K. Fletcher</h3>
<p>Contemporary wisdom based on empirical studies suggests that standard
recurrent neural networks (RNNs) do not perform well on tasks requiring
long-term memory. However, precise reasoning for this behavior is still
unknown. This paper provides a rigorous explanation of this property in the
special case of linear RNNs. Although this work is limited to linear RNNs, even
these systems have traditionally been difficult to analyze due to their
non-linear parameterization. Using recently-developed kernel regime analysis,
our main result shows that linear RNNs learned from random initializations are
functionally equivalent to a certain weighted 1D-convolutional network.
Importantly, the weightings in the equivalent model cause an implicit bias to
elements with smaller time lags in the convolution and hence, shorter memory.
The degree of this bias depends on the variance of the transition kernel matrix
at initialization and is related to the classic exploding and vanishing
gradients problem. The theory is validated in both synthetic and real data
experiments.
</p>
<a href="http://arxiv.org/abs/2101.07833" target="_blank">arXiv:2101.07833</a> [<a href="http://arxiv.org/pdf/2101.07833" target="_blank">pdf</a>]

<h2>Scalable Optimization for Wind Farm Control using Coordination Graphs. (arXiv:2101.07844v1 [cs.LG])</h2>
<h3>Timothy Verstraeten, Pieter-Jan Daems, Eugenio Bargiacchi, Diederik M. Roijers, Pieter J.K. Libin, Jan Helsen</h3>
<p>Wind farms are a crucial driver toward the generation of ecological and
renewable energy. Due to their rapid increase in capacity, contemporary wind
farms need to adhere to strict constraints on power output to ensure stability
of the electricity grid. Specifically, a wind farm controller is required to
match the farm's power production with a power demand imposed by the grid
operator. This is a non-trivial optimization problem, as complex dependencies
exist between the wind turbines. State-of-the-art wind farm control typically
relies on physics-based heuristics that fail to capture the full load spectrum
that defines a turbine's health status. When this is not taken into account,
the long-term viability of the farm's turbines is put at risk. Given the
complex dependencies that determine a turbine's lifetime, learning a flexible
and optimal control strategy requires a data-driven approach. However, as wind
farms are large-scale multi-agent systems, optimizing control strategies over
the full joint action space is intractable. We propose a new learning method
for wind farm control that leverages the sparse wind farm structure to
factorize the optimization problem. Using a Bayesian approach, based on
multi-agent Thompson sampling, we explore the factored joint action space for
configurations that match the demand, while considering the lifetime of
turbines. We apply our method to a grid-like wind farm layout, and evaluate
configurations using a state-of-the-art wind flow simulator. Our results are
competitive with a physics-based heuristic approach in terms of demand error,
while, contrary to the heuristic, our method prolongs the lifetime of high-risk
turbines.
</p>
<a href="http://arxiv.org/abs/2101.07844" target="_blank">arXiv:2101.07844</a> [<a href="http://arxiv.org/pdf/2101.07844" target="_blank">pdf</a>]

<h2>DyLoc: Dynamic Localization for Massive MIMO Using Predictive Recurrent Neural Networks. (arXiv:2101.07848v1 [cs.CV])</h2>
<h3>Farzam Hejazi, Katarina Vuckovic, Nazanin Rahnavard</h3>
<p>This paper presents a data-driven localization framework with high precision
in time-varying complex multipath environments, such as dense urban areas and
indoors, where GPS and model-based localization techniques come short. We
consider the angle-delay profile (ADP), a linear transformation of channel
state information (CSI), in massive MIMO systems and show that ADPs preserve
users' motion when stacked temporally. We discuss that given a static
environment, future frames of ADP time-series are predictable employing a video
frame prediction algorithm. We express that a deep convolutional neural network
(DCNN) can be employed to learn the background static scattering environment.
To detect foreground changes in the environment, corresponding to path blockage
or addition, we introduce an algorithm taking advantage of the trained DCNN.
Furthermore, we present DyLoc, a data-driven framework to recover distorted
ADPs due to foreground changes and to obtain precise location estimations. We
evaluate the performance of DyLoc in several dynamic scenarios employing
DeepMIMO dataset to generate geo-tagged CSI datasets for indoor and outdoor
environments. We show that previous DCNN-based techniques fail to perform with
desirable accuracy in dynamic environments, while DyLoc pursues localization
precisely. Moreover, simulations show that as the environment gets richer in
terms of the number of multipath, DyLoc gets more robust to foreground changes.
</p>
<a href="http://arxiv.org/abs/2101.07848" target="_blank">arXiv:2101.07848</a> [<a href="http://arxiv.org/pdf/2101.07848" target="_blank">pdf</a>]

<h2>Learning Abstract Task Representations. (arXiv:2101.07852v1 [cs.LG])</h2>
<h3>Mikhail M. Meskhi, Adriano Rivolli, Rafael G. Mantovani, Ricardo Vilalta</h3>
<p>A proper form of data characterization can guide the process of
learning-algorithm selection and model-performance estimation. The field of
meta-learning has provided a rich body of work describing effective forms of
data characterization using different families of meta-features (statistical,
model-based, information-theoretic, topological, etc.). In this paper, we start
with the abundant set of existing meta-features and propose a method to induce
new abstract meta-features as latent variables in a deep neural network. We
discuss the pitfalls of using traditional meta-features directly and argue for
the importance of learning high-level task properties. We demonstrate our
methodology using a deep neural network as a feature extractor. We demonstrate
that 1) induced meta-models mapping abstract meta-features to generalization
performance outperform other methods by ~18% on average, and 2) abstract
meta-features attain high feature-relevance scores.
</p>
<a href="http://arxiv.org/abs/2101.07852" target="_blank">arXiv:2101.07852</a> [<a href="http://arxiv.org/pdf/2101.07852" target="_blank">pdf</a>]

<h2>Machine-Generated Hierarchical Structure of Human Activities to Reveal How Machines Think. (arXiv:2101.07855v1 [cs.CV])</h2>
<h3>Mahsun Alt&#x131;n, Furkan G&#xfc;rsoy, Lina Xu</h3>
<p>Deep-learning based computer vision models have proved themselves to be
ground-breaking approaches to human activity recognition (HAR). However, most
existing works are dedicated to improve the prediction accuracy through either
creating new model architectures, increasing model complexity, or refining
model parameters by training on larger datasets. Here, we propose an
alternative idea, differing from existing work, to increase model accuracy and
also to shape model predictions to align with human understandings through
automatically creating higher-level summarizing labels for similar groups of
human activities. First, we argue the importance and feasibility of
constructing a hierarchical labeling system for human activity recognition.
Then, we utilize the predictions of a black box HAR model to identify
similarities between different activities. Finally, we tailor hierarchical
clustering methods to automatically generate hierarchical trees of activities
and conduct experiments. In this system, the activity labels on the same level
will have a designed magnitude of accuracy and reflect a specific amount of
activity details. This strategy enables a trade-off between the extent of the
details in the recognized activity and the user privacy by masking some
sensitive predictions; and also provides possibilities for the use of formerly
prohibited invasive models in privacy-concerned scenarios. Since the hierarchy
is generated from the machine's perspective, the predictions at the upper
levels provide better accuracy, which is especially useful when there are too
detailed labels in the training set that are rather trivial to the final
prediction goal. Moreover, the analysis of the structure of these trees can
reveal the biases in the prediction model and guide future data collection
strategies.
</p>
<a href="http://arxiv.org/abs/2101.07855" target="_blank">arXiv:2101.07855</a> [<a href="http://arxiv.org/pdf/2101.07855" target="_blank">pdf</a>]

<h2>SEMULATOR: Emulating the Dynamics of Crossbar Array-based Analog Neural System with Regression Neural Networks. (arXiv:2101.07864v1 [cs.LG])</h2>
<h3>Chaeun Lee, Seyoung Kim</h3>
<p>As deep neural networks require tremendous amount of computation and memory,
analog computing with emerging memory devices is a promising alternative to
digital computing for edge devices. However, because of the increasing
simulation time for analog computing system, it has not been explored. To
overcome this issue, analytically approximated simulators are developed, but
these models are inaccurate and narrow down the options for peripheral circuits
for multiply-accumulate operation (MAC). In this sense, we propose a
methodology, SEMULATOR (SiMULATOR by Emulating the analog computing block)
which uses a deep neural network to emulate the behavior of crossbar-based
analog computing system. With the proposed neural architecture, we
experimentally and theoretically shows that it emulates a MAC unit for neural
computation. In addition, the simulation time is incomparably reduced when it
compared to the circuit simulators such as SPICE.
</p>
<a href="http://arxiv.org/abs/2101.07864" target="_blank">arXiv:2101.07864</a> [<a href="http://arxiv.org/pdf/2101.07864" target="_blank">pdf</a>]

<h2>Illuminating the Space of Beatable Lode Runner Levels Produced By Various Generative Adversarial Networks. (arXiv:2101.07868v1 [cs.LG])</h2>
<h3>Kirby Steckel, Jacob Schrum</h3>
<p>Generative Adversarial Networks (GANs) are capable of generating convincing
imitations of elements from a training set, but the distribution of elements in
the training set affects to difficulty of properly training the GAN and the
quality of the outputs it produces. This paper looks at six different GANs
trained on different subsets of data from the game Lode Runner. The quality
diversity algorithm MAP-Elites was used to explore the set of quality levels
that could be produced by each GAN, where quality was defined as being beatable
and having the longest solution path possible. Interestingly, a GAN trained on
only 20 levels generated the largest set of diverse beatable levels while a GAN
trained on 150 levels generated the smallest set of diverse beatable levels,
thus challenging the notion that more is always better when training GANs.
</p>
<a href="http://arxiv.org/abs/2101.07868" target="_blank">arXiv:2101.07868</a> [<a href="http://arxiv.org/pdf/2101.07868" target="_blank">pdf</a>]

<h2>Joint Learning of 3D Shape Retrieval and Deformation. (arXiv:2101.07889v1 [cs.CV])</h2>
<h3>Mikaela Angelina Uy, Vladimir G. Kim, Minhyuk Sung, Noam Aigerman, Siddhartha Chaudhuri, Leonidas Guibas</h3>
<p>We propose a novel technique for producing high-quality 3D models that match
a given target object image or scan. Our method is based on retrieving an
existing shape from a database of 3D models and then deforming its parts to
match the target shape. Unlike previous approaches that independently focus on
either shape retrieval or deformation, we propose a joint learning procedure
that simultaneously trains the neural deformation module along with the
embedding space used by the retrieval module. This enables our network to learn
a deformation-aware embedding space, so that retrieved models are more amenable
to match the target after an appropriate deformation. In fact, we use the
embedding space to guide the shape pairs used to train the deformation module,
so that it invests its capacity in learning deformations between meaningful
shape pairs. Furthermore, our novel part-aware deformation module can work with
inconsistent and diverse part-structures on the source shapes. We demonstrate
the benefits of our joint training not only on our novel framework, but also on
other state-of-the-art neural deformation modules proposed in recent years.
Lastly, we also show that our jointly-trained method outperforms a two-step
deformation-aware retrieval that uses direct optimization instead of neural
deformation or a pre-trained deformation module.
</p>
<a href="http://arxiv.org/abs/2101.07889" target="_blank">arXiv:2101.07889</a> [<a href="http://arxiv.org/pdf/2101.07889" target="_blank">pdf</a>]

<h2>A modular vision language navigation and manipulation framework for long horizon compositional tasks in indoor environment. (arXiv:2101.07891v1 [cs.CV])</h2>
<h3>Homagni Saha, Fateme Fotouhif, Qisai Liu, Soumik Sarkar</h3>
<p>In this paper we propose a new framework - MoViLan (Modular Vision and
Language) for execution of visually grounded natural language instructions for
day to day indoor household tasks. While several data-driven, end-to-end
learning frameworks have been proposed for targeted navigation tasks based on
the vision and language modalities, performance on recent benchmark data sets
revealed the gap in developing comprehensive techniques for long horizon,
compositional tasks (involving manipulation and navigation) with diverse object
categories, realistic instructions and visual scenarios with non-reversible
state changes. We propose a modular approach to deal with the combined
navigation and object interaction problem without the need for strictly aligned
vision and language training data (e.g., in the form of expert demonstrated
trajectories). Such an approach is a significant departure from the traditional
end-to-end techniques in this space and allows for a more tractable training
process with separate vision and language data sets. Specifically, we propose a
novel geometry-aware mapping technique for cluttered indoor environments, and a
language understanding model generalized for household instruction following.
We demonstrate a significant increase in success rates for long-horizon,
compositional tasks over the baseline on the recently released benchmark data
set-ALFRED.
</p>
<a href="http://arxiv.org/abs/2101.07891" target="_blank">arXiv:2101.07891</a> [<a href="http://arxiv.org/pdf/2101.07891" target="_blank">pdf</a>]

<h2>Cross-domain few-shot learning with unlabelled data. (arXiv:2101.07899v1 [cs.CV])</h2>
<h3>Fupin Yao</h3>
<p>Few shot learning aims to solve the data scarcity problem. If there is a
domain shift between the test set and the training set, their performance will
decrease a lot. This setting is called Cross-domain few-shot learning. However,
this is very challenging because the target domain is unseen during training.
Thus we propose a new setting some unlabelled data from the target domain is
provided, which can bridge the gap between the source domain and the target
domain. A benchmark for this setting is constructed using DomainNet
\cite{peng2018oment}. We come up with a self-supervised learning method to
fully utilize the knowledge in the labeled training set and the unlabelled set.
Extensive experiments show that our methods outperforms several baseline
methods by a large margin. We also carefully design an episodic training
pipeline which yields a significant performance boost.
</p>
<a href="http://arxiv.org/abs/2101.07899" target="_blank">arXiv:2101.07899</a> [<a href="http://arxiv.org/pdf/2101.07899" target="_blank">pdf</a>]

<h2>Feature Sharing Cooperative Network for Semantic Segmentation. (arXiv:2101.07905v1 [cs.CV])</h2>
<h3>Ryota Ikedo, Kazuhiro Hotta</h3>
<p>In recent years, deep neural networks have achieved high ac-curacy in the
field of image recognition. By inspired from human learning method, we propose
a semantic segmentation method using cooperative learning which shares the
information resembling a group learning. We use two same networks and paths for
sending feature maps between two networks. Two networks are trained
simultaneously. By sharing feature maps, one of two networks can obtain the
information that cannot be obtained by a single network. In addition, in order
to enhance the degree of cooperation, we propose two kinds of methods that
connect only the same layer and multiple layers. We evaluated our proposed idea
on two kinds of networks. One is Dual Attention Network (DANet) and the other
one is DeepLabv3+. The proposed method achieved better segmentation accuracy
than the conventional single network and ensemble of networks.
</p>
<a href="http://arxiv.org/abs/2101.07905" target="_blank">arXiv:2101.07905</a> [<a href="http://arxiv.org/pdf/2101.07905" target="_blank">pdf</a>]

<h2>IntentNet: Learning to Predict Intention from Raw Sensor Data. (arXiv:2101.07907v1 [cs.RO])</h2>
<h3>Sergio Casas, Wenjie Luo, Raquel Urtasun</h3>
<p>In order to plan a safe maneuver, self-driving vehicles need to understand
the intent of other traffic participants. We define intent as a combination of
discrete high-level behaviors as well as continuous trajectories describing
future motion. In this paper, we develop a one-stage detector and forecaster
that exploits both 3D point clouds produced by a LiDAR sensor as well as
dynamic maps of the environment. Our multi-task model achieves better accuracy
than the respective separate modules while saving computation, which is
critical to reducing reaction time in self-driving applications.
</p>
<a href="http://arxiv.org/abs/2101.07907" target="_blank">arXiv:2101.07907</a> [<a href="http://arxiv.org/pdf/2101.07907" target="_blank">pdf</a>]

<h2>Intelligent Icing Detection Model of Wind Turbine Blades Based on SCADA data. (arXiv:2101.07914v1 [cs.LG])</h2>
<h3>Wenqian Jiang, Junyang Jin</h3>
<p>Diagnosis of ice accretion on wind turbine blades is all the time a hard nut
to crack in condition monitoring of wind farms. Existing methods focus on
mechanism analysis of icing process, deviation degree analysis of feature
engineering. However, there have not been deep researches of neural networks
applied in this field at present. Supervisory control and data acquisition
(SCADA) makes it possible to train networks through continuously providing not
only operation parameters and performance parameters of wind turbines but also
environmental parameters and operation modes. This paper explores the
possibility that using convolutional neural networks (CNNs), generative
adversarial networks (GANs) and domain adaption learning to establish
intelligent diagnosis frameworks under different training scenarios.
Specifically, PGANC and PGANT are proposed for sufficient and non-sufficient
target wind turbine labeled data, respectively. The basic idea is that we
consider a two-stage training with parallel GANs, which are aimed at capturing
intrinsic features for normal and icing samples, followed by classification CNN
or domain adaption module in various training cases. Model validation on three
wind turbine SCADA data shows that two-stage training can effectively improve
the model performance. Besides, if there is no sufficient labeled data for a
target turbine, which is an extremely common phenomenon in real industrial
practices, the addition of domain adaption learning makes the trained model
show better performance. Overall, our proposed intelligent diagnosis frameworks
can achieve more accurate detection on the same wind turbine and more
generalized capability on a new wind turbine, compared with other machine
learning models and conventional CNNs.
</p>
<a href="http://arxiv.org/abs/2101.07914" target="_blank">arXiv:2101.07914</a> [<a href="http://arxiv.org/pdf/2101.07914" target="_blank">pdf</a>]

<h2>LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition. (arXiv:2101.07922v1 [cs.CV])</h2>
<h3>Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan, John Dickerson, Gavin Taylor, Tom Goldstein</h3>
<p>Facial recognition systems are increasingly deployed by private corporations,
government agencies, and contractors for consumer services and mass
surveillance programs alike. These systems are typically built by scraping
social media profiles for user images. Adversarial perturbations have been
proposed for bypassing facial recognition systems. However, existing methods
fail on full-scale systems and commercial APIs. We develop our own adversarial
filter that accounts for the entire image processing pipeline and is
demonstrably effective against industrial-grade pipelines that include face
detection and large scale databases. Additionally, we release an easy-to-use
webtool that significantly degrades the accuracy of Amazon Rekognition and the
Microsoft Azure Face Recognition API, reducing the accuracy of each to below 1%
</p>
<a href="http://arxiv.org/abs/2101.07922" target="_blank">arXiv:2101.07922</a> [<a href="http://arxiv.org/pdf/2101.07922" target="_blank">pdf</a>]

<h2>A Discrete Scheme for Computing Image's Weighted Gaussian Curvature. (arXiv:2101.07927v1 [cs.CV])</h2>
<h3>Yuanhao Gong, Wenming Tang, Lebin Zhou, Lantao Yu, Guoping Qiu</h3>
<p>Weighted Gaussian Curvature is an important measurement for images. However,
its conventional computation scheme has low performance, low accuracy and
requires that the input image must be second order differentiable. To tackle
these three issues, we propose a novel discrete computation scheme for the
weighted Gaussian curvature. Our scheme does not require the second order
differentiability. Moreover, our scheme is more accurate, has smaller support
region and computationally more efficient than the conventional schemes.
Therefore, our scheme holds promise for a large range of applications where the
weighted Gaussian curvature is needed, for example, image smoothing, cartoon
texture decomposition, optical flow estimation, etc.
</p>
<a href="http://arxiv.org/abs/2101.07927" target="_blank">arXiv:2101.07927</a> [<a href="http://arxiv.org/pdf/2101.07927" target="_blank">pdf</a>]

<h2>Online Active Proposal Set Generation for Weakly Supervised Object Detection. (arXiv:2101.07929v1 [cs.CV])</h2>
<h3>Ruibing Jin, Guosheng Lin, Changyun Wen</h3>
<p>To reduce the manpower consumption on box-level annotations, many weakly
supervised object detection methods which only require image-level annotations,
have been proposed recently. The training process in these methods is
formulated into two steps. They firstly train a neural network under weak
supervision to generate pseudo ground truths (PGTs). Then, these PGTs are used
to train another network under full supervision. Compared with fully supervised
methods, the training process in weakly supervised methods becomes more complex
and time-consuming. Furthermore, overwhelming negative proposals are involved
at the first step. This is neglected by most methods, which makes the training
network biased towards to negative proposals and thus degrades the quality of
the PGTs, limiting the training network performance at the second step. Online
proposal sampling is an intuitive solution to these issues. However, lacking of
adequate labeling, a simple online proposal sampling may make the training
network stuck into local minima. To solve this problem, we propose an Online
Active Proposal Set Generation (OPG) algorithm. Our OPG algorithm consists of
two parts: Dynamic Proposal Constraint (DPC) and Proposal Partition (PP). DPC
is proposed to dynamically determine different proposal sampling strategy
according to the current training state. PP is used to score each proposal,
part proposals into different sets and generate an active proposal set for the
network optimization. Through experiments, our proposed OPG shows consistent
and significant improvement on both datasets PASCAL VOC 2007 and 2012, yielding
comparable performance to the state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2101.07929" target="_blank">arXiv:2101.07929</a> [<a href="http://arxiv.org/pdf/2101.07929" target="_blank">pdf</a>]

<h2>Noise Learning Based Denoising Autoencoder. (arXiv:2101.07937v1 [cs.LG])</h2>
<h3>Woong-Hee Lee, Mustafa Ozger, Ursula Challita, Ki Won Sung</h3>
<p>This letter introduces a new denoiser that modifies the structure of
denoising autoencoder (DAE), namely noise learning based DAE (nlDAE). The
proposed nlDAE learns the noise instead of the original data. Then, the
denoising is performed by subtracting the regenerated noise from the noisy
input. Hence, nlDAE is more effective than DAE when the noise is simpler to
regenerate than the original data. To validate the performance of nlDAE, we
provide two case studies: symbol demodulation and precise localization.
Numerical results suggest that nlDAE requires smaller latent space dimension
and less training dataset compared to DAE.
</p>
<a href="http://arxiv.org/abs/2101.07937" target="_blank">arXiv:2101.07937</a> [<a href="http://arxiv.org/pdf/2101.07937" target="_blank">pdf</a>]

<h2>Beyond Fine-tuning: Classifying High Resolution Mammograms using Function-Preserving Transformations. (arXiv:2101.07945v1 [cs.CV])</h2>
<h3>Tao Wei, Angelica I Aviles-Rivero, Shuo Wang, Yuan Huang, Fiona J Gilbert, Carola-Bibiane Sch&#xf6;nlieb, Chang Wen Chen</h3>
<p>The task of classifying mammograms is very challenging because the lesion is
usually small in the high resolution image. The current state-of-the-art
approaches for medical image classification rely on using the de-facto method
for ConvNets - fine-tuning. However, there are fundamental differences between
natural images and medical images, which based on existing evidence from the
literature, limits the overall performance gain when designed with algorithmic
approaches. In this paper, we propose to go beyond fine-tuning by introducing a
novel framework called MorphHR, in which we highlight a new transfer learning
scheme. The idea behind the proposed framework is to integrate
function-preserving transformations, for any continuous non-linear activation
neurons, to internally regularise the network for improving mammograms
classification. The proposed solution offers two major advantages over the
existing techniques. Firstly and unlike fine-tuning, the proposed approach
allows for modifying not only the last few layers but also several of the first
ones on a deep ConvNet. By doing this, we can design the network front to be
suitable for learning domain specific features. Secondly, the proposed scheme
is scalable to hardware. Therefore, one can fit high resolution images on
standard GPU memory. We show that by using high resolution images, one prevents
losing relevant information. We demonstrate, through numerical and visual
experiments, that the proposed approach yields to a significant improvement in
the classification performance over state-of-the-art techniques, and is indeed
on a par with radiology experts. Moreover and for generalisation purposes, we
show the effectiveness of the proposed learning scheme on another large
dataset, the ChestX-ray14, surpassing current state-of-the-art techniques.
</p>
<a href="http://arxiv.org/abs/2101.07945" target="_blank">arXiv:2101.07945</a> [<a href="http://arxiv.org/pdf/2101.07945" target="_blank">pdf</a>]

<h2>SparseDNN: Fast Sparse Deep Learning Inference on CPUs. (arXiv:2101.07948v1 [cs.LG])</h2>
<h3>Ziheng Wang</h3>
<p>The last few years have seen gigantic leaps in algorithms and systems to
support efficient deep learning inference. Pruning and quantization algorithms
can now consistently compress neural networks by an order of magnitude. For a
compressed neural network, a multitude of inference frameworks have been
designed to maximize the performance of the target hardware. While we find
mature support for quantized neural networks in production frameworks such as
OpenVINO and MNN, support for pruned sparse neural networks is still lacking.
To tackle this challenge, we present SparseDNN, a sparse deep learning
inference engine targeting CPUs. We present both kernel-level optimizations
with a sparse code generator to accelerate sparse operators and novel
network-level optimizations catering to sparse networks. We show that our
sparse code generator can achieve significant speedups over state-of-the-art
sparse and dense libraries. On end-to-end benchmarks such as Huggingface
pruneBERT, SparseDNN achieves up to 5x throughput improvement over dense
inference with state-of-the-art OpenVINO.
</p>
<a href="http://arxiv.org/abs/2101.07948" target="_blank">arXiv:2101.07948</a> [<a href="http://arxiv.org/pdf/2101.07948" target="_blank">pdf</a>]

<h2>Convolutional conditional neural processes for local climate downscaling. (arXiv:2101.07950v1 [cs.LG])</h2>
<h3>Anna Vaughan, Will Tebbutt, J.Scott Hosking, Richard E. Turner</h3>
<p>A new model is presented for multisite statistical downscaling of temperature
and precipitation using convolutional conditional neural processes (convCNPs).
ConvCNPs are a recently developed class of models that allow deep learning
techniques to be applied to off-the-grid spatio-temporal data. This model has a
substantial advantage over existing downscaling methods in that the trained
model can be used to generate multisite predictions at an arbitrary set of
locations, regardless of the availability of training data. The convCNP model
is shown to outperform an ensemble of existing downscaling techniques over
Europe for both temperature and precipitation taken from the VALUE
intercomparison project. The model also outperforms an approach that uses
Gaussian processes to interpolate single-site downscaling models at unseen
locations. Importantly, substantial improvement is seen in the representation
of extreme precipitation events. These results indicate that the convCNP is a
robust downscaling model suitable for generating localised projections for use
in climate impact studies, and motivates further research into applications of
deep learning techniques in statistical downscaling.
</p>
<a href="http://arxiv.org/abs/2101.07950" target="_blank">arXiv:2101.07950</a> [<a href="http://arxiv.org/pdf/2101.07950" target="_blank">pdf</a>]

<h2>PyTorch-Direct: Enabling GPU Centric Data Access for Very Large Graph Neural Network Training with Irregular Accesses. (arXiv:2101.07956v1 [cs.LG])</h2>
<h3>Seung Won Min, Kun Wu, Sitao Huang, Mert Hidayeto&#x11f;lu, Jinjun Xiong, Eiman Ebrahimi, Deming Chen, Wen-mei Hwu</h3>
<p>With the increasing adoption of graph neural networks (GNNs) in the machine
learning community, GPUs have become an essential tool to accelerate GNN
training. However, training GNNs on very large graphs that do not fit in GPU
memory is still a challenging task. Unlike conventional neural networks,
mini-batching input samples in GNNs requires complicated tasks such as
traversing neighboring nodes and gathering their feature values. While this
process accounts for a significant portion of the training time, we find
existing GNN implementations using popular deep neural network (DNN) libraries
such as PyTorch are limited to a CPU-centric approach for the entire data
preparation step. This "all-in-CPU" approach has negative impact on the overall
GNN training performance as it over-utilizes CPU resources and hinders GPU
acceleration of GNN training. To overcome such limitations, we introduce
PyTorch-Direct, which enables a GPU-centric data accessing paradigm for GNN
training. In PyTorch-Direct, GPUs are capable of efficiently accessing
complicated data structures in host memory directly without CPU intervention.
Our microbenchmark and end-to-end GNN training results show that PyTorch-Direct
reduces data transfer time by 47.1% on average and speeds up GNN training by up
to 1.6x. Furthermore, by reducing CPU utilization, PyTorch-Direct also saves
system power by 12.4% to 17.5% during training. To minimize programmer effort,
we introduce a new "unified tensor" type along with necessary changes to the
PyTorch memory allocator, dispatch logic, and placement rules. As a result,
users need to change at most two lines of their PyTorch GNN training code for
each tensor object to take advantage of PyTorch-Direct.
</p>
<a href="http://arxiv.org/abs/2101.07956" target="_blank">arXiv:2101.07956</a> [<a href="http://arxiv.org/pdf/2101.07956" target="_blank">pdf</a>]

<h2>Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits with Linear Payoff Functions. (arXiv:2101.07957v1 [stat.ML])</h2>
<h3>Kei Takemura, Shinji Ito, Daisuke Hatano, Hanna Sumita, Takuro Fukunaga, Naonori Kakimura, Ken-ichi Kawarabayashi</h3>
<p>The contextual combinatorial semi-bandit problem with linear payoff functions
is a decision-making problem in which a learner chooses a set of arms with the
feature vectors in each round under given constraints so as to maximize the sum
of rewards of arms. Several existing algorithms have regret bounds that are
optimal with respect to the number of rounds $T$. However, there is a gap of
$\tilde{O}(\max(\sqrt{d}, \sqrt{k}))$ between the current best upper and lower
bounds, where $d$ is the dimension of the feature vectors, $k$ is the number of
the chosen arms in a round, and $\tilde{O}(\cdot)$ ignores the logarithmic
factors. The dependence of $k$ and $d$ is of practical importance because $k$
may be larger than $T$ in real-world applications such as recommender systems.
In this paper, we fill the gap by improving the upper and lower bounds. More
precisely, we show that the C${}^2$UCB algorithm proposed by Qin, Chen, and Zhu
(2014) has the optimal regret bound $\tilde{O}(d\sqrt{kT} + dk)$ for the
partition matroid constraints. For general constraints, we propose an algorithm
that modifies the reward estimates of arms in the C${}^2$UCB algorithm and
demonstrate that it enjoys the optimal regret bound for a more general problem
that can take into account other objectives simultaneously. We also show that
our technique would be applicable to related problems. Numerical experiments
support our theoretical results and considerations.
</p>
<a href="http://arxiv.org/abs/2101.07957" target="_blank">arXiv:2101.07957</a> [<a href="http://arxiv.org/pdf/2101.07957" target="_blank">pdf</a>]

<h2>Class balanced underwater object detection dataset generated by class-wise style augmentation. (arXiv:2101.07959v1 [cs.CV])</h2>
<h3>Long Chen, Junyu Dong, Huiyu Zhou</h3>
<p>Underwater object detection technique is of great significance for various
applications in underwater the scenes. However, class imbalance issue is still
an unsolved bottleneck for current underwater object detection algorithms. It
leads to large precision discrepancies among different classes that the
dominant classes with more training data achieve higher detection precisions
while the minority classes with fewer training data achieves much lower
detection precisions. In this paper, we propose a novel class-wise style
augmentation (CWSA) algorithm to generate a class-balanced underwater dataset
Balance18 from the public contest underwater dataset URPC2018. CWSA is a new
kind of data augmentation technique which augments the training data for the
minority classes by generating various colors, textures and contrasts for the
minority classes. Compare with previous data augmentation algorithms such
flipping, cropping and rotations, CWSA is able to generate a class balanced
underwater dataset with diverse color distortions and haze-effects.
</p>
<a href="http://arxiv.org/abs/2101.07959" target="_blank">arXiv:2101.07959</a> [<a href="http://arxiv.org/pdf/2101.07959" target="_blank">pdf</a>]

<h2>Directed Acyclic Graph Neural Networks. (arXiv:2101.07965v1 [cs.LG])</h2>
<h3>Veronika Thost, Jie Chen</h3>
<p>Graph-structured data ubiquitously appears in science and engineering. Graph
neural networks (GNNs) are designed to exploit the relational inductive bias
exhibited in graphs; they have been shown to outperform other forms of neural
networks in scenarios where structure information supplements node features.
The most common GNN architecture aggregates information from neighborhoods
based on message passing. Its generality has made it broadly applicable. In
this paper, we focus on a special, yet widely used, type of graphs -- DAGs --
and inject a stronger inductive bias -- partial ordering -- into the neural
network design. We propose the \emph{directed acyclic graph neural network},
DAGNN, an architecture that processes information according to the flow defined
by the partial order. DAGNN can be considered a framework that entails earlier
works as special cases (e.g., models for trees and models updating node
representations recurrently), but we identify several crucial components that
prior architectures lack. We perform comprehensive experiments, including
ablation studies, on representative DAG datasets (i.e., source code, neural
architectures, and probabilistic graphical models) and demonstrate the
superiority of DAGNN over simpler DAG architectures as well as general graph
architectures.
</p>
<a href="http://arxiv.org/abs/2101.07965" target="_blank">arXiv:2101.07965</a> [<a href="http://arxiv.org/pdf/2101.07965" target="_blank">pdf</a>]

<h2>TCLR: Temporal Contrastive Learning for Video Representation. (arXiv:2101.07974v1 [cs.CV])</h2>
<h3>Ishan Dave, Rohit Gupta, Mamshad Nayeem Rizve, Mubarak Shah</h3>
<p>Contrastive learning has nearly closed the gap between supervised and
self-supervised learning of image representations. Existing extensions of
contrastive learning to the domain of video data however, rely on naive
transposition of ideas from image-based methods and do not fully utilize the
temporal dimension present in video. We develop a new temporal contrastive
learning framework consisting of two novel losses to improve upon existing
contrastive self-supervised video representation learning methods. The first
loss adds the task of discriminating between non-overlapping clips from the
same video, whereas the second loss aims to discriminate between timesteps of
the feature map of an input clip in order to increase the temporal diversity of
the features. Temporal contrastive learning achieves significant improvement
over the state-of-the-art results in downstream video understanding tasks such
as action recognition, limited-label action classification, and
nearest-neighbor video retrieval on video datasets across multiple 3D CNN
architectures. With the commonly used 3D-ResNet-18 architecture, we achieve
82.4% (+5.1% increase over the previous best) top-1 accuracy on UCF101 and
52.9% (+5.4% increase) on HMDB51 action classification, and 56.2% (+11.7%
increase) Top-1 Recall on UCF101 nearest neighbor video retrieval.
</p>
<a href="http://arxiv.org/abs/2101.07974" target="_blank">arXiv:2101.07974</a> [<a href="http://arxiv.org/pdf/2101.07974" target="_blank">pdf</a>]

<h2>Representation Evaluation Block-based Teacher-Student Network for the Industrial Quality-relevant Performance Modeling and Monitoring. (arXiv:2101.07976v1 [cs.LG])</h2>
<h3>Dan Yang, Xin Peng, Yusheng Lu, Haojie Huang, Weimin Zhong</h3>
<p>Quality-relevant fault detection plays an important role in industrial
processes, while the current quality-related fault detection methods based on
neural networks main concentrate on process-relevant variables and ignore
quality-relevant variables, which restrict the application of process
monitoring. Therefore, in this paper, a fault detection scheme based on the
improved teacher-student network is proposed for quality-relevant fault
detection. In the traditional teacher-student network, as the features
differences between the teacher network and the student network will cause
performance degradation on the student network, representation evaluation block
(REB) is proposed to quantify the features differences between the teacher and
the student networks, and uncertainty modeling is used to add this difference
in modeling process, which are beneficial to reduce the features differences
and improve the performance of the student network. Accordingly, REB and
uncertainty modeling is applied in the teacher-student network named as
uncertainty modeling teacher-student uncertainty autoencoder (TSUAE). Then, the
proposed TSUAE is applied to process monitoring, which can effectively detect
faults in the process-relevant subspace and quality-relevant subspace
simultaneously. The proposed TSUAE-based fault detection method is verified in
two simulation experiments illustrating that it has satisfactory fault
detection performance compared to other fault detection methods.
</p>
<a href="http://arxiv.org/abs/2101.07976" target="_blank">arXiv:2101.07976</a> [<a href="http://arxiv.org/pdf/2101.07976" target="_blank">pdf</a>]

<h2>Semantic Disentangling Generalized Zero-ShotLearning. (arXiv:2101.07978v1 [cs.CV])</h2>
<h3>Zhi Chen, Ruihong Qiu, Sen Wang, Zi Huang, Jingjing Li, Zheng Zhang</h3>
<p>Generalized Zero-Shot Learning (GZSL) aims to recognize images from both seen
and unseen categories. Most GZSL methods typically learn to synthesize CNN
visual features for the unseen classes by leveraging entire semantic
information, e.g., tags and attributes, and the visual features of the seen
classes. Within the visual features, we define two types of features that
semantic-consistent and semantic-unrelated to represent the characteristics of
images annotated in attributes and less informative features of images
respectively. Ideally, the semantic-unrelated information is impossible to
transfer by semantic-visual relationship from seen classes to unseen classes,
as the corresponding characteristics are not annotated in the semantic
information. Thus, the foundation of the visual feature synthesis is not always
solid as the features of the seen classes may involve semantic-unrelated
information that could interfere with the alignment between semantic and visual
modalities. To address this issue, in this paper, we propose a novel feature
disentangling approach based on an encoder-decoder architecture to factorize
visual features of images into these two latent feature spaces to extract
corresponding representations. Furthermore, a relation module is incorporated
into this architecture to learn semantic-visual relationship, whilst a total
correlation penalty is applied to encourage the disentanglement of two latent
representations. The proposed model aims to distill quality semantic-consistent
representations that capture intrinsic features of seen images, which are
further taken as the generation target for unseen classes. Extensive
experiments conducted on seven GZSL benchmark datasets have verified the
state-of-the-art performance of the proposal.
</p>
<a href="http://arxiv.org/abs/2101.07978" target="_blank">arXiv:2101.07978</a> [<a href="http://arxiv.org/pdf/2101.07978" target="_blank">pdf</a>]

<h2>Non-Parametric Adaptive Network Pruning. (arXiv:2101.07985v1 [cs.CV])</h2>
<h3>Lin Mingbao, Ji Rongrong, Li Shaojie, Wang Yan, Wu Yongjian, Huang Feiyue, Ye Qixiang</h3>
<p>Popular network pruning algorithms reduce redundant information by optimizing
hand-crafted parametric models, and may cause suboptimal performance and long
time in selecting filters. We innovatively introduce non-parametric modeling to
simplify the algorithm design, resulting in an automatic and efficient pruning
approach called EPruner. Inspired by the face recognition community, we use a
message passing algorithm Affinity Propagation on the weight matrices to obtain
an adaptive number of exemplars, which then act as the preserved filters.
EPruner breaks the dependency on the training data in determining the
"important" filters and allows the CPU implementation in seconds, an order of
magnitude faster than GPU based SOTAs. Moreover, we show that the weights of
exemplars provide a better initialization for the fine-tuning. On VGGNet-16,
EPruner achieves a 76.34%-FLOPs reduction by removing 88.80% parameters, with
0.06% accuracy improvement on CIFAR-10. In ResNet-152, EPruner achieves a
65.12%-FLOPs reduction by removing 64.18% parameters, with only 0.71% top-5
accuracy loss on ILSVRC-2012. Code can be available at
https://github.com/lmbxmu/EPruner.
</p>
<a href="http://arxiv.org/abs/2101.07985" target="_blank">arXiv:2101.07985</a> [<a href="http://arxiv.org/pdf/2101.07985" target="_blank">pdf</a>]

<h2>Semi-supervised Keypoint Localization. (arXiv:2101.07988v1 [cs.CV])</h2>
<h3>Olga Moskvyak, Frederic Maire, Feras Dayoub, Mahsa Baktashmotlagh</h3>
<p>Knowledge about the locations of keypoints of an object in an image can
assist in fine-grained classification and identification tasks, particularly
for the case of objects that exhibit large variations in poses that greatly
influence their visual appearance, such as wild animals. However, supervised
training of a keypoint detection network requires annotating a large image
dataset for each animal species, which is a labor-intensive task. To reduce the
need for labeled data, we propose to learn simultaneously keypoint heatmaps and
pose invariant keypoint representations in a semi-supervised manner using a
small set of labeled images along with a larger set of unlabeled images.
Keypoint representations are learnt with a semantic keypoint consistency
constraint that forces the keypoint detection network to learn similar features
for the same keypoint across the dataset. Pose invariance is achieved by making
keypoint representations for the image and its augmented copies closer together
in feature space. Our semi-supervised approach significantly outperforms
previous methods on several benchmarks for human and animal body landmark
localization.
</p>
<a href="http://arxiv.org/abs/2101.07988" target="_blank">arXiv:2101.07988</a> [<a href="http://arxiv.org/pdf/2101.07988" target="_blank">pdf</a>]

<h2>Distributed Motion Coordination Using Convex Feasible Set Based Model Predictive Control. (arXiv:2101.07994v1 [cs.RO])</h2>
<h3>Hongyu Zhou, Changliu Liu</h3>
<p>The implementation of optimization-based motion coordination approaches in
real world multi-agent systems remains challenging due to their high
computational complexity and potential deadlocks. This paper presents a
distributed model predictive control (MPC) approach based on convex feasible
set (CFS) algorithm for multi-vehicle motion coordination in autonomous
driving. By using CFS to convexify the collision avoidance constraints,
collision-free trajectories can be computed in real time. We analyze the
potential deadlocks and show that a deadlock can be resolved by changing
vehicles' desired speeds. The MPC structure ensures that our algorithm is
robust to low-level tracking errors. The proposed distributed method has been
tested in multiple challenging multi-vehicle environments, including
unstructured road, intersection, crossing, platoon formation, merging, and
overtaking scenarios. The numerical results and comparison with other
approaches (including a centralized MPC and reciprocal velocity obstacles) show
that the proposed method is computationally efficient and robust, and avoids
deadlocks.
</p>
<a href="http://arxiv.org/abs/2101.07994" target="_blank">arXiv:2101.07994</a> [<a href="http://arxiv.org/pdf/2101.07994" target="_blank">pdf</a>]

<h2>FedNS: Improving Federated Learning for collaborative image classification on mobile clients. (arXiv:2101.07995v1 [cs.CV])</h2>
<h3>Yaoxin Zhuo, Baoxin Li</h3>
<p>Federated Learning (FL) is a paradigm that aims to support loosely connected
clients in learning a global model collaboratively with the help of a
centralized server. The most popular FL algorithm is Federated Averaging
(FedAvg), which is based on taking weighted average of the client models, with
the weights determined largely based on dataset sizes at the clients. In this
paper, we propose a new approach, termed Federated Node Selection (FedNS), for
the server's global model aggregation in the FL setting. FedNS filters and
re-weights the clients' models at the node/kernel level, hence leading to a
potentially better global model by fusing the best components of the clients.
Using collaborative image classification as an example, we show with
experiments from multiple datasets and networks that FedNS can consistently
achieve improved performance over FedAvg.
</p>
<a href="http://arxiv.org/abs/2101.07995" target="_blank">arXiv:2101.07995</a> [<a href="http://arxiv.org/pdf/2101.07995" target="_blank">pdf</a>]

<h2>Macroscopic Control of Text Generation for Image Captioning. (arXiv:2101.08000v1 [cs.CV])</h2>
<h3>Zhangzi Zhu, Tianlei Wang, Hong Qu</h3>
<p>Despite the fact that image captioning models have been able to generate
impressive descriptions for a given image, challenges remain: (1) the
controllability and diversity of existing models are still far from
satisfactory; (2) models sometimes may produce extremely poor-quality captions.
In this paper, two novel methods are introduced to solve the problems
respectively. Specifically, for the former problem, we introduce a control
signal which can control the macroscopic sentence attributes, such as sentence
quality, sentence length, sentence tense and number of nouns etc. With such a
control signal, the controllability and diversity of existing captioning models
are enhanced. For the latter problem, we innovatively propose a strategy that
an image-text matching model is trained to measure the quality of sentences
generated in both forward and backward directions and finally choose the better
one. As a result, this strategy can effectively reduce the proportion of
poorquality sentences. Our proposed methods can be easily applie on most image
captioning models to improve their overall performance. Based on the Up-Down
model, the experimental results show that our methods achieve BLEU-
4/CIDEr/SPICE scores of 37.5/120.3/21.5 on MSCOCO Karpathy test split with
cross-entropy training, which surpass the results of other state-of-the-art
methods trained by cross-entropy loss.
</p>
<a href="http://arxiv.org/abs/2101.08000" target="_blank">arXiv:2101.08000</a> [<a href="http://arxiv.org/pdf/2101.08000" target="_blank">pdf</a>]

<h2>UPDeT: Universal Multi-agent Reinforcement Learning via Policy Decoupling with Transformers. (arXiv:2101.08001v1 [cs.LG])</h2>
<h3>Siyi Hu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang</h3>
<p>Recent advances in multi-agent reinforcement learning have been largely
limited in training one model from scratch for every new task. The limitation
is due to the restricted model architecture related to fixed input and output
dimensions. This hinders the experience accumulation and transfer of the
learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs
6 multi-agent games). In this paper, we make the first attempt to explore a
universal multi-agent reinforcement learning pipeline, designing one single
architecture to fit tasks with the requirement of different observation and
action configurations. Unlike previous RNN-based models, we utilize a
transformer-based model to generate a flexible policy by decoupling the policy
distribution from the intertwined input observation with an importance weight
measured by the merits of the self-attention mechanism. Compared to a standard
transformer block, the proposed model, named as Universal Policy Decoupling
Transformer (UPDeT), further relaxes the action restriction and makes the
multi-agent task's decision process more explainable. UPDeT is general enough
to be plugged into any multi-agent reinforcement learning pipeline and equip
them with strong generalization abilities that enables the handling of multiple
tasks at a time. Extensive experiments on large-scale SMAC multi-agent
competitive games demonstrate that the proposed UPDeT-based multi-agent
reinforcement learning achieves significant results relative to
state-of-the-art approaches, demonstrating advantageous transfer capability in
terms of both performance and training speed (10 times faster).
</p>
<a href="http://arxiv.org/abs/2101.08001" target="_blank">arXiv:2101.08001</a> [<a href="http://arxiv.org/pdf/2101.08001" target="_blank">pdf</a>]

<h2>Deep Learning for Intelligent Demand Response and Smart Grids: A Comprehensive Survey. (arXiv:2101.08013v1 [cs.LG])</h2>
<h3>Prabadevi B, Quoc-Viet Pham, Madhusanka Liyanage, N Deepa, Mounik VVSS, Shivani Reddy, Praveen Kumar Reddy Maddikunta, Neelu Khare, Thippa Reddy Gadekallu, Won-Joo Hwang</h3>
<p>Electricity is one of the mandatory commodities for mankind today. To address
challenges and issues in the transmission of electricity through the
traditional grid, the concepts of smart grids and demand response have been
developed. In such systems, a large amount of data is generated daily from
various sources such as power generation (e.g., wind turbines), transmission
and distribution (microgrids and fault detectors), load management (smart
meters and smart electric appliances). Thanks to recent advancements in big
data and computing technologies, Deep Learning (DL) can be leveraged to learn
the patterns from the generated data and predict the demand for electricity and
peak hours. Motivated by the advantages of deep learning in smart grids, this
paper sets to provide a comprehensive survey on the application of DL for
intelligent smart grids and demand response. Firstly, we present the
fundamental of DL, smart grids, demand response, and the motivation behind the
use of DL. Secondly, we review the state-of-the-art applications of DL in smart
grids and demand response, including electric load forecasting, state
estimation, energy theft detection, energy sharing and trading. Furthermore, we
illustrate the practicality of DL via various use cases and projects. Finally,
we highlight the challenges presented in existing research works and highlight
important issues and potential directions in the use of DL for smart grids and
demand response.
</p>
<a href="http://arxiv.org/abs/2101.08013" target="_blank">arXiv:2101.08013</a> [<a href="http://arxiv.org/pdf/2101.08013" target="_blank">pdf</a>]

<h2>Improved Signed Distance Function for 2D Real-time SLAM and Accurate Localization. (arXiv:2101.08018v1 [cs.RO])</h2>
<h3>Xingyin Fu, Zheng Fang, Xizhen Xiao, Yijia He, Xiao Liu</h3>
<p>Accurate mapping and localization are very important for many industrial
robotics applications. In this paper, we propose an improved Signed Distance
Function (SDF) for both 2D SLAM and pure localization to improve the accuracy
of mapping and localization. To achieve this goal, firstly we improved the
back-end mapping to build a more accurate SDF map by extending the update range
and building free space, etc. Secondly, to get more accurate pose estimation
for the front-end, we proposed a new iterative registration method to align the
current scan to the SDF submap by removing random outliers of laser scanners.
Thirdly, we merged all the SDF submaps to produce an integrated SDF map for
highly accurate pure localization. Experimental results show that based on the
merged SDF map, a localization accuracy of a few millimeters (5mm) can be
achieved globally within the map. We believe that this method is important for
mobile robots working in scenarios where high localization accuracy matters.
</p>
<a href="http://arxiv.org/abs/2101.08018" target="_blank">arXiv:2101.08018</a> [<a href="http://arxiv.org/pdf/2101.08018" target="_blank">pdf</a>]

<h2>Scalable Deep Compressive Sensing. (arXiv:2101.08024v1 [cs.CV])</h2>
<h3>Zhonghao Zhang, Yipeng Liu, Xingyu Cao, Fei Wen, Ce Zhu</h3>
<p>Deep learning has been used to image compressive sensing (CS) for enhanced
reconstruction performance. However, most existing deep learning methods train
different models for different subsampling ratios, which brings additional
hardware burden. In this paper, we develop a general framework named scalable
deep compressive sensing (SDCS) for the scalable sampling and reconstruction
(SSR) of all existing end-to-end-trained models. In the proposed way, images
are measured and initialized linearly. Two sampling masks are introduced to
flexibly control the subsampling ratios used in sampling and reconstruction,
respectively. To make the reconstruction model adapt to any subsampling ratio,
a training strategy dubbed scalable training is developed. In scalable
training, the model is trained with the sampling matrix and the initialization
matrix at various subsampling ratios by integrating different sampling matrix
masks. Experimental results show that models with SDCS can achieve SSR without
changing their structure while maintaining good performance, and SDCS
outperforms other SSR methods.
</p>
<a href="http://arxiv.org/abs/2101.08024" target="_blank">arXiv:2101.08024</a> [<a href="http://arxiv.org/pdf/2101.08024" target="_blank">pdf</a>]

<h2>Riemannian-based Discriminant Analysis for Feature Extraction and Classification. (arXiv:2101.08032v1 [cs.LG])</h2>
<h3>Wanguang Yin, Zhengming Ma, Quanying Liu</h3>
<p>Discriminant analysis, as a widely used approach in machine learning to
extract low-dimensional features from the high-dimensional data, applies the
Fisher discriminant criterion to find the orthogonal discriminant projection
subspace. But most of the Euclidean-based algorithms for discriminant analysis
are easily convergent to a spurious local minima and hardly obtain an unique
solution. To address such problem, in this study we propose a novel method
named Riemannian-based Discriminant Analysis (RDA), which transforms the
traditional Euclidean-based methods to the Riemannian manifold space. In RDA,
the second-order geometry of trust-region methods is utilized to learn the
discriminant bases. To validate the efficiency and effectiveness of RDA, we
conduct a variety of experiments on image classification tasks. The numerical
results suggest that RDA can extract statistically significant features and
robustly outperform state-of-the-art algorithms in classification tasks.
</p>
<a href="http://arxiv.org/abs/2101.08032" target="_blank">arXiv:2101.08032</a> [<a href="http://arxiv.org/pdf/2101.08032" target="_blank">pdf</a>]

<h2>Bias in ontologies -- a preliminary assessment. (arXiv:2101.08035v1 [cs.AI])</h2>
<h3>C. Maria Keet</h3>
<p>Logical theories in the form of ontologies and similar artefacts in computing
and IT are used for structuring, annotating, and querying data, among others,
and therewith influence data analytics regarding what is fed into the
algorithms. Algorithmic bias is a well-known notion, but what does bias mean in
the context of ontologies that provide a structuring mechanism for an
algorithm's input? What are the sources of bias there and how would they
manifest themselves in ontologies? We examine and enumerate types of bias
relevant for ontologies, and whether they are explicit or implicit. These eight
types are illustrated with examples from extant production-level ontologies and
samples from the literature. We then assessed three concurrently developed
COVID-19 ontologies on bias and detected different subsets of types of bias in
each one, to a greater or lesser extent. This first characterisation aims
contribute to a sensitisation of ethical aspects of ontologies primarily
regarding representation of information and knowledge.
</p>
<a href="http://arxiv.org/abs/2101.08035" target="_blank">arXiv:2101.08035</a> [<a href="http://arxiv.org/pdf/2101.08035" target="_blank">pdf</a>]

<h2>1st Place Solution to ECCV-TAO-2020: Detect and Represent Any Object for Tracking. (arXiv:2101.08040v1 [cs.CV])</h2>
<h3>Fei Du, Bo Xu, Jiasheng Tang, Yuqi Zhang, Fan Wang, Hao Li</h3>
<p>We extend the classical tracking-by-detection paradigm to this
tracking-any-object task. Solid detection results are first extracted from TAO
dataset. Some state-of-the-art techniques like \textbf{BA}lanced-\textbf{G}roup
\textbf{S}oftmax (\textbf{BAGS}\cite{li2020overcoming}) and
DetectoRS\cite{qiao2020detectors} are integrated during detection. Then we
learned appearance features to represent any object by training feature
learning networks. We ensemble several models for improving detection and
feature representation. Simple linking strategies with most similar appearance
features and tracklet-level post association module are finally applied to
generate final tracking results. Our method is submitted as \textbf{AOA} on the
challenge website.
</p>
<a href="http://arxiv.org/abs/2101.08040" target="_blank">arXiv:2101.08040</a> [<a href="http://arxiv.org/pdf/2101.08040" target="_blank">pdf</a>]

<h2>A Similarity Measure of Gaussian Process Predictive Distributions. (arXiv:2101.08061v1 [cs.LG])</h2>
<h3>Lucia Asencio-Mart&#xed;n, Eduardo C. Garrido-Merch&#xe1;n</h3>
<p>Some scenarios require the computation of a predictive distribution of a new
value evaluated on an objective function conditioned on previous observations.
We are interested on using a model that makes valid assumptions on the
objective function whose values we are trying to predict. Some of these
assumptions may be smoothness or stationarity. Gaussian process (GPs) are
probabilistic models that can be interpreted as flexible distributions over
functions. They encode the assumptions through covariance functions, making
hypotheses about new data through a predictive distribution by being fitted to
old observations. We can face the case where several GPs are used to model
different objective functions. GPs are non-parametric models whose complexity
is cubic on the number of observations. A measure that represents how similar
is one GP predictive distribution with respect to another would be useful to
stop using one GP when they are modelling functions of the same input space. We
are really inferring that two objective functions are correlated, so one GP is
enough to model both of them by performing a transformation of the prediction
of the other function in case of inverse correlation. We show empirical
evidence in a set of synthetic and benchmark experiments that GPs predictive
distributions can be compared and that one of them is enough to predict two
correlated functions in the same input space. This similarity metric could be
extremely useful used to discard objectives in Bayesian many-objective
optimization.
</p>
<a href="http://arxiv.org/abs/2101.08061" target="_blank">arXiv:2101.08061</a> [<a href="http://arxiv.org/pdf/2101.08061" target="_blank">pdf</a>]

<h2>Component Tree Loss Function: Definition and Optimization. (arXiv:2101.08063v1 [cs.LG])</h2>
<h3>Benjamin Perret (LIGM), Jean Cousty (LIGM)</h3>
<p>In this article, we propose a method to design loss functions based on
component trees which can be optimized by gradient descent algorithms and which
are therefore usable in conjunction with recent machine learning approaches
such as neural networks. We show how the altitudes associated to the nodes of
such hierarchical image representations can be differentiated with respect to
the image pixel values. This feature is used to design a generic loss function
that can select or discard image maxima based on various attributes such as
extinction values. The possibilities of the proposed method are demonstrated on
simulated and real image filtering.
</p>
<a href="http://arxiv.org/abs/2101.08063" target="_blank">arXiv:2101.08063</a> [<a href="http://arxiv.org/pdf/2101.08063" target="_blank">pdf</a>]

<h2>Few-shot Action Recognition with Prototype-centered Attentive Learning. (arXiv:2101.08085v1 [cs.CV])</h2>
<h3>Xiatian Zhu, Antoine Toisoul, Juan-Manuel Prez-Ra, Li Zhang, Brais Martinez, Tao Xiang</h3>
<p>Few-shot action recognition aims to recognize action classes with few
training samples. Most existing methods adopt a meta-learning approach with
episodic training. In each episode, the few samples in a meta-training task are
split into support and query sets. The former is used to build a classifier,
which is then evaluated on the latter using a query-centered loss for model
updating. There are however two major limitations: lack of data efficiency due
to the query-centered only loss design and inability to deal with the support
set outlying samples and inter-class distribution overlapping problems. In this
paper, we overcome both limitations by proposing a new Prototype-centered
Attentive Learning (PAL) model composed of two novel components. First, a
prototype-centered contrastive learning loss is introduced to complement the
conventional query-centered learning objective, in order to make full use of
the limited training samples in each episode. Second, PAL further integrates a
hybrid attentive learning mechanism that can minimize the negative impacts of
outliers and promote class separation. Extensive experiments on four standard
few-shot action benchmarks show that our method clearly outperforms previous
state-of-the-art methods, with the improvement particularly significant (10+\%)
on the most challenging fine-grained action recognition benchmark.
</p>
<a href="http://arxiv.org/abs/2101.08085" target="_blank">arXiv:2101.08085</a> [<a href="http://arxiv.org/pdf/2101.08085" target="_blank">pdf</a>]

<h2>Active Model Learning using Informative Trajectories for Improved Closed-Loop Control on Real Robots. (arXiv:2101.08100v1 [cs.RO])</h2>
<h3>Weixuan Zhang, Lionel Ott, Marco Tognon, Roland Siegwart, Juan Nieto</h3>
<p>Model-based controllers on real robots require accurate knowledge of the
system dynamics to perform optimally. For complex dynamics, first-principles
modeling is not sufficiently precise, and data-driven approaches can be
leveraged to learn a statistical model from real experiments. However, the
efficient and effective data collection for such a data-driven system on real
robots is still an open challenge. This paper introduces an optimization
problem formulation to find an informative trajectory that allows for efficient
data collection and model learning. We present a sampling-based method that
computes an approximation of the trajectory that minimizes the prediction
uncertainty of the dynamics model. This trajectory is then executed, collecting
the data to update the learned model. In experiments we demonstrate the
capabilities of our proposed framework when applied to a complex
omnidirectional flying vehicle with tiltable rotors. Using our informative
trajectories results in models which outperform models obtained from
non-informative trajectory by 13.3\% with the same amount of training data.
Furthermore, we show that the model learned from informative trajectories
generalizes better than the one learned from non-informative trajectories,
achieving better tracking performance on different tasks.
</p>
<a href="http://arxiv.org/abs/2101.08100" target="_blank">arXiv:2101.08100</a> [<a href="http://arxiv.org/pdf/2101.08100" target="_blank">pdf</a>]

<h2>A Generalized Weisfeiler-Lehman Graph Kernel. (arXiv:2101.08104v1 [cs.LG])</h2>
<h3>Till Hendrik Schulz, Tam&#xe1;s Horv&#xe1;th, Pascal Welke, Stefan Wrobel</h3>
<p>The Weisfeiler-Lehman graph kernels are among the most prevalent graph
kernels due to their remarkable time complexity and predictive performance.
Their key concept is based on an implicit comparison of neighborhood
representing trees with respect to equality (i.e., isomorphism). This binary
valued comparison is, however, arguably too rigid for defining suitable
similarity measures over graphs. To overcome this limitation, we propose a
generalization of Weisfeiler-Lehman graph kernels which takes into account the
similarity between trees rather than equality. We achieve this using a
specifically fitted variation of the well-known tree edit distance which can
efficiently be calculated. We empirically show that our approach significantly
outperforms state-of-the-art methods in terms of predictive performance on
datasets containing structurally more complex graphs beyond the typically
considered molecular graphs.
</p>
<a href="http://arxiv.org/abs/2101.08104" target="_blank">arXiv:2101.08104</a> [<a href="http://arxiv.org/pdf/2101.08104" target="_blank">pdf</a>]

<h2>Self-supervised pre-training enhances change detection in Sentinel-2 imagery. (arXiv:2101.08122v1 [cs.CV])</h2>
<h3>Marrit Leenstra, Diego Marcos, Francesca Bovolo, Devis Tuia</h3>
<p>While annotated images for change detection using satellite imagery are
scarce and costly to obtain, there is a wealth of unlabeled images being
generated every day. In order to leverage these data to learn an image
representation more adequate for change detection, we explore methods that
exploit the temporal consistency of Sentinel-2 times series to obtain a usable
self-supervised learning signal. For this, we build and make publicly available
(https://zenodo.org/record/4280482) the Sentinel-2 Multitemporal Cities Pairs
(S2MTCP) dataset, containing multitemporal image pairs from 1520 urban areas
worldwide. We test the results of multiple self-supervised learning methods for
pre-training models for change detection and apply it on a public change
detection dataset made of Sentinel-2 image pairs (OSCD).
</p>
<a href="http://arxiv.org/abs/2101.08122" target="_blank">arXiv:2101.08122</a> [<a href="http://arxiv.org/pdf/2101.08122" target="_blank">pdf</a>]

<h2>Zero-Cost Proxies for Lightweight NAS. (arXiv:2101.08134v1 [cs.LG])</h2>
<h3>Mohamed S. Abdelfattah, Abhinav Mehrotra, &#x141;ukasz Dudziak, Nicholas D. Lane</h3>
<p>Neural Architecture Search (NAS) is quickly becoming the standard methodology
to design neural network models. However, NAS is typically compute-intensive
because multiple models need to be evaluated before choosing the best one. To
reduce the computational power and time needed, a proxy task is often used for
evaluating each model instead of full training. In this paper, we evaluate
conventional reduced-training proxies and quantify how well they preserve
ranking between multiple models during search when compared with the rankings
produced by final trained accuracy. We propose a series of zero-cost proxies,
based on recent pruning literature, that use just a single minibatch of
training data to compute a model's score. Our zero-cost proxies use 3 orders of
magnitude less computation but can match and even outperform conventional
proxies. For example, Spearman's rank correlation coefficient between final
validation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82,
compared to 0.61 for EcoNAS (a recently proposed reduced-training proxy).
Finally, we use these zero-cost proxies to enhance existing NAS search
algorithms such as random search, reinforcement learning, evolutionary search
and predictor-based search. For all search methodologies and across three
different NAS datasets, we are able to significantly improve sample efficiency,
and thereby decrease computation, by using our zero-cost proxies. For example
on NAS-Bench-101, we achieved the same accuracy 4$\times$ quicker than the best
previous result.
</p>
<a href="http://arxiv.org/abs/2101.08134" target="_blank">arXiv:2101.08134</a> [<a href="http://arxiv.org/pdf/2101.08134" target="_blank">pdf</a>]

<h2>Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments. (arXiv:2101.08152v1 [cs.LG])</h2>
<h3>Daochen Zha, Wenye Ma, Lei Yuan, Xia Hu, Ji Liu</h3>
<p>Exploration under sparse reward is a long-standing challenge of model-free
reinforcement learning. The state-of-the-art methods address this challenge by
introducing intrinsic rewards to encourage exploration in novel states or
uncertain environment dynamics. Unfortunately, methods based on intrinsic
rewards often fall short in procedurally-generated environments, where a
different environment is generated in each episode so that the agent is not
likely to visit the same state more than once. Motivated by how humans
distinguish good exploration behaviors by looking into the entire episode, we
introduce RAPID, a simple yet effective episode-level exploration method for
procedurally-generated environments. RAPID regards each episode as a whole and
gives an episodic exploration score from both per-episode and long-term views.
Those highly scored episodes are treated as good exploration behaviors and are
stored in a small ranking buffer. The agent then imitates the episodes in the
buffer to reproduce the past good exploration behaviors. We demonstrate our
method on several procedurally-generated MiniGrid environments, a
first-person-view 3D Maze navigation task from MiniWorld, and several sparse
MuJoCo tasks. The results show that RAPID significantly outperforms the
state-of-the-art intrinsic reward strategies in terms of sample efficiency and
final performance. The code is available at https://github.com/daochenzha/rapid
</p>
<a href="http://arxiv.org/abs/2101.08152" target="_blank">arXiv:2101.08152</a> [<a href="http://arxiv.org/pdf/2101.08152" target="_blank">pdf</a>]

<h2>Shielding Atari Games with Bounded Prescience. (arXiv:2101.08153v1 [cs.AI])</h2>
<h3>Mirco Giacobbe, Mohammadhosein Hasanbeig, Daniel Kroening, Hjalmar Wijk</h3>
<p>Deep reinforcement learning (DRL) is applied in safety-critical domains such
as robotics and autonomous driving. It achieves superhuman abilities in many
tasks, however whether DRL agents can be shown to act safely is an open
problem. Atari games are a simple yet challenging exemplar for evaluating the
safety of DRL agents and feature a diverse portfolio of game mechanics. The
safety of neural agents has been studied before using methods that either
require a model of the system dynamics or an abstraction; unfortunately, these
are unsuitable to Atari games because their low-level dynamics are complex and
hidden inside their emulator. We present the first exact method for analysing
and ensuring the safety of DRL agents for Atari games. Our method only requires
access to the emulator. First, we give a set of properties that characterise
"safe behaviour" for several games. Second, we develop a method for exploring
all traces induced by an agent and a game and consider a variety of sources of
game non-determinism. We observe that the best available DRL agents reliably
satisfy only very few properties; several critical properties are violated by
all agents. Finally, we propose a countermeasure that combines a bounded
explicit-state exploration with shielding. We demonstrate that our method
improves the safety of all agents over multiple properties.
</p>
<a href="http://arxiv.org/abs/2101.08153" target="_blank">arXiv:2101.08153</a> [<a href="http://arxiv.org/pdf/2101.08153" target="_blank">pdf</a>]

<h2>Fooling thermal infrared pedestrian detectors in real world using small bulbs. (arXiv:2101.08154v1 [cs.CV])</h2>
<h3>Xiaopei Zhu, Xiao Li, Jianmin Li, Zheyao Wang, Xiaolin Hu</h3>
<p>Thermal infrared detection systems play an important role in many areas such
as night security, autonomous driving, and body temperature detection. They
have the unique advantages of passive imaging, temperature sensitivity and
penetration. But the security of these systems themselves has not been fully
explored, which poses risks in applying these systems. We propose a physical
attack method with small bulbs on a board against the state of-the-art
pedestrian detectors. Our goal is to make infrared pedestrian detectors unable
to detect real-world pedestrians. Towards this goal, we first showed that it is
possible to use two kinds of patches to attack the infrared pedestrian detector
based on YOLOv3. The average precision (AP) dropped by 64.12% in the digital
world, while a blank board with the same size caused the AP to drop by 29.69%
only. After that, we designed and manufactured a physical board and
successfully attacked YOLOv3 in the real world. In recorded videos, the
physical board caused AP of the target detector to drop by 34.48%, while a
blank board with the same size caused the AP to drop by 14.91% only. With the
ensemble attack techniques, the designed physical board had good
transferability to unseen detectors.
</p>
<a href="http://arxiv.org/abs/2101.08154" target="_blank">arXiv:2101.08154</a> [<a href="http://arxiv.org/pdf/2101.08154" target="_blank">pdf</a>]

<h2>Focal and Efficient IOU Loss for Accurate Bounding Box Regression. (arXiv:2101.08158v1 [cs.CV])</h2>
<h3>Yi-Fan Zhang, Weiqiang Ren, Zhang Zhang, Zhen Jia, Liang Wang, Tieniu Tan</h3>
<p>In object detection, bounding box regression (BBR) is a crucial step that
determines the object localization performance. However, we find that most
previous loss functions for BBR have two main drawbacks: (i) Both $\ell_n$-norm
and IOU-based loss functions are inefficient to depict the objective of BBR,
which leads to slow convergence and inaccurate regression results. (ii) Most of
the loss functions ignore the imbalance problem in BBR that the large number of
anchor boxes which have small overlaps with the target boxes contribute most to
the optimization of BBR. To mitigate the adverse effects caused thereby, we
perform thorough studies to exploit the potential of BBR losses in this paper.
Firstly, an Efficient Intersection over Union (EIOU) loss is proposed, which
explicitly measures the discrepancies of three geometric factors in BBR, i.e.,
the overlap area, the central point and the side length. After that, we state
the Effective Example Mining (EEM) problem and propose a regression version of
focal loss to make the regression process focus on high-quality anchor boxes.
Finally, the above two parts are combined to obtain a new loss function, namely
Focal-EIOU loss. Extensive experiments on both synthetic and real datasets are
performed. Notable superiorities on both the convergence speed and the
localization accuracy can be achieved over other BBR losses.
</p>
<a href="http://arxiv.org/abs/2101.08158" target="_blank">arXiv:2101.08158</a> [<a href="http://arxiv.org/pdf/2101.08158" target="_blank">pdf</a>]

<h2>Video Relation Detection with Trajectory-aware Multi-modal Features. (arXiv:2101.08165v1 [cs.CV])</h2>
<h3>Wentao Xie, Guanghui Ren, Si Liu</h3>
<p>Video relation detection problem refers to the detection of the relationship
between different objects in videos, such as spatial relationship and action
relationship. In this paper, we present video relation detection with
trajectory-aware multi-modal features to solve this task.

Considering the complexity of doing visual relation detection in videos, we
decompose this task into three sub-tasks: object detection, trajectory proposal
and relation prediction. We use the state-of-the-art object detection method to
ensure the accuracy of object trajectory detection and multi-modal feature
representation to help the prediction of relation between objects. Our method
won the first place on the video relation detection task of Video Relation
Understanding Grand Challenge in ACM Multimedia 2020 with 11.74\% mAP, which
surpasses other methods by a large margin.
</p>
<a href="http://arxiv.org/abs/2101.08165" target="_blank">arXiv:2101.08165</a> [<a href="http://arxiv.org/pdf/2101.08165" target="_blank">pdf</a>]

<h2>mt5b3: A Framework for Building AutonomousTraders. (arXiv:2101.08169v1 [cs.AI])</h2>
<h3>Paulo Andr&#xe9; Lima de Castro</h3>
<p>Autonomous trading robots have been studied in ar-tificial intelligence area
for quite some time. Many AI techniqueshave been tested in finance field
including recent approaches likeconvolutional neural networks and deep
reinforcement learning.There are many reported cases, where the developers are
suc-cessful in creating robots with great performance when executingwith
historical price series, so called backtesting. However, whenthese robots are
used in real markets or data not used intheir training or evaluation frequently
they present very poorperformance in terms of risks and return. In this paper,
wediscussed some fundamental aspects of modelling autonomoustraders and the
complex environment that is the financialworld. Furthermore, we presented a
framework that helps thedevelopment and testing of autonomous traders. It may
also beused in real or simulated operation in financial markets. Finally,we
discussed some open problems in the area and pointed outsome interesting
technologies that may contribute to advancein such task. We believe that mt5b3
may also contribute todevelopment of new autonomous traders.
</p>
<a href="http://arxiv.org/abs/2101.08169" target="_blank">arXiv:2101.08169</a> [<a href="http://arxiv.org/pdf/2101.08169" target="_blank">pdf</a>]

<h2>SUGAR: Subgraph Neural Network with Reinforcement Pooling and Self-Supervised Mutual Information Mechanism. (arXiv:2101.08170v1 [cs.LG])</h2>
<h3>Qingyun Sun, Hao Peng, Jianxin Li, Jia Wu, Yuanxing Ning, Phillip S. Yu, Lifang He</h3>
<p>Graph representation learning has attracted increasing research attention.
However, most existing studies fuse all structural features and node attributes
to provide an overarching view of graphs, neglecting finer substructures'
semantics, and suffering from interpretation enigmas. This paper presents a
novel hierarchical subgraph-level selection and embedding based graph neural
network for graph classification, namely SUGAR, to learn more discriminative
subgraph representations and respond in an explanatory way. SUGAR reconstructs
a sketched graph by extracting striking subgraphs as the representative part of
the original graph to reveal subgraph-level patterns. To adaptively select
striking subgraphs without prior knowledge, we develop a reinforcement pooling
mechanism, which improves the generalization ability of the model. To
differentiate subgraph representations among graphs, we present a
self-supervised mutual information mechanism to encourage subgraph embedding to
be mindful of the global graph structural properties by maximizing their mutual
information. Extensive experiments on six typical bioinformatics datasets
demonstrate a significant and consistent improvement in model quality with
competitive performance and interpretability.
</p>
<a href="http://arxiv.org/abs/2101.08170" target="_blank">arXiv:2101.08170</a> [<a href="http://arxiv.org/pdf/2101.08170" target="_blank">pdf</a>]

<h2>Mask-GD Segmentation Based Robotic Grasp Detection. (arXiv:2101.08183v1 [cs.RO])</h2>
<h3>Mingshuai Dong, Shimin Wei, Xiuli Yu, Jianqin Yin</h3>
<p>The reliability of grasp detection for target objects in complex scenes is a
challenging task and a critical problem that needs to be solved urgently in
practical application. At present, the grasp detection location comes from
searching the feature space of the whole image. However, the cluttered
background information in the image impairs the accuracy of grasping detection.
In this paper, a robotic grasp detection algorithm named MASK-GD is proposed,
which provides a feasible solution to this problem. MASK is a segmented image
that only contains the pixels of the target object. MASK-GD for grasp detection
only uses MASK features rather than the features of the entire image in the
scene. It has two stages: the first stage is to provide the MASK of the target
object as the input image, and the second stage is a grasp detector based on
the MASK feature. Experimental results demonstrate that MASK-GD's performance
is comparable with state-of-the-art grasp detection algorithms on Cornell
Datasets and Jacquard Dataset. In the meantime, MASK-GD performs much better in
complex scenes.
</p>
<a href="http://arxiv.org/abs/2101.08183" target="_blank">arXiv:2101.08183</a> [<a href="http://arxiv.org/pdf/2101.08183" target="_blank">pdf</a>]

<h2>SAR and Optical data fusion based on Anisotropic Diffusion with PCA and Classification using Patch-based with LBP. (arXiv:2101.08215v1 [cs.CV])</h2>
<h3>Achala Shakya, Mantosh Biswas, Mahesh Pal</h3>
<p>SAR (VV and VH polarization) and optical data are widely used in image fusion
to use the complimentary information of each other and to obtain the
better-quality image (in terms of spatial and spectral features) for the
improved classification results. This paper uses anisotropic diffusion with PCA
for the fusion of SAR and optical data and patch-based SVM Classification with
LBP (LBP-PSVM). Fusion results with VV polarization performed better than VH
polarization using considered fusion method. For classification, the
performance of LBP-PSVM using S1 (VV) with S2, S1 (VH) with S2 is compared with
SVM classifier (without patch) and PSVM classifier (with patch), respectively.
Classification results suggests that the LBP-PSVM classifier is more effective
in comparison to SVM and PSVM classifiers for considered data.
</p>
<a href="http://arxiv.org/abs/2101.08215" target="_blank">arXiv:2101.08215</a> [<a href="http://arxiv.org/pdf/2101.08215" target="_blank">pdf</a>]

<h2>Data Association Between Perception and V2V Communication Sensors. (arXiv:2101.08228v1 [cs.RO])</h2>
<h3>Mustafa Ridvan Cantas, Arpita Chand, Hao Zhang, Gopi Chandra Surnilla, Levent Guvenc</h3>
<p>The connectivity between vehicles, infrastructure, and other traffic
participants brings a new dimension to automotive safety applications. Soon all
the newly produced cars will have Vehicle to Everything (V2X) communication
modems alongside the existing Advanced Driver Assistant Systems (ADAS). It is
essential to identify the different sensor measurements for the same targets
(Data Association) to use connectivity reliably as a safety feature alongside
the standard ADAS functionality. Considering the camera is the most common
sensor available for ADAS systems, in this paper, we present an experimental
implementation of a Mahalanobis distance-based data association algorithm
between the camera and the Vehicle to Vehicle (V2V) communication sensors. The
implemented algorithm has low computational complexity and the capability of
running in real-time. One can use the presented algorithm for sensor fusion
algorithms or higher-level decision-making applications in ADAS modules.
</p>
<a href="http://arxiv.org/abs/2101.08228" target="_blank">arXiv:2101.08228</a> [<a href="http://arxiv.org/pdf/2101.08228" target="_blank">pdf</a>]

<h2>Probabilistic Solar Power Forecasting: Long Short-Term Memory Network vs Simpler Approaches. (arXiv:2101.08236v1 [cs.LG])</h2>
<h3>Vinayak Sharma, Jorge Angel Gonzalez Ordiano, Ralf Mikut, Umit Cali</h3>
<p>The high penetration of volatile renewable energy sources such as solar make
methods for coping with the uncertainty associated with them of paramount
importance. Probabilistic forecasts are an example of these methods, as they
assist energy planners in their decision-making process by providing them with
information about the uncertainty of future power generation. Currently, there
is a trend towards the use of deep learning probabilistic forecasting methods.
However, the point at which the more complex deep learning methods should be
preferred over more simple approaches is not yet clear. Therefore, the current
article presents a simple comparison between a long short-term memory neural
network and other more simple approaches. The comparison consists of training
and comparing models able to provide one-day-ahead probabilistic forecasts for
a solar power system. Moreover, the current paper makes use of an open-source
dataset provided during the Global Energy Forecasting Competition of 2014
(GEFCom14).
</p>
<a href="http://arxiv.org/abs/2101.08236" target="_blank">arXiv:2101.08236</a> [<a href="http://arxiv.org/pdf/2101.08236" target="_blank">pdf</a>]

<h2>On The Consistency Training for Open-Set Semi-Supervised Learning. (arXiv:2101.08237v1 [cs.CV])</h2>
<h3>Huixiang Luo, Hao Cheng, Yuting Gao, Ke Li, Mengdan Zhang, Fanxu Meng, Xiaowei Guo, Feiyue Huang, Xing Sun</h3>
<p>Conventional semi-supervised learning (SSL) methods, e.g., MixMatch, achieve
great performance when both labeled and unlabeled dataset are drawn from the
same distribution. However, these methods often suffer severe performance
degradation in a more realistic setting, where unlabeled dataset contains
out-of-distribution (OOD) samples. Recent approaches mitigate the negative
influence of OOD samples by filtering them out from the unlabeled data. Our
studies show that it is not necessary to get rid of OOD samples during
training. On the contrary, the network can benefit from them if OOD samples are
properly utilized. We thoroughly study how OOD samples affect DNN training in
both low- and high-dimensional spaces, where two fundamental SSL methods are
considered: Pseudo Labeling (PL) and Data Augmentation based Consistency
Training (DACT). Conclusion is twofold: (1) unlike PL that suffers performance
degradation, DACT brings improvement to model performance; (2) the improvement
is closely related to class-wise distribution gap between the labeled and the
unlabeled dataset. Motivated by this observation, we further improve the model
performance by bridging the gap between the labeled and the unlabeled datasets
(containing OOD samples). Compared to previous algorithms paying much attention
to distinguishing between ID and OOD samples, our method makes better use of
OOD samples and achieves state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2101.08237" target="_blank">arXiv:2101.08237</a> [<a href="http://arxiv.org/pdf/2101.08237" target="_blank">pdf</a>]

<h2>AXM-Net: Cross-Modal Context Sharing Attention Network for Person Re-ID. (arXiv:2101.08238v1 [cs.CV])</h2>
<h3>Ammarah Farooq, Muhammad Awais, Josef Kittler, Syed Safwan Khalid</h3>
<p>Cross-modal person re-identification (Re-ID) is critical for modern video
surveillance systems. The key challenge is to align inter-modality
representations according to semantic information present for a person and
ignore background information. In this work, we present AXM-Net, a novel CNN
based architecture designed for learning semantically aligned visual and
textual representations. The underlying building block consists of multiple
streams of feature maps coming from visual and textual modalities and a novel
learnable context sharing semantic alignment network. We also propose
complementary intra modal attention learning mechanisms to focus on more
fine-grained local details in the features along with a cross-modal affinity
loss for robust feature matching. Our design is unique in its ability to
implicitly learn feature alignments from data. The entire AXM-Net can be
trained in an end-to-end manner. We report results on both person search and
cross-modal Re-ID tasks. Extensive experimentation validates the proposed
framework and demonstrates its superiority by outperforming the current
state-of-the-art methods by a significant margin.
</p>
<a href="http://arxiv.org/abs/2101.08238" target="_blank">arXiv:2101.08238</a> [<a href="http://arxiv.org/pdf/2101.08238" target="_blank">pdf</a>]

<h2>Trajectory optimization for contact-rich motions using implicit differential dynamic programming. (arXiv:2101.08246v1 [cs.RO])</h2>
<h3>Iordanis Chatzinikolaidis, Zhibin Li</h3>
<p>This paper presents a novel approach using sensitivity analysis for
generalizing Differential Dynamic Programming (DDP) to systems characterized by
implicit dynamics, such as those modelled via inverse dynamics and variational
or implicit integrators. It leads to a more general formulation of DDP,
enabling for example the use of the faster recursive Newton-Euler inverse
dynamics. We leverage the implicit formulation for precise and exact contact
modelling in DDP, where we focus on two contributions: (1) Contact dynamics in
acceleration level that enables high-order integration schemes; (2) Formulation
using an invertible contact model in the forward pass and a closed form
solution in the backward pass to improve the numerical resolution of contacts.
The performance of the proposed framework is validated (1) by comparing
implicit versus explicit DDP for the swing-up of a double pendulum, and (2) by
planning motions for two tasks using a single leg model making multi-body
contacts with the environment: standing up from ground, where a priori contact
enumeration is challenging, and maintaining balance under an external
perturbation.
</p>
<a href="http://arxiv.org/abs/2101.08246" target="_blank">arXiv:2101.08246</a> [<a href="http://arxiv.org/pdf/2101.08246" target="_blank">pdf</a>]

<h2>Low-Rank Semidefinite Programs via Bilinear Factorization. (arXiv:1811.01198v5 [cs.LG] UPDATED)</h2>
<h3>En-Liang Hu</h3>
<p>Many machine learning problems can be reduced to learning a low-rank positive
semidefinite matrix (denoted as $Z$), which encounters semidefinite program
(SDP). Existing SDP solvers are often expensive for large-scale learning. To
avoid directly solving SDP, some works convert SDP into a nonconvex program by
factorizing $Z$ \textit{quadraticly} as $XX^\top$. However, this would bring
higher-order nonlinearity, resulting in scarcity of structure in subsequent
optimization. In this paper, we propose a novel surrogate for SDP learning, in
which the structure of subproblem is exploited. More specifically, we surrogate
unconstrained SDP by a biconvex problem, through factorizing $Z$
\textit{bilinearly} as $XY^\top$ and using a Courant penalty to penalize the
difference of $X$ and $Y$, in which the resultant subproblems in terms of $X$
and $Y$ are convex respectively. Furthermore, we provide a theoretical bound
for the associated penalty parameter under the assumption that the subobjective
function of $X$ or $Y$ is $L$-Lipschitz-smooth and $\sigma$-strongly convex,
such that the proposed surrogate will solve the original SDP when the penalty
parameter is larger than this bound (that is $\gamma&gt;\frac{1}{4}(L-\sigma)$).
Experiments on two SDP-related applications demonstrate that the proposed
algorithm is as accurate as the state-of-the-art, but is faster on large-scale
learning.
</p>
<a href="http://arxiv.org/abs/1811.01198" target="_blank">arXiv:1811.01198</a> [<a href="http://arxiv.org/pdf/1811.01198" target="_blank">pdf</a>]

<h2>DNA: Deeply-supervised Nonlinear Aggregation for Salient Object Detection. (arXiv:1903.12476v4 [cs.CV] UPDATED)</h2>
<h3>Yun Liu, Ming-Ming Cheng, Xinyu Zhang, Guang-Yu Nie, Meng Wang</h3>
<p>Recent progress on salient object detection mainly aims at exploiting how to
effectively integrate multi-scale convolutional features in convolutional
neural networks (CNNs). Many popular methods impose deep supervision to perform
side-output predictions that are linearly aggregated for final saliency
prediction. In this paper, we theoretically and experimentally demonstrate that
linear aggregation of side-output predictions is suboptimal, and it only makes
limited use of the side-output information obtained by deep supervision. To
solve this problem, we propose Deeply-supervised Nonlinear Aggregation (DNA)
for better leveraging the complementary information of various side-outputs.
Compared with existing methods, it i) aggregates side-output features rather
than predictions, and ii) adopts nonlinear instead of linear transformations.
Experiments demonstrate that DNA can successfully break through the bottleneck
of current linear approaches. Specifically, the proposed saliency detector, a
modified U-Net architecture with DNA, performs favorably against
state-of-the-art methods on various datasets and evaluation metrics without
bells and whistles.
</p>
<a href="http://arxiv.org/abs/1903.12476" target="_blank">arXiv:1903.12476</a> [<a href="http://arxiv.org/pdf/1903.12476" target="_blank">pdf</a>]

<h2>Imitation-Projected Programmatic Reinforcement Learning. (arXiv:1907.05431v4 [cs.LG] UPDATED)</h2>
<h3>Abhinav Verma, Hoang M. Le, Yisong Yue, Swarat Chaudhuri</h3>
<p>We study the problem of programmatic reinforcement learning, in which
policies are represented as short programs in a symbolic language. Programmatic
policies can be more interpretable, generalizable, and amenable to formal
verification than neural policies; however, designing rigorous learning
approaches for such policies remains a challenge. Our approach to this
challenge -- a meta-algorithm called PROPEL -- is based on three insights.
First, we view our learning task as optimization in policy space, modulo the
constraint that the desired policy has a programmatic representation, and solve
this optimization problem using a form of mirror descent that takes a gradient
step into the unconstrained policy space and then projects back onto the
constrained space. Second, we view the unconstrained policy space as mixing
neural and programmatic representations, which enables employing
state-of-the-art deep policy gradient approaches. Third, we cast the projection
step as program synthesis via imitation learning, and exploit contemporary
combinatorial methods for this task. We present theoretical convergence results
for PROPEL and empirically evaluate the approach in three continuous control
domains. The experiments show that PROPEL can significantly outperform
state-of-the-art approaches for learning programmatic policies.
</p>
<a href="http://arxiv.org/abs/1907.05431" target="_blank">arXiv:1907.05431</a> [<a href="http://arxiv.org/pdf/1907.05431" target="_blank">pdf</a>]

<h2>Imitation Learning Based on Bilateral Control for Human-Robot Cooperation. (arXiv:1909.13018v6 [cs.RO] UPDATED)</h2>
<h3>Ayumu Sasagawa, Kazuki Fujimoto, Sho Sakaino, Toshiaki Tsuji</h3>
<p>Robots are required to autonomously respond to changing situations. Imitation
learning is a promising candidate for achieving generalization performance, and
extensive results have been demonstrated in object manipulation. However,
cooperative work between humans and robots is still a challenging issue because
robots must control dynamic interactions among themselves, humans, and objects.
Furthermore, it is difficult to follow subtle perturbations that may occur
among coworkers. In this study, we find that cooperative work can be
accomplished by imitation learning using bilateral control. Thanks to bilateral
control, which can extract response values and command values independently,
human skills to control dynamic interactions can be extracted. Then, the task
of serving food is considered. The experimental results clearly demonstrate the
importance of force control, and the dynamic interactions can be controlled by
the inferred action force.
</p>
<a href="http://arxiv.org/abs/1909.13018" target="_blank">arXiv:1909.13018</a> [<a href="http://arxiv.org/pdf/1909.13018" target="_blank">pdf</a>]

<h2>Practical Compositional Fairness: Understanding Fairness in Multi-Component Recommender Systems. (arXiv:1911.01916v3 [cs.LG] UPDATED)</h2>
<h3>Xuezhi Wang, Nithum Thain, Anu Sinha, Flavien Prost, Ed H. Chi, Jilin Chen, Alex Beutel</h3>
<p>How can we build recommender systems to take into account fairness?
Real-world recommender systems are often composed of multiple models, built by
multiple teams. However, most research on fairness focuses on improving
fairness in a single model. Further, recent research on classification fairness
has shown that combining multiple "fair" classifiers can still result in an
"unfair" classification system. This presents a significant challenge: how do
we understand and improve fairness in recommender systems composed of multiple
components?

In this paper, we study the compositionality of recommender fairness. We
consider two recently proposed fairness ranking metrics: equality of exposure
and pairwise ranking accuracy. While we show that fairness in recommendation is
not guaranteed to compose, we provide theory for a set of conditions under
which fairness of individual models does compose. We then present an analytical
framework for both understanding whether a real system's signals can achieve
compositional fairness, and improving which component would have the greatest
impact on the fairness of the overall system. In addition to the theoretical
results, we find on multiple datasets -- including a large-scale real-world
recommender system -- that the overall system's end-to-end fairness is largely
achievable by improving fairness in individual components.
</p>
<a href="http://arxiv.org/abs/1911.01916" target="_blank">arXiv:1911.01916</a> [<a href="http://arxiv.org/pdf/1911.01916" target="_blank">pdf</a>]

<h2>Deep Neural Network Fingerprinting by Conferrable Adversarial Examples. (arXiv:1912.00888v4 [cs.LG] UPDATED)</h2>
<h3>Nils Lukas, Yuxuan Zhang, Florian Kerschbaum</h3>
<p>In Machine Learning as a Service, a provider trains a deep neural network and
gives many users access. The hosted (source) model is susceptible to model
stealing attacks, where an adversary derives a surrogate model from API access
to the source model. For post hoc detection of such attacks, the provider needs
a robust method to determine whether a suspect model is a surrogate of their
model. We propose a fingerprinting method for deep neural network classifiers
that extracts a set of inputs from the source model so that only surrogates
agree with the source model on the classification of such inputs. These inputs
are a subclass of transferable adversarial examples which we call conferrable
adversarial examples that exclusively transfer with a target label from a
source model to its surrogates. We propose a new method to generate these
conferrable adversarial examples. We present an extensive study on the
irremovability of our fingerprint against fine-tuning, weight pruning,
retraining, retraining with different architectures, three model extraction
attacks from related work, transfer learning, adversarial training, and two new
adaptive attacks. Our fingerprint is robust against distillation, related model
extraction attacks, and even transfer learning when the attacker has no access
to the model provider's dataset. Our fingerprint is the first method that
reaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63
by previous fingerprints.
</p>
<a href="http://arxiv.org/abs/1912.00888" target="_blank">arXiv:1912.00888</a> [<a href="http://arxiv.org/pdf/1912.00888" target="_blank">pdf</a>]

<h2>Attentive Representation Learning with Adversarial Training for Short Text Clustering. (arXiv:1912.03720v2 [cs.LG] UPDATED)</h2>
<h3>Wei Zhang, Chao Dong, Jianhua Yin, Jianyong Wang</h3>
<p>Short text clustering has far-reaching effects on semantic analysis, showing
its importance for multiple applications such as corpus summarization and
information retrieval. However, it inevitably encounters the severe sparsity of
short text representations, making the previous clustering approaches still far
from satisfactory. In this paper, we present a novel attentive representation
learning model for shot text clustering, wherein cluster-level attention is
proposed to capture the correlations between text representations and cluster
representations. Relying on this, the representation learning and clustering
for short texts are seamlessly integrated into a unified model. To further
ensure robust model training for short texts, we apply adversarial training to
the unsupervised clustering setting, by injecting perturbations into the
cluster representations. The model parameters and perturbations are optimized
alternately through a minimax game. Extensive experiments on four real-world
short text datasets demonstrate the superiority of the proposed model over
several strong competitors, verifying that robust adversarial training yields
substantial performance gains.
</p>
<a href="http://arxiv.org/abs/1912.03720" target="_blank">arXiv:1912.03720</a> [<a href="http://arxiv.org/pdf/1912.03720" target="_blank">pdf</a>]

<h2>BNAS:An Efficient Neural Architecture Search Approach Using Broad Scalable Architecture. (arXiv:2001.06679v5 [stat.ML] UPDATED)</h2>
<h3>Zixiang Ding, Yaran Chen, Nannan Li, Dongbin Zhao, Zhiquan Sun, C.L. Philip Chen</h3>
<p>In this paper, we propose Broad Neural Architecture Search (BNAS) where we
elaborately design broad scalable architecture dubbed Broad Convolutional
Neural Network (BCNN) to solve the above issue. On one hand, the proposed broad
scalable architecture has fast training speed due to its shallow topology.
Moreover, we also adopt reinforcement learning and parameter sharing used in
ENAS as the optimization strategy of BNAS. Hence, the proposed approach can
achieve higher search efficiency. On the other hand, the broad scalable
architecture extracts multi-scale features and enhancement representations, and
feeds them into global average pooling layer to yield more reasonable and
comprehensive representations. Therefore, the performance of broad scalable
architecture can be promised. In particular, we also develop two variants for
BNAS who modify the topology of BCNN. In order to verify the effectiveness of
BNAS, several experiments are performed and experimental results show that 1)
BNAS delivers 0.19 days which is 2.37x less expensive than ENAS who ranks the
best in reinforcement learning-based NAS approaches, 2) compared with
small-size (0.5 millions parameters) and medium-size (1.1 millions parameters)
models, the architecture learned by BNAS obtains state-of-the-art performance
(3.58% and 3.24% test error) on CIFAR-10, 3) the learned architecture achieves
25.3% top-1 error on ImageNet just using 3.9 millions parameters.
</p>
<a href="http://arxiv.org/abs/2001.06679" target="_blank">arXiv:2001.06679</a> [<a href="http://arxiv.org/pdf/2001.06679" target="_blank">pdf</a>]

<h2>General linear-time inference for Gaussian Processes on one dimension. (arXiv:2003.05554v2 [stat.ML] UPDATED)</h2>
<h3>Jackson Loper, David Blei, John P. Cunningham, Liam Paninski</h3>
<p>Gaussian Processes (GPs) provide a powerful probabilistic framework for
interpolation, forecasting, and smoothing, but have been hampered by
computational scaling issues. Here we prove that for data sampled on one
dimension (e.g., a time series sampled at arbitrarily-spaced intervals),
approximate GP inference at any desired level of accuracy requires
computational effort that scales linearly with the number of observations; this
new theorem enables inference on much larger datasets than was previously
feasible. To achieve this improved scaling we propose a new family of
stationary covariance kernels: the Latent Exponentially Generated (LEG) family,
which admits a convenient stable state-space representation that allows
linear-time inference. We prove that any continuous integrable stationary
kernel can be approximated arbitrarily well by some member of the LEG family.
The proof draws connections to Spectral Mixture Kernels, providing new insight
about the flexibility of this popular family of kernels. We propose
parallelized algorithms for performing inference and learning in the LEG model,
test the algorithm on real and synthetic data, and demonstrate scaling to
datasets with billions of samples.
</p>
<a href="http://arxiv.org/abs/2003.05554" target="_blank">arXiv:2003.05554</a> [<a href="http://arxiv.org/pdf/2003.05554" target="_blank">pdf</a>]

<h2>Progressive Graph Convolutional Networks for Semi-Supervised Node Classification. (arXiv:2003.12277v2 [cs.LG] UPDATED)</h2>
<h3>Negar Heidari, Alexandros Iosifidis</h3>
<p>Graph convolutional networks have been successful in addressing graph-based
tasks such as semi-supervised node classification. Existing methods use a
network structure defined by the user based on experimentation with fixed
number of layers and neurons per layer and employ a layer-wise propagation rule
to obtain the node embeddings. Designing an automatic process to define a
problem-dependant architecture for graph convolutional networks can greatly
help to reduce the need for manual design of the structure of the model in the
training process. In this paper, we propose a method to automatically build
compact and task-specific graph convolutional networks. Experimental results on
widely used publicly available datasets show that the proposed method
outperforms related methods based on convolutional graph networks in terms of
classification performance and network compactness.
</p>
<a href="http://arxiv.org/abs/2003.12277" target="_blank">arXiv:2003.12277</a> [<a href="http://arxiv.org/pdf/2003.12277" target="_blank">pdf</a>]

<h2>OF-VO: Reliable Navigation among Pedestrians Using Commodity Sensors. (arXiv:2004.10976v4 [cs.RO] UPDATED)</h2>
<h3>Jing Liang, Yi-Ling Qiao, Tianrui Guan, Dinesh Manocha</h3>
<p>We present a modified velocity-obstacle (VO) algorithm that uses
probabilistic partial observations of the environment to compute velocities and
navigate a robot to a target. Our system uses commodity visual sensors,
including a mono-camera and a 2D Lidar, to explicitly predict the velocities
and positions of surrounding obstacles through optical flow estimation, object
detection, and sensor fusion. A key aspect of our work is coupling the
perception (OF: optical flow) and planning (VO) components for reliable
navigation. Overall, our OF-VO algorithm using learning-based perception and
model-based planning methods offers better performance than prior algorithms in
terms of navigation time and success rate of collision avoidance. Our method
also provides bounds on the probabilistic collision avoidance algorithm. We
highlight the realtime performance of OF-VO on a Turtlebot navigating among
pedestrians in both simulated and real-world scenes. A demo video is available
at https://gamma.umd.edu/ofvo
</p>
<a href="http://arxiv.org/abs/2004.10976" target="_blank">arXiv:2004.10976</a> [<a href="http://arxiv.org/pdf/2004.10976" target="_blank">pdf</a>]

<h2>Latent Fingerprint Registration via Matching Densely Sampled Points. (arXiv:2005.05878v2 [cs.CV] UPDATED)</h2>
<h3>Shan Gu, Jianjiang Feng, Jiwen Lu, Jie Zhou</h3>
<p>Latent fingerprint matching is a very important but unsolved problem. As a
key step of fingerprint matching, fingerprint registration has a great impact
on the recognition performance. Existing latent fingerprint registration
approaches are mainly based on establishing correspondences between minutiae,
and hence will certainly fail when there are no sufficient number of extracted
minutiae due to small fingerprint area or poor image quality. Minutiae
extraction has become the bottleneck of latent fingerprint registration. In
this paper, we propose a non-minutia latent fingerprint registration method
which estimates the spatial transformation between a pair of fingerprints
through a dense fingerprint patch alignment and matching procedure. Given a
pair of fingerprints to match, we bypass the minutiae extraction step and take
uniformly sampled points as key points. Then the proposed patch alignment and
matching algorithm compares all pairs of sampling points and produces their
similarities along with alignment parameters. Finally, a set of consistent
correspondences are found by spectral clustering. Extensive experiments on
NIST27 database and MOLF database show that the proposed method achieves the
state-of-the-art registration performance, especially under challenging
conditions.
</p>
<a href="http://arxiv.org/abs/2005.05878" target="_blank">arXiv:2005.05878</a> [<a href="http://arxiv.org/pdf/2005.05878" target="_blank">pdf</a>]

<h2>MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning. (arXiv:2006.16908v2 [cs.LG] UPDATED)</h2>
<h3>Elise van der Pol, Daniel E. Worrall, Herke van Hoof, Frans A. Oliehoek, Max Welling</h3>
<p>This paper introduces MDP homomorphic networks for deep reinforcement
learning. MDP homomorphic networks are neural networks that are equivariant
under symmetries in the joint state-action space of an MDP. Current approaches
to deep reinforcement learning do not usually exploit knowledge about such
structure. By building this prior knowledge into policy and value networks
using an equivariance constraint, we can reduce the size of the solution space.
We specifically focus on group-structured symmetries (invertible
transformations). Additionally, we introduce an easy method for constructing
equivariant network layers numerically, so the system designer need not solve
the constraints by hand, as is typically done. We construct MDP homomorphic
MLPs and CNNs that are equivariant under either a group of reflections or
rotations. We show that such networks converge faster than unstructured
baselines on CartPole, a grid world and Pong.
</p>
<a href="http://arxiv.org/abs/2006.16908" target="_blank">arXiv:2006.16908</a> [<a href="http://arxiv.org/pdf/2006.16908" target="_blank">pdf</a>]

<h2>Decentralized Stochastic Gradient Langevin Dynamics and Hamiltonian Monte Carlo. (arXiv:2007.00590v3 [stat.ML] UPDATED)</h2>
<h3>Mert G&#xfc;rb&#xfc;zbalaban, Xuefeng Gao, Yuanhan Hu, Lingjiong Zhu</h3>
<p>Stochastic gradient Langevin dynamics (SGLD) and stochastic gradient
Hamiltonian Monte Carlo (SGHMC) are two popular Markov Chain Monte Carlo (MCMC)
algorithms for Bayesian inference that can scale to large datasets, allowing to
sample from the posterior distribution of the parameters of a statistical model
given the input data and the prior distribution over the model parameters.
However, these algorithms do not apply to the decentralized learning setting,
when a network of agents are working collaboratively to learn the parameters of
a statistical model without sharing their individual data due to privacy
reasons or communication constraints. We study two algorithms: Decentralized
SGLD (DE-SGLD) and Decentralized SGHMC (DE-SGHMC) which are adaptations of SGLD
and SGHMC methods that allow scaleable Bayesian inference in the decentralized
setting for large datasets. We show that when the posterior distribution is
strongly log-concave and smooth, the iterates of these algorithms converge
linearly to a neighborhood of the target distribution in the 2-Wasserstein
distance if their parameters are selected appropriately. We illustrate the
efficiency of our algorithms on decentralized Bayesian linear regression and
Bayesian logistic regression problems.
</p>
<a href="http://arxiv.org/abs/2007.00590" target="_blank">arXiv:2007.00590</a> [<a href="http://arxiv.org/pdf/2007.00590" target="_blank">pdf</a>]

<h2>VisImages: A Corpus of Images from Visualization Publications. (arXiv:2007.04584v3 [cs.CV] UPDATED)</h2>
<h3>Dazhen Deng, Yihong Wu, Xinhuan Shu, Jiang Wu, Mengye Xu, Siwei Fu, Yingcai Wu</h3>
<p>Images in visualization publications contain rich information, e.g., novel
visualization designs and common combinations of visualizations. A systematic
collection of these images can contribute to the community in many aspects,
such as literature analysis and automated tasks for visualization. In this
paper, we build and make public a dataset, VisImages, which collects 12,267
images with captions from 1,397 papers in IEEE InfoVis and VAST. Based on a
refined taxonomy for visualizations in publications, the dataset includes
35,096 annotated visualizations, as well as their positions. We demonstrate the
usefulness of VisImages through three use cases: 1) exploring and analyzing the
evolution of visualizations with VisImages Explorer, 2) training and
benchmarking models for visualization classification, and 3) localizing and
recognizing visualizations in the images automatically.
</p>
<a href="http://arxiv.org/abs/2007.04584" target="_blank">arXiv:2007.04584</a> [<a href="http://arxiv.org/pdf/2007.04584" target="_blank">pdf</a>]

<h2>Towards Visual Distortion in Black-Box Attacks. (arXiv:2007.10593v2 [cs.LG] UPDATED)</h2>
<h3>Nannan Li, Zhenzhong Chen</h3>
<p>Constructing adversarial examples in a black-box threat model injures the
original images by introducing visual distortion. In this paper, we propose a
novel black-box attack approach that can directly minimize the induced
distortion by learning the noise distribution of the adversarial example,
assuming only loss-oracle access to the black-box network. The quantified
visual distortion, which measures the perceptual distance between the
adversarial example and the original image, is introduced in our loss whilst
the gradient of the corresponding non-differentiable loss function is
approximated by sampling noise from the learned noise distribution. We validate
the effectiveness of our attack on ImageNet. Our attack results in much lower
distortion when compared to the state-of-the-art black-box attacks and achieves
$100\%$ success rate on InceptionV3, ResNet50 and VGG16bn. The code is
available at https://github.com/Alina-1997/visual-distortion-in-attack.
</p>
<a href="http://arxiv.org/abs/2007.10593" target="_blank">arXiv:2007.10593</a> [<a href="http://arxiv.org/pdf/2007.10593" target="_blank">pdf</a>]

<h2>Toward Agile Maneuvers in Highly Constrained Spaces: Learning from Hallucination. (arXiv:2007.14479v4 [cs.RO] UPDATED)</h2>
<h3>Xuesu Xiao, Bo Liu, Garrett Warnell, Peter Stone</h3>
<p>While classical approaches to autonomous robot navigation currently enable
operation in certain environments, they break down in tightly constrained
spaces, e.g., where the robot needs to engage in agile maneuvers to squeeze
between obstacles. Recent machine learning techniques have the potential to
address this shortcoming, but existing approaches require vast amounts of
navigation experience for training, during which the robot must operate in
close proximity to obstacles and risk collision. In this paper, we propose to
side-step this requirement by introducing a new machine learning paradigm for
autonomous navigation called learning from hallucination (LfH), which can use
training data collected in completely safe environments to compute navigation
controllers that result in fast, smooth, and safe navigation in highly
constrained environments. Our experimental results show that the proposed LfH
system outperforms three autonomous navigation baselines on a real robot and
generalizes well to unseen environments, including those based on both
classical and machine learning techniques.
</p>
<a href="http://arxiv.org/abs/2007.14479" target="_blank">arXiv:2007.14479</a> [<a href="http://arxiv.org/pdf/2007.14479" target="_blank">pdf</a>]

<h2>Sketching Datasets for Large-Scale Learning (long version). (arXiv:2008.01839v2 [stat.ML] UPDATED)</h2>
<h3>R&#xe9;mi Gribonval, Antoine Chatalic, Nicolas Keriven, Vincent Schellekens, Laurent Jacques, Philip Schniter</h3>
<p>This article considers "compressive learning," an approach to large-scale
machine learning where datasets are massively compressed before learning (e.g.,
clustering, classification, or regression) is performed. In particular, a
"sketch" is first constructed by computing carefully chosen nonlinear random
features (e.g., random Fourier features) and averaging them over the whole
dataset. Parameters are then learned from the sketch, without access to the
original dataset. This article surveys the current state-of-the-art in sketched
learning, including the main concepts and algorithms, their connections with
established signal-processing methods, existing theoretical guarantees -- on
both information preservation and privacy preservation, and important open
problems.
</p>
<a href="http://arxiv.org/abs/2008.01839" target="_blank">arXiv:2008.01839</a> [<a href="http://arxiv.org/pdf/2008.01839" target="_blank">pdf</a>]

<h2>Neural Light Transport for Relighting and View Synthesis. (arXiv:2008.03806v3 [cs.CV] UPDATED)</h2>
<h3>Xiuming Zhang, Sean Fanello, Yun-Ta Tsai, Tiancheng Sun, Tianfan Xue, Rohit Pandey, Sergio Orts-Escolano, Philip Davidson, Christoph Rhemann, Paul Debevec, Jonathan T. Barron, Ravi Ramamoorthi, William T. Freeman</h3>
<p>The light transport (LT) of a scene describes how it appears under different
lighting and viewing directions, and complete knowledge of a scene's LT enables
the synthesis of novel views under arbitrary lighting. In this paper, we focus
on image-based LT acquisition, primarily for human bodies within a light stage
setup. We propose a semi-parametric approach to learn a neural representation
of LT that is embedded in the space of a texture atlas of known geometric
properties, and model all non-diffuse and global LT as residuals added to a
physically-accurate diffuse base rendering. In particular, we show how to fuse
previously seen observations of illuminants and views to synthesize a new image
of the same scene under a desired lighting condition from a chosen viewpoint.
This strategy allows the network to learn complex material effects (such as
subsurface scattering) and global illumination, while guaranteeing the physical
correctness of the diffuse LT (such as hard shadows). With this learned LT, one
can relight the scene photorealistically with a directional light or an HDRI
map, synthesize novel views with view-dependent effects, or do both
simultaneously, all in a unified framework using a set of sparse, previously
seen observations. Qualitative and quantitative experiments demonstrate that
our neural LT (NLT) outperforms state-of-the-art solutions for relighting and
view synthesis, without separate treatment for both problems that prior work
requires.
</p>
<a href="http://arxiv.org/abs/2008.03806" target="_blank">arXiv:2008.03806</a> [<a href="http://arxiv.org/pdf/2008.03806" target="_blank">pdf</a>]

<h2>Minimum discrepancy principle strategy for choosing $k$ in $k$-NN regression. (arXiv:2008.08718v2 [stat.ML] UPDATED)</h2>
<h3>Yaroslav Averyanov, Alain Celisse</h3>
<p>This paper presents a novel data-driven strategy to choose the hyperparameter
$k$ in the $k$-NN regression estimator. We treat the problem of choosing the
hyperparameter as an iterative procedure (over $k$) and propose using an easily
implemented in practice strategy based on the idea of early stopping and the
minimum discrepancy principle. This model selection strategy is proven to be
minimax-optimal, under the fixed-design assumption on covariates, over some
smoothness function classes, for instance, the Lipschitz functions class on a
bounded domain. After that, the novel strategy shows consistent simulation
results on artificial and real-world data sets in comparison to other model
selection strategies, such as the Hold-out method and generalized
cross-validation. The novelty of the strategy comes from reducing the
computational time of the model selection procedure while preserving the
statistical (minimax) optimality of the resulting estimator. More precisely,
given a sample of size $n$, if one should choose $k$ among $\left\{ 1, \ldots,
n \right\}$, the strategy reduces the computational time of the generalized
cross-validation or Akaike's AIC criteria from $\mathcal{O}\left( n^3 \right)$
to $\mathcal{O}\left( n^2 (n - k) \right)$, where $k$ is the proposed (minimum
discrepancy principle) value of the nearest neighbors.
</p>
<a href="http://arxiv.org/abs/2008.08718" target="_blank">arXiv:2008.08718</a> [<a href="http://arxiv.org/pdf/2008.08718" target="_blank">pdf</a>]

<h2>Multi-domain Semantic Segmentation on Datasets with Overlapping Classes. (arXiv:2009.01636v4 [cs.CV] UPDATED)</h2>
<h3>Petra Bevandi&#x107;, Marin Or&#x161;i&#x107;, Ivan Grubi&#x161;i&#x107;, Josip &#x160;ari&#x107;, Sini&#x161;a &#x160;egvi&#x107;</h3>
<p>Deep supervised models have an unprecedented capacity to apsorb large
quantities of training data. Hence, training on all available datasets appears
as a feasible approach towards accurate semantic segmentation models with
graceful degradation in unusual scenes. Unfortunately, different datasets often
use incompatible labels. For instance, the Cityscapes road class subsumes all
pixels on driving surfaces, while Vistas defines separate classes for road
markings, zebra crossings etc. Such inconsistencies pose a major obstacle
towards successful multi-domain learning. We address this challenge by
proposing a principled technique for learning with incompatible labeling
policies. Different than recent related work, our technique allows seamless
training on datasets with overlapping classes. Consequently, it can learn
visual concepts which are not represented as a separate class in any of the
individual datasets. We evaluate our method on a collection of seven semantic
segmentation datasets across four different domains. The results exceed the
state of the art in multi-domain semantic segmentation.
</p>
<a href="http://arxiv.org/abs/2009.01636" target="_blank">arXiv:2009.01636</a> [<a href="http://arxiv.org/pdf/2009.01636" target="_blank">pdf</a>]

<h2>Arbitrary Video Style Transfer via Multi-Channel Correlation. (arXiv:2009.08003v2 [cs.CV] UPDATED)</h2>
<h3>Yingying Deng, Fan Tang, Weiming Dong, Haibin Huang, Chongyang Ma, Changsheng Xu</h3>
<p>Video style transfer is getting more attention in AI community for its
numerous applications such as augmented reality and animation productions.
Compared with traditional image style transfer, performing this task on video
presents new challenges: how to effectively generate satisfactory stylized
results for any specified style, and maintain temporal coherence across frames
at the same time. Towards this end, we propose Multi-Channel Correction network
(MCCNet), which can be trained to fuse the exemplar style features and input
content features for efficient style transfer while naturally maintaining the
coherence of input videos. Specifically, MCCNet works directly on the feature
space of style and content domain where it learns to rearrange and fuse style
features based on their similarity with content features. The outputs generated
by MCC are features containing the desired style patterns which can further be
decoded into images with vivid style textures. Moreover, MCCNet is also
designed to explicitly align the features to input which ensures the output
maintains the content structures as well as the temporal continuity. To further
improve the performance of MCCNet under complex light conditions, we also
introduce the illumination loss during training. Qualitative and quantitative
evaluations demonstrate that MCCNet performs well in both arbitrary video and
image style transfer tasks.
</p>
<a href="http://arxiv.org/abs/2009.08003" target="_blank">arXiv:2009.08003</a> [<a href="http://arxiv.org/pdf/2009.08003" target="_blank">pdf</a>]

<h2>A Direct-Indirect Hybridization Approach to Control-Limited DDP. (arXiv:2010.00411v2 [cs.RO] UPDATED)</h2>
<h3>Carlos Mastalli, Wolfgang Merkt, Josep Marti-Saumell, Henrique Ferrolho, Joan Sola, Nicolas Mansard, Sethu Vijayakumar</h3>
<p>Differential Dynamic Programming (DDP) is an indirect method for trajectory
optimization. Its efficiency derives from the exploitation of temporal
structure (inherent to optimal control problems) and explicit
roll-out/integration of the system dynamics. However, it suffers from numerical
instability and, when compared to direct methods, it has limited initialization
options (allows initialization of controls, but not of states) and lacks proper
handling of control constraints. These limitations are due to the fact that DDP
is a single shooting algorithm. In this work, we tackle these issues with a
direct-indirect hybridization approach that is primarily driven by the dynamic
feasibility of the optimal control problem. Our feasibility search emulates the
numerical resolution of a direct transcription problem with only dynamics
constraints, namely a multiple shooting formulation. We show that our approach
has better numerical convergence than BOX-DDP (a shooting method), and that its
convergence rate and runtime performance are competitive with state-of-the-art
direct transcription formulations solved using the interior point and active
set algorithms available in KNITRO. We further show that our approach decreases
the dynamic feasibility error monotonically -- as in state-of-the-art nonlinear
programming algorithms. We demonstrate the benefits of our hybrid approach by
generating complex and athletic motions for quadruped and humanoid robots.
</p>
<a href="http://arxiv.org/abs/2010.00411" target="_blank">arXiv:2010.00411</a> [<a href="http://arxiv.org/pdf/2010.00411" target="_blank">pdf</a>]

<h2>Prioritized Level Replay. (arXiv:2010.03934v3 [cs.LG] UPDATED)</h2>
<h3>Minqi Jiang, Edward Grefenstette, Tim Rockt&#xe4;schel</h3>
<p>Simulated environments with procedurally generated content have become
popular benchmarks for testing systematic generalization of reinforcement
learning agents. Every level in such an environment is algorithmically created,
thereby exhibiting a unique configuration of underlying factors of variation,
such as layout, positions of entities, asset appearances, or even the rules
governing environment transitions. Fixed sets of training levels can be
determined to aid comparison and reproducibility, and test levels can be held
out to evaluate the generalization and robustness of agents. While prior work
samples training levels in a direct way (e.g. uniformly) for the agent to learn
from, we investigate the hypothesis that different levels provide different
learning progress for an agent at specific times during training. We introduce
Prioritized Level Replay, a general framework for estimating the future
learning potential of a level given the current state of the agent's policy. We
find that temporal-difference (TD) errors, while previously used to selectively
sample past transitions, also prove effective for scoring a level's future
learning potential when the agent replays (that is, revisits) that level to
generate entirely new episodes of experiences from it. We report significantly
improved sample-efficiency and generalization on the majority of Procgen
Benchmark environments as well as two challenging MiniGrid environments.
Lastly, we present a qualitative analysis showing that Prioritized Level Replay
induces an implicit curriculum, taking the agent gradually from easier to
harder levels.
</p>
<a href="http://arxiv.org/abs/2010.03934" target="_blank">arXiv:2010.03934</a> [<a href="http://arxiv.org/pdf/2010.03934" target="_blank">pdf</a>]

<h2>Disentangled Dynamic Graph Deep Generation. (arXiv:2010.07276v2 [cs.LG] UPDATED)</h2>
<h3>Wenbin Zhang, Liming Zhang, Dieter Pfoser, Liang Zhao</h3>
<p>Deep generative models for graphs have exhibited promising performance in
ever-increasing domains such as design of molecules (i.e, graph of atoms) and
structure prediction of proteins (i.e., graph of amino acids). Existing work
typically focuses on static rather than dynamic graphs, which are actually very
important in the applications such as protein folding, molecule reactions, and
human mobility. Extending existing deep generative models from static to
dynamic graphs is a challenging task, which requires to handle the
factorization of static and dynamic characteristics as well as mutual
interactions among node and edge patterns. Here, this paper proposes a novel
framework of factorized deep generative models to achieve interpretable dynamic
graph generation. Various generative models are proposed to characterize
conditional independence among node, edge, static, and dynamic factors. Then,
variational optimization strategies as well as dynamic graph decoders are
proposed based on newly designed factorized variational autoencoders and
recurrent graph deconvolutions. Extensive experiments on multiple datasets
demonstrate the effectiveness of the proposed models.
</p>
<a href="http://arxiv.org/abs/2010.07276" target="_blank">arXiv:2010.07276</a> [<a href="http://arxiv.org/pdf/2010.07276" target="_blank">pdf</a>]

<h2>Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI. (arXiv:2010.07487v3 [cs.AI] UPDATED)</h2>
<h3>Alon Jacovi, Ana Marasovi&#x107;, Tim Miller, Yoav Goldberg</h3>
<p>Trust is a central component of the interaction between people and AI, in
that 'incorrect' levels of trust may cause misuse, abuse or disuse of the
technology. But what, precisely, is the nature of trust in AI? What are the
prerequisites and goals of the cognitive mechanism of trust, and how can we
promote them, or assess whether they are being satisfied in a given
interaction? This work aims to answer these questions. We discuss a model of
trust inspired by, but not identical to, sociology's interpersonal trust (i.e.,
trust between people). This model rests on two key properties of the
vulnerability of the user and the ability to anticipate the impact of the AI
model's decisions. We incorporate a formalization of 'contractual trust', such
that trust between a user and an AI is trust that some implicit or explicit
contract will hold, and a formalization of 'trustworthiness' (which detaches
from the notion of trustworthiness in sociology), and with it concepts of
'warranted' and 'unwarranted' trust. We then present the possible causes of
warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how
to design trustworthy AI, how to evaluate whether trust has manifested, and
whether it is warranted. Finally, we elucidate the connection between trust and
XAI using our formalization.
</p>
<a href="http://arxiv.org/abs/2010.07487" target="_blank">arXiv:2010.07487</a> [<a href="http://arxiv.org/pdf/2010.07487" target="_blank">pdf</a>]

<h2>Failures of model-dependent generalization bounds for least-norm interpolation. (arXiv:2010.08479v3 [stat.ML] UPDATED)</h2>
<h3>Peter L. Bartlett, Philip M. Long</h3>
<p>We consider bounds on the generalization performance of the least-norm linear
regressor, in the over-parameterized regime where it can interpolate the data.
We describe a sense in which any generalization bound of a type that is
commonly proved in statistical learning theory must sometimes be very loose
when applied to analyze the least-norm interpolant. In particular, for a
variety of natural joint distributions on training examples, any valid
generalization bound that depends only on the output of the learning algorithm,
the number of training examples, and the confidence parameter, and that
satisfies a mild condition (substantially weaker than monotonicity in sample
size), must sometimes be very loose -- it can be bounded below by a constant
when the true excess risk goes to zero.
</p>
<a href="http://arxiv.org/abs/2010.08479" target="_blank">arXiv:2010.08479</a> [<a href="http://arxiv.org/pdf/2010.08479" target="_blank">pdf</a>]

<h2>American Sign Language Identification Using Hand Trackpoint Analysis. (arXiv:2010.10590v3 [cs.CV] UPDATED)</h2>
<h3>Yugam Bajaj, Puru Malhotra</h3>
<p>Sign Language helps people with Speaking and Hearing Disabilities communicate
with others efficiently. Sign Language identification is a challenging area in
the field of computer vision and recent developments have been able to achieve
near perfect results for the task, though some challenges are yet to be solved.
In this paper we propose a novel machine learning based pipeline for American
Sign Language identification using hand track points. We convert a hand gesture
into a series of hand track point coordinates that serve as an input to our
system. In order to make the solution more efficient, we experimented with 28
different combinations of pre-processing techniques, each run on three
different machine learning algorithms namely k-Nearest Neighbours, Random
Forests and a Neural Network. Their performance was contrasted to determine the
best pre-processing scheme and algorithm pair. Our system achieved an Accuracy
of 95.66% to identify American sign language gestures.
</p>
<a href="http://arxiv.org/abs/2010.10590" target="_blank">arXiv:2010.10590</a> [<a href="http://arxiv.org/pdf/2010.10590" target="_blank">pdf</a>]

<h2>Density of States Graph Kernels. (arXiv:2010.11341v3 [cs.LG] UPDATED)</h2>
<h3>Leo Huang, Andrew Graven, David Bindel</h3>
<p>A fundamental problem on graph-structured data is that of quantifying
similarity between graphs. Graph kernels are an established technique for such
tasks; in particular, those based on random walks and return probabilities have
proven to be effective in wide-ranging applications, from bioinformatics to
social networks to computer vision. However, random walk kernels generally
suffer from slowness and tottering, an effect which causes walks to
overemphasize local graph topology, undercutting the importance of global
structure. To correct for these issues, we recast return probability graph
kernels under the more general framework of density of states -- a framework
which uses the lens of spectral analysis to uncover graph motifs and properties
hidden within the interior of the spectrum -- and use our interpretation to
construct scalable, composite density of states based graph kernels which
balance local and global information, leading to higher classification
accuracies on a host of benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2010.11341" target="_blank">arXiv:2010.11341</a> [<a href="http://arxiv.org/pdf/2010.11341" target="_blank">pdf</a>]

<h2>Motion Generation Using Bilateral Control-Based Imitation Learning with Autoregressive Learning. (arXiv:2011.06192v4 [cs.RO] UPDATED)</h2>
<h3>Ayumu Sasagawa, Sho Sakaino, Toshiaki Tsuji</h3>
<p>Robots that can execute various tasks automatically on behalf of humans are
becoming an increasingly important focus of research in the field of robotics.
Imitation learning has been studied as an efficient and high-performance
method, and imitation learning based on bilateral control has been proposed as
a method that can realize fast motion. However, because this method cannot
implement autoregressive learning, this method may not generate desirable
long-term behavior. Therefore, in this paper, we propose a method of
autoregressive learning for bilateral control-based imitation learning. A new
neural network model for implementing autoregressive learning is proposed. In
this study, three types of experiments are conducted to verify the
effectiveness of the proposed method. The performance is improved compared to
conventional approaches; the proposed method has the highest rate of success.
Owing to the structure and autoregressive learning of the proposed model, the
proposed method can generate the desirable motion for successful tasks and have
a high generalization ability for environmental changes.
</p>
<a href="http://arxiv.org/abs/2011.06192" target="_blank">arXiv:2011.06192</a> [<a href="http://arxiv.org/pdf/2011.06192" target="_blank">pdf</a>]

<h2>Rethinking movie genre classification with fine-grained semantic clustering. (arXiv:2012.02639v3 [cs.CV] UPDATED)</h2>
<h3>Edward Fish, Jon Weinbren, Andrew Gilbert</h3>
<p>Movie genre classification is an active research area in machine learning.
However, due to the limited labels available, there can be large semantic
variations between movies within a single genre definition. We expand these
'coarse' genre labels by identifying 'fine-grained' semantic information within
the multi-modal content of movies. By leveraging pre-trained 'expert' networks,
we learn the influence of different combinations of modes for multi-label genre
classification. Using a contrastive loss, we continue to fine-tune this
'coarse' genre classification network to identify high-level intertextual
similarities between the movies across all genre labels. This leads to a more
'fine-grained' and detailed clustering, based on semantic similarities while
still retaining some genre information. Our approach is demonstrated on a newly
introduced multi-modal 37,866,450 frame, 8,800 movie trailer dataset,
MMX-Trailer-20, which includes pre-computed audio, location, motion, and image
embeddings.
</p>
<a href="http://arxiv.org/abs/2012.02639" target="_blank">arXiv:2012.02639</a> [<a href="http://arxiv.org/pdf/2012.02639" target="_blank">pdf</a>]

<h2>Driver Glance Classification In-the-wild: Towards Generalization Across Domains and Subjects. (arXiv:2012.02906v2 [cs.CV] UPDATED)</h2>
<h3>Sandipan Banerjee, Ajjen Joshi, Jay Turcot, Bryan Reimer, Taniya Mishra</h3>
<p>Distracted drivers are dangerous drivers. Equipping advanced driver
assistance systems (ADAS) with the ability to detect driver distraction can
help prevent accidents and improve driver safety. In order to detect driver
distraction, an ADAS must be able to monitor their visual attention. We propose
a model that takes as input a patch of the driver's face along with a crop of
the eye-region and classifies their glance into 6 coarse regions-of-interest
(ROIs) in the vehicle. We demonstrate that an hourglass network, trained with
an additional reconstruction loss, allows the model to learn stronger
contextual feature representations than a traditional encoder-only
classification module. To make the system robust to subject-specific variations
in appearance and behavior, we design a personalized hourglass model tuned with
an auxiliary input representing the driver's baseline glance behavior. Finally,
we present a weakly supervised multi-domain training regimen that enables the
hourglass to jointly learn representations from different domains (varying in
camera type, angle), utilizing unlabeled samples and thereby reducing
annotation cost.
</p>
<a href="http://arxiv.org/abs/2012.02906" target="_blank">arXiv:2012.02906</a> [<a href="http://arxiv.org/pdf/2012.02906" target="_blank">pdf</a>]

<h2>On the Power of Localized Perceptron for Label-Optimal Learning of Halfspaces with Adversarial Noise. (arXiv:2012.10793v2 [cs.LG] UPDATED)</h2>
<h3>Jie Shen</h3>
<p>We study {\em online} active learning of homogeneous halfspaces in
$\mathbb{R}^d$ with adversarial noise where the overall probability of a noisy
label is constrained to be at most $\nu$. Our main contribution is a
Perceptron-like online active learning algorithm that runs in polynomial time,
and under the conditions that the marginal distribution is isotropic
log-concave and $\nu = \Omega(\epsilon)$, where $\epsilon \in (0, 1)$ is the
target error rate, our algorithm PAC learns the underlying halfspace with
near-optimal label complexity of $\tilde{O}\big(d \cdot
polylog(\frac{1}{\epsilon})\big)$ and sample complexity of
$\tilde{O}\big(\frac{d}{\epsilon} \big)$. Prior to this work, existing online
algorithms designed for tolerating the adversarial noise are subject to either
label complexity polynomial in $\frac{1}{\epsilon}$, or suboptimal noise
tolerance, or restrictive marginal distributions. With the additional prior
knowledge that the underlying halfspace is $s$-sparse, we obtain
attribute-efficient label complexity of $\tilde{O}\big( s \cdot polylog(d,
\frac{1}{\epsilon}) \big)$ and sample complexity of
$\tilde{O}\big(\frac{s}{\epsilon} \cdot polylog(d) \big)$. As an immediate
corollary, we show that under the agnostic model where no assumption is made on
the noise rate $\nu$, our active learner achieves an error rate of $O(OPT) +
\epsilon$ with the same running time and label and sample complexity, where
$OPT$ is the best possible error rate achievable by any homogeneous halfspace.
</p>
<a href="http://arxiv.org/abs/2012.10793" target="_blank">arXiv:2012.10793</a> [<a href="http://arxiv.org/pdf/2012.10793" target="_blank">pdf</a>]

<h2>Improving the Certified Robustness of Neural Networks via Consistency Regularization. (arXiv:2012.13103v2 [cs.LG] UPDATED)</h2>
<h3>Mengting Xu, Tao Zhang, Zhongnian Li, Daoqiang Zhang</h3>
<p>A range of defense methods have been proposed to improve the robustness of
neural networks on adversarial examples, among which provable defense methods
have been demonstrated to be effective to train neural networks that are
certifiably robust to the attacker. However, most of these provable defense
methods treat all examples equally during training process, which ignore the
inconsistent constraint of certified robustness between correctly classified
(natural) and misclassified examples. In this paper, we explore this
inconsistency caused by misclassified examples and add a novel consistency
regularization term to make better use of the misclassified examples.
Specifically, we identified that the certified robustness of network can be
significantly improved if the constraint of certified robustness on
misclassified examples and correctly classified examples is consistent.
Motivated by this discovery, we design a new defense regularization term called
Misclassification Aware Adversarial Regularization (MAAR), which constrains the
output probability distributions of all examples in the certified region of the
misclassified example. Experimental results show that our proposed MAAR
achieves the best certified robustness and comparable accuracy on CIFAR-10 and
MNIST datasets in comparison with several state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.13103" target="_blank">arXiv:2012.13103</a> [<a href="http://arxiv.org/pdf/2012.13103" target="_blank">pdf</a>]

<h2>Optimizing Optimizers: Regret-optimal gradient descent algorithms. (arXiv:2101.00041v2 [cs.LG] UPDATED)</h2>
<h3>Philippe Casgrain, Anastasis Kratsios</h3>
<p>The need for fast and robust optimization algorithms are of critical
importance in all areas of machine learning. This paper treats the task of
designing optimization algorithms as an optimal control problem. Using regret
as a metric for an algorithm's performance, we study the existence, uniqueness
and consistency of regret-optimal algorithms. By providing first-order
optimality conditions for the control problem, we show that regret-optimal
algorithms must satisfy a specific structure in their dynamics which we show is
equivalent to performing dual-preconditioned gradient descent on the value
function generated by its regret. Using these optimal dynamics, we provide
bounds on their rates of convergence to solutions of convex optimization
problems. Though closed-form optimal dynamics cannot be obtained in general, we
present fast numerical methods for approximating them, generating optimization
algorithms which directly optimize their long-term regret. Lastly, these are
benchmarked against commonly used optimization algorithms to demonstrate their
effectiveness.
</p>
<a href="http://arxiv.org/abs/2101.00041" target="_blank">arXiv:2101.00041</a> [<a href="http://arxiv.org/pdf/2101.00041" target="_blank">pdf</a>]

<h2>Variationally and Intrinsically motivated reinforcement learning for decentralized traffic signal control. (arXiv:2101.00746v4 [cs.LG] UPDATED)</h2>
<h3>Liwen Zhu, Peixi Peng, Zongqing Lu, Xiangqian Wang, Yonghong Tian</h3>
<p>One of the biggest challenges in multi-agent reinforcement learning is
coordination, a typical application scenario of this is traffic signal control.
Recently, it has attracted a rising number of researchers and has become a hot
research field with great practical significance. In this paper, we propose a
novel method called MetaVRS~(Meta Variational RewardShaping) for traffic signal
coordination control. By heuristically applying the intrinsic reward to the
environmental reward, MetaVRS can wisely capture the agent-to-agent interplay.
Besides, latent variables generated by VAE are brought into policy for
automatically tradeoff between exploration and exploitation to optimize the
policy. In addition, meta learning was used in decoder for faster adaptation
and better approximation. Empirically, we demonstate that MetaVRS substantially
outperforms existing methods and shows superior adaptability, which predictably
has a far-reaching significance to the multi-agent traffic signal coordination
control.
</p>
<a href="http://arxiv.org/abs/2101.00746" target="_blank">arXiv:2101.00746</a> [<a href="http://arxiv.org/pdf/2101.00746" target="_blank">pdf</a>]

<h2>Joint Prediction of Remaining Useful Life and Failure Type of Train Wheelsets: A Multi-task Learning Approach. (arXiv:2101.03497v2 [cs.LG] UPDATED)</h2>
<h3>Weixin Wang</h3>
<p>The failures of train wheels account for disruptions of train operations and
even a large portion of train derailments. Remaining useful life (RUL) of a
wheelset measures the how soon the next failure will arrive, and the failure
type reveals how severe the failure will be. RUL prediction is a regression
task, whereas failure type is a classification task. In this paper, we propose
a multi-task learning approach to jointly accomplish these two tasks by using a
common input space to achieve more desirable results. We develop a convex
optimization formulation to integrate both least square loss and the negative
maximum likelihood of logistic regression, and model the joint sparsity as the
L2/L1 norm of the model parameters to couple feature selection across tasks.
The experiment results show that our method outperforms the single task
learning method by 3% in prediction accuracy.
</p>
<a href="http://arxiv.org/abs/2101.03497" target="_blank">arXiv:2101.03497</a> [<a href="http://arxiv.org/pdf/2101.03497" target="_blank">pdf</a>]

<h2>Learning Intuitive Physics with Multimodal Generative Models. (arXiv:2101.04454v2 [cs.LG] UPDATED)</h2>
<h3>Sahand Rezaei-Shoshtari, Francois Robert Hogan, Michael Jenkin, David Meger, Gregory Dudek</h3>
<p>Predicting the future interaction of objects when they come into contact with
their environment is key for autonomous agents to take intelligent and
anticipatory actions. This paper presents a perception framework that fuses
visual and tactile feedback to make predictions about the expected motion of
objects in dynamic scenes. Visual information captures object properties such
as 3D shape and location, while tactile information provides critical cues
about interaction forces and resulting object motion when it makes contact with
the environment. Utilizing a novel See-Through-your-Skin (STS) sensor that
provides high resolution multimodal sensing of contact surfaces, our system
captures both the visual appearance and the tactile properties of objects. We
interpret the dual stream signals from the sensor using a Multimodal
Variational Autoencoder (MVAE), allowing us to capture both modalities of
contacting objects and to develop a mapping from visual to tactile interaction
and vice-versa. Additionally, the perceptual system can be used to infer the
outcome of future physical interactions, which we validate through simulated
and real-world experiments in which the resting state of an object is predicted
from given initial conditions.
</p>
<a href="http://arxiv.org/abs/2101.04454" target="_blank">arXiv:2101.04454</a> [<a href="http://arxiv.org/pdf/2101.04454" target="_blank">pdf</a>]

<h2>Hand-Based Person Identification using Global and Part-Aware Deep Feature Representation Learning. (arXiv:2101.05260v2 [cs.CV] UPDATED)</h2>
<h3>Nathanael L. Baisa, Zheheng Jiang, Ritesh Vyas, Bryan Williams, Hossein Rahmani, Plamen Angelov, Sue Black</h3>
<p>In cases of serious crime, including sexual abuse, often the only available
information with demonstrated potential for identification is images of the
hands. Since this evidence is captured in uncontrolled situations, it is
difficult to analyse. As global approaches to feature comparison are limited in
this case, it is important to extend to consider local information. In this
work, we propose hand-based person identification by learning both global and
local deep feature representation. Our proposed method, Global and Part-Aware
Network (GPA-Net), creates global and local branches on the conv-layer for
learning robust discriminative global and part-level features. For learning the
local (part-level) features, we perform uniform partitioning on the conv-layer
in both horizontal and vertical directions. We retrieve the parts by conducting
a soft partition without explicitly partitioning the images or requiring
external cues such as pose estimation. We make extensive evaluations on two
large multi-ethnic and publicly available hand datasets, demonstrating that our
proposed method significantly outperforms competing approaches.
</p>
<a href="http://arxiv.org/abs/2101.05260" target="_blank">arXiv:2101.05260</a> [<a href="http://arxiv.org/pdf/2101.05260" target="_blank">pdf</a>]

<h2>Adversarially Robust and Explainable Model Compression with On-Device Personalization for Text Classification. (arXiv:2101.05624v3 [cs.LG] UPDATED)</h2>
<h3>Yao Qiang, Supriya Tumkur Suresh Kumar, Marco Brocanelli, Dongxiao Zhu</h3>
<p>On-device Deep Neural Networks (DNNs) have recently gained more attention due
to the increasing computing power of the mobile devices and the number of
applications in Computer Vision (CV), Natural Language Processing (NLP), and
Internet of Things (IoTs). Unfortunately, the existing efficient convolutional
neural network (CNN) architectures designed for CV tasks are not directly
applicable to NLP tasks and the tiny Recurrent Neural Network (RNN)
architectures have been designed primarily for IoT applications. In NLP
applications, although model compression has seen initial success in on-device
text classification, there are at least three major challenges yet to be
addressed: adversarial robustness, explainability, and personalization. Here we
attempt to tackle these challenges by designing a new training scheme for model
compression and adversarial robustness, including the optimization of an
explainable feature mapping objective, a knowledge distillation objective, and
an adversarially robustness objective. The resulting compressed model is
personalized using on-device private training data via fine-tuning. We perform
extensive experiments to compare our approach with both compact RNN (e.g.,
FastGRNN) and compressed RNN (e.g., PRADO) architectures in both natural and
adversarial NLP test settings.
</p>
<a href="http://arxiv.org/abs/2101.05624" target="_blank">arXiv:2101.05624</a> [<a href="http://arxiv.org/pdf/2101.05624" target="_blank">pdf</a>]

<h2>Temporal Logic Task Allocation in Heterogeneous Multi-Robot Systems. (arXiv:2101.05694v2 [cs.RO] UPDATED)</h2>
<h3>Xusheng Luo, Michael M. Zavlanos</h3>
<p>In this paper, we consider the problem of optimally allocating tasks,
expressed as global Linear Temporal Logic (LTL) specifications, to teams of
heterogeneous mobile robots. The robots are classified in different types that
capture their different capabilities, and each task may require robots of
multiple types. The specific robots assigned to each task are immaterial, as
long as they are of the desired type. Given a discrete workspace, our goal is
to design paths, i.e., sequences of discrete states, for the robots so that the
LTL specification is satisfied. To obtain a scalable solution to this complex
temporal logic task allocation problem, we propose a hierarchical approach that
first allocates specific robots to tasks using the information about the tasks
contained in the Nondeterministic Buchi Automaton (NBA) that captures the LTL
specification, and then designs low-level executable plans for the robots that
respect the high-level assignment. Specifically, we first prune and relax the
NBA by removing all negative atomic propositions. This step is motivated by
"lazy collision checking" methods in robotics and allows to simplify the
planning problem by checking constraint satisfaction only when needed. Then, we
extract sequences of subtasks from the relaxed NBA along with their temporal
orders, and formulate a Mixed Integer Linear Program (MILP) to allocate these
subtasks to the robots. Finally, we define generalized multi-robot path
planning problems to obtain low-level executable robot plans that satisfy both
the high-level task allocation and the temporal constraints captured by the
negative atomic propositions in the original NBA. We provide theoretical
results showing completeness and soundness of our proposed method and present
numerical simulations demonstrating that our method can generate robot paths
with lower cost, considerably faster than existing methods.
</p>
<a href="http://arxiv.org/abs/2101.05694" target="_blank">arXiv:2101.05694</a> [<a href="http://arxiv.org/pdf/2101.05694" target="_blank">pdf</a>]

<h2>U-Noise: Learnable Noise Masks for Interpretable Image Segmentation. (arXiv:2101.05791v2 [cs.CV] UPDATED)</h2>
<h3>Teddy Koker, Fatemehsadat Mireshghallah, Tom Titcombe, Georgios Kaissis</h3>
<p>Deep Neural Networks (DNNs) are widely used for decision making in a myriad
of critical applications, ranging from medical to societal and even judicial.
Given the importance of these decisions, it is crucial for us to be able to
interpret these models. We introduce a new method for interpreting image
segmentation models by learning regions of images in which noise can be applied
without hindering downstream model performance. We apply this method to
segmentation of the pancreas in CT scans, and qualitatively compare the quality
of the method to existing explainability techniques, such as Grad-CAM and
occlusion sensitivity. Additionally we show that, unlike other methods, our
interpretability model can be quantitatively evaluated based on the downstream
performance over obscured images.
</p>
<a href="http://arxiv.org/abs/2101.05791" target="_blank">arXiv:2101.05791</a> [<a href="http://arxiv.org/pdf/2101.05791" target="_blank">pdf</a>]

<h2>Data-Driven Protection Levels for Camera and 3D Map-based Safe Urban Localization. (arXiv:2101.06379v2 [cs.RO] UPDATED)</h2>
<h3>Shubh Gupta, Grace X. Gao</h3>
<p>Reliably assessing the error in an estimated vehicle position is integral for
ensuring the vehicle's safety in urban environments. Many existing approaches
use GNSS measurements to characterize protection levels (PLs) as probabilistic
upper bounds on the position error. However, GNSS signals might be reflected or
blocked in urban environments, and thus additional sensor modalities need to be
considered to determine PLs. In this paper, we propose a novel approach for
computing PLs by matching camera image measurements to a LiDAR-based 3D map of
the environment. We specify a Gaussian mixture model probability distribution
of position error using deep neural network-based data-driven models and
statistical outlier weighting techniques. From the probability distribution, we
compute the PLs by evaluating the position error bound using numerical
line-search methods. Through experimental validation with real-world data, we
demonstrate that the PLs computed from our method are reliable bounds on the
position error in urban environments.
</p>
<a href="http://arxiv.org/abs/2101.06379" target="_blank">arXiv:2101.06379</a> [<a href="http://arxiv.org/pdf/2101.06379" target="_blank">pdf</a>]

<h2>A New Particle Filter Framework for Bayesian Receiver Autonomous Integrity Monitoring in Urban Environments. (arXiv:2101.06380v2 [cs.RO] UPDATED)</h2>
<h3>Shubh Gupta, Grace X. Gao</h3>
<p>Existing urban navigation algorithms employ integrity monitoring (IM) to
mitigate the impact of measurement bias errors and determine system
availability when estimating the position of a receiver. Many IM techniques,
such as receiver autonomous integrity monitoring (RAIM), utilize measurement
residuals associated with a single receiver position to provide integrity.
However, identifying a single correct receiver position is often challenging in
urban environments due to low satellite visibility and multiple measurements
with bias errors. To address this, we propose Particle RAIM as a novel
framework for robust state estimation and IM using GNSS and odometry
measurements. Particle RAIM integrates residual-based RAIM with a particle
filter and Gaussian mixture model likelihood to jointly perform state
estimation and fault mitigation using a multimodal probability distribution of
the receiver state. Our experiments on simulated and real-world data show that
Particle RAIM achieves smaller positioning errors as well as smaller
probability of false alarm and probability of missed-identification in
determining system availability than existing urban localization and IM
approaches in challenging environments with a relatively small computation
overhead.
</p>
<a href="http://arxiv.org/abs/2101.06380" target="_blank">arXiv:2101.06380</a> [<a href="http://arxiv.org/pdf/2101.06380" target="_blank">pdf</a>]

<h2>The Connection between Discrete- and Continuous-Time Descriptions of Gaussian Continuous Processes. (arXiv:2101.06482v2 [stat.ML] UPDATED)</h2>
<h3>Federica Ferretti, Victor Chard&#xe8;s, Thierry Mora, Aleksandra M Walczak, Irene Giardina</h3>
<p>Learning the continuous equations of motion from discrete observations is a
common task in all areas of physics. However, not any discretization of a
Gaussian continuous-time stochastic process can be adopted in parametric
inference. We show that discretizations yielding consistent estimators have the
property of `invariance under coarse-graining', and correspond to fixed points
of a renormalization group map on the space of autoregressive moving average
(ARMA) models (for linear processes). This result explains why combining
differencing schemes for derivatives reconstruction and local-in-time inference
approaches does not work for time series analysis of second or higher order
stochastic differential equations, even if the corresponding integration
schemes may be acceptably good for numerical simulations.
</p>
<a href="http://arxiv.org/abs/2101.06482" target="_blank">arXiv:2101.06482</a> [<a href="http://arxiv.org/pdf/2101.06482" target="_blank">pdf</a>]

<h2>A Literature Review of Recent Graph Embedding Techniques for Biomedical Data. (arXiv:2101.06569v2 [cs.AI] UPDATED)</h2>
<h3>Yankai Chen, Yaozu Wu, Shicheng Ma, Irwin King</h3>
<p>With the rapid development of biomedical software and hardware, a large
amount of relational data interlinking genes, proteins, chemical components,
drugs, diseases, and symptoms has been collected for modern biomedical
research. Many graph-based learning methods have been proposed to analyze such
type of data, giving a deeper insight into the topology and knowledge behind
the biomedical data, which greatly benefit to both academic research and
industrial application for human healthcare. However, the main difficulty is
how to handle high dimensionality and sparsity of the biomedical graphs.
Recently, graph embedding methods provide an effective and efficient way to
address the above issues. It converts graph-based data into a low dimensional
vector space where the graph structural properties and knowledge information
are well preserved. In this survey, we conduct a literature review of recent
developments and trends in applying graph embedding methods for biomedical
data. We also introduce important applications and tasks in the biomedical
domain as well as associated public biomedical datasets.
</p>
<a href="http://arxiv.org/abs/2101.06569" target="_blank">arXiv:2101.06569</a> [<a href="http://arxiv.org/pdf/2101.06569" target="_blank">pdf</a>]

<h2>Generalized Image Reconstruction over T-Algebra. (arXiv:2101.06650v2 [cs.CV] UPDATED)</h2>
<h3>Liang Liao, Xuechun Zhang, Xinqiang Wang, Sen Lin, Xin Liu</h3>
<p>Principal Component Analysis (PCA) is well known for its capability of
dimension reduction and data compression. However, when using PCA for
compressing/reconstructing images, images need to be recast to vectors. The
vectorization of images makes some correlation constraints of neighboring
pixels and spatial information lost. To deal with the drawbacks of the
vectorizations adopted by PCA, we used small neighborhoods of each pixel to
form compounded pixels and use a tensorial version of PCA, called TPCA
(Tensorial Principal Component Analysis), to compress and reconstruct a
compounded image of compounded pixels. Our experiments on public data show that
TPCA compares favorably with PCA in compressing and reconstructing images. We
also show in our experiments that the performance of TPCA increases when the
order of compounded pixels increases.
</p>
<a href="http://arxiv.org/abs/2101.06650" target="_blank">arXiv:2101.06650</a> [<a href="http://arxiv.org/pdf/2101.06650" target="_blank">pdf</a>]

<h2>HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network that Achieves over 0.9 Mean Dice and 86 FPS. (arXiv:2101.07172v2 [cs.CV] UPDATED)</h2>
<h3>Chien-Hsiang Huang, Hung-Yu Wu, Youn-Long Lin</h3>
<p>We propose a new convolution neural network called HarDNet-MSEG for polyp
segmentation. It achieves SOTA in both accuracy and inference speed on five
popular datasets. For Kvasir-SEG, HarDNet-MSEG delivers 0.904 mean Dice running
at 86.7 FPS on a GeForce RTX 2080 Ti GPU. It consists of a backbone and a
decoder. The backbone is a low memory traffic CNN called HarDNet68, which has
been successfully applied to various CV tasks including image classification,
object detection, multi-object tracking and semantic segmentation, etc. The
decoder part is inspired by the Cascaded Partial Decoder, known for fast and
accurate salient object detection. We have evaluated HarDNet-MSEG using those
five popular datasets. The code and all experiment details are available at
Github. https://github.com/james128333/HarDNet-MSEG
</p>
<a href="http://arxiv.org/abs/2101.07172" target="_blank">arXiv:2101.07172</a> [<a href="http://arxiv.org/pdf/2101.07172" target="_blank">pdf</a>]

<h2>Learning Visual Representations with Optimum-Path Forest and its Applications to Barrett's Esophagus and Adenocarcinoma Diagnosis. (arXiv:2101.07209v2 [cs.CV] UPDATED)</h2>
<h3>Luis A. de Souza Jr., Luis C. S. Afonso, Alanna Ebigbo, Andreas Probst, Helmut Messmann, Robert Mendel, Christoph Palm, Jo&#xe3;o P. Papa</h3>
<p>In this work, we introduce the unsupervised Optimum-Path Forest (OPF)
classifier for learning visual dictionaries in the context of Barrett's
esophagus (BE) and automatic adenocarcinoma diagnosis. The proposed approach
was validated in two datasets (MICCAI 2015 and Augsburg) using three different
feature extractors (SIFT, SURF, and the not yet applied to the BE context
A-KAZE), as well as five supervised classifiers, including two variants of the
OPF, Support Vector Machines with Radial Basis Function and Linear kernels, and
a Bayesian classifier. Concerning MICCAI 2015 dataset, the best results were
obtained using unsupervised OPF for dictionary generation using supervised OPF
for classification purposes and using SURF feature extractor with accuracy
nearly to 78% for distinguishing BE patients from adenocarcinoma ones.
Regarding the Augsburg dataset, the most accurate results were also obtained
using both OPF classifiers but with A-KAZE as the feature extractor with
accuracy close to 73%. The combination of feature extraction and
bag-of-visual-words techniques showed results that outperformed others obtained
recently in the literature, as well as we highlight new advances in the related
research area. Reinforcing the significance of this work, to the best of our
knowledge, this is the first one that aimed at addressing computer-aided BE
identification using bag-of-visual-words and OPF classifiers, being this
application of unsupervised technique in the BE feature calculation the major
contribution of this work. It is also proposed a new BE and adenocarcinoma
description using the A-KAZE features, not yet applied in the literature.
</p>
<a href="http://arxiv.org/abs/2101.07209" target="_blank">arXiv:2101.07209</a> [<a href="http://arxiv.org/pdf/2101.07209" target="_blank">pdf</a>]

<h2>Salient Object Detection via Integrity Learning. (arXiv:2101.07663v2 [cs.CV] UPDATED)</h2>
<h3>Mingchen Zhuge, Deng-Ping Fan, Nian Liu, Dingwen Zhang, Dong Xu, Ling Shao</h3>
<p>Albeit current salient object detection (SOD) works have achieved fantastic
progress, they are cast into the shade when it comes to the integrity of the
predicted salient regions. We define the concept of integrity at both the micro
and macro level. Specifically, at the micro level, the model should highlight
all parts that belong to a certain salient object, while at the macro level,
the model needs to discover all salient objects from the given image scene. To
facilitate integrity learning for salient object detection, we design a novel
Integrity Cognition Network (ICON), which explores three important components
to learn strong integrity features. 1) Unlike the existing models that focus
more on feature discriminability, we introduce a diverse feature aggregation
(DFA) component to aggregate features with various receptive fields (i.e.,,
kernel shape and context) and increase the feature diversity. Such diversity is
the foundation for mining the integral salient objects. 2) Based on the DFA
features, we introduce the integrity channel enhancement (ICE) component with
the goal of enhancing feature channels that highlight the integral salient
objects at the macro level, while suppressing the other distracting ones. 3)
After extracting the enhanced features, the part-whole verification (PWV)
method is employed to determine whether the part and whole object features have
strong agreement. Such part-whole agreements can further improve the
micro-level integrity for each salient object. To demonstrate the effectiveness
of ICON, comprehensive experiments are conducted on seven challenging
benchmarks, where promising results are achieved.
</p>
<a href="http://arxiv.org/abs/2101.07663" target="_blank">arXiv:2101.07663</a> [<a href="http://arxiv.org/pdf/2101.07663" target="_blank">pdf</a>]

<h2>Hyperspectral Image Restoration via Multi-mode and Double-weighted Tensor Nuclear Norm Minimization. (arXiv:2101.07681v2 [cs.CV] UPDATED)</h2>
<h3>Sheng Liu, Xiaozhen Xie, Wenfeng Kong</h3>
<p>Tensor nuclear norm (TNN) induced by tensor singular value decomposition
plays an important role in hyperspectral image (HSI) restoration tasks. In this
letter, we first consider three inconspicuous but crucial phenomenons in TNN.
In the Fourier transform domain of HSIs, different frequency components contain
different information; different singular values of each frequency component
also represent different information. The two physical phenomenons lie not only
in the spectral dimension but also in the spatial dimensions. Then, to improve
the capability and flexibility of TNN for HSI restoration, we propose a
multi-mode and double-weighted TNN based on the above three crucial
phenomenons. It can adaptively shrink the frequency components and singular
values according to their physical meanings in all modes of HSIs. In the
framework of the alternating direction method of multipliers, we design an
effective alternating iterative strategy to optimize our proposed model.
Restoration experiments on both synthetic and real HSI datasets demonstrate
their superiority against related methods.
</p>
<a href="http://arxiv.org/abs/2101.07681" target="_blank">arXiv:2101.07681</a> [<a href="http://arxiv.org/pdf/2101.07681" target="_blank">pdf</a>]

<h2>TC-DTW: Accelerating Multivariate Dynamic Time Warping Through Triangle Inequality and Point Clustering. (arXiv:2101.07731v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Shen, Min Chi</h3>
<p>Dynamic time warping (DTW) plays an important role in analytics on time
series. Despite the large body of research on speeding up univariate DTW, the
method for multivariate DTW has not been improved much in the last two decades.
The most popular algorithm used today is still the one developed seventeen
years ago. This paper presents a solution that, as far as we know, for the
first time consistently outperforms the classic multivariate DTW algorithm
across dataset sizes, series lengths, data dimensions, temporal window sizes,
and machines. The new solution, named TC-DTW, introduces Triangle Inequality
and Point Clustering into the algorithm design on lower bound calculations for
multivariate DTW. In experiments on DTW-based nearest neighbor finding, the new
solution avoids as much as 98% (60% average) DTW distance calculations and
yields as much as 25X (7.5X average) speedups.
</p>
<a href="http://arxiv.org/abs/2101.07731" target="_blank">arXiv:2101.07731</a> [<a href="http://arxiv.org/pdf/2101.07731" target="_blank">pdf</a>]

<h2>The Risks of Invariant Risk Minimization. (arXiv:2010.05761v1 [cs.LG] CROSS LISTED)</h2>
<h3>Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski</h3>
<p>Invariant Causal Prediction (Peters et al., 2016) is a technique for
out-of-distribution generalization which assumes that some aspects of the data
distribution vary across the training set but that the underlying causal
mechanisms remain constant. Recently, Arjovsky et al. (2019) proposed Invariant
Risk Minimization (IRM), an objective based on this idea for learning deep,
invariant features of data which are a complex function of latent variables;
many alternatives have subsequently been suggested. However, formal guarantees
for all of these works are severely lacking. In this paper, we present the
first analysis of classification under the IRM objective$-$as well as these
recently proposed alternatives$-$under a fairly natural and general model. In
the linear case, we show simple conditions under which the optimal solution
succeeds or, more often, fails to recover the optimal invariant predictor. We
furthermore present the very first results in the non-linear regime: we
demonstrate that IRM can fail catastrophically unless the test data are
sufficiently similar to the training distribution$-$this is precisely the issue
that it was intended to solve. Thus, in this setting we find that IRM and its
alternatives fundamentally do not improve over standard Empirical Risk
Minimization.
</p>
<a href="http://arxiv.org/abs/2010.05761" target="_blank">arXiv:2010.05761</a> [<a href="http://arxiv.org/pdf/2010.05761" target="_blank">pdf</a>]

<h2>A Unifying Generative Model for Graph Learning Algorithms: Label Propagation, Graph Convolutions, and Combinations. (arXiv:2101.07730v1 [cs.LG] CROSS LISTED)</h2>
<h3>Junteng Jia, Austin R. Benson</h3>
<p>Semi-supervised learning on graphs is a widely applicable problem in network
science and machine learning. Two standard algorithms -- label propagation and
graph neural networks -- both operate by repeatedly passing information along
edges, the former by passing labels and the latter by passing node features,
modulated by neural networks. These two types of algorithms have largely
developed separately, and there is little understanding about the structure of
network data that would make one of these approaches work particularly well
compared to the other or when the approaches can be meaningfully combined.
Here, we develop a Markov random field model for the data generation process of
node attributes, based on correlations of attributes on and between vertices,
that motivates and unifies these algorithmic approaches. We show that label
propagation, a linearized graph convolutional network, and their combination
can all be derived as conditional expectations under our model, when
conditioning on different attributes. In addition, the data model highlights
deficiencies in existing graph neural networks (while producing new algorithmic
solutions), serves as a rigorous statistical framework for understanding graph
learning issues such as over-smoothing, creates a testbed for evaluating
inductive learning performance, and provides a way to sample graphs attributes
that resemble empirical data. We also find that a new algorithm derived from
our data generation model, which we call a Linear Graph Convolution, performs
extremely well in practice on empirical data, and provide theoretical
justification for why this is the case.
</p>
<a href="http://arxiv.org/abs/2101.07730" target="_blank">arXiv:2101.07730</a> [<a href="http://arxiv.org/pdf/2101.07730" target="_blank">pdf</a>]

