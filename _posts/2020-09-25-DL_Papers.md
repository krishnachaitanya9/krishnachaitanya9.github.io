---
title: Latest Deep Learning Papers
date: 2021-02-02 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (164 Articles)</h1>
<h2>Diagnosis of Acute Poisoning Using Explainable Artificial Intelligence. (arXiv:2102.01116v1 [cs.AI])</h2>
<h3>Michael Chary, Ed W Boyer, Michele M Burns</h3>
<p>Medical toxicology is the clinical specialty that treats the toxic effects of
substances, be it an overdose, a medication error, or a scorpion sting. The
volume of toxicological knowledge and research has, as with other medical
specialties, outstripped the ability of the individual clinician to entirely
master and stay current with it. The application of machine learning techniques
to medical toxicology is challenging because initial treatment decisions are
often based on a few pieces of textual data and rely heavily on prior
knowledge. ML techniques often do not represent knowledge in a way that is
transparent for the physician, raising barriers to usability. Rule-based
systems and decision tree learning are more transparent approaches, but often
generalize poorly and require expert curation to implement and maintain. Here,
we construct a probabilistic logic network to represent a portion of the
knowledge base of a medical toxicologist. Our approach transparently mimics the
knowledge representation and clinical decision-making of practicing clinicians.
The software, dubbed Tak, performs comparably to humans on straightforward
cases and intermediate difficulty cases, but is outperformed by humans on
challenging clinical cases. Tak outperforms a decision tree classifier at all
levels of difficulty. Probabilistic logic provides one form of explainable
artificial intelligence that may be more acceptable for use in healthcare, if
it can achieve acceptable levels of performance.
</p>
<a href="http://arxiv.org/abs/2102.01116" target="_blank">arXiv:2102.01116</a> [<a href="http://arxiv.org/pdf/2102.01116" target="_blank">pdf</a>]

<h2>SGD Generalizes Better Than GD (And Regularization Doesn't Help). (arXiv:2102.01117v1 [cs.LG])</h2>
<h3>Idan Amir, Tomer Koren, Roi Livni</h3>
<p>We give a new separation result between the generalization performance of
stochastic gradient descent (SGD) and of full-batch gradient descent (GD) in
the fundamental stochastic convex optimization model. While for SGD it is
well-known that $O(1/\epsilon^2)$ iterations suffice for obtaining a solution
with $\epsilon$ excess expected risk, we show that with the same number of
steps GD may overfit and emit a solution with $\Omega(1)$ generalization error.
Moreover, we show that in fact $\Omega(1/\epsilon^4)$ iterations are necessary
for GD to match the generalization performance of SGD, which is also tight due
to recent work by Bassily et al. (2020). We further discuss how regularizing
the empirical risk minimized by GD essentially does not change the above
result, and revisit the concepts of stability, implicit bias and the role of
the learning algorithm in generalization.
</p>
<a href="http://arxiv.org/abs/2102.01117" target="_blank">arXiv:2102.01117</a> [<a href="http://arxiv.org/pdf/2102.01117" target="_blank">pdf</a>]

<h2>RectiNet-v2: A stacked network architecture for document image dewarping. (arXiv:2102.01120v1 [cs.CV])</h2>
<h3>Hmrishav Bandyopadhyay, Tanmoy Dasgupta, Nibaran Das, Mita Nasipuri</h3>
<p>With the advent of mobile and hand-held cameras, document images have found
their way into almost every domain. Dewarping of these images for the removal
of perspective distortions and folds is essential so that they can be
understood by document recognition algorithms. For this, we propose an
end-to-end CNN architecture that can produce distortion free document images
from warped documents it takes as input. We train this model on warped document
images simulated synthetically to compensate for lack of enough natural data.
Our method is novel in the use of a bifurcated decoder with shared weights to
prevent intermingling of grid coordinates, in the use of residual networks in
the U-Net skip connections to allow flow of data from different receptive
fields in the model, and in the use of a gated network to help the model focus
on structure and line level detail of the document image. We evaluate our
method on the DocUNet dataset, a benchmark in this domain, and obtain results
comparable to state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.01120" target="_blank">arXiv:2102.01120</a> [<a href="http://arxiv.org/pdf/2102.01120" target="_blank">pdf</a>]

<h2>Comparing hundreds of machine learning classifiers and discrete choice models in predicting travel behavior: an empirical benchmark. (arXiv:2102.01130v1 [cs.LG])</h2>
<h3>Shenhao Wang, Baichuan Mo, Stephane Hess, Jinhua Zhao</h3>
<p>Researchers have compared machine learning (ML) classifiers and discrete
choice models (DCMs) in predicting travel behavior, but the generalizability of
the findings is limited by the specifics of data, contexts, and authors'
expertise. This study seeks to provide a generalizable empirical benchmark by
comparing hundreds of ML and DCM classifiers in a highly structured manner. The
experiments evaluate both prediction accuracy and computational cost by
spanning four hyper-dimensions, including 105 ML and DCM classifiers from 12
model families, 3 datasets, 3 sample sizes, and 3 outputs. This experimental
design leads to an immense number of 6,970 experiments, which are corroborated
with a meta dataset of 136 experiment points from 35 previous studies. This
study is hitherto the most comprehensive and almost exhaustive comparison of
the classifiers for travel behavioral prediction. We found that the ensemble
methods and deep neural networks achieve the highest predictive performance,
but at a relatively high computational cost. Random forests are the most
computationally efficient, balancing between prediction and computation. While
discrete choice models offer accuracy with only 3-4 percentage points lower
than the top ML classifiers, they have much longer computational time and
become computationally impossible with large sample size, high input
dimensions, or simulation-based estimation. The relative ranking of the ML and
DCM classifiers is highly stable, while the absolute values of the prediction
accuracy and computational time have large variations. Overall, this paper
suggests using deep neural networks, model ensembles, and random forests as
baseline models for future travel behavior prediction. For choice modeling, the
DCM community should switch more attention from fitting models to improving
computational efficiency, so that the DCMs can be widely adopted in the big
data context.
</p>
<a href="http://arxiv.org/abs/2102.01130" target="_blank">arXiv:2102.01130</a> [<a href="http://arxiv.org/pdf/2102.01130" target="_blank">pdf</a>]

<h2>toon2real: Translating Cartoon Images to Realistic Images. (arXiv:2102.01143v1 [cs.CV])</h2>
<h3>K. M. Arefeen Sultan, Mohammad Imrul Jubair, MD. Nahidul Islam, Sayed Hossain Khan</h3>
<p>In terms of Image-to-image translation, Generative Adversarial Networks
(GANs) has achieved great success even when it is used in the unsupervised
dataset. In this work, we aim to translate cartoon images to photo-realistic
images using GAN. We apply several state-of-the-art models to perform this
task; however, they fail to perform good quality translations. We observe that
the shallow difference between these two domains causes this issue. Based on
this idea, we propose a method based on CycleGAN model for image translation
from cartoon domain to photo-realistic domain. To make our model efficient, we
implemented Spectral Normalization which added stability in our model. We
demonstrate our experimental results and show that our proposed model has
achieved the lowest Frechet Inception Distance score and better results
compared to another state-of-the-art technique, UNIT.
</p>
<a href="http://arxiv.org/abs/2102.01143" target="_blank">arXiv:2102.01143</a> [<a href="http://arxiv.org/pdf/2102.01143" target="_blank">pdf</a>]

<h2>Real-time Prediction for Mechanical Ventilation in COVID-19 Patients using A Multi-task Gaussian Process Multi-objective Self-attention Network. (arXiv:2102.01147v1 [cs.LG])</h2>
<h3>Kai Zhang, Siddharth Karanth, Bela Patel, Robert Murphy, Xiaoqian Jiang</h3>
<p>We propose a robust in-time predictor for in-hospital COVID-19 patient's
probability of requiring mechanical ventilation. A challenge in the risk
prediction for COVID-19 patients lies in the great variability and irregular
sampling of patient's vitals and labs observed in the clinical setting.
Existing methods have strong limitations in handling time-dependent features'
complex dynamics, either oversimplifying temporal data with summary statistics
that lose information or over-engineering features that lead to less robust
outcomes. We propose a novel in-time risk trajectory predictive model to handle
the irregular sampling rate in the data, which follows the dynamics of risk of
performing mechanical ventilation for individual patients. The model
incorporates the Multi-task Gaussian Process using observed values to learn the
posterior joint multi-variant conditional probability and infer the missing
values on a unified time grid. The temporal imputed data is fed into a
multi-objective self-attention network for the prediction task. A novel
positional encoding layer is proposed and added to the network for producing
in-time predictions. The positional layer outputs a risk score at each
user-defined time point during the entire hospital stay of an inpatient. We
frame the prediction task into a multi-objective learning framework, and the
risk scores at all time points are optimized altogether, which adds robustness
and consistency to the risk score trajectory prediction. Our experimental
evaluation on a large database with nationwide in-hospital patients with
COVID-19 also demonstrates that it improved the state-of-the-art performance in
terms of AUC (Area Under the receiver operating characteristic Curve) and AUPRC
(Area Under the Precision-Recall Curve) performance metrics, especially at
early times after hospital admission.
</p>
<a href="http://arxiv.org/abs/2102.01147" target="_blank">arXiv:2102.01147</a> [<a href="http://arxiv.org/pdf/2102.01147" target="_blank">pdf</a>]

<h2>System-reliability based multi-ensemble of GAN and one-class joint Gaussian distributions for unsupervised real-time structural health monitoring. (arXiv:2102.01158v1 [cs.LG])</h2>
<h3>Mohammad Hesam Soleimani-Babakamali, Reza Sepasdar, Kourosh Nasrollahzadeh, Rodrigo Sarlo</h3>
<p>Unsupervised health monitoring has gained much attention in the last decade
as the most practical real-time structural health monitoring (SHM) approach.
Among the proposed unsupervised techniques in the literature, there are still
obstacles to robust and real-time health monitoring. These barriers include
loss of information from dimensionality reduction in feature extraction steps,
case-dependency of those steps, lack of a dynamic clustering, and detection
results' sensitivity to user-defined parameters. This study introduces an
unsupervised real-time SHM method with a mixture of low- and high-dimensional
features without a case-dependent extraction scheme. Both features are used to
train multi-ensembles of Generative Adversarial Networks (GAN) and one-class
joint Gaussian distribution models (1-CG). A novelty detection system of
limit-state functions based on GAN and 1-CG models' detection scores is
constructed. The Resistance of those limit-state functions (detection
thresholds) is tuned to user-defined parameters with the GAN-generated data
objects by employing the Monte Carlo histogram sampling through a
reliability-based analysis. The tuning makes the method robust to user-defined
parameters, which is crucial as there is no rule for selecting those parameters
in a real-time SHM. The proposed novelty detection framework is applied to two
standard SHM datasets to illustrate its generalizability: Yellow Frame (twenty
damage classes) and Z24 Bridge (fifteen damage classes). All different damage
categories are identified with low sensitivity to the initial choice of
user-defined parameters with both introduced dynamic and static baseline
approaches with few or no false alarms.
</p>
<a href="http://arxiv.org/abs/2102.01158" target="_blank">arXiv:2102.01158</a> [<a href="http://arxiv.org/pdf/2102.01158" target="_blank">pdf</a>]

<h2>Adjoint Rigid Transform Network: Self-supervised Alignment of 3D Shapes. (arXiv:2102.01161v1 [cs.CV])</h2>
<h3>Keyang Zhou, Bharat Lal Bhatnagar, Bernt Schiele, Gerard Pons-Moll</h3>
<p>Most learning methods for 3D data (point clouds, meshes) suffer significant
performance drops when the data is not carefully aligned to a canonical
orientation. Aligning real world 3D data collected from different sources is
non-trivial and requires manual intervention. In this paper, we propose the
Adjoint Rigid Transform (ART) Network, a neural module which can be integrated
with existing 3D networks to significantly boost their performance in tasks
such as shape reconstruction, non-rigid registration, and latent
disentanglement. ART learns to rotate input shapes to a canonical orientation
that is crucial for a lot of tasks. ART achieves this by imposing rotation
equivariance constraint on input shapes. The remarkable result is that with
only self-supervision, ART can discover a unique canonical orientation for both
rigid and nonrigid objects, which leads to a notable boost in downstream task
performance. We will release our code and pre-trained models for further
research.
</p>
<a href="http://arxiv.org/abs/2102.01161" target="_blank">arXiv:2102.01161</a> [<a href="http://arxiv.org/pdf/2102.01161" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Decision-Making and Control in Power Systems: Tutorial, Review, and Vision. (arXiv:2102.01168v1 [cs.LG])</h2>
<h3>Xin Chen, Guannan Qu, Yujie Tang, Steven Low, Na Li</h3>
<p>With large-scale integration of renewable generation and ubiquitous
distributed energy resources (DERs), modern power systems confront a series of
new challenges in operation and control, such as growing complexity, increasing
uncertainty, and aggravating volatility. While the upside is that more and more
data are available owing to the widely-deployed smart meters, smart sensors,
and upgraded communication networks. As a result, data-driven control
techniques, especially reinforcement learning (RL), have attracted surging
attention in recent years. In this paper, we focus on RL and aim to provide a
tutorial on various RL techniques and how they can be applied to the
decision-making and control in power systems. In particular, we select three
key applications, including frequency regulation, voltage control, and energy
management, for illustration, and present the typical ways to model and tackle
them with RL methods. We conclude by emphasizing two critical issues in the
application of RL, i.e., safety and scalability. Several potential future
directions are discussed as well.
</p>
<a href="http://arxiv.org/abs/2102.01168" target="_blank">arXiv:2102.01168</a> [<a href="http://arxiv.org/pdf/2102.01168" target="_blank">pdf</a>]

<h2>Novel Design and Implementation of a Vehicle Controlling and Tracking System. (arXiv:2102.01170v1 [cs.RO])</h2>
<h3>Hasan Naji, Iuliana Marin, Nicolae Goga, Cristian Taslitschi</h3>
<p>The purpose of this project is to build a system that will quickly track the
location of a stolen vehicle, thereby reducing the cost and effort of police.
Moreover, the vehicle's computer system can be controlled remotely by the
owners of the vehicle or police. More precisely, the goal of this work is to
design a, develop remote control of the vehicle, and find the locations with
Latitude (LAT) and Longitude (LONG).
</p>
<a href="http://arxiv.org/abs/2102.01170" target="_blank">arXiv:2102.01170</a> [<a href="http://arxiv.org/pdf/2102.01170" target="_blank">pdf</a>]

<h2>Multi-modal Ensemble Models for Predicting Video Memorability. (arXiv:2102.01173v1 [cs.LG])</h2>
<h3>Tony Zhao, Irving Fang, Jeffrey Kim, Gerald Friedland</h3>
<p>Modeling media memorability has been a consistent challenge in the field of
machine learning. The Predicting Media Memorability task in MediaEval2020 is
the latest benchmark among similar challenges addressing this topic. Building
upon techniques developed in previous iterations of the challenge, we developed
ensemble methods with the use of extracted video, image, text, and audio
features. Critically, in this work we introduce and demonstrate the efficacy
and high generalizability of extracted audio embeddings as a feature for the
task of predicting media memorability.
</p>
<a href="http://arxiv.org/abs/2102.01173" target="_blank">arXiv:2102.01173</a> [<a href="http://arxiv.org/pdf/2102.01173" target="_blank">pdf</a>]

<h2>Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation. (arXiv:2102.01187v1 [cs.CV])</h2>
<h3>Peiye Zhuang, Oluwasanmi Koyejo, Alexander G. Schwing</h3>
<p>Controllable semantic image editing enables a user to change entire image
attributes with few clicks, e.g., gradually making a summer scene look like it
was taken in winter. Classic approaches for this task use a Generative
Adversarial Net (GAN) to learn a latent space and suitable latent-space
transformations. However, current approaches often suffer from attribute edits
that are entangled, global image identity changes, and diminished
photo-realism. To address these concerns, we learn multiple attribute
transformations simultaneously, we integrate attribute regression into the
training of transformation functions, apply a content loss and an adversarial
loss that encourage the maintenance of image identity and photo-realism. We
propose quantitative evaluation strategies for measuring controllable editing
performance, unlike prior work which primarily focuses on qualitative
evaluation. Our model permits better control for both single- and
multiple-attribute editing, while also preserving image identity and realism
during transformation. We provide empirical results for both real and synthetic
images, highlighting that our model achieves state-of-the-art performance for
targeted image manipulation.
</p>
<a href="http://arxiv.org/abs/2102.01187" target="_blank">arXiv:2102.01187</a> [<a href="http://arxiv.org/pdf/2102.01187" target="_blank">pdf</a>]

<h2>GraphDF: A Discrete Flow Model for Molecular Graph Generation. (arXiv:2102.01189v1 [cs.LG])</h2>
<h3>Youzhi Luo, Keqiang Yan, Shuiwang Ji</h3>
<p>We consider the problem of molecular graph generation using deep models.
While graphs are discrete, most existing methods use continuous latent
variables, resulting in inaccurate modeling of discrete graph structures. In
this work, we propose GraphDF, a novel discrete latent variable model for
molecular graph generation based on normalizing flow methods. GraphDF uses
invertible modulo shift transforms to map discrete latent variables to graph
nodes and edges. We show that the use of discrete latent variables reduces
computational costs and eliminates the negative effect of dequantization.
Comprehensive experimental results show that GraphDF outperforms prior methods
on random generation, property optimization, and constrained optimization
tasks.
</p>
<a href="http://arxiv.org/abs/2102.01189" target="_blank">arXiv:2102.01189</a> [<a href="http://arxiv.org/pdf/2102.01189" target="_blank">pdf</a>]

<h2>The 4th International Workshop on Smart Simulation and Modelling for Complex Systems. (arXiv:2102.01190v1 [cs.AI])</h2>
<h3>Xing Su, Yan Kong, Weihua Li</h3>
<p>Computer-based modelling and simulation have become useful tools to
facilitate humans to understand systems in different domains, such as physics,
astrophysics, chemistry, biology, economics, engineering and social science. A
complex system is featured with a large number of interacting components
(agents, processes, etc.), whose aggregate activities are nonlinear and
self-organized. Complex systems are hard to be simulated or modelled by using
traditional computational approaches due to complex relationships among system
components, distributed features of resources, and dynamics of environments.
Meanwhile, smart systems such as multi-agent systems have demonstrated
advantages and great potentials in modelling and simulating complex systems.
</p>
<a href="http://arxiv.org/abs/2102.01190" target="_blank">arXiv:2102.01190</a> [<a href="http://arxiv.org/pdf/2102.01190" target="_blank">pdf</a>]

<h2>Tight-Integration of Feature-Based Relocalization in Monocular Direct Visual Odometry. (arXiv:2102.01191v1 [cs.CV])</h2>
<h3>Mariia Gladkova, Rui Wang, Niclas Zeller, Daniel Cremers</h3>
<p>In this paper we propose a framework for integrating map-based relocalization
into online direct visual odometry. To achieve map-based relocalization for
direct methods, we integrate image features into Direct Sparse Odometry (DSO)
and rely on feature matching to associate online visual odometry (VO) with a
previously built map. The integration of the relocalization poses is threefold.
Firstly, they are treated as pose priors and tightly integrated into the direct
image alignment of the front-end tracking. Secondly, they are also tightly
integrated into the back-end bundle adjustment. An online fusion module is
further proposed to combine relative VO poses and global relocalization poses
in a pose graph to estimate keyframe-wise smooth and globally accurate poses.
We evaluate our method on two multi-weather datasets showing the benefits of
integrating different handcrafted and learned features and demonstrating
promising improvements on camera tracking accuracy.
</p>
<a href="http://arxiv.org/abs/2102.01191" target="_blank">arXiv:2102.01191</a> [<a href="http://arxiv.org/pdf/2102.01191" target="_blank">pdf</a>]

<h2>A Statistician Teaches Deep Learning. (arXiv:2102.01194v1 [stat.ML])</h2>
<h3>G. Jogesh Babu, David Banks, Hyunsoon Cho, David Han, Hailin Sang, Shouyi Wang</h3>
<p>Deep learning (DL) has gained much attention and become increasingly popular
in modern data science. Computer scientists led the way in developing deep
learning techniques, so the ideas and perspectives can seem alien to
statisticians. Nonetheless, it is important that statisticians become involved
-- many of our students need this expertise for their careers. In this paper,
developed as part of a program on DL held at the Statistical and Applied
Mathematical Sciences Institute, we address this culture gap and provide tips
on how to teach deep learning to statistics graduate students. After some
background, we list ways in which DL and statistical perspectives differ,
provide a recommended syllabus that evolved from teaching two iterations of a
DL graduate course, offer examples of suggested homework assignments, give an
annotated list of teaching resources, and discuss DL in the context of two
research areas.
</p>
<a href="http://arxiv.org/abs/2102.01194" target="_blank">arXiv:2102.01194</a> [<a href="http://arxiv.org/pdf/2102.01194" target="_blank">pdf</a>]

<h2>Causal Inference with the Instrumental Variable Approach and Bayesian Nonparametric Machine Learning. (arXiv:2102.01199v1 [stat.ML])</h2>
<h3>Robert E. McCulloch, Rodney A. Sparapani, Brent R. Logan, Purushottam W. Laud</h3>
<p>We provide a new flexible framework for inference with the instrumental
variable model. Rather than using linear specifications, functions
characterizing the effects of instruments and other explanatory variables are
estimated using machine learning via Bayesian Additive Regression Trees (BART).
Error terms and their distribution are inferred using Dirichlet Process
mixtures. Simulated and real examples show that when the true functions are
linear, little is lost. But when nonlinearities are present, dramatic
improvements are obtained with virtually no manual tuning.
</p>
<a href="http://arxiv.org/abs/2102.01199" target="_blank">arXiv:2102.01199</a> [<a href="http://arxiv.org/pdf/2102.01199" target="_blank">pdf</a>]

<h2>Fast Training of Provably Robust Neural Networks by SingleProp. (arXiv:2102.01208v1 [cs.LG])</h2>
<h3>Akhilan Boopathy, Tsui-Wei Weng, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang, Luca Daniel</h3>
<p>Recent works have developed several methods of defending neural networks
against adversarial attacks with certified guarantees. However, these
techniques can be computationally costly due to the use of certification during
training. We develop a new regularizer that is both more efficient than
existing certified defenses, requiring only one additional forward propagation
through a network, and can be used to train networks with similar certified
accuracy. Through experiments on MNIST and CIFAR-10 we demonstrate improvements
in training speed and comparable certified accuracy compared to
state-of-the-art certified defenses.
</p>
<a href="http://arxiv.org/abs/2102.01208" target="_blank">arXiv:2102.01208</a> [<a href="http://arxiv.org/pdf/2102.01208" target="_blank">pdf</a>]

<h2>MPC path-planner for autonomous driving solved by genetic algorithm technique. (arXiv:2102.01211v1 [cs.RO])</h2>
<h3>Stefano Arrigoni, Francesco Braghin, Federico Cheli</h3>
<p>Autonomous vehicle's technology is expected to be disruptive for automotive
industry in next years. This paper proposes a novel real-time trajectory
planner based on a Nonlinear Model Predictive Control (NMPC) algorithm. A
nonlinear single track vehicle model with Pacejka's lateral tyre formulas has
been implemented. The numerical solution of the NMPC problem is obtained by
means of the implementation of a novel genetic algorithm strategy. Numerical
results are discussed through simulations that shown a reasonable behavior of
the proposed strategy in presence of static or moving obstacles as well as in a
wide rage of road friction conditions. Moreover a real-time implementation is
made possible by the reported computational time analysis.
</p>
<a href="http://arxiv.org/abs/2102.01211" target="_blank">arXiv:2102.01211</a> [<a href="http://arxiv.org/pdf/2102.01211" target="_blank">pdf</a>]

<h2>Kinova Gen3-Lite manipulator inverse kinematics: optimal polynomial solution. (arXiv:2102.01217v1 [cs.RO])</h2>
<h3>Hamed Montazer Zohour, Bruno Belzile, David St-Onge</h3>
<p>A polynomial solution to the inverse kinematic problem of the Kinova Gen3
Lite robot is proposed in this paper. This serial robot is based on a 6R
kinematic chain and is not wrist-partitioned. We first start from the forward
kinematics equation providing the position and orientation of the end-effector,
finally, the univariate polynomial equation is given as a function of the first
joint variable $\theta_{1}$. The remaining joint variables are computed by back
substitution. Thus, an unique set of joint position is obtain for each root of
the univariate equation. Numerical examples, simulated in ROS (Robot Operating
System), are given to validate the results, which are compared to the
coordinates obtained with MoveIt! and with the actual robot. A procedure to
choose an optimum posture of the robot is also proposed.
</p>
<a href="http://arxiv.org/abs/2102.01217" target="_blank">arXiv:2102.01217</a> [<a href="http://arxiv.org/pdf/2102.01217" target="_blank">pdf</a>]

<h2>Doubly Robust Thompson Sampling for linear payoffs. (arXiv:2102.01229v1 [stat.ML])</h2>
<h3>Wonyoung Kim, Gi-soo Kim, Myunghee Cho Paik</h3>
<p>A challenging aspect of the bandit problem is that a stochastic reward is
observed only for the chosen arm and the rewards of other arms remain missing.
Since the arm choice depends on the past context and reward pairs, the contexts
of chosen arms suffer from correlation and render the analysis difficult. We
propose a novel multi-armed contextual bandit algorithm called Doubly Robust
(DR) Thompson Sampling (TS) that applies the DR technique used in missing data
literature to TS. The proposed algorithm improves the bound of TS by a factor
of $\sqrt{d}$, where $d$ is the dimension of the context. A benefit of the
proposed method is that it uses all the context data, chosen or not chosen,
thus allowing to circumvent the technical definition of unsaturated arms used
in theoretical analysis of TS. Empirical studies show the advantage of the
proposed algorithm over TS.
</p>
<a href="http://arxiv.org/abs/2102.01229" target="_blank">arXiv:2102.01229</a> [<a href="http://arxiv.org/pdf/2102.01229" target="_blank">pdf</a>]

<h2>Time Adaptive Gaussian Model. (arXiv:2102.01238v1 [stat.ML])</h2>
<h3>Federico Cieca, Veronica Tozzo</h3>
<p>Multivariate time series analysis is becoming an integral part of data
analysis pipelines. Understanding the individual time point connections between
covariates as well as how these connections change in time is non-trivial. To
this aim, we propose a novel method that leverages on Hidden Markov Models and
Gaussian Graphical Models -- Time Adaptive Gaussian Model (TAGM). Our model is
a generalization of state-of-the-art methods for the inference of temporal
graphical models, its formulation leverages on both aspects of these models
providing better results than current methods. In particular,it performs
pattern recognition by clustering data points in time; and, it finds
probabilistic (and possibly causal) relationships among the observed variables.
Compared to current methods for temporal network inference, it reduces the
basic assumptions while still showing good inference performances.
</p>
<a href="http://arxiv.org/abs/2102.01238" target="_blank">arXiv:2102.01238</a> [<a href="http://arxiv.org/pdf/2102.01238" target="_blank">pdf</a>]

<h2>TinyML for Ubiquitous Edge AI. (arXiv:2102.01255v1 [cs.LG])</h2>
<h3>Stanislava Soro</h3>
<p>TinyML is a fast-growing multidisciplinary field at the intersection of
machine learning, hardware, and software, that focuses on enabling deep
learning algorithms on embedded (microcontroller powered) devices operating at
extremely low power range (mW range and below). TinyML addresses the challenges
in designing power-efficient, compact deep neural network models, supporting
software framework, and embedded hardware that will enable a wide range of
customized, ubiquitous inference applications on battery-operated,
resource-constrained devices. In this report, we discuss the major challenges
and technological enablers that direct this field's expansion. TinyML will open
the door to the new types of edge services and applications that do not rely on
cloud processing but thrive on distributed edge inference and autonomous
reasoning.
</p>
<a href="http://arxiv.org/abs/2102.01255" target="_blank">arXiv:2102.01255</a> [<a href="http://arxiv.org/pdf/2102.01255" target="_blank">pdf</a>]

<h2>Atlas-aware ConvNetfor Accurate yet Robust Anatomical Segmentation. (arXiv:2102.01256v1 [cs.CV])</h2>
<h3>Yuan Liang, Weinan Song, Jiawei Yang, Liang Qiu, Kun Wang, Lei He</h3>
<p>Convolutional networks (ConvNets) have achieved promising accuracy for
various anatomical segmentation tasks. Despite the success, these methods can
be sensitive to data appearance variations. Considering the large variability
of scans caused by artifacts, pathologies, and scanning setups, robust ConvNets
are vital for clinical applications, while have not been fully explored. In
this paper, we propose to mitigate the challenge by enabling ConvNets'
awareness of the underlying anatomical invariances among imaging scans.
Specifically, we introduce a fully convolutional Constraint Adoption Module
(CAM) that incorporates probabilistic atlas priors as explicit constraints for
predictions over a locally connected Conditional Random Field (CFR), which
effectively reinforces the anatomical consistency of the labeling outputs. We
design the CAM to be flexible for boosting various ConvNet, and compact for
co-optimizing with ConvNets for fusion parameters that leads to the optimal
performance. We show the advantage of such atlas priors fusion is two-fold with
two brain parcellation tasks. First, our models achieve state-of-the-art
accuracy among ConvNet-based methods on both datasets, by significantly
reducing structural abnormalities of predictions. Second, we can largely boost
the robustness of existing ConvNets, proved by: (i) testing on scans with
synthetic pathologies, and (ii) training and evaluation on scans of different
scanning setups across datasets. Our method is proposing to be easily adopted
to existing ConvNets by fine-tuning with CAM plugged in for accuracy and
robustness boosts.
</p>
<a href="http://arxiv.org/abs/2102.01256" target="_blank">arXiv:2102.01256</a> [<a href="http://arxiv.org/pdf/2102.01256" target="_blank">pdf</a>]

<h2>Evaluating the Interpretability of Generative Models by Interactive Reconstruction. (arXiv:2102.01264v1 [cs.LG])</h2>
<h3>Andrew Slavin Ross, Nina Chen, Elisa Zhao Hang, Elena L. Glassman, Finale Doshi-Velez</h3>
<p>For machine learning models to be most useful in numerous sociotechnical
systems, many have argued that they must be human-interpretable. However,
despite increasing interest in interpretability, there remains no firm
consensus on how to measure it. This is especially true in representation
learning, where interpretability research has focused on "disentanglement"
measures only applicable to synthetic datasets and not grounded in human
factors. We introduce a task to quantify the human-interpretability of
generative model representations, where users interactively modify
representations to reconstruct target instances. On synthetic datasets, we find
performance on this task much more reliably differentiates entangled and
disentangled models than baseline approaches. On a real dataset, we find it
differentiates between representation learning methods widely believed but
never shown to produce more or less interpretable models. In both cases, we ran
small-scale think-aloud studies and large-scale experiments on Amazon
Mechanical Turk to confirm that our qualitative and quantitative results
agreed.
</p>
<a href="http://arxiv.org/abs/2102.01264" target="_blank">arXiv:2102.01264</a> [<a href="http://arxiv.org/pdf/2102.01264" target="_blank">pdf</a>]

<h2>Predicting student performance using data from an auto-grading system. (arXiv:2102.01270v1 [cs.LG])</h2>
<h3>Huanyi Chen, Paul A.S. Ward</h3>
<p>As online auto-grading systems appear, information obtained from those
systems can potentially enable researchers to create predictive models to
predict student behaviour and performances. In the University of Waterloo, the
ECE 150 (Fundamentals of Programming) Instructional Team wants to get an
insight into how to allocate the limited teaching resources better to achieve
improved educational outcomes. Currently, the Instructional Team allocates
tutoring time in a reactive basis. They help students "as-requested". This
approach serves those students with the wherewithal to request help; however,
many of the students who are struggling do not reach out for assistance.
Therefore, we, as the Research Team, want to explore if we can determine
students which need help by looking into the data from our auto-grading system,
Marmoset.

In this paper, we conducted experiments building decision-tree and
linear-regression models with various features extracted from the Marmoset
auto-grading system, including passing rate, testcase outcomes, number of
submissions and submission time intervals (the time interval between the
student's first reasonable submission and the deadline). For each feature, we
interpreted the result at the confusion matrix level. Specifically for
poor-performance students, we show that the linear-regression model using
submission time intervals performs the best among all models in terms of
Precision and F-Measure. We also show that for students who are misclassified
into poor-performance students, they have the lowest actual grades in the
linear-regression model among all models. In addition, we show that for the
midterm, the submission time interval of the last assignment before the midterm
predicts the midterm performance the most. However, for the final exam, the
midterm performance contributes the most on the final exam performance.
</p>
<a href="http://arxiv.org/abs/2102.01270" target="_blank">arXiv:2102.01270</a> [<a href="http://arxiv.org/pdf/2102.01270" target="_blank">pdf</a>]

<h2>Deep Online Fused Video Stabilization. (arXiv:2102.01279v1 [cs.CV])</h2>
<h3>Zhenmei Shi, Fuhao Shi, Wei-Sheng Lai, Chia-Kai Liang, Yingyu Liang</h3>
<p>We present a deep neural network (DNN) that uses both sensor data (gyroscope)
and image content (optical flow) to stabilize videos through unsupervised
learning. The network fuses optical flow with real/virtual camera pose
histories into a joint motion representation. Next, the LSTM block infers the
new virtual camera pose, and this virtual pose is used to generate a warping
grid that stabilizes the frame. Novel relative motion representation as well as
a multi-stage training process are presented to optimize our model without any
supervision. To the best of our knowledge, this is the first DNN solution that
adopts both sensor data and image for stabilization. We validate the proposed
framework through ablation studies and demonstrated the proposed method
outperforms the state-of-art alternative solutions via quantitative evaluations
and a user study.
</p>
<a href="http://arxiv.org/abs/2102.01279" target="_blank">arXiv:2102.01279</a> [<a href="http://arxiv.org/pdf/2102.01279" target="_blank">pdf</a>]

<h2>Progressive Localization Networks for Language-based Moment Localization. (arXiv:2102.01282v1 [cs.CV])</h2>
<h3>Qi Zheng, Jianfeng Dong, Xiaoye Qu, Xun Yang, Shouling Ji, Xun Wang</h3>
<p>This paper targets the task of language-based moment localization. The
language-based setting of this task allows for an open set of target
activities, resulting in a large variation of the temporal lengths of video
moments. Most existing methods prefer to first sample sufficient candidate
moments with various temporal lengths, and then match them with the given query
to determine the target moment. However, candidate moments generated with a
fixed temporal granularity may be suboptimal to handle the large variation in
moment lengths. To this end, we propose a novel multi-stage Progressive
Localization Network (PLN) which progressively localizes the target moment in a
coarse-to-fine manner. Specifically, each stage of PLN has a localization
branch, and focuses on candidate moments that are generated with a specific
temporal granularity. The temporal granularities of candidate moments are
different across the stages. Moreover, we devise a conditional feature
manipulation module and an upsampling connection to bridge the multiple
localization branches. In this fashion, the later stages are able to absorb the
previously learned information, thus facilitating the more fine-grained
localization. Extensive experiments on three public datasets demonstrate the
effectiveness of our proposed PLN for language-based moment localization and
its potential for localizing short moments in long videos.
</p>
<a href="http://arxiv.org/abs/2102.01282" target="_blank">arXiv:2102.01282</a> [<a href="http://arxiv.org/pdf/2102.01282" target="_blank">pdf</a>]

<h2>Single Model Deep Learning on Imbalanced Small Datasets for Skin Lesion Classification. (arXiv:2102.01284v1 [cs.CV])</h2>
<h3>Peng Yao, Shuwei Shen, Mengjuan Xu, Peng Liu, Fan Zhang, Jinyu Xing, Pengfei Shao, Benjamin Kaffenberger, Ronald X. Xu</h3>
<p>Deep convolutional neural network (DCNN) models have been widely explored for
skin disease diagnosis and some of them have achieved the diagnostic outcomes
comparable or even superior to those of dermatologists. However, broad
implementation of DCNN in skin disease detection is hindered by small size and
data imbalance of the publically accessible skin lesion datasets. This paper
proposes a novel data augmentation strategy for single model classification of
skin lesions based on a small and imbalanced dataset. First, various DCNNs are
trained on this dataset to show that the models with moderate complexity
outperform the larger models. Second, regularization DropOut and DropBlock are
added to reduce overfitting and a Modified RandAugment augmentation strategy is
proposed to address the defects of sample underrepresentation in the small
dataset. Finally, a novel Multi-Weighted Focal Loss function is introduced to
overcome the challenge of uneven sample size and classification difficulty. By
combining Modified RandAugment and Multi-weighted Focal Loss in a single DCNN
model, we have achieved the classification accuracy comparable to those of
multiple ensembling models on the ISIC 2018 challenge test dataset. Our study
shows that this method is able to achieve a high classification performance at
a low cost of computational resources and inference time, potentially suitable
to implement in mobile devices for automated screening of skin lesions and many
other malignancies in low resource settings.
</p>
<a href="http://arxiv.org/abs/2102.01284" target="_blank">arXiv:2102.01284</a> [<a href="http://arxiv.org/pdf/2102.01284" target="_blank">pdf</a>]

<h2>GCF-Net: Gated Clip Fusion Network for Video Action Recognition. (arXiv:2102.01285v1 [cs.CV])</h2>
<h3>Jenhao Hsiao, Jiawei Chen, Chiuman Ho</h3>
<p>In recent years, most of the accuracy gains for video action recognition have
come from the newly designed CNN architectures (e.g., 3D-CNNs). These models
are trained by applying a deep CNN on single clip of fixed temporal length.
Since each video segment are processed by the 3D-CNN module separately, the
corresponding clip descriptor is local and the inter-clip relationships are
inherently implicit. Common method that directly averages the clip-level
outputs as a video-level prediction is prone to fail due to the lack of
mechanism that can extract and integrate relevant information to represent the
video.

In this paper, we introduce the Gated Clip Fusion Network (GCF-Net) that can
greatly boost the existing video action classifiers with the cost of a tiny
computation overhead. The GCF-Net explicitly models the inter-dependencies
between video clips to strengthen the receptive field of local clip
descriptors. Furthermore, the importance of each clip to an action event is
calculated and a relevant subset of clips is selected accordingly for a
video-level analysis. On a large benchmark dataset (Kinetics-600), the proposed
GCF-Net elevates the accuracy of existing action classifiers by 11.49% (based
on central clip) and 3.67% (based on densely sampled clips) respectively.
</p>
<a href="http://arxiv.org/abs/2102.01285" target="_blank">arXiv:2102.01285</a> [<a href="http://arxiv.org/pdf/2102.01285" target="_blank">pdf</a>]

<h2>Detection of Racial Bias from Physiological Responses. (arXiv:2102.01287v1 [cs.AI])</h2>
<h3>Fateme Nikseresht, Runze Yan, Rachel Lew, Yingzheng Liu, Rose M.Sebastian, Afsaneh Doryab</h3>
<p>Despite the evolution of norms and regulations to mitigate the harm from
biases, harmful discrimination linked to an individual's unconscious biases
persists. Our goal is to better understand and detect the physiological and
behavioral indicators of implicit biases. This paper investigates whether we
can reliably detect racial bias from physiological responses, including heart
rate, conductive skin response, skin temperature, and micro-body movements. We
analyzed data from 46 subjects whose physiological data was collected with
Empatica E4 wristband while taking an Implicit Association Test (IAT). Our
machine learning and statistical analysis show that implicit bias can be
predicted from physiological signals with 76.1% accuracy. Our results also show
that the EDA signal associated with skin response has the strongest correlation
with racial bias and that there are significant differences between the values
of EDA features for biased and unbiased participants.
</p>
<a href="http://arxiv.org/abs/2102.01287" target="_blank">arXiv:2102.01287</a> [<a href="http://arxiv.org/pdf/2102.01287" target="_blank">pdf</a>]

<h2>Scaling Laws for Transfer. (arXiv:2102.01293v1 [cs.LG])</h2>
<h3>Danny Hernandez, Jared Kaplan, Tom Henighan, Sam McCandlish</h3>
<p>We study empirical scaling laws for transfer learning between distributions
in an unsupervised, fine-tuning setting. When we train increasingly large
neural networks from-scratch on a fixed-size dataset, they eventually become
data-limited and stop improving in performance (cross-entropy loss). When we do
the same for models pre-trained on a large language dataset, the slope in
performance gains is merely reduced rather than going to zero. We calculate the
effective data "transferred" from pre-training by determining how much data a
transformer of the same size would have required to achieve the same loss when
training from scratch. In other words, we focus on units of data while holding
everything else fixed. We find that the effective data transferred is described
well in the low data regime by a power-law of parameter count and fine-tuning
dataset size. We believe the exponents in these power-laws correspond to
measures of the generality of a model and proximity of distributions (in a
directed rather than symmetric sense). We find that pre-training effectively
multiplies the fine-tuning dataset size. Transfer, like overall performance,
scales predictably in terms of parameters, data, and compute.
</p>
<a href="http://arxiv.org/abs/2102.01293" target="_blank">arXiv:2102.01293</a> [<a href="http://arxiv.org/pdf/2102.01293" target="_blank">pdf</a>]

<h2>Gaze-based dual resolution deep imitation learning for high-precision dexterous robot manipulation. (arXiv:2102.01295v1 [cs.RO])</h2>
<h3>Heecheol Kim, Yoshiyuki Ohmura, Yasuo Kuniyoshi</h3>
<p>A high-precision manipulation task, such as needle threading, is challenging.
Physiological studies have proposed connecting low-resolution peripheral vision
and fast movement to transport the hand into the vicinity of an object, and
using high-resolution foveated vision to achieve the accurate homing of the
hand to the object. The results of this study demonstrate that a deep imitation
learning based method, inspired by the gaze-based dual resolution visuomotor
control system in humans, can solve the needle threading task. First, we
recorded the gaze movements of a human operator who was teleoperating a robot.
Then, we used only a high-resolution image around the gaze to precisely control
the thread position when it was close to the target. We used a low-resolution
peripheral image to reach the vicinity of the target. The experimental results
obtained in this study demonstrate that the proposed method enables precise
manipulation tasks using a general-purpose robot manipulator and improves
computational efficiency.
</p>
<a href="http://arxiv.org/abs/2102.01295" target="_blank">arXiv:2102.01295</a> [<a href="http://arxiv.org/pdf/2102.01295" target="_blank">pdf</a>]

<h2>Reinforcement Learning with Probabilistic Boolean Network Models of Smart Grid Devices. (arXiv:2102.01297v1 [cs.LG])</h2>
<h3>Pedro J. Rivera Torres, Carlos Gershenson Garc&#xed;a, Samir Kanaan Izquierdo</h3>
<p>The area of Smart Power Grids needs to constantly improve its efficiency and
resilience, to pro-vide high quality electrical power, in a resistant grid,
managing faults and avoiding failures. Achieving this requires high component
reliability, adequate maintenance, and a studied failure occurrence. Correct
system operation involves those activities, and novel methodologies to detect,
classify, and isolate faults and failures, model and simulate processes with
predictive algorithms and analytics (using data analysis and asset condition to
plan and perform activities). We show-case the application of a
complex-adaptive, self-organizing modeling method, Probabilistic Boolean
Networks (PBN), as a way towards the understanding of the dynamics of smart
grid devices, and to model and characterize their behavior. This work
demonstrates that PBNs are is equivalent to the standard Reinforcement Learning
Cycle, in which the agent/model has an inter-action with its environment and
receives feedback from it in the form of a reward signal. Differ-ent reward
structures were created in order to characterize preferred behavior. This
information can be used to guide the PBN to avoid fault conditions and
failures.
</p>
<a href="http://arxiv.org/abs/2102.01297" target="_blank">arXiv:2102.01297</a> [<a href="http://arxiv.org/pdf/2102.01297" target="_blank">pdf</a>]

<h2>Learning Crisp Boundaries Using Deep Refinement Network and Adaptive Weighting Loss. (arXiv:2102.01301v1 [cs.CV])</h2>
<h3>Yi-Jun Cao, Chuan Lin, Yong-Jie Li</h3>
<p>Significant progress has been made in boundary detection with the help of
convolutional neural networks. Recent boundary detection models not only focus
on real object boundary detection but also "crisp" boundaries (precisely
localized along the object's contour). There are two methods to evaluate crisp
boundary performance. One uses more strict tolerance to measure the distance
between the ground truth and the detected contour. The other focuses on
evaluating the contour map without any postprocessing. In this study, we
analyze both methods and conclude that both methods are two aspects of crisp
contour evaluation. Accordingly, we propose a novel network named deep
refinement network (DRNet) that stacks multiple refinement modules to achieve
richer feature representation and a novel loss function, which combines
cross-entropy and dice loss through effective adaptive fusion. Experimental
results demonstrated that we achieve state-of-the-art performance for several
available datasets.
</p>
<a href="http://arxiv.org/abs/2102.01301" target="_blank">arXiv:2102.01301</a> [<a href="http://arxiv.org/pdf/2102.01301" target="_blank">pdf</a>]

<h2>Stability and Generalization of the Decentralized Stochastic Gradient Descent. (arXiv:2102.01302v1 [stat.ML])</h2>
<h3>Tao Sun, Dongsheng Li, Bao Wang</h3>
<p>The stability and generalization of stochastic gradient-based methods provide
valuable insights into understanding the algorithmic performance of machine
learning models. As the main workhorse for deep learning, stochastic gradient
descent has received a considerable amount of studies. Nevertheless, the
community paid little attention to its decentralized variants. In this paper,
we provide a novel formulation of the decentralized stochastic gradient
descent. Leveraging this formulation together with (non)convex optimization
theory, we establish the first stability and generalization guarantees for the
decentralized stochastic gradient descent. Our theoretical results are built on
top of a few common and mild assumptions and reveal that the decentralization
deteriorates the stability of SGD for the first time. We verify our theoretical
findings by using a variety of decentralized settings and benchmark machine
learning models.
</p>
<a href="http://arxiv.org/abs/2102.01302" target="_blank">arXiv:2102.01302</a> [<a href="http://arxiv.org/pdf/2102.01302" target="_blank">pdf</a>]

<h2>Tooth Instance Segmentation from Cone-Beam CT Images through Point-based Detection and Gaussian Disentanglement. (arXiv:2102.01315v1 [cs.CV])</h2>
<h3>Jusang Lee, Minyoung Chung, Minkyung Lee, Yeong-Gil Shin</h3>
<p>Individual tooth segmentation and identification from cone-beam computed
tomography images are preoperative prerequisites for orthodontic treatments.
Instance segmentation methods using convolutional neural networks have
demonstrated ground-breaking results on individual tooth segmentation tasks,
and are used in various medical imaging applications. While point-based
detection networks achieve superior results on dental images, it is still a
challenging task to distinguish adjacent teeth because of their similar
topologies and proximate nature. In this study, we propose a point-based tooth
localization network that effectively disentangles each individual tooth based
on a Gaussian disentanglement objective function. The proposed network first
performs heatmap regression accompanied by box regression for all the
anatomical teeth. A novel Gaussian disentanglement penalty is employed by
minimizing the sum of the pixel-wise multiplication of the heatmaps for all
adjacent teeth pairs. Subsequently, individual tooth segmentation is performed
by converting a pixel-wise labeling task to a distance map regression task to
minimize false positives in adjacent regions of the teeth. Experimental results
demonstrate that the proposed algorithm outperforms state-of-the-art approaches
by increasing the average precision of detection by 9.1%, which results in a
high performance in terms of individual tooth segmentation. The primary
significance of the proposed method is two-fold: 1) the introduction of a
point-based tooth detection framework that does not require additional
classification and 2) the design of a novel loss function that effectively
separates Gaussian distributions based on heatmap responses in the point-based
detection framework.
</p>
<a href="http://arxiv.org/abs/2102.01315" target="_blank">arXiv:2102.01315</a> [<a href="http://arxiv.org/pdf/2102.01315" target="_blank">pdf</a>]

<h2>Anomaly Detection of Time Series with Smoothness-Inducing Sequential Variational Auto-Encoder. (arXiv:2102.01331v1 [cs.LG])</h2>
<h3>Longyuan Li, Junchi Yan, Haiyang Wang, Yaohui Jin</h3>
<p>Deep generative models have demonstrated their effectiveness in learning
latent representation and modeling complex dependencies of time series. In this
paper, we present a Smoothness-Inducing Sequential Variational Auto-Encoder
(SISVAE) model for robust estimation and anomaly detection of multi-dimensional
time series. Our model is based on Variational Auto-Encoder (VAE), and its
backbone is fulfilled by a Recurrent Neural Network to capture latent temporal
structures of time series for both generative model and inference model.
Specifically, our model parameterizes mean and variance for each time-stamp
with flexible neural networks, resulting in a non-stationary model that can
work without the assumption of constant noise as commonly made by existing
Markov models. However, such a flexibility may cause the model fragile to
anomalies. To achieve robust density estimation which can also benefit
detection tasks, we propose a smoothness-inducing prior over possible
estimations. The proposed prior works as a regularizer that places penalty at
non-smooth reconstructions. Our model is learned efficiently with a novel
stochastic gradient variational Bayes estimator. In particular, we study two
decision criteria for anomaly detection: reconstruction probability and
reconstruction error. We show the effectiveness of our model on both synthetic
datasets and public real-world benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.01331" target="_blank">arXiv:2102.01331</a> [<a href="http://arxiv.org/pdf/2102.01331" target="_blank">pdf</a>]

<h2>pseudo-Bayesian Neural Networks for detecting Out of Distribution Inputs. (arXiv:2102.01336v1 [cs.LG])</h2>
<h3>Gagandeep Singh, Deepak Mishra</h3>
<p>Conventional Bayesian Neural Networks (BNNs) are known to be capable of
providing multiple outputs for a single input, the variations in which can be
utilised to detect Out of Distribution (OOD) inputs. BNNs are difficult to
train due to their sensitivity towards the choice of priors. To alleviate this
issue, we propose pseudo-BNNs where instead of learning distributions over
weights, we use point estimates and perturb weights at the time of inference.
We modify the cost function of conventional BNNs and use it to learn parameters
for the purpose of injecting right amount of random perturbations to each of
the weights of a neural network with point estimate. In order to effectively
segregate OOD inputs from In Distribution (ID) inputs using multiple outputs,
we further propose two measures, derived from the index of dispersion and
entropy of probability distributions, and combine them with the proposed
pseudo-BNNs. Overall, this combination results in a principled technique to
detect OOD samples at the time of inference. We evaluate our technique on a
wide variety of neural network architectures and image classification datasets.
We observe that our method achieves state of the art results and beats the
related previous work on various metrics such as FPR at 95% TPR, AUROC, AUPR
and Detection Error by just using 2 to 5 samples of weights per input.
</p>
<a href="http://arxiv.org/abs/2102.01336" target="_blank">arXiv:2102.01336</a> [<a href="http://arxiv.org/pdf/2102.01336" target="_blank">pdf</a>]

<h2>Enabling energy efficient machine learning on a Ultra-Low-Power vision sensor for IoT. (arXiv:2102.01340v1 [cs.CV])</h2>
<h3>Francesco Paissan, Massimo Gottardi, Elisabetta Farella</h3>
<p>The Internet of Things (IoT) and smart city paradigm includes ubiquitous
technology to extract context information in order to return useful services to
users and citizens. An essential role in this scenario is often played by
computer vision applications, requiring the acquisition of images from specific
devices. The need for high-end cameras often penalizes this process since they
are power-hungry and ask for high computational resources to be processed.
Thus, the availability of novel low-power vision sensors, implementing advanced
features like in-hardware motion detection, is crucial for computer vision in
the IoT domain. Unfortunately, to be highly energy-efficient, these sensors
might worsen the perception performance (e.g., resolution, frame rate, color).
Therefore, domain-specific pipelines are usually delivered in order to exploit
the full potential of these cameras. This paper presents the development,
analysis, and embedded implementation of a realtime detection, classification
and tracking pipeline able to exploit the full potential of background
filtering Smart Vision Sensors (SVS). The power consumption obtained for the
inference - which requires 8ms - is 7.5 mW.
</p>
<a href="http://arxiv.org/abs/2102.01340" target="_blank">arXiv:2102.01340</a> [<a href="http://arxiv.org/pdf/2102.01340" target="_blank">pdf</a>]

<h2>Benchmarking Quantized Neural Networks on FPGAs with FINN. (arXiv:2102.01341v1 [cs.LG])</h2>
<h3>Quentin Ducasse, Pascal Cotret, Lo&#xef;c Lagadec, Robert Stewart</h3>
<p>The ever-growing cost of both training and inference for state-of-the-art
neural networks has brought literature to look upon ways to cut off resources
used with a minimal impact on accuracy. Using lower precision comes at the cost
of negligible loss in accuracy. While training neural networks may require a
powerful setup, deploying a network must be possible on low-power and
low-resource hardware architectures. Reconfigurable architectures have proven
to be more powerful and flexible than GPUs when looking at a specific
application. This article aims to assess the impact of mixed-precision when
applied to neural networks deployed on FPGAs. While several frameworks exist
that create tools to deploy neural networks using reduced-precision, few of
them assess the importance of quantization and the framework quality. FINN and
Brevitas, two frameworks from Xilinx labs, are used to assess the impact of
quantization on neural networks using 2 to 8 bit precisions and weights with
several parallelization configurations. Equivalent accuracy can be obtained
using lower-precision representation and enough training. However, the
compressed network can be better parallelized allowing the deployed network
throughput to be 62 times faster. The benchmark set up in this work is
available in a public repository (https://github.com/QDucasse/nn benchmark).
</p>
<a href="http://arxiv.org/abs/2102.01341" target="_blank">arXiv:2102.01341</a> [<a href="http://arxiv.org/pdf/2102.01341" target="_blank">pdf</a>]

<h2>Bit Error Tolerance Metrics for Binarized Neural Networks. (arXiv:2102.01344v1 [cs.LG])</h2>
<h3>Sebastian Buschj&#xe4;ger, Jian-Jia Chen, Kuan-Hsun Chen, Mario G&#xfc;nzel, Katharina Morik, Rodion Novkin, Lukas Pfahler, Mikail Yayla</h3>
<p>To reduce the resource demand of neural network (NN) inference systems, it
has been proposed to use approximate memory, in which the supply voltage and
the timing parameters are tuned trading accuracy with energy consumption and
performance. Tuning these parameters aggressively leads to bit errors, which
can be tolerated by NNs when bit flips are injected during training. However,
bit flip training, which is the state of the art for achieving bit error
tolerance, does not scale well; it leads to massive overheads and cannot be
applied for high bit error rates (BERs). Alternative methods to achieve bit
error tolerance in NNs are needed, but the underlying principles behind the bit
error tolerance of NNs have not been reported yet. With this lack of
understanding, further progress in the research on NN bit error tolerance will
be restrained.

In this study, our objective is to investigate the internal changes in the
NNs that bit flip training causes, with a focus on binarized NNs (BNNs). To
this end, we quantify the properties of bit error tolerant BNNs with two
metrics. First, we propose a neuron-level bit error tolerance metric, which
calculates the margin between the pre-activation values and batch normalization
thresholds. Secondly, to capture the effects of bit error tolerance on the
interplay of neurons, we propose an inter-neuron bit error tolerance metric,
which measures the importance of each neuron and computes the variance over all
importance values. Our experimental results support that these two metrics are
strongly related to bit error tolerance.
</p>
<a href="http://arxiv.org/abs/2102.01344" target="_blank">arXiv:2102.01344</a> [<a href="http://arxiv.org/pdf/2102.01344" target="_blank">pdf</a>]

<h2>Fast Exploration of Weight Sharing Opportunities for CNN Compression. (arXiv:2102.01345v1 [cs.LG])</h2>
<h3>Etienne Dupuis, David Novo, Ian O&#x27;Connor, Alberto Bosio</h3>
<p>The computational workload involved in Convolutional Neural Networks (CNNs)
is typically out of reach for low-power embedded devices. There are a large
number of approximation techniques to address this problem. These methods have
hyper-parameters that need to be optimized for each CNNs using design space
exploration (DSE). The goal of this work is to demonstrate that the DSE phase
time can easily explode for state of the art CNN. We thus propose the use of an
optimized exploration process to drastically reduce the exploration time
without sacrificing the quality of the output.
</p>
<a href="http://arxiv.org/abs/2102.01345" target="_blank">arXiv:2102.01345</a> [<a href="http://arxiv.org/pdf/2102.01345" target="_blank">pdf</a>]

<h2>Modular approach to data preprocessing in ALOHA and application to a smart industry use case. (arXiv:2102.01349v1 [cs.AI])</h2>
<h3>Cristina Chesta, Luca Rinelli</h3>
<p>Applications in the smart industry domain, such as interaction with
collaborative robots using vocal commands or machine vision systems often
requires the deployment of deep learning algorithms on heterogeneous low power
computing platforms. The availability of software tools and frameworks to
automatize different design steps can support the effective implementation of
DL algorithms on embedded systems, reducing related effort and costs. One very
important aspect for the acceptance of the framework, is its extensibility,
i.e. the capability to accommodate different datasets and define customized
preprocessing, without requiring advanced skills. The paper addresses a modular
approach, integrated into the ALOHA tool flow, to support the data
preprocessing and transformation pipeline. This is realized through
customizable plugins and allows the easy extension of the tool flow to
encompass new use cases. To demonstrate the effectiveness of the approach, we
present some experimental results related to a keyword spotting use case and we
outline possible extensions to different use cases.
</p>
<a href="http://arxiv.org/abs/2102.01349" target="_blank">arXiv:2102.01349</a> [<a href="http://arxiv.org/pdf/2102.01349" target="_blank">pdf</a>]

<h2>Graph Coarsening with Neural Networks. (arXiv:2102.01350v1 [cs.LG])</h2>
<h3>Chen Cai, Dingkang Wang, Yusu Wang</h3>
<p>As large-scale graphs become increasingly more prevalent, it poses
significant computational challenges to process, extract and analyze large
graph data. Graph coarsening is one popular technique to reduce the size of a
graph while maintaining essential properties. Despite rich graph coarsening
literature, there is only limited exploration of data-driven methods in the
field. In this work, we leverage the recent progress of deep learning on graphs
for graph coarsening. We first propose a framework for measuring the quality of
coarsening algorithm and show that depending on the goal, we need to carefully
choose the Laplace operator on the coarse graph and associated projection/lift
operators. Motivated by the observation that the current choice of edge weight
for the coarse graph may be sub-optimal, we parametrize the weight assignment
map with graph neural networks and train it to improve the coarsening quality
in an unsupervised way. Through extensive experiments on both synthetic and
real networks, we demonstrate that our method significantly improves common
graph coarsening methods under various metrics, reduction ratios, graph sizes,
and graph types. It generalizes to graphs of larger size ($25\times$ of
training graphs), is adaptive to different losses (differentiable and
non-differentiable), and scales to much larger graphs than previous work.
</p>
<a href="http://arxiv.org/abs/2102.01350" target="_blank">arXiv:2102.01350</a> [<a href="http://arxiv.org/pdf/2102.01350" target="_blank">pdf</a>]

<h2>Hardware-efficient Residual Networks for FPGAs. (arXiv:2102.01351v1 [cs.CV])</h2>
<h3>Olivia Weng, Alireza Khodamoradi, Ryan Kastner</h3>
<p>Residual networks (ResNets) employ skip connections in their networks --
reusing activations from previous layers -- to improve training convergence,
but these skip connections create challenges for hardware implementations of
ResNets. The hardware must either wait for skip connections to be processed
before processing more incoming data or buffer them elsewhere. Without skip
connections, ResNets would be more hardware-efficient. Thus, we present the
teacher-student learning method to gradually prune away all of a ResNet's skip
connections, constructing a network we call NonResNet. We show that when
implemented for FPGAs, NonResNet decreases ResNet's BRAM utilization by 9% and
LUT utilization by 3% and increases throughput by 5%.
</p>
<a href="http://arxiv.org/abs/2102.01351" target="_blank">arXiv:2102.01351</a> [<a href="http://arxiv.org/pdf/2102.01351" target="_blank">pdf</a>]

<h2>Subdimensional Expansion for Multi-objective Multi-agent Path Finding. (arXiv:2102.01353v1 [cs.RO])</h2>
<h3>Zhongqiang Ren, Sivakumar Rathinam, Howie Choset</h3>
<p>Conventional multi-agent path planners typically determine a path that
optimizes a single objective, such as path length. Many applications, however,
may require multiple objectives, say time-to-completion and fuel use, to be
simultaneously optimized in the planning process. Often, these criteria may not
be readily compared and sometimes lie in competition with each other. Simply
applying standard multi-objective search algorithms to multi-agent path finding
may prove to be inefficient because the size of the space of possible
solutions, i.e., the Pareto-optimal set, can grow exponentially with the number
of agents (the dimension of the search space). This paper presents an approach
that bypasses this so-called curse of dimensionality by leveraging our prior
multi-agent work with a framework called subdimensional expansion. One example
of subdimensional expansion, when applied to A*, is called M* and M* was
limited to a single objective function. We combine principles of dominance and
subdimensional expansion to create a new algorithm named multi-objective M*
(MOM*), which dynamically couples agents for planning only when those agents
have to "interact" with each other. MOM* computes the complete Pareto-optimal
set for multiple agents efficiently and naturally trades off sub-optimal
approximations of the Pareto-optimal set and computational efficiency. Our
approach is able to find the complete Pareto-optimal set for problem instances
with hundreds of solutions which the standard multi-objective A* algorithms
could not find within a bounded time.
</p>
<a href="http://arxiv.org/abs/2102.01353" target="_blank">arXiv:2102.01353</a> [<a href="http://arxiv.org/pdf/2102.01353" target="_blank">pdf</a>]

<h2>Mining Feature Relationships in Data. (arXiv:2102.01355v1 [cs.LG])</h2>
<h3>Andrew Lensen</h3>
<p>When faced with a new dataset, most practitioners begin by performing
exploratory data analysis to discover interesting patterns and characteristics
within data. Techniques such as association rule mining are commonly applied to
uncover relationships between features (attributes) of the data. However,
association rules are primarily designed for use on binary or categorical data,
due to their use of rule-based machine learning. A large proportion of
real-world data is continuous in nature, and discretisation of such data leads
to inaccurate and less informative association rules. In this paper, we propose
an alternative approach called feature relationship mining (FRM), which uses a
genetic programming approach to automatically discover symbolic relationships
between continuous or categorical features in data. To the best of our
knowledge, our proposed approach is the first such symbolic approach with the
goal of explicitly discovering relationships between features. Empirical
testing on a variety of real-world datasets shows the proposed method is able
to find high-quality, simple feature relationships which can be easily
interpreted and which provide clear and non-trivial insight into data.
</p>
<a href="http://arxiv.org/abs/2102.01355" target="_blank">arXiv:2102.01355</a> [<a href="http://arxiv.org/pdf/2102.01355" target="_blank">pdf</a>]

<h2>Recent Advances in Adversarial Training for Adversarial Robustness. (arXiv:2102.01356v1 [cs.LG])</h2>
<h3>Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen</h3>
<p>Adversarial examples for fooling deep learning models have been studied for
several years and are still a hot topic. Adversarial training also receives
enormous attention because of its effectiveness in defending adversarial
examples. However, adversarial training is not perfect, many questions of which
remain to solve. During the last few years, researchers in this community have
studied and discussed adversarial training from various aspects. Many new
theories and understandings of adversarial training have been proposed. In this
survey, we systematically review the recent progress on adversarial training
for the first time, categorized by different improvements. Then we discuss the
generalization problems in adversarial training from three perspectives.
Finally, we highlight the challenges which are not fully solved and present
potential future directions.
</p>
<a href="http://arxiv.org/abs/2102.01356" target="_blank">arXiv:2102.01356</a> [<a href="http://arxiv.org/pdf/2102.01356" target="_blank">pdf</a>]

<h2>Test-Time Adaptation for Out-of-distributed Image Inpainting. (arXiv:2102.01360v1 [cs.CV])</h2>
<h3>Chajin Shin, Taeoh Kim, Sangjin Lee, Sangyoun Lee</h3>
<p>Deep learning-based image inpainting algorithms have shown great performance
via powerful learned prior from the numerous external natural images. However,
they show unpleasant results on the test image whose distribution is far from
the that of training images because their models are biased toward the training
images. In this paper, we propose a simple image inpainting algorithm with
test-time adaptation named AdaFill. Given a single out-of-distributed test
image, our goal is to complete hole region more naturally than the pre-trained
inpainting models. To achieve this goal, we treat remained valid regions of the
test image as another training cues because natural images have strong internal
similarities. From this test-time adaptation, our network can exploit
externally learned image priors from the pre-trained features as well as the
internal prior of the test image explicitly. Experimental results show that
AdaFill outperforms other models on the various out-of-distribution test
images. Furthermore, the model named ZeroFill, that are not pre-trained also
sometimes outperforms the pre-trained models.
</p>
<a href="http://arxiv.org/abs/2102.01360" target="_blank">arXiv:2102.01360</a> [<a href="http://arxiv.org/pdf/2102.01360" target="_blank">pdf</a>]

<h2>Leveraging IoT and Weather Conditions to Estimate the Riders Waiting for the Bus Transit on Campus. (arXiv:2102.01364v1 [cs.LG])</h2>
<h3>Ismail Arai, Ahmed Elnoshokaty, Samy El-Tawab</h3>
<p>The communication technology revolution in this era has increased the use of
smartphones in the world of transportation. In this paper, we propose to
leverage IoT device data, capturing passengers' smartphones' Wi-Fi data in
conjunction with weather conditions to predict the expected number of
passengers waiting at a bus stop at a specific time using deep learning models.
Our study collected data from the transit bus system at James Madison
University (JMU) in Virginia, USA. This paper studies the correlation between
the number of passengers waiting at bus stops and weather conditions.
Empirically, an experiment with several bus stops in JMU, was utilized to
confirm a high precision level. We compared our Deep Neural Network (DNN) model
against two baseline models: Linear Regression (LR) and a Wide Neural Network
(WNN). The gap between the baseline models and DNN was 35% and 14% better Mean
Squared Error (MSE) scores for predictions in favor of the DNN compared to LR
and WNN, respectively.
</p>
<a href="http://arxiv.org/abs/2102.01364" target="_blank">arXiv:2102.01364</a> [<a href="http://arxiv.org/pdf/2102.01364" target="_blank">pdf</a>]

<h2>Federated Learning in Smart Cities: A Comprehensive Survey. (arXiv:2102.01375v1 [cs.LG])</h2>
<h3>Zhaohua Zheng, Yize Zhou, Yilong Sun, Zhang Wang, Boyi Liu, Keqiu Li</h3>
<p>Federated learning plays an important role in the process of smart cities.
With the development of big data and artificial intelligence, there is a
problem of data privacy protection in this process. Federated learning is
capable of solving this problem. This paper starts with the current
developments of federated learning and its applications in various fields. We
conduct a comprehensive investigation. This paper summarize the latest research
on the application of federated learning in various fields of smart cities.
In-depth understanding of the current development of federated learning from
the Internet of Things, transportation, communications, finance, medical and
other fields. Before that, we introduce the background, definition and key
technologies of federated learning. Further more, we review the key
technologies and the latest results. Finally, we discuss the future
applications and research directions of federated learning in smart cities.
</p>
<a href="http://arxiv.org/abs/2102.01375" target="_blank">arXiv:2102.01375</a> [<a href="http://arxiv.org/pdf/2102.01375" target="_blank">pdf</a>]

<h2>Facial Manipulation Detection Based on the Color Distribution Analysis in Edge Region. (arXiv:2102.01381v1 [cs.CV])</h2>
<h3>Dong-Keon Kim, DongHee Kim, Kwangsu Kim</h3>
<p>In this work, we present a generalized and robust facial manipulation
detection method based on color distribution analysis of the vertical region of
edge in a manipulated image. Most of the contemporary facial manipulation
method involves pixel correction procedures for reducing awkwardness of pixel
value differences along the facial boundary in a synthesized image. For this
procedure, there are distinctive differences in the facial boundary between
face manipulated image and unforged natural image. Also, in the forged image,
there should be distinctive and unnatural features in the gap distribution
between facial boundary and background edge region because it tends to damage
the natural effect of lighting. We design the neural network for detecting
face-manipulated image with these distinctive features in facial boundary and
background edge. Our extensive experiments show that our method outperforms
other existing face manipulation detection methods on detecting synthesized
face image in various datasets regardless of whether it has participated in
training.
</p>
<a href="http://arxiv.org/abs/2102.01381" target="_blank">arXiv:2102.01381</a> [<a href="http://arxiv.org/pdf/2102.01381" target="_blank">pdf</a>]

<h2>Stability-Constrained Markov Decision Processes Using MPC. (arXiv:2102.01383v1 [cs.LG])</h2>
<h3>Mario Zanon, S&#xe9;bastien Gros, Michele Palladino</h3>
<p>In this paper, we consider solving discounted Markov Decision Processes
(MDPs) under the constraint that the resulting policy is stabilizing. In
practice MDPs are solved based on some form of policy approximation. We will
leverage recent results proposing to use Model Predictive Control (MPC) as a
structured policy in the context of Reinforcement Learning to make it possible
to introduce stability requirements directly inside the MPC-based policy. This
will restrict the solution of the MDP to stabilizing policies by construction.
The stability theory for MPC is most mature for the undiscounted MPC case.
Hence, we will first show in this paper that stable discounted MDPs can be
reformulated as undiscounted ones. This observation will entail that the
MPC-based policy with stability requirements will produce the optimal policy
for the discounted MDP if it is stable, and the best stabilizing policy
otherwise.
</p>
<a href="http://arxiv.org/abs/2102.01383" target="_blank">arXiv:2102.01383</a> [<a href="http://arxiv.org/pdf/2102.01383" target="_blank">pdf</a>]

<h2>AutoFreeze: Automatically Freezing Model Blocks to Accelerate Fine-tuning. (arXiv:2102.01386v1 [cs.LG])</h2>
<h3>Yuhan Liu, Saurabh Agarwal, Shivaram Venkataraman</h3>
<p>With the rapid adoption of machine learning (ML), a number of domains now use
the approach of fine-tuning models pre-trained on a large corpus of data.
However, our experiments show that even fine-tuning on models like BERT can
take many hours when using GPUs. While prior work proposes limiting the number
of layers that are fine-tuned, e.g., freezing all layers but the last layer, we
find that such static approaches lead to reduced accuracy. We propose,
AutoFreeze, a system that uses an adaptive approach to choose which layers are
trained and show how this can accelerate model fine-tuning while preserving
accuracy. We also develop mechanisms to enable efficient caching of
intermediate activations which can reduce the forward computation time when
performing fine-tuning. Our evaluation on fourNLP tasks shows that AutoFreeze,
with caching enabled, can improve fine-tuning performance by up to 2.55x.
</p>
<a href="http://arxiv.org/abs/2102.01386" target="_blank">arXiv:2102.01386</a> [<a href="http://arxiv.org/pdf/2102.01386" target="_blank">pdf</a>]

<h2>Bayesian Neural Networks for Virtual Flow Metering: An Empirical Study. (arXiv:2102.01391v1 [cs.LG])</h2>
<h3>Bjarne Grimstad, Mathilde Hotvedt, Anders T. Sandnes, Odd Kolbj&#xf8;rnsen, Lars S. Imsland</h3>
<p>Recent works have presented promising results from the application of machine
learning (ML) to the modeling of flow rates in oil and gas wells. The
encouraging results combined with advantageous properties of ML models, such as
computationally cheap evaluation and ease of calibration to new data, have
sparked optimism for the development of data-driven virtual flow meters (VFMs).
We contribute to this development by presenting a probabilistic VFM based on a
Bayesian neural network. We consider homoscedastic and heteroscedastic
measurement noise, and show how to train the models using maximum a posteriori
estimation and variational inference. We study the methods by modeling on a
large and heterogeneous dataset, consisting of 60 wells across five different
oil and gas assets. The predictive performance is analyzed on historical and
future test data, where we achieve an average error of 5-6% and 9-13% for the
50% best performing models, respectively. Variational inference appears to
provide more robust predictions than the reference approach on future data. The
difference in prediction performance and uncertainty on historical and future
data is explored in detail, and the findings motivate the development of
alternative strategies for data-driven VFM.
</p>
<a href="http://arxiv.org/abs/2102.01391" target="_blank">arXiv:2102.01391</a> [<a href="http://arxiv.org/pdf/2102.01391" target="_blank">pdf</a>]

<h2>It's always personal: Using Early Exits for Efficient On-Device CNN Personalisation. (arXiv:2102.01393v1 [cs.LG])</h2>
<h3>Ilias Leontiadis, Stefanos Laskaridis, Stylianos I. Venieris, Nicholas D. Lane</h3>
<p>On-device machine learning is becoming a reality thanks to the availability
of powerful hardware and model compression techniques. Typically, these models
are pretrained on large GPU clusters and have enough parameters to generalise
across a wide variety of inputs. In this work, we observe that a much smaller,
personalised model can be employed to fit a specific scenario, resulting in
both higher accuracy and faster execution. Nevertheless, on-device training is
extremely challenging, imposing excessive computational and memory requirements
even for flagship smartphones. At the same time, on-device data availability
might be limited and samples are most frequently unlabelled. To this end, we
introduce PersEPhonEE, a framework that attaches early exits on the model and
personalises them on-device. These allow the model to progressively bypass a
larger part of the computation as more personalised data become available.
Moreover, we introduce an efficient on-device algorithm that trains the early
exits in a semi-supervised manner at a fraction of the whole network's
personalisation time. Results show that PersEPhonEE boosts accuracy by up to
15.9% while dropping the training cost by up to 2.2x and inference latency by
2.2-3.2x on average for the same accuracy, depending on the availability of
labels on-device.
</p>
<a href="http://arxiv.org/abs/2102.01393" target="_blank">arXiv:2102.01393</a> [<a href="http://arxiv.org/pdf/2102.01393" target="_blank">pdf</a>]

<h2>Unassisted Noise Reduction of Chemical Reaction Data Sets. (arXiv:2102.01399v1 [cs.LG])</h2>
<h3>Alessandra Toniato, Philippe Schwaller, Antonio Cardinale, Joppe Geluykens, Teodoro Laino</h3>
<p>Existing deep learning models applied to reaction prediction in organic
chemistry can reach high levels of accuracy (&gt; 90% for Natural Language
Processing-based ones). With no chemical knowledge embedded than the
information learnt from reaction data, the quality of the data sets plays a
crucial role in the performance of the prediction models. While human curation
is prohibitively expensive, the need for unaided approaches to remove
chemically incorrect entries from existing data sets is essential to improve
artificial intelligence models' performance in synthetic chemistry tasks. Here
we propose a machine learning-based, unassisted approach to remove chemically
wrong entries from chemical reaction collections. We applied this method to the
collection of chemical reactions Pistachio and to an open data set, both
extracted from USPTO (United States Patent Office) patents. Our results show an
improved prediction quality for models trained on the cleaned and balanced data
sets. For the retrosynthetic models, the round-trip accuracy metric grows by 13
percentage points and the value of the cumulative Jensen Shannon divergence
decreases by 30% compared to its original record. The coverage remains high
with 97%, and the value of the class-diversity is not affected by the cleaning.
The proposed strategy is the first unassisted rule-free technique to address
automatic noise reduction in chemical data sets.
</p>
<a href="http://arxiv.org/abs/2102.01399" target="_blank">arXiv:2102.01399</a> [<a href="http://arxiv.org/pdf/2102.01399" target="_blank">pdf</a>]

<h2>Face Recognition Using $Sf_{3}CNN$ With Higher Feature Discrimination. (arXiv:2102.01404v1 [cs.CV])</h2>
<h3>Nayaneesh Kumar Mishra, Satish Kumar Singh</h3>
<p>With the advent of 2-dimensional Convolution Neural Networks (2D CNNs), the
face recognition accuracy has reached above 99%. However, face recognition is
still a challenge in real world conditions. A video, instead of an image, as an
input can be more useful to solve the challenges of face recognition in real
world conditions. This is because a video provides more features than an image.
However, 2D CNNs cannot take advantage of the temporal features present in the
video. We therefore, propose a framework called $Sf_{3}CNN$ for face
recognition in videos. The $Sf_{3}CNN$ framework uses 3-dimensional Residual
Network (3D Resnet) and A-Softmax loss for face recognition in videos. The use
of 3D ResNet helps to capture both spatial and temporal features into one
compact feature map. However, the 3D CNN features must be highly discriminative
for efficient face recognition. The use of A-Softmax loss helps to extract
highly discriminative features from the video for face recognition. $Sf_{3}CNN$
framework gives an increased accuracy of 99.10% on CVBL video database in
comparison to the previous 97% on the same database using 3D ResNets.
</p>
<a href="http://arxiv.org/abs/2102.01404" target="_blank">arXiv:2102.01404</a> [<a href="http://arxiv.org/pdf/2102.01404" target="_blank">pdf</a>]

<h2>AURSAD: Universal Robot Screwdriving Anomaly Detection Dataset. (arXiv:2102.01409v1 [cs.LG])</h2>
<h3>B&#x142;a&#x17c;ej Leporowski, Daniella Tola, Casper Hansen, Alexandros Iosifidis</h3>
<p>Screwdriving is one of the most popular industrial processes. As such, it is
increasingly common to automate that procedure by using various robots. Even
though the automation increases the efficiency of the screwdriving process, if
the process is not monitored correctly, faults may occur during operation,
which can impact the effectiveness and quality of assembly. Machine Learning
(ML) has the potential to detect those undesirable events and limit their
impact. In order to do so, first a dataset that fully describes the operation
of an industrial robot performing automated screwdriving must be available.

This report describes a dataset created using a UR3e series robot and OnRobot
Screwdriver. We create different scenarios and introduce 3 types of anomalies
to the process while all available robot and screwdriver sensors are
continuously recorded. The resulting data contains 2042 samples of normal and
anomalous robot operation. Brief ML benchmarks using this data are also
provided, showcasing the data's suitability and potential for further analysis
and experimentation.
</p>
<a href="http://arxiv.org/abs/2102.01409" target="_blank">arXiv:2102.01409</a> [<a href="http://arxiv.org/pdf/2102.01409" target="_blank">pdf</a>]

<h2>Vision Based Autonomous UAV Plane Estimation And Following for Building Inspection. (arXiv:2102.01423v1 [cs.RO])</h2>
<h3>Yang Lyu, Muqing Cao, Shenghai Yuan, Lihua Xie</h3>
<p>Unmanned Aerial Vehicle (UAV) has already demonstrated its potential in many
civilian applications, and the fa\c{c}ade inspection is among the most
promising ones. In this paper, we focus on enabling the autonomous perception
and control of a small UAV for a fa\c{c}ade inspection task. Specifically, we
consider the perception as a planar object pose estimation problem by
simplifying the building structure as concatenation of planes, and the control
as an optimal reference tracking control problem. First, a vision based
adaptive observer is proposed which can realize stable plane pose estimation
under very mild observation conditions. Second, a model predictive controller
is designed to achieve stable tracking and smooth transition in a multi-plane
scenario, while the persistent excitation (PE) condition of the observer and
the maneuver constraints of the UAV are satisfied. The proposed autonomous
plane pose estimation and plane tracking methods are tested in both simulation
and practical building fas\c{c}ade inspection scenarios, which demonstrate
their effectiveness and practicability.
</p>
<a href="http://arxiv.org/abs/2102.01423" target="_blank">arXiv:2102.01423</a> [<a href="http://arxiv.org/pdf/2102.01423" target="_blank">pdf</a>]

<h2>Clustering with Penalty for Joint Occurrence of Objects: Computational Aspects. (arXiv:2102.01424v1 [cs.AI])</h2>
<h3>Ond&#x159;ej Sokol, Vladim&#xed;r Hol&#xfd;</h3>
<p>The method of Hol\'y, Sokol and \v{C}ern\'y (Applied Soft Computing, 2017,
Vol. 60, p. 752-762) clusters objects based on their incidence in a large
number of given sets. The idea is to minimize the occurrence of multiple
objects from the same cluster in the same set. In the current paper, we study
computational aspects of the method. First, we prove that the problem of
finding the optimal clustering is NP-hard. Second, to numerically find a
suitable clustering, we propose to use the genetic algorithm augmented by a
renumbering procedure, a fast task-specific local search heuristic and an
initial solution based on a simplified model. Third, in a simulation study, we
demonstrate that our improvements of the standard genetic algorithm
significantly enhance its computational performance.
</p>
<a href="http://arxiv.org/abs/2102.01424" target="_blank">arXiv:2102.01424</a> [<a href="http://arxiv.org/pdf/2102.01424" target="_blank">pdf</a>]

<h2>Graph Classification Based on Skeleton and Component Features. (arXiv:2102.01428v1 [cs.LG])</h2>
<h3>Xue Liu, Wei Wei, Xiangnan Feng, Xiaobo Cao, Dan Sun</h3>
<p>Most existing popular methods for learning graph embedding only consider
fixed-order global structural features and lack structures hierarchical
representation. To address this weakness, we propose a novel graph embedding
algorithm named GraphCSC that realizes classification based on skeleton
information using fixed-order structures learned in anonymous random walks
manner, and component information using different size subgraphs. Two graphs
are similar if their skeletons and components are both similar, thus in our
model, we integrate both of them together into embeddings as graph homogeneity
characterization. We demonstrate our model on different datasets in comparison
with a comprehensive list of up-to-date state-of-the-art baselines, and
experiments show that our work is superior in real-world graph classification
tasks.
</p>
<a href="http://arxiv.org/abs/2102.01428" target="_blank">arXiv:2102.01428</a> [<a href="http://arxiv.org/pdf/2102.01428" target="_blank">pdf</a>]

<h2>Predicting the Time Until a Vehicle Changes the Lane Using LSTM-based Recurrent Neural Networks. (arXiv:2102.01431v1 [cs.LG])</h2>
<h3>Florian Wirthm&#xfc;ller, Marvin Klimke, Julian Schlechtriemen, Jochen Hipp, Manfred Reichert</h3>
<p>To plan safe and comfortable trajectories for automated vehicles on highways,
accurate predictions of traffic situations are needed. So far, a lot of
research effort has been spent on detecting lane change maneuvers rather than
on estimating the point in time a lane change actually happens. In practice,
however, this temporal information might be even more useful. This paper deals
with the development of a system that accurately predicts the time to the next
lane change of surrounding vehicles on highways using long short-term
memory-based recurrent neural networks. An extensive evaluation based on a
large real-world data set shows that our approach is able to make reliable
predictions, even in the most challenging situations, with a root mean squared
error around 0.7 seconds. Already 3.5 seconds prior to lane changes the
predictions become highly accurate, showing a median error of less than 0.25
seconds. In summary, this article forms a fundamental step towards downstreamed
highly accurate position predictions.
</p>
<a href="http://arxiv.org/abs/2102.01431" target="_blank">arXiv:2102.01431</a> [<a href="http://arxiv.org/pdf/2102.01431" target="_blank">pdf</a>]

<h2>Robust data-driven discovery of partial differential equations with time-dependent coefficients. (arXiv:2102.01432v1 [stat.ML])</h2>
<h3>Aoxue Chen, Guang Lin</h3>
<p>In this work, we propose a robust Bayesian sparse learning algorithm based on
Bayesian group Lasso with spike and slab priors for the discovery of partial
differential equations with variable coefficients. Using the samples draw from
the posterior distribution with a Gibbs sampler, we are able to estimate the
values of coefficients, together with their standard errors and confidence
intervals. Apart from constructing the error bars, uncertainty quantification
can also be employed for designing new criteria of model selection and
threshold setting. This enables our method more adjustable and robust in
learning equations with time-dependent coefficients. Three criteria are
introduced for model selection and threshold setting to identify the correct
terms: the root mean square, total error bar, and group error bar. Moreover,
three noise filters are integrated with the robust Bayesian sparse learning
algorithm for better results with larger noise. Numerical results demonstrate
that our method is more robust than sequential grouped threshold ridge
regression and group Lasso in noisy situations through three examples.
</p>
<a href="http://arxiv.org/abs/2102.01432" target="_blank">arXiv:2102.01432</a> [<a href="http://arxiv.org/pdf/2102.01432" target="_blank">pdf</a>]

<h2>Model-Predictive Control of Blood Suction for Surgical Hemostasis using Differentiable Fluid Simulations. (arXiv:2102.01436v1 [cs.RO])</h2>
<h3>Jingbin Huang, Fei Liu, Florian Richter, Michael C. Yip</h3>
<p>Recent developments in surgical robotics have led to new advancements in the
automation of surgical sub-tasks such as suturing, soft tissue manipulation,
tissue tensioning and cutting. However, integration of dynamics to optimize
these control policies for the variety of scenes encountered in surgery remains
unsolved. Towards this effort, we investigate the integration of differentiable
fluid dynamics to optimizing a suction tool's trajectory to clear the surgical
field from blood as fast as possible. The fully differentiable fluid dynamics
is integrated with a novel suction model for effective model predictive control
of the tool. The differentiability of the fluid model is crucial because we
utilize the gradients of the fluid states with respect to the suction tool
position to optimize the trajectory. Through a series of experiments, we
demonstrate how, by incorporating fluid models, the trajectories generated by
our method can perform as good as or better than handcrafted human-intuitive
suction policies. We also show that our method is adaptable and can work in
different cavity conditions while using a single handcrafted strategy fails.
</p>
<a href="http://arxiv.org/abs/2102.01436" target="_blank">arXiv:2102.01436</a> [<a href="http://arxiv.org/pdf/2102.01436" target="_blank">pdf</a>]

<h2>Face Recognition using 3D CNNs. (arXiv:2102.01441v1 [cs.CV])</h2>
<h3>Nayaneesh Kumar Mishra, Satish Kumar Singh</h3>
<p>The area of face recognition is one of the most widely researched areas in
the domain of computer vision and biometric. This is because, the non-intrusive
nature of face biometric makes it comparatively more suitable for application
in area of surveillance at public places such as airports. The application of
primitive methods in face recognition could not give very satisfactory
performance. However, with the advent of machine and deep learning methods and
their application in face recognition, several major breakthroughs were
obtained. The use of 2D Convolution Neural networks(2D CNN) in face recognition
crossed the human face recognition accuracy and reached to 99%. Still, robust
face recognition in the presence of real world conditions such as variation in
resolution, illumination and pose is a major challenge for researchers in face
recognition. In this work, we used video as input to the 3D CNN architectures
for capturing both spatial and time domain information from the video for face
recognition in real world environment. For the purpose of experimentation, we
have developed our own video dataset called CVBL video dataset. The use of 3D
CNN for face recognition in videos shows promising results with DenseNets
performing the best with an accuracy of 97% on CVBL dataset.
</p>
<a href="http://arxiv.org/abs/2102.01441" target="_blank">arXiv:2102.01441</a> [<a href="http://arxiv.org/pdf/2102.01441" target="_blank">pdf</a>]

<h2>Drift Estimation with Graphical Models. (arXiv:2102.01458v1 [cs.LG])</h2>
<h3>Luigi Riso, Marco Guerzoni</h3>
<p>This paper deals with the issue of concept drift in supervised machine
learn-ing. We make use of graphical models to elicit the visible structure of
the dataand we infer from there changes in the hidden context. Differently from
previous concept-drift detection methods, this application does not depend on
the supervised machine learning model in use for a specific target variable,
but it tries to assess the concept drift as independent characteristic of the
evolution of a dataset. Specifically, we investigate how a graphical model
evolves by looking at the creation of new links and the disappearing of
existing ones in different time periods. The paper suggests a method that
highlights the changes and eventually produce a metric to evaluate the
stability over time. The paper evaluate the method with real world data on the
Australian Electric market.
</p>
<a href="http://arxiv.org/abs/2102.01458" target="_blank">arXiv:2102.01458</a> [<a href="http://arxiv.org/pdf/2102.01458" target="_blank">pdf</a>]

<h2>Learning to Segment Human Body Parts with Synthetically Trained Deep Convolutional Networks. (arXiv:2102.01460v1 [cs.CV])</h2>
<h3>Alessandro Saviolo, Matteo Bonotto, Daniele Evangelista, Marco Imperoli, Emanuele Menegatti, Alberto Pretto</h3>
<p>This paper presents a new framework for human body part segmentation based on
Deep Convolutional Neural Networks trained using only synthetic data. The
proposed approach achieves cutting-edge results without the need of training
the models with real annotated data of human body parts. Our contributions
include a data generation pipeline, that exploits a game engine for the
creation of the synthetic data used for training the network, and a novel
pre-processing module, that combines edge response map and adaptive histogram
equalization to guide the network to learn the shape of the human body parts
ensuring robustness to changes in the illumination conditions. For selecting
the best candidate architecture, we performed exhaustive tests on
manually-annotated images of real human body limbs. We further present an
ablation study to validate our pre-processing module. The results show that our
method outperforms several state-of-the-art semantic segmentation networks by a
large margin. We release an implementation of the proposed approach along with
the acquired datasets with this paper.
</p>
<a href="http://arxiv.org/abs/2102.01460" target="_blank">arXiv:2102.01460</a> [<a href="http://arxiv.org/pdf/2102.01460" target="_blank">pdf</a>]

<h2>Individual dynamic prediction of clinical endpoint from large dimensional longitudinal biomarker history: a landmark approach. (arXiv:2102.01466v1 [stat.ML])</h2>
<h3>Anthony Devaux (BPH), Robin Genuer (BPH, SISTM), Karine P&#xe9;r&#xe8;s (BPH), C&#xe9;cile Proust-Lima (BPH)</h3>
<p>The individual data collected throughout patient follow-up constitute crucial
information for assessing the risk of a clinical event, and eventually for
adapting a therapeutic strategy. Joint models and landmark models have been
proposed to compute individual dynamic predictions from repeated measures to
one or two markers. However, they hardly extend to the case where the complete
patient history includes much more repeated markers possibly. Our objective was
thus to propose a solution for the dynamic prediction of a health event that
may exploit repeated measures of a possibly large number of markers. We
combined a landmark approach extended to endogenous markers history with
machine learning methods adapted to survival data. Each marker trajectory is
modeled using the information collected up to landmark time, and summary
variables that best capture the individual trajectories are derived. These
summaries and additional covariates are then included in different prediction
methods. To handle a possibly large dimensional history, we rely on machine
learning methods adapted to survival data, namely regularized regressions and
random survival forests, to predict the event from the landmark time, and we
show how they can be combined into a superlearner. Then, the performances are
evaluated by cross-validation using estimators of Brier Score and the area
under the Receiver Operating Characteristic curve adapted to censored data. We
demonstrate in a simulation study the benefits of machine learning survival
methods over standard survival models, especially in the case of numerous
and/or nonlinear relationships between the predictors and the event. We then
applied the methodology in two prediction contexts: a clinical context with the
prediction of death for patients with primary biliary cholangitis, and a public
health context with the prediction of death in the general elderly population
at different ages. Our methodology, implemented in R, enables the prediction of
an event using the entire longitudinal patient history, even when the number of
repeated markers is large. Although introduced with mixed models for the
repeated markers and methods for a single right censored time-to-event, our
method can be used with any other appropriate modeling technique for the
markers and can be easily extended to competing risks setting.
</p>
<a href="http://arxiv.org/abs/2102.01466" target="_blank">arXiv:2102.01466</a> [<a href="http://arxiv.org/pdf/2102.01466" target="_blank">pdf</a>]

<h2>Rank-Consistency Deep Hashing for Scalable Multi-Label Image Search. (arXiv:2102.01486v1 [cs.CV])</h2>
<h3>Cheng Ma, Jiwen Lu, Jie Zhou</h3>
<p>As hashing becomes an increasingly appealing technique for large-scale image
retrieval, multi-label hashing is also attracting more attention for the
ability to exploit multi-level semantic contents. In this paper, we propose a
novel deep hashing method for scalable multi-label image search. Unlike
existing approaches with conventional objectives such as contrast and triplet
losses, we employ a rank list, rather than pairs or triplets, to provide
sufficient global supervision information for all the samples. Specifically, a
new rank-consistency objective is applied to align the similarity orders from
two spaces, the original space and the hamming space. A powerful loss function
is designed to penalize the samples whose semantic similarity and hamming
distance are mismatched in two spaces. Besides, a multi-label softmax
cross-entropy loss is presented to enhance the discriminative power with a
concise formulation of the derivative function. In order to manipulate the
neighborhood structure of the samples with different labels, we design a
multi-label clustering loss to cluster the hashing vectors of the samples with
the same labels by reducing the distances between the samples and their
multiple corresponding class centers. The state-of-the-art experimental results
achieved on three public multi-label datasets, MIRFLICKR-25K, IAPRTC12 and
NUS-WIDE, demonstrate the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.01486" target="_blank">arXiv:2102.01486</a> [<a href="http://arxiv.org/pdf/2102.01486" target="_blank">pdf</a>]

<h2>Gaussian Experts Selection using Graphical Models. (arXiv:2102.01496v1 [cs.LG])</h2>
<h3>Hamed Jalali, Martin Pawelczyk, Gjerji Kasneci</h3>
<p>Local approximations are popular methods to scale Gaussian processes (GPs) to
big data. Local approximations reduce time complexity by dividing the original
dataset into subsets and training a local expert on each subset. Aggregating
the experts' prediction is done assuming either conditional dependence or
independence between the experts. Imposing the \emph{conditional independence
assumption} (CI) between the experts renders the aggregation of different
expert predictions time efficient at the cost of poor uncertainty
quantification. On the other hand, modeling dependent experts can provide
precise predictions and uncertainty quantification at the expense of
impractically high computational costs. By eliminating weak experts via a
theory-guided expert selection step, we substantially reduce the computational
cost of aggregating dependent experts while ensuring calibrated uncertainty
quantification. We leverage techniques from the literature on undirected
graphical models, using sparse precision matrices that encode conditional
dependencies between experts to select the most important experts. Moreov
</p>
<a href="http://arxiv.org/abs/2102.01496" target="_blank">arXiv:2102.01496</a> [<a href="http://arxiv.org/pdf/2102.01496" target="_blank">pdf</a>]

<h2>Enterprise domain ontology learning from web-based corpus. (arXiv:2102.01498v1 [cs.AI])</h2>
<h3>Andrei Vasilateanu, Nicolae Goga, Elena-Alice Tanase, Iuliana Marin</h3>
<p>Enterprise knowledge is a key asset in the competing and fast-changing
corporate landscape. The ability to learn, store and distribute implicit and
explicit knowledge can be the difference between success and failure. While
enterprise knowledge management is a well-defined research domain, current
implementations lack orientation towards small and medium enterprise. We
propose a semantic search engine for relevant documents in an enterprise, based
on automatic generated domain ontologies. In this paper we focus on the
component for ontology learning and population.
</p>
<a href="http://arxiv.org/abs/2102.01498" target="_blank">arXiv:2102.01498</a> [<a href="http://arxiv.org/pdf/2102.01498" target="_blank">pdf</a>]

<h2>A Survey On (Stochastic Fractal Search) Algorithm. (arXiv:2102.01503v1 [cs.AI])</h2>
<h3>Mohammed ElKomy</h3>
<p>Evolutionary Algorithms are naturally inspired approximation optimisation
algorithms that usually interfere with science problems when common
mathematical methods are unable to provide a good solution or finding the exact
solution requires an unreasonable amount of time using traditional exhaustive
search algorithms. The success of these population-based frameworks is mainly
due to their flexibility and ease of adaptation to the most different and
complex optimisation problems. This paper presents a metaheuristic algorithm
called Stochastic Fractal Search, inspired by the natural phenomenon of growth
based on a mathematical concept called the fractal, which is shown to be able
to explore the search space more efficiently. This paper also focuses on the
algorithm steps and some example applications of engineering design
optimisation problems commonly used in the literature being applied to the
proposed algorithm.
</p>
<a href="http://arxiv.org/abs/2102.01503" target="_blank">arXiv:2102.01503</a> [<a href="http://arxiv.org/pdf/2102.01503" target="_blank">pdf</a>]

<h2>Android Controlled Mobile Robot Design with IP Camera. (arXiv:2102.01511v1 [cs.RO])</h2>
<h3>Emre Demir, Ahmet Gokcen, Yakup Kutlu</h3>
<p>In this study Arduino card based mobile robot design was realized. This robot
can serve as a security robot, an auxiliary robot or a control robot. The
designed robot has two operation modes. The first operating mode is autonomous
mode. In this mode, the robot detects the surroundings with the help of
ultrasonic sensors placed around it, and keeps track of the places it passes by
using the encoder. It is able to navigate without hitting any place and passing
from where it passes, and it transmits the patient's pulse and temperature
condition to the user by other systems installed on it. Also the IP camera
sends the scene on the screen. The emergency button to be placed next to the
patient sends information to the user in emergency situations. If the
abnormality is detected in the temperature and pulse again, the user gives a
message. When the pre-recorded drug use times come, the system can alert the
patient. The second mode is manual mode. In this mode, the user can move the
desired direction of the robot with the Android operating system. In addition,
all data received in autonomous mode can be sent to the user. Thus, the user
can control the mobile robot with the camera image even if it is not in the
vicinity of the robot.
</p>
<a href="http://arxiv.org/abs/2102.01511" target="_blank">arXiv:2102.01511</a> [<a href="http://arxiv.org/pdf/2102.01511" target="_blank">pdf</a>]

<h2>Metrics and continuity in reinforcement learning. (arXiv:2102.01514v1 [cs.LG])</h2>
<h3>Charline Le Lan, Marc G. Bellemare, Pablo Samuel Castro</h3>
<p>In most practical applications of reinforcement learning, it is untenable to
maintain direct estimates for individual states; in continuous-state systems,
it is impossible. Instead, researchers often leverage state similarity (whether
explicitly or implicitly) to build models that can generalize well from a
limited set of samples. The notion of state similarity used, and the
neighbourhoods and topologies they induce, is thus of crucial importance, as it
will directly affect the performance of the algorithms. Indeed, a number of
recent works introduce algorithms assuming the existence of "well-behaved"
neighbourhoods, but leave the full specification of such topologies for future
work. In this paper we introduce a unified formalism for defining these
topologies through the lens of metrics. We establish a hierarchy amongst these
metrics and demonstrate their theoretical implications on the Markov Decision
Process specifying the reinforcement learning problem. We complement our
theoretical results with empirical evaluations showcasing the differences
between the metrics considered.
</p>
<a href="http://arxiv.org/abs/2102.01514" target="_blank">arXiv:2102.01514</a> [<a href="http://arxiv.org/pdf/2102.01514" target="_blank">pdf</a>]

<h2>Orientation Convolutional Networks for Image Recognition. (arXiv:2102.01523v1 [cs.CV])</h2>
<h3>Yalan Qin, Guorui Feng, Hanzhou Wu, Yanli Ren, Xinpeng Zhang</h3>
<p>Deep Convolutional Neural Networks (DCNNs) are capable of obtaining powerful
image representations, which have attracted great attentions in image
recognition. However, they are limited in modeling orientation transformation
by the internal mechanism. In this paper, we develop Orientation Convolution
Networks (OCNs) for image recognition based on the proposed Landmark Gabor
Filters (LGFs) that the robustness of the learned representation against
changed of orientation can be enhanced. By modulating the convolutional filter
with LGFs, OCNs can be compatible with any existing deep learning networks.
LGFs act as a Gabor filter bank achieved by selecting $ p $ $ \left( \ll
n\right) $ representative Gabor filters as andmarks and express the original
Gabor filters as sparse linear combinations of these landmarks. Specifically,
based on a matrix factorization framework, a flexible integration for the local
and the global structure of original Gabor filters by sparsity and low-rank
constraints is utilized. With the propogation of the low-rank structure, the
corresponding sparsity for representation of original Gabor filter bank can be
significantly promoted. Experimental results over several benchmarks
demonstrate that our method is less sensitive to the orientation and produce
higher performance both in accuracy and cost, compared with the existing
state-of-art methods. Besides, our OCNs have few parameters to learn and can
significantly reduce the complexity of training network.
</p>
<a href="http://arxiv.org/abs/2102.01523" target="_blank">arXiv:2102.01523</a> [<a href="http://arxiv.org/pdf/2102.01523" target="_blank">pdf</a>]

<h2>A new distance measure of Pythagorean fuzzy sets based on matrix and and its application in medical diagnosis. (arXiv:2102.01538v1 [cs.AI])</h2>
<h3>Yuanpeng He</h3>
<p>The pythagorean fuzzy set (PFS) which is developed based on intuitionistic
fuzzy set, is more efficient in elaborating and disposing uncertainties in
indeterminate situations, which is a very reason of that PFS is applied in
various kinds of fields. How to measure the distance between two pythagorean
fuzzy sets is still an open issue. Mnay kinds of methods have been proposed to
present the of the question in former reaserches. However, not all of existing
methods can accurately manifest differences among pythagorean fuzzy sets and
satisfy the property of similarity. And some other kinds of methods neglect the
relationship among three variables of pythagorean fuzzy set. To addrees the
proplem, a new method of measuring distance is proposed which meets the
requirements of axiom of distance measurement and is able to indicate the
degree of distinction of PFSs well. Then some numerical examples are offered to
to verify that the method of measuring distances can avoid the situation that
some counter? intuitive and irrational results are produced and is more
effective, reasonable and advanced than other similar methods. Besides, the
proposed method of measuring distances between PFSs is applied in a real
environment of application which is the medical diagnosis and is compared with
other previous methods to demonstrate its superiority and efficiency. And the
feasibility of the proposed method in handling uncertainties in practice is
also proved at the same time.
</p>
<a href="http://arxiv.org/abs/2102.01538" target="_blank">arXiv:2102.01538</a> [<a href="http://arxiv.org/pdf/2102.01538" target="_blank">pdf</a>]

<h2>An Open-Source Modular Robotic System for Telepresence and Remote Disinfection. (arXiv:2102.01551v1 [cs.RO])</h2>
<h3>Andre Potenza, Andrey Kiselev, Alessandro Saffiotti, Amy Loutfi</h3>
<p>In a pandemic contact between humans needs to be avoided wherever possible.
Robots can take over an increasing number of tasks to protect people from being
exposed to others. One such task is the disinfection of environments in which
infection spread is particularly likely or bears increased risks. It has been
shown that UVC light is effective in neutralizing a variety of pathogens, among
others the virus causing COVID-19, SARS-CoV-2. Another function which can
reduce the need for physical proximity between humans is interaction via
telepresence, i.e., the remote embodiment of a person controlling the robot.
This work presents a modular mobile robot for telepresence and disinfection
with UVC lamps. Both operation modes are supported by adaptable autonomy
navigation features for facilitating efficient task execution. The platform's
primary contributions are its hardware and software design, which combine
consumer-grade components and 3D-printed mounting with open-source software
frameworks.
</p>
<a href="http://arxiv.org/abs/2102.01551" target="_blank">arXiv:2102.01551</a> [<a href="http://arxiv.org/pdf/2102.01551" target="_blank">pdf</a>]

<h2>Occluded Video Instance Segmentation. (arXiv:2102.01558v1 [cs.CV])</h2>
<h3>Jiyang Qi, Yan Gao, Xiaoyu Liu, Yao Hu, Xinggang Wang, Xiang Bai, Philip H.S. Torr, Serge Belongie, Alan Yuille, Song Bai</h3>
<p>Can our video understanding systems perceive objects when a heavy occlusion
exists in a scene?

To answer this question, we collect a large scale dataset called OVIS for
occluded video instance segmentation, that is, to simultaneously detect,
segment, and track instances in occluded scenes. OVIS consists of 296k
high-quality instance masks from 25 semantic categories, where object
occlusions usually occur. While our human vision systems can understand those
occluded instances by contextual reasoning and association, our experiments
suggest that current video understanding systems are not satisfying. On the
OVIS dataset, the highest AP achieved by state-of-the-art algorithms is only
14.4, which reveals that we are still at a nascent stage for understanding
objects, instances, and videos in a real-world scenario. Moreover, to
complement missing object cues caused by occlusion, we propose a plug-and-play
module called temporal feature calibration. Built upon MaskTrack R-CNN and
SipMask, we report an AP of 15.2 and 15.0 respectively. The OVIS dataset is
released at this http URL , and the project code will be available
soon.
</p>
<a href="http://arxiv.org/abs/2102.01558" target="_blank">arXiv:2102.01558</a> [<a href="http://arxiv.org/pdf/2102.01558" target="_blank">pdf</a>]

<h2>Guidance on the Assurance of Machine Learning in Autonomous Systems (AMLAS). (arXiv:2102.01564v1 [cs.LG])</h2>
<h3>Richard Hawkins, Colin Paterson, Chiara Picardi, Yan Jia, Radu Calinescu, Ibrahim Habli</h3>
<p>Machine Learning (ML) is now used in a range of systems with results that are
reported to exceed, under certain conditions, human performance. Many of these
systems, in domains such as healthcare , automotive and manufacturing, exhibit
high degrees of autonomy and are safety critical. Establishing justified
confidence in ML forms a core part of the safety case for these systems. In
this document we introduce a methodology for the Assurance of Machine Learning
for use in Autonomous Systems (AMLAS). AMLAS comprises a set of safety case
patterns and a process for (1) systematically integrating safety assurance into
the development of ML components and (2) for generating the evidence base for
explicitly justifying the acceptable safety of these components when integrated
into autonomous system applications.
</p>
<a href="http://arxiv.org/abs/2102.01564" target="_blank">arXiv:2102.01564</a> [<a href="http://arxiv.org/pdf/2102.01564" target="_blank">pdf</a>]

<h2>Real-time detection of uncalibrated sensors using Neural Networks. (arXiv:2102.01565v1 [cs.LG])</h2>
<h3>Luis J. Mu&#xf1;oz-Molina, Ignacio Cazorla-Pi&#xf1;ar, Juan P. Dominguez-Morales, Fernando Perez-Pe&#xf1;a</h3>
<p>Nowadays, sensors play a major role in several contexts like science,
industry and daily life which benefit of their use. However, the retrieved
information must be reliable. Anomalies in the behavior of sensors can give
rise to critical consequences such as ruining a scientific project or
jeopardizing the quality of the production in industrial production lines. One
of the more subtle kind of anomalies are uncalibrations. An uncalibration is
said to take place when the sensor is not adjusted or standardized by
calibration according to a ground truth value. In this work, an online
machine-learning based uncalibration detector for temperature, humidity and
pressure sensors was developed. This solution integrates an Artificial Neural
Network as main component which learns from the behavior of the sensors under
calibrated conditions. Then, after trained and deployed, it detects
uncalibrations once they take place. The obtained results show that the
proposed solution is able to detect uncalibrations for deviation values of 0.25
degrees, 1% RH and 1.5 Pa, respectively. This solution can be adapted to
different contexts by means of transfer learning, whose application allows for
the addition of new sensors, the deployment into new environments and the
retraining of the model with minimum amounts of data.
</p>
<a href="http://arxiv.org/abs/2102.01565" target="_blank">arXiv:2102.01565</a> [<a href="http://arxiv.org/pdf/2102.01565" target="_blank">pdf</a>]

<h2>A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous Q-Learning and TD-Learning Variants. (arXiv:2102.01567v1 [cs.LG])</h2>
<h3>Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, Karthikeyan Shanmugam</h3>
<p>This paper develops an unified framework to study finite-sample convergence
guarantees of a large class of value-based asynchronous Reinforcement Learning
(RL) algorithms. We do this by first reformulating the RL algorithms as
Markovian Stochastic Approximation (SA) algorithms to solve fixed-point
equations. We then develop a Lyapunov analysis and derive mean-square error
bounds on the convergence of the Markovian SA. Based on this central result, we
establish finite-sample mean-square convergence bounds for asynchronous RL
algorithms such as $Q$-learning, $n$-step TD, TD$(\lambda)$, and off-policy TD
algorithms including V-trace. As a by-product, by analyzing the performance
bounds of the TD$(\lambda)$ (and $n$-step TD) algorithm for general $\lambda$
(and $n$), we demonstrate a bias-variance trade-off, i.e., efficiency of
bootstrapping in RL. This was first posed as an open problem in [37].
</p>
<a href="http://arxiv.org/abs/2102.01567" target="_blank">arXiv:2102.01567</a> [<a href="http://arxiv.org/pdf/2102.01567" target="_blank">pdf</a>]

<h2>Symmetric Boolean Factor Analysis with Applications to InstaHide. (arXiv:2102.01570v1 [cs.LG])</h2>
<h3>Sitan Chen, Zhao Song, Runzhou Tao, Ruizhe Zhang</h3>
<p>In this work we examine the security of InstaHide, a recently proposed scheme
for distributed learning (Huang et al.). A number of recent works have given
reconstruction attacks for InstaHide in various regimes by leveraging an
intriguing connection to the following matrix factorization problem: given the
Gram matrix of a collection of m random k-sparse Boolean vectors in {0,1}^r,
recover the vectors (up to the trivial symmetries). Equivalently, this can be
thought of as a sparse, symmetric variant of the well-studied problem of
Boolean factor analysis, or as an average-case version of the classic problem
of recovering a k-uniform hypergraph from its line graph.

As previous algorithms either required m to be exponentially large in k or
only applied to k = 2, they left open the question of whether InstaHide
possesses some form of "fine-grained security" against reconstruction attacks
for moderately large k. In this work, we answer this in the negative by giving
a simple O(m^{\omega + 1}) time algorithm for the above matrix factorization
problem. Our algorithm, based on tensor decomposition, only requires m to be at
least quasi-linear in r. We complement this result with a quasipolynomial-time
algorithm for a worst-case setting of the problem where the collection of
k-sparse vectors is chosen arbitrarily.
</p>
<a href="http://arxiv.org/abs/2102.01570" target="_blank">arXiv:2102.01570</a> [<a href="http://arxiv.org/pdf/2102.01570" target="_blank">pdf</a>]

<h2>Super-klust: Another Way of Piecewise Linear Classification. (arXiv:2102.01571v1 [cs.LG])</h2>
<h3>Rahman Salim Zengin (1), Volkan Sezer (1) ((1) Istanbul Technical University)</h3>
<p>With our previous study, the Super-k algorithm, we have introduced a novel
way of piecewise-linear classification. While working on the Super-k algorithm,
we have found that there is a similar, and simpler way to explain for obtaining
a piecewise-linear classifier based on Voronoi tessellations. Replacing the
multidimensional voxelization and expectation-maximization stages of the
algorithm with a distance-based clustering algorithm, preferably k-means, works
as well as the prior approach. Since we are replacing the voxelization with the
clustering, we have found it meaningful to name the modified algorithm, with
respect to Super-k, as Supervised k Clusters or in short Super-klust. Similar
to the Super-k algorithm, the Super-klust algorithm covers data with a labeled
Voronoi tessellation, and uses resulting tessellation for classification.
According to the experimental results, the Super-klust algorithm has similar
performance characteristics with the Super-k algorithm.
</p>
<a href="http://arxiv.org/abs/2102.01571" target="_blank">arXiv:2102.01571</a> [<a href="http://arxiv.org/pdf/2102.01571" target="_blank">pdf</a>]

<h2>Policy Analysis using Synthetic Controls in Continuous-Time. (arXiv:2102.01577v1 [stat.ML])</h2>
<h3>Alexis Bellot, Mihaela van der Schaar</h3>
<p>Counterfactual estimation using synthetic controls is one of the most
successful recent methodological developments in causal inference. Despite its
popularity, the current description only considers time series aligned across
units and synthetic controls expressed as linear combinations of observed
control units. We propose a continuous-time alternative that models the latent
counterfactual path explicitly using the formalism of controlled differential
equations. This model is directly applicable to the general setting of
irregularly-aligned multivariate time series and may be optimized in rich
function spaces -- thereby improving on some limitations of existing
approaches.
</p>
<a href="http://arxiv.org/abs/2102.01577" target="_blank">arXiv:2102.01577</a> [<a href="http://arxiv.org/pdf/2102.01577" target="_blank">pdf</a>]

<h2>Exploiting Raw Images for Real-Scene Super-Resolution. (arXiv:2102.01579v1 [cs.CV])</h2>
<h3>Xiangyu Xu, Yongrui Ma, Wenxiu Sun, Ming-Hsuan Yang</h3>
<p>Super-resolution is a fundamental problem in computer vision which aims to
overcome the spatial limitation of camera sensors. While significant progress
has been made in single image super-resolution, most algorithms only perform
well on synthetic data, which limits their applications in real scenarios. In
this paper, we study the problem of real-scene single image super-resolution to
bridge the gap between synthetic data and real captured images. We focus on two
issues of existing super-resolution algorithms: lack of realistic training data
and insufficient utilization of visual information obtained from cameras. To
address the first issue, we propose a method to generate more realistic
training data by mimicking the imaging process of digital cameras. For the
second issue, we develop a two-branch convolutional neural network to exploit
the radiance information originally-recorded in raw images. In addition, we
propose a dense channel-attention block for better image restoration as well as
a learning-based guided filter network for effective color correction. Our
model is able to generalize to different cameras without deliberately training
on images from specific camera types. Extensive experiments demonstrate that
the proposed algorithm can recover fine details and clear structures, and
achieve high-quality results for single image super-resolution in real scenes.
</p>
<a href="http://arxiv.org/abs/2102.01579" target="_blank">arXiv:2102.01579</a> [<a href="http://arxiv.org/pdf/2102.01579" target="_blank">pdf</a>]

<h2>Size Matters. (arXiv:2102.01582v1 [cs.LG])</h2>
<h3>Mats L. Richter, Johan Byttner, Ulf Krumnack, Ludwdig Schallner, Justin Shenk</h3>
<p>Fully convolutional neural networks can process input of arbitrary size by
applying a combination of downsampling and pooling. However, we find that fully
convolutional image classifiers are not agnostic to the input size but rather
show significant differences in performance: presenting the same image at
different scales can result in different outcomes. A closer look reveals that
there is no simple relationship between input size and model performance (no
`bigger is better'), but that each each network has a preferred input size, for
which it shows best results. We investigate this phenomenon by applying
different methods, including spectral analysis of layer activations and probe
classifiers, showing that there are characteristic features depending on the
network architecture. From this we find that the size of discriminatory
features is critically influencing how the inference process is distributed
among the layers.
</p>
<a href="http://arxiv.org/abs/2102.01582" target="_blank">arXiv:2102.01582</a> [<a href="http://arxiv.org/pdf/2102.01582" target="_blank">pdf</a>]

<h2>The Min-Max Complexity of Distributed Stochastic Convex Optimization with Intermittent Communication. (arXiv:2102.01583v1 [cs.LG])</h2>
<h3>Blake Woodworth, Brian Bullins, Ohad Shamir, Nathan Srebro</h3>
<p>We resolve the min-max complexity of distributed stochastic convex
optimization (up to a log factor) in the intermittent communication setting,
where $M$ machines work in parallel over the course of $R$ rounds of
communication to optimize the objective, and during each round of
communication, each machine may sequentially compute $K$ stochastic gradient
estimates. We present a novel lower bound with a matching upper bound that
establishes an optimal algorithm.
</p>
<a href="http://arxiv.org/abs/2102.01583" target="_blank">arXiv:2102.01583</a> [<a href="http://arxiv.org/pdf/2102.01583" target="_blank">pdf</a>]

<h2>U-LanD: Uncertainty-Driven Video Landmark Detection. (arXiv:2102.01586v1 [cs.CV])</h2>
<h3>Mohammad H. Jafari, Christina Luong, Michael Tsang, Ang Nan Gu, Nathan Van Woudenberg, Robert Rohling, Teresa Tsang, Purang Abolmaesumi</h3>
<p>This paper presents U-LanD, a framework for joint detection of key frames and
landmarks in videos. We tackle a specifically challenging problem, where
training labels are noisy and highly sparse. U-LanD builds upon a pivotal
observation: a deep Bayesian landmark detector solely trained on key video
frames, has significantly lower predictive uncertainty on those frames vs.
other frames in videos. We use this observation as an unsupervised signal to
automatically recognize key frames on which we detect landmarks. As a test-bed
for our framework, we use ultrasound imaging videos of the heart, where sparse
and noisy clinical labels are only available for a single frame in each video.
Using data from 4,493 patients, we demonstrate that U-LanD can exceedingly
outperform the state-of-the-art non-Bayesian counterpart by a noticeable
absolute margin of 42% in R2 score, with almost no overhead imposed on the
model size. Our approach is generic and can be potentially applied to other
challenging data with noisy and sparse training labels.
</p>
<a href="http://arxiv.org/abs/2102.01586" target="_blank">arXiv:2102.01586</a> [<a href="http://arxiv.org/pdf/2102.01586" target="_blank">pdf</a>]

<h2>FEDZIP: A Compression Framework for Communication-Efficient Federated Learning. (arXiv:2102.01593v1 [cs.LG])</h2>
<h3>Amirhossein Malekijoo, Mohammad Javad Fadaeieslam, Hanieh Malekijou, Morteza Homayounfar, Farshid Alizadeh-Shabdiz, Reza Rawassizadeh</h3>
<p>Federated Learning marks a turning point in the implementation of
decentralized machine learning (especially deep learning) for wireless devices
by protecting users' privacy and safeguarding raw data from third-party access.
It assigns the learning process independently to each client. First, clients
locally train a machine learning model based on local data. Next, clients
transfer local updates of model weights and biases (training data) to a server.
Then, the server aggregates updates (received from clients) to create a global
learning model. However, the continuous transfer between clients and the server
increases communication costs and is inefficient from a resource utilization
perspective due to the large number of parameters (weights and biases) used by
deep learning models. The cost of communication becomes a greater concern when
the number of contributing clients and communication rounds increases. In this
work, we propose a novel framework, FedZip, that significantly decreases the
size of updates while transferring weights from the deep learning model between
clients and their servers. FedZip implements Top-z sparsification, uses
quantization with clustering, and implements compression with three different
encoding methods. FedZip outperforms state-of-the-art compression frameworks
and reaches compression rates up to 1085x, and preserves up to 99% of bandwidth
and 99% of energy for clients during communication.
</p>
<a href="http://arxiv.org/abs/2102.01593" target="_blank">arXiv:2102.01593</a> [<a href="http://arxiv.org/pdf/2102.01593" target="_blank">pdf</a>]

<h2>Model-based multi-parameter mapping. (arXiv:2102.01604v1 [cs.CV])</h2>
<h3>Yael Balbastre, Mikael Brudfors, Michela Azzarito, Christian Lambert, Martina F. Callaghan, John Ashburner</h3>
<p>Quantitative MR imaging is increasingly favoured for its richer information
content and standardised measures. However, extracting quantitative parameters
such as the longitudinal relaxation rate (R1), apparent transverse relaxation
rate (R2*), or magnetisation-transfer saturation (MTsat) involves inverting a
highly non-linear function. Estimations often assume noise-free measurements
and use subsets of the data to solve for different quantities in isolation,
with error propagating through each computation. Instead, a probabilistic
generative model of the entire dataset can be formulated and inverted to
jointly recover parameter estimates with a well-defined probabilistic meaning
(e.g., maximum likelihood or maximum a posteriori). In practice, iterative
methods must be used but convergence is difficult due to the non-convexity of
the log-likelihood; yet, we show that it can be achieved thanks to a novel
approximate Hessian and, with it, reliable parameter estimates obtained. Here,
we demonstrate the utility of this flexible framework in the context of the
popular multi-parameter mapping framework and further show how to incorporate a
denoising prior and predict posterior uncertainty. Our implementation uses a
PyTorch backend and benefits from GPU acceleration. It is available at
https://github.com/balbasty/nitorch.
</p>
<a href="http://arxiv.org/abs/2102.01604" target="_blank">arXiv:2102.01604</a> [<a href="http://arxiv.org/pdf/2102.01604" target="_blank">pdf</a>]

<h2>Symplectic Gaussian Process Dynamics. (arXiv:2102.01606v1 [cs.LG])</h2>
<h3>Katharina Ensinger, Friedrich Solowjow, Michael Tiemann, Sebastian Trimpe</h3>
<p>Dynamics model learning is challenging and at the same time an active field
of research. Due to potential safety critical downstream applications, such as
control tasks, there is a need for theoretical guarantees. While GPs induce
rich theoretical guarantees as function approximators in space, they do not
explicitly cope with the time aspect of dynamical systems. However, propagating
system properties through time is exactly what classical numerical integrators
were designed for. We introduce a recurrent sparse Gaussian process based
variational inference scheme that is able to discretize the underlying system
with any explicit or implicit single or multistep integrator, thus leveraging
properties of numerical integrators. In particular we discuss Hamiltonian
problems coupled with symplectic integrators producing volume preserving
predictions.
</p>
<a href="http://arxiv.org/abs/2102.01606" target="_blank">arXiv:2102.01606</a> [<a href="http://arxiv.org/pdf/2102.01606" target="_blank">pdf</a>]

<h2>Towards Multi-agent Reinforcement Learning for Wireless Network Protocol Synthesis. (arXiv:2102.01611v1 [cs.LG])</h2>
<h3>Hrishikesh Dutta, Subir Biswas</h3>
<p>This paper proposes a multi-agent reinforcement learning based medium access
framework for wireless networks. The access problem is formulated as a Markov
Decision Process (MDP), and solved using reinforcement learning with every
network node acting as a distributed learning agent. The solution components
are developed step by step, starting from a single-node access scenario in
which a node agent incrementally learns to control MAC layer packet loads for
reining in self-collisions. The strategy is then scaled up for multi-node
fully-connected scenarios by using more elaborate reward structures. It also
demonstrates preliminary feasibility for more general partially connected
topologies. It is shown that by learning to adjust MAC layer transmission
probabilities, the protocol is not only able to attain theoretical maximum
throughput at an optimal load, but unlike classical approaches, it can also
retain that maximum throughput at higher loading conditions. Additionally, the
mechanism is agnostic to heterogeneous loading while preserving that feature.
It is also shown that access priorities of the protocol across nodes can be
parametrically adjusted. Finally, it is also shown that the online learning
feature of reinforcement learning is able to make the protocol adapt to
time-varying loading conditions.
</p>
<a href="http://arxiv.org/abs/2102.01611" target="_blank">arXiv:2102.01611</a> [<a href="http://arxiv.org/pdf/2102.01611" target="_blank">pdf</a>]

<h2>Depth separation beyond radial functions. (arXiv:2102.01621v1 [cs.LG])</h2>
<h3>Luca Venturi, Samy Jelassi, Tristan Ozuch, Joan Bruna</h3>
<p>High-dimensional depth separation results for neural networks show that
certain functions can be efficiently approximated by two-hidden-layer networks
but not by one-hidden-layer ones in high-dimensions $d$. Existing results of
this type mainly focus on functions with an underlying radial or
one-dimensional structure, which are usually not encountered in practice. The
first contribution of this paper is to extend such results to a more general
class of functions, namely functions with piece-wise oscillatory structure, by
building on the proof strategy of (Eldan and Shamir, 2016).

A common theme in the proof of such results is the fact that one-hidden-layer
fail to approximate high-energy functions whose Fourier representation is
spread in the domain. On the other hand, existing approximation results of a
function by one-hidden-layer neural networks rely on the function having a
sparse Fourier representation. The choice of the domain also represents a
source of gaps between upper and lower approximation bounds. Focusing on a
fixed approximation domain, namely the sphere $\mathbb{S}^{d-1}$ in dimension
$d$, we provide a characterization of both functions which are efficiently
approximable by one-hidden-layer networks and of functions which are provably
not, in terms of their Fourier expansion.
</p>
<a href="http://arxiv.org/abs/2102.01621" target="_blank">arXiv:2102.01621</a> [<a href="http://arxiv.org/pdf/2102.01621" target="_blank">pdf</a>]

<h2>Strongly Adaptive OCO with Memory. (arXiv:2102.01623v1 [cs.LG])</h2>
<h3>Zhiyu Zhang, Ashok Cutkosky, Ioannis Ch. Paschalidis</h3>
<p>Recent progress in online control has popularized online learning with
memory, a variant of the standard online learning problem with loss functions
dependent on the prediction history. In this paper, we propose the first
strongly adaptive algorithm for this problem: on any interval
$\mathcal{I}\subset[1:T]$, the proposed algorithm achieves $\tilde
O\left(\sqrt{|\mathcal{I}|}\right)$ policy regret against the best fixed
comparator for that interval. Combined with online control techniques, our
algorithm results in a strongly adaptive regret bound for the control of linear
time-varying systems.
</p>
<a href="http://arxiv.org/abs/2102.01623" target="_blank">arXiv:2102.01623</a> [<a href="http://arxiv.org/pdf/2102.01623" target="_blank">pdf</a>]

<h2>OPAM: Online Purchasing-behavior Analysis using Machine learning. (arXiv:2102.01625v1 [cs.LG])</h2>
<h3>Sohini Roychowdhury, Ebrahim Alareqi, Wenxi Li</h3>
<p>Customer purchasing behavior analysis plays a key role in developing
insightful communication strategies between online vendors and their customers.
To support the recent increase in online shopping trends, in this work, we
present a customer purchasing behavior analysis system using supervised,
unsupervised and semi-supervised learning methods. The proposed system analyzes
session and user-journey level purchasing behaviors to identify customer
categories/clusters that can be useful for targeted consumer insights at scale.
We observe higher sensitivity to the design of online shopping portals for
session-level purchasing prediction with accuracy/recall in range
91-98%/73-99%, respectively. The user-journey level analysis demonstrates five
unique user clusters, wherein 'New Shoppers' are most predictable and
'Impulsive Shoppers' are most unique with low viewing and high carting
behaviors for purchases. Further, cluster transformation metrics and partial
label learning demonstrates the robustness of each user cluster to
new/unlabelled events. Thus, customer clusters can aid strategic targeted nudge
models.
</p>
<a href="http://arxiv.org/abs/2102.01625" target="_blank">arXiv:2102.01625</a> [<a href="http://arxiv.org/pdf/2102.01625" target="_blank">pdf</a>]

<h2>A Hierarchical Multi-Robot Mapping Architecture Subject to Communication Constraints. (arXiv:2102.01641v1 [cs.RO])</h2>
<h3>Henry Fielding Cappel</h3>
<p>Multi-robot systems are an efficient method to explore and map an unknown
environment. The simulataneous localization and mapping (SLAM) algorithm is
common for single robot systems, however multiple robots can share respective
map data in order to merge a larger global map. This thesis contributes to the
multi-robot mapping problem by considering cases in which robots have
communication range limitations. The architecture coordinates a team of robots
and the central server to explore an unknown environment by exploiting a
hierarchical choice structure. The coordination algorithms ensure that the
hierarchy of robots choose frontier points that provide maximum information
gain, while maintaining viable communication amongst themselves and the central
computer through an ad-hoc relay network. In addition, the robots employ a
backup choice algorithm in cases when no valid frontier points remain by
arranging the communication relay network as a fireline back to the source.

This work contributes a scalable, efficient, and robust architecture towards
hybrid multi-robot mapping systems that take into account communication range
limitations. The architecture is tested in a simulation environment using
various maps.
</p>
<a href="http://arxiv.org/abs/2102.01641" target="_blank">arXiv:2102.01641</a> [<a href="http://arxiv.org/pdf/2102.01641" target="_blank">pdf</a>]

<h2>Online Learning with Simple Predictors and a Combinatorial Characterization of Minimax in 0/1 Games. (arXiv:2102.01646v1 [cs.LG])</h2>
<h3>Steve Hanneke, Roi Livni, Shay Moran</h3>
<p>Which classes can be learned properly in the online model? -- that is, by an
algorithm that at each round uses a predictor from the concept class. While
there are simple and natural cases where improper learning is necessary, it is
natural to ask how complex must the improper predictors be in such cases. Can
one always achieve nearly optimal mistake/regret bounds using "simple"
predictors?

In this work, we give a complete characterization of when this is possible,
thus settling an open problem which has been studied since the pioneering works
of Angluin (1987) and Littlestone (1988). More precisely, given any concept
class C and any hypothesis class H, we provide nearly tight bounds (up to a log
factor) on the optimal mistake bounds for online learning C using predictors
from H. Our bound yields an exponential improvement over the previously best
known bound by Chase and Freitag (2020).

As applications, we give constructive proofs showing that (i) in the
realizable setting, a near-optimal mistake bound (up to a constant factor) can
be attained by a sparse majority-vote of proper predictors, and (ii) in the
agnostic setting, a near-optimal regret bound (up to a log factor) can be
attained by a randomized proper algorithm.

A technical ingredient of our proof which may be of independent interest is a
generalization of the celebrated Minimax Theorem (von Neumann, 1928) for binary
zero-sum games. A simple game which fails to satisfy Minimax is "Guess the
Larger Number", where each player picks a number and the larger number wins.
The payoff matrix is infinite triangular. We show this is the only obstruction:
if a game does not contain triangular submatrices of unbounded sizes then the
Minimax Theorem holds. This generalizes von Neumann's Minimax Theorem by
removing requirements of finiteness (or compactness), and captures precisely
the games of interest in online learning.
</p>
<a href="http://arxiv.org/abs/2102.01646" target="_blank">arXiv:2102.01646</a> [<a href="http://arxiv.org/pdf/2102.01646" target="_blank">pdf</a>]

<h2>Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization. (arXiv:2102.01670v1 [cs.LG])</h2>
<h3>Kale-ab Tessera, Sara Hooker, Benjamin Rosman</h3>
<p>Training sparse networks to converge to the same performance as dense neural
architectures has proven to be elusive. Recent work suggests that
initialization is the key. However, while this direction of research has had
some success, focusing on initialization alone appears to be inadequate. In
this paper, we take a broader view of training sparse networks and consider the
role of regularization, optimization and architecture choices on sparse models.
We propose a simple experimental framework, Same Capacity Sparse vs Dense
Comparison (SC-SDC), that allows for fair comparison of sparse and dense
networks. Furthermore, we propose a new measure of gradient flow, Effective
Gradient Flow (EGF), that better correlates to performance in sparse networks.
Using top-line metrics, SC-SDC and EGF, we show that default choices of
optimizers, activation functions and regularizers used for dense networks can
disadvantage sparse networks. Based upon these findings, we show that gradient
flow in sparse networks can be improved by reconsidering aspects of the
architecture design and the training regime. Our work suggests that
initialization is only one piece of the puzzle and taking a wider view of
tailoring optimization to sparse networks yields promising results.
</p>
<a href="http://arxiv.org/abs/2102.01670" target="_blank">arXiv:2102.01670</a> [<a href="http://arxiv.org/pdf/2102.01670" target="_blank">pdf</a>]

<h2>Agent Incentives: A Causal Perspective. (arXiv:2102.01685v1 [cs.AI])</h2>
<h3>Tom Everitt, Ryan Carey, Eric Langlois, Pedro A Ortega, Shane Legg</h3>
<p>We present a framework for analysing agent incentives using causal influence
diagrams. We establish that a well-known criterion for value of information is
complete. We propose a new graphical criterion for value of control,
establishing its soundness and completeness. We also introduce two new concepts
for incentive analysis: response incentives indicate which changes in the
environment affect an optimal decision, while instrumental control incentives
establish whether an agent can influence its utility via a variable X. For both
new concepts, we provide sound and complete graphical criteria. We show by
example how these results can help with evaluating the safety and fairness of
an AI system.
</p>
<a href="http://arxiv.org/abs/2102.01685" target="_blank">arXiv:2102.01685</a> [<a href="http://arxiv.org/pdf/2102.01685" target="_blank">pdf</a>]

<h2>Report of the Workshop on Program Synthesis for Scientific Computing. (arXiv:2102.01687v1 [cs.LG])</h2>
<h3>Hal Finkel, Ignacio Laguna</h3>
<p>Program synthesis is an active research field in academia, national labs, and
industry. Yet, work directly applicable to scientific computing, while having
some impressive successes, has been limited. This report reviews the relevant
areas of program synthesis work for scientific computing, discusses successes
to date, and outlines opportunities for future work. This report is the result
of the Workshop on Program Synthesis for Scientific Computing was held
virtually on August 4-5 2020 (https://prog-synth-science.github.io/2020/).
</p>
<a href="http://arxiv.org/abs/2102.01687" target="_blank">arXiv:2102.01687</a> [<a href="http://arxiv.org/pdf/2102.01687" target="_blank">pdf</a>]

<h2>From Culture to Clothing: Discovering the World Events Behind A Century of Fashion Images. (arXiv:2102.01690v1 [cs.CV])</h2>
<h3>Wei-Lin Hsiao, Kristen Grauman</h3>
<p>Fashion is intertwined with external cultural factors, but identifying these
links remains a manual process limited to only the most salient phenomena. We
propose a data-driven approach to identify specific cultural factors affecting
the clothes people wear. Using large-scale datasets of news articles and
vintage photos spanning a century, we introduce a multi-modal statistical model
to detect influence relationships between happenings in the world and people's
choice of clothing. Furthermore, we apply our model to improve the concrete
vision tasks of visual style forecasting and photo timestamping on two
datasets. Our work is a first step towards a computational, scalable, and
easily refreshable approach to link culture to clothing.
</p>
<a href="http://arxiv.org/abs/2102.01690" target="_blank">arXiv:2102.01690</a> [<a href="http://arxiv.org/pdf/2102.01690" target="_blank">pdf</a>]

<h2>Exact Langevin Dynamics with Stochastic Gradients. (arXiv:2102.01691v1 [stat.ML])</h2>
<h3>Adri&#xe0; Garriga-Alonso, Vincent Fortuin</h3>
<p>Stochastic gradient Markov Chain Monte Carlo algorithms are popular samplers
for approximate inference, but they are generally biased. We show that many
recent versions of these methods (e.g. Chen et al. (2014)) cannot be corrected
using Metropolis-Hastings rejection sampling, because their acceptance
probability is always zero. We can fix this by employing a sampler with
realizable backwards trajectories, such as Gradient-Guided Monte Carlo
(Horowitz, 1991), which generalizes stochastic gradient Langevin dynamics
(Welling and Teh, 2011) and Hamiltonian Monte Carlo. We show that this sampler
can be used with stochastic gradients, yielding nonzero acceptance
probabilities, which can be computed even across multiple steps.
</p>
<a href="http://arxiv.org/abs/2102.01691" target="_blank">arXiv:2102.01691</a> [<a href="http://arxiv.org/pdf/2102.01691" target="_blank">pdf</a>]

<h2>General Value Function Networks. (arXiv:1807.06763v4 [cs.LG] UPDATED)</h2>
<h3>Matthew Schlegel, Andrew Jacobsen, Zaheer Abbas, Andrew Patterson, Adam White, Martha White</h3>
<p>State construction is important for learning in partially observable
environments. A general purpose strategy for state construction is to learn the
state update using a Recurrent Neural Network (RNN), which updates the internal
state using the current internal state and the most recent observation. This
internal state provides a summary of the observed sequence, to facilitate
accurate predictions and decision-making. At the same time, specifying and
training RNNs is notoriously tricky, particularly as the common strategy to
approximate gradients back in time, called truncated Back-prop Through Time
(BPTT), can be sensitive to the truncation window. Further,
domain-expertise--which can usually help constrain the function class and so
improve trainability--can be difficult to incorporate into complex recurrent
units used within RNNs. In this work, we explore how to use multi-step
predictions to constrain the RNN and incorporate prior knowledge. In
particular, we revisit the idea of using predictions to construct state and
ask: does constraining (parts of) the state to consist of predictions about the
future improve RNN trainability? We formulate a novel RNN architecture, called
a General Value Function Network (GVFN), where each internal state component
corresponds to a prediction about the future represented as a value function.
We first provide an objective for optimizing GVFNs, and derive several
algorithms to optimize this objective. We then show that GVFNs are more robust
to the truncation level, in many cases only requiring one-step gradient
updates.
</p>
<a href="http://arxiv.org/abs/1807.06763" target="_blank">arXiv:1807.06763</a> [<a href="http://arxiv.org/pdf/1807.06763" target="_blank">pdf</a>]

<h2>Low-Rank Semidefinite Programs via Bilinear Factorization. (arXiv:1811.01198v7 [cs.LG] UPDATED)</h2>
<h3>En-Liang Hu</h3>
<p>Many machine learning problems can be reduced to learning a low-rank positive
semidefinite matrix (denoted as $Z$), which encounters semidefinite program
(SDP). Existing SDP solvers are often expensive for large-scale learning. To
avoid directly solving SDP, some works convert SDP into a nonconvex program by
factorizing $Z$ \textit{quadraticly} as $XX^\top$. However, this would bring
higher-order nonlinearity, resulting in scarcity of structure in subsequent
optimization. In this paper, we propose a novel surrogate for SDP learning, in
which the structure of subproblem is exploited. More specifically, we surrogate
unconstrained SDP by a biconvex problem, through factorizing $Z$
\textit{bilinearly} as $XY^\top$ and using a Courant penalty to penalize the
difference of $X$ and $Y$, in which the resultant subproblems in terms of $X$
and $Y$ are convex respectively. Furthermore, we provide a theoretical bound
for the associated penalty parameter under the assumption that the subobjective
function of $X$ or $Y$ is $L$-Lipschitz-smooth and $\sigma$-strongly convex,
such that the proposed surrogate will solve the original SDP when the penalty
parameter is larger than this bound (that is $\gamma&gt;\frac{1}{4}(L-\sigma)$).
Experiments on two SDP-related applications demonstrate that the proposed
algorithm is as accurate as the state-of-the-art, but is faster on large-scale
learning.
</p>
<a href="http://arxiv.org/abs/1811.01198" target="_blank">arXiv:1811.01198</a> [<a href="http://arxiv.org/pdf/1811.01198" target="_blank">pdf</a>]

<h2>General Control Functions for Causal Effect Estimation from Instrumental Variables. (arXiv:1907.03451v2 [cs.LG] UPDATED)</h2>
<h3>Aahlad Manas Puli, Rajesh Ranganath</h3>
<p>Causal effect estimation relies on separating the variation in the outcome
into parts due to the treatment and due to the confounders. To achieve this
separation, practitioners often use external sources of randomness that only
influence the treatment called instrumental variables (IVs). We study variables
constructed from treatment and IV that help estimate effects, called control
functions. We characterize general control functions for effect estimation in a
meta-identification result. Then, we show that structural assumptions on the
treatment process allow the construction of general control functions, thereby
guaranteeing identification. To construct general control functions and
estimate effects, we develop the general control function method (GCFN). GCFN's
first stage called variational decoupling (VDE) constructs general control
functions by recovering the residual variation in the treatment given the IV.
Using VDE's control function, GCFN's second stage estimates effects via
regression. Further, we develop semi-supervised GCFN to construct general
control functions using subsets of data that have both IV and confounders
observed as supervision; this needs no structural treatment process
assumptions. We evaluate GCFN on low and high dimensional simulated data and on
recovering the causal effect of slave export on modern community trust.
</p>
<a href="http://arxiv.org/abs/1907.03451" target="_blank">arXiv:1907.03451</a> [<a href="http://arxiv.org/pdf/1907.03451" target="_blank">pdf</a>]

<h2>GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural Network Representation of AIS Tracks and A Contrario Detection. (arXiv:1912.00682v4 [cs.LG] UPDATED)</h2>
<h3>Duong Nguyen, Rodolphe Vadaine, Guillaume Hajduch, Ren&#xe9; Garello, Ronan Fablet</h3>
<p>Representing maritime traffic patterns and detecting anomalies from them are
key to vessel monitoring and maritime situational awareness. We propose a novel
approach -- referred to as GeoTrackNet -- for maritime anomaly detection from
AIS data streams. Our model exploits state-of-the-art neural network schemes to
learn a probabilistic representation of AIS tracks and a contrario detection to
detect abnormal events. The neural network provides a new means to capture
complex and heterogeneous patterns in vessels' behaviours, while the a
contrario detector takes into account the fact that the learnt distribution may
be location-dependent. Experiments on a real AIS dataset comprising more than
4.2 million AIS messages demonstrate the relevance of the proposed method
compared with state-of-the-art schemes.
</p>
<a href="http://arxiv.org/abs/1912.00682" target="_blank">arXiv:1912.00682</a> [<a href="http://arxiv.org/pdf/1912.00682" target="_blank">pdf</a>]

<h2>Mimetics: Towards Understanding Human Actions Out of Context. (arXiv:1912.07249v3 [cs.CV] UPDATED)</h2>
<h3>Philippe Weinzaepfel, Gr&#xe9;gory Rogez</h3>
<p>Recent methods for video action recognition have reached outstanding
performances on existing benchmarks. However, they tend to leverage context
such as scenes or objects instead of focusing on understanding the human action
itself. For instance, a tennis field leads to the prediction playing tennis
irrespectively of the actions performed in the video. In contrast, humans have
a more complete understanding of actions and can recognize them without
context. The best example of out-of-context actions are mimes, that people can
typically recognize despite missing relevant objects and scenes. In this paper,
we propose to benchmark action recognition methods in such absence of context
and introduce a novel dataset, Mimetics, consisting of mimed actions for a
subset of 50 classes from the Kinetics benchmark. Our experiments show that (a)
state-of-the-art 3D convolutional neural networks obtain disappointing results
on such videos, highlighting the lack of true understanding of the human
actions and (b) models leveraging body language via human pose are less prone
to context biases. In particular, we show that applying a shallow neural
network with a single temporal convolution over body pose features transferred
to the action recognition problem performs surprisingly well compared to 3D
action recognition methods.
</p>
<a href="http://arxiv.org/abs/1912.07249" target="_blank">arXiv:1912.07249</a> [<a href="http://arxiv.org/pdf/1912.07249" target="_blank">pdf</a>]

<h2>Overcoming Long-term Catastrophic Forgetting through Adversarial Neural Pruning and Synaptic Consolidation. (arXiv:1912.09091v3 [cs.LG] UPDATED)</h2>
<h3>Jian Peng, Bo Tang, Hao Jiang, Zhuo Li, Yinjie Lei, Tao Lin, Haifeng Li</h3>
<p>Artificial neural networks face the well-known problem of catastrophic
forgetting. What's worse, the degradation of previously learned skills becomes
more severe as the task sequence increases, known as the long-term catastrophic
forgetting. It is due to two facts: first, as the model learns more tasks, the
intersection of the low-error parameter subspace satisfying for these tasks
becomes smaller or even does not exist; second, when the model learns a new
task, the cumulative error keeps increasing as the model tries to protect the
parameter configuration of previous tasks from interference. Inspired by the
memory consolidation mechanism in mammalian brains with synaptic plasticity, we
propose a confrontation mechanism in which Adversarial Neural Pruning and
synaptic Consolidation (ANPyC) is used to overcome the long-term catastrophic
forgetting issue. The neural pruning acts as long-term depression to prune
task-irrelevant parameters, while the novel synaptic consolidation acts as
long-term potentiation to strengthen task-relevant parameters. During the
training, this confrontation achieves a balance in that only crucial parameters
remain, and non-significant parameters are freed to learn subsequent tasks.
ANPyC avoids forgetting important information and makes the model efficient to
learn a large number of tasks. Specifically, the neural pruning iteratively
relaxes the current task's parameter conditions to expand the common parameter
subspace of the task; the synaptic consolidation strategy, which consists of a
structure-aware parameter-importance measurement and an element-wise parameter
updating strategy, decreases the cumulative error when learning new tasks. The
full source code is available at https://github.com/GeoX-Lab/ANPyC.
</p>
<a href="http://arxiv.org/abs/1912.09091" target="_blank">arXiv:1912.09091</a> [<a href="http://arxiv.org/pdf/1912.09091" target="_blank">pdf</a>]

<h2>Convolutional Neural Networks with Intermediate Loss for 3D Super-Resolution of CT and MRI Scans. (arXiv:2001.01330v3 [cs.CV] UPDATED)</h2>
<h3>Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Nicolae Verga</h3>
<p>CT scanners that are commonly-used in hospitals nowadays produce
low-resolution images, up to 512 pixels in size. One pixel in the image
corresponds to a one millimeter piece of tissue. In order to accurately segment
tumors and make treatment plans, doctors need CT scans of higher resolution.
The same problem appears in MRI. In this paper, we propose an approach for the
single-image super-resolution of 3D CT or MRI scans. Our method is based on
deep convolutional neural networks (CNNs) composed of 10 convolutional layers
and an intermediate upscaling layer that is placed after the first 6
convolutional layers. Our first CNN, which increases the resolution on two axes
(width and height), is followed by a second CNN, which increases the resolution
on the third axis (depth). Different from other methods, we compute the loss
with respect to the ground-truth high-resolution output right after the
upscaling layer, in addition to computing the loss after the last convolutional
layer. The intermediate loss forces our network to produce a better output,
closer to the ground-truth. A widely-used approach to obtain sharp results is
to add Gaussian blur using a fixed standard deviation. In order to avoid
overfitting to a fixed standard deviation, we apply Gaussian smoothing with
various standard deviations, unlike other approaches. We evaluate our method in
the context of 2D and 3D super-resolution of CT and MRI scans from two
databases, comparing it to relevant related works from the literature and
baselines based on various interpolation schemes, using 2x and 4x scaling
factors. The empirical results show that our approach attains superior results
to all other methods. Moreover, our human annotation study reveals that both
doctors and regular annotators chose our method in favor of Lanczos
interpolation in 97.55% cases for 2x upscaling factor and in 96.69% cases for
4x upscaling factor.
</p>
<a href="http://arxiv.org/abs/2001.01330" target="_blank">arXiv:2001.01330</a> [<a href="http://arxiv.org/pdf/2001.01330" target="_blank">pdf</a>]

<h2>PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees. (arXiv:2002.05551v4 [stat.ML] UPDATED)</h2>
<h3>Jonas Rothfuss, Vincent Fortuin, Martin Josifoski, Andreas Krause</h3>
<p>Meta-learning can successfully acquire useful inductive biases from data.
Yet, its generalization properties to unseen learning tasks are poorly
understood. Particularly if the number of meta-training tasks is small, this
raises concerns about overfitting. We provide a theoretical analysis using the
PAC-Bayesian framework and derive novel generalization bounds for
meta-learning. Using these bounds, we develop a class of PAC-optimal
meta-learning algorithms with performance guarantees and a principled
meta-level regularization. Unlike previous PAC-Bayesian meta-learners, our
method results in a standard stochastic optimization problem which can be
solved efficiently and scales well. When instantiating our PAC-optimal
hyper-posterior (PACOH) with Gaussian processes and Bayesian Neural Networks as
base learners, the resulting methods yield state-of-the-art performance, both
in terms of predictive accuracy and the quality of uncertainty estimates.
Thanks to their principled treatment of uncertainty, our meta-learners can also
be successfully employed for sequential decision problems.
</p>
<a href="http://arxiv.org/abs/2002.05551" target="_blank">arXiv:2002.05551</a> [<a href="http://arxiv.org/pdf/2002.05551" target="_blank">pdf</a>]

<h2>A General Pairwise Comparison Model for Extremely Sparse Networks. (arXiv:2002.08853v2 [stat.ML] UPDATED)</h2>
<h3>Ruijian Han, Yiming Xu, Kani Chen</h3>
<p>Statistical inference using pairwise comparison data has been an effective
approach to analyzing complex and sparse networks. In this paper we propose a
general framework for modeling the mutual interaction in a network, which
enjoys ample flexibility in terms of parametrization. Within this setup, we
establish that the maximum likelihood estimator (MLE) for the latent scores of
the subjects is uniformly consistent under a near-minimal condition on network
sparsity. This condition is sharp in terms of the leading order asymptotics
describing the sparsity. The proof utilizes a novel chaining technique based on
the error-induced metric as well as careful counting of comparison graph
structures. Our results guarantee that the MLE is a valid estimator for
inference in large-scale comparison networks where data is asymptotically
deficient. Numerical simulations are provided to complement the theoretical
analysis.
</p>
<a href="http://arxiv.org/abs/2002.08853" target="_blank">arXiv:2002.08853</a> [<a href="http://arxiv.org/pdf/2002.08853" target="_blank">pdf</a>]

<h2>Deep Attentive Study Session Dropout Prediction in Mobile Learning Environment. (arXiv:2002.11624v5 [cs.LG] UPDATED)</h2>
<h3>Youngnam Lee, Dongmin Shin, HyunBin Loh, Jaemin Lee, Piljae Chae, Junghyun Cho, Seoyon Park, Jinhwan Lee, Jineon Baek, Byungsoo Kim, Youngduck Choi</h3>
<p>Student dropout prediction provides an opportunity to improve student
engagement, which maximizes the overall effectiveness of learning experiences.
However, researches on student dropout were mainly conducted on school dropout
or course dropout, and study session dropout in a mobile learning environment
has not been considered thoroughly. In this paper, we investigate the study
session dropout prediction problem in a mobile learning environment. First, we
define the concept of the study session, study session dropout and study
session dropout prediction task in a mobile learning environment. Based on the
definitions, we propose a novel Transformer based model for predicting study
session dropout, DAS: Deep Attentive Study Session Dropout Prediction in Mobile
Learning Environment. DAS has an encoder-decoder structure which is composed of
stacked multi-head attention and point-wise feed-forward networks. The deep
attentive computations in DAS are capable of capturing complex relations among
dynamic student interactions. To the best of our knowledge, this is the first
attempt to investigate study session dropout in a mobile learning environment.
Empirical evaluations on a large-scale dataset show that DAS achieves the best
performance with a significant improvement in area under the receiver operating
characteristic curve compared to baseline models.
</p>
<a href="http://arxiv.org/abs/2002.11624" target="_blank">arXiv:2002.11624</a> [<a href="http://arxiv.org/pdf/2002.11624" target="_blank">pdf</a>]

<h2>Deep Randomized Neural Networks. (arXiv:2002.12287v2 [cs.LG] UPDATED)</h2>
<h3>Claudio Gallicchio, Simone Scardapane</h3>
<p>Randomized Neural Networks explore the behavior of neural systems where the
majority of connections are fixed, either in a stochastic or a deterministic
fashion. Typical examples of such systems consist of multi-layered neural
network architectures where the connections to the hidden layer(s) are left
untrained after initialization. Limiting the training algorithms to operate on
a reduced set of weights inherently characterizes the class of Randomized
Neural Networks with a number of intriguing features. Among them, the extreme
efficiency of the resulting learning processes is undoubtedly a striking
advantage with respect to fully trained architectures. Besides, despite the
involved simplifications, randomized neural systems possess remarkable
properties both in practice, achieving state-of-the-art results in multiple
domains, and theoretically, allowing to analyze intrinsic properties of neural
architectures (e.g. before training of the hidden layers' connections). In
recent years, the study of Randomized Neural Networks has been extended towards
deep architectures, opening new research directions to the design of effective
yet extremely efficient deep learning models in vectorial as well as in more
complex data domains. This chapter surveys all the major aspects regarding the
design and analysis of Randomized Neural Networks, and some of the key results
with respect to their approximation capabilities. In particular, we first
introduce the fundamentals of randomized neural models in the context of
feed-forward networks (i.e., Random Vector Functional Link and equivalent
models) and convolutional filters, before moving to the case of recurrent
systems (i.e., Reservoir Computing networks). For both, we focus specifically
on recent results in the domain of deep randomized systems, and (for recurrent
models) their application to structured domains.
</p>
<a href="http://arxiv.org/abs/2002.12287" target="_blank">arXiv:2002.12287</a> [<a href="http://arxiv.org/pdf/2002.12287" target="_blank">pdf</a>]

<h2>Model-Based Meta-Reinforcement Learning for Flight with Suspended Payloads. (arXiv:2004.11345v2 [cs.RO] UPDATED)</h2>
<h3>Suneel Belkhale, Rachel Li, Gregory Kahn, Rowan McAllister, Roberto Calandra, Sergey Levine</h3>
<p>Transporting suspended payloads is challenging for autonomous aerial vehicles
because the payload can cause significant and unpredictable changes to the
robot's dynamics. These changes can lead to suboptimal flight performance or
even catastrophic failure. Although adaptive control and learning-based methods
can in principle adapt to changes in these hybrid robot-payload systems, rapid
mid-flight adaptation to payloads that have a priori unknown physical
properties remains an open problem. We propose a meta-learning approach that
"learns how to learn" models of altered dynamics within seconds of
post-connection flight data. Our experiments demonstrate that our online
adaptation approach outperforms non-adaptive methods on a series of challenging
suspended payload transportation tasks. Videos and other supplemental material
are available on our website: https://sites.google.com/view/meta-rl-for-flight
</p>
<a href="http://arxiv.org/abs/2004.11345" target="_blank">arXiv:2004.11345</a> [<a href="http://arxiv.org/pdf/2004.11345" target="_blank">pdf</a>]

<h2>Orientation Attentive Robotic Grasp Synthesis with Augmented Grasp Map Representation. (arXiv:2006.05123v2 [cs.RO] UPDATED)</h2>
<h3>Georgia Chalvatzaki, Nikolaos Gkanatsios, Petros Maragos, Jan Peters</h3>
<p>Inherent morphological characteristics in objects may offer a wide range of
plausible grasping orientations that obfuscates the visual learning of robotic
grasping. Existing grasp generation approaches are cursed to construct
discontinuous grasp maps by aggregating annotations for drastically different
orientations per grasping point. Moreover, current methods generate grasp
candidates across a single direction in the robot's viewpoint, ignoring its
feasibility constraints. In this paper, we propose a novel augmented grasp map
representation, suitable for pixel-wise synthesis, that locally disentangles
grasping orientations by partitioning the angle space into multiple bins.
Furthermore, we introduce the ORientation AtteNtive Grasp synthEsis (ORANGE)
framework, that jointly addresses classification into orientation bins and
angle-value regression. The bin-wise orientation maps further serve as an
attention mechanism for areas with higher graspability, i.e. probability of
being an actual grasp point. We report new state-of-the-art 94.71% performance
on Jacquard, with a simple U-Net using only depth images, outperforming even
multi-modal approaches. Subsequent qualitative results with a real bi-manual
robot validate ORANGE's effectiveness in generating grasps for multiple
orientations, hence allowing planning grasps that are feasible.
</p>
<a href="http://arxiv.org/abs/2006.05123" target="_blank">arXiv:2006.05123</a> [<a href="http://arxiv.org/pdf/2006.05123" target="_blank">pdf</a>]

<h2>Reintroducing Straight-Through Estimators as Principled Methods for Stochastic Binary Networks. (arXiv:2006.06880v2 [stat.ML] UPDATED)</h2>
<h3>Alexander Shekhovtsov, Viktor Yanush</h3>
<p>Training neural networks with binary weights and activations is a challenging
problem due to the lack of gradients and difficulty of optimization over
discrete weights. Many successful experimental results have been achieved with
empirical straight-through (ST) approaches, proposing a variety of ad-hoc rules
for propagating gradients through non-differentiable activations and updating
discrete weights. At the same time, ST methods can be truly derived as
estimators in the stochastic binary network (SBN) model with Bernoulli weights.
We advance these derivations to a more complete and systematic study. We
analyze properties, estimation accuracy, obtain different forms of correct ST
estimators for activations and weights, explain existing empirical approaches
and their shortcomings, explain how latent weights arise from the mirror
descent method when optimizing over probabilities. This allows to reintroduce,
once empirical, ST methods as sound approximations, apply them with clarity and
develop further improvements.
</p>
<a href="http://arxiv.org/abs/2006.06880" target="_blank">arXiv:2006.06880</a> [<a href="http://arxiv.org/pdf/2006.06880" target="_blank">pdf</a>]

<h2>Debona: Decoupled Boundary Network Analysis for Tighter Bounds and Faster Adversarial Robustness Proofs. (arXiv:2006.09040v2 [cs.LG] UPDATED)</h2>
<h3>Christopher Brix, Thomas Noll</h3>
<p>Neural networks are commonly used in safety-critical real-world applications.
Unfortunately, the predicted output is often highly sensitive to small, and
possibly imperceptible, changes to the input data. Proving that either no such
adversarial examples exist, or providing a concrete instance, is therefore
crucial to ensure safe applications. As enumerating and testing all potential
adversarial examples is computationally infeasible, verification techniques
have been developed to provide mathematically sound proofs of their absence
using overestimations of the network activations. We propose an improved
technique for computing tight upper and lower bounds of these node values,
based on increased flexibility gained by computing both bounds independently of
each other. Furthermore, we gain an additional improvement by re-implementing
part of the original state-of-the-art software "Neurify", leading to a faster
analysis. Combined, these adaptations reduce the necessary runtime by up to
94%, and allow a successful search for networks and inputs that were previously
too complex. We provide proofs for tight upper and lower bounds on max-pooling
layers in convolutional networks. To ensure widespread usability, we open
source our implementation "Debona", featuring both the implementation specific
enhancements as well as the refined boundary computation for faster and more
exact~results.
</p>
<a href="http://arxiv.org/abs/2006.09040" target="_blank">arXiv:2006.09040</a> [<a href="http://arxiv.org/pdf/2006.09040" target="_blank">pdf</a>]

<h2>Conversational Neuro-Symbolic Commonsense Reasoning. (arXiv:2006.10022v3 [cs.AI] UPDATED)</h2>
<h3>Forough Arabshahi, Jennifer Lee, Mikayla Gawarecki, Kathryn Mazaitis, Amos Azaria, Tom Mitchell</h3>
<p>In order for conversational AI systems to hold more natural and broad-ranging
conversations, they will require much more commonsense, including the ability
to identify unstated presumptions of their conversational partners. For
example, in the command "If it snows at night then wake me up early because I
don't want to be late for work" the speaker relies on commonsense reasoning of
the listener to infer the implicit presumption that they wish to be woken only
if it snows enough to cause traffic slowdowns. We consider here the problem of
understanding such imprecisely stated natural language commands given in the
form of "if-(state), then-(action), because-(goal)" statements. More precisely,
we consider the problem of identifying the unstated presumptions of the speaker
that allow the requested action to achieve the desired goal from the given
state (perhaps elaborated by making the implicit presumptions explicit). We
release a benchmark data set for this task, collected from humans and annotated
with commonsense presumptions. We present a neuro-symbolic theorem prover that
extracts multi-hop reasoning chains, and apply it to this problem. Furthermore,
to accommodate the reality that current AI commonsense systems lack full
coverage, we also present an interactive conversational framework built on our
neuro-symbolic system, that conversationally evokes commonsense knowledge from
humans to complete its reasoning chains.
</p>
<a href="http://arxiv.org/abs/2006.10022" target="_blank">arXiv:2006.10022</a> [<a href="http://arxiv.org/pdf/2006.10022" target="_blank">pdf</a>]

<h2>Efficient Conformal Prediction via Cascaded Inference with Expanded Admission. (arXiv:2007.03114v3 [cs.LG] UPDATED)</h2>
<h3>Adam Fisch, Tal Schuster, Tommi Jaakkola, Regina Barzilay</h3>
<p>In this paper, we present a novel approach for conformal prediction (CP), in
which we aim to identify a set of promising prediction candidates -- in place
of a single prediction. This set is guaranteed to contain a correct answer with
high probability, and is well-suited for many open-ended classification tasks.
In the standard CP paradigm, the predicted set can often be unusably large and
also costly to obtain. This is particularly pervasive in settings where the
correct answer is not unique, and the number of total possible answers is high.
We first expand the CP correctness criterion to allow for additional, inferred
"admissible" answers, which can substantially reduce the size of the predicted
set while still providing valid performance guarantees. Second, we amortize
costs by conformalizing prediction cascades, in which we aggressively prune
implausible labels early on by using progressively stronger classifiers --
again, while still providing valid performance guarantees. We demonstrate the
empirical effectiveness of our approach for multiple applications in natural
language processing and computational chemistry for drug discovery.
</p>
<a href="http://arxiv.org/abs/2007.03114" target="_blank">arXiv:2007.03114</a> [<a href="http://arxiv.org/pdf/2007.03114" target="_blank">pdf</a>]

<h2>Region-based Non-local Operation for Video Classification. (arXiv:2007.09033v5 [cs.CV] UPDATED)</h2>
<h3>Guoxi Huang, Adrian G. Bors</h3>
<p>Convolutional Neural Networks (CNNs) model long-range dependencies by deeply
stacking convolution operations with small window sizes, which makes the
optimizations difficult. This paper presents region-based non-local (RNL)
operations as a family of self-attention mechanisms, which can directly capture
long-range dependencies without using a deep stack of local operations. Given
an intermediate feature map, our method recalibrates the feature at a position
by aggregating the information from the neighboring regions of all positions.
By combining a channel attention module with the proposed RNL, we design an
attention chain, which can be integrated into the off-the-shelf CNNs for
end-to-end training. We evaluate our method on two video classification
benchmarks. The experimental results of our method outperform other attention
mechanisms, and we achieve state-of-the-art performance on the
Something-Something V1 dataset.
</p>
<a href="http://arxiv.org/abs/2007.09033" target="_blank">arXiv:2007.09033</a> [<a href="http://arxiv.org/pdf/2007.09033" target="_blank">pdf</a>]

<h2>Accounting for Unobserved Confounding in Domain Generalization. (arXiv:2007.10653v4 [stat.ML] UPDATED)</h2>
<h3>Alexis Bellot, Mihaela van der Schaar</h3>
<p>The ability to extrapolate, or generalize, from observed to new related
environments is central to any form of reliable machine learning, yet most
methods fail when moving beyond $i.i.d$ data. In some cases, the reason lies in
a misappreciation of the causal structure that governs the data, and in
particular as a consequence of the influence of unobserved confounders that
drive changes in observed distributions and distort correlations. In this
paper, we argue for defining generalization with respect to a broader class of
distribution shifts (defined as arising from interventions in the underlying
causal model), including changes in observed, unobserved and target variable
distributions. We propose a new robust learning principle that may be paired
with any gradient-based learning algorithm. This learning principle has
explicit generalization guarantees, and relates robustness with certain
invariances in the causal model, clarifying why, in some cases, test
performance lags training performance. We demonstrate the empirical performance
of our approach on healthcare data from different modalities, including image
and speech data.
</p>
<a href="http://arxiv.org/abs/2007.10653" target="_blank">arXiv:2007.10653</a> [<a href="http://arxiv.org/pdf/2007.10653" target="_blank">pdf</a>]

<h2>Compact Graph Architecture for Speech Emotion Recognition. (arXiv:2008.02063v4 [cs.CV] UPDATED)</h2>
<h3>A. Shirian, T. Guha</h3>
<p>We propose a deep graph approach to address the task of speech emotion
recognition. A compact, efficient and scalable way to represent data is in the
form of graphs. Following the theory of graph signal processing, we propose to
model speech signal as a cycle graph or a line graph. Such graph structure
enables us to construct a Graph Convolution Network (GCN)-based architecture
that can perform an accurate graph convolution in contrast to the approximate
convolution used in standard GCNs. We evaluated the performance of our model
for speech emotion recognition on the popular IEMOCAP and MSP-IMPROV databases.
Our model outperforms standard GCN and other relevant deep graph architectures
indicating the effectiveness of our approach. When compared with existing
speech emotion recognition methods, our model achieves comparable performance
to the state-of-the-art with significantly fewer learnable parameters (~30K)
indicating its applicability in resource-constrained devices.
</p>
<a href="http://arxiv.org/abs/2008.02063" target="_blank">arXiv:2008.02063</a> [<a href="http://arxiv.org/pdf/2008.02063" target="_blank">pdf</a>]

<h2>Stabilizing Invertible Neural Networks Using Mixture Models. (arXiv:2009.02994v2 [cs.LG] UPDATED)</h2>
<h3>Paul Hagemann, Sebastian Neumayer</h3>
<p>In this paper, we analyze the properties of invertible neural networks, which
provide a way of solving inverse problems. Our main focus lies on investigating
and controlling the Lipschitz constants of the corresponding inverse networks.
Without such an control, numerical simulations are prone to errors and not much
is gained against traditional approaches. Fortunately, our analysis indicates
that changing the latent distribution from a standard normal one to a Gaussian
mixture model resolves the issue of exploding Lipschitz constants. Indeed,
numerical simulations confirm that this modification leads to significantly
improved sampling quality in multimodal applications.
</p>
<a href="http://arxiv.org/abs/2009.02994" target="_blank">arXiv:2009.02994</a> [<a href="http://arxiv.org/pdf/2009.02994" target="_blank">pdf</a>]

<h2>Understanding the Landscape of Sparse Networks: A Brief Investigation. (arXiv:2009.07439v2 [cs.LG] UPDATED)</h2>
<h3>Dachao Lin, Ruoyu Sun, Zhihua Zhang</h3>
<p>Network pruning or network sparsification has a long history and practical
significance in modern applications. The loss surface of dense neural networks
would yield a bad landscape due to non-convexity and non-linear activations,
but over-parameterization may lead to benign geometrical properties. In this
paper, we study sparse networks with the squared loss objective, showing that
like dense networks, sparse networks can still preserve benign landscape when
the last hidden layer width is larger than the number of training data. Our
results have been built on general linear sparse networks, linear CNNs (a
special class of sparse networks), and nonlinear sparse networks. We also
present counterexamples when certain assumptions are violated, which implies
that these assumptions are necessary for our results.
</p>
<a href="http://arxiv.org/abs/2009.07439" target="_blank">arXiv:2009.07439</a> [<a href="http://arxiv.org/pdf/2009.07439" target="_blank">pdf</a>]

<h2>An Intuitive Tutorial to Gaussian Processes Regression. (arXiv:2009.10862v3 [stat.ML] UPDATED)</h2>
<h3>Jie Wang</h3>
<p>This tutorial aims to provide an intuitive understanding of the Gaussian
processes regression. Gaussian processes regression (GPR) models have been
widely used in machine learning applications because of their representation
flexibility and inherently uncertainty measures over predictions. The basic
concepts that a Gaussian process is built on, including multivariate normal
distribution, kernels, non-parametric models, joint and conditional probability
were explained first. Next, the GPR was described concisely together with an
implementation of a standard GPR algorithm. Beyond the standard GPR, packages
to implement state-of-the-art Gaussian processes algorithms were reviewed. This
tutorial was written in an accessible way to make sure readers without a
machine learning background can obtain a good understanding of the GPR basics.
</p>
<a href="http://arxiv.org/abs/2009.10862" target="_blank">arXiv:2009.10862</a> [<a href="http://arxiv.org/pdf/2009.10862" target="_blank">pdf</a>]

<h2>Graph-based methods for analyzing orchard tree structure using noisy point cloud data. (arXiv:2009.13727v2 [cs.CV] UPDATED)</h2>
<h3>Fredrik Westling, Dr James Underwood, Dr Mitch Bryson</h3>
<p>Digitisation of fruit trees using LiDAR enables analysis which can be used to
better growing practices to improve yield. Sophisticated analysis requires
geometric and semantic understanding of the data, including the ability to
discern individual trees as well as identifying leafy and structural matter.
Extraction of this information should be rapid, as should data capture, so that
entire orchards can be processed, but existing methods for classification and
segmentation rely on high-quality data or additional data sources like cameras.
We present a method for analysis of LiDAR data specifically for individual tree
location, segmentation and matter classification, which can operate on
low-quality data captured by handheld or mobile LiDAR. Our methods for tree
location and segmentation improved on existing methods with an F1 score of
0.774 and a v-measure of 0.915 respectively, while trunk matter classification
performed poorly in absolute terms with an average F1 score of 0.490 on real
data, though consistently outperformed existing methods and displayed a
significantly shorter runtime.
</p>
<a href="http://arxiv.org/abs/2009.13727" target="_blank">arXiv:2009.13727</a> [<a href="http://arxiv.org/pdf/2009.13727" target="_blank">pdf</a>]

<h2>Beneficial Perturbation Network for designing general adaptive artificial intelligence systems. (arXiv:2009.13954v2 [cs.CV] UPDATED)</h2>
<h3>Shixian Wen, Amanda Rios, Yunhao Ge, Laurent Itti</h3>
<p>The human brain is the gold standard of adaptive learning. It not only can
learn and benefit from experience, but also can adapt to new situations. In
contrast, deep neural networks only learn one sophisticated but fixed mapping
from inputs to outputs. This limits their applicability to more dynamic
situations, where input to output mapping may change with different contexts. A
salient example is continual learning - learning new independent tasks
sequentially without forgetting previous tasks. Continual learning of multiple
tasks in artificial neural networks using gradient descent leads to
catastrophic forgetting, whereby a previously learned mapping of an old task is
erased when learning new mappings for new tasks. Here, we propose a new
biologically plausible type of deep neural network with extra, out-of-network,
task-dependent biasing units to accommodate these dynamic situations. This
allows, for the first time, a single network to learn potentially unlimited
parallel input to output mappings, and to switch on the fly between them at
runtime. Biasing units are programmed by leveraging beneficial perturbations
(opposite to well-known adversarial perturbations) for each task. Beneficial
perturbations for a given task bias the network toward that task, essentially
switching the network into a different mode to process that task. This largely
eliminates catastrophic interference between tasks. Our approach is
memory-efficient and parameter-efficient, can accommodate many tasks, and
achieves state-of-the-art performance across different tasks and domains.
</p>
<a href="http://arxiv.org/abs/2009.13954" target="_blank">arXiv:2009.13954</a> [<a href="http://arxiv.org/pdf/2009.13954" target="_blank">pdf</a>]

<h2>Explainable Deep Reinforcement Learning for UAV Autonomous Navigation. (arXiv:2009.14551v2 [cs.RO] UPDATED)</h2>
<h3>Lei He, Aouf Nabil, Bifeng Song</h3>
<p>Autonomous navigation in unknown complex environment is still a hard problem,
especially for small Unmanned Aerial Vehicles (UAVs) with limited computation
resources. In this paper, a neural network-based reactive controller is
proposed for a quadrotor to fly autonomously in unknown outdoor environment.
The navigation controller makes use of only current sensor data to generate the
control signal without any optimization or configuration space searching, which
reduces both memory and computation requirement. The navigation problem is
modelled as a Markov Decision Process (MDP) and solved using deep reinforcement
learning (DRL) method. Specifically, to get better understanding of the trained
network, some model explanation methods are proposed. Based on the feature
attribution, each decision making result during flight is explained using both
visual and texture explanation. Moreover, some global analysis are also
provided for experts to evaluate and improve the trained neural network. The
simulation results illustrated the proposed method can make useful and
reasonable explanation for the trained model, which is beneficial for both
non-expert users and controller designer. Finally, the real world tests shown
the proposed controller can navigate the quadrotor to goal position
successfully and the reactive controller performs much faster than some
conventional approach under the same computation resource.
</p>
<a href="http://arxiv.org/abs/2009.14551" target="_blank">arXiv:2009.14551</a> [<a href="http://arxiv.org/pdf/2009.14551" target="_blank">pdf</a>]

<h2>Guided Curriculum Learning for Walking Over Complex Terrain. (arXiv:2010.03848v2 [cs.RO] UPDATED)</h2>
<h3>Brendan Tidd, Nicolas Hudson, Akansel Cosgun</h3>
<p>Reliable bipedal walking over complex terrain is a challenging problem, using
a curriculum can help learning. Curriculum learning is the idea of starting
with an achievable version of a task and increasing the difficulty as a success
criteria is met. We propose a 3-stage curriculum to train Deep Reinforcement
Learning policies for bipedal walking over various challenging terrains. In the
first stage, the agent starts on an easy terrain and the terrain difficulty is
gradually increased, while forces derived from a target policy are applied to
the robot joints and the base. In the second stage, the guiding forces are
gradually reduced to zero. Finally, in the third stage, random perturbations
with increasing magnitude are applied to the robot base, so the robustness of
the policies are improved. In simulation experiments, we show that our approach
is effective in learning walking policies, separate from each other, for five
terrain types: flat, hurdles, gaps, stairs, and steps. Moreover, we demonstrate
that in the absence of human demonstrations, a simple hand designed walking
trajectory is a sufficient prior to learn to traverse complex terrain types. In
ablation studies, we show that taking out any one of the three stages of the
curriculum degrades the learning performance.
</p>
<a href="http://arxiv.org/abs/2010.03848" target="_blank">arXiv:2010.03848</a> [<a href="http://arxiv.org/pdf/2010.03848" target="_blank">pdf</a>]

<h2>R-GAP: Recursive Gradient Attack on Privacy. (arXiv:2010.07733v2 [cs.LG] UPDATED)</h2>
<h3>Junyi Zhu, Matthew Blaschko</h3>
<p>Federated learning frameworks have been regarded as a promising approach to
break the dilemma between demands on privacy and the promise of learning from
large collections of distributed data. Many such frameworks only ask
collaborators to share their local update of a common model, i.e. gradients
with respect to locally stored data, instead of exposing their raw data to
other collaborators. However, recent optimization-based gradient attacks show
that raw data can often be accurately recovered from gradients. It has been
shown that minimizing the Euclidean distance between true gradients and those
calculated from estimated data is often effective in fully recovering private
data. However, there is a fundamental lack of theoretical understanding of how
and when gradients can lead to unique recovery of original data. Our research
fills this gap by providing a closed-form recursive procedure to recover data
from gradients in deep neural networks. We name it Recursive Gradient Attack on
Privacy (R-GAP). Experimental results demonstrate that R-GAP works as well as
or even better than optimization-based approaches at a fraction of the
computation under certain conditions. Additionally, we propose a Rank Analysis
method, which can be used to estimate the risk of gradient attacks inherent in
certain network architectures, regardless of whether an optimization-based or
closed-form-recursive attack is used. Experimental results demonstrate the
utility of the rank analysis towards improving the network's security. Source
code is available for download from https://github.com/JunyiZhu-AI/R-GAP.
</p>
<a href="http://arxiv.org/abs/2010.07733" target="_blank">arXiv:2010.07733</a> [<a href="http://arxiv.org/pdf/2010.07733" target="_blank">pdf</a>]

<h2>Sufficient dimension reduction for classification using principal optimal transport direction. (arXiv:2010.09921v4 [cs.LG] UPDATED)</h2>
<h3>Cheng Meng, Jun Yu, Jingyi Zhang, Ping Ma, Wenxuan Zhong</h3>
<p>Sufficient dimension reduction is used pervasively as a supervised dimension
reduction approach. Most existing sufficient dimension reduction methods are
developed for data with a continuous response and may have an unsatisfactory
performance for the categorical response, especially for the binary-response.
To address this issue, we propose a novel estimation method of sufficient
dimension reduction subspace (SDR subspace) using optimal transport. The
proposed method, named principal optimal transport direction (POTD), estimates
the basis of the SDR subspace using the principal directions of the optimal
transport coupling between the data respecting different response categories.
The proposed method also reveals the relationship among three seemingly
irrelevant topics, i.e., sufficient dimension reduction, support vector
machine, and optimal transport. We study the asymptotic properties of POTD and
show that in the cases when the class labels contain no error, POTD estimates
the SDR subspace exclusively. Empirical studies show POTD outperforms most of
the state-of-the-art linear dimension reduction methods.
</p>
<a href="http://arxiv.org/abs/2010.09921" target="_blank">arXiv:2010.09921</a> [<a href="http://arxiv.org/pdf/2010.09921" target="_blank">pdf</a>]

<h2>Regret-optimal control in dynamic environments. (arXiv:2010.10473v2 [cs.LG] UPDATED)</h2>
<h3>Gautam Goel, Babak Hassibi</h3>
<p>We consider control in linear time-varying dynamical systems from the
perspective of regret minimization. Unlike most prior work in this area, we
focus on the problem of designing an online controller which minimizes regret
against the best dynamic sequence of control actions selected in hindsight
(dynamic regret), instead of the best fixed controller in some specific class
of controllers (static regret). This formulation is attractive when the
environment changes over time and no single controller achieves good
performance over the entire time horizon. We derive the state-space structure
of the regret-optimal controller via a novel reduction to $H_{\infty}$ control
and present a tight data-dependent bound on its regret in terms of the energy
of the disturbance. Our results easily extend to the model-predictive setting
where the controller can anticipate future disturbances and to settings where
the controller only affects the system dynamics after a fixed delay. We present
numerical experiments which show that our regret-optimal controller
interpolates between the performance of the $H_2$-optimal and
$H_{\infty}$-optimal controllers across stochastic and adversarial
environments.
</p>
<a href="http://arxiv.org/abs/2010.10473" target="_blank">arXiv:2010.10473</a> [<a href="http://arxiv.org/pdf/2010.10473" target="_blank">pdf</a>]

<h2>Cross-Modal Information Maximization for Medical Imaging: CMIM. (arXiv:2010.10593v3 [cs.CV] UPDATED)</h2>
<h3>Tristan Sylvain, Francis Dutil, Tess Berthier, Lisa Di Jorio, Margaux Luck, Devon Hjelm, Yoshua Bengio</h3>
<p>In hospitals, data are siloed to specific information systems that make the
same information available under different modalities such as the different
medical imaging exams the patient undergoes (CT scans, MRI, PET, Ultrasound,
etc.) and their associated radiology reports. This offers unique opportunities
to obtain and use at train-time those multiple views of the same information
that might not always be available at test-time.

In this paper, we propose an innovative framework that makes the most of
available data by learning good representations of a multi-modal input that are
resilient to modality dropping at test-time, using recent advances in mutual
information maximization. By maximizing cross-modal information at train time,
we are able to outperform several state-of-the-art baselines in two different
settings, medical image classification, and segmentation. In particular, our
method is shown to have a strong impact on the inference-time performance of
weaker modalities.
</p>
<a href="http://arxiv.org/abs/2010.10593" target="_blank">arXiv:2010.10593</a> [<a href="http://arxiv.org/pdf/2010.10593" target="_blank">pdf</a>]

<h2>Deep DA for Ordinal Regression of Pain Intensity Estimation Using Weakly-Labeled Videos. (arXiv:2010.15675v2 [cs.CV] UPDATED)</h2>
<h3>Gnana Praveen R, Eric Granger, Patrick Cardinal</h3>
<p>Automatic estimation of pain intensity from facial expressions in videos has
an immense potential in health care applications. However, domain adaptation
(DA) is needed to alleviate the problem of domain shifts that typically occurs
between video data captured in source and target do-mains. Given the laborious
task of collecting and annotating videos, and the subjective bias due to
ambiguity among adjacent intensity levels, weakly-supervised learning (WSL)is
gaining attention in such applications. Yet, most state-of-the-art WSL models
are typically formulated as regression problems, and do not leverage the
ordinal relation between intensity levels, nor the temporal coherence of
multiple consecutive frames. This paper introduces a new deep learn-ing model
for weakly-supervised DA with ordinal regression(WSDA-OR), where videos in
target domain have coarse la-bels provided on a periodic basis. The WSDA-OR
model enforces ordinal relationships among the intensity levels as-signed to
the target sequences, and associates multiple relevant frames to sequence-level
labels (instead of a single frame). In particular, it learns discriminant and
domain-invariant feature representations by integrating multiple in-stance
learning with deep adversarial DA, where soft Gaussian labels are used to
efficiently represent the weak ordinal sequence-level labels from the target
domain. The proposed approach was validated on the RECOLA video dataset as
fully-labeled source domain, and UNBC-McMaster video data as weakly-labeled
target domain. We have also validated WSDA-OR on BIOVID and Fatigue (private)
datasets for sequence level estimation. Experimental results indicate that our
approach can provide a significant improvement over the state-of-the-art
models, allowing to achieve a greater localization accuracy.
</p>
<a href="http://arxiv.org/abs/2010.15675" target="_blank">arXiv:2010.15675</a> [<a href="http://arxiv.org/pdf/2010.15675" target="_blank">pdf</a>]

<h2>Leveraging Activity Recognition to Enable Protective Behavior Detection in Continuous Data. (arXiv:2011.01776v4 [cs.LG] UPDATED)</h2>
<h3>Chongyang Wang, Yuan Gao, Akhil Mathur, Amanda C. De C. Williams, Nicholas D. Lane, Nadia Bianchi-Berthouze</h3>
<p>Protective behavior exhibited by people with chronic pain (CP) during
physical activities is the key to understanding their physical and emotional
states. Existing automatic protective behavior detection (PBD) methods rely on
pre-segmentation of activities predefined by users. However, in real life,
people perform activities casually. Therefore, where those activities present
difficulties for people with chronic pain, technology-enabled support should be
delivered continuously and automatically adapted to activity type and
occurrence of protective behavior. Hence, to facilitate ubiquitous CP
management, it becomes critical to enable accurate PBD over continuous data. In
this paper, we propose to integrate human activity recognition (HAR) with PBD
via a novel hierarchical HAR-PBD architecture comprising graph-convolution and
long short-term memory (GC-LSTM) networks, and alleviate class imbalances using
a class-balanced focal categorical-cross-entropy (CFCC) loss. Through in-depth
evaluation of the approach using a CP patients' dataset, we show that the
leveraging of HAR, GC-LSTM networks, and CFCC loss leads to clear increase in
PBD performance against the baseline (macro F1 score of 0.81 vs. 0.66 and
precision-recall area-under-the-curve (PR-AUC) of 0.60 vs. 0.44). We conclude
by discussing possible use cases of the hierarchical architecture in CP
management and beyond. We also discuss current limitations and ways forward.
</p>
<a href="http://arxiv.org/abs/2011.01776" target="_blank">arXiv:2011.01776</a> [<a href="http://arxiv.org/pdf/2011.01776" target="_blank">pdf</a>]

<h2>Leveraging Regular Fundus Images for Training UWF Fundus Diagnosis Models via Adversarial Learning and Pseudo-Labeling. (arXiv:2011.13816v2 [cs.CV] UPDATED)</h2>
<h3>Lie Ju, Xin Wang, Xin Zhao, Paul Bonnington, Tom Drummond, Zongyuan Ge</h3>
<p>Recently, ultra-widefield (UWF) 200\degree~fundus imaging by Optos cameras
has gradually been introduced because of its broader insights for detecting
more information on the fundus than regular 30 degree - 60 degree fundus
cameras. Compared with UWF fundus images, regular fundus images contain a large
amount of high-quality and well-annotated data. Due to the domain gap, models
trained by regular fundus images to recognize UWF fundus images perform poorly.
Hence, given that annotating medical data is labor intensive and time
consuming, in this paper, we explore how to leverage regular fundus images to
improve the limited UWF fundus data and annotations for more efficient
training. We propose the use of a modified cycle generative adversarial network
(CycleGAN) model to bridge the gap between regular and UWF fundus and generate
additional UWF fundus images for training. A consistency regularization term is
proposed in the loss of the GAN to improve and regulate the quality of the
generated data. Our method does not require that images from the two domains be
paired or even that the semantic labels be the same, which provides great
convenience for data collection. Furthermore, we show that our method is robust
to noise and errors introduced by the generated unlabeled data with the
pseudo-labeling technique. We evaluated the effectiveness of our methods on
several common fundus diseases and tasks, such as diabetic retinopathy (DR)
classification, lesion detection and tessellated fundus segmentation. The
experimental results demonstrate that our proposed method simultaneously
achieves superior generalizability of the learned representations and
performance improvements in multiple tasks.
</p>
<a href="http://arxiv.org/abs/2011.13816" target="_blank">arXiv:2011.13816</a> [<a href="http://arxiv.org/pdf/2011.13816" target="_blank">pdf</a>]

<h2>Self-correcting Q-Learning. (arXiv:2012.01100v2 [cs.LG] UPDATED)</h2>
<h3>Rong Zhu, Mattia Rigotti</h3>
<p>The Q-learning algorithm is known to be affected by the maximization bias,
i.e. the systematic overestimation of action values, an important issue that
has recently received renewed attention. Double Q-learning has been proposed as
an efficient algorithm to mitigate this bias. However, this comes at the price
of an underestimation of action values, in addition to increased memory
requirements and a slower convergence. In this paper, we introduce a new way to
address the maximization bias in the form of a "self-correcting algorithm" for
approximating the maximum of an expected value. Our method balances the
overestimation of the single estimator used in conventional Q-learning and the
underestimation of the double estimator used in Double Q-learning. Applying
this strategy to Q-learning results in Self-correcting Q-learning. We show
theoretically that this new algorithm enjoys the same convergence guarantees as
Q-learning while being more accurate. Empirically, it performs better than
Double Q-learning in domains with rewards of high variance, and it even attains
faster convergence than Q-learning in domains with rewards of zero or low
variance. These advantages transfer to a Deep Q Network implementation that we
call Self-correcting DQN and which outperforms regular DQN and Double DQN on
several tasks in the Atari 2600 domain.
</p>
<a href="http://arxiv.org/abs/2012.01100" target="_blank">arXiv:2012.01100</a> [<a href="http://arxiv.org/pdf/2012.01100" target="_blank">pdf</a>]

<h2>Flexible, Non-parametric Modeling Using Regularized Neural Networks. (arXiv:2012.11369v2 [cs.LG] UPDATED)</h2>
<h3>Oskar Allerbo, Rebecka J&#xf6;rnsten</h3>
<p>Non-parametric regression, such as generalized additive models (GAMs), is
able to capture complex data dependencies in a flexible, yet interpretable way.
However, choosing the format of the additive components often requires
non-trivial data exploration. Here, we propose an alternative to GAMs,
PrAda-net, which uses a one hidden layer neural network, trained with proximal
gradient descent and adaptive lasso. PrAda-net automatically adjusts the size
and architecture of the neural network to capture the complexity and structure
of the underlying data generative model. The compact network obtained by
PrAda-net can be translated to additive model components, making it suitable
for non-parametric statistical modelling with automatic model selection. We
demonstrate PrAda-net on simulated data, where we compare the test error
performance, variable importance and variable subset identification properties
of PrAda-net to other lasso-based approaches. We also apply Prada-net to the
massive U.K. black smoke data set, to demonstrate the capability of using
Prada-net as an alternative to GAMs. In contrast to GAMs, which often require
domain knowledge to select the functional forms of the additive components,
Prada-net requires no such pre-selection while still resulting in interpretable
additive components.
</p>
<a href="http://arxiv.org/abs/2012.11369" target="_blank">arXiv:2012.11369</a> [<a href="http://arxiv.org/pdf/2012.11369" target="_blank">pdf</a>]

<h2>Towards the Localisation of Lesions in Diabetic Retinopathy. (arXiv:2012.11432v2 [cs.CV] UPDATED)</h2>
<h3>Samuel Ofosu Mensah, Bubacarr Bah, Willie Brink</h3>
<p>Convolutional Neural Networks (CNNs) have successfully been used to classify
diabetic retinopathy (DR) fundus images in recent times. However, deeper
representations in CNNs may capture higher-level semantics at the expense of
spatial resolution. To make predictions usable for ophthalmologists, we use a
post-attention technique called Gradient-weighted Class Activation Mapping
(Grad-CAM) on the penultimate layer of deep learning models to produce coarse
localisation maps on DR fundus images. This is to help identify discriminative
regions in the images, consequently providing evidence for ophthalmologists to
make a diagnosis and potentially save lives by early diagnosis. Specifically,
this study uses pre-trained weights from four state-of-the-art deep learning
models to produce and compare localisation maps of DR fundus images. The models
used include VGG16, ResNet50, InceptionV3, and InceptionResNetV2. We find that
InceptionV3 achieves the best performance with a test classification accuracy
of 96.07%, and localise lesions better and faster than the other models.
</p>
<a href="http://arxiv.org/abs/2012.11432" target="_blank">arXiv:2012.11432</a> [<a href="http://arxiv.org/pdf/2012.11432" target="_blank">pdf</a>]

<h2>A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v7 [cs.LG] UPDATED)</h2>
<h3>Felix Leibfried, Vincent Dutordoir, ST John, Nicolas Durrande</h3>
<p>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model enjoys a posterior in closed form. However, identifying the posterior GP
scales cubically with the number of training examples and requires to store all
examples in memory. In order to overcome these obstacles, sparse GPs have been
proposed that approximate the true posterior GP with pseudo-training examples.
Importantly, the number of pseudo-training examples is user-defined and enables
control over computational and memory complexity. In the general case, sparse
GPs do not enjoy closed-form solutions and one has to resort to approximate
inference. In this context, a convenient choice for approximate inference is
variational inference (VI), where the problem of Bayesian inference is cast as
an optimization problem -- namely, to maximize a lower bound of the log
marginal likelihood. This paves the way for a powerful and versatile framework,
where pseudo-training examples are treated as optimization arguments of the
approximate posterior that are jointly identified together with hyperparameters
of the generative model (i.e. prior and likelihood). The framework can
naturally handle a wide scope of supervised learning problems, ranging from
regression with heteroscedastic and non-Gaussian likelihoods to classification
problems with discrete labels, but also multilabel problems. The purpose of
this tutorial is to provide access to the basic matter for readers without
prior knowledge in both GPs and VI. A proper exposition to the subject enables
also access to more recent advances (like importance-weighted VI as well as
inderdomain, multioutput and deep GPs) that can serve as an inspiration for new
research ideas.
</p>
<a href="http://arxiv.org/abs/2012.13962" target="_blank">arXiv:2012.13962</a> [<a href="http://arxiv.org/pdf/2012.13962" target="_blank">pdf</a>]

<h2>Weight-of-evidence 2.0 with shrinkage and spline-binning. (arXiv:2101.01494v2 [stat.ML] UPDATED)</h2>
<h3>Jakob Raymaekers, Wouter Verbeke, Tim Verdonck</h3>
<p>In many practical applications, such as fraud detection, credit risk modeling
or medical decision making, classification models for assigning instances to a
predefined set of classes are required to be both precise as well as
interpretable. Linear modeling methods such as logistic regression are often
adopted, since they offer an acceptable balance between precision and
interpretability. Linear methods, however, are not well equipped to handle
categorical predictors with high-cardinality or to exploit non-linear relations
in the data. As a solution, data preprocessing methods such as
weight-of-evidence are typically used for transforming the predictors. The
binning procedure that underlies the weight-of-evidence approach, however, has
been little researched and typically relies on ad-hoc or expert driven
procedures. The objective in this paper, therefore, is to propose a formalized,
data-driven and powerful method.

To this end, we explore the discretization of continuous variables through
the binning of spline functions, which allows for capturing non-linear effects
in the predictor variables and yields highly interpretable predictors taking
only a small number of discrete values. Moreover, we extend upon the
weight-of-evidence approach and propose to estimate the proportions using
shrinkage estimators. Together, this offers an improved ability to exploit both
non-linear and categorical predictors for achieving increased classification
precision, while maintaining interpretability of the resulting model and
decreasing the risk of overfitting.

We present the results of a series of experiments in a fraud detection
setting, which illustrate the effectiveness of the presented approach. We
facilitate reproduction of the presented results and adoption of the proposed
approaches by providing both the dataset and the code for implementing the
experiments and the presented approach.
</p>
<a href="http://arxiv.org/abs/2101.01494" target="_blank">arXiv:2101.01494</a> [<a href="http://arxiv.org/pdf/2101.01494" target="_blank">pdf</a>]

<h2>Directed Acyclic Graph Neural Networks. (arXiv:2101.07965v3 [cs.LG] UPDATED)</h2>
<h3>Veronika Thost, Jie Chen</h3>
<p>Graph-structured data ubiquitously appears in science and engineering. Graph
neural networks (GNNs) are designed to exploit the relational inductive bias
exhibited in graphs; they have been shown to outperform other forms of neural
networks in scenarios where structure information supplements node features.
The most common GNN architecture aggregates information from neighborhoods
based on message passing. Its generality has made it broadly applicable. In
this paper, we focus on a special, yet widely used, type of graphs -- DAGs --
and inject a stronger inductive bias -- partial ordering -- into the neural
network design. We propose the \emph{directed acyclic graph neural network},
DAGNN, an architecture that processes information according to the flow defined
by the partial order. DAGNN can be considered a framework that entails earlier
works as special cases (e.g., models for trees and models updating node
representations recurrently), but we identify several crucial components that
prior architectures lack. We perform comprehensive experiments, including
ablation studies, on representative DAG datasets (i.e., source code, neural
architectures, and probabilistic graphical models) and demonstrate the
superiority of DAGNN over simpler DAG architectures as well as general graph
architectures.
</p>
<a href="http://arxiv.org/abs/2101.07965" target="_blank">arXiv:2101.07965</a> [<a href="http://arxiv.org/pdf/2101.07965" target="_blank">pdf</a>]

<h2>Unifying Cardiovascular Modelling with Deep Reinforcement Learning for Uncertainty Aware Control of Sepsis Treatment. (arXiv:2101.08477v2 [cs.LG] UPDATED)</h2>
<h3>Thesath Nanayakkara, Gilles Clermont, Christopher James Langmead, David Swigon</h3>
<p>Sepsis is the leading cause of mortality in the ICU, responsible for 6% of
all hospitalizations and 35% of all in-hospital deaths in USA. However, there
is no universally agreed upon strategy for vasopressor and fluid
administration. It has also been observed that different patients respond
differently to treatment, highlighting the need for individualized treatment.
Vasopressors and fluids are administrated with specific effects to
cardiovascular physiology in mind and medical research has suggested that
physiologic, hemodynamically guided, approaches to treatment. Thus we propose a
novel approach, exploiting and unifying complementary strengths of Mathematical
Modelling, Deep Learning, Reinforcement Learning and Uncertainty
Quantification, to learn individualized, safe, and uncertainty aware treatment
strategies. We first infer patient-specific, dynamic cardiovascular states
using a novel physiology-driven recurrent neural network trained in an
unsupervised manner. This information, along with a learned low dimensional
representation of the patient's lab history and observable data, is then used
to derive value distributions using Batch Distributional Reinforcement
Learning. Moreover in a safety critical domain it is essential to know what our
agent does and does not know, for this we also quantify the model uncertainty
associated with each patient state and action, and propose a general framework
for uncertainty aware, interpretable treatment policies. This framework can be
tweaked easily, to reflect a clinician's own confidence of the framework, and
can be easily modified to factor in human expert opinion, whenever it's
accessible. Using representative patients and a validation cohort, we show that
our method has learned physiologically interpretable generalizable policies.
</p>
<a href="http://arxiv.org/abs/2101.08477" target="_blank">arXiv:2101.08477</a> [<a href="http://arxiv.org/pdf/2101.08477" target="_blank">pdf</a>]

<h2>Learn to Dance with AIST++: Music Conditioned 3D Dance Generation. (arXiv:2101.08779v2 [cs.CV] UPDATED)</h2>
<h3>Ruilong Li, Shan Yang, David A. Ross, Angjoo Kanazawa</h3>
<p>In this paper, we present a transformer-based learning framework for 3D dance
generation conditioned on music. We carefully design our network architecture
and empirically study the keys for obtaining qualitatively pleasing results.
The critical components include a deep cross-modal transformer, which well
learns the correlation between the music and dance motion; and the
full-attention with future-N supervision mechanism which is essential in
producing long-range non-freezing motion. In addition, we propose a new dataset
of paired 3D motion and music called AIST++, which we reconstruct from the AIST
multi-view dance videos. This dataset contains 1.1M frames of 3D dance motion
in 1408 sequences, covering 10 genres of dance choreographies and accompanied
with multi-view camera parameters. To our knowledge it is the largest dataset
of this kind. Rich experiments on AIST++ demonstrate our method produces much
better results than the state-of-the-art methods both qualitatively and
quantitatively.
</p>
<a href="http://arxiv.org/abs/2101.08779" target="_blank">arXiv:2101.08779</a> [<a href="http://arxiv.org/pdf/2101.08779" target="_blank">pdf</a>]

<h2>Breaking the Deadly Triad with a Target Network. (arXiv:2101.08862v2 [cs.LG] UPDATED)</h2>
<h3>Shangtong Zhang, Hengshuai Yao, Shimon Whiteson</h3>
<p>The deadly triad refers to the instability of a reinforcement learning
algorithm when it employs off-policy learning, function approximation, and
bootstrapping simultaneously. In this paper, we investigate the target network
as a tool for breaking the deadly triad, providing theoretical support for the
conventional wisdom that a target network stabilizes training. We first propose
and analyze a novel target network update rule which augments the commonly used
Polyak-averaging style update with two projections. We then apply the target
network and ridge regularization in several divergent algorithms and show their
convergence to regularized TD fixed points. Those algorithms are off-policy
with linear function approximation and bootstrapping, spanning both policy
evaluation and control, as well as both discounted and average-reward settings.
In particular, we provide the first convergent linear $Q$-learning algorithms
under nonrestrictive and changing behavior policies without bi-level
optimization.
</p>
<a href="http://arxiv.org/abs/2101.08862" target="_blank">arXiv:2101.08862</a> [<a href="http://arxiv.org/pdf/2101.08862" target="_blank">pdf</a>]

<h2>How do some Bayesian Network machine learned graphs compare to causal knowledge?. (arXiv:2101.10461v2 [cs.AI] UPDATED)</h2>
<h3>Anthony C. Constantinou, Norman Fenton, Martin Neil</h3>
<p>The graph of a Bayesian Network (BN) can be machine learned, determined by
causal knowledge, or a combination of both. In disciplines like bioinformatics,
applying BN structure learning algorithms can reveal new insights that would
otherwise remain unknown. However, these algorithms are less effective when the
input data are limited in terms of sample size, which is often the case when
working with real data. This paper focuses on purely machine learned and purely
knowledge-based BNs and investigates their differences in terms of graphical
structure and how well the implied statistical models explain the data. The
tests are based on four previous case studies whose BN structure was determined
by domain knowledge. Using various metrics, we compare the knowledge-based
graphs to the machine learned graphs generated from various algorithms
implemented in TETRAD spanning all three classes of learning. The results show
that, while the algorithms produce graphs with much higher model selection
score, the knowledge-based graphs are more accurate predictors of variables of
interest. Maximising score fitting is ineffective in the presence of limited
sample size because the fitting becomes increasingly distorted with limited
data, guiding algorithms towards graphical patterns that share higher fitting
scores and yet deviate considerably from the true graph. This highlights the
value of causal knowledge in these cases, as well as the need for more
appropriate fitting scores suitable for limited data. Lastly, the experiments
also provide new evidence that support the notion that results from simulated
data tell us little about actual real-world performance.
</p>
<a href="http://arxiv.org/abs/2101.10461" target="_blank">arXiv:2101.10461</a> [<a href="http://arxiv.org/pdf/2101.10461" target="_blank">pdf</a>]

<h2>Generative Adversarial Network using Perturbed-Convolutions. (arXiv:2101.10841v2 [cs.CV] UPDATED)</h2>
<h3>Seung Park, Yoon-Jae Yeo, Yong-Goo Shin</h3>
<p>Despite growing insights into the GAN training, it still suffers from
instability during the training procedure. To alleviate this problem, this
paper presents a novel convolutional layer, called perturbed-convolution
(PConv), which focuses on achieving two goals simultaneously: penalize the
discriminator for training GAN stably and prevent the overfitting problem in
the discriminator. PConv generates perturbed features by randomly disturbing an
input tensor before performing the convolution operation. This approach is
simple but surprisingly effective. First, to reliably classify real and
generated samples using the disturbed input tensor, the intermediate layers in
the discriminator should learn features having a small local Lipschitz value.
Second, due to the perturbed features in PConv, the discriminator is difficult
to memorize the real images; this makes the discriminator avoid the overfitting
problem. To show the generalization ability of the proposed method, we
conducted extensive experiments with various loss functions and datasets
including CIFAR-10, CelebA-HQ, LSUN, and tiny-ImageNet. Quantitative
evaluations demonstrate that WCL significantly improves the performance of GAN
and conditional GAN in terms of Frechet inception distance (FID). For instance,
the proposed method improves FID scores on the tiny-ImageNet dataset from 58.59
to 50.42.
</p>
<a href="http://arxiv.org/abs/2101.10841" target="_blank">arXiv:2101.10841</a> [<a href="http://arxiv.org/pdf/2101.10841" target="_blank">pdf</a>]

<h2>Safe Multi-Agent Reinforcement Learning via Shielding. (arXiv:2101.11196v2 [cs.LG] UPDATED)</h2>
<h3>Ingy Elsayed-Aly, Suda Bharadwaj, Christopher Amato, R&#xfc;diger Ehlers, Ufuk Topcu, Lu Feng</h3>
<p>Multi-agent reinforcement learning (MARL) has been increasingly used in a
wide range of safety-critical applications, which require guaranteed safety
(e.g., no unsafe states are ever visited) during the learning
process.Unfortunately, current MARL methods do not have safety guarantees.
Therefore, we present two shielding approaches for safe MARL. In centralized
shielding, we synthesize a single shield to monitor all agents' joint actions
and correct any unsafe action if necessary. In factored shielding, we
synthesize multiple shields based on a factorization of the joint state space
observed by all agents; the set of shields monitors agents concurrently and
each shield is only responsible for a subset of agents at each
step.Experimental results show that both approaches can guarantee the safety of
agents during learning without compromising the quality of learned policies;
moreover, factored shielding is more scalable in the number of agents than
centralized shielding.
</p>
<a href="http://arxiv.org/abs/2101.11196" target="_blank">arXiv:2101.11196</a> [<a href="http://arxiv.org/pdf/2101.11196" target="_blank">pdf</a>]

<h2>Puzzle-CAM: Improved localization via matching partial and full features. (arXiv:2101.11253v3 [cs.CV] UPDATED)</h2>
<h3>Sanghyun Jo, In-Jae Yu</h3>
<p>Weakly-supervised semantic segmentation (WSSS) is introduced to narrow the
gap for semantic segmentation performance from pixel-level supervision to
image-level supervision. Most advanced approaches are based on class activation
maps (CAMs) to generate pseudo-labels to train the segmentation network. The
main limitation of WSSS is that the process of generating pseudo-labels from
CAMs that use an image classifier is mainly focused on the most discriminative
parts of the objects. To address this issue, we propose Puzzle-CAM, a process
that minimizes differences between the features from separate patches and the
whole image. Our method consists of a puzzle module and two regularization
terms to discover the most integrated region in an object. Puzzle-CAM can
activate the overall region of an object using image-level supervision without
requiring extra parameters. % In experiments, Puzzle-CAM outperformed previous
state-of-the-art methods using the same labels for supervision on the PASCAL
VOC 2012 test dataset. In experiments, Puzzle-CAM outperformed previous
state-of-the-art methods using the same labels for supervision on the PASCAL
VOC 2012 dataset. Code associated with our experiments is available at
https://github.com/OFRIN/PuzzleCAM.
</p>
<a href="http://arxiv.org/abs/2101.11253" target="_blank">arXiv:2101.11253</a> [<a href="http://arxiv.org/pdf/2101.11253" target="_blank">pdf</a>]

<h2>Learning Matching Representations for Individualized Organ Transplantation Allocation. (arXiv:2101.11769v2 [stat.ML] UPDATED)</h2>
<h3>Can Xu, Ahmed M. Alaa, Ioana Bica, Brent D. Ershoff, Maxime Cannesson, Mihaela van der Schaar</h3>
<p>Organ transplantation is often the last resort for treating end-stage
illness, but the probability of a successful transplantation depends greatly on
compatibility between donors and recipients. Current medical practice relies on
coarse rules for donor-recipient matching, but is short of domain knowledge
regarding the complex factors underlying organ compatibility. In this paper, we
formulate the problem of learning data-driven rules for organ matching using
observational data for organ allocations and transplant outcomes. This problem
departs from the standard supervised learning setup in that it involves
matching the two feature spaces (i.e., donors and recipients), and requires
estimating transplant outcomes under counterfactual matches not observed in the
data. To address these problems, we propose a model based on representation
learning to predict donor-recipient compatibility; our model learns
representations that cluster donor features, and applies donor-invariant
transformations to recipient features to predict outcomes for a given
donor-recipient feature instance. Experiments on semi-synthetic and real-world
datasets show that our model outperforms state-of-art allocation methods and
policies executed by human experts.
</p>
<a href="http://arxiv.org/abs/2101.11769" target="_blank">arXiv:2101.11769</a> [<a href="http://arxiv.org/pdf/2101.11769" target="_blank">pdf</a>]

<h2>Autoregressive Denoising Diffusion Models for Multivariate Probabilistic Time Series Forecasting. (arXiv:2101.12072v2 [cs.LG] UPDATED)</h2>
<h3>Kashif Rasul, Calvin Seward, Ingmar Schuster, Roland Vollgraf</h3>
<p>In this work, we propose \texttt{TimeGrad}, an autoregressive model for
multivariate probabilistic time series forecasting which samples from the data
distribution at each time step by estimating its gradient. To this end, we use
diffusion probabilistic models, a class of latent variable models closely
connected to score matching and energy-based methods. Our model learns
gradients by optimizing a variational bound on the data likelihood and at
inference time converts white noise into a sample of the distribution of
interest through a Markov chain using Langevin sampling. We demonstrate
experimentally that the proposed autoregressive denoising diffusion model is
the new state-of-the-art multivariate probabilistic forecasting method on
real-world data sets with thousands of correlated dimensions. We hope that this
method is a useful tool for practitioners and lays the foundation for future
research in this area.
</p>
<a href="http://arxiv.org/abs/2101.12072" target="_blank">arXiv:2101.12072</a> [<a href="http://arxiv.org/pdf/2101.12072" target="_blank">pdf</a>]

<h2>NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation. (arXiv:2101.12378v2 [cs.CV] UPDATED)</h2>
<h3>Angtian Wang, Adam Kortylewski, Alan Yuille</h3>
<p>3D pose estimation is a challenging but important task in computer vision. In
this work, we show that standard deep learning approaches to 3D pose estimation
are not robust when objects are partially occluded or viewed from a previously
unseen pose. Inspired by the robustness of generative vision models to partial
occlusion, we propose to integrate deep neural networks with 3D generative
representations of objects into a unified neural architecture that we term
NeMo. In particular, NeMo learns a generative model of neural feature
activations at each vertex on a dense 3D mesh. Using differentiable rendering
we estimate the 3D object pose by minimizing the reconstruction error between
NeMo and the feature representation of the target image. To avoid local optima
in the reconstruction loss, we train the feature extractor to maximize the
distance between the individual feature representations on the mesh using
contrastive learning. Our extensive experiments on PASCAL3D+,
occluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to
partial occlusion and unseen pose compared to standard deep networks, while
retaining competitive performance on regular data. Interestingly, our
experiments also show that NeMo performs reasonably well even when the mesh
representation only crudely approximates the true object geometry with a
cuboid, hence revealing that the detailed 3D geometry is not needed for
accurate 3D pose estimation. The code is publicly available at
https://github.com/Angtian/NeMo.
</p>
<a href="http://arxiv.org/abs/2101.12378" target="_blank">arXiv:2101.12378</a> [<a href="http://arxiv.org/pdf/2101.12378" target="_blank">pdf</a>]

<h2>A note on synthesizing geodesic based contact curves. (arXiv:2101.12411v2 [cs.RO] UPDATED)</h2>
<h3>Rajesh Kumar, Sudipto Mukherjee</h3>
<p>The paper focuses on synthesizing optimal contact curves that can be used to
ensure a rolling constraint between two bodies in relative motion. We show that
geodesic based contact curves generated on both the contacting surfaces are
sufficient conditions to ensure rolling. The differential geodesic equations,
when modified, can ensure proper disturbance rejection in case the system of
interacting bodies is perturbed from the desired curve. A corollary states that
geodesic curves are generated on the surface if rolling constraints are
satisfied. Simulations in the context of in-hand manipulations of the objects
are used as examples.
</p>
<a href="http://arxiv.org/abs/2101.12411" target="_blank">arXiv:2101.12411</a> [<a href="http://arxiv.org/pdf/2101.12411" target="_blank">pdf</a>]

<h2>General-Purpose OCR Paragraph Identification by Graph Convolutional Neural Networks. (arXiv:2101.12741v2 [cs.CV] UPDATED)</h2>
<h3>Renshen Wang, Yasuhisa Fujii, Ashok C. Popat</h3>
<p>Paragraphs are an important class of document entities. We propose a new
approach for paragraph identification by spatial graph convolutional neural
networks (GCN) applied on OCR text boxes. Two steps, namely line splitting and
line clustering, are performed to extract paragraphs from the lines in OCR
results. Each step uses a beta-skeleton graph constructed from bounding boxes,
where the graph edges provide efficient support for graph convolution
operations. With only pure layout input features, the GCN model size is 3~4
orders of magnitude smaller compared to R-CNN based models, while achieving
comparable or better accuracies on PubLayNet and other datasets. Furthermore,
the GCN models show good generalization from synthetic training data to
real-world images, and good adaptivity for variable document styles.
</p>
<a href="http://arxiv.org/abs/2101.12741" target="_blank">arXiv:2101.12741</a> [<a href="http://arxiv.org/pdf/2101.12741" target="_blank">pdf</a>]

<h2>Policy Mirror Descent for Reinforcement Learning: Linear Convergence, New Sampling Complexity, and Generalized Problem Classes. (arXiv:2102.00135v2 [cs.LG] UPDATED)</h2>
<h3>Guanghui Lan</h3>
<p>We present new policy mirror descent (PMD) methods for solving reinforcement
learning (RL) problems with either strongly convex or general convex
regularizers. By exploring the structural properties of these overall seemly
highly nonconvex problems we show that the PMD methods exhibit fast linear rate
of convergence to the global optimality. We develop stochastic counterparts of
these methods, and establish an ${\cal O}(1/\epsilon)$ (resp., ${\cal
O}(1/\epsilon^2)$) sampling complexity for solving these RL problems with
strongly (resp., general) convex regularizers using different sampling schemes,
where $\epsilon$ denote the target accuracy. We further show that the
complexity for computing the gradients of these regularizers, if necessary, can
be bounded by ${\cal O}\{(\log_\gamma \epsilon) [(1-\gamma)L/\mu]^{1/2}\log
(1/\epsilon)\}$ (resp., ${\cal O} \{(\log_\gamma \epsilon )
[(1-\gamma)L/\epsilon]^{1/2}\}$) for problems with strongly (resp., general)
convex regularizers. Here $\gamma$ denotes the discounting factor. To the best
of our knowledge, these complexity bounds, along with our algorithmic
developments, appear to be new in both optimization and RL literature. The
introduction of these convex regularizers also greatly expands the flexibility
and applicability of RL models.
</p>
<a href="http://arxiv.org/abs/2102.00135" target="_blank">arXiv:2102.00135</a> [<a href="http://arxiv.org/pdf/2102.00135" target="_blank">pdf</a>]

<h2>SNR-adaptive deep joint source-channel coding for wireless image transmission. (arXiv:2102.00202v2 [cs.AI] UPDATED)</h2>
<h3>Mingze Ding, Jiahui Li, Mengyao Ma, Xiaopeng Fan</h3>
<p>Considering the problem of joint source-channel coding (JSCC) for multi-user
transmission of images over noisy channels, an autoencoder-based novel deep
joint source-channel coding scheme is proposed in this paper. In the proposed
JSCC scheme, the decoder can estimate the signal-to-noise ratio (SNR) and use
it to adaptively decode the transmitted image. Experiments demonstrate that the
proposed scheme achieves impressive results in adaptability for different SNRs
and is robust to the decoder's estimation error of the SNR. To the best of our
knowledge, this is the first deep JSCC scheme that focuses on the adaptability
for different SNRs and can be applied to multi-user scenarios.
</p>
<a href="http://arxiv.org/abs/2102.00202" target="_blank">arXiv:2102.00202</a> [<a href="http://arxiv.org/pdf/2102.00202" target="_blank">pdf</a>]

<h2>Fairness through Optimization. (arXiv:2102.00311v2 [cs.AI] UPDATED)</h2>
<h3>Violet Xinying Chen, J.N. Hooker</h3>
<p>We propose optimization as a general paradigm for formalizing fairness in
AI-based decision models. We argue that optimization models allow formulation
of a wide range of fairness criteria as social welfare functions, while
enabling AI to take advantage of highly advanced solution technology. We show
how optimization models can assist fairness-oriented decision making in the
context of neural networks, support vector machines, and rule-based systems by
maximizing a social welfare function subject to appropriate constraints. In
particular, we state tractable optimization models for a variety of functions
that measure fairness or a combination of fairness and efficiency. These
include several inequality metrics, Rawlsian criteria, the McLoone and Hoover
indices, alpha fairness, the Nash and Kalai-Smorodinsky bargaining solutions,
combinations of Rawlsian and utilitarian criteria, and statistical bias
measures. All of these models can be efficiently solved by linear programming,
mixed integer/linear programming, or (in two cases) specialized convex
programming methods.
</p>
<a href="http://arxiv.org/abs/2102.00311" target="_blank">arXiv:2102.00311</a> [<a href="http://arxiv.org/pdf/2102.00311" target="_blank">pdf</a>]

<h2>M2FN: Multi-step Modality Fusion for Advertisement Image Assessment. (arXiv:2102.00441v2 [cs.CV] UPDATED)</h2>
<h3>Kyung-Wha Park (1), Jung-Woo Ha (2), JungHoon Lee (3), Sunyoung Kwon (4), Kyung-Min Kim (2), Byoung-Tak Zhang (1 and 5 and 6) ((1) Interdisciplinary Program in Neuroscience, Seoul National University., (2) NAVER AI LAB, NAVER CLOVA., (3) Statistics and Actuarial Science, Soongsil University., (4) School of Biomedical Convergence Engineering, Pusan National University., (5) Department of Computer Science and Engineering, Seoul National University., (6) Surromind Robotics.)</h3>
<p>Assessing advertisements, specifically on the basis of user preferences and
ad quality, is crucial to the marketing industry. Although recent studies have
attempted to use deep neural networks for this purpose, these studies have not
utilized image-related auxiliary attributes, which include embedded text
frequently found in ad images. We, therefore, investigated the influence of
these attributes on ad image preferences. First, we analyzed large-scale
real-world ad log data and, based on our findings, proposed a novel multi-step
modality fusion network (M2FN) that determines advertising images likely to
appeal to user preferences. Our method utilizes auxiliary attributes through
multiple steps in the network, which include conditional batch
normalization-based low-level fusion and attention-based high-level fusion. We
verified M2FN on the AVA dataset, which is widely used for aesthetic image
assessment, and then demonstrated that M2FN can achieve state-of-the-art
performance in preference prediction using a real-world ad dataset with rich
auxiliary attributes.
</p>
<a href="http://arxiv.org/abs/2102.00441" target="_blank">arXiv:2102.00441</a> [<a href="http://arxiv.org/pdf/2102.00441" target="_blank">pdf</a>]

<h2>Benchmarking of Deep Learning Irradiance Forecasting Models from Sky Images -- an in-depth Analysis. (arXiv:2102.00721v2 [cs.CV] UPDATED)</h2>
<h3>Quentin Paletta, Guillaume Arbod, Joan Lasenby</h3>
<p>A number of industrial applications, such as smart grids, power plant
operation, hybrid system management or energy trading, could benefit from
improved short-term solar forecasting, addressing the intermittent energy
production from solar panels. However, current approaches to modelling the
cloud cover dynamics from sky images still lack precision regarding the spatial
configuration of clouds, their temporal dynamics and physical interactions with
solar radiation. Benefiting from a growing number of large datasets, data
driven methods are being developed to address these limitations with promising
results. In this study, we compare four commonly used Deep Learning
architectures trained to forecast solar irradiance from sequences of
hemispherical sky images and exogenous variables. To assess the relative
performance of each model, we used the Forecast Skill metric based on the smart
persistence model, as well as ramp and time distortion metrics. The results
show that encoding spatiotemporal aspects of the sequence of sky images greatly
improved the predictions with 10 min ahead Forecast Skill reaching 20.4% on the
test year. However, based on the experimental data, we conclude that, with a
common setup, Deep Learning models tend to behave just as a 'very smart
persistence model', temporally aligned with the persistence model while
mitigating its most penalising errors. Thus, despite being captured by the sky
cameras, models often miss fundamental events causing large irradiance changes
such as clouds obscuring the sun. We hope that our work will contribute to a
shift of this approach to irradiance forecasting, from reactive to
anticipatory.
</p>
<a href="http://arxiv.org/abs/2102.00721" target="_blank">arXiv:2102.00721</a> [<a href="http://arxiv.org/pdf/2102.00721" target="_blank">pdf</a>]

<h2>Generalized non-stationary bandits. (arXiv:2102.00725v2 [stat.ML] UPDATED)</h2>
<h3>Anne Gael Manegueu, Alexandra Carpentier, Yi Yu</h3>
<p>In this paper, we study a non-stationary stochastic bandit problem, which
generalizes the switching bandit problem. On top of the switching bandit
problem (\textbf{Case a}), we are interested in three concrete examples:
(\textbf{b}) the means of the arms are local polynomials, (\textbf{c}) the
means of the arms are locally smooth, and (\textbf{d}) the gaps of the arms
have a bounded number of inflexion points and where the highest arm mean cannot
vary too much in a short range. These three settings are very different, but
have in common the following: (i) the number of similarly-sized level sets of
the logarithm of the gaps can be controlled, and (ii) the highest mean has a
limited number of abrupt changes, and otherwise has limited variations. We
propose a single algorithm in this general setting, that in particular solves
in an efficient and unified way the four problems (a)-(d) mentioned.
</p>
<a href="http://arxiv.org/abs/2102.00725" target="_blank">arXiv:2102.00725</a> [<a href="http://arxiv.org/pdf/2102.00725" target="_blank">pdf</a>]

<h2>Risk Aware and Multi-Objective Decision Making with Distributional Monte Carlo Tree Search. (arXiv:2102.00966v2 [cs.LG] UPDATED)</h2>
<h3>Conor F. Hayes, Mathieu Reymond, Diederik M. Roijers, Enda Howley, Patrick Mannion</h3>
<p>In many risk-aware and multi-objective reinforcement learning settings, the
utility of the user is derived from the single execution of a policy. In these
settings, making decisions based on the average future returns is not suitable.
For example, in a medical setting a patient may only have one opportunity to
treat their illness. When making a decision, just the expected return -- known
in reinforcement learning as the value -- cannot account for the potential
range of adverse or positive outcomes a decision may have. Our key insight is
that we should use the distribution over expected future returns differently to
represent the critical information that the agent requires at decision time. In
this paper, we propose Distributional Monte Carlo Tree Search, an algorithm
that learns a posterior distribution over the utility of the different possible
returns attainable from individual policy executions, resulting in good
policies for both risk-aware and multi-objective settings. Moreover, our
algorithm outperforms the state-of-the-art in multi-objective reinforcement
learning for the expected utility of the returns.
</p>
<a href="http://arxiv.org/abs/2102.00966" target="_blank">arXiv:2102.00966</a> [<a href="http://arxiv.org/pdf/2102.00966" target="_blank">pdf</a>]

<h2>Learning to Combat Noisy Labels via Classification Margins. (arXiv:2102.00751v1 [cs.LG] CROSS LISTED)</h2>
<h3>Jason Z. Lin, Jelena Bradic</h3>
<p>A deep neural network trained on noisy labels is known to quickly lose its
power to discriminate clean instances from noisy ones. After the early learning
phase has ended, the network memorizes the noisy instances, which leads to a
degradation in generalization performance. To resolve this issue, we propose
MARVEL (MARgins Via Early Learning), where we track the goodness of "fit" for
every instance by maintaining an epoch-history of its classification margins.
Based on consecutive negative margins, we discard suspected noisy instances by
zeroing out their weights. In addition, MARVEL+ upweights arduous instances
enabling the network to learn a more nuanced representation of the
classification boundary. Experimental results on benchmark datasets with
synthetic label noise show that MARVEL outperforms other baselines consistently
across different noise levels, with a significantly larger margin under
asymmetric noise.
</p>
<a href="http://arxiv.org/abs/2102.00751" target="_blank">arXiv:2102.00751</a> [<a href="http://arxiv.org/pdf/2102.00751" target="_blank">pdf</a>]

