---
title: Latest Deep Learning Papers
date: 2020-11-01 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Greedy Optimization Provably Wins the Lottery: Logarithmic Number of Winning Tickets is Enough. (arXiv:2010.15969v1 [cs.LG])</h2>
<h3>Mao Ye, Lemeng Wu, Qiang Liu</h3>
<p>Despite the great success of deep learning, recent works show that large deep
neural networks are often highly redundant and can be significantly reduced in
size. However, the theoretical question of how much we can prune a neural
network given a specified tolerance of accuracy drop is still open. This paper
provides one answer to this question by proposing a greedy optimization based
pruning method. The proposed method has the guarantee that the discrepancy
between the pruned network and the original network decays with exponentially
fast rate w.r.t. the size of the pruned network, under weak assumptions that
apply for most practical settings. Empirically, our method improves prior arts
on pruning various network architectures including ResNet, MobilenetV2/V3 on
ImageNet.
</p>
<a href="http://arxiv.org/abs/2010.15969" target="_blank">arXiv:2010.15969</a> [<a href="http://arxiv.org/pdf/2010.15969" target="_blank">pdf</a>]

<h2>Guaranteeing Safety of Learned Perception Modules via Measurement-Robust Control Barrier Functions. (arXiv:2010.16001v1 [eess.SY])</h2>
<h3>Sarah Dean, Andrew J. Taylor, Ryan K. Cosner, Benjamin Recht, Aaron D. Ames</h3>
<p>Modern nonlinear control theory seeks to develop feedback controllers that
endow systems with properties such as safety and stability. The guarantees
ensured by these controllers often rely on accurate estimates of the system
state for determining control actions. In practice, measurement model
uncertainty can lead to error in state estimates that degrades these
guarantees. In this paper, we seek to unify techniques from control theory and
machine learning to synthesize controllers that achieve safety in the presence
of measurement model uncertainty. We define the notion of a Measurement-Robust
Control Barrier Function (MR-CBF) as a tool for determining safe control inputs
when facing measurement model uncertainty. Furthermore, MR-CBFs are used to
inform sampling methodologies for learning-based perception systems and
quantify tolerable error in the resulting learned models. We demonstrate the
efficacy of MR-CBFs in achieving safety with measurement model uncertainty on a
simulated Segway system.
</p>
<a href="http://arxiv.org/abs/2010.16001" target="_blank">arXiv:2010.16001</a> [<a href="http://arxiv.org/pdf/2010.16001" target="_blank">pdf</a>]

<h2>PersGNN: Applying Topological Data Analysis and Geometric Deep Learning to Structure-Based Protein Function Prediction. (arXiv:2010.16027v1 [q-bio.BM])</h2>
<h3>Nicolas Swenson, Aditi S. Krishnapriyan, Aydin Buluc, Dmitriy Morozov, Katherine Yelick</h3>
<p>Understanding protein structure-function relationships is a key challenge in
computational biology, with applications across the biotechnology and
pharmaceutical industries. While it is known that protein structure directly
impacts protein function, many functional prediction tasks use only protein
sequence. In this work, we isolate protein structure to make functional
annotations for proteins in the Protein Data Bank in order to study the
expressiveness of different structure-based prediction schemes. We present
PersGNN - an end-to-end trainable deep learning model that combines graph
representation learning with topological data analysis to capture a complex set
of both local and global structural features. While variations of these
techniques have been successfully applied to proteins before, we demonstrate
that our hybridized approach, PersGNN, outperforms either method on its own as
well as a baseline neural network that learns from the same information.
PersGNN achieves a 9.3% boost in area under the precision recall curve (AUPR)
compared to the best individual model, as well as high F1 scores across
different gene ontology categories, indicating the transferability of this
approach.
</p>
<a href="http://arxiv.org/abs/2010.16027" target="_blank">arXiv:2010.16027</a> [<a href="http://arxiv.org/pdf/2010.16027" target="_blank">pdf</a>]

<h2>Parasite infection in a cell population with deaths. (arXiv:2010.16070v1 [math.PR])</h2>
<h3>Aline Marguet, Charline Smadi</h3>
<p>We introduce a general class of branching Markov processes for the modelling
of a parasite infection in a cell population. Each cell contains a quantity of
parasites which evolves as a diffusion with positive jumps. The growth rate,
diffusive function and positive jump rate of this quantity of parasites depend
on its current value. The division rate of the cells also depends on the
quantity of parasites they contain. At division, a cell gives birth to two
daughter cells and shares its parasites between them. Cells may also die, at a
rate which may depend on the quantity of parasites they contain. We study the
long time behaviour of the parasite infection. In particular, we are interested
in the quantity of parasites in a `typical' cell and on the survival of the
cell population. We specifically focus on the influence of two parameters on
the probability for the cell population to survive and/or contain the parasite
infection: the law of the sharing of the parasites between the daughter cells
at division and the form of the division and death rates of the cells as
functions of the quantity of parasites they contain.
</p>
<a href="http://arxiv.org/abs/2010.16070" target="_blank">arXiv:2010.16070</a> [<a href="http://arxiv.org/pdf/2010.16070" target="_blank">pdf</a>]

<h2>Local laws for multiplication of random matrices and spiked invariant model. (arXiv:2010.16083v1 [math.PR])</h2>
<h3>Xiucai Ding, Hong Chang Ji</h3>
<p>High dimensional Haar random matrices are common objects in modern
statistical learning theory. We consider the random matrix model $A^{1/2} UBU^*
A^{1/2},$ where $A$ and $B$ are two $N \times N$ positive {definite} matrices
satisfying some regularity conditions and $U$ is either an $N \times N$ Haar
unitary or orthogonal random matrix. On the macroscopic scale, it is well-known
that the empirical spectral distribution (ESD) of the above model is given by
the free multiplicative convolution of the ESDs of $A$ and $B,$ denoted as
$\mu_A \boxtimes \mu_B,$ where $\mu_A$ and $\mu_B$ are the ESDs of $A$ and $B,$
respectively.

In this paper, motivated by applications in statistical learning theory, we
systematically study the above random matrix model. We first establish the
local laws both near and far away from the rightmost edge of the support of
$\mu_A \boxtimes \mu_B.$ We also prove eigenvalue rigidity and eigenvector
delocalization. Then we study the spiked invariant model by adding a few
eigenvalues that are detached from the bulks of the spectrums to $A$ or $B.$ We
derive the convergent limits and rates for the outlier eigenvalues and their
associated generalized components under general and weak assumptions. We
believe all these results are optimal up to an $N^{\epsilon}$ factor, for some
small $\epsilon&gt;0.$
</p>
<a href="http://arxiv.org/abs/2010.16083" target="_blank">arXiv:2010.16083</a> [<a href="http://arxiv.org/pdf/2010.16083" target="_blank">pdf</a>]

<h2>Effects of round-to-nearest and stochastic rounding in the numerical solution of the heat equation in low precision. (arXiv:2010.16225v1 [math.NA])</h2>
<h3>Matteo Croci, Michael Bryce Giles</h3>
<p>Motivated by the advent of machine learning, the last few years saw the
return of hardware-supported low-precision computing. Computations with fewer
digits are faster and more memory and energy efficient, but can be extremely
susceptible to rounding errors. An application that can largely benefit from
the advantages of low-precision computing is the numerical solution of partial
differential equations (PDEs), but a careful implementation and rounding error
analysis are required to ensure that sensible results can still be obtained.

In this paper we study the accumulation of rounding errors in the solution of
the heat equation, a proxy for parabolic PDEs, via Runge-Kutta finite
difference methods using round-to-nearest (RtN) and stochastic rounding (SR).
We demonstrate how to implement the scheme to reduce rounding errors and we
derive \emph{a priori} estimates for local and global rounding errors. Let $u$
be the roundoff unit. While the worst-case local errors are $O(u)$ with respect
to the discretization parameters, the RtN and SR error behavior is
substantially different. We prove that the RtN solution is discretization,
initial condition and precision dependent, and always stagnates for small
enough $\Delta t$. Until stagnation, the global error grows like $O(u\Delta
t^{-1})$. In contrast, we show that the leading order errors introduced by SR
are zero-mean, independent in space and mean-independent in time, making SR
resilient to stagnation and rounding error accumulation. In fact, we prove that
for SR the global rounding errors are only $O(u\Delta t^{-1/4})$ in 1D and are
essentially bounded (up to logarithmic factors) in higher dimensions.
</p>
<a href="http://arxiv.org/abs/2010.16225" target="_blank">arXiv:2010.16225</a> [<a href="http://arxiv.org/pdf/2010.16225" target="_blank">pdf</a>]

<h2>Learning to Unknot. (arXiv:2010.16263v1 [math.GT])</h2>
<h3>Sergei Gukov, James Halverson, Fabian Ruehle, Piotr Su&#x142;kowski</h3>
<p>We introduce natural language processing into the study of knot theory, as
made natural by the braid word representation of knots. We study the UNKNOT
problem of determining whether or not a given knot is the unknot. After
describing an algorithm to randomly generate $N$-crossing braids and their knot
closures and discussing the induced prior on the distribution of knots, we
apply binary classification to the UNKNOT decision problem. We find that the
Reformer and shared-QK Transformer network architectures outperform
fully-connected networks, though all perform well. Perhaps surprisingly, we
find that accuracy increases with the length of the braid word, and that the
networks learn a direct correlation between the confidence of their predictions
and the degree of the Jones polynomial. Finally, we utilize reinforcement
learning (RL) to find sequences of Markov moves and braid relations that
simplify knots and can identify unknots by explicitly giving the sequence of
unknotting actions. Trust region policy optimization (TRPO) performs
consistently well for a wide range of crossing numbers and thoroughly
outperformed other RL algorithms and random walkers. Studying these actions, we
find that braid relations are more useful in simplifying to the unknot than one
of the Markov moves.
</p>
<a href="http://arxiv.org/abs/2010.16263" target="_blank">arXiv:2010.16263</a> [<a href="http://arxiv.org/pdf/2010.16263" target="_blank">pdf</a>]

<h2>Wasserstein Distributionally Robust Optimization and Variation Regularization. (arXiv:1712.06050v3 [cs.LG] UPDATED)</h2>
<h3>Rui Gao, Xi Chen, Anton J. Kleywegt</h3>
<p>Wasserstein distributionally robust optimization (DRO) has recently achieved
empirical success for various applications in operations research and machine
learning, owing partly to its regularization effect. Although connection
between Wasserstein DRO and regularization has been established in several
settings, existing results often require restrictive assumptions, such as
smoothness or convexity, that are not satisfied for many problems. In this
paper, we develop a general theory on the variation regularization effect of
the Wasserstein DRO - a new form of regularization that generalizes
total-variation regularization, Lipschitz regularization and gradient
regularization. Our results cover possibly non-convex and non-smooth losses and
losses on non-Euclidean spaces. Examples include multi-item newsvendor,
portfolio selection, linear prediction, neural networks, manifold learning, and
intensity estimation for Poisson processes, etc. As an application of our
theory of variation regularization, we derive new generalization guarantees for
adversarial robust learning.
</p>
<a href="http://arxiv.org/abs/1712.06050" target="_blank">arXiv:1712.06050</a> [<a href="http://arxiv.org/pdf/1712.06050" target="_blank">pdf</a>]

<h2>Compressed Sensing with Deep Image Prior and Learned Regularization. (arXiv:1806.06438v4 [stat.ML] UPDATED)</h2>
<h3>Dave Van Veen, Ajil Jalal, Mahdi Soltanolkotabi, Eric Price, Sriram Vishwanath, Alexandros G. Dimakis</h3>
<p>We propose a novel method for compressed sensing recovery using untrained
deep generative models. Our method is based on the recently proposed Deep Image
Prior (DIP), wherein the convolutional weights of the network are optimized to
match the observed measurements. We show that this approach can be applied to
solve any differentiable linear inverse problem, outperforming previous
unlearned methods. Unlike various learned approaches based on generative
models, our method does not require pre-training over large datasets. We
further introduce a novel learned regularization technique, which incorporates
prior information on the network weights. This reduces reconstruction error,
especially for noisy measurements. Finally, we prove that, using the DIP
optimization approach, moderately overparameterized single-layer networks can
perfectly fit any signal despite the non-convex nature of the fitting problem.
This theoretical result provides justification for early stopping.
</p>
<a href="http://arxiv.org/abs/1806.06438" target="_blank">arXiv:1806.06438</a> [<a href="http://arxiv.org/pdf/1806.06438" target="_blank">pdf</a>]

<h2>An Inertial Newton Algorithm for Deep Learning. (arXiv:1905.12278v4 [cs.LG] UPDATED)</h2>
<h3>Camille Castera, J&#xe9;r&#xf4;me Bolte (UT1), C&#xe9;dric F&#xe9;votte, Edouard Pauwels (UT3)</h3>
<p>We introduce a new second-order inertial optimization method for machine
learning called INDIAN. It exploits the geometry of the loss function while
only requiring stochastic approximations of the function values and the
generalized gradients. This makes INDIAN fully implementable and adapted to
large-scale optimization problems such as the training of deep neural networks.
The algorithm combines both gradient-descent and Newton-like behaviors as well
as inertia. We prove the convergence of INDIAN for most deep learning problems.
To do so, we provide a well-suited framework to analyze deep learning loss
functions involving tame optimization in which we study the continuous
dynamical system together with the discrete stochastic approximations. We prove
sublinear convergence for the continuous-time differential inclusion which
underlies our algorithm. Besides, we also show how standard optimization
mini-batch methods applied to nonsmooth nonconvex problems can yield a certain
type of spurious stationary points never discussed before. We address this
issue by providing a theoretical framework around the new idea of
$D$-criticality; we then give a simple asymptotic analysis of INDIAN. Our
algorithm allows for using an aggressive learning rate of $o(1/\log k)$. From
an empirical viewpoint, we show that INDIAN returns competitive results with
respect to state of the art (stochastic gradient descent, ADAGRAD, ADAM) on
popular deep learning benchmark problems.
</p>
<a href="http://arxiv.org/abs/1905.12278" target="_blank">arXiv:1905.12278</a> [<a href="http://arxiv.org/pdf/1905.12278" target="_blank">pdf</a>]

<h2>Sparse $\ell^q$-regularization of Inverse Problems Using Deep Learning. (arXiv:1908.03006v2 [math.NA] UPDATED)</h2>
<h3>Daniel Obmann, Linh Nguyen, Johannes Schwab, Markus Haltmeier</h3>
<p>We propose a novel data driven sparse reconstruction framework for solving
inverse problems named aNET (augmented NEtwork Tikhonov regularization).
Opposed to existing sparse reconstruction techniques that are based on linear
sparsifying transformations, we train an encoder-decoder network $\mathbf{D}
\circ \mathbf{E}$ to construct a regularizer formed by $\ell^q$-norm of the
encoder coefficients enforcing sparsity and an additional term penalizing the
distance to the data manifold. We present a full convergence analysis and
derive convergence rates in a general setting including the $\ell^q$-norm of
the encoder coefficients. As a main ingredient for the theoretical analysis we
establish the coercivity of the augmented regularization term. Application to
sparse view and low dose CT demonstrate the practical benefits of the proposal.
We show that the proposed method is able to leverage increased sampling rates
without retraining the networks.
</p>
<a href="http://arxiv.org/abs/1908.03006" target="_blank">arXiv:1908.03006</a> [<a href="http://arxiv.org/pdf/1908.03006" target="_blank">pdf</a>]

<h2>Density estimation on an unknown submanifold. (arXiv:1910.08477v2 [math.ST] UPDATED)</h2>
<h3>Cl&#xe9;ment Berenfeld, Marc Hoffmann</h3>
<p>We investigate density estimation from a $n$-sample in the Euclidean space
$\mathbb R^D$, when the data is supported by an unknown submanifold $M$ of
possibly unknown dimension $d &lt; D$ under a reach condition. We study
nonparametric kernel methods for pointwise loss, with data-driven bandwidths
that incorporate some learning of the geometry via a local dimension estimator.
When $f$ has H\"older smoothness $\beta$ and $M$ has regularity $\alpha$, our
estimator achieves the rate $n^{-\alpha \wedge \beta/(2\alpha \wedge \beta+d)}$
and does not depend on the ambient dimension $D$ and is asymptotically minimax
for $\alpha \geq \beta$. Following Lepski's principle, a bandwidth selection
rule is shown to achieve smoothness adaptation. We also investigate the case
$\alpha \leq \beta$: by estimating in some sense the underlying geometry of
$M$, we establish in dimension $d=1$ that the minimax rate is
$n^{-\beta/(2\beta+1)}$ proving in particular that it does not depend on the
regularity of $M$. Finally, a numerical implementation is conducted on some
case studies in order to confirm the practical feasibility of our estimators.
</p>
<a href="http://arxiv.org/abs/1910.08477" target="_blank">arXiv:1910.08477</a> [<a href="http://arxiv.org/pdf/1910.08477" target="_blank">pdf</a>]

<h2>Cooperative Multiple-Access Channels with Distributed State Information. (arXiv:1911.07899v3 [cs.IT] UPDATED)</h2>
<h3>Lorenzo Miretti, Mari Kobayashi, David Gesbert, Paul de Kerret</h3>
<p>This paper studies a memoryless state-dependent multiple access channel (MAC)
where two transmitters wish to convey a message to a receiver under the
assumption of causal and imperfect channel state information at transmitters
(CSIT) and imperfect channel state information at receiver (CSIR). In order to
emphasize the limitation of transmitter cooperation between physically
distributed nodes, we focus on the so-called distributed CSIT assumption, i.e.
where each transmitter has its individual channel knowledge, while the message
can be assumed to be partially or entirely shared a priori between transmitters
by exploiting some on-board memory. Under this setup, the first part of the
paper characterizes the common message capacity of the channel at hand for
arbitrary CSIT and CSIR structure. The optimal scheme builds on Shannon
strategies, i.e. optimal codes are constructed by letting the channel inputs be
a function of current CSIT only. For a special case when CSIT is a
deterministic function of CSIR, the considered scheme also achieves the
capacity region of a common message and two private messages. The second part
addresses an important instance of the previous general result in a context of
a cooperative multi-antenna Gaussian channel under i.i.d. fading operating in
frequency-division duplex mode, such that CSIT is acquired via an explicit
feedback of perfect CSIR. The capacity of the channel at hand is achieved by
distributed linear precoding applied to Gaussian codes. Surprisingly, we
demonstrate that it is suboptimal to send a number of data streams bounded by
the number of transmit antennas as typically considered in a centralized CSIT
setup. Finally, numerical examples are provided to evaluate the sum capacity of
the binary MAC with binary states as well as the Gaussian MAC with i.i.d.
fading.
</p>
<a href="http://arxiv.org/abs/1911.07899" target="_blank">arXiv:1911.07899</a> [<a href="http://arxiv.org/pdf/1911.07899" target="_blank">pdf</a>]

<h2>Federated Matrix Factorization: Algorithm Design and Application to Data Clustering. (arXiv:2002.04930v2 [cs.LG] UPDATED)</h2>
<h3>Shuai Wang, Tsung-Hui Chang</h3>
<p>Recent demands on data privacy have called for federated learning (FL) as a
new distributed learning paradigm in massive and heterogeneous networks.
Although many FL algorithms have been proposed, few of them have considered the
matrix factorization (MF) model, which is known to have a vast number of signal
processing and machine learning applications. Different from the existing FL
algorithms that are designed for smooth problems with single block of
variables, in federated MF (FedMF), one has to deal with challenging non-convex
and non-smooth problems (due to constraints or regularization) with two blocks
of variables. In this paper, we address the challenge by proposing two new
FedMF algorithms, namely, FedMAvg and FedMGS, based on the model averaging and
gradient sharing principles, respectively. Both FedMAvg and FedMGS adopt
multiple steps of local updates per communication round to speed up
convergence, and allow only a randomly sampled subset of clients to communicate
with the server for reducing the communication cost. Convergence analyses for
the two algorithms are respectively presented, which delineate the impacts of
data distribution, local update number, and partial client communication on the
algorithm performance. By focusing on a data clustering task, extensive
experiment results are presented to examine the practical performance of both
algorithms, as well as demonstrating their efficacy over the existing
distributed clustering algorithms.
</p>
<a href="http://arxiv.org/abs/2002.04930" target="_blank">arXiv:2002.04930</a> [<a href="http://arxiv.org/pdf/2002.04930" target="_blank">pdf</a>]

<h2>Safeguarded Learned Convex Optimization. (arXiv:2003.01880v2 [math.OC] UPDATED)</h2>
<h3>Howard Heaton, Xiaohan Chen, Zhangyang Wang, Wotao Yin</h3>
<p>Many applications require repeatedly solving a certain type of optimization
problem, each time with new (but similar) data. Data-driven algorithms can
"learn to optimize" (L2O) with much fewer iterations and with similar cost per
iteration as general-purpose optimization algorithms. L2O algorithms are often
derived from general-purpose algorithms, but with the inclusion of (possibly
many) tunable parameters. Exceptional performance has been demonstrated when
the parameters are optimized for a particular distribution of data.
Unfortunately, it is impossible to ensure all L2O algorithms always converge to
a solution. However, we present a framework that uses L2O updates together with
a safeguard to guarantee convergence for convex problems with proximal and/or
gradient oracles. The safeguard is simple and computationally cheap to
implement, and it should be activated only when the current L2O updates would
perform poorly or appear to diverge. This approach yields the numerical
benefits of employing machine learning methods to create rapid L2O algorithms
while still guaranteeing convergence. Our numerical examples demonstrate the
efficacy of this approach for existing and new L2O schemes.
</p>
<a href="http://arxiv.org/abs/2003.01880" target="_blank">arXiv:2003.01880</a> [<a href="http://arxiv.org/pdf/2003.01880" target="_blank">pdf</a>]

<h2>Markov Decision Process Based Design of SWIPT Systems: Non-linear EH Circuits, Memory, and Impedance Mismatch. (arXiv:2004.03429v2 [cs.IT] UPDATED)</h2>
<h3>Nikita Shanin, Laura Cottatellucci, Robert Schober</h3>
<p>In this paper, we study simultaneous wireless information and power transfer
(SWIPT) systems employing practical non-linear energy harvester (EH) circuits.
Since the voltage across the reactive elements of realistic EH circuits cannot
drop or rise instantaneously, EHs have memory which we model with a Markov
decision process (MDP). Moreover, since an analytical model that accurately
models all non-linear effects and the unavoidable impedance mismatch of EHs is
not tractable, we propose a learning based model for the EH circuit. We
optimize the input signal distribution for maximization of the harvested power
under a constraint on the minimum mutual information between transmitter (TX)
and information receiver (IR). We distinguish the cases where the MDP state is
known and not known at TX and IR. When the MDP state is known, the formulated
optimization problem for the harvested power is convex. In contrast, if TX and
IR do not know the MDP state, the resulting optimization problem is non-convex
and solved via alternating optimization, which is shown to yield a limit point
of the problem. Our simulation results reveal that the rate-power region of the
considered SWIPT system depends on the symbol duration, the EH input power
level, the EH impedance mismatch, and the type of EH circuit. In particular, a
shorter symbol duration enables higher bit rates at the expense of a
significant decrease in the average harvested power. Furthermore, whereas
half-wave rectifiers outperform full-wave rectifiers in the low and medium
input power regimes, full-wave rectifiers are preferable if the input power at
the EH is high.
</p>
<a href="http://arxiv.org/abs/2004.03429" target="_blank">arXiv:2004.03429</a> [<a href="http://arxiv.org/pdf/2004.03429" target="_blank">pdf</a>]

<h2>Spectral convergence of diffusion maps: improved error bounds and an alternative normalisation. (arXiv:2006.02037v2 [math.ST] UPDATED)</h2>
<h3>Caroline L. Wormell, Sebastian Reich</h3>
<p>Diffusion maps is a manifold learning algorithm widely used for
dimensionality reduction. Using a sample from a distribution, it approximates
the eigenvalues and eigenfunctions of associated Laplace-Beltrami operators.
Theoretical bounds on the approximation error are however generally much weaker
than the rates that are seen in practice. This paper uses new approaches to
improve the error bounds in the model case where the distribution is supported
on a hypertorus. For the data sampling (variance) component of the error we
make spatially localised compact embedding estimates on certain Hardy spaces;
we study the deterministic (bias) component as a perturbation of the
Laplace-Beltrami operator's associated PDE, and apply relevant spectral
stability results. Using these approaches, we match long-standing pointwise
error bounds for both the spectral data and the norm convergence of the
operator discretisation.

We also introduce an alternative normalisation for diffusion maps based on
Sinkhorn weights. This normalisation approximates a Langevin diffusion on the
sample and yields a symmetric operator approximation. We prove that it has
better convergence compared with the standard normalisation on flat domains,
and present a highly efficient algorithm to compute the Sinkhorn weights.
</p>
<a href="http://arxiv.org/abs/2006.02037" target="_blank">arXiv:2006.02037</a> [<a href="http://arxiv.org/pdf/2006.02037" target="_blank">pdf</a>]

<h2>High probability convergence bounds for stochastic gradient descent assuming the Polyak-Lojasiewicz inequality. (arXiv:2006.05610v2 [math.OC] UPDATED)</h2>
<h3>Liam Madden, Emiliano Dall&#x27;Anese, Stephen Becker</h3>
<p>Stochastic gradient descent (with a mini-batch) is one of the most common
iterative algorithms used in machine learning. While being computationally
cheap to implement, recent literature suggests that it may also have implicit
regularization properties that prevent overfitting. This paper analyzes the
properties of stochastic gradient descent from a theoretical standpoint to help
bridge the gap between theoretical and empirical results. Assuming smoothness,
the Polyak-Lojasiewicz inequality, and sub-gaussian stochasticity, we prove
high probability bounds on the convergence rate, matching existing expected
bounds. As an application of our convergence results, we combine them with
existing uniform stability and generalization bounds to bound the true risk of
the iterates of stochastic gradient descent. We find that for a certain number
of epochs, the convergence and generalization balance in such a way that the
true risk bound goes to zero as the number of samples goes to infinity.
</p>
<a href="http://arxiv.org/abs/2006.05610" target="_blank">arXiv:2006.05610</a> [<a href="http://arxiv.org/pdf/2006.05610" target="_blank">pdf</a>]

<h2>Learning Dynamics Models with Stable Invariant Sets. (arXiv:2006.08935v2 [cs.LG] UPDATED)</h2>
<h3>Naoya Takeishi, Yoshinobu Kawahara</h3>
<p>Invariance and stability are essential notions in dynamical systems study,
and thus it is of great interest to learn a dynamics model with a stable
invariant set. However, existing methods can only handle the stability of an
equilibrium. In this paper, we propose a method to ensure that a dynamics model
has a stable invariant set of general classes such as limit cycles and line
attractors. We start with the approach by Manek and Kolter (2019), where they
use a learnable Lyapunov function to make a model stable with regard to an
equilibrium. We generalize it for general sets by introducing projection onto
them. To resolve the difficulty of specifying a to-be stable invariant set
analytically, we propose defining such a set as a primitive shape (e.g.,
sphere) in a latent space and learning the transformation between the original
and latent spaces. It enables us to compute the projection easily, and at the
same time, we can maintain the model's flexibility using various invertible
neural networks for the transformation. We present experimental results that
show the validity of the proposed method and the usefulness for long-term
prediction.
</p>
<a href="http://arxiv.org/abs/2006.08935" target="_blank">arXiv:2006.08935</a> [<a href="http://arxiv.org/pdf/2006.08935" target="_blank">pdf</a>]

<h2>Computing the untruncated signature kernel as the solution of a Goursat problem. (arXiv:2006.14794v4 [math.AP] UPDATED)</h2>
<h3>Thomas Cass, Terry Lyons, Cristopher Salvi, Weixin Yang</h3>
<p>Recently there has been an increased interest in the development of kernel
methods for learning with sequential data. The truncated signature kernel is a
new learning tool designed to handle irregularly sampled, multidimensional data
streams. In this article we consider the untruncated signature kernel and show
that for paths of bounded variation it is the solution of a Goursat problem.
This linear hyperbolic PDE only depends on the increments of the input
sequences, doesn't require the explicit computation of signatures and can be
solved using any PDE numerical solver; it is a kernel trick for the untruncated
signature kernel. In addition, we extend the analysis to the space of geometric
rough paths, and establish using classical results from stochastic analysis
that the rough version of the untruncated signature kernel solves a rough
integral equation analogous to the Goursat problem for the bounded variation
case. Finally we empirically demonstrate the effectiveness of this kernel in
two data science applications: multivariate time-series classification and
dimensionality reduction.
</p>
<a href="http://arxiv.org/abs/2006.14794" target="_blank">arXiv:2006.14794</a> [<a href="http://arxiv.org/pdf/2006.14794" target="_blank">pdf</a>]

<h2>A time-space tradeoff for Lehman's deterministic integer factorization method. (arXiv:2006.16729v2 [math.NT] UPDATED)</h2>
<h3>Markus Hittmeir</h3>
<p>Fermat's well-known factorization algorithm is based on finding a
representation of natural numbers $N$ as the difference of squares. In 1895,
Lawrence generalized this idea and applied it to multiples $kN$ of the original
number. A systematic approach to choose suitable values for $k$ was introduced
by Lehman in 1974, which resulted in the first deterministic factorization
algorithm considerably faster than trial division. In this paper, we construct
a time-space tradeoff for Lawrence's generalization and apply it together with
Lehman's result to obtain a deterministic integer factorization algorithm with
runtime complexity $O(N^{2/9+o(1)})$. This is the first exponential improvement
since the establishment of the $O(N^{1/4+o(1)})$ bound in 1977.
</p>
<a href="http://arxiv.org/abs/2006.16729" target="_blank">arXiv:2006.16729</a> [<a href="http://arxiv.org/pdf/2006.16729" target="_blank">pdf</a>]

<h2>Finite-Sample Guarantees for Wasserstein Distributionally Robust Optimization: Breaking the Curse of Dimensionality. (arXiv:2009.04382v2 [cs.LG] UPDATED)</h2>
<h3>Rui Gao</h3>
<p>Wasserstein distributionally robust optimization (DRO) aims to find robust
and generalizable solutions by hedging against data perturbations in
Wasserstein distance. Despite its recent empirical success in operations
research and machine learning, existing performance guarantees for generic loss
functions are either overly conservative due to the curse of dimensionality, or
plausible only in large sample asymptotics. In this paper, we develop a
non-asymptotic framework for analyzing the out-of-sample performance for
Wasserstein robust learning and the generalization bound for its related
Lipschitz and gradient regularization problems. To the best of our knowledge,
this gives the first finite-sample guarantee for generic Wasserstein DRO
problems without suffering from the curse of dimensionality. Our results
highlight the bias-variation trade-off intrinsic in the Wasserstein DRO, which
balances between the empirical mean of the loss and the variation of the loss,
measured by the Lipschitz norm or the gradient norm of the loss. Our analysis
is based on two novel methodological developments that are of independent
interest: 1) a new concentration inequality controlling the decay rate of large
deviation probabilities by the variation of the loss and, 2) a localized
Rademacher complexity theory based on the variation of the loss.
</p>
<a href="http://arxiv.org/abs/2009.04382" target="_blank">arXiv:2009.04382</a> [<a href="http://arxiv.org/pdf/2009.04382" target="_blank">pdf</a>]

<h2>Machine-Learning the Sato--Tate Conjecture. (arXiv:2010.01213v2 [math.NT] UPDATED)</h2>
<h3>Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver</h3>
<p>We apply some of the latest techniques from machine-learning to the
arithmetic of hyperelliptic curves. More precisely we show that, with
impressive accuracy and confidence (between 99 and 100 percent precision), and
in very short time (matter of seconds on an ordinary laptop), a Bayesian
classifier can distinguish between Sato-Tate groups given a small number of
Euler factors for the L-function. Our observations are in keeping with the
Sato-Tate conjecture for curves of low genus. For elliptic curves, this amounts
to distinguishing generic curves (with Sato-Tate group SU(2)) from those with
complex multiplication. In genus 2, a principal component analysis is observed
to separate the generic Sato-Tate group USp(4) from the non-generic groups.
Furthermore in this case, for which there are many more non-generic
possibilities than in the case of elliptic curves, we demonstrate an accurate
characterisation of several Sato-Tate groups with the same identity component.
Throughout, our observations are verified using known results from the
literature and the data available in the LMFDB. The results in this paper
suggest that a machine can be trained to learn the Sato-Tate distributions and
may be able to classify curves much more efficiently than the methods available
in the literature.
</p>
<a href="http://arxiv.org/abs/2010.01213" target="_blank">arXiv:2010.01213</a> [<a href="http://arxiv.org/pdf/2010.01213" target="_blank">pdf</a>]

<h2>Self-Learning Threshold-Based Load Balancing. (arXiv:2010.15525v2 [cs.PF] UPDATED)</h2>
<h3>Diego Goldsztajn, Sem C. Borst, Johan S. H. van Leeuwaarden, Debankur Mukherjee, Philip A. Whiting</h3>
<p>We consider a large-scale service system where incoming tasks have to be
instantaneously dispatched to one out of many parallel server pools. The
dispatcher uses a threshold for balancing the load and keeping the maximum
number of concurrent tasks across server pools low. We demonstrate that such a
policy is optimal on the fluid and diffusion scales for a suitable threshold
value, while only involving a small communication overhead. In order to set the
threshold optimally, it is important, however, to learn the load of the system,
which may be uncertain or even time-varying. For that purpose, we design a
control rule for tuning the threshold in an online manner. We provide
conditions which guarantee that this adaptive threshold settles at the optimal
value, along with estimates for the time until this happens.
</p>
<a href="http://arxiv.org/abs/2010.15525" target="_blank">arXiv:2010.15525</a> [<a href="http://arxiv.org/pdf/2010.15525" target="_blank">pdf</a>]

<h2>Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent. (arXiv:2005.08898v3 [cs.LG] CROSS LISTED)</h2>
<h3>Tian Tong, Cong Ma, Yuejie Chi</h3>
<p>Low-rank matrix estimation is a canonical problem that finds numerous
applications in signal processing, machine learning and imaging science. A
popular approach in practice is to factorize the matrix into two compact
low-rank factors, and then optimize these factors directly via simple iterative
methods such as gradient descent and alternating minimization. Despite
nonconvexity, recent literatures have shown that these simple heuristics in
fact achieve linear convergence when initialized properly for a growing number
of problems of interest. However, upon closer examination, existing approaches
can still be computationally expensive especially for ill-conditioned matrices:
the convergence rate of gradient descent depends linearly on the condition
number of the low-rank matrix, while the per-iteration cost of alternating
minimization is often prohibitive for large matrices. The goal of this paper is
to set forth a competitive algorithmic approach dubbed Scaled Gradient Descent
(ScaledGD) which can be viewed as pre-conditioned or diagonally-scaled gradient
descent, where the pre-conditioners are adaptive and iteration-varying with a
minimal computational overhead. With tailored variants for low-rank matrix
sensing, robust principal component analysis and matrix completion, we
theoretically show that ScaledGD achieves the best of both worlds: it converges
linearly at a rate independent of the condition number of the low-rank matrix
similar as alternating minimization, while maintaining the low per-iteration
cost of gradient descent. Our analysis is also applicable to general loss
functions that are restricted strongly convex and smooth over low-rank
matrices. To the best of our knowledge, ScaledGD is the first algorithm that
provably has such properties over a wide range of low-rank matrix estimation
tasks.
</p>
<a href="http://arxiv.org/abs/2005.08898" target="_blank">arXiv:2005.08898</a> [<a href="http://arxiv.org/pdf/2005.08898" target="_blank">pdf</a>]

<h2>Targeting for long-term outcomes. (arXiv:2010.15835v1 [cs.LG])</h2>
<h3>Jeremy Yang, Dean Eckles, Paramveer Dhillon, Sinan Aral</h3>
<p>Decision-makers often want to target interventions (e.g., marketing
campaigns) so as to maximize an outcome that is observed only in the long-term.
This typically requires delaying decisions until the outcome is observed or
relying on simple short-term proxies for the long-term outcome. Here we build
on the statistical surrogacy and off-policy learning literature to impute the
missing long-term outcomes and then approximate the optimal targeting policy on
the imputed outcomes via a doubly-robust approach. We apply our approach in
large-scale proactive churn management experiments at The Boston Globe by
targeting optimal discounts to its digital subscribers to maximize their
long-term revenue. We first show that conditions for validity of average
treatment effect estimation with imputed outcomes are also sufficient for valid
policy evaluation and optimization; furthermore, these conditions can be
somewhat relaxed for policy optimization. We then validate this approach
empirically by comparing it with a policy learned on the ground truth long-term
outcomes and show that they are statistically indistinguishable. Our approach
also outperforms a policy learned on short-term proxies for the long-term
outcome. In a second field experiment, we implement the optimal targeting
policy with additional randomized exploration, which allows us to update the
optimal policy for each new cohort of customers to account for potential
non-stationarity. Over three years, our approach had a net-positive revenue
impact in the range of $4-5 million compared to The Boston Globe's current
policies.
</p>
<a href="http://arxiv.org/abs/2010.15835" target="_blank">arXiv:2010.15835</a> [<a href="http://arxiv.org/pdf/2010.15835" target="_blank">pdf</a>]

<h2>$\texttt{deep21}$: a Deep Learning Method for 21cm Foreground Removal. (arXiv:2010.15843v1 [astro-ph.CO])</h2>
<h3>T. Lucas Makinen, Lachlan Lancaster, Francisco Villaescusa-Navarro, Peter Melchior, Shirley Ho, Laurence Perreault-Levasseur, David N. Spergel</h3>
<p>We seek to remove foreground contaminants from 21cm intensity mapping
observations. We demonstrate that a deep convolutional neural network (CNN)
with a UNet architecture and three-dimensional convolutions, trained on
simulated observations, can effectively separate frequency and spatial patterns
of the cosmic neutral hydrogen (HI) signal from foregrounds in the presence of
noise. Cleaned maps recover cosmological clustering statistics within 10% at
all relevant angular scales and frequencies. This amounts to a reduction in
prediction variance of over an order of magnitude on small angular scales
($\ell &gt; 300$), and improved accuracy for small radial scales ($k_{\parallel} &gt;
0.17\ \rm h\ Mpc^{-1})$ compared to standard Principal Component Analysis (PCA)
methods. We estimate posterior confidence intervals for the network's
prediction by training an ensemble of UNets. Our approach demonstrates the
feasibility of analyzing 21cm intensity maps, as opposed to derived summary
statistics, for upcoming radio experiments, as long as the simulated foreground
model is sufficiently realistic. We provide the code used for this analysis on
$\href{https://github.com/tlmakinen/deep21}{\rm GitHub}$, as well as a
browser-based tutorial for the experiment and UNet model via the accompanying
$\href{this http URL}{\rm Colab\ notebook}$.
</p>
<a href="http://arxiv.org/abs/2010.15843" target="_blank">arXiv:2010.15843</a> [<a href="http://arxiv.org/pdf/2010.15843" target="_blank">pdf</a>]

<h2>Ink Marker Segmentation in Histopathology Images Using Deep Learning. (arXiv:2010.15865v1 [eess.IV])</h2>
<h3>Danial Maleki, Mehdi Afshari, Morteza Babaie, H.R. Tizhoosh</h3>
<p>Due to the recent advancements in machine vision, digital pathology has
gained significant attention. Histopathology images are distinctly rich in
visual information. The tissue glass slide images are utilized for disease
diagnosis. Researchers study many methods to process histopathology images and
facilitate fast and reliable diagnosis; therefore, the availability of
high-quality slides becomes paramount. The quality of the images can be
negatively affected when the glass slides are ink-marked by pathologists to
delineate regions of interest. As an example, in one of the largest public
histopathology datasets, The Cancer Genome Atlas (TCGA), approximately $12\%$
of the digitized slides are affected by manual delineations through ink
markings. To process these open-access slide images and other repositories for
the design and validation of new methods, an algorithm to detect the marked
regions of the images is essential to avoid confusing tissue pixels with
ink-colored pixels for computer methods. In this study, we propose to segment
the ink-marked areas of pathology patches through a deep network. A dataset
from $79$ whole slide images with $4,305$ patches was created and different
networks were trained. Finally, the results showed an FPN model with the
EffiecentNet-B3 as the backbone was found to be the superior configuration with
an F1 score of $94.53\%$.
</p>
<a href="http://arxiv.org/abs/2010.15865" target="_blank">arXiv:2010.15865</a> [<a href="http://arxiv.org/pdf/2010.15865" target="_blank">pdf</a>]

<h2>CURE: A Security Architecture with CUstomizable and Resilient Enclaves. (arXiv:2010.15866v1 [cs.CR])</h2>
<h3>Raad Bahmani, Ferdinand Brasser, Ghada Dessouky, Patrick Jauernig, Matthias Klimmek, Ahmad-Reza Sadeghi, Emmanuel Stapf</h3>
<p>Security architectures providing Trusted Execution Environments (TEEs) have
been an appealing research subject for a wide range of computer systems, from
low-end embedded devices to powerful cloud servers. The goal of these
architectures is to protect sensitive services in isolated execution contexts,
called enclaves. Unfortunately, existing TEE solutions suffer from significant
design shortcomings. First, they follow a one-size-fits-all approach offering
only a single enclave type, however, different services need flexible enclaves
that can adjust to their demands. Second, they cannot efficiently support
emerging applications (e.g., Machine Learning as a Service), which require
secure channels to peripherals (e.g., accelerators), or the computational power
of multiple cores. Third, their protection against cache side-channel attacks
is either an afterthought or impractical, i.e., no fine-grained mapping between
cache resources and individual enclaves is provided.

In this work, we propose CURE, the first security architecture, which tackles
these design challenges by providing different types of enclaves: (i) sub-space
enclaves provide vertical isolation at all execution privilege levels, (ii)
user-space enclaves provide isolated execution to unprivileged applications,
and (iii) self-contained enclaves allow isolated execution environments that
span multiple privilege levels. Moreover, CURE enables the exclusive assignment
of system resources, e.g., peripherals, CPU cores, or cache resources to single
enclaves. CURE requires minimal hardware changes while significantly improving
the state of the art of hardware-assisted security architectures. We
implemented CURE on a RISC-V-based SoC and thoroughly evaluated our prototype
in terms of hardware and performance overhead. CURE imposes a geometric mean
performance overhead of 15.33% on standard benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.15866" target="_blank">arXiv:2010.15866</a> [<a href="http://arxiv.org/pdf/2010.15866" target="_blank">pdf</a>]

<h2>Retrieve, Program, Repeat: Complex Knowledge Base Question Answering via Alternate Meta-learning. (arXiv:2010.15875v1 [cs.AI])</h2>
<h3>Yuncheng Hua, Yuan-Fang Li, Gholamreza Haffari, Guilin Qi, Wei Wu</h3>
<p>A compelling approach to complex question answering is to convert the
question to a sequence of actions, which can then be executed on the knowledge
base to yield the answer, aka the programmer-interpreter approach. Use similar
training questions to the test question, meta-learning enables the programmer
to adapt to unseen questions to tackle potential distributional biases quickly.
However, this comes at the cost of manually labeling similar questions to learn
a retrieval model, which is tedious and expensive. In this paper, we present a
novel method that automatically learns a retrieval model alternately with the
programmer from weak supervision, i.e., the system's performance with respect
to the produced answers. To the best of our knowledge, this is the first
attempt to train the retrieval model with the programmer jointly. Our system
leads to state-of-the-art performance on a large-scale task for complex
question answering over knowledge bases. We have released our code at
https://github.com/DevinJake/MARL.
</p>
<a href="http://arxiv.org/abs/2010.15875" target="_blank">arXiv:2010.15875</a> [<a href="http://arxiv.org/pdf/2010.15875" target="_blank">pdf</a>]

<h2>Few-Shot Complex Knowledge Base Question Answering via Meta Reinforcement Learning. (arXiv:2010.15877v1 [cs.CL])</h2>
<h3>Yuncheng Hua, Yuan-Fang Li, Gholamreza Haffari, Guilin Qi, Tongtong Wu</h3>
<p>Complex question-answering (CQA) involves answering complex natural-language
questions on a knowledge base (KB). However, the conventional neural program
induction (NPI) approach exhibits uneven performance when the questions have
different types, harboring inherently different characteristics, e.g.,
difficulty level. This paper proposes a meta-reinforcement learning approach to
program induction in CQA to tackle the potential distributional bias in
questions. Our method quickly and effectively adapts the meta-learned
programmer to new questions based on the most similar questions retrieved from
the training data. The meta-learned policy is then used to learn a good
programming policy, utilizing the trial trajectories and their rewards for
similar questions in the support set. Our method achieves state-of-the-art
performance on the CQA dataset (Saha et al., 2018) while using only five trial
trajectories for the top-5 retrieved questions in each support set, and
metatraining on tasks constructed from only 1% of the training set. We have
released our code at https://github.com/DevinJake/MRL-CQA.
</p>
<a href="http://arxiv.org/abs/2010.15877" target="_blank">arXiv:2010.15877</a> [<a href="http://arxiv.org/pdf/2010.15877" target="_blank">pdf</a>]

<h2>Log(Graph): A Near-Optimal High-Performance Graph Representation. (arXiv:2010.15879v1 [cs.DS])</h2>
<h3>Maciej Besta, Dimitri Stanojevic, Tijana Zivic, Jagpreet Singh, Maurice Hoerold, Torsten Hoefler</h3>
<p>Today's graphs used in domains such as machine learning or social network
analysis may contain hundreds of billions of edges. Yet, they are not
necessarily stored efficiently, and standard graph representations such as
adjacency lists waste a significant number of bits while graph compression
schemes such as WebGraph often require time-consuming decompression. To address
this, we propose Log(Graph): a graph representation that combines high
compression ratios with very low-overhead decompression to enable cheaper and
faster graph processing. The key idea is to encode a graph so that the parts of
the representation approach or match the respective storage lower bounds. We
call our approach "graph logarithmization" because these bounds are usually
logarithmic. Our high-performance Log(Graph) implementation based on modern
bitwise operations and state-of-the-art succinct data structures achieves high
compression ratios as well as performance. For example, compared to the tuned
Graph Algorithm Processing Benchmark Suite (GAPBS), it reduces graph sizes by
20-35% while matching GAPBS' performance or even delivering speedups due to
reducing amounts of transferred data. It approaches the compression ratio of
the established WebGraph compression library while enabling speedups of up to
more than 2x. Log(Graph) can improve the design of various graph processing
engines or libraries on single NUMA nodes as well as distributed-memory
systems.
</p>
<a href="http://arxiv.org/abs/2010.15879" target="_blank">arXiv:2010.15879</a> [<a href="http://arxiv.org/pdf/2010.15879" target="_blank">pdf</a>]

<h2>Less is More: Data-Efficient Complex Question Answering over Knowledge Bases. (arXiv:2010.15881v1 [cs.CL])</h2>
<h3>Yuncheng Hua, Yuan-Fang Li, Guilin Qi, Wei Wu, Jingyao Zhang, Daiqing Qi</h3>
<p>Question answering is an effective method for obtaining information from
knowledge bases (KB). In this paper, we propose the Neural-Symbolic Complex
Question Answering (NS-CQA) model, a data-efficient reinforcement learning
framework for complex question answering by using only a modest number of
training samples. Our framework consists of a neural generator and a symbolic
executor that, respectively, transforms a natural-language question into a
sequence of primitive actions, and executes them over the knowledge base to
compute the answer. We carefully formulate a set of primitive symbolic actions
that allows us to not only simplify our neural network design but also
accelerate model convergence. To reduce search space, we employ the copy and
masking mechanisms in our encoder-decoder architecture to drastically reduce
the decoder output vocabulary and improve model generalizability. We equip our
model with a memory buffer that stores high-reward promising programs. Besides,
we propose an adaptive reward function. By comparing the generated trial with
the trials stored in the memory buffer, we derive the curriculum-guided reward
bonus, i.e., the proximity and the novelty. To mitigate the sparse reward
problem, we combine the adaptive reward and the reward bonus, reshaping the
sparse reward into dense feedback. Also, we encourage the model to generate new
trials to avoid imitating the spurious trials while making the model remember
the past high-reward trials to improve data efficiency. Our NS-CQA model is
evaluated on two datasets: CQA, a recent large-scale complex question answering
dataset, and WebQuestionsSP, a multi-hop question answering dataset. On both
datasets, our model outperforms the state-of-the-art models. Notably, on CQA,
NS-CQA performs well on questions with higher complexity, while only using
approximately 1% of the total training samples.
</p>
<a href="http://arxiv.org/abs/2010.15881" target="_blank">arXiv:2010.15881</a> [<a href="http://arxiv.org/pdf/2010.15881" target="_blank">pdf</a>]

<h2>Perception Matters: Exploring Imperceptible and Transferable Anti-forensics for GAN-generated Fake Face Imagery Detection. (arXiv:2010.15886v1 [cs.CV])</h2>
<h3>Yongwei Wang, Xin Ding, Li Ding, Rabab Ward, Z. Jane Wang</h3>
<p>Recently, generative adversarial networks (GANs) can generate photo-realistic
fake facial images which are perceptually indistinguishable from real face
photos, promoting research on fake face detection. Though fake face forensics
can achieve high detection accuracy, their anti-forensic counterparts are less
investigated. Here we explore more \textit{imperceptible} and
\textit{transferable} anti-forensics for fake face imagery detection based on
adversarial attacks. Since facial and background regions are often smooth, even
small perturbation could cause noticeable perceptual impairment in fake face
images. Therefore it makes existing adversarial attacks ineffective as an
anti-forensic method. Our perturbation analysis reveals the intuitive reason of
the perceptual degradation issue when directly applying existing attacks. We
then propose a novel adversarial attack method, better suitable for image
anti-forensics, in the transformed color domain by considering visual
perception. Simple yet effective, the proposed method can fool both deep
learning and non-deep learning based forensic detectors, achieving higher
attack success rate and significantly improved visual quality. Specially, when
adversaries consider imperceptibility as a constraint, the proposed
anti-forensic method can improve the average attack success rate by around 30\%
on fake face images over two baseline attacks. \textit{More imperceptible} and
\textit{more transferable}, the proposed method raises new security concerns to
fake face imagery detection. We have released our code for public use, and
hopefully the proposed method can be further explored in related forensic
applications as an anti-forensic benchmark.
</p>
<a href="http://arxiv.org/abs/2010.15886" target="_blank">arXiv:2010.15886</a> [<a href="http://arxiv.org/pdf/2010.15886" target="_blank">pdf</a>]

<h2>Multi-agent Trajectory Prediction with Fuzzy Query Attention. (arXiv:2010.15891v1 [cs.LG])</h2>
<h3>Nitin Kamra, Hao Zhu, Dweep Trivedi, Ming Zhang, Yan Liu</h3>
<p>Trajectory prediction for scenes with multiple agents and entities is a
challenging problem in numerous domains such as traffic prediction, pedestrian
tracking and path planning. We present a general architecture to address this
challenge which models the crucial inductive biases of motion, namely, inertia,
relative motion, intents and interactions. Specifically, we propose a
relational model to flexibly model interactions between agents in diverse
environments. Since it is well-known that human decision making is fuzzy by
nature, at the core of our model lies a novel attention mechanism which models
interactions by making continuous-valued (fuzzy) decisions and learning the
corresponding responses. Our architecture demonstrates significant performance
gains over existing state-of-the-art predictive models in diverse domains such
as human crowd trajectories, US freeway traffic, NBA sports data and physics
datasets. We also present ablations and augmentations to understand the
decision-making process and the source of gains in our model.
</p>
<a href="http://arxiv.org/abs/2010.15891" target="_blank">arXiv:2010.15891</a> [<a href="http://arxiv.org/pdf/2010.15891" target="_blank">pdf</a>]

<h2>Identification of Ischemic Heart Disease by using machine learning technique based on parameters measuring Heart Rate Variability. (arXiv:2010.15893v1 [eess.SP])</h2>
<h3>Giulia Silveri, Marco Merlo, Luca Restivo, Beatrice De Paola, Aleksandar Miladinovi&#x107;, Milo&#x161; Aj&#x10d;evi&#x107;, Gianfranco Sinagra, Agostino Accardo</h3>
<p>The diagnosis of heart diseases is a difficult task generally addressed by an
appropriate examination of patients clinical data. Recently, the use of heart
rate variability (HRV) analysis as well as of some machine learning algorithms,
has proved to be a valuable support in the diagnosis process. However, till
now, ischemic heart disease (IHD) has been diagnosed on the basis of Artificial
Neural Networks (ANN) applied only to signs, symptoms and sequential ECG and
coronary angiography, an invasive tool, while could be probably identified in a
non-invasive way by using parameters extracted from HRV, a signal easily
obtained from the ECG. In this study, 18 non-invasive features (age, gender,
left ventricular ejection fraction and 15 obtained from HRV) of 243 subjects
(156 normal subjects and 87 IHD patients) were used to train and validate a
series of several ANN, different for number of input and hidden nodes. The best
result was obtained using 7 input parameters and 7 hidden nodes with an
accuracy of 98.9% and 82% for the training and validation dataset,
respectively.
</p>
<a href="http://arxiv.org/abs/2010.15893" target="_blank">arXiv:2010.15893</a> [<a href="http://arxiv.org/pdf/2010.15893" target="_blank">pdf</a>]

<h2>Transfer Learning improves MI BCI models classification accuracy in Parkinson's disease patients. (arXiv:2010.15899v1 [eess.SP])</h2>
<h3>Aleksandar Miladinovi&#x107;, Milo&#x161; Aj&#x10d;evi&#x107;, Pierpaolo Busan, Joanna Jarmolowska, Giulia Silveri, Susanna Mezzarobba, Piero Paolo Battaglini, Agostino Accardo</h3>
<p>Motor-Imagery based BCI (MI-BCI) neurorehabilitation can improve locomotor
ability and reduce the deficit symptoms in Parkinson's Disease patients.
Advanced Motor-Imagery BCI methods are needed to overcome the accuracy and
time-related MI BCI calibration challenges in such patients. In this study, we
proposed a Multi-session FBCSP (msFBCSP) based on inter-session transfer
learning and we investigated its performance compared to the single-session
based FBSCP. The main result of this study is the significantly improved
accuracy obtained by proposed msFBCSP compared to single-session FBCSP in PD
patients (median 81.3%, range 41.2-100.0% vs median 61.1%, range 25.0-100.0%,
respectively; p&lt;0.001). In conclusion, this study proposes a transfer
learning-based multi-session based FBCSP approach which allowed to
significantly improve calibration accuracy in MI BCI performed on PD patients.
</p>
<a href="http://arxiv.org/abs/2010.15899" target="_blank">arXiv:2010.15899</a> [<a href="http://arxiv.org/pdf/2010.15899" target="_blank">pdf</a>]

<h2>A Comprehensive Comparison of End-to-End Approaches for Handwritten Digit String Recognition. (arXiv:2010.15904v1 [cs.CV])</h2>
<h3>Andre G. Hochuli, Alceu S. Britto Jr, David A. Saji, Jose M. Saavedra, Robert Sabourin, Luiz S. Oliveira</h3>
<p>Over the last decades, most approaches proposed for handwritten digit string
recognition (HDSR) have resorted to digit segmentation, which is dominated by
heuristics, thereby imposing substantial constraints on the final performance.
Few of them have been based on segmentation-free strategies where each pixel
column has a potential cut location. Recently, segmentation-free strategies has
added another perspective to the problem, leading to promising results.
However, these strategies still show some limitations when dealing with a large
number of touching digits. To bridge the resulting gap, in this paper, we
hypothesize that a string of digits can be approached as a sequence of objects.
We thus evaluate different end-to-end approaches to solve the HDSR problem,
particularly in two verticals: those based on object-detection (e.g., Yolo and
RetinaNet) and those based on sequence-to-sequence representation (CRNN). The
main contribution of this work lies in its provision of a comprehensive
comparison with a critical analysis of the above mentioned strategies on five
benchmarks commonly used to assess HDSR, including the challenging Touching
Pair dataset, NIST SD19, and two real-world datasets (CAR and CVL) proposed for
the ICFHR 2014 competition on HDSR. Our results show that the Yolo model
compares favorably against segmentation-free models with the advantage of
having a shorter pipeline that minimizes the presence of heuristics-based
models. It achieved a 97%, 96%, and 84% recognition rate on the NIST-SD19, CAR,
and CVL datasets, respectively.
</p>
<a href="http://arxiv.org/abs/2010.15904" target="_blank">arXiv:2010.15904</a> [<a href="http://arxiv.org/pdf/2010.15904" target="_blank">pdf</a>]

<h2>Graph Neural Network for Metal Organic Framework Potential Energy Approximation. (arXiv:2010.15908v1 [cs.LG])</h2>
<h3>Shehtab Zaman, Christopher Owen, Kenneth Chiu, Michael Lawler</h3>
<p>Metal-organic frameworks (MOFs) are nanoporous compounds composed of metal
ions and organic linkers. MOFs play an important role in industrial
applications such as gas separation, gas purification, and electrolytic
catalysis. Important MOF properties such as potential energy are currently
computed via techniques such as density functional theory (DFT). Although DFT
provides accurate results, it is computationally costly. We propose a machine
learning approach for estimating the potential energy of candidate MOFs,
decomposing it into separate pair-wise atomic interactions using a graph neural
network. Such a technique will allow high-throughput screening of candidates
MOFs. We also generate a database of 50,000 spatial configurations and
high-quality potential energy values using DFT.
</p>
<a href="http://arxiv.org/abs/2010.15908" target="_blank">arXiv:2010.15908</a> [<a href="http://arxiv.org/pdf/2010.15908" target="_blank">pdf</a>]

<h2>Learning as Abduction: Trainable Natural Logic Theorem Prover for Natural Language Inference. (arXiv:2010.15909v1 [cs.CL])</h2>
<h3>Lasha Abzianidze</h3>
<p>Tackling Natural Language Inference with a logic-based method is becoming
less and less common. While this might have been counterintuitive several
decades ago, nowadays it seems pretty obvious. The main reasons for such a
conception are that (a) logic-based methods are usually brittle when it comes
to processing wide-coverage texts, and (b) instead of automatically learning
from data, they require much of manual effort for development. We make a step
towards to overcome such shortcomings by modeling learning from data as
abduction: reversing a theorem-proving procedure to abduce semantic relations
that serve as the best explanation for the gold label of an inference problem.
In other words, instead of proving sentence-level inference relations with the
help of lexical relations, the lexical relations are proved taking into account
the sentence-level inference relations. We implement the learning method in a
tableau theorem prover for natural language and show that it improves the
performance of the theorem prover on the SICK dataset by 1.4% while still
maintaining high precision (&gt;94%). The obtained results are competitive with
the state of the art among logic-based systems.
</p>
<a href="http://arxiv.org/abs/2010.15909" target="_blank">arXiv:2010.15909</a> [<a href="http://arxiv.org/pdf/2010.15909" target="_blank">pdf</a>]

<h2>GripNet: Graph Information Propagation on Supergraph for Heterogeneous Graphs. (arXiv:2010.15914v1 [cs.LG])</h2>
<h3>Hao Xu, Shengqi Sang, Peizhen Bai, Laurence Yang, Haiping Lu</h3>
<p>Heterogeneous graph representation learning aims to learn low-dimensional
vector representations of different types of entities and relations to empower
downstream tasks. Existing methods either capture semantic relationships but
indirectly leverage node/edge attributes in a complex way, or leverage
node/edge attributes directly without taking semantic relationships into
account. When involving multiple convolution operations, they also have poor
scalability. To overcome these limitations, this paper proposes a flexible and
efficient Graph information propagation Network (GripNet) framework.
Specifically, we introduce a new supergraph data structure consisting of
supervertices and superedges. A supervertex is a semantically-coherent
subgraph. A superedge defines an information propagation path between two
supervertices. GripNet learns new representations for the supervertex of
interest by propagating information along the defined path using multiple
layers. We construct multiple large-scale graphs and evaluate GripNet against
competing methods to show its superiority in link prediction, node
classification, and data integration.
</p>
<a href="http://arxiv.org/abs/2010.15914" target="_blank">arXiv:2010.15914</a> [<a href="http://arxiv.org/pdf/2010.15914" target="_blank">pdf</a>]

<h2>Recovery RL: Safe Reinforcement Learning with Learned Recovery Zones. (arXiv:2010.15920v1 [cs.LG])</h2>
<h3>Brijen Thananjeyan, Ashwin Balakrishna, Suraj Nair, Michael Luo, Krishnan Srinivasan, Minho Hwang, Joseph E. Gonzalez, Julian Ibarz, Chelsea Finn, Ken Goldberg</h3>
<p>Safety remains a central obstacle preventing widespread use of RL in the real
world: learning new tasks in uncertain environments requires extensive
exploration, but safety requires limiting exploration. We propose Recovery RL,
an algorithm which navigates this tradeoff by (1) leveraging offline data to
learn about constraint violating zones before policy learning and (2)
separating the goals of improving task performance and constraint satisfaction
across two policies: a task policy that only optimizes the task reward and a
recovery policy that guides the agent to safety when constraint violation is
likely. We evaluate Recovery RL on 6 simulation domains, including two
contact-rich manipulation tasks and an image-based navigation task, and an
image-based obstacle avoidance task on a physical robot. We compare Recovery RL
to 5 prior safe RL methods which jointly optimize for task performance and
safety via constrained optimization or reward shaping and find that Recovery RL
outperforms the next best prior method across all domains. Results suggest that
Recovery RL trades off constraint violations and task successes 2 - 80 times
more efficiently in simulation domains and 3 times more efficiently in physical
experiments. See https://tinyurl.com/rl-recovery for videos and supplementary
material.
</p>
<a href="http://arxiv.org/abs/2010.15920" target="_blank">arXiv:2010.15920</a> [<a href="http://arxiv.org/pdf/2010.15920" target="_blank">pdf</a>]

<h2>How Many Pages? Paper Length Prediction from the Metadata. (arXiv:2010.15924v1 [cs.CL])</h2>
<h3>Erion &#xc7;ano, Ond&#x159;ej Bojar</h3>
<p>Being able to predict the length of a scientific paper may be helpful in
numerous situations. This work defines the paper length prediction task as a
regression problem and reports several experimental results using popular
machine learning models. We also create a huge dataset of publication metadata
and the respective lengths in number of pages. The dataset will be freely
available and is intended to foster research in this domain. As future work, we
would like to explore more advanced regressors based on neural networks and big
pretrained language models.
</p>
<a href="http://arxiv.org/abs/2010.15924" target="_blank">arXiv:2010.15924</a> [<a href="http://arxiv.org/pdf/2010.15924" target="_blank">pdf</a>]

<h2>Detecting small polyps using a Dynamic SSD-GAN. (arXiv:2010.15937v1 [cs.CV])</h2>
<h3>Daniel C. Ohrenstein, Patrick Brandao, Daniel Toth, Laurence Lovat, Danail Stoyanov, Peter Mountney</h3>
<p>Endoscopic examinations are used to inspect the throat, stomach and bowel for
polyps which could develop into cancer. Machine learning systems can be trained
to process colonoscopy images and detect polyps. However, these systems tend to
perform poorly on objects which appear visually small in the images. It is
shown here that combining the single-shot detector as a region proposal network
with an adversarially-trained generator to upsample small region proposals can
significantly improve the detection of visually-small polyps. The Dynamic
SSD-GAN pipeline introduced in this paper achieved a 12% increase in
sensitivity on visually-small polyps compared to a conventional FCN baseline.
</p>
<a href="http://arxiv.org/abs/2010.15937" target="_blank">arXiv:2010.15937</a> [<a href="http://arxiv.org/pdf/2010.15937" target="_blank">pdf</a>]

<h2>Human versus Machine Attention in Deep Reinforcement Learning Tasks. (arXiv:2010.15942v1 [cs.LG])</h2>
<h3>Ruohan Zhang, Bo Liu, Yifeng Zhu, Sihang Guo, Mary Hayhoe, Dana Ballard, Peter Stone</h3>
<p>Deep reinforcement learning (RL) algorithms are powerful tools for solving
visuomotor decision tasks. However, the trained models are often difficult to
interpret, because they are represented as end-to-end deep neural networks. In
this paper, we shed light on the inner workings of such trained models by
analyzing the pixels that they attend to during task execution, and comparing
them with the pixels attended to by humans executing the same tasks. To this
end, we investigate the following two questions that, to the best of our
knowledge, have not been previously studied. 1) How similar are the visual
features learned by RL agents and humans when performing the same task? and, 2)
How do similarities and differences in these learned features correlate with RL
agents' performance on these tasks? Specifically, we compare the saliency maps
of RL agents against visual attention models of human experts when learning to
play Atari games. Further, we analyze how hyperparameters of the deep RL
algorithm affect the learned features and saliency maps of the trained agents.
The insights provided by our results have the potential to inform novel
algorithms for the purpose of closing the performance gap between human experts
and deep RL agents.
</p>
<a href="http://arxiv.org/abs/2010.15942" target="_blank">arXiv:2010.15942</a> [<a href="http://arxiv.org/pdf/2010.15942" target="_blank">pdf</a>]

<h2>PAL : Pretext-based Active Learning. (arXiv:2010.15947v1 [cs.CV])</h2>
<h3>Shubhang Bhatnagar, Darshan Tank, Sachin Goyal, Amit Sethi</h3>
<p>When obtaining labels is expensive, the requirement of a large labeled
training data set for deep learning can be mitigated by active learning. Active
learning refers to the development of algorithms to judiciously pick limited
subsets of unlabeled samples that can be sent for labeling by an oracle. We
propose an intuitive active learning technique that, in addition to the task
neural network (e.g., for classification), uses an auxiliary self-supervised
neural network that assesses the utility of an unlabeled sample for inclusion
in the labeled set. Our core idea is that the difficulty of the auxiliary
network trained on labeled samples to solve a self-supervision task on an
unlabeled sample represents the utility of obtaining the label of that
unlabeled sample. Specifically, we assume that an unlabeled image on which the
precision of predicting a random applied geometric transform is low must be out
of the distribution represented by the current set of labeled images. These
images will therefore maximize the relative information gain when labeled by
the oracle. We also demonstrate that augmenting the auxiliary network with task
specific training further improves the results. We demonstrate strong
performance on a range of widely used datasets and establish a new state of the
art for active learning. We also make our code publicly available to encourage
further research.
</p>
<a href="http://arxiv.org/abs/2010.15947" target="_blank">arXiv:2010.15947</a> [<a href="http://arxiv.org/pdf/2010.15947" target="_blank">pdf</a>]

<h2>Bayes-Adaptive Deep Model-Based Policy Optimisation. (arXiv:2010.15948v1 [cs.RO])</h2>
<h3>Tai Hoang, Vien Ngo</h3>
<p>We introduce a Bayesian (deep) model-based reinforcement learning method
(RoMBRL) that can capture model uncertainty to achieve sample-efficient policy
optimisation. We propose to formulate the model-based policy optimisation
problem as a Bayes-adaptive Markov decision process (BAMDP). RoMBRL maintains
model uncertainty via belief distributions through a deep Bayesian neural
network whose samples are generated via stochastic gradient Hamiltonian Monte
Carlo. Uncertainty is propagated through simulations controlled by sampled
models and history-based policies. As beliefs are encoded in visited histories,
we propose a history-based policy network that can be end-to-end trained to
generalise across history space and will be trained using recurrent
Trust-Region Policy Optimisation. We show that RoMBRL outperforms existing
approaches on many challenging control benchmark tasks in terms of sample
complexity and task performance. The source code of this paper is also publicly
available on https://github.com/thobotics/RoMBRL.
</p>
<a href="http://arxiv.org/abs/2010.15948" target="_blank">arXiv:2010.15948</a> [<a href="http://arxiv.org/pdf/2010.15948" target="_blank">pdf</a>]

<h2>Graph Regularized Autoencoder and its Application in Unsupervised Anomaly Detection. (arXiv:2010.15949v1 [cs.LG])</h2>
<h3>Imtiaz Ahmed, Travis Galoppo, Xia Hu, Yu Ding</h3>
<p>Dimensionality reduction is a crucial first step for many unsupervised
learning tasks including anomaly detection. Autoencoder is a popular mechanism
to accomplish the goal of dimensionality reduction. In order to make
dimensionality reduction effective for high-dimensional data embedding
nonlinear low-dimensional manifold, it is understood that some sort of geodesic
distance metric should be used to discriminate the data samples. Inspired by
the success of neighborhood aware shortest path based geodesic approximatiors
such as ISOMAP, in this work, we propose to use a minimum spanning tree (MST),
a graph-based algorithm, to approximate the local neighborhood structure and
generate structure-preserving distances among data points. We use this
MST-based distance metric to replace the Euclidean distance metric in the
embedding function of autoencoders and develop a new graph regularized
autoencoder, which outperforms, over 20 benchmark anomaly detection datasets,
the plain autoencoder using no regularizer as well as the autoencoders using
the Euclidean-based regularizer. We furthermore incorporate the MST regularizer
into two generative adversarial networks and find that using the MST
regularizer improves the performance of anomaly detection substantially for
both generative adversarial networks.
</p>
<a href="http://arxiv.org/abs/2010.15949" target="_blank">arXiv:2010.15949</a> [<a href="http://arxiv.org/pdf/2010.15949" target="_blank">pdf</a>]

<h2>Deep Jump Q-Evaluation for Offline Policy Evaluation in Continuous Action Space. (arXiv:2010.15963v1 [stat.ML])</h2>
<h3>Hengrui Cai, Chengchun Shi, Rui Song, Wenbin Lu</h3>
<p>We consider off-policy evaluation (OPE) in continuous action domains, such as
dynamic pricing and personalized dose finding. In OPE, one aims to learn the
value under a new policy using historical data generated by a different
behavior policy. Most existing works on OPE focus on discrete action domains.
To handle continuous action space, we develop a brand-new deep jump
Q-evaluation method for OPE. The key ingredient of our method lies in
adaptively discretizing the action space using deep jump Q-learning. This
allows us to apply existing OPE methods in discrete domains to handle
continuous actions. Our method is further justified by theoretical results,
synthetic and real datasets.
</p>
<a href="http://arxiv.org/abs/2010.15963" target="_blank">arXiv:2010.15963</a> [<a href="http://arxiv.org/pdf/2010.15963" target="_blank">pdf</a>]

<h2>Training Speech Recognition Models with Federated Learning: A Quality/Cost Framework. (arXiv:2010.15965v1 [cs.LG])</h2>
<h3>Dhruv Guliani, Francoise Beaufays, Giovanni Motta</h3>
<p>We propose using federated learning, a decentralized on-device learning
paradigm, to train speech recognition models. By performing epochs of training
on a per-user basis, federated learning must incur the cost of dealing with
non-IID data distributions, which are expected to negatively affect the quality
of the trained model. We propose a framework by which the degree of
non-IID-ness can be varied, consequently illustrating a trade-off between model
quality and the computational cost of federated training, which we capture
through a novel metric. Finally, we demonstrate that hyper-parameter
optimization and appropriate use of variational noise are sufficient to
compensate for the quality impact of non-IID distributions, while decreasing
the cost.
</p>
<a href="http://arxiv.org/abs/2010.15965" target="_blank">arXiv:2010.15965</a> [<a href="http://arxiv.org/pdf/2010.15965" target="_blank">pdf</a>]

<h2>Entanglement Induced Barren Plateaus. (arXiv:2010.15968v1 [quant-ph])</h2>
<h3>Carlos Ortiz Marrero, M&#xe1;ria Kieferov&#xe1;, Nathan Wiebe</h3>
<p>We argue that an excess in entanglement between the visible and hidden units
in a Quantum Neural Network can hinder learning. In particular, we show that
quantum neural networks that satisfy a volume-law in the entanglement entropy
will give rise to models not suitable for learning with high probability. Using
arguments from quantum thermodynamics, we then show that this volume law is
typical and that there exists a barren plateau in the optimization landscape
due to entanglement. More precisely, we show that for any bounded objective
function on the visible layers, the Lipshitz constants of the expectation value
of that objective function will scale inversely with the dimension of the
hidden-subsystem with high probability. We show how this can cause both
gradient descent and gradient-free methods to fail. We note that similar
problems can happen with quantum Boltzmann machines, although stronger
assumptions on the coupling between the hidden/visible subspaces are necessary.
We highlight how pretraining such generative models may provide a way to
navigate these barren plateaus.
</p>
<a href="http://arxiv.org/abs/2010.15968" target="_blank">arXiv:2010.15968</a> [<a href="http://arxiv.org/pdf/2010.15968" target="_blank">pdf</a>]

<h2>Can the state of relevant neurons in a deep neural networks serve as indicators for detecting adversarial attacks?. (arXiv:2010.15974v1 [cs.CV])</h2>
<h3>Roger Granda, Tinne Tuytelaars, Jose Oramas</h3>
<p>We present a method for adversarial attack detection based on the inspection
of a sparse set of neurons. We follow the hypothesis that adversarial attacks
introduce imperceptible perturbations in the input and that these perturbations
change the state of neurons relevant for the concepts modelled by the attacked
model. Therefore, monitoring the status of these neurons would enable the
detection of adversarial attacks. Focusing on the image classification task,
our method identifies neurons that are relevant for the classes predicted by
the model. A deeper qualitative inspection of these sparse set of neurons
indicates that their state changes in the presence of adversarial samples.
Moreover, quantitative results from our empirical evaluation indicate that our
method is capable of recognizing adversarial samples, produced by
state-of-the-art attack methods, with comparable accuracy to that of
state-of-the-art detectors.
</p>
<a href="http://arxiv.org/abs/2010.15974" target="_blank">arXiv:2010.15974</a> [<a href="http://arxiv.org/pdf/2010.15974" target="_blank">pdf</a>]

<h2>Examining the Relationship of Code and Architectural Smells with Software Vulnerabilities. (arXiv:2010.15978v1 [cs.SE])</h2>
<h3>Kazi Zakia Sultana, Zadia Codabux, Byron Williams</h3>
<p>Context: Security is vital to software developed for commercial or personal
use. Although more organizations are realizing the importance of applying
secure coding practices, in many of them, security concerns are not known or
addressed until a security failure occurs. The root cause of security failures
is vulnerable code. While metrics have been used to predict software
vulnerabilities, we explore the relationship between code and architectural
smells with security weaknesses. As smells are surface indicators of a deeper
problem in software, determining the relationship between smells and software
vulnerabilities can play a significant role in vulnerability prediction models.
Objective: This study explores the relationship between smells and software
vulnerabilities to identify the smells. Method: We extracted the class, method,
file, and package level smells for three systems: Apache Tomcat, Apache CXF,
and Android. We then compared their occurrences in the vulnerable classes which
were reported to contain vulnerable code and in the neutral classes
(non-vulnerable classes where no vulnerability had yet been reported). Results:
We found that a vulnerable class is more likely to have certain smells compared
to a non-vulnerable class. God Class, Complex Class, Large Class, Data Class,
Feature Envy, Brain Class have a statistically significant relationship with
software vulnerabilities. We found no significant relationship between
architectural smells and software vulnerabilities. Conclusion: We can conclude
that for all the systems examined, there is a statistically significant
correlation between software vulnerabilities and some smells.
</p>
<a href="http://arxiv.org/abs/2010.15978" target="_blank">arXiv:2010.15978</a> [<a href="http://arxiv.org/pdf/2010.15978" target="_blank">pdf</a>]

<h2>A Model of Two Tales: Dual Transfer Learning Framework for Improved Long-tail Item Recommendation. (arXiv:2010.15982v1 [cs.IR])</h2>
<h3>Yin Zhang, Derek Zhiyuan Cheng, Tiansheng Yao, Xinyang Yi, Lichan Hong, Ed H. Chi</h3>
<p>Highly skewed long-tail item distribution is very common in recommendation
systems. It significantly affects model performance, and especially on tail
items. To improve tail-item recommendation, we conduct research to transfer
knowledge from head items to tail items, leveraging the rich user feedback in
head items and the semantic connections between head and tail items.
Specifically, we propose a novel dual transfer learning framework that
collaboratively learns the knowledge transfer from both model-level and
item-level. The model-level knowledge transfer builds a generic meta-mapping of
model parameters from few-shot to many-shot model. It captures the implicit
data augmentation on the model level to improve the representation learning of
tail items. The item-level transfer connects head and tail items through
item-level features, to ensure a smooth transfer of meta-mapping from head
items to tail items. The two types of transfers are incorporated to ensure the
learned knowledge from head items can be well applied for tail item
representation learning in the long-tail distribution settings. Through
extensive experiments on two benchmark datasets, results show that our proposed
dual transfer learning framework significantly outperforms other
state-of-the-art methods for tail item recommendation in hit ratio and NDCG. It
is also very encouraging that our framework further improves head items and
overall performance on top of the gains on tail items.
</p>
<a href="http://arxiv.org/abs/2010.15982" target="_blank">arXiv:2010.15982</a> [<a href="http://arxiv.org/pdf/2010.15982" target="_blank">pdf</a>]

<h2>Differential Privacy and Natural Language Processing to Generate Contextually Similar Decoy Messages in Honey Encryption Scheme. (arXiv:2010.15985v1 [cs.CR])</h2>
<h3>Kunjal Panchal</h3>
<p>Honey Encryption is an approach to encrypt the messages using low min-entropy
keys, such as weak passwords, OTPs, PINs, credit card numbers. The ciphertext
is produces, when decrypted with any number of incorrect keys, produces
plausible-looking but bogus plaintext called "honey messages". But the current
techniques used in producing the decoy plaintexts do not model human language
entirely. A gibberish, random assortment of words is not enough to fool an
attacker; that will not be acceptable and convincing, whether or not the
attacker knows some information of the genuine source.

In this paper, I focus on the plaintexts which are some non-numeric
informative messages. In order to fool the attacker into believing that the
decoy message can actually be from a certain source, we need to capture the
empirical and contextual properties of the language. That is, there should be
no linguistic difference between real and fake message, without revealing the
structure of the real message. I employ natural language processing and
generalized differential privacy to solve this problem. Mainly I focus on
machine learning methods like keyword extraction, context classification,
bags-of-words, word embeddings, transformers for text processing to model
privacy for text documents. Then I prove the security of this approach with
e-differential privacy.
</p>
<a href="http://arxiv.org/abs/2010.15985" target="_blank">arXiv:2010.15985</a> [<a href="http://arxiv.org/pdf/2010.15985" target="_blank">pdf</a>]

<h2>AutoAtlas: Neural Network for 3D Unsupervised Partitioning and Representation Learning. (arXiv:2010.15987v1 [eess.IV])</h2>
<h3>K. Aditya Mohan, Alan D. Kaplan</h3>
<p>We present a novel neural network architecture called AutoAtlas for fully
unsupervised partitioning and representation learning of 3D brain Magnetic
Resonance Imaging (MRI) volumes. AutoAtlas consists of two neural network
components: one that performs multi-label partitioning based on local texture
in the volume and a second that compresses the information contained within
each partition. We train both of these components simultaneously by optimizing
a loss function that is designed to promote accurate reconstruction of each
partition, while encouraging spatially smooth and contiguous partitioning, and
discouraging relatively small partitions. We show that the partitions adapt to
the subject specific structural variations of brain tissue while consistently
appearing at similar spatial locations across subjects. AutoAtlas also produces
very low dimensional features that represent local texture of each partition.
We demonstrate prediction of metadata associated with each subject using the
derived feature representations and compare the results to prediction using
features derived from FreeSurfer anatomical parcellation. Since our features
are intrinsically linked to distinct partitions, we can then map values of
interest, such as partition-specific feature importance scores onto the brain
for visualization.
</p>
<a href="http://arxiv.org/abs/2010.15987" target="_blank">arXiv:2010.15987</a> [<a href="http://arxiv.org/pdf/2010.15987" target="_blank">pdf</a>]

<h2>Lessons Learned from the 1st ARIEL Machine Learning Challenge: Correcting Transiting Exoplanet Light Curves for Stellar Spots. (arXiv:2010.15996v1 [astro-ph.IM])</h2>
<h3>Nikolaos Nikolaou, Ingo P. Waldmann, Angelos Tsiaras, Mario Morvan, Billy Edwards, Kai Hou Yip, Giovanna Tinetti, Subhajit Sarkar, James M. Dawson, Vadim Borisov, Gjergji Kasneci, Matej Petkovic, Tomaz Stepisnik, Tarek Al-Ubaidi, Rachel Louise Bailey, Michael Granitzer, Sahib Julka, Roman Kern, Patrick Ofner, Stefan Wagner, Lukas Heppe, Mirko Bunse, Katharina Morik</h3>
<p>The last decade has witnessed a rapid growth of the field of exoplanet
discovery and characterisation. However, several big challenges remain, many of
which could be addressed using machine learning methodology. For instance, the
most prolific method for detecting exoplanets and inferring several of their
characteristics, transit photometry, is very sensitive to the presence of
stellar spots. The current practice in the literature is to identify the
effects of spots visually and correct for them manually or discard the affected
data. This paper explores a first step towards fully automating the efficient
and precise derivation of transit depths from transit light curves in the
presence of stellar spots. The methods and results we present were obtained in
the context of the 1st Machine Learning Challenge organized for the European
Space Agency's upcoming Ariel mission. We first present the problem, the
simulated Ariel-like data and outline the Challenge while identifying best
practices for organizing similar challenges in the future. Finally, we present
the solutions obtained by the top-5 winning teams, provide their code and
discuss their implications. Successful solutions either construct highly
non-linear (w.r.t. the raw data) models with minimal preprocessing -deep neural
networks and ensemble methods- or amount to obtaining meaningful statistics
from the light curves, constructing linear models on which yields comparably
good predictive performance.
</p>
<a href="http://arxiv.org/abs/2010.15996" target="_blank">arXiv:2010.15996</a> [<a href="http://arxiv.org/pdf/2010.15996" target="_blank">pdf</a>]

<h2>Unsupervised One-shot Learning of Both Specific Instances and Generalised Classes with a Hippocampal Architecture. (arXiv:2010.15999v1 [cs.LG])</h2>
<h3>Gideon Kowadlo, Abdelrahman Ahmed, David Rawlinson</h3>
<p>Established experimental procedures for one-shot machine learning do not test
the ability to learn or remember specific instances of classes, a key feature
of animal intelligence. Distinguishing specific instances is necessary for many
real-world tasks, such as remembering which cup belongs to you. Generalisation
within classes conflicts with the ability to separate instances of classes,
making it difficult to achieve both capabilities within a single architecture.
We propose an extension to the standard Omniglot classification-generalisation
framework that additionally tests the ability to distinguish specific instances
after one exposure and introduces noise and occlusion corruption. Learning is
defined as an ability to classify as well as recall training samples.
Complementary Learning Systems (CLS) is a popular model of mammalian brain
regions believed to play a crucial role in learning from a single exposure to a
stimulus. We created an artificial neural network implementation of CLS and
applied it to the extended Omniglot benchmark. Our unsupervised model
demonstrates comparable performance to existing supervised ANNs on the Omniglot
classification task (requiring generalisation), without the need for
domain-specific inductive biases. On the extended Omniglot instance-recognition
task, the same model also demonstrates significantly better performance than a
baseline nearest-neighbour approach, given partial occlusion and noise.
</p>
<a href="http://arxiv.org/abs/2010.15999" target="_blank">arXiv:2010.15999</a> [<a href="http://arxiv.org/pdf/2010.15999" target="_blank">pdf</a>]

<h2>PIINET: A 360-degree Panoramic Image Inpainting Network Using a Cube Map. (arXiv:2010.16003v1 [eess.IV])</h2>
<h3>Seo Woo Han, Doug Young Suh</h3>
<p>Inpainting has been continuously studied in the field of computer vision. As
artificial intelligence technology developed, deep learning technology was
introduced in inpainting research, helping to improve performance. Currently,
the input target of an inpainting algorithm using deep learning has been
studied from a single image to a video. However, deep learning-based inpainting
technology for panoramic images has not been actively studied. We propose a
360-degree panoramic image inpainting method using generative adversarial
networks (GANs). The proposed network inputs a 360-degree equirectangular
format panoramic image converts it into a cube map format, which has relatively
little distortion and uses it as a training network. Since the cube map format
is used, the correlation of the six sides of the cube map should be considered.
Therefore, all faces of the cube map are used as input for the whole
discriminative network, and each face of the cube map is used as input for the
slice discriminative network to determine the authenticity of the generated
image. The proposed network performed qualitatively better than existing
single-image inpainting algorithms and baseline algorithms.
</p>
<a href="http://arxiv.org/abs/2010.16003" target="_blank">arXiv:2010.16003</a> [<a href="http://arxiv.org/pdf/2010.16003" target="_blank">pdf</a>]

<h2>Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View. (arXiv:2010.16010v1 [cs.CV])</h2>
<h3>Yangyang Guo, Liqiang Nie, Zhiyong Cheng, Qi Tian</h3>
<p>Recent studies have pointed out that many well-developed Visual Question
Answering (VQA) models are heavily affected by the language prior problem,
which refers to making predictions based on the co-occurrence pattern between
textual questions and answers instead of reasoning visual contents. To tackle
it, most existing methods focus on enhancing visual feature learning to reduce
this superficial textual shortcut influence on VQA model decisions. However,
limited effort has been devoted to providing an explicit interpretation for its
inherent cause. It thus lacks a good guidance for the research community to
move forward in a purposeful way, resulting in model construction perplexity in
overcoming this non-trivial problem. In this paper, we propose to interpret the
language prior problem in VQA from a class-imbalance view. Concretely, we
design a novel interpretation scheme whereby the loss of mis-predicted frequent
and sparse answers of the same question type is distinctly exhibited during the
late training phase. It explicitly reveals why the VQA model tends to produce a
frequent yet obviously wrong answer, to a given question whose right answer is
sparse in the training set. Based upon this observation, we further develop a
novel loss re-scaling approach to assign different weights to each answer based
on the training data statistics for computing the final loss. We apply our
approach into three baselines and the experimental results on two VQA-CP
benchmark datasets evidently demonstrate its effectiveness. In addition, we
also justify the validity of the class imbalance interpretation scheme on other
computer vision tasks, such as face recognition and image classification.
</p>
<a href="http://arxiv.org/abs/2010.16010" target="_blank">arXiv:2010.16010</a> [<a href="http://arxiv.org/pdf/2010.16010" target="_blank">pdf</a>]

<h2>POMO: Policy Optimization with Multiple Optima for Reinforcement Learning. (arXiv:2010.16011v1 [cs.LG])</h2>
<h3>Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon, Seungjai Min, Youngjune Gwon</h3>
<p>In neural combinatorial optimization (CO), reinforcement learning (RL) can
turn a deep neural net into a fast, powerful heuristic solver of NP-hard
problems. This approach has a great potential in practical applications because
it allows near-optimal solutions to be found without expert guides armed with
substantial domain knowledge. We introduce Policy Optimization with Multiple
Optima (POMO), an end-to-end approach for building such a heuristic solver.
POMO is applicable to a wide range of CO problems. It is designed to exploit
the symmetries in the representation of a CO solution. POMO uses a modified
REINFORCE algorithm that forces diverse rollouts towards all optimal solutions.
Empirically, the low-variance baseline of POMO makes RL training fast and
stable, and it is more resistant to local minima compared to previous
approaches. We also introduce a new augmentation-based inference method, which
accompanies POMO nicely. We demonstrate the effectiveness of POMO by solving
three popular NP-hard problems, namely, traveling salesman (TSP), capacitated
vehicle routing (CVRP), and 0-1 knapsack (KP). For all three, our solver based
on POMO shows a significant improvement in performance over all recent learned
heuristics. In particular, we achieve the optimality gap of 0.14% with TSP100
while reducing inference time by more than an order of magnitude.
</p>
<a href="http://arxiv.org/abs/2010.16011" target="_blank">arXiv:2010.16011</a> [<a href="http://arxiv.org/pdf/2010.16011" target="_blank">pdf</a>]

<h2>Multimodal Metric Learning for Tag-based Music Retrieval. (arXiv:2010.16030v1 [cs.IR])</h2>
<h3>Minz Won, Sergio Oramas, Oriol Nieto, Fabien Gouyon, Xavier Serra</h3>
<p>Tag-based music retrieval is crucial to browse large-scale music libraries
efficiently. Hence, automatic music tagging has been actively explored, mostly
as a classification task, which has an inherent limitation: a fixed vocabulary.
On the other hand, metric learning enables flexible vocabularies by using
pretrained word embeddings as side information. Also, metric learning has
already proven its suitability for cross-modal retrieval tasks in other domains
(e.g., text-to-image) by jointly learning a multimodal embedding space. In this
paper, we investigate three ideas to successfully introduce multimodal metric
learning for tag-based music retrieval: elaborate triplet sampling, acoustic
and cultural music information, and domain-specific word embeddings. Our
experimental results show that the proposed ideas enhance the retrieval system
quantitatively, and qualitatively. Furthermore, we release the MSD500, a subset
of the Million Song Dataset (MSD) containing 500 cleaned tags, 7 manually
annotated tag categories, and user taste profiles.
</p>
<a href="http://arxiv.org/abs/2010.16030" target="_blank">arXiv:2010.16030</a> [<a href="http://arxiv.org/pdf/2010.16030" target="_blank">pdf</a>]

<h2>Semantic Labeling Using a Deep Contextualized Language Model. (arXiv:2010.16037v1 [cs.LG])</h2>
<h3>Mohamed Trabelsi, Jin Cao, Jeff Heflin</h3>
<p>Generating schema labels automatically for column values of data tables has
many data science applications such as schema matching, and data discovery and
linking. For example, automatically extracted tables with missing headers can
be filled by the predicted schema labels which significantly minimizes human
effort. Furthermore, the predicted labels can reduce the impact of inconsistent
names across multiple data tables. Understanding the connection between column
values and contextual information is an important yet neglected aspect as
previously proposed methods treat each column independently. In this paper, we
propose a context-aware semantic labeling method using both the column values
and context. Our new method is based on a new setting for semantic labeling,
where we sequentially predict labels for an input table with missing headers.
We incorporate both the values and context of each data column using the
pre-trained contextualized language model, BERT, that has achieved significant
improvements in multiple natural language processing tasks. To our knowledge,
we are the first to successfully apply BERT to solve the semantic labeling
task. We evaluate our approach using two real-world datasets from different
domains, and we demonstrate substantial improvements in terms of evaluation
metrics over state-of-the-art feature-based methods.
</p>
<a href="http://arxiv.org/abs/2010.16037" target="_blank">arXiv:2010.16037</a> [<a href="http://arxiv.org/pdf/2010.16037" target="_blank">pdf</a>]

<h2>FLANNEL: Focal Loss Based Neural Network Ensemble for COVID-19 Detection. (arXiv:2010.16039v1 [eess.IV])</h2>
<h3>Zhi Qiao, Austin Bae, Lucas M. Glass, Cao Xiao, Jimeng Sun</h3>
<p>To test the possibility of differentiating chest x-ray images of COVID-19
against other pneumonia and healthy patients using deep neural networks. We
construct the X-ray imaging data from two publicly available sources, which
include 5508 chest x-ray images across 2874 patients with four classes: normal,
bacterial pneumonia, non-COVID-19 viral pneumonia, and COVID-19. To identify
COVID-19, we propose a Focal Loss Based Neural Ensemble Network (FLANNEL), a
flexible module to ensemble several convolutional neural network (CNN) models
and fuse with a focal loss for accurate COVID-19 detection on class imbalance
data. FLANNEL consistently outperforms baseline models on COVID-19
identification task in all metrics. Compared with the best baseline, FLANNEL
shows a higher macro-F1 score with 6% relative increase on Covid-19
identification task where it achieves 0.7833(0.07) in Precision, 0.8609(0.03)
in Recall, and 0.8168(0.03) F1 score.
</p>
<a href="http://arxiv.org/abs/2010.16039" target="_blank">arXiv:2010.16039</a> [<a href="http://arxiv.org/pdf/2010.16039" target="_blank">pdf</a>]

<h2>Deep Hurdle Networks for Zero-Inflated Multi-Target Regression: Application to Multiple Species Abundance Estimation. (arXiv:2010.16040v1 [cs.LG])</h2>
<h3>Shufeng Kong, Junwen Bai, Jae Hee Lee, Di Chen, Andrew Allyn, Michelle Stuart, Malin Pinsky, Katherine Mills, Carla P. Gomes</h3>
<p>A key problem in computational sustainability is to understand the
distribution of species across landscapes over time. This question gives rise
to challenging large-scale prediction problems since (i) hundreds of species
have to be simultaneously modeled and (ii) the survey data are usually inflated
with zeros due to the absence of species for a large number of sites. The
problem of tackling both issues simultaneously, which we refer to as the
zero-inflated multi-target regression problem, has not been addressed by
previous methods in statistics and machine learning. In this paper, we propose
a novel deep model for the zero-inflated multi-target regression problem. To
this end, we first model the joint distribution of multiple response variables
as a multivariate probit model and then couple the positive outcomes with a
multivariate log-normal distribution. By penalizing the difference between the
two distributions' covariance matrices, a link between both distributions is
established. The whole model is cast as an end-to-end learning framework and we
provide an efficient learning algorithm for our model that can be fully
implemented on GPUs. We show that our model outperforms the existing
state-of-the-art baselines on two challenging real-world species distribution
datasets concerning bird and fish populations.
</p>
<a href="http://arxiv.org/abs/2010.16040" target="_blank">arXiv:2010.16040</a> [<a href="http://arxiv.org/pdf/2010.16040" target="_blank">pdf</a>]

<h2>COVID-FACT: A Fully-Automated Capsule Network-based Framework for Identification of COVID-19 Cases from Chest CT scans. (arXiv:2010.16041v1 [eess.IV])</h2>
<h3>Shahin Heidarian, Parnian Afshar, Nastaran Enshaei, Farnoosh Naderkhani, Anastasia Oikonomou, S. Farokh Atashzar, Faranak Babaki Fard, Kaveh Samimi, Konstantinos N. Plataniotis, Arash Mohammadi, Moezedin Javad Rafiee</h3>
<p>The newly discovered Corona virus Disease 2019 (COVID-19) has been globally
spreading and causing hundreds of thousands of deaths around the world as of
its first emergence in late 2019. Computed tomography (CT) scans have shown
distinctive features and higher sensitivity compared to other diagnostic tests,
in particular the current gold standard, i.e., the Reverse Transcription
Polymerase Chain Reaction (RT-PCR) test. Current deep learning-based algorithms
are mainly developed based on Convolutional Neural Networks (CNNs) to identify
COVID-19 pneumonia cases. CNNs, however, require extensive data augmentation
and large datasets to identify detailed spatial relations between image
instances. Furthermore, existing algorithms utilizing CT scans, either extend
slice-level predictions to patient-level ones using a simple thresholding
mechanism or rely on a sophisticated infection segmentation to identify the
disease. In this paper, we propose a two-stage fully-automated CT-based
framework for identification of COVID-19 positive cases referred to as the
"COVID-FACT". COVID-FACT utilizes Capsule Networks, as its main building blocks
and is, therefore, capable of capturing spatial information. In particular, to
make the proposed COVID-FACT independent from sophisticated segmentation of the
area of infection, slices demonstrating infection are detected at the first
stage and the second stage is responsible for classifying patients into COVID
and non-COVID cases. COVID-FACT detects slices with infection, and identifies
positive COVID-19 cases using an in-house CT scan dataset, containing COVID-19,
community acquired pneumonia, and normal cases. Based on our experiments,
COVID-FACT achieves an accuracy of 90.82%, a sensitivity of 94.55%, a
specificity of 86.04%, and an Area Under the Curve (AUC) of 0.98, while
depending on far less supervision and annotation, in comparison to its
counterparts.
</p>
<a href="http://arxiv.org/abs/2010.16041" target="_blank">arXiv:2010.16041</a> [<a href="http://arxiv.org/pdf/2010.16041" target="_blank">pdf</a>]

<h2>CT-CAPS: Feature Extraction-based Automated Framework for COVID-19 Disease Identification from Chest CT Scans using Capsule Networks. (arXiv:2010.16043v1 [eess.IV])</h2>
<h3>Shahin Heidarian, Parnian Afshar, Arash Mohammadi, Moezedin Javad Rafiee, Anastasia Oikonomou, Konstantinos N. Plataniotis, Farnoosh Naderkhani</h3>
<p>The global outbreak of the novel corona virus (COVID-19) disease has
drastically impacted the world and led to one of the most challenging crisis
across the globe since World War II. The early diagnosis and isolation of
COVID-19 positive cases are considered as crucial steps towards preventing the
spread of the disease and flattening the epidemic curve. Chest Computed
Tomography (CT) scan is a highly sensitive, rapid, and accurate diagnostic
technique that can complement Reverse Transcription Polymerase Chain Reaction
(RT-PCR) test. Recently, deep learning-based models, mostly based on
Convolutional Neural Networks (CNN), have shown promising diagnostic results.
CNNs, however, are incapable of capturing spatial relations between image
instances and require large datasets. Capsule Networks, on the other hand, can
capture spatial relations, require smaller datasets, and have considerably
fewer parameters. In this paper, a Capsule network framework, referred to as
the "CT-CAPS", is presented to automatically extract distinctive features of
chest CT scans. These features, which are extracted from the layer before the
final capsule layer, are then leveraged to differentiate COVID-19 from
Non-COVID cases. The experiments on our in-house dataset of 307 patients show
the state-of-the-art performance with the accuracy of 90.8%, sensitivity of
94.5%, and specificity of 86.0%.
</p>
<a href="http://arxiv.org/abs/2010.16043" target="_blank">arXiv:2010.16043</a> [<a href="http://arxiv.org/pdf/2010.16043" target="_blank">pdf</a>]

<h2>Machine Learning (In) Security: A Stream of Problems. (arXiv:2010.16045v1 [cs.CR])</h2>
<h3>Fabr&#xed;cio Ceschin, Heitor Murilo Gomes, Marcus Botacin, Albert Bifet, Bernhard Pfahringer, Luiz S. Oliveira, Andr&#xe9; Gr&#xe9;gio</h3>
<p>Machine Learning (ML) has been widely applied to cybersecurity, and is
currently considered state-of-the-art for solving many of the field's open
issues. However, it is very difficult to evaluate how good the produced
solutions are, since the challenges faced in security may not appear in other
areas (at least not in the same way). One of these challenges is the concept
drift, that actually creates an arms race between attackers and defenders,
given that any attacker may create novel, different threats as time goes by (to
overcome defense solutions) and this "evolution" is not always considered in
many works. Due to this type of issue, it is fundamental to know how to
correctly build and evaluate a ML-based security solution. In this work, we
list, detail, and discuss some of the challenges of applying ML to
cybersecurity, including concept drift, concept evolution, delayed labels, and
adversarial machine learning. We also show how existing solutions fail and, in
some cases, we propose possible solutions to fix them.
</p>
<a href="http://arxiv.org/abs/2010.16045" target="_blank">arXiv:2010.16045</a> [<a href="http://arxiv.org/pdf/2010.16045" target="_blank">pdf</a>]

<h2>VECO: Variable Encoder-decoder Pre-training for Cross-lingual Understanding and Generation. (arXiv:2010.16046v1 [cs.CL])</h2>
<h3>Fuli Luo, Wei Wang, Jiahao Liu, Yijia Liu, Bin Bi, Songfang Huang, Fei Huang, Luo Si</h3>
<p>Recent studies about learning multilingual representations have achieved
significant performance gains across a wide range of downstream cross-lingual
tasks. They train either an encoder-only Transformer mainly for understanding
tasks, or an encoder-decoder Transformer specifically for generation tasks,
ignoring the correlation between the two tasks and frameworks. In contrast,
this paper presents a variable encoder-decoder (VECO) pre-training approach to
unify the two mainstreams in both model architectures and pre-training tasks.
VECO splits the standard Transformer block into several sub-modules trained
with both inner-sequence and cross-sequence masked language modeling, and
correspondingly reorganizes certain sub-modules for understanding and
generation tasks during inference. Such a workflow not only ensures to train
the most streamlined parameters necessary for two kinds of tasks, but also
enables them to boost each other via sharing common sub-modules. As a result,
VECO delivers new state-of-the-art results on various cross-lingual
understanding tasks of the XTREME benchmark covering text classification,
sequence labeling, question answering, and sentence retrieval. For generation
tasks, VECO also outperforms all existing cross-lingual models and
state-of-the-art Transformer variants on WMT14 English-to-German and
English-to-French translation datasets, with gains of up to 1$\sim$2 BLEU.
</p>
<a href="http://arxiv.org/abs/2010.16046" target="_blank">arXiv:2010.16046</a> [<a href="http://arxiv.org/pdf/2010.16046" target="_blank">pdf</a>]

<h2>NILM as a regression versus classification problem: the importance of thresholding. (arXiv:2010.16050v1 [eess.SP])</h2>
<h3>Daniel Precioso, David G&#xf3;mez-Ullate</h3>
<p>Non-Intrusive Load Monitoring (NILM) aims to predict the status or
consumption of domestic appliances in a household only by knowing the
aggregated power load. NILM can be formulated as regression problem or most
often as a classification problem. Most datasets gathered by smart meters allow
to define naturally a regression problem, but the corresponding classification
problem is a derived one, since it requires a conversion from the power signal
to the status of each device by a thresholding method. We treat three different
thresholding methods to perform this task, discussing their differences on
various devices from the UK-DALE dataset. We analyze the performance of deep
learning state-of-the-art architectures on both the regression and
classification problems, introducing criteria to select the most convenient
thresholding method.
</p>
<a href="http://arxiv.org/abs/2010.16050" target="_blank">arXiv:2010.16050</a> [<a href="http://arxiv.org/pdf/2010.16050" target="_blank">pdf</a>]

<h2>Unsupervised Embedding of Hierarchical Structure in Euclidean Space. (arXiv:2010.16055v1 [cs.LG])</h2>
<h3>Jinyu Zhao, Yi Hao, Cyrus Rashtchian</h3>
<p>Deep embedding methods have influenced many areas of unsupervised learning.
However, the best methods for learning hierarchical structure use non-Euclidean
representations, whereas Euclidean geometry underlies the theory behind many
hierarchical clustering algorithms. To bridge the gap between these two areas,
we consider learning a non-linear embedding of data into Euclidean space as a
way to improve the hierarchical clustering produced by agglomerative
algorithms. To learn the embedding, we revisit using a variational autoencoder
with a Gaussian mixture prior, and we show that rescaling the latent space
embedding and then applying Ward's linkage-based algorithm leads to improved
results for both dendrogram purity and the Moseley-Wang cost function. Finally,
we complement our empirical results with a theoretical explanation of the
success of this approach. We study a synthetic model of the embedded vectors
and prove that Ward's method exactly recovers the planted hierarchical
clustering with high probability.
</p>
<a href="http://arxiv.org/abs/2010.16055" target="_blank">arXiv:2010.16055</a> [<a href="http://arxiv.org/pdf/2010.16055" target="_blank">pdf</a>]

<h2>Bridging Text and Knowledge with Multi-Prototype Embedding for Few-Shot Relational Triple Extraction. (arXiv:2010.16059v1 [cs.CL])</h2>
<h3>Haiyang Yu, Ningyu Zhang, Shumin Deng, Hongbin Ye, Wei Zhang, Huajun Chen</h3>
<p>Current supervised relational triple extraction approaches require huge
amounts of labeled data and thus suffer from poor performance in few-shot
settings. However, people can grasp new knowledge by learning a few instances.
To this end, we take the first step to study the few-shot relational triple
extraction, which has not been well understood. Unlike previous single-task
few-shot problems, relational triple extraction is more challenging as the
entities and relations have implicit correlations. In this paper, We propose a
novel multi-prototype embedding network model to jointly extract the
composition of relational triples, namely, entity pairs and corresponding
relations. To be specific, we design a hybrid prototypical learning mechanism
that bridges text and knowledge concerning both entities and relations. Thus,
implicit correlations between entities and relations are injected.
Additionally, we propose a prototype-aware regularization to learn more
representative prototypes. Experimental results demonstrate that the proposed
method can improve the performance of the few-shot triple extraction.
</p>
<a href="http://arxiv.org/abs/2010.16059" target="_blank">arXiv:2010.16059</a> [<a href="http://arxiv.org/pdf/2010.16059" target="_blank">pdf</a>]

<h2>Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification. (arXiv:2010.16068v1 [cs.CL])</h2>
<h3>Juan Li, Ruoxu Wang, Ningyu Zhang, Wen Zhang, Fan Yang, Huajun Chen</h3>
<p>Relation classification aims to extract semantic relations between entity
pairs from the sentences. However, most existing methods can only identify seen
relation classes that occurred during training. To recognize unseen relations
at test time, we explore the problem of zero-shot relation classification.
Previous work regards the problem as reading comprehension or textual
entailment, which have to rely on artificial descriptive information to improve
the understandability of relation types. Thus, rich semantic knowledge of the
relation labels is ignored. In this paper, we propose a novel logic-guided
semantic representation learning model for zero-shot relation classification.
Our approach builds connections between seen and unseen relations via implicit
and explicit semantic representations with knowledge graph embeddings and logic
rules. Extensive experimental results demonstrate that our method can
generalize to unseen relation types and achieve promising improvements.
</p>
<a href="http://arxiv.org/abs/2010.16068" target="_blank">arXiv:2010.16068</a> [<a href="http://arxiv.org/pdf/2010.16068" target="_blank">pdf</a>]

<h2>Volumetric Medical Image Segmentation: A 3D Deep Coarse-to-fine Framework and Its Adversarial Examples. (arXiv:2010.16074v1 [cs.CV])</h2>
<h3>Yingwei Li, Zhuotun Zhu, Yuyin Zhou, Yingda Xia, Wei Shen, Elliot K. Fishman, Alan L. Yuille</h3>
<p>Although deep neural networks have been a dominant method for many 2D vision
tasks, it is still challenging to apply them to 3D tasks, such as medical image
segmentation, due to the limited amount of annotated 3D data and limited
computational resources. In this chapter, by rethinking the strategy to apply
3D Convolutional Neural Networks to segment medical images, we propose a novel
3D-based coarse-to-fine framework to efficiently tackle these challenges. The
proposed 3D-based framework outperforms their 2D counterparts by a large margin
since it can leverage the rich spatial information along all three axes. We
further analyze the threat of adversarial attacks on the proposed framework and
show how to defense against the attack. We conduct experiments on three
datasets, the NIH pancreas dataset, the JHMI pancreas dataset and the JHMI
pathological cyst dataset, where the first two and the last one contain healthy
and pathological pancreases respectively, and achieve the current
state-of-the-art in terms of Dice-Sorensen Coefficient (DSC) on all of them.
Especially, on the NIH pancreas segmentation dataset, we outperform the
previous best by an average of over $2\%$, and the worst case is improved by
$7\%$ to reach almost $70\%$, which indicates the reliability of our framework
in clinical applications.
</p>
<a href="http://arxiv.org/abs/2010.16074" target="_blank">arXiv:2010.16074</a> [<a href="http://arxiv.org/pdf/2010.16074" target="_blank">pdf</a>]

<h2>LIFI: Towards Linguistically Informed Frame Interpolation. (arXiv:2010.16078v1 [cs.CV])</h2>
<h3>Aradhya Neeraj Mathur, Devansh Batra, Yaman Kumar, Rajiv Ratn Shah, Roger Zimmermann, Amanda Stent</h3>
<p>In this work, we explore a new problem of frame interpolation for speech
videos. Such content today forms the major form of online communication. We try
to solve this problem by using several deep learning video generation
algorithms to generate the missing frames. We also provide examples where
computer vision models despite showing high performance on conventional
non-linguistic metrics fail to accurately produce faithful interpolation of
speech. With this motivation, we provide a new set of linguistically-informed
metrics specifically targeted to the problem of speech videos interpolation. We
also release several datasets to test computer vision video generation models
of their speech understanding.
</p>
<a href="http://arxiv.org/abs/2010.16078" target="_blank">arXiv:2010.16078</a> [<a href="http://arxiv.org/pdf/2010.16078" target="_blank">pdf</a>]

<h2>Correspondence Matrices are Underrated. (arXiv:2010.16085v1 [cs.CV])</h2>
<h3>Tejas Zodage, Rahul Chakwate, Vinit Sarode, Rangaprasad Arun Srivatsan, Howie Choset</h3>
<p>Point-cloud registration (PCR) is an important task in various applications
such as robotic manipulation, augmented and virtual reality, SLAM, etc. PCR is
an optimization problem involving minimization over two different types of
interdependent variables: transformation parameters and point-to-point
correspondences. Recent developments in deep-learning have produced
computationally fast approaches for PCR. The loss functions that are optimized
in these networks are based on the error in the transformation parameters. We
hypothesize that these methods would perform significantly better if they
calculated their loss function using correspondence error instead of only using
error in transformation parameters. We define correspondence error as a metric
based on incorrectly matched point pairs. We provide a fundamental explanation
for why this is the case and test our hypothesis by modifying existing methods
to use correspondence-based loss instead of transformation-based loss. These
experiments show that the modified networks converge faster and register more
accurately even at larger misalignment when compared to the original networks.
</p>
<a href="http://arxiv.org/abs/2010.16085" target="_blank">arXiv:2010.16085</a> [<a href="http://arxiv.org/pdf/2010.16085" target="_blank">pdf</a>]

<h2>Health improvement framework for planning actionable treatment process using surrogate Bayesian model. (arXiv:2010.16087v1 [cs.LG])</h2>
<h3>Kazuki Nakamura, Ryosuke Kojima, Eiichiro Uchino, Koichi Murashita, Ken Itoh, Shigeyuki Nakaji, Yasushi Okuno</h3>
<p>Clinical decision making about treatments and interventions based on personal
characteristics leads to effective health improvement. Machine learning (ML)
has been the central concern of the diagnosis support and disease prediction
based on comprehensive patient information. Because the black-box problem in ML
is serious for medical applications, explainable artificial intelligence (XAI)
techniques to explain the reasons for ML models predictions have been focused.
A remaining important issue in clinical situations is discovery of concrete and
realistic treatment processes. This paper proposes an innovative framework to
plan concrete treatment processes based on an ML model. A key point of our
proposed framework is to evaluate an "actionability" of the treatment process
using a stochastic surrogate model constructed through hierarchical Bayesian
modeling. The actionability is an essential concept for suggesting a realistic
treatment process, which leads to clinical applications for personal health
improvement. This paper also presents two experiments to evaluate our
framework. We first demonstrate the feasibility of our framework from the
viewpoint of the methodology using a synthetic dataset. Subsequently, our
framework is applied to an actual health checkup dataset, which comprises 3,132
participants, considering an application to improve systolic blood pressure
values at a personal level. We confirmed that the computed treatment processes
are actionable and consistent with clinical knowledge for lowering blood
pressure. These results demonstrate that our framework can contribute to
decision making in the medical field. Our framework can be expected to provide
clinicians deeper insights by proposing concrete and actionable treatment
process based on the ML model.
</p>
<a href="http://arxiv.org/abs/2010.16087" target="_blank">arXiv:2010.16087</a> [<a href="http://arxiv.org/pdf/2010.16087" target="_blank">pdf</a>]

<h2>Cross-Domain Sentiment Classification With Contrastive Learning and Mutual Information Maximization. (arXiv:2010.16088v1 [cs.CL])</h2>
<h3>Tian Li, Xiang Chen, Shanghang Zhang, Zhen Dong, Kurt Keutzer</h3>
<p>Contrastive learning (CL) has been successful as a powerful representation
learning method. In this work we propose CLIM: Contrastive Learning with mutual
Information Maximization, to explore the potential of CL on cross-domain
sentiment classification. To the best of our knowledge, CLIM is the first to
adopt contrastive learning for natural language processing (NLP) tasks across
domains. Due to scarcity of labels on the target domain, we introduce mutual
information maximization (MIM) apart from CL to exploit the features that best
support the final prediction. Furthermore, MIM is able to maintain a relatively
balanced distribution of the model's prediction, and enlarges the margin
between classes on the target domain. The larger margin increases our model's
robustness and enables the same classifier to be optimal across domains.
Consequently, we achieve new state-of-the-art results on the Amazon-review
dataset as well as the airlines dataset, showing the efficacy of our proposed
method CLIM.
</p>
<a href="http://arxiv.org/abs/2010.16088" target="_blank">arXiv:2010.16088</a> [<a href="http://arxiv.org/pdf/2010.16088" target="_blank">pdf</a>]

<h2>Deep Active Graph Representation Learning. (arXiv:2010.16091v1 [cs.LG])</h2>
<h3>Yanqiao Zhu, Weizhi Xu, Feng Yu, Qiang Liu, Shu Wu, Liang Wang</h3>
<p>Graph neural networks (GNNs) aim to learn graph representations that preserve
both attributive and structural information. In this paper, we study the
problem of how to select high-quality nodes for training GNNs, considering GNNs
are sensitive to different training datasets. Active learning (AL), whose
purpose is to find the most informative instances to maximize the performance
of the model, is a promising approach to solve this problem. Previous attempts
have combined AL with graph representation learning by designing several
selection criteria to measure how informative a node is. However, these methods
do not directly utilize both the rich semantic and structural information and
are prone to select sparsely-connected nodes (i.e. nodes having few neighbors)
and low-purity nodes (i.e. nodes having noisy inter-class edges), which are
less effective for training GNN models. To address these problems, we present a
Deep Active Graph Representation Learning framework (DAGRL), in which three
novel selection criteria are proposed. Specifically, we propose to measure the
uncertainty of nodes via random topological perturbation. Besides, we propose
two novel representativeness sampling criteria, which utilize both the
structural and label information to find densely-connected nodes with many
intra-class edges, hence enhance the performance of GNN models significantly.
Then, we combine these three criteria with time-sensitive scheduling in
accordance to the training progress of GNNs. Furthermore, considering the
different size of classes, we employ a novel cluster-aware node selection
policy, which ensures the number of selected nodes in each class is
proportional to the size of the class. Comprehensive experiments on three
public datasets show that our method outperforms previous baselines by a
significant margin, which demonstrates its effectiveness.
</p>
<a href="http://arxiv.org/abs/2010.16091" target="_blank">arXiv:2010.16091</a> [<a href="http://arxiv.org/pdf/2010.16091" target="_blank">pdf</a>]

<h2>Revisiting Graph Neural Networks for Link Prediction. (arXiv:2010.16103v1 [cs.LG])</h2>
<h3>Muhan Zhang, Pan Li, Yinglong Xia, Kai Wang, Long Jin</h3>
<p>Graph neural networks (GNNs) have achieved great success in recent years.
Three most common applications include node classification, link prediction,
and graph classification. While there is rich literature on node classification
and graph classification, GNNs for link prediction is relatively less studied
and less understood. Two representative classes of methods exist: GAE and SEAL.
GAE (Graph Autoencoder) first uses a GNN to learn node embeddings for all
nodes, and then aggregates the embeddings of the source and target nodes as
their link representation. SEAL extracts a subgraph around the source and
target nodes, labels the nodes in the subgraph, and then uses a GNN to learn a
link representation from the labeled subgraph. In this paper, we thoroughly
discuss the differences between these two classes of methods, and conclude that
simply aggregating node embeddings does not lead to effective link
representations, while learning from properly labeled subgraphs around links
provides highly expressive and generalizable link representations. Experiments
on the recent large-scale OGB link prediction datasets show that SEAL has up to
195% performance gains over GAE methods, achieving new state-of-the-art results
on 3 out of 4 datasets.
</p>
<a href="http://arxiv.org/abs/2010.16103" target="_blank">arXiv:2010.16103</a> [<a href="http://arxiv.org/pdf/2010.16103" target="_blank">pdf</a>]

<h2>Classifying Malware Images with Convolutional Neural Network Models. (arXiv:2010.16108v1 [cs.CR])</h2>
<h3>Ahmed Bensaoud, Nawaf Abudawaood, Jugal Kalita</h3>
<p>Due to increasing threats from malicious software (malware) in both number
and complexity, researchers have developed approaches to automatic detection
and classification of malware, instead of analyzing methods for malware files
manually in a time-consuming effort. At the same time, malware authors have
developed techniques to evade signature-based detection techniques used by
antivirus companies. Most recently, deep learning is being used in malware
classification to solve this issue. In this paper, we use several convolutional
neural network (CNN) models for static malware classification. In particular,
we use six deep learning models, three of which are past winners of the
ImageNet Large-Scale Visual Recognition Challenge. The other three models are
CNN-SVM, GRU-SVM and MLP-SVM, which enhance neural models with support vector
machines (SVM). We perform experiments using the Malimg dataset, which has
malware images that were converted from Portable Executable malware binaries.
The dataset is divided into 25 malware families. Comparisons show that the
Inception V3 model achieves a test accuracy of 99.24%, which is better than the
accuracy of 98.52% achieved by the current state-of-the-art system called the
M-CNN model.
</p>
<a href="http://arxiv.org/abs/2010.16108" target="_blank">arXiv:2010.16108</a> [<a href="http://arxiv.org/pdf/2010.16108" target="_blank">pdf</a>]

<h2>PyraPose: Feature Pyramids for Fast and Accurate Object Pose Estimation under Domain Shift. (arXiv:2010.16117v1 [cs.CV])</h2>
<h3>Stefan Thalhammer, Markus Leitner, Timothy Patten, Markus Vincze</h3>
<p>Object pose estimation enables robots to understand and interact with their
environments. Training with synthetic data is necessary in order to adapt to
novel situations. Unfortunately, pose estimation under domain shift, i.e.,
training on synthetic data and testing in the real world, is challenging. Deep
learning-based approaches currently perform best when using encoder-decoder
networks but typically do not generalize to new scenarios with different scene
characteristics. We argue that patch-based approaches, instead of
encoder-decoder networks, are more suited for synthetic-to-real transfer
because local to global object information is better represented. To that end,
we present a novel approach based on a specialized feature pyramid network to
compute multi-scale features for creating pose hypotheses on different feature
map resolutions in parallel. Our single-shot pose estimation approach is
evaluated on multiple standard datasets and outperforms the state of the art by
up to 35%. We also perform grasping experiments in the real world to
demonstrate the advantage of using synthetic data to generalize to novel
environments.
</p>
<a href="http://arxiv.org/abs/2010.16117" target="_blank">arXiv:2010.16117</a> [<a href="http://arxiv.org/pdf/2010.16117" target="_blank">pdf</a>]

<h2>Multiview Variational Graph Autoencoders for Canonical Correlation Analysis. (arXiv:2010.16132v1 [cs.LG])</h2>
<h3>Yacouba Kaloga, Pierre Borgnat, Sundeep Prabhakar Chepuri, Patrice Abry, Amaury Habrard</h3>
<p>We present a novel multiview canonical correlation analysis model based on a
variational approach. This is the first nonlinear model that takes into account
the available graph-based geometric constraints while being scalable for
processing large scale datasets with multiple views. It is based on an
autoencoder architecture with graph convolutional neural network layers. We
experiment with our approach on classification, clustering, and recommendation
tasks on real datasets. The algorithm is competitive with state-of-the-art
multiview representation learning techniques.
</p>
<a href="http://arxiv.org/abs/2010.16132" target="_blank">arXiv:2010.16132</a> [<a href="http://arxiv.org/pdf/2010.16132" target="_blank">pdf</a>]

<h2>Deep generative LDA. (arXiv:2010.16138v1 [cs.LG])</h2>
<h3>Yunqi Cai, Dong Wang</h3>
<p>Linear discriminant analysis (LDA) is a popular tool for classification and
dimension reduction. Limited by its linear form and the underlying Gaussian
assumption, however, LDA is not applicable in situations where the data
distribution is complex. Recently, we proposed a discriminative normalization
flow (DNF) model. In this study, we reinterpret DNF as a deep generative LDA
model, and study its properties in representing complex data. We conducted a
simulation experiment and a speaker recognition experiment. The results show
that DNF and its subspace version are much more powerful than the conventional
LDA in modeling complex data and retrieving low-dimensional representations.
</p>
<a href="http://arxiv.org/abs/2010.16138" target="_blank">arXiv:2010.16138</a> [<a href="http://arxiv.org/pdf/2010.16138" target="_blank">pdf</a>]

<h2>Bayesian Optimization Meets Laplace Approximation for Robotic Introspection. (arXiv:2010.16141v1 [cs.RO])</h2>
<h3>Matthias Humt, Jongseok Lee, Rudolph Triebel</h3>
<p>In robotics, deep learning (DL) methods are used more and more widely, but
their general inability to provide reliable confidence estimates will
ultimately lead to fragile and unreliable systems. This impedes the potential
deployments of DL methods for long-term autonomy. Therefore, in this paper we
introduce a scalable Laplace Approximation (LA) technique to make Deep Neural
Networks (DNNs) more introspective, i.e. to enable them to provide accurate
assessments of their failure probability for unseen test data. In particular,
we propose a novel Bayesian Optimization (BO) algorithm to mitigate their
tendency of under-fitting the true weight posterior, so that both the
calibration and the accuracy of the predictions can be simultaneously
optimized. We demonstrate empirically that the proposed BO approach requires
fewer iterations for this when compared to random search, and we show that the
proposed framework can be scaled up to large datasets and architectures.
</p>
<a href="http://arxiv.org/abs/2010.16141" target="_blank">arXiv:2010.16141</a> [<a href="http://arxiv.org/pdf/2010.16141" target="_blank">pdf</a>]

<h2>Deep Speaker Vector Normalization with Maximum Gaussianality Training. (arXiv:2010.16148v1 [cs.SD])</h2>
<h3>Yunqi Cai, Lantian Li, Dong Wang, Andrew Abel</h3>
<p>Deep speaker embedding represents the state-of-the-art technique for speaker
recognition. A key problem with this approach is that the resulting deep
speaker vectors tend to be irregularly distributed. In previous research, we
proposed a deep normalization approach based on a new discriminative
normalization flow (DNF) model, by which the distributions of individual
speakers are arguably transformed to homogeneous Gaussians. This normalization
was demonstrated to be effective, but despite this remarkable success, we
empirically found that the latent codes produced by the DNF model are generally
neither homogeneous nor Gaussian, although the model has assumed so. In this
paper, we argue that this problem is largely attributed to the
maximum-likelihood (ML) training criterion of the DNF model, which aims to
maximize the likelihood of the observations but not necessarily improve the
Gaussianality of the latent codes. We therefore propose a new Maximum
Gaussianality (MG) training approach that directly maximizes the Gaussianality
of the latent codes. Our experiments on two data sets, SITW and CNCeleb,
demonstrate that our new MG training approach can deliver much better
performance than the previous ML training, and exhibits improved domain
generalizability, particularly with regard to cosine scoring.
</p>
<a href="http://arxiv.org/abs/2010.16148" target="_blank">arXiv:2010.16148</a> [<a href="http://arxiv.org/pdf/2010.16148" target="_blank">pdf</a>]

<h2>Unsatisfied Today, Satisfied Tomorrow: a simulation framework for performance evaluation of crowdsourcing-based network monitoring. (arXiv:2010.16162v1 [cs.NI])</h2>
<h3>Andrea Pimpinella, Marianna Repossi, Alessandro Enrico Cesare Redondi</h3>
<p>Network operators need to continuosly upgrade their infrastructures in order
to keep their customer satisfaction levels high. Crowdsourcing-based approaches
are generally adopted, where customers are directly asked to answer surveys
about their user experience. Since the number of collaborative users is
generally low, network operators rely on Machine Learning models to predict the
satisfaction levels/QoE of the users rather than directly measuring it through
surveys. Finally, combining the true/predicted user satisfaction levels with
information on each user mobility (e.g, which network sites each user has
visited and for how long), an operator may reveal critical areas in the
networks and drive/prioritize investments properly. In this work, we propose an
empirical framework tailored to assess the quality of the detection of
under-performing cells starting from subjective user experience grades. The
framework allows to simulate diverse networking scenarios, where a network
characterized by a small set of under-performing cells is visited by
heterogeneous users moving through it according to realistic mobility models.
The framework simulates both the processes of satisfaction surveys delivery and
users satisfaction prediction, considering different delivery strategies and
evaluating prediction algorithms characterized by different prediction
performance. We use the simulation framework to test empirically the
performance of under-performing sites detection in general scenarios
characterized by different users density and mobility models to obtain insights
which are generalizable and that provide interesting guidelines for network
operators.
</p>
<a href="http://arxiv.org/abs/2010.16162" target="_blank">arXiv:2010.16162</a> [<a href="http://arxiv.org/pdf/2010.16162" target="_blank">pdf</a>]

<h2>Fusion-Catalyzed Pruning for Optimizing Deep Learning on Intelligent Edge Devices. (arXiv:2010.16165v1 [cs.NE])</h2>
<h3>Guangli Li, Xiu Ma, Xueying Wang, Lei Liu, Jingling Xue, Xiaobing Feng</h3>
<p>The increasing computational cost of deep neural network models limits the
applicability of intelligent applications on resource-constrained edge devices.
While a number of neural network pruning methods have been proposed to compress
the models, prevailing approaches focus only on parametric operators (e.g.,
convolution), which may miss optimization opportunities. In this paper, we
present a novel fusion-catalyzed pruning approach, called FuPruner, which
simultaneously optimizes the parametric and non-parametric operators for
accelerating neural networks. We introduce an aggressive fusion method to
equivalently transform a model, which extends the optimization space of pruning
and enables non-parametric operators to be pruned in a similar manner as
parametric operators, and a dynamic filter pruning method is applied to
decrease the computational cost of models while retaining the accuracy
requirement. Moreover, FuPruner provides configurable optimization options for
controlling fusion and pruning, allowing much more flexible
performance-accuracy trade-offs to be made. Evaluation with state-of-the-art
residual neural networks on five representative intelligent edge platforms,
Jetson TX2, Jetson Nano, Edge TPU, NCS, and NCS2, demonstrates the
effectiveness of our approach, which can accelerate the inference of models on
CIFAR-10 and ImageNet datasets.
</p>
<a href="http://arxiv.org/abs/2010.16165" target="_blank">arXiv:2010.16165</a> [<a href="http://arxiv.org/pdf/2010.16165" target="_blank">pdf</a>]

<h2>RVCoreP-32IM: An effective architecture to implement mul/div instructions for five stage RISC-V soft processors. (arXiv:2010.16171v1 [cs.AR])</h2>
<h3>Md Ashraful Islam, Hiromu Miyazaki, Kenji Kise</h3>
<p>RISC-V, an open instruction set architecture, is getting the attention of
soft processor developers. Implementing only a basic 32-bit integer instruction
set of RISC-V, which is defined as RV32I, might be satisfactory for embedded
systems. However, multiplication and division instructions are not present in
RV32I, rather than defined as M-extension. Several research projects have
proposed both RV32I and RV32IM processor. However, there is no indication of
how much performance can be improved by adding M-extension to RV32I. In other
words, when we should consider adding M-extension into the soft processor and
how much hardware resource requirements will increase.

In this paper, we propose an extension of the RVCoreP soft processor (which
implements RV32I instruction set only) to support RISC-V M-extension
instructions. A simple fork-join method is used to expand the execution
capability to support M-extension instructions as well as a possible future
enhancement. We then perform the benchmark using Dhrystone, Coremark, and
Embench programs. We found that RV32IM is 1.87 and 3.13 times better in
performance for radix-4 and DSP multiplier, respectively. In addition to that,
our RV32IM implementation is 13\% better than the equivalent RISC-V processor.
</p>
<a href="http://arxiv.org/abs/2010.16171" target="_blank">arXiv:2010.16171</a> [<a href="http://arxiv.org/pdf/2010.16171" target="_blank">pdf</a>]

<h2>Information-theoretic Feature Selection via Tensor Decomposition and Submodularity. (arXiv:2010.16181v1 [cs.LG])</h2>
<h3>Magda Amiridi, Nikos Kargas, Nicholas D. Sidiropoulos</h3>
<p>Feature selection by maximizing high-order mutual information between the
selected feature vector and a target variable is the gold standard in terms of
selecting the best subset of relevant features that maximizes the performance
of prediction models. However, such an approach typically requires knowledge of
the multivariate probability distribution of all features and the target, and
involves a challenging combinatorial optimization problem. Recent work has
shown that any joint Probability Mass Function (PMF) can be represented as a
naive Bayes model, via Canonical Polyadic (tensor rank) Decomposition. In this
paper, we introduce a low-rank tensor model of the joint PMF of all variables
and indirect targeting as a way of mitigating complexity and maximizing the
classification performance for a given number of features. Through low-rank
modeling of the joint PMF, it is possible to circumvent the curse of
dimensionality by learning principal components of the joint distribution. By
indirectly aiming to predict the latent variable of the naive Bayes model
instead of the original target variable, it is possible to formulate the
feature selection problem as maximization of a monotone submodular function
subject to a cardinality constraint - which can be tackled using a greedy
algorithm that comes with performance guarantees. Numerical experiments with
several standard datasets suggest that the proposed approach compares favorably
to the state-of-art for this important problem.
</p>
<a href="http://arxiv.org/abs/2010.16181" target="_blank">arXiv:2010.16181</a> [<a href="http://arxiv.org/pdf/2010.16181" target="_blank">pdf</a>]

<h2>Automatic Myocardial Infarction Evaluation from Delayed-Enhancement Cardiac MRI using Deep Convolutional Networks. (arXiv:2010.16198v1 [eess.IV])</h2>
<h3>Kibrom Berihu Girum, Youssef Skandarani, Raabid Hussain, Alexis Bozorg Grayeli, Gilles Cr&#xe9;hange, Alain Lalande</h3>
<p>In this paper, we propose a new deep learning framework for an automatic
myocardial infarction evaluation from clinical information and delayed
enhancement-MRI (DE-MRI). The proposed framework addresses two tasks. The first
task is automatic detection of myocardial contours, the infarcted area, the
no-reflow area, and the left ventricular cavity from a short-axis DE-MRI
series. It employs two segmentation neural networks. The first network is used
to segment the anatomical structures such as the myocardium and left
ventricular cavity. The second network is used to segment the pathological
areas such as myocardial infarction, myocardial no-reflow, and normal
myocardial region. The segmented myocardium region from the first network is
further used to refine the second network's pathological segmentation results.
The second task is to automatically classify a given case into normal or
pathological from clinical information with or without DE-MRI. A cascaded
support vector machine (SVM) is employed to classify a given case from its
associated clinical information. The segmented pathological areas from DE-MRI
are also used for the classification task. We evaluated our method on the 2020
EMIDEC MICCAI challenge dataset. It yielded an average Dice index of 0.93 and
0.84, respectively, for the left ventricular cavity and the myocardium. The
classification from using only clinical information yielded 80% accuracy over
five-fold cross-validation. Using the DE-MRI, our method can classify the cases
with 93.3% accuracy. These experimental results reveal that the proposed method
can automatically evaluate the myocardial infarction.
</p>
<a href="http://arxiv.org/abs/2010.16198" target="_blank">arXiv:2010.16198</a> [<a href="http://arxiv.org/pdf/2010.16198" target="_blank">pdf</a>]

<h2>AudVowelConsNet: A Phoneme-Level Based Deep CNN Architecture for Clinical Depression Diagnosis. (arXiv:2010.16201v1 [cs.SD])</h2>
<h3>Muhammad Muzammel, Hanan Salam, Yann Hoffmann, Mohamed Chetouani, Alice Othmani</h3>
<p>Depression is a common and serious mood disorder that negatively affects the
patient's capacity of functioning normally in daily tasks. Speech is proven to
be a vigorous tool in depression diagnosis. Research in psychiatry concentrated
on performing fine-grained analysis on word-level speech components
contributing to the manifestation of depression in speech and revealed
significant variations at the phoneme-level in depressed speech. On the other
hand, research in Machine Learning-based automatic recognition of depression
from speech focused on the exploration of various acoustic features for the
detection of depression and its severity level. Few have focused on
incorporating phoneme-level speech components in automatic assessment systems.
In this paper, we propose an Artificial Intelligence (AI) based application for
clinical depression recognition and assessment from speech. We investigate the
acoustic characteristics of phoneme units, specifically vowels and consonants
for depression recognition via Deep Learning. We present and compare three
spectrogram-based Deep Neural Network architectures, trained on phoneme
consonant and vowel units and their fusion respectively. Our experiments show
that the deep learned consonant-based acoustic characteristics lead to better
recognition results than vowel-based ones. The fusion of vowel and consonant
speech characteristics through a deep network significantly outperforms the
single space networks as well as the state-of-art deep learning approaches on
the DAIC-WOZ database.
</p>
<a href="http://arxiv.org/abs/2010.16201" target="_blank">arXiv:2010.16201</a> [<a href="http://arxiv.org/pdf/2010.16201" target="_blank">pdf</a>]

<h2>Capture the Bot: Using Adversarial Examples to Improve CAPTCHA Robustness to Bot Attacks. (arXiv:2010.16204v1 [cs.CR])</h2>
<h3>Dorjan Hitaj, Briland Hitaj, Sushil Jajodia, Luigi V. Mancini</h3>
<p>To this date, CAPTCHAs have served as the first line of defense preventing
unauthorized access by (malicious) bots to web-based services, while at the
same time maintaining a trouble-free experience for human visitors. However,
recent work in the literature has provided evidence of sophisticated bots that
make use of advancements in machine learning (ML) to easily bypass existing
CAPTCHA-based defenses. In this work, we take the first step to address this
problem. We introduce CAPTURE, a novel CAPTCHA scheme based on adversarial
examples. While typically adversarial examples are used to lead an ML model
astray, to the best of our knowledge, CAPTURE is the first work to make a "good
use" of such mechanisms. Our empirical evaluations show that CAPTURE can
produce CAPTCHAs that are easy to solve by humans while at the same time,
effectively thwarting ML-based bot solvers.
</p>
<a href="http://arxiv.org/abs/2010.16204" target="_blank">arXiv:2010.16204</a> [<a href="http://arxiv.org/pdf/2010.16204" target="_blank">pdf</a>]

<h2>Joint Transceiver Design Based on Dictionary Learning Algorithm for SCMA. (arXiv:2010.16213v1 [eess.SP])</h2>
<h3>Shanshan Zhang, Wen Chen, Shaoyuan Chen</h3>
<p>With the explosively increasing demands on the network capacity, throughput
and number of connected wireless devices, massive connectivity is an urgent
problem for the next generation wireless communications. In this paper, we
propose a grant-free access protocol for massive connectivity that utilizes a
large number of antennas in a base station (BS) and is expected to be widely
deployed in cellular networks. The scheme consists of a sparse structure in
sparse code multiple access (SCMA) and receiver processing based on dictionary
learning (DL). A large number of devices can transmit data without any
scheduling process. Unlike existing schemes, whose signal schedulings require a
lot of overhead, the scheduling overhead required by the proposed scheme is
negligible, which is attractive for resource utilization and transmission power
efficiency. The numerical results show that the proposed scheme has promising
performance in massive connectivity scenario of cellular networks.
</p>
<a href="http://arxiv.org/abs/2010.16213" target="_blank">arXiv:2010.16213</a> [<a href="http://arxiv.org/pdf/2010.16213" target="_blank">pdf</a>]

<h2>HOI Analysis: Integrating and Decomposing Human-Object Interaction. (arXiv:2010.16219v1 [cs.CV])</h2>
<h3>Yong-Lu Li, Xinpeng Liu, Xiaoqian Wu, Yizhuo Li, Cewu Lu</h3>
<p>Human-Object Interaction (HOI) consists of human, object and implicit
interaction/verb. Different from previous methods that directly map pixels to
HOI semantics, we propose a novel perspective for HOI learning in an analytical
manner. In analogy to Harmonic Analysis, whose goal is to study how to
represent the signals with the superposition of basic waves, we propose the HOI
Analysis. We argue that coherent HOI can be decomposed into isolated human and
object. Meanwhile, isolated human and object can also be integrated into
coherent HOI again. Moreover, transformations between human-object pairs with
the same HOI can also be easier approached with integration and decomposition.
As a result, the implicit verb will be represented in the transformation
function space. In light of this, we propose an Integration-Decomposition
Network (IDN) to implement the above transformations and achieve
state-of-the-art performance on widely-used HOI detection benchmarks. Code is
available at
https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/IDN-(Integrating-Decomposing-Network).
</p>
<a href="http://arxiv.org/abs/2010.16219" target="_blank">arXiv:2010.16219</a> [<a href="http://arxiv.org/pdf/2010.16219" target="_blank">pdf</a>]

<h2>Interleaving Fast and Slow Decision Making. (arXiv:2010.16244v1 [cs.AI])</h2>
<h3>Aditya Gulati, Sarthak Soni, Shrisha Rao</h3>
<p>The "Thinking, Fast and Slow" paradigm of Kahneman proposes that we use two
different styles of thinking -- a fast and intuitive System 1 for certain
tasks, along with a slower but more analytical System 2 for others. While the
idea of using this two-system style of thinking is gaining popularity in AI and
robotics, our work considers how to interleave the two styles of
decision-making, i.e., how System 1 and System 2 should be used together. For
this, we propose a novel and general framework which includes a new System 0 to
oversee Systems 1 and 2. At every point when a decision needs to be made,
System 0 evaluates the situation and quickly hands over the decision-making
process to either System 1 or System 2. We evaluate such a framework on a
modified version of the classic Pac-Man game, with an already-trained RL
algorithm for System 1, a Monte-Carlo tree search for System 2, and several
different possible strategies for System 0. As expected, arbitrary switches
between Systems 1 and 2 do not work, but certain strategies do well. With
System 0, an agent is able to perform better than one that uses only System 1
or System 2.
</p>
<a href="http://arxiv.org/abs/2010.16244" target="_blank">arXiv:2010.16244</a> [<a href="http://arxiv.org/pdf/2010.16244" target="_blank">pdf</a>]

<h2>On the Impact of Communities on Semi-supervised Classification Using Graph Neural Networks. (arXiv:2010.16245v1 [cs.LG])</h2>
<h3>Hussain Hussain, Tomislav Duricic, Elisabeth Lex, Roman Kern, Denis Helic</h3>
<p>Graph Neural Networks (GNNs) are effective in many applications. Still, there
is a limited understanding of the effect of common graph structures on the
learning process of GNNs. In this work, we systematically study the impact of
community structure on the performance of GNNs in semi-supervised node
classification on graphs. Following an ablation study on six datasets, we
measure the performance of GNNs on the original graphs, and the change in
performance in the presence and the absence of community structure. Our results
suggest that communities typically have a major impact on the learning process
and classification performance. For example, in cases where the majority of
nodes from one community share a single classification label, breaking up
community structure results in a significant performance drop. On the other
hand, for cases where labels show low correlation with communities, we find
that the graph structure is rather irrelevant to the learning process, and a
feature-only baseline becomes hard to beat. With our work, we provide deeper
insights in the abilities and limitations of GNNs, including a set of general
guidelines for model selection based on the graph structure.
</p>
<a href="http://arxiv.org/abs/2010.16245" target="_blank">arXiv:2010.16245</a> [<a href="http://arxiv.org/pdf/2010.16245" target="_blank">pdf</a>]

<h2>Accordion: Adaptive Gradient Communication via Critical Learning Regime Identification. (arXiv:2010.16248v1 [cs.LG])</h2>
<h3>Saurabh Agarwal, Hongyi Wang, Kangwook Lee, Shivaram Venkataraman, Dimitris Papailiopoulos</h3>
<p>Distributed model training suffers from communication bottlenecks due to
frequent model updates transmitted across compute nodes. To alleviate these
bottlenecks, practitioners use gradient compression techniques like
sparsification, quantization, or low-rank updates. The techniques usually
require choosing a static compression ratio, often requiring users to balance
the trade-off between model accuracy and per-iteration speedup. In this work,
we show that such performance degradation due to choosing a high compression
ratio is not fundamental. An adaptive compression strategy can reduce
communication while maintaining final test accuracy. Inspired by recent
findings on critical learning regimes, in which small gradient errors can have
irrecoverable impact on model performance, we propose Accordion a simple yet
effective adaptive compression algorithm. While Accordion maintains a high
enough compression rate on average, it avoids over-compressing gradients
whenever in critical learning regimes, detected by a simple gradient-norm based
criterion. Our extensive experimental study over a number of machine learning
tasks in distributed environments indicates that Accordion, maintains similar
model accuracy to uncompressed training, yet achieves up to 5.5x better
compression and up to 4.1x end-to-end speedup over static approaches. We show
that Accordion also works for adjusting the batch size, another popular
strategy for alleviating communication bottlenecks.
</p>
<a href="http://arxiv.org/abs/2010.16248" target="_blank">arXiv:2010.16248</a> [<a href="http://arxiv.org/pdf/2010.16248" target="_blank">pdf</a>]

<h2>SLM: Learning a Discourse Language Representation with Sentence Unshuffling. (arXiv:2010.16249v1 [cs.CL])</h2>
<h3>Haejun Lee, Drew A. Hudson, Kangwook Lee, Christopher D. Manning</h3>
<p>We introduce Sentence-level Language Modeling, a new pre-training objective
for learning a discourse language representation in a fully self-supervised
manner. Recent pre-training methods in NLP focus on learning either bottom or
top-level language representations: contextualized word representations derived
from language model objectives at one extreme and a whole sequence
representation learned by order classification of two given textual segments at
the other. However, these models are not directly encouraged to capture
representations of intermediate-size structures that exist in natural languages
such as sentences and the relationships among them. To that end, we propose a
new approach to encourage learning of a contextualized sentence-level
representation by shuffling the sequence of input sentences and training a
hierarchical transformer model to reconstruct the original ordering. Through
experiments on downstream tasks such as GLUE, SQuAD, and DiscoEval, we show
that this feature of our model improves the performance of the original BERT by
large margins.
</p>
<a href="http://arxiv.org/abs/2010.16249" target="_blank">arXiv:2010.16249</a> [<a href="http://arxiv.org/pdf/2010.16249" target="_blank">pdf</a>]

<h2>Exploring the potential of transfer learning for metamodels of heterogeneous material deformation. (arXiv:2010.16260v1 [q-bio.TO])</h2>
<h3>Emma Lejeune, Bill Zhao</h3>
<p>From the nano-scale to the macro-scale, biological tissue is spatially
heterogeneous. Even when tissue behavior is well understood, the exact subject
specific spatial distribution of material properties is often unknown. And,
when developing computational models of biological tissue, it is usually
prohibitively computationally expensive to simulate every plausible spatial
distribution of material properties for each problem of interest. Therefore,
one of the major challenges in developing accurate computational models of
biological tissue is capturing the potential effects of this spatial
heterogeneity. Recently, machine learning based metamodels have gained
popularity as a computationally tractable way to overcome this problem because
they can make predictions based on a limited number of direct simulation runs.
These metamodels are promising, but they often still require a high number of
direct simulations to achieve an acceptable performance. Here we show that
transfer learning, a strategy where knowledge gained while solving one problem
is transferred to solving a different but related problem, can help overcome
this limitation. Critically, transfer learning can be used to leverage both
low-fidelity simulation data and simulation data that is the outcome of solving
a different but related mechanical problem. In this paper, we extend Mechanical
MNIST, our open source benchmark dataset of heterogeneous material undergoing
large deformation, to include a selection of low-fidelity simulation results
that require 2-4 orders of magnitude less CPU time to run. Then, we show that
transferring the knowledge stored in metamodels trained on these low-fidelity
simulation results can vastly improve the performance of metamodels used to
predict the results of high-fidelity simulations.
</p>
<a href="http://arxiv.org/abs/2010.16260" target="_blank">arXiv:2010.16260</a> [<a href="http://arxiv.org/pdf/2010.16260" target="_blank">pdf</a>]

<h2>Towards Accurate and Consistent Evaluation: A Dataset for Distantly-Supervised Relation Extraction. (arXiv:2010.16275v1 [cs.CL])</h2>
<h3>Tong Zhu, Haitao Wang, Junjie Yu, Xiabing Zhou, Wenliang Chen, Wei Zhang, Min Zhang</h3>
<p>In recent years, distantly-supervised relation extraction has achieved a
certain success by using deep neural networks. Distant Supervision (DS) can
automatically generate large-scale annotated data by aligning entity pairs from
Knowledge Bases (KB) to sentences. However, these DS-generated datasets
inevitably have wrong labels that result in incorrect evaluation scores during
testing, which may mislead the researchers. To solve this problem, we build a
new dataset NYTH, where we use the DS-generated data as training data and hire
annotators to label test data. Compared with the previous datasets, NYT-H has a
much larger test set and then we can perform more accurate and consistent
evaluation. Finally, we present the experimental results of several widely used
systems on NYT-H. The experimental results show that the ranking lists of the
comparison systems on the DS-labelled test data and human-annotated test data
are different. This indicates that our human-annotated data is necessary for
evaluation of distantly-supervised relation extraction.
</p>
<a href="http://arxiv.org/abs/2010.16275" target="_blank">arXiv:2010.16275</a> [<a href="http://arxiv.org/pdf/2010.16275" target="_blank">pdf</a>]

<h2>3D Object Recognition By Corresponding and Quantizing Neural 3D Scene Representations. (arXiv:2010.16279v1 [cs.CV])</h2>
<h3>Mihir Prabhudesai, Shamit Lal, Hsiao-Yu Fish Tung, Adam W. Harley, Shubhankar Potdar, Katerina Fragkiadaki</h3>
<p>We propose a system that learns to detect objects and infer their 3D poses in
RGB-D images. Many existing systems can identify objects and infer 3D poses,
but they heavily rely on human labels and 3D annotations. The challenge here is
to achieve this without relying on strong supervision signals. To address this
challenge, we propose a model that maps RGB-D images to a set of 3D visual
feature maps in a differentiable fully-convolutional manner, supervised by
predicting views. The 3D feature maps correspond to a featurization of the 3D
world scene depicted in the images. The object 3D feature representations are
invariant to camera viewpoint changes or zooms, which means feature matching
can identify similar objects under different camera viewpoints. We can compare
the 3D feature maps of two objects by searching alignment across scales and 3D
rotations, and, as a result of the operation, we can estimate pose and scale
changes without the need for 3D pose annotations. We cluster object feature
maps into a set of 3D prototypes that represent familiar objects in canonical
scales and orientations. We then parse images by inferring the prototype
identity and 3D pose for each detected object. We compare our method to
numerous baselines that do not learn 3D feature visual representations or do
not attempt to correspond features across scenes, and outperform them by a
large margin in the tasks of object retrieval and object pose estimation.
Thanks to the 3D nature of the object-centric feature maps, the visual
similarity cues are invariant to 3D pose changes or small scale changes, which
gives our method an advantage over 2D and 1D methods.
</p>
<a href="http://arxiv.org/abs/2010.16279" target="_blank">arXiv:2010.16279</a> [<a href="http://arxiv.org/pdf/2010.16279" target="_blank">pdf</a>]

<h2>DeepRx MIMO: Convolutional MIMO Detection with Learned Multiplicative Transformations. (arXiv:2010.16283v1 [eess.SP])</h2>
<h3>Dani Korpi, Mikko Honkala, Janne M.J. Huttunen, Vesa Starck</h3>
<p>Recently, deep learning has been proposed as a potential technique for
improving the physical layer performance of radio receivers. Despite the large
amount of encouraging results, most works have not considered spatial
multiplexing in the context of multiple-input and multiple-output (MIMO)
receivers. In this paper, we present a deep learning-based MIMO receiver
architecture that consists of a ResNet-based convolutional neural network, also
known as DeepRx, combined with a so-called transformation layer, all trained
together. We propose two novel alternatives for the transformation layer: a
maximal ratio combining-based transformation, or a fully learned
transformation. The former relies more on expert knowledge, while the latter
utilizes learned multiplicative layers. Both proposed transformation layers are
shown to clearly outperform the conventional baseline receiver, especially with
sparse pilot configurations. To the best of our knowledge, these are some of
the first results showing such high performance for a fully learned MIMO
receiver.
</p>
<a href="http://arxiv.org/abs/2010.16283" target="_blank">arXiv:2010.16283</a> [<a href="http://arxiv.org/pdf/2010.16283" target="_blank">pdf</a>]

<h2>All-Weather Object Recognition Using Radar and Infrared Sensing. (arXiv:2010.16285v1 [cs.CV])</h2>
<h3>Marcel Sheeny</h3>
<p>Autonomous cars are an emergent technology which has the capacity to change
human lives. The current sensor systems which are most capable of perception
are based on optical sensors. For example, deep neural networks show
outstanding results in recognising objects when used to process data from
cameras and Light Detection And Ranging (LiDAR) sensors. However these sensors
perform poorly under adverse weather conditions such as rain, fog, and snow due
to the sensor wavelengths. This thesis explores new sensing developments based
on long wave polarised infrared (IR) imagery and imaging radar to recognise
objects. First, we developed a methodology based on Stokes parameters using
polarised infrared data to recognise vehicles using deep neural networks.
Second, we explored the potential of using only the power spectrum captured by
low-THz radar sensors to perform object recognition in a controlled scenario.
This latter work is based on a data-driven approach together with the
development of a data augmentation method based on attenuation, range and
speckle noise. Last, we created a new large-scale dataset in the "wild" with
many different weather scenarios (sunny, overcast, night, fog, rain and snow)
showing radar robustness to detect vehicles in adverse weather. High resolution
radar and polarised IR imagery, combined with a deep learning approach, are
shown as a potential alternative to current automotive sensing systems based on
visible spectrum optical technology as they are more robust in severe weather
and adverse light conditions.
</p>
<a href="http://arxiv.org/abs/2010.16285" target="_blank">arXiv:2010.16285</a> [<a href="http://arxiv.org/pdf/2010.16285" target="_blank">pdf</a>]

<h2>Learning Vision-based Reactive Policies for Obstacle Avoidance. (arXiv:2010.16298v1 [cs.RO])</h2>
<h3>Elie Aljalbout, Ji Chen, Konstantin Ritt, Maximilian Ulmer, Sami Haddadin</h3>
<p>In this paper, we address the problem of vision-based obstacle avoidance for
robotic manipulators. This topic poses challenges for both perception and
motion generation. While most work in the field aims at improving one of those
aspects, we provide a unified framework for approaching this problem. The main
goal of this framework is to connect perception and motion by identifying the
relationship between the visual input and the corresponding motion
representation. To this end, we propose a method for learning reactive obstacle
avoidance policies. We evaluate our method on goal-reaching tasks for single
and multiple obstacles scenarios. We show the ability of the proposed method to
efficiently learn stable obstacle avoidance strategies at a high success rate,
while maintaining closed-loop responsiveness required for critical applications
like human-robot interaction.
</p>
<a href="http://arxiv.org/abs/2010.16298" target="_blank">arXiv:2010.16298</a> [<a href="http://arxiv.org/pdf/2010.16298" target="_blank">pdf</a>]

<h2>Automatic Counting and Identification of Train Wagons Based on Computer Vision and Deep Learning. (arXiv:2010.16307v1 [cs.CV])</h2>
<h3>Rayson Laroca, Alessander Cidral Boslooper, David Menotti</h3>
<p>In this work, we present a robust and efficient solution for counting and
identifying train wagons using computer vision and deep learning. The proposed
solution is cost-effective and can easily replace solutions based on
radiofrequency identification (RFID), which are known to have high installation
and maintenance costs. According to our experiments, our two-stage methodology
achieves impressive results on real-world scenarios, i.e., 100% accuracy in the
counting stage and 99.7% recognition rate in the identification one. Moreover,
the system is able to automatically reject some of the train wagons
successfully counted, as they have damaged identification codes. The results
achieved were surprising considering that the proposed system requires low
processing power (i.e., it can run in low-end setups) and that we used a
relatively small number of images to train our Convolutional Neural Network
(CNN) for character recognition. The proposed method is registered, under
number BR512020000808-9, with the National Institute of Industrial Property
(Brazil).
</p>
<a href="http://arxiv.org/abs/2010.16307" target="_blank">arXiv:2010.16307</a> [<a href="http://arxiv.org/pdf/2010.16307" target="_blank">pdf</a>]

<h2>Embedding Meta-Textual Information for Improved Learning to Rank. (arXiv:2010.16313v1 [cs.IR])</h2>
<h3>Toshitaka Kuwa, Shigehiko Schamoni, Stefan Riezler</h3>
<p>Neural approaches to learning term embeddings have led to improved
computation of similarity and ranking in information retrieval (IR). So far
neural representation learning has not been extended to meta-textual
information that is readily available for many IR tasks, for example, patent
classes in prior-art retrieval, topical information in Wikipedia articles, or
product categories in e-commerce data. We present a framework that learns
embeddings for meta-textual categories, and optimizes a pairwise ranking
objective for improved matching based on combined embeddings of textual and
meta-textual information. We show considerable gains in an experimental
evaluation on cross-lingual retrieval in the Wikipedia domain for three
language pairs, and in the Patent domain for one language pair. Our results
emphasize that the mode of combining different types of information is crucial
for model improvement.
</p>
<a href="http://arxiv.org/abs/2010.16313" target="_blank">arXiv:2010.16313</a> [<a href="http://arxiv.org/pdf/2010.16313" target="_blank">pdf</a>]

<h2>DeepWay: a Deep Learning Estimator for Unmanned Ground Vehicle Global Path Planning. (arXiv:2010.16322v1 [cs.RO])</h2>
<h3>Vittorio Mazzia, Francesco Salvetti, Diego Aghi, Marcello Chiaberge</h3>
<p>Agriculture 3.0 and 4.0 have gradually introduced service robotics and
automation into several agricultural processes, mostly improving crops quality
and seasonal yield. Row-based crops are the perfect settings to test and deploy
smart machines capable of monitoring and manage the harvest. In this context,
global path planning is essential either for ground or aerial vehicles, and it
is the starting point for every type of mission plan. Nevertheless, little
attention has been currently given to this problem by the research community
and global path planning automation is still far to be solved. In order to
generate a viable path for an autonomous machine, the presented research
proposes a feature learning fully convolutional model capable of estimating
waypoints given an occupancy grid map. In particular, we apply the proposed
data-driven methodology to the specific case of row-based crops with the
general objective to generate a global path able to cover the extension of the
crop completely. Extensive experimentation with a custom made synthetic dataset
and real satellite-derived images of different scenarios have proved the
effectiveness of our methodology and demonstrated the feasibility of an
end-to-end and completely autonomous global path planner.
</p>
<a href="http://arxiv.org/abs/2010.16322" target="_blank">arXiv:2010.16322</a> [<a href="http://arxiv.org/pdf/2010.16322" target="_blank">pdf</a>]

<h2>Being Single Has Benefits. Instance Poisoning to Deceive Malware Classifiers. (arXiv:2010.16323v1 [cs.CR])</h2>
<h3>Tzvika Shapira, David Berend, Ishai Rosenberg, Yang Liu, Asaf Shabtai, Yuval Elovici</h3>
<p>The performance of a machine learning-based malware classifier depends on the
large and updated training set used to induce its model. In order to maintain
an up-to-date training set, there is a need to continuously collect benign and
malicious files from a wide range of sources, providing an exploitable target
to attackers. In this study, we show how an attacker can launch a sophisticated
and efficient poisoning attack targeting the dataset used to train a malware
classifier. The attacker's ultimate goal is to ensure that the model induced by
the poisoned dataset will be unable to detect the attacker's malware yet
capable of detecting other malware. As opposed to other poisoning attacks in
the malware detection domain, our attack does not focus on malware families but
rather on specific malware instances that contain an implanted trigger,
reducing the detection rate from 99.23% to 0% depending on the amount of
poisoning. We evaluate our attack on the EMBER dataset with a state-of-the-art
classifier and malware samples from VirusTotal for end-to-end validation of our
work. We propose a comprehensive detection approach that could serve as a
future sophisticated defense against this newly discovered severe threat.
</p>
<a href="http://arxiv.org/abs/2010.16323" target="_blank">arXiv:2010.16323</a> [<a href="http://arxiv.org/pdf/2010.16323" target="_blank">pdf</a>]

<h2>Topic-Preserving Synthetic News Generation: An Adversarial Deep Reinforcement Learning Approach. (arXiv:2010.16324v1 [cs.CL])</h2>
<h3>Ahmadreza Mosallanezhad, Kai Shu, Huan Liu</h3>
<p>Nowadays, there exist powerful language models such as OpenAI's GPT-2 that
can generate readable text and can be fine-tuned to generate text for a
specific domain. Considering GPT-2, it cannot directly generate synthetic news
with respect to a given topic and the output of the language model cannot be
explicitly controlled. In this paper, we study the novel problem of
topic-preserving synthetic news generation. We propose a novel deep
reinforcement learning-based method to control the output of GPT-2 with respect
to a given news topic. When generating text using GPT-2, by default, the most
probable word is selected from the vocabulary. Instead of selecting the best
word each time from GPT-2's output, an RL agent tries to select words that
optimize the matching of a given topic. In addition, using a fake news detector
as an adversary, we investigate generating realistic news using our proposed
method. In this paper, we consider realistic news as news that cannot be easily
detected by a fake news classifier. Experimental results demonstrate the
effectiveness of the proposed framework on generating topic-preserving news
content than state-of-the-art baselines.
</p>
<a href="http://arxiv.org/abs/2010.16324" target="_blank">arXiv:2010.16324</a> [<a href="http://arxiv.org/pdf/2010.16324" target="_blank">pdf</a>]

<h2>All of the Fairness for Edge Prediction with Optimal Transport. (arXiv:2010.16326v1 [cs.LG])</h2>
<h3>Charlotte Laclau, Ievgen Redko, Manvi Choudhary, Christine Largeron</h3>
<p>Machine learning and data mining algorithms have been increasingly used
recently to support decision-making systems in many areas of high societal
importance such as healthcare, education, or security. While being very
efficient in their predictive abilities, the deployed algorithms sometimes tend
to learn an inductive model with a discriminative bias due to the presence of
this latter in the learning sample. This problem gave rise to a new field of
algorithmic fairness where the goal is to correct the discriminative bias
introduced by a certain attribute in order to decorrelate it from the model's
output. In this paper, we study the problem of fairness for the task of edge
prediction in graphs, a largely underinvestigated scenario compared to a more
popular setting of fair classification. To this end, we formulate the problem
of fair edge prediction, analyze it theoretically, and propose an
embedding-agnostic repairing procedure for the adjacency matrix of an arbitrary
graph with a trade-off between the group and individual fairness. We
experimentally show the versatility of our approach and its capacity to provide
explicit control over different notions of fairness and prediction accuracy.
</p>
<a href="http://arxiv.org/abs/2010.16326" target="_blank">arXiv:2010.16326</a> [<a href="http://arxiv.org/pdf/2010.16326" target="_blank">pdf</a>]

<h2>Calibration-Aided Edge Inference Offloading via Adaptive Model Partitioning of Deep Neural Networks. (arXiv:2010.16335v1 [cs.LG])</h2>
<h3>Roberto G. Pacheco, Rodrigo S. Couto, Osvaldo Simeone</h3>
<p>Mobile devices can offload deep neural network (DNN)-based inference to the
cloud, overcoming local hardware and energy limitations. However, offloading
adds communication delay, thus increasing the overall inference time, and hence
it should be used only when needed. An approach to address this problem
consists of the use of adaptive model partitioning based on early-exit DNNs.
Accordingly, the inference starts at the mobile device, and an intermediate
layer estimates the accuracy: If the estimated accuracy is sufficient, the
device takes the inference decision; Otherwise, the remaining layers of the DNN
run at the cloud. Thus, the device offloads the inference to the cloud only if
it cannot classify a sample with high confidence. This offloading requires a
correct accuracy prediction at the device. Nevertheless, DNNs are typically
miscalibrated, providing overconfident decisions. This work shows that the
employment of a miscalibrated early-exit DNN for offloading via model
partitioning can significantly decrease inference accuracy. In contrast, we
argue that implementing a calibration algorithm prior to deployment can solve
this problem, allowing for more reliable offloading decisions.
</p>
<a href="http://arxiv.org/abs/2010.16335" target="_blank">arXiv:2010.16335</a> [<a href="http://arxiv.org/pdf/2010.16335" target="_blank">pdf</a>]

<h2>Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach. (arXiv:2010.16342v1 [cs.RO])</h2>
<h3>Kartik Paigwar, Lokesh Krishna, Sashank Tirumala, Naman Khetan, Aditya Sagi, Ashish Joglekar, Shalabh Bhatnagar, Ashitava Ghosal, Bharadwaj Amrutur, Shishir Kolathaya</h3>
<p>In this paper, with a view toward fast deployment of locomotion gaits in
low-cost hardware, we use a linear policy for realizing end-foot trajectories
in the quadruped robot, Stoch $2$. In particular, the parameters of the
end-foot trajectories are shaped via a linear feedback policy that takes the
torso orientation and the terrain slope as inputs. The corresponding desired
joint angles are obtained via an inverse kinematics solver and tracked via a
PID control law. Augmented Random Search, a model-free and a gradient-free
learning algorithm is used to train this linear policy. Simulation results show
that the resulting walking is robust to external pushes and terrain slope
variations. This methodology is not only computationally light-weight but also
uses minimal sensing and actuation capabilities in the robot, thereby
justifying the approach.
</p>
<a href="http://arxiv.org/abs/2010.16342" target="_blank">arXiv:2010.16342</a> [<a href="http://arxiv.org/pdf/2010.16342" target="_blank">pdf</a>]

<h2>Marginalised Gaussian Processes with Nested Sampling. (arXiv:2010.16344v1 [stat.ML])</h2>
<h3>Fergus Simpson, Vidhi Lalchand, Carl Edward Rasmussen</h3>
<p>Gaussian Process (GPs) models are a rich distribution over functions with
inductive biases controlled by a kernel function. Learning occurs through the
optimisation of kernel hyperparameters using the marginal likelihood as the
objective. This classical approach known as Type-II maximum likelihood (ML-II)
yields point estimates of the hyperparameters, and continues to be the default
method for training GPs. However, this approach risks underestimating
predictive uncertainty and is prone to overfitting especially when there are
many hyperparameters. Furthermore, gradient based optimisation makes ML-II
point estimates highly susceptible to the presence of local minima. This work
presents an alternative learning procedure where the hyperparameters of the
kernel function are marginalised using Nested Sampling (NS), a technique that
is well suited to sample from complex, multi-modal distributions. We focus on
regression tasks with the spectral mixture (SM) class of kernels and find that
a principled approach to quantifying model uncertainty leads to substantial
gains in predictive performance across a range of synthetic and benchmark data
sets. In this context, nested sampling is also found to offer a speed advantage
over Hamiltonian Monte Carlo (HMC), widely considered to be the gold-standard
in MCMC based inference.
</p>
<a href="http://arxiv.org/abs/2010.16344" target="_blank">arXiv:2010.16344</a> [<a href="http://arxiv.org/pdf/2010.16344" target="_blank">pdf</a>]

<h2>AgEBO-Tabular: Joint Neural Architecture and Hyperparameter Search with Autotuned Data-Parallel Training for Tabular Data. (arXiv:2010.16358v1 [cs.LG])</h2>
<h3>Romain Egele, Prasanna Balaprakash, Venkatram Vishwanath, Isabelle Guyon, Zhengying Liu</h3>
<p>Developing high-performing predictive models for large tabular data sets is a
challenging task. The state-of-the-art methods are based on expert-developed
model ensembles from different supervised learning methods. Recently, automated
machine learning (AutoML) is emerging as a promising approach to automate
predictive model development. Neural architecture search (NAS) is an AutoML
approach that generates and evaluates multiple neural network architectures
concurrently and improves the accuracy of the generated models iteratively. A
key issue in NAS, particularly for large data sets, is the large computation
time required to evaluate each generated architecture. While data-parallel
training is a promising approach that can address this issue, its use within
NAS is difficult. For different data sets, the data-parallel training settings
such as the number of parallel processes, learning rate, and batch size need to
be adapted to achieve high accuracy and reduction in training time. To that
end, we have developed AgEBO-Tabular, an approach to combine aging evolution
(AgE), a parallel NAS method that searches over neural architecture space, and
an asynchronous Bayesian optimization method for tuning the hyperparameters of
the data-parallel training simultaneously. We demonstrate the efficacy of the
proposed method to generate high-performing neural network models for large
tabular benchmark data sets. Furthermore, we demonstrate that the automatically
discovered neural network models using our method outperform the
state-of-the-art AutoML ensemble models in inference speed by two orders of
magnitude while reaching similar accuracy values.
</p>
<a href="http://arxiv.org/abs/2010.16358" target="_blank">arXiv:2010.16358</a> [<a href="http://arxiv.org/pdf/2010.16358" target="_blank">pdf</a>]

<h2>Towards Preference Learning for Autonomous Ground Robot Navigation Tasks. (arXiv:2010.16361v1 [cs.RO])</h2>
<h3>C. Hayes, M. Marge</h3>
<p>We are interested in the design of autonomous robot behaviors that learn the
preferences of users over continued interactions, with the goal of efficiently
executing navigation behaviors in a way that the user expects. In this paper,
we discuss our work in progress to modify a general model for robot navigation
behaviors in an exploration task on a per-user basis using preference-based
reinforcement learning. The novel contribution of this approach is that it
combines reinforcement learning, motion planning, and natural language
processing to allow an autonomous agent to learn from sustained dialogue with a
human teammate as opposed to one-off instructions.
</p>
<a href="http://arxiv.org/abs/2010.16361" target="_blank">arXiv:2010.16361</a> [<a href="http://arxiv.org/pdf/2010.16361" target="_blank">pdf</a>]

<h2>Development and Evaluation of a Deep Neural Network for Histologic Classification of Renal Cell Carcinoma on Biopsy and Surgical Resection Slides. (arXiv:2010.16380v1 [eess.IV])</h2>
<h3>Mengdan Zhu, Bing Ren, Ryland Richards, Matthew Suriawinata, Naofumi Tomita, Saeed Hassanpour</h3>
<p>Renal cell carcinoma (RCC) is the most common renal cancer in adults. The
histopathologic classification of RCC is essential for diagnosis, prognosis,
and management of patients. Reorganization and classification of complex
histologic patterns of RCC on biopsy and surgical resection slides under a
microscope remains a heavily specialized, error-prone, and time-consuming task
for pathologists. In this study, we developed a deep neural network model that
can accurately classify digitized surgical resection slides and biopsy slides
into five related classes: clear cell RCC, papillary RCC, chromophobe RCC,
renal oncocytoma, and normal. In addition to the whole-slide classification
pipeline, we visualized the identified indicative regions and features on
slides for classification by reprocessing patch-level classification results to
ensure the explainability of our diagnostic model. We evaluated our model on
independent test sets of 78 surgical resection whole slides and 79 biopsy
slides from our tertiary medical institution, and 69 randomly selected surgical
resection slides from The Cancer Genome Atlas (TCGA) database. The average area
under the curve (AUC) of our classifier on the internal resection slides,
internal biopsy slides, and external TCGA slides is 0.98, 0.98 and 0.99,
respectively. Our results suggest that the high generalizability of our
approach across different data sources and specimen types. More importantly,
our model has the potential to assist pathologists by (1) automatically
pre-screening slides to reduce false-negative cases, (2) highlighting regions
of importance on digitized slides to accelerate diagnosis, and (3) providing
objective and accurate diagnosis as the second opinion.
</p>
<a href="http://arxiv.org/abs/2010.16380" target="_blank">arXiv:2010.16380</a> [<a href="http://arxiv.org/pdf/2010.16380" target="_blank">pdf</a>]

<h2>Goal directed molecule generation using Monte Carlo Tree Search. (arXiv:2010.16399v1 [cs.LG])</h2>
<h3>Anand A. Rajasekar, Karthik Raman, Balaraman Ravindran</h3>
<p>One challenging and essential task in biochemistry is the generation of novel
molecules with desired properties. Novel molecule generation remains a
challenge since the molecule space is difficult to navigate through, and the
generated molecules should obey the rules of chemical valency. Through this
work, we propose a novel method, which we call unitMCTS, to perform molecule
generation by making a unit change to the molecule at every step using Monte
Carlo Tree Search. We show that this method outperforms the recently published
techniques on benchmark molecular optimization tasks such as QED and penalized
logP. We also demonstrate the usefulness of this method in improving molecule
properties while being similar to the starting molecule. Given that there is no
learning involved, our method finds desired molecules within a shorter amount
of time.
</p>
<a href="http://arxiv.org/abs/2010.16399" target="_blank">arXiv:2010.16399</a> [<a href="http://arxiv.org/pdf/2010.16399" target="_blank">pdf</a>]

<h2>Unsupervised Monocular Depth Learning in Dynamic Scenes. (arXiv:2010.16404v1 [cs.CV])</h2>
<h3>Hanhan Li, Ariel Gordon, Hang Zhao, Vincent Casser, Anelia Angelova</h3>
<p>We present a method for jointly training the estimation of depth, ego-motion,
and a dense 3D translation field of objects relative to the scene, with
monocular photometric consistency being the sole source of supervision. We show
that this apparently heavily underdetermined problem can be regularized by
imposing the following prior knowledge about 3D translation fields: they are
sparse, since most of the scene is static, and they tend to be constant for
rigid moving objects. We show that this regularization alone is sufficient to
train monocular depth prediction models that exceed the accuracy achieved in
prior work for dynamic scenes, including methods that require semantic input.
Code is at
https://github.com/google-research/google-research/tree/master/depth_and_motion_learning .
</p>
<a href="http://arxiv.org/abs/2010.16404" target="_blank">arXiv:2010.16404</a> [<a href="http://arxiv.org/pdf/2010.16404" target="_blank">pdf</a>]

<h2>TopicBERT for Energy Efficient Document Classification. (arXiv:2010.16407v1 [cs.CL])</h2>
<h3>Yatin Chaudhary, Pankaj Gupta, Khushbu Saxena, Vivek Kulkarni, Thomas Runkler, Hinrich Sch&#xfc;tze</h3>
<p>Prior research notes that BERT's computational cost grows quadratically with
sequence length thus leading to longer training times, higher GPU memory
constraints and carbon emissions. While recent work seeks to address these
scalability issues at pre-training, these issues are also prominent in
fine-tuning especially for long sequence tasks like document classification.
Our work thus focuses on optimizing the computational cost of fine-tuning for
document classification. We achieve this by complementary learning of both
topic and language models in a unified framework, named TopicBERT. This
significantly reduces the number of self-attention operations - a main
performance bottleneck. Consequently, our model achieves a 1.4x ($\sim40\%$)
speedup with $\sim40\%$ reduction in $CO_2$ emission while retaining $99.9\%$
performance over 5 datasets.
</p>
<a href="http://arxiv.org/abs/2010.16407" target="_blank">arXiv:2010.16407</a> [<a href="http://arxiv.org/pdf/2010.16407" target="_blank">pdf</a>]

<h2>Inherent Trade-offs in the Fair Allocation of Treatments. (arXiv:2010.16409v1 [cs.LG])</h2>
<h3>Yuzi He, Keith Burghardt, Siyi Guo, Kristina Lerman</h3>
<p>Explicit and implicit bias clouds human judgement, leading to discriminatory
treatment of minority groups. A fundamental goal of algorithmic fairness is to
avoid the pitfalls in human judgement by learning policies that improve the
overall outcomes while providing fair treatment to protected classes. In this
paper, we propose a causal framework that learns optimal intervention policies
from data subject to fairness constraints. We define two measures of treatment
bias and infer best treatment assignment that minimizes the bias while
optimizing overall outcome. We demonstrate that there is a dilemma of balancing
fairness and overall benefit; however, allowing preferential treatment to
protected classes in certain circumstances (affirmative action) can
dramatically improve the overall benefit while also preserving fairness. We
apply our framework to data containing student outcomes on standardized tests
and show how it can be used to design real-world policies that fairly improve
student test scores. Our framework provides a principled way to learn fair
treatment policies in real-world settings.
</p>
<a href="http://arxiv.org/abs/2010.16409" target="_blank">arXiv:2010.16409</a> [<a href="http://arxiv.org/pdf/2010.16409" target="_blank">pdf</a>]

<h2>Semi-supervised Relation Extraction via Incremental Meta Self-Training. (arXiv:2010.16410v1 [cs.CL])</h2>
<h3>Xuming Hu, Fukun Ma, Chenyao Liu, Chenwei Zhang, Lijie Wen, Philip S. Yu</h3>
<p>To alleviate human efforts from obtaining large-scale annotations,
Semi-Supervised Relation Extraction methods aim to leverage unlabeled data in
addition to learning from limited samples. Existing self-training methods
suffer from the gradual drift problem, where noisy pseudo labels on unlabeled
data are incorporated during training. To alleviate the noise in pseudo labels,
we propose a method called MetaSRE, where a Relation Label Generation Network
generates accurate quality assessment on pseudo labels by (meta) learning from
the successful and failed attempts on Relation Classification as an additional
meta-objective. To reduce the influence of noisy pseudo labels, MetaSRE adopts
a pseudo label selection and exploitation scheme which assesses pseudo label
quality on unlabeled samples and only exploits high-quality pseudo labels in a
self-training fashion to incrementally augment labeled samples for both
robustness and accuracy. Experimental results on two public datasets
demonstrate the effectiveness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2010.16410" target="_blank">arXiv:2010.16410</a> [<a href="http://arxiv.org/pdf/2010.16410" target="_blank">pdf</a>]

<h2>Handling Missing Data with Graph Representation Learning. (arXiv:2010.16418v1 [cs.LG])</h2>
<h3>Jiaxuan You, Xiaobai Ma, Daisy Yi Ding, Mykel Kochenderfer, Jure Leskovec</h3>
<p>Machine learning with missing data has been approached in two different ways,
including feature imputation where missing feature values are estimated based
on observed values, and label prediction where downstream labels are learned
directly from incomplete data. However, existing imputation models tend to have
strong prior assumptions and cannot learn from downstream tasks, while models
targeting label prediction often involve heuristics and can encounter
scalability issues. Here we propose GRAPE, a graph-based framework for feature
imputation as well as label prediction. GRAPE tackles the missing data problem
using a graph representation, where the observations and features are viewed as
two types of nodes in a bipartite graph, and the observed feature values as
edges. Under the GRAPE framework, the feature imputation is formulated as an
edge-level prediction task and the label prediction as a node-level prediction
task. These tasks are then solved with Graph Neural Networks. Experimental
results on nine benchmark datasets show that GRAPE yields 20% lower mean
absolute error for imputation tasks and 10% lower for label prediction tasks,
compared with existing state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.16418" target="_blank">arXiv:2010.16418</a> [<a href="http://arxiv.org/pdf/2010.16418" target="_blank">pdf</a>]

<h2>A self-organizing fuzzy neural network for sequence learning. (arXiv:1908.00617v2 [cs.NE] UPDATED)</h2>
<h3>Armin Salimi-Badr, Mohammad Mehdi Ebadzadeh</h3>
<p>In this paper, a new self-organizing fuzzy neural network model is presented
which is able to learn and reproduce different sequences accurately. Sequence
learning is important in performing skillful tasks, such as writing and playing
piano. The structure of the proposed network is composed of two parts:
1-sequence identifier which computes a novel sequence identity value based on
initial samples of a sequence, and detects the sequence identity based on
proper fuzzy rules, and 2-sequence locator, which locates the input sample in
the sequence. Therefore, by integrating outputs of these two parts in fuzzy
rules, the network is able to produce the proper output based on current state
of the sequence. To learn the proposed structure, a gradual learning procedure
is proposed. First, learning is performed by adding new fuzzy rules, based on
coverage measure, using available correct data. Next, the initialized
parameters are fine-tuned, by gradient descent algorithm, based on fed back
approximated network output as the next input. The proposed method has a
dynamic structure which is able to learn new sequences online. The proposed
method is used to learn and reproduce different sequences simultaneously which
is the novelty of this method.
</p>
<a href="http://arxiv.org/abs/1908.00617" target="_blank">arXiv:1908.00617</a> [<a href="http://arxiv.org/pdf/1908.00617" target="_blank">pdf</a>]

<h2>Active inference: demystified and compared. (arXiv:1909.10863v3 [cs.AI] UPDATED)</h2>
<h3>Noor Sajid, Philip J. Ball, Thomas Parr, Karl J. Friston</h3>
<p>Active inference is a first principle account of how autonomous agents
operate in dynamic, non-stationary environments. This problem is also
considered in reinforcement learning (RL), but limited work exists on comparing
the two approaches on the same discrete-state environments. In this paper, we
provide: 1) an accessible overview of the discrete-state formulation of active
inference, highlighting natural behaviors in active inference that are
generally engineered in RL; 2) an explicit discrete-state comparison between
active inference and RL on an OpenAI gym baseline. We begin by providing a
condensed overview of the active inference literature, in particular viewing
the various natural behaviors of active inference agents through the lens of
RL. We show that by operating in a pure belief-based setting, active inference
agents can carry out epistemic exploration, and account for uncertainty about
their environment in a Bayes-optimal fashion. Furthermore, we show that the
reliance on an explicit reward signal in RL is removed in active inference,
where reward can simply be treated as another observation; even in the total
absence of rewards, agent behaviors are learned through preference learning. We
make these properties explicit by showing two scenarios in which active
inference agents can infer behaviors in reward-free environments compared to
both Q-learning and Bayesian model-based RL agents; by placing zero prior
preferences over rewards and by learning the prior preferences over the
observations corresponding to reward. We conclude by noting that this formalism
can be applied to more complex settings if appropriate generative models can be
formulated. In short, we aim to demystify the behavior of active inference
agents by presenting an accessible discrete state-space and time formulation,
and demonstrate these behaviors in a OpenAI gym environment, alongside RL
agents.
</p>
<a href="http://arxiv.org/abs/1909.10863" target="_blank">arXiv:1909.10863</a> [<a href="http://arxiv.org/pdf/1909.10863" target="_blank">pdf</a>]

<h2>Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Class-Imbalanced Data. (arXiv:1910.01112v2 [cs.LG] UPDATED)</h2>
<h3>Utkarsh Ojha, Krishna Kumar Singh, Cho-Jui Hsieh, Yong Jae Lee</h3>
<p>We propose a novel unsupervised generative model that learns to disentangle
object identity from other low-level aspects in class-imbalanced data. We first
investigate the issues surrounding the assumptions about uniformity made by
InfoGAN, and demonstrate its ineffectiveness to properly disentangle object
identity in imbalanced data. Our key idea is to make the discovery of the
discrete latent factor of variation invariant to identity-preserving
transformations in real images, and use that as a signal to learn the
appropriate latent distribution representing object identity. Experiments on
both artificial (MNIST, 3D cars, 3D chairs, ShapeNet) and real-world
(YouTube-Faces) imbalanced datasets demonstrate the effectiveness of our method
in disentangling object identity as a latent factor of variation.
</p>
<a href="http://arxiv.org/abs/1910.01112" target="_blank">arXiv:1910.01112</a> [<a href="http://arxiv.org/pdf/1910.01112" target="_blank">pdf</a>]

<h2>AITom: Open-source AI platform for cryo-electron tomography data analysis. (arXiv:1911.03044v2 [q-bio.QM] UPDATED)</h2>
<h3>Xiangrui Zeng, Min Xu</h3>
<p>Cryo-electron tomography (cryo-ET) is an emerging technology for the 3D
visualization of structural organizations and interactions of subcellular
components at near-native state and sub-molecular resolution. Tomograms
captured by cryo-ET contain heterogeneous structures representing the complex
and dynamic subcellular environment. Since the structures are not purified or
fluorescently labeled, the spatial organization and interaction between both
the known and unknown structures can be studied in their native environment.
The rapid advances of cryo-electron tomography (cryo-ET) have generated
abundant 3D cellular imaging data. However, the systematic localization,
identification, segmentation, and structural recovery of the subcellular
components require efficient and accurate large-scale image analysis methods.
We introduce AITom, an open-source artificial intelligence platform for cryo-ET
researchers. AITom provides many public as well as in-house algorithms for
performing cryo-ET data analysis through both the traditional template-based or
template-free approach and the deep learning approach. AITom also supports
remote interactive analysis. Comprehensive tutorials for each analysis module
are provided to guide the user through. We welcome researchers and developers
to join this collaborative open-source software development project.
Availability: https://github.com/xulabs/aitom
</p>
<a href="http://arxiv.org/abs/1911.03044" target="_blank">arXiv:1911.03044</a> [<a href="http://arxiv.org/pdf/1911.03044" target="_blank">pdf</a>]

<h2>Aggregative Efficiency of Bayesian Learning in Networks. (arXiv:1911.10116v5 [econ.TH] UPDATED)</h2>
<h3>Krishna Dasaratha, Kevin He</h3>
<p>In social-learning settings where individuals receive private signals and
observe network neighbors' actions, the network structure often obstructs
information aggregation. We consider sequential social learning with rational
agents and Gaussian signals and ask how the efficiency of signal aggregation
changes with the network. Rational actions in our model admit a signal-counting
interpretation of accuracy, which lets us compare the aggregative efficiency of
social learning across networks. Learning is very inefficient in a class of
networks where agents move in generations and observe the previous generation.
Generations after the first contribute very little additional information, even
when generations are arbitrarily large.
</p>
<a href="http://arxiv.org/abs/1911.10116" target="_blank">arXiv:1911.10116</a> [<a href="http://arxiv.org/pdf/1911.10116" target="_blank">pdf</a>]

<h2>Reducing Non-Normative Text Generation from Language Models. (arXiv:2001.08764v2 [cs.CL] UPDATED)</h2>
<h3>Xiangyu Peng, Siyan Li, Spencer Frazier, Mark Riedl</h3>
<p>Large-scale, transformer-based language models such as GPT-2 are pretrained
on diverse corpora scraped from the internet. Consequently, they are prone to
generating non-normative text (i.e. in violation of social norms). We introduce
a technique for fine-tuning GPT-2, using a policy gradient reinforcement
learning technique and a normative text classifier to produce reward and
punishment values. We evaluate our technique on five data sets using automated
and human participant experiments. The normative text classifier is 81-90%
accurate when compared to gold-standard human judgments of normative and
non-normative generated text. Our normative fine-tuning technique is able to
reduce non-normative text by 27-61%, depending on the data set.
</p>
<a href="http://arxiv.org/abs/2001.08764" target="_blank">arXiv:2001.08764</a> [<a href="http://arxiv.org/pdf/2001.08764" target="_blank">pdf</a>]

<h2>Gaze Preserving CycleGANs for Eyeglass Removal & Persistent Gaze Estimation. (arXiv:2002.02077v5 [cs.CV] UPDATED)</h2>
<h3>Akshay Rangesh, Bowen Zhang, Mohan M. Trivedi</h3>
<p>A driver's gaze is critical for determining their attention, state,
situational awareness, and readiness to take over control from partially
automated vehicles. Estimating the gaze direction is the most obvious way to
gauge a driver's state under ideal conditions when limited to using
non-intrusive imaging sensors. Unfortunately, the vehicular environment
introduces a variety of challenges that are usually unaccounted for - harsh
illumination, nighttime conditions, and reflective eyeglasses. Relying on head
pose alone under such conditions can prove to be unreliable and erroneous. In
this study, we offer solutions to address these problems encountered in the
real world. To solve issues with lighting, we demonstrate that using an
infrared camera with suitable equalization and normalization suffices. To
handle eyeglasses and their corresponding artifacts, we adopt image-to-image
translation using generative adversarial networks to pre-process images prior
to gaze estimation. Our proposed Gaze Preserving CycleGAN (GPCycleGAN) is
trained to preserve the driver's gaze while removing potential eyeglasses from
face images. GPCycleGAN is based on the well-known CycleGAN approach - with the
addition of a gaze classifier and a gaze consistency loss for additional
supervision. Our approach exhibits improved performance, interpretability,
robustness and superior qualitative results on challenging real-world datasets.
</p>
<a href="http://arxiv.org/abs/2002.02077" target="_blank">arXiv:2002.02077</a> [<a href="http://arxiv.org/pdf/2002.02077" target="_blank">pdf</a>]

<h2>Multi-Task Learning by a Top-Down Control Network. (arXiv:2002.03335v3 [cs.LG] UPDATED)</h2>
<h3>Hila Levi, Shimon Ullman</h3>
<p>As the range of tasks performed by a general vision system expands, executing
multiple tasks accurately and efficiently in a single network has become an
important and still open problem. Recent computer vision approaches address
this problem by branching networks, or by a channel-wise modulation of the
network feature-maps with task specific vectors. We present a novel
architecture that uses a dedicated top-down control network to modify the
activation of all the units in the main recognition network in a manner that
depends on the selected task, image content, and spatial location. We show the
effectiveness of our scheme by achieving significantly better results than
alternative state-of-the-art approaches on four datasets. We further
demonstrate our advantages in terms of task selectivity, scaling the number of
tasks and interpretability.
</p>
<a href="http://arxiv.org/abs/2002.03335" target="_blank">arXiv:2002.03335</a> [<a href="http://arxiv.org/pdf/2002.03335" target="_blank">pdf</a>]

<h2>Learning to Prove Theorems by Learning to Generate Theorems. (arXiv:2002.07019v2 [cs.LO] UPDATED)</h2>
<h3>Mingzhe Wang, Jia Deng</h3>
<p>We consider the task of automated theorem proving, a key AI task. Deep
learning has shown promise for training theorem provers, but there are limited
human-written theorems and proofs available for supervised learning. To address
this limitation, we propose to learn a neural generator that automatically
synthesizes theorems and proofs for the purpose of training a theorem prover.
Experiments on real-world tasks demonstrate that synthetic data from our
approach improves the theorem prover and advances the state of the art of
automated theorem proving in Metamath. Code is available at
https://github.com/princeton-vl/MetaGen.
</p>
<a href="http://arxiv.org/abs/2002.07019" target="_blank">arXiv:2002.07019</a> [<a href="http://arxiv.org/pdf/2002.07019" target="_blank">pdf</a>]

<h2>A Machine Learning Application for Raising WASH Awareness in the Times of COVID-19 Pandemic. (arXiv:2003.07074v3 [cs.CY] UPDATED)</h2>
<h3>Rohan Pandey, Vaibhav Gautam, Ridam Pal, Harsh Bandhey, Lovedeep Singh Dhingra, Himanshu Sharma, Chirag Jain, Kanav Bhagat, Arushi, Lajjaben Patel, Mudit Agarwal, Samprati Agrawal, Rishabh Jalan, Akshat Wadhwa, Ayush Garg, Vihaan Misra, Yashwin Agrawal, Bhavika Rana, Ponnurangam Kumaraguru, Tavpritesh Sethi</h3>
<p>Background: The COVID-19 pandemic has uncovered the potential of digital
misinformation in shaping the health of nations. The deluge of unverified
information that spreads faster than the epidemic itself is an unprecedented
phenomenon that has put millions of lives in danger. Mitigating this Infodemic
requires strong health messaging systems that are engaging, vernacular,
scalable, effective and continuously learn the new patterns of misinformation.

Objective: We created WashKaro, a multi-pronged intervention for mitigating
misinformation through conversational AI, machine translation and natural
language processing. WashKaro provides the right information matched against
WHO guidelines through AI, and delivers it in the right format in local
languages.

Methods: We theorize (i) an NLP based AI engine that could continuously
incorporate user feedback to improve relevance of information, (ii) bite sized
audio in the local language to improve penetrance in a country with skewed
gender literacy ratios, and (iii) conversational but interactive AI engagement
with users towards an increased health awareness in the community. Results: A
total of 5026 people who downloaded the app during the study window, among
those 1545 were active users. Our study shows that 3.4 times more females
engaged with the App in Hindi as compared to males, the relevance of
AI-filtered news content doubled within 45 days of continuous machine learning,
and the prudence of integrated AI chatbot Satya increased thus proving the
usefulness of an mHealth platform to mitigate health misinformation.

Conclusion: We conclude that a multi-pronged machine learning application
delivering vernacular bite-sized audios and conversational AI is an effective
approach to mitigate health misinformation.
</p>
<a href="http://arxiv.org/abs/2003.07074" target="_blank">arXiv:2003.07074</a> [<a href="http://arxiv.org/pdf/2003.07074" target="_blank">pdf</a>]

<h2>Industrial Forecasting with Exponentially Smoothed Recurrent Neural Networks. (arXiv:2004.04717v2 [stat.ML] UPDATED)</h2>
<h3>Matthew F Dixon</h3>
<p>Time series modeling has entered an era of unprecedented growth in the size
and complexity of data which require new modeling approaches. While many new
general purpose machine learning approaches have emerged, they remain poorly
understand and irreconcilable with more traditional statistical modeling
approaches. We present a general class of exponential smoothed recurrent neural
networks (RNNs) which are well suited to modeling non-stationary dynamical
systems arising in industrial applications. In particular, we analyze their
capacity to characterize the non-linear partial autocorrelation structure of
time series and directly capture dynamic effects such as seasonality and
trends. Application of exponentially smoothed RNNs to forecasting electricity
load, weather data, and stock prices highlight the efficacy of exponential
smoothing of the hidden state for multi-step time series forecasting. The
results also suggest that popular, but more complicated neural network
architectures originally designed for speech processing, such as LSTMs and
GRUs, are likely over-engineered for industrial forecasting and light-weight
exponentially smoothed architectures, trained in a fraction of the time,
capture the salient features while being superior and more robust than simple
RNNs and ARIMA models. Additionally uncertainty quantification of the
exponential smoothed recurrent neural networks, provided by Bayesian
estimation, is shown to provide improved coverage.
</p>
<a href="http://arxiv.org/abs/2004.04717" target="_blank">arXiv:2004.04717</a> [<a href="http://arxiv.org/pdf/2004.04717" target="_blank">pdf</a>]

<h2>Neural Head Reenactment with Latent Pose Descriptors. (arXiv:2004.12000v2 [cs.CV] UPDATED)</h2>
<h3>Egor Burkov, Igor Pasechnik, Artur Grigorev, Victor Lempitsky</h3>
<p>We propose a neural head reenactment system, which is driven by a latent pose
representation and is capable of predicting the foreground segmentation
alongside the RGB image. The latent pose representation is learned as a part of
the entire reenactment system, and the learning process is based solely on
image reconstruction losses. We show that despite its simplicity, with a large
and diverse enough training dataset, such learning successfully decomposes pose
from identity. The resulting system can then reproduce mimics of the driving
person and, furthermore, can perform cross-person reenactment. Additionally, we
show that the learned descriptors are useful for other pose-related tasks, such
as keypoint prediction and pose-based retrieval.
</p>
<a href="http://arxiv.org/abs/2004.12000" target="_blank">arXiv:2004.12000</a> [<a href="http://arxiv.org/pdf/2004.12000" target="_blank">pdf</a>]

<h2>Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models. (arXiv:2004.14601v3 [cs.CL] UPDATED)</h2>
<h3>Isabel Papadimitriou, Dan Jurafsky</h3>
<p>We propose transfer learning as a method for analyzing the encoding of
grammatical structure in neural language models. We train LSTMs on
non-linguistic data and evaluate their performance on natural language to
assess which kinds of data induce generalizable structural features that LSTMs
can use for natural language. We find that training on non-linguistic data with
latent structure (MIDI music or Java code) improves test performance on natural
language, despite no overlap in surface form or vocabulary. To pinpoint the
kinds of abstract structure that models may be encoding to lead to this
improvement, we run similar experiments with two artificial parentheses
languages: one which has a hierarchical recursive structure, and a control
which has paired tokens but no recursion. Surprisingly, training a model on
either of these artificial languages leads to the same substantial gains when
testing on natural language. Further experiments on transfer between natural
languages controlling for vocabulary overlap show that zero-shot performance on
a test language is highly correlated with typological syntactic similarity to
the training language, suggesting that representations induced by pre-training
correspond to the cross-linguistic syntactic properties. Our results provide
insights into the ways that neural models represent abstract syntactic
structure, and also about the kind of structural inductive biases which allow
for natural language acquisition.
</p>
<a href="http://arxiv.org/abs/2004.14601" target="_blank">arXiv:2004.14601</a> [<a href="http://arxiv.org/pdf/2004.14601" target="_blank">pdf</a>]

<h2>Improved Noisy Student Training for Automatic Speech Recognition. (arXiv:2005.09629v2 [eess.AS] UPDATED)</h2>
<h3>Daniel S. Park, Yu Zhang, Ye Jia, Wei Han, Chung-Cheng Chiu, Bo Li, Yonghui Wu, Quoc V. Le</h3>
<p>Recently, a semi-supervised learning method known as "noisy student training"
has been shown to improve image classification performance of deep networks
significantly. Noisy student training is an iterative self-training method that
leverages augmentation to improve network performance. In this work, we adapt
and improve noisy student training for automatic speech recognition, employing
(adaptive) SpecAugment as the augmentation method. We find effective methods to
filter, balance and augment the data generated in between self-training
iterations. By doing so, we are able to obtain word error rates (WERs)
4.2%/8.6% on the clean/noisy LibriSpeech test sets by only using the clean 100h
subset of LibriSpeech as the supervised set and the rest (860h) as the
unlabeled set. Furthermore, we are able to achieve WERs 1.7%/3.4% on the
clean/noisy LibriSpeech test sets by using the unlab-60k subset of LibriLight
as the unlabeled set for LibriSpeech 960h. We are thus able to improve upon the
previous state-of-the-art clean/noisy test WERs achieved on LibriSpeech 100h
(4.74%/12.20%) and LibriSpeech (1.9%/4.1%).
</p>
<a href="http://arxiv.org/abs/2005.09629" target="_blank">arXiv:2005.09629</a> [<a href="http://arxiv.org/pdf/2005.09629" target="_blank">pdf</a>]

<h2>SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning. (arXiv:2005.10296v2 [cs.CR] UPDATED)</h2>
<h3>Nishat Koti, Mahak Pancholi, Arpita Patra, Ajith Suresh</h3>
<p>Performing ML computation on private data while maintaining data privacy, aka
Privacy-preserving Machine Learning~(PPML), is an emergent field of research.
Recently, PPML has seen a visible shift towards the adoption of the Secure
Outsourced Computation~(SOC) paradigm due to the heavy computation that it
entails. In the SOC paradigm, computation is outsourced to a set of powerful
and specially equipped servers that provide service on a pay-per-use basis. In
this work, we propose SWIFT, a robust PPML framework for a range of ML
algorithms in SOC setting, that guarantees output delivery to the users
irrespective of any adversarial behaviour. Robustness, a highly desirable
feature, evokes user participation without the fear of denial of service.

At the heart of our framework lies a highly-efficient, maliciously-secure,
three-party computation (3PC) over rings that provides guaranteed output
delivery (GOD) in the honest-majority setting. To the best of our knowledge,
SWIFT is the first robust and efficient PPML framework in the 3PC setting.
SWIFT is as fast as (and is strictly better in some cases than) the best-known
3PC framework BLAZE (Patra et al. NDSS'20), which only achieves fairness. We
extend our 3PC framework for four parties (4PC). In this regime, SWIFT is as
fast as the best known fair 4PC framework Trident (Chaudhari et al. NDSS'20)
and twice faster than the best-known robust 4PC framework FLASH (Byali et al.
PETS'20).

We demonstrate our framework's practical relevance by benchmarking popular ML
algorithms such as Logistic Regression and deep Neural Networks such as VGG16
and LeNet, both over a 64-bit ring in a WAN setting. For deep NN, our results
testify to our claims that we provide improved security guarantee while
incurring no additional overhead for 3PC and obtaining 2x improvement for 4PC.
</p>
<a href="http://arxiv.org/abs/2005.10296" target="_blank">arXiv:2005.10296</a> [<a href="http://arxiv.org/pdf/2005.10296" target="_blank">pdf</a>]

<h2>Parameter-Efficient Person Re-identification in the 3D Space. (arXiv:2006.04569v2 [cs.CV] UPDATED)</h2>
<h3>Zhedong Zheng, Yi Yang</h3>
<p>People live in a 3D world. However, existing works on person
re-identification (re-id) mostly consider the semantic representation learning
in a 2D space, intrinsically limiting the understanding of people. In this
work, we address this limitation by exploring the prior knowledge of the 3D
body structure. Specifically, we project 2D images to a 3D space and introduce
a novel parameter-efficient Omni-scale Graph Network (OG-Net) to learn the
pedestrian representation directly from 3D point clouds. OG-Net effectively
exploits the local information provided by sparse 3D points and takes advantage
of the structure and appearance information in a coherent manner. With the help
of 3D geometry information, we can learn a new type of deep re-id feature free
from noisy variants, such as scale and viewpoint. To our knowledge, we are
among the first attempts to conduct person re-identification in the 3D space.
We demonstrate through extensive experiments that the proposed method (1) eases
the matching difficulty in the traditional 2D space, (2) exploits the
complementary information of 2D appearance and 3D structure, (3) achieves
competitive results with limited parameters on four large-scale person re-id
datasets, and (4) has good scalability to unseen datasets.
</p>
<a href="http://arxiv.org/abs/2006.04569" target="_blank">arXiv:2006.04569</a> [<a href="http://arxiv.org/pdf/2006.04569" target="_blank">pdf</a>]

<h2>Picket: Guarding Against Corrupted Data in Tabular Data during Learning and Inference. (arXiv:2006.04730v2 [cs.LG] UPDATED)</h2>
<h3>Zifan Liu, Zhechun Zhou, Theodoros Rekatsinas</h3>
<p>Data corruption is an impediment to modern machine learning deployments.
Corrupted data can severely bias the learned model and can also lead to invalid
inferences. We present, Picket, a simple framework to safeguard against data
corruptions during both training and deployment of machine learning models over
tabular data. For the training stage, Picket identifies and removes corrupted
data points from the training data to avoid obtaining a biased model. For the
deployment stage, Picket flags, in an online manner, corrupted query points to
a trained machine learning model that due to noise will result in incorrect
predictions. To detect corrupted data, Picket uses a self-supervised deep
learning model for mixed-type tabular data, which we call PicketNet. To
minimize the burden of deployment, learning a PicketNet model does not require
any human-labeled data. Picket is designed as a plugin that can increase the
robustness of any machine learning pipeline. We evaluate Picket on a diverse
array of real-world data considering different corruption models that include
systematic and adversarial noise during both training and testing. We show that
Picket consistently safeguards against corrupted data during both training and
deployment of various models ranging from SVMs to neural networks, beating a
diverse array of competing methods that span from data quality validation
models to robust outlier-detection models.
</p>
<a href="http://arxiv.org/abs/2006.04730" target="_blank">arXiv:2006.04730</a> [<a href="http://arxiv.org/pdf/2006.04730" target="_blank">pdf</a>]

<h2>Improving GAN Training with Probability Ratio Clipping and Sample Reweighting. (arXiv:2006.06900v4 [cs.LG] UPDATED)</h2>
<h3>Yue Wu, Pan Zhou, Andrew Gordon Wilson, Eric P. Xing, Zhiting Hu</h3>
<p>Despite success on a wide range of problems related to vision, generative
adversarial networks (GANs) often suffer from inferior performance due to
unstable training, especially for text generation. To solve this issue, we
propose a new variational GAN training framework which enjoys superior training
stability. Our approach is inspired by a connection of GANs and reinforcement
learning under a variational perspective. The connection leads to (1)
probability ratio clipping that regularizes generator training to prevent
excessively large updates, and (2) a sample re-weighting mechanism that
improves discriminator training by downplaying bad-quality fake samples.
Moreover, our variational GAN framework can provably overcome the training
issue in many GANs that an optimal discriminator cannot provide any informative
gradient to training generator. By plugging the training approach in diverse
state-of-the-art GAN architectures, we obtain significantly improved
performance over a range of tasks, including text generation, text style
transfer, and image generation.
</p>
<a href="http://arxiv.org/abs/2006.06900" target="_blank">arXiv:2006.06900</a> [<a href="http://arxiv.org/pdf/2006.06900" target="_blank">pdf</a>]

<h2>Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs. (arXiv:2006.08040v2 [cs.LG] UPDATED)</h2>
<h3>Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang</h3>
<p>We develop a new approach to obtaining high probability regret bounds for
online learning with bandit feedback against an adaptive adversary. While
existing approaches all require carefully constructing optimistic and biased
loss estimators, our approach uses standard unbiased estimators and relies on a
simple increasing learning rate schedule, together with the help of
logarithmically homogeneous self-concordant barriers and a strengthened
Freedman's inequality.

Besides its simplicity, our approach enjoys several advantages. First, the
obtained high-probability regret bounds are data-dependent and could be much
smaller than the worst-case bounds, which resolves an open problem asked by Neu
(2015). Second, resolving another open problem of Bartlett et al. (2008) and
Abernethy and Rakhlin (2009), our approach leads to the first general and
efficient algorithm with a high-probability regret bound for adversarial linear
bandits, while previous methods are either inefficient or only applicable to
specific action sets. Finally, our approach can also be applied to learning
adversarial Markov Decision Processes and provides the first algorithm with a
high-probability small-loss bound for this problem.
</p>
<a href="http://arxiv.org/abs/2006.08040" target="_blank">arXiv:2006.08040</a> [<a href="http://arxiv.org/pdf/2006.08040" target="_blank">pdf</a>]

<h2>Multi-Objective CNN Based Algorithm for SAR Despeckling. (arXiv:2006.09050v4 [eess.IV] UPDATED)</h2>
<h3>Sergio Vitale, Giampaolo Ferraioli, Vito Pascazio</h3>
<p>Deep learning (DL) in remote sensing has nowadays become an effective
operative tool: it is largely used in applications such as change detection,
image restoration, segmentation, detection and classification. With reference
to synthetic aperture radar (SAR) domain the application of DL techniques is
not straightforward due to non trivial interpretation of SAR images, specially
caused by the presence of speckle. Several deep learning solutions for SAR
despeckling have been proposed in the last few years. Most of these solutions
focus on the definition of different network architectures with similar cost
functions not involving SAR image properties. In this paper, a convolutional
neural network (CNN) with a multi-objective cost function taking care of
spatial and statistical properties of the SAR image is proposed. This is
achieved by the definition of a peculiar loss function obtained by the weighted
combination of three different terms. Each of this term is dedicated mainly to
one of the following SAR image characteristics: spatial details, speckle
statistical properties and strong scatterers identification. Their combination
allows to balance these effects. Moreover, a specifically designed architecture
is proposed for effectively extract distinctive features within the considered
framework. Experiments on simulated and real SAR images show the accuracy of
the proposed method compared to the State-of-Art despeckling algorithms, both
from quantitative and qualitative point of view. The importance of considering
such SAR properties in the cost function is crucial for a correct noise
rejection and details preservation in different underlined scenarios, such as
homogeneous, heterogeneous and extremely heterogeneous.
</p>
<a href="http://arxiv.org/abs/2006.09050" target="_blank">arXiv:2006.09050</a> [<a href="http://arxiv.org/pdf/2006.09050" target="_blank">pdf</a>]

<h2>Contrastive learning of global and local features for medical image segmentation with limited annotations. (arXiv:2006.10511v2 [cs.CV] UPDATED)</h2>
<h3>Krishna Chaitanya, Ertunc Erdil, Neerav Karani, Ender Konukoglu</h3>
<p>A key requirement for the success of supervised deep learning is a large
labeled dataset - a condition that is difficult to meet in medical image
analysis. Self-supervised learning (SSL) can help in this regard by providing a
strategy to pre-train a neural network with unlabeled data, followed by
fine-tuning for a downstream task with limited annotations. Contrastive
learning, a particular variant of SSL, is a powerful technique for learning
image-level representations. In this work, we propose strategies for extending
the contrastive learning framework for segmentation of volumetric medical
images in the semi-supervised setting with limited annotations, by leveraging
domain-specific and problem-specific cues. Specifically, we propose (1) novel
contrasting strategies that leverage structural similarity across volumetric
medical images (domain-specific cue) and (2) a local version of the contrastive
loss to learn distinctive representations of local regions that are useful for
per-pixel segmentation (problem-specific cue). We carry out an extensive
evaluation on three Magnetic Resonance Imaging (MRI) datasets. In the limited
annotation setting, the proposed method yields substantial improvements
compared to other self-supervision and semi-supervised learning techniques.
When combined with a simple data augmentation technique, the proposed method
reaches within 8% of benchmark performance using only two labeled MRI volumes
for training, corresponding to only 4% (for ACDC) of the training data used to
train the benchmark. The code is made public at
https://github.com/krishnabits001/domain_specific_cl.
</p>
<a href="http://arxiv.org/abs/2006.10511" target="_blank">arXiv:2006.10511</a> [<a href="http://arxiv.org/pdf/2006.10511" target="_blank">pdf</a>]

<h2>Discriminative Representation Loss (DRL): A More Efficient Approach Than Gradient Re-projection in continual learning. (arXiv:2006.11234v2 [stat.ML] UPDATED)</h2>
<h3>Yu Chen, Tom Diethe, Peter Flach</h3>
<p>The use of episodic memories in continual learning has been shown to be
effective in terms of alleviating catastrophic forgetting. In recent studies,
several gradient-based approaches have been developed to make more efficient
use of compact episodic memories, which constrain the gradients resulting from
new samples with those from memorized samples, aiming to reduce the diversity
of gradients from different tasks. In this paper, we reveal the relation
between diversity of gradients and discriminativeness of representations,
demonstrating connections between Deep Metric Learning and continual learning.
Based on these findings,we propose a simple yet highly efficient method -
Discriminative Representation Loss (DRL) - for continual learning. In
comparison with several state-of-the-art methods, DRL shows effectiveness with
low computational cost on multiple benchmark experiments in the setting of
online continual learning.
</p>
<a href="http://arxiv.org/abs/2006.11234" target="_blank">arXiv:2006.11234</a> [<a href="http://arxiv.org/pdf/2006.11234" target="_blank">pdf</a>]

<h2>Neural Cellular Automata Manifold. (arXiv:2006.12155v2 [cs.NE] UPDATED)</h2>
<h3>Alejandro Hernandez Ruiz, Armand Vilalta, Francesc Moreno-Noguer</h3>
<p>Very recently, the Neural Cellular Automata (NCA) has been proposed to
simulate the morphogenesis process with deep networks. NCA learns to grow an
image starting from a fixed single pixel. In this work, we show that the neural
network (NN) architecture of the NCA can be encapsulated in a larger NN. This
allows us to propose a new model that encodes a manifold of NCA, each of them
capable of generating a distinct image. Therefore, we are effectively learning
a representation space of CA, which shows generalization capabilities. We
accomplish this by introducing dynamic convolutions inside an Auto-Encoder
architecture, for the first time used to join two different sources of
information, the encoding and cell's environment information. In biological
terms, our approach would play the role of the transcription factors,
modulating the mapping of genes into specific proteins that drive cellular
differentiation, which occurs right before the morphogenesis. We thoroughly
evaluate our approach in a dataset of synthetic emojis and also in real images
of CIFAR-10. Our model introduces a general-purpose network, which can be used
in a broad range of problems beyond image generation.
</p>
<a href="http://arxiv.org/abs/2006.12155" target="_blank">arXiv:2006.12155</a> [<a href="http://arxiv.org/pdf/2006.12155" target="_blank">pdf</a>]

<h2>Understanding Deep Architectures with Reasoning Layer. (arXiv:2006.13401v2 [cs.LG] UPDATED)</h2>
<h3>Xinshi Chen, Yufei Zhang, Christoph Reisinger, Le Song</h3>
<p>Recently, there has been a surge of interest in combining deep learning
models with reasoning in order to handle more sophisticated learning tasks. In
many cases, a reasoning task can be solved by an iterative algorithm. This
algorithm is often unrolled, and used as a specialized layer in the deep
architecture, which can be trained end-to-end with other neural components.
Although such hybrid deep architectures have led to many empirical successes,
the theoretical foundation of such architectures, especially the interplay
between algorithm layers and other neural layers, remains largely unexplored.
In this paper, we take an initial step towards an understanding of such hybrid
deep architectures by showing that properties of the algorithm layers, such as
convergence, stability, and sensitivity, are intimately related to the
approximation and generalization abilities of the end-to-end model.
Furthermore, our analysis matches closely our experimental observations under
various conditions, suggesting that our theory can provide useful guidelines
for designing deep architectures with reasoning layers.
</p>
<a href="http://arxiv.org/abs/2006.13401" target="_blank">arXiv:2006.13401</a> [<a href="http://arxiv.org/pdf/2006.13401" target="_blank">pdf</a>]

<h2>A Theoretical Framework for Target Propagation. (arXiv:2006.14331v3 [cs.LG] UPDATED)</h2>
<h3>Alexander Meulemans, Francesco S. Carzaniga, Johan A.K. Suykens, Jo&#xe3;o Sacramento, Benjamin F. Grewe</h3>
<p>The success of deep learning, a brain-inspired form of AI, has sparked
interest in understanding how the brain could similarly learn across multiple
layers of neurons. However, the majority of biologically-plausible learning
algorithms have not yet reached the performance of backpropagation (BP), nor
are they built on strong theoretical foundations. Here, we analyze target
propagation (TP), a popular but not yet fully understood alternative to BP,
from the standpoint of mathematical optimization. Our theory shows that TP is
closely related to Gauss-Newton optimization and thus substantially differs
from BP. Furthermore, our analysis reveals a fundamental limitation of
difference target propagation (DTP), a well-known variant of TP, in the
realistic scenario of non-invertible neural networks. We provide a first
solution to this problem through a novel reconstruction loss that improves
feedback weight training, while simultaneously introducing architectural
flexibility by allowing for direct feedback connections from the output to each
hidden layer. Our theory is corroborated by experimental results that show
significant improvements in performance and in the alignment of forward weight
updates with loss gradients, compared to DTP.
</p>
<a href="http://arxiv.org/abs/2006.14331" target="_blank">arXiv:2006.14331</a> [<a href="http://arxiv.org/pdf/2006.14331" target="_blank">pdf</a>]

<h2>Self-Supervised MultiModal Versatile Networks. (arXiv:2006.16228v2 [cs.CV] UPDATED)</h2>
<h3>Jean-Baptiste Alayrac, Adri&#xe0; Recasens, Rosalia Schneider, Relja Arandjelovi&#x107;, Jason Ramapuram, Jeffrey De Fauw, Lucas Smaira, Sander Dieleman, Andrew Zisserman</h3>
<p>Videos are a rich source of multi-modal supervision. In this work, we learn
representations using self-supervision by leveraging three modalities naturally
present in videos: visual, audio and language streams. To this end, we
introduce the notion of a multimodal versatile network -- a network that can
ingest multiple modalities and whose representations enable downstream tasks in
multiple modalities. In particular, we explore how best to combine the
modalities, such that fine-grained representations of the visual and audio
modalities can be maintained, whilst also integrating text into a common
embedding. Driven by versatility, we also introduce a novel process of
deflation, so that the networks can be effortlessly applied to the visual data
in the form of video or a static image. We demonstrate how such networks
trained on large collections of unlabelled video data can be applied on video,
video-text, image and audio tasks. Equipped with these representations, we
obtain state-of-the-art performance on multiple challenging benchmarks
including UCF101, HMDB51, Kinetics600, AudioSet and ESC-50 when compared to
previous self-supervised work. Our models are publicly available.
</p>
<a href="http://arxiv.org/abs/2006.16228" target="_blank">arXiv:2006.16228</a> [<a href="http://arxiv.org/pdf/2006.16228" target="_blank">pdf</a>]

<h2>Efficient Algorithms for Device Placement of DNN Graph Operators. (arXiv:2006.16423v2 [cs.LG] UPDATED)</h2>
<h3>Jakub Tarnawski, Amar Phanishayee, Nikhil R. Devanur, Divya Mahajan, Fanny Nina Paravecino</h3>
<p>Modern machine learning workloads use large models, with complex structures,
that are very expensive to execute. The devices that execute complex models are
becoming increasingly heterogeneous as we see a flourishing of domain-specific
accelerators being offered as hardware accelerators in addition to CPUs. These
trends necessitate distributing the workload across multiple devices. Recent
work has shown that significant gains can be obtained with model parallelism,
i.e, partitioning a neural network's computational graph onto multiple devices.
In particular, this form of parallelism assumes a pipeline of devices, which is
fed a stream of samples and yields high throughput for training and inference
of DNNs. However, for such settings (large models and multiple heterogeneous
devices), we require automated algorithms and toolchains that can partition the
ML workload across devices. In this paper, we identify and isolate the
structured optimization problem at the core of device placement of DNN
operators, for both inference and training, especially in modern pipelined
settings. We then provide algorithms that solve this problem to optimality. We
demonstrate the applicability and efficiency of our approaches using several
contemporary DNN computation graphs.
</p>
<a href="http://arxiv.org/abs/2006.16423" target="_blank">arXiv:2006.16423</a> [<a href="http://arxiv.org/pdf/2006.16423" target="_blank">pdf</a>]

<h2>Hybrid deep learning architecture for general disruption prediction across tokamaks. (arXiv:2007.01401v3 [physics.plasm-ph] UPDATED)</h2>
<h3>J.X. Zhu, C. Rea, K. Montes, R.S. Granetz, R. Sweeney, R.A. Tinguely</h3>
<p>In this paper, we present a new deep learning disruption prediction algorithm
based on important findings from explorative data analysis which effectively
allows knowledge transfer from existing devices to new ones, thereby predicting
disruptions using very limited disruptive data from the new devices. The
explorative data analysis conducted via unsupervised clustering techniques
confirms that time-sequence data are much better separators of disruptive and
non-disruptive behavior than the instantaneous plasma state data with further
advantageous implications for a sequence-based predictor. Based on such
important findings, we have designed a new algorithm for multi-machine
disruption prediction that achieves high predictive accuracy on the C-Mod
(AUC=0.801), DIII-D (AUC=0.947) and EAST (AUC=0.973) tokamaks with limited
hyperparameter tuning. Through numerical experiments, we show that boosted
accuracy (AUC=0.959) is achieved on EAST predictions by including in the
training only 20 disruptive discharges, thousands of non-disruptive discharges
from EAST, and combining this with more than a thousand discharges from DIII-D
and C-Mod. The improvement of predictive ability obtained by combining
disruptive data from other devices is found to be true for all permutations of
the three devices. Furthermore, by comparing the predictive performance of each
individual numerical experiment, we find that non-disruptive data are
machine-specific while disruptive data from multiple devices contain
device-independent knowledge that can be used to inform predictions for
disruptions occurring on a new device.
</p>
<a href="http://arxiv.org/abs/2007.01401" target="_blank">arXiv:2007.01401</a> [<a href="http://arxiv.org/pdf/2007.01401" target="_blank">pdf</a>]

<h2>Multi-Agent Low-Dimensional Linear Bandits. (arXiv:2007.01442v2 [cs.LG] UPDATED)</h2>
<h3>Ronshee Chawla, Abishek Sankararaman, Sanjay Shakkottai</h3>
<p>We study a multi-agent stochastic linear bandit with side information,
parameterized by an unknown vector $\theta^* \in \mathbb{R}^d$. The side
information consists of a finite collection of low-dimensional subspaces, one
of which contains $\theta^*$. In our setting, agents can collaborate to reduce
regret by sending recommendations across a communication graph connecting them.
We present a novel decentralized algorithm, where agents communicate subspace
indices with each other, and each agent plays a projected variant of LinUCB on
the corresponding (low-dimensional) subspace. Through a combination of
collaborative best subspace identification, and per-agent learning of an
unknown vector in the corresponding low-dimensional subspace, we show that the
per-agent regret is much smaller than the case when agents do not communicate.
By collaborating to identify the subspace containing $\theta^*$, we show that
each agent effectively solves an easier instance of the linear bandit (compared
to the case of no collaboration), thus leading to the reduced per-agent regret.
We finally complement these results through simulations.
</p>
<a href="http://arxiv.org/abs/2007.01442" target="_blank">arXiv:2007.01442</a> [<a href="http://arxiv.org/pdf/2007.01442" target="_blank">pdf</a>]

<h2>A Humanoid Social Agent Embodying Physical Assistance Enhances Motor Training Experience. (arXiv:2007.05980v3 [cs.RO] UPDATED)</h2>
<h3>Giulia Belgiovine, Francesco Rea, Jacopo Zenzeri, Alessandra Sciutti</h3>
<p>Skilled motor behavior is critical in many human daily life activities and
professions. The design of robots that can effectively teach motor skills is an
important challenge in the robotics field. In particular, it is important to
understand whether the involvement in the training of a robot exhibiting social
behaviors impacts on the learning and the experience of the human pupils. In
this study, we addressed this question and we asked participants to learn a
complex task - stabilizing an inverted pendulum - by training with physical
assistance provided by a robotic manipulandum, the Wristbot. One group of
participants performed the training only using the Wristbot, whereas for
another group the same physical assistance was attributed to the humanoid robot
iCub, who played the role of an expert trainer and exhibited also some social
behaviors. The results obtained show that participants of both groups
effectively acquired the skill by leveraging the physical assistance, as they
significantly improved their stabilization performance even when the assistance
was removed. Moreover, learning in a context of interaction with a humanoid
robot assistant led subjects to increased motivation and more enjoyable
training experience, without negative effects on attention and perceived
effort. With the experimental approach presented in this study, it is possible
to investigate the relative contribution of haptic and social signals in the
context of motor learning mediated by human-robot interaction, with the aim of
developing effective robot trainers.
</p>
<a href="http://arxiv.org/abs/2007.05980" target="_blank">arXiv:2007.05980</a> [<a href="http://arxiv.org/pdf/2007.05980" target="_blank">pdf</a>]

<h2>COBE: Contextualized Object Embeddings from Narrated Instructional Video. (arXiv:2007.07306v2 [cs.CV] UPDATED)</h2>
<h3>Gedas Bertasius, Lorenzo Torresani</h3>
<p>Many objects in the real world undergo dramatic variations in visual
appearance. For example, a tomato may be red or green, sliced or chopped, fresh
or fried, liquid or solid. Training a single detector to accurately recognize
tomatoes in all these different states is challenging. On the other hand,
contextual cues (e.g., the presence of a knife, a cutting board, a strainer or
a pan) are often strongly indicative of how the object appears in the scene.
Recognizing such contextual cues is useful not only to improve the accuracy of
object detection or to determine the state of the object, but also to
understand its functional properties and to infer ongoing or upcoming
human-object interactions. A fully-supervised approach to recognizing object
states and their contexts in the real-world is unfortunately marred by the
long-tailed, open-ended distribution of the data, which would effectively
require massive amounts of annotations to capture the appearance of objects in
all their different forms. Instead of relying on manually-labeled data for this
task, we propose a new framework for learning Contextualized OBject Embeddings
(COBE) from automatically-transcribed narrations of instructional videos. We
leverage the semantic and compositional structure of language by training a
visual detector to predict a contextualized word embedding of the object and
its associated narration. This enables the learning of an object representation
where concepts relate according to a semantic language metric. Our experiments
show that our detector learns to predict a rich variety of contextual object
information, and that it is highly effective in the settings of few-shot and
zero-shot learning.
</p>
<a href="http://arxiv.org/abs/2007.07306" target="_blank">arXiv:2007.07306</a> [<a href="http://arxiv.org/pdf/2007.07306" target="_blank">pdf</a>]

<h2>Temporal Pointwise Convolutional Networks for Length of Stay Prediction in the Intensive Care Unit. (arXiv:2007.09483v3 [cs.LG] UPDATED)</h2>
<h3>Emma Rocheteau, Pietro Li&#xf2;, Stephanie Hyland</h3>
<p>The pressure of ever-increasing patient demand and budget restrictions make
hospital bed management a daily challenge for clinical staff. Most critical is
the efficient allocation of resource-heavy Intensive Care Unit (ICU) beds to
the patients who need life support. Central to solving this problem is knowing
for how long the current set of ICU patients are likely to stay in the unit. In
this work, we propose a new deep learning model based on the combination of
temporal convolution and pointwise (1x1) convolution, to solve the length of
stay prediction task on the eICU critical care dataset. The model - which we
refer to as Temporal Pointwise Convolution (TPC) - is specifically designed to
mitigate for common challenges with Electronic Health Records, such as
skewness, irregular sampling and missing data. In doing so, we have achieved
significant performance benefits of 18-51% (metric dependent) over the commonly
used Long-Short Term Memory (LSTM) network, and the multi-head self-attention
network known as the Transformer.
</p>
<a href="http://arxiv.org/abs/2007.09483" target="_blank">arXiv:2007.09483</a> [<a href="http://arxiv.org/pdf/2007.09483" target="_blank">pdf</a>]

<h2>Augmentation adversarial training for self-supervised speaker recognition. (arXiv:2007.12085v3 [cs.SD] UPDATED)</h2>
<h3>Jaesung Huh, Hee Soo Heo, Jingu Kang, Shinji Watanabe, Joon Son Chung</h3>
<p>The goal of this work is to train robust speaker recognition models without
speaker labels. Recent works on unsupervised speaker representations are based
on contrastive learning in which they encourage within-utterance embeddings to
be similar and across-utterance embeddings to be dissimilar. However, since the
within-utterance segments share the same acoustic characteristics, it is
difficult to separate the speaker information from the channel information. To
this end, we propose augmentation adversarial training strategy that trains the
network to be discriminative for the speaker information, while invariant to
the augmentation applied. Since the augmentation simulates the acoustic
characteristics, training the network to be invariant to augmentation also
encourages the network to be invariant to the channel information in general.
Extensive experiments on the VoxCeleb and VOiCES datasets show significant
improvements over previous works using self-supervision, and the performance of
our self-supervised models far exceed that of humans.
</p>
<a href="http://arxiv.org/abs/2007.12085" target="_blank">arXiv:2007.12085</a> [<a href="http://arxiv.org/pdf/2007.12085" target="_blank">pdf</a>]

<h2>Hallucinating Saliency Maps for Fine-Grained Image Classification for Limited Data Domains. (arXiv:2007.12562v2 [cs.CV] UPDATED)</h2>
<h3>Carola Figueroa-Flores, Bogdan Raducanu, David Berga, Joost van de Weijer</h3>
<p>Most of the saliency methods are evaluated on their ability to generate
saliency maps, and not on their functionality in a complete vision pipeline,
like for instance, image classification. In the current paper, we propose an
approach which does not require explicit saliency maps to improve image
classification, but they are learned implicitely, during the training of an
end-to-end image classification task. We show that our approach obtains similar
results as the case when the saliency maps are provided explicitely. Combining
RGB data with saliency maps represents a significant advantage for object
recognition, especially for the case when training data is limited. We validate
our method on several datasets for fine-grained classification tasks (Flowers,
Birds and Cars). In addition, we show that our saliency estimation method,
which is trained without any saliency groundtruth data, obtains competitive
results on real image saliency benchmark (Toronto), and outperforms deep
saliency models with synthetic images (SID4VAM).
</p>
<a href="http://arxiv.org/abs/2007.12562" target="_blank">arXiv:2007.12562</a> [<a href="http://arxiv.org/pdf/2007.12562" target="_blank">pdf</a>]

<h2>Bid Prediction in Repeated Auctions with Learning. (arXiv:2007.13193v2 [cs.GT] UPDATED)</h2>
<h3>Gali Noti, Vasilis Syrgkanis</h3>
<p>We consider the problem of bid prediction in repeated auctions and evaluate
the performance of econometric methods for learning agents using a dataset from
a mainstream sponsored search auction marketplace. Sponsored search auctions is
a billion dollar industry and the main source of revenue of several tech
giants. A critical problem in optimizing such marketplaces is understanding how
bidders will react to changes in the auction design. We propose the use of
no-regret based econometrics for bid prediction, modeling players as no-regret
learners with respect to a utility function, unknown to the analyst. We propose
new econometric approaches to simultaneously learn the parameters of a player's
utility and her learning rule, and apply these methods in a real-world dataset
from the BingAds sponsored search auction marketplace. We show that the
no-regret econometric methods perform comparable to state-of-the-art
time-series machine learning methods when there is no co-variate shift, but
significantly outperform machine learning methods when there is a co-variate
shift between the training and test periods. This portrays the importance of
using structural econometric approaches in predicting how players will respond
to changes in the market. Moreover, we show that among structural econometric
methods, approaches based on no-regret learning outperform more traditional,
equilibrium-based, econometric methods that assume that players continuously
best-respond to competition. Finally, we demonstrate how the prediction
performance of the no-regret learning algorithms can be further improved by
considering bidders who optimize a utility function with a visibility bias
component.
</p>
<a href="http://arxiv.org/abs/2007.13193" target="_blank">arXiv:2007.13193</a> [<a href="http://arxiv.org/pdf/2007.13193" target="_blank">pdf</a>]

<h2>Cross-Domain Facial Expression Recognition: A Unified Evaluation Benchmark and Adversarial Graph Learning. (arXiv:2008.00923v6 [cs.CV] UPDATED)</h2>
<h3>Tianshui Chen, Tao Pu, Yuan Xie, Hefeng Wu, Lingbo Liu, Liang Lin</h3>
<p>To address the problem of data inconsistencies among different facial
expression recognition (FER) datasets, many cross-domain FER methods (CD-FERs)
have been extensively devised in recent years. Although each declares to
achieve superior performance, fair comparisons are lacking due to the
inconsistent choices of the source/target datasets and feature extractors. In
this work, we first analyze the performance effect caused by these inconsistent
choices, and then re-implement some well-performing CD-FER and recently
published domain adaptation algorithms. We ensure that all these algorithms
adopt the same source datasets and feature extractors for fair CD-FER
evaluations. We find that most of the current leading algorithms use
adversarial learning to learn holistic domain-invariant features to mitigate
domain shifts. However, these algorithms ignore local features, which are more
transferable across different datasets and carry more detailed content for
fine-grained adaptation. To address these issues, we integrate graph
representation propagation with adversarial learning for cross-domain
holistic-local feature co-adaptation by developing a novel adversarial graph
representation adaptation (AGRA) framework. Specifically, it first builds two
graphs to correlate holistic and local regions within each domain and across
different domains, respectively. Then, it extracts holistic-local features from
the input image and uses learnable per-class statistical distributions to
initialize the corresponding graph nodes. Finally, two stacked graph
convolution networks (GCNs) are adopted to propagate holistic-local features
within each domain to explore their interaction and across different domains
for holistic-local feature co-adaptation. We conduct extensive and fair
evaluations on several popular benchmarks and show that the proposed AGRA
framework outperforms previous state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2008.00923" target="_blank">arXiv:2008.00923</a> [<a href="http://arxiv.org/pdf/2008.00923" target="_blank">pdf</a>]

<h2>Multi-Task Learning for Interpretable Weakly Labelled Sound Event Detection. (arXiv:2008.07085v2 [eess.AS] UPDATED)</h2>
<h3>Soham Deshmukh, Bhiksha Raj, Rita Singh</h3>
<p>Weakly Labelled learning has garnered lot of attention in recent years due to
its potential to scale Sound Event Detection (SED) and is formulated as
Multiple Instance Learning (MIL) problem. This paper proposes a Multi-Task
Learning (MTL) framework for learning from Weakly Labelled Audio data which
encompasses the traditional MIL setup. To show the utility of proposed
framework, we use the input TimeFrequency representation (T-F) reconstruction
as the auxiliary task. We show that the chosen auxiliary task de-noises
internal T-F representation and improves SED performance under noisy
recordings. Our second contribution is introducing two step Attention Pooling
mechanism. By having 2-steps in attention mechanism, the network retains better
T-F level information without compromising SED performance. The visualisation
of first step and second step attention weights helps in localising the
audio-event in T-F domain. For evaluating the proposed framework, we remix the
DCASE 2019 task 1 acoustic scene data with DCASE 2018 Task 2 sounds event data
under 0, 10 and 20 db SNR resulting in a multi-class Weakly labelled SED
problem. The proposed total framework outperforms existing benchmark models
over all SNRs, specifically 22.3 %, 12.8 %, 5.9 % improvement over benchmark
model on 0, 10 and 20 dB SNR respectively. We carry out ablation study to
determine the contribution of each auxiliary task and 2-step Attention Pooling
to the SED performance improvement. The code is publicly released
</p>
<a href="http://arxiv.org/abs/2008.07085" target="_blank">arXiv:2008.07085</a> [<a href="http://arxiv.org/pdf/2008.07085" target="_blank">pdf</a>]

<h2>Tactical Decision Making for Emergency Vehicles Based on A Combinational Learning Method. (arXiv:2009.04203v2 [cs.AI] UPDATED)</h2>
<h3>Haoyi Niu, Jianming Hu, Zheyu Cui, Yi Zhang</h3>
<p>Increasing the response time of emergency vehicles(EVs) could lead to an
immeasurable loss of property and life. On this account, tactical decision
making for EVs' microscopic control remains an indispensable issue to be
improved. In this paper, a rule-based avoiding strategy(AS) is devised, that
CVs in the prioritized zone ahead of EV should accelerate or change their lane
to avoid it. Besides, a novel DQN method with speed-adaptive compact state
space (SC-DQN) is put forward to fit in EVs' high-speed feature and generalize
in various road topologies. Afterward, the execution of AS feedback to the
input of SC-DQN so that they joint organically as a combinational method. The
following approach reveals that DRL could complement rule-based avoiding
strategy in generalization, and on the contrary, the rule-based avoiding
strategy could complement DRL in stability, and their combination could lead to
less response time, lower collision rate and smoother trajectory.
</p>
<a href="http://arxiv.org/abs/2009.04203" target="_blank">arXiv:2009.04203</a> [<a href="http://arxiv.org/pdf/2009.04203" target="_blank">pdf</a>]

<h2>Semantically Sensible Video Captioning (SSVC). (arXiv:2009.07335v2 [cs.CV] UPDATED)</h2>
<h3>Md. Mushfiqur Rahman, Thasin Abedin, Khondokar S. S. Prottoy, Ayana Moshruba, Fazlul Hasan Siddiqui</h3>
<p>Video captioning, i.e. the task of generating captions from video sequences
creates a bridge between the Natural Language Processing and Computer Vision
domains of computer science. Generating a semantically accurate description of
a video is an arduous task. Considering the complexity of the problem, the
results obtained in recent researches are quite outstanding. But still there is
plenty of scope for improvement. This paper addresses this scope and proposes a
novel solution. Most video captioning models comprise of two
sequential/recurrent layers - one as a video-to-context encoder and the other
as a context-to-caption decoder. This paper proposes a novel architecture, SSVC
(Semantically Sensible Video Captioning) which modifies the context generation
mechanism by using two novel approaches - "stacked attention" and "spatial hard
pull". For evaluating the proposed architecture, along with the BLEU scoring
metric for quantitative analysis, we have used a human evaluation metric for
qualitative analysis. This paper refers to this proposed human evaluation
metric as the Semantic Sensibility (SS) scoring metric. SS score overcomes the
shortcomings of common automated scoring metrics. This paper reports that the
use of the aforementioned novelties improves the performance of the
state-of-the-art architectures.
</p>
<a href="http://arxiv.org/abs/2009.07335" target="_blank">arXiv:2009.07335</a> [<a href="http://arxiv.org/pdf/2009.07335" target="_blank">pdf</a>]

<h2>Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics. (arXiv:2009.12576v2 [cs.LG] UPDATED)</h2>
<h3>Minhae Kwon, Saurabh Daptardar, Paul Schrater, Xaq Pitkow</h3>
<p>A fundamental question in neuroscience is how the brain creates an internal
model of the world to guide actions using sequences of ambiguous sensory
information. This is naturally formulated as a reinforcement learning problem
under partial observations, where an agent must estimate relevant latent
variables in the world from its evidence, anticipate possible future states,
and choose actions that optimize total expected reward. This problem can be
solved by control theory, which allows us to find the optimal actions for a
given system dynamics and objective function. However, animals often appear to
behave suboptimally. Why? We hypothesize that animals have their own flawed
internal model of the world, and choose actions with the highest expected
subjective reward according to that flawed model. We describe this behavior as
rational but not optimal. The problem of Inverse Rational Control (IRC) aims to
identify which internal model would best explain an agent's actions. Our
contribution here generalizes past work on Inverse Rational Control which
solved this problem for discrete control in partially observable Markov
decision processes. Here we accommodate continuous nonlinear dynamics and
continuous actions, and impute sensory observations corrupted by unknown noise
that is private to the animal. We first build an optimal Bayesian agent that
learns an optimal policy generalized over the entire model space of dynamics
and subjective rewards using deep reinforcement learning. Crucially, this
allows us to compute a likelihood over models for experimentally observable
action trajectories acquired from a suboptimal agent. We then find the model
parameters that maximize the likelihood using gradient ascent.
</p>
<a href="http://arxiv.org/abs/2009.12576" target="_blank">arXiv:2009.12576</a> [<a href="http://arxiv.org/pdf/2009.12576" target="_blank">pdf</a>]

<h2>Bidirectional Representation Learning from Transformers using Multimodal Electronic Health Record Data to Predict Depression. (arXiv:2009.12656v2 [cs.LG] UPDATED)</h2>
<h3>Yiwen Meng, William Speier, Michael K. Ong, Corey W. Arnold</h3>
<p>Advancements in machine learning algorithms have had a beneficial impact on
representation learning, classification, and prediction models built using
electronic health record (EHR) data. Effort has been put both on increasing
models' overall performance as well as improving their interpretability,
particularly regarding the decision-making process. In this study, we present a
temporal deep learning model to perform bidirectional representation learning
on EHR sequences with a transformer architecture to predict future diagnosis of
depression. This model is able to aggregate five heterogenous and
high-dimensional data sources from the EHR and process them in a temporal
manner for chronic disease prediction at various prediction windows. We applied
the current trend of pretraining and fine-tuning on EHR data to outperform the
current state-of-the-art in chronic disease prediction, and to demonstrate the
underlying relation between EHR codes in the sequence. The model generated the
highest increases of precision-recall area under the curve (PRAUC) from 0.70 to
0.76 in depression prediction compared to the best baseline model. Furthermore,
the self-attention weights in each sequence quantitatively demonstrated the
inner relationship between various codes, which improved the model's
interpretability. These results demonstrate the model's ability to utilize
heterogeneous EHR data to predict depression while achieving high accuracy and
interpretability, which may facilitate constructing clinical decision support
systems in the future for chronic disease screening and early detection.
</p>
<a href="http://arxiv.org/abs/2009.12656" target="_blank">arXiv:2009.12656</a> [<a href="http://arxiv.org/pdf/2009.12656" target="_blank">pdf</a>]

<h2>Multi-label Classification of Common Bengali Handwritten Graphemes: Dataset and Challenge. (arXiv:2010.00170v2 [cs.CV] UPDATED)</h2>
<h3>Samiul Alam, Tahsin Reasat, Asif Shahriyar Sushmit, Sadi Mohammad Siddiquee, Fuad Rahman, Mahady Hasan, Ahmed Imtiaz Humayun</h3>
<p>Latin has historically led the state-of-the-art in handwritten optical
character recognition (OCR) research. Adapting existing systems from Latin to
alpha-syllabary languages is particularly challenging due to a sharp contrast
between their orthographies. The segmentation of graphical constituents
corresponding to characters becomes significantly hard due to a cursive writing
system and frequent use of diacritics in the alpha-syllabary family of
languages. We propose a labeling scheme based on graphemes (linguistic segments
of word formation) that makes segmentation inside alpha-syllabary words linear
and present the first dataset of Bengali handwritten graphemes that are
commonly used in an everyday context. The dataset is open-sourced as a part of
the BengaliAI Handwritten Grapheme Classification Challenge on Kaggle to
benchmark vision algorithms for multi-label grapheme classification. From
competition proceedings, we see that deep learning methods can generalize to a
large span of uncommon graphemes even when they are absent during training.
Dataset and starter codes at www.kaggle.com/c/bengaliai-cv19.
</p>
<a href="http://arxiv.org/abs/2010.00170" target="_blank">arXiv:2010.00170</a> [<a href="http://arxiv.org/pdf/2010.00170" target="_blank">pdf</a>]

<h2>Explainable Online Validation of Machine Learning Models for Practical Applications. (arXiv:2010.00821v2 [cs.LG] UPDATED)</h2>
<h3>Wolfgang Fuhl, Yao Rong, Thomas Motz, Michael Scheidt, Andreas Hartel, Andreas Koch, Enkelejda Kasneci</h3>
<p>We present a reformulation of the regression and classification, which aims
to validate the result of a machine learning algorithm. Our reformulation
simplifies the original problem and validates the result of the machine
learning algorithm using the training data. Since the validation of machine
learning algorithms must always be explainable, we perform our experiments with
the kNN algorithm as well as with an algorithm based on conditional
probabilities, which is proposed in this work. For the evaluation of our
approach, three publicly available data sets were used and three classification
and two regression problems were evaluated. The presented algorithm based on
conditional probabilities is also online capable and requires only a fraction
of memory compared to the kNN algorithm.
</p>
<a href="http://arxiv.org/abs/2010.00821" target="_blank">arXiv:2010.00821</a> [<a href="http://arxiv.org/pdf/2010.00821" target="_blank">pdf</a>]

<h2>Weight and Gradient Centralization in Deep Neural Networks. (arXiv:2010.00866v2 [cs.CV] UPDATED)</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>Batch normalization is currently the most widely used variant of internal
normalization for deep neural networks. Additional work has shown that the
normalization of weights and additional conditioning as well as the
normalization of gradients further improve the generalization. In this work, we
combine several of these methods and thereby increase the generalization of the
networks. The advantage of the newer methods compared to the batch
normalization is not only increased generalization, but also that these methods
only have to be applied during training and, therefore, do not influence the
running time during use. Link to CUDA code
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/
</p>
<a href="http://arxiv.org/abs/2010.00866" target="_blank">arXiv:2010.00866</a> [<a href="http://arxiv.org/pdf/2010.00866" target="_blank">pdf</a>]

<h2>Rotated Ring, Radial and Depth Wise Separable Radial Convolutions. (arXiv:2010.00873v2 [cs.CV] UPDATED)</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>Simple image rotations significantly reduce the accuracy of deep neural
networks. Moreover, training with all possible rotations increases the data
set, which also increases the training duration. In this work, we address
trainable rotation invariant convolutions as well as the construction of nets,
since fully connected layers can only be rotation invariant with a
one-dimensional input. On the one hand, we show that our approach is
rotationally invariant for different models and on different public data sets.
We also discuss the influence of purely rotational invariant features on
accuracy. The rotationally adaptive convolution models presented in this work
are more computationally intensive than normal convolution models. Therefore,
we also present a depth wise separable approach with radial convolution. Link
to CUDA code
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/
</p>
<a href="http://arxiv.org/abs/2010.00873" target="_blank">arXiv:2010.00873</a> [<a href="http://arxiv.org/pdf/2010.00873" target="_blank">pdf</a>]

<h2>CAPT: Contrastive Pre-Training for Learning Denoised Sequence Representations. (arXiv:2010.06351v4 [cs.CL] UPDATED)</h2>
<h3>Fuli Luo, Pengcheng Yang, Shicheng Li, Xuancheng Ren, Xu Sun</h3>
<p>Pre-trained self-supervised models such as BERT have achieved striking
success in learning sequence representations, especially for natural language
processing. These models typically corrupt the given sequences with certain
types of noise, such as masking, shuffling, or substitution, and then try to
recover the original input. However, such pre-training approaches are prone to
learning representations that are covariant with the noise, leading to the
discrepancy between the pre-training and fine-tuning stage. To remedy this, we
present ContrAstive Pre-Training (CAPT) to learn noise invariant sequence
representations. The proposed CAPT encourages the consistency between
representations of the original sequence and its corrupted version via
unsupervised instance-wise training signals. In this way, it not only
alleviates the pretrain-finetune discrepancy induced by the noise of
pre-training, but also aids the pre-trained model in better capturing global
semantics of the input via more effective sentence-level supervision. Different
from most prior work that focuses on a particular modality, comprehensive
empirical evidence on 11 natural language understanding and cross-modal tasks
illustrates that CAPT is applicable for both language and vision-language
tasks, and obtains surprisingly consistent improvement, including 0.6\%
absolute gain on GLUE benchmarks and 0.8\% absolute increment on
$\text{NLVR}^2$.
</p>
<a href="http://arxiv.org/abs/2010.06351" target="_blank">arXiv:2010.06351</a> [<a href="http://arxiv.org/pdf/2010.06351" target="_blank">pdf</a>]

<h2>Self-Imitation Learning in Sparse Reward Settings. (arXiv:2010.06962v2 [cs.LG] UPDATED)</h2>
<h3>Zhixin Chen, Mengxiang Lin</h3>
<p>The application of reinforcement learning (RL) in real-world is still limited
in the environments with sparse and delayed rewards. Self-imitation learning
(SIL) is developed as an auxiliary component of RL to relieve the problem by
encouraging the agents to imitate their historical best behaviors. In this
paper, we propose a practical SIL algorithm named Self-Imitation Learning with
Constant Reward (SILCR). Instead of requiring hand-defined immediate rewards
from environments, our algorithm assigns the immediate rewards at each timestep
with constant values according to their final episodic rewards. In this way,
even if the dense rewards from environments are unavailable, every action taken
by the agents would be guided properly. We demonstrate the effectiveness of our
method in some challenging MuJoCo locomotion tasks and the results show that
our method significantly outperforms the alternative methods in tasks with
delayed and sparse rewards. Even compared with alternatives with dense rewards
available, our method achieves competitive performance. The ablation
experiments also show the stability and reproducibility of our method.
</p>
<a href="http://arxiv.org/abs/2010.06962" target="_blank">arXiv:2010.06962</a> [<a href="http://arxiv.org/pdf/2010.06962" target="_blank">pdf</a>]

<h2>Generalizing Universal Adversarial Attacks Beyond Additive Perturbations. (arXiv:2010.07788v2 [cs.CV] UPDATED)</h2>
<h3>Yanghao Zhang, Wenjie Ruan, Fu Wang, Xiaowei Huang</h3>
<p>The previous study has shown that universal adversarial attacks can fool deep
neural networks over a large set of input images with a single human-invisible
perturbation. However, current methods for universal adversarial attacks are
based on additive perturbation, which cause misclassification when the
perturbation is directly added to the input images. In this paper, for the
first time, we show that a universal adversarial attack can also be achieved
via non-additive perturbation (e.g., spatial transformation). More importantly,
to unify both additive and non-additive perturbations, we propose a novel
unified yet flexible framework for universal adversarial attacks, called GUAP,
which is able to initiate attacks by additive perturbation, non-additive
perturbation, or the combination of both. Extensive experiments are conducted
on CIFAR-10 and ImageNet datasets with six deep neural network models including
GoogleLeNet, VGG16/19, ResNet101/152, and DenseNet121. The empirical
experiments demonstrate that GUAP can obtain up to 90.9% and 99.24% successful
attack rates on CIFAR-10 and ImageNet datasets, leading to over 15% and 19%
improvements respectively than current state-of-the-art universal adversarial
attacks. The code for reproducing the experiments in this paper is available at
https://github.com/TrustAI/GUAP.
</p>
<a href="http://arxiv.org/abs/2010.07788" target="_blank">arXiv:2010.07788</a> [<a href="http://arxiv.org/pdf/2010.07788" target="_blank">pdf</a>]

<h2>Taking A Closer Look at Synthesis: Fine-grained Attribute Analysis for Person Re-Identification. (arXiv:2010.08145v2 [cs.CV] UPDATED)</h2>
<h3>Suncheng Xiang, Yuzhuo Fu, Guanjie You, Ting Liu</h3>
<p>Person re-identification (re-ID) plays an important role in applications such
as public security and video surveillance. Recently, learning from synthetic
data, which benefits from the popularity of synthetic data engine, has achieved
remarkable performance. However, in pursuit of high accuracy, researchers in
the academic always focus on training with large-scale datasets at a high cost
of time and label expenses, while neglect to explore the potential of
performing efficient training from millions of synthetic data. To facilitate
development in this field, we reviewed the previously developed synthetic
dataset GPR and built an improved one (GPR+) with larger number of identities
and distinguished attributes. Based on it, we quantitatively analyze the
influence of dataset attribute on re-ID system. To our best knowledge, we are
among the first attempts to explicitly dissect person re-ID from the aspect of
attribute on synthetic dataset. This research helps us have a deeper
understanding of the fundamental problems in person re-ID, which also provides
useful insights for dataset building and future practical usage.
</p>
<a href="http://arxiv.org/abs/2010.08145" target="_blank">arXiv:2010.08145</a> [<a href="http://arxiv.org/pdf/2010.08145" target="_blank">pdf</a>]

<h2>Price of Fairness in Budget Division for Egalitarian Social Welfare. (arXiv:2010.09637v2 [cs.GT] UPDATED)</h2>
<h3>Zhongzheng Tang, Chenhao Wang, Mengqi Zhang</h3>
<p>We study a participatory budgeting problem of aggregating the preferences of
agents and dividing a budget over the projects. A budget division solution is a
probability distribution over the projects. The main purpose of our study
concerns the comparison between the system optimum solution and a fair
solution. We are interested in assessing the quality of fair solutions, i.e.,
in measuring the system efficiency loss under a fair allocation compared to the
one that maximizes (egalitarian) social welfare. This indicator is called the
price of fairness. We are also interested in the performance of several
aggregation rules. Asymptotically tight bounds are provided both for the price
of fairness and the efficiency guarantee of aggregation rules.
</p>
<a href="http://arxiv.org/abs/2010.09637" target="_blank">arXiv:2010.09637</a> [<a href="http://arxiv.org/pdf/2010.09637" target="_blank">pdf</a>]

<h2>Knowledge Graph Embedding with Atrous Convolution and Residual Learning. (arXiv:2010.12121v2 [cs.AI] UPDATED)</h2>
<h3>Feiliang Ren, Juchen Li, Huihui Zhang, Shilei Liu, Bochao Li, Ruicheng Ming, Yujia Bai</h3>
<p>Knowledge graph embedding is an important task and it will benefit lots of
downstream applications. Currently, deep neural networks based methods achieve
state-of-the-art performance. However, most of these existing methods are very
complex and need much time for training and inference. To address this issue,
we propose a simple but effective atrous convolution based knowledge graph
embedding method. Compared with existing state-of-the-art methods, our method
has following main characteristics. First, it effectively increases feature
interactions by using atrous convolutions. Second, to address the original
information forgotten issue and vanishing/exploding gradient issue, it uses the
residual learning method. Third, it has simpler structure but much higher
parameter efficiency. We evaluate our method on six benchmark datasets with
different evaluation metrics. Extensive experiments show that our model is very
effective. On these diverse datasets, it achieves better results than the
compared state-of-the-art methods on most of evaluation metrics. The source
codes of our model could be found at https://github.com/neukg/AcrE.
</p>
<a href="http://arxiv.org/abs/2010.12121" target="_blank">arXiv:2010.12121</a> [<a href="http://arxiv.org/pdf/2010.12121" target="_blank">pdf</a>]

<h2>Multi-task Supervised Learning via Cross-learning. (arXiv:2010.12993v2 [cs.LG] UPDATED)</h2>
<h3>Juan Cervino, Juan Andres Bazerque, Miguel Calvo-Fullana, Alejandro Ribeiro</h3>
<p>In this paper we consider a problem known as multi-task learning, consisting
of fitting a set of classifier or regression functions intended for solving
different tasks. In our novel formulation, we couple the parameters of these
functions, so that they learn in their task specific domains while staying
close to each other. This facilitates cross-fertilization in which data
collected across different domains help improving the learning performance at
each other task. First, we present a simplified case in which the goal is to
estimate the means of two Gaussian variables, for the purpose of gaining some
insights on the advantage of the proposed cross-learning strategy. Then we
provide a stochastic projected gradient algorithm to perform cross-learning
over a generic loss function. If the number of parameters is large, then the
projection step becomes computationally expensive. To avoid this situation, we
derive a primal-dual algorithm that exploits the structure of the dual problem,
achieving a formulation whose complexity only depends on the number of tasks.
Preliminary numerical experiments for image classification by neural networks
trained on a dataset divided in different domains corroborate that the
cross-learned function outperforms both the task-specific and the consensus
approaches.
</p>
<a href="http://arxiv.org/abs/2010.12993" target="_blank">arXiv:2010.12993</a> [<a href="http://arxiv.org/pdf/2010.12993" target="_blank">pdf</a>]

<h2>Financial Data Analysis Using Expert Bayesian Framework For Bankruptcy Prediction. (arXiv:2010.13892v2 [q-fin.ST] UPDATED)</h2>
<h3>Amir Mukeri, Habibullah Shaikh, Dr. D.P. Gaikwad</h3>
<p>In recent years, bankruptcy forecasting has gained lot of attention from
researchers as well as practitioners in the field of financial risk management.
For bankruptcy prediction, various approaches proposed in the past and
currently in practice relies on accounting ratios and using statistical
modeling or machine learning methods. These models have had varying degrees of
successes. Models such as Linear Discriminant Analysis or Artificial Neural
Network employ discriminative classification techniques. They lack explicit
provision to include prior expert knowledge. In this paper, we propose another
route of generative modeling using Expert Bayesian framework. The biggest
advantage of the proposed framework is an explicit inclusion of expert judgment
in the modeling process. Also the proposed methodology provides a way to
quantify uncertainty in prediction. As a result the model built using Bayesian
framework is highly flexible, interpretable and intuitive in nature. The
proposed approach is well suited for highly regulated or safety critical
applications such as in finance or in medical diagnosis. In such cases accuracy
in the prediction is not the only concern for decision makers. Decision makers
and other stakeholders are also interested in uncertainty in the prediction as
well as interpretability of the model. We empirically demonstrate these
benefits of proposed framework on real world dataset using Stan, a
probabilistic programming language. We found that the proposed model is either
comparable or superior to the other existing methods. Also resulting model has
much less False Positive Rate compared to many existing state of the art
methods. The corresponding R code for the experiments is available at Github
repository.
</p>
<a href="http://arxiv.org/abs/2010.13892" target="_blank">arXiv:2010.13892</a> [<a href="http://arxiv.org/pdf/2010.13892" target="_blank">pdf</a>]

<h2>Classification Beats Regression: Counting of Cells from Greyscale Microscopic Images based on Annotation-free Training Samples. (arXiv:2010.14782v2 [eess.IV] UPDATED)</h2>
<h3>Xin Ding, Qiong Zhang, William J. Welch</h3>
<p>Modern methods often formulate the counting of cells from microscopic images
as a regression problem and more or less rely on expensive, manually annotated
training images (e.g., dot annotations indicating the centroids of cells or
segmentation masks identifying the contours of cells). This work proposes a
supervised learning framework based on classification-oriented convolutional
neural networks (CNNs) to count cells from greyscale microscopic images without
using annotated training images. In this framework, we formulate the cell
counting task as an image classification problem, where the cell counts are
taken as class labels. This formulation has its limitation when some cell
counts in the test stage do not appear in the training data. Moreover, the
ordinal relation among cell counts is not utilized. To deal with these
limitations, we propose a simple but effective data augmentation (DA) method to
synthesize images for the unseen cell counts. We also introduce an ensemble
method, which can not only moderate the influence of unseen cell counts but
also utilize the ordinal information to improve the prediction accuracy. This
framework outperforms many modern cell counting methods and won the data
analysis competition (Case Study 1: Counting Cells From Microscopic Images
https://ssc.ca/en/case-study/case-study-1-counting-cells-microscopic-images) of
the 47th Annual Meeting of the Statistical Society of Canada (SSC). Our code is
available at https://github.com/anno2020/CellCount_TinyBBBC005.
</p>
<a href="http://arxiv.org/abs/2010.14782" target="_blank">arXiv:2010.14782</a> [<a href="http://arxiv.org/pdf/2010.14782" target="_blank">pdf</a>]

<h2>Improving Perceptual Quality by Phone-Fortified Perceptual Loss for Speech Enhancement. (arXiv:2010.15174v2 [cs.SD] UPDATED)</h2>
<h3>Tsun-An Hsieh, Cheng Yu, Szu-Wei Fu, Xugang Lu, Yu Tsao</h3>
<p>Speech enhancement (SE) aims to improve speech quality and intelligibility,
which are both related to a smooth transition in speech segments that may carry
linguistic information, e.g. phones and syllables. In this study, we took
phonetic characteristics into account in the SE training process. Hence, we
designed a phone-fortified perceptual (PFP) loss, and the training of our SE
model was guided by PFP loss. In PFP loss, phonetic characteristics are
extracted by wav2vec, an unsupervised learning model based on the contrastive
predictive coding (CPC) criterion. Different from previous deep-feature-based
approaches, the proposed approach explicitly uses the phonetic information in
the deep feature extraction process to guide the SE model training. To test the
proposed approach, we first confirmed that the wav2vec representations carried
clear phonetic information using a t-distributed stochastic neighbor embedding
(t-SNE) analysis. Next, we observed that the proposed PFP loss was more
strongly correlated with the perceptual evaluation metrics than point-wise and
signal-level losses, thus achieving higher scores for standardized quality and
intelligibility evaluation metrics in the Voice Bank-DEMAND dataset.
</p>
<a href="http://arxiv.org/abs/2010.15174" target="_blank">arXiv:2010.15174</a> [<a href="http://arxiv.org/pdf/2010.15174" target="_blank">pdf</a>]

<h2>Representation learning for improved interpretability and classification accuracy of clinical factors from EEG. (arXiv:2010.15274v2 [cs.LG] UPDATED)</h2>
<h3>Garrett Honke, Irina Higgins, Nina Thigpen, Vladimir Miskovic, Katie Link, Pramod Gupta, Julia Klawohn, Greg Hajcak</h3>
<p>Despite extensive standardization, diagnostic interviews for mental health
disorders encompass substantial subjective judgment. Previous studies have
demonstrated that EEG-based neural measures can function as reliable objective
correlates of depression, or even predictors of depression and its course.
However, their clinical utility has not been fully realized because of 1) the
lack of automated ways to deal with the inherent noise associated with EEG data
at scale, and 2) the lack of knowledge of which aspects of the EEG signal may
be markers of a clinical disorder. Here we adapt an unsupervised pipeline from
the recent deep representation learning literature to address these problems by
1) learning a disentangled representation using $\beta$-VAE to denoise the
signal, and 2) extracting interpretable features associated with a sparse set
of clinical labels using a Symbol-Concept Association Network (SCAN). We
demonstrate that our method is able to outperform the canonical hand-engineered
baseline classification method on a number of factors, including participant
age and depression diagnosis. Furthermore, our method recovers a representation
that can be used to automatically extract denoised Event Related Potentials
(ERPs) from novel, single EEG trajectories, and supports fast supervised
re-mapping to various clinical labels, allowing clinicians to re-use a single
EEG representation regardless of updates to the standardized diagnostic system.
Finally, single factors of the learned disentangled representations often
correspond to meaningful markers of clinical factors, as automatically detected
by SCAN, allowing for human interpretability and post-hoc expert analysis of
the recommendations made by the model.
</p>
<a href="http://arxiv.org/abs/2010.15274" target="_blank">arXiv:2010.15274</a> [<a href="http://arxiv.org/pdf/2010.15274" target="_blank">pdf</a>]

<h2>Detection of asteroid trails in Hubble Space Telescope images using Deep Learning. (arXiv:2010.15425v2 [astro-ph.IM] UPDATED)</h2>
<h3>Andrei A. Parfeni, Laurentiu I. Caramete, Andreea M. Dobre, Nguyen Tran Bach</h3>
<p>We present an application of Deep Learning for the image recognition of
asteroid trails in single-exposure photos taken by the Hubble Space Telescope.
Using algorithms based on multi-layered deep Convolutional Neural Networks, we
report accuracies of above 80% on the validation set. Our project was motivated
by the Hubble Asteroid Hunter project on Zooniverse, which focused on
identifying these objects in order to localize and better characterize them. We
aim to demonstrate that Machine Learning techniques can be very useful in
trying to solve problems that are closely related to Astronomy and
Astrophysics, but that they are still not developed enough for very specific
tasks.
</p>
<a href="http://arxiv.org/abs/2010.15425" target="_blank">arXiv:2010.15425</a> [<a href="http://arxiv.org/pdf/2010.15425" target="_blank">pdf</a>]

<h2>"What, not how": Solving an under-actuated insertion task from scratch. (arXiv:2010.15492v2 [cs.RO] UPDATED)</h2>
<h3>Giulia Vezzani, Michael Neunert, Markus Wulfmeier, Rae Jeong, Thomas Lampe, Noah Siegel, Roland Hafner, Abbas Abdolmaleki, Martin Riedmiller, Francesco Nori</h3>
<p>Robot manipulation requires a complex set of skills that need to be carefully
combined and coordinated to solve a task. Yet, most ReinforcementLearning (RL)
approaches in robotics study tasks which actually consist only of a single
manipulation skill, such as grasping an object or inserting a pre-grasped
object. As a result the skill ('how' to solve the task) but not the actual goal
of a complete manipulation ('what' to solve) is specified. In contrast, we
study a complex manipulation goal that requires an agent to learn and combine
diverse manipulation skills. We propose a challenging, highly under-actuated
peg-in-hole task with a free, rotational asymmetrical peg, requiring a broad
range of manipulation skills. While correct peg (re-)orientation is a
requirement for successful insertion, there is no reward associated with it.
Hence an agent needs to understand this pre-condition and learn the skill to
fulfil it. The final insertion reward is sparse, allowing freedom in the
solution and leading to complex emerging behaviour not envisioned during the
task design. We tackle the problem in a multi-task RL framework using Scheduled
Auxiliary Control (SAC-X) combined with Regularized Hierarchical Policy
Optimization (RHPO) which successfully solves the task in simulation and from
scratch on a single robot where data is severely limited.
</p>
<a href="http://arxiv.org/abs/2010.15492" target="_blank">arXiv:2010.15492</a> [<a href="http://arxiv.org/pdf/2010.15492" target="_blank">pdf</a>]

<h2>Explainable Automated Coding of Clinical Notes using Hierarchical Label-wise Attention Networks and Label Embedding Initialisation. (arXiv:2010.15728v2 [cs.CL] UPDATED)</h2>
<h3>Hang Dong, V&#xed;ctor Su&#xe1;rez-Paniagua, William Whiteley, Honghan Wu</h3>
<p>Diagnostic or procedural coding of clinical notes aims to derive a coded
summary of disease-related information about patients. Such coding is usually
done manually in hospitals but could potentially be automated to improve the
efficiency and accuracy of medical coding. Recent studies on deep learning for
automated medical coding achieved promising performances. However, the
explainability of these models is usually poor, preventing them to be used
confidently in supporting clinical practice. Another limitation is that these
models mostly assume independence among labels, ignoring the complex
correlation among medical codes which can potentially be exploited to improve
the performance. We propose a Hierarchical Label-wise Attention Network (HLAN),
which aimed to interpret the model by quantifying importance (as attention
weights) of words and sentences related to each of the labels. Secondly, we
propose to enhance the major deep learning models with a label embedding (LE)
initialisation approach, which learns a dense, continuous vector representation
and then injects the representation into the final layers and the label-wise
attention layers in the models. We evaluated the methods using three settings
on the MIMIC-III discharge summaries: full codes, top-50 codes, and the UK NHS
COVID-19 shielding codes. Experiments were conducted to compare HLAN and LE
initialisation to the state-of-the-art neural network based methods. HLAN
achieved the best Micro-level AUC and $F_1$ on the top-50 code prediction and
comparable results on the NHS COVID-19 shielding code prediction to other
models. By highlighting the most salient words and sentences for each label,
HLAN showed more meaningful and comprehensive model interpretation compared to
its downgraded baselines and the CNN-based models. LE initialisation
consistently boosted most deep learning models for automated medical coding.
</p>
<a href="http://arxiv.org/abs/2010.15728" target="_blank">arXiv:2010.15728</a> [<a href="http://arxiv.org/pdf/2010.15728" target="_blank">pdf</a>]

<h2>Panoster: End-to-end Panoptic Segmentation of LiDAR Point Clouds. (arXiv:2010.15157v1 [cs.CV] CROSS LISTED)</h2>
<h3>Stefano Gasperini, Mohammad-Ali Nikouei Mahani, Alvaro Marcos-Ramiro, Nassir Navab, Federico Tombari</h3>
<p>Panoptic segmentation has recently unified semantic and instance
segmentation, previously addressed separately, thus taking a step further
towards creating more comprehensive and efficient perception systems. In this
paper, we present Panoster, a novel proposal-free panoptic segmentation method
for point clouds. Unlike previous approaches relying on several steps to group
pixels or points into objects, Panoster proposes a simplified framework
incorporating a learning-based clustering solution to identify instances. At
inference time, this acts as a class-agnostic semantic segmentation, allowing
Panoster to be fast, while outperforming prior methods in terms of accuracy.
Additionally, we showcase how our approach can be flexibly and effectively
applied on diverse existing semantic architectures to deliver panoptic
predictions.
</p>
<a href="http://arxiv.org/abs/2010.15157" target="_blank">arXiv:2010.15157</a> [<a href="http://arxiv.org/pdf/2010.15157" target="_blank">pdf</a>]

<h2>Modern strategies for time series regression. (arXiv:2010.15997v1 [stat.ME])</h2>
<h3>Stephanie Clark, Rob J Hyndman, Dan Pagendam, Louise M Ryan</h3>
<p>This paper discusses several modern approaches to regression analysis
involving time series data where some of the predictor variables are also
indexed by time. We discuss classical statistical approaches as well as methods
that have been proposed recently in the machine learning literature. The
approaches are compared and contrasted, and it will be seen that there are
advantages and disadvantages to most currently available approaches. There is
ample room for methodological developments in this area. The work is motivated
by an application involving the prediction of water levels as a function of
rainfall and other climate variables in an aquifer in eastern Australia.
</p>
<a href="http://arxiv.org/abs/2010.15997" target="_blank">arXiv:2010.15997</a> [<a href="http://arxiv.org/pdf/2010.15997" target="_blank">pdf</a>]

