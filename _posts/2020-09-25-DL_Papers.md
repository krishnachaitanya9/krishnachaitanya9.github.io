---
title: Latest Deep Learning Papers
date: 2021-01-01 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (261 Articles)</h1>
<h2>Deep Learning Towards Edge Computing: Neural Networks Straight from Compressed Data. (arXiv:2012.14426v1 [cs.CV])</h2>
<h3>Samuel Felipe dos Santos, Jurandy Almeida</h3>
<p>Due to the popularization and grow in computational power of mobile phones,
as well as advances in artificial intelligence, many intelligent applications
have been developed, meaningfully enriching people's life. For this reason,
there is a growing interest in the area of edge intelligence, that aims to push
the computation of data to the edges of the network, in order to make those
applications more efficient and secure. Many intelligent applications rely on
deep learning models, like convolutional neural networks (CNNs). Over the past
decade, they have achieved state-of-the-art performance in many computer vision
tasks. To increase the performance of these methods, the trend has been to use
increasingly deeper architectures and with more parameters, leading to a high
computational cost. Indeed, this is one of the main problems faced by deep
architectures, limiting their applicability in domains with limited
computational resources, like edge devices. To alleviate the computational
complexity, we propose a deep neural network capable of learning straight from
the relevant information pertaining to visual content readily available in the
compressed representation used for image and video storage and transmission.
The novelty of our approach is that it was designed to operate directly on
frequency domain data, learning with DCT coefficients rather than RGB pixels.
This enables to save high computational load in full decoding the data stream
and therefore greatly speed up the processing time, which has become a big
bottleneck of deep learning. We evaluated our network on two challenging tasks:
(1) image classification on the ImageNet dataset and (2) video classification
on the UCF-101 and HMDB-51 datasets. Our results demonstrate comparable
effectiveness to the state-of-the-art methods in terms of accuracy, with the
advantage of being more computationally efficient.
</p>
<a href="http://arxiv.org/abs/2012.14426" target="_blank">arXiv:2012.14426</a> [<a href="http://arxiv.org/pdf/2012.14426" target="_blank">pdf</a>]

<h2>LOCUS: A Multi-Sensor Lidar-Centric Solution for High-Precision Odometry and 3D Mapping in Real-Time. (arXiv:2012.14447v1 [cs.RO])</h2>
<h3>M. Palieri, B. Morrell, A Thakur, K. Ebadi, J. Nash, A. Chatterjee, C. Kanellakis, L. Carlone, C. Guaragnella, A. Agha-mohammadi</h3>
<p>A reliable odometry source is a prerequisite to enable complex autonomy
behaviour in next-generation robots operating in extreme environments. In this
work, we present a high-precision lidar odometry system to achieve robust and
real-time operation under challenging perceptual conditions. LOCUS (Lidar
Odometry for Consistent operation in Uncertain Settings), provides an accurate
multi-stage scan matching unit equipped with an health-aware sensor integration
module for seamless fusion of additional sensing modalities. We evaluate the
performance of the proposed system against state-of-the-art techniques in
perceptually challenging environments, and demonstrate top-class localization
accuracy along with substantial improvements in robustness to sensor failures.
We then demonstrate real-time performance of LOCUS on various types of robotic
mobility platforms involved in the autonomous exploration of the Satsop power
plant in Elma, WA where the proposed system was a key element of the CoSTAR
team's solution that won first place in the Urban Circuit of the DARPA
Subterranean Challenge.
</p>
<a href="http://arxiv.org/abs/2012.14447" target="_blank">arXiv:2012.14447</a> [<a href="http://arxiv.org/pdf/2012.14447" target="_blank">pdf</a>]

<h2>Straggler-Resilient Federated Learning: Leveraging the Interplay Between Statistical Accuracy and System Heterogeneity. (arXiv:2012.14453v1 [cs.LG])</h2>
<h3>Amirhossein Reisizadeh, Isidoros Tziotis, Hamed Hassani, Aryan Mokhtari, Ramtin Pedarsani</h3>
<p>Federated Learning is a novel paradigm that involves learning from data
samples distributed across a large network of clients while the data remains
local. It is, however, known that federated learning is prone to multiple
system challenges including system heterogeneity where clients have different
computation and communication capabilities. Such heterogeneity in clients'
computation speeds has a negative effect on the scalability of federated
learning algorithms and causes significant slow-down in their runtime due to
the existence of stragglers. In this paper, we propose a novel
straggler-resilient federated learning method that incorporates statistical
characteristics of the clients' data to adaptively select the clients in order
to speed up the learning procedure. The key idea of our algorithm is to start
the training procedure with faster nodes and gradually involve the slower nodes
in the model training once the statistical accuracy of the data corresponding
to the current participating nodes is reached. The proposed approach reduces
the overall runtime required to achieve the statistical accuracy of data of all
nodes, as the solution for each stage is close to the solution of the
subsequent stage with more samples and can be used as a warm-start. Our
theoretical results characterize the speedup gain in comparison to standard
federated benchmarks for strongly convex objectives, and our numerical
experiments also demonstrate significant speedups in wall-clock time of our
straggler-resilient method compared to federated learning benchmarks.
</p>
<a href="http://arxiv.org/abs/2012.14453" target="_blank">arXiv:2012.14453</a> [<a href="http://arxiv.org/pdf/2012.14453" target="_blank">pdf</a>]

<h2>Color Channel Perturbation Attacks for Fooling Convolutional Neural Networks and A Defense Against Such Attacks. (arXiv:2012.14456v1 [cs.CV])</h2>
<h3>Jayendra Kantipudi, Shiv Ram Dubey, Soumendu Chakraborty</h3>
<p>The Convolutional Neural Networks (CNNs) have emerged as a very powerful data
dependent hierarchical feature extraction method. It is widely used in several
computer vision problems. The CNNs learn the important visual features from
training samples automatically. It is observed that the network overfits the
training samples very easily. Several regularization methods have been proposed
to avoid the overfitting. In spite of this, the network is sensitive to the
color distribution within the images which is ignored by the existing
approaches. In this paper, we discover the color robustness problem of CNN by
proposing a Color Channel Perturbation (CCP) attack to fool the CNNs. In CCP
attack new images are generated with new channels created by combining the
original channels with the stochastic weights. Experiments were carried out
over widely used CIFAR10, Caltech256 and TinyImageNet datasets in the image
classification framework. The VGG, ResNet and DenseNet models are used to test
the impact of the proposed attack. It is observed that the performance of the
CNNs degrades drastically under the proposed CCP attack. Result show the effect
of the proposed simple CCP attack over the robustness of the CNN trained model.
The results are also compared with existing CNN fooling approaches to evaluate
the accuracy drop. We also propose a primary defense mechanism to this problem
by augmenting the training dataset with the proposed CCP attack. The
state-of-the-art performance using the proposed solution in terms of the CNN
robustness under CCP attack is observed in the experiments. The code is made
publicly available at
\url{https://github.com/jayendrakantipudi/Color-Channel-Perturbation-Attack}.
</p>
<a href="http://arxiv.org/abs/2012.14456" target="_blank">arXiv:2012.14456</a> [<a href="http://arxiv.org/pdf/2012.14456" target="_blank">pdf</a>]

<h2>Enhancing Handwritten Text Recognition with N-gram sequence decomposition and Multitask Learning. (arXiv:2012.14459v1 [cs.CV])</h2>
<h3>Vasiliki Tassopoulou, George Retsinas, Petros Maragos</h3>
<p>Current state-of-the-art approaches in the field of Handwritten Text
Recognition are predominately single task with unigram, character level target
units. In our work, we utilize a Multi-task Learning scheme, training the model
to perform decompositions of the target sequence with target units of different
granularity, from fine to coarse. We consider this method as a way to utilize
n-gram information, implicitly, in the training process, while the final
recognition is performed using only the unigram output. % in order to highlight
the difference of the internal Unigram decoding of such a multi-task approach
highlights the capability of the learned internal representations, imposed by
the different n-grams at the training step. We select n-grams as our target
units and we experiment from unigrams to fourgrams, namely subword level
granularities. These multiple decompositions are learned from the network with
task-specific CTC losses. Concerning network architectures, we propose two
alternatives, namely the Hierarchical and the Block Multi-task. Overall, our
proposed model, even though evaluated only on the unigram task, outperforms its
counterpart single-task by absolute 2.52\% WER and 1.02\% CER, in the greedy
decoding, without any computational overhead during inference, hinting towards
successfully imposing an implicit language model.
</p>
<a href="http://arxiv.org/abs/2012.14459" target="_blank">arXiv:2012.14459</a> [<a href="http://arxiv.org/pdf/2012.14459" target="_blank">pdf</a>]

<h2>Disentangled Planning and Control in Vision Based Robotics via Reward Machines. (arXiv:2012.14464v1 [cs.RO])</h2>
<h3>Alberto Camacho, Jacob Varley, Deepali Jain, Atil Iscen, Dmitry Kalashnikov</h3>
<p>In this work we augment a Deep Q-Learning agent with a Reward Machine (DQRM)
to increase speed of learning vision-based policies for robot tasks, and
overcome some of the limitations of DQN that prevent it from converging to
good-quality policies. A reward machine (RM) is a finite state machine that
decomposes a task into a discrete planning graph and equips the agent with a
reward function to guide it toward task completion. The reward machine can be
used for both reward shaping, and informing the policy what abstract state it
is currently at. An abstract state is a high level simplification of the
current state, defined in terms of task relevant features. These two
supervisory signals of reward shaping and knowledge of current abstract state
coming from the reward machine complement each other and can both be used to
improve policy performance as demonstrated on several vision based robotic pick
and place tasks. Particularly for vision based robotics applications, it is
often easier to build a reward machine than to try and get a policy to learn
the task without this structure.
</p>
<a href="http://arxiv.org/abs/2012.14464" target="_blank">arXiv:2012.14464</a> [<a href="http://arxiv.org/pdf/2012.14464" target="_blank">pdf</a>]

<h2>Classification of Pathological and Normal Gait: A Survey. (arXiv:2012.14465v1 [cs.LG])</h2>
<h3>Ryan C. Saxe, Samantha Kappagoda, David K.A. Mordecai</h3>
<p>Gait recognition is a term commonly referred to as an identification problem
within the Computer Science field. There are a variety of methods and models
capable of identifying an individual based on their pattern of ambulatory
locomotion. By surveying the current literature on gait recognition, this paper
seeks to identify appropriate metrics, devices, and algorithms for collecting
and analyzing data regarding patterns and modes of ambulatory movement across
individuals. Furthermore, this survey seeks to motivate interest in a broader
scope of longitudinal analysis regarding the perturbations in gait across
states (i.e. physiological, emotive, and/or cognitive states). More broadly,
inferences to normal versus pathological gait patterns can be attributed, based
on both longitudinal and non-longitudinal forms of classification. This may
indicate promising research directions and experimental designs, such as
creating algorithmic metrics for the quantification of fatigue, or models for
forecasting episodic disorders. Furthermore, in conjunction with other
measurements of physiological and environmental conditions, pathological gait
classification might be applicable to inference for syndromic surveillance of
infectious disease states or cognitive impairment.
</p>
<a href="http://arxiv.org/abs/2012.14465" target="_blank">arXiv:2012.14465</a> [<a href="http://arxiv.org/pdf/2012.14465" target="_blank">pdf</a>]

<h2>Paraconsistent Foundations for Probabilistic Reasoning, Programming and Concept Formation. (arXiv:2012.14474v1 [cs.AI])</h2>
<h3>Ben Goertzel</h3>
<p>It is argued that 4-valued paraconsistent logic can serve as a conceptual,
mathematical and practical foundation for highly AI-relevant forms of
probabilistic logic and probabilistic programming and concept formation.

First it is shown that appropriate averaging of 4-valued Constructible
Duality (CD) logic truth values across possible situations yields PLN
(Probabilistic Logic Networks) strength-and-confidence truth values. Then
variations on the Curry-Howard correspondence are used to map these
paraconsistent and probabilistic logics into probabilistic types suitable for
use within dependent type based programming languages.

Zach Weber's paraconsistent analysis of the sorites paradox is extended to
form a paraconsistent / probabilistic / fuzzy analysis of concept boundaries;
and a paraconsistent version of concept formation via Formal Concept Analysis
is presented, building on a definition of fuzzy property-value degrees in terms
of relative entropy on paraconsistent probability distributions.

These general points are fleshed out via reference to the realization of
probabilistic reasoning and programming and concept formation in the OpenCog
AGI framework which is centered on collaborative multi-algorithm updating of a
common knowledge metagraph.
</p>
<a href="http://arxiv.org/abs/2012.14474" target="_blank">arXiv:2012.14474</a> [<a href="http://arxiv.org/pdf/2012.14474" target="_blank">pdf</a>]

<h2>Detecting Anomalous line-items by Modeling the Legal Case Lifecycle. (arXiv:2012.14511v1 [cs.LG])</h2>
<h3>Valentino Constantinou, Mori Kabiri</h3>
<p>Anomaly detection continues to be the subject of research and development
efforts due to its wide-ranging applications and the value of detecting
anomalous patterns in a variety of use cases. While many anomalies may be
relatively benign, others may be more severe have the potential to
significantly impact to the business, user, or other involved parties. In
finance, detecting anomalous transactions can provide dramatic improvements to
financial audits, given that many audits continue to involve significant human
effort in review of accounting documents. In the case of the legal industry -
which is the focus of this work - detecting anomalies is important to both data
and legal integrity, and serves a secondary function in supporting downstream
analytics and machine-learning capabilities. In this work, we detail an
approach for detecting anomalous activities based their suitability in the
legal case's lifecycle (modeled using a set of case-level and invoice
line-item-level features). We illustrate our approach for invoice line-item
anomaly detection which works in the absence of labeled data, by utilizing a
combination of subject matter expertise and synthetic data generation for model
training. We characterize the method's performance using a set of well
understood, easily accessible model architectures. We demonstrate how this
process provides a path towards solving certain anomaly detection problems when
the characteristics of the anomalies are well known, and offer lessons learned
from applying our approach to detecting potentially anomalous line-items on
real-world data.
</p>
<a href="http://arxiv.org/abs/2012.14511" target="_blank">arXiv:2012.14511</a> [<a href="http://arxiv.org/pdf/2012.14511" target="_blank">pdf</a>]

<h2>TensorX: Extensible API for Neural Network Model Design and Deployment. (arXiv:2012.14539v1 [cs.LG])</h2>
<h3>Davide Nunes, Luis Antunes</h3>
<p>TensorX is a Python library for prototyping, design, and deployment of
complex neural network models in TensorFlow. A special emphasis is put on ease
of use, performance, and API consistency. It aims to make available high-level
components like neural network layers that are, in effect, stateful functions,
easy to compose and reuse. Its architecture allows for the expression of
patterns commonly found when building neural network models either on research
or industrial settings. Incorporating ideas from several other deep learning
libraries, it makes it easy to use components commonly found in
state-of-the-art models. The library design mixes functional dataflow
computation graphs with object-oriented neural network building blocks. TensorX
combines the dynamic nature of Python with the high-performance GPU-enabled
operations of TensorFlow.

This library has minimal core dependencies (TensorFlow and NumPy) and is
distributed under Apache License 2.0 licence, encouraging its use in both an
academic and commercial settings. Full documentation, source code, and binaries
can be found in https://tensorx.org/.
</p>
<a href="http://arxiv.org/abs/2012.14539" target="_blank">arXiv:2012.14539</a> [<a href="http://arxiv.org/pdf/2012.14539" target="_blank">pdf</a>]

<h2>Source Identification for Mixtures of Product Distributions. (arXiv:2012.14540v1 [cs.LG])</h2>
<h3>Spencer L. Gordon, Bijan Mazaheri, Yuval Rabani, Leonard J. Schulman</h3>
<p>We give an algorithm for source identification of a mixture of $k$ product
distributions on $n$ bits. This is a fundamental problem in machine learning
with many applications. Our algorithm identifies the source parameters of an
identifiable mixture, given, as input, approximate values of multilinear
moments (derived, for instance, from a sufficiently large sample), using
$2^{O(k^2)} n^{O(k)}$ arithmetic operations. Our result is the first explicit
bound on the computational complexity of source identification of such
mixtures. The running time improves previous results by Feldman, O'Donnell, and
Servedio (FOCS 2005) and Chen and Moitra (STOC 2019) that guaranteed only
learning the mixture (without parametric identification of the source). Our
analysis gives a quantitative version of a qualitative characterization of
identifiable sources that is due to Tahmasebi, Motahari, and Maddah-Ali (ISIT
2018).
</p>
<a href="http://arxiv.org/abs/2012.14540" target="_blank">arXiv:2012.14540</a> [<a href="http://arxiv.org/pdf/2012.14540" target="_blank">pdf</a>]

<h2>Visual Probing and Correction of Object Recognition Models with Interactive user feedback. (arXiv:2012.14544v1 [cs.CV])</h2>
<h3>Viny Saajan Victor, Pramod Vadiraja, Jan-Tobias Sohns, Heike Leitte</h3>
<p>With the advent of state-of-the-art machine learning and deep learning
technologies, several industries are moving towards the field. Applications of
such technologies are highly diverse ranging from natural language processing
to computer vision. Object recognition is one such area in the computer vision
domain. Although proven to perform with high accuracy, there are still areas
where such models can be improved. This is in-fact highly important in
real-world use cases like autonomous driving or cancer detection, that are
highly sensitive and expect such technologies to have almost no uncertainties.
In this paper, we attempt to visualise the uncertainties in object recognition
models and propose a correction process via user feedback. We further
demonstrate our approach on the data provided by the VAST 2020 Mini-Challenge
2.
</p>
<a href="http://arxiv.org/abs/2012.14544" target="_blank">arXiv:2012.14544</a> [<a href="http://arxiv.org/pdf/2012.14544" target="_blank">pdf</a>]

<h2>Gradient Descent Averaging and Primal-dual Averaging for Strongly Convex Optimization. (arXiv:2012.14558v1 [cs.LG])</h2>
<h3>Wei Tao, Wei Li, Zhisong Pan, Qing Tao</h3>
<p>Averaging scheme has attracted extensive attention in deep learning as well
as traditional machine learning. It achieves theoretically optimal convergence
and also improves the empirical model performance. However, there is still a
lack of sufficient convergence analysis for strongly convex optimization.
Typically, the convergence about the last iterate of gradient descent methods,
which is referred to as individual convergence, fails to attain its optimality
due to the existence of logarithmic factor. In order to remove this factor, we
first develop \textit{gradient descent averaging} (GDA), which is a general
projection-based dual averaging algorithm in the strongly convex setting. We
further present \textit{primal-dual averaging} for strongly convex cases
(SC-PDA), where primal and dual averaging schemes are simultaneously utilized.
We prove that GDA yields the optimal convergence rate in terms of output
averaging, while SC-PDA derives the optimal individual convergence. Several
experiments on SVMs and deep learning models validate the correctness of
theoretical analysis and effectiveness of algorithms.
</p>
<a href="http://arxiv.org/abs/2012.14558" target="_blank">arXiv:2012.14558</a> [<a href="http://arxiv.org/pdf/2012.14558" target="_blank">pdf</a>]

<h2>Random Planted Forest: a directly interpretable tree ensemble. (arXiv:2012.14563v1 [stat.ML])</h2>
<h3>Munir Hiabu, Enno Mammen, Joseph T. Meyer</h3>
<p>We introduce a novel interpretable and tree-based algorithm for prediction in
a regression setting in which each tree in a classical random forest is
replaced by a family of planted trees that grow simultaneously. The motivation
for our algorithm is to estimate the unknown regression function from a
functional ANOVA decomposition perspective, where each tree corresponds to a
function within that decomposition. Therefore, planted trees are limited in the
number of interaction terms. The maximal order of approximation in the ANOVA
decomposition can be specified or left unlimited. If a first order
approximation is chosen, the result is an additive model. In the other extreme
case, if the order of approximation is not limited, the resulting model puts no
restrictions on the form of the regression function. In a simulation study we
find encouraging prediction and visualisation properties of our random planted
forest method. We also develop theory for an idealised version of random
planted forests in the case of an underlying additive model. We show that in
the additive case, the idealised version achieves up to a logarithmic factor
asymptotically optimal one-dimensional convergence rates of order $n^{-2/5}$.
</p>
<a href="http://arxiv.org/abs/2012.14563" target="_blank">arXiv:2012.14563</a> [<a href="http://arxiv.org/pdf/2012.14563" target="_blank">pdf</a>]

<h2>MGML: Multi-Granularity Multi-Level Feature Ensemble Network for Remote Sensing Scene Classification. (arXiv:2012.14569v1 [cs.CV])</h2>
<h3>Qi Zhao, Shuchang Lyu, Yuewen Li, Yujing Ma, Lijiang Chen</h3>
<p>Remote sensing (RS) scene classification is a challenging task to predict
scene categories of RS images. RS images have two main characters: large
intra-class variance caused by large resolution variance and confusing
information from large geographic covering area. To ease the negative influence
from the above two characters. We propose a Multi-granularity Multi-Level
Feature Ensemble Network (MGML-FENet) to efficiently tackle RS scene
classification task in this paper. Specifically, we propose Multi-granularity
Multi-Level Feature Fusion Branch (MGML-FFB) to extract multi-granularity
features in different levels of network by channel-separate feature generator
(CS-FG). To avoid the interference from confusing information, we propose
Multi-granularity Multi-Level Feature Ensemble Module (MGML-FEM) which can
provide diverse predictions by full-channel feature generator (FC-FG). Compared
to previous methods, our proposed networks have ability to use structure
information and abundant fine-grained features. Furthermore, through ensemble
learning method, our proposed MGML-FENets can obtain more convincing final
predictions. Extensive classification experiments on multiple RS datasets (AID,
NWPU-RESISC45, UC-Merced and VGoogle) demonstrate that our proposed networks
achieve better performance than previous state-of-the-art (SOTA) networks. The
visualization analysis also shows the good interpretability of MGML-FENet.
</p>
<a href="http://arxiv.org/abs/2012.14569" target="_blank">arXiv:2012.14569</a> [<a href="http://arxiv.org/pdf/2012.14569" target="_blank">pdf</a>]

<h2>A Differentially Private Multi-Output Deep Generative Networks Approach For Activity Diary Synthesis. (arXiv:2012.14574v1 [cs.LG])</h2>
<h3>Godwin Badu-Marfo, Bilal Farooq, Zachary Patterson</h3>
<p>In this work, we develop a privacy-by-design generative model for
synthesizing the activity diary of the travel population using state-of-art
deep learning approaches. This proposed approach extends literature on
population synthesis by contributing novel deep learning to the development and
application of synthetic travel data while guaranteeing privacy protection for
members of the sample population on which the synthetic populations are based.
First, we show a complete de-generalization of activity diaries to simulate the
socioeconomic features and longitudinal sequences of geographically and
temporally explicit activities. Second, we introduce a differential privacy
approach to control the level of resolution disclosing the uniqueness of survey
participants. Finally, we experiment using the Generative Adversarial Networks
(GANs). We evaluate the statistical distributions, pairwise correlations and
measure the level of privacy guaranteed on simulated datasets for varying
noise. The results of the model show successes in simulating activity diaries
composed of multiple outputs including structured socio-economic features and
sequential tour activities in a differentially private manner.
</p>
<a href="http://arxiv.org/abs/2012.14574" target="_blank">arXiv:2012.14574</a> [<a href="http://arxiv.org/pdf/2012.14574" target="_blank">pdf</a>]

<h2>Dynamical Systems based Obstacle Avoidance with Workspace Constraint for Manipulators. (arXiv:2012.14576v1 [cs.RO])</h2>
<h3>Dake Zheng, Xinyu Wu, Jianxin Pang</h3>
<p>In this paper, based on Dynamical Systems (DS), we present an obstacle
avoidance method that take into account workspace constraint for serial
manipulators. Two modulation matrices that consider the effect of an obstacle
and the workspace of a manipulator are determined when the obstacle does not
intersect the workspace boundary and when the obstacle intersects the workspace
boundary respectively. Using the modulation matrices, an original DS is
deformed. The proposed approach can ensure that the trajectory of the
manipulator computed according to the deformed DS neither penetrate the
obstacle nor go out of the workspace. We validate the effectiveness of the
approach in the simulations and experiments on the left arm of the UBTECH
humanoid robot.
</p>
<a href="http://arxiv.org/abs/2012.14576" target="_blank">arXiv:2012.14576</a> [<a href="http://arxiv.org/pdf/2012.14576" target="_blank">pdf</a>]

<h2>Real-time Whole-body Obstacle Avoidance for 7-DOF Redundant Manipulators. (arXiv:2012.14578v1 [cs.RO])</h2>
<h3>Dake Zheng, Xinyu Wu, Jianxin Pang</h3>
<p>Mainly because of the heavy computational costs, the real-time whole-body
obstacle avoidance for the redundant manipulators has not been well
implemented. This paper presents an approach that can ensure that the
whole-body of a redundant manipulator can avoid moving obstacles in real-time
during the execution of a task. The manipulator is divided into end-effector
and non-end-effector portion. Based on dynamical systems (DS), the real-time
end-effector obstacle avoidance is obtained. Besides, the end-effector can
reach the given target. By using null-space velocity control, the real-time
non-endeffector obstacle avoidance is achieved. Finally, a controller is
designed to ensure the whole-body obstacle avoidance. We validate the
effectiveness of the method in the simulations and experiments on the 7-DOF arm
of the UBTECH humanoid robot.
</p>
<a href="http://arxiv.org/abs/2012.14578" target="_blank">arXiv:2012.14578</a> [<a href="http://arxiv.org/pdf/2012.14578" target="_blank">pdf</a>]

<h2>AU-Expression Knowledge Constrained Representation Learning for Facial Expression Recognition. (arXiv:2012.14587v1 [cs.CV])</h2>
<h3>Tao Pu, Tianshui Chen, Yuan Xie, Hefeng Wu, Liang Lin</h3>
<p>Recognizing human emotion/expressions automatically is quite an expected
ability for intelligent robotics, as it can promote better communication and
cooperation with humans. Current deep-learning-based algorithms may achieve
impressive performance in some lab-controlled environments, but they always
fail to recognize the expressions accurately for the uncontrolled in-the-wild
situation. Fortunately, facial action units (AU) describe subtle facial
behaviors, and they can help distinguish uncertain and ambiguous expressions.
In this work, we explore the correlations among the action units and facial
expressions, and devise an AU-Expression Knowledge Constrained Representation
Learning (AUE-CRL) framework to learn the AU representations without AU
annotations and adaptively use representations to facilitate facial expression
recognition. Specifically, it leverages AU-expression correlations to guide the
learning of the AU classifiers, and thus it can obtain AU representations
without incurring any AU annotations. Then, it introduces a knowledge-guided
attention mechanism that mines useful AU representations under the constraint
of AU-expression correlations. In this way, the framework can capture local
discriminative and complementary features to enhance facial representation for
facial expression recognition. We conduct experiments on the challenging
uncontrolled datasets to demonstrate the superiority of the proposed framework
over current state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.14587" target="_blank">arXiv:2012.14587</a> [<a href="http://arxiv.org/pdf/2012.14587" target="_blank">pdf</a>]

<h2>Sparse PCA via $l_{2,p}$-Norm Regularization for Unsupervised Feature Selection. (arXiv:2012.14595v1 [cs.LG])</h2>
<h3>Zhengxin Li, Feiping Nie, Jintang Bian, Xuelong Li</h3>
<p>In the field of data mining, how to deal with high-dimensional data is an
inevitable problem. Unsupervised feature selection has attracted more and more
attention because it does not rely on labels. The performance of spectral-based
unsupervised methods depends on the quality of constructed similarity matrix,
which is used to depict the intrinsic structure of data. However, real-world
data contain a large number of noise samples and features, making the
similarity matrix constructed by original data cannot be completely reliable.
Worse still, the size of similarity matrix expands rapidly as the number of
samples increases, making the computational cost increase significantly.
Inspired by principal component analysis, we propose a simple and efficient
unsupervised feature selection method, by combining reconstruction error with
$l_{2,p}$-norm regularization. The projection matrix, which is used for feature
selection, is learned by minimizing the reconstruction error under the sparse
constraint. Then, we present an efficient optimization algorithm to solve the
proposed unsupervised model, and analyse the convergence and computational
complexity of the algorithm theoretically. Finally, extensive experiments on
real-world data sets demonstrate the effectiveness of our proposed method.
</p>
<a href="http://arxiv.org/abs/2012.14595" target="_blank">arXiv:2012.14595</a> [<a href="http://arxiv.org/pdf/2012.14595" target="_blank">pdf</a>]

<h2>Hierarchical Representation via Message Propagation for Robust Model Fitting. (arXiv:2012.14597v1 [cs.CV])</h2>
<h3>Shuyuan Lin, Xing Wang, Guobao Xiao, Yan Yan, Hanzi Wang</h3>
<p>In this paper, we propose a novel hierarchical representation via message
propagation (HRMP) method for robust model fitting, which simultaneously takes
advantages of both the consensus analysis and the preference analysis to
estimate the parameters of multiple model instances from data corrupted by
outliers, for robust model fitting. Instead of analyzing the information of
each data point or each model hypothesis independently, we formulate the
consensus information and the preference information as a hierarchical
representation to alleviate the sensitivity to gross outliers. Specifically, we
firstly construct a hierarchical representation, which consists of a model
hypothesis layer and a data point layer. The model hypothesis layer is used to
remove insignificant model hypotheses and the data point layer is used to
remove gross outliers. Then, based on the hierarchical representation, we
propose an effective hierarchical message propagation (HMP) algorithm and an
improved affinity propagation (IAP) algorithm to prune insignificant vertices
and cluster the remaining data points, respectively. The proposed HRMP can not
only accurately estimate the number and parameters of multiple model instances,
but also handle multi-structural data contaminated with a large number of
outliers. Experimental results on both synthetic data and real images show that
the proposed HRMP significantly outperforms several state-of-the-art model
fitting methods in terms of fitting accuracy and speed.
</p>
<a href="http://arxiv.org/abs/2012.14597" target="_blank">arXiv:2012.14597</a> [<a href="http://arxiv.org/pdf/2012.14597" target="_blank">pdf</a>]

<h2>Emergent Symbols through Binding in External Memory. (arXiv:2012.14601v1 [cs.AI])</h2>
<h3>Taylor W. Webb, Ishan Sinha, Jonathan D. Cohen</h3>
<p>A key aspect of human intelligence is the ability to infer abstract rules
directly from high-dimensional sensory data, and to do so given only a limited
amount of training experience. Deep neural network algorithms have proven to be
a powerful tool for learning directly from high-dimensional data, but currently
lack this capacity for data-efficient induction of abstract rules, leading some
to argue that symbol-processing mechanisms will be necessary to account for
this capacity. In this work, we take a step toward bridging this gap by
introducing the Emergent Symbol Binding Network (ESBN), a recurrent network
augmented with an external memory that enables a form of variable-binding and
indirection. This binding mechanism allows symbol-like representations to
emerge through the learning process without the need to explicitly incorporate
symbol-processing machinery, enabling the ESBN to learn rules in a manner that
is abstracted away from the particular entities to which those rules apply.
Across a series of tasks, we show that this architecture displays nearly
perfect generalization of learned rules to novel entities given only a limited
number of training examples, and outperforms a number of other competitive
neural network architectures.
</p>
<a href="http://arxiv.org/abs/2012.14601" target="_blank">arXiv:2012.14601</a> [<a href="http://arxiv.org/pdf/2012.14601" target="_blank">pdf</a>]

<h2>An Efficient Generation Method based on Dynamic Curvature of the Reference Curve for Robust Trajectory Planning. (arXiv:2012.14617v1 [cs.RO])</h2>
<h3>Yuchen Sun, Dongchun Ren, Shiqi Lian, Mingyu Fan, Xiangyi Teng</h3>
<p>Trajectory planning is a fundamental task on various autonomous driving
platforms, such as social robotics and self-driving cars. Many trajectory
planning algorithms use a reference curve based Frenet frame with time to
reduce the planning dimension. However, there is a common implicit assumption
in classic trajectory planning approaches, which is that the generated
trajectory should follow the reference curve continuously. This assumption is
not always true in real applications and it might cause some undesired issues
in planning. One issue is that the projection of the planned trajectory onto
the reference curve maybe discontinuous. Then, some segments on the reference
curve are not the image of any part of the planned path. Another issue is that
the planned path might self-intersect when following a simple reference curve
continuously. The generated trajectories are unnatural and suboptimal ones when
these issues happen. In this paper, we firstly demonstrate these issues and
then introduce an efficient trajectory generation method which uses a new
transformation from the Cartesian frame to Frenet frames. Experimental results
on a simulated street scenario demonstrated the effectiveness of the proposed
method.
</p>
<a href="http://arxiv.org/abs/2012.14617" target="_blank">arXiv:2012.14617</a> [<a href="http://arxiv.org/pdf/2012.14617" target="_blank">pdf</a>]

<h2>FPCC-Net: Fast Point Cloud Clustering for Instance Segmentation. (arXiv:2012.14618v1 [cs.CV])</h2>
<h3>Yajun Xu, Shogo Arai, Diyi Liu, Fangzhou Lin, Kazuhiro Kosuge</h3>
<p>Instance segmentation is an important pre-processing task in numerous
real-world applications, such as robotics, autonomous vehicles, and
human-computer interaction. However, there has been little research on 3D point
cloud instance segmentation of bin-picking scenes in which multiple objects of
the same class are stacked together. Compared with the rapid development of
deep learning for two-dimensional (2D) image tasks, deep learning-based 3D
point cloud segmentation still has a lot of room for development. In such a
situation, distinguishing a large number of occluded objects of the same class
is a highly challenging problem. In a usual bin-picking scene, an object model
is known and the number of object type is one. Thus, the semantic information
can be ignored; instead, the focus is put on the segmentation of instances.
Based on this task requirement, we propose a network (FPCC-Net) that infers
feature centers of each instance and then clusters the remaining points to the
closest feature center in feature embedding space. FPCC-Net includes two
subnets, one for inferring the feature centers for clustering and the other for
describing features of each point. The proposed method is compared with
existing 3D point clouds and 2D segmentation methods in some bin-picking
scenes. It is shown that FPCC-Net outperforms SGPN by about 40\% average
precision (AP) and can process about 60,000 points in about 0.8[s]
</p>
<a href="http://arxiv.org/abs/2012.14618" target="_blank">arXiv:2012.14618</a> [<a href="http://arxiv.org/pdf/2012.14618" target="_blank">pdf</a>]

<h2>MS-GWNN:multi-scale graph wavelet neural network for breast cancer diagnosis. (arXiv:2012.14619v1 [cs.CV])</h2>
<h3>Mo Zhang, Quanzheng Li</h3>
<p>Breast cancer is one of the most common cancers in women worldwide, and early
detection can significantly reduce the mortality rate of breast cancer. It is
crucial to take multi-scale information of tissue structure into account in the
detection of breast cancer. And thus, it is the key to design an accurate
computer-aided detection (CAD) system to capture multi-scale contextual
features in a cancerous tissue. In this work, we present a novel graph
convolutional neural network for histopathological image classification of
breast cancer. The new method, named multi-scale graph wavelet neural network
(MS-GWNN), leverages the localization property of spectral graph wavelet to
perform multi-scale analysis. By aggregating features at different scales,
MS-GWNN can encode the multi-scale contextual interactions in the whole
pathological slide. Experimental results on two public datasets demonstrate the
superiority of the proposed method. Moreover, through ablation studies, we find
that multi-scale analysis has a significant impact on the accuracy of cancer
diagnosis.
</p>
<a href="http://arxiv.org/abs/2012.14619" target="_blank">arXiv:2012.14619</a> [<a href="http://arxiv.org/pdf/2012.14619" target="_blank">pdf</a>]

<h2>The VIP Gallery for Video Processing Education. (arXiv:2012.14625v1 [cs.CV])</h2>
<h3>Todd Goodall, Alan C. Bovik</h3>
<p>Digital video pervades daily life. Mobile video, digital TV, and digital
cinema are now ubiquitous, and as such, the field of Digital Video Processing
(DVP) has experienced tremendous growth. Digital video systems also permeate
scientific and engineering disciplines including but not limited to astronomy,
communications, surveillance, entertainment, video coding, computer vision, and
vision research. As a consequence, educational tools for DVP must cater to a
large and diverse base of students. Towards enhancing DVP education we have
created a carefully constructed gallery of educational tools that is designed
to complement a comprehensive corpus of online lectures by providing examples
of DVP on real-world content, along with a user-friendly interface that
organizes numerous key DVP topics ranging from analog video, to human visual
processing, to modern video codecs, etc. This demonstration gallery is
currently being used effectively in the graduate class ``Digital Video'' at the
University of Texas at Austin. Students receive enhanced access to concepts
through both learning theory from highly visual lectures and watching concrete
examples from the gallery, which captures the beauty of the underlying
principles of modern video processing. To better understand the educational
value of these tools, we conducted a pair of questionaire-based surveys to
assess student background, expectations, and outcomes. The survey results
support the teaching efficacy of this new didactic video toolset.
</p>
<a href="http://arxiv.org/abs/2012.14625" target="_blank">arXiv:2012.14625</a> [<a href="http://arxiv.org/pdf/2012.14625" target="_blank">pdf</a>]

<h2>TrustMAE: A Noise-Resilient Defect Classification Framework using Memory-Augmented Auto-Encoders with Trust Regions. (arXiv:2012.14629v1 [cs.CV])</h2>
<h3>Daniel Stanley Tan, Yi-Chun Chen, Trista Pei-Chun Chen, Wei-Chao Chen</h3>
<p>In this paper, we propose a framework called TrustMAE to address the problem
of product defect classification. Instead of relying on defective images that
are difficult to collect and laborious to label, our framework can accept
datasets with unlabeled images. Moreover, unlike most anomaly detection
methods, our approach is robust against noises, or defective images, in the
training dataset. Our framework uses a memory-augmented auto-encoder with a
sparse memory addressing scheme to avoid over-generalizing the auto-encoder,
and a novel trust-region memory updating scheme to keep the noises away from
the memory slots. The result is a framework that can reconstruct defect-free
images and identify the defective regions using a perceptual distance network.
When compared against various state-of-the-art baselines, our approach performs
competitively under noise-free MVTec datasets. More importantly, it remains
effective at a noise level up to 40% while significantly outperforming other
baselines.
</p>
<a href="http://arxiv.org/abs/2012.14629" target="_blank">arXiv:2012.14629</a> [<a href="http://arxiv.org/pdf/2012.14629" target="_blank">pdf</a>]

<h2>AILearn: An Adaptive Incremental Learning Model for Spoof Fingerprint Detection. (arXiv:2012.14639v1 [cs.LG])</h2>
<h3>Shivang Agarwal, Ajita Rattani, C. Ravindranath Chowdary</h3>
<p>Incremental learning enables the learner to accommodate new knowledge without
retraining the existing model. It is a challenging task which requires learning
from new data as well as preserving the knowledge extracted from the previously
accessed data. This challenge is known as the stability-plasticity dilemma. We
propose AILearn, a generic model for incremental learning which overcomes the
stability-plasticity dilemma by carefully integrating the ensemble of base
classifiers trained on new data with the current ensemble without retraining
the model from scratch using entire data. We demonstrate the efficacy of the
proposed AILearn model on spoof fingerprint detection application. One of the
significant challenges associated with spoof fingerprint detection is the
performance drop on spoofs generated using new fabrication materials. AILearn
is an adaptive incremental learning model which adapts to the features of the
``live'' and ``spoof'' fingerprint images and efficiently recognizes the new
spoof fingerprints as well as the known spoof fingerprints when the new data is
available. To the best of our knowledge, AILearn is the first attempt in
incremental learning algorithms that adapts to the properties of data for
generating a diverse ensemble of base classifiers. From the experiments
conducted on standard high-dimensional datasets LivDet 2011, LivDet 2013 and
LivDet 2015, we show that the performance gain on new fake materials is
significantly high. On an average, we achieve $49.57\%$ improvement in accuracy
between the consecutive learning phases.
</p>
<a href="http://arxiv.org/abs/2012.14639" target="_blank">arXiv:2012.14639</a> [<a href="http://arxiv.org/pdf/2012.14639" target="_blank">pdf</a>]

<h2>Peacock Exploration: A Lightweight Exploration for UAV using Control-Efficient Trajectory. (arXiv:2012.14649v1 [cs.RO])</h2>
<h3>EungChang Mason Lee, Duckyu Choi, Hyun Myung</h3>
<p>Unmanned Aerial Vehicles have received much attention in recent years due to
its wide range of applications, such as exploration of an unknown environment
to acquire a 3D map without prior knowledge of it. Existing exploration methods
have been largely challenged by computationally heavy probabilistic path
planning. Similarly, kinodynamic constraints or proper sensors considering the
payload for UAVs were not considered. In this paper, to solve those issues and
to consider the limited payload and computational resource of UAVs, we propose
"Peacock Exploration": A lightweight exploration method for UAVs using
precomputed minimum snap trajectories which look like a peacock's tail. Using
the widely known, control efficient minimum snap trajectories and OctoMap, the
UAV equipped with a RGB-D camera can explore unknown 3D environments without
any prior knowledge or human-guidance with only O(logN) computational
complexity. It also adopts the receding horizon approach and simple, heuristic
scoring criteria. The proposed algorithm's performance is demonstrated by
exploring a challenging 3D maze environment and compared with a
state-of-the-art algorithm.
</p>
<a href="http://arxiv.org/abs/2012.14649" target="_blank">arXiv:2012.14649</a> [<a href="http://arxiv.org/pdf/2012.14649" target="_blank">pdf</a>]

<h2>Parzen Window Approximation on Riemannian Manifold. (arXiv:2012.14661v1 [cs.LG])</h2>
<h3>Abhishek, Shekhar Verma</h3>
<p>In graph motivated learning, label propagation largely depends on data
affinity represented as edges between connected data points. The affinity
assignment implicitly assumes even distribution of data on the manifold. This
assumption may not hold and may lead to inaccurate metric assignment due to
drift towards high-density regions. The drift affected heat kernel based
affinity with a globally fixed Parzen window either discards genuine neighbors
or forces distant data points to become a member of the neighborhood. This
yields a biased affinity matrix. In this paper, the bias due to uneven data
sampling on the Riemannian manifold is catered to by a variable Parzen window
determined as a function of neighborhood size, ambient dimension, flatness
range, etc. Additionally, affinity adjustment is used which offsets the effect
of uneven sampling responsible for the bias. An affinity metric which takes
into consideration the irregular sampling effect to yield accurate label
propagation is proposed. Extensive experiments on synthetic and real-world data
sets confirm that the proposed method increases the classification accuracy
significantly and outperforms existing Parzen window estimators in graph
Laplacian manifold regularization methods.
</p>
<a href="http://arxiv.org/abs/2012.14661" target="_blank">arXiv:2012.14661</a> [<a href="http://arxiv.org/pdf/2012.14661" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Control of Valves. (arXiv:2012.14668v1 [cs.LG])</h2>
<h3>Rajesh Siraskar</h3>
<p>This paper compares reinforcement learning (RL) with PID
(proportional-integral-derivative) strategy for control of nonlinear valves
using a unified framework. RL is an autonomous learning mechanism that learns
by interacting with its environment. It is gaining increasing attention in the
world of control systems as a means of building optimal-controllers for
challenging dynamic and nonlinear processes. Published RL research often uses
open-source tools (Python and OpenAI Gym environments) which could be difficult
to adapt and apply by practicing industrial engineers, we therefore used
MathWorks tools. MATLAB's recently launched (R2019a) Reinforcement Learning
Toolbox was used to develop the valve controller; trained using the DDPG (Deep
Deterministic Policy-Gradient) algorithm and Simulink to simulate the nonlinear
valve and setup the experimental test-bench to evaluate the RL and PID
controllers. Results indicate that the RL controller is extremely good at
tracking the signal with speed and produces a lower error with respect to the
reference signals. The PID, however, is better at disturbance rejection and
hence provides a longer life for the valves. Experiential learnings gained from
this research are corroborated against published research. It is known that
successful machine learning involves tuning many hyperparameters and
significant investment of time and efforts. We introduce ``Graded Learning" as
a simplified, application oriented adaptation of the more formal and
algorithmic ``Curriculum for Reinforcement Learning''. It is shown via
experiments that it helps converge the learning task of complex non-linear real
world systems.
</p>
<a href="http://arxiv.org/abs/2012.14668" target="_blank">arXiv:2012.14668</a> [<a href="http://arxiv.org/pdf/2012.14668" target="_blank">pdf</a>]

<h2>Fast Incremental Expectation Maximization for finite-sum optimization: nonasymptotic convergence. (arXiv:2012.14670v1 [cs.LG])</h2>
<h3>Gersende Fort (IMT), P. Gach (IMT), E. Moulines (CMAP, XPOP)</h3>
<p>Fast Incremental Expectation Maximization (FIEM) is a version of the EM
framework for large datasets. In this paper, we first recast FIEM and other
incremental EM type algorithms in the {\em Stochastic Approximation within EM}
framework. Then, we provide nonasymptotic bounds for the convergence in
expectation as a function of the number of examples $n$ and of the maximal
number of iterations $\kmax$. We propose two strategies for achieving an
$\epsilon$-approximate stationary point, respectively with $\kmax =
O(n^{2/3}/\epsilon)$ and $\kmax = O(\sqrt{n}/\epsilon^{3/2})$, both strategies
relying on a random termination rule before $\kmax$ and on a constant step size
in the Stochastic Approximation step. Our bounds provide some improvements on
the literature. First, they allow $\kmax$ to scale as $\sqrt{n}$ which is
better than $n^{2/3}$ which was the best rate obtained so far; it is at the
cost of a larger dependence upon the tolerance $\epsilon$, thus making this
control relevant for small to medium accuracy with respect to the number of
examples $n$. Second, for the $n^{2/3}$-rate, the numerical illustrations show
that thanks to an optimized choice of the step size and of the bounds in terms
of quantities characterizing the optimization problem at hand, our results
desig a less conservative choice of the step size and provide a better control
of the convergence in expectation.
</p>
<a href="http://arxiv.org/abs/2012.14670" target="_blank">arXiv:2012.14670</a> [<a href="http://arxiv.org/pdf/2012.14670" target="_blank">pdf</a>]

<h2>Tips and Tricks for Webly-Supervised Fine-Grained Recognition: Learning from the WebFG 2020 Challenge. (arXiv:2012.14672v1 [cs.CV])</h2>
<h3>Xiu-Shen Wei, Yu-Yan Xu, Yazhou Yao, Jia Wei, Si Xi, Wenyuan Xu, Weidong Zhang, Xiaoxin Lv, Dengpan Fu, Qing Li, Baoying Chen, Haojie Guo, Taolue Xue, Haipeng Jing, Zhiheng Wang, Tianming Zhang, Mingwen Zhang</h3>
<p>WebFG 2020 is an international challenge hosted by Nanjing University of
Science and Technology, University of Edinburgh, Nanjing University, The
University of Adelaide, Waseda University, etc. This challenge mainly pays
attention to the webly-supervised fine-grained recognition problem. In the
literature, existing deep learning methods highly rely on large-scale and
high-quality labeled training data, which poses a limitation to their
practicability and scalability in real world applications. In particular, for
fine-grained recognition, a visual task that requires professional knowledge
for labeling, the cost of acquiring labeled training data is quite high. It
causes extreme difficulties to obtain a large amount of high-quality training
data. Therefore, utilizing free web data to train fine-grained recognition
models has attracted increasing attentions from researchers in the fine-grained
community. This challenge expects participants to develop webly-supervised
fine-grained recognition methods, which leverages web images in training
fine-grained recognition models to ease the extreme dependence of deep learning
methods on large-scale manually labeled datasets and to enhance their
practicability and scalability. In this technical report, we have pulled
together the top WebFG 2020 solutions of total 54 competing teams, and discuss
what methods worked best across the set of winning teams, and what surprisingly
did not help.
</p>
<a href="http://arxiv.org/abs/2012.14672" target="_blank">arXiv:2012.14672</a> [<a href="http://arxiv.org/pdf/2012.14672" target="_blank">pdf</a>]

<h2>Towards Reducing Severe Defocus Spread Effects for Multi-Focus Image Fusion via an Optimization Based Strategy. (arXiv:2012.14678v1 [cs.CV])</h2>
<h3>Shuang Xu, Lizhen Ji, Zhe Wang, Pengfei Li, Kai Sun, Chunxia Zhang, Jiangshe Zhang</h3>
<p>Multi-focus image fusion (MFF) is a popular technique to generate an
all-in-focus image, where all objects in the scene are sharp. However, existing
methods pay little attention to defocus spread effects of the real-world
multi-focus images. Consequently, most of the methods perform badly in the
areas near focus map boundaries. According to the idea that each local region
in the fused image should be similar to the sharpest one among source images,
this paper presents an optimization-based approach to reduce defocus spread
effects. Firstly, a new MFF assessmentmetric is presented by combining the
principle of structure similarity and detected focus maps. Then, MFF problem is
cast into maximizing this metric. The optimization is solved by gradient
ascent. Experiments conducted on the real-world dataset verify superiority of
the proposed model. The codes are available at
https://github.com/xsxjtu/MFF-SSIM.
</p>
<a href="http://arxiv.org/abs/2012.14678" target="_blank">arXiv:2012.14678</a> [<a href="http://arxiv.org/pdf/2012.14678" target="_blank">pdf</a>]

<h2>COIN: Contrastive Identifier Network for Breast Mass Diagnosis in Mammography. (arXiv:2012.14690v1 [cs.CV])</h2>
<h3>Heyi Li, Dongdong Chen, William H. Nailon, Mike E. Davies, David Laurenson</h3>
<p>Computer-aided breast cancer diagnosis in mammography is a challenging
problem, stemming from mammographical data scarcity and data entanglement. In
particular, data scarcity is attributed to the privacy and expensive
annotation. And data entanglement is due to the high similarity between benign
and malignant masses, of which manifolds reside in lower dimensional space with
very small margin. To address these two challenges, we propose a deep learning
framework, named Contrastive Identifier Network (\textsc{COIN}), which
integrates adversarial augmentation and manifold-based contrastive learning.
Firstly, we employ adversarial learning to create both on- and off-distribution
mass contained ROIs. After that, we propose a novel contrastive loss with a
built Signed graph. Finally, the neural network is optimized in a contrastive
learning manner, with the purpose of improving the deep model's
discriminativity on the extended dataset. In particular, by employing COIN,
data samples from the same category are pulled close whereas those with
different labels are pushed further in the deep latent space. Moreover, COIN
outperforms the state-of-the-art related algorithms for solving breast cancer
diagnosis problem by a considerable margin, achieving 93.4\% accuracy and
95.0\% AUC score. The code will release on ***.
</p>
<a href="http://arxiv.org/abs/2012.14690" target="_blank">arXiv:2012.14690</a> [<a href="http://arxiv.org/pdf/2012.14690" target="_blank">pdf</a>]

<h2>Image-to-Image Retrieval by Learning Similarity between Scene Graphs. (arXiv:2012.14700v1 [cs.CV])</h2>
<h3>Sangwoong Yoon, Woo Young Kang, Sungwook Jeon, SeongEun Lee, Changjin Han, Jonghun Park, Eun-Sol Kim</h3>
<p>As a scene graph compactly summarizes the high-level content of an image in a
structured and symbolic manner, the similarity between scene graphs of two
images reflects the relevance of their contents. Based on this idea, we propose
a novel approach for image-to-image retrieval using scene graph similarity
measured by graph neural networks. In our approach, graph neural networks are
trained to predict the proxy image relevance measure, computed from
human-annotated captions using a pre-trained sentence similarity model. We
collect and publish the dataset for image relevance measured by human
annotators to evaluate retrieval algorithms. The collected dataset shows that
our method agrees well with the human perception of image similarity than other
competitive baselines.
</p>
<a href="http://arxiv.org/abs/2012.14700" target="_blank">arXiv:2012.14700</a> [<a href="http://arxiv.org/pdf/2012.14700" target="_blank">pdf</a>]

<h2>Advances in deep learning methods for pavement surface crack detection and identification with visible light visual images. (arXiv:2012.14704v1 [cs.CV])</h2>
<h3>Kailiang Lu</h3>
<p>Compared to NDT and health monitoring method for cracks in engineering
structures, surface crack detection or identification based on visible light
images is non-contact, with the advantages of fast speed, low cost and high
precision. Firstly, typical pavement (concrete also) crack public data sets
were collected, and the characteristics of sample images as well as the random
variable factors, including environmental, noise and interference etc., were
summarized. Subsequently, the advantages and disadvantages of three main crack
identification methods (i.e., hand-crafted feature engineering, machine
learning, deep learning) were compared. Finally, from the aspects of model
architecture, testing performance and predicting effectiveness, the development
and progress of typical deep learning models, including self-built CNN,
transfer learning(TL) and encoder-decoder(ED), which can be easily deployed on
embedded platform, were reviewed. The benchmark test shows that: 1) It has been
able to realize real-time pixel-level crack identification on embedded
platform: the entire crack detection average time cost of an image sample is
less than 100ms, either using the ED method (i.e., FPCNet) or the TL method
based on InceptionV3. It can be reduced to less than 10ms with TL method based
on MobileNet (a lightweight backbone base network). 2) In terms of accuracy, it
can reach over 99.8% on CCIC which is easily identified by human eyes. On
SDNET2018, some samples of which are difficult to be identified, FPCNet can
reach 97.5%, while TL method is close to 96.1%.

To the best of our knowledge, this paper for the first time comprehensively
summarizes the pavement crack public data sets, and the performance and
effectiveness of surface crack detection and identification deep learning
methods for embedded platform, are reviewed and evaluated.
</p>
<a href="http://arxiv.org/abs/2012.14704" target="_blank">arXiv:2012.14704</a> [<a href="http://arxiv.org/pdf/2012.14704" target="_blank">pdf</a>]

<h2>Hybrid Micro/Macro Level Convolution for Heterogeneous Graph Learning. (arXiv:2012.14722v1 [cs.LG])</h2>
<h3>Le Yu, Leilei Sun, Bowen Du, Chuanren Liu, Weifeng Lv, Hui Xiong</h3>
<p>Heterogeneous graphs are pervasive in practical scenarios, where each graph
consists of multiple types of nodes and edges. Representation learning on
heterogeneous graphs aims to obtain low-dimensional node representations that
could preserve both node attributes and relation information. However, most of
the existing graph convolution approaches were designed for homogeneous graphs,
and therefore cannot handle heterogeneous graphs. Some recent methods designed
for heterogeneous graphs are also faced with several issues, including the
insufficient utilization of heterogeneous properties, structural information
loss, and lack of interpretability. In this paper, we propose HGConv, a novel
Heterogeneous Graph Convolution approach, to learn comprehensive node
representations on heterogeneous graphs with a hybrid micro/macro level
convolutional operation. Different from existing methods, HGConv could perform
convolutions on the intrinsic structure of heterogeneous graphs directly at
both micro and macro levels: A micro-level convolution to learn the importance
of nodes within the same relation, and a macro-level convolution to distinguish
the subtle difference across different relations. The hybrid strategy enables
HGConv to fully leverage heterogeneous information with proper
interpretability. Moreover, a weighted residual connection is designed to
aggregate both inherent attributes and neighbor information of the focal node
adaptively. Extensive experiments on various tasks demonstrate not only the
superiority of HGConv over existing methods, but also the intuitive
interpretability of our approach for graph analysis.
</p>
<a href="http://arxiv.org/abs/2012.14722" target="_blank">arXiv:2012.14722</a> [<a href="http://arxiv.org/pdf/2012.14722" target="_blank">pdf</a>]

<h2>AttrE2vec: Unsupervised Attributed Edge Representation Learning. (arXiv:2012.14727v1 [cs.LG])</h2>
<h3>Piotr Bielak, Tomasz Kajdanowicz, Nitesh V. Chawla</h3>
<p>Representation learning has overcome the often arduous and manual
featurization of networks through (unsupervised) feature learning as it results
in embeddings that can apply to a variety of downstream learning tasks. The
focus of representation learning on graphs has focused mainly on shallow
(node-centric) or deep (graph-based) learning approaches. While there have been
approaches that work on homogeneous and heterogeneous networks with multi-typed
nodes and edges, there is a gap in learning edge representations. This paper
proposes a novel unsupervised inductive method called AttrE2Vec, which learns a
low-dimensional vector representation for edges in attributed networks. It
systematically captures the topological proximity, attributes affinity, and
feature similarity of edges. Contrary to current advances in edge embedding
research, our proposal extends the body of methods providing representations
for edges, capturing graph attributes in an inductive and unsupervised manner.
Experimental results show that, compared to contemporary approaches, our method
builds more powerful edge vector representations, reflected by higher quality
measures (AUC, accuracy) in downstream tasks as edge classification and edge
clustering. It is also confirmed by analyzing low-dimensional embedding
projections.
</p>
<a href="http://arxiv.org/abs/2012.14727" target="_blank">arXiv:2012.14727</a> [<a href="http://arxiv.org/pdf/2012.14727" target="_blank">pdf</a>]

<h2>With False Friends Like These, Who Can Have Self-Knowledge?. (arXiv:2012.14738v1 [cs.LG])</h2>
<h3>Lue Tao, Songcan Chen</h3>
<p>Adversarial examples arise from excessive sensitivity of a model. Commonly
studied adversarial examples are malicious inputs, crafted by an adversary from
correctly classified examples, to induce misclassification. This paper studies
an intriguing, yet far overlooked consequence of the excessive sensitivity,
that is, a misclassified example can be easily perturbed to help the model to
produce correct output. Such perturbed examples look harmless, but actually can
be maliciously utilized by a false friend to make the model self-satisfied.
Thus we name them hypocritical examples. With false friends like these, a
poorly performed model could behave like a state-of-the-art one. Once a
deployer trusts the hypocritical performance and uses the "well-performed"
model in real-world applications, potential security concerns appear even in
benign environments. In this paper, we formalize the hypocritical risk for the
first time and propose a defense method specialized for hypocritical examples
by minimizing the tradeoff between natural risk and an upper bound of
hypocritical risk. Moreover, our theoretical analysis reveals connections
between adversarial risk and hypocritical risk. Extensive experiments verify
the theoretical results and the effectiveness of our proposed methods.
</p>
<a href="http://arxiv.org/abs/2012.14738" target="_blank">arXiv:2012.14738</a> [<a href="http://arxiv.org/pdf/2012.14738" target="_blank">pdf</a>]

<h2>Chasing the Tail in Monocular 3D Human Reconstruction with Prototype Memory. (arXiv:2012.14739v1 [cs.CV])</h2>
<h3>Yu Rong, Ziwei Liu, Chen Change Loy</h3>
<p>Deep neural networks have achieved great progress in single-image 3D human
reconstruction. However, existing methods still fall short in predicting rare
poses. The reason is that most of the current models perform regression based
on a single human prototype, which is similar to common poses while far from
the rare poses. In this work, we 1) identify and analyze this learning obstacle
and 2) propose a prototype memory-augmented network, PM-Net, that effectively
improves performances of predicting rare poses. The core of our framework is a
memory module that learns and stores a set of 3D human prototypes capturing
local distributions for either common poses or rare poses. With this
formulation, the regression starts from a better initialization, which is
relatively easier to converge. Extensive experiments on several widely employed
datasets demonstrate the proposed framework's effectiveness compared to other
state-of-the-art methods. Notably, our approach significantly improves the
models' performances on rare poses while generating comparable results on other
samples.
</p>
<a href="http://arxiv.org/abs/2012.14739" target="_blank">arXiv:2012.14739</a> [<a href="http://arxiv.org/pdf/2012.14739" target="_blank">pdf</a>]

<h2>Improved Sample Complexity for Incremental Autonomous Exploration in MDPs. (arXiv:2012.14755v1 [cs.LG])</h2>
<h3>Jean Tarbouriech, Matteo Pirotta, Michal Valko, Alessandro Lazaric</h3>
<p>We investigate the exploration of an unknown environment when no reward
function is provided. Building on the incremental exploration setting
introduced by Lim and Auer [1], we define the objective of learning the set of
$\epsilon$-optimal goal-conditioned policies attaining all states that are
incrementally reachable within $L$ steps (in expectation) from a reference
state $s_0$. In this paper, we introduce a novel model-based approach that
interleaves discovering new states from $s_0$ and improving the accuracy of a
model estimate that is used to compute goal-conditioned policies to reach newly
discovered states. The resulting algorithm, DisCo, achieves a sample complexity
scaling as $\tilde{O}(L^5 S_{L+\epsilon} \Gamma_{L+\epsilon} A \epsilon^{-2})$,
where $A$ is the number of actions, $S_{L+\epsilon}$ is the number of states
that are incrementally reachable from $s_0$ in $L+\epsilon$ steps, and
$\Gamma_{L+\epsilon}$ is the branching factor of the dynamics over such states.
This improves over the algorithm proposed in [1] in both $\epsilon$ and $L$ at
the cost of an extra $\Gamma_{L+\epsilon}$ factor, which is small in most
environments of interest. Furthermore, DisCo is the first algorithm that can
return an $\epsilon/c_{\min}$-optimal policy for any cost-sensitive
shortest-path problem defined on the $L$-reachable states with minimum cost
$c_{\min}$. Finally, we report preliminary empirical results confirming our
theoretical findings.
</p>
<a href="http://arxiv.org/abs/2012.14755" target="_blank">arXiv:2012.14755</a> [<a href="http://arxiv.org/pdf/2012.14755" target="_blank">pdf</a>]

<h2>Deep Hashing for Secure Multimodal Biometrics. (arXiv:2012.14758v1 [cs.CV])</h2>
<h3>Veeru Talreja, Matthew Valenti, Nasser Nasrabadi</h3>
<p>When compared to unimodal systems, multimodal biometric systems have several
advantages, including lower error rate, higher accuracy, and larger population
coverage. However, multimodal systems have an increased demand for integrity
and privacy because they must store multiple biometric traits associated with
each user. In this paper, we present a deep learning framework for
feature-level fusion that generates a secure multimodal template from each
user's face and iris biometrics. We integrate a deep hashing (binarization)
technique into the fusion architecture to generate a robust binary multimodal
shared latent representation. Further, we employ a hybrid secure architecture
by combining cancelable biometrics with secure sketch techniques and integrate
it with a deep hashing framework, which makes it computationally prohibitive to
forge a combination of multiple biometrics that pass the authentication. The
efficacy of the proposed approach is shown using a multimodal database of face
and iris and it is observed that the matching performance is improved due to
the fusion of multiple biometrics. Furthermore, the proposed approach also
provides cancelability and unlinkability of the templates along with improved
privacy of the biometric data. Additionally, we also test the proposed hashing
function for an image retrieval application using a benchmark dataset. The main
goal of this paper is to develop a method for integrating multimodal fusion,
deep hashing, and biometric security, with an emphasis on structural data from
modalities like face and iris. The proposed approach is in no way a general
biometric security framework that can be applied to all biometric modalities,
as further research is needed to extend the proposed framework to other
unconstrained biometric modalities.
</p>
<a href="http://arxiv.org/abs/2012.14758" target="_blank">arXiv:2012.14758</a> [<a href="http://arxiv.org/pdf/2012.14758" target="_blank">pdf</a>]

<h2>The HyperTrac Project: Recent Progress and Future Research Directions on Hypergraph Decompositions. (arXiv:2012.14762v1 [cs.AI])</h2>
<h3>Georg Gottlob, Matthias Lanzinger, Davide Mario Longo, Cem Okulmus, Reinhard Pichler</h3>
<p>Constraint Satisfaction Problems (CSPs) play a central role in many
applications in Artificial Intelligence and Operations Research. In general,
solving CSPs is NP-complete. The structure of CSPs is best described by
hypergraphs. Therefore, various forms of hypergraph decompositions have been
proposed in the literature to identify tractable fragments of CSPs. However,
also the computation of a concrete hypergraph decomposition is a challenging
task in itself. In this paper, we report on recent progress in the study of
hypergraph decompositions and we outline several directions for future
research.
</p>
<a href="http://arxiv.org/abs/2012.14762" target="_blank">arXiv:2012.14762</a> [<a href="http://arxiv.org/pdf/2012.14762" target="_blank">pdf</a>]

<h2>Graph-based non-linear least squares optimization for visual place recognition in changing environments. (arXiv:2012.14766v1 [cs.CV])</h2>
<h3>Stefan Schubert, Peer Neubert, Peter Protzel</h3>
<p>Visual place recognition is an important subproblem of mobile robot
localization. Since it is a special case of image retrieval, the basic source
of information is the pairwise similarity of image descriptors. However, the
embedding of the image retrieval problem in this robotic task provides
additional structure that can be exploited, e.g. spatio-temporal consistency.
Several algorithms exist to exploit this structure, e.g., sequence processing
approaches or descriptor standardization approaches for changing environments.
In this paper, we propose a graph-based framework to systematically exploit
different types of additional structure and information. The graphical model is
used to formulate a non-linear least squares problem that can be optimized with
standard tools. Beyond sequences and standardization, we propose the usage of
intra-set similarities within the database and/or the query image set as
additional source of information. If available, our approach also allows to
seamlessly integrate additional knowledge about poses of database images. We
evaluate the system on a variety of standard place recognition datasets and
demonstrate performance improvements for a large number of different
configurations including different sources of information, different types of
constraints, and online or offline place recognition setups.
</p>
<a href="http://arxiv.org/abs/2012.14766" target="_blank">arXiv:2012.14766</a> [<a href="http://arxiv.org/pdf/2012.14766" target="_blank">pdf</a>]

<h2>Drift-Aware Multi-Memory Model for Imbalanced Data Streams. (arXiv:2012.14791v1 [cs.LG])</h2>
<h3>Amir Abolfazli, Eirini Ntoutsi</h3>
<p>Online class imbalance learning deals with data streams that are affected by
both concept drift and class imbalance. Online learning tries to find a
trade-off between exploiting previously learned information and incorporating
new information into the model. This requires both the incremental update of
the model and the ability to unlearn outdated information. The improper use of
unlearning, however, can lead to the retroactive interference problem, a
phenomenon that occurs when newly learned information interferes with the old
information and impedes the recall of previously learned information. The
problem becomes more severe when the classes are not equally represented,
resulting in the removal of minority information from the model. In this work,
we propose the Drift-Aware Multi-Memory Model (DAM3), which addresses the class
imbalance problem in online learning for memory-based models. DAM3 mitigates
class imbalance by incorporating an imbalance-sensitive drift detector,
preserving a balanced representation of classes in the model, and resolving
retroactive interference using a working memory that prevents the forgetting of
old information. We show through experiments on real-world and synthetic
datasets that the proposed method mitigates class imbalance and outperforms the
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.14791" target="_blank">arXiv:2012.14791</a> [<a href="http://arxiv.org/pdf/2012.14791" target="_blank">pdf</a>]

<h2>A Deep Reinforcement Learning Based Multi-Criteria Decision Support System for Textile Manufacturing Process Optimization. (arXiv:2012.14794v1 [cs.AI])</h2>
<h3>Zhenglei He (GEMTEX), Kim Phuc Tran (GEMTEX), Sebastien Thomassey (GEMTEX), Xianyi Zeng (GEMTEX), Jie Xu, Chang Haiyi</h3>
<p>Textile manufacturing is a typical traditional industry involving high
complexity in interconnected processes with limited capacity on the application
of modern technologies. Decision-making in this domain generally takes multiple
criteria into consideration, which usually arouses more complexity. To address
this issue, the present paper proposes a decision support system that combines
the intelligent data-based random forest (RF) models and a human knowledge
based analytical hierarchical process (AHP) multi-criteria structure in
accordance to the objective and the subjective factors of the textile
manufacturing process. More importantly, the textile manufacturing process is
described as the Markov decision process (MDP) paradigm, and a deep
reinforcement learning scheme, the Deep Q-networks (DQN), is employed to
optimize it. The effectiveness of this system has been validated in a case
study of optimizing a textile ozonation process, showing that it can better
master the challenging decision-making tasks in textile manufacturing
processes.
</p>
<a href="http://arxiv.org/abs/2012.14794" target="_blank">arXiv:2012.14794</a> [<a href="http://arxiv.org/pdf/2012.14794" target="_blank">pdf</a>]

<h2>Accelerated NMR Spectroscopy: Merge Optimization with Deep Learning. (arXiv:2012.14830v1 [cs.LG])</h2>
<h3>Zi Wang, Di Guo, Yihui Huang, Zhangren Tu, Vladislav Orekhov, Xiaobo Qu</h3>
<p>Multi-dimensional NMR spectroscopy is an invaluable biophysical tool in
studies of structure, interactions, and dynamics of large molecules like
proteins and nuclear acids. Non-uniform sampling is a powerful approach for
shortening measurement time and increasing spectra resolution. Several methods
have been established for spectra reconstruction from the undersampled data,
typical approaches include model-based optimization and data-driven deep
learning. The former is well theoretically grounded and provides high-quality
spectra, while the latter has a huge advantage in reconstruction time potential
and push further limits of spectra quality and analysis. Combining the merits
of the two, we propose a model-inspired deep learning, for reliable,
high-quality, and ultra-fast spectra reconstruction, exemplified by
multi-dimensional spectra of several representative proteins. We demonstrate
that the proposed network needs very few parameters, and shows very high
robustness in respect to dissimilarity of the training and target data in the
spectra size, type, and sampling level. This work can be considered as a
proof-of-concept of merging optimization with deep learning in NMR
spectroscopy.
</p>
<a href="http://arxiv.org/abs/2012.14830" target="_blank">arXiv:2012.14830</a> [<a href="http://arxiv.org/pdf/2012.14830" target="_blank">pdf</a>]

<h2>Visual-Thermal Camera Dataset Release and Multi-Modal Alignment without Calibration Information. (arXiv:2012.14833v1 [cs.CV])</h2>
<h3>Frank Mascarich, Kostas Alexis</h3>
<p>This report accompanies a dataset release on visual and thermal camera data
and details a procedure followed to align such multi-modal camera frames in
order to provide pixel-level correspondence between the two without using
intrinsic or extrinsic calibration information. To achieve this goal we benefit
from progress in the domain of multi-modal image alignment and specifically
employ the Mattes Mutual Information Metric to guide the registration process.
In the released dataset we release both the raw visual and thermal camera data,
as well as the aligned frames, alongside calibration parameters with the goal
to better facilitate the investigation on common local/global features across
such multi-modal image streams.
</p>
<a href="http://arxiv.org/abs/2012.14833" target="_blank">arXiv:2012.14833</a> [<a href="http://arxiv.org/pdf/2012.14833" target="_blank">pdf</a>]

<h2>Object sorting using faster R-CNN. (arXiv:2012.14840v1 [cs.CV])</h2>
<h3>Pengchang Chen, Vinayak Elangovan</h3>
<p>In a factory production line, different industry parts need to be quickly
differentiated and sorted for further process. Parts can be of different colors
and shapes. It is tedious for humans to differentiate and sort these objects in
appropriate categories. Automating this process would save more time and cost.
In the automation process, choosing an appropriate model to detect and classify
different objects based on specific features is more challenging. In this
paper, three different neural network models are compared to the object sorting
system. They are namely CNN, Fast R-CNN, and Faster R-CNN. These models are
tested, and their performance is analyzed. Moreover, for the object sorting
system, an Arduino-controlled 5 DoF (degree of freedom) robot arm is programmed
to grab and drop symmetrical objects to the targeted zone. Objects are
categorized into classes based on color, defective and non-defective objects.
</p>
<a href="http://arxiv.org/abs/2012.14840" target="_blank">arXiv:2012.14840</a> [<a href="http://arxiv.org/pdf/2012.14840" target="_blank">pdf</a>]

<h2>Modeling Social Interaction for Baby in Simulated Environment for Developmental Robotics. (arXiv:2012.14842v1 [cs.AI])</h2>
<h3>Md Ashaduzzaman Rubel Mondol, Aishwarya Pothula, Deokgun Park</h3>
<p>Task-specific AI agents are showing remarkable performance across different
domains. But modeling generalized AI agents like human intelligence will
require more than current datasets or only reward-based environments that don't
include experiences that an infant gathers throughout its initial stages. In
this paper, we present Simulated Environment for Developmental Robotics
(SEDRo). It simulates the environments for a baby agent that a human baby
experiences throughout the pre-born fetus stage to post-birth 12 months. SEDRo
also includes a mother character to provide social interaction with the agent.
To evaluate different developmental milestones of the agent, SEDRo incorporates
some experiments from developmental psychology.
</p>
<a href="http://arxiv.org/abs/2012.14842" target="_blank">arXiv:2012.14842</a> [<a href="http://arxiv.org/pdf/2012.14842" target="_blank">pdf</a>]

<h2>Learning Adversarial Markov Decision Processes with Delayed Feedback. (arXiv:2012.14843v1 [cs.LG])</h2>
<h3>Tal Lancewicki, Aviv Rosenberg, Yishay Mansour</h3>
<p>Reinforcement learning typically assumes that the agent observes feedback
from the environment immediately, but in many real-world applications (like
recommendation systems) the feedback is observed in delay. Thus, we consider
online learning in episodic Markov decision processes (MDPs) with unknown
transitions, adversarially changing costs and unrestricted delayed feedback.
That is, the costs and trajectory of episode $k$ are only available at the end
of episode $k + d^k$, where the delays $d^k$ are neither identical nor bounded,
and are chosen by an adversary. We present novel algorithms based on policy
optimization that achieve near-optimal high-probability regret of $\widetilde O
( \sqrt{K} + \sqrt{D} )$ under full-information feedback, where $K$ is the
number of episodes and $D = \sum_{k} d^k$ is the total delay. Under bandit
feedback, we prove similar $\widetilde O ( \sqrt{K} + \sqrt{D} )$ regret
assuming that the costs are stochastic, and $\widetilde O ( K^{2/3} + D^{2/3}
)$ regret in the general case. To our knowledge, we are the first to consider
the important setting of delayed feedback in adversarial MDPs.
</p>
<a href="http://arxiv.org/abs/2012.14843" target="_blank">arXiv:2012.14843</a> [<a href="http://arxiv.org/pdf/2012.14843" target="_blank">pdf</a>]

<h2>Minimum Excess Risk in Bayesian Learning. (arXiv:2012.14868v1 [cs.LG])</h2>
<h3>Aolin Xu, Maxim Raginsky</h3>
<p>We analyze the best achievable performance of Bayesian learning under
generative models by defining and upper-bounding the minimum excess risk (MER):
the gap between the minimum expected loss attainable by learning from data and
the minimum expected loss that could be achieved if the model realization were
known. The definition of MER provides a principled way to define different
notions of uncertainties in Bayesian learning, including the aleatoric
uncertainty and the minimum epistemic uncertainty. Two methods for deriving
upper bounds for the MER are presented. The first method, generally suitable
for Bayesian learning with a parametric generative model, upper-bounds the MER
by the conditional mutual information between the model parameters and the
quantity being predicted given the observed data. It allows us to quantify the
rate at which the MER decays to zero as more data becomes available. The second
method, particularly suitable for Bayesian learning with a parametric
predictive model, relates the MER to the deviation of the posterior predictive
distribution from the true predictive model, and further to the minimum
estimation error of the model parameters from data. It explicitly shows how the
uncertainty in model parameter estimation translates to the MER and to the
final prediction uncertainty. We also extend the definition and analysis of MER
to the setting with multiple parametric model families and the setting with
nonparametric models. Along the discussions we draw some comparisons between
the MER in Bayesian learning and the excess risk in frequentist learning.
</p>
<a href="http://arxiv.org/abs/2012.14868" target="_blank">arXiv:2012.14868</a> [<a href="http://arxiv.org/pdf/2012.14868" target="_blank">pdf</a>]

<h2>Twin Neural Network Regression. (arXiv:2012.14873v1 [cs.LG])</h2>
<h3>Sebastian J. Wetzel, Kevin Ryczko, Roger G. Melko, Isaac Tamblyn</h3>
<p>We introduce twin neural network (TNN) regression. This method predicts
differences between the target values of two different data points rather than
the targets themselves. The solution of a traditional regression problem is
then obtained by averaging over an ensemble of all predicted differences
between the targets of an unseen data point and all training data points.
Whereas ensembles are normally costly to produce, TNN regression intrinsically
creates an ensemble of predictions of twice the size of the training set while
only training a single neural network. Since ensembles have been shown to be
more accurate than single models this property naturally transfers to TNN
regression. We show that TNNs are able to compete or yield more accurate
predictions for different data sets, compared to other state-of-the-art
methods. Furthermore, TNN regression is constrained by self-consistency
conditions. We find that the violation of these conditions provides an estimate
for the prediction uncertainty.
</p>
<a href="http://arxiv.org/abs/2012.14873" target="_blank">arXiv:2012.14873</a> [<a href="http://arxiv.org/pdf/2012.14873" target="_blank">pdf</a>]

<h2>Growing Deep Forests Efficiently with Soft Routing and Learned Connectivity. (arXiv:2012.14878v1 [cs.LG])</h2>
<h3>Jianghao Shen, Sicheng Wang, Zhangyang Wang</h3>
<p>Despite the latest prevailing success of deep neural networks (DNNs), several
concerns have been raised against their usage, including the lack of
intepretability the gap between DNNs and other well-established machine
learning models, and the growingly expensive computational costs. A number of
recent works [1], [2], [3] explored the alternative to sequentially stacking
decision tree/random forest building blocks in a purely feed-forward way, with
no need of back propagation. Since decision trees enjoy inherent reasoning
transparency, such deep forest models can also facilitate the understanding of
the internaldecision making process. This paper further extends the deep forest
idea in several important aspects. Firstly, we employ a probabilistic tree
whose nodes make probabilistic routing decisions, a.k.a., soft routing, rather
than hard binary decisions.Besides enhancing the flexibility, it also enables
non-greedy optimization for each tree. Second, we propose an innovative
topology learning strategy: every node in the ree now maintains a new learnable
hyperparameter indicating the probability that it will be a leaf node. In that
way, the tree will jointly optimize both its parameters and the tree topology
during training. Experiments on the MNIST dataset demonstrate that our
empowered deep forests can achieve better or comparable performance than
[1],[3] , with dramatically reduced model complexity. For example,our model
with only 1 layer of 15 trees can perform comparably with the model in [3] with
2 layers of 2000 trees each.
</p>
<a href="http://arxiv.org/abs/2012.14878" target="_blank">arXiv:2012.14878</a> [<a href="http://arxiv.org/pdf/2012.14878" target="_blank">pdf</a>]

<h2>An LQR-assisted Control Algorithm for an Under-actuated In-pipe Robot in Water Distribution Systems. (arXiv:2012.14879v1 [cs.RO])</h2>
<h3>Saber Kazeminasab, Roozbeh Jafari, M. Katherine Banks</h3>
<p>To address the operational challenges of in-pipe robots in large pipes of
water distribution systems (WDS), in this research, a control algorithm is
proposed for our previously designed robot [4]. Our size adaptable robot has an
under-actuated modular design that can be used for both leak detection and
quality monitoring. First, nonlinear dynamical governing equations of the robot
are derived with the definition of two perpendicular planes, and two sets of
states are defined for the robot for stabilization and mobilization. For
stabilization, we calculated the auxiliary system matrices and designed a
stabilizer controller based on the linear quadratic regulator (LQR) controller,
and combined it with a proportional-integral-derivative (PID) based controller
for mobilization. The controller scheme is validated with simulation in MATLAB
in various operation conditions in three iterations. The simulation results
show that the controller can stabilize the robot inside the pipe by converging
the stabilizing states to zero and keeping them in zero with initial values
between -25 degree and +25 degree and tracking velocities of 10cm/s, 30cm/s,
and 50cm/s which makes the robot agile and dexterous for operation in
pipelines.
</p>
<a href="http://arxiv.org/abs/2012.14879" target="_blank">arXiv:2012.14879</a> [<a href="http://arxiv.org/pdf/2012.14879" target="_blank">pdf</a>]

<h2>Learning a Dynamic Map of Visual Appearance. (arXiv:2012.14885v1 [cs.CV])</h2>
<h3>Tawfiq Salem, Scott Workman, Nathan Jacobs</h3>
<p>The appearance of the world varies dramatically not only from place to place
but also from hour to hour and month to month. Every day billions of images
capture this complex relationship, many of which are associated with precise
time and location metadata. We propose to use these images to construct a
global-scale, dynamic map of visual appearance attributes. Such a map enables
fine-grained understanding of the expected appearance at any geographic
location and time. Our approach integrates dense overhead imagery with location
and time metadata into a general framework capable of mapping a wide variety of
visual attributes. A key feature of our approach is that it requires no manual
data annotation. We demonstrate how this approach can support various
applications, including image-driven mapping, image geolocalization, and
metadata verification.
</p>
<a href="http://arxiv.org/abs/2012.14885" target="_blank">arXiv:2012.14885</a> [<a href="http://arxiv.org/pdf/2012.14885" target="_blank">pdf</a>]

<h2>Detecting Hate Speech in Multi-modal Memes. (arXiv:2012.14891v1 [cs.CV])</h2>
<h3>Abhishek Das, Japsimar Singh Wahi, Siyao Li</h3>
<p>In the past few years, there has been a surge of interest in multi-modal
problems, from image captioning to visual question answering and beyond. In
this paper, we focus on hate speech detection in multi-modal memes wherein
memes pose an interesting multi-modal fusion problem. We aim to solve the
Facebook Meme Challenge \cite{kiela2020hateful} which aims to solve a binary
classification problem of predicting whether a meme is hateful or not. A
crucial characteristic of the challenge is that it includes "benign
confounders" to counter the possibility of models exploiting unimodal priors.
The challenge states that the state-of-the-art models perform poorly compared
to humans. During the analysis of the dataset, we realized that majority of the
data points which are originally hateful are turned into benign just be
describing the image of the meme. Also, majority of the multi-modal baselines
give more preference to the hate speech (language modality). To tackle these
problems, we explore the visual modality using object detection and image
captioning models to fetch the "actual caption" and then combine it with the
multi-modal representation to perform binary classification. This approach
tackles the benign text confounders present in the dataset to improve the
performance. Another approach we experiment with is to improve the prediction
with sentiment analysis. Instead of only using multi-modal representations
obtained from pre-trained neural networks, we also include the unimodal
sentiment to enrich the features. We perform a detailed analysis of the above
two approaches, providing compelling reasons in favor of the methodologies
used.
</p>
<a href="http://arxiv.org/abs/2012.14891" target="_blank">arXiv:2012.14891</a> [<a href="http://arxiv.org/pdf/2012.14891" target="_blank">pdf</a>]

<h2>Statistical Formulas for F Measures. (arXiv:2012.14894v1 [stat.ML])</h2>
<h3>Wenxin Jiang</h3>
<p>We provide analytic formulas for the standard error and confidence intervals
for the F measures, based on a property of asymptotic normality in the large
sample limit. The formula can be applied for sample size planning in order to
achieve accurate enough estimation of these F measures.
</p>
<a href="http://arxiv.org/abs/2012.14894" target="_blank">arXiv:2012.14894</a> [<a href="http://arxiv.org/pdf/2012.14894" target="_blank">pdf</a>]

<h2>Meta Learning Backpropagation And Improving It. (arXiv:2012.14905v1 [cs.LG])</h2>
<h3>Louis Kirsch, J&#xfc;rgen Schmidhuber</h3>
<p>Many concepts have been proposed for meta learning with neural networks
(NNs), e.g., NNs that learn to control fast weights, hyper networks, learned
learning rules, and meta recurrent neural networks (Meta RNNs). Our Variable
Shared Meta Learning (VS-ML) unifies the above and demonstrates that simple
weight-sharing and sparsity in an NN is sufficient to express powerful learning
algorithms. A simple implementation of VS-ML called Variable Shared Meta RNN
allows for implementing the backpropagation learning algorithm solely by
running an RNN in forward-mode. It can even meta-learn new learning algorithms
that improve upon backpropagation, generalizing to different datasets without
explicit gradient calculation.
</p>
<a href="http://arxiv.org/abs/2012.14905" target="_blank">arXiv:2012.14905</a> [<a href="http://arxiv.org/pdf/2012.14905" target="_blank">pdf</a>]

<h2>Decentralized Control with Graph Neural Networks. (arXiv:2012.14906v1 [cs.LG])</h2>
<h3>Fernando Gama, Qingbiao Li, Ekaterina Tolstaya, Amanda Prorok, Alejandro Ribeiro</h3>
<p>Dynamical systems consisting of a set of autonomous agents face the challenge
of having to accomplish a global task, relying only on local information. While
centralized controllers are readily available, they face limitations in terms
of scalability and implementation, as they do not respect the distributed
information structure imposed by the network system of agents. Given the
difficulties in finding optimal decentralized controllers, we propose a novel
framework using graph neural networks (GNNs) to learn these controllers. GNNs
are well-suited for the task since they are naturally distributed architectures
and exhibit good scalability and transferability properties. The problems of
flocking and multi-agent path planning are explored to illustrate the potential
of GNNs in learning decentralized controllers.
</p>
<a href="http://arxiv.org/abs/2012.14906" target="_blank">arXiv:2012.14906</a> [<a href="http://arxiv.org/pdf/2012.14906" target="_blank">pdf</a>]

<h2>SALA: Soft Assignment Local Aggregation for 3D Semantic Segmentation. (arXiv:2012.14929v1 [cs.CV])</h2>
<h3>Hani Itani, Silvio Giancola, Ali Thabet, Bernard Ghanem</h3>
<p>We introduce the idea of using learnable neighbor-to-grid soft assignment in
grid-based aggregation functions for the task of 3D semantic segmentation.
Previous methods in literature operate on a predefined geometric grid such as
local volume partitions or irregular kernel points. These methods use geometric
functions to assign local neighbors to their corresponding grid. Such geometric
heuristics are potentially sub-optimal for the end task of semantic
segmentation. Furthermore, they are applied uniformly throughout the depth of
the network. A more general alternative would allow the network to learn its
own neighbor-to-grid assignment function that best suits the end task. Since it
is learnable, this mapping has the flexibility to be different per layer. This
paper leverages learned neighbor-to-grid soft assignment to define an
aggregation function that balances efficiency and performance. We demonstrate
the efficacy of our method by reaching state-of-the-art (SOTA) performance on
S3DIS with almost 10$\times$ less parameters than the current reigning method.
We also demonstrate competitive performance on ScanNet and PartNet as compared
with much larger SOTA models.
</p>
<a href="http://arxiv.org/abs/2012.14929" target="_blank">arXiv:2012.14929</a> [<a href="http://arxiv.org/pdf/2012.14929" target="_blank">pdf</a>]

<h2>An extension of the angular synchronization problem to the heterogeneous setting. (arXiv:2012.14932v1 [stat.ML])</h2>
<h3>Mihai Cucuringu, Hemant Tyagi</h3>
<p>Given an undirected measurement graph $G = ([n], E)$, the classical angular
synchronization problem consists of recovering unknown angles
$\theta_1,\dots,\theta_n$ from a collection of noisy pairwise measurements of
the form $(\theta_i - \theta_j) \mod 2\pi$, for each $\{i,j\} \in E$. This
problem arises in a variety of applications, including computer vision, time
synchronization of distributed networks, and ranking from preference
relationships. In this paper, we consider a generalization to the setting where
there exist $k$ unknown groups of angles $\theta_{l,1}, \dots,\theta_{l,n}$,
for $l=1,\dots,k$. For each $ \{i,j\} \in E$, we are given noisy pairwise
measurements of the form $\theta_{\ell,i} - \theta_{\ell,j}$ for an unknown
$\ell \in \{1,2,\ldots,k\}$. This can be thought of as a natural extension of
the angular synchronization problem to the heterogeneous setting of multiple
groups of angles, where the measurement graph has an unknown edge-disjoint
decomposition $G = G_1 \cup G_2 \ldots \cup G_k$, where the $G_i$'s denote the
subgraphs of edges corresponding to each group. We propose a probabilistic
generative model for this problem, along with a spectral algorithm for which we
provide a detailed theoretical analysis in terms of robustness against both
sampling sparsity and noise. The theoretical findings are complemented by a
comprehensive set of numerical experiments, showcasing the efficacy of our
algorithm under various parameter regimes. Finally, we consider an application
of bi-synchronization to the graph realization problem, and provide along the
way an iterative graph disentangling procedure that uncovers the subgraphs
$G_i$, $i=1,\ldots,k$ which is of independent interest, as it is shown to
improve the final recovery accuracy across all the experiments considered.
</p>
<a href="http://arxiv.org/abs/2012.14932" target="_blank">arXiv:2012.14932</a> [<a href="http://arxiv.org/pdf/2012.14932" target="_blank">pdf</a>]

<h2>Learning Energy-Based Model with Variational Auto-Encoder as Amortized Sampler. (arXiv:2012.14936v1 [stat.ML])</h2>
<h3>Jianwen Xie, Zilong Zheng, Ping Li</h3>
<p>Due to the intractable partition function, training energy-based models
(EBMs) by maximum likelihood requires Markov chain Monte Carlo (MCMC) sampling
to approximate the gradient of the Kullback-Leibler divergence between data and
model distributions. However, it is non-trivial to sample from an EBM because
of the difficulty of mixing between modes. In this paper, we propose to learn a
variational auto-encoder (VAE) to initialize the finite-step MCMC, such as
Langevin dynamics that is derived from the energy function, for efficient
amortized sampling of the EBM. With these amortized MCMC samples, the EBM can
be trained by maximum likelihood, which follows an "analysis by synthesis"
scheme; while the variational auto-encoder learns from these MCMC samples via
variational Bayes. We call this joint training algorithm the variational MCMC
teaching, in which the VAE chases the EBM toward data distribution. We
interpret the learning algorithm as a dynamic alternating projection in the
context of information geometry. Our proposed models can generate samples
comparable to GANs and EBMs. Additionally, we demonstrate that our models can
learn effective probabilistic distribution toward supervised conditional
learning experiments.
</p>
<a href="http://arxiv.org/abs/2012.14936" target="_blank">arXiv:2012.14936</a> [<a href="http://arxiv.org/pdf/2012.14936" target="_blank">pdf</a>]

<h2>LISPR: An Options Framework for Policy Reuse with Reinforcement Learning. (arXiv:2012.14942v1 [cs.LG])</h2>
<h3>Daniel Graves, Jun Jin, Jun Luo</h3>
<p>We propose a framework for transferring any existing policy from a
potentially unknown source MDP to a target MDP. This framework (1) enables
reuse in the target domain of any form of source policy, including classical
controllers, heuristic policies, or deep neural network-based policies, (2)
attains optimality under suitable theoretical conditions, and (3) guarantees
improvement over the source policy in the target MDP. These are achieved by
packaging the source policy as a black-box option in the target MDP and
providing a theoretically grounded way to learn the option's initiation set
through general value functions. Our approach facilitates the learning of new
policies by (1) maximizing the target MDP reward with the help of the black-box
option, and (2) returning the agent to states in the learned initiation set of
the black-box option where it is already optimal. We show that these two
variants are equivalent in performance under some conditions. Through a series
of experiments in simulated environments, we demonstrate that our framework
performs excellently in sparse reward problems given (sub-)optimal source
policies and improves upon prior art in transfer methods such as continual
learning and progressive networks, which lack our framework's desirable
theoretical properties.
</p>
<a href="http://arxiv.org/abs/2012.14942" target="_blank">arXiv:2012.14942</a> [<a href="http://arxiv.org/pdf/2012.14942" target="_blank">pdf</a>]

<h2>Learning non-stationary Langevin dynamics from stochastic observations of latent trajectories. (arXiv:2012.14944v1 [stat.ML])</h2>
<h3>Mikhail Genkin, Owen Hughes, Tatiana A. Engel</h3>
<p>Many complex systems operating far from the equilibrium exhibit stochastic
dynamics that can be described by a Langevin equation. Inferring Langevin
equations from data can reveal how transient dynamics of such systems give rise
to their function. However, dynamics are often inaccessible directly and can be
only gleaned through a stochastic observation process, which makes the
inference challenging. Here we present a non-parametric framework for inferring
the Langevin equation, which explicitly models the stochastic observation
process and non-stationary latent dynamics. The framework accounts for the
non-equilibrium initial and final states of the observed system and for the
possibility that the system's dynamics define the duration of observations.
Omitting any of these non-stationary components results in incorrect inference,
in which erroneous features arise in the dynamics due to non-stationary data
distribution. We illustrate the framework using models of neural dynamics
underlying decision making in the brain.
</p>
<a href="http://arxiv.org/abs/2012.14944" target="_blank">arXiv:2012.14944</a> [<a href="http://arxiv.org/pdf/2012.14944" target="_blank">pdf</a>]

<h2>2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition. (arXiv:2012.14950v1 [cs.CV])</h2>
<h3>Hengduo Li, Zuxuan Wu, Abhinav Shrivastava, Larry S. Davis</h3>
<p>3D convolutional networks are prevalent for video recognition. While
achieving excellent recognition performance on standard benchmarks, they
operate on a sequence of frames with 3D convolutions and thus are
computationally demanding. Exploiting large variations among different videos,
we introduce Ada3D, a conditional computation framework that learns
instance-specific 3D usage policies to determine frames and convolution layers
to be used in a 3D network. These policies are derived with a two-head
lightweight selection network conditioned on each input video clip. Then, only
frames and convolutions that are selected by the selection network are used in
the 3D model to generate predictions. The selection network is optimized with
policy gradient methods to maximize a reward that encourages making correct
predictions with limited computation. We conduct experiments on three video
recognition benchmarks and demonstrate that our method achieves similar
accuracies to state-of-the-art 3D models while requiring 20%-50% less
computation across different datasets. We also show that learned policies are
transferable and Ada3D is compatible to different backbones and modern clip
selection approaches. Our qualitative analysis indicates that our method
allocates fewer 3D convolutions and frames for "static" inputs, yet uses more
for motion-intensive clips.
</p>
<a href="http://arxiv.org/abs/2012.14950" target="_blank">arXiv:2012.14950</a> [<a href="http://arxiv.org/pdf/2012.14950" target="_blank">pdf</a>]

<h2>Bridging Cost-sensitive and Neyman-Pearson Paradigms for Asymmetric Binary Classification. (arXiv:2012.14951v1 [stat.ML])</h2>
<h3>Wei Vivian Li, Xin Tong, Jingyi Jessica Li</h3>
<p>Asymmetric binary classification problems, in which the type I and II errors
have unequal severity, are ubiquitous in real-world applications. To handle
such asymmetry, researchers have developed the cost-sensitive and
Neyman-Pearson paradigms for training classifiers to control the more severe
type of classification error, say the type I error. The cost-sensitive paradigm
is widely used and has straightforward implementations that do not require
sample splitting; however, it demands an explicit specification of the costs of
the type I and II errors, and an open question is what specification can
guarantee a high-probability control on the population type I error. In
contrast, the Neyman-Pearson paradigm can train classifiers to achieve a
high-probability control of the population type I error, but it relies on
sample splitting that reduces the effective training sample size. Since the two
paradigms have complementary strengths, it is reasonable to combine their
strengths for classifier construction. In this work, we for the first time
study the methodological connections between the two paradigms, and we develop
the TUBE-CS algorithm to bridge the two paradigms from the perspective of
controlling the population type I error.
</p>
<a href="http://arxiv.org/abs/2012.14951" target="_blank">arXiv:2012.14951</a> [<a href="http://arxiv.org/pdf/2012.14951" target="_blank">pdf</a>]

<h2>Towards Fair Deep Anomaly Detection. (arXiv:2012.14961v1 [cs.LG])</h2>
<h3>Hongjing Zhang, Ian Davidson</h3>
<p>Anomaly detection aims to find instances that are considered unusual and is a
fundamental problem of data science. Recently, deep anomaly detection methods
were shown to achieve superior results particularly in complex data such as
images. Our work focuses on deep one-class classification for anomaly detection
which learns a mapping only from the normal samples. However, the non-linear
transformation performed by deep learning can potentially find patterns
associated with social bias. The challenge with adding fairness to deep anomaly
detection is to ensure both making fair and correct anomaly predictions
simultaneously. In this paper, we propose a new architecture for the fair
anomaly detection approach (Deep Fair SVDD) and train it using an adversarial
network to de-correlate the relationships between the sensitive attributes and
the learned representations. This differs from how fairness is typically added
namely as a regularizer or a constraint. Further, we propose two effective
fairness measures and empirically demonstrate that existing deep anomaly
detection methods are unfair. We show that our proposed approach can remove the
unfairness largely with minimal loss on the anomaly detection performance.
Lastly, we conduct an in-depth analysis to show the strength and limitations of
our proposed model, including parameter analysis, feature visualization, and
run-time analysis.
</p>
<a href="http://arxiv.org/abs/2012.14961" target="_blank">arXiv:2012.14961</a> [<a href="http://arxiv.org/pdf/2012.14961" target="_blank">pdf</a>]

<h2>Improving Adversarial Robustness in Weight-quantized Neural Networks. (arXiv:2012.14965v1 [cs.LG])</h2>
<h3>Chang Song, Elias Fallon, Hai Li</h3>
<p>Neural networks are getting deeper and more computation-intensive nowadays.
Quantization is a useful technique in deploying neural networks on hardware
platforms and saving computation costs with negligible performance loss.
However, recent research reveals that neural network models, no matter
full-precision or quantized, are vulnerable to adversarial attacks. In this
work, we analyze both adversarial and quantization losses and then introduce
criteria to evaluate them. We propose a boundary-based retraining method to
mitigate adversarial and quantization losses together and adopt a nonlinear
mapping method to defend against white-box gradient-based adversarial attacks.
The evaluations demonstrate that our method can better restore accuracy after
quantization than other baseline methods on both black-box and white-box
adversarial attacks. The results also show that adversarial training suffers
quantization loss and does not cooperate well with other training methods.
</p>
<a href="http://arxiv.org/abs/2012.14965" target="_blank">arXiv:2012.14965</a> [<a href="http://arxiv.org/pdf/2012.14965" target="_blank">pdf</a>]

<h2>Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps. (arXiv:2012.14966v1 [cs.LG])</h2>
<h3>Tri Dao, Nimit S. Sohoni, Albert Gu, Matthew Eichhorn, Amit Blonder, Megan Leszczynski, Atri Rudra, Christopher R&#xe9;</h3>
<p>Modern neural network architectures use structured linear transformations,
such as low-rank matrices, sparse matrices, permutations, and the Fourier
transform, to improve inference speed and reduce memory usage compared to
general linear maps. However, choosing which of the myriad structured
transformations to use (and its associated parameterization) is a laborious
task that requires trading off speed, space, and accuracy. We consider a
different approach: we introduce a family of matrices called kaleidoscope
matrices (K-matrices) that provably capture any structured matrix with
near-optimal space (parameter) and time (arithmetic operation) complexity. We
empirically validate that K-matrices can be automatically learned within
end-to-end pipelines to replace hand-crafted procedures, in order to improve
model quality. For example, replacing channel shuffles in ShuffleNet improves
classification accuracy on ImageNet by up to 5%. K-matrices can also simplify
hand-engineered pipelines -- we replace filter bank feature computation in
speech data preprocessing with a learnable kaleidoscope layer, resulting in
only 0.4% loss in accuracy on the TIMIT speech recognition task. In addition,
K-matrices can capture latent structure in models: for a challenging permuted
image classification task, a K-matrix based representation of permutations is
able to learn the right latent structure and improves accuracy of a downstream
convolutional model by over 9%. We provide a practically efficient
implementation of our approach, and use K-matrices in a Transformer network to
attain 36% faster end-to-end inference speed on a language translation task.
</p>
<a href="http://arxiv.org/abs/2012.14966" target="_blank">arXiv:2012.14966</a> [<a href="http://arxiv.org/pdf/2012.14966" target="_blank">pdf</a>]

<h2>Alternative Paths Planner (APP) for Provably Fixed-time Manipulation Planning in Semi-structured Environments. (arXiv:2012.14970v1 [cs.RO])</h2>
<h3>Fahad Islam, Chris Paxton, Clemens Eppner, Bryan Peele, Maxim Likhachev, Dieter Fox</h3>
<p>In many applications, including logistics and manufacturing, robot
manipulators operate in semi-structured environments alongside humans or other
robots. These environments are largely static, but they may contain some
movable obstacles that the robot must avoid. Manipulation tasks in these
applications are often highly repetitive, but require fast and reliable motion
planning capabilities, often under strict time constraints. Existing
preprocessing-based approaches are beneficial when the environments are
highly-structured, but their performance degrades in the presence of movable
obstacles, since these are not modelled a priori. We propose a novel
preprocessing-based method called Alternative Paths Planner (APP) that provides
provably fixed-time planning guarantees in semi-structured environments. APP
plans a set of alternative paths offline such that, for any configuration of
the movable obstacles, at least one of the paths from this set is
collision-free. During online execution, a collision-free path can be looked up
efficiently within a few microseconds. We evaluate APP on a 7 DoF robot arm in
semi-structured domains of varying complexity and demonstrate that APP is
several orders of magnitude faster than state-of-the-art motion planners for
each domain. We further validate this approach with real-time experiments on a
robotic manipulator.
</p>
<a href="http://arxiv.org/abs/2012.14970" target="_blank">arXiv:2012.14970</a> [<a href="http://arxiv.org/pdf/2012.14970" target="_blank">pdf</a>]

<h2>Perimeter-defense Game between Aerial Defender and Ground Intruder. (arXiv:2012.14980v1 [cs.RO])</h2>
<h3>Elijah S. Lee, Daigo Shishika, Vijay Kumar</h3>
<p>We study a variant of pursuit-evasion game in the context of perimeter
defense. In this problem, the intruder aims to reach the base plane of a
hemisphere without being captured by the defender, while the defender tries to
capture the intruder. The perimeter-defense game was previously studied under
the assumption that the defender moves on a circle. We extend the problem to
the case where the defender moves on a hemisphere. To solve this problem, we
analyze the strategies based on the breaching point at which the intruder tries
to reach the target and predict the goal position, defined as optimal breaching
point, that is achieved by the optimal strategies on both players. We provide
the barrier that divides the state space into defender-winning and
intruder-winning regions and prove that the optimal strategies for both players
are to move towards the optimal breaching point. Simulation results are
presented to demonstrate that the optimality of the game is given as a Nash
equilibrium.
</p>
<a href="http://arxiv.org/abs/2012.14980" target="_blank">arXiv:2012.14980</a> [<a href="http://arxiv.org/pdf/2012.14980" target="_blank">pdf</a>]

<h2>Elastic Net based Feature Ranking and Selection. (arXiv:2012.14982v1 [cs.LG])</h2>
<h3>Shaode Yu, Haobo Chen, Hang Yu, Zhicheng Zhang, Xiaokun Liang, Wenjian Qin, Yaoqin Xie, Ping Shi</h3>
<p>Feature selection is important in data representation and intelligent
diagnosis. Elastic net is one of the most widely used feature selectors.
However, the features selected are dependant on the training data, and their
weights dedicated for regularized regression are irrelevant to their importance
if used for feature ranking, that degrades the model interpretability and
extension. In this study, an intuitive idea is put at the end of multiple times
of data splitting and elastic net based feature selection. It concerns the
frequency of selected features and uses the frequency as an indicator of
feature importance. After features are sorted according to their frequency,
linear support vector machine performs the classification in an incremental
manner. At last, a compact subset of discriminative features is selected by
comparing the prediction performance. Experimental results on breast cancer
data sets (BCDR-F03, WDBC, GSE 10810, and GSE 15852) suggest that the proposed
framework achieves competitive or superior performance to elastic net and with
consistent selection of fewer features. How to further enhance its consistency
on high-dimension small-sample-size data sets should be paid more attention in
our future work. The proposed framework is accessible online
(https://github.com/NicoYuCN/elasticnetFR).
</p>
<a href="http://arxiv.org/abs/2012.14982" target="_blank">arXiv:2012.14982</a> [<a href="http://arxiv.org/pdf/2012.14982" target="_blank">pdf</a>]

<h2>DeepSphere: a graph-based spherical CNN. (arXiv:2012.15000v1 [cs.LG])</h2>
<h3>Micha&#xeb;l Defferrard, Martino Milani, Fr&#xe9;d&#xe9;rick Gusset, Nathana&#xeb;l Perraudin</h3>
<p>Designing a convolution for a spherical neural network requires a delicate
tradeoff between efficiency and rotation equivariance. DeepSphere, a method
based on a graph representation of the sampled sphere, strikes a controllable
balance between these two desiderata. This contribution is twofold. First, we
study both theoretically and empirically how equivariance is affected by the
underlying graph with respect to the number of vertices and neighbors. Second,
we evaluate DeepSphere on relevant problems. Experiments show state-of-the-art
performance and demonstrates the efficiency and flexibility of this
formulation. Perhaps surprisingly, comparison with previous work suggests that
anisotropic filters might be an unnecessary price to pay. Our code is available
at https://github.com/deepsphere
</p>
<a href="http://arxiv.org/abs/2012.15000" target="_blank">arXiv:2012.15000</a> [<a href="http://arxiv.org/pdf/2012.15000" target="_blank">pdf</a>]

<h2>Infer-AVAE: An Attribute Inference Model Based on Adversarial Variational Autoencoder. (arXiv:2012.15005v1 [cs.LG])</h2>
<h3>Yadong Zhou, Zhihao Ding, Xiaoming Liu, Chao Shen, Lingling Tong, Xiaohong Guan</h3>
<p>Facing the sparsity of user attributes on social networks, attribute
inference aims at inferring missing attributes based on existing data and
additional information such as social connections between users. Recently,
Variational Autoencoders (VAEs) have been successfully applied to solve the
problem in a semi-supervised way. However, the latent representations learned
by the encoder contain either insufficient or useless information: i) MLPs can
successfully reconstruct the input data but fail in completing missing part,
ii) GNNs merge information according to social connections but suffer from
over-smoothing, which is a common problem with GNNs. Moreover, existing methods
neglect regulating the decoder, as a result, it lacks adequate inference
ability and faces severe overfitting. To address the above issues, we propose
an attribute inference model based on adversarial VAE (Infer-AVAE). Our model
deliberately unifies MLPs and GNNs in encoder to learn dual latent
representations: one contains only the observed attributes of each user, the
other converges extra information from the neighborhood. Then, an adversarial
network is trained to leverage the differences between the two representations
and adversarial training is conducted to guide GNNs using MLPs for robust
representations. What's more, mutual information constraint is introduced in
loss function to specifically train the decoder as a discriminator. Thus, it
can make better use of auxiliary information in the representations for
attribute inference. Based on real-world social network datasets, experimental
results demonstrate that our model averagely outperforms state-of-art by 7.0%
in accuracy.
</p>
<a href="http://arxiv.org/abs/2012.15005" target="_blank">arXiv:2012.15005</a> [<a href="http://arxiv.org/pdf/2012.15005" target="_blank">pdf</a>]

<h2>Dynamic Graph-Based Anomaly Detection in the Electrical Grid. (arXiv:2012.15006v1 [cs.LG])</h2>
<h3>Shimiao Li, Bryan Hooi, Amritanshu Pandey, Christos Faloutsos, Larry Pileggi</h3>
<p>Given sensor readings over time from a power grid, how can we accurately
detect when an anomaly occurs? A key part of achieving this goal is to use the
network of power grid sensors to quickly detect, in real-time, when any unusual
events, whether natural faults or malicious, occur on the power grid. Existing
bad-data detectors in the industry lack the sophistication to robustly detect
broad types of anomalies, especially those due to emerging cyber-attacks, since
they operate on a single measurement snapshot of the grid at a time. New ML
methods are more widely applicable, but generally do not consider the impact of
topology change on sensor measurements and thus cannot accommodate regular
topology adjustments in historical data. Hence, we propose DYNWATCH, a domain
knowledge based and topology-aware algorithm for anomaly detection using
sensors placed on a dynamic grid. Our approach is accurate, outperforming
existing approaches by 20% or more (F-measure) in experiments; and fast,
running in less than 1.7ms on average per time tick per sensor on a 60K+ branch
case using a laptop computer, and scaling linearly in the size of the graph.
</p>
<a href="http://arxiv.org/abs/2012.15006" target="_blank">arXiv:2012.15006</a> [<a href="http://arxiv.org/pdf/2012.15006" target="_blank">pdf</a>]

<h2>ALVIO: Adaptive Line and Point Feature-based Visual Inertial Odometry for Robust Localization in Indoor Environments. (arXiv:2012.15008v1 [cs.RO])</h2>
<h3>KwangYik Jung, YeEun Kim, HyunJun Lim, Hyun Myung</h3>
<p>The amount of texture can be rich or deficient depending on the objects and
the structures of the building. The conventional mono visual-initial navigation
system (VINS)-based localization techniques perform well in environments where
stable features are guaranteed. However, their performance is not assured in a
changing indoor environment. As a solution to this, we propose Adaptive Line
and point feature-based Visual Inertial Odometry (ALVIO) in this paper. ALVIO
actively exploits the geometrical information of lines that exist in abundance
in an indoor space. By using a strong line tracker and adaptive selection of
feature-based tightly coupled optimization, it is possible to perform robust
localization in a variable texture environment. The structural characteristics
of ALVIO are as follows: First, the proposed optical flow-based line tracker
performs robust line feature tracking and management. By using epipolar
geometry and trigonometry, accurate 3D lines are recovered. These 3D lines are
used to calculate the line re-projection error. Finally, with the
sensitivity-analysis-based adaptive feature selection in the optimization
process, we can estimate the pose robustly in various indoor environments. We
validate the performance of our system on public datasets and compare it
against other state-of the-art algorithms (S-MSKCF, VINS-Mono). In the proposed
algorithm based on point and line feature selection, translation RMSE increased
by 16.06% compared to VINS-Mono, while total optimization time decreased by up
to 49.31%. Through this, we proved that it is a useful algorithm as a real-time
pose estimation algorithm.
</p>
<a href="http://arxiv.org/abs/2012.15008" target="_blank">arXiv:2012.15008</a> [<a href="http://arxiv.org/pdf/2012.15008" target="_blank">pdf</a>]

<h2>Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients. (arXiv:2012.15019v1 [cs.LG])</h2>
<h3>Chris Cundy, Stefano Ermon</h3>
<p>As reinforcement learning techniques are increasingly applied to real-world
decision problems, attention has turned to how these algorithms use potentially
sensitive information. We consider the task of training a policy that maximizes
reward while minimizing disclosure of certain sensitive state variables through
the actions. We give examples of how this setting covers real-world problems in
privacy for sequential decision-making. We solve this problem in the policy
gradients framework by introducing a regularizer based on the mutual
information (MI) between the sensitive state and the actions at a given
timestep. We develop a model-based stochastic gradient estimator for
optimization of privacy-constrained policies. We also discuss an alternative MI
regularizer that serves as an upper bound to our main MI regularizer and can be
optimized in a model-free setting. We contrast previous work in
differentially-private RL to our mutual-information formulation of information
disclosure. Experimental results show that our training method results in
policies which hide the sensitive state.
</p>
<a href="http://arxiv.org/abs/2012.15019" target="_blank">arXiv:2012.15019</a> [<a href="http://arxiv.org/pdf/2012.15019" target="_blank">pdf</a>]

<h2>Towards Unsupervised Deep Image Enhancement with Generative Adversarial Network. (arXiv:2012.15020v1 [cs.CV])</h2>
<h3>Zhangkai Ni, Wenhan Yang, Shiqi Wang, Lin Ma, Sam Kwong</h3>
<p>Improving the aesthetic quality of images is challenging and eager for the
public. To address this problem, most existing algorithms are based on
supervised learning methods to learn an automatic photo enhancer for paired
data, which consists of low-quality photos and corresponding expert-retouched
versions. However, the style and characteristics of photos retouched by experts
may not meet the needs or preferences of general users. In this paper, we
present an unsupervised image enhancement generative adversarial network
(UEGAN), which learns the corresponding image-to-image mapping from a set of
images with desired characteristics in an unsupervised manner, rather than
learning on a large number of paired images. The proposed model is based on
single deep GAN which embeds the modulation and attention mechanisms to capture
richer global and local features. Based on the proposed model, we introduce two
losses to deal with the unsupervised image enhancement: (1) fidelity loss,
which is defined as a L2 regularization in the feature domain of a pre-trained
VGG network to ensure the content between the enhanced image and the input
image is the same, and (2) quality loss that is formulated as a relativistic
hinge adversarial loss to endow the input image the desired characteristics.
Both quantitative and qualitative results show that the proposed model
effectively improves the aesthetic quality of images. Our code is available at:
https://github.com/eezkni/UEGAN.
</p>
<a href="http://arxiv.org/abs/2012.15020" target="_blank">arXiv:2012.15020</a> [<a href="http://arxiv.org/pdf/2012.15020" target="_blank">pdf</a>]

<h2>Adaptive Graph Diffusion Networks with Hop-wise Attention. (arXiv:2012.15024v1 [cs.LG])</h2>
<h3>Chuxiong Sun, Guoshi Wu</h3>
<p>Graph Neural Networks (GNNs) have received much attention recent years and
have achieved state-of-the-art performances in many fields. The deeper GNNs can
theoretically capture deeper neighborhood information. However, they often
suffer from problems of over-fitting and over-smoothing. In order to
incorporate deeper information while preserving considerable complexity and
generalization ability, we propose Adaptive Graph Diffusion Networks with
Hop-wise Attention (AGDNs-HA). We stack multi-hop neighborhood aggregations of
different orders into single layer. Then we integrate them with the help of
hop-wise attention, which is learnable and adaptive for each node. Experimental
results on the standard dataset with semi-supervised node classification task
show that our proposed methods achieve significant improvements.
</p>
<a href="http://arxiv.org/abs/2012.15024" target="_blank">arXiv:2012.15024</a> [<a href="http://arxiv.org/pdf/2012.15024" target="_blank">pdf</a>]

<h2>NBNet: Noise Basis Learning for Image Denoising with Subspace Projection. (arXiv:2012.15028v1 [cs.CV])</h2>
<h3>Shen Cheng, Yuzhi Wang, Haibin Huang, Donghao Liu, Haoqiang Fan, Shuaicheng Liu</h3>
<p>In this paper, we introduce NBNet, a novel framework for image denoising.
Unlike previous works, we propose to tackle this challenging problem from a new
perspective: noise reduction by image-adaptive projection. Specifically, we
propose to train a network that can separate signal and noise by learning a set
of reconstruction basis in the feature space. Subsequently, image denosing can
be achieved by selecting corresponding basis of the signal subspace and
projecting the input into such space. Our key insight is that projection can
naturally maintain the local structure of input signal, especially for areas
with low light or weak textures. Towards this end, we propose SSA, a non-local
subspace attention module designed explicitly to learn the basis generation as
well as the subspace projection. We further incorporate SSA with NBNet, a UNet
structured network designed for end-to-end image denosing. We conduct
evaluations on benchmarks, including SIDD and DND, and NBNet achieves
state-of-the-art performance on PSNR and SSIM with significantly less
computational cost.
</p>
<a href="http://arxiv.org/abs/2012.15028" target="_blank">arXiv:2012.15028</a> [<a href="http://arxiv.org/pdf/2012.15028" target="_blank">pdf</a>]

<h2>Equipment Failure Analysis for Oil and Gas Industry with an Ensemble Predictive Model. (arXiv:2012.15030v1 [cs.LG])</h2>
<h3>Chen ZhiYuan, Olugbenro. O. Selere, Nicholas Lu Chee Seng</h3>
<p>This paper aims at improving the classification accuracy of a Support Vector
Machine (SVM) classifier with Sequential Minimal Optimization (SMO) training
algorithm in order to properly classify failure and normal instances from oil
and gas equipment data. Recent applications of failure analysis have made use
of the SVM technique without implementing SMO training algorithm, while in our
study we show that the proposed solution can perform much better when using the
SMO training algorithm. Furthermore, we implement the ensemble approach, which
is a hybrid rule based and neural network classifier to improve the performance
of the SVM classifier (with SMO training algorithm). The optimization study is
as a result of the underperformance of the classifier when dealing with
imbalanced dataset. The selected best performing classifiers are combined
together with SVM classifier (with SMO training algorithm) by using the
stacking ensemble method which is to create an efficient ensemble predictive
model that can handle the issue of imbalanced data. The classification
performance of this predictive model is considerably better than the SVM with
and without SMO training algorithm and many other conventional classifiers.
</p>
<a href="http://arxiv.org/abs/2012.15030" target="_blank">arXiv:2012.15030</a> [<a href="http://arxiv.org/pdf/2012.15030" target="_blank">pdf</a>]

<h2>Unsupervised Real Time Prediction of Faults Using the Support Vector Machine. (arXiv:2012.15032v1 [cs.LG])</h2>
<h3>Zhiyuan Chen, Isa Dino, Nik Ahmad Akram</h3>
<p>This paper aims at improving the classification accuracy of a Support Vector
Machine (SVM) classifier with Sequential Minimal Optimization (SMO) training
algorithm in order to properly classify failure and normal instances from oil
and gas equipment data. Recent applications of failure analysis have made use
of the SVM technique without implementing SMO training algorithm, while in our
study we show that the proposed solution can perform much better when using the
SMO training algorithm. Furthermore, we implement the ensemble approach, which
is a hybrid rule based and neural network classifier to improve the performance
of the SVM classifier (with SMO training algorithm). The optimization study is
as a result of the underperformance of the classifier when dealing with
imbalanced dataset. The selected best performing classifiers are combined
together with SVM classifier (with SMO training algorithm) by using the
stacking ensemble method which is to create an efficient ensemble predictive
model that can handle the issue of imbalanced data. The classification
performance of this predictive model is considerably better than the SVM with
and without SMO training algorithm and many other conventional classifiers.
</p>
<a href="http://arxiv.org/abs/2012.15032" target="_blank">arXiv:2012.15032</a> [<a href="http://arxiv.org/pdf/2012.15032" target="_blank">pdf</a>]

<h2>SGD Distributional Dynamics of Three Layer Neural Networks. (arXiv:2012.15036v1 [cs.LG])</h2>
<h3>Victor Luo, Yazhen Wang, Glenn Fung</h3>
<p>With the rise of big data analytics, multi-layer neural networks have
surfaced as one of the most powerful machine learning methods. However, their
theoretical mathematical properties are still not fully understood. Training a
neural network requires optimizing a non-convex objective function, typically
done using stochastic gradient descent (SGD). In this paper, we seek to extend
the mean field results of Mei et al. (2018) from two-layer neural networks with
one hidden layer to three-layer neural networks with two hidden layers. We will
show that the SGD dynamics is captured by a set of non-linear partial
differential equations, and prove that the distributions of weights in the two
hidden layers are independent. We will also detail exploratory work done based
on simulation and real-world data.
</p>
<a href="http://arxiv.org/abs/2012.15036" target="_blank">arXiv:2012.15036</a> [<a href="http://arxiv.org/pdf/2012.15036" target="_blank">pdf</a>]

<h2>Joint Air Quality and Weather Prediction Based on Multi-Adversarial Spatiotemporal Networks. (arXiv:2012.15037v1 [cs.LG])</h2>
<h3>Jindong Han, Hao Liu, Hengshu Zhu, Hui Xiong, Dejing Dou</h3>
<p>Accurate and timely air quality and weather predictions are of great
importance to urban governance and human livelihood. Though many efforts have
been made for air quality or weather prediction, most of them simply employ one
another as feature input, which ignores the inner-connection between two
predictive tasks. On the one hand, the accurate prediction of one task can help
improve another task's performance. On the other hand, geospatially distributed
air quality and weather monitoring stations provide additional hints for
city-wide spatiotemporal dependency modeling. Inspired by the above two
insights, in this paper, we propose the Multi-adversarial spatiotemporal
recurrent Graph Neural Networks (MasterGNN) for joint air quality and weather
predictions. Specifically, we first propose a heterogeneous recurrent graph
neural network to model the spatiotemporal autocorrelation among air quality
and weather monitoring stations. Then, we develop a multi-adversarial graph
learning framework to against observation noise propagation introduced by
spatiotemporal modeling. Moreover, we present an adaptive training strategy by
formulating multi-adversarial learning as a multi-task learning problem.
Finally, extensive experiments on two real-world datasets show that MasterGNN
achieves the best performance compared with seven baselines on both air quality
and weather prediction tasks.
</p>
<a href="http://arxiv.org/abs/2012.15037" target="_blank">arXiv:2012.15037</a> [<a href="http://arxiv.org/pdf/2012.15037" target="_blank">pdf</a>]

<h2>Damaged Fingerprint Recognition by Convolutional Long Short-Term Memory Networks for Forensic Purposes. (arXiv:2012.15041v1 [cs.CV])</h2>
<h3>Jaouhar Fattahi, Mohamed Mejri</h3>
<p>Fingerprint recognition is often a game-changing step in establishing
evidence against criminals. However, we are increasingly finding that criminals
deliberately alter their fingerprints in a variety of ways to make it difficult
for technicians and automatic sensors to recognize their fingerprints, making
it tedious for investigators to establish strong evidence against them in a
forensic procedure. In this sense, deep learning comes out as a prime candidate
to assist in the recognition of damaged fingerprints. In particular,
convolution algorithms. In this paper, we focus on the recognition of damaged
fingerprints by Convolutional Long Short-Term Memory networks. We present the
architecture of our model and demonstrate its performance which exceeds 95%
accuracy, 99% precision, and approaches 95% recall and 99% AUC.
</p>
<a href="http://arxiv.org/abs/2012.15041" target="_blank">arXiv:2012.15041</a> [<a href="http://arxiv.org/pdf/2012.15041" target="_blank">pdf</a>]

<h2>SkiNet: A Deep Learning Solution for Skin Lesion Diagnosis with Uncertainty Estimation and Explainability. (arXiv:2012.15049v1 [cs.CV])</h2>
<h3>Rajeev Kumar Singh, Rohan Gorantla, Sai Giridhar Allada, Narra Pratap</h3>
<p>Skin cancer is considered to be the most common human malignancy. Around 5
million new cases of skin cancer are recorded in the United States annually.
Early identification and evaluation of skin lesions is of great clinical
significance, but the disproportionate dermatologist-patient ratio poses
significant problem in most developing nations. Therefore a deep learning based
architecture, known as SkiNet, is proposed with an objective to provide faster
screening solution and assistance to newly trained physicians in the clinical
diagnosis process. The main motive behind Skinet's design and development is to
provide a white box solution, addressing a critical problem of trust and
interpretability which is crucial for the wider adoption of Computer-aided
diagnosis systems by the medical practitioners. SkiNet is a two-stage pipeline
wherein the lesion segmentation is followed by the lesion classification. In
our SkiNet methodology, Monte Carlo dropout and test time augmentation
techniques have been employed to estimate epistemic and aleatoric uncertainty,
while saliency-based methods are explored to provide post-hoc explanations of
the deep learning models. The publicly available dataset, ISIC-2018, is used to
perform experimentation and ablation studies. The results establish the
robustness of the model on the traditional benchmarks while addressing the
black-box nature of such models to alleviate the skepticism of medical
practitioners by incorporating transparency and confidence to the model's
prediction.
</p>
<a href="http://arxiv.org/abs/2012.15049" target="_blank">arXiv:2012.15049</a> [<a href="http://arxiv.org/pdf/2012.15049" target="_blank">pdf</a>]

<h2>Bidirectional Mapping Coupled GAN for Generalized Zero-Shot Learning. (arXiv:2012.15054v1 [cs.CV])</h2>
<h3>Tasfia Shermin, Shyh Wei Teng, Ferdous Sohel, Manzur Murshed, Guojun Lu</h3>
<p>Bidirectional mapping-based generative models have achieved remarkable
performance for the generalized zero-shot learning (GZSL) recognition by
learning to construct visual features from class semantics and reconstruct
class semantics back from generated visual features. The performance of these
models relies on the quality of synthesized features. This depends on the
ability of the model to capture the underlying seen data distribution by
relating semantic-visual spaces, learning discriminative information, and
re-purposing the learned distribution to recognize unseen data. This means
learning the seen-unseen domains joint distribution is crucial for GZSL tasks.
However, existing models only learn the underlying distribution of the seen
domain as unseen data is inaccessible. In this work, we propose to utilize the
available unseen class semantics along with seen class semantics and learn
dual-domain joint distribution through a strong visual-semantic coupling.
Therefore, we propose a bidirectional mapping coupled generative adversarial
network (BMCoGAN) by extending the coupled generative adversarial network
(CoGAN) into a dual-domain learning bidirectional mapping model. We further
integrate a Wasserstein generative adversarial optimization to supervise the
joint distribution learning. For retaining distinctive information in the
synthesized visual space and reducing bias towards seen classes, we design an
optimization, which pushes synthesized seen features towards real seen features
and pulls synthesized unseen features away from real seen features. We evaluate
BMCoGAN on several benchmark datasets against contemporary methods and show its
superior performance. Also, we present ablative analysis to demonstrate the
importance of different components in BMCoGAN.
</p>
<a href="http://arxiv.org/abs/2012.15054" target="_blank">arXiv:2012.15054</a> [<a href="http://arxiv.org/pdf/2012.15054" target="_blank">pdf</a>]

<h2>Ensembles of Localised Models for Time Series Forecasting. (arXiv:2012.15059v1 [cs.LG])</h2>
<h3>Rakshitha Godahewa, Kasun Bandara, Geoffrey I. Webb, Slawek Smyl, Christoph Bergmeir</h3>
<p>With large quantities of data typically available nowadays, forecasting
models that are trained across sets of time series, known as Global Forecasting
Models (GFM), are regularly outperforming traditional univariate forecasting
models that work on isolated series. As GFMs usually share the same set of
parameters across all time series, they often have the problem of not being
localised enough to a particular series, especially in situations where
datasets are heterogeneous. We study how ensembling techniques can be used with
generic GFMs and univariate models to solve this issue. Our work systematises
and compares relevant current approaches, namely clustering series and training
separate submodels per cluster, the so-called ensemble of specialists approach,
and building heterogeneous ensembles of global and local models. We fill some
gaps in the approaches and generalise them to different underlying GFM model
types. We then propose a new methodology of clustered ensembles where we train
multiple GFMs on different clusters of series, obtained by changing the number
of clusters and cluster seeds. Using Feed-forward Neural Networks, Recurrent
Neural Networks, and Pooled Regression models as the underlying GFMs, in our
evaluation on six publicly available datasets, the proposed models are able to
achieve significantly higher accuracy than baseline GFM models and univariate
forecasting methods.
</p>
<a href="http://arxiv.org/abs/2012.15059" target="_blank">arXiv:2012.15059</a> [<a href="http://arxiv.org/pdf/2012.15059" target="_blank">pdf</a>]

<h2>RTS3D: Real-time Stereo 3D Detection from 4D Feature-Consistency Embedding Space for Autonomous Driving. (arXiv:2012.15072v1 [cs.CV])</h2>
<h3>Peixuan Li, Shun Su, Huaici Zhao</h3>
<p>Although the recent image-based 3D object detection methods using
Pseudo-LiDAR representation have shown great capabilities, a notable gap in
efficiency and accuracy still exist compared with LiDAR-based methods. Besides,
over-reliance on the stand-alone depth estimator, requiring a large number of
pixel-wise annotations in the training stage and more computation in the
inferencing stage, limits the scaling application in the real world.

In this paper, we propose an efficient and accurate 3D object detection
method from stereo images, named RTS3D. Different from the 3D occupancy space
in the Pseudo-LiDAR similar methods, we design a novel 4D feature-consistent
embedding (FCE) space as the intermediate representation of the 3D scene
without depth supervision. The FCE space encodes the object's structural and
semantic information by exploring the multi-scale feature consistency warped
from stereo pair. Furthermore, a semantic-guided RBF (Radial Basis Function)
and a structure-aware attention module are devised to reduce the influence of
FCE space noise without instance mask supervision. Experiments on the KITTI
benchmark show that RTS3D is the first true real-time system (FPS$&gt;$24) for
stereo image 3D detection meanwhile achieves $10\%$ improvement in average
precision comparing with the previous state-of-the-art method. The code will be
available at https://github.com/Banconxuan/RTS3D
</p>
<a href="http://arxiv.org/abs/2012.15072" target="_blank">arXiv:2012.15072</a> [<a href="http://arxiv.org/pdf/2012.15072" target="_blank">pdf</a>]

<h2>Is Pessimism Provably Efficient for Offline RL?. (arXiv:2012.15085v1 [cs.LG])</h2>
<h3>Ying Jin, Zhuoran Yang, Zhaoran Wang</h3>
<p>We study offline reinforcement learning (RL), which aims to learn an optimal
policy based on a dataset collected a priori. Due to the lack of further
interactions with the environment, offline RL suffers from the insufficient
coverage of the dataset, which eludes most existing theoretical analysis. In
this paper, we propose a pessimistic variant of the value iteration algorithm
(PEVI), which incorporates an uncertainty quantifier as the penalty function.
Such a penalty function simply flips the sign of the bonus function for
promoting exploration in online RL, which makes it easily implementable and
compatible with general function approximators.

Without assuming the sufficient coverage of the dataset, we establish a
data-dependent upper bound on the suboptimality of PEVI for general Markov
decision processes (MDPs). When specialized to linear MDPs, it matches the
information-theoretic lower bound up to multiplicative factors of the dimension
and horizon. In other words, pessimism is not only provably efficient but also
minimax optimal. In particular, given the dataset, the learned policy serves as
the ``best effort'' among all policies, as no other policies can do better. Our
theoretical analysis identifies the critical role of pessimism in eliminating a
notion of spurious correlation, which emerges from the ``irrelevant''
trajectories that are less covered by the dataset and not informative for the
optimal policy.
</p>
<a href="http://arxiv.org/abs/2012.15085" target="_blank">arXiv:2012.15085</a> [<a href="http://arxiv.org/pdf/2012.15085" target="_blank">pdf</a>]

<h2>Explanations of Machine Learning predictions: a mandatory step for its application to Operational Processes. (arXiv:2012.15103v1 [cs.LG])</h2>
<h3>Giorgio Visani, Federico Chesani, Enrico Bagli, Davide Capuzzo, Alessandro Poluzzi</h3>
<p>In the global economy, credit companies play a central role in economic
development, through their activity as money lenders. This important task comes
with some drawbacks, mainly the risk of the debtors not being able to repay the
provided credit. Therefore, Credit Risk Modelling (CRM), namely the evaluation
of the probability that a debtor will not repay the due amount, plays a
paramount role. Statistical approaches have been successfully exploited since
long, becoming the most used methods for CRM. Recently, also machine and deep
learning techniques have been applied to the CRM task, showing an important
increase in prediction quality and performances. However, such techniques
usually do not provide reliable explanations for the scores they come up with.
As a consequence, many machine and deep learning techniques fail to comply with
western countries' regulations such as, for example, GDPR. In this paper we
suggest to use LIME (Local Interpretable Model-agnostic Explanations) technique
to tackle the explainability problem in this field, we show its employment on a
real credit-risk dataset and eventually discuss its soundness and the necessary
improvements to guarantee its adoption and compliance with the task.
</p>
<a href="http://arxiv.org/abs/2012.15103" target="_blank">arXiv:2012.15103</a> [<a href="http://arxiv.org/pdf/2012.15103" target="_blank">pdf</a>]

<h2>Perspective: A Phase Diagram for Deep Learning unifying Jamming, Feature Learning and Lazy Training. (arXiv:2012.15110v1 [cs.LG])</h2>
<h3>Mario Geiger, Leonardo Petrini, Matthieu Wyart</h3>
<p>Deep learning algorithms are responsible for a technological revolution in a
variety of tasks including image recognition or Go playing. Yet, why they work
is not understood. Ultimately, they manage to classify data lying in high
dimension -- a feat generically impossible due to the geometry of high
dimensional space and the associated curse of dimensionality. Understanding
what kind of structure, symmetry or invariance makes data such as images
learnable is a fundamental challenge. Other puzzles include that (i) learning
corresponds to minimizing a loss in high dimension, which is in general not
convex and could well get stuck bad minima. (ii) Deep learning predicting power
increases with the number of fitting parameters, even in a regime where data
are perfectly fitted. In this manuscript, we review recent results elucidating
(i,ii) and the perspective they offer on the (still unexplained) curse of
dimensionality paradox. We base our theoretical discussion on the $(h,\alpha)$
plane where $h$ is the network width and $\alpha$ the scale of the output of
the network at initialization, and provide new systematic measures of
performance in that plane for MNIST and CIFAR 10. We argue that different
learning regimes can be organized into a phase diagram. A line of critical
points sharply delimits an under-parametrised phase from an over-parametrized
one. In over-parametrized nets, learning can operate in two regimes separated
by a smooth cross-over. At large initialization, it corresponds to a kernel
method, whereas for small initializations features can be learnt, together with
invariants in the data. We review the properties of these different phases, of
the transition separating them and some open questions. Our treatment
emphasizes analogies with physical systems, scaling arguments and the
development of numerical observables to quantitatively test these results
empirically.
</p>
<a href="http://arxiv.org/abs/2012.15110" target="_blank">arXiv:2012.15110</a> [<a href="http://arxiv.org/pdf/2012.15110" target="_blank">pdf</a>]

<h2>DUT-LFSaliency: Versatile Dataset and Light Field-to-RGB Saliency Detection. (arXiv:2012.15124v1 [cs.CV])</h2>
<h3>Yongri Piao, Zhengkun Rong, Shuang Xu, Miao Zhang, Huchuan Lu</h3>
<p>Light field data exhibit favorable characteristics conducive to saliency
detection. The success of learning-based light field saliency detection is
heavily dependent on how a comprehensive dataset can be constructed for higher
generalizability of models, how high dimensional light field data can be
effectively exploited, and how a flexible model can be designed to achieve
versatility for desktop computers and mobile devices. To answer these
questions, first we introduce a large-scale dataset to enable versatile
applications for RGB, RGB-D and light field saliency detection, containing 102
classes and 4204 samples. Second, we present an asymmetrical two-stream model
consisting of the Focal stream and RGB stream. The Focal stream is designed to
achieve higher performance on desktop computers and transfer focusness
knowledge to the RGB stream, relying on two tailor-made modules. The RGB stream
guarantees the flexibility and memory/computation efficiency on mobile devices
through three distillation schemes. Experiments demonstrate that our Focal
stream achieves state-of-the-arts performance. The RGB stream achieves Top-2
F-measure on DUTLF-V2, which tremendously minimizes the model size by 83% and
boosts FPS by 5 times, compared with the best performing method. Furthermore,
our proposed distillation schemes are applicable to RGB saliency models,
achieving impressive performance gains while ensuring flexibility.
</p>
<a href="http://arxiv.org/abs/2012.15124" target="_blank">arXiv:2012.15124</a> [<a href="http://arxiv.org/pdf/2012.15124" target="_blank">pdf</a>]

<h2>MM-FSOD: Meta and metric integrated few-shot object detection. (arXiv:2012.15159v1 [cs.CV])</h2>
<h3>Yuewen Li, Wenquan Feng, Shuchang Lyu, Qi Zhao, Xuliang Li</h3>
<p>In the object detection task, CNN (Convolutional neural networks) models
always need a large amount of annotated examples in the training process. To
reduce the dependency of expensive annotations, few-shot object detection has
become an increasing research focus. In this paper, we present an effective
object detection framework (MM-FSOD) that integrates metric learning and
meta-learning to tackle the few-shot object detection task. Our model is a
class-agnostic detection model that can accurately recognize new categories,
which are not appearing in training samples. Specifically, to fast learn the
features of new categories without a fine-tuning process, we propose a
meta-representation module (MR module) to learn intra-class mean prototypes. MR
module is trained with a meta-learning method to obtain the ability to
reconstruct high-level features. To further conduct similarity of features
between support prototype with query RoIs features, we propose a Pearson metric
module (PR module) which serves as a classifier. Compared to the previous
commonly used metric method, cosine distance metric. PR module enables the
model to align features into discriminative embedding space. We conduct
extensive experiments on benchmark datasets FSOD, MS COCO, and PASCAL VOC to
demonstrate the feasibility and efficiency of our model. Comparing with the
previous method, MM-FSOD achieves state-of-the-art (SOTA) results.
</p>
<a href="http://arxiv.org/abs/2012.15159" target="_blank">arXiv:2012.15159</a> [<a href="http://arxiv.org/pdf/2012.15159" target="_blank">pdf</a>]

<h2>Analysis of Truck Driver Behavior to Design Different Lane Change Styles in Automated Driving. (arXiv:2012.15164v1 [cs.RO])</h2>
<h3>Zheng Wang, Muhua Guan, Jin Lan, Bo Yang, Tsutomu Kaizuka, Junichi Taki, Kimihiko Nakano</h3>
<p>Lane change is a very demanding driving task and number of traffic accidents
are induced by mistaken maneuvers. An automated lane change system has the
potential to reduce driver workload and to improve driving safety. One
challenge is how to improve driver acceptance on the automated system. From the
viewpoint of human factors, an automated system with different styles would
improve user acceptance as the drivers can adapt the style to different driving
situations. This paper proposes a method to design different lane change styles
in automated driving by analysis and modeling of truck driver behavior. A truck
driving simulator experiment with 12 participants was conducted to identify the
driver model parameters and three lane change styles were classified as the
aggressive, medium, and conservative ones. The proposed automated lane change
system was evaluated by another truck driving simulator experiment with the
same 12 participants. Moreover, the effect of different driving styles on
driver experience and acceptance was evaluated. The evaluation results
demonstrate that the different lane change styles could be distinguished by the
drivers; meanwhile, the three styles were overall evaluated as acceptable on
safety issues and reliable by the human drivers. This study provides insight
into designing the automated driving system with different driving styles and
the findings can be applied to commercial automated trucks.
</p>
<a href="http://arxiv.org/abs/2012.15164" target="_blank">arXiv:2012.15164</a> [<a href="http://arxiv.org/pdf/2012.15164" target="_blank">pdf</a>]

<h2>A Versatile Keyframe-Based Structureless Filter for Visual Inertial Odometry. (arXiv:2012.15170v1 [cs.RO])</h2>
<h3>Jianzhu Huai, Yukai Lin, Charles Toth, Yuan Zhuang, Dong Chen</h3>
<p>Motion estimation by fusing data from at least a camera and an Inertial
Measurement Unit (IMU) enables many applications in robotics. However, among
the multitude of Visual Inertial Odometry (VIO) methods, few efficiently
estimate device motion with consistent covariance, and calibrate sensor
parameters online for handling data from consumer sensors. This paper addresses
the gap with a Keyframe-based Structureless Filter (KSF). For efficiency,
landmarks are not included in the filter's state vector. For robustness, KSF
associates feature observations and manages state variables using the concept
of keyframes. For flexibility, KSF supports anytime calibration of IMU
systematic errors, as well as extrinsic, intrinsic, and temporal parameters of
each camera. Estimator consistency and observability of sensor parameters were
analyzed by simulation. Sensitivity to design options, e.g., feature matching
method and camera count was studied with the EuRoC benchmark. Sensor parameter
estimation was evaluated on raw TUM VI sequences and smartphone data. Moreover,
pose estimation accuracy was evaluated on EuRoC and TUM VI sequences versus
recent VIO methods. These tests confirm that KSF reliably calibrates sensor
parameters when the data contain adequate motion, and consistently estimate
motion with accuracy rivaling recent VIO methods. Our implementation runs at 42
Hz with stereo camera images on a consumer laptop.
</p>
<a href="http://arxiv.org/abs/2012.15170" target="_blank">arXiv:2012.15170</a> [<a href="http://arxiv.org/pdf/2012.15170" target="_blank">pdf</a>]

<h2>Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation. (arXiv:2012.15175v1 [cs.CV])</h2>
<h3>Zhengxiong Luo, Zhicheng Wang, Yan Huang, Tieniu Tan, Erjin Zhou</h3>
<p>Heatmap regression has become the most prevalent choice for nowadays human
pose estimation methods. The ground-truth heatmaps are usually constructed via
covering all skeletal keypoints by 2D gaussian kernels. The standard deviations
of these kernels are fixed. However, for bottom-up methods, which need to
handle a large variance of human scales and labeling ambiguities, the current
practice seems unreasonable. To better cope with these problems, we propose the
scale-adaptive heatmap regression (SAHR) method, which can adaptively adjust
the standard deviation for each keypoint. In this way, SAHR is more tolerant of
various human scales and labeling ambiguities. However, SAHR may aggravate the
imbalance between fore-background samples, which potentially hurts the
improvement of SAHR. Thus, we further introduce the weight-adaptive heatmap
regression (WAHR) to help balance the fore-background samples. Extensive
experiments show that SAHR together with WAHR largely improves the accuracy of
bottom-up human pose estimation. As a result, we finally outperform the
state-of-the-art model by $+1.5AP$ and achieve $72.0 AP$ on COCO test-dev2017,
which is comparable with the performances of most top-down methods.
</p>
<a href="http://arxiv.org/abs/2012.15175" target="_blank">arXiv:2012.15175</a> [<a href="http://arxiv.org/pdf/2012.15175" target="_blank">pdf</a>]

<h2>Temporally-Transferable Perturbations: Efficient, One-Shot Adversarial Attacks for Online Visual Object Trackers. (arXiv:2012.15183v1 [cs.CV])</h2>
<h3>Krishna Kanth Nakka, Mathieu Salzmann</h3>
<p>In recent years, the trackers based on Siamese networks have emerged as
highly effective and efficient for visual object tracking (VOT). While these
methods were shown to be vulnerable to adversarial attacks, as most deep
networks for visual recognition tasks, the existing attacks for VOT trackers
all require perturbing the search region of every input frame to be effective,
which comes at a non-negligible cost, considering that VOT is a real-time task.
In this paper, we propose a framework to generate a single temporally
transferable adversarial perturbation from the object template image only. This
perturbation can then be added to every search image, which comes at virtually
no cost, and still, successfully fool the tracker. Our experiments evidence
that our approach outperforms the state-of-the-art attacks on the standard VOT
benchmarks in the untargeted scenario. Furthermore, we show that our formalism
naturally extends to targeted attacks that force the tracker to follow any
given trajectory by precomputing diverse directional perturbations.
</p>
<a href="http://arxiv.org/abs/2012.15183" target="_blank">arXiv:2012.15183</a> [<a href="http://arxiv.org/pdf/2012.15183" target="_blank">pdf</a>]

<h2>Crossover-SGD: A gossip-based communication in distributed deep learning for alleviating large mini-batch problem and enhancing scalability. (arXiv:2012.15198v1 [cs.LG])</h2>
<h3>Sangho Yeo, Minho Bae, Minjoong Jeong, Oh-kyoung Kwon, Sangyoon Oh</h3>
<p>Distributed deep learning is an effective way to reduce the training time of
deep learning for large datasets as well as complex models. However, the
limited scalability caused by network overheads makes it difficult to
synchronize the parameters of all workers. To resolve this problem,
gossip-based methods that demonstrates stable scalability regardless of the
number of workers have been proposed. However, to use gossip-based methods in
general cases, the validation accuracy for a large mini-batch needs to be
verified. To verify this, we first empirically study the characteristics of
gossip methods in a large mini-batch problem and observe that the gossip
methods preserve higher validation accuracy than AllReduce-SGD(Stochastic
Gradient Descent) when the number of batch sizes is increased and the number of
workers is fixed. However, the delayed parameter propagation of the
gossip-based models decreases validation accuracy in large node scales. To cope
with this problem, we propose Crossover-SGD that alleviates the delay
propagation of weight parameters via segment-wise communication and load
balancing random network topology. We also adapt hierarchical communication to
limit the number of workers in gossip-based communication methods. To validate
the effectiveness of our proposed method, we conduct empirical experiments and
observe that our Crossover-SGD shows higher node scalability than
SGP(Stochastic Gradient Push).
</p>
<a href="http://arxiv.org/abs/2012.15198" target="_blank">arXiv:2012.15198</a> [<a href="http://arxiv.org/pdf/2012.15198" target="_blank">pdf</a>]

<h2>A Novel Resampling Technique for Imbalanced Dataset Optimization. (arXiv:2012.15231v1 [cs.LG])</h2>
<h3>Ivan Letteri, Antonio Di Cecco, Abeer Dyoub, Giuseppe Della Penna</h3>
<p>Despite the enormous amount of data, particular events of interest can still
be quite rare. Classification of rare events is a common problem in many
domains, such as fraudulent transactions, malware traffic analysis and network
intrusion detection. Many studies have been developed for malware detection
using machine learning approaches on various datasets, but as far as we know
only the MTA-KDD'19 dataset has the peculiarity of updating the representative
set of malicious traffic on a daily basis. This daily updating is the added
value of the dataset, but it translates into a potential due to the class
imbalance problem that the RRw-Optimized MTA-KDD'19 will occur. We capture
difficulties of class distribution in real datasets by considering four types
of minority class examples: safe, borderline, rare and outliers. In this work,
we developed two versions of Generative Silhouette Resampling 1-Nearest
Neighbour (G1Nos) oversampling algorithms for dealing with class imbalance
problem. The first module of G1Nos algorithms performs a coefficient-based
instance selection silhouette identifying the critical threshold of Imbalance
Degree. (ID), the second module generates synthetic samples using a SMOTE-like
oversampling algorithm. The balancing of the classes is done by our G1Nos
algorithms to re-establish the proportions between the two classes of the used
dataset. The experimental results show that our oversampling algorithm work
better than the other two SOTA methodologies in all the metrics considered.
</p>
<a href="http://arxiv.org/abs/2012.15231" target="_blank">arXiv:2012.15231</a> [<a href="http://arxiv.org/pdf/2012.15231" target="_blank">pdf</a>]

<h2>AI Development Race Can Be Mediated on Heterogeneous Networks. (arXiv:2012.15234v1 [cs.AI])</h2>
<h3>Theodor Cimpeanu, Francisco C. Santos, Luis Moniz Pereira, Tom Lenaerts, The Anh Han</h3>
<p>The field of Artificial Intelligence (AI) has been introducing a certain
level of anxiety in research, business and also policy. Tensions are further
heightened by an AI race narrative which makes many stakeholders fear that they
might be missing out. Whether real or not, a belief in this narrative may be
detrimental as some stakeholders will feel obliged to cut corners on safety
precautions or ignore societal consequences. Starting from a game-theoretical
model describing an idealised technology race in a well-mixed world, here we
investigate how different interaction structures among race participants can
alter collective choices and requirements for regulatory actions. Our findings
indicate that, when participants portray a strong diversity in terms of
connections and peer-influence (e.g., when scale-free networks shape
interactions among parties), the conflicts that exist in homogeneous settings
are significantly reduced, thereby lessening the need for regulatory actions.
Furthermore, our results suggest that technology governance and regulation may
profit from the world's patent heterogeneity and inequality among firms and
nations to design and implement meticulous interventions on a minority of
participants capable of influencing an entire population towards an ethical and
sustainable use of AI.
</p>
<a href="http://arxiv.org/abs/2012.15234" target="_blank">arXiv:2012.15234</a> [<a href="http://arxiv.org/pdf/2012.15234" target="_blank">pdf</a>]

<h2>Design, Characterization, and Control of a Size Adaptable In-pipe Robot for Water Distribution Systems. (arXiv:2012.15236v1 [cs.RO])</h2>
<h3>Saber Kazeminasab, Ali Akbari, Roozbeh Jafari, M. Katherine Banks</h3>
<p>Leak detection and water quality monitoring are requirements and challenging
tasks in Water Distribution Systems (WDS). In-line robots are designed for this
aim. In our previous work, we designed an in-pipe robot [1]. In this research,
we present the design of the central processor, characterize and control the
robot based on the condition of operation in a highly pressurized environment
of pipelines with the presence of high-speed flow. To this aim, an extreme
operation condition is simulated with computational fluid dynamics (CFD) and
the spring mechanism is characterized to ensure sufficient stabilizing force
during operation based on the extreme operating condition. Also, an end-to-end
method is suggested for power considerations for our robot that calculates
minimum battery capacity and operation duration in the extreme operating
condition. Finally, we design a novel LQR-PID based controller based on the
system auxiliary matrices that retain the robot stability inside the pipeline
against disturbances and uncertainties during operation. The ADAMS-MATLAB
co-simulation of the robot-controller shows the rotational velocity with -4
degree/sec and +3 degree/sec margin around x, y, and z axes while the system
tracks different desired velocities in pipelines (i.e. 0.12m/s, 0.17m/s, and
0.35m/s). Also, experimental results for four iterations in a 14-inch diameter
PVC pipe show that the controller brings initial values of stabilizing states
to zero and oscillate around it with a margin of 2 degrees and the system
tracks desired velocities of 0.1m/s, 0.2m/s, 0.3m/s, and 0.35m/s in which makes
the robot dexterous in uncertain and highly disturbed the environment of
pipelines during operation.
</p>
<a href="http://arxiv.org/abs/2012.15236" target="_blank">arXiv:2012.15236</a> [<a href="http://arxiv.org/pdf/2012.15236" target="_blank">pdf</a>]

<h2>A Maximal Correlation Approach to Imposing Fairness in Machine Learning. (arXiv:2012.15259v1 [cs.LG])</h2>
<h3>Joshua Lee, Yuheng Bu, Prasanna Sattigeri, Rameswar Panda, Gregory Wornell, Leonid Karlinsky, Rogerio Feris</h3>
<p>As machine learning algorithms grow in popularity and diversify to many
industries, ethical and legal concerns regarding their fairness have become
increasingly relevant. We explore the problem of algorithmic fairness, taking
an information-theoretic view. The maximal correlation framework is introduced
for expressing fairness constraints and shown to be capable of being used to
derive regularizers that enforce independence and separation-based fairness
criteria, which admit optimization algorithms for both discrete and continuous
variables which are more computationally efficient than existing algorithms. We
show that these algorithms provide smooth performance-fairness tradeoff curves
and perform competitively with state-of-the-art methods on both discrete
datasets (COMPAS, Adult) and continuous datasets (Communities and Crimes).
</p>
<a href="http://arxiv.org/abs/2012.15259" target="_blank">arXiv:2012.15259</a> [<a href="http://arxiv.org/pdf/2012.15259" target="_blank">pdf</a>]

<h2>Provably Training Neural Network Classifiers under Fairness Constraints. (arXiv:2012.15274v1 [stat.ML])</h2>
<h3>You-Lin Chen, Zhaoran Wang, Mladen Kolar</h3>
<p>Training a classifier under fairness constraints has gotten increasing
attention in the machine learning community thanks to moral, legal, and
business reasons. However, several recent works addressing algorithmic fairness
have only focused on simple models such as logistic regression or support
vector machines due to non-convex and non-differentiable fairness criteria
across protected groups, such as race or gender. Neural networks, the most
widely used models for classification nowadays, are precluded and lack
theoretical guarantees. This paper aims to fill this missing but crucial part
of the literature of algorithmic fairness for neural networks. In particular,
we show that overparametrized neural networks could meet the fairness
constraints. The key ingredient of building a fair neural network classifier is
establishing no-regret analysis for neural networks in the overparameterization
regime, which may be of independent interest in the online learning of neural
networks and related applications.
</p>
<a href="http://arxiv.org/abs/2012.15274" target="_blank">arXiv:2012.15274</a> [<a href="http://arxiv.org/pdf/2012.15274" target="_blank">pdf</a>]

<h2>Optimal trees selection for classification via out-of-bag assessment and sub-bagging. (arXiv:2012.15301v1 [stat.ML])</h2>
<h3>Zardad Khan, Naz Gul, Nosheen Faiz, Asma Gul, Werner Adler, Berthold Lausen</h3>
<p>The effect of training data size on machine learning methods has been well
investigated over the past two decades. The predictive performance of tree
based machine learning methods, in general, improves with a decreasing rate as
the size of training data increases. We investigate this in optimal trees
ensemble (OTE) where the method fails to learn from some of the training
observations due to internal validation. Modified tree selection methods are
thus proposed for OTE to cater for the loss of training observations in
internal validation. In the first method, corresponding out-of-bag (OOB)
observations are used in both individual and collective performance assessment
for each tree. Trees are ranked based on their individual performance on the
OOB observations. A certain number of top ranked trees is selected and starting
from the most accurate tree, subsequent trees are added one by one and their
impact is recorded by using the OOB observations left out from the bootstrap
sample taken for the tree being added. A tree is selected if it improves
predictive accuracy of the ensemble. In the second approach, trees are grown on
random subsets, taken without replacement-known as sub-bagging, of the training
data instead of bootstrap samples (taken with replacement). The remaining
observations from each sample are used in both individual and collective
assessments for each corresponding tree similar to the first method. Analysis
on 21 benchmark datasets and simulations studies show improved performance of
the modified methods in comparison to OTE and other state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.15301" target="_blank">arXiv:2012.15301</a> [<a href="http://arxiv.org/pdf/2012.15301" target="_blank">pdf</a>]

<h2>Fast covariance parameter estimation of spatial Gaussian process models using neural networks. (arXiv:2012.15339v1 [stat.ML])</h2>
<h3>Florian Gerber, Douglas W. Nychka</h3>
<p>Gaussian processes (GPs) are a popular model for spatially referenced data
and allow descriptive statements, predictions at new locations, and simulation
of new fields. Often a few parameters are sufficient to parameterize the
covariance function, and maximum likelihood (ML) methods can be used to
estimate these parameters from data. ML methods, however, are computationally
demanding. For example, in the case of local likelihood estimation, even
fitting covariance models on modest size windows can overwhelm typical
computational resources for data analysis. This limitation motivates the idea
of using neural network (NN) methods to approximate ML estimates. We train NNs
to take moderate size spatial fields or variograms as input and return the
range and noise-to-signal covariance parameters. Once trained, the NNs provide
estimates with a similar accuracy compared to ML estimation and at a speedup by
a factor of 100 or more. Although we focus on a specific covariance estimation
problem motivated by a climate science application, this work can be easily
extended to other, more complex, spatial problems and provides a
proof-of-concept for this use of machine learning in computational statistics.
</p>
<a href="http://arxiv.org/abs/2012.15339" target="_blank">arXiv:2012.15339</a> [<a href="http://arxiv.org/pdf/2012.15339" target="_blank">pdf</a>]

<h2>Active Annotation of Informative Overlapping Frames in Video Mosaicking Applications. (arXiv:2012.15343v1 [cs.CV])</h2>
<h3>Loic Peter, Marcel Tella-Amo, Dzhoshkun Ismail Shakir, Jan Deprest, Sebastien Ourselin, Juan Eugenio Iglesias, Tom Vercauteren</h3>
<p>Video mosaicking requires the registration of overlapping frames located at
distant timepoints in the sequence to ensure global consistency of the
reconstructed scene. However, fully automated registration of such long-range
pairs is (i) challenging when the registration of images itself is difficult;
and (ii) computationally expensive for long sequences due to the large number
of candidate pairs for registration. In this paper, we introduce an efficient
framework for the active annotation of long-range pairwise correspondences in a
sequence. Our framework suggests pairs of images that are sought to be
informative to an oracle agent (e.g., a human user, or a reliable matching
algorithm) who provides visual correspondences on each suggested pair.
Informative pairs are retrieved according to an iterative strategy based on a
principled annotation reward coupled with two complementary and online
adaptable models of frame overlap. In addition to the efficient construction of
a mosaic, our framework provides, as a by-product, ground truth landmark
correspondences which can be used for evaluation or learning purposes. We
evaluate our approach in both automated and interactive scenarios via
experiments on synthetic sequences, on a publicly available dataset for aerial
imaging and on a clinical dataset for placenta mosaicking during fetal surgery.
</p>
<a href="http://arxiv.org/abs/2012.15343" target="_blank">arXiv:2012.15343</a> [<a href="http://arxiv.org/pdf/2012.15343" target="_blank">pdf</a>]

<h2>A Review into Data Science and Its Approaches in Mechanical Engineering. (arXiv:2012.15358v1 [cs.AI])</h2>
<h3>Ashkan Yousefi Zadeh, Meysam Shahbazy</h3>
<p>Nowadays it is inevitable to use intelligent systems to improve the
performance and optimization of different components of devices or factories.
Furthermore, it's so essential to have appropriate predictions to make better
decisions in businesses, medical studies, and engineering studies, etc. One of
the newest and most widely used of these methods is a field called Data Science
that all of the scientists, engineers, and factories need to learn and use in
their careers. This article briefly introduced data science and reviewed its
methods, especially it's usages in mechanical engineering and challenges and
ways of developing data science in mechanical engineering. In the introduction,
different definitions of data science and its background in technology
reviewed. In the following, data science methodology which is the process that
a data scientist needs to do in its works been discussed. Further, some
researches in the mechanical engineering area that used data science methods in
their studies, are reviewed. Eventually, it has been discussed according to the
subjects that have been reviewed in the article, why it is necessary to use
data science in mechanical engineering researches and projects.
</p>
<a href="http://arxiv.org/abs/2012.15358" target="_blank">arXiv:2012.15358</a> [<a href="http://arxiv.org/pdf/2012.15358" target="_blank">pdf</a>]

<h2>Knowledge Distillation with Adaptive Asymmetric Label Sharpening for Semi-supervised Fracture Detection in Chest X-rays. (arXiv:2012.15359v1 [cs.CV])</h2>
<h3>Yirui Wang, Kang Zheng, Chi-Tung Chang, Xiao-Yun Zhou, Zhilin Zheng, Lingyun Huang, Jing Xiao, Le Lu, Chien-Hung Liao, Shun Miao</h3>
<p>Exploiting available medical records to train high performance computer-aided
diagnosis (CAD) models via the semi-supervised learning (SSL) setting is
emerging to tackle the prohibitively high labor costs involved in large-scale
medical image annotations. Despite the extensive attentions received on SSL,
previous methods failed to 1) account for the low disease prevalence in medical
records and 2) utilize the image-level diagnosis indicated from the medical
records. Both issues are unique to SSL for CAD models. In this work, we propose
a new knowledge distillation method that effectively exploits large-scale
image-level labels extracted from the medical records, augmented with limited
expert annotated region-level labels, to train a rib and clavicle fracture CAD
model for chest X-ray (CXR). Our method leverages the teacher-student model
paradigm and features a novel adaptive asymmetric label sharpening (AALS)
algorithm to address the label imbalance problem that specially exists in
medical domain. Our approach is extensively evaluated on all CXR (N = 65,845)
from the trauma registry of anonymous hospital over a period of 9 years
(2008-2016), on the most common rib and clavicle fractures. The experiment
results demonstrate that our method achieves the state-of-the-art fracture
detection performance, i.e., an area under receiver operating characteristic
curve (AUROC) of 0.9318 and a free-response receiver operating characteristic
(FROC) score of 0.8914 on the rib fractures, significantly outperforming
previous approaches by an AUROC gap of 1.63% and an FROC improvement by 3.74%.
Consistent performance gains are also observed for clavicle fracture detection.
</p>
<a href="http://arxiv.org/abs/2012.15359" target="_blank">arXiv:2012.15359</a> [<a href="http://arxiv.org/pdf/2012.15359" target="_blank">pdf</a>]

<h2>OSTeC: One-Shot Texture Completion. (arXiv:2012.15370v1 [cs.CV])</h2>
<h3>Baris Gecer, Jiankang Deng, Stefanos Zafeiriou</h3>
<p>The last few years have witnessed the great success of non-linear generative
models in synthesizing high-quality photorealistic face images. Many recent 3D
facial texture reconstruction and pose manipulation from a single image
approaches still rely on large and clean face datasets to train image-to-image
Generative Adversarial Networks (GANs). Yet the collection of such a large
scale high-resolution 3D texture dataset is still very costly and difficult to
maintain age/ethnicity balance. Moreover, regression-based approaches suffer
from generalization to the in-the-wild conditions and are unable to fine-tune
to a target-image. In this work, we propose an unsupervised approach for
one-shot 3D facial texture completion that does not require large-scale texture
datasets, but rather harnesses the knowledge stored in 2D face generators. The
proposed approach rotates an input image in 3D and fill-in the unseen regions
by reconstructing the rotated image in a 2D face generator, based on the
visible parts. Finally, we stitch the most visible textures at different angles
in the UV image-plane. Further, we frontalize the target image by projecting
the completed texture into the generator. The qualitative and quantitative
experiments demonstrate that the completed UV textures and frontalized images
are of high quality, resembles the original identity, can be used to train a
texture GAN model for 3DMM fitting and improve pose-invariant face recognition.
</p>
<a href="http://arxiv.org/abs/2012.15370" target="_blank">arXiv:2012.15370</a> [<a href="http://arxiv.org/pdf/2012.15370" target="_blank">pdf</a>]

<h2>Model-Based Visual Planning with Self-Supervised Functional Distances. (arXiv:2012.15373v1 [cs.LG])</h2>
<h3>Stephen Tian, Suraj Nair, Frederik Ebert, Sudeep Dasari, Benjamin Eysenbach, Chelsea Finn, Sergey Levine</h3>
<p>A generalist robot must be able to complete a variety of tasks in its
environment. One appealing way to specify each task is in terms of a goal
observation. However, learning goal-reaching policies with reinforcement
learning remains a challenging problem, particularly when hand-engineered
reward functions are not available. Learned dynamics models are a promising
approach for learning about the environment without rewards or task-directed
data, but planning to reach goals with such a model requires a notion of
functional similarity between observations and goal states. We present a
self-supervised method for model-based visual goal reaching, which uses both a
visual dynamics model as well as a dynamical distance function learned using
model-free reinforcement learning. Our approach learns entirely using offline,
unlabeled data, making it practical to scale to large and diverse datasets. In
our experiments, we find that our method can successfully learn models that
perform a variety of tasks at test-time, moving objects amid distractors with a
simulated robotic arm and even learning to open and close a drawer using a
real-world robot. In comparisons, we find that this approach substantially
outperforms both model-free and model-based prior methods. Videos and
visualizations are available here: this http URL
</p>
<a href="http://arxiv.org/abs/2012.15373" target="_blank">arXiv:2012.15373</a> [<a href="http://arxiv.org/pdf/2012.15373" target="_blank">pdf</a>]

<h2>Provident Vehicle Detection at Night: The PVDN Dataset. (arXiv:2012.15376v1 [cs.CV])</h2>
<h3>Lars Ohnemus, Lukas Ewecker, Ebubekir Asan, Stefan Roos, Simon Isele, Jakob Ketterer, Leopold M&#xfc;ller, Sascha Saralajew</h3>
<p>For advanced driver assistance systems, it is crucial to have information
about oncoming vehicles as early as possible. At night, this task is especially
difficult due to poor lighting conditions. For that, during nighttime, every
vehicle uses headlamps to improve sight and therefore ensure safe driving. As
humans, we intuitively assume oncoming vehicles before the vehicles are
actually physically visible by detecting light reflections caused by their
headlamps. In this paper, we present a novel dataset containing 54659 annotated
grayscale images out of 349 different scenes in a rural environment at night.
In these images, all oncoming vehicles, their corresponding light objects
(e.g., headlamps), and their respective light reflections (e.g., light
reflections on guardrails) are labeled. This is accompanied by an in-depth
analysis of the dataset characteristics. With that, we are providing the first
open-source dataset with comprehensive ground truth data to enable research
into new methods of detecting oncoming vehicles based on the light reflections
they cause, long before they are directly visible. We consider this as an
essential step to further close the performance gap between current advanced
driver assistance systems and human behavior.
</p>
<a href="http://arxiv.org/abs/2012.15376" target="_blank">arXiv:2012.15376</a> [<a href="http://arxiv.org/pdf/2012.15376" target="_blank">pdf</a>]

<h2>3D Human motion anticipation and classification. (arXiv:2012.15378v1 [cs.CV])</h2>
<h3>Emad Barsoum, John Kender, Zicheng Liu</h3>
<p>Human motion prediction and understanding is a challenging problem. Due to
the complex dynamic of human motion and the non-deterministic aspect of future
prediction. We propose a novel sequence-to-sequence model for human motion
prediction and feature learning, trained with a modified version of generative
adversarial network, with a custom loss function that takes inspiration from
human motion animation and can control the variation between multiple predicted
motion from the same input poses.

Our model learns to predict multiple future sequences of human poses from the
same input sequence. We show that the discriminator learns general presentation
of human motion by using the learned feature in action recognition task.
Furthermore, to quantify the quality of the non-deterministic predictions, we
simultaneously train a motion-quality-assessment network that learns the
probability that a given sequence of poses is a real human motion or not.

We test our model on two of the largest human pose datasets: NTURGB-D and
Human3.6M. We train on both single and multiple action types. Its predictive
power for motion estimation is demonstrated by generating multiple plausible
futures from the same input and show the effect of each of the loss functions.
Furthermore, we show that it takes less than half the number of epochs to train
an activity recognition network by using the feature learned from the
discriminator.
</p>
<a href="http://arxiv.org/abs/2012.15378" target="_blank">arXiv:2012.15378</a> [<a href="http://arxiv.org/pdf/2012.15378" target="_blank">pdf</a>]

<h2>Beating Attackers At Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions. (arXiv:2012.15386v1 [cs.CV])</h2>
<h3>Yuhang Wu, Sunpreet S. Arora, Yanhong Wu, Hao Yang</h3>
<p>Adversarial examples are input examples that are specifically crafted to
deceive machine learning classifiers. State-of-the-art adversarial example
detection methods characterize an input example as adversarial either by
quantifying the magnitude of feature variations under multiple perturbations or
by measuring its distance from estimated benign example distribution. Instead
of using such metrics, the proposed method is based on the observation that the
directions of adversarial gradients when crafting (new) adversarial examples
play a key role in characterizing the adversarial space. Compared to detection
methods that use multiple perturbations, the proposed method is efficient as it
only applies a single random perturbation on the input example. Experiments
conducted on two different databases, CIFAR-10 and ImageNet, show that the
proposed detection method achieves, respectively, 97.9% and 98.6% AUC-ROC (on
average) on five different adversarial attacks, and outperforms multiple
state-of-the-art detection methods. Results demonstrate the effectiveness of
using adversarial gradient directions for adversarial example detection.
</p>
<a href="http://arxiv.org/abs/2012.15386" target="_blank">arXiv:2012.15386</a> [<a href="http://arxiv.org/pdf/2012.15386" target="_blank">pdf</a>]

<h2>Generalized Operating Procedure for Deep Learning: an Unconstrained Optimal Design Perspective. (arXiv:2012.15391v1 [cs.LG])</h2>
<h3>Shen Chen, Mingwei Zhang, Jiamin Cui, Wei Yao</h3>
<p>Deep learning (DL) has brought about remarkable breakthrough in processing
images, video and speech due to its efficacy in extracting highly abstract
representation and learning very complex functions. However, there is seldom
operating procedure reported on how to make it for real use cases. In this
paper, we intend to address this problem by presenting a generalized operating
procedure for DL from the perspective of unconstrained optimal design, which is
motivated by a simple intension to remove the barrier of using DL, especially
for those scientists or engineers who are new but eager to use it. Our proposed
procedure contains seven steps, which are project/problem statement, data
collection, architecture design, initialization of parameters, defining loss
function, computing optimal parameters, and inference, respectively. Following
this procedure, we build a multi-stream end-to-end speaker verification system,
in which the input speech utterance is processed by multiple parallel streams
within different frequency range, so that the acoustic modeling can be more
robust resulting from the diversity of features. Trained with VoxCeleb dataset,
our experimental results verify the effectiveness of our proposed operating
procedure, and also show that our multi-stream framework outperforms
single-stream baseline with 20 % relative reduction in minimum decision cost
function (minDCF).
</p>
<a href="http://arxiv.org/abs/2012.15391" target="_blank">arXiv:2012.15391</a> [<a href="http://arxiv.org/pdf/2012.15391" target="_blank">pdf</a>]

<h2>Understanding Black-box Predictions via Influence Functions. (arXiv:1703.04730v3 [stat.ML] UPDATED)</h2>
<h3>Pang Wei Koh, Percy Liang</h3>
<p>How can we explain the predictions of a black-box model? In this paper, we
use influence functions -- a classic technique from robust statistics -- to
trace a model's prediction through the learning algorithm and back to its
training data, thereby identifying training points most responsible for a given
prediction. To scale up influence functions to modern machine learning
settings, we develop a simple, efficient implementation that requires only
oracle access to gradients and Hessian-vector products. We show that even on
non-convex and non-differentiable models where the theory breaks down,
approximations to influence functions can still provide valuable information.
On linear models and convolutional neural networks, we demonstrate that
influence functions are useful for multiple purposes: understanding model
behavior, debugging models, detecting dataset errors, and even creating
visually-indistinguishable training-set attacks.
</p>
<a href="http://arxiv.org/abs/1703.04730" target="_blank">arXiv:1703.04730</a> [<a href="http://arxiv.org/pdf/1703.04730" target="_blank">pdf</a>]

<h2>Neural SLAM: Learning to Explore with External Memory. (arXiv:1706.09520v7 [cs.LG] UPDATED)</h2>
<h3>Jingwei Zhang, Lei Tai, Ming Liu, Joschka Boedecker, Wolfram Burgard</h3>
<p>We present an approach for agents to learn representations of a global map
from sensor data, to aid their exploration in new environments. To achieve
this, we embed procedures mimicking that of traditional Simultaneous
Localization and Mapping (SLAM) into the soft attention based addressing of
external memory architectures, in which the external memory acts as an internal
representation of the environment. This structure encourages the evolution of
SLAM-like behaviors inside a completely differentiable deep neural network. We
show that this approach can help reinforcement learning agents to successfully
explore new environments where long-term memory is essential. We validate our
approach in both challenging grid-world environments and preliminary Gazebo
experiments. A video of our experiments can be found at: https://goo.gl/G2Vu5y.
</p>
<a href="http://arxiv.org/abs/1706.09520" target="_blank">arXiv:1706.09520</a> [<a href="http://arxiv.org/pdf/1706.09520" target="_blank">pdf</a>]

<h2>Flow: A Modular Learning Framework for Autonomy in Traffic. (arXiv:1710.05465v3 [cs.AI] UPDATED)</h2>
<h3>Cathy Wu, Aboudy Kreidieh, Kanaad Parvate, Eugene Vinitsky, Alexandre M Bayen</h3>
<p>The rapid development of autonomous vehicles (AVs) holds vast potential for
transportation systems through improved safety, efficiency, and access to
mobility. However, due to numerous technical, political, and human factors
challenges, new methodologies are needed to design vehicles and transportation
systems for these positive outcomes. This article tackles technical challenges
arising from the partial adoption of autonomy: partial control, partial
observation, complex multi-vehicle interactions, and the sheer variety of
traffic settings represented by real-world networks. The article presents a
modular learning framework which leverages deep Reinforcement Learning methods
to address complex traffic dynamics. Modules are composed to capture common
traffic phenomena (traffic jams, lane changing, intersections). Learned control
laws are found to exceed human driving performance by at least 40% with only
5-10% adoption of AVs. In partially-observed single-lane traffic, a small
neural network control law can eliminate stop-and-go traffic -- surpassing all
known model-based controllers, achieving near-optimal performance, and
generalizing to out-of-distribution traffic densities.
</p>
<a href="http://arxiv.org/abs/1710.05465" target="_blank">arXiv:1710.05465</a> [<a href="http://arxiv.org/pdf/1710.05465" target="_blank">pdf</a>]

<h2>Mirrored Langevin Dynamics. (arXiv:1802.10174v5 [cs.LG] UPDATED)</h2>
<h3>Ya-Ping Hsieh, Ali Kavis, Paul Rolland, Volkan Cevher</h3>
<p>We consider the problem of sampling from constrained distributions, which has
posed significant challenges to both non-asymptotic analysis and algorithmic
design. We propose a unified framework, which is inspired by the classical
mirror descent, to derive novel first-order sampling schemes. We prove that,
for a general target distribution with strongly convex potential, our framework
implies the existence of a first-order algorithm achieving
$\tilde{O}(\epsilon^{-2}d)$ convergence, suggesting that the state-of-the-art
$\tilde{O}(\epsilon^{-6}d^5)$ can be vastly improved. With the important Latent
Dirichlet Allocation (LDA) application in mind, we specialize our algorithm to
sample from Dirichlet posteriors, and derive the first non-asymptotic
$\tilde{O}(\epsilon^{-2}d^2)$ rate for first-order sampling. We further extend
our framework to the mini-batch setting and prove convergence rates when only
stochastic gradients are available. Finally, we report promising experimental
results for LDA on real datasets.
</p>
<a href="http://arxiv.org/abs/1802.10174" target="_blank">arXiv:1802.10174</a> [<a href="http://arxiv.org/pdf/1802.10174" target="_blank">pdf</a>]

<h2>Effective Occlusion Handling for Fast Correlation Filter-based Trackers. (arXiv:1807.04880v2 [cs.CV] UPDATED)</h2>
<h3>Zheng Zhang, Yang Li, Jinwei Ren, Jianke Zhu</h3>
<p>Correlation filter-based trackers heavily suffer from the problem of multiple
peaks in their response maps incurred by occlusions. Moreover, the whole
tracking pipeline may break down due to the uncertainties brought by shifting
among peaks, which will further lead to the degraded correlation filter model.
To alleviate the drift problem caused by occlusions, we propose a novel scheme
to choose the specific filter model according to different scenarios.
Specifically, an effective measurement function is designed to evaluate the
quality of filter response. A sophisticated strategy is employed to judge
whether occlusions occur, and then decide how to update the filter models. In
addition, we take advantage of both log-polar method and pyramid-like approach
to estimate the best scale of the target. We evaluate our proposed approach on
VOT2018 challenge and OTB100 dataset, whose experimental result shows that the
proposed tracker achieves the promising performance compared against the
state-of-the-art trackers.
</p>
<a href="http://arxiv.org/abs/1807.04880" target="_blank">arXiv:1807.04880</a> [<a href="http://arxiv.org/pdf/1807.04880" target="_blank">pdf</a>]

<h2>Introducing Quantum-Like Influence Diagrams for Violations of the Sure Thing Principle. (arXiv:1807.06142v2 [cs.AI] UPDATED)</h2>
<h3>Catarina Moreira, Andreas Wichert</h3>
<p>It is the focus of this work to extend and study the previously proposed
quantum-like Bayesian networks to deal with decision-making scenarios by
incorporating the notion of maximum expected utility in influence diagrams. The
general idea is to take advantage of the quantum interference terms produced in
the quantum-like Bayesian Network to influence the probabilities used to
compute the expected utility of some action. This way, we are not proposing a
new type of expected utility hypothesis. On the contrary, we are keeping it
under its classical definition. We are only incorporating it as an extension of
a probabilistic graphical model in a compact graphical representation called an
influence diagram in which the utility function depends on the probabilistic
influences of the quantum-like Bayesian network.

Our findings suggest that the proposed quantum-like influence digram can
indeed take advantage of the quantum interference effects of quantum-like
Bayesian Networks to maximise the utility of a cooperative behaviour in
detriment of a fully rational defect behaviour under the prisoner's dilemma
game.
</p>
<a href="http://arxiv.org/abs/1807.06142" target="_blank">arXiv:1807.06142</a> [<a href="http://arxiv.org/pdf/1807.06142" target="_blank">pdf</a>]

<h2>How Complex is your classification problem? A survey on measuring classification complexity. (arXiv:1808.03591v3 [cs.LG] UPDATED)</h2>
<h3>Ana C. Lorena, Lu&#xed;s P. F. Garcia, Jens Lehmann, Marcilio C. P. Souto, Tin K. Ho</h3>
<p>Characteristics extracted from the training datasets of classification
problems have proven to be effective predictors in a number of meta-analyses.
Among them, measures of classification complexity can be used to estimate the
difficulty in separating the data points into their expected classes.
Descriptors of the spatial distribution of the data and estimates of the shape
and size of the decision boundary are among the known measures for this
characterization. This information can support the formulation of new
data-driven pre-processing and pattern recognition techniques, which can in
turn be focused on challenges highlighted by such characteristics of the
problems. This paper surveys and analyzes measures which can be extracted from
the training datasets in order to characterize the complexity of the respective
classification problems. Their use in recent literature is also reviewed and
discussed, allowing to prospect opportunities for future work in the area.
Finally, descriptions are given on an R package named Extended Complexity
Library (ECoL) that implements a set of complexity measures and is made
publicly available.
</p>
<a href="http://arxiv.org/abs/1808.03591" target="_blank">arXiv:1808.03591</a> [<a href="http://arxiv.org/pdf/1808.03591" target="_blank">pdf</a>]

<h2>OrthographicNet: A Deep Transfer Learning Approach for 3D Object Recognition in Open-Ended Domains. (arXiv:1902.03057v3 [cs.RO] UPDATED)</h2>
<h3>Hamidreza Kasaei</h3>
<p>Nowadays, service robots are appearing more and more in our daily life. For
this type of robot, open-ended object category learning and recognition is
necessary since no matter how extensive the training data used for batch
learning, the robot might be faced with a new object when operating in a
real-world environment. In this work, we present OrthographicNet, a
Convolutional Neural Network (CNN)-based model, for 3D object recognition in
open-ended domains. In particular, OrthographicNet generates a global rotation-
and scale-invariant representation for a given 3D object, enabling robots to
recognize the same or similar objects seen from different perspectives.
Experimental results show that our approach yields significant improvements
over the previous state-of-the-art approaches concerning object recognition
performance and scalability in open-ended scenarios. Moreover, OrthographicNet
demonstrates the capability of learning new categories from very few examples
on-site. Regarding real-time performance, three real-world demonstrations
validate the promising performance of the proposed architecture.
</p>
<a href="http://arxiv.org/abs/1902.03057" target="_blank">arXiv:1902.03057</a> [<a href="http://arxiv.org/pdf/1902.03057" target="_blank">pdf</a>]

<h2>Deep Learning in Cardiology. (arXiv:1902.11122v2 [cs.CV] UPDATED)</h2>
<h3>Paschalis Bizopoulos, Dimitrios Koutsouris</h3>
<p>The medical field is creating large amount of data that physicians are unable
to decipher and use efficiently. Moreover, rule-based expert systems are
inefficient in solving complicated medical tasks or for creating insights using
big data. Deep learning has emerged as a more accurate and effective technology
in a wide range of medical problems such as diagnosis, prediction and
intervention. Deep learning is a representation learning method that consists
of layers that transform the data non-linearly, thus, revealing hierarchical
relationships and structures. In this review we survey deep learning
application papers that use structured data, signal and imaging modalities from
cardiology. We discuss the advantages and limitations of applying deep learning
in cardiology that also apply in medicine in general, while proposing certain
directions as the most viable for clinical use.
</p>
<a href="http://arxiv.org/abs/1902.11122" target="_blank">arXiv:1902.11122</a> [<a href="http://arxiv.org/pdf/1902.11122" target="_blank">pdf</a>]

<h2>Interpolation Consistency Training for Semi-Supervised Learning. (arXiv:1903.03825v4 [stat.ML] UPDATED)</h2>
<h3>Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala, Yoshua Bengio, David Lopez-Paz</h3>
<p>We introduce Interpolation Consistency Training (ICT), a simple and
computation efficient algorithm for training Deep Neural Networks in the
semi-supervised learning paradigm. ICT encourages the prediction at an
interpolation of unlabeled points to be consistent with the interpolation of
the predictions at those points. In classification problems, ICT moves the
decision boundary to low-density regions of the data distribution. Our
experiments show that ICT achieves state-of-the-art performance when applied to
standard neural network architectures on the CIFAR-10 and SVHN benchmark
datasets. Our theoretical analysis shows that ICT corresponds to a certain type
of data-adaptive regularization with unlabeled points which reduces overfitting
to labeled points under high confidence values.
</p>
<a href="http://arxiv.org/abs/1903.03825" target="_blank">arXiv:1903.03825</a> [<a href="http://arxiv.org/pdf/1903.03825" target="_blank">pdf</a>]

<h2>Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations. (arXiv:1903.05895v2 [cs.LG] UPDATED)</h2>
<h3>Tri Dao, Albert Gu, Matthew Eichhorn, Atri Rudra, Christopher R&#xe9;</h3>
<p>Fast linear transforms are ubiquitous in machine learning, including the
discrete Fourier transform, discrete cosine transform, and other structured
transformations such as convolutions. All of these transforms can be
represented by dense matrix-vector multiplication, yet each has a specialized
and highly efficient (subquadratic) algorithm. We ask to what extent
hand-crafting these algorithms and implementations is necessary, what
structural priors they encode, and how much knowledge is required to
automatically learn a fast algorithm for a provided structured transform.
Motivated by a characterization of fast matrix-vector multiplication as
products of sparse matrices, we introduce a parameterization of
divide-and-conquer methods that is capable of representing a large class of
transforms. This generic formulation can automatically learn an efficient
algorithm for many important transforms; for example, it recovers the $O(N \log
N)$ Cooley-Tukey FFT algorithm to machine precision, for dimensions $N$ up to
$1024$. Furthermore, our method can be incorporated as a lightweight
replacement of generic matrices in machine learning pipelines to learn
efficient and compressible transformations. On a standard task of compressing a
single hidden-layer network, our method exceeds the classification accuracy of
unconstrained matrices on CIFAR-10 by 3.9 points -- the first time a structured
approach has done so -- with 4X faster inference speed and 40X fewer
parameters.
</p>
<a href="http://arxiv.org/abs/1903.05895" target="_blank">arXiv:1903.05895</a> [<a href="http://arxiv.org/pdf/1903.05895" target="_blank">pdf</a>]

<h2>Inverse Reinforcement Learning in Contextual MDPs. (arXiv:1905.09710v5 [cs.LG] UPDATED)</h2>
<h3>Stav Belogolovsky, Philip Korsunsky, Shie Mannor, Chen Tessler, Tom Zahavy</h3>
<p>We consider the task of Inverse Reinforcement Learning in Contextual Markov
Decision Processes (MDPs). In this setting, contexts, which define the reward
and transition kernel, are sampled from a distribution. In addition, although
the reward is a function of the context, it is not provided to the agent.
Instead, the agent observes demonstrations from an optimal policy. The goal is
to learn the reward mapping, such that the agent will act optimally even when
encountering previously unseen contexts, also known as zero-shot transfer. We
formulate this problem as a non-differential convex optimization problem and
propose a novel algorithm to compute its subgradients. Based on this scheme, we
analyze several methods both theoretically, where we compare the sample
complexity and scalability, and empirically. Most importantly, we show both
theoretically and empirically that our algorithms perform zero-shot transfer
(generalize to new and unseen contexts). Specifically, we present empirical
experiments in a dynamic treatment regime, where the goal is to learn a reward
function which explains the behavior of expert physicians based on recorded
data of them treating patients diagnosed with sepsis.
</p>
<a href="http://arxiv.org/abs/1905.09710" target="_blank">arXiv:1905.09710</a> [<a href="http://arxiv.org/pdf/1905.09710" target="_blank">pdf</a>]

<h2>Quantifying Exposure Bias for Open-ended Language Generation. (arXiv:1905.10617v7 [cs.LG] UPDATED)</h2>
<h3>Tianxing He, Jingzhao Zhang, Zhiming Zhou, James Glass</h3>
<p>The exposure bias problem refers to the incrementally distorted generation
induced by the training-generation discrepancy, in teacher-forcing training for
auto-regressive neural network language models (LM). It has been regarded as a
central problem for LMs trained for open-ended language generation. Although a
lot of algorithms have been proposed to avoid teacher forcing and therefore
alleviate exposure bias, there is little work showing how serious the exposure
bias problem actually is. In this work, we propose novel metrics to quantify
the impact of exposure bias in the generation of MLE-trained LMs. Our key
intuition is that if we feed ground-truth data prefixes (instead of prefixes
generated by the model itself) into the model and ask it to continue the
generation, the performance should become much better because the
training-generation discrepancy in the prefix is removed. We conduct both
automatic and human evaluation in our experiments, and our observations are
two-fold: (1) We confirm that the prefix discrepancy indeed induces some level
of performance loss. (2) However, the induced distortion seems to be limited,
and is not incremental during the generation, which contradicts the claim of
exposure bias.
</p>
<a href="http://arxiv.org/abs/1905.10617" target="_blank">arXiv:1905.10617</a> [<a href="http://arxiv.org/pdf/1905.10617" target="_blank">pdf</a>]

<h2>Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy. (arXiv:1906.01529v6 [cs.LG] UPDATED)</h2>
<h3>Zhengwei Wang, Qi She, Tomas E. Ward</h3>
<p>Generative adversarial networks (GANs) have been extensively studied in the
past few years. Arguably their most significant impact has been in the area of
computer vision where great advances have been made in challenges such as
plausible image generation, image-to-image translation, facial attribute
manipulation and similar domains. Despite the significant successes achieved to
date, applying GANs to real-world problems still poses significant challenges,
three of which we focus on here. These are: (1) the generation of high quality
images, (2) diversity of image generation, and (3) stable training. Focusing on
the degree to which popular GAN technologies have made progress against these
challenges, we provide a detailed review of the state of the art in GAN-related
research in the published scientific literature. We further structure this
review through a convenient taxonomy we have adopted based on variations in GAN
architectures and loss functions. While several reviews for GANs have been
presented to date, none have considered the status of this field based on their
progress towards addressing practical challenges relevant to computer vision.
Accordingly, we review and critically discuss the most popular
architecture-variant, and loss-variant GANs, for tackling these challenges. Our
objective is to provide an overview as well as a critical analysis of the
status of GAN research in terms of relevant progress towards important computer
vision application requirements. As we do this we also discuss the most
compelling applications in computer vision in which GANs have demonstrated
considerable success along with some suggestions for future research
directions. Code related to GAN-variants studied in this work is summarized on
https://github.com/sheqi/GAN_Review.
</p>
<a href="http://arxiv.org/abs/1906.01529" target="_blank">arXiv:1906.01529</a> [<a href="http://arxiv.org/pdf/1906.01529" target="_blank">pdf</a>]

<h2>Bayesian Active Learning With Abstention Feedbacks. (arXiv:1906.02179v2 [cs.LG] UPDATED)</h2>
<h3>Cuong V. Nguyen, Lam Si Tung Ho, Huan Xu, Vu Dinh, Binh Nguyen</h3>
<p>We study pool-based active learning with abstention feedbacks where a labeler
can abstain from labeling a queried example with some unknown abstention rate.
This is an important problem with many useful applications. We take a Bayesian
approach to the problem and develop two new greedy algorithms that learn both
the classification problem and the unknown abstention rate at the same time.
These are achieved by simply incorporating the estimated average abstention
rate into the greedy criteria. We prove that both algorithms have
near-optimality guarantees: they respectively achieve a ${(1-\frac{1}{e})}$
constant factor approximation of the optimal expected or worst-case value of a
useful utility function. Our experiments show the algorithms perform well in
various practical scenarios.
</p>
<a href="http://arxiv.org/abs/1906.02179" target="_blank">arXiv:1906.02179</a> [<a href="http://arxiv.org/pdf/1906.02179" target="_blank">pdf</a>]

<h2>Gradient Descent Maximizes the Margin of Homogeneous Neural Networks. (arXiv:1906.05890v4 [cs.LG] UPDATED)</h2>
<h3>Kaifeng Lyu, Jian Li</h3>
<p>In this paper, we study the implicit regularization of the gradient descent
algorithm in homogeneous neural networks, including fully-connected and
convolutional neural networks with ReLU or LeakyReLU activations. In
particular, we study the gradient descent or gradient flow (i.e., gradient
descent with infinitesimal step size) optimizing the logistic loss or
cross-entropy loss of any homogeneous model (possibly non-smooth), and show
that if the training loss decreases below a certain threshold, then we can
define a smoothed version of the normalized margin which increases over time.
We also formulate a natural constrained optimization problem related to margin
maximization, and prove that both the normalized margin and its smoothed
version converge to the objective value at a KKT point of the optimization
problem. Our results generalize the previous results for logistic regression
with one-layer or multi-layer linear networks, and provide more quantitative
convergence results with weaker assumptions than previous results for
homogeneous smooth neural networks. We conduct several experiments to justify
our theoretical finding on MNIST and CIFAR-10 datasets. Finally, as margin is
closely related to robustness, we discuss potential benefits of training longer
for improving the robustness of the model.
</p>
<a href="http://arxiv.org/abs/1906.05890" target="_blank">arXiv:1906.05890</a> [<a href="http://arxiv.org/pdf/1906.05890" target="_blank">pdf</a>]

<h2>Membership Privacy for Machine Learning Models Through Knowledge Transfer. (arXiv:1906.06589v3 [cs.LG] UPDATED)</h2>
<h3>Virat Shejwalkar, Amir Houmansadr</h3>
<p>Large capacity machine learning (ML) models are prone to membership inference
attacks (MIAs), which aim to infer whether the target sample is a member of the
target model's training dataset. The serious privacy concerns due to the
membership inference have motivated multiple defenses against MIAs, e.g.,
differential privacy and adversarial regularization. Unfortunately, these
defenses produce ML models with unacceptably low classification performances.
Our work proposes a new defense, called distillation for membership privacy
(DMP), against MIAs that preserves the utility of the resulting models
significantly better than prior defenses. DMP leverages knowledge distillation
to train ML models with membership privacy. We provide a novel criterion to
tune the data used for knowledge transfer in order to amplify the membership
privacy of DMP. Our extensive evaluation shows that DMP provides significantly
better tradeoffs between membership privacy and classification accuracies
compared to state-of-the-art MIA defenses. For instance, DMP achieves ~100%
accuracy improvement over adversarial regularization for DenseNet trained on
CIFAR100, for similar membership privacy (measured using MIA risk): when the
MIA risk is 53.7%, adversarially regularized DenseNet is 33.6% accurate, while
DMP-trained DenseNet is 65.3% accurate.
</p>
<a href="http://arxiv.org/abs/1906.06589" target="_blank">arXiv:1906.06589</a> [<a href="http://arxiv.org/pdf/1906.06589" target="_blank">pdf</a>]

<h2>Online A-Optimal Design and Active Linear Regression. (arXiv:1906.08509v2 [stat.ML] UPDATED)</h2>
<h3>Xavier Fontaine, Pierre Perrault, Michal Valko, Vianney Perchet</h3>
<p>We consider in this paper the problem of optimal experiment design where a
decision maker can choose which points to sample to obtain an estimate
$\hat{\beta}$ of the hidden parameter $\beta^{\star}$ of an underlying linear
model. The key challenge of this work lies in the heteroscedasticity assumption
that we make, meaning that each covariate has a different and unknown variance.
The goal of the decision maker is then to figure out on the fly the optimal way
to allocate the total budget of $T$ samples between covariates, as sampling
several times a specific one will reduce the variance of the estimated model
around it (but at the cost of a possible higher variance elsewhere). By trying
to minimize the $\ell^2$-loss $\mathbb{E}
[\lVert\hat{\beta}-\beta^{\star}\rVert^2]$ the decision maker is actually
minimizing the trace of the covariance matrix of the problem, which corresponds
then to online A-optimal design. Combining techniques from bandit and convex
optimization we propose a new active sampling algorithm and we compare it with
existing ones. We provide theoretical guarantees of this algorithm in different
settings, including a $\mathcal{O}(T^{-2})$ regret bound in the case where the
covariates form a basis of the feature space, generalizing and improving
existing results. Numerical experiments validate our theoretical findings.
</p>
<a href="http://arxiv.org/abs/1906.08509" target="_blank">arXiv:1906.08509</a> [<a href="http://arxiv.org/pdf/1906.08509" target="_blank">pdf</a>]

<h2>Spectral Clustering with Graph Neural Networks for Graph Pooling. (arXiv:1907.00481v6 [cs.LG] UPDATED)</h2>
<h3>Filippo Maria Bianchi, Daniele Grattarola, Cesare Alippi</h3>
<p>Spectral clustering (SC) is a popular clustering technique to find strongly
connected communities on a graph. SC can be used in Graph Neural Networks
(GNNs) to implement pooling operations that aggregate nodes belonging to the
same cluster. However, the eigendecomposition of the Laplacian is expensive
and, since clustering results are graph-specific, pooling methods based on SC
must perform a new optimization for each new sample. In this paper, we propose
a graph clustering approach that addresses these limitations of SC. We
formulate a continuous relaxation of the normalized minCUT problem and train a
GNN to compute cluster assignments that minimize this objective. Our GNN-based
implementation is differentiable, does not require to compute the spectral
decomposition, and learns a clustering function that can be quickly evaluated
on out-of-sample graphs. From the proposed clustering method, we design a graph
pooling operator that overcomes some important limitations of state-of-the-art
graph pooling techniques and achieves the best performance in several
supervised and unsupervised tasks.
</p>
<a href="http://arxiv.org/abs/1907.00481" target="_blank">arXiv:1907.00481</a> [<a href="http://arxiv.org/pdf/1907.00481" target="_blank">pdf</a>]

<h2>SPA-GAN: Spatial Attention GAN for Image-to-Image Translation. (arXiv:1908.06616v3 [cs.CV] UPDATED)</h2>
<h3>Hajar Emami, Majid Moradi Aliabadi, Ming Dong, Ratna Babu Chinnam</h3>
<p>Image-to-image translation is to learn a mapping between images from a source
domain and images from a target domain. In this paper, we introduce the
attention mechanism directly to the generative adversarial network (GAN)
architecture and propose a novel spatial attention GAN model (SPA-GAN) for
image-to-image translation tasks. SPA-GAN computes the attention in its
discriminator and use it to help the generator focus more on the most
discriminative regions between the source and target domains, leading to more
realistic output images. We also find it helpful to introduce an additional
feature map loss in SPA-GAN training to preserve domain specific features
during translation. Compared with existing attention-guided GAN models, SPA-GAN
is a lightweight model that does not need additional attention networks or
supervision. Qualitative and quantitative comparison against state-of-the-art
methods on benchmark datasets demonstrates the superior performance of SPA-GAN.
</p>
<a href="http://arxiv.org/abs/1908.06616" target="_blank">arXiv:1908.06616</a> [<a href="http://arxiv.org/pdf/1908.06616" target="_blank">pdf</a>]

<h2>Oracle Efficient Private Non-Convex Optimization. (arXiv:1909.01783v3 [cs.LG] UPDATED)</h2>
<h3>Seth Neel, Aaron Roth, Giuseppe Vietri, Zhiwei Steven Wu</h3>
<p>One of the most effective algorithms for differentially private learning and
optimization is objective perturbation. This technique augments a given
optimization problem (e.g. deriving from an ERM problem) with a random linear
term, and then exactly solves it. However, to date, analyses of this approach
crucially rely on the convexity and smoothness of the objective function,
limiting its generality. We give two algorithms that extend this approach
substantially. The first algorithm requires nothing except boundedness of the
loss function, and operates over a discrete domain. Its privacy and accuracy
guarantees hold even without assuming convexity. This gives an oracle-efficient
optimization algorithm over arbitrary discrete domains that is comparable in
its generality to the exponential mechanism. The second algorithm operates over
a continuous domain and requires only that the loss function be bounded and
Lipschitz in its continuous parameter. Its privacy analysis does not require
convexity. Its accuracy analysis does require convexity, but does not require
second order conditions like smoothness. Even without convexity, this algorithm
can be generically used as an oracle-efficient optimization algorithm, with
accuracy evaluated empirically. We complement our theoretical results with an
empirical evaluation of the non-convex case, in which we use an integer program
solver as our optimization oracle. We find that for the problem of learning
linear classifiers, directly optimizing for 0/1 loss using our approach can
out-perform the more standard approach of privately optimizing a
convex-surrogate loss function on the Adult dataset.
</p>
<a href="http://arxiv.org/abs/1909.01783" target="_blank">arXiv:1909.01783</a> [<a href="http://arxiv.org/pdf/1909.01783" target="_blank">pdf</a>]

<h2>Deep weakly-supervised learning methods for classification and localization in histology images: a survey. (arXiv:1909.03354v4 [cs.CV] UPDATED)</h2>
<h3>J&#xe9;r&#xf4;me Rony, Soufiane Belharbi, Jose Dolz, Ismail Ben Ayed, Luke McCaffrey, Eric Granger</h3>
<p>Using state-of-the-art deep learning models for cancer diagnosis presents
several challenges related to the nature and availability of labeled histology
images. In particular, cancer grading and localization in these images normally
relies on both image- and pixel-level labels, the latter requiring a costly
annotation process. In this survey, deep weakly-supervised learning (WSL)
models are investigated to identify and locate diseases in histology images,
without the need for pixel-level annotations. Given training data with global
image-level labels, these models allow to simultaneously classify histology
images and yield pixel-wise localization scores, thereby identifying the
corresponding regions of interest (ROI). Since relevant WSL models have mainly
been investigated within the computer vision community, and validated on
natural scene images, we assess the extent to which they apply to histology
images which have challenging properties, e.g. very large size, similarity
between foreground/background, highly unstructured regions, stain
heterogeneity, and noisy/ambiguous labels. The most relevant models for deep
WSL are compared experimentally in terms of accuracy (classification and
pixel-wise localization) on several public benchmark histology datasets for
breast and colon cancer -- BACH ICIAR 2018, BreaKHis, CAMELYON16, and GlaS.
Furthermore, for large-scale evaluation of WSL models on histology images, we
propose a protocol to construct WSL datasets from Whole Slide Imaging. Results
indicate that several deep learning models can provide a high level of
classification accuracy, although accurate pixel-wise localization of cancer
regions remains an issue for such images. Code is publicly available.
</p>
<a href="http://arxiv.org/abs/1909.03354" target="_blank">arXiv:1909.03354</a> [<a href="http://arxiv.org/pdf/1909.03354" target="_blank">pdf</a>]

<h2>SDM-Net: A Simple and Effective Model for Generalized Zero-Shot Learning. (arXiv:1909.04790v2 [cs.CV] UPDATED)</h2>
<h3>Shabnam Daghaghi, Tharun Medini, Anshumali Shrivastava</h3>
<p>Zero-Shot Learning (ZSL) is a classification task where we do not have even a
single training labeled example from a set of unseen classes. Instead, we only
have prior information (or description) about seen and unseen classes, often in
the form of physically realizable or descriptive attributes. Lack of any single
training example from a set of classes prohibits use of standard classification
techniques and losses, including the popular crossentropy loss. Currently,
state-of-the-art approaches encode the prior class information into dense
vectors and optimize some distance between the learned projections of the input
vector and the corresponding class vector (collectively known as embedding
models). In this paper, we propose a novel architecture of casting zero-shot
learning as a standard neural-network with crossentropy loss. During training
our approach performs soft-labeling by combining the observed training data for
the seen classes with the similarity information from the attributes for which
we have no training data or unseen classes. To the best of our knowledge, such
similarity based soft-labeling is not explored in the field of deep learning.
We evaluate the proposed model on the four benchmark datasets for zero-shot
learning, AwA, aPY, SUN and CUB datasets, and show that our model achieves
significant improvement over the state-of-the-art methods in Generalized-ZSL
and ZSL settings on all of these datasets consistently.
</p>
<a href="http://arxiv.org/abs/1909.04790" target="_blank">arXiv:1909.04790</a> [<a href="http://arxiv.org/pdf/1909.04790" target="_blank">pdf</a>]

<h2>Safe Policy Improvement with an Estimated Baseline Policy. (arXiv:1909.05236v2 [cs.LG] UPDATED)</h2>
<h3>Thiago D. Sim&#xe3;o, Romain Laroche, R&#xe9;mi Tachet des Combes</h3>
<p>Previous work has shown the unreliability of existing algorithms in the batch
Reinforcement Learning setting, and proposed the theoretically-grounded Safe
Policy Improvement with Baseline Bootstrapping (SPIBB) fix: reproduce the
baseline policy in the uncertain state-action pairs, in order to control the
variance on the trained policy performance. However, in many real-world
applications such as dialogue systems, pharmaceutical tests or crop management,
data is collected under human supervision and the baseline remains unknown. In
this paper, we apply SPIBB algorithms with a baseline estimate built from the
data. We formally show safe policy improvement guarantees over the true
baseline even without direct access to it. Our empirical experiments on finite
and continuous states tasks support the theoretical findings. It shows little
loss of performance in comparison with SPIBB when the baseline policy is given,
and more importantly, drastically and significantly outperforms competing
algorithms both in safe policy improvement, and in average performance.
</p>
<a href="http://arxiv.org/abs/1909.05236" target="_blank">arXiv:1909.05236</a> [<a href="http://arxiv.org/pdf/1909.05236" target="_blank">pdf</a>]

<h2>FALCON: Lightweight and Accurate Convolution. (arXiv:1909.11321v2 [cs.CV] UPDATED)</h2>
<h3>Jun-Gi Jang, Chun Quan, Hyun Dong Lee, U Kang</h3>
<p>How can we efficiently compress Convolutional Neural Network (CNN) while
retaining their accuracy on classification tasks? Depthwise Separable
Convolution (DSConv), which replaces a standard convolution with a depthwise
convolution and a pointwise convolution, has been used for building lightweight
architectures. However, previous works based on depthwise separable convolution
are limited when compressing a trained CNN model since 1) they are mostly
heuristic approaches without a precise understanding of their relations to
standard convolution, and 2) their accuracies do not match that of the standard
convolution. In this paper, we propose FALCON, an accurate and lightweight
method to compress CNN. FALCON uses GEP, our proposed mathematical formulation
to approximate the standard convolution kernel, to interpret existing
convolution methods based on depthwise separable convolution. By exploiting the
knowledge of a trained standard model and carefully determining the order of
depthwise separable convolution via GEP, FALCON achieves sufficient accuracy
close to that of the trained standard model. Furthermore, this interpretation
leads to developing a generalized version rank-k FALCON which performs k
independent FALCON operations and sums up the result. Experiments show that
FALCON 1) provides higher accuracy than existing methods based on depthwise
separable convolution and tensor decomposition, and 2) reduces the number of
parameters and FLOPs of standard convolution by up to a factor of 8 while
ensuring similar accuracy. We also demonstrate that rank-k FALCON further
improves the accuracy while sacrificing a bit of compression and computation
reduction rates.
</p>
<a href="http://arxiv.org/abs/1909.11321" target="_blank">arXiv:1909.11321</a> [<a href="http://arxiv.org/pdf/1909.11321" target="_blank">pdf</a>]

<h2>Convolutional Neural Networks with Dynamic Regularization. (arXiv:1909.11862v3 [cs.CV] UPDATED)</h2>
<h3>Yi Wang, Zhen-Peng Bian, Junhui Hou, Lap-Pui Chau</h3>
<p>Regularization is commonly used for alleviating overfitting in machine
learning. For convolutional neural networks (CNNs), regularization methods,
such as DropBlock and Shake-Shake, have illustrated the improvement in the
generalization performance. However, these methods lack a self-adaptive ability
throughout training. That is, the regularization strength is fixed to a
predefined schedule, and manual adjustments are required to adapt to various
network architectures. In this paper, we propose a dynamic regularization
method for CNNs. Specifically, we model the regularization strength as a
function of the training loss. According to the change of the training loss,
our method can dynamically adjust the regularization strength in the training
procedure, thereby balancing the underfitting and overfitting of CNNs. With
dynamic regularization, a large-scale model is automatically regularized by the
strong perturbation, and vice versa. Experimental results show that the
proposed method can improve the generalization capability on off-the-shelf
network architectures and outperform state-of-the-art regularization methods.
</p>
<a href="http://arxiv.org/abs/1909.11862" target="_blank">arXiv:1909.11862</a> [<a href="http://arxiv.org/pdf/1909.11862" target="_blank">pdf</a>]

<h2>On Warm-Starting Neural Network Training. (arXiv:1910.08475v3 [cs.LG] UPDATED)</h2>
<h3>Jordan T. Ash, Ryan P. Adams</h3>
<p>In many real-world deployments of machine learning systems, data arrive
piecemeal. These learning scenarios may be passive, where data arrive
incrementally due to structural properties of the problem (e.g., daily
financial data) or active, where samples are selected according to a measure of
their quality (e.g., experimental design). In both of these cases, we are
building a sequence of models that incorporate an increasing amount of data. We
would like each of these models in the sequence to be performant and take
advantage of all the data that are available to that point. Conventional
intuition suggests that when solving a sequence of related optimization
problems of this form, it should be possible to initialize using the solution
of the previous iterate -- to "warm start" the optimization rather than
initialize from scratch -- and see reductions in wall-clock time. However, in
practice this warm-starting seems to yield poorer generalization performance
than models that have fresh random initializations, even though the final
training losses are similar. While it appears that some hyperparameter settings
allow a practitioner to close this generalization gap, they seem to only do so
in regimes that damage the wall-clock gains of the warm start. Nevertheless, it
is highly desirable to be able to warm-start neural network training, as it
would dramatically reduce the resource usage associated with the construction
of performant deep learning systems. In this work, we take a closer look at
this empirical phenomenon and try to understand when and how it occurs. We also
provide a surprisingly simple trick that overcomes this pathology in several
important situations, and present experiments that elucidate some of its
properties.
</p>
<a href="http://arxiv.org/abs/1910.08475" target="_blank">arXiv:1910.08475</a> [<a href="http://arxiv.org/pdf/1910.08475" target="_blank">pdf</a>]

<h2>Graph-Revised Convolutional Network. (arXiv:1911.07123v3 [cs.LG] UPDATED)</h2>
<h3>Donghan Yu, Ruohong Zhang, Zhengbao Jiang, Yuexin Wu, Yiming Yang</h3>
<p>Graph Convolutional Networks (GCNs) have received increasing attention in the
machine learning community for effectively leveraging both the content features
of nodes and the linkage patterns across graphs in various applications. As
real-world graphs are often incomplete and noisy, treating them as ground-truth
information, which is a common practice in most GCNs, unavoidably leads to
sub-optimal solutions. Existing efforts for addressing this problem either
involve an over-parameterized model which is difficult to scale, or simply
re-weight observed edges without dealing with the missing-edge issue. This
paper proposes a novel framework called Graph-Revised Convolutional Network
(GRCN), which avoids both extremes. Specifically, a GCN-based graph revision
module is introduced for predicting missing edges and revising edge weights
w.r.t. downstream tasks via joint optimization. A theoretical analysis reveals
the connection between GRCN and previous work on multigraph belief propagation.
Experiments on six benchmark datasets show that GRCN consistently outperforms
strong baseline methods by a large margin, especially when the original graphs
are severely incomplete or the labeled instances for model training are highly
sparse.
</p>
<a href="http://arxiv.org/abs/1911.07123" target="_blank">arXiv:1911.07123</a> [<a href="http://arxiv.org/pdf/1911.07123" target="_blank">pdf</a>]

<h2>The Devil is in the Details: Delving into Unbiased Data Processing for Human Pose Estimation. (arXiv:1911.07524v2 [cs.CV] UPDATED)</h2>
<h3>Junjie Huang, Zheng Zhu, Feng Guo, Guan Huang, Dalong Du</h3>
<p>Being a fundamental component in training and inference, data processing has
not been systematically considered in human pose estimation community, to the
best of our knowledge. In this paper, we focus on this problem and find that
the devil of human pose estimation evolution is in the biased data processing.
Specifically, by investigating the standard data processing in state-of-the-art
approaches mainly including coordinate system transformation and keypoint
format transformation (i.e., encoding and decoding), we find that the results
obtained by common flipping strategy are unaligned with the original ones in
inference. Moreover, there is a statistical error in some keypoint format
transformation methods. Two problems couple together, significantly degrade the
pose estimation performance and thus lay a trap for the research community.
This trap has given bone to many suboptimal remedies, which are always
unreported, confusing but influential. By causing failure in reproduction and
unfair in comparison, the unreported remedies seriously impedes the
technological development. To tackle this dilemma from the source, we propose
Unbiased Data Processing (UDP) consist of two technique aspect for the two
aforementioned problems respectively (i.e., unbiased coordinate system
transformation and unbiased keypoint format transformation). As a
model-agnostic approach and a superior solution, UDP successfully pushes the
performance boundary of human pose estimation and offers a higher and more
reliable baseline for research community. Code is public available in
https://github.com/HuangJunJie2017/UDP-Pose
</p>
<a href="http://arxiv.org/abs/1911.07524" target="_blank">arXiv:1911.07524</a> [<a href="http://arxiv.org/pdf/1911.07524" target="_blank">pdf</a>]

<h2>Deeply Shape-guided Cascade for High Quality Instance Segmentation. (arXiv:1911.11263v3 [cs.CV] UPDATED)</h2>
<h3>Hao Ding, Siyuan Qiao, Alan Yuille, Wei Shen</h3>
<p>The key to a successful cascade architecture for high quality instance
segmentation is to fully leverage the relationship between bounding box
detection and mask segmentation across multiple stages. Although modern
instance segmentation cascades achieve leading performance, they mainly make
use of an unidirectional relationship, i.e., mask segmentation can benefit from
iteratively refined bounding box detection. In this paper, we investigate an
alternative direction, i.e., how to take the advantage of precise mask
segmentation for bounding box detection in a cascade architecture. We propose a
Deeply Shape-guided Cascade (DSC) for instance segmentation, which iteratively
imposes the shape guidances extracted from mask prediction at previous stage on
bounding box detection at current stage. It forms a bi-directional relationship
between the two tasks by introducing three key components: (1) Initial shape
guidance: A mask-supervised Region Proposal Network (mPRN) with the ability to
generate class-agnostic masks; (2) Explicit shape guidance: A mask-guided
region-of-interest (RoI) feature extractor, which employs mask segmentation at
previous stage to focus feature extraction at current stage within a region
aligned well with the shape of the instance-of-interest rather than a
rectangular RoI; (3) Implicit shape guidance: A feature fusion operation which
feeds intermediate mask features at previous stage to the bounding box head at
current stage. Experimental results show that, DSC outperforms the
state-of-the-art instance segmentation cascade, Hybrid Task Cascade (HTC), by a
large margin and achieves 51.8 box AP and 45.5 mask AP on COCO test-dev.
</p>
<a href="http://arxiv.org/abs/1911.11263" target="_blank">arXiv:1911.11263</a> [<a href="http://arxiv.org/pdf/1911.11263" target="_blank">pdf</a>]

<h2>DEGAS: Differentiable Efficient Generator Search. (arXiv:1912.00606v3 [cs.CV] UPDATED)</h2>
<h3>Sivan Doveh, Raja Giryes</h3>
<p>Network architecture search (NAS) achieves state-of-the-art results in
various tasks such as classification and semantic segmentation. Recently, a
reinforcement learning-based approach has been proposed for Generative
Adversarial Networks (GANs) search. In this work, we propose an alternative
strategy for GAN search by using a method called DEGAS (Differentiable
Efficient GenerAtor Search), which focuses on efficiently finding the generator
in the GAN. Our search algorithm is inspired by the differential architecture
search strategy and the Global Latent Optimization (GLO) procedure. This leads
to both an efficient and stable GAN search. After the generator architecture is
found, it can be plugged into any existing framework for GAN training. For
CTGAN, which we use in this work, the new model outperforms the original
inception score results by 0.25 for CIFAR-10 and 0.77 for STL. It also gets
better results than the RL based GAN search methods in shorter search time.
</p>
<a href="http://arxiv.org/abs/1912.00606" target="_blank">arXiv:1912.00606</a> [<a href="http://arxiv.org/pdf/1912.00606" target="_blank">pdf</a>]

<h2>Occlusion-Robust Online Multi-Object Visual Tracking using a GM-PHD Filter with CNN-Based Re-Identification. (arXiv:1912.05949v5 [cs.CV] UPDATED)</h2>
<h3>Nathanael L. Baisa</h3>
<p>We propose a novel online multi-object visual tracking algorithm via a
tracking-by-detection paradigm using a Gaussian mixture Probability Hypothesis
Density (GM-PHD) filter and deep Convolutional Neural Network (CNN) appearance
representations learning. The GM-PHD filter has a linear complexity with the
number of objects and observations while estimating the states and cardinality
of unknown and time-varying number of objects in the scene. Though it handles
object birth, death and clutter in a unified framework, it is susceptible to
miss-detections and does not include the identity of objects. We use
visual-spatio-temporal information obtained from object bounding boxes and
deeply learned appearance representations to perform estimates-to-tracks data
association for labeling of each target as well as formulate an augmented
likelihood and then integrate into the update step of the GM-PHD filter. We
learn the deep CNN appearance representations by training an identification
network (IdNet) on large-scale person re-identification data sets. We also
employ additional unassigned tracks prediction after the data association step
to overcome the susceptibility of the GM-PHD filter towards miss-detections
caused by occlusion. Our tracker which runs in real-time is applied to track
multiple objects in video sequences acquired under varying environmental
conditions and objects density. Lastly, we make extensive evaluations on
Multiple Object Tracking 2016 (MOT16) and 2017 (MOT17) benchmark data sets and
find out that our online tracker significantly outperforms several
state-of-the-art trackers in terms of tracking accuracy and identification.
</p>
<a href="http://arxiv.org/abs/1912.05949" target="_blank">arXiv:1912.05949</a> [<a href="http://arxiv.org/pdf/1912.05949" target="_blank">pdf</a>]

<h2>A Modern Introduction to Online Learning. (arXiv:1912.13213v3 [cs.LG] UPDATED)</h2>
<h3>Francesco Orabona</h3>
<p>In this monograph, I introduce the basic concepts of Online Learning through
a modern view of Online Convex Optimization. Here, online learning refers to
the framework of regret minimization under worst-case assumptions. I present
first-order and second-order algorithms for online learning with convex losses,
in Euclidean and non-Euclidean settings. All the algorithms are clearly
presented as instantiation of Online Mirror Descent or
Follow-The-Regularized-Leader and their variants. Particular attention is given
to the issue of tuning the parameters of the algorithms and learning in
unbounded domains, through adaptive and parameter-free online learning
algorithms. Non-convex losses are dealt through convex surrogate losses and
through randomization. The bandit setting is also briefly discussed, touching
on the problem of adversarial and stochastic multi-armed bandits. These notes
do not require prior knowledge of convex analysis and all the required
mathematical tools are rigorously explained. Moreover, all the proofs have been
carefully chosen to be as simple and as short as possible.
</p>
<a href="http://arxiv.org/abs/1912.13213" target="_blank">arXiv:1912.13213</a> [<a href="http://arxiv.org/pdf/1912.13213" target="_blank">pdf</a>]

<h2>RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion Segmentation. (arXiv:2001.09138v4 [cs.CV] UPDATED)</h2>
<h3>Juan Miguel Valverde, Artem Shatillo, Riccardo de Feo, Olli Gr&#xf6;hn, Alejandra Sierra, Jussi Tohka</h3>
<p>We present a fully convolutional neural network (ConvNet), named RatLesNetv2,
for segmenting lesions in rodent magnetic resonance (MR) brain images.
RatLesNetv2 architecture resembles an autoencoder and it incorporates residual
blocks that facilitate its optimization. RatLesNetv2 is trained end to end on
three-dimensional images and it requires no preprocessing. We evaluated
RatLesNetv2 on an exceptionally large dataset composed of 916 T2-weighted rat
brain MRI scans of 671 rats at nine different lesion stages that were used to
study focal cerebral ischemia for drug development. In addition, we compared
its performance with three other ConvNets specifically designed for medical
image segmentation. RatLesNetv2 obtained similar to higher Dice coefficient
values than the other ConvNets and it produced much more realistic and compact
segmentations with notably fewer holes and lower Hausdorff distance. The Dice
scores of RatLesNetv2 segmentations also exceeded inter-rater agreement of
manual segmentations. In conclusion, RatLesNetv2 could be used for automated
lesion segmentation, reducing human workload and improving reproducibility.
RatLesNetv2 is publicly available at https://github.com/jmlipman/RatLesNetv2.
</p>
<a href="http://arxiv.org/abs/2001.09138" target="_blank">arXiv:2001.09138</a> [<a href="http://arxiv.org/pdf/2001.09138" target="_blank">pdf</a>]

<h2>Multi-class Gaussian Process Classification with Noisy Inputs. (arXiv:2001.10523v3 [stat.ML] UPDATED)</h2>
<h3>Carlos Villacampa-Calvo, Bryan Zaldivar, Eduardo C. Garrido-Merch&#xe1;n, Daniel Hern&#xe1;ndez-Lobato</h3>
<p>It is a common practice in the machine learning community to assume that the
observed data are noise-free in the input attributes. Nevertheless, scenarios
with input noise are common in real problems, as measurements are never
perfectly accurate. If this input noise is not taken into account, a supervised
machine learning method is expected to perform sub-optimally. In this paper, we
focus on multi-class classification problems and use Gaussian processes (GPs)
as the underlying classifier. Motivated by a data set coming from the
astrophysics domain, we hypothesize that the observed data may contain noise in
the inputs. Therefore, we devise several multi-class GP classifiers that can
account for input noise. Such classifiers can be efficiently trained using
variational inference to approximate the posterior distribution of the latent
variables of the model. Moreover, in some situations, the amount of noise can
be known before-hand. If this is the case, it can be readily introduced in the
proposed methods. This prior information is expected to lead to better
performance results. We have evaluated the proposed methods by carrying out
several experiments, involving synthetic and real data. These include several
data sets from the UCI repository, the MNIST data set and a data set coming
from astrophysics. The results obtained show that, although the classification
error is similar across methods, the predictive distribution of the proposed
methods is better, in terms of the test log-likelihood, than the predictive
distribution of a classifier based on GPs that ignores input noise.
</p>
<a href="http://arxiv.org/abs/2001.10523" target="_blank">arXiv:2001.10523</a> [<a href="http://arxiv.org/pdf/2001.10523" target="_blank">pdf</a>]

<h2>An Autonomous Intrusion Detection System Using an Ensemble of Advanced Learners. (arXiv:2001.11936v2 [cs.LG] UPDATED)</h2>
<h3>Amir Andalib, Vahid Tabataba Vakili</h3>
<p>An intrusion detection system (IDS) is a vital security component of modern
computer networks. With the increasing amount of sensitive services that use
computer network-based infrastructures, IDSs need to be more intelligent and
autonomous. Aside from autonomy, another important feature for an IDS is its
ability to detect zero-day attacks. To address these issues, in this paper, we
propose an IDS which reduces the amount of manual interaction and needed expert
knowledge and is able to yield acceptable performance under zero-day attacks.
Our approach is to use three learning techniques in parallel: gated recurrent
unit (GRU), convolutional neural network as deep techniques and random forest
as an ensemble technique. These systems are trained in parallel and the results
are combined under two logics: majority vote and "OR" logic. We use the NSL-KDD
dataset to verify the proficiency of our proposed system. Simulation results
show that the system has the potential to operate with a very low technician
interaction under the zero-day attacks. We achieved 87:28% accuracy on the
NSL-KDD's "KDDTest+" dataset and 76:61% accuracy on the challenging
"KDDTest-21" with lower training time and lower needed computational resources.
</p>
<a href="http://arxiv.org/abs/2001.11936" target="_blank">arXiv:2001.11936</a> [<a href="http://arxiv.org/pdf/2001.11936" target="_blank">pdf</a>]

<h2>On Implicit Regularization in $\beta$-VAEs. (arXiv:2002.00041v4 [cs.LG] UPDATED)</h2>
<h3>Abhishek Kumar, Ben Poole</h3>
<p>While the impact of variational inference (VI) on posterior inference in a
fixed generative model is well-characterized, its role in regularizing a
learned generative model when used in variational autoencoders (VAEs) is poorly
understood. We study the regularizing effects of variational distributions on
learning in generative models from two perspectives. First, we analyze the role
that the choice of variational family plays in imparting uniqueness to the
learned model by restricting the set of optimal generative models. Second, we
study the regularization effect of the variational family on the local geometry
of the decoding model. This analysis uncovers the regularizer implicit in the
$\beta$-VAE objective, and leads to an approximation consisting of a
deterministic autoencoding objective plus analytic regularizers that depend on
the Hessian or Jacobian of the decoding model, unifying VAEs with recent
heuristics proposed for training regularized autoencoders. We empirically
verify these findings, observing that the proposed deterministic objective
exhibits similar behavior to the $\beta$-VAE in terms of objective value and
sample quality.
</p>
<a href="http://arxiv.org/abs/2002.00041" target="_blank">arXiv:2002.00041</a> [<a href="http://arxiv.org/pdf/2002.00041" target="_blank">pdf</a>]

<h2>Bandits with Knapsacks beyond the Worst-Case Analysis. (arXiv:2002.00253v2 [cs.LG] UPDATED)</h2>
<h3>Karthik Abinav Sankararaman, Aleksandrs Slivkins</h3>
<p>"Bandits with Knapsacks" (BwK) is a general model for multi-armed bandits
under supply/budget constraints. While worst-case regret bounds for BwK are
well-understood, we present three results that go beyond the worst-case
perspective. First, we provide upper and lower bounds which amount to a full
characterization for logarithmic, instance-dependent regret rates. Second, we
consider "simple regret" in BwK, which tracks the algorithm's performance in a
given round, and prove that it is small in all but a few rounds. Third, we
provide a general template for extensions from bandits to BwK which takes
advantage of some known helpful structure and apply this template to
combinatorial semi-bandits and linear contextual bandits. Our results build on
the BwK algorithm from (Agrawal and Devanur, 2014), providing new analyses
thereof.
</p>
<a href="http://arxiv.org/abs/2002.00253" target="_blank">arXiv:2002.00253</a> [<a href="http://arxiv.org/pdf/2002.00253" target="_blank">pdf</a>]

<h2>Neural Network Compression Framework for fast model inference. (arXiv:2002.08679v4 [cs.CV] UPDATED)</h2>
<h3>Alexander Kozlov, Ivan Lazarevich, Vasily Shamporov, Nikolay Lyalyushkin, Yury Gorbachev</h3>
<p>In this work we present a new framework for neural networks compression with
fine-tuning, which we called Neural Network Compression Framework (NNCF). It
leverages recent advances of various network compression methods and implements
some of them, such as sparsity, quantization, and binarization. These methods
allow getting more hardware-friendly models which can be efficiently run on
general-purpose hardware computation units (CPU, GPU) or special Deep Learning
accelerators. We show that the developed methods can be successfully applied to
a wide range of models to accelerate the inference time while keeping the
original accuracy. The framework can be used within the training samples, which
are supplied with it, or as a standalone package that can be seamlessly
integrated into the existing training code with minimal adaptations. Currently,
a PyTorch version of NNCF is available as a part of OpenVINO Training
Extensions at https://github.com/openvinotoolkit/nncf.
</p>
<a href="http://arxiv.org/abs/2002.08679" target="_blank">arXiv:2002.08679</a> [<a href="http://arxiv.org/pdf/2002.08679" target="_blank">pdf</a>]

<h2>An Elementary Approach to Convergence Guarantees of Optimization Algorithms for Deep Networks. (arXiv:2002.09051v2 [cs.LG] UPDATED)</h2>
<h3>Vincent Roulet, Zaid Harchaoui</h3>
<p>We present an approach to obtain convergence guarantees of optimization
algorithms for deep networks based on elementary arguments and computations.
The convergence analysis revolves around the analytical and computational
structures of optimization oracles central to the implementation of deep
networks in machine learning software. We provide a systematic way to compute
estimates of the smoothness constants that govern the convergence behavior of
first-order optimization algorithms used to train deep networks. A diverse set
of example components and architectures arising in modern deep networks
intersperse the exposition to illustrate the approach.
</p>
<a href="http://arxiv.org/abs/2002.09051" target="_blank">arXiv:2002.09051</a> [<a href="http://arxiv.org/pdf/2002.09051" target="_blank">pdf</a>]

<h2>When are Non-Parametric Methods Robust?. (arXiv:2003.06121v2 [cs.LG] UPDATED)</h2>
<h3>Robi Bhattacharjee, Kamalika Chaudhuri</h3>
<p>A growing body of research has shown that many classifiers are susceptible to
{\em{adversarial examples}} -- small strategic modifications to test inputs
that lead to misclassification. In this work, we study general non-parametric
methods, with a view towards understanding when they are robust to these
modifications. We establish general conditions under which non-parametric
methods are r-consistent -- in the sense that they converge to optimally robust
and accurate classifiers in the large sample limit.

Concretely, our results show that when data is well-separated, nearest
neighbors and kernel classifiers are r-consistent, while histograms are not.
For general data distributions, we prove that preprocessing by Adversarial
Pruning (Yang et. al., 2019) -- that makes data well-separated -- followed by
nearest neighbors or kernel classifiers also leads to r-consistency.
</p>
<a href="http://arxiv.org/abs/2003.06121" target="_blank">arXiv:2003.06121</a> [<a href="http://arxiv.org/pdf/2003.06121" target="_blank">pdf</a>]

<h2>Preferential Batch Bayesian Optimization. (arXiv:2003.11435v2 [cs.LG] UPDATED)</h2>
<h3>Eero Siivola, Akash Kumar Dhaka, Michael Riis Andersen, Javier Gonzalez, Pablo Garcia Moreno, Aki Vehtari</h3>
<p>Most research in Bayesian optimization (BO) has focused on \emph{direct
feedback} scenarios, where one has access to exact, or perturbed, values of
some expensive-to-evaluate objective. This direction has been mainly driven by
the use of \bo in machine learning hyper-parameter configuration problems.
However, in domains such as modelling human preferences, A/B tests or
recommender systems, there is a need of methods that are able to replace direct
feedback with \emph{preferential feedback}, obtained via rankings or pairwise
comparisons. In this work, we present Preferential Batch Bayesian Optimization
(PBBO), a new framework that allows to find the optimum of a latent function of
interest, given any type of parallel preferential feedback for a group of two
or more points. We do so by using a Gaussian process model with a likelihood
specially designed to enable parallel and efficient data collection mechanisms,
which are key in modern machine learning. We show how the acquisitions
developed under this framework generalize and augment previous approaches in
Bayesian optimization, expanding the use of these techniques to a wider range
of domains. An extensive simulation study shows the benefits of this approach,
both with simulated functions and four real data sets.
</p>
<a href="http://arxiv.org/abs/2003.11435" target="_blank">arXiv:2003.11435</a> [<a href="http://arxiv.org/pdf/2003.11435" target="_blank">pdf</a>]

<h2>AliExpress Learning-To-Rank: Maximizing Online Model Performance without Going Online. (arXiv:2003.11941v5 [cs.LG] UPDATED)</h2>
<h3>Guangda Huzhang, Zhen-Jia Pang, Yongqing Gao, Yawen Liu, Weijie Shen, Wen-Ji Zhou, Qing Da, An-Xiang Zeng, Han Yu, Yang Yu, Zhi-Hua Zhou</h3>
<p>Learning-to-rank (LTR) has become a key technology in E-commerce
applications. Most existing LTR approaches follow a supervised learning
paradigm from offline labeled data collected from the online system. However,
it has been noticed that previous LTR models can have a good validation
performance over offline validation data but have a poor online performance,
and vice versa, which implies a possible large inconsistency between the
offline and online evaluation. We investigate and confirm in this paper that
such inconsistency exists and can have a significant impact on AliExpress
Search. Reasons for the inconsistency include the ignorance of item context
during the learning, and the offline data set is insufficient for learning the
context. Therefore, this paper proposes an evaluator-generator framework for
LTR with item context. The framework consists of an evaluator that generalizes
to evaluate recommendations involving the context, and a generator that
maximizes the evaluator score by reinforcement learning, and a discriminator
that ensures the generalization of the evaluator. Extensive experiments in
simulation environments and AliExpress Search online system show that, firstly,
the classic data-based metrics on the offline dataset can show significant
inconsistency with online performance, and can even be misleading. Secondly,
the proposed evaluator score is significantly more consistent with the online
performance than common ranking metrics. Finally, as the consequence, our
method achieves a significant improvement (\textgreater$2\%$) in terms of
Conversion Rate (CR) over the industrial-level fine-tuned model in online A/B
tests.
</p>
<a href="http://arxiv.org/abs/2003.11941" target="_blank">arXiv:2003.11941</a> [<a href="http://arxiv.org/pdf/2003.11941" target="_blank">pdf</a>]

<h2>Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program). (arXiv:2003.12206v4 [cs.LG] UPDATED)</h2>
<h3>Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent Larivi&#xe8;re, Alina Beygelzimer, Florence d&#x27;Alch&#xe9;-Buc, Emily Fox, Hugo Larochelle</h3>
<p>One of the challenges in machine learning research is to ensure that
presented and published results are sound and reliable. Reproducibility, that
is obtaining similar results as presented in a paper or talk, using the same
code and data (when available), is a necessary step to verify the reliability
of research findings. Reproducibility is also an important step to promote open
and accessible research, thereby allowing the scientific community to quickly
integrate new findings and convert ideas to practice. Reproducibility also
promotes the use of robust experimental workflows, which potentially reduce
unintentional errors. In 2019, the Neural Information Processing Systems
(NeurIPS) conference, the premier international conference for research in
machine learning, introduced a reproducibility program, designed to improve the
standards across the community for how we conduct, communicate, and evaluate
machine learning research. The program contained three components: a code
submission policy, a community-wide reproducibility challenge, and the
inclusion of the Machine Learning Reproducibility checklist as part of the
paper submission process. In this paper, we describe each of these components,
how it was deployed, as well as what we were able to learn from this
initiative.
</p>
<a href="http://arxiv.org/abs/2003.12206" target="_blank">arXiv:2003.12206</a> [<a href="http://arxiv.org/pdf/2003.12206" target="_blank">pdf</a>]

<h2>Counterfactual Multi-Agent Reinforcement Learning with Graph Convolution Communication. (arXiv:2004.00470v2 [cs.AI] UPDATED)</h2>
<h3>Jianyu Su, Stephen Adams, Peter A. Beling</h3>
<p>We consider a fully cooperative multi-agent system where agents cooperate to
maximize a system's utility in a partial-observable environment. We propose
that multi-agent systems must have the ability to (1) communicate and
understand the inter-plays between agents and (2) correctly distribute rewards
based on an individual agent's contribution. In contrast, most work in this
setting considers only one of the above abilities. In this study, we develop an
architecture that allows for communication among agents and tailors the
system's reward for each individual agent. Our architecture represents agent
communication through graph convolution and applies an existing credit
assignment structure, counterfactual multi-agent policy gradient (COMA), to
assist agents to learn communication by back-propagation. The flexibility of
the graph structure enables our method to be applicable to a variety of
multi-agent systems, e.g. dynamic systems that consist of varying numbers of
agents and static systems with a fixed number of agents. We evaluate our method
on a range of tasks, demonstrating the advantage of marrying communication with
credit assignment. In the experiments, our proposed method yields better
performance than the state-of-art methods, including COMA. Moreover, we show
that the communication strategies offers us insights and interpretability of
the system's cooperative policies.
</p>
<a href="http://arxiv.org/abs/2004.00470" target="_blank">arXiv:2004.00470</a> [<a href="http://arxiv.org/pdf/2004.00470" target="_blank">pdf</a>]

<h2>Model-based actor-critic: GAN + DRL (actor-critic) => AGI. (arXiv:2004.04574v5 [cs.AI] UPDATED)</h2>
<h3>Aras Dargazany</h3>
<p>Our effort is toward unifying GAN and DRL algorithms into a unifying AI model
(AGI or general-purpose AI or artificial general intelligence which has
general-purpose applications to: (A) offline learning (of stored data) like GAN
in (un/semi-/fully-)SL setting such as big data analytics (mining) and
visualization; (B) online learning (of real or simulated devices) like DRL in
RL setting (with/out environment reward) such as (real or simulated) robotics
and control; Our core proposal is adding an (generative/predictive) environment
model to the actor-critic (model-free) architecture which results in a
model-based actor-critic architecture with temporal-differencing (TD) error and
an episodic memory. The proposed AI model is similar to (model-free) DDPG and
therefore it's called model-based DDPG. To evaluate it, we compare it with
(model-free) DDPG by applying them both to a variety (wide range) of
independent simulated robotic and control task environments in OpenAI Gym and
Unity Agents. Our initial limited experiments show that DRL and GAN in
model-based actor-critic results in an incremental goal-driven intellignce
required to solve each task with similar performance to (model-free) DDPG. Our
future focus is to investigate the proposed AI model potential to: (A) unify
DRL field inside AI by producing competitive performance compared to the best
of model-based (PlaNet) and model-free (D4PG) approaches; (B) bridge the gap
between AI and robotics communities by solving the important problem of reward
engineering with learning the reward function by demonstration.
</p>
<a href="http://arxiv.org/abs/2004.04574" target="_blank">arXiv:2004.04574</a> [<a href="http://arxiv.org/pdf/2004.04574" target="_blank">pdf</a>]

<h2>End-to-end Learning Improves Static Object Geo-localization in Monocular Video. (arXiv:2004.05232v3 [cs.CV] UPDATED)</h2>
<h3>Mohamed Chaabane, Lionel Gueguen, Ameni Trabelsi, Ross Beveridge, Stephen O&#x27;Hara</h3>
<p>Accurately estimating the position of static objects, such as traffic lights,
from the moving camera of a self-driving car is a challenging problem. In this
work, we present a system that improves the localization of static objects by
jointly-optimizing the components of the system via learning. Our system is
comprised of networks that perform: 1) 5DoF object pose estimation from a
single image, 2) association of objects between pairs of frames, and 3)
multi-object tracking to produce the final geo-localization of the static
objects within the scene. We evaluate our approach using a publicly-available
data set, focusing on traffic lights due to data availability. For each
component, we compare against contemporary alternatives and show
significantly-improved performance. We also show that the end-to-end system
performance is further improved via joint-training of the constituent models.
</p>
<a href="http://arxiv.org/abs/2004.05232" target="_blank">arXiv:2004.05232</a> [<a href="http://arxiv.org/pdf/2004.05232" target="_blank">pdf</a>]

<h2>Principal Neighbourhood Aggregation for Graph Nets. (arXiv:2004.05718v5 [cs.LG] UPDATED)</h2>
<h3>Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li&#xf2;, Petar Veli&#x10d;kovi&#x107;</h3>
<p>Graph Neural Networks (GNNs) have been shown to be effective models for
different predictive tasks on graph-structured data. Recent work on their
expressive power has focused on isomorphism tasks and countable feature spaces.
We extend this theoretical framework to include continuous features - which
occur regularly in real-world input domains and within the hidden layers of
GNNs - and we demonstrate the requirement for multiple aggregation functions in
this context. Accordingly, we propose Principal Neighbourhood Aggregation
(PNA), a novel architecture combining multiple aggregators with degree-scalers
(which generalize the sum aggregator). Finally, we compare the capacity of
different models to capture and exploit the graph structure via a novel
benchmark containing multiple tasks taken from classical graph theory,
alongside existing benchmarks from real-world domains, all of which demonstrate
the strength of our model. With this work, we hope to steer some of the GNN
research towards new aggregation methods which we believe are essential in the
search for powerful and robust models.
</p>
<a href="http://arxiv.org/abs/2004.05718" target="_blank">arXiv:2004.05718</a> [<a href="http://arxiv.org/pdf/2004.05718" target="_blank">pdf</a>]

<h2>Geometry-Aware Gradient Algorithms for Neural Architecture Search. (arXiv:2004.07802v4 [cs.LG] UPDATED)</h2>
<h3>Liam Li, Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar</h3>
<p>Recent state-of-the-art methods for neural architecture search (NAS) exploit
gradient-based optimization by relaxing the problem into continuous
optimization over architectures and shared-weights, a noisy process that
remains poorly understood. We argue for the study of single-level empirical
risk minimization to understand NAS with weight-sharing, reducing the design of
NAS methods to devising optimizers and regularizers that can quickly obtain
high-quality solutions to this problem. Invoking the theory of mirror descent,
we present a geometry-aware framework that exploits the underlying structure of
this optimization to return sparse architectural parameters, leading to simple
yet novel algorithms that enjoy fast convergence guarantees and achieve
state-of-the-art accuracy on the latest NAS benchmarks in computer vision.
Notably, we exceed the best published results for both CIFAR and ImageNet on
both the DARTS search space and NAS-Bench-201; on the latter we achieve
near-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory
and experiments demonstrate a principled way to co-design optimizers and
continuous relaxations of discrete NAS search spaces.
</p>
<a href="http://arxiv.org/abs/2004.07802" target="_blank">arXiv:2004.07802</a> [<a href="http://arxiv.org/pdf/2004.07802" target="_blank">pdf</a>]

<h2>DMT: Dynamic Mutual Training for Semi-Supervised Learning. (arXiv:2004.08514v2 [cs.CV] UPDATED)</h2>
<h3>Zhengyang Feng, Qianyu Zhou, Qiqi Gu, Xin Tan, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma</h3>
<p>Recent semi-supervised learning methods use pseudo supervision as core idea,
especially self-training methods that generate pseudo labels. However, pseudo
labels are unreliable. Self-training methods usually rely on single model
prediction confidence to filter low-confidence pseudo labels, thus remaining
high-confidence errors and wasting many low-confidence correct labels. In this
paper, we point out it is difficult for a model to counter its own errors.
Instead, leveraging inter-model disagreement between different models is a key
to locate pseudo label errors. With this new viewpoint, we propose mutual
training between two different models by a dynamically re-weighted loss
function, called Dynamic Mutual Training (DMT). We quantify inter-model
disagreement by comparing predictions from two different models to dynamically
re-weight loss in training, where a larger disagreement indicates a possible
error and corresponds to a lower loss value. Extensive experiments show that
DMT achieves state-of-the-art performance in both image classification and
semantic segmentation. Our codes are released at
https://github.com/voldemortX/DST-CBC .
</p>
<a href="http://arxiv.org/abs/2004.08514" target="_blank">arXiv:2004.08514</a> [<a href="http://arxiv.org/pdf/2004.08514" target="_blank">pdf</a>]

<h2>ResNeSt: Split-Attention Networks. (arXiv:2004.08955v2 [cs.CV] UPDATED)</h2>
<h3>Hang Zhang, Chongruo Wu, Zhongyue Zhang, Yi Zhu, Haibin Lin, Zhi Zhang, Yue Sun, Tong He, Jonas Mueller, R. Manmatha, Mu Li, Alexander Smola</h3>
<p>It is well known that featuremap attention and multi-path representation are
important for visual recognition. In this paper, we present a modularized
architecture, which applies the channel-wise attention on different network
branches to leverage their success in capturing cross-feature interactions and
learning diverse representations. Our design results in a simple and unified
computation block, which can be parameterized using only a few variables. Our
model, named ResNeSt, outperforms EfficientNet in accuracy and latency
trade-off on image classification. In addition, ResNeSt has achieved superior
transfer learning results on several public benchmarks serving as the backbone,
and has been adopted by the winning entries of COCO-LVIS challenge. The source
code for complete system and pretrained models are publicly available.
</p>
<a href="http://arxiv.org/abs/2004.08955" target="_blank">arXiv:2004.08955</a> [<a href="http://arxiv.org/pdf/2004.08955" target="_blank">pdf</a>]

<h2>Measuring the Discrepancy between Conditional Distributions: Methods, Properties and Applications. (arXiv:2005.02196v2 [cs.LG] UPDATED)</h2>
<h3>Shujian Yu, Ammar Shaker, Francesco Alesiani, Jose C. Principe</h3>
<p>We propose a simple yet powerful test statistic to quantify the discrepancy
between two conditional distributions. The new statistic avoids the explicit
estimation of the underlying distributions in highdimensional space and it
operates on the cone of symmetric positive semidefinite (SPS) matrix using the
Bregman matrix divergence. Moreover, it inherits the merits of the correntropy
function to explicitly incorporate high-order statistics in the data. We
present the properties of our new statistic and illustrate its connections to
prior art. We finally show the applications of our new statistic on three
different machine learning problems, namely the multi-task learning over
graphs, the concept drift detection, and the information-theoretic feature
selection, to demonstrate its utility and advantage. Code of our statistic is
available at https://bit.ly/BregmanCorrentropy.
</p>
<a href="http://arxiv.org/abs/2005.02196" target="_blank">arXiv:2005.02196</a> [<a href="http://arxiv.org/pdf/2005.02196" target="_blank">pdf</a>]

<h2>An Experimental Study of Reduced-Voltage Operation in Modern FPGAs for Neural Network Acceleration. (arXiv:2005.03451v2 [cs.LG] UPDATED)</h2>
<h3>Behzad Salami, Erhan Baturay Onural, Ismail Emir Yuksel, Fahrettin Koc, Oguz Ergin, Adrian Cristal Kestelman, Osman S. Unsal, Hamid Sarbazi-Azad, Onur Mutlu</h3>
<p>We empirically evaluate an undervolting technique, i.e., underscaling the
circuit supply voltage below the nominal level, to improve the power-efficiency
of Convolutional Neural Network (CNN) accelerators mapped to Field Programmable
Gate Arrays (FPGAs). Undervolting below a safe voltage level can lead to timing
faults due to excessive circuit latency increase. We evaluate the
reliability-power trade-off for such accelerators. Specifically, we
experimentally study the reduced-voltage operation of multiple components of
real FPGAs, characterize the corresponding reliability behavior of CNN
accelerators, propose techniques to minimize the drawbacks of reduced-voltage
operation, and combine undervolting with architectural CNN optimization
techniques, i.e., quantization and pruning. We investigate the effect of
environmental temperature on the reliability-power trade-off of such
accelerators. We perform experiments on three identical samples of modern
Xilinx ZCU102 FPGA platforms with five state-of-the-art image classification
CNN benchmarks. This approach allows us to study the effects of our
undervolting technique for both software and hardware variability. We achieve
more than 3X power-efficiency (GOPs/W) gain via undervolting. 2.6X of this gain
is the result of eliminating the voltage guardband region, i.e., the safe
voltage region below the nominal level that is set by FPGA vendor to ensure
correct functionality in worst-case environmental and circuit conditions. 43%
of the power-efficiency gain is due to further undervolting below the
guardband, which comes at the cost of accuracy loss in the CNN accelerator. We
evaluate an effective frequency underscaling technique that prevents this
accuracy loss, and find that it reduces the power-efficiency gain from 43% to
25%.
</p>
<a href="http://arxiv.org/abs/2005.03451" target="_blank">arXiv:2005.03451</a> [<a href="http://arxiv.org/pdf/2005.03451" target="_blank">pdf</a>]

<h2>Reference Pose Generation for Long-term Visual Localization via Learned Features and View Synthesis. (arXiv:2005.05179v4 [cs.CV] UPDATED)</h2>
<h3>Zichao Zhang, Torsten Sattler, Davide Scaramuzza</h3>
<p>Visual Localization is one of the key enabling technologies for autonomous
driving and augmented reality. High quality datasets with accurate 6
Degree-of-Freedom (DoF) reference poses are the foundation for benchmarking and
improving existing methods. Traditionally, reference poses have been obtained
via Structure-from-Motion (SfM). However, SfM itself relies on local features
which are prone to fail when images were taken under different conditions,
e.g., day/ night changes. At the same time, manually annotating feature
correspondences is not scalable and potentially inaccurate. In this work, we
propose a semi-automated approach to generate reference poses based on feature
matching between renderings of a 3D model and real images via learned features.
Given an initial pose estimate, our approach iteratively refines the pose based
on feature matches against a rendering of the model from the current pose
estimate. We significantly improve the nighttime reference poses of the popular
Aachen Day-Night dataset, showing that state-of-the-art visual localization
methods perform better (up to $47\%$) than predicted by the original reference
poses. We extend the dataset with new nighttime test images, provide
uncertainty estimates for our new reference poses, and introduce a new
evaluation criterion. We will make our reference poses and our framework
publicly available upon publication.
</p>
<a href="http://arxiv.org/abs/2005.05179" target="_blank">arXiv:2005.05179</a> [<a href="http://arxiv.org/pdf/2005.05179" target="_blank">pdf</a>]

<h2>Bi-directional Exponential Angular Triplet Loss for RGB-Infrared Person Re-Identification. (arXiv:2006.00878v5 [cs.CV] UPDATED)</h2>
<h3>Hanrong Ye, Hong Liu, Fanyang Meng, Xia Li</h3>
<p>RGB-Infrared person re-identification (RGB-IR Re- ID) is a cross-modality
matching problem, where the modality discrepancy is a big challenge. Most
existing works use Euclidean metric based constraints to resolve the
discrepancy between features of images from different modalities. However,
these methods are incapable of learning angularly discriminative feature
embedding because Euclidean distance cannot measure the included angle between
embedding vectors effectively. As an angularly discriminative feature space is
important for classifying the human images based on their embedding vectors, in
this paper, we propose a novel ranking loss function, named Bi-directional
Exponential Angular Triplet Loss, to help learn an angularly separable common
feature space by explicitly constraining the included angles between embedding
vectors. Moreover, to help stabilize and learn the magnitudes of embedding
vectors, we adopt a common space batch normalization layer. The quantitative
and qualitative experiments on the SYSU-MM01 and RegDB dataset support our
analysis. On SYSU-MM01 dataset, the performance is improved from 7.40% / 11.46%
to 38.57% / 38.61% for rank-1 accuracy / mAP compared with the baseline. The
proposed method can be generalized to the task of single-modality Re-ID and
improves the rank-1 accuracy / mAP from 92.0% / 81.7% to 94.7% / 86.6% on the
Market-1501 dataset, from 82.6% / 70.6% to 87.6% / 77.1% on the DukeMTMC-reID
dataset. Code: https://github.com/prismformore/expAT
</p>
<a href="http://arxiv.org/abs/2006.00878" target="_blank">arXiv:2006.00878</a> [<a href="http://arxiv.org/pdf/2006.00878" target="_blank">pdf</a>]

<h2>Interpolation-based semi-supervised learning for object detection. (arXiv:2006.02158v2 [cs.CV] UPDATED)</h2>
<h3>Jisoo Jeong, Vikas Verma, Minsung Hyun, Juho Kannala, Nojun Kwak</h3>
<p>Despite the data labeling cost for the object detection tasks being
substantially more than that of the classification tasks, semi-supervised
learning methods for object detection have not been studied much. In this
paper, we propose an Interpolation-based Semi-supervised learning method for
object Detection (ISD), which considers and solves the problems caused by
applying conventional Interpolation Regularization (IR) directly to object
detection. We divide the output of the model into two types according to the
objectness scores of both original patches that are mixed in IR. Then, we apply
a separate loss suitable for each type in an unsupervised manner. The proposed
losses dramatically improve the performance of semi-supervised learning as well
as supervised learning. In the supervised learning setting, our method improves
the baseline methods by a significant margin. In the semi-supervised learning
setting, our algorithm improves the performance on a benchmark dataset (PASCAL
VOC and MSCOCO) in a benchmark architecture (SSD).
</p>
<a href="http://arxiv.org/abs/2006.02158" target="_blank">arXiv:2006.02158</a> [<a href="http://arxiv.org/pdf/2006.02158" target="_blank">pdf</a>]

<h2>Least $k$th-Order and R\'{e}nyi Generative Adversarial Networks. (arXiv:2006.02479v2 [cs.LG] UPDATED)</h2>
<h3>Himesh Bhatia, William Paul, Fady Alajaji, Bahman Gharesifard, Philippe Burlina</h3>
<p>We investigate the use of parametrized families of information-theoretic
measures to generalize the loss functions of generative adversarial networks
(GANs) with the objective of improving performance. A new generator loss
function, called least $k$th-order GAN (L$k$GAN), is first introduced,
generalizing the least squares GANs (LSGANs) by using a $k$th order absolute
error distortion measure with $k \geq 1$ (which recovers the LSGAN loss
function when $k=2$). It is shown that minimizing this generalized loss
function under an (unconstrained) optimal discriminator is equivalent to
minimizing the $k$th-order Pearson-Vajda divergence. Another novel GAN
generator loss function is next proposed in terms of R\'{e}nyi cross-entropy
functionals with order $\alpha &gt;0$, $\alpha\neq 1$. It is demonstrated that
this R\'{e}nyi-centric generalized loss function, which provably reduces to the
original GAN loss function as $\alpha\to1$, preserves the equilibrium point
satisfied by the original GAN based on the Jensen-R\'{e}nyi divergence, a
natural extension of the Jensen-Shannon divergence.

Experimental results indicate that the proposed loss functions, applied to
the MNIST and CelebA datasets, under both DCGAN and StyleGAN architectures,
confer performance benefits by virtue of the extra degrees of freedom provided
by the parameters $k$ and $\alpha$, respectively. More specifically,
experiments show improvements with regard to the quality of the generated
images as measured by the Fr\'echet Inception Distance (FID) score and training
stability. While it was applied to GANs in this study, the proposed approach is
generic and can be used in other applications of information theory to deep
learning, e.g., the issues of fairness or privacy in artificial intelligence.
</p>
<a href="http://arxiv.org/abs/2006.02479" target="_blank">arXiv:2006.02479</a> [<a href="http://arxiv.org/pdf/2006.02479" target="_blank">pdf</a>]

<h2>Learned Factor Graphs for Inference from Stationary Time Sequences. (arXiv:2006.03258v2 [cs.LG] UPDATED)</h2>
<h3>Nir Shlezinger, Nariman Farsad, Yonina C. Eldar, Andrea J. Goldsmith</h3>
<p>The design of methods for inference from time sequences has traditionally
relied on statistical models that describe the relation between a latent
desired sequence and the observed one. A broad family of model-based algorithms
have been derived to carry out inference at controllable complexity using
recursive computations over the factor graph representing the underlying
distribution. An alternative model-agnostic approach utilizes machine learning
(ML) methods. Here we propose a framework that combines model-based algorithms
and data-driven ML tools for stationary time sequences. In the proposed
approach, neural networks are developed to separately learn specific components
of a factor graph describing the distribution of the time sequence, rather than
the complete inference task. By exploiting stationary properties of this
distribution, the resulting approach can be applied to sequences of varying
temporal duration. Learned factor graph can be realized using compact neural
networks that are trainable using small training sets, or alternatively, be
used to improve upon existing deep inference systems. We present an inference
algorithm based on learned stationary factor graphs, which learns to implement
the sum-product scheme from labeled data, and can be applied to sequences of
different lengths. Our experimental results demonstrate the ability of the
proposed learned factor graphs to learn to carry out accurate inference from
small training sets for sleep stage detection using the Sleep-EDF dataset, as
well as for symbol detection in digital communications with unknown channels.
</p>
<a href="http://arxiv.org/abs/2006.03258" target="_blank">arXiv:2006.03258</a> [<a href="http://arxiv.org/pdf/2006.03258" target="_blank">pdf</a>]

<h2>STDI-Net: Spatial-Temporal Network with Dynamic Interval Mapping for Bike Sharing Demand Prediction. (arXiv:2006.04089v3 [cs.AI] UPDATED)</h2>
<h3>Weiguo Pian, Yingbo Wu, Ziyi Kou</h3>
<p>As an economical and healthy mode of shared transportation, Bike Sharing
System (BSS) develops quickly in many big cities. An accurate prediction method
can help BSS schedule resources in advance to meet the demands of users, and
definitely improve operating efficiencies of it. However, most of the existing
methods for similar tasks just utilize spatial or temporal information
independently. Though there are some methods consider both, they only focus on
demand prediction in a single location or between location pairs. In this
paper, we propose a novel deep learning method called Spatial-Temporal Dynamic
Interval Network (STDI-Net). The method predicts the number of renting and
returning orders of multiple connected stations in the near future by modeling
joint spatial-temporal information. Furthermore, we embed an additional module
that generates dynamical learnable mappings for different time intervals, to
include the factor that different time intervals have a strong influence on
demand prediction in BSS. Extensive experiments are conducted on the NYC Bike
dataset, the results demonstrate the superiority of our method over existing
methods.
</p>
<a href="http://arxiv.org/abs/2006.04089" target="_blank">arXiv:2006.04089</a> [<a href="http://arxiv.org/pdf/2006.04089" target="_blank">pdf</a>]

<h2>POLY-HOOT: Monte-Carlo Planning in Continuous Space MDPs with Non-Asymptotic Analysis. (arXiv:2006.04672v2 [cs.AI] UPDATED)</h2>
<h3>Weichao Mao, Kaiqing Zhang, Qiaomin Xie, Tamer Ba&#x15f;ar</h3>
<p>Monte-Carlo planning, as exemplified by Monte-Carlo Tree Search (MCTS), has
demonstrated remarkable performance in applications with finite spaces. In this
paper, we consider Monte-Carlo planning in an environment with continuous
state-action spaces, a much less understood problem with important applications
in control and robotics. We introduce POLY-HOOT, an algorithm that augments
MCTS with a continuous armed bandit strategy named Hierarchical Optimistic
Optimization (HOO) (Bubeck et al., 2011). Specifically, we enhance HOO by using
an appropriate polynomial, rather than logarithmic, bonus term in the upper
confidence bounds. Such a polynomial bonus is motivated by its empirical
successes in AlphaGo Zero (Silver et al., 2017b), as well as its significant
role in achieving theoretical guarantees of finite space MCTS (Shah et al.,
2019). We investigate, for the first time, the regret of the enhanced HOO
algorithm in non-stationary bandit problems. Using this result as a building
block, we establish non-asymptotic convergence guarantees for POLY-HOOT: the
value estimate converges to an arbitrarily small neighborhood of the optimal
value function at a polynomial rate. We further provide experimental results
that corroborate our theoretical findings.
</p>
<a href="http://arxiv.org/abs/2006.04672" target="_blank">arXiv:2006.04672</a> [<a href="http://arxiv.org/pdf/2006.04672" target="_blank">pdf</a>]

<h2>Homomorphic Sensing of Subspace Arrangements. (arXiv:2006.05158v2 [cs.LG] UPDATED)</h2>
<h3>Liangzu Peng, Manolis C. Tsakiris</h3>
<p>Homomorphic sensing is a recent algebraic-geometric framework that studies
the unique recovery of points in a linear subspace from their images under a
given collection of linear maps. It has been successful in interpreting such a
recovery in the case of permutations composed by coordinate projections, an
important instance in applications known as unlabeled sensing, which models
data that are out of order and have missing values. In this paper, we provide
tighter and simpler conditions that guarantee the unique recovery for the
single-subspace case, extend the result to the case of a subspace arrangement,
and show that the unique recovery in a single subspace is locally stable under
noise. We specialize our results to several examples of homomorphic sensing
such as real phase retrieval and unlabeled sensing. In so doing, in a unified
way, we obtain conditions that guarantee the unique recovery for those
examples, typically known via diverse techniques in the literature, as well as
novel conditions for sparse and unsigned versions of unlabeled sensing.
Similarly, our noise result also implies that the unique recovery in unlabeled
sensing is locally stable.
</p>
<a href="http://arxiv.org/abs/2006.05158" target="_blank">arXiv:2006.05158</a> [<a href="http://arxiv.org/pdf/2006.05158" target="_blank">pdf</a>]

<h2>On Data Augmentation for GAN Training. (arXiv:2006.05338v3 [cs.CV] UPDATED)</h2>
<h3>Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Trung-Kien Nguyen, Ngai-Man Cheung</h3>
<p>Recent successes in Generative Adversarial Networks (GAN) have affirmed the
importance of using more data in GAN training. Yet it is expensive to collect
data in many domains such as medical applications. Data Augmentation (DA) has
been applied in these applications. In this work, we first argue that the
classical DA approach could mislead the generator to learn the distribution of
the augmented data, which could be different from that of the original data. We
then propose a principled framework, termed Data Augmentation Optimized for GAN
(DAG), to enable the use of augmented data in GAN training to improve the
learning of the original distribution. We provide theoretical analysis to show
that using our proposed DAG aligns with the original GAN in minimizing the
Jensen-Shannon (JS) divergence between the original distribution and model
distribution. Importantly, the proposed DAG effectively leverages the augmented
data to improve the learning of discriminator and generator. We conduct
experiments to apply DAG to different GAN models: unconditional GAN,
conditional GAN, self-supervised GAN and CycleGAN using datasets of natural
images and medical images. The results show that DAG achieves consistent and
considerable improvements across these models. Furthermore, when DAG is used in
some GAN models, the system establishes state-of-the-art Frechet Inception
Distance (FID) scores. Our code is available.
</p>
<a href="http://arxiv.org/abs/2006.05338" target="_blank">arXiv:2006.05338</a> [<a href="http://arxiv.org/pdf/2006.05338" target="_blank">pdf</a>]

<h2>Bayesian Additive Regression Trees with Model Trees. (arXiv:2006.07493v4 [stat.ML] UPDATED)</h2>
<h3>Estev&#xe3;o B. Prado, Rafael A. Moral, Andrew C. Parnell</h3>
<p>Bayesian Additive Regression Trees (BART) is a tree-based machine learning
method that has been successfully applied to regression and classification
problems. BART assumes regularisation priors on a set of trees that work as
weak learners and is very flexible for predicting in the presence of
non-linearity and high-order interactions. In this paper, we introduce an
extension of BART, called Model Trees BART (MOTR-BART), that considers
piecewise linear functions at node levels instead of piecewise constants. In
MOTR-BART, rather than having a unique value at node level for the prediction,
a linear predictor is estimated considering the covariates that have been used
as the split variables in the corresponding tree. In our approach, local
linearities are captured more efficiently and fewer trees are required to
achieve equal or better performance than BART. Via simulation studies and real
data applications, we compare MOTR-BART to its main competitors. R code for
MOTR-BART implementation is available at https://github.com/ebprado/MOTR-BART.
</p>
<a href="http://arxiv.org/abs/2006.07493" target="_blank">arXiv:2006.07493</a> [<a href="http://arxiv.org/pdf/2006.07493" target="_blank">pdf</a>]

<h2>Class-Attentive Diffusion Network for Semi-Supervised Classification. (arXiv:2006.10222v3 [cs.LG] UPDATED)</h2>
<h3>Jongin Lim, Daeho Um, Hyung Jin Chang, Dae Ung Jo, Jin Young Choi</h3>
<p>Recently, graph neural networks for semi-supervised classification have been
widely studied. However, existing methods only use the information of limited
neighbors and do not deal with the inter-class connections in graphs. In this
paper, we propose Adaptive aggregation with Class-Attentive Diffusion (AdaCAD),
a new aggregation scheme that adaptively aggregates nodes probably of the same
class among K-hop neighbors. To this end, we first propose a novel stochastic
process, called Class-Attentive Diffusion (CAD), that strengthens attention to
intra-class nodes and attenuates attention to inter-class nodes. In contrast to
the existing diffusion methods with a transition matrix determined solely by
the graph structure, CAD considers both the node features and the graph
structure with the design of our class-attentive transition matrix that
utilizes a classifier. Then, we further propose an adaptive update scheme that
leverages different reflection ratios of the diffusion result for each node
depending on the local class-context. As the main advantage, AdaCAD alleviates
the problem of undesired mixing of inter-class features caused by discrepancies
between node labels and the graph topology. Built on AdaCAD, we construct a
simple model called Class-Attentive Diffusion Network (CAD-Net). Extensive
experiments on seven benchmark datasets consistently demonstrate the efficacy
of the proposed method and our CAD-Net significantly outperforms the
state-of-the-art methods. Code is available at
https://github.com/ljin0429/CAD-Net.
</p>
<a href="http://arxiv.org/abs/2006.10222" target="_blank">arXiv:2006.10222</a> [<a href="http://arxiv.org/pdf/2006.10222" target="_blank">pdf</a>]

<h2>Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework. (arXiv:2006.13365v3 [cs.LG] UPDATED)</h2>
<h3>Mehdi Ali, Max Berrendorf, Charles Tapley Hoyt, Laurent Vermue, Mikhail Galkin, Sahand Sharifzadeh, Asja Fischer, Volker Tresp, Jens Lehmann</h3>
<p>The heterogeneity in recently published knowledge graph embedding models'
implementations, training, and evaluation has made fair and thorough
comparisons difficult. In order to assess the reproducibility of previously
published results, we re-implemented and evaluated 19 interaction models in the
PyKEEN software package. Here, we outline which results could be reproduced
with their reported hyper-parameters, which could only be reproduced with
alternate hyper-parameters, and which could not be reproduced at all as well as
provide insight as to why this might be the case.

We then performed a large-scale benchmarking on four datasets with several
thousands of experiments and 21,246 GPU hours of computation time. We present
insights gained as to best practices, best configurations for each model, and
where improvements could be made over previously published best configurations.
Our results highlight that the combination of model architecture, training
approach, loss function, and the explicit modeling of inverse relations is
crucial for a model's performances, and not only determined by the model
architecture. We provide evidence that several architectures can obtain results
competitive to the state-of-the-art when configured carefully. We have made all
code, experimental configurations, results, and analyses that lead to our
interpretations available at https://github.com/pykeen/pykeen and
https://github.com/pykeen/benchmarking
</p>
<a href="http://arxiv.org/abs/2006.13365" target="_blank">arXiv:2006.13365</a> [<a href="http://arxiv.org/pdf/2006.13365" target="_blank">pdf</a>]

<h2>Submodular Combinatorial Information Measures with Applications in Machine Learning. (arXiv:2006.15412v4 [cs.LG] UPDATED)</h2>
<h3>Rishabh Iyer, Ninad Khargonkar, Jeff Bilmes, Himanshu Asnani</h3>
<p>Information-theoretic quantities like entropy and mutual information have
found numerous uses in machine learning. It is well known that there is a
strong connection between these entropic quantities and submodularity since
entropy over a set of random variables is submodular. In this paper, we study
combinatorial information measures that generalize independence, (conditional)
entropy, (conditional) mutual information, and total correlation defined over
sets of (not necessarily random) variables. These measures strictly generalize
the corresponding entropic measures since they are all parameterized via
submodular functions that themselves strictly generalize entropy. Critically,
we show that, unlike entropic mutual information in general, the submodular
mutual information is actually submodular in one argument, holding the other
fixed, for a large class of submodular functions whose third-order partial
derivatives satisfy a non-negativity property. This turns out to include a
number of practically useful cases such as the facility location and set-cover
functions. We study specific instantiations of the submodular information
measures on these, as well as the probabilistic coverage, graph-cut, and
saturated coverage functions, and see that they all have mathematically
intuitive and practically useful expressions. Regarding applications, we
connect the maximization of submodular (conditional) mutual information to
problems such as mutual-information-based, query-based, and privacy-preserving
summarization -- and we connect optimizing the multi-set submodular mutual
information to clustering and robust partitioning.
</p>
<a href="http://arxiv.org/abs/2006.15412" target="_blank">arXiv:2006.15412</a> [<a href="http://arxiv.org/pdf/2006.15412" target="_blank">pdf</a>]

<h2>Concept Bottleneck Models. (arXiv:2007.04612v3 [cs.LG] UPDATED)</h2>
<h3>Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, Percy Liang</h3>
<p>We seek to learn models that we can interact with using high-level concepts:
if the model did not think there was a bone spur in the x-ray, would it still
predict severe arthritis? State-of-the-art models today do not typically
support the manipulation of concepts like "the existence of bone spurs", as
they are trained end-to-end to go directly from raw input (e.g., pixels) to
output (e.g., arthritis severity). We revisit the classic idea of first
predicting concepts that are provided at training time, and then using these
concepts to predict the label. By construction, we can intervene on these
concept bottleneck models by editing their predicted concept values and
propagating these changes to the final prediction. On x-ray grading and bird
identification, concept bottleneck models achieve competitive accuracy with
standard end-to-end models, while enabling interpretation in terms of
high-level clinical concepts ("bone spurs") or bird attributes ("wing color").
These models also allow for richer human-model interaction: accuracy improves
significantly if we can correct model mistakes on concepts at test time.
</p>
<a href="http://arxiv.org/abs/2007.04612" target="_blank">arXiv:2007.04612</a> [<a href="http://arxiv.org/pdf/2007.04612" target="_blank">pdf</a>]

<h2>Fast and Robust Iterative Closest Point. (arXiv:2007.07627v2 [cs.CV] UPDATED)</h2>
<h3>Juyong Zhang, Yuxin Yao, Bailin Deng</h3>
<p>The Iterative Closest Point (ICP) algorithm and its variants are a
fundamental technique for rigid registration between two point sets, with wide
applications in different areas from robotics to 3D reconstruction. The main
drawbacks for ICP are its slow convergence as well as its sensitivity to
outliers, missing data, and partial overlaps. Recent work such as Sparse ICP
achieves robustness via sparsity optimization at the cost of computational
speed. In this paper, we propose a new method for robust registration with fast
convergence. First, we show that the classical point-to-point ICP can be
treated as a majorization-minimization (MM) algorithm, and propose an Anderson
acceleration approach to speed up its convergence. In addition, we introduce a
robust error metric based on the Welsch's function, which is minimized
efficiently using the MM algorithm with Anderson acceleration. On challenging
datasets with noises and partial overlaps, we achieve similar or better
accuracy than Sparse ICP while being at least an order of magnitude faster.
Finally, we extend the robust formulation to point-to-plane ICP, and solve the
resulting problem using a similar Anderson-accelerated MM strategy. Our robust
ICP methods improve the registration accuracy on benchmark datasets while being
competitive in computational time.
</p>
<a href="http://arxiv.org/abs/2007.07627" target="_blank">arXiv:2007.07627</a> [<a href="http://arxiv.org/pdf/2007.07627" target="_blank">pdf</a>]

<h2>EfficientHRNet: Efficient Scaling for Lightweight High-Resolution Multi-Person Pose Estimation. (arXiv:2007.08090v2 [cs.CV] UPDATED)</h2>
<h3>Christopher Neff, Aneri Sheth, Steven Furgurson, Hamed Tabkhi</h3>
<p>There is an increasing demand for lightweight multi-person pose estimation
for many emerging smart IoT applications. However, the existing algorithms tend
to have large model sizes and intense computational requirements, making them
ill-suited for real-time applications and deployment on resource-constrained
hardware. Lightweight and real-time approaches are exceedingly rare and come at
the cost of inferior accuracy. In this paper, we present EfficientHRNet, a
family of lightweight multi-person human pose estimators that are able to
perform in real-time on resource-constrained devices. By unifying recent
advances in model scaling with high-resolution feature representations,
EfficientHRNet creates highly accurate models while reducing computation enough
to achieve real-time performance. The largest model is able to come within 4.4%
accuracy of the current state-of-the-art, while having 1/3 the model size and
1/6 the computation, achieving 23 FPS on Nvidia Jetson Xavier. Compared to the
top real-time approach, EfficientHRNet increases accuracy by 22% while
achieving similar FPS with 1/3 the power. At every level, EfficientHRNet proves
to be more computationally efficient than other bottom-up 2D human pose
estimation approaches, while achieving highly competitive accuracy.
</p>
<a href="http://arxiv.org/abs/2007.08090" target="_blank">arXiv:2007.08090</a> [<a href="http://arxiv.org/pdf/2007.08090" target="_blank">pdf</a>]

<h2>Task-oriented Motion Mapping on Robots of Various Configuration using Body Role Division. (arXiv:2007.08750v2 [cs.RO] UPDATED)</h2>
<h3>Kazuhiro Sasabuchi, Naoki Wake, Katsushi Ikeuchi</h3>
<p>Many works in robot teaching either focus only on teaching task knowledge,
such as geometric constraints, or motion knowledge, such as the motion for
accomplishing a task. However, to effectively teach a complex task sequence to
a robot, it is important to take advantage of both task and motion knowledge.
The task knowledge provides the goals of each individual task within the
sequence and reduces the number of required human demonstrations, whereas the
motion knowledge contain the task-to-task constraints that would otherwise
require expert knowledge to model the problem. In this paper, we propose a body
role division approach that combines both types of knowledge using a single
human demonstration. The method is inspired by facts on human body motion and
uses a body structural analogy to decompose a robot's body configuration into
different roles: body parts that are dominant for imitating the human motion
and body parts that are substitutional for adjusting the imitation with respect
to the task knowledge. Our results show that our method scales to robots of
different number of arm links, guides a robot's configuration to one that
achieves an upcoming task, and is potentially beneficial for teaching a range
of task sequences.
</p>
<a href="http://arxiv.org/abs/2007.08750" target="_blank">arXiv:2007.08750</a> [<a href="http://arxiv.org/pdf/2007.08750" target="_blank">pdf</a>]

<h2>Hypersolvers: Toward Fast Continuous-Depth Models. (arXiv:2007.09601v2 [cs.LG] UPDATED)</h2>
<h3>Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama, Jinkyoo Park</h3>
<p>The infinite-depth paradigm pioneered by Neural ODEs has launched a
renaissance in the search for novel dynamical system-inspired deep learning
primitives; however, their utilization in problems of non-trivial size has
often proved impossible due to poor computational scalability. This work paves
the way for scalable Neural ODEs with time-to-prediction comparable to
traditional discrete networks. We introduce hypersolvers, neural networks
designed to solve ODEs with low overhead and theoretical guarantees on
accuracy. The synergistic combination of hypersolvers and Neural ODEs allows
for cheap inference and unlocks a new frontier for practical application of
continuous-depth models. Experimental evaluations on standard benchmarks, such
as sampling for continuous normalizing flows, reveal consistent pareto
efficiency over classical numerical methods.
</p>
<a href="http://arxiv.org/abs/2007.09601" target="_blank">arXiv:2007.09601</a> [<a href="http://arxiv.org/pdf/2007.09601" target="_blank">pdf</a>]

<h2>Gesture Recognition for Initiating Human-to-Robot Handovers. (arXiv:2007.09945v2 [cs.CV] UPDATED)</h2>
<h3>Jun Kwan, Chinkye Tan, Akansel Cosgun</h3>
<p>Human-to-Robot handovers are useful for many Human-Robot Interaction
scenarios. It is important to recognize when a human intends to initiate
handovers, so that the robot does not try to take objects from humans when a
handover is not intended. We pose the handover gesture recognition as a binary
classification problem in a single RGB image. Three separate neural network
modules for detecting the object, human body key points and head orientation,
are implemented to extract relevant features from the RGB images, and then the
feature vectors are passed into a deep neural net to perform binary
classification. Our results show that the handover gestures are correctly
identified with an accuracy of over 90%. The abstraction of the features makes
our approach modular and generalizable to different objects and human body
types.
</p>
<a href="http://arxiv.org/abs/2007.09945" target="_blank">arXiv:2007.09945</a> [<a href="http://arxiv.org/pdf/2007.09945" target="_blank">pdf</a>]

<h2>HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching. (arXiv:2007.12140v2 [cs.CV] UPDATED)</h2>
<h3>Vladimir Tankovich, Christian H&#xe4;ne, Yinda Zhang, Adarsh Kowdle, Sean Fanello, Sofien Bouaziz</h3>
<p>This paper presents HITNet, a novel neural network architecture for real-time
stereo matching. Contrary to many recent neural network approaches that operate
on a full cost volume and rely on 3D convolutions, our approach does not
explicitly build a volume and instead relies on a fast multi-resolution
initialization step, differentiable 2D geometric propagation and warping
mechanisms to infer disparity hypotheses. To achieve a high level of accuracy,
our network not only geometrically reasons about disparities but also infers
slanted plane hypotheses allowing to more accurately perform geometric warping
and upsampling operations. Our architecture is inherently multi-resolution
allowing the propagation of information across different levels. Multiple
experiments prove the effectiveness of the proposed approach at a fraction of
the computation required by state-of-the-art methods. At the time of writing,
HITNet ranks 1st-3rd on all the metrics published on the ETH3D website for two
view stereo, ranks 1st on most of the metrics among all the end-to-end learning
approaches on Middlebury-v3, ranks 1st on the popular KITTI 2012 and 2015
benchmarks among the published methods faster than 100ms.
</p>
<a href="http://arxiv.org/abs/2007.12140" target="_blank">arXiv:2007.12140</a> [<a href="http://arxiv.org/pdf/2007.12140" target="_blank">pdf</a>]

<h2>Geometric Interpretations of the Normalized Epipolar Error. (arXiv:2008.01254v7 [cs.CV] UPDATED)</h2>
<h3>Seong Hun Lee, Javier Civera</h3>
<p>In this work, we provide geometric interpretations of the normalized epipolar
error. Most notably, we show that it is directly related to the following
quantities: (1) the shortest distance between the two backprojected rays, (2)
the dihedral angle between the two bounding epipolar planes, and (3) the
$L_1$-optimal angular reprojection error.
</p>
<a href="http://arxiv.org/abs/2008.01254" target="_blank">arXiv:2008.01254</a> [<a href="http://arxiv.org/pdf/2008.01254" target="_blank">pdf</a>]

<h2>Individualized Prediction of COVID-19 Adverse outcomes with MLHO. (arXiv:2008.03869v2 [stat.ML] UPDATED)</h2>
<h3>Hossein Estiri, Zachary H. Strasser, Shawn N. Murphy</h3>
<p>We developed MLHO (pronounced as melo), an end-to-end Machine Learning
framework that leverages iterative feature and algorithm selection to predict
Health Outcomes. MLHO implements iterative sequential representation mining,
and feature and model selection, for predicting the patient-level risk of
hospitalization, ICU admission, need for mechanical ventilation, and death. It
bases this prediction on data from patients' past medical records (before their
COVID-19 infection). MLHO's architecture enables a parallel and
outcome-oriented model calibration, in which different statistical learning
algorithms and vectors of features are simultaneously tested to improve the
prediction of health outcomes. Using clinical and demographic data from a large
cohort of over 13,000 COVID-19-positive patients, we modeled the four adverse
outcomes utilizing about 600 features representing patients' pre-COVID health
records and demographics. The mean AUC ROC for mortality prediction was 0.91,
while the prediction performance ranged between 0.80 and 0.81 for the ICU,
hospitalization, and ventilation. We broadly describe the clusters of features
that were utilized in modeling and their relative influence for predicting each
outcome. Our results demonstrated that while demographic variables (namely age)
are important predictors of adverse outcomes after a COVID-19 infection, the
incorporation of the past clinical records are vital for a reliable prediction
model. As the COVID-19 pandemic unfolds around the world, adaptable and
interpretable machine learning frameworks (like MLHO) are crucial to improve
our readiness for confronting the potential future waves of COVID-19, as well
as other novel infectious diseases that may emerge.
</p>
<a href="http://arxiv.org/abs/2008.03869" target="_blank">arXiv:2008.03869</a> [<a href="http://arxiv.org/pdf/2008.03869" target="_blank">pdf</a>]

<h2>RTFN: Robust Temporal Feature Network. (arXiv:2008.07707v2 [cs.LG] UPDATED)</h2>
<h3>Zhiwen Xiao, Xin Xu, Huanlai Xing, Juan Chen</h3>
<p>Time series analysis plays a vital role in various applications, for
instance, healthcare, weather prediction, disaster forecast, etc. However, to
obtain sufficient shapelets by a feature network is still challenging. To this
end, we propose a novel robust temporal feature network (RTFN) that contains
temporal feature networks and attentional LSTM networks. The temporal feature
networks are built to extract basic features from input data while the
attentional LSTM networks are devised to capture complicated shapelets and
relationships to enrich features. In experiments, we embed RTFN into supervised
structure as a feature extraction network and into unsupervised clustering as
an encoder, respectively. The results show that the RTFN-based supervised
structure is a winner of 40 out of 85 datasets and the RTFN-based unsupervised
clustering performs the best on 4 out of 11 datasets in the UCR2018 archive.
</p>
<a href="http://arxiv.org/abs/2008.07707" target="_blank">arXiv:2008.07707</a> [<a href="http://arxiv.org/pdf/2008.07707" target="_blank">pdf</a>]

<h2>Data Programming using Semi-Supervision and Subset Selection. (arXiv:2008.09887v2 [cs.LG] UPDATED)</h2>
<h3>Ayush Maheshwari, Oishik Chatterjee, KrishnaTeja Killamsetty, Rishabh Iyer, Ganesh Ramakrishnan</h3>
<p>The paradigm of data programming has shown a lot of promise in using weak
supervision in the form of rules and labelling functions to learn in scenarios
where labelled data is not available. Another approach which has shown a lot of
promise is that of semi-supervised learning where we augment small amounts of
labelled data with a large unlabelled dataset. In this work, we argue that by
not using any labelled data, data programming based approaches can yield
sub-optimal performance, particularly, in cases when the labelling functions
are noisy. The first contribution of this work is to study a framework of joint
learning which combines un-supervised consensus from labelling functions with
semi-supervised learning and \emph{jointly learns a model} to efficiently use
the rules/labelling functions along with semi-supervised loss functions on the
feature space. Next, we also study a subset selection approach to \emph{select}
the set of examples which can be used as the labelled set. We evaluate our
techniques on synthetic data as well as four publicly available datasets and
show improvement over state-of-the-art techniques.
</p>
<a href="http://arxiv.org/abs/2008.09887" target="_blank">arXiv:2008.09887</a> [<a href="http://arxiv.org/pdf/2008.09887" target="_blank">pdf</a>]

<h2>Experimental Verification of Stability Theory for a Planar Rigid Body with Two Unilateral Frictional Contacts. (arXiv:2008.10323v2 [cs.RO] UPDATED)</h2>
<h3>Yizhar Or, Peter L. Varkonyi</h3>
<p>Stability of equilibrium states in mechanical systems with multiple
unilateral frictional contacts is an important practical requirement, with high
relevance for robotic applications. In our previous work, we theoretically
analyzed finite-time Lyapunov stability for a minimal model of planar rigid
body with two frictional point contacts. Assuming inelastic impacts and Coulomb
friction, conditions for stability and instability of an equilibrium
configuration have been derived. In this work, we present for the first time an
experimental demonstration of this stability theory, using a variable-structure
rigid ''biped'' with frictional footpads on an inclined plane. By changing the
biped's center-of-mass location, we attain different equilibrium states, which
respond to small perturbations by divergence or convergence, showing remarkable
agreement with the predictions of the stability theory. Using high-speed
recording of video movies, good quantitative agreement between experiments and
numerical simulations is obtained, and limitations of the rigid-body model and
inelastic impact assumptions are also studied. The results prove the utility
and practical value of our stability theory.
</p>
<a href="http://arxiv.org/abs/2008.10323" target="_blank">arXiv:2008.10323</a> [<a href="http://arxiv.org/pdf/2008.10323" target="_blank">pdf</a>]

<h2>On the implementation of a global optimization method for mixed-variable problems. (arXiv:2009.02183v3 [cs.LG] UPDATED)</h2>
<h3>Giacomo Nannicini</h3>
<p>We describe the optimization algorithm implemented in the open-source
derivative-free solver RBFOpt. The algorithm is based on the radial basis
function method of Gutmann and the metric stochastic response surface method of
Regis and Shoemaker. We propose several modifications aimed at generalizing and
improving these two algorithms: (i) the use of an extended space to represent
categorical variables in unary encoding; (ii) a refinement phase to locally
improve a candidate solution; (iii) interpolation models without the
unisolvence condition, to both help deal with categorical variables, and
initiate the optimization before a uniquely determined model is possible; (iv)
a master-worker framework to allow asynchronous objective function evaluations
in parallel. Numerical experiments show the effectiveness of these ideas.
</p>
<a href="http://arxiv.org/abs/2009.02183" target="_blank">arXiv:2009.02183</a> [<a href="http://arxiv.org/pdf/2009.02183" target="_blank">pdf</a>]

<h2>Deep Hiearchical Multi-Label Classification Applied to Chest X-Ray Abnormality Taxonomies. (arXiv:2009.05609v3 [cs.CV] UPDATED)</h2>
<h3>Haomin Chen, Shun Miao, Daguang Xu, Gregory D. Hager, Adam P. Harrison</h3>
<p>CXRs are a crucial and extraordinarily common diagnostic tool, leading to
heavy research for CAD solutions. However, both high classification accuracy
and meaningful model predictions that respect and incorporate clinical
taxonomies are crucial for CAD usability. To this end, we present a deep HMLC
approach for CXR CAD. Different than other hierarchical systems, we show that
first training the network to model conditional probability directly and then
refining it with unconditional probabilities is key in boosting performance. In
addition, we also formulate a numerically stable cross-entropy loss function
for unconditional probabilities that provides concrete performance
improvements. Finally, we demonstrate that HMLC can be an effective means to
manage missing or incomplete labels. To the best of our knowledge, we are the
first to apply HMLC to medical imaging CAD. We extensively evaluate our
approach on detecting abnormality labels from the CXR arm of the PLCO dataset,
which comprises over $198,000$ manually annotated CXRs. When using complete
labels, we report a mean AUC of 0.887, the highest yet reported for this
dataset. These results are supported by ancillary experiments on the PadChest
dataset, where we also report significant improvements, 1.2% and 4.1% in AUC
and AP, respectively over strong "flat" classifiers. Finally, we demonstrate
that our HMLC approach can much better handle incompletely labelled data. These
performance improvements, combined with the inherent usefulness of taxonomic
predictions, indicate that our approach represents a useful step forward for
CXR CAD.
</p>
<a href="http://arxiv.org/abs/2009.05609" target="_blank">arXiv:2009.05609</a> [<a href="http://arxiv.org/pdf/2009.05609" target="_blank">pdf</a>]

<h2>YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design. (arXiv:2009.05697v2 [cs.CV] UPDATED)</h2>
<h3>Yuxuan Cai, Hongjia Li, Geng Yuan, Wei Niu, Yanyu Li, Xulong Tang, Bin Ren, Yanzhi Wang</h3>
<p>The rapid development and wide utilization of object detection techniques
have aroused attention on both accuracy and speed of object detectors. However,
the current state-of-the-art object detection works are either
accuracy-oriented using a large model but leading to high latency or
speed-oriented using a lightweight model but sacrificing accuracy. In this
work, we propose YOLObile framework, a real-time object detection on mobile
devices via compression-compilation co-design. A novel block-punched pruning
scheme is proposed for any kernel size. To improve computational efficiency on
mobile devices, a GPU-CPU collaborative scheme is adopted along with advanced
compiler-assisted optimizations. Experimental results indicate that our pruning
scheme achieves 14$\times$ compression rate of YOLOv4 with 49.0 mAP. Under our
YOLObile framework, we achieve 17 FPS inference speed using GPU on Samsung
Galaxy S20. By incorporating our proposed GPU-CPU collaborative scheme, the
inference speed is increased to 19.1 FPS, and outperforms the original YOLOv4
by 5$\times$ speedup. Source code is at:
\url{https://github.com/nightsnack/YOLObile}.
</p>
<a href="http://arxiv.org/abs/2009.05697" target="_blank">arXiv:2009.05697</a> [<a href="http://arxiv.org/pdf/2009.05697" target="_blank">pdf</a>]

<h2>Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup. (arXiv:2009.06962v2 [cs.LG] UPDATED)</h2>
<h3>Jang-Hyun Kim, Wonho Choo, Hyun Oh Song</h3>
<p>While deep neural networks achieve great performance on fitting the training
distribution, the learned networks are prone to overfitting and are susceptible
to adversarial attacks. In this regard, a number of mixup based augmentation
methods have been recently proposed. However, these approaches mainly focus on
creating previously unseen virtual examples and can sometimes provide
misleading supervisory signal to the network. To this end, we propose Puzzle
Mix, a mixup method for explicitly utilizing the saliency information and the
underlying statistics of the natural examples. This leads to an interesting
optimization problem alternating between the multi-label objective for optimal
mixing mask and saliency discounted optimal transport objective. Our
experiments show Puzzle Mix achieves the state of the art generalization and
the adversarial robustness results compared to other mixup methods on
CIFAR-100, Tiny-ImageNet, and ImageNet datasets. The source code is available
at https://github.com/snu-mllab/PuzzleMix.
</p>
<a href="http://arxiv.org/abs/2009.06962" target="_blank">arXiv:2009.06962</a> [<a href="http://arxiv.org/pdf/2009.06962" target="_blank">pdf</a>]

<h2>Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v4 [cs.LG] UPDATED)</h2>
<h3>Youwei Liang, Dong Huang</h3>
<p>Since the Lipschitz properties of convolutional neural networks (CNNs) are
widely considered to be related to adversarial robustness, we theoretically
characterize the $\ell_1$ norm and $\ell_\infty$ norm of 2D multi-channel
convolutional layers and provide efficient methods to compute the exact
$\ell_1$ norm and $\ell_\infty$ norm. Based on our theorem, we propose a novel
regularization method termed norm decay, which can effectively reduce the norms
of convolutional layers and fully-connected layers. Experiments show that
norm-regularization methods, including norm decay, weight decay, and singular
value clipping, can improve generalization of CNNs. However, they can slightly
hurt adversarial robustness. Observing this unexpected phenomenon, we compute
the norms of layers in the CNNs trained with three different adversarial
training frameworks and suprisingly find that adversarially robust CNNs have
comparable or even larger layer norms than their non-adversarially robust
counterparts. Furthermore, we prove that under a mild assumption, adversarially
robust classifiers can be achieved using neural networks, and an adversarially
robust neural network can have an arbitrarily large Lipschitz constant. For
this reason, enforcing small norms on CNN layers may be neither necessary nor
effective in achieving adversarial robustness. The code is available at
https://github.com/youweiliang/norm_robustness.
</p>
<a href="http://arxiv.org/abs/2009.08435" target="_blank">arXiv:2009.08435</a> [<a href="http://arxiv.org/pdf/2009.08435" target="_blank">pdf</a>]

<h2>Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations. (arXiv:2009.10142v2 [cs.CV] UPDATED)</h2>
<h3>Alex Wong, Mukund Mundhra, Stefano Soatto</h3>
<p>We study the effect of adversarial perturbations of images on the estimates
of disparity by deep learning models trained for stereo. We show that
imperceptible additive perturbations can significantly alter the disparity map,
and correspondingly the perceived geometry of the scene. These perturbations
not only affect the specific model they are crafted for, but transfer to models
with different architecture, trained with different loss functions. We show
that, when used for adversarial data augmentation, our perturbations result in
trained models that are more robust, without sacrificing overall accuracy of
the model. This is unlike what has been observed in image classification, where
adding the perturbed images to the training set makes the model less vulnerable
to adversarial perturbations, but to the detriment of overall accuracy. We test
our method using the most recent stereo networks and evaluate their performance
on public benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2009.10142" target="_blank">arXiv:2009.10142</a> [<a href="http://arxiv.org/pdf/2009.10142" target="_blank">pdf</a>]

<h2>A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection. (arXiv:2009.13592v3 [cs.CV] UPDATED)</h2>
<h3>Kemal Oksuz, Baris Can Cam, Emre Akbas, Sinan Kalkan</h3>
<p>We propose average Localisation-Recall-Precision (aLRP), a unified, bounded,
balanced and ranking-based loss function for both classification and
localisation tasks in object detection. aLRP extends the
Localisation-Recall-Precision (LRP) performance metric (Oksuz et al., 2018)
inspired from how Average Precision (AP) Loss extends precision to a
ranking-based loss function for classification (Chen et al., 2020). aLRP has
the following distinct advantages: (i) aLRP is the first ranking-based loss
function for both classification and localisation tasks. (ii) Thanks to using
ranking for both tasks, aLRP naturally enforces high-quality localisation for
high-precision classification. (iii) aLRP provides provable balance between
positives and negatives. (iv) Compared to on average $\sim$6 hyperparameters in
the loss functions of state-of-the-art detectors, aLRP Loss has only one
hyperparameter, which we did not tune in practice. On the COCO dataset, aLRP
Loss improves its ranking-based predecessor, AP Loss, up to around $5$ AP
points, achieves $48.9$ AP without test time augmentation and outperforms all
one-stage detectors. Code available at: https://github.com/kemaloksuz/aLRPLoss .
</p>
<a href="http://arxiv.org/abs/2009.13592" target="_blank">arXiv:2009.13592</a> [<a href="http://arxiv.org/pdf/2009.13592" target="_blank">pdf</a>]

<h2>Covariate Shift Adaptation in High-Dimensional and Divergent Distributions. (arXiv:2010.01184v2 [stat.ML] UPDATED)</h2>
<h3>Felipe Maia Polo, Renato Vicente</h3>
<p>In real world applications of supervised learning methods, training and test
sets are often sampled from the distinct distributions and we must resort to
domain adaptation techniques. One special class of techniques is Covariate
Shift Adaptation, which allows practitioners to obtain good generalization
performance in the distribution of interest when domains differ only by the
marginal distribution of features. Traditionally, Covariate Shift Adaptation is
implemented using Importance Weighting which may fail in high-dimensional
settings due to small Effective Sample Sizes (ESS). In this paper, we propose
(i) a connection between ESS, high-dimensional settings and generalization
bounds and (ii) a simple, general and theoretically sound approach to combine
feature selection and Covariate Shift Adaptation. The new approach yields good
performance with improved ESS.
</p>
<a href="http://arxiv.org/abs/2010.01184" target="_blank">arXiv:2010.01184</a> [<a href="http://arxiv.org/pdf/2010.01184" target="_blank">pdf</a>]

<h2>SAFENet: Self-Supervised Monocular Depth Estimation with Semantic-Aware Feature Extraction. (arXiv:2010.02893v3 [cs.CV] UPDATED)</h2>
<h3>Jaehoon Choi, Dongki Jung, Donghwan Lee, Changick Kim</h3>
<p>Self-supervised monocular depth estimation has emerged as a promising method
because it does not require groundtruth depth maps during training. As an
alternative for the groundtruth depth map, the photometric loss enables to
provide self-supervision on depth prediction by matching the input image
frames. However, the photometric loss causes various problems, resulting in
less accurate depth values compared with supervised approaches. In this paper,
we propose SAFENet that is designed to leverage semantic information to
overcome the limitations of the photometric loss. Our key idea is to exploit
semantic-aware depth features that integrate the semantic and geometric
knowledge. Therefore, we introduce multi-task learning schemes to incorporate
semantic-awareness into the representation of depth features. Experiments on
KITTI dataset demonstrate that our methods compete or even outperform the
state-of-the-art methods. Furthermore, extensive experiments on different
datasets show its better generalization ability and robustness to various
conditions, such as low-light or adverse weather.
</p>
<a href="http://arxiv.org/abs/2010.02893" target="_blank">arXiv:2010.02893</a> [<a href="http://arxiv.org/pdf/2010.02893" target="_blank">pdf</a>]

<h2>Revisiting Batch Normalization for Improving Corruption Robustness. (arXiv:2010.03630v3 [cs.CV] UPDATED)</h2>
<h3>Philipp Benz, Chaoning Zhang, Adil Karjauv, In So Kweon</h3>
<p>The performance of DNNs trained on clean images has been shown to decrease
when the test images have common corruptions. In this work, we interpret
corruption robustness as a domain shift and propose to rectify batch
normalization (BN) statistics for improving model robustness. This is motivated
by perceiving the shift from the clean domain to the corruption domain as a
style shift that is represented by the BN statistics. We find that simply
estimating and adapting the BN statistics on a few (32 for instance)
representation samples, without retraining the model, improves the corruption
robustness by a large margin on several benchmark datasets with a wide range of
model architectures. For example, on ImageNet-C, statistics adaptation improves
the top1 accuracy of ResNet50 from 39.2% to 48.7%. Moreover, we find that this
technique can further improve state-of-the-art robust models from 58.1% to
63.3%.
</p>
<a href="http://arxiv.org/abs/2010.03630" target="_blank">arXiv:2010.03630</a> [<a href="http://arxiv.org/pdf/2010.03630" target="_blank">pdf</a>]

<h2>Cardiac Cohort Classification based on Morphologic and Hemodynamic Parameters extracted from 4D PC-MRI Data. (arXiv:2010.05612v2 [cs.LG] UPDATED)</h2>
<h3>Uli Niemann, Atrayee Neog, Benjamin Behrendt, Kai Lawonn, Matthias Gutberlet, Myra Spiliopoulou, Bernhard Preim, Monique Meuschke</h3>
<p>An accurate assessment of the cardiovascular system and prediction of
cardiovascular diseases (CVDs) are crucial. Measured cardiac blood flow data
provide insights about patient-specific hemodynamics, where many specialized
techniques have been developed for the visual exploration of such data sets to
better understand the influence of morphological and hemodynamic conditions on
CVDs. However, there is a lack of machine learning approaches techniques that
allow a feature-based classification of heart-healthy people and patients with
CVDs. In this work, we investigate the potential of morphological and
hemodynamic characteristics, extracted from measured blood flow data in the
aorta, for the classification of heart-healthy volunteers and patients with
bicuspid aortic valve (BAV). Furthermore, we research if there are
characteristic features to classify male and female as well as older
heart-healthy volunteers and BAV patients. We propose a data analysis pipeline
for the classification of the cardiac status, encompassing feature selection,
model training and hyperparameter tuning. In our experiments, we use several
feature selection methods and classification algorithms to train separate
models for the healthy subgroups and BAV patients. We report on classification
performance and investigate the predictive power of morphological and
hemodynamic features with regard to the classification of the defined groups.
Finally, we identify the key features for the best models.
</p>
<a href="http://arxiv.org/abs/2010.05612" target="_blank">arXiv:2010.05612</a> [<a href="http://arxiv.org/pdf/2010.05612" target="_blank">pdf</a>]

<h2>Garfield: System Support for Byzantine Machine Learning. (arXiv:2010.05888v2 [cs.LG] UPDATED)</h2>
<h3>Rachid Guerraoui, Arsany Guirguis, J&#xe9;r&#xe9;my Max Plassmann, Anton Alexandre Ragot, S&#xe9;bastien Rouault</h3>
<p>We present Garfield, a library to transparently make machine learning (ML)
applications, initially built with popular (but fragile) frameworks, e.g.,
TensorFlow and PyTorch, Byzantine-resilient. Garfield relies on a novel
object-oriented design, reducing the coding effort, and addressing the
vulnerability of the shared-graph architecture followed by classical ML
frameworks. Garfield encompasses various communication patterns and supports
computations on CPUs and GPUs, allowing addressing the general question of the
very practical cost of Byzantine resilience in SGD-based ML applications. We
report on the usage of Garfield on three main ML architectures: (a) a single
server with multiple workers, (b) several servers and workers, and (c)
peer-to-peer settings. Using Garfield, we highlight several interesting facts
about the cost of Byzantine resilience. In particular, (a) Byzantine
resilience, unlike crash resilience, induces an accuracy loss, (b) the
throughput overhead comes more from communication than from robust aggregation,
and (c) tolerating Byzantine servers costs more than tolerating Byzantine
workers.
</p>
<a href="http://arxiv.org/abs/2010.05888" target="_blank">arXiv:2010.05888</a> [<a href="http://arxiv.org/pdf/2010.05888" target="_blank">pdf</a>]

<h2>On Deep Learning Techniques to Boost Monocular Depth Estimation for Autonomous Navigation. (arXiv:2010.06626v2 [cs.CV] UPDATED)</h2>
<h3>Raul de Queiroz Mendes, Eduardo Godinho Ribeiro, Nicolas dos Santos Rosa, Valdir Grassi Jr</h3>
<p>Inferring the depth of images is a fundamental inverse problem within the
field of Computer Vision since depth information is obtained through 2D images,
which can be generated from infinite possibilities of observed real scenes.
Benefiting from the progress of Convolutional Neural Networks (CNNs) to explore
structural features and spatial image information, Single Image Depth
Estimation (SIDE) is often highlighted in scopes of scientific and
technological innovation, as this concept provides advantages related to its
low implementation cost and robustness to environmental conditions. In the
context of autonomous vehicles, state-of-the-art CNNs optimize the SIDE task by
producing high-quality depth maps, which are essential during the autonomous
navigation process in different locations. However, such networks are usually
supervised by sparse and noisy depth data, from Light Detection and Ranging
(LiDAR) laser scans, and are carried out at high computational cost, requiring
high-performance Graphic Processing Units (GPUs). Therefore, we propose a new
lightweight and fast supervised CNN architecture combined with novel feature
extraction models which are designed for real-world autonomous navigation. We
also introduce an efficient surface normals module, jointly with a simple
geometric 2.5D loss function, to solve SIDE problems. We also innovate by
incorporating multiple Deep Learning techniques, such as the use of
densification algorithms and additional semantic, surface normals and depth
information to train our framework. The method introduced in this work focuses
on robotic applications in indoor and outdoor environments and its results are
evaluated on the competitive and publicly available NYU Depth V2 and KITTI
Depth datasets.
</p>
<a href="http://arxiv.org/abs/2010.06626" target="_blank">arXiv:2010.06626</a> [<a href="http://arxiv.org/pdf/2010.06626" target="_blank">pdf</a>]

<h2>A Heteroscedastic Likelihood Model for Two-frame Optical Flow. (arXiv:2010.06871v2 [cs.RO] UPDATED)</h2>
<h3>Timothy Farnworth, Christopher Renton, Reuben Strydom, Adrian Wills, Tristan Perez</h3>
<p>Machine vision is an important sensing technology used in mobile robotic
systems. Advancing the autonomy of such systems requires accurate
characterisation of sensor uncertainty. Vision includes intrinsic uncertainty
due to the camera sensor and extrinsic uncertainty due to environmental
lighting and texture, which propagate through the image processing algorithms
used to produce visual measurements. To faithfully characterise visual
measurements, we must take into account these uncertainties.

In this paper, we propose a new class of likelihood functions that
characterises the uncertainty of the error distribution of two-frame optical
flow that enables a heteroscedastic dependence on texture. We employ the
proposed class to characterise the Farneback and Lucas Kanade optical flow
algorithms and achieve close agreement with their respective empirical error
distributions over a wide range of texture in a simulated environment. The
utility of the proposed likelihood model is demonstrated in a visual odometry
ego-motion study, which results in performance competitive with contemporary
methods. The development of an empirically congruent likelihood model advances
the requisite tool-set for vision-based Bayesian inference and enables sensor
data fusion with GPS, LiDAR and IMU to advance robust autonomous navigation.
</p>
<a href="http://arxiv.org/abs/2010.06871" target="_blank">arXiv:2010.06871</a> [<a href="http://arxiv.org/pdf/2010.06871" target="_blank">pdf</a>]

<h2>Weight Squeezing: Reparameterization for Extreme Compression and Fast Inference. (arXiv:2010.06993v2 [cs.LG] UPDATED)</h2>
<h3>Artem Chumachenko, Daniil Gavrilov, Nikita Balagansky, Pavel Kalaidin</h3>
<p>In this work, we present a novel approach for simultaneous knowledge transfer
and model compression called Weight Squeezing. With this method, we perform
knowledge transfer from a pre-trained teacher model by learning the mapping
from its weights to smaller student model weights, without significant loss of
model accuracy.

We applied Weight Squeezing to a pre-trained text classification model and
compared our method to various other knowledge transfer and model compression
methods on several downstream text classification tasks based on the GLUE
dataset. We observed that our approach produces better results than other
methods for training student models without any loss in inference speed. We
also compared Weight Squeezing with Low-Rank Factorization approach and
observed that our method is significantly faster at inference while being
competitive in terms of accuracy.
</p>
<a href="http://arxiv.org/abs/2010.06993" target="_blank">arXiv:2010.06993</a> [<a href="http://arxiv.org/pdf/2010.06993" target="_blank">pdf</a>]

<h2>RADIATE: A Radar Dataset for Automotive Perception. (arXiv:2010.09076v2 [cs.CV] UPDATED)</h2>
<h3>Marcel Sheeny, Emanuele De Pellegrin, Saptarshi Mukherjee, Alireza Ahrabian, Sen Wang, Andrew Wallace</h3>
<p>Datasets for autonomous cars are essential for the development and
benchmarking of perception systems. However, most existing datasets are
captured with camera and LiDAR sensors in good weather conditions. In this
paper, we present the RAdar Dataset In Adverse weaThEr (RADIATE), aiming to
facilitate research on object detection, tracking and scene understanding using
radar sensing for safe autonomous driving. RADIATE includes 3 hours of
annotated radar images with more than 200K labelled road actors in total, on
average about 4.6 instances per radar image. It covers 8 different categories
of actors in a variety of weather conditions (e.g., sun, night, rain, fog and
snow) and driving scenarios (e.g., parked, urban, motorway and suburban),
representing different levels of challenge. To the best of our knowledge, this
is the first public radar dataset which provides high-resolution radar images
on public roads with a large amount of road actors labelled. The data collected
in adverse weather, e.g., fog and snowfall, is unique. Some baseline results of
radar based object detection and recognition are given to show that the use of
radar data is promising for automotive applications in bad weather, where
vision and LiDAR can fail. RADIATE also has stereo images, 32-channel LiDAR and
GPS data, directed at other applications such as sensor fusion, localisation
and mapping. The public dataset can be accessed at
this http URL
</p>
<a href="http://arxiv.org/abs/2010.09076" target="_blank">arXiv:2010.09076</a> [<a href="http://arxiv.org/pdf/2010.09076" target="_blank">pdf</a>]

<h2>Frame Aggregation and Multi-Modal Fusion Framework for Video-Based Person Recognition. (arXiv:2010.09290v2 [cs.CV] UPDATED)</h2>
<h3>Fangtao Li, Wenzhe Wang, Zihe Liu, Haoran Wang, Chenghao Yan, Bin Wu</h3>
<p>Video-based person recognition is challenging due to persons being blocked
and blurred, and the variation of shooting angle. Previous research always
focused on person recognition on still images, ignoring similarity and
continuity between video frames. To tackle the challenges above, we propose a
novel Frame Aggregation and Multi-Modal Fusion (FAMF) framework for video-based
person recognition, which aggregates face features and incorporates them with
multi-modal information to identify persons in videos. For frame aggregation,
we propose a novel trainable layer based on NetVLAD (named AttentionVLAD),
which takes arbitrary number of features as input and computes a fixed-length
aggregation feature based on feature quality. We show that introducing an
attention mechanism to NetVLAD can effectively decrease the impact of
low-quality frames. For the multi-model information of videos, we propose a
Multi-Layer Multi-Modal Attention (MLMA) module to learn the correlation of
multi-modality by adaptively updating Gram matrix. Experimental results on
iQIYI-VID-2019 dataset show that our framework outperforms other
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.09290" target="_blank">arXiv:2010.09290</a> [<a href="http://arxiv.org/pdf/2010.09290" target="_blank">pdf</a>]

<h2>FTBNN: Rethinking Non-linearity for 1-bit CNNs and Going Beyond. (arXiv:2010.09294v4 [cs.CV] UPDATED)</h2>
<h3>Zhuo Su, Linpu Fang, Deke Guo, Dewen Hu, Matti Pietik&#xe4;inen, Li Liu</h3>
<p>Binary neural networks (BNNs), where both weights and activations are
binarized into 1 bit, have been widely studied in recent years due to its great
benefit of highly accelerated computation and substantially reduced memory
footprint that appeal to the development of resource constrained devices. In
contrast to previous methods tending to reduce the quantization error for
training BNN structures, we argue that the binarized convolution process owns
an increasing linearity towards the target of minimizing such error, which in
turn hampers BNN's discriminative ability. In this paper, we re-investigate and
tune proper non-linear modules to fix that contradiction, leading to a strong
baseline which achieves state-of-the-art performance on the large-scale
ImageNet dataset in terms of accuracy and training efficiency. To go further,
we find that the proposed BNN model still has much potential to be compressed
by making a better use of the efficient binary operations, without losing
accuracy. In addition, the limited capacity of the BNN model can also be
increased with the help of group execution. Based on these insights, we are
able to improve the baseline with an additional 4~5% top-1 accuracy gain even
with less computational cost. Our code will be made public at
https://github.com/zhuogege1943/ftbnn.
</p>
<a href="http://arxiv.org/abs/2010.09294" target="_blank">arXiv:2010.09294</a> [<a href="http://arxiv.org/pdf/2010.09294" target="_blank">pdf</a>]

<h2>Multi-view Graph Contrastive Representation Learning for Drug-Drug Interaction Prediction. (arXiv:2010.11711v2 [cs.LG] UPDATED)</h2>
<h3>Yingheng Wang, Yaosen Min, Xin Chen, Ji Wu</h3>
<p>Drug-drug interaction(DDI) prediction is an important task in the medical
health machine learning community. This study presents a new method, multi-view
graph contrastive representation learning for drug-drug interaction prediction,
MIRACLE for brevity, to capture inter-view molecule structure and intra-view
interactions between molecules simultaneously. MIRACLE treats a DDI network as
a multi-view graph where each node in the interaction graph itself is a drug
molecular graph instance. We use GCNs and bond-aware attentive message passing
networks to encode DDI relationships and drug molecular graphs in the MIRACLE
learning stage, respectively. Also, we propose a novel unsupervised contrastive
learning component to balance and integrate the multi-view information.
Comprehensive experiments on multiple real datasets show that MIRACLE
outperforms the state-of-the-art DDI prediction models consistently.
</p>
<a href="http://arxiv.org/abs/2010.11711" target="_blank">arXiv:2010.11711</a> [<a href="http://arxiv.org/pdf/2010.11711" target="_blank">pdf</a>]

<h2>Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses. (arXiv:2010.12033v2 [cs.LG] UPDATED)</h2>
<h3>Yihan Zhou, Victor S. Portella, Mark Schmidt, Nicholas J. A. Harvey</h3>
<p>In online convex optimization (OCO), Lipschitz continuity of the functions is
commonly assumed in order to obtain sublinear regret. Moreover, many algorithms
have only logarithmic regret when these functions are also strongly convex.
Recently, researchers from convex optimization proposed the notions of
"relative Lipschitz continuity" and "relative strong convexity". Both of the
notions are generalizations of their classical counterparts. It has been shown
that subgradient methods in the relative setting have performance analogous to
their performance in the classical setting.

In this work, we consider OCO for relative Lipschitz and relative strongly
convex functions. We extend the known regret bounds for classical OCO
algorithms to the relative setting. Specifically, we show regret bounds for the
follow the regularized leader algorithms and a variant of online mirror
descent. Due to the generality of these methods, these results yield regret
bounds for a wide variety of OCO algorithms. Furthermore, we further extend the
results to algorithms with extra regularization such as regularized dual
averaging.
</p>
<a href="http://arxiv.org/abs/2010.12033" target="_blank">arXiv:2010.12033</a> [<a href="http://arxiv.org/pdf/2010.12033" target="_blank">pdf</a>]

<h2>Improved Actor Relation Graph based Group Activity Recognition. (arXiv:2010.12968v2 [cs.CV] UPDATED)</h2>
<h3>Zijian Kuang, Xinran Tie</h3>
<p>Video understanding is to recognize and classify different actions or
activities appearing in the video. A lot of previous work, such as video
captioning, has shown promising performance in producing general video
understanding. However, it is still challenging to generate a fine-grained
description of human actions and their interactions using state-of-the-art
video captioning techniques. The detailed description of human actions and
group activities is essential information, which can be used in real-time CCTV
video surveillance, health care, sports video analysis, etc. This study
proposes a video understanding method that mainly focused on group activity
recognition by learning the pair-wise actor appearance similarity and actor
positions. We propose to use Normalized cross-correlation (NCC) and the sum of
absolute differences (SAD) to calculate the pair-wise appearance similarity and
build the actor relationship graph to allow the graph convolution network to
learn how to classify group activities. We also propose to use MobileNet as the
backbone to extract features from each video frame. A visualization model is
further introduced to visualize each input video frame with predicted bounding
boxes on each human object and predict individual action and collective
activity.
</p>
<a href="http://arxiv.org/abs/2010.12968" target="_blank">arXiv:2010.12968</a> [<a href="http://arxiv.org/pdf/2010.12968" target="_blank">pdf</a>]

<h2>POMO: Policy Optimization with Multiple Optima for Reinforcement Learning. (arXiv:2010.16011v2 [cs.LG] UPDATED)</h2>
<h3>Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon, Youngjune Gwon, Seungjai Min</h3>
<p>In neural combinatorial optimization (CO), reinforcement learning (RL) can
turn a deep neural net into a fast, powerful heuristic solver of NP-hard
problems. This approach has a great potential in practical applications because
it allows near-optimal solutions to be found without expert guides armed with
substantial domain knowledge. We introduce Policy Optimization with Multiple
Optima (POMO), an end-to-end approach for building such a heuristic solver.
POMO is applicable to a wide range of CO problems. It is designed to exploit
the symmetries in the representation of a CO solution. POMO uses a modified
REINFORCE algorithm that forces diverse rollouts towards all optimal solutions.
Empirically, the low-variance baseline of POMO makes RL training fast and
stable, and it is more resistant to local minima compared to previous
approaches. We also introduce a new augmentation-based inference method, which
accompanies POMO nicely. We demonstrate the effectiveness of POMO by solving
three popular NP-hard problems, namely, traveling salesman (TSP), capacitated
vehicle routing (CVRP), and 0-1 knapsack (KP). For all three, our solver based
on POMO shows a significant improvement in performance over all recent learned
heuristics. In particular, we achieve the optimality gap of 0.14% with TSP100
while reducing inference time by more than an order of magnitude.
</p>
<a href="http://arxiv.org/abs/2010.16011" target="_blank">arXiv:2010.16011</a> [<a href="http://arxiv.org/pdf/2010.16011" target="_blank">pdf</a>]

<h2>(Un)Masked COVID-19 Trends from Social Media. (arXiv:2011.00052v2 [cs.CV] UPDATED)</h2>
<h3>Asmit Kumar Singh, Paras Mehan, Divyanshu Sharma, Rohan Pandey, Tavpritesh Sethi, Ponnurangam Kumaraguru</h3>
<p>Wearing masks is a useful protection method against COVID-19, which has
caused widespread economic and social impact worldwide. Across the globe,
governments have put mandates for the use of face masks, which have received
both positive and negative reaction. Online social media provides an exciting
platform to study the use of masks and analyze underlying mask-wearing
patterns. In this article, we analyze 2.04 million social media images for six
US cities. An increase in masks worn in images is seen as the COVID-19 cases
rose, particularly when their respective states imposed strict regulations. We
also found a decrease in the posting of group pictures as stay-at-home laws
were put into place. Furthermore, mask compliance in the Black Lives Matter
protest was analyzed, eliciting that 40% of the people in group photos wore
masks, and 45% of them wore the masks with a fit score of greater than 80%. We
introduce two new datasets, VAriety MAsks - Classification (VAMA-C) and VAriety
MAsks - Segmentation (VAMA-S), for mask detection and mask fit analysis tasks,
respectively. For the analysis, we create two frameworks, face mask detector
(for classifying masked and unmasked faces) and mask fit analyzer (a semantic
segmentation based model to calculate a mask-fit score). The face mask detector
achieved a classification accuracy of 98%, and the semantic segmentation model
for the mask fit analyzer achieved an Intersection Over Union (IOU) score of
98%. We conclude that such a framework can be used to evaluate the
effectiveness of such public health strategies using social media platforms in
times of pandemic.
</p>
<a href="http://arxiv.org/abs/2011.00052" target="_blank">arXiv:2011.00052</a> [<a href="http://arxiv.org/pdf/2011.00052" target="_blank">pdf</a>]

<h2>On Function Approximation in Reinforcement Learning: Optimism in the Face of Large State Spaces. (arXiv:2011.04622v2 [cs.LG] UPDATED)</h2>
<h3>Zhuoran Yang, Chi Jin, Zhaoran Wang, Mengdi Wang, Michael I. Jordan</h3>
<p>The classical theory of reinforcement learning (RL) has focused on tabular
and linear representations of value functions. Further progress hinges on
combining RL with modern function approximators such as kernel functions and
deep neural networks, and indeed there have been many empirical successes that
have exploited such combinations in large-scale applications. There are
profound challenges, however, in developing a theory to support this
enterprise, most notably the need to take into consideration the
exploration-exploitation tradeoff at the core of RL in conjunction with the
computational and statistical tradeoffs that arise in modern
function-approximation-based learning systems. We approach these challenges by
studying an optimistic modification of the least-squares value iteration
algorithm, in the context of the action-value function

represented by a kernel function or an overparameterized neural network. We
establish both polynomial runtime complexity and polynomial sample complexity
for this algorithm, without additional assumptions on the data-generating
model. In particular, we prove that the algorithm incurs an
$\tilde{\mathcal{O}}(\delta_{\mathcal{F}} H^2 \sqrt{T})$ regret, where
$\delta_{\mathcal{F}}$ characterizes the intrinsic complexity of the function
class $\mathcal{F}$, $H$ is the length of each episode, and $T$ is the total
number of episodes. Our regret bounds are independent of the number of states,
a result which exhibits clearly the benefit of function approximation in RL.
</p>
<a href="http://arxiv.org/abs/2011.04622" target="_blank">arXiv:2011.04622</a> [<a href="http://arxiv.org/pdf/2011.04622" target="_blank">pdf</a>]

<h2>f-IRL: Inverse Reinforcement Learning via State Marginal Matching. (arXiv:2011.04709v2 [cs.LG] UPDATED)</h2>
<h3>Tianwei Ni, Harshit Sikchi, Yufei Wang, Tejus Gupta, Lisa Lee, Benjamin Eysenbach</h3>
<p>Imitation learning is well-suited for robotic tasks where it is difficult to
directly program the behavior or specify a cost for optimal control. In this
work, we propose a method for learning the reward function (and the
corresponding policy) to match the expert state density. Our main result is the
analytic gradient of any f-divergence between the agent and expert state
distribution w.r.t. reward parameters. Based on the derived gradient, we
present an algorithm, f-IRL, that recovers a stationary reward function from
the expert density by gradient descent. We show that f-IRL can learn behaviors
from a hand-designed target state density or implicitly through expert
observations. Our method outperforms adversarial imitation learning methods in
terms of sample efficiency and the required number of expert trajectories on
IRL benchmarks. Moreover, we show that the recovered reward function can be
used to quickly solve downstream tasks, and empirically demonstrate its utility
on hard-to-explore tasks and for behavior transfer across changes in dynamics.
</p>
<a href="http://arxiv.org/abs/2011.04709" target="_blank">arXiv:2011.04709</a> [<a href="http://arxiv.org/pdf/2011.04709" target="_blank">pdf</a>]

<h2>Online Influence Maximization under Linear Threshold Model. (arXiv:2011.06378v2 [cs.LG] UPDATED)</h2>
<h3>Shuai Li, Fang Kong, Kejie Tang, Qizhi Li, Wei Chen</h3>
<p>Online influence maximization (OIM) is a popular problem in social networks
to learn influence propagation model parameters and maximize the influence
spread at the same time. Most previous studies focus on the independent cascade
(IC) model under the edge-level feedback. In this paper, we address OIM in the
linear threshold (LT) model. Because node activations in the LT model are due
to the aggregated effect of all active neighbors, it is more natural to model
OIM with the node-level feedback. And this brings new challenge in online
learning since we only observe aggregated effect from groups of nodes and the
groups are also random. Based on the linear structure in node activations, we
incorporate ideas from linear bandits and design an algorithm LT-LinUCB that is
consistent with the observed feedback. By proving group observation modulated
(GOM) bounded smoothness property, a novel result of the influence difference
in terms of the random observations, we provide a regret of order
$\tilde{O}(\mathrm{poly}(m)\sqrt{T})$, where $m$ is the number of edges and $T$
is the number of rounds. This is the first theoretical result in such order for
OIM under the LT model. In the end, we also provide an algorithm OIM-ETC with
regret bound $O(\mathrm{poly}(m)\ T^{2/3})$, which is model-independent, simple
and has less requirement on online feedback and offline computation.
</p>
<a href="http://arxiv.org/abs/2011.06378" target="_blank">arXiv:2011.06378</a> [<a href="http://arxiv.org/pdf/2011.06378" target="_blank">pdf</a>]

<h2>RTFN: A Robust Temporal Feature Network for Time Series Classification. (arXiv:2011.11829v2 [cs.LG] UPDATED)</h2>
<h3>Zhiwen Xiao, Xin Xu, Huanlai Xing, Shouxi Luo, Penglin Dai, Dawei Zhan</h3>
<p>Time series data usually contains local and global patterns. Most of the
existing feature networks pay more attention to local features rather than the
relationships among them. The latter is, however, also important yet more
difficult to explore. To obtain sufficient representations by a feature network
is still challenging. To this end, we propose a novel robust temporal feature
network (RTFN) for feature extraction in time series classification, containing
a temporal feature network (TFN) and an LSTM-based attention network (LSTMaN).
TFN is a residual structure with multiple convolutional layers. It functions as
a local-feature extraction network to mine sufficient local features from data.
LSTMaN is composed of two identical layers, where attention and long short-term
memory (LSTM) networks are hybridized. This network acts as a relation
extraction network to discover the intrinsic relationships among the extracted
features at different positions in sequential data. In experiments, we embed
RTFN into a supervised structure as a feature extractor and into an
unsupervised structure as an encoder, respectively. The results show that the
RTFN-based structures achieve excellent supervised and unsupervised performance
on a large number of UCR2018 and UEA2018 datasets.
</p>
<a href="http://arxiv.org/abs/2011.11829" target="_blank">arXiv:2011.11829</a> [<a href="http://arxiv.org/pdf/2011.11829" target="_blank">pdf</a>]

<h2>Auto Graph Encoder-Decoder for Model Compression and Network Acceleration. (arXiv:2011.12641v2 [cs.CV] UPDATED)</h2>
<h3>Sixing Yu, Arya Mazaheri, Ali Jannesari</h3>
<p>Model compression aims to deploy deep neural networks (DNN) to mobile devices
with limited computing power and storage resource. However, most of the
existing model compression methods rely on manually defined rules, which
requires domain expertise. In this paper, we propose an Auto Graph
encoder-decoder Model Compression (AGMC) method combined with graph neural
networks (GNN) and reinforcement learning (RL) to find the best compression
policy. We model the target DNN as a graph and use GNN to learn the embeddings
of the DNN automatically. In our experiments, we first compared our method with
rule-based DNN embedding methods to show the graph auto encoder-decoder's
effectiveness. Our learning-based DNN embedding achieved better performance and
a higher compression ratio with fewer search steps. Moreover, we evaluated the
AGMC on CIFAR-10 and ILSVRC-2012 datasets and compared handcrafted and
learning-based model compression approaches. Our method outperformed
handcrafted and learning-based methods on ResNet-56 with 3.6% and 1.8% higher
accuracy, respectively. Furthermore, we achieved a higher compression ratio
than state-of-the-art methods on MobileNet-V2 with just 0.93% accuracy loss.
</p>
<a href="http://arxiv.org/abs/2011.12641" target="_blank">arXiv:2011.12641</a> [<a href="http://arxiv.org/pdf/2011.12641" target="_blank">pdf</a>]

<h2>Towards Playing Full MOBA Games with Deep Reinforcement Learning. (arXiv:2011.12692v4 [cs.AI] UPDATED)</h2>
<h3>Deheng Ye, Guibin Chen, Wen Zhang, Sheng Chen, Bo Yuan, Bo Liu, Jia Chen, Zhao Liu, Fuhao Qiu, Hongsheng Yu, Yinyuting Yin, Bei Shi, Liang Wang, Tengfei Shi, Qiang Fu, Wei Yang, Lanxiao Huang, Wei Liu</h3>
<p>MOBA games, e.g., Honor of Kings, League of Legends, and Dota 2, pose grand
challenges to AI systems such as multi-agent, enormous state-action space,
complex action control, etc. Developing AI for playing MOBA games has raised
much attention accordingly. However, existing work falls short in handling the
raw game complexity caused by the explosion of agent combinations, i.e.,
lineups, when expanding the hero pool in case that OpenAI's Dota AI limits the
play to a pool of only 17 heroes. As a result, full MOBA games without
restrictions are far from being mastered by any existing AI system. In this
paper, we propose a MOBA AI learning paradigm that methodologically enables
playing full MOBA games with deep reinforcement learning. Specifically, we
develop a combination of novel and existing learning techniques, including
curriculum self-play learning, policy distillation, off-policy adaption,
multi-head value estimation, and Monte-Carlo tree-search, in training and
playing a large pool of heroes, meanwhile addressing the scalability issue
skillfully. Tested on Honor of Kings, a popular MOBA game, we show how to build
superhuman AI agents that can defeat top esports players. The superiority of
our AI is demonstrated by the first large-scale performance test of MOBA AI
agent in the literature.
</p>
<a href="http://arxiv.org/abs/2011.12692" target="_blank">arXiv:2011.12692</a> [<a href="http://arxiv.org/pdf/2011.12692" target="_blank">pdf</a>]

<h2>SplitNet: Divide and Co-training. (arXiv:2011.14660v2 [cs.CV] UPDATED)</h2>
<h3>Shuai Zhao, Liguang Zhou, Wenxiao Wang, Deng Cai, Tin Lun Lam, Yangsheng Xu</h3>
<p>The width of a neural network matters since increasing the width will
necessarily increase the model capacity. However, the performance of a network
does not improve linearly with the width and soon gets saturated. To tackle
this problem, we propose to increase the number of networks rather than purely
scaling up the width. To prove it, one large network is divided into several
small ones, and each of these small networks has a fraction of the original
one's parameters. We then train these small networks together and make them see
various views of the same data to learn different and complementary knowledge.
During this co-training process, networks can also learn from each other. As a
result, small networks can achieve better ensemble performance than the large
one with few or no extra parameters or FLOPs. \emph{This reveals that the
number of networks is a new dimension of effective model scaling, besides
depth/width/resolution}. Small networks can also achieve faster inference speed
than the large one by concurrent running on different devices. We validate the
idea -- increasing the number of networks is a new dimension of effective model
scaling -- with different network architectures on common benchmarks through
extensive experiments. The code is available at
\url{https://github.com/mzhaoshuai/SplitNet-Divide-and-Co-training}.
</p>
<a href="http://arxiv.org/abs/2011.14660" target="_blank">arXiv:2011.14660</a> [<a href="http://arxiv.org/pdf/2011.14660" target="_blank">pdf</a>]

<h2>Scale-covariant and scale-invariant Gaussian derivative networks. (arXiv:2011.14759v4 [cs.CV] UPDATED)</h2>
<h3>Tony Lindeberg</h3>
<p>This paper presents a hybrid approach between scale-space theory and deep
learning, where a deep learning architecture is constructed by coupling
parameterized scale-space operations in cascade. By sharing the learnt
parameters between multiple scale channels, and by using the transformation
properties of the scale-space primitives under scaling transformations, the
resulting network becomes provably scale covariant. By in addition performing
max pooling over the multiple scale channels, a resulting network architecture
for image classification also becomes provably scale invariant. We investigate
the performance of such networks on the MNISTLargeScale dataset, which contains
rescaled images from original MNIST over a factor of 4 concerning training data
and over a factor of 16 concerning testing data. It is demonstrated that the
resulting approach allows for scale generalization, enabling good performance
for classifying patterns at scales not present in the training data.
</p>
<a href="http://arxiv.org/abs/2011.14759" target="_blank">arXiv:2011.14759</a> [<a href="http://arxiv.org/pdf/2011.14759" target="_blank">pdf</a>]

<h2>Deep Gravity: enhancing mobility flows generation with deep neural networks and geographic information. (arXiv:2012.00489v2 [cs.LG] UPDATED)</h2>
<h3>Filippo Simini, Gianni Barlacchi, Massimiliano Luca, Luca Pappalardo</h3>
<p>The movements of individuals within and among cities influence key aspects of
our society, such as the objective and subjective well-being, the diffusion of
innovations, the spreading of epidemics, and the quality of the environment.
For this reason, there is increasing interest around the challenging problem of
flow generation, which consists in generating the flows between a set of
geographic locations, given the characteristics of the locations and without
any information about the real flows. Existing solutions to flow generation are
mainly based on mechanistic approaches, such as the gravity model and the
radiation model, which suffer from underfitting and overdispersion, neglect
important variables such as land use and the transportation network, and cannot
describe non-linear relationships between these variables. In this paper, we
propose the Multi-Feature Deep Gravity (MFDG) model as an effective solution to
flow generation. On the one hand, the MFDG model exploits a large number of
variables (e.g., characteristics of land use and the road network; transport,
food, and health facilities) extracted from voluntary geographic information
data (OpenStreetMap). On the other hand, our model exploits deep neural
networks to describe complex non-linear relationships between those variables.
Our experiments, conducted on commuting flows in England, show that the MFDG
model achieves a significant increase in the performance (up to 250\% for
highly populated areas) than mechanistic models that do not use deep neural
networks, or that do not exploit geographic voluntary data. Our work presents a
precise definition of the flow generation problem, which is a novel task for
the deep learning community working with spatio-temporal data, and proposes a
deep neural network model that significantly outperforms current
state-of-the-art statistical models.
</p>
<a href="http://arxiv.org/abs/2012.00489" target="_blank">arXiv:2012.00489</a> [<a href="http://arxiv.org/pdf/2012.00489" target="_blank">pdf</a>]

<h2>Benchmarking Energy-Conserving Neural Networks for Learning Dynamics from Data. (arXiv:2012.02334v2 [cs.LG] UPDATED)</h2>
<h3>Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty</h3>
<p>The last few years have witnessed an increased interest in incorporating
physics-informed inductive bias in deep learning frameworks. In particular, a
growing volume of literature has been exploring ways to enforce energy
conservation while using neural networks for learning dynamics from observed
time-series data. In this work, we present a comparative analysis of the
energy-conserving neural networks - for example, deep Lagrangian network,
Hamiltonian neural network, etc. - wherein the underlying physics is encoded in
their computation graph. We focus on ten neural network models and explain the
similarities and differences between the models. We compare their performance
in 4 different physical systems. Our result highlights that using a
high-dimensional coordinate system and then imposing restrictions via explicit
constraints can lead to higher accuracy in the learned dynamics. We also point
out the possibility of leveraging some of these energy-conserving models to
design energy-based controllers.
</p>
<a href="http://arxiv.org/abs/2012.02334" target="_blank">arXiv:2012.02334</a> [<a href="http://arxiv.org/pdf/2012.02334" target="_blank">pdf</a>]

<h2>DenserNet: Weakly Supervised Visual Localization Using Multi-scale Feature Aggregation. (arXiv:2012.02366v3 [cs.CV] UPDATED)</h2>
<h3>Dongfang Liu, Yiming Cui, Liqi Yan, Christos Mousas, Baijian Yang, Yingjie Chen</h3>
<p>In this work, we introduce a Denser Feature Network (DenserNet) for visual
localization. Our work provides three principal contributions. First, we
develop a convolutional neural network (CNN) architecture which aggregates
feature maps at different semantic levels for image representations. Using
denser feature maps, our method can produce more keypoint features and increase
image retrieval accuracy. Second, our model is trained end-to-end without
pixel-level annotation other than positive and negative GPS-tagged image pairs.
We use a weakly supervised triplet ranking loss to learn discriminative
features and encourage keypoint feature repeatability for image representation.
Finally, our method is computationally efficient as our architecture has shared
features and parameters during computation. Our method can perform accurate
large-scale localization under challenging conditions while remaining the
computational constraint. Extensive experiment results indicate that our method
sets a new state-of-the-art on four challenging large-scale localization
benchmarks and three image retrieval benchmarks.
</p>
<a href="http://arxiv.org/abs/2012.02366" target="_blank">arXiv:2012.02366</a> [<a href="http://arxiv.org/pdf/2012.02366" target="_blank">pdf</a>]

<h2>Spectral Distribution Aware Image Generation. (arXiv:2012.03110v2 [cs.CV] UPDATED)</h2>
<h3>Steffen Jung, Margret Keuper</h3>
<p>Recent advances in deep generative models for photo-realistic images have led
to high quality visual results. Such models learn to generate data from a given
training distribution such that generated images can not be easily
distinguished from real images by the human eye. Yet, recent work on the
detection of such fake images pointed out that they are actually easily
distinguishable by artifacts in their frequency spectra. In this paper, we
propose to generate images according to the frequency distribution of the real
data by employing a spectral discriminator. The proposed discriminator is
lightweight, modular and works stably with different commonly used GAN losses.
We show that the resulting models can better generate images with realistic
frequency spectra, which are thus harder to detect by this cue.
</p>
<a href="http://arxiv.org/abs/2012.03110" target="_blank">arXiv:2012.03110</a> [<a href="http://arxiv.org/pdf/2012.03110" target="_blank">pdf</a>]

<h2>Sparse encoding for more-interpretable feature-selecting representations in probabilistic matrix factorization. (arXiv:2012.04171v3 [cs.LG] UPDATED)</h2>
<h3>Joshua C. Chang, Patrick Fletcher, Jungmin Han, Ted L. Chang, Shashaank Vattikuti, Bart Desmet, Ayah Zirikly, Carson C. Chow</h3>
<p>Dimensionality reduction methods for count data are critical to a wide range
of applications in medical informatics and other fields where model
interpretability is paramount. For such data, hierarchical Poisson matrix
factorization (HPF) and other sparse probabilistic non-negative matrix
factorization (NMF) methods are considered to be interpretable generative
models. They consist of sparse transformations for decoding their learned
representations into predictions. However, sparsity in representation decoding
does not necessarily imply sparsity in the encoding of representations from the
original data features. HPF is often incorrectly interpreted in the literature
as if it possesses encoder sparsity. The distinction between decoder sparsity
and encoder sparsity is subtle but important. Due to the lack of encoder
sparsity, HPF does not possess the column-clustering property of classical NMF
-- the factor loading matrix does not sufficiently define how each factor is
formed from the original features. We address this deficiency by
self-consistently enforcing encoder sparsity, using a generalized additive
model (GAM), thereby allowing one to relate each representation coordinate to a
subset of the original data features. In doing so, the method also gains the
ability to perform feature selection. We demonstrate our method on simulated
data and give an example of how encoder sparsity is of practical use in a
concrete application of representing inpatient comorbidities in Medicare
patients.
</p>
<a href="http://arxiv.org/abs/2012.04171" target="_blank">arXiv:2012.04171</a> [<a href="http://arxiv.org/pdf/2012.04171" target="_blank">pdf</a>]

<h2>A Quality Diversity Approach to Automatically Generating Human-Robot Interaction Scenarios in Shared Autonomy. (arXiv:2012.04283v3 [cs.RO] UPDATED)</h2>
<h3>Matthew Fontaine, Stefanos Nikolaidis</h3>
<p>The growth of scale and complexity of interactions between humans and robots
highlights the need for new computational methods to automatically evaluate the
performance of novel algorithms and applications. Strong evaluation methods
should explore the diverse scenarios of interaction between humans and robots.
We propose quality diversity (QD) algorithms as a method for simultaneously
exploring both environments and human actions to discover diverse failure
scenarios. We focus on the shared autonomy domain, where the robot attempts to
infer the goal of a human operator. We evaluate our approach by automatically
generating scenarios for two published algorithms in this domain: shared
autonomy via hindsight optimization and linear policy blending. Some of the
generated scenarios confirm previous theoretical findings, while others are
surprising and bring about a new understanding of state-of-the-art
implementations. Our experiments show that QD outperforms Monte-Carlo
simulation and optimization based methods in effectively searching the scenario
space, highlighting its promise for automatic evaluation of algorithms in
shared autonomy.
</p>
<a href="http://arxiv.org/abs/2012.04283" target="_blank">arXiv:2012.04283</a> [<a href="http://arxiv.org/pdf/2012.04283" target="_blank">pdf</a>]

<h2>A Riemannian Block Coordinate Descent Method for Computing the Projection Robust Wasserstein Distance. (arXiv:2012.05199v2 [cs.LG] UPDATED)</h2>
<h3>Minhui Huang, Shiqian Ma, Lifeng Lai</h3>
<p>The Wasserstein distance has become increasingly important in machine
learning and deep learning. Despite its popularity, the Wasserstein distance is
hard to approximate because of the curse of dimensionality. A recently proposed
approach to alleviate the curse of dimensionality is to project the sampled
data from the high dimensional probability distribution onto a
lower-dimensional subspace, and then compute the Wasserstein distance between
the projected data. However, this approach requires to solve a max-min problem
over the Stiefel manifold, which is very challenging in practice. The only
existing work that solves this problem directly is the RGAS (Riemannian
Gradient Ascent with Sinkhorn Iteration) algorithm, which requires to solve an
entropy-regularized optimal transport problem in each iteration, and thus can
be costly for large-scale problems. In this paper, we propose a Riemannian
block coordinate descent (RBCD) method to solve this problem, which is based on
a novel reformulation of the regularized max-min problem over the Stiefel
manifold. We show that the complexity of arithmetic operations for RBCD to
obtain an $\epsilon$-stationary point is $O(\epsilon^{-3})$. This significantly
improves the corresponding complexity of RGAS, which is $O(\epsilon^{-12})$.
Moreover, our RBCD has very low per-iteration complexity, and hence is suitable
for large-scale problems. Numerical results on both synthetic and real datasets
demonstrate that our method is more efficient than existing methods, especially
when the number of sampled data is very large.
</p>
<a href="http://arxiv.org/abs/2012.05199" target="_blank">arXiv:2012.05199</a> [<a href="http://arxiv.org/pdf/2012.05199" target="_blank">pdf</a>]

<h2>Privacy-preserving Decentralized Aggregation for Federated Learning. (arXiv:2012.07183v2 [cs.LG] UPDATED)</h2>
<h3>Beomyeol Jeon, S.M. Ferdous, Muntasir Raihan Rahman, Anwar Walid</h3>
<p>Federated learning is a promising framework for learning over decentralized
data spanning multiple regions. This approach avoids expensive central training
data aggregation cost and can improve privacy because distributed sites do not
have to reveal privacy-sensitive data. In this paper, we develop a
privacy-preserving decentralized aggregation protocol for federated learning.
We formulate the distributed aggregation protocol with the Alternating
Direction Method of Multiplier (ADMM) and examine its privacy weakness. Unlike
prior work that use Differential Privacy or homomorphic encryption for privacy,
we develop a protocol that controls communication among participants in each
round of aggregation to minimize privacy leakage. We establish its privacy
guarantee against an honest-but-curious adversary. We also propose an efficient
algorithm to construct such a communication pattern, inspired by combinatorial
block design theory. Our secure aggregation protocol based on this novel group
communication pattern design leads to an efficient algorithm for federated
training with privacy guarantees. We evaluate our federated training algorithm
on image classification and next-word prediction applications over benchmark
datasets with 9 and 15 distributed sites. Evaluation results show that our
algorithm performs comparably to the standard centralized federated learning
method while preserving privacy; the degradation in test accuracy is only up to
0.73%.
</p>
<a href="http://arxiv.org/abs/2012.07183" target="_blank">arXiv:2012.07183</a> [<a href="http://arxiv.org/pdf/2012.07183" target="_blank">pdf</a>]

<h2>Bandit Learning in Decentralized Matching Markets. (arXiv:2012.07348v2 [cs.LG] UPDATED)</h2>
<h3>Lydia T. Liu, Feng Ruan, Horia Mania, Michael I. Jordan</h3>
<p>We study two-sided matching markets in which one side of the market (the
players) does not have a priori knowledge about its preferences for the other
side (the arms) and is required to learn its preferences from experience. Also,
we assume the players have no direct means of communication. This model extends
the standard stochastic multi-armed bandit framework to a decentralized
multiple player setting with competition. We introduce a new algorithm for this
setting that, over a time horizon $T$, attains $\mathcal{O}(\log(T))$ stable
regret when preferences of the arms over players are shared, and
$\mathcal{O}(\log(T)^2)$ regret when there are no assumptions on the
preferences on either side.
</p>
<a href="http://arxiv.org/abs/2012.07348" target="_blank">arXiv:2012.07348</a> [<a href="http://arxiv.org/pdf/2012.07348" target="_blank">pdf</a>]

<h2>Understanding Image Retrieval Re-Ranking: A Graph Neural Network Perspective. (arXiv:2012.07620v2 [cs.CV] UPDATED)</h2>
<h3>Xuanmeng Zhang, Minyue Jiang, Zhedong Zheng, Xiao Tan, Errui Ding, Yi Yang</h3>
<p>The re-ranking approach leverages high-confidence retrieved samples to refine
retrieval results, which have been widely adopted as a post-processing tool for
image retrieval tasks. However, we notice one main flaw of re-ranking, i.e.,
high computational complexity, which leads to an unaffordable time cost for
real-world applications. In this paper, we revisit re-ranking and demonstrate
that re-ranking can be reformulated as a high-parallelism Graph Neural Network
(GNN) function. In particular, we divide the conventional re-ranking process
into two phases, i.e., retrieving high-quality gallery samples and updating
features. We argue that the first phase equals building the k-nearest neighbor
graph, while the second phase can be viewed as spreading the message within the
graph. In practice, GNN only needs to concern vertices with the connected
edges. Since the graph is sparse, we can efficiently update the vertex
features. On the Market-1501 dataset, we accelerate the re-ranking processing
from 89.2s to 9.4ms with one K40m GPU, facilitating the real-time
post-processing. Similarly, we observe that our method achieves comparable or
even better retrieval results on the other four image retrieval benchmarks,
i.e., VeRi-776, Oxford-5k, Paris-6k and University-1652, with limited time
cost. Our code is publicly available.
</p>
<a href="http://arxiv.org/abs/2012.07620" target="_blank">arXiv:2012.07620</a> [<a href="http://arxiv.org/pdf/2012.07620" target="_blank">pdf</a>]

<h2>Quantum neural networks with deep residual learning. (arXiv:2012.07772v2 [cs.LG] UPDATED)</h2>
<h3>Yanying Liang, Wei Peng, Zhu-Jun Zheng, Olli Silv&#xe9;n, Guoying Zhao</h3>
<p>Inspired by the success of neural networks in the classical machine learning
tasks, there has been tremendous effort to develop quantum neural networks
(QNNs), especially for quantum data or tasks that are inherently quantum in
nature. Currently, with the imminent advent of quantum computing processors to
evade the computational and thermodynamic limitation of classical
computations,} designing an efficient quantum neural network becomes a valuable
task in quantum machine learning. In this paper, a novel quantum neural network
with deep residual learning (ResQNN) is proposed. {Specifically, a multiple
layer quantum perceptron with residual connection is provided. Our ResQNN is
able to learn an unknown unitary and get remarkable performance. Besides, the
model can be trained with an end-to-end fashion, as analogue of the
backpropagation in the classical neural networks. To explore the effectiveness
of our ResQNN , we perform extensive experiments on the quantum data under the
setting of both clean and noisy training data. The experimental results show
the robustness and superiority of our ResQNN, when compared to current
remarkable work, which is from \textit{Nature communications, 2020}. Moreover,
when training with higher proportion of noisy data, the superiority of our
ResQNN model can be even significant, which implies the generalization ability
and the remarkable tolerance for noisy data of the proposed method.
</p>
<a href="http://arxiv.org/abs/2012.07772" target="_blank">arXiv:2012.07772</a> [<a href="http://arxiv.org/pdf/2012.07772" target="_blank">pdf</a>]

<h2>Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses. (arXiv:2012.10544v2 [cs.LG] UPDATED)</h2>
<h3>Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein</h3>
<p>As machine learning systems grow in scale, so do their training data
requirements, forcing practitioners to automate and outsource the curation of
training data in order to achieve state-of-the-art performance. The absence of
trustworthy human supervision over the data collection process exposes
organizations to security vulnerabilities; training data can be manipulated to
control and degrade the downstream behaviors of learned models. The goal of
this work is to systematically categorize and discuss a wide range of dataset
vulnerabilities and exploits, approaches for defending against these threats,
and an array of open problems in this space. In addition to describing various
poisoning and backdoor threat models and the relationships among them, we
develop their unified taxonomy.
</p>
<a href="http://arxiv.org/abs/2012.10544" target="_blank">arXiv:2012.10544</a> [<a href="http://arxiv.org/pdf/2012.10544" target="_blank">pdf</a>]

<h2>Rethinking Road Surface 3D Reconstruction and Pothole Detection: From Perspective Transformation to Disparity Map Segmentation. (arXiv:2012.10802v2 [cs.CV] UPDATED)</h2>
<h3>Rui Fan, Umar Ozgunalp, Yuan Wang, Ming Liu, Ioannis Pitas</h3>
<p>Potholes are one of the most common forms of road damage, which can severely
affect driving comfort, road safety and vehicle condition. Pothole detection is
typically performed by either structural engineers or certified inspectors.
This task is, however, not only hazardous for the personnel but also extremely
time-consuming. This paper presents an efficient pothole detection algorithm
based on road disparity map estimation and segmentation. We first generalize
the perspective transformation by incorporating the stereo rig roll angle. The
road disparities are then estimated using semi-global matching. A disparity map
transformation algorithm is then performed to better distinguish the damaged
road areas. Finally, we utilize simple linear iterative clustering to group the
transformed disparities into a collection of superpixels. The potholes are then
detected by finding the superpixels, whose values are lower than an adaptively
determined threshold. The proposed algorithm is implemented on an NVIDIA RTX
2080 Ti GPU in CUDA. The experiments demonstrate the accuracy and efficiency of
our proposed road pothole detection algorithm, where an accuracy of 99.6% and
an F-score of 89.4% are achieved.
</p>
<a href="http://arxiv.org/abs/2012.10802" target="_blank">arXiv:2012.10802</a> [<a href="http://arxiv.org/pdf/2012.10802" target="_blank">pdf</a>]

<h2>Sim-to-real for high-resolution optical tactile sensing: From images to 3D contact force distributions. (arXiv:2012.11295v2 [cs.RO] UPDATED)</h2>
<h3>Carmelo Sferrazza, Raffaello D&#x27;Andrea</h3>
<p>The images captured by vision-based tactile sensors carry information about
high-resolution tactile fields, such as the distribution of the contact forces
applied to their soft sensing surface. However, extracting the information
encoded in the images is challenging and often addressed with learning-based
approaches, which generally require a large amount of training data. This
article proposes a strategy to generate tactile images in simulation for a
vision-based tactile sensor based on an internal camera that tracks the motion
of spherical particles within a soft material. The deformation of the material
is simulated in a finite element environment under a diverse set of contact
conditions, and spherical particles are projected to a simulated image.
Features extracted from the images are mapped to the 3D contact force
distribution, with the ground truth also obtained via finite-element
simulations, with an artificial neural network that is therefore entirely
trained on synthetic data avoiding the need for real-world data collection. The
resulting model exhibits high accuracy when evaluated on real-world tactile
images, is transferable across multiple tactile sensors without further
training, and is suitable for efficient real-time inference.
</p>
<a href="http://arxiv.org/abs/2012.11295" target="_blank">arXiv:2012.11295</a> [<a href="http://arxiv.org/pdf/2012.11295" target="_blank">pdf</a>]

<h2>Selective Forgetting of Deep Networks at a Finer Level than Samples. (arXiv:2012.11849v2 [stat.ML] UPDATED)</h2>
<h3>Tomohiro Hayase, Suguru Yasutomi, Takashi Katoh</h3>
<p>Selective forgetting or removing information from deep neural networks (DNNs)
is essential for continual learning and is challenging in controlling the DNNs.
Such forgetting is crucial also in a practical sense since the deployed DNNs
may be trained on the data with outliers, poisoned by attackers, or with
leaked/sensitive information. In this paper, we formulate selective forgetting
for classification tasks at a finer level than the samples' level. We specify
the finer level based on four datasets distinguished by two conditions: whether
they contain information to be forgotten and whether they are available for the
forgetting procedure. Additionally, we reveal the need for such formulation
with the datasets by showing concrete and practical situations. Moreover, we
introduce the forgetting procedure as an optimization problem on three
criteria; the forgetting, the correction, and the remembering term.
Experimental results show that the proposed methods can make the model forget
to use specific information for classification. Notably, in specific cases, our
methods improved the model's accuracy on the datasets, which contains
information to be forgotten but is unavailable in the forgetting procedure.
Such data are unexpectedly found and misclassified in actual situations.
</p>
<a href="http://arxiv.org/abs/2012.11849" target="_blank">arXiv:2012.11849</a> [<a href="http://arxiv.org/pdf/2012.11849" target="_blank">pdf</a>]

<h2>Hybrid Federated Learning: Algorithms and Implementation. (arXiv:2012.12420v2 [cs.LG] UPDATED)</h2>
<h3>Xinwei Zhang, Wotao Yin, Mingyi Hong, Tianyi Chen</h3>
<p>Federated learning (FL) is a recently proposed distributed machine learning
paradigm dealing with distributed and private data sets. Based on the data
partition pattern, FL is often categorized into horizontal, vertical, and
hybrid settings. Despite the fact that many works have been developed for the
first two approaches, the hybrid FL setting (which deals with partially
overlapped feature space and sample space) remains less explored, though this
setting is extremely important in practice. In this paper, we first set up a
new model-matching-based problem formulation for hybrid FL, then propose an
efficient algorithm that can collaboratively train the global and local models
to deal with full and partial featured data. We conduct numerical experiments
on the multi-view ModelNet40 data set to validate the performance of the
proposed algorithm. To the best of our knowledge, this is the first formulation
and algorithm developed for the hybrid FL.
</p>
<a href="http://arxiv.org/abs/2012.12420" target="_blank">arXiv:2012.12420</a> [<a href="http://arxiv.org/pdf/2012.12420" target="_blank">pdf</a>]

<h2>Memory-Gated Recurrent Networks. (arXiv:2012.13121v2 [cs.LG] UPDATED)</h2>
<h3>Yaquan Zhang, Qi Wu, Nanbo Peng, Min Dai, Jing Zhang, Hu Wang</h3>
<p>The essence of multivariate sequential learning is all about how to extract
dependencies in data. These data sets, such as hourly medical records in
intensive care units and multi-frequency phonetic time series, often time
exhibit not only strong serial dependencies in the individual components (the
"marginal" memory) but also non-negligible memories in the cross-sectional
dependencies (the "joint" memory). Because of the multivariate complexity in
the evolution of the joint distribution that underlies the data generating
process, we take a data-driven approach and construct a novel recurrent network
architecture, termed Memory-Gated Recurrent Networks (mGRN), with gates
explicitly regulating two distinct types of memories: the marginal memory and
the joint memory. Through a combination of comprehensive simulation studies and
empirical experiments on a range of public datasets, we show that our proposed
mGRN architecture consistently outperforms state-of-the-art architectures
targeting multivariate time series.
</p>
<a href="http://arxiv.org/abs/2012.13121" target="_blank">arXiv:2012.13121</a> [<a href="http://arxiv.org/pdf/2012.13121" target="_blank">pdf</a>]

<h2>Taxonomy of multimodal self-supervised representation learning. (arXiv:2012.13623v2 [cs.LG] UPDATED)</h2>
<h3>Alex Fedorov, Tristan Sylvain, Margaux Luck, Lei Wu, Thomas P. DeRamus, Alex Kirilin, Dmitry Bleklov, Vince D. Calhoun, Sergey M. Plis</h3>
<p>Sensory input from multiple sources is crucial for robust and coherent human
perception. Different sources contribute complementary explanatory factors and
get combined based on factors they share. This system motivated the design of
powerful unsupervised representation-learning algorithms. In this paper, we
unify recent work on multimodal self-supervised learning under a single
framework. Observing that most self-supervised methods optimize similarity
metrics between a set of model components, we propose a taxonomy of all
reasonable ways to organize this process. We empirically show on two versions
of multimodal MNIST and a multimodal brain imaging dataset that (1) multimodal
contrastive learning has significant benefits over its unimodal counterpart,
(2) the specific composition of multiple contrastive objectives is critical to
performance on a downstream task, (3) maximization of the similarity between
representations has a regularizing effect on a neural network, which sometimes
can lead to reduced downstream performance but still can reveal multimodal
relations. Consequently, we outperform previous unsupervised encoder-decoder
methods based on CCA or variational mixtures MMVAE on various datasets on
linear evaluation protocol.
</p>
<a href="http://arxiv.org/abs/2012.13623" target="_blank">arXiv:2012.13623</a> [<a href="http://arxiv.org/pdf/2012.13623" target="_blank">pdf</a>]

<h2>Learning Inter- and Intra-frame Representations for Non-Lambertian Photometric Stereo. (arXiv:2012.13720v2 [cs.CV] UPDATED)</h2>
<h3>Yanlong Cao, Binjie Ding, Zewei He, Jiangxin Yang, Jingxi Chen, Yanpeng Cao, Xin Li</h3>
<p>In this paper, we build a two-stage Convolutional Neural Network (CNN)
architecture to construct inter- and intra-frame representations based on an
arbitrary number of images captured under different light directions,
performing accurate normal estimation of non-Lambertian objects. We
experimentally investigate numerous network design alternatives for identifying
the optimal scheme to deploy inter-frame and intra-frame feature extraction
modules for the photometric stereo problem. Moreover, we propose to utilize the
easily obtained object mask for eliminating adverse interference from invalid
background regions in intra-frame spatial convolutions, thus effectively
improve the accuracy of normal estimation for surfaces made of dark materials
or with cast shadows. Experimental results demonstrate that proposed masked
two-stage photometric stereo CNN model (MT-PS-CNN) performs favorably against
state-of-the-art photometric stereo techniques in terms of both accuracy and
efficiency. In addition, the proposed method is capable of predicting accurate
and rich surface normal details for non-Lambertian objects of complex geometry
and performs stably given inputs captured in both sparse and dense lighting
distributions.
</p>
<a href="http://arxiv.org/abs/2012.13720" target="_blank">arXiv:2012.13720</a> [<a href="http://arxiv.org/pdf/2012.13720" target="_blank">pdf</a>]

<h2>A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v2 [cs.LG] UPDATED)</h2>
<h3>Felix Leibfried, Vincent Dutordoir, ST John, Nicolas Durrande</h3>
<p>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model enjoys a posterior in closed form. However, identifying the posterior GP
scales cubically with the number of training examples and requires to store all
examples in memory. In order to overcome these obstacles, sparse GPs have been
proposed that approximate the true posterior GP with pseudo-training examples.
Importantly, the number of pseudo-training examples is user-defined and enables
control over computational and memory complexity. In the general case, sparse
GPs do not enjoy closed-form solutions and one has to resort to approximate
inference. In this context, a convenient choice for approximate inference is
variational inference (VI), where the problem of Bayesian inference is cast as
an optimization problem -- namely, to maximize a lower bound of the log
marginal likelihood. This paves the way for a powerful and versatile framework,
where pseudo-training examples are treated as optimization arguments of the
approximate posterior that are jointly identified together with hyperparameters
of the generative model (i.e. prior and likelihood). The framework can
naturally handle a wide scope of supervised learning problems, ranging from
regression with heteroscedastic and non-Gaussian likelihoods to classification
problems with discrete labels, but also multilabel problems. The purpose of
this tutorial is to provide access to the basic matter for readers without
prior knowledge in both GPs and VI. A proper exposition to the subject enables
also access to more recent advances (like importance-weighted VI as well as
inderdomain, multioutput and deep GPs) that can serve as an inspiration for new
research ideas.
</p>
<a href="http://arxiv.org/abs/2012.13962" target="_blank">arXiv:2012.13962</a> [<a href="http://arxiv.org/pdf/2012.13962" target="_blank">pdf</a>]

<h2>TransPose: Towards Explainable Human Pose Estimation by Transformer. (arXiv:2012.14214v2 [cs.CV] UPDATED)</h2>
<h3>Sen Yang, Zhibin Quan, Mu Nie, Wankou Yang</h3>
<p>Deep Convolutional Neural Networks (CNNs) have made remarkable progress on
human pose estimation task. However, there is no explicit understanding of how
the locations of body keypoints are predicted by CNN, and it is also unknown
what spatial dependency relationships between structural variables are learned
in the model. To explore these questions, we construct an explainable model
named TransPose based on Transformer architecture and low-level convolutional
blocks. Given an image, the attention layers built in Transformer can capture
long-range spatial relationships between keypoints and explain what
dependencies the predicted keypoints locations highly rely on. We analyze the
rationality of using attention as the explanation to reveal the spatial
dependencies in this task. The revealed dependencies are image-specific and
variable for different keypoint types, layer depths, or trained models. The
experiments show that TransPose can accurately predict the positions of
keypoints. It achieves state-of-the-art performance on COCO dataset, while
being more interpretable, lightweight, and efficient than mainstream fully
convolutional architectures.
</p>
<a href="http://arxiv.org/abs/2012.14214" target="_blank">arXiv:2012.14214</a> [<a href="http://arxiv.org/pdf/2012.14214" target="_blank">pdf</a>]

<h2>A method to integrate and classify normal distributions. (arXiv:2012.14331v2 [stat.ML] UPDATED)</h2>
<h3>Abhranil Das, Wilson S Geisler</h3>
<p>Univariate and multivariate normal probability distributions are widely used
when modeling decisions under uncertainty. Computing the performance of such
models requires integrating these distributions over specific domains, which
can vary widely across models. Besides some special cases where these integrals
are easy to calculate, there exists no general analytical expression, standard
numerical method or software for these integrals. Here we present mathematical
results and software that provide (i) the probability in any domain of a normal
in any dimensions with any parameters, (ii) the probability density,
distribution, and percentage points of any function of a normal vector, (iii)
quantities, such as the error matrix and discriminability, which summarize
classification performance amongst any number of normal distributions, (iv)
dimension reduction and visualizations for all such problems, and (v) tests for
how reliably these methods can be used on given data. We illustrate these tools
with models for detecting occluding targets in natural scenes and for detecting
camouflage.
</p>
<a href="http://arxiv.org/abs/2012.14331" target="_blank">arXiv:2012.14331</a> [<a href="http://arxiv.org/pdf/2012.14331" target="_blank">pdf</a>]

<h2>Tensor Representations for Action Recognition. (arXiv:2012.14371v2 [cs.CV] UPDATED)</h2>
<h3>Piotr Koniusz, Lei Wang, Anoop Cherian</h3>
<p>Human actions in video sequences are characterized by the complex interplay
between spatial features and their temporal dynamics. In this paper, we propose
novel tensor representations for compactly capturing such higher-order
relationships between visual features for the task of action recognition. We
propose two tensor-based feature representations, viz. (i) sequence
compatibility kernel (SCK) and (ii) dynamics compatibility kernel (DCK); the
former building on the spatio-temporal correlations between features, while the
latter explicitly modeling the action dynamics of a sequence. We also explore
generalization of SCK, coined SCK(+), that operates on subsequences to capture
the local-global interplay of correlations, which can incorporate multi-modal
inputs e.g., skeleton 3D body-joints and per-frame classifier scores obtained
from deep learning models trained on videos. We introduce linearization of
these kernels that lead to compact and fast descriptors. We provide experiments
on (i) 3D skeleton action sequences, (ii) fine-grained video sequences, and
(iii) standard non-fine-grained videos. As our final representations are
tensors that capture higher-order relationships of features, they relate to
co-occurrences for robust fine-grained recognition. We use higher-order tensors
and so-called Eigenvalue Power Normalization (EPN) which have been long
speculated to perform spectral detection of higher-order occurrences, thus
detecting fine-grained relationships of features rather than merely count
features in action sequences. We prove that a tensor of order r, built from Z*
dimensional features, coupled with EPN indeed detects if at least one
higher-order occurrence is `projected' into one of its binom(Z*,r) subspaces of
dim. r represented by the tensor, thus forming a Tensor Power Normalization
metric endowed with binom(Z*,r) such `detectors'.
</p>
<a href="http://arxiv.org/abs/2012.14371" target="_blank">arXiv:2012.14371</a> [<a href="http://arxiv.org/pdf/2012.14371" target="_blank">pdf</a>]

<h2>Behavior of linear L2-boosting algorithms in the vanishing learning rate asymptotic. (arXiv:2012.14657v1 [stat.ML])</h2>
<h3>Cl&#xe9;ment Dombry (UBFC, LMB), Youssef Esstafa (ENSAI)</h3>
<p>We investigate the asymptotic behaviour of gradient boosting algorithms when
the learning rate converges to zero and the number of iterations is rescaled
accordingly. We mostly consider L2-boosting for regression with linear base
learner as studied in B{\"u}hlmann and Yu (2003) and analyze also a stochastic
version of the model where subsampling is used at each step (Friedman 2002). We
prove a deterministic limit in the vanishing learning rate asymptotic and
characterize the limit as the unique solution of a linear differential equation
in an infinite dimensional function space. Besides, the training and test error
of the limiting procedure are thoroughly analyzed. We finally illustrate and
discuss our result on a simple numerical experiment where the linear
L2-boosting operator is interpreted as a smoothed projection and time is
related to its number of degrees of freedom.
</p>
<a href="http://arxiv.org/abs/2012.14657" target="_blank">arXiv:2012.14657</a> [<a href="http://arxiv.org/pdf/2012.14657" target="_blank">pdf</a>]

<h2>Fast Global Convergence for Low-rank Matrix Recovery via Riemannian Gradient Descent with Random Initialization. (arXiv:2012.15467v1 [stat.ML])</h2>
<h3>Thomas Y. Hou, Zhenzhen Li, Ziyun Zhang</h3>
<p>In this paper, we propose a new global analysis framework for a class of
low-rank matrix recovery problems on the Riemannian manifold. We analyze the
global behavior for the Riemannian optimization with random initialization. We
use the Riemannian gradient descent algorithm to minimize a least squares loss
function, and study the asymptotic behavior as well as the exact convergence
rate. We reveal a previously unknown geometric property of the low-rank matrix
manifold, which is the existence of spurious critical points for the simple
least squares function on the manifold. We show that under some assumptions,
the Riemannian gradient descent starting from a random initialization with high
probability avoids these spurious critical points and only converges to the
ground truth in nearly linear convergence rate, i.e.
$\mathcal{O}(\text{log}(\frac{1}{\epsilon})+ \text{log}(n))$ iterations to
reach an $\epsilon$-accurate solution. We use two applications as examples for
our global analysis. The first one is a rank-1 matrix recovery problem. The
second one is the Gaussian phase retrieval problem. The second example only
satisfies the weak isometry property, but has behavior similar to that of the
first one except for an extra saddle set. Our convergence guarantee is nearly
optimal and almost dimension-free, which fully explains the numerical
observations. The global analysis can be potentially extended to other data
problems with random measurement structures and empirical least squares loss
functions.
</p>
<a href="http://arxiv.org/abs/2012.15467" target="_blank">arXiv:2012.15467</a> [<a href="http://arxiv.org/pdf/2012.15467" target="_blank">pdf</a>]

<h2>Particle Dual Averaging: Optimization of Mean Field Neural Networks with Global Convergence Rate Analysis. (arXiv:2012.15477v1 [stat.ML])</h2>
<h3>Atsushi Nitanda, Denny Wu, Taiji Suzuki</h3>
<p>We propose the particle dual averaging (PDA) method, which generalizes the
dual averaging method in convex optimization to the optimization over
probability distributions with quantitative runtime guarantee. The algorithm
consists of an inner loop and outer loop: the inner loop utilizes the Langevin
algorithm to approximately solve for a stationary distribution, which is then
optimized in the outer loop. The method can thus be interpreted as an extension
of the Langevin algorithm to naturally handle nonlinear functional on the
probability space. An important application of the proposed method is the
optimization of two-layer neural network in the mean field regime, which is
theoretically attractive due to the presence of nonlinear feature learning, but
quantitative convergence rate can be challenging to establish. We show that
neural networks in the mean field limit can be globally optimized by PDA.
Furthermore, we characterize the convergence rate by leveraging convex
optimization theory in finite-dimensional spaces. Our theoretical results are
supported by numerical simulations on neural networks with reasonable size.
</p>
<a href="http://arxiv.org/abs/2012.15477" target="_blank">arXiv:2012.15477</a> [<a href="http://arxiv.org/pdf/2012.15477" target="_blank">pdf</a>]

<h2>Likelihood Ratio Exponential Families. (arXiv:2012.15480v1 [cs.LG])</h2>
<h3>Rob Brekelmans, Frank Nielsen, Alireza Makhzani, Aram Galstyan, Greg Ver Steeg</h3>
<p>The exponential family is well known in machine learning and statistical
physics as the maximum entropy distribution subject to a set of observed
constraints, while the geometric mixture path is common in MCMC methods such as
annealed importance sampling. Linking these two ideas, recent work has
interpreted the geometric mixture path as an exponential family of
distributions to analyse the thermodynamic variational objective (TVO).

We extend likelihood ratio exponential families to include solutions to
rate-distortion (RD) optimization, the information bottleneck (IB) method, and
recent rate-distortion-classification approaches which combine RD and IB. This
provides a common mathematical framework for understanding these methods via
the conjugate duality of exponential families and hypothesis testing. Further,
we collect existing results to provide a variational representation of
intermediate RD or TVO distributions as a minimizing an expectation of KL
divergences. This solution also corresponds to a size-power tradeoff using the
likelihood ratio test and the Neyman Pearson lemma. In thermodynamic
integration bounds such as the TVO, we identify the intermediate distribution
whose expected sufficient statistics match the log partition function.
</p>
<a href="http://arxiv.org/abs/2012.15480" target="_blank">arXiv:2012.15480</a> [<a href="http://arxiv.org/pdf/2012.15480" target="_blank">pdf</a>]

<h2>Why do classifier accuracies show linear trends under distribution shift?. (arXiv:2012.15483v1 [cs.LG])</h2>
<h3>Horia Mania, Suvrit Sra</h3>
<p>Several recent studies observed that when classification models are evaluated
on two different data distributions, the models' accuracies on one distribution
are approximately a linear function of their accuracies on another
distribution. We offer an explanation for these observations based on two
assumptions that can be assessed empirically: (1) certain events have similar
probabilities under the two distributions; (2) the probability that a lower
accuracy model correctly classifies a data point sampled from one distribution
when a higher accuracy model classifies it incorrectly is small.
</p>
<a href="http://arxiv.org/abs/2012.15483" target="_blank">arXiv:2012.15483</a> [<a href="http://arxiv.org/pdf/2012.15483" target="_blank">pdf</a>]

<h2>Robust Asymmetric Learning in POMDPs. (arXiv:2012.15566v1 [cs.LG])</h2>
<h3>Andrew Warrington, J. Wilder Lavington, Adam Scibior, Mark Schmidt, Frank Wood</h3>
<p>Policies for partially observed Markov decision processes can be efficiently
learned by imitating policies for the corresponding fully observed Markov
decision processes. Unfortunately, existing approaches for this kind of
imitation learning have a serious flaw: the expert does not know what the
trainee cannot see, and so may encourage actions that are sub-optimal, even
unsafe, under partial information. We derive an objective to instead train the
expert to maximize the expected reward of the imitating agent policy, and use
it to construct an efficient algorithm, adaptive asymmetric DAgger (A2D), that
jointly trains the expert and the agent. We show that A2D produces an expert
policy that the agent can safely imitate, in turn outperforming policies
learned by imitating a fixed expert.
</p>
<a href="http://arxiv.org/abs/2012.15566" target="_blank">arXiv:2012.15566</a> [<a href="http://arxiv.org/pdf/2012.15566" target="_blank">pdf</a>]

<h2>Combinatorial Pure Exploration with Full-bandit Feedback and Beyond: Solving Combinatorial Optimization under Uncertainty with Limited Observation. (arXiv:2012.15584v1 [cs.LG])</h2>
<h3>Yuko Kuroki, Junya Honda, Masashi Sugiyama</h3>
<p>Combinatorial optimization is one of the fundamental research fields that has
been extensively studied in theoretical computer science and operations
research. When developing an algorithm for combinatorial optimization, it is
commonly assumed that parameters such as edge weights are exactly known as
inputs. However, this assumption may not be fulfilled since input parameters
are often uncertain or initially unknown in many applications such as
recommender systems, crowdsourcing, communication networks, and online
advertisement. To resolve such uncertainty, the problem of combinatorial pure
exploration of multi-armed bandits (CPE) and its variants have recieved
increasing attention. Earlier work on CPE has studied the semi-bandit feedback
or assumed that the outcome from each individual edge is always accessible at
all rounds. However, due to practical constraints such as a budget ceiling or
privacy concern, such strong feedback is not always available in recent
applications. In this article, we review recently proposed techniques for
combinatorial pure exploration problems with limited feedback.
</p>
<a href="http://arxiv.org/abs/2012.15584" target="_blank">arXiv:2012.15584</a> [<a href="http://arxiv.org/pdf/2012.15584" target="_blank">pdf</a>]

<h2>The Sample Complexity of Robust Covariance Testing. (arXiv:2012.15802v1 [cs.LG])</h2>
<h3>Ilias Diakonikolas, Daniel M. Kane</h3>
<p>We study the problem of testing the covariance matrix of a high-dimensional
Gaussian in a robust setting, where the input distribution has been corrupted
in Huber's contamination model. Specifically, we are given i.i.d. samples from
a distribution of the form $Z = (1-\epsilon) X + \epsilon B$, where $X$ is a
zero-mean and unknown covariance Gaussian $\mathcal{N}(0, \Sigma)$, $B$ is a
fixed but unknown noise distribution, and $\epsilon&gt;0$ is an arbitrarily small
constant representing the proportion of contamination. We want to distinguish
between the cases that $\Sigma$ is the identity matrix versus $\gamma$-far from
the identity in Frobenius norm.

In the absence of contamination, prior work gave a simple tester for this
hypothesis testing task that uses $O(d)$ samples. Moreover, this sample upper
bound was shown to be best possible, within constant factors. Our main result
is that the sample complexity of covariance testing dramatically increases in
the contaminated setting. In particular, we prove a sample complexity lower
bound of $\Omega(d^2)$ for $\epsilon$ an arbitrarily small constant and $\gamma
= 1/2$. This lower bound is best possible, as $O(d^2)$ samples suffice to even
robustly {\em learn} the covariance. The conceptual implication of our result
is that, for the natural setting we consider, robust hypothesis testing is at
least as hard as robust estimation.
</p>
<a href="http://arxiv.org/abs/2012.15802" target="_blank">arXiv:2012.15802</a> [<a href="http://arxiv.org/pdf/2012.15802" target="_blank">pdf</a>]

<h2>Language-Mediated, Object-Centric Representation Learning. (arXiv:2012.15814v1 [cs.LG])</h2>
<h3>Ruocheng Wang, Jiayuan Mao, Samuel J. Gershman, Jiajun Wu</h3>
<p>We present Language-mediated, Object-centric Representation Learning (LORL),
a paradigm for learning disentangled, object-centric scene representations from
vision and language. LORL builds upon recent advances in unsupervised object
segmentation, notably MONet and Slot Attention. While these algorithms learn an
object-centric representation just by reconstructing the input image, LORL
enables them to further learn to associate the learned representations to
concepts, i.e., words for object categories, properties, and spatial
relationships, from language input. These object-centric concepts derived from
language facilitate the learning of object-centric representations. LORL can be
integrated with various unsupervised segmentation algorithms that are
language-agnostic. Experiments show that the integration of LORL consistently
improves the object segmentation performance of MONet and Slot Attention on two
datasets via the help of language. We also show that concepts learned by LORL,
in conjunction with segmentation algorithms such as MONet, aid downstream tasks
such as referring expression comprehension.
</p>
<a href="http://arxiv.org/abs/2012.15814" target="_blank">arXiv:2012.15814</a> [<a href="http://arxiv.org/pdf/2012.15814" target="_blank">pdf</a>]

<h2>Fairness in Machine Learning. (arXiv:2012.15816v1 [cs.LG])</h2>
<h3>Luca Oneto, Silvia Chiappa</h3>
<p>Machine learning based systems are reaching society at large and in many
aspects of everyday life. This phenomenon has been accompanied by concerns
about the ethical issues that may arise from the adoption of these
technologies. ML fairness is a recently established area of machine learning
that studies how to ensure that biases in the data and model inaccuracies do
not lead to models that treat individuals unfavorably on the basis of
characteristics such as e.g. race, gender, disabilities, and sexual or
political orientation. In this manuscript, we discuss some of the limitations
present in the current reasoning about fairness and in methods that deal with
it, and describe some work done by the authors to address them. More
specifically, we show how causal Bayesian networks can play an important role
to reason about and deal with fairness, especially in complex unfairness
scenarios. We describe how optimal transport theory can be used to develop
methods that impose constraints on the full shapes of distributions
corresponding to different sensitive attributes, overcoming the limitation of
most approaches that approximate fairness desiderata by imposing constraints on
the lower order moments or other functions of those distributions. We present a
unified framework that encompasses methods that can deal with different
settings and fairness criteria, and that enjoys strong theoretical guarantees.
We introduce an approach to learn fair representations that can generalize to
unseen tasks. Finally, we describe a technique that accounts for legal
restrictions about the use of sensitive attributes.
</p>
<a href="http://arxiv.org/abs/2012.15816" target="_blank">arXiv:2012.15816</a> [<a href="http://arxiv.org/pdf/2012.15816" target="_blank">pdf</a>]

<h2>Continuity of Generalized Entropy and Statistical Learning. (arXiv:2012.15829v1 [cs.LG])</h2>
<h3>Aolin Xu</h3>
<p>We study the continuity property of the generalized entropy as a functional
of the underlying probability distribution, defined with an action space and a
loss function, and use this property to answer the basic questions in
statistical learning theory, the excess risk analyses for various learning
methods. We first derive upper and lower bounds for the entropy difference of
two distributions in terms of several commonly used $f$-divergences, the
Wasserstein distance, and a distance that depends on the action space and the
loss function. Examples are given along with the discussion of each general
result, comparisons are made with the existing entropy difference bounds, and
new mutual information upper bounds are derived based on the new results. We
then apply the entropy difference bounds to the theory of statistical learning.
It is shown that the excess risks in the two popular learning paradigms, the
frequentist learning and the Bayesian learning, both can be studied with the
continuity property of different forms of the generalized entropy. The analysis
is then extended to the continuity of generalized conditional entropy. The
extension provides performance bounds for Bayes decision making with mismatched
distributions. It also leads to excess risk bounds for a third paradigm of
learning, where the decision rule is optimally designed under the projection of
the empirical distribution to a predefined family of distributions. We thus
establish a unified method of excess risk analysis for the three major
paradigms of statistical learning, through the continuity of generalized
entropy.
</p>
<a href="http://arxiv.org/abs/2012.15829" target="_blank">arXiv:2012.15829</a> [<a href="http://arxiv.org/pdf/2012.15829" target="_blank">pdf</a>]

<h2>Estimating Shape Parameters of Piecewise Linear-Quadratic Problems. (arXiv:1706.01865v2 [stat.ML] UPDATED)</h2>
<h3>Peng Zheng, Aleksandr Y. Aravkin, Karthikeyan Natesan Ramamurthy</h3>
<p>Piecewise Linear-Quadratic (PLQ) penalties are widely used to develop models
in statistical inference, signal processing, and machine learning. Common
examples of PLQ penalties include least squares, Huber, Vapnik, 1-norm, and
their asymmetric generalizations. Properties of these estimators depend on the
choice of penalty and its shape parameters, such as degree of asymmetry for the
quantile loss, and transition point between linear and quadratic pieces for the
Huber function. In this paper, we develop a statistical framework that can help
the modeler to automatically tune shape parameters once the shape of the
penalty has been chosen. The choice of the parameter is informed by the basic
notion that each QS penalty should correspond to a true statistical density.
The normalization constant inherent in this requirement helps to inform the
optimization over shape parameters, giving a joint optimization problem over
these as well as primary parameters of interest. A second contribution is to
consider optimization methods for these joint problems. We show that basic
first-order methods can be immediately brought to bear, and design specialized
extensions of interior point (IP) methods for PLQ problems that can quickly and
efficiently solve the joint problem. Synthetic problems and larger-scale
practical examples illustrate the potential of the approach.
</p>
<a href="http://arxiv.org/abs/1706.01865" target="_blank">arXiv:1706.01865</a> [<a href="http://arxiv.org/pdf/1706.01865" target="_blank">pdf</a>]

