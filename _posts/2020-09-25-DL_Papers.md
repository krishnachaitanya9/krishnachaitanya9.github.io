---
title: Latest Deep Learning Papers
date: 2020-11-03 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Impact of Community Structure on Consensus Machine Learning. (arXiv:2011.01334v1 [cs.LG])</h2>
<h3>Bao Huynh, Haimonti Dutta, Dane Taylor</h3>
<p>Consensus dynamics support decentralized machine learning for data that is
distributed across a cloud compute cluster or across the internet of things. In
these and other settings, one seeks to minimize the time $\tau_\epsilon$
required to obtain consensus within some $\epsilon&gt;0$ margin of error.
$\tau_\epsilon$ typically depends on the topology of the underlying
communication network, and for many algorithms $\tau_\epsilon$ depends on the
second-smallest eigenvalue $\lambda_2\in[0,1]$ of the network's normalized
Laplacian matrix: $\tau_\epsilon\sim\mathcal{O}(\lambda_2^{-1})$. Here, we
analyze the effect on $\tau_\epsilon$ of network community structure, which can
arise when compute nodes/sensors are spatially clustered, for example. We study
consensus machine learning over networks drawn from stochastic block models,
which yield random networks that can contain heterogeneous communities with
different sizes and densities. Using random matrix theory, we analyze the
effects of communities on $\lambda_2$ and consensus, finding that $\lambda_2$
generally increases (i.e., $\tau_\epsilon$ decreases) as one decreases the
extent of community structure. We further observe that there exists a critical
level of community structure at which $\tau_\epsilon$ reaches a lower bound and
is no longer limited by the presence of communities. We support our findings
with empirical experiments for decentralized support vector machines.
</p>
<a href="http://arxiv.org/abs/2011.01334" target="_blank">arXiv:2011.01334</a> [<a href="http://arxiv.org/pdf/2011.01334" target="_blank">pdf</a>]

<h2>Distributed Machine Learning for Computational Engineering using MPI. (arXiv:2011.01349v1 [cs.DC])</h2>
<h3>Kailai Xu, Weiqiang Zhu, Eric Darve</h3>
<p>We propose a framework for training neural networks that are coupled with
partial differential equations (PDEs) in a parallel computing environment.
Unlike most distributed computing frameworks for deep neural networks, our
focus is to parallelize both numerical solvers and deep neural networks in
forward and adjoint computations. Our parallel computing model views data
communication as a node in the computational graph for numerical simulation.
The advantage of our model is that data communication and computing are cleanly
separated and thus provide better flexibility, modularity, and testability. We
demonstrate using various large-scale problems that we can achieve substantial
acceleration by using parallel solvers for PDEs in training deep neural
networks that are coupled with PDEs.
</p>
<a href="http://arxiv.org/abs/2011.01349" target="_blank">arXiv:2011.01349</a> [<a href="http://arxiv.org/pdf/2011.01349" target="_blank">pdf</a>]

<h2>On the Relevance-Complexity Region of Scalable Information Bottleneck. (arXiv:2011.01352v1 [cs.IT])</h2>
<h3>Mohammad Mahdi Mahvari, Mari Kobayashi, Abdellatif Zaidi</h3>
<p>The Information Bottleneck method is a learning technique that seeks a right
balance between accuracy and generalization capability through a suitable
tradeoff between compression complexity, measured by minimum description
length, and distortion evaluated under logarithmic loss measure. In this paper,
we study a variation of the problem, called scalable information bottleneck,
where the encoder outputs multiple descriptions of the observation with
increasingly richer features. The problem at hand is motivated by some
application scenarios that require varying levels of accuracy depending on the
allowed level of generalization. First, we establish explicit (analytic)
characterizations of the relevance-complexity region for memoryless Gaussian
sources and memoryless binary sources. Then, we derive a Blahut-Arimoto type
algorithm that allows us to compute (an approximation of) the region for
general discrete sources. Finally, an application example in the pattern
classification problem is provided along with numerical results.
</p>
<a href="http://arxiv.org/abs/2011.01352" target="_blank">arXiv:2011.01352</a> [<a href="http://arxiv.org/pdf/2011.01352" target="_blank">pdf</a>]

<h2>Exact Asymptotics for Linear Quadratic Adaptive Control. (arXiv:2011.01364v1 [cs.LG])</h2>
<h3>Feicheng Wang, Lucas Janson</h3>
<p>Recent progress in reinforcement learning has led to remarkable performance
in a range of applications, but its deployment in high-stakes settings remains
quite rare. One reason is a limited understanding of the behavior of
reinforcement algorithms, both in terms of their regret and their ability to
learn the underlying system dynamics---existing work is focused almost
exclusively on characterizing rates, with little attention paid to the
constants multiplying those rates that can be critically important in practice.
To start to address this challenge, we study perhaps the simplest non-bandit
reinforcement learning problem: linear quadratic adaptive control (LQAC). By
carefully combining recent finite-sample performance bounds for the LQAC
problem with a particular (less-recent) martingale central limit theorem, we
are able to derive asymptotically-exact expressions for the regret, estimation
error, and prediction error of a rate-optimal stepwise-updating LQAC algorithm.
In simulations on both stable and unstable systems, we find that our asymptotic
theory also describes the algorithm's finite-sample behavior remarkably well.
</p>
<a href="http://arxiv.org/abs/2011.01364" target="_blank">arXiv:2011.01364</a> [<a href="http://arxiv.org/pdf/2011.01364" target="_blank">pdf</a>]

<h2>Data-Driven Control of the COVID-19 Outbreak via Non-Pharmaceutical Interventions: A Geometric Programming Approach. (arXiv:2011.01392v1 [math.OC])</h2>
<h3>Mikhail Hayhoe, Francisco Barreras, Victor M. Preciado</h3>
<p>In this paper we propose a data-driven model for the spread of SARS-CoV-2 and
use it to design optimal control strategies of human-mobility restrictions that
both curb the epidemic and minimize the economic costs associated with
implementing non-pharmaceutical interventions. We develop an extension of the
SEIR epidemic model that captures the effects of changes in human mobility on
the spread of the disease. The parameters of our data-driven model are learned
using a multitask learning approach that leverages both data on the number of
deaths across a set of regions, and cellphone data on individuals' mobility
patterns specific to each region. We propose an optimal control problem on this
data-driven model with a tractable solution provided by geometric programming.
The result of this framework is a mobility-based intervention strategy that
curbs the spread of the epidemic while obeying a budget on the economic cost
incurred. Furthermore, in the absence of a straightforward mapping from human
mobility data to economic costs, we propose a practical method by which a
budget on economic losses incurred may be chosen to eliminate excess deaths due
to over-utilization of hospital resources. Our results are demonstrated with
numerical simulations using real data from the Philadelphia metropolitan area.
</p>
<a href="http://arxiv.org/abs/2011.01392" target="_blank">arXiv:2011.01392</a> [<a href="http://arxiv.org/pdf/2011.01392" target="_blank">pdf</a>]

<h2>SGB: Stochastic Gradient Bound Method for Optimizing Partition Functions. (arXiv:2011.01474v1 [cs.LG])</h2>
<h3>Jing Wang, Anna Choromanska</h3>
<p>This paper addresses the problem of optimizing partition functions in a
stochastic learning setting. We propose a stochastic variant of the bound
majorization algorithm that relies on upper-bounding the partition function
with a quadratic surrogate. The update of the proposed method, that we refer to
as Stochastic Partition Function Bound (SPFB), resembles scaled stochastic
gradient descent where the scaling factor relies on a second order term that is
however different from the Hessian. Similarly to quasi-Newton schemes, this
term is constructed using the stochastic approximation of the value of the
function and its gradient. We prove sub-linear convergence rate of the proposed
method and show the construction of its low-rank variant (LSPFB). Experiments
on logistic regression demonstrate that the proposed schemes significantly
outperform SGD. We also discuss how to use quadratic partition function bound
for efficient training of deep learning models and in non-convex optimization.
</p>
<a href="http://arxiv.org/abs/2011.01474" target="_blank">arXiv:2011.01474</a> [<a href="http://arxiv.org/pdf/2011.01474" target="_blank">pdf</a>]

<h2>Convergence of Graph Laplacian with kNN Self-tuned Kernels. (arXiv:2011.01479v1 [math.ST])</h2>
<h3>Xiuyuan Cheng, Hau-Tieng Wu</h3>
<p>Kernelized Gram matrix $W$ constructed from data points $\{x_i\}_{i=1}^N$ as
$W_{ij}= k_0( \frac{ \| x_i - x_j \|^2} {\sigma^2} ) $ is widely used in
graph-based geometric data analysis and unsupervised learning. An important
question is how to choose the kernel bandwidth $\sigma$, and a common practice
called self-tuned kernel adaptively sets a $\sigma_i$ at each point $x_i$ by
the $k$-nearest neighbor (kNN) distance. When $x_i$'s are sampled from a
$d$-dimensional manifold embedded in a possibly high-dimensional space, unlike
with fixed-bandwidth kernels, theoretical results of graph Laplacian
convergence with self-tuned kernels, however, have been incomplete. This paper
proves the convergence of graph Laplacian operator $L_N$ to manifold
(weighted-)Laplacian for a new family of kNN self-tuned kernels
$W^{(\alpha)}_{ij} = k_0( \frac{ \| x_i - x_j \|^2}{ \epsilon \hat{\rho}(x_i)
\hat{\rho}(x_j)})/\hat{\rho}(x_i)^\alpha \hat{\rho}(x_j)^\alpha$, where
$\hat{\rho}$ is the estimated bandwidth function {by kNN}, and the limiting
operator is also parametrized by $\alpha$. When $\alpha = 1$, the limiting
operator is the weighted manifold Laplacian $\Delta_p$. Specifically, we prove
the pointwise convergence of $L_N f $ and convergence of the graph Dirichlet
form with rates. Our analysis is based on first establishing a $C^0$
consistency for $\hat{\rho}$ which bounds the relative estimation error
$|\hat{\rho} - \bar{\rho}|/\bar{\rho}$ uniformly with high probability, where
$\bar{\rho} = p^{-1/d}$, and $p$ is the data density function. Our theoretical
results reveal the advantage of self-tuned kernel over fixed-bandwidth kernel
via smaller variance error in low-density regions. In the algorithm, no prior
knowledge of $d$ or data density is needed. The theoretical results are
supported by numerical experiments.
</p>
<a href="http://arxiv.org/abs/2011.01479" target="_blank">arXiv:2011.01479</a> [<a href="http://arxiv.org/pdf/2011.01479" target="_blank">pdf</a>]

<h2>Asymmetric Interference Cancellation for 5G Non-Public Network with Uplink-Downlink Spectrum Sharing. (arXiv:2011.01511v1 [cs.IT])</h2>
<h3>Peiming Li, Lifeng Xie, Jianping Yao, Jie Xu, Shuguang Cui, Ping Zhang</h3>
<p>Different from public 4G/5G networks that are dominated by downlink traffic,
emerging 5G non-public networks (NPNs) need to support significant uplink
traffic to enable emerging applications such as industrial Internet of things
(IIoT). The uplink-and-downlink spectrum sharing is becoming a viable solution
to enhance the uplink throughput of NPNs, which allows the NPNs to perform the
uplink transmission over the time-frequency resources configured for downlink
transmission in coexisting public networks. To deal with the severe
interference from the downlink public base station (BS) transmitter to the
coexisting uplink non-public BS receiver, we propose an adaptive asymmetric
successive interference cancellation (SIC) approach, in which the non-public BS
receiver is enabled to have the capability of decoding the downlink signals
transmitted from the public BS and successively cancelling them for
interference mitigation. In particular, this paper studies a basic
uplink-and-downlink spectrum sharing scenario when an uplink non-public BS and
a downlink public BS coexist in the same area, each communicating with multiple
users via orthogonal frequency-division multiple access (OFDMA). Under this
setup, we aim to maximize the common uplink throughput of all non-public users,
under the condition that the downlink throughput of each public user is above a
certain threshold. The decision variables include the subcarrier allocation and
user scheduling for both non-public (uplink) and public (downlink) BSs, the
decoding mode of the non-public BS over each subcarrier (i.e., with or without
SIC), as well as the rate and power control over subcarriers. Numerical results
show that the proposed adaptive asymmetric SIC design significantly improves
the common uplink throughput as compared to benchmark schemes without such
design.
</p>
<a href="http://arxiv.org/abs/2011.01511" target="_blank">arXiv:2011.01511</a> [<a href="http://arxiv.org/pdf/2011.01511" target="_blank">pdf</a>]

<h2>A Linearly Convergent Algorithm for Decentralized Optimization: Sending Less Bits for Free!. (arXiv:2011.01697v1 [math.OC])</h2>
<h3>Dmitry Kovalev, Anastasia Koloskova, Martin Jaggi, Peter Richtarik, Sebastian U. Stich</h3>
<p>Decentralized optimization methods enable on-device training of machine
learning models without a central coordinator. In many scenarios communication
between devices is energy demanding and time consuming and forms the bottleneck
of the entire system.

We propose a new randomized first-order method which tackles the
communication bottleneck by applying randomized compression operators to the
communicated messages. By combining our scheme with a new variance reduction
technique that progressively throughout the iterations reduces the adverse
effect of the injected quantization noise, we obtain the first scheme that
converges linearly on strongly convex decentralized problems while using
compressed communication only.

We prove that our method can solve the problems without any increase in the
number of communications compared to the baseline which does not perform any
communication compression while still allowing for a significant compression
factor which depends on the conditioning of the problem and the topology of the
network. Our key theoretical findings are supported by numerical experiments.
</p>
<a href="http://arxiv.org/abs/2011.01697" target="_blank">arXiv:2011.01697</a> [<a href="http://arxiv.org/pdf/2011.01697" target="_blank">pdf</a>]

<h2>Federated LQR: Learning through Sharing. (arXiv:2011.01815v1 [math.OC])</h2>
<h3>Zhaolin Ren, Aoxiao Zhong, Zhengyuan Zhou, Na Li</h3>
<p>In many multi-agent reinforcement learning applications such as flocking,
multi-robot applications and smart manufacturing, distinct agents share similar
dynamics but face different objectives. In these applications, an important
question is how the similarities amongst the agents can accelerate learning in
spite of the agents' differing goals. We study a distributed LQR (Linear
Quadratic Regulator) tracking problem which models this setting, where the
agents, acting independently, share identical (unknown) dynamics and cost
structure but need to track different targets. In this paper, we propose a
communication-efficient, federated model-free zeroth-order algorithm that
provably achieves a convergence speedup linear in the number of agents compared
with the communication-free setup where each agent's problem is treated
independently. We support our arguments with numerical simulations of both
linear and nonlinear systems.
</p>
<a href="http://arxiv.org/abs/2011.01815" target="_blank">arXiv:2011.01815</a> [<a href="http://arxiv.org/pdf/2011.01815" target="_blank">pdf</a>]

<h2>Distributional Reinforcement Learning for mmWave Communications with Intelligent Reflectors on a UAV. (arXiv:2011.01840v1 [cs.IT])</h2>
<h3>Qianqian Zhang, Walid Saad, Mehdi Bennis</h3>
<p>In this paper, a novel communication framework that uses an unmanned aerial
vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance
multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In
order to maximize the downlink sum-rate, the optimal precoding matrix (at the
base station) and reflection coefficient (at the IR) are jointly derived. Next,
to address the uncertainty of mmWave channels and maintain line-of-sight links
in a real-time manner, a distributional reinforcement learning approach, based
on quantile regression optimization, is proposed to learn the propagation
environment of mmWave communications, and, then, optimize the location of the
UAV-IR so as to maximize the long-term downlink communication capacity.
Simulation results show that the proposed learning-based deployment of the
UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a
static IR, and a direct transmission schemes, in terms of the average data rate
and the achievable line-of-sight probability of downlink mmWave communications.
</p>
<a href="http://arxiv.org/abs/2011.01840" target="_blank">arXiv:2011.01840</a> [<a href="http://arxiv.org/pdf/2011.01840" target="_blank">pdf</a>]

<h2>Analytical aspects of non-differentiable neural networks. (arXiv:2011.01858v1 [cs.LG])</h2>
<h3>Gian Paolo Leonardi, Matteo Spallanzani</h3>
<p>Research in computational deep learning has directed considerable efforts
towards hardware-oriented optimisations for deep neural networks, via the
simplification of the activation functions, or the quantization of both
activations and weights. The resulting non-differentiability (or even
discontinuity) of the networks poses some challenging problems, especially in
connection with the learning process. In this paper, we address several
questions regarding both the expressivity of quantized neural networks and
approximation techniques for non-differentiable networks. First, we answer in
the affirmative the question of whether QNNs have the same expressivity as DNNs
in terms of approximation of Lipschitz functions in the $L^{\infty}$ norm.
Then, considering a continuous but not necessarily differentiable network, we
describe a layer-wise stochastic regularisation technique to produce
differentiable approximations, and we show how this approach to regularisation
provides elegant quantitative estimates. Finally, we consider networks defined
by means of Heaviside-type activation functions, and prove for them a pointwise
approximation result by means of smooth networks under suitable assumptions on
the regularised activations.
</p>
<a href="http://arxiv.org/abs/2011.01858" target="_blank">arXiv:2011.01858</a> [<a href="http://arxiv.org/pdf/2011.01858" target="_blank">pdf</a>]

<h2>A Study of Policy Gradient on a Class of Exactly Solvable Models. (arXiv:2011.01859v1 [cs.LG])</h2>
<h3>Gavin McCracken, Colin Daniels, Rosie Zhao, Anna Brandenberger, Prakash Panangaden, Doina Precup</h3>
<p>Policy gradient methods are extensively used in reinforcement learning as a
way to optimize expected return. In this paper, we explore the evolution of the
policy parameters, for a special class of exactly solvable POMDPs, as a
continuous-state Markov chain, whose transition probabilities are determined by
the gradient of the distribution of the policy's value. Our approach relies
heavily on random walk theory, specifically on affine Weyl groups. We construct
a class of novel partially observable environments with controllable
exploration difficulty, in which the value distribution, and hence the policy
parameter evolution, can be derived analytically. Using these environments, we
analyze the probabilistic convergence of policy gradient to different local
maxima of the value function. To our knowledge, this is the first approach
developed to analytically compute the landscape of policy gradient in POMDPs
for a class of such environments, leading to interesting insights into the
difficulty of this problem.
</p>
<a href="http://arxiv.org/abs/2011.01859" target="_blank">arXiv:2011.01859</a> [<a href="http://arxiv.org/pdf/2011.01859" target="_blank">pdf</a>]

<h2>Nonlinear Two-Time-Scale Stochastic Approximation: Convergence and Finite-Time Performance. (arXiv:2011.01868v1 [math.OC])</h2>
<h3>Thinh T. Doan</h3>
<p>Two-time-scale stochastic approximation, a generalized version of the popular
stochastic approximation, has found broad applications in many areas including
stochastic control, optimization, and machine learning. Despite of its
popularity, theoretical guarantees of this method, especially its finite-time
performance, are mostly achieved for the linear case while the results for the
nonlinear counterpart are very sparse. Motivated by the classic control theory
for singularly perturbed systems, we study in this paper the asymptotic
convergence and finite-time analysis of the nonlinear two-time-scale stochastic
approximation. Under some fairly standard assumptions, we provide a formula
that characterizes the rate of convergence of the main iterates to the desired
solutions. In particular, we show that the method achieves a convergence in
expectation at a rate $\mathcal{O}(1/k^{2/3})$, where $k$ is the number of
iterations. The key idea in our analysis is to properly choose the two step
sizes to characterize the coupling between the fast and slow-time-scale
iterates.
</p>
<a href="http://arxiv.org/abs/2011.01868" target="_blank">arXiv:2011.01868</a> [<a href="http://arxiv.org/pdf/2011.01868" target="_blank">pdf</a>]

<h2>Deep Joint Transmission-Recognition for Multi-View Cameras. (arXiv:2011.01902v1 [cs.LG])</h2>
<h3>Ezgi Ozyilkan, Mikolaj Jankowski</h3>
<p>We propose joint transmission-recognition schemes for efficient inference at
the wireless edge. Motivated by the surveillance applications with wireless
cameras, we consider the person classification task over a wireless channel
carried out by multi-view cameras operating as edge devices. We introduce deep
neural network (DNN) based compression schemes which incorporate digital
(separate) transmission and joint source-channel coding (JSCC) methods. We
evaluate the proposed device-edge communication schemes under different channel
SNRs, bandwidth and power constraints. We show that the JSCC schemes not only
improve the end-to-end accuracy but also simplify the encoding process and
provide graceful degradation with channel quality.
</p>
<a href="http://arxiv.org/abs/2011.01902" target="_blank">arXiv:2011.01902</a> [<a href="http://arxiv.org/pdf/2011.01902" target="_blank">pdf</a>]

<h2>Multiplicative Subgroups in weakly locally finite division rings. (arXiv:2011.01905v1 [math.RA])</h2>
<h3>Bui Xuan Hai, Huynh Viet Khanh</h3>
<p>The description of the subgroup structure of a non-commutative division ring
is the subject of the intensive study in the theory of division rings in
particular, and of the theory of skew linear groups in general. This study is
still so far to be complete. In this paper, we study this problem for weakly
locally finite division rings. Such division rings constitute a large class
which strictly contains the class of locally finite division rings.
</p>
<a href="http://arxiv.org/abs/2011.01905" target="_blank">arXiv:2011.01905</a> [<a href="http://arxiv.org/pdf/2011.01905" target="_blank">pdf</a>]

<h2>Algebraic commutators with respect to subnormal subgroups in division rings. (arXiv:2011.01911v1 [math.RA])</h2>
<h3>Mai Hoang Bien, Bui Xuan Hai, Vu Mai Trang</h3>
<p>Let $D$ be a division ring and $K$ a subfield of $D$ which is not necessarily
contained in the center $F$ of $D$. In this paper, we study the structure of
$D$ under the condition of left algebraicity of certain subsets of $D$ over
$K$. Among results, it is proved that if $D^*$ contains a noncentral normal
subgroup which is left algebraic over $K$ of bounded degree $d$, then $[D:F]\le
d^2$. In case $K=F$, the obtained results show that if either all additive
commutators or all multiplicative commutators with respect to a noncentral
subnormal subgroup of $D^*$ are algebraic of bounded degree $d$ over $F$, then
$[D:F]\le d^2$.
</p>
<a href="http://arxiv.org/abs/2011.01911" target="_blank">arXiv:2011.01911</a> [<a href="http://arxiv.org/pdf/2011.01911" target="_blank">pdf</a>]

<h2>DNN Expression Rate Analysis of High-dimensional PDEs: Application to Option Pricing. (arXiv:1809.07669v3 [math.FA] UPDATED)</h2>
<h3>Dennis Elbr&#xe4;chter, Philipp Grohs, Arnulf Jentzen, Christoph Schwab</h3>
<p>We analyze approximation rates by deep ReLU networks of a class of
multi-variate solutions of Kolmogorov equations which arise in option pricing.
Key technical devices are deep ReLU architectures capable of efficiently
approximating tensor products. Combining this with results concerning the
approximation of well behaved (i.e. fulfilling some smoothness properties)
univariate functions, this provides insights into rates of deep ReLU
approximation of multi-variate functions with tensor structures. We apply this
in particular to the model problem given by the price of a European maximum
option on a basket of $d$ assets within the Black-Scholes model for European
maximum option pricing. We prove that the solution to the $d$-variate option
pricing problem can be approximated up to an $\varepsilon$-error by a deep ReLU
network with depth $\mathcal{O}\big(\ln(d)\ln(\varepsilon^{-1})+\ln(d)^2\big)$
and $\mathcal{O}\big(d^{2+\frac{1}{n}}\varepsilon^{-\frac{1}{n}}\big)$ non-zero
weights, where $n\in \mathbb{N}$ is arbitrary (with the constant implied in
$\mathcal{O}(\cdot)$ depending on $n$). The techniques developed in the
constructive proof are of independent interest in the analysis of the
expressive power of deep neural networks for solution manifolds of PDEs in high
dimension.
</p>
<a href="http://arxiv.org/abs/1809.07669" target="_blank">arXiv:1809.07669</a> [<a href="http://arxiv.org/pdf/1809.07669" target="_blank">pdf</a>]

<h2>Performance Analysis of Low-Interference N-Continuous OFDM. (arXiv:1811.11044v3 [cs.IT] UPDATED)</h2>
<h3>Peng Wei, Yue Xiao, Lilin Dan, Shichao Lv, Wei Xiang</h3>
<p>The low-interference N-continuous orthogonal frequency division multiplexing
(NC-OFDM) system [25], [26] is investigated in terms of power spectrum density
(PSD) and bit error rate (BER), to prove and quantify its advantages over
traditional NC-OFDM. The PSD and BER performances of the low-interference
scheme are analyzed and compared under the parameters of the highest derivative
order (HDO) and the length of the smooth signal. In the context of PSD,
different from one discontinuous point per NC-OFDM symbol in [25], the sidelobe
suppression performance is evaluated upon considering two discontinuous points
due to the finite continuity of the smooth signal and its higher-order
derivatives. It was shown that with an increased HDO and an increased length of
the smooth signal, a more rapid sidelobe decaying is achieved, for the
significant continuity improvement of the OFDM signal and its higher-order
derivatives. However, our PSD analysis also shows that if the length of the
smooth signal is set inappropriately, the performance may be degraded, even if
the HDO is large. Furthermore, it was shown in the error performance analysis
that under the assumptions of perfect and imperfect synchronization, the
low-interference scheme incurs small BER performance degradation for a short
length of the smooth signal or a small HDO as opposed to conventional NC-OFDM.
Based on analysis and simulation results, the trade-offs between sidelobe
suppression and BER are studied with the above two parameters.
</p>
<a href="http://arxiv.org/abs/1811.11044" target="_blank">arXiv:1811.11044</a> [<a href="http://arxiv.org/pdf/1811.11044" target="_blank">pdf</a>]

<h2>Basis Signal Optimization for N-Continuous OFDM. (arXiv:1812.10944v4 [eess.SP] UPDATED)</h2>
<h3>Peng Wei, Yue Xiao, Wei Xiang</h3>
<p>A novel basis signal optimization method is proposed for reducing the
interference in the N-continuous orthogonal frequency division multiplexing
(NC-OFDM) system. Compared to conventional NC-OFDM, the proposed scheme is
capable of improving the transmission performance while maintaining an
identical sidelobe suppression performance imposed by the linear combination of
two groups of basis signals. Our performance results demonstrate that with a
low complexity overhead, the proposed scheme is capable of striking a better
trade-off among the bit error rate (BER), complexity, and the sidelobe
suppression performance compared to its conventional counterpart.
</p>
<a href="http://arxiv.org/abs/1812.10944" target="_blank">arXiv:1812.10944</a> [<a href="http://arxiv.org/pdf/1812.10944" target="_blank">pdf</a>]

<h2>Eight-dimensional Octonion-like but Associative Normed Division Algebra. (arXiv:1908.06172v7 [math.GM] UPDATED)</h2>
<h3>Joy Christian (Oxford)</h3>
<p>We present an eight-dimensional even sub-algebra of the 2^4 = 16-dimensional
associative Clifford algebra Cl(4,0) and show that its eight-dimensional
elements denoted as X and Y respect the norm relation ||XY|| = ||X|| ||Y||,
thus forming an octonion-like but associative normed division algebra, where
the norms are calculated using the fundamental geometric product instead of the
usual scalar product so that the underlying coefficient algebra resembles that
of split complex numbers instead of reals. The corresponding 7-sphere has a
topology that differs from that of octonionic 7-sphere.
</p>
<a href="http://arxiv.org/abs/1908.06172" target="_blank">arXiv:1908.06172</a> [<a href="http://arxiv.org/pdf/1908.06172" target="_blank">pdf</a>]

<h2>From weakly separated collections to matroid subdivisions. (arXiv:1910.11522v3 [math.CO] UPDATED)</h2>
<h3>Nick Early</h3>
<p>We study arrangements of slightly skewed tropical hyperplanes, called blades
by A. Ocneanu, on the vertices of a hypersimplex $\Delta_{k,n}$, and we
investigate the resulting induced polytopal subdivisions. We show that placing
a blade on a vertex $e_J$ induces an $\ell$-split matroid subdivision of
$\Delta_{k,n}$, where $\ell$ is the number of cyclic intervals in the
$k$-element subset $J$. We prove that a given collection of $k$-element subsets
is weakly separated, in the sense of the work of Leclerc and Zelevinsky on
quasicommuting families of quantum minors, if and only if the arrangement of
the blade $((1,2,\ldots, n))$ on the corresponding vertices of $\Delta_{k,n}$
induces a matroid (in fact, a positroid) subdivision. In this way we obtain a
compatibility criterion for (planar) multi-splits of a hypersimplex,
generalizing the rule known for 2-splits. We study in an extended example the
case $(k,n) = (3,7)$ the set of arrangements of $(k-1)(n-k-1)$ weakly separated
vertices of $\Delta_{k,n}$.
</p>
<a href="http://arxiv.org/abs/1910.11522" target="_blank">arXiv:1910.11522</a> [<a href="http://arxiv.org/pdf/1910.11522" target="_blank">pdf</a>]

<h2>Efficient improper learning for online logistic regression. (arXiv:2003.08109v3 [cs.LG] UPDATED)</h2>
<h3>R&#xe9;mi J&#xe9;z&#xe9;quel (SIERRA), Pierre Gaillard (SIERRA), Alessandro Rudi (SIERRA)</h3>
<p>We consider the setting of online logistic regression and consider the regret
with respect to the 2-ball of radius B. It is known (see [Hazan et al., 2014])
that any proper algorithm which has logarithmic regret in the number of samples
(denoted n) necessarily suffers an exponential multiplicative constant in B. In
this work, we design an efficient improper algorithm that avoids this
exponential constant while preserving a logarithmic regret. Indeed, [Foster et
al., 2018] showed that the lower bound does not apply to improper algorithms
and proposed a strategy based on exponential weights with prohibitive
computational complexity. Our new algorithm based on regularized empirical risk
minimization with surrogate losses satisfies a regret scaling as O(B log(Bn))
with a per-round time-complexity of order O(d^2).
</p>
<a href="http://arxiv.org/abs/2003.08109" target="_blank">arXiv:2003.08109</a> [<a href="http://arxiv.org/pdf/2003.08109" target="_blank">pdf</a>]

<h2>Territorial behaviour of buzzards versus random matrix spacing distributions. (arXiv:2003.09204v2 [q-bio.PE] UPDATED)</h2>
<h3>Gernot Akemann, Michael Baake, Nayden Chakarov, Oliver Kr&#xfc;ger, Adam Mielke, Meinolf Ottensmann, Rebecca Werdehausen</h3>
<p>A deeper understanding of the processes underlying the distribution of
animals in space is crucial for both basic and applied ecology. The Common
buzzard (Buteo buteo) is a highly aggressive, territorial bird of prey that
interacts strongly with its intra- and interspecific competitors. We propose
and use random matrix theory to quantify the strength and range of repulsion as
a function of the buzzard population density, thus providing a novel approach
to model density dependence. As an indicator of territorial behaviour, we
perform a large-scale analysis of the distribution of buzzard nests in an area
of $300$ square kilometres around the Teutoburger Wald, Germany, as gathered
over a period of $20$ years. The nearest and next-to-nearest neighbour spacing
distribution between nests is compared to the two-dimensional Poisson
distribution, originating from uncorrelated random variables, to the complex
eigenvalues of random matrices, which are strongly correlated, and to a
two-dimensional Coulomb gas interpolating between these two. A one-parameter
fit to a time-moving average reveals a significant increase of repulsion
between neighbouring nests, as a function of the observed increase in absolute
population density over the monitored period of time, thereby proving an
unexpected yet simple model for density-dependent spacing of predator
territories. A similar effect is obtained for next-to-nearest neighbours,
albeit with weaker repulsion, indicating a short-range interaction. Our results
show that random matrix theory might be useful in the context of population
ecology.
</p>
<a href="http://arxiv.org/abs/2003.09204" target="_blank">arXiv:2003.09204</a> [<a href="http://arxiv.org/pdf/2003.09204" target="_blank">pdf</a>]

<h2>The SPDE Approach to Mat\'ern Fields: Graph Representations. (arXiv:2004.08000v2 [stat.ME] UPDATED)</h2>
<h3>Daniel Sanz-Alonso, Ruiyi Yang</h3>
<p>This paper investigates Gaussian Markov random field approximations to
nonstationary Gaussian fields using graph representations of stochastic partial
differential equations. We establish approximation error guarantees building on
and generalizing the theory of spectral convergence of graph Laplacians. Graph
representations allow inference and sampling with linear algebra methods for
sparse matrices, thus reducing the computational cost. In addition, they bridge
and unify several models in Bayesian inverse problems, spatial statistics and
graph-based machine learning. We demonstrate through examples in these three
disciplines that the unity revealed by graph representations facilitates the
exchange of ideas across them.
</p>
<a href="http://arxiv.org/abs/2004.08000" target="_blank">arXiv:2004.08000</a> [<a href="http://arxiv.org/pdf/2004.08000" target="_blank">pdf</a>]

<h2>Equitable and Optimal Transport with Multiple Agents. (arXiv:2006.07260v2 [stat.ML] UPDATED)</h2>
<h3>Meyer Scetbon, Laurent Meunier, Jamal Atif, Marco Cuturi</h3>
<p>We introduce an extension of the Optimal Transport problem when multiple
costs are involved. Considering each cost as an agent, we aim to share equally
between agents the work of transporting one distribution to another. To do so,
we minimize the transportation cost of the agent who works the most. Another
point of view is when the goal is to partition equitably goods between agents
according to their heterogeneous preferences. Here we aim to maximize the
utility of the least advantaged agent. This is a fair division problem. Like
Optimal Transport, the problem can be cast as a linear optimization problem.
When there is only one agent, we recover the Optimal Transport problem. When
two agents are considered, we are able to recover Integral Probability Metrics
defined by $\alpha$-H\"older functions, which include the widely-known Dudley
metric. To the best of our knowledge, this is the first time a link is given
between the Dudley metric and Optimal Transport. We provide an entropic
regularization of that problem which leads to an alternative algorithm faster
than the standard linear program.
</p>
<a href="http://arxiv.org/abs/2006.07260" target="_blank">arXiv:2006.07260</a> [<a href="http://arxiv.org/pdf/2006.07260" target="_blank">pdf</a>]

<h2>Optimizing Mode Connectivity via Neuron Alignment. (arXiv:2009.02439v2 [cs.LG] UPDATED)</h2>
<h3>N. Joseph Tatro, Pin-Yu Chen, Payel Das, Igor Melnyk, Prasanna Sattigeri, Rongjie Lai</h3>
<p>The loss landscapes of deep neural networks are not well understood due to
their high nonconvexity. Empirically, the local minima of these loss functions
can be connected by a learned curve in model space, along which the loss
remains nearly constant; a feature known as mode connectivity. Yet, current
curve finding algorithms do not consider the influence of symmetry in the loss
surface created by model weight permutations. We propose a more general
framework to investigate the effect of symmetry on landscape connectivity by
accounting for the weight permutations of the networks being connected. To
approximate the optimal permutation, we introduce an inexpensive heuristic
referred to as neuron alignment. Neuron alignment promotes similarity between
the distribution of intermediate activations of models along the curve. We
provide theoretical analysis establishing the benefit of alignment to mode
connectivity based on this simple heuristic. We empirically verify that the
permutation given by alignment is locally optimal via a proximal alternating
minimization scheme. Empirically, optimizing the weight permutation is critical
for efficiently learning a simple, planar, low-loss curve between networks that
successfully generalizes. Our alignment method can significantly alleviate the
recently identified robust loss barrier on the path connecting two adversarial
robust models and find more robust and accurate models on the path.
</p>
<a href="http://arxiv.org/abs/2009.02439" target="_blank">arXiv:2009.02439</a> [<a href="http://arxiv.org/pdf/2009.02439" target="_blank">pdf</a>]

<h2>Learning to Optimise General TSP Instances. (arXiv:2010.12214v2 [cs.LG] UPDATED)</h2>
<h3>Nasrin Sultana, Jeffrey Chan, A. K. Qin, Tabinda Sarwar</h3>
<p>The Travelling Salesman Problem (TSP) is a classical combinatorial
optimisation problem. Deep learning has been successfully extended to
meta-learning, where previous solving efforts assist in learning how to
optimise future optimisation instances. In recent years, learning to optimise
approaches have shown success in solving TSP problems. However, they focus on
one type of TSP problem, namely ones where the points are uniformly distributed
in Euclidean spaces and have issues in generalising to other embedding spaces,
e.g., spherical distance spaces, and to TSP instances where the points are
distributed in a non-uniform manner. An aim of learning to optimise is to train
once and solve across a broad spectrum of (TSP) problems. Although supervised
learning approaches have shown to achieve more optimal solutions than
unsupervised approaches, they do require the generation of training data and
running a solver to obtain solutions to learn from, which can be time-consuming
and difficult to find reasonable solutions for harder TSP instances. Hence this
paper introduces a new learning-based approach to solve a variety of different
and common TSP problems that are trained on easier instances which are faster
to train and are easier to obtain better solutions. We name this approach the
non-Euclidean TSP network (NETSP-Net). The approach is evaluated on various TSP
instances using the benchmark TSPLIB dataset and popular instance generator
used in the literature. We performed extensive experiments that indicate our
approach generalises across many types of instances and scales to instances
that are larger than what was used during training.
</p>
<a href="http://arxiv.org/abs/2010.12214" target="_blank">arXiv:2010.12214</a> [<a href="http://arxiv.org/pdf/2010.12214" target="_blank">pdf</a>]

<h2>Sub-linear convergence of a stochastic proximal iteration method in Hilbert space. (arXiv:2010.12348v2 [math.OC] UPDATED)</h2>
<h3>Monika Eisenmann, Tony Stillfjord, M&#xe5;ns Williamson</h3>
<p>We consider a stochastic version of the proximal point algorithm for
optimization problems posed on a Hilbert space. A typical application of this
is supervised learning. While the method is not new, it has not been
extensively analyzed in this form. Indeed, most related results are confined to
the finite-dimensional setting, where error bounds could depend on the
dimension of the space. On the other hand, the few existing results in the
infinite-dimensional setting only prove very weak types of convergence, owing
to weak assumptions on the problem. In particular, there are no results that
show convergence with a rate. In this article, we bridge these two worlds by
assuming more regularity of the optimization problem, which allows us to prove
convergence with an (optimal) sub-linear rate also in an infinite-dimensional
setting. We illustrate these results by discretizing a concrete
infinite-dimensional classification problem with varying degrees of accuracy.
</p>
<a href="http://arxiv.org/abs/2010.12348" target="_blank">arXiv:2010.12348</a> [<a href="http://arxiv.org/pdf/2010.12348" target="_blank">pdf</a>]

<h2>Uplink Transmission Design for Crowded Correlated Cell-Free Massive MIMO-OFDM Systems. (arXiv:2011.00203v2 [cs.IT] UPDATED)</h2>
<h3>Junyuan Gao, Yongpeng Wu, Yongjian Wang, Wenjun Zhang, Fan Wei</h3>
<p>In cell-free massive multiple-input multiple-output (MIMO) orthogonal
frequency division multiplexing (OFDM) systems, user equipments (UEs) are
served by many distributed access points (APs), where channels are correlated
due to finite angle-delay spread in realistic outdoor wireless propagation
environments. Meanwhile, the number of UEs is growing rapidly for future fully
networked society. In this paper, we focus on the uplink transmission design in
crowded correlated cell-free massive MIMO-OFDM systems with limited number of
orthogonal pilots. For the pilot transmission phase, we identify active UEs
based on non-orthogonal pilot phase shift hopping patterns and non-orthogonal
adjustable phase shift pilots (APSP). We derive a closed-form expression of
mean square error of channel estimation (MSE-CE) and obtain an optimal
condition for minimizing MSE-CE. According to this condition, the APSP set
allocation scheme is proposed. Furthermore, for the data transmission, the
max-min power control algorithm is devised to maximize the minimum spectral
efficiency (SE) lower bound among active UEs. Simulation results indicate
significant performance gains in terms of MSE-CE for the proposed APSP set
allocation scheme. The proposed power control scheme can further improve the
minimum SE among active UEs. Hence, they are crucial for crowded correlated
cell-free massive MIMO-OFDM systems.
</p>
<a href="http://arxiv.org/abs/2011.00203" target="_blank">arXiv:2011.00203</a> [<a href="http://arxiv.org/pdf/2011.00203" target="_blank">pdf</a>]

<h2>Planar Kinematics: Cyclic Fixed Points, Mirror Superpotential, k-Dimensional Catalan Numbers, and Root Polytopes. (arXiv:2010.09708v1 [math.CO] CROSS LISTED)</h2>
<h3>Freddy Cachazo, Nick Early</h3>
<p>In this paper we prove that points in the space $X(k,n)$ of configurations of
$n$ points in $\mathbb{CP}^{k-1}$ which are fixed under a certain cyclic action
are the solutions to the generalized scattering equations on planar kinematics
(PK). In the first part, we give a constructive upper bound: we show that these
solutions inject into certain aperiodic k-element subsets of $\{1,\ldots, n\}$,
and consequently that their number is bounded above by the number of Lyndon
words with k one's and n-k zeros. The proof uses a somewhat surprising
connection between the superpotential of the mirror of $G(n-k,n)$ and the
generalized CHY potential on $X(k,n)$. We also check the recent conjecture that
generalized biadjoint amplitudes evaluate to $k$-dimensional Catalan numbers on
PK for several examples including $k=3$ and $n\leq 40$ and $(k,n)=(6,13)$. We
then reformulate the CEGM generalized biadjoint scalar amplitude directly as a
Laplace transform-type integral over ${\rm Trop}^+ G(k,n)$ and we use it to
evaluate the amplitude on PK with the purpose of exhibiting how GFD's glue
together.

We initiate the study of two minimal lattice polytopal neighborhoods of the
planar kinematics point. One of these, the rank-graded root polytope
$\mathcal{R}_{k,n}$, in the case $k=2$, is a projection of the standard type A
root polytope. The other, denoted $\Pi_{k,n}$, in the case $k=2$, is a
degeneration of the associahedron. We check up to and including
$\mathcal{R}_{3,9}$ and $\mathcal{R}_{4,9}$ that the relative volume of
$\mathcal{R}_{k,n}$ is the multi-dimensional Catalan number $C^{(k)}_{n-k}$,
hinting towards the possibility of deeper geometric and combinatorial
interpretations of $m^{(k)}(\mathbb{I}_n,\mathbb{I}_n)$ near the PK point.
</p>
<a href="http://arxiv.org/abs/2010.09708" target="_blank">arXiv:2010.09708</a> [<a href="http://arxiv.org/pdf/2010.09708" target="_blank">pdf</a>]

<h2>Estimating County-Level COVID-19 Exponential Growth Rates Using Generalized Random Forests. (arXiv:2011.01219v1 [cs.LG])</h2>
<h3>Zhaowei She, Zilong Wang, Turgay Ayer, Jagpreet Chhatwal, Asmae Toumi</h3>
<p>Rapid and accurate detection of community outbreaks is critical to address
the threat of resurgent waves of COVID-19. A practical challenge in outbreak
detection is balancing accuracy vs. speed. In particular, while accuracy
improves with estimations based on longer fitting windows, speed degrades. This
paper presents a machine learning framework to balance this tradeoff using
generalized random forests (GRF), and applies it to detect county level
COVID-19 outbreaks. This algorithm chooses an adaptive fitting window size for
each county based on relevant features affecting the disease spread, such as
changes in social distancing policies. Experiment results show that our method
outperforms any non-adaptive window size choices in 7-day ahead COVID-19
outbreak case number predictions.
</p>
<a href="http://arxiv.org/abs/2011.01219" target="_blank">arXiv:2011.01219</a> [<a href="http://arxiv.org/pdf/2011.01219" target="_blank">pdf</a>]

<h2>A Lane-Changing Prediction Method Based on Temporal Convolution Network. (arXiv:2011.01224v1 [cs.LG])</h2>
<h3>Yue Zhang, Yajie Zou, Jinjun Tang, Jian Liang</h3>
<p>Lane-changing is an important driving behavior and unreasonable lane changes
can result in potentially dangerous traffic collisions. Advanced Driver
Assistance System (ADAS) can assist drivers to change lanes safely and
efficiently. To capture the stochastic time series of lane-changing behavior,
this study proposes a temporal convolutional network (TCN) to predict the
long-term lane-changing trajectory and behavior. In addition, the convolutional
neural network (CNN) and recurrent neural network (RNN) methods are considered
as the benchmark models to demonstrate the learning ability of the TCN. The
lane-changing dataset was collected by the driving simulator. The prediction
performance of TCN is demonstrated from three aspects: different input
variables, different input dimensions and different driving scenarios.
Prediction results show that the TCN can accurately predict the long-term
lane-changing trajectory and driving behavior with shorter computational time
compared with two benchmark models. The TCN can provide accurate lane-changing
prediction, which is one key information for the development of accurate ADAS.
</p>
<a href="http://arxiv.org/abs/2011.01224" target="_blank">arXiv:2011.01224</a> [<a href="http://arxiv.org/pdf/2011.01224" target="_blank">pdf</a>]

<h2>Sample-efficient reinforcement learning using deep Gaussian processes. (arXiv:2011.01226v1 [stat.ML])</h2>
<h3>Charles Gadd, Markus Heinonen, Harri L&#xe4;hdesm&#xe4;ki, Samuel Kaski</h3>
<p>Reinforcement learning provides a framework for learning to control which
actions to take towards completing a task through trial-and-error. In many
applications observing interactions is costly, necessitating sample-efficient
learning. In model-based reinforcement learning efficiency is improved by
learning to simulate the world dynamics. The challenge is that model
inaccuracies rapidly accumulate over planned trajectories. We introduce deep
Gaussian processes where the depth of the compositions introduces model
complexity while incorporating prior knowledge on the dynamics brings
smoothness and structure. Our approach is able to sample a Bayesian posterior
over trajectories. We demonstrate highly improved early sample-efficiency over
competing methods. This is shown across a number of continuous control tasks,
including the half-cheetah whose contact dynamics have previously posed an
insurmountable problem for earlier sample-efficient Gaussian process based
models.
</p>
<a href="http://arxiv.org/abs/2011.01226" target="_blank">arXiv:2011.01226</a> [<a href="http://arxiv.org/pdf/2011.01226" target="_blank">pdf</a>]

<h2>Modular-Relatedness for Continual Learning. (arXiv:2011.01272v1 [cs.LG])</h2>
<h3>Ammar Shaker, Shujian Yu, Francesco Alesiani</h3>
<p>In this paper, we propose a continual learning (CL) technique that is
beneficial to sequential task learners by improving their retained accuracy and
reducing catastrophic forgetting. The principal target of our approach is the
automatic extraction of modular parts of the neural network and then estimating
the relatedness between the tasks given these modular components. This
technique is applicable to different families of CL methods such as
regularization-based (e.g., the Elastic Weight Consolidation) or the
rehearsal-based (e.g., the Gradient Episodic Memory) approaches where episodic
memory is needed. Empirical results demonstrate remarkable performance gain (in
terms of robustness to forgetting) for methods such as EWC and GEM based on our
technique, especially when the memory budget is very limited.
</p>
<a href="http://arxiv.org/abs/2011.01272" target="_blank">arXiv:2011.01272</a> [<a href="http://arxiv.org/pdf/2011.01272" target="_blank">pdf</a>]

<h2>Exemplar Guided Active Learning. (arXiv:2011.01285v1 [cs.LG])</h2>
<h3>Jason Hartford, Kevin Leyton-Brown, Hadas Raviv, Dan Padnos, Shahar Lev, Barak Lenz</h3>
<p>We consider the problem of wisely using a limited budget to label a small
subset of a large unlabeled dataset. We are motivated by the NLP problem of
word sense disambiguation. For any word, we have a set of candidate labels from
a knowledge base, but the label set is not necessarily representative of what
occurs in the data: there may exist labels in the knowledge base that very
rarely occur in the corpus because the sense is rare in modern English; and
conversely there may exist true labels that do not exist in our knowledge base.
Our aim is to obtain a classifier that performs as well as possible on examples
of each "common class" that occurs with frequency above a given threshold in
the unlabeled set while annotating as few examples as possible from "rare
classes" whose labels occur with less than this frequency. The challenge is
that we are not informed which labels are common and which are rare, and the
true label distribution may exhibit extreme skew. We describe an active
learning approach that (1) explicitly searches for rare classes by leveraging
the contextual embedding spaces provided by modern language models, and (2)
incorporates a stopping rule that ignores classes once we prove that they occur
below our target threshold with high probability. We prove that our algorithm
only costs logarithmically more than a hypothetical approach that knows all
true label frequencies and show experimentally that incorporating automated
search can significantly reduce the number of samples needed to reach target
accuracy levels.
</p>
<a href="http://arxiv.org/abs/2011.01285" target="_blank">arXiv:2011.01285</a> [<a href="http://arxiv.org/pdf/2011.01285" target="_blank">pdf</a>]

<h2>Useful Policy Invariant Shaping from Arbitrary Advice. (arXiv:2011.01297v1 [cs.LG])</h2>
<h3>Paniz Behboudian, Yash Satsangi, Matthew E. Taylor, Anna Harutyunyan, Michael Bowling</h3>
<p>Reinforcement learning is a powerful learning paradigm in which agents can
learn to maximize sparse and delayed reward signals. Although RL has had many
impressive successes in complex domains, learning can take hours, days, or even
years of training data. A major challenge of contemporary RL research is to
discover how to learn with less data. Previous work has shown that domain
information can be successfully used to shape the reward; by adding additional
reward information, the agent can learn with much less data. Furthermore, if
the reward is constructed from a potential function, the optimal policy is
guaranteed to be unaltered. While such potential-based reward shaping (PBRS)
holds promise, it is limited by the need for a well-defined potential function.
Ideally, we would like to be able to take arbitrary advice from a human or
other agent and improve performance without affecting the optimal policy. The
recently introduced dynamic potential based advice (DPBA) method tackles this
challenge by admitting arbitrary advice from a human or other agent and
improves performance without affecting the optimal policy. The main
contribution of this paper is to expose, theoretically and empirically, a flaw
in DPBA. Alternatively, to achieve the ideal goals, we present a simple method
called policy invariant explicit shaping (PIES) and show theoretically and
empirically that PIES succeeds where DPBA fails.
</p>
<a href="http://arxiv.org/abs/2011.01297" target="_blank">arXiv:2011.01297</a> [<a href="http://arxiv.org/pdf/2011.01297" target="_blank">pdf</a>]

<h2>Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations using Generative Models. (arXiv:2011.01298v1 [cs.RO])</h2>
<h3>Yuchen Wu, Melissa Mozifian, Florian Shkurti</h3>
<p>The potential benefits of model-free reinforcement learning to real robotics
systems are limited by its uninformed exploration that leads to slow
convergence, lack of data-efficiency, and unnecessary interactions with the
environment. To address these drawbacks we propose a method that combines
reinforcement and imitation learning by shaping the reward function with a
state-and-action-dependent potential that is trained from demonstration data,
using a generative model. We show that this accelerates policy learning by
specifying high-value areas of the state and action space that are worth
exploring first. Unlike the majority of existing methods that assume optimal
demonstrations and incorporate the demonstration data as hard constraints on
policy optimization, we instead incorporate demonstration data as advice in the
form of a reward shaping potential trained as a generative model of states and
actions. In particular, we examine both normalizing flows and Generative
Adversarial Networks to represent these potentials. We show that, unlike many
existing approaches that incorporate demonstrations as hard constraints, our
approach is unbiased even in the case of suboptimal and noisy demonstrations.
We present an extensive range of simulations, as well as experiments on the
Franka Emika 7DOF arm, to demonstrate the practicality of our method.
</p>
<a href="http://arxiv.org/abs/2011.01298" target="_blank">arXiv:2011.01298</a> [<a href="http://arxiv.org/pdf/2011.01298" target="_blank">pdf</a>]

<h2>IOS: Inter-Operator Scheduler for CNN Acceleration. (arXiv:2011.01302v1 [cs.LG])</h2>
<h3>Yaoyao Ding, Ligeng Zhu, Zhihao Jia, Gennady Pekhimenko, Song Han</h3>
<p>To accelerate CNN inference, existing deep learning frameworks focus on
optimizing intra-operator parallelization. However, a single operator can no
longer fully utilize the available parallelism given the rapid advances in
high-performance hardware, resulting in a large gap between the peak
performance and the real performance. This performance gap is more severe under
smaller batch sizes. In this work, we extensively study the parallelism between
operators and propose Inter-Operator Scheduler (IOS) to automatically schedule
the execution of multiple operators in parallel. IOS utilizes dynamic
programming to find a scheduling policy specialized for the target hardware.
IOS consistently outperforms state-of-the-art libraries (e.g., TensorRT) by 1.1
to 1.5x on modern CNN benchmarks.
</p>
<a href="http://arxiv.org/abs/2011.01302" target="_blank">arXiv:2011.01302</a> [<a href="http://arxiv.org/pdf/2011.01302" target="_blank">pdf</a>]

<h2>Pairwise Relations Discriminator for Unsupervised Raven's Progressive Matrices. (arXiv:2011.01306v1 [cs.AI])</h2>
<h3>Nicholas Quek Wei Kiat, Duo Wang, Mateja Jamnik</h3>
<p>Abstract reasoning is a key indicator of intelligence. The ability to
hypothesise, develop abstract concepts based on concrete observations and apply
this hypothesis to justify future actions has been paramount in human
development. An existing line of research in outfitting intelligent machines
with abstract reasoning capabilities revolves around the Raven's Progressive
Matrices (RPM), a multiple-choice visual puzzle where one must identify the
missing component which completes the pattern. There have been many
breakthroughs in supervised approaches to solving RPM in recent years. However,
since this process requires external assistance, we cannot claim that machines
have achieved reasoning ability comparable to humans. Namely, when the RPM rule
that relations can only exist row/column-wise is properly introduced, humans
can solve RPM problems without supervision or prior experience. In this paper,
we introduce a pairwise relations discriminator (PRD), a technique to develop
unsupervised models with sufficient reasoning abilities to tackle an RPM
problem. PRD reframes the RPM problem into a relation comparison task, which we
can solve without requiring the labelling of the RPM problem. We can identify
the optimal candidate by adapting the application of PRD on the RPM problem.
The previous state-of-the-art approach "mcpt" in this domain achieved 28.5%
accuracy on the RAVEN dataset "drt", a standard dataset for computational work
on RPM. Our approach, the PRD, establishes a new state-of-the-art benchmark
with an accuracy of 50.74% on the same dataset, presenting a significant
improvement and a step forward in equipping machines with abstract reasoning.
</p>
<a href="http://arxiv.org/abs/2011.01306" target="_blank">arXiv:2011.01306</a> [<a href="http://arxiv.org/pdf/2011.01306" target="_blank">pdf</a>]

<h2>The Mathematical Foundations of Manifold Learning. (arXiv:2011.01307v1 [cs.LG])</h2>
<h3>Luke Melas-Kyriazi</h3>
<p>Manifold learning is a popular and quickly-growing subfield of machine
learning based on the assumption that one's observed data lie on a
low-dimensional manifold embedded in a higher-dimensional space. This thesis
presents a mathematical perspective on manifold learning, delving into the
intersection of kernel learning, spectral graph theory, and differential
geometry. Emphasis is placed on the remarkable interplay between graphs and
manifolds, which forms the foundation for the widely-used technique of manifold
regularization. This work is written to be accessible to a broad mathematical
audience, including machine learning researchers and practitioners interested
in understanding the theorems underlying popular manifold learning algorithms
and dimensionality reduction techniques.
</p>
<a href="http://arxiv.org/abs/2011.01307" target="_blank">arXiv:2011.01307</a> [<a href="http://arxiv.org/pdf/2011.01307" target="_blank">pdf</a>]

<h2>Automatic Detection of Machine Generated Text: A Critical Survey. (arXiv:2011.01314v1 [cs.CL])</h2>
<h3>Ganesh Jawahar, Muhammad Abdul-Mageed, Laks V.S. Lakshmanan</h3>
<p>Text generative models (TGMs) excel in producing text that matches the style
of human language reasonably well. Such TGMs can be misused by adversaries,
e.g., by automatically generating fake news and fake product reviews that can
look authentic and fool humans. Detectors that can distinguish text generated
by TGM from human written text play a vital role in mitigating such misuse of
TGMs. Recently, there has been a flurry of works from both natural language
processing (NLP) and machine learning (ML) communities to build accurate
detectors for English. Despite the importance of this problem, there is
currently no work that surveys this fast-growing literature and introduces
newcomers to important research challenges. In this work, we fill this void by
providing a critical survey and review of this literature to facilitate a
comprehensive understanding of this problem. We conduct an in-depth error
analysis of the state-of-the-art detector and discuss research directions to
guide future work in this exciting area.
</p>
<a href="http://arxiv.org/abs/2011.01314" target="_blank">arXiv:2011.01314</a> [<a href="http://arxiv.org/pdf/2011.01314" target="_blank">pdf</a>]

<h2>Incorporating Rivalry in Reinforcement Learning for a Competitive Game. (arXiv:2011.01337v1 [cs.AI])</h2>
<h3>Pablo Barros, Ana Tanevska, Ozge Yalcin, Alessandra Sciutti</h3>
<p>Recent advances in reinforcement learning with social agents have allowed us
to achieve human-level performance on some interaction tasks. However, most
interactive scenarios do not have as end-goal performance alone; instead, the
social impact of these agents when interacting with humans is as important and,
in most cases, never explored properly. This preregistration study focuses on
providing a novel learning mechanism based on a rivalry social impact. Our
scenario explored different reinforcement learning-based agents playing a
competitive card game against human players. Based on the concept of
competitive rivalry, our analysis aims to investigate if we can change the
assessment of these agents from a human perspective.
</p>
<a href="http://arxiv.org/abs/2011.01337" target="_blank">arXiv:2011.01337</a> [<a href="http://arxiv.org/pdf/2011.01337" target="_blank">pdf</a>]

<h2>Recyclable Waste Identification Using CNN Image Recognition and Gaussian Clustering. (arXiv:2011.01353v1 [cs.CV])</h2>
<h3>Yuheng Wang, Wen Jie Zhao, Jiahui Xu, Raymond Hong</h3>
<p>Waste recycling is an important way of saving energy and materials in the
production process. In general cases recyclable objects are mixed with
unrecyclable objects, which raises a need for identification and
classification. This paper proposes a convolutional neural network (CNN) model
to complete both tasks. The model uses transfer learning from a pretrained
Resnet-50 CNN to complete feature extraction. A subsequent fully connected
layer for classification was trained on the augmented TrashNet dataset [1]. In
the application, sliding-window is used for image segmentation in the
pre-classification stage. In the post-classification stage, the labelled sample
points are integrated with Gaussian Clustering to locate the object. The
resulting model has achieved an overall detection rate of 48.4% in simulation
and final classification accuracy of 92.4%.
</p>
<a href="http://arxiv.org/abs/2011.01353" target="_blank">arXiv:2011.01353</a> [<a href="http://arxiv.org/pdf/2011.01353" target="_blank">pdf</a>]

<h2>Unsupervised Monocular Depth Learning with Integrated Intrinsics and Spatio-Temporal Constraints. (arXiv:2011.01354v1 [cs.CV])</h2>
<h3>Kenny Chen, Alexandra Pogue, Brett T. Lopez, Ali-akbar Agha-mohammadi, Ankur Mehta</h3>
<p>Monocular depth inference has gained tremendous attention from researchers in
recent years and remains as a promising replacement for expensive
time-of-flight sensors, but issues with scale acquisition and implementation
overhead still plague these systems. To this end, this work presents an
unsupervised learning framework that is able to predict at-scale depth maps and
egomotion, in addition to camera intrinsics, from a sequence of monocular
images via a single network. Our method incorporates both spatial and temporal
geometric constraints to resolve depth and pose scale factors, which are
enforced within the supervisory reconstruction loss functions at training time.
Only unlabeled stereo sequences are required for training the weights of our
single-network architecture, which reduces overall implementation overhead as
compared to previous methods. Our results demonstrate strong performance when
compared to the current state-of-the-art on multiple sequences of the KITTI
driving dataset.
</p>
<a href="http://arxiv.org/abs/2011.01354" target="_blank">arXiv:2011.01354</a> [<a href="http://arxiv.org/pdf/2011.01354" target="_blank">pdf</a>]

<h2>Patch2Self: Denoising Diffusion MRI with Self-Supervised Learning. (arXiv:2011.01355v1 [cs.LG])</h2>
<h3>Shreyas Fadnavis, Joshua Batson, Eleftherios Garyfallidis</h3>
<p>Diffusion-weighted magnetic resonance imaging (DWI) is the only noninvasive
method for quantifying microstructure and reconstructing white-matter pathways
in the living human brain. Fluctuations from multiple sources create
significant additive noise in DWI data which must be suppressed before
subsequent microstructure analysis. We introduce a self-supervised learning
method for denoising DWI data, Patch2Self, which uses the entire volume to
learn a full-rank locally linear denoiser for that volume. By taking advantage
of the oversampled q-space of DWI data, Patch2Self can separate structure from
noise without requiring an explicit model for either. We demonstrate the
effectiveness of Patch2Self via quantitative and qualitative improvements in
microstructure modeling, tracking (via fiber bundle coherency) and model
estimation relative to other unsupervised methods on real and simulated data.
</p>
<a href="http://arxiv.org/abs/2011.01355" target="_blank">arXiv:2011.01355</a> [<a href="http://arxiv.org/pdf/2011.01355" target="_blank">pdf</a>]

<h2>Optimal Policies for the Homogeneous Selective Labels Problem. (arXiv:2011.01381v1 [cs.LG])</h2>
<h3>Dennis Wei</h3>
<p>Selective labels are a common feature of consequential decision-making
applications, referring to the lack of observed outcomes under one of the
possible decisions. This paper reports work in progress on learning decision
policies in the face of selective labels. The setting considered is both a
simplified homogeneous one, disregarding individuals' features to facilitate
determination of optimal policies, and an online one, to balance costs incurred
in learning with future utility. For maximizing discounted total reward, the
optimal policy is shown to be a threshold policy, and the problem is one of
optimal stopping. In contrast, for undiscounted infinite-horizon average
reward, optimal policies have positive acceptance probability in all states.
Future work stemming from these results is discussed.
</p>
<a href="http://arxiv.org/abs/2011.01381" target="_blank">arXiv:2011.01381</a> [<a href="http://arxiv.org/pdf/2011.01381" target="_blank">pdf</a>]

<h2>Cortex: A Compiler for Recursive Deep Learning Models. (arXiv:2011.01383v1 [cs.LG])</h2>
<h3>Pratik Fegade, Tianqi Chen, Phil Gibbons, Todd Mowry</h3>
<p>Optimizing deep learning models is generally performed in two steps: (i)
high-level graph optimizations such as kernel fusion and (ii) low level kernel
optimizations such as those found in vendor libraries. This approach often
leaves significant performance on the table, especially for the case of
recursive deep learning models. In this paper, we present Cortex, a
compiler-based approach to generate highly-efficient code for recursive models
for low latency inference. Our compiler approach and low reliance on vendor
libraries enables us to perform end-to-end optimizations, leading to up to 14X
lower inference latencies over past work, across different backends.
</p>
<a href="http://arxiv.org/abs/2011.01383" target="_blank">arXiv:2011.01383</a> [<a href="http://arxiv.org/pdf/2011.01383" target="_blank">pdf</a>]

<h2>Dual Attention on Pyramid Feature Maps for Image Captioning. (arXiv:2011.01385v1 [cs.CV])</h2>
<h3>Litao Yu, Jian Zhang, Qiang Wu</h3>
<p>Generating natural sentences from images is a fundamental learning task for
visual-semantic understanding in multimedia. In this paper, we propose to apply
dual attention on pyramid image feature maps to fully explore the
visual-semantic correlations and improve the quality of generated sentences.
Specifically, with the full consideration of the contextual information
provided by the hidden state of the RNN controller, the pyramid attention can
better localize the visually indicative and semantically consistent regions in
images. On the other hand, the contextual information can help re-calibrate the
importance of feature components by learning the channel-wise dependencies, to
improve the discriminative power of visual features for better content
description. We conducted comprehensive experiments on three well-known
datasets: Flickr8K, Flickr30K and MS COCO, which achieved impressive results in
generating descriptive and smooth natural sentences from images. Using either
convolution visual features or more informative bottom-up attention features,
our composite captioning model achieves very promising performance in a
single-model mode. The proposed pyramid attention and dual attention methods
are highly modular, which can be inserted into various image captioning modules
to further improve the performance.
</p>
<a href="http://arxiv.org/abs/2011.01385" target="_blank">arXiv:2011.01385</a> [<a href="http://arxiv.org/pdf/2011.01385" target="_blank">pdf</a>]

<h2>Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition. (arXiv:2011.01387v1 [cs.RO])</h2>
<h3>Jonah Siekmann, Yesh Godse, Alan Fern, Jonathan Hurst</h3>
<p>We study the problem of realizing the full spectrum of bipedal locomotion on
a real robot with sim-to-real reinforcement learning (RL). A key challenge of
learning legged locomotion is describing different gaits, via reward functions,
in a way that is intuitive for the designer and specific enough to reliably
learn the gait across different initial random seeds or hyperparameters. A
common approach is to use reference motions (e.g. trajectories of joint
positions) to guide learning. However, finding high-quality reference motions
can be difficult and the trajectories themselves narrowly constrain the space
of learned motion. At the other extreme, reference-free reward functions are
often underspecified (e.g. move forward) leading to massive variance in policy
behavior, or are the product of significant reward-shaping via trial-and-error,
making them exclusive to specific gaits. In this work, we propose a
reward-specification framework based on composing simple probabilistic periodic
costs on basic forces and velocities. We instantiate this framework to define a
parametric reward function with intuitive settings for all common bipedal gaits
- standing, walking, hopping, running, and skipping. Using this function we
demonstrate successful sim-to-real transfer of the learned gaits to the bipedal
robot Cassie, as well as a generic policy that can transition between all of
the two-beat gaits.
</p>
<a href="http://arxiv.org/abs/2011.01387" target="_blank">arXiv:2011.01387</a> [<a href="http://arxiv.org/pdf/2011.01387" target="_blank">pdf</a>]

<h2>Parameter Efficient Deep Neural Networks with Bilinear Projections. (arXiv:2011.01391v1 [cs.CV])</h2>
<h3>Litao Yu, Yongsheng Gao, Jun Zhou, Jian Zhang</h3>
<p>Recent research on deep neural networks (DNNs) has primarily focused on
improving the model accuracy. Given a proper deep learning framework, it is
generally possible to increase the depth or layer width to achieve a higher
level of accuracy. However, the huge number of model parameters imposes more
computational and memory usage overhead and leads to the parameter redundancy.
In this paper, we address the parameter redundancy problem in DNNs by replacing
conventional full projections with bilinear projections. For a fully-connected
layer with $D$ input nodes and $D$ output nodes, applying bilinear projection
can reduce the model space complexity from $\mathcal{O}(D^2)$ to
$\mathcal{O}(2D)$, achieving a deep model with a sub-linear layer size.
However, structured projection has a lower freedom of degree compared to the
full projection, causing the under-fitting problem. So we simply scale up the
mapping size by increasing the number of output channels, which can keep and
even boosts the model accuracy. This makes it very parameter-efficient and
handy to deploy such deep models on mobile systems with memory limitations.
Experiments on four benchmark datasets show that applying the proposed bilinear
projection to deep neural networks can achieve even higher accuracies than
conventional full DNNs, while significantly reduces the model size.
</p>
<a href="http://arxiv.org/abs/2011.01391" target="_blank">arXiv:2011.01391</a> [<a href="http://arxiv.org/pdf/2011.01391" target="_blank">pdf</a>]

<h2>GAIN: Graph Attention & Interaction Network for Inductive Semi-Supervised Learning over Large-scale Graphs. (arXiv:2011.01393v1 [cs.LG])</h2>
<h3>Yunpeng Weng, Xu Chen, Liang Chen, Wei Liu</h3>
<p>Graph Neural Networks (GNNs) have led to state-of-the-art performance on a
variety of machine learning tasks such as recommendation, node classification
and link prediction. Graph neural network models generate node embeddings by
merging nodes features with the aggregated neighboring nodes information. Most
existing GNN models exploit a single type of aggregator (e.g., mean-pooling) to
aggregate neighboring nodes information, and then add or concatenate the output
of aggregator to the current representation vector of the center node. However,
using only a single type of aggregator is difficult to capture the different
aspects of neighboring information and the simple addition or concatenation
update methods limit the expressive capability of GNNs. Not only that, existing
supervised or semi-supervised GNN models are trained based on the loss function
of the node label, which leads to the neglect of graph structure information.
In this paper, we propose a novel graph neural network architecture, Graph
Attention \&amp; Interaction Network (GAIN), for inductive learning on graphs.
Unlike the previous GNN models that only utilize a single type of aggregation
method, we use multiple types of aggregators to gather neighboring information
in different aspects and integrate the outputs of these aggregators through the
aggregator-level attention mechanism. Furthermore, we design a graph
regularized loss to better capture the topological relationship of the nodes in
the graph. Additionally, we first present the concept of graph feature
interaction and propose a vector-wise explicit feature interaction mechanism to
update the node embeddings. We conduct comprehensive experiments on two
node-classification benchmarks and a real-world financial news dataset. The
experiments demonstrate our GAIN model outperforms current state-of-the-art
performances on all the tasks.
</p>
<a href="http://arxiv.org/abs/2011.01393" target="_blank">arXiv:2011.01393</a> [<a href="http://arxiv.org/pdf/2011.01393" target="_blank">pdf</a>]

<h2>Guided Navigation from Multiple Viewpoints using Qualitative Spatial Reasoning. (arXiv:2011.01397v1 [cs.RO])</h2>
<h3>Danilo Perico, Paulo E. Santos, Reinaldo Bianchi</h3>
<p>Navigation is an essential ability for mobile agents to be completely
autonomous and able to perform complex actions. However, the problem of
navigation for agents with limited (or no) perception of the world, or devoid
of a fully defined motion model, has received little attention from research in
AI and Robotics. One way to tackle this problem is to use guided navigation, in
which other autonomous agents, endowed with perception, can combine their
distinct viewpoints to infer the localisation and the appropriate commands to
guide a sensory deprived agent through a particular path. Due to the limited
knowledge about the physical and perceptual characteristics of the guided
agent, this task should be conducted on a level of abstraction allowing the use
of a generic motion model, and high-level commands, that can be applied by any
type of autonomous agents, including humans. The main task considered in this
work is, given a group of autonomous agents perceiving their common environment
with their independent, egocentric and local vision sensors, the development
and evaluation of algorithms capable of producing a set of high-level commands
(involving qualitative directions: e.g. move left, go straight ahead) capable
of guiding a sensory deprived robot to a goal location.
</p>
<a href="http://arxiv.org/abs/2011.01397" target="_blank">arXiv:2011.01397</a> [<a href="http://arxiv.org/pdf/2011.01397" target="_blank">pdf</a>]

<h2>Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning. (arXiv:2011.01403v1 [cs.CL])</h2>
<h3>Beliz Gunel, Jingfei Du, Alexis Conneau, Ves Stoyanov</h3>
<p>State-of-the-art natural language understanding classification models follow
two-stages: pre-training a large language model on an auxiliary task, and then
fine-tuning the model on a task-specific labeled dataset using cross-entropy
loss. Cross-entropy loss has several shortcomings that can lead to sub-optimal
generalization and instability. Driven by the intuition that good
generalization requires capturing the similarity between examples in one class
and contrasting them with examples in other classes, we propose a supervised
contrastive learning (SCL) objective for the fine-tuning stage. Combined with
cross-entropy, the SCL loss we propose obtains improvements over a strong
RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in both the
high-data and low-data regimes, and it does not require any specialized
architecture, data augmentation of any kind, memory banks, or additional
unsupervised data. We also demonstrate that the new objective leads to models
that are more robust to different levels of noise in the training data, and can
generalize better to related tasks with limited labeled task data.
</p>
<a href="http://arxiv.org/abs/2011.01403" target="_blank">arXiv:2011.01403</a> [<a href="http://arxiv.org/pdf/2011.01403" target="_blank">pdf</a>]

<h2>Faraway-Frustum: Dealing with Lidar Sparsity for 3D Object Detection using Fusion. (arXiv:2011.01404v1 [cs.CV])</h2>
<h3>Haolin Zhang, Dongfang Yang, Ekim Yurtsever, Keith A. Redmill, &#xdc;mit &#xd6;zg&#xfc;ner</h3>
<p>Learned pointcloud representations do not generalize well with an increase in
distance to the sensor. For example, at a range greater than 60 meters, the
sparsity of lidar pointclouds reaches to a point where even humans cannot
discern object shapes from each other. However, this distance should not be
considered very far for fast-moving vehicles: A vehicle can traverse 60 meters
under two seconds while moving at 70 mph. For safe and robust driving
automation, acute 3D object detection at these ranges is indispensable. Against
this backdrop, we introduce faraway-frustum: a novel fusion strategy for
detecting faraway objects. The main strategy is to depend solely on the 2D
vision for recognizing object class, as object shape does not change
drastically with an increase in depth, and use pointcloud data for object
localization in the 3D space for faraway objects. For closer objects, we use
learned pointcloud representations instead, following state-of-the-art. This
strategy alleviates the main shortcoming of object detection with learned
pointcloud representations. Experiments on the KITTI dataset demonstrate that
our method outperforms state-of-the-art by a considerable margin for faraway
object detection in bird's-eye-view and 3D.
</p>
<a href="http://arxiv.org/abs/2011.01404" target="_blank">arXiv:2011.01404</a> [<a href="http://arxiv.org/pdf/2011.01404" target="_blank">pdf</a>]

<h2>BIGPrior: Towards Decoupling Learned Prior Hallucination and Data Fidelity in Image Restoration. (arXiv:2011.01406v1 [cs.CV])</h2>
<h3>Majed El Helou, Sabine S&#xfc;sstrunk</h3>
<p>Image restoration encompasses fundamental image processing tasks that have
been addressed with different algorithms and deep learning methods. Classical
restoration algorithms leverage a variety of priors, either implicitly or
explicitly. Their priors are hand-designed and their corresponding weights are
heuristically assigned. Thus, deep learning methods often produce superior
restoration quality. Deep networks are, however, capable of strong and
hardly-predictable hallucinations. Networks jointly and implicitly learn to be
faithful to the observed data while learning an image prior, and the separation
of original and hallucinated data downstream is then not possible. This limits
their wide-spread adoption in restoration applications. Furthermore, it is
often the hallucinated part that is victim to degradation-model overfitting. We
present an approach with decoupled network-prior hallucination and data
fidelity. We refer to our framework as the Bayesian Integration of a Generative
Prior (BIGPrior). Our BIGPrior method is rooted in a Bayesian restoration
framework, and tightly connected to classical restoration methods. In fact, our
approach can be viewed as a generalization of a large family of classical
restoration algorithms. We leverage a recent network inversion method to
extract image prior information from a generative network. We show on image
colorization, inpainting, and denoising that our framework consistently
improves the prior results through good integration of data fidelity. Our
method, though partly reliant on the quality of the generative network
inversion, is competitive with state-of-the-art supervised and task-specific
restoration methods. It also provides an additional metric that sets forth the
degree of prior reliance per pixel. Indeed, the per pixel contributions of the
decoupled data fidelity and prior terms are readily available in our proposed
framework.
</p>
<a href="http://arxiv.org/abs/2011.01406" target="_blank">arXiv:2011.01406</a> [<a href="http://arxiv.org/pdf/2011.01406" target="_blank">pdf</a>]

<h2>Sampling and Recovery of Graph Signals based on Graph Neural Networks. (arXiv:2011.01412v1 [cs.LG])</h2>
<h3>Siheng Chen, Maosen Li, Ya Zhang</h3>
<p>We propose interpretable graph neural networks for sampling and recovery of
graph signals, respectively. To take informative measurements, we propose a new
graph neural sampling module, which aims to select those vertices that
maximally express their corresponding neighborhoods. Such expressiveness can be
quantified by the mutual information between vertices' features and
neighborhoods' features, which are estimated via a graph neural network. To
reconstruct an original graph signal from the sampled measurements, we propose
a graph neural recovery module based on the algorithm-unrolling technique.
Compared to previous analytical sampling and recovery, the proposed methods are
able to flexibly learn a variety of graph signal models from data by leveraging
the learning ability of neural networks; compared to previous
neural-network-based sampling and recovery, the proposed methods are designed
through exploiting specific graph properties and provide interpretability. We
further design a new multiscale graph neural network, which is a trainable
multiscale graph filter bank and can handle various graph-related learning
tasks. The multiscale network leverages the proposed graph neural sampling and
recovery modules to achieve multiscale representations of a graph. In the
experiments, we illustrate the effects of the proposed graph neural sampling
and recovery modules and find that the modules can flexibly adapt to various
graph structures and graph signals. In the task of active-sampling-based
semi-supervised learning, the graph neural sampling module improves the
classification accuracy over 10% in Cora dataset. We further validate the
proposed multiscale graph neural network on several standard datasets for both
vertex and graph classification. The results show that our method consistently
improves the classification accuracies.
</p>
<a href="http://arxiv.org/abs/2011.01412" target="_blank">arXiv:2011.01412</a> [<a href="http://arxiv.org/pdf/2011.01412" target="_blank">pdf</a>]

<h2>Meta-learning Transferable Representations with a Single Target Domain. (arXiv:2011.01418v1 [cs.LG])</h2>
<h3>Hong Liu, Jeff Z. HaoChen, Colin Wei, Tengyu Ma</h3>
<p>Recent works found that fine-tuning and joint training---two popular
approaches for transfer learning---do not always improve accuracy on downstream
tasks. First, we aim to understand more about when and why fine-tuning and
joint training can be suboptimal or even harmful for transfer learning. We
design semi-synthetic datasets where the source task can be solved by either
source-specific features or transferable features. We observe that (1)
pre-training may not have incentive to learn transferable features and (2)
joint training may simultaneously learn source-specific features and overfit to
the target. Second, to improve over fine-tuning and joint training, we propose
Meta Representation Learning (MeRLin) to learn transferable features. MeRLin
meta-learns representations by ensuring that a head fit on top of the
representations with target training data also performs well on target
validation data. We also prove that MeRLin recovers the target ground-truth
model with a quadratic neural net parameterization and a source distribution
that contains both transferable and source-specific features. On the same
distribution, pre-training and joint training provably fail to learn
transferable features. MeRLin empirically outperforms previous state-of-the-art
transfer learning algorithms on various real-world vision and NLP transfer
learning benchmarks.
</p>
<a href="http://arxiv.org/abs/2011.01418" target="_blank">arXiv:2011.01418</a> [<a href="http://arxiv.org/pdf/2011.01418" target="_blank">pdf</a>]

<h2>WSL-DS: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization. (arXiv:2011.01421v1 [cs.CL])</h2>
<h3>Md Tahmid Rahman Laskar, Enamul Hoque, Jimmy Xiangji Huang</h3>
<p>In the Query Focused Multi-Document Summarization (QF-MDS) task, a set of
documents and a query are given where the goal is to generate a summary from
these documents based on the given query. However, one major challenge for this
task is the lack of availability of labeled training datasets. To overcome this
issue, in this paper, we propose a novel weakly supervised learning approach
via utilizing distant supervision. In particular, we use datasets similar to
the target dataset as the training data where we leverage pre-trained sentence
similarity models to generate the weak reference summary of each individual
document in a document set from the multi-document gold reference summaries.
Then, we iteratively train our summarization model on each single-document to
alleviate the computational complexity issue that occurs while training neural
summarization models in multiple documents (i.e., long sequences) at once.
Experimental results in Document Understanding Conferences (DUC) datasets show
that our proposed approach sets a new state-of-the-art result in terms of
various evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2011.01421" target="_blank">arXiv:2011.01421</a> [<a href="http://arxiv.org/pdf/2011.01421" target="_blank">pdf</a>]

<h2>GAGE: Geometry Preserving Attributed Graph Embeddings. (arXiv:2011.01422v1 [cs.SI])</h2>
<h3>Charilaos I. Kanatsoulis, Nicholas D. Sidiropoulos</h3>
<p>Node representation learning is the task of extracting concise and
informative feature embeddings of certain entities that are connected in a
network. Many real world network datasets include information about both node
connectivity and certain node attributes, in the form of features or
time-series data. Modern representation learning techniques utilize both
connectivity and attribute information of the nodes to produce embeddings in an
unsupervised manner. In this context, deriving embeddings that preserve the
geometry of the network and the attribute vectors would be highly desirable, as
they would reflect both the topological neighborhood structure and proximity in
feature space. While this is fairly straightforward to maintain when only
observing the connectivity or attributed information of the network, preserving
the geometry of both types of information is challenging. A novel tensor
factorization approach for node embedding in attributed networks that preserves
the distances of both the connections and the attributes is proposed in this
paper, along with an effective and lightweight algorithm to tackle the learning
task. Judicious experiments with multiple state-of-art baselines suggest that
the proposed algorithm offers significant performance improvements in node
classification and link prediction tasks.
</p>
<a href="http://arxiv.org/abs/2011.01422" target="_blank">arXiv:2011.01422</a> [<a href="http://arxiv.org/pdf/2011.01422" target="_blank">pdf</a>]

<h2>In Defense of Feature Mimicking for Knowledge Distillation. (arXiv:2011.01424v1 [cs.CV])</h2>
<h3>Guo-Hua Wang, Yifan Ge, Jianxin Wu</h3>
<p>Knowledge distillation (KD) is a popular method to train efficient networks
("student") with the help of high-capacity networks ("teacher"). Traditional
methods use the teacher's soft logit as extra supervision to train the student
network. In this paper, we argue that it is more advantageous to make the
student mimic the teacher's features in the penultimate layer. Not only the
student can directly learn more effective information from the teacher feature,
feature mimicking can also be applied for teachers trained without a softmax
layer. Experiments show that it can achieve higher accuracy than traditional
KD. To further facilitate feature mimicking, we decompose a feature vector into
the magnitude and the direction. We argue that the teacher should give more
freedom to the student feature's magnitude, and let the student pay more
attention on mimicking the feature direction. To meet this requirement, we
propose a loss term based on locality-sensitive hashing (LSH). With the help of
this new loss, our method indeed mimics feature directions more accurately,
relaxes constraints on feature magnitudes, and achieves state-of-the-art
distillation accuracy.
</p>
<a href="http://arxiv.org/abs/2011.01424" target="_blank">arXiv:2011.01424</a> [<a href="http://arxiv.org/pdf/2011.01424" target="_blank">pdf</a>]

<h2>Self-semi-supervised Learning to Learn from NoisyLabeled Data. (arXiv:2011.01429v1 [cs.LG])</h2>
<h3>Jiacheng Wang, Yue Ma, Shuang Gao</h3>
<p>The remarkable success of today's deep neural networks highly depends on a
massive number of correctly labeled data. However, it is rather costly to
obtain high-quality human-labeled data, leading to the active research area of
training models robust to noisy labels. To achieve this goal, on the one hand,
many papers have been dedicated to differentiating noisy labels from clean ones
to increase the generalization of DNN. On the other hand, the increasingly
prevalent methods of self-semi-supervised learning have been proven to benefit
the tasks when labels are incomplete. By 'semi' we regard the wrongly labeled
data detected as un-labeled data; by 'self' we choose a self-supervised
technique to conduct semi-supervised learning. In this project, we designed
methods to more accurately differentiate clean and noisy labels and borrowed
the wisdom of self-semi-supervised learning to train noisy labeled data.
</p>
<a href="http://arxiv.org/abs/2011.01429" target="_blank">arXiv:2011.01429</a> [<a href="http://arxiv.org/pdf/2011.01429" target="_blank">pdf</a>]

<h2>"You eat with your eyes first": Optimizing Yelp Image Advertising. (arXiv:2011.01434v1 [cs.CV])</h2>
<h3>Gaurab Banerjee, Samuel Spinner, Yasmine Mitchell</h3>
<p>A business's online, photographic representation can play a crucial role in
its success or failure. We use Yelp's image dataset and star-based review
system as a measurement of an image's effectiveness in promoting a business.
After preprocessing the Yelp dataset, we use transfer learning to train a
classifier which accepts Yelp images and predicts star-ratings. Additionally,
we then train a GAN to qualitatively investigate the common properties of
highly effective images. We achieve 90-98% accuracy in classifying simplified
star ratings for various image categories and observe that images containing
blue skies, open surroundings, and many windows are correlated with higher Yelp
reviews.
</p>
<a href="http://arxiv.org/abs/2011.01434" target="_blank">arXiv:2011.01434</a> [<a href="http://arxiv.org/pdf/2011.01434" target="_blank">pdf</a>]

<h2>Developing High Quality Training Samples for Deep Learning Based Local Climate Classification in Korea. (arXiv:2011.01436v1 [cs.CV])</h2>
<h3>Minho Kim, Doyoung Jeong, Hyoungwoo Choi, Yongil Kim</h3>
<p>Two out of three people will be living in urban areas by 2050, as projected
by the United Nations, emphasizing the need for sustainable urban development
and monitoring. Common urban footprint data provide high-resolution city
extents but lack essential information on the distribution, pattern, and
characteristics. The Local Climate Zone (LCZ) offers an efficient and
standardized framework that can delineate the internal structure and
characteristics of urban areas. Global-scale LCZ mapping has been explored, but
are limited by low accuracy, variable labeling quality, or domain adaptation
challenges. Instead, this study developed a custom LCZ data to map key Korean
cities using a multi-scale convolutional neural network. Results demonstrated
that using a novel, custom LCZ data with deep learning can generate more
accurate LCZ map results compared to conventional community-based LCZ mapping
with machine learning as well as transfer learning of the global So2Sat
dataset.
</p>
<a href="http://arxiv.org/abs/2011.01436" target="_blank">arXiv:2011.01436</a> [<a href="http://arxiv.org/pdf/2011.01436" target="_blank">pdf</a>]

<h2>Learning Deformable Tetrahedral Meshes for 3D Reconstruction. (arXiv:2011.01437v1 [cs.CV])</h2>
<h3>Jun Gao, Wenzheng Chen, Tommy Xiang, Alec Jacobson, Morgan McGuire, Sanja Fidler</h3>
<p>3D shape representations that accommodate learning-based 3D reconstruction
are an open problem in machine learning and computer graphics. Previous work on
neural 3D reconstruction demonstrated benefits, but also limitations, of point
cloud, voxel, surface mesh, and implicit function representations. We introduce
Deformable Tetrahedral Meshes (DefTet) as a particular parameterization that
utilizes volumetric tetrahedral meshes for the reconstruction problem. Unlike
existing volumetric approaches, DefTet optimizes for both vertex placement and
occupancy, and is differentiable with respect to standard 3D reconstruction
loss functions. It is thus simultaneously high-precision, volumetric, and
amenable to learning-based neural architectures. We show that it can represent
arbitrary, complex topology, is both memory and computationally efficient, and
can produce high-fidelity reconstructions with a significantly smaller grid
size than alternative volumetric approaches. The predicted surfaces are also
inherently defined as tetrahedral meshes, thus do not require post-processing.
We demonstrate that DefTet matches or exceeds both the quality of the previous
best approaches and the performance of the fastest ones. Our approach obtains
high-quality tetrahedral meshes computed directly from noisy point clouds, and
is the first to showcase high-quality 3D tet-mesh results using only a single
image as input.
</p>
<a href="http://arxiv.org/abs/2011.01437" target="_blank">arXiv:2011.01437</a> [<a href="http://arxiv.org/pdf/2011.01437" target="_blank">pdf</a>]

<h2>A Score-and-Search Approach to Learning Bayesian Networks with Noisy-OR Relations. (arXiv:2011.01444v1 [cs.LG])</h2>
<h3>Charupriya Sharma, Zhenyu A. Liao, James Cussens, Peter van Beek</h3>
<p>A Bayesian network is a probabilistic graphical model that consists of a
directed acyclic graph (DAG), where each node is a random variable and attached
to each node is a conditional probability distribution (CPD). A Bayesian
network can be learned from data using the well-known score-and-search
approach, and within this approach a key consideration is how to simultaneously
learn the global structure in the form of the underlying DAG and the local
structure in the CPDs. Several useful forms of local structure have been
identified in the literature but thus far the score-and-search approach has
only been extended to handle local structure in form of context-specific
independence. In this paper, we show how to extend the score-and-search
approach to the important and widely useful case of noisy-OR relations. We
provide an effective gradient descent algorithm to score a candidate noisy-OR
using the widely used BIC score and we provide pruning rules that allow the
search to successfully scale to medium sized networks. Our empirical results
provide evidence for the success of our approach to learning Bayesian networks
that incorporate noisy-OR relations.
</p>
<a href="http://arxiv.org/abs/2011.01444" target="_blank">arXiv:2011.01444</a> [<a href="http://arxiv.org/pdf/2011.01444" target="_blank">pdf</a>]

<h2>Random Walk Bandits. (arXiv:2011.01445v1 [cs.LG])</h2>
<h3>Tianyu Wang, Lin F. Yang, Zizhuo Wang</h3>
<p>Bandit learning problems find important applications ranging from medical
trials to online advertisement. In this paper, we study a novel bandit learning
problem motivated by recommender systems. The goal is to recommend items so
that users are likely to continue browsing. Our model views a user's browsing
record as a random walk over a graph of webpages. This random walk ends (hits
an absorbing node) when the user exits the website. Our model introduces a
novel learning problem that calls for new technical insights on learning with
graph random walk feedback. In particular, the performance and complexity
depend on the structure of the decision space (represented by graphs). Our
paper provides a comprehensive understanding of this new problem. We provide
bandit learning algorithms for this problem with provable performance
guarantees, and provide matching lower bounds.
</p>
<a href="http://arxiv.org/abs/2011.01445" target="_blank">arXiv:2011.01445</a> [<a href="http://arxiv.org/pdf/2011.01445" target="_blank">pdf</a>]

<h2>Meta-Learning for Natural Language Understanding under Continual Learning Framework. (arXiv:2011.01452v1 [cs.CL])</h2>
<h3>Jiacheng Wang, Yong Fan, Duo Jiang, Shiqing Li</h3>
<p>Neural network has been recognized with its accomplishments on tackling
various natural language understanding (NLU) tasks. Methods have been developed
to train a robust model to handle multiple tasks to gain a general
representation of text. In this paper, we implement the model-agnostic
meta-learning (MAML) and Online aware Meta-learning (OML) meta-objective under
the continual framework for NLU tasks. We validate our methods on selected
SuperGLUE and GLUE benchmark.
</p>
<a href="http://arxiv.org/abs/2011.01452" target="_blank">arXiv:2011.01452</a> [<a href="http://arxiv.org/pdf/2011.01452" target="_blank">pdf</a>]

<h2>Participation in TREC 2020 COVID Track Using Continuous Active Learning. (arXiv:2011.01453v1 [cs.IR])</h2>
<h3>Xue Jun Wang, Maura R. Grossman, Seung Gyu Hyun</h3>
<p>We describe our participation in all five rounds of the TREC 2020 COVID Track
(TREC-COVID). The goal of TREC-COVID is to contribute to the response to the
COVID-19 pandemic by identifying answers to many pressing questions and
building infrastructure to improve search systems [8]. All five rounds of this
Track challenged participants to perform a classic ad-hoc search task on the
new data collection CORD-19. Our solution addressed this challenge by applying
the Continuous Active Learning model (CAL) and its variations. Our results
showed us to be amongst the top scoring manual runs and we remained competitive
within all categories of submissions.
</p>
<a href="http://arxiv.org/abs/2011.01453" target="_blank">arXiv:2011.01453</a> [<a href="http://arxiv.org/pdf/2011.01453" target="_blank">pdf</a>]

<h2>Communication-Efficient Distributed Machine Learning over Strategic Networks: A Two-Layer Game Approach. (arXiv:2011.01455v1 [cs.GT])</h2>
<h3>Shutian Liu, Tao Li, Quanyan Zhu</h3>
<p>This paper considers a game-theoretic framework for distributed learning
problems over networks where communications between nodes are costly. In the
proposed game, players decide both the learning parameters and the network
structure for communications. The Nash equilibrium characterizes the tradeoff
between the local performance and the global agreement of the learned
classifiers. We introduce a two-layer algorithm to find the equilibrium. The
algorithm features a joint learning process that integrates the iterative
learning at each node and the network formation. We show that our game is
equivalent to a generalized potential game in the setting of symmetric
networks. We study the convergence of the proposed algorithm, analyze the
network structures determined by our game, and show the improvement of the
social welfare in comparison with the distributed learning over non-strategic
networks. In the case study, we deal with streaming data and use telemonitoring
of Parkinson's disease to corroborate the results.
</p>
<a href="http://arxiv.org/abs/2011.01455" target="_blank">arXiv:2011.01455</a> [<a href="http://arxiv.org/pdf/2011.01455" target="_blank">pdf</a>]

<h2>Frequency-compensated PINNs for Fluid-dynamic Design Problems. (arXiv:2011.01456v1 [cs.LG])</h2>
<h3>Tongtao Zhang, Biswadip Dey, Pratik Kakkar, Arindam Dasgupta, Amit Chakraborty</h3>
<p>Incompressible fluid flow around a cylinder is one of the classical problems
in fluid-dynamics with strong relevance with many real-world engineering
problems, for example, design of offshore structures or design of a pin-fin
heat exchanger. Thus learning a high-accuracy surrogate for this problem can
demonstrate the efficacy of a novel machine learning approach. In this work, we
propose a physics-informed neural network (PINN) architecture for learning the
relationship between simulation output and the underlying geometry and boundary
conditions. In addition to using a physics-based regularization term, the
proposed approach also exploits the underlying physics to learn a set of
Fourier features, i.e. frequency and phase offset parameters, and then use them
for predicting flow velocity and pressure over the spatio-temporal domain. We
demonstrate this approach by predicting simulation results over out of range
time interval and for novel design conditions. Our results show that
incorporation of Fourier features improves the generalization performance over
both temporal domain and design space.
</p>
<a href="http://arxiv.org/abs/2011.01456" target="_blank">arXiv:2011.01456</a> [<a href="http://arxiv.org/pdf/2011.01456" target="_blank">pdf</a>]

<h2>Blockchain based Attack Detection on Machine Learning Algorithms for IoT based E-Health Applications. (arXiv:2011.01457v1 [cs.CR])</h2>
<h3>Thippa Reddy Gadekallu, Manoj M K, Sivarama Krishnan S, Neeraj Kumar, Saqib Hakak, Sweta Bhattacharya</h3>
<p>The application of machine learning (ML) algorithms are massively scaling-up
due to rapid digitization and emergence of new tecnologies like Internet of
Things (IoT). In today's digital era, we can find ML algorithms being applied
in the areas of healthcare, IoT, engineering, finance and so on. However, all
these algorithms need to be trained in order to predict/solve a particular
problem. There is high possibility of tampering the training datasets and
produce biased results. Hence, in this article, we have proposed blockchain
based solution to secure the datasets generated from IoT devices for E-Health
applications. The proposed blockchain based solution uses using private cloud
to tackle the aforementioned issue. For evaluation, we have developed a system
that can be used by dataset owners to secure their data.
</p>
<a href="http://arxiv.org/abs/2011.01457" target="_blank">arXiv:2011.01457</a> [<a href="http://arxiv.org/pdf/2011.01457" target="_blank">pdf</a>]

<h2>Weakly- and Semi-supervised Evidence Extraction. (arXiv:2011.01459v1 [cs.CL])</h2>
<h3>Danish Pruthi, Bhuwan Dhingra, Graham Neubig, Zachary C. Lipton</h3>
<p>For many prediction tasks, stakeholders desire not only predictions but also
supporting evidence that a human can use to verify its correctness. However, in
practice, additional annotations marking supporting evidence may only be
available for a minority of training examples (if available at all). In this
paper, we propose new methods to combine few evidence annotations (strong
semi-supervision) with abundant document-level labels (weak supervision) for
the task of evidence extraction. Evaluating on two classification tasks that
feature evidence annotations, we find that our methods outperform baselines
adapted from the interpretability literature to our task. Our approach yields
substantial gains with as few as hundred evidence annotations. Code and
datasets to reproduce our work are available at
https://github.com/danishpruthi/evidence-extraction.
</p>
<a href="http://arxiv.org/abs/2011.01459" target="_blank">arXiv:2011.01459</a> [<a href="http://arxiv.org/pdf/2011.01459" target="_blank">pdf</a>]

<h2>Learning Effective Representations from Global and Local Features for Cross-View Gait Recognition. (arXiv:2011.01461v1 [cs.CV])</h2>
<h3>Beibei Lin, Shunli Zhang, Xin Yu, Zedong Chu, Haikun Zhang</h3>
<p>Gait recognition is one of the most important biometric technologies and has
been applied in many fields. Recent gait recognition frameworks represent each
human gait frame by descriptors extracted from either global appearances or
local regions of humans. However, the representations based on global
information often neglect the details of the gait frame, while local region
based descriptors cannot capture the relations among neighboring regions, thus
reducing their discriminativeness. In this paper, we propose a novel feature
extraction and fusion framework to achieve discriminative feature
representations for gait recognition. Towards this goal, we take advantage of
both global visual information and local region details and develop a Global
and Local Feature Extractor (GLFE). Specifically, our GLFE module is composed
of our newly designed multiple global and local convolutional layers (GLConv)
to ensemble global and local features in a principle manner. Furthermore, we
present a novel operation, namely Local Temporal Aggregation (LTA), to further
preserve the spatial information by reducing the temporal resolution to obtain
higher spatial resolution. With the help of our GLFE and LTA, our method
significantly improves the discriminativeness of our visual features, thus
improving the gait recognition performance. Extensive experiments demonstrate
that our proposed method outperforms state-of-the-art gait recognition methods
on popular widely-used CASIA-B and OUMVLP datasets.
</p>
<a href="http://arxiv.org/abs/2011.01461" target="_blank">arXiv:2011.01461</a> [<a href="http://arxiv.org/pdf/2011.01461" target="_blank">pdf</a>]

<h2>Distribution-aware Margin Calibration for Medical Image Segmentation. (arXiv:2011.01462v1 [cs.CV])</h2>
<h3>Zhibin Li, Litao Yu, Jian Zhang</h3>
<p>The Jaccard index, also known as Intersection-over-Union (IoU score), is one
of the most critical evaluation metrics in medical image segmentation. However,
directly optimizing the mean IoU (mIoU) score over multiple objective classes
is an open problem. Although some algorithms have been proposed to optimize its
surrogates, there is no guarantee provided for their generalization ability. In
this paper, we present a novel data-distribution-aware margin calibration
method for a better generalization of the mIoU over the whole
data-distribution, underpinned by a rigid lower bound. This scheme ensures a
better segmentation performance in terms of IoU scores in practice. We evaluate
the effectiveness of the proposed margin calibration method on two medical
image segmentation datasets, showing substantial improvements of IoU scores
over other learning schemes using deep segmentation models.
</p>
<a href="http://arxiv.org/abs/2011.01462" target="_blank">arXiv:2011.01462</a> [<a href="http://arxiv.org/pdf/2011.01462" target="_blank">pdf</a>]

<h2>Autoencoding Features for Aviation Machine Learning Problems. (arXiv:2011.01464v1 [cs.LG])</h2>
<h3>Liya Wang, Panta Lucic, Keith Campbell, Craig Wanke</h3>
<p>The current practice of manually processing features for high-dimensional and
heterogeneous aviation data is labor-intensive, does not scale well to new
problems, and is prone to information loss, affecting the effectiveness and
maintainability of machine learning (ML) procedures. This research explored an
unsupervised learning method, autoencoder, to extract effective features for
aviation machine learning problems. The study explored variants of autoencoders
with the aim of forcing the learned representations of the input to assume
useful properties. A flight track anomaly detection autoencoder was developed
to demonstrate the versatility of the technique. The research results show that
the autoencoder can not only automatically extract effective features for the
flight track data, but also efficiently deep clean data, thereby reducing the
workload of data scientists. Moreover, the research leveraged transfer learning
to efficiently train models for multiple airports. Transfer learning can reduce
model training times from days to hours, as well as improving model
performance. The developed applications and techniques are shared with the
whole aviation community to improve effectiveness of ongoing and future machine
learning studies.
</p>
<a href="http://arxiv.org/abs/2011.01464" target="_blank">arXiv:2011.01464</a> [<a href="http://arxiv.org/pdf/2011.01464" target="_blank">pdf</a>]

<h2>MACE: Model Agnostic Concept Extractor for Explaining Image Classification Networks. (arXiv:2011.01472v1 [cs.LG])</h2>
<h3>Ashish Kumar, Karan Sehgal, Prerna Garg, Vidhya Kamakshi, Narayanan C Krishnan</h3>
<p>Deep convolutional networks have been quite successful at various image
classification tasks. The current methods to explain the predictions of a
pre-trained model rely on gradient information, often resulting in saliency
maps that focus on the foreground object as a whole. However, humans typically
reason by dissecting an image and pointing out the presence of smaller
concepts. The final output is often an aggregation of the presence or absence
of these smaller concepts. In this work, we propose MACE: a Model Agnostic
Concept Extractor, which can explain the working of a convolutional network
through smaller concepts. The MACE framework dissects the feature maps
generated by a convolution network for an image to extract concept based
prototypical explanations. Further, it estimates the relevance of the extracted
concepts to the pre-trained model's predictions, a critical aspect required for
explaining the individual class predictions, missing in existing approaches. We
validate our framework using VGG16 and ResNet50 CNN architectures, and on
datasets like Animals With Attributes 2 (AWA2) and Places365. Our experiments
demonstrate that the concepts extracted by the MACE framework increase the
human interpretability of the explanations, and are faithful to the underlying
pre-trained black-box model.
</p>
<a href="http://arxiv.org/abs/2011.01472" target="_blank">arXiv:2011.01472</a> [<a href="http://arxiv.org/pdf/2011.01472" target="_blank">pdf</a>]

<h2>A Framework for Prediction and Storage of Battery Life in IoT Devices using DNN and Blockchain. (arXiv:2011.01473v1 [cs.CR])</h2>
<h3>Siva Rama Krishnan Somayaji, Mamoun Alazab, Manoj MK, Antonio Bucchiarone, Chiranji Lal Chowdhary, Thippa Reddy Gadekallu</h3>
<p>As digitization increases, the need to automate various entities becomes
crucial for development. The data generated by the IoT devices need to be
processed accurately and in a secure manner. The basis for the success of such
a scenario requires blockchain as a means of unalterable data storage to
improve the overall security and trust in the system. By providing trust in an
automated system, with real-time data updates to all stakeholders, an improved
form of implementation takes the stage and can help reduce the stress of
adaptability to complete automated systems. This research focuses on a use case
with respect to the real time Internet of Things (IoT) network which is
deployed at the beach of Chicago Park District. This real time data which is
collected from various sensors is then used to design a predictive model using
Deep Neural Networks for estimating the battery life of IoT sensors that is
deployed at the beach. This proposed model could help the government to plan
for placing orders of replaceable batteries before time so that there can be an
uninterrupted service. Since this data is sensitive and requires to be secured,
the predicted battery life value is stored in blockchain which would be a
tamper-proof record of the data.
</p>
<a href="http://arxiv.org/abs/2011.01473" target="_blank">arXiv:2011.01473</a> [<a href="http://arxiv.org/pdf/2011.01473" target="_blank">pdf</a>]

<h2>Kernel Two-Dimensional Ridge Regression for Subspace Clustering. (arXiv:2011.01477v1 [cs.CV])</h2>
<h3>Chong Peng, Qian Zhang, Zhao Kang, Chenglizhao Chen, Qiang Cheng</h3>
<p>Subspace clustering methods have been widely studied recently. When the
inputs are 2-dimensional (2D) data, existing subspace clustering methods
usually convert them into vectors, which severely damages inherent structures
and relationships from original data. In this paper, we propose a novel
subspace clustering method for 2D data. It directly uses 2D data as inputs such
that the learning of representations benefits from inherent structures and
relationships of the data. It simultaneously seeks image projection and
representation coefficients such that they mutually enhance each other and lead
to powerful data representations. An efficient algorithm is developed to solve
the proposed objective function with provable decreasing and convergence
property. Extensive experimental results verify the effectiveness of the new
method.
</p>
<a href="http://arxiv.org/abs/2011.01477" target="_blank">arXiv:2011.01477</a> [<a href="http://arxiv.org/pdf/2011.01477" target="_blank">pdf</a>]

<h2>Layer-Wise Multi-View Learning for Neural Machine Translation. (arXiv:2011.01482v1 [cs.CL])</h2>
<h3>Qiang Wang, Changliang Li, Yue Zhang, Tong Xiao, Jingbo Zhu</h3>
<p>Traditional neural machine translation is limited to the topmost encoder
layer's context representation and cannot directly perceive the lower encoder
layers. Existing solutions usually rely on the adjustment of network
architecture, making the calculation more complicated or introducing additional
structural restrictions. In this work, we propose layer-wise multi-view
learning to solve this problem, circumventing the necessity to change the model
structure. We regard each encoder layer's off-the-shelf output, a by-product in
layer-by-layer encoding, as the redundant view for the input sentence. In this
way, in addition to the topmost encoder layer (referred to as the primary
view), we also incorporate an intermediate encoder layer as the auxiliary view.
We feed the two views to a partially shared decoder to maintain independent
prediction. Consistency regularization based on KL divergence is used to
encourage the two views to learn from each other. Extensive experimental
results on five translation tasks show that our approach yields stable
improvements over multiple strong baselines. As another bonus, our method is
agnostic to network architectures and can maintain the same inference speed as
the original model.
</p>
<a href="http://arxiv.org/abs/2011.01482" target="_blank">arXiv:2011.01482</a> [<a href="http://arxiv.org/pdf/2011.01482" target="_blank">pdf</a>]

<h2>Multi-armed Bandits with Cost Subsidy. (arXiv:2011.01488v1 [cs.LG])</h2>
<h3>Deeksha Sinha, Karthik Abinav Sankararama, Abbas Kazerouni, Vashist Avadhanula</h3>
<p>In this paper, we consider a novel variant of the multi-armed bandit (MAB)
problem, \emph{MAB with cost subsidy}, which models many real-life applications
where the learning agent has to pay to select an arm and is concerned about
optimizing cumulative costs and rewards. We present two applications,
\emph{intelligent SMS routing problem} and \emph{ad audience optimization
problem} faced by a number of businesses (especially online platforms) and show
how our problem uniquely captures key features of these applications. We show
that naive generalizations of existing MAB algorithms like Upper Confidence
Bound and Thompson Sampling do not perform well for this problem. We then
establish fundamental lower bound of $\Omega(K^{1/3} T^{2/3})$ on the
performance of any online learning algorithm for this problem, highlighting the
hardness of our problem in comparison to the classical MAB problem (where $T$
is the time horizon and $K$ is the number of arms). We also present a simple
variant of \textit{explore-then-commit} and establish near-optimal regret
bounds for this algorithm. Lastly, we perform extensive numerical simulations
to understand the behavior of a suite of algorithms for various instances and
recommend a practical guide to employ different algorithms.
</p>
<a href="http://arxiv.org/abs/2011.01488" target="_blank">arXiv:2011.01488</a> [<a href="http://arxiv.org/pdf/2011.01488" target="_blank">pdf</a>]

<h2>Wheat Crop Yield Prediction Using Deep LSTM Model. (arXiv:2011.01498v1 [cs.CV])</h2>
<h3>Sagarika Sharma, Sujit Rai, Narayanan C. Krishnan</h3>
<p>An in-season early crop yield forecast before harvest can benefit the farmers
to improve the production and enable various agencies to devise plans
accordingly. We introduce a reliable and inexpensive method to predict crop
yields from publicly available satellite imagery. The proposed method works
directly on raw satellite imagery without the need to extract any hand-crafted
features or perform dimensionality reduction on the images. The approach
implicitly models the relevance of the different steps in the growing season
and the various bands in the satellite imagery. We evaluate the proposed
approach on tehsil (block) level wheat predictions across several states in
India and demonstrate that it outperforms existing methods by over 50\%. We
also show that incorporating additional contextual information such as the
location of farmlands, water bodies, and urban areas helps in improving the
yield estimates.
</p>
<a href="http://arxiv.org/abs/2011.01498" target="_blank">arXiv:2011.01498</a> [<a href="http://arxiv.org/pdf/2011.01498" target="_blank">pdf</a>]

<h2>VEGA: Towards an End-to-End Configurable AutoML Pipeline. (arXiv:2011.01507v1 [cs.CV])</h2>
<h3>Bochao Wang, Hang Xu, Jiajin Zhang, Chen Chen, Xiaozhi Fang, Ning Kang, Lanqing Hong, Wei Zhang, Yong Li, Zhicheng Liu, Zhenguo Li, Weizhi Liu, Tong Zhang</h3>
<p>Automated Machine Learning (AutoML) is an important industrial solution for
automatic discovery and deployment of the machine learning models. However,
designing an integrated AutoML system faces four great challenges of
configurability, scalability, integrability, and platform diversity. In this
work, we present VEGA, an efficient and comprehensive AutoML framework that is
compatible and optimized for multiple hardware platforms. a) The VEGA pipeline
integrates various modules of AutoML, including Neural Architecture Search
(NAS), Hyperparameter Optimization (HPO), Auto Data Augmentation, Model
Compression, and Fully Train. b) To support a variety of search algorithms and
tasks, we design a novel fine-grained search space and its description language
to enable easy adaptation to different search algorithms and tasks. c) We
abstract the common components of deep learning frameworks into a unified
interface. VEGA can be executed with multiple back-ends and hardwares.
Extensive benchmark experiments on multiple tasks demonstrate that VEGA can
improve the existing AutoML algorithms and discover new high-performance models
against SOTA methods, e.g. the searched DNet model zoo for Ascend 10x faster
than EfficientNet-B5 and 9.2x faster than RegNetX-32GF on ImageNet. VEGA is
open-sourced at https://github.com/huawei-noah/vega.
</p>
<a href="http://arxiv.org/abs/2011.01507" target="_blank">arXiv:2011.01507</a> [<a href="http://arxiv.org/pdf/2011.01507" target="_blank">pdf</a>]

<h2>MalFox: Camouflaged Adversarial Malware Example Generation Based on C-GANs Against Black-Box Detectors. (arXiv:2011.01509v1 [cs.CR])</h2>
<h3>Fangtian Zhong, Xiuzhen Cheng, Dongxiao Yu, Bei Gong, Shuaiwen Song, Jiguo Yu</h3>
<p>Deep learning is a thriving field currently stuffed with many practical
applications and active research topics. It allows computers to learn from
experience and to understand the world in terms of a hierarchy of concepts,
with each being defined through its relations to simpler concepts. Relying on
the strong learning capabilities of deep learning, we propose a convolutional
generative adversarial network-based (C-GAN) framework titled MalFox, targeting
adversarial malware example generation against third-party black-box detectors.
MalFox adopts a novel approach to confrontationally produce perturbation paths,
with each formed by up to three methods (namely Obfusmal, Stealmal, and
Hollowmal) to generate adversarial malware examples via changing the process of
program execution in our implementation. To demonstrate the effectiveness of
MalFox, we collect a large dataset consisting of both malware and benignware,
and investigate the performance of MalFox in terms of accuracy, detection rate,
and evasive rate of the generated adversarial malware examples. Our evaluation
indicates that the accuracy can be as high as 99.01% which significantly
outperforms the other 6 well-known learning models. Furthermore, the detection
rate is dramatically decreased by 44.3% on average, and the average evasive
rate is noticeably improved by up to 55.3%.
</p>
<a href="http://arxiv.org/abs/2011.01509" target="_blank">arXiv:2011.01509</a> [<a href="http://arxiv.org/pdf/2011.01509" target="_blank">pdf</a>]

<h2>Embedding Node Structural Role Identity into Hyperbolic Space. (arXiv:2011.01512v1 [cs.SI])</h2>
<h3>Lili Wang, Ying Lu, Chenghan Huang, Soroush Vosoughi</h3>
<p>Recently, there has been an interest in embedding networks in hyperbolic
space, since hyperbolic space has been shown to work well in capturing
graph/network structure as it can naturally reflect some properties of complex
networks. However, the work on network embedding in hyperbolic space has been
focused on microscopic node embedding. In this work, we are the first to
present a framework to embed the structural roles of nodes into hyperbolic
space. Our framework extends struct2vec, a well-known structural role
preserving embedding method, by moving it to a hyperboloid model. We evaluated
our method on four real-world and one synthetic network. Our results show that
hyperbolic space is more effective than euclidean space in learning latent
representations for the structural role of nodes.
</p>
<a href="http://arxiv.org/abs/2011.01512" target="_blank">arXiv:2011.01512</a> [<a href="http://arxiv.org/pdf/2011.01512" target="_blank">pdf</a>]

<h2>CharBERT: Character-aware Pre-trained Language Model. (arXiv:2011.01513v1 [cs.CL])</h2>
<h3>Wentao Ma, Yiming Cui, Chenglei Si, Ting Liu, Shijin Wang, Guoping Hu</h3>
<p>Most pre-trained language models (PLMs) construct word representations at
subword level with Byte-Pair Encoding (BPE) or its variations, by which OOV
(out-of-vocab) words are almost avoidable. However, those methods split a word
into subword units and make the representation incomplete and fragile. In this
paper, we propose a character-aware pre-trained language model named CharBERT
improving on the previous methods (such as BERT, RoBERTa) to tackle these
problems. We first construct the contextual word embedding for each token from
the sequential character representations, then fuse the representations of
characters and the subword representations by a novel heterogeneous interaction
module. We also propose a new pre-training task named NLM (Noisy LM) for
unsupervised character representation learning. We evaluate our method on
question answering, sequence labeling, and text classification tasks, both on
the original datasets and adversarial misspelling test sets. The experimental
results show that our method can significantly improve the performance and
robustness of PLMs simultaneously. Pretrained models, evaluation sets, and code
are available at https://github.com/wtma/CharBERT
</p>
<a href="http://arxiv.org/abs/2011.01513" target="_blank">arXiv:2011.01513</a> [<a href="http://arxiv.org/pdf/2011.01513" target="_blank">pdf</a>]

<h2>You Do (Not) Belong Here: Detecting DPI Evasion Attacks with Context Learning. (arXiv:2011.01514v1 [cs.CR])</h2>
<h3>Shitong Zhu, Shasha Li, Zhongjie Wang, Xun Chen, Zhiyun Qian, Srikanth V. Krishnamurthy, Kevin S. Chan, Ananthram Swami</h3>
<p>As Deep Packet Inspection (DPI) middleboxes become increasingly popular, a
spectrum of adversarial attacks have emerged with the goal of evading such
middleboxes. Many of these attacks exploit discrepancies between the middlebox
network protocol implementations, and the more rigorous/complete versions
implemented at end hosts. These evasion attacks largely involve subtle
manipulations of packets to cause different behaviours at DPI and end hosts, to
cloak malicious network traffic that is otherwise detectable. With recent
automated discovery, it has become prohibitively challenging to manually curate
rules for detecting these manipulations. In this work, we propose CLAP, the
first fully-automated, unsupervised ML solution to accurately detect and
localize DPI evasion attacks. By learning what we call the packet context,
which essentially captures inter-relationships across both (1) different
packets in a connection; and (2) different header fields within each packet,
from benign traffic traces only, CLAP can detect and pinpoint packets that
violate the benign packet contexts (which are the ones that are specially
crafted for evasion purposes). Our evaluations with 73 state-of-the-art DPI
evasion attacks show that CLAP achieves an Area Under the Receiver Operating
Characteristic Curve (AUC-ROC) of 0.963, an Equal Error Rate (EER) of only
0.061 in detection, and an accuracy of 94.6% in localization. These results
suggest that CLAP can be a promising tool for thwarting DPI evasion attacks.
</p>
<a href="http://arxiv.org/abs/2011.01514" target="_blank">arXiv:2011.01514</a> [<a href="http://arxiv.org/pdf/2011.01514" target="_blank">pdf</a>]

<h2>Model of Trust Management for Digital Industry Services. Towards E-Commerce 4.0. (arXiv:2011.01523v1 [cs.SI])</h2>
<h3>Wolfgang Bauer (1), Natalia Kryvinska (1), J&#xfc;rgen Dorn (2) ((1) Comenius University in Bratislava, Information Systems Department (2) Technical University in Vienna, Institute for Information Systems Engineering)</h3>
<p>The progressive digitalization is changing the way businesses work and
interact. Concepts like Internet of Things, Cloud Computing, Industry 4.0,
Service 4.0, Smart Production or Smart Cities are based on systems that are
linked to the Internet. The online access to the provided data creates
potential to optimize processes and cost reductions, but also exposes it to a
risk for an inappropriate use. Trust management systems are necessary in terms
of data security, but also to assure the trustworthiness of data that is
distributed. Fake news in social media is an example for problems with online
data that is not trustable. Security and trustworthiness of data are major
concerns today. The speed in digitalization makes it even a greater challenge
for future research. This article introduces therefore a model of online trust
content usable to compute the trust of an online service advertisement. It
contributes to standardize business service descriptions necessary to realize
visions of E-commerce 4.0, because it is the basis for the development of AI
systems that are able to match an service request to a service advertisement.
It is necessary for building trust enhancing architectures in B2B e-commerce.
To do so, we conducted case studies, analysed websites, developed a prototype
system and verified it by conducting expert interviews.
</p>
<a href="http://arxiv.org/abs/2011.01523" target="_blank">arXiv:2011.01523</a> [<a href="http://arxiv.org/pdf/2011.01523" target="_blank">pdf</a>]

<h2>TransQuest: Translation Quality Estimation with Cross-lingual Transformers. (arXiv:2011.01536v1 [cs.CL])</h2>
<h3>Tharindu Ranasinghe, Constantin Orasan, Ruslan Mitkov</h3>
<p>Recent years have seen big advances in the field of sentence-level quality
estimation (QE), largely as a result of using neural-based architectures.
However, the majority of these methods work only on the language pair they are
trained on and need retraining for new language pairs. This process can prove
difficult from a technical point of view and is usually computationally
expensive. In this paper we propose a simple QE framework based on
cross-lingual transformers, and we use it to implement and evaluate two
different neural architectures. Our evaluation shows that the proposed methods
achieve state-of-the-art results outperforming current open-source quality
estimation frameworks when trained on datasets from WMT. In addition, the
framework proves very useful in transfer learning settings, especially when
dealing with low-resourced languages, allowing us to obtain very competitive
results.
</p>
<a href="http://arxiv.org/abs/2011.01536" target="_blank">arXiv:2011.01536</a> [<a href="http://arxiv.org/pdf/2011.01536" target="_blank">pdf</a>]

<h2>Penetrating RF Fingerprinting-based Authentication with a Generative Adversarial Attack. (arXiv:2011.01538v1 [cs.CR])</h2>
<h3>Samurdhi Karunaratne, Enes Krijestorac, Danijela Cabric</h3>
<p>Physical layer authentication relies on detecting unique imperfections in
signals transmitted by radio devices to isolate their fingerprint. Recently,
deep learning-based authenticators have increasingly been proposed to classify
devices using these fingerprints, as they achieve higher accuracies compared to
traditional approaches. However, it has been shown in other domains that adding
carefully crafted perturbations to legitimate inputs can fool such classifiers.
This can undermine the security provided by the authenticator. Unlike
adversarial attacks applied in other domains, an adversary has no control over
the propagation environment. Therefore, to investigate the severity of this
type of attack in wireless communications, we consider an unauthorized
transmitter attempting to have its signals classified as authorized by a deep
learning-based authenticator. We demonstrate a reinforcement learning-based
attack where the impersonator--using only the authenticator's binary
authentication decision--distorts its signals in order to penetrate the system.
Extensive simulations and experiments on a software-defined radio testbed
indicate that at appropriate channel conditions and bounded by a maximum
distortion level, it is possible to fool the authenticator reliably at more
than 90% success rate.
</p>
<a href="http://arxiv.org/abs/2011.01538" target="_blank">arXiv:2011.01538</a> [<a href="http://arxiv.org/pdf/2011.01538" target="_blank">pdf</a>]

<h2>Recent Advances in Understanding Adversarial Robustness of Deep Neural Networks. (arXiv:2011.01539v1 [cs.LG])</h2>
<h3>Tao Bai, Jinqi Luo, Jun Zhao</h3>
<p>Adversarial examples are inevitable on the road of pervasive applications of
deep neural networks (DNN). Imperceptible perturbations applied on natural
samples can lead DNN-based classifiers to output wrong prediction with fair
confidence score. It is increasingly important to obtain models with high
robustness that are resistant to adversarial examples. In this paper, we survey
recent advances in how to understand such intriguing property, i.e. adversarial
robustness, from different perspectives. We give preliminary definitions on
what adversarial attacks and robustness are. After that, we study
frequently-used benchmarks and mention theoretically-proved bounds for
adversarial robustness. We then provide an overview on analyzing correlations
among adversarial robustness and other critical indicators of DNN models.
Lastly, we introduce recent arguments on potential costs of adversarial
training which have attracted wide attention from the research community.
</p>
<a href="http://arxiv.org/abs/2011.01539" target="_blank">arXiv:2011.01539</a> [<a href="http://arxiv.org/pdf/2011.01539" target="_blank">pdf</a>]

<h2>DAGA: Data Augmentation with a Generation Approach for Low-resource Tagging Tasks. (arXiv:2011.01549v1 [cs.CL])</h2>
<h3>Bosheng Ding, Linlin Liu, Lidong Bing, Canasai Kruengkrai, Thien Hai Nguyen, Shafiq Joty, Luo Si, Chunyan Miao</h3>
<p>Data augmentation techniques have been widely used to improve machine
learning performance as they enhance the generalization capability of models.
In this work, to generate high quality synthetic data for low-resource tagging
tasks, we propose a novel augmentation method with language models trained on
the linearized labeled sentences. Our method is applicable to both supervised
and semi-supervised settings. For the supervised settings, we conduct extensive
experiments on named entity recognition (NER), part of speech (POS) tagging and
end-to-end target based sentiment analysis (E2E-TBSA) tasks. For the
semi-supervised settings, we evaluate our method on the NER task under the
conditions of given unlabeled data only and unlabeled data plus a knowledge
base. The results show that our method can consistently outperform the
baselines, particularly when the given gold training data are less.
</p>
<a href="http://arxiv.org/abs/2011.01549" target="_blank">arXiv:2011.01549</a> [<a href="http://arxiv.org/pdf/2011.01549" target="_blank">pdf</a>]

<h2>Episodic Linear Quadratic Regulators with Low-rank Transitions. (arXiv:2011.01568v1 [cs.LG])</h2>
<h3>Tianyu Wang, Lin F. Yang</h3>
<p>Linear Quadratic Regulators (LQR) achieve enormous successful real-world
applications. Very recently, people have been focusing on efficient learning
algorithms for LQRs when their dynamics are unknown. Existing results
effectively learn to control the unknown system using number of episodes
depending polynomially on the system parameters, including the ambient
dimension of the states. These traditional approaches, however, become
inefficient in common scenarios, e.g., when the states are high-resolution
images. In this paper, we propose an algorithm that utilizes the intrinsic
system low-rank structure for efficient learning. For problems of rank-$m$, our
algorithm achieves a $K$-episode regret bound of order $\widetilde{O}(m^{3/2}
K^{1/2})$. Consequently, the sample complexity of our algorithm only depends on
the rank, $m$, rather than the ambient dimension, $d$, which can be
orders-of-magnitude larger.
</p>
<a href="http://arxiv.org/abs/2011.01568" target="_blank">arXiv:2011.01568</a> [<a href="http://arxiv.org/pdf/2011.01568" target="_blank">pdf</a>]

<h2>Dynamic latency speech recognition with asynchronous revision. (arXiv:2011.01570v1 [eess.AS])</h2>
<h3>Mingkun Huang, Meng Cai, Jun Zhang, Yang Zhang, Yongbin You, Yi He, Zejun Ma</h3>
<p>In this work we propose an inference technique, asynchronous revision, to
unify streaming and non-streaming speech recognition models. Specifically, we
achieve dynamic latency with only one model by using arbitrary right context
during inference. The model is composed of a stack of convolutional layers for
audio encoding. In inference stage, the history states of encoder and decoder
can be asynchronously revised to trade off between the latency and the accuracy
of the model. To alleviate training and inference mismatch, we propose a
training technique, segment cropping, which randomly splits input utterances
into several segments with forward connections. This allows us to have dynamic
latency speech recognition results with large improvements in accuracy.
Experiments show that our dynamic latency model with asynchronous revision
gives 8\%-14\% relative improvements over the streaming models.
</p>
<a href="http://arxiv.org/abs/2011.01570" target="_blank">arXiv:2011.01570</a> [<a href="http://arxiv.org/pdf/2011.01570" target="_blank">pdf</a>]

<h2>Incorporating User-Comment Graph for Fake News Detection. (arXiv:2011.01579v1 [cs.SI])</h2>
<h3>Hao Liao, Qixin Liu, Kai Shu, Xing xie</h3>
<p>Disinformation has long been regarded as a severe social problem, where fake
news is one of the most representative issues. What is worse, today's highly
developed social media makes fake news widely spread at incredible speed,
bringing in substantial harm to various aspects of human life. Yet, the
popularity of social media also provides opportunities to better detect fake
news. Unlike conventional means which merely focus on either content or user
comments, effective collaboration of heterogeneous social media information,
including content and context factors of news, users' comments and the
engagement of social media with users, will hopefully give rise to better
detection of fake news.

Motivated by the above observations, a novel detection framework, namely
graph comment-user advanced learning framework (GCAL) is proposed in this
paper. User-comment information is crucial but not well studied in fake news
detection. Thus, we model user-comment context through network representation
learning based on heterogeneous graph neural network. We conduct experiments on
two real-world datasets, which demonstrate that the proposed joint model
outperforms 8 state-of-the-art baseline methods for fake news detection (at
least 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method
is also explainable.
</p>
<a href="http://arxiv.org/abs/2011.01579" target="_blank">arXiv:2011.01579</a> [<a href="http://arxiv.org/pdf/2011.01579" target="_blank">pdf</a>]

<h2>CMT in TREC-COVID Round 2: Mitigating the Generalization Gaps from Web to Special Domain Search. (arXiv:2011.01580v1 [cs.IR])</h2>
<h3>Chenyan Xiong, Zhenghao Liu, Si Sun, Zhuyun Dai, Kaitao Zhang, Shi Yu, Zhiyuan Liu, Hoifung Poon, Jianfeng Gao, Paul Bennett</h3>
<p>Neural rankers based on deep pretrained language models (LMs) have been shown
to improve many information retrieval benchmarks. However, these methods are
affected by their the correlation between pretraining domain and target domain
and rely on massive fine-tuning relevance labels. Directly applying pretraining
methods to specific domains may result in suboptimal search quality because
specific domains may have domain adaption problems, such as the COVID domain.
This paper presents a search system to alleviate the special domain adaption
problem. The system utilizes the domain-adaptive pretraining and few-shot
learning technologies to help neural rankers mitigate the domain discrepancy
and label scarcity problems. Besides, we also integrate dense retrieval to
alleviate traditional sparse retrieval's vocabulary mismatch obstacle. Our
system performs the best among the non-manual runs in Round 2 of the TREC-COVID
task, which aims to retrieve useful information from scientific literature
related to COVID-19. Our code is publicly available at
https://github.com/thunlp/OpenMatch.
</p>
<a href="http://arxiv.org/abs/2011.01580" target="_blank">arXiv:2011.01580</a> [<a href="http://arxiv.org/pdf/2011.01580" target="_blank">pdf</a>]

<h2>Estimating decision tree learnability with polylogarithmic sample complexity. (arXiv:2011.01584v1 [cs.LG])</h2>
<h3>Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan</h3>
<p>We show that top-down decision tree learning heuristics are amenable to
highly efficient learnability estimation: for monotone target functions, the
error of the decision tree hypothesis constructed by these heuristics can be
estimated with polylogarithmically many labeled examples, exponentially smaller
than the number necessary to run these heuristics, and indeed, exponentially
smaller than information-theoretic minimum required to learn a good decision
tree. This adds to a small but growing list of fundamental learning algorithms
that have been shown to be amenable to learnability estimation.

En route to this result, we design and analyze sample-efficient minibatch
versions of top-down decision tree learning heuristics and show that they
achieve the same provable guarantees as the full-batch versions. We further
give "active local" versions of these heuristics: given a test point $x^\star$,
we show how the label $T(x^\star)$ of the decision tree hypothesis $T$ can be
computed with polylogarithmically many labeled examples, exponentially smaller
than the number necessary to learn $T$.
</p>
<a href="http://arxiv.org/abs/2011.01584" target="_blank">arXiv:2011.01584</a> [<a href="http://arxiv.org/pdf/2011.01584" target="_blank">pdf</a>]

<h2>Turning Software Engineers into AI Engineers. (arXiv:2011.01590v1 [cs.SE])</h2>
<h3>Petra Heck, Gerard Schouten</h3>
<p>In industry as well as education as well as academics we see a growing need
for knowledge on how to apply machine learning in software applications. With
the educational programme ICT &amp; AI at Fontys UAS we had to find an answer to
the question: "How should we educate software engineers to become AI
engineers?" This paper describes our educational programme, the open source
tools we use, and the literature it is based on. After three years of
experience, we present our lessons learned for both educational institutions
and software engineers in practice.
</p>
<a href="http://arxiv.org/abs/2011.01590" target="_blank">arXiv:2011.01590</a> [<a href="http://arxiv.org/pdf/2011.01590" target="_blank">pdf</a>]

<h2>Experiencers, Stimuli, or Targets: Which Semantic Roles Enable Machine Learning to Infer the Emotions?. (arXiv:2011.01599v1 [cs.CL])</h2>
<h3>Laura Oberl&#xe4;nder, Kevin Reich, Roman Klinger</h3>
<p>Emotion recognition is predominantly formulated as text classification in
which textual units are assigned to an emotion from a predefined inventory
(e.g., fear, joy, anger, disgust, sadness, surprise, trust, anticipation). More
recently, semantic role labeling approaches have been developed to extract
structures from the text to answer questions like: "who is described to feel
the emotion?" (experiencer), "what causes this emotion?" (stimulus), and at
which entity is it directed?" (target). Though it has been shown that jointly
modeling stimulus and emotion category prediction is beneficial for both
subtasks, it remains unclear which of these semantic roles enables a classifier
to infer the emotion. Is it the experiencer, because the identity of a person
is biased towards a particular emotion (X is always happy)? Is it a particular
target (everybody loves X) or a stimulus (doing X makes everybody sad)? We
answer these questions by training emotion classification models on five
available datasets annotated with at least one semantic role by masking the
fillers of these roles in the text in a controlled manner and find that across
multiple corpora, stimuli and targets carry emotion information, while the
experiencer might be considered a confounder. Further, we analyze if informing
the model about the position of the role improves the classification decision.
Particularly on literature corpora we find that the role information improves
the emotion classification.
</p>
<a href="http://arxiv.org/abs/2011.01599" target="_blank">arXiv:2011.01599</a> [<a href="http://arxiv.org/pdf/2011.01599" target="_blank">pdf</a>]

<h2>A Deep Temporal Fusion Framework for Scene Flow Using a Learnable Motion Model and Occlusions. (arXiv:2011.01603v1 [cs.CV])</h2>
<h3>Ren&#xe9; Schuster, Christian Unger, Didier Stricker</h3>
<p>Motion estimation is one of the core challenges in computer vision. With
traditional dual-frame approaches, occlusions and out-of-view motions are a
limiting factor, especially in the context of environmental perception for
vehicles due to the large (ego-) motion of objects. Our work proposes a novel
data-driven approach for temporal fusion of scene flow estimates in a
multi-frame setup to overcome the issue of occlusion. Contrary to most previous
methods, we do not rely on a constant motion model, but instead learn a generic
temporal relation of motion from data. In a second step, a neural network
combines bi-directional scene flow estimates from a common reference frame,
yielding a refined estimate and a natural byproduct of occlusion masks. This
way, our approach provides a fast multi-frame extension for a variety of scene
flow estimators, which outperforms the underlying dual-frame approaches.
</p>
<a href="http://arxiv.org/abs/2011.01603" target="_blank">arXiv:2011.01603</a> [<a href="http://arxiv.org/pdf/2011.01603" target="_blank">pdf</a>]

<h2>Towards Conceptual Modeling Semantics: Eventizing Tarski's Truth Schema. (arXiv:2011.01608v1 [cs.SE])</h2>
<h3>Sabah Al-Fedaghi</h3>
<p>Modeling languages in software engineering (e.g., UML) evolved from software
systems modeling where denotational and operational kinds of semantics are the
traditional subjects of research and practice. According to some authors,
although a large portion of the static semantics (e.g., UML) seems to have
reached a consensus, the dynamic semantics of activities, interactions, and
state machines poses a major challenge. Central to semantics is the
relationship between a sentence and the (actual) world. Carefully examining
semantics-related issues in the modeling languages field to avoid problems that
may affect practical applicability is important. One effort in this direction
is OMG s release of a 2020 draft specification for Foundational UML (fUML),
with the base semantics specifying executions that are executable in the same
sense as a program in a traditional programming language. Additionally, efforts
within academia have sought to develop an alternative approach to modeling
languages using formal semantics (e.g., using Russell s theory of types and
Tarski s declarative semantics). This paper aims at a similar exploratory
venture of developing semantics, only for a much more modest diagrammatic
modeling language, called the thinging machine model. The model promotes a deep
understanding of the scrutinized modeling language and leads to considerably
fruitful questions. Constructing the thinging machine model seems to facilitate
progress in this direction, and the initial results in this paper indicate the
viability of the approach.
</p>
<a href="http://arxiv.org/abs/2011.01608" target="_blank">arXiv:2011.01608</a> [<a href="http://arxiv.org/pdf/2011.01608" target="_blank">pdf</a>]

<h2>Generalized Wasserstein Dice Score, Distributionally Robust Deep Learning, and Ranger for brain tumor segmentation: BraTS 2020 challenge. (arXiv:2011.01614v1 [eess.IV])</h2>
<h3>Lucas Fidon, Sebastien Ourselin, Tom Vercauteren</h3>
<p>Training a deep neural network is an optimization problem with four main
ingredients: the design of the deep neural network, the per-sample loss
function, the population loss function, and the optimizer. However, methods
developed to compete in recent BraTS challenges tend to focus only on the
design of deep neural network architectures, while paying less attention to the
three other aspects. In this paper, we experimented with adopting the opposite
approach. We stuck to a generic and state-of-the-art 3D U-Net architecture and
experimented with a non-standard per-sample loss function, the generalized
Wasserstein Dice loss, a non-standard population loss function, corresponding
to distributionally robust optimization, and a non-standard optimizer, Ranger.
Those variations were selected specifically for the problem of multi-class
brain tumor segmentation. The generalized Wasserstein Dice loss is a per-sample
loss function that allows taking advantage of the hierarchical structure of the
tumor regions labeled in BraTS. Distributionally robust optimization is a
generalization of empirical risk minimization that accounts for the presence of
underrepresented subdomains in the training dataset. Ranger is a generalization
of the widely used Adam optimizer that is more stable with small batch size and
noisy labels. We found that each of those variations of the optimization of
deep neural networks for brain tumor segmentation leads to improvements in
terms of Dice scores and Hausdorff distances. With an ensemble of three deep
neural networks trained with various optimization procedures, we achieved
promising results on the validation dataset of the BraTS 2020 challenge. Our
ensemble ranked fourth out of the 693 registered teams for the segmentation
task of the BraTS 2020 challenge.
</p>
<a href="http://arxiv.org/abs/2011.01614" target="_blank">arXiv:2011.01614</a> [<a href="http://arxiv.org/pdf/2011.01614" target="_blank">pdf</a>]

<h2>Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery. (arXiv:2011.01619v1 [cs.CV])</h2>
<h3>Yong-Hao Long, Jie-Ying Wu, Bo Lu, Yue-Ming Jin, Mathias Unberath, Yun-Hui Liu, Pheng-Ann Heng, Qi Dou</h3>
<p>Automatic surgical gesture recognition is fundamentally important to enable
intelligent cognitive assistance in robotic surgery. With recent advancement in
robot-assisted minimally invasive surgery, rich information including surgical
videos and robotic kinematics can be recorded, which provide complementary
knowledge for understanding surgical gestures. However, existing methods either
solely adopt uni-modal data or directly concatenate multi-modal
representations, which can not sufficiently exploit the informative
correlations inherent in visual and kinematics data to boost gesture
recognition accuracies. In this regard, we propose a novel approach of
multimodal relational graph network (i.e., MRG-Net) to dynamically integrate
visual and kinematics information through interactive message propagation in
the latent feature space. In specific, we first extract embeddings from video
and kinematics sequences with temporal convolutional networks and LSTM units.
Next, we identify multi-relations in these multi-modal features and model them
through a hierarchical relational graph learning module. The effectiveness of
our method is demonstrated with state-of-the-art results on the public JIGSAWS
dataset, outperforming current uni-modal and multi-modal methods on both
suturing and knot typing tasks. Furthermore, we validated our method on
in-house visual-kinematics datasets collected with da Vinci Research Kit (dVRK)
platforms in two centers, with consistent promising performance achieved.
</p>
<a href="http://arxiv.org/abs/2011.01619" target="_blank">arXiv:2011.01619</a> [<a href="http://arxiv.org/pdf/2011.01619" target="_blank">pdf</a>]

<h2>Learning on Attribute-Missing Graphs. (arXiv:2011.01623v1 [cs.LG])</h2>
<h3>Xu Chen, Siheng Chen, Jiangchao Yao, Huangjie Zheng, Ya Zhang, Ivor W Tsang</h3>
<p>Graphs with complete node attributes have been widely explored recently.
While in practice, there is a graph where attributes of only partial nodes
could be available and those of the others might be entirely missing. This
attribute-missing graph is related to numerous real-world applications and
there are limited studies investigating the corresponding learning problems.
Existing graph learning methods including the popular GNN cannot provide
satisfied learning performance since they are not specified for
attribute-missing graphs. Thereby, designing a new GNN for these graphs is a
burning issue to the graph learning community. In this paper, we make a
shared-latent space assumption on graphs and develop a novel distribution
matching based GNN called structure-attribute transformer (SAT) for
attribute-missing graphs. SAT leverages structures and attributes in a
decoupled scheme and achieves the joint distribution modeling of structures and
attributes by distribution matching techniques. It could not only perform the
link prediction task but also the newly introduced node attribute completion
task. Furthermore, practical measures are introduced to quantify the
performance of node attribute completion. Extensive experiments on seven
real-world datasets indicate SAT shows better performance than other methods on
both link prediction and node attribute completion tasks. Codes and data are
available online: https://github.com/xuChenSJTU/SAT-master-online
</p>
<a href="http://arxiv.org/abs/2011.01623" target="_blank">arXiv:2011.01623</a> [<a href="http://arxiv.org/pdf/2011.01623" target="_blank">pdf</a>]

<h2>Results of a Single Blind Literary Taste Test with Short Anonymized Novel Fragments. (arXiv:2011.01624v1 [cs.CL])</h2>
<h3>Andreas van Cranenburgh, Corina Koolen</h3>
<p>It is an open question to what extent perceptions of literary quality are
derived from text-intrinsic versus social factors. While supervised models can
predict literary quality ratings from textual factors quite successfully, as
shown in the Riddle of Literary Quality project (Koolen et al., 2020), this
does not prove that social factors are not important, nor can we assume that
readers make judgments on literary quality in the same way and based on the
same information as machine learning models. We report the results of a pilot
study to gauge the effect of textual features on literary ratings of
Dutch-language novels by participants in a controlled experiment with 48
participants. In an exploratory analysis, we compare the ratings to those from
the large reader survey of the Riddle in which social factors were not
excluded, and to machine learning predictions of those literary ratings. We
find moderate to strong correlations of questionnaire ratings with the survey
ratings, but the predictions are closer to the survey ratings. Code and data:
https://github.com/andreasvc/litquest
</p>
<a href="http://arxiv.org/abs/2011.01624" target="_blank">arXiv:2011.01624</a> [<a href="http://arxiv.org/pdf/2011.01624" target="_blank">pdf</a>]

<h2>Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models. (arXiv:2011.01625v1 [cs.AI])</h2>
<h3>Tom Heskes, Evi Sijben, Ioan Gabriel Bucur, Tom Claassen</h3>
<p>Shapley values underlie one of the most popular model-agnostic methods within
explainable artificial intelligence. These values are designed to attribute the
difference between a model's prediction and an average baseline to the
different features used as input to the model. Being based on solid
game-theoretic principles, Shapley values uniquely satisfy several desirable
properties, which is why they are increasingly used to explain the predictions
of possibly complex and highly non-linear machine learning models. Shapley
values are well calibrated to a user's intuition when features are independent,
but may lead to undesirable, counterintuitive explanations when the
independence assumption is violated.

In this paper, we propose a novel framework for computing Shapley values that
generalizes recent work that aims to circumvent the independence assumption. By
employing Pearl's do-calculus, we show how these 'causal' Shapley values can be
derived for general causal graphs without sacrificing any of their desirable
properties. Moreover, causal Shapley values enable us to separate the
contribution of direct and indirect effects. We provide a practical
implementation for computing causal Shapley values based on causal chain graphs
when only partial information is available and illustrate their utility on a
real-world example.
</p>
<a href="http://arxiv.org/abs/2011.01625" target="_blank">arXiv:2011.01625</a> [<a href="http://arxiv.org/pdf/2011.01625" target="_blank">pdf</a>]

<h2>PCEDNet : A Neural Network for Fast and Efficient Edge Detection in 3D Point Clouds. (arXiv:2011.01630v1 [cs.GR])</h2>
<h3>Himeur Chems-Eddine, Lejemble Thibault, Pellegrini Thomas, Paulin Mathias, Barthe Loic, Mellado Nicolas</h3>
<p>In recent years, Convolutional Neural Networks (CNN) have proven to be
efficient analysis tools for processing point clouds, e.g., for reconstruction,
segmentation and classification. In this paper, we focus on the classification
of edges in point clouds, where both edges and their surrounding are described.
We propose a new parameterization adding to each point a set of differential
information on its surrounding shape reconstructed at different scales. These
parameters, stored in a Scale-Space Matrix (SSM), provide a well suited
information from which an adequate neural network can learn the description of
edges and use it to efficiently detect them in acquired point clouds. After
successfully applying a multi-scale CNN on SSMs for the efficient
classification of edges and their neighborhood, we propose a new neural network
architecture outperforming the CNN in learning time, processing time and
classification capabilities. Our architecture is compact, requires small
learning sets, is very fast to train and classifies millions of points in
seconds.
</p>
<a href="http://arxiv.org/abs/2011.01630" target="_blank">arXiv:2011.01630</a> [<a href="http://arxiv.org/pdf/2011.01630" target="_blank">pdf</a>]

<h2>Robust Latent Representations via Cross-Modal Translation and Alignment. (arXiv:2011.01631v1 [cs.LG])</h2>
<h3>Vandana Rajan, Alessio Brutti, Andrea Cavallaro</h3>
<p>Multi-modal learning relates information across observation modalities of the
same physical phenomenon to leverage complementary information. Most
multi-modal machine learning methods require that all the modalities used for
training are also available for testing. This is a limitation when the signals
from some modalities are unavailable or are severely degraded by noise. To
address this limitation, we aim to improve the testing performance of uni-modal
systems using multiple modalities during training only. The proposed
multi-modal training framework uses cross-modal translation and
correlation-based latent space alignment to improve the representations of the
weaker modalities. The translation from the weaker to the stronger modality
generates a multi-modal intermediate encoding that is representative of both
modalities. This encoding is then correlated with the stronger modality
representations in a shared latent space. We validate the proposed approach on
the AVEC 2016 dataset for continuous emotion recognition and show the
effectiveness of the approach that achieves state-of-the-art (uni-modal)
performance for weaker modalities.
</p>
<a href="http://arxiv.org/abs/2011.01631" target="_blank">arXiv:2011.01631</a> [<a href="http://arxiv.org/pdf/2011.01631" target="_blank">pdf</a>]

<h2>Vision-Based Control for Robots by a Fully Spiking Neural System Relying on Cerebellar Predictive Learning. (arXiv:2011.01641v1 [cs.RO])</h2>
<h3>Omar Zahra, David Navarro-Alarcon, Silvia Tolu</h3>
<p>The cerebellum plays a distinctive role within our motor control system to
achieve fine and coordinated motions. While cerebellar lesions do not lead to a
complete loss of motor functions, both action and perception are severally
impacted. Hence, it is assumed that the cerebellum uses an internal forward
model to provide anticipatory signals by learning from the error in sensory
states. In some studies, it was demonstrated that the learning process relies
on the joint-space error. However, this may not exist. This work proposes a
novel fully spiking neural system that relies on a forward predictive learning
by means of a cellular cerebellar model. The forward model is learnt thanks to
the sensory feedback in task-space and it acts as a Smith predictor. The latter
predicts sensory corrections in input to a differential mapping spiking neural
network during a visual servoing task of a robot arm manipulator. In this
paper, we promote the developed control system to achieve more accurate target
reaching actions and reduce the motion execution time for the robotic reaching
tasks thanks to the cerebellar predictive capabilities.
</p>
<a href="http://arxiv.org/abs/2011.01641" target="_blank">arXiv:2011.01641</a> [<a href="http://arxiv.org/pdf/2011.01641" target="_blank">pdf</a>]

<h2>Automated simulation and verification of process models discovered by process mining. (arXiv:2011.01646v1 [cs.AI])</h2>
<h3>Ivona Zakarija, Frano &#x160;kopljanac-Ma&#x10d;ina, Bruno Bla&#x161;kovi&#x107;</h3>
<p>This paper presents a novel approach for automated analysis of process models
discovered using process mining techniques. Process mining explores underlying
processes hidden in the event data generated by various devices. Our proposed
Inductive machine learning method was used to build business process models
based on actual event log data obtained from a hotel's Property Management
System (PMS). The PMS can be considered as a Multi Agent System (MAS) because
it is integrated with a variety of external systems and IoT devices. Collected
event log combines data on guests stay recorded by hotel staff, as well as data
streams captured from telephone exchange and other external IoT devices. Next,
we performed automated analysis of the discovered process models using formal
methods. Spin model checker was used to simulate process model executions and
automatically verify the process model. We proposed an algorithm for the
automatic transformation of the discovered process model into a verification
model. Additionally, we developed a generator of positive and negative
examples. In the verification stage, we have also used Linear temporal logic
(LTL) to define requested system specifications. We find that the analysis
results will be well suited for process model repair.
</p>
<a href="http://arxiv.org/abs/2011.01646" target="_blank">arXiv:2011.01646</a> [<a href="http://arxiv.org/pdf/2011.01646" target="_blank">pdf</a>]

<h2>Uncertainty Quantification of Darcy Flow through Porous Media using Deep Gaussian Process. (arXiv:2011.01647v1 [stat.ML])</h2>
<h3>A. Daneshkhah, M. Mousavi Nezhad, O. Chatrabgoun, M. Esmaeilbeigi, T. Sedighi, S. Abolfathi</h3>
<p>A computational method based on the non-linear Gaussian process (GP), known
as deep Gaussian processes (deep GPs) for uncertainty quantification &amp;
propagation in modelling of flow through heterogeneous porous media is
presented. The method is also used for reducing dimensionality of model output
and consequently emulating highly complex relationship between hydrogeological
properties and reduced order fluid velocity field in a tractable manner. Deep
GPs are multi-layer hierarchical generalisations of GPs with multiple,
infinitely wide hidden layers that are very efficient models for deep learning
and modelling of high-dimensional complex systems by tackling the complexity
through several hidden layers connected with non-linear mappings. According to
this approach, the hydrogeological data is modelled as the output of a
multivariate GP whose inputs are governed by another GP such that each single
layer is either a standard GP or the Gaussian process latent variable model. A
variational approximation framework is used so that the posterior distribution
of the model outputs associated to given inputs can be analytically
approximated. In contrast to the other dimensionality reduction, methods that
do not provide any information about the dimensionality of each hidden layer,
the proposed method automatically selects the dimensionality of each hidden
layer and it can be used to propagate uncertainty obtained in each layer across
the hierarchy. Using this, dimensionality of the full input space consists of
both geometrical parameters of modelling domain and stochastic hydrogeological
parameters can be simultaneously reduced without the need for any
simplifications generally being assumed for stochastic modelling of subsurface
flow problems. It allows estimation of the flow statistics with greatly reduced
computational efforts compared to other stochastic approaches such as Monte
Carlo method.
</p>
<a href="http://arxiv.org/abs/2011.01647" target="_blank">arXiv:2011.01647</a> [<a href="http://arxiv.org/pdf/2011.01647" target="_blank">pdf</a>]

<h2>Multicollinearity Correction and Combined Feature Effect in Shapley Values. (arXiv:2011.01661v1 [stat.ML])</h2>
<h3>Indranil Basu, Subhadip Maji</h3>
<p>Model interpretability is one of the most intriguing problems in most of the
Machine Learning models, particularly for those that are mathematically
sophisticated. Computing Shapley Values are arguably the best approach so far
to find the importance of each feature in a model, at the row level. In other
words, Shapley values represent the importance of a feature for a particular
row, especially for Classification or Regression problems. One of the biggest
limitations of Shapley vales is that, Shapley value calculations assume all the
features are uncorrelated (independent of each other), this assumption is often
incorrect. To address this problem, we present a unified framework to calculate
Shapley values with correlated features. To be more specific, we do an
adjustment (Matrix formulation) of the features while calculating Independent
Shapley values for the rows. Moreover, we have given a Mathematical proof
against the said adjustments. With these adjustments, Shapley values
(Importance) for the features become independent of the correlations existing
between them. We have also enhanced this adjustment concept for more than
features. As the Shapley values are additive, to calculate combined effect of
two features, we just have to add their individual Shapley values. This is
again not right if one or more of the features (used in the combination) are
correlated with the other features (not in the combination). We have addressed
this problem also by extending the correlation adjustment for one feature to
multiple features in the said combination for which Shapley values are
determined. Our implementation of this method proves that our method is
computationally efficient also, compared to original Shapley method.
</p>
<a href="http://arxiv.org/abs/2011.01661" target="_blank">arXiv:2011.01661</a> [<a href="http://arxiv.org/pdf/2011.01661" target="_blank">pdf</a>]

<h2>Learning Causal Semantic Representation for Out-of-Distribution Prediction. (arXiv:2011.01681v1 [stat.ML])</h2>
<h3>Chang Liu, Xinwei Sun, Jindong Wang, Tao Li, Tao Qin, Wei Chen, Tie-Yan Liu</h3>
<p>Conventional supervised learning methods, especially deep ones, are found to
be sensitive to out-of-distribution (OOD) examples, largely because the learned
representation mixes the semantic factor with the variation factor due to their
domain-specific correlation, while only the semantic factor causes the output.
To address the problem, we propose a Causal Semantic Generative model (CSG)
based on causality to model the two factors separately, and learn it on a
single training domain for prediction without (OOD generalization) or with
(domain adaptation) unsupervised data in a test domain. We prove that CSG
identifies the semantic factor on the training domain, and the invariance
principle of causality subsequently guarantees the boundedness of OOD
generalization error and the success of adaptation. We design learning methods
for both effective learning and easy prediction, by leveraging the graphical
structure of CSG. Empirical study demonstrates the effect of our methods to
improve test accuracy for OOD generalization and domain adaptation.
</p>
<a href="http://arxiv.org/abs/2011.01681" target="_blank">arXiv:2011.01681</a> [<a href="http://arxiv.org/pdf/2011.01681" target="_blank">pdf</a>]

<h2>Improved unsupervised physics-informed deep learning for intravoxel-incoherent motion modeling and evaluation in pancreatic cancer patients. (arXiv:2011.01689v1 [physics.med-ph])</h2>
<h3>Misha P.T. Kaandorp, Sebastiano Barbieri, Remy Klaassen, Hanneke W.M. van Laarhoven, Hans Crezee, Peter T. While, Aart J. Nederveen, Oliver J. Gurney-Champion</h3>
<p>${\bf Purpose}$: Earlier work showed that IVIM-NET$_{orig}$, an unsupervised
physics-informed deep neural network, was faster and more accurate than other
state-of-the-art intravoxel-incoherent motion (IVIM) fitting approaches to DWI.
This study presents: IVIM-NET$_{optim}$, overcoming IVIM-NET$_{orig}$'s
shortcomings. ${\bf Method}$: In simulations (SNR=20), the accuracy,
independence and consistency of IVIM-NET were evaluated for combinations of
hyperparameters (fit S0, constraints, network architecture, # hidden layers,
dropout, batch normalization, learning rate), by calculating the NRMSE,
Spearman's $\rho$, and the coefficient of variation (CV$_{NET}$), respectively.
The best performing network, IVIM-NET$_{optim}$ was compared to least squares
(LS) and a Bayesian approach at different SNRs. IVIM-NET$_{optim}$'s
performance was evaluated in 23 pancreatic ductal adenocarcinoma (PDAC)
patients. 14 of the patients received no treatment between 2 repeated scan
sessions and 9 received chemoradiotherapy between sessions. Intersession
within-subject standard deviations (wSD) and treatment-induced changes were
assessed. ${\bf Results}$: In simulations, IVIM-NET$_{optim}$ outperformed
IVIM-NET$_{orig}$ in accuracy (NRMSE(D)=0.14 vs 0.17; NMRSE(f)=0.26 vs 0.31;
NMRSE(D*)=0.46 vs 0.49), independence ($\rho$(D*,f)=0.32 vs 0.95) and
consistency (CV$_{NET}$ (D)=0.028 vs 0.185; CV$_{NET}$ (f)=0.025 vs 0.078;
CV$_{NET}$ (D*)=0.075 vs 0.144). IVIM-NET$_{optim}$ showed superior performance
to the LS and Bayesian approaches at SNRs&lt;50. In vivo, IVIM-NET$_{optim}$
showed less noisy and more detailed parameter maps with lower wSD for D and f
than the alternatives. In the treated cohort, IVIM-NET$_{optim}$ detected the
most individual patients with significant parameter changes compared to
day-to-day variations. ${\bf Conclusion}$: IVIM-NET$_{optim}$ is recommended
for accurate IVIM fitting to DWI data.
</p>
<a href="http://arxiv.org/abs/2011.01689" target="_blank">arXiv:2011.01689</a> [<a href="http://arxiv.org/pdf/2011.01689" target="_blank">pdf</a>]

<h2>Uncertainty Quantification in Extreme Learning Machine: Analytical Developments, Variance Estimates and Confidence Intervals. (arXiv:2011.01704v1 [stat.ML])</h2>
<h3>Fabian Guignard, Federico Amato, Mikhail Kanevski</h3>
<p>Uncertainty quantification is crucial to assess prediction quality of a
machine learning model. In the case of Extreme Learning Machines (ELM), most
methods proposed in the literature make strong assumptions on the data, ignore
the randomness of input weights or neglect the bias contribution in confidence
interval estimations. This paper presents novel estimations that overcome these
constraints and improve the understanding of ELM variability. Analytical
derivations are provided under general assumptions, supporting the
identification and the interpretation of the contribution of different
variability sources. Under both homoskedasticity and heteroskedasticity,
several variance estimates are proposed, investigated, and numerically tested,
showing their effectiveness in replicating the expected variance behaviours.
Finally, the feasibility of confidence intervals estimation is discussed by
adopting a critical approach, hence raising the awareness of ELM users
concerning some of their pitfalls. The paper is accompanied with a scikit-learn
compatible Python library enabling efficient computation of all estimates
discussed herein.
</p>
<a href="http://arxiv.org/abs/2011.01704" target="_blank">arXiv:2011.01704</a> [<a href="http://arxiv.org/pdf/2011.01704" target="_blank">pdf</a>]

<h2>Amortized Variational Deep Q Network. (arXiv:2011.01706v1 [cs.LG])</h2>
<h3>Haotian Zhang, Yuhao Wang, Jianyong Sun, Zongben Xu</h3>
<p>Efficient exploration is one of the most important issues in deep
reinforcement learning. To address this issue, recent methods consider the
value function parameters as random variables, and resort variational inference
to approximate the posterior of the parameters. In this paper, we propose an
amortized variational inference framework to approximate the posterior
distribution of the action value function in Deep Q Network. We establish the
equivalence between the loss of the new model and the amortized variational
inference loss. We realize the balance of exploration and exploitation by
assuming the posterior as Cauchy and Gaussian, respectively in a two-stage
training process. We show that the amortized framework can results in
significant less learning parameters than existing state-of-the-art method.
Experimental results on classical control tasks in OpenAI Gym and chain Markov
Decision Process tasks show that the proposed method performs significantly
better than state-of-art methods and requires much less training time.
</p>
<a href="http://arxiv.org/abs/2011.01706" target="_blank">arXiv:2011.01706</a> [<a href="http://arxiv.org/pdf/2011.01706" target="_blank">pdf</a>]

<h2>Small footprint Text-Independent Speaker Verification for Embedded Systems. (arXiv:2011.01709v1 [cs.SD])</h2>
<h3>Julien Balian, Raffaele Tavarone, Mathieu Poumeyrol, Alice Coucke</h3>
<p>Deep neural network approaches to speaker verification have proven
successful, but typical computational requirements of State-Of-The-Art (SOTA)
systems make them unsuited for embedded applications. In this work, we present
a two-stage model architecture orders of magnitude smaller than common
solutions (237.5K learning parameters, 11.5MFLOPS) reaching a competitive
result of 3.31% Equal Error Rate (EER) on the well established VoxCeleb1
verification test set. We demonstrate the possibility of running our solution
on small devices typical of IoT systems such as the Raspberry Pi 3B with a
latency smaller than 200ms on a 5s long utterance. Additionally, we evaluate
our model on the acoustically challenging VOiCES corpus. We report a limited
increase in EER of 2.6 percentage points with respect to the best scoring model
of the 2019 VOiCES from a Distance Challenge, against a reduction of 25.6 times
in the number of learning parameters.
</p>
<a href="http://arxiv.org/abs/2011.01709" target="_blank">arXiv:2011.01709</a> [<a href="http://arxiv.org/pdf/2011.01709" target="_blank">pdf</a>]

<h2>Brain Predictability toolbox: a Python library for neuroimaging based machine learning. (arXiv:2011.01715v1 [cs.LG])</h2>
<h3>Sage Hahn, Dekang Yuan, Wesley Thompson, Max M Owens, Nicholas Allgaier, Hugh Garavan</h3>
<p>Summary Brain Predictability toolbox (BPt) represents a unified framework of
machine learning (ML) tools designed to work with both tabulated data (in
particular brain, psychiatric, behavioral, and physiological variables) and
neuroimaging specific derived data (e.g., brain volumes and surfaces). This
package is suitable for investigating a wide range of different neuroimaging
based ML questions, in particular, those queried from large human datasets.

Availability and Implementation BPt has been developed as an open-source
Python 3.6+ package hosted at https://github.com/sahahn/BPt under MIT License,
with documentation provided at https://bpt.readthedocs.io/en/latest/, and
continues to be actively developed. The project can be downloaded through the
github link provided. A web GUI interface based on the same code is currently
under development and can be set up through docker with instructions at
https://github.com/sahahn/BPt_app.

Contact Please contact Sage Hahn at sahahn@uvm.edu
</p>
<a href="http://arxiv.org/abs/2011.01715" target="_blank">arXiv:2011.01715</a> [<a href="http://arxiv.org/pdf/2011.01715" target="_blank">pdf</a>]

<h2>Recommendations for Bayesian hierarchical model specifications for case-control studies in mental health. (arXiv:2011.01725v1 [cs.CY])</h2>
<h3>Vincent Valton, Toby Wise, Oliver J. Robinson</h3>
<p>Hierarchical model fitting has become commonplace for case-control studies of
cognition and behaviour in mental health. However, these techniques require us
to formalise assumptions about the data-generating process at the group level,
which may not be known. Specifically, researchers typically must choose whether
to assume all subjects are drawn from a common population, or to model them as
deriving from separate populations. These assumptions have profound
implications for computational psychiatry, as they affect the resulting
inference (latent parameter recovery) and may conflate or mask true group-level
differences. To test these assumptions we ran systematic simulations on
synthetic multi-group behavioural data from a commonly used multi-armed bandit
task (reinforcement learning task). We then examined recovery of group
differences in latent parameter space under the two commonly used generative
modelling assumptions: (1) modelling groups under a common shared group-level
prior (assuming all participants are generated from a common distribution, and
are likely to share common characteristics); (2) modelling separate groups
based on symptomatology or diagnostic labels, resulting in separate group-level
priors. We evaluated the robustness of these approaches to variations in data
quality and prior specifications on a variety of metrics. We found that fitting
groups separately (assumptions 2), provided the most accurate and robust
inference across all conditions. Our results suggest that when dealing with
data from multiple clinical groups, researchers should analyse patient and
control groups separately as it provides the most accurate and robust recovery
of the parameters of interest.
</p>
<a href="http://arxiv.org/abs/2011.01725" target="_blank">arXiv:2011.01725</a> [<a href="http://arxiv.org/pdf/2011.01725" target="_blank">pdf</a>]

<h2>Exploring DeshuffleGANs in Self-Supervised Generative Adversarial Networks. (arXiv:2011.01730v1 [cs.CV])</h2>
<h3>Gulcin Baykal, Furkan Ozcelik, Gozde Unal</h3>
<p>Generative Adversarial Networks (GANs) have become the most used network
models towards solving the problem of image generation. In recent years,
self-supervised GANs are proposed to aid stabilized GAN training without the
catastrophic forgetting problem and to improve the image generation quality
without the need for the class labels of the data. However, the
generalizability of the self-supervision tasks on different GAN architectures
is not studied before. To that end, we extensively analyze the contribution of
the deshuffling task of DeshuffleGANs in the generalizability context. We
assign the deshuffling task to two different GAN discriminators and study the
effects of the deshuffling on both architectures. We also evaluate the
performance of DeshuffleGANs on various datasets that are mostly used in GAN
benchmarks: LSUN-Bedroom, LSUN-Church, and CelebA-HQ. We show that the
DeshuffleGAN obtains the best FID results for LSUN datasets compared to the
other self-supervised GANs. Furthermore, we compare the deshuffling with the
rotation prediction that is firstly deployed to the GAN training and
demonstrate that its contribution exceeds the rotation prediction. Lastly, we
show the contribution of the self-supervision tasks to the GAN training on loss
landscape and present that the effects of the self-supervision tasks may not be
cooperative to the adversarial training in some settings. Our code can be found
at https://github.com/gulcinbaykal/DeshuffleGAN.
</p>
<a href="http://arxiv.org/abs/2011.01730" target="_blank">arXiv:2011.01730</a> [<a href="http://arxiv.org/pdf/2011.01730" target="_blank">pdf</a>]

<h2>RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms. (arXiv:2011.01731v1 [cs.IR])</h2>
<h3>Wayne Xin Zhao, Shanlei Mu, Yupeng Hou, Zihan Lin, Kaiyuan Li, Yushuo Chen, Yujie Lu, Hui Wang, Changxin Tian, Xingyu Pan, Yingqian Min, Zhichao Feng, Xinyan Fan, Xu Chen, Pengfei Wang, Wendi Ji, Yaliang Li, Xiaoling Wang, Ji-Rong Wen</h3>
<p>In recent years, there are a large number of recommendation algorithms
proposed in the literature, from traditional collaborative filtering to neural
network algorithms. However, the concerns about how to standardize open source
implementation of recommendation algorithms continually increase in the
research community.

In the light of this challenge, we propose a unified, comprehensive and
efficient recommender system library called RecBole, which provides a unified
framework to develop and reproduce recommender systems for research purpose. In
this library, we implement 53 recommendation models on 27 benchmark datasets,
covering the categories of general recommendation, sequential recommendation,
context-aware recommendation and knowledge-based recommendation. We implement
the RecBole library based on PyTorch, which is one of the most popular deep
learning frameworks. Our library is featured in many aspects, including general
and extensible data structures, comprehensive benchmark models and datasets,
efficient GPU-accelerated execution, and extensive and standard evaluation
protocols. We provide a series of auxiliary functions, tools, and scripts to
facilitate the use of this library, such as automatic parameter tuning and
break-point resume. Such a framework is useful to standardize the
implementation and evaluation of recommender systems. The project and documents
are released at https://recbole.io.
</p>
<a href="http://arxiv.org/abs/2011.01731" target="_blank">arXiv:2011.01731</a> [<a href="http://arxiv.org/pdf/2011.01731" target="_blank">pdf</a>]

<h2>Differentiable Physics Models for Real-world Offline Model-based Reinforcement Learning. (arXiv:2011.01734v1 [cs.RO])</h2>
<h3>Michael Lutter, Johannes Silberbauer, Joe Watson, Jan Peters</h3>
<p>A limitation of model-based reinforcement learning (MBRL) is the exploitation
of errors in the learned models. Black-box models can fit complex dynamics with
high fidelity, but their behavior is undefined outside of the data
distribution.Physics-based models are better at extrapolating, due to the
general validity of their informed structure, but underfit in the real world
due to the presence of unmodeled phenomena. In this work, we demonstrate
experimentally that for the offline model-based reinforcement learning setting,
physics-based models can be beneficial compared to high-capacity function
approximators if the mechanical structure is known. Physics-based models can
learn to perform the ball in a cup (BiC) task on a physical manipulator using
only 4 minutes of sampled data using offline MBRL. We find that black-box
models consistently produce unviable policies for BiC as all predicted
trajectories diverge to physically impossible state, despite having access to
more data than the physics-based model. In addition, we generalize the approach
of physics parameter identification from modeling holonomic multi-body systems
to systems with nonholonomic dynamics using end-to-end automatic
differentiation.

Videos: https://sites.google.com/view/ball-in-a-cup-in-4-minutes/
</p>
<a href="http://arxiv.org/abs/2011.01734" target="_blank">arXiv:2011.01734</a> [<a href="http://arxiv.org/pdf/2011.01734" target="_blank">pdf</a>]

<h2>Learning a Generative Motion Model from Image Sequences based on a Latent Motion Matrix. (arXiv:2011.01741v1 [cs.CV])</h2>
<h3>Julian Krebs, Herv&#xe9; Delingette, Nicholas Ayache, Tommaso Mansi</h3>
<p>We propose to learn a probabilistic motion model from a sequence of images
for spatio-temporal registration. Our model encodes motion in a low-dimensional
probabilistic space - the motion matrix - which enables various motion analysis
tasks such as simulation and interpolation of realistic motion patterns
allowing for faster data acquisition and data augmentation. More precisely, the
motion matrix allows to transport the recovered motion from one subject to
another simulating for example a pathological motion in a healthy subject
without the need for inter-subject registration. The method is based on a
conditional latent variable model that is trained using amortized variational
inference. This unsupervised generative model follows a novel multivariate
Gaussian process prior and is applied within a temporal convolutional network
which leads to a diffeomorphic motion model. Temporal consistency and
generalizability is further improved by applying a temporal dropout training
scheme. Applied to cardiac cine-MRI sequences, we show improved registration
accuracy and spatio-temporally smoother deformations compared to three
state-of-the-art registration algorithms. Besides, we demonstrate the model's
applicability for motion analysis, simulation and super-resolution by an
improved motion reconstruction from sequences with missing frames compared to
linear and cubic interpolation.
</p>
<a href="http://arxiv.org/abs/2011.01741" target="_blank">arXiv:2011.01741</a> [<a href="http://arxiv.org/pdf/2011.01741" target="_blank">pdf</a>]

<h2>Solving Inverse Problems with Hybrid Deep Image Priors: the challenge of preventing overfitting. (arXiv:2011.01748v1 [eess.IV])</h2>
<h3>Zhaodong Sun</h3>
<p>We mainly analyze and solve the overfitting problem of deep image prior
(DIP). Deep image prior can solve inverse problems such as super-resolution,
inpainting and denoising. The main advantage of DIP over other deep learning
approaches is that it does not need access to a large dataset. However, due to
the large number of parameters of the neural network and noisy data, DIP
overfits to the noise in the image as the number of iterations grows. In the
thesis, we use hybrid deep image priors to avoid overfitting. The hybrid priors
are to combine DIP with an explicit prior such as total variation or with an
implicit prior such as a denoising algorithm. We use the alternating direction
method-of-multipliers (ADMM) to incorporate the new prior and try different
forms of ADMM to avoid extra computation caused by the inner loop of ADMM
steps. We also study the relation between the dynamics of gradient descent, and
the overfitting phenomenon. The numerical results show the hybrid priors play
an important role in preventing overfitting. Besides, we try to fit the image
along some directions and find this method can reduce overfitting when the
noise level is large. When the noise level is small, it does not considerably
reduce the overfitting problem.
</p>
<a href="http://arxiv.org/abs/2011.01748" target="_blank">arXiv:2011.01748</a> [<a href="http://arxiv.org/pdf/2011.01748" target="_blank">pdf</a>]

<h2>Attention Beam: An Image Captioning Approach. (arXiv:2011.01753v1 [cs.CV])</h2>
<h3>Anubhav Shrimal, Tanmoy Chakraborty</h3>
<p>The aim of image captioning is to generate textual description of a given
image. Though seemingly an easy task for humans, it is challenging for machines
as it requires the ability to comprehend the image (computer vision) and
consequently generate a human-like description for the image (natural language
understanding). In recent times, encoder-decoder based architectures have
achieved state-of-the-art results for image captioning. Here, we present a
heuristic of beam search on top of the encoder-decoder based architecture that
gives better quality captions on three benchmark datasets: Flickr8k, Flickr30k
and MS COCO.
</p>
<a href="http://arxiv.org/abs/2011.01753" target="_blank">arXiv:2011.01753</a> [<a href="http://arxiv.org/pdf/2011.01753" target="_blank">pdf</a>]

<h2>ControlVAE: Tuning, Analytical Properties, and Performance Analysis. (arXiv:2011.01754v1 [cs.LG])</h2>
<h3>Huajie Shao, Zhisheng Xiao, Shuochao Yao, Aston Zhang, Shengzhong Liu, Tarek Abdelzaher</h3>
<p>This paper reviews the novel concept of controllable variational autoencoder
(ControlVAE), discusses its parameter tuning to meet application needs, derives
its key analytic properties, and offers useful extensions and applications.
ControlVAE is a new variational autoencoder (VAE) framework that combines the
automatic control theory with the basic VAE to stabilize the KL-divergence of
VAE models to a specified value. It leverages a non-linear PI controller, a
variant of the proportional-integral-derivative (PID) control, to dynamically
tune the weight of the KL-divergence term in the evidence lower bound (ELBO)
using the output KL-divergence as feedback. This allows us to precisely control
the KL-divergence to a desired value (set point), which is effective in
avoiding posterior collapse and learning disentangled representations. In order
to improve the ELBO over the regular VAE, we provide simplified theoretical
analysis to inform setting the set point of KL-divergence for ControlVAE. We
observe that compared to other methods that seek to balance the two terms in
VAE's objective, ControlVAE leads to better learning dynamics. In particular,
it can achieve a good trade-off between reconstruction quality and
KL-divergence. We evaluate the proposed method on three tasks: image
generation, language modeling and disentangled representation learning. The
results show that ControlVAE can achieve much better reconstruction quality
than the other methods for comparable disentanglement. On the language modeling
task, ControlVAE can avoid posterior collapse (KL vanishing) and improve the
diversity of generated text. Moreover, our method can change the optimization
trajectory, improving the ELBO and the reconstruction quality for image
generation.
</p>
<a href="http://arxiv.org/abs/2011.01754" target="_blank">arXiv:2011.01754</a> [<a href="http://arxiv.org/pdf/2011.01754" target="_blank">pdf</a>]

<h2>MAD-VAE: Manifold Awareness Defense Variational Autoencoder. (arXiv:2011.01755v1 [cs.CR])</h2>
<h3>Frederick Morlock, Dingsu Wang</h3>
<p>Although deep generative models such as Defense-GAN and Defense-VAE have made
significant progress in terms of adversarial defenses of image classification
neural networks, several methods have been found to circumvent these defenses.
Based on Defense-VAE, in our research we introduce several methods to improve
the robustness of defense models. The methods introduced in this paper are
straight forward yet show promise over the vanilla Defense-VAE. With extensive
experiments on MNIST data set, we have demonstrated the effectiveness of our
algorithms against different attacks. Our experiments also include attacks on
the latent space of the defensive model. We also discuss the applicability of
existing adversarial latent space attacks as they may have a significant flaw.
</p>
<a href="http://arxiv.org/abs/2011.01755" target="_blank">arXiv:2011.01755</a> [<a href="http://arxiv.org/pdf/2011.01755" target="_blank">pdf</a>]

<h2>Representation Matters: Improving Perception and Exploration for Robotics. (arXiv:2011.01758v1 [cs.LG])</h2>
<h3>Markus Wulfmeier, Arunkumar Byravan, Tim Hertweck, Irina Higgins, Ankush Gupta, Tejas Kulkarni, Malcolm Reynolds, Denis Teplyashin, Roland Hafner, Thomas Lampe, Martin Riedmiller</h3>
<p>Projecting high-dimensional environment observations into lower-dimensional
structured representations can considerably improve data-efficiency for
reinforcement learning in domains with limited data such as robotics. Can a
single generally useful representation be found? In order to answer this
question, it is important to understand how the representation will be used by
the agent and what properties such a 'good' representation should have. In this
paper we systematically evaluate a number of common learnt and hand-engineered
representations in the context of three robotics tasks: lifting, stacking and
pushing of 3D blocks. The representations are evaluated in two use-cases: as
input to the agent, or as a source of auxiliary tasks. Furthermore, the value
of each representation is evaluated in terms of three properties:
dimensionality, observability and disentanglement. We can significantly improve
performance in both use-cases and demonstrate that some representations can
perform commensurate to simulator states as agent inputs. Finally, our results
challenge common intuitions by demonstrating that: 1) dimensionality strongly
matters for task generation, but is negligible for inputs, 2) observability of
task-relevant aspects mostly affects the input representation use-case, and 3)
disentanglement leads to better auxiliary tasks, but has only limited benefits
for input representations. This work serves as a step towards a more systematic
understanding of what makes a 'good' representation for control in robotics,
enabling practitioners to make more informed choices for developing new learned
or hand-engineered representations.
</p>
<a href="http://arxiv.org/abs/2011.01758" target="_blank">arXiv:2011.01758</a> [<a href="http://arxiv.org/pdf/2011.01758" target="_blank">pdf</a>]

<h2>Problems using deep generative models for probabilistic audio source separation. (arXiv:2011.01761v1 [cs.LG])</h2>
<h3>Maurice Frank, Maximilian Ilse</h3>
<p>Recent advancements in deep generative modeling make it possible to learn
prior distributions from complex data that subsequently can be used for
Bayesian inference. However, we find that distributions learned by deep
generative models for audio signals do not exhibit the right properties that
are necessary for tasks like audio source separation using a probabilistic
approach. We observe that the learned prior distributions are either
discriminative and extremely peaked or smooth and non-discriminative. We
quantify this behavior for two types of deep generative models on two audio
datasets.
</p>
<a href="http://arxiv.org/abs/2011.01761" target="_blank">arXiv:2011.01761</a> [<a href="http://arxiv.org/pdf/2011.01761" target="_blank">pdf</a>]

<h2>Mitigating Backdoor Attacks in Federated Learning. (arXiv:2011.01767v1 [cs.CR])</h2>
<h3>Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra</h3>
<p>Malicious clients can attack federated learning systems by using malicious
data, including backdoor samples, during the training phase. The compromised
global model will perform well on the validation dataset designed for the task.
However, a small subset of data with backdoor patterns may trigger the model to
make a wrong prediction. Previously, there was an arms race. Attackers tried to
conceal attacks and defenders tried to detect attacks during the aggregation
stage of training on the server-side in a federated learning system. In this
work, we propose a new method to mitigate backdoor attacks after the training
phase. Specifically, we designed a federated pruning method to remove redundant
neurons in the network and then adjust the model's extreme weight values.
Experiments conducted on distributed Fashion-MNIST have shown that our method
can reduce the average attack success rate from 99.7% to 1.9% with a 5.5% loss
of test accuracy on the validation dataset. To minimize the pruning influence
on test accuracy, we can fine-tune after pruning, and the attack success rate
drops to 6.4%, with only a 1.7% loss of test accuracy.
</p>
<a href="http://arxiv.org/abs/2011.01767" target="_blank">arXiv:2011.01767</a> [<a href="http://arxiv.org/pdf/2011.01767" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning Based Dynamic Route Planning for Minimizing Travel Time. (arXiv:2011.01771v1 [cs.LG])</h2>
<h3>Yuanzhe Geng, Erwu Liu, Rui Wang, Yiming Liu</h3>
<p>Route planning is important in transportation. Existing works focus on
finding the shortest path solution or using metrics such as safety and energy
consumption to determine the planning. It is noted that most of these studies
rely on prior knowledge of road network, which may be not available in certain
situations. In this paper, we design a route planning algorithm based on deep
reinforcement learning (DRL) for pedestrians. We use travel time consumption as
the metric, and plan the route by predicting pedestrian flow in the road
network. We put an agent, which is an intelligent robot, on a virtual map.
Different from previous studies, our approach assumes that the agent does not
need any prior information about road network, but simply relies on the
interaction with the environment. We propose a dynamically adjustable route
planning (DARP) algorithm, where the agent learns strategies through a dueling
deep Q network to avoid congested roads. Simulation results show that the DARP
algorithm saves 52% of the time under congestion condition when compared with
traditional shortest path planning algorithms.
</p>
<a href="http://arxiv.org/abs/2011.01771" target="_blank">arXiv:2011.01771</a> [<a href="http://arxiv.org/pdf/2011.01771" target="_blank">pdf</a>]

<h2>Memory-Efficient RkNN Retrieval by Nonlinear k-Distance Approximation. (arXiv:2011.01773v1 [cs.DB])</h2>
<h3>Sandra Obermeier, Max Berrendorf, Peer Kr&#xf6;ger</h3>
<p>The reverse k-nearest neighbor (RkNN) query is an established query type with
various applications reaching from identifying highly influential objects over
incrementally updating kNN graphs to optimizing sensor communication and
outlier detection. State-of-the-art solutions exploit that the k-distances in
real-world datasets often follow the power-law distribution, and bound them
with linear lines in log-log space. In this work, we investigate this
assumption and uncover that it is violated in regions of changing density,
which we show are typical for real-life datasets. Towards a generic solution,
we pose the estimation of k-distances as a regression problem. Thereby, we
enable harnessing the power of the abundance of available Machine Learning
models and profiting from their advancement. We propose a flexible approach
which allows steering the performance-memory consumption trade-off, and in
particular to find good solutions with a fixed memory budget crucial in the
context of edge computing. Moreover, we show how to obtain and improve
guaranteed bounds essential to exact query processing. In experiments on
real-world datasets, we demonstrate how this framework can significantly reduce
the index memory consumption, and strongly reduce the candidate set size. We
publish our code at https://github.com/sobermeier/nonlinear-kdist.
</p>
<a href="http://arxiv.org/abs/2011.01773" target="_blank">arXiv:2011.01773</a> [<a href="http://arxiv.org/pdf/2011.01773" target="_blank">pdf</a>]

<h2>An Efficiency-boosting Client Selection Scheme for Federated Learning with Fairness Guarantee. (arXiv:2011.01783v1 [cs.LG])</h2>
<h3>Tiansheng Huang, Weiwei Lin, Wentai Wu, Ligang He, Keqin Li, Albert Y.Zomaya</h3>
<p>The issue of potential privacy leakage during centralized AI's model training
has drawn intensive concern from the public. A Parallel and Distributed
Computing (or PDC) scheme, termed Federated Learning (FL), has emerged as a new
paradigm to cope with the privacy issue by allowing clients to perform model
training locally, without the necessity to upload their personal sensitive
data. In FL, the number of clients could be sufficiently large, but the
bandwidth available for model distribution and re-upload is quite limited,
making it sensible to only involve part of the volunteers to participate in the
training process. The client selection policy is critical to an FL process in
terms of training efficiency, the final model's quality as well as fairness. In
this paper, we will model the fairness guaranteed client selection as a
Lyapunov optimization problem and then a C2MAB-based method is proposed for
estimation of the model exchange time between each client and the server, based
on which we design a fairness guaranteed algorithm termed RBCS-F for
problem-solving. The regret of RBCS-F is strictly bounded by a finite constant,
justifying its theoretical feasibility. Barring the theoretical results, more
empirical data can be derived from our real training experiments on public
datasets.
</p>
<a href="http://arxiv.org/abs/2011.01783" target="_blank">arXiv:2011.01783</a> [<a href="http://arxiv.org/pdf/2011.01783" target="_blank">pdf</a>]

<h2>Predicting intubation support requirement of patients using Chest X-ray with Deep Representation Learning. (arXiv:2011.01787v1 [eess.IV])</h2>
<h3>Aniket Maurya</h3>
<p>Recent developments in medical imaging with Deep Learning presents evidence
of automated diagnosis and prognosis. It can also be a complement to currently
available diagnosis methods. Deep Learning can be leveraged for diagnosis,
severity prediction, intubation support prediction and many similar tasks. We
present prediction of intubation support requirement for patients from the
Chest X-ray using Deep representation learning. We release our source code
publicly at https://github.com/aniketmaurya/covid-research.
</p>
<a href="http://arxiv.org/abs/2011.01787" target="_blank">arXiv:2011.01787</a> [<a href="http://arxiv.org/pdf/2011.01787" target="_blank">pdf</a>]

<h2>Loss Bounds for Approximate Influence-Based Abstraction. (arXiv:2011.01788v1 [cs.AI])</h2>
<h3>Elena Congeduti, Alexander Mey, Frans A. Oliehoek</h3>
<p>Sequential decision making techniques hold great promise to improve the
performance of many real-world systems, but computational complexity hampers
their principled application. Influence-based abstraction aims to gain leverage
by modeling local subproblems together with the 'influence' that the rest of
the system exerts on them. While computing exact representations of such
influence might be intractable, learning approximate representations offers a
promising approach to enable scalable solutions. This paper investigates the
performance of such approaches from a theoretical perspective. The primary
contribution is the derivation of sufficient conditions on approximate
influence representations that can guarantee solutions with small value loss.
In particular we show that neural networks trained with cross entropy are well
suited to learn approximate influence representations. Moreover, we provide a
sample based formulation of the bounds, which reduces the gap to applications.
Finally, driven by our theoretical insights, we propose approximation error
estimators, which empirically reveal to correlate well with the value loss.
</p>
<a href="http://arxiv.org/abs/2011.01788" target="_blank">arXiv:2011.01788</a> [<a href="http://arxiv.org/pdf/2011.01788" target="_blank">pdf</a>]

<h2>Point of Care Image Analysis for COVID-19. (arXiv:2011.01789v1 [eess.IV])</h2>
<h3>Daniel Yaron, Daphna Keidar, Elisha Goldstein, Yair Shachar, Ayelet Blass, Oz Frank, Nir Schipper, Nogah Shabshin, Ahuva Grubstein, Dror Suhami, Naama R. Bogot, Eyal Sela, Amiel A. Dror, Mordehay Vaturi, Federico Mento, Elena Torri, Riccardo Inchingolo, Andrea Smargiassi, Gino Soldati, Tiziano Perrone, Libertario Demi, Meirav Galun, Shai Bagon, Yishai M. Elyada, Yonina C. Eldar</h3>
<p>Early detection of COVID-19 is key in containing the pandemic. Disease
detection and evaluation based on imaging is fast and cheap and therefore plays
an important role in COVID-19 handling. COVID-19 is easier to detect in chest
CT, however, it is expensive, non-portable, and difficult to disinfect, making
it unfit as a point-of-care (POC) modality. On the other hand, chest X-ray
(CXR) and lung ultrasound (LUS) are widely used, yet, COVID-19 findings in
these modalities are not always very clear. Here we train deep neural networks
to significantly enhance the capability to detect, grade and monitor COVID-19
patients using CXRs and LUS. Collaborating with several hospitals in Israel we
collect a large dataset of CXRs and use this dataset to train a neural network
obtaining above 90% detection rate for COVID-19. In addition, in collaboration
with ULTRa (Ultrasound Laboratory Trento, Italy) and hospitals in Italy we
obtained POC ultrasound data with annotations of the severity of disease and
trained a deep network for automatic severity grading.
</p>
<a href="http://arxiv.org/abs/2011.01789" target="_blank">arXiv:2011.01789</a> [<a href="http://arxiv.org/pdf/2011.01789" target="_blank">pdf</a>]

<h2>Doubly Robust Off-Policy Learning on Low-Dimensional Manifolds by Deep Neural Networks. (arXiv:2011.01797v1 [cs.LG])</h2>
<h3>Minshuo Chen, Hao Liu, Wenjing Liao, Tuo Zhao</h3>
<p>Causal inference explores the causation between actions and the consequent
rewards on a covariate set. Recently deep learning has achieved a remarkable
performance in causal inference, but existing statistical theories cannot well
explain such an empirical success, especially when the covariates are
high-dimensional. Most theoretical results in causal inference are asymptotic,
suffer from the curse of dimensionality, and only work for the finite-action
scenario. To bridge such a gap between theory and practice, this paper studies
doubly robust off-policy learning by deep neural networks. When the covariates
lie on a low-dimensional manifold, we prove nonasymptotic regret bounds, which
converge at a fast rate depending on the intrinsic dimension of the manifold.
Our results cover both the finite- and continuous-action scenarios. Our theory
shows that deep neural networks are adaptive to the low-dimensional geometric
structures of the covariates, and partially explains the success of deep
learning for causal inference.
</p>
<a href="http://arxiv.org/abs/2011.01797" target="_blank">arXiv:2011.01797</a> [<a href="http://arxiv.org/pdf/2011.01797" target="_blank">pdf</a>]

<h2>Ensuring Dataset Quality for Machine Learning Certification. (arXiv:2011.01799v1 [cs.LG])</h2>
<h3>Sylvaine Picard, Camille Chapdelaine, Cyril Cappi, Laurent Gardes, Eric Jenn, Baptiste Lef&#xe8;vre, Thomas Soumarmon</h3>
<p>In this paper, we address the problem of dataset quality in the context of
Machine Learning (ML)-based critical systems. We briefly analyse the
applicability of some existing standards dealing with data and show that the
specificities of the ML context are neither properly captured nor taken into
ac-count. As a first answer to this concerning situation, we propose a dataset
specification and verification process, and apply it on a signal recognition
system from the railway domain. In addi-tion, we also give a list of
recommendations for the collection and management of datasets. This work is one
step towards the dataset engineering process that will be required for ML to be
used on safety critical systems.
</p>
<a href="http://arxiv.org/abs/2011.01799" target="_blank">arXiv:2011.01799</a> [<a href="http://arxiv.org/pdf/2011.01799" target="_blank">pdf</a>]

<h2>One-Shot Federated Learning with Neuromorphic Processors. (arXiv:2011.01813v1 [cs.LG])</h2>
<h3>Kenneth Stewart, Yanqi Gu</h3>
<p>Being very low power, the use of neuromorphic processors in mobile devices to
solve machine learning problems is a promising alternative to traditional Von
Neumann processors. Federated Learning enables entities such as mobile devices
to collaboratively learn a shared model while keeping their training data
local. Additionally, federated learning is a secure way of learning because
only the model weights need to be shared between models, keeping the data
private. Here we demonstrate the efficacy of federated learning in neuromorphic
processors. Neuromorphic processors benefit from the collaborative learning,
achieving state of the art accuracy on a one-shot learning gesture recognition
task across individual processor models while preserving local data privacy.
</p>
<a href="http://arxiv.org/abs/2011.01813" target="_blank">arXiv:2011.01813</a> [<a href="http://arxiv.org/pdf/2011.01813" target="_blank">pdf</a>]

<h2>A Deep Learning based Detection Method for Combined Integrity-Availability Cyber Attacks in Power System. (arXiv:2011.01816v1 [eess.SY])</h2>
<h3>Wangkun Xu, Fei Teng</h3>
<p>As one of the largest and most complex systems on earth, power grid (PG)
operation and control have stepped forward as a compound analysis on both
physical and cyber layers which makes it vulnerable to assaults from economic
and security considerations. A new type of attack, namely as combined data
Integrity-Availability attack, has been recently proposed, where the attackers
can simultaneously manipulate and blind some measurements on SCADA system to
mislead the control operation and keep stealthy. Compared with traditional
FDIAs, this combined attack can further complicate and vitiate the model-based
detection mechanism. To detect such attack, this paper proposes a novel random
denoising LSTM-AE (LSTMRDAE) framework, where the spatial-temporal correlations
of measurements can be explicitly captured and the unavailable data is
countered by the random dropout layer. The proposed algorithm is evaluated and
the performance is verified on a standard IEEE 118-bus system under various
unseen attack attempts.
</p>
<a href="http://arxiv.org/abs/2011.01816" target="_blank">arXiv:2011.01816</a> [<a href="http://arxiv.org/pdf/2011.01816" target="_blank">pdf</a>]

<h2>Learning Representations from Audio-Visual Spatial Alignment. (arXiv:2011.01819v1 [cs.CV])</h2>
<h3>Pedro Morgado, Yi Li, Nuno Vasconcelos</h3>
<p>We introduce a novel self-supervised pretext task for learning
representations from audio-visual content. Prior work on audio-visual
representation learning leverages correspondences at the video level.
Approaches based on audio-visual correspondence (AVC) predict whether audio and
video clips originate from the same or different video instances. Audio-visual
temporal synchronization (AVTS) further discriminates negative pairs originated
from the same video instance but at different moments in time. While these
approaches learn high-quality representations for downstream tasks such as
action recognition, their training objectives disregard spatial cues naturally
occurring in audio and visual signals. To learn from these spatial cues, we
tasked a network to perform contrastive audio-visual spatial alignment of
360{\deg} video and spatial audio. The ability to perform spatial alignment is
enhanced by reasoning over the full spatial content of the 360{\deg} video
using a transformer architecture to combine representations from multiple
viewpoints. The advantages of the proposed pretext task are demonstrated on a
variety of audio and visual downstream tasks, including audio-visual
correspondence, spatial alignment, action recognition, and video semantic
segmentation.
</p>
<a href="http://arxiv.org/abs/2011.01819" target="_blank">arXiv:2011.01819</a> [<a href="http://arxiv.org/pdf/2011.01819" target="_blank">pdf</a>]

<h2>Minimax Pareto Fairness: A Multi Objective Perspective. (arXiv:2011.01821v1 [stat.ML])</h2>
<h3>Natalia Martinez, Martin Bertran, Guillermo Sapiro</h3>
<p>In this work we formulate and formally characterize group fairness as a
multi-objective optimization problem, where each sensitive group risk is a
separate objective. We propose a fairness criterion where a classifier achieves
minimax risk and is Pareto-efficient w.r.t. all groups, avoiding unnecessary
harm, and can lead to the best zero-gap model if policy dictates so. We provide
a simple optimization algorithm compatible with deep neural networks to satisfy
these constraints. Since our method does not require test-time access to
sensitive attributes, it can be applied to reduce worst-case classification
errors between outcomes in unbalanced classification problems. We test the
proposed methodology on real case-studies of predicting income, ICU patient
mortality, skin lesions classification, and assessing credit risk,
demonstrating how our framework compares favorably to other approaches.
</p>
<a href="http://arxiv.org/abs/2011.01821" target="_blank">arXiv:2011.01821</a> [<a href="http://arxiv.org/pdf/2011.01821" target="_blank">pdf</a>]

<h2>Simulating and classifying behavior in adversarial environments based on action-state traces: an application to money laundering. (arXiv:2011.01826v1 [cs.AI])</h2>
<h3>Daniel Borrajo, Manuela Veloso, Sameena Shah</h3>
<p>Many business applications involve adversarial relationships in which both
sides adapt their strategies to optimize their opposing benefits. One of the
key characteristics of these applications is the wide range of strategies that
an adversary may choose as they adapt their strategy dynamically to sustain
benefits and evade authorities. In this paper, we present a novel way of
approaching these types of applications, in particular in the context of
Anti-Money Laundering. We provide a mechanism through which diverse, realistic
and new unobserved behavior may be generated to discover potential unobserved
adversarial actions to enable organizations to preemptively mitigate these
risks. In this regard, we make three main contributions. (a) Propose a novel
behavior-based model as opposed to individual transactions-based models
currently used by financial institutions. We introduce behavior traces as
enriched relational representation to represent observed human behavior. (b) A
modelling approach that observes these traces and is able to accurately infer
the goals of actors by classifying the behavior into money laundering or
standard behavior despite significant unobserved activity. And (c) a synthetic
behavior simulator that can generate new previously unseen traces. The
simulator incorporates a high level of flexibility in the behavioral parameters
so that we can challenge the detection algorithm. Finally, we provide
experimental results that show that the learning module (automated
investigator) that has only partial observability can still successfully infer
the type of behavior, and thus the simulated goals, followed by customers based
on traces - a key aspiration for many applications today.
</p>
<a href="http://arxiv.org/abs/2011.01826" target="_blank">arXiv:2011.01826</a> [<a href="http://arxiv.org/pdf/2011.01826" target="_blank">pdf</a>]

<h2>Goal recognition via model-based and model-free techniques. (arXiv:2011.01832v1 [cs.AI])</h2>
<h3>Daniel Borrajo, Sriram Gopalakrishnan, Vamsi K. Potluru</h3>
<p>Goal recognition aims at predicting human intentions from a trace of
observations. This ability allows people or organizations to anticipate future
actions and intervene in a positive (collaborative) or negative (adversarial)
way. Goal recognition has been successfully used in many domains, but it has
been seldom been used by financial institutions. We claim the techniques are
ripe for its wide use in finance-related tasks. The main two approaches to
perform goal recognition are model-based (planning-based) and model-free
(learning-based). In this paper, we adapt state-of-the-art learning techniques
to goal recognition, and compare model-based and model-free approaches in
different domains. We analyze the experimental data to understand the
trade-offs of using both types of methods. The experiments show that
planning-based approaches are ready for some goal-recognition finance tasks.
</p>
<a href="http://arxiv.org/abs/2011.01832" target="_blank">arXiv:2011.01832</a> [<a href="http://arxiv.org/pdf/2011.01832" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Test Case Prioritization. (arXiv:2011.01834v1 [cs.SE])</h2>
<h3>Mojtaba Bagherzadeh, Nafiseh Kahani, Lionel Briand</h3>
<p>Continuous Integration (CI) significantly reduces integration problems,
speeds up development time, and shortens release time. However, it also
introduces new challenges for quality assurance activities, including
regression testing, which is the focus of this work. Though various approaches
for test case prioritization have shown to be very promising in the context of
regression testing, specific techniques must be designed to deal with the
dynamic nature and timing constraints of CI.

Recently, Reinforcement Learning (RL) has shown great potential in various
challenging scenarios that require continuous adaptation, such as game playing,
real-time ads bidding, and recommender systems. Inspired by this line of work
and building on initial efforts in supporting test case prioritization with RL
techniques, we perform here a comprehensive investigation of RL-based test case
prioritization in a CI context. To this end, taking test case prioritization as
a ranking problem, we model the sequential interactions between the CI
environment and a test case prioritization agent as an RL problem, using three
alternative ranking models. We then rely on carefully selected and tailored,
state-of-the-art RL techniques to automatically and continuously learn an
optimal test case prioritization strategy. Our extensive experimental analysis
shows that the best RL solutions provide a significant accuracy improvement
over previous RL-based work, with prioritization strategies getting close to
being optimal, thus paving the way for using RL to prioritize test cases in a
CI context.
</p>
<a href="http://arxiv.org/abs/2011.01834" target="_blank">arXiv:2011.01834</a> [<a href="http://arxiv.org/pdf/2011.01834" target="_blank">pdf</a>]

<h2>Tabular Transformers for Modeling Multivariate Time Series. (arXiv:2011.01843v1 [cs.LG])</h2>
<h3>Inkit Padhi, Yair Schiff, Igor Melnyk, Mattia Rigotti, Youssef Mroueh, Pierre Dognin, Jerret Ross, Ravi Nair, Erik Altman</h3>
<p>Tabular datasets are ubiquitous in data science applications. Given their
importance, it seems natural to apply state-of-the-art deep learning algorithms
in order to fully unlock their potential. Here we propose neural network models
that represent tabular time series that can optionally leverage their
hierarchical structure. This results in two architectures for tabular time
series: one for learning representations that is analogous to BERT and can be
pre-trained end-to-end and used in downstream tasks, and one that is akin to
GPT and can be used for generation of realistic synthetic tabular sequences. We
demonstrate our models on two datasets: a synthetic credit card transaction
dataset, where the learned representations are used for fraud detection and
synthetic data generation, and on a real pollution dataset, where the learned
encodings are used to predict atmospheric pollutant concentrations. Code and
data are available at https://github.com/IBM/TabFormer.
</p>
<a href="http://arxiv.org/abs/2011.01843" target="_blank">arXiv:2011.01843</a> [<a href="http://arxiv.org/pdf/2011.01843" target="_blank">pdf</a>]

<h2>A Comprehensive Study of Class Incremental Learning Algorithms for Visual Tasks. (arXiv:2011.01844v1 [cs.LG])</h2>
<h3>Eden Belouadah, Adrian Popescu, Ioannis Kanellos</h3>
<p>The ability of artificial agents to increment their capabilities when
confronted with new data is an open challenge in artificial intelligence. The
main challenge faced in such cases is catastrophic forgetting, i.e., the
tendency of neural networks to underfit past data when new ones are ingested. A
first group of approaches tackles catastrophic forgetting by increasing deep
model capacity to accommodate new knowledge. A second type of approaches fix
the deep model size and introduce a mechanism whose objective is to ensure a
good compromise between stability and plasticity of the model. While the first
type of algorithms were compared thoroughly, this is not the case for methods
which exploit a fixed size model. Here, we focus on the latter, place them in a
common conceptual and experimental framework and propose the following
contributions: (1) define six desirable properties of incremental learning
algorithms and analyze them according to these properties, (2) introduce a
unified formalization of the class-incremental learning problem, (3) propose a
common evaluation framework which is more thorough than existing ones in terms
of number of datasets, size of datasets, size of bounded memory and number of
incremental states, (4) investigate the usefulness of herding for past
exemplars selection, (5) provide experimental evidence that it is possible to
obtain competitive performance without the use of knowledge distillation to
tackle catastrophic forgetting, and (6) facilitate reproducibility by
integrating all tested methods in a common open-source repository. The main
experimental finding is that none of the existing algorithms achieves the best
results in all evaluated settings. Important differences arise notably if a
bounded memory of past classes is allowed or not.
</p>
<a href="http://arxiv.org/abs/2011.01844" target="_blank">arXiv:2011.01844</a> [<a href="http://arxiv.org/pdf/2011.01844" target="_blank">pdf</a>]

<h2>Specialization in Hierarchical Learning Systems. (arXiv:2011.01845v1 [cs.LG])</h2>
<h3>Heinke Hihn, Daniel A. Braun</h3>
<p>Joining multiple decision-makers together is a powerful way to obtain more
sophisticated decision-making systems, but requires to address the questions of
division of labor and specialization. We investigate in how far information
constraints in hierarchies of experts not only provide a principled method for
regularization but also to enforce specialization. In particular, we devise an
information-theoretically motivated on-line learning rule that allows
partitioning of the problem space into multiple sub-problems that can be solved
by the individual experts. We demonstrate two different ways to apply our
method: (i) partitioning problems based on individual data samples and (ii)
based on sets of data samples representing tasks. Approach (i) equips the
system with the ability to solve complex decision-making problems by finding an
optimal combination of local expert decision-makers. Approach (ii) leads to
decision-makers specialized in solving families of tasks, which equips the
system with the ability to solve meta-learning problems. We show the broad
applicability of our approach on a range of problems including classification,
regression, density estimation, and reinforcement learning problems, both in
the standard machine learning setup and in a meta-learning setting.
</p>
<a href="http://arxiv.org/abs/2011.01845" target="_blank">arXiv:2011.01845</a> [<a href="http://arxiv.org/pdf/2011.01845" target="_blank">pdf</a>]

<h2>Detecting Word Sense Disambiguation Biases in Machine Translation for Model-Agnostic Adversarial Attacks. (arXiv:2011.01846v1 [cs.CL])</h2>
<h3>Denis Emelin, Ivan Titov, Rico Sennrich</h3>
<p>Word sense disambiguation is a well-known source of translation errors in
NMT. We posit that some of the incorrect disambiguation choices are due to
models' over-reliance on dataset artifacts found in training data, specifically
superficial word co-occurrences, rather than a deeper understanding of the
source text. We introduce a method for the prediction of disambiguation errors
based on statistical data properties, demonstrating its effectiveness across
several domains and model types. Moreover, we develop a simple adversarial
attack strategy that minimally perturbs sentences in order to elicit
disambiguation errors to further probe the robustness of translation models.
Our findings indicate that disambiguation robustness varies substantially
between domains and that different models trained on the same data are
vulnerable to different attacks.
</p>
<a href="http://arxiv.org/abs/2011.01846" target="_blank">arXiv:2011.01846</a> [<a href="http://arxiv.org/pdf/2011.01846" target="_blank">pdf</a>]

<h2>Fast Adaptive Fault Accommodation in Floating Offshore Wind Turbines via Model-Based Fault Diagnosis and Subspace Predictive Repetitive Control. (arXiv:2011.01855v1 [eess.SY])</h2>
<h3>Yichao Liu, Ping Wu, Riccardo M.G. Ferrari, Jan-Willem van Wingerden</h3>
<p>As Floating Offshore Wind Turbines (FOWTs) operate in deep waters and are
subjected to stressful wind and wave induced loads, they are more prone than
onshore counterparts to experience faults and failure. In particular, the pitch
system may experience Pitch Actuator Stuck (PAS) type of faults, which will
result in a complete loss of control authority. In this paper, a novel fast and
adaptive solution is developed by integrating a model-based Fault Diagnosis
(FD) scheme and the Subspace Predictive Repetitive Control (SPRC). The FD role
is to quickly detect and isolate the failed pitch actuator. Based on the fault
isolation results, a pre-tuned adaptive SPRC is switched online in place of the
existing one, whose initial values of the parameters has been tuned offline to
match the specific faulty case. After that, SPRC employs subspace
identification to continuously identify a linear model of the wind turbine over
a moving time window, and thereby formulate an adaptive control law to
alleviate the PAS-induced loads. Results show that the developed architecture
allows to achieve a considerable reduction of the PAS-induced blade loads. More
importantly, the time needed to reduce the PAS-induced loads are significantly
shortened, thus avoiding further damage to other components during the adaption
time and allowing continued power generation.
</p>
<a href="http://arxiv.org/abs/2011.01855" target="_blank">arXiv:2011.01855</a> [<a href="http://arxiv.org/pdf/2011.01855" target="_blank">pdf</a>]

<h2>Decoupling entrainment from consistency using deep neural networks. (arXiv:2011.01860v1 [cs.CL])</h2>
<h3>Andreas Weise, Rivka Levitan</h3>
<p>Human interlocutors tend to engage in adaptive behavior known as entrainment
to become more similar to each other. Isolating the effect of consistency,
i.e., speakers adhering to their individual styles, is a critical part of the
analysis of entrainment. We propose to treat speakers' initial vocal features
as confounds for the prediction of subsequent outputs. Using two existing
neural approaches to deconfounding, we define new measures of entrainment that
control for consistency. These successfully discriminate real interactions from
fake ones. Interestingly, our stricter methods correlate with social variables
in opposite direction from previous measures that do not account for
consistency. These results demonstrate the advantages of using neural networks
to model entrainment, and raise questions regarding how to interpret prior
associations of conversation quality with entrainment measures that do not
account for consistency.
</p>
<a href="http://arxiv.org/abs/2011.01860" target="_blank">arXiv:2011.01860</a> [<a href="http://arxiv.org/pdf/2011.01860" target="_blank">pdf</a>]

<h2>DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection. (arXiv:2011.01861v1 [cs.CL])</h2>
<h3>Joshua Melton, Arunkumar Bagavathi, Siddharth Krishnan</h3>
<p>Online hate speech on social media has become a fast-growing problem in
recent times. Nefarious groups have developed large content delivery networks
across several main-stream (Twitter and Facebook) and fringe (Gab, 4chan,
8chan, etc.) outlets to deliver cascades of hate messages directed both at
individuals and communities. Thus addressing these issues has become a top
priority for large-scale social media outlets. Three key challenges in
automated detection and classification of hateful content are the lack of
clearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc.
- and the lack of baseline models for fringe outlets such as Gab. In this work,
we propose a novel framework with three major contributions. (a) We engineer an
ensemble of deep learning models that combines the strengths of
state-of-the-art approaches, (b) we incorporate a tuning factor into this
framework that leverages transfer learning to conduct automated hate speech
classification on unlabeled datasets, like Gab, and (c) we develop a weak
supervised learning methodology that allows our framework to train on unlabeled
data. Our ensemble models achieve an 83% hate recall on the HON dataset,
surpassing the performance of the state-of-the-art deep models. We demonstrate
that weak supervised training in combination with classifier tuning
significantly increases model performance on unlabeled data from Gab, achieving
a hate recall of 67%.
</p>
<a href="http://arxiv.org/abs/2011.01861" target="_blank">arXiv:2011.01861</a> [<a href="http://arxiv.org/pdf/2011.01861" target="_blank">pdf</a>]

<h2>Semi-supervised AU Intensity Estimation with Contrastive Learning. (arXiv:2011.01864v1 [cs.CV])</h2>
<h3>Enrique Sanchez, Adrian Bulat, Anestis Zaganidis, Georgios Tzimiropoulos</h3>
<p>This paper tackles the challenging problem of estimating the intensity of
Facial Action Units with few labeled images. Contrary to previous works, our
method does not require to manually select key frames, and produces
state-of-the-art results with as little as $2\%$ of annotated frames, which are
\textit{randomly chosen}. To this end, we propose a semi-supervised learning
approach where a spatio-temporal model combining a feature extractor and a
temporal module are learned in two stages. The first stage uses datasets of
unlabeled videos to learn a strong spatio-temporal representation of facial
behavior dynamics based on contrastive learning. To our knowledge we are the
first to build upon this framework for modeling facial behavior in an
unsupervised manner. The second stage uses another dataset of randomly chosen
labeled frames to train a regressor on top of our spatio-temporal model for
estimating the AU intensity. We show that although backpropagation through time
is applied only with respect to the output of the network for extremely sparse
and randomly chosen labeled frames, our model can be effectively trained to
estimate AU intensity accurately, thanks to the unsupervised pre-training of
the first stage. We experimentally validate that our method outperforms
existing methods when working with as little as $2\%$ of randomly chosen data
for both DISFA and BP4D datasets, without a careful choice of labeled frames, a
time-consuming task still required in previous approaches.
</p>
<a href="http://arxiv.org/abs/2011.01864" target="_blank">arXiv:2011.01864</a> [<a href="http://arxiv.org/pdf/2011.01864" target="_blank">pdf</a>]

<h2>Learning unbiased registration and joint segmentation: evaluation on longitudinal diffusion MRI. (arXiv:2011.01869v1 [cs.CV])</h2>
<h3>Bo Li, Wiro J. Niessen, Stefan Klein, M. Arfan Ikram, Meike W. Vernooij, Esther E. Bron</h3>
<p>Analysis of longitudinal changes in imaging studies often involves both
segmentation of structures of interest and registration of multiple timeframes.
The accuracy of such analysis could benefit from a tailored framework that
jointly optimizes both tasks to fully exploit the information available in the
longitudinal data. Most learning-based registration algorithms, including joint
optimization approaches, currently suffer from bias due to selection of a fixed
reference frame and only support pairwise transformations. We here propose an
analytical framework based on an unbiased learning strategy for group-wise
registration that simultaneously registers images to the mean space of a group
to obtain consistent segmentations. We evaluate the proposed method on
longitudinal analysis of a white matter tract in a brain MRI dataset with 2-3
time-points for 3249 individuals, i.e., 8045 images in total. The
reproducibility of the method is evaluated on test-retest data from 97
individuals. The results confirm that the implicit reference image is an
average of the input image. In addition, the proposed framework leads to
consistent segmentations and significantly lower processing bias than that of a
pair-wise fixed-reference approach. This processing bias is even smaller than
those obtained when translating segmentations by only one voxel, which can be
attributed to subtle numerical instabilities and interpolation. Therefore, we
postulate that the proposed mean-space learning strategy could be widely
applied to learning-based registration tasks. In addition, this group-wise
framework introduces a novel way for learning-based longitudinal studies by
direct construction of an unbiased within-subject template and allowing
reliable and efficient analysis of spatio-temporal imaging biomarkers.
</p>
<a href="http://arxiv.org/abs/2011.01869" target="_blank">arXiv:2011.01869</a> [<a href="http://arxiv.org/pdf/2011.01869" target="_blank">pdf</a>]

<h2>FASTCloud: A framework of assessment and selection for trustworthy cloud service based on QoS. (arXiv:2011.01871v1 [cs.DC])</h2>
<h3>Xiang Li</h3>
<p>By virtue of technology and benefit advantages, cloud computing has
increasingly attracted a large number of potential cloud consumers (PCC) plan
to migrate traditional business to the cloud service. However, trust has become
one of the most challenging issues that prevent the PCC from adopting cloud
services, especially in trustworthy cloud service selection. In addition, due
to the diversity and dynamic of quality of service (QoS) in cloud environment,
the existing trust assessment methods based on the single constant value of QoS
attribute and the subjective weight assignment are not good enough to provides
an effective solution for PCCs to identify and select a trustworthy cloud
service among a wide range of functionally-equivalent cloud service providers
(CSP). To address the challenge, a novel assessment and selection framework for
trustworthy cloud service, FASTCloud, is proposed in this study. This framework
facilitate PCCs to select a trustworthy cloud service based on their actual QoS
requirements. In order to accurately and efficiently assess the trust level of
cloud services, a QoS-based trust assessment model is proposed. This model
represents a trust level assessment method based on the interval multiple
attributes with a objective weight assignment method based on the deviation
maximization to adaptively determine the trust level of different cloud
services provisioned by candidate CSPs. The advantage of proposed trust level
assessment method in time complexity is demonstrated by the performance
analysis and comparison.The experimental result of a case study with an open
source dataset shows that the trust model is efficient in cloud service trust
assessment and the FASTCloud can effectively help PCCs select a trustworthy
cloud service.
</p>
<a href="http://arxiv.org/abs/2011.01871" target="_blank">arXiv:2011.01871</a> [<a href="http://arxiv.org/pdf/2011.01871" target="_blank">pdf</a>]

<h2>Predicting Terrain Mechanical Properties in Sight for Planetary Rovers with Semantic Clues. (arXiv:2011.01872v1 [cs.RO])</h2>
<h3>Ruyi Zhou, Wenhao Feng, Huaiguang Yang, Haibo Gao, Nan Li, Zongquan Deng, Liang Ding</h3>
<p>Non-geometric mobility hazards such as rover slippage and sinkage posing
great challenges to costly planetary missions are closely related to the
mechanical properties of terrain. In-situ proprioceptive processes for rovers
to estimate terrain mechanical properties need to experience different slip as
well as sinkage and are helpless to untraversed regions. This paper proposes to
predict terrain mechanical properties with vision in the distance, which
expands the sensing range to the whole view and can partly halt potential
slippage and sinkage hazards in the planning stage. A semantic-based method is
designed to predict bearing and shearing properties of terrain in two stages
connected with semantic clues. The former segmentation phase segments terrain
with a light-weighted network promising to be applied onboard with competitive
93% accuracy and high recall rate over 96%, while the latter inference phase
predicts terrain properties in a quantitative manner based on human-like
inference principles. The prediction results in several test routes are 12.5%
and 10.8% in full-scale error and help to plan appropriate strategies to avoid
suffering non-geometric hazards.
</p>
<a href="http://arxiv.org/abs/2011.01872" target="_blank">arXiv:2011.01872</a> [<a href="http://arxiv.org/pdf/2011.01872" target="_blank">pdf</a>]

<h2>Intrinsic Robotic Introspection: Learning Internal States From Neuron Activations. (arXiv:2011.01880v1 [cs.RO])</h2>
<h3>Nikos Pitsillos, Ameya Pore, Bjorn Sand Jensen, Gerardo Aragon-Camarasa</h3>
<p>We present an introspective framework inspired by the process of how humans
perform introspection. Our working assumption is that neural network
activations encode information, and building internal states from these
activations can improve the performance of an actor-critic model. We perform
experiments where we first train a Variational Autoencoder model to reconstruct
the activations of a feature extraction network and use the latent space to
improve the performance of an actor-critic when deciding which low-level
robotic behaviour to execute. We show that internal states reduce the number of
episodes needed by about 1300 episodes while training an actor-critic, denoting
faster convergence to get a high success value while completing a robotic task.
</p>
<a href="http://arxiv.org/abs/2011.01880" target="_blank">arXiv:2011.01880</a> [<a href="http://arxiv.org/pdf/2011.01880" target="_blank">pdf</a>]

<h2>Secure Planning Against Stealthy Attacks via Model-Free Reinforcement Learning. (arXiv:2011.01882v1 [cs.RO])</h2>
<h3>Alper Kamil Bozkurt, Yu Wang, Miroslav Pajic</h3>
<p>We consider the problem of security-aware planning in an unknown stochastic
environment, in the presence of attacks on control signals (i.e., actuators) of
the robot. We model the attacker as an agent who has the full knowledge of the
controller as well as the employed intrusion-detection system and who wants to
prevent the controller from performing tasks while staying stealthy. We
formulate the problem as a stochastic game between the attacker and the
controller and present an approach to express the objective of such an agent
and the controller as a combined linear temporal logic (LTL) formula. We then
show that the planning problem, described formally as the problem of satisfying
an LTL formula in a stochastic game, can be solved via model-free reinforcement
learning when the environment is completely unknown. Finally, we illustrate and
evaluate our methods on two robotic planning case studies.
</p>
<a href="http://arxiv.org/abs/2011.01882" target="_blank">arXiv:2011.01882</a> [<a href="http://arxiv.org/pdf/2011.01882" target="_blank">pdf</a>]

<h2>Unsupervised Attention Based Instance Discriminative Learning for Person Re-Identification. (arXiv:2011.01888v1 [cs.CV])</h2>
<h3>Kshitij Nikhal, Benjamin S. Riggan</h3>
<p>Recent advances in person re-identification have demonstrated enhanced
discriminability, especially with supervised learning or transfer learning.
However, since the data requirements---including the degree of data
curations---are becoming increasingly complex and laborious, there is a
critical need for unsupervised methods that are robust to large intra-class
variations, such as changes in perspective, illumination, articulated motion,
resolution, etc. Therefore, we propose an unsupervised framework for person
re-identification which is trained in an end-to-end manner without any
pre-training. Our proposed framework leverages a new attention mechanism that
combines group convolutions to (1) enhance spatial attention at multiple scales
and (2) reduce the number of trainable parameters by 59.6%. Additionally, our
framework jointly optimizes the network with agglomerative clustering and
instance learning to tackle hard samples. We perform extensive analysis using
the Market1501 and DukeMTMC-reID datasets to demonstrate that our method
consistently outperforms the state-of-the-art methods (with and without
pre-trained weights).
</p>
<a href="http://arxiv.org/abs/2011.01888" target="_blank">arXiv:2011.01888</a> [<a href="http://arxiv.org/pdf/2011.01888" target="_blank">pdf</a>]

<h2>Policy Transfer via Kinematic Domain Randomization and Adaptation. (arXiv:2011.01891v1 [cs.RO])</h2>
<h3>Ioannis Exarchos, Yifeng Jiang, Wenhao Yu, C. Karen Liu</h3>
<p>Transferring reinforcement learning policies trained in physics simulation to
the real hardware remains a challenge, known as the "sim-to-real" gap. Domain
randomization is a simple yet effective technique to address dynamics
discrepancies across source and target domains, but its success generally
depends on heuristics and trial-and-error. In this work we investigate the
impact of randomized parameter selection on policy transferability across
different types of domain discrepancies. Contrary to common practice in which
kinematic parameters are carefully measured while dynamic parameters are
randomized, we found that virtually randomizing kinematic parameters (e.g.,
link lengths) during training in simulation generally outperforms dynamic
randomization. Based on this finding, we introduce a new domain adaptation
algorithm that utilizes simulated kinematic parameters variation. Our
algorithm, Multi-Policy Bayesian Optimization, trains an ensemble of universal
policies conditioned on virtual kinematic parameters and efficiently adapts to
the target environment using a limited number of target domain rollouts. We
showcase our findings on a simulated quadruped robot in five different target
environments covering different aspects of domain discrepancies.
</p>
<a href="http://arxiv.org/abs/2011.01891" target="_blank">arXiv:2011.01891</a> [<a href="http://arxiv.org/pdf/2011.01891" target="_blank">pdf</a>]

<h2>Learning Barrier Functions with Memory for Robust Safe Navigation. (arXiv:2011.01899v1 [cs.RO])</h2>
<h3>Kehan Long, Cheng Qian, Jorge Cort&#xe9;s, Nikolay Atanasov</h3>
<p>Control barrier functions are widely used to enforce safety properties in
robot motion planning and control. However, the problem of constructing barrier
functions online and synthesizing safe controllers that can deal with the
associated uncertainty has received little attention. This paper investigates
safe navigation in unknown environments, using onboard range sensing to
construct control barrier functions online. To represent different objects in
the environment, we use the distance measurements to train neural network
approximations of the signed distance functions incrementally with replay
memory. This allows us to formulate a novel robust control barrier safety
constraint which takes into account the error in the estimated distance fields
and its gradient. Our formulation leads to a second-order cone program,
enabling safe and stable control synthesis in a priori unknown environments.
</p>
<a href="http://arxiv.org/abs/2011.01899" target="_blank">arXiv:2011.01899</a> [<a href="http://arxiv.org/pdf/2011.01899" target="_blank">pdf</a>]

<h2>Learning Visual Representations for Transfer Learning by Suppressing Texture. (arXiv:2011.01901v1 [cs.CV])</h2>
<h3>Shlok Mishra, Anshul Shah, Ankan Bansal, Jonghyun Choi, Abhinav Shrivastava, Abhishek Sharma, David Jacobs</h3>
<p>Recent literature has shown that features obtained from supervised training
of CNNs may over-emphasize texture rather than encoding high-level information.
In self-supervised learning in particular, texture as a low-level cue may
provide shortcuts that prevent the network from learning higher level
representations. To address these problems we propose to use classic methods
based on anisotropic diffusion to augment training using images with suppressed
texture. This simple method helps retain important edge information and
suppress texture at the same time. We empirically show that our method achieves
state-of-the-art results on object detection and image classification with
eight diverse datasets in either supervised or self-supervised learning tasks
such as MoCoV2 and Jigsaw. Our method is particularly effective for transfer
learning tasks and we observed improved performance on five standard transfer
learning datasets. The large improvements (up to 11.49\%) on the
Sketch-ImageNet dataset, DTD dataset and additional visual analyses with
saliency maps suggest that our approach helps in learning better
representations that better transfer.
</p>
<a href="http://arxiv.org/abs/2011.01901" target="_blank">arXiv:2011.01901</a> [<a href="http://arxiv.org/pdf/2011.01901" target="_blank">pdf</a>]

<h2>Optimizing Molecules using Efficient Queries from Property Evaluations. (arXiv:2011.01921v1 [cs.LG])</h2>
<h3>Samuel Hoffman, Vijil Chenthamarakshan, Kahini Wadhawan, Pin-Yu Chen, Payel Das</h3>
<p>Machine learning has shown potential for optimizing existing molecules with
more desirable properties, a critical step towards accelerating new chemical
discovery. In this work, we propose QMO, a generic query-based molecule
optimization framework that exploits latent embeddings from a molecule
autoencoder. QMO improves the desired properties of an input molecule based on
efficient queries, guided by a set of molecular property predictions and
evaluation metrics. We show that QMO outperforms existing methods in the
benchmark tasks of optimizing molecules for drug likeliness and solubility
under similarity constraints. We also demonstrate significant property
improvement using QMO on two new and challenging tasks that are also important
in real-world discovery problems: (i) optimizing existing SARS-CoV-2 Main
Protease inhibitors toward higher binding affinity; and (ii) improving known
antimicrobial peptides towards lower toxicity. Results from QMO show high
consistency with external validations, suggesting effective means of
facilitating molecule optimization problems with design constraints.
</p>
<a href="http://arxiv.org/abs/2011.01921" target="_blank">arXiv:2011.01921</a> [<a href="http://arxiv.org/pdf/2011.01921" target="_blank">pdf</a>]

<h2>Comparison of pharmacist evaluation of medication orders with predictions of a machine learning model. (arXiv:2011.01925v1 [cs.LG])</h2>
<h3>Sophie-Camille Hogue, Flora Chen, Genevi&#xe8;ve Brassard, Denis Lebel, Jean-Fran&#xe7;ois Bussi&#xe8;res, Audrey Durand, Maxime Thibault</h3>
<p>The objective of this work was to assess the clinical performance of an
unsupervised machine learning model aimed at identifying unusual medication
orders and pharmacological profiles. We conducted a prospective study between
April 2020 and August 2020 where 25 clinical pharmacists dichotomously (typical
or atypical) rated 12,471 medication orders and 1,356 pharmacological profiles.
Based on AUPR, performance was poor for orders, but satisfactory for profiles.
Pharmacists considered the model a useful screening tool.
</p>
<a href="http://arxiv.org/abs/2011.01925" target="_blank">arXiv:2011.01925</a> [<a href="http://arxiv.org/pdf/2011.01925" target="_blank">pdf</a>]

<h2>Generating Unobserved Alternatives: A Case Study through Super-Resolution and Decompression. (arXiv:2011.01926v1 [cs.LG])</h2>
<h3>Shichong Peng, Ke Li</h3>
<p>We consider problems where multiple predictions can be considered correct,
but only one of them is given as supervision. This setting differs from both
the regression and class-conditional generative modelling settings: in the
former, there is a unique observed output for each input, which is provided as
supervision; in the latter, there are many observed outputs for each input, and
many are provided as supervision. Applying either regression methods and
conditional generative models to the present setting often results in a model
that can only make a single prediction for each input. We explore several
problems that have this property and develop an approach that can generate
multiple high-quality predictions given the same input. As a result, it can be
used to generate high-quality outputs that are different from the observed
output.
</p>
<a href="http://arxiv.org/abs/2011.01926" target="_blank">arXiv:2011.01926</a> [<a href="http://arxiv.org/pdf/2011.01926" target="_blank">pdf</a>]

<h2>Generalization to New Actions in Reinforcement Learning. (arXiv:2011.01928v1 [cs.LG])</h2>
<h3>Ayush Jain, Andrew Szot, Joseph J. Lim</h3>
<p>A fundamental trait of intelligence is the ability to achieve goals in the
face of novel circumstances, such as making decisions from new action choices.
However, standard reinforcement learning assumes a fixed set of actions and
requires expensive retraining when given a new action set. To make learning
agents more adaptable, we introduce the problem of zero-shot generalization to
new actions. We propose a two-stage framework where the agent first infers
action representations from action information acquired separately from the
task. A policy flexible to varying action sets is then trained with
generalization objectives. We benchmark generalization on sequential tasks,
such as selecting from an unseen tool-set to solve physical reasoning puzzles
and stacking towers with novel 3D shapes. Videos and code are available at
https://sites.google.com/view/action-generalization
</p>
<a href="http://arxiv.org/abs/2011.01928" target="_blank">arXiv:2011.01928</a> [<a href="http://arxiv.org/pdf/2011.01928" target="_blank">pdf</a>]

<h2>Rotational Rectification Network: Enabling Pedestrian Detection for Mobile Vision. (arXiv:1706.08917v4 [cs.CV] UPDATED)</h2>
<h3>Xinshuo Weng, Shangxuan Wu, Fares Beainy, Kris Kitani</h3>
<p>Across a majority of pedestrian detection datasets, it is typically assumed
that pedestrians will be standing upright with respect to the image coordinate
system. This assumption, however, is not always valid for many vision-equipped
mobile platforms such as mobile phones, UAVs or construction vehicles on rugged
terrain. In these situations, the motion of the camera can cause images of
pedestrians to be captured at extreme angles. This can lead to very poor
pedestrian detection performance when using standard pedestrian detectors. To
address this issue, we propose a Rotational Rectification Network (R2N) that
can be inserted into any CNN-based pedestrian (or object) detector to adapt it
to significant changes in camera rotation. The rotational rectification network
uses a 2D rotation estimation module that passes rotational information to a
spatial transformer network to undistort image features. To enable robust
rotation estimation, we propose a Global Polar Pooling (GP-Pooling) operator to
capture rotational shifts in convolutional features. Through our experiments,
we show how our rotational rectification network can be used to improve the
performance of the state-of-the-art pedestrian detector under heavy image
rotation by up to 45%
</p>
<a href="http://arxiv.org/abs/1706.08917" target="_blank">arXiv:1706.08917</a> [<a href="http://arxiv.org/pdf/1706.08917" target="_blank">pdf</a>]

<h2>Economics of UAV-aided Mobile Services Deployment. (arXiv:1805.08357v2 [cs.NI] UPDATED)</h2>
<h3>Xiao Zhang, Xuehe Wang, Xinping Xu, Lingjie Duan</h3>
<p>Unmanned Aerial Vehicle (UAV) networks have emerged as a promising technology
in rapidly providing communication services to a geographical area out of
coverage or capacity of the ground infrastructure. However, UAV-aided
communication services (UCS) faces challenges due to the UAV limitation in
wireless coverage and energy storage. Aware of such physical limitations, a
future UAV network should be intelligent enough to self-plan trajectories and
best service users. There are important issues regarding the UAV-user
interaction for path planning, UAV-UAV cooperation for sustainable service
provision, onboard energy allocation for balancing both hovering time and
service capacity, and dynamic UCS pricing according to leftover energy and
random demands. These networking and service management issues are largely
overlooked in the literature and this article presents intelligent solutions
for the autonomous UCS deployment and operation. As mobile users' locations are
their private information and are changing over time, how to learn on-demand
users' truthful location reporting is important for determining optimal UAV
deployment in serving all the users fairly. After addressing the truthful
UAV-user interaction issue via artificial intelligence, we further study the
UAV network sustainability for UCS provision by minimizing the energy
consumption cost during deployment and seeking UAV-UAV cooperation. Finally,
for profit-maximizing purpose, we analyze the cooperative UAVs' deployment,
capacity allocation and dynamic service pricing.
</p>
<a href="http://arxiv.org/abs/1805.08357" target="_blank">arXiv:1805.08357</a> [<a href="http://arxiv.org/pdf/1805.08357" target="_blank">pdf</a>]

<h2>PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation. (arXiv:1810.02541v9 [cs.LG] UPDATED)</h2>
<h3>Perttu H&#xe4;m&#xe4;l&#xe4;inen, Amin Babadi, Xiaoxiao Ma, Jaakko Lehtinen</h3>
<p>Proximal Policy Optimization (PPO) is a highly popular model-free
reinforcement learning (RL) approach. However, we observe that in a continuous
action space, PPO can prematurely shrink the exploration variance, which leads
to slow progress and may make the algorithm prone to getting stuck in local
optima. Drawing inspiration from CMA-ES, a black-box evolutionary optimization
method designed for robustness in similar situations, we propose PPO-CMA, a
proximal policy optimization approach that adaptively expands the exploration
variance to speed up progress. With only minor changes to PPO, our algorithm
considerably improves performance in Roboschool continuous control benchmarks.
Our results also show that PPO-CMA, as opposed to PPO, is significantly less
sensitive to the choice of hyperparameters, allowing one to use it in complex
movement optimization tasks without requiring tedious tuning.
</p>
<a href="http://arxiv.org/abs/1810.02541" target="_blank">arXiv:1810.02541</a> [<a href="http://arxiv.org/pdf/1810.02541" target="_blank">pdf</a>]

<h2>Game of Thrones: Fully Distributed Learning for Multi-Player Bandits. (arXiv:1810.11162v6 [cs.GT] UPDATED)</h2>
<h3>Ilai Bistritz, Amir Leshem</h3>
<p>We consider an N-player multi-armed bandit game where each player chooses one
out of M arms for T turns. Each player has different expected rewards for the
arms, and the instantaneous rewards are independent and identically distributed
or Markovian. When two or more players choose the same arm, they all receive
zero reward. Performance is measured using the expected sum of regrets,
compared with an optimal assignment of arms to players that maximizes the sum
of expected rewards. We assume that each player only knows her actions and the
reward she received each turn. Players cannot observe the actions of other
players, and no communication between players is possible. We present a
distributed algorithm and prove that it achieves an expected sum of regrets of
near-O\left(\log T\right). This is the first algorithm to achieve a near order
optimal regret in this fully distributed scenario. All other works have assumed
that either all players have the same vector of expected rewards or that
communication between players is possible.
</p>
<a href="http://arxiv.org/abs/1810.11162" target="_blank">arXiv:1810.11162</a> [<a href="http://arxiv.org/pdf/1810.11162" target="_blank">pdf</a>]

<h2>An Optimistic Acceleration of AMSGrad for Nonconvex Optimization. (arXiv:1903.01435v3 [stat.ML] UPDATED)</h2>
<h3>Jun-Kun Wang, Xiaoyun Li, Belhal Karimi, Ping Li</h3>
<p>We propose a new variant of AMSGrad, a popular adaptive gradient based
optimization algorithm widely used for training deep neural networks. Our
algorithm adds prior knowledge about the sequence of consecutive mini-batch
gradients and leverages its underlying structure making the gradients
sequentially predictable. By exploiting the predictability and ideas from
optimistic online learning, the proposed algorithm can accelerate the
convergence and increase sample efficiency. After establishing a tighter upper
bound under some convexity conditions on the regret, we offer a complimentary
view of our algorithm which generalizes the offline and stochastic version of
nonconvex optimization. In the nonconvex case, we establish a non-asymptotic
convergence bound independently of the initialization. We illustrate the
practical speedup on several deep learning models via numerical experiments.
</p>
<a href="http://arxiv.org/abs/1903.01435" target="_blank">arXiv:1903.01435</a> [<a href="http://arxiv.org/pdf/1903.01435" target="_blank">pdf</a>]

<h2>Learning to Approximate a Bregman Divergence. (arXiv:1905.11545v4 [stat.ML] UPDATED)</h2>
<h3>Ali Siahkamari, Xide Xia, Venkatesh Saligrama, David Castanon, Brian Kulis</h3>
<p>Bregman divergences generalize measures such as the squared Euclidean
distance and the KL divergence, and arise throughout many areas of machine
learning. In this paper, we focus on the problem of approximating an arbitrary
Bregman divergence from supervision, and we provide a well-principled approach
to analyzing such approximations. We develop a formulation and algorithm for
learning arbitrary Bregman divergences based on approximating their underlying
convex generating function via a piecewise linear function. We provide
theoretical approximation bounds using our parameterization and show that the
generalization error $O_p(m^{-1/2})$ for metric learning using our framework
matches the known generalization error in the strictly less general Mahalanobis
metric learning setting. We further demonstrate empirically that our method
performs well in comparison to existing metric learning methods, particularly
for clustering and ranking problems.
</p>
<a href="http://arxiv.org/abs/1905.11545" target="_blank">arXiv:1905.11545</a> [<a href="http://arxiv.org/pdf/1905.11545" target="_blank">pdf</a>]

<h2>Fr\'echet random forests for metric space valued regression with non euclidean predictors. (arXiv:1906.01741v2 [stat.ML] UPDATED)</h2>
<h3>Louis Capitaine, J&#xe9;r&#xe9;mie Bigot, Rodolphe Thi&#xe9;baut, Robin Genuer</h3>
<p>Random forests are a statistical learning method widely used in many areas of
scientific research because of its ability to learn complex relationships
between input and output variables and also their capacity to handle
high-dimensional data. However, current random forest approaches are not
flexible enough to handle heterogeneous data such as curves, images and shapes.
In this paper, we introduce Fr\'echet trees and Fr\'echet random forests, which
allow to handle data for which input and output variables take values in
general metric spaces (which can be unordered). To this end, a new way of
splitting the nodes of trees is introduced and the prediction procedures of
trees and forests are generalized. Then, random forests out-of-bag error and
variable importance score are naturally adapted. A consistency theorem for
Fr\'echet regressogram predictor using data-driven partitions is given and
applied to Fr\'echet purely uniformly random trees. The method is studied
through several simulation scenarios on heterogeneous data combining
longitudinal, image and scalar data. Finally, two real datasets from HIV
vaccine trials are analyzed with the proposed method.
</p>
<a href="http://arxiv.org/abs/1906.01741" target="_blank">arXiv:1906.01741</a> [<a href="http://arxiv.org/pdf/1906.01741" target="_blank">pdf</a>]

<h2>Best Practices for Scientific Research on Neural Architecture Search. (arXiv:1909.02453v3 [cs.LG] UPDATED)</h2>
<h3>Marius Lindauer, Frank Hutter</h3>
<p>Finding a well-performing architecture is often tedious for both DL
practitioners and researchers, leading to tremendous interest in the automation
of this task by means of neural architecture search (NAS). Although the
community has made major strides in developing better NAS methods, the quality
of scientific empirical evaluations in the young field of NAS is still lacking
behind that of other areas of machine learning. To address this issue, we
describe a set of possible issues and ways to avoid them, leading to the NAS
best practices checklist available at this http URL
</p>
<a href="http://arxiv.org/abs/1909.02453" target="_blank">arXiv:1909.02453</a> [<a href="http://arxiv.org/pdf/1909.02453" target="_blank">pdf</a>]

<h2>The OpenUAV Swarm Simulation Testbed: a Collaborative Design Studio for Field Robotics. (arXiv:1910.00739v3 [cs.RO] UPDATED)</h2>
<h3>Harish Anand, Stephen A. Rees, Ashwin Jose, Sarah Bearman, Zhiang Chen, Prasad Antervedi, Jnaneshwar Das</h3>
<p>Simulations play a crucial role in robotics research and education. This
paper presents the OpenUAV testbed, an open-source, easy-to-use, web-based, and
reproducible software system that enables students and researchers to run
robotic simulations on the cloud. The key contributions of the paper are
threefold. First, OpenUAV saves students and researchers from tedious and
complicated software setup by providing web-browser based Linux desktop
sessions with robotics software like Gazebo, ROS, PX4 vehicles, ground control
software, and swarm simulation capabilities. Second, a containerized desktop
session provides the necessary means to save an individual's research work with
its dependencies for future reproducibility of the work. Third, the platform
provides a mechanism to support photorealistic robotics simulations by
combining Unity game engine based camera rendering and Gazebo physics. The
paper describes a methodology for creating such a photorealistic aquatic
simulation for autonomous underwater vehicles. We also present the various
academic and research use-cases of this platform to improve robotics education
and research, especially during times like the COVID-19 pandemic, when virtual
collaboration is necessary.
</p>
<a href="http://arxiv.org/abs/1910.00739" target="_blank">arXiv:1910.00739</a> [<a href="http://arxiv.org/pdf/1910.00739" target="_blank">pdf</a>]

<h2>Adversarial Learning on the Latent Space for Diverse Dialog Generation. (arXiv:1911.03817v3 [cs.CL] UPDATED)</h2>
<h3>Kashif Khan, Gaurav Sahu, Vikash Balasubramanian, Lili Mou, Olga Vechtomova</h3>
<p>Generating relevant responses in a dialog is challenging, and requires not
only proper modeling of context in the conversation but also being able to
generate fluent sentences during inference. In this paper, we propose a
two-step framework based on generative adversarial nets for generating
conditioned responses. Our model first learns a meaningful representation of
sentences by autoencoding and then learns to map an input query to the response
representation, which is in turn decoded as a response sentence. Both
quantitative and qualitative evaluations show that our model generates more
fluent, relevant, and diverse responses than existing state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/1911.03817" target="_blank">arXiv:1911.03817</a> [<a href="http://arxiv.org/pdf/1911.03817" target="_blank">pdf</a>]

<h2>Clone Swarms: Learning to Predict and Control Multi-Robot Systems by Imitation. (arXiv:1912.02811v2 [cs.NE] UPDATED)</h2>
<h3>Siyu Zhou, Mariano Phielipp, Jorge A. Sefair, Sara I. Walker, Heni Ben Amor</h3>
<p>In this paper, we propose SwarmNet -- a neural network architecture that can
learn to predict and imitate the behavior of an observed swarm of agents in a
centralized manner. Tested on artificially generated swarm motion data, the
network achieves high levels of prediction accuracy and imitation authenticity.
We compare our model to previous approaches for modelling interaction systems
and show how modifying components of other models gradually approaches the
performance of ours. Finally, we also discuss an extension of SwarmNet that can
deal with nondeterministic, noisy, and uncertain environments, as often found
in robotics applications.
</p>
<a href="http://arxiv.org/abs/1912.02811" target="_blank">arXiv:1912.02811</a> [<a href="http://arxiv.org/pdf/1912.02811" target="_blank">pdf</a>]

<h2>Physical-Virtual Collaboration Modeling for Intra-and Inter-Station Metro Ridership Prediction. (arXiv:2001.04889v3 [cs.LG] UPDATED)</h2>
<h3>Lingbo Liu, Jingwen Chen, Hefeng Wu, Jiajie Zhen, Guanbin Li, Liang Lin</h3>
<p>Due to the widespread applications in real-world scenarios, metro ridership
prediction is a crucial but challenging task in intelligent transportation
systems. However, conventional methods either ignore the topological
information of metro systems or directly learn on physical topology, and cannot
fully explore the patterns of ridership evolution. To address this problem, we
model a metro system as graphs with various topologies and propose a unified
Physical-Virtual Collaboration Graph Network (PVCGN), which can effectively
learn the complex ridership patterns from the tailor-designed graphs.
Specifically, a physical graph is directly built based on the realistic
topology of the studied metro system, while a similarity graph and a
correlation graph are built with virtual topologies under the guidance of the
inter-station passenger flow similarity and correlation. These complementary
graphs are incorporated into a Graph Convolution Gated Recurrent Unit (GC-GRU)
for spatial-temporal representation learning. Further, a Fully-Connected Gated
Recurrent Unit (FC-GRU) is also applied to capture the global evolution
tendency. Finally, we develop a Seq2Seq model with GC-GRU and FC-GRU to
forecast the future metro ridership sequentially. Extensive experiments on two
large-scale benchmarks (e.g., Shanghai Metro and Hangzhou Metro) well
demonstrate the superiority of our PVCGN for station-level metro ridership
prediction. Moreover, we apply the proposed PVCGN to address the online
origin-destination (OD) ridership prediction and the experiment results show
the universality of our method. Our code and benchmarks are available at
https://github.com/HCPLab-SYSU/PVCGN.
</p>
<a href="http://arxiv.org/abs/2001.04889" target="_blank">arXiv:2001.04889</a> [<a href="http://arxiv.org/pdf/2001.04889" target="_blank">pdf</a>]

<h2>Gesticulator: A framework for semantically-aware speech-driven gesture generation. (arXiv:2001.09326v4 [cs.HC] UPDATED)</h2>
<h3>Taras Kucherenko, Patrik Jonell, Sanne van Waveren, Gustav Eje Henter, Simon Alexanderson, Iolanda Leite, Hedvig Kjellstr&#xf6;m</h3>
<p>During speech, people spontaneously gesticulate, which plays a key role in
conveying information. Similarly, realistic co-speech gestures are crucial to
enable natural and smooth interactions with social agents. Current end-to-end
co-speech gesture generation systems use a single modality for representing
speech: either audio or text. These systems are therefore confined to producing
either acoustically-linked beat gestures or semantically-linked gesticulation
(e.g., raising a hand when saying "high"): they cannot appropriately learn to
generate both gesture types. We present a model designed to produce arbitrary
beat and semantic gestures together. Our deep-learning based model takes both
acoustic and semantic representations of speech as input, and generates
gestures as a sequence of joint angle rotations as output. The resulting
gestures can be applied to both virtual agents and humanoid robots. Subjective
and objective evaluations confirm the success of our approach. The code and
video are available at the project page
https://svito-zar.github.io/gesticulator .
</p>
<a href="http://arxiv.org/abs/2001.09326" target="_blank">arXiv:2001.09326</a> [<a href="http://arxiv.org/pdf/2001.09326" target="_blank">pdf</a>]

<h2>Harvesting Ambient RF for Presence Detection Through Deep Learning. (arXiv:2002.05770v2 [cs.LG] UPDATED)</h2>
<h3>Yang Liu, Tiexing Wang, Yuexin Jiang, Biao Chen</h3>
<p>This paper explores the use of ambient radio frequency (RF) signals for human
presence detection through deep learning. Using WiFi signal as an example, we
demonstrate that the channel state information (CSI) obtained at the receiver
contains rich information about the propagation environment. Through judicious
pre-processing of the estimated CSI followed by deep learning, reliable
presence detection can be achieved. Several challenges in passive RF sensing
are addressed. With presence detection, how to collect training data with human
presence can have a significant impact on the performance. This is in contrast
to activity detection when a specific motion pattern is of interest. A second
challenge is that RF signals are complex-valued. Handling complex-valued input
in deep learning requires careful data representation and network architecture
design. Finally, human presence affects CSI variation along multiple
dimensions; such variation, however, is often masked by system impediments such
as timing or frequency offset. Addressing these challenges, the proposed
learning system uses pre-processing to preserve human motion induced channel
variation while insulating against other impairments. A convolutional neural
network (CNN) properly trained with both magnitude and phase information is
then designed to achieve reliable presence detection. Extensive experiments are
conducted. Using off-the-shelf WiFi devices, the proposed deep learning based
RF sensing achieves near perfect presence detection during multiple extended
periods of test and exhibits superior performance compared with leading edge
passive infrared sensors. Comparison with existing RF based human presence
detection also demonstrates its robustness in performance, especially when
deployed in a completely new environment.
</p>
<a href="http://arxiv.org/abs/2002.05770" target="_blank">arXiv:2002.05770</a> [<a href="http://arxiv.org/pdf/2002.05770" target="_blank">pdf</a>]

<h2>Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain Morphometric Data. (arXiv:2002.07699v2 [q-bio.QM] UPDATED)</h2>
<h3>Bo Peng, Xiaohui Yao, Shannon L. Risacher, Andrew J. Saykin, Li Shen, Xia Ning (for the Alzheimer&#x27;s Disease Neuroimaging Initiative)</h3>
<p>Background: Cognitive assessments represent the most common clinical routine
for the diagnosis of Alzheimer's Disease (AD). Given a large number of
cognitive assessment tools and time-limited office visits, determining a proper
set of cognitive tests is a widely studied topic. Most existing studies aim to
create selection guidelines for a targeted population but not for each
individual subject. In this manuscript, we develop a machine learning paradigm
enabling personalized cognitive assessments prioritization. Method: We adapt a
newly developed learning-to-rank method PLTR to implement our paradigm. This
method learns the latent scoring function that pushes the most effective
cognitive assessments on top of the prioritization list. We also extend PLTR to
better separate the most effective cognitive assessments and the less effective
ones. Results: Our empirical study on the ADNI data shows that the proposed
paradigm outperforms the state-of-the-art baselines on identifying and
prioritizing individual-specific cognitive biomarkers. We conduct experiments
in cross validation and level-out validation settings. In the two settings, our
paradigm significantly outperforms the best baselines with improvement as much
as 22.1% and 19.7%, respectively, on prioritizing cognitive features.
Conclusions: The proposed paradigm achieves superior performance on
prioritizing cognitive biomarkers. The top ranked cognitive biomarkers have the
potential to aid personalized diagnosis and disease subtyping, and to make
progress towards enabling precision medicine in AD.
</p>
<a href="http://arxiv.org/abs/2002.07699" target="_blank">arXiv:2002.07699</a> [<a href="http://arxiv.org/pdf/2002.07699" target="_blank">pdf</a>]

<h2>Learning to Walk in the Real World with Minimal Human Effort. (arXiv:2002.08550v3 [cs.RO] UPDATED)</h2>
<h3>Sehoon Ha, Peng Xu, Zhenyu Tan, Sergey Levine, Jie Tan</h3>
<p>Reliable and stable locomotion has been one of the most fundamental
challenges for legged robots. Deep reinforcement learning (deep RL) has emerged
as a promising method for developing such control policies autonomously. In
this paper, we develop a system for learning legged locomotion policies with
deep RL in the real world with minimal human effort. The key difficulties for
on-robot learning systems are automatic data collection and safety. We overcome
these two challenges by developing a multi-task learning procedure and a
safety-constrained RL framework. We tested our system on the task of learning
to walk on three different terrains: flat ground, a soft mattress, and a
doormat with crevices. Our system can automatically and efficiently learn
locomotion skills on a Minitaur robot with little human intervention. The
supplemental video can be found at: \url{https://youtu.be/cwyiq6dCgOc}.
</p>
<a href="http://arxiv.org/abs/2002.08550" target="_blank">arXiv:2002.08550</a> [<a href="http://arxiv.org/pdf/2002.08550" target="_blank">pdf</a>]

<h2>Adversarial Attacks on Machine Learning Systems for High-Frequency Trading. (arXiv:2002.09565v3 [cs.LG] UPDATED)</h2>
<h3>Micah Goldblum, Avi Schwarzschild, Ankit B. Patel, Tom Goldstein</h3>
<p>Algorithmic trading systems are often completely automated, and deep learning
is increasingly receiving attention in this domain. Nonetheless, little is
known about the robustness properties of these models. We study valuation
models for algorithmic trading from the perspective of adversarial machine
learning. We introduce new attacks specific to this domain with size
constraints that minimize attack costs. We further discuss how these attacks
can be used as an analysis tool to study and evaluate the robustness properties
of financial models. Finally, we investigate the feasibility of realistic
adversarial attacks in which an adversarial trader fools automated trading
systems into making inaccurate predictions.
</p>
<a href="http://arxiv.org/abs/2002.09565" target="_blank">arXiv:2002.09565</a> [<a href="http://arxiv.org/pdf/2002.09565" target="_blank">pdf</a>]

<h2>A Self-Tuning Actor-Critic Algorithm. (arXiv:2002.12928v4 [stat.ML] UPDATED)</h2>
<h3>Tom Zahavy, Zhongwen Xu, Vivek Veeriah, Matteo Hessel, Junhyuk Oh, Hado van Hasselt, David Silver, Satinder Singh</h3>
<p>Reinforcement learning algorithms are highly sensitive to the choice of
hyperparameters, typically requiring significant manual effort to identify
hyperparameters that perform well on a new domain. In this paper, we take a
step towards addressing this issue by using metagradients to automatically
adapt hyperparameters online by meta-gradient descent (Xu et al., 2018). We
apply our algorithm, Self-Tuning Actor-Critic (STAC), to self-tune all the
differentiable hyperparameters of an actor-critic loss function, to discover
auxiliary tasks, and to improve off-policy learning using a novel leaky V-trace
operator. STAC is simple to use, sample efficient and does not require a
significant increase in compute. Ablative studies show that the overall
performance of STAC improved as we adapt more hyperparameters. When applied to
the Arcade Learning Environment (Bellemare et al. 2012), STAC improved the
median human normalized score in 200M steps from 243% to 364%. When applied to
the DM Control suite (Tassa et al., 2018), STAC improved the mean score in 30M
steps from 217 to 389 when learning with features, from 108 to 202 when
learning from pixels, and from 195 to 295 in the Real-World Reinforcement
Learning Challenge (Dulac-Arnold et al., 2020).
</p>
<a href="http://arxiv.org/abs/2002.12928" target="_blank">arXiv:2002.12928</a> [<a href="http://arxiv.org/pdf/2002.12928" target="_blank">pdf</a>]

<h2>Nonlinear Functional Output Regression: a Dictionary Approach. (arXiv:2003.01432v3 [stat.ML] UPDATED)</h2>
<h3>Dimitri Bouche, Marianne Clausel, Fran&#xe7;ois Roueff, Florence d&#x27;Alch&#xe9;-Buc</h3>
<p>To address functional-output regression, we introduce projection learning, a
novel dictionary-based approach that learns to predict a projection of the
output function on a dictionary while minimizing a functional loss. Projection
learning makes it possible to use non orthogonal dictionaries and can then be
combined with dictionary learning. It is thus much more flexible than
expansion-based approaches relying on vectorial losses. Using reproducing
kernel Hilbert spaces of vector-valued functions, this general method is
instantiated as kernel-based projection learning (KPL). For the functional
square loss, we propose two closed-form estimators, one for fully observed
output functions and the other for partially observed ones. Both are backed
theoretically by an excess risk analysis. Then, in the more general setting of
integral losses based on differentiable ground losses, KPL is implemented using
first-order optimization for both fully and partially observed output
functions. Eventually, several robustness aspects of the proposed algorithms
are highlighted on a toy dataset; and a study on two real datasets shows that
they are competitive compared to other nonlinear approaches while keeping the
computational cost significantly lower.
</p>
<a href="http://arxiv.org/abs/2003.01432" target="_blank">arXiv:2003.01432</a> [<a href="http://arxiv.org/pdf/2003.01432" target="_blank">pdf</a>]

<h2>Towards Fair Cross-Domain Adaptation via Generative Learning. (arXiv:2003.02366v2 [cs.CV] UPDATED)</h2>
<h3>Tongxin Wang, Zhengming Ding, Wei Shao, Haixu Tang, Kun Huang</h3>
<p>Domain Adaptation (DA) targets at adapting a model trained over the
well-labeled source domain to the unlabeled target domain lying in different
distributions. Existing DA normally assumes the well-labeled source domain is
class-wise balanced, which means the size per source class is relatively
similar. However, in real-world applications, labeled samples for some
categories in the source domain could be extremely few due to the difficulty of
data collection and annotation, which leads to decreasing performance over
target domain on those few-shot categories. To perform fair cross-domain
adaptation and boost the performance on these minority categories, we develop a
novel Generative Few-shot Cross-domain Adaptation (GFCA) algorithm for fair
cross-domain classification. Specifically, generative feature augmentation is
explored to synthesize effective training data for few-shot source classes,
while effective cross-domain alignment aims to adapt knowledge from source to
facilitate the target learning. Experimental results on two large cross-domain
visual datasets demonstrate the effectiveness of our proposed method on
improving both few-shot and overall classification accuracy comparing with the
state-of-the-art DA approaches.
</p>
<a href="http://arxiv.org/abs/2003.02366" target="_blank">arXiv:2003.02366</a> [<a href="http://arxiv.org/pdf/2003.02366" target="_blank">pdf</a>]

<h2>Contention-Driven Feature Extraction for Low-Regret Contextual Bandit-Based Channel Selection Dedicated to Wireless LANs. (arXiv:2003.10094v2 [cs.NI] UPDATED)</h2>
<h3>Kota Yamashita, Shotaro Kamiya, Koji Yamamoto, Takayuki Nishio, Masahiro Morikura</h3>
<p>To achieve low-regret learning in a radio channel selection for wireless
local area networks (WLANs), we propose a contention-driven feature extraction
(FE) scheme for a contextual multi-armed bandit (CMAB) algorithm. This study
aims to learn the optimal WLAN channel online particularly in a scalable manner
with respect to the number of APs and channels, which is accomplished by
leveraging the context, i.e., channel allocation information. The proposed FE
is designed by focusing on contention with neighboring and same-channel APs
where the key idea is to consolidate contexts ignoring APs that are not
connected to the target AP on the contention graph. The simulation results
confirm that contention-driven FE enables a target AP to learn the optimal
channel in a scalable manner for the number of APs and available channels and
to have low regret using the CMAB algorithm.
</p>
<a href="http://arxiv.org/abs/2003.10094" target="_blank">arXiv:2003.10094</a> [<a href="http://arxiv.org/pdf/2003.10094" target="_blank">pdf</a>]

<h2>Learning-based Handover in Mobile Millimeter-wave Networks. (arXiv:2003.11009v2 [eess.SP] UPDATED)</h2>
<h3>Sara Khosravi, Hossein S. Ghadikolaei, Marina Petrova</h3>
<p>Millimeter-wave (mmWave) communication is considered as a key enabler of
ultra-high data rates in the future cellular and wireless networks. The need
for directional communication between base stations (BSs) and users in mmWave
systems, that is achieved through beamforming, increases the complexity of the
channel estimation. Moreover, in order to provide better coverage, dense
deployment of BSs is required which causes frequent handovers and increased
association overhead. In this paper, we present an approach that jointly
addresses the beamforming and handover problems. Our solution entails an
efficient beamforming method with a minimum number of pilots and a
learning-based handover method supporting mobile scenarios. We use
reinforcement learning algorithm to learn the optimal choices of the backup BSs
in different locations of a mobile user. We show that our method provides high
rate and reliability in all locations of the user's trajectory with a minimal
number of handovers. Simulation results in an outdoor environment based on
geometric mmWave channel modeling and real building map data show the superior
performance of our proposed solution in achievable instantaneous rate and
trajectory rate.
</p>
<a href="http://arxiv.org/abs/2003.11009" target="_blank">arXiv:2003.11009</a> [<a href="http://arxiv.org/pdf/2003.11009" target="_blank">pdf</a>]

<h2>On Infinite-Width Hypernetworks. (arXiv:2003.12193v6 [cs.LG] UPDATED)</h2>
<h3>Etai Littwin, Tomer Galanti, Lior Wolf, Greg Yang</h3>
<p>{\em Hypernetworks} are architectures that produce the weights of a
task-specific {\em primary network}. A notable application of hypernetworks in
the recent literature involves learning to output functional representations.
In these scenarios, the hypernetwork learns a representation corresponding to
the weights of a shallow MLP, which typically encodes shape or image
information. While such representations have seen considerable success in
practice, they remain lacking in the theoretical guarantees in the wide regime
of the standard architectures. In this work, we study wide over-parameterized
hypernetworks. We show that unlike typical architectures, infinitely wide
hypernetworks do not guarantee convergence to a global minima under gradient
descent. We further show that convexity can be achieved by increasing the
dimensionality of the hypernetwork's output, to represent wide MLPs. In the
dually infinite-width regime, we identify the functional priors of these
architectures by deriving their corresponding GP and NTK kernels, the latter of
which we refer to as the {\em hyperkernel}. As part of this study, we make a
mathematical contribution by deriving tight bounds on high order Taylor
expansion terms of standard fully connected ReLU networks.
</p>
<a href="http://arxiv.org/abs/2003.12193" target="_blank">arXiv:2003.12193</a> [<a href="http://arxiv.org/pdf/2003.12193" target="_blank">pdf</a>]

<h2>Better Sign Language Translation with STMC-Transformer. (arXiv:2004.00588v2 [cs.CL] UPDATED)</h2>
<h3>Kayo Yin, Jesse Read</h3>
<p>Sign Language Translation (SLT) first uses a Sign Language Recognition (SLR)
system to extract sign language glosses from videos. Then, a translation system
generates spoken language translations from the sign language glosses. This
paper focuses on the translation system and introduces the STMC-Transformer
which improves on the current state-of-the-art by over 5 and 7 BLEU
respectively on gloss-to-text and video-to-text translation of the
PHOENIX-Weather 2014T dataset. On the ASLG-PC12 corpus, we report an increase
of over 16 BLEU.

We also demonstrate the problem in current methods that rely on gloss
supervision. The video-to-text translation of our STMC-Transformer outperforms
translation of GT glosses. This contradicts previous claims that GT gloss
translation acts as an upper bound for SLT performance and reveals that glosses
are an inefficient representation of sign language. For future SLT research, we
therefore suggest an end-to-end training of the recognition and translation
models, or using a different sign language annotation scheme.
</p>
<a href="http://arxiv.org/abs/2004.00588" target="_blank">arXiv:2004.00588</a> [<a href="http://arxiv.org/pdf/2004.00588" target="_blank">pdf</a>]

<h2>Robust Large-Margin Learning in Hyperbolic Space. (arXiv:2004.05465v2 [cs.LG] UPDATED)</h2>
<h3>Melanie Weber, Manzil Zaheer, Ankit Singh Rawat, Aditya Menon, Sanjiv Kumar</h3>
<p>Recently, there has been a surge of interest in representation learning in
hyperbolic spaces, driven by their ability to represent hierarchical data with
significantly fewer dimensions than standard Euclidean spaces. However, the
viability and benefits of hyperbolic spaces for downstream machine learning
tasks have received less attention. In this paper, we present, to our
knowledge, the first theoretical guarantees for learning a classifier in
hyperbolic rather than Euclidean space. Specifically, we consider the problem
of learning a large-margin classifier for data possessing a hierarchical
structure. Our first contribution is a hyperbolic perceptron algorithm, which
provably converges to a separating hyperplane. We then provide an algorithm to
efficiently learn a large-margin hyperplane, relying on the careful injection
of adversarial examples. Finally, we prove that for hierarchical data that
embeds well into hyperbolic space, the low embedding dimension ensures superior
guarantees when learning the classifier directly in hyperbolic space.
</p>
<a href="http://arxiv.org/abs/2004.05465" target="_blank">arXiv:2004.05465</a> [<a href="http://arxiv.org/pdf/2004.05465" target="_blank">pdf</a>]

<h2>Deep-Edge: An Efficient Framework for Deep Learning Model Update on Heterogeneous Edge. (arXiv:2004.05740v2 [cs.DC] UPDATED)</h2>
<h3>Anirban Bhattacharjee, Ajay Dev Chhokra, Hongyang Sun, Shashank Shekhar, Aniruddha Gokhale, Gabor Karsai, Abhishek Dubey</h3>
<p>Deep Learning (DL) model-based AI services are increasingly offered in a
variety of predictive analytics services such as computer vision, natural
language processing, speech recognition. However, the quality of the DL models
can degrade over time due to changes in the input data distribution, thereby
requiring periodic model updates. Although cloud data-centers can meet the
computational requirements of the resource-intensive and time-consuming model
update task, transferring data from the edge devices to the cloud incurs a
significant cost in terms of network bandwidth and are prone to data privacy
issues. With the advent of GPU-enabled edge devices, the DL model update can be
performed at the edge in a distributed manner using multiple connected edge
devices. However, efficiently utilizing the edge resources for the model update
is a hard problem due to the heterogeneity among the edge devices and the
resource interference caused by the co-location of the DL model update task
with latency-critical tasks running in the background. To overcome these
challenges, we present Deep-Edge, a load- and interference-aware,
fault-tolerant resource management framework for performing model update at the
edge that uses distributed training. This paper makes the following
contributions. First, it provides a unified framework for monitoring,
profiling, and deploying the DL model update tasks on heterogeneous edge
devices. Second, it presents a scheduler that reduces the total re-training
time by appropriately selecting the edge devices and distributing data among
them such that no latency-critical applications experience deadline violations.
Finally, we present empirical results to validate the efficacy of the framework
using a real-world DL model update case-study based on the Caltech dataset and
an edge AI cluster testbed.
</p>
<a href="http://arxiv.org/abs/2004.05740" target="_blank">arXiv:2004.05740</a> [<a href="http://arxiv.org/pdf/2004.05740" target="_blank">pdf</a>]

<h2>Private Learning of Halfspaces: Simplifying the Construction and Reducing the Sample Complexity. (arXiv:2004.07839v2 [cs.LG] UPDATED)</h2>
<h3>Haim Kaplan, Yishay Mansour, Uri Stemmer, Eliad Tsfadia</h3>
<p>We present a differentially private learner for halfspaces over a finite grid
$G$ in $\mathbb{R}^d$ with sample complexity $\approx d^{2.5}\cdot
2^{\log^*|G|}$, which improves the state-of-the-art result of [Beimel et al.,
COLT 2019] by a $d^2$ factor. The building block for our learner is a new
differentially private algorithm for approximately solving the linear
feasibility problem: Given a feasible collection of $m$ linear constraints of
the form $Ax\geq b$, the task is to privately identify a solution $x$ that
satisfies most of the constraints. Our algorithm is iterative, where each
iteration determines the next coordinate of the constructed solution $x$.
</p>
<a href="http://arxiv.org/abs/2004.07839" target="_blank">arXiv:2004.07839</a> [<a href="http://arxiv.org/pdf/2004.07839" target="_blank">pdf</a>]

<h2>An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction. (arXiv:2005.00652v3 [cs.CL] UPDATED)</h2>
<h3>Bhargavi Paranjape, Mandar Joshi, John Thickstun, Hannaneh Hajishirzi, Luke Zettlemoyer</h3>
<p>Decisions of complex language understanding models can be rationalized by
limiting their inputs to a relevant subsequence of the original text. A
rationale should be as concise as possible without significantly degrading task
performance, but this balance can be difficult to achieve in practice. In this
paper, we show that it is possible to better manage this trade-off by
optimizing a bound on the Information Bottleneck (IB) objective. Our fully
unsupervised approach jointly learns an explainer that predicts sparse binary
masks over sentences, and an end-task predictor that considers only the
extracted rationale. Using IB, we derive a learning objective that allows
direct control of mask sparsity levels through a tunable sparse prior.
Experiments on ERASER benchmark tasks demonstrate significant gains over
norm-minimization techniques for both task performance and agreement with human
rationales. Furthermore, we find that in the semi-supervised setting, a modest
amount of gold rationales (25% of training examples) closes the gap with a
model that uses the full input.
</p>
<a href="http://arxiv.org/abs/2005.00652" target="_blank">arXiv:2005.00652</a> [<a href="http://arxiv.org/pdf/2005.00652" target="_blank">pdf</a>]

<h2>Performance and safety of Bayesian model predictive control: Scalable model-based RL with guarantees. (arXiv:2006.03483v2 [eess.SY] UPDATED)</h2>
<h3>Kim P. Wabersich, Melanie N. Zeilinger</h3>
<p>Despite the success of reinforcement learning (RL) in various research
fields, relatively few algorithms have been applied to industrial control
applications. The reason for this unexplored potential is partly related to the
significant required tuning effort, large numbers of required learning
episodes, i.e. experiments, and the limited availability of RL methods that can
address high dimensional and safety-critical dynamical systems with continuous
state and action spaces. By building on model predictive control (MPC)
concepts, we propose a cautious model-based reinforcement learning algorithm to
mitigate these limitations. While the underlying policy of the approach can be
efficiently implemented in the form of a standard MPC controller,
data-efficient learning is achieved through posterior sampling techniques. We
provide a rigorous performance analysis of the resulting `Bayesian MPC'
algorithm by establishing Lipschitz continuity of the corresponding future
reward function and bound the expected number of unsafe learning episodes using
an exact penalty soft-constrained MPC formulation. The efficiency and
scalability of the method are illustrated using a 100-dimensional server
cooling example and a nonlinear 10-dimensional drone example by comparing the
performance against nominal posterior MPC, which is commonly used for
data-driven control of constrained dynamical systems.
</p>
<a href="http://arxiv.org/abs/2006.03483" target="_blank">arXiv:2006.03483</a> [<a href="http://arxiv.org/pdf/2006.03483" target="_blank">pdf</a>]

<h2>Input-independent Attention Weights Are Expressive Enough: A Study of Attention in Self-supervised Audio Transformers. (arXiv:2006.05174v2 [eess.AS] UPDATED)</h2>
<h3>Tsung-Han Wu, Chun-Chen Hsieh, Yen-Hao Chen, Po-Han Chi, Hung-yi Lee</h3>
<p>In this paper, we seek solutions for reducing the computation complexity of
transformer-based models for speech representation learning. We evaluate 10
attention algorithms; then, we pre-train the transformer-based model with those
attention algorithms in a self-supervised fashion and treat them as feature
extractors on downstream tasks, including phoneme classification and speaker
classification. With the assistance of t-SNE, PCA and some observation, the
attention weights in self-supervised audio transformers can be categorized into
four general cases. Based on these cases and some analyses, we are able to use
a specific set of attention weights to initialize the model. Our approach shows
comparable performance to the typical self-attention yet requires 20% less time
in both training and inference.
</p>
<a href="http://arxiv.org/abs/2006.05174" target="_blank">arXiv:2006.05174</a> [<a href="http://arxiv.org/pdf/2006.05174" target="_blank">pdf</a>]

<h2>Applying Deep-Learning-Based Computer Vision to Wireless Communications: Methodologies, Opportunities, and Challenges. (arXiv:2006.05782v3 [eess.SP] UPDATED)</h2>
<h3>Yu Tian, Gaofeng Pan, Mohamed-Slim Alouini</h3>
<p>Deep learning (DL) has seen great success in the computer vision (CV) field,
and related techniques have been used in security, healthcare, remote sensing,
and many other fields. As a parallel development, visual data has become
universal in daily life, easily generated by ubiquitous low-cost cameras.
Therefore, exploring DL-based CV may yield useful information about objects,
such as their number, locations, distribution, motion, etc. Intuitively,
DL-based CV can also facilitate and improve the designs of wireless
communications, especially in dynamic network scenarios. However, so far, such
work is rare in the literature. The primary purpose of this article, then, is
to introduce ideas about applying DL-based CV in wireless communications to
bring some novel degrees of freedom to both theoretical research and
engineering applications. To illustrate how DL-based CV can be applied in
wireless communications, an example of using a DL-based CV with a
millimeter-wave (mmWave) system is given to realize optimal mmWave
multiple-input and multiple-output (MIMO) beamforming in mobile scenarios. In
this example, we propose a framework to predict future beam indices from
previously observed beam indices and images of street views using ResNet,
3-dimensional ResNext, and a long short-term memory network. The experimental
results show that our frameworks achieve much higher accuracy than the baseline
method, and that visual data can significantly improve the performance of the
MIMO beamforming system. Finally, we discuss the opportunities and challenges
of applying DL-based CV in wireless communications.
</p>
<a href="http://arxiv.org/abs/2006.05782" target="_blank">arXiv:2006.05782</a> [<a href="http://arxiv.org/pdf/2006.05782" target="_blank">pdf</a>]

<h2>On the Feasibility of Perfect Resilience with Local Fast Failover. (arXiv:2006.06513v2 [cs.NI] UPDATED)</h2>
<h3>Klaus-Tycho Foerster, Juho Hirvonen, Yvonne-Anne Pignolet, Stefan Schmid, Gilles Tredan</h3>
<p>In order to provide a high resilience and to react quickly to link failures,
modern computer networks support fully decentralized flow rerouting, also known
as local fast failover. In a nutshell, the task of a local fast failover
algorithm is to pre-define fast failover rules for each node using locally
available information only. These rules determine for each incoming link from
which a packet may arrive and the set of local link failures (i.e., the failed
links incident to a node), on which outgoing link a packet should be forwarded.
Ideally, such a local fast failover algorithm provides a perfect resilience
deterministically: a packet emitted from any source can reach any target, as
long as the underlying network remains connected. Feigenbaum et al. (ACM PODC
2012) and also Chiesa et al. (IEEE/ACM Trans. Netw. 2017) showed that it is not
always possible to provide perfect resilience. Interestingly, not much more is
known currently about the feasibility of perfect resilience.

This paper revisits perfect resilience with local fast failover, both in a
model where the source can and cannot be used for forwarding decisions. We
first derive several fairly general impossibility results: By establishing a
connection between graph minors and resilience, we prove that it is impossible
to achieve perfect resilience on any non-planar graph; furthermore, while
planarity is necessary, it is also not sufficient for perfect resilience. On
the positive side, we show that graph families closed under link subdivision
allow for simple and efficient failover algorithms which simply skip failed
links. We demonstrate this technique by deriving perfect resilience for
outerplanar graphs and related scenarios, as well as for scenarios where the
source and target are topologically close after failures.
</p>
<a href="http://arxiv.org/abs/2006.06513" target="_blank">arXiv:2006.06513</a> [<a href="http://arxiv.org/pdf/2006.06513" target="_blank">pdf</a>]

<h2>NeuroCard: One Cardinality Estimator for All Tables. (arXiv:2006.08109v2 [cs.DB] UPDATED)</h2>
<h3>Zongheng Yang, Amog Kamsetty, Sifei Luan, Eric Liang, Yan Duan, Xi Chen, Ion Stoica</h3>
<p>Query optimizers rely on accurate cardinality estimates to produce good
execution plans. Despite decades of research, existing cardinality estimators
are inaccurate for complex queries, due to making lossy modeling assumptions
and not capturing inter-table correlations. In this work, we show that it is
possible to learn the correlations across all tables in a database without any
independence assumptions. We present NeuroCard, a join cardinality estimator
that builds a single neural density estimator over an entire database.
Leveraging join sampling and modern deep autoregressive models, NeuroCard makes
no inter-table or inter-column independence assumptions in its probabilistic
modeling. NeuroCard achieves orders of magnitude higher accuracy than the best
prior methods (a new state-of-the-art result of 8.5$\times$ maximum error on
JOB-light), scales to dozens of tables, while being compact in space (several
MBs) and efficient to construct or update (seconds to minutes).
</p>
<a href="http://arxiv.org/abs/2006.08109" target="_blank">arXiv:2006.08109</a> [<a href="http://arxiv.org/pdf/2006.08109" target="_blank">pdf</a>]

<h2>On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them. (arXiv:2006.08403v2 [cs.LG] UPDATED)</h2>
<h3>Chen Liu, Mathieu Salzmann, Tao Lin, Ryota Tomioka, Sabine S&#xfc;sstrunk</h3>
<p>We analyze the influence of adversarial training on the loss landscape of
machine learning models. To this end, we first provide analytical studies of
the properties of adversarial loss functions under different adversarial
budgets. We then demonstrate that the adversarial loss landscape is less
favorable to optimization, due to increased curvature and more scattered
gradients. Our conclusions are validated by numerical analyses, which show that
training under large adversarial budgets impede the escape from suboptimal
random initialization, cause non-vanishing gradients and make the model find
sharper minima. Based on these observations, we show that a periodic
adversarial scheduling (PAS) strategy can effectively overcome these
challenges, yielding better results than vanilla adversarial training while
being much less sensitive to the choice of learning rate.
</p>
<a href="http://arxiv.org/abs/2006.08403" target="_blank">arXiv:2006.08403</a> [<a href="http://arxiv.org/pdf/2006.08403" target="_blank">pdf</a>]

<h2>De-Anonymizing Text by Fingerprinting Language Generation. (arXiv:2006.09615v2 [cs.CR] UPDATED)</h2>
<h3>Zhen Sun, Roei Schuster, Vitaly Shmatikov</h3>
<p>Components of machine learning systems are not (yet) perceived as security
hotspots. Secure coding practices, such as ensuring that no execution paths
depend on confidential inputs, have not yet been adopted by ML developers. We
initiate the study of code security of ML systems by investigating how nucleus
sampling---a popular approach for generating text, used for applications such
as auto-completion---unwittingly leaks texts typed by users. Our main result is
that the series of nucleus sizes for many natural English word sequences is a
unique fingerprint. We then show how an attacker can infer typed text by
measuring these fingerprints via a suitable side channel (e.g., cache access
times), explain how this attack could help de-anonymize anonymous texts, and
discuss defenses.
</p>
<a href="http://arxiv.org/abs/2006.09615" target="_blank">arXiv:2006.09615</a> [<a href="http://arxiv.org/pdf/2006.09615" target="_blank">pdf</a>]

<h2>HyNet: Learning Local Descriptor with Hybrid Similarity Measure and Triplet Loss. (arXiv:2006.10202v2 [cs.CV] UPDATED)</h2>
<h3>Yurun Tian, Axel Barroso-Laguna, Tony Ng, Vassileios Balntas, Krystian Mikolajczyk</h3>
<p>Recent works show that local descriptor learning benefits from the use of L2
normalisation, however, an in-depth analysis of this effect lacks in the
literature. In this paper, we investigate how L2 normalisation affects the
back-propagated descriptor gradients during training. Based on our
observations, we propose HyNet, a new local descriptor that leads to
state-of-the-art results in matching. HyNet introduces a hybrid similarity
measure for triplet margin loss, a regularisation term constraining the
descriptor norm, and a new network architecture that performs L2 normalisation
of all intermediate feature maps and the output descriptors. HyNet surpasses
previous methods by a significant margin on standard benchmarks that include
patch matching, verification, and retrieval, as well as outperforming full
end-to-end methods on 3D reconstruction tasks.
</p>
<a href="http://arxiv.org/abs/2006.10202" target="_blank">arXiv:2006.10202</a> [<a href="http://arxiv.org/pdf/2006.10202" target="_blank">pdf</a>]

<h2>FISAR: Forward Invariant Safe Reinforcement Learning with a Deep Neural Network-Based Optimize. (arXiv:2006.11419v3 [cs.LG] UPDATED)</h2>
<h3>Chuangchuang Sun, Dong-Ki Kim, Jonathan P. How</h3>
<p>This paper investigates reinforcement learning with constraints, which are
indispensable in safety-critical environments. To drive the constraint
violation monotonically decrease, we take the constraints as Lyapunov functions
and impose new linear constraints on the policy parameters' updating dynamics.
As a result, the original safety set can be forward-invariant. However, because
the new guaranteed-feasible constraints are imposed on the updating dynamics
instead of the original policy parameters, classic optimization algorithms are
no longer applicable. To address this, we propose to learn a generic deep
neural network (DNN)-based optimizer to optimize the objective while satisfying
the linear constraints. The constraint-satisfaction is achieved via projection
onto a polytope formulated by multiple linear inequality constraints, which can
be solved analytically with our newly designed metric. To the best of our
knowledge, this is the \textit{first} DNN-based optimizer for constrained
optimization with the forward invariance guarantee. We show that our optimizer
trains a policy to decrease the constraint violation and maximize the
cumulative reward monotonically. Results on numerical constrained optimization
and obstacle-avoidance navigation validate the theoretical findings.
</p>
<a href="http://arxiv.org/abs/2006.11419" target="_blank">arXiv:2006.11419</a> [<a href="http://arxiv.org/pdf/2006.11419" target="_blank">pdf</a>]

<h2>P3GM: Private High-Dimensional Data Release via Privacy Preserving Phased Generative Model. (arXiv:2006.12101v2 [cs.LG] UPDATED)</h2>
<h3>Shun Takagi, Tsubasa Takahashi, Yang Cao, Masatoshi Yoshikawa</h3>
<p>How can we release a massive volume of sensitive data while mitigating
privacy risks? Privacy-preserving data synthesis enables the data holder to
outsource analytical tasks to an untrusted third party. The state-of-the-art
approach for this problem is to build a generative model under differential
privacy, which offers a rigorous privacy guarantee. However, the existing
method cannot adequately handle high dimensional data. In particular, when the
input dataset contains a large number of features, the existing techniques
require injecting a prohibitive amount of noise to satisfy differential
privacy, which results in the outsourced data analysis meaningless. To address
the above issue, this paper proposes privacy-preserving phased generative model
(P3GM), which is a differentially private generative model for releasing such
sensitive data. P3GM employs the two-phase learning process to make it robust
against the noise, and to increase learning efficiency (e.g., easy to
converge). We give theoretical analyses about the learning complexity and
privacy loss in P3GM. We further experimentally evaluate our proposed method
and demonstrate that P3GM significantly outperforms existing solutions.
Compared with the state-of-the-art methods, our generated samples look fewer
noises and closer to the original data in terms of data diversity. Besides, in
several data mining tasks with synthesized data, our model outperforms the
competitors in terms of accuracy.
</p>
<a href="http://arxiv.org/abs/2006.12101" target="_blank">arXiv:2006.12101</a> [<a href="http://arxiv.org/pdf/2006.12101" target="_blank">pdf</a>]

<h2>Fairness without Demographics through Adversarially Reweighted Learning. (arXiv:2006.13114v3 [cs.LG] UPDATED)</h2>
<h3>Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, Nithum Thain, Xuezhi Wang, Ed H. Chi</h3>
<p>Much of the previous machine learning (ML) fairness literature assumes that
protected features such as race and sex are present in the dataset, and relies
upon them to mitigate fairness concerns. However, in practice factors like
privacy and regulation often preclude the collection of protected features, or
their use for training or inference, severely limiting the applicability of
traditional fairness research. Therefore we ask: How can we train an ML model
to improve fairness when we do not even know the protected group memberships?
In this work we address this problem by proposing Adversarially Reweighted
Learning (ARL). In particular, we hypothesize that non-protected features and
task labels are valuable for identifying fairness issues, and can be used to
co-train an adversarial reweighting approach for improving fairness. Our
results show that {ARL} improves Rawlsian Max-Min fairness, with notable AUC
improvements for worst-case protected groups in multiple datasets,
outperforming state-of-the-art alternatives.
</p>
<a href="http://arxiv.org/abs/2006.13114" target="_blank">arXiv:2006.13114</a> [<a href="http://arxiv.org/pdf/2006.13114" target="_blank">pdf</a>]

<h2>Joint Object Detection and Multi-Object Tracking with Graph Neural Networks. (arXiv:2006.13164v2 [cs.CV] UPDATED)</h2>
<h3>Yongxin Wang, Kris Kitani, Xinshuo Weng</h3>
<p>Object detection and data association are critical components in multi-object
tracking (MOT) systems. Despite the fact that the two components are dependent
on each other, prior work often designs detection and data association modules
separately which are trained with different objectives. As a result, we cannot
back-propagate the gradients and optimize the entire MOT system, which leads to
sub-optimal performance. To address this issue, recent work simultaneously
optimizes detection and data association modules under a joint MOT framework,
which has shown improved performance in both modules. In this work, we propose
a new instance of joint MOT approach based on Graph Neural Networks (GNNs). The
key idea is that GNNs can model relations between variable-sized objects in
both the spatial and temporal domains, which is essential for learning
discriminative features for detection and data association. Through extensive
experiments on the MOT15/16/17/20 datasets, we demonstrate the effectiveness of
our GNN-based joint MOT approach and show the state-of-the-art performance for
both detection and MOT tasks.
</p>
<a href="http://arxiv.org/abs/2006.13164" target="_blank">arXiv:2006.13164</a> [<a href="http://arxiv.org/pdf/2006.13164" target="_blank">pdf</a>]

<h2>ELMV: an Ensemble-Learning Approach for Analyzing Electrical Health Records with Significant Missing Values. (arXiv:2006.14942v2 [cs.LG] UPDATED)</h2>
<h3>Lucas J. Liu, Hongwei Zhang, Jianzhong Di, Jin Chen</h3>
<p>Many real-world Electronic Health Record (EHR) data contains a large
proportion of missing values. Leaving substantial portion of missing
information unaddressed usually causes significant bias, which leads to invalid
conclusion to be drawn. On the other hand, training a machine learning model
with a much smaller nearly-complete subset can drastically impact the
reliability and accuracy of model inference. Data imputation algorithms that
attempt to replace missing data with meaningful values inevitably increase the
variability of effect estimates with increased missingness, making it
unreliable for hypothesis validation. We propose a novel Ensemble-Learning for
Missing Value (ELMV) framework, which introduces an effective approach to
construct multiple subsets of the original EHR data with a much lower missing
rate, as well as mobilizing a dedicated support set for the ensemble learning
in the purpose of reducing the bias caused by substantial missing values. ELMV
has been evaluated on a real-world healthcare data for critical feature
identification as well as a batch of simulation data with different missing
rates for outcome prediction. On both experiments, ELMV clearly outperforms
conventional missing value imputation methods and ensemble learning models.
</p>
<a href="http://arxiv.org/abs/2006.14942" target="_blank">arXiv:2006.14942</a> [<a href="http://arxiv.org/pdf/2006.14942" target="_blank">pdf</a>]

<h2>Rapid Transitions with Robust Accelerated Delayed Self Reinforcement for Consensus-Based Networks. (arXiv:2006.16295v2 [eess.SY] UPDATED)</h2>
<h3>Anuj Tiwari, Santosh Devasia</h3>
<p>Rapid transitions are important for quick response of consensus-based,
multi-agent networks to external stimuli. While high-gain can increase response
speed, potential instability tends to limit the maximum possible gain, and
therefore, limits the maximum convergence rate to consensus during transitions.
Since the update law for multi-agent networks with symmetric graphs can be
considered as the gradient of its Laplacian-potential function, Nesterov-type
accelerated-gradient approaches from optimization theory, can further improve
the convergence rate of such networks. An advantage of the accelerated-gradient
approach is that it can be implemented using accelerated
delayed-self-reinforcement (A-DSR), which does not require new information from
the network nor modifications in the network connectivity. However, the
accelerated-gradient approach is not directly applicable to general directed
graphs since the update law is not the gradient of the Laplacian-potential
function. The main contribution of this work is to extend the
accelerated-gradient approach to general directed graph networks, without
requiring the graph to be strongly connected. Additionally, while both the
momentum term and outdated-feedback term in the accelerated-gradient approach
are important in general, it is shown that the momentum term alone is
sufficient to achieve balanced robustness and rapid transitions without
oscillations in the dominant mode, for networks whose graph Laplacians have
real spectrum. Simulation results are presented to illustrate the performance
improvement with the proposed Robust A-DSR of 40% in structural robustness and
50% in convergence rate to consensus, when compared to the case without the
A-DSR. Moreover, experimental results are presented that show a similar 37%
faster convergence with the Robust A-DSR when compared to the case without the
A-DSR.
</p>
<a href="http://arxiv.org/abs/2006.16295" target="_blank">arXiv:2006.16295</a> [<a href="http://arxiv.org/pdf/2006.16295" target="_blank">pdf</a>]

<h2>Applying Machine Learning Techniques for Caching in Edge Networks: A Comprehensive Survey. (arXiv:2006.16864v4 [cs.NI] UPDATED)</h2>
<h3>Junaid Shuja, Kashif Bilal, Waleed Alasmary, Hassan Sinky, Eisa Alanazi</h3>
<p>Edge networking is a complex and dynamic computing paradigm that aims to push
cloud resources closer to the end user improving responsiveness and reducing
backhaul traffic. User mobility, preferences, and content popularity are the
dominant dynamic features of edge networks. Temporal and social features of
content, such as the number of views and likes are leveraged to estimate the
popularity of content from a global perspective. However, such estimates should
not be mapped to an edge network with particular social and geographic
characteristics. In next generation edge networks, i.e., 5G and beyond 5G,
machine learning techniques can be applied to predict content popularity based
on user preferences, cluster users based on similar content interests, and
optimize cache placement and replacement strategies provided a set of
constraints and predictions about the state of the network. These applications
of machine learning can help identify relevant content for an edge network.
This article investigates the application of machine learning techniques for
in-network caching in edge networks. We survey recent state-of-the-art
literature and formulate a comprehensive taxonomy based on (a) machine learning
technique (method, objective, and features), (b) caching strategy (policy,
location, and replacement), and (c) edge network (type and delivery strategy).
A comparative analysis of the state-of-the-art literature is presented with
respect to the parameters identified in the taxonomy. Moreover, we debate
research challenges and future directions for optimal caching decisions and the
application of machine learning in edge networks.
</p>
<a href="http://arxiv.org/abs/2006.16864" target="_blank">arXiv:2006.16864</a> [<a href="http://arxiv.org/pdf/2006.16864" target="_blank">pdf</a>]

<h2>3D Shape Reconstruction from Vision and Touch. (arXiv:2007.03778v2 [cs.CV] UPDATED)</h2>
<h3>Edward J. Smith, Roberto Calandra, Adriana Romero, Georgia Gkioxari, David Meger, Jitendra Malik, Michal Drozdzal</h3>
<p>When a toddler is presented a new toy, their instinctual behaviour is to pick
it upand inspect it with their hand and eyes in tandem, clearly searching over
its surface to properly understand what they are playing with. At any instance
here, touch provides high fidelity localized information while vision provides
complementary global context. However, in 3D shape reconstruction, the
complementary fusion of visual and haptic modalities remains largely
unexplored. In this paper, we study this problem and present an effective
chart-based approach to multi-modal shape understanding which encourages a
similar fusion vision and touch information.To do so, we introduce a dataset of
simulated touch and vision signals from the interaction between a robotic hand
and a large array of 3D objects. Our results show that (1) leveraging both
vision and touch signals consistently improves single-modality baselines; (2)
our approach outperforms alternative modality fusion methods and strongly
benefits from the proposed chart-based structure; (3) there construction
quality increases with the number of grasps provided; and (4) the touch
information not only enhances the reconstruction at the touch site but also
extrapolates to its local neighborhood.
</p>
<a href="http://arxiv.org/abs/2007.03778" target="_blank">arXiv:2007.03778</a> [<a href="http://arxiv.org/pdf/2007.03778" target="_blank">pdf</a>]

<h2>InfoMax-GAN: Improved Adversarial Image Generation via Information Maximization and Contrastive Learning. (arXiv:2007.04589v4 [cs.LG] UPDATED)</h2>
<h3>Kwot Sin Lee, Ngoc-Trung Tran, Ngai-Man Cheung</h3>
<p>While Generative Adversarial Networks (GANs) are fundamental to many
generative modelling applications, they suffer from numerous issues. In this
work, we propose a principled framework to simultaneously address two
fundamental issues in GANs: catastrophic forgetting of the discriminator and
mode collapse of the generator. We achieve this by employing for GANs a
contrastive learning and mutual information maximization approach, and perform
extensive analyses to understand sources of improvements. Our approach
significantly stabilizes GAN training and improves GAN performance for image
synthesis across five datasets under the same training and evaluation
conditions against state-of-the-art works. Our approach is simple to implement
and practical: it involves only one auxiliary objective, has low computational
cost, and performs robustly across a wide range of training settings and
datasets without any hyperparameter tuning. For reproducibility, our code is
available at https://github.com/kwotsin/mimicry.
</p>
<a href="http://arxiv.org/abs/2007.04589" target="_blank">arXiv:2007.04589</a> [<a href="http://arxiv.org/pdf/2007.04589" target="_blank">pdf</a>]

<h2>Self-supervised Auxiliary Learning with Meta-paths for Heterogeneous Graphs. (arXiv:2007.08294v4 [cs.LG] UPDATED)</h2>
<h3>Dasol Hwang, Jinyoung Park, Sunyoung Kwon, Kyung-Min Kim, Jung-Woo Ha, Hyunwoo J. Kim</h3>
<p>Graph neural networks have shown superior performance in a wide range of
applications providing a powerful representation of graph-structured data.
Recent works show that the representation can be further improved by auxiliary
tasks. However, the auxiliary tasks for heterogeneous graphs, which contain
rich semantic information with various types of nodes and edges, have less
explored in the literature. In this paper, to learn graph neural networks on
heterogeneous graphs we propose a novel self-supervised auxiliary learning
method using meta-paths, which are composite relations of multiple edge types.
Our proposed method is learning to learn a primary task by predicting
meta-paths as auxiliary tasks. This can be viewed as a type of meta-learning.
The proposed method can identify an effective combination of auxiliary tasks
and automatically balance them to improve the primary task. Our methods can be
applied to any graph neural networks in a plug-in manner without manual
labeling or additional data. The experiments demonstrate that the proposed
method consistently improves the performance of link prediction and node
classification on heterogeneous graphs.
</p>
<a href="http://arxiv.org/abs/2007.08294" target="_blank">arXiv:2007.08294</a> [<a href="http://arxiv.org/pdf/2007.08294" target="_blank">pdf</a>]

<h2>A robot that counts like a child: a developmental model of counting and pointing. (arXiv:2008.02366v2 [cs.LG] UPDATED)</h2>
<h3>Leszek Pecyna, Angelo Cangelosi, Alessandro Di Nuovo</h3>
<p>In this paper, a novel neuro-robotics model capable of counting real items is
introduced. The model allows us to investigate the interaction between
embodiment and numerical cognition. This is composed of a deep neural network
capable of image processing and sequential tasks performance, and a robotic
platform providing the embodiment - the iCub humanoid robot. The network is
trained using images from the robot's cameras and proprioceptive signals from
its joints. The trained model is able to count a set of items and at the same
time points to them. We investigate the influence of pointing on the counting
process and compare our results with those from studies with children. Several
training approaches are presented in this paper all of them uses pre-training
routine allowing the network to gain the ability of pointing and number
recitation (from 1 to 10) prior to counting training. The impact of the counted
set size and distance to the objects are investigated. The obtained results on
counting performance show similarities with those from human studies.
</p>
<a href="http://arxiv.org/abs/2008.02366" target="_blank">arXiv:2008.02366</a> [<a href="http://arxiv.org/pdf/2008.02366" target="_blank">pdf</a>]

<h2>Image Colorization: A Survey and Dataset. (arXiv:2008.10774v2 [cs.CV] UPDATED)</h2>
<h3>Saeed Anwar, Muhammad Tahir, Chongyi Li, Ajmal Mian, Fahad Shahbaz Khan, Abdul Wahab Muzaffar</h3>
<p>Image colorization is an essential image processing and computer vision
branch to colorize images and videos. Recently, deep learning techniques
progressed notably for image colorization. This article presents a
comprehensive survey of recent state-of-the-art colorization using deep
learning algorithms, describing their fundamental block architectures in terms
of skip connections, input etc. as well as optimizers, loss functions, training
protocols, and training data etc. Generally, we can roughly categorize the
existing colorization techniques into seven classes. Besides, we also provide
some additional essential issues, such as benchmark datasets and evaluation
metrics. We also introduce a new dataset specific to colorization and perform
an experimental evaluation of the publicly available methods. In the last
section, we discuss the limitations, possible solutions, and future research
directions of the rapidly evolving topic of deep image colorization that the
community should further address. Dataset and Codes for evaluation will be
publicly available at https://github.com/saeed-anwar/ColorSurvey
</p>
<a href="http://arxiv.org/abs/2008.10774" target="_blank">arXiv:2008.10774</a> [<a href="http://arxiv.org/pdf/2008.10774" target="_blank">pdf</a>]

<h2>On estimating gaze by self-attention augmented convolutions. (arXiv:2008.11055v2 [cs.CV] UPDATED)</h2>
<h3>Gabriel Lefundes, Luciano Oliveira</h3>
<p>Estimation of 3D gaze is highly relevant to multiple fields, including but
not limited to interactive systems, specialized human-computer interfaces, and
behavioral research. Although recently deep learning methods have boosted the
accuracy of appearance-based gaze estimation, there is still room for
improvement in the network architectures for this particular task. Therefore we
propose here a novel network architecture grounded on self-attention augmented
convolutions to improve the quality of the learned features during the training
of a shallower residual network. The rationale is that self-attention mechanism
can help outperform deeper architectures by learning dependencies between
distant regions in full-face images. This mechanism can also create better and
more spatially-aware feature representations derived from the face and eye
images before gaze regression. We dubbed our framework ARes-gaze, which
explores our Attention-augmented ResNet (ARes-14) as twin convolutional
backbones. In our experiments, results showed a decrease of the average angular
error by 2.38% when compared to state-of-the-art methods on the MPIIFaceGaze
data set, and a second-place on the EyeDiap data set. It is noteworthy that our
proposed framework was the only one to reach high accuracy simultaneously on
both data sets.
</p>
<a href="http://arxiv.org/abs/2008.11055" target="_blank">arXiv:2008.11055</a> [<a href="http://arxiv.org/pdf/2008.11055" target="_blank">pdf</a>]

<h2>Learning Obstacle Representations for Neural Motion Planning. (arXiv:2008.11174v3 [cs.RO] UPDATED)</h2>
<h3>Robin Strudel, Ricardo Garcia, Justin Carpentier, Jean-Paul Laumond, Ivan Laptev, Cordelia Schmid</h3>
<p>Motion planning and obstacle avoidance is a key challenge in robotics
applications. While previous work succeeds to provide excellent solutions for
known environments, sensor-based motion planning in new and dynamic
environments remains difficult. In this work we address sensor-based motion
planning from a learning perspective. Motivated by recent advances in visual
recognition, we argue the importance of learning appropriate representations
for motion planning. We propose a new obstacle representation based on the
PointNet architecture and train it jointly with policies for obstacle
avoidance. We experimentally evaluate our approach for rigid body motion
planning in challenging environments and demonstrate significant improvements
of the state of the art in terms of accuracy and efficiency.
</p>
<a href="http://arxiv.org/abs/2008.11174" target="_blank">arXiv:2008.11174</a> [<a href="http://arxiv.org/pdf/2008.11174" target="_blank">pdf</a>]

<h2>From the digital data revolution to digital health and digital economy toward a digital society: Pervasiveness of Artificial Intelligence. (arXiv:2008.12672v2 [cs.GL] UPDATED)</h2>
<h3>Frank Emmert-Streib</h3>
<p>Technological progress has led to powerful computers and communication
technologies that penetrate nowadays all areas of science, industry and our
private lives. As a consequence, all these areas are generating digital traces
of data amounting to big data resources. This opens unprecedented opportunities
but also challenges toward the analysis, management, interpretation and
utilization of these data. Fortunately, recent breakthroughs in deep learning
algorithms complement now machine learning and statistics methods for an
efficient analysis of such data. Furthermore, advances in text mining and
natural language processing, e.g., word-embedding methods, enable also the
processing of large amounts of text data from diverse sources as governmental
reports, blog entries in social media or clinical health records of patients.
In this paper, we present a perspective on the role of artificial intelligence
in these developments and discuss also potential problems we are facing in a
digital society.
</p>
<a href="http://arxiv.org/abs/2008.12672" target="_blank">arXiv:2008.12672</a> [<a href="http://arxiv.org/pdf/2008.12672" target="_blank">pdf</a>]

<h2>Benchmarking Metric Ground Navigation. (arXiv:2008.13315v3 [cs.RO] UPDATED)</h2>
<h3>Daniel Perille, Abigail Truong, Xuesu Xiao, Peter Stone</h3>
<p>Metric ground navigation addresses the problem of autonomously moving a robot
from one point to another in an obstacle-occupied planar environment in a
collision-free manner. It is one of the most fundamental capabilities of
intelligent mobile robots. This paper presents a standardized testbed with a
set of environments and metrics to benchmark difficulty of different scenarios
and performance of different systems of metric ground navigation. Current
benchmarks focus on individual components of mobile robot navigation, such as
perception and state estimation, but the navigation performance as a whole is
rarely measured in a systematic and standardized fashion. As a result,
navigation systems are usually tested and compared in an ad hoc manner, such as
in one or two manually chosen environments. The introduced benchmark provides a
general testbed for ground robot navigation in a metric world. The Benchmark
for Autonomous Robot Navigation (BARN) dataset includes 300 navigation
environments, which are ordered by a set of difficulty metrics. Navigation
performance can be tested and compared in those environments in a systematic
and objective fashion. This benchmark can be used to predict navigation
difficulty of a new environment, compare navigation systems, and potentially
serve as a cost function and a curriculum for planning-based and learning-based
navigation systems. We have published our dataset and the source code to
generate datasets for different robot footprints at
www.cs.utexas.edu/~xiao/BARN/BARN.html.
</p>
<a href="http://arxiv.org/abs/2008.13315" target="_blank">arXiv:2008.13315</a> [<a href="http://arxiv.org/pdf/2008.13315" target="_blank">pdf</a>]

<h2>An Algorithm for Out-Of-Distribution Attack to Neural Network Encoder. (arXiv:2009.08016v3 [cs.CV] UPDATED)</h2>
<h3>Liang Liang, Linhai Ma, Linchen Qian, Jiasong Chen</h3>
<p>Deep neural network (DNN), especially convolutional neural network, has
achieved superior performance on image classification tasks. However, such
performance is only guaranteed if the input to a trained model is similar to
the training samples, i.e., the input follows the probability distribution of
the training set. Out-Of-Distribution (OOD) samples do not follow the
distribution of training set, and therefore the predicted class labels on OOD
samples become meaningless. Classification-based methods have been proposed for
OOD detection; however, in this study we show that this type of method is
theoretically ineffective and practically breakable because of dimensionality
reduction in the model. We also show that Glow likelihood-based OOD detection
is ineffective as well. Our analysis is demonstrated on five open datasets,
including a COVID-19 CT dataset. At last, we present a simple theoretical
solution with guaranteed performance for OOD detection.
</p>
<a href="http://arxiv.org/abs/2009.08016" target="_blank">arXiv:2009.08016</a> [<a href="http://arxiv.org/pdf/2009.08016" target="_blank">pdf</a>]

<h2>Review: Deep Learning in Electron Microscopy. (arXiv:2009.08328v4 [eess.IV] UPDATED)</h2>
<h3>Jeffrey M. Ede</h3>
<p>Deep learning is transforming most areas of science and technology, including
electron microscopy. This review paper offers a practical perspective aimed at
developers with limited familiarity. For context, we review popular
applications of deep learning in electron microscopy. Following, we discuss
hardware and software needed to get started with deep learning and interface
with electron microscopes. We then review neural network components, popular
architectures, and their optimization. Finally, we discuss future directions of
deep learning in electron microscopy.
</p>
<a href="http://arxiv.org/abs/2009.08328" target="_blank">arXiv:2009.08328</a> [<a href="http://arxiv.org/pdf/2009.08328" target="_blank">pdf</a>]

<h2>A Principle of Least Action for the Training of Neural Networks. (arXiv:2009.08372v2 [stat.ML] UPDATED)</h2>
<h3>Skander Karkar, Ibrahhim Ayed, Emmanuel de B&#xe9;zenac, Patrick Gallinari</h3>
<p>Neural networks have been achieving high generalization performance on many
tasks despite being highly over-parameterized. Since classical statistical
learning theory struggles to explain this behavior, much effort has recently
been focused on uncovering the mechanisms behind it, in the hope of developing
a more adequate theoretical framework and having a better control over the
trained models. In this work, we adopt an alternate perspective, viewing the
neural network as a dynamical system displacing input particles over time. We
conduct a series of experiments and, by analyzing the network's behavior
through its displacements, we show the presence of a low kinetic energy
displacement bias in the transport map of the network, and link this bias with
generalization performance. From this observation, we reformulate the learning
problem as follows: finding neural networks which solve the task while
transporting the data as efficiently as possible. This offers a novel
formulation of the learning problem which allows us to provide regularity
results for the solution network, based on Optimal Transport theory. From a
practical viewpoint, this allows us to propose a new learning algorithm, which
automatically adapts to the complexity of the given task, and leads to networks
with a high generalization ability even in low data regimes.
</p>
<a href="http://arxiv.org/abs/2009.08372" target="_blank">arXiv:2009.08372</a> [<a href="http://arxiv.org/pdf/2009.08372" target="_blank">pdf</a>]

<h2>Projection Mapping Implementation: Enabling Direct Externalization of Perception Results and Action Intent to Improve Robot Explainability. (arXiv:2010.02263v2 [cs.RO] UPDATED)</h2>
<h3>Zhao Han, Alexander Wilkinson, Jenna Parrillo, Jordan Allspaw, Holly A. Yanco</h3>
<p>Existing research on non-verbal cues, e.g., eye gaze or arm movement, may not
accurately present a robot's internal states such as perception results and
action intent. Projecting the states directly onto a robot's operating
environment has the advantages of being direct, accurate, and more salient,
eliminating mental inference about the robot's intention. However, there is a
lack of tools for projection mapping in robotics, compared to established
motion planning libraries (e.g., MoveIt). In this paper, we detail the
implementation of projection mapping to enable researchers and practitioners to
push the boundaries for better interaction between robots and humans. We also
provide practical documentation and code for a sample manipulation projection
mapping on GitHub: https://github.com/uml-robotics/projection_mapping.
</p>
<a href="http://arxiv.org/abs/2010.02263" target="_blank">arXiv:2010.02263</a> [<a href="http://arxiv.org/pdf/2010.02263" target="_blank">pdf</a>]

<h2>Feature Extraction of Text for Deep Learning Algorithms: Application on Fake News Detection. (arXiv:2010.05496v2 [cs.CL] UPDATED)</h2>
<h3>HyeonJun Kim</h3>
<p>Feature extraction is an important process of machine learning and deep
learning, as the process make algorithms function more efficiently, and also
accurate. In natural language processing used in deception detection such as
fake news detection, several ways of feature extraction in statistical aspect
had been introduced (e.g. N-gram). In this research, it will be shown that by
using deep learning algorithms and alphabet frequencies of the original text of
a news without any information about the sequence of the alphabet can actually
be used to classify fake news and trustworthy ones in high accuracy (85\%). As
this pre-processing method makes the data notably compact but also include the
feature that is needed for the classifier, it seems that alphabet frequencies
contains some useful features for understanding complex context or meaning of
the original text.
</p>
<a href="http://arxiv.org/abs/2010.05496" target="_blank">arXiv:2010.05496</a> [<a href="http://arxiv.org/pdf/2010.05496" target="_blank">pdf</a>]

<h2>Analysis of Twitter and YouTube during USelections 2020. (arXiv:2010.08183v3 [cs.SI] UPDATED)</h2>
<h3>Alexander Shevtsov, Maria Oikonomidou, Despoina Antonakaki, Polyvios Pratikakis, Sotiris Ioannidis</h3>
<p>The upcoming November 2020 presidential elections in the United States have
caused extensive discussions on social media. A part of the content on US
elections is organic, coming from users discussing their opinions of the
candidates, political positions, or relevant content presented on television.
Another significant part of the content generated originates from organized
campaigns, both official and by astroturfing.

In this study, we obtain approximately 17.5 M tweets containing 3M users,
based on prevalent hashtags related to US election 2020, as well as the related
YouTube links, contained in the Twitter dataset, likes, dislikes and comments
of the videos and conduct volume, sentiment and graph analysis on the
communities formed. Particularly, we study the daily traffic per prevalent
hashtags and show the evolution of the retweet graph from July to September
2020, highlighting the two main entities ('Biden' and 'Trump') contained in our
dataset. Additionally, we gather the related YouTube links contained in the
previous dataset and perform sentiment analysis. The results on sentiment
analysis on the Twitter corpus and the YouTube metadata gathered, show the
positive and negative sentiment for the two entities throughout this period.
The results of sentiment analysis indicate that 45.7% express positive
sentiment towards Trump in Twitter and 33.8% positive sentiment towards Biden,
while 14.55% of users express positive sentiment in YouTube metadata gathered
towards Trump and 8.7% positive sentiment towards Biden. Our analysis fill the
gap between the connection of offline events and their consequences in social
media by monitoring important events in real world and measuring public volume
and sentiment before and after the event in social media.
</p>
<a href="http://arxiv.org/abs/2010.08183" target="_blank">arXiv:2010.08183</a> [<a href="http://arxiv.org/pdf/2010.08183" target="_blank">pdf</a>]

<h2>Semantics of the Black-Box: Can knowledge graphs help make deep learning systems more interpretable and explainable?. (arXiv:2010.08660v3 [cs.AI] UPDATED)</h2>
<h3>Manas Gaur, Keyur Faldu, Amit Sheth</h3>
<p>The recent series of innovations in deep learning (DL) have shown enormous
potential to impact individuals and society, both positively and negatively.
The DL models utilizing massive computing power and enormous datasets have
significantly outperformed prior historical benchmarks on increasingly
difficult, well-defined research tasks across technology domains such as
computer vision, natural language processing, signal processing, and
human-computer interactions. However, the Black-Box nature of DL models and
their over-reliance on massive amounts of data condensed into labels and dense
representations poses challenges for interpretability and explainability of the
system. Furthermore, DLs have not yet been proven in their ability to
effectively utilize relevant domain knowledge and experience critical to human
understanding. This aspect is missing in early data-focused approaches and
necessitated knowledge-infused learning and other strategies to incorporate
computational knowledge. This article demonstrates how knowledge, provided as a
knowledge graph, is incorporated into DL methods using knowledge-infused
learning, which is one of the strategies. We then discuss how this makes a
fundamental difference in the interpretability and explainability of current
approaches, and illustrate it with examples from natural language processing
for healthcare and education applications.
</p>
<a href="http://arxiv.org/abs/2010.08660" target="_blank">arXiv:2010.08660</a> [<a href="http://arxiv.org/pdf/2010.08660" target="_blank">pdf</a>]

<h2>RONELD: Robust Neural Network Output Enhancement for Active Lane Detection. (arXiv:2010.09548v2 [cs.CV] UPDATED)</h2>
<h3>Zhe Ming Chng, Joseph Mun Hung Lew, Jimmy Addison Lee</h3>
<p>Accurate lane detection is critical for navigation in autonomous vehicles,
particularly the active lane which demarcates the single road space that the
vehicle is currently traveling on. Recent state-of-the-art lane detection
algorithms utilize convolutional neural networks (CNNs) to train deep learning
models on popular benchmarks such as TuSimple and CULane. While each of these
models works particularly well on train and test inputs obtained from the same
dataset, the performance drops significantly on unseen datasets of different
environments. In this paper, we present a real-time robust neural network
output enhancement for active lane detection (RONELD) method to identify,
track, and optimize active lanes from deep learning probability map outputs. We
first adaptively extract lane points from the probability map outputs, followed
by detecting curved and straight lanes before using weighted least squares
linear regression on straight lanes to fix broken lane edges resulting from
fragmentation of edge maps in real images. Lastly, we hypothesize true active
lanes through tracking preceding frames. Experimental results demonstrate an up
to two-fold increase in accuracy using RONELD on cross-dataset validation
tests.
</p>
<a href="http://arxiv.org/abs/2010.09548" target="_blank">arXiv:2010.09548</a> [<a href="http://arxiv.org/pdf/2010.09548" target="_blank">pdf</a>]

<h2>FLAP -- A Federated Learning Framework for Attribute-based Access Control Policies. (arXiv:2010.09767v2 [cs.CR] UPDATED)</h2>
<h3>Amani Abu Jabal, Elisa Bertino, Jorge Lobo, Dinesh Verma, Seraphin Calo, Alessandra Russo</h3>
<p>Technology advances in areas such as sensors, IoT, and robotics, enable new
collaborative applications (e.g., autonomous devices). A primary requirement
for such collaborations is to have a secure system which enables information
sharing and information flow protection. Policy-based management system is a
key mechanism for secure selective sharing of protected resources. However,
policies in each party of such a collaborative environment cannot be static as
they have to adapt to different contexts and situations. One advantage of
collaborative applications is that each party in the collaboration can take
advantage of knowledge of the other parties for learning or enhancing its own
policies. We refer to this learning mechanism as policy transfer. The design of
a policy transfer framework has challenges, including policy conflicts and
privacy issues. Policy conflicts typically arise because of differences in the
obligations of the parties, whereas privacy issues result because of data
sharing constraints for sensitive data. Hence, the policy transfer framework
should be able to tackle such challenges by considering minimal sharing of data
and support policy adaptation to address conflict. In the paper we propose a
framework that aims at addressing such challenges. We introduce a formal
definition of the policy transfer problem for attribute-based policies. We then
introduce the transfer methodology that consists of three sequential steps.
Finally we report experimental results.
</p>
<a href="http://arxiv.org/abs/2010.09767" target="_blank">arXiv:2010.09767</a> [<a href="http://arxiv.org/pdf/2010.09767" target="_blank">pdf</a>]

<h2>"It is just a flu": Assessing the Effect of Watch History on YouTube's Pseudoscientific Video Recommendations. (arXiv:2010.11638v2 [cs.CY] UPDATED)</h2>
<h3>Kostantinos Papadamou, Savvas Zannettou, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca Stringhini, Michael Sirivianos</h3>
<p>YouTube has revolutionized the way people discover and consume videos,
becoming one of the primary news sources for Internet users. Since content on
YouTube is generated by its users, the platform is particularly vulnerable to
misinformative and conspiratorial videos. Even worse, the role played by
YouTube's recommendation algorithm in unwittingly promoting questionable
content is not well understood, and could potentially make the problem even
worse. This can have dire real-world consequences, especially when
pseudoscientific content is promoted to users at critical times, e.g., during
the COVID-19 pandemic.

In this paper, we set out to characterize and detect pseudoscientific
misinformation on YouTube. We collect 6.6K videos related to COVID-19, the flat
earth theory, the anti-vaccination, and anti-mask movements; using
crowdsourcing, we annotate them as pseudoscience, legitimate science, or
irrelevant. We then train a deep learning classifier to detect pseudoscientific
videos with an accuracy of 76.1%. Next, we quantify user exposure to this
content on various parts of the platform (i.e., a user's homepage, recommended
videos while watching a specific video, or search results) and how this
exposure changes based on the user's watch history. We find that YouTube's
recommendation algorithm is more aggressive in suggesting pseudoscientific
content when users are searching for specific topics, while these
recommendations are less common on a user's homepage or when actively watching
pseudoscientific videos. Finally, we shed light on how a user's watch history
substantially affects the type of recommended videos.
</p>
<a href="http://arxiv.org/abs/2010.11638" target="_blank">arXiv:2010.11638</a> [<a href="http://arxiv.org/pdf/2010.11638" target="_blank">pdf</a>]

<h2>Unsupervised Representation Learning by InvariancePropagation. (arXiv:2010.11694v2 [cs.CV] UPDATED)</h2>
<h3>Feng Wang, Huaping Liu, Di Guo, Fuchun Sun</h3>
<p>Unsupervised learning methods based on contrastive learning have drawn
increasing attention and achieved promising results. Most of them aim to learn
representations invariant to instance-level variations, which are provided by
different views of the same instance. In this paper, we propose Invariance
Propagation to focus on learning representations invariant to category-level
variations, which are provided by different instances from the same category.
Our method recursively discovers semantically consistent samples residing in
the same high-density regions in representation space. We demonstrate a hard
sampling strategy to concentrate on maximizing the agreement between the anchor
sample and its hard positive samples, which provide more intra-class variations
to help capture more abstract invariance. As a result, with a ResNet-50 as the
backbone, our method achieves 71.3% top-1 accuracy on ImageNet linear
classification and 78.2% top-5 accuracy fine-tuning on only 1% labels,
surpassing previous results. We also achieve state-of-the-art performance on
other downstream tasks, including linear classification on Places205 and Pascal
VOC, and transfer learning on small scale datasets.
</p>
<a href="http://arxiv.org/abs/2010.11694" target="_blank">arXiv:2010.11694</a> [<a href="http://arxiv.org/pdf/2010.11694" target="_blank">pdf</a>]

<h2>Temporal Attention-Augmented Graph Convolutional Network for Efficient Skeleton-Based Human Action Recognition. (arXiv:2010.12221v2 [cs.CV] UPDATED)</h2>
<h3>Negar Heidari, Alexandros Iosifidis</h3>
<p>Graph convolutional networks (GCNs) have been very successful in modeling
non-Euclidean data structures, like sequences of body skeletons forming actions
modeled as spatio-temporal graphs. Most GCN-based action recognition methods
use deep feed-forward networks with high computational complexity to process
all skeletons in an action. This leads to a high number of floating point
operations (ranging from 16G to 100G FLOPs) to process a single sample, making
their adoption in restricted computation application scenarios infeasible. In
this paper, we propose a temporal attention module (TAM) for increasing the
efficiency in skeleton-based action recognition by selecting the most
informative skeletons of an action at the early layers of the network. We
incorporate the TAM in a light-weight GCN topology to further reduce the
overall number of computations. Experimental results on two benchmark datasets
show that the proposed method outperforms with a large margin the baseline
GCN-based method while having 2.9 times less number of computations. Moreover,
it performs on par with the state-of-the-art with up to 9.6 times less number
of computations.
</p>
<a href="http://arxiv.org/abs/2010.12221" target="_blank">arXiv:2010.12221</a> [<a href="http://arxiv.org/pdf/2010.12221" target="_blank">pdf</a>]

<h2>Combining Label Propagation and Simple Models Out-performs Graph Neural Networks. (arXiv:2010.13993v2 [cs.LG] UPDATED)</h2>
<h3>Qian Huang, Horace He, Abhay Singh, Ser-Nam Lim, Austin R. Benson</h3>
<p>Graph Neural Networks (GNNs) are the predominant technique for learning over
graphs. However, there is relatively little understanding of why GNNs are
successful in practice and whether they are necessary for good performance.
Here, we show that for many standard transductive node classification
benchmarks, we can exceed or match the performance of state-of-the-art GNNs by
combining shallow models that ignore the graph structure with two simple
post-processing steps that exploit correlation in the label structure: (i) an
"error correlation" that spreads residual errors in training data to correct
errors in test data and (ii) a "prediction correlation" that smooths the
predictions on the test data. We call this overall procedure Correct and Smooth
(C&amp;S), and the post-processing steps are implemented via simple modifications
to standard label propagation techniques from early graph-based semi-supervised
learning methods. Our approach exceeds or nearly matches the performance of
state-of-the-art GNNs on a wide variety of benchmarks, with just a small
fraction of the parameters and orders of magnitude faster runtime. For
instance, we exceed the best known GNN performance on the OGB-Products dataset
with 137 times fewer parameters and greater than 100 times less training time.
The performance of our methods highlights how directly incorporating label
information into the learning algorithm (as was done in traditional techniques)
yields easy and substantial performance gains. We can also incorporate our
techniques into big GNN models, providing modest gains. Our code for the OGB
results is at https://github.com/Chillee/CorrectAndSmooth.
</p>
<a href="http://arxiv.org/abs/2010.13993" target="_blank">arXiv:2010.13993</a> [<a href="http://arxiv.org/pdf/2010.13993" target="_blank">pdf</a>]

<h2>Learning to Infer Unseen Attribute-Object Compositions. (arXiv:2010.14343v2 [cs.CV] UPDATED)</h2>
<h3>Hui Chen, Zhixiong Nan, Jingjing Jiang, Nanning Zheng</h3>
<p>The composition recognition of unseen attribute-object is critical to make
machines learn to decompose and compose complex concepts like people. Most of
the existing methods are limited to the composition recognition of
single-attribute-object, and can hardly distinguish the compositions with
similar appearances. In this paper, a graph-based model is proposed that can
flexibly recognize both single- and multi-attribute-object compositions. The
model maps the visual features of images and the attribute-object category
labels represented by word embedding vectors into a latent space. Then,
according to the constraints of the attribute-object semantic association,
distances are calculated between visual features and the corresponding label
semantic features in the latent space. During the inference, the composition
that is closest to the given image feature among all compositions is used as
the reasoning result. In addition, we build a large-scale Multi-Attribute
Dataset (MAD) with 116,099 images and 8,030 composition categories. Experiments
on MAD and two other single-attribute-object benchmark datasets demonstrate the
effectiveness of our approach.
</p>
<a href="http://arxiv.org/abs/2010.14343" target="_blank">arXiv:2010.14343</a> [<a href="http://arxiv.org/pdf/2010.14343" target="_blank">pdf</a>]

<h2>Micro Stripes Analyses for Iris Presentation Attack Detection. (arXiv:2010.14850v2 [cs.CV] UPDATED)</h2>
<h3>Meiling Fang, Naser Damer, Florian Kirchbuchner, Arjan Kuijper</h3>
<p>Iris recognition systems are vulnerable to the presentation attacks, such as
textured contact lenses or printed images. In this paper, we propose a
lightweight framework to detect iris presentation attacks by extracting
multiple micro-stripes of expanded normalized iris textures. In this procedure,
a standard iris segmentation is modified. For our presentation attack detection
network to better model the classification problem, the segmented area is
processed to provide lower dimensional input segments and a higher number of
learning samples. Our proposed Micro Stripes Analyses (MSA) solution samples
the segmented areas as individual stripes. Then, the majority vote makes the
final classification decision of those micro-stripes. Experiments are
demonstrated on five databases, where two databases (IIITD-WVU and Notre Dame)
are from the LivDet-2017 Iris competition. An in-depth experimental evaluation
of this framework reveals a superior performance compared with state-of-the-art
algorithms. Moreover, our solution minimizes the confusion between textured
(attack) and soft (bona fide) contact lens presentations.
</p>
<a href="http://arxiv.org/abs/2010.14850" target="_blank">arXiv:2010.14850</a> [<a href="http://arxiv.org/pdf/2010.14850" target="_blank">pdf</a>]

<h2>Genetic U-Net: Automatically Designing Lightweight U-shaped CNN Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation. (arXiv:2010.15560v3 [eess.IV] UPDATED)</h2>
<h3>Jiahong Wei, Zhun Fan</h3>
<p>Many previous works based on deep learning for retinal vessel segmentation
have achieved promising performance by manually designing U-shaped
convolutional neural networks (CNNs). However, the manual design of these CNNs
is time-consuming and requires extensive empirical knowledge. To address this
problem, we propose a novel method using genetic algorithms (GAs) to
automatically design a lightweight U-shaped CNN for retinal vessel
segmentation, called Genetic U-Net. Here we first design a special search space
containing the structure of U-Net and its corresponding operations, and then
use genetic algorithm to search for superior architectures in this search
space. Experimental results show that the proposed method outperforms the
existing methods on three public datasets, DRIVE, CHASE\_DB1 and STARE. In
addition, the architectures obtained by the proposed method are more
lightweight but accurate than the state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2010.15560" target="_blank">arXiv:2010.15560</a> [<a href="http://arxiv.org/pdf/2010.15560" target="_blank">pdf</a>]

<h2>Passport-aware Normalization for Deep Model Protection. (arXiv:2010.15824v2 [cs.CV] UPDATED)</h2>
<h3>Jie Zhang, Dongdong Chen, Jing Liao, Weiming Zhang, Gang Hua, Nenghai Yu</h3>
<p>Despite tremendous success in many application scenarios, deep learning faces
serious intellectual property (IP) infringement threats. Considering the cost
of designing and training a good model, infringements will significantly
infringe the interests of the original model owner. Recently, many impressive
works have emerged for deep model IP protection. However, they either are
vulnerable to ambiguity attacks, or require changes in the target network
structure by replacing its original normalization layers and hence cause
significant performance drops. To this end, we propose a new passport-aware
normalization formulation, which is generally applicable to most existing
normalization layers and only needs to add another passport-aware branch for IP
protection. This new branch is jointly trained with the target model but
discarded in the inference stage. Therefore it causes no structure change in
the target model. Only when the model IP is suspected to be stolen by someone,
the private passport-aware branch is added back for ownership verification.
Through extensive experiments, we verify its effectiveness in both image and 3D
point recognition models. It is demonstrated to be robust not only to common
attack techniques like fine-tuning and model compression, but also to ambiguity
attacks. By further combining it with trigger-set based methods, both black-box
and white-box verification can be achieved for enhanced security of deep
learning models deployed in real systems. Code can be found at
https://github.com/ZJZAC/Passport-aware-Normalization.
</p>
<a href="http://arxiv.org/abs/2010.15824" target="_blank">arXiv:2010.15824</a> [<a href="http://arxiv.org/pdf/2010.15824" target="_blank">pdf</a>]

<h2>Leveraging Natural Language Processing to Mine Issues on Twitter During the COVID-19 Pandemic. (arXiv:2011.00377v2 [cs.IR] UPDATED)</h2>
<h3>Ankita Agarwal, Preetham Salehundam, Swati Padhee, William L. Romine, Tanvi Banerjee</h3>
<p>The recent global outbreak of the coronavirus disease (COVID-19) has spread
to all corners of the globe. The international travel ban, panic buying, and
the need for self-quarantine are among the many other social challenges brought
about in this new era. Twitter platforms have been used in various public
health studies to identify public opinion about an event at the local and
global scale. To understand the public concerns and responses to the pandemic,
a system that can leverage machine learning techniques to filter out irrelevant
tweets and identify the important topics of discussion on social media
platforms like Twitter is needed. In this study, we constructed a system to
identify the relevant tweets related to the COVID-19 pandemic throughout
January 1st, 2020 to April 30th, 2020, and explored topic modeling to identify
the most discussed topics and themes during this period in our data set.
Additionally, we analyzed the temporal changes in the topics with respect to
the events that occurred during this pandemic. We found out that eight topics
were sufficient to identify the themes in our corpus. These topics depicted a
temporal trend. The dominant topics vary over time and align with the events
related to the COVID-19 pandemic.
</p>
<a href="http://arxiv.org/abs/2011.00377" target="_blank">arXiv:2011.00377</a> [<a href="http://arxiv.org/pdf/2011.00377" target="_blank">pdf</a>]

<h2>AI Marker-based Large-scale AI Literature Mining. (arXiv:2011.00518v2 [cs.IR] UPDATED)</h2>
<h3>Rujing Yao, Yingchun Ye, Ji Zhang, Shuxiao Li, Ou Wu</h3>
<p>The knowledge contained in academic literature is interesting to mine.
Inspired by the idea of molecular markers tracing in the field of biochemistry,
three named entities, namely, methods, datasets and metrics are used as AI
markers for AI literature. These entities can be used to trace the research
process described in the bodies of papers, which opens up new perspectives for
seeking and mining more valuable academic information. Firstly, the entity
extraction model is used in this study to extract AI markers from large-scale
AI literature. Secondly, original papers are traced for AI markers. Statistical
and propagation analysis are performed based on tracing results. Finally, the
co-occurrences of AI markers are used to achieve clustering. The evolution
within method clusters and the influencing relationships amongst different
research scene clusters are explored. The above-mentioned mining based on AI
markers yields many meaningful discoveries. For example, the propagation of
effective methods on the datasets is rapidly increasing with the development of
time; effective methods proposed by China in recent years have increasing
influence on other countries, whilst France is the opposite. Saliency
detection, a classic computer vision research scene, is the least likely to be
affected by other research scenes.
</p>
<a href="http://arxiv.org/abs/2011.00518" target="_blank">arXiv:2011.00518</a> [<a href="http://arxiv.org/pdf/2011.00518" target="_blank">pdf</a>]

<h2>Real-to-Sim Registration of Deformable Soft Tissue with Position-Based Dynamics for Surgical Robot Autonomy. (arXiv:2011.00800v2 [cs.RO] UPDATED)</h2>
<h3>Fei Liu, Zihan Li, Yunhai Han, Jingpei Lu, Florian Richter, Michael C. Yip</h3>
<p>Autonomy in robotic surgery is very challenging in unstructured environments,
especially when interacting with deformable soft tissues. This creates a
challenge for model-based control methods that must account for deformation
dynamics during tissue manipulation. Previous works in vision-based perception
can capture the geometric changes within the scene, however, integration with
dynamic properties toachieve accurate and safe model-based controllers has not
been considered before. Considering the mechanic coupling between the robot and
the environment, it is crucial to develop a registered, simulated dynamical
model. In this work, we propose an online, continuous, real-to-sim registration
method to bridge from 3D visual perception to position-based dynamics(PBD)
modeling of tissues. The PBD method is employed to simulate soft tissue
dynamics as well as rigid tool interactions for model-based control. Meanwhile,
a vision-based strategy is used to generate 3D reconstructed point cloud
surfaces that can be used to register and update the simulation, accounting for
differences between the simulation and the real world. To verify this
real-to-sim approach, tissue manipulation experiments have been conducted on
the da Vinci Researach Kit. Our real-to-sim approach successfully reduced
registration errors online, which is especially important for safety during
autonomous control. Moreover, the result shows higher accuracy in occluded
areas than fusion-based reconstruction.
</p>
<a href="http://arxiv.org/abs/2011.00800" target="_blank">arXiv:2011.00800</a> [<a href="http://arxiv.org/pdf/2011.00800" target="_blank">pdf</a>]

<h2>PV-NAS: Practical Neural Architecture Search for Video Recognition. (arXiv:2011.00826v2 [cs.CV] UPDATED)</h2>
<h3>Zihao Wang, Chen Lin, Lu Sheng, Junjie Yan, Jing Shao</h3>
<p>Recently, deep learning has been utilized to solve video recognition problem
due to its prominent representation ability. Deep neural networks for video
tasks is highly customized and the design of such networks requires domain
experts and costly trial and error tests. Recent advance in network
architecture search has boosted the image recognition performance in a large
margin. However, automatic designing of video recognition network is less
explored. In this study, we propose a practical solution, namely Practical
Video Neural Architecture Search (PV-NAS).Our PV-NAS can efficiently search
across tremendous large scale of architectures in a novel spatial-temporal
network search space using the gradient based search methods. To avoid sticking
into sub-optimal solutions, we propose a novel learning rate scheduler to
encourage sufficient network diversity of the searched models. Extensive
empirical evaluations show that the proposed PV-NAS achieves state-of-the-art
performance with much fewer computational resources. 1) Within light-weight
models, our PV-NAS-L achieves 78.7% and 62.5% Top-1 accuracy on Kinetics-400
and Something-Something V2, which are better than previous state-of-the-art
methods (i.e., TSM) with a large margin (4.6% and 3.4% on each dataset,
respectively), and 2) among median-weight models, our PV-NAS-M achieves the
best performance (also a new record)in the Something-Something V2 dataset.
</p>
<a href="http://arxiv.org/abs/2011.00826" target="_blank">arXiv:2011.00826</a> [<a href="http://arxiv.org/pdf/2011.00826" target="_blank">pdf</a>]

<h2>Exploiting Multiple Intelligent Reflecting Surfaces in Multi-Cell Uplink MIMO Communications. (arXiv:2011.01141v2 [eess.SP] UPDATED)</h2>
<h3>Junghoon Kim, Seyyedali Hosseinalipour, Taejoon Kim, David J. Love, Christopher G. Brinton</h3>
<p>Applications of intelligent reflecting surfaces (IRSs) in wireless networks
have attracted significant attention recently. Most of the relevant literature
is focused on the single cell setting where a single IRS is deployed, while
static and perfect channel state information (CSI) is assumed. In this work, we
develop a novel methodology for multi-IRS-assisted multi-cell networks in the
uplink. We formulate the sum-rate maximization problem aiming to jointly
optimize the IRS reflect beamformers, base station (BS) combiners, and user
equipment (UE) transmit powers. In this optimization, we consider the scenario
in which (i) channels are dynamic and (ii) only partial CSI is available at
each BS; specifically, scalar effective channels of local UEs and some of the
interfering UEs. In casting this as a sequential decision making problem, we
propose a multi-agent deep reinforcement learning algorithm to solve it, where
each BS acts as an independent agent in charge of tuning the local UEs transmit
powers, the local IRS reflect beamformer, and its combiners. We introduce an
efficient message passing scheme that requires limited information exchange
among the neighboring BSs to cope with the non-stationarity caused by the
coupling of actions taken by multiple BSs. Our numerical simulations show that
our method obtains substantial improvement in average data rate compared to
several baseline approaches, e.g., fixed UEs transmit power and maximum ratio
combining.
</p>
<a href="http://arxiv.org/abs/2011.01141" target="_blank">arXiv:2011.01141</a> [<a href="http://arxiv.org/pdf/2011.01141" target="_blank">pdf</a>]

<h2>Continuous and Diverse Image-to-Image Translation via Signed Attribute Vectors. (arXiv:2011.01215v2 [cs.CV] UPDATED)</h2>
<h3>Qi Mao, Hsin-Ying Lee, Hung-Yu Tseng, Jia-Bin Huang, Siwei Ma, Ming-Hsuan Yang</h3>
<p>Recent image-to-image (I2I) translation algorithms focus on learning the
mapping from a source to a target domain. However, the continuous translation
problem that synthesizes intermediate results between the two domains has not
been well-studied in the literature. Generating a smooth sequence of
intermediate results bridges the gap of two different domains, facilitating the
morphing effect across domains. Existing I2I approaches are limited to either
intra-domain or deterministic inter-domain continuous translation. In this
work, we present an effective signed attribute vector, which enables continuous
translation on diverse mapping paths across various domains. In particular,
utilizing the sign operation to encode the domain information, we introduce a
unified attribute space shared by all domains, thereby allowing the
interpolation on attribute vectors of different domains. To enhance the visual
quality of continuous translation results, we generate a trajectory between two
sign-symmetrical attribute vectors and leverage the domain information of the
interpolated results along the trajectory for adversarial training. We evaluate
the proposed method on a wide range of I2I translation tasks. Both qualitative
and quantitative results demonstrate that the proposed framework generates more
high-quality continuous translation results against the state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/2011.01215" target="_blank">arXiv:2011.01215</a> [<a href="http://arxiv.org/pdf/2011.01215" target="_blank">pdf</a>]

<h2>High-dimensional structure learning of sparse vector autoregressive models using fractional marginal pseudo-likelihood. (arXiv:2011.01484v1 [stat.CO])</h2>
<h3>Kimmo Suotsalo, Yingying Xu, Jukka Corander, Johan Pensar</h3>
<p>Learning vector autoregressive models from multivariate time series is
conventionally approached through least squares or maximum likelihood
estimation. These methods typically assume a fully connected model which
provides no direct insight to the model structure and may lead to highly noisy
estimates of the parameters. Because of these limitations, there has been an
increasing interest towards methods that produce sparse estimates through
penalized regression. However, such methods are computationally intensive and
may become prohibitively time-consuming when the number of variables in the
model increases. In this paper we adopt an approximate Bayesian approach to the
learning problem by combining fractional marginal likelihood and
pseudo-likelihood. We propose a novel method, PLVAR, that is both faster and
produces more accurate estimates than the state-of-the-art methods based on
penalized regression. We prove the consistency of the PLVAR estimator and
demonstrate the attractive performance of the method on both simulated and
real-world data.
</p>
<a href="http://arxiv.org/abs/2011.01484" target="_blank">arXiv:2011.01484</a> [<a href="http://arxiv.org/pdf/2011.01484" target="_blank">pdf</a>]

<h2>Bayesian Computing in the Undergraduate Statistics Curriculum. (arXiv:2002.09716v3 [stat.CO] UPDATED)</h2>
<h3>Jim Albert, Jingchen Hu</h3>
<p>Bayesian statistics has gained great momentum since the computational
developments of the 1990s. Gradually, advances in Bayesian methodology and
software have made Bayesian techniques much more accessible to applied
statisticians and, in turn, have potentially transformed Bayesian education at
the undergraduate level. This article provides an overview on the various
options for implementing Bayesian computational methods motivated to achieve
particular learning outcomes. The advantages and disadvantages of each
computational method are described based on the authors' experience in using
these methods in the classroom. The goal is to present guidance on the choice
of computation for the instructors who are introducing Bayesian methods in
their undergraduate statistics curriculum.
</p>
<a href="http://arxiv.org/abs/2002.09716" target="_blank">arXiv:2002.09716</a> [<a href="http://arxiv.org/pdf/2002.09716" target="_blank">pdf</a>]

<h2>KrigHedge: Gaussian Process Surrogates for Delta Hedging. (arXiv:2010.08407v3 [q-fin.CP] UPDATED)</h2>
<h3>Mike Ludkovski, Yuri Saporito</h3>
<p>We investigate a machine learning approach to option Greeks approximation
based on Gaussian process (GP) surrogates. The method takes in noisily observed
option prices, fits a nonparametric input-output map and then analytically
differentiates the latter to obtain the various price sensitivities. Our
motivation is to compute Greeks in cases where direct computation is expensive,
such as in local volatility models, or can only ever be done approximately. We
provide a detailed analysis of numerous aspects of GP surrogates, including
choice of kernel family, simulation design, choice of trend function and impact
of noise.

We further discuss the application to Delta hedging, including a new Lemma
that relates quality of the Delta approximation to discrete-time hedging loss.
Results are illustrated with two extensive case studies that consider
estimation of Delta, Theta and Gamma and benchmark approximation quality and
uncertainty quantification using a variety of statistical metrics. Among our
key take-aways are the recommendation to use Matern kernels, the benefit of
including virtual training points to capture boundary conditions, and the
significant loss of fidelity when training on stock-path-based datasets.
</p>
<a href="http://arxiv.org/abs/2010.08407" target="_blank">arXiv:2010.08407</a> [<a href="http://arxiv.org/pdf/2010.08407" target="_blank">pdf</a>]

