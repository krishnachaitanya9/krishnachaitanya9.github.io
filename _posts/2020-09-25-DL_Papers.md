---
title: Latest Deep Learning Papers
date: 2020-10-08 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Actor-Critic Algorithm for High-dimensional Partial Differential Equations. (arXiv:2010.03647v1 [cs.LG])</h2>
<h3>Xiaohan Zhang</h3>
<p>We develop a deep learning model to effectively solve high-dimensional
nonlinear parabolic partial differential equations (PDE). We follow Feynman-Kac
formula to reformulate PDE into the equivalent stochastic control problem
governed by a Backward Stochastic Differential Equation (BSDE) system. The
Markovian property of the BSDE is utilized in designing our neural network
architecture, which is inspired by the Actor-Critic algorithm usually applied
for deep Reinforcement Learning. Compared to the State-of-the-Art model, we
make several improvements including 1) largely reduced trainable parameters, 2)
faster convergence rate and 3) fewer hyperparameters to tune. We demonstrate
those improvements by solving a few well-known classes of PDEs such as
Hamilton-Jacobian-Bellman equation, Allen-Cahn equation and Black-Scholes
equation with dimensions on the order of 100.
</p>
<a href="http://arxiv.org/abs/2010.03647" target="_blank">arXiv:2010.03647</a> [<a href="http://arxiv.org/pdf/2010.03647" target="_blank">pdf</a>]

<h2>An optimization-based approach to parameter learning for fractional type nonlocal models. (arXiv:2010.03666v1 [math.OC])</h2>
<h3>Olena Burkovska, Christian Glusa, Marta D&#x27;Elia</h3>
<p>Nonlocal operators of fractional type are a popular modeling choice for
applications that do not adhere to classical diffusive behavior; however, one
major challenge in nonlocal simulations is the selection of model parameters.
In this work we propose an optimization-based approach to parameter
identification for fractional models with an optional truncation radius. We
formulate the inference problem as an optimal control problem where the
objective is to minimize the discrepancy between observed data and an
approximate solution of the model, and the control variables are the fractional
order and the truncation length. For the numerical solution of the minimization
problem we propose a gradient-based approach, where we enhance the numerical
performance by an approximation of the bilinear form of the state equation and
its derivative with respect to the fractional order. Several numerical tests in
one and two dimensions illustrate the theoretical results and show the
robustness and applicability of our method.
</p>
<a href="http://arxiv.org/abs/2010.03666" target="_blank">arXiv:2010.03666</a> [<a href="http://arxiv.org/pdf/2010.03666" target="_blank">pdf</a>]

<h2>Learning Theory for Inferring Interaction Kernels in Second-Order Interacting Agent Systems. (arXiv:2010.03729v1 [stat.ML])</h2>
<h3>Jason Miller, Sui Tang, Ming Zhong, Mauro Maggioni</h3>
<p>Modeling the complex interactions of systems of particles or agents is a
fundamental scientific and mathematical problem that is studied in diverse
fields, ranging from physics and biology, to economics and machine learning. In
this work, we describe a very general second-order, heterogeneous,
multivariable, interacting agent model, with an environment, that encompasses a
wide variety of known systems. We describe an inference framework that uses
nonparametric regression and approximation theory based techniques to
efficiently derive estimators of the interaction kernels which drive these
dynamical systems. We develop a complete learning theory which establishes
strong consistency and optimal nonparametric min-max rates of convergence for
the estimators, as well as provably accurate predicted trajectories. The
estimators exploit the structure of the equations in order to overcome the
curse of dimensionality and we describe a fundamental coercivity condition on
the inverse problem which ensures that the kernels can be learned and relates
to the minimal singular value of the learning matrix. The numerical algorithm
presented to build the estimators is parallelizable, performs well on
high-dimensional problems, and is demonstrated on complex dynamical systems.
</p>
<a href="http://arxiv.org/abs/2010.03729" target="_blank">arXiv:2010.03729</a> [<a href="http://arxiv.org/pdf/2010.03729" target="_blank">pdf</a>]

<h2>On the arithmetic-geometric index of graphs. (arXiv:2010.03748v1 [math.CO])</h2>
<h3>Shu-Yu Cui, Weifan Wang, Gui-Xian Tian, Baoyindureng Wu</h3>
<p>Very recently, the first geometric-arithmetic index $GA$ and
arithmetic-geometric index $AG$ were introduced in mathematical chemistry. In
the present paper, we first obtain some lower and upper bounds on $AG$ and
characterize the extremal graphs. We also establish various relations between
$AG$ and other topological indices, such as the first geometric-arithmetic
index $GA$, atom-bond-connectivity index $ABC$, symmetric division deg index
$SDD$, chromatic number $\chi$ and so on. Finally, we present some sufficient
conditions of $GA(G)&gt;GA(G-e)$ or $AG(G)&gt;AG(G-e)$ for an edge $e$ of a graph
$G$. In particular, for the first geometric-arithmetic index, we also give a
refinement of Bollob\'{a}s-Erd\H{o}s-type theorem obtained in [3].
</p>
<a href="http://arxiv.org/abs/2010.03748" target="_blank">arXiv:2010.03748</a> [<a href="http://arxiv.org/pdf/2010.03748" target="_blank">pdf</a>]

<h2>Classification of Thompson related groups arising from Jones technology I. (arXiv:2010.03765v1 [math.GR])</h2>
<h3>Arnaud Brothier</h3>
<p>In the quest in constructing conformal field theories (CFT) Jones has
discovered a beautiful and deep connection between CFT, Richard Thompson's
groups and knot theory. This led to a powerful framework for constructing
actions of particular groups arising from categories such as Richard Thompson's
groups and braid groups. In particular, given a group and two of its
endomorphisms one can construct a semidirect product. Those semidirect products
have remarkable diagrammatic descriptions which were previously used to provide
new examples of groups having the Haagerup property. Moreover, they naturally
appear in certain field theories as being generated by local and global
symmetries.

We consider in this article the class of groups obtained in that way where
one of the endomorphism is trivial leaving the case of two nontrivial
endomorphisms to a second article. The groups obtained can be described in
terms of permutational restricted twisted wreath products containing the larger
Thompson group. We classify this class of groups up to isomorphisms and provide
a thin description of their automorphism group thanks to an unexpected rigidity
phenomena.
</p>
<a href="http://arxiv.org/abs/2010.03765" target="_blank">arXiv:2010.03765</a> [<a href="http://arxiv.org/pdf/2010.03765" target="_blank">pdf</a>]

<h2>Learning the Linear Quadratic Regulator from Nonlinear Observations. (arXiv:2010.03799v1 [cs.LG])</h2>
<h3>Zakaria Mhammedi, Dylan J. Foster, Max Simchowitz, Dipendra Misra, Wen Sun, Akshay Krishnamurthy, Alexander Rakhlin, John Langford</h3>
<p>We introduce a new problem setting for continuous control called the LQR with
Rich Observations, or RichLQR. In our setting, the environment is summarized by
a low-dimensional continuous latent state with linear dynamics and quadratic
costs, but the agent operates on high-dimensional, nonlinear observations such
as images from a camera. To enable sample-efficient learning, we assume that
the learner has access to a class of decoder functions (e.g., neural networks)
that is flexible enough to capture the mapping from observations to latent
states. We introduce a new algorithm, RichID, which learns a near-optimal
policy for the RichLQR with sample complexity scaling only with the dimension
of the latent state space and the capacity of the decoder function class.
RichID is oracle-efficient and accesses the decoder class only through calls to
a least-squares regression oracle. Our results constitute the first provable
sample complexity guarantee for continuous control with an unknown nonlinearity
in the system model and general function approximation.
</p>
<a href="http://arxiv.org/abs/2010.03799" target="_blank">arXiv:2010.03799</a> [<a href="http://arxiv.org/pdf/2010.03799" target="_blank">pdf</a>]

<h2>A Variational Auto-Encoder Approach for Image Transmission in Wireless Channel. (arXiv:2010.03967v1 [eess.SP])</h2>
<h3>Amir Hossein Estiri, Mohammad Reza Sabramooz, Ali Banaei, Amir Hossein Dehghan, Benyamin Jamialahmadi, Mahdi Jafari Siavoshani</h3>
<p>Recent advancements in information technology and the widespread use of the
Internet have led to easier access to data worldwide. As a result, transmitting
data through noisy channels is inevitable. Reducing the size of data and
protecting it during transmission from corruption due to channel noises are two
classical problems in communication and information theory. Recently, inspired
by deep neural networks' success in different tasks, many works have been done
to address these two problems using deep learning techniques.

In this paper, we investigate the performance of variational auto-encoders
and compare the results with standard auto-encoders. Our findings suggest that
variational auto-encoders are more robust to channel degradation than
auto-encoders. Furthermore, we have tried to excel in the human perceptual
quality of reconstructed images by using perception-based error metrics as our
network's loss function. To this end, we use the structural similarity index
(SSIM) as a perception-based metric to optimize the proposed neural network.
Our experiments demonstrate that the SSIM metric visually improves the quality
of the reconstructed images at the receiver.
</p>
<a href="http://arxiv.org/abs/2010.03967" target="_blank">arXiv:2010.03967</a> [<a href="http://arxiv.org/pdf/2010.03967" target="_blank">pdf</a>]

<h2>Learning Partially Observed Linear Dynamical Systems from Logarithmic Number of Samples. (arXiv:2010.04015v1 [cs.LG])</h2>
<h3>Salar Fattahi</h3>
<p>In this work, we study the problem of learning partially observed linear
dynamical systems from a single sample trajectory. A major practical challenge
in the existing system identification methods is the undesirable dependency of
their required sample size on the system dimension: roughly speaking, they
presume and rely on sample sizes that scale linearly with respect to the system
dimension. Evidently, in high-dimensional regime where the system dimension is
large, it may be costly, if not impossible, to collect as many samples from the
unknown system. In this paper, we will remedy this undesirable dependency on
the system dimension by introducing an $\ell_1$-regularized estimation method
that can accurately estimate the Markov parameters of the system, provided that
the number of samples scale logarithmically with the system dimension. Our
result significantly improves the sample complexity of learning partially
observed linear dynamical systems: it shows that the Markov parameters of the
system can be learned in the high-dimensional setting, where the number of
samples is significantly smaller than the system dimension. Traditionally, the
$\ell_1$-regularized estimators have been used to promote sparsity in the
estimated parameters. By resorting to the notion of "weak sparsity", we show
that, irrespective of the true sparsity of the system, a similar regularized
estimator can be used to reduce the sample complexity of learning partially
observed linear systems, provided that the true system is inherently stable.
</p>
<a href="http://arxiv.org/abs/2010.04015" target="_blank">arXiv:2010.04015</a> [<a href="http://arxiv.org/pdf/2010.04015" target="_blank">pdf</a>]

<h2>Adaptive Subcarrier, Parameter, and Power Allocation for Partitioned Edge Learning Over Broadband Channels. (arXiv:2010.04061v1 [cs.IT])</h2>
<h3>Dingzhu Wen, Ki-Jun Jeon, Mehdi Bennis, Kaibin Huang</h3>
<p>A main edge learning paradigm, called partitioned edge learning (PARTEL), is
considered. It supports the distributed training of a large-scale AI model by
dynamically partitioning the model and allocating the resultant parametric
blocks to different devices for updating. Then devices upload the updates to a
server where they are assembled and applied to updating the model. The two
steps are iterated till the model converges. In this work, we consider the
efficient joint management of parameter allocation and radio resources to
reduce the learning latency of PARTEL, when deployed in a broadband system
using orthogonal frequency-division multiplexing (OFDM). Specifically, the
policies for joint subcarrier, parameter, and power allocation (SUPPORT) are
optimized under the criterion of minimum latency. Two cases are considered.
First, for the case of decomposable models (e.g., logistic regression or
support vector machine), the latency-minimization problem is a mixed-integer
program and non-convex. Due to its intractability, we develop a practical
solution by 1) relaxing the binary subcarrier-assignment decisions and 2)
transforming the relaxed problem into a convex problem of model size
maximization under a latency constraint nested in a simple search for the
target model size. By deriving the properties of the convex problem, a
low-complexity algorithm is designed to compute the SUPPORT policy. Second,
consider the case of convolutional neural network (CNN) models which can be
trained using PARTEL by introducing some auxiliary variables. This, however,
introduces constraints on model partitioning reducing the granularity of
parameter allocation. The preceding policy is extended to CNN models by
applying the proposed techniques of load rounding and proportional adjustment
to rein in latency expansion caused by the load granularity constraints.
</p>
<a href="http://arxiv.org/abs/2010.04061" target="_blank">arXiv:2010.04061</a> [<a href="http://arxiv.org/pdf/2010.04061" target="_blank">pdf</a>]

<h2>A Machine Learning Framework for Computing the Most Probable Paths of Stochastic Dynamical Systems. (arXiv:2010.04114v1 [math.DS])</h2>
<h3>Yang Li, Jinqiao Duan, Xianbin Liu</h3>
<p>The emergence of transition phenomena between metastable states induced by
noise plays a fundamental role in a broad range of nonlinear systems. The
computation of the most probable paths is a key issue to understand the
mechanism of transition behaviors. Shooting method is a common technique for
this purpose, while losing its efficacy in high-dimensional systems. In the
present work, we develop a machine learning framework to compute the most
probable paths in the sense of Onsager-Machlup theory. Specifically, we
reformulate the boundary value problem of Hamiltonian system and design a
neural network to remedy the shortcomings of shooting method. The successful
applications of our algorithms to several prototypical examples demonstrate its
efficacy and accuracy for stochastic systems with both (Gaussian) Brownian
noise and (non-Gaussian) L\'evy noise. This novel approach is effective in
exploring the internal mechanisms of rare events triggered by random
fluctuations in various scientific fields.
</p>
<a href="http://arxiv.org/abs/2010.04114" target="_blank">arXiv:2010.04114</a> [<a href="http://arxiv.org/pdf/2010.04114" target="_blank">pdf</a>]

<h2>A big data based method for pass rates optimization in mathematics university lower division courses. (arXiv:1809.09724v3 [econ.GN] UPDATED)</h2>
<h3>Fernando A Morales, Cristian C Chica, Carlos A Osorio, Daniel Cabarcas J</h3>
<p>In this paper an algorithm designed for large databases is introduced for the
enhancement of pass rates in mathematical university lower division courses
with several sections. Using integer programming techniques, the algorithm
finds the optimal pairing of students and lecturers in order to maximize the
success chances of the students' body. The students-lecturer success
probability is computed according to their corresponding profiles stored in the
data bases.
</p>
<a href="http://arxiv.org/abs/1809.09724" target="_blank">arXiv:1809.09724</a> [<a href="http://arxiv.org/pdf/1809.09724" target="_blank">pdf</a>]

<h2>On the approximation of rough functions with deep neural networks. (arXiv:1912.06732v2 [math.NA] UPDATED)</h2>
<h3>Tim De Ryck, Siddhartha Mishra, Deep Ray</h3>
<p>Deep neural networks and the ENO procedure are both efficient frameworks for
approximating rough functions. We prove that at any order, the ENO
interpolation procedure can be cast as a deep ReLU neural network. This
surprising fact enables the transfer of several desirable properties of the ENO
procedure to deep neural networks, including its high-order accuracy at
approximating Lipschitz functions. Numerical tests for the resulting neural
networks show excellent performance for approximating solutions of nonlinear
conservation laws and at data compression.
</p>
<a href="http://arxiv.org/abs/1912.06732" target="_blank">arXiv:1912.06732</a> [<a href="http://arxiv.org/pdf/1912.06732" target="_blank">pdf</a>]

<h2>SelectNet: Self-paced Learning for High-dimensional Partial Differential Equations. (arXiv:2001.04860v2 [math.NA] UPDATED)</h2>
<h3>Yiqi Gu, Haizhao Yang, Chao Zhou</h3>
<p>The residual method with deep neural networks as function parametrization has
been applied to solve certain high-dimensional partial differential equations
(PDEs) successfully; however, its convergence is slow and might not be
guaranteed even within a simple class of PDEs. To improve the convergence of
the network-based residual model, we introduce a novel self-paced learning
framework, SelectNet, which quantifies the difficulty of training samples,
chooses simpler samples in the early stage of training, and slowly explores
more challenging samples, e.g., samples with larger residual errors, mimicking
the human cognitive process for more efficient learning. In particular, a
selection network and the PDE solution network are trained simultaneously; the
selection network adaptively weighting the training samples of the solution
network achieving the goal of self-paced learning. Numerical examples indicate
that the proposed SelectNet model outperforms existing models on the
convergence speed and the convergence robustness, especially for low-regularity
solutions.
</p>
<a href="http://arxiv.org/abs/2001.04860" target="_blank">arXiv:2001.04860</a> [<a href="http://arxiv.org/pdf/2001.04860" target="_blank">pdf</a>]

<h2>Quantum arithmetic operations based on quantum Fourier transform on signed integers. (arXiv:2005.00443v3 [cs.IT] UPDATED)</h2>
<h3>Engin &#x15e;ahin</h3>
<p>The quantum Fourier transform (QFT) brings efficiency in many respects,
especially usage of resource, for most operations on quantum computers. In this
study, the existing QFT-based and non-QFT-based quantum arithmetic operations
are examined. The capabilities of QFT-based addition and multiplication are
improved with some modifications. The proposed operations are compared with the
nearest quantum arithmetic operations. Furthermore, novel QFT-based
subtraction, division and exponentiation operations are presented. The proposed
arithmetic operations can perform nonmodular operations on all signed numbers
without any limitation by using less resources. In addition, novel quantum
circuits of two's complement, absolute value and comparison operations are also
presented by using the proposed QFT-based addition and subtraction operations.
</p>
<a href="http://arxiv.org/abs/2005.00443" target="_blank">arXiv:2005.00443</a> [<a href="http://arxiv.org/pdf/2005.00443" target="_blank">pdf</a>]

<h2>Mode Decomposition for Homogeneous Symmetric Operators. (arXiv:2007.01534v2 [math.DS] UPDATED)</h2>
<h3>Ido Cohen, Omri Azencot, Pavel Lifshitz, Guy Gilboa</h3>
<p>Finding latent structures in data is drawing increasing attention in diverse
fields such as fluid dynamics, signal processing, and machine learning.
Dimensionality reduction facilitates the revelation of such structures. For
dynamical systems of linear and nonlinear flows, a prominent dimensionality
reduction method is DMD, based on the theory of Koopman operators. In this
work, we adapt DMD to homogeneous flows and show it can approximate well
nonlinear spectral image decomposition techniques. We examine dynamics based on
symmetric $\gamma$-homogeneous operators, $0 &lt; \gamma &lt; 1$. These systems have
a polynomial decay profile and reach steady state in finite time. DMD, on the
other hand, can be viewed as an exponential data fitting algorithm. This yields
an inherent conflict, causing large approximation errors (and non-existence of
solutions in some particular cases). The contribution of this work is
threefold. First, we suggest a rescaling of the time variable that solves the
conflict between DMD and homogeneous flows. This adaptation of DMD can be
performed when the homogeneity and the time step size are known. Second, we
suggest the blind homogeneity normalization for time rescaling when neither the
homogeneity nor the step size are known. Third, we formulate a new dynamic mode
decomposition that constrains the matrix of the dynamics to be symmetric,
termed SDMD. With these adaptations, we provide a closed form solution of DMD
for dynamics $u_t = P(u) $, $u(t=0)=u_0$, where $P$ is a nonlinear
$\gamma$-homogeneous operator, when $u_0$ admits $P(u_0)=\lambda u_0 $. Then,
we prove the validity of the blind homogeneity normalization. In addition, we
show SDMD achieves lower mean square error for the spectrum estimation.
Finally, we turn to formulating a discrete nonlinear spectral decomposition,
based on SDMD and related to nonlinear eigenfunctions of $\gamma$-homogeneous
operators.
</p>
<a href="http://arxiv.org/abs/2007.01534" target="_blank">arXiv:2007.01534</a> [<a href="http://arxiv.org/pdf/2007.01534" target="_blank">pdf</a>]

<h2>On the Convergence of Consensus Algorithms with Markovian Noise and Gradient Bias. (arXiv:2008.07841v2 [math.OC] UPDATED)</h2>
<h3>Hoi-To Wai</h3>
<p>This paper presents a finite time convergence analysis for a decentralized
stochastic approximation (SA) scheme. The scheme generalizes several algorithms
for decentralized machine learning and multi-agent reinforcement learning. Our
proof technique involves separating the iterates into their respective
consensual parts and consensus error. The consensus error is bounded in terms
of the stationarity of the consensual part, while the updates of the consensual
part can be analyzed as a perturbed SA scheme. Under the Markovian noise and
time varying communication graph assumptions, the decentralized SA scheme has
an expected convergence rate of ${\cal O}(\log T/ \sqrt{T} )$, where $T$ is the
iteration number, in terms of squared norms of gradient for nonlinear SA with
smooth but non-convex cost function. This rate is comparable to the best known
performances of SA in a centralized setting with a non-convex potential
function.
</p>
<a href="http://arxiv.org/abs/2008.07841" target="_blank">arXiv:2008.07841</a> [<a href="http://arxiv.org/pdf/2008.07841" target="_blank">pdf</a>]

<h2>Infinite-Dimensional Fisher Markets: Equilibrium, Duality and Optimization. (arXiv:2010.03025v2 [cs.GT] UPDATED)</h2>
<h3>Yuan Gao, Christian Kroer</h3>
<p>This paper considers a linear Fisher market with $n$ buyers and a continuum
of items. In order to compute market equilibria, we introduce
(infinite-dimensional) convex programs over Banach spaces, thereby generalizing
the Eisenberg-Gale convex program and its dual. Regarding the new convex
programs, we establish existence of optimal solutions, the existence of
KKT-type conditions, as well as strong duality. All these properties are
established via non-standard arguments, which circumvent the limitations of
duality theory in optimization over infinite-dimensional vector spaces.
Furthermore, we show that there exists a pure equilibrium allocation, i.e., a
division of the item space. Similar to the finite-dimensional case, a market
equilibrium under the infinite-dimensional Fisher market is Pareto optimal,
envy-free and proportional. We also show how to obtain the (a.e. unique)
equilibrium price vector and a pure equilibrium allocation from the (unique)
$n$-dimensional equilibrium bang-per-buck vector. When the item space is the
unit interval $[0,1]$ and buyers have piecewise linear utilities, we show that
$\epsilon$-approximate equilibrium prices can be computed in time polynomial in
the market size and $\log \frac{1}{\epsilon}$. This is achieved by solving a
finite-dimensional convex program using the ellipsoid method. To this end, we
give nontrivial and efficient subgradient and separation oracles. For general
buyer valuations, we propose computing market equilibrium using stochastic dual
averaging, which finds an approximate equilibrium price vector with high
probability.
</p>
<a href="http://arxiv.org/abs/2010.03025" target="_blank">arXiv:2010.03025</a> [<a href="http://arxiv.org/pdf/2010.03025" target="_blank">pdf</a>]

<h2>Characterizing the Value of Information in Medical Notes. (arXiv:2010.03574v1 [cs.CL])</h2>
<h3>Chao-Chun Hsu, Shantanu Karnwal, Sendhil Mullainathan, Ziad Obermeyer, Chenhao Tan</h3>
<p>Machine learning models depend on the quality of input data. As electronic
health records are widely adopted, the amount of data in health care is
growing, along with complaints about the quality of medical notes. We use two
prediction tasks, readmission prediction and in-hospital mortality prediction,
to characterize the value of information in medical notes. We show that as a
whole, medical notes only provide additional predictive power over structured
information in readmission prediction. We further propose a probing framework
to select parts of notes that enable more accurate predictions than using all
notes, despite that the selected information leads to a distribution shift from
the training data ("all notes"). Finally, we demonstrate that models trained on
the selected valuable information achieve even better predictive performance,
with only 6.8% of all the tokens for readmission prediction.
</p>
<a href="http://arxiv.org/abs/2010.03574" target="_blank">arXiv:2010.03574</a> [<a href="http://arxiv.org/pdf/2010.03574" target="_blank">pdf</a>]

<h2>Shape, Illumination, and Reflectance from Shading. (arXiv:2010.03592v1 [cs.CV])</h2>
<h3>Jonathan T. Barron, Jitendra Malik</h3>
<p>A fundamental problem in computer vision is that of inferring the intrinsic,
3D structure of the world from flat, 2D images of that world. Traditional
methods for recovering scene properties such as shape, reflectance, or
illumination rely on multiple observations of the same scene to overconstrain
the problem. Recovering these same properties from a single image seems almost
impossible in comparison -- there are an infinite number of shapes, paint, and
lights that exactly reproduce a single image. However, certain explanations are
more likely than others: surfaces tend to be smooth, paint tends to be uniform,
and illumination tends to be natural. We therefore pose this problem as one of
statistical inference, and define an optimization problem that searches for the
*most likely* explanation of a single image. Our technique can be viewed as a
superset of several classic computer vision problems (shape-from-shading,
intrinsic images, color constancy, illumination estimation, etc) and
outperforms all previous solutions to those constituent problems.
</p>
<a href="http://arxiv.org/abs/2010.03592" target="_blank">arXiv:2010.03592</a> [<a href="http://arxiv.org/pdf/2010.03592" target="_blank">pdf</a>]

<h2>Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples. (arXiv:2010.03593v1 [stat.ML])</h2>
<h3>Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli</h3>
<p>Adversarial training and its variants have become de facto standards for
learning robust deep neural networks. In this paper, we explore the landscape
around adversarial training in a bid to uncover its limits. We systematically
study the effect of different training losses, model sizes, activation
functions, the addition of unlabeled data (through pseudo-labeling) and other
factors on adversarial robustness. We discover that it is possible to train
robust models that go well beyond state-of-the-art results by combining larger
models, Swish/SiLU activations and model weight averaging. We demonstrate large
improvements on CIFAR-10 and CIFAR-100 against $\ell_\infty$ and $\ell_2$
norm-bounded perturbations of size $8/255$ and $128/255$, respectively. In the
setting with additional unlabeled data, we obtain an accuracy under attack of
65.87% against $\ell_\infty$ perturbations of size $8/255$ on CIFAR-10 (+6.34%
with respect to prior art). Without additional data, we obtain an accuracy
under attack of 56.43% (+2.69%). To test the generality of our findings and
without any additional modifications, we obtain an accuracy under attack of
80.45% (+7.58%) against $\ell_2$ perturbations of size $128/255$ on CIFAR-10,
and of 37.70% (+9.28%) against $\ell_\infty$ perturbations of size $8/255$ on
CIFAR-100.
</p>
<a href="http://arxiv.org/abs/2010.03593" target="_blank">arXiv:2010.03593</a> [<a href="http://arxiv.org/pdf/2010.03593" target="_blank">pdf</a>]

<h2>Quantum-enhanced barcode decoding and pattern recognition. (arXiv:2010.03594v1 [quant-ph])</h2>
<h3>Leonardo Banchi, Quntao Zhuang, Stefano Pirandola</h3>
<p>Quantum hypothesis testing is one of the most fundamental problems in quantum
information theory, with crucial implications in areas like quantum sensing,
where it has been used to prove quantum advantage in a series of binary
photonic protocols, e.g., for target detection or memory cell readout. In this
work, we generalize this theoretical model to the multi-partite setting of
barcode decoding and pattern recognition. We start by defining a digital image
as an array or grid of pixels, each pixel corresponding to an ensemble of
quantum channels. Specializing each pixel to a black and white alphabet, we
naturally define an optical model of barcode. In this scenario, we show that
the use of quantum entangled sources, combined with suitable measurements and
data processing, greatly outperforms classical coherent-state strategies for
the tasks of barcode data decoding and classification of black and white
patterns. Moreover, introducing relevant bounds, we show that the problem of
pattern recognition is significantly simpler than barcode decoding, as long as
the minimum Hamming distance between images from different classes is large
enough. Finally, we theoretically demonstrate the advantage of using quantum
sensors for pattern recognition with the nearest neighbor classifier, a
supervised learning algorithm, and numerically verify this prediction for
handwritten digit classification.
</p>
<a href="http://arxiv.org/abs/2010.03594" target="_blank">arXiv:2010.03594</a> [<a href="http://arxiv.org/pdf/2010.03594" target="_blank">pdf</a>]

<h2>Solving stochastic inverse problems for property-structure linkages using data-consistent inversion and machine learning. (arXiv:2010.03603v1 [cs.CE])</h2>
<h3>Anh Tran, Tim Wildey</h3>
<p>Determining process-structure-property linkages is one of the key objectives
in material science, and uncertainty quantification plays a critical role in
understanding both process-structure and structure-property linkages. In this
work, we seek to learn a distribution of microstructure parameters that are
consistent in the sense that the forward propagation of this distribution
through a crystal plasticity finite element model (CPFEM) matches a target
distribution on materials properties. This stochastic inversion formulation
infers a distribution of acceptable/consistent microstructures, as opposed to a
deterministic solution, which expands the range of feasible designs in a
probabilistic manner. To solve this stochastic inverse problem, we employ a
recently developed uncertainty quantification (UQ) framework based on
push-forward probability measures, which combines techniques from measure
theory and Bayes rule to define a unique and numerically stable solution. This
approach requires making an initial prediction using an initial guess for the
distribution on model inputs and solving a stochastic forward problem. To
reduce the computational burden in solving both stochastic forward and
stochastic inverse problems, we combine this approach with a machine learning
(ML) Bayesian regression model based on Gaussian processes and demonstrate the
proposed methodology on two representative case studies in structure-property
linkages.
</p>
<a href="http://arxiv.org/abs/2010.03603" target="_blank">arXiv:2010.03603</a> [<a href="http://arxiv.org/pdf/2010.03603" target="_blank">pdf</a>]

<h2>SRLGRN: Semantic Role Labeling Graph Reasoning Network. (arXiv:2010.03604v1 [cs.CL])</h2>
<h3>Chen Zheng, Parisa Kordjamshidi</h3>
<p>This work deals with the challenge of learning and reasoning over multi-hop
question answering (QA). We propose a graph reasoning network based on the
semantic structure of the sentences to learn cross paragraph reasoning paths
and find the supporting facts and the answer jointly. The proposed graph is a
heterogeneous document-level graph that contains nodes of type sentence
(question, title, and other sentences), and semantic role labeling sub-graphs
per sentence that contain arguments as nodes and predicates as edges.
Incorporating the argument types, the argument phrases, and the semantics of
the edges originated from SRL predicates into the graph encoder helps in
finding and also the explainability of the reasoning paths. Our proposed
approach shows competitive performance on the HotpotQA distractor setting
benchmark compared to the recent state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2010.03604" target="_blank">arXiv:2010.03604</a> [<a href="http://arxiv.org/pdf/2010.03604" target="_blank">pdf</a>]

<h2>Combining Deep Learning and String Kernels for the Localization of Swiss German Tweets. (arXiv:2010.03614v1 [cs.CL])</h2>
<h3>Mihaela Gaman, Radu Tudor Ionescu</h3>
<p>In this work, we introduce the methods proposed by the UnibucKernel team in
solving the Social Media Variety Geolocation task featured in the 2020 VarDial
Evaluation Campaign. We address only the second subtask, which targets a data
set composed of nearly 30 thousand Swiss German Jodels. The dialect
identification task is about accurately predicting the latitude and longitude
of test samples. We frame the task as a double regression problem, employing a
variety of machine learning approaches to predict both latitude and longitude.
From simple models for regression, such as Support Vector Regression, to deep
neural networks, such as Long Short-Term Memory networks and character-level
convolutional neural networks, and, finally, to ensemble models based on
meta-learners, such as XGBoost, our interest is focused on approaching the
problem from a few different perspectives, in an attempt to minimize the
prediction error. With the same goal in mind, we also considered many types of
features, from high-level features, such as BERT embeddings, to low-level
features, such as characters n-grams, which are known to provide good results
in dialect identification. Our empirical results indicate that the handcrafted
model based on string kernels outperforms the deep learning approaches.
Nevertheless, our best performance is given by the ensemble model that combines
both handcrafted and deep learning models.
</p>
<a href="http://arxiv.org/abs/2010.03614" target="_blank">arXiv:2010.03614</a> [<a href="http://arxiv.org/pdf/2010.03614" target="_blank">pdf</a>]

<h2>MuSeM: Detecting Incongruent News Headlines using Mutual Attentive Semantic Matching. (arXiv:2010.03617v1 [cs.CL])</h2>
<h3>Rahul Mishra, Piyush Yadav, Remi Calizzano, Markus Leippold</h3>
<p>Measuring the congruence between two texts has several useful applications,
such as detecting the prevalent deceptive and misleading news headlines on the
web. Many works have proposed machine learning based solutions such as text
similarity between the headline and body text to detect the incongruence. Text
similarity based methods fail to perform well due to different inherent
challenges such as relative length mismatch between the news headline and its
body content and non-overlapping vocabulary. On the other hand, more recent
works that use headline guided attention to learn a headline derived contextual
representation of the news body also result in convoluting overall
representation due to the news body's lengthiness. This paper proposes a method
that uses inter-mutual attention-based semantic matching between the original
and synthetically generated headlines, which utilizes the difference between
all pairs of word embeddings of words involved. The paper also investigates two
more variations of our method, which use concatenation and dot-products of word
embeddings of the words of original and synthetic headlines. We observe that
the proposed method outperforms prior arts significantly for two publicly
available datasets.
</p>
<a href="http://arxiv.org/abs/2010.03617" target="_blank">arXiv:2010.03617</a> [<a href="http://arxiv.org/pdf/2010.03617" target="_blank">pdf</a>]

<h2>Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v1 [cs.LG])</h2>
<h3>Colin Wei, Kendrick Shen, Yining Chen, Tengyu Ma</h3>
<p>Self-training algorithms, which train a model to fit pseudolabels predicted
by another previously-learned model, have been very successful for learning
with unlabeled data using neural networks. However, the current theoretical
understanding of self-training only applies to linear models. This work
provides a unified theoretical analysis of self-training with deep networks for
semi-supervised learning, unsupervised domain adaptation, and unsupervised
learning. At the core of our analysis is a simple but realistic "expansion"
assumption, which states that a low-probability subset of the data must expand
to a neighborhood with large probability relative to the subset. We also assume
that neighborhoods of examples in different classes have minimal overlap. We
prove that under these assumptions, the minimizers of population objectives
based on self-training and input-consistency regularization will achieve high
accuracy with respect to ground-truth labels. By using off-the-shelf
generalization bounds, we immediately convert this result to sample complexity
guarantees for neural nets that are polynomial in the margin and Lipschitzness.
Our results help explain the empirical successes of recently proposed
self-training algorithms which use input consistency regularization.
</p>
<a href="http://arxiv.org/abs/2010.03622" target="_blank">arXiv:2010.03622</a> [<a href="http://arxiv.org/pdf/2010.03622" target="_blank">pdf</a>]

<h2>Domain Adversarial Neural Networks for Dysarthric Speech Recognition. (arXiv:2010.03623v1 [cs.SD])</h2>
<h3>Dominika Woszczyk, Stavros Petridis, David Millard</h3>
<p>Speech recognition systems have improved dramatically over the last few
years, however, their performance is significantly degraded for the cases of
accented or impaired speech. This work explores domain adversarial neural
networks (DANN) for speaker-independent speech recognition on the UAS dataset
of dysarthric speech. The classification task on 10 spoken digits is performed
using an end-to-end CNN taking raw audio as input. The results are compared to
a speaker-adaptive (SA) model as well as speaker-dependent (SD) and multi-task
learning models (MTL). The experiments conducted in this paper show that DANN
achieves an absolute recognition rate of 74.91% and outperforms the baseline by
12.18%. Additionally, the DANN model achieves comparable results to the SA
model's recognition rate of 77.65%. We also observe that when labelled
dysarthric speech data is available DANN and MTL perform similarly, but when
they are not DANN performs better than MTL.
</p>
<a href="http://arxiv.org/abs/2010.03623" target="_blank">arXiv:2010.03623</a> [<a href="http://arxiv.org/pdf/2010.03623" target="_blank">pdf</a>]

<h2>Online Safety Assurance for Deep Reinforcement Learning. (arXiv:2010.03625v1 [cs.AI])</h2>
<h3>Noga H. Rotman, Michael Schapira, Aviv Tamar</h3>
<p>Recently, deep learning has been successfully applied to a variety of
networking problems. A fundamental challenge is that when the operational
environment for a learning-augmented system differs from its training
environment, such systems often make badly informed decisions, leading to bad
performance. We argue that safely deploying learning-driven systems requires
being able to determine, in real time, whether system behavior is coherent, for
the purpose of defaulting to a reasonable heuristic when this is not so. We
term this the online safety assurance problem (OSAP). We present three
approaches to quantifying decision uncertainty that differ in terms of the
signal used to infer uncertainty. We illustrate the usefulness of online safety
assurance in the context of the proposed deep reinforcement learning (RL)
approach to video streaming. While deep RL for video streaming bests other
approaches when the operational and training environments match, it is
dominated by simple heuristics when the two differ. Our preliminary findings
suggest that transitioning to a default policy when decision uncertainty is
detected is key to enjoying the performance benefits afforded by leveraging ML
without compromising on safety.
</p>
<a href="http://arxiv.org/abs/2010.03625" target="_blank">arXiv:2010.03625</a> [<a href="http://arxiv.org/pdf/2010.03625" target="_blank">pdf</a>]

<h2>Revisiting Batch Normalization for Improving Corruption Robustness. (arXiv:2010.03630v1 [cs.CV])</h2>
<h3>Philipp Benz, Chaoning Zhang, Adil Karjauv, In So Kweon</h3>
<p>Modern deep neural networks (DNN) have demonstrated remarkable success in
image recognition tasks when the test dataset and training dataset are from the
same distribution. In practical applications, however, this assumption is often
not valid and results in performance drop when there is a domain shift. For
example, the performance of DNNs trained on clean images has been shown to
decrease when the test images have common corruptions, limiting their use in
performance-sensitive applications. In this work, we interpret corruption
robustness as a domain shift problem and propose to rectify batch normalization
(BN) statistics for improving model robustness. This shift from the clean
domain to the corruption domain can be interpreted as a style shift that is
represented by the BN statistics. Straightforwardly, adapting BN statistics is
beneficial for rectifying this style shift. Specifically, we find that simply
estimating and adapting the BN statistics on a few (32 for instance)
representation samples, without retraining the model, improves the corruption
robustness by a large margin on several benchmark datasets with a wide range of
model architectures. For example, on ImageNet-C, statistics adaptation improves
the top1 accuracy from 40.2% to 49%. Moreover, we find that this technique can
further improve state-of-the-art robust models from 59.0% to 63.5%.
</p>
<a href="http://arxiv.org/abs/2010.03630" target="_blank">arXiv:2010.03630</a> [<a href="http://arxiv.org/pdf/2010.03630" target="_blank">pdf</a>]

<h2>Hierarchical Relational Inference. (arXiv:2010.03635v1 [cs.LG])</h2>
<h3>Aleksandar Stani&#x107;, Sjoerd van Steenkiste, J&#xfc;rgen Schmidhuber</h3>
<p>Common-sense physical reasoning in the real world requires learning about the
interactions of objects and their dynamics. The notion of an abstract object,
however, encompasses a wide variety of physical objects that differ greatly in
terms of the complex behaviors they support. To address this, we propose a
novel approach to physical reasoning that models objects as hierarchies of
parts that may locally behave separately, but also act more globally as a
single whole. Unlike prior approaches, our method learns in an unsupervised
fashion directly from raw visual images to discover objects, parts, and their
relations. It explicitly distinguishes multiple levels of abstraction and
improves over a strong baseline at modeling synthetic and real-world videos.
</p>
<a href="http://arxiv.org/abs/2010.03635" target="_blank">arXiv:2010.03635</a> [<a href="http://arxiv.org/pdf/2010.03635" target="_blank">pdf</a>]

<h2>pymia: A Python package for data handling and evaluation in deep learning-based medical image analysis. (arXiv:2010.03639v1 [eess.IV])</h2>
<h3>Alain Jungo, Olivier Scheidegger, Mauricio Reyes, Fabian Balsiger</h3>
<p>Background and Objective: Deep learning enables tremendous progress in
medical image analysis. One driving force of this progress are open-source
frameworks like TensorFlow and PyTorch. However, these frameworks rarely
address issues specific to the domain of medical image analysis, such as 3-D
data handling and distance metrics for evaluation. pymia, an open-source Python
package, tries to address these issues by providing flexible data handling and
evaluation independent of the deep learning framework.

Methods: The pymia package provides data handling and evaluation
functionalities. The data handling allows flexible medical image handling in
every commonly used format (e.g., 2-D, 2.5-D, and 3-D; full- or patch-wise).
Even data beyond images like demographics or clinical reports can easily be
integrated into deep learning pipelines. The evaluation allows stand-alone
result calculation and reporting, as well as performance monitoring during
training using a vast amount of domain-specific metrics for segmentation,
reconstruction, and regression.

Results: The pymia package is highly flexible, allows for fast prototyping,
and reduces the burden of implementing data handling routines and evaluation
methods. While data handling and evaluation are independent of the deep
learning framework used, they can easily be integrated into TensorFlow and
PyTorch pipelines. The developed package was successfully used in a variety of
research projects for segmentation, reconstruction, and regression.

Conclusions: The pymia package fills the gap of current deep learning
frameworks regarding data handling and evaluation in medical image analysis. It
is available at https://github.com/rundherum/pymia and can directly be
installed from the Python Package Index using pip install pymia.
</p>
<a href="http://arxiv.org/abs/2010.03639" target="_blank">arXiv:2010.03639</a> [<a href="http://arxiv.org/pdf/2010.03639" target="_blank">pdf</a>]

<h2>Parkland Trauma Index of Mortality (PTIM): Real-time Predictive Model for PolyTrauma Patients. (arXiv:2010.03642v1 [q-bio.QM])</h2>
<h3>Adam J. Starr, Manjula Julka, Arun Nethi, John D. Watkins, Ryan W. Fairchild, Michael W. Cripps, Dustin Rinehart, Hayden N. Box</h3>
<p>Vital signs and laboratory values are routinely used to guide clinical
decision-making for polytrauma patients, such as the decision to use damage
control techniques versus early definitive fracture fixation. Prior
multivariate models have tried to predict mortality risk, but due to several
limitations like one-time prediction at the time of admission, they have not
proven clinically useful. There is a need for a dynamic model that captures
evolving physiologic changes during patient's hospital course to trauma and
resuscitation for mortality prediction. The Parkland Trauma Index of Mortality
(PTIM) is a machine learning algorithm that uses electronic medical record
(EMR) data to predict $48-$hour mortality during the first $72$ hours of
hospitalization. The model updates every hour, evolving with the patient's
physiologic response to trauma. Area under (AUC) the receiver-operator
characteristic curve (ROC), sensitivity, specificity, positive (PPV) and
negative predictive value (NPV), and positive and negative likelihood ratios
(LR) were used to evaluate model performance. By evolving with the patient's
physiologic response to trauma and relying only on EMR data, the PTIM overcomes
many of the limitations of prior mortality risk models. It may be a useful tool
to inform clinical decision-making for polytrauma patients early in their
hospitalization.
</p>
<a href="http://arxiv.org/abs/2010.03642" target="_blank">arXiv:2010.03642</a> [<a href="http://arxiv.org/pdf/2010.03642" target="_blank">pdf</a>]

<h2>Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations. (arXiv:2010.03644v1 [cs.CL])</h2>
<h3>Wanrong Zhu, Xin Eric Wang, Pradyumna Narayana, Kazoo Sone, Sugato Basu, William Yang Wang</h3>
<p>A major challenge in visually grounded language generation is to build robust
benchmark datasets and models that can generalize well in real-world settings.
To do this, it is critical to ensure that our evaluation protocols are correct,
and benchmarks are reliable. In this work, we set forth to design a set of
experiments to understand an important but often ignored problem in visually
grounded language generation: given that humans have different utilities and
visual attention, how will the sample variance in multi-reference datasets
affect the models' performance? Empirically, we study several multi-reference
datasets and corresponding vision-and-language tasks. We show that it is of
paramount importance to report variance in experiments; that human-generated
references could vary drastically in different datasets/tasks, revealing the
nature of each task; that metric-wise, CIDEr has shown systematically larger
variances than others. Our evaluations on reference-per-instance shed light on
the design of reliable datasets in the future.
</p>
<a href="http://arxiv.org/abs/2010.03644" target="_blank">arXiv:2010.03644</a> [<a href="http://arxiv.org/pdf/2010.03644" target="_blank">pdf</a>]

<h2>A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks. (arXiv:2010.03648v1 [cs.CL])</h2>
<h3>Nikunj Saunshi, Sadhika Malladi, Sanjeev Arora</h3>
<p>Autoregressive language models pretrained on large corpora have been
successful at solving downstream tasks, even with zero-shot usage. However,
there is little theoretical justification for their success. This paper
considers the following questions: (1) Why should learning the distribution of
natural language help with downstream classification tasks? (2) Why do features
learned using language modeling help solve downstream tasks with linear
classifiers? For (1), we hypothesize, and verify empirically, that
classification tasks of interest can be reformulated as next word prediction
tasks, thus making language modeling a meaningful pretraining task. For (2), we
analyze properties of the cross-entropy objective to show that
$\epsilon$-optimal language models in cross-entropy (log-perplexity) learn
features that are $\mathcal{O}(\sqrt{\epsilon})$-good on natural linear
classification tasks, thus demonstrating mathematically that doing well on
language modeling can be beneficial for downstream tasks. We perform
experiments to verify assumptions and validate theoretical results. Our
theoretical insights motivate a simple alternative to the cross-entropy
objective that performs well on some linear classification tasks.
</p>
<a href="http://arxiv.org/abs/2010.03648" target="_blank">arXiv:2010.03648</a> [<a href="http://arxiv.org/pdf/2010.03648" target="_blank">pdf</a>]

<h2>Learning the aerodynamic design of supercritical airfoils through deep reinforcement learning. (arXiv:2010.03651v1 [cs.CE])</h2>
<h3>Runze Li, Yufei Zhang, Haixin Chen</h3>
<p>The aerodynamic design of modern civil aircraft requires a true sense of
intelligence since it requires a good understanding of transonic aerodynamics
and sufficient experience. Reinforcement learning is an artificial general
intelligence that can learn sophisticated skills by trial-and-error, rather
than simply extracting features or making predictions from data. The present
paper utilizes a deep reinforcement learning algorithm to learn the policy for
reducing the aerodynamic drag of supercritical airfoils. The policy is designed
to take actions based on features of the wall Mach number distribution so that
the learned policy can be more general. The initial policy for reinforcement
learning is pretrained through imitation learning, and the result is compared
with randomly generated initial policies. The policy is then trained in
environments based on surrogate models, of which the mean drag reduction of 200
airfoils can be effectively improved by reinforcement learning. The policy is
also tested by multiple airfoils in different flow conditions using
computational fluid dynamics calculations. The results show that the policy is
effective in both the training condition and other similar conditions, and the
policy can be applied repeatedly to achieve greater drag reduction.
</p>
<a href="http://arxiv.org/abs/2010.03651" target="_blank">arXiv:2010.03651</a> [<a href="http://arxiv.org/pdf/2010.03651" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Many-Body Ground State Preparation based on Counter-Diabatic Driving. (arXiv:2010.03655v1 [quant-ph])</h2>
<h3>Jiahao Yao, Lin Lin, Marin Bukov</h3>
<p>The Quantum Approximate Optimization Ansatz (QAOA) is a prominent example of
variational quantum algorithms. We propose a generalized QAOA ansatz called
CD-QAOA, which is inspired by the counter-diabatic (CD) driving procedure,
designed for quantum many-body systems, and optimized using a reinforcement
learning (RL) approach. The resulting hybrid control algorithm proves versatile
in preparing the ground state of quantum-chaotic many-body spin chains, by
minimizing the energy. We show that using terms occurring in the adiabatic
gauge potential as additional control unitaries, it is possible to achieve fast
high-fidelity many-body control away from the adiabatic regime. While each
unitary retains the conventional QAOA-intrinsic continuous control degree of
freedom such as the time duration, we take into account the order of the
multiple available unitaries appearing in the control sequence as an additional
discrete optimization problem. Endowing the policy gradient algorithm with an
autoregressive deep learning architecture to capture causality, we train the RL
agent to construct optimal sequences of unitaries. The algorithm has no access
to the quantum state, and we find that the protocol learned on small systems
may generalize to larger systems. By scanning a range of protocol durations, we
present numerical evidence for a finite quantum speed limit in the
nonintegrable mixed-field spin-1/2 Ising model, and for the suitability of the
ansatz to prepare ground states of the spin-1 Heisenberg chain in the
long-range and topologically ordered parameter regimes. This work paves the way
to incorporate recent success from deep learning for the purpose of quantum
many-body control.
</p>
<a href="http://arxiv.org/abs/2010.03655" target="_blank">arXiv:2010.03655</a> [<a href="http://arxiv.org/pdf/2010.03655" target="_blank">pdf</a>]

<h2>Robust Semi-Supervised Learning with Out of Distribution Data. (arXiv:2010.03658v1 [cs.LG])</h2>
<h3>Xujiang Zhao, Killamsetty Krishnateja, Rishabh Iyer, Feng Chen</h3>
<p>Semi-supervised learning (SSL) based on deep neural networks (DNNs) has
recently been proven effective. However, recent work [Oliver et al., 2018]
shows that the performance of SSL could degrade substantially when the
unlabeled set has out-of-distribution examples (OODs). In this work, we first
study the key causes about the negative impact of OOD on SSL. We found that (1)
OODs close to the decision boundary have a larger effect on the performance of
existing SSL algorithms than the OODs far away from the decision boundary and
(2) Batch Normalization (BN), a popular module in deep networks, could degrade
the performance of a DNN for SSL substantially when the unlabeled set contains
OODs. To address these causes, we proposed a novel unified robust SSL approach
for many existing SSL algorithms in order to improve their robustness against
OODs. In particular, we proposed a simple modification to batch normalization,
called weighted batch normalization, capable of improving the robustness of BN
against OODs. We developed two efficient hyperparameter optimization algorithms
that have different tradeoffs in computational efficiency and accuracy. The
first is meta-approximation and the second is implicit-differentiation based
approximation. Both algorithms learn to reweight the unlabeled samples in order
to improve the robustness of SSL against OODs. Extensive experiments on both
synthetic and real-world datasets demonstrate that our proposed approach
significantly improves the robustness of four representative SSL algorithms
against OODs, in comparison with four state-of-the-art robust SSL approaches.
We performed an ablation study to demonstrate which components of our approach
are most important for its success.
</p>
<a href="http://arxiv.org/abs/2010.03658" target="_blank">arXiv:2010.03658</a> [<a href="http://arxiv.org/pdf/2010.03658" target="_blank">pdf</a>]

<h2>Multivariate Temporal Autoencoder for Predictive Reconstruction of Deep Sequences. (arXiv:2010.03661v1 [cs.LG])</h2>
<h3>Jakob Aungiers</h3>
<p>Time series sequence prediction and modelling has proven to be a challenging
endeavor in real world datasets. Two key issues are the multi-dimensionality of
data and the interaction of independent dimensions forming a latent output
signal, as well as the representation of multi-dimensional temporal data inside
of a predictive model. This paper proposes a multi-branch deep neural network
approach to tackling the aforementioned problems by modelling a latent state
vector representation of data windows through the use of a recurrent
autoencoder branch and subsequently feeding the trained latent vector
representation into a predictor branch of the model. This model is henceforth
referred to as Multivariate Temporal Autoencoder (MvTAe). The framework in this
paper utilizes a synthetic multivariate temporal dataset which contains
dimensions that combine to create a hidden output target.
</p>
<a href="http://arxiv.org/abs/2010.03661" target="_blank">arXiv:2010.03661</a> [<a href="http://arxiv.org/pdf/2010.03661" target="_blank">pdf</a>]

<h2>Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank. (arXiv:2010.03662v1 [cs.CL])</h2>
<h3>Eleftheria Briakou, Marine Carpuat</h3>
<p>Detecting fine-grained differences in content conveyed in different languages
matters for cross-lingual NLP and multilingual corpora analysis, but it is a
challenging machine learning problem since annotation is expensive and hard to
scale. This work improves the prediction and annotation of fine-grained
semantic divergences. We introduce a training strategy for multilingual BERT
models by learning to rank synthetic divergent examples of varying granularity.
We evaluate our models on the Rationalized English-French Semantic Divergences,
a new dataset released with this work, consisting of English-French
sentence-pairs annotated with semantic divergence classes and token-level
rationales. Learning to rank helps detect fine-grained sentence-level
divergences more accurately than a strong sentence-level similarity model,
while token-level predictions have the potential of further distinguishing
between coarse and fine-grained divergences.
</p>
<a href="http://arxiv.org/abs/2010.03662" target="_blank">arXiv:2010.03662</a> [<a href="http://arxiv.org/pdf/2010.03662" target="_blank">pdf</a>]

<h2>Adversarial Attacks to Machine Learning-Based Smart Healthcare Systems. (arXiv:2010.03671v1 [cs.LG])</h2>
<h3>AKM Iqtidar Newaz, Nur Imtiazul Haque, Amit Kumar Sikder, Mohammad Ashiqur Rahman, A. Selcuk Uluagac</h3>
<p>The increasing availability of healthcare data requires accurate analysis of
disease diagnosis, progression, and realtime monitoring to provide improved
treatments to the patients. In this context, Machine Learning (ML) models are
used to extract valuable features and insights from high-dimensional and
heterogeneous healthcare data to detect different diseases and patient
activities in a Smart Healthcare System (SHS). However, recent researches show
that ML models used in different application domains are vulnerable to
adversarial attacks. In this paper, we introduce a new type of adversarial
attacks to exploit the ML classifiers used in a SHS. We consider an adversary
who has partial knowledge of data distribution, SHS model, and ML algorithm to
perform both targeted and untargeted attacks. Employing these adversarial
capabilities, we manipulate medical device readings to alter patient status
(disease-affected, normal condition, activities, etc.) in the outcome of the
SHS. Our attack utilizes five different adversarial ML algorithms (HopSkipJump,
Fast Gradient Method, Crafting Decision Tree, Carlini &amp; Wagner, Zeroth Order
Optimization) to perform different malicious activities (e.g., data poisoning,
misclassify outputs, etc.) on a SHS. Moreover, based on the training and
testing phase capabilities of an adversary, we perform white box and black box
attacks on a SHS. We evaluate the performance of our work in different SHS
settings and medical devices. Our extensive evaluation shows that our proposed
adversarial attack can significantly degrade the performance of a ML-based SHS
in detecting diseases and normal activities of the patients correctly, which
eventually leads to erroneous treatment.
</p>
<a href="http://arxiv.org/abs/2010.03671" target="_blank">arXiv:2010.03671</a> [<a href="http://arxiv.org/pdf/2010.03671" target="_blank">pdf</a>]

<h2>Predicting Mechanical Properties from Microstructure Images in Fiber-reinforced Polymers using Convolutional Neural Networks. (arXiv:2010.03675v1 [cond-mat.mtrl-sci])</h2>
<h3>Yixuan Sun, Imad Hanhan, Michael D. Sangid, Guang Lin</h3>
<p>Evaluating the mechanical response of fiber-reinforced composites can be
extremely time consuming and expensive. Machine learning (ML) techniques offer
a means for faster predictions via models trained on existing input-output
pairs and have exhibited success in composite research. This paper explores a
fully convolutional neural network modified from StressNet, which was
originally for lin-ear elastic materials and extended here for a non-linear
finite element (FE) simulation to predict the stress field in 2D slices of
segmented tomography images of a fiber-reinforced polymer specimen. The network
was trained and evaluated on data generated from the FE simulations of the
exact microstructure. The testing results show that the trained network
accurately captures the characteristics of the stress distribution, especially
on fibers, solely from the segmented microstructure images. The trained model
can make predictions within seconds in a single forward pass on an ordinary
laptop, given the input microstructure, compared to 92.5 hours to run the full
FE simulation on a high-performance computing cluster. These results show
promise in using ML techniques to conduct fast structural analysis for
fiber-reinforced composites and suggest a corollary that the trained model can
be used to identify the location of potential damage sites in fiber-reinforced
polymers.
</p>
<a href="http://arxiv.org/abs/2010.03675" target="_blank">arXiv:2010.03675</a> [<a href="http://arxiv.org/pdf/2010.03675" target="_blank">pdf</a>]

<h2>Adaptive Self-training for Few-shot Neural Sequence Labeling. (arXiv:2010.03680v1 [cs.CL])</h2>
<h3>Yaqing Wang, Subhabrata Mukherjee, Haoda Chu, Yuancheng Tu, Ming Wu, Jing Gao, Ahmed Hassan Awadallah</h3>
<p>Neural sequence labeling is an important technique employed for many Natural
Language Processing (NLP) tasks, such as Named Entity Recognition (NER), slot
tagging for dialog systems and semantic parsing. Large-scale pre-trained
language models obtain very good performance on these tasks when fine-tuned on
large amounts of task-specific labeled data. However, such large-scale labeled
datasets are difficult to obtain for several tasks and domains due to the high
cost of human annotation as well as privacy and data access constraints for
sensitive user applications. This is exacerbated for sequence labeling tasks
requiring such annotations at token-level. In this work, we develop techniques
to address the label scarcity challenge for neural sequence labeling models.
Specifically, we develop self-training and meta-learning techniques for
few-shot training of neural sequence taggers, namely MetaST. While
self-training serves as an effective mechanism to learn from large amounts of
unlabeled data -- meta-learning helps in adaptive sample re-weighting to
mitigate error propagation from noisy pseudo-labels. Extensive experiments on
six benchmark datasets including two massive multilingual NER datasets and four
slot tagging datasets for task-oriented dialog systems demonstrate the
effectiveness of our method with around 10% improvement over state-of-the-art
systems for the 10-shot setting.
</p>
<a href="http://arxiv.org/abs/2010.03680" target="_blank">arXiv:2010.03680</a> [<a href="http://arxiv.org/pdf/2010.03680" target="_blank">pdf</a>]

<h2>Optimizing Transformers with Approximate Computing for Faster, Smaller and more Accurate NLP Models. (arXiv:2010.03688v1 [cs.CL])</h2>
<h3>Amrit Nagarajan, Sanchari Sen, Jacob R. Stevens, Anand Raghunathan</h3>
<p>Transformer models have garnered a lot of interest in recent years by
delivering state-of-the-art performance in a range of Natural Language
Processing (NLP) tasks. However, these models can have over a hundred billion
parameters, presenting very high computational and memory requirements. We
address this challenge through Approximate Computing, specifically targeting
the use of Transformers in NLP tasks. Transformers are typically pre-trained
and subsequently specialized for specific tasks through transfer learning.
Based on the observation that pre-trained Transformers are often
over-parameterized for several downstream NLP tasks, we propose a framework to
create smaller, faster and in some cases more accurate models. The key
cornerstones of the framework are a Significance Analysis (SA) method that
identifies components in a pre-trained Transformer that are less significant
for a given task, and techniques to approximate the less significant
components. Our approximations include pruning of blocks, attention heads and
weight groups, quantization of less significant weights and a low-complexity
sign-matching based attention mechanism. Our framework can be adapted to
produce models that are faster, smaller and/or more accurate, depending on the
user's constraints. We apply our framework to seven Transformer models,
including optimized models like DistilBERT and Q8BERT, and three downstream
tasks. We demonstrate that our framework produces models that are up to 4x
faster and up to 14x smaller (with less than 0.5% relative accuracy
degradation), or up to 5.5% more accurate with simultaneous improvements of up
to 9.83x in model size or 2.94x in speed.
</p>
<a href="http://arxiv.org/abs/2010.03688" target="_blank">arXiv:2010.03688</a> [<a href="http://arxiv.org/pdf/2010.03688" target="_blank">pdf</a>]

<h2>Regularized Inverse Reinforcement Learning. (arXiv:2010.03691v1 [cs.LG])</h2>
<h3>Wonseok Jeon, Chen-Yang Su, Paul Barde, Thang Doan, Derek Nowrouzezahrai, Joelle Pineau</h3>
<p>Inverse Reinforcement Learning (IRL) aims to facilitate a learner's ability
to imitate expert behavior by acquiring reward functions that explain the
expert's decisions. Regularized IRL applies convex regularizers to the
learner's policy in order to avoid the expert's behavior being rationalized by
arbitrary constant rewards, also known as degenerate solutions. We propose
analytical solutions, and practical methods to obtain them, for regularized
IRL. Current methods are restricted to the maximum-entropy IRL framework,
limiting them to Shannon-entropy regularizers, as well as proposing
functional-form solutions that are generally intractable. We present
theoretical backing for our proposed IRL method's applicability to both
discrete and continuous controls and empirically validate its performance on a
variety of tasks.
</p>
<a href="http://arxiv.org/abs/2010.03691" target="_blank">arXiv:2010.03691</a> [<a href="http://arxiv.org/pdf/2010.03691" target="_blank">pdf</a>]

<h2>An Audio-Video Deep and Transfer Learning Framework for Multimodal Emotion Recognition in the wild. (arXiv:2010.03692v1 [cs.LG])</h2>
<h3>Denis Dresvyanskiy, Elena Ryumina, Heysem Kaya, Maxim Markitantov, Alexey Karpov, Wolfgang Minker</h3>
<p>In this paper, we present our contribution to ABAW facial expression
challenge. We report the proposed system and the official challenge results
adhering to the challenge protocol. Using end-to-end deep learning and
benefiting from transfer learning approaches, we reached a validation set
challenge performance measure of 56.56%.
</p>
<a href="http://arxiv.org/abs/2010.03692" target="_blank">arXiv:2010.03692</a> [<a href="http://arxiv.org/pdf/2010.03692" target="_blank">pdf</a>]

<h2>Learning Intrinsic Symbolic Rewards in Reinforcement Learning. (arXiv:2010.03694v1 [cs.LG])</h2>
<h3>Hassam Sheikh, Shauharda Khadka, Santiago Miret, Somdeb Majumdar</h3>
<p>Learning effective policies for sparse objectives is a key challenge in Deep
Reinforcement Learning (RL). A common approach is to design task-related dense
rewards to improve task learnability. While such rewards are easily
interpreted, they rely on heuristics and domain expertise. Alternate approaches
that train neural networks to discover dense surrogate rewards avoid
heuristics, but are high-dimensional, black-box solutions offering little
interpretability. In this paper, we present a method that discovers dense
rewards in the form of low-dimensional symbolic trees - thus making them more
tractable for analysis. The trees use simple functional operators to map an
agent's observations to a scalar reward, which then supervises the policy
gradient learning of a neural network policy. We test our method on continuous
action spaces in Mujoco and discrete action spaces in Atari and Pygame
environments. We show that the discovered dense rewards are an effective signal
for an RL policy to solve the benchmark tasks. Notably, we significantly
outperform a widely used, contemporary neural-network based reward-discovery
algorithm in all environments considered.
</p>
<a href="http://arxiv.org/abs/2010.03694" target="_blank">arXiv:2010.03694</a> [<a href="http://arxiv.org/pdf/2010.03694" target="_blank">pdf</a>]

<h2>A Critique of Self-Expressive Deep Subspace Clustering. (arXiv:2010.03697v1 [cs.LG])</h2>
<h3>Benjamin D. Haeffele, Chong You, Ren&#xe9; Vidal</h3>
<p>Subspace clustering is an unsupervised clustering technique designed to
cluster data that is supported on a union of linear subspaces, with each
subspace defining a cluster with dimension lower than the ambient space. Many
existing formulations for this problem are based on exploiting the
self-expressive property of linear subspaces, where any point within a subspace
can be represented as linear combination of other points within the subspace.
To extend this approach to data supported on a union of non-linear manifolds,
numerous studies have proposed learning an appropriate kernel embedding of the
original data using a neural network, which is regularized by a self-expressive
loss function on the data in the embedded space to encourage a union of linear
subspaces prior on the data in the embedded space. Here we show that there are
a number of potential flaws with this approach which have not been adequately
addressed in prior work. In particular, we show the model formulation is often
ill-posed in multiple ways, which can lead to a degenerate embedding of the
data, which need not correspond to a union of subspaces at all. We validate our
theoretical results experimentally and additionally repeat prior experiments
reported in the literature, where we conclude that a significant portion of the
previously claimed performance benefits can be attributed to an ad-hoc post
processing step rather than the clustering model.
</p>
<a href="http://arxiv.org/abs/2010.03697" target="_blank">arXiv:2010.03697</a> [<a href="http://arxiv.org/pdf/2010.03697" target="_blank">pdf</a>]

<h2>Differentially Private Deep Learning with Direct Feedback Alignment. (arXiv:2010.03701v1 [cs.LG])</h2>
<h3>Jaewoo Lee, Daniel Kifer</h3>
<p>Standard methods for differentially private training of deep neural networks
replace back-propagated mini-batch gradients with biased and noisy
approximations to the gradient. These modifications to training often result in
a privacy-preserving model that is significantly less accurate than its
non-private counterpart. We hypothesize that alternative training algorithms
may be more amenable to differential privacy. Specifically, we examine the
suitability of direct feedback alignment (DFA). We propose the first
differentially private method for training deep neural networks with DFA and
show that it achieves significant gains in accuracy (often by 10-20%) compared
to backprop-based differentially private training on a variety of architectures
(fully connected, convolutional) and datasets.
</p>
<a href="http://arxiv.org/abs/2010.03701" target="_blank">arXiv:2010.03701</a> [<a href="http://arxiv.org/pdf/2010.03701" target="_blank">pdf</a>]

<h2>Learning to Recombine and Resample Data for Compositional Generalization. (arXiv:2010.03706v1 [cs.CL])</h2>
<h3>Ekin Aky&#xfc;rek, Afra Feyza Aky&#xfc;rek, Jacob Andreas</h3>
<p>Flexible neural models outperform grammar- and automaton-based counterparts
on a variety of sequence modeling tasks. However, neural models perform poorly
in settings requiring compositional generalization beyond the training data --
particularly to rare or unseen subsequences. Past work has found symbolic
scaffolding (e.g. grammars or automata) essential in these settings. Here we
present a family of learned data augmentation schemes that support a large
category of compositional generalizations without appeal to latent symbolic
structure. Our approach to data augmentation has two components: recombination
of original training examples via a prototype-based generative model and
resampling of generated examples to encourage extrapolation. Training an
ordinary neural sequence model on a dataset augmented with recombined and
resampled examples significantly improves generalization in two language
processing problems---instruction following (SCAN) and morphological analysis
(Sigmorphon 2018)---where our approach enables learning of new constructions
and tenses from as few as eight initial examples.
</p>
<a href="http://arxiv.org/abs/2010.03706" target="_blank">arXiv:2010.03706</a> [<a href="http://arxiv.org/pdf/2010.03706" target="_blank">pdf</a>]

<h2>Topic Diffusion Discovery Based on Deep Non-negative Autoencoder. (arXiv:2010.03710v1 [stat.ML])</h2>
<h3>Sheng-Tai Huang, Yihuang Kang, Shao-Min Hung, Bowen Kuo, I-Ling Cheng</h3>
<p>Researchers have been overwhelmed by the explosion of research articles
published by various research communities. Many research scholarly websites,
search engines, and digital libraries have been created to help researchers
identify potential research topics and keep up with recent progress on research
of interests. However, it is still difficult for researchers to keep track of
the research topic diffusion and evolution without spending a large amount of
time reviewing numerous relevant and irrelevant articles. In this paper, we
consider a novel topic diffusion discovery technique. Specifically, we propose
using a Deep Non-negative Autoencoder with information divergence measurement
that monitors evolutionary distance of the topic diffusion to understand how
research topics change with time. The experimental results show that the
proposed approach is able to identify the evolution of research topics as well
as to discover topic diffusions in online fashions.
</p>
<a href="http://arxiv.org/abs/2010.03710" target="_blank">arXiv:2010.03710</a> [<a href="http://arxiv.org/pdf/2010.03710" target="_blank">pdf</a>]

<h2>Deep Tiered Image Segmentation forDetecting Internal Ice Layers in Radar Imagery. (arXiv:2010.03712v1 [cs.CV])</h2>
<h3>Yuchen Wang, Mingze Xu, John Paden, Lora Koenig, Geoffrey Fox, David Crandall</h3>
<p>Understanding the structure of the ice at the Earth's poles is important for
modeling how global warming will impact polar ice and, in turn, the Earth's
climate. Ground-penetrating radar is able to collect observations of the
internal structure of snow and ice, but the process of manually labeling these
observations with layer boundaries is slow and laborious. Recent work has
developed automatic techniques for finding ice-bed boundaries, but finding
internal boundaries is much more challenging because the number of layers is
unknown and the layers can disappear, reappear, merge, and split. In this
paper, we propose a novel deep neural network-based model for solving a general
class of tiered segmentation problems. We then apply it to detecting internal
layers in polar ice, and evaluate on a large-scale dataset of polar ice radar
data with human-labeled annotations as ground truth.
</p>
<a href="http://arxiv.org/abs/2010.03712" target="_blank">arXiv:2010.03712</a> [<a href="http://arxiv.org/pdf/2010.03712" target="_blank">pdf</a>]

<h2>Don't Parse, Insert: Multilingual Semantic Parsing with Insertion Based Decoding. (arXiv:2010.03714v1 [cs.CL])</h2>
<h3>Qile Zhu, Haidar Khan, Saleh Soltan, Stephen Rawls, Wael Hamza</h3>
<p>Semantic parsing is one of the key components of natural language
understanding systems. A successful parse transforms an input utterance to an
action that is easily understood by the system. Many algorithms have been
proposed to solve this problem, from conventional rulebased or statistical
slot-filling systems to shiftreduce based neural parsers. For complex parsing
tasks, the state-of-the-art method is based on autoregressive sequence to
sequence models to generate the parse directly. This model is slow at inference
time, generating parses in O(n) decoding steps (n is the length of the target
sequence). In addition, we demonstrate that this method performs poorly in
zero-shot cross-lingual transfer learning settings. In this paper, we propose a
non-autoregressive parser which is based on the insertion transformer to
overcome these two issues. Our approach 1) speeds up decoding by 3x while
outperforming the autoregressive model and 2) significantly improves
cross-lingual transfer in the low-resource setting by 37% compared to
autoregressive baseline. We test our approach on three well-known monolingual
datasets: ATIS, SNIPS and TOP. For cross lingual semantic parsing, we use the
MultiATIS++ and the multilingual TOP datasets.
</p>
<a href="http://arxiv.org/abs/2010.03714" target="_blank">arXiv:2010.03714</a> [<a href="http://arxiv.org/pdf/2010.03714" target="_blank">pdf</a>]

<h2>Simplifying the explanation of deep neural networks with sufficient and necessary feature-sets: case of text classification. (arXiv:2010.03724v1 [cs.LG])</h2>
<h3>Jiechieu Kameni Florentin Flambeau, Tsopze Norbert</h3>
<p>During the last decade, deep neural networks (DNN) have demonstrated
impressive performances solving a wide range of problems in various domains
such as medicine, finance, law, etc. Despite their great performances, they
have long been considered as black-box systems, providing good results without
being able to explain them. However, the inability to explain a system decision
presents a serious risk in critical domains such as medicine where people's
lives are at stake. Several works have been done to uncover the inner reasoning
of deep neural networks. Saliency methods explain model decisions by assigning
weights to input features that reflect their contribution to the classifier
decision. However, not all features are necessary to explain a model decision.
In practice, classifiers might strongly rely on a subset of features that might
be sufficient to explain a particular decision. The aim of this article is to
propose a method to simplify the prediction explanation of One-Dimensional (1D)
Convolutional Neural Networks (CNN) by identifying sufficient and necessary
features-sets. We also propose an adaptation of Layer-wise Relevance
Propagation for 1D-CNN. Experiments carried out on multiple datasets show that
the distribution of relevance among features is similar to that obtained with a
well known state of the art model. Moreover, the sufficient and necessary
features extracted perceptually appear convincing to humans.
</p>
<a href="http://arxiv.org/abs/2010.03724" target="_blank">arXiv:2010.03724</a> [<a href="http://arxiv.org/pdf/2010.03724" target="_blank">pdf</a>]

<h2>Learning to Fuse Sentences with Transformers for Summarization. (arXiv:2010.03726v1 [cs.CL])</h2>
<h3>Logan Lebanoff, Franck Dernoncourt, Doo Soon Kim, Lidan Wang, Walter Chang, Fei Liu</h3>
<p>The ability to fuse sentences is highly attractive for summarization systems
because it is an essential step to produce succinct abstracts. However, to
date, summarizers can fail on fusing sentences. They tend to produce few
summary sentences by fusion or generate incorrect fusions that lead the summary
to fail to retain the original meaning. In this paper, we explore the ability
of Transformers to fuse sentences and propose novel algorithms to enhance their
ability to perform sentence fusion by leveraging the knowledge of points of
correspondence between sentences. Through extensive experiments, we investigate
the effects of different design choices on Transformer's performance. Our
findings highlight the importance of modeling points of correspondence between
sentences for effective sentence fusion.
</p>
<a href="http://arxiv.org/abs/2010.03726" target="_blank">arXiv:2010.03726</a> [<a href="http://arxiv.org/pdf/2010.03726" target="_blank">pdf</a>]

<h2>Robust Multi-class Feature Selection via $l_{2,0}$-Norm Regularization Minimization. (arXiv:2010.03728v1 [cs.LG])</h2>
<h3>Zhenzhen Sun, Yuanlong Yu</h3>
<p>Feature selection is an important data preprocessing in data mining and
machine learning, which can reduce feature size without deteriorating model's
performance. Recently, sparse regression based feature selection methods have
received considerable attention due to their good performance. However, these
methods generally cannot determine the number of selected features
automatically without using a predefined threshold. In order to get a
satisfactory result, it often costs significant time and effort to tune the
number of selected features carefully. To this end, this paper proposed a novel
framework to solve the $l_{2,0}$-norm regularization least square problem
directly for multi-class feature selection, which can produce exact rowsparsity
solution for the weights matrix, features corresponding to non-zero rows will
be selected thus the number of selected features can be determined
automatically. An efficient homotopy iterative hard threshold (HIHT) algorithm
is derived to solve the above optimization problem and find out the stable
local solution. Besides, in order to reduce the computational time of HIHT, an
acceleration version of HIHT (AHIHT) is derived. Extensive experiments on eight
biological datasets show that the proposed method can achieve higher
classification accuracy with fewest number of selected features comparing with
the approximate convex counterparts and state-of-the-art feature selection
methods. The robustness of classification accuracy to the regularization
parameter is also exhibited.
</p>
<a href="http://arxiv.org/abs/2010.03728" target="_blank">arXiv:2010.03728</a> [<a href="http://arxiv.org/pdf/2010.03728" target="_blank">pdf</a>]

<h2>Leveraging Discourse Rewards for Document-Level Neural Machine Translation. (arXiv:2010.03732v1 [cs.CL])</h2>
<h3>Inigo Jauregi Unanue, Nazanin Esmaili, Gholamreza Haffari, Massimo Piccardi</h3>
<p>Document-level machine translation focuses on the translation of entire
documents from a source to a target language. It is widely regarded as a
challenging task since the translation of the individual sentences in the
document needs to retain aspects of the discourse at document level. However,
document-level translation models are usually not trained to explicitly ensure
discourse quality. Therefore, in this paper we propose a training approach that
explicitly optimizes two established discourse metrics, lexical cohesion (LC)
and coherence (COH), by using a reinforcement learning objective. Experiments
over four different language pairs and three translation domains have shown
that our training approach has been able to achieve more cohesive and coherent
document translations than other competitive approaches, yet without
compromising the faithfulness to the reference translation. In the case of the
Zh-En language pair, our method has achieved an improvement of 2.46 percentage
points (pp) in LC and 1.17 pp in COH over the runner-up, while at the same time
improving 0.63 pp in BLEU score and 0.47 pp in F_BERT.
</p>
<a href="http://arxiv.org/abs/2010.03732" target="_blank">arXiv:2010.03732</a> [<a href="http://arxiv.org/pdf/2010.03732" target="_blank">pdf</a>]

<h2>Neural Group Actions. (arXiv:2010.03733v1 [stat.ML])</h2>
<h3>Span Spanbauer, Luke Sciarappa</h3>
<p>We introduce an algorithm for designing Neural Group Actions, collections of
deep neural network architectures which model symmetric transformations
satisfying the laws of a given finite group. This generalizes involutive neural
networks $\mathcal{N}$, which satisfy $\mathcal{N}(\mathcal{N}(x))=x$ for any
data $x$, the group law of $\mathbb{Z}_2$. We show how to optionally enforce an
additional constraint that the group action be volume-preserving. We
conjecture, by analogy to a universality result for involutive neural networks,
that generative models built from Neural Group Actions are universal
approximators for collections of probabilistic transitions adhering to the
group laws. We demonstrate experimentally that a Neural Group Action for the
quaternion group $Q_8$ can learn how a set of nonuniversal quantum gates
satisfying the $Q_8$ group laws act on single qubit quantum states.
</p>
<a href="http://arxiv.org/abs/2010.03733" target="_blank">arXiv:2010.03733</a> [<a href="http://arxiv.org/pdf/2010.03733" target="_blank">pdf</a>]

<h2>Decamouflage: A Framework to Detect Image-Scaling Attacks on Convolutional Neural Networks. (arXiv:2010.03735v1 [cs.CV])</h2>
<h3>Bedeuro Kim, Alsharif Abuadbba, Yansong Gao, Yifeng Zheng, Muhammad Ejaz Ahmed, Hyoungshick Kim, Surya Nepal</h3>
<p>As an essential processing step in computer vision applications, image
resizing or scaling, more specifically downsampling, has to be applied before
feeding a normally large image into a convolutional neural network (CNN) model
because CNN models typically take small fixed-size images as inputs. However,
image scaling functions could be adversarially abused to perform a newly
revealed attack called image-scaling attack, which can affect a wide range of
computer vision applications building upon image-scaling functions.

This work presents an image-scaling attack detection framework, termed as
Decamouflage. Decamouflage consists of three independent detection methods: (1)
rescaling, (2) filtering/pooling, and (3) steganalysis. While each of these
three methods is efficient standalone, they can work in an ensemble manner not
only to improve the detection accuracy but also to harden potential adaptive
attacks. Decamouflage has a pre-determined detection threshold that is generic.
More precisely, as we have validated, the threshold determined from one dataset
is also applicable to other different datasets. Extensive experiments show that
Decamouflage achieves detection accuracy of 99.9\% and 99.8\% in the white-box
(with the knowledge of attack algorithms) and the black-box (without the
knowledge of attack algorithms) settings, respectively. To corroborate the
efficiency of Decamouflage, we have also measured its run-time overhead on a
personal PC with an i5 CPU and found that Decamouflage can detect image-scaling
attacks in milliseconds. Overall, Decamouflage can accurately detect image
scaling attacks in both white-box and black-box settings with acceptable
run-time overhead.
</p>
<a href="http://arxiv.org/abs/2010.03735" target="_blank">arXiv:2010.03735</a> [<a href="http://arxiv.org/pdf/2010.03735" target="_blank">pdf</a>]

<h2>Shallow-to-Deep Training for Neural Machine Translation. (arXiv:2010.03737v1 [cs.CL])</h2>
<h3>Bei Li, Ziyang Wang, Hui Liu, Yufan Jiang, Quan Du, Tong Xiao, Huizhen Wang, Jingbo Zhu</h3>
<p>Deep encoders have been proven to be effective in improving neural machine
translation (NMT) systems, but training an extremely deep encoder is time
consuming. Moreover, why deep models help NMT is an open question. In this
paper, we investigate the behavior of a well-tuned deep Transformer system. We
find that stacking layers is helpful in improving the representation ability of
NMT models and adjacent layers perform similarly. This inspires us to develop a
shallow-to-deep training method that learns deep models by stacking shallow
models. In this way, we successfully train a Transformer system with a 54-layer
encoder. Experimental results on WMT'16 English-German and WMT'14
English-French translation tasks show that it is $1.4$ $\times$ faster than
training from scratch, and achieves a BLEU score of $30.33$ and $43.29$ on two
tasks. The code is publicly available at
https://github.com/libeineu/SDT-Training/.
</p>
<a href="http://arxiv.org/abs/2010.03737" target="_blank">arXiv:2010.03737</a> [<a href="http://arxiv.org/pdf/2010.03737" target="_blank">pdf</a>]

<h2>Maximum Reward Formulation In Reinforcement Learning. (arXiv:2010.03744v1 [cs.LG])</h2>
<h3>Sai Krishna Gottipati, Yashaswi Pathak, Rohan Nuttall, Sahir, Raviteja Chunduru, Ahmed Touati, Sriram Ganapathi Subramanian, Matthew E. Taylor, Sarath Chandar</h3>
<p>Reinforcement learning (RL) algorithms typically deal with maximizing the
expected cumulative return (discounted or undiscounted, finite or infinite
horizon). However, several crucial applications in the real world, such as drug
discovery, do not fit within this framework because an RL agent only needs to
identify states (molecules) that achieve the highest reward within a trajectory
and does not need to optimize for the expected cumulative return. In this work,
we formulate an objective function to maximize the expected maximum reward
along a trajectory, derive a novel functional form of the Bellman equation,
introduce the corresponding Bellman operators, and provide a proof of
convergence. Using this formulation, we achieve state-of-the-art results on the
task of molecule generation that mimics a real-world drug discovery pipeline.
</p>
<a href="http://arxiv.org/abs/2010.03744" target="_blank">arXiv:2010.03744</a> [<a href="http://arxiv.org/pdf/2010.03744" target="_blank">pdf</a>]

<h2>Tatum-Level Drum Transcription Based on a Convolutional Recurrent Neural Network with Language Model-Based Regularized Training. (arXiv:2010.03749v1 [cs.SD])</h2>
<h3>Ryoto Ishizuka, Ryo Nishikimi, Eita Nakamura, Kazuyoshi Yoshii</h3>
<p>This paper describes a neural drum transcription method that detects from
music signals the onset times of drums at the $\textit{tatum}$ level, where
tatum times are assumed to be estimated in advance. In conventional studies on
drum transcription, deep neural networks (DNNs) have often been used to take a
music spectrogram as input and estimate the onset times of drums at the
$\textit{frame}$ level. The major problem with such frame-to-frame DNNs,
however, is that the estimated onset times do not often conform with the
typical tatum-level patterns appearing in symbolic drum scores because the
long-term musically meaningful structures of those patterns are difficult to
learn at the frame level. To solve this problem, we propose a regularized
training method for a frame-to-tatum DNN. In the proposed method, a tatum-level
probabilistic language model (gated recurrent unit (GRU) network or
repetition-aware bi-gram model) is trained from an extensive collection of drum
scores. Given that the musical naturalness of tatum-level onset times can be
evaluated by the language model, the frame-to-tatum DNN is trained with a
regularizer based on the pretrained language model. The experimental results
demonstrate the effectiveness of the proposed regularized training method.
</p>
<a href="http://arxiv.org/abs/2010.03749" target="_blank">arXiv:2010.03749</a> [<a href="http://arxiv.org/pdf/2010.03749" target="_blank">pdf</a>]

<h2>Generalizable and Explainable Dialogue Generation via Explicit Action Learning. (arXiv:2010.03755v1 [cs.CL])</h2>
<h3>Xinting Huang, Jianzhong Qi, Yu Sun, Rui Zhang</h3>
<p>Response generation for task-oriented dialogues implicitly optimizes two
objectives at the same time: task completion and language quality. Conditioned
response generation serves as an effective approach to separately and better
optimize these two objectives. Such an approach relies on system action
annotations which are expensive to obtain. To alleviate the need of action
annotations, latent action learning is introduced to map each utterance to a
latent representation. However, this approach is prone to over-dependence on
the training data, and the generalization capability is thus restricted. To
address this issue, we propose to learn natural language actions that represent
utterances as a span of words. This explicit action representation promotes
generalization via the compositional structure of language. It also enables an
explainable generation process. Our proposed unsupervised approach learns a
memory component to summarize system utterances into a short span of words. To
further promote a compact action representation, we propose an auxiliary task
that restores state annotations as the summarized dialogue context using the
memory component. Our proposed approach outperforms latent action baselines on
MultiWOZ, a benchmark multi-domain dataset.
</p>
<a href="http://arxiv.org/abs/2010.03755" target="_blank">arXiv:2010.03755</a> [<a href="http://arxiv.org/pdf/2010.03755" target="_blank">pdf</a>]

<h2>AICov: An Integrative Deep Learning Framework for COVID-19 Forecasting with Population Covariates. (arXiv:2010.03757v1 [cs.LG])</h2>
<h3>Geoffrey C. Fox, Gregor von Laszewski, Fugang Wang, Saumyadipta Pyne</h3>
<p>The COVID-19 pandemic has profound global consequences on health, economic,
social, political, and almost every major aspect of human life. Therefore, it
is of great importance to model COVID-19 and other pandemics in terms of the
broader social contexts in which they take place. We present the architecture
of AICov, which provides an integrative deep learning framework for COVID-19
forecasting with population covariates, some of which may serve as putative
risk factors. We have integrated multiple different strategies into AICov,
including the ability to use deep learning strategies based on LSTM and even
modeling. To demonstrate our approach, we have conducted a pilot that
integrates population covariates from multiple sources. Thus, AICov not only
includes data on COVID-19 cases and deaths but, more importantly, the
population's socioeconomic, health and behavioral risk factors at a local
level. The compiled data are fed into AICov, and thus we obtain improved
prediction by integration of the data to our model as compared to one that only
uses case and death data.
</p>
<a href="http://arxiv.org/abs/2010.03757" target="_blank">arXiv:2010.03757</a> [<a href="http://arxiv.org/pdf/2010.03757" target="_blank">pdf</a>]

<h2>Energy-based Out-of-distribution Detection. (arXiv:2010.03759v1 [cs.LG])</h2>
<h3>Weitang Liu, Xiaoyun Wang, John D. Owens, Yixuan Li</h3>
<p>Determining whether inputs are out-of-distribution (OOD) is an essential
building block for safely deploying machine learning models in the open world.
However, previous methods relying on the softmax confidence score suffer from
overconfident posterior distributions for OOD data. We propose a unified
framework for OOD detection that uses an energy score. We show that energy
scores better distinguish in- and out-of-distribution samples than the
traditional approach using the softmax scores. Unlike softmax confidence
scores, energy scores are theoretically aligned with the probability density of
the inputs and are less susceptible to the overconfidence issue. Within this
framework, energy can be flexibly used as a scoring function for any
pre-trained neural classifier as well as a trainable cost function to shape the
energy surface explicitly for OOD detection. On a CIFAR-10 pre-trained
WideResNet, using the energy score reduces the average FPR (at TPR 95%) by
18.03% compared to the softmax confidence score. With energy-based training,
our method outperforms the state-of-the-art on common benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.03759" target="_blank">arXiv:2010.03759</a> [<a href="http://arxiv.org/pdf/2010.03759" target="_blank">pdf</a>]

<h2>Assessing Phrasal Representation and Composition in Transformers. (arXiv:2010.03763v1 [cs.CL])</h2>
<h3>Lang Yu, Allyson Ettinger</h3>
<p>Deep transformer models have pushed performance on NLP tasks to new limits,
suggesting sophisticated treatment of complex linguistic inputs, such as
phrases. However, we have limited understanding of how these models handle
representation of phrases, and whether this reflects sophisticated composition
of phrase meaning like that done by humans. In this paper, we present
systematic analysis of phrasal representations in state-of-the-art pre-trained
transformers. We use tests leveraging human judgments of phrase similarity and
meaning shift, and compare results before and after control of word overlap, to
tease apart lexical effects versus composition effects. We find that phrase
representation in these models relies heavily on word content, with little
evidence of nuanced composition. We also identify variations in phrase
representation quality across models, layers, and representation types, and
make corresponding recommendations for usage of representations from these
models.
</p>
<a href="http://arxiv.org/abs/2010.03763" target="_blank">arXiv:2010.03763</a> [<a href="http://arxiv.org/pdf/2010.03763" target="_blank">pdf</a>]

<h2>Improving Attention Mechanism with Query-Value Interaction. (arXiv:2010.03766v1 [cs.CL])</h2>
<h3>Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang</h3>
<p>Attention mechanism has played critical roles in various state-of-the-art NLP
models such as Transformer and BERT. It can be formulated as a ternary function
that maps the input queries, keys and values into an output by using a
summation of values weighted by the attention weights derived from the
interactions between queries and keys. Similar with query-key interactions,
there is also inherent relatedness between queries and values, and
incorporating query-value interactions has the potential to enhance the output
by learning customized values according to the characteristics of queries.
However, the query-value interactions are ignored by existing attention
methods, which may be not optimal. In this paper, we propose to improve the
existing attention mechanism by incorporating query-value interactions. We
propose a query-value interaction function which can learn query-aware
attention values, and combine them with the original values and attention
weights to form the final output. Extensive experiments on four datasets for
different tasks show that our approach can consistently improve the performance
of many attention-based models by incorporating query-value interactions.
</p>
<a href="http://arxiv.org/abs/2010.03766" target="_blank">arXiv:2010.03766</a> [<a href="http://arxiv.org/pdf/2010.03766" target="_blank">pdf</a>]

<h2>ALFWorld: Aligning Text and Embodied Environments for Interactive Learning. (arXiv:2010.03768v1 [cs.CL])</h2>
<h3>Mohit Shridhar, Xingdi Yuan, Marc-Alexandre C&#xf4;t&#xe9;, Yonatan Bisk, Adam Trischler, Matthew Hausknecht</h3>
<p>Given a simple request (e.g., Put a washed apple in the kitchen fridge),
humans can reason in purely abstract terms by imagining action sequences and
scoring their likelihood of success, prototypicality, and efficiency, all
without moving a muscle. Once we see the kitchen in question, we can update our
abstract plans to fit the scene. Embodied agents require the same abilities,
but existing work does not yet provide the infrastructure necessary for both
reasoning abstractly and executing concretely. We address this limitation by
introducing ALFWorld, a simulator that enables agents to learn abstract,
text-based policies in TextWorld (C\^ot\'e et al., 2018) and then execute goals
from the ALFRED benchmark (Shridhar et al., 2020) in a rich visual environment.
ALFWorld enables the creation of a new BUTLER agent whose abstract knowledge,
learned in TextWorld, corresponds directly to concrete, visually grounded
actions. In turn, as we demonstrate empirically, this fosters better agent
generalization than training only in the visually grounded environment.
BUTLER's simple, modular design factors the problem to allow researchers to
focus on models for improving every piece of the pipeline (language
understanding, planning, navigation, visual scene understanding, and so forth).
</p>
<a href="http://arxiv.org/abs/2010.03768" target="_blank">arXiv:2010.03768</a> [<a href="http://arxiv.org/pdf/2010.03768" target="_blank">pdf</a>]

<h2>DBLFace: Domain-Based Labels for NIR-VIS Heterogeneous Face Recognition. (arXiv:2010.03771v1 [cs.CV])</h2>
<h3>Ha Le, Ioannis A. Kakadiaris</h3>
<p>Deep learning-based domain-invariant feature learning methods are advancing
in near-infrared and visible (NIR-VIS) heterogeneous face recognition. However,
these methods are prone to overfitting due to the large intra-class variation
and the lack of NIR images for training. In this paper, we introduce
Domain-Based Label Face (DBLFace), a learning approach based on the assumption
that a subject is not represented by a single label but by a set of labels.
Each label represents images of a specific domain. In particular, a set of two
labels per subject, one for the NIR images and one for the VIS images, are used
for training a NIR-VIS face recognition model. The classification of images
into different domains reduces the intra-class variation and lessens the
negative impact of data imbalance in training. To train a network with sets of
labels, we introduce a domain-based angular margin loss and a maximum angular
loss to maintain the inter-class discrepancy and to enforce the close
relationship of labels in a set. Quantitative experiments confirm that DBLFace
significantly improves the rank-1 identification rate by 6.7% on the EDGE20
dataset and achieves state-of-the-art performance on the CASIA NIR-VIS 2.0
dataset.
</p>
<a href="http://arxiv.org/abs/2010.03771" target="_blank">arXiv:2010.03771</a> [<a href="http://arxiv.org/pdf/2010.03771" target="_blank">pdf</a>]

<h2>Improving Long-Tail Relation Extraction with Collaborating Relation-Augmented Attention. (arXiv:2010.03773v1 [cs.CL])</h2>
<h3>Yang Li, Tao Shen, Guodong Long, Jing Jiang, Tianyi Zhou, Chengqi Zhang</h3>
<p>Wrong labeling problem and long-tail relations are two main challenges caused
by distant supervision in relation extraction. Recent works alleviate the wrong
labeling by selective attention via multi-instance learning, but cannot well
handle long-tail relations even if hierarchies of the relations are introduced
to share knowledge. In this work, we propose a novel neural network,
Collaborating Relation-augmented Attention (CoRA), to handle both the wrong
labeling and long-tail relations. Particularly, we first propose
relation-augmented attention network as base model. It operates on sentence bag
with a sentence-to-relation attention to minimize the effect of wrong labeling.
Then, facilitated by the proposed base model, we introduce collaborating
relation features shared among relations in the hierarchies to promote the
relation-augmenting process and balance the training data for long-tail
relations. Besides the main training objective to predict the relation of a
sentence bag, an auxiliary objective is utilized to guide the
relation-augmenting process for a more accurate bag-level representation. In
the experiments on the popular benchmark dataset NYT, the proposed CoRA
improves the prior state-of-the-art performance by a large margin in terms of
Precision@N, AUC and Hits@K. Further analyses verify its superior capability in
handling long-tail relations in contrast to the competitors.
</p>
<a href="http://arxiv.org/abs/2010.03773" target="_blank">arXiv:2010.03773</a> [<a href="http://arxiv.org/pdf/2010.03773" target="_blank">pdf</a>]

<h2>A two-stage approach for beam hardening artifact reduction in low-dose dental CBCT. (arXiv:2010.03778v1 [cs.CE])</h2>
<h3>T. Bayaraa, C. M. Hyun, T. J. Jang, S. M. Lee, J. K. Seo</h3>
<p>This paper presents a two-stage method for beam hardening artifact correction
of dental cone beam computerized tomography (CBCT). The proposed artifact
reduction method is designed to improve the quality of maxillofacial imaging,
where soft tissue details are not required. Compared to standard CT, the
additional difficulty of dental CBCT comes from the problems caused by offset
detector, FOV truncation, and low signal-to-noise ratio due to low X-ray
irradiation. To address these problems, the proposed method primarily performs
a sinogram adjustment in the direction of enhancing data consistency,
considering the situation according to the FOV truncation and offset detector.
This sinogram correction algorithm significantly reduces beam hardening
artifacts caused by high-density materials such as teeth, bones, and metal
implants, while tending to amplify special types of noise. To suppress such
noise, a deep convolutional neural network is complementarily used, where CT
images adjusted by the sinogram correction are used as the input of the neural
network. Numerous experiments validate that the proposed method successfully
reduces beam hardening artifacts and, in particular, has the advantage of
improving the image quality of teeth, associated with maxillofacial CBCT
imaging.
</p>
<a href="http://arxiv.org/abs/2010.03778" target="_blank">arXiv:2010.03778</a> [<a href="http://arxiv.org/pdf/2010.03778" target="_blank">pdf</a>]

<h2>Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines. (arXiv:2010.03790v1 [cs.AI])</h2>
<h3>Keerthiram Murugesan, Mattia Atzeni, Pavan Kapanipathi, Pushkar Shukla, Sadhana Kumaravel, Gerald Tesauro, Kartik Talamadupula, Mrinmaya Sachan, Murray Campbell</h3>
<p>Text-based games have emerged as an important test-bed for Reinforcement
Learning (RL) research, requiring RL agents to combine grounded language
understanding with sequential decision making. In this paper, we examine the
problem of infusing RL agents with commonsense knowledge. Such knowledge would
allow agents to efficiently act in the world by pruning out implausible
actions, and to perform look-ahead planning to determine how current actions
might affect future world states. We design a new text-based gaming environment
called TextWorld Commonsense (TWC) for training and evaluating RL agents with a
specific kind of commonsense knowledge about objects, their attributes, and
affordances. We also introduce several baseline RL agents which track the
sequential context and dynamically retrieve the relevant commonsense knowledge
from ConceptNet. We show that agents which incorporate commonsense knowledge in
TWC perform better, while acting more efficiently. We conduct user-studies to
estimate human performance on TWC and show that there is ample room for future
improvement.
</p>
<a href="http://arxiv.org/abs/2010.03790" target="_blank">arXiv:2010.03790</a> [<a href="http://arxiv.org/pdf/2010.03790" target="_blank">pdf</a>]

<h2>Age and Gender Prediction From Face Images Using Attentional Convolutional Network. (arXiv:2010.03791v1 [cs.CV])</h2>
<h3>Amirali Abdolrashidi, Mehdi Minaei, Elham Azimi, Shervin Minaee</h3>
<p>Automatic prediction of age and gender from face images has drawn a lot of
attention recently, due it is wide applications in various facial analysis
problems. However, due to the large intra-class variation of face images (such
as variation in lighting, pose, scale, occlusion), the existing models are
still behind the desired accuracy level, which is necessary for the use of
these models in real-world applications. In this work, we propose a deep
learning framework, based on the ensemble of attentional and residual
convolutional networks, to predict gender and age group of facial images with
high accuracy rate. Using attention mechanism enables our model to focus on the
important and informative parts of the face, which can help it to make a more
accurate prediction. We train our model in a multi-task learning fashion, and
augment the feature embedding of the age classifier, with the predicted gender,
and show that doing so can further increase the accuracy of age prediction. Our
model is trained on a popular face age and gender dataset, and achieved
promising results. Through visualization of the attention maps of the train
model, we show that our model has learned to become sensitive to the right
regions of the face.
</p>
<a href="http://arxiv.org/abs/2010.03791" target="_blank">arXiv:2010.03791</a> [<a href="http://arxiv.org/pdf/2010.03791" target="_blank">pdf</a>]

<h2>Adaptive Doubly Robust Estimator. (arXiv:2010.03792v1 [cs.LG])</h2>
<h3>Masahiro Kato</h3>
<p>We propose a doubly robust (DR) estimator for off-policy evaluation (OPE)
from data obtained via multi-armed bandit (MAB) algorithms. The goal of OPE is
to evaluate a new policy using historical data. Because the MAB algorithms
sequentially updates the policy based on past observations, the generated
samples are not independent and identically distributed (i.i.d.). To conduct
OPE from dependent samples, we propose an OPE estimator with asymptotic
normality even under the dependency. In particular, we focus on a DR estimator,
which consists of an inverse probability weighting (IPW) component and an
estimator of the conditionally expected outcome. The proposed adaptive DR
estimator only requires the convergence rate conditions of the nuisance
estimators and the other mild regularity conditions; that is, we do not impose
a specific time-series structure and Donsker's condition. We investigate the
effectiveness by using benchmark datasets compared to a past proposed DR
estimator with double/debiased machine learning and an adaptive version of an
augmented IPW estimator.
</p>
<a href="http://arxiv.org/abs/2010.03792" target="_blank">arXiv:2010.03792</a> [<a href="http://arxiv.org/pdf/2010.03792" target="_blank">pdf</a>]

<h2>Information Theory Measures via Multidimensional Gaussianization. (arXiv:2010.03807v1 [stat.ML])</h2>
<h3>Valero Laparra, J. Emmanuel Johnson, Gustau Camps-Valls, Raul Santos-Rodr&#xed;guez, Jesus Malo</h3>
<p>Information theory is an outstanding framework to measure uncertainty,
dependence and relevance in data and systems. It has several desirable
properties for real world applications: it naturally deals with multivariate
data, it can handle heterogeneous data types, and the measures can be
interpreted in physical units. However, it has not been adopted by a wider
audience because obtaining information from multidimensional data is a
challenging problem due to the curse of dimensionality. Here we propose an
indirect way of computing information based on a multivariate Gaussianization
transform. Our proposal mitigates the difficulty of multivariate density
estimation by reducing it to a composition of tractable (marginal) operations
and simple linear transformations, which can be interpreted as a particular
deep neural network. We introduce specific Gaussianization-based methodologies
to estimate total correlation, entropy, mutual information and Kullback-Leibler
divergence. We compare them to recent estimators showing the accuracy on
synthetic data generated from different multivariate distributions. We made the
tools and datasets publicly available to provide a test-bed to analyze future
methodologies. Results show that our proposal is superior to previous
estimators particularly in high-dimensional scenarios; and that it leads to
interesting insights in neuroscience, geoscience, computer vision, and machine
learning.
</p>
<a href="http://arxiv.org/abs/2010.03807" target="_blank">arXiv:2010.03807</a> [<a href="http://arxiv.org/pdf/2010.03807" target="_blank">pdf</a>]

<h2>A novel control mode of bionic morphing tail based on deep reinforcement learning. (arXiv:2010.03814v1 [physics.flu-dyn])</h2>
<h3>Liming Zheng, Zhou Zhou, Pengbo Sun, Zhilin Zhang, Rui Wang</h3>
<p>In the field of fixed wing aircraft, many morphing technologies have been
applied to the wing, such as adaptive airfoil, variable span aircraft, variable
swept angle aircraft, etc., but few are aimed at the tail. The traditional
fixed wing tail includes horizontal and vertical tail. Inspired by the bird
tail, this paper will introduce a new bionic tail. The tail has a novel control
mode, which has multiple control variables. Compared with the traditional fixed
wing tail, it adds the area control and rotation control around the
longitudinal symmetry axis, so it can control the pitch and yaw of the aircraft
at the same time. When the area of the tail changes, the maneuverability and
stability of the aircraft can be changed, and the aerodynamic efficiency of the
aircraft can also be improved. The aircraft with morphing ability is often
difficult to establish accurate mathematical model, because the model has a
strong nonlinear, model-based control method is difficult to deal with the
strong nonlinear aircraft. In recent years, with the rapid development of
artificial intelligence technology, learning based control methods are also
brilliant, in which the deep reinforcement learning algorithm can be a good
solution to the control object which is difficult to establish model. In this
paper, the model-free control algorithm PPO is used to control the tail, and
the traditional PID is used to control the aileron and throttle. After training
in simulation, the tail shows excellent attitude control ability.
</p>
<a href="http://arxiv.org/abs/2010.03814" target="_blank">arXiv:2010.03814</a> [<a href="http://arxiv.org/pdf/2010.03814" target="_blank">pdf</a>]

<h2>A Comparative Study on Effects of Original and Pseudo Labels for Weakly Supervised Learning for Car Localization Problem. (arXiv:2010.03815v1 [cs.CV])</h2>
<h3>Cenk Bircanoglu</h3>
<p>In this study, the effects of different class labels created as a result of
multiple conceptual meanings on localization using Weakly Supervised Learning
presented on Car Dataset. In addition, the generated labels are included in the
comparison, and the solution turned into Unsupervised Learning. This paper
investigates multiple setups for car localization in the images with other
approaches rather than Supervised Learning. To predict localization labels,
Class Activation Mapping (CAM) is implemented and from the results, the
bounding boxes are extracted by using morphological edge detection. Besides the
original class labels, generated class labels also employed to train CAM on
which turn to a solution to Unsupervised Learning example. In the experiments,
we first analyze the effects of class labels in Weakly Supervised localization
on the Compcars dataset. We then show that the proposed Unsupervised approach
outperforms the Weakly Supervised method in this particular dataset by
approximately %6.
</p>
<a href="http://arxiv.org/abs/2010.03815" target="_blank">arXiv:2010.03815</a> [<a href="http://arxiv.org/pdf/2010.03815" target="_blank">pdf</a>]

<h2>Clustering Analysis of Interactive Learning Activities Based on Improved BIRCH Algorithm. (arXiv:2010.03821v1 [cs.LG])</h2>
<h3>Xiaona Xia</h3>
<p>Group tendency is a research branch of computer assisted learning. The
construction of good learning behavior is of great significance to learners'
learning process and learning effect, and is the key basis of data-driven
education decision-making. Clustering analysis is an effective method for the
study of group tendency. Therefore, it is necessary to obtain the online
learning behavior big data set of multi period and multi course, and describe
the learning behavior as multi-dimensional learning interaction activities.
First of all, on the basis of data initialization and standardization, we
locate the classification conditions of data, realize the differentiation and
integration of learning behavior, and form multiple subsets of data to be
clustered; secondly, according to the topological relevance and dependence
between learning interaction activities, we design an improved algorithm of
BIRCH clustering based on random walking strategy, which realizes the retrieval
evaluation and data of key learning interaction activities; Thirdly, through
the calculation and comparison of several performance indexes, the improved
algorithm has obvious advantages in learning interactive activity clustering,
and the clustering process and results are feasible and reliable. The
conclusion of this study can be used for reference and can be popularized. It
has practical significance for the research of education big data and the
practical application of learning analytics.
</p>
<a href="http://arxiv.org/abs/2010.03821" target="_blank">arXiv:2010.03821</a> [<a href="http://arxiv.org/pdf/2010.03821" target="_blank">pdf</a>]

<h2>Association rules over time. (arXiv:2010.03834v1 [cs.NE])</h2>
<h3>Iztok Fister Jr., Iztok Fister</h3>
<p>Decisions made nowadays by Artificial Intelligence powered systems are
usually hard for users to understand. One of the more important issues faced by
developers is exposed as how to create more explainable Machine Learning
models. In line with this, more explainable techniques need to be developed,
where visual explanation also plays a more important role. This technique could
also be applied successfully for explaining the results of Association Rule
Mining.This Chapter focuses on two issues: (1) How to discover the relevant
association rules, and (2) How to express relations between more attributes
visually. For the solution of the first issue, the proposed method uses
Differential Evolution, while Sankey diagrams are adopted to solve the second
one. This method was applied to a transaction database containing data
generated by an amateur cyclist in past seasons, using a mobile device worn
during the realization of training sessions that is divided into four time
periods. The results of visualization showed that a trend in improving
performance of an athlete can be indicated by changing the attributes appearing
in the selected association rules in different time periods.
</p>
<a href="http://arxiv.org/abs/2010.03834" target="_blank">arXiv:2010.03834</a> [<a href="http://arxiv.org/pdf/2010.03834" target="_blank">pdf</a>]

<h2>Strategies for Integrating Controls Flows in Software-Defined In-Vehicle Networks and Their Impact on Network Security. (arXiv:2010.03839v1 [cs.NI])</h2>
<h3>Timo H&#xe4;ckel, Anja Schmidt, Philipp Meyer, Franz Korf, Thomas C. Schmidt</h3>
<p>Current In-Vehicle Networks (IVNs) connect Electronic Control Units (ECUs)
via domain busses. A gateway forwards messages between these domains.
Automotive Ethernet emerges as a flat, high-speed backbone technology for IVNs
that carries the various control flows within Ethernet frames. Recently,
Software-Defined-Networking (SDN) has been identified as a useful building
block of the vehicular domain, as it allows the differentiation of packets
based on all header fields and thus can isolate unrelated control flows. In
this work, we systematically explore the different strategies for integrating
automotive control flows in switched Ether-networks and analyze their security
impact for a software-defined IVN. We discuss how control flow identifiers can
be embedded on different layers resulting in a range of solutions from fully
exposed embedding to deep encapsulation. We evaluate these strategies in a
realistic IVN based on the communication matrix of a production grade vehicle,
which we map into a modern Ethernet topology. We find that visibility of
automotive control flows within packet headers is essential for the network
infrastructure to enable isolation and access control. With an exposed
embedding, the SDN backbone can establish and survey trust zones within the IVN
and largely reduce the attack surface of connected cars. An exposed embedding
strategy also minimizes communication expenses.
</p>
<a href="http://arxiv.org/abs/2010.03839" target="_blank">arXiv:2010.03839</a> [<a href="http://arxiv.org/pdf/2010.03839" target="_blank">pdf</a>]

<h2>Adaptive Shielding under Uncertainty. (arXiv:2010.03842v1 [cs.LO])</h2>
<h3>Stefan Pranger, Bettina K&#xf6;nighofer, Martin Tappler, Martin Deixelberger, Nils Jansen, Roderick Bloem</h3>
<p>This paper targets control problems that exhibit specific safety and
performance requirements. In particular, the aim is to ensure that an agent,
operating under uncertainty, will at runtime strictly adhere to such
requirements. Previous works create so-called shields that correct an existing
controller for the agent if it is about to take unbearable safety risks.
However, so far, shields do not consider that an environment may not be fully
known in advance and may evolve for complex control and learning tasks. We
propose a new method for the efficient computation of a shield that is adaptive
to a changing environment. In particular, we base our method on problems that
are sufficiently captured by potentially infinite Markov decision processes
(MDP) and quantitative specifications such as mean payoff objectives. The
shield is independent of the controller, which may, for instance, take the form
of a high-performing reinforcement learning agent. At runtime, our method
builds an internal abstract representation of the MDP and constantly adapts
this abstraction and the shield based on observations from the environment. We
showcase the applicability of our method via an urban traffic control problem.
</p>
<a href="http://arxiv.org/abs/2010.03842" target="_blank">arXiv:2010.03842</a> [<a href="http://arxiv.org/pdf/2010.03842" target="_blank">pdf</a>]

<h2>Improve Adversarial Robustness via Weight Penalization on Classification Layer. (arXiv:2010.03844v1 [cs.LG])</h2>
<h3>Cong Xu, Dan Li, Min Yang</h3>
<p>It is well-known that deep neural networks are vulnerable to adversarial
attacks. Recent studies show that well-designed classification parts can lead
to better robustness. However, there is still much space for improvement along
this line. In this paper, we first prove that, from a geometric point of view,
the robustness of a neural network is equivalent to some angular margin
condition of the classifier weights. We then explain why ReLU type function is
not a good choice for activation under this framework. These findings reveal
the limitations of the existing approaches and lead us to develop a novel
light-weight-penalized defensive method, which is simple and has a good
scalability. Empirical results on multiple benchmark datasets demonstrate that
our method can effectively improve the robustness of the network without
requiring too much additional computation, while maintaining a high
classification precision for clean data.
</p>
<a href="http://arxiv.org/abs/2010.03844" target="_blank">arXiv:2010.03844</a> [<a href="http://arxiv.org/pdf/2010.03844" target="_blank">pdf</a>]

<h2>Guided Curriculum Learning for Walking Over Complex Terrain. (arXiv:2010.03848v1 [cs.RO])</h2>
<h3>Brendan Tidd, Nicolas Hudson, Akansel Cosgun</h3>
<p>Reliable bipedal walking over complex terrain is a challenging problem, using
a curriculum can help learning. Curriculum learning is the idea of starting
with an achievable version of a task and increasing the difficulty as a success
criteria is met. We propose a 3-stage curriculum to train Deep Reinforcement
Learning policies for bipedal walking over various challenging terrains. In the
first stage, the agent starts on an easy terrain and the terrain difficulty is
gradually increased, while forces derived from a target policy are applied to
the robot joints and the base. In the second stage, the guiding forces are
gradually reduced to zero. Finally, in the third stage, random perturbations
with increasing magnitude are applied to the robot base, so the robustness of
the policies are improved. In simulation experiments, we show that our approach
is effective in learning walking policies, separate from each other, for five
terrain types: flat, hurdles, gaps, stairs, and steps. Moreover, we demonstrate
that in the absence of human demonstrations, a simple hand designed walking
trajectory is a sufficient prior to learn to traverse complex terrain types. In
ablation studies, we show that taking out any one of the three stages of the
curriculum degrades the learning performance.
</p>
<a href="http://arxiv.org/abs/2010.03848" target="_blank">arXiv:2010.03848</a> [<a href="http://arxiv.org/pdf/2010.03848" target="_blank">pdf</a>]

<h2>Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders. (arXiv:2010.03851v1 [cs.CL])</h2>
<h3>Jue Wang, Wei Lu</h3>
<p>Named entity recognition and relation extraction are two important
fundamental problems. Joint learning algorithms have been proposed to solve
both tasks simultaneously, and many of them cast the joint task as a
table-filling problem. However, they typically focused on learning a single
encoder (usually learning representation in the form of a table) to capture
information required for both tasks within the same space. We argue that it can
be beneficial to design two distinct encoders to capture such two different
types of information in the learning process. In this work, we propose the
novel {\em table-sequence encoders} where two different encoders -- a table
encoder and a sequence encoder are designed to help each other in the
representation learning process. Our experiments confirm the advantages of
having {\em two} encoders over {\em one} encoder. On several standard datasets,
our model shows significant improvements over existing approaches.
</p>
<a href="http://arxiv.org/abs/2010.03851" target="_blank">arXiv:2010.03851</a> [<a href="http://arxiv.org/pdf/2010.03851" target="_blank">pdf</a>]

<h2>Transcending Transcend: Revisiting Malware Classification with Conformal Evaluation. (arXiv:2010.03856v1 [cs.CR])</h2>
<h3>Federico Barbero, Feargus Pendlebury, Fabio Pierazzi, Lorenzo Cavallaro</h3>
<p>Machine learning for malware classification shows encouraging results, but
real deployments suffer from performance degradation as malware authors adapt
their techniques to evade detection. This evolution of malware results in a
phenomenon known as concept drift, as new examples become less and less like
the original training examples. One promising method to cope with concept drift
is classification with rejection in which examples that are likely to be
misclassified are instead quarantined until they can be expertly analyzed.

We revisit Transcend, a recently proposed framework for performing rejection
based on conformal prediction theory. In particular, we provide a formal
treatment of Transcend, enabling us to refine conformal evaluation theory---its
underlying statistical engine---and gain a better understanding of the
theoretical reasons for its effectiveness. In the process, we develop two
additional conformal evaluators that match or surpass the performance of the
original while significantly decreasing the computational overhead. We evaluate
our extension on a large dataset that removes sources of experimental bias
present in the original evaluation.

Finally, to aid practitioners, we determine the optimal operational settings
for a Transcend deployment and show how it can be applied to many popular
learning algorithms.

These insights support both old and new empirical findings, making Transcend
a sound and practical solution, while shedding light on how rejection
strategies may be further applied to the related problem of evasive adversarial
inputs.
</p>
<a href="http://arxiv.org/abs/2010.03856" target="_blank">arXiv:2010.03856</a> [<a href="http://arxiv.org/pdf/2010.03856" target="_blank">pdf</a>]

<h2>Clinically Verified Hybrid Deep Learning System for Retinal Ganglion Cells Aware Grading of Glaucomatous Progression. (arXiv:2010.03872v1 [cs.CV])</h2>
<h3>Hina Raja, Taimur Hassan, Muhammad Usman Akram, Naoufel Werghi</h3>
<p>Objective: Glaucoma is the second leading cause of blindness worldwide.
Glaucomatous progression can be easily monitored by analyzing the degeneration
of retinal ganglion cells (RGCs). Many researchers have screened glaucoma by
measuring cup-to-disc ratios from fundus and optical coherence tomography
scans. However, this paper presents a novel strategy that pays attention to the
RGC atrophy for screening glaucomatous pathologies and grading their severity.
Methods: The proposed framework encompasses a hybrid convolutional network that
extracts the retinal nerve fiber layer, ganglion cell with the inner plexiform
layer and ganglion cell complex regions, allowing thus a quantitative screening
of glaucomatous subjects. Furthermore, the severity of glaucoma in screened
cases is objectively graded by analyzing the thickness of these regions.
Results: The proposed framework is rigorously tested on publicly available
Armed Forces Institute of Ophthalmology (AFIO) dataset, where it achieved the
F1 score of 0.9577 for diagnosing glaucoma, a mean dice coefficient score of
0.8697 for extracting the RGC regions and an accuracy of 0.9117 for grading
glaucomatous progression. Furthermore, the performance of the proposed
framework is clinically verified with the markings of four expert
ophthalmologists, achieving a statistically significant Pearson correlation
coefficient of 0.9236. Conclusion: An automated assessment of RGC degeneration
yields better glaucomatous screening and grading as compared to the
state-of-the-art solutions. Significance: An RGC-aware system not only screens
glaucoma but can also grade its severity and here we present an end-to-end
solution that is thoroughly evaluated on a standardized dataset and is
clinically validated for analyzing glaucomatous pathologies.
</p>
<a href="http://arxiv.org/abs/2010.03872" target="_blank">arXiv:2010.03872</a> [<a href="http://arxiv.org/pdf/2010.03872" target="_blank">pdf</a>]

<h2>IRX-1D: A Simple Deep Learning Architecture for Remote Sensing Classifications. (arXiv:2010.03902v1 [cs.CV])</h2>
<h3>Mahesh Pal, Akshay, B. Charan Teja</h3>
<p>We proposes a simple deep learning architecture combining elements of
Inception, ResNet and Xception networks. Four new datasets were used for
classification with both small and large training samples. Results in terms of
classification accuracy suggests improved performance by proposed architecture
in comparison to Bayesian optimised 2D-CNN with small training samples.
Comparison of results using small training sample with Indiana Pines
hyperspectral dataset suggests comparable or better performance by proposed
architecture than nine reported works using different deep learning
architectures. In spite of achieving high classification accuracy with limited
training samples, comparison of classified image suggests different land cover
classes are assigned to same area when compared with the classified image
provided by the model trained using large training samples with all datasets.
</p>
<a href="http://arxiv.org/abs/2010.03902" target="_blank">arXiv:2010.03902</a> [<a href="http://arxiv.org/pdf/2010.03902" target="_blank">pdf</a>]

<h2>Classification of Speech with and without Face Mask using Acoustic Features. (arXiv:2010.03907v1 [eess.AS])</h2>
<h3>Rohan Kumar Das, Haizhou Li</h3>
<p>The understanding and interpretation of speech can be affected by various
external factors. The use of face masks is one such factors that can create
obstruction to speech while communicating. This may lead to degradation of
speech processing and affect humans perceptually. Knowing whether a speaker
wears a mask may be useful for modeling speech for different applications. With
this motivation, finding whether a speaker wears face mask from a given speech
is included as a task in Computational Paralinguistics Evaluation (ComParE)
2020. We study novel acoustic features based on linear filterbanks,
instantaneous phase and long-term information that can capture the artifacts
for classification of speech with and without face mask. These acoustic
features are used along with the state-of-the-art baselines of ComParE
functionals, bag-of-audio-words, DeepSpectrum and auDeep features for ComParE
2020. The studies reveal the effectiveness of acoustic features, and their
score level fusion with the ComParE 2020 baselines leads to an unweighted
average recall of 73.50% on the test set.
</p>
<a href="http://arxiv.org/abs/2010.03907" target="_blank">arXiv:2010.03907</a> [<a href="http://arxiv.org/pdf/2010.03907" target="_blank">pdf</a>]

<h2>Assessing the Fairness of Classifiers with Collider Bias. (arXiv:2010.03933v1 [cs.LG])</h2>
<h3>Zhenlong Xu (1), Jixue Liu (1), Debo Cheng (1), Jiuyong Li (1), Lin Liu (1), Ke Wang (2) ((1) STEM, Univsersity of South Austrlia, (2) Simon Frasier University)</h3>
<p>The increasing maturity of machine learning technologies and their
applications to decisions relate to everyday decision making have brought
concerns about the fairness of the decisions. However, current fairness
assessment systems often suffer from collider bias, which leads to a spurious
association between the protected attribute and the outcomes. To achieve
fairness evaluation on prediction models at the individual level, in this
paper, we develop the causality-based theorems to support the use of direct
causal effect estimation for fairness assessment on a given a classifier
without access to original training data. Based on the theorems, an unbiased
situation test method is presented to assess individual fairness of predictions
by a classifier, through the elimination of the impact of collider bias of the
classifier on the fairness assessment. Extensive experiments have been
performed on synthetic and real-world data to evaluate the performance of the
proposed method. The experimental results show that the proposed method reduces
bias significantly.
</p>
<a href="http://arxiv.org/abs/2010.03933" target="_blank">arXiv:2010.03933</a> [<a href="http://arxiv.org/pdf/2010.03933" target="_blank">pdf</a>]

<h2>Prioritized Level Replay. (arXiv:2010.03934v1 [cs.LG])</h2>
<h3>Minqi Jiang, Ed Grefenstette, Tim Rockt&#xe4;schel</h3>
<p>Simulated environments with procedurally generated content have become
popular benchmarks for testing systematic generalization of reinforcement
learning agents. Every level in such an environment is algorithmically created,
thereby exhibiting a unique configuration of underlying factors of variation,
such as layout, positions of entities, asset appearances, or even the rules
governing environment transitions. Fixed sets of training levels can be
determined to aid comparison and reproducibility, and test levels can be held
out to evaluate the generalization and robustness of agents. While prior work
samples training levels in a direct way (e.g.~uniformly) for the agent to learn
from, we investigate the hypothesis that different levels provide different
learning progress for an agent at specific times during training. We introduce
Prioritized Level Replay, a general framework for estimating the future
learning potential of a level given the current state of the agent's policy. We
find that temporal-difference (TD) errors, while previously used to selectively
sample past transitions, also prove effective for scoring a level's future
learning potential in generating entire episodes that an agent would experience
when replaying it. We report significantly improved sample-efficiency and
generalization on the majority of Procgen Benchmark environments as well as two
challenging MiniGrid environments. Lastly, we present a qualitative analysis
showing that Prioritized Level Replay induces an implicit curriculum, taking
the agent gradually from easier to harder levels.
</p>
<a href="http://arxiv.org/abs/2010.03934" target="_blank">arXiv:2010.03934</a> [<a href="http://arxiv.org/pdf/2010.03934" target="_blank">pdf</a>]

<h2>Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning. (arXiv:2010.03950v1 [cs.LG])</h2>
<h3>Rodrigo Toro Icarte, Toryn Q. Klassen, Richard Valenzano, Sheila A. McIlraith</h3>
<p>Reinforcement learning (RL) methods usually treat reward functions as black
boxes. As such, these methods must extensively interact with the environment in
order to discover rewards and optimal policies. In most RL applications,
however, users have to program the reward function and, hence, there is the
opportunity to treat reward functions as white boxes instead -- to show the
reward function's code to the RL agent so it can exploit its internal
structures to learn optimal policies faster. In this paper, we show how to
accomplish this idea in two steps. First, we propose reward machines (RMs), a
type of finite state machine that supports the specification of reward
functions while exposing reward function structure. We then describe different
methodologies to exploit such structures, including automated reward shaping,
task decomposition, and counterfactual reasoning for data augmentation.
Experiments on tabular and continuous domains show the benefits of exploiting
reward structure across different tasks and RL agents.
</p>
<a href="http://arxiv.org/abs/2010.03950" target="_blank">arXiv:2010.03950</a> [<a href="http://arxiv.org/pdf/2010.03950" target="_blank">pdf</a>]

<h2>MolDesigner: Interactive Design of Efficacious Drugs with Deep Learning. (arXiv:2010.03951v1 [q-bio.QM])</h2>
<h3>Kexin Huang, Tianfan Fu, Dawood Khan, Ali Abid, Ali Abdalla, Abubakar Abid, Lucas M. Glass, Marinka Zitnik, Cao Xiao, Jimeng Sun</h3>
<p>The efficacy of a drug depends on its binding affinity to the therapeutic
target and pharmacokinetics. Deep learning (DL) has demonstrated remarkable
progress in predicting drug efficacy. We develop MolDesigner, a
human-in-the-loop web user-interface (UI), to assist drug developers leverage
DL predictions to design more effective drugs. A developer can draw a drug
molecule in the interface. In the backend, more than 17 state-of-the-art DL
models generate predictions on important indices that are crucial for a drug's
efficacy. Based on these predictions, drug developers can edit the drug
molecule and reiterate until satisfaction. MolDesigner can make predictions in
real-time with a latency of less than a second.
</p>
<a href="http://arxiv.org/abs/2010.03951" target="_blank">arXiv:2010.03951</a> [<a href="http://arxiv.org/pdf/2010.03951" target="_blank">pdf</a>]

<h2>A Survey on Deep Neural Network Compression: Challenges, Overview, and Solutions. (arXiv:2010.03954v1 [cs.LG])</h2>
<h3>Rahul Mishra, Hari Prabhat Gupta, Tanima Dutta</h3>
<p>Deep Neural Network (DNN) has gained unprecedented performance due to its
automated feature extraction capability. This high order performance leads to
significant incorporation of DNN models in different Internet of Things (IoT)
applications in the past decade. However, the colossal requirement of
computation, energy, and storage of DNN models make their deployment
prohibitive on resource constraint IoT devices. Therefore, several compression
techniques were proposed in recent years for reducing the storage and
computation requirements of the DNN model. These techniques on DNN compression
have utilized a different perspective for compressing DNN with minimal accuracy
compromise. It encourages us to make a comprehensive overview of the DNN
compression techniques. In this paper, we present a comprehensive review of
existing literature on compressing DNN model that reduces both storage and
computation requirements. We divide the existing approaches into five broad
categories, i.e., network pruning, sparse representation, bits precision,
knowledge distillation, and miscellaneous, based upon the mechanism
incorporated for compressing the DNN model. The paper also discussed the
challenges associated with each category of DNN compression techniques.
Finally, we provide a quick summary of existing work under each category with
the future direction in DNN compression.
</p>
<a href="http://arxiv.org/abs/2010.03954" target="_blank">arXiv:2010.03954</a> [<a href="http://arxiv.org/pdf/2010.03954" target="_blank">pdf</a>]

<h2>Action Guidance: Getting the Best of Sparse Rewards and Shaped Rewards for Real-time Strategy Games. (arXiv:2010.03956v1 [cs.LG])</h2>
<h3>Shengyi Huang, Santiago Onta&#xf1;&#xf3;n</h3>
<p>Training agents using Reinforcement Learning in games with sparse rewards is
a challenging problem, since large amounts of exploration are required to
retrieve even the first reward. To tackle this problem, a common approach is to
use reward shaping to help exploration. However, an important drawback of
reward shaping is that agents sometimes learn to optimize the shaped reward
instead of the true objective. In this paper, we present a novel technique that
we call action guidance that successfully trains agents to eventually optimize
the true objective in games with sparse rewards while maintaining most of the
sample efficiency that comes with reward shaping. We evaluate our approach in a
simplified real-time strategy (RTS) game simulator called $\mu$RTS.
</p>
<a href="http://arxiv.org/abs/2010.03956" target="_blank">arXiv:2010.03956</a> [<a href="http://arxiv.org/pdf/2010.03956" target="_blank">pdf</a>]

<h2>Transformers for Modeling Physical Systems. (arXiv:2010.03957v1 [cs.LG])</h2>
<h3>Nicholas Geneva, Nicholas Zabaras</h3>
<p>Transformers are widely used in neural language processing due to their
ability to model longer-term dependencies in text. Although these models
achieve state-of-the-art performance for many language related tasks, their
applicability outside of the neural language processing field has been minimal.
In this work, we propose the use of transformer models for the prediction of
dynamical systems representative of physical phenomena. The use of Koopman
based embeddings provide a unique and powerful method for projecting any
dynamical system into a vector representation which can then be predicted by a
transformer model. The proposed model is able to accurately predict various
dynamical systems and outperform classical methods that are commonly used in
the scientific machine learning literature.
</p>
<a href="http://arxiv.org/abs/2010.03957" target="_blank">arXiv:2010.03957</a> [<a href="http://arxiv.org/pdf/2010.03957" target="_blank">pdf</a>]

<h2>Test-Cost Sensitive Methods for Identifying Nearby Points. (arXiv:2010.03962v1 [cs.LG])</h2>
<h3>Seung Gyu Hyun, Christopher Leung</h3>
<p>Real-world applications that involve missing values are often constrained by
the cost to obtain data. Test-cost sensitive, or costly feature, methods
additionally consider the cost of acquiring features. Such methods have been
extensively studied in the problem of classification. In this paper, we study a
related problem of test-cost sensitive methods to identify nearby points from a
large set, given a new point with some unknown feature values. We present two
models, one based on a tree and another based on Deep Reinforcement Learning.
In our simulations, we show that the models outperform random agents on a set
of five real-world data sets.
</p>
<a href="http://arxiv.org/abs/2010.03962" target="_blank">arXiv:2010.03962</a> [<a href="http://arxiv.org/pdf/2010.03962" target="_blank">pdf</a>]

<h2>High Definition image classification in Geoscience using Machine Learning. (arXiv:2010.03965v1 [eess.IV])</h2>
<h3>Yajun An, Zachary Golden, Tarka Wilcox, Renzhi Cao</h3>
<p>High Definition (HD) digital photos taken with drones are widely used in the
study of Geoscience. However, blurry images are often taken in collected data,
and it takes a lot of time and effort to distinguish clear images from blurry
ones. In this work, we apply Machine learning techniques, such as Support
Vector Machine (SVM) and Neural Network (NN) to classify HD images in
Geoscience as clear and blurry, and therefore automate data cleaning in
Geoscience. We compare the results of classification based on features
abstracted from several mathematical models. Some of the implementation of our
machine learning tool is freely available at:
https://github.com/zachgolden/geoai.
</p>
<a href="http://arxiv.org/abs/2010.03965" target="_blank">arXiv:2010.03965</a> [<a href="http://arxiv.org/pdf/2010.03965" target="_blank">pdf</a>]

<h2>A Human Ear Reconstruction Autoencoder. (arXiv:2010.03972v1 [cs.CV])</h2>
<h3>Hao Sun, Nick Pears, Hang Dai</h3>
<p>The ear, as an important part of the human head, has received much less
attention compared to the human face in the area of computer vision. Inspired
by previous work on monocular 3D face reconstruction using an autoencoder
structure to achieve self-supervised learning, we aim to utilise such a
framework to tackle the 3D ear reconstruction task, where more subtle and
difficult curves and features are present on the 2D ear input images. Our Human
Ear Reconstruction Autoencoder (HERA) system predicts 3D ear poses and shape
parameters for 3D ear meshes, without any supervision to these parameters. To
make our approach cover the variance for in-the-wild images, even grayscale
images, we propose an in-the-wild ear colour model. The constructed end-to-end
self-supervised model is then evaluated both with 2D landmark localisation
performance and the appearance of the reconstructed 3D ears.
</p>
<a href="http://arxiv.org/abs/2010.03972" target="_blank">arXiv:2010.03972</a> [<a href="http://arxiv.org/pdf/2010.03972" target="_blank">pdf</a>]

<h2>Synthesising clinically realistic Chest X-rays using Generative Adversarial Networks. (arXiv:2010.03975v1 [eess.IV])</h2>
<h3>Bradley Segal, David M. Rubin, Grace Rubin, Adam Pantanowitz</h3>
<p>Chest x-rays are one of the most commonly performed medical investigations
globally and are vital to identifying a number of conditions. These images are
however protected under patient confidentiality and as such require the removal
of identifying information as well as ethical clearance to be released.
Generative adversarial networks (GANs) are a branch of deep learning which are
capable of producing synthetic samples of a desired distribution. Image
generation is one such application with recent advances enabling the production
of high-resolution images, a feature vital to the utility of x-rays given the
scale of various pathologies. We apply the Progressive Growing GAN (PGGAN) to
the task of chest x-ray generation with the goal of being able to produce
images without any ethical concerns that may be used for medical education or
in other machine learning work. We evaluate the properties of the generated
x-rays with a practicing radiologist and demonstrate that high-quality,
realistic images can be produced with global features consistent with
pathologies seen in the NIH dataset. Improvements in the reproduction of
small-scale details remains for future work. We train a classification model on
the NIH images and evaluate the distribution of disease labels across the
generated samples. We find that the model is capable of reproducing all the
abnormalities in a similar proportion to the source image distribution as
labelled by the classifier. We additionally demonstrate that the latent space
can be optimised to produce images of a particular class despite unconditional
training, with the model producing related features and complications for the
class of interest. We also validate the application of the Fr'echet Inception
Distance (FID) to x-ray images and determine that the PGGAN reproduces x-ray
images with an FID of 8.02, which is similar to other high resolution tasks.
</p>
<a href="http://arxiv.org/abs/2010.03975" target="_blank">arXiv:2010.03975</a> [<a href="http://arxiv.org/pdf/2010.03975" target="_blank">pdf</a>]

<h2>A Brief Review of Domain Adaptation. (arXiv:2010.03978v1 [cs.LG])</h2>
<h3>Abolfazl Farahani, Sahar Voghoei, Khaled Rasheed, Hamid R. Arabnia</h3>
<p>Classical machine learning assumes that the training and test sets come from
the same distributions. Therefore, a model learned from the labeled training
data is expected to perform well on the test data. However, This assumption may
not always hold in real-world applications where the training and the test data
fall from different distributions, due to many factors, e.g., collecting the
training and test sets from different sources, or having an out-dated training
set due to the change of data over time. In this case, there would be a
discrepancy across domain distributions, and naively applying the trained model
on the new dataset may cause degradation in the performance. Domain adaptation
is a sub-field within machine learning that aims to cope with these types of
problems by aligning the disparity between domains such that the trained model
can be generalized into the domain of interest. This paper focuses on
unsupervised domain adaptation, where the labels are only available in the
source domain. It addresses the categorization of domain adaptation from
different viewpoints. Besides, It presents some successful shallow and deep
domain adaptation approaches that aim to deal with domain adaptation problems.
</p>
<a href="http://arxiv.org/abs/2010.03978" target="_blank">arXiv:2010.03978</a> [<a href="http://arxiv.org/pdf/2010.03978" target="_blank">pdf</a>]

<h2>Metrics and methods for a systematic comparison of fairness-aware machine learning algorithms. (arXiv:2010.03986v1 [cs.LG])</h2>
<h3>Gareth P. Jones, James M. Hickey, Pietro G. Di Stefano, Charanpal Dhanjal, Laura C. Stoddart, Vlasios Vasileiou</h3>
<p>Understanding and removing bias from the decisions made by machine learning
models is essential to avoid discrimination against unprivileged groups.
Despite recent progress in algorithmic fairness, there is still no clear answer
as to which bias-mitigation approaches are most effective. Evaluation
strategies are typically use-case specific, rely on data with unclear bias, and
employ a fixed policy to convert model outputs to decision outcomes. To address
these problems, we performed a systematic comparison of a number of popular
fairness algorithms applicable to supervised classification. Our study is the
most comprehensive of its kind. It utilizes three real and four synthetic
datasets, and two different ways of converting model outputs to decisions. It
considers fairness, predictive-performance, calibration quality, and speed of
28 different modelling pipelines, corresponding to both fairness-unaware and
fairness-aware algorithms. We found that fairness-unaware algorithms typically
fail to produce adequately fair models and that the simplest algorithms are not
necessarily the fairest ones. We also found that fairness-aware algorithms can
induce fairness without material drops in predictive power. Finally, we found
that dataset idiosyncracies (e.g., degree of intrinsic unfairness, nature of
correlations) do affect the performance of fairness-aware approaches. Our
results allow the practitioner to narrow down the approach(es) they would like
to adopt without having to know in advance their fairness requirements.
</p>
<a href="http://arxiv.org/abs/2010.03986" target="_blank">arXiv:2010.03986</a> [<a href="http://arxiv.org/pdf/2010.03986" target="_blank">pdf</a>]

<h2>Free annotated data for deep learning in microscopy? A hitchhiker's guide. (arXiv:2010.03988v1 [eess.IV])</h2>
<h3>Adrian Shajkofci, Michael Liebling</h3>
<p>In microscopy, the time burden and cost of acquiring and annotating large
datasets that many deep learning models take as a prerequisite, often appears
to make these methods impractical. Can this requirement for annotated data be
relaxed? Is it possible to borrow the knowledge gathered from datasets in other
application fields and leverage it for microscopy? Here, we aim to provide an
overview of methods that have recently emerged to successfully train
learning-based methods in bio-microscopy.
</p>
<a href="http://arxiv.org/abs/2010.03988" target="_blank">arXiv:2010.03988</a> [<a href="http://arxiv.org/pdf/2010.03988" target="_blank">pdf</a>]

<h2>UESegNet: Context Aware Unconstrained ROI Segmentation Networks for Ear Biometric. (arXiv:2010.03990v1 [cs.CV])</h2>
<h3>Aman Kamboj, Rajneesh Rani, Aditya Nigam, Ranjeet Ranjan Jha</h3>
<p>Biometric-based personal authentication systems have seen a strong demand
mainly due to the increasing concern in various privacy and security
applications. Although the use of each biometric trait is problem dependent,
the human ear has been found to have enough discriminating characteristics to
allow its use as a strong biometric measure. To locate an ear in a 2D side face
image is a challenging task, numerous existing approaches have achieved
significant performance, but the majority of studies are based on the
constrained environment. However, ear biometrics possess a great level of
difficulties in the unconstrained environment, where pose, scale, occlusion,
illuminations, background clutter etc. varies to a great extent. To address the
problem of ear localization in the wild, we have proposed two high-performance
region of interest (ROI) segmentation models UESegNet-1 and UESegNet-2, which
are fundamentally based on deep convolutional neural networks and primarily
uses contextual information to localize ear in the unconstrained environment.
Additionally, we have applied state-of-the-art deep learning models viz; FRCNN
(Faster Region Proposal Network) and SSD (Single Shot MultiBox Detecor) for ear
localization task. To test the model's generalization, they are evaluated on
six different benchmark datasets viz; IITD, IITK, USTB-DB3, UND-E, UND-J2 and
UBEAR, all of which contain challenging images. The performance of the models
is compared on the basis of object detection performance measure parameters
such as IOU (Intersection Over Union), Accuracy, Precision, Recall, and
F1-Score. It has been observed that the proposed models UESegNet-1 and
UESegNet-2 outperformed the FRCNN and SSD at higher values of IOUs i.e. an
accuracy of 100\% is achieved at IOU 0.5 on majority of the databases.
</p>
<a href="http://arxiv.org/abs/2010.03990" target="_blank">arXiv:2010.03990</a> [<a href="http://arxiv.org/pdf/2010.03990" target="_blank">pdf</a>]

<h2>Unconstrained Text Detection in Manga. (arXiv:2010.03997v1 [cs.CV])</h2>
<h3>Juli&#xe1;n Del Gobbo, Rosana Matuk Herrera</h3>
<p>The detection and recognition of unconstrained text is an open problem in
research. Text in comic books has unusual styles that raise many challenges for
text detection. This work aims to identify text characters at a pixel level in
a comic genre with highly sophisticated text styles: Japanese manga. To
overcome the lack of a manga dataset with individual character level
annotations, we create our own. Most of the literature in text detection use
bounding box metrics, which are unsuitable for pixel-level evaluation. Thus, we
implemented special metrics to evaluate performance. Using these resources, we
designed and evaluated a deep network model, outperforming current methods for
text detection in manga in most metrics.
</p>
<a href="http://arxiv.org/abs/2010.03997" target="_blank">arXiv:2010.03997</a> [<a href="http://arxiv.org/pdf/2010.03997" target="_blank">pdf</a>]

<h2>Watch, read and lookup: learning to spot signs from multiple supervisors. (arXiv:2010.04002v1 [cs.CV])</h2>
<h3>Liliane Momeni, G&#xfc;l Varol, Samuel Albanie, Triantafyllos Afouras, Andrew Zisserman</h3>
<p>The focus of this work is sign spotting - given a video of an isolated sign,
our task is to identify whether and where it has been signed in a continuous,
co-articulated sign language video. To achieve this sign spotting task, we
train a model using multiple types of available supervision by: (1) watching
existing sparsely labelled footage; (2) reading associated subtitles (readily
available translations of the signed content) which provide additional
weak-supervision; (3) looking up words (for which no co-articulated labelled
examples are available) in visual sign language dictionaries to enable novel
sign spotting. These three tasks are integrated into a unified learning
framework using the principles of Noise Contrastive Estimation and Multiple
Instance Learning. We validate the effectiveness of our approach on low-shot
sign spotting benchmarks. In addition, we contribute a machine-readable British
Sign Language (BSL) dictionary dataset of isolated signs, BSLDict, to
facilitate study of this task. The dataset, models and code are available at
our project page.
</p>
<a href="http://arxiv.org/abs/2010.04002" target="_blank">arXiv:2010.04002</a> [<a href="http://arxiv.org/pdf/2010.04002" target="_blank">pdf</a>]

<h2>A Theoretical Analysis of Catastrophic Forgetting through the NTK Overlap Matrix. (arXiv:2010.04003v1 [cs.LG])</h2>
<h3>Thang Doan, Mehdi Bennani, Bogdan Mazoure, Guillaume Rabusseau, Pierre Alquier</h3>
<p>Continual learning (CL) is a setting in which an agent has to learn from an
incoming stream of data during its entire lifetime. Although major advances
have been made in the field, one recurring problem which remains unsolved is
that of Catastrophic Forgetting (CF). While the issue has been extensively
studied empirically, little attention has been paid from a theoretical angle.
In this paper, we show that the impact of CF increases as two tasks
increasingly align. We introduce a measure of task similarity called the NTK
overlap matrix which is at the core of CF. We analyze common projected gradient
algorithms and demonstrate how they mitigate forgetting. Then, we propose a
variant of Orthogonal Gradient Descent (OGD) which leverages structure of the
data through Principal Component Analysis (PCA). Experiments support our
theoretical findings and show how our method reduces CF on classical CL
datasets.
</p>
<a href="http://arxiv.org/abs/2010.04003" target="_blank">arXiv:2010.04003</a> [<a href="http://arxiv.org/pdf/2010.04003" target="_blank">pdf</a>]

<h2>Tractography filtering using autoencoders. (arXiv:2010.04007v1 [eess.IV])</h2>
<h3>Jon Haitz Legarreta, Laurent Petit, Fran&#xe7;ois Rheault, Guillaume Theaud, Carl Lemaire, Maxime Descoteaux, Pierre-Marc Jodoin</h3>
<p>Current brain white matter fiber tracking techniques show a number of
problems, including: generating large proportions of streamlines that do not
accurately describe the underlying anatomy; extracting streamlines that are not
supported by the underlying diffusion signal; and under-representing some fiber
populations, among others. In this paper, we describe a novel unsupervised
learning method to filter streamlines from diffusion MRI tractography, and
hence, to obtain more reliable tractograms.

We show that a convolutional neural network autoencoder provides a
straightforward and elegant way to learn a robust representation of brain
streamlines, which can be used to filter undesired samples with a nearest
neighbor algorithm. Our method, dubbed FINTA (Filtering in Tractography using
Autoencoders) comes with several key advantages: training does not need labeled
data, as it uses raw tractograms, it is fast and easily reproducible, it does
not rely on the input diffusion MRI data, and thus, does not suffer from domain
adaptation issues. We demonstrate the ability of FINTA to discriminate between
"plausible" and "implausible" streamlines as well as to recover individual
streamline group instances from a raw tractogram, from both synthetic and real
human brain diffusion MRI tractography data, including partial tractograms.
Results reveal that FINTA has a superior filtering performance compared to
state-of-the-art methods.

Together, this work brings forward a new deep learning framework in
tractography based on autoencoders, and shows how it can be applied for
filtering purposes. It sets the foundations for opening up new prospects
towards more accurate and robust tractometry and connectivity diffusion MRI
analyses, which may ultimately lead to improve the imaging of the white matter
anatomy.
</p>
<a href="http://arxiv.org/abs/2010.04007" target="_blank">arXiv:2010.04007</a> [<a href="http://arxiv.org/pdf/2010.04007" target="_blank">pdf</a>]

<h2>Single-Image Camera Response Function Using Prediction Consistency and Gradual Refinement. (arXiv:2010.04009v1 [cs.CV])</h2>
<h3>Aashish Sharma, Robby T. Tan, Loong-Fah Cheong</h3>
<p>A few methods have been proposed to estimate the CRF from a single image,
however most of them tend to fail in handling general real images. For
instance, EdgeCRF based on patches extracted from colour edges works
effectively only when the presence of noise is insignificant, which is not the
case for many real images; and, CRFNet, a recent method based on fully
supervised deep learning works only for the CRFs that are in the training data,
and hence fail to deal with other possible CRFs beyond the training data. To
address these problems, we introduce a non-deep-learning method using
prediction consistency and gradual refinement. First, we rely more on the
patches of the input image that provide more consistent predictions. If the
predictions from a patch are more consistent, it means that the patch is likely
to be less affected by noise or any inferior colour combinations, and hence, it
can be more reliable for CRF estimation. Second, we employ a gradual refinement
scheme in which we start from a simple CRF model to generate a result which is
more robust to noise but less accurate, and then we gradually increase the
model's complexity to improve the estimation. This is because a simple model,
while being less accurate, overfits less to noise than a complex model does.
Our experiments confirm that our method outperforms the existing single-image
methods for both daytime and nighttime real images.
</p>
<a href="http://arxiv.org/abs/2010.04009" target="_blank">arXiv:2010.04009</a> [<a href="http://arxiv.org/pdf/2010.04009" target="_blank">pdf</a>]

<h2>Invertible Manifold Learning for Dimension Reduction. (arXiv:2010.04012v1 [cs.LG])</h2>
<h3>Siyuan Li, Haitao Lin, Zelin Zang, Lirong Wu, Jun Xia, Stan Z. Li</h3>
<p>It is widely believed that a nonlinear dimension reduction (NLDR) process
drops information inevitably in most practical scenarios, and even with the
manifold assumption, most existing methods are unable to preserve structure of
data after DR due to the loss of information, especially in high-dimensional
cases. In the context of manifold learning, we think a good low-dimensional
representation should preserve topological and geometric properties of data
manifold. To achieve this, the inveribility of a NLDR transformation is
required such that the learned representation is reconstructible via its
inverse transformation. In this paper, we propose a novel method, called
invertible manifold learning (inv-ML), to tackle this problem. A locally
isometric smoothness (LIS) constraint for preserving local geometry is applied
to a two-stage inv-ML algorithm. Firstly, a homeomorphic sparse coordinate
transformation is learned to find the low-dimensional representation without
loss of topological information. Secondly, a linear compression is performed on
the learned sparse coding, with the trade-off between the target dimension and
the incurred information loss. Experiments are conducted on seven datasets,
whose results demonstrate that the proposed inv-ML not only achieves better
invertible NLDR in comparison with typical existing methods but also reveals
the characteristics of the learned manifolds through linear interpolation in
latent space. Moreover, we find that the reliability of tangent space
approximated by its local neighborhood on real-world datasets is a key to the
success of manifold based DR algorithms. The code will be made available soon.
</p>
<a href="http://arxiv.org/abs/2010.04012" target="_blank">arXiv:2010.04012</a> [<a href="http://arxiv.org/pdf/2010.04012" target="_blank">pdf</a>]

<h2>DiffTune: Optimizing CPU Simulator Parameters with Learned Differentiable Surrogates. (arXiv:2010.04017v1 [cs.LG])</h2>
<h3>Alex Renda, Yishen Chen, Charith Mendis, Michael Carbin</h3>
<p>CPU simulators are useful tools for modeling CPU execution behavior. However,
they suffer from inaccuracies due to the cost and complexity of setting their
fine-grained parameters, such as the latencies of individual instructions. This
complexity arises from the expertise required to design benchmarks and
measurement frameworks that can precisely measure the values of parameters at
such fine granularity. In some cases, these parameters do not necessarily have
a physical realization and are therefore fundamentally approximate, or even
unmeasurable.

In this paper we present DiffTune, a system for learning the parameters of
x86 basic block CPU simulators from coarse-grained end-to-end measurements.
Given a simulator, DiffTune learns its parameters by first replacing the
original simulator with a differentiable surrogate, another function that
approximates the original function; by making the surrogate differentiable,
DiffTune is then able to apply gradient-based optimization techniques even when
the original function is non-differentiable, such as is the case with CPU
simulators. With this differentiable surrogate, DiffTune then applies
gradient-based optimization to produce values of the simulator's parameters
that minimize the simulator's error on a dataset of ground truth end-to-end
performance measurements. Finally, the learned parameters are plugged back into
the original simulator.

DiffTune is able to automatically learn the entire set of
microarchitecture-specific parameters within the Intel x86 simulation model of
llvm-mca, a basic block CPU simulator based on LLVM's instruction scheduling
model. DiffTune's learned parameters lead llvm-mca to an average error that not
only matches but lowers that of its original, expert-provided parameter values.
</p>
<a href="http://arxiv.org/abs/2010.04017" target="_blank">arXiv:2010.04017</a> [<a href="http://arxiv.org/pdf/2010.04017" target="_blank">pdf</a>]

<h2>RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs. (arXiv:2010.04029v1 [cs.AI])</h2>
<h3>Meng Qu, Junkun Chen, Louis-Pascal Xhonneux, Yoshua Bengio, Jian Tang</h3>
<p>This paper studies learning logic rules for reasoning on knowledge graphs.
Logic rules provide interpretable explanations when used for prediction as well
as being able to generalize to other tasks, and hence are critical to learn.
Existing methods either suffer from the problem of searching in a large search
space (e.g., neural logic programming) or ineffective optimization due to
sparse rewards (e.g., techniques based on reinforcement learning). To address
these limitations, this paper proposes a probabilistic model called RNNLogic.
RNNLogic treats logic rules as a latent variable, and simultaneously trains a
rule generator as well as a reasoning predictor with logic rules. We develop an
EM-based algorithm for optimization. In each iteration, the reasoning predictor
is first updated to explore some generated logic rules for reasoning. Then in
the E-step, we select a set of high-quality rules from all generated rules with
both the rule generator and reasoning predictor via posterior inference; and in
the M-step, the rule generator is updated with the rules selected in the
E-step. Experiments on four datasets prove the effectiveness of RNNLogic.
</p>
<a href="http://arxiv.org/abs/2010.04029" target="_blank">arXiv:2010.04029</a> [<a href="http://arxiv.org/pdf/2010.04029" target="_blank">pdf</a>]

<h2>Semi-Supervised Learning of Multi-Object 3D Scene Representations. (arXiv:2010.04030v1 [cs.CV])</h2>
<h3>Cathrin Elich, Martin R. Oswald, Marc Pollefeys, J&#xf6;rg St&#xfc;ckler</h3>
<p>Representing scenes at the granularity of objects is a prerequisite for scene
understanding and decision making. We propose a novel approach for learning
multi-object 3D scene representations from images. A recurrent encoder
regresses a latent representation of 3D shapes, poses and texture of each
object from an input RGB image. The 3D shapes are represented continuously in
function-space as signed distance functions (SDF) which we efficiently
pre-train from example shapes in a supervised way. By differentiable rendering
we then train our model to decompose scenes self-supervised from RGB-D images.
Our approach learns to decompose images into the constituent objects of the
scene and to infer their shape, pose and texture from a single view. We
evaluate the accuracy of our model in inferring the 3D scene layout and
demonstrate its generative capabilities.
</p>
<a href="http://arxiv.org/abs/2010.04030" target="_blank">arXiv:2010.04030</a> [<a href="http://arxiv.org/pdf/2010.04030" target="_blank">pdf</a>]

<h2>Prediction intervals for Deep Neural Networks. (arXiv:2010.04044v1 [stat.ML])</h2>
<h3>Tullio Mancini, Hector Calvo-Pardo, Jose Olmo</h3>
<p>The aim of this paper is to propose a suitable method for constructing
prediction intervals for the output of neural network models. To do this, we
adapt the extremely randomized trees method originally developed for random
forests to construct ensembles of neural networks. The extra-randomness
introduced in the ensemble reduces the variance of the predictions and yields
gains in out-of-sample accuracy. An extensive Monte Carlo simulation exercise
shows the good performance of this novel method for constructing prediction
intervals in terms of coverage probability and mean square prediction error.
This approach is superior to state-of-the-art methods extant in the literature
such as the widely used MC dropout and bootstrap procedures. The out-of-sample
accuracy of the novel algorithm is further evaluated using experimental
settings already adopted in the literature.
</p>
<a href="http://arxiv.org/abs/2010.04044" target="_blank">arXiv:2010.04044</a> [<a href="http://arxiv.org/pdf/2010.04044" target="_blank">pdf</a>]

<h2>Hierarchical Classification of Pulmonary Lesions: A Large-Scale Radio-Pathomics Study. (arXiv:2010.04049v1 [eess.IV])</h2>
<h3>Jiancheng Yang, Mingze Gao, Kaiming Kuang, Bingbing Ni, Yunlang She, Dong Xie, Chang Chen</h3>
<p>Diagnosis of pulmonary lesions from computed tomography (CT) is important but
challenging for clinical decision making in lung cancer related diseases. Deep
learning has achieved great success in computer aided diagnosis (CADx) area for
lung cancer, whereas it suffers from label ambiguity due to the difficulty in
the radiological diagnosis. Considering that invasive pathological analysis
serves as the clinical golden standard of lung cancer diagnosis, in this study,
we solve the label ambiguity issue via a large-scale radio-pathomics dataset
containing 5,134 radiological CT images with pathologically confirmed labels,
including cancers (e.g., invasive/non-invasive adenocarcinoma, squamous
carcinoma) and non-cancer diseases (e.g., tuberculosis, hamartoma). This
retrospective dataset, named Pulmonary-RadPath, enables development and
validation of accurate deep learning systems to predict invasive pathological
labels with a non-invasive procedure, i.e., radiological CT scans. A
three-level hierarchical classification system for pulmonary lesions is
developed, which covers most diseases in cancer-related diagnosis. We explore
several techniques for hierarchical classification on this dataset, and propose
a Leaky Dense Hierarchy approach with proven effectiveness in experiments. Our
study significantly outperforms prior arts in terms of data scales (6x larger),
disease comprehensiveness and hierarchies. The promising results suggest the
potentials to facilitate precision medicine.
</p>
<a href="http://arxiv.org/abs/2010.04049" target="_blank">arXiv:2010.04049</a> [<a href="http://arxiv.org/pdf/2010.04049" target="_blank">pdf</a>]

<h2>A survey of algorithmic recourse: definitions, formulations, solutions, and prospects. (arXiv:2010.04050v1 [cs.LG])</h2>
<h3>Amir-Hossein Karimi, Gilles Barthe, Bernhard Sch&#xf6;lkopf, Isabel Valera</h3>
<p>Machine learning is increasingly used to inform decision-making in sensitive
situations where decisions have consequential effects on individuals' lives. In
these settings, in addition to requiring models to be accurate and robust,
socially relevant values such as fairness, privacy, accountability, and
explainability play an important role for the adoption and impact of said
technologies. In this work, we focus on algorithmic recourse, which is
concerned with providing explanations and recommendations to individuals who
are unfavourably treated by automated decision-making systems. We first perform
an extensive literature review, and align the efforts of many authors by
presenting unified definitions, formulations, and solutions to recourse. Then,
we provide an overview of the prospective research directions towards which the
community may engage, challenging existing assumptions and making explicit
connections to other ethical challenges such as security, privacy, and
fairness.
</p>
<a href="http://arxiv.org/abs/2010.04050" target="_blank">arXiv:2010.04050</a> [<a href="http://arxiv.org/pdf/2010.04050" target="_blank">pdf</a>]

<h2>Ensemble Machine Learning Methods for Modeling COVID19 Deaths. (arXiv:2010.04052v1 [cs.LG])</h2>
<h3>R. Bathwal, P. Chitta, K. Tirumala, V. Varadarajan</h3>
<p>Using a hybrid of machine learning and epidemiological approaches, we propose
a novel data-driven approach in predicting US COVID-19 deaths at a county
level. The model gives a more complete description of the daily death
distribution, outputting quantile-estimates instead of mean deaths, where the
model's objective is to minimize the pinball loss on deaths reported by the New
York Times coronavirus county dataset. The resulting quantile estimates
accurately forecast deaths at an individual-county level for a variable-length
forecast period, and the approach generalizes well across different forecast
period lengths. We won the Caltech-run modeling competition out of 50+ teams,
and our aggregate is competitive with the best COVID-19 modeling systems (on
root mean squared error).
</p>
<a href="http://arxiv.org/abs/2010.04052" target="_blank">arXiv:2010.04052</a> [<a href="http://arxiv.org/pdf/2010.04052" target="_blank">pdf</a>]

<h2>Fairness in Machine Learning: A Survey. (arXiv:2010.04053v1 [cs.LG])</h2>
<h3>Simon Caton, Christian Haas</h3>
<p>As Machine Learning technologies become increasingly used in contexts that
affect citizens, companies as well as researchers need to be confident that
their application of these methods will not have unexpected social
implications, such as bias towards gender, ethnicity, and/or people with
disabilities. There is significant literature on approaches to mitigate bias
and promote fairness, yet the area is complex and hard to penetrate for
newcomers to the domain. This article seeks to provide an overview of the
different schools of thought and approaches to mitigating (social) biases and
increase fairness in the Machine Learning literature. It organises approaches
into the widely accepted framework of pre-processing, in-processing, and
post-processing methods, subcategorizing into a further 11 method areas.
Although much of the literature emphasizes binary classification, a discussion
of fairness in regression, recommender systems, unsupervised learning, and
natural language processing is also provided along with a selection of
currently available open source libraries. The article concludes by summarising
open challenges articulated as four dilemmas for fairness research.
</p>
<a href="http://arxiv.org/abs/2010.04053" target="_blank">arXiv:2010.04053</a> [<a href="http://arxiv.org/pdf/2010.04053" target="_blank">pdf</a>]

<h2>MIA-Prognosis: A Deep Learning Framework to Predict Therapy Response. (arXiv:2010.04062v1 [cs.LG])</h2>
<h3>Jiancheng Yang, Jiajun Chen, Kaiming Kuang, Tiancheng Lin, Junjun He, Bingbing Ni</h3>
<p>Predicting clinical outcome is remarkably important but challenging. Research
efforts have been paid on seeking significant biomarkers associated with the
therapy response or/and patient survival. However, these biomarkers are
generally costly and invasive, and possibly dissatifactory for novel therapy.
On the other hand, multi-modal, heterogeneous, unaligned temporal data is
continuously generated in clinical practice. This paper aims at a unified deep
learning approach to predict patient prognosis and therapy response, with
easily accessible data, e.g., radiographics, laboratory and clinical
information. Prior arts focus on modeling single data modality, or ignore the
temporal changes. Importantly, the clinical time series is asynchronous in
practice, i.e., recorded with irregular intervals. In this study, we formalize
the prognosis modeling as a multi-modal asynchronous time series classification
task, and propose a MIA-Prognosis framework with Measurement, Intervention and
Assessment (MIA) information to predict therapy response, where a Simple
Temporal Attention (SimTA) module is developed to process the asynchronous time
series. Experiments on synthetic dataset validate the superiory of SimTA over
standard RNN-based approaches. Furthermore, we experiment the proposed method
on an in-house, retrospective dataset of real-world non-small cell lung cancer
patients under anti-PD-1 immunotherapy. The proposed method achieves promising
performance on predicting the immunotherapy response. Notably, our predictive
model could further stratify low-risk and high-risk patients in terms of
long-term survival.
</p>
<a href="http://arxiv.org/abs/2010.04062" target="_blank">arXiv:2010.04062</a> [<a href="http://arxiv.org/pdf/2010.04062" target="_blank">pdf</a>]

<h2>Are Adaptive Face Recognition Systems still Necessary? Experiments on the APE Dataset. (arXiv:2010.04072v1 [cs.CV])</h2>
<h3>Giulia Orr&#xf9;, Marco Micheletto, Julian Fierrez, Gian Luca Marcialis</h3>
<p>In the last five years, deep learning methods, in particular CNN, have
attracted considerable attention in the field of face-based recognition,
achieving impressive results. Despite this progress, it is not yet clear
precisely to what extent deep features are able to follow all the intra-class
variations that the face can present over time. In this paper we investigate
the performance the performance improvement of face recognition systems by
adopting self updating strategies of the face templates. For that purpose, we
evaluate the performance of a well-known deep-learning face representation,
namely, FaceNet, on a dataset that we generated explicitly conceived to embed
intra-class variations of users on a large time span of captures: the
APhotoEveryday (APE) dataset. Moreover, we compare these deep features with
handcrafted features extracted using the BSIF algorithm. In both cases, we
evaluate various template update strategies, in order to detect the most useful
for such kind of features. Experimental results show the effectiveness of
"optimized" self-update methods with respect to systems without update or
random selection of templates.
</p>
<a href="http://arxiv.org/abs/2010.04072" target="_blank">arXiv:2010.04072</a> [<a href="http://arxiv.org/pdf/2010.04072" target="_blank">pdf</a>]

<h2>A Mixed-Precision RISC-V Processor for Extreme-Edge DNN Inference. (arXiv:2010.04073v1 [cs.AR])</h2>
<h3>Gianmarco Ottavi, Angelo Garofalo, Giuseppe Tagliavini, Francesco Conti, Luca Benini, Davide Rossi</h3>
<p>Low bit-width Quantized Neural Networks (QNNs) enable deployment of complex
machine learning models on constrained devices such as microcontrollers (MCUs)
by reducing their memory footprint. Fine-grained asymmetric quantization (i.e.,
different bit-widths assigned to weights and activations on a tensor-by-tensor
basis) is a particularly interesting scheme to maximize accuracy under a tight
memory constraint. However, the lack of sub-byte instruction set architecture
(ISA) support in SoA microprocessors makes it hard to fully exploit this
extreme quantization paradigm in embedded MCUs. Support for sub-byte and
asymmetric QNNs would require many precision formats and an exorbitant amount
of opcode space. In this work, we attack this problem with status-based SIMD
instructions: rather than encoding precision explicitly, each operand's
precision is set dynamically in a core status register. We propose a novel
RISC-V ISA core MPIC (Mixed Precision Inference Core) based on the open-source
RI5CY core. Our approach enables full support for mixed-precision QNN inference
with different combinations of operands at 16-, 8-, 4- and 2-bit precision,
without adding any extra opcode or increasing the complexity of the decode
stage. Our results show that MPIC improves both performance and energy
efficiency by a factor of 1.1-4.9x when compared to software-based
mixed-precision on RI5CY; with respect to commercially available Cortex-M4 and
M7 microcontrollers, it delivers 3.6-11.7x better performance and 41-155x
higher efficiency.
</p>
<a href="http://arxiv.org/abs/2010.04073" target="_blank">arXiv:2010.04073</a> [<a href="http://arxiv.org/pdf/2010.04073" target="_blank">pdf</a>]

<h2>3D Object Detection and Pose Estimation of Unseen Objects in Color Images with Local Surface Embeddings. (arXiv:2010.04075v1 [cs.CV])</h2>
<h3>Giorgia Pitteri, Aur&#xe9;lie Bugeau, Slobodan Ilic, Vincent Lepetit</h3>
<p>We present an approach for detecting and estimating the 3D poses of objects
in images that requires only an untextured CAD model and no training phase for
new objects. Our approach combines Deep Learning and 3D geometry: It relies on
an embedding of local 3D geometry to match the CAD models to the input images.
For points at the surface of objects, this embedding can be computed directly
from the CAD model; for image locations, we learn to predict it from the image
itself. This establishes correspondences between 3D points on the CAD model and
2D locations of the input images. However, many of these correspondences are
ambiguous as many points may have similar local geometries. We show that we can
use Mask-RCNN in a class-agnostic way to detect the new objects without
retraining and thus drastically limit the number of possible correspondences.
We can then robustly estimate a 3D pose from these discriminative
correspondences using a RANSAC- like algorithm. We demonstrate the performance
of this approach on the T-LESS dataset, by using a small number of objects to
learn the embedding and testing it on the other objects. Our experiments show
that our method is on par or better than previous methods.
</p>
<a href="http://arxiv.org/abs/2010.04075" target="_blank">arXiv:2010.04075</a> [<a href="http://arxiv.org/pdf/2010.04075" target="_blank">pdf</a>]

<h2>Classifying Songs with EEG. (arXiv:2010.04087v1 [eess.SP])</h2>
<h3>Prashant Lawhatre, Bharatesh R Shiraguppi, Esha Sharma, Krishna Prasad Miyapuram, Derek Lomas</h3>
<p>This research study aims to use machine learning methods to characterize the
EEG response to music. Specifically, we investigate how resonance in the EEG
response correlates with individual aesthetic enjoyment. Inspired by the notion
of musical processing as resonance, we hypothesize that the intensity of an
aesthetic experience is based on the degree to which a participants EEG
entrains to the perceptual input. To test this and other hypotheses, we have
built an EEG dataset from 20 subjects listening to 12 two minute-long songs in
random order. After preprocessing and feature construction, we used this
dataset to train and test multiple machine learning models.
</p>
<a href="http://arxiv.org/abs/2010.04087" target="_blank">arXiv:2010.04087</a> [<a href="http://arxiv.org/pdf/2010.04087" target="_blank">pdf</a>]

<h2>Reward-Biased Maximum Likelihood Estimation for Linear Stochastic Bandits. (arXiv:2010.04091v1 [cs.LG])</h2>
<h3>Yu-Heng Hung, Ping-Chun Hsieh, Xi Liu, P. R. Kumar</h3>
<p>Modifying the reward-biased maximum likelihood method originally proposed in
the adaptive control literature, we propose novel learning algorithms to handle
the explore-exploit trade-off in linear bandits problems as well as generalized
linear bandits problems. We develop novel index policies that we prove achieve
order-optimality, and show that they achieve empirical performance competitive
with the state-of-the-art benchmark methods in extensive experiments. The new
policies achieve this with low computation time per pull for linear bandits,
and thereby resulting in both favorable regret as well as computational
efficiency.
</p>
<a href="http://arxiv.org/abs/2010.04091" target="_blank">arXiv:2010.04091</a> [<a href="http://arxiv.org/pdf/2010.04091" target="_blank">pdf</a>]

<h2>Improved Techniques for Model Inversion Attack. (arXiv:2010.04092v1 [cs.LG])</h2>
<h3>Si Chen, Ruoxi Jia, Guo-Jun Qi</h3>
<p>Model inversion (MI) attacks in the whitebox setting are aimed at
reconstructing training data from model parameters. Such attacks have triggered
increasing concerns about privacy, especially given a growing number of online
model repositories. However, existing MI attacks against deep neural networks
(DNNs) have large room for performance improvement. A natural question is
whether the underperformance is because the target model does not memorize much
about its training data or it is simply an artifact of imperfect attack
algorithm design? This paper shows that it is the latter. We present a variety
of new techniques that can significantly boost the performance of MI attacks
against DNNs. Recent advances to attack DNNs are largely attributed to the idea
of training a general generative adversarial network (GAN) with potential
public data and using it to regularize the search space for reconstructed
images. We propose to customize the training of a GAN to the inversion task so
as to better distill knowledge useful for performing attacks from public data.
Moreover, unlike previous work that directly searches for a single data point
to represent a target class, we propose to model private data distribution in
order to better reconstruct representative data points. Our experiments show
that the combination of these techniques can lead to state-of-the-art attack
performance on a variety of datasets and models, even when the public data has
a large distributional shift from the private data.
</p>
<a href="http://arxiv.org/abs/2010.04092" target="_blank">arXiv:2010.04092</a> [<a href="http://arxiv.org/pdf/2010.04092" target="_blank">pdf</a>]

<h2>BERTering RAMS: What and How Much does BERT Already Know About Event Arguments? -- A Study on the RAMS Dataset. (arXiv:2010.04098v1 [cs.CL])</h2>
<h3>Varun Gangal, Eduard Hovy</h3>
<p>Using the attention map based probing framework from (Clark et al., 2019), we
observe that BERT's attention heads have modest but well above-chance ability
to spot event arguments sans any training or domain finetuning, varying from a
low of 17.77% for Place to a high of 51.61% for Artifact. Next, we find that
linear combinations of these heads, estimated with approx 11% of available
total supervision, can push performance well-higher for some roles - highest
two being Victim (68.29% Accuracy) and Artifact (58.82% Accuracy). Furthermore,
we investigate how well our methods do for cross-sentence event arguments. We
propose a procedure to isolate "best heads" for cross-sentence argument
detection separately of those for intra-sentence arguments. The heads thus
estimated have superior cross-sentence performance compared to their jointly
estimated equivalents. Lastly, we seek to isolate to what extent our numbers
stem from lexical frequency based associations between gold arguments and
roles. We propose NONCE, a scheme to create adversarial test examples by
replacing gold arguments with randomly generated "nonce" words. We find that
learnt linear combinations are robust to NONCE, though individual best heads
can be much more sensitive.
</p>
<a href="http://arxiv.org/abs/2010.04098" target="_blank">arXiv:2010.04098</a> [<a href="http://arxiv.org/pdf/2010.04098" target="_blank">pdf</a>]

<h2>Learning the Pareto Front with Hypernetworks. (arXiv:2010.04104v1 [cs.LG])</h2>
<h3>Aviv Navon, Aviv Shamsian, Gal Chechik, Ethan Fetaya</h3>
<p>Multi-objective optimization problems are prevalent in machine learning.
These problems have a set of optimal solutions, called the Pareto front, where
each point on the front represents a different trade-off between possibly
conflicting objectives. Recent optimization algorithms can target a specific
desired ray in loss space, but still face two grave limitations: (i) A separate
model has to be trained for each point on the front; and (ii) The exact
trade-off must be known prior to the optimization process. Here, we tackle the
problem of learning the entire Pareto front, with the capability of selecting a
desired operating point on the front after training. We call this new setup
Pareto-Front Learning (PFL).

We describe an approach to PFL implemented using HyperNetworks, which we term
Pareto HyperNetworks (PHNs). PHN learns the entire Pareto front simultaneously
using a single hypernetwork, which receives as input a desired preference
vector and returns a Pareto-optimal model whose loss vector is in the desired
ray. The unified model is runtime efficient compared to training multiple
models, and generalizes to new operating points not used during training. We
evaluate our method on a wide set of problems, from multi-task regression and
classification to fairness. PHNs learns the entire Pareto front in roughly the
same time as learning a single point on the front, and also reaches a better
solution set. PFL opens the door to new applications where models are selected
based on preferences that are only available at run time.
</p>
<a href="http://arxiv.org/abs/2010.04104" target="_blank">arXiv:2010.04104</a> [<a href="http://arxiv.org/pdf/2010.04104" target="_blank">pdf</a>]

<h2>Set Prediction without Imposing Structure as Conditional Density Estimation. (arXiv:2010.04109v1 [cs.LG])</h2>
<h3>David W. Zhang, Gertjan J. Burghouts, Cees G.M. Snoek</h3>
<p>Set prediction is about learning to predict a collection of unordered
variables with unknown interrelations. Training such models with set losses
imposes the structure of a metric space over sets. We focus on stochastic and
underdefined cases, where an incorrectly chosen loss function leads to
implausible predictions. Example tasks include conditional point-cloud
reconstruction and predicting future states of molecules. In this paper, we
propose an alternative to training via set losses by viewing learning as
conditional density estimation. Our learning framework fits deep energy-based
models and approximates the intractable likelihood with gradient-guided
sampling. Furthermore, we propose a stochastically augmented prediction
algorithm that enables multiple predictions, reflecting the possible variations
in the target set. We empirically demonstrate on a variety of datasets the
capability to learn multi-modal densities and produce multiple plausible
predictions. Our approach is competitive with previous set prediction models on
standard benchmarks. More importantly, it extends the family of addressable
tasks beyond those that have unambiguous predictions.
</p>
<a href="http://arxiv.org/abs/2010.04109" target="_blank">arXiv:2010.04109</a> [<a href="http://arxiv.org/pdf/2010.04109" target="_blank">pdf</a>]

<h2>Information-Driven Adaptive Sensing Based on Deep Reinforcement Learning. (arXiv:2010.04112v1 [cs.LG])</h2>
<h3>Abdulmajid Murad, Frank Alexander Kraemer, Kerstin Bach, Gavin Taylor</h3>
<p>In order to make better use of deep reinforcement learning in the creation of
sensing policies for resource-constrained IoT devices, we present and study a
novel reward function based on the Fisher information value. This reward
function enables IoT sensor devices to learn to spend available energy on
measurements at otherwise unpredictable moments, while conserving energy at
times when measurements would provide little new information. This is a highly
general approach, which allows for a wide range of use cases without
significant human design effort or hyper-parameter tuning. We illustrate the
approach in a scenario of workplace noise monitoring, where results show that
the learned behavior outperforms a uniform sampling strategy and comes close to
a near-optimal oracle solution.
</p>
<a href="http://arxiv.org/abs/2010.04112" target="_blank">arXiv:2010.04112</a> [<a href="http://arxiv.org/pdf/2010.04112" target="_blank">pdf</a>]

<h2>Interlocking Backpropagation: Improving depthwise model-parallelism. (arXiv:2010.04116v1 [cs.LG])</h2>
<h3>Aidan N. Gomez, Oscar Key, Stephen Gou, Nick Frosst, Jeff Dean, Yarin Gal</h3>
<p>The number of parameters in state of the art neural networks has drastically
increased in recent years. This surge of interest in large scale neural
networks has motivated the development of new distributed training strategies
enabling such models. One such strategy is model-parallel distributed training.
Unfortunately, model-parallelism suffers from poor resource utilisation, which
leads to wasted resources. In this work, we improve upon recent developments in
an idealised model-parallel optimisation setting: local learning. Motivated by
poor resource utilisation, we introduce a class of intermediary strategies
between local and global learning referred to as interlocking backpropagation.
These strategies preserve many of the compute-efficiency advantages of local
optimisation, while recovering much of the task performance achieved by global
optimisation. We assess our strategies on both image classification ResNets and
Transformer language models, finding that our strategy consistently
out-performs local learning in terms of task performance, and out-performs
global learning in training efficiency.
</p>
<a href="http://arxiv.org/abs/2010.04116" target="_blank">arXiv:2010.04116</a> [<a href="http://arxiv.org/pdf/2010.04116" target="_blank">pdf</a>]

<h2>Extending the Hint Factory for the assistance dilemma: A novel, data-driven HelpNeed Predictor for proactive problem-solving help. (arXiv:2010.04124v1 [cs.AI])</h2>
<h3>Mehak Maniktala, Christa Cody, Amy Isvik, Nicholas Lytle, Min Chi, Tiffany Barnes</h3>
<p>Determining when and whether to provide personalized support is a well-known
challenge called the assistance dilemma. A core problem in solving the
assistance dilemma is the need to discover when students are unproductive so
that the tutor can intervene. Such a task is particularly challenging for
open-ended domains, even those that are well-structured with defined principles
and goals. In this paper, we present a set of data-driven methods to classify,
predict, and prevent unproductive problem-solving steps in the well-structured
open-ended domain of logic. This approach leverages and extends the Hint
Factory, a set of methods that leverages prior student solution attempts to
build data-driven intelligent tutors. We present a HelpNeed classification,
that uses prior student data to determine when students are likely to be
unproductive and need help learning optimal problem-solving strategies. We
present a controlled study to determine the impact of an Adaptive pedagogical
policy that provides proactive hints at the start of each step based on the
outcomes of our HelpNeed predictor: productive vs. unproductive. Our results
show that the students in the Adaptive condition exhibited better training
behaviors, with lower help avoidance, and higher help appropriateness (a higher
chance of receiving help when it was likely to be needed), as measured using
the HelpNeed classifier, when compared to the Control. Furthermore, the results
show that the students who received Adaptive hints based on HelpNeed
predictions during training significantly outperform their Control peers on the
posttest, with the former producing shorter, more optimal solutions in less
time. We conclude with suggestions on how these HelpNeed methods could be
applied in other well-structured open-ended domains.
</p>
<a href="http://arxiv.org/abs/2010.04124" target="_blank">arXiv:2010.04124</a> [<a href="http://arxiv.org/pdf/2010.04124" target="_blank">pdf</a>]

<h2>DART: A Lightweight Quality-Suggestive Data-to-Text Annotation Tool. (arXiv:2010.04141v1 [cs.CL])</h2>
<h3>Ernie Chang, Jeriah Caplinger, Alex Marin, Xiaoyu Shen, Vera Demberg</h3>
<p>We present a lightweight annotation tool, the Data AnnotatoR Tool (DART), for
the general task of labeling structured data with textual descriptions. The
tool is implemented as an interactive application that reduces human efforts in
annotating large quantities of structured data, e.g. in the format of a table
or tree structure. By using a backend sequence-to-sequence model, our system
iteratively analyzes the annotated labels in order to better sample unlabeled
data. In a simulation experiment performed on annotating large quantities of
structured data, DART has been shown to reduce the total number of annotations
needed with active learning and automatically suggesting relevant labels.
</p>
<a href="http://arxiv.org/abs/2010.04141" target="_blank">arXiv:2010.04141</a> [<a href="http://arxiv.org/pdf/2010.04141" target="_blank">pdf</a>]

<h2>Deep SVBRDF Estimation on Real Materials. (arXiv:2010.04143v1 [cs.CV])</h2>
<h3>Louis-Philippe Asselin, Denis Laurendeau, Jean-Fran&#xe7;ois Lalonde</h3>
<p>Recent work has demonstrated that deep learning approaches can successfully
be used to recover accurate estimates of the spatially-varying BRDF (SVBRDF) of
a surface from as little as a single image. Closer inspection reveals, however,
that most approaches in the literature are trained purely on synthetic data,
which, while diverse and realistic, is often not representative of the richness
of the real world. In this paper, we show that training such networks
exclusively on synthetic data is insufficient to achieve adequate results when
tested on real data. Our analysis leverages a new dataset of real materials
obtained with a novel portable multi-light capture apparatus. Through an
extensive series of experiments and with the use of a novel deep learning
architecture, we explore two strategies for improving results on real data:
finetuning, and a per-material optimization procedure. We show that adapting
network weights to real data is of critical importance, resulting in an
approach which significantly outperforms previous methods for SVBRDF estimation
on real materials. Dataset and code are available at
https://lvsn.github.io/real-svbrdf
</p>
<a href="http://arxiv.org/abs/2010.04143" target="_blank">arXiv:2010.04143</a> [<a href="http://arxiv.org/pdf/2010.04143" target="_blank">pdf</a>]

<h2>Olympus: a benchmarking framework for noisy optimization and experiment planning. (arXiv:2010.04153v1 [stat.ML])</h2>
<h3>Florian H&#xe4;se, Matteo Aldeghi, Riley J. Hickman, Lo&#xef;c M. Roch, Melodie Christensen, Elena Liles, Jason E. Hein, Al&#xe1;n Aspuru-Guzik</h3>
<p>Research challenges encountered across science, engineering, and economics
can frequently be formulated as optimization tasks. In chemistry and materials
science, recent growth in laboratory digitization and automation has sparked
interest in optimization-guided autonomous discovery and closed-loop
experimentation. Experiment planning strategies based on off-the-shelf
optimization algorithms can be employed in fully autonomous research platforms
to achieve desired experimentation goals with the minimum number of trials.
However, the experiment planning strategy that is most suitable to a scientific
discovery task is a priori unknown while rigorous comparisons of different
strategies are highly time and resource demanding. As optimization algorithms
are typically benchmarked on low-dimensional synthetic functions, it is unclear
how their performance would translate to noisy, higher-dimensional experimental
tasks encountered in chemistry and materials science. We introduce Olympus, a
software package that provides a consistent and easy-to-use framework for
benchmarking optimization algorithms against realistic experiments emulated via
probabilistic deep-learning models. Olympus includes a collection of
experimentally derived benchmark sets from chemistry and materials science and
a suite of experiment planning strategies that can be easily accessed via a
user-friendly python interface. Furthermore, Olympus facilitates the
integration, testing, and sharing of custom algorithms and user-defined
datasets. In brief, Olympus mitigates the barriers associated with benchmarking
optimization algorithms on realistic experimental scenarios, promoting data
sharing and the creation of a standard framework for evaluating the performance
of experiment planning strategies
</p>
<a href="http://arxiv.org/abs/2010.04153" target="_blank">arXiv:2010.04153</a> [<a href="http://arxiv.org/pdf/2010.04153" target="_blank">pdf</a>]

<h2>Online and Distribution-Free Robustness: Regression and Contextual Bandits with Huber Contamination. (arXiv:2010.04157v1 [cs.LG])</h2>
<h3>Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau</h3>
<p>In this work we revisit two classic high-dimensional online learning
problems, namely regression and linear contextual bandits, from the perspective
of adversarial robustness. Existing works in algorithmic robust statistics make
strong distributional assumptions that ensure that the input data is evenly
spread out or comes from a nice generative model. Is it possible to achieve
strong robustness guarantees even without distributional assumptions
altogether, where the sequence of tasks we are asked to solve is adaptively and
adversarially chosen?

We answer this question in the affirmative for both regression and linear
contextual bandits. In fact our algorithms succeed where convex surrogates fail
in the sense that we show strong lower bounds categorically for the existing
approaches. Our approach is based on a novel way to use the sum-of-squares
hierarchy in online learning and in the absence of distributional assumptions.
Moreover we give extensions of our main results to infinite dimensional
settings where the feature vectors are represented implicitly via a kernel map.
</p>
<a href="http://arxiv.org/abs/2010.04157" target="_blank">arXiv:2010.04157</a> [<a href="http://arxiv.org/pdf/2010.04157" target="_blank">pdf</a>]

<h2>Adversarial Attack and Defense on Point Sets. (arXiv:1902.10899v3 [cs.CV] UPDATED)</h2>
<h3>Qiang Zhang, Jiancheng Yang, Rongyao Fang, Bingbing Ni, Jinxian Liu, Qi Tian</h3>
<p>Emergence of the utility of 3D point cloud data in safety-critical vision
tasks (e.g., ADAS) urges researchers to pay more attention to the robustness of
3D representations and deep networks. To this end, we develop an attack and
defense scheme, dedicated to 3D point cloud data, for preventing 3D point
clouds from manipulated as well as pursuing noise-tolerable 3D representation.
A set of novel 3D point cloud attack operations are proposed via pointwise
gradient perturbation and adversarial point attachment / detachment. We then
develop a flexible perturbation-measurement scheme for 3D point cloud data to
detect potential attack data or noisy sensing data. Notably, the proposed
defense methods are even effective to detect the adversarial point clouds
generated by a proof-of-concept attack directly targeting the defense.
Transferability of adversarial attacks between several point cloud networks is
addressed, and we propose an momentum-enhanced pointwise gradient to improve
the attack transferability. We further analyze the transferability from
adversarial point clouds to grid CNNs and the inverse. Extensive experimental
results on common point cloud benchmarks demonstrate the validity of the
proposed 3D attack and defense framework.
</p>
<a href="http://arxiv.org/abs/1902.10899" target="_blank">arXiv:1902.10899</a> [<a href="http://arxiv.org/pdf/1902.10899" target="_blank">pdf</a>]

<h2>The Supermarket Model with Known and Predicted Service Times. (arXiv:1905.12155v2 [cs.PF] UPDATED)</h2>
<h3>Michael Mitzenmacher, Matteo Dell&#x27;Amico</h3>
<p>The supermarket model refers to a system with a large number of queues, where
arriving customers choose $d$ queues at random and join the queue with the
fewest customers. The supermarket model demonstrates the power of even small
amounts of choice, as compared to simply joining a queue chosen uniformly at
random, for load balancing systems. In this work we perform simulation-based
studies to consider variations where service times for a customer are
predicted, as might be done in modern settings using machine learning
techniques or related mechanisms. Our primary takeaway is that using even
seemingly weak predictions of service times can yield significant benefits over
blind First In First Out queueing in this context. However, some care must be
taken when using predicted service time information to both choose a queue and
order elements for service within a queue; while in many cases using the
information for both choosing and ordering is beneficial, in many of our
simulation settings we find that simply using the number of jobs to choose a
queue is better when using predicted service times to order jobs in a queue.
Although this study is simulation based, our study leaves many natural
theoretical open questions for future work.
</p>
<a href="http://arxiv.org/abs/1905.12155" target="_blank">arXiv:1905.12155</a> [<a href="http://arxiv.org/pdf/1905.12155" target="_blank">pdf</a>]

<h2>Open Set Domain Adaptation: Theoretical Bound and Algorithm. (arXiv:1907.08375v2 [cs.LG] UPDATED)</h2>
<h3>Zhen Fang, Jie Lu, Feng Liu, Junyu Xuan, Guangquan Zhang</h3>
<p>The aim of unsupervised domain adaptation is to leverage the knowledge in a
labeled (source) domain to improve a model's learning performance with an
unlabeled (target) domain -- the basic strategy being to mitigate the effects
of discrepancies between the two distributions. Most existing algorithms can
only handle unsupervised closed set domain adaptation (UCSDA), i.e., where the
source and target domains are assumed to share the same label set. In this
paper, we target a more challenging but realistic setting: unsupervised open
set domain adaptation (UOSDA), where the target domain has unknown classes that
are not found in the source domain. This is the first study to provide a
learning bound for open set domain adaptation, which we do by theoretically
investigating the risk of the target classifier on unknown classes. The
proposed learning bound has a special term, namely open set difference, which
reflects the risk of the target classifier on unknown classes. Further, we
present a novel and theoretically guided unsupervised algorithm for open set
domain adaptation, called distribution alignment with ppen difference (DAOD),
which is based on regularizing this open set difference bound. The experiments
on several benchmark datasets show the superior performance of the proposed
UOSDA method compared with the state-of-the-art methods in the literature.
</p>
<a href="http://arxiv.org/abs/1907.08375" target="_blank">arXiv:1907.08375</a> [<a href="http://arxiv.org/pdf/1907.08375" target="_blank">pdf</a>]

<h2>MDP Playground: Controlling Dimensions of Hardness in Reinforcement Learning. (arXiv:1909.07750v3 [cs.LG] UPDATED)</h2>
<h3>Raghu Rajan, Jessica Lizeth Borja Diaz, Suresh Guttikonda, Fabio Ferreira, Andr&#xe9; Biedenkapp, Frank Hutter</h3>
<p>We present MDP Playground, an efficient benchmark for Reinforcement Learning
(RL) algorithms with various dimensions of hardness that can be controlled
independently to challenge algorithms in different ways and to obtain varying
degrees of hardness in generated environments. We consider and allow control
over a wide variety of key hardness dimensions, including delayed rewards,
rewardable sequences, sparsity of rewards, stochasticity, image
representations, irrelevant features, time unit, and action max. While it is
very time consuming to run RL algorithms on standard benchmarks, we define a
parameterised collection of fast-to-run toy benchmarks in OpenAI Gym by varying
these dimensions. Despite their toy nature and low compute requirements, we
show that these benchmarks present substantial challenges to current RL
algorithms. Furthermore, since we can generate environments with a desired
value for each of the dimensions, in addition to having fine-grained control
over the environments' hardness, we also have the ground truth available for
evaluating algorithms. Finally, we evaluate the kinds of transfer for these
dimensions that may be expected from our benchmarks to more complex benchmarks.
We believe that MDP Playground is a valuable testbed for researchers designing
new, adaptive and intelligent RL algorithms and those wanting to unit test
their algorithms.
</p>
<a href="http://arxiv.org/abs/1909.07750" target="_blank">arXiv:1909.07750</a> [<a href="http://arxiv.org/pdf/1909.07750" target="_blank">pdf</a>]

<h2>Interpretations are useful: penalizing explanations to align neural networks with prior knowledge. (arXiv:1909.13584v4 [cs.LG] UPDATED)</h2>
<h3>Laura Rieger, Chandan Singh, W. James Murdoch, Bin Yu</h3>
<p>For an explanation of a deep learning model to be effective, it must provide
both insight into a model and suggest a corresponding action in order to
achieve some objective. Too often, the litany of proposed explainable deep
learning methods stop at the first step, providing practitioners with insight
into a model, but no way to act on it. In this paper, we propose contextual
decomposition explanation penalization (CDEP), a method which enables
practitioners to leverage existing explanation methods in order to increase the
predictive accuracy of deep learning models. In particular, when shown that a
model has incorrectly assigned importance to some features, CDEP enables
practitioners to correct these errors by directly regularizing the provided
explanations. Using explanations provided by contextual decomposition (CD)
(Murdoch et al., 2018), we demonstrate the ability of our method to increase
performance on an array of toy and real datasets.
</p>
<a href="http://arxiv.org/abs/1909.13584" target="_blank">arXiv:1909.13584</a> [<a href="http://arxiv.org/pdf/1909.13584" target="_blank">pdf</a>]

<h2>Reducing Sentiment Bias in Language Models via Counterfactual Evaluation. (arXiv:1911.03064v3 [cs.CL] UPDATED)</h2>
<h3>Po-Sen Huang, Huan Zhang, Ray Jiang, Robert Stanforth, Johannes Welbl, Jack Rae, Vishal Maini, Dani Yogatama, Pushmeet Kohli</h3>
<p>Advances in language modeling architectures and the availability of large
text corpora have driven progress in automatic text generation. While this
results in models capable of generating coherent texts, it also prompts models
to internalize social biases present in the training corpus. This paper aims to
quantify and reduce a particular type of bias exhibited by language models:
bias in the sentiment of generated text. Given a conditioning context (e.g., a
writing prompt) and a language model, we analyze if (and how) the sentiment of
the generated text is affected by changes in values of sensitive attributes
(e.g., country names, occupations, genders) in the conditioning context using a
form of counterfactual evaluation. We quantify sentiment bias by adopting
individual and group fairness metrics from the fair machine learning
literature, and demonstrate that large-scale models trained on two different
corpora (news articles, and Wikipedia) exhibit considerable levels of bias. We
then propose embedding and sentiment prediction-derived regularization on the
language model's latent representations. The regularizations improve fairness
metrics while retaining comparable levels of perplexity and semantic
similarity.
</p>
<a href="http://arxiv.org/abs/1911.03064" target="_blank">arXiv:1911.03064</a> [<a href="http://arxiv.org/pdf/1911.03064" target="_blank">pdf</a>]

<h2>Inflationary Constant Factors and Why Python is Faster Than C++. (arXiv:1911.12338v2 [cs.OH] UPDATED)</h2>
<h3>Mehrdad Niknami</h3>
<p>Constant-factor differences are frequently ignored when analyzing the
complexity of algorithms and implementations, as they appear to be
insignificant in practice. In this paper, we demonstrate that this assumption
can in fact have far more profound implications on time complexity than is
obvious at first glance, and that a poor consideration of trade-offs can result
in polynomially slower algorithms whose roots can be deeply and fundamentally
ingrained into a programming language itself. While the general observation may
not be novel from a theoretical standpoint, it is rarely (if ever) presented in
traditional computer science curricula or other settings, and appears to be far
from common knowledge in practical software engineering. We thus hope bring
awareness to this issue and urge careful consideration of significant
trade-offs that can result from trivial decisions made while programming.
</p>
<a href="http://arxiv.org/abs/1911.12338" target="_blank">arXiv:1911.12338</a> [<a href="http://arxiv.org/pdf/1911.12338" target="_blank">pdf</a>]

<h2>Learning to synthesise the ageing brain without longitudinal data. (arXiv:1912.02620v3 [eess.IV] UPDATED)</h2>
<h3>Tian Xia, Agisilaos Chartsias, Chengjia Wang, Sotirios A. Tsaftaris</h3>
<p>How will my face look when I get older? Or, for a more challenging question:
How will my brain look when I get older? To answer this question one must
devise (and learn from data) a multivariate auto-regressive function which
given an image and a desired target age generates an output image. While
collecting data for faces may be easier, collecting longitudinal brain data is
not trivial. We propose a deep learning-based method that learns to simulate
subject-specific brain ageing trajectories without relying on longitudinal
data. Our method synthesises images conditioned on two factors: age (a
continuous variable), and status of Alzheimer's Disease (AD, an ordinal
variable). With an adversarial formulation we learn the joint distribution of
brain appearance, age and AD status, and define reconstruction losses to
address the challenging problem of preserving subject identity. We compare with
several benchmarks using two widely used datasets. We evaluate the quality and
realism of synthesised images using ground-truth longitudinal data and a
pre-trained age predictor. We show that, despite the use of cross-sectional
data, our model learns patterns of gray matter atrophy in the middle temporal
gyrus in patients with AD. To demonstrate generalisation ability, we train on
one dataset and evaluate predictions on the other. In conclusion, our model
shows an ability to separate age, disease influence and anatomy using only 2D
cross-sectional data that should should be useful in large studies into
neurodegenerative disease, that aim to combine several data sources. To
facilitate such future studies by the community at large our code is made
available at https://github.com/xiat0616/BrainAgeing.
</p>
<a href="http://arxiv.org/abs/1912.02620" target="_blank">arXiv:1912.02620</a> [<a href="http://arxiv.org/pdf/1912.02620" target="_blank">pdf</a>]

<h2>A Hybrid Approach and Unified Framework for Bibliographic Reference Extraction. (arXiv:1912.07266v2 [cs.CV] UPDATED)</h2>
<h3>Syed Tahseen Raza Rizvi, Andreas Dengel, Sheraz Ahmed</h3>
<p>Publications are an integral part in a scientific community. Bibliographic
reference extraction from scientific publication is a challenging task due to
diversity in referencing styles and document layout. Existing methods perform
sufficiently on one dataset however, applying these solutions to a different
dataset proves to be challenging. Therefore, a generic solution was anticipated
which could overcome the limitations of the previous approaches. The
contribution of this paper is three-fold. First, it presents a novel approach
called DeepBiRD which is inspired by human visual perception and exploits
layout features to identify individual references in a scientific publication.
Second, we release a large dataset for image-based reference detection with
2401 scans containing 38863 references, all manually annotated for individual
reference. Third, we present a unified and highly configurable end-to-end
automatic bibliographic reference extraction framework called BRExSys which
employs DeepBiRD along with state-of-the-art text-based models to detect and
visualize references from a bibliographic document. Our proposed approach
pre-processes the images in which a hybrid representation is obtained by
processing the given image using different computer vision techniques. Then, it
performs layout driven reference detection using Mask R-CNN on a given
scientific publication. DeepBiRD was evaluated on two different datasets to
demonstrate the generalization of this approach. The proposed system achieved
an AP50 of 98.56% on our dataset. DeepBiRD significantly outperformed the
current state-of-the-art approach on their dataset. Therefore, suggesting that
DeepBiRD is significantly superior in performance, generalized, and independent
of any domain or referencing style.
</p>
<a href="http://arxiv.org/abs/1912.07266" target="_blank">arXiv:1912.07266</a> [<a href="http://arxiv.org/pdf/1912.07266" target="_blank">pdf</a>]

<h2>Transfer learning in hybrid classical-quantum neural networks. (arXiv:1912.08278v2 [quant-ph] UPDATED)</h2>
<h3>Andrea Mari, Thomas R. Bromley, Josh Izaac, Maria Schuld, Nathan Killoran</h3>
<p>We extend the concept of transfer learning, widely applied in modern machine
learning algorithms, to the emerging context of hybrid neural networks composed
of classical and quantum elements. We propose different implementations of
hybrid transfer learning, but we focus mainly on the paradigm in which a
pre-trained classical network is modified and augmented by a final variational
quantum circuit. This approach is particularly attractive in the current era of
intermediate-scale quantum technology since it allows to optimally pre-process
high dimensional data (e.g., images) with any state-of-the-art classical
network and to embed a select set of highly informative features into a quantum
processor. We present several proof-of-concept examples of the convenient
application of quantum transfer learning for image recognition and quantum
state classification. We use the cross-platform software library PennyLane to
experimentally test a high-resolution image classifier with two different
quantum computers, respectively provided by IBM and Rigetti.
</p>
<a href="http://arxiv.org/abs/1912.08278" target="_blank">arXiv:1912.08278</a> [<a href="http://arxiv.org/pdf/1912.08278" target="_blank">pdf</a>]

<h2>Backpropagation through nonlinear units for all-optical training of neural networks. (arXiv:1912.12256v3 [cs.ET] UPDATED)</h2>
<h3>Xianxin Guo, Thomas D. Barrett, Zhiming M. Wang, A. I. Lvovsky</h3>
<p>Backpropagation through nonlinear neurons is an outstanding challenge to the
field of optical neural networks and the major conceptual barrier to
all-optical training schemes. Each neuron is required to exhibit a
directionally dependent response to propagating optical signals, with the
backwards response conditioned on the forward signal, which is highly
non-trivial to implement optically. We propose a practical and surprisingly
simple solution that uses saturable absorption to provide the network
nonlinearity. We find that the backward propagating gradients required to train
the network can be approximated in a pump-probe scheme that requires only
passive optical elements. Simulations show that, with readily obtainable
optical depths, our approach can achieve equivalent performance to
state-of-the-art computational networks on image classification benchmarks,
even in deep networks with multiple sequential gradient approximations. This
scheme is compatible with leading optical neural network proposals and
therefore provides a feasible path towards end-to-end optical training.
</p>
<a href="http://arxiv.org/abs/1912.12256" target="_blank">arXiv:1912.12256</a> [<a href="http://arxiv.org/pdf/1912.12256" target="_blank">pdf</a>]

<h2>Adversarially Guided Self-Play for Adopting Social Conventions. (arXiv:2001.05994v2 [cs.AI] UPDATED)</h2>
<h3>Mycal Tucker, Yilun Zhou, Julie Shah</h3>
<p>Robotic agents must adopt existing social conventions in order to be
effective teammates. These social conventions, such as driving on the right or
left side of the road, are arbitrary choices among optimal policies, but all
agents on a successful team must use the same convention. Prior work has
identified a method of combining self-play with paired input-output data
gathered from existing agents in order to learn their social convention without
interacting with them. We build upon this work by introducing a technique
called Adversarial Self-Play (ASP) that uses adversarial training to shape the
space of possible learned policies and substantially improves learning
efficiency. ASP only requires the addition of unpaired data: a dataset of
outputs produced by the social convention without associated inputs.
Theoretical analysis reveals how ASP shapes the policy space and the
circumstances (when behaviors are clustered or exhibit some other structure)
under which it offers the greatest benefits. Empirical results across three
domains confirm ASP's advantages: it produces models that more closely match
the desired social convention when given as few as two paired datapoints.
</p>
<a href="http://arxiv.org/abs/2001.05994" target="_blank">arXiv:2001.05994</a> [<a href="http://arxiv.org/pdf/2001.05994" target="_blank">pdf</a>]

<h2>Building high accuracy emulators for scientific simulations with deep neural architecture search. (arXiv:2001.08055v2 [stat.ML] UPDATED)</h2>
<h3>M. F. Kasim, D. Watson-Parris, L. Deaconu, S. Oliver, P. Hatfield, D. H. Froula, G. Gregori, M. Jarvis, S. Khatiwala, J. Korenaga, J. Topp-Mugglestone, E. Viezzer, S. M. Vinko</h3>
<p>Computer simulations are invaluable tools for scientific discovery. However,
accurate simulations are often slow to execute, which limits their
applicability to extensive parameter exploration, large-scale data analysis,
and uncertainty quantification. A promising route to accelerate simulations by
building fast emulators with machine learning requires large training datasets,
which can be prohibitively expensive to obtain with slow simulations. Here we
present a method based on neural architecture search to build accurate
emulators even with a limited number of training data. The method successfully
accelerates simulations by up to 2 billion times in 10 scientific cases
including astrophysics, climate science, biogeochemistry, high energy density
physics, fusion energy, and seismology, using the same super-architecture,
algorithm, and hyperparameters. Our approach also inherently provides emulator
uncertainty estimation, adding further confidence in their use. We anticipate
this work will accelerate research involving expensive simulations, allow more
extensive parameters exploration, and enable new, previously unfeasible
computational discovery.
</p>
<a href="http://arxiv.org/abs/2001.08055" target="_blank">arXiv:2001.08055</a> [<a href="http://arxiv.org/pdf/2001.08055" target="_blank">pdf</a>]

<h2>MRI Banding Removal via Adversarial Training. (arXiv:2001.08699v3 [eess.IV] UPDATED)</h2>
<h3>Aaron Defazio, Tullie Murrell, Michael P. Recht</h3>
<p>MRI images reconstructed from sub-sampled Cartesian data using deep learning
techniques often show a characteristic banding (sometimes described as
streaking), which is particularly strong in low signal-to-noise regions of the
reconstructed image. In this work, we propose the use of an adversarial loss
that penalizes banding structures without requiring any human annotation. Our
technique greatly reduces the appearance of banding, without requiring any
additional computation or post-processing at reconstruction time. We report the
results of a blind comparison against a strong baseline by a group of expert
evaluators (board-certified radiologists), where our approach is ranked
superior at banding removal with no statistically significant loss of detail.
</p>
<a href="http://arxiv.org/abs/2001.08699" target="_blank">arXiv:2001.08699</a> [<a href="http://arxiv.org/pdf/2001.08699" target="_blank">pdf</a>]

<h2>Encoding Physical Constraints in Differentiable Newton-Euler Algorithm. (arXiv:2001.08861v4 [cs.RO] UPDATED)</h2>
<h3>Giovanni Sutanto, Austin S. Wang, Yixin Lin, Mustafa Mukadam, Gaurav S. Sukhatme, Akshara Rai, Franziska Meier</h3>
<p>The recursive Newton-Euler Algorithm (RNEA) is a popular technique for
computing the dynamics of robots. RNEA can be framed as a differentiable
computational graph, enabling the dynamics parameters of the robot to be
learned from data via modern auto-differentiation toolboxes. However, the
dynamics parameters learned in this manner can be physically implausible. In
this work, we incorporate physical constraints in the learning by adding
structure to the learned parameters. This results in a framework that can learn
physically plausible dynamics via gradient descent, improving the training
speed as well as generalization of the learned dynamics models. We evaluate our
method on real-time inverse dynamics control tasks on a 7 degree of freedom
robot arm, both in simulation and on the real robot. Our experiments study a
spectrum of structure added to the parameters of the differentiable RNEA
algorithm, and compare their performance and generalization.
</p>
<a href="http://arxiv.org/abs/2001.08861" target="_blank">arXiv:2001.08861</a> [<a href="http://arxiv.org/pdf/2001.08861" target="_blank">pdf</a>]

<h2>Algorithmic Recourse: from Counterfactual Explanations to Interventions. (arXiv:2002.06278v4 [cs.LG] UPDATED)</h2>
<h3>Amir-Hossein Karimi, Bernhard Sch&#xf6;lkopf, Isabel Valera</h3>
<p>As machine learning is increasingly used to inform consequential
decision-making (e.g., pre-trial bail and loan approval), it becomes important
to explain how the system arrived at its decision, and also suggest actions to
achieve a favorable decision. Counterfactual explanations -- "how the world
would have (had) to be different for a desirable outcome to occur" -- aim to
satisfy these criteria. Existing works have primarily focused on designing
algorithms to obtain counterfactual explanations for a wide range of settings.
However, one of the main objectives of "explanations as a means to help a
data-subject act rather than merely understand" has been overlooked. In
layman's terms, counterfactual explanations inform an individual where they
need to get to, but not how to get there. In this work, we rely on causal
reasoning to caution against the use of counterfactual explanations as a
recommendable set of actions for recourse. Instead, we propose a shift of
paradigm from recourse via nearest counterfactual explanations to recourse
through minimal interventions, moving the focus from explanations to
recommendations. Finally, we provide the reader with an extensive discussion on
how to realistically achieve recourse beyond structural interventions.
</p>
<a href="http://arxiv.org/abs/2002.06278" target="_blank">arXiv:2002.06278</a> [<a href="http://arxiv.org/pdf/2002.06278" target="_blank">pdf</a>]

<h2>Map-less Navigation: A Single DRL-based Controller for Robots with Varied Dimensions. (arXiv:2002.06320v2 [cs.RO] UPDATED)</h2>
<h3>Wei Zhang, Yunfeng Zhang, Ning Liu</h3>
<p>Deep reinforcement learning (DRL) has shown great potential in training
control agents for map-less robot navigation. However, the trained agents are
generally dependent on the employed robot in training or dimension-specific,
which cannot be directly reused by robots with different dimensional
configurations. To address this issue, a DRL-based dimension-variable robot
navigation method is proposed in this paper. The proposed approach trains a
meta-agent with DRL and then transfers the meta-skill to a robot with a
different dimensional configuration (named dimension-scaled robot) using a
method named dimension-variable skill transfer (DVST). During the training
phase, the meta-agent learns to perform self-navigation with the meta-robot in
a simulation environment. In the skill-transfer phase, the observations of the
dimension-scaled robot are transferred to the meta-agent in a scaled manner,
and the control policy generated by the meta-agent is scaled back to the
dimension-scaled robot. Simulation and real-world experimental results indicate
that robots with different sizes and angular velocity bounds can accomplish
navigation tasks in unknown and dynamic environments without any retraining.
This work greatly extends the application range of DRL-based navigation methods
from the fixed dimensional configuration to varied dimensional configurations.
</p>
<a href="http://arxiv.org/abs/2002.06320" target="_blank">arXiv:2002.06320</a> [<a href="http://arxiv.org/pdf/2002.06320" target="_blank">pdf</a>]

<h2>Snitch: A tiny Pseudo Dual-Issue Processor for Area and Energy Efficient Execution of Floating-Point Intensive Workloads. (arXiv:2002.10143v2 [cs.AR] UPDATED)</h2>
<h3>Florian Zaruba, Fabian Schuiki, Torsten Hoefler, Luca Benini</h3>
<p>Data-parallel applications, such as data analytics, machine learning, and
scientific computing, are placing an ever-growing demand on floating-point
operations per second on emerging systems. With increasing integration density,
the quest for energy efficiency becomes the number one design concern. While
dedicated accelerators provide high energy efficiency, they are
over-specialized and hard to adjust to algorithmic changes. We propose an
architectural concept that tackles the issues of achieving extreme energy
efficiency while still maintaining high flexibility as a general-purpose
compute engine. The key idea is to pair a tiny 10kGE control core, called
Snitch, with a double-precision FPU to adjust the compute to control ratio.
While traditionally minimizing non-FPU area and achieving high floating-point
utilization has been a trade-off, with Snitch, we achieve them both, by
enhancing the ISA with two minimally intrusive extensions: stream semantic
registers (SSR) and a floating-point repetition instruction (FREP). SSRs allow
the core to implicitly encode load/store instructions as register reads/writes,
eliding many explicit memory instructions. The FREP extension decouples the
floating-point and integer pipeline by sequencing instructions from a
micro-loop buffer. These ISA extensions significantly reduce the pressure on
the core and free it up for other tasks, making Snitch and FPU effectively
dual-issue at a minimal incremental cost of 3.2%. The two low overhead ISA
extensions make Snitch more flexible than a contemporary vector processor lane,
achieving a $2\times$ energy-efficiency improvement. We have evaluated the
proposed core and ISA extensions on an octa-core cluster in 22nm technology. We
achieve more than $5\times$ multi-core speed-up and a $3.5\times$ gain in
energy efficiency on several parallel microkernels.
</p>
<a href="http://arxiv.org/abs/2002.10143" target="_blank">arXiv:2002.10143</a> [<a href="http://arxiv.org/pdf/2002.10143" target="_blank">pdf</a>]

<h2>DeepURL: Deep Pose Estimation Framework for Underwater Relative Localization. (arXiv:2003.05523v3 [cs.RO] UPDATED)</h2>
<h3>Bharat Joshi, Md Modasshir, Travis Manderson, Hunter Damron, Marios Xanthidis, Alberto Quattrini Li, Ioannis Rekleitis, Gregory Dudek</h3>
<p>In this paper, we propose a real-time deep learning approach for determining
the 6D relative pose of Autonomous Underwater Vehicles (AUV) from a single
image. A team of autonomous robots localizing themselves in a
communication-constrained underwater environment is essential for many
applications such as underwater exploration, mapping, multi-robot convoying,
and other multi-robot tasks. Due to the profound difficulty of collecting
ground truth images with accurate 6D poses underwater, this work utilizes
rendered images from the Unreal Game Engine simulation for training. An
image-to-image translation network is employed to bridge the gap between the
rendered and the real images producing synthetic images for training. The
proposed method predicts the 6D pose of an AUV from a single image as 2D image
keypoints representing 8 corners of the 3D model of the AUV, and then the 6D
pose in the camera coordinates is determined using RANSAC-based PnP.
Experimental results in real-world underwater environments (swimming pool and
ocean) with different cameras demonstrate the robustness and accuracy of the
proposed technique in terms of translation error and orientation error over the
state-of-the-art methods. The code is publicly available.
</p>
<a href="http://arxiv.org/abs/2003.05523" target="_blank">arXiv:2003.05523</a> [<a href="http://arxiv.org/pdf/2003.05523" target="_blank">pdf</a>]

<h2>Learning to Segment 3D Point Clouds in 2D Image Space. (arXiv:2003.05593v4 [cs.CV] UPDATED)</h2>
<h3>Yecheng Lyu, Xinming Huang, Ziming Zhang</h3>
<p>In contrast to the literature where local patterns in 3D point clouds are
captured by customized convolutional operators, in this paper we study the
problem of how to effectively and efficiently project such point clouds into a
2D image space so that traditional 2D convolutional neural networks (CNNs) such
as U-Net can be applied for segmentation. To this end, we are motivated by
graph drawing and reformulate it as an integer programming problem to learn the
topology-preserving graph-to-grid mapping for each individual point cloud. To
accelerate the computation in practice, we further propose a novel hierarchical
approximate algorithm. With the help of the Delaunay triangulation for graph
construction from point clouds and a multi-scale U-Net for segmentation, we
manage to demonstrate the state-of-the-art performance on ShapeNet and PartNet,
respectively, with significant improvement over the literature. Code is
available at https://github.com/Zhang-VISLab.
</p>
<a href="http://arxiv.org/abs/2003.05593" target="_blank">arXiv:2003.05593</a> [<a href="http://arxiv.org/pdf/2003.05593" target="_blank">pdf</a>]

<h2>L2B: Learning to Balance the Safety-Efficiency Trade-off in Interactive Crowd-aware Robot Navigation. (arXiv:2003.09207v2 [cs.RO] UPDATED)</h2>
<h3>Mai Nishimura, Ryo Yonetani</h3>
<p>This work presents a deep reinforcement learning framework for interactive
navigation in a crowded place. Our proposed approach, Learning to Balance (L2B)
framework enables mobile robot agents to steer safely towards their
destinations by avoiding collisions with a crowd, while actively clearing a
path by asking nearby pedestrians to make room, if necessary, to keep their
travel efficient. We observe that the safety and efficiency requirements in
crowd-aware navigation have a trade-off in the presence of social dilemmas
between the agent and the crowd. On the one hand, intervening in pedestrian
paths too much to achieve instant efficiency will result in collapsing a
natural crowd flow and may eventually put everyone, including the self, at risk
of collisions. On the other hand, keeping in silence to avoid every single
collision will lead to the agent's inefficient travel. With this observation,
our L2B framework augments the reward function used in learning an interactive
navigation policy to penalize frequent active path clearing and passive
collision avoidance, which substantially improves the balance of the
safety-efficiency trade-off. We evaluate our L2B framework in a challenging
crowd simulation and demonstrate its superiority, in terms of both navigation
success and collision rate, over a state-of-the-art navigation approach.
</p>
<a href="http://arxiv.org/abs/2003.09207" target="_blank">arXiv:2003.09207</a> [<a href="http://arxiv.org/pdf/2003.09207" target="_blank">pdf</a>]

<h2>Privacy-Preserving News Recommendation Model Learning. (arXiv:2003.09592v3 [cs.IR] UPDATED)</h2>
<h3>Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang, Xing Xie</h3>
<p>News recommendation aims to display news articles to users based on their
personal interest. Existing news recommendation methods rely on centralized
storage of user behavior data for model training, which may lead to privacy
concerns and risks due to the privacy-sensitive nature of user behaviors. In
this paper, we propose a privacy-preserving method for news recommendation
model training based on federated learning, where the user behavior data is
locally stored on user devices. Our method can leverage the useful information
in the behaviors of massive number users to train accurate news recommendation
models and meanwhile remove the need of centralized storage of them. More
specifically, on each user device we keep a local copy of the news
recommendation model, and compute gradients of the local model based on the
user behaviors in this device. The local gradients from a group of randomly
selected users are uploaded to server, which are further aggregated to update
the global model in the server. Since the model gradients may contain some
implicit private information, we apply local differential privacy (LDP) to them
before uploading for better privacy protection. The updated global model is
then distributed to each user device for local model update. We repeat this
process for multiple rounds. Extensive experiments on a real-world dataset show
the effectiveness of our method in news recommendation model training with
privacy protection.
</p>
<a href="http://arxiv.org/abs/2003.09592" target="_blank">arXiv:2003.09592</a> [<a href="http://arxiv.org/pdf/2003.09592" target="_blank">pdf</a>]

<h2>BVI-DVC: A Training Database for Deep Video Compression. (arXiv:2003.13552v2 [eess.IV] UPDATED)</h2>
<h3>Di Ma, Fan Zhang, David R. Bull</h3>
<p>Deep learning methods are increasingly being applied in the optimisation of
video compression algorithms and can achieve significantly enhanced coding
gains, compared to conventional approaches. Such approaches often employ
Convolutional Neural Networks (CNNs) which are trained on databases with
relatively limited content coverage. In this paper, a new extensive and
representative video database, BVI-DVC, is presented for training CNN-based
video compression systems, with specific emphasis on machine learning tools
that enhance conventional coding architectures, including spatial resolution
and bit depth up-sampling, post-processing and in-loop filtering. BVI-DVC
contains 800 sequences at various spatial resolutions from 270p to 2160p and
has been evaluated on ten existing network architectures for four different
coding tools. Experimental results show that this database produces significant
improvements in terms of coding gains over three existing (commonly used)
image/video training databases under the same training and evaluation
configurations. The overall additional coding improvements by using the
proposed database for all tested coding modules and CNN architectures are up to
10.3% based on the assessment of PSNR and 8.1% based on VMAF.
</p>
<a href="http://arxiv.org/abs/2003.13552" target="_blank">arXiv:2003.13552</a> [<a href="http://arxiv.org/pdf/2003.13552" target="_blank">pdf</a>]

<h2>Neural Architecture Generator Optimization. (arXiv:2004.01395v2 [cs.LG] UPDATED)</h2>
<h3>Binxin Ru, Pedro Esperanca, Fabio Carlucci</h3>
<p>Neural Architecture Search (NAS) was first proposed to achieve
state-of-the-art performance through the discovery of new architecture
patterns, without human intervention. An over-reliance on expert knowledge in
the search space design has however led to increased performance (local optima)
without significant architectural breakthroughs, thus preventing truly novel
solutions from being reached. In this work we 1) are the first to investigate
casting NAS as a problem of finding the optimal network generator and 2) we
propose a new, hierarchical and graph-based search space capable of
representing an extremely large variety of network types, yet only requiring
few continuous hyper-parameters. This greatly reduces the dimensionality of the
problem, enabling the effective use of Bayesian Optimisation as a search
strategy. At the same time, we expand the range of valid architectures,
motivating a multi-objective learning approach. We demonstrate the
effectiveness of this strategy on six benchmark datasets and show that our
search space generates extremely lightweight yet highly competitive models.
</p>
<a href="http://arxiv.org/abs/2004.01395" target="_blank">arXiv:2004.01395</a> [<a href="http://arxiv.org/pdf/2004.01395" target="_blank">pdf</a>]

<h2>Dynamic Data Selection and Weighting for Iterative Back-Translation. (arXiv:2004.03672v2 [cs.CL] UPDATED)</h2>
<h3>Zi-Yi Dou, Antonios Anastasopoulos, Graham Neubig</h3>
<p>Back-translation has proven to be an effective method to utilize monolingual
data in neural machine translation (NMT), and iteratively conducting
back-translation can further improve the model performance. Selecting which
monolingual data to back-translate is crucial, as we require that the resulting
synthetic data are of high quality and reflect the target domain. To achieve
these two goals, data selection and weighting strategies have been proposed,
with a common practice being to select samples close to the target domain but
also dissimilar to the average general-domain text. In this paper, we provide
insights into this commonly used approach and generalize it to a dynamic
curriculum learning strategy, which is applied to iterative back-translation
models. In addition, we propose weighting strategies based on both the current
quality of the sentence and its improvement over the previous iteration. We
evaluate our models on domain adaptation, low-resource, and high-resource MT
settings and on two language pairs. Experimental results demonstrate that our
methods achieve improvements of up to 1.8 BLEU points over competitive
baselines.
</p>
<a href="http://arxiv.org/abs/2004.03672" target="_blank">arXiv:2004.03672</a> [<a href="http://arxiv.org/pdf/2004.03672" target="_blank">pdf</a>]

<h2>Predicting nucleation near the spinodal in the Ising model using machine learning. (arXiv:2004.09575v2 [physics.comp-ph] UPDATED)</h2>
<h3>Shan Huang, William Klein, Harvey Gould</h3>
<p>We use a Convolutional Neural Network (CNN) and two logistic regression
models to predict the probability of nucleation in the two-dimensional Ising
model. The three models successfully predict the probability for the Nearest
Neighbor Ising model for which classical nucleation is observed. The CNN
outperforms the logistic regression models near the spinodal of the Long Range
Ising model, but the accuracy of its predictions decreases as the quenches
approach the spinodal. Occlusion analysis suggests that this decrease is due to
the vanishing difference between the density of the nucleating droplet and the
background. Our results are consistent with the general conclusion that
predictability decreases near a critical point.
</p>
<a href="http://arxiv.org/abs/2004.09575" target="_blank">arXiv:2004.09575</a> [<a href="http://arxiv.org/pdf/2004.09575" target="_blank">pdf</a>]

<h2>Few-Shot Learning for Opinion Summarization. (arXiv:2004.14884v2 [cs.LG] UPDATED)</h2>
<h3>Arthur Bra&#x17e;inskas, Mirella Lapata, Ivan Titov</h3>
<p>Opinion summarization is the automatic creation of text reflecting subjective
information expressed in multiple documents, such as user reviews of a product.
The task is practically important and has attracted a lot of attention.
However, due to the high cost of summary production, datasets large enough for
training supervised models are lacking. Instead, the task has been
traditionally approached with extractive methods that learn to select text
fragments in an unsupervised or weakly-supervised way. Recently, it has been
shown that abstractive summaries, potentially more fluent and better at
reflecting conflicting information, can also be produced in an unsupervised
fashion. However, these models, not being exposed to actual summaries, fail to
capture their essential properties. In this work, we show that even a handful
of summaries is sufficient to bootstrap generation of the summary text with all
expected properties, such as writing style, informativeness, fluency, and
sentiment preservation. We start by training a conditional Transformer language
model to generate a new product review given other available reviews of the
product. The model is also conditioned on review properties that are directly
related to summaries; the properties are derived from reviews with no manual
effort. In the second stage, we fine-tune a plug-in module that learns to
predict property values on a handful of summaries. This lets us switch the
generator to the summarization mode. We show on Amazon and Yelp datasets that
our approach substantially outperforms previous extractive and abstractive
methods in automatic and human evaluation.
</p>
<a href="http://arxiv.org/abs/2004.14884" target="_blank">arXiv:2004.14884</a> [<a href="http://arxiv.org/pdf/2004.14884" target="_blank">pdf</a>]

<h2>How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking. (arXiv:2004.14992v2 [cs.CL] UPDATED)</h2>
<h3>Nicola De Cao, Michael Schlichtkrull, Wilker Aziz, Ivan Titov</h3>
<p>Attribution methods assess the contribution of inputs to the model
prediction. One way to do so is erasure: a subset of inputs is considered
irrelevant if it can be removed without affecting the prediction. Though
conceptually simple, erasure's objective is intractable and approximate search
remains expensive with modern deep NLP models. Erasure is also susceptible to
the hindsight bias: the fact that an input can be dropped does not mean that
the model `knows' it can be dropped. The resulting pruning is over-aggressive
and does not reflect how the model arrives at the prediction. To deal with
these challenges, we introduce Differentiable Masking. DiffMask learns to
mask-out subsets of the input while maintaining differentiability. The decision
to include or disregard an input token is made with a simple model based on
intermediate hidden layers of the analyzed model. First, this makes the
approach efficient because we predict rather than search. Second, as with
probing classifiers, this reveals what the network `knows' at the corresponding
layers. This lets us not only plot attribution heatmaps but also analyze how
decisions are formed across network layers. We use DiffMask to study BERT
models on sentiment classification and question answering.
</p>
<a href="http://arxiv.org/abs/2004.14992" target="_blank">arXiv:2004.14992</a> [<a href="http://arxiv.org/pdf/2004.14992" target="_blank">pdf</a>]

<h2>Visuo-Lingustic Question Answering (VLQA) Challenge. (arXiv:2005.00330v2 [cs.CV] UPDATED)</h2>
<h3>Shailaja Keyur Sampat, Yezhou Yang, Chitta Baral</h3>
<p>Understanding images and text together is an important aspect of cognition
and building advanced Artificial Intelligence (AI) systems. As a community, we
have achieved good benchmarks over language and vision domains separately,
however joint reasoning is still a challenge for state-of-the-art computer
vision and natural language processing (NLP) systems. We propose a novel task
to derive joint inference about a given image-text modality and compile the
Visuo-Linguistic Question Answering (VLQA) challenge corpus in a question
answering setting. Each dataset item consists of an image and a reading
passage, where questions are designed to combine both visual and textual
information i.e., ignoring either modality would make the question
unanswerable. We first explore the best existing vision-language architectures
to solve VLQA subsets and show that they are unable to reason well. We then
develop a modular method with slightly better baseline performance, but it is
still far behind human performance. We believe that VLQA will be a good
benchmark for reasoning over a visuo-linguistic context. The dataset, code and
leaderboard is available at https://shailaja183.github.io/vlqa/.
</p>
<a href="http://arxiv.org/abs/2005.00330" target="_blank">arXiv:2005.00330</a> [<a href="http://arxiv.org/pdf/2005.00330" target="_blank">pdf</a>]

<h2>Visually Grounded Continual Learning of Compositional Phrases. (arXiv:2005.00785v4 [cs.CL] UPDATED)</h2>
<h3>Xisen Jin, Junyi Du, Arka Sadhu, Ram Nevatia, Xiang Ren</h3>
<p>Humans acquire language continually with much more limited access to data
samples at a time, as compared to contemporary NLP systems. To study this
human-like language acquisition ability, we present VisCOLL, a visually
grounded language learning task, which simulates the continual acquisition of
compositional phrases from streaming visual scenes. In the task, models are
trained on a paired image-caption stream which has shifting object
distribution; while being constantly evaluated by a visually-grounded masked
language prediction task on held-out test sets. VisCOLL compounds the
challenges of continual learning (i.e., learning from continuously shifting
data distribution) and compositional generalization (i.e., generalizing to
novel compositions). To facilitate research on VisCOLL, we construct two
datasets, COCO-shift and Flickr-shift, and benchmark them using different
continual learning methods. Results reveal that SoTA continual learning
approaches provide little to no improvements on VisCOLL, since storing examples
of all possible compositions is infeasible. We conduct further ablations and
analysis to guide future work.
</p>
<a href="http://arxiv.org/abs/2005.00785" target="_blank">arXiv:2005.00785</a> [<a href="http://arxiv.org/pdf/2005.00785" target="_blank">pdf</a>]

<h2>What-if I ask you to explain: Explaining the effects of perturbations in procedural text. (arXiv:2005.01526v2 [cs.CL] UPDATED)</h2>
<h3>Dheeraj Rajagopal, Niket Tandon, Bhavana Dalvi, Peter Clark, Eduard Hovy</h3>
<p>We address the task of explaining the effects of perturbations in procedural
text, an important test of process comprehension. Consider a passage describing
a rabbit's life-cycle: humans can easily explain the effect on the rabbit
population if a female rabbit becomes ill -- i.e., the female rabbit would not
become pregnant, and as a result not have babies leading to a decrease in
rabbit population. We present QUARTET, a system that constructs such
explanations from paragraphs, by modeling the explanation task as a multitask
learning problem. QUARTET provides better explanations (based on the sentences
in the procedural text) compared to several strong baselines on a recent
process comprehension benchmark. We also present a surprising secondary effect:
our model also achieves a new SOTA with a 7% absolute F1 improvement on a
downstream QA task. This illustrates that good explanations do not have to come
at the expense of end task performance.
</p>
<a href="http://arxiv.org/abs/2005.01526" target="_blank">arXiv:2005.01526</a> [<a href="http://arxiv.org/pdf/2005.01526" target="_blank">pdf</a>]

<h2>BlackBox: Generalizable Reconstruction of Extremal Values from Incomplete Spatio-Temporal Data. (arXiv:2005.02140v3 [cs.LG] UPDATED)</h2>
<h3>Tomislav Ivek, Domagoj Vlah</h3>
<p>We describe our submission to the Extreme Value Analysis 2019 Data Challenge
in which teams were asked to predict extremes of sea surface temperature
anomaly within spatio-temporal regions of missing data. We present a
computational framework which reconstructs missing data using convolutional
deep neural networks. Conditioned on incomplete data, we employ
autoencoder-like models as multivariate conditional distributions from which
possible reconstructions of the complete dataset are sampled using imputed
noise. In order to mitigate bias introduced by any one particular model, a
prediction ensemble is constructed to create the final distribution of extremal
values. Our method does not rely on expert knowledge in order to accurately
reproduce dynamic features of a complex oceanographic system with minimal
assumptions. The obtained results promise reusability and generalization to
other domains.
</p>
<a href="http://arxiv.org/abs/2005.02140" target="_blank">arXiv:2005.02140</a> [<a href="http://arxiv.org/pdf/2005.02140" target="_blank">pdf</a>]

<h2>Communication-Efficient Distributed Stochastic AUC Maximization with Deep Neural Networks. (arXiv:2005.02426v2 [cs.DC] UPDATED)</h2>
<h3>Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, Tianbao Yang</h3>
<p>In this paper, we study distributed algorithms for large-scale AUC
maximization with a deep neural network as a predictive model. Although
distributed learning techniques have been investigated extensively in deep
learning, they are not directly applicable to stochastic AUC maximization with
deep neural networks due to its striking differences from standard loss
minimization problems (e.g., cross-entropy). Towards addressing this challenge,
we propose and analyze a communication-efficient distributed optimization
algorithm based on a {\it non-convex concave} reformulation of the AUC
maximization, in which the communication of both the primal variable and the
dual variable between each worker and the parameter server only occurs after
multiple steps of gradient-based updates in each worker. Compared with the
naive parallel version of an existing algorithm that computes stochastic
gradients at individual machines and averages them for updating the model
parameters, our algorithm requires a much less number of communication rounds
and still achieves a linear speedup in theory. To the best of our knowledge,
this is the \textbf{first} work that solves the {\it non-convex concave
min-max} problem for AUC maximization with deep neural networks in a
communication-efficient distributed manner while still maintaining the linear
speedup property in theory. Our experiments on several benchmark datasets show
the effectiveness of our algorithm and also confirm our theory.
</p>
<a href="http://arxiv.org/abs/2005.02426" target="_blank">arXiv:2005.02426</a> [<a href="http://arxiv.org/pdf/2005.02426" target="_blank">pdf</a>]

<h2>Local Cascade Ensemble for Multivariate Data Classification. (arXiv:2005.03645v3 [cs.LG] UPDATED)</h2>
<h3>Kevin Fauvel, &#xc9;lisa Fromont, V&#xe9;ronique Masson, Philippe Faverdin, Alexandre Termier</h3>
<p>We present LCE, a Local Cascade Ensemble for traditional (tabular)
multivariate data classification, and its extension LCEM for Multivariate Time
Series (MTS) classification. LCE is a new hybrid ensemble method that combines
an explicit boosting-bagging approach to handle the bias-variance trade-off
faced by machine learning models and an implicit divide-and-conquer approach to
individualize classifier errors on different parts of the training data. Our
evaluation firstly shows that the hybrid ensemble method LCE outperforms the
state-of-the-art classifiers on the UCI datasets and that LCEM outperforms the
state-of-the-art MTS classifiers on the UEA datasets. Furthermore, LCEM
provides faithful explainability by design and manifests robust performance
when faced with challenges arising from continuous data collection (different
MTS length, missing data and noise).
</p>
<a href="http://arxiv.org/abs/2005.03645" target="_blank">arXiv:2005.03645</a> [<a href="http://arxiv.org/pdf/2005.03645" target="_blank">pdf</a>]

<h2>Towards Robustness against Unsuspicious Adversarial Examples. (arXiv:2005.04272v2 [cs.LG] UPDATED)</h2>
<h3>Liang Tong, Minzhe Guo, Atul Prakash, Yevgeniy Vorobeychik</h3>
<p>Despite the remarkable success of deep neural networks, significant concerns
have emerged about their robustness to adversarial perturbations to inputs.
While most attacks aim to ensure that these are imperceptible, physical
perturbation attacks typically aim for being unsuspicious, even if perceptible.
However, there is no universal notion of what it means for adversarial examples
to be unsuspicious. We propose an approach for modeling suspiciousness by
leveraging cognitive salience. Specifically, we split an image into foreground
(salient region) and background (the rest), and allow significantly larger
adversarial perturbations in the background, while ensuring that cognitive
salience of background remains low. We describe how to compute the resulting
non-salience-preserving dual-perturbation attacks on classifiers. We then
experimentally demonstrate that our attacks indeed do not significantly change
perceptual salience of the background, but are highly effective against
classifiers robust to conventional attacks. Furthermore, we show that
adversarial training with dual-perturbation attacks yields classifiers that are
more robust to these than state-of-the-art robust learning approaches, and
comparable in terms of robustness to conventional attacks.
</p>
<a href="http://arxiv.org/abs/2005.04272" target="_blank">arXiv:2005.04272</a> [<a href="http://arxiv.org/pdf/2005.04272" target="_blank">pdf</a>]

<h2>Isometric Transformation Invariant and Equivariant Graph Convolutional Networks. (arXiv:2005.06316v2 [cs.LG] UPDATED)</h2>
<h3>Masanobu Horie, Naoki Morita, Toshiaki Hishinuma, Yu Ihara, Naoto Mitsume</h3>
<p>Graphs are one of the most important data structures for representing
pairwise relations between objects. Specifically, a graph embedded in a
Euclidean space is essential to solving real problems, such as object
detection, structural chemistry analyses, and physical simulation. A crucial
requirement to applying a graph in a Euclidean space is learning the isometric
transformation invariant and equivariant features. In the present paper, we
propose a set of transformation invariant and equivariant models based on graph
convolutional networks (GCNs), called IsoGCNs. We demonstrate that the proposed
model outperforms state-of-the-art methods on tasks related with geometrical
and physical data. Moreover, the proposed model can scale up to the graphs with
1M vertices and conduct an inference faster than a conventional finite element
analysis.
</p>
<a href="http://arxiv.org/abs/2005.06316" target="_blank">arXiv:2005.06316</a> [<a href="http://arxiv.org/pdf/2005.06316" target="_blank">pdf</a>]

<h2>Double Double Descent: On Generalization Errors in Transfer Learning between Linear Regression Tasks. (arXiv:2006.07002v2 [cs.LG] UPDATED)</h2>
<h3>Yehuda Dar, Richard G. Baraniuk</h3>
<p>We study the transfer learning process between two linear regression
problems. An important and timely special case is when the regressors are
overparameterized and perfectly interpolate their training data. We examine a
parameter transfer mechanism whereby a subset of the parameters of the target
task solution are constrained to the values learned for a related source task.
We analytically characterize the generalization error of the target task in
terms of the salient factors in the transfer learning architecture, i.e., the
number of examples available, the number of (free) parameters in each of the
tasks, the number of parameters transferred from the source to target task, and
the correlation between the two tasks. Our non-asymptotic analysis shows that
the generalization error of the target task follows a two-dimensional double
descent trend (with respect to the number of free parameters in each of the
tasks) that is controlled by the transfer learning factors. Our analysis points
to specific cases where the transfer of parameters is beneficial.
</p>
<a href="http://arxiv.org/abs/2006.07002" target="_blank">arXiv:2006.07002</a> [<a href="http://arxiv.org/pdf/2006.07002" target="_blank">pdf</a>]

<h2>A quantum extension of SVM-perf for training nonlinear SVMs in almost linear time. (arXiv:2006.10299v2 [quant-ph] UPDATED)</h2>
<h3>Jonathan Allcock, Chang-Yu Hsieh</h3>
<p>We propose a quantum algorithm for training nonlinear support vector machines
(SVM) for feature space learning where classical input data is encoded in the
amplitudes of quantum states. Based on the classical SVM-perf algorithm of
Joachims, our algorithm has a running time which scales linearly in the number
of training examples $m$ (up to polylogarithmic factors) and applies to the
standard soft-margin $\ell_1$-SVM model. In contrast, while classical SVM-perf
has demonstrated impressive performance on both linear and nonlinear SVMs, its
efficiency is guaranteed only in certain cases: it achieves linear $m$ scaling
only for linear SVMs, where classification is performed in the original input
data space, or for the special cases of low-rank or shift-invariant kernels.
Similarly, previously proposed quantum algorithms either have super-linear
scaling in $m$, or else apply to different SVM models such as the hard-margin
or least squares $\ell_2$-SVM which lack certain desirable properties of the
soft-margin $\ell_1$-SVM model. We classically simulate our algorithm and give
evidence that it can perform well in practice, and not only for asymptotically
large data sets.
</p>
<a href="http://arxiv.org/abs/2006.10299" target="_blank">arXiv:2006.10299</a> [<a href="http://arxiv.org/pdf/2006.10299" target="_blank">pdf</a>]

<h2>Model-Free Robust Reinforcement Learning with Linear Function Approximation. (arXiv:2006.11608v3 [cs.LG] UPDATED)</h2>
<h3>Kishan Panaganti, Dileep Kalathil</h3>
<p>This paper addresses the problem of model-free reinforcement learning for
Robust Markov Decision Process (RMDP) with large state spaces. The goal of the
RMDPs framework is to find a policy that is robust against the parameter
uncertainties due to the mismatch between the simulator model and real-world
settings. We first propose Robust Least Squares Policy Evaluation algorithm,
which is a multi-step online model-free learning algorithm for policy
evaluation. We prove the convergence of this algorithm using stochastic
approximation techniques. We then propose Robust Least Squares Policy Iteration
(RLSPI) algorithm for learning the optimal robust policy. We also give a
general weighted Euclidean norm bound on the error (closeness to optimality) of
the resulting policy. Finally, we demonstrate the performance of our RLSPI
algorithm on some benchmark problems from OpenAI Gym.
</p>
<a href="http://arxiv.org/abs/2006.11608" target="_blank">arXiv:2006.11608</a> [<a href="http://arxiv.org/pdf/2006.11608" target="_blank">pdf</a>]

<h2>Calibration of Shared Equilibria in General Sum Partially Observable Markov Games. (arXiv:2006.13085v4 [cs.MA] UPDATED)</h2>
<h3>Nelson Vadori, Sumitra Ganesh, Prashant Reddy, Manuela Veloso</h3>
<p>Training multi-agent systems (MAS) to achieve realistic equilibria gives us a
useful tool to understand and model real-world systems. We consider a general
sum partially observable Markov game where agents of different types share a
single policy network, conditioned on agent-specific information. This paper
aims at i) formally understanding equilibria reached by such agents, and ii)
matching emergent phenomena of such equilibria to real-world targets. Parameter
sharing with decentralized execution has been introduced as an efficient way to
train multiple agents using a single policy network. However, the nature of
resulting equilibria reached by such agents has not been yet studied: we
introduce the novel concept of \textit{Shared equilibrium} as a symmetric pure
Nash equilibrium of a certain Functional Form Game (FFG) and prove convergence
to the latter for a certain class of games using self-play. In addition, it is
important that such equilibria satisfy certain constraints so that MAS are
calibrated to real world data for practical use: we solve this problem by
introducing a novel dual-Reinforcement Learning based approach that fits
emergent behaviors of agents in a Shared equilibrium to externally-specified
targets, and apply our methods to a $n$-player market example. We do so by
calibrating parameters governing distributions of agent types rather than
individual agents, which allows both behavior differentiation among agents and
coherent scaling of the shared policy network to multiple agents.
</p>
<a href="http://arxiv.org/abs/2006.13085" target="_blank">arXiv:2006.13085</a> [<a href="http://arxiv.org/pdf/2006.13085" target="_blank">pdf</a>]

<h2>Quantifying Differences in Reward Functions. (arXiv:2006.13900v2 [cs.LG] UPDATED)</h2>
<h3>Adam Gleave, Michael Dennis, Shane Legg, Stuart Russell, Jan Leike</h3>
<p>For many tasks, the reward function is too complex to be specified
procedurally, and must instead be learned from user data. Prior work has
evaluated learned reward functions by examining rollouts from a policy
optimized for the learned reward. However, this method cannot distinguish
between the learned reward function failing to reflect user preferences, and
the reinforcement learning algorithm failing to optimize the learned reward.
Moreover, the rollout method is highly sensitive to details of the environment
the learned reward is evaluated in, which often differ in the deployment
environment. To address these problems, we introduce the Equivalent-Policy
Invariant Comparison (EPIC) distance to quantify the difference between two
reward functions directly, without training a policy. We prove EPIC is
invariant on an equivalence class of reward functions that always induce the
same optimal policy. Furthermore, we find EPIC can be precisely approximated
and is more robust than baselines to the choice of visitation distribution.
Finally, we show that EPIC distance bounds the regret of optimal policies even
under different transition dynamics, and confirm empirically that it predicts
policy training success. Our source code is available at
https://github.com/HumanCompatibleAI/evaluating-rewards.
</p>
<a href="http://arxiv.org/abs/2006.13900" target="_blank">arXiv:2006.13900</a> [<a href="http://arxiv.org/pdf/2006.13900" target="_blank">pdf</a>]

<h2>Prior-guided Bayesian Optimization. (arXiv:2006.14608v2 [cs.LG] UPDATED)</h2>
<h3>Artur Souza, Luigi Nardi, Leonardo B. Oliveira, Kunle Olukotun, Marius Lindauer, Frank Hutter</h3>
<p>While Bayesian Optimization (BO) is a very popular method for optimizing
expensive black-box functions, it fails to leverage the experience of domain
experts. This causes BO to waste function evaluations on bad design choices
(e.g., machine learning hyperparameters) that the expert already knows to work
poorly. To address this issue, we introduce Prior-guided Bayesian Optimization
(PrBO). PrBO allows users to inject their knowledge into the optimization
process in the form of priors about which parts of the input space will yield
the best performance, rather than BO's standard priors over functions (which
are much less intuitive for users). PrBO then combines these priors with BO's
standard probabilistic model to form a pseudo-posterior used to select which
points to evaluate next. We show that PrBO is around 12x faster than
state-of-the-art methods without user priors and 10,000x faster than random
search on a common suite of benchmarks, and achieves a new state-of-the-art
performance on a real-world hardware design application. We also show that PrBO
converges faster even if the user priors are not entirely accurate and that it
robustly recovers from misleading priors.
</p>
<a href="http://arxiv.org/abs/2006.14608" target="_blank">arXiv:2006.14608</a> [<a href="http://arxiv.org/pdf/2006.14608" target="_blank">pdf</a>]

<h2>Deep Bayesian Quadrature Policy Optimization. (arXiv:2006.15637v2 [cs.LG] UPDATED)</h2>
<h3>Akella Ravi Tej, Kamyar Azizzadenesheli, Mohammad Ghavamzadeh, Anima Anandkumar, Yisong Yue</h3>
<p>We study the problem of obtaining accurate policy gradient estimates using a
finite number of samples. Monte-Carlo methods have been the default choice for
policy gradient estimation, despite suffering from high variance in the
gradient estimates. On the other hand, more sample efficient alternatives like
Bayesian quadrature methods are less scalable due to their high computational
complexity. In this work, we propose deep Bayesian quadrature policy gradient
(DBQPG), a computationally efficient high-dimensional generalization of
Bayesian quadrature, for policy gradient estimation. We show that DBQPG can
substitute Monte-Carlo estimation in policy gradient methods, and demonstrate
its effectiveness on a set of continuous control benchmarks. In comparison to
Monte-Carlo estimation, DBQPG provides (i) more accurate gradient estimates
with a significantly lower variance, (ii) a consistent improvement in the
sample complexity and average return for several deep policy gradient
algorithms, and, (iii) the uncertainty in gradient estimation that can be
incorporated to further improve the performance.
</p>
<a href="http://arxiv.org/abs/2006.15637" target="_blank">arXiv:2006.15637</a> [<a href="http://arxiv.org/pdf/2006.15637" target="_blank">pdf</a>]

<h2>In the Wild: From ML Models to Pragmatic ML Systems. (arXiv:2007.02519v2 [cs.CV] UPDATED)</h2>
<h3>Matthew Wallingford, Aditya Kusupati, Keivan Alizadeh-Vahid, Aaron Walsman, Aniruddha Kembhavi, Ali Farhadi</h3>
<p>Enabling robust intelligence in the wild entails learning systems that offer
uninterrupted inference while affording sustained learning from varying amounts
of data and supervision. The machine learning community has organically broken
down this challenging task into manageable sub tasks such as supervised,
few-shot, continual, and self-supervised learning; each affording distinct
challenges and a unique set of methods. Notwithstanding this remarkable
progress, the simplified and isolated nature of these experimental setups has
resulted in methods that excel in their specific settings, but struggle to
generalize beyond them. To foster research towards more general ML systems, we
present a new learning and evaluation framework - In The Wild (NED). NED
naturally integrates the objectives of previous frameworks while removing many
of the overly strong assumptions such as predefined training and test phases,
sufficient amounts of labeled data for every class, and the closed-world
assumption. In NED, a learner faces a stream of data and must make sequential
predictions while choosing how to update itself, adapt quickly to novel
classes, and deal with changing data distributions; while optimizing for the
total amount of compute. We present novel insights from NED that contradict the
findings of less realistic or smaller-scale experiments which emphasizes the
need to move towards more pragmatic setups. For example, we show that
meta-training causes larger networks to overfit in a way that supervised
training does not, few-shot methods break down outside of their narrow
experimental setting, and self-supervised method MoCo performs significantly
worse when the downstream task contains new and old classes. Additionally, we
present two new methods (Exemplar Tuning and Minimum Distance Thresholding)
that significantly outperform all other methods evaluated in NED.
</p>
<a href="http://arxiv.org/abs/2007.02519" target="_blank">arXiv:2007.02519</a> [<a href="http://arxiv.org/pdf/2007.02519" target="_blank">pdf</a>]

<h2>Novel-View Human Action Synthesis. (arXiv:2007.02808v3 [cs.CV] UPDATED)</h2>
<h3>Mohamed Ilyes Lakhal, Davide Boscaini, Fabio Poiesi, Oswald Lanz, Andrea Cavallaro</h3>
<p>Novel-View Human Action Synthesis aims to synthesize the movement of a body
from a virtual viewpoint, given a video from a real viewpoint. We present a
novel 3D reasoning to synthesize the target viewpoint. We first estimate the 3D
mesh of the target body and transfer the rough textures from the 2D images to
the mesh. As this transfer may generate sparse textures on the mesh due to
frame resolution or occlusions. We produce a semi-dense textured mesh by
propagating the transferred textures both locally, within local geodesic
neighborhoods, and globally, across symmetric semantic parts. Next, we
introduce a context-based generator to learn how to correct and complete the
residual appearance information. This allows the network to independently focus
on learning the foreground and background synthesis tasks. We validate the
proposed solution on the public NTU RGB+D dataset. The code and resources are
available at https://bit.ly/36u3h4K.
</p>
<a href="http://arxiv.org/abs/2007.02808" target="_blank">arXiv:2007.02808</a> [<a href="http://arxiv.org/pdf/2007.02808" target="_blank">pdf</a>]

<h2>Failure Modes of Variational Autoencoders and Their Effects on Downstream Tasks. (arXiv:2007.07124v2 [stat.ML] UPDATED)</h2>
<h3>Yaniv Yacoby, Weiwei Pan, Finale Doshi-Velez</h3>
<p>Variational Auto-encoders (VAEs) are deep generative latent variable models
that are widely used for a number of downstream tasks. While it has been
demonstrated that VAE training can suffer from a number of pathologies,
existing literature lacks characterizations of exactly when these pathologies
occur and how they impact down-stream task performance. In this paper we
concretely characterize conditions under which VAE training exhibits
pathologies and connect these failure modes to undesirable effects on specific
downstream tasks, such as learning compressed and disentangled representations,
adversarial robustness and semi-supervised learning.
</p>
<a href="http://arxiv.org/abs/2007.07124" target="_blank">arXiv:2007.07124</a> [<a href="http://arxiv.org/pdf/2007.07124" target="_blank">pdf</a>]

<h2>FetchSGD: Communication-Efficient Federated Learning with Sketching. (arXiv:2007.07682v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Rothchild, Ashwinee Panda, Enayat Ullah, Nikita Ivkin, Ion Stoica, Vladimir Braverman, Joseph Gonzalez, Raman Arora</h3>
<p>Existing approaches to federated learning suffer from a communication
bottleneck as well as convergence issues due to sparse client participation. In
this paper we introduce a novel algorithm, called FetchSGD, to overcome these
challenges. FetchSGD compresses model updates using a Count Sketch, and then
takes advantage of the mergeability of sketches to combine model updates from
many workers. A key insight in the design of FetchSGD is that, because the
Count Sketch is linear, momentum and error accumulation can both be carried out
within the sketch. This allows the algorithm to move momentum and error
accumulation from clients to the central aggregator, overcoming the challenges
of sparse client participation while still achieving high compression rates and
good convergence. We prove that FetchSGD has favorable convergence guarantees,
and we demonstrate its empirical effectiveness by training two residual
networks and a transformer model.
</p>
<a href="http://arxiv.org/abs/2007.07682" target="_blank">arXiv:2007.07682</a> [<a href="http://arxiv.org/pdf/2007.07682" target="_blank">pdf</a>]

<h2>Learning perturbation sets for robust machine learning. (arXiv:2007.08450v2 [cs.LG] UPDATED)</h2>
<h3>Eric Wong, J. Zico Kolter</h3>
<p>Although much progress has been made towards robust deep learning, a
significant gap in robustness remains between real-world perturbations and more
narrowly defined sets typically studied in adversarial defenses. In this paper,
we aim to bridge this gap by learning perturbation sets from data, in order to
characterize real-world effects for robust training and evaluation.
Specifically, we use a conditional generator that defines the perturbation set
over a constrained region of the latent space. We formulate desirable
properties that measure the quality of a learned perturbation set, and
theoretically prove that a conditional variational autoencoder naturally
satisfies these criteria. Using this framework, our approach can generate a
variety of perturbations at different complexities and scales, ranging from
baseline spatial transformations, through common image corruptions, to lighting
variations. We measure the quality of our learned perturbation sets both
quantitatively and qualitatively, finding that our models are capable of
producing a diverse set of meaningful perturbations beyond the limited data
seen during training. Finally, we leverage our learned perturbation sets to
train models which are empirically and certifiably robust to adversarial image
corruptions and adversarial lighting variations, while improving generalization
on non-adversarial data. All code and configuration files for reproducing the
experiments as well as pretrained model weights can be found at
https://github.com/locuslab/perturbation_learning.
</p>
<a href="http://arxiv.org/abs/2007.08450" target="_blank">arXiv:2007.08450</a> [<a href="http://arxiv.org/pdf/2007.08450" target="_blank">pdf</a>]

<h2>Active MR k-space Sampling with Reinforcement Learning. (arXiv:2007.10469v2 [eess.IV] UPDATED)</h2>
<h3>Luis Pineda, Sumana Basu, Adriana Romero, Roberto Calandra, Michal Drozdzal</h3>
<p>Deep learning approaches have recently shown great promise in accelerating
magnetic resonance image (MRI) acquisition. The majority of existing work have
focused on designing better reconstruction models given a pre-determined
acquisition trajectory, ignoring the question of trajectory optimization. In
this paper, we focus on learning acquisition trajectories given a fixed image
reconstruction model. We formulate the problem as a sequential decision process
and propose the use of reinforcement learning to solve it. Experiments on a
large scale public MRI dataset of knees show that our proposed models
significantly outperform the state-of-the-art in active MRI acquisition, over a
large range of acceleration factors.
</p>
<a href="http://arxiv.org/abs/2007.10469" target="_blank">arXiv:2007.10469</a> [<a href="http://arxiv.org/pdf/2007.10469" target="_blank">pdf</a>]

<h2>Online Spatio-Temporal Learning in Deep Neural Networks. (arXiv:2007.12723v2 [cs.LG] UPDATED)</h2>
<h3>Thomas Bohnstingl, Stanis&#x142;aw Wo&#x17a;niak, Wolfgang Maass, Angeliki Pantazi, Evangelos Eleftheriou</h3>
<p>Biological neural networks are equipped with an inherent capability to
continuously adapt through online learning. This aspect remains in stark
contrast to learning with error backpropagation through time (BPTT) applied to
recurrent neural networks (RNNs), or recently to biologically-inspired spiking
neural networks (SNNs). BPTT involves offline computation of the gradients due
to the requirement to unroll the network through time. Online learning has
recently regained the attention of the research community, focusing either on
approaches that approximate BPTT or on biologically-plausible schemes applied
to SNNs. Here we present an alternative perspective that is based on a clear
separation of spatial and temporal gradient components. Combined with insights
from biology, we derive from first principles a novel online learning algorithm
for deep SNNs, called online spatio-temporal learning (OSTL). For shallow
networks, OSTL is gradient-equivalent to BPTT enabling for the first time
online training of SNNs with BPTT-equivalent gradients. In addition, the
proposed formulation unveils a class of SNN architectures trainable online at
low time complexity. Moreover, we extend OSTL to a generic form, applicable to
a wide range of network architectures, including networks comprising long
short-term memory (LSTM) and gated recurrent units (GRU). We demonstrate the
operation of our algorithm on various tasks from language modelling to speech
recognition and obtain results on par with the BPTT baselines. The proposed
algorithm provides a framework for developing succinct and efficient online
training approaches for SNNs and in general deep RNNs.
</p>
<a href="http://arxiv.org/abs/2007.12723" target="_blank">arXiv:2007.12723</a> [<a href="http://arxiv.org/pdf/2007.12723" target="_blank">pdf</a>]

<h2>Enhance CNN Robustness Against Noises for Classification of 12-Lead ECG with Variable Length. (arXiv:2008.03609v3 [eess.SP] UPDATED)</h2>
<h3>Linhai Ma, Liang Liang</h3>
<p>Electrocardiogram (ECG) is the most widely used diagnostic tool to monitor
the condition of the cardiovascular system. Deep neural networks (DNNs), have
been developed in many research labs for automatic interpretation of ECG
signals to identify potential abnormalities in patient hearts. Studies have
shown that given a sufficiently large amount of data, the classification
accuracy of DNNs could reach human-expert cardiologist level. However, despite
of the excellent performance in classification accuracy, it has been shown that
DNNs are highly vulnerable to adversarial noises which are subtle changes in
input of a DNN and lead to a wrong class-label prediction with a high
confidence. Thus, it is challenging and essential to improve robustness of DNNs
against adversarial noises for ECG signal classification, a life-critical
application. In this work, we designed a CNN for classification of 12-lead ECG
signals with variable length, and we applied three defense methods to improve
robustness of this CNN for this classification task. The ECG data in this study
is very challenging because the sample size is limited, and the length of each
ECG recording varies in a large range. The evaluation results show that our
customized CNN reached satisfying F1 score and average accuracy, comparable to
the top-6 entries in the CPSC2018 ECG classification challenge, and the defense
methods enhanced robustness of our CNN against adversarial noises and white
noises, with a minimal reduction in accuracy on clean data.
</p>
<a href="http://arxiv.org/abs/2008.03609" target="_blank">arXiv:2008.03609</a> [<a href="http://arxiv.org/pdf/2008.03609" target="_blank">pdf</a>]

<h2>AIPerf: Automated machine learning as an AI-HPC benchmark. (arXiv:2008.07141v4 [cs.DC] UPDATED)</h2>
<h3>Zhixiang Ren, Yongheng Liu, Tianhui Shi, Lei Xie, Yue Zhou, Jidong Zhai, Youhui Zhang, Yunquan Zhang, Wenguang Chen</h3>
<p>The plethora of complex artificial intelligence (AI) algorithms and available
high performance computing (HPC) power stimulates the expeditious development
of AI components in both hardware and software domains. Existing HPC and AI
benchmarks fail to cover the variety of heterogeneous systems while providing a
simple yet comprehensive measurement of the cross-stack performance. To address
the challenges, we propose an end-to-end benchmark suite utilizing automated
machine learning (AutoML) as a representative AI application. The extreme
computational cost and scalability make AutoML a desired workload for
benchmarking AI-HPC. We implement the algorithms in a highly parallel and
flexible way to ensure the efficiency and customizability on diverse systems.
The major metric to quantify the system performance is floating-point
operations per second (FLOPS), which is measured in a systematic and analytical
approach. We verify the benchmark's stability at discrete timestamps on
different types and scales of machines equipped with up to 400 AI accelerators.
Our evaluation show the benchmark scores scale linearly with the number of
machines and reflect the overall computing power on AI. The source code,
specifications and detailed procedures are publicly accessible on GitHub.
</p>
<a href="http://arxiv.org/abs/2008.07141" target="_blank">arXiv:2008.07141</a> [<a href="http://arxiv.org/pdf/2008.07141" target="_blank">pdf</a>]

<h2>Learning Complex Multi-Agent Policies in Presence of an Adversary. (arXiv:2008.07698v2 [cs.MA] UPDATED)</h2>
<h3>Siddharth Ghiya, Katia Sycara</h3>
<p>In recent years, there has been some outstanding work on applying deep
reinforcement learning to multi-agent settings. Often in such multi-agent
scenarios, adversaries can be present. We address the requirements of such a
setting by implementing a graph-based multi-agent deep reinforcement learning
algorithm. In this work, we consider the scenario of multi-agent deception in
which multiple agents need to learn to cooperate and communicate in order to
deceive an adversary. We have employed a two-stage learning process to get the
cooperating agents to learn such deceptive behaviors. Our experiments show that
our approach allows us to employ curriculum learning to increase the number of
cooperating agents in the environment and enables a team of agents to learn
complex behaviors to successfully deceive an adversary.

Keywords: Multi-agent system, Graph neural network, Reinforcement learning
</p>
<a href="http://arxiv.org/abs/2008.07698" target="_blank">arXiv:2008.07698</a> [<a href="http://arxiv.org/pdf/2008.07698" target="_blank">pdf</a>]

<h2>FANG: Leveraging Social Context for Fake News Detection Using Graph Representation. (arXiv:2008.07939v2 [cs.SI] UPDATED)</h2>
<h3>Van-Hoang Nguyen, Kazunari Sugiyama, Preslav Nakov, Min-Yen Kan</h3>
<p>We propose Factual News Graph (FANG), a novel graphical social context
representation and learning framework for fake news detection. Unlike previous
contextual models that have targeted performance, our focus is on
representation learning. Compared to transductive models, FANG is scalable in
training as it does not have to maintain all nodes, and it is efficient at
inference time, without the need to re-process the entire graph. Our
experimental results show that FANG is better at capturing the social context
into a high fidelity representation, compared to recent graphical and
non-graphical models. In particular, FANG yields significant improvements for
the task of fake news detection, and it is robust in the case of limited
training data. We further demonstrate that the representations learned by FANG
generalize to related tasks, such as predicting the factuality of reporting of
a news medium.
</p>
<a href="http://arxiv.org/abs/2008.07939" target="_blank">arXiv:2008.07939</a> [<a href="http://arxiv.org/pdf/2008.07939" target="_blank">pdf</a>]

<h2>Creation and Validation of a Chest X-Ray Dataset with Eye-tracking and Report Dictation for AI Development. (arXiv:2009.07386v3 [cs.CV] UPDATED)</h2>
<h3>Alexandros Karargyris, Satyananda Kashyap, Ismini Lourentzou, Joy Wu, Arjun Sharma, Matthew Tong, Shafiq Abedin, David Beymer, Vandana Mukherjee, Elizabeth A Krupinski, Mehdi Moradi</h3>
<p>We developed a rich dataset of Chest X-Ray (CXR) images to assist
investigators in artificial intelligence. The data were collected using an eye
tracking system while a radiologist reviewed and reported on 1,083 CXR images.
The dataset contains the following aligned data: CXR image, transcribed
radiology report text, radiologist's dictation audio and eye gaze coordinates
data. We hope this dataset can contribute to various areas of research
particularly towards explainable and multimodal deep learning / machine
learning methods. Furthermore, investigators in disease classification and
localization, automated radiology report generation, and human-machine
interaction can benefit from these data. We report deep learning experiments
that utilize the attention maps produced by eye gaze dataset to show the
potential utility of this data.
</p>
<a href="http://arxiv.org/abs/2009.07386" target="_blank">arXiv:2009.07386</a> [<a href="http://arxiv.org/pdf/2009.07386" target="_blank">pdf</a>]

<h2>Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes' Rule. (arXiv:2009.07783v3 [cs.CL] UPDATED)</h2>
<h3>Shuhei Kurita, Kyunghyun Cho</h3>
<p>Vision-and-language navigation (VLN) is a task in which an agent is embodied
in a realistic 3D environment and follows an instruction to reach the goal
node. While most of the previous studies have built and investigated a
discriminative approach, we notice that there are in fact two possible
approaches to building such a VLN agent: discriminative \textit{and}
generative. In this paper, we design and investigate a generative
language-grounded policy which uses a language model to compute the
distribution over all possible instructions i.e. all possible sequences of
vocabulary tokens given action and the transition history. In experiments, we
show that the proposed generative approach outperforms the discriminative
approach in the Room-2-Room (R2R) and Room-4-Room (R4R) datasets, especially in
the unseen environments. We further show that the combination of the generative
and discriminative policies achieves close to the state-of-the art results in
the R2R dataset, demonstrating that the generative and discriminative policies
capture the different aspects of VLN.
</p>
<a href="http://arxiv.org/abs/2009.07783" target="_blank">arXiv:2009.07783</a> [<a href="http://arxiv.org/pdf/2009.07783" target="_blank">pdf</a>]

<h2>Sub-graph Contrast for Scalable Self-Supervised Graph Representation Learning. (arXiv:2009.10273v2 [cs.LG] UPDATED)</h2>
<h3>Yizhu Jiao, Yun Xiong, Jiawei Zhang, Yao Zhang, Tianqi Zhang, Yangyong Zhu</h3>
<p>Graph representation learning has attracted lots of attention recently.
Existing graph neural networks fed with the complete graph data are not
scalable due to limited computation and memory costs. Thus, it remains a great
challenge to capture rich information in large-scale graph data. Besides, these
methods mainly focus on supervised learning and highly depend on node label
information, which is expensive to obtain in the real world. As to unsupervised
network embedding approaches, they overemphasize node proximity instead, whose
learned representations can hardly be used in downstream application tasks
directly. In recent years, emerging self-supervised learning provides a
potential solution to address the aforementioned problems. However, existing
self-supervised works also operate on the complete graph data and are biased to
fit either global or very local (1-hop neighborhood) graph structures in
defining the mutual information based loss terms.

In this paper, a novel self-supervised representation learning method via
Subgraph Contrast, namely \textsc{Subg-Con}, is proposed by utilizing the
strong correlation between central nodes and their sampled subgraphs to capture
regional structure information. Instead of learning on the complete input graph
data, with a novel data augmentation strategy, \textsc{Subg-Con} learns node
representations through a contrastive loss defined based on subgraphs sampled
from the original graph instead. Compared with existing graph representation
learning approaches, \textsc{Subg-Con} has prominent performance advantages in
weaker supervision requirements, model learning scalability, and
parallelization. Extensive experiments verify both the effectiveness and the
efficiency of our work compared with both classic and state-of-the-art graph
representation learning approaches on multiple real-world large-scale benchmark
datasets from different domains.
</p>
<a href="http://arxiv.org/abs/2009.10273" target="_blank">arXiv:2009.10273</a> [<a href="http://arxiv.org/pdf/2009.10273" target="_blank">pdf</a>]

<h2>Ethical Machine Learning in Health Care. (arXiv:2009.10576v3 [cs.CY] UPDATED)</h2>
<h3>Irene Y. Chen, Emma Pierson, Sherri Rose, Shalmali Joshi, Kadija Ferryman, Marzyeh Ghassemi</h3>
<p>The use of machine learning (ML) in health care raises numerous ethical
concerns, especially as models can amplify existing health inequities. Here, we
outline ethical considerations for equitable ML in the advancement of health
care. Specifically, we frame ethics of ML in health care through the lens of
social justice. We describe ongoing efforts and outline challenges in a
proposed pipeline of ethical ML in health, ranging from problem selection to
post-deployment considerations. We close by summarizing recommendations to
address these challenges.
</p>
<a href="http://arxiv.org/abs/2009.10576" target="_blank">arXiv:2009.10576</a> [<a href="http://arxiv.org/pdf/2009.10576" target="_blank">pdf</a>]

<h2>On the Ability and Limitations of Transformers to Recognize Formal Languages. (arXiv:2009.11264v2 [cs.CL] UPDATED)</h2>
<h3>Satwik Bhattamishra, Kabir Ahuja, Navin Goyal</h3>
<p>Transformers have supplanted recurrent models in a large number of NLP tasks.
However, the differences in their abilities to model different syntactic
properties remain largely unknown. Past works suggest that LSTMs generalize
very well on regular languages and have close connections with counter
languages. In this work, we systematically study the ability of Transformers to
model such languages as well as the role of its individual components in doing
so. We first provide a construction of Transformers for a subclass of counter
languages, including well-studied languages such as n-ary Boolean Expressions,
Dyck-1, and its generalizations. In experiments, we find that Transformers do
well on this subclass, and their learned mechanism strongly correlates with our
construction. Perhaps surprisingly, in contrast to LSTMs, Transformers do well
only on a subset of regular languages with degrading performance as we make
languages more complex according to a well-known measure of complexity. Our
analysis also provides insights on the role of self-attention mechanism in
modeling certain behaviors and the influence of positional encoding schemes on
the learning and generalization abilities of the model.
</p>
<a href="http://arxiv.org/abs/2009.11264" target="_blank">arXiv:2009.11264</a> [<a href="http://arxiv.org/pdf/2009.11264" target="_blank">pdf</a>]

<h2>Towards Debiasing NLU Models from Unknown Biases. (arXiv:2009.12303v2 [cs.CL] UPDATED)</h2>
<h3>Prasetya Ajie Utama, Nafise Sadat Moosavi, Iryna Gurevych</h3>
<p>NLU models often exploit biases to achieve high dataset-specific performance
without properly learning the intended task. Recently proposed debiasing
methods are shown to be effective in mitigating this tendency. However, these
methods rely on a major assumption that the types of bias should be
\emph{known} a-priori, which limits their application to many NLU tasks and
datasets. In this work, we present the first step to bridge this gap by
introducing a self-debiasing framework that prevents models from mainly
utilizing biases without knowing them in advance. The proposed framework is
general and complementary to the existing debiasing methods. We show that it
allows these existing methods to retain the improvement on the challenge
datasets (i.e., sets of examples designed to expose models' reliance on biases)
without specifically targeting certain biases. Furthermore, the evaluation
suggests that applying the framework results in improved overall robustness.
</p>
<a href="http://arxiv.org/abs/2009.12303" target="_blank">arXiv:2009.12303</a> [<a href="http://arxiv.org/pdf/2009.12303" target="_blank">pdf</a>]

<h2>Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX). (arXiv:2010.02013v2 [cs.SE] UPDATED)</h2>
<h3>Konstantinos (Gus) Katsiapis, Abhijit Karmarkar, Ahmet Altay, Aleksandr Zaks, Neoklis Polyzotis, Anusha Ramesh, Ben Mathes, Gautam Vasudevan, Irene Giannoumis, Jarek Wilkiewicz, Jiri Simsa, Justin Hong, Mitch Trott, No&#xe9; Lutz, Pavel A. Dournov, Robert Crowe, Sarah Sirajuddin, Tris Brian Warkentin, Zhitao Li</h3>
<p>Software Engineering, as a discipline, has matured over the past 5+ decades.
The modern world heavily depends on it, so the increased maturity of Software
Engineering was an eventuality. Practices like testing and reliable
technologies help make Software Engineering reliable enough to build industries
upon. Meanwhile, Machine Learning (ML) has also grown over the past 2+ decades.
ML is used more and more for research, experimentation and production
workloads. ML now commonly powers widely-used products integral to our lives.
But ML Engineering, as a discipline, has not widely matured as much as its
Software Engineering ancestor. Can we take what we have learned and help the
nascent field of applied ML evolve into ML Engineering the way Programming
evolved into Software Engineering [1]? In this article we will give a whirlwind
tour of Sibyl [2] and TensorFlow Extended (TFX) [3], two successive end-to-end
(E2E) ML platforms at Alphabet. We will share the lessons learned from over a
decade of applied ML built on these platforms, explain both their similarities
and their differences, and expand on the shifts (both mental and technical)
that helped us on our journey. In addition, we will highlight some of the
capabilities of TFX that help realize several aspects of ML Engineering. We
argue that in order to unlock the gains ML can bring, organizations should
advance the maturity of their ML teams by investing in robust ML infrastructure
and promoting ML Engineering education. We also recommend that before focusing
on cutting-edge ML modeling techniques, product leaders should invest more time
in adopting interoperable ML platforms for their organizations. In closing, we
will also share a glimpse into the future of TFX.
</p>
<a href="http://arxiv.org/abs/2010.02013" target="_blank">arXiv:2010.02013</a> [<a href="http://arxiv.org/pdf/2010.02013" target="_blank">pdf</a>]

<h2>Downscaling Attack and Defense: Turning What You See Back Into What You Get. (arXiv:2010.02456v2 [cs.CR] UPDATED)</h2>
<h3>Andrew J. Lohn</h3>
<p>The resizing of images, which is typically a required part of preprocessing
for computer vision systems, is vulnerable to attack. Images can be created
such that the image is completely different at machine-vision scales than at
other scales and the default settings for some common computer vision and
machine learning systems are vulnerable. We show that defenses exist and are
trivial to administer provided that defenders are aware of the threat. These
attacks and defenses help to establish the role of input sanitization in
machine learning.
</p>
<a href="http://arxiv.org/abs/2010.02456" target="_blank">arXiv:2010.02456</a> [<a href="http://arxiv.org/pdf/2010.02456" target="_blank">pdf</a>]

<h2>A Transformer-based Framework for Multivariate Time Series Representation Learning. (arXiv:2010.02803v2 [cs.LG] UPDATED)</h2>
<h3>George Zerveas, Srideepika Jayaraman, Dhaval Patel, Anuradha Bhamidipaty, Carsten Eickhoff</h3>
<p>In this work we propose for the first time a transformer-based framework for
unsupervised representation learning of multivariate time series. Pre-trained
models can be potentially used for downstream tasks such as regression and
classification, forecasting and missing value imputation. By evaluating our
models on several benchmark datasets for multivariate time series regression
and classification, we show that not only does our modeling approach represent
the most successful method employing unsupervised learning of multivariate time
series presented to date, but also that it exceeds the current state-of-the-art
performance of supervised methods; it does so even when the number of training
samples is very limited, while offering computational efficiency. Finally, we
demonstrate that unsupervised pre-training of our transformer models offers a
substantial performance benefit over fully supervised learning, even without
leveraging additional unlabeled data, i.e., by reusing the same data samples
through the unsupervised objective.
</p>
<a href="http://arxiv.org/abs/2010.02803" target="_blank">arXiv:2010.02803</a> [<a href="http://arxiv.org/pdf/2010.02803" target="_blank">pdf</a>]

<h2>Reinforcement Learning with Random Delays. (arXiv:2010.02966v2 [cs.LG] UPDATED)</h2>
<h3>Simon Ramstedt, Yann Bouteiller, Giovanni Beltrame, Christopher Pal, Jonathan Binas</h3>
<p>Action and observation delays commonly occur in many Reinforcement Learning
applications, such as remote control scenarios. We study the anatomy of
randomly delayed environments, and show that partially resampling trajectory
fragments in hindsight allows for off-policy multi-step value estimation. We
apply this principle to derive Delay-Correcting Actor-Critic (DCAC), an
algorithm based on Soft Actor-Critic with significantly better performance in
environments with delays. This is shown theoretically and also demonstrated
practically on a delay-augmented version of the MuJoCo continuous control
benchmark.
</p>
<a href="http://arxiv.org/abs/2010.02966" target="_blank">arXiv:2010.02966</a> [<a href="http://arxiv.org/pdf/2010.02966" target="_blank">pdf</a>]

<h2>BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models. (arXiv:2010.03007v2 [cs.CR] UPDATED)</h2>
<h3>Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang Zhang</h3>
<p>The tremendous progress of autoencoders and generative adversarial networks
(GANs) has led to their application to multiple critical tasks, such as fraud
detection and sanitized data generation. This increasing adoption has fostered
the study of security and privacy risks stemming from these models. However,
previous works have mainly focused on membership inference attacks. In this
work, we explore one of the most severe attacks against machine learning
models, namely the backdoor attack, against both autoencoders and GANs. The
backdoor attack is a training time attack where the adversary implements a
hidden backdoor in the target model that can only be activated by a secret
trigger. State-of-the-art backdoor attacks focus on classification-based tasks.
We extend the applicability of backdoor attacks to autoencoders and GAN-based
models. More concretely, we propose the first backdoor attack against
autoencoders and GANs where the adversary can control what the decoded or
generated images are when the backdoor is activated. Our results show that the
adversary can build a backdoored autoencoder that returns a target output for
all backdoored inputs, while behaving perfectly normal on clean inputs.
Similarly, for the GANs, our experiments show that the adversary can generate
data from a different distribution when the backdoor is activated, while
maintaining the same utility when the backdoor is not.
</p>
<a href="http://arxiv.org/abs/2010.03007" target="_blank">arXiv:2010.03007</a> [<a href="http://arxiv.org/pdf/2010.03007" target="_blank">pdf</a>]

<h2>Knowledge-enriched, Type-constrained and Grammar-guided Question Generation over Knowledge Bases. (arXiv:2010.03157v2 [cs.CL] UPDATED)</h2>
<h3>Sheng Bi, Xiya Cheng, Yuan-Fang Li, Yongzhen Wang, Guilin Qi</h3>
<p>Question generation over knowledge bases (KBQG) aims at generating
natural-language questions about a subgraph, i.e. a set of (connected) triples.
Two main challenges still face the current crop of encoder-decoder-based
methods, especially on small subgraphs: (1) low diversity and poor fluency due
to the limited information contained in the subgraphs, and (2) semantic drift
due to the decoder's oblivion of the semantics of the answer entity. We propose
an innovative knowledge-enriched, type-constrained and grammar-guided KBQG
model, named KTG, to addresses the above challenges. In our model, the encoder
is equipped with auxiliary information from the KB, and the decoder is
constrained with word types during QG. Specifically, entity domain and
description, as well as relation hierarchy information are considered to
construct question contexts, while a conditional copy mechanism is incorporated
to modulate question semantics according to current word types. Besides, a
novel reward function featuring grammatical similarity is designed to improve
both generative richness and syntactic correctness via reinforcement learning.
Extensive experiments show that our proposed model outperforms existing methods
by a significant margin on two widely-used benchmark datasets SimpleQuestion
and PathQuestion.
</p>
<a href="http://arxiv.org/abs/2010.03157" target="_blank">arXiv:2010.03157</a> [<a href="http://arxiv.org/pdf/2010.03157" target="_blank">pdf</a>]

<h2>Multilingual Knowledge Graph Completion via Ensemble Knowledge Transfer. (arXiv:2010.03158v2 [cs.CL] UPDATED)</h2>
<h3>Xuelu Chen, Muhao Chen, Changjun Fan, Ankith Uppunda, Yizhou Sun, Carlo Zaniolo</h3>
<p>Predicting missing facts in a knowledge graph (KG) is a crucial task in
knowledge base construction and reasoning, and it has been the subject of much
research in recent works using KG embeddings. While existing KG embedding
approaches mainly learn and predict facts within a single KG, a more plausible
solution would benefit from the knowledge in multiple language-specific KGs,
considering that different KGs have their own strengths and limitations on data
quality and coverage. This is quite challenging, since the transfer of
knowledge among multiple independently maintained KGs is often hindered by the
insufficiency of alignment information and the inconsistency of described
facts. In this paper, we propose KEnS, a novel framework for embedding learning
and ensemble knowledge transfer across a number of language-specific KGs. KEnS
embeds all KGs in a shared embedding space, where the association of entities
is captured based on self-learning. Then, KEnS performs ensemble inference to
combine prediction results from embeddings of multiple language-specific KGs,
for which multiple ensemble techniques are investigated. Experiments on five
real-world language-specific KGs show that KEnS consistently improves
state-of-the-art methods on KG completion, via effectively identifying and
leveraging complementary knowledge.
</p>
<a href="http://arxiv.org/abs/2010.03158" target="_blank">arXiv:2010.03158</a> [<a href="http://arxiv.org/pdf/2010.03158" target="_blank">pdf</a>]

<h2>Rotation-Invariant Local-to-Global Representation Learning for 3D Point Cloud. (arXiv:2010.03318v2 [cs.CV] UPDATED)</h2>
<h3>Seohyun Kim, Jaeyoo Park, Bohyung Han</h3>
<p>We propose a local-to-global representation learning algorithm for 3D point
cloud data, which is appropriate to handle various geometric transformations,
especially rotation, without explicit data augmentation with respect to the
transformations. Our model takes advantage of multi-level abstraction based on
graph convolutional neural networks, which constructs a descriptor hierarchy to
encode rotation-invariant shape information of an input object in a bottom-up
manner. The descriptors in each level are obtained from neural networks based
on graphs via stochastic sampling of 3D points, which is effective to make the
learned representations robust to the variations of input data. The proposed
algorithm presents the state-of-the-art performance on the rotation-augmented
3D object recognition benchmarks and we further analyze its characteristics
through comprehensive ablative experiments.
</p>
<a href="http://arxiv.org/abs/2010.03318" target="_blank">arXiv:2010.03318</a> [<a href="http://arxiv.org/pdf/2010.03318" target="_blank">pdf</a>]

<h2>DYSAN: Dynamically sanitizing motion sensor data against sensitive inferences through adversarial networks. (arXiv:2003.10325v2 [cs.CR] CROSS LISTED)</h2>
<h3>Claude Rosin Ngueveu (UQAM), Antoine Boutet (PRIVATICS), Carole Frindel (CREATIS), S&#xe9;bastien Gambs (UQAM), Th&#xe9;o Jourdan (CREATIS, PRIVATICS), Claude Rosin</h3>
<p>With the widespread adoption of the quantified self movement, an increasing
number of users rely on mobile applications to monitor their physical activity
through their smartphones. Granting to applications a direct access to sensor
data expose users to privacy risks. Indeed, usually these motion sensor data
are transmitted to analytics applications hosted on the cloud leveraging
machine learning models to provide feedback on their health to users. However,
nothing prevents the service provider to infer private and sensitive
information about a user such as health or demographic attributes.In this
paper, we present DySan, a privacy-preserving framework to sanitize motion
sensor data against unwanted sensitive inferences (i.e., improving privacy)
while limiting the loss of accuracy on the physical activity monitoring (i.e.,
maintaining data utility). To ensure a good trade-off between utility and
privacy, DySan leverages on the framework of Generative Adversarial Network
(GAN) to sanitize the sensor data. More precisely, by learning in a competitive
manner several networks, DySan is able to build models that sanitize motion
data against inferences on a specified sensitive attribute (e.g., gender) while
maintaining a high accuracy on activity recognition. In addition, DySan
dynamically selects the sanitizing model which maximize the privacy according
to the incoming data. Experiments conducted on real datasets demonstrate that
DySan can drasticallylimit the gender inference to 47% while only reducing the
accuracy of activity recognition by 3%.
</p>
<a href="http://arxiv.org/abs/2003.10325" target="_blank">arXiv:2003.10325</a> [<a href="http://arxiv.org/pdf/2003.10325" target="_blank">pdf</a>]

<h2>A multi-surrogate higher-order singular value decomposition tensor emulator for spatio-temporal simulators. (arXiv:2010.03985v1 [stat.ME])</h2>
<h3>Giri Gopalan, Christopher K. Wikle</h3>
<p>We introduce methodology to construct an emulator for environmental and
ecological spatio-temporal processes that uses the higher order singular value
decomposition (HOSVD) as an extension of singular value decomposition (SVD)
approaches to emulation. Some important advantages of the method are that it
allows for the use of a combination of supervised learning methods (e.g.,
neural networks, random forests, and Gaussian process regression) and also
allows for the prediction of process values at spatial locations and time
points that were not used in the training sample. The method is demonstrated
with two applications: the first is a periodic solution to a shallow ice
approximation partial differential equation from glaciology, and second is an
agent-based model of collective animal movement. In both cases, we demonstrate
the value of combining different machine learning models (i.e., a
multi-surrogate approach) for accurate emulation. In addition, in the
agent-based model case we demonstrate the ability of the tensor emulator to
successfully capture individual behavior in space and time. We demonstrate via
a real data example the ability to perform Bayesian inference in order to learn
parameters governing collective animal behavior.
</p>
<a href="http://arxiv.org/abs/2010.03985" target="_blank">arXiv:2010.03985</a> [<a href="http://arxiv.org/pdf/2010.03985" target="_blank">pdf</a>]

<h2>HECT: High-Dimensional Ensemble Consistency Testing for Climate Models. (arXiv:2010.04051v1 [stat.AP])</h2>
<h3>Niccol&#xf2; Dalmasso, Galen Vincent, Dorit Hammerling, Ann B. Lee</h3>
<p>Climate models play a crucial role in understanding the effect of
environmental and man-made changes on climate to help mitigate climate risks
and inform governmental decisions. Large global climate models such as the
Community Earth System Model (CESM), developed by the National Center for
Atmospheric Research, are very complex with millions of lines of code
describing interactions of the atmosphere, land, oceans, and ice, among other
components. As development of the CESM is constantly ongoing, simulation
outputs need to be continuously controlled for quality. To be able to
distinguish a "climate-changing" modification of the code base from a true
climate-changing physical process or intervention, there needs to be a
principled way of assessing statistical reproducibility that can handle both
spatial and temporal high-dimensional simulation outputs. Our proposed work
uses probabilistic classifiers like tree-based algorithms and deep neural
networks to perform a statistically rigorous goodness-of-fit test of
high-dimensional spatio-temporal data.
</p>
<a href="http://arxiv.org/abs/2010.04051" target="_blank">arXiv:2010.04051</a> [<a href="http://arxiv.org/pdf/2010.04051" target="_blank">pdf</a>]

<h2>Sobolev Norm Learning Rates for Regularized Least-Squares Algorithm. (arXiv:1702.07254v3 [stat.ML] UPDATED)</h2>
<h3>Simon Fischer, Ingo Steinwart</h3>
<p>Learning rates for least-squares regression are typically expressed in terms
of $L_2$-norms. In this paper we extend these rates to norms stronger than the
$L_2$-norm without requiring the regression function to be contained in the
hypothesis space. In the special case of Sobolev reproducing kernel Hilbert
spaces used as hypotheses spaces, these stronger norms coincide with fractional
Sobolev norms between the used Sobolev space and $L_2$. As a consequence, not
only the target function but also some of its derivatives can be estimated
without changing the algorithm. From a technical point of view, we combine the
well-known integral operator techniques with an embedding property, which so
far has only been used in combination with empirical process arguments. This
combination results in new finite sample bounds with respect to the stronger
norms. From these finite sample bounds our rates easily follow. Finally, we
prove the asymptotic optimality of our results in many cases.
</p>
<a href="http://arxiv.org/abs/1702.07254" target="_blank">arXiv:1702.07254</a> [<a href="http://arxiv.org/pdf/1702.07254" target="_blank">pdf</a>]

