---
title: Latest Deep Learning Papers
date: 2020-10-05 00:10:16 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Data-driven model reduction for stochastic Burgers equations. (arXiv:2010.00736v1 [math.NA])</h2>
<h3>Fei Lu</h3>
<p>We present a class of efficient parametric closure models for 1D stochastic
Burgers equations. Casting it as statistical learning of the flow map, we
derive the parametric form by representing the unresolved high wavenumber
Fourier modes as functionals of the resolved variables' trajectory. The reduced
models are nonlinear autoregression (NAR) time series models, with coefficients
estimated from data by least squares. The NAR models can accurately reproduce
the energy spectrum, the invariant densities, and the autocorrelations. Taking
advantage of the simplicity of the NAR models, we investigate maximal and
optimal space-time reduction. Reduction in space dimension is unlimited, and
NAR models with two Fourier modes can perform well. The NAR model's stability
limits time reduction, with a maximal time step smaller than that of the K-mode
Galerkin system. We report a potential criterion for optimal space-time
reduction: the NAR models achieve minimal relative error in the energy spectrum
at the time step where the K-mode Galerkin system's mean CFL number agrees with
the full model's.
</p>
<a href="http://arxiv.org/abs/2010.00736" target="_blank">arXiv:2010.00736</a> [<a href="http://arxiv.org/pdf/2010.00736" target="_blank">pdf</a>]

<h2>Greedy Covariance Control for Stochastic Nonlinear Systems using Gaussian Process Prediction Models and the Unscented Transform. (arXiv:2010.00778v1 [math.OC])</h2>
<h3>Alexandros Tsolovikos, Efstathios Bakolas</h3>
<p>In this work, the problem of steering the first two moments of the uncertain
state of an unknown discrete-time nonlinear stochastic system to a given
terminal distribution in finite time is considered. Toward that goal, first, a
non-parametric prediction model is learned from a set of available training
data points using Gaussian process regression: a powerful machine learning tool
for learning distributions over arbitrary nonlinear functions. Second, a
tractable nonlinear covariance steering algorithm that utilizes the Gaussian
process prediction model to compute a feedback policy that will drive the
probability density function of the state of the system close to the goal
density is formulated. In particular, a greedy covariance steering control
policy is implemented that linearizes the Gaussian process prediction model
around the latest mean and covariance predictions at each time step and solves
the linear covariance steering control problem, which can be formulated as a
tractable, finite-dimensional convex program. Then, only the first control law
of the solution to the linear problem is applied. At each step, the information
on the state statistics is updated by computing approximations of the predicted
state mean and covariance of the resulting closed-loop nonlinear system step
using the unscented transform and the learned Gaussian process prediction
model. Numerical simulations illustrating the main ideas of this paper are also
presented.
</p>
<a href="http://arxiv.org/abs/2010.00778" target="_blank">arXiv:2010.00778</a> [<a href="http://arxiv.org/pdf/2010.00778" target="_blank">pdf</a>]

<h2>Nonsmoothness in Machine Learning: specific structure, proximal identification, and applications. (arXiv:2010.00848v1 [math.OC])</h2>
<h3>Franck Iutzeler (DAO), J&#xe9;r&#xf4;me Malick (DAO)</h3>
<p>Nonsmoothness is often a curse for optimization; but it is sometimes a
blessing, in particular for applications in machine learning. In this paper, we
present the specific structure of nonsmooth optimization problems appearing in
machine learning and illustrate how to leverage this structure in practice, for
compression, acceleration, or dimension reduction. We pay a special attention
to the presentation to make it concise and easily accessible, with both simple
examples and general results.
</p>
<a href="http://arxiv.org/abs/2010.00848" target="_blank">arXiv:2010.00848</a> [<a href="http://arxiv.org/pdf/2010.00848" target="_blank">pdf</a>]

<h2>Systematic Orbifold Constructions of Schellekens' Vertex Operator Algebras from Niemeier Lattices. (arXiv:2010.00849v1 [math.QA])</h2>
<h3>Gerald H&#xf6;hn, Sven M&#xf6;ller</h3>
<p>We present a systematic, rigorous construction of all 70 strongly rational,
holomorphic vertex operator algebras $V$ of central charge 24 with non-zero
weight-one space $V_1$ as cyclic orbifold constructions associated with the 24
Niemeier lattice vertex operator algebras $V_N$ and certain 226 short
automorphisms in $\operatorname{Aut}(V_N)$.

We show that up to algebraic conjugacy these automorphisms are exactly the
generalised deep holes, as introduced in arXiv:1910.04947, of the Niemeier
lattice vertex operator algebras with the additional property that their orders
are equal to those of the corresponding outer automorphisms.

Together with the constructions in arXiv:1708.05990 and arXiv:1910.04947 this
gives three different uniform constructions of these vertex operator algebras,
which are related through 11 algebraic conjugacy classes in
$\operatorname{Co}_0$.

Finally, by considering the inverse orbifold constructions associated with
the 226 short automorphisms, we give the first systematic proof of the result
that each strongly rational, holomorphic vertex operator algebra $V$ of central
charge 24 with non-zero weight-one space $V_1$ is uniquely determined by the
Lie algebra structure of $V_1$.
</p>
<a href="http://arxiv.org/abs/2010.00849" target="_blank">arXiv:2010.00849</a> [<a href="http://arxiv.org/pdf/2010.00849" target="_blank">pdf</a>]

<h2>Variance-Reduced Methods for Machine Learning. (arXiv:2010.00892v1 [cs.LG])</h2>
<h3>Robert M. Gower, Mark Schmidt, Francis Bach, Peter Richtarik</h3>
<p>Stochastic optimization lies at the heart of machine learning, and its
cornerstone is stochastic gradient descent (SGD), a method introduced over 60
years ago. The last 8 years have seen an exciting new development: variance
reduction (VR) for stochastic optimization methods. These VR methods excel in
settings where more than one pass through the training data is allowed,
achieving a faster convergence than SGD in theory as well as practice. These
speedups underline the surge of interest in VR methods and the fast-growing
body of work on this topic. This review covers the key principles and main
developments behind VR methods for optimization with finite data sets and is
aimed at non-expert readers. We focus mainly on the convex setting, and leave
pointers to readers interested in extensions for minimizing non-convex
functions.
</p>
<a href="http://arxiv.org/abs/2010.00892" target="_blank">arXiv:2010.00892</a> [<a href="http://arxiv.org/pdf/2010.00892" target="_blank">pdf</a>]

<h2>Generalized Self-Concordant Analysis of Frank-Wolfe algorithms. (arXiv:2010.01009v1 [math.OC])</h2>
<h3>Pavel Dvurechensky, Kamil Satin, Shimrit Shtern, Mathias Staudigl</h3>
<p>Projection-free optimization via different variants of the Frank-Wolfe (FW)
method has become one of the cornerstones in large scale optimization for
machine learning and computational statistics. Numerous applications within
these fields involve the minimization of functions with self-concordance like
properties. Such generalized self-concordant (GSC) functions do not necessarily
feature a Lipschitz continuous gradient, nor are they strongly convex. Indeed,
in a number of applications, e.g. inverse covariance estimation or
distance-weighted discrimination problems in support vector machines, the loss
is given by a GSC function having unbounded curvature, implying absence of
theoretical guarantees for the existing FW methods. This paper closes this
apparent gap in the literature by developing provably convergent FW algorithms
with standard O(1/k) convergence rate guarantees. If the problem formulation
allows the efficient construction of a local linear minimization oracle, we
develop a FW method with linear convergence rate.
</p>
<a href="http://arxiv.org/abs/2010.01009" target="_blank">arXiv:2010.01009</a> [<a href="http://arxiv.org/pdf/2010.01009" target="_blank">pdf</a>]

<h2>POMDPs in Continuous Time and Discrete Spaces. (arXiv:2010.01014v1 [cs.LG])</h2>
<h3>Bastian Alt, Matthias Schultheis, Heinz Koeppl</h3>
<p>Many processes, such as discrete event systems in engineering or population
dynamics in biology, evolve in discrete space and continuous time. We consider
the problem of optimal decision making in such discrete state and action space
systems under partial observability. This places our work at the intersection
of optimal filtering and optimal control. At the current state of research, a
mathematical description for simultaneous decision making and filtering in
continuous time with finite countable state and action spaces is still missing.
In this paper, we give a mathematical description of a continuous-time POMDP.
By leveraging optimal filtering theory we derive a HJB type equation that
characterizes the optimal solution. Using techniques from deep learning we
approximately solve the resulting partial integro-differential equation. We
present (i) an approach solving the decision problem offline by learning an
approximation of the value function and (ii) an online algorithm which provides
a solution in belief space using deep reinforcement learning. We show the
applicability on a set of toy examples which pave the way for future methods
providing solutions for high dimensional problems.
</p>
<a href="http://arxiv.org/abs/2010.01014" target="_blank">arXiv:2010.01014</a> [<a href="http://arxiv.org/pdf/2010.01014" target="_blank">pdf</a>]

<h2>$X$-Secure $T$-Private Federated Submodel Learning. (arXiv:2010.01059v1 [cs.IT])</h2>
<h3>Zhuqing Jia, Syed A. Jafar</h3>
<p>The problem of (information-theoretic) $X$-secure $T$-private federated
submodel learning represents a setting where a large scale machine learning
model is partitioned into $K$ submodels and stored across $N$ distributed
servers according to an $X$-secure threshold secret sharing scheme. Various
users wish to successively train (update) the submodel that is most relevant to
their local data while keeping the identity of their relevant submodel private
from any set of up to $T$ colluding servers. Inspired by the idea of
cross-subspace alignment (CSA) for $X$-secure $T$-private information
retrieval, we propose a novel CSA-RW (read-write) scheme for efficiently (in
terms of communication cost) and privately reading from and writing to a
distributed database. CSA-RW is shown to be asymptotically/approximately
optimal in download/upload communication cost, and improves significantly upon
available baselines from prior work. It also answers in the affirmative an open
question by Kairouz et al. by exploiting synergistic gains from the joint
design of private read and write operations.
</p>
<a href="http://arxiv.org/abs/2010.01059" target="_blank">arXiv:2010.01059</a> [<a href="http://arxiv.org/pdf/2010.01059" target="_blank">pdf</a>]

<h2>Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction. (arXiv:2010.01084v1 [stat.ML])</h2>
<h3>Wei Deng, Qi Feng, Georgios Karagiannis, Guang Lin, Faming Liang</h3>
<p>Replica exchange stochastic gradient Langevin dynamics (reSGLD) has shown
promise in accelerating the convergence in non-convex learning; however, an
excessively large correction for avoiding biases from noisy energy estimators
has limited the potential of the acceleration. To address this issue, we study
the variance reduction for noisy energy estimators, which promotes much more
effective swaps. Theoretically, we provide a non-asymptotic analysis on the
exponential acceleration for the underlying continuous-time Markov jump
process; moreover, we consider a generalized Girsanov theorem which includes
the change of Poisson measure to overcome the crude discretization based on the
Gr\"{o}wall's inequality and yields a much tighter error in the 2-Wasserstein
($\mathcal{W}_2$) distance. Numerically, we conduct extensive experiments and
obtain the state-of-the-art results in optimization and uncertainty estimates
for synthetic experiments and image data.
</p>
<a href="http://arxiv.org/abs/2010.01084" target="_blank">arXiv:2010.01084</a> [<a href="http://arxiv.org/pdf/2010.01084" target="_blank">pdf</a>]

<h2>Convergence Certificate for Stochastic Derivative-Free Trust-Region Methods based on Gaussian Processes. (arXiv:2010.01120v1 [eess.SY])</h2>
<h3>Harsh A. Shukla, Tafarel de Avila Ferreira, Timm Faulwasser, Dominique Bonvin, Colin N. Jones</h3>
<p>In many machine learning applications, one wants to learn the unknown
objective and constraint functions of an optimization problem from available
data and then apply some technique to attain a local optimizer of the learned
model. This work considers Gaussian processes as global surrogate models and
utilizes them in conjunction with derivative-free trust-region methods. It is
well known that derivative-free trust-region methods converge
globally---provided the surrogate model is probabilistically fully linear. We
prove that \glspl{gp} are indeed probabilistically fully linear, thus resulting
in fast (compared to linear or quadratic local surrogate models) and global
convergence. We draw upon the optimization of a chemical reactor to demonstrate
the efficiency of \gls{gp}-based trust-region methods.
</p>
<a href="http://arxiv.org/abs/2010.01120" target="_blank">arXiv:2010.01120</a> [<a href="http://arxiv.org/pdf/2010.01120" target="_blank">pdf</a>]

<h2>REQIBA: Regression and Deep Q-Learning for Intelligent UAV Cellular User to Base Station Association. (arXiv:2010.01126v1 [cs.IT])</h2>
<h3>Boris Galkin, Erika Fonseca, Ramy Amer, Luiz A. DaSilva, Ivana Dusparic</h3>
<p>Unmanned Aerial Vehicles (UAVs) are emerging as important users of
next-generation cellular networks. By operating in the sky, these UAV users
experience very different radio conditions than terrestrial users, due to
factors such as strong Line-of-Sight (LoS) channels (and interference) and Base
Station (BS) antenna misalignment. The consequence of this is that the UAVs
experience significant degradation to their received quality of service,
particularly when they are moving and are subject to frequent handovers. The
solution is to allow the UAV to be aware of its surrounding environment, and
intelligently connect into the cellular network using this awareness. In this
paper we present REgression and deep Q-learning for Intelligent UAV cellular
user to Base station Association (REQIBA) to allow a UAV which is flying over
an urban area to intelligently connect to underlying BSs, using information
about the received signal powers, the BS locations, and the surrounding
building topology. We demonstrate how REQIBA can as much as double the total
UAV throughput, when compared to heuristic association schemes similar to those
commonly used by terrestrial users. We also evaluate how environmental factors
such as UAV height, building density, and throughput loss due to handovers
impact the performance of our solution.
</p>
<a href="http://arxiv.org/abs/2010.01126" target="_blank">arXiv:2010.01126</a> [<a href="http://arxiv.org/pdf/2010.01126" target="_blank">pdf</a>]

<h2>Algorithms for stochastic optimization with functional or expectation constraints. (arXiv:1604.03887v8 [math.OC] UPDATED)</h2>
<h3>Guanghui Lan, Zhiqiang Zhou</h3>
<p>This paper considers the problem of minimizing an expectation function over a
closed convex set, coupled with a {\color{black} functional or expectation}
constraint on either decision variables or problem parameters. We first present
a new stochastic approximation (SA) type algorithm, namely the cooperative SA
(CSA), to handle problems with the constraint on devision variables. We show
that this algorithm exhibits the optimal ${\cal O}(1/\epsilon^2)$ rate of
convergence, in terms of both optimality gap and constraint violation, when the
objective and constraint functions are generally convex, where $\epsilon$
denotes the optimality gap and infeasibility. Moreover, we show that this rate
of convergence can be improved to ${\cal O}(1/\epsilon)$ if the objective and
constraint functions are strongly convex. We then present a variant of CSA,
namely the cooperative stochastic parameter approximation (CSPA) algorithm, to
deal with the situation when the constraint is defined over problem parameters
and show that it exhibits similar optimal rate of convergence to CSA. It is
worth noting that CSA and CSPA are primal methods which do not require the
iterations on the dual space and/or the estimation on the size of the dual
variables. To the best of our knowledge, this is the first time that such
optimal SA methods for solving functional or expectation constrained stochastic
optimization are presented in the literature.
</p>
<a href="http://arxiv.org/abs/1604.03887" target="_blank">arXiv:1604.03887</a> [<a href="http://arxiv.org/pdf/1604.03887" target="_blank">pdf</a>]

<h2>Stochastic proximal splitting algorithm for composite minimization. (arXiv:1912.02039v3 [math.OC] UPDATED)</h2>
<h3>Andrei Patrascu, Paul Irofti</h3>
<p>Supported by the recent contributions in multiple branches, the first-order
splitting algorithms became central for structured nonsmooth optimization. In
the large-scale or noisy contexts, when only stochastic information on the
smooth part of the objective function is available, the extension of proximal
gradient schemes to stochastic oracles is based on proximal tractability of the
nonsmooth component and it has been deeply analyzed in the literature. However,
there remained gaps illustrated by composite models where the nonsmooth term is
not proximally tractable anymore. In this note we tackle composite optimization
problems, where the access only to stochastic information on both smooth and
nonsmooth components is assumed, using a stochastic proximal first-order scheme
with stochastic proximal updates. We provide $\mathcal{O}\left( \frac{1}{k}
\right)$ the iteration complexity (in expectation of squared distance to the
optimal set) under the strong convexity assumption on the objective function.
Empirical behavior is illustrated by numerical tests on parametric sparse
representation models.
</p>
<a href="http://arxiv.org/abs/1912.02039" target="_blank">arXiv:1912.02039</a> [<a href="http://arxiv.org/pdf/1912.02039" target="_blank">pdf</a>]

<h2>Asymptotic Guarantees for Generative Modeling based on the Smooth Wasserstein Distance. (arXiv:2002.01012v3 [math.ST] UPDATED)</h2>
<h3>Ziv Goldfeld, Kristjan Greenewald, Kengo Kato</h3>
<p>Minimum distance estimation (MDE) gained recent attention as a formulation of
(implicit) generative modeling. It considers minimizing, over model parameters,
a statistical distance between the empirical data distribution and the model.
This formulation lends itself well to theoretical analysis, but typical results
are hindered by the curse of dimensionality. To overcome this and devise a
scalable finite-sample statistical MDE theory, we adopt the framework of smooth
1-Wasserstein distance (SWD) $\mathsf{W}_1^{(\sigma)}$. The SWD was recently
shown to preserve the metric and topological structure of classic Wasserstein
distances, while enjoying dimension-free empirical convergence rates. In this
work, we conduct a thorough statistical study of the minimum smooth Wasserstein
estimators (MSWEs), first proving the estimator's measurability and asymptotic
consistency. We then characterize the limit distribution of the optimal model
parameters and their associated minimal SWD. These results imply an
$O(n^{-1/2})$ generalization bound for generative modeling based on MSWE, which
holds in arbitrary dimension. Our main technical tool is a novel
high-dimensional limit distribution result for empirical
$\mathsf{W}_1^{(\sigma)}$. The characterization of a nondegenerate limit stands
in sharp contrast with the classic unsmooth empirical 1-Wasserstein distance,
for which a similar result is known only in the one-dimensional case. The
validity of our theory is supported by empirical results, posing the SWD as a
potent tool for learning and inference in high dimensions.
</p>
<a href="http://arxiv.org/abs/2002.01012" target="_blank">arXiv:2002.01012</a> [<a href="http://arxiv.org/pdf/2002.01012" target="_blank">pdf</a>]

<h2>Stability for the Training of Deep Neural Networks and Other Classifiers. (arXiv:2002.04122v3 [math.AP] UPDATED)</h2>
<h3>Leonid Berlyand, Pierre-Emmanuel Jabin, C. Alex Safsten</h3>
<p>We examine the stability of loss-minimizing training processes that are used
for deep neural networks (DNN) and other classifiers. While a classifier is
optimized during training through a so-called loss function, the performance of
classifiers is usually evaluated by some measure of accuracy, such as the
overall accuracy which quantifies the proportion of objects that are well
classified. This leads to the guiding question of stability: does decreasing
loss through training always result in increased accuracy? We formalize the
notion of stability, and provide examples of instability. Our main result
consists of two novel conditions on the classifier which, if either is
satisfied, ensure stability of training, that is we derive tight bounds on
accuracy as loss decreases. We also derive a sufficient condition for stability
on the training set alone, identifying flat portions of the data manifold as
potential sources of instability. The latter condition is explicitly verifiable
on the training dataset. Our results do not depend on the algorithm used for
training, as long as loss decreases with training.
</p>
<a href="http://arxiv.org/abs/2002.04122" target="_blank">arXiv:2002.04122</a> [<a href="http://arxiv.org/pdf/2002.04122" target="_blank">pdf</a>]

<h2>Online Learning with Imperfect Hints. (arXiv:2002.04726v2 [cs.LG] UPDATED)</h2>
<h3>Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar, Manish Purohit</h3>
<p>We consider a variant of the classical online linear optimization problem in
which at every step, the online player receives a "hint" vector before choosing
the action for that round. Rather surprisingly, it was shown that if the hint
vector is guaranteed to have a positive correlation with the cost vector, then
the online player can achieve a regret of $O(\log T)$, thus significantly
improving over the $O(\sqrt{T})$ regret in the general setting. However, the
result and analysis require the correlation property at \emph{all} time steps,
thus raising the natural question: can we design online learning algorithms
that are resilient to bad hints?

In this paper we develop algorithms and nearly matching lower bounds for
online learning with imperfect directional hints. Our algorithms are oblivious
to the quality of the hints, and the regret bounds interpolate between the
always-correlated hints case and the no-hints case. Our results also
generalize, simplify, and improve upon previous results on optimistic regret
bounds, which can be viewed as an additive version of hints.
</p>
<a href="http://arxiv.org/abs/2002.04726" target="_blank">arXiv:2002.04726</a> [<a href="http://arxiv.org/pdf/2002.04726" target="_blank">pdf</a>]

<h2>Quantum Computing Assisted Deep Learning for Fault Detection and Diagnosis in Industrial Process Systems. (arXiv:2003.00264v2 [quant-ph] UPDATED)</h2>
<h3>Akshay Ajagekar, Fengqi You</h3>
<p>Quantum computing (QC) and deep learning techniques have attracted widespread
attention in the recent years. This paper proposes QC-based deep learning
methods for fault diagnosis that exploit their unique capabilities to overcome
the computational challenges faced by conventional data-driven approaches
performed on classical computers. Deep belief networks are integrated into the
proposed fault diagnosis model and are used to extract features at different
levels for normal and faulty process operations. The QC-based fault diagnosis
model uses a quantum computing assisted generative training process followed by
discriminative training to address the shortcomings of classical algorithms. To
demonstrate its applicability and efficiency, the proposed fault diagnosis
method is applied to process monitoring of continuous stirred tank reactor
(CSTR) and Tennessee Eastman (TE) process. The proposed QC-based deep learning
approach enjoys superior fault detection and diagnosis performance with
obtained average fault detection rates of 79.2% and 99.39% for CSTR and TE
process, respectively.
</p>
<a href="http://arxiv.org/abs/2003.00264" target="_blank">arXiv:2003.00264</a> [<a href="http://arxiv.org/pdf/2003.00264" target="_blank">pdf</a>]

<h2>Riemannian Adaptive Optimization Algorithm and Its Application to Natural Language Processing. (arXiv:2004.00897v3 [math.OC] UPDATED)</h2>
<h3>Hiroyuki Sakai, Hideaki Iiduka</h3>
<p>This paper proposes a Riemannian adaptive optimization algorithm to optimize
the parameters of deep neural networks. The algorithm is an extension of both
AMSGrad in Euclidean space and RAMSGrad on a Riemannian manifold. The algorithm
helps to resolve two issues affecting RAMSGrad. The first is that it can solve
the Riemannian stochastic optimization problem directly, in contrast to
RAMSGrad which only achieves a low regret. The other is that it can use
constant learning rates, which makes it implementable in practice.
Additionally, we apply the proposed algorithm to Poincar{\'e} embeddings, which
embed the transitive closure of the WordNet nouns into the Poincar{\'e} ball
model of hyperbolic space. Numerical experiments show that regardless of the
initial value of the learning rate, our algorithm stably converges to the
optimal solution and converges faster than RSGD, the most basic Riemannian
stochastic optimization algorithm.
</p>
<a href="http://arxiv.org/abs/2004.00897" target="_blank">arXiv:2004.00897</a> [<a href="http://arxiv.org/pdf/2004.00897" target="_blank">pdf</a>]

<h2>Kolmogorov Width Decay and Poor Approximators in Machine Learning: Shallow Neural Networks, Random Feature Models and Neural Tangent Kernels. (arXiv:2005.10807v2 [math.FA] UPDATED)</h2>
<h3>Weinan E, Stephan Wojtowytsch</h3>
<p>We establish a scale separation of Kolmogorov width type between subspaces of
a given Banach space under the condition that a sequence of linear maps
converges much faster on one of the subspaces. The general technique is then
applied to show that reproducing kernel Hilbert spaces are poor
$L^2$-approximators for the class of two-layer neural networks in high
dimension, and that multi-layer networks with small path norm are poor
approximators for certain Lipschitz functions, also in the $L^2$-topology.
</p>
<a href="http://arxiv.org/abs/2005.10807" target="_blank">arXiv:2005.10807</a> [<a href="http://arxiv.org/pdf/2005.10807" target="_blank">pdf</a>]

<h2>The Heavy-Tail Phenomenon in SGD. (arXiv:2006.04740v2 [math.OC] UPDATED)</h2>
<h3>Mert Gurbuzbalaban, Umut Simsekli, Lingjiong Zhu</h3>
<p>In recent years, various notions of capacity and complexity have been
proposed for characterizing the generalization properties of stochastic
gradient descent (SGD) in deep learning. Some of the popular notions that
correlate well with the performance on unseen data are (i) the `flatness' of
the local minimum found by SGD, which is related to the eigenvalues of the
Hessian, (ii) the ratio of the stepsize $\eta$ to the batch size $b$, which
essentially controls the magnitude of the stochastic gradient noise, and (iii)
the `tail-index', which measures the heaviness of the tails of the network
weights at convergence. In this paper, we argue that these three seemingly
unrelated perspectives for generalization are deeply linked to each other. We
claim that depending on the structure of the Hessian of the loss at the
minimum, and the choices of the algorithm parameters $\eta$ and $b$, the SGD
iterates will converge to a \emph{heavy-tailed} stationary distribution. We
rigorously prove this claim in the setting of quadratic optimization: we show
that even in a simple linear regression problem with independent and
identically distributed Gaussian data, the iterates can be heavy-tailed with
infinite variance. We further characterize the behavior of the tails with
respect to algorithm parameters, the dimension, and the curvature. We then
translate our results into insights about the behavior of SGD in deep learning.
We finally support our theory with experiments conducted on both synthetic data
and fully connected neural networks.
</p>
<a href="http://arxiv.org/abs/2006.04740" target="_blank">arXiv:2006.04740</a> [<a href="http://arxiv.org/pdf/2006.04740" target="_blank">pdf</a>]

<h2>Adaptive Gradient Methods Converge Faster with Over-Parameterization (and you can do a line-search). (arXiv:2006.06835v2 [cs.LG] UPDATED)</h2>
<h3>Sharan Vaswani, Issam Laradji, Frederik Kunstner, Si Yi Meng, Mark Schmidt, Simon Lacoste-Julien</h3>
<p>Adaptive gradient methods are typically used for training over-parameterized
models capable of exactly fitting the data; we thus study their convergence in
this interpolation setting. Under an interpolation assumption, we prove that
AMSGrad with a constant step-size and momentum can converge to the minimizer at
the faster $O(1/T)$ rate for smooth, convex functions. Furthermore, in this
setting, we show that AdaGrad can achieve an $O(1)$ regret in the online convex
optimization framework. When interpolation is only approximately satisfied, we
show that constant step-size AMSGrad converges to a neighbourhood of the
solution. On the other hand, we prove that AdaGrad is robust to the violation
of interpolation and converges to the minimizer at the optimal rate. However,
we demonstrate that even for simple, convex problems satisfying interpolation,
the empirical performance of these methods heavily depends on the step-size and
requires tuning. We alleviate this problem by using stochastic line-search
(SLS) and Polyak's step-sizes (SPS) to help these methods adapt to the
function's local smoothness. By using these techniques, we prove that AdaGrad
and AMSGrad do not require knowledge of problem-dependent constants and retain
the convergence guarantees of their constant step-size counterparts.
Experimentally, we show that these techniques help improve the convergence and
generalization performance across tasks, from binary classification with kernel
mappings to classification with deep neural networks.
</p>
<a href="http://arxiv.org/abs/2006.06835" target="_blank">arXiv:2006.06835</a> [<a href="http://arxiv.org/pdf/2006.06835" target="_blank">pdf</a>]

<h2>Non-convex Optimization via Adaptive Stochastic Search for End-to-End Learning and Control. (arXiv:2006.11992v2 [cs.LG] UPDATED)</h2>
<h3>Ioannis Exarchos, Marcus A. Pereira, Ziyi Wang, Evangelos A. Theodorou</h3>
<p>In this work we propose the use of adaptive stochastic search as a building
block for general, non-convex optimization operations within deep neural
network architectures. Specifically, for an objective function located at some
layer in the network and parameterized by some network parameters, we employ
adaptive stochastic search to perform optimization over its output. This
operation is differentiable and does not obstruct the passing of gradients
during backpropagation, thus enabling us to incorporate it as a component in
end-to-end learning. We study the proposed optimization module's properties and
benchmark it against two existing alternatives on a synthetic energy-based
structured prediction task, and further showcase its use in stochastic optimal
control applications.
</p>
<a href="http://arxiv.org/abs/2006.11992" target="_blank">arXiv:2006.11992</a> [<a href="http://arxiv.org/pdf/2006.11992" target="_blank">pdf</a>]

<h2>Towards Joint Learning of Optimal MAC Signaling and Wireless Channel Access. (arXiv:2007.09948v2 [cs.IT] UPDATED)</h2>
<h3>Alvaro Valcarce, Jakob Hoydis</h3>
<p>Communication protocols are the languages used by network nodes. Before a
user equipment (UE) can exchange data with a base station (BS), it must first
negotiate the conditions and parameters for that transmission. This negotiation
is supported by signaling messages at all layers of the protocol stack. Each
year, the mobile communications industry defines and standardizes these
messages, which are designed by humans during lengthy technical (and often
political) debates. Following this standardization effort, the development
phase begins, wherein the industry interprets and implements the resulting
standards. But is this massive development undertaking the only way to
implement a given protocol? We address the question of whether radios can learn
a pre-given target protocol as an intermediate step towards evolving their own.
Furthermore, we train cellular radios to emerge a channel access policy that
performs optimally under the constraints of the target protocol. We show that
multi-agent reinforcement learning (MARL) and learning-to-communicate (L2C)
techniques achieve this goal with gains over expert systems. Finally, we
provide insight into the transferability of these results to scenarios never
seen during training.
</p>
<a href="http://arxiv.org/abs/2007.09948" target="_blank">arXiv:2007.09948</a> [<a href="http://arxiv.org/pdf/2007.09948" target="_blank">pdf</a>]

<h2>Over-the-Air Federated Learning from Heterogeneous Data. (arXiv:2009.12787v2 [cs.LG] UPDATED)</h2>
<h3>Tomer Sery, Nir Shlezinger, Kobi Cohen, Yonina C. Eldar</h3>
<p>Federated learning (FL) is a framework for distributed learning of
centralized models. In FL, a set of edge devices train a model using their
local data, while repeatedly exchanging their trained updates with a central
server. This procedure allows tuning a centralized model in a distributed
fashion without having the users share their possibly private data. In this
paper, we focus on over-the-air (OTA) FL, which has been suggested recently to
reduce the communication overhead of FL due to the repeated transmissions of
the model updates by a large number of users over the wireless channel. In OTA
FL, all users simultaneously transmit their updates as analog signals over a
multiple access channel, and the server receives a superposition of the analog
transmitted signals. However, this approach results in the channel noise
directly affecting the optimization procedure, which may degrade the accuracy
of the trained model. We develop a Convergent OTA FL (COTAF) algorithm which
enhances the common local stochastic gradient descent (SGD) FL algorithm,
introducing precoding at the users and scaling at the server, which gradually
mitigates the effect of the noise. We analyze the convergence of COTAF to the
loss minimizing model and quantify the effect of a statistically heterogeneous
setup, i.e. when the training data of each user obeys a different distribution.
Our analysis reveals the ability of COTAF to achieve a convergence rate similar
to that achievable over error-free channels. Our simulations demonstrate the
improved convergence of COTAF over vanilla OTA local SGD for training using
non-synthetic datasets. Furthermore, we numerically show that the precoding
induced by COTAF notably improves the convergence rate and the accuracy of
models trained via OTA FL.
</p>
<a href="http://arxiv.org/abs/2009.12787" target="_blank">arXiv:2009.12787</a> [<a href="http://arxiv.org/pdf/2009.12787" target="_blank">pdf</a>]

<h2>Predicting User Engagement Status for Online Evaluation of Intelligent Assistants. (arXiv:2010.00656v1 [cs.CL])</h2>
<h3>Rui Meng, Zhen Yue, Alyssa Glass</h3>
<p>Evaluation of intelligent assistants in large-scale and online settings
remains an open challenge. User behavior-based online evaluation metrics have
demonstrated great effectiveness for monitoring large-scale web search and
recommender systems. Therefore, we consider predicting user engagement status
as the very first and critical step to online evaluation for intelligent
assistants. In this work, we first proposed a novel framework for classifying
user engagement status into four categories -- fulfillment, continuation,
reformulation and abandonment. We then demonstrated how to design simple but
indicative metrics based on the framework to quantify user engagement levels.
We also aim for automating user engagement prediction with machine learning
methods. We compare various models and features for predicting engagement
status using four real-world datasets. We conducted detailed analyses on
features and failure cases to discuss the performance of current models as well
as challenges.
</p>
<a href="http://arxiv.org/abs/2010.00656" target="_blank">arXiv:2010.00656</a> [<a href="http://arxiv.org/pdf/2010.00656" target="_blank">pdf</a>]

<h2>Machine Learning in Generation, Detection, and Mitigation of Cyberattacks in Smart Grid: A Survey. (arXiv:2010.00661v1 [cs.CR])</h2>
<h3>Nur Imtiazul Haque, Md Hasan Shahriar, Md Golam Dastgir, Anjan Debnath, Imtiaz Parvez, Arif Sarwat, Mohammad Ashiqur Rahman</h3>
<p>Smart grid (SG) is a complex cyber-physical system that utilizes modern cyber
and physical equipment to run at an optimal operating point. Cyberattacks are
the principal threats confronting the usage and advancement of the
state-of-the-art systems. The advancement of SG has added a wide range of
technologies, equipment, and tools to make the system more reliable, efficient,
and cost-effective. Despite attaining these goals, the threat space for the
adversarial attacks has also been expanded because of the extensive
implementation of the cyber networks. Due to the promising computational and
reasoning capability, machine learning (ML) is being used to exploit and defend
the cyberattacks in SG by the attackers and system operators, respectively. In
this paper, we perform a comprehensive summary of cyberattacks generation,
detection, and mitigation schemes by reviewing state-of-the-art research in the
SG domain. Additionally, we have summarized the current research in a
structured way using tabular format. We also present the shortcomings of the
existing works and possible future research direction based on our
investigation.
</p>
<a href="http://arxiv.org/abs/2010.00661" target="_blank">arXiv:2010.00661</a> [<a href="http://arxiv.org/pdf/2010.00661" target="_blank">pdf</a>]

<h2>Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers. (arXiv:2010.00667v1 [cs.CL])</h2>
<h3>Hanjie Chen, Yangfeng Ji</h3>
<p>To build an interpretable neural text classifier, most of the prior work has
focused on designing inherently interpretable models or finding faithful
explanations. A new line of work on improving model interpretability has just
started, and many existing methods require either prior information or human
annotations as additional inputs in training. To address this limitation, we
propose the variational word mask (VMASK) method to automatically learn
task-specific important words and reduce irrelevant information on
classification, which ultimately improves the interpretability of model
predictions. The proposed method is evaluated with three neural text
classifiers (CNN, LSTM, and BERT) on seven benchmark text classification
datasets. Experiments show the effectiveness of VMASK in improving both model
prediction accuracy and interpretability.
</p>
<a href="http://arxiv.org/abs/2010.00667" target="_blank">arXiv:2010.00667</a> [<a href="http://arxiv.org/pdf/2010.00667" target="_blank">pdf</a>]

<h2>Explaining Convolutional Neural Networks through Attribution-Based Input Sampling and Block-Wise Feature Aggregation. (arXiv:2010.00672v1 [cs.CV])</h2>
<h3>Sam Sattarzadeh, Mahesh Sudhakar, Anthony Lem, Shervin Mehryar, K. N. Plataniotis, Jongseong Jang, Hyunwoo Kim, Yeonjeong Jeong, Sangmin Lee, Kyunghoon Bae</h3>
<p>As an emerging field in Machine Learning, Explainable AI (XAI) has been
offering remarkable performance in interpreting the decisions made by
Convolutional Neural Networks (CNNs). To achieve visual explanations for CNNs,
methods based on class activation mapping and randomized input sampling have
gained great popularity. However, the attribution methods based on these
techniques provide lower resolution and blurry explanation maps that limit
their explanation power. To circumvent this issue, visualization based on
various layers is sought. In this work, we collect visualization maps from
multiple layers of the model based on an attribution-based input sampling
technique and aggregate them to reach a fine-grained and complete explanation.
We also propose a layer selection strategy that applies to the whole family of
CNN-based models, based on which our extraction framework is applied to
visualize the last layers of each convolutional block of the model. Moreover,
we perform an empirical analysis of the efficacy of derived lower-level
information to enhance the represented attributions. Comprehensive experiments
conducted on shallow and deep models trained on natural and industrial
datasets, using both ground-truth and model-truth based evaluation metrics
validate our proposed algorithm by meeting or outperforming the
state-of-the-art methods in terms of explanation ability and visual quality,
demonstrating that our method shows stability regardless of the size of objects
or instances to be explained.
</p>
<a href="http://arxiv.org/abs/2010.00672" target="_blank">arXiv:2010.00672</a> [<a href="http://arxiv.org/pdf/2010.00672" target="_blank">pdf</a>]

<h2>Helicality: An Isomap-based Measure of Octave Equivalence in Audio Data. (arXiv:2010.00673v1 [eess.AS])</h2>
<h3>Sripathi Sridhar, Vincent Lostanlen</h3>
<p>Octave equivalence serves as domain-knowledge in MIR systems, including
chromagram, spiral convolutional networks, and harmonic CQT. Prior work has
applied the Isomap manifold learning algorithm to unlabeled audio data to embed
frequency sub-bands in 3-D space where the Euclidean distances are inversely
proportional to the strength of their Pearson correlations. However,
discovering octave equivalence via Isomap requires visual inspection and is not
scalable. To address this problem, we define "helicality" as the goodness of
fit of the 3-D Isomap embedding to a Shepherd-Risset helix. Our method is
unsupervised and uses a custom Frank-Wolfe algorithm to minimize a
least-squares objective inside a convex hull. Numerical experiments indicate
that isolated musical notes have a higher helicality than speech, followed by
drum hits.
</p>
<a href="http://arxiv.org/abs/2010.00673" target="_blank">arXiv:2010.00673</a> [<a href="http://arxiv.org/pdf/2010.00673" target="_blank">pdf</a>]

<h2>Implicit Rank-Minimizing Autoencoder. (arXiv:2010.00679v1 [cs.LG])</h2>
<h3>Li Jing, Jure Zbontar, Yann LeCun</h3>
<p>An important component of autoencoders is the method by which the information
capacity of the latent representation is minimized or limited. In this work,
the rank of the covariance matrix of the codes is implicitly minimized by
relying on the fact that gradient descent learning in multi-layer linear
networks leads to minimum-rank solutions. By inserting a number of extra linear
layers between the encoder and the decoder, the system spontaneously learns
representations with a low effective dimension. The model, dubbed Implicit
Rank-Minimizing Autoencoder (IRMAE), is simple, deterministic, and learns
compact latent spaces. We demonstrate the validity of the method on several
image generation and representation learning tasks.
</p>
<a href="http://arxiv.org/abs/2010.00679" target="_blank">arXiv:2010.00679</a> [<a href="http://arxiv.org/pdf/2010.00679" target="_blank">pdf</a>]

<h2>Towards Hybrid Classical-Quantum Computation Structures in Wirelessly-Networked Systems. (arXiv:2010.00682v1 [cs.NI])</h2>
<h3>Minsung Kim, Davide Venturelli, Kyle Jamieson</h3>
<p>With unprecedented increases in traffic load in today's wireless networks,
design challenges shift from the wireless network itself to the computational
support behind the wireless network. In this vein, there is new interest in
quantum-compute approaches because of their potential to substantially speed up
processing, and so improve network throughput. However, quantum hardware that
actually exists today is much more susceptible to computational errors than
silicon-based hardware, due to the physical phenomena of decoherence and noise.
This paper explores the boundary between the two types of
computation---classical-quantum hybrid processing for optimization problems in
wireless systems---envisioning how wireless can simultaneously leverage the
benefit of both approaches. We explore the feasibility of a hybrid system with
a real hardware prototype using one of the most advanced experimentally
available techniques today, reverse quantum annealing. Preliminary results on a
low-latency, large MIMO system envisioned in the 5G New Radio roadmap are
encouraging, showing approximately 2--10X better performance in terms of
processing time than prior published results.
</p>
<a href="http://arxiv.org/abs/2010.00682" target="_blank">arXiv:2010.00682</a> [<a href="http://arxiv.org/pdf/2010.00682" target="_blank">pdf</a>]

<h2>Towards Scalable Bayesian Learning of Causal DAGs. (arXiv:2010.00684v1 [cs.LG])</h2>
<h3>Jussi Viinikka, Antti Hyttinen, Johan Pensar, Mikko Koivisto</h3>
<p>We give methods for Bayesian inference of directed acyclic graphs, DAGs, and
the induced causal effects from passively observed complete data. Our methods
build on a recent Markov chain Monte Carlo scheme for learning Bayesian
networks, which enables efficient approximate sampling from the graph
posterior, provided that each node is assigned a small number K of candidate
parents. We present algorithmic tricks to significantly reduce the space and
time requirements of the method, making it feasible to use substantially larger
values of K. Furthermore, we investigate the problem of selecting the candidate
parents per node so as to maximize the covered posterior mass. Finally, we
combine our sampling method with a novel Bayesian approach for estimating
causal effects in linear Gaussian DAG models. Numerical experiments demonstrate
the performance of our methods in detecting ancestor-descendant relations, and
in effect estimation our Bayesian method is shown to outperform existing
approaches.
</p>
<a href="http://arxiv.org/abs/2010.00684" target="_blank">arXiv:2010.00684</a> [<a href="http://arxiv.org/pdf/2010.00684" target="_blank">pdf</a>]

<h2>How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds. (arXiv:2010.00685v1 [cs.CL])</h2>
<h3>Prithviraj Ammanabrolu, Jack Urbanek, Margaret Li, Arthur Szlam, Tim Rockt&#xe4;schel, Jason Weston</h3>
<p>We seek to create agents that both act and communicate with other agents in
pursuit of a goal. Towards this end, we extend LIGHT (Urbanek et al. 2019)---a
large-scale crowd-sourced fantasy text-game---with a dataset of quests. These
contain natural language motivations paired with in-game goals and human
demonstrations; completing a quest might require dialogue or actions (or both).
We introduce a reinforcement learning system that (1) incorporates large-scale
language modeling-based and commonsense reasoning-based pre-training to imbue
the agent with relevant priors; and (2) leverages a factorized action space of
action commands and dialogue, balancing between the two. We conduct zero-shot
evaluations using held-out human expert demonstrations, showing that our agents
are able to act consistently and talk naturally with respect to their
motivations.
</p>
<a href="http://arxiv.org/abs/2010.00685" target="_blank">arXiv:2010.00685</a> [<a href="http://arxiv.org/pdf/2010.00685" target="_blank">pdf</a>]

<h2>Active Learning for Bayesian 3D Hand Pose Estimation. (arXiv:2010.00694v1 [cs.CV])</h2>
<h3>Razvan Caramalau, Binod Bhattarai, Tae-Kyun Kim</h3>
<p>We propose a Bayesian approximation to a deep learning architecture for 3D
hand pose estimation. Through this framework, we explore and analyse the two
types of uncertainties that are influenced either by data or by the learning
capability. Furthermore, we draw comparisons against the standard estimator
over three popular benchmarks. The first contribution lies in outperforming the
baseline while in the second part we address the active learning application.
We also show that with a newly proposed acquisition function, our Bayesian 3D
hand pose estimator obtains lowest errors with the least amount of data. The
underlying code is publicly available at
https://github.com/razvancaramalau/al_bhpe.
</p>
<a href="http://arxiv.org/abs/2010.00694" target="_blank">arXiv:2010.00694</a> [<a href="http://arxiv.org/pdf/2010.00694" target="_blank">pdf</a>]

<h2>Automatic and Efficient Variability-Aware Lifting of Functional Programs. (arXiv:2010.00697v1 [cs.PL])</h2>
<h3>Ramy Shahin, Marsha Chechik</h3>
<p>A software analysis is a computer program that takes some representation of a
software product as input and produces some useful information about that
product as output. A software product line encompasses \emph{many} software
product variants, and thus existing analyses can be applied to each of the
product variations individually, but not to the entire product line as a whole.
Enumerating all product variants and analyzing them one by one is usually
intractable due to the combinatorial explosion of the number of product
variants with respect to product line features. Several software analyses
(e.g., type checkers, model checkers, data flow analyses) have been
redesigned/re-implemented to support variability. This usually requires a lot
of time and effort, and the variability-aware version of the analysis might
have new errors/bugs that do not exist in the original one.

Given an analysis program written in a functional language based on PCF, in
this paper we present two approaches to transforming (lifting) it into a
semantically equivalent variability-aware analysis. A light-weight approach
(referred to as \emph{shallow lifting}) wraps the analysis program into a
variability-aware version, exploring all combinations of its input arguments.
Deep lifting, on the other hand, is a program rewriting mechanism where the
syntactic constructs of the input program are rewritten into their
variability-aware counterparts. Compositionally this results in an efficient
program semantically equivalent to the input program, modulo variability. We
present the correctness criteria for functional program lifting, together with
correctness proof sketches of our program transformations. We evaluate our
approach on a set of program analyses applied to the BusyBox C-language product
line.
</p>
<a href="http://arxiv.org/abs/2010.00697" target="_blank">arXiv:2010.00697</a> [<a href="http://arxiv.org/pdf/2010.00697" target="_blank">pdf</a>]

<h2>Learned Dual-View Reflection Removal. (arXiv:2010.00702v1 [cs.CV])</h2>
<h3>Simon Niklaus, Xuaner Cecilia Zhang, Jonathan T. Barron, Neal Wadhwa, Rahul Garg, Feng Liu, Tianfan Xue</h3>
<p>Traditional reflection removal algorithms either use a single image as input,
which suffers from intrinsic ambiguities, or use multiple images from a moving
camera, which is inconvenient for users. We instead propose a learning-based
dereflection algorithm that uses stereo images as input. This is an effective
trade-off between the two extremes: the parallax between two views provides
cues to remove reflections, and two views are easy to capture due to the
adoption of stereo cameras in smartphones. Our model consists of a
learning-based reflection-invariant flow model for dual-view registration, and
a learned synthesis model for combining aligned image pairs. Because no dataset
for dual-view reflection removal exists, we render a synthetic dataset of
dual-views with and without reflections for use in training. Our evaluation on
an additional real-world dataset of stereo pairs shows that our algorithm
outperforms existing single-image and multi-image dereflection approaches.
</p>
<a href="http://arxiv.org/abs/2010.00702" target="_blank">arXiv:2010.00702</a> [<a href="http://arxiv.org/pdf/2010.00702" target="_blank">pdf</a>]

<h2>Binary Neural Networks for Memory-Efficient and Effective Visual Place Recognition in Changing Environments. (arXiv:2010.00716v1 [cs.CV])</h2>
<h3>Bruno Ferrarini, Michael Milford, Klaus D. McDonald-Maier, Shoaib Ehsan</h3>
<p>Visual place recognition (VPR) is a robot's ability to determine whether a
place was visited before using visual data. While conventional hand-crafted
methods for VPR fail under extreme environmental appearance changes, those
based on convolutional neural networks (CNNs) achieve state-of-the-art
performance but result in model sizes that demand a large amount of memory.
Hence, CNN-based approaches are unsuitable for memory-constrained platforms,
such as small robots and drones. In this paper, we take a multi-step approach
of decreasing the precision of model parameters, combining it with network
depth reduction and fewer neurons in the classifier stage to propose a new
class of highly compact models that drastically reduce the memory requirements
while maintaining state-of-the-art VPR performance, and can be tuned to various
platforms and application scenarios. To the best of our knowledge, this is the
first attempt to propose binary neural networks for solving the visual place
recognition problem effectively under changing conditions and with
significantly reduced memory requirements. Our best-performing binary neural
network with a minimum number of layers, dubbed FloppyNet, achieves comparable
VPR performance when considered against its full precision and deeper
counterparts while consuming 99% less memory.
</p>
<a href="http://arxiv.org/abs/2010.00716" target="_blank">arXiv:2010.00716</a> [<a href="http://arxiv.org/pdf/2010.00716" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning with Mixed Convolutional Network. (arXiv:2010.00717v1 [cs.CV])</h2>
<h3>Yanyu Zhang</h3>
<p>Recent research has shown that map raw pixels from a single front-facing
camera directly to steering commands are surprisingly powerful. This paper
presents a convolutional neural network (CNN) to playing the CarRacing-v0 using
imitation learning in OpenAI Gym. The dataset is generated by playing the game
manually in Gym and used a data augmentation method to expand the dataset to 4
times larger than before. Also, we read the true speed, four ABS sensors,
steering wheel position, and gyroscope for each image and designed a mixed
model by combining the sensor input and image input. After training, this model
can automatically detect the boundaries of road features and drive the robot
like a human. By comparing with AlexNet and VGG16 using the average reward in
CarRacing-v0, our model wins the maximum overall system performance.
</p>
<a href="http://arxiv.org/abs/2010.00717" target="_blank">arXiv:2010.00717</a> [<a href="http://arxiv.org/pdf/2010.00717" target="_blank">pdf</a>]

<h2>Using ROC and Unlabeled Data for Increasing Low-Shot Transfer Learning Classification Accuracy. (arXiv:2010.00721v1 [cs.CV])</h2>
<h3>Spiridon Kasapis, Geng Zhang, Jonathon Smereka, Nickolas Vlahopoulos</h3>
<p>One of the most important characteristics of human visual intelligence is the
ability to identify unknown objects. The capability to distinguish between a
substance which a human mind has no previous experience of and a familiar
object, is innate to every human. In everyday life, within seconds of seeing an
"unknown" object, we are able to categorize it as such without any substantial
effort. Convolutional Neural Networks, regardless of how they are trained (i.e.
in a conventional manner or through transfer learning) can recognize only the
classes that they are trained for. When using them for classification, any
candidate image will be placed in one of the available classes. We propose a
low-shot classifier which can serve as the top layer to any existing CNN that
the feature extractor was already trained. Using a limited amount of labeled
data for the type of images which need to be specifically classified along with
unlabeled data for all other images, a unique target matrix and a Receiver
Operator Curve (ROC) criterion, we are able to increase identification accuracy
by up to 30% for the images that do not belong to any specific classes, while
retaining the ability to identify images that belong to the specific classes of
interest.
</p>
<a href="http://arxiv.org/abs/2010.00721" target="_blank">arXiv:2010.00721</a> [<a href="http://arxiv.org/pdf/2010.00721" target="_blank">pdf</a>]

<h2>Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations and visualizations via ParaMonte::Python library. (arXiv:2010.00724v1 [cs.MS])</h2>
<h3>Amir Shahmoradi, Fatemeh Bagheri, Joshua Alexander Osborne</h3>
<p>ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial
and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for
sampling mathematical objective functions, in particular, the posterior
distributions of parameters in Bayesian modeling and analysis in data science,
Machine Learning, and scientific inference in general. In addition to providing
access to fast high-performance serial/parallel Monte Carlo and MCMC sampling
routines, the ParaMonte::Python library provides extensive post-processing and
visualization tools that aim to automate and streamline the process of model
calibration and uncertainty quantification in Bayesian data analysis.
Furthermore, the automatically-enabled restart functionality of
ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future
restart of Monte Carlo simulations, should any interruptions happen. The
ParaMonte::Python library is MIT-licensed and is permanently maintained on
GitHub at
https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.
</p>
<a href="http://arxiv.org/abs/2010.00724" target="_blank">arXiv:2010.00724</a> [<a href="http://arxiv.org/pdf/2010.00724" target="_blank">pdf</a>]

<h2>Smart-Inspect: Micro Scale Localization and Classification of Smartphone Glass Defects for Industrial Automation. (arXiv:2010.00741v1 [cs.CV])</h2>
<h3>M Usman Maqbool Bhutta, Shoaib Aslam, Peng Yun, Jianhao Jiao, Ming Liu</h3>
<p>The presence of any type of defect on the glass screen of smart devices has a
great impact on their quality. We present a robust semi-supervised learning
framework for intelligent micro-scaled localization and classification of
defects on a 16K pixel image of smartphone glass. Our model features the
efficient recognition and labeling of three types of defects: scratches, light
leakage due to cracks, and pits. Our method also differentiates between the
defects and light reflections due to dust particles and sensor regions, which
are classified as non-defect areas. We use a partially labeled dataset to
achieve high robustness and excellent classification of defect and non-defect
areas as compared to principal components analysis (PCA), multi-resolution and
information-fusion-based algorithms. In addition, we incorporated two
classifiers at different stages of our inspection framework for labeling and
refining the unlabeled defects. We successfully enhanced the inspection
depth-limit up to 5 microns. The experimental results show that our method
outperforms manual inspection in testing the quality of glass screen samples by
identifying defects on samples that have been marked as good by human
inspection.
</p>
<a href="http://arxiv.org/abs/2010.00741" target="_blank">arXiv:2010.00741</a> [<a href="http://arxiv.org/pdf/2010.00741" target="_blank">pdf</a>]

<h2>Contrastive Learning of Medical Visual Representations from Paired Images and Text. (arXiv:2010.00747v1 [cs.CV])</h2>
<h3>Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher D. Manning, Curtis P. Langlotz</h3>
<p>Learning visual representations of medical images is core to medical image
understanding but its progress has been held back by the small size of
hand-labeled datasets. Existing work commonly relies on transferring weights
from ImageNet pretraining, which is suboptimal due to drastically different
image characteristics, or rule-based label extraction from the textual report
data paired with medical images, which is inaccurate and hard to generalize. We
propose an alternative unsupervised strategy to learn medical visual
representations directly from the naturally occurring pairing of images and
textual data. Our method of pretraining medical image encoders with the paired
text data via a bidirectional contrastive objective between the two modalities
is domain-agnostic, and requires no additional expert input. We test our method
by transferring our pretrained weights to 4 medical image classification tasks
and 2 zero-shot retrieval tasks, and show that our method leads to image
representations that considerably outperform strong baselines in most settings.
Notably, in all 4 classification tasks, our method requires only 10% as much
labeled training data as an ImageNet initialized counterpart to achieve better
or comparable performance, demonstrating superior data efficiency.
</p>
<a href="http://arxiv.org/abs/2010.00747" target="_blank">arXiv:2010.00747</a> [<a href="http://arxiv.org/pdf/2010.00747" target="_blank">pdf</a>]

<h2>Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation. (arXiv:2010.00753v1 [cs.GT])</h2>
<h3>Kate Donahue, Jon Kleinberg</h3>
<p>Federated learning is a setting where agents, each with access to their own
data source, combine models learned from local data to create a global model.
If agents are drawing their data from different distributions, though,
federated learning might produce a biased global model that is not optimal for
each agent. This means that agents face a fundamental question: should they
join the global model or stay with their local model? In this work, we show how
this situation can be naturally analyzed through the framework of coalitional
game theory.

Motivated by these considerations, we propose the following game: there are
heterogeneous players with different model parameters governing their data
distribution and different amounts of data they have noisily drawn from their
own distribution. Each player's goal is to obtain a model with minimal expected
mean squared error (MSE) on their own distribution. They have a choice of
fitting a model based solely on their own data, or combining their learned
parameters with those of some subset of the other players. Combining models
reduces the variance component of their error through access to more data, but
increases the bias because of the heterogeneity of distributions. In this work,
we derive exact expected MSE values for problems in linear regression and mean
estimation. We use these values to analyze the resulting game in the framework
of hedonic game theory; we study how players might divide into coalitions,
where each set of players within a coalition jointly constructs a single model.
In a case with arbitrarily many players that each have either a "small" or
"large" amount of data, we constructively show that there always exists a
stable partition of players into coalitions.
</p>
<a href="http://arxiv.org/abs/2010.00753" target="_blank">arXiv:2010.00753</a> [<a href="http://arxiv.org/pdf/2010.00753" target="_blank">pdf</a>]

<h2>Deep Learning for Earth Image Segmentation based on Imperfect Polyline Labels with Annotation Errors. (arXiv:2010.00757v1 [cs.CV])</h2>
<h3>Zhe Jiang, Marcus Stephen Kirby, Wenchong He, Arpan Man Sainju</h3>
<p>In recent years, deep learning techniques (e.g., U-Net, DeepLab) have
achieved tremendous success in image segmentation. The performance of these
models heavily relies on high-quality ground truth segment labels.
Unfortunately, in many real-world problems, ground truth segment labels often
have geometric annotation errors due to manual annotation mistakes, GPS errors,
or visually interpreting background imagery at a coarse resolution. Such
location errors will significantly impact the training performance of existing
deep learning algorithms. Existing research on label errors either models
ground truth errors in label semantics (assuming label locations to be correct)
or models label location errors with simple square patch shifting. These
methods cannot fully incorporate the geometric properties of label location
errors. To fill the gap, this paper proposes a generic learning framework based
on the EM algorithm to update deep learning model parameters and infer hidden
true label locations simultaneously. Evaluations on a real-world hydrological
dataset in the streamline refinement application show that the proposed
framework outperforms baseline methods in classification accuracy (reducing the
number of false positives by 67% and reducing the number of false negatives by
55%).
</p>
<a href="http://arxiv.org/abs/2010.00757" target="_blank">arXiv:2010.00757</a> [<a href="http://arxiv.org/pdf/2010.00757" target="_blank">pdf</a>]

<h2>Enriching Word Embeddings with Temporal and Spatial Information. (arXiv:2010.00761v1 [cs.CL])</h2>
<h3>Hongyu Gong, Suma Bhat, Pramod Viswanath</h3>
<p>The meaning of a word is closely linked to sociocultural factors that can
change over time and location, resulting in corresponding meaning changes.
Taking a global view of words and their meanings in a widely used language,
such as English, may require us to capture more refined semantics for use in
time-specific or location-aware situations, such as the study of cultural
trends or language use. However, popular vector representations for words do
not adequately include temporal or spatial information. In this work, we
present a model for learning word representation conditioned on time and
location. In addition to capturing meaning changes over time and location, we
require that the resulting word embeddings retain salient semantic and
geometric properties. We train our model on time- and location-stamped corpora,
and show using both quantitative and qualitative evaluations that it can
capture semantics across time and locations. We note that our model compares
favorably with the state-of-the-art for time-specific embedding, and serves as
a new benchmark for location-specific embeddings.
</p>
<a href="http://arxiv.org/abs/2010.00761" target="_blank">arXiv:2010.00761</a> [<a href="http://arxiv.org/pdf/2010.00761" target="_blank">pdf</a>]

<h2>Bongard-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning. (arXiv:2010.00763v1 [cs.AI])</h2>
<h3>Weili Nie, Zhiding Yu, Lei Mao, Ankit B. Patel, Yuke Zhu, Animashree Anandkumar</h3>
<p>Humans have an inherent ability to learn novel concepts from only a few
samples and generalize these concepts to different situations. Even though
today's machine learning models excel with a plethora of training data on
standard recognition tasks, a considerable gap exists between machine-level
pattern recognition and human-level concept learning. To narrow this gap, the
Bongard Problems (BPs) were introduced as an inspirational challenge for visual
cognition in intelligent systems. Albeit new advances in representation
learning and learning to learn, BPs remain a daunting challenge for modern AI.
Inspired by the original one hundred BPs, we propose a new benchmark
Bongard-LOGO for human-level concept learning and reasoning. We develop a
program-guided generation technique to produce a large set of
human-interpretable visual cognition problems in action-oriented LOGO language.
Our benchmark captures three core properties of human cognition: 1)
context-dependent perception, in which the same object may have disparate
interpretations given different contexts; 2) analogy-making perception, in
which some meaningful concepts are traded off for other meaningful concepts;
and 3) perception with a few samples but infinite vocabulary. In experiments,
we show that the state-of-the-art deep learning methods perform substantially
worse than human subjects, implying that they fail to capture core human
cognition properties. Finally, we discuss research directions towards a general
architecture for visual reasoning to tackle this benchmark.
</p>
<a href="http://arxiv.org/abs/2010.00763" target="_blank">arXiv:2010.00763</a> [<a href="http://arxiv.org/pdf/2010.00763" target="_blank">pdf</a>]

<h2>SparTerm: Learning Term-based Sparse Representation for Fast Text Retrieval. (arXiv:2010.00768v1 [cs.IR])</h2>
<h3>Yang Bai, Xiaoguang Li, Gang Wang, Chaoliang Zhang, Lifeng Shang, Jun Xu, Zhaowei Wang, Fangshan Wang, Qun Liu</h3>
<p>Term-based sparse representations dominate the first-stage text retrieval in
industrial applications, due to its advantage in efficiency, interpretability,
and exact term matching. In this paper, we study the problem of transferring
the deep knowledge of the pre-trained language model (PLM) to Term-based Sparse
representations, aiming to improve the representation capacity of
bag-of-words(BoW) method for semantic-level matching, while still keeping its
advantages. Specifically, we propose a novel framework SparTerm to directly
learn sparse text representations in the full vocabulary space. The proposed
SparTerm comprises an importance predictor to predict the importance for each
term in the vocabulary, and a gating controller to control the term activation.
These two modules cooperatively ensure the sparsity and flexibility of the
final text representation, which unifies the term-weighting and expansion in
the same framework. Evaluated on MSMARCO dataset, SparTerm significantly
outperforms traditional sparse methods and achieves state of the art ranking
performance among all the PLM-based sparse models.
</p>
<a href="http://arxiv.org/abs/2010.00768" target="_blank">arXiv:2010.00768</a> [<a href="http://arxiv.org/pdf/2010.00768" target="_blank">pdf</a>]

<h2>XDA: Accurate, Robust Disassembly with Transfer Learning. (arXiv:2010.00770v1 [cs.CR])</h2>
<h3>Kexin Pei, Jonas Guan, David Williams King, Junfeng Yang, Suman Jana</h3>
<p>Accurate and robust disassembly of stripped binaries is challenging. The root
of the difficulty is that high-level structures, such as instruction and
function boundaries, are absent in stripped binaries and must be recovered
based on incomplete information. Current disassembly approaches rely on
heuristics or simple pattern matching to approximate the recovery, but these
methods are often inaccurate and brittle, especially across different compiler
optimizations.

We present XDA, a transfer-learning-based disassembly framework that learns
different contextual dependencies present in machine code and transfers this
knowledge for accurate and robust disassembly. We design a self-supervised
learning task motivated by masked Language Modeling to learn interactions among
byte sequences in binaries. The outputs from this task are byte embeddings that
encode sophisticated contextual dependencies between input binaries' byte
tokens, which can then be finetuned for downstream disassembly tasks.

We evaluate XDA's performance on two disassembly tasks, recovering function
boundaries and assembly instructions, on a collection of 3,121 binaries taken
from SPEC CPU2017, SPEC CPU2006, and the BAP corpus. The binaries are compiled
by GCC, ICC, and MSVC on x86/x64 Windows and Linux platforms over 4
optimization levels. XDA achieves 99.0% and 99.7% F1 score at recovering
function boundaries and instructions, respectively, surpassing the previous
state-of-the-art on both tasks. It also maintains speed on par with the fastest
ML-based approach and is up to 38x faster than hand-written disassemblers like
IDA Pro.
</p>
<a href="http://arxiv.org/abs/2010.00770" target="_blank">arXiv:2010.00770</a> [<a href="http://arxiv.org/pdf/2010.00770" target="_blank">pdf</a>]

<h2>Effective Regularization Through Loss-Function Metalearning. (arXiv:2010.00788v1 [cs.LG])</h2>
<h3>Santiago Gonzalez, Risto Miikkulainen</h3>
<p>Loss-function metalearning can be used to discover novel, customized loss
functions for deep neural networks, resulting in improved performance, faster
training, and improved data utilization. A likely explanation is that such
functions discourage overfitting, leading to effective regularization. This
paper theoretically demonstrates that this is indeed the case: decomposition of
learning rules makes it possible to characterize the training dynamics and show
that loss functions evolved through TaylorGLO regularize both in the beginning
and end of learning, and maintain an invariant in between. The invariant can be
utilized to make the metalearning process more efficient in practice, and the
regularization can train networks that are robust against adversarial attacks.
Loss-function optimization can thus be seen as a well-founded new aspect of
metalearning in neural networks.
</p>
<a href="http://arxiv.org/abs/2010.00788" target="_blank">arXiv:2010.00788</a> [<a href="http://arxiv.org/pdf/2010.00788" target="_blank">pdf</a>]

<h2>PrognoseNet: A Generative Probabilistic Framework for Multimodal Position Prediction given Context Information. (arXiv:2010.00802v1 [cs.CV])</h2>
<h3>Thomas Kurbiel, Akash Sachdeva, Kun Zhao, Markus Buehren</h3>
<p>The ability to predict multiple possible future positions of the ego-vehicle
given the surrounding context while also estimating their probabilities is key
to safe autonomous driving. Most of the current state-of-the-art Deep Learning
approaches are trained on trajectory data to achieve this task. However
trajectory data captured by sensor systems is highly imbalanced, since by far
most of the trajectories follow straight lines with an approximately constant
velocity. This poses a huge challenge for the task of predicting future
positions, which is inherently a regression problem. Current state-of-the-art
approaches alleviate this problem only by major preprocessing of the training
data, e.g. resampling, clustering into anchors etc. In this paper we propose an
approach which reformulates the prediction problem as a classification task,
allowing for powerful tools, e.g. focal loss, to combat the imbalance. To this
end we design a generative probabilistic model consisting of a deep neural
network with a Mixture of Gaussian head. A smart choice of the latent variable
allows for the reformulation of the log-likelihood function as a combination of
a classification problem and a much simplified regression problem. The output
of our model is an estimate of the probability density function of future
positions, hence allowing for prediction of multiple possible positions while
also estimating their probabilities. The proposed approach can easily
incorporate context information and does not require any preprocessing of the
data.
</p>
<a href="http://arxiv.org/abs/2010.00802" target="_blank">arXiv:2010.00802</a> [<a href="http://arxiv.org/pdf/2010.00802" target="_blank">pdf</a>]

<h2>Deep4Air: A Novel Deep Learning Framework for Airport Airside Surveillance. (arXiv:2010.00806v1 [cs.CV])</h2>
<h3>Phat Thai, Sameer Alam, Nimrod Lilith, Phu N. Tran, Binh Nguyen Thanh</h3>
<p>An airport runway and taxiway (airside) area is a highly dynamic and complex
environment featuring interactions between different types of vehicles (speed
and dimension), under varying visibility and traffic conditions. Airport ground
movements are deemed safety-critical activities, and safe-separation procedures
must be maintained by Air Traffic Controllers (ATCs). Large airports with
complicated runway-taxiway systems use advanced ground surveillance systems.
However, these systems have inherent limitations and a lack of real-time
analytics. In this paper, we propose a novel computer-vision based framework,
namely "Deep4Air", which can not only augment the ground surveillance systems
via the automated visual monitoring of runways and taxiways for aircraft
location, but also provide real-time speed and distance analytics for aircraft
on runways and taxiways. The proposed framework includes an adaptive deep
neural network for efficiently detecting and tracking aircraft. The
experimental results show an average precision of detection and tracking of up
to 99.8% on simulated data with validations on surveillance videos from the
digital tower at George Bush Intercontinental Airport. The results also
demonstrate that "Deep4Air" can locate aircraft positions relative to the
airport runway and taxiway infrastructure with high accuracy. Furthermore,
aircraft speed and separation distance are monitored in real-time, providing
enhanced safety management.
</p>
<a href="http://arxiv.org/abs/2010.00806" target="_blank">arXiv:2010.00806</a> [<a href="http://arxiv.org/pdf/2010.00806" target="_blank">pdf</a>]

<h2>Overcoming Data Sparsity in Group Recommendation. (arXiv:2010.00813v1 [cs.IR])</h2>
<h3>Hongzhi Yin, Qinyong Wang, Kai Zheng, Zhixu Li, Xiaofang Zhou</h3>
<p>It has been an important task for recommender systems to suggest satisfying
activities to a group of users in people's daily social life. The major
challenge in this task is how to aggregate personal preferences of group
members to infer the decision of a group. Conventional group recommendation
methods applied a predefined strategy for preference aggregation. However,
these static strategies are too simple to model the real and complex process of
group decision-making, especially for occasional groups which are formed
ad-hoc. Moreover, group members should have non-uniform influences or weights
in a group, and the weight of a user can be varied in different groups.
Therefore, an ideal group recommender system should be able to accurately learn
not only users' personal preferences but also the preference aggregation
strategy from data. In this paper, we propose a novel end-to-end group
recommender system named CAGR (short for Centrality Aware Group Recommender"),
which takes Bipartite Graph Embedding Model (BGEM), the self-attention
mechanism and Graph Convolutional Networks (GCNs) as basic building blocks to
learn group and user representations in a unified way. Specifically, we first
extend BGEM to model group-item interactions, and then in order to overcome the
limitation and sparsity of the interaction data generated by occasional groups,
we propose a self-attentive mechanism to represent groups based on the group
members. In addition, to overcome the sparsity issue of user-item interaction
data, we leverage the user social networks to enhance user representation
learning, obtaining centrality-aware user representations. We create three
large-scale benchmark datasets and conduct extensive experiments on them. The
experimental results show the superiority of our proposed CAGR by comparing it
with state-of-the-art group recommender models.
</p>
<a href="http://arxiv.org/abs/2010.00813" target="_blank">arXiv:2010.00813</a> [<a href="http://arxiv.org/pdf/2010.00813" target="_blank">pdf</a>]

<h2>Discriminative and Generative Models for Anatomical Shape Analysison Point Clouds with Deep Neural Networks. (arXiv:2010.00820v1 [cs.CV])</h2>
<h3>Benjamin Gutierrez Becker, Ignacio Sarasua, Christian Wachinger</h3>
<p>We introduce deep neural networks for the analysis of anatomical shapes that
learn a low-dimensional shape representation from the given task, instead of
relying on hand-engineered representations. Our framework is modular and
consists of several computing blocks that perform fundamental shape processing
tasks. The networks operate on unordered point clouds and provide invariance to
similarity transformations, avoiding the need to identify point correspondences
between shapes. Based on the framework, we assemble a discriminative model for
disease classification and age regression, as well as a generative model for
the accruate reconstruction of shapes. In particular, we propose a conditional
generative model, where the condition vector provides a mechanism to control
the generative process. instance, it enables to assess shape variations
specific to a particular diagnosis, when passing it as side information. Next
to working on single shapes, we introduce an extension for the joint analysis
of multiple anatomical structures, where the simultaneous modeling of multiple
structures can lead to a more compact encoding and a better understanding of
disorders. We demonstrate the advantages of our framework in comprehensive
experiments on real and synthetic data. The key insights are that (i) learning
a shape representation specific to the given task yields higher performance
than alternative shape descriptors, (ii) multi-structure analysis is both more
efficient and more accurate than single-structure analysis, and (iii) point
clouds generated by our model capture morphological differences associated to
Alzheimers disease, to the point that they can be used to train a
discriminative model for disease classification. Our framework naturally scales
to the analysis of large datasets, giving it the potential to learn
characteristic variations in large populations.
</p>
<a href="http://arxiv.org/abs/2010.00820" target="_blank">arXiv:2010.00820</a> [<a href="http://arxiv.org/pdf/2010.00820" target="_blank">pdf</a>]

<h2>Explainable Online Validation of Machine Learning Models for Practical Applications. (arXiv:2010.00821v1 [cs.LG])</h2>
<h3>Wolfgang Fuhl, Yao Rong, Thomas Motz, Michael Scheidt, Andreas Hartel, Andreas Koch, Enkelejda Kasneci</h3>
<p>We present a reformulation of the regression and classification, which aims
to validate the result of a machine learning algorithm. Our reformulation
simplifies the original problem and validates the result of the machine
learning algorithm using the training data. Since the validation of machine
learning algorithms must always be explainable, we perform our experiments with
the kNN algorithm as well as with an algorithm based on conditional
probabilities, which is proposed in this work. For the evaluation of our
approach, three publicly available data sets were used and three classification
and two regression problems were evaluated. The presented algorithm based on
conditional probabilities is also online capable and requires only a fraction
of memory compared to the kNN algorithm.
</p>
<a href="http://arxiv.org/abs/2010.00821" target="_blank">arXiv:2010.00821</a> [<a href="http://arxiv.org/pdf/2010.00821" target="_blank">pdf</a>]

<h2>Deep Composer Classification Using Symbolic Representation. (arXiv:2010.00823v1 [cs.SD])</h2>
<h3>Sunghyeon Kim, Hyeyoon Lee, Sunjong Park, Jinho Lee, Keunwoo Choi</h3>
<p>In this study, we train deep neural networks to classify composer on a
symbolic domain. The model takes a two-channel two-dimensional input, i.e.,
onset and note activations of time-pitch representation, which is converted
from MIDI recordings and performs a single-label classification. On the
experiments conducted on MAESTRO dataset, we report an F1 value of 0.8333 for
the classification of 13~classical composers.
</p>
<a href="http://arxiv.org/abs/2010.00823" target="_blank">arXiv:2010.00823</a> [<a href="http://arxiv.org/pdf/2010.00823" target="_blank">pdf</a>]

<h2>Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds. (arXiv:2010.00824v1 [cs.RO])</h2>
<h3>Lirui Wang, Yu Xiang, Dieter Fox</h3>
<p>6D robotic grasping beyond top-down bin-picking scenarios is a challenging
task. Previous solutions based on 6D grasp synthesis with robot motion planning
usually operate in an open-loop setting without considering the dynamics and
contacts of objects, which makes them sensitive to grasp synthesis errors. In
this work, we propose a novel method for learning closed-loop control policies
for 6D robotic grasping using point clouds from an egocentric camera. We
combine imitation learning and reinforcement learning in order to grasp unseen
objects and handle the continuous 6D action space, where expert demonstrations
are obtained from a joint motion and grasp planner. We introduce a
goal-auxiliary actor-critic algorithm, which uses grasping goal prediction as
an auxiliary task to facilitate policy learning. The supervision on grasping
goals can be obtained from the expert planner for known objects or from
hindsight goals for unknown objects. Overall, our learned closed-loop policy
achieves over 90% success rates on grasping various ShapeNet objects and YCB
objects in the simulation. Our video can be found at
https://www.youtube.com/watch?v=rKsCRXLykiY&amp;t=1s .
</p>
<a href="http://arxiv.org/abs/2010.00824" target="_blank">arXiv:2010.00824</a> [<a href="http://arxiv.org/pdf/2010.00824" target="_blank">pdf</a>]

<h2>Incorporating Machine Learning to Evaluate Solutions to the University Course Timetabling Problem. (arXiv:2010.00826v1 [cs.NE])</h2>
<h3>Patrick Kenekayoro</h3>
<p>Evaluating solutions to optimization problems is arguably the most important
step for heuristic algorithms, as it is used to guide the algorithms towards
the optimal solution in the solution search space. Research has shown
evaluation functions to some optimization problems to be impractical to compute
and have thus found surrogate less expensive evaluation functions to those
problems. This study investigates the extent to which supervised learning
algorithms can be used to find approximations to evaluation functions for the
university course timetabling problem. Up to 97 percent of the time, the
traditional evaluation function agreed with the supervised learning regression
model on the result of comparison of the quality of pair of solutions to the
university course timetabling problem, suggesting that supervised learning
regression models can be suitable alternatives for optimization problems'
evaluation functions.
</p>
<a href="http://arxiv.org/abs/2010.00826" target="_blank">arXiv:2010.00826</a> [<a href="http://arxiv.org/pdf/2010.00826" target="_blank">pdf</a>]

<h2>Neural Thompson Sampling. (arXiv:2010.00827v1 [cs.LG])</h2>
<h3>Weitong Zhang, Dongruo Zhou, Lihong Li, Quanquan Gu</h3>
<p>Thompson Sampling (TS) is one of the most effective algorithms for solving
contextual multi-armed bandit problems. In this paper, we propose a new
algorithm, called Neural Thompson Sampling, which adapts deep neural networks
for both exploration and exploitation. At the core of our algorithm is a novel
posterior distribution of the reward, where its mean is the neural network
approximator, and its variance is built upon the neural tangent features of the
corresponding neural network. We prove that, provided the underlying reward
function is bounded, the proposed algorithm is guaranteed to achieve a
cumulative regret of $\mathcal{O}(T^{1/2})$, which matches the regret of other
contextual bandit algorithms in terms of total round number $T$. Experimental
comparisons with other benchmark bandit algorithms on various data sets
corroborate our theory.
</p>
<a href="http://arxiv.org/abs/2010.00827" target="_blank">arXiv:2010.00827</a> [<a href="http://arxiv.org/pdf/2010.00827" target="_blank">pdf</a>]

<h2>Continuous close-range 3D object pose estimation. (arXiv:2010.00829v1 [cs.RO])</h2>
<h3>Bjarne Grossmann, Francesco Rovida, Volker Krueger</h3>
<p>In the context of future manufacturing lines, removing fixtures will be a
fundamental step to increase the flexibility of autonomous systems in assembly
and logistic operations. Vision-based 3D pose estimation is a necessity to
accurately handle objects that might not be placed at fixed positions during
the robot task execution. Industrial tasks bring multiple challenges for the
robust pose estimation of objects such as difficult object properties, tight
cycle times and constraints on camera views. In particular, when interacting
with objects, we have to work with close-range partial views of objects that
pose a new challenge for typical view-based pose estimation methods. In this
paper, we present a 3D pose estimation method based on a gradient-ascend
particle filter that integrates new observations on-the-fly to improve the pose
estimate. Thereby, we can apply this method online during task execution to
save valuable cycle time. In contrast to other view-based pose estimation
methods, we model potential views in full 6- dimensional space that allows us
to cope with close-range partial objects views. We demonstrate the approach on
a real assembly task, in which the algorithm usually converges to the correct
pose within 10-15 iterations with an average accuracy of less than 8mm.
</p>
<a href="http://arxiv.org/abs/2010.00829" target="_blank">arXiv:2010.00829</a> [<a href="http://arxiv.org/pdf/2010.00829" target="_blank">pdf</a>]

<h2>CAPTION: Correction by Analyses, POS-Tagging and Interpretation of Objects using only Nouns. (arXiv:2010.00839v1 [cs.CV])</h2>
<h3>Leonardo Anjoletto Ferreira, Douglas De Rizzo Meneghetti, Paulo Eduardo Santos</h3>
<p>Recently, Deep Learning (DL) methods have shown an excellent performance in
image captioning and visual question answering. However, despite their
performance, DL methods do not learn the semantics of the words that are being
used to describe a scene, making it difficult to spot incorrect words used in
captions or to interchange words that have similar meanings. This work proposes
a combination of DL methods for object detection and natural language
processing to validate image's captions. We test our method in the FOIL-COCO
data set, since it provides correct and incorrect captions for various images
using only objects represented in the MS-COCO image data set. Results show that
our method has a good overall performance, in some cases similar to the human
performance.
</p>
<a href="http://arxiv.org/abs/2010.00839" target="_blank">arXiv:2010.00839</a> [<a href="http://arxiv.org/pdf/2010.00839" target="_blank">pdf</a>]

<h2>MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models. (arXiv:2010.00840v1 [cs.CL])</h2>
<h3>Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Raul Puri, Pascale Fung, Anima Anandkumar, Bryan Catanzaro</h3>
<p>Existing pre-trained large language models have shown unparalleled generative
capabilities. However, they are not controllable. In this paper, we propose
MEGATRON-CNTRL, a novel framework that uses large-scale language models and
adds control to text generation by incorporating an external knowledge base.
Our framework consists of a keyword predictor, a knowledge retriever, a
contextual knowledge ranker, and a conditional text generator. As we do not
have access to ground-truth supervision for the knowledge ranker, we make use
of weak supervision from sentence embedding. The empirical results show that
our model generates more fluent, consistent, and coherent stories with less
repetition and higher diversity compared to prior work on the ROC story
dataset. We showcase the controllability of our model by replacing the keywords
used to generate stories and re-running the generation process. Human
evaluation results show that 77.5% of these stories are successfully controlled
by the new keywords. Furthermore, by scaling our model from 124 million to 8.3
billion parameters we demonstrate that larger models improve both the quality
of generation (from 74.5% to 93.0% for consistency) and controllability (from
77.5% to 91.5%).
</p>
<a href="http://arxiv.org/abs/2010.00840" target="_blank">arXiv:2010.00840</a> [<a href="http://arxiv.org/pdf/2010.00840" target="_blank">pdf</a>]

<h2>Which *BERT? A Survey Organizing Contextualized Encoders. (arXiv:2010.00854v1 [cs.CL])</h2>
<h3>Patrick Xia, Shijie Wu, Benjamin Van Durme</h3>
<p>Pretrained contextualized text encoders are now a staple of the NLP
community. We present a survey on language representation learning with the aim
of consolidating a series of shared lessons learned across a variety of recent
efforts. While significant advancements continue at a rapid pace, we find that
enough has now been discovered, in different directions, that we can begin to
organize advances according to common themes. Through this organization, we
highlight important considerations when interpreting recent contributions and
choosing which model to use.
</p>
<a href="http://arxiv.org/abs/2010.00854" target="_blank">arXiv:2010.00854</a> [<a href="http://arxiv.org/pdf/2010.00854" target="_blank">pdf</a>]

<h2>Weight and Gradient Centralization in Deep Neural Networks. (arXiv:2010.00866v1 [cs.CV])</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>Batch normalization is currently the most widely used variant of internal
normalization for deep neural networks. Additional work has shown that the
normalization of weights and additional conditioning as well as the
normalization of gradients further improve the generalization. In this work, we
combine several of these methods and thereby increase the generalization of the
networks. The advantage of the newer methods compared to the batch
normalization is not only increased generalization, but also that these methods
only have to be applied during training and, therefore, do not influence the
running time during use. Link to CUDA code
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/
</p>
<a href="http://arxiv.org/abs/2010.00866" target="_blank">arXiv:2010.00866</a> [<a href="http://arxiv.org/pdf/2010.00866" target="_blank">pdf</a>]

<h2>Rotated Ring, Radial and Depth Wise Separable Radial Convolutions. (arXiv:2010.00873v1 [cs.CV])</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>Simple image rotations significantly reduce the accuracy of deep neural
networks. Moreover, training with all possible rotations increases the data
set, which also increases the training duration. In this work, we address
trainable rotation invariant convolutions as well as the construction of nets,
since fully connected layers can only be rotation invariant with a
one-dimensional input. On the one hand, we show that our approach is
rotationally invariant for different models and on different public data sets.
We also discuss the influence of purely rotational invariant features on
accuracy. The rotationally adaptive convolution models presented in this work
are more computationally intensive than normal convolution models. Therefore,
we also present a depth wise separable approach with radial convolution. Link
to CUDA code
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/
</p>
<a href="http://arxiv.org/abs/2010.00873" target="_blank">arXiv:2010.00873</a> [<a href="http://arxiv.org/pdf/2010.00873" target="_blank">pdf</a>]

<h2>Understanding Approximate Fisher Information for Fast Convergence of Natural Gradient Descent in Wide Neural Networks. (arXiv:2010.00879v1 [stat.ML])</h2>
<h3>Ryo Karakida, Kazuki Osawa</h3>
<p>Natural Gradient Descent (NGD) helps to accelerate the convergence of
gradient descent dynamics, but it requires approximations in large-scale deep
neural networks because of its high computational cost. Empirical studies have
confirmed that some NGD methods with approximate Fisher information converge
sufficiently fast in practice. Nevertheless, it remains unclear from the
theoretical perspective why and under what conditions such heuristic
approximations work well. In this work, we reveal that, under specific
conditions, NGD with approximate Fisher information achieves the same fast
convergence to global minima as exact NGD. We consider deep neural networks in
the infinite-width limit, and analyze the asymptotic training dynamics of NGD
in function space via the neural tangent kernel. In the function space, the
training dynamics with the approximate Fisher information are identical to
those with the exact Fisher information, and they converge quickly. The fast
convergence holds in layer-wise approximations; for instance, in block diagonal
approximation where each block corresponds to a layer as well as in block
tri-diagonal and K-FAC approximations. We also find that a unit-wise
approximation achieves the same fast convergence under some assumptions. All of
these different approximations have an isotropic gradient in the function
space, and this plays a fundamental role in achieving the same convergence
properties in training. Thus, the current study gives a novel and unified
theoretical foundation with which to understand NGD methods in deep learning.
</p>
<a href="http://arxiv.org/abs/2010.00879" target="_blank">arXiv:2010.00879</a> [<a href="http://arxiv.org/pdf/2010.00879" target="_blank">pdf</a>]

<h2>Remote Sensing Image Scene Classification with Self-Supervised Paradigm under Limited Labeled Samples. (arXiv:2010.00882v1 [cs.CV])</h2>
<h3>Chao Tao, Ji Qi, Weipeng Lu, Hao Wang, Haifeng Li</h3>
<p>With the development of deep learning, supervised learning methods perform
well in remote sensing images (RSIs) scene classification. However, supervised
learning requires a huge number of annotated data for training. When labeled
samples are not sufficient, the most common solution is to fine-tune the
pre-training models using a large natural image dataset (e.g. ImageNet).
However, this learning paradigm is not a panacea, especially when the target
remote sensing images (e.g. multispectral and hyperspectral data) have
different imaging mechanisms from RGB natural images. To solve this problem, we
introduce new self-supervised learning (SSL) mechanism to obtain the
high-performance pre-training model for RSIs scene classification from large
unlabeled data. Experiments on three commonly used RSIs scene classification
datasets demonstrated that this new learning paradigm outperforms the
traditional dominant ImageNet pre-trained model. Moreover, we analyze the
impacts of several factors in SSL on RSIs scene classification tasks, including
the choice of self-supervised signals, the domain difference between the source
and target dataset, and the amount of pre-training data. The insights distilled
from our studies can help to foster the development of SSL in the remote
sensing community. Since SSL could learn from unlabeled massive RSIs which are
extremely easy to obtain, it will be a potentially promising way to alleviate
dependence on labeled samples and thus efficiently solve many problems, such as
global mapping.
</p>
<a href="http://arxiv.org/abs/2010.00882" target="_blank">arXiv:2010.00882</a> [<a href="http://arxiv.org/pdf/2010.00882" target="_blank">pdf</a>]

<h2>DIETERpy: a Python framework for The Dispatch and Investment Evaluation Tool with Endogenous Renewables. (arXiv:2010.00883v1 [cs.CY])</h2>
<h3>Carlos Gaete-Morales, Martin Kittel, Alexander Roth, Wolf-Peter Schill, Alexander Zerrahn</h3>
<p>DIETER is an open-source power sector model designed to analyze future
settings with very high shares of variable renewable energy sources. It
minimizes overall system costs, including fixed and variable costs of various
generation, storage and sector coupling options. Here we introduce DIETERpy
that builds on the existing model version, written in the General Algebraic
Modeling System (GAMS), and enhances it with a Python framework. This combines
the flexibility of Python regarding pre- and post-processing of data with a
straightforward algebraic formulation in GAMS and the use of efficient solvers.
DIETERpy also offers a browser-based graphical user interface. The new
framework is designed to be easily accessible as it enables users to run the
model, alter its configuration, and define numerous scenarios without a deeper
knowledge of GAMS. Code, data, and manuals are available in public repositories
under permissive licenses for transparency and reproducibility.
</p>
<a href="http://arxiv.org/abs/2010.00883" target="_blank">arXiv:2010.00883</a> [<a href="http://arxiv.org/pdf/2010.00883" target="_blank">pdf</a>]

<h2>Impact of Short Blocklength Coding on Stability of an AGV Control System in Industry 4.0. (arXiv:2010.00884v1 [eess.SY])</h2>
<h3>Shreya Tayade, Peter Rost, Andreas Maeder, Hans D Schotten</h3>
<p>With the advent of 5G and beyond, using wireless communication for
closed-loop control and automation processes is one of the main aspects of the
envisioned Industry 4.0. In this regard, a major challenge is to ensure a
robust and stable control system over an unreliable wireless channel. One of
the main use-cases in this context is Automated Guided Vehicle (AGV) control in
a future factory. Specifically, we consider a system where an AGV controller is
placed in an edge cloud in the factory network infrastructure and the control
commands are sent over a time-correlated Rayleigh fading channel. In an
industrial control, short packets are exchanged between the controller and the
actuator. Therefore, in this case, Shannon's assumption for an infinite block
length is not applicable. The objective is to analyse the stability performance
of an AGV control system in a Finite Block-Length (FBL) regime. We evaluate the
coding rate required to maintain a stable edge cloud based AGV system. The
results illustrate that adapting the control parameters can lower the stringent
requirements on the coding rate. It reveals that a constant stability
performance can be achieved even at higher coding rate by increasing the AGV's
velocity. Moreover, this paper also determines the maximum number of AGVs that
can be served seamlessly over the available communication resources while
maintaining a stable control system.
</p>
<a href="http://arxiv.org/abs/2010.00884" target="_blank">arXiv:2010.00884</a> [<a href="http://arxiv.org/pdf/2010.00884" target="_blank">pdf</a>]

<h2>No Spurious Local Minima: on the Optimization Landscapes of Wide and Deep Neural Networks. (arXiv:2010.00885v1 [cs.LG])</h2>
<h3>Johannes Lederer</h3>
<p>Empirical studies suggest that wide neural networks are comparably easy to
optimize, but mathematical support for this observation is scarce. In this
paper, we analyze the optimization landscapes of deep learning with wide
networks. We prove especially that constraint and unconstraint empirical-risk
minimization over such networks has no spurious local minima. Hence, our
theories substantiate the common belief that increasing network widths not only
improves the expressiveness of deep-learning pipelines but also facilitates
their optimizations.
</p>
<a href="http://arxiv.org/abs/2010.00885" target="_blank">arXiv:2010.00885</a> [<a href="http://arxiv.org/pdf/2010.00885" target="_blank">pdf</a>]

<h2>Time Matters: Time-Aware LSTMs for Predictive Business Process Monitoring. (arXiv:2010.00889v1 [cs.LG])</h2>
<h3>An Nguyen, Srijeet Chatterjee, Sven Weinzierl, Leo Schwinn, Martin Matzner, Bjoern Eskofier</h3>
<p>Predictive business process monitoring (PBPM) aims to predict future process
behavior during ongoing process executions based on event log data. Especially,
techniques for the next activity and timestamp prediction can help to improve
the performance of operational business processes. Recently, many PBPM
solutions based on deep learning were proposed by researchers. Due to the
sequential nature of event log data, a common choice is to apply recurrent
neural networks with long short-term memory (LSTM) cells. We argue, that the
elapsed time between events is informative. However, current PBPM techniques
mainly use 'vanilla' LSTM cells and hand-crafted time-related control flow
features. To better model the time dependencies between events, we propose a
new PBPM technique based on time-aware LSTM (T-LSTM) cells. T-LSTM cells
incorporate the elapsed time between consecutive events inherently to adjust
the cell memory. Furthermore, we introduce cost-sensitive learning to account
for the common class imbalance in event logs. Our experiments on publicly
available benchmark event logs indicate the effectiveness of the introduced
techniques.
</p>
<a href="http://arxiv.org/abs/2010.00889" target="_blank">arXiv:2010.00889</a> [<a href="http://arxiv.org/pdf/2010.00889" target="_blank">pdf</a>]

<h2>Weight Encode Reconstruction Network for Computed Tomography in a Semi-Case-Wise and Learning-Based Way. (arXiv:2010.00893v1 [eess.IV])</h2>
<h3>Hujie Pan, Xuesong Li, Min Xu</h3>
<p>Classic algebraic reconstruction technology (ART) for computed tomography
requires pre-determined weights of the voxels for projecting pixel values.
However, such weight cannot be accurately obtained due to the limitation of the
physical understanding and computation resources. In this study, we propose a
semi-case-wise learning-based method named Weight Encode Reconstruction Network
(WERNet) to tackle the issues mentioned above. The model is trained in a
self-supervised manner without the label of a voxel set. It contains two
branches, including the voxel weight encoder and the voxel attention part.
Using gradient normalization, we are able to co-train the encoder and voxel set
numerically stably. With WERNet, the reconstructed result was obtained with a
cosine similarity greater than 0.999 with the ground truth. Moreover, the model
shows the extraordinary capability of denoising comparing to the classic ART
method. In the generalization test of the model, the encoder is transferable
from a voxel set with complex structure to the unseen cases without the
deduction of the accuracy.
</p>
<a href="http://arxiv.org/abs/2010.00893" target="_blank">arXiv:2010.00893</a> [<a href="http://arxiv.org/pdf/2010.00893" target="_blank">pdf</a>]

<h2>An Evaluation of Classification Methods for 3D Printing Time-Series Data. (arXiv:2010.00903v1 [cs.LG])</h2>
<h3>Vivek Mahato, Muhannad Ahmed Obeidi, Dermot Brabazon, Padraig Cunningham</h3>
<p>Additive Manufacturing presents a great application area for Machine Learning
because of the vast volume of data generated and the potential to mine this
data to control outcomes. In this paper we present preliminary work on
classifying infrared time-series data representing melt-pool temperature in a
metal 3D printing process. Our ultimate objective is to use this data to
predict process outcomes (e.g. hardness, porosity, surface roughness). In the
work presented here we simply show that there is a signal in this data that can
be used for the classification of different components and stages of the AM
process. In line with other Machine Learning research on time-series
classification we use k-Nearest Neighbour classifiers. The results we present
suggests that Dynamic Time Warping is an effective distance measure compared
with alternatives for 3D printing data of this type.
</p>
<a href="http://arxiv.org/abs/2010.00903" target="_blank">arXiv:2010.00903</a> [<a href="http://arxiv.org/pdf/2010.00903" target="_blank">pdf</a>]

<h2>Self-Play Reinforcement Learning for Fast Image Retargeting. (arXiv:2010.00909v1 [cs.CV])</h2>
<h3>Nobukatsu Kajiura, Satoshi Kosugi, Xueting Wang, Toshihiko Yamasaki</h3>
<p>In this study, we address image retargeting, which is a task that adjusts
input images to arbitrary sizes. In one of the best-performing methods called
MULTIOP, multiple retargeting operators were combined and retargeted images at
each stage were generated to find the optimal sequence of operators that
minimized the distance between original and retargeted images. The limitation
of this method is in its tremendous processing time, which severely prohibits
its practical use. Therefore, the purpose of this study is to find the optimal
combination of operators within a reasonable processing time; we propose a
method of predicting the optimal operator for each step using a reinforcement
learning agent. The technical contributions of this study are as follows.
Firstly, we propose a reward based on self-play, which will be insensitive to
the large variance in the content-dependent distance measured in MULTIOP.
Secondly, we propose to dynamically change the loss weight for each action to
prevent the algorithm from falling into a local optimum and from choosing only
the most frequently used operator in its training. Our experiments showed that
we achieved multi-operator image retargeting with less processing time by three
orders of magnitude and the same quality as the original multi-operator-based
method, which was the best-performing algorithm in retargeting tasks.
</p>
<a href="http://arxiv.org/abs/2010.00909" target="_blank">arXiv:2010.00909</a> [<a href="http://arxiv.org/pdf/2010.00909" target="_blank">pdf</a>]

<h2>Continual Learning for Natural Language Generation in Task-oriented Dialog Systems. (arXiv:2010.00910v1 [cs.CL])</h2>
<h3>Fei Mi, Liangwei Chen, Mengjie Zhao, Minlie Huang, Boi Faltings</h3>
<p>Natural language generation (NLG) is an essential component of task-oriented
dialog systems. Despite the recent success of neural approaches for NLG, they
are typically developed in an offline manner for particular domains. To better
fit real-life applications where new data come in a stream, we study NLG in a
"continual learning" setting to expand its knowledge to new domains or
functionalities incrementally. The major challenge towards this goal is
catastrophic forgetting, meaning that a continually trained model tends to
forget the knowledge it has learned before. To this end, we propose a method
called ARPER (Adaptively Regularized Prioritized Exemplar Replay) by replaying
prioritized historical exemplars, together with an adaptive regularization
technique based on ElasticWeight Consolidation. Extensive experiments to
continually learn new domains and intents are conducted on MultiWoZ-2.0 to
benchmark ARPER with a wide range of techniques. Empirical results demonstrate
that ARPER significantly outperforms other methods by effectively mitigating
the detrimental catastrophic forgetting issue.
</p>
<a href="http://arxiv.org/abs/2010.00910" target="_blank">arXiv:2010.00910</a> [<a href="http://arxiv.org/pdf/2010.00910" target="_blank">pdf</a>]

<h2>GECKO: Reconciling Privacy, Accuracy and Efficiency in Embedded Deep Learning. (arXiv:2010.00912v1 [cs.CR])</h2>
<h3>Vasisht Duddu, Antoine Boutet, Virat Shejwalkar</h3>
<p>Embedded systems demand on-device processing of data using Neural Networks
(NNs) while conforming to the memory, power and computation constraints,
leading to an efficiency and accuracy tradeoff. To bring NNs to edge devices,
several optimizations such as model compression through pruning, quantization,
and off-the-shelf architectures with efficient design have been extensively
adopted. These algorithms when deployed to real world sensitive applications,
requires to resist inference attacks to protect privacy of users training data.
However, resistance against inference attacks is not accounted for designing NN
models for IoT. In this work, we analyse the three-dimensional
privacy-accuracy-efficiency tradeoff in NNs for IoT devices and propose Gecko
training methodology where we explicitly add resistance to private inferences
as a design objective. We optimize the inference-time memory, computation, and
power constraints of embedded devices as a criterion for designing NN
architecture while also preserving privacy. We choose quantization as design
choice for highly efficient and private models. This choice is driven by the
observation that compressed models leak more information compared to baseline
models while off-the-shelf efficient architectures indicate poor efficiency and
privacy tradeoff. We show that models trained using Gecko methodology are
comparable to prior defences against black-box membership attacks in terms of
accuracy and privacy while providing efficiency.
</p>
<a href="http://arxiv.org/abs/2010.00912" target="_blank">arXiv:2010.00912</a> [<a href="http://arxiv.org/pdf/2010.00912" target="_blank">pdf</a>]

<h2>Coded Stochastic ADMM for Decentralized Consensus Optimization with Edge Computing. (arXiv:2010.00914v1 [cs.DC])</h2>
<h3>Hao Chen, Yu Ye, Ming Xiao, Mikael Skoglund, H. Vincent Poor</h3>
<p>Big data, including applications with high security requirements, are often
collected and stored on multiple heterogeneous devices, such as mobile devices,
drones and vehicles. Due to the limitations of communication costs and security
requirements, it is of paramount importance to extract information in a
decentralized manner instead of aggregating data to a fusion center. To train
large-scale machine learning models, edge/fog computing is often leveraged as
an alternative to centralized learning. We consider the problem of learning
model parameters in a multi-agent system with data locally processed via
distributed edge nodes. A class of mini-batch stochastic alternating direction
method of multipliers (ADMM) algorithms is explored to develop the distributed
learning model. To address two main critical challenges in distributed
networks, i.e., communication bottleneck and straggler nodes (nodes with slow
responses), error-control-coding based stochastic incremental ADMM is
investigated. Given an appropriate mini-batch size, we show that the mini-batch
stochastic ADMM based method converges in a rate of $O(\frac{1}{\sqrt{k}})$,
where $k$ denotes the number of iterations. Through numerical experiments, it
is revealed that the proposed algorithm is communication-efficient, rapidly
responding and robust in the presence of straggler nodes compared with state of
the art algorithms.
</p>
<a href="http://arxiv.org/abs/2010.00914" target="_blank">arXiv:2010.00914</a> [<a href="http://arxiv.org/pdf/2010.00914" target="_blank">pdf</a>]

<h2>A straightforward line search approach on the expected empirical loss for stochastic deep learning problems. (arXiv:2010.00921v1 [cs.LG])</h2>
<h3>Maximus Mutschler, Andreas Zell</h3>
<p>A fundamental challenge in deep learning is that the optimal step sizes for
update steps of stochastic gradient descent are unknown. In traditional
optimization, line searches are used to determine good step sizes, however, in
deep learning, it is too costly to search for good step sizes on the expected
empirical loss due to noisy losses. This empirical work shows that it is
possible to approximate the expected empirical loss on vertical cross sections
for common deep learning tasks considerably cheaply. This is achieved by
applying traditional one-dimensional function fitting to measured noisy losses
of such cross sections. The step to a minimum of the resulting approximation is
then used as step size for the optimization. This approach leads to a robust
and straightforward optimization method which performs well across datasets and
architectures without the need of hyperparameter tuning.
</p>
<a href="http://arxiv.org/abs/2010.00921" target="_blank">arXiv:2010.00921</a> [<a href="http://arxiv.org/pdf/2010.00921" target="_blank">pdf</a>]

<h2>Image-based underwater 3D reconstruction for Cultural Heritage: from image collection to 3D. Critical steps and considerations. (arXiv:2010.00928v1 [cs.CV])</h2>
<h3>Dimitrios Skarlatos, Panagiotis Agrafiotis</h3>
<p>Underwater Cultural Heritage (CH) sites are widely spread; from ruins in
coastlines up to shipwrecks in deep. The documentation and preservation of this
heritage is an obligation of the mankind, dictated also by the international
treaties like the Convention on the Protection of the Underwater Cultural
Her-itage which fosters the use of "non-destructive techniques and survey
meth-ods in preference over the recovery of objects". However, submerged CH
lacks in protection and monitoring in regards to the land CH and nowadays
recording and documenting, for digital preservation as well as dissemination
through VR to wide public, is of most importance. At the same time, it is most
difficult to document it, due to inherent restrictions posed by the
environ-ment. In order to create high detailed textured 3D models, optical
sensors and photogrammetric techniques seems to be the best solution. This
chapter dis-cusses critical aspects of all phases of image based underwater 3D
reconstruc-tion process, from data acquisition and data preparation using
colour restora-tion and colour enhancement algorithms to Structure from Motion
(SfM) and Multi-View Stereo (MVS) techniques to produce an accurate, precise
and complete 3D model for a number of applications.
</p>
<a href="http://arxiv.org/abs/2010.00928" target="_blank">arXiv:2010.00928</a> [<a href="http://arxiv.org/pdf/2010.00928" target="_blank">pdf</a>]

<h2>A Deep-Unfolded Reference-Based RPCA Network For Video Foreground-Background Separation. (arXiv:2010.00929v1 [cs.LG])</h2>
<h3>Huynh Van Luong, Boris Joukovsky, Yonina C. Eldar, Nikos Deligiannis</h3>
<p>Deep unfolded neural networks are designed by unrolling the iterations of
optimization algorithms. They can be shown to achieve faster convergence and
higher accuracy than their optimization counterparts. This paper proposes a new
deep-unfolding-based network design for the problem of Robust Principal
Component Analysis (RPCA) with application to video foreground-background
separation. Unlike existing designs, our approach focuses on modeling the
temporal correlation between the sparse representations of consecutive video
frames. To this end, we perform the unfolding of an iterative algorithm for
solving reweighted $\ell_1$-$\ell_1$ minimization; this unfolding leads to a
different proximal operator (a.k.a. different activation function) adaptively
learned per neuron. Experimentation using the moving MNIST dataset shows that
the proposed network outperforms a recently proposed state-of-the-art RPCA
network in the task of video foreground-background separation.
</p>
<a href="http://arxiv.org/abs/2010.00929" target="_blank">arXiv:2010.00929</a> [<a href="http://arxiv.org/pdf/2010.00929" target="_blank">pdf</a>]

<h2>Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies. (arXiv:2010.00951v1 [cs.LG])</h2>
<h3>T. Konstantin Rusch, Siddhartha Mishra</h3>
<p>Circuits of biological neurons, such as in the functional parts of the brain
can be modeled as networks of coupled oscillators. Inspired by the ability of
these systems to express a rich set of outputs while keeping (gradients of)
state variables bounded, we propose a novel architecture for recurrent neural
networks. Our proposed RNN is based on a time-discretization of a system of
second-order ordinary differential equations, modeling networks of controlled
nonlinear oscillators. We prove precise bounds on the gradients of the hidden
states, leading to the mitigation of the exploding and vanishing gradient
problem for this RNN. Experiments show that the proposed RNN is comparable in
performance to the state of the art on a variety of benchmarks, demonstrating
the potential of this architecture to provide stable and accurate RNNs for
processing complex sequential data.
</p>
<a href="http://arxiv.org/abs/2010.00951" target="_blank">arXiv:2010.00951</a> [<a href="http://arxiv.org/pdf/2010.00951" target="_blank">pdf</a>]

<h2>Deep Learning Based Computer-Aided Systems for Breast Cancer Imaging : A Critical Review. (arXiv:2010.00961v1 [eess.IV])</h2>
<h3>Yuliana Jim&#xe9;nez-Gaona, Mar&#xed;a Jos&#xe9; Rodr&#xed;guez-&#xc1;lvarez, Vasudevan Lakshminarayanan</h3>
<p>This paper provides a critical review of the literature on deep learning
applications in breast tumor diagnosis using ultrasound and mammography images.
It also summarizes recent advances in computer-aided diagnosis (CAD) systems,
which make use of new deep learning methods to automatically recognize images
and improve the accuracy of diagnosis made by radiologists. This review is
based upon published literature in the past decade (January 2010 January 2020).
The main findings in the classification process reveal that new DL-CAD methods
are useful and effective screening tools for breast cancer, thus reducing the
need for manual feature extraction. The breast tumor research community can
utilize this survey as a basis for their current and future studies.
</p>
<a href="http://arxiv.org/abs/2010.00961" target="_blank">arXiv:2010.00961</a> [<a href="http://arxiv.org/pdf/2010.00961" target="_blank">pdf</a>]

<h2>Augmenting Machine Learning with Information Retrieval to Recommend Real Cloned Code Methods for Code Completion. (arXiv:2010.00964v1 [cs.SE])</h2>
<h3>Muhammad Hammad, &#xd6;nder Babur, Hamid Abdul Basit</h3>
<p>Software developers frequently reuse source code from repositories as it
saves development time and effort. Code clones accumulated in these
repositories hence represent often repeated functionalities and are candidates
for reuse in an exploratory or rapid development. In previous work, we
introduced DeepClone, a deep neural network model trained by fine tuning GPT-2
model over the BigCloneBench dataset to predict code clone methods. The
probabilistic nature of DeepClone output generation can lead to syntax and
logic errors that requires manual editing of the output for final reuse. In
this paper, we propose a novel approach of applying an information retrieval
(IR) technique on top of DeepClone output to recommend real clone methods
closely matching the predicted output. We have quantitatively evaluated our
strategy, showing that the proposed approach significantly improves the quality
of recommendation.
</p>
<a href="http://arxiv.org/abs/2010.00964" target="_blank">arXiv:2010.00964</a> [<a href="http://arxiv.org/pdf/2010.00964" target="_blank">pdf</a>]

<h2>RISA-Net: Rotation-Invariant Structure-Aware Network for Fine-Grained 3D Shape Retrieval. (arXiv:2010.00973v1 [cs.CV])</h2>
<h3>Rao Fu, Jie Yang, Jiawei Sun, Fang-Lue Zhang, Yu-Kun Lai, Lin Gao</h3>
<p>Fine-grained 3D shape retrieval aims to retrieve 3D shapes similar to a query
shape in a repository with models belonging to the same class, which requires
shape descriptors to be capable of representing detailed geometric information
to discriminate shapes with globally similar structures. Moreover, 3D objects
can be placed with arbitrary position and orientation in real-world
applications, which further requires shape descriptors to be robust to rigid
transformations. The shape descriptions used in existing 3D shape retrieval
systems fail to meet the above two criteria. In this paper, we introduce a
novel deep architecture, RISA-Net, which learns rotation invariant 3D shape
descriptors that are capable of encoding fine-grained geometric information and
structural information, and thus achieve accurate results on the task of
fine-grained 3D object retrieval. RISA-Net extracts a set of compact and
detailed geometric features part-wisely and discriminatively estimates the
contribution of each semantic part to shape representation. Furthermore, our
method is able to learn the importance of geometric and structural information
of all the parts when generating the final compact latent feature of a 3D shape
for fine-grained retrieval. We also build and publish a new 3D shape dataset
with sub-class labels for validating the performance of fine-grained 3D shape
retrieval methods. Qualitative and quantitative experiments show that our
RISA-Net outperforms state-of-the-art methods on the fine-grained object
retrieval task, demonstrating its capability in geometric detail extraction.
The code and dataset are available at: https://github.com/IGLICT/RisaNET.
</p>
<a href="http://arxiv.org/abs/2010.00973" target="_blank">arXiv:2010.00973</a> [<a href="http://arxiv.org/pdf/2010.00973" target="_blank">pdf</a>]

<h2>Taking Modality-free Human Identification as Zero-shot Learning. (arXiv:2010.00975v1 [cs.CV])</h2>
<h3>Zhizhe Liu, Xingxing Zhang, Zhenfeng Zhu, Shuai Zheng, Yao Zhao, Jian Cheng</h3>
<p>Human identification is an important topic in event detection, person
tracking, and public security. There have been numerous methods proposed for
human identification, such as face identification, person re-identification,
and gait identification. Typically, existing methods predominantly classify a
queried image to a specific identity in an image gallery set (I2I). This is
seriously limited for the scenario where only a textual description of the
query or an attribute gallery set is available in a wide range of video
surveillance applications (A2I or I2A). However, very few efforts have been
devoted towards modality-free identification, i.e., identifying a query in a
gallery set in a scalable way. In this work, we take an initial attempt, and
formulate such a novel Modality-Free Human Identification (named MFHI) task as
a generic zero-shot learning model in a scalable way. Meanwhile, it is capable
of bridging the visual and semantic modalities by learning a discriminative
prototype of each identity. In addition, the semantics-guided spatial attention
is enforced on visual modality to obtain representations with both high global
category-level and local attribute-level discrimination. Finally, we design and
conduct an extensive group of experiments on two common challenging
identification tasks, including face identification and person
re-identification, demonstrating that our method outperforms a wide variety of
state-of-the-art methods on modality-free human identification.
</p>
<a href="http://arxiv.org/abs/2010.00975" target="_blank">arXiv:2010.00975</a> [<a href="http://arxiv.org/pdf/2010.00975" target="_blank">pdf</a>]

<h2>Group Equivariant Stand-Alone Self-Attention For Vision. (arXiv:2010.00977v1 [cs.CV])</h2>
<h3>David W. Romero, Jean-Baptiste Cordonnier</h3>
<p>We provide a general self-attention formulation to impose group equivariance
to arbitrary symmetry groups. This is achieved by defining positional encodings
that are invariant to the action of the group considered. Since the group acts
on the positional encoding directly, group equivariant self-attention networks
(GSA-Nets) are steerable by nature. Our experiments on vision benchmarks
demonstrate consistent improvements of GSA-Nets over non-equivariant
self-attention networks.
</p>
<a href="http://arxiv.org/abs/2010.00977" target="_blank">arXiv:2010.00977</a> [<a href="http://arxiv.org/pdf/2010.00977" target="_blank">pdf</a>]

<h2>BOSS: Bayesian Optimization over String Spaces. (arXiv:2010.00979v1 [cs.LG])</h2>
<h3>Henry B. Moss, Daniel Beck, Javier Gonzalez, David S. Leslie, Paul Rayson</h3>
<p>This article develops a Bayesian optimization (BO) method which acts directly
over raw strings, proposing the first uses of string kernels and genetic
algorithms within BO loops. Recent applications of BO over strings have been
hindered by the need to map inputs into a smooth and unconstrained latent
space. Learning this projection is computationally and data-intensive. Our
approach instead builds a powerful Gaussian process surrogate model based on
string kernels, naturally supporting variable length inputs, and performs
efficient acquisition function maximization for spaces with syntactical
constraints. Experiments demonstrate considerably improved optimization over
existing approaches across a broad range of constraints, including the popular
setting where syntax is governed by a context-free grammar.
</p>
<a href="http://arxiv.org/abs/2010.00979" target="_blank">arXiv:2010.00979</a> [<a href="http://arxiv.org/pdf/2010.00979" target="_blank">pdf</a>]

<h2>MultiCQA: Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale. (arXiv:2010.00980v1 [cs.CL])</h2>
<h3>Andreas R&#xfc;ckl&#xe9;, Jonas Pfeiffer, Iryna Gurevych</h3>
<p>We study the zero-shot transfer capabilities of text matching models on a
massive scale, by self-supervised training on 140 source domains from community
question answering forums in English. We investigate the model performances on
nine benchmarks of answer selection and question similarity tasks, and show
that all 140 models transfer surprisingly well, where the large majority of
models substantially outperforms common IR baselines. We also demonstrate that
considering a broad selection of source domains is crucial for obtaining the
best zero-shot transfer performances, which contrasts the standard procedure
that merely relies on the largest and most similar domains. In addition, we
extensively study how to best combine multiple source domains. We propose to
incorporate self-supervised with supervised multi-task learning on all
available source domains. Our best zero-shot transfer model considerably
outperforms in-domain BERT and the previous state of the art on six benchmarks.
Fine-tuning of our model with in-domain data results in additional large gains
and achieves the new state of the art on all nine benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.00980" target="_blank">arXiv:2010.00980</a> [<a href="http://arxiv.org/pdf/2010.00980" target="_blank">pdf</a>]

<h2>An Empirical Study of DNNs Robustification Inefficacy in Protecting Visual Recommenders. (arXiv:2010.00984v1 [cs.IR])</h2>
<h3>Vito Walter Anelli, Tommaso Di Noia, Daniele Malitesta, Felice Antonio Merra</h3>
<p>Visual-based recommender systems (VRSs) enhance recommendation performance by
integrating users' feedback with the visual features of product images
extracted from a deep neural network (DNN). Recently, human-imperceptible
images perturbations, defined \textit{adversarial attacks}, have been
demonstrated to alter the VRSs recommendation performance, e.g., pushing/nuking
category of products. However, since adversarial training techniques have
proven to successfully robustify DNNs in preserving classification accuracy, to
the best of our knowledge, two important questions have not been investigated
yet: 1) How well can these defensive mechanisms protect the VRSs performance?
2) What are the reasons behind ineffective/effective defenses? To answer these
questions, we define a set of defense and attack settings, as well as
recommender models, to empirically investigate the efficacy of defensive
mechanisms. The results indicate alarming risks in protecting a VRS through the
DNN robustification. Our experiments shed light on the importance of visual
features in very effective attack scenarios. Given the financial impact of VRSs
on many companies, we believe this work might rise the need to investigate how
to successfully protect visual-based recommenders. Source code and data are
available at
https://anonymous.4open.science/r/868f87ca-c8a4-41ba-9af9-20c41de33029/.
</p>
<a href="http://arxiv.org/abs/2010.00984" target="_blank">arXiv:2010.00984</a> [<a href="http://arxiv.org/pdf/2010.00984" target="_blank">pdf</a>]

<h2>RDCNet: Instance segmentation with a minimalist recurrent residual network. (arXiv:2010.00991v1 [cs.CV])</h2>
<h3>Raphael Ortiz, Gustavo de Medeiros, Antoine H.F.M. Peters, Prisca Liberali, Markus Rempfler</h3>
<p>Instance segmentation is a key step for quantitative microscopy. While
several machine learning based methods have been proposed for this problem,
most of them rely on computationally complex models that are trained on
surrogate tasks. Building on recent developments towards end-to-end trainable
instance segmentation, we propose a minimalist recurrent network called
recurrent dilated convolutional network (RDCNet), consisting of a shared
stacked dilated convolution (sSDC) layer that iteratively refines its output
and thereby generates interpretable intermediate predictions. It is
light-weight and has few critical hyperparameters, which can be related to
physical aspects such as object size or density.We perform a sensitivity
analysis of its main parameters and we demonstrate its versatility on 3 tasks
with different imaging modalities: nuclear segmentation of H&amp;E slides, of 3D
anisotropic stacks from light-sheet fluorescence microscopy and leaf
segmentation of top-view images of plants. It achieves state-of-the-art on 2 of
the 3 datasets.
</p>
<a href="http://arxiv.org/abs/2010.00991" target="_blank">arXiv:2010.00991</a> [<a href="http://arxiv.org/pdf/2010.00991" target="_blank">pdf</a>]

<h2>MADRaS : Multi Agent Driving Simulator. (arXiv:2010.00993v1 [cs.RO])</h2>
<h3>Anirban Santara, Sohan Rudra, Sree Aditya Buridi, Meha Kaushik, Abhishek Naik, Bharat Kaul, Balaraman Ravindran</h3>
<p>In this work, we present MADRaS, an open-source multi-agent driving simulator
for use in the design and evaluation of motion planning algorithms for
autonomous driving. MADRaS provides a platform for constructing a wide variety
of highway and track driving scenarios where multiple driving agents can train
for motion planning tasks using reinforcement learning and other machine
learning algorithms. MADRaS is built on TORCS, an open-source car-racing
simulator. TORCS offers a variety of cars with different dynamic properties and
driving tracks with different geometries and surface properties. MADRaS
inherits these functionalities from TORCS and introduces support for
multi-agent training, inter-vehicular communication, noisy observations,
stochastic actions, and custom traffic cars whose behaviours can be programmed
to simulate challenging traffic conditions encountered in the real world.
MADRaS can be used to create driving tasks whose complexities can be tuned
along eight axes in well-defined steps. This makes it particularly suited for
curriculum and continual learning. MADRaS is lightweight and it provides a
convenient OpenAI Gym interface for independent control of each car. Apart from
the primitive steering-acceleration-brake control mode of TORCS, MADRaS offers
a hierarchical track-position -- speed control that can potentially be used to
achieve better generalization. MADRaS uses multiprocessing to run each agent as
a parallel process for efficiency and integrates well with popular
reinforcement learning libraries like RLLib.
</p>
<a href="http://arxiv.org/abs/2010.00993" target="_blank">arXiv:2010.00993</a> [<a href="http://arxiv.org/pdf/2010.00993" target="_blank">pdf</a>]

<h2>Differentiable Weighted Finite-State Transducers. (arXiv:2010.01003v1 [cs.LG])</h2>
<h3>Awni Hannun, Vineel Pratap, Jacob Kahn, Wei-Ning Hsu</h3>
<p>We introduce a framework for automatic differentiation with weighted
finite-state transducers (WFSTs) allowing them to be used dynamically at
training time. Through the separation of graphs from operations on graphs, this
framework enables the exploration of new structured loss functions which in
turn eases the encoding of prior knowledge into learning algorithms. We show
how the framework can combine pruning and back-off in transition models with
various sequence-level loss functions. We also show how to learn over the
latent decomposition of phrases into word pieces. Finally, to demonstrate that
WFSTs can be used in the interior of a deep neural network, we propose a
convolutional WFST layer which maps lower-level representations to higher-level
representations and can be used as a drop-in replacement for a traditional
convolution. We validate these algorithms with experiments in handwriting
recognition and speech recognition.
</p>
<a href="http://arxiv.org/abs/2010.01003" target="_blank">arXiv:2010.01003</a> [<a href="http://arxiv.org/pdf/2010.01003" target="_blank">pdf</a>]

<h2>Deep Convolutional Transform Learning -- Extended version. (arXiv:2010.01011v1 [cs.LG])</h2>
<h3>Jyoti Maggu, Angshul Majumdar, Emilie Chouzenoux, Giovanni Chierchia</h3>
<p>This work introduces a new unsupervised representation learning technique
called Deep Convolutional Transform Learning (DCTL). By stacking convolutional
transforms, our approach is able to learn a set of independent kernels at
different layers. The features extracted in an unsupervised manner can then be
used to perform machine learning tasks, such as classification and clustering.
The learning technique relies on a well-sounded alternating proximal
minimization scheme with established convergence guarantees. Our experimental
results show that the proposed DCTL technique outperforms its shallow version
CTL, on several benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2010.01011" target="_blank">arXiv:2010.01011</a> [<a href="http://arxiv.org/pdf/2010.01011" target="_blank">pdf</a>]

<h2>Model-Agnostic Round-Optimal Federated Learning via Knowledge Transfer. (arXiv:2010.01017v1 [cs.LG])</h2>
<h3>Qinbin Li, Bingsheng He, Dawn Song</h3>
<p>Federated learning enables multiple parties to collaboratively learn a model
without exchanging their local data. Currently, federated averaging (FedAvg) is
the most widely used federated learning algorithm. However, FedAvg or its
variants have obvious shortcomings. It can only be used to learn differentiable
models and needs many communication rounds to converge. In this paper, we
propose a novel federated learning algorithm FedKT that needs only a single
communication round (i.e., round-optimal). With applying the knowledge transfer
approach, our algorithm can be applied to any classification model. Moreover,
we develop the differentially private versions of FedKT and theoretically
analyze the privacy loss. The experiments show that our method can achieve
close or better accuracy compared with the other state-of-the-art federated
learning algorithms.
</p>
<a href="http://arxiv.org/abs/2010.01017" target="_blank">arXiv:2010.01017</a> [<a href="http://arxiv.org/pdf/2010.01017" target="_blank">pdf</a>]

<h2>Memory Clustering using Persistent Homology for Multimodality- and Discontinuity-Sensitive Learning of Optimal Control Warm-starts. (arXiv:2010.01024v1 [cs.RO])</h2>
<h3>Wolfgang Merkt, Vladimir Ivan, Traiko Dinev, Ioannis Havoutis, Sethu Vijayakumar</h3>
<p>Shooting methods are an efficient approach to solving nonlinear optimal
control problems. As they use local optimization, they exhibit favorable
convergence when initialized with a good warm-start but may not converge at all
if provided with a poor initial guess. Recent work has focused on providing an
initial guess from a learned model trained on samples generated during an
offline exploration of the problem space. However, in practice the solutions
contain discontinuities introduced by system dynamics or the environment.
Additionally, in many cases multiple equally suitable, i.e., multi-modal,
solutions exist to solve a problem. Classic learning approaches smooth across
the boundary of these discontinuities and thus generalize poorly. In this work,
we apply tools from algebraic topology to extract information on the underlying
structure of the solution space. In particular, we introduce a method based on
persistent homology to automatically cluster the dataset of precomputed
solutions to obtain different candidate initial guesses. We then train a
Mixture-of-Experts within each cluster to predict initial guesses and provide a
comparison with modality-agnostic learning. We demonstrate our method on a
cart-pole toy problem and a quadrotor avoiding obstacles, and show that
clustering samples based on inherent structure improves the warm-start quality.
</p>
<a href="http://arxiv.org/abs/2010.01024" target="_blank">arXiv:2010.01024</a> [<a href="http://arxiv.org/pdf/2010.01024" target="_blank">pdf</a>]

<h2>Hard Negative Mixing for Contrastive Learning. (arXiv:2010.01028v1 [cs.CV])</h2>
<h3>Yannis Kalantidis, Mert Bulent Sariyildiz, Noe Pion, Philippe Weinzaepfel, Diane Larlus</h3>
<p>Contrastive learning has become a key component of self-supervised learning
approaches for computer vision. By learning to embed two augmented versions of
the same image close to each other and to push the embeddings of different
images apart, one can train highly transferable visual representations. As
revealed by recent studies, heavy data augmentation and large sets of negatives
are both crucial in learning such representations. At the same time, data
mixing strategies either at the image or the feature level improve both
supervised and semi-supervised learning by synthesizing novel examples, forcing
networks to learn more robust features. In this paper, we argue that an
important aspect of contrastive learning, i.e., the effect of hard negatives,
has so far been neglected. To get more meaningful negative samples, current top
contrastive self-supervised learning approaches either substantially increase
the batch sizes, or keep very large memory banks; increasing the memory size,
however, leads to diminishing returns in terms of performance. We therefore
start by delving deeper into a top-performing framework and show evidence that
harder negatives are needed to facilitate better and faster learning. Based on
these observations, and motivated by the success of data mixing, we propose
hard negative mixing strategies at the feature level, that can be computed
on-the-fly with a minimal computational overhead. We exhaustively ablate our
approach on linear classification, object detection and instance segmentation
and show that employing our hard negative mixing procedure improves the quality
of visual representations learned by a state-of-the-art self-supervised
learning method.
</p>
<a href="http://arxiv.org/abs/2010.01028" target="_blank">arXiv:2010.01028</a> [<a href="http://arxiv.org/pdf/2010.01028" target="_blank">pdf</a>]

<h2>TeRo: A Time-aware Knowledge Graph Embedding via Temporal Rotation. (arXiv:2010.01029v1 [cs.CL])</h2>
<h3>Chengjin Xu, Mojtaba Nayyeri, Fouad Alkhoury, Hamed Shariat Yazdi, Jens Lehmann</h3>
<p>In the last few years, there has been a surge of interest in learning
representations of entitiesand relations in knowledge graph (KG). However, the
recent availability of temporal knowledgegraphs (TKGs) that contain time
information for each fact created the need for reasoning overtime in such TKGs.
In this regard, we present a new approach of TKG embedding, TeRo, which defines
the temporal evolution of entity embedding as a rotation from the initial time
to the currenttime in the complex vector space. Specially, for facts involving
time intervals, each relation isrepresented as a pair of dual complex
embeddings to handle the beginning and the end of therelation, respectively. We
show our proposed model overcomes the limitations of the existing KG embedding
models and TKG embedding models and has the ability of learning and
inferringvarious relation patterns over time. Experimental results on four
different TKGs show that TeRo significantly outperforms existing
state-of-the-art models for link prediction. In addition, we analyze the effect
of time granularity on link prediction over TKGs, which as far as we know
hasnot been investigated in previous literature.
</p>
<a href="http://arxiv.org/abs/2010.01029" target="_blank">arXiv:2010.01029</a> [<a href="http://arxiv.org/pdf/2010.01029" target="_blank">pdf</a>]

<h2>Machine-learning-enhanced time-of-flight mass spectrometry analysis. (arXiv:2010.01030v1 [cond-mat.mtrl-sci])</h2>
<h3>Ye Wei, Rama Srinivas Varanasi, Torsten Schwarz, Leonie Gomell, Huan Zhao, David J. Larson, Binhan Sun, Geng Liu, Hao Chen, Dierk Raabe, Baptiste Gault</h3>
<p>Mass spectrometry is a widespread approach to work out what are the
constituents of a material. Atoms and molecules are removed from the material
and collected, and subsequently, a critical step is to infer their correct
identities based from patterns formed in their mass-to-charge ratios and
relative isotopic abundances. However, this identification step still mainly
relies on individual user's expertise, making its standardization challenging,
and hindering efficient data processing. Here, we introduce an approach that
leverages modern machine learning technique to identify peak patterns in
time-of-flight mass spectra within microseconds, outperforming human users
without loss of accuracy. Our approach is cross-validated on mass spectra
generated from different time-of-flight mass spectrometry(ToF-MS) techniques,
offering the ToF-MS community an open-source, intelligent mass spectra
analysis.
</p>
<a href="http://arxiv.org/abs/2010.01030" target="_blank">arXiv:2010.01030</a> [<a href="http://arxiv.org/pdf/2010.01030" target="_blank">pdf</a>]

<h2>Numerical Methods to Compute the Coriolis Matrix and Christoffel Symbols for Rigid-Body Systems. (arXiv:2010.01033v1 [cs.RO])</h2>
<h3>Sebastian Echeandia, Patrick M. Wensing</h3>
<p>The growth of model-based control strategies for robotics platforms has led
to the need for additional rigid-body-dynamics algorithms to support their
operation. Toward addressing this need, this article summarizes efficient
numerical methods to compute the Coriolis matrix and underlying Christoffel
Symbols (of the first kind) for tree-structure rigid-body systems. The
resulting algorithms can be executed purely numerically, without requiring any
partial derivatives that would be required in symbolic techniques that do not
scale. Properties of the presented algorithms share recursive structure in
common with classical methods such as the Composite-Rigid-Body Algorithm. The
algorithms presented are of the lowest possible order: $O(Nd)$ for the Coriolis
Matrix and $O(Nd^2)$ for the Christoffel symbols, where $N$ is the number of
bodies and $d$ is the depth of the kinematic tree. A method of order $O(Nd)$ is
also provided to compute the time derivative of the mass matrix. A numerical
implementation of these algorithms in C/C++ is benchmarked showing computation
times on the order of 10-20 $\mu$s for the computation of the Coriolis matrix
and $40-120$ $\mu$s for the computation of the Christoffel symbols for systems
with $20$ degrees of freedom. These results demonstrate feasibility for the
adoption of these numerical methods within control loops that need to operate
at $1$kHz rates or higher, as is commonly required for model-based control
applications.
</p>
<a href="http://arxiv.org/abs/2010.01033" target="_blank">arXiv:2010.01033</a> [<a href="http://arxiv.org/pdf/2010.01033" target="_blank">pdf</a>]

<h2>Encoded Prior Sliced Wasserstein AutoEncoder for learning latent manifold representations. (arXiv:2010.01037v1 [cs.LG])</h2>
<h3>Sanjukta Krishnagopal, Jacob Bedrossian</h3>
<p>While variational autoencoders have been successful generative models for a
variety of tasks, the use of conventional Gaussian or Gaussian mixture priors
are limited in their ability to capture topological or geometric properties of
data in the latent representation. In this work, we introduce an Encoded Prior
Sliced Wasserstein AutoEncoder (EPSWAE) wherein an additional prior-encoder
network learns an unconstrained prior to match the encoded data manifold. The
autoencoder and prior-encoder networks are iteratively trained using the Sliced
Wasserstein Distance (SWD), which efficiently measures the distance between two
$\textit{arbitrary}$ sampleable distributions without being constrained to a
specific form as in the KL divergence, and without requiring expensive
adversarial training. Additionally, we enhance the conventional SWD by
introducing a nonlinear shearing, i.e., averaging over random
$\textit{nonlinear}$ transformations, to better capture differences between two
distributions. The prior is further encouraged to encode the data manifold by
use of a structural consistency term that encourages isometry between feature
space and latent space. Lastly, interpolation along $\textit{geodesics}$ on the
latent space representation of the data manifold generates samples that lie on
the manifold and hence is advantageous compared with standard Euclidean
interpolation. To this end, we introduce a graph-based algorithm for
identifying network-geodesics in latent space from samples of the prior that
maximize the density of samples along the path while minimizing total energy.
We apply our framework to 3D-spiral, MNIST, and CelebA datasets, and show that
its latent representations and interpolations are comparable to the state of
the art on equivalent architectures.
</p>
<a href="http://arxiv.org/abs/2010.01037" target="_blank">arXiv:2010.01037</a> [<a href="http://arxiv.org/pdf/2010.01037" target="_blank">pdf</a>]

<h2>Query complexity of adversarial attacks. (arXiv:2010.01039v1 [cs.LG])</h2>
<h3>Grzegorz G&#x142;uch, R&#xfc;diger Urbanke</h3>
<p>Modern machine learning models are typically highly accurate but have been
shown to be vulnerable to small, adversarially-chosen perturbations of the
input. There are two main models of attacks considered in the literature:
black-box and white-box. We consider these threat models as two ends of a
fine-grained spectrum, indexed by the number of queries the adversary can ask.
Using this point of view we investigate how many queries the adversary needs to
make to design an attack that is comparable to the best possible attack in the
white-box model. We analyze two classical learning algorithms on two synthetic
tasks for which we prove meaningful security guarantees. The obtained bounds
suggest that some learning algorithms are inherently more robust against
query-bounded adversaries than others.
</p>
<a href="http://arxiv.org/abs/2010.01039" target="_blank">arXiv:2010.01039</a> [<a href="http://arxiv.org/pdf/2010.01039" target="_blank">pdf</a>]

<h2>Attention-Based Clustering: Learning a Kernel from Context. (arXiv:2010.01040v1 [cs.LG])</h2>
<h3>Samuel Coward, Erik Visse-Martindale, Chithrupa Ramesh</h3>
<p>In machine learning, no data point stands alone. We believe that context is
an underappreciated concept in many machine learning methods. We propose
Attention-Based Clustering (ABC), a neural architecture based on the attention
mechanism, which is designed to learn latent representations that adapt to
context within an input set, and which is inherently agnostic to input sizes
and number of clusters. By learning a similarity kernel, our method directly
combines with any out-of-the-box kernel-based clustering approach. We present
competitive results for clustering Omniglot characters and include analytical
evidence of the effectiveness of an attention-based approach for clustering.
</p>
<a href="http://arxiv.org/abs/2010.01040" target="_blank">arXiv:2010.01040</a> [<a href="http://arxiv.org/pdf/2010.01040" target="_blank">pdf</a>]

<h2>Homography Estimation with Convolutional Neural Networks Under Conditions of Variance. (arXiv:2010.01041v1 [cs.CV])</h2>
<h3>David Niblick, Avinash Kak</h3>
<p>Planar homography estimation is foundational to many computer vision
problems, such as Simultaneous Localization and Mapping (SLAM) and Augmented
Reality (AR). However, conditions of high variance confound even the
state-of-the-art algorithms. In this report, we analyze the performance of two
recently published methods using Convolutional Neural Networks (CNNs) that are
meant to replace the more traditional feature-matching based approaches to the
estimation of homography. Our evaluation of the CNN based methods focuses
particularly on measuring the performance under conditions of significant
noise, illumination shift, and occlusion. We also measure the benefits of
training CNNs to varying degrees of noise. Additionally, we compare the effect
of using color images instead of grayscale images for inputs to CNNs. Finally,
we compare the results against baseline feature-matching based homography
estimation methods using SIFT, SURF, and ORB. We find that CNNs can be trained
to be more robust against noise, but at a small cost to accuracy in the
noiseless case. Additionally, CNNs perform significantly better in conditions
of extreme variance than their feature-matching based counterparts. With regard
to color inputs, we conclude that with no change in the CNN architecture to
take advantage of the additional information in the color planes, the
difference in performance using color inputs or grayscale inputs is negligible.
About the CNNs trained with noise-corrupted inputs, we show that training a CNN
to a specific magnitude of noise leads to a "Goldilocks Zone" with regard to
the noise levels where that CNN performs best.
</p>
<a href="http://arxiv.org/abs/2010.01041" target="_blank">arXiv:2010.01041</a> [<a href="http://arxiv.org/pdf/2010.01041" target="_blank">pdf</a>]

<h2>Relaxing the Constraints on Predictive Coding Models. (arXiv:2010.01047v1 [q-bio.NC])</h2>
<h3>Beren Millidge, Alexander Tschantz, Anil Seth, Christopher L Buckley</h3>
<p>Predictive coding is an influential theory of cortical function which posits
that the principal computation the brain performs, which underlies both
perception and learning, is the minimization of prediction errors. While
motivated by high-level notions of variational inference, detailed
neurophysiological models of cortical microcircuits which can implements its
computations have been developed. Moreover, under certain conditions,
predictive coding has been shown to approximate the backpropagation of error
algorithm, and thus provides a relatively biologically plausible
credit-assignment mechanism for training deep networks. However, standard
implementations of the algorithm still involve potentially neurally implausible
features such as identical forward and backward weights, backward nonlinear
derivatives, and 1-1 error unit connectivity. In this paper, we show that these
features are not integral to the algorithm and can be removed either directly
or through learning additional sets of parameters with Hebbian update rules
without noticeable harm to learning performance. Our work thus relaxes current
constraints on potential microcircuit designs and hopefully opens up new
regions of the design-space for neuromorphic implementations of predictive
coding.
</p>
<a href="http://arxiv.org/abs/2010.01047" target="_blank">arXiv:2010.01047</a> [<a href="http://arxiv.org/pdf/2010.01047" target="_blank">pdf</a>]

<h2>Model-Free Reinforcement Learning for Stochastic Games with Linear Temporal Logic Objectives. (arXiv:2010.01050v1 [cs.RO])</h2>
<h3>Alper Kamil Bozkurt, Yu Wang, Michael Zavlanos, Miroslav Pajic</h3>
<p>We study the problem of synthesizing control strategies for Linear Temporal
Logic (LTL) objectives in unknown environments. We model this problem as a
turn-based zero-sum stochastic game between the controller and the environment,
where the transition probabilities and the model topology are fully unknown.
The winning condition for the controller in this game is the satisfaction of
the given LTL specification, which can be captured by the acceptance condition
of a deterministic Rabin automaton (DRA) directly derived from the LTL
specification. We introduce a model-free reinforcement learning (RL)
methodology to find a strategy that maximizes the probability of satisfying a
given LTL specification when the Rabin condition of the derived DRA has a
single accepting pair. We then generalize this approach to LTL formulas for
which the Rabin condition has a larger number of accepting pairs, providing a
lower bound on the satisfaction probability. Finally, we illustrate
applicability of our RL method on two motion planning case studies.
</p>
<a href="http://arxiv.org/abs/2010.01050" target="_blank">arXiv:2010.01050</a> [<a href="http://arxiv.org/pdf/2010.01050" target="_blank">pdf</a>]

<h2>Neural Bootstrapper. (arXiv:2010.01051v1 [cs.LG])</h2>
<h3>Minsuk Shin, Hyungjoo Cho, Sungbin Lim</h3>
<p>Bootstrapping has been a primary tool for uncertainty quantification, and
their theoretical and computational properties have been investigated in the
field of statistics and machine learning. However, due to its nature of
repetitive computations, the computational burden required to implement
bootstrap procedures for the neural network is painfully heavy, and this fact
seriously hurdles the practical use of these procedures on the uncertainty
estimation of modern deep learning. To overcome the inconvenience, we propose a
procedure called \emph{Neural Bootstrapper} (NeuBoots). We reveal that the
NeuBoots stably generate valid bootstrap samples that coincide with the desired
target samples with minimal extra computational cost compared to traditional
bootstrapping. Consequently, NeuBoots makes it feasible to construct bootstrap
confidence intervals of outputs of neural networks and quantify their
predictive uncertainty. We also suggest NeuBoots for deep convolutional neural
networks to consider its utility in image classification tasks, including
calibration, detection of out-of-distribution samples, and active learning.
Empirical results demonstrate that NeuBoots is significantly beneficial for the
above purposes.
</p>
<a href="http://arxiv.org/abs/2010.01051" target="_blank">arXiv:2010.01051</a> [<a href="http://arxiv.org/pdf/2010.01051" target="_blank">pdf</a>]

<h2>LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention. (arXiv:2010.01057v1 [cs.CL])</h2>
<h3>Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto</h3>
<p>Entity representations are useful in natural language tasks involving
entities. In this paper, we propose new pretrained contextualized
representations of words and entities based on the bidirectional transformer.
The proposed model treats words and entities in a given text as independent
tokens, and outputs contextualized representations of them. Our model is
trained using a new pretraining task based on the masked language model of
BERT. The task involves predicting randomly masked words and entities in a
large entity-annotated corpus retrieved from Wikipedia. We also propose an
entity-aware self-attention mechanism that is an extension of the
self-attention mechanism of the transformer, and considers the types of tokens
(words or entities) when computing attention scores. The proposed model
achieves impressive empirical performance on a wide range of entity-related
tasks. In particular, it obtains state-of-the-art results on five well-known
datasets: Open Entity (entity typing), TACRED (relation classification),
CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering),
and SQuAD 1.1 (extractive question answering). Our source code and pretrained
representations are available at https://github.com/studio-ousia/luke.
</p>
<a href="http://arxiv.org/abs/2010.01057" target="_blank">arXiv:2010.01057</a> [<a href="http://arxiv.org/pdf/2010.01057" target="_blank">pdf</a>]

<h2>Long-Tail Zero and Few-Shot Learning via Contrastive Pretraining on and for Small Data. (arXiv:2010.01061v1 [cs.CL])</h2>
<h3>Nils Rethmeier, Isabelle Augenstein</h3>
<p>For natural language processing (NLP) tasks such as sentiment or topic
classification, currently prevailing approaches heavily rely on pretraining
large self-supervised models on massive external data resources. However, this
methodology is being critiqued for: exceptional compute and pretraining data
requirements; diminishing returns on both large and small datasets; and
importantly, favourable evaluation settings that overestimate performance
differences. The core belief behind current methodology, coined `the bitter
lesson' by R. Sutton, is that `compute scale-up beats data and
compute-efficient algorithms', neglecting that progress in compute hardware
scale-up is based almost entirely on the miniaturisation of resource
consumption. We thus approach pretraining from a miniaturisation perspective,
such as not to require massive external data sources and models, or learned
translations from continuous input embeddings to discrete labels. To minimise
overly favourable evaluation, we examine learning on a long-tailed,
low-resource, multi-label text classification dataset with noisy, highly sparse
labels and many rare concepts. To this end, we propose a novel
`dataset-internal' contrastive autoencoding approach to self-supervised
pretraining and demonstrate marked improvements in zero-shot, few-shot and
solely supervised learning performance; even under an unfavorable low-resource
scenario, and without defaulting to large-scale external datasets for
self-supervision. We also find empirical evidence that zero and few-shot
learning markedly benefit from adding more `dataset-internal', self-supervised
training signals, which is of practical importance when retrieving or computing
on large external sources of such signals is infeasible.
</p>
<a href="http://arxiv.org/abs/2010.01061" target="_blank">arXiv:2010.01061</a> [<a href="http://arxiv.org/pdf/2010.01061" target="_blank">pdf</a>]

<h2>Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning. (arXiv:2010.01062v1 [cs.LG])</h2>
<h3>Luisa Zintgraf, Leo Feng, Maximilian Igl, Kristian Hartikainen, Katja Hofmann, Shimon Whiteson</h3>
<p>Meta-learning is a powerful tool for learning policies that can adapt
efficiently when deployed in new tasks. If however the meta-training tasks have
sparse rewards, the need for exploration during meta-training is exacerbated
given that the agent has to explore and learn across many tasks. We show that
current meta-learning methods can fail catastrophically in such environments.
To address this problem, we propose HyperX, a novel method for meta-learning in
sparse reward tasks. Using novel reward bonuses for meta-training, we
incentivise the agent to explore in approximate hyper-state space, i.e., the
joint state and approximate belief space, where the beliefs are over tasks. We
show empirically that these bonuses allow an agent to successfully learn to
solve sparse reward tasks where existing meta-learning methods fail.
</p>
<a href="http://arxiv.org/abs/2010.01062" target="_blank">arXiv:2010.01062</a> [<a href="http://arxiv.org/pdf/2010.01062" target="_blank">pdf</a>]

<h2>Syntax Representation in Word Embeddings and Neural Networks -- A Survey. (arXiv:2010.01063v1 [cs.CL])</h2>
<h3>Tomasz Limisiewicz, David Mare&#x10d;ek</h3>
<p>Neural networks trained on natural language processing tasks capture syntax
even though it is not provided as a supervision signal. This indicates that
syntactic analysis is essential to the understating of language in artificial
intelligence systems. This overview paper covers approaches of evaluating the
amount of syntactic information included in the representations of words for
different neural network architectures. We mainly summarize re-search on
English monolingual data on language modeling tasks and multilingual data for
neural machine translation systems and multilingual language models. We
describe which pre-trained models and representations of language are best
suited for transfer to syntactic tasks.
</p>
<a href="http://arxiv.org/abs/2010.01063" target="_blank">arXiv:2010.01063</a> [<a href="http://arxiv.org/pdf/2010.01063" target="_blank">pdf</a>]

<h2>A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms. (arXiv:2010.01069v1 [cs.AI])</h2>
<h3>Shangtong Zhang, Romain Laroche, Harm van Seijen, Shimon Whiteson, Remi Tachet des Combes</h3>
<p>We investigate the discounting mismatch in actor-critic algorithm
implementations from a representation learning perspective. Theoretically,
actor-critic algorithms usually have discounting for both actor and critic,
i.e., there is a $\gamma^t$ term in the actor update for the transition
observed at time $t$ in a trajectory and the critic is a discounted value
function. Practitioners, however, usually ignore the discounting ($\gamma^t$)
for the actor while using a discounted critic. We investigate this mismatch in
two scenarios. In the first scenario, we consider optimizing an undiscounted
objective $(\gamma = 1)$ where $\gamma^t$ disappears naturally $(1^t = 1)$. We
then propose to interpret the discounting in critic in terms of a
bias-variance-representation trade-off and provide supporting empirical
results. In the second scenario, we consider optimizing a discounted objective
($\gamma &lt; 1$) and propose to interpret the omission of the discounting in the
actor update from an auxiliary task perspective and provide supporting
empirical results.
</p>
<a href="http://arxiv.org/abs/2010.01069" target="_blank">arXiv:2010.01069</a> [<a href="http://arxiv.org/pdf/2010.01069" target="_blank">pdf</a>]

<h2>On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach. (arXiv:2010.01079v1 [econ.TH])</h2>
<h3>Junpei Komiyama, Shunya Noda</h3>
<p>We analyze statistical discrimination using a multi-armed bandit model where
myopic firms face candidate workers arriving with heterogeneous observable
characteristics. The association between the worker's skill and characteristics
is unknown ex ante; thus, firms need to learn it. In such an environment,
laissez-faire may result in a highly unfair and inefficient outcome---myopic
firms are reluctant to hire minority workers because the lack of data about
minority workers prevents accurate estimation of their performance.
Consequently, minority groups could be perpetually underestimated---they are
never hired, and therefore, data about them is never accumulated. We proved
that this problem becomes more serious when the population ratio is imbalanced,
as is the case in many extant discrimination problems. We consider two
affirmative-action policies for solving this dilemma: One is a subsidy rule
that is based on the popular upper confidence bound algorithm, and another is
the Rooney Rule, which requires firms to interview at least one minority worker
for each hiring opportunity. Our results indicate temporary affirmative actions
are effective for statistical discrimination caused by data insufficiency.
</p>
<a href="http://arxiv.org/abs/2010.01079" target="_blank">arXiv:2010.01079</a> [<a href="http://arxiv.org/pdf/2010.01079" target="_blank">pdf</a>]

<h2>HUMAN: Hierarchical Universal Modular ANnotator. (arXiv:2010.01080v1 [cs.CL])</h2>
<h3>Moritz Wolf, Dana Ruiter, Ashwin Geet D&#x27;Sa, Liane Reiners, Jan Alexandersson, Dietrich Klakow</h3>
<p>A lot of real-world phenomena are complex and cannot be captured by single
task annotations. This causes a need for subsequent annotations, with
interdependent questions and answers describing the nature of the subject at
hand. Even in the case a phenomenon is easily captured by a single task, the
high specialisation of most annotation tools can result in having to switch to
another tool if the task only slightly changes.

We introduce HUMAN, a novel web-based annotation tool that addresses the
above problems by a) covering a variety of annotation tasks on both textual and
image data, and b) the usage of an internal deterministic state machine,
allowing the researcher to chain different annotation tasks in an
interdependent manner. Further, the modular nature of the tool makes it easy to
define new annotation tasks and integrate machine learning algorithms e.g., for
active learning. HUMAN comes with an easy-to-use graphical user interface that
simplifies the annotation task and management.
</p>
<a href="http://arxiv.org/abs/2010.01080" target="_blank">arXiv:2010.01080</a> [<a href="http://arxiv.org/pdf/2010.01080" target="_blank">pdf</a>]

<h2>Multi-Modal Open-Domain Dialogue. (arXiv:2010.01082v1 [cs.CL])</h2>
<h3>Kurt Shuster, Eric Michael Smith, Da Ju, Jason Weston</h3>
<p>Recent work in open-domain conversational agents has demonstrated that
significant improvements in model engagingness and humanness metrics can be
achieved via massive scaling in both pre-training data and model size
(Adiwardana et al., 2020; Roller et al., 2020). However, if we want to build
agents with human-like abilities, we must expand beyond handling just text. A
particularly important topic is the ability to see images and communicate about
what is perceived. With the goal of engaging humans in multi-modal dialogue, we
investigate combining components from state-of-the-art open-domain dialogue
agents with those from state-of-the-art vision models. We study incorporating
different image fusion schemes and domain-adaptive pre-training and fine-tuning
strategies, and show that our best resulting model outperforms strong existing
models in multi-modal dialogue while simultaneously performing as well as its
predecessor (text-only) BlenderBot (Roller et al., 2020) in text-based
conversation. We additionally investigate and incorporate safety components in
our final model, and show that such efforts do not diminish model performance
with respect to engagingness metrics.
</p>
<a href="http://arxiv.org/abs/2010.01082" target="_blank">arXiv:2010.01082</a> [<a href="http://arxiv.org/pdf/2010.01082" target="_blank">pdf</a>]

<h2>Semi-Supervised Learning for Multi-Task Scene Understanding by Neural Graph Consensus. (arXiv:2010.01086v1 [cs.CV])</h2>
<h3>Marius Leordeanu, Mihai Pirvu, Dragos Costea, Alina Marcu, Emil Slusanschi, Rahul Sukthankar</h3>
<p>We address the challenging problem of semi-supervised learning in the context
of multiple visual interpretations of the world by finding consensus in a graph
of neural networks. Each graph node is a scene interpretation layer, while each
edge is a deep net that transforms one layer at one node into another from a
different node. During the supervised phase edge networks are trained
independently. During the next unsupervised stage edge nets are trained on the
pseudo-ground truth provided by consensus among multiple paths that reach the
nets' start and end nodes. These paths act as ensemble teachers for any given
edge and strong consensus is used for high-confidence supervisory signal. The
unsupervised learning process is repeated over several generations, in which
each edge becomes a "student" and also part of different ensemble "teachers"
for training other students. By optimizing such consensus between different
paths, the graph reaches consistency and robustness over multiple
interpretations and generations, in the face of unknown labels. We give
theoretical justifications of the proposed idea and validate it on a large
dataset. We show how prediction of different representations such as depth,
semantic segmentation, surface normals and pose from RGB input could be
effectively learned through self-supervised consensus in our graph. We also
compare to state-of-the-art methods for multi-task and semi-supervised learning
and show superior performance.
</p>
<a href="http://arxiv.org/abs/2010.01086" target="_blank">arXiv:2010.01086</a> [<a href="http://arxiv.org/pdf/2010.01086" target="_blank">pdf</a>]

<h2>Pre-Training by Completing Point Clouds. (arXiv:2010.01089v1 [cs.CV])</h2>
<h3>Hanchen Wang, Qi Liu, Xiangyu Yue, Joan Lasenby, Matthew J. Kusner</h3>
<p>There has recently been a flurry of exciting advances in deep learning models
on point clouds. However, these advances have been hampered by the difficulty
of creating labelled point cloud datasets: sparse point clouds often have
unclear label identities for certain points, while dense point clouds are
time-consuming to annotate. Inspired by mask-based pre-training in the natural
language processing community, we propose a novel pre-training mechanism for
point clouds. It works by masking occluded points that result from observing
the point cloud at different camera views. It then optimizes a completion model
that learns how to reconstruct the occluded points, given the partial point
cloud. In this way, our method learns a pre-trained representation that can
identify the visual constraints inherently embedded in real-world point clouds.
We call our method Occlusion Completion (OcCo). We demonstrate that OcCo learns
representations that improve generalization on downstream tasks over prior
pre-training methods, that transfer to different datasets, that reduce training
time, and improve labelled sample efficiency. %, and (e) more effective than
previous pre-training methods. Our code and dataset are available at
https://github.com/hansen7/OcCo
</p>
<a href="http://arxiv.org/abs/2010.01089" target="_blank">arXiv:2010.01089</a> [<a href="http://arxiv.org/pdf/2010.01089" target="_blank">pdf</a>]

<h2>Dynamic Graph: Learning Instance-aware Connectivity for Neural Networks. (arXiv:2010.01097v1 [cs.CV])</h2>
<h3>Kun Yuan, Quanquan Li, Dapeng Chen, Aojun Zhou, Junjie Yan</h3>
<p>One practice of employing deep neural networks is to apply the same
architecture to all the input instances. However, a fixed architecture may not
be representative enough for data with high diversity. To promote the model
capacity, existing approaches usually employ larger convolutional kernels or
deeper network structure, which may increase the computational cost. In this
paper, we address this issue by raising the Dynamic Graph Network (DG-Net). The
network learns the instance-aware connectivity, which creates different forward
paths for different instances. Specifically, the network is initialized as a
complete directed acyclic graph, where the nodes represent convolutional blocks
and the edges represent the connection paths. We generate edge weights by a
learnable module \textit{router} and select the edges whose weights are larger
than a threshold, to adjust the connectivity of the neural network structure.
Instead of using the same path of the network, DG-Net aggregates features
dynamically in each node, which allows the network to have more representation
ability. To facilitate the training, we represent the network connectivity of
each sample in an adjacency matrix. The matrix is updated to aggregate features
in the forward pass, cached in the memory, and used for gradient computing in
the backward pass. We verify the effectiveness of our method with several
static architectures, including MobileNetV2, ResNet, ResNeXt, and RegNet.
Extensive experiments are performed on ImageNet classification and COCO object
detection, which shows the effectiveness and generalization ability of our
approach.
</p>
<a href="http://arxiv.org/abs/2010.01097" target="_blank">arXiv:2010.01097</a> [<a href="http://arxiv.org/pdf/2010.01097" target="_blank">pdf</a>]

<h2>Cross-Lingual Transfer Learning for Complex Word Identification. (arXiv:2010.01108v1 [cs.CL])</h2>
<h3>George-Eduard Zaharia, Dumitru-Clementin Cercel, Mihai Dascalu</h3>
<p>Complex Word Identification (CWI) is a task centered on detecting
hard-to-understand words, or groups of words, in texts from different areas of
expertise. The purpose of CWI is to highlight problematic structures that
non-native speakers would usually find difficult to understand. Our approach
uses zero-shot, one-shot, and few-shot learning techniques, alongside
state-of-the-art solutions for Natural Language Processing (NLP) tasks (i.e.,
Transformers). Our aim is to provide evidence that the proposed models can
learn the characteristics of complex words in a multilingual environment by
relying on the CWI shared task 2018 dataset available for four different
languages (i.e., English, German, Spanish, and also French). Our approach
surpasses state-of-the-art cross-lingual results in terms of macro F1-score on
English (0.774), German (0.782), and Spanish (0.734) languages, for the
zero-shot learning scenario. At the same time, our model also outperforms the
state-of-the-art monolingual result for German (0.795 macro F1-score).
</p>
<a href="http://arxiv.org/abs/2010.01108" target="_blank">arXiv:2010.01108</a> [<a href="http://arxiv.org/pdf/2010.01108" target="_blank">pdf</a>]

<h2>AIM 2020 Challenge on Image Extreme Inpainting. (arXiv:2010.01110v1 [cs.CV])</h2>
<h3>Evangelos Ntavelis, Andr&#xe9;s Romero, Siavash Bigdeli, Radu Timofte</h3>
<p>This paper reviews the AIM 2020 challenge on extreme image inpainting. This
report focuses on proposed solutions and results for two different tracks on
extreme image inpainting: classical image inpainting and semantically guided
image inpainting. The goal of track 1 is to inpaint considerably large part of
the image using no supervision but the context. Similarly, the goal of track 2
is to inpaint the image by having access to the entire semantic segmentation
map of the image to inpaint. The challenge had 88 and 74 participants,
respectively. 11 and 6 teams competed in the final phase of the challenge,
respectively. This report gauges current solutions and set a benchmark for
future extreme image inpainting methods.
</p>
<a href="http://arxiv.org/abs/2010.01110" target="_blank">arXiv:2010.01110</a> [<a href="http://arxiv.org/pdf/2010.01110" target="_blank">pdf</a>]

<h2>Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization. (arXiv:2010.01112v1 [cs.LG])</h2>
<h3>Lanqing Li, Rui Yang, Dijun Luo</h3>
<p>We study the offline meta-reinforcement learning (OMRL) problem, a paradigm
which enables reinforcement learning (RL) algorithms to quickly adapt to unseen
tasks without any interactions with the environments, making RL truly practical
in many real-world applications. This problem is still not fully understood,
for which two major challenges need to be addressed. First, offline RL often
suffers from bootstrapping errors of out-of-distribution state-actions which
leads to divergence of value functions. Second, meta-RL requires efficient and
robust task inference learned jointly with control policy. In this work, we
enforce behavior regularization on learned policy as a general approach to
offline RL, combined with a deterministic context encoder for efficient task
inference. We propose a novel negative-power distance metric on bounded context
embedding space, whose gradients propagation is detached from that of the
Bellman backup. We provide analysis and insight showing that some simple design
choices can yield substantial improvements over recent approaches involving
meta-RL and distance metric learning. To the best of our knowledge, our method
is the first model-free and end-to-end OMRL algorithm, which is computationally
efficient and demonstrated to outperform prior algorithms on several meta-RL
benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.01112" target="_blank">arXiv:2010.01112</a> [<a href="http://arxiv.org/pdf/2010.01112" target="_blank">pdf</a>]

<h2>Gaussian Process Molecule Property Prediction with FlowMO. (arXiv:2010.01118v1 [cs.LG])</h2>
<h3>Henry B. Moss, Ryan-Rhys Griffiths</h3>
<p>We present FlowMO: an open-source Python library for molecular property
prediction with Gaussian Processes. Built upon GPflow and RDKit, FlowMO enables
the user to make predictions with well-calibrated uncertainty estimates, an
output central to active learning and molecular design applications. Gaussian
Processes are particularly attractive for modelling small molecular datasets, a
characteristic of many real-world virtual screening campaigns where
high-quality experimental data is scarce. Computational experiments across
three small datasets demonstrate comparable predictive performance to deep
learning methods but with superior uncertainty calibration.
</p>
<a href="http://arxiv.org/abs/2010.01118" target="_blank">arXiv:2010.01118</a> [<a href="http://arxiv.org/pdf/2010.01118" target="_blank">pdf</a>]

<h2>Embedded Systems and Computer Vision Techniques utilized in Spray Painting Robots: A Review. (arXiv:2010.01131v1 [cs.CV])</h2>
<h3>Soham Shah, Siddhi Vinayak Pandey, Archit Sorathiya, Raj Sheth, Alok Kumar Singh, Jignesh Thaker</h3>
<p>The advent of the era of machines has limited human interaction and this has
increased their presence in the last decade. The requirement to increase the
effectiveness, durability and reliability in the robots has also risen quite
drastically too. Present paper covers the various embedded system and computer
vision methodologies, techniques and innovations used in the field of spray
painting robots. There have been many advancements in the sphere of painting
robots utilized for high rise buildings, wall painting, road marking paintings,
etc. Review focuses on image processing, computational and computer vision
techniques that can be applied in the product to increase efficiency of the
performance drastically. Image analysis, filtering, enhancement, object
detection, edge detection methods, path and localization methods and fine
tuning of parameters are being discussed in depth to use while developing such
products. Dynamic system design is being deliberated by using which results in
reduction of human interaction, environment sustainability and better quality
of work in detail. Embedded systems involving the micro-controllers,
processors, communicating devices, sensors and actuators, soft-ware to use
them; is being explained for end-to-end development and enhancement of accuracy
and precision in Spray Painting Robots.
</p>
<a href="http://arxiv.org/abs/2010.01131" target="_blank">arXiv:2010.01131</a> [<a href="http://arxiv.org/pdf/2010.01131" target="_blank">pdf</a>]

<h2>Time-Space Trade-offs for Triangulations and Voronoi Diagrams. (arXiv:1507.03403v3 [cs.CG] UPDATED)</h2>
<h3>Matias Korman, Wolfgang Mulzer, Andre van Renssen, Marcel Roeloffzen, Paul Seiferth, Yannik Stein</h3>
<p>Let $S$ be a planar $n$-point set. A triangulation for $S$ is a maximal plane
straight-line graph with vertex set $S$. The Voronoi diagram for $S$ is the
subdivision of the plane into cells such that all points in a cell have the
same nearest neighbor in $S$. Classically, both structures can be computed in
$O(n \log n)$ time and $O(n)$ space. We study the situation when the available
workspace is limited: given a parameter $s \in \{1, \dots, n\}$, an
$s$-workspace algorithm has read-only access to an input array with the points
from $S$ in arbitrary order, and it may use only $O(s)$ additional words of
$\Theta(\log n)$ bits for reading and writing intermediate data. The output
should then be written to a write-only structure. We describe a deterministic
$s$-workspace algorithm for computing an arbitrary triangulation of $S$ in time
$O(n^2/s + n \log n \log s )$ and a randomized $s$-workspace algorithm for
finding the Voronoi diagram of $S$ in expected time $O((n^2/s) \log s + n \log
s \log^*s)$.
</p>
<a href="http://arxiv.org/abs/1507.03403" target="_blank">arXiv:1507.03403</a> [<a href="http://arxiv.org/pdf/1507.03403" target="_blank">pdf</a>]

<h2>ART: Abstraction Refinement-Guided Training for Provably Correct Neural Networks. (arXiv:1907.10662v3 [cs.LG] UPDATED)</h2>
<h3>Xuankang Lin, He Zhu, Roopsha Samanta, Suresh Jagannathan</h3>
<p>Artificial Neural Networks (ANNs) have demonstrated remarkable utility in
various challenging machine learning applications. While formally verified
properties of their behaviors are highly desired, they have proven notoriously
difficult to derive and enforce. Existing approaches typically formulate this
problem as a post facto analysis process. In this paper, we present a novel
learning framework that ensures such formal guarantees are enforced by
construction. Our technique enables training provably correct networks with
respect to a broad class of safety properties, a capability that goes
well-beyond existing approaches, without compromising much accuracy. Our key
insight is that we can integrate an optimization-based abstraction refinement
loop into the learning process and operate over dynamically constructed
partitions of the input space that considers accuracy and safety objectives
synergistically. The refinement procedure iteratively splits the input space
from which training data is drawn, guided by the efficacy with which such
partitions enable safety verification. We have implemented our approach in a
tool (ART) and applied it to enforce general safety properties on unmanned
aviator collision avoidance system ACAS Xu dataset and the Collision Detection
dataset. Importantly, we empirically demonstrate that realizing safety does not
come at the price of much accuracy. Our methodology demonstrates that an
abstraction refinement methodology provides a meaningful pathway for building
both accurate and correct machine learning networks.
</p>
<a href="http://arxiv.org/abs/1907.10662" target="_blank">arXiv:1907.10662</a> [<a href="http://arxiv.org/pdf/1907.10662" target="_blank">pdf</a>]

<h2>Dynamic Pricing and Fleet Management for Electric Autonomous Mobility on Demand Systems. (arXiv:1909.06962v2 [eess.SY] UPDATED)</h2>
<h3>Berkay Turan, Ramtin Pedarsani, Mahnoosh Alizadeh</h3>
<p>The proliferation of ride sharing systems is a major drive in the advancement
of autonomous and electric vehicle technologies. This paper considers the joint
routing, battery charging, and pricing problem faced by a profit-maximizing
transportation service provider that operates a fleet of autonomous electric
vehicles. We first establish the static planning problem by considering
time-invariant system parameters and determine the optimal static policy. While
the static policy provides stability of customer queues waiting for rides even
if consider the system dynamics, we see that it is inefficient to utilize a
static policy as it can lead to long wait times for customers and low profits.
To accommodate for the stochastic nature of trip demands, renewable energy
availability, and electricity prices and to further optimally manage the
autonomous fleet given the need to generate integer allocations, a real-time
policy is required. The optimal real-time policy that executes actions based on
full state information of the system is the solution of a complex dynamic
program. However, we argue that it is intractable to exactly solve for the
optimal policy using exact dynamic programming methods and therefore apply deep
reinforcement learning to develop a near-optimal control policy. The two case
studies we conducted in Manhattan and San Francisco demonstrate the efficacy of
our real-time policy in terms of network stability and profits, while keeping
the queue lengths up to 200 times less than the static policy.
</p>
<a href="http://arxiv.org/abs/1909.06962" target="_blank">arXiv:1909.06962</a> [<a href="http://arxiv.org/pdf/1909.06962" target="_blank">pdf</a>]

<h2>A Joint Learning and Communications Framework for Federated Learning over Wireless Networks. (arXiv:1909.07972v3 [cs.NI] UPDATED)</h2>
<h3>Mingzhe Chen, Zhaohui Yang, Walid Saad, Changchuan Yin, H. Vincent Poor, Shuguang Cui</h3>
<p>In this paper, the problem of training federated learning (FL) algorithms
over a realistic wireless network is studied. In particular, in the considered
model, wireless users execute an FL algorithm while training their local FL
models using their own data and transmitting the trained local FL models to a
base station (BS) that will generate a global FL model and send it back to the
users. Since all training parameters are transmitted over wireless links, the
quality of the training will be affected by wireless factors such as packet
errors and the availability of wireless resources. Meanwhile, due to the
limited wireless bandwidth, the BS must select an appropriate subset of users
to execute the FL algorithm so as to build a global FL model accurately. This
joint learning, wireless resource allocation, and user selection problem is
formulated as an optimization problem whose goal is to minimize an FL loss
function that captures the performance of the FL algorithm. To address this
problem, a closed-form expression for the expected convergence rate of the FL
algorithm is first derived to quantify the impact of wireless factors on FL.
Then, based on the expected convergence rate of the FL algorithm, the optimal
transmit power for each user is derived, under a given user selection and
uplink resource block (RB) allocation scheme. Finally, the user selection and
uplink RB allocation is optimized so as to minimize the FL loss function.
Simulation results show that the proposed joint federated learning and
communication framework can reduce the FL loss function value by up to 10% and
16%, respectively, compared to: 1) An optimal user selection algorithm with
random resource allocation and 2) a standard FL algorithm with random user
selection and resource allocation.
</p>
<a href="http://arxiv.org/abs/1909.07972" target="_blank">arXiv:1909.07972</a> [<a href="http://arxiv.org/pdf/1909.07972" target="_blank">pdf</a>]

<h2>Multi-task Batch Reinforcement Learning with Metric Learning. (arXiv:1909.11373v5 [cs.LG] UPDATED)</h2>
<h3>Jiachen Li, Quan Vuong, Shuang Liu, Minghua Liu, Kamil Ciosek, Henrik Iskov Christensen, Hao Su</h3>
<p>We tackle the Multi-task Batch Reinforcement Learning problem. Given multiple
datasets collected from different tasks, we train a multi-task policy to
perform well in unseen tasks sampled from the same distribution. The task
identities of the unseen tasks are not provided. To perform well, the policy
must infer the task identity from collected transitions by modelling its
dependency on states, actions and rewards. Because the different datasets may
have state-action distributions with large divergence, the task inference
module can learn to ignore the rewards and spuriously correlate $\textit{only}$
state-action pairs to the task identity, leading to poor test time performance.
To robustify task inference, we propose a novel application of the triplet
loss. To mine hard negative examples, we relabel the transitions from the
training tasks by approximating their reward functions. When we allow further
training on the unseen tasks, using the trained policy as an initialization
leads to significantly faster convergence compared to randomly initialized
policies (up to $80\%$ improvement and across 5 different Mujoco task
distributions). We name our method $\textbf{MBML}$
($\textbf{M}\text{ulti-task}$ $\textbf{B}\text{atch}$ RL with
$\textbf{M}\text{etric}$ $\textbf{L}\text{earning}$).
</p>
<a href="http://arxiv.org/abs/1909.11373" target="_blank">arXiv:1909.11373</a> [<a href="http://arxiv.org/pdf/1909.11373" target="_blank">pdf</a>]

<h2>Cross-modal representation alignment of molecular structure and perturbation-induced transcriptional profiles. (arXiv:1911.10241v2 [q-bio.QM] UPDATED)</h2>
<h3>Samuel G. Finlayson, Matthew B.A. McDermott, Alex V. Pickering, Scott L. Lipnick, Isaac S. Kohane</h3>
<p>Modeling the relationship between chemical structure and molecular activity
is a key goal in drug development. Many benchmark tasks have been proposed for
molecular property prediction, but these tasks are generally aimed at specific,
isolated biomedical properties. In this work, we propose a new cross-modal
small molecule retrieval task, designed to force a model to learn to associate
the structure of a small molecule with the transcriptional change it induces.
We develop this task formally as multi-view alignment problem, and present a
coordinated deep learning approach that jointly optimizes representations of
both chemical structure and perturbational gene expression profiles. We
benchmark our results against oracle models and principled baselines, and find
that cell line variability markedly influences performance in this domain. Our
work establishes the feasibility of this new task, elucidates the limitations
of current data and systems, and may serve to catalyze future research in small
molecule representation learning.
</p>
<a href="http://arxiv.org/abs/1911.10241" target="_blank">arXiv:1911.10241</a> [<a href="http://arxiv.org/pdf/1911.10241" target="_blank">pdf</a>]

<h2>Privacy-preserving data sharing via probabilistic modelling. (arXiv:1912.04439v3 [stat.ML] UPDATED)</h2>
<h3>Joonas J&#xe4;lk&#xf6;, Eemil Lagerspetz, Jari Haukka, Sasu Tarkoma, Samuel Kaski, Antti Honkela</h3>
<p>Differential privacy allows quantifying privacy loss from computations on
sensitive personal data. This loss grows with the number of accesses to the
data, making it hard to open the use of such data while respecting privacy. To
avoid this limitation, we propose privacy-preserving release of a synthetic
version of a data set, which can be used for an unlimited number of analyses
with any methods, without affecting the privacy guarantees. The synthetic data
generation is based on differentially private learning of a generative
probabilistic model which can capture the probability distribution of the
original data. We demonstrate empirically that we can reliably reproduce
statistical discoveries from the synthetic data. We expect the method to have
broad use in sharing anonymized versions of key data sets for research.
</p>
<a href="http://arxiv.org/abs/1912.04439" target="_blank">arXiv:1912.04439</a> [<a href="http://arxiv.org/pdf/1912.04439" target="_blank">pdf</a>]

<h2>WCE Polyp Detection with Triplet based Embeddings. (arXiv:1912.04643v3 [eess.IV] UPDATED)</h2>
<h3>Pablo Laiz, Jordi Vitri&#xe0;, Hagen Wenzek, Carolina Malagelada, Fernando Azpiroz, Santi Segu&#xed;</h3>
<p>Wireless capsule endoscopy is a medical procedure used to visualize the
entire gastrointestinal tract and to diagnose intestinal conditions, such as
polyps or bleeding. Current analyses are performed by manually inspecting
nearly each one of the frames of the video, a tedious and error-prone task.
Automatic image analysis methods can be used to reduce the time needed for
physicians to evaluate a capsule endoscopy video, however these methods are
still in a research phase. In this paper we focus on computer-aided polyp
detection in capsule endoscopy images. This is a challenging problem because of
the diversity of polyp appearance, the imbalanced dataset structure and the
scarcity of data. We have developed a new polyp computer-aided decision system
that combines a deep convolutional neural network and metric learning. The key
point of the method is the use of the triplet loss function with the aim of
improving feature extraction from the images when having small dataset. The
triplet loss function allows to train robust detectors by forcing images from
the same category to be represented by similar embedding vectors while ensuring
that images from different categories are represented by dissimilar vectors.
Empirical results show a meaningful increase of AUC values compared to baseline
methods. A good performance is not the only requirement when considering the
adoption of this technology to clinical practice. Trust and explainability of
decisions are as important as performance. With this purpose, we also provide a
method to generate visual explanations of the outcome of our polyp detector.
These explanations can be used to build a physician's trust in the system and
also to convey information about the inner working of the method to the
designer for debugging purposes.
</p>
<a href="http://arxiv.org/abs/1912.04643" target="_blank">arXiv:1912.04643</a> [<a href="http://arxiv.org/pdf/1912.04643" target="_blank">pdf</a>]

<h2>Optimizing Loss Functions Through Multivariate Taylor Polynomial Parameterization. (arXiv:2002.00059v4 [cs.LG] UPDATED)</h2>
<h3>Santiago Gonzalez, Risto Miikkulainen</h3>
<p>Metalearning of deep neural network (DNN) architectures and hyperparameters
has become an increasingly important area of research. Loss functions are a
type of metaknowledge that is crucial to effective training of DNNs, however,
their potential role in metalearning has not yet been fully explored. Whereas
early work focused on genetic programming (GP) on tree representations, this
paper proposes continuous CMA-ES optimization of multivariate Taylor polynomial
parameterizations. This approach, TaylorGLO, makes it possible to represent and
search useful loss functions more effectively. In MNIST, CIFAR-10, and SVHN
benchmark tasks, TaylorGLO finds new loss functions that outperform functions
previously discovered through GP, as well as the standard cross-entropy loss,
in fewer generations. These functions serve to regularize the learning task by
discouraging overfitting to the labels, which is particularly useful in tasks
where limited training data is available. The results thus demonstrate that
loss function optimization is a productive new avenue for metalearning.
</p>
<a href="http://arxiv.org/abs/2002.00059" target="_blank">arXiv:2002.00059</a> [<a href="http://arxiv.org/pdf/2002.00059" target="_blank">pdf</a>]

<h2>A Set of Distinct Facial Traits Learned by Machines Is Not Predictive of Appearance Bias in the Wild. (arXiv:2002.05636v2 [cs.CY] UPDATED)</h2>
<h3>Ryan Steed, Aylin Caliskan</h3>
<p>We seek to determine whether state-of-the-art, black box face processing
technology can learn to make biased trait judgments from human first impression
biases. Using features extracted with FaceNet, a widely used face recognition
framework, we train a transfer learning model on human subjects' first
impressions of personality traits in other faces as measured by social
psychologists. We measure the extent to which this appearance bias can be
embedded in state-of-the-art face recognition models and benchmark learning
performance for subjective perceptions of personality traits from faces. In
particular, we find that features extracted with FaceNet can be used to predict
human appearance biases for deliberately manipulated faces but not for randomly
generated faces scored by humans. Additionally, in contrast to prior work in
social psychology, the model does not find a significant signal correlating
politicians' vote shares with perceived competence bias. With Local
Interpretable Model-Agnostic Explanations (LIME), we provide several
explanations for this discrepancy. Our results suggest that some signals of
appearance bias documented in social psychology are not embedded by the machine
learning techniques we investigate.
</p>
<a href="http://arxiv.org/abs/2002.05636" target="_blank">arXiv:2002.05636</a> [<a href="http://arxiv.org/pdf/2002.05636" target="_blank">pdf</a>]

<h2>Reinforcement learning for the privacy preservation and manipulation of eye tracking data. (arXiv:2002.06806v2 [cs.LG] UPDATED)</h2>
<h3>Wolfgang Fuhl, Efe Bozkir, Enkelejda Kasneci</h3>
<p>In this paper, we present an approach based on reinforcement learning for eye
tracking data manipulation. It is based on two opposing agents, where one tries
to classify the data correctly and the second agent looks for patterns in the
data, which get manipulated to hide specific information. We show that our
approach is successfully applicable to preserve the privacy of the subjects.
For this purpose, we evaluate our approach iteratively to showcase the behavior
of the reinforcement learning based approach. In addition, we evaluate the
importance of temporal, as well as spatial, information of eye tracking data
for specific classification goals. In the last part of our evaluation, we apply
the procedure to further public data sets without re-training the autoencoder
or the data manipulator. The results show that the learned manipulation is
generalized and applicable to unseen data as well.
</p>
<a href="http://arxiv.org/abs/2002.06806" target="_blank">arXiv:2002.06806</a> [<a href="http://arxiv.org/pdf/2002.06806" target="_blank">pdf</a>]

<h2>Efficient reinforcement learning control for continuum robots based on Inexplicit Prior Knowledge. (arXiv:2002.11573v2 [cs.RO] UPDATED)</h2>
<h3>Junjia Liu, Jiaying Shou, Zhuang Fu, Hangfei Zhou, Rongli Xie, Jun Zhang, Jian Fei, Yanna Zhao</h3>
<p>Compared to rigid robots that are generally studied in reinforcement
learning, the physical characteristics of some sophisticated robots such as
soft or continuum robots are higher complicated. Moreover, recent reinforcement
learning methods are data-inefficient and can not be directly deployed to the
robot without simulation. In this paper, we propose an efficient reinforcement
learning method based on inexplicit prior knowledge in response to such
problems. We first corroborate the method by simulation and employed directly
in the real world. By using our method, we can achieve active visual tracking
and distance maintenance of a tendon-driven robot which will be critical in
minimally invasive procedures. Codes are available at
https://github.com/Skylark0924/TendonTrack.
</p>
<a href="http://arxiv.org/abs/2002.11573" target="_blank">arXiv:2002.11573</a> [<a href="http://arxiv.org/pdf/2002.11573" target="_blank">pdf</a>]

<h2>Learning control for polynomial systems using sum of squares relaxations. (arXiv:2004.00850v2 [eess.SY] UPDATED)</h2>
<h3>Meichen Guo, Claudio De Persis, Pietro Tesi</h3>
<p>This paper considers the problem of learning control laws for nonlinear
polynomial systems directly from the data, which are input-output measurements
collected in an experiment over a finite time period. Without explicitly
identifying the system dynamics, stabilizing laws are directly designed for
nonlinear polynomial systems using experimental data alone. By using data-based
sum of square programming, the stabilizing state-dependent control gains can be
constructed.
</p>
<a href="http://arxiv.org/abs/2004.00850" target="_blank">arXiv:2004.00850</a> [<a href="http://arxiv.org/pdf/2004.00850" target="_blank">pdf</a>]

<h2>Pre-training for Abstractive Document Summarization by Reinstating Source Text. (arXiv:2004.01853v3 [cs.CL] UPDATED)</h2>
<h3>Yanyan Zou, Xingxing Zhang, Wei Lu, Furu Wei, Ming Zhou</h3>
<p>Abstractive document summarization is usually modeled as a
sequence-to-sequence (Seq2Seq) learning problem. Unfortunately, training large
Seq2Seq based summarization models on limited supervised summarization data is
challenging. This paper presents three pre-training objectives which allow us
to pre-train a Seq2Seq based abstractive summarization model on unlabeled text.
The main idea is that, given an input text artificially constructed from a
document, a model is pre-trained to reinstate the original document. These
objectives include sentence reordering, next sentence generation, and masked
document generation, which have close relations with the abstractive document
summarization task. Experiments on two benchmark summarization datasets (i.e.,
CNN/DailyMail and New York Times) show that all three objectives can improve
performance upon baselines. Compared to models pre-trained on large-scale data
(more than 160GB), our method, with only 19GB text for pre-training, achieves
comparable results, which demonstrates its effectiveness.
</p>
<a href="http://arxiv.org/abs/2004.01853" target="_blank">arXiv:2004.01853</a> [<a href="http://arxiv.org/pdf/2004.01853" target="_blank">pdf</a>]

<h2>Reinforced Multi-task Approach for Multi-hop Question Generation. (arXiv:2004.02143v3 [cs.CL] UPDATED)</h2>
<h3>Deepak Gupta, Hardik Chauhan, Akella Ravi Tej, Asif Ekbal, Pushpak Bhattacharyya</h3>
<p>Question generation (QG) attempts to solve the inverse of question answering
(QA) problem by generating a natural language question given a document and an
answer. While sequence to sequence neural models surpass rule-based systems for
QG, they are limited in their capacity to focus on more than one supporting
fact. For QG, we often require multiple supporting facts to generate
high-quality questions. Inspired by recent works on multi-hop reasoning in QA,
we take up Multi-hop question generation, which aims at generating relevant
questions based on supporting facts in the context. We employ multitask
learning with the auxiliary task of answer-aware supporting fact prediction to
guide the question generator. In addition, we also proposed a question-aware
reward function in a Reinforcement Learning (RL) framework to maximize the
utilization of the supporting facts. We demonstrate the effectiveness of our
approach through experiments on the multi-hop question answering dataset,
HotPotQA. Empirical evaluation shows our model to outperform the single-hop
neural question generation models on both automatic evaluation metrics such as
BLEU, METEOR, and ROUGE, and human evaluation metrics for quality and coverage
of the generated questions.
</p>
<a href="http://arxiv.org/abs/2004.02143" target="_blank">arXiv:2004.02143</a> [<a href="http://arxiv.org/pdf/2004.02143" target="_blank">pdf</a>]

<h2>Evaluating Models' Local Decision Boundaries via Contrast Sets. (arXiv:2004.02709v2 [cs.CL] UPDATED)</h2>
<h3>Matt Gardner, Yoav Artzi, Victoria Basmova, Jonathan Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi, Dheeru Dua, Yanai Elazar, Ananth Gottumukkala, Nitish Gupta, Hanna Hajishirzi, Gabriel Ilharco, Daniel Khashabi, Kevin Lin, Jiangming Liu, Nelson F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer Singh, Noah A. Smith, Sanjay Subramanian, Reut Tsarfaty, Eric Wallace, Ally Zhang, Ben Zhou</h3>
<p>Standard test sets for supervised learning evaluate in-distribution
generalization. Unfortunately, when a dataset has systematic gaps (e.g.,
annotation artifacts), these evaluations are misleading: a model can learn
simple decision rules that perform well on the test set but do not capture a
dataset's intended capabilities. We propose a new annotation paradigm for NLP
that helps to close systematic gaps in the test data. In particular, after a
dataset is constructed, we recommend that the dataset authors manually perturb
the test instances in small but meaningful ways that (typically) change the
gold label, creating contrast sets. Contrast sets provide a local view of a
model's decision boundary, which can be used to more accurately evaluate a
model's true linguistic capabilities. We demonstrate the efficacy of contrast
sets by creating them for 10 diverse NLP datasets (e.g., DROP reading
comprehension, UD parsing, IMDb sentiment analysis). Although our contrast sets
are not explicitly adversarial, model performance is significantly lower on
them than on the original test sets---up to 25\% in some cases. We release our
contrast sets as new evaluation benchmarks and encourage future dataset
construction efforts to follow similar annotation processes.
</p>
<a href="http://arxiv.org/abs/2004.02709" target="_blank">arXiv:2004.02709</a> [<a href="http://arxiv.org/pdf/2004.02709" target="_blank">pdf</a>]

<h2>DeepSEE: Deep Disentangled Semantic Explorative Extreme Super-Resolution. (arXiv:2004.04433v3 [cs.CV] UPDATED)</h2>
<h3>Marcel C. B&#xfc;hler, Andr&#xe9;s Romero, Radu Timofte</h3>
<p>Super-resolution (SR) is by definition ill-posed. There are infinitely many
plausible high-resolution variants for a given low-resolution natural image.
Most of the current literature aims at a single deterministic solution of
either high reconstruction fidelity or photo-realistic perceptual quality. In
this work, we propose an explorative facial super-resolution framework,
DeepSEE, for Deep disentangled Semantic Explorative Extreme super-resolution.
To the best of our knowledge, DeepSEE is the first method to leverage semantic
maps for explorative super-resolution. In particular, it provides control of
the semantic regions, their disentangled appearance and it allows a broad range
of image manipulations. We validate DeepSEE on faces, for up to 32x
magnification and exploration of the space of super-resolution. Our code and
models are available at: https://mcbuehler.github.io/DeepSEE/
</p>
<a href="http://arxiv.org/abs/2004.04433" target="_blank">arXiv:2004.04433</a> [<a href="http://arxiv.org/pdf/2004.04433" target="_blank">pdf</a>]

<h2>k-decay: A New Method For Learning Rate Schedule. (arXiv:2004.05909v4 [cs.LG] UPDATED)</h2>
<h3>Tao Zhang, Wei Li</h3>
<p>Recent work has shown that optimizing the learning rate (LR) schedule can be
a very accurate and efficient way to train the deep neural networks. In this
paper, we propose the k-decay method, in which the rate of change (ROC) of the
LR is changed by its k-th order derivative, to obtain the new LR schedule. In
the new LR schedule, a new hyper-parameter $k$ controls the change degree of
LR, whereas the original method of $k$ at 1. By repeatedly using the k-decay
method, one can identify the best LR schedule. We evaluate the k-decay method
on CIFAR And ImageNet datasets with different neural networks (ResNet, Wide
ResNet, and DenseNet). Our experiments show that the k-decay method can achieve
improvements over the state-of-the-art results on most of them. The accuracy
improved by 1.08% on the CIFAR-10 dataset, and by 2.07% on the CIFAR-100
dataset. On the ImageNet, accuracy improved by 1.25%. Our method is not only
efficient but also easy to use.
</p>
<a href="http://arxiv.org/abs/2004.05909" target="_blank">arXiv:2004.05909</a> [<a href="http://arxiv.org/pdf/2004.05909" target="_blank">pdf</a>]

<h2>BERT-ATTACK: Adversarial Attack Against BERT Using BERT. (arXiv:2004.09984v3 [cs.CL] UPDATED)</h2>
<h3>Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, Xipeng Qiu</h3>
<p>Adversarial attacks for discrete data (such as texts) have been proved
significantly more challenging than continuous data (such as images) since it
is difficult to generate adversarial samples with gradient-based methods.
Current successful attack methods for texts usually adopt heuristic replacement
strategies on the character or word level, which remains challenging to find
the optimal solution in the massive space of possible combinations of
replacements while preserving semantic consistency and language fluency. In
this paper, we propose \textbf{BERT-Attack}, a high-quality and effective
method to generate adversarial samples using pre-trained masked language models
exemplified by BERT. We turn BERT against its fine-tuned models and other deep
neural models in downstream tasks so that we can successfully mislead the
target models to predict incorrectly. Our method outperforms state-of-the-art
attack strategies in both success rate and perturb percentage, while the
generated adversarial samples are fluent and semantically preserved. Also, the
cost of calculation is low, thus possible for large-scale generations. The code
is available at https://github.com/LinyangLee/BERT-Attack.
</p>
<a href="http://arxiv.org/abs/2004.09984" target="_blank">arXiv:2004.09984</a> [<a href="http://arxiv.org/pdf/2004.09984" target="_blank">pdf</a>]

<h2>Control, Generate, Augment: A Scalable Framework for Multi-Attribute Text Generation. (arXiv:2004.14983v2 [cs.CL] UPDATED)</h2>
<h3>Giuseppe Russo, Nora Hollenstein, Claudiu Musat, Ce Zhang</h3>
<p>We introduce CGA, a conditional VAE architecture, to control, generate, and
augment text. CGA is able to generate natural English sentences controlling
multiple semantic and syntactic attributes by combining adversarial learning
with a context-aware loss and a cyclical word dropout routine. We demonstrate
the value of the individual model components in an ablation study. The
scalability of our approach is ensured through a single discriminator,
independently of the number of attributes. We show high quality, diversity and
attribute control in the generated sentences through a series of automatic and
human assessments. As the main application of our work, we test the potential
of this new NLG model in a data augmentation scenario. In a downstream NLP
task, the sentences generated by our CGA model show significant improvements
over a strong baseline, and a classification performance often comparable to
adding same amount of additional real data.
</p>
<a href="http://arxiv.org/abs/2004.14983" target="_blank">arXiv:2004.14983</a> [<a href="http://arxiv.org/pdf/2004.14983" target="_blank">pdf</a>]

<h2>Transforming task representations to allow models to perform novel tasks. (arXiv:2005.04318v2 [cs.LG] UPDATED)</h2>
<h3>Andrew K. Lampinen, James L. McClelland</h3>
<p>An important aspect of intelligence is the ability to adapt to a novel task
without any direct experience (zero-shot), based on its relationship to
previous tasks. Humans can exhibit this cognitive flexibility. By contrast,
models that achieve superhuman performance in specific tasks often fail to
adapt to even slight task alterations. To address this, we propose a general
computational framework for adapting to novel tasks based on their relationship
to prior tasks. We begin by learning vector representations of tasks. To adapt
to new tasks, we propose meta-mappings, higher-order tasks that transform basic
task representations. We demonstrate the effectiveness of this framework across
a wide variety of tasks and computational paradigms, ranging from regression to
image classification and reinforcement learning. We compare to both human
adaptability and language-based approaches to zero-shot learning. Across these
domains, meta-mapping is successful, often achieving 80-90% performance,
without any data, on a novel task, even when the new task directly contradicts
prior experience. We further show that meta-mapping can not only generalize to
new tasks via learned relationships, but can also generalize using novel
relationships unseen during training. Finally, using meta-mapping as a starting
point can dramatically accelerate later learning on a new task, and reduce
learning time and cumulative error substantially. Our results provide insight
into a possible computational basis of intelligent adaptability and offer a
possible framework for modeling cognitive flexibility and building more
flexible artificial intelligence systems.
</p>
<a href="http://arxiv.org/abs/2005.04318" target="_blank">arXiv:2005.04318</a> [<a href="http://arxiv.org/pdf/2005.04318" target="_blank">pdf</a>]

<h2>Reinforcement based Transmission Range Control in Software Defined Wireless Sensor Networks with Moving Sensor. (arXiv:2005.08215v3 [cs.NI] UPDATED)</h2>
<h3>Anuradha Banerjee (1), Abu Sufian (2) ((1) Kalyani Government Engineering College, West Bengal, India, (2) University of Gour Banga, West Bengal, India.)</h3>
<p>Routing in Software-Defined Wireless sensor networks (SD-WSNs) can be either
single or multi-hop whereas the network is either static or dynamic. In static
SD-WSN, the selection of the optimum route from source to destination is
accomplished by the SDN controller(s). On the other hand, if moving sensors are
there then SDN controllers of zones are not able to handle route discovery
sessions by themselves; they can only store information about the most recent
zone state. Moving sensors find lots of applications in robotics where robots
continue to move from one room to another to sensing the environment. A huge
amount of energy can be saved in these kinds of networks if transmission range
control is applied. The multiple power levels exist in each node, and each of
these levels takes possible actions after a potential sender node decides to
transmit/forward a message. Based on each such action, the next states of the
concerned sender node as well as the communication session are re-determined
while the router receives a reward. In order to decide the optimum power level
in the next iteration, the Epsilon-greedy algorithm is applied in this study.
It is determined anew depending upon the present network scenario. Simulation
results show that our proposed work leads the network to equilibrium by
reducing energy consumption and maintaining high network throughput.
</p>
<a href="http://arxiv.org/abs/2005.08215" target="_blank">arXiv:2005.08215</a> [<a href="http://arxiv.org/pdf/2005.08215" target="_blank">pdf</a>]

<h2>Communication-Efficient Decentralized Optimization Over Time-Varying Directed Graphs. (arXiv:2005.13189v3 [eess.SY] UPDATED)</h2>
<h3>Yiyue Chen, Abolfazl Hashemi, Haris Vikalo</h3>
<p>We study decentralized optimization tasks carried out by a collection of
agents, each having access only to a local cost function; the agents, who can
communicate over a time-varying directed network, aim to minimize the sum of
those functions. In practical settings, communication constraints impose a
limit on the amount of information that can be exchanged between the agents. We
propose communication-efficient algorithms for decentralized convex
optimization and its special case, distributed average consensus, that rely on
sparsification of local updates exchanged between neighboring agents in the
network. Message sparsification alters column-stochasticity of the mixing
matrices of directed networks, a property that plays an important role in
establishing convergence of decentralized learning tasks. We show that by
locally modifying mixing matrices the proposed framework achieves
$\O(\frac{\mathrm{ln}T}{\sqrt{T}})$ convergence rate in general decentralized
optimization settings, and a geometric convergence rate in the average
consensus problem. Experimental results on synthetic and real datasets show
efficacy of the proposed algorithms.
</p>
<a href="http://arxiv.org/abs/2005.13189" target="_blank">arXiv:2005.13189</a> [<a href="http://arxiv.org/pdf/2005.13189" target="_blank">pdf</a>]

<h2>DeepMark++: Real-time Clothing Detection at the Edge. (arXiv:2006.00710v2 [cs.CV] UPDATED)</h2>
<h3>Alexey Sidnev, Alexander Krapivin, Alexey Trushkov, Ekaterina Krasikova, Maxim Kazakov, Mikhail Viryasov</h3>
<p>Clothing recognition is the most fundamental AI application challenge within
the fashion domain. While existing solutions offer decent recognition accuracy,
they are generally slow and require significant computational resources. In
this paper we propose a single-stage approach to overcome this obstacle and
deliver rapid clothing detection and keypoint estimation. Our solution is based
on a multi-target network CenterNet, and we introduce several powerful
post-processing techniques to enhance performance. Our most accurate model
achieves results comparable to state-of-the-art solutions on the DeepFashion2
dataset, and our light and fast model runs at 17 FPS on the Huawei P40 Pro
smartphone. In addition, we achieved second place in the DeepFashion2 Landmark
Estimation Challenge 2020 with 0.582 mAP on the test dataset.
</p>
<a href="http://arxiv.org/abs/2006.00710" target="_blank">arXiv:2006.00710</a> [<a href="http://arxiv.org/pdf/2006.00710" target="_blank">pdf</a>]

<h2>A generalized linear joint trained framework for semi-supervised learning of sparse features. (arXiv:2006.01671v2 [stat.ML] UPDATED)</h2>
<h3>Juan C. Laria, Line H. Clemmensen, Bjarne K. Ersb&#xf8;ll</h3>
<p>The elastic-net is among the most widely used types of regularization
algorithms, commonly associated with the problem of supervised generalized
linear model estimation via penalized maximum likelihood. Its nice properties
originate from a combination of $\ell_1$ and $\ell_2$ norms, which endow this
method with the ability to select variables taking into account the
correlations between them. In the last few years, semi-supervised approaches,
that use both labeled and unlabeled data, have become an important component in
the statistical research. Despite this interest, however, few researches have
investigated semi-supervised elastic-net extensions. This paper introduces a
novel solution for semi-supervised learning of sparse features in the context
of generalized linear model estimation: the generalized semi-supervised
elastic-net (s2net), which extends the supervised elastic-net method, with a
general mathematical formulation that covers, but is not limited to, both
regression and classification problems. We develop a flexible and fast
implementation for s2net in R, and its advantages are illustrated using both
real and synthetic data sets.
</p>
<a href="http://arxiv.org/abs/2006.01671" target="_blank">arXiv:2006.01671</a> [<a href="http://arxiv.org/pdf/2006.01671" target="_blank">pdf</a>]

<h2>Evaluating the Disentanglement of Deep Generative Models through Manifold Topology. (arXiv:2006.03680v3 [stat.ML] UPDATED)</h2>
<h3>Sharon Zhou, Eric Zelikman, Fred Lu, Andrew Y. Ng, Gunnar Carlsson, Stefano Ermon</h3>
<p>Learning disentangled representations is regarded as a fundamental task for
improving the generalization, robustness, and interpretability of generative
models. However, measuring disentanglement has been challenging and
inconsistent, often dependent on an ad-hoc external model or specific to a
certain dataset. To address this, we present a method for quantifying
disentanglement that only uses the generative model, by measuring the
topological similarity of conditional submanifolds in the learned
representation. This method showcases both unsupervised and supervised
variants. To illustrate the effectiveness and applicability of our method, we
empirically evaluate several state-of-the-art models across multiple datasets.
We find that our method ranks models similarly to existing methods.
</p>
<a href="http://arxiv.org/abs/2006.03680" target="_blank">arXiv:2006.03680</a> [<a href="http://arxiv.org/pdf/2006.03680" target="_blank">pdf</a>]

<h2>Learning Continuous-Time Dynamics by Stochastic Differential Networks. (arXiv:2006.06145v2 [cs.LG] UPDATED)</h2>
<h3>Yingru Liu, Yucheng Xing, Xuewen Yang, Xin Wang, Jing Shi, Di Jin, Zhaoyue Chen</h3>
<p>Learning continuous-time stochastic dynamics is a fundamental and essential
problem in modeling sporadic time series, whose observations are irregular and
sparse in both time and dimension. For a given system whose latent states and
observed data are high-dimensional, it is generally impossible to derive a
precise continuous-time stochastic process to describe the system behaviors. To
solve the above problem, we apply Variational Bayesian method and propose a
flexible continuous-time stochastic recurrent neural network named Variational
Stochastic Differential Networks (VSDN), which embeds the complicated dynamics
of the sporadic time series by neural Stochastic Differential Equations (SDE).
VSDNs capture the stochastic dependency among latent states and observations by
deep neural networks. We also incorporate two differential Evidence Lower
Bounds to efficiently train the models. Through comprehensive experiments, we
show that VSDNs outperform state-of-the-art continuous-time deep learning
models and achieve remarkable performance on prediction and interpolation tasks
for sporadic time series.
</p>
<a href="http://arxiv.org/abs/2006.06145" target="_blank">arXiv:2006.06145</a> [<a href="http://arxiv.org/pdf/2006.06145" target="_blank">pdf</a>]

<h2>Deep Learning Requires Explicit Regularization for Reliable Predictive Probability. (arXiv:2006.06399v2 [cs.LG] UPDATED)</h2>
<h3>Taejong Joo, Uijung Chung</h3>
<p>From the statistical learning perspective, complexity control via explicit
regularization is a necessity for improving the generalization of
over-parameterized models, which deters the memorization of intricate patterns
existing only in the training data. However, the impressive generalization
performance of over-parameterized neural networks with only implicit
regularization challenges the importance of explicit regularization.
Furthermore, explicit regularization does not prevent neural networks from
memorizing unnatural patterns, such as random labels. In this work, we revisit
the role and importance of explicit regularization methods for generalization
of the predictive probability, not just the generalization of the 0-1 loss.
Specifically, we analyze the possible cause of the poor predictive probability
and identify that regularization of predictive confidence is required during
training. We then empirically show that explicit regularization significantly
improves the reliability of the predictive probability, which enables better
predictive uncertainty representation and prevents the overconfidence problem.
Our findings present a new direction to improve the predictive probability
quality of deterministic neural networks, which can be an efficient and
scalable alternative to Bayesian neural networks and ensemble methods.
</p>
<a href="http://arxiv.org/abs/2006.06399" target="_blank">arXiv:2006.06399</a> [<a href="http://arxiv.org/pdf/2006.06399" target="_blank">pdf</a>]

<h2>Adaptive Universal Generalized PageRank Graph Neural Network. (arXiv:2006.07988v2 [cs.LG] UPDATED)</h2>
<h3>Eli Chien, Jianhao Peng, Pan Li, Olgica Milenkovic</h3>
<p>In many important graph data processing applications the acquired information
includes both node features and observations of the graph topology. Graph
neural networks (GNNs) are designed to exploit both sources of evidence but
they do not optimally trade-off their utility and integrate them in a manner
that is also universal. Here, universality refers to independence on homophily
or heterophily graph assumptions. We address these issues by introducing a new
Generalized PageRank (GPR) GNN architecture that adaptively learns the GPR
weights so as to jointly optimize node feature and topological information
extraction, regardless of the extent to which the node labels are homophilic or
heterophilic. Learned GPR weights automatically adjust to the node label
pattern, irrelevant on the type of initialization, and thereby guarantee
excellent learning performance for label patterns that are usually hard to
handle. Furthermore, they allow one to avoid feature over-smoothing, a process
which renders feature information nondiscriminative, without requiring the
network to be shallow. Our accompanying theoretical analysis of the GPR-GNN
method is facilitated by novel synthetic benchmark datasets generated by the
so-called contextual stochastic block model. We also compare the performance of
our GNN architecture with that of several state-of-the-art GNNs on the problem
of node-classification, using well-known benchmark homophilic and heterophilic
datasets. The results demonstrate that GPR-GNN offers significant performance
improvement compared to existing techniques on both synthetic and benchmark
data.
</p>
<a href="http://arxiv.org/abs/2006.07988" target="_blank">arXiv:2006.07988</a> [<a href="http://arxiv.org/pdf/2006.07988" target="_blank">pdf</a>]

<h2>Spherical Motion Dynamics: Learning Dynamics of Neural Network with Normalization, Weight Decay, and SGD. (arXiv:2006.08419v3 [stat.ML] UPDATED)</h2>
<h3>Ruosi Wan, Zhanxing Zhu, Xiangyu Zhang, Jian Sun</h3>
<p>In this work, we comprehensively reveal the learning dynamics of neural
network with normalization, weight decay (WD), and SGD (with momentum), named
as Spherical Motion Dynamics (SMD). Most related works study SMD by focusing on
"effective learning rate" in "equilibrium" condition, where weight norm remains
unchanged. However, their discussions on why equilibrium condition can be
reached in SMD is either absent or less convincing. Our work investigates SMD
by directly exploring the cause of equilibrium condition. Specifically, 1) we
introduce the assumptions that can lead to equilibrium condition in SMD, and
prove that weight norm can converge at linear rate with given assumptions; 2)
we propose "angular update" as a substitute for effective learning rate to
measure the evolving of neural network in SMD, and prove angular update can
also converge to its theoretical value at linear rate; 3) we verify our
assumptions and theoretical results on various computer vision tasks including
ImageNet and MSCOCO with standard settings. Experiment results show our
theoretical findings agree well with empirical observations.
</p>
<a href="http://arxiv.org/abs/2006.08419" target="_blank">arXiv:2006.08419</a> [<a href="http://arxiv.org/pdf/2006.08419" target="_blank">pdf</a>]

<h2>Systematic Generalisation through Task Temporal Logic and Deep Reinforcement Learning. (arXiv:2006.08767v2 [cs.LG] UPDATED)</h2>
<h3>Borja G. Leon, Murray Shanahan, Francesco Belardinelli</h3>
<p>This paper presents a neuro-symbolic agent that combines deep reinforcement
learning (DRL) with temporal logic (TL), and achieves systematic
out-of-distribution generalisation in tasks that involve following a formally
specified instruction. Specifically, the agent learns general notions of
negation and disjunction, and successfully applies them to previously unseen
objects without further training. To this end, we also introduce Task Temporal
Logic (TTL), a learning-oriented formal language, whose atoms are designed to
help the training of a DRL agent targeting systematic generalisation. To
validate this combination of logic-based and neural-network techniques, we
provide experimental evidence for the kind of neural-network architecture that
most enhances the generalisation performance of the agent. Our findings suggest
that the right architecture can significatively improve the ability of the
agent to generalise in systematic ways, even with abstract operators, such as
negation, which previous research have struggled with.
</p>
<a href="http://arxiv.org/abs/2006.08767" target="_blank">arXiv:2006.08767</a> [<a href="http://arxiv.org/pdf/2006.08767" target="_blank">pdf</a>]

<h2>Learning continuous-time PDEs from sparse data with graph neural networks. (arXiv:2006.08956v2 [cs.LG] UPDATED)</h2>
<h3>Valerii Iakovlev, Markus Heinonen, Harri L&#xe4;hdesm&#xe4;ki</h3>
<p>The behavior of many dynamical systems follow complex, yet still unknown
partial differential equations (PDEs). While several machine learning methods
have been proposed to learn PDEs directly from data, previous methods are
limited to discrete-time approximations or make the limiting assumption of the
observations arriving at regular grids. We propose a general continuous-time
differential model for dynamical systems whose governing equations are
parameterized by message passing graph neural networks. The model admits
arbitrary space and time discretizations, which removes constraints on the
locations of observation points and time intervals between the observations.
The model is trained with continuous-time adjoint method enabling efficient
neural PDE inference. We demonstrate the model's ability to work with
unstructured grids, arbitrary time steps, and noisy observations. We compare
our method with existing approaches on several well-known physical systems that
involve first and higher-order PDEs with state-of-the-art predictive
performance.
</p>
<a href="http://arxiv.org/abs/2006.08956" target="_blank">arXiv:2006.08956</a> [<a href="http://arxiv.org/pdf/2006.08956" target="_blank">pdf</a>]

<h2>Temporal Graph Networks for Deep Learning on Dynamic Graphs. (arXiv:2006.10637v2 [cs.LG] UPDATED)</h2>
<h3>Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, Michael Bronstein</h3>
<p>Graph Neural Networks (GNNs) have recently become increasingly popular due to
their ability to learn complex systems of relations or interactions arising in
a broad spectrum of problems ranging from biology and particle physics to
social networks and recommendation systems. Despite the plethora of different
models for deep learning on graphs, few approaches have been proposed thus far
for dealing with graphs that present some sort of dynamic nature (e.g. evolving
features or connectivity over time). In this paper, we present Temporal Graph
Networks (TGNs), a generic, efficient framework for deep learning on dynamic
graphs represented as sequences of timed events. Thanks to a novel combination
of memory modules and graph-based operators, TGNs are able to significantly
outperform previous approaches being at the same time more computationally
efficient. We furthermore show that several previous models for learning on
dynamic graphs can be cast as specific instances of our framework. We perform a
detailed ablation study of different components of our framework and devise the
best configuration that achieves state-of-the-art performance on several
transductive and inductive prediction tasks for dynamic graphs.
</p>
<a href="http://arxiv.org/abs/2006.10637" target="_blank">arXiv:2006.10637</a> [<a href="http://arxiv.org/pdf/2006.10637" target="_blank">pdf</a>]

<h2>COVID-19 Image Data Collection: Prospective Predictions Are the Future. (arXiv:2006.11988v2 [q-bio.QM] UPDATED)</h2>
<h3>Joseph Paul Cohen, Paul Morrison, Lan Dao, Karsten Roth, Tim Q Duong, Marzyeh Ghassemi</h3>
<p>Across the world's coronavirus disease 2019 (COVID-19) hot spots, the need to
streamline patient diagnosis and management has become more pressing than ever.
As one of the main imaging tools, chest X-rays (CXRs) are common, fast,
non-invasive, relatively cheap, and potentially bedside to monitor the
progression of the disease. This paper describes the first public COVID-19
image data collection as well as a preliminary exploration of possible use
cases for the data. This dataset currently contains hundreds of frontal view
X-rays and is the largest public resource for COVID-19 image and prognostic
data, making it a necessary resource to develop and evaluate tools to aid in
the treatment of COVID-19. It was manually aggregated from publication figures
as well as various web based repositories into a machine learning (ML) friendly
format with accompanying dataloader code. We collected frontal and lateral view
imagery and metadata such as the time since first symptoms, intensive care unit
(ICU) status, survival status, intubation status, or hospital location. We
present multiple possible use cases for the data such as predicting the need
for the ICU, predicting patient survival, and understanding a patient's
trajectory during treatment. Data can be accessed here:
https://github.com/ieee8023/covid-chestxray-dataset
</p>
<a href="http://arxiv.org/abs/2006.11988" target="_blank">arXiv:2006.11988</a> [<a href="http://arxiv.org/pdf/2006.11988" target="_blank">pdf</a>]

<h2>Calibration of Shared Equilibria in General Sum Partially Observable Markov Games. (arXiv:2006.13085v2 [cs.MA] UPDATED)</h2>
<h3>Nelson Vadori, Sumitra Ganesh, Prashant Reddy, Manuela Veloso</h3>
<p>Training multi-agent systems (MAS) to achieve realistic equilibria gives us a
useful tool to understand and model real-world systems. We consider a general
sum partially observable Markov game where agents of different types share a
single policy network, conditioned on agent-specific information. This paper
aims at i) formally understanding equilibria reached by such agents, and ii)
matching emergent phenomena of such equilibria to real-world targets. Parameter
sharing with decentralized execution has been introduced as an efficient way to
train multiple agents using a single policy network. However, the nature of
resulting equilibria reached by such agents is not yet understood: we introduce
the novel concept of \textit{Shared equilibrium} as a symmetric pure Nash
equilibrium of a certain Functional Form Game (FFG) and prove convergence to
the latter for a certain class of games using self-play. In addition, it is
important that such equilibria satisfy certain constraints so that MAS are
\textit{calibrated} to real world data for practical use: we solve this problem
by introducing a novel dual-Reinforcement Learning based approach that fits
emergent behaviors of agents in a Shared equilibrium to externally-specified
targets, and apply our methods to a $n$-player market example. We do so by
calibrating parameters governing distributions of agent types rather than
individual agents, which allows both behavior differentiation among agents and
coherent scaling of the shared policy network to multiple agents.
</p>
<a href="http://arxiv.org/abs/2006.13085" target="_blank">arXiv:2006.13085</a> [<a href="http://arxiv.org/pdf/2006.13085" target="_blank">pdf</a>]

<h2>Learning Potentials of Quantum Systems using Deep Neural Networks. (arXiv:2006.13297v2 [cs.LG] UPDATED)</h2>
<h3>Arijit Sehanobish, Hector H. Corzo, Onur Kara, David van Dijk</h3>
<p>Machine Learning has wide applications in a broad range of subjects,
including physics. Recent works have shown that neural networks can learn
classical Hamiltonian mechanics. The results of these works motivate the
following question: Can we endow neural networks with inductive biases coming
from quantum mechanics and provide insights for quantum phenomena? In this
work, we try answering these questions by investigating possible approximations
for reconstructing the Hamiltonian of a quantum system given one of its
wave--functions. Instead of handcrafting the Hamiltonian and a solution of the
Schr\"odinger equation, we design neural networks that aim to learn it directly
from our observations. We show that our method, termed Quantum Potential Neural
Networks (QPNN), can learn potentials in an unsupervised manner with remarkable
accuracy for a wide range of quantum systems, such as the quantum harmonic
oscillator, particle in a box perturbed by an external potential, hydrogen
atom, P\"oschl--Teller potential, and a solitary wave system. Furthermore, in
the case of a particle perturbed by an external force, we also learn the
perturbed wave function in a joint end-to-end manner.
</p>
<a href="http://arxiv.org/abs/2006.13297" target="_blank">arXiv:2006.13297</a> [<a href="http://arxiv.org/pdf/2006.13297" target="_blank">pdf</a>]

<h2>AReLU: Attention-based Rectified Linear Unit. (arXiv:2006.13858v2 [cs.LG] UPDATED)</h2>
<h3>Dengsheng Chen, Jun Li, Kai Xu</h3>
<p>Element-wise activation functions play a critical role in deep neural
networks via affecting the expressivity power and the learning dynamics.
Learning-based activation functions have recently gained increasing attention
and success. We propose a new perspective of learnable activation function
through formulating them with element-wise attention mechanism. In each network
layer, we devise an attention module which learns an element-wise, sign-based
attention map for the pre-activation feature map. The attention map scales an
element based on its sign. Adding the attention module with a rectified linear
unit (ReLU) results in an amplification of positive elements and a suppression
of negative ones, both with learned, data-adaptive parameters. We coin the
resulting activation function Attention-based Rectified Linear Unit (AReLU).
The attention module essentially learns an element-wise residue of the
activated part of the input, as ReLU can be viewed as an identity
transformation. This makes the network training more resistant to gradient
vanishing. The learned attentive activation leads to well-focused activation of
relevant regions of a feature map. Through extensive evaluations, we show that
AReLU significantly boosts the performance of most mainstream network
architectures with only two extra learnable parameters per layer introduced.
Notably, AReLU facilitates fast network training under small learning rates,
which makes it especially suited in the case of transfer learning and meta
learning. Our source code has been released (see
https://github.com/densechen/AReLU).
</p>
<a href="http://arxiv.org/abs/2006.13858" target="_blank">arXiv:2006.13858</a> [<a href="http://arxiv.org/pdf/2006.13858" target="_blank">pdf</a>]

<h2>Deep Neural Networks for Nonlinear Model Order Reduction of Unsteady Flows. (arXiv:2007.00936v3 [physics.flu-dyn] UPDATED)</h2>
<h3>Hamidreza Eivazi, Hadi Veisi, Mohammad Hossein Naderi, Vahid Esfahanian</h3>
<p>Unsteady fluid systems are nonlinear high-dimensional dynamical systems that
may exhibit multiple complex phenomena both in time and space. Reduced Order
Modeling (ROM) of fluid flows has been an active research topic in the recent
decade with the primary goal to decompose complex flows to a set of features
most important for future state prediction and control, typically using a
dimensionality reduction technique. In this work, a novel data-driven technique
based on the power of deep neural networks for reduced order modeling of the
unsteady fluid flows is introduced. An autoencoder network is used for
nonlinear dimension reduction and feature extraction as an alternative for
singular value decomposition (SVD). Then, the extracted features are used as an
input for long short-term memory network (LSTM) to predict the velocity field
at future time instances. The proposed autoencoder-LSTM method is compared with
non-intrusive reduced order models based on dynamic mode decomposition (DMD)
and proper orthogonal decomposition (POD). Moreover, an autoencoder-DMD
algorithm is introduced for reduced order modeling, which uses the autoencoder
network for dimensionality reduction rather than SVD rank truncation. Results
show that the autoencoder-LSTM method is considerably capable of predicting
fluid flow evolution, where higher values for coefficient of determination
$R^{2}$ are obtained using autoencoder-LSTM compared to other models.
</p>
<a href="http://arxiv.org/abs/2007.00936" target="_blank">arXiv:2007.00936</a> [<a href="http://arxiv.org/pdf/2007.00936" target="_blank">pdf</a>]

<h2>Leveraging Class Hierarchies with Metric-Guided Prototype Learning. (arXiv:2007.03047v2 [cs.LG] UPDATED)</h2>
<h3>Vivien Sainte Fare Garnot, Loic Landrieu</h3>
<p>Not all errors are created equal. This is especially true for many key
machine learning applications. In the case of classification tasks, the
severity of errors can be summarized under the form of a cost matrix, which
assesses the gravity of confusing each pair of classes. When the target classes
are organized into a hierarchical structure, this matrix defines a metric. We
propose to integrate this metric in a new and versatile classification layer in
order to model the disparity of errors. Our method relies on jointly learning a
feature-extracting network and a set of class representations, or prototypes,
which incorporate the error metric into their relative arrangement in the
embedding space. Our approach allows for consistent improvement of the severity
of the network's errors with regard to the cost matrix. Furthermore, when the
induced metric contains insight on the data structure, our approach improves
the overall precision as well. Experiments on four different public datasets --
from agricultural time series classification to depth image semantic
segmentation -- validate our approach.
</p>
<a href="http://arxiv.org/abs/2007.03047" target="_blank">arXiv:2007.03047</a> [<a href="http://arxiv.org/pdf/2007.03047" target="_blank">pdf</a>]

<h2>Attentive Graph Neural Networks for Few-Shot Learning. (arXiv:2007.06878v2 [cs.LG] UPDATED)</h2>
<h3>Hao Cheng, Joey Tianyi Zhou, Wee Peng Tay, Bihan Wen</h3>
<p>Graph Neural Networks (GNN) has demonstrated the superior performance in many
challenging applications, including the few-shot learning tasks. Despite its
powerful capacity to learn and generalize the model from few samples, GNN
usually suffers from severe over-fitting and over-smoothing as the model
becomes deep, which limit the scalability. In this work, we propose a novel
Attentive GNN to tackle these challenges, by incorporating a triple-attention
mechanism, i.e. node self-attention, neighborhood attention, and layer memory
attention. We explain why the proposed attentive modules can improve GNN for
few-shot learning with theoretical analysis and illustrations. Extensive
experiments show that the proposed Attentive GNN model achieves the promising
results, comparing to the state-of-the-art GNN- and CNN-based methods for
few-shot learning tasks, over the mini-ImageNet and tiered-ImageNet benchmarks,
under ConvNet-4 and ResNet-based backbone with both inductive and transductive
settings. The codes will be made publicly available.
</p>
<a href="http://arxiv.org/abs/2007.06878" target="_blank">arXiv:2007.06878</a> [<a href="http://arxiv.org/pdf/2007.06878" target="_blank">pdf</a>]

<h2>Learning Structured Latent Factors from Dependent Data:A Generative Model Framework from Information-Theoretic Perspective. (arXiv:2007.10623v2 [cs.LG] UPDATED)</h2>
<h3>Ruixiang Zhang, Masanori Koyama, Katsuhiko Ishiguro</h3>
<p>Learning controllable and generalizable representation of multivariate data
with desired structural properties remains a fundamental problem in machine
learning. In this paper, we present a novel framework for learning generative
models with various underlying structures in the latent space. We represent the
inductive bias in the form of mask variables to model the dependency structure
in the graphical model and extend the theory of multivariate information
bottleneck to enforce it. Our model provides a principled approach to learn a
set of semantically meaningful latent factors that reflect various types of
desired structures like capturing correlation or encoding invariance, while
also offering the flexibility to automatically estimate the dependency
structure from data. We show that our framework unifies many existing
generative models and can be applied to a variety of tasks including
multi-modal data modeling, algorithmic fairness, and invariant risk
minimization.
</p>
<a href="http://arxiv.org/abs/2007.10623" target="_blank">arXiv:2007.10623</a> [<a href="http://arxiv.org/pdf/2007.10623" target="_blank">pdf</a>]

<h2>Stable Learning via Self-supervised Invariant Risk Minimization. (arXiv:2007.15241v2 [cs.LG] UPDATED)</h2>
<h3>Zhengxu Yu, Pengfei Wang, Junkai Xu, Liang Xie, Zhongming Jin, Jianqiang Huang, Xiaofei He, Deng Cai, Xian-Sheng Hua</h3>
<p>Empirical Risk Minimization based methods are based on the consistency
hypothesis that all data samples are generated i.i.d. However, this hypothesis
cannot hold in many real-world applications. Consequently, simply minimizing
training loss can lead the model into recklessly absorbing all statistical
correlations in the training dataset. It is why a well-trained model may
perform unstably in different testing environments. Hence, learning a stable
predictor that can simultaneously performs well in all testing environments is
important for machine learning tasks. In this work, we study this problem from
the perspective of Invariant Risk Minimization. Specifically, we propose a
novel Self-supervised Invariant Risk Minimization method based on the fact that
the real causality connections between features are consistent no matter how
the environment changes. First, we propose a self-supervised invariant
representation learning objective function, which aims to learn a stable
representation of the consistent causality. Based on that, we further propose a
stable predictor training algorithm. This algorithm aims to improve the
predictor's stability using the invariant representation learned by using our
proposed objective function. We conduct extensive experiments on both synthetic
and real-world datasets to show that our proposal outperforms previous
state-of-the-art stable learning methods. The code will be released later.
</p>
<a href="http://arxiv.org/abs/2007.15241" target="_blank">arXiv:2007.15241</a> [<a href="http://arxiv.org/pdf/2007.15241" target="_blank">pdf</a>]

<h2>DeVLBert: Learning Deconfounded Visio-Linguistic Representations. (arXiv:2008.06884v2 [cs.CV] UPDATED)</h2>
<h3>Shengyu Zhang, Tan Jiang, Tan Wang, Kun Kuang, Zhou Zhao, Jianke Zhu, Jin Yu, Hongxia Yang, Fei Wu</h3>
<p>In this paper, we propose to investigate the problem of out-of-domain
visio-linguistic pretraining, where the pretraining data distribution differs
from that of downstream data on which the pretrained model will be fine-tuned.
Existing methods for this problem are purely likelihood-based, leading to the
spurious correlations and hurt the generalization ability when transferred to
out-of-domain downstream tasks. By spurious correlation, we mean that the
conditional probability of one token (object or word) given another one can be
high (due to the dataset biases) without robust (causal) relationships between
them. To mitigate such dataset biases, we propose a Deconfounded
Visio-Linguistic Bert framework, abbreviated as DeVLBert, to perform
intervention-based learning. We borrow the idea of the backdoor adjustment from
the research field of causality and propose several neural-network based
architectures for Bert-style out-of-domain pretraining. The quantitative
results on three downstream tasks, Image Retrieval (IR), Zero-shot IR, and
Visual Question Answering, show the effectiveness of DeVLBert by boosting
generalization ability.
</p>
<a href="http://arxiv.org/abs/2008.06884" target="_blank">arXiv:2008.06884</a> [<a href="http://arxiv.org/pdf/2008.06884" target="_blank">pdf</a>]

<h2>Towards Class-incremental Object Detection with Nearest Mean of Exemplars. (arXiv:2008.08336v2 [cs.CV] UPDATED)</h2>
<h3>Sheng Ren, Yan He, Neal N. Xiong, Kehua Guo</h3>
<p>Incremental learning is a form of online learning. Incremental learning can
modify the parameters and structure of the deep learning model so that the
model does not forget the old knowledge while learning new knowledge.
Preventing catastrophic forgetting is the most important task of incremental
learning. However, the current incremental learning is often only for one type
of input. For example, if the input images are of the same type, the current
incremental model can learn new knowledge while not forgetting old knowledge.
However, if several categories are added to the input graphics, the current
model will not be able to deal with it correctly, and the accuracy will drop
significantly. Therefore, this paper proposes a kind of incremental method,
which adjusts the parameters of the model by identifying the prototype vector
and increasing the distance of the vector, so that the model can learn new
knowledge without catastrophic forgetting. Experiments show the effectiveness
of our proposed method.
</p>
<a href="http://arxiv.org/abs/2008.08336" target="_blank">arXiv:2008.08336</a> [<a href="http://arxiv.org/pdf/2008.08336" target="_blank">pdf</a>]

<h2>Unsupervised MRI Super-Resolution Using Deep External Learning and Guided Residual Dense Network with Multimodal Image Priors. (arXiv:2008.11921v2 [eess.IV] UPDATED)</h2>
<h3>Yutaro Iwamoto, Kyohei Takeda, Yinhao Li, Akihiko Shiino, Yen-Wei Chen</h3>
<p>Deep learning techniques have led to state-of-the-art single image
super-resolution (SISR) with natural images. Pairs of high-resolution (HR) and
low-resolution (LR) images are used to train the deep learning model (mapping
function). These techniques have also been applied to medical image
super-resolution (SR). Compared with natural images, medical images have
several unique characteristics. First, there are no HR images for training in
real clinical applications because of the limitations of imaging systems and
clinical requirements. Second, other modal HR images are available (e.g., HR
T1-weighted images are available for enhancing LR T2-weighted images). In this
paper, we propose an unsupervised SISR technique based on simple prior
knowledge of the human anatomy; this technique does not require HR images for
training. Furthermore, we present a guided residual dense network, which
incorporates a residual dense network with a guided deep convolutional neural
network for enhancing the resolution of LR images by referring to different HR
images of the same subject. Experiments on a publicly available brain MRI
database showed that our proposed method achieves better performance than the
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2008.11921" target="_blank">arXiv:2008.11921</a> [<a href="http://arxiv.org/pdf/2008.11921" target="_blank">pdf</a>]

<h2>Tensor Relational Algebra for Machine Learning System Design. (arXiv:2009.00524v2 [cs.DB] UPDATED)</h2>
<h3>Binhang Yuan, Dimitrije Jankov, Jia Zou, Yuxin Tang, Daniel Bourgeois, Chris Jermaine</h3>
<p>Machine learning (ML) systems have to support various tensor operations.
However, such ML systems were largely developed without asking: what are the
foundational abstractions necessary for building machine learning systems? We
believe that proper computational and implementation abstractions will allow
for the construction of self-configuring, declarative ML systems, especially
when the goal is to execute tensor operations in a distributed environment, or
partitioned across multiple AI accelerators (ASICs). To this end, we first
introduce a tensor relational algebra (TRA), which is expressive to encode any
tensor operation that can be written in the Einstein notation. We consider how
TRA expressions can be re-written into an implementation algebra (IA) that
enables effective implementation in a distributed environment, as well as how
expressions in the IA can be optimized. Our empirical study shows that the
optimized implementation provided by IA can reach or even out-perform carefully
engineered HPC or ML systems for large scale tensor manipulations and ML
workflows in distributed clusters.
</p>
<a href="http://arxiv.org/abs/2009.00524" target="_blank">arXiv:2009.00524</a> [<a href="http://arxiv.org/pdf/2009.00524" target="_blank">pdf</a>]

<h2>Effective Proximal Methods for Non-convex Non-smooth Regularized Learning. (arXiv:2009.06562v2 [cs.LG] UPDATED)</h2>
<h3>Guannan Liang, Qianqian Tong, Jiahao Ding, Miao Pan, Jinbo Bi</h3>
<p>Sparse learning is a very important tool for mining useful information and
patterns from high dimensional data. Non-convex non-smooth regularized learning
problems play essential roles in sparse learning, and have drawn extensive
attentions recently. We design a family of stochastic proximal gradient methods
by applying arbitrary sampling to solve the empirical risk minimization problem
with a non-convex and non-smooth regularizer. These methods draw mini-batches
of training examples according to an arbitrary probability distribution when
computing stochastic gradients. A unified analytic approach is developed to
examine the convergence and computational complexity of these methods, allowing
us to compare the different sampling schemes. We show that the independent
sampling scheme tends to improve performance over the commonly-used uniform
sampling scheme. Our new analysis also derives a tighter bound on convergence
speed for the uniform sampling than the best one available so far. Empirical
evaluations demonstrate that the proposed algorithms converge faster than the
state of the art.
</p>
<a href="http://arxiv.org/abs/2009.06562" target="_blank">arXiv:2009.06562</a> [<a href="http://arxiv.org/pdf/2009.06562" target="_blank">pdf</a>]

<h2>Competing AI: How competition feedback affects machine learning. (arXiv:2009.06797v2 [cs.LG] UPDATED)</h2>
<h3>Antonio Ginart, Eva Zhang, Yongchan Kwon, James Zou</h3>
<p>This papers studies how competition affects machine learning (ML) predictors.
As ML becomes more ubiquitous, it is often deployed by companies to compete
over customers. For example, digital platforms like Yelp use ML to predict user
preference and make recommendations. A service that is more often queried by
users, perhaps because it more accurately anticipates user preferences, is also
more likely to obtain additional user data (e.g. in the form of a Yelp review).
Thus, competing predictors cause feedback loops whereby a predictor's
performance impacts what training data it receives and biases its predictions
over time. We introduce a flexible model of competing ML predictors that
enables both rapid experimentation and theoretical tractability. We show with
empirical and mathematical analysis that competition causes predictors to
specialize for specific sub-populations at the cost of worse performance over
the general population. We further analyze the impact of predictor
specialization on the overall prediction quality experienced by users. We show
that having too few or too many competing predictors in a market can hurt the
overall prediction quality. Our theory is complemented by experiments on
several real datasets using popular learning algorithms, such as neural
networks and nearest neighbor methods.
</p>
<a href="http://arxiv.org/abs/2009.06797" target="_blank">arXiv:2009.06797</a> [<a href="http://arxiv.org/pdf/2009.06797" target="_blank">pdf</a>]

<h2>S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric Learning. (arXiv:2009.08348v2 [cs.CV] UPDATED)</h2>
<h3>Karsten Roth, Timo Milbich, Bj&#xf6;rn Ommer, Joseph Paul Cohen, Marzyeh Ghassemi</h3>
<p>Deep Metric Learning (DML) provides a crucial tool for visual similarity and
zero-shot retrieval applications by learning generalizing embedding spaces,
although recent work in DML has shown strong performance saturation across
training objectives. However, generalization capacity is known to scale with
the embedding space dimensionality. Unfortunately, high dimensional embeddings
also create higher retrieval cost for downstream applications. To remedy this,
we propose S2SD - Simultaneous Similarity-based Self-distillation. S2SD extends
DML with knowledge distillation from auxiliary, high-dimensional embedding and
feature spaces to leverage complementary context during training while
retaining test-time cost and with negligible changes to the training time.
Experiments and ablations across different objectives and standard benchmarks
show S2SD offering notable improvements of up to 7% in Recall@1, while also
setting a new state-of-the-art. Code available at
https://github.com/MLforHealth/S2SD.
</p>
<a href="http://arxiv.org/abs/2009.08348" target="_blank">arXiv:2009.08348</a> [<a href="http://arxiv.org/pdf/2009.08348" target="_blank">pdf</a>]

<h2>CLEVR Parser: A Graph Parser Library for Geometric Learning on Language Grounded Image Scenes. (arXiv:2009.09154v2 [cs.CL] UPDATED)</h2>
<h3>Raeid Saqur, Ameet Deshpande</h3>
<p>The CLEVR dataset has been used extensively in language grounded visual
reasoning in Machine Learning (ML) and Natural Language Processing (NLP)
domains. We present a graph parser library for CLEVR, that provides
functionalities for object-centric attributes and relationships extraction, and
construction of structural graph representations for dual modalities.
Structural order-invariant representations enable geometric learning and can
aid in downstream tasks like language grounding to vision, robotics,
compositionality, interpretability, and computational grammar construction. We
provide three extensible main components - parser, embedder, and visualizer
that can be tailored to suit specific learning setups. We also provide
out-of-the-box functionality for seamless integration with popular deep graph
neural network (GNN) libraries. Additionally, we discuss downstream usage and
applications of the library, and how it accelerates research for the NLP
research community.
</p>
<a href="http://arxiv.org/abs/2009.09154" target="_blank">arXiv:2009.09154</a> [<a href="http://arxiv.org/pdf/2009.09154" target="_blank">pdf</a>]

<h2>Learning Image Labels On-the-fly for Training Robust Classification Models. (arXiv:2009.10325v2 [cs.CV] UPDATED)</h2>
<h3>Xiaosong Wang, Ziyue Xu, Dong Yang, Leo Tam, Holger Roth, Daguang Xu</h3>
<p>Current deep learning paradigms largely benefit from the tremendous amount of
annotated data. However, the quality of the annotations often varies among
labelers. Multi-observer studies have been conducted to study these annotation
variances (by labeling the same data for multiple times) and its effects on
critical applications like medical image analysis. This process indeed adds an
extra burden to the already tedious annotation work that usually requires
professional training and expertise in the specific domains. On the other hand,
automated annotation methods based on NLP algorithms have recently shown
promise as a reasonable alternative, relying on the existing diagnostic reports
of those images that are widely available in the clinical system. Compared to
human labelers, different algorithms provide labels with varying qualities that
are even noisier. In this paper, we show how noisy annotations (e.g., from
different algorithm-based labelers) can be utilized together and mutually
benefit the learning of classification tasks. Specifically, the concept of
attention-on-label is introduced to sample better label sets on-the-fly as the
training data. A meta-training based label-sampling module is designed to
attend the labels that benefit the model learning the most through additional
back-propagation processes. We apply the attention-on-label scheme on the
classification task of a synthetic noisy CIFAR-10 dataset to prove the concept,
and then demonstrate superior results (3-5% increase on average in multiple
disease classification AUCs) on the chest x-ray images from a hospital-scale
dataset (MIMIC-CXR) and hand-labeled dataset (OpenI) in comparison to regular
training paradigms.
</p>
<a href="http://arxiv.org/abs/2009.10325" target="_blank">arXiv:2009.10325</a> [<a href="http://arxiv.org/pdf/2009.10325" target="_blank">pdf</a>]

<h2>A Variational Auto-Encoder for Reservoir Monitoring. (arXiv:2009.11693v2 [cs.LG] UPDATED)</h2>
<h3>Kristian Gundersen, Seyyed A. Hosseini, Anna Oleynik, Guttorm Alendal</h3>
<p>Carbon dioxide Capture and Storage (CCS) is an important strategy in
mitigating anthropogenic CO$_2$ emissions. In order for CCS to be successful,
large quantities of CO$_2$ must be stored and the storage site conformance must
be monitored. Here we present a deep learning method to reconstruct pressure
fields and classify the flux out of the storage formation based on the pressure
data from Above Zone Monitoring Interval (AZMI) wells. The deep learning method
is a version of a semi conditional variational auto-encoder tailored to solve
two tasks: reconstruction of an incremental pressure field and leakage rate
classification. The method, predictions and associated uncertainty estimates
are illustrated on the synthetic data from a high-fidelity heterogeneous 2D
numerical reservoir model, which was used to simulate subsurface CO$_2$
movement and pressure changes in the AZMI due to a CO$_2$ leakage.
</p>
<a href="http://arxiv.org/abs/2009.11693" target="_blank">arXiv:2009.11693</a> [<a href="http://arxiv.org/pdf/2009.11693" target="_blank">pdf</a>]

<h2>A Gradient Flow Framework For Analyzing Network Pruning. (arXiv:2009.11839v2 [cs.LG] UPDATED)</h2>
<h3>Ekdeep Singh Lubana, Robert P. Dick</h3>
<p>Recent network pruning methods focus on pruning models early-on in training.
To estimate the impact of removing a parameter, these methods use importance
measures that were originally designed to prune trained models. Despite lacking
justification for their use early-on in training, such measures result in
surprisingly low accuracy loss. To better explain this behavior, we develop a
general gradient flow based framework that unifies state-of-the-art importance
measures through the norm of model parameters. We use this framework to
determine the relationship between pruning measures and evolution of model
parameters, establishing several results related to pruning models early-on in
training: (i) magnitude-based pruning removes parameters that contribute least
to reduction in loss, resulting in models that converge faster than
magnitude-agnostic methods; (ii) loss-preservation based pruning preserves
first-order model evolution dynamics and is therefore appropriate for pruning
minimally trained models; and (iii) gradient-norm based pruning affects
second-order model evolution dynamics, such that increasing gradient norm via
pruning can produce poorly performing models. We validate our claims on several
VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10 and CIFAR-100.
Code available at https://github.com/EkdeepSLubana/flowandprune.
</p>
<a href="http://arxiv.org/abs/2009.11839" target="_blank">arXiv:2009.11839</a> [<a href="http://arxiv.org/pdf/2009.11839" target="_blank">pdf</a>]

<h2>Fast Design Space Adaptation with Deep Reinforcement Learning for Analog Circuit Sizing. (arXiv:2009.13772v2 [cs.LG] UPDATED)</h2>
<h3>Kevin-CY Tsai, Kai-En Yang, Hung-Hao Shen, Mike Jiang, Fammy Tsai, CA Wang, Yiju Ting, Jason Yeh, Citi Lai</h3>
<p>We present a novel framework for design space search on analog circuit sizing
using deep reinforcement learning (DRL). Nowadays, analog circuit design is a
manual routine that requires heavy design efforts due to the absence of
automation tools, motivating the urge to develop one. Prior approaches cast
this process as an optimization problem. They use global search strategies
based on DRL with complex network architectures. Nonetheless, the models are
hard to converge and neglected various working conditions of PVT (process,
voltage, temperature).In this work, we reduce the problem to a constraint
satisfaction problem, where a local strategy is adopted. Thus, a simple
feed-forward network with few layers can be used to implement a model-based
reinforcement learning agent. To evaluate the value of the our framework in
production, we cooperate with R&amp;Ds in an IC design company. On circuits with
TSMC advanced 5 and 6nm process, our agents can deliver PPA (performance,
power, area) beyond human level. Furthermore, the product will be taped out in
the near future.
</p>
<a href="http://arxiv.org/abs/2009.13772" target="_blank">arXiv:2009.13772</a> [<a href="http://arxiv.org/pdf/2009.13772" target="_blank">pdf</a>]

<h2>A Multi-term and Multi-task Analyzing Framework for Affective Analysis in-the-wild. (arXiv:2009.13885v2 [cs.CV] UPDATED)</h2>
<h3>Sachihiro Youoku, Yuushi Toyoda, Takahisa Yamamoto, Junya Saito, Ryosuke Kawamura, Xiaoyu Mi, Kentaro Murase</h3>
<p>Human affective recognition is an important factor in human-computer
interaction. However, the method development with in-the-wild data is not yet
accurate enough for practical usage. In this paper, we introduce the affective
recognition method focusing on valence-arousal (VA) and expression (EXP) that
was submitted to the Affective Behavior Analysis in-the-wild (ABAW) 2020
Contest. Since we considered that affective behaviors have many observable
features that have their own time frames, we introduced multiple optimized time
windows (short-term, middle-term, and long-term) into our analyzing framework
for extracting feature parameters from video data. Moreover, multiple modality
data are used, including action units, head poses, gaze, posture, and ResNet 50
or Efficient NET features, and are optimized during the extraction of these
features. Then, we generated affective recognition models for each time window
and ensembled these models together. Also, we fussed the valence, arousal, and
expression models together to enable the multi-task learning, considering the
fact that the basic psychological states behind facial expressions are closely
related to each another. In the validation set, our model achieved a
valence-arousal score of 0.498 and a facial expression score of 0.471. These
verification results reveal that our proposed framework can improve estimation
accuracy and robustness effectively.
</p>
<a href="http://arxiv.org/abs/2009.13885" target="_blank">arXiv:2009.13885</a> [<a href="http://arxiv.org/pdf/2009.13885" target="_blank">pdf</a>]

<h2>Attention-Driven Body Pose Encoding for Human Activity Recognition. (arXiv:2009.14326v2 [cs.CV] UPDATED)</h2>
<h3>B Debnath, M O&#x27;brien, S Kumar, A Behera</h3>
<p>This article proposes a novel attention-based body pose encoding for human
activity recognition that presents a enriched representation of body-pose that
is learned. The enriched data complements the 3D body joint position data and
improves model performance. In this paper, we propose a novel approach that
learns enhanced feature representations from a given sequence of 3D body
joints. To achieve this encoding, the approach exploits 1) a spatial stream
which encodes the spatial relationship between various body joints at each time
point to learn spatial structure involving the spatial distribution of
different body joints 2) a temporal stream that learns the temporal variation
of individual body joints over the entire sequence duration to present a
temporally enhanced representation. Afterwards, these two pose streams are
fused with a multi-head attention mechanism. % adapted from neural machine
translation. We also capture the contextual information from the RGB video
stream using a Inception-ResNet-V2 model combined with a multi-head attention
and a bidirectional Long Short-Term Memory (LSTM) network. %Moreover, we whose
performance is enhanced through the multi-head attention mechanism. Finally,
the RGB video stream is combined with the fused body pose stream to give a
novel end-to-end deep model for effective human activity recognition.
</p>
<a href="http://arxiv.org/abs/2009.14326" target="_blank">arXiv:2009.14326</a> [<a href="http://arxiv.org/pdf/2009.14326" target="_blank">pdf</a>]

<h2>Direct Multi-hop Attention based Graph Neural Network. (arXiv:2009.14332v3 [cs.LG] UPDATED)</h2>
<h3>Guangtao Wang, Rex Ying, Jing Huang, Jure Leskovec</h3>
<p>Introducing self-attention mechanism in graph neural networks (GNNs) achieved
state-of-the-art performance for graph representation learning. However, at
every layer, attention is only computed between two connected nodes and depends
solely on the representation of both nodes. This attention computation cannot
account for the multi-hop neighbors which supply graph structure context
information and have influence on the node representation learning as well. In
this paper, we propose Direct Multi-hop Attention based Graph neural Network
(DAGN) for graph representation learning, a principled way to incorporate
multi-hop neighboring context into attention computation, enabling long-range
interactions at every layer. To compute attention between nodes that are
multiple hops away, DAGN diffuses the attention scores from neighboring nodes
to non-neighboring nodes, thus increasing the receptive field for every message
passing layer. Unlike previous methods, DAGN uses a diffusion prior on
attention values, to efficiently account for all paths between the pair of
nodes when computing multi-hop attention weights. This helps DAGN capture
large-scale structural information in a single layer, and learn more
informative attention distribution. Experimental results on standard
semi-supervised node classification as well as the knowledge graph completion
show that DAGN achieves state-of-the-art results: DAGN achieves up to 5.7%
relative error reduction over the previous state-of-the-art on Cora, Citeseer,
and Pubmed. DAGN also obtains the best performance on a large-scale Open Graph
Benchmark dataset. On knowledge graph completion DAGN advances state-of-the-art
on WN18RR and FB15k-237 across four different performance metrics.
</p>
<a href="http://arxiv.org/abs/2009.14332" target="_blank">arXiv:2009.14332</a> [<a href="http://arxiv.org/pdf/2009.14332" target="_blank">pdf</a>]

<h2>Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval. (arXiv:2009.14661v2 [cs.CV] UPDATED)</h2>
<h3>Tong Yu, Nicolas Padoy</h3>
<p>This paper tackles a new problem in computer vision: mid-stream
video-to-video retrieval. This task, which consists in searching a database for
content similar to a video right as it is playing, e.g. from a live stream,
exhibits challenging characteristics. Only the beginning part of the video is
available as query and new frames are constantly added as the video plays out.
To perform retrieval in this demanding situation, we propose an approach based
on a binary encoder that is both predictive and incremental in order to (1)
account for the missing video content at query time and (2) keep up with
repeated, continuously evolving queries throughout the streaming. In
particular, we present the first hashing framework that infers the unseen
future content of a currently playing video. Experiments on FCVID and
ActivityNet demonstrate the feasibility of this task. Our approach also yields
a significant mAP@20 performance increase compared to a baseline adapted from
the literature for this task, for instance 7.4% (2.6%) increase at 20% (50%) of
elapsed runtime on FCVID using bitcodes of size 192 bits.
</p>
<a href="http://arxiv.org/abs/2009.14661" target="_blank">arXiv:2009.14661</a> [<a href="http://arxiv.org/pdf/2009.14661" target="_blank">pdf</a>]

<h2>Action Units Recognition by Pairwise Deep Architecture. (arXiv:2010.00288v2 [cs.CV] UPDATED)</h2>
<h3>Junya Saito, Ryosuke Kawamura, Akiyoshi Uchida, Sachihiro Youoku, Yuushi Toyoda, Takahisa Yamamoto, Xiaoyu Mi, Kentaro Murase</h3>
<p>In this paper, we propose a new automatic Action Units (AUs) recognition
method used in a competition, Affective Behavior Analysis in-the-wild (ABAW).
Our method tackles a problem of AUs label inconsistency among subjects by using
pairwise deep architecture. While the baseline score is 0.31, our method
achieved 0.67 in validation dataset of the competition.
</p>
<a href="http://arxiv.org/abs/2010.00288" target="_blank">arXiv:2010.00288</a> [<a href="http://arxiv.org/pdf/2010.00288" target="_blank">pdf</a>]

<h2>Quasar Detection using Linear Support Vector Machine with Learning From Mistakes Methodology. (arXiv:2010.00401v2 [cs.LG] UPDATED)</h2>
<h3>Aniruddh Herle, Janamejaya Channegowda, Dinakar Prabhu</h3>
<p>The field of Astronomy requires the collection and assimilation of vast
volumes of data. The data handling and processing problem has become severe as
the sheer volume of data produced by scientific instruments each night grows
exponentially. This problem becomes extensive for conventional methods of
processing the data, which was mostly manual, but is the perfect setting for
the use of Machine Learning approaches. While building classifiers for
Astronomy, the cost of losing a rare object like supernovae or quasars to
detection losses is far more severe than having many false positives, given the
rarity and scientific value of these objects. In this paper, a Linear Support
Vector Machine (LSVM) is explored to detect Quasars, which are extremely bright
objects in which a supermassive black hole is surrounded by a luminous
accretion disk. In Astronomy, it is vital to correctly identify quasars, as
they are very rare in nature. Their rarity creates a class-imbalance problem
that needs to be taken into consideration. The class-imbalance problem and high
cost of misclassification are taken into account while designing the
classifier. To achieve this detection, a novel classifier is explored, and its
performance is evaluated. It was observed that LSVM along with Ensemble Bagged
Trees (EBT) achieved a 10x reduction in the False Negative Rate, using the
Learning from Mistakes methodology.
</p>
<a href="http://arxiv.org/abs/2010.00401" target="_blank">arXiv:2010.00401</a> [<a href="http://arxiv.org/pdf/2010.00401" target="_blank">pdf</a>]

<h2>PipeTune: Pipeline Parallelism of Hyper and System Parameters Tuning for Deep Learning Clusters. (arXiv:2010.00501v2 [cs.DC] UPDATED)</h2>
<h3>Isabelly Rocha, Nathaniel Morris, Lydia Y. Chen, Pascal Felber, Robert Birke, Valerio Schiavoni</h3>
<p>DNN learning jobs are common in today's clusters due to the advances in AI
driven services such as machine translation and image recognition. The most
critical phase of these jobs for model performance and learning cost is the
tuning of hyperparameters. Existing approaches make use of techniques such as
early stopping criteria to reduce the tuning impact on learning cost. However,
these strategies do not consider the impact that certain hyperparameters and
systems parameters have on training time. This paper presents PipeTune, a
framework for DNN learning jobs that addresses the trade-offs between these two
types of parameters. PipeTune takes advantage of the high parallelism and
recurring characteristics of such jobs to minimize the learning cost via a
pipelined simultaneous tuning of both hyper and system parameters. Our
experimental evaluation using three different types of workloads indicates that
PipeTune achieves up to 22.6% reduction and 1.7x speed up on tuning and
training time, respectively. PipeTune not only improves performance but also
lowers energy consumption up to 29%.
</p>
<a href="http://arxiv.org/abs/2010.00501" target="_blank">arXiv:2010.00501</a> [<a href="http://arxiv.org/pdf/2010.00501" target="_blank">pdf</a>]

<h2>D3C: Reducing the Price of Anarchy in Multi-Agent Learning. (arXiv:2010.00575v2 [cs.MA] UPDATED)</h2>
<h3>Ian Gemp, Kevin R. McKee, Richard Everett, Edgar A. Du&#xe9;&#xf1;ez-Guzm&#xe1;n, Yoram Bachrach, David Balduzzi, Andrea Tacchetti</h3>
<p>Even in simple multi-agent systems, fixed incentives can lead to outcomes
that are poor for the group and each individual agent. We propose a method,
D3C, for online adjustment of agent incentives that reduces the loss incurred
at a Nash equilibrium. Agents adjust their incentives by learning to mix their
incentive with that of other agents, until a compromise is reached in a
distributed fashion. We show that D3C improves outcomes for each agent and the
group as a whole on several social dilemmas including a traffic network with
Braess's paradox, a prisoner's dilemma, and several reinforcement learning
domains.
</p>
<a href="http://arxiv.org/abs/2010.00575" target="_blank">arXiv:2010.00575</a> [<a href="http://arxiv.org/pdf/2010.00575" target="_blank">pdf</a>]

