---
title: Latest Deep Learning Papers
date: 2020-10-14 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Deep generative demixing: Recovering Lipschitz signals from noisy subgaussian mixtures. (arXiv:2010.06652v1 [cs.IT])</h2>
<h3>Aaron Berk</h3>
<p>Generative neural networks (GNNs) have gained renown for efficaciously
capturing intrinsic low-dimensional structure in natural images. Here, we
investigate the subgaussian demixing problem for two Lipschitz signals, with
GNN demixing as a special case. In demixing, one seeks identification of two
signals given their sum and prior structural information. Here, we assume each
signal lies in the range of a Lipschitz function, which includes many popular
GNNs as a special case. We prove a sample complexity bound for nearly optimal
recovery error that extends a recent result of Bora, et al. (2017) from the
compressed sensing setting with gaussian matrices to demixing with subgaussian
ones. Under a linear signal model in which the signals lie in convex sets,
McCoy &amp; Tropp (2014) have characterized the sample complexity for
identification under subgaussian mixing. In the present setting, the signal
structure need not be convex. For example, our result applies to a domain that
is a non-convex union of convex cones. We support the efficacy of this demixing
model with numerical simulations using trained GNNs, suggesting an algorithm
that would be an interesting object of further theoretical study.
</p>
<a href="http://arxiv.org/abs/2010.06652" target="_blank">arXiv:2010.06652</a> [<a href="http://arxiv.org/pdf/2010.06652" target="_blank">pdf</a>]

<h2>Non-Bayesian Social Learning on Random Digraphs with Aperiodically Varying Network Connectivity. (arXiv:2010.06695v1 [math.OC])</h2>
<h3>Rohit Parasnis, Massimo Franceschetti, Behrouz Touri</h3>
<p>We study non-Bayesian social learning on random directed graphs and show that
under mild assumptions on the connectivity of the network, all the agents
almost surely learn the true state of the world asymptotically in time if the
sequence of the associated weighted adjacency matrices belongs to Class P* (a
broad class of stochastic chains that subsumes uniformly strongly connected
chains). We show that though uniform strong connectivity is not necessary for
asymptotic learning, it helps ensure that all the agents' beliefs converge to a
consensus almost surely even when the true state is not identifiable. We then
show how our main result applies to a few variants of the original model such
as inertial non-Bayesian learning and learning in the presence of link
failures. Besides, we show that our main result is an extension of a few known
results that pertain to learning on time-varying graphs. We also show by proof
and an example that if the network of influences is balanced in a certain
sense, then asymptotic learning occurs almost surely even in the absence of
uniform strong connectivity.
</p>
<a href="http://arxiv.org/abs/2010.06695" target="_blank">arXiv:2010.06695</a> [<a href="http://arxiv.org/pdf/2010.06695" target="_blank">pdf</a>]

<h2>Operator Inference and Physics-Informed Learning of Low-Dimensional Models for Incompressible Flows. (arXiv:2010.06701v1 [math.DS])</h2>
<h3>Peter Benner, Pawan Goyal, Jan Heiland, Igor Pontes Duff</h3>
<p>Reduced-order modeling has a long tradition in computational fluid dynamics.
The ever-increasing significance of data for the synthesis of low-order models
is well reflected in the recent successes of data-driven approaches such as
Dynamic Mode Decomposition and Operator Inference. With this work, we suggest a
new approach to learning structured low-order models for incompressible flow
from data that can be used for engineering studies such as control,
optimization, and simulation. To that end, we utilize the intrinsic structure
of the Navier-Stokes equations for incompressible flows and show that learning
dynamics of the velocity and pressure can be decoupled, thus leading to an
efficient operator inference approach for learning the underlying dynamics of
incompressible flows. Furthermore, we show the operator inference performance
in learning low-order models using two benchmark problems and compare with an
intrusive method, namely proper orthogonal decomposition, and other data-driven
approaches.
</p>
<a href="http://arxiv.org/abs/2010.06701" target="_blank">arXiv:2010.06701</a> [<a href="http://arxiv.org/pdf/2010.06701" target="_blank">pdf</a>]

<h2>Data-driven Distributionally Robust Optimal Stochastic Control Using theWasserstein Metric. (arXiv:2010.06794v1 [math.OC])</h2>
<h3>Feiran Zhao, Keyou You</h3>
<p>Optimal control of a stochastic dynamical system usually requires a good
dynamical model with probability distributions, which is difficult to obtain
due to limited measurements and/or complicated dynamics. To solve it, this work
proposes a data-driven distributionally robust control framework with the
Wasserstein metric via a constrained two-player zero-sum Markov game, where the
adversarial player selects the probability distribution from a Wasserstein ball
centered at an empirical distribution. Then, the game is approached by its
penalized version, an optimal stabilizing solution of which is derived
explicitly in a linear structure under the Riccati-type iterations. Moreover,
we design a model-free Q-learning algorithm with global convergence to learn
the optimal controller. Finally, we verify the effectiveness of the proposed
learning algorithm and demonstrate its robustness to the probability
distribution errors via numerical examples.
</p>
<a href="http://arxiv.org/abs/2010.06794" target="_blank">arXiv:2010.06794</a> [<a href="http://arxiv.org/pdf/2010.06794" target="_blank">pdf</a>]

<h2>Reinforcement Learning Based Temporal Logic Control with Maximum Probabilistic Satisfaction. (arXiv:2010.06797v1 [cs.FL])</h2>
<h3>Mingyu Cai, Shaoping Xiao, Zhen Kan</h3>
<p>This paper presents a model-free reinforcement learning (RL) algorithm to
synthesize a control policy that maximizes the satisfaction probability of
linear temporal logic (LTL) specifications. Due to the consideration of
environment and motion uncertainties, we model the robot motion as a
probabilistic labeled Markov decision process with unknown transition
probabilities and unknown probabilistic label functions. The LTL task
specification is converted to a limit deterministic generalized B\"uchi
automaton (LDGBA) with several accepting sets to maintain dense rewards during
learning. The novelty of applying LDGBA is to construct an embedded LDGBA
(E-LDGBA) by designing a synchronous tracking-frontier function, which enables
the record of non-visited accepting sets without increasing dimensional and
computational complexity. With appropriate dependent reward and discount
functions, rigorous analysis shows that any method that optimizes the expected
discount return of the RL-based approach is guaranteed to find the optimal
policy that maximizes the satisfaction probability of the LTL specifications. A
model-free RL-based motion planning strategy is developed to generate the
optimal policy in this paper. The effectiveness of the RL-based control
synthesis is demonstrated via simulation and experimental results.
</p>
<a href="http://arxiv.org/abs/2010.06797" target="_blank">arXiv:2010.06797</a> [<a href="http://arxiv.org/pdf/2010.06797" target="_blank">pdf</a>]

<h2>Full-stack Hybrid Beamforming in mmWave 5G Networks. (arXiv:2010.06836v1 [cs.IT])</h2>
<h3>Felipe Gomez-Cuba, Tommaso Zugno, Junseok Kim, Michele Polese, Saewoong Bahk, Michele Zorzi</h3>
<p>This paper analyzes Hybrid Beamforming (HBF) and Multi-User Multiple-Input
Multiple-Output (MU-MIMO) in millimeter wave (mmWave) 5th generation (5G)
cellular networks considering the full protocol stack with TCP/IP traffic and
MAC scheduling. Prior work on HBF and MU-MIMO has assumed full-buffer
transmissions and studied link-level performance. We report non-trivial
interactions between the HBF technique, the front-loaded channel estimation
pilot scheme in NR, and the constraints of MU-MIMO scheduling. We also report
that joint multi-user beamforming design is imperative, in the sense that the
MU-MIMO system cannot be fully exploited when implemented as a mere collection
of single-user analog beams working in parallel. By addressing these issues,
throughput can be dramatically increased in mmWave 5G networks by means of
Spatial Division Multiple Access (SDMA).
</p>
<a href="http://arxiv.org/abs/2010.06836" target="_blank">arXiv:2010.06836</a> [<a href="http://arxiv.org/pdf/2010.06836" target="_blank">pdf</a>]

<h2>Measuring the originality of intellectual property assets based on machine learning outputs. (arXiv:2010.06997v1 [cs.LG])</h2>
<h3>S&#xe9;bastien Ragot</h3>
<p>Originality criteria are frequently used to assess the validity of
intellectual property (IP) rights, such as copyright and design rights. In this
work, the originality of an asset is formulated as a function of the distances
between this asset and its comparands, using concepts of maximum entropy and
surprisal analysis. Namely, this function is defined as the reciprocal of the
surprisal associated with a given asset. Creative assets can justifiably be
compared to particles that repel each other. This allows a very simple formula
to be obtained, in which the originality of a given asset writes as the ratio
of a reference energy to an interaction energy imparted to that asset. In
particular, using an electrostatic-like pair potential makes it possible to
rewrite the originality function as the ratio of two average distances, i.e.,
as the harmonic mean of the distances from the given asset to its comparands
divided by the harmonic mean of the distances between the sole comparands.
Thus, the originality of objects such as IP assets can be simply estimated
based on distances computed according to vectors extracted thanks to
unsupervised machine learning techniques or other algorithms. Application is
made to various types of IP assets, including emojis, typeface designs,
paintings, and novel titles.
</p>
<a href="http://arxiv.org/abs/2010.06997" target="_blank">arXiv:2010.06997</a> [<a href="http://arxiv.org/pdf/2010.06997" target="_blank">pdf</a>]

<h2>Fairness for Freshness: Optimal Age of Information Based OFDMA Scheduling with Minimal Knowledge. (arXiv:2010.07139v1 [cs.IT])</h2>
<h3>Bin Han, Yao Zhu, Zhiyuan Jiang, Muxia Sun, Hans D. Schotten</h3>
<p>It is becoming increasingly clear that an important task for wireless
networks is to minimize the age of information (AoI), i.e., the timeliness of
information delivery. While mainstream approaches generally rely on the
real-time observation of user AoI and channel state, there has been little
attention to solve the problem in a complete (or partial) absence of such
knowledge. In this paper, we present a novel study to address the optimal blind
radio resource scheduling problem in orthogonal frequency division multiplexing
access (OFDMA) systems towards minimizing long-term average AoI, which is
proven to be the composition of time-domain-fair clustered round-robin and
frequency-domain-fair intra-cluster sub-carrier assignment. Heuristic solutions
that are near-optimal as shown by simulation results are also proposed to
effectively improve the performance upon presence of various degrees of extra
knowledge, e.g., channel state and AoI.
</p>
<a href="http://arxiv.org/abs/2010.07139" target="_blank">arXiv:2010.07139</a> [<a href="http://arxiv.org/pdf/2010.07139" target="_blank">pdf</a>]

<h2>Theoretical bounds on estimation error for meta-learning. (arXiv:2010.07140v1 [stat.ML])</h2>
<h3>James Lucas, Mengye Ren, Irene Kameni, Toniann Pitassi, Richard Zemel</h3>
<p>Machine learning models have traditionally been developed under the
assumption that the training and test distributions match exactly. However,
recent success in few-shot learning and related problems are encouraging signs
that these models can be adapted to more realistic settings where train and
test distributions differ. Unfortunately, there is severely limited theoretical
support for these algorithms and little is known about the difficulty of these
problems. In this work, we provide novel information-theoretic lower-bounds on
minimax rates of convergence for algorithms that are trained on data from
multiple sources and tested on novel data. Our bounds depend intuitively on the
information shared between sources of data, and characterize the difficulty of
learning in this setting for arbitrary algorithms. We demonstrate these bounds
on a hierarchical Bayesian model of meta-learning, computing both upper and
lower bounds on parameter estimation via maximum-a-posteriori inference.
</p>
<a href="http://arxiv.org/abs/2010.07140" target="_blank">arXiv:2010.07140</a> [<a href="http://arxiv.org/pdf/2010.07140" target="_blank">pdf</a>]

<h2>Importance of Linking Inertia and Frequency Response Procurement: The Great Britain Case. (arXiv:2010.07161v1 [math.OC])</h2>
<h3>Aimon Mirza Baig, Luis Badesa, Goran Strbac</h3>
<p>In order to decarbonise the electricity sector, the future Great Britain (GB)
power system will be largely dominated by non-synchronous renewables. This will
cause low levels of inertia, a key parameter that could lead to frequency
deterioration. Therefore, the requirement for ancillary services that contain
frequency deviations will increase significantly, particularly given the
increase in size of the largest possible loss with the commissioning of large
nuclear plants in the near future. In this paper, an inertia-dependent
Stochastic Unit Commitment (SUC) model is used to illustrate the benefits of
linking inertia and frequency response provision in low-inertia systems. We
demonstrate that the cost of procuring ancillary services in GB could increase
by 165% if the level of inertia is not explicitly considered when procuring
frequency response. These results highlight the need to re-think the structure
of ancillary-services markets, which in GB are nowadays held one month ahead of
delivery.
</p>
<a href="http://arxiv.org/abs/2010.07161" target="_blank">arXiv:2010.07161</a> [<a href="http://arxiv.org/pdf/2010.07161" target="_blank">pdf</a>]

<h2>Deep brain stimulation for movement disorder treatment: Exploring frequency-dependent efficacy in a computational network model. (arXiv:2010.07162v1 [q-bio.NC])</h2>
<h3>Konstantinos Spiliotis, Jens Starke, Denise Franz, Angelika Richter, R&#xfc;diger K&#xf6;hling</h3>
<p>A large scale computational model of the basal ganglia (BG) network is
proposed to describes movement disorder including deep brain stimulation (DBS).
The model of this complex network considers four areas of the basal ganglia
network: the subthalamic nucleus (STN) as target area of DBS, globus pallidus,
both pars externa and pars interna (GPe-GPi), and the thalamus (THA).
Parkinsonian conditions are simulated by assuming reduced dopaminergic input
and corresponding pronounced inhibitory or disinhibited projections to GPe and
GPi. Macroscopic quantities can be derived which correlate closely to thalamic
responses and hence motor programme fidelity. It can be demonstrated that
depending on different levels of striatal projections to the GPe and GPi, the
dynamics of these macroscopic quantities switch from normal conditions to
parkinsonian. Simulating DBS on the STN affects the dynamics of the entire
network, increasing the thalamic activity to levels close to normal, while
differing from both normal and parkinsonian dynamics. Using the mentioned
macroscopic quantities, the model proposes optimal DBS frequency ranges above
130 Hz.
</p>
<a href="http://arxiv.org/abs/2010.07162" target="_blank">arXiv:2010.07162</a> [<a href="http://arxiv.org/pdf/2010.07162" target="_blank">pdf</a>]

<h2>Deep Neural Network Training with Frank-Wolfe. (arXiv:2010.07243v1 [cs.LG])</h2>
<h3>Sebastian Pokutta, Christoph Spiegel, Max Zimmer</h3>
<p>This paper studies the empirical efficacy and benefits of using
projection-free first-order methods in the form of Conditional Gradients,
a.k.a. Frank-Wolfe methods, for training Neural Networks with constrained
parameters. We draw comparisons both to current state-of-the-art stochastic
Gradient Descent methods as well as across different variants of stochastic
Conditional Gradients. In particular, we show the general feasibility of
training Neural Networks whose parameters are constrained by a convex feasible
region using Frank-Wolfe algorithms and compare different stochastic variants.
We then show that, by choosing an appropriate region, one can achieve
performance exceeding that of unconstrained stochastic Gradient Descent and
matching state-of-the-art results relying on $L^2$-regularization. Lastly, we
also demonstrate that, besides impacting performance, the particular choice of
constraints can have a drastic impact on the learned representations.
</p>
<a href="http://arxiv.org/abs/2010.07243" target="_blank">arXiv:2010.07243</a> [<a href="http://arxiv.org/pdf/2010.07243" target="_blank">pdf</a>]

<h2>Triangulations and Canonical Forms of Amplituhedra: a fiber-based approach beyond polytopes. (arXiv:2010.07254v1 [math.CO])</h2>
<h3>Fatemeh Mohammadi, Leonid Monin, Matteo Parisi</h3>
<p>Any totally positive $(k+m)\times n$ matrix induces a map $\pi_+$ from the
positive Grassmannian $\Gr_+(k,n)$ to $\Gr(k,k+m)$, whose image is the
amplituhedron $\A_{n,k,m}$ and is endowed with a top-degree form called the
canonical form ${\bf\Omega}(\A_{n,k,m})$. This construction was introduced by
Arkani-Hamed and Trnka, where they showed that ${\bf\Omega}(\A_{n,k,4})$
encodes scattering amplitudes in $\mathcal{N}=4$ super Yang-Mills theory.
Moreover, the computation of ${\bf\Omega}(\A_{n,k,m})$ is reduced to finding
the triangulations of $\A_{n,k,m}$. However, while triangulations of polytopes
are fully captured by their secondary and fiber polytopes, the study of
triangulations of objects beyond polytopes is still underdeveloped.

We initiate the geometric study of subdivisions of $\A_{n,k,m}$ in order to
establish the notion of secondary amplituhedron. For this purpose, we provide a
concrete birational parametrization of fibers of the projection $\pi:
\Gr(k,n)\dasharrow \mathcal{A}_{n,k,m}$. We then use this to explicitly
describe a rational top-degree form $\omega_{n,k,m}$ (with simple poles) on the
fibers and compute ${\bf\Omega}(\A_{n,k,m})$ as a summation of certain residues
of $\omega_{n,k,m}$. As main application of our approach, we develop a
well-structured notion of secondary amplituhedra for conjugate to polytopes,
i.e.~when $n-k-1=m$. We show that, in this case, each fiber of $\pi$ is
parameterized by a projective space and its volume form $\omega_{n,k,m}$ has
only poles on a hyperplane arrangement. Using such linear structures, for
amplituhedra which are cyclic polytopes or conjugate to polytopes, we show that
the Jeffrey-Kirwan residue computes ${\bf\Omega}(\A_{n,k,m})$ from the fiber
volume form $\omega_{n,k,m}$. Finally, we propose a more general framework of
fiber positive geometries and analyze new families of examples such as fiber
and Grassmann polytopes.
</p>
<a href="http://arxiv.org/abs/2010.07254" target="_blank">arXiv:2010.07254</a> [<a href="http://arxiv.org/pdf/2010.07254" target="_blank">pdf</a>]

<h2>Regret Guarantees for Online Receding Horizon Control. (arXiv:2010.07269v1 [math.OC])</h2>
<h3>Deepan Muthirayan, Jianjun Yuan, Pramod P. Khargonekar</h3>
<p>In this paper we provide provable regret guarantees for an online receding
horizon type control policy in a setting where the system to be controlled is
an unknown linear dynamical system, the cost for the controller is a general
additive function over a finite period $T$, and there exist control input
constraints that when violated incur an additional cost. We show that the
learning based receding horizon control policy achieves the regret of
$O(T^{3/4})$ for both the controller's cost and cumulative constraint violation
w.r.t the baseline receding horizon control policy that has full knowledge of
the system.
</p>
<a href="http://arxiv.org/abs/2010.07269" target="_blank">arXiv:2010.07269</a> [<a href="http://arxiv.org/pdf/2010.07269" target="_blank">pdf</a>]

<h2>Conformal Symplectic and Relativistic Optimization. (arXiv:1903.04100v5 [math.OC] UPDATED)</h2>
<h3>Guilherme Fran&#xe7;a, Jeremias Sulam, Daniel P. Robinson, Ren&#xe9; Vidal</h3>
<p>Arguably, the two most popular accelerated or momentum-based optimization
methods in machine learning are Nesterov's accelerated gradient and Polyaks's
heavy ball, both corresponding to different discretizations of a particular
second order differential equation with friction. Such connections with
continuous-time dynamical systems have been instrumental in demystifying
acceleration phenomena in optimization. Here we study structure-preserving
discretizations for a certain class of dissipative (conformal) Hamiltonian
systems, allowing us to analyze the symplectic structure of both Nesterov and
heavy ball, besides providing several new insights into these methods.
Moreover, we propose a new algorithm based on a dissipative relativistic system
that normalizes the momentum and may result in more stable/faster optimization.
Importantly, such a method generalizes both Nesterov and heavy ball, each being
recovered as distinct limiting cases, and has potential advantages at no
additional cost.
</p>
<a href="http://arxiv.org/abs/1903.04100" target="_blank">arXiv:1903.04100</a> [<a href="http://arxiv.org/pdf/1903.04100" target="_blank">pdf</a>]

<h2>Online matrix factorization for Markovian data and applications to Network Dictionary Learning. (arXiv:1911.01931v5 [cs.LG] UPDATED)</h2>
<h3>Hanbaek Lyu, Deanna Needell, Laura Balzano</h3>
<p>Online Matrix Factorization (OMF) is a fundamental tool for dictionary
learning problems, giving an approximate representation of complex data sets in
terms of a reduced number of extracted features. Convergence guarantees for
most of the OMF algorithms in the literature assume independence between data
matrices, and the case of dependent data streams remains largely unexplored. In
this paper, we show that a non-convex generalization of the well-known OMF
algorithm for i.i.d. stream of data in \citep{mairal2010online} converges
almost surely to the set of critical points of the expected loss function, even
when the data matrices are functions of some underlying Markov chain satisfying
a mild mixing condition. This allows one to extract features more efficiently
from dependent data streams, as there is no need to subsample the data sequence
to approximately satisfy the independence assumption. As the main application,
by combining online non-negative matrix factorization and a recent MCMC
algorithm for sampling motifs from networks, we propose a novel framework of
Network Dictionary Learning, which extracts ``network dictionary patches' from
a given network in an online manner that encodes main features of the network.
We demonstrate this technique and its application to network denoising problems
on real-world network data.
</p>
<a href="http://arxiv.org/abs/1911.01931" target="_blank">arXiv:1911.01931</a> [<a href="http://arxiv.org/pdf/1911.01931" target="_blank">pdf</a>]

<h2>Experienced Deep Reinforcement Learning with Generative Adversarial Networks (GANs) for Model-Free Ultra Reliable Low Latency Communication. (arXiv:1911.03264v2 [cs.IT] UPDATED)</h2>
<h3>Ali Taleb Zadeh Kasgari, Walid Saad, Mohammad Mozaffari, H. Vincent Poor</h3>
<p>In this paper, a novel experienced deep reinforcement learning (deep-RL)
framework is proposed to provide model-free resource allocation for ultra
reliable low latency communication (URLLC). The proposed, experienced deep-RL
framework can guarantee high end-to-end reliability and low end-to-end latency,
under explicit data rate constraints, for each wireless without any models of
or assumptions on the users' traffic. In particular, in order to enable the
deep-RL framework to account for extreme network conditions and operate in
highly reliable systems, a new approach based on generative adversarial
networks (GANs) is proposed. This GAN approach is used to pre-train the deep-RL
framework using a mix of real and synthetic data, thus creating an experienced
deep-RL framework that has been exposed to a broad range of network conditions.
Formally, the URLLC resource allocation problem is posed as a power
minimization problem under reliability, latency, and rate constraints. To solve
this problem using experienced deep-RL, first, the rate of each user is
determined. Then, these rates are mapped to the resource block and power
allocation vectors of the studied wireless system. Finally, the end-to-end
reliability and latency of each user are used as feedback to the deep-RL
framework. It is then shown that at the fixed-point of the deep-RL algorithm,
the reliability and latency of the users are near-optimal. Moreover, for the
proposed GAN approach, a theoretical limit for the generator output is
analytically derived. Simulation results show how the proposed approach can
achieve near-optimal performance within the rate-reliability-latency region,
depending on the network and service requirements. The results also show that
the proposed experienced deep-RL framework is able to remove the transient
training time that makes conventional deep-RL methods unsuitable for URLLC.
</p>
<a href="http://arxiv.org/abs/1911.03264" target="_blank">arXiv:1911.03264</a> [<a href="http://arxiv.org/pdf/1911.03264" target="_blank">pdf</a>]

<h2>Learning in Markov Decision Processes under Constraints. (arXiv:2002.12435v2 [cs.LG] UPDATED)</h2>
<h3>Rahul Singh, Abhishek Gupta, Ness B. Shroff</h3>
<p>We consider reinforcement learning (RL) in Markov Decision Processes in which
an agent repeatedly interacts with an environment that is modeled by a
controlled Markov process. At each time step $t$, it earns a reward, and also
incurs a cost-vector consisting of $M$ costs. We design learning algorithms
that maximize the cumulative reward earned over a time horizon of $T$
time-steps, while simultaneously ensuring that the average values of the $M$
cost expenditures are bounded by agent-specified thresholds
$c^{ub}_i,i=1,2,\ldots,M$. The considerations on the cumulative cost
expenditures departs from the existing literature, in that the agent now
additionally needs to balance the cost expenses in an online manner, while
simultaneously performing the exploration-exploitation trade-off that is
typically encountered in RL tasks.

In order to measure the performance of a reinforcement learning algorithm
that satisfies the average cost constraints, we define an $M+1$ dimensional
regret vector that is composed of its reward regret, and $M$ cost regrets. The
reward regret measures the sub-optimality in the cumulative reward, while the
$i$-th component of the cost regret vector is the difference between its $i$-th
cumulative cost expense and the expected cost expenditures $Tc^{ub}_i$. We
prove that with a high probablity, the regret vector of UCRL-CMDP is
upper-bounded as $O\left( S\sqrt{AT^{1.5}\log(T)}\right)$, where $S$ is the
number of states, $A$ is the number of actions, and $T$ is the time horizon. We
further show how to reduce the regret of a desired subset of the $M$ costs, at
the expense of increasing the regrets of rewards and the remaining costs. To
the best of our knowledge, ours is the only work that considers non-episodic RL
under average cost constraints, and derive algorithms that can~\emph{tune the
regret vector} according to the agent's requirements on its cost regrets.
</p>
<a href="http://arxiv.org/abs/2002.12435" target="_blank">arXiv:2002.12435</a> [<a href="http://arxiv.org/pdf/2002.12435" target="_blank">pdf</a>]

<h2>A safety aware model based reinforcement learning framework for systems with uncertainties. (arXiv:2007.12666v2 [eess.SY] UPDATED)</h2>
<h3>S M Nahid Mahmud, Katrine Hareland, Scott A Nivison, Zachary I. Bell, Rushikesh Kamalapurkar</h3>
<p>Safety awareness is critical in reinforcement learning when task restarts are
not available and/or when the system is safety critical. Safety requirements
are often expressed in terms of state and/or control constraints. In the past,
model-based reinforcement learning approaches combined with barrier
transformations have been used as an effective tool to learn the optimal
control policy under state constraints for systems with fully known models. In
this paper, a reinforcement learning technique is developed that utilizes a
novel filtered concurrent learning method to realize simultaneous learning and
control in the presence of model uncertainties for safety critical systems.
</p>
<a href="http://arxiv.org/abs/2007.12666" target="_blank">arXiv:2007.12666</a> [<a href="http://arxiv.org/pdf/2007.12666" target="_blank">pdf</a>]

<h2>PAGE: A Simple and Optimal Probabilistic Gradient Estimator for Nonconvex Optimization. (arXiv:2008.10898v2 [cs.LG] UPDATED)</h2>
<h3>Zhize Li, Hongyan Bao, Xiangliang Zhang, Peter Richt&#xe1;rik</h3>
<p>In this paper, we propose a novel stochastic gradient
estimator---ProbAbilistic Gradient Estimator (PAGE)---for nonconvex
optimization. PAGE is easy to implement as it is designed via a small
adjustment to vanilla SGD: in each iteration, PAGE uses the vanilla minibatch
SGD update with probability $p$ or reuses the previous gradient with a small
adjustment, at a much lower computational cost, with probability $1-p$. We give
a simple formula for the optimal choice of $p$. We prove tight lower bounds for
nonconvex problems, which are of independent interest. Moreover, we prove
matching upper bounds both in the finite-sum and online regimes, which
establish that PAGE is an optimal method. Besides, we show that for nonconvex
functions satisfying the Polyak-\L{}ojasiewicz (PL) condition, PAGE can
automatically switch to a faster linear convergence rate. Finally, we conduct
several deep learning experiments (e.g., LeNet, VGG, ResNet) on real datasets
in PyTorch, and the results demonstrate that PAGE not only converges much
faster than SGD in training but also achieves the higher test accuracy,
validating our theoretical results and confirming the practical superiority of
PAGE.
</p>
<a href="http://arxiv.org/abs/2008.10898" target="_blank">arXiv:2008.10898</a> [<a href="http://arxiv.org/pdf/2008.10898" target="_blank">pdf</a>]

<h2>Group-like small cancellation theory for rings. (arXiv:2010.02836v2 [math.RA] UPDATED)</h2>
<h3>A. Atkarskaya (Department of Mathematics, The Hebrew University of Jerusalem, Israel), A. Kanel-Belov (Department of Mathematics, Bar-Ilan University, Israel), E. Plotkin (Department of Mathematics, Bar-Ilan University, Israel), E. Rips (Department of Mathematics, The Hebrew University of Jerusalem, Israel)</h3>
<p>In the present paper we develop a small cancellation theory for associative
algebras with a basis of invertible elements. Namely, we study quotients of a
group algebra of a free group and introduce three axioms for the corresponding
defining relations. We show that the obtained ring is non-trivial. Moreover, we
show that this ring enjoys a global filtration that agrees with relations, find
a basis of the ring as a vector space and establish the corresponding structure
theorems. We also provide a revision of a concept of Gr\"{o}bner basis for our
rings and establish a greedy algorithm for the Ideal Membership Problem.
</p>
<a href="http://arxiv.org/abs/2010.02836" target="_blank">arXiv:2010.02836</a> [<a href="http://arxiv.org/pdf/2010.02836" target="_blank">pdf</a>]

<h2>Search-free DOA Estimation Method Based on Tensor Decomposition and Polynomial Rooting for Transmit Beamspace MIMO Radar. (arXiv:2010.03296v2 [cs.IT] UPDATED)</h2>
<h3>Feng Xu, Xiaopeng Yang, Tian Lan</h3>
<p>In order to improve the accuracy and resolution for transmit beamspace
multiple-input multiple-output (MIMO) radar, a search-free direction-of-arrival
(DOA) estimation method based on tensor decomposition and polynomial rooting is
proposed. In the proposed method, a 3-order tensor is firstly designed to model
the received signal of MIMO radar on the basis of the multi-linear property.
Then, the factor matrix with target DOA information is obtained by the tensor
decomposition via alternating least squares (ALS) algorithm, and subsequently
the DOA estimation is converted into the independent minimization problem. By
exploiting the Vandermonde structure of the transmit steering vector, a
polynomial function is constructed to solve the minimization problem via
polynomial rooting. The factor matrix contained in the coefficients of the
polynomial can be regarded as a block matrix in the generalized sidelobe
canceller (GSC), which accordingly forms a unique deep null in the direction of
target in the transmit beampattern. The proposed method can obtain the DOA
estimation without the requirements of spectrum searching or transmit beamspace
matrix design, which is different from the conventional DOA estimation
techniques. The effectiveness of the proposed method is verified by the
simulations.
</p>
<a href="http://arxiv.org/abs/2010.03296" target="_blank">arXiv:2010.03296</a> [<a href="http://arxiv.org/pdf/2010.03296" target="_blank">pdf</a>]

<h2>k-simplex2vec: a simplicial extension of node2vec. (arXiv:2010.05636v1 [cs.LG] CROSS LISTED)</h2>
<h3>Celia Hacker</h3>
<p>We present a novel method of associating Euclidean features to simplicial
complexes, providing a way to use them as input to statistical and machine
learning tools. This method extends the node2vec algorithm to simplices of
higher dimensions, providing insight into the structure of a simplicial
complex, or into the higher-order interactions in a graph.
</p>
<a href="http://arxiv.org/abs/2010.05636" target="_blank">arXiv:2010.05636</a> [<a href="http://arxiv.org/pdf/2010.05636" target="_blank">pdf</a>]

<h2>Jointly Optimizing Sensing Pipelines for Multimodal Mixed Reality Interaction. (arXiv:2010.06584v1 [cs.HC])</h2>
<h3>Darshana Rathnayake, Ashen de Silva, Dasun Puwakdandawa, Lakmal Meegahapola, Archan Misra, Indika Perera</h3>
<p>Natural human interactions for Mixed Reality Applications are overwhelmingly
multimodal: humans communicate intent and instructions via a combination of
visual, aural and gestural cues. However, supporting low-latency and accurate
comprehension of such multimodal instructions (MMI), on resource-constrained
wearable devices, remains an open challenge, especially as the state-of-the-art
comprehension techniques for each individual modality increasingly utilize
complex Deep Neural Network models. We demonstrate the possibility of
overcoming the core limitation of latency--vs.--accuracy tradeoff by exploiting
cross-modal dependencies - i.e., by compensating for the inferior performance
of one model with an increased accuracy of more complex model of a different
modality. We present a sensor fusion architecture that performs MMI
comprehension in a quasi-synchronous fashion, by fusing visual, speech and
gestural input. The architecture is reconfigurable and supports dynamic
modification of the complexity of the data processing pipeline for each
individual modality in response to contextual changes. Using a representative
"classroom" context and a set of four common interaction primitives, we then
demonstrate how the choices between low and high complexity models for each
individual modality are coupled. In particular, we show that (a) a judicious
combination of low and high complexity models across modalities can offer a
dramatic 3-fold decrease in comprehension latency together with an increase
10-15% in accuracy, and (b) the right collective choice of models is context
dependent, with the performance of some model combinations being significantly
more sensitive to changes in scene context or choice of interaction.
</p>
<a href="http://arxiv.org/abs/2010.06584" target="_blank">arXiv:2010.06584</a> [<a href="http://arxiv.org/pdf/2010.06584" target="_blank">pdf</a>]

<h2>AI-assisted super-resolution cosmological simulations. (arXiv:2010.06608v1 [astro-ph.CO])</h2>
<h3>Yin Li, Yueying Ni, Rupert A. C. Croft, Tiziana Di Matteo, Simeon Bird, Yu Feng</h3>
<p>Cosmological simulations of galaxy formation are limited by finite
computational resources. We draw from the ongoing rapid advances in Artificial
Intelligence (specifically Deep Learning) to address this problem. Neural
networks have been developed to learn from high-resolution (HR) image data, and
then make accurate super-resolution (SR) versions of different low-resolution
(LR) images. We apply such techniques to LR cosmological N-body simulations,
generating SR versions. Specifically, we are able to enhance the simulation
resolution by generating 512 times more particles and predicting their
displacements from the initial positions. Therefore our results can be viewed
as new simulation realizations themselves rather than projections, e.g., to
their density fields. Furthermore, the generation process is stochastic,
enabling us to sample the small-scale modes conditioning on the large-scale
environment. Our model learns from only 16 pairs of LR-HR simulations, and is
then able to generate SR simulations that successfully reproduce the matter
power spectrum and the halo mass function of the HR targets. We successfully
deploy the model in a box 1000 times larger than the training simulation box,
showing that high-resolution mock surveys can be generated rapidly. We conclude
that AI assistance has the potential to revolutionize modeling of small-scale
galaxy formation physics in large cosmological volumes.
</p>
<a href="http://arxiv.org/abs/2010.06608" target="_blank">arXiv:2010.06608</a> [<a href="http://arxiv.org/pdf/2010.06608" target="_blank">pdf</a>]

<h2>On Deep Learning Techniques to Boost Monocular Depth Estimation for Autonomous Navigation. (arXiv:2010.06626v1 [cs.CV])</h2>
<h3>Raul de Queiroz Mendes, Eduardo Godinho Ribeiro, Nicolas dos Santos Rosa, Valdir Grassi Jr</h3>
<p>Inferring the depth of images is a fundamental inverse problem within the
field of Computer Vision since depth information is obtained through 2D images,
which can be generated from infinite possibilities of observed real scenes.
Benefiting from the progress of Convolutional Neural Networks (CNNs) to explore
structural features and spatial image information, Single Image Depth
Estimation (SIDE) is often highlighted in scopes of scientific and
technological innovation, as this concept provides advantages related to its
low implementation cost and robustness to environmental conditions. In the
context of autonomous vehicles, state-of-the-art CNNs optimize the SIDE task by
producing high-quality depth maps, which are essential during the autonomous
navigation process in different locations. However, such networks are usually
supervised by sparse and noisy depth data, from Light Detection and Ranging
(LiDAR) laser scans, and are carried out at high computational cost, requiring
high-performance Graphic Processing Units (GPUs). Therefore, we propose a new
lightweight and fast supervised CNN architecture combined with novel feature
extraction models which are designed for real-world autonomous navigation. We
also introduce an efficient surface normals module, jointly with a simple
geometric 2.5D loss function, to solve SIDE problems. We also innovate by
incorporating multiple Deep Learning techniques, such as the use of
densification algorithms and additional semantic, surface normals and depth
information to train our framework. The method introduced in this work focuses
on robotic applications in indoor and outdoor environments and its results are
evaluated on the competitive and publicly available NYU Depth V2 and KITTI
Depth datasets.
</p>
<a href="http://arxiv.org/abs/2010.06626" target="_blank">arXiv:2010.06626</a> [<a href="http://arxiv.org/pdf/2010.06626" target="_blank">pdf</a>]

<h2>Video Game Level Repair via Mixed Integer Linear Programming. (arXiv:2010.06627v1 [cs.AI])</h2>
<h3>Hejia Zhang, Matthew C. Fontaine, Amy K. Hoover, Julian Togelius, Bistra Dilkina, Stefanos Nikolaidis</h3>
<p>Recent advancements in procedural content generation via machine learning
enable the generation of video-game levels that are aesthetically similar to
human-authored examples. However, the generated levels are often unplayable
without additional editing. We propose a generate-then-repair framework for
automatic generation of playable levels adhering to specific styles. The
framework constructs levels using a generative adversarial network (GAN)
trained with human-authored examples and repairs them using a mixed-integer
linear program (MIP) with playability constraints. A key component of the
framework is computing minimum cost edits between the GAN generated level and
the solution of the MIP solver, which we cast as a minimum cost network flow
problem. Results show that the proposed framework generates a diverse range of
playable levels, that capture the spatial relationships between objects
exhibited in the human-authored levels.
</p>
<a href="http://arxiv.org/abs/2010.06627" target="_blank">arXiv:2010.06627</a> [<a href="http://arxiv.org/pdf/2010.06627" target="_blank">pdf</a>]

<h2>Succinct Explanations With Cascading Decision Trees. (arXiv:2010.06631v1 [cs.LG])</h2>
<h3>Jialu Zhang, Mark Santolucito, Ruzica Piskac</h3>
<p>Classic decision tree learning is a binary classification algorithm that
constructs models with first-class transparency - every classification has a
directly derivable explanation. However, learning decision trees on modern
datasets generates large trees, which in turn generate decision paths of
excessive depth, obscuring the explanation of classifications. To improve the
comprehensibility of classifications, we propose a new decision tree model that
we call Cascading Decision Trees. Cascading Decision Trees shorten the size of
explanations of classifications, without sacrificing model performance overall.
Our key insight is to separate the notion of a decision path and an explanation
path. Utilizing this insight, instead of having one monolithic decision tree,
we build several smaller decision subtrees and cascade them in sequence. Our
cascading decision subtrees are designed to specifically target explanations
for positive classifications. This way each subtree identifies the smallest set
of features that can classify as many positive samples as possible, without
misclassifying any negative samples. Applying cascading decision trees to new
samples results in a significantly shorter and succinct explanation, if one of
the subtrees detects a positive classification. In that case, we immediately
stop and report the decision path of only the current subtree to the user as an
explanation for the classification. We evaluate our algorithm on standard
datasets, as well as new real-world applications and find that our model
shortens the explanation depth by over 40.8% for positive classifications
compared to the classic decision tree model.
</p>
<a href="http://arxiv.org/abs/2010.06631" target="_blank">arXiv:2010.06631</a> [<a href="http://arxiv.org/pdf/2010.06631" target="_blank">pdf</a>]

<h2>Video Action Understanding: A Tutorial. (arXiv:2010.06647v1 [cs.CV])</h2>
<h3>Matthew Hutchinson, Vijay Gadepally</h3>
<p>Many believe that the successes of deep learning on image understanding
problems can be replicated in the realm of video understanding. However, the
span of video action problems and the set of proposed deep learning solutions
is arguably wider and more diverse than those of their 2D image siblings.
Finding, identifying, and predicting actions are a few of the most salient
tasks in video action understanding. This tutorial clarifies a taxonomy of
video action problems, highlights datasets and metrics used to baseline each
problem, describes common data preparation methods, and presents the building
blocks of state-of-the-art deep learning model architectures.
</p>
<a href="http://arxiv.org/abs/2010.06647" target="_blank">arXiv:2010.06647</a> [<a href="http://arxiv.org/pdf/2010.06647" target="_blank">pdf</a>]

<h2>Deep Delay Loop Reservoir Computing for Specific Emitter Identification. (arXiv:2010.06649v1 [eess.SP])</h2>
<h3>Silvija Kokalj-Filipovic, Paul Toliver, William Johnson, Raymond R. Hoare II, Joseph J. Jezak</h3>
<p>Current AI systems at the tactical edge lack the computational resources to
support in-situ training and inference for situational awareness, and it is not
always practical to leverage backhaul resources due to security, bandwidth, and
mission latency requirements. We propose a solution through Deep delay Loop
Reservoir Computing (DLR), a processing architecture supporting general machine
learning algorithms on compact mobile devices by leveraging delay-loop (DL)
reservoir computing in combination with innovative photonic hardware exploiting
the inherent speed, and spatial, temporal and wavelength-based processing
diversity of signals in the optical domain. DLR delivers reductions in form
factor, hardware complexity, power consumption and latency, compared to
State-of-the-Art . DLR can be implemented with a single photonic DL and a few
electro-optical components. In certain cases multiple DL layers increase
learning capacity of the DLR with no added latency. We demonstrate the
advantages of DLR on the application of RF Specific Emitter Identification.
</p>
<a href="http://arxiv.org/abs/2010.06649" target="_blank">arXiv:2010.06649</a> [<a href="http://arxiv.org/pdf/2010.06649" target="_blank">pdf</a>]

<h2>On the Efficiency of K-Means Clustering: Evaluation, Optimization, and Algorithm Selection. (arXiv:2010.06654v1 [cs.DB])</h2>
<h3>Sheng Wang, Yuan Sun, Zhifeng Bao</h3>
<p>This paper presents a thorough evaluation of the existing methods that
accelerate Lloyd's algorithm for fast k-means clustering. To do so, we analyze
the pruning mechanisms of existing methods, and summarize their common pipeline
into a unified evaluation framework UniK. UniK embraces a class of well-known
methods and enables a fine-grained performance breakdown. Within UniK, we
thoroughly evaluate the pros and cons of existing methods using multiple
performance metrics on a number of datasets. Furthermore, we derive an
optimized algorithm over UniK, which effectively hybridizes multiple existing
methods for more aggressive pruning. To take this further, we investigate
whether the most efficient method for a given clustering task can be
automatically selected by machine learning, to benefit practitioners and
researchers.
</p>
<a href="http://arxiv.org/abs/2010.06654" target="_blank">arXiv:2010.06654</a> [<a href="http://arxiv.org/pdf/2010.06654" target="_blank">pdf</a>]

<h2>Towards Data-efficient Modeling for Wake Word Spotting. (arXiv:2010.06659v1 [eess.AS])</h2>
<h3>Yixin Gao, Yuriy Mishchenko, Anish Shah, Spyros Matsoukas, Shiv Vitaladevuni</h3>
<p>Wake word (WW) spotting is challenging in far-field not only because of the
interference in signal transmission but also the complexity in acoustic
environments. Traditional WW model training requires large amount of in-domain
WW-specific data with substantial human annotations therefore it is hard to
build WW models without such data. In this paper we present data-efficient
solutions to address the challenges in WW modeling, such as domain-mismatch,
noisy conditions, limited annotation, etc. Our proposed system is composed of a
multi-condition training pipeline with a stratified data augmentation, which
improves the model robustness to a variety of predefined acoustic conditions,
together with a semi-supervised learning pipeline to accurately extract the WW
and confusable examples from untranscribed speech corpus. Starting from only 10
hours of domain-mismatched WW audio, we are able to enlarge and enrich the
training dataset by 20-100 times to capture the acoustic complexity. Our
experiments on real user data show that the proposed solutions can achieve
comparable performance of a production-grade model by saving 97\% of the amount
of WW-specific data collection and 86\% of the bandwidth for annotation.
</p>
<a href="http://arxiv.org/abs/2010.06659" target="_blank">arXiv:2010.06659</a> [<a href="http://arxiv.org/pdf/2010.06659" target="_blank">pdf</a>]

<h2>Mixed data Deep Gaussian Mixture Model: A clustering model for mixed datasets. (arXiv:2010.06661v1 [cs.LG])</h2>
<h3>Robin Fuchs, Denys Pommeret, Cinzia Viroli</h3>
<p>Clustering mixed data presents numerous challenges inherent to the very
heterogeneous nature of the variables. Two major difficulties lie in the
initialisation of the algorithms and in making variables comparable between
types. This work is concerned with these two problems. We introduce a two-heads
architecture model-based clustering method called Mixed data Deep Gaussian
Mixture Model (MDGMM) that can be viewed as an automatic way to merge the
clusterings performed separately on continuous and non continuous data. We also
design a new initialisation strategy and a data driven method that selects "on
the fly" the best specification of the model and the optimal number of clusters
for a given dataset. Besides, our model provides continuous low-dimensional
representations of the data which can be a useful tool to visualize mixed
datasets. Finally, we validate the performance of our approach comparing its
results with state-of-the-art mixed data clustering models over several
commonly used datasets
</p>
<a href="http://arxiv.org/abs/2010.06661" target="_blank">arXiv:2010.06661</a> [<a href="http://arxiv.org/pdf/2010.06661" target="_blank">pdf</a>]

<h2>Chasing Your Long Tails: Differentially Private Prediction in Health Care Settings. (arXiv:2010.06667v1 [cs.LG])</h2>
<h3>Vinith M. Suriyakumar, Nicolas Papernot, Anna Goldenberg, Marzyeh Ghassemi</h3>
<p>Machine learning models in health care are often deployed in settings where
it is important to protect patient privacy. In such settings, methods for
differentially private (DP) learning provide a general-purpose approach to
learn models with privacy guarantees. Modern methods for DP learning ensure
privacy through mechanisms that censor information judged as too unique. The
resulting privacy-preserving models, therefore, neglect information from the
tails of a data distribution, resulting in a loss of accuracy that can
disproportionately affect small groups. In this paper, we study the effects of
DP learning in health care. We use state-of-the-art methods for DP learning to
train privacy-preserving models in clinical prediction tasks, including x-ray
classification of images and mortality prediction in time series data. We use
these models to perform a comprehensive empirical investigation of the
tradeoffs between privacy, utility, robustness to dataset shift, and fairness.
Our results highlight lesser-known limitations of methods for DP learning in
health care, models that exhibit steep tradeoffs between privacy and utility,
and models whose predictions are disproportionately influenced by large
demographic groups in the training data. We discuss the costs and benefits of
differentially private learning in health care.
</p>
<a href="http://arxiv.org/abs/2010.06667" target="_blank">arXiv:2010.06667</a> [<a href="http://arxiv.org/pdf/2010.06667" target="_blank">pdf</a>]

<h2>LiDAM: Semi-Supervised Learning with Localized Domain Adaptation and Iterative Matching. (arXiv:2010.06668v1 [cs.LG])</h2>
<h3>Qun Liu, Matthew Shreve, Raja Bala</h3>
<p>Although data is abundant, data labeling is expensive. Semi-supervised
learning methods combine a few labeled samples with a large corpus of unlabeled
data to effectively train models. This paper introduces our proposed method
LiDAM, a semi-supervised learning approach rooted in both domain adaptation and
self-paced learning. LiDAM first performs localized domain shifts to extract
better domain-invariant features for the model that results in more accurate
clusters and pseudo-labels. These pseudo-labels are then aligned with real
class labels in a self-paced fashion using a novel iterative matching technique
that is based on majority consistency over high-confidence predictions.
Simultaneously, a final classifier is trained to predict ground-truth labels
until convergence. LiDAM achieves state-of-the-art performance on the CIFAR-100
dataset, outperforming FixMatch (73.50% vs. 71.82%) when using 2500 labels.
</p>
<a href="http://arxiv.org/abs/2010.06668" target="_blank">arXiv:2010.06668</a> [<a href="http://arxiv.org/pdf/2010.06668" target="_blank">pdf</a>]

<h2>Are all negatives created equal in contrastive instance discrimination?. (arXiv:2010.06682v1 [cs.CV])</h2>
<h3>Tiffany (Tianhui)Cai, Jonathan Frankle, David J. Schwab, Ari S. Morcos</h3>
<p>Self-supervised learning has recently begun to rival supervised learning on
computer vision tasks. Many of the recent approaches have been based on
contrastive instance discrimination (CID), in which the network is trained to
recognize two augmented versions of the same instance (a query and positive)
while discriminating against a pool of other instances (negatives). The learned
representation is then used on downstream tasks such as image classification.
Using methodology from MoCo v2 (Chen et al., 2020), we divided negatives by
their difficulty for a given query and studied which difficulty ranges were
most important for learning useful representations. We found a minority of
negatives -- the hardest 5% -- were both necessary and sufficient for the
downstream task to reach nearly full accuracy. Conversely, the easiest 95% of
negatives were unnecessary and insufficient. Moreover, the very hardest 0.1% of
negatives were unnecessary and sometimes detrimental. Finally, we studied the
properties of negatives that affect their hardness, and found that hard
negatives were more semantically similar to the query, and that some negatives
were more consistently easy or hard than we would expect by chance. Together,
our results indicate that negatives vary in importance and that CID may benefit
from more intelligent negative treatment.
</p>
<a href="http://arxiv.org/abs/2010.06682" target="_blank">arXiv:2010.06682</a> [<a href="http://arxiv.org/pdf/2010.06682" target="_blank">pdf</a>]

<h2>Motif Learning in Knowledge Graphsusing Trajectories Of Differential Equations. (arXiv:2010.06684v1 [cs.LG])</h2>
<h3>Mojtaba Nayyeri, Chengjin Xu, Jens Lehmann, Sahar Vahdati</h3>
<p>Knowledge Graph Embeddings (KGEs) have shown promising performance on link
prediction tasks by mapping the entities and relations from a knowledge graph
into a geometric space (usually a vector space). Ultimately, the plausibility
of the predicted links is measured by using a scoring function over the learned
embeddings (vectors). Therefore, the capability in preserving graph
characteristics including structural aspects and semantics highly depends on
the design of the KGE, as well as the inherited abilities from the underlying
geometry. Many KGEs use the flat geometry which renders them incapable of
preserving complex structures and consequently causes wrong inferences by the
models. To address this problem, we propose a neuro differential KGE that
embeds nodes of a KG on the trajectories of Ordinary Differential Equations
(ODEs). To this end, we represent each relation (edge) in a KG as a vector
field on a smooth Riemannian manifold. We specifically parameterize ODEs by a
neural network to represent various complex shape manifolds and more
importantly complex shape vector fields on the manifold. Therefore, the
underlying embedding space is capable of getting various geometric forms to
encode complexity in subgraph structures with different motifs. Experiments on
synthetic and benchmark dataset as well as social network KGs justify the ODE
trajectories as a means to structure preservation and consequently avoiding
wrong inferences over state-of-the-art KGE models.
</p>
<a href="http://arxiv.org/abs/2010.06684" target="_blank">arXiv:2010.06684</a> [<a href="http://arxiv.org/pdf/2010.06684" target="_blank">pdf</a>]

<h2>Applying Graph-based Deep Learning To Realistic Network Scenarios. (arXiv:2010.06686v1 [cs.NI])</h2>
<h3>Miquel Ferriol-Galm&#xe9;s, Jos&#xe9; Su&#xe1;rez-Varela, Pere Barlet-Ros, Albert Cabellos-Aparicio</h3>
<p>Recent advances in Machine Learning (ML) have shown a great potential to
build data-driven solutions for a plethora of network-related problems. In this
context, building fast and accurate network models is essential to achieve
functional optimization tools for networking. However, state-of-the-art
ML-based techniques for network modelling are not able to provide accurate
estimates of important performance metrics such as delay or jitter in realistic
network scenarios with sophisticated queue scheduling configurations. This
paper presents a new Graph-based deep learning model able to estimate
accurately the per-path mean delay in networks. The proposed model can
generalize successfully over topologies, routing configurations, queue
scheduling policies and traffic matrices unseen during the training phase.
</p>
<a href="http://arxiv.org/abs/2010.06686" target="_blank">arXiv:2010.06686</a> [<a href="http://arxiv.org/pdf/2010.06686" target="_blank">pdf</a>]

<h2>Handwriting Quality Analysis using Online-Offline Models. (arXiv:2010.06693v1 [cs.HC])</h2>
<h3>Yahia Hamdi, Hanen Akouaydi, Houcine Boubaker, Adel M. Alimi</h3>
<p>This work is part of an innovative e-learning project allowing the
development of an advanced digital educational tool that provides feedback
during the process of learning handwriting for young school children (three to
eight years old). In this paper, we describe a new method for children
handwriting quality analysis. It automatically detects mistakes, gives
real-time on-line feedback for children's writing, and helps teachers
comprehend and evaluate children's writing skills. The proposed method adjudges
five main criteria shape, direction, stroke order, position respect to the
reference lines, and kinematics of the trace. It analyzes the handwriting
quality and automatically gives feedback based on the combination of three
extracted models: Beta-Elliptic Model (BEM) using similarity detection (SD) and
dissimilarity distance (DD) measure, Fourier Descriptor Model (FDM), and
perceptive Convolutional Neural Network (CNN) with Support Vector Machine (SVM)
comparison engine. The originality of our work lies partly in the system
architecture which apprehends complementary dynamic, geometric, and visual
representation of the examined handwritten scripts and in the efficient
selected features adapted to various handwriting styles and multiple script
languages such as Arabic, Latin, digits, and symbol drawing. The application
offers two interactive interfaces respectively dedicated to learners,
educators, experts or teachers and allows them to adapt it easily to the
specificity of their disciples. The evaluation of our framework is enhanced by
a database collected in Tunisia primary school with 400 children. Experimental
results show the efficiency and robustness of our suggested framework that
helps teachers and children by offering positive feedback throughout the
handwriting learning process using tactile digital devices.
</p>
<a href="http://arxiv.org/abs/2010.06693" target="_blank">arXiv:2010.06693</a> [<a href="http://arxiv.org/pdf/2010.06693" target="_blank">pdf</a>]

<h2>Local Differential Privacy for Bayesian Optimization. (arXiv:2010.06709v1 [cs.LG])</h2>
<h3>Xingyu Zhou, Jian Tan</h3>
<p>Motivated by the increasing concern about privacy in nowadays data-intensive
online learning systems, we consider a black-box optimization in the
nonparametric Gaussian process setting with local differential privacy (LDP)
guarantee. Specifically, the rewards from each user are further corrupted to
protect privacy and the learner only has access to the corrupted rewards to
minimize the regret. We first derive the regret lower bounds for any LDP
mechanism and any learning algorithm. Then, we present three almost optimal
algorithms based on the GP-UCB framework and Laplace DP mechanism. In this
process, we also propose a new Bayesian optimization (BO) method (called
MoMA-GP-UCB) based on median-of-means techniques and kernel approximations,
which complements previous BO algorithms for heavy-tailed payoffs with a
reduced complexity. Further, empirical comparisons of different algorithms on
both synthetic and real-world datasets highlight the superior performance of
MoMA-GP-UCB in both private and non-private scenarios.
</p>
<a href="http://arxiv.org/abs/2010.06709" target="_blank">arXiv:2010.06709</a> [<a href="http://arxiv.org/pdf/2010.06709" target="_blank">pdf</a>]

<h2>Language Networks: a Practical Approach. (arXiv:2010.06710v1 [cs.CL])</h2>
<h3>Jorge A. V. Tohalino, Diego R. Amancio</h3>
<p>This manuscript provides a short and practical introduction to the topic of
language networks. This text aims at assisting researchers with no practical
experience in text and/or network analysis. We provide a practical tutorial on
how to model and characterize texts using network-based features. In this
tutorial, we also include examples of pre-processing and network
representations. A brief description of the main tasks allying network science
and text analysis is also provided. A further development of this text shall
include a practical description of network classification via machine learning
methods.
</p>
<a href="http://arxiv.org/abs/2010.06710" target="_blank">arXiv:2010.06710</a> [<a href="http://arxiv.org/pdf/2010.06710" target="_blank">pdf</a>]

<h2>CoRel: Seed-Guided Topical Taxonomy Construction by Concept Learning and Relation Transferring. (arXiv:2010.06714v1 [cs.CL])</h2>
<h3>Jiaxin Huang, Yiqing Xie, Yu Meng, Yunyi Zhang, Jiawei Han</h3>
<p>Taxonomy is not only a fundamental form of knowledge representation, but also
crucial to vast knowledge-rich applications, such as question answering and web
search. Most existing taxonomy construction methods extract hypernym-hyponym
entity pairs to organize a "universal" taxonomy. However, these generic
taxonomies cannot satisfy user's specific interest in certain areas and
relations. Moreover, the nature of instance taxonomy treats each node as a
single word, which has low semantic coverage. In this paper, we propose a
method for seed-guided topical taxonomy construction, which takes a corpus and
a seed taxonomy described by concept names as input, and constructs a more
complete taxonomy based on user's interest, wherein each node is represented by
a cluster of coherent terms. Our framework, CoRel, has two modules to fulfill
this goal. A relation transferring module learns and transfers the user's
interested relation along multiple paths to expand the seed taxonomy structure
in width and depth. A concept learning module enriches the semantics of each
concept node by jointly embedding the taxonomy and text. Comprehensive
experiments conducted on real-world datasets show that Corel generates
high-quality topical taxonomies and outperforms all the baselines
significantly.
</p>
<a href="http://arxiv.org/abs/2010.06714" target="_blank">arXiv:2010.06714</a> [<a href="http://arxiv.org/pdf/2010.06714" target="_blank">pdf</a>]

<h2>Random Network Distillation as a Diversity Metric for Both Image and Text Generation. (arXiv:2010.06715v1 [cs.LG])</h2>
<h3>Liam Fowl, Micah Goldblum, Arjun Gupta, Amr Sharaf, Tom Goldstein</h3>
<p>Generative models are increasingly able to produce remarkably high quality
images and text. The community has developed numerous evaluation metrics for
comparing generative models. However, these metrics do not effectively quantify
data diversity. We develop a new diversity metric that can readily be applied
to data, both synthetic and natural, of any type. Our method employs random
network distillation, a technique introduced in reinforcement learning. We
validate and deploy this metric on both images and text. We further explore
diversity in few-shot image generation, a setting which was previously
difficult to evaluate.
</p>
<a href="http://arxiv.org/abs/2010.06715" target="_blank">arXiv:2010.06715</a> [<a href="http://arxiv.org/pdf/2010.06715" target="_blank">pdf</a>]

<h2>Grid-Interactive Multi-Zone Building Control Using Reinforcement Learning with Global-Local Policy Search. (arXiv:2010.06718v1 [eess.SY])</h2>
<h3>Xiangyu Zhang, Rohit Chintala, Andrey Bernstein, Peter Graf, Xin Jin</h3>
<p>In this paper, we develop a grid-interactive multi-zone building controller
based on a deep reinforcement learning (RL) approach. The controller is
designed to facilitate building operation during normal conditions and demand
response events, while ensuring occupants comfort and energy efficiency. We
leverage a continuous action space RL formulation, and devise a two-stage
global-local RL training framework. In the first stage, a global fast policy
search is performed using a gradient-free RL algorithm. In the second stage, a
local fine-tuning is conducted using a policy gradient method. In contrast to
the state-of-the-art model predictive control (MPC) approach, the proposed RL
controller does not require complex computation during real-time operation and
can adapt to non-linear building models. We illustrate the controller
performance numerically using a five-zone commercial building.
</p>
<a href="http://arxiv.org/abs/2010.06718" target="_blank">arXiv:2010.06718</a> [<a href="http://arxiv.org/pdf/2010.06718" target="_blank">pdf</a>]

<h2>"What Are You Trying to Do?" Semantic Typing of Event Processes. (arXiv:2010.06724v1 [cs.CL])</h2>
<h3>Muhao Chen, Hongming Zhang, Haoyu Wang, Dan Roth</h3>
<p>This paper studies a new cognitively motivated semantic typing task,
multi-axis event process typing, that, given an event process, attempts to
infer free-form type labels describing (i) the type of action made by the
process and (ii) the type of object the process seeks to affect. This task is
inspired by computational and cognitive studies of event understanding, which
suggest that understanding processes of events is often directed by recognizing
the goals, plans or intentions of the protagonist(s). We develop a large
dataset containing over 60k event processes, featuring ultra fine-grained
typing on both the action and object type axes with very large ($10^3\sim
10^4$) label vocabularies. We then propose a hybrid learning framework, P2GT,
which addresses the challenging typing problem with indirect supervision from
glosses1and a joint learning-to-rank framework. As our experiments indicate,
P2GT supports identifying the intent of processes, as well as the fine semantic
type of the affected object. It also demonstrates the capability of handling
few-shot cases, and strong generalizability on out-of-domain event processes.
</p>
<a href="http://arxiv.org/abs/2010.06724" target="_blank">arXiv:2010.06724</a> [<a href="http://arxiv.org/pdf/2010.06724" target="_blank">pdf</a>]

<h2>Joint Constrained Learning for Event-Event Relation Extraction. (arXiv:2010.06727v1 [cs.CL])</h2>
<h3>Haoyu Wang, Muhao Chen, Hongming Zhang, Dan Roth</h3>
<p>Understanding natural language involves recognizing how multiple event
mentions structurally and temporally interact with each other. In this process,
one can induce event complexes that organize multi-granular events with
temporal order and membership relations interweaving among them. Due to the
lack of jointly labeled data for these relational phenomena and the restriction
on the structures they articulate, we propose a joint constrained learning
framework for modeling event-event relations. Specifically, the framework
enforces logical constraints within and across multiple temporal and subevent
relations by converting these constraints into differentiable learning
objectives. We show that our joint constrained learning approach effectively
compensates for the lack of jointly labeled data, and outperforms SOTA methods
on benchmarks for both temporal relation extraction and event hierarchy
construction, replacing a commonly used but more expensive global inference
process. We also present a promising case study showing the effectiveness of
our approach in inducing event complexes on an external corpus.
</p>
<a href="http://arxiv.org/abs/2010.06727" target="_blank">arXiv:2010.06727</a> [<a href="http://arxiv.org/pdf/2010.06727" target="_blank">pdf</a>]

<h2>Evaluating Tree Explanation Methods for Anomaly Reasoning: A Case Study of SHAP TreeExplainer and TreeInterpreter. (arXiv:2010.06734v1 [cs.AI])</h2>
<h3>Pulkit Sharma, Shezan Rohinton Mirzan, Apurva Bhandari, Anish Pimpley, Abhiram Eswaran, Soundar Srinivasan, Liqun Shao</h3>
<p>Understanding predictions made by Machine Learning models is critical in many
applications. In this work, we investigate the performance of two methods for
explaining tree-based models- Tree Interpreter (TI) and SHapley Additive
exPlanations TreeExplainer (SHAP-TE). Using a case study on detecting anomalies
in job runtimes of applications that utilize cloud-computing platforms, we
compare these approaches using a variety of metrics, including computation
time, significance of attribution value, and explanation accuracy. We find
that, although the SHAP-TE offers consistency guarantees over TI, at the cost
of increased computation, consistency does not necessarily improve the
explanation performance in our case study.
</p>
<a href="http://arxiv.org/abs/2010.06734" target="_blank">arXiv:2010.06734</a> [<a href="http://arxiv.org/pdf/2010.06734" target="_blank">pdf</a>]

<h2>Measuring Visual Generalization in Continuous Control from Pixels. (arXiv:2010.06740v1 [cs.LG])</h2>
<h3>Jake Grigsby, Yanjun Qi</h3>
<p>Self-supervised learning and data augmentation have significantly reduced the
performance gap between state and image-based reinforcement learning agents in
continuous control tasks. However, it is still unclear whether current
techniques can face a variety of visual conditions required by real-world
environments. We propose a challenging benchmark that tests agents' visual
generalization by adding graphical variety to existing continuous control
domains. Our empirical analysis shows that current methods struggle to
generalize across a diverse set of visual changes, and we examine the specific
factors of variation that make these tasks difficult. We find that data
augmentation techniques outperform self-supervised learning approaches and that
more significant image transformations provide better visual generalization
\footnote{The benchmark and our augmented actor-critic implementation are
open-sourced @ https://github.com/jakegrigsby/dmc_remastered)
</p>
<a href="http://arxiv.org/abs/2010.06740" target="_blank">arXiv:2010.06740</a> [<a href="http://arxiv.org/pdf/2010.06740" target="_blank">pdf</a>]

<h2>Analogical and Relational Reasoning with Spiking Neural Networks. (arXiv:2010.06746v1 [cs.NE])</h2>
<h3>Rollin Omari, R. I. (Bob) McKay, Tom Gedeon</h3>
<p>Raven's Progressive Matrices have been widely used for measuring abstract
reasoning and intelligence in humans. However for artificial learning systems,
abstract reasoning remains a challenging problem. In this paper we investigate
how neural networks augmented with biologically inspired spiking modules gain a
significant advantage in solving this problem. To illustrate this, we first
investigate the performance of our networks with supervised learning, then with
unsupervised learning. Experiments on the RAVEN dataset show that the overall
accuracy of our supervised networks surpass human-level performance, while our
unsupervised networks significantly outperform existing unsupervised methods.
Finally, our results from both supervised and unsupervised learning illustrate
that, unlike their non-augmented counterparts, networks with spiking modules
are able to extract and encode temporal features without any explicit
instruction, do not heavily rely on training data, and generalise more readily
to new problems. In summary, the results reported here indicate that artificial
neural networks with spiking modules are well suited to solving abstract
reasoning.
</p>
<a href="http://arxiv.org/abs/2010.06746" target="_blank">arXiv:2010.06746</a> [<a href="http://arxiv.org/pdf/2010.06746" target="_blank">pdf</a>]

<h2>AlphaZero Based Post-Storm Vehicle Routing for Distribution Grid Restoration. (arXiv:2010.06764v1 [eess.SY])</h2>
<h3>Hang Shuai, Haibo He</h3>
<p>Natural disasters such as storms usually bring significant damages to
distribution grids. However, plenty of distribution grids are not installed
sensors that can pinpoint the location of damaged equipments (lines,
transforms, etc.), which greatly increased the difficulty of the outage
restoration. This paper investigates the optimal routing of repair vehicles to
restore outages in distribution grid as fast as possible after a storm. First,
the vehicle routing problem is formulated as a sequential stochastic
optimization problem. In the formulated optimization model, the belief state of
the power grid is updated according to the phone calls from customers and the
information collected by the repair vehicles. Second, an AlphaZero based
utility vehicle routing (AlphaZero-UVR) approach is developed to achieve the
real-time dispatching of the repair vehicle. The proposed AlphaZero-UVR
approach combines deep neural networks with a Monte-Carlo tree search (MCTS) to
give a lookahead search decisions, which can learn to navigate the repair
vehicle without human guidance. Simulation results show that the proposed
approach can effectively navigate the vehicle to repair all outages.
</p>
<a href="http://arxiv.org/abs/2010.06764" target="_blank">arXiv:2010.06764</a> [<a href="http://arxiv.org/pdf/2010.06764" target="_blank">pdf</a>]

<h2>Scaling Hamiltonian Monte Carlo Inference for Bayesian Neural Networks with Symmetric Splitting. (arXiv:2010.06772v1 [stat.ML])</h2>
<h3>Adam D. Cobb, Brian Jalaian</h3>
<p>Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) approach
that exhibits favourable exploration properties in high-dimensional models such
as neural networks. Unfortunately, HMC has limited use in large-data regimes
and little work has explored suitable approaches that aim to preserve the
entire Hamiltonian. In our work, we introduce a new symmetric integration
scheme for split HMC that does not rely on stochastic gradients. We show that
our new formulation is more efficient than previous approaches and is easy to
implement with a single GPU. As a result, we are able to perform full HMC over
common deep learning architectures using entire data sets. In addition, when we
compare with stochastic gradient MCMC, we show that our method achieves better
performance in both accuracy and uncertainty quantification. Our approach
demonstrates HMC as a feasible option when considering inference schemes for
large-scale machine learning problems.
</p>
<a href="http://arxiv.org/abs/2010.06772" target="_blank">arXiv:2010.06772</a> [<a href="http://arxiv.org/pdf/2010.06772" target="_blank">pdf</a>]

<h2>Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision. (arXiv:2010.06775v1 [cs.CL])</h2>
<h3>Hao Tan, Mohit Bansal</h3>
<p>Humans learn language by listening, speaking, writing, reading, and also, via
interaction with the multimodal real world. Existing language pre-training
frameworks show the effectiveness of text-only self-supervision while we
explore the idea of a visually-supervised language model in this paper. We find
that the main reason hindering this exploration is the large divergence in
magnitude and distributions between the visually-grounded language datasets and
pure-language corpora. Therefore, we develop a technique named "vokenization"
that extrapolates multimodal alignments to language-only data by contextually
mapping language tokens to their related images (which we call "vokens"). The
"vokenizer" is trained on relatively small image captioning datasets and we
then apply it to generate vokens for large language corpora. Trained with these
contextually generated vokens, our visually-supervised language models show
consistent improvements over self-supervised alternatives on multiple
pure-language tasks such as GLUE, SQuAD, and SWAG. Code and pre-trained models
publicly available at https://github.com/airsplay/vokenization
</p>
<a href="http://arxiv.org/abs/2010.06775" target="_blank">arXiv:2010.06775</a> [<a href="http://arxiv.org/pdf/2010.06775" target="_blank">pdf</a>]

<h2>A Self-supervised Representation Learning of Sentence Structure for Authorship Attribution. (arXiv:2010.06786v1 [cs.CL])</h2>
<h3>Fereshteh Jafariakinabad, Kien A. Hua</h3>
<p>Syntactic structure of sentences in a document substantially informs about
its authorial writing style. Sentence representation learning has been widely
explored in recent years and it has been shown that it improves the
generalization of different downstream tasks across many domains. Even though
utilizing probing methods in several studies suggests that these learned
contextual representations implicitly encode some amount of syntax, explicit
syntactic information further improves the performance of deep neural models in
the domain of authorship attribution. These observations have motivated us to
investigate the explicit representation learning of syntactic structure of
sentences. In this paper, we propose a self-supervised framework for learning
structural representations of sentences. The self-supervised network contains
two components; a lexical sub-network and a syntactic sub-network which take
the sequence of words and their corresponding structural labels as the input,
respectively. Due to the n-to-1 mapping of words to their structural labels,
each word will be embedded into a vector representation which mainly carries
structural information. We evaluate the learned structural representations of
sentences using different probing tasks, and subsequently utilize them in the
authorship attribution task. Our experimental results indicate that the
structural embeddings significantly improve the classification tasks when
concatenated with the existing pre-trained word embeddings.
</p>
<a href="http://arxiv.org/abs/2010.06786" target="_blank">arXiv:2010.06786</a> [<a href="http://arxiv.org/pdf/2010.06786" target="_blank">pdf</a>]

<h2>Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach. (arXiv:2010.06792v1 [cs.CL])</h2>
<h3>Bowen Tan, Lianhui Qin, Eric P. Xing, Zhiting Hu</h3>
<p>Given a document and a target aspect (e.g., a topic of interest),
aspect-based abstractive summarization attempts to generate a summary with
respect to the aspect. Previous studies usually assume a small pre-defined set
of aspects and fall short of summarizing on other diverse topics. In this work,
we study summarizing on arbitrary aspects relevant to the document, which
significantly expands the application of the task in practice. Due to the lack
of supervision data, we develop a new weak supervision construction method and
an aspect modeling scheme, both of which integrate rich external knowledge
sources such as ConceptNet and Wikipedia. Experiments show our approach
achieves performance boosts on summarizing both real and synthetic documents
given pre-defined or arbitrary aspects.
</p>
<a href="http://arxiv.org/abs/2010.06792" target="_blank">arXiv:2010.06792</a> [<a href="http://arxiv.org/pdf/2010.06792" target="_blank">pdf</a>]

<h2>Tire Slip Angle Estimation based on the Intelligent Tire Technology. (arXiv:2010.06803v1 [eess.SY])</h2>
<h3>Nan Xu, Yanjun Huang, Hassan Askari, Zepeng Tang</h3>
<p>Tire slip angle is a vital parameter in tire/vehicle dynamics and control.
This paper proposes an accurate estimation method by the fusion of intelligent
tire technology and machine-learning techniques. The intelligent tire is
equipped by MEMS accelerometers attached to its inner liner. First, we describe
the intelligent tire system along with the implemented testing apparatus.
Second, experimental results under different loading and velocity conditions
are provided. Then,~we show the procedure of data processing, which will be
used for training three different machine learning techniques to estimate tire
slip angles. The results show that the machine learning techniques, especially
in frequency domain, can accurately estimate tire slip angles up to 10 degrees.
More importantly, with the accurate tire slip angle estimation, all other
states and parameters can be easily and precisely obtained, which is
significant to vehicle advanced control, and thus this study has a high
potential to obviously improve the vehicle safety especially in extreme
maneuvers.
</p>
<a href="http://arxiv.org/abs/2010.06803" target="_blank">arXiv:2010.06803</a> [<a href="http://arxiv.org/pdf/2010.06803" target="_blank">pdf</a>]

<h2>Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout. (arXiv:2010.06808v1 [cs.LG])</h2>
<h3>Zhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong, Henrik Kretzschmar, Yuning Chai, Dragomir Anguelov</h3>
<p>The vast majority of deep models use multiple gradient signals, typically
corresponding to a sum of multiple loss terms, to update a shared set of
trainable weights. However, these multiple updates can impede optimal training
by pulling the model in conflicting directions. We present Gradient Sign
Dropout (GradDrop), a probabilistic masking procedure which samples gradients
at an activation layer based on their level of consistency. GradDrop is
implemented as a simple deep layer that can be used in any deep net and
synergizes with other gradient balancing approaches. We show that GradDrop
outperforms the state-of-the-art multiloss methods within traditional multitask
and transfer learning settings, and we discuss how GradDrop reveals links
between optimal multiloss training and gradient stochasticity.
</p>
<a href="http://arxiv.org/abs/2010.06808" target="_blank">arXiv:2010.06808</a> [<a href="http://arxiv.org/pdf/2010.06808" target="_blank">pdf</a>]

<h2>Transfer2Attack: Text Adversarial Attack with Cross-Domain Interpretability. (arXiv:2010.06812v1 [cs.LG])</h2>
<h3>Mahmoud Hossam, Trung Le, He Zhao, Dinh Phung</h3>
<p>Training robust deep learning models for down-stream tasks is a critical
challenge. Research has shown that common down-stream models can be easily
fooled with adversarial inputs that look like the training data, but slightly
perturbed, in a way imperceptible to humans. Understanding the behavior of
natural language models under these attacks is crucial to better defend these
models against such attacks. In the black-box attack setting, where no access
to model parameters is available, the attacker can only query the output
information from the targeted model to craft a successful attack. Current
black-box state-of-the-art models are costly in both computational complexity
and number of queries needed to craft successful adversarial examples. For real
world scenarios, the number of queries is critical, where less queries are
desired to avoid suspicion towards an attacking agent. In this paper, we
propose Transfer2Attack, a black-box adversarial attack on text classification
task, that employs cross-domain interpretability to reduce target model queries
during attack. We show that our framework either achieves or out-performs
attack rates of the state-of-the-art models, yet with lower queries cost and
higher efficiency.
</p>
<a href="http://arxiv.org/abs/2010.06812" target="_blank">arXiv:2010.06812</a> [<a href="http://arxiv.org/pdf/2010.06812" target="_blank">pdf</a>]

<h2>TriNE: Network Representation Learning for Tripartite Heterogeneous Networks. (arXiv:2010.06816v1 [cs.LG])</h2>
<h3>Zhabiz Gharibshah, Xingquan Zhu</h3>
<p>In this paper, we study network representation learning for tripartite
heterogeneous networks which learns node representation features for networks
with three types of node entities. We argue that tripartite networks are common
in real world applications, and the essential challenge of the representation
learning is the heterogeneous relations between various node types and links in
the network. To tackle the challenge, we develop a tripartite heterogeneous
network embedding called TriNE. The method considers unique user-item-tag
tripartite relationships, to build an objective function to model explicit
relationships between nodes (observed links), and also capture implicit
relationships between tripartite nodes (unobserved links across tripartite node
sets). The method organizes metapath guided random walks to create
heterogeneous neighborhood for all node types in the network. This information
is then utilized to train a heterogeneous skip-gram model based on a joint
optimization. Experiments on real-world tripartite networks validate the
performance of TriNE for the online user response prediction using embedding
node features.
</p>
<a href="http://arxiv.org/abs/2010.06816" target="_blank">arXiv:2010.06816</a> [<a href="http://arxiv.org/pdf/2010.06816" target="_blank">pdf</a>]

<h2>Modeling Protagonist Emotions for Emotion-Aware Storytelling. (arXiv:2010.06822v1 [cs.CL])</h2>
<h3>Faeze Brahman, Snigdha Chaturvedi</h3>
<p>Emotions and their evolution play a central role in creating a captivating
story. In this paper, we present the first study on modeling the emotional
trajectory of the protagonist in neural storytelling. We design methods that
generate stories that adhere to given story titles and desired emotion arcs for
the protagonist. Our models include Emotion Supervision (EmoSup) and two
Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards
designed to regularize the story generation process through reinforcement
learning. Our automatic and manual evaluations demonstrate that these models
are significantly better at generating stories that follow the desired emotion
arcs compared to baseline methods, without sacrificing story quality.
</p>
<a href="http://arxiv.org/abs/2010.06822" target="_blank">arXiv:2010.06822</a> [<a href="http://arxiv.org/pdf/2010.06822" target="_blank">pdf</a>]

<h2>A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering. (arXiv:2010.06835v1 [cs.CL])</h2>
<h3>Svitlana Vakulenko, Shayne Longpre, Zhucheng Tu, Raviteja Anantha</h3>
<p>The dependency between an adequate question formulation and correct answer
selection is a very intriguing but still underexplored area. In this paper, we
show that question rewriting (QR) of the conversational context allows to shed
more light on this phenomenon and also use it to evaluate robustness of
different answer selection approaches. We introduce a simple framework that
enables an automated analysis of the conversational question answering (QA)
performance using question rewrites, and present the results of this analysis
on the TREC CAsT and QuAC (CANARD) datasets. Our experiments uncover
sensitivity to question formulation of the popular state-of-the-art models for
reading comprehension and passage ranking. Our results demonstrate that the
reading comprehension model is insensitive to question formulation, while the
passage ranking changes dramatically with a little variation in the input
question. The benefit of QR is that it allows us to pinpoint and group such
cases automatically. We show how to use this methodology to verify whether QA
models are really learning the task or just finding shortcuts in the dataset,
and better understand the frequent types of error they make.
</p>
<a href="http://arxiv.org/abs/2010.06835" target="_blank">arXiv:2010.06835</a> [<a href="http://arxiv.org/pdf/2010.06835" target="_blank">pdf</a>]

<h2>Multi-Scale Networks for 3D Human PoseEstimation with Inference Stage Optimization. (arXiv:2010.06844v1 [cs.CV])</h2>
<h3>Cheng Yu, Bo Wang, Bo Yang, Robby T. Tan</h3>
<p>Estimating 3D human poses from a monocular video is still a challenging task.
Many existing methods' performance drops when the target person is occluded by
other objects, or the motion is too fast/slow relative to the scale and speed
of the training data. Moreover, many of these methods are not designed or
trained under severe occlusion explicitly, making their performance on handling
occlusion compromised. Addressing these problems, we introduce a
spatio-temporal network for robust 3D human pose estimation. As humans in
videos may appear in different scales and have various motion speeds, we apply
multi-scale spatial features for 2D joints or keypoints prediction in each
individual frame, and multi-stride temporal convolutional networks (TCNs) to
estimate 3D joints or keypoints. Furthermore, we design a spatio-temporal
discriminator based on body structures as well as limb motions to assess
whether the predicted pose forms a valid pose and a valid movement. During
training, we explicitly mask out some keypoints to simulate various occlusion
cases, from minor to severe occlusion, so that our network can learn better and
becomes robust to various degrees of occlusion. As there are limited 3D
ground-truth data, we further utilize 2D video data to inject a semi-supervised
learning capability to our network. Moreover, we observe that there is a
discrepancy between 3D pose prediction and 2D pose estimation due to different
pose variations between video and image training datasets. We, therefore
propose a confidence-based inference stage optimization to adaptively enforce
3D pose projection to match 2D pose estimation to further improve final pose
prediction accuracy. Experiments on public datasets validate the effectiveness
of our method, and our ablation studies show the strengths of our network's
individual submodules.
</p>
<a href="http://arxiv.org/abs/2010.06844" target="_blank">arXiv:2010.06844</a> [<a href="http://arxiv.org/pdf/2010.06844" target="_blank">pdf</a>]

<h2>Extended Koopman Models. (arXiv:2010.06845v1 [eess.SY])</h2>
<h3>Span Spanbauer, Ian Hunter</h3>
<p>We introduce two novel generalizations of the Koopman operator method of
nonlinear dynamic modeling. Each of these generalizations leads to greatly
improved predictive performance without sacrificing a unique trait of Koopman
methods: the potential for fast, globally optimal control of nonlinear,
nonconvex systems. The first generalization, Convex Koopman Models, uses convex
rather than linear dynamics in the lifted space. The second, Extended Koopman
Models, additionally introduces an invertible transformation of the control
signal which contributes to the lifted convex dynamics. We describe a deep
learning architecture for parameterizing these classes of models, and show
experimentally that each significantly outperforms traditional Koopman models
in trajectory prediction for two nonlinear, nonconvex dynamic systems.
</p>
<a href="http://arxiv.org/abs/2010.06845" target="_blank">arXiv:2010.06845</a> [<a href="http://arxiv.org/pdf/2010.06845" target="_blank">pdf</a>]

<h2>Reconstruct Anomaly to Normal: Adversarial Learned and Latent Vector-constrained Autoencoder for Time-series Anomaly Detection. (arXiv:2010.06846v1 [cs.LG])</h2>
<h3>Chunkai Zhang, Wei Zuo, Xuan Wang</h3>
<p>Anomaly detection in time series has been widely researched and has important
practical applications. In recent years, anomaly detection algorithms are
mostly based on deep-learning generative models and use the reconstruction
error to detect anomalies. They try to capture the distribution of normal data
by reconstructing normal data in the training phase, then calculate the
reconstruction error of test data to do anomaly detection. However, most of
them only use the normal data in the training phase and can not ensure the
reconstruction process of anomaly data. So, anomaly data can also be well
reconstructed sometimes and gets low reconstruction error, which leads to the
omission of anomalies. What's more, the neighbor information of data points in
time series data has not been fully utilized in these algorithms. In this
paper, we propose RAN based on the idea of Reconstruct Anomalies to Normal and
apply it for unsupervised time series anomaly detection. To minimize the
reconstruction error of normal data and maximize this of anomaly data, we do
not just ensure normal data to reconstruct well, but also try to make the
reconstruction of anomaly data consistent with the distribution of normal data,
then anomalies will get higher reconstruction errors. We implement this idea by
introducing the "imitated anomaly data" and combining a specially designed
latent vector-constrained Autoencoder with the discriminator to construct an
adversary network. Extensive experiments on time-series datasets from different
scenes such as ECG diagnosis also show that RAN can detect meaningful
anomalies, and it outperforms other algorithms in terms of AUC-ROC.
</p>
<a href="http://arxiv.org/abs/2010.06846" target="_blank">arXiv:2010.06846</a> [<a href="http://arxiv.org/pdf/2010.06846" target="_blank">pdf</a>]

<h2>A Review of Cyber-Ranges and Test-Beds: Current and Future Trends. (arXiv:2010.06850v1 [cs.CR])</h2>
<h3>Elochukwu Ukwandu, Mohamed Amine Ben Farah, Hanan Hindy, David Brosset, Dimitris Kavallieros, Robert Atkinson, Christos Tachtatzis, Miroslav Bures, Ivan Andonovic, Xavier Bellekens</h3>
<p>Cyber situational awareness has been proven to be of value in forming a
comprehensive understanding of threats and vulnerabilities within
organisations, as the degree of exposure is governed by the prevailing levels
of cyber-hygiene and established processes. A more accurate assessment of the
security provision informs on the most vulnerable environments that necessitate
more diligent management. The rapid proliferation in the automation of
cyber-attacks is reducing the gap between information and operational
technologies and the need to review the current levels of robustness against
new sophisticated cyber-attacks, trends, technologies and mitigation
countermeasures has become pressing. A deeper characterisation is also the
basis with which to predict future vulnerabilities in turn guiding the most
appropriate deployment technologies. Thus, refreshing established practices and
the scope of the training to support the decision making of users and
operators. The foundation of the training provision is the use of Cyber-Ranges
(CRs) and Test-Beds (TBs), platforms/tools that help inculcate a deeper
understanding of the evolution of an attack and the methodology to deploy the
most impactful countermeasures to arrest breaches. In this paper, an evaluation
of documented CR and TB platforms is evaluated. CRs and TBs are segmented by
type, technology, threat scenarios, applications and the scope of attainable
training. To enrich the analysis of documented CR and TB research and cap the
study, a taxonomy is developed to provide a broader comprehension of the future
of CRs and TBs. The taxonomy elaborates on the CRs/TBs different dimensions, as
well as, highlighting a diminishing differentiation between application areas.
</p>
<a href="http://arxiv.org/abs/2010.06850" target="_blank">arXiv:2010.06850</a> [<a href="http://arxiv.org/pdf/2010.06850" target="_blank">pdf</a>]

<h2>GreedyFool: An Imperceptible Black-box Adversarial Example Attack against Neural Networks. (arXiv:2010.06855v1 [cs.LG])</h2>
<h3>Hui Liu, Bo Zhao, Jiabao Guo, Pengyuan Zhao, Peng Liu</h3>
<p>Deep neural networks (DNNs) are inherently vulnerable to well-designed input
samples called adversarial examples. The adversary can easily fool DNNs by
adding slight perturbations to the input. In this paper, we propose a novel
black-box adversarial example attack named GreedyFool, which synthesizes
adversarial examples based on the differential evolution and the greedy
approximation. The differential evolution is utilized to evaluate the effects
of perturbed pixels on the confidence of the DNNs-based classifier. The greedy
approximation is an approximate optimization algorithm to automatically get
adversarial perturbations. Existing works synthesize the adversarial examples
by leveraging simple metrics to penalize the perturbations, which lack
sufficient consideration of the human visual system (HVS), resulting in
noticeable artifacts. In order to sufficient imperceptibility, we launch a lot
of investigations into the HVS and design an integrated metric considering just
noticeable distortion (JND), Weber-Fechner law, texture masking and channel
modulation, which is proven to be a better metric to measure the perceptual
distance between the benign examples and the adversarial ones. The experimental
results demonstrate that the GreedyFool has several remarkable properties
including black-box, 100% success rate, flexibility, automation and can
synthesize the more imperceptible adversarial examples than the
state-of-the-art pixel-wise methods.
</p>
<a href="http://arxiv.org/abs/2010.06855" target="_blank">arXiv:2010.06855</a> [<a href="http://arxiv.org/pdf/2010.06855" target="_blank">pdf</a>]

<h2>Learning Word Representations for Tunisian Sentiment Analysis. (arXiv:2010.06857v1 [cs.CL])</h2>
<h3>Abir Messaoudi, Hatem Haddad, Moez Ben HajHmida, Chayma Fourati, Abderrazak Ben Hamida</h3>
<p>Tunisians on social media tend to express themselves in their local dialect
using Latin script (TUNIZI). This raises an additional challenge to the process
of exploring and recognizing online opinions. To date, very little work has
addressed TUNIZI sentiment analysis due to scarce resources for training an
automated system. In this paper, we focus on the Tunisian dialect sentiment
analysis used on social media. Most of the previous work used machine learning
techniques combined with handcrafted features. More recently, Deep Neural
Networks were widely used for this task, especially for the English language.
In this paper, we explore the importance of various unsupervised word
representations (word2vec, BERT) and we investigate the use of Convolutional
Neural Networks and Bidirectional Long Short-Term Memory. Without using any
kind of handcrafted features, our experimental results on two publicly
available datasets showed comparable performances to other languages.
</p>
<a href="http://arxiv.org/abs/2010.06857" target="_blank">arXiv:2010.06857</a> [<a href="http://arxiv.org/pdf/2010.06857" target="_blank">pdf</a>]

<h2>Deep Ensembles for Low-Data Transfer Learning. (arXiv:2010.06866v1 [cs.LG])</h2>
<h3>Basil Mustafa, Carlos Riquelme, Joan Puigcerver, andAndr&#xe9; Susano Pinto, Daniel Keysers, Neil Houlsby</h3>
<p>In the low-data regime, it is difficult to train good supervised models from
scratch. Instead practitioners turn to pre-trained models, leveraging transfer
learning. Ensembling is an empirically and theoretically appealing way to
construct powerful predictive models, but the predominant approach of training
multiple deep networks with different random initialisations collides with the
need for transfer via pre-trained weights. In this work, we study different
ways of creating ensembles from pre-trained models. We show that the nature of
pre-training itself is a performant source of diversity, and propose a
practical algorithm that efficiently identifies a subset of pre-trained models
for any downstream dataset. The approach is simple: Use nearest-neighbour
accuracy to rank pre-trained models, fine-tune the best ones with a small
hyperparameter sweep, and greedily construct an ensemble to minimise validation
cross-entropy. When evaluated together with strong baselines on 19 different
downstream tasks (the Visual Task Adaptation Benchmark), this achieves
state-of-the-art performance at a much lower inference budget, even when
selecting from over 2,000 pre-trained models. We also assess our ensembles on
ImageNet variants and show improved robustness to distribution shift.
</p>
<a href="http://arxiv.org/abs/2010.06866" target="_blank">arXiv:2010.06866</a> [<a href="http://arxiv.org/pdf/2010.06866" target="_blank">pdf</a>]

<h2>FedGroup: Ternary Cosine Similarity-based Clustered Federated Learning Framework toward High Accuracy in Heterogeneity Data. (arXiv:2010.06870v1 [cs.LG])</h2>
<h3>Moming Duan, Duo Liu, Xinyuan Ji, Renping Liu, Liang Liang, Xianzhang Chen, Yujuan Tan</h3>
<p>Federated Learning (FL) enables the multiple participating devices to
collaboratively contribute to a global neural network model while keeping the
training data locally. Unlike the centralized training setting, the non-IID and
imbalanced (statistical heterogeneity) training data of FL is distributed in
the federated network, which will increase the divergences between the local
models and global model and further degrade the performance. In this paper, we
propose a novel federated learning framework FedGroup based on a
similarity-based clustering strategy, in which we 1) group the training of
clients based on the ternary cosine similarities between the clients' parameter
updates; 2) reduce the clustering complexity of high-dimension low-sample size
(HDLSS) parameter updates data by decomposed the direction vectors to derive
the ternary cosine similarity metrics for clustering. FedGroup can achieve
improvements by dividing joint optimization into groups of sub-optimization,
and can be combined with \textit{FedProx}, the state-of-the-art federated
optimization algorithm. We evaluate FedGroup and FedGrouProx (combined with
FedProx) on several open datasets. The experimental results show that our
proposed frameworks significantly improving absolute test accuracy by +14.7% on
FEMNIST compared to FedAvg, +5.4% on Sentiment140 compared to FedProx.
</p>
<a href="http://arxiv.org/abs/2010.06870" target="_blank">arXiv:2010.06870</a> [<a href="http://arxiv.org/pdf/2010.06870" target="_blank">pdf</a>]

<h2>A Heteroscedastic Likelihood Model for Two-frame Optical Flow. (arXiv:2010.06871v1 [cs.RO])</h2>
<h3>Timothy Farnworth, Christopher Renton, Reuben Strydom, Adrian Wills, Tristan Perez</h3>
<p>Machine vision is an important sensing technology used in mobile robotic
systems. Advancing the autonomy of such systems requires accurate
characterisation of sensor uncertainty. Vision includes intrinsic uncertainty
due to the camera sensor and extrinsic uncertainty due to environmental
lighting and texture, which propagate through the image processing algorithms
used to produce visual measurements. To faithfully characterise visual
measurements, we must take into account these uncertainties. In this paper, we
propose a new class of likelihood functions that characterises the uncertainty
of the error distribution of two-frame optical flow that enables a
heteroscedastic dependence on texture. We employ the proposed class to
characterise the Farneback and Lucas Kanade optical flow algorithms and achieve
close agreement with their respective empirical error distributions over a wide
range of texture in a simulated environment. The utility of the proposed
likelihood model is demonstrated in a visual odometry ego-motion simulation
study, which results in 30-83% reduction in position drift rate compared to
traditional methods employing a Gaussian error assumption. The development of
an empirically congruent likelihood model advances the requisite tool-set for
vision-based Bayesian inference and enables sensor data fusion with GPS, LiDAR
and IMU to advance robust autonomous navigation.
</p>
<a href="http://arxiv.org/abs/2010.06871" target="_blank">arXiv:2010.06871</a> [<a href="http://arxiv.org/pdf/2010.06871" target="_blank">pdf</a>]

<h2>Semantic Segmentation for Partially Occluded Apple Trees Based on Deep Learning. (arXiv:2010.06879v1 [cs.CV])</h2>
<h3>Zijue Chen, David Ting, Rhys Newbury, Chao Chen</h3>
<p>Fruit tree pruning and fruit thinning require a powerful vision system that
can provide high resolution segmentation of the fruit trees and their branches.
However, recent works only consider the dormant season, where there are minimal
occlusions on the branches or fit a polynomial curve to reconstruct branch
shape and hence, losing information about branch thickness. In this work, we
apply two state-of-the-art supervised learning models U-Net and DeepLabv3, and
a conditional Generative Adversarial Network Pix2Pix (with and without the
discriminator) to segment partially occluded 2D-open-V apple trees. Binary
accuracy, Mean IoU, Boundary F1 score and Occluded branch recall were used to
evaluate the performances of the models. DeepLabv3 outperforms the other models
at Binary accuracy, Mean IoU and Boundary F1 score, but is surpassed by Pix2Pix
(without discriminator) and U-Net in Occluded branch recall. We define two
difficulty indices to quantify the difficulty of the task: (1) Occlusion
Difficulty Index and (2) Depth Difficulty Index. We analyze the worst 10 images
in both difficulty indices by means of Branch Recall and Occluded Branch
Recall. U-Net outperforms the other two models in the current metrics. On the
other hand, Pix2Pix (without discriminator) provides more information on branch
paths, which are not reflected by the metrics. This highlights the need for
more specific metrics on recovering occluded information. Furthermore, this
shows the usefulness of image-transfer networks for hallucination behind
occlusions. Future work is required to further enhance the models to recover
more information from occlusions such that this technology can be applied to
automating agricultural tasks in a commercial environment.
</p>
<a href="http://arxiv.org/abs/2010.06879" target="_blank">arXiv:2010.06879</a> [<a href="http://arxiv.org/pdf/2010.06879" target="_blank">pdf</a>]

<h2>Neural Mixture Distributional Regression. (arXiv:2010.06889v1 [stat.CO])</h2>
<h3>David R&#xfc;gamer, Florian Pfisterer, Bernd Bischl</h3>
<p>We present neural mixture distributional regression (NMDR), a holistic
framework to estimate complex finite mixtures of distributional regressions
defined by flexible additive predictors. Our framework is able to handle a
large number of mixtures of potentially different distributions in
high-dimensional settings, allows for efficient and scalable optimization and
can be applied to recent concepts that combine structured regression models
with deep neural networks. While many existing approaches for mixture models
address challenges in optimization of such and provide results for convergence
under specific model assumptions, our approach is assumption-free and instead
makes use of optimizers well-established in deep learning. Through extensive
numerical experiments and a high-dimensional deep learning application we
provide evidence that the proposed approach is competitive to existing
approaches and works well in more complex scenarios.
</p>
<a href="http://arxiv.org/abs/2010.06889" target="_blank">arXiv:2010.06889</a> [<a href="http://arxiv.org/pdf/2010.06889" target="_blank">pdf</a>]

<h2>Identifying Wrongly Predicted Samples: A Method for Active Learning. (arXiv:2010.06890v1 [cs.LG])</h2>
<h3>Rahaf Aljundi, Nikolay Chumerin, Daniel Olmeda Reino</h3>
<p>State-of-the-art machine learning models require access to significant amount
of annotated data in order to achieve the desired level of performance. While
unlabelled data can be largely available and even abundant, annotation process
can be quite expensive and limiting. Under the assumption that some samples are
more important for a given task than others, active learning targets the
problem of identifying the most informative samples that one should acquire
annotations for. Instead of the conventional reliance on model uncertainty as a
proxy to leverage new unknown labels, in this work we propose a simple sample
selection criterion that moves beyond uncertainty. By first accepting the model
prediction and then judging its effect on the generalization error, we can
better identify wrongly predicted samples. We further present an approximation
to our criterion that is very efficient and provides a similarity based
interpretation. In addition to evaluating our method on the standard benchmarks
of active learning, we consider the challenging yet realistic scenario of
imbalanced data where categories are not equally represented. We show
state-of-the-art results and better rates at identifying wrongly predicted
samples. Our method is simple, model agnostic and relies on the current model
status without the need for re-training from scratch.
</p>
<a href="http://arxiv.org/abs/2010.06890" target="_blank">arXiv:2010.06890</a> [<a href="http://arxiv.org/pdf/2010.06890" target="_blank">pdf</a>]

<h2>Adaptive-Attentive Geolocalization from few queries: a hybrid approach. (arXiv:2010.06897v1 [cs.CV])</h2>
<h3>Gabriele Moreno Berton, Valerio Paolicelli, Carlo Masone, Barbara Caputo</h3>
<p>We address the task of cross-domain visual place recognition, where the goal
is to geolocalize a given query image against a labeled gallery, in the case
where the query and the gallery belong to different visual domains. To achieve
this, we focus on building a domain robust deep network by leveraging over an
attention mechanism combined with few-shot unsupervised domain adaptation
techniques, where we use a small number of unlabeled target domain images to
learn about the target distribution. With our method, we are able to outperform
the current state of the art while using two orders of magnitude less target
domain images. Finally we propose a new large-scale dataset for cross-domain
visual place recognition, called SVOX. Upon acceptance of the paper, code and
dataset will be released.
</p>
<a href="http://arxiv.org/abs/2010.06897" target="_blank">arXiv:2010.06897</a> [<a href="http://arxiv.org/pdf/2010.06897" target="_blank">pdf</a>]

<h2>No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet Detection. (arXiv:2010.06906v1 [cs.CL])</h2>
<h3>Debanjana Kar, Mohit Bhardwaj, Suranjana Samanta, Amar Prakash Azad</h3>
<p>The sudden widespread menace created by the present global pandemic COVID-19
has had an unprecedented effect on our lives. Man-kind is going through
humongous fear and dependence on social media like never before. Fear
inevitably leads to panic, speculations, and the spread of misinformation. Many
governments have taken measures to curb the spread of such misinformation for
public well being. Besides global measures, to have effective outreach, systems
for demographically local languages have an important role to play in this
effort. Towards this, we propose an approach to detect fake news about COVID-19
early on from social media, such as tweets, for multiple Indic-Languages
besides English. In addition, we also create an annotated dataset of Hindi and
Bengali tweet for fake news detection. We propose a BERT based model augmented
with additional relevant features extracted from Twitter to identify fake
tweets. To expand our approach to multiple Indic languages, we resort to mBERT
based model which is fine-tuned over created dataset in Hindi and Bengali. We
also propose a zero-shot learning approach to alleviate the data scarcity issue
for such low resource languages. Through rigorous experiments, we show that our
approach reaches around 89% F-Score in fake tweet detection which supercedes
the state-of-the-art (SOTA) results. Moreover, we establish the first benchmark
for two Indic-Languages, Hindi and Bengali. Using our annotated data, our model
achieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our
zero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali
Tweets without any annotated data, which clearly indicates the efficacy of our
approach.
</p>
<a href="http://arxiv.org/abs/2010.06906" target="_blank">arXiv:2010.06906</a> [<a href="http://arxiv.org/pdf/2010.06906" target="_blank">pdf</a>]

<h2>AMPA-Net: Optimization-Inspired Attention Neural Network for Deep Compressed Sensing. (arXiv:2010.06907v1 [cs.CV])</h2>
<h3>Nanyu Li, Charles C. Zhou</h3>
<p>Compressed sensing (CS) is a challenging problem in image processing due to
reconstructing an almost complete image from a limited measurement. To achieve
fast and accurate CS reconstruction, we synthesize the advantages of two
well-known methods (neural network and optimization algorithm) to propose a
novel optimization inspired neural network which dubbed AMP-Net. AMP-Net
realizes the fusion of the Approximate Message Passing (AMP) algorithm and
neural network. All of its parameters are learned automatically. Furthermore,
we propose an AMPA-Net which uses three attention networks to improve the
representation ability of AMP-Net. Finally, We demonstrate the effectiveness of
AMP-Net and AMPA-Net on four CS reconstruction benchmark data sets.
</p>
<a href="http://arxiv.org/abs/2010.06907" target="_blank">arXiv:2010.06907</a> [<a href="http://arxiv.org/pdf/2010.06907" target="_blank">pdf</a>]

<h2>UAV Path Planning using Global and Local Map Information with Deep Reinforcement Learning. (arXiv:2010.06917v1 [cs.RO])</h2>
<h3>Mirco Theile, Harald Bayerlein, Richard Nai, David Gesbert, Marco Caccamo</h3>
<p>Path planning methods for autonomous unmanned aerial vehicles (UAVs) are
typically designed for one specific type of mission. In this work, we present a
method for autonomous UAV path planning based on deep reinforcement learning
(DRL) that can be applied to a wide range of mission scenarios. Specifically,
we compare coverage path planning (CPP), where the UAV's goal is to survey an
area of interest to data harvesting (DH), where the UAV collects data from
distributed Internet of Things (IoT) sensor devices. By exploiting structured
map information of the environment, we train double deep Q-networks (DDQNs)
with identical architectures on both distinctly different mission scenarios, to
make movement decisions that balance the respective mission goal with
navigation constraints. By introducing a novel approach exploiting a compressed
global map of the environment combined with a cropped but uncompressed local
map showing the vicinity of the UAV agent, we demonstrate that the proposed
method can efficiently scale to large environments. We also extend previous
results for generalizing control policies that require no retraining when
scenario parameters change and offer a detailed analysis of crucial map
processing parameters' effects on path planning performance.
</p>
<a href="http://arxiv.org/abs/2010.06917" target="_blank">arXiv:2010.06917</a> [<a href="http://arxiv.org/pdf/2010.06917" target="_blank">pdf</a>]

<h2>PP-LinkNet: Improving Semantic Segmentation of High Resolution Satellite Imagery with Multi-stage Training. (arXiv:2010.06932v1 [cs.CV])</h2>
<h3>An Tran, Ali Zonoozi, Jagannadan Varadarajan, Hannes Kruppa</h3>
<p>Road network and building footprint extraction is essential for many
applications such as updating maps, traffic regulations, city planning,
ride-hailing, disaster response \textit{etc}. Mapping road networks is
currently both expensive and labor-intensive. Recently, improvements in image
segmentation through the application of deep neural networks has shown
promising results in extracting road segments from large scale, high resolution
satellite imagery. However, significant challenges remain due to lack of enough
labeled training data needed to build models for industry grade applications.
In this paper, we propose a two-stage transfer learning technique to improve
robustness of semantic segmentation for satellite images that leverages noisy
pseudo ground truth masks obtained automatically (without human labor) from
crowd-sourced OpenStreetMap (OSM) data. We further propose Pyramid
Pooling-LinkNet (PP-LinkNet), an improved deep neural network for segmentation
that uses focal loss, poly learning rate, and context module. We demonstrate
the strengths of our approach through evaluations done on three popular
datasets over two tasks, namely, road extraction and building foot-print
detection. Specifically, we obtain 78.19\% meanIoU on SpaceNet building
footprint dataset, 67.03\% and 77.11\% on the road topology metric on SpaceNet
and DeepGlobe road extraction dataset, respectively.
</p>
<a href="http://arxiv.org/abs/2010.06932" target="_blank">arXiv:2010.06932</a> [<a href="http://arxiv.org/pdf/2010.06932" target="_blank">pdf</a>]

<h2>Practical Deep Raw Image Denoising on Mobile Devices. (arXiv:2010.06935v1 [eess.IV])</h2>
<h3>Yuzhi Wang, Haibin Huang, Qin Xu, Jiaming Liu, Yiqun Liu, Jue Wang</h3>
<p>Deep learning-based image denoising approaches have been extensively studied
in recent years, prevailing in many public benchmark datasets. However, the
stat-of-the-art networks are computationally too expensive to be directly
applied on mobile devices. In this work, we propose a light-weight, efficient
neural network-based raw image denoiser that runs smoothly on mainstream mobile
devices, and produces high quality denoising results. Our key insights are
twofold: (1) by measuring and estimating sensor noise level, a smaller network
trained on synthetic sensor-specific data can out-perform larger ones trained
on general data; (2) the large noise level variation under different ISO
settings can be removed by a novel k-Sigma Transform, allowing a small network
to efficiently handle a wide range of noise levels. We conduct extensive
experiments to demonstrate the efficiency and accuracy of our approach. Our
proposed mobile-friendly denoising model runs at ~70 milliseconds per megapixel
on Qualcomm Snapdragon 855 chipset, and it is the basis of the night shot
feature of several flagship smartphones released in 2019.
</p>
<a href="http://arxiv.org/abs/2010.06935" target="_blank">arXiv:2010.06935</a> [<a href="http://arxiv.org/pdf/2010.06935" target="_blank">pdf</a>]

<h2>Deep Learning from Small Amount of Medical Data with Noisy Labels: A Meta-Learning Approach. (arXiv:2010.06939v1 [cs.CV])</h2>
<h3>G&#xf6;rkem Algan, Ilkay Ulusoy, &#x15e;aban G&#xf6;n&#xfc;l, Banu Turgut, Berker Bakbak</h3>
<p>Computer vision systems recently made a big leap thanks to deep neural
networks. However, these systems require correctly labeled large datasets in
order to be trained properly, which is very difficult to obtain for medical
applications. Two main reasons for label noise in medical applications are the
high complexity of the data and conflicting opinions of experts. Moreover,
medical imaging datasets are commonly tiny, which makes each data very
important in learning. As a result, if not handled properly, label noise
significantly degrades the performance. Therefore, we propose a
label-noise-robust learning algorithm that makes use of the meta-learning
paradigm. We tested our proposed solution on retinopathy of prematurity (ROP)
dataset with a very high label noise of 68%. Our results show that the proposed
algorithm significantly improves the classification algorithm's performance in
the presence of noisy labels.
</p>
<a href="http://arxiv.org/abs/2010.06939" target="_blank">arXiv:2010.06939</a> [<a href="http://arxiv.org/pdf/2010.06939" target="_blank">pdf</a>]

<h2>Pair the Dots: Jointly Examining Training History and Test Stimuli for Model Interpretability. (arXiv:2010.06943v1 [cs.CL])</h2>
<h3>Yuxian Meng, Chun Fan, Zijun Sun, Eduard Hovy, Fei Wu, Jiwei Li</h3>
<p>Any prediction from a model is made by a combination of learning history and
test stimuli. This provides significant insights for improving model
interpretability: {\it because of which part(s) of which training example(s),
the model attends to which part(s) of a test example}. Unfortunately, existing
methods to interpret a model's predictions are only able to capture a single
aspect of either test stimuli or learning history, and evidences from both are
never combined or integrated. In this paper, we propose an efficient and
differentiable approach to make it feasible to interpret a model's prediction
by jointly examining training history and test stimuli. Test stimuli is first
identified by gradient-based methods, signifying {\it the part of a test
example that the model attends to}. The gradient-based saliency scores are then
propagated to training examples using influence functions to identify {\it
which part(s) of which training example(s)} make the model attends to the test
stimuli. The system is differentiable and time efficient: the adoption of
saliency scores from gradient-based methods allows us to efficiently trace a
model's prediction through test stimuli, and then back to training examples
through influence functions. We demonstrate that the proposed methodology
offers clear explanations about neural model decisions, along with being useful
for performing error analysis, crafting adversarial examples and fixing
erroneously classified examples.
</p>
<a href="http://arxiv.org/abs/2010.06943" target="_blank">arXiv:2010.06943</a> [<a href="http://arxiv.org/pdf/2010.06943" target="_blank">pdf</a>]

<h2>Scalable Graph Networks for Particle Simulations. (arXiv:2010.06948v1 [cs.LG])</h2>
<h3>Karolis Martinkus, Aurelien Lucchi, Nathana&#xeb;l Perraudin</h3>
<p>Learning system dynamics directly from observations is a promising direction
in machine learning due to its potential to significantly enhance our ability
to understand physical systems. However, the dynamics of many real-world
systems are challenging to learn due to the presence of nonlinear potentials
and a number of interactions that scales quadratically with the number of
particles $N$, as in the case of the N-body problem. In this work, we introduce
an approach that transforms a fully-connected interaction graph into a
hierarchical one which reduces the number of edges to $O(N)$. This results in
linear time and space complexity while the pre-computation of the hierarchical
graph requires $O(N\log (N))$ time and $O(N)$ space. Using our approach, we are
able to train models on much larger particle counts, even on a single GPU. We
evaluate how the phase space position accuracy and energy conservation depend
on the number of simulated particles. Our approach retains high accuracy and
efficiency even on large-scale gravitational N-body simulations which are
impossible to run on a single machine if a fully-connected graph is used.
Similar results are also observed when simulating Coulomb interactions.
Furthermore, we make several important observations regarding the performance
of this new hierarchical model, including: i) its accuracy tends to improve
with the number of particles in the simulation and ii) its generalisation to
unseen particle counts is also much better than for models that use all
$O(N^2)$ interactions.
</p>
<a href="http://arxiv.org/abs/2010.06948" target="_blank">arXiv:2010.06948</a> [<a href="http://arxiv.org/pdf/2010.06948" target="_blank">pdf</a>]

<h2>Consumer Behaviour in Retail: Next Logical Purchase using Deep Neural Network. (arXiv:2010.06952v1 [cs.LG])</h2>
<h3>Ankur Verma</h3>
<p>Predicting future consumer behaviour is one of the most challenging problems
for large scale retail firms. Accurate prediction of consumer purchase pattern
enables better inventory planning and efficient personalized marketing
strategies. Optimal inventory planning helps minimise instances of
Out-of-stock/ Excess Inventory and, smart Personalized marketing strategy
ensures smooth and delightful shopping experience. Consumer purchase prediction
problem has generally been addressed by ML researchers in conventional manners,
either through recommender systems or traditional ML approaches. Such modelling
approaches do not generalise well in predicting consumer purchase pattern. In
this paper, we present our study of consumer purchase behaviour, wherein, we
establish a data-driven framework to predict whether a consumer is going to
purchase an item within a certain time frame using e-commerce retail data. To
model this relationship, we create a sequential time-series data for all
relevant consumer-item combinations. We then build generalized non-linear
models by generating features at the intersection of consumer, item, and time.
We demonstrate robust performance by experimenting with different neural
network architectures, ML models, and their combinations. We present the
results of 60 modelling experiments with varying Hyperparameters along with
Stacked Generalization ensemble and F1-Maximization framework. We then present
the benefits that neural network architectures like Multi Layer Perceptron,
Long Short Term Memory (LSTM), Temporal Convolutional Networks (TCN) and
TCN-LSTM bring over ML models like Xgboost and RandomForest.
</p>
<a href="http://arxiv.org/abs/2010.06952" target="_blank">arXiv:2010.06952</a> [<a href="http://arxiv.org/pdf/2010.06952" target="_blank">pdf</a>]

<h2>Self-Imitation Learning in Sparse Reward Settings. (arXiv:2010.06962v1 [cs.LG])</h2>
<h3>Zhixin Chen, Mengxiang Lin</h3>
<p>The application of reinforcement learning (RL) in real-world is still limited
in the environments with sparse and delayed rewards. Self-imitation learning
(SIL) is developed as an auxiliary component of RL to relieve the problem by
encouraging the agents to imitate their historical best behaviors. In this
paper, we propose a practical SIL algorithm named Self-Imitation Learning with
Constant Reward (SILCR). Instead of requiring hand-defined immediate rewards
from environments, our algorithm assigns the immediate rewards at each timestep
with constant values according to their final episodic rewards. In this way,
even if the dense rewards from environments are unavailable, every action taken
by the agents would be guided properly. We demonstrate the effectiveness of our
method in some challenging MuJoCo locomotion tasks and the results show that
our method significantly outperforms the alternative methods in tasks with
delayed and sparse rewards. Even compared with alternatives with dense rewards
available, our method achieves competitive performance. The ablation
experiments also show the stability and reproducibility of our method.
</p>
<a href="http://arxiv.org/abs/2010.06962" target="_blank">arXiv:2010.06962</a> [<a href="http://arxiv.org/pdf/2010.06962" target="_blank">pdf</a>]

<h2>NwQM: A neural quality assessment framework for Wikipedia. (arXiv:2010.06969v1 [cs.SI])</h2>
<h3>Bhanu Prakash Reddy, Sasi Bhusan, Soumya Sarkar, Animesh Mukherjee</h3>
<p>Millions of people irrespective of socioeconomic and demographic backgrounds,
depend on Wikipedia articles everyday for keeping themselves informed regarding
popular as well as obscure topics. Articles have been categorized by editors
into several quality classes, which indicate their reliability as encyclopedic
content. This manual designation is an onerous task because it necessitates
profound knowledge about encyclopedic language, as well navigating circuitous
set of wiki guidelines. In this paper we propose Neural wikipedia
QualityMonitor (NwQM), a novel deep learning model which accumulates signals
from several key information sources such as article text, meta data and images
to obtain improved Wikipedia article representation. We present comparison of
our approach against a plethora of available solutions and show 8% improvement
over state-of-the-art approaches with detailed ablation studies.
</p>
<a href="http://arxiv.org/abs/2010.06969" target="_blank">arXiv:2010.06969</a> [<a href="http://arxiv.org/pdf/2010.06969" target="_blank">pdf</a>]

<h2>Medical Code Assignment with Gated Convolution and Note-Code Interaction. (arXiv:2010.06975v1 [cs.CL])</h2>
<h3>Shaoxiong Ji, Shirui Pan, Pekka Marttinen</h3>
<p>Medical code assignment from clinical text is a fundamental task in clinical
information system management. As medical notes are typically lengthy and the
medical coding system's code space is large, this task is a long-standing
challenge. Recent work applies deep neural network models to encode the medical
notes and assign medical codes to clinical documents. However, these methods
are still ineffective as they do not fully encode and capture the lengthy and
rich semantic information of medical notes nor explicitly exploit the
interactions between the notes and codes. We propose a novel method, gated
convolutional neural networks, and a note-code interaction (GatedCNN-NCI), for
automatic medical code assignment to overcome these challenges. Our methods
capture the rich semantic information of the lengthy clinical text for better
representation by utilizing embedding injection and gated information
propagation in the medical note encoding module. With a novel note-code
interaction design and a graph message passing mechanism, we explicitly capture
the underlying dependency between notes and codes, enabling effective code
prediction. A weight sharing scheme is further designed to decrease the number
of trainable parameters. Empirical experiments on real-world clinical datasets
show that our proposed model outperforms state-of-the-art models in most cases,
and our model size is on par with light-weighted baselines.
</p>
<a href="http://arxiv.org/abs/2010.06975" target="_blank">arXiv:2010.06975</a> [<a href="http://arxiv.org/pdf/2010.06975" target="_blank">pdf</a>]

<h2>Ranking for Individual and Group Fairness Simultaneously. (arXiv:2010.06986v1 [cs.IR])</h2>
<h3>Sruthi Gorantla, Amit Deshpande, Anand Louis</h3>
<p>Search and recommendation systems, such as search engines, recruiting tools,
online marketplaces, news, and social media, output ranked lists of content,
products, and sometimes, people. Credit ratings, standardized tests, risk
assessments output only a score, but are also used implicitly for ranking. Bias
in such ranking systems, especially among the top ranks, can worsen social and
economic inequalities, polarize opinions, and reinforce stereotypes. On the
other hand, a bias correction for minority groups can cause more harm if
perceived as favoring group-fair outcomes over meritocracy. In this paper, we
study a trade-off between individual fairness and group fairness in ranking. We
define individual fairness based on how close the predicted rank of each item
is to its true rank, and prove a lower bound on the trade-off achievable for
simultaneous individual and group fairness in ranking. We give a fair ranking
algorithm that takes any given ranking and outputs another ranking with
simultaneous individual and group fairness guarantees comparable to the lower
bound we prove. Our algorithm can be used to both pre-process training data as
well as post-process the output of existing ranking algorithms. Our
experimental results show that our algorithm performs better than the
state-of-the-art fair learning to rank and fair post-processing baselines.
</p>
<a href="http://arxiv.org/abs/2010.06986" target="_blank">arXiv:2010.06986</a> [<a href="http://arxiv.org/pdf/2010.06986" target="_blank">pdf</a>]

<h2>Learning Representations of Hierarchical Slates in Collaborative Filtering. (arXiv:2010.06987v1 [cs.IR])</h2>
<h3>Ehtsham Elahi, Ashok Chandrashekar</h3>
<p>We are interested in building collaborative filtering models for
recommendation systems where users interact with slates instead of individual
items. These slates can be hierarchical in nature. The central idea of our
approach is to learn low dimensional embeddings of these slates. We present a
novel way to learn these embeddings by making use of the (unknown) statistics
of the underlying distribution generating the hierarchical data. Our
representation learning algorithm can be viewed as a simple composition rule
that can be applied recursively in a bottom-up fashion to represent arbitrarily
complex hierarchical structures in terms of the representations of its
constituent components. We demonstrate our ideas on two real world
recommendation systems datasets including the one used for the RecSys 2019
challenge. For that dataset, we improve upon the performance achieved by the
winning team's model by incorporating embeddings as features generated by our
approach in their solution.
</p>
<a href="http://arxiv.org/abs/2010.06987" target="_blank">arXiv:2010.06987</a> [<a href="http://arxiv.org/pdf/2010.06987" target="_blank">pdf</a>]

<h2>Using satellite imagery to understand and promote sustainable development. (arXiv:2010.06988v1 [cs.CY])</h2>
<h3>Marshall Burke, Anne Driscoll, David B. Lobell, Stefano Ermon</h3>
<p>Accurate and comprehensive measurements of a range of sustainable development
outcomes are fundamental inputs into both research and policy. We synthesize
the growing literature that uses satellite imagery to understand these
outcomes, with a focus on approaches that combine imagery with machine
learning. We quantify the paucity of ground data on key human-related outcomes
and the growing abundance and resolution (spatial, temporal, and spectral) of
satellite imagery. We then review recent machine learning approaches to
model-building in the context of scarce and noisy training data, highlighting
how this noise often leads to incorrect assessment of models' predictive
performance. We quantify recent model performance across multiple sustainable
development domains, discuss research and policy applications, explore
constraints to future progress, and highlight key research directions for the
field.
</p>
<a href="http://arxiv.org/abs/2010.06988" target="_blank">arXiv:2010.06988</a> [<a href="http://arxiv.org/pdf/2010.06988" target="_blank">pdf</a>]

<h2>Review the Enterprise Resource Planning in Moroccan Healthcare Organizations. (arXiv:2010.06989v1 [cs.CY])</h2>
<h3>Fatima Zahra Yamani, Mohamed El Merouani</h3>
<p>The Hospital Information Systems (HIS) in Morocco take a central place in the
process of patient care. An approach is made to analyze the current situation
of the HIS within the institutions in order to bring an integral and generic
vision, allowing the judicious articulation of the business and IT layers.
Currently, the Enterprise Resource Planning (ERP) implemented remains a system
consisting of several applications dedicated to specific areas. These systems
have become an indispensable element within any hospital. The goal of our study
is to discover how the ERP has been used in Moroccan healthcare sector and how
these software should be implemented and used to improve healthcare services.
</p>
<a href="http://arxiv.org/abs/2010.06989" target="_blank">arXiv:2010.06989</a> [<a href="http://arxiv.org/pdf/2010.06989" target="_blank">pdf</a>]

<h2>InstantEmbedding: Efficient Local Node Representations. (arXiv:2010.06992v1 [cs.LG])</h2>
<h3>&#x15e;tefan Post&#x103;varu, Anton Tsitsulin, Filipe Miguel Gon&#xe7;alves de Almeida, Yingtao Tian, Silvio Lattanzi, Bryan Perozzi</h3>
<p>In this paper, we introduce InstantEmbedding, an efficient method for
generating single-node representations using local PageRank computations. We
theoretically prove that our approach produces globally consistent
representations in sublinear time. We demonstrate this empirically by
conducting extensive experiments on real-world datasets with over a billion
edges. Our experiments confirm that InstantEmbedding requires drastically less
computation time (over 9,000 times faster) and less memory (by over 8,000
times) to produce a single node's embedding than traditional methods including
DeepWalk, node2vec, VERSE, and FastRP. We also show that our method produces
high quality representations, demonstrating results that meet or exceed the
state of the art for unsupervised representation learning on tasks like node
classification and link prediction.
</p>
<a href="http://arxiv.org/abs/2010.06992" target="_blank">arXiv:2010.06992</a> [<a href="http://arxiv.org/pdf/2010.06992" target="_blank">pdf</a>]

<h2>Weight Squeezing: Reparameterization for Compression and Fast Inference. (arXiv:2010.06993v1 [cs.LG])</h2>
<h3>Artem Chumachenko, Daniil Gavrilov, Pavel Kalaidin</h3>
<p>In this work, we present a novel approach for simultaneous knowledge transfer
and model compression called Weight Squeezing. With this method, we perform
knowledge transfer from a pre-trained teacher model by learning the mapping
from its weights to smaller student model weights, without significant loss of
model accuracy.

We applied Weight Squeezing combined with Knowledge Distillation to a
pre-trained text classification model, and compared it to various knowledge
transfer and model compression methods on several downstream text
classification tasks. We observed that our approach produces better results
than Knowledge Distillation methods without any loss in inference speed. We
also compared Weight Squeezing with Low Rank Factorization methods and observed
that our method is significantly faster at inference while being competitive in
terms of accuracy.
</p>
<a href="http://arxiv.org/abs/2010.06993" target="_blank">arXiv:2010.06993</a> [<a href="http://arxiv.org/pdf/2010.06993" target="_blank">pdf</a>]

<h2>Fast meningioma segmentation in T1-weighted MRI volumes using a lightweight 3D deep learning architecture. (arXiv:2010.07002v1 [eess.IV])</h2>
<h3>David Bouget, Andr&#xe9; Pedersen, Sayied Abdol Mohieb Hosainey, Johanna Vanel, Ole Solheim, Ingerid Reinertsen</h3>
<p>Automatic and consistent meningioma segmentation in T1-weighted MRI volumes
and corresponding volumetric assessment is of use for diagnosis, treatment
planning, and tumor growth evaluation. In this paper, we optimized the
segmentation and processing speed performances using a large number of both
surgically treated meningiomas and untreated meningiomas followed at the
outpatient clinic. We studied two different 3D neural network architectures:
(i) a simple encoder-decoder similar to a 3D U-Net, and (ii) a lightweight
multi-scale architecture (PLS-Net). In addition, we studied the impact of
different training schemes. For the validation studies, we used 698 T1-weighted
MR volumes from St. Olav University Hospital, Trondheim, Norway. The models
were evaluated in terms of detection accuracy, segmentation accuracy and
training/inference speed. While both architectures reached a similar Dice score
of 70% on average, the PLS-Net was more accurate with an F1-score of up to 88%.
The highest accuracy was achieved for the largest meningiomas. Speed-wise, the
PLS-Net architecture tended to converge in about 50 hours while 130 hours were
necessary for U-Net. Inference with PLS-Net takes less than a second on GPU and
about 15 seconds on CPU. Overall, with the use of mixed precision training, it
was possible to train competitive segmentation models in a relatively short
amount of time using the lightweight PLS-Net architecture. In the future, the
focus should be brought toward the segmentation of small meningiomas (less than
2ml) to improve clinical relevance for automatic and early diagnosis as well as
speed of growth estimates.
</p>
<a href="http://arxiv.org/abs/2010.07002" target="_blank">arXiv:2010.07002</a> [<a href="http://arxiv.org/pdf/2010.07002" target="_blank">pdf</a>]

<h2>Binarization Methods for Motor-Imagery Brain-Computer Interface Classification. (arXiv:2010.07004v1 [eess.SP])</h2>
<h3>Michael Hersche, Luca Benini, Abbas Rahimi</h3>
<p>Successful motor-imagery brain-computer interface (MI-BCI) algorithms either
extract a large number of handcrafted features and train a classifier, or
combine feature extraction and classification within deep convolutional neural
networks (CNNs). Both approaches typically result in a set of real-valued
weights, that pose challenges when targeting real-time execution on tightly
resource-constrained devices. We propose methods for each of these approaches
that allow transforming real-valued weights to binary numbers for efficient
inference. Our first method, based on sparse bipolar random projection,
projects a large number of real-valued Riemannian covariance features to a
binary space, where a linear SVM classifier can be learned with binary weights
too. By tuning the dimension of the binary embedding, we achieve almost the
same accuracy in 4-class MI ($\leq$1.27% lower) compared to models with float16
weights, yet delivering a more compact model with simpler operations to
execute. Second, we propose to use memory-augmented neural networks (MANNs) for
MI-BCI such that the augmented memory is binarized. Our method replaces the
fully connected layer of CNNs with a binary augmented memory using bipolar
random projection, or learned projection. Our experimental results on EEGNet,
an already compact CNN for MI-BCI, show that it can be compressed by 1.28x at
iso-accuracy using the random projection. On the other hand, using the learned
projection provides 3.89% higher accuracy but increases the memory size by
28.10x.
</p>
<a href="http://arxiv.org/abs/2010.07004" target="_blank">arXiv:2010.07004</a> [<a href="http://arxiv.org/pdf/2010.07004" target="_blank">pdf</a>]

<h2>iPaaS in Agriculture 4.0: An Industrial Case. (arXiv:2010.07015v1 [cs.CY])</h2>
<h3>Rafael Cestari, Sebastien Ducos (LIUPPA), Ernesto Exposito (LIUPPA)</h3>
<p>Current automation approaches in the Industry 4.0 have generated increased
interest in the utilization of Integration Platforms as a Service (iPaaS) cloud
architectures in order to unify and synchronize several systems, applications,
and services in order to build smart solutions for automated and adaptive
industrial process management. Existing iPaaS solutions present several
out-of-the-box connectors and automation engines for easier integration of
customers' projects, but show issues regarding overall adaptation outside their
scope, brand locking, and occasionally high prices. Moreover, existing
platforms fail to respond adequately to the needs of deploying multiple
decision models capable of offering automated or semi-automated management of
processes, thanks to the integration of the large diversity of data and event
sources as well as the different physical or logical action entities. With the
popularization of open-source software and applications such as BPM Engines,
Machine Learning libraries, and Integration suites and libraries, it is
possible to develop a fully customizable and adaptable, open-source iPaaS that
can be used both in and outside industrial applications. In this paper, we
propose a generic iPaaS architecture implemented on the basis of several open
source solutions boasting integration, interoperability, and automated
decision-making capabilities in the domain of Agriculture 4.0. A
proof-of-concept based on these solutions is presented, as well as a case study
on MA{\"I}SADOUR's grain storage process with a comparison with the currently
human-operated tasks.
</p>
<a href="http://arxiv.org/abs/2010.07015" target="_blank">arXiv:2010.07015</a> [<a href="http://arxiv.org/pdf/2010.07015" target="_blank">pdf</a>]

<h2>Towards a Policy-as-a-Service Framework to Enable Compliant, Trustworthy AI and HRI Systems in the Wild. (arXiv:2010.07022v1 [cs.CY])</h2>
<h3>Alexis Morris, Hallie Siegel, Jonathan Kelly</h3>
<p>Building trustworthy autonomous systems is challenging for many reasons
beyond simply trying to engineer agents that 'always do the right thing.' There
is a broader context that is often not considered within AI and HRI: that the
problem of trustworthiness is inherently socio-technical and ultimately
involves a broad set of complex human factors and multidimensional
relationships that can arise between agents, humans, organizations, and even
governments and legal institutions, each with their own understanding and
definitions of trust. This complexity presents a significant barrier to the
development of trustworthy AI and HRI systems---while systems developers may
desire to have their systems 'always do the right thing,' they generally lack
the practical tools and expertise in law, regulation, policy and ethics to
ensure this outcome. In this paper, we emphasize the "fuzzy" socio-technical
aspects of trustworthiness and the need for their careful consideration during
both design and deployment. We hope to contribute to the discussion of
trustworthy engineering in AI and HRI by i) describing the policy landscape
that must be considered when addressing trustworthy computing and the need for
usable trust models, ii) highlighting an opportunity for trustworthy-by-design
intervention within the systems engineering process, and iii) introducing the
concept of a "policy-as-a-service" (PaaS) framework that can be readily applied
by AI systems engineers to address the fuzzy problem of trust during the
development and (eventually) runtime process. We envision that the PaaS
approach, which offloads the development of policy design parameters and
maintenance of policy standards to policy experts, will enable runtime trust
capabilities intelligent systems in the wild.
</p>
<a href="http://arxiv.org/abs/2010.07022" target="_blank">arXiv:2010.07022</a> [<a href="http://arxiv.org/pdf/2010.07022" target="_blank">pdf</a>]

<h2>Heterogeneous Graph Collaborative Filtering using Textual Information. (arXiv:2010.07027v1 [cs.IR])</h2>
<h3>Chaoyang Wang, Zhiqiang Guo, Guohui Li, Jianjun Li, Peng Pan, Ke Liu</h3>
<p>Due to the development of graph neural network models, like graph
convolutional network (GCN), graph-based representation learning methods have
made great progress in recommender systems. However, the data sparsity is still
a challenging problem that graph-based methods are confronted with. Recent
works try to solve this problem by utilizing the side information. In this
paper, we introduce easily accessible textual information to alleviate the
negative effects of data sparsity. Specifically, to incorporate with rich
textual knowledge, we utilize a pre-trained context-awareness natural language
processing model to initialize the embeddings of text nodes. By a GCN-based
node information propagation on the constructed heterogeneous graph, the
embeddings of users and items can finally be enriched by the textual knowledge.
The matching function used by most graph-based representation learning methods
is the inner product, this linear operation can not fit complex semantics well.
We design a predictive network, which can combine the graph-based
representation learning with the matching function learning, and demonstrate
that this predictive architecture can gain significant improvements. Extensive
experiments are conducted on three public datasets and the results verify the
superior performance of our method over several baselines.
</p>
<a href="http://arxiv.org/abs/2010.07027" target="_blank">arXiv:2010.07027</a> [<a href="http://arxiv.org/pdf/2010.07027" target="_blank">pdf</a>]

<h2>Basic principles and concept design of a real-time clinical decision support system for autonomous medical care on missions to Mars based on adaptive deep learning. (arXiv:2010.07029v1 [cs.CY])</h2>
<h3>Juan M Garcia-Gomez</h3>
<p>Space agencies and private companies prepare the beginning of the human space
exploration for the 2030s with missions to put the first human on the Mars
surface. The absence of gravity and radiation, along with distance, isolation
and hostile environment are expected to increase medical events with
unidentified manifestations along the crewmembers. The current healthcare
strategy based on telemedicine and the possibility to stabilise and transport
the injured crewmember to a terrestrial definitive medical facility is not
applicable in exploration class missions. Therefore, full autonomous capability
to solve medical situations will guide design of future healthcare systems
on-board.

This study presents ten basic principles and the concept design of MEDEA, an
on-board clinical decision support system to help crewmembers to deal with
medical conditions, with special attention to emergency care situations and
critical monitoring. Therefore, MEDEA is conceptually designed as a software
suite of four interconnected modules. The main of them is responsible to give
direct advice to the crew by means of a deep learning multitask neural network
to predict the characters of the medical event, a classifier of the tertiary
medical intervention and an optimiser of medical action plans. This module is
continuously evaluate and re-trained with changing physiological data from the
crew by an adaptive deep learning module, ensuring fairness, interpretability
and traceability of decision making during the full operational time of MEDEA.
Finally, MEDEA would be semantically interoperable with health information
systems on-board by a FHIR module.

The deployment of MEDEA on-board of future missions to Mars will facilitate
the deployment of a comprehensive preventive medical strategy, future
quantitative medicine on Earth and on the expansion of humans throughout the
solar system.
</p>
<a href="http://arxiv.org/abs/2010.07029" target="_blank">arXiv:2010.07029</a> [<a href="http://arxiv.org/pdf/2010.07029" target="_blank">pdf</a>]

<h2>MARS-Gym: A Gym framework to model, train, and evaluate Recommender Systems for Marketplaces. (arXiv:2010.07035v1 [cs.IR])</h2>
<h3>Marlesson R. O. Santana, Luckeciano C. Melo, Fernando H. F. Camargo, Bruno Brand&#xe3;o, Anderson Soares, Renan M. Oliveira, Sandor Caetano</h3>
<p>Recommender Systems are especially challenging for marketplaces since they
must maximize user satisfaction while maintaining the healthiness and fairness
of such ecosystems. In this context, we observed a lack of resources to design,
train, and evaluate agents that learn by interacting within these environments.
For this matter, we propose MARS-Gym, an open-source framework to empower
researchers and engineers to quickly build and evaluate Reinforcement Learning
agents for recommendations in marketplaces. MARS-Gym addresses the whole
development pipeline: data processing, model design and optimization, and
multi-sided evaluation. We also provide the implementation of a diverse set of
baseline agents, with a metrics-driven analysis of them in the Trivago
marketplace dataset, to illustrate how to conduct a holistic assessment using
the available metrics of recommendation, off-policy estimation, and fairness.
With MARS-Gym, we expect to bridge the gap between academic research and
production systems, as well as to facilitate the design of new algorithms and
applications.
</p>
<a href="http://arxiv.org/abs/2010.07035" target="_blank">arXiv:2010.07035</a> [<a href="http://arxiv.org/pdf/2010.07035" target="_blank">pdf</a>]

<h2>Machine Learning Research Towards Combating COVID-19: Virus Detection, Spread Prevention, and Medical Assistance. (arXiv:2010.07036v1 [cs.CY])</h2>
<h3>Osama Shahid, Mohammad Nasajpour, Seyedamin Pouriyeh, Reza M. Parizi, Meng Han, Maria Valero, Fangyu Li, Mohammed Aledhari, Quan Z. Sheng</h3>
<p>COVID-19 was first discovered in December 2019 and has continued to rapidly
spread across countries worldwide infecting thousands and millions of people.
The virus is deadly, and people who are suffering from prior illnesses or are
older than the age of 60 are at a higher risk of mortality. Medicine and
Healthcare industries have surged towards finding a cure, and different
policies have been amended to mitigate the spread of the virus. While Machine
Learning (ML) methods have been widely used in other domains, there is now a
high demand for ML-aided diagnosis systems for screening, tracking, and
predicting the spread of COVID-19 and finding a cure against it. In this paper,
we present a journey of what role ML has played so far in combating the virus,
mainly looking at it from a screening, forecasting, and vaccine perspectives.
We present a comprehensive survey of the ML algorithms and models that can be
used on this expedition and aid with battling the virus.
</p>
<a href="http://arxiv.org/abs/2010.07036" target="_blank">arXiv:2010.07036</a> [<a href="http://arxiv.org/pdf/2010.07036" target="_blank">pdf</a>]

<h2>Practical guide to regulating a medical AI product. (arXiv:2010.07038v1 [cs.CY])</h2>
<h3>David Higgins</h3>
<p>Medical AI products require certification before deployment in most
jurisdictions. To date, no clear pathways for regulating medical AI exist. I
present guidelines for development of such a regulatory package. This approach
is predicated on the translation between a statistical risk perspective,
typical of medical device regulators, and a deep understanding of machine
learning methodologies. This work of translation will enable medical device
regulators and machine learning experts to communicate more clearly, and thus
lead to the development of standardised pathways for medical AI regulation.
</p>
<a href="http://arxiv.org/abs/2010.07038" target="_blank">arXiv:2010.07038</a> [<a href="http://arxiv.org/pdf/2010.07038" target="_blank">pdf</a>]

<h2>3D Segmentation Networks for Excessive Numbers of Classes: Distinct Bone Segmentation in Upper Bodies. (arXiv:2010.07045v1 [eess.IV])</h2>
<h3>Eva Schnider, Antal Horv&#xe1;th, Georg Rauter, Azhar Zam, Magdalena M&#xfc;ller-Gerbl, Philippe C. Cattin</h3>
<p>Segmentation of distinct bones plays a crucial role in diagnosis, planning,
navigation, and the assessment of bone metastasis. It supplies semantic
knowledge to visualisation tools for the planning of surgical interventions and
the education of health professionals. Fully supervised segmentation of 3D data
using Deep Learning methods has been extensively studied for many tasks but is
usually restricted to distinguishing only a handful of classes. With 125
distinct bones, our case includes many more labels than typical 3D segmentation
tasks. For this reason, the direct adaptation of most established methods is
not possible. This paper discusses the intricacies of training a 3D
segmentation network in a many-label setting and shows necessary modifications
in network architecture, loss function, and data augmentation. As a result, we
demonstrate the robustness of our method by automatically segmenting over one
hundred distinct bones simultaneously in an end-to-end learnt fashion from a
CT-scan.
</p>
<a href="http://arxiv.org/abs/2010.07045" target="_blank">arXiv:2010.07045</a> [<a href="http://arxiv.org/pdf/2010.07045" target="_blank">pdf</a>]

<h2>Representativity Fairness in Clustering. (arXiv:2010.07054v1 [cs.CY])</h2>
<h3>Deepak P, Savitha Sam Abraham</h3>
<p>Incorporating fairness constructs into machine learning algorithms is a topic
of much societal importance and recent interest. Clustering, a fundamental task
in unsupervised learning that manifests across a number of web data scenarios,
has also been subject of attention within fair ML research. In this paper, we
develop a novel notion of fairness in clustering, called representativity
fairness. Representativity fairness is motivated by the need to alleviate
disparity across objects' proximity to their assigned cluster representatives,
to aid fairer decision making. We illustrate the importance of representativity
fairness in real-world decision making scenarios involving clustering and
provide ways of quantifying objects' representativity and fairness over it. We
develop a new clustering formulation, RFKM, that targets to optimize for
representativity fairness along with clustering quality. Inspired by the
$K$-Means framework, RFKM incorporates novel loss terms to formulate an
objective function. The RFKM objective and optimization approach guides it
towards clustering configurations that yield higher representativity fairness.
Through an empirical evaluation over a variety of public datasets, we establish
the effectiveness of our method. We illustrate that we are able to
significantly improve representativity fairness at only marginal impact to
clustering quality.
</p>
<a href="http://arxiv.org/abs/2010.07054" target="_blank">arXiv:2010.07054</a> [<a href="http://arxiv.org/pdf/2010.07054" target="_blank">pdf</a>]

<h2>Learned Greedy Method (LGM): A Novel Neural Architecture for Sparse Coding and Beyond. (arXiv:2010.07069v1 [cs.LG])</h2>
<h3>Rajaei Khatib, Dror Simon, Michael Elad</h3>
<p>The fields of signal and image processing have been deeply influenced by the
introduction of deep neural networks. These are successfully deployed in a wide
range of real-world applications, obtaining state of the art results and
surpassing well-known and well-established classical methods. Despite their
impressive success, the architectures used in many of these neural networks
come with no clear justification. As such, these are usually treated as "black
box" machines that lack any kind of interpretability. A constructive remedy to
this drawback is a systematic design of such networks by unfolding
well-understood iterative algorithms. A popular representative of this approach
is the Iterative Shrinkage-Thresholding Algorithm (ISTA) and its learned
version -- LISTA, aiming for the sparse representations of the processed
signals. In this paper we revisit this sparse coding task and propose an
unfolded version of a greedy pursuit algorithm for the same goal. More
specifically, we concentrate on the well-known Orthogonal-Matching-Pursuit
(OMP) algorithm, and introduce its unfolded and learned version. Key features
of our Learned Greedy Method (LGM) are the ability to accommodate a dynamic
number of unfolded layers, and a stopping mechanism based on representation
error, both adapted to the input. We develop several variants of the proposed
LGM architecture and test some of them in various experiments, demonstrating
their flexibility and efficiency.
</p>
<a href="http://arxiv.org/abs/2010.07069" target="_blank">arXiv:2010.07069</a> [<a href="http://arxiv.org/pdf/2010.07069" target="_blank">pdf</a>]

<h2>Summarize, Outline, and Elaborate: Long-Text Generation via Hierarchical Supervision from Extractive Summaries. (arXiv:2010.07074v1 [cs.CL])</h2>
<h3>Xiaofei Sun, Chun Fan, Zijun Sun, Yuxian Meng, Fei Wu, Jiwei Li</h3>
<p>Long-text generation remains a challenge. The difficulty of generating
coherent long texts lies in the fact that existing models overwhelmingly focus
on the tasks of local word prediction, and cannot make high level plans on what
to generate or capture the high-level discourse dependencies between chunks of
texts. Inspired by how humans write, where a list of bullet points or a catalog
is first outlined, and then each bullet point is expanded to form the whole
article, we propose {\it SOE}, a pipelined system that involves of summarizing,
outlining and elaborating for long text generation: the model first outlines
the summaries for different segments of long texts, and then elaborates on each
bullet point to generate the corresponding segment. To avoid the
labor-intensive process of summary soliciting, we propose the {\it
reconstruction} strategy, which extracts segment summaries in an unsupervised
manner by selecting its most informative part to reconstruct the segment.The
proposed generation system comes with the following merits: (1) the summary
provides high-level guidances for text generation and avoids the local minimum
of individual word predictions; (2) the high-level discourse dependencies are
captured in the conditional dependencies between summaries and are preserved
during the summary expansion process and (3) additionally, we are able to
consider significantly more contexts by representing contexts as concise
summaries. Extensive experiments demonstrate that SOE produces long texts with
significantly better quality, along with faster convergence speed.
</p>
<a href="http://arxiv.org/abs/2010.07074" target="_blank">arXiv:2010.07074</a> [<a href="http://arxiv.org/pdf/2010.07074" target="_blank">pdf</a>]

<h2>Concise Outlines for a Complex Logic: A Proof Outline Checker for TaDA (Full Paper). (arXiv:2010.07080v1 [cs.PL])</h2>
<h3>Felix A. Wolf, Malte Schwerhoff, Peter M&#xfc;ller</h3>
<p>Modern separation logics allow one to prove rich properties of intricate
code, e.g. functional correctness and linearizability of non-blocking
concurrent code. However, this expressiveness leads to a complexity that makes
these logics difficult to apply. Manual proofs or proofs in interactive theorem
provers consist of a large number of steps, often with subtle side conditions.
On the other hand, automation with dedicated verifiers typically requires
sophisticated proof search algorithms that are specific to the given program
logic, resulting in limited tool support that makes it difficult to experiment
with program logics, e.g. when learning, improving, or comparing them. Proof
outline checkers fill this gap. Their input is a program annotated with the
most essential proof steps, just like the proof outlines typically presented in
papers. The tool then checks automatically that this outline represents a valid
proof in the program logic. In this paper, we systematically develop a proof
outline checker for the TaDA logic, which reduces the checking to a simpler
verification problem, for which automated tools exist. Our approach leads to
proof outline checkers that provide substantially more automation than
interactive provers, but are much simpler to develop than custom automatic
verifiers.
</p>
<a href="http://arxiv.org/abs/2010.07080" target="_blank">arXiv:2010.07080</a> [<a href="http://arxiv.org/pdf/2010.07080" target="_blank">pdf</a>]

<h2>A Systematic Review on Online Exams Solutions in E-learning -- Techniques, Tools, and Global Adoption. (arXiv:2010.07086v1 [cs.CY])</h2>
<h3>Abdul Wahab Muzaffar, Muhammad Tahir, Muhammad Waseem Anwar, Qaiser Chaudry, Shamaila Rasheed Mir</h3>
<p>E-learning in higher education is exponentially increased during the past
decade due to its inevitable benefits in critical situations like natural
disasters, and pandemic. The reliable, fair, and seamless execution of online
exams in E-learning is highly significant. Particularly, online exams are
conducted on E-learning platforms without the physical presence of students and
instructors at the same place. This poses several issues like integrity and
security during online exams. To address such issues, researchers frequently
proposed different techniques and tools. However, a study summarizing and
analyzing latest developments, particularly in the area of online examination,
is hard to find in the literature. In this article, an SLR for online
examination is performed to select and analyze 53 studies published during the
last five years. Subsequently, five leading online exams features targeted in
the selected studies are identified and underlying development approaches for
the implementation of online exams solutions are explored. Furthermore, 16
important techniques and 11 datasets are presented. In addition, 21 online
exams tools proposed in the selected studies are identified. Additionally, 25
leading existing tools used in the selected studies are also presented.
Finally, the participation of countries in online exam research is
investigated. Key factors for the global adoption of online exams are
identified and investigated. This facilitates the selection of right online
exam system for a particular country on the basis of existing E-learning
infrastructure and overall cost. To conclude, the findings of this article
provide a solid platform for the researchers and practitioners of the domain to
select appropriate features along with underlying development approaches, tools
and techniques for the implementation of a particular online exams solution as
per given requirements.
</p>
<a href="http://arxiv.org/abs/2010.07086" target="_blank">arXiv:2010.07086</a> [<a href="http://arxiv.org/pdf/2010.07086" target="_blank">pdf</a>]

<h2>Data Augmentation for Meta-Learning. (arXiv:2010.07092v1 [cs.LG])</h2>
<h3>Renkun Ni, Micah Goldblum, Amr Sharaf, Kezhi Kong, Tom Goldstein</h3>
<p>Conventional image classifiers are trained by randomly sampling mini-batches
of images. To achieve state-of-the-art performance, sophisticated data
augmentation schemes are used to expand the amount of training data available
for sampling. In contrast, meta-learning algorithms sample not only images, but
classes as well. We investigate how data augmentation can be used not only to
expand the number of images available per class, but also to generate entirely
new classes. We systematically dissect the meta-learning pipeline and
investigate the distinct ways in which data augmentation can be integrated at
both the image and class levels. Our proposed meta-specific data augmentation
significantly improves the performance of meta-learners on few-shot
classification benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.07092" target="_blank">arXiv:2010.07092</a> [<a href="http://arxiv.org/pdf/2010.07092" target="_blank">pdf</a>]

<h2>Function Contrastive Learning of Transferable Representations. (arXiv:2010.07093v1 [cs.LG])</h2>
<h3>Muhammad Waleed Gondal, Shruti Joshi, Nasim Rahaman, Stefan Bauer, Manuel W&#xfc;thrich, Bernhard Sch&#xf6;lkopf</h3>
<p>Few-shot-learning seeks to find models that are capable of fast-adaptation to
novel tasks. Unlike typical few-shot learning algorithms, we propose a
contrastive learning method which is not trained to solve a set of tasks, but
rather attempts to find a good representation of the underlying data-generating
processes (\emph{functions}). This allows for finding representations which are
useful for an entire series of tasks sharing the same function. In particular,
our training scheme is driven by the self-supervision signal indicating whether
two sets of samples stem from the same underlying function. Our experiments on
a number of synthetic and real-world datasets show that the representations we
obtain can outperform strong baselines in terms of downstream performance and
noise robustness, even when these baselines are trained in an end-to-end
manner.
</p>
<a href="http://arxiv.org/abs/2010.07093" target="_blank">arXiv:2010.07093</a> [<a href="http://arxiv.org/pdf/2010.07093" target="_blank">pdf</a>]

<h2>Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction. (arXiv:2010.07101v1 [cs.CL])</h2>
<h3>Xu Zhao, Zihao Wang, Hao Wu, Yong Zhang</h3>
<p>Semi-supervision is a promising paradigm for Bilingual Lexicon Induction
(BLI) with limited annotations. However, previous semisupervised methods do not
fully utilize the knowledge hidden in annotated and nonannotated data, which
hinders further improvement of their performance. In this paper, we propose a
new semi-supervised BLI framework to encourage the interaction between the
supervised signal and unsupervised alignment. We design two message-passing
mechanisms to transfer knowledge between annotated and non-annotated data,
named prior optimal transport and bi-directional lexicon update respectively.
Then, we perform semi-supervised learning based on a cyclic or a parallel
parameter feeding routine to update our models. Our framework is a general
framework that can incorporate any supervised and unsupervised BLI methods
based on optimal transport. Experimental results on MUSE and VecMap datasets
show significant improvement of our models. Ablation study also proves that the
two-way interaction between the supervised signal and unsupervised alignment
accounts for the gain of the overall performance. Results on distant language
pairs further illustrate the advantage and robustness of our proposed method.
</p>
<a href="http://arxiv.org/abs/2010.07101" target="_blank">arXiv:2010.07101</a> [<a href="http://arxiv.org/pdf/2010.07101" target="_blank">pdf</a>]

<h2>Online Anomaly Detection in Surveillance Videos with Asymptotic Bounds on False Alarm Rate. (arXiv:2010.07110v1 [cs.CV])</h2>
<h3>Keval Doshi, Yasin Yilmaz</h3>
<p>Anomaly detection in surveillance videos is attracting an increasing amount
of attention. Despite the competitive performance of recent methods, they lack
theoretical performance analysis, particularly due to the complex deep neural
network architectures used in decision making. Additionally, online decision
making is an important but mostly neglected factor in this domain. Much of the
existing methods that claim to be online, depend on batch or offline processing
in practice. Motivated by these research gaps, we propose an online anomaly
detection method in surveillance videos with asymptotic bounds on the false
alarm rate, which in turn provides a clear procedure for selecting a proper
decision threshold that satisfies the desired false alarm rate. Our proposed
algorithm consists of a multi-objective deep learning module along with a
statistical anomaly detection module, and its effectiveness is demonstrated on
several publicly available data sets where we outperform the state-of-the-art
algorithms. All codes are available at
https://github.com/kevaldoshi17/Prediction-based-Video-Anomaly-Detection-.
</p>
<a href="http://arxiv.org/abs/2010.07110" target="_blank">arXiv:2010.07110</a> [<a href="http://arxiv.org/pdf/2010.07110" target="_blank">pdf</a>]

<h2>Learning Deep Features in Instrumental Variable Regression. (arXiv:2010.07154v1 [cs.LG])</h2>
<h3>Liyuan Xu, Yutian Chen, Siddarth Srinivasan, Nando de Freitas, Arnaud Doucet, Arthur Gretton</h3>
<p>Instrumental variable (IV) regression is a standard strategy for learning
causal relationships between confounded treatment and outcome variables by
utilizing an instrumental variable, which is conditionally independent of the
outcome given the treatment. In classical IV regression, learning proceeds in
two stages: stage 1 performs linear regression from the instrument to the
treatment; and stage 2 performs linear regression from the treatment to the
outcome, conditioned on the instrument. We propose a novel method, {\it deep
feature instrumental variable regression (DFIV)}, to address the case where
relations between instruments, treatments, and outcomes may be nonlinear. In
this case, deep neural nets are trained to define informative nonlinear
features on the instruments and treatments. We propose an alternating training
regime for these features to ensure good end-to-end performance when composing
stages 1 and 2, thus obtaining highly flexible feature maps in a
computationally efficient manner. DFIV outperforms recent state-of-the-art
methods on challenging IV benchmarks, including settings involving high
dimensional image data. DFIV also exhibits competitive performance in
off-policy policy evaluation for reinforcement learning, which can be
understood as an IV regression task.
</p>
<a href="http://arxiv.org/abs/2010.07154" target="_blank">arXiv:2010.07154</a> [<a href="http://arxiv.org/pdf/2010.07154" target="_blank">pdf</a>]

<h2>WeightAlign: Normalizing Activations by Weight Alignment. (arXiv:2010.07160v1 [cs.CV])</h2>
<h3>Xiangwei Shi, Yunqiang Li, Xin Liu, Jan van Gemert</h3>
<p>Batch normalization (BN) allows training very deep networks by normalizing
activations by mini-batch sample statistics which renders BN unstable for small
batch sizes. Current small-batch solutions such as Instance Norm, Layer Norm,
and Group Norm use channel statistics which can be computed even for a single
sample. Such methods are less stable than BN as they critically depend on the
statistics of a single input sample. To address this problem, we propose a
normalization of activation without sample statistics. We present WeightAlign:
a method that normalizes the weights by the mean and scaled standard derivation
computed within a filter, which normalizes activations without computing any
sample statistics. Our proposed method is independent of batch size and stable
over a wide range of batch sizes. Because weight statistics are orthogonal to
sample statistics, we can directly combine WeightAlign with any method for
activation normalization. We experimentally demonstrate these benefits for
classification on CIFAR-10, CIFAR-100, ImageNet, for semantic segmentation on
PASCAL VOC 2012 and for domain adaptation on Office-31.
</p>
<a href="http://arxiv.org/abs/2010.07160" target="_blank">arXiv:2010.07160</a> [<a href="http://arxiv.org/pdf/2010.07160" target="_blank">pdf</a>]

<h2>Learning Robust Models Using The Principle of Independent Causal Mechanisms. (arXiv:2010.07167v1 [cs.LG])</h2>
<h3>Jens M&#xfc;ller, Robert Schmier, Lynton Ardizzone, Carsten Rother, Ullrich K&#xf6;the</h3>
<p>Standard supervised learning breaks down under data distribution shift.
However, the principle of independent causal mechanisms (ICM, Peters et al.
(2017)) can turn this weakness into an opportunity: one can take advantage of
distribution shift between different environments during training in order to
obtain more robust models. We propose a new gradient-based learning framework
whose objective function is derived from the ICM principle. We show
theoretically and experimentally that neural networks trained in this framework
focus on relations remaining invariant across environments and ignore unstable
ones. Moreover, we prove that the recovered stable relations correspond to the
true causal mechanisms under certain conditions. In both regression and
classification, the resulting models generalize well to unseen scenarios where
traditionally trained models fail.
</p>
<a href="http://arxiv.org/abs/2010.07167" target="_blank">arXiv:2010.07167</a> [<a href="http://arxiv.org/pdf/2010.07167" target="_blank">pdf</a>]

<h2>Effective Algorithm-Accelerator Co-design for AI Solutions on Edge Devices. (arXiv:2010.07185v1 [cs.AR])</h2>
<h3>Cong Hao, Yao Chen, Xiaofan Zhang, Yuhong Li, Jinjun Xiong, Wen-mei Hwu, Deming Chen</h3>
<p>High quality AI solutions require joint optimization of AI algorithms, such
as deep neural networks (DNNs), and their hardware accelerators. To improve the
overall solution quality as well as to boost the design productivity, efficient
algorithm and accelerator co-design methodologies are indispensable. In this
paper, we first discuss the motivations and challenges for the
Algorithm/Accelerator co-design problem and then provide several effective
solutions. Especially, we highlight three leading works of effective co-design
methodologies: 1) the first simultaneous DNN/FPGA co-design method; 2) a
bi-directional lightweight DNN and accelerator co-design method; 3) a
differentiable and efficient DNN and accelerator co-search method. We
demonstrate the effectiveness of the proposed co-design approaches using
extensive experiments on both FPGAs and GPUs, with comparisons to existing
works. This paper emphasizes the importance and efficacy of
algorithm-accelerator co-design and calls for more research breakthroughs in
this interesting and demanding area.
</p>
<a href="http://arxiv.org/abs/2010.07185" target="_blank">arXiv:2010.07185</a> [<a href="http://arxiv.org/pdf/2010.07185" target="_blank">pdf</a>]

<h2>Towards Resistant Audio Adversarial Examples. (arXiv:2010.07190v1 [cs.SD])</h2>
<h3>Tom D&#xf6;rr, Karla Markert, Nicolas M. M&#xfc;ller, Konstantin B&#xf6;ttinger</h3>
<p>Adversarial examples tremendously threaten the availability and integrity of
machine learning-based systems. While the feasibility of such attacks has been
observed first in the domain of image processing, recent research shows that
speech recognition is also susceptible to adversarial attacks. However,
reliably bridging the air gap (i.e., making the adversarial examples work when
recorded via a microphone) has so far eluded researchers. We find that due to
flaws in the generation process, state-of-the-art adversarial example
generation methods cause overfitting because of the binning operation in the
target speech recognition system (e.g., Mozilla Deepspeech). We devise an
approach to mitigate this flaw and find that our method improves generation of
adversarial examples with varying offsets. We confirm the significant
improvement with our approach by empirical comparison of the edit distance in a
realistic over-the-air setting. Our approach states a significant step towards
over-the-air attacks. We publish the code and an applicable implementation of
our approach.
</p>
<a href="http://arxiv.org/abs/2010.07190" target="_blank">arXiv:2010.07190</a> [<a href="http://arxiv.org/pdf/2010.07190" target="_blank">pdf</a>]

<h2>Emergent Jaw Predominance in Vocal Development through Stochastic Optimization. (arXiv:2010.07208v1 [cs.SD])</h2>
<h3>Cl&#xe9;ment Moulin-Frier, Jules Brochard, Freek Stulp, Pierre-Yves Oudeyer</h3>
<p>Infant vocal babbling strongly relies on jaw oscillations, especially at the
stage of canonical babbling, which underlies the syllabic structure of world
languages. In this paper, we propose, model and analyze an hypothesis to
explain this predominance of the jaw in early babbling. This hypothesis states
that general stochastic optimization principles, when applied to learning
sensorimotor control, automatically generate ordered babbling stages with a
predominant exploration of jaw movements in early stages. The reason is that
those movements impact the auditory effects more than other articulators. In
previous computational models, such general principles were shown to
selectively freeze and free degrees of freedom in a model reproducing the
proximo-distal development observed in infant arm reaching. The contribution of
this paper is to show how, using the same methods, we are able to explain such
patterns in vocal development. We present three experiments. The two first ones
show that the recruitment order of articulators emerging from stochastic
optimization depends on the target sound to be achieved but that on average the
jaw is largely chosen as the first recruited articulator. The third experiment
analyses in more detail how the emerging recruitment order is shaped by the
dynamics of the optimization process.
</p>
<a href="http://arxiv.org/abs/2010.07208" target="_blank">arXiv:2010.07208</a> [<a href="http://arxiv.org/pdf/2010.07208" target="_blank">pdf</a>]

<h2>Learning Propagation Rules for Attribution Map Generation. (arXiv:2010.07210v1 [cs.CV])</h2>
<h3>Yiding Yang, Jiayan Qiu, Mingli Song, Dacheng Tao, Xinchao Wang</h3>
<p>Prior gradient-based attribution-map methods rely on handcrafted propagation
rules for the non-linear/activation layers during the backward pass, so as to
produce gradients of the input and then the attribution map. Despite the
promising results achieved, such methods are sensitive to the non-informative
high-frequency components and lack adaptability for various models and samples.
In this paper, we propose a dedicated method to generate attribution maps that
allow us to learn the propagation rules automatically, overcoming the flaws of
the handcrafted ones. Specifically, we introduce a learnable plugin module,
which enables adaptive propagation rules for each pixel, to the non-linear
layers during the backward pass for mask generating. The masked input image is
then fed into the model again to obtain new output that can be used as a
guidance when combined with the original one. The introduced learnable module
can be trained under any auto-grad framework with higher-order differential
support. As demonstrated on five datasets and six network architectures, the
proposed method yields state-of-the-art results and gives cleaner and more
visually plausible attribution maps.
</p>
<a href="http://arxiv.org/abs/2010.07210" target="_blank">arXiv:2010.07210</a> [<a href="http://arxiv.org/pdf/2010.07210" target="_blank">pdf</a>]

<h2>Geometry matters: Exploring language examples at the decision boundary. (arXiv:2010.07212v1 [cs.CL])</h2>
<h3>Debajyoti Datta, Shashwat Kumar, Laura Barnes, Tom Fletcher</h3>
<p>A growing body of recent evidence has highlighted the limitations of natural
language processing (NLP) datasets and classifiers. These include the presence
of annotation artifacts in datasets, classifiers relying on shallow features
like a single word (e.g., if a movie review has the word "romantic", the review
tends to be positive), or unnecessary words (e.g., learning a proper noun to
classify a movie as positive or negative). The presence of such artifacts has
subsequently led to the development of challenging datasets to force the model
to generalize better. While a variety of heuristic strategies, such as
counterfactual examples and contrast sets, have been proposed, the theoretical
justification about what makes these examples difficult is often lacking or
unclear. In this paper, using tools from information geometry, we propose a
theoretical way to quantify the difficulty of an example in NLP. Using our
approach, we explore difficult examples for two popular NLP architectures. We
discover that both BERT and CNN are susceptible to single word substitutions in
high difficulty examples. Consequently, examples with low difficulty scores
tend to be robust to multiple word substitutions. Our analysis shows that
perturbations like contrast sets and counterfactual examples are not
necessarily difficult for the model, and they may not be accomplishing the
intended goal. Our approach is simple, architecture agnostic, and easily
extendable to other datasets. All the code used will be made publicly
available, including a tool to explore the difficult examples for other
datasets.
</p>
<a href="http://arxiv.org/abs/2010.07212" target="_blank">arXiv:2010.07212</a> [<a href="http://arxiv.org/pdf/2010.07212" target="_blank">pdf</a>]

<h2>Data Readiness Report. (arXiv:2010.07213v1 [cs.DB])</h2>
<h3>Shazia Afzal, Rajmohan C, Manish Kesarwani, Sameep Mehta, Hima Patel</h3>
<p>Data exploration and quality analysis is an important yet tedious process in
the AI pipeline. Current practices of data cleaning and data readiness
assessment for machine learning tasks are mostly conducted in an arbitrary
manner which limits their reuse and results in loss of productivity. We
introduce the concept of a Data Readiness Report as an accompanying
documentation to a dataset that allows data consumers to get detailed insights
into the quality of input data. Data characteristics and challenges on various
quality dimensions are identified and documented keeping in mind the principles
of transparency and explainability. The Data Readiness Report also serves as a
record of all data assessment operations including applied transformations.
This provides a detailed lineage for the purpose of data governance and
management. In effect, the report captures and documents the actions taken by
various personas in a data readiness and assessment workflow. Overtime this
becomes a repository of best practices and can potentially drive a
recommendation system for building automated data readiness workflows on the
lines of AutoML [8]. We anticipate that together with the Datasheets [9],
Dataset Nutrition Label [11], FactSheets [1] and Model Cards [15], the Data
Readiness Report completes the AI documentation pipeline.
</p>
<a href="http://arxiv.org/abs/2010.07213" target="_blank">arXiv:2010.07213</a> [<a href="http://arxiv.org/pdf/2010.07213" target="_blank">pdf</a>]

<h2>Manifold-Net: Using Manifold Learning for Point Cloud Classification. (arXiv:2010.07215v1 [cs.CV])</h2>
<h3>Dinghao Yang, Wei Gao</h3>
<p>In this paper, we propose a point cloud classification method based on graph
neural network and manifold learning. Different from the conventional point
cloud analysis methods, this paper uses manifold learning algorithms to embed
point cloud features for better considering the geometric continuity on the
surface. Then, the nature of point cloud can be acquired in low dimensional
space, and after being concatenated with features in the original
three-dimensional (3D)space, both the capability of feature representation and
the classification network performance can be improved. We pro-pose two
manifold learning modules, where one is based on locally linear embedding
algorithm, and the other is a non-linear projection method based on neural
network architecture. Both of them can obtain better performances than the
state-of-the-art baseline. Afterwards, the graph model is constructed by using
the k nearest neighbors algorithm, where the edge features are effectively
aggregated for the implementation of point cloud classification. Experiments
show that the proposed point cloud classification methods obtain the mean class
accuracy (mA) of 90.2% and the overall accuracy (oA)of 93.2%, which reach
competitive performances compared with the existing state-of-the-art related
methods.
</p>
<a href="http://arxiv.org/abs/2010.07215" target="_blank">arXiv:2010.07215</a> [<a href="http://arxiv.org/pdf/2010.07215" target="_blank">pdf</a>]

<h2>Back to the Future: Cycle Encoding Prediction for Self-supervised Contrastive Video Representation Learning. (arXiv:2010.07217v1 [cs.CV])</h2>
<h3>Xinyu Yang, Majid Mirmehdi, Tilo Burghardt</h3>
<p>In this paper we show that learning video feature spaces in which temporal
cycles are maximally predictable benefits action classification. In particular,
we propose a novel learning approach termed Cycle Encoding Prediction~(CEP)
that is able to effectively represent high-level spatio-temporal structure of
unlabelled video content. CEP builds a latent space wherein the concept of
closed forward-backward as well as backward-forward temporal loops is
approximately preserved. As a self-supervision signal, CEP leverages the
bi-directional temporal coherence of the video stream and applies loss
functions that encourage both temporal cycle closure as well as contrastive
feature separation. Architecturally, the underpinning network structure
utilises a single feature encoder for all video snippets, adding two predictive
modules that learn temporal forward and backward transitions. We apply our
framework for pretext training of networks for action recognition tasks. We
report significantly improved results for the standard datasets UCF101 and
HMDB51. Detailed ablation studies support the effectiveness of the proposed
components. We publish source code for the CEP components in full with this
paper.
</p>
<a href="http://arxiv.org/abs/2010.07217" target="_blank">arXiv:2010.07217</a> [<a href="http://arxiv.org/pdf/2010.07217" target="_blank">pdf</a>]

<h2>Vision-Aided Radio: User Identity Match in Radio and Video Domains Using Machine Learning. (arXiv:2010.07219v1 [cs.CV])</h2>
<h3>Vinicius M. de Pinho, Marcello L. R. de Campos, Luis Uzeda Garcia, Dalia Popescu</h3>
<p>5G is designed to be an essential enabler and a leading infrastructure
provider in the communication technology industry by supporting the demand for
the growing data traffic and a variety of services with distinct requirements.
The use of deep learning and computer vision tools has the means to increase
the environmental awareness of the network with information from visual data.
Information extracted via computer vision tools such as user position, movement
direction, and speed can be promptly available for the network. However, the
network must have a mechanism to match the identity of a user in both visual
and radio systems. This mechanism is absent in the present literature.
Therefore, we propose a framework to match the information from both visual and
radio domains. This is an essential step to practical applications of computer
vision tools in communications. We detail the proposed framework training and
deployment phases for a presented setup. We carried out practical experiments
using data collected in different types of environments. The work compares the
use of Deep Neural Network and Random Forest classifiers and shows that the
former performed better across all experiments, achieving classification
accuracy greater than 99%.
</p>
<a href="http://arxiv.org/abs/2010.07219" target="_blank">arXiv:2010.07219</a> [<a href="http://arxiv.org/pdf/2010.07219" target="_blank">pdf</a>]

<h2>Affect-Driven Modelling of Robot Personality for Collaborative Human-Robot Interactions. (arXiv:2010.07221v1 [cs.RO])</h2>
<h3>Nikhil Churamani, Pablo Barros, Hatice Gunes, Stefan Wermter</h3>
<p>Collaborative interactions require social robots to adapt to the dynamics of
human affective behaviour. Yet, current approaches for affective behaviour
generation in robots focus on instantaneous perception to generate a one-to-one
mapping between observed human expressions and static robot actions. In this
paper, we propose a novel framework for personality-driven behaviour generation
in social robots. The framework consists of (i) a hybrid neural model for
evaluating facial expressions and speech, forming intrinsic affective
representations in the robot, (ii) an Affective Core, that employs
self-organising neural models to embed robot personality traits like patience
and emotional actuation, and (iii) a Reinforcement Learning model that uses the
robot's affective appraisal to learn interaction behaviour. For evaluation, we
conduct a user study (n = 31) where the NICO robot acts as a proposer in the
Ultimatum Game. The effect of robot personality on its negotiation strategy is
witnessed by participants, who rank a patient robot with high emotional
actuation higher on persistence, while an inert and impatient robot higher on
its generosity and altruistic behaviour.
</p>
<a href="http://arxiv.org/abs/2010.07221" target="_blank">arXiv:2010.07221</a> [<a href="http://arxiv.org/pdf/2010.07221" target="_blank">pdf</a>]

<h2>Domain Shift in Computer Vision models for MRI data analysis: An Overview. (arXiv:2010.07222v1 [eess.IV])</h2>
<h3>Ekaterina Kondrateva, Marina Pominova, Elena Popova, Maxim Sharaev, Alexander Bernstein, Evgeny Burnaev</h3>
<p>Machine learning and computer vision methods are showing good performance in
medical imagery analysis. Yetonly a few applications are now in clinical use
and one of the reasons for that is poor transferability of themodels to data
from different sources or acquisition domains. Development of new methods and
algorithms forthe transfer of training and adaptation of the domain in
multi-modal medical imaging data is crucial for thedevelopment of accurate
models and their use in clinics. In present work, we overview methods used to
tackle thedomain shift problem in machine learning and computer vision. The
algorithms discussed in this survey includeadvanced data processing, model
architecture enhancing and featured training, as well as predicting in
domaininvariant latent space. The application of the autoencoding neural
networks and their domain-invariant variationsare heavily discussed in a
survey. We observe the latest methods applied to the magnetic resonance
imaging(MRI) data analysis and conclude on their performance as well as propose
directions for further research.
</p>
<a href="http://arxiv.org/abs/2010.07222" target="_blank">arXiv:2010.07222</a> [<a href="http://arxiv.org/pdf/2010.07222" target="_blank">pdf</a>]

<h2>Fader Networks for domain adaptation on fMRI: ABIDE-II study. (arXiv:2010.07233v1 [eess.IV])</h2>
<h3>Marina Pominova, Ekaterina Kondrateva, Maxim Sharaev, Alexander Bernstein, Evgeny Burnaev</h3>
<p>ABIDE is the largest open-source autism spectrum disorder database with both
fMRI data and full phenotype description. These data were extensively studied
based on functional connectivity analysis as well as with deep learning on raw
data, with top models accuracy close to 75\% for separate scanning sites. Yet
there is still a problem of models transferability between different scanning
sites within ABIDE. In the current paper, we for the first time perform domain
adaptation for brain pathology classification problem on raw neuroimaging data.
We use 3D convolutional autoencoders to build the domain irrelevant latent
space image representation and demonstrate this method to outperform existing
approaches on ABIDE data.
</p>
<a href="http://arxiv.org/abs/2010.07233" target="_blank">arXiv:2010.07233</a> [<a href="http://arxiv.org/pdf/2010.07233" target="_blank">pdf</a>]

<h2>Text Classification Using Label Names Only: A Language Model Self-Training Approach. (arXiv:2010.07245v1 [cs.CL])</h2>
<h3>Yu Meng, Yunyi Zhang, Jiaxin Huang, Chenyan Xiong, Heng Ji, Chao Zhang, Jiawei Han</h3>
<p>Current text classification methods typically require a good number of
human-labeled documents as training data, which can be costly and difficult to
obtain in real applications. Humans can perform classification without seeing
any labeled examples but only based on a small set of words describing the
categories to be classified. In this paper, we explore the potential of only
using the label name of each class to train classification models on unlabeled
data, without using any labeled documents. We use pre-trained neural language
models both as general linguistic knowledge sources for category understanding
and as representation learning models for document classification. Our method
(1) associates semantically related words with the label names, (2) finds
category-indicative words and trains the model to predict their implied
categories, and (3) generalizes the model via self-training. We show that our
model achieves around 90% accuracy on four benchmark datasets including topic
and sentiment classification without using any labeled documents but learning
from unlabeled data supervised by at most 3 words (1 in most cases) per class
as the label name.
</p>
<a href="http://arxiv.org/abs/2010.07245" target="_blank">arXiv:2010.07245</a> [<a href="http://arxiv.org/pdf/2010.07245" target="_blank">pdf</a>]

<h2>Exchanging Lessons Between Algorithmic Fairness and Domain Generalization. (arXiv:2010.07249v1 [cs.LG])</h2>
<h3>Elliot Creager, J&#xf6;rn-Henrik Jacobsen, Richard Zemel</h3>
<p>Standard learning approaches are designed to perform well on average for the
data distribution available at training time. Developing learning approaches
that are not overly sensitive to the training distribution is central to
research on domain- or out-of-distribution generalization, robust optimization
and fairness. In this work we focus on links between research on domain
generalization and algorithmic fairness -- where performance under a distinct
but related test distributions is studied -- and show how the two fields can be
mutually beneficial. While domain generalization methods typically rely on
knowledge of disjoint "domains" or "environments", "sensitive" label
information indicating which demographic groups are at risk of discrimination
is often used in the fairness literature. Drawing inspiration from recent
fairness approaches that improve worst-case performance without knowledge of
sensitive groups, we propose a novel domain generalization method that handles
the more realistic scenario where environment partitions are not provided. We
then show theoretically and empirically how different partitioning schemes can
lead to increased or decreased generalization performance, enabling us to
outperform Invariant Risk Minimization with handcrafted environments in
multiple cases. We also show how a re-interpretation of IRMv1 allows us for the
first time to directly optimize a common fairness criterion, group-sufficiency,
and thereby improve performance on a fair prediction task.
</p>
<a href="http://arxiv.org/abs/2010.07249" target="_blank">arXiv:2010.07249</a> [<a href="http://arxiv.org/pdf/2010.07249" target="_blank">pdf</a>]

<h2>Robust path-following control design of heavy vehicles based on multiobjective evolutionary optimization. (arXiv:2010.07255v1 [eess.SY])</h2>
<h3>Gustavo Alves Prudencio de Morais, Lucas Barbosa Marcos, Filipe Marques Barbosa, Bruno Henrique Groenner Barbosa, Marco Henrique Terra, Valdir Grassi Jr</h3>
<p>The ability to deal with systems parametric uncertainties is an essential
issue for heavy self-driving vehicles in unconfined environments. In this
sense, robust controllers prove to be efficient for autonomous navigation.
However, uncertainty matrices for this class of systems are usually defined by
algebraic methods which demand prior knowledge of the system dynamics. In this
case, the control system designer depends, on the quality of the uncertain
model to obtain an optimal control performance. This work proposes a robust
recursive controller designed via multiobjective optimization to overcome these
shortcomings. Furthermore, a local search approach for multiobjective
optimization problems is presented. The proposed method applies to any
multiobjective evolutionary algorithm already established in the literature.
The results presented show that this combination of model-based controller and
machine learning improves the effectiveness of the system in terms of
robustness, stability and smoothness.
</p>
<a href="http://arxiv.org/abs/2010.07255" target="_blank">arXiv:2010.07255</a> [<a href="http://arxiv.org/pdf/2010.07255" target="_blank">pdf</a>]

<h2>Self-Supervised Ranking for Representation Learning. (arXiv:2010.07258v1 [cs.CV])</h2>
<h3>Ali Varamesh, Ali Diba, Tinne Tuytelaars, Luc Van Gool</h3>
<p>We present a new framework for self-supervised representation learning by
positing it as a ranking problem in an image retrieval context on a large
number of random views from random sets of images. Our work is based on two
intuitive observations: first, a good representation of images must yield a
high-quality image ranking in a retrieval task; second, we would expect random
views of an image to be ranked closer to a reference view of that image than
random views of other images. Hence, we model representation learning as a
learning-to-rank problem in an image retrieval context, and train it by
maximizing average precision (AP) for ranking. Specifically, given a mini-batch
of images, we generate a large number of positive/negative samples and
calculate a ranking loss term by separately treating each image view as a
retrieval query. The new framework, dubbed S2R2, enables computing a global
objective compared to the local objective in the popular contrastive learning
framework calculated on pairs of views. A global objective leads S2R2 to faster
convergence in terms of the number of epochs. In principle, by using a ranking
criterion, we eliminate reliance on object-centered curated datasets (e.g.,
ImageNet). When trained on STL10 and MS-COCO, S2R2 outperforms SimCLR and
performs on par with the state-of-the-art clustering-based contrastive learning
model, SwAV, while being much simpler both conceptually and
implementation-wise. Furthermore, when trained on a small subset of MS-COCO
with fewer similar scenes, S2R2 significantly outperforms both SwAV and SimCLR.
This indicates that S2R2 is potentially more effective on diverse scenes and
decreases the need for a large training dataset for self-supervised learning.
</p>
<a href="http://arxiv.org/abs/2010.07258" target="_blank">arXiv:2010.07258</a> [<a href="http://arxiv.org/pdf/2010.07258" target="_blank">pdf</a>]

<h2>Privacy-Preserving Object Detection & Localization Using Distributed Machine Learning: A Case Study of Infant Eyeblink Conditioning. (arXiv:2010.07259v1 [cs.LG])</h2>
<h3>Stefan Zwaard, Henk-Jan Boele, Hani Alers, Christos Strydis, Casey Lew-Williams, Zaid Al-Ars</h3>
<p>Distributed machine learning is becoming a popular model-training method due
to privacy, computational scalability, and bandwidth capacities. In this work,
we explore scalable distributed-training versions of two algorithms commonly
used in object detection. A novel distributed training algorithm using Mean
Weight Matrix Aggregation (MWMA) is proposed for Linear Support Vector Machine
(L-SVM) object detection based in Histogram of Orientated Gradients (HOG). In
addition, a novel Weighted Bin Aggregation (WBA) algorithm is proposed for
distributed training of Ensemble of Regression Trees (ERT) landmark
localization. Both algorithms do not restrict the location of model aggregation
and allow custom architectures for model distribution. For this work, a
Pool-Based Local Training and Aggregation (PBLTA) architecture for both
algorithms is explored. The application of both algorithms in the medical field
is examined using a paradigm from the fields of psychology and neuroscience -
eyeblink conditioning with infants - where models need to be trained on facial
images while protecting participant privacy. Using distributed learning, models
can be trained without sending image data to other nodes. The custom software
has been made available for public use on GitHub:
https://github.com/SLWZwaard/DMT. Results show that the aggregation of models
for the HOG algorithm using MWMA not only preserves the accuracy of the model
but also allows for distributed learning with an accuracy increase of 0.9%
compared with traditional learning. Furthermore, WBA allows for ERT model
aggregation with an accuracy increase of 8% when compared to single-node
models.
</p>
<a href="http://arxiv.org/abs/2010.07259" target="_blank">arXiv:2010.07259</a> [<a href="http://arxiv.org/pdf/2010.07259" target="_blank">pdf</a>]

<h2>Learning Improvised Chatbots from Adversarial Modifications of Natural Language Feedback. (arXiv:2010.07261v1 [cs.CL])</h2>
<h3>Makesh Narsimhan Sreedhar, Kun Ni, Siva Reddy</h3>
<p>The ubiquitous nature of chatbots and their interaction with users generate
an enormous amount of data. Can we improve chatbots using this data? A
self-feeding chatbot improves itself by asking natural language feedback when a
user is dissatisfied with its response and uses this feedback as an additional
training sample. However, user feedback in most cases contains extraneous
sequences hindering their usefulness as a training sample. In this work, we
propose a generative adversarial model that converts noisy feedback into a
plausible natural response in a conversation. The generator's goal is to
convert the feedback into a response that answers the user's previous utterance
and to fool the discriminator which distinguishes feedback from natural
responses. We show that augmenting original training data with these modified
feedback responses improves the original chatbot performance from 69.94% to
75.96% in ranking correct responses on the Personachat dataset, a large
improvement given that the original model is already trained on 131k samples.
</p>
<a href="http://arxiv.org/abs/2010.07261" target="_blank">arXiv:2010.07261</a> [<a href="http://arxiv.org/pdf/2010.07261" target="_blank">pdf</a>]

<h2>Disentangled Dynamic Graph Deep Generation. (arXiv:2010.07276v1 [cs.LG])</h2>
<h3>Wenbin Zhang, Liming Zhang, Dieter Pfoser, Liang Zhao</h3>
<p>Deep generative models for graphs have exhibited promising performance in
ever-increasing domains such as design of molecules (i.e, graph of atoms) and
structure prediction of proteins (i.e., graph of amino acids). Existing work
typically focuses on static rather than dynamic graphs, which are actually very
important in the applications such as protein folding, molecule reactions, and
human mobility. Extending existing deep generative models from static to
dynamic graphs is a challenging task, which requires to handle the
factorization of static and dynamic characteristics as well as mutual
interactions among node and edge patterns. Here, this paper proposes a novel
framework of factorized deep generative models to achieve interpretable dynamic
graph generation. Various generative models are proposed to characterize
conditional independence among node, edge, static, and dynamic factors. Then,
variational optimization strategies as well as dynamic graph decoders are
proposed based on newly designed factorized variational autoencoders and
recurrent graph deconvolutions. Extensive experiments on multiple datasets
demonstrate the effectiveness of the proposed models.
</p>
<a href="http://arxiv.org/abs/2010.07276" target="_blank">arXiv:2010.07276</a> [<a href="http://arxiv.org/pdf/2010.07276" target="_blank">pdf</a>]

<h2>Dissecting the components and factors of Neural Text Generation. (arXiv:2010.07279v1 [cs.CL])</h2>
<h3>Khyathi Raghavi Chandu, Alan W Black</h3>
<p>Neural text generation metamorphosed into several critical natural language
applications ranging from text completion to free form narrative generation.
Generating natural language has fundamentally been a human attribute and the
advent of ubiquitous NLP applications and virtual agents marks the need to
impart this skill to machines. There has been a colossal research effort in
various frontiers of neural text generation including machine translation,
summarization, image captioning, storytelling etc., We believe that this is an
excellent juncture to retrospect on the directions of the field. Specifically,
this paper surveys the fundamental factors and components relaying task
agnostic impacts across various generation tasks such as storytelling,
summarization, translation etc., In specific, we present an abstraction of the
imperative techniques with respect to learning paradigms, pretraining, modeling
approaches, decoding and the key challenges. Thereby, we hope to deliver a
one-stop destination for researchers in the field to facilitate a perspective
on where to situate their work and how it impacts other closely related tasks.
</p>
<a href="http://arxiv.org/abs/2010.07279" target="_blank">arXiv:2010.07279</a> [<a href="http://arxiv.org/pdf/2010.07279" target="_blank">pdf</a>]

<h2>On Fair Division under Heterogeneous Matroid Constraints. (arXiv:2010.07280v1 [cs.GT])</h2>
<h3>Amitay Dror, Michal Feldman, Erel Segal Halevi</h3>
<p>We study fair allocation of indivisible goods among additive agents with
feasibility constraints. In these settings, every agent is restricted to get a
bundle among a specified set of feasible bundles. Such scenarios have been of
great interest to the AI community due to their applicability to real-world
problems. Following some impossibility results, we restrict attention to
matroid feasibility constraints that capture natural scenarios, such as the
allocation of shifts to medical doctors or conference papers to referees.

We focus on the common fairness notion of envy-freeness up to one good (EF1).
Previous algorithms for finding EF1 allocations are either restricted to agents
with identical feasibility constraints, or allow free disposal of items. A
major open problem is the existence of EF1 complete allocations among
heterogeneous agents, where the heterogeneity is both in the agents'
feasibility constraints and in their valuations. In this work, we make progress
on this problem by providing positive and negative results for different
matroid and valuation types. Among other results, we devise polynomial-time
algorithms for finding EF1 allocations in the following settings: (i) n agents
with heterogeneous partition matroids and heterogeneous binary valuations, (ii)
2 agents with heterogeneous partition matroids and heterogeneous valuations,
and (iii) at most 3 agents with identical arbitrary matroids and heterogeneous
binary valuations.
</p>
<a href="http://arxiv.org/abs/2010.07280" target="_blank">arXiv:2010.07280</a> [<a href="http://arxiv.org/pdf/2010.07280" target="_blank">pdf</a>]

<h2>A Deep Q-Network for the Beer Game: A Deep Reinforcement Learning algorithm to Solve Inventory Optimization Problems. (arXiv:1708.05924v4 [cs.LG] UPDATED)</h2>
<h3>Afshin Oroojlooyjadid, MohammadReza Nazari, Lawrence Snyder, Martin Tak&#xe1;&#x10d;</h3>
<p>The beer game is a widely used in-class game that is played in supply chain
management classes to demonstrate the bullwhip effect. The game is a
decentralized, multi-agent, cooperative problem that can be modeled as a serial
supply chain network in which agents cooperatively attempt to minimize the
total cost of the network even though each agent can only observe its own local
information. Each agent chooses order quantities to replenish its stock. Under
some conditions, a base-stock replenishment policy is known to be optimal.
However, in a decentralized supply chain in which some agents (stages) may act
irrationally (as they do in the beer game), there is no known optimal policy
for an agent wishing to act optimally.

We propose a machine learning algorithm, based on deep Q-networks, to
optimize the replenishment decisions at a given stage. When playing alongside
agents who follow a base-stock policy, our algorithm obtains near-optimal order
quantities. It performs much better than a base-stock policy when the other
agents use a more realistic model of human ordering behavior. Unlike most other
algorithms in the literature, our algorithm does not have any limits on the
beer game parameter values. Like any deep learning algorithm, training the
algorithm can be computationally intensive, but this can be performed ahead of
time; the algorithm executes in real time when the game is played. Moreover, we
propose a transfer learning approach so that the training performed for one
agent and one set of cost coefficients can be adapted quickly for other agents
and costs. Our algorithm can be extended to other decentralized multi-agent
cooperative games with partially observed information, which is a common type
of situation in real-world supply chain problems.
</p>
<a href="http://arxiv.org/abs/1708.05924" target="_blank">arXiv:1708.05924</a> [<a href="http://arxiv.org/pdf/1708.05924" target="_blank">pdf</a>]

<h2>An Algorithmic Framework for Fairness Elicitation. (arXiv:1905.10660v2 [cs.LG] UPDATED)</h2>
<h3>Christopher Jung, Michael Kearns, Seth Neel, Aaron Roth, Logan Stapleton, Zhiwei Steven Wu</h3>
<p>We consider settings in which the right notion of fairness is not captured by
simple mathematical definitions (such as equality of error rates across
groups), but might be more complex and nuanced and thus require elicitation
from individual or collective stakeholders. We introduce a framework in which
pairs of individuals can be identified as requiring (approximately) equal
treatment under a learned model, or requiring ordered treatment such as
"applicant Alice should be at least as likely to receive a loan as applicant
Bob". We provide a provably convergent and oracle efficient algorithm for
learning the most accurate model subject to the elicited fairness constraints,
and prove generalization bounds for both accuracy and fairness. This algorithm
can also combine the elicited constraints with traditional statistical fairness
notions, thus "correcting" or modifying the latter by the former. We report
preliminary findings of a behavioral study of our framework using human-subject
fairness constraints elicited on the COMPAS criminal recidivism dataset.
</p>
<a href="http://arxiv.org/abs/1905.10660" target="_blank">arXiv:1905.10660</a> [<a href="http://arxiv.org/pdf/1905.10660" target="_blank">pdf</a>]

<h2>Generative Restricted Kernel Machines: A Framework for Multi-view Generation and Disentangled Feature Learning. (arXiv:1906.08144v6 [cs.LG] UPDATED)</h2>
<h3>Arun Pandey, Joachim Schreurs, Johan A. K. Suykens</h3>
<p>This paper introduces a novel framework for generative models based on
Restricted Kernel Machines (RKMs) with joint multi-view generation and
uncorrelated feature learning, called Gen-RKM. To enable joint multi-view
generation, this mechanism uses a shared representation of data from various
views. Furthermore, the model has a primal and dual formulation to incorporate
both kernel-based and (deep convolutional) neural network based models within
the same setting. When using neural networks as explicit feature-maps, a novel
training procedure is proposed, which jointly learns the features and shared
subspace representation. The latent variables are given by the
eigen-decomposition of the kernel matrix, where the mutual orthogonality of
eigenvectors represent the learned uncorrelated features. Experiments
demonstrate the potential of the framework through qualitative and quantitative
evaluation of generated samples on various standard datasets.
</p>
<a href="http://arxiv.org/abs/1906.08144" target="_blank">arXiv:1906.08144</a> [<a href="http://arxiv.org/pdf/1906.08144" target="_blank">pdf</a>]

<h2>Deep Learning-powered Iterative Combinatorial Auctions. (arXiv:1907.05771v5 [cs.GT] UPDATED)</h2>
<h3>Jakob Weissteiner, Sven Seuken</h3>
<p>In this paper, we study the design of deep learning-powered iterative
combinatorial auctions (ICAs). We build on prior work where preference
elicitation was done via kernelized support vector regressions (SVRs). However,
the SVR-based approach has limitations because it requires solving a machine
learning (ML)-based winner determination problem (WDP). With expressive kernels
(like gaussians), the ML-based WDP cannot be solved for large domains. While
linear or quadratic kernels have better computational scalability, these
kernels have limited expressiveness. In this work, we address these
shortcomings by using deep neural networks (DNNs) instead of SVRs. We first
show how the DNN-based WDP can be reformulated into a mixed integer program
(MIP). Second, we experimentally compare the prediction performance of DNNs
against SVRs. Third, we present experimental evaluations in two medium-sized
domains which show that even ICAs based on relatively small-sized DNNs lead to
higher economic efficiency than ICAs based on kernelized SVRs. Finally, we show
that our DNN-powered ICA also scales well to very large CA domains.
</p>
<a href="http://arxiv.org/abs/1907.05771" target="_blank">arXiv:1907.05771</a> [<a href="http://arxiv.org/pdf/1907.05771" target="_blank">pdf</a>]

<h2>Taming Momentum in a Distributed Asynchronous Environment. (arXiv:1907.11612v3 [cs.LG] UPDATED)</h2>
<h3>Ido Hakimi, Saar Barkai, Moshe Gabel, Assaf Schuster</h3>
<p>Although distributed computing can significantly reduce the training time of
deep neural networks, scaling the training process while maintaining high
efficiency and final accuracy is challenging. Distributed asynchronous training
enjoys near-linear speedup, but asynchrony causes gradient staleness - the main
difficulty in scaling stochastic gradient descent to large clusters. Momentum,
which is often used to accelerate convergence and escape local minima,
exacerbates the gradient staleness, thereby hindering convergence. We propose
DANA: a novel technique for asynchronous distributed SGD with momentum that
mitigates gradient staleness by computing the gradient on an estimated future
position of the model's parameters. Thereby, we show for the first time that
momentum can be fully incorporated in asynchronous training with almost no
ramifications to final accuracy. Our evaluation on the CIFAR and ImageNet
datasets shows that DANA outperforms existing methods, in both final accuracy
and convergence speed while scaling up to a total batch size of 16K on 64
asynchronous workers.
</p>
<a href="http://arxiv.org/abs/1907.11612" target="_blank">arXiv:1907.11612</a> [<a href="http://arxiv.org/pdf/1907.11612" target="_blank">pdf</a>]

<h2>Meta-Neighborhoods. (arXiv:1909.09140v3 [cs.LG] UPDATED)</h2>
<h3>Siyuan Shan, Yang Li, Junier Oliva</h3>
<p>Making an adaptive prediction based on one's input is an important ability
for general artificial intelligence. In this work, we step forward in this
direction and propose a semi-parametric method, Meta-Neighborhoods, where
predictions are made adaptively to the neighborhood of the input. We show that
Meta-Neighborhoods is a generalization of $k$-nearest-neighbors. Due to the
simpler manifold structure around a local neighborhood, Meta-Neighborhoods
represent the predictive distribution $p(y \mid x)$ more accurately. To reduce
memory and computation overhead, we propose induced neighborhoods that
summarize the training data into a much smaller dictionary. A meta-learning
based training mechanism is then exploited to jointly learn the induced
neighborhoods and the model. Extensive studies demonstrate the superiority of
our method.
</p>
<a href="http://arxiv.org/abs/1909.09140" target="_blank">arXiv:1909.09140</a> [<a href="http://arxiv.org/pdf/1909.09140" target="_blank">pdf</a>]

<h2>Improved Schemes for Episodic Memory-based Lifelong Learning. (arXiv:1909.11763v6 [cs.LG] UPDATED)</h2>
<h3>Yunhui Guo, Mingrui Liu, Tianbao Yang, Tajana Rosing</h3>
<p>Current deep neural networks can achieve remarkable performance on a single
task. However, when the deep neural network is continually trained on a
sequence of tasks, it seems to gradually forget the previous learned knowledge.
This phenomenon is referred to as \textit{catastrophic forgetting} and
motivates the field called lifelong learning. Recently, episodic memory based
approaches such as GEM \cite{lopez2017gradient} and A-GEM
\cite{chaudhry2018efficient} have shown remarkable performance. In this paper,
we provide the first unified view of episodic memory based approaches from an
optimization's perspective. This view leads to two improved schemes for
episodic memory based lifelong learning, called MEGA-I and MEGA-II. MEGA-I and
MEGA-II modulate the balance between old tasks and the new task by integrating
the current gradient with the gradient computed on the episodic memory.
Notably, we show that GEM and A-GEM are degenerate cases of MEGA-I and MEGA-II
which consistently put the same emphasis on the current task, regardless of how
the loss changes over time. Our proposed schemes address this issue by using
novel loss-balancing updating rules, which drastically improve the performance
over GEM and A-GEM. Extensive experimental results show that the proposed
schemes significantly advance the state-of-the-art on four commonly used
lifelong learning benchmarks, reducing the error by up to 18\%.
</p>
<a href="http://arxiv.org/abs/1909.11763" target="_blank">arXiv:1909.11763</a> [<a href="http://arxiv.org/pdf/1909.11763" target="_blank">pdf</a>]

<h2>Formal Language Constraints for Markov Decision Processes. (arXiv:1910.01074v3 [cs.LG] UPDATED)</h2>
<h3>Eleanor Quint, Dong Xu, Samuel Flint, Stephen Scott, Matthew Dwyer</h3>
<p>In order to satisfy safety conditions, an agent may be constrained from
acting freely. A safe controller can be designed a priori if an environment is
well understood, but not when learning is employed. In particular,
reinforcement learned (RL) controllers require exploration, which can be
hazardous in safety critical situations. We study the benefits of giving
structure to the constraints of a constrained Markov decision process by
specifying them in formal languages as a step towards using safety methods from
software engineering and controller synthesis. We instantiate these constraints
as finite automata to efficiently recognise constraint violations. Constraint
states are then used to augment the underlying MDP state and to learn a dense
cost function, easing the problem of quickly learning joint MDP/constraint
dynamics. We empirically evaluate the effect of these methods on training a
variety of RL algorithms over several constraints specified in Safety Gym,
MuJoCo, and Atari environments.
</p>
<a href="http://arxiv.org/abs/1910.01074" target="_blank">arXiv:1910.01074</a> [<a href="http://arxiv.org/pdf/1910.01074" target="_blank">pdf</a>]

<h2>FOCUS: Flexible Optimizable Counterfactual Explanations for Tree Ensembles. (arXiv:1911.12199v3 [cs.LG] UPDATED)</h2>
<h3>Ana Lucic, Harrie Oosterhuis, Hinda Haned, Maarten de Rijke</h3>
<p>Model interpretability has become an important problem in machine learning
(ML) due to the increased effect algorithmic decisions have on humans.
Counterfactual explanations can help users understand not only why ML models
make certain decisions, but also give insight into how these decisions can be
modified. We frame the problem of finding counterfactual explanations as an
optimization task and extend previous work that could only be applied to
differentiable models. In order to accommodate non-differentiable models such
as tree ensembles, we propose using probabilistic model approximations in the
optimization framework. We introduce a simple approximation technique that is
effective for finding counterfactual explanations for predictions of the
original model using a range of distance metrics. We show that our
counterfactual examples are significantly closer to the original instances
compared to other methods designed for tree ensembles for four distance
metrics.
</p>
<a href="http://arxiv.org/abs/1911.12199" target="_blank">arXiv:1911.12199</a> [<a href="http://arxiv.org/pdf/1911.12199" target="_blank">pdf</a>]

<h2>PolyTransform: Deep Polygon Transformer for Instance Segmentation. (arXiv:1912.02801v3 [cs.CV] UPDATED)</h2>
<h3>Justin Liang, Namdar Homayounfar, Wei-Chiu Ma, Yuwen Xiong, Rui Hu, Raquel Urtasun</h3>
<p>In this paper, we propose PolyTransform, a novel instance segmentation
algorithm that produces precise, geometry-preserving masks by combining the
strengths of prevailing segmentation approaches and modern polygon-based
methods. In particular, we first exploit a segmentation network to generate
instance masks. We then convert the masks into a set of polygons that are then
fed to a deforming network that transforms the polygons such that they better
fit the object boundaries. Our experiments on the challenging Cityscapes
dataset show that our PolyTransform significantly improves the performance of
the backbone instance segmentation network and ranks 1st on the Cityscapes
test-set leaderboard. We also show impressive gains in the interactive
annotation setting. We release the code at
https://github.com/uber-research/PolyTransform.
</p>
<a href="http://arxiv.org/abs/1912.02801" target="_blank">arXiv:1912.02801</a> [<a href="http://arxiv.org/pdf/1912.02801" target="_blank">pdf</a>]

<h2>Deep learning reveals hidden interactions in complex systems. (arXiv:2001.02539v3 [cond-mat.stat-mech] UPDATED)</h2>
<h3>Seungwoong Ha, Hawoong Jeong</h3>
<p>Rich phenomena from complex systems have long intrigued researchers, and yet
modeling system micro-dynamics and inferring the forms of interaction remain
challenging for conventional data-driven approaches, being generally
established by human scientists. In this study, we propose AgentNet, a
model-free data-driven framework consisting of deep neural networks to reveal
and analyze the hidden interactions in complex systems from observed data
alone. AgentNet utilizes a graph attention network with novel variable-wise
attention to model the interaction between individual agents, and employs
various encoders and decoders that can be selectively applied to any desired
system. Our model successfully captured a wide variety of simulated complex
systems, namely cellular automata (discrete), the Vicsek model (continuous),
and active Ornstein--Uhlenbeck particles (non-Markovian) in which, notably,
AgentNet's visualized attention values coincided with the true interaction
strength and exhibited collective behavior that was absent in the training
data. A demonstration with empirical data from a flock of birds showed that
AgentNet could identify hidden interaction ranges exhibited by real birds,
which cannot be detected by conventional velocity correlation analysis. We
expect our framework to open a novel path to investigating complex systems and
to provide insight into general process-driven modeling.
</p>
<a href="http://arxiv.org/abs/2001.02539" target="_blank">arXiv:2001.02539</a> [<a href="http://arxiv.org/pdf/2001.02539" target="_blank">pdf</a>]

<h2>Deep S$^3$PR: Simultaneous Source Separation and Phase Retrieval Using Deep Generative Models. (arXiv:2002.05856v2 [cs.LG] UPDATED)</h2>
<h3>Christopher A. Metzler, Gordon Wetzstein</h3>
<p>This paper introduces and solves the simultaneous source separation and phase
retrieval (S$^3$PR) problem. S$^3$PR is an important but largely unsolved
problem in a number application domains, including microscopy, wireless
communication, and imaging through scattering media, where one has multiple
independent coherent sources whose phase is difficult to measure. In general,
S$^3$PR is highly under-determined, non-convex, and difficult to solve. In this
work, we demonstrate that by restricting the solutions to lie in the range of a
deep generative model, we can constrain the search space sufficiently to solve
S$^3$PR.
</p>
<a href="http://arxiv.org/abs/2002.05856" target="_blank">arXiv:2002.05856</a> [<a href="http://arxiv.org/pdf/2002.05856" target="_blank">pdf</a>]

<h2>Hold me tight! Influence of discriminative features on deep network boundaries. (arXiv:2002.06349v3 [cs.LG] UPDATED)</h2>
<h3>Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard</h3>
<p>Important insights towards the explainability of neural networks reside in
the characteristics of their decision boundaries. In this work, we borrow tools
from the field of adversarial robustness, and propose a new perspective that
relates dataset features to the distance of samples to the decision boundary.
This enables us to carefully tweak the position of the training samples and
measure the induced changes on the boundaries of CNNs trained on large-scale
vision datasets. We use this framework to reveal some intriguing properties of
CNNs. Specifically, we rigorously confirm that neural networks exhibit a high
invariance to non-discriminative features, and show that the decision
boundaries of a DNN can only exist as long as the classifier is trained with
some features that hold them together. Finally, we show that the construction
of the decision boundary is extremely sensitive to small perturbations of the
training samples, and that changes in certain directions can lead to sudden
invariances in the orthogonal ones. This is precisely the mechanism that
adversarial training uses to achieve robustness.
</p>
<a href="http://arxiv.org/abs/2002.06349" target="_blank">arXiv:2002.06349</a> [<a href="http://arxiv.org/pdf/2002.06349" target="_blank">pdf</a>]

<h2>Learning Global Transparent Models Consistent with Local Contrastive Explanations. (arXiv:2002.08247v3 [cs.LG] UPDATED)</h2>
<h3>Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam, Amit Dhurandhar</h3>
<p>There is a rich and growing literature on producing local
contrastive/counterfactual explanations for black-box models (e.g. neural
networks).

In these methods, for an input, an explanation is in the form of a contrast
point differing in very few features from the original input and lying in a
different class. Other works try to build globally interpretable models like
decision trees and rule lists based on the data using actual labels or based on
the black-box models predictions. Although these interpretable global models
can be useful, they may not be consistent with local explanations from a
specific black-box of choice. In this work, we explore the question: Can we
produce a transparent global model that is simultaneously accurate and
consistent with the local (contrastive) explanations of the black-box model? We
introduce a natural local consistency metric that quantifies if the local
explanations and predictions of the black-box model are also consistent with
the proxy global transparent model. Based on a key insight we propose a novel
method where we create custom boolean features from \emph{only} (sparse) local
contrastive explanations of the black-box model and then train a globally
transparent model on just these, and showcase empirically that such models have
higher local consistency compared with other known strategies, while still
being close in performance to models that are trained with access to the
original data.
</p>
<a href="http://arxiv.org/abs/2002.08247" target="_blank">arXiv:2002.08247</a> [<a href="http://arxiv.org/pdf/2002.08247" target="_blank">pdf</a>]

<h2>Robust Robotic Pouring using Audition and Haptics. (arXiv:2003.00342v2 [cs.RO] UPDATED)</h2>
<h3>Hongzhuo Liang, Chuangchuang Zhou, Shuang Li, Xiaojian Ma, Norman Hendrich, Timo Gerkmann, Fuchun Sun, Marcus Stoffel, Jianwei Zhang</h3>
<p>Robust and accurate estimation of liquid height lies as an essential part of
pouring tasks for service robots. However, vision-based methods often fail in
occluded conditions while audio-based methods cannot work well in a noisy
environment. We instead propose a multimodal pouring network (MP-Net) that is
able to robustly predict liquid height by conditioning on both audition and
haptics input. MP-Net is trained on a self-collected multimodal pouring
dataset. This dataset contains 300 robot pouring recordings with audio and
force/torque measurements for three types of target containers. We also augment
the audio data by inserting robot noise. We evaluated MP-Net on our collected
dataset and a wide variety of robot experiments. Both network training results
and robot experiments demonstrate that MP-Net is robust against noise and
changes to the task and environment. Moreover, we further combine the predicted
height and force data to estimate the shape of the target container.
</p>
<a href="http://arxiv.org/abs/2003.00342" target="_blank">arXiv:2003.00342</a> [<a href="http://arxiv.org/pdf/2003.00342" target="_blank">pdf</a>]

<h2>Selectivity considered harmful: evaluating the causal impact of class selectivity in DNNs. (arXiv:2003.01262v3 [cs.LG] UPDATED)</h2>
<h3>Matthew L. Leavitt, Ari Morcos</h3>
<p>The properties of individual neurons are often analyzed in order to
understand the biological and artificial neural networks in which they're
embedded. Class selectivity-typically defined as how different a neuron's
responses are across different classes of stimuli or data samples-is commonly
used for this purpose. However, it remains an open question whether it is
necessary and/or sufficient for deep neural networks (DNNs) to learn class
selectivity in individual units. We investigated the causal impact of class
selectivity on network function by directly regularizing for or against class
selectivity. Using this regularizer to reduce class selectivity across units in
convolutional neural networks increased test accuracy by over 2% for ResNet18
trained on Tiny ImageNet. For ResNet20 trained on CIFAR10 we could reduce class
selectivity by a factor of 2.5 with no impact on test accuracy, and reduce it
nearly to zero with only a small ($\sim$2%) drop in test accuracy. In contrast,
regularizing to increase class selectivity significantly decreased test
accuracy across all models and datasets. These results indicate that class
selectivity in individual units is neither sufficient nor strictly necessary,
and can even impair DNN performance. They also encourage caution when focusing
on the properties of single units as representative of the mechanisms by which
DNNs function.
</p>
<a href="http://arxiv.org/abs/2003.01262" target="_blank">arXiv:2003.01262</a> [<a href="http://arxiv.org/pdf/2003.01262" target="_blank">pdf</a>]

<h2>Adaptive Discretization for Continuous Control using Particle Filtering Policy Network. (arXiv:2003.06959v3 [cs.LG] UPDATED)</h2>
<h3>Pei Xu, Ioannis Karamouzas</h3>
<p>Controlling the movements of highly articulated agents and robots has been a
long-standing challenge to model-free deep reinforcement learning. In this
paper, we propose a simple, yet general, framework for improving the
performance of policy gradient algorithms by discretizing the continuous action
space. Instead of using a fixed set of predetermined atomic actions, we exploit
particle filtering to adaptively discretize actions during training and track
the posterior policy distribution represented as a mixture of Gaussians. The
resulting policy can replace the original continuous policy of any given policy
gradient algorithm without changing its underlying model architecture. We
demonstrate the applicability of our approach to state-of-the-art on-policy and
off-policy baselines in challenging control tasks. Baselines using our
particle-based policies achieve better final performance and speed of
convergence as compared to corresponding continuous implementations and
implementations that rely on fixed discretization schemes.
</p>
<a href="http://arxiv.org/abs/2003.06959" target="_blank">arXiv:2003.06959</a> [<a href="http://arxiv.org/pdf/2003.06959" target="_blank">pdf</a>]

<h2>Distributed and Democratized Learning: Philosophy and Research Challenges. (arXiv:2003.09301v2 [cs.AI] UPDATED)</h2>
<h3>Minh N. H. Nguyen, Shashi Raj Pandey, Kyi Thar, Nguyen H. Tran, Mingzhe Chen, Walid Saad, Choong Seon Hong</h3>
<p>Due to the availability of huge amounts of data and processing abilities,
current artificial intelligence (AI) systems are effective in solving complex
tasks. However, despite the success of AI in different areas, the problem of
designing AI systems that can truly mimic human cognitive capabilities such as
artificial general intelligence, remains largely open. Consequently, many
emerging cross-device AI applications will require a transition from
traditional centralized learning systems towards large-scale distributed AI
systems that can collaboratively perform multiple complex learning tasks. In
this paper, we propose a novel design philosophy called democratized learning
(Dem-AI) whose goal is to build large-scale distributed learning systems that
rely on the self-organization of distributed learning agents that are
well-connected, but limited in learning capabilities. Correspondingly, inspired
by the societal groups of humans, the specialized groups of learning agents in
the proposed Dem-AI system are self-organized in a hierarchical structure to
collectively perform learning tasks more efficiently. As such, the Dem-AI
learning system can evolve and regulate itself based on the underlying duality
of two processes which we call specialized and generalized processes. In this
regard, we present a reference design as a guideline to realize future Dem-AI
systems, inspired by various interdisciplinary fields. Accordingly, we
introduce four underlying mechanisms in the design such as plasticity-stability
transition mechanism, self-organizing hierarchical structuring, specialized
learning, and generalization. Finally, we establish possible extensions and new
challenges for the existing learning approaches to provide better scalable,
flexible, and more powerful learning systems with the new setting of Dem-AI.
</p>
<a href="http://arxiv.org/abs/2003.09301" target="_blank">arXiv:2003.09301</a> [<a href="http://arxiv.org/pdf/2003.09301" target="_blank">pdf</a>]

<h2>Atlas: End-to-End 3D Scene Reconstruction from Posed Images. (arXiv:2003.10432v3 [cs.CV] UPDATED)</h2>
<h3>Zak Murez, Tarrence van As, James Bartolozzi, Ayan Sinha, Vijay Badrinarayanan, Andrew Rabinovich</h3>
<p>We present an end-to-end 3D reconstruction method for a scene by directly
regressing a truncated signed distance function (TSDF) from a set of posed RGB
images. Traditional approaches to 3D reconstruction rely on an intermediate
representation of depth maps prior to estimating a full 3D model of a scene. We
hypothesize that a direct regression to 3D is more effective. A 2D CNN extracts
features from each image independently which are then back-projected and
accumulated into a voxel volume using the camera intrinsics and extrinsics.
After accumulation, a 3D CNN refines the accumulated features and predicts the
TSDF values. Additionally, semantic segmentation of the 3D model is obtained
without significant computation. This approach is evaluated on the Scannet
dataset where we significantly outperform state-of-the-art baselines (deep
multiview stereo followed by traditional TSDF fusion) both quantitatively and
qualitatively. We compare our 3D semantic segmentation to prior methods that
use a depth sensor since no previous work attempts the problem with only RGB
input.
</p>
<a href="http://arxiv.org/abs/2003.10432" target="_blank">arXiv:2003.10432</a> [<a href="http://arxiv.org/pdf/2003.10432" target="_blank">pdf</a>]

<h2>Pipelined Backpropagation at Scale: Training Large Models without Batches. (arXiv:2003.11666v2 [cs.LG] UPDATED)</h2>
<h3>Atli Kosson, Vitaliy Chiley, Abhinav Venigalla, Joel Hestness, Urs K&#xf6;ster</h3>
<p>New hardware can substantially increase the speed and efficiency of deep
neural network training. To guide the development of future hardware
architectures, it is pertinent to explore the hardware and machine learning
properties of alternative training algorithms. In this work we evaluate the use
of small batch, fine-grained Pipelined Backpropagation, an asynchronous
pipeline parallel training algorithm that has significant hardware advantages.
We introduce two methods, Spike Compensation and Linear Weight Prediction, that
effectively mitigate the downsides caused by the asynchronicity of Pipelined
Backpropagation and outperform existing techniques in our setting. We show that
appropriate normalization and small batch sizes can also aid training. With our
methods, fine-grained Pipelined Backpropagation using a batch size of one can
match the accuracy of SGD for multiple networks trained on CIFAR-10 and
ImageNet. Simple scaling rules allow the use of existing hyperparamaters for
traditional training without additional tuning.
</p>
<a href="http://arxiv.org/abs/2003.11666" target="_blank">arXiv:2003.11666</a> [<a href="http://arxiv.org/pdf/2003.11666" target="_blank">pdf</a>]

<h2>Model Predictive Path Integral Control Framework for Partially Observable Navigation: A Quadrotor Case Study. (arXiv:2004.08641v3 [cs.RO] UPDATED)</h2>
<h3>Ihab S. Mohamed, Guillaume Allibert, Philippe Martinet</h3>
<p>Recently, Model Predictive Path Integral (MPPI) control algorithm has been
extensively applied to autonomous navigation tasks, where the cost map is
mostly assumed to be known and the 2D navigation tasks are only performed. In
this paper, we propose a generic MPPI control framework that can be used for 2D
or 3D autonomous navigation tasks in either fully or partially observable
environments, which are the most prevalent in robotics applications. This
framework exploits directly the 3D-voxel grid acquired from an on-board sensing
system for performing collision-free navigation. We test the framework, in
realistic RotorS-based simulation, on goal-oriented quadrotor navigation tasks
in a cluttered environment, for both fully and partially observable scenarios.
Preliminary results demonstrate that the proposed framework works perfectly,
under partial observability, in 2D and 3D cluttered environments.
</p>
<a href="http://arxiv.org/abs/2004.08641" target="_blank">arXiv:2004.08641</a> [<a href="http://arxiv.org/pdf/2004.08641" target="_blank">pdf</a>]

<h2>Space of Functions Computed by Deep-Layered Machines. (arXiv:2004.08930v3 [cs.LG] UPDATED)</h2>
<h3>Alexander Mozeika, Bo Li, David Saad</h3>
<p>We study the space of functions computed by random-layered machines,
including deep neural networks and Boolean circuits. Investigating the
distribution of Boolean functions computed on the recurrent and layer-dependent
architectures, we find that it is the same in both models. Depending on the
initial conditions and computing elements used, we characterize the space of
functions computed at the large depth limit and show that the macroscopic
entropy of Boolean functions is either monotonically increasing or decreasing
with the growing depth.
</p>
<a href="http://arxiv.org/abs/2004.08930" target="_blank">arXiv:2004.08930</a> [<a href="http://arxiv.org/pdf/2004.08930" target="_blank">pdf</a>]

<h2>Teaching Machine Comprehension with Compositional Explanations. (arXiv:2005.00806v3 [cs.CL] UPDATED)</h2>
<h3>Qinyuan Ye, Xiao Huang, Elizabeth Boschee, Xiang Ren</h3>
<p>Advances in machine reading comprehension (MRC) rely heavily on the
collection of large scale human-annotated examples in the form of (question,
paragraph, answer) triples. In contrast, humans are typically able to
generalize with only a few examples, relying on deeper underlying world
knowledge, linguistic sophistication, and/or simply superior deductive powers.
In this paper, we focus on "teaching" machines reading comprehension, using a
small number of semi-structured explanations that explicitly inform machines
why answer spans are correct. We extract structured variables and rules from
explanations and compose neural module teachers that annotate instances for
training downstream MRC models. We use learnable neural modules and soft logic
to handle linguistic variation and overcome sparse coverage; the modules are
jointly optimized with the MRC model to improve final performance. On the SQuAD
dataset, our proposed method achieves 70.14% F1 score with supervision from 26
explanations, comparable to plain supervised learning using 1,100 labeled
instances, yielding a 12x speed up.
</p>
<a href="http://arxiv.org/abs/2005.00806" target="_blank">arXiv:2005.00806</a> [<a href="http://arxiv.org/pdf/2005.00806" target="_blank">pdf</a>]

<h2>Catching Attention with Automatic Pull Quote Selection. (arXiv:2005.13263v2 [cs.CL] UPDATED)</h2>
<h3>Tanner Bohn, Charles X. Ling</h3>
<p>To advance understanding on how to engage readers, we advocate the novel task
of automatic pull quote selection. Pull quotes are a component of articles
specifically designed to catch the attention of readers with spans of text
selected from the article and given more salient presentation. This task
differs from related tasks such as summarization and clickbait identification
by several aspects. We establish a spectrum of baseline approaches to the task,
ranging from handcrafted features to a neural mixture-of-experts to cross-task
models. By examining the contributions of individual features and embedding
dimensions from these models, we uncover unexpected properties of pull quotes
to help answer the important question of what engages readers. Human evaluation
also supports the uniqueness of this task and the suitability of our selection
models. The benefits of exploring this problem further are clear: pull quotes
increase enjoyment and readability, shape reader perceptions, and facilitate
learning. Code to reproduce this work is available at
https://github.com/tannerbohn/AutomaticPullQuoteSelection.
</p>
<a href="http://arxiv.org/abs/2005.13263" target="_blank">arXiv:2005.13263</a> [<a href="http://arxiv.org/pdf/2005.13263" target="_blank">pdf</a>]

<h2>Neural Networks with Small Weights and Depth-Separation Barriers. (arXiv:2006.00625v3 [cs.LG] UPDATED)</h2>
<h3>Gal Vardi, Ohad Shamir</h3>
<p>In studying the expressiveness of neural networks, an important question is
whether there are functions which can only be approximated by sufficiently deep
networks, assuming their size is bounded. However, for constant depths,
existing results are limited to depths $2$ and $3$, and achieving results for
higher depths has been an important open question. In this paper, we focus on
feedforward ReLU networks, and prove fundamental barriers to proving such
results beyond depth $4$, by reduction to open problems and natural-proof
barriers in circuit complexity. To show this, we study a seemingly unrelated
problem of independent interest: Namely, whether there are polynomially-bounded
functions which require super-polynomial weights in order to approximate with
constant-depth neural networks. We provide a negative and constructive answer
to that question, by showing that if a function can be approximated by a
polynomially-sized, constant depth $k$ network with arbitrarily large weights,
it can also be approximated by a polynomially-sized, depth $3k+3$ network,
whose weights are polynomially bounded.
</p>
<a href="http://arxiv.org/abs/2006.00625" target="_blank">arXiv:2006.00625</a> [<a href="http://arxiv.org/pdf/2006.00625" target="_blank">pdf</a>]

<h2>Communication-Computation Trade-Off in Resource-Constrained Edge Inference. (arXiv:2006.02166v2 [cs.LG] UPDATED)</h2>
<h3>Jiawei Shao, Jun Zhang</h3>
<p>The recent breakthrough in artificial intelligence (AI), especially deep
neural networks (DNNs), has affected every branch of science and technology.
Particularly, edge AI has been envisioned as a major application scenario to
provide DNN-based services at edge devices. This article presents effective
methods for edge inference at resource-constrained devices. It focuses on
device-edge co-inference, assisted by an edge computing server, and
investigates a critical trade-off among the computation cost of the on-device
model and the communication cost of forwarding the intermediate feature to the
edge server. A three-step framework is proposed for the effective inference:
(1) model split point selection to determine the on-device model, (2)
communication-aware model compression to reduce the on-device computation and
the resulting communication overhead simultaneously, and (3) task-oriented
encoding of the intermediate feature to further reduce the communication
overhead. Experiments demonstrate that our proposed framework achieves a better
trade-off and significantly reduces the inference latency than baseline
methods.
</p>
<a href="http://arxiv.org/abs/2006.02166" target="_blank">arXiv:2006.02166</a> [<a href="http://arxiv.org/pdf/2006.02166" target="_blank">pdf</a>]

<h2>MFPP: Morphological Fragmental Perturbation Pyramid for Black-Box Model Explanations. (arXiv:2006.02659v3 [cs.CV] UPDATED)</h2>
<h3>Qing Yang, Xia Zhu, Jong-Kae Fwu, Yun Ye, Ganmei You, Yuan Zhu</h3>
<p>Deep neural networks (DNNs) have recently been applied and used in many
advanced and diverse tasks, such as medical diagnosis, automatic driving, etc.
Due to the lack of transparency of the deep models, DNNs are often criticized
for their prediction that cannot be explainable by human. In this paper, we
propose a novel Morphological Fragmental Perturbation Pyramid (MFPP) method to
solve the Explainable AI problem. In particular, we focus on the black-box
scheme, which can identify the input area that is responsible for the output of
the DNN without having to understand the internal architecture of the DNN. In
the MFPP method, we divide the input image into multi-scale fragments and
randomly mask out fragments as perturbation to generate a saliency map, which
indicates the significance of each pixel for the prediction result of the black
box model. Compared with the existing input sampling perturbation method, the
pyramid structure fragment has proved to be more effective. It can better
explore the morphological information of the input image to match its semantic
information, and does not need any value inside the DNN. We qualitatively and
quantitatively prove that MFPP meets and exceeds the performance of
state-of-the-art (SOTA) black-box interpretation method on multiple DNN models
and datasets.
</p>
<a href="http://arxiv.org/abs/2006.02659" target="_blank">arXiv:2006.02659</a> [<a href="http://arxiv.org/pdf/2006.02659" target="_blank">pdf</a>]

<h2>Hardness of Learning Neural Networks with Natural Weights. (arXiv:2006.03177v2 [cs.LG] UPDATED)</h2>
<h3>Amit Daniely, Gal Vardi</h3>
<p>Neural networks are nowadays highly successful despite strong hardness
results. The existing hardness results focus on the network architecture, and
assume that the network's weights are arbitrary. A natural approach to settle
the discrepancy is to assume that the network's weights are "well-behaved" and
posses some generic properties that may allow efficient learning. This approach
is supported by the intuition that the weights in real-world networks are not
arbitrary, but exhibit some "random-like" properties with respect to some
"natural" distributions. We prove negative results in this regard, and show
that for depth-$2$ networks, and many "natural" weights distributions such as
the normal and the uniform distribution, most networks are hard to learn.
Namely, there is no efficient learning algorithm that is provably successful
for most weights, and every input distribution. It implies that there is no
generic property that holds with high probability in such random networks and
allows efficient learning.
</p>
<a href="http://arxiv.org/abs/2006.03177" target="_blank">arXiv:2006.03177</a> [<a href="http://arxiv.org/pdf/2006.03177" target="_blank">pdf</a>]

<h2>Combinatorial Black-Box Optimization with Expert Advice. (arXiv:2006.03963v2 [cs.LG] UPDATED)</h2>
<h3>Hamid Dadkhahi, Karthikeyan Shanmugam, Jesus Rios, Payel Das, Samuel Hoffman, Troy David Loeffler, Subramanian Sankaranarayanan</h3>
<p>We consider the problem of black-box function optimization over the boolean
hypercube. Despite the vast literature on black-box function optimization over
continuous domains, not much attention has been paid to learning models for
optimization over combinatorial domains until recently. However, the
computational complexity of the recently devised algorithms are prohibitive
even for moderate numbers of variables; drawing one sample using the existing
algorithms is more expensive than a function evaluation for many black-box
functions of interest. To address this problem, we propose a computationally
efficient model learning algorithm based on multilinear polynomials and
exponential weight updates. In the proposed algorithm, we alternate between
simulated annealing with respect to the current polynomial representation and
updating the weights using monomial experts' advice. Numerical experiments on
various datasets in both unconstrained and sum-constrained boolean optimization
indicate the competitive performance of the proposed algorithm, while improving
the computational time up to several orders of magnitude compared to
state-of-the-art algorithms in the literature.
</p>
<a href="http://arxiv.org/abs/2006.03963" target="_blank">arXiv:2006.03963</a> [<a href="http://arxiv.org/pdf/2006.03963" target="_blank">pdf</a>]

<h2>Fair Classification with Noisy Protected Attributes: A Framework with Provable Guarantees. (arXiv:2006.04778v2 [cs.LG] UPDATED)</h2>
<h3>L. Elisa Celis, Lingxiao Huang, Vijay Keswani, Nisheeth K. Vishnoi</h3>
<p>Due to the deployment of classification algorithms in a multitude of
applications directly and indirectly affecting people and society, developing
methods that are fair with respect to protected attributes such as gender or
race is crucial. However, protected attributes in datasets may be inaccurate
due to noise in the data collection or if the protected attributes are imputed
either in whole or in part. Such inaccuracies can prevent existing fair
classification algorithms from achieving their claimed fairness guarantees.
Motivated by this, recent works have studied the fair classification problem in
which a binary protected attribute is "noisy" (the protected type is flipped
with a known fixed probability) by either suggesting optimization using tighter
statistical or equalized odds constraints to counter the noise or by
identifying conditions under which prior equalized odds post-processing
algorithms can handle noisy attributes. We extend the study of noise-tolerant
fair classification to a very general setting. Our main contribution is an
optimization framework for learning a fair classifier in the presence of noisy
perturbations in the protected attributes that can be employed with linear and
linear-fractional class of fairness constraints, comes with probabilistic
guarantees on accuracy and fairness, and can handle multiple, non-binary
protected attributes. Empirically, we show that our framework can be used to
attain either statistical rate or false positive rate fairness guarantees with
a minimal loss in accuracy, even when the noise corruption is large in two
real-world datasets. Prior existing noisy fair classification approaches, on
the other hand, either do not always achieve the desired fairness levels or
suffer a larger loss in accuracy for guaranteeing high fairness compared to our
framework.
</p>
<a href="http://arxiv.org/abs/2006.04778" target="_blank">arXiv:2006.04778</a> [<a href="http://arxiv.org/pdf/2006.04778" target="_blank">pdf</a>]

<h2>Neural Methods for Point-wise Dependency Estimation. (arXiv:2006.05553v3 [cs.LG] UPDATED)</h2>
<h3>Yao-Hung Hubert Tsai, Han Zhao, Makoto Yamada, Louis-Philippe Morency, Ruslan Salakhutdinov</h3>
<p>Since its inception, the neural estimation of mutual information (MI) has
demonstrated the empirical success of modeling expected dependency between
high-dimensional random variables. However, MI is an aggregate statistic and
cannot be used to measure point-wise dependency between different events. In
this work, instead of estimating the expected dependency, we focus on
estimating point-wise dependency (PD), which quantitatively measures how likely
two outcomes co-occur. We show that we can naturally obtain PD when we are
optimizing MI neural variational bounds. However, optimizing these bounds is
challenging due to its large variance in practice. To address this issue, we
develop two methods (free of optimizing MI variational bounds): Probabilistic
Classifier and Density-Ratio Fitting. We demonstrate the effectiveness of our
approaches in 1) MI estimation, 2) self-supervised representation learning, and
3) cross-modal retrieval task.
</p>
<a href="http://arxiv.org/abs/2006.05553" target="_blank">arXiv:2006.05553</a> [<a href="http://arxiv.org/pdf/2006.05553" target="_blank">pdf</a>]

<h2>Heuristic Semi-Supervised Learning for Graph Generation Inspired by Electoral College. (arXiv:2006.06469v2 [cs.SI] UPDATED)</h2>
<h3>Chen Li, Xutan Peng, Hao Peng, Jianxin Li, Lihong Wang, Philip S. Yu, Lifang He</h3>
<p>Recently, graph-based algorithms have drawn much attention because of their
impressive success in semi-supervised setups. For better model performance,
previous studies learn to transform the topology of the input graph. However,
these works only focus on optimizing the original nodes and edges, leaving the
direction of augmenting existing data unexplored. In this paper, by simulating
the generation process of graph signals, we propose a novel heuristic
pre-processing technique, namely ELectoral COllege (ELCO), which automatically
expands new nodes and edges to refine the label similarity within a dense
subgraph. Substantially enlarging the original training set with high-quality
generated labeled data, our framework can effectively benefit downstream
models. To justify the generality and practicality of ELCO, we couple it with
the popular Graph Convolution Network and Graph Attention Network to perform
extensive evaluations on three standard datasets. In all setups tested, our
method boosts the average score of base models by a large margin of 4.7 points,
as well as consistently outperforms the state-of-the-art. We release our code
and data on https://github.com/RingBDStack/ELCO to guarantee reproducibility.
</p>
<a href="http://arxiv.org/abs/2006.06469" target="_blank">arXiv:2006.06469</a> [<a href="http://arxiv.org/pdf/2006.06469" target="_blank">pdf</a>]

<h2>Few-shot Neural Architecture Search. (arXiv:2006.06863v6 [cs.LG] UPDATED)</h2>
<h3>Yiyang Zhao, Linnan Wang, Yuandong Tian, Rodrigo Fonseca, Tian Guo</h3>
<p>Efficient evaluation of a network architecture drawn from a large search
space remains a key challenge in Neural Architecture Search (NAS). Vanilla NAS
evaluates each architecture by training from scratch, which gives the true
performance but is extremely time-consuming. Recently, one-shot NAS
substantially reduces the computation cost by training only one supernetwork,
a.k.a. supernet, to approximate the performance of every architecture in the
search space via weight-sharing. However, the performance estimation can be
very inaccurate due to the co-adaption among operations. In this paper, we
propose few-shot NAS that uses multiple supernetworks, called sub-supernet,
each covering different regions of the search space to alleviate the undesired
co-adaption. Since each subsupernet only covers a small search space, compared
to one-shot NAS, few-shot NAS improves the accuracy of architecture evaluation
with a small increase of evaluation cost. With only up to 7 sub-supernets,
few-shot NAS establishes new SoTAs: on ImageNet, it finds models that reach
80.5 top-1 at 600 MB FLOPS and 77.3 top-1 at 230 MFLOPS; on CIFAR10, it reaches
98.72 top-1 without using extra data or transfer learning. In Auto-GAN,
few-shot NAS outperforms the previously published results by up to 20\%.
Extensive experiments show that few-shot NAS significantly improves various
one-shot methods, including 4 gradient-based and 6 search-based methods on 3
different tasks in NASBench-201 and NASBench one-shot-one.
</p>
<a href="http://arxiv.org/abs/2006.06863" target="_blank">arXiv:2006.06863</a> [<a href="http://arxiv.org/pdf/2006.06863" target="_blank">pdf</a>]

<h2>Subjective Question Answering: Deciphering the inner workings of Transformers in the realm of subjectivity. (arXiv:2006.08342v2 [cs.CL] UPDATED)</h2>
<h3>Lukas Muttenthaler</h3>
<p>Understanding subjectivity demands reasoning skills beyond the realm of
common knowledge. It requires a machine learning model to process sentiment and
to perform opinion mining. In this work, I've exploited a recently released
dataset for span-selection Question Answering, namely SubjQA. SubjQA is the
first QA dataset that contains questions that ask for subjective opinions
corresponding to review paragraphs from six different domains. Hence, to answer
these subjective questions, a learner must extract opinions and process
sentiment for various domains, and additionally, align the knowledge extracted
from a paragraph with the natural language utterances in the corresponding
question, which together enhance the difficulty of a QA task. The primary goal
of this thesis was to investigate the inner workings (i.e., latent
representations) of a Transformer-based architecture to contribute to a better
understanding of these not yet well understood "black-box" models.
Transformer's hidden representations, concerning the true answer span, are
clustered more closely in vector space than those representations corresponding
to erroneous predictions. This observation holds across the top three
Transformer layers for both objective and subjective questions and generally
increases as a function of layer dimensions. Moreover, the probability to
achieve a high cosine similarity among hidden representations in latent space
concerning the true answer span tokens is significantly higher for correct
compared to incorrect answer span predictions. These results have decisive
implications for down-stream applications, where it is crucial to know about
why a neural network made mistakes, and in which point, in space and time the
mistake has happened (e.g., to automatically predict correctness of an answer
span prediction without the necessity of labeled data).
</p>
<a href="http://arxiv.org/abs/2006.08342" target="_blank">arXiv:2006.08342</a> [<a href="http://arxiv.org/pdf/2006.08342" target="_blank">pdf</a>]

<h2>Visual Identification of Individual Holstein-Friesian Cattle via Deep Metric Learning. (arXiv:2006.09205v3 [cs.CV] UPDATED)</h2>
<h3>William Andrew, Jing Gao, Siobhan Mullan, Neill Campbell, Andrew W Dowsey, Tilo Burghardt</h3>
<p>Holstein-Friesian cattle exhibit individually-characteristic black and white
coat patterns visually akin to those arising from Turing's reaction-diffusion
systems. This work takes advantage of these natural markings in order to
automate visual detection and biometric identification of individual
Holstein-Friesians via convolutional neural networks and deep metric learning
techniques. Existing approaches rely on markings, tags or wearables with a
variety of maintenance requirements, whereas we present a totally hands-off
method for the automated detection, localisation, and identification of
individual animals from overhead imaging in an open herd setting, i.e. where
new additions to the herd are identified without re-training. We propose the
use of SoftMax-based reciprocal triplet loss to address the identification
problem and evaluate the techniques in detail against fixed herd paradigms. We
find that deep metric learning systems show strong performance even when many
cattle unseen during system training are to be identified and re-identified --
achieving 93.8% accuracy when trained on just half of the population. This work
paves the way for facilitating the non-intrusive monitoring of cattle
applicable to precision farming and surveillance for automated productivity,
health and welfare monitoring, and to veterinary research such as behavioural
analysis, disease outbreak tracing, and more. Key parts of the source code,
network weights and datasets are available publicly.
</p>
<a href="http://arxiv.org/abs/2006.09205" target="_blank">arXiv:2006.09205</a> [<a href="http://arxiv.org/pdf/2006.09205" target="_blank">pdf</a>]

<h2>Directional Pruning of Deep Neural Networks. (arXiv:2006.09358v2 [cs.LG] UPDATED)</h2>
<h3>Shih-Kang Chao, Zhanyu Wang, Yue Xing, Guang Cheng</h3>
<p>In the light of the fact that the stochastic gradient descent (SGD) often
finds a flat minimum valley in the training loss, we propose a novel
directional pruning method which searches for a sparse minimizer in or close to
that flat region. The proposed pruning method does not require retraining or
the expert knowledge on the sparsity level. To overcome the computational
formidability of estimating the flat directions, we propose to use a carefully
tuned $\ell_1$ proximal gradient algorithm which can provably achieve the
directional pruning with a small learning rate after sufficient training. The
empirical results demonstrate the promising results of our solution in highly
sparse regime (92% sparsity) among many existing pruning methods on the
ResNet50 with the ImageNet, while using only a slightly higher wall time and
memory footprint than the SGD. Using the VGG16 and the wide ResNet 28x10 on the
CIFAR-10 and CIFAR-100, we demonstrate that our solution reaches the same
minima valley as the SGD, and the minima found by our solution and the SGD do
not deviate in directions that impact the training loss. The code that
reproduces the results of this paper is available at
https://github.com/donlan2710/gRDA-Optimizer/tree/master/directional_pruning.
</p>
<a href="http://arxiv.org/abs/2006.09358" target="_blank">arXiv:2006.09358</a> [<a href="http://arxiv.org/pdf/2006.09358" target="_blank">pdf</a>]

<h2>Neural Anisotropy Directions. (arXiv:2006.09717v2 [cs.LG] UPDATED)</h2>
<h3>Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard</h3>
<p>In this work, we analyze the role of the network architecture in shaping the
inductive bias of deep classifiers. To that end, we start by focusing on a very
simple problem, i.e., classifying a class of linearly separable distributions,
and show that, depending on the direction of the discriminative feature of the
distribution, many state-of-the-art deep convolutional neural networks (CNNs)
have a surprisingly hard time solving this simple task. We then define as
neural anisotropy directions (NADs) the vectors that encapsulate the
directional inductive bias of an architecture. These vectors, which are
specific for each architecture and hence act as a signature, encode the
preference of a network to separate the input data based on some particular
features. We provide an efficient method to identify NADs for several CNN
architectures and thus reveal their directional inductive biases. Furthermore,
we show that, for the CIFAR-10 dataset, NADs characterize the features used by
CNNs to discriminate between different classes.
</p>
<a href="http://arxiv.org/abs/2006.09717" target="_blank">arXiv:2006.09717</a> [<a href="http://arxiv.org/pdf/2006.09717" target="_blank">pdf</a>]

<h2>ASReview: Open Source Software for Efficient and Transparent Active Learning for Systematic Reviews. (arXiv:2006.12166v2 [cs.IR] UPDATED)</h2>
<h3>Rens van de Schoot, Jonathan de Bruin, Raoul Schram, Parisa Zahedi, Jan de Boer, Felix Weijdema, Bianca Kramer, Martijn Huijts, Maarten Hoogerwerf, Gerbrich Ferdinands, Albert Harkema, Joukje Willemsen, Yongchao Ma, Qixiang Fang, Sybren Hindriks, Lars Tummers, Daniel Oberski</h3>
<p>For many tasks - including but not limited to systematic reviews for research
fields - the scientific literature needs to be checked systematically.
Currently, scholars and practitioners might screen thousands of studies by hand
to determine which studies to include in their review. This process is error
prone and inefficient, because of the extremely imbalanced data: only a very
small fraction of the studies screened will be relevant. The future of
systematic reviewing will be an interaction with machine learning algorithms to
deal with the enormous increase of available text. We therefore developed an
open source machine learning-aided pipeline applying active learning: ASReview.
We demonstrate by means of simulation studies that ASReview can yield far more
efficient reviewing than manual reviewing, while exhibiting adequate quality.
Furthermore, we describe the different options of the free and open source
research software, we show how it can be used for screening the COVID19
literature, and we present the results from a series of user experience tests.
We invite the community to contribute to open source projects such as our own,
that provide measurable and reproducible improvement over current practice.
</p>
<a href="http://arxiv.org/abs/2006.12166" target="_blank">arXiv:2006.12166</a> [<a href="http://arxiv.org/pdf/2006.12166" target="_blank">pdf</a>]

<h2>Object-Centric Learning with Slot Attention. (arXiv:2006.15055v2 [cs.LG] UPDATED)</h2>
<h3>Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, Thomas Kipf</h3>
<p>Learning object-centric representations of complex scenes is a promising step
towards enabling efficient abstract reasoning from low-level perceptual
features. Yet, most deep learning approaches learn distributed representations
that do not capture the compositional properties of natural scenes. In this
paper, we present the Slot Attention module, an architectural component that
interfaces with perceptual representations such as the output of a
convolutional neural network and produces a set of task-dependent abstract
representations which we call slots. These slots are exchangeable and can bind
to any object in the input by specializing through a competitive procedure over
multiple rounds of attention. We empirically demonstrate that Slot Attention
can extract object-centric representations that enable generalization to unseen
compositions when trained on unsupervised object discovery and supervised
property prediction tasks.
</p>
<a href="http://arxiv.org/abs/2006.15055" target="_blank">arXiv:2006.15055</a> [<a href="http://arxiv.org/pdf/2006.15055" target="_blank">pdf</a>]

<h2>Interpretation of 3D CNNs for Brain MRI Data Classification. (arXiv:2006.15969v2 [q-bio.NC] UPDATED)</h2>
<h3>Maxim Kan, Ruslan Aliev, Anna Rudenko, Nikita Drobyshev, Nikita Petrashen, Ekaterina Kondrateva, Maxim Sharaev, Alexander Bernstein, Evgeny Burnaev</h3>
<p>Deep learning shows high potential for many medical image analysis tasks.
Neural networks can work with full-size data without extensive preprocessing
and feature generation and, thus, information loss. Recent work has shown that
the morphological difference in specific brain regions can be found on MRI with
the means of Convolution Neural Networks (CNN). However, interpretation of the
existing models is based on a region of interest and can not be extended to
voxel-wise image interpretation on a whole image. In the current work, we
consider the classification task on a large-scale open-source dataset of young
healthy subjects -- an exploration of brain differences between men and women.
In this paper, we extend the previous findings in gender differences from
diffusion-tensor imaging on T1 brain MRI scans. We provide the voxel-wise 3D
CNN interpretation comparing the results of three interpretation methods:
Meaningful Perturbations, Grad CAM and Guided Backpropagation, and contribute
with the open-source library.
</p>
<a href="http://arxiv.org/abs/2006.15969" target="_blank">arXiv:2006.15969</a> [<a href="http://arxiv.org/pdf/2006.15969" target="_blank">pdf</a>]

<h2>Accelerating Reinforcement Learning Agent with EEG-based Implicit Human Feedback. (arXiv:2006.16498v3 [cs.NE] UPDATED)</h2>
<h3>Duo Xu, Mohit Agarwal, Ekansh Gupta, Faramarz Fekri, Raghupathy Sivakumar</h3>
<p>Providing Reinforcement Learning (RL) agents with human feedback can
dramatically improve various aspects of learning. However, previous methods
require human observer to give inputs explicitly (e.g., press buttons, voice
interface), burdening the human in the loop of RL agent's learning process.
Further, it is sometimes difficult or impossible to obtain the explicit human
advise (feedback), e.g., autonomous driving, disabled rehabilitation, etc. In
this work, we investigate capturing human's intrinsic reactions as implicit
(and natural) feedback through EEG in the form of error-related potentials
(ErrP), providing a natural and direct way for humans to improve the RL agent
learning. As such, the human intelligence can be integrated via implicit
feedback with RL algorithms to accelerate the learning of RL agent. We develop
three reasonably complex 2D discrete navigational games to experimentally
evaluate the overall performance of the proposed work. Major contributions of
our work are as follows,

(i) we propose and experimentally validate the zero-shot learning of ErrPs,
where the ErrPs can be learned for one game, and transferred to other unseen
games, (ii) we propose a novel RL framework for integrating implicit human
feedbacks via ErrPs with RL agent, improving the label efficiency and
robustness to human mistakes, and (iii) compared to prior works, we scale the
application of ErrPs to reasonably complex environments, and demonstrate the
significance of our approach for accelerated learning through real user
experiments.
</p>
<a href="http://arxiv.org/abs/2006.16498" target="_blank">arXiv:2006.16498</a> [<a href="http://arxiv.org/pdf/2006.16498" target="_blank">pdf</a>]

<h2>JUMPS: Joints Upsampling Method for Pose Sequences. (arXiv:2007.01151v4 [cs.CV] UPDATED)</h2>
<h3>Lucas Mourot, Fran&#xe7;ois Le Clerc, C&#xe9;dric Th&#xe9;bault, Pierre Hellier</h3>
<p>Human Pose Estimation is a low-level task useful forsurveillance, human
action recognition, and scene understandingat large. It also offers promising
perspectives for the animationof synthetic characters. For all these
applications, and especiallythe latter, estimating the positions of many joints
is desirablefor improved performance and realism. To this purpose, wepropose a
novel method called JUMPS for increasing the numberof joints in 2D pose
estimates and recovering occluded ormissing joints. We believe this is the
first attempt to addressthe issue. We build on a deep generative model that
combines aGenerative Adversarial Network (GAN) and an encoder. TheGAN learns
the distribution of high-resolution human posesequences, the encoder maps the
input low-resolution sequencesto its latent space. Inpainting is obtained by
computing the latentrepresentation whose decoding by the GAN generator
optimallymatches the joints locations at the input. Post-processing a 2Dpose
sequence using our method provides a richer representationof the character
motion. We show experimentally that thelocalization accuracy of the additional
joints is on average onpar with the original pose estimates.
</p>
<a href="http://arxiv.org/abs/2007.01151" target="_blank">arXiv:2007.01151</a> [<a href="http://arxiv.org/pdf/2007.01151" target="_blank">pdf</a>]

<h2>Rethinking Bottleneck Structure for Efficient Mobile Network Design. (arXiv:2007.02269v3 [cs.CV] UPDATED)</h2>
<h3>Zhou Daquan, Qibin Hou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan</h3>
<p>The inverted residual block is dominating architecture design for mobile
networks recently. It changes the classic residual bottleneck by introducing
two design rules: learning inverted residuals and using linear bottlenecks. In
this paper, we rethink the necessity of such design changes and find it may
bring risks of information loss and gradient confusion. We thus propose to flip
the structure and present a novel bottleneck design, called the sandglass
block, that performs identity mapping and spatial transformation at higher
dimensions and thus alleviates information loss and gradient confusion
effectively. Extensive experiments demonstrate that, different from the common
belief, such bottleneck structure is more beneficial than the inverted ones for
mobile networks. In ImageNet classification, by simply replacing the inverted
residual block with our sandglass block without increasing parameters and
computation, the classification accuracy can be improved by more than 1.7% over
MobileNetV2. On Pascal VOC 2007 test set, we observe that there is also 0.9%
mAP improvement in object detection. We further verify the effectiveness of the
sandglass block by adding it into the search space of neural architecture
search method DARTS. With 25% parameter reduction, the classification accuracy
is improved by 0.13% over previous DARTS models. Code can be found at:
https://github.com/zhoudaquan/rethinking_bottleneck_design.
</p>
<a href="http://arxiv.org/abs/2007.02269" target="_blank">arXiv:2007.02269</a> [<a href="http://arxiv.org/pdf/2007.02269" target="_blank">pdf</a>]

<h2>Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift. (arXiv:2007.02931v2 [cs.LG] UPDATED)</h2>
<h3>Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, Chelsea Finn</h3>
<p>A fundamental assumption of most machine learning algorithms is that the
training and test data are drawn from the same underlying distribution.
However, this assumption is violated in almost all practical applications:
machine learning systems are regularly tested under distribution shift, due to
temporal correlations, particular end users, or other factors. In this work, we
consider the setting where the training data are structured into groups and
test time shifts correspond to changes in the group distribution. Prior work
has approached this problem by attempting to be robust to all possible test
time distributions, which may degrade average performance. In contrast, we
propose to use ideas from meta-learning to learn models that are adaptable,
such that they can adapt to shift at test time using a batch of unlabeled test
points. We acquire such models by learning to adapt to training batches sampled
according to different distributions, which simulate structural shifts that may
occur at test time. Our primary contribution is to introduce the framework of
adaptive risk minimization (ARM), a formalization of this setting that lends
itself to meta-learning. We develop meta-learning methods for solving the ARM
problem, and compared to a variety of prior methods, these methods provide
substantial gains on image classification problems in the presence of shift.
</p>
<a href="http://arxiv.org/abs/2007.02931" target="_blank">arXiv:2007.02931</a> [<a href="http://arxiv.org/pdf/2007.02931" target="_blank">pdf</a>]

<h2>On the relationship between class selectivity, dimensionality, and robustness. (arXiv:2007.04440v2 [cs.LG] UPDATED)</h2>
<h3>Matthew L. Leavitt, Ari S. Morcos</h3>
<p>While the relative trade-offs between sparse and distributed representations
in deep neural networks (DNNs) are well-studied, less is known about how these
trade-offs apply to representations of semantically-meaningful information.
Class selectivity, the variability of a unit's responses across data classes or
dimensions, is one way of quantifying the sparsity of semantic representations.
Given recent evidence showing that class selectivity can impair generalization,
we sought to investigate whether it also confers robustness (or vulnerability)
to perturbations of input data. We found that mean class selectivity predicts
vulnerability to naturalistic corruptions; networks regularized to have lower
levels of class selectivity are more robust to corruption, while networks with
higher class selectivity are more vulnerable to corruption, as measured using
Tiny ImageNetC and CIFAR10C. In contrast, we found that class selectivity
increases robustness to multiple types of gradient-based adversarial attacks.
To examine this difference, we studied the dimensionality of the change in the
representation due to perturbation, finding that decreasing class selectivity
increases the dimensionality of this change for both corruption types, but with
a notably larger increase for adversarial attacks. These results demonstrate
the causal relationship between selectivity and robustness and provide new
insights into the mechanisms of this relationship.
</p>
<a href="http://arxiv.org/abs/2007.04440" target="_blank">arXiv:2007.04440</a> [<a href="http://arxiv.org/pdf/2007.04440" target="_blank">pdf</a>]

<h2>Identifying Latent Stochastic Differential Equations with Variational Auto-Encoders. (arXiv:2007.06075v3 [stat.ML] UPDATED)</h2>
<h3>Ali Hasan, Jo&#xe3;o M. Pereira, Sina Farsiu, Vahid Tarokh</h3>
<p>We present a method for learning latent stochastic differential equations
(SDEs) from high dimensional time series data. Given a time series generated
from a lower dimensional It\^{o} process, the proposed method uncovers the
relevant parameters of the SDE through a self-supervised learning approach.
Using the framework of variational autoencoders (VAEs), we consider a
conditional generative model for the data based on the Euler-Maruyama
approximation of SDE solutions. Furthermore, we use recent results on
identifiability of semi-supervised learning to show that our model can recover
not only the underlying SDE parameters, but also the original latent space, up
to an isometry, in the limit of infinite data. We validate the model through a
series of different simulated video processing tasks where the underlying SDE
is known. Our results suggest that the proposed method effectively learns the
underlying SDE, as predicted by the theory.
</p>
<a href="http://arxiv.org/abs/2007.06075" target="_blank">arXiv:2007.06075</a> [<a href="http://arxiv.org/pdf/2007.06075" target="_blank">pdf</a>]

<h2>Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators. (arXiv:2007.08082v2 [cs.RO] UPDATED)</h2>
<h3>Yasuhiro Fujita, Kota Uenishi, Avinash Ummadisingu, Prabhat Nagarajan, Shimpei Masuda, Mario Ynocente Castro</h3>
<p>Developing personal robots that can perform a diverse range of manipulation
tasks in unstructured environments necessitates solving several challenges for
robotic grasping systems. We take a step towards this broader goal by
presenting the first RL-based system, to our knowledge, for a mobile
manipulator that can (a) achieve targeted grasping generalizing to unseen
target objects, (b) learn complex grasping strategies for cluttered scenes with
occluded objects, and (c) perform active vision through its movable wrist
camera to better locate objects. The system is informed of the desired target
object in the form of a single, arbitrary-pose RGB image of that object,
enabling the system to generalize to unseen objects without retraining. To
achieve such a system, we combine several advances in deep reinforcement
learning and present a large-scale distributed training system using
synchronous SGD that seamlessly scales to multi-node, multi-GPU infrastructure
to make rapid prototyping easier. We train and evaluate our system in a
simulated environment, identify key components for improving performance,
analyze its behaviors, and transfer to a real-world setup.
</p>
<a href="http://arxiv.org/abs/2007.08082" target="_blank">arXiv:2007.08082</a> [<a href="http://arxiv.org/pdf/2007.08082" target="_blank">pdf</a>]

<h2>Complex Skill Acquisition through Simple Skill Imitation Learning. (arXiv:2007.10281v3 [cs.LG] UPDATED)</h2>
<h3>Pranay Pasula</h3>
<p>Humans often think of complex tasks as combinations of simpler subtasks in
order to learn those complex tasks more efficiently. For example, a backflip
could be considered a combination of four subskills: jumping, tucking knees,
rolling backwards, and thrusting arms downwards. Motivated by this line of
reasoning, we propose a new algorithm that trains neural network policies on
simple, easy-to-learn skills in order to cultivate latent spaces that
accelerate imitation learning of complex, hard-to-learn skills. We focus on the
case in which the complex task comprises a concurrent (and possibly sequential)
combination of the simpler subtasks, and therefore our algorithm can be seen as
a novel approach to concurrent hierarchical imitation learning. We evaluate our
algorithm on difficult tasks in a high-dimensional environment and find that it
consistently outperforms a state-of-the-art baseline in training speed and
overall performance.
</p>
<a href="http://arxiv.org/abs/2007.10281" target="_blank">arXiv:2007.10281</a> [<a href="http://arxiv.org/pdf/2007.10281" target="_blank">pdf</a>]

<h2>Sentiment Analysis based Multi-person Multi-criteria Decision Making Methodology using Natural Language Processing and Deep Learning for Smarter Decision Aid. Case study of restaurant choice using TripAdvisor reviews. (arXiv:2008.00032v2 [cs.CL] UPDATED)</h2>
<h3>Cristina Zuheros, Eugenio Mart&#xed;nez-C&#xe1;mara, Enrique Herrera-Viedma, Francisco Herrera</h3>
<p>Decision making models are constrained by taking the expert evaluations with
pre-defined numerical or linguistic terms. We claim that the use of sentiment
analysis will allow decision making models to consider expert evaluations in
natural language. Accordingly, we propose the Sentiment Analysis based
Multi-person Multi-criteria Decision Making (SA-MpMcDM) methodology for smarter
decision aid, which builds the expert evaluations from their natural language
reviews, and even from their numerical ratings if they are available. The
SA-MpMcDM methodology incorporates an end-to-end multi-task deep learning model
for aspect based sentiment analysis, named DOC-ABSADeepL model, able to
identify the aspect categories mentioned in an expert review, and to distill
their opinions and criteria. The individual evaluations are aggregated via the
procedure named criteria weighting through the attention of the experts. We
evaluate the methodology in a case study of restaurant choice using TripAdvisor
reviews, hence we build, manually annotate, and release the TripR-2020 dataset
of restaurant reviews. We analyze the SA-MpMcDM methodology in different
scenarios using and not using natural language and numerical evaluations. The
analysis shows that the combination of both sources of information results in a
higher quality preference vector.
</p>
<a href="http://arxiv.org/abs/2008.00032" target="_blank">arXiv:2008.00032</a> [<a href="http://arxiv.org/pdf/2008.00032" target="_blank">pdf</a>]

<h2>Online Few-shot Gesture Learning on a Neuromorphic Processor. (arXiv:2008.01151v2 [cs.NE] UPDATED)</h2>
<h3>Kenneth Stewart, Garrick Orchard, Sumit Bam Shrestha, Emre Neftci</h3>
<p>We present the Surrogate-gradient Online Error-triggered Learning (SOEL)
system for online few-shot learning on neuromorphic processors. The SOEL
learning system uses a combination of transfer learning and principles of
computational neuroscience and deep learning. We show that partially trained
deep Spiking Neural Networks (SNNs) implemented on neuromorphic hardware can
rapidly adapt online to new classes of data within a domain. SOEL updates
trigger when an error occurs, enabling faster learning with fewer updates.
Using gesture recognition as a case study, we show SOEL can be used for online
few-shot learning of new classes of pre-recorded gesture data and rapid online
learning of new gestures from data streamed live from a Dynamic Active-pixel
Vision Sensor to an Intel Loihi neuromorphic research processor.
</p>
<a href="http://arxiv.org/abs/2008.01151" target="_blank">arXiv:2008.01151</a> [<a href="http://arxiv.org/pdf/2008.01151" target="_blank">pdf</a>]

<h2>Evaluating Snowflake as an Indistinguishable Censorship Circumvention Tool. (arXiv:2008.03254v3 [cs.CR] UPDATED)</h2>
<h3>Kyle MacMillan, Jordan Holland, Prateek Mittal</h3>
<p>Tor is the most well-known tool for circumventing censorship. Unfortunately,
Tor traffic has been shown to be detectable using deep-packet inspection.
WebRTC is a popular web frame-work that enables browser-to-browser connections.
Snowflake is a novel pluggable transport that leverages WebRTC to connect Tor
clients to the Tor network. In theory, Snowflake was created to be
indistinguishable from other WebRTC services. In this paper, we evaluate the
indistinguishability of Snowflake. We collect over 6,500 DTLS handshakes from
Snowflake, Facebook Messenger, Google Hangouts, and Discord WebRTC connections
and show that Snowflake is identifiable among these applications with 100%
accuracy. We show that several features, including the extensions offered and
the number of packets in the handshake, distinguish Snowflake among these
services. Finally, we suggest recommendations for improving identification
resistance in Snowflake. We have made the dataset publicly available.
</p>
<a href="http://arxiv.org/abs/2008.03254" target="_blank">arXiv:2008.03254</a> [<a href="http://arxiv.org/pdf/2008.03254" target="_blank">pdf</a>]

<h2>Spatiotemporal Contrastive Video Representation Learning. (arXiv:2008.03800v2 [cs.CV] UPDATED)</h2>
<h3>Rui Qian, Tianjian Meng, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang, Serge Belongie, Yin Cui</h3>
<p>We present a self-supervised Contrastive Video Representation Learning (CVRL)
method to learn spatiotemporal visual representations from unlabeled videos.
Inspired by the recently proposed self-supervised contrastive learning
framework, our representations are learned using a contrastive loss, where two
clips from the same short video are pulled together in the embedding space,
while clips from different videos are pushed away. We study what makes for good
data augmentation for video self-supervised learning and find both spatial and
temporal information are crucial. In particular, we propose a simple yet
effective temporally consistent spatial augmentation method to impose strong
spatial augmentations on each frame of a video clip while maintaining the
temporal consistency across frames. For Kinetics-600 action recognition, a
linear classifier trained on representations learned by CVRL achieves 64.1%
top-1 accuracy with a 3D-ResNet50 backbone, outperforming ImageNet supervised
pre-training by 9.4% and SimCLR unsupervised pre-training by 16.1% using the
same inflated 3D-ResNet50. The performance of CVRL can be further improved to
68.2% with a larger 3D-ResNet50 (4$\times$) backbone, significantly closing the
gap between unsupervised and supervised video representation learning.
</p>
<a href="http://arxiv.org/abs/2008.03800" target="_blank">arXiv:2008.03800</a> [<a href="http://arxiv.org/pdf/2008.03800" target="_blank">pdf</a>]

<h2>Balancing Taxi Distribution in A City-Scale Dynamic Ridesharing Service: A Hybrid Solution Based on Demand Learning. (arXiv:2008.05890v2 [cs.CY] UPDATED)</h2>
<h3>Jiyao Li, Vicki H. Allan</h3>
<p>In this paper, we study the challenging problem of how to balance taxi
distribution across a city in a dynamic ridesharing service. First, we
introduce the architecture of the dynamic ridesharing system and formally
define the performance metrics indicating the efficiency of the system. Then,
we propose a hybrid solution involving a series of algorithms: the Correlated
Pooling collects correlated rider requests, the Adjacency Ride-Matching based
on Demand Learning assigns taxis to riders and balances taxi distribution
locally, the Greedy Idle Movement aims to direct taxis without a current
assignment to the areas with riders in need of service. In the experiment, we
apply city-scale data sets from the city of Chicago and complete a case study
analyzing the threshold of correlated rider requests and the average online
running time of each algorithm. We also compare our hybrid solution with
multiple other methods. The results of our experiment show that our hybrid
solution improves customer serving rate without increasing the number of taxis
in operation, allows both drivers to earn more and riders to save more per
trip, and all with a small increase in calling and extra trip time.
</p>
<a href="http://arxiv.org/abs/2008.05890" target="_blank">arXiv:2008.05890</a> [<a href="http://arxiv.org/pdf/2008.05890" target="_blank">pdf</a>]

<h2>Analyzing Who and What Appears in a Decade of US Cable TV News. (arXiv:2008.06007v3 [cs.CY] UPDATED)</h2>
<h3>James Hong, Will Crichton, Haotian Zhang, Daniel Y. Fu, Jacob Ritchie, Jeremy Barenholtz, Ben Hannel, Xinwei Yao, Michaela Murray, Geraldine Moriba, Maneesh Agrawala, Kayvon Fatahalian</h3>
<p>Cable TV news reaches millions of U.S. households each day, meaning that
decisions about who appears on the news and what stories get covered can
profoundly influence public opinion and discourse. We analyze a data set of
nearly 24/7 video, audio, and text captions from three U.S. cable TV networks
(CNN, FOX, and MSNBC) from January 2010 to July 2019. Using machine learning
tools, we detect faces in 244,038 hours of video, label each face's presented
gender, identify prominent public figures, and align text captions to audio. We
use these labels to perform screen time and word frequency analyses. For
example, we find that overall, much more screen time is given to
male-presenting individuals than to female-presenting individuals (2.4x in 2010
and 1.9x in 2019). We present an interactive web-based tool, accessible at
https://tvnews.stanford.edu, that allows the general public to perform their
own analyses on the full cable TV news data set.
</p>
<a href="http://arxiv.org/abs/2008.06007" target="_blank">arXiv:2008.06007</a> [<a href="http://arxiv.org/pdf/2008.06007" target="_blank">pdf</a>]

<h2>Towards Visually Explaining Similarity Models. (arXiv:2008.06035v2 [cs.CV] UPDATED)</h2>
<h3>Meng Zheng, Srikrishna Karanam, Terrence Chen, Richard J. Radke, Ziyan Wu</h3>
<p>We consider the problem of visually explaining similarity models, i.e.,
explaining why a model predicts two images to be similar in addition to
producing a scalar score. While much recent work in visual model
interpretability has focused on gradient-based attention, these methods rely on
a classification module to generate visual explanations. Consequently, they
cannot readily explain other kinds of models that do not use or need
classification-like loss functions (e.g., similarity models trained with a
metric learning loss). In this work, we bridge this crucial gap, presenting a
method to generate gradient-based visual attention for image similarity
predictors. By relying solely on the learned feature embedding, we show that
our approach can be applied to any kind of CNN-based similarity architecture,
an important step towards generic visual explainability. We show that our
resulting attention maps serve more than just interpretability; they can be
infused into the model learning process itself with new trainable constraints.
We show that the resulting similarity models perform, and can be visually
explained, better than the corresponding baseline models trained without these
constraints. We demonstrate our approach using extensive experiments on three
different kinds of tasks: generic image retrieval, person re-identification,
and low-shot semantic segmentation.
</p>
<a href="http://arxiv.org/abs/2008.06035" target="_blank">arXiv:2008.06035</a> [<a href="http://arxiv.org/pdf/2008.06035" target="_blank">pdf</a>]

<h2>A transfer learning metamodel using artificial neural networks applied to natural convection flows in enclosures. (arXiv:2008.12483v2 [physics.comp-ph] UPDATED)</h2>
<h3>Majid Ashouri, Alireza Hashemi</h3>
<p>In this paper, we employed a transfer learning technique to predict the
Nusselt number for natural convection flows in enclosures. Specifically, we
considered the benchmark problem of a two-dimensional square enclosure with
isolated horizontal walls and vertical walls at constant temperatures. The
Rayleigh and Prandtl numbers are sufficient parameters to simulate this problem
numerically. We adopted two approaches to this problem: Firstly, we made use of
a multi-grid dataset in order to train our artificial neural network in a
cost-effective manner. By monitoring the training losses for this dataset, we
detected any significant anomalies that stemmed from an insufficient grid size,
which we further corrected by altering the grid size or adding more data.
Secondly, we sought to endow our metamodel with the ability to account for
additional input features by performing transfer learning using deep neural
networks. We trained a neural network with a single input feature (Rayleigh)
and extended it to incorporate the effects of a second feature (Prandtl). We
also considered the case of hollow enclosures, demonstrating that our learning
framework can be applied to systems with higher physical complexity, while
bringing the computational and training costs down.
</p>
<a href="http://arxiv.org/abs/2008.12483" target="_blank">arXiv:2008.12483</a> [<a href="http://arxiv.org/pdf/2008.12483" target="_blank">pdf</a>]

<h2>Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time. (arXiv:2009.10623v2 [cs.LG] UPDATED)</h2>
<h3>Ferran Alet, Kenji Kawaguchi, Maria Bauza, Nurullah Giray Kuru, Tomas Lozano-Perez, Leslie Pack Kaelbling</h3>
<p>From CNNs to attention mechanisms, encoding inductive biases into neural
networks has been a fruitful source of improvement in machine learning.
Auxiliary losses are a general way of encoding biases in order to help networks
learn better representations by adding extra terms to the loss function.
However, since they are minimized on the training data, they suffer from the
same generalization gap as regular task losses. Moreover, by changing the loss
function, the network is optimizing a different objective than the one we care
about. In this work we solve both problems: first, we take inspiration from
\textit{transductive learning} and note that, after receiving an input but
before making a prediction, we can fine-tune our models on any unsupervised
objective. We call this process tailoring, because we customize the model to
each input. Second, we formulate a nested optimization (similar to those in
meta-learning) and train our models to perform well on the task loss after
adapting to the tailoring loss. The advantages of tailoring and meta-tailoring
are discussed theoretically and demonstrated empirically on several diverse
examples: encoding inductive conservation laws from physics to improve
predictions, improving local smoothness to increase robustness to adversarial
examples, and using contrastive losses on the query image to improve
generalization.
</p>
<a href="http://arxiv.org/abs/2009.10623" target="_blank">arXiv:2009.10623</a> [<a href="http://arxiv.org/pdf/2009.10623" target="_blank">pdf</a>]

<h2>Implicit Rank-Minimizing Autoencoder. (arXiv:2010.00679v2 [cs.LG] UPDATED)</h2>
<h3>Li Jing, Jure Zbontar, Yann LeCun</h3>
<p>An important component of autoencoders is the method by which the information
capacity of the latent representation is minimized or limited. In this work,
the rank of the covariance matrix of the codes is implicitly minimized by
relying on the fact that gradient descent learning in multi-layer linear
networks leads to minimum-rank solutions. By inserting a number of extra linear
layers between the encoder and the decoder, the system spontaneously learns
representations with a low effective dimension. The model, dubbed Implicit
Rank-Minimizing Autoencoder (IRMAE), is simple, deterministic, and learns
compact latent spaces. We demonstrate the validity of the method on several
image generation and representation learning tasks.
</p>
<a href="http://arxiv.org/abs/2010.00679" target="_blank">arXiv:2010.00679</a> [<a href="http://arxiv.org/pdf/2010.00679" target="_blank">pdf</a>]

<h2>On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach. (arXiv:2010.01079v2 [econ.TH] UPDATED)</h2>
<h3>Junpei Komiyama, Shunya Noda</h3>
<p>We analyze statistical discrimination using a multi-armed bandit model where
myopic firms face candidate workers arriving with heterogeneous observable
characteristics. The association between the worker's skill and characteristics
is unknown ex ante; thus, firms need to learn it. In such an environment,
laissez-faire may result in a highly unfair and inefficient outcome---myopic
firms are reluctant to hire minority workers because the lack of data about
minority workers prevents accurate estimation of their performance.
Consequently, minority groups could be perpetually underestimated---they are
never hired, and therefore, data about them is never accumulated. We proved
that this problem becomes more serious when the population ratio is imbalanced,
as is the case in many extant discrimination problems. We consider two
affirmative-action policies for solving this dilemma: One is a subsidy rule
that is based on the popular upper confidence bound algorithm, and another is
the Rooney Rule, which requires firms to interview at least one minority worker
for each hiring opportunity. Our results indicate temporary affirmative actions
are effective for statistical discrimination caused by data insufficiency.
</p>
<a href="http://arxiv.org/abs/2010.01079" target="_blank">arXiv:2010.01079</a> [<a href="http://arxiv.org/pdf/2010.01079" target="_blank">pdf</a>]

<h2>Gaussian Process Molecule Property Prediction with FlowMO. (arXiv:2010.01118v2 [cs.LG] UPDATED)</h2>
<h3>Henry B. Moss, Ryan-Rhys Griffiths</h3>
<p>We present FlowMO: an open-source Python library for molecular property
prediction with Gaussian Processes. Built upon GPflow and RDKit, FlowMO enables
the user to make predictions with well-calibrated uncertainty estimates, an
output central to active learning and molecular design applications. Gaussian
Processes are particularly attractive for modelling small molecular datasets, a
characteristic of many real-world virtual screening campaigns where
high-quality experimental data is scarce. Computational experiments across
three small datasets demonstrate comparable predictive performance to deep
learning methods but with superior uncertainty calibration.
</p>
<a href="http://arxiv.org/abs/2010.01118" target="_blank">arXiv:2010.01118</a> [<a href="http://arxiv.org/pdf/2010.01118" target="_blank">pdf</a>]

<h2>A Generative Machine Learning Approach to Policy Optimization in Pursuit-Evasion Games. (arXiv:2010.01711v2 [cs.LG] UPDATED)</h2>
<h3>Shiva Navabi, Osonde A. Osoba</h3>
<p>We consider a pursuit-evasion game [11] played between two agents, 'Blue'
(the pursuer) and 'Red' (the evader), over $T$ time steps. Red aims to attack
Blue's territory. Blue's objective is to intercept Red by time $T$ and thereby
limit the success of Red's attack. Blue must plan its pursuit trajectory by
choosing parameters that determine its course of movement (speed and angle in
our setup) such that it intercepts Red by time $T$. We show that Blue's
path-planning problem in pursuing Red, can be posed as a sequential decision
making problem under uncertainty. Blue's unawareness of Red's action policy
renders the analytic dynamic programming approach intractable for finding the
optimal action policy for Blue. In this work, we are interested in exploring
data-driven approaches to the policy optimization problem that Blue faces. We
apply generative machine learning (ML) approaches to learn optimal action
policies for Blue. This highlights the ability of generative ML model to learn
the relevant implicit representations for the dynamics of simulated
pursuit-evasion games. We demonstrate the effectiveness of our modeling
approach via extensive statistical assessments. This work can be viewed as a
preliminary step towards further adoption of generative modeling approaches for
addressing policy optimization problems that arise in the context of
multi-agent learning and planning [1].
</p>
<a href="http://arxiv.org/abs/2010.01711" target="_blank">arXiv:2010.01711</a> [<a href="http://arxiv.org/pdf/2010.01711" target="_blank">pdf</a>]

<h2>OLALA: Object-Level Active Learning Based Layout Annotation. (arXiv:2010.01762v2 [cs.LG] UPDATED)</h2>
<h3>Zejiang Shen, Jian Zhao, Melissa Dell, Yaoliang Yu, Weining Li</h3>
<p>In layout object detection problems, the ground-truth datasets are
constructed by annotating object instances individually. Yet active learning
for object detection is typically conducted at the image level, not at the
object level. Because objects appear with different frequencies across images,
image-level active learning may be subject to over-exposure to common objects.
This reduces the efficiency of human labeling. This work introduces an
Object-Level Active Learning based Layout Annotation framework, OLALA, which
includes an object scoring method and a prediction correction algorithm. The
object scoring method estimates the object prediction informativeness
considering both the object category and the location. It selects only the most
ambiguous object prediction regions within an image for annotators to label,
optimizing the use of the annotation budget. For the unselected model
predictions, we propose a correction algorithm to rectify two types of
potential errors with minor supervision from ground-truths. The human annotated
and model predicted objects are then merged as new image annotations for
training the object detection models. In simulated labeling experiments, we
show that OLALA helps to create the dataset more efficiently and report strong
accuracy improvements of the trained models compared to image-level active
learning baselines. The code is available at
https://github.com/lolipopshock/Detectron2_AL.
</p>
<a href="http://arxiv.org/abs/2010.01762" target="_blank">arXiv:2010.01762</a> [<a href="http://arxiv.org/pdf/2010.01762" target="_blank">pdf</a>]

<h2>InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective. (arXiv:2010.02329v2 [cs.CL] UPDATED)</h2>
<h3>Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li, Jingjing Liu</h3>
<p>Large-scale language models such as BERT have achieved state-of-the-art
performance across a wide range of NLP tasks. Recent studies, however, show
that such BERT-based models are vulnerable facing the threats of textual
adversarial attacks. We aim to address this problem from an
information-theoretic perspective, and propose InfoBERT, a novel learning
framework for robust fine-tuning of pre-trained language models. InfoBERT
contains two mutual-information-based regularizers for model training: (i) an
Information Bottleneck regularizer, which suppresses noisy mutual information
between the input and the feature representation; and (ii) a Robust Feature
regularizer, which increases the mutual information between local robust
features and global features. We provide a principled way to theoretically
analyze and improve the robustness of representation learning for language
models in both standard and adversarial training. Extensive experiments
demonstrate that InfoBERT achieves state-of-the-art robust accuracy over
several adversarial datasets on Natural Language Inference (NLI) and Question
Answering (QA) tasks.
</p>
<a href="http://arxiv.org/abs/2010.02329" target="_blank">arXiv:2010.02329</a> [<a href="http://arxiv.org/pdf/2010.02329" target="_blank">pdf</a>]

<h2>Self-supervised Monocular Depth Estimation with Semantic-aware Depth Features. (arXiv:2010.02893v2 [cs.CV] UPDATED)</h2>
<h3>Jaehoon Choi, Dongki Jung, Donghwan Lee, Changick Kim</h3>
<p>Self-supervised monocular depth estimation has emerged as a promising method
because it does not require groundtruth depth maps during training. As an
alternative for the groundtruth depth map, the photometric loss enables to
provide self-supervision on depth prediction by matching the input image
frames. However, the photometric loss causes various problems, resulting in
less accurate depth values compared with supervised approaches. In this paper,
we propose SAFENet that is designed to leverage semantic information to
overcome the limitations of the photometric loss. Our key idea is to exploit
semantic-aware depth features that integrate the semantic and geometric
knowledge. Therefore, we introduce multi-task learning schemes to incorporate
semantic-awareness into the representation of depth features. Experiments on
KITTI dataset demonstrate that our methods compete or even outperform the
state-of-the-art methods. Furthermore, extensive experiments on different
datasets show its better generalization ability and robustness to various
conditions, such as low-light or adverse weather.
</p>
<a href="http://arxiv.org/abs/2010.02893" target="_blank">arXiv:2010.02893</a> [<a href="http://arxiv.org/pdf/2010.02893" target="_blank">pdf</a>]

<h2>Global Self-Attention Networks for Image Recognition. (arXiv:2010.03019v2 [cs.CV] UPDATED)</h2>
<h3>Zhuoran Shen, Irwan Bello, Raviteja Vemulapalli, Xuhui Jia, Ching-Hui Chen</h3>
<p>Recently, a series of works in computer vision have shown promising results
on various image and video understanding tasks using self-attention. However,
due to the quadratic computational and memory complexities of self-attention,
these works either apply attention only to low-resolution feature maps in later
stages of a deep network or restrict the receptive field of attention in each
layer to a small local region. To overcome these limitations, this work
introduces a new global self-attention module, referred to as the GSA module,
which is efficient enough to serve as the backbone component of a deep network.
This module consists of two parallel layers: a content attention layer that
attends to pixels based only on their content and a positional attention layer
that attends to pixels based on their spatial locations. The output of this
module is the sum of the outputs of the two layers. Based on the proposed GSA
module, we introduce new standalone global attention-based deep networks that
use GSA modules instead of convolutions to model pixel interactions. Due to the
global extent of the proposed GSA module, a GSA network has the ability to
model long-range pixel interactions throughout the network. Our experimental
results show that GSA networks outperform the corresponding convolution-based
networks significantly on the CIFAR-100 and ImageNet datasets while using less
parameters and computations. The proposed GSA networks also outperform various
existing attention-based networks on the ImageNet dataset.
</p>
<a href="http://arxiv.org/abs/2010.03019" target="_blank">arXiv:2010.03019</a> [<a href="http://arxiv.org/pdf/2010.03019" target="_blank">pdf</a>]

<h2>FairMixRep : Self-supervised Robust Representation Learning for Heterogeneous Data with Fairness constraints. (arXiv:2010.03228v2 [stat.ML] UPDATED)</h2>
<h3>Souradip Chakraborty, Ekansh Verma, Saswata Sahoo, Jyotishka Datta</h3>
<p>Representation Learning in a heterogeneous space with mixed variables of
numerical and categorical types has interesting challenges due to its complex
feature manifold. Moreover, feature learning in an unsupervised setup, without
class labels and a suitable learning loss function, adds to the problem
complexity. Further, the learned representation and subsequent predictions
should not reflect discriminatory behavior towards certain sensitive groups or
attributes. The proposed feature map should preserve maximum variations present
in the data and needs to be fair with respect to the sensitive variables. We
propose, in the first phase of our work, an efficient encoder-decoder framework
to capture the mixed-domain information. The second phase of our work focuses
on de-biasing the mixed space representations by adding relevant fairness
constraints. This ensures minimal information loss between the representations
before and after the fairness-preserving projections. Both the information
content and the fairness aspect of the final representation learned has been
validated through several metrics where it shows excellent performance. Our
work (FairMixRep) addresses the problem of Mixed Space Fair Representation
learning from an unsupervised perspective and learns a Universal representation
that is timely, unique, and a novel research contribution.
</p>
<a href="http://arxiv.org/abs/2010.03228" target="_blank">arXiv:2010.03228</a> [<a href="http://arxiv.org/pdf/2010.03228" target="_blank">pdf</a>]

<h2>Learning Clusterable Visual Features for Zero-Shot Recognition. (arXiv:2010.03245v2 [cs.CV] UPDATED)</h2>
<h3>Jingyi Xu, Zhixin Shu, Dimitris Samaras</h3>
<p>In zero-shot learning (ZSL), conditional generators have been widely used to
generate additional training features. These features can then be used to train
the classifiers for testing data. However, some testing data are considered
"hard" as they lie close to the decision boundaries and are prone to
misclassification, leading to performance degradation for ZSL. In this paper,
we propose to learn clusterable features for ZSL problems. Using a Conditional
Variational Autoencoder (CVAE) as the feature generator, we project the
original features to a new feature space supervised by an auxiliary
classification loss. To further increase clusterability, we fine-tune the
features using Gaussian similarity loss. The clusterable visual features are
not only more suitable for CVAE reconstruction but are also more separable
which improves classification accuracy. Moreover, we introduce Gaussian noise
to enlarge the intra-class variance of the generated features, which helps to
improve the classifier's robustness. Our experiments on SUN,CUB, and AWA2
datasets show consistent improvement over previous state-of-the-art ZSL results
by a large margin. In addition to its effectiveness on zero-shot
classification, experiments show that our method to increase feature
clusterability benefits few-shot learning algorithms as well.
</p>
<a href="http://arxiv.org/abs/2010.03245" target="_blank">arXiv:2010.03245</a> [<a href="http://arxiv.org/pdf/2010.03245" target="_blank">pdf</a>]

<h2>Learning Nonlinear Dynamics and Chaos: A Universal Framework for Knowledge-Based System Identification and Prediction. (arXiv:2010.03415v2 [nlin.CD] UPDATED)</h2>
<h3>Tom Z. Jiahao, M. Ani Hsieh, Eric Forgoston</h3>
<p>We present a universal framework for learning the behavior of dynamical
systems from observations. We formulate the learning task as a constrained
optimization problem which can be efficiently solved with the adjoint
sensitivity method. Our scheme is flexible with regards to the choice of model,
and existing knowledge can be readily incorporated for hybrid learning. We
demonstrate the effectiveness of our scheme by learning a variety of systems
including a stiff Van der Pol oscillator, a chaotic Lorenz system, and the
Kuramoto-Sivashinsky equation. We also include examples of hybrid learning and
learning from noisy observations.
</p>
<a href="http://arxiv.org/abs/2010.03415" target="_blank">arXiv:2010.03415</a> [<a href="http://arxiv.org/pdf/2010.03415" target="_blank">pdf</a>]

<h2>Energy-based Out-of-distribution Detection. (arXiv:2010.03759v2 [cs.LG] UPDATED)</h2>
<h3>Weitang Liu, Xiaoyun Wang, John D. Owens, Yixuan Li</h3>
<p>Determining whether inputs are out-of-distribution (OOD) is an essential
building block for safely deploying machine learning models in the open world.
However, previous methods relying on the softmax confidence score suffer from
overconfident posterior distributions for OOD data. We propose a unified
framework for OOD detection that uses an energy score. We show that energy
scores better distinguish in- and out-of-distribution samples than the
traditional approach using the softmax scores. Unlike softmax confidence
scores, energy scores are theoretically aligned with the probability density of
the inputs and are less susceptible to the overconfidence issue. Within this
framework, energy can be flexibly used as a scoring function for any
pre-trained neural classifier as well as a trainable cost function to shape the
energy surface explicitly for OOD detection. On a CIFAR-10 pre-trained
WideResNet, using the energy score reduces the average FPR (at TPR 95%) by
18.03% compared to the softmax confidence score. With energy-based training,
our method outperforms the state-of-the-art on common benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.03759" target="_blank">arXiv:2010.03759</a> [<a href="http://arxiv.org/pdf/2010.03759" target="_blank">pdf</a>]

<h2>Assessing Phrasal Representation and Composition in Transformers. (arXiv:2010.03763v2 [cs.CL] UPDATED)</h2>
<h3>Lang Yu, Allyson Ettinger</h3>
<p>Deep transformer models have pushed performance on NLP tasks to new limits,
suggesting sophisticated treatment of complex linguistic inputs, such as
phrases. However, we have limited understanding of how these models handle
representation of phrases, and whether this reflects sophisticated composition
of phrase meaning like that done by humans. In this paper, we present
systematic analysis of phrasal representations in state-of-the-art pre-trained
transformers. We use tests leveraging human judgments of phrase similarity and
meaning shift, and compare results before and after control of word overlap, to
tease apart lexical effects versus composition effects. We find that phrase
representation in these models relies heavily on word content, with little
evidence of nuanced composition. We also identify variations in phrase
representation quality across models, layers, and representation types, and
make corresponding recommendations for usage of representations from these
models.
</p>
<a href="http://arxiv.org/abs/2010.03763" target="_blank">arXiv:2010.03763</a> [<a href="http://arxiv.org/pdf/2010.03763" target="_blank">pdf</a>]

<h2>Young Adult Unemployment Through the Lens of Social Media: Italy as a case study. (arXiv:2010.04496v2 [cs.CY] UPDATED)</h2>
<h3>Alessandra Urbinati, Kyriaki Kalimeri, Andrea Bonanomi, Alessandro Rosina, Ciro Cattuto, Daniela Paolotti</h3>
<p>Youth unemployment rates are still in alerting levels for many countries,
among which Italy. Direct consequences include poverty, social exclusion, and
criminal behaviours, while negative impact on the future employability and wage
cannot be obscured. In this study, we employ survey data together with social
media data, and in particular likes on Facebook Pages, to analyse personality,
moral values, but also cultural elements of the young unemployed population in
Italy. Our findings show that there are small but significant differences in
personality and moral values, with the unemployed males to be less agreeable
while females more open to new experiences. At the same time, unemployed have a
more collectivist point of view, valuing more in-group loyalty, authority, and
purity foundations. Interestingly, topic modelling analysis did not reveal
major differences in interests and cultural elements of the unemployed.
Utilisation patterns emerged though; the employed seem to use Facebook to
connect with local activities, while the unemployed use it mostly as for
entertainment purposes and as a source of news, making them susceptible to
mis/disinformation. We believe these findings can help policymakers get a
deeper understanding of this population and initiatives that improve both the
hard and the soft skills of this fragile population.
</p>
<a href="http://arxiv.org/abs/2010.04496" target="_blank">arXiv:2010.04496</a> [<a href="http://arxiv.org/pdf/2010.04496" target="_blank">pdf</a>]

<h2>Deep Neural Network Test Coverage: How Far Are We?. (arXiv:2010.04946v2 [cs.SE] UPDATED)</h2>
<h3>Junjie Chen, Ming Yan, Zan Wang, Yuning Kang, Zhuo Wu</h3>
<p>DNN testing is one of the most effective methods to guarantee the quality of
DNN. In DNN testing, many test coverage metrics have been proposed to measure
test effectiveness, including structural coverage and non-structural coverage
(which are classified according to whether considering which structural
elements are covered during testing). Those test coverage metrics are proposed
based on the assumption: they are correlated with test effectiveness (i.e., the
generation of adversarial test inputs or the error-revealing capability of test
inputs in DNN testing studies). However, it is still unknown whether the
assumption is tenable. In this work, we conducted the first extensive study to
systematically validate the assumption by controlling for the size of test
sets. In the study, we studied seven typical test coverage metrics based on 9
pairs of datasets and models with great diversity (including four pairs that
have never been used to evaluate these test coverage metrics before). The
results demonstrate that the assumption fails for structural coverage in
general but holds for non-structural coverage on more than half of subjects,
indicating that measuring the difference of DNN behaviors between test inputs
and training data is more promising than measuring which structural elements
are covered by test inputs for measuring test effectiveness. Even so, the
current non-structural coverage metrics still can be improved from several
aspects such as unfriendly parameters and unstable performance. That indicates
that although a lot of test coverage metrics have been proposed before, there
is still a lot of room for improvement of measuring test effectiveness in DNN
testing, and our study has pointed out some promising directions.
</p>
<a href="http://arxiv.org/abs/2010.04946" target="_blank">arXiv:2010.04946</a> [<a href="http://arxiv.org/pdf/2010.04946" target="_blank">pdf</a>]

<h2>EB-DEVS: A Formal Framework for Modeling and Simulation of Emergent Behavior in Dynamic Complex Systems. (arXiv:2010.05042v2 [cs.MA] UPDATED)</h2>
<h3>Daniel J. Foguelman, Philipp Henning, Adelinde Uhrmacher, Rodrigo Castro</h3>
<p>Emergent behavior is a key feature defining a system under study as a complex
system. Simulation has been recognized as the only way to deal with the study
of the emergency of properties (at a macroscopic level) among groups of system
components (at a microscopic level), for the manifestations of emergent
structures cannot be deduced from analysing components in isolation. A
systems-oriented generalisation must consider the presence of feedback loops
(micro components react to macro properties), interaction among components of
different classes (modular composition) and layered interaction of subsystems
operating at different spatio-temporal scales (hierarchical organisation). In
this work we introduce Emergent Behavior-DEVS (EB-DEVS) a Modeling and
Simulation (M&amp;S) formalism that permits reasoning about complex systems where
emergent behavior is placed at the forefront of the analysis activity. EB-DEVS
builds on the DEVS formalism, adding upward/downward communication channels to
well-established capabilities for modular and hierarchical M&amp;S of heterogeneous
multi-formalism systems. EB-DEVS takes a minimalist stance on expressiveness,
introducing a small set of extensions on Classic DEVS that can cope with
emergent behavior, and making both formalisms interoperable (the modeler
decides which subsystems deserve to be expressed via micro-macro dynamics). We
present three case studies: flocks of birds with learning, population epidemics
with vaccination and sub-cellular dynamics with homeostasis, through which we
showcase how EB-DEVS performs by placing emergent properties at the center of
the M&amp;S process.
</p>
<a href="http://arxiv.org/abs/2010.05042" target="_blank">arXiv:2010.05042</a> [<a href="http://arxiv.org/pdf/2010.05042" target="_blank">pdf</a>]

<h2>MS$^2$L: Multi-Task Self-Supervised Learning for Skeleton Based Action Recognition. (arXiv:2010.05599v2 [cs.CV] UPDATED)</h2>
<h3>Lilang Lin, Sijie Song, Wenhan Yan, Jiaying Liu</h3>
<p>In this paper, we address self-supervised representation learning from human
skeletons for action recognition. Previous methods, which usually learn feature
presentations from a single reconstruction task, may come across the
overfitting problem, and the features are not generalizable for action
recognition. Instead, we propose to integrate multiple tasks to learn more
general representations in a self-supervised manner. To realize this goal, we
integrate motion prediction, jigsaw puzzle recognition, and contrastive
learning to learn skeleton features from different aspects. Skeleton dynamics
can be modeled through motion prediction by predicting the future sequence. And
temporal patterns, which are critical for action recognition, are learned
through solving jigsaw puzzles. We further regularize the feature space by
contrastive learning. Besides, we explore different training strategies to
utilize the knowledge from self-supervised tasks for action recognition. We
evaluate our multi-task self-supervised learning approach with action
classifiers trained under different configurations, including unsupervised,
semi-supervised and fully-supervised settings. Our experiments on the NW-UCLA,
NTU RGB+D, and PKUMMD datasets show remarkable performance for action
recognition, demonstrating the superiority of our method in learning more
discriminative and general features. Our project website is available at
https://langlandslin.github.io/projects/MSL/.
</p>
<a href="http://arxiv.org/abs/2010.05599" target="_blank">arXiv:2010.05599</a> [<a href="http://arxiv.org/pdf/2010.05599" target="_blank">pdf</a>]

<h2>Monitoring War Destruction from Space: A Machine Learning Approach. (arXiv:2010.05970v2 [econ.GN] UPDATED)</h2>
<h3>Hannes Mueller, Andre Groger, Jonathan Hersh, Andrea Matranga, Joan Serrat</h3>
<p>Existing data on building destruction in conflict zones rely on eyewitness
reports or manual detection, which makes it generally scarce, incomplete and
potentially biased. This lack of reliable data imposes severe limitations for
media reporting, humanitarian relief efforts, human rights monitoring,
reconstruction initiatives, and academic studies of violent conflict. This
article introduces an automated method of measuring destruction in
high-resolution satellite images using deep learning techniques combined with
data augmentation to expand training samples. We apply this method to the
Syrian civil war and reconstruct the evolution of damage in major cities across
the country. The approach allows generating destruction data with unprecedented
scope, resolution, and frequency - only limited by the available satellite
imagery - which can alleviate data limitations decisively.
</p>
<a href="http://arxiv.org/abs/2010.05970" target="_blank">arXiv:2010.05970</a> [<a href="http://arxiv.org/pdf/2010.05970" target="_blank">pdf</a>]

<h2>Probabilistic Social Learning Improves the Public's Detection of Misinformation. (arXiv:2010.06019v2 [cs.SI] UPDATED)</h2>
<h3>Douglas Guilbeault, Samuel Woolley, Joshua Becker</h3>
<p>The digital spread of misinformation is one of the leading threats to
democracy, public health, and the global economy. Popular strategies for
mitigating misinformation include crowdsourcing, machine learning, and media
literacy programs that require social media users to classify news in binary
terms as either true or false. However, research on peer influence suggests
that framing decisions in binary terms can amplify judgment errors and limit
social learning, whereas framing decisions in probabilistic terms can reliably
improve judgments. In this preregistered experiment, we compare online peer
networks that collaboratively evaluate the veracity of news by communicating
either binary or probabilistic judgments. Exchanging probabilistic estimates of
news veracity substantially improved individual and group judgments, with the
effect of eliminating polarization in news evaluation. By contrast, exchanging
binary classifications reduced social learning and entrenched polarization. The
benefits of probabilistic social learning are robust to participants'
education, gender, race, income, religion, and partisanship.
</p>
<a href="http://arxiv.org/abs/2010.06019" target="_blank">arXiv:2010.06019</a> [<a href="http://arxiv.org/pdf/2010.06019" target="_blank">pdf</a>]

<h2>A Physics-Guided Neural Network Framework for Elastic Plates: Comparison of Governing Equations-Based and Energy-Based Approaches. (arXiv:2010.06050v2 [cs.CE] UPDATED)</h2>
<h3>Wei Li, Martin Z. Bazant, Juner Zhu</h3>
<p>One of the obstacles hindering the scaling-up of the initial successes of
machine learning in practical engineering applications is the dependence of the
accuracy on the size of the database that "drives" the algorithms.
Incorporating the already-known physical laws into the training process can
significantly reduce the size of the required database. In this study, we
establish a neural network-based computational framework to characterize the
finite deformation of elastic plates, which in classic theories is described by
the F\"oppl--von K\'arm\'an (FvK) equations with a set of boundary conditions
(BCs). A neural network is constructed by taking the spatial coordinates as the
input and the displacement field as the output to approximate the exact
solution of the FvK equations. The physical information (PDEs, BCs, and
potential energies) is then incorporated into the loss function, and a pseudo
dataset is sampled without knowing the exact solution to finally train the
neural network. The prediction accuracy of the modeling framework is carefully
examined by applying it to four different loading cases: in-plane tension with
non-uniformly distributed stretching forces, in-plane central-hole tension,
out-of-plane deflection, and buckling under compression. Two ways of
formulating the loss function are compared, one based on the PDEs and BCs, and
the other based on the total potential energy of the plate. Through the
comparison with the finite element simulation results, it is found that our
computational framework is capable of characterizing the elastic deformation of
plates with a satisfactory accuracy. Compared with incorporating the PDEs and
BCs in the loss, using the total potential energy is a better way in terms of
training accuracy and efficiency.
</p>
<a href="http://arxiv.org/abs/2010.06050" target="_blank">arXiv:2010.06050</a> [<a href="http://arxiv.org/pdf/2010.06050" target="_blank">pdf</a>]

<h2>BioMegatron: Larger Biomedical Domain Language Model. (arXiv:2010.06060v2 [cs.CL] UPDATED)</h2>
<h3>Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, Mostofa Patwary, Mohammad Shoeybi, Raghav Mani</h3>
<p>There has been an influx of biomedical domain-specific language models,
showing language models pre-trained on biomedical text perform better on
biomedical domain benchmarks than those trained on general domain text corpora
such as Wikipedia and Books. Yet, most works do not study the factors affecting
each domain language application deeply. Additionally, the study of model size
on domain-specific models has been mostly missing. We empirically study and
evaluate several factors that can affect performance on domain language
applications, such as the sub-word vocabulary set, model size, pre-training
corpus, and domain transfer. We show consistent improvements on benchmarks with
our larger BioMegatron model trained on a larger domain corpus, contributing to
our understanding of domain language model applications. We demonstrate
noticeable improvements over the previous state-of-the-art (SOTA) on standard
biomedical NLP benchmarks of named entity recognition, relation extraction, and
question answering. Model checkpoints and code are available at
[https://ngc.nvidia.com] and [https://github.com/NVIDIA/NeMo].
</p>
<a href="http://arxiv.org/abs/2010.06060" target="_blank">arXiv:2010.06060</a> [<a href="http://arxiv.org/pdf/2010.06060" target="_blank">pdf</a>]

<h2>Attn-HybridNet: Improving Discriminability of Hybrid Features with Attention Fusion. (arXiv:2010.06096v2 [cs.CV] UPDATED)</h2>
<h3>Sunny Verma, Chen Wang, Liming Zhu, Wei Liu</h3>
<p>The principal component analysis network (PCANet) is an unsupervised
parsimonious deep network, utilizing principal components as filters in its
convolution layers. Albeit powerful, the PCANet consists of basic operations
such as principal components and spatial pooling, which suffers from two
fundamental problems. First, the principal components obtain information by
transforming it to column vectors (which we call the amalgamated view), which
incurs the loss of the spatial information in the data. Second, the generalized
spatial pooling utilized in the PCANet induces feature redundancy and also
fails to accommodate spatial statistics of natural images. In this research, we
first propose a tensor-factorization based deep network called the Tensor
Factorization Network (TFNet). The TFNet extracts features from the spatial
structure of the data (which we call the minutiae view). We then show that the
information obtained by the PCANet and the TFNet are distinctive and
non-trivial but individually insufficient. This phenomenon necessitates the
development of proposed HybridNet, which integrates the information discovery
with the two views of the data. To enhance the discriminability of hybrid
features, we propose Attn-HybridNet, which alleviates the feature redundancy by
performing attention-based feature fusion. The significance of our proposed
Attn-HybridNet is demonstrated on multiple real-world datasets where the
features obtained with Attn-HybridNet achieves better classification
performance over other popular baseline methods, demonstrating the
effectiveness of the proposed technique.
</p>
<a href="http://arxiv.org/abs/2010.06096" target="_blank">arXiv:2010.06096</a> [<a href="http://arxiv.org/pdf/2010.06096" target="_blank">pdf</a>]

<h2>Deep Reservoir Networks with Learned Hidden Reservoir Weights using Direct Feedback Alignment. (arXiv:2010.06209v2 [cs.NE] UPDATED)</h2>
<h3>Matthew Evanusa, Yiannis Aloimonos, Cornelia Ferm&#xfc;ller</h3>
<p>Deep Reservoir Computing has emerged as a new paradigm for deep learning,
which is based around the reservoir computing principle of maintaining random
pools of neurons. The reservoir paradigm reflects and respects the high degree
of recurrence in biological brains, and the role that neuronal dynamics play in
learning. However, one issue hampering deep reservoir development is that one
cannot backpropagate through the reservoir layers. Recent deep reservoir
architectures do not learn hidden or hierarchical representations in the same
manner as deep artifical neural neteworks (ANNs), but rather concatenate all
hidden reservoirs together to perform traditional regression. Here we present a
novel Deep Reservoir Computer for time series prediction and classification
that learns through the non-differentiable hidden reservoir layers using a
biologically-inspired backpropagation alternative called Direct Feedback
Alignment, which resembles global dopamine signal broadcasting in the brain.
The hope is that this will enable future deep reservoir architectures to learn
hidden temporal representations.
</p>
<a href="http://arxiv.org/abs/2010.06209" target="_blank">arXiv:2010.06209</a> [<a href="http://arxiv.org/pdf/2010.06209" target="_blank">pdf</a>]

<h2>Annotationsaurus: A Searchable Directory of Annotation Tools. (arXiv:2010.06251v2 [cs.CL] UPDATED)</h2>
<h3>Mariana Neves, Jurica Seva</h3>
<p>Manual annotation of textual documents is a necessary task when constructing
benchmark corpora for training and evaluating machine learning algorithms. We
created a comprehensive directory of annotation tools that currently includes
93 tools. We analyzed the tools over a set of 31 features and implemented
simple scripts and a Web application that filters the tools based on chosen
criteria. We present two use cases using the directory and propose ideas for
its maintenance. The directory, source codes for scripts, and link to the Web
application are available at: https://github.com/mariananeves/annotation-tools
</p>
<a href="http://arxiv.org/abs/2010.06251" target="_blank">arXiv:2010.06251</a> [<a href="http://arxiv.org/pdf/2010.06251" target="_blank">pdf</a>]

<h2>Tire Force Estimation in Intelligent Tires Using Machine Learning. (arXiv:2010.06299v2 [eess.SY] UPDATED)</h2>
<h3>Nan Xu, Hassan Askari, Yanjun Huang, Jianfeng Zhou, Amir Khajepour</h3>
<p>The concept of intelligent tires has drawn attention of researchers in the
areas of autonomous driving, advanced vehicle control, and artificial
intelligence. The focus of this paper is on intelligent tires and the
application of machine learning techniques to tire force estimation. We present
an intelligent tire system with a tri-axial acceleration sensor, which is
installed onto the inner liner of the tire, and Neural Network techniques for
real-time processing of the sensor data. The accelerometer is capable of
measuring the acceleration in x,y, and z directions. When the accelerometer
enters the tire contact patch, it starts generating signals until it fully
leaves it. Simultaneously, by using MTS Flat-Trac test platform, tire actual
forces are measured. Signals generated by the accelerometer and MTS Flat-Trac
testing system are used for training three different machine learning
techniques with the purpose of online prediction of tire forces. It is shown
that the developed intelligent tire in conjunction with machine learning is
effective in accurate prediction of tire forces under different driving
conditions. The results presented in this work will open a new avenue of
research in the area of intelligent tires, vehicle systems, and tire force
estimation.
</p>
<a href="http://arxiv.org/abs/2010.06299" target="_blank">arXiv:2010.06299</a> [<a href="http://arxiv.org/pdf/2010.06299" target="_blank">pdf</a>]

<h2>Coarse and fine-grained automatic cropping deep convolutional neural network. (arXiv:2010.06379v2 [cs.CV] UPDATED)</h2>
<h3>Jingfei Chang</h3>
<p>The existing convolutional neural network pruning algorithms can be divided
into two categories: coarse-grained clipping and fine-grained clipping. This
paper proposes a coarse and fine-grained automatic pruning algorithm, which can
achieve more efficient and accurate compression acceleration for convolutional
neural networks. First, cluster the intermediate feature maps of the
convolutional neural network to obtain the network structure after
coarse-grained clipping, and then use the particle swarm optimization algorithm
to iteratively search and optimize the structure. Finally, the optimal network
tailoring substructure is obtained.
</p>
<a href="http://arxiv.org/abs/2010.06379" target="_blank">arXiv:2010.06379</a> [<a href="http://arxiv.org/pdf/2010.06379" target="_blank">pdf</a>]

<h2>Pagsusuri ng RNN-based Transfer Learning Technique sa Low-Resource Language. (arXiv:2010.06447v2 [cs.CL] UPDATED)</h2>
<h3>Dan John Velasco</h3>
<p>Low-resource languages such as Filipino suffer from data scarcity which makes
it challenging to develop NLP applications for Filipino language. The use of
Transfer Learning (TL) techniques alleviates this problem in low-resource
setting. In recent years, transformer-based models are proven to be effective
in low-resource tasks but faces challenges in accessibility due to its high
compute and memory requirements. For this reason, there's a need for a cheaper
but effective alternative. This paper has three contributions. First, release a
pre-trained AWD-LSTM language model for Filipino language. Second, benchmark
AWD-LSTM in the Hate Speech classification task and show that it performs on
par with transformer-based models. Third, analyze the the performance of
AWD-LSTM in low-resource setting using degradation test and compare it with
transformer-based models.

-----

Ang mga low-resource languages tulad ng Filipino ay gipit sa accessible na
datos kaya't mahirap gumawa ng mga applications sa wikang ito. Ang mga Transfer
Learning (TL) techniques ay malaking tulong para sa low-resource setting o mga
pagkakataong gipit sa datos. Sa mga nagdaang taon, nanaig ang mga
transformer-based TL techniques pagdating sa low-resource tasks ngunit ito ay
mataas na compute and memory requirements kaya nangangailangan ng mas mura pero
epektibong alternatibo. Ang papel na ito ay may tatlong kontribusyon. Una,
maglabas ng pre-trained AWD-LSTM language model sa wikang Filipino upang maging
tuntungan sa pagbuo ng mga NLP applications sa wikang Filipino. Pangalawa, mag
benchmark ng AWD-LSTM sa Hate Speech classification task at ipakita na kayang
nitong makipagsabayan sa mga transformer-based models. Pangatlo, suriin ang
performance ng AWD-LSTM sa low-resource setting gamit ang degradation test at
ikumpara ito sa mga transformer-based models.
</p>
<a href="http://arxiv.org/abs/2010.06447" target="_blank">arXiv:2010.06447</a> [<a href="http://arxiv.org/pdf/2010.06447" target="_blank">pdf</a>]

<h2>A first look into the carbon footprint of federated learning. (arXiv:2010.06537v2 [cs.LG] UPDATED)</h2>
<h3>Xinchi Qiu, Titouan Parcolle, Daniel J. Beutel, Taner Topal, Akhil Mathur, Nicholas D. Lane</h3>
<p>Despite impressive results, deep learning-based technologies also raise
severe privacy and environmental concerns induced by the training procedure
often conducted in data centers. In response, alternatives to centralized
training such as Federated Learning (FL) have emerged. Perhaps unexpectedly, FL
in particular is starting to be deployed at a global scale by companies that
must adhere to new legal demands and policies originating from governments and
the civil society for privacy protection. However, the potential environmental
impact related to FL remains unclear and unexplored. This paper offers the
first-ever systematic study of the carbon footprint of FL. First, we propose a
rigorous model to quantify the carbon footprint, hence facilitating the
investigation of the relationship between FL design and carbon emissions. Then,
we compare the carbon footprint of FL to traditional centralized learning. We
also formalize an early-stage FL optimization problem enabling the community to
consider the importance of optimizing the rate of CO$_2$ emissions jointly to
the accuracy of neural networks. Finally, we highlight and connect the reported
results to the future challenges and trends in FL to reduce its environmental
impact, including algorithms efficiency, hardware capabilities, and stronger
industry transparency.
</p>
<a href="http://arxiv.org/abs/2010.06537" target="_blank">arXiv:2010.06537</a> [<a href="http://arxiv.org/pdf/2010.06537" target="_blank">pdf</a>]

<h2>Controlling the Interaction Between Generation and Inference in Semi-Supervised Variational Autoencoders Using Importance Weighting. (arXiv:2010.06549v2 [cs.LG] UPDATED)</h2>
<h3>Ghazi Felhi, Joseph Leroux, Djam&#xe9; Seddah</h3>
<p>Even though Variational Autoencoders (VAEs) are widely used for
semi-supervised learning, the reason why they work remains unclear. In fact,
the addition of the unsupervised objective is most often vaguely described as a
regularization. The strength of this regularization is controlled by
down-weighting the objective on the unlabeled part of the training set. Through
an analysis of the objective of semi-supervised VAEs, we observe that they use
the posterior of the learned generative model to guide the inference model in
learning the partially observed latent variable. We show that given this
observation, it is possible to gain finer control on the effect of the
unsupervised objective on the training procedure. Using importance weighting,
we derive two novel objectives that prioritize either one of the partially
observed latent variable, or the unobserved latent variable. Experiments on the
IMDB english sentiment analysis dataset and on the AG News topic classification
dataset show the improvements brought by our prioritization mechanism and
exhibit a behavior that is inline with our description of the inner working of
Semi-Supervised VAEs.
</p>
<a href="http://arxiv.org/abs/2010.06549" target="_blank">arXiv:2010.06549</a> [<a href="http://arxiv.org/pdf/2010.06549" target="_blank">pdf</a>]

<h2>Grounded Language Learning Fast and Slow. (arXiv:2009.01719v4 [cs.CL] CROSS LISTED)</h2>
<h3>Felix Hill, Olivier Tieleman, Tamara von Glehn, Nathaniel Wong, Hamza Merzic, Stephen Clark</h3>
<p>Recent work has shown that large text-based neural language models, trained
with conventional supervised learning objectives, acquire a surprising
propensity for few- and one-shot learning. Here, we show that an embodied agent
situated in a simulated 3D world, and endowed with a novel dual-coding external
memory, can exhibit similar one-shot word learning when trained with
conventional reinforcement learning algorithms. After a single introduction to
a novel object via continuous visual perception and a language prompt ("This is
a dax"), the agent can re-identify the object and manipulate it as instructed
("Put the dax on the bed"). In doing so, it seamlessly integrates short-term,
within-episode knowledge of the appropriate referent for the word "dax" with
long-term lexical and motor knowledge acquired across episodes (i.e. "bed" and
"putting"). We find that, under certain training conditions and with a
particular memory writing mechanism, the agent's one-shot word-object binding
generalizes to novel exemplars within the same ShapeNet category, and is
effective in settings with unfamiliar numbers of objects. We further show how
dual-coding memory can be exploited as a signal for intrinsic motivation,
stimulating the agent to seek names for objects that may be useful for later
executing instructions. Together, the results demonstrate that deep neural
networks can exploit meta-learning, episodic memory and an explicitly
multi-modal environment to account for 'fast-mapping', a fundamental pillar of
human cognitive development and a potentially transformative capacity for
agents that interact with human users.
</p>
<a href="http://arxiv.org/abs/2009.01719" target="_blank">arXiv:2009.01719</a> [<a href="http://arxiv.org/pdf/2009.01719" target="_blank">pdf</a>]

<h2>The Kendall Interaction Filter for Variable Interaction Screening in Ultra High Dimensional Classification Problems. (arXiv:2010.06688v1 [stat.ME])</h2>
<h3>Youssef Anzarmou, Abdallah Mkhadri, Karim Oualkacha</h3>
<p>Accounting for important interaction effects can improve prediction of many
statistical learning models. Identification of relevant interactions, however,
is a challenging issue owing to their ultrahigh-dimensional nature. Interaction
screening strategies can alleviate such issues. However, due to heavier tail
distribution and complex dependence structure of interaction effects,
innovative robust and/or model-free methods for screening interactions are
required to better scale analysis of complex and high-throughput data. In this
work, we develop a new model-free interaction screening method, termed Kendall
Interaction Filter (KIF), for the classification in high-dimensional settings.
The KIF method suggests a weighted-sum measure, which compares the overall to
the within-cluster Kendall's $\tau$ of pairs of predictors, to select
interactive couples of features. The proposed KIF measure captures relevant
interactions for the clusters response-variable, handles continuous,
categorical or a mixture of continuous-categorical features, and is invariant
under monotonic transformations. We show that the KIF measure enjoys the sure
screening property in the high-dimensional setting under mild conditions,
without imposing sub-exponential moment assumptions on the features'
distributions. We illustrate the favorable behavior of the proposed methodology
compared to the methods in the same category using simulation studies, and we
conduct real data analyses to demonstrate its utility.
</p>
<a href="http://arxiv.org/abs/2010.06688" target="_blank">arXiv:2010.06688</a> [<a href="http://arxiv.org/pdf/2010.06688" target="_blank">pdf</a>]

<h2>Machine Learning Force Fields. (arXiv:2010.07067v1 [physics.chem-ph])</h2>
<h3>Oliver T. Unke, Stefan Chmiela, Huziel E. Sauceda, Michael Gastegger, Igor Poltavsky, Kristof T. Sch&#xfc;tt, Alexandre Tkatchenko, Klaus-Robert M&#xfc;ller</h3>
<p>In recent years, the use of Machine Learning (ML) in computational chemistry
has enabled numerous advances previously out of reach due to the computational
complexity of traditional electronic-structure methods. One of the most
promising applications is the construction of ML-based force fields (FFs), with
the aim to narrow the gap between the accuracy of ab initio methods and the
efficiency of classical FFs. The key idea is to learn the statistical relation
between chemical structure and potential energy without relying on a
preconceived notion of fixed chemical bonds or knowledge about the relevant
interactions. Such universal ML approximations are in principle only limited by
the quality and quantity of the reference data used to train them. This review
gives an overview of applications of ML-FFs and the chemical insights that can
be obtained from them. The core concepts underlying ML-FFs are described in
detail and a step-by-step guide for constructing and testing them from scratch
is given. The text concludes with a discussion of the challenges that remain to
be overcome by the next generation of ML-FFs.
</p>
<a href="http://arxiv.org/abs/2010.07067" target="_blank">arXiv:2010.07067</a> [<a href="http://arxiv.org/pdf/2010.07067" target="_blank">pdf</a>]

<h2>A Distribution-Free Test of Covariate Shift Using Conformal Prediction. (arXiv:2010.07147v1 [stat.ME])</h2>
<h3>Xiaoyu Hu, Jing Lei</h3>
<p>Covariate shift is a common and important assumption in transfer learning and
domain adaptation to treat the distributional difference between the training
and testing data. We propose a nonparametric test of covariate shift using the
conformal prediction framework. The construction of our test statistic combines
recent developments in conformal prediction with a novel choice of conformity
score, resulting in a valid and powerful test statistic under very general
settings. To our knowledge, this is the first successful attempt of using
conformal prediction for testing statistical hypotheses. Our method is suitable
for modern machine learning scenarios where the data has high dimensionality
and large sample sizes, and can be effectively combined with existing
classification algorithms to find good conformity score functions. The
performance of the proposed method is demonstrated in synthetic and real data
examples.
</p>
<a href="http://arxiv.org/abs/2010.07147" target="_blank">arXiv:2010.07147</a> [<a href="http://arxiv.org/pdf/2010.07147" target="_blank">pdf</a>]

<h2>A Groupwise Approach for Inferring Heterogeneous Treatment Effects in Causal Inference. (arXiv:1908.04427v2 [stat.ME] UPDATED)</h2>
<h3>Chan Park, Hyunseung Kang</h3>
<p>Recently, there has been great interest in estimating the conditional average
treatment effect using flexible machine learning methods. However, this
estimate is often difficult to interpret if covariates are high dimensional.
The paper propose a groupwise approach to study effect heterogeneity where the
conditional average treatment effect is partitioned into interpretable
subgroups. Our method is simple, only based on linear regression and sample
splitting, and is semiparametrically efficient under assumptions. We also
discuss ways to conduct multiple testing across different subgroups. We
conclude by reanalyzing a get-out-the-vote experiment during the 2014 U.S.
midterm elections.
</p>
<a href="http://arxiv.org/abs/1908.04427" target="_blank">arXiv:1908.04427</a> [<a href="http://arxiv.org/pdf/1908.04427" target="_blank">pdf</a>]

<h2>Unfolding recurrence by Green's functions for optimized reservoir computing. (arXiv:2010.06247v2 [cond-mat.dis-nn] UPDATED)</h2>
<h3>Sandra Nestler, Christian Keup, David Dahmen, Matthieu Gilson, Holger Rauhut, Moritz Helias</h3>
<p>Cortical networks are strongly recurrent, and neurons have intrinsic temporal
dynamics. This sets them apart from deep feed-forward networks. Despite the
tremendous progress in the application of feed-forward networks and their
theoretical understanding, it remains unclear how the interplay of recurrence
and non-linearities in recurrent cortical networks contributes to their
function. The purpose of this work is to present a solvable recurrent network
model that links to feed forward networks. By perturbative methods we transform
the time-continuous, recurrent dynamics into an effective feed-forward
structure of linear and non-linear temporal kernels. The resulting analytical
expressions allow us to build optimal time-series classifiers from random
reservoir networks. Firstly, this allows us to optimize not only the readout
vectors, but also the input projection, demonstrating a strong potential
performance gain. Secondly, the analysis exposes how the second order stimulus
statistics is a crucial element that interacts with the non-linearity of the
dynamics and boosts performance.
</p>
<a href="http://arxiv.org/abs/2010.06247" target="_blank">arXiv:2010.06247</a> [<a href="http://arxiv.org/pdf/2010.06247" target="_blank">pdf</a>]

