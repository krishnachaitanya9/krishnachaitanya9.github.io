---
title: Latest Deep Learning Papers
date: 2021-01-19 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (144 Articles)</h1>
<h2>Guided parallelized stochastic gradient descent for delay compensation. (arXiv:2101.07259v1 [cs.LG])</h2>
<h3>Anuraganand Sharma</h3>
<p>Stochastic gradient descent (SGD) algorithm and its variations have been
effectively used to optimize neural network models. However, with the rapid
growth of big data and deep learning, SGD is no longer the most suitable choice
due to its natural behavior of sequential optimization of the error function.
This has led to the development of parallel SGD algorithms, such as
asynchronous SGD (ASGD) and synchronous SGD (SSGD) to train deep neural
networks. However, it introduces a high variance due to the delay in parameter
(weight) update. We address this delay in our proposed algorithm and try to
minimize its impact. We employed guided SGD (gSGD) that encourages consistent
examples to steer the convergence by compensating the unpredictable deviation
caused by the delay. Its convergence rate is also similar to A/SSGD, however,
some additional (parallel) processing is required to compensate for the delay.
The experimental results demonstrate that our proposed approach has been able
to mitigate the impact of delay for the quality of classification accuracy. The
guided approach with SSGD clearly outperforms sequential SGD and even achieves
the accuracy close to sequential SGD for some benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2101.07259" target="_blank">arXiv:2101.07259</a> [<a href="http://arxiv.org/pdf/2101.07259" target="_blank">pdf</a>]

<h2>Does Continual Learning = Catastrophic Forgetting?. (arXiv:2101.07295v1 [cs.LG])</h2>
<h3>Anh Thai, Stefan Stojanov, Isaac Rehg, James M. Rehg</h3>
<p>Continual learning is known for suffering from catastrophic forgetting, a
phenomenon where earlier learned concepts are forgotten at the expense of more
recent samples. In this work, we challenge the assumption that continual
learning is inevitably associated with catastrophic forgetting by presenting a
set of tasks that surprisingly do not suffer from catastrophic forgetting when
learned continually. We attempt to provide an insight into the property of
these tasks that make them robust to catastrophic forgetting and the potential
of having a proxy representation learning task for continual classification. We
further introduce a novel yet simple algorithm, YASS that outperforms
state-of-the-art methods in the class-incremental categorization learning task.
Finally, we present DyRT, a novel tool for tracking the dynamics of
representation learning in continual models. The codebase, dataset and
pre-trained models released with this article can be found at
https://github.com/ngailapdi/CLRec.
</p>
<a href="http://arxiv.org/abs/2101.07295" target="_blank">arXiv:2101.07295</a> [<a href="http://arxiv.org/pdf/2101.07295" target="_blank">pdf</a>]

<h2>Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias. (arXiv:2101.07296v1 [cs.CV])</h2>
<h3>Stefan Stojanov, Anh Thai, James M. Rehg</h3>
<p>It is widely accepted that reasoning about object shape is important for
object recognition. However, the most powerful object recognition methods today
do not explicitly make use of object shape during learning. In this work,
motivated by recent developments in low-shot learning, findings in
developmental psychology, and the increased use of synthetic data in computer
vision research, we investigate how reasoning about 3D shape can be used to
improve low-shot learning methods' generalization performance. We propose a new
way to improve existing low-shot learning approaches by learning a
discriminative embedding space using 3D object shape, and utilizing this
embedding by learning how to map images into it. Our new approach improves the
performance of image-only low-shot learning approaches on multiple datasets. We
also develop Toys4K, a new 3D object dataset with the biggest number of object
categories that can also support low-shot learning.
</p>
<a href="http://arxiv.org/abs/2101.07296" target="_blank">arXiv:2101.07296</a> [<a href="http://arxiv.org/pdf/2101.07296" target="_blank">pdf</a>]

<h2>Diagnostic Captioning: A Survey. (arXiv:2101.07299v1 [cs.CV])</h2>
<h3>John Pavlopoulos, Vasiliki Kougia, Ion Androutsopoulos, Dimitris Papamichail</h3>
<p>Diagnostic Captioning (DC) concerns the automatic generation of a diagnostic
text from a set of medical images of a patient collected during an examination.
DC can assist inexperienced physicians, reducing clinical errors. It can also
help experienced physicians produce diagnostic reports faster. Following the
advances of deep learning, especially in generic image captioning, DC has
recently attracted more attention, leading to several systems and datasets.
This article is an extensive overview of DC. It presents relevant datasets,
evaluation measures, and up to date systems. It also highlights shortcomings
that hinder DC's progress and proposes future directions.
</p>
<a href="http://arxiv.org/abs/2101.07299" target="_blank">arXiv:2101.07299</a> [<a href="http://arxiv.org/pdf/2101.07299" target="_blank">pdf</a>]

<h2>Knowledge Distillation Methods for Efficient Unsupervised Adaptation Across Multiple Domains. (arXiv:2101.07308v1 [cs.CV])</h2>
<h3>Le Thanh Nguyen-Meidine, Atif Belal, Madhu Kiran, Jose Dolz, Louis-Antoine Blais-Morin, Eric Granger</h3>
<p>Beyond the complexity of CNNs that require training on large annotated
datasets, the domain shift between design and operational data has limited the
adoption of CNNs in many real-world applications. For instance, in person
re-identification, videos are captured over a distributed set of cameras with
non-overlapping viewpoints. The shift between the source (e.g. lab setting) and
target (e.g. cameras) domains may lead to a significant decline in recognition
accuracy. Additionally, state-of-the-art CNNs may not be suitable for such
real-time applications given their computational requirements. Although several
techniques have recently been proposed to address domain shift problems through
unsupervised domain adaptation (UDA), or to accelerate/compress CNNs through
knowledge distillation (KD), we seek to simultaneously adapt and compress CNNs
to generalize well across multiple target domains. In this paper, we propose a
progressive KD approach for unsupervised single-target DA (STDA) and
multi-target DA (MTDA) of CNNs. Our method for KD-STDA adapts a CNN to a single
target domain by distilling from a larger teacher CNN, trained on both target
and source domain data in order to maintain its consistency with a common
representation. Our proposed approach is compared against state-of-the-art
methods for compression and STDA of CNNs on the Office31 and ImageClef-DA image
classification datasets. It is also compared against state-of-the-art methods
for MTDA on Digits, Office31, and OfficeHome. In both settings -- KD-STDA and
KD-MTDA -- results indicate that our approach can achieve the highest level of
accuracy across target domains, while requiring a comparable or lower CNN
complexity.
</p>
<a href="http://arxiv.org/abs/2101.07308" target="_blank">arXiv:2101.07308</a> [<a href="http://arxiv.org/pdf/2101.07308" target="_blank">pdf</a>]

<h2>Benchmarking Perturbation-based Saliency Maps for Explaining Deep Reinforcement Learning Agents. (arXiv:2101.07312v1 [cs.LG])</h2>
<h3>Tobias Huber, Benedikt Limmer, Elisabeth Andr&#xe9;</h3>
<p>Recent years saw a plethora of work on explaining complex intelligent agents.
One example is the development of several algorithms that generate saliency
maps which show how much each pixel attributed to the agents' decision.
However, most evaluations of such saliency maps focus on image classification
tasks. As far as we know, there is no work which thoroughly compares different
saliency maps for Deep Reinforcement Learning agents. This paper compares four
perturbation-based approaches to create saliency maps for Deep Reinforcement
Learning agents trained on four different Atari 2600 games. All four approaches
work by perturbing parts of the input and measuring how much this affects the
agent's output. The approaches are compared using three computational metrics:
dependence on the learned parameters of the agent (sanity checks), faithfulness
to the agent's reasoning (input degradation), and run-time.
</p>
<a href="http://arxiv.org/abs/2101.07312" target="_blank">arXiv:2101.07312</a> [<a href="http://arxiv.org/pdf/2101.07312" target="_blank">pdf</a>]

<h2>Classification of Pedagogical content using conventional machine learning and deep learning model. (arXiv:2101.07321v1 [cs.AI])</h2>
<h3>Vedat Apuk, Krenare Pireva Nu&#xe7;i</h3>
<p>The advent of the Internet and a large number of digital technologies has
brought with it many different challenges. A large amount of data is found on
the web, which in most cases is unstructured and unorganized, and this
contributes to the fact that the use and manipulation of this data is quite a
difficult process. Due to this fact, the usage of different machine and deep
learning techniques for Text Classification has gained its importance, which
improved this discipline and made it more interesting for scientists and
researchers for further study. This paper aims to classify the pedagogical
content using two different models, the K-Nearest Neighbor (KNN) from the
conventional models and the Long short-term memory (LSTM) recurrent neural
network from the deep learning models. The result indicates that the accuracy
of classifying the pedagogical content reaches 92.52 % using KNN model and
87.71 % using LSTM model.
</p>
<a href="http://arxiv.org/abs/2101.07321" target="_blank">arXiv:2101.07321</a> [<a href="http://arxiv.org/pdf/2101.07321" target="_blank">pdf</a>]

<h2>Dissonance Between Human and Machine Understanding. (arXiv:2101.07337v1 [cs.AI])</h2>
<h3>Zijian Zhang, Jaspreet Singh, Ujwal Gadiraju, Avishek Anand</h3>
<p>Complex machine learning models are deployed in several critical domains
including healthcare and autonomous vehicles nowadays, albeit as functional
black boxes. Consequently, there has been a recent surge in interpreting
decisions of such complex models in order to explain their actions to humans.
Models that correspond to human interpretation of a task are more desirable in
certain contexts and can help attribute liability, build trust, expose biases
and in turn build better models. It is, therefore, crucial to understand how
and which models conform to human understanding of tasks. In this paper, we
present a large-scale crowdsourcing study that reveals and quantifies the
dissonance between human and machine understanding, through the lens of an
image classification task. In particular, we seek to answer the following
questions: Which (well-performing) complex ML models are closer to humans in
their use of features to make accurate predictions? How does task difficulty
affect the feature selection capability of machines in comparison to humans?
Are humans consistently better at selecting features that make image
recognition more accurate? Our findings have important implications on
human-machine collaboration, considering that a long term goal in the field of
artificial intelligence is to make machines capable of learning and reasoning
like humans.
</p>
<a href="http://arxiv.org/abs/2101.07337" target="_blank">arXiv:2101.07337</a> [<a href="http://arxiv.org/pdf/2101.07337" target="_blank">pdf</a>]

<h2>Improving Makeup Face Verification by Exploring Part-Based Representations. (arXiv:2101.07338v1 [cs.CV])</h2>
<h3>Marcus de Assis Angeloni, Helio Pedrini</h3>
<p>Recently, we have seen an increase in the global facial recognition market
size. Despite significant advances in face recognition technology with the
adoption of convolutional neural networks, there are still open challenges, as
when there is makeup in the face. To address this challenge, we propose and
evaluate the adoption of facial parts to fuse with current holistic
representations. We propose two strategies of facial parts: one with four
regions (left periocular, right periocular, nose and mouth) and another with
three facial thirds (upper, middle and lower). Experimental results obtained in
four public makeup face datasets and in a challenging cross-dataset protocol
show that the fusion of deep features extracted of facial parts with holistic
representation increases the accuracy of face verification systems and
decreases the error rates, even without any retraining of the CNN models. Our
proposed pipeline achieved state-of-the-art performance for the YMU dataset and
competitive results for other three datasets (EMFD, FAM and M501).
</p>
<a href="http://arxiv.org/abs/2101.07338" target="_blank">arXiv:2101.07338</a> [<a href="http://arxiv.org/pdf/2101.07338" target="_blank">pdf</a>]

<h2>Accelerating Deep Learning Inference via Learned Caches. (arXiv:2101.07344v1 [cs.LG])</h2>
<h3>Arjun Balasubramanian, Adarsh Kumar, Yuhan Liu, Han Cao, Shivaram Venkataraman, Aditya Akella</h3>
<p>Deep Neural Networks (DNNs) are witnessing increased adoption in multiple
domains owing to their high accuracy in solving real-world problems. However,
this high accuracy has been achieved by building deeper networks, posing a
fundamental challenge to the low latency inference desired by user-facing
applications. Current low latency solutions trade-off on accuracy or fail to
exploit the inherent temporal locality in prediction serving workloads.

We observe that caching hidden layer outputs of the DNN can introduce a form
of late-binding where inference requests only consume the amount of computation
needed. This enables a mechanism for achieving low latencies, coupled with an
ability to exploit temporal locality. However, traditional caching approaches
incur high memory overheads and lookup latencies, leading us to design learned
caches - caches that consist of simple ML models that are continuously updated.
We present the design of GATI, an end-to-end prediction serving system that
incorporates learned caches for low-latency DNN inference. Results show that
GATI can reduce inference latency by up to 7.69X on realistic workloads.
</p>
<a href="http://arxiv.org/abs/2101.07344" target="_blank">arXiv:2101.07344</a> [<a href="http://arxiv.org/pdf/2101.07344" target="_blank">pdf</a>]

<h2>Object Detection and Pose Estimation from RGB and Depth Data for Real-time, Adaptive Robotic Grasping. (arXiv:2101.07347v1 [cs.RO])</h2>
<h3>S. K. Paul, M. T. Chowdhury, M. Nicolescu, M. Nicolescu</h3>
<p>In recent times, object detection and pose estimation have gained significant
attention in the context of robotic vision applications. Both the
identification of objects of interest as well as the estimation of their pose
remain important capabilities in order for robots to provide effective
assistance for numerous robotic applications ranging from household tasks to
industrial manipulation. This problem is particularly challenging because of
the heterogeneity of objects having different and potentially complex shapes,
and the difficulties arising due to background clutter and partial occlusions
between objects. As the main contribution of this work, we propose a system
that performs real-time object detection and pose estimation, for the purpose
of dynamic robot grasping. The robot has been pre-trained to perform a small
set of canonical grasps from a few fixed poses for each object. When presented
with an unknown object in an arbitrary pose, the proposed approach allows the
robot to detect the object identity and its actual pose, and then adapt a
canonical grasp in order to be used with the new pose. For training, the system
defines a canonical grasp by capturing the relative pose of an object with
respect to the gripper attached to the robot's wrist. During testing, once a
new pose is detected, a canonical grasp for the object is identified and then
dynamically adapted by adjusting the robot arm's joint angles, so that the
gripper can grasp the object in its new pose. We conducted experiments using a
humanoid PR2 robot and showed that the proposed framework can detect
well-textured objects, and provide accurate pose estimation in the presence of
tolerable amounts of out-of-plane rotation. The performance is also illustrated
by the robot successfully grasping objects from a wide range of arbitrary
poses.
</p>
<a href="http://arxiv.org/abs/2101.07347" target="_blank">arXiv:2101.07347</a> [<a href="http://arxiv.org/pdf/2101.07347" target="_blank">pdf</a>]

<h2>Consistency of random-walk based network embedding algorithms. (arXiv:2101.07354v1 [stat.ML])</h2>
<h3>Yichi Zhang, Minh Tang</h3>
<p>Random-walk based network embedding algorithms like node2vec and DeepWalk are
widely used to obtain Euclidean representation of the nodes in a network prior
to performing down-stream network inference tasks. Nevertheless, despite their
impressive empirical performance, there is a lack of theoretical results
explaining their behavior. In this paper we studied the node2vec and DeepWalk
algorithms through the perspective of matrix factorization. We analyze these
algorithms in the setting of community detection for stochastic blockmodel
graphs; in particular we established large-sample error bounds and prove
consistent community recovery of node2vec/DeepWalk embedding followed by
k-means clustering. Our theoretical results indicate a subtle interplay between
the sparsity of the observed networks, the window sizes of the random walks,
and the convergence rates of the node2vec/DeepWalk embedding toward the
embedding of the true but unknown edge probabilities matrix. More specifically,
as the network becomes sparser, our results suggest using larger window sizes,
or equivalently, taking longer random walks, in order to attain better
convergence rate for the resulting embeddings. The paper includes numerical
experiments corroborating these observations.
</p>
<a href="http://arxiv.org/abs/2101.07354" target="_blank">arXiv:2101.07354</a> [<a href="http://arxiv.org/pdf/2101.07354" target="_blank">pdf</a>]

<h2>Handling Non-ignorably Missing Features in Electronic Health Records Data Using Importance-Weighted Autoencoders. (arXiv:2101.07357v1 [cs.LG])</h2>
<h3>David K. Lim, Naim U. Rashid, Junier B. Oliva, Joseph G. Ibrahim</h3>
<p>Electronic Health Records (EHRs) are commonly used to investigate
relationships between patient health information and outcomes. Deep learning
methods are emerging as powerful tools to learn such relationships, given the
characteristic high dimension and large sample size of EHR datasets. The
Physionet 2012 Challenge involves an EHR dataset pertaining to 12,000 ICU
patients, where researchers investigated the relationships between clinical
measurements, and in-hospital mortality. However, the prevalence and complexity
of missing data in the Physionet data present significant challenges for the
application of deep learning methods, such as Variational Autoencoders (VAEs).
Although a rich literature exists regarding the treatment of missing data in
traditional statistical models, it is unclear how this extends to deep learning
architectures. To address these issues, we propose a novel extension of VAEs
called Importance-Weighted Autoencoders (IWAEs) to flexibly handle Missing Not
At Random (MNAR) patterns in the Physionet data. Our proposed method models the
missingness mechanism using an embedded neural network, eliminating the need to
specify the exact form of the missingness mechanism a priori. We show that the
use of our method leads to more realistic imputed values relative to the
state-of-the-art, as well as significant differences in fitted downstream
models for mortality.
</p>
<a href="http://arxiv.org/abs/2101.07357" target="_blank">arXiv:2101.07357</a> [<a href="http://arxiv.org/pdf/2101.07357" target="_blank">pdf</a>]

<h2>Through the Data Management Lens: Experimental Analysis and Evaluation of Fair Classification. (arXiv:2101.07361v1 [cs.LG])</h2>
<h3>Maliha Tashfia Islam, Anna Fariha, Alexandra Meliou</h3>
<p>Classification, a heavily-studied data-driven machine learning task, drives
an increasing number of prediction systems involving critical human decisions
such as loan approval and criminal risk assessment. However, classifiers often
demonstrate discriminatory behavior, especially when presented with biased
data. Consequently, fairness in classification has emerged as a high-priority
research area. Data management research is showing an increasing presence and
interest in topics related to data and algorithmic fairness, including the
topic of fair classification. The interdisciplinary efforts in fair
classification, with machine learning research having the largest presence,
have resulted in a large number of fairness notions and a wide range of
approaches that have not been systematically evaluated and compared. In this
paper, we contribute a broad analysis of 13 fair classification approaches and
additional variants, over their correctness, fairness, efficiency, scalability,
and stability, using a variety of metrics and real-world datasets. Our analysis
highlights novel insights on the impact of different metrics and high-level
approach characteristics on different aspects of performance. We also discuss
general principles for choosing approaches suitable for different practical
settings, and identify areas where data-management-centric solutions are likely
to have the most impact.
</p>
<a href="http://arxiv.org/abs/2101.07361" target="_blank">arXiv:2101.07361</a> [<a href="http://arxiv.org/pdf/2101.07361" target="_blank">pdf</a>]

<h2>Training Learned Optimizers with Randomly Initialized Learned Optimizers. (arXiv:2101.07367v1 [cs.LG])</h2>
<h3>Luke Metz, C. Daniel Freeman, Niru Maheswaranathan, Jascha Sohl-Dickstein</h3>
<p>Learned optimizers are increasingly effective, with performance exceeding
that of hand designed optimizers such as Adam~\citep{kingma2014adam} on
specific tasks \citep{metz2019understanding}. Despite the potential gains
available, in current work the meta-training (or `outer-training') of the
learned optimizer is performed by a hand-designed optimizer, or by an optimizer
trained by a hand-designed optimizer \citep{metz2020tasks}. We show that a
population of randomly initialized learned optimizers can be used to train
themselves from scratch in an online fashion, without resorting to a hand
designed optimizer in any part of the process. A form of population based
training is used to orchestrate this self-training. Although the randomly
initialized optimizers initially make slow progress, as they improve they
experience a positive feedback loop, and become rapidly more effective at
training themselves. We believe feedback loops of this type, where an optimizer
improves itself, will be important and powerful in the future of machine
learning. These methods not only provide a path towards increased performance,
but more importantly relieve research and engineering effort.
</p>
<a href="http://arxiv.org/abs/2101.07367" target="_blank">arXiv:2101.07367</a> [<a href="http://arxiv.org/pdf/2101.07367" target="_blank">pdf</a>]

<h2>Text line extraction using fully convolutional network and energy minimization. (arXiv:2101.07370v1 [cs.CV])</h2>
<h3>Berat Kurar Barakat, Ahmad Droby, Reem Alaasam, Boraq Madi, Irina Rabaev, Jihad El-Sana</h3>
<p>Text lines are important parts of handwritten document images and easier to
analyze by further applications. Despite recent progress in text line
detection, text line extraction from a handwritten document remains an unsolved
task. This paper proposes to use a fully convolutional network for text line
detection and energy minimization for text line extraction. Detected text lines
are represented by blob lines that strike through the text lines. These blob
lines assist an energy function for text line extraction. The detection stage
can locate arbitrarily oriented text lines. Furthermore, the extraction stage
is capable of finding out the pixels of text lines with various heights and
interline proximity independent of their orientations. Besides, it can finely
split the touching and overlapping text lines without an orientation
assumption. We evaluate the proposed method on VML-AHTE, VML-MOC, and
Diva-HisDB datasets. The VML-AHTE dataset contains overlapping, touching and
close text lines with rich diacritics. The VML-MOC dataset is very challenging
by its multiply oriented and skewed text lines. The Diva-HisDB dataset exhibits
distinct text line heights and touching text lines. The results demonstrate the
effectiveness of the method despite various types of challenges, yet using the
same parameters in all the experiments.
</p>
<a href="http://arxiv.org/abs/2101.07370" target="_blank">arXiv:2101.07370</a> [<a href="http://arxiv.org/pdf/2101.07370" target="_blank">pdf</a>]

<h2>A DCNN-based Arbitrarily-Oriented Object Detector for Quality Control and Inspection Application. (arXiv:2101.07383v1 [cs.CV])</h2>
<h3>Kai Yao, Alberto Ortiz, Francisco Bonnin-Pascual</h3>
<p>Following the success of machine vision systems for on-line automated quality
control and inspection processes, an object recognition solution is presented
in this work for two different specific applications, i.e., the detection of
quality control items in surgery toolboxes prepared for sterilizing in a
hospital, as well as the detection of defects in vessel hulls to prevent
potential structural failures. The solution has two stages. First, a feature
pyramid architecture based on Single Shot MultiBox Detector (SSD) is used to
improve the detection performance, and a statistical analysis based on ground
truth is employed to select parameters of a range of default boxes. Second, a
lightweight neural network is exploited to achieve oriented detection results
using a regression method. The first stage of the proposed method is capable of
detecting the small targets considered in the two scenarios. In the second
stage, despite the simplicity, it is efficient to detect elongated targets
while maintaining high running efficiency.
</p>
<a href="http://arxiv.org/abs/2101.07383" target="_blank">arXiv:2101.07383</a> [<a href="http://arxiv.org/pdf/2101.07383" target="_blank">pdf</a>]

<h2>Galaxy Image Translation with Semi-supervised Noise-reconstructed Generative Adversarial Networks. (arXiv:2101.07389v1 [cs.CV])</h2>
<h3>Qiufan Lin, Dominique Fouchez, J&#xe9;r&#xf4;me Pasquet</h3>
<p>Image-to-image translation with Deep Learning neural networks, particularly
with Generative Adversarial Networks (GANs), is one of the most powerful
methods for simulating astronomical images. However, current work is limited to
utilizing paired images with supervised translation, and there has been rare
discussion on reconstructing noise background that encodes instrumental and
observational effects. These limitations might be harmful for subsequent
scientific applications in astrophysics. Therefore, we aim to develop methods
for using unpaired images and preserving noise characteristics in image
translation. In this work, we propose a two-way image translation model using
GANs that exploits both paired and unpaired images in a semi-supervised manner,
and introduce a noise emulating module that is able to learn and reconstruct
noise characterized by high-frequency features. By experimenting on multi-band
galaxy images from the Sloan Digital Sky Survey (SDSS) and the Canada France
Hawaii Telescope Legacy Survey (CFHT), we show that our method recovers global
and local properties effectively and outperforms benchmark image translation
models. To our best knowledge, this work is the first attempt to apply
semi-supervised methods and noise reconstruction techniques in astrophysical
studies.
</p>
<a href="http://arxiv.org/abs/2101.07389" target="_blank">arXiv:2101.07389</a> [<a href="http://arxiv.org/pdf/2101.07389" target="_blank">pdf</a>]

<h2>ArtEmis: Affective Language for Visual Art. (arXiv:2101.07396v1 [cs.CV])</h2>
<h3>Panos Achlioptas, Maks Ovsjanikov, Kilichbek Haydarov, Mohamed Elhoseiny, Leonidas Guibas</h3>
<p>We present a novel large-scale dataset and accompanying machine learning
models aimed at providing a detailed understanding of the interplay between
visual content, its emotional effect, and explanations for the latter in
language. In contrast to most existing annotation datasets in computer vision,
we focus on the affective experience triggered by visual artworks and ask the
annotators to indicate the dominant emotion they feel for a given image and,
crucially, to also provide a grounded verbal explanation for their emotion
choice. As we demonstrate below, this leads to a rich set of signals for both
the objective content and the affective impact of an image, creating
associations with abstract concepts (e.g., "freedom" or "love"), or references
that go beyond what is directly visible, including visual similes and
metaphors, or subjective references to personal experiences. We focus on visual
art (e.g., paintings, artistic photographs) as it is a prime example of imagery
created to elicit emotional responses from its viewers. Our dataset, termed
ArtEmis, contains 439K emotion attributions and explanations from humans, on
81K artworks from WikiArt. Building on this data, we train and demonstrate a
series of captioning systems capable of expressing and explaining emotions from
visual stimuli. Remarkably, the captions produced by these systems often
succeed in reflecting the semantic and abstract content of the image, going
well beyond systems trained on existing datasets. The collected dataset and
developed methods are available at https://artemisdataset.org.
</p>
<a href="http://arxiv.org/abs/2101.07396" target="_blank">arXiv:2101.07396</a> [<a href="http://arxiv.org/pdf/2101.07396" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning Optimizes Graphene Nanopores for Efficient Desalination. (arXiv:2101.07399v1 [cs.LG])</h2>
<h3>Yuyang Wang, Zhonglin Cao, Amir Barati Farimani</h3>
<p>Two-dimensional nanomaterials, such as graphene, have been extensively
studied because of their outstanding physical properties. Structure and
geometry optimization of nanopores on such materials is beneficial for their
performances in real-world engineering applications, like water desalination.
However, the optimization process often involves very large number of
experiments or simulations which are expensive and time-consuming. In this
work, we propose a graphene nanopore optimization framework via the combination
of deep reinforcement learning (DRL) and convolutional neural network (CNN) for
efficient water desalination. The DRL agent controls the growth of nanopore by
determining the atom to be removed at each timestep, while the CNN predicts the
performance of nanoporus graphene for water desalination: the water flux and
ion rejection at a certain external pressure. With the synchronous feedback
from CNN-accelerated desalination performance prediction, our DRL agent can
optimize the nanoporous graphene efficiently in an online manner. Molecular
dynamics (MD) simulations on promising DRL-designed graphene nanopores show
that they have higher water flux while maintaining rival ion rejection rate
compared to the normal circular nanopores. Semi-oval shape with rough edges
geometry of DRL-designed pores is found to be the key factor for their high
water desalination performance. Ultimately, this study shows that DRL can be a
powerful tool for material design.
</p>
<a href="http://arxiv.org/abs/2101.07399" target="_blank">arXiv:2101.07399</a> [<a href="http://arxiv.org/pdf/2101.07399" target="_blank">pdf</a>]

<h2>Initialization Using Perlin Noise for Training Networks with a Limited Amount of Data. (arXiv:2101.07406v1 [cs.CV])</h2>
<h3>Nakamasa Inoue, Eisuke Yamagata, Hirokatsu Kataoka</h3>
<p>We propose a novel network initialization method using Perlin noise for
training image classification networks with a limited amount of data. Our main
idea is to initialize the network parameters by solving an artificial noise
classification problem, where the aim is to classify Perlin noise samples into
their noise categories. Specifically, the proposed method consists of two
steps. First, it generates Perlin noise samples with category labels defined
based on noise complexity. Second, it solves a classification problem, in which
network parameters are optimized to classify the generated noise samples. This
method produces a reasonable set of initial weights (filters) for image
classification. To the best of our knowledge, this is the first work to
initialize networks by solving an artificial optimization problem without using
any real-world images. Our experiments show that the proposed method
outperforms conventional initialization methods on four image classification
datasets.
</p>
<a href="http://arxiv.org/abs/2101.07406" target="_blank">arXiv:2101.07406</a> [<a href="http://arxiv.org/pdf/2101.07406" target="_blank">pdf</a>]

<h2>On Dynamic Noise Influence in Differentially Private Learning. (arXiv:2101.07413v1 [cs.LG])</h2>
<h3>Junyuan Hong, Zhangyang Wang, Jiayu Zhou</h3>
<p>Protecting privacy in learning while maintaining the model performance has
become increasingly critical in many applications that involve sensitive data.
Private Gradient Descent (PGD) is a commonly used private learning framework,
which noises gradients based on the Differential Privacy protocol. Recent
studies show that \emph{dynamic privacy schedules} of decreasing noise
magnitudes can improve loss at the final iteration, and yet theoretical
understandings of the effectiveness of such schedules and their connections to
optimization algorithms remain limited. In this paper, we provide comprehensive
analysis of noise influence in dynamic privacy schedules to answer these
critical questions. We first present a dynamic noise schedule minimizing the
utility upper bound of PGD, and show how the noise influence from each
optimization step collectively impacts utility of the final model. Our study
also reveals how impacts from dynamic noise influence change when momentum is
used. We empirically show the connection exists for general non-convex losses,
and the influence is greatly impacted by the loss curvature.
</p>
<a href="http://arxiv.org/abs/2101.07413" target="_blank">arXiv:2101.07413</a> [<a href="http://arxiv.org/pdf/2101.07413" target="_blank">pdf</a>]

<h2>ES-ENAS: Combining Evolution Strategies with Neural Architecture Search at No Extra Cost for Reinforcement Learning. (arXiv:2101.07415v1 [cs.LG])</h2>
<h3>Xingyou Song, Krzysztof Choromanski, Jack Parker-Holder, Yunhao Tang, Daiyi Peng, Deepali Jain, Wenbo Gao, Aldo Pacchiano, Tamas Sarlos, Yuxiang Yang</h3>
<p>We introduce ES-ENAS, a simple neural architecture search (NAS) algorithm for
the purpose of reinforcement learning (RL) policy design, by combining
Evolutionary Strategies (ES) and Efficient NAS (ENAS) in a highly scalable and
intuitive way. Our main insight is noticing that ES is already a distributed
blackbox algorithm, and thus we may simply insert a model controller from ENAS
into the central aggregator in ES and obtain weight sharing properties for
free. By doing so, we bridge the gap from NAS research in supervised learning
settings to the reinforcement learning scenario through this relatively simple
marriage between two different lines of research, and are one of the first to
apply controller-based NAS techniques to RL. We demonstrate the utility of our
method by training combinatorial neural network architectures for RL problems
in continuous control, via edge pruning and weight sharing. We also incorporate
a wide variety of popular techniques from modern NAS literature, including
multiobjective optimization and varying controller methods, to showcase their
promise in the RL field and discuss possible extensions. We achieve &gt;90%
network compression for multiple tasks, which may be special interest in mobile
robotics with limited storage and computational resources.
</p>
<a href="http://arxiv.org/abs/2101.07415" target="_blank">arXiv:2101.07415</a> [<a href="http://arxiv.org/pdf/2101.07415" target="_blank">pdf</a>]

<h2>Swarm Herding: A Leader-Follower Framework For Multi-Robot Navigation. (arXiv:2101.07416v1 [cs.RO])</h2>
<h3>Xiaotian Xu, Yancy Diaz-Mercado</h3>
<p>A leader-follower framework is proposed for multi-robot navigation of large
scale teams where the leader agents corral the follower agents. A group of
leaders is modeled as a 2D deformable object where discrete masses (i.e.,
leader robots) are interconnected by springs and dampers. A time-varying domain
is defined by the positions of leaders while the external forces induce
deformations of the domain from its nominal configuration. The team of
followers is performing coverage over the time-varying domain by employing a
perspective transformation that maps between the nominal and deformed
configurations. A decentralized control strategy is proposed where a leader
only takes local sensing information and information about its neighbors
(connected by virtual springs and dampers), and a follower only needs partial
information about leaders and information about its Delaunay neighbors.
</p>
<a href="http://arxiv.org/abs/2101.07416" target="_blank">arXiv:2101.07416</a> [<a href="http://arxiv.org/pdf/2101.07416" target="_blank">pdf</a>]

<h2>GIID-Net: Generalizable Image Inpainting Detection via Neural Architecture Search and Attention. (arXiv:2101.07419v1 [cs.CV])</h2>
<h3>Haiwei Wu, Jiantao Zhou</h3>
<p>Deep learning (DL) has demonstrated its powerful capabilities in the field of
image inpainting, which could produce visually plausible results. Meanwhile,
the malicious use of advanced image inpainting tools (e.g. removing key objects
to report fake news) has led to increasing threats to the reliability of image
data. To fight against the inpainting forgeries, in this work, we propose a
novel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),
to detect the inpainted regions at pixel accuracy. The proposed GIID-Net
consists of three sub-blocks: the enhancement block, the extraction block and
the decision block. Specifically, the enhancement block aims to enhance the
inpainting traces by using hierarchically combined special layers. The
extraction block, automatically designed by Neural Architecture Search (NAS)
algorithm, is targeted to extract features for the actual inpainting detection
tasks. In order to further optimize the extracted latent features, we integrate
global and local attention modules in the decision block, where the global
attention reduces the intra-class differences by measuring the similarity of
global features, while the local attention strengthens the consistency of local
features. Furthermore, we thoroughly study the generalizability of our
GIID-Net, and find that different training data could result in vastly
different generalization capability. Extensive experimental results are
presented to validate the superiority of the proposed GIID-Net, compared with
the state-of-the-art competitors. Our results would suggest that common
artifacts are shared across diverse image inpainting methods. Finally, we build
a public inpainting dataset of 10K image pairs for the future research in this
area.
</p>
<a href="http://arxiv.org/abs/2101.07419" target="_blank">arXiv:2101.07419</a> [<a href="http://arxiv.org/pdf/2101.07419" target="_blank">pdf</a>]

<h2>SOSD-Net: Joint Semantic Object Segmentation and Depth Estimation from Monocular images. (arXiv:2101.07422v1 [cs.CV])</h2>
<h3>Lei He, Jiwen Lu, Guanghui Wang, Shiyu Song, Jie Zhou</h3>
<p>Depth estimation and semantic segmentation play essential roles in scene
understanding. The state-of-the-art methods employ multi-task learning to
simultaneously learn models for these two tasks at the pixel-wise level. They
usually focus on sharing the common features or stitching feature maps from the
corresponding branches. However, these methods lack in-depth consideration on
the correlation of the geometric cues and the scene parsing. In this paper, we
first introduce the concept of semantic objectness to exploit the geometric
relationship of these two tasks through an analysis of the imaging process,
then propose a Semantic Object Segmentation and Depth Estimation Network
(SOSD-Net) based on the objectness assumption. To the best of our knowledge,
SOSD-Net is the first network that exploits the geometry constraint for
simultaneous monocular depth estimation and semantic segmentation. In addition,
considering the mutual implicit relationship between these two tasks, we
exploit the iterative idea from the expectation-maximization algorithm to train
the proposed network more effectively. Extensive experimental results on the
Cityscapes and NYU v2 dataset are presented to demonstrate the superior
performance of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.07422" target="_blank">arXiv:2101.07422</a> [<a href="http://arxiv.org/pdf/2101.07422" target="_blank">pdf</a>]

<h2>Submodular Maximization via Taylor Series Approximation. (arXiv:2101.07423v1 [cs.LG])</h2>
<h3>G&#xf6;zde &#xd6;zcan, Armin Moharrer, Stratis Ioannidis</h3>
<p>We study submodular maximization problems with matroid constraints, in
particular, problems where the objective can be expressed via compositions of
analytic and multilinear functions. We show that for functions of this form,
the so-called continuous greedy algorithm attains a ratio arbitrarily close to
$(1-1/e) \approx 0.63$ using a deterministic estimation via Taylor series
approximation. This drastically reduces execution time over prior art that uses
sampling.
</p>
<a href="http://arxiv.org/abs/2101.07423" target="_blank">arXiv:2101.07423</a> [<a href="http://arxiv.org/pdf/2101.07423" target="_blank">pdf</a>]

<h2>Dynamic Planning of Bicycle Stations in Dockless Public Bicycle-sharing System Using Gated Graph Neural Network. (arXiv:2101.07425v1 [cs.LG])</h2>
<h3>Jianguo Chen, Kenli Li, Keqin Li, Philip S. Yu, Zeng Zeng</h3>
<p>Benefiting from convenient cycling and flexible parking locations, the
Dockless Public Bicycle-sharing (DL-PBS) network becomes increasingly popular
in many countries. However, redundant and low-utility stations waste public
urban space and maintenance costs of DL-PBS vendors. In this paper, we propose
a Bicycle Station Dynamic Planning (BSDP) system to dynamically provide the
optimal bicycle station layout for the DL-PBS network. The BSDP system contains
four modules: bicycle drop-off location clustering, bicycle-station graph
modeling, bicycle-station location prediction, and bicycle-station layout
recommendation. In the bicycle drop-off location clustering module, candidate
bicycle stations are clustered from each spatio-temporal subset of the
large-scale cycling trajectory records. In the bicycle-station graph modeling
module, a weighted digraph model is built based on the clustering results and
inferior stations with low station revenue and utility are filtered. Then,
graph models across time periods are combined to create a graph sequence model.
In the bicycle-station location prediction module, the GGNN model is used to
train the graph sequence data and dynamically predict bicycle stations in the
next period. In the bicycle-station layout recommendation module, the predicted
bicycle stations are fine-tuned according to the government urban management
plan, which ensures that the recommended station layout is conducive to city
management, vendor revenue, and user convenience. Experiments on actual DL-PBS
networks verify the effectiveness, accuracy and feasibility of the proposed
BSDP system.
</p>
<a href="http://arxiv.org/abs/2101.07425" target="_blank">arXiv:2101.07425</a> [<a href="http://arxiv.org/pdf/2101.07425" target="_blank">pdf</a>]

<h2>CAA : Channelized Axial Attention for Semantic Segmentation. (arXiv:2101.07434v1 [cs.CV])</h2>
<h3>Ye Huang, Wenjing Jia, Xiangjian He, Liu Liu, Yuxin Li, Dacheng Tao</h3>
<p>Self-attention and channel attention, modelling the semantic
interdependencies in spatial and channel dimensions respectively, have recently
been widely used for semantic segmentation. However, computing self-attention
and channel attention separately and then fusing them directly can cause
conflicting feature representations. In this paper, we propose the Channelized
Axial Attention (CAA) to seamlessly integrate channel attention and axial
attention with reduced computational complexity. After computing axial
attention maps, we propose to channelize the intermediate results obtained from
the transposed dot-product so that the channel importance of each axial
representation is optimized across the whole receptive field. We further
develop grouped vectorization, which allows our model to be run in the very
limited GPU memory with a speed comparable with full vectorization. Comparative
experiments conducted on multiple benchmark datasets, including Cityscapes,
PASCAL Context and COCO-Stuff, demonstrate that our CAA not only requires much
less computation resources but also outperforms the state-of-the-art
segmentation models based on ResNet-101 on all tested datasets.
</p>
<a href="http://arxiv.org/abs/2101.07434" target="_blank">arXiv:2101.07434</a> [<a href="http://arxiv.org/pdf/2101.07434" target="_blank">pdf</a>]

<h2>Dynamic Bicycle Dispatching of Dockless Public Bicycle-sharing Systems using Multi-objective Reinforcement Learning. (arXiv:2101.07437v1 [cs.AI])</h2>
<h3>Jianguo Chen, Kenli Li, Keqin Li, Philip S. Yu, Zeng Zeng</h3>
<p>As a new generation of Public Bicycle-sharing Systems (PBS), the dockless PBS
(DL-PBS) is an important application of cyber-physical systems and intelligent
transportation. How to use AI to provide efficient bicycle dispatching
solutions based on dynamic bicycle rental demand is an essential issue for
DL-PBS. In this paper, we propose a dynamic bicycle dispatching algorithm based
on multi-objective reinforcement learning (MORL-BD) to provide the optimal
bicycle dispatching solution for DL-PBS. We model the DL-PBS system from the
perspective of CPS and use deep learning to predict the layout of bicycle
parking spots and the dynamic demand of bicycle dispatching. We define the
multi-route bicycle dispatching problem as a multi-objective optimization
problem by considering the optimization objectives of dispatching costs,
dispatch truck's initial load, workload balance among the trucks, and the
dynamic balance of bicycle supply and demand. On this basis, the collaborative
multi-route bicycle dispatching problem among multiple dispatch trucks is
modeled as a multi-agent MORL model. All dispatch paths between parking spots
are defined as state spaces, and the reciprocal of dispatching costs is defined
as a reward. Each dispatch truck is equipped with an agent to learn the optimal
dispatch path in the dynamic DL-PBS network. We create an elite list to store
the Pareto optimal solutions of bicycle dispatch paths found in each action,
and finally, get the Pareto frontier. Experimental results on the actual DL-PBS
systems show that compared with existing methods, MORL-BD can find a higher
quality Pareto frontier with less execution time.
</p>
<a href="http://arxiv.org/abs/2101.07437" target="_blank">arXiv:2101.07437</a> [<a href="http://arxiv.org/pdf/2101.07437" target="_blank">pdf</a>]

<h2>Fast Convergence of DETR with Spatially Modulated Co-Attention. (arXiv:2101.07448v1 [cs.CV])</h2>
<h3>Peng Gao, Minghang Zheng, Xiaogang Wang, Jifeng Dai, Hongsheng Li</h3>
<p>The recently proposed Detection Transformer (DETR) model successfully applies
Transformer to objects detection and achieves comparable performance with
two-stage object detection frameworks, such as Faster-RCNN. However, DETR
suffers from its slow convergence. Training DETR \cite{carion2020end} from
scratch needs 500 epochs to achieve a high accuracy. To accelerate its
convergence, we propose a simple yet effective scheme for improving the DETR
framework, namely Spatially Modulated Co-Attention (SMCA) mechanism. The core
idea of SMCA is to conduct regression-aware co-attention in DETR by
constraining co-attention responses to be high near initially estimated
bounding box locations. Our proposed SMCA increases DETR's convergence speed by
replacing the original co-attention mechanism in the decoder while keeping
other operations in DETR unchanged. Furthermore, by integrating multi-head and
scale-selection attention designs into SMCA, our fully-fledged SMCA can achieve
better performance compared to DETR with a dilated convolution-based backbone
(45.6 mAP at 108 epochs vs. 43.3 mAP at 500 epochs). We perform extensive
ablation studies on COCO dataset to validate the effectiveness of the proposed
SMCA.
</p>
<a href="http://arxiv.org/abs/2101.07448" target="_blank">arXiv:2101.07448</a> [<a href="http://arxiv.org/pdf/2101.07448" target="_blank">pdf</a>]

<h2>Hybrid Trilinear and Bilinear Programming for Aligning Partially Overlapping Point Sets. (arXiv:2101.07458v1 [cs.CV])</h2>
<h3>Wei Lian, Wangmeng Zuo, Lei Zhang</h3>
<p>Alignment methods which can handle partially overlapping point sets and are
invariant to the corresponding transformations are desirable in computer
vision, with applications such as providing initial transformation
configuration for local search based methods like ICP. To this end, we first
show that the objective of the robust point matching (RPM) algorithm is a cubic
polynomial. We then utilize the convex envelopes of trilinear and bilinear
monomials to develop its lower bounding function. The resulting lower bounding
problem can be efficiently solved via linear assignment and low dimensional
convex quadratic programming. We next develop a branch-and-bound (BnB)
algorithm which only branches over the transformation parameters and converges
quickly. Experimental results demonstrated favorable performance of the
proposed method over the state-of-the-art methods in terms of robustness and
speed.
</p>
<a href="http://arxiv.org/abs/2101.07458" target="_blank">arXiv:2101.07458</a> [<a href="http://arxiv.org/pdf/2101.07458" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning for Producing Furniture Layout in Indoor Scenes. (arXiv:2101.07462v1 [cs.CV])</h2>
<h3>Xinhan Di, Pengqian Yu</h3>
<p>In the industrial interior design process, professional designers plan the
size and position of furniture in a room to achieve a satisfactory design for
selling. In this paper, we explore the interior scene design task as a Markov
decision process (MDP), which is solved by deep reinforcement learning. The
goal is to produce an accurate position and size of the furniture
simultaneously for the indoor layout task. In particular, we first formulate
the furniture layout task as a MDP problem by defining the state, action, and
reward function. We then design the simulated environment and train
reinforcement learning agents to produce the optimal layout for the MDP
formulation. We conduct our experiments on a large-scale real-world interior
layout dataset that contains industrial designs from professional designers.
Our numerical results demonstrate that the proposed model yields higher-quality
layouts as compared with the state-of-art model. The developed simulator and
codes are available at \url{https://github.com/CODE-SUBMIT/simulator1}.
</p>
<a href="http://arxiv.org/abs/2101.07462" target="_blank">arXiv:2101.07462</a> [<a href="http://arxiv.org/pdf/2101.07462" target="_blank">pdf</a>]

<h2>Unsupervised Deep Learning for Handwritten Page Segmentation. (arXiv:2101.07487v1 [cs.CV])</h2>
<h3>Ahmad Droby, Berat Kurar Barakat, Borak Madi, Reem Alaasam, Jihad El-Sana</h3>
<p>Segmenting handwritten document images into regions with homogeneous patterns
is an important pre-processing step for many document images analysis tasks.
Hand-labeling data to train a deep learning model for layout analysis requires
significant human effort. In this paper, we present an unsupervised deep
learning method for page segmentation, which revokes the need for annotated
images. A siamese neural network is trained to differentiate between patches
using their measurable properties such as number of foreground pixels, and
average component height and width. The network is trained that spatially
nearby patches are similar. The network's learned features are used for page
segmentation, where patches are classified as main and side text based on the
extracted features. We tested the method on a dataset of handwritten document
images with quite complex layouts. Our experiments show that the proposed
unsupervised method is as effective as typical supervised methods.
</p>
<a href="http://arxiv.org/abs/2101.07487" target="_blank">arXiv:2101.07487</a> [<a href="http://arxiv.org/pdf/2101.07487" target="_blank">pdf</a>]

<h2>Optimizing Hyperparameters in CNNs using Bilevel Programming in Time Series Data. (arXiv:2101.07492v1 [cs.LG])</h2>
<h3>Taniya Seth, Pranab K. Muhuri</h3>
<p>Hyperparameter optimization has remained a central topic within the machine
learning community due to its ability to produce state-of-the-art results. With
the recent interest growing in the usage of CNNs for time series prediction, we
propose the notion of optimizing Hyperparameters in CNNs for the purpose of
time series prediction. In this position paper, we give away the idea of
modeling the concerned hyperparameter optimization problem using bilevel
programming.
</p>
<a href="http://arxiv.org/abs/2101.07492" target="_blank">arXiv:2101.07492</a> [<a href="http://arxiv.org/pdf/2101.07492" target="_blank">pdf</a>]

<h2>Disentangled Recurrent Wasserstein Autoencoder. (arXiv:2101.07496v1 [cs.LG])</h2>
<h3>Jun Han, Martin Renqiang Min, Ligong Han, Li Erran Li, Xuan Zhang</h3>
<p>Learning disentangled representations leads to interpretable models and
facilitates data generation with style transfer, which has been extensively
studied on static data such as images in an unsupervised learning framework.
However, only a few works have explored unsupervised disentangled sequential
representation learning due to challenges of generating sequential data. In
this paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new
framework for generative modeling of sequential data. R-WAE disentangles the
representation of an input sequence into static and dynamic factors (i.e.,
time-invariant and time-varying parts). Our theoretical analysis shows that,
R-WAE minimizes an upper bound of a penalized form of the Wasserstein distance
between model distribution and sequential data distribution, and simultaneously
maximizes the mutual information between input data and different disentangled
latent factors, respectively. This is superior to (recurrent) VAE which does
not explicitly enforce mutual information maximization between input data and
disentangled latent representations. When the number of actions in sequential
data is available as weak supervision information, R-WAE is extended to learn a
categorical latent representation of actions to improve its disentanglement.
Experiments on a variety of datasets show that our models outperform other
baselines with the same settings in terms of disentanglement and unconditional
video generation both quantitatively and qualitatively.
</p>
<a href="http://arxiv.org/abs/2101.07496" target="_blank">arXiv:2101.07496</a> [<a href="http://arxiv.org/pdf/2101.07496" target="_blank">pdf</a>]

<h2>Paraconsistent Foundations for Quantum Probability. (arXiv:2101.07498v1 [cs.AI])</h2>
<h3>Ben Goertzel</h3>
<p>It is argued that a fuzzy version of 4-truth-valued paraconsistent logic
(with truth values corresponding to True, False, Both and Neither) can be
approximately isomorphically mapped into the complex-number algebra of quantum
probabilities. I.e., p-bits (paraconsistent bits) can be transformed into close
approximations of qubits. The approximation error can be made arbitrarily
small, at least in a formal sense, and can be related to the degree of
irreducible "evidential error" assumed to plague an observer's observations.
This logical correspondence manifests itself in program space via an
approximate mapping between probabilistic and quantum types in programming
languages.
</p>
<a href="http://arxiv.org/abs/2101.07498" target="_blank">arXiv:2101.07498</a> [<a href="http://arxiv.org/pdf/2101.07498" target="_blank">pdf</a>]

<h2>Collaborative Federated Learning For Healthcare: Multi-Modal COVID-19 Diagnosis at the Edge. (arXiv:2101.07511v1 [cs.LG])</h2>
<h3>Adnan Qayyum, Kashif Ahmad, Muhammad Ahtazaz Ahsan, Ala Al-Fuqaha, Junaid Qadir</h3>
<p>Despite significant improvements over the last few years, cloud-based
healthcare applications continue to suffer from poor adoption due to their
limitations in meeting stringent security, privacy, and quality of service
requirements (such as low latency). The edge computing trend, along with
techniques for distributed machine learning such as federated learning, have
gained popularity as a viable solution in such settings. In this paper, we
leverage the capabilities of edge computing in medicine by analyzing and
evaluating the potential of intelligent processing of clinical visual data at
the edge allowing the remote healthcare centers, lacking advanced diagnostic
facilities, to benefit from the multi-modal data securely. To this aim, we
utilize the emerging concept of clustered federated learning (CFL) for an
automatic diagnosis of COVID-19. Such an automated system can help reduce the
burden on healthcare systems across the world that has been under a lot of
stress since the COVID-19 pandemic emerged in late 2019. We evaluate the
performance of the proposed framework under different experimental setups on
two benchmark datasets. Promising results are obtained on both datasets
resulting in comparable results against the central baseline where the
specialized models (i.e., each on a specific type of COVID-19 imagery) are
trained with central data, and improvements of 16\% and 11\% in overall
F1-Scores have been achieved over the multi-modal model trained in the
conventional Federated Learning setup on X-ray and Ultrasound datasets,
respectively. We also discuss in detail the associated challenges,
technologies, tools, and techniques available for deploying ML at the edge in
such privacy and delay-sensitive applications.
</p>
<a href="http://arxiv.org/abs/2101.07511" target="_blank">arXiv:2101.07511</a> [<a href="http://arxiv.org/pdf/2101.07511" target="_blank">pdf</a>]

<h2>Attention-Guided Black-box Adversarial Attacks with Large-Scale Multiobjective Evolutionary Optimization. (arXiv:2101.07512v1 [cs.CV])</h2>
<h3>Jie Wang, Zhaoxia Yin, Jing Jiang, Yang Du</h3>
<p>Fooling deep neural networks (DNNs) with the black-box optimization has
become a popular adversarial attack fashion, as the structural prior knowledge
of DNNs is always unknown. Nevertheless, recent black-box adversarial attacks
may struggle to balance their attack ability and visual quality of the
generated adversarial examples (AEs) in tackling high-resolution images. In
this paper, we propose an attention-guided black-box adversarial attack based
on the large-scale multiobjective evolutionary optimization, termed as LMOA. By
considering the spatial semantic information of images, we firstly take
advantage of the attention map to determine the perturbed pixels. Instead of
attacking the entire image, reducing the perturbed pixels with the attention
mechanism can help to avoid the notorious curse of dimensionality and thereby
improves the performance of attacking. Secondly, a large-scale multiobjective
evolutionary algorithm is employed to traverse the reduced pixels in the
salient region. Benefiting from its characteristics, the generated AEs have the
potential to fool target DNNs while being imperceptible by the human vision.
Extensive experimental results have verified the effectiveness of the proposed
LMOA on the ImageNet dataset. More importantly, it is more competitive to
generate high-resolution AEs with better visual quality compared with the
existing black-box adversarial attacks.
</p>
<a href="http://arxiv.org/abs/2101.07512" target="_blank">arXiv:2101.07512</a> [<a href="http://arxiv.org/pdf/2101.07512" target="_blank">pdf</a>]

<h2>Towards Latent Space Based Manipulation of Elastic Rods using Autoencoder Models and Robust Centerline Extractions. (arXiv:2101.07513v1 [cs.RO])</h2>
<h3>Jiaming Qi, Guangfu Ma, David Navarro-Alarcon, Haibo Zhang, Yueyong Lyu</h3>
<p>The automatic shape control of deformable objects is an open (and currently
hot) manipulation problem that is challenging due to the object's
high-dimensional shape information and its complex physical properties. As a
feasible solution to these issues, in this paper, we propose a new methodology
to automatically deform elastic rods into 2D desired shapes. For that, we
present an efficient vision-based controller that uses a deep autoencoder
network to compute a compact representation of the object's infinite
dimensional shape. To deal with the (typically unknown) mechanical properties
of the object, we use an online algorithm that approximates the sensorimotor
mapping between the robot's configuration and the object's shape features. Our
new approach has the capability to compute the rod's centerline from raw visual
data in real-time; This is done by introducing an adaptive algorithm based on a
self-organizing network. The effectiveness of the proposed method is thoroughly
validated with simulations and experiments.
</p>
<a href="http://arxiv.org/abs/2101.07513" target="_blank">arXiv:2101.07513</a> [<a href="http://arxiv.org/pdf/2101.07513" target="_blank">pdf</a>]

<h2>BANet: Blur-aware Attention Networks for Dynamic Scene Deblurring. (arXiv:2101.07518v1 [cs.CV])</h2>
<h3>Fu-Jen Tsai, Yan-Tsung Peng, Yen-Yu Lin, Chung-Chi Tsai, Chia-Wen Lin</h3>
<p>Image motion blur usually results from moving objects or camera shakes. Such
blur is generally directional and non-uniform. Previous research efforts
attempt to solve non-uniform blur by using self-recurrent multi-scale or
multi-patch architectures accompanying with self-attention. However, using
self-recurrent frameworks typically leads to a longer inference time, while
inter-pixel or inter-channel self-attention may cause excessive memory usage.
This paper proposes blur-aware attention networks (BANet) that accomplish
accurate and efficient deblurring via a single forward pass. Our BANet utilizes
region-based self-attention with multi-kernel strip pooling to disentangle blur
patterns of different degrees and with cascaded parallel dilated convolution to
aggregate multi-scale content features. Extensive experimental results on the
GoPro and HIDE benchmarks demonstrate that the proposed BANet performs
favorably against the state-of-the-art in blurred image restoration and can
provide deblurred results in realtime.
</p>
<a href="http://arxiv.org/abs/2101.07518" target="_blank">arXiv:2101.07518</a> [<a href="http://arxiv.org/pdf/2101.07518" target="_blank">pdf</a>]

<h2>Mapping and Describing Geospatial Data to Generalize Complex Mapping and Describing Geospatial Data to Generalize Complex Models: The Case of LittoSIM-GEN Models. (arXiv:2101.07523v1 [cs.AI])</h2>
<h3>Ahmed Laatabi, Nicolas Becu (LIENSs), Nicolas Marilleau (UMMISCO), C&#xe9;cilia Pignon-Mussaud (LIENSs), Marion Amalric (CITERES), X. Bertin (LIENSs), Brice Anselme (PRODIG), Elise Beck (PACTE)</h3>
<p>For some scientific questions, empirical data are essential to develop
reliable simulation models. These data usually come from different sources with
diverse and heterogeneous formats. The design of complex data-driven models is
often shaped by the structure of the data available in research projects.
Hence, applying such models to other case studies requires either to get
similar data or to transform new data to fit the model inputs. It is the case
of agent-based models (ABMs) that use advanced data structures such as
Geographic Information Systems data. We faced this problem in the LittoSIM-GEN
project when generalizing our participatory flooding model (LittoSIM) to new
territories. From this experience, we provide a mapping approach to structure,
describe, and automatize the integration of geospatial data into ABMs.
</p>
<a href="http://arxiv.org/abs/2101.07523" target="_blank">arXiv:2101.07523</a> [<a href="http://arxiv.org/pdf/2101.07523" target="_blank">pdf</a>]

<h2>PeerGAN: Generative Adversarial Networks with a Competing Peer Discriminator. (arXiv:2101.07524v1 [cs.LG])</h2>
<h3>Jiaheng Wei, Minghao Liu, Jiahao Luo, Qiutong Li, James Davis, Yang Liu</h3>
<p>In this paper, we introduce PeerGAN, a generative adversarial network (GAN)
solution to improve the stability of the generated samples and to mitigate mode
collapse. Built upon the Vanilla GAN's two-player game between the
discriminator $D_1$ and the generator $G$, we introduce a peer discriminator
$D_2$ to the min-max game. Similar to previous work using two discriminators,
the first role of both $D_1$, $D_2$ is to distinguish between generated samples
and real ones, while the generator tries to generate high-quality samples that
are able to fool both discriminators. Different from existing methods, we
introduce another game between $D_1$ and $D_2$ to discourage their agreement
and therefore increase the level of diversity of the generated samples. This
property helps avoid early mode collapse by preventing $D_1$ and $D_2$ from
converging too fast. We provide theoretical analysis for the equilibrium of the
min-max game formed among $G, D_1, D_2$. We offer convergence behavior of
PeerGAN as well as stability of the min-max game. It's worth mentioning that
PeerGAN operates in the unsupervised setting, and the additional game between
$D_1$ and $D_2$ does not need any label supervision. Experiments results on a
synthetic dataset and on real-world image datasets (MNIST, Fashion MNIST,
CIFAR-10, STL-10, CelebA, VGG) demonstrate that PeerGAN outperforms competitive
baseline work in generating diverse and high-quality samples, while only
introduces negligible computation cost.
</p>
<a href="http://arxiv.org/abs/2101.07524" target="_blank">arXiv:2101.07524</a> [<a href="http://arxiv.org/pdf/2101.07524" target="_blank">pdf</a>]

<h2>Momentum^2 Teacher: Momentum Teacher with Momentum Statistics for Self-Supervised Learning. (arXiv:2101.07525v1 [cs.LG])</h2>
<h3>Zeming Li, Songtao Liu, Jian Sun</h3>
<p>In this paper, we present a novel approach, Momentum$^2$ Teacher, for
student-teacher based self-supervised learning. The approach performs momentum
update on both network weights and batch normalization (BN) statistics. The
teacher's weight is a momentum update of the student, and the teacher's BN
statistics is a momentum update of those in history. The Momentum$^2$ Teacher
is simple and efficient. It can achieve the state of the art results (74.5\%)
under ImageNet linear evaluation protocol using small-batch size(\eg, 128),
without requiring large-batch training on special hardware like TPU or
inefficient across GPU operation (\eg, shuffling BN, synced BN). Our
implementation and pre-trained models will be given on
GitHub\footnote{https://github.com/zengarden/momentum2-teacher}.
</p>
<a href="http://arxiv.org/abs/2101.07525" target="_blank">arXiv:2101.07525</a> [<a href="http://arxiv.org/pdf/2101.07525" target="_blank">pdf</a>]

<h2>The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels Methods. (arXiv:2101.07528v1 [cs.CV])</h2>
<h3>Louis Thiry (DI-ENS), Michael Arbel (UCL), Eugene Belilovsky (MILA), Edouard Oyallon (MLIA)</h3>
<p>A recent line of work showed that various forms of convolutional kernel
methods can be competitive with standard supervised deep convolutional networks
on datasets like CIFAR-10, obtaining accuracies in the range of 87-90% while
being more amenable to theoretical analysis. In this work, we highlight the
importance of a data-dependent feature extraction step that is key to the
obtain good performance in convolutional kernel methods. This step typically
corresponds to a whitened dictionary of patches, and gives rise to a
data-driven convolutional kernel methods. We extensively study its effect,
demonstrating it is the key ingredient for high performance of these methods.
Specifically, we show that one of the simplest instances of such kernel
methods, based on a single layer of image patches followed by a linear
classifier is already obtaining classification accuracies on CIFAR-10 in the
same range as previous more sophisticated convolutional kernel methods. We
scale this method to the challenging ImageNet dataset, showing such a simple
approach can exceed all existing non-learned representation methods. This is a
new baseline for object recognition without representation learning methods,
that initiates the investigation of convolutional kernel models on ImageNet. We
conduct experiments to analyze the dictionary that we used, our ablations
showing they exhibit low-dimensional properties.
</p>
<a href="http://arxiv.org/abs/2101.07528" target="_blank">arXiv:2101.07528</a> [<a href="http://arxiv.org/pdf/2101.07528" target="_blank">pdf</a>]

<h2>Intelligent Frame Selection as a Privacy-Friendlier Alternative to Face Recognition. (arXiv:2101.07529v1 [cs.CV])</h2>
<h3>Mattijs Baert, Sam Leroux, Pieter Simoens</h3>
<p>The widespread deployment of surveillance cameras for facial recognition
gives rise to many privacy concerns. This study proposes a privacy-friendly
alternative to large scale facial recognition. While there are multiple
techniques to preserve privacy, our work is based on the minimization principle
which implies minimizing the amount of collected personal data. Instead of
running facial recognition software on all video data, we propose to
automatically extract a high quality snapshot of each detected person without
revealing his or her identity. This snapshot is then encrypted and access is
only granted after legal authorization. We introduce a novel unsupervised face
image quality assessment method which is used to select the high quality
snapshots. For this, we train a variational autoencoder on high quality face
images from a publicly available dataset and use the reconstruction probability
as a metric to estimate the quality of each face crop. We experimentally
confirm that the reconstruction probability can be used as biometric quality
predictor. Unlike most previous studies, we do not rely on a manually defined
face quality metric as everything is learned from data. Our face quality
assessment method outperforms supervised, unsupervised and general image
quality assessment methods on the task of improving face verification
performance by rejecting low quality images. The effectiveness of the whole
system is validated qualitatively on still images and videos.
</p>
<a href="http://arxiv.org/abs/2101.07529" target="_blank">arXiv:2101.07529</a> [<a href="http://arxiv.org/pdf/2101.07529" target="_blank">pdf</a>]

<h2>PICA: A Pixel Correlation-based Attentional Black-box Adversarial Attack. (arXiv:2101.07538v1 [cs.CV])</h2>
<h3>Jie Wang, Zhaoxia Yin, Jin Tang, Jing Jiang, Bin Luo</h3>
<p>The studies on black-box adversarial attacks have become increasingly
prevalent due to the intractable acquisition of the structural knowledge of
deep neural networks (DNNs). However, the performance of emerging attacks is
negatively impacted when fooling DNNs tailored for high-resolution images. One
of the explanations is that these methods usually focus on attacking the entire
image, regardless of its spatial semantic information, and thereby encounter
the notorious curse of dimensionality. To this end, we propose a pixel
correlation-based attentional black-box adversarial attack, termed as PICA.
Firstly, we take only one of every two neighboring pixels in the salient region
as the target by leveraging the attentional mechanism and pixel correlation of
images, such that the dimension of the black-box attack reduces. After that, a
general multiobjective evolutionary algorithm is employed to traverse the
reduced pixels and generate perturbations that are imperceptible by the human
vision. Extensive experimental results have verified the effectiveness of the
proposed PICA on the ImageNet dataset. More importantly, PICA is
computationally more efficient to generate high-resolution adversarial examples
compared with the existing black-box attacks.
</p>
<a href="http://arxiv.org/abs/2101.07538" target="_blank">arXiv:2101.07538</a> [<a href="http://arxiv.org/pdf/2101.07538" target="_blank">pdf</a>]

<h2>VML-MOC: Segmenting a multiply oriented and curved handwritten text lines dataset. (arXiv:2101.07542v1 [cs.CV])</h2>
<h3>Berat Kurar Barakat, Rafi Cohen, Irina Rabaev, Jihad El-Sana</h3>
<p>This paper publishes a natural and very complicated dataset of handwritten
documents with multiply oriented and curved text lines, namely VML-MOC dataset.
These text lines were written as remarks on the page margins by different
writers over the years. They appear at different locations within the
orientations that range between 0 and 180 or as curvilinear forms. We evaluate
a multi-oriented Gaussian based method to segment these handwritten text lines
that are skewed or curved in any orientation. It achieves a mean pixel
Intersection over Union score of 80.96% on the test documents. The results are
compared with the results of a single-oriented Gaussian based text line
segmentation method.
</p>
<a href="http://arxiv.org/abs/2101.07542" target="_blank">arXiv:2101.07542</a> [<a href="http://arxiv.org/pdf/2101.07542" target="_blank">pdf</a>]

<h2>Object Tracking by Detection with Visual and Motion Cues. (arXiv:2101.07549v1 [cs.CV])</h2>
<h3>Niels Ole Salscheider</h3>
<p>Self-driving cars and other autonomous vehicles need to detect and track
objects in camera images. We present a simple online tracking algorithm that is
based on a constant velocity motion model with a Kalman filter, and an
assignment heuristic. The assignment heuristic relies on four metrics: An
embedding vector that describes the appearance of objects and can be used to
re-identify them, a displacement vector that describes the object movement
between two consecutive video frames, the Mahalanobis distance between the
Kalman filter states and the new detections, and a class distance. These
metrics are combined with a linear SVM, and then the assignment problem is
solved by the Hungarian algorithm. We also propose an efficient CNN
architecture that estimates these metrics. Our multi-frame model accepts two
consecutive video frames which are processed individually in the backbone, and
then optical flow is estimated on the resulting feature maps. This allows the
network heads to estimate the displacement vectors. We evaluate our approach on
the challenging BDD100K tracking dataset. Our multi-frame model achieves a good
MOTA value of 39.1% with low localization error of 0.206 in MOTP. Our fast
single-frame model achieves an even lower localization error of 0.202 in MOTP,
and a MOTA value of 36.8%.
</p>
<a href="http://arxiv.org/abs/2101.07549" target="_blank">arXiv:2101.07549</a> [<a href="http://arxiv.org/pdf/2101.07549" target="_blank">pdf</a>]

<h2>JigsawGAN: Self-supervised Learning for Solving Jigsaw Puzzles with Generative Adversarial Networks. (arXiv:2101.07555v1 [cs.CV])</h2>
<h3>Ru Li, Shuaicheng Liu, Guangfu Wang, Guanghui Liu, Bing Zeng</h3>
<p>The paper proposes a solution based on Generative Adversarial Network (GAN)
for solving jigsaw puzzles. The problem assumes that an image is cut into equal
square pieces, and asks to recover the image according to pieces information.
Conventional jigsaw solvers often determine piece relationships based on the
piece boundaries, which ignore the important semantic information. In this
paper, we propose JigsawGAN, a GAN-based self-supervised method for solving
jigsaw puzzles with unpaired images (with no prior knowledge of the initial
images). We design a multi-task pipeline that includes, (1) a classification
branch to classify jigsaw permutations, and (2) a GAN branch to recover
features to images with correct orders. The classification branch is
constrained by the pseudo-labels generated according to the shuffled pieces.
The GAN branch concentrates on the image semantic information, among which the
generator produces the natural images to fool the discriminator with
reassembled pieces, while the discriminator distinguishes whether a given image
belongs to the synthesized or the real target manifold. These two branches are
connected by a flow-based warp that is applied to warp features to correct
order according to the classification results. The proposed method can solve
jigsaw puzzles more efficiently by utilizing both semantic information and edge
information simultaneously. Qualitative and quantitative comparisons against
several leading prior methods demonstrate the superiority of our method.
</p>
<a href="http://arxiv.org/abs/2101.07555" target="_blank">arXiv:2101.07555</a> [<a href="http://arxiv.org/pdf/2101.07555" target="_blank">pdf</a>]

<h2>Variance Based Samples Weighting for Supervised Deep Learning. (arXiv:2101.07561v1 [stat.ML])</h2>
<h3>Paul Novello (CMAP, CEA, PLATON), Ga&#xeb;l Po&#xeb;tte (CEA), David Lugato (CEA), Pietro Congedo (CMAP, PLATON)</h3>
<p>In the context of supervised learning of a function by a Neural Network (NN),
we claim and empirically justify that a NN yields better results when the
distribution of the data set focuses on regions where the function to learn is
steeper. We first traduce this assumption in a mathematically workable way
using Taylor expansion. Then, theoretical derivations allow to construct a
methodology that we call Variance Based Samples Weighting (VBSW). VBSW uses
local variance of the labels to weight the training points. This methodology is
general, scalable, cost effective, and significantly increases the performances
of a large class of NNs for various classification and regression tasks on
image, text and multivariate data. We highlight its benefits with experiments
involving NNs from shallow linear NN to Resnet or Bert.
</p>
<a href="http://arxiv.org/abs/2101.07561" target="_blank">arXiv:2101.07561</a> [<a href="http://arxiv.org/pdf/2101.07561" target="_blank">pdf</a>]

<h2>Performance analysis of greedy algorithms for minimising a Maximum Mean Discrepancy. (arXiv:2101.07564v1 [stat.ML])</h2>
<h3>Luc Pronzato</h3>
<p>We analyse the performance of several iterative algorithms for the
quantisation of a probability measure $\mu$, based on the minimisation of a
Maximum Mean Discrepancy (MMD). Our analysis includes kernel herding, greedy
MMD minimisation and Sequential Bayesian Quadrature (SBQ). We show that the
finite-sample-size approximation error, measured by the MMD, decreases as $1/n$
for SBQ and also for kernel herding and greedy MMD minimisation when using a
suitable step-size sequence. The upper bound on the approximation error is
slightly better for SBQ, but the other methods are significantly faster, with a
computational cost that increases only linearly with the number of points
selected. This is illustrated by two numerical examples, with the target
measure $\mu$ being uniform (a space-filling design application) and with $\mu$
a Gaussian mixture.
</p>
<a href="http://arxiv.org/abs/2101.07564" target="_blank">arXiv:2101.07564</a> [<a href="http://arxiv.org/pdf/2101.07564" target="_blank">pdf</a>]

<h2>Creation and Evaluation of a Pre-tertiary Artificial Intelligence (AI) Curriculum. (arXiv:2101.07570v1 [cs.AI])</h2>
<h3>Thomas K.F. Chiu, Helen Meng, Ching-Sing Chai, Irwin King, Savio Wong, Yeung Yam</h3>
<p>Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for
the Future Project (AI4Future) co-created an AI curriculum for pre-tertiary
education and evaluated its efficacy. While AI is conventionally taught in
tertiary level education, our co-creation process successfully developed the
curriculum that has been used in secondary school teaching in Hong Kong and
received positive feedback. Background: AI4Future is a cross-sector project
that engages five major partners - CUHK Faculty of Engineering and Faculty of
Education, Hong Kong secondary schools, the government and the AI industry. A
team of 14 professors with expertise in engineering and education collaborated
with 17 principals and teachers from 6 secondary schools to co-create the
curriculum. This team formation bridges the gap between researchers in
engineering and education, together with practitioners in education context.
Research Questions: What are the main features of the curriculum content
developed through the co-creation process? Would the curriculum significantly
improve the students perceived competence in, as well as attitude and
motivation towards AI? What are the teachers perceptions of the co-creation
process that aims to accommodate and foster teacher autonomy? Methodology: This
study adopted a mix of quantitative and qualitative methods and involved 335
student participants. Findings: 1) two main features of learning resources, 2)
the students perceived greater competence, and developed more positive attitude
to learn AI, and 3) the co-creation process generated a variety of resources
which enhanced the teachers knowledge in AI, as well as fostered teachers
autonomy in bringing the subject matter into their classrooms.
</p>
<a href="http://arxiv.org/abs/2101.07570" target="_blank">arXiv:2101.07570</a> [<a href="http://arxiv.org/pdf/2101.07570" target="_blank">pdf</a>]

<h2>An Improvement of Object Detection Performance using Multi-step Machine Learnings. (arXiv:2101.07571v1 [cs.CV])</h2>
<h3>Tomoe Kishimoto, Masahiko Saito, Junichi Tanaka, Yutaro Iiyama, Ryu Sawada, Koji Terashi</h3>
<p>Connecting multiple machine learning models into a pipeline is effective for
handling complex problems. By breaking down the problem into steps, each
tackled by a specific component model of the pipeline, the overall solution can
be made accurate and explainable. This paper describes an enhancement of object
detection based on this multi-step concept, where a post-processing step called
the calibration model is introduced. The calibration model consists of a
convolutional neural network, and utilizes rich contextual information based on
the domain knowledge of the input. Improvements of object detection performance
by 0.8-1.9 in average precision metric over existing object detectors have been
observed using the new model.
</p>
<a href="http://arxiv.org/abs/2101.07571" target="_blank">arXiv:2101.07571</a> [<a href="http://arxiv.org/pdf/2101.07571" target="_blank">pdf</a>]

<h2>Collaboration among Image and Object Level Features for Image Colourisation. (arXiv:2101.07576v1 [cs.CV])</h2>
<h3>Rita Pucci, Christian Micheloni, Niki Martinel</h3>
<p>Image colourisation is an ill-posed problem, with multiple correct solutions
which depend on the context and object instances present in the input datum.
Previous approaches attacked the problem either by requiring intense user
interactions or by exploiting the ability of convolutional neural networks
(CNNs) in learning image level (context) features. However, obtaining human
hints is not always feasible and CNNs alone are not able to learn object-level
semantics unless multiple models pretrained with supervision are considered. In
this work, we propose a single network, named UCapsNet, that separate
image-level features obtained through convolutions and object-level features
captured by means of capsules. Then, by skip connections over different layers,
we enforce collaboration between such disentangling factors to produce high
quality and plausible image colourisation. We pose the problem as a
classification task that can be addressed by a fully self-supervised approach,
thus requires no human effort. Experimental results on three benchmark datasets
show that our approach outperforms existing methods on standard quality metrics
and achieves a state of the art performances on image colourisation. A large
scale user study shows that our method is preferred over existing solutions.
</p>
<a href="http://arxiv.org/abs/2101.07576" target="_blank">arXiv:2101.07576</a> [<a href="http://arxiv.org/pdf/2101.07576" target="_blank">pdf</a>]

<h2>Learnable Embedding Sizes for Recommender Systems. (arXiv:2101.07577v1 [cs.LG])</h2>
<h3>Siyi Liu, Chen Gao, Yihong Chen, Depeng Jin, Yong Li</h3>
<p>The embedding-based representation learning is commonly used in deep learning
recommendation models to map the raw sparse features to dense vectors. The
traditional embedding manner that assigns a uniform size to all features has
two issues. First, the numerous features inevitably lead to a gigantic
embedding table that causes a high memory usage cost. Second, it is likely to
cause the over-fitting problem for those features that do not require too large
representation capacity. Existing works that try to address the problem always
cause a significant drop in recommendation performance or suffers from the
limitation of unaffordable training time cost. In this paper, we proposed a
novel approach, named PEP (short for Plug-in Embedding Pruning), to reduce the
size of the embedding table while obviating a drop in accuracy and
computational optimization. PEP prunes embedding parameter where the pruning
threshold(s) can be adaptively learned from data. Therefore we can
automatically obtain a mixed-dimension embedding-scheme by pruning redundant
parameters for each feature. PEP is a general framework that can plug in
various base recommendation models. Extensive experiments demonstrate it can
efficiently cut down embedding parameters and boost the base model's
performance. Specifically, it achieves strong recommendation performance while
reducing 97-99% parameters. As for the computation cost, PEP only brings an
additional 20-30% time cost compared with base models. Codes are available at
https://github.com/ssui-liu/learnable-embed-sizes-for-RecSys.
</p>
<a href="http://arxiv.org/abs/2101.07577" target="_blank">arXiv:2101.07577</a> [<a href="http://arxiv.org/pdf/2101.07577" target="_blank">pdf</a>]

<h2>Practical Distributed Control for VTOL UAVs to Pass a Tunnel. (arXiv:2101.07578v1 [cs.RO])</h2>
<h3>Quan Quan, Rao Fu, Mengxin Li, Donghui Wei, Yan Gao, Kai-Yuan Cai</h3>
<p>Unmanned Aerial Vehicles (UAVs) are now becoming increasingly accessible to
amateur and commercial users alike. An air traffic management (ATM) system is
needed to help ensure that this newest entrant into the skies does not collide
with others. In an ATM, airspace can be composed of airways, intersections and
nodes. In this paper, for simplicity, distributed coordinating the motions of
Vertical TakeOff and Landing (VTOL) UAVs to pass an airway is focused. This is
formulated as a tunnel passing problem, which includes passing a tunnel,
inter-agent collision avoidance and keeping within the tunnel. Lyapunov-like
functions are designed elaborately, and formal analysis based on invariant set
theorem is made to show that all UAVs can pass the tunnel without getting
trapped, avoid collision and keep within the tunnel. What is more, by the
proposed distributed control, a VTOL UAV can keep away from another VTOL UAV or
return back to the tunnel as soon as possible, once it enters into the safety
area of another or has a collision with the tunnel during it is passing the
tunnel. Simulations and experiments are carried out to show the effectiveness
of the proposed method and the comparison with other methods.
</p>
<a href="http://arxiv.org/abs/2101.07578" target="_blank">arXiv:2101.07578</a> [<a href="http://arxiv.org/pdf/2101.07578" target="_blank">pdf</a>]

<h2>Spatial Assembly: Generative Architecture With Reinforcement Learning, Self Play and Tree Search. (arXiv:2101.07579v1 [cs.AI])</h2>
<h3>Panagiotis Tigas, Tyson Hosmer</h3>
<p>With this work, we investigate the use of Reinforcement Learning (RL) for the
generation of spatial assemblies, by combining ideas from Procedural Generation
algorithms (Wave Function Collapse algorithm (WFC)) and RL for Game Solving.
WFC is a Generative Design algorithm, inspired by Constraint Solving. In WFC,
one defines a set of tiles/blocks and constraints and the algorithm generates
an assembly that satisfies these constraints. Casting the problem of generation
of spatial assemblies as a Markov Decision Process whose states transitions are
defined by WFC, we propose an algorithm that uses Reinforcement Learning and
Self-Play to learn a policy that generates assemblies that maximize objectives
set by the designer. Finally, we demonstrate the use of our Spatial Assembly
algorithm in Architecture Design.
</p>
<a href="http://arxiv.org/abs/2101.07579" target="_blank">arXiv:2101.07579</a> [<a href="http://arxiv.org/pdf/2101.07579" target="_blank">pdf</a>]

<h2>Continual Deterioration Prediction for Hospitalized COVID-19 Patients. (arXiv:2101.07581v1 [cs.LG])</h2>
<h3>Jiacheng Liu, Meghna Singh, Catherine ST.Hill, Vino Raj, Lisa Kirkland, Jaideep Srivastava</h3>
<p>Leading up to August 2020, COVID-19 has spread to almost every country in the
world, causing millions of infected and hundreds of thousands of deaths. In
this paper, we first verify the assumption that clinical variables could have
time-varying effects on COVID-19 outcomes. Then, we develop a temporal
stratification approach to make daily predictions on patients' outcome at the
end of hospital stay. Training data is segmented by the remaining length of
stay, which is a proxy for the patient's overall condition. Based on this, a
sequence of predictive models are built, one for each time segment. Thanks to
the publicly shared data, we were able to build and evaluate prototype models.
Preliminary experiments show 0.98 AUROC, 0.91 F1 score and 0.97 AUPR on
continuous deterioration prediction, encouraging further development of the
model as well as validations on different datasets. We also verify the key
assumption which motivates our method. Clinical variables could have
time-varying effects on COVID-19 outcomes. That is to say, the feature
importance of a variable in the predictive model varies at different disease
stages.
</p>
<a href="http://arxiv.org/abs/2101.07581" target="_blank">arXiv:2101.07581</a> [<a href="http://arxiv.org/pdf/2101.07581" target="_blank">pdf</a>]

<h2>Hyperspectral Image Super-Resolution with Spectral Mixup and Heterogeneous Datasets. (arXiv:2101.07589v1 [cs.CV])</h2>
<h3>Ke Li, Dengxin Dai, Ender Konukoglu, Luc Van Gool</h3>
<p>This work studies Hyperspectral image (HSI) super-resolution (SR). HSI SR is
characterized by high-dimensional data and a limited amount of training
examples. This exacerbates the undesirable behaviors of neural networks such as
memorization and sensitivity to out-of-distribution samples. This work
addresses these issues with three contributions. First, we propose a simple,
yet effective data augmentation routine, termed Spectral Mixup, to construct
effective virtual training samples. Second, we observe that HSI SR and RGB
image SR are correlated and develop a novel multi-tasking network to train them
jointly so that the auxiliary task RGB image SR can provide additional
supervision. Finally, we extend the network to a semi-supervised setting so
that it can learn from datasets containing low-resolution HSIs only. With these
contributions, our method is able to learn from heterogeneous datasets and lift
the requirement for having a large amount of HD HSI training samples. Extensive
experiments on four datasets show that our method outperforms existing methods
significantly and underpin the relevance of our contributions. The code of this
work will be released soon.
</p>
<a href="http://arxiv.org/abs/2101.07589" target="_blank">arXiv:2101.07589</a> [<a href="http://arxiv.org/pdf/2101.07589" target="_blank">pdf</a>]

<h2>Analysis and tuning of hierarchical topic models based on Renyi entropy approach. (arXiv:2101.07598v1 [stat.ML])</h2>
<h3>Sergei Koltcov, Vera Ignatenko, Maxim Terpilovskii, Paolo Rosso</h3>
<p>Hierarchical topic modeling is a potentially powerful instrument for
determining the topical structure of text collections that allows constructing
a topical hierarchy representing levels of topical abstraction. However, tuning
of parameters of hierarchical models, including the number of topics on each
hierarchical level, remains a challenging task and an open issue. In this
paper, we propose a Renyi entropy-based approach for a partial solution to the
above problem. First, we propose a Renyi entropy-based metric of quality for
hierarchical models. Second, we propose a practical concept of hierarchical
topic model tuning tested on datasets with human mark-up. In the numerical
experiments, we consider three different hierarchical models, namely,
hierarchical latent Dirichlet allocation (hLDA) model, hierarchical Pachinko
allocation model (hPAM), and hierarchical additive regularization of topic
models (hARTM). We demonstrate that hLDA model possesses a significant level of
instability and, moreover, the derived numbers of topics are far away from the
true numbers for labeled datasets. For hPAM model, the Renyi entropy approach
allows us to determine only one level of the data structure. For hARTM model,
the proposed approach allows us to estimate the number of topics for two
hierarchical levels.
</p>
<a href="http://arxiv.org/abs/2101.07598" target="_blank">arXiv:2101.07598</a> [<a href="http://arxiv.org/pdf/2101.07598" target="_blank">pdf</a>]

<h2>Meta-Reinforcement Learning for Adaptive Motor Control in Changing Robot Dynamics and Environments. (arXiv:2101.07599v1 [cs.RO])</h2>
<h3>Timoth&#xe9;e Anne, Jack Wilkinson, Zhibin Li</h3>
<p>This work developed a meta-learning approach that adapts the control policy
on the fly to different changing conditions for robust locomotion. The proposed
method constantly updates the interaction model, samples feasible sequences of
actions of estimated the state-action trajectories, and then applies the
optimal actions to maximize the reward. To achieve online model adaptation, our
proposed method learns different latent vectors of each training condition,
which are selected online given the newly collected data. Our work designs
appropriate state space and reward functions, and optimizes feasible actions in
an MPC fashion which are then sampled directly in the joint space considering
constraints, hence requiring no prior design of specific walking gaits. We
further demonstrate the robot's capability of detecting unexpected changes
during interaction and adapting control policies quickly. The extensive
validation on the SpotMicro robot in a physics simulation shows adaptive and
robust locomotion skills under varying ground friction, external pushes, and
different robot models including hardware faults and changes.
</p>
<a href="http://arxiv.org/abs/2101.07599" target="_blank">arXiv:2101.07599</a> [<a href="http://arxiv.org/pdf/2101.07599" target="_blank">pdf</a>]

<h2>Interpretable Models for Granger Causality Using Self-explaining Neural Networks. (arXiv:2101.07600v1 [cs.LG])</h2>
<h3>Ri&#x10d;ards Marcinkevi&#x10d;s, Julia E. Vogt</h3>
<p>Exploratory analysis of time series data can yield a better understanding of
complex dynamical systems. Granger causality is a practical framework for
analysing interactions in sequential data, applied in a wide range of domains.
In this paper, we propose a novel framework for inferring multivariate Granger
causality under nonlinear dynamics based on an extension of self-explaining
neural networks. This framework is more interpretable than other
neural-network-based techniques for inferring Granger causality, since in
addition to relational inference, it also allows detecting signs of
Granger-causal effects and inspecting their variability over time. In
comprehensive experiments on simulated data, we show that our framework
performs on par with several powerful baseline methods at inferring Granger
causality and that it achieves better performance at inferring interaction
signs. The results suggest that our framework is a viable and more
interpretable alternative to sparse-input neural networks for inferring Granger
causality.
</p>
<a href="http://arxiv.org/abs/2101.07600" target="_blank">arXiv:2101.07600</a> [<a href="http://arxiv.org/pdf/2101.07600" target="_blank">pdf</a>]

<h2>Human Action Recognition Based on Multi-scale Feature Maps from Depth Video Sequences. (arXiv:2101.07618v1 [cs.CV])</h2>
<h3>Chang Li, Qian Huang, Xing Li, Qianhan Wu</h3>
<p>Human action recognition is an active research area in computer vision.
Although great process has been made, previous methods mostly recognize actions
based on depth data at only one scale, and thus they often neglect multi-scale
features that provide additional information action recognition in practical
application scenarios. In this paper, we present a novel framework focusing on
multi-scale motion information to recognize human actions from depth video
sequences. We propose a multi-scale feature map called Laplacian pyramid depth
motion images(LP-DMI). We employ depth motion images (DMI) as the templates to
generate the multi-scale static representation of actions. Then, we caculate
LP-DMI to enhance multi-scale dynamic information of motions and reduces
redundant static information in human bodies. We further extract the
multi-granularity descriptor called LP-DMI-HOG to provide more discriminative
features. Finally, we utilize extreme learning machine (ELM) for action
classification. The proposed method yeilds the recognition accuracy of 93.41%,
85.12%, 91.94% on public MSRAction3D dataset, UTD-MHAD and DHA dataset. Through
extensive experiments, we prove that our method outperforms state-of-the-art
benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.07618" target="_blank">arXiv:2101.07618</a> [<a href="http://arxiv.org/pdf/2101.07618" target="_blank">pdf</a>]

<h2>Mirror-Descent Inverse Kinematics for Box-constrained Joint Space. (arXiv:2101.07625v1 [cs.RO])</h2>
<h3>Taisuke Kobayashi</h3>
<p>This paper proposes a new Jacobian-based inverse kinematics (IK) explicitly
considering box-constrained joint space. To control humanoid robots, the
reference pose of end effector(s) is planned in task space, then mapped into
the reference joints by IK. Due to the limited analytical solutions for IK,
iterative numerical IK solvers based on Jacobian between task and joint spaces
have become popular. However, the conventional Jacobian-based IK does not
explicitly consider the joint constraints, and therefore, they usually clamp
the obtained joints during iteration according to the constraints in practice.
The problem in clamping operation has been pointed out that it causes numerical
instability due to non-smoothed objective function. To alleviate the clamping
problem, this study explicitly considers the joint constraints, especially the
box constraints in this paper, inside the new IK solver. Specifically, instead
of clamping, a mirror descent (MD) method with box-constrained real joint space
and no-constrained mirror space is integrated with the conventional
Jacobian-based IK methods, so-called MD-IK. In addition, to escape local optima
nearly on the boundaries of constraints, a heuristic technique, called
$\epsilon$-clamping, is implemented as margin in software level. As a result,
MD-IK achieved more stable and enough fast i) regulation on the random
reference poses and ii) tracking to the random trajectories compared to the
conventional IK solvers.
</p>
<a href="http://arxiv.org/abs/2101.07625" target="_blank">arXiv:2101.07625</a> [<a href="http://arxiv.org/pdf/2101.07625" target="_blank">pdf</a>]

<h2>Salient Object Detection via Integrity Learning. (arXiv:2101.07663v1 [cs.CV])</h2>
<h3>Mingchen Zhuge, Deng-Ping Fan, Nian Liu, Dingwen Zhang, Dong Xu, Ling Shao</h3>
<p>Albeit current salient object detection (SOD) works have achieved fantastic
progress, they are cast into the shade when it comes to the integrity of the
predicted salient regions. We define the concept of integrity at both the micro
and macro level. Specifically, at the micro level, the model should highlight
all parts that belong to a certain salient object, while at the macro level,
the model needs to discover all salient objects from the given image scene. To
facilitate integrity learning for salient object detection, we design a novel
Integrity Cognition Network (ICON), which explores three important components
to learn strong integrity features. 1) Unlike the existing models that focus
more on feature discriminability, we introduce a diverse feature aggregation
(DFA) component to aggregate features with various receptive fields (i.e.,,
kernel shape and context) and increase the feature diversity. Such diversity is
the foundation for mining the integral salient objects. 2) Based on the DFA
features, we introduce the integrity channel enhancement (ICE) component with
the goal of enhancing feature channels that highlight the integral salient
objects at the macro level, while suppressing the other distracting ones. 3)
After extracting the enhanced features, the part-whole verification (PWV)
method is employed to determine whether the part and whole object features have
strong agreement. Such part-whole agreements can further improve the
micro-level integrity for each salient object. To demonstrate the effectiveness
of ICON, comprehensive experiments are conducted on seven challenging
benchmarks, where promising results are achieved.
</p>
<a href="http://arxiv.org/abs/2101.07663" target="_blank">arXiv:2101.07663</a> [<a href="http://arxiv.org/pdf/2101.07663" target="_blank">pdf</a>]

<h2>Few-Shot Bayesian Optimization with Deep Kernel Surrogates. (arXiv:2101.07667v1 [cs.LG])</h2>
<h3>Martin Wistuba, Josif Grabocka</h3>
<p>Hyperparameter optimization (HPO) is a central pillar in the automation of
machine learning solutions and is mainly performed via Bayesian optimization,
where a parametric surrogate is learned to approximate the black box response
function (e.g. validation error). Unfortunately, evaluating the response
function is computationally intensive. As a remedy, earlier work emphasizes the
need for transfer learning surrogates which learn to optimize hyperparameters
for an algorithm from other tasks. In contrast to previous work, we propose to
rethink HPO as a few-shot learning problem in which we train a shared deep
surrogate model to quickly adapt (with few response evaluations) to the
response function of a new task. We propose the use of a deep kernel network
for a Gaussian process surrogate that is meta-learned in an end-to-end fashion
in order to jointly approximate the response functions of a collection of
training data sets. As a result, the novel few-shot optimization of our deep
kernel surrogate leads to new state-of-the-art results at HPO compared to
several recent methods on diverse metadata sets.
</p>
<a href="http://arxiv.org/abs/2101.07667" target="_blank">arXiv:2101.07667</a> [<a href="http://arxiv.org/pdf/2101.07667" target="_blank">pdf</a>]

<h2>Edge-Featured Graph Attention Network. (arXiv:2101.07671v1 [cs.LG])</h2>
<h3>Jun Chen, Haopeng Chen</h3>
<p>Lots of neural network architectures have been proposed to deal with learning
tasks on graph-structured data. However, most of these models concentrate on
only node features during the learning process. The edge features, which
usually play a similarly important role as the nodes, are often ignored or
simplified by these models. In this paper, we present edge-featured graph
attention networks, namely EGATs, to extend the use of graph neural networks to
those tasks learning on graphs with both node and edge features. These models
can be regarded as extensions of graph attention networks (GATs). By reforming
the model structure and the learning process, the new models can accept node
and edge features as inputs, incorporate the edge information into feature
representations, and iterate both node and edge features in a parallel but
mutual way. The results demonstrate that our work is highly competitive against
other node classification approaches, and can be well applied in edge-featured
graph learning tasks.
</p>
<a href="http://arxiv.org/abs/2101.07671" target="_blank">arXiv:2101.07671</a> [<a href="http://arxiv.org/pdf/2101.07671" target="_blank">pdf</a>]

<h2>COTORRA: COntext-aware Testbed fOR Robotic Applications. (arXiv:2101.07676v1 [cs.RO])</h2>
<h3>Milan Groshev, Jorge Mart&#xed;n-P&#xe9;rez, Kiril Antevski, Antonio de la Oliva, Carlos J. Bernardos</h3>
<p>Edge &amp; Fog computing have received considerable attention as promising
candidates for the evolution of robotic systems. In this letter, we propose
COTORRA, an Edge &amp; Fog driven robotic testbed that combines context information
with robot sensor data to validate innovative concepts for robotic systems
prior to being applied in a production environment. In lab/university, we
established COTORRA as an easy applicable and modular testbed on top of
heterogeneous network infrastructure. COTORRA is open for pluggable robotic
applications. To verify its feasibility and assess its performance, we ran set
of experiments that show how autonomous navigation applications can achieve
target latencies bellow 15ms or perform an inter-domain (DLT) federation within
19 seconds.
</p>
<a href="http://arxiv.org/abs/2101.07676" target="_blank">arXiv:2101.07676</a> [<a href="http://arxiv.org/pdf/2101.07676" target="_blank">pdf</a>]

<h2>The Six Hug Commandments: Design and Evaluation of a Human-Sized Hugging Robot with Visual and Haptic Perception. (arXiv:2101.07679v1 [cs.RO])</h2>
<h3>Alexis E. Block, Sammy Christen, Roger Gassert, Otmar Hilliges, Katherine J. Kuchenbecker</h3>
<p>Receiving a hug is one of the best ways to feel socially supported, and the
lack of social touch can have severe negative effects on an individual's
well-being. Based on previous research both within and outside of HRI, we
propose six tenets ("commandments") of natural and enjoyable robotic hugging: a
hugging robot should be soft, be warm, be human sized, visually perceive its
user, adjust its embrace to the user's size and position, and reliably release
when the user wants to end the hug. Prior work validated the first two tenets,
and the final four are new. We followed all six tenets to create a new robotic
platform, HuggieBot 2.0, that has a soft, warm, inflated body (HuggieChest) and
uses visual and haptic sensing to deliver closed-loop hugging. We first
verified the outward appeal of this platform in comparison to the previous
PR2-based HuggieBot 1.0 via an online video-watching study involving 117 users.
We then conducted an in-person experiment in which 32 users each exchanged
eight hugs with HuggieBot 2.0, experiencing all combinations of visual hug
initiation, haptic sizing, and haptic releasing. The results show that adding
haptic reactivity definitively improves user perception a hugging robot,
largely verifying our four new tenets and illuminating several interesting
opportunities for further improvement.
</p>
<a href="http://arxiv.org/abs/2101.07679" target="_blank">arXiv:2101.07679</a> [<a href="http://arxiv.org/pdf/2101.07679" target="_blank">pdf</a>]

<h2>Hyperspectral Image Restoration via Multi-mode and Double-weighted Tensor Nuclear Norm Minimization. (arXiv:2101.07681v1 [cs.CV])</h2>
<h3>Sheng Liu, Xiaozhen Xie, Wenfeng Kong</h3>
<p>Tensor nuclear norm (TNN) induced by tensor singular value decomposition
plays an important role in hyperspectral image (HSI) restoration tasks. In this
letter, we first consider three inconspicuous but crucial phenomenons in TNN.
In the Fourier transform domain of HSIs, different frequency components contain
different information; different singular values of each frequency component
also represent different information. The two physical phenomenons lie not only
in the spectral dimension but also in the spatial dimensions. Then, to improve
the capability and flexibility of TNN for HSI restoration, we propose a
multi-mode and double-weighted TNN based on the above three crucial
phenomenons. It can adaptively shrink the frequency components and singular
values according to their physical meanings in all modes of HSIs. In the
framework of the alternating direction method of multipliers, we design an
effective alternating iterative strategy to optimize our proposed model.
Restoration experiments on both synthetic and real HSI datasets demonstrate
their superiority against related methods.
</p>
<a href="http://arxiv.org/abs/2101.07681" target="_blank">arXiv:2101.07681</a> [<a href="http://arxiv.org/pdf/2101.07681" target="_blank">pdf</a>]

<h2>Utilizing Import Vector Machines to Identify Dangerous Pro-active Traffic Conditions. (arXiv:2101.07683v1 [stat.ML])</h2>
<h3>Kui Yang, Wenjing Zhao, Constantinos Antoniou</h3>
<p>Traffic accidents have been a severe issue in metropolises with the
development of traffic flow. This paper explores the theory and application of
a recently developed machine learning technique, namely Import Vector Machines
(IVMs), in real-time crash risk analysis, which is a hot topic to reduce
traffic accidents. Historical crash data and corresponding traffic data from
Shanghai Urban Expressway System were employed and matched. Traffic conditions
are labelled as dangerous (i.e. probably leading to a crash) and safe (i.e. a
normal traffic condition) based on 5-minute measurements of average speed,
volume and occupancy. The IVM algorithm is trained to build the classifier and
its performance is compared to the popular and successfully applied technique
of Support Vector Machines (SVMs). The main findings indicate that IVMs could
successfully be employed in real-time identification of dangerous pro-active
traffic conditions. Furthermore, similar to the "support points" of the SVM,
the IVM model uses only a fraction of the training data to index kernel basis
functions, typically a much smaller fraction than the SVM, and its
classification rates are similar to those of SVMs. This gives the IVM a
computational advantage over the SVM, especially when the size of the training
data set is large.
</p>
<a href="http://arxiv.org/abs/2101.07683" target="_blank">arXiv:2101.07683</a> [<a href="http://arxiv.org/pdf/2101.07683" target="_blank">pdf</a>]

<h2>GLocalX -- From Local to Global Explanations of Black Box AI Models. (arXiv:2101.07685v1 [cs.LG])</h2>
<h3>Mattia Setzu, Riccardo Guidotti, Anna Monreale, Franco Turini, Dino Pedreschi, Fosca Giannotti</h3>
<p>Artificial Intelligence (AI) has come to prominence as one of the major
components of our society, with applications in most aspects of our lives. In
this field, complex and highly nonlinear machine learning models such as
ensemble models, deep neural networks, and Support Vector Machines have
consistently shown remarkable accuracy in solving complex tasks. Although
accurate, AI models often are "black boxes" which we are not able to
understand. Relying on these models has a multifaceted impact and raises
significant concerns about their transparency. Applications in sensitive and
critical domains are a strong motivational factor in trying to understand the
behavior of black boxes. We propose to address this issue by providing an
interpretable layer on top of black box models by aggregating "local"
explanations. We present GLocalX, a "local-first" model agnostic explanation
method. Starting from local explanations expressed in form of local decision
rules, GLocalX iteratively generalizes them into global explanations by
hierarchically aggregating them. Our goal is to learn accurate yet simple
interpretable models to emulate the given black box, and, if possible, replace
it entirely. We validate GLocalX in a set of experiments in standard and
constrained settings with limited or no access to either data or local
explanations. Experiments show that GLocalX is able to accurately emulate
several models with simple and small models, reaching state-of-the-art
performance against natively global solutions. Our findings show how it is
often possible to achieve a high level of both accuracy and comprehensibility
of classification models, even in complex domains with high-dimensional data,
without necessarily trading one property for the other. This is a key
requirement for a trustworthy AI, necessary for adoption in high-stakes
decision making applications.
</p>
<a href="http://arxiv.org/abs/2101.07685" target="_blank">arXiv:2101.07685</a> [<a href="http://arxiv.org/pdf/2101.07685" target="_blank">pdf</a>]

<h2>Choice Set Misspecification in Reward Inference. (arXiv:2101.07691v1 [cs.AI])</h2>
<h3>Rachel Freedman, Rohin Shah, Anca Dragan</h3>
<p>Specifying reward functions for robots that operate in environments without a
natural reward signal can be challenging, and incorrectly specified rewards can
incentivise degenerate or dangerous behavior. A promising alternative to
manually specifying reward functions is to enable robots to infer them from
human feedback, like demonstrations or corrections. To interpret this feedback,
robots treat as approximately optimal a choice the person makes from a choice
set, like the set of possible trajectories they could have demonstrated or
possible corrections they could have made. In this work, we introduce the idea
that the choice set itself might be difficult to specify, and analyze choice
set misspecification: what happens as the robot makes incorrect assumptions
about the set of choices from which the human selects their feedback. We
propose a classification of different kinds of choice set misspecification, and
show that these different classes lead to meaningful differences in the
inferred reward and resulting performance. While we would normally expect
misspecification to hurt, we find that certain kinds of misspecification are
neither helpful nor harmful (in expectation). However, in other situations,
misspecification can be extremely harmful, leading the robot to believe the
opposite of what it should believe. We hope our results will allow for better
prediction and response to the effects of misspecification in real-world reward
inference.
</p>
<a href="http://arxiv.org/abs/2101.07691" target="_blank">arXiv:2101.07691</a> [<a href="http://arxiv.org/pdf/2101.07691" target="_blank">pdf</a>]

<h2>Communication-Efficient Sampling for Distributed Training of Graph Convolutional Networks. (arXiv:2101.07706v1 [cs.LG])</h2>
<h3>Peng Jiang, Masuma Akter Rumi</h3>
<p>Training Graph Convolutional Networks (GCNs) is expensive as it needs to
aggregate data recursively from neighboring nodes. To reduce the computation
overhead, previous works have proposed various neighbor sampling methods that
estimate the aggregation result based on a small number of sampled neighbors.
Although these methods have successfully accelerated the training, they mainly
focus on the single-machine setting. As real-world graphs are large, training
GCNs in distributed systems is desirable. However, we found that the existing
neighbor sampling methods do not work well in a distributed setting.
Specifically, a naive implementation may incur a huge amount of communication
of feature vectors among different machines. To address this problem, we
propose a communication-efficient neighbor sampling method in this work. Our
main idea is to assign higher sampling probabilities to the local nodes so that
remote nodes are accessed less frequently. We present an algorithm that
determines the local sampling probabilities and makes sure our skewed neighbor
sampling does not affect much the convergence of the training. Our experiments
with node classification benchmarks show that our method significantly reduces
the communication overhead for distributed GCN training with little accuracy
loss.
</p>
<a href="http://arxiv.org/abs/2101.07706" target="_blank">arXiv:2101.07706</a> [<a href="http://arxiv.org/pdf/2101.07706" target="_blank">pdf</a>]

<h2>Image Denoising using Attention-Residual Convolutional Neural Networks. (arXiv:2101.07713v1 [cs.LG])</h2>
<h3>Rafael G. Pires, Daniel F. S. Santos, Marcos C.S. Santana, Claudio F.G. Santos, Joao P. Papa</h3>
<p>During the image acquisition process, noise is usually added to the data
mainly due to physical limitations of the acquisition sensor, and also
regarding imprecisions during the data transmission and manipulation. In that
sense, the resultant image needs to be processed to attenuate its noise without
losing details. Non-learning-based strategies such as filter-based and noise
prior modeling have been adopted to solve the image denoising problem.
Nowadays, learning-based denoising techniques showed to be much more effective
and flexible approaches, such as Residual Convolutional Neural Networks. Here,
we propose a new learning-based non-blind denoising technique named Attention
Residual Convolutional Neural Network (ARCNN), and its extension to blind
denoising named Flexible Attention Residual Convolutional Neural Network
(FARCNN). The proposed methods try to learn the underlying noise expectation
using an Attention-Residual mechanism. Experiments on public datasets corrupted
by different levels of Gaussian and Poisson noise support the effectiveness of
the proposed approaches against some state-of-the-art image denoising methods.
ARCNN achieved an overall average PSNR results of around 0.44dB and 0.96dB for
Gaussian and Poisson denoising, respectively FARCNN presented very consistent
results, even with slightly worsen performance compared to ARCNN.
</p>
<a href="http://arxiv.org/abs/2101.07713" target="_blank">arXiv:2101.07713</a> [<a href="http://arxiv.org/pdf/2101.07713" target="_blank">pdf</a>]

<h2>Deep Feedback Inverse Problem Solver. (arXiv:2101.07719v1 [cs.CV])</h2>
<h3>Wei-Chiu Ma, Shenlong Wang, Jiayuan Gu, Sivabalan Manivasagam, Antonio Torralba, Raquel Urtasun</h3>
<p>We present an efficient, effective, and generic approach towards solving
inverse problems. The key idea is to leverage the feedback signal provided by
the forward process and learn an iterative update model. Specifically, at each
iteration, the neural network takes the feedback as input and outputs an update
on the current estimation. Our approach does not have any restrictions on the
forward process; it does not require any prior knowledge either. Through the
feedback information, our model not only can produce accurate estimations that
are coherent to the input observation but also is capable of recovering from
early incorrect predictions. We verify the performance of our approach over a
wide range of inverse problems, including 6-DOF pose estimation, illumination
estimation, as well as inverse kinematics. Comparing to traditional
optimization-based methods, we can achieve comparable or better performance
while being two to three orders of magnitude faster. Compared to deep
learning-based approaches, our model consistently improves the performance on
all metrics. Please refer to the project page for videos, animations,
supplementary materials, etc.
</p>
<a href="http://arxiv.org/abs/2101.07719" target="_blank">arXiv:2101.07719</a> [<a href="http://arxiv.org/pdf/2101.07719" target="_blank">pdf</a>]

<h2>Hyperdimensional computing as a framework for systematic aggregation of image descriptors. (arXiv:2101.07720v1 [cs.CV])</h2>
<h3>Peer Neubert, Stefan Schubert</h3>
<p>Image and video descriptors are an omnipresent tool in computer vision and
its application fields like mobile robotics. Many hand-crafted and in
particular learned image descriptors are numerical vectors with a potentially
(very) large number of dimensions. Practical considerations like memory
consumption or time for comparisons call for the creation of compact
representations. In this paper, we use hyperdimensional computing (HDC) as an
approach to systematically combine information from a set of vectors in a
single vector of the same dimensionality. HDC is a known technique to perform
symbolic processing with distributed representation in numerical vectors with
thousands of dimensions. We present a HDC implementation that is suitable for
processing the output of existing and future (deep-learning based) image
descriptors. We discuss how this can be used as a framework to process
descriptors together with additional knowledge by simple and fast vector
operations. A concrete outcome is a novel HDC-based approach to aggregate a set
of local image descriptors together with their image positions in a single
holistic descriptor. The comparison to available holistic descriptors and
aggregation methods on a series of standard mobile robotics place recognition
experiments shows a 20% improvement in average performance compared to
runner-up and 3.6x better worst-case performance.
</p>
<a href="http://arxiv.org/abs/2101.07720" target="_blank">arXiv:2101.07720</a> [<a href="http://arxiv.org/pdf/2101.07720" target="_blank">pdf</a>]

<h2>A Unifying Generative Model for Graph Learning Algorithms: Label Propagation, Graph Convolutions, and Combinations. (arXiv:2101.07730v1 [cs.LG])</h2>
<h3>Junteng Jia, Austin R. Benson</h3>
<p>Semi-supervised learning on graphs is a widely applicable problem in network
science and machine learning. Two standard algorithms -- label propagation and
graph neural networks -- both operate by repeatedly passing information along
edges, the former by passing labels and the latter by passing node features,
modulated by neural networks. These two types of algorithms have largely
developed separately, and there is little understanding about the structure of
network data that would make one of these approaches work particularly well
compared to the other or when the approaches can be meaningfully combined.
Here, we develop a Markov random field model for the data generation process of
node attributes, based on correlations of attributes on and between vertices,
that motivates and unifies these algorithmic approaches. We show that label
propagation, a linearized graph convolutional network, and their combination
can all be derived as conditional expectations under our model, when
conditioning on different attributes. In addition, the data model highlights
deficiencies in existing graph neural networks (while producing new algorithmic
solutions), serves as a rigorous statistical framework for understanding graph
learning issues such as over-smoothing, creates a testbed for evaluating
inductive learning performance, and provides a way to sample graphs attributes
that resemble empirical data. We also find that a new algorithm derived from
our data generation model, which we call a Linear Graph Convolution, performs
extremely well in practice on empirical data, and provide theoretical
justification for why this is the case.
</p>
<a href="http://arxiv.org/abs/2101.07730" target="_blank">arXiv:2101.07730</a> [<a href="http://arxiv.org/pdf/2101.07730" target="_blank">pdf</a>]

<h2>TC-DTW: Accelerating Multivariate Dynamic Time Warping Through Triangle Inequality and Point Clustering. (arXiv:2101.07731v1 [cs.LG])</h2>
<h3>Daniel Shen, Min Chi</h3>
<p>Dynamic time warping (DTW) plays an important role in analytics on time
series. Despite the large body of research on speeding up univariate DTW, the
method for multivariate DTW has not been improved much in the last two decades.
The most popular algorithm used today is still the one developed seventeen
years ago. This paper presents a solution that, as far as we know, for the
first time consistently outperforms the classic multivariate DTW algorithm
across dataset sizes, series lengths, data dimensions, temporal window sizes,
and machines. The new solution, named TC-DTW, introduces Triangle Inequality
and Point Clustering into the algorithm design on lower bound calculations for
multivariate DTW. In experiments on DTW-based nearest neighbor finding, the new
solution avoids as much as 98% (60% average) DTW distance calculations and
yields as much as 25X (7.5X average) speedups.
</p>
<a href="http://arxiv.org/abs/2101.07731" target="_blank">arXiv:2101.07731</a> [<a href="http://arxiv.org/pdf/2101.07731" target="_blank">pdf</a>]

<h2>Out-of-distribution Prediction with Invariant Risk Minimization: The Limitation and An Effective Fix. (arXiv:2101.07732v1 [cs.LG])</h2>
<h3>Ruocheng Guo, Pengchuan Zhang, Hao Liu, Emre Kiciman</h3>
<p>This work considers the out-of-distribution (OOD) prediction problem where
(1)~the training data are from multiple domains and (2)~the test domain is
unseen in the training. DNNs fail in OOD prediction because they are prone to
pick up spurious correlations. Recently, Invariant Risk Minimization (IRM) is
proposed to address this issue. Its effectiveness has been demonstrated in the
colored MNIST experiment. Nevertheless, we find that the performance of IRM can
be dramatically degraded under \emph{strong $\Lambda$ spuriousness} -- when the
spurious correlation between the spurious features and the class label is
strong due to the strong causal influence of their common cause, the domain
label, on both of them (see Fig. 1). In this work, we try to answer the
questions: why does IRM fail in the aforementioned setting? Why does IRM work
for the original colored MNIST dataset? How can we fix this problem of IRM?
Then, we propose a simple and effective approach to fix the problem of IRM. We
combine IRM with conditional distribution matching to avoid a specific type of
spurious correlation under strong $\Lambda$ spuriousness. Empirically, we
design a series of semi synthetic datasets -- the colored MNIST plus, which
exposes the problems of IRM and demonstrates the efficacy of the proposed
method.
</p>
<a href="http://arxiv.org/abs/2101.07732" target="_blank">arXiv:2101.07732</a> [<a href="http://arxiv.org/pdf/2101.07732" target="_blank">pdf</a>]

<h2>Determining Structural Properties of Artificial Neural Networks Using Algebraic Topology. (arXiv:2101.07752v1 [cs.LG])</h2>
<h3>David P&#xe9;rez Fern&#xe1;ndez, Asier Guti&#xe9;rrez-Fandi&#xf1;o, Jordi Armengol-Estap&#xe9;, Marta Villegas</h3>
<p>Artificial Neural Networks (ANNs) are widely used for approximating complex
functions. The process that is usually followed to define the most appropriate
architecture for an ANN given a specific function is mostly empirical. Once
this architecture has been defined, weights are usually optimized according to
the error function. On the other hand, we observe that ANNs can be represented
as graphs and their topological 'fingerprints' can be obtained using Persistent
Homology (PH). In this paper, we describe a proposal focused on designing more
principled architecture search procedures. To do this, different architectures
for solving problems related to a heterogeneous set of datasets have been
analyzed. The results of the evaluation corroborate that PH effectively
characterizes the ANN invariants: when ANN density (layers and neurons) or
sample feeding order is the only difference, PH topological invariants appear;
in the opposite direction in different sub-problems (i.e. different labels), PH
varies. This approach based on topological analysis helps towards the goal of
designing more principled architecture search procedures and having a better
understanding of ANNs.
</p>
<a href="http://arxiv.org/abs/2101.07752" target="_blank">arXiv:2101.07752</a> [<a href="http://arxiv.org/pdf/2101.07752" target="_blank">pdf</a>]

<h2>Learning over Families of Sets -- Hypergraph Representation Learning for Higher Order Tasks. (arXiv:2101.07773v1 [cs.LG])</h2>
<h3>Balasubramaniam Srinivasan, Da Zheng, George Karypis</h3>
<p>Graph representation learning has made major strides over the past decade.
However, in many relational domains, the input data are not suited for simple
graph representations as the relationships between entities go beyond pairwise
interactions. In such cases, the relationships in the data are better
represented as hyperedges (set of entities) of a non-uniform hypergraph. While
there have been works on principled methods for learning representations of
nodes of a hypergraph, these approaches are limited in their applicability to
tasks on non-uniform hypergraphs (hyperedges with different cardinalities). In
this work, we exploit the incidence structure to develop a hypergraph neural
network to learn provably expressive representations of variable sized
hyperedges which preserve local-isomorphism in the line graph of the
hypergraph, while also being invariant to permutations of its constituent
vertices. Specifically, for a given vertex set, we propose frameworks for (1)
hyperedge classification and (2) variable sized expansion of partially observed
hyperedges which captures the higher order interactions among vertices and
hyperedges. We evaluate performance on multiple real-world hypergraph datasets
and demonstrate consistent, significant improvement in accuracy, over
state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2101.07773" target="_blank">arXiv:2101.07773</a> [<a href="http://arxiv.org/pdf/2101.07773" target="_blank">pdf</a>]

<h2>Minimax Off-Policy Evaluation for Multi-Armed Bandits. (arXiv:2101.07781v1 [stat.ML])</h2>
<h3>Cong Ma, Banghua Zhu, Jiantao Jiao, Martin J. Wainwright</h3>
<p>We study the problem of off-policy evaluation in the multi-armed bandit model
with bounded rewards, and develop minimax rate-optimal procedures under three
settings. First, when the behavior policy is known, we show that the Switch
estimator, a method that alternates between the plug-in and importance sampling
estimators, is minimax rate-optimal for all sample sizes. Second, when the
behavior policy is unknown, we analyze performance in terms of the competitive
ratio, thereby revealing a fundamental gap between the settings of known and
unknown behavior policies. When the behavior policy is unknown, any estimator
must have mean-squared error larger -- relative to the oracle estimator
equipped with the knowledge of the behavior policy -- by a multiplicative
factor proportional to the support size of the target policy. Moreover, we
demonstrate that the plug-in approach achieves this worst-case competitive
ratio up to a logarithmic factor. Third, we initiate the study of the partial
knowledge setting in which it is assumed that the minimum probability taken by
the behavior policy is known. We show that the plug-in estimator is optimal for
relatively large values of the minimum probability, but is sub-optimal when the
minimum probability is low. In order to remedy this gap, we propose a new
estimator based on approximation by Chebyshev polynomials that provably
achieves the optimal estimation error. Numerical experiments on both simulated
and real data corroborate our theoretical findings.
</p>
<a href="http://arxiv.org/abs/2101.07781" target="_blank">arXiv:2101.07781</a> [<a href="http://arxiv.org/pdf/2101.07781" target="_blank">pdf</a>]

<h2>Learning the structure of Bayesian Networks via the bootstrap. (arXiv:1706.02386v2 [cs.LG] UPDATED)</h2>
<h3>Giulio Caravagna, Daniele Ramazzotti</h3>
<p>Learning the structure of dependencies among multiple random variables is a
problem of considerable theoretical and practical interest. Within the context
of Bayesian Networks, a practical and surprisingly successful solution to this
learning problem is achieved by adopting score-functions optimisation schema,
augmented with multiple restarts to avoid local optima. Yet, the conditions
under which such strategies work well are poorly understood, and there are also
some intrinsic limitations to learning the directionality of the interaction
among the variables. Following an early intuition of Friedman and Koller, we
propose to decouple the learning problem into two steps: first, we identify a
partial ordering among input variables which constrains the structural learning
problem, and then propose an effective bootstrap-based algorithm to simulate
augmented data sets, and select the most important dependencies among the
variables. By using several synthetic data sets, we show that our algorithm
yields better recovery performance than the state of the art, increasing the
chances of identifying a globally-optimal solution to the learning problem, and
solving also well-known identifiability issues that affect the standard
approach. We use our new algorithm to infer statistical dependencies between
cancer driver somatic mutations detected by high-throughput genome sequencing
data of multiple colorectal cancer patients. In this way, we also show how the
proposed methods can shade new insights about cancer initiation, and
progression. Code: https://github.com/caravagn/Bootstrap-based-Learning
</p>
<a href="http://arxiv.org/abs/1706.02386" target="_blank">arXiv:1706.02386</a> [<a href="http://arxiv.org/pdf/1706.02386" target="_blank">pdf</a>]

<h2>On the Benefit of Width for Neural Networks: Disappearance of Bad Basins. (arXiv:1812.11039v6 [cs.LG] UPDATED)</h2>
<h3>Dawei Li, Tian Ding, Ruoyu Sun</h3>
<p>Wide networks are often believed to have nice optimization landscape, but
what rigorous results can we prove? To understand the benefit of width, it is
important to identify the difference between wide and narrow networks. In this
work, we prove that from narrow to wide networks, there is a phase transition
from having sub-optimal basins to no sub-optimal basins. Specifically, we prove
two results: on the positive side, for any continuous activation functions, the
loss surface of a class of wide networks has no sub-optimal basin, where
"basin" is defined as the set-wise strict local minimum; on the negative side,
for a large class of networks with width below a threshold, we construct strict
local minima that are not global. These two results together show the phase
transition from narrow to wide networks.
</p>
<a href="http://arxiv.org/abs/1812.11039" target="_blank">arXiv:1812.11039</a> [<a href="http://arxiv.org/pdf/1812.11039" target="_blank">pdf</a>]

<h2>Fast Pedestrian Detection based on T-CENTRIST in infrared image. (arXiv:1902.06218v2 [cs.CV] UPDATED)</h2>
<h3>Hongyin Ni, Fengping Li</h3>
<p>Pedestrian detection is a research hotspot and a difficult issue in the
computer vision such as the Intelligent Surveillance System, the Intelligent
Transport System, robotics, and automotive safety. However, the human body's
position, angle, and dress in a video scene are complicated and changeable,
which have a great influence on the detection accuracy. In this paper, through
the analysis on the pros and cons of Census Transform Histogram (CENTRIST), a
novel feature is presented for human detection Ternary CENTRIST (T-CENTRIST).
The T-CENTRIST feature takes the relationship between each pixel and its
neighborhood pixels into account. Meanwhile, it also considers the relevancy
among these neighborhood pixels. Therefore, the proposed feature description
method can reflect the silhouette of pedestrian more adequately and accurately
than that of CENTRIST. Second, we propose a fast pedestrian detection framework
based on T-CENTRIST in infrared image, which introduces the idea of extended
blocks and the integral image. Finally, experimental results verify the
effectiveness of the proposed pedestrian detection method.
</p>
<a href="http://arxiv.org/abs/1902.06218" target="_blank">arXiv:1902.06218</a> [<a href="http://arxiv.org/pdf/1902.06218" target="_blank">pdf</a>]

<h2>Perfect reconstruction of sparse signals with piecewise continuous nonconvex penalties and nonconvexity control. (arXiv:1902.07436v2 [stat.ML] UPDATED)</h2>
<h3>Ayaka Sakata, Tomoyuki Obuchi</h3>
<p>We consider compressed sensing formulated as a minimization problem of
nonconvex sparse penalties, Smoothly Clipped Absolute deviation (SCAD) and
Minimax Concave Penalty (MCP). The nonconvexity of these penalties is
controlled by nonconvexity parameters, and L1 penalty is contained as a limit
with respect to these parameters. The analytically derived reconstruction limit
overcomes that of L1 and the algorithmic limit in the Bayes-optimal setting,
when the nonconvexity parameters have suitable values. However, for small
nonconvexity parameters, where the reconstruction of the relatively dense
signals is theoretically guaranteed, the corresponding approximate message
passing (AMP) cannot achieve perfect reconstruction. We identify that the
shrinks in the basin of attraction to the perfect reconstruction causes the
discrepancy between the AMP and corresponding theory using state evolution. A
part of the discrepancy is resolved by introducing the control of the
nonconvexity parameters to guide the AMP trajectory to the basin of the
attraction.
</p>
<a href="http://arxiv.org/abs/1902.07436" target="_blank">arXiv:1902.07436</a> [<a href="http://arxiv.org/pdf/1902.07436" target="_blank">pdf</a>]

<h2>An LBP-HOG Descriptor Based on Matrix Projection For Mammogram Classification. (arXiv:1904.00187v3 [cs.CV] UPDATED)</h2>
<h3>Zainab Alhakeem, Se-In Jang</h3>
<p>In image based feature descriptor design, local information from local image
patches are extracted using iterative scanning operations which cause high
computational costs. In order to avoid such scanning operations, we present
matrix multiplication based local feature descriptors, namely a Matrix
projection based Local Binary Pattern (M-LBP) descriptor and a Matrix
projection based Histogram of Oriented Gradients (M-HOG) descriptor.
Additionally, an integrated formulation of M-LBP and M-HOG (M-LBP-HOG) is also
proposed to perform the two descriptors together in a single step. The proposed
descriptors are evaluated using a publicly available mammogram database. The
results show promising performances in terms of classification accuracy and
computational efficiency.
</p>
<a href="http://arxiv.org/abs/1904.00187" target="_blank">arXiv:1904.00187</a> [<a href="http://arxiv.org/pdf/1904.00187" target="_blank">pdf</a>]

<h2>The MineRL 2019 Competition on Sample Efficient Reinforcement Learning using Human Priors. (arXiv:1904.10079v3 [cs.LG] UPDATED)</h2>
<h3>William H. Guss, Cayden Codel, Katja Hofmann, Brandon Houghton, Noboru Kuno, Stephanie Milani, Sharada Mohanty, Diego Perez Liebana, Ruslan Salakhutdinov, Nicholay Topin, Manuela Veloso, Phillip Wang</h3>
<p>Though deep reinforcement learning has led to breakthroughs in many difficult
domains, these successes have required an ever-increasing number of samples. As
state-of-the-art reinforcement learning (RL) systems require an exponentially
increasing number of samples, their development is restricted to a continually
shrinking segment of the AI community. Likewise, many of these systems cannot
be applied to real-world problems, where environment samples are expensive.
Resolution of these limitations requires new, sample-efficient methods. To
facilitate research in this direction, we introduce the MineRL Competition on
Sample Efficient Reinforcement Learning using Human Priors.

The primary goal of the competition is to foster the development of
algorithms which can efficiently leverage human demonstrations to drastically
reduce the number of samples needed to solve complex, hierarchical, and sparse
environments. To that end, we introduce: (1) the Minecraft ObtainDiamond task,
a sequential decision making environment requiring long-term planning,
hierarchical control, and efficient exploration methods; and (2) the MineRL-v0
dataset, a large-scale collection of over 60 million state-action pairs of
human demonstrations that can be resimulated into embodied trajectories with
arbitrary modifications to game state and visuals.

Participants will compete to develop systems which solve the ObtainDiamond
task with a limited number of samples from the environment simulator, Malmo.
The competition is structured into two rounds in which competitors are provided
several paired versions of the dataset and environment with different game
textures. At the end of each round, competitors will submit containerized
versions of their learning algorithms and they will then be trained/evaluated
from scratch on a hold-out dataset-environment pair for a total of 4-days on a
prespecified hardware platform.
</p>
<a href="http://arxiv.org/abs/1904.10079" target="_blank">arXiv:1904.10079</a> [<a href="http://arxiv.org/pdf/1904.10079" target="_blank">pdf</a>]

<h2>Limitation of capsule networks. (arXiv:1905.08744v4 [cs.LG] UPDATED)</h2>
<h3>David Peer, Sebastian Stabinger, Antonio Rodriguez-Sanchez</h3>
<p>A recently proposed method in deep learning groups multiple neurons to
capsules such that each capsule represents an object or part of an object.
Routing algorithms route the output of capsules from lower-level layers to
upper-level layers. In this paper, we prove that state-of-the-art routing
procedures decrease the expressivity of capsule networks. More precisely, it is
shown that EM-routing and routing-by-agreement prevent capsule networks from
distinguishing inputs and their negative counterpart. Therefore, only symmetric
functions can be expressed by capsule networks, and it can be concluded that
they are not universal approximators. We also theoretically motivate and
empirically show that this limitation affects the training of deep capsule
networks negatively. Therefore, we present an incremental improvement for
state-of-the-art routing algorithms that solves the aforementioned limitation
and stabilizes the training of capsule networks.
</p>
<a href="http://arxiv.org/abs/1905.08744" target="_blank">arXiv:1905.08744</a> [<a href="http://arxiv.org/pdf/1905.08744" target="_blank">pdf</a>]

<h2>Meta-Learning via Learned Loss. (arXiv:1906.05374v4 [cs.LG] UPDATED)</h2>
<h3>Sarah Bechtle, Artem Molchanov, Yevgen Chebotar, Edward Grefenstette, Ludovic Righetti, Gaurav Sukhatme, Franziska Meier</h3>
<p>Typically, loss functions, regularization mechanisms and other important
aspects of training parametric models are chosen heuristically from a limited
set of options. In this paper, we take the first step towards automating this
process, with the view of producing models which train faster and more
robustly. Concretely, we present a meta-learning method for learning parametric
loss functions that can generalize across different tasks and model
architectures. We develop a pipeline for meta-training such loss functions,
targeted at maximizing the performance of the model trained under them. The
loss landscape produced by our learned losses significantly improves upon the
original task-specific losses in both supervised and reinforcement learning
tasks. Furthermore, we show that our meta-learning framework is flexible enough
to incorporate additional information at meta-train time. This information
shapes the learned loss function such that the environment does not need to
provide this information during meta-test time. We make our code available at
https://sites.google.com/view/mlthree.
</p>
<a href="http://arxiv.org/abs/1906.05374" target="_blank">arXiv:1906.05374</a> [<a href="http://arxiv.org/pdf/1906.05374" target="_blank">pdf</a>]

<h2>Imitation Learning Based on Bilateral Control for Human-Robot Cooperation. (arXiv:1909.13018v5 [cs.RO] UPDATED)</h2>
<h3>Ayumu Sasagawa, Kazuki Fujimoto, Sho Sakaino, Toshiaki Tsuji</h3>
<p>Robots are required to autonomously respond to changing situations. Imitation
learning is a promising candidate for achieving generalization performance, and
extensive results have been demonstrated in object manipulation. However,
cooperative work between humans and robots is still a challenging issue because
robots must control dynamic interactions among themselves, humans, and objects.
Furthermore, it is difficult to follow subtle perturbations that may occur
among coworkers. In this study, we find that cooperative work can be
accomplished by imitation learning using bilateral control. Thanks to bilateral
control, which can extract response values and command values independently,
human skills to control dynamic interactions can be extracted. Then, the task
of serving food is considered. The experimental results clearly demonstrate the
importance of force control, and the dynamic interactions can be controlled by
the inferred action force.
</p>
<a href="http://arxiv.org/abs/1909.13018" target="_blank">arXiv:1909.13018</a> [<a href="http://arxiv.org/pdf/1909.13018" target="_blank">pdf</a>]

<h2>Quantized Reinforcement Learning (QUARL). (arXiv:1910.01055v4 [cs.LG] UPDATED)</h2>
<h3>Maximilian Lam, Sharad Chitlangia, Srivatsan Krishnan, Zishen Wan, Gabriel Barth-Maron, Aleksandra Faust, Vijay Janapa Reddi</h3>
<p>Deep reinforcement learning has achieved significant milestones, however, the
computational demands of reinforcement learning training and inference remain
substantial. Quantization is an effective method to reduce the computational
overheads of neural networks, though in the context of reinforcement learning,
it is unknown whether quantization's computational benefits outweigh the
accuracy costs introduced by the corresponding quantization error. To quantify
this tradeoff we perform a broad study applying quantization to reinforcement
learning. We apply standard quantization techniques such as post-training
quantization (PTQ) and quantization aware training (QAT) to a comprehensive set
of reinforcement learning tasks (Atari, Gym), algorithms (A2C, DDPG, DQN, D4PG,
PPO), and models (MLPs, CNNs) and show that policies may be quantized to 8-bits
without degrading reward, enabling significant inference speedups on
resource-constrained edge devices. Motivated by the effectiveness of standard
quantization techniques on reinforcement learning policies, we introduce a
novel quantization algorithm, \textit{ActorQ}, for quantized actor-learner
distributed reinforcement learning training. By leveraging full precision
optimization on the learner and quantized execution on the actors,
\textit{ActorQ} enables 8-bit inference while maintaining convergence. We
develop a system for quantized reinforcement learning training around
\textit{ActorQ} and demonstrate end to end speedups of $&gt;$ 1.5 $\times$ - 2.5
$\times$ over full precision training on a range of tasks (Deepmind Control
Suite). Finally, we break down the various runtime costs of distributed
reinforcement learning training (such as communication time, inference time,
model load time, etc) and evaluate the effects of quantization on these system
attributes.
</p>
<a href="http://arxiv.org/abs/1910.01055" target="_blank">arXiv:1910.01055</a> [<a href="http://arxiv.org/pdf/1910.01055" target="_blank">pdf</a>]

<h2>Decentralized Heterogeneous Multi-Player Multi-Armed Bandits with Non-Zero Rewards on Collisions. (arXiv:1910.09089v3 [cs.LG] UPDATED)</h2>
<h3>Akshayaa Magesh, Venugopal V. Veeravalli</h3>
<p>We consider a fully decentralized multi-player stochastic multi-armed bandit
setting where the players cannot communicate with each other and can observe
only their own actions and rewards. The environment may appear differently to
different players, $\textit{i.e.}$, the reward distributions for a given arm
are heterogeneous across players. In the case of a collision (when more than
one player plays the same arm), we allow for the colliding players to receive
non-zero rewards. The time-horizon $T$ for which the arms are played is
\emph{not} known to the players. Within this setup, where the number of players
is allowed to be greater than the number of arms, we present a policy that
achieves near order-optimal expected regret of order $O(\log^{1 + \delta} T)$
for some $0 &lt; \delta &lt; 1$ over a time-horizon of duration $T$.

This paper is currently under review at IEEE Transactions on Information
Theory.
</p>
<a href="http://arxiv.org/abs/1910.09089" target="_blank">arXiv:1910.09089</a> [<a href="http://arxiv.org/pdf/1910.09089" target="_blank">pdf</a>]

<h2>When does Diversity Help Generalization in Classification Ensembles?. (arXiv:1910.13631v2 [cs.LG] UPDATED)</h2>
<h3>Yijun Bian, Huanhuan Chen</h3>
<p>Ensembles, as a widely used and effective technique in the machine learning
community, succeed within a key element -- "diversity." The relationship
between diversity and generalization, unfortunately, is not entirely understood
and remains an open research issue. To reveal the effect of diversity on the
generalization of classification ensembles, we investigate three issues on
diversity, i.e., the measurement of diversity, the relationship between the
proposed diversity and the generalization error, and the utilization of this
relationship for ensemble pruning. In the diversity measurement, we measure
diversity by error decomposition inspired by regression ensembles, which
decomposes the error of classification ensembles into accuracy and diversity.
Then we formulate the relationship between the measured diversity and ensemble
performance through the theorem of margin and generalization and observe that
the generalization error is reduced effectively only when the measured
diversity is increased in a few specific ranges, while in other ranges larger
diversity is less beneficial to increasing the generalization of an ensemble.
Besides, we propose two pruning methods based on diversity management to
utilize this relationship, which could increase diversity appropriately and
shrink the size of the ensemble without much-decreasing performance. Empirical
results validate the reasonableness of the proposed relationship between
diversity and ensemble generalization error and the effectiveness of the
proposed pruning methods.
</p>
<a href="http://arxiv.org/abs/1910.13631" target="_blank">arXiv:1910.13631</a> [<a href="http://arxiv.org/pdf/1910.13631" target="_blank">pdf</a>]

<h2>Option Compatible Reward Inverse Reinforcement Learning. (arXiv:1911.02723v2 [cs.LG] UPDATED)</h2>
<h3>Rakhoon Hwang, Hanjin Lee, Hyung Ju Hwang</h3>
<p>Reinforcement learning in complex environments is a challenging problem. In
particular, the success of reinforcement learning algorithms depends on a
well-designed reward function. Inverse reinforcement learning (IRL) solves the
problem of recovering reward functions from expert demonstrations. In this
paper, we solve a hierarchical inverse reinforcement learning problem within
the options framework, which allows us to utilize intrinsic motivation of the
expert demonstrations. A gradient method for parametrized options is used to
deduce a defining equation for the Q-feature space, which leads to a reward
feature space. Using a second-order optimality condition for option parameters,
an optimal reward function is selected. Experimental results in both discrete
and continuous domains confirm that our recovered rewards provide a solution to
the IRL problem using temporal abstraction, which in turn are effective in
accelerating transfer learning tasks. We also show that our method is robust to
noises contained in expert demonstrations.
</p>
<a href="http://arxiv.org/abs/1911.02723" target="_blank">arXiv:1911.02723</a> [<a href="http://arxiv.org/pdf/1911.02723" target="_blank">pdf</a>]

<h2>Simple yet Effective Way for Improving the Performance of GAN. (arXiv:1911.10979v4 [cs.LG] UPDATED)</h2>
<h3>Yong-Goo Shin, Yoon-Jae Yeo, Sung-Jea Ko</h3>
<p>In adversarial learning, discriminator often fails to guide the generator
successfully since it distinguishes between real and generated images using
silly or non-robust features. To alleviate this problem, this brief presents a
simple but effective way that improves the performance of generative
adversarial network (GAN) without imposing the training overhead or modifying
the network architectures of existing methods. The proposed method employs a
novel cascading rejection (CR) module for discriminator, which extracts
multiple non-overlapped features in an iterative manner using the vector
rejection operation. Since the extracted diverse features prevent the
discriminator from concentrating on non-meaningful features, the discriminator
can guide the generator effectively to produce the images that are more similar
to the real images. In addition, since the proposed CR module requires only a
few simple vector operations, it can be readily applied to existing frameworks
with marginal training overheads. Quantitative evaluations on various datasets
including CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet confirm that the
proposed method significantly improves the performance of GAN and conditional
GAN in terms of Frechet inception distance (FID) indicating the diversity and
visual appearance of the generated images.
</p>
<a href="http://arxiv.org/abs/1911.10979" target="_blank">arXiv:1911.10979</a> [<a href="http://arxiv.org/pdf/1911.10979" target="_blank">pdf</a>]

<h2>Simple and Effective Prevention of Mode Collapse in Deep One-Class Classification. (arXiv:2001.08873v4 [cs.LG] UPDATED)</h2>
<h3>Penny Chong, Lukas Ruff, Marius Kloft, Alexander Binder</h3>
<p>Anomaly detection algorithms find extensive use in various fields. This area
of research has recently made great advances thanks to deep learning. A recent
method, the deep Support Vector Data Description (deep SVDD), which is inspired
by the classic kernel-based Support Vector Data Description (SVDD), is capable
of simultaneously learning a feature representation of the data and a
data-enclosing hypersphere. The method has shown promising results in both
unsupervised and semi-supervised settings. However, deep SVDD suffers from
hypersphere collapse -- also known as mode collapse, if the architecture of the
model does not comply with certain architectural constraints, e.g. the removal
of bias terms. These constraints limit the adaptability of the model and in
some cases, may affect the model performance due to learning sub-optimal
features. In this work, we consider two regularizers to prevent hypersphere
collapse in deep SVDD. The first regularizer is based on injecting random noise
via the standard cross-entropy loss. The second regularizer penalizes the
minibatch variance when it becomes too small. Moreover, we introduce an
adaptive weighting scheme to control the amount of penalization between the
SVDD loss and the respective regularizer. Our proposed regularized variants of
deep SVDD show encouraging results and outperform a prominent state-of-the-art
method on a setup where the anomalies have no apparent geometrical structure.
</p>
<a href="http://arxiv.org/abs/2001.08873" target="_blank">arXiv:2001.08873</a> [<a href="http://arxiv.org/pdf/2001.08873" target="_blank">pdf</a>]

<h2>Attention-guided Chained Context Aggregation for Semantic Segmentation. (arXiv:2002.12041v3 [cs.CV] UPDATED)</h2>
<h3>Quan Tang, Fagui Liu, Tong Zhang, Jun Jiang, Yu Zhang</h3>
<p>The way features propagate in Fully Convolutional Networks is of momentous
importance to capture multi-scale contexts for obtaining precise segmentation
masks. This paper proposes a novel series-parallel hybrid paradigm called the
Chained Context Aggregation Module (CAM) to diversify feature propagation. CAM
gains features of various spatial scales through chain-connected ladder-style
information flows and fuses them in a two-stage process, namely pre-fusion and
re-fusion. The serial flow continuously increases receptive fields of output
neurons and those in parallel encode different region-based contexts. Each
information flow is a shallow encoder-decoder with appropriate down-sampling
scales to sufficiently capture contextual information. We further adopt an
attention model in CAM to guide feature re-fusion. Based on these developments,
we construct the Chained Context Aggregation Network (CANet), which employs an
asymmetric decoder to recover precise spatial details of prediction maps. We
conduct extensive experiments on six challenging datasets, including Pascal VOC
2012, Pascal Context, Cityscapes, CamVid, SUN-RGBD and GATECH. Results evidence
that CANet achieves state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2002.12041" target="_blank">arXiv:2002.12041</a> [<a href="http://arxiv.org/pdf/2002.12041" target="_blank">pdf</a>]

<h2>SUOD: Accelerating Large-scale Unsupervised Heterogeneous Outlier Detection. (arXiv:2003.05731v3 [cs.LG] UPDATED)</h2>
<h3>Yue Zhao, Xiyang Hu, Cheng Cheng, Cong Wang, Changlin Wan, Wen Wang, Jianing Yang, Haoping Bai, Zheng Li, Cao Xiao, Yunlong Wang, Zhi Qiao, Jimeng Sun, Leman Akoglu</h3>
<p>Outlier detection (OD) is a key data mining task for identifying abnormal
objects from general samples with numerous high-stake applications including
fraud detection and intrusion detection. Due to the lack of ground truth
labels, practitioners often have to build a large number of unsupervised models
that are heterogeneous (i.e., different algorithms and hyperparameters) for
further combination and analysis with ensemble learning, rather than relying on
a single model. However, this yields severe scalability issues on
high-dimensional, large datasets.

How to accelerate the training and predicting with a large number of
heterogeneous unsupervised OD models? How to ensure the acceleration does not
deteriorate detection models' accuracy? How to accommodate the acceleration
need for both a single worker setting and a distributed system with multiple
workers? In this study, we propose a three-module acceleration system called
SUOD (scalable unsupervised outlier detection) to address these questions. It
focuses on three complementary aspects to accelerate (dimensionality reduction
for high-dimensional data, model approximation for complex models, and
execution efficiency improvement for taskload imbalance within distributed
systems), while controlling detection performance degradation. Extensive
experiments on more than 20 benchmark datasets demonstrate SUOD's effectiveness
in heterogeneous OD acceleration. By the submission time, the released
open-source system has been widely used with more than 700,000 times downloads.
A real-world deployment case on fraudulent claim analysis at IQVIA, a leading
healthcare firm, is also provided.
</p>
<a href="http://arxiv.org/abs/2003.05731" target="_blank">arXiv:2003.05731</a> [<a href="http://arxiv.org/pdf/2003.05731" target="_blank">pdf</a>]

<h2>Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations. (arXiv:2003.08938v5 [cs.LG] UPDATED)</h2>
<h3>Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, Mingyan Liu, Duane Boning, Cho-Jui Hsieh</h3>
<p>A deep reinforcement learning (DRL) agent observes its states through
observations, which may contain natural measurement errors or adversarial
noises. Since the observations deviate from the true states, they can mislead
the agent into making suboptimal actions. Several works have shown this
vulnerability via adversarial attacks, but existing approaches on improving the
robustness of DRL under this setting have limited success and lack theoretical
principles. We show that naively applying existing techniques on improving the
robustness for classification tasks, like adversarial training, are ineffective
for many RL tasks. We propose the state-adversarial Markov decision process
(SA-MDP) to study the fundamental properties of this problem and develop a
theoretically principled policy regularization that can be applied to a large
family of DRL algorithms, including proximal policy optimization (PPO), deep
deterministic policy gradient (DDPG) and deep Qnetworks (DQN), for both
discrete and continuous action control problems. We significantly improve the
robustness of PPO, DDPG, and DQN agents under a suite of strong white box
adversarial attacks, including new attacks of our own. Additionally, we find
that a robust policy noticeably improves DRL performance even without an
adversary in a number of environments. Our code is available
athttps://github.com/chenhongge/StateAdvDRL.
</p>
<a href="http://arxiv.org/abs/2003.08938" target="_blank">arXiv:2003.08938</a> [<a href="http://arxiv.org/pdf/2003.08938" target="_blank">pdf</a>]

<h2>Convolutional Spiking Neural Networks for Spatio-Temporal Feature Extraction. (arXiv:2003.12346v2 [cs.CV] UPDATED)</h2>
<h3>Ali Samadzadeh, Fatemeh Sadat Tabatabaei Far, Ali Javadi, Ahmad Nickabadi, Morteza Haghir Chehreghani</h3>
<p>Spiking neural networks (SNNs) can be used in low-power and embedded systems
(such as emerging neuromorphic chips) due to their event-based nature. Also,
they have the advantage of low computation cost in contrast to conventional
artificial neural networks (ANNs), while preserving ANN's properties. However,
temporal coding in layers of convolutional spiking neural networks and other
types of SNNs has yet to be studied. In this paper, we provide insight into
spatio-temporal feature extraction of convolutional SNNs in experiments
designed to exploit this property. The shallow convolutional SNN outperforms
state-of-the-art spatio-temporal feature extractor methods such as C3D,
ConvLstm, and similar networks. Furthermore, we present a new deep spiking
architecture to tackle real-world problems (in particular classification tasks)
which achieved superior performance compared to other SNN methods on NMNIST
(99.6%), DVS-CIFAR10 (69.2%) and DVS-Gesture (96.7%) and ANN methods on UCF-101
(42.1%) and HMDB-51 (21.5%) datasets. It is also worth noting that the training
process is implemented based on variation of spatio-temporal backpropagation
explained in the paper.
</p>
<a href="http://arxiv.org/abs/2003.12346" target="_blank">arXiv:2003.12346</a> [<a href="http://arxiv.org/pdf/2003.12346" target="_blank">pdf</a>]

<h2>In-Hand Object-Dynamics Inference using Tactile Fingertips. (arXiv:2003.13165v2 [cs.RO] UPDATED)</h2>
<h3>Balakumar Sundaralingam, Tucker Hermans</h3>
<p>Having the ability to estimate an object's properties through interaction
will enable robots to manipulate novel objects. Object's dynamics, specifically
the friction and inertial parameters have only been estimated in a lab
environment with precise and often external sensing. Could we infer an object's
dynamics in the wild with only the robot's sensors? In this paper, we explore
the estimation of dynamics of a grasped object in motion, with tactile force
sensing at multiple fingertips. Our estimation approach does not rely on torque
sensing to estimate the dynamics. To estimate friction, we develop a control
scheme to actively interact with the object until slip is detected. To robustly
perform the inertial estimation, we setup a factor graph that fuses all our
sensor measurements on physically consistent manifolds and perform inference.
We show that tactile fingertips enable in-hand dynamics estimation of low mass
objects.
</p>
<a href="http://arxiv.org/abs/2003.13165" target="_blank">arXiv:2003.13165</a> [<a href="http://arxiv.org/pdf/2003.13165" target="_blank">pdf</a>]

<h2>Attend and Decode: 4D fMRI Task State Decoding Using Attention Models. (arXiv:2004.05234v2 [cs.CV] UPDATED)</h2>
<h3>Sam Nguyen, Brenda Ng, Alan D. Kaplan, Priyadip Ray</h3>
<p>Functional magnetic resonance imaging (fMRI) is a neuroimaging modality that
captures the blood oxygen level in a subject's brain while the subject either
rests or performs a variety of functional tasks under different conditions.
Given fMRI data, the problem of inferring the task, known as task state
decoding, is challenging due to the high dimensionality (hundreds of million
sampling points per datum) and complex spatio-temporal blood flow patterns
inherent in the data. In this work, we propose to tackle the fMRI task state
decoding problem by casting it as a 4D spatio-temporal classification problem.
We present a novel architecture called Brain Attend and Decode (BAnD), that
uses residual convolutional neural networks for spatial feature extraction and
self-attention mechanisms for temporal modeling. We achieve significant
performance gain compared to previous works on a 7-task benchmark from the
large-scale Human Connectome Project-Young Adult (HCP-YA) dataset. We also
investigate the transferability of BAnD's extracted features on unseen HCP
tasks, either by freezing the spatial feature extraction layers and retraining
the temporal model, or finetuning the entire model. The pre-trained features
from BAnD are useful on similar tasks while finetuning them yields competitive
results on unseen tasks/conditions.
</p>
<a href="http://arxiv.org/abs/2004.05234" target="_blank">arXiv:2004.05234</a> [<a href="http://arxiv.org/pdf/2004.05234" target="_blank">pdf</a>]

<h2>Distilling Localization for Self-Supervised Representation Learning. (arXiv:2004.06638v2 [cs.CV] UPDATED)</h2>
<h3>Nanxuan Zhao, Zhirong Wu, Rynson W.H. Lau, Stephen Lin</h3>
<p>Recent progress in contrastive learning has revolutionized unsupervised
representation learning. Concretely, multiple views (augmentations) from the
same image are encouraged to map to the similar embeddings, while views from
different images are pulled apart. In this paper, through visualizing and
diagnosing classification errors, we observe that current contrastive models
are ineffective at localizing the foreground object, limiting their ability to
extract discriminative high-level features. This is due to the fact that view
generation process considers pixels in an image uniformly. To address this
problem, we propose a data-driven approach for learning invariance to
backgrounds. It first estimates foreground saliency in images and then creates
augmentations by copy-and-pasting the foreground onto a variety of backgrounds.
The learning still follows the instance discrimination pretext task, so that
the representation is trained to disregard background content and focus on the
foreground. We study a variety of saliency estimation methods, and find that
most methods lead to improvements for contrastive learning. With this approach
(DiLo), significant performance is achieved for self-supervised learning on
ImageNet classification, and also for object detection on PASCAL VOC and
MSCOCO.
</p>
<a href="http://arxiv.org/abs/2004.06638" target="_blank">arXiv:2004.06638</a> [<a href="http://arxiv.org/pdf/2004.06638" target="_blank">pdf</a>]

<h2>Detection of Makeup Presentation Attacks based on Deep Face Representations. (arXiv:2006.05074v2 [cs.CV] UPDATED)</h2>
<h3>Christian Rathgeb, Pawel Drozdowski, Christoph Busch</h3>
<p>Facial cosmetics have the ability to substantially alter the facial
appearance, which can negatively affect the decisions of a face recognition. In
addition, it was recently shown that the application of makeup can be abused to
launch so-called makeup presentation attacks. In such attacks, the attacker
might apply heavy makeup in order to achieve the facial appearance of a target
subject for the purpose of impersonation. In this work, we assess the
vulnerability of a COTS face recognition system to makeup presentation attacks
employing the publicly available Makeup Induced Face Spoofing (MIFS) database.
It is shown that makeup presentation attacks might seriously impact the
security of the face recognition system. Further, we propose an attack
detection scheme which distinguishes makeup presentation attacks from genuine
authentication attempts by analysing differences in deep face representations
obtained from potential makeup presentation attacks and corresponding target
face images. The proposed detection system employs a machine learning-based
classifier, which is trained with synthetically generated makeup presentation
attacks utilizing a generative adversarial network for facial makeup transfer
in conjunction with image warping. Experimental evaluations conducted using the
MIFS database reveal a detection equal error rate of 0.7% for the task of
separating genuine authentication attempts from makeup presentation attacks.
</p>
<a href="http://arxiv.org/abs/2006.05074" target="_blank">arXiv:2006.05074</a> [<a href="http://arxiv.org/pdf/2006.05074" target="_blank">pdf</a>]

<h2>What makes instance discrimination good for transfer learning?. (arXiv:2006.06606v2 [cs.CV] UPDATED)</h2>
<h3>Nanxuan Zhao, Zhirong Wu, Rynson W.H. Lau, Stephen Lin</h3>
<p>Contrastive visual pretraining based on the instance discrimination pretext
task has made significant progress. Notably, recent work on unsupervised
pretraining has shown to surpass the supervised counterpart for finetuning
downstream applications such as object detection and segmentation. It comes as
a surprise that image annotations would be better left unused for transfer
learning. In this work, we investigate the following problems: What makes
instance discrimination pretraining good for transfer learning? What knowledge
is actually learned and transferred from these models? From this understanding
of instance discrimination, how can we better exploit human annotation labels
for pretraining? Our findings are threefold. First, what truly matters for the
transfer is low-level and mid-level representations, not high-level
representations. Second, the intra-category invariance enforced by the
traditional supervised model weakens transferability by increasing task
misalignment. Finally, supervised pretraining can be strengthened by following
an exemplar-based approach without explicit constraints among the instances
within the same category.
</p>
<a href="http://arxiv.org/abs/2006.06606" target="_blank">arXiv:2006.06606</a> [<a href="http://arxiv.org/pdf/2006.06606" target="_blank">pdf</a>]

<h2>3D Reconstruction of Novel Object Shapes from Single Images. (arXiv:2006.07752v3 [cs.CV] UPDATED)</h2>
<h3>Anh Thai, Stefan Stojanov, Vijay Upadhya, James M. Rehg</h3>
<p>The key challenge in single image 3D shape reconstruction is to ensure that
deep models can generalize to shapes which were not part of the training set.
This is challenging because the algorithm must infer the occluded portion of
the surface by leveraging a representation learned based on the shape
characteristics of the training data, and is therefore vulnerable to
overfitting. Such generalization to unseen categories of objects is a function
of both architecture design and training approaches. This paper introduces
SDFNet, a novel shape prediction architecture and training approach which
supports effective generalization. We provide an extensive investigation of the
factors which influence generalization accuracy and its measurement, ranging
from the consistent use of 3D shape metrics to the choice of rendering approach
and the large-scale evaluation on unseen shapes using ShapeNetCore.v2 and ABC.
We show that SDFNet provides state-of-the-art performance on seen and unseen
shapes relative to existing baseline methods GenRe and OccNet. We provide the
first large-scale experimental evaluation of generalization performance. The
codebase released with this article will allow for the consistent evaluation
and comparison of methods for single image shape reconstruction.
</p>
<a href="http://arxiv.org/abs/2006.07752" target="_blank">arXiv:2006.07752</a> [<a href="http://arxiv.org/pdf/2006.07752" target="_blank">pdf</a>]

<h2>Hyperbolic Neural Networks++. (arXiv:2006.08210v2 [cs.LG] UPDATED)</h2>
<h3>Ryohei Shimizu, Yusuke Mukuta, Tatsuya Harada</h3>
<p>Hyperbolic spaces, which have the capacity to embed tree structures without
distortion owing to their exponential volume growth, have recently been applied
to machine learning to better capture the hierarchical nature of data. In this
study, we generalize the fundamental components of neural networks in a single
hyperbolic geometry model, namely, the Poincar\'e ball model. This novel
methodology constructs a multinomial logistic regression, fully-connected
layers, convolutional layers, and attention mechanisms under a unified
mathematical interpretation, without increasing the parameters. Experiments
show the superior parameter efficiency of our methods compared to conventional
hyperbolic components, and stability and outperformance over their Euclidean
counterparts.
</p>
<a href="http://arxiv.org/abs/2006.08210" target="_blank">arXiv:2006.08210</a> [<a href="http://arxiv.org/pdf/2006.08210" target="_blank">pdf</a>]

<h2>Mitigating Gender Bias in Captioning Systems. (arXiv:2006.08315v4 [cs.CV] UPDATED)</h2>
<h3>Ruixiang Tang, Mengnan Du, Yuening Li, Zirui Liu, Na Zou, Xia Hu</h3>
<p>Image captioning has made substantial progress with huge supporting image
collections sourced from the web. However, recent studies have pointed out that
captioning datasets, such as COCO, contain gender bias found in web corpora. As
a result, learning models could heavily rely on the learned priors and image
context for gender identification, leading to incorrect or even offensive
errors. To encourage models to learn correct gender features, we reorganize the
COCO dataset and present two new splits COCO-GB V1 and V2 datasets where the
train and test sets have different gender-context joint distribution. Models
relying on contextual cues will suffer from huge gender prediction errors on
the anti-stereotypical test data. Benchmarking experiments reveal that most
captioning models learn gender bias, leading to high gender prediction errors,
especially for women. To alleviate the unwanted bias, we propose a new Guided
Attention Image Captioning model (GAIC) which provides self-guidance on visual
attention to encourage the model to capture correct gender visual evidence.
Experimental results validate that GAIC can significantly reduce gender
prediction errors with a competitive caption quality. Our codes and the
designed benchmark datasets are available at
https://github.com/CaptionGenderBias2020.
</p>
<a href="http://arxiv.org/abs/2006.08315" target="_blank">arXiv:2006.08315</a> [<a href="http://arxiv.org/pdf/2006.08315" target="_blank">pdf</a>]

<h2>Network Diffusions via Neural Mean-Field Dynamics. (arXiv:2006.09449v3 [cs.LG] UPDATED)</h2>
<h3>Shushan He, Hongyuan Zha, Xiaojing Ye</h3>
<p>We propose a novel learning framework based on neural mean-field dynamics for
inference and estimation problems of diffusion on networks. Our new framework
is derived from the Mori-Zwanzig formalism to obtain an exact evolution of the
node infection probabilities, which renders a delay differential equation with
memory integral approximated by learnable time convolution operators, resulting
in a highly structured and interpretable RNN. Directly using cascade data, our
framework can jointly learn the structure of the diffusion network and the
evolution of infection probabilities, which are cornerstone to important
downstream applications such as influence maximization. Connections between
parameter learning and optimal control are also established. Empirical study
shows that our approach is versatile and robust to variations of the underlying
diffusion network models, and significantly outperform existing approaches in
accuracy and efficiency on both synthetic and real-world data.
</p>
<a href="http://arxiv.org/abs/2006.09449" target="_blank">arXiv:2006.09449</a> [<a href="http://arxiv.org/pdf/2006.09449" target="_blank">pdf</a>]

<h2>Matrix Completion with Quantified Uncertainty through Low Rank Gaussian Copula. (arXiv:2006.10829v2 [stat.ML] UPDATED)</h2>
<h3>Yuxuan Zhao, Madeleine Udell</h3>
<p>Modern large scale datasets are often plagued with missing entries. For
tabular data with missing values, a flurry of imputation algorithms solve for a
complete matrix which minimizes some penalized reconstruction error. However,
almost none of them can estimate the uncertainty of its imputations. This paper
proposes a probabilistic and scalable framework for missing value imputation
with quantified uncertainty. Our model, the Low Rank Gaussian Copula, augments
a standard probabilistic model, Probabilistic Principal Component Analysis,
with marginal transformations for each column that allow the model to better
match the distribution of the data. It naturally handles Boolean, ordinal, and
real-valued observations and quantifies the uncertainty in each imputation. The
time required to fit the model scales linearly with the number of rows and the
number of columns in the dataset. Empirical results show the method yields
state-of-the-art imputation accuracy across a wide range of data types,
including those with high rank. Our uncertainty measure predicts imputation
error well: entries with lower uncertainty do have lower imputation error (on
average). Moreover, for real-valued data, the resulting confidence intervals
are well-calibrated.
</p>
<a href="http://arxiv.org/abs/2006.10829" target="_blank">arXiv:2006.10829</a> [<a href="http://arxiv.org/pdf/2006.10829" target="_blank">pdf</a>]

<h2>Encoding Legal Balancing: Automating an Abstract Ethico-Legal Value Ontology in Preference Logic. (arXiv:2006.12789v2 [cs.AI] UPDATED)</h2>
<h3>Christoph Benzm&#xfc;ller, David Fuenmayor, Bertram Lomfeld</h3>
<p>Enabling machines to legal balancing is a non-trivial task challenged by a
multitude of factors some of which are addressed and explored in this work. We
propose a holistic approach to formal modelling at different abstraction layers
supported by a pluralistic framework in which the encoding of an ethico-legal
value ontology is developed in combination with the exploration of a
formalisation logic, with legal domain knowledge and with exemplary use cases
until a reflective equilibrium is reached. Our work is enabled by a
meta-logical approach to universal logical reasoning and it applies the
recently introduced LOGIKEY methodology for designing normative theories for
ethical and legal reasoning. We explore and illustrate the application of the
multilayered LOGIKEY approach for the modelling of legal and world knowledge
that is constrained by context-dependent value preferences. The framework is
then exemplary applied for explaining and resolving legal conflicts in property
law (wild animal cases) within a modern proof assistant system.
</p>
<a href="http://arxiv.org/abs/2006.12789" target="_blank">arXiv:2006.12789</a> [<a href="http://arxiv.org/pdf/2006.12789" target="_blank">pdf</a>]

<h2>Meta Soft Label Generation for Noisy Labels. (arXiv:2007.05836v2 [cs.CV] UPDATED)</h2>
<h3>G&#xf6;rkem Algan, Ilkay Ulusoy</h3>
<p>The existence of noisy labels in the dataset causes significant performance
degradation for deep neural networks (DNNs). To address this problem, we
propose a Meta Soft Label Generation algorithm called MSLG, which can jointly
generate soft labels using meta-learning techniques and learn DNN parameters in
an end-to-end fashion. Our approach adapts the meta-learning paradigm to
estimate optimal label distribution by checking gradient directions on both
noisy training data and noise-free meta-data. In order to iteratively update
soft labels, meta-gradient descent step is performed on estimated labels, which
would minimize the loss of noise-free meta samples. In each iteration, the base
classifier is trained on estimated meta labels. MSLG is model-agnostic and can
be added on top of any existing model at hand with ease. We performed extensive
experiments on CIFAR10, Clothing1M and Food101N datasets. Results show that our
approach outperforms other state-of-the-art methods by a large margin.
</p>
<a href="http://arxiv.org/abs/2007.05836" target="_blank">arXiv:2007.05836</a> [<a href="http://arxiv.org/pdf/2007.05836" target="_blank">pdf</a>]

<h2>Adaptive Periodic Averaging: A Practical Approach to Reducing Communication in Distributed Learning. (arXiv:2007.06134v2 [cs.LG] UPDATED)</h2>
<h3>Peng Jiang, Gagan Agrawal</h3>
<p>Stochastic Gradient Descent (SGD) is the key learning algorithm for many
machine learning tasks. Because of its computational costs, there is a growing
interest in accelerating SGD on HPC resources like GPU clusters. However, the
performance of parallel SGD is still bottlenecked by the high communication
costs even with a fast connection among the machines. A simple approach to
alleviating this problem, used in many existing efforts, is to perform
communication every few iterations, using a constant averaging period. In this
paper, we show that the optimal averaging period in terms of convergence and
communication cost is not a constant, but instead varies over the course of the
execution. Specifically, we observe that reducing the variance of model
parameters among the computing nodes is critical to the convergence of periodic
parameter averaging SGD. Given a fixed communication budget, we show that it is
more beneficial to synchronize more frequently in early iterations to reduce
the initial large variance and synchronize less frequently in the later phase
of the training process. We propose a practical algorithm, named ADaptive
Periodic parameter averaging SGD (ADPSGD), to achieve a smaller overall
variance of model parameters, and thus better convergence compared with the
Constant Periodic parameter averaging SGD (CPSGD). We evaluate our method with
several image classification benchmarks and show that our ADPSGD indeed
achieves smaller training losses and higher test accuracies with smaller
communication compared with CPSGD. Compared with gradient-quantization SGD, we
show that our algorithm achieves faster convergence with only half of the
communication. Compared with full-communication SGD, our ADPSGD achieves 1:14x
to 1:27x speedups with a 100Gbps connection among computing nodes, and the
speedups increase to 1:46x ~ 1:95x with a 10Gbps connection.
</p>
<a href="http://arxiv.org/abs/2007.06134" target="_blank">arXiv:2007.06134</a> [<a href="http://arxiv.org/pdf/2007.06134" target="_blank">pdf</a>]

<h2>Explicit Regularisation in Gaussian Noise Injections. (arXiv:2007.07368v6 [stat.ML] UPDATED)</h2>
<h3>Alexander Camuto, Matthew Willetts, Umut &#x15e;im&#x15f;ekli, Stephen Roberts, Chris Holmes</h3>
<p>We study the regularisation induced in neural networks by Gaussian noise
injections (GNIs). Though such injections have been extensively studied when
applied to data, there have been few studies on understanding the regularising
effect they induce when applied to network activations. Here we derive the
explicit regulariser of GNIs, obtained by marginalising out the injected noise,
and show that it penalises functions with high-frequency components in the
Fourier domain; particularly in layers closer to a neural network's output. We
show analytically and empirically that such regularisation produces calibrated
classifiers with large classification margins.
</p>
<a href="http://arxiv.org/abs/2007.07368" target="_blank">arXiv:2007.07368</a> [<a href="http://arxiv.org/pdf/2007.07368" target="_blank">pdf</a>]

<h2>BRP-NAS: Prediction-based NAS using GCNs. (arXiv:2007.08668v4 [cs.LG] UPDATED)</h2>
<h3>&#x141;ukasz Dudziak, Thomas Chau, Mohamed S. Abdelfattah, Royson Lee, Hyeji Kim, Nicholas D. Lane</h3>
<p>Neural architecture search (NAS) enables researchers to automatically explore
broad design spaces in order to improve efficiency of neural networks. This
efficiency is especially important in the case of on-device deployment, where
improvements in accuracy should be balanced out with computational demands of a
model. In practice, performance metrics of model are computationally expensive
to obtain. Previous work uses a proxy (e.g., number of operations) or a
layer-wise measurement of neural network layers to estimate end-to-end hardware
performance but the imprecise prediction diminishes the quality of NAS. To
address this problem, we propose BRP-NAS, an efficient hardware-aware NAS
enabled by an accurate performance predictor-based on graph convolutional
network (GCN). What is more, we investigate prediction quality on different
metrics and show that sample efficiency of the predictor-based NAS can be
improved by considering binary relations of models and an iterative data
selection strategy. We show that our proposed method outperforms all prior
methods on NAS-Bench-101 and NAS-Bench-201, and that our predictor can
consistently learn to extract useful features from the DARTS search space,
improving upon the second-order baseline. Finally, to raise awareness of the
fact that accurate latency estimation is not a trivial task, we release
LatBench -- a latency dataset of NAS-Bench-201 models running on a broad range
of devices.
</p>
<a href="http://arxiv.org/abs/2007.08668" target="_blank">arXiv:2007.08668</a> [<a href="http://arxiv.org/pdf/2007.08668" target="_blank">pdf</a>]

<h2>DNN2LR: Interpretation-inspired Feature Crossing for Real-world Tabular Data. (arXiv:2008.09775v5 [cs.LG] UPDATED)</h2>
<h3>Zhaocheng Liu, Qiang Liu, Haoli Zhang, Yuntian Chen</h3>
<p>For sake of reliability, it is necessary for models in real-world
applications to be both powerful and globally interpretable. Simple
classifiers, e.g., Logistic Regression (LR), are globally interpretable, but
not powerful enough to model complex nonlinear interactions among features in
tabular data. Meanwhile, Deep Neural Networks (DNNs) have shown great
effectiveness for modeling tabular data, but is not globally interpretable. In
this work, we find local piece-wise interpretations in DNN of a specific
feature are usually inconsistent in different samples, which is caused by
feature interactions in the hidden layers. Accordingly, we can design an
automatic feature crossing method to find feature interactions in DNN, and use
them as cross features in LR. We give definition of the interpretation
inconsistency in DNN, based on which a novel feature crossing method called
DNN2LR is proposed. Extensive experiments have been conducted on four public
datasets and two real-world datasets. The final model, i.e., a LR model
empowered with cross features, generated by DNN2LR can outperform the complex
DNN model, as well as several state-of-the-art feature crossing methods. The
experimental results strongly verify the effectiveness and efficiency of
DNN2LR, especially on real-world datasets with large numbers of feature fields.
</p>
<a href="http://arxiv.org/abs/2008.09775" target="_blank">arXiv:2008.09775</a> [<a href="http://arxiv.org/pdf/2008.09775" target="_blank">pdf</a>]

<h2>Non-exponentially weighted aggregation: regret bounds for unbounded loss functions. (arXiv:2009.03017v4 [stat.ML] UPDATED)</h2>
<h3>Pierre Alquier</h3>
<p>We tackle the problem of online optimization with a general, possibly
unbounded, loss function. It is well known that when the loss is bounded, the
exponentially weighted aggregation strategy (EWA) leads to a regret in
$\sqrt{T}$ after $T$ steps. In this paper, we study a generalized aggregation
strategy, where the weights do no longer depend exponentially on the losses.
Our strategy is defined as the minimizer of the expected losses plus a
regularizer. When this regularizer is the Kullback-Leibler divergence, we
obtain EWA as a special case, but using alternative divergences lead to regret
bounds for unbounded losses, at the cost of a worst regret bound in some cases.
</p>
<a href="http://arxiv.org/abs/2009.03017" target="_blank">arXiv:2009.03017</a> [<a href="http://arxiv.org/pdf/2009.03017" target="_blank">pdf</a>]

<h2>DIRV: Dense Interaction Region Voting for End-to-End Human-Object Interaction Detection. (arXiv:2010.01005v2 [cs.CV] UPDATED)</h2>
<h3>Hao-Shu Fang, Yichen Xie, Dian Shao, Cewu Lu</h3>
<p>Recent years, human-object interaction (HOI) detection has achieved
impressive advances. However, conventional two-stage methods are usually slow
in inference. On the other hand, existing one-stage methods mainly focus on the
union regions of interactions, which introduce unnecessary visual information
as disturbances to HOI detection. To tackle the problems above, we propose a
novel one-stage HOI detection approach DIRV in this paper, based on a new
concept called interaction region for the HOI problem. Unlike previous methods,
our approach concentrates on the densely sampled interaction regions across
different scales for each human-object pair, so as to capture the subtle visual
features that is most essential to the interaction. Moreover, in order to
compensate for the detection flaws of a single interaction region, we introduce
a novel voting strategy that makes full use of those overlapped interaction
regions in place of conventional Non-Maximal Suppression (NMS). Extensive
experiments on two popular benchmarks: V-COCO and HICO-DET show that our
approach outperforms existing state-of-the-arts by a large margin with the
highest inference speed and lightest network architecture. We achieved 56.1 mAP
on V-COCO without addtional input. Our code is publicly available at:
https://github.com/MVIG-SJTU/DIRV
</p>
<a href="http://arxiv.org/abs/2010.01005" target="_blank">arXiv:2010.01005</a> [<a href="http://arxiv.org/pdf/2010.01005" target="_blank">pdf</a>]

<h2>Transformers for Modeling Physical Systems. (arXiv:2010.03957v3 [cs.LG] UPDATED)</h2>
<h3>Nicholas Geneva, Nicholas Zabaras</h3>
<p>Transformers are widely used in neural language processing due to their
ability to model longer-term dependencies in text. Although these models
achieve state-of-the-art performance for many language related tasks, their
applicability outside of the neural language processing field has been minimal.
In this work, we propose the use of transformer models for the prediction of
dynamical systems representative of physical phenomena. The use of Koopman
based embeddings provide a unique and powerful method for projecting any
dynamical system into a vector representation which can then be predicted by a
transformer model. The proposed model is able to accurately predict various
dynamical systems and outperform classical methods that are commonly used in
the scientific machine learning literature.
</p>
<a href="http://arxiv.org/abs/2010.03957" target="_blank">arXiv:2010.03957</a> [<a href="http://arxiv.org/pdf/2010.03957" target="_blank">pdf</a>]

<h2>A Series of Unfortunate Counterfactual Events: the Role of Time in Counterfactual Explanations. (arXiv:2010.04687v2 [cs.AI] UPDATED)</h2>
<h3>Andrea Ferrario, Michele Loi</h3>
<p>Counterfactual explanations are a prominent example of post-hoc
interpretability methods in the explainable Artificial Intelligence research
domain. They provide individuals with alternative scenarios and a set of
recommendations to achieve a sought-after machine learning model outcome.
Recently, the literature has identified desiderata of counterfactual
explanations, such as feasibility, actionability and sparsity that should
support their applicability in real-world contexts. However, we show that the
literature has neglected the problem of the time dependency of counterfactual
explanations. We argue that, due to their time dependency and because of the
provision of recommendations, even feasible, actionable and sparse
counterfactual explanations may not be appropriate in real-world applications.
This is due to the possible emergence of what we call "unfortunate
counterfactual events." These events may occur due to the retraining of machine
learning models whose outcomes have to be explained via counterfactual
explanation. Series of unfortunate counterfactual events frustrate the efforts
of those individuals who successfully implemented the recommendations of
counterfactual explanations. This negatively affects people's trust in the
ability of institutions to provide machine learning-supported decisions
consistently. We introduce an approach to address the problem of the emergence
of unfortunate counterfactual events that makes use of histories of
counterfactual explanations. In the final part of the paper we propose an
ethical analysis of two distinct strategies to cope with the challenge of
unfortunate counterfactual events. We show that they respond to an ethically
responsible imperative to preserve the trustworthiness of credit lending
organizations, the decision models they employ, and the social-economic
function of credit lending.
</p>
<a href="http://arxiv.org/abs/2010.04687" target="_blank">arXiv:2010.04687</a> [<a href="http://arxiv.org/pdf/2010.04687" target="_blank">pdf</a>]

<h2>Discovering Discriminative Geometric Features with Self-Supervised Attention for Vehicle Re-Identification and Beyond. (arXiv:2010.09221v2 [cs.CV] UPDATED)</h2>
<h3>Ming Li, Xinming Huang, Ziming Zhang</h3>
<p>In the literature of vehicle re-identification (ReID), intensive manual
labels such as landmarks, critical parts or semantic segmentation masks are
often required to improve the performance. Such extra information helps to
detect locally geometric features as a part of representation learning for
vehicles. In contrast, in this paper, we aim to address the challenge of {\em
automatically} learning to detect geometric features as landmarks {\em with no
extra labels}. To the best of our knowledge, we are the {\em first} to
successfully learn discriminative geometric features for vehicle ReID based on
self-supervised attention. Specifically, we implement an end-to-end trainable
deep network architecture consisting of three branches: (1) a global branch as
backbone for image feature extraction, (2) an attentional branch for producing
attention masks, and (3) a self-supervised branch for regularizing the
attention learning with rotated images to locate geometric features. %Our
network design naturally leads to an end-to-end multi-task joint optimization.
We conduct comprehensive experiments on three benchmark datasets for vehicle
ReID, \ie VeRi-776, CityFlow-ReID, and VehicleID, and demonstrate our
state-of-the-art performance. %of our approach with the capability of capturing
informative vehicle parts with no corresponding manual labels. We also show the
good generalization of our approach in other ReID tasks such as person ReID and
multi-target multi-camera (MTMC) vehicle tracking. {\em Our demo code is
attached in the supplementary file.}
</p>
<a href="http://arxiv.org/abs/2010.09221" target="_blank">arXiv:2010.09221</a> [<a href="http://arxiv.org/pdf/2010.09221" target="_blank">pdf</a>]

<h2>Density of States Graph Kernels. (arXiv:2010.11341v2 [cs.LG] UPDATED)</h2>
<h3>Leo Huang, Andrew Graven, David Bindel</h3>
<p>A fundamental problem on graph-structured data is that of quantifying
similarity between graphs. Graph kernels are an established technique for such
tasks; in particular, those based on random walks and return probabilities have
proven to be effective in wide-ranging applications, from bioinformatics to
social networks to computer vision. However, random walk kernels generally
suffer from slowness and tottering, an effect which causes walks to
overemphasize local graph topology, undercutting the importance of global
structure. To correct for these issues, we recast return probability graph
kernels under the more general framework of density of states -- a framework
which uses the lens of spectral analysis to uncover graph motifs and properties
hidden within the interior of the spectrum -- and use our interpretation to
construct scalable, composite density of states based graph kernels which
balance local and global information, leading to higher classification
accuracies on a host of benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2010.11341" target="_blank">arXiv:2010.11341</a> [<a href="http://arxiv.org/pdf/2010.11341" target="_blank">pdf</a>]

<h2>Evolving test instances of the Hamiltonian completion problem. (arXiv:2011.02291v2 [cs.AI] UPDATED)</h2>
<h3>Thibault Lechien, Jorik Jooken, Patrick De Causmaecker</h3>
<p>Predicting and comparing algorithm performance on graph instances is
challenging for multiple reasons. First, there is usually no standard set of
instances to benchmark performance. Second, using existing graph generators
results in a restricted spectrum of difficulty and the resulting graphs are
usually not diverse enough to draw sound conclusions. That is why recent work
proposes a new methodology to generate a diverse set of instances by using an
evolutionary algorithm. We can then analyze the resulting graphs and get key
insights into which attributes are most related to algorithm performance. We
can also fill observed gaps in the instance space in order to generate graphs
with previously unseen combinations of features. This methodology is applied to
the instance space of the Hamiltonian completion problem using two different
solvers, namely the Concorde TSP Solver and a multi-start local search
algorithm.
</p>
<a href="http://arxiv.org/abs/2011.02291" target="_blank">arXiv:2011.02291</a> [<a href="http://arxiv.org/pdf/2011.02291" target="_blank">pdf</a>]

<h2>Identifying Mislabeled Images in Supervised Learning Utilizing Autoencoder. (arXiv:2011.03667v2 [cs.CV] UPDATED)</h2>
<h3>Yunhao Yang, Andrew Whinston</h3>
<p>Supervised learning is based on the assumption that the ground truth in the
training data is accurate. However, this may not be guaranteed in real-world
settings. Inaccurate training data will result in some unexpected predictions.
In image classification, incorrect labels may cause the classification model to
be inaccurate as well. In this paper, I am going to apply unsupervised
techniques to the training data before training the classification network. A
convolutional autoencoder is applied to encode and reconstruct images. The
encoder will project the image data on to latent space. In the latent space,
image features are preserved in a lower dimension. The assumption is that data
samples with similar features are likely to have the same label. Noised samples
can be classified in the latent space by the Density-Base Scan (DBSCAN)
clustering algorithm. These incorrectly labeled data are visualized as outliers
in the latent space. Therefore, the outliers identified by the DBSCAN algorithm
can be classified as incorrectly labeled samples. After the outliers are
detected, all the outliers are treated as mislabeled data samples and removed
from the dataset. Thus the training data can be directly used in training the
supervised learning network. The algorithm can detect and remove above 67\% of
mislabeled data in the experimental dataset.
</p>
<a href="http://arxiv.org/abs/2011.03667" target="_blank">arXiv:2011.03667</a> [<a href="http://arxiv.org/pdf/2011.03667" target="_blank">pdf</a>]

<h2>Motion Generation Using Bilateral Control-Based Imitation Learning with Autoregressive Learning. (arXiv:2011.06192v3 [cs.RO] UPDATED)</h2>
<h3>Ayumu Sasagawa, Sho Sakaino, Toshiaki Tsuji</h3>
<p>Robots that can execute various tasks automatically on behalf of humans are
becoming an increasingly important focus of research in the field of robotics.
Imitation learning has been studied as an efficient and high-performance
method, and imitation learning based on bilateral control has been proposed as
a method that can realize fast motion. However, because this method cannot
implement autoregressive learning, this method may not generate desirable
long-term behavior. Therefore, in this paper, we propose a method of
autoregressive learning for bilateral control-based imitation learning. A new
neural network model for implementing autoregressive learning is proposed. In
this study, three types of experiments are conducted to verify the
effectiveness of the proposed method. The performance is improved compared to
conventional approaches; the proposed method has the highest rate of success.
Owing to the structure and autoregressive learning of the proposed model, the
proposed method can generate the desirable motion for successful tasks and have
a high generalization ability for environmental changes.
</p>
<a href="http://arxiv.org/abs/2011.06192" target="_blank">arXiv:2011.06192</a> [<a href="http://arxiv.org/pdf/2011.06192" target="_blank">pdf</a>]

<h2>Reachability-based Trajectory Safeguard (RTS): A Safe and Fast Reinforcement Learning Safety Layer for Continuous Control. (arXiv:2011.08421v2 [cs.RO] UPDATED)</h2>
<h3>Yifei Simon Shao, Chao Chen, Shreyas Kousik, Ram Vasudevan</h3>
<p>Reinforcement Learning (RL) algorithms have achieved remarkable performance
in decision making and control tasks due to their ability to reason about
long-term, cumulative reward using trial and error. However, during RL
training, applying this trial-and-error approach to real-world robots operating
in safety critical environment may lead to collisions. To address this
challenge, this paper proposes a Reachability-based Trajectory Safeguard (RTS),
which leverages reachability analysis to ensure safety during training and
operation. Given a known (but uncertain) model of a robot, RTS precomputes a
Forward Reachable Set of the robot tracking a continuum of parameterized
trajectories. At runtime, the RL agent selects from this continuum in a
receding-horizon way to control the robot; the FRS is used to identify if the
agent's choice is safe or not, and to adjust unsafe choices. The efficacy of
this method is illustrated on three nonlinear robot models, including a 12-D
quadrotor drone, in simulation and in comparison with state-of-the-art safe
motion planning methods.
</p>
<a href="http://arxiv.org/abs/2011.08421" target="_blank">arXiv:2011.08421</a> [<a href="http://arxiv.org/pdf/2011.08421" target="_blank">pdf</a>]

<h2>Using Radiomics as Prior Knowledge for Abnormality Classification and Localization in Chest X-rays. (arXiv:2011.12506v2 [cs.CV] UPDATED)</h2>
<h3>Yan Han, Chongyan Chen, Liyan Tang, Mingquan Lin, Ajay Jaiswal, Ying Ding, Yifan Peng</h3>
<p>Chest X-rays become one of the most common medical diagnoses due to its
noninvasiveness. The number of chest X-ray images has skyrocketed, but reading
chest X-rays still have been manually performed by radiologists, which creates
huge burnouts and delays. Traditionally, radiomics, as a subfield of radiology
that can extract a large number of quantitative features from medical images,
demonstrates its potential to facilitate medical imaging diagnosis before the
deep learning era. In this paper, we develop an algorithm that can utilize the
radiomics features to improve the abnormality classification performance. Our
algorithm, ChexRadiNet, applies a light-weight but efficient triplet-attention
mechanism for highlighting the meaningful image regions to improve localization
accuracy. We first apply ChexRadiNet to classify the chest X-rays by using only
image features. Then we use the generated heatmaps of chest X-rays to extract
radiomics features. Finally, the extracted radiomics features could be used to
guide our model to learn more robust accurate image features. After a number of
iterations, our model could focus on more accurate image regions and extract
more robust features. The empirical evaluation of our method supports our
intuition and outperforms other state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2011.12506" target="_blank">arXiv:2011.12506</a> [<a href="http://arxiv.org/pdf/2011.12506" target="_blank">pdf</a>]

<h2>Understand Watchdogs: Discover How Game Bot Get Discovered. (arXiv:2011.13374v2 [cs.AI] UPDATED)</h2>
<h3>Eunji Park, Kyung Ho Park, Huy Kang Kim</h3>
<p>The game industry has long been troubled by malicious activities utilizing
game bots. The game bots disturb other game players and destroy the
environmental system of the games. For these reasons, the game industry put
their best efforts to detect the game bots among players' characters using the
learning-based detections. However, one problem with the detection
methodologies is that they do not provide rational explanations about their
decisions. To resolve this problem, in this work, we investigate the
explainabilities of the game bot detection. We develop the XAI model using a
dataset from the Korean MMORPG, AION, which includes game logs of human players
and game bots. More than one classification model has been applied to the
dataset to be analyzed by applying interpretable models. This provides us
explanations about the game bots' behavior, and the truthfulness of the
explanations has been evaluated. Besides, interpretability contributes to
minimizing false detection, which imposes unfair restrictions on human players.
</p>
<a href="http://arxiv.org/abs/2011.13374" target="_blank">arXiv:2011.13374</a> [<a href="http://arxiv.org/pdf/2011.13374" target="_blank">pdf</a>]

<h2>A Data-Driven Study of Commonsense Knowledge using the ConceptNet Knowledge Base. (arXiv:2011.14084v2 [cs.AI] UPDATED)</h2>
<h3>Ke Shen, Mayank Kejriwal</h3>
<p>Acquiring commonsense knowledge and reasoning is recognized as an important
frontier in achieving general Artificial Intelligence (AI). Recent research in
the Natural Language Processing (NLP) community has demonstrated significant
progress in this problem setting. Despite this progress, which is mainly on
multiple-choice question answering tasks in limited settings, there is still a
lack of understanding (especially at scale) of the nature of commonsense
knowledge itself. In this paper, we propose and conduct a systematic study to
enable a deeper understanding of commonsense knowledge by doing an empirical
and structural analysis of the ConceptNet knowledge base. ConceptNet is a
freely available knowledge base containing millions of commonsense assertions
presented in natural language. Detailed experimental results on three carefully
designed research questions, using state-of-the-art unsupervised graph
representation learning ('embedding') and clustering techniques, reveal deep
substructures in ConceptNet relations, allowing us to make data-driven and
computational claims about the meaning of phenomena such as 'context' that are
traditionally discussed only in qualitative terms. Furthermore, our methodology
provides a case study in how to use data-science and computational
methodologies for understanding the nature of an everyday (yet complex)
psychological phenomenon that is an essential feature of human intelligence.
</p>
<a href="http://arxiv.org/abs/2011.14084" target="_blank">arXiv:2011.14084</a> [<a href="http://arxiv.org/pdf/2011.14084" target="_blank">pdf</a>]

<h2>One-Vote Veto: A Self-Training Strategy for Low-Shot Learning of a Task-Invariant Embedding to Diagnose Glaucoma. (arXiv:2012.04841v2 [cs.CV] UPDATED)</h2>
<h3>Rui Fan, Christopher Bowd, Nicole Brye, Mark Christopher, Robert N. Weinreb, David Kriegman, Linda Zangwill</h3>
<p>Convolutional neural networks (CNNs) are a promising technique for automated
glaucoma diagnosis from images of the fundus, and these images are routinely
acquired as part of an ophthalmic exam. Nevertheless, CNNs typically require a
large amount of well-labeled data for training, which may not be available in
many biomedical image classification applications, especially when diseases are
rare and where labeling by experts is costly.

This paper makes two contributions to address this issue: (1) It introduces a
new network architecture and training method for low-shot learning when labeled
data are limited and imbalanced, and (2) it introduces a new semi-supervised
learning strategy that uses additional unlabeled training data to achieve great
accuracy. Our multi-task twin neural network (MTTNN) can use any backbone CNN,
and we demonstrate with ResNet-50 and MobileNet-v2 that its accuracy with
limited training data approaches the accuracy of a finetuned backbone trained
with a dataset that is 50 times larger. We also introduce One-Vote Veto (OVV)
self-training, a semi-supervised learning strategy, that is designed
specifically for MTTNNs. By taking both self-predictions and
contrastive-predictions of the unlabeled training data into account, OVV
self-training provides additional pseudo labels for finetuning a pretrained
MTTNN. Using a large dataset with more than 50,000 fundus images acquired over
25 years, extensive experimental results demonstrate the effectiveness of
low-shot learning with MTTNN and semi-supervised learning with OVV. Three
additional, smaller clinical datasets of fundus images acquired under different
conditions (cameras, instruments, locations, populations), are used to
demonstrate generalizability of the methods. Source code and pretrained models
will be publicly available upon publication.
</p>
<a href="http://arxiv.org/abs/2012.04841" target="_blank">arXiv:2012.04841</a> [<a href="http://arxiv.org/pdf/2012.04841" target="_blank">pdf</a>]

<h2>Visual Perception Generalization for Vision-and-Language Navigation via Meta-Learning. (arXiv:2012.05446v3 [cs.RO] UPDATED)</h2>
<h3>Ting Wang, Zongkai Wu, Donglin Wang</h3>
<p>Vision-and-language navigation (VLN) is a challenging task that requires an
agent to navigate in real-world environments by understanding natural language
instructions and visual information received in real-time. Prior works have
implemented VLN tasks on continuous environments or physical robots, all of
which use a fixed camera configuration due to the limitations of datasets, such
as 1.5 meters height, 90 degrees horizontal field of view (HFOV), etc. However,
real-life robots with different purposes have multiple camera configurations,
and the huge gap in visual information makes it difficult to directly transfer
the learned navigation model between various robots. In this paper, we propose
a visual perception generalization strategy based on meta-learning, which
enables the agent to fast adapt to a new camera configuration with a few shots.
In the training phase, we first locate the generalization problem to the visual
perception module, and then compare two meta-learning algorithms for better
generalization in seen and unseen environments. One of them uses the
Model-Agnostic Meta-Learning (MAML) algorithm that requires a few shot
adaptation, and the other refers to a metric-based meta-learning method with a
feature-wise affine transformation layer. The experiment results show that our
strategy successfully adapts the learned navigation model to a new camera
configuration, and the two algorithms show their advantages in seen and unseen
environments respectively.
</p>
<a href="http://arxiv.org/abs/2012.05446" target="_blank">arXiv:2012.05446</a> [<a href="http://arxiv.org/pdf/2012.05446" target="_blank">pdf</a>]

<h2>Detection of Binary Square Fiducial Markers Using an Event Camera. (arXiv:2012.06516v2 [cs.CV] UPDATED)</h2>
<h3>Hamid Sarmadi, Rafael Mu&#xf1;oz-Salinas, Miguel A. Olivares-Mendez, Rafael Medina-Carnicer</h3>
<p>Event cameras are a new type of image sensors that output changes in light
intensity (events) instead of absolute intensity values. They have a very high
temporal resolution and a high dynamic range. In this paper, we propose a
method to detect and decode binary square markers using an event camera. We
detect the edges of the markers by detecting line segments in an image created
from events in the current packet. The line segments are combined to form
marker candidates. The bit value of marker cells is decoded using the events on
their borders. To the best of our knowledge, no other approach exists for
detecting square binary markers directly from an event camera. Experimental
results show that the performance of our proposal is much superior to the one
from the RGB ArUco marker detector. Additionally, the proposed method can run
on a single CPU thread in real-time.
</p>
<a href="http://arxiv.org/abs/2012.06516" target="_blank">arXiv:2012.06516</a> [<a href="http://arxiv.org/pdf/2012.06516" target="_blank">pdf</a>]

<h2>Noisy Linear Convergence of Stochastic Gradient Descent for CV@R Statistical Learning under Polyak-{\L}ojasiewicz Conditions. (arXiv:2012.07785v3 [cs.LG] UPDATED)</h2>
<h3>Dionysios S. Kalogerias</h3>
<p>Conditional Value-at-Risk ($\mathrm{CV@R}$) is one of the most popular
measures of risk, which has been recently considered as a performance criterion
in supervised statistical learning, as it is related to desirable operational
features in modern applications, such as safety, fairness, distributional
robustness, and prediction error stability. However, due to its variational
definition, $\mathrm{CV@R}$ is commonly believed to result in difficult
optimization problems, even for smooth and strongly convex loss functions. We
disprove this statement by establishing noisy (i.e., fixed-accuracy) linear
convergence of stochastic gradient descent for sequential $\mathrm{CV@R}$
learning, for a large class of not necessarily strongly-convex (or even convex)
loss functions satisfying a set-restricted Polyak-Lojasiewicz inequality. This
class contains all smooth and strongly convex losses, confirming that classical
problems, such as linear least squares regression, can be solved efficiently
under the $\mathrm{CV@R}$ criterion, just as their risk-neutral versions. Our
results are illustrated numerically on such a risk-aware ridge regression task,
also verifying their validity in practice.
</p>
<a href="http://arxiv.org/abs/2012.07785" target="_blank">arXiv:2012.07785</a> [<a href="http://arxiv.org/pdf/2012.07785" target="_blank">pdf</a>]

<h2>Neural Collapse with Cross-Entropy Loss. (arXiv:2012.08465v2 [cs.LG] UPDATED)</h2>
<h3>Jianfeng Lu, Stefan Steinerberger</h3>
<p>We consider the variational problem of cross-entropy loss with $n$ feature
vectors on a unit hypersphere in $\mathbb{R}^d$. We prove that when $d \geq n -
1$, the global minimum is given by the simplex equiangular tight frame, which
justifies the neural collapse behavior. We also prove that as $n \rightarrow
\infty$ with fixed $d$, the minimizing points will distribute uniformly on the
hypersphere and show a connection with the frame potential of Benedetto &amp;
Fickus.
</p>
<a href="http://arxiv.org/abs/2012.08465" target="_blank">arXiv:2012.08465</a> [<a href="http://arxiv.org/pdf/2012.08465" target="_blank">pdf</a>]

<h2>FPCC-Net: Fast Point Cloud Clustering for Instance Segmentation. (arXiv:2012.14618v2 [cs.CV] UPDATED)</h2>
<h3>Yajun Xu, Shogo Arai, Diyi Liu, Fangzhou Lin, Kazuhiro Kosuge</h3>
<p>Instance segmentation is an important pre-processing task in numerous
real-world applications, such as robotics, autonomous vehicles, and
human-computer interaction. However, there has been little research on 3D point
cloud instance segmentation of bin-picking scenes in which multiple objects of
the same class are stacked together. Compared with the rapid development of
deep learning for two-dimensional (2D) image tasks, deep learning-based 3D
point cloud segmentation still has a lot of room for development. In such a
situation, distinguishing a large number of occluded objects of the same class
is a highly challenging problem. In a usual bin-picking scene, an object model
is known and the number of object type is one. Thus, the semantic information
can be ignored; instead, the focus is put on the segmentation of instances.
Based on this task requirement, we propose a network (FPCC-Net) that infers
feature centers of each instance and then clusters the remaining points to the
closest feature center in feature embedding space. FPCC-Net includes two
subnets, one for inferring the feature centers for clustering and the other for
describing features of each point. The proposed method is compared with
existing 3D point cloud and 2D segmentation methods in some bin-picking scenes.
It is shown that FPCC-Net improves average precision (AP) by about 40\% than
SGPN and can process about 60,000 points in about 0.8 [s].
</p>
<a href="http://arxiv.org/abs/2012.14618" target="_blank">arXiv:2012.14618</a> [<a href="http://arxiv.org/pdf/2012.14618" target="_blank">pdf</a>]

<h2>Learning to Anticipate Egocentric Actions by Imagination. (arXiv:2101.04924v2 [cs.CV] UPDATED)</h2>
<h3>Yu Wu, Linchao Zhu, Xiaohan Wang, Yi Yang, Fei Wu</h3>
<p>Anticipating actions before they are executed is crucial for a wide range of
practical applications, including autonomous driving and robotics. In this
paper, we study the egocentric action anticipation task, which predicts future
action seconds before it is performed for egocentric videos. Previous
approaches focus on summarizing the observed content and directly predicting
future action based on past observations. We believe it would benefit the
action anticipation if we could mine some cues to compensate for the missing
information of the unobserved frames. We then propose to decompose the action
anticipation into a series of future feature predictions. We imagine how the
visual feature changes in the near future and then predicts future action
labels based on these imagined representations. Differently, our ImagineRNN is
optimized in a contrastive learning way instead of feature regression. We
utilize a proxy task to train the ImagineRNN, i.e., selecting the correct
future states from distractors. We further improve ImagineRNN by residual
anticipation, i.e., changing its target to predicting the feature difference of
adjacent frames instead of the frame content. This promotes the network to
focus on our target, i.e., the future action, as the difference between
adjacent frame features is more important for forecasting the future. Extensive
experiments on two large-scale egocentric action datasets validate the
effectiveness of our method. Our method significantly outperforms previous
methods on both the seen test set and the unseen test set of the EPIC Kitchens
Action Anticipation Challenge.
</p>
<a href="http://arxiv.org/abs/2101.04924" target="_blank">arXiv:2101.04924</a> [<a href="http://arxiv.org/pdf/2101.04924" target="_blank">pdf</a>]

<h2>Estimating and Evaluating Regression Predictive Uncertainty in Deep Object Detectors. (arXiv:2101.05036v2 [cs.CV] UPDATED)</h2>
<h3>Ali Harakeh, Steven L. Waslander</h3>
<p>Predictive uncertainty estimation is an essential next step for the reliable
deployment of deep object detectors in safety-critical tasks. In this work, we
focus on estimating predictive distributions for bounding box regression output
with variance networks. We show that in the context of object detection,
training variance networks with negative log likelihood (NLL) can lead to high
entropy predictive distributions regardless of the correctness of the output
mean. We propose to use the energy score as a non-local proper scoring rule and
find that when used for training, the energy score leads to better calibrated
and lower entropy predictive distributions than NLL. We also address the
widespread use of non-proper scoring metrics for evaluating predictive
distributions from deep object detectors by proposing an alternate evaluation
approach founded on proper scoring rules. Using the proposed evaluation tools,
we show that although variance networks can be used to produce high quality
predictive distributions, ad-hoc approaches used by seminal object detectors
for choosing regression targets during training do not provide wide enough data
support for reliable variance learning. We hope that our work helps shift
evaluation in probabilistic object detection to better align with predictive
uncertainty evaluation in other machine learning domains. Code for all models,
evaluation, and datasets is available at:
https://github.com/asharakeh/probdet.git.
</p>
<a href="http://arxiv.org/abs/2101.05036" target="_blank">arXiv:2101.05036</a> [<a href="http://arxiv.org/pdf/2101.05036" target="_blank">pdf</a>]

<h2>JITuNE: Just-In-Time Hyperparameter Tuning for Network Embedding Algorithms. (arXiv:2101.06427v2 [cs.LG] UPDATED)</h2>
<h3>Mengying Guo, Tao Yi, Yuqing Zhu, Yungang Bao</h3>
<p>Network embedding (NE) can generate succinct node representations for
massive-scale networks and enable direct applications of common machine
learning methods to the network structure. Various NE algorithms have been
proposed and used in a number of applications, such as node classification and
link prediction. NE algorithms typically contain hyperparameters that are key
to performance, but the hyperparameter tuning process can be time consuming. It
is desirable to have the hyperparameters tuned within a specified length of
time. Although AutoML methods have been applied to the hyperparameter tuning of
NE algorithms, the problem of how to tune hyperparameters in a given period of
time is not studied for NE algorithms before. In this paper, we propose JITuNE,
a just-in-time hyperparameter tuning framework for NE algorithms. Our JITuNE
framework enables the time-constrained hyperparameter tuning for NE algorithms
by employing the tuning over hierarchical network synopses and transferring the
knowledge obtained on synopses to the whole network. The hierarchical
generation of synopsis and a time-constrained tuning method enable the
constraining of overall tuning time. Extensive experiments demonstrate that
JITuNE can significantly improve performances of NE algorithms, outperforming
state-of-the-art methods within the same number of algorithm runs.
</p>
<a href="http://arxiv.org/abs/2101.06427" target="_blank">arXiv:2101.06427</a> [<a href="http://arxiv.org/pdf/2101.06427" target="_blank">pdf</a>]

<h2>Deep-Mobility: A Deep Learning Approach for an Efficient and Reliable 5G Handover. (arXiv:2101.06558v2 [cs.LG] UPDATED)</h2>
<h3>Rahul Arun Paropkari, Anurag Thantharate, Cory Beard</h3>
<p>5G cellular networks are being deployed all over the world and this
architecture supports ultra-dense network (UDN) deployment. Small cells have a
very important role in providing 5G connectivity to the end users. Exponential
increases in devices, data and network demands make it mandatory for the
service providers to manage handovers better, to cater to the services that a
user desire. In contrast to any traditional handover improvement scheme, we
develop a 'Deep-Mobility' model by implementing a deep learning neural network
(DLNN) to manage network mobility, utilizing in-network deep learning and
prediction. We use network key performance indicators (KPIs) to train our model
to analyze network traffic and handover requirements. In this method, RF signal
conditions are continuously observed and tracked using deep learning neural
networks such as the Recurrent neural network (RNN) or Long Short-Term Memory
network (LSTM) and system level inputs are also considered in conjunction, to
take a collective decision for a handover. We can study multiple parameters and
interactions between system events along with the user mobility, which would
then trigger a handoff in any given scenario. Here, we show the fundamental
modeling approach and demonstrate usefulness of our model while investigating
impacts and sensitivities of certain KPIs from the user equipment (UE) and
network side.
</p>
<a href="http://arxiv.org/abs/2101.06558" target="_blank">arXiv:2101.06558</a> [<a href="http://arxiv.org/pdf/2101.06558" target="_blank">pdf</a>]

<h2>Deep Multi-Task Learning for Joint Localization, Perception, and Prediction. (arXiv:2101.06720v2 [cs.CV] UPDATED)</h2>
<h3>John Phillips, Julieta Martinez, Ioan Andrei B&#xe2;rsan, Sergio Casas, Abbas Sadat, Raquel Urtasun</h3>
<p>Over the last few years, we have witnessed tremendous progress on many
subtasks of autonomous driving, including perception, motion forecasting, and
motion planning. However, these systems often assume that the car is accurately
localized against a high-definition map. In this paper we question this
assumption, and investigate the issues that arise in state-of-the-art autonomy
stacks under localization error. Based on our observations, we design a system
that jointly performs perception, prediction, and localization. Our
architecture is able to reuse computation between both tasks, and is thus able
to correct localization errors efficiently. We show experiments on a
large-scale autonomy dataset, demonstrating the efficiency and accuracy of our
proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.06720" target="_blank">arXiv:2101.06720</a> [<a href="http://arxiv.org/pdf/2101.06720" target="_blank">pdf</a>]

<h2>Yet Another Representation of Binary Decision Trees: A Mathematical Demonstration. (arXiv:2101.07077v2 [cs.LG] UPDATED)</h2>
<h3>Jinxiong Zhang</h3>
<p>A decision tree looks like a simple computational graph without cycles, where
only the leaf nodes specify the output values and the non-terminals specify
their tests or split conditions. From the numerical perspective, we express
decision trees in the language of computational graph. We explicitly
parameterize the test phase, traversal phase and prediction phase of decision
trees based on the bitvectors of non-terminal nodes. As shown later, the
decision tree is a shallow binary network in some sense. Especially, we
introduce the bitvector matrix to implement the tree traversal in numerical
approach, where the core is to convert the logical `AND' operation to
arithmetic operations. And we apply this numerical representation to extend and
unify diverse decision trees in concept.
</p>
<a href="http://arxiv.org/abs/2101.07077" target="_blank">arXiv:2101.07077</a> [<a href="http://arxiv.org/pdf/2101.07077" target="_blank">pdf</a>]

