---
title: Latest Deep Learning Papers
date: 2021-01-31 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (113 Articles)</h1>
<h2>Meta-learning on Spectral Images of Electroencephalogram of Schizophenics. (arXiv:2101.12208v1 [cs.LG])</h2>
<h3>Maritza Tynes, Mahboobeh Parsapoor</h3>
<p>Schizophrenia is a complex psychiatric disorder involving changes in thought
patterns, perception, mood, and behavior. The diagnosis of schizophrenia is
challenging and requires that patients show two or more positive symptoms for
at least one month. Delays in identifying this debilitating disorder can impede
a patient ability to receive much needed treatment. Advances in neuroimaging
and machine learning algorithms can facilitate the diagnosis of schizophrenia
and help clinicians to provide an accurate diagnosis of the disease. This paper
presents a methodology for analyzing spectral images of Electroencephalography
collected from patients with schizophrenia using convolutional neural networks.
It also explains how we have developed accurate classifiers employing
Model-Agnostic Meta-Learning and prototypical networks. Such classifiers have
the capacity to distinguish people with schizophrenia from healthy controls
based on their brain activity.
</p>
<a href="http://arxiv.org/abs/2101.12208" target="_blank">arXiv:2101.12208</a> [<a href="http://arxiv.org/pdf/2101.12208" target="_blank">pdf</a>]

<h2>Differential Privacy Meets Federated Learning under Communication Constraints. (arXiv:2101.12240v1 [cs.LG])</h2>
<h3>Nima Mohammadi, Jianan Bai, Qiang Fan, Yifei Song, Yang Yi, Lingjia Liu</h3>
<p>The performance of federated learning systems is bottlenecked by
communication costs and training variance. The communication overhead problem
is usually addressed by three communication-reduction techniques, namely, model
compression, partial device participation, and periodic aggregation, at the
cost of increased training variance. Different from traditional distributed
learning systems, federated learning suffers from data heterogeneity (since the
devices sample their data from possibly different distributions), which induces
additional variance among devices during training. Various variance-reduced
training algorithms have been introduced to combat the effects of data
heterogeneity, while they usually cost additional communication resources to
deliver necessary control information. Additionally, data privacy remains a
critical issue in FL, and thus there have been attempts at bringing
Differential Privacy to this framework as a mediator between utility and
privacy requirements. This paper investigates the trade-offs between
communication costs and training variance under a resource-constrained
federated system theoretically and experimentally, and how communication
reduction techniques interplay in a differentially private setting. The results
provide important insights into designing practical privacy-aware federated
learning systems.
</p>
<a href="http://arxiv.org/abs/2101.12240" target="_blank">arXiv:2101.12240</a> [<a href="http://arxiv.org/pdf/2101.12240" target="_blank">pdf</a>]

<h2>Uniform Object Rearrangement: From Complete Monotone Primitives to Efficient Non-Monotone Informed Search. (arXiv:2101.12241v1 [cs.RO])</h2>
<h3>Rui Wang, Kai Gao, Daniel Nakhimovich, Jingjin Yu, Kostas E. Bekris</h3>
<p>Object rearrangement is a widely-applicable and challenging task for robots.
Geometric constraints must be carefully examined to avoid collisions and
combinatorial issues arise as the number of objects increases. This work
studies the algorithmic structure of rearranging uniform objects, where
robot-object collisions do not occur but object-object collisions have to be
avoided. The objective is minimizing the number of object transfers under the
assumption that the robot can manipulate one object at a time. An efficiently
computable decomposition of the configuration space is used to create a "region
graph", which classifies all continuous paths of equivalent collision
possibilities. Based on this compact but rich representation, a complete
dynamic programming primitive DFSDP performs a recursive depth first search to
solve monotone problems quickly, i.e., those instances that do not require
objects to be moved first to an intermediate buffer. DFSDP is extended to solve
single-buffer, non-monotone instances, given a choice of an object and a
buffer. This work utilizes these primitives as local planners in an informed
search framework for more general, non-monotone instances. The search utilizes
partial solutions from the primitives to identify the most promising choice of
objects and buffers. Experiments demonstrate that the proposed solution returns
near-optimal paths with higher success rate, even for challenging non-monotone
instances, than other leading alternatives.
</p>
<a href="http://arxiv.org/abs/2101.12241" target="_blank">arXiv:2101.12241</a> [<a href="http://arxiv.org/pdf/2101.12241" target="_blank">pdf</a>]

<h2>D3DLO: Deep 3D LiDAR Odometry. (arXiv:2101.12242v1 [cs.CV])</h2>
<h3>Philipp Adis, Nicolas Horst, Mathias Wien</h3>
<p>LiDAR odometry (LO) describes the task of finding an alignment of subsequent
LiDAR point clouds. This alignment can be used to estimate the motion of the
platform where the LiDAR sensor is mounted on. Currently, on the well-known
KITTI Vision Benchmark Suite state-of-the-art algorithms are non-learning
approaches. We propose a network architecture that learns LO by directly
processing 3D point clouds. It is trained on the KITTI dataset in an end-to-end
manner without the necessity of pre-defining corresponding pairs of points. An
evaluation on the KITTI Vision Benchmark Suite shows similar performance to a
previously published work, DeepCLR [1], even though our model uses only around
3.56% of the number of network parameters thereof. Furthermore, a plane point
extraction is applied which leads to a marginal performance decrease while
simultaneously reducing the input size by up to 50%.
</p>
<a href="http://arxiv.org/abs/2101.12242" target="_blank">arXiv:2101.12242</a> [<a href="http://arxiv.org/pdf/2101.12242" target="_blank">pdf</a>]

<h2>Revisiting Non-Specific Syndromic Surveillance. (arXiv:2101.12246v1 [cs.LG])</h2>
<h3>Moritz Kulessa, Eneldo Loza Menc&#xed;a, Johannes F&#xfc;rnkranz</h3>
<p>Infectious disease surveillance is of great importance for the prevention of
major outbreaks. Syndromic surveillance aims at developing algorithms which can
detect outbreaks as early as possible by monitoring data sources which allow to
capture the occurrences of a certain disease. Recent research mainly focuses on
the surveillance of specific, known diseases, putting the focus on the
definition of the disease pattern under surveillance. Until now, only little
effort has been devoted to what we call non-specific syndromic surveillance,
i.e., the use of all available data for detecting any kind of outbreaks,
including infectious diseases which are unknown beforehand. In this work, we
revisit published approaches for non-specific syndromic surveillance and
present a set of simple statistical modeling techniques which can serve as
benchmarks for more elaborate machine learning approaches. Our experimental
comparison on established synthetic data and real data in which we injected
synthetic outbreaks shows that these benchmarks already achieve very
competitive results and often outperform more elaborate algorithms.
</p>
<a href="http://arxiv.org/abs/2101.12246" target="_blank">arXiv:2101.12246</a> [<a href="http://arxiv.org/pdf/2101.12246" target="_blank">pdf</a>]

<h2>A Survey of Complex-Valued Neural Networks. (arXiv:2101.12249v1 [stat.ML])</h2>
<h3>Joshua Bassey, Lijun Qian, Xianfang Li</h3>
<p>Artificial neural networks (ANNs) based machine learning models and
especially deep learning models have been widely applied in computer vision,
signal processing, wireless communications, and many other domains, where
complex numbers occur either naturally or by design. However, most of the
current implementations of ANNs and machine learning frameworks are using real
numbers rather than complex numbers. There are growing interests in building
ANNs using complex numbers, and exploring the potential advantages of the
so-called complex-valued neural networks (CVNNs) over their real-valued
counterparts. In this paper, we discuss the recent development of CVNNs by
performing a survey of the works on CVNNs in the literature. Specifically, a
detailed review of various CVNNs in terms of activation function, learning and
optimization, input and output representations, and their applications in tasks
such as signal processing and computer vision are provided, followed by a
discussion on some pertinent challenges and future research directions.
</p>
<a href="http://arxiv.org/abs/2101.12249" target="_blank">arXiv:2101.12249</a> [<a href="http://arxiv.org/pdf/2101.12249" target="_blank">pdf</a>]

<h2>Hybrid leg compliance enables robots to operate with sensorimotor delays and low control update frequencies. (arXiv:2101.12255v1 [cs.RO])</h2>
<h3>Milad Shafiee Ashtiani, Alborz Aghamaleki Sarvestani, Alexander Badri-Spr&#xf6;witz</h3>
<p>Animals locomote robustly and agile, albeit significant sensorimotor delays
of their nervous system. The sensorimotor control of legged robots is
implemented with much higher frequencies-often in the kilohertz range-and
sensor and actuator delays in the low millisecond range. But especially at
harsh impacts with unknown touch-down timing, legged robots show unstable
controller behaviors, while animals are seemingly not impacted. Here we examine
this discrepancy and suggest a hybrid robotic leg and controller design. We
implemented a physical, parallel joint compliance dimensioned in combination
with an active, virtual leg length controller. We present an extensive set of
systematic experiments both in computer simulation and hardware. Our hybrid leg
and controller design shows previously unseen robustness, in the presence of
sensorimotor delays up to 60 ms, or control frequencies as low as 20 Hz, for a
drop landing task from 1.3 leg lengths high and with a passive compliance ratio
of 0.7. In computer simulations, we report successful drop-landings of the
hybrid compliant leg from 3.8 leg lengths (1.2 m) for a 2 kg quadruped robot
with 100 Hz control frequency and a sensorimotor delay of 35 ms. The results of
our presented hybrid leg design and control provide a further explanation for
the performance robustness of animals, and the resulting discrepancy between
animals and legged robots.
</p>
<a href="http://arxiv.org/abs/2101.12255" target="_blank">arXiv:2101.12255</a> [<a href="http://arxiv.org/pdf/2101.12255" target="_blank">pdf</a>]

<h2>Teaching Turn-Taking Skills to Children with Autism using a Parrot-Like Robot. (arXiv:2101.12273v1 [cs.RO])</h2>
<h3>Pegah Soleiman (1), Hadi Moradi (1 and 2), Maryam Mahmoudi (3), Mohyeddin Teymouri (4), Hamid Reza Pouretemad (5) ((1) School of ECE, University of Tehran, North Karegar St., Tehran, Iran, (2) Intelligent Systems Research Institute, SKKU, Suwon, South Korea, (3) Department of Psychology, Allameh Tabatab&#xe1;i University, Tehran, Iran, (4) Department of speech therapy, Iran university of medical sciences, Tehran, Iran (5) Department of Psychology, Shahid Beheshti University, Tehran, Iran)</h3>
<p>Robot Assisted Therapy is a new paradigm in many therapies such as the
therapy of children with autism spectrum disorder. In this paper we present the
use of a parrot-like robot as an assistive tool in turn taking therapy. The
therapy is designed in the form of a card game between a child with autism and
a therapist or the robot. The intervention was implemented in a single subject
study format and the effect sizes for different turn taking variables are
calculated. The results show that the child robot interaction had larger effect
size than the child trainer effect size in most of the turn taking variables.
Furthermore the therapist point of view on the proposed Robot Assisted Therapy
is evaluated using a questionnaire. The therapist believes that the robot is
appealing to children which may ease the therapy process. The therapist
suggested to add other functionalities and games to let children with autism to
learn more turn taking tasks and better generalize the learned tasks
</p>
<a href="http://arxiv.org/abs/2101.12273" target="_blank">arXiv:2101.12273</a> [<a href="http://arxiv.org/pdf/2101.12273" target="_blank">pdf</a>]

<h2>Position, Padding and Predictions: A Deeper Look at Position Information in CNNs. (arXiv:2101.12322v1 [cs.CV])</h2>
<h3>Md Amirul Islam, Matthew Kowal, Sen Jia, Konstantinos G. Derpanis, Neil D. B. Bruce</h3>
<p>In contrast to fully connected networks, Convolutional Neural Networks (CNNs)
achieve efficiency by learning weights associated with local filters with a
finite spatial extent. An implication of this is that a filter may know what it
is looking at, but not where it is positioned in the image. In this paper, we
first test this hypothesis and reveal that a surprising degree of absolute
position information is encoded in commonly used CNNs. We show that zero
padding drives CNNs to encode position information in their internal
representations, while a lack of padding precludes position encoding. This
gives rise to deeper questions about the role of position information in CNNs:
(i) What boundary heuristics enable optimal position encoding for downstream
tasks?; (ii) Does position encoding affect the learning of semantic
representations?; (iii) Does position encoding always improve performance? To
provide answers, we perform the largest case study to date on the role that
padding and border heuristics play in CNNs. We design novel tasks which allow
us to quantify boundary effects as a function of the distance to the border.
Numerous semantic objectives reveal the effect of the border on semantic
representations. Finally, we demonstrate the implications of these findings on
multiple real-world tasks to show that position information can both help or
hurt performance.
</p>
<a href="http://arxiv.org/abs/2101.12322" target="_blank">arXiv:2101.12322</a> [<a href="http://arxiv.org/pdf/2101.12322" target="_blank">pdf</a>]

<h2>Enabling Robots to Draw and Tell: Towards Visually Grounded Multimodal Description Generation. (arXiv:2101.12338v1 [cs.RO])</h2>
<h3>Ting Han, Sina Zarrie&#xdf;</h3>
<p>Socially competent robots should be equipped with the ability to perceive the
world that surrounds them and communicate about it in a human-like manner.
Representative skills that exhibit such ability include generating image
descriptions and visually grounded referring expressions. In the NLG community,
these generation tasks are largely investigated in non-interactive and
language-only settings. However, in face-to-face interaction, humans often
deploy multiple modalities to communicate, forming seamless integration of
natural language, hand gestures and other modalities like sketches. To enable
robots to describe what they perceive with speech and sketches/gestures, we
propose to model the task of generating natural language together with
free-hand sketches/hand gestures to describe visual scenes and real life
objects, namely, visually-grounded multimodal description generation. In this
paper, we discuss the challenges and evaluation metrics of the task, and how
the task can benefit from progress recently made in the natural language
processing and computer vision realms, where related topics such as visually
grounded NLG, distributional semantics, and photo-based sketch generation have
been extensively studied.
</p>
<a href="http://arxiv.org/abs/2101.12338" target="_blank">arXiv:2101.12338</a> [<a href="http://arxiv.org/pdf/2101.12338" target="_blank">pdf</a>]

<h2>Deep Triplet Hashing Network for Case-based Medical Image Retrieval. (arXiv:2101.12346v1 [cs.CV])</h2>
<h3>Jiansheng Fang, Huazhu Fu, Jiang Liu</h3>
<p>Deep hashing methods have been shown to be the most efficient approximate
nearest neighbor search techniques for large-scale image retrieval. However,
existing deep hashing methods have a poor small-sample ranking performance for
case-based medical image retrieval. The top-ranked images in the returned query
results may be as a different class than the query image. This ranking problem
is caused by classification, regions of interest (ROI), and small-sample
information loss in the hashing space. To address the ranking problem, we
propose an end-to-end framework, called Attention-based Triplet Hashing (ATH)
network, to learn low-dimensional hash codes that preserve the classification,
ROI, and small-sample information. We embed a spatial-attention module into the
network structure of our ATH to focus on ROI information. The spatial-attention
module aggregates the spatial information of feature maps by utilizing
max-pooling, element-wise maximum, and element-wise mean operations jointly
along the channel axis. The triplet cross-entropy loss can help to map the
classification information of images and similarity between images into the
hash codes. Extensive experiments on two case-based medical datasets
demonstrate that our proposed ATH can further improve the retrieval performance
compared to the state-of-the-art deep hashing methods and boost the ranking
performance for small samples. Compared to the other loss methods, the triplet
cross-entropy loss can enhance the classification performance and hash
code-discriminability
</p>
<a href="http://arxiv.org/abs/2101.12346" target="_blank">arXiv:2101.12346</a> [<a href="http://arxiv.org/pdf/2101.12346" target="_blank">pdf</a>]

<h2>The Analysis of Discrete-Event System in Autonomous Package Delivery using Legged Robot and Conveyor Belt. (arXiv:2101.12347v1 [cs.RO])</h2>
<h3>Garen Haddeler</h3>
<p>In this paper, the supervisory control of a Discrete Event System (DES)
analyses states and events to construct an autonomous package delivery system.
The delivery system includes a legged robot in order to autonomously navigate
uneven indoor terrain and a conveyor belt for transporting the package to the
legged robot.The aim of the paper is using the theory of supervisory control of
DES to supervise and control machine's state and event and ensure robots
autonomously collaborate. By applying the theory, we show the collaboration of
two individual robots to deliver goods in a multi-floor environment. The
obtained results from the theory of supervisory control are implemented and
verified in a simulation environment.
</p>
<a href="http://arxiv.org/abs/2101.12347" target="_blank">arXiv:2101.12347</a> [<a href="http://arxiv.org/pdf/2101.12347" target="_blank">pdf</a>]

<h2>On the capacity of deep generative networks for approximating distributions. (arXiv:2101.12353v1 [cs.LG])</h2>
<h3>Yunfei Yang, Zhen Li, Yang Wang</h3>
<p>We study the efficacy and efficiency of deep generative networks for
approximating probability distributions. We prove that neural networks can
transform a one-dimensional source distribution to a distribution that is
arbitrarily close to a high-dimensional target distribution in Wasserstein
distances. Upper bounds of the approximation error are obtained in terms of
neural networks' width and depth. It is shown that the approximation error
grows at most linearly on the ambient dimension and that the approximation
order only depends on the intrinsic dimension of the target distribution. On
the contrary, when $f$-divergences are used as metrics of distributions, the
approximation property is different. We prove that in order to approximate the
target distribution in $f$-divergences, the dimension of the source
distribution cannot be smaller than the intrinsic dimension of the target
distribution. Therefore, $f$-divergences are less adequate than Waserstein
distances as metrics of distributions for generating samples.
</p>
<a href="http://arxiv.org/abs/2101.12353" target="_blank">arXiv:2101.12353</a> [<a href="http://arxiv.org/pdf/2101.12353" target="_blank">pdf</a>]

<h2>Optimal Approximation Rates and Metric Entropy of ReLU$^k$ and Cosine Networks. (arXiv:2101.12365v1 [stat.ML])</h2>
<h3>Jonathan W. Siegel, Jinchao Xu</h3>
<p>This article addresses several fundamental issues associated with the
approximation theory of neural networks, including the characterization of
approximation spaces, the determination of the metric entropy of these spaces,
and approximation rates of neural networks. For any activation function
$\sigma$, we show that the largest Banach space of functions which can be
efficiently approximated by the corresponding shallow neural networks is the
space whose norm is given by the gauge of the closed convex hull of the set
$\{\pm\sigma(\omega\cdot x + b)\}$. We characterize this space for the ReLU$^k$
and cosine activation functions and, in particular, show that the resulting
gauge space is equivalent to the spectral Barron space if $\sigma=\cos$ and is
equivalent to the Barron space when $\sigma={\rm ReLU}$. Our main result
establishes the precise asymptotics of the $L^2$-metric entropy of the unit
ball of these guage spaces and, as a consequence, the optimal approximation
rates for shallow ReLU$^k$ networks. The sharpest previous results hold only in
the special case that $k=0$ and $d=2$, where the metric entropy has been
determined up to logarithmic factors. When $k &gt; 0$ or $d &gt; 2$, there is a
significant gap between the previous best upper and lower bounds. We close all
of these gaps and determine the precise asymptotics of the metric entropy for
all $k \geq 0$ and $d\geq 2$, including removing the logarithmic factors
previously mentioned. Finally, we use these results to quantify how much is
lost by Barron's spectral condition relative to the convex hull of
$\{\pm\sigma(\omega\cdot x + b)\}$ when $\sigma={\rm ReLU}^k$.
</p>
<a href="http://arxiv.org/abs/2101.12365" target="_blank">arXiv:2101.12365</a> [<a href="http://arxiv.org/pdf/2101.12365" target="_blank">pdf</a>]

<h2>Information Theoretic Limits of Exact Recovery in Sub-hypergraph Models for Community Detection. (arXiv:2101.12369v1 [stat.ML])</h2>
<h3>Jiajun Liang, Chuyang Ke, Jean Honorio</h3>
<p>In this paper, we study the information theoretic bounds for exact recovery
in sub-hypergraph models for community detection. We define a general model
called the $m-$uniform sub-hypergraph stochastic block model ($m-$ShSBM). Under
the $m-$ShSBM, we use Fano's inequality to identify the region of model
parameters where any algorithm fails to exactly recover the planted communities
with a large probability. We also identify the region where a Maximum
Likelihood Estimation (MLE) algorithm succeeds to exactly recover the
communities with high probability. Our bounds are tight and pertain to the
community detection problems in various models such as the planted hypergraph
stochastic block model, the planted densest sub-hypergraph model, and the
planted multipartite hypergraph model.
</p>
<a href="http://arxiv.org/abs/2101.12369" target="_blank">arXiv:2101.12369</a> [<a href="http://arxiv.org/pdf/2101.12369" target="_blank">pdf</a>]

<h2>Adversarial Learning with Cost-Sensitive Classes. (arXiv:2101.12372v1 [cs.LG])</h2>
<h3>Haojing Shen, Sihong Chen, Ran Wang, Xizhao Wang</h3>
<p>It is necessary to improve the performance of some special classes or to
particularly protect them from attacks in adversarial learning. This paper
proposes a framework combining cost-sensitive classification and adversarial
learning together to train a model that can distinguish between protected and
unprotected classes, such that the protected classes are less vulnerable to
adversarial examples. We find in this framework an interesting phenomenon
during the training of deep neural networks, called Min-Max property, that is,
the absolute values of most parameters in the convolutional layer approach zero
while the absolute values of a few parameters are significantly larger becoming
bigger. Based on this Min-Max property which is formulated and analyzed in a
view of random distribution, we further build a new defense model against
adversarial examples for adversarial robustness improvement. An advantage of
the built model is that it does no longer need adversarial training, and thus,
has a higher computational efficiency than most existing models of needing
adversarial training. It is experimentally confirmed that, regarding the
average accuracy of all classes, our model is almost as same as the existing
models when an attack does not occur and is better than the existing models
when an attack occurs. Specifically, regarding the accuracy of protected
classes, the proposed model is much better than the existing models when an
attack occurs.
</p>
<a href="http://arxiv.org/abs/2101.12372" target="_blank">arXiv:2101.12372</a> [<a href="http://arxiv.org/pdf/2101.12372" target="_blank">pdf</a>]

<h2>NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation. (arXiv:2101.12378v1 [cs.CV])</h2>
<h3>Angtian Wang, Adam Kortylewski, Alan Yuille</h3>
<p>3D pose estimation is a challenging but important task in computer vision. In
this work, we show that standard deep learning approaches to 3D pose estimation
are not robust when objects are partially occluded or viewed from a previously
unseen pose. Inspired by the robustness of generative vision models to partial
occlusion, we propose to integrate deep neural networks with 3D generative
representations of objects into a unified neural architecture that we term
NeMo. In particular, NeMo learns a generative model of neural feature
activations at each vertex on a dense 3D mesh. Using differentiable rendering
we estimate the 3D object pose by minimizing the reconstruction error between
NeMo and the feature representation of the target image. To avoid local optima
in the reconstruction loss, we train the feature extractor to maximize the
distance between the individual feature representations on the mesh using
contrastive learning. Our extensive experiments on PASCAL3D+,
occluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to
partial occlusion and unseen pose compared to standard deep networks, while
retaining competitive performance on regular data. Interestingly, our
experiments also show that NeMo performs reasonably well even when the mesh
representation only crudely approximates the true object geometry with a
cuboid, hence revealing that the detailed 3D geometry is not needed for
accurate 3D pose estimation. The code is publicly available at
https://github.com/Angtian/NeMo.
</p>
<a href="http://arxiv.org/abs/2101.12378" target="_blank">arXiv:2101.12378</a> [<a href="http://arxiv.org/pdf/2101.12378" target="_blank">pdf</a>]

<h2>Learning-based Optoelectronically Innervated Tactile Finger for Rigid-Soft Interactive Grasping. (arXiv:2101.12379v1 [cs.RO])</h2>
<h3>Linhan Yang, Xudong Han, Weijie Guo, Fang Wan, Jia Pan, Chaoyang Song</h3>
<p>This paper presents a novel design of a soft tactile finger with
omni-directional adaptation using multi-channel optical fibers for rigid-soft
interactive grasping. Machine learning methods are used to train a model for
real-time prediction of force, torque, and contact using the tactile data
collected. We further integrated such fingers in a reconfigurable gripper
design with three fingers so that the finger arrangement can be actively
adjusted in real-time based on the tactile data collected during grasping,
achieving the process of rigid-soft interactive grasping. Detailed sensor
calibration and experimental results are also included to further validate the
proposed design for enhanced grasping robustness.
</p>
<a href="http://arxiv.org/abs/2101.12379" target="_blank">arXiv:2101.12379</a> [<a href="http://arxiv.org/pdf/2101.12379" target="_blank">pdf</a>]

<h2>Re Learning Memory Guided Normality for Anomaly Detection. (arXiv:2101.12382v1 [cs.CV])</h2>
<h3>Kevin Stephen, Varun Menon</h3>
<p>The authors have introduced a novel method for unsupervised anomaly detection
that utilises a newly introduced Memory Module in their paper. We validate the
authors claim that this helps improve performance by helping the network learn
prototypical patterns, and uses the learnt memory to reduce the representation
capacity of Convolutional Neural Networks. Further, we validate the efficacy of
two losses introduced by the authors, Separateness Loss and Compactness Loss
presented to increase the discriminative power of the memory items and the
deeply learned features. We test the efficacy with the help of t-SNE plots of
the memory items.
</p>
<a href="http://arxiv.org/abs/2101.12382" target="_blank">arXiv:2101.12382</a> [<a href="http://arxiv.org/pdf/2101.12382" target="_blank">pdf</a>]

<h2>Fair Resource Allocation for Demands with Sharp Lower Tail Inequalities. (arXiv:2101.12403v1 [cs.LG])</h2>
<h3>Vacharapat Mettanant, Jittat Fakcharoenphol</h3>
<p>We consider a fairness problem in resource allocation where multiple groups
demand resources from a common source with the total fixed amount. The general
model was introduced by Elzayn et al. [FAT*'19]. We follow Donahue and
Kleinberg [FAT*'20] who considered the case when the demand distribution is
known. We show that for many common demand distributions that satisfy sharp
lower tail inequalities, a natural allocation that provides resources
proportional to each group's average demand performs very well. More
specifically, this natural allocation is approximately fair and efficient
(i.e., it provides near maximum utilization). We also show that, when small
amount of unfairness is allowed, the Price of Fairness (PoF), in this case, is
close to 1.
</p>
<a href="http://arxiv.org/abs/2101.12403" target="_blank">arXiv:2101.12403</a> [<a href="http://arxiv.org/pdf/2101.12403" target="_blank">pdf</a>]

<h2>Multi-Threshold Attention U-Net (MTAU) based Model for Multimodal Brain Tumor Segmentation in MRI scans. (arXiv:2101.12404v1 [cs.CV])</h2>
<h3>Navchetan Awasthi, Rohit Pardasani, Swati Gupta</h3>
<p>Gliomas are one of the most frequent brain tumors and are classified into
high grade and low grade gliomas. The segmentation of various regions such as
tumor core, enhancing tumor etc. plays an important role in determining
severity and prognosis. Here, we have developed a multi-threshold model based
on attention U-Net for identification of various regions of the tumor in
magnetic resonance imaging (MRI). We propose a multi-path segmentation and
built three separate models for the different regions of interest. The proposed
model achieved mean Dice Coefficient of 0.59, 0.72, and 0.61 for enhancing
tumor, whole tumor and tumor core respectively on the training dataset. The
same model gave mean Dice Coefficient of 0.57, 0.73, and 0.61 on the validation
dataset and 0.59, 0.72, and 0.57 on the test dataset.
</p>
<a href="http://arxiv.org/abs/2101.12404" target="_blank">arXiv:2101.12404</a> [<a href="http://arxiv.org/pdf/2101.12404" target="_blank">pdf</a>]

<h2>An adaptive artificial neural network-based generative design method for layout designs. (arXiv:2101.12410v1 [cs.LG])</h2>
<h3>Chao Qian, Renkai Tan, Wenjing Ye</h3>
<p>Layout designs are encountered in a variety of fields. For problems with many
design degrees of freedom, efficiency of design methods becomes a major
concern. In recent years, machine learning methods such as artificial neural
networks have been used increasingly to speed up the design process. A main
issue of many such approaches is the need for a large corpus of training data
that are generated using high-dimensional simulations. The high computational
cost associated with training data generation largely diminishes the efficiency
gained by using machine learning methods. In this work, an adaptive artificial
neural network-based generative design approach is proposed and developed. This
method uses a generative adversarial network to generate design candidates and
thus the number of design variables is greatly reduced. To speed up the
evaluation of the objective function, a convolutional neural network is
constructed as the surrogate model for function evaluation. The inverse design
is carried out using the genetic algorithm in conjunction with two neural
networks. A novel adaptive learning and optimization strategy is proposed,
which allows the design space to be effectively explored for the search for
optimal solutions. As such the number of training data needed is greatly
reduced. The performance of the proposed design method is demonstrated on two
heat source layout design problems. In both problems, optimal designs have been
obtained. Compared with several existing approaches, the proposed approach has
the best performance in terms of accuracy and efficiency.
</p>
<a href="http://arxiv.org/abs/2101.12410" target="_blank">arXiv:2101.12410</a> [<a href="http://arxiv.org/pdf/2101.12410" target="_blank">pdf</a>]

<h2>A note on synthesizing geodesic based contact curves. (arXiv:2101.12411v1 [cs.RO])</h2>
<h3>Rajesh Kumar, Sudipto Mukherjee</h3>
<p>The paper focuses on synthesizing optimal contact curves that can be used to
ensure a rolling constraint between two bodies in relative motion. We show that
geodesic based contact curves generated on both the contacting surfaces are
sufficient conditions to ensure rolling. The differential geodesic equations,
when modified, can ensure proper disturbance rejection in case the system of
interacting bodies is perturbed from the desired curve. A corollary states that
geodesic curves are generated on the surface if rolling constraints are
satisfied. Simulations in the context of in-hand manipulations of the objects
are used as examples.
</p>
<a href="http://arxiv.org/abs/2101.12411" target="_blank">arXiv:2101.12411</a> [<a href="http://arxiv.org/pdf/2101.12411" target="_blank">pdf</a>]

<h2>Low Rank Forecasting. (arXiv:2101.12414v1 [stat.ML])</h2>
<h3>Shane Barratt, Yining Dong, Stephen Boyd</h3>
<p>We consider the problem of forecasting multiple values of the future of a
vector time series, using some past values. This problem, and related ones such
as one-step-ahead prediction, have a very long history, and there are a number
of well-known methods for it, including vector auto-regressive models,
state-space methods, multi-task regression, and others. Our focus is on low
rank forecasters, which break forecasting up into two steps: estimating a
vector that can be interpreted as a latent state, given the past, and then
estimating the future values of the time series, given the latent state
estimate. We introduce the concept of forecast consistency, which means that
the estimates of the same value made at different times are consistent. We
formulate the forecasting problem in general form, and focus on linear
forecasters, for which we propose a formulation that can be solved via convex
optimization. We describe a number of extensions and variations, including
nonlinear forecasters, data weighting, the inclusion of auxiliary data, and
additional objective terms. We illustrate our methods with several examples.
</p>
<a href="http://arxiv.org/abs/2101.12414" target="_blank">arXiv:2101.12414</a> [<a href="http://arxiv.org/pdf/2101.12414" target="_blank">pdf</a>]

<h2>Covariance Prediction via Convex Optimization. (arXiv:2101.12416v1 [stat.ML])</h2>
<h3>Shane Barratt, Stephen Boyd</h3>
<p>We consider the problem of predicting the covariance of a zero mean Gaussian
vector, based on another feature vector. We describe a covariance predictor
that has the form of a generalized linear model, i.e., an affine function of
the features followed by an inverse link function that maps vectors to
symmetric positive definite matrices. The log-likelihood is a concave function
of the predictor parameters, so fitting the predictor involves convex
optimization. Such predictors can be combined with others, or recursively
applied to improve performance.
</p>
<a href="http://arxiv.org/abs/2101.12416" target="_blank">arXiv:2101.12416</a> [<a href="http://arxiv.org/pdf/2101.12416" target="_blank">pdf</a>]

<h2>Subgraph nomination: Query by Example Subgraph Retrieval in Networks. (arXiv:2101.12430v1 [cs.LG])</h2>
<h3>Al-Fahad M. Al-Qadhi, Carey E. Priebe, Hayden S. Helm, Vince Lyzinski</h3>
<p>This paper introduces the subgraph nomination inference task, in which
example subgraphs of interest are used to query a network for similarly
interesting subgraphs. This type of problem appears time and again in real
world problems connected to, for example, user recommendation systems and
structural retrieval tasks in social and biological/connectomic networks. We
formally define the subgraph nomination framework with an emphasis on the
notion of a user-in-the-loop in the subgraph nomination pipeline. In this
setting, a user can provide additional post-nomination light supervision that
can be incorporated into the retrieval task. After introducing and formalizing
the retrieval task, we examine the nuanced effect that user-supervision can
have on performance, both analytically and across real and simulated data
examples.
</p>
<a href="http://arxiv.org/abs/2101.12430" target="_blank">arXiv:2101.12430</a> [<a href="http://arxiv.org/pdf/2101.12430" target="_blank">pdf</a>]

<h2>Learning Twofold Heterogeneous Multi-Task by Sharing Similar Convolution Kernel Pairs. (arXiv:2101.12431v1 [cs.LG])</h2>
<h3>Quan Feng, Songcan Chen</h3>
<p>Heterogeneous multi-task learning (HMTL) is an important topic in multi-task
learning (MTL). Most existing HMTL methods usually solve either scenario where
all tasks reside in the same input (feature) space yet unnecessarily the
consistent output (label) space or scenario where their input (feature) spaces
are heterogeneous while the output (label) space is consistent. However, to the
best of our knowledge, there is limited study on twofold heterogeneous MTL
(THMTL) scenario where the input and the output spaces are both inconsistent or
heterogeneous. In order to handle this complicated scenario, in this paper, we
design a simple and effective multi-task adaptive learning (MTAL) network to
learn multiple tasks in such THMTL setting. Specifically, we explore and
utilize the inherent relationship between tasks for knowledge sharing from
similar convolution kernels in individual layers of the MTAL network. Then in
order to realize the sharing, we weightedly aggregate any pair of convolutional
kernels with their similarity greater than some threshold $\rho$, consequently,
our model effectively performs cross-task learning while suppresses the
intra-redundancy of the entire network. Finally, we conduct end-to-end
training. Our experimental results demonstrate the effectiveness of our method
in comparison with the state-of-the-art counterparts.
</p>
<a href="http://arxiv.org/abs/2101.12431" target="_blank">arXiv:2101.12431</a> [<a href="http://arxiv.org/pdf/2101.12431" target="_blank">pdf</a>]

<h2>Spatiotemporal Dilated Convolution with Uncertain Matching for Video-based Crowd Estimation. (arXiv:2101.12439v1 [cs.CV])</h2>
<h3>Yu-Jen Ma, Hong-Han Shuai, Wen-Huang Cheng</h3>
<p>In this paper, we propose a novel SpatioTemporal convolutional Dense Network
(STDNet) to address the video-based crowd counting problem, which contains the
decomposition of 3D convolution and the 3D spatiotemporal dilated dense
convolution to alleviate the rapid growth of the model size caused by the
Conv3D layer. Moreover, since the dilated convolution extracts the multiscale
features, we combine the dilated convolution with the channel attention block
to enhance the feature representations. Due to the error that occurs from the
difficulty of labeling crowds, especially for videos, imprecise or
standard-inconsistent labels may lead to poor convergence for the model. To
address this issue, we further propose a new patch-wise regression loss (PRL)
to improve the original pixel-wise loss. Experimental results on three
video-based benchmarks, i.e., the UCSD, Mall and WorldExpo'10 datasets, show
that STDNet outperforms both image- and video-based state-of-the-art methods.
The source codes are released at \url{https://github.com/STDNet/STDNet}.
</p>
<a href="http://arxiv.org/abs/2101.12439" target="_blank">arXiv:2101.12439</a> [<a href="http://arxiv.org/pdf/2101.12439" target="_blank">pdf</a>]

<h2>Counterfactual State Explanations for Reinforcement Learning Agents via Generative Deep Learning. (arXiv:2101.12446v1 [cs.AI])</h2>
<h3>Matthew L. Olson, Roli Khanna, Lawrence Neal, Fuxin Li, Weng-Keen Wong</h3>
<p>Counterfactual explanations, which deal with "why not?" scenarios, can
provide insightful explanations to an AI agent's behavior. In this work, we
focus on generating counterfactual explanations for deep reinforcement learning
(RL) agents which operate in visual input environments like Atari. We introduce
counterfactual state explanations, a novel example-based approach to
counterfactual explanations based on generative deep learning. Specifically, a
counterfactual state illustrates what minimal change is needed to an Atari game
image such that the agent chooses a different action. We also evaluate the
effectiveness of counterfactual states on human participants who are not
machine learning experts. Our first user study investigates if humans can
discern if the counterfactual state explanations are produced by the actual
game or produced by a generative deep learning approach. Our second user study
investigates if counterfactual state explanations can help non-expert
participants identify a flawed agent; we compare against a baseline approach
based on a nearest neighbor explanation which uses images from the actual game.
Our results indicate that counterfactual state explanations have sufficient
fidelity to the actual game images to enable non-experts to more effectively
identify a flawed RL agent compared to the nearest neighbor baseline and to
having no explanation at all.
</p>
<a href="http://arxiv.org/abs/2101.12446" target="_blank">arXiv:2101.12446</a> [<a href="http://arxiv.org/pdf/2101.12446" target="_blank">pdf</a>]

<h2>The Mind's Eye: Visualizing Class-Agnostic Features of CNNs. (arXiv:2101.12447v1 [cs.CV])</h2>
<h3>Alexandros Stergiou</h3>
<p>Visual interpretability of Convolutional Neural Networks (CNNs) has gained
significant popularity because of the great challenges that CNN complexity
imposes to understanding their inner workings. Although many techniques have
been proposed to visualize class features of CNNs, most of them do not provide
a correspondence between inputs and the extracted features in specific layers.
This prevents the discovery of stimuli that each layer responds better to. We
propose an approach to visually interpret CNN features given a set of images by
creating corresponding images that depict the most informative features of a
specific layer. Exploring features in this class-agnostic manner allows for a
greater focus on the feature extractor of CNNs. Our method uses a
dual-objective activation maximization and distance minimization loss, without
requiring a generator network nor modifications to the original model. This
limits the number of FLOPs to that of the original network. We demonstrate the
visualization quality on widely-used architectures.
</p>
<a href="http://arxiv.org/abs/2101.12447" target="_blank">arXiv:2101.12447</a> [<a href="http://arxiv.org/pdf/2101.12447" target="_blank">pdf</a>]

<h2>AGSTN: Learning Attention-adjusted Graph Spatio-Temporal Networks for Short-term Urban Sensor Value Forecasting. (arXiv:2101.12465v1 [cs.LG])</h2>
<h3>Yi-Ju Lu, Cheng-Te Li</h3>
<p>Forecasting spatio-temporal correlated time series of sensor values is
crucial in urban applications, such as air pollution alert, biking resource
management, and intelligent transportation systems. While recent advances
exploit graph neural networks (GNN) to better learn spatial and temporal
dependencies between sensors, they cannot model time-evolving spatio-temporal
correlation (STC) between sensors, and require pre-defined graphs, which are
neither always available nor totally reliable, and target at only a specific
type of sensor data at one time. Moreover, since the form of time-series
fluctuation is varied across sensors, a model needs to learn fluctuation
modulation. To tackle these issues, in this work, we propose a novel GNN-based
model, Attention-adjusted Graph Spatio-Temporal Network (AGSTN). In AGSTN,
multi-graph convolution with sequential learning is developed to learn
time-evolving STC. Fluctuation modulation is realized by a proposed attention
adjustment mechanism. Experiments on three sensor data, air quality, bike
demand, and traffic flow, exhibit that AGSTN outperforms the state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/2101.12465" target="_blank">arXiv:2101.12465</a> [<a href="http://arxiv.org/pdf/2101.12465" target="_blank">pdf</a>]

<h2>Contact Pose Identification for Peg-in-Hole Assembly under Uncertainties. (arXiv:2101.12467v1 [cs.RO])</h2>
<h3>Shiyu Jin, Xinghao Zhu, Changhao Wang, Masayoshi Tomizuka</h3>
<p>Peg-in-hole assembly is a challenging contact-rich manipulation task. There
is no general solution to identify the relative position and orientation
between the peg and the hole. In this paper, we propose a novel method to
classify the contact poses based on a sequence of contact measurements. When
the peg contacts the hole with pose uncertainties, a tilt-then-rotate strategy
is applied, and the contacts are measured as a group of patterns to encode the
contact pose. A convolutional neural network (CNN) is trained to classify the
contact poses according to the patterns. In the end, an admittance controller
guides the peg towards the error direction and finishes the peg-in-hole
assembly. Simulations and experiments are provided to show that the proposed
method can be applied to the peg-in-hole assembly of different geometries. We
also demonstrate the ability to alleviate the sim-to-real gap.
</p>
<a href="http://arxiv.org/abs/2101.12467" target="_blank">arXiv:2101.12467</a> [<a href="http://arxiv.org/pdf/2101.12467" target="_blank">pdf</a>]

<h2>Beyond traditional assumptions in fair machine learning. (arXiv:2101.12476v1 [cs.LG])</h2>
<h3>Niki Kilbertus</h3>
<p>This thesis scrutinizes common assumptions underlying traditional machine
learning approaches to fairness in consequential decision making. After
challenging the validity of these assumptions in real-world applications, we
propose ways to move forward when they are violated. First, we show that group
fairness criteria purely based on statistical properties of observed data are
fundamentally limited. Revisiting this limitation from a causal viewpoint we
develop a more versatile conceptual framework, causal fairness criteria, and
first algorithms to achieve them. We also provide tools to analyze how
sensitive a believed-to-be causally fair algorithm is to misspecifications of
the causal graph. Second, we overcome the assumption that sensitive data is
readily available in practice. To this end we devise protocols based on secure
multi-party computation to train, validate, and contest fair decision
algorithms without requiring users to disclose their sensitive data or decision
makers to disclose their models. Finally, we also accommodate the fact that
outcome labels are often only observed when a certain decision has been made.
We suggest a paradigm shift away from training predictive models towards
directly learning decisions to relax the traditional assumption that labels can
always be recorded. The main contribution of this thesis is the development of
theoretically substantiated and practically feasible methods to move research
on fair machine learning closer to real-world applications.
</p>
<a href="http://arxiv.org/abs/2101.12476" target="_blank">arXiv:2101.12476</a> [<a href="http://arxiv.org/pdf/2101.12476" target="_blank">pdf</a>]

<h2>Neural networks for semantic segmentation of historical city maps: Cross-cultural performance and the impact of figurative diversity. (arXiv:2101.12478v1 [cs.CV])</h2>
<h3>R&#xe9;mi Petitpierre (Ecole polytechnique f&#xe9;d&#xe9;rale de Lausanne, EPFL, Switzerland)</h3>
<p>In this work, we present a new semantic segmentation model for historical
city maps that surpasses the state of the art in terms of flexibility and
performance. Research in automatic map processing is largely focused on
homogeneous corpora or even individual maps, leading to inflexible algorithms.
Recently, convolutional neural networks have opened new perspectives for the
development of more generic tools. Based on two new maps corpora, the first one
centered on Paris and the second one gathering cities from all over the world,
we propose a method for operationalizing the figuration based on traditional
computer vision algorithms that allows large-scale quantitative analysis. In a
second step, we propose a semantic segmentation model based on neural networks
and implement several improvements. Finally, we analyze the impact of map
figuration on segmentation performance and evaluate future ways to improve the
representational flexibility of neural networks. To conclude, we show that
these networks are able to semantically segment map data of a very large
figurative diversity with efficiency.
</p>
<a href="http://arxiv.org/abs/2101.12478" target="_blank">arXiv:2101.12478</a> [<a href="http://arxiv.org/pdf/2101.12478" target="_blank">pdf</a>]

<h2>Self-Supervised Representation Learning for RGB-D Salient Object Detection. (arXiv:2101.12482v1 [cs.CV])</h2>
<h3>Xiaoqi Zhao, Youwei Pang, Lihe Zhang, Huchuan Lu, Xiang Ruan</h3>
<p>Existing CNNs-Based RGB-D Salient Object Detection (SOD) networks are all
required to be pre-trained on the ImageNet to learn the hierarchy features
which can help to provide a good initialization. However, the collection and
annotation of large-scale datasets are time-consuming and expensive. In this
paper, we utilize Self-Supervised Representation Learning (SSL) to design two
pretext tasks: the cross-modal auto-encoder and the depth-contour estimation.
Our pretext tasks require only a few and unlabeled RGB-D datasets to perform
pre-training, which make the network capture rich semantic contexts as well as
reduce the gap between two modalities, thereby providing an effective
initialization for the downstream task. In addition, for the inherent problem
of cross-modal fusion in RGB-D SOD, we propose a multi-path fusion (MPF) module
that splits a single feature fusion into multi-path fusion to achieve an
adequate perception of consistent and differential information. The MPF module
is general and suitable for both cross-modal and cross-level feature fusion.
Extensive experiments on six benchmark RGB-D SOD datasets, our model
pre-trained on the RGB-D dataset ($6,335$ without any annotations) can perform
favorably against most state-of-the-art RGB-D methods pre-trained on ImageNet
($1,280,000$ with image-level annotations).
</p>
<a href="http://arxiv.org/abs/2101.12482" target="_blank">arXiv:2101.12482</a> [<a href="http://arxiv.org/pdf/2101.12482" target="_blank">pdf</a>]

<h2>Efficient-CapsNet: Capsule Network with Self-Attention Routing. (arXiv:2101.12491v1 [cs.CV])</h2>
<h3>Vittorio Mazzia, Francesco Salvetti, Marcello Chiaberge</h3>
<p>Deep convolutional neural networks, assisted by architectural design
strategies, make extensive use of data augmentation techniques and layers with
a high number of feature maps to embed object transformations. That is highly
inefficient and for large datasets implies a massive redundancy of features
detectors. Even though capsules networks are still in their infancy, they
constitute a promising solution to extend current convolutional networks and
endow artificial visual perception with a process to encode more efficiently
all feature affine transformations. Indeed, a properly working capsule network
should theoretically achieve higher results with a considerably lower number of
parameters count due to intrinsic capability to generalize to novel viewpoints.
Nevertheless, little attention has been given to this relevant aspect. In this
paper, we investigate the efficiency of capsule networks and, pushing their
capacity to the limits with an extreme architecture with barely 160K
parameters, we prove that the proposed architecture is still able to achieve
state-of-the-art results on three different datasets with only 2% of the
original CapsNet parameters. Moreover, we replace dynamic routing with a novel
non-iterative, highly parallelizable routing algorithm that can easily cope
with a reduced number of capsules. Extensive experimentation with other capsule
implementations has proved the effectiveness of our methodology and the
capability of capsule networks to efficiently embed visual representations more
prone to generalization.
</p>
<a href="http://arxiv.org/abs/2101.12491" target="_blank">arXiv:2101.12491</a> [<a href="http://arxiv.org/pdf/2101.12491" target="_blank">pdf</a>]

<h2>Learning-based vs Model-free Adaptive Control of a MAV under Wind Gust. (arXiv:2101.12501v1 [cs.RO])</h2>
<h3>Thomas Chaffre, Julien Moras, Adrien Chan-Hon-Tong, Julien Marzat, Karl Sammut, Gilles Le Chenadec, Benoit Clement</h3>
<p>Navigation problems under unknown varying conditions are among the most
important and well-studied problems in the control field. Classic model-based
adaptive control methods can be applied only when a convenient model of the
plant or environment is provided. Recent model-free adaptive control methods
aim at removing this dependency by learning the physical characteristics of the
plant and/or process directly from sensor feedback. Although there have been
prior attempts at improving these techniques, it remains an open question as to
whether it is possible to cope with real-world uncertainties in a control
system that is fully based on either paradigm. We propose a conceptually simple
learning-based approach composed of a full state feedback controller, tuned
robustly by a deep reinforcement learning framework based on the Soft
Actor-Critic algorithm. We compare it, in realistic simulations, to a
model-free controller that uses the same deep reinforcement learning framework
for the control of a micro aerial vehicle under wind gust. The results indicate
the great potential of learning-based adaptive control methods in modern
dynamical systems.
</p>
<a href="http://arxiv.org/abs/2101.12501" target="_blank">arXiv:2101.12501</a> [<a href="http://arxiv.org/pdf/2101.12501" target="_blank">pdf</a>]

<h2>Learning User Preferences in Non-Stationary Environments. (arXiv:2101.12506v1 [cs.LG])</h2>
<h3>Wasim Huleihel, Soumyabrata Pal, Ofer Shayevitz</h3>
<p>Recommendation systems often use online collaborative filtering (CF)
algorithms to identify items a given user likes over time, based on ratings
that this user and a large number of other users have provided in the past.
This problem has been studied extensively when users' preferences do not change
over time (static case); an assumption that is often violated in practical
settings. In this paper, we introduce a novel model for online non-stationary
recommendation systems which allows for temporal uncertainties in the users'
preferences. For this model, we propose a user-based CF algorithm, and provide
a theoretical analysis of its achievable reward. Compared to related
non-stationary multi-armed bandit literature, the main fundamental difficulty
in our model lies in the fact that variations in the preferences of a certain
user may affect the recommendations for other users severely. We also test our
algorithm over real-world datasets, showing its effectiveness in real-world
applications. One of the main surprising observations in our experiments is the
fact our algorithm outperforms other static algorithms even when preferences do
not change over time. This hints toward the general conclusion that in
practice, dynamic algorithms, such as the one we propose, might be beneficial
even in stationary environments.
</p>
<a href="http://arxiv.org/abs/2101.12506" target="_blank">arXiv:2101.12506</a> [<a href="http://arxiv.org/pdf/2101.12506" target="_blank">pdf</a>]

<h2>Challenges for Using Impact Regularizers to Avoid Negative Side Effects. (arXiv:2101.12509v1 [cs.LG])</h2>
<h3>David Lindner, Kyle Matoba, Alexander Meulemans</h3>
<p>Designing reward functions for reinforcement learning is difficult: besides
specifying which behavior is rewarded for a task, the reward also has to
discourage undesired outcomes. Misspecified reward functions can lead to
unintended negative side effects, and overall unsafe behavior. To overcome this
problem, recent work proposed to augment the specified reward function with an
impact regularizer that discourages behavior that has a big impact on the
environment. Although initial results with impact regularizers seem promising
in mitigating some types of side effects, important challenges remain. In this
paper, we examine the main current challenges of impact regularizers and relate
them to fundamental design decisions. We discuss in detail which challenges
recent approaches address and which remain unsolved. Finally, we explore
promising directions to overcome the unsolved challenges in preventing negative
side effects with impact regularizers.
</p>
<a href="http://arxiv.org/abs/2101.12509" target="_blank">arXiv:2101.12509</a> [<a href="http://arxiv.org/pdf/2101.12509" target="_blank">pdf</a>]

<h2>Complementary Pseudo Labels For Unsupervised Domain Adaptation On Person Re-identification. (arXiv:2101.12521v1 [cs.CV])</h2>
<h3>Hao Feng, Minghao Chen, Jinming Hu, Dong Shen, Haifeng Liu, Deng Cai</h3>
<p>In recent years, supervised person re-identification (re-ID) models have
received increasing studies. However, these models trained on the source domain
always suffer dramatic performance drop when tested on an unseen domain.
Existing methods are primary to use pseudo labels to alleviate this problem.
One of the most successful approaches predicts neighbors of each unlabeled
image and then uses them to train the model. Although the predicted neighbors
are credible, they always miss some hard positive samples, which may hinder the
model from discovering important discriminative information of the unlabeled
domain. In this paper, to complement these low recall neighbor pseudo labels,
we propose a joint learning framework to learn better feature embeddings via
high precision neighbor pseudo labels and high recall group pseudo labels. The
group pseudo labels are generated by transitively merging neighbors of
different samples into a group to achieve higher recall. However, the merging
operation may cause subgroups in the group due to imperfect neighbor
predictions. To utilize these group pseudo labels properly, we propose using a
similarity-aggregating loss to mitigate the influence of these subgroups by
pulling the input sample towards the most similar embeddings. Extensive
experiments on three large-scale datasets demonstrate that our method can
achieve state-of-the-art performance under the unsupervised domain adaptation
re-ID setting.
</p>
<a href="http://arxiv.org/abs/2101.12521" target="_blank">arXiv:2101.12521</a> [<a href="http://arxiv.org/pdf/2101.12521" target="_blank">pdf</a>]

<h2>Optimal strategies for reject option classifiers. (arXiv:2101.12523v1 [cs.LG])</h2>
<h3>V. Franc, D. Prusa, V. Voracek</h3>
<p>In classification with a reject option, the classifier is allowed in
uncertain cases to abstain from prediction. The classical cost-based model of a
reject option classifier requires the cost of rejection to be defined
explicitly. An alternative bounded-improvement model, avoiding the notion of
the reject cost, seeks for a classifier with a guaranteed selective risk and
maximal cover. We coin a symmetric definition, the bounded-coverage model,
which seeks for a classifier with minimal selective risk and guaranteed
coverage. We prove that despite their different formulations the three
rejection models lead to the same prediction strategy: a Bayes classifier
endowed with a randomized Bayes selection function. We define a notion of a
proper uncertainty score as a scalar summary of prediction uncertainty
sufficient to construct the randomized Bayes selection function. We propose two
algorithms to learn the proper uncertainty score from examples for an arbitrary
black-box classifier. We prove that both algorithms provide Fisher consistent
estimates of the proper uncertainty score and we demonstrate their efficiency
on different prediction problems including classification, ordinal regression
and structured output classification.
</p>
<a href="http://arxiv.org/abs/2101.12523" target="_blank">arXiv:2101.12523</a> [<a href="http://arxiv.org/pdf/2101.12523" target="_blank">pdf</a>]

<h2>Few-Shot Learning for Road Object Detection. (arXiv:2101.12543v1 [cs.CV])</h2>
<h3>Anay Majee, Kshitij Agrawal, Anbumani Subramanian</h3>
<p>Few-shot learning is a problem of high interest in the evolution of deep
learning. In this work, we consider the problem of few-shot object detection
(FSOD) in a real-world, class-imbalanced scenario. For our experiments, we
utilize the India Driving Dataset (IDD), as it includes a class of
less-occurring road objects in the image dataset and hence provides a setup
suitable for few-shot learning. We evaluate both metric-learning and
meta-learning based FSOD methods, in two experimental settings: (i)
representative (same-domain) splits from IDD, that evaluates the ability of a
model to learn in the context of road images, and (ii) object classes with
less-occurring object samples, similar to the open-set setting in real-world.
From our experiments, we demonstrate that the metric-learning method
outperforms meta-learning on the novel classes by (i) 11.2 mAP points on the
same domain, and (ii) 1.0 mAP point on the open-set. We also show that our
extension of object classes in a real-world open dataset offers a rich ground
for few-shot learning studies.
</p>
<a href="http://arxiv.org/abs/2101.12543" target="_blank">arXiv:2101.12543</a> [<a href="http://arxiv.org/pdf/2101.12543" target="_blank">pdf</a>]

<h2>BridgeDPI: A Novel Graph Neural Network for Predicting Drug-Protein Interactions. (arXiv:2101.12547v1 [cs.LG])</h2>
<h3>Yifan Wu, Min Gao, Min Zeng, Feiyang Chen, Min Li, Jie Zhang</h3>
<p>Motivation: Exploring drug-protein interactions (DPIs) work as a pivotal step
in drug discovery. The fast expansion of available biological data enables
computational methods effectively assist in experimental methods. Among them,
deep learning methods extract features only from basic characteristics, such as
protein sequences, molecule structures. Others achieve significant improvement
by learning from not only sequences/molecules but the protein-protein and
drug-drug associations (PPAs and DDAs). The PPAs and DDAs are generally
obtained by using computational methods. However, existing computational
methods have some limitations, resulting in low-quality PPAs and DDAs that
hamper the prediction performance. Therefore, we hope to develop a novel
supervised learning method to learn the PPAs and DDAs effectively and thereby
improve the prediction performance of the specific task of DPI. Results: In
this research, we propose a novel deep learning framework, namely BridgeDPI.
BridgeDPI introduces a class of nodes named hyper-nodes, which bridge different
proteins/drugs to work as PPAs and DDAs. The hyper-nodes can be supervised
learned for the specific task of DPI since the whole process is an end-to-end
learning. Consequently, such a model would improve prediction performance of
DPI. In three real-world datasets, we further demonstrate that BridgeDPI
outperforms state-of-the-art methods. Moreover, ablation studies verify the
effectiveness of the hyper-nodes. Last, in an independent verification,
BridgeDPI explores the candidate bindings among COVID-19's proteins and various
antiviral drugs. And the predictive results accord with the statement of the
World Health Organization and Food and Drug Administration, showing the
validity and reliability of BridgeDPI.
</p>
<a href="http://arxiv.org/abs/2101.12547" target="_blank">arXiv:2101.12547</a> [<a href="http://arxiv.org/pdf/2101.12547" target="_blank">pdf</a>]

<h2>Interleaving Graph Search and Trajectory Optimization for Aggressive Quadrotor Flight. (arXiv:2101.12548v1 [cs.RO])</h2>
<h3>Ramkumar Natarajan, Howie Choset, Maxim Likhachev</h3>
<p>Quadrotors can achieve aggressive flight by tracking complex maneuvers and
rapidly changing directions. Planning for aggressive flight with trajectory
optimization could be incredibly fast, even in higher dimensions, and can
account for dynamics of the quadrotor, however, only provides a locally optimal
solution. On the other hand, planning with discrete graph search can handle
non-convex spaces to guarantee optimality but suffers from exponential
complexity with the dimension of search. We introduce a framework for
aggressive quadrotor trajectory generation with global reasoning capabilities
that combines the best of trajectory optimization and discrete graph search.
Specifically, we develop a novel algorithmic framework that
\textit{interleaves} these two methods to complement each other and generate
trajectories with provable guarantees on completeness up to discretization. We
demonstrate and quantitatively analyze the performance of our algorithm in
challenging simulation environments with narrow gaps that create severe
attitude constraints and push the dynamic capabilities of the quadrotor.
Experiments show the benefits of the proposed algorithmic framework over
standalone trajectory optimization and graph search-based planning techniques
for aggressive quadrotor flight.
</p>
<a href="http://arxiv.org/abs/2101.12548" target="_blank">arXiv:2101.12548</a> [<a href="http://arxiv.org/pdf/2101.12548" target="_blank">pdf</a>]

<h2>Constrained Probabilistic Movement Primitives for Robot Trajectory Adaptation. (arXiv:2101.12561v1 [cs.RO])</h2>
<h3>Felix Frank, Alexandros Paraschos, Patrick van der Smagt, Botond Cseke</h3>
<p>Versatile movement representations allow robots to learn new tasks and
rapidly adapt them to environmental changes, e.g. introduction of obstacles,
placing additional robots in the workspace, modification of the joint range due
to faults or range of motion constraints due to tool manipulation.
Probabilistic movement primitives (ProMP) model robot movements as a
distribution over trajectories and they are an important tool due to their
analytical tractability and ability to learn and generalise from a small number
of demonstrations. Current approaches solve specific adaptation problems, e.g.
obstacle avoidance, however, a generic probabilistic approach to adaptation has
not yet been developed. In this paper we propose a generic probabilistic
framework for adapting ProMPs. We formulate adaptation as a constrained
optimisation problem where we minimise the Kullback-Leibler divergence between
the adapted distribution and the distribution of the original primitive and we
constrain the probability mass associated with undesired trajectories to be
low. We derive several types of constraints that can be added depending on the
task, such us joint limiting, various types of obstacle avoidance, via-points,
and mutual avoidance, under a common framework. We demonstrate our approach on
several adaptation problems on simulated planar robot arms and 7-DOF
Franka-Emika robots in single and dual robot arm settings.
</p>
<a href="http://arxiv.org/abs/2101.12561" target="_blank">arXiv:2101.12561</a> [<a href="http://arxiv.org/pdf/2101.12561" target="_blank">pdf</a>]

<h2>Adjusting for Autocorrelated Errors in Neural Networks for Time Series Regression and Forecasting. (arXiv:2101.12578v1 [cs.LG])</h2>
<h3>Fan-Keng Sun, Christopher I. Lang, Duane S. Boning</h3>
<p>In many cases, it is difficult to generate highly accurate models for time
series data using a known parametric model structure. In response, an
increasing body of research focuses on using neural networks to model time
series approximately. A common assumption in training neural networks on time
series is that the errors at different time steps are uncorrelated. However,
due to the temporality of the data, errors are actually autocorrelated in many
cases, which makes such maximum likelihood estimation inaccurate. In this
paper, we propose to learn the autocorrelation coefficient jointly with the
model parameters in order to adjust for autocorrelated errors. For time series
regression, large-scale experiments indicate that our method outperforms the
Prais-Winsten method, especially when the autocorrelation is strong.
Furthermore, we broaden our method to time series forecasting and apply it with
various state-of-the-art models. Results across a wide range of real-world
datasets show that our method enhances performance in almost all cases.
</p>
<a href="http://arxiv.org/abs/2101.12578" target="_blank">arXiv:2101.12578</a> [<a href="http://arxiv.org/pdf/2101.12578" target="_blank">pdf</a>]

<h2>Automated decontamination of workspaces using UVC coupled with occupancy detection. (arXiv:2101.12581v1 [cs.RO])</h2>
<h3>Asit Kumar Mishra, Federico Tartarini, Zuraimi Sultan, Stefano Schiavon</h3>
<p>Periodic disinfection of workspaces can reduce SARS-CoV-2 transmission. In
many buildings periodic disinfection is performed manually; this has several
disadvantages: it is expensive, limited in the number of times it can be done
over a day, and poses an increased risk to the workers performing the task. To
solve these problems, we developed an automated decontamination system that
uses ultraviolet C (UVC) radiation for disinfection, coupled with occupancy
detection for its safe operation. UVC irradiation is a well-established
technology for the deactivation of a wide range of pathogens. Our proposed
system can deactivate pathogens both on surfaces and in the air. The coupling
with occupancy detection ensures that occupants are never directly exposed to
UVC lights and their potential harmful effects. To help the wider community, we
have shared our complete work as an open-source repository, to be used under
GPL v3.
</p>
<a href="http://arxiv.org/abs/2101.12581" target="_blank">arXiv:2101.12581</a> [<a href="http://arxiv.org/pdf/2101.12581" target="_blank">pdf</a>]

<h2>Raspberry Pi Based Intelligent Robot that Recognizes and Places Puzzle Objects. (arXiv:2101.12584v1 [cs.RO])</h2>
<h3>Yakup Kutlu, Z&#xfc;lf&#xfc; Alanoglu, Ahmet G&#xf6;k&#xe7;en, Mustafa Yeniad</h3>
<p>In this study; in order to diagnose congestive heart failure (CHF) patients,
non-linear secondorder difference plot (SODP) obtained from raw 256 Hz sampled
frequency and windowed record with different time of ECG records are used. All
of the data rows are labelled with their belongings to classify much more
realistically. SODPs are divided into different radius of quadrant regions and
numbers of the points fall in the quadrants are computed in order to extract
feature vectors. Fisher's linear discriminant, Naive Bayes, and artificial
neural network are used as classifier. The results are considered in two step
validation methods as general kfold cross-validation and patient based
cross-validation. As a result, it is shown that using neural network classifier
with features obtained from SODP, the constructed system could distinguish
normal and CHF patients with 100% accuracy rate.
</p>
<a href="http://arxiv.org/abs/2101.12584" target="_blank">arXiv:2101.12584</a> [<a href="http://arxiv.org/pdf/2101.12584" target="_blank">pdf</a>]

<h2>No-Regret Caching via Online Mirror Descent. (arXiv:2101.12588v1 [cs.LG])</h2>
<h3>Tareq Si Salem, Giovanni Neglia, Stratis Ioannidis</h3>
<p>We study an online caching problem in which requests can be served by a local
cache to avoid retrieval costs from a remote server. The cache can update its
state after a batch of requests and store an arbitrarily small fraction of each
content. We study no-regret algorithms based on Online Mirror Descent (OMD)
strategies. We show that the optimal OMD strategy depends on the request
diversity present in a batch. We also prove that, when the cache must store the
entire content, rather than a fraction, OMD strategies can be coupled with a
randomized rounding scheme that preserves regret guarantees.
</p>
<a href="http://arxiv.org/abs/2101.12588" target="_blank">arXiv:2101.12588</a> [<a href="http://arxiv.org/pdf/2101.12588" target="_blank">pdf</a>]

<h2>Open World Compositional Zero-Shot Learning. (arXiv:2101.12609v1 [cs.CV])</h2>
<h3>Massimiliano Mancini, Muhammad Ferjad Naeem, Yongqin Xian, Zeynep Akata</h3>
<p>Compositional Zero-Shot learning (CZSL) requires to recognize state-object
compositions unseen during training. In this work, instead of assuming the
presence of prior knowledge about the unseen compositions, we operate on the
open world setting, where the search space includes a large number of unseen
compositions some of which might be unfeasible. In this setting, we start from
the cosine similarity between visual features and compositional embeddings.
After estimating the feasibility score of each composition, we use these scores
to either directly mask the output space or as a margin for the cosine
similarity between visual features and compositional embeddings during
training. Our experiments on two standard CZSL benchmarks show that all the
methods suffer severe performance degradation when applied in the open world
setting. While our simple CZSL model achieves state-of-the-art performances in
the closed world scenario, our feasibility scores boost the performance of our
approach in the open world setting, clearly outperforming the previous state of
the art.
</p>
<a href="http://arxiv.org/abs/2101.12609" target="_blank">arXiv:2101.12609</a> [<a href="http://arxiv.org/pdf/2101.12609" target="_blank">pdf</a>]

<h2>DigitalExposome: Quantifying the Urban Environment Influence on Wellbeing based on Real-Time Multi-Sensor Fusion and Deep Belief Network. (arXiv:2101.12615v1 [cs.LG])</h2>
<h3>Thomas Johnson, Eiman Kanjo, Kieran Woodward</h3>
<p>In this paper, we define the term 'DigitalExposome' as a conceptual framework
that takes us closer towards understanding the relationship between
environment, personal characteristics, behaviour and wellbeing using multimodel
mobile sensing technology. Specifically, we simultaneously collected (for the
first time) multi-sensor data including urban environmental factors (e.g. air
pollution including: PM1, PM2.5, PM10, Oxidised, Reduced, NH3 and Noise, People
Count in the vicinity), body reaction (physiological reactions including: EDA,
HR, HRV, Body Temperature, BVP and movement) and individuals' perceived
responses (e.g. self-reported valence) in urban settings. Our users followed a
pre-specified urban path and collected the data using a comprehensive sensing
edge devices. The data is instantly fused, time-stamped and geo-tagged at the
point of collection. A range of multivariate statistical analysis techniques
have been applied including Principle Component Analysis, Regression and
spatial visualisations to unravel the relationship between the variables.
Results showed that EDA and Heart Rate Variability HRV are noticeably impacted
by the level of Particulate Matters (PM) in the environment well with the
environmental variables. Furthermore, we adopted Deep Belief Network to extract
features from the multimodel data feed which outperformed Convolutional Neural
Network and achieved up to (a=80.8%, {\sigma}=0.001) accuracy.
</p>
<a href="http://arxiv.org/abs/2101.12615" target="_blank">arXiv:2101.12615</a> [<a href="http://arxiv.org/pdf/2101.12615" target="_blank">pdf</a>]

<h2>Polynomial Trajectory Predictions for Improved Learning Performance. (arXiv:2101.12616v1 [cs.CV])</h2>
<h3>Ido Freeman, Kun Zhao, Anton Kummert</h3>
<p>The rising demand for Active Safety systems in automotive applications
stresses the need for a reliable short to mid-term trajectory prediction.
Anticipating the unfolding path of road users, one can act to increase the
overall safety. In this work, we propose to train artificial neural networks
for movement understanding by predicting trajectories in their natural form, as
a function of time. Predicting polynomial coefficients allows us to increased
accuracy and improve generalisation.
</p>
<a href="http://arxiv.org/abs/2101.12616" target="_blank">arXiv:2101.12616</a> [<a href="http://arxiv.org/pdf/2101.12616" target="_blank">pdf</a>]

<h2>The Deep Radial Basis Function Data Descriptor (D-RBFDD) Network: A One-Class Neural Network for Anomaly Detection. (arXiv:2101.12632v1 [cs.LG])</h2>
<h3>Mehran H. Z. Bazargani, Arjun Pakrashi, Brian Mac Namee</h3>
<p>Anomaly detection is a challenging problem in machine learning, and is even
more so when dealing with instances that are captured in low-level, raw data
representations without a well-behaved set of engineered features. The Radial
Basis Function Data Descriptor (RBFDD) network is an effective solution for
anomaly detection, however, it is a shallow model that does not deal
effectively with raw data representations. This paper investigates approaches
to modifying the RBFDD network to transform it into a deep one-class classifier
suitable for anomaly detection problems with low-level raw data
representations. We show that approaches based on transfer learning are not
effective and our results suggest that this is because the latent
representations learned by generic classification models are not suitable for
anomaly detection. Instead we show that an approach that adds multiple
convolutional layers before the RBF layer, to form a Deep Radial Basis Function
Data Descriptor (D-RBFDD) network, is very effective. This is shown in a set of
evaluation experiments using multiple anomaly detection scenarios created from
publicly available image classification datasets, and a real-world anomaly
detection dataset in which different types of arrhythmia are detected in
electrocardiogram (ECG) data. Our experiments show that the D-RBFDD network
out-performs state-of-the-art anomaly detection methods including the Deep
Support Vector Data Descriptor (Deep SVDD), One-Class SVM, and Isolation Forest
on the image datasets, and produces competitive results for the ECG dataset.
</p>
<a href="http://arxiv.org/abs/2101.12632" target="_blank">arXiv:2101.12632</a> [<a href="http://arxiv.org/pdf/2101.12632" target="_blank">pdf</a>]

<h2>Optimizing $\alpha\mu$. (arXiv:2101.12639v1 [cs.AI])</h2>
<h3>Tristan Cazenave, Swann Legras, V&#xe9;ronique Ventos</h3>
<p>$\alpha\mu$ is a search algorithm which repairs two defaults of Perfect
Information Monte Carlo search: strategy fusion and non locality. In this paper
we optimize $\alpha\mu$ for the game of Bridge, avoiding useless computations.
The proposed optimizations are general and apply to other imperfect information
turn-based games. We define multiple optimizations involving Pareto fronts, and
show that these optimizations speed up the search. Some of these optimizations
are cuts that stop the search at a node, while others keep track of which
possible worlds have become redundant, avoiding unnecessary, costly
evaluations. We also measure the benefits of parallelizing the double dummy
searches at the leaves of the $\alpha\mu$ search tree.
</p>
<a href="http://arxiv.org/abs/2101.12639" target="_blank">arXiv:2101.12639</a> [<a href="http://arxiv.org/pdf/2101.12639" target="_blank">pdf</a>]

<h2>Leveraging domain labels for object detection from UAVs. (arXiv:2101.12677v1 [cs.CV])</h2>
<h3>Benjamin Kiefer, Martin Messmer, Andreas Zell</h3>
<p>Object detection from Unmanned Aerial Vehicles (UAVs) is of great importance
in many aerial vision-based applications. Despite the great success of generic
object detection methods, a large performance drop is observed when applied to
images captured by UAVs. This is due to large variations in imaging conditions,
such as varying altitudes, dynamically changing viewing angles, and different
capture times. We demonstrate that domain knowledge is a valuable source of
information and thus propose domain-aware object detectors by using freely
accessible sensor data. By splitting the model into cross-domain and
domain-specific parts, substantial performance improvements are achieved on
multiple datasets across multiple models and metrics. In particular, we achieve
a new state-of-the-art performance on UAVDT for real-time detectors.
Furthermore, we create a new airborne image dataset by annotating 13 713
objects in 2 900 images featuring precise altitude and viewing angle
annotations.
</p>
<a href="http://arxiv.org/abs/2101.12677" target="_blank">arXiv:2101.12677</a> [<a href="http://arxiv.org/pdf/2101.12677" target="_blank">pdf</a>]

<h2>Total Stability of SVMs and Localized SVMs. (arXiv:2101.12678v1 [stat.ML])</h2>
<h3>Hannes K&#xf6;hler, Andreas Christmann</h3>
<p>Regularized kernel-based methods such as support vector machines (SVMs)
typically depend on the underlying probability measure $\mathrm{P}$
(respectively an empirical measure $\mathrm{D}_n$ in applications) as well as
on the regularization parameter $\lambda$ and the kernel $k$. Whereas classical
statistical robustness only considers the effect of small perturbations in
$\mathrm{P}$, the present paper investigates the influence of simultaneous
slight variations in the whole triple $(\mathrm{P},\lambda,k)$, respectively
$(\mathrm{D}_n,\lambda_n,k)$, on the resulting predictor. Existing results from
the literature are considerably generalized and improved. In order to also make
them applicable to big data, where regular SVMs suffer from their super-linear
computational requirements, we show how our results can be transferred to the
context of localized learning. Here, the effect of slight variations in the
applied regionalization, which might for example stem from changes in
$\mathrm{P}$ respectively $\mathrm{D}_n$, is considered as well.
</p>
<a href="http://arxiv.org/abs/2101.12678" target="_blank">arXiv:2101.12678</a> [<a href="http://arxiv.org/pdf/2101.12678" target="_blank">pdf</a>]

<h2>Towards Generalising Neural Implicit Representations. (arXiv:2101.12690v1 [cs.CV])</h2>
<h3>Theo W. Costain, Victor Adrian Prisacariu</h3>
<p>Neural implicit representations have shown substantial improvements in
efficiently storing 3D data, when compared to conventional formats. However,
the focus of existing work has mainly been on storage and subsequent
reconstruction. In this work, we argue that training neural representations for
both reconstruction tasks, alongside conventional tasks, can produce more
general encodings that admit equal quality reconstructions to single task
training, whilst providing improved results on conventional tasks when compared
to single task encodings. Through multi-task experiments on reconstruction,
classification, and segmentation our approach learns feature rich encodings
that produce high quality results for each task. We also reformulate the
segmentation task, creating a more representative challenge for implicit
representation contexts.
</p>
<a href="http://arxiv.org/abs/2101.12690" target="_blank">arXiv:2101.12690</a> [<a href="http://arxiv.org/pdf/2101.12690" target="_blank">pdf</a>]

<h2>Gaining Scale Invariance in UAV Bird's Eye View Object Detection by Adaptive Resizing. (arXiv:2101.12694v1 [cs.CV])</h2>
<h3>Martin Messmer, Benjamin Kiefer, Andreas Zell</h3>
<p>In this work, we introduce a new preprocessing step applicable to UAV bird's
eye view imagery, which we call Adaptive Resizing. It is constructed to adjust
the vast variances in objects' scales, which are naturally inherent to UAV data
sets. Furthermore, it improves inference speed by four to five times on
average. We test this extensively on UAVDT, VisDrone, and on a new data set, we
captured ourselves. On UAVDT, we achieve more than 100 % relative improvement
in AP50. Moreover, we show how this method can be applied to a general UAV
object detection task. Additionally, we successfully test our method on a
domain transfer task where we train on some interval of altitudes and test on a
different one. Code will be made available at our website.
</p>
<a href="http://arxiv.org/abs/2101.12694" target="_blank">arXiv:2101.12694</a> [<a href="http://arxiv.org/pdf/2101.12694" target="_blank">pdf</a>]

<h2>Layer-Peeled Model: Toward Understanding Well-Trained Deep Neural Networks. (arXiv:2101.12699v1 [cs.LG])</h2>
<h3>Cong Fang, Hangfeng He, Qi Long, Weijie J Su</h3>
<p>In this paper, we introduce the Layer-Peeled Model, a nonconvex yet
analytically tractable optimization program, in a quest to better understand
deep neural networks that are trained for a sufficiently long time. As the name
suggests, this new model is derived by isolating the topmost layer from the
remainder of the neural network, followed by imposing certain constraints
separately on the two parts. We demonstrate that the Layer-Peeled Model, albeit
simple, inherits many characteristics of well-trained neural networks, thereby
offering an effective tool for explaining and predicting common empirical
patterns of deep learning training. First, when working on class-balanced
datasets, we prove that any solution to this model forms a simplex equiangular
tight frame, which in part explains the recently discovered phenomenon of
neural collapse in deep learning training [PHD20]. Moreover, when moving to the
imbalanced case, our analysis of the Layer-Peeled Model reveals a hitherto
unknown phenomenon that we term Minority Collapse, which fundamentally limits
the performance of deep learning models on the minority classes. In addition,
we use the Layer-Peeled Model to gain insights into how to mitigate Minority
Collapse. Interestingly, this phenomenon is first predicted by the Layer-Peeled
Model before its confirmation by our computational experiments.
</p>
<a href="http://arxiv.org/abs/2101.12699" target="_blank">arXiv:2101.12699</a> [<a href="http://arxiv.org/pdf/2101.12699" target="_blank">pdf</a>]

<h2>Predicting Nanorobot Shapes via Generative Models. (arXiv:2101.12719v1 [cs.LG])</h2>
<h3>Emma Benjaminson (1), Rebecca E. Taylor (1,2,3), Matthew Travers (4) ((1) Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, (2) Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA, (3) Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh PA, (4) Robotics Institute, Carnegie Mellon University, Pittsburgh, PA)</h3>
<p>The field of DNA nanotechnology has made it possible to assemble, with high
yields, different structures that have actionable properties. For example,
researchers have created components that can be actuated. An exciting next step
is to combine these components into multifunctional nanorobots that could,
potentially, perform complex tasks like swimming to a target location in the
human body, detect an adverse reaction and then release a drug load to stop it.
However, as we start to assemble more complex nanorobots, the yield of the
desired nanorobot begins to decrease as the number of possible component
combinations increases. Therefore, the ultimate goal of this work is to develop
a predictive model to maximize yield. However, training predictive models
typically requires a large dataset. For the nanorobots we are interested in
assembling, this will be difficult to collect. This is because high-fidelity
data, which allows us to characterize the shape and size of individual
structures, is very time-consuming to collect, whereas low-fidelity data is
readily available but only captures bulk statistics for different processes.
Therefore, this work combines low- and high-fidelity data to train a generative
model using a two-step process. We first use a relatively small, high-fidelity
dataset to train a generative model. At run time, the model takes low-fidelity
data and uses it to approximate the high-fidelity content. We do this by
biasing the model towards samples with specific properties as measured by
low-fidelity data. In this work we bias our distribution towards a desired node
degree of a graphical model that we take as a surrogate representation of the
nanorobots that this work will ultimately focus on. We have not yet accumulated
a high-fidelity dataset of nanorobots, so we leverage the MolGAN architecture
[1] and the QM9 small molecule dataset [2-3] to demonstrate our approach.
</p>
<a href="http://arxiv.org/abs/2101.12719" target="_blank">arXiv:2101.12719</a> [<a href="http://arxiv.org/pdf/2101.12719" target="_blank">pdf</a>]

<h2>Surprisingly Simple Semi-Supervised Domain Adaptation with Pretraining and Consistency. (arXiv:2101.12727v1 [cs.CV])</h2>
<h3>Samarth Mishra, Kate Saenko, Venkatesh Saligrama</h3>
<p>Visual domain adaptation involves learning to classify images from a target
visual domain using labels available in a different source domain. A range of
prior work uses adversarial domain alignment to try and learn a domain
invariant feature space, where a good source classifier can perform well on
target data. This however, can lead to errors where class A features in the
target domain get aligned to class B features in source. We show that in the
presence of a few target labels, simple techniques like self-supervision (via
rotation prediction) and consistency regularization can be effective without
any adversarial alignment to learn a good target classifier. Our Pretraining
and Consistency (PAC) approach, can achieve state of the art accuracy on this
semi-supervised domain adaptation task, surpassing multiple adversarial domain
alignment methods, across multiple datasets. Notably, it outperforms all recent
approaches by 3-5% on the large and challenging DomainNet benchmark, showing
the strength of these simple techniques in fixing errors made by adversarial
alignment.
</p>
<a href="http://arxiv.org/abs/2101.12727" target="_blank">arXiv:2101.12727</a> [<a href="http://arxiv.org/pdf/2101.12727" target="_blank">pdf</a>]

<h2>General-Purpose OCR Paragraph Identification by Graph Convolution Networks. (arXiv:2101.12741v1 [cs.CV])</h2>
<h3>Renshen Wang, Yasuhisa Fujii, Ashok C. Popat</h3>
<p>Paragraphs are an important class of document entities. We propose a new
approach for paragraph identification by spatial graph convolution networks
(GCN) applied on OCR text boxes. Two steps, namely line splitting and line
clustering, are performed to extract paragraphs from the lines in OCR results.
Each step uses a beta-skeleton graph constructed from bounding boxes, where the
graph edges provide efficient support for graph convolution operations. With
only pure layout input features, the GCN model size is 3~4 orders of magnitude
smaller compared to R-CNN based models, while achieving comparable or better
accuracies on PubLayNet and other datasets. Furthermore, the GCN models show
good generalization from synthetic training data to real-world images, and good
adaptivity for variable document styles.
</p>
<a href="http://arxiv.org/abs/2101.12741" target="_blank">arXiv:2101.12741</a> [<a href="http://arxiv.org/pdf/2101.12741" target="_blank">pdf</a>]

<h2>Variance-Aware Confidence Set: Variance-Dependent Bound for Linear Bandits and Horizon-Free Bound for Linear Mixture MDP. (arXiv:2101.12745v1 [cs.LG])</h2>
<h3>Zihan Zhang, Jiaqi Yang, Xiangyang Ji, Simon S. Du</h3>
<p>We show how to construct variance-aware confidence sets for linear bandits
and linear mixture Markov Decision Process (MDP). Our method yields the
following new regret bounds:

* For linear bandits, we obtain an $\widetilde{O}(\mathrm{poly}(d)\sqrt{1 +
\sum_{i=1}^{K}\sigma_i^2})$ regret bound, where $d$ is the feature dimension,
$K$ is the number of rounds, and $\sigma_i^2$ is the (unknown) variance of the
reward at the $i$-th round. This is the first regret bound that only scales
with the variance and the dimension, with no explicit polynomial dependency on
$K$.

* For linear mixture MDP, we obtain an $\widetilde{O}(\mathrm{poly}(d, \log
H)\sqrt{K})$ regret bound for linear mixture MDP, where $d$ is the number of
base models, $K$ is the number of episodes, and $H$ is the planning horizon.
This is the first regret bound that only scales logarthmically with $H$ in the
reinforcement learning (RL) with linear function approximation setting, thus
exponentially improving existing results.

Our methods utilize three novel ideas that may be of independent interest: 1)
applications of the layering techniques to the norm of input and the magnitude
of variance, 2) a recursion-based approach to estimate the variance, and 3) a
convex potential lemma that in a sense generalizes the seminal elliptical
potential lemma.
</p>
<a href="http://arxiv.org/abs/2101.12745" target="_blank">arXiv:2101.12745</a> [<a href="http://arxiv.org/pdf/2101.12745" target="_blank">pdf</a>]

<h2>Improving VAEs' Robustness to Adversarial Attack. (arXiv:1906.00230v6 [stat.ML] UPDATED)</h2>
<h3>Matthew Willetts, Alexander Camuto, Tom Rainforth, Stephen Roberts, Chris Holmes</h3>
<p>Variational autoencoders (VAEs) have recently been shown to be vulnerable to
adversarial attacks, wherein they are fooled into reconstructing a chosen
target image. However, how to defend against such attacks remains an open
problem. We make significant advances in addressing this issue by introducing
methods for producing adversarially robust VAEs. Namely, we first demonstrate
that methods proposed to obtain disentangled latent representations produce
VAEs that are more robust to these attacks. However, this robustness comes at
the cost of reducing the quality of the reconstructions. We ameliorate this by
applying disentangling methods to hierarchical VAEs. The resulting models
produce high-fidelity autoencoders that are also adversarially robust. We
confirm their capabilities on several different datasets and with current
state-of-the-art VAE adversarial attacks, and also show that they increase the
robustness of downstream tasks to attack.
</p>
<a href="http://arxiv.org/abs/1906.00230" target="_blank">arXiv:1906.00230</a> [<a href="http://arxiv.org/pdf/1906.00230" target="_blank">pdf</a>]

<h2>Fast and Accurate Transferability Measurement for Heterogeneous Multivariate Data. (arXiv:1912.13366v2 [cs.LG] UPDATED)</h2>
<h3>Seungcheol Park, Huiwen Xu, Taehun Kim, Inhwan Hwang, Kyung-Jun Kim, U Kang</h3>
<p>Given a set of heterogeneous source datasets with their classifiers, how can
we quickly find the most useful source dataset for a specific target task? We
address the problem of measuring transferability between source and target
datasets, where the source and the target have different feature spaces and
distributions. We propose Transmeter, a fast and accurate method to estimate
the transferability of two heterogeneous multivariate datasets. We address
three challenges in measuring transferability between two heterogeneous
multivariate datasets: reducing time, minimizing domain gap, and extracting
meaningful homogeneous representations. To overcome the above issues, we
utilize a pre-trained source model, an adversarial network, and an
encoder-decoder architecture. Extensive experiments on heterogeneous
multivariate datasets show that Transmeter gives the most accurate
transferability measurement with up to 10.3 times faster performance than its
competitor. We also show that selecting the best source data with Transmeter
followed by a full transfer leads to the best transfer accuracy and the fastest
running time.
</p>
<a href="http://arxiv.org/abs/1912.13366" target="_blank">arXiv:1912.13366</a> [<a href="http://arxiv.org/pdf/1912.13366" target="_blank">pdf</a>]

<h2>Regime Switching Bandits. (arXiv:2001.09390v2 [cs.LG] UPDATED)</h2>
<h3>Xiang Zhou, Yi Xiong, Ningyuan Chen, Xuefeng Gao</h3>
<p>We study a multi-armed bandit problem where the rewards exhibit regime
switching. Specifically, the distributions of the random rewards generated from
all arms are modulated by a common underlying state modeled as a finite-state
Markov chain. The agent does not observe the underlying state and has to learn
the transition matrix and the reward distributions. We propose a learning
algorithm for this problem, building on spectral method-of-moments estimations
for hidden Markov models, belief error control in partially observable Markov
decision processes and upper-confidence-bound methods for online learning. We
also establish an upper bound $O(T^{2/3}\sqrt{\log T})$ for the proposed
learning algorithm where $T$ is the learning horizon. Finally, we conduct
proof-of-concept experiments to illustrate the performance of the learning
algorithm.
</p>
<a href="http://arxiv.org/abs/2001.09390" target="_blank">arXiv:2001.09390</a> [<a href="http://arxiv.org/pdf/2001.09390" target="_blank">pdf</a>]

<h2>Optimal Confidence Regions for the Multinomial Parameter. (arXiv:2002.01044v2 [stat.ML] UPDATED)</h2>
<h3>Matthew L. Malloy, Ardhendu Tripathy, Robert D. Nowak</h3>
<p>Construction of tight confidence regions and intervals is central to
statistical inference and decision making. This paper develops new theory
showing minimum average volume confidence regions for categorical data. More
precisely, consider an empirical distribution $\widehat{\boldsymbol{p}}$
generated from $n$ iid realizations of a random variable that takes one of $k$
possible values according to an unknown distribution $\boldsymbol{p}$. This is
analogous to a single draw from a multinomial distribution. A confidence region
is a subset of the probability simplex that depends on
$\widehat{\boldsymbol{p}}$ and contains the unknown $\boldsymbol{p}$ with a
specified confidence. This paper shows how one can construct minimum average
volume confidence regions, answering a long standing question. We also show the
optimality of the regions directly translates to optimal confidence intervals
of linear functionals such as the mean, implying sample complexity and regret
improvements for adaptive machine learning algorithms.
</p>
<a href="http://arxiv.org/abs/2002.01044" target="_blank">arXiv:2002.01044</a> [<a href="http://arxiv.org/pdf/2002.01044" target="_blank">pdf</a>]

<h2>On the Sensory Commutativity of Action Sequences for Embodied Agents. (arXiv:2002.05630v3 [cs.AI] UPDATED)</h2>
<h3>Hugo Caselles-Dupr&#xe9;, Michael Garcia-Ortiz, David Filliat</h3>
<p>Perception of artificial agents is one the grand challenges of AI research.
Deep Learning and data-driven approaches are successful on constrained problems
where perception can be learned using supervision, but do not scale to
open-worlds. In such case, for autonomous embodied agents with first-person
sensors, perception can be learned end-to-end to solve particular tasks.
However, literature shows that perception is not a purely passive compression
mechanism, and that actions play an important role in the formulation of
abstract representations. We propose to study perception for these embodied
agents, under the mathematical formalism of group theory in order to make the
link between perception and action. In particular, we consider the commutative
properties of continuous action sequences with respect to sensory information
perceived by such an embodied agent. We introduce the Sensory Commutativity
Probability (SCP) criterion which measures how much an agent's degree of
freedom affects the environment in embodied scenarios. We show how to compute
this criterion in different environments, including realistic robotic setups.
We empirically illustrate how SCP and the commutative properties of action
sequences can be used to learn about objects in the environment and improve
sample-efficiency in Reinforcement Learning.
</p>
<a href="http://arxiv.org/abs/2002.05630" target="_blank">arXiv:2002.05630</a> [<a href="http://arxiv.org/pdf/2002.05630" target="_blank">pdf</a>]

<h2>Learning Bijective Feature Maps for Linear ICA. (arXiv:2002.07766v5 [cs.LG] UPDATED)</h2>
<h3>Alexander Camuto, Matthew Willetts, Brooks Paige, Chris Holmes, Stephen Roberts</h3>
<p>Separating high-dimensional data like images into independent latent factors,
i.e independent component analysis (ICA), remains an open research problem. As
we show, existing probabilistic deep generative models (DGMs), which are
tailor-made for image data, underperform on non-linear ICA tasks. To address
this, we propose a DGM which combines bijective feature maps with a linear ICA
model to learn interpretable latent structures for high-dimensional data. Given
the complexities of jointly training such a hybrid model, we introduce novel
theory that constrains linear ICA to lie close to the manifold of orthogonal
rectangular matrices, the Stiefel manifold. By doing so we create models that
converge quickly, are easy to train, and achieve better unsupervised latent
factor discovery than flow-based models, linear ICA, and Variational
Autoencoders on images.
</p>
<a href="http://arxiv.org/abs/2002.07766" target="_blank">arXiv:2002.07766</a> [<a href="http://arxiv.org/pdf/2002.07766" target="_blank">pdf</a>]

<h2>User-Level Privacy-Preserving Federated Learning: Analysis and Performance Optimization. (arXiv:2003.00229v2 [cs.LG] UPDATED)</h2>
<h3>Kang Wei, Jun Li, Ming Ding, Chuan Ma, Hang Su, Bo Zhang, H. Vincent Poor</h3>
<p>Federated learning (FL), as a type of collaborative machine learning
framework, is capable of preserving private data from mobile terminals (MTs)
while training the data into useful models. Nevertheless, from a viewpoint of
information theory, it is still possible for a curious server to infer private
information from the shared models uploaded by MTs. To address this problem, we
first make use of the concept of local differential privacy (LDP), and propose
a user-level differential privacy (UDP) algorithm by adding artificial noise to
the shared models before uploading them to servers. According to our analysis,
the UDP framework can realize $(\epsilon_{i}, \delta_{i})$-LDP for the $i$-th
MT with adjustable privacy protection levels by varying the variances of the
artificial noise processes. We then derive a theoretical convergence
upper-bound for the UDP algorithm. It reveals that there exists an optimal
number of communication rounds to achieve the best learning performance. More
importantly, we propose a communication rounds discounting (CRD) method.
Compared with the heuristic search method, the proposed CRD method can achieve
a much better trade-off between the computational complexity of searching and
the convergence performance. Extensive experiments indicate that our UDP
algorithm using the proposed CRD method can effectively improve both the
training efficiency and model quality for the given privacy protection levels.
</p>
<a href="http://arxiv.org/abs/2003.00229" target="_blank">arXiv:2003.00229</a> [<a href="http://arxiv.org/pdf/2003.00229" target="_blank">pdf</a>]

<h2>Monocular Human Pose and Shape Reconstruction using Part Differentiable Rendering. (arXiv:2003.10873v2 [cs.CV] UPDATED)</h2>
<h3>Min Wang, Feng Qiu, Wentao Liu, Chen Qian, Xiaowei Zhou, Lizhuang Ma</h3>
<p>Superior human pose and shape reconstruction from monocular images depends on
removing the ambiguities caused by occlusions and shape variance. Recent works
succeed in regression-based methods which estimate parametric models directly
through a deep neural network supervised by 3D ground truth. However, 3D ground
truth is neither in abundance nor can efficiently be obtained. In this paper,
we introduce body part segmentation as critical supervision. Part segmentation
not only indicates the shape of each body part but helps to infer the
occlusions among parts as well. To improve the reconstruction with part
segmentation, we propose a part-level differentiable renderer that enables
part-based models to be supervised by part segmentation in neural networks or
optimization loops. We also introduce a general parametric model engaged in the
rendering pipeline as an intermediate representation between skeletons and
detailed shapes, which consists of primitive geometries for better
interpretability. The proposed approach combines parameter regression, body
model optimization, and detailed model registration altogether. Experimental
results demonstrate that the proposed method achieves balanced evaluation on
pose and shape, and outperforms the state-of-the-art approaches on Human3.6M,
UP-3D and LSP datasets.
</p>
<a href="http://arxiv.org/abs/2003.10873" target="_blank">arXiv:2003.10873</a> [<a href="http://arxiv.org/pdf/2003.10873" target="_blank">pdf</a>]

<h2>Faithful Embeddings for Knowledge Base Queries. (arXiv:2004.03658v3 [cs.LG] UPDATED)</h2>
<h3>Haitian Sun, Andrew O. Arnold, Tania Bedrax-Weiss, Fernando Pereira, William W. Cohen</h3>
<p>The deductive closure of an ideal knowledge base (KB) contains exactly the
logical queries that the KB can answer. However, in practice KBs are both
incomplete and over-specified, failing to answer some queries that have
real-world answers. \emph{Query embedding} (QE) techniques have been recently
proposed where KB entities and KB queries are represented jointly in an
embedding space, supporting relaxation and generalization in KB inference.
However, experiments in this paper show that QE systems may disagree with
deductive reasoning on answers that do not require generalization or
relaxation. We address this problem with a novel QE method that is more
faithful to deductive reasoning, and show that this leads to better performance
on complex queries to incomplete KBs. Finally we show that inserting this new
QE module into a neural question-answering system leads to substantial
improvements over the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2004.03658" target="_blank">arXiv:2004.03658</a> [<a href="http://arxiv.org/pdf/2004.03658" target="_blank">pdf</a>]

<h2>IterDet: Iterative Scheme for Object Detection in Crowded Environments. (arXiv:2005.05708v2 [cs.CV] UPDATED)</h2>
<h3>Danila Rukhovich, Konstantin Sofiiuk, Danil Galeev, Olga Barinova, Anton Konushin</h3>
<p>Deep learning-based detectors usually produce a redundant set of object
bounding boxes including many duplicate detections of the same object. These
boxes are then filtered using non-maximum suppression (NMS) in order to select
exactly one bounding box per object of interest. This greedy scheme is simple
and provides sufficient accuracy for isolated objects but often fails in
crowded environments, since one needs to both preserve boxes for different
objects and suppress duplicate detections. In this work we develop an
alternative iterative scheme, where a new subset of objects is detected at each
iteration. Detected boxes from the previous iterations are passed to the
network at the following iterations to ensure that the same object would not be
detected twice. This iterative scheme can be applied to both one-stage and
two-stage object detectors with just minor modifications of the training and
inference procedures. We perform extensive experiments with two different
baseline detectors on four datasets and show significant improvement over the
baseline, leading to state-of-the-art performance on CrowdHuman and WiderPerson
datasets. The source code and the trained models are available at
https://github.com/saic-vul/iterdet.
</p>
<a href="http://arxiv.org/abs/2005.05708" target="_blank">arXiv:2005.05708</a> [<a href="http://arxiv.org/pdf/2005.05708" target="_blank">pdf</a>]

<h2>Quantifying the Complexity of Standard Benchmarking Datasets for Long-Term Human Trajectory Prediction. (arXiv:2005.13934v3 [cs.CV] UPDATED)</h2>
<h3>Ronny Hug, Stefan Becker, Wolfgang H&#xfc;bner, Michael Arens</h3>
<p>Methods to quantify the complexity of trajectory datasets are still a missing
piece in benchmarking human trajectory prediction models. In order to gain a
better understanding of the complexity of trajectory prediction tasks and
following the intuition, that more complex datasets contain more information,
an approach for quantifying the amount of information contained in a dataset
from a prototype-based dataset representation is proposed. The dataset
representation is obtained by first employing a non-trivial spatial sequence
alignment, which enables a subsequent learning vector quantization (LVQ) stage.
A large-scale complexity analysis is conducted on several human trajectory
prediction benchmarking datasets, followed by a brief discussion on indications
for human trajectory prediction and benchmarking.
</p>
<a href="http://arxiv.org/abs/2005.13934" target="_blank">arXiv:2005.13934</a> [<a href="http://arxiv.org/pdf/2005.13934" target="_blank">pdf</a>]

<h2>Non-convergence of stochastic gradient descent in the training of deep neural networks. (arXiv:2006.07075v2 [cs.LG] UPDATED)</h2>
<h3>Patrick Cheridito, Arnulf Jentzen, Florian Rossmannek</h3>
<p>Deep neural networks have successfully been trained in various application
areas with stochastic gradient descent. However, there exists no rigorous
mathematical explanation why this works so well. The training of neural
networks with stochastic gradient descent has four different discretization
parameters: (i) the network architecture; (ii) the amount of training data;
(iii) the number of gradient steps; and (iv) the number of randomly initialized
gradient trajectories. While it can be shown that the approximation error
converges to zero if all four parameters are sent to infinity in the right
order, we demonstrate in this paper that stochastic gradient descent fails to
converge for ReLU networks if their depth is much larger than their width and
the number of random initializations does not increase to infinity fast enough.
</p>
<a href="http://arxiv.org/abs/2006.07075" target="_blank">arXiv:2006.07075</a> [<a href="http://arxiv.org/pdf/2006.07075" target="_blank">pdf</a>]

<h2>Learning continuous-time PDEs from sparse data with graph neural networks. (arXiv:2006.08956v3 [cs.LG] UPDATED)</h2>
<h3>Valerii Iakovlev, Markus Heinonen, Harri L&#xe4;hdesm&#xe4;ki</h3>
<p>The behavior of many dynamical systems follow complex, yet still unknown
partial differential equations (PDEs). While several machine learning methods
have been proposed to learn PDEs directly from data, previous methods are
limited to discrete-time approximations or make the limiting assumption of the
observations arriving at regular grids. We propose a general continuous-time
differential model for dynamical systems whose governing equations are
parameterized by message passing graph neural networks. The model admits
arbitrary space and time discretizations, which removes constraints on the
locations of observation points and time intervals between the observations.
The model is trained with continuous-time adjoint method enabling efficient
neural PDE inference. We demonstrate the model's ability to work with
unstructured grids, arbitrary time steps, and noisy observations. We compare
our method with existing approaches on several well-known physical systems that
involve first and higher-order PDEs with state-of-the-art predictive
performance.
</p>
<a href="http://arxiv.org/abs/2006.08956" target="_blank">arXiv:2006.08956</a> [<a href="http://arxiv.org/pdf/2006.08956" target="_blank">pdf</a>]

<h2>Free-rider Attacks on Model Aggregation in Federated Learning. (arXiv:2006.11901v3 [cs.LG] UPDATED)</h2>
<h3>Yann Fraboni, Richard Vidal, Marco Lorenzi</h3>
<p>Free-rider attacks against federated learning consist in dissimulating
participation to the federated learning process with the goal of obtaining the
final aggregated model without actually contributing with any data. This kind
of attacks is critical in sensitive applications of federated learning, where
data is scarce and the model has high commercial value. We introduce here the
first theoretical and experimental analysis of free-rider attacks on federated
learning schemes based on iterative parameters aggregation, such as FedAvg or
FedProx, and provide formal guarantees for these attacks to converge to the
aggregated models of the fair participants. We first show that a
straightforward implementation of this attack can be simply achieved by not
updating the local parameters during the iterative federated optimization. As
this attack can be detected by adopting simple countermeasures at the server
level, we subsequently study more complex disguising schemes based on
stochastic updates of the free-rider parameters. We demonstrate the proposed
strategies on a number of experimental scenarios, in both iid and non-iid
settings. We conclude by providing recommendations to avoid free-rider attacks
in real world applications of federated learning, especially in sensitive
domains where security of data and models is critical.
</p>
<a href="http://arxiv.org/abs/2006.11901" target="_blank">arXiv:2006.11901</a> [<a href="http://arxiv.org/pdf/2006.11901" target="_blank">pdf</a>]

<h2>Encoding Legal Balancing: Automating an Abstract Ethico-Legal Value Ontology in Preference Logic. (arXiv:2006.12789v3 [cs.AI] UPDATED)</h2>
<h3>Christoph Benzm&#xfc;ller, David Fuenmayor, Bertram Lomfeld</h3>
<p>Enabling machines to legal balancing is a non-trivial task challenged by a
multitude of factors some of which are addressed and explored in this work. We
propose a holistic approach to formal modelling at different abstraction layers
supported by a pluralistic framework in which the encoding of an ethico-legal
value ontology is developed in combination with the exploration of a
formalisation logic, with legal domain knowledge and with exemplary use cases
until a reflective equilibrium is reached. Our work is enabled by a
meta-logical approach to universal logical reasoning and it applies the
recently introduced LOGIKEY methodology for designing normative theories for
ethical and legal reasoning. We explore and illustrate the application of the
multilayered LOGIKEY approach for the modelling of legal and world knowledge
that is constrained by context-dependent value preferences. The framework is
then exemplary applied for explaining and resolving legal conflicts in property
law (wild animal cases) within a modern proof assistant system.
</p>
<a href="http://arxiv.org/abs/2006.12789" target="_blank">arXiv:2006.12789</a> [<a href="http://arxiv.org/pdf/2006.12789" target="_blank">pdf</a>]

<h2>Stochastic Subset Selection. (arXiv:2006.14222v2 [cs.LG] UPDATED)</h2>
<h3>A. Tuan Nguyen, Bruno Andreis, Juho Lee, Eunho Yang, Sung Ju Hwang</h3>
<p>Current machine learning algorithms are designed to work with huge volumes of
high dimensional data such as images. However, these algorithms are being
increasingly deployed to resource constrained systems such as mobile devices
and embedded systems. Even in cases where large computing infrastructure is
available, the size of each data instance, as well as datasets, can provide a
huge bottleneck in data transfer across communication channels. Also, there is
a huge incentive both in energy and monetary terms in reducing both the
computational and memory requirements of these algorithms. For non-parametric
models that require to leverage the stored training data at the inference time,
the increased cost in memory and computation could be even more problematic. In
this work, we aim to reduce the volume of data these algorithms must process
through an end-to-end two-stage neural subset selection model, where the first
stage selects a set of candidate points using a conditionally independent
Bernoulli mask followed by an iterative coreset selection via a conditional
Categorical distribution. The subset selection model is trained by
meta-learning with a distribution of sets. We validate our method on set
reconstruction and classification tasks with feature selection as well as the
selection of representative samples from a given dataset, on which our method
outperforms relevant baselines. We also show in our experiments that our method
enhances scalability of non-parametric models such as Neural Processes.
</p>
<a href="http://arxiv.org/abs/2006.14222" target="_blank">arXiv:2006.14222</a> [<a href="http://arxiv.org/pdf/2006.14222" target="_blank">pdf</a>]

<h2>Towards a Theoretical Understanding of the Robustness of Variational Autoencoders. (arXiv:2007.07365v3 [stat.ML] UPDATED)</h2>
<h3>Alexander Camuto, Matthew Willetts, Stephen Roberts, Chris Holmes, Tom Rainforth</h3>
<p>We make inroads into understanding the robustness of Variational Autoencoders
(VAEs) to adversarial attacks and other input perturbations. While previous
work has developed algorithmic approaches to attacking and defending VAEs,
there remains a lack of formalization for what it means for a VAE to be robust.
To address this, we develop a novel criterion for robustness in probabilistic
models: $r$-robustness. We then use this to construct the first theoretical
results for the robustness of VAEs, deriving margins in the input space for
which we can provide guarantees about the resulting reconstruction. Informally,
we are able to define a region within which any perturbation will produce a
reconstruction that is similar to the original reconstruction. To support our
analysis, we show that VAEs trained using disentangling methods not only score
well under our robustness metrics, but that the reasons for this can be
interpreted through our theoretical results.
</p>
<a href="http://arxiv.org/abs/2007.07365" target="_blank">arXiv:2007.07365</a> [<a href="http://arxiv.org/pdf/2007.07365" target="_blank">pdf</a>]

<h2>A finite sample analysis of the benign overfitting phenomenon for ridge function estimation. (arXiv:2007.12882v3 [stat.ML] UPDATED)</h2>
<h3>Emmanuel Caron, Stephane Chretien</h3>
<p>Recent extensive numerical experiments in high scale machine learning have
allowed to uncover a quite counterintuitive phase transition, as a function of
the ratio between the sample size and the number of parameters in the model. As
the number of parameters $p$ approaches the sample size $n$, the generalisation
error (a.k.a. testing error) increases, but in many cases, it starts decreasing
again past the threshold $p=n$. This surprising phenomenon, brought to the
theoretical community attention in \cite{belkin2019reconciling}, has been
thoroughly investigated lately, more specifically for simpler models than deep
neural networks, such as the linear model when the parameter is taken to be the
minimum norm solution to the least-square problem, mostly in the asymptotic
regime when $p$ and $n$ tend to $+\infty$; see e.g. \cite{hastie2019surprises}.
In the present paper, we propose a finite sample analysis of non-linear models
of \textit{ridge} type, where we investigate the \textit{overparametrised
regime} of the double descent phenomenon for both the \textit{estimation
problem} and the \textit{prediction} problem. Our results provide a precise
analysis of the distance of the best estimator from the true parameter as well
as a generalisation bound which complements recent works of
\cite{bartlett2020benign} and \cite{chinot2020benign}. Our analysis is based on
efficient but elementary tools closely related to the continuous Newton method
\cite{neuberger2007continuous}.
</p>
<a href="http://arxiv.org/abs/2007.12882" target="_blank">arXiv:2007.12882</a> [<a href="http://arxiv.org/pdf/2007.12882" target="_blank">pdf</a>]

<h2>Graph Neural Networks: Architectures, Stability and Transferability. (arXiv:2008.01767v3 [cs.LG] UPDATED)</h2>
<h3>Luana Ruiz, Fernando Gama, Alejandro Ribeiro</h3>
<p>Graph Neural Networks (GNNs) are information processing architectures for
signals supported on graphs. They are presented here as generalizations of
convolutional neural networks (CNNs) in which individual layers contain banks
of graph convolutional filters instead of banks of classical convolutional
filters. Otherwise, GNNs operate as CNNs. Filters are composed with pointwise
nonlinearities and stacked in layers. It is shown that GNN architectures
exhibit equivariance to permutation and stability to graph deformations. These
properties help explain the good performance of GNNs that can be observed
empirically. It is also shown that if graphs converge to a limit object, a
graphon, GNNs converge to a corresponding limit object, a graphon neural
network. This convergence justifies the transferability of GNNs across networks
with different number of nodes. Concepts are illustrated by the application of
GNNs to recommendation systems, decentralized collaborative control, and
wireless communication networks.
</p>
<a href="http://arxiv.org/abs/2008.01767" target="_blank">arXiv:2008.01767</a> [<a href="http://arxiv.org/pdf/2008.01767" target="_blank">pdf</a>]

<h2>Learning Long-term Visual Dynamics with Region Proposal Interaction Networks. (arXiv:2008.02265v2 [cs.CV] UPDATED)</h2>
<h3>Haozhi Qi, Xiaolong Wang, Deepak Pathak, Yi Ma, Jitendra Malik</h3>
<p>Learning long-term dynamics models is the key to understanding physical
common sense. Most existing approaches on learning dynamics from visual input
sidestep long-term predictions by resorting to rapid re-planning with
short-term models. This not only requires such models to be super accurate but
also limits them only to tasks where an agent can continuously obtain feedback
and take action at each step until completion. In this paper, we aim to
leverage the ideas from success stories in visual recognition tasks to build
object representations that can capture inter-object and object-environment
interactions over a long-range. To this end, we propose Region Proposal
Interaction Networks (RPIN), which reason about each object's trajectory in a
latent region-proposal feature space. Thanks to the simple yet effective object
representation, our approach outperforms prior methods by a significant margin
both in terms of prediction quality and their ability to plan for downstream
tasks, and also generalize well to novel environments. Code, pre-trained
models, and more visualization results are available at
https://haozhiqi.github.io/RPIN.
</p>
<a href="http://arxiv.org/abs/2008.02265" target="_blank">arXiv:2008.02265</a> [<a href="http://arxiv.org/pdf/2008.02265" target="_blank">pdf</a>]

<h2>Reconstructing Sparse Signals via Greedy Monte-Carlo Search. (arXiv:2008.03175v3 [stat.ML] UPDATED)</h2>
<h3>Kao Hayashi, Tomoyuki Obuchi, Yoshiyuki Kabashima</h3>
<p>We propose a Monte-Carlo-based method for reconstructing sparse signals in
the formulation of sparse linear regression in a high-dimensional setting. The
basic idea of this algorithm is to explicitly select variables or covariates to
represent a given data vector or responses and accept randomly generated
updates of that selection if and only if the energy or cost function decreases.
This algorithm is called the greedy Monte-Carlo (GMC) search algorithm. Its
performance is examined via numerical experiments, which suggests that in the
noiseless case, GMC can achieve perfect reconstruction in undersampling
situations of a reasonable level: it can outperform the $\ell_1$ relaxation but
does not reach the algorithmic limit of MC-based methods theoretically
clarified by an earlier analysis. The necessary computational time is also
examined and compared with that of an algorithm using simulated annealing.
Additionally, experiments on the noisy case are conducted on synthetic datasets
and on a real-world dataset, supporting the practicality of GMC.
</p>
<a href="http://arxiv.org/abs/2008.03175" target="_blank">arXiv:2008.03175</a> [<a href="http://arxiv.org/pdf/2008.03175" target="_blank">pdf</a>]

<h2>Self-supervised Video Representation Learning by Uncovering Spatio-temporal Statistics. (arXiv:2008.13426v2 [cs.CV] UPDATED)</h2>
<h3>Jiangliu Wang, Jianbo Jiao, Linchao Bao, Shengfeng He, Wei Liu, Yun-hui Liu</h3>
<p>This paper proposes a novel pretext task to address the self-supervised video
representation learning problem. Specifically, given an unlabeled video clip,
we compute a series of spatio-temporal statistical summaries, such as the
spatial location and dominant direction of the largest motion, the spatial
location and dominant color of the largest color diversity along the temporal
axis, etc. Then a neural network is built and trained to yield the statistical
summaries given the video frames as inputs. In order to alleviate the learning
difficulty, we employ several spatial partitioning patterns to encode rough
spatial locations instead of exact spatial Cartesian coordinates. Our approach
is inspired by the observation that human visual system is sensitive to rapidly
changing contents in the visual field, and only needs impressions about rough
spatial locations to understand the visual contents. To validate the
effectiveness of the proposed approach, we conduct extensive experiments with
four 3D backbone networks, i.e., C3D, 3D-ResNet, R(2+1)D and S3D-G. The results
show that our approach outperforms the existing approaches across these
backbone networks on four downstream video analysis tasks including action
recognition, video retrieval, dynamic scene recognition, and action similarity
labeling. The source code is publicly available at:
https://github.com/laura-wang/video_repres_sts.
</p>
<a href="http://arxiv.org/abs/2008.13426" target="_blank">arXiv:2008.13426</a> [<a href="http://arxiv.org/pdf/2008.13426" target="_blank">pdf</a>]

<h2>Quantifying Explainability of Saliency Methods in Deep Neural Networks. (arXiv:2009.02899v3 [cs.CV] UPDATED)</h2>
<h3>Erico Tjoa, Cuntai Guan</h3>
<p>One way to achieve eXplainable artificial intelligence (XAI) is through the
use of post-hoc analysis methods. In particular, methods that generate heatmaps
have been used to explain black-box models, such as deep neural network. In
some cases, heatmaps are appealing due to the intuitive and visual ways to
understand them. However, quantitative analysis that demonstrates the actual
potential of heatmaps have been lacking, and comparison between different
methods are not standardized as well. In this paper, we introduce a synthetic
dataset that can be generated adhoc along with the ground-truth heatmaps for
better quantitative assessment. Each sample data is an image of a cell with
easily distinguishable features, facilitating a more transparent assessment of
different XAI methods. Comparison and recommendations are made, shortcomings
are clarified along with suggestions for future research directions to handle
the finer details of select post-hoc analysis methods.
</p>
<a href="http://arxiv.org/abs/2009.02899" target="_blank">arXiv:2009.02899</a> [<a href="http://arxiv.org/pdf/2009.02899" target="_blank">pdf</a>]

<h2>Tactical Decision Making for Emergency Vehicles Based on A Combinational Learning Method. (arXiv:2009.04203v3 [cs.AI] UPDATED)</h2>
<h3>Haoyi Niu, Jianming Hu, Zheyu Cui, Yi Zhang</h3>
<p>Increasing the response time of emergency vehicles(EVs) could lead to an
immeasurable loss of property and life. On this account, tactical decision
making for EVs' microscopic control remains an indispensable issue to be
improved. In this paper, a rule-based avoiding strategy(AS) is devised, that
CVs in the prioritized zone ahead of EV should accelerate or change their lane
to avoid it. Besides, a novel DQN method with speed-adaptive compact state
space (SC-DQN) is put forward to fit in EVs' high-speed feature and generalize
in various road topologies. Afterward, the execution of AS feedback to the
input of SC-DQN so that they joint organically as a combinational method. The
following approach reveals that DRL could complement rule-based avoiding
strategy in generalization, and on the contrary, the rule-based avoiding
strategy could complement DRL in stability, and their combination could lead to
less response time, lower collision rate and smoother trajectory.
</p>
<a href="http://arxiv.org/abs/2009.04203" target="_blank">arXiv:2009.04203</a> [<a href="http://arxiv.org/pdf/2009.04203" target="_blank">pdf</a>]

<h2>Oracle-Efficient Reinforcement Learning in Factored MDPs with Unknown Structure. (arXiv:2009.05986v3 [cs.LG] UPDATED)</h2>
<h3>Aviv Rosenberg, Yishay Mansour</h3>
<p>We study provably-efficient reinforcement learning in non-episodic factored
Markov decision processes (FMDPs). All previous regret minimization algorithms
in this setting made the strong assumption that the factored structure of the
FMDP is known to the learner in advance. In this paper, we provide the first
algorithm that learns the structure of the FMDP while minimizing the regret.
Our algorithm is based on the optimism in face of uncertainty principle,
combined with a simple statistical method for structure learning, and can be
implemented efficiently given oracle-access to an FMDP planner. In addition, we
give a variant of our algorithm that remains efficient even when the oracle is
limited to non-factored actions, which is the case with almost all existing
approximate planners. Finally, we also provide a novel lower bound for the
known structure case that matches the best known regret bound of Chen et al.
(2020).
</p>
<a href="http://arxiv.org/abs/2009.05986" target="_blank">arXiv:2009.05986</a> [<a href="http://arxiv.org/pdf/2009.05986" target="_blank">pdf</a>]

<h2>Deep Autoencoders: From Understanding to Generalization Guarantees. (arXiv:2009.09525v2 [cs.LG] UPDATED)</h2>
<h3>Romain Cosentino, Randall Balestriero, Richard Baraniuk, Behnaam Aazhang</h3>
<p>A big mystery in deep learning continues to be the ability of methods to
generalize when the number of model parameters is larger than the number of
training examples. In this work, we take a step towards a better understanding
of the underlying phenomena of Deep Autoencoders (AEs), a mainstream deep
learning solution for learning compressed, interpretable, and structured data
representations. In particular, we interpret how AEs approximate the data
manifold by exploiting their continuous piecewise affine structure. Our
reformulation of AEs provides new insights into their mapping, reconstruction
guarantees, as well as an interpretation of commonly used regularization
techniques. We leverage these findings to derive two new regularizations that
enable AEs to capture the inherent symmetry in the data. Our regularizations
leverage recent advances in the group of transformation learning to enable AEs
to better approximate the data manifold without explicitly defining the group
underlying the manifold. Under the assumption that the symmetry of the data can
be explained by a Lie group, we prove that the regularizations ensure the
generalization of the corresponding AEs. A range of experimental evaluations
demonstrate that our methods outperform other state-of-the-art regularization
techniques.
</p>
<a href="http://arxiv.org/abs/2009.09525" target="_blank">arXiv:2009.09525</a> [<a href="http://arxiv.org/pdf/2009.09525" target="_blank">pdf</a>]

<h2>Deliberative Acting, Online Planning and Learning with Hierarchical Operational Models. (arXiv:2010.01909v2 [cs.AI] UPDATED)</h2>
<h3>Sunandita Patra, James Mason, Malik Ghallab, Dana Nau, Paolo Traverso</h3>
<p>In AI research, synthesizing a plan of action has typically used descriptive
models of the actions that abstractly specify what might happen as a result of
an action, and are tailored for efficiently computing state transitions.
However, executing the planned actions has needed operational models, in which
rich computational control structures and closed-loop online decision-making
are used to specify how to perform an action in a complex execution context,
react to events and adapt to an unfolding situation. Deliberative actors, which
integrate acting and planning, have typically needed to use both of these
models together -- which causes problems when attempting to develop the
different models, verify their consistency, and smoothly interleave acting and
planning.

As an alternative, we define and implement an integrated acting-and-planning
system in which both planning and acting use the same operational models. These
rely on hierarchical task-oriented refinement methods offering rich control
structures. The acting component, called Reactive Acting Engine (RAE), is
inspired by the well-known PRS system. At each decision step, RAE can get
advice from a planner for a near-optimal choice with respect to a utility
function. The anytime planner uses a UCT-like Monte Carlo Tree Search
procedure, called UPOM, (UCT Procedure for Operational Models), whose rollouts
are simulations of the actor's operational models. We also present learning
strategies for use with RAE and UPOM that acquire, from online acting
experiences and/or simulated planning results, a mapping from decision contexts
to method instances as well as a heuristic function to guide UPOM. We
demonstrate the asymptotic convergence of UPOM towards optimal methods in
static domains, and show experimentally that UPOM and the learning strategies
significantly improve the acting efficiency and robustness.
</p>
<a href="http://arxiv.org/abs/2010.01909" target="_blank">arXiv:2010.01909</a> [<a href="http://arxiv.org/pdf/2010.01909" target="_blank">pdf</a>]

<h2>Winning Lottery Tickets in Deep Generative Models. (arXiv:2010.02350v2 [cs.LG] UPDATED)</h2>
<h3>Neha Mukund Kalibhat, Yogesh Balaji, Soheil Feizi</h3>
<p>The lottery ticket hypothesis suggests that sparse, sub-networks of a given
neural network, if initialized properly, can be trained to reach comparable or
even better performance to that of the original network. Prior works in lottery
tickets have primarily focused on the supervised learning setup, with several
papers proposing effective ways of finding "winning tickets" in classification
problems. In this paper, we confirm the existence of winning tickets in deep
generative models such as GANs and VAEs. We show that the popular iterative
magnitude pruning approach (with late rewinding) can be used with generative
losses to find the winning tickets. This approach effectively yields tickets
with sparsity up to 99% for AutoEncoders, 93% for VAEs and 89% for GANs on
CIFAR and Celeb-A datasets. We also demonstrate the transferability of winning
tickets across different generative models (GANs and VAEs) sharing the same
architecture, suggesting that winning tickets have inductive biases that could
help train a wide range of deep generative models. Furthermore, we show the
practical benefits of lottery tickets in generative models by detecting tickets
at very early stages in training called "early-bird tickets". Through
early-bird tickets, we can achieve up to 88% reduction in floating-point
operations (FLOPs) and 54% reduction in training time, making it possible to
train large-scale generative models over tight resource constraints. These
results out-perform existing early pruning methods like SNIP (Lee, Ajanthan,
and Torr 2019) and GraSP (Wang, Zhang, and Grosse 2020). Our findings shed
light towards existence of proper network initializations that could improve
convergence and stability of generative models.
</p>
<a href="http://arxiv.org/abs/2010.02350" target="_blank">arXiv:2010.02350</a> [<a href="http://arxiv.org/pdf/2010.02350" target="_blank">pdf</a>]

<h2>SplitEasy: A Practical Approach for Training ML models on Mobile Devices. (arXiv:2011.04232v2 [cs.LG] UPDATED)</h2>
<h3>Kamalesh Palanisamy, Vivek Khimani, Moin Hussain Moti, Dimitris Chatzopoulos</h3>
<p>Modern mobile devices, although resourceful, cannot train state-of-the-art
machine learning models without the assistance of servers, which require access
to, potentially, privacy-sensitive user data. Split learning has recently
emerged as a promising technique for training complex deep learning (DL) models
on low-powered mobile devices. The core idea behind this technique is to train
the sensitive layers of a DL model on mobile devices while offloading the
computationally intensive layers to a server. Although a lot of works have
already explored the effectiveness of split learning in simulated settings, a
usable toolkit for this purpose does not exist. In this work, we highlight the
theoretical and technical challenges that need to be resolved to develop a
functional framework that trains ML models in mobile devices without
transferring raw data to a server. Focusing on these challenges, we propose
SplitEasy, a framework for training ML models on mobile devices using split
learning. Using the abstraction provided by SplitEasy, developers can run
various DL models under split learning setting by making minimal modifications.
We provide a detailed explanation of SplitEasy and perform experiments with six
state-of-the-art neural networks. We demonstrate how SplitEasy can train models
that cannot be trained solely by a mobile device while incurring nearly
constant time per data sample.
</p>
<a href="http://arxiv.org/abs/2011.04232" target="_blank">arXiv:2011.04232</a> [<a href="http://arxiv.org/pdf/2011.04232" target="_blank">pdf</a>]

<h2>A Fast Point Cloud Ground Segmentation Approach Based on Coarse-To-Fine Markov Random Field. (arXiv:2011.13140v2 [cs.CV] UPDATED)</h2>
<h3>Weixin Huang, Huawei Liang, Linglong Lin, Zhiling Wang, Shaobo Wang, Biao Yu, Runxin Niu</h3>
<p>Ground segmentation is an important preprocessing task for autonomous
vehicles (AVs) with 3D LiDARs. To solve the problem of existing ground
segmentation methods being very difficult to balance accuracy and computational
complexity, a fast point cloud ground segmentation approach based on a
coarse-to-fine Markov random field (MRF) method is proposed. The method uses an
improved elevation map for ground coarse segmentation, and then uses
spatiotemporal adjacent points to optimize the segmentation results. The
processed point cloud is classified into high-confidence obstacle points,
ground points, and unknown classification points to initialize an MRF model.
The graph cut method is then used to solve the model to achieve fine
segmentation. Experiments on datasets showed that our method improves on other
algorithms in terms of ground segmentation accuracy and is faster than other
graph-based algorithms, which require only a single core of an I7-3770 CPU to
process a frame of Velodyne HDL-64E data (in 39.77 ms, on average). Field tests
were also conducted to demonstrate the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2011.13140" target="_blank">arXiv:2011.13140</a> [<a href="http://arxiv.org/pdf/2011.13140" target="_blank">pdf</a>]

<h2>A Full Characterization of Excess Risk via Empirical Risk Landscape. (arXiv:2012.02456v2 [cs.LG] UPDATED)</h2>
<h3>Mingyang Yi, Ruoyu Wang, Zhi-Ming Ma</h3>
<p>In this paper, we provide a unified analysis of the excess risk of the model
trained by a proper algorithm with both smooth convex and non-convex loss
functions. In contrast to the existing bounds in the literature that depends on
iteration steps, our bounds to the excess risk do not diverge with the number
of iterations. This underscores that, at least for smooth loss functions, the
excess risk can be guaranteed after training. To get the bounds to excess risk,
we develop a technique based on algorithmic stability and non-asymptotic
characterization of the empirical risk landscape. The model obtained by a
proper algorithm is proved to generalize with this technique. Specifically, for
non-convex loss, the conclusion is obtained via the technique and analyzing the
stability of a constructed auxiliary algorithm. Combining this with some
properties of the empirical risk landscape, we derive converged upper bounds to
the excess risk in both convex and non-convex regime with the help of some
classical optimization results.
</p>
<a href="http://arxiv.org/abs/2012.02456" target="_blank">arXiv:2012.02456</a> [<a href="http://arxiv.org/pdf/2012.02456" target="_blank">pdf</a>]

<h2>PBNS: Physically Based Neural Simulator for Unsupervised Garment Pose Space Deformation. (arXiv:2012.11310v2 [cs.CV] UPDATED)</h2>
<h3>Hugo Bertiche, Meysam Madadi, Sergio Escalera</h3>
<p>We present a methodology to automatically obtain Pose Space Deformation (PSD)
basis for rigged garments through deep learning. Classical approaches rely on
Physically Based Simulations (PBS) to animate clothes. These are general
solutions that, given a sufficiently fine-grained discretization of space and
time, can achieve highly realistic results. However, they are computationally
expensive and any scene modification prompts the need of re-simulation. Linear
Blend Skinning (LBS) with PSD offers a lightweight alternative to PBS, though,
it needs huge volumes of data to learn proper PSD. We propose using deep
learning, formulated as an implicit PBS, to unsupervisedly learn realistic
cloth Pose Space Deformations in a constrained scenario: dressed humans.
Furthermore, we show it is possible to train these models in an amount of time
comparable to a PBS of a few sequences. To the best of our knowledge, we are
the first to propose a neural simulator for cloth. While deep-based approaches
in the domain are becoming a trend, these are data-hungry models. Moreover,
authors often propose complex formulations to better learn wrinkles from PBS
data. Dependency from data makes these solutions scalability lower, while their
formulation hinders its applicability and compatibility. By proposing an
unsupervised methodology to learn PSD for LBS models (3D animation standard),
we overcome both of these drawbacks. Results obtained show cloth-consistency in
the animated garments and meaningful pose-dependant folds and wrinkles.
</p>
<a href="http://arxiv.org/abs/2012.11310" target="_blank">arXiv:2012.11310</a> [<a href="http://arxiv.org/pdf/2012.11310" target="_blank">pdf</a>]

<h2>Human Action Recognition from Various Data Modalities: A Review. (arXiv:2012.11866v3 [cs.CV] UPDATED)</h2>
<h3>Zehua Sun, Jun Liu, Qiuhong Ke, Hossein Rahmani, Mohammed Bennamoun, Gang Wang</h3>
<p>Human Action Recognition (HAR) aims to understand human behavior and assign a
label to each action. It has a wide range of applications, and therefore has
been attracting increasing attention in the field of computer vision. Human
actions can be represented using various data modalities, such as RGB,
skeleton, depth, infrared, point cloud, event stream, audio, acceleration,
radar, and WiFi signal, which encode different sources of useful yet distinct
information and have various advantages depending on the application scenarios.
Consequently, lots of existing works have attempted to investigate different
types of approaches for HAR using various modalities. In this paper, we present
a comprehensive survey of recent progress in deep learning methods for HAR
based on the type of input data modality. Specifically, we review the current
mainstream deep learning methods for single data modalities and multiple data
modalities, including the fusion-based and the co-learning-based frameworks. We
also present comparative results on several benchmark datasets for HAR,
together with insightful observations and inspiring future research directions.
</p>
<a href="http://arxiv.org/abs/2012.11866" target="_blank">arXiv:2012.11866</a> [<a href="http://arxiv.org/pdf/2012.11866" target="_blank">pdf</a>]

<h2>A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v6 [cs.LG] UPDATED)</h2>
<h3>Felix Leibfried, Vincent Dutordoir, ST John, Nicolas Durrande</h3>
<p>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model enjoys a posterior in closed form. However, identifying the posterior GP
scales cubically with the number of training examples and requires to store all
examples in memory. In order to overcome these obstacles, sparse GPs have been
proposed that approximate the true posterior GP with pseudo-training examples.
Importantly, the number of pseudo-training examples is user-defined and enables
control over computational and memory complexity. In the general case, sparse
GPs do not enjoy closed-form solutions and one has to resort to approximate
inference. In this context, a convenient choice for approximate inference is
variational inference (VI), where the problem of Bayesian inference is cast as
an optimization problem -- namely, to maximize a lower bound of the log
marginal likelihood. This paves the way for a powerful and versatile framework,
where pseudo-training examples are treated as optimization arguments of the
approximate posterior that are jointly identified together with hyperparameters
of the generative model (i.e. prior and likelihood). The framework can
naturally handle a wide scope of supervised learning problems, ranging from
regression with heteroscedastic and non-Gaussian likelihoods to classification
problems with discrete labels, but also multilabel problems. The purpose of
this tutorial is to provide access to the basic matter for readers without
prior knowledge in both GPs and VI. A proper exposition to the subject enables
also access to more recent advances (like importance-weighted VI as well as
inderdomain, multioutput and deep GPs) that can serve as an inspiration for new
research ideas.
</p>
<a href="http://arxiv.org/abs/2012.13962" target="_blank">arXiv:2012.13962</a> [<a href="http://arxiv.org/pdf/2012.13962" target="_blank">pdf</a>]

<h2>A cortical-inspired sub-Riemannian model for Poggendorff-type visual illusions. (arXiv:2012.14184v2 [cs.CV] UPDATED)</h2>
<h3>Emre Baspinar, Luca Calatroni, Valentina Franceschi, Dario Prandi</h3>
<p>We consider Wilson-Cowan-type models for the mathematical description of
orientation-dependent Poggendorff-like illusions. Our modelling improves two
previously proposed cortical-inspired approaches embedding the sub-Riemannian
heat kernel into the neuronal interaction term, in agreement with the
intrinsically anisotropic functional architecture of V1 based on both local and
lateral connections. For the numerical realisation of both models, we consider
standard gradient descent algorithms combined with Fourier-based approaches for
the efficient computation of the sub-Laplacian evolution. Our numerical results
show that the use of the sub-Riemannian kernel allows to reproduce numerically
visual misperceptions and inpainting-type biases in a stronger way in
comparison with the previous approaches.
</p>
<a href="http://arxiv.org/abs/2012.14184" target="_blank">arXiv:2012.14184</a> [<a href="http://arxiv.org/pdf/2012.14184" target="_blank">pdf</a>]

<h2>Learning Adversarial Markov Decision Processes with Delayed Feedback. (arXiv:2012.14843v2 [cs.LG] UPDATED)</h2>
<h3>Tal Lancewicki, Aviv Rosenberg, Yishay Mansour</h3>
<p>Reinforcement learning typically assumes that the agent observes feedback
from the environment immediately, but in many real-world applications (like
recommendation systems) the feedback is observed in delay. Thus, we consider
online learning in episodic Markov decision processes (MDPs) with unknown
transitions, adversarially changing costs and unrestricted delayed feedback.
That is, the costs and trajectory of episode $k$ are only available at the end
of episode $k + d^k$, where the delays $d^k$ are neither identical nor bounded,
and are chosen by an adversary. We present novel algorithms based on policy
optimization that achieve near-optimal high-probability regret of $\widetilde O
( \sqrt{K} + \sqrt{D} )$ under full-information feedback, where $K$ is the
number of episodes and $D = \sum_{k} d^k$ is the total delay. Under bandit
feedback, we prove similar $\widetilde O ( \sqrt{K} + \sqrt{D} )$ regret
assuming that the costs are stochastic, and $\widetilde O ( K^{2/3} + D^{2/3}
)$ regret in the general case. To our knowledge, we are the first to consider
the important setting of delayed feedback in adversarial MDPs.
</p>
<a href="http://arxiv.org/abs/2012.14843" target="_blank">arXiv:2012.14843</a> [<a href="http://arxiv.org/pdf/2012.14843" target="_blank">pdf</a>]

<h2>Stereo Correspondence and Reconstruction of Endoscopic Data Challenge. (arXiv:2101.01133v4 [cs.CV] UPDATED)</h2>
<h3>Max Allan, Jonathan Mcleod, Congcong Wang, Jean Claude Rosenthal, Zhenglei Hu, Niklas Gard, Peter Eisert, Ke Xue Fu, Trevor Zeffiro, Wenyao Xia, Zhanshi Zhu, Huoling Luo, Fucang Jia, Xiran Zhang, Xiaohong Li, Lalith Sharan, Tom Kurmann, Sebastian Schmid, Raphael Sznitman, Dimitris Psychogyios, Mahdi Azizian, Danail Stoyanov, Lena Maier-Hein, Stefanie Speidel</h3>
<p>The stereo correspondence and reconstruction of endoscopic data sub-challenge
was organized during the Endovis challenge at MICCAI 2019 in Shenzhen, China.
The task was to perform dense depth estimation using 7 training datasets and 2
test sets of structured light data captured using porcine cadavers. These were
provided by a team at Intuitive Surgical. 10 teams participated in the
challenge day. This paper contains 3 additional methods which were submitted
after the challenge finished as well as a supplemental section from these teams
on issues they found with the dataset.
</p>
<a href="http://arxiv.org/abs/2101.01133" target="_blank">arXiv:2101.01133</a> [<a href="http://arxiv.org/pdf/2101.01133" target="_blank">pdf</a>]

<h2>TrackMPNN: A Message Passing Graph Neural Architecture for Multi-Object Tracking. (arXiv:2101.04206v3 [cs.CV] UPDATED)</h2>
<h3>Akshay Rangesh, Pranav Maheshwari, Mez Gebre, Siddhesh Mhatre, Vahid Ramezani, Mohan M. Trivedi</h3>
<p>This study follows many previous approaches to multi-object tracking (MOT)
that model the problem using graph-based data structures, and adapts this
formulation to make it amenable to modern neural networks. Our main
contributions in this work are the creation of a framework based on dynamic
undirected graphs that represent the data association problem over multiple
timesteps, and a message passing graph neural network (GNN) that operates on
these graphs to produce the desired likelihood for every association therein.
We further provide solutions and propositions for the computational problems
that need to be addressed to create a memory-efficient, real-time, online
algorithm that can reason over multiple timesteps, correct previous mistakes,
update beliefs, possess long-term memory, and handle missed/false detections.
In addition to this, our framework provides flexibility in the choice of
temporal window sizes to operate on and the losses used for training. In
essence, this study provides a framework for any kind of graph based neural
network to be trained using conventional techniques from supervised learning,
and then use these trained models to infer on new sequences in an online,
real-time, computationally tractable manner. To demonstrate the efficacy and
robustness of our approach, we only use the 2D box location and object category
to construct the descriptor for each object instance. Despite this, our model
performs on par with state-of-the-art approaches that make use of multiple
hand-crafted and/or learned features. Experiments, qualitative examples and
competitive results on popular MOT benchmarks for autonomous driving
demonstrate the promise and uniqueness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.04206" target="_blank">arXiv:2101.04206</a> [<a href="http://arxiv.org/pdf/2101.04206" target="_blank">pdf</a>]

<h2>Structured Prediction as Translation between Augmented Natural Languages. (arXiv:2101.05779v2 [cs.LG] UPDATED)</h2>
<h3>Giovanni Paolini, Ben Athiwaratkun, Jason Krone, Jie Ma, Alessandro Achille, Rishita Anubhai, Cicero Nogueira dos Santos, Bing Xiang, Stefano Soatto</h3>
<p>We propose a new framework, Translation between Augmented Natural Languages
(TANL), to solve many structured prediction language tasks including joint
entity and relation extraction, nested named entity recognition, relation
classification, semantic role labeling, event extraction, coreference
resolution, and dialogue state tracking. Instead of tackling the problem by
training task-specific discriminative classifiers, we frame it as a translation
task between augmented natural languages, from which the task-relevant
information can be easily extracted. Our approach can match or outperform
task-specific models on all tasks, and in particular, achieves new
state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE,
NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and
semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while
using the same architecture and hyperparameters for all tasks and even when
training a single model to solve all tasks at the same time (multi-task
learning). Finally, we show that our framework can also significantly improve
the performance in a low-resource regime, thanks to better use of label
semantics.
</p>
<a href="http://arxiv.org/abs/2101.05779" target="_blank">arXiv:2101.05779</a> [<a href="http://arxiv.org/pdf/2101.05779" target="_blank">pdf</a>]

<h2>GIID-Net: Generalizable Image Inpainting Detection via Neural Architecture Search and Attention. (arXiv:2101.07419v2 [cs.CV] UPDATED)</h2>
<h3>Haiwei Wu, Jiantao Zhou</h3>
<p>Deep learning (DL) has demonstrated its powerful capabilities in the field of
image inpainting, which could produce visually plausible results. Meanwhile,
the malicious use of advanced image inpainting tools (e.g. removing key objects
to report fake news) has led to increasing threats to the reliability of image
data. To fight against the inpainting forgeries, in this work, we propose a
novel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),
to detect the inpainted regions at pixel accuracy. The proposed GIID-Net
consists of three sub-blocks: the enhancement block, the extraction block and
the decision block. Specifically, the enhancement block aims to enhance the
inpainting traces by using hierarchically combined special layers. The
extraction block, automatically designed by Neural Architecture Search (NAS)
algorithm, is targeted to extract features for the actual inpainting detection
tasks. In order to further optimize the extracted latent features, we integrate
global and local attention modules in the decision block, where the global
attention reduces the intra-class differences by measuring the similarity of
global features, while the local attention strengthens the consistency of local
features. Furthermore, we thoroughly study the generalizability of our
GIID-Net, and find that different training data could result in vastly
different generalization capability. Extensive experimental results are
presented to validate the superiority of the proposed GIID-Net, compared with
the state-of-the-art competitors. Our results would suggest that common
artifacts are shared across diverse image inpainting methods. Finally, we build
a public inpainting dataset of 10K image pairs for the future research in this
area.
</p>
<a href="http://arxiv.org/abs/2101.07419" target="_blank">arXiv:2101.07419</a> [<a href="http://arxiv.org/pdf/2101.07419" target="_blank">pdf</a>]

<h2>The Devils in the Point Clouds: Studying the Robustness of Point Cloud Convolutions. (arXiv:2101.07832v2 [cs.CV] UPDATED)</h2>
<h3>Xingyi Li, Wenxuan Wu, Xiaoli Z. Fern, Li Fuxin</h3>
<p>Recently, there has been a significant interest in performing convolution
over irregularly sampled point clouds. Since point clouds are very different
from regular raster images, it is imperative to study the generalization of the
convolution networks more closely, especially their robustness under variations
in scale and rotations of the input data. This paper investigates different
variants of PointConv, a convolution network on point clouds, to examine their
robustness to input scale and rotation changes. Of the variants we explored,
two are novel and generated significant improvements. The first is replacing
the multilayer perceptron based weight function with much simpler third degree
polynomials, together with a Sobolev norm regularization. Secondly, for 3D
datasets, we derive a novel viewpoint-invariant descriptor by utilizing 3D
geometric properties as the input to PointConv, in addition to the regular 3D
coordinates. We have also explored choices of activation functions,
neighborhood, and subsampling methods. Experiments are conducted on the 2D
MNIST &amp; CIFAR-10 datasets as well as the 3D SemanticKITTI &amp; ScanNet datasets.
Results reveal that on 2D, using third degree polynomials greatly improves
PointConv's robustness to scale changes and rotations, even surpassing
traditional 2D CNNs for the MNIST dataset. On 3D datasets, the novel
viewpoint-invariant descriptor significantly improves the performance as well
as robustness of PointConv. We achieve the state-of-the-art semantic
segmentation performance on the SemanticKITTI dataset, as well as comparable
performance with the current highest framework on the ScanNet dataset among
point-based approaches.
</p>
<a href="http://arxiv.org/abs/2101.07832" target="_blank">arXiv:2101.07832</a> [<a href="http://arxiv.org/pdf/2101.07832" target="_blank">pdf</a>]

<h2>Learning Abstract Task Representations. (arXiv:2101.07852v3 [cs.LG] UPDATED)</h2>
<h3>Mikhail M. Meskhi, Adriano Rivolli, Rafael G. Mantovani, Ricardo Vilalta</h3>
<p>A proper form of data characterization can guide the process of
learning-algorithm selection and model-performance estimation. The field of
meta-learning has provided a rich body of work describing effective forms of
data characterization using different families of meta-features (statistical,
model-based, information-theoretic, topological, etc.). In this paper, we start
with the abundant set of existing meta-features and propose a method to induce
new abstract meta-features as latent variables in a deep neural network. We
discuss the pitfalls of using traditional meta-features directly and argue for
the importance of learning high-level task properties. We demonstrate our
methodology using a deep neural network as a feature extractor. We demonstrate
that 1) induced meta-models mapping abstract meta-features to generalization
performance outperform other methods by ~18% on average, and 2) abstract
meta-features attain high feature-relevance scores.
</p>
<a href="http://arxiv.org/abs/2101.07852" target="_blank">arXiv:2101.07852</a> [<a href="http://arxiv.org/pdf/2101.07852" target="_blank">pdf</a>]

<h2>Vessel-CAPTCHA: an efficient learning framework for vessel annotation and segmentation. (arXiv:2101.09321v3 [cs.CV] UPDATED)</h2>
<h3>Vien Ngoc Dang, Giuseppe Di Giacomo, Viola Marconetto, Prateek Mathur, Rosa Cortese, Marco Lorenzi, Ferran Prados, Maria A. Zuluaga</h3>
<p>The use of deep learning techniques for 3D brain vessel image segmentation
has not been as widespread as for the segmentation of other organs and tissues.
This can be explained by two factors. First, deep learning techniques tend to
show poor performances at the segmentation of relatively small objects compared
to the size of the full image. Second, due to the complexity of vascular trees
and the small size of vessels, it is challenging to obtain the amount of
annotated training data typically needed by deep learning methods. To address
these problems, we propose a novel annotation-efficient deep learning vessel
segmentation framework. The framework avoids pixel-wise annotations, only
requiring patch-level labels to discriminate between vessel and non-vessel 2D
patches in the training set, in a setup similar to the CAPTCHAs used to
differentiate humans from bots in web applications. The user-provided
annotations are used for two tasks: 1) to automatically generate pixel-wise
labels for vessels and background in each patch, which are used to train a
segmentation network, and 2) to train a classifier network. The classifier
network allows to generate additional weak patch labels, further reducing the
annotation burden, and it acts as a noise filter for poor quality images. We
use this framework for the segmentation of the cerebrovascular tree in
Time-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The
results show that the framework achieves state-of-the-art accuracy, while
reducing the annotation time by up to 80% with respect to learning-based
segmentation methods using pixel-wise labels for training
</p>
<a href="http://arxiv.org/abs/2101.09321" target="_blank">arXiv:2101.09321</a> [<a href="http://arxiv.org/pdf/2101.09321" target="_blank">pdf</a>]

<h2>A Review on Deep Learning in UAV Remote Sensing. (arXiv:2101.10861v2 [cs.CV] UPDATED)</h2>
<h3>Lucas Prado Osco, Jos&#xe9; Marcato Junior, Ana Paula Marques Ramos, L&#xfa;cio Andr&#xe9; de Castro Jorge, Sarah Narges Fatholahi, Jonathan de Andrade Silva, Edson Takashi Matsubara, Hemerson Pistori, Wesley Nunes Gon&#xe7;alves, Jonathan Li</h3>
<p>Deep Neural Networks (DNNs) learn representation from data with an impressive
capability, and brought important breakthroughs for processing images,
time-series, natural language, audio, video, and many others. In the remote
sensing field, surveys and literature revisions specifically involving DNNs
algorithms' applications have been conducted in an attempt to summarize the
amount of information produced in its subfields. Recently, Unmanned Aerial
Vehicles (UAV) based applications have dominated aerial sensing research.
However, a literature revision that combines both "deep learning" and "UAV
remote sensing" thematics has not yet been conducted. The motivation for our
work was to present a comprehensive review of the fundamentals of Deep Learning
(DL) applied in UAV-based imagery. We focused mainly on describing
classification and regression techniques used in recent applications with
UAV-acquired data. For that, a total of 232 papers published in international
scientific journal databases was examined. We gathered the published material
and evaluated their characteristics regarding application, sensor, and
technique used. We relate how DL presents promising results and has the
potential for processing tasks associated with UAV-based image data. Lastly, we
project future perspectives, commentating on prominent DL paths to be explored
in the UAV remote sensing field. Our revision consists of a friendly-approach
to introduce, commentate, and summarize the state-of-the-art in UAV-based image
applications with DNNs algorithms in diverse subfields of remote sensing,
grouping it in the environmental, urban, and agricultural contexts.
</p>
<a href="http://arxiv.org/abs/2101.10861" target="_blank">arXiv:2101.10861</a> [<a href="http://arxiv.org/pdf/2101.10861" target="_blank">pdf</a>]

<h2>EPIC-Survival: End-to-end Part Inferred Clustering for Survival Analysis, Featuring Prognostic Stratification Boosting. (arXiv:2101.11085v2 [cs.CV] UPDATED)</h2>
<h3>Hassan Muhammad, Chensu Xie, Carlie S. Sigel, Michael Doukas, Lindsay Alpert, Thomas J. Fuchs</h3>
<p>Histopathology-based survival modelling has two major hurdles. Firstly, a
well-performing survival model has minimal clinical application if it does not
contribute to the stratification of a cancer patient cohort into different risk
groups, preferably driven by histologic morphologies. In the clinical setting,
individuals are not given specific prognostic predictions, but are rather
predicted to lie within a risk group which has a general survival trend. Thus,
It is imperative that a survival model produces well-stratified risk groups.
Secondly, until now, survival modelling was done in a two-stage approach
(encoding and aggregation). The massive amount of pixels in digitized whole
slide images were never utilized to their fullest extent due to technological
constraints on data processing, forcing decoupled learning. EPIC-Survival
bridges encoding and aggregation into an end-to-end survival modelling
approach, while introducing stratification boosting to encourage the model to
not only optimize ranking, but also to discriminate between risk groups. In
this study we show that EPIC-Survival performs better than other approaches in
modelling intrahepatic cholangiocarcinoma, a historically difficult cancer to
model. Further, we show that stratification boosting improves further improves
model performance, resulting in a concordance-index of 0.880 on a held-out test
set. Finally, we were able to identify specific histologic differences, not
commonly sought out in ICC, between low and high risk groups.
</p>
<a href="http://arxiv.org/abs/2101.11085" target="_blank">arXiv:2101.11085</a> [<a href="http://arxiv.org/pdf/2101.11085" target="_blank">pdf</a>]

<h2>NTU60-X: Towards Skeleton-based Recognition of Subtle Human Actions. (arXiv:2101.11529v2 [cs.CV] UPDATED)</h2>
<h3>Anirudh Thatipelli, Neel Trivedi, Ravi Kiran Sarvadevabhatla</h3>
<p>The lack of fine-grained joints such as hand fingers is a fundamental
performance bottleneck for state of the art skeleton action recognition models
trained on the largest action recognition dataset, NTU-RGBD. To address this
bottleneck, we introduce a new skeleton based human action dataset - NTU60-X.
In addition to the 25 body joints for each skeleton as in NTU-RGBD, NTU60-X
dataset includes finger and facial joints, enabling a richer skeleton
representation. We appropriately modify the state of the art approaches to
enable training using the introduced dataset. Our results demonstrate the
effectiveness of NTU60-X in overcoming the aforementioned bottleneck and
improve state of the art performance, overall and on hitherto worst performing
action categories.
</p>
<a href="http://arxiv.org/abs/2101.11529" target="_blank">arXiv:2101.11529</a> [<a href="http://arxiv.org/pdf/2101.11529" target="_blank">pdf</a>]

<h2>Dopamine: Differentially Private Federated Learning on Medical Data. (arXiv:2101.11693v2 [cs.LG] UPDATED)</h2>
<h3>Mohammad Malekzadeh, Burak Hasircioglu, Nitish Mital, Kunal Katarya, Mehmet Emre Ozfatura, Deniz G&#xfc;nd&#xfc;z</h3>
<p>While rich medical datasets are hosted in hospitals distributed across the
world, concerns on patients' privacy is a barrier against using such data to
train deep neural networks (DNNs) for medical diagnostics. We propose Dopamine,
a system to train DNNs on distributed datasets, which employs federated
learning (FL) with differentially-private stochastic gradient descent (DPSGD),
and, in combination with secure aggregation, can establish a better trade-off
between differential privacy (DP) guarantee and DNN's accuracy than other
approaches. Results on a diabetic retinopathy~(DR) task show that Dopamine
provides a DP guarantee close to the centralized training counterpart, while
achieving a better classification accuracy than FL with parallel DP where DPSGD
is applied without coordination. Code is available at
https://github.com/ipc-lab/private-ml-for-health.
</p>
<a href="http://arxiv.org/abs/2101.11693" target="_blank">arXiv:2101.11693</a> [<a href="http://arxiv.org/pdf/2101.11693" target="_blank">pdf</a>]

<h2>Improving Neural Network Robustness through Neighborhood Preserving Layers. (arXiv:2101.11766v2 [cs.LG] UPDATED)</h2>
<h3>Bingyuan Liu, Christopher Malon, Lingzhou Xue, Erik Kruus</h3>
<p>Robustness against adversarial attack in neural networks is an important
research topic in the machine learning community. We observe one major source
of vulnerability of neural nets is from overparameterized fully-connected
layers. In this paper, we propose a new neighborhood preserving layer which can
replace these fully connected layers to improve the network robustness. We
demonstrate a novel neural network architecture which can incorporate such
layers and also can be trained efficiently. We theoretically prove that our
models are more robust against distortion because they effectively control the
magnitude of gradients. Finally, we empirically show that our designed network
architecture is more robust against state-of-art gradient descent based
attacks, such as a PGD attack on the benchmark datasets MNIST and CIFAR10.
</p>
<a href="http://arxiv.org/abs/2101.11766" target="_blank">arXiv:2101.11766</a> [<a href="http://arxiv.org/pdf/2101.11766" target="_blank">pdf</a>]

<h2>The Hidden Tasks of Generative Adversarial Networks: An Alternative Perspective on GAN Training. (arXiv:2101.11863v2 [cs.LG] UPDATED)</h2>
<h3>Romann M. Weber</h3>
<p>We present an alternative perspective on the training of generative
adversarial networks (GANs), showing that the training step for a GAN generator
decomposes into two implicit sub-problems. In the first, the discriminator
provides new target data to the generator in the form of "inverse examples"
produced by approximately inverting classifier labels. In the second, these
examples are used as targets to update the generator via least-squares
regression, regardless of the main loss specified to train the network. We
experimentally validate our main theoretical result and discuss implications
for alternative training methods that are made possible by making these
sub-problems explicit. We also introduce a simple representation of inductive
bias in networks, which we apply to describing the generator's output relative
to its regression targets.
</p>
<a href="http://arxiv.org/abs/2101.11863" target="_blank">arXiv:2101.11863</a> [<a href="http://arxiv.org/pdf/2101.11863" target="_blank">pdf</a>]

<h2>Automatic design of novel potential 3CL$^{\text{pro}}$ and PL$^{\text{pro}}$ inhibitors. (arXiv:2101.11890v2 [cs.LG] UPDATED)</h2>
<h3>Timothy Atkinson, Saeed Saremi, Faustino Gomez, Jonathan Masci</h3>
<p>With the goal of designing novel inhibitors for SARS-CoV-1 and SARS-CoV-2, we
propose the general molecule optimization framework, Molecular Neural Assay
Search (MONAS), consisting of three components: a property predictor which
identifies molecules with specific desirable properties, an energy model which
approximates the statistical similarity of a given molecule to known training
molecules, and a molecule search method. In this work, these components are
instantiated with graph neural networks (GNNs), Deep Energy Estimator Networks
(DEEN) and Monte Carlo tree search (MCTS), respectively. This implementation is
used to identify 120K molecules (out of 40-million explored) which the GNN
determined to be likely SARS-CoV-1 inhibitors, and, at the same time, are
statistically close to the dataset used to train the GNN.
</p>
<a href="http://arxiv.org/abs/2101.11890" target="_blank">arXiv:2101.11890</a> [<a href="http://arxiv.org/pdf/2101.11890" target="_blank">pdf</a>]

