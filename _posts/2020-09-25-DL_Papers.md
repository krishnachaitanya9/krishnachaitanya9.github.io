---
title: Latest Deep Learning Papers
date: 2020-12-28 21:00:02 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (248 Articles)</h1>
<h2>Weighted defeasible knowledge bases and a multipreference semantics for a deep neural network model. (arXiv:2012.13421v1 [cs.AI])</h2>
<h3>Laura Giordano, Daniele Theseider Dupr&#xe9;</h3>
<p>In this paper we investigate the relationships between a multipreferential
semantics for defeasible reasoning in knowledge representation and a deep
neural network model. Weighted knowledge bases for description logics are
considered under a "concept-wise" multipreference semantics. The semantics is
further extended to fuzzy interpretations and exploited to provide a
preferential interpretation of Multilayer Perceptrons.
</p>
<a href="http://arxiv.org/abs/2012.13421" target="_blank">arXiv:2012.13421</a> [<a href="http://arxiv.org/pdf/2012.13421" target="_blank">pdf</a>]

<h2>Mixed-Privacy Forgetting in Deep Networks. (arXiv:2012.13431v1 [cs.LG])</h2>
<h3>Aditya Golatkar, Alessandro Achille, Avinash Ravichandran, Marzia Polito, Stefano Soatto</h3>
<p>We show that the influence of a subset of the training samples can be removed
-- or "forgotten" -- from the weights of a network trained on large-scale image
classification tasks, and we provide strong computable bounds on the amount of
remaining information after forgetting. Inspired by real-world applications of
forgetting techniques, we introduce a novel notion of forgetting in
mixed-privacy setting, where we know that a "core" subset of the training
samples does not need to be forgotten. While this variation of the problem is
conceptually simple, we show that working in this setting significantly
improves the accuracy and guarantees of forgetting methods applied to vision
classification tasks. Moreover, our method allows efficient removal of all
information contained in non-core data by simply setting to zero a subset of
the weights with minimal loss in performance. We achieve these results by
replacing a standard deep network with a suitable linear approximation. With
opportune changes to the network architecture and training procedure, we show
that such linear approximation achieves comparable performance to the original
network and that the forgetting problem becomes quadratic and can be solved
efficiently even for large models. Unlike previous forgetting methods on deep
networks, ours can achieve close to the state-of-the-art accuracy on large
scale vision tasks. In particular, we show that our method allows forgetting
without having to trade off the model accuracy.
</p>
<a href="http://arxiv.org/abs/2012.13431" target="_blank">arXiv:2012.13431</a> [<a href="http://arxiv.org/pdf/2012.13431" target="_blank">pdf</a>]

<h2>Identifying Training Stop Point with Noisy Labeled Data. (arXiv:2012.13435v1 [cs.LG])</h2>
<h3>Sree Ram Kamabattula, Venkat Devarajan, Babak Namazi, Ganesh Sankaranarayanan</h3>
<p>Training deep neural networks (DNNs) with noisy labels is a challenging
problem due to over-parameterization. DNNs tend to essentially fit on clean
samples at a higher rate in the initial stages, and later fit on the noisy
samples at a relatively lower rate. Thus, with a noisy dataset, the test
accuracy increases initially and drops in the later stages. To find an early
stopping point at the maximum obtainable test accuracy (MOTA), recent studies
assume either that i) a clean validation set is available or ii) the noise
ratio is known, or, both. However, often a clean validation set is unavailable,
and the noise estimation can be inaccurate. To overcome these issues, we
provide a novel training solution, free of these conditions. We analyze the
rate of change of the training accuracy for different noise ratios under
different conditions to identify a training stop region. We further develop a
heuristic algorithm based on a small-learning assumption to find a training
stop point (TSP) at or close to MOTA. To the best of our knowledge, our method
is the first to rely solely on the \textit{training behavior}, while utilizing
the entire training set, to automatically find a TSP. We validated the
robustness of our algorithm (AutoTSP) through several experiments on CIFAR-10,
CIFAR-100, and a real-world noisy dataset for different noise ratios, noise
types and architectures.
</p>
<a href="http://arxiv.org/abs/2012.13435" target="_blank">arXiv:2012.13435</a> [<a href="http://arxiv.org/pdf/2012.13435" target="_blank">pdf</a>]

<h2>Real-Time Facial Expression Emoji Masking with Convolutional Neural Networks and Homography. (arXiv:2012.13447v1 [cs.CV])</h2>
<h3>Qinchen Wang, Sixuan Wu, Tingfeng Xia</h3>
<p>Neural network based algorithms has shown success in many applications. In
image processing, Convolutional Neural Networks (CNN) can be trained to
categorize facial expressions of images of human faces. In this work, we create
a system that masks a student's face with a emoji of the respective emotion.
Our system consists of three building blocks: face detection using Histogram of
Gradients (HoG) and Support Vector Machine (SVM), facial expression
categorization using CNN trained on FER2013 dataset, and finally masking the
respective emoji back onto the student's face via homography estimation. (Demo:
https://youtu.be/GCjtXw1y8Pw) Our results show that this pipeline is
deploy-able in real-time, and is usable in educational settings.
</p>
<a href="http://arxiv.org/abs/2012.13447" target="_blank">arXiv:2012.13447</a> [<a href="http://arxiv.org/pdf/2012.13447" target="_blank">pdf</a>]

<h2>Modeling Disease Progression in Mild Cognitive Impairment and Alzheimer's Disease with Digital Twins. (arXiv:2012.13455v1 [cs.LG])</h2>
<h3>Daniele Bertolini, Anton D. Loukianov, Aaron M. Smith, David Li-Bland, Yannick Pouliot, Jonathan R. Walsh, Charles K. Fisher</h3>
<p>Alzheimer's Disease (AD) is a neurodegenerative disease that affects subjects
in a broad range of severity and is assessed in clinical trials with multiple
cognitive and functional instruments. As clinical trials in AD increasingly
focus on earlier stages of the disease, especially Mild Cognitive Impairment
(MCI), the ability to model subject outcomes across the disease spectrum is
extremely important. We use unsupervised machine learning models called
Conditional Restricted Boltzmann Machines (CRBMs) to create Digital Twins of AD
subjects. Digital Twins are simulated clinical records that share baseline data
with actual subjects and comprehensively model their outcomes under
standard-of-care. The CRBMs are trained on a large set of records from subjects
in observational studies and the placebo arms of clinical trials across the AD
spectrum. These data exhibit a challenging, but common, patchwork of measured
and missing observations across subjects in the dataset, and we present a novel
model architecture designed to learn effectively from it. We evaluate
performance against a held-out test dataset and show how Digital Twins
simultaneously capture the progression of a number of key endpoints in clinical
trials across a broad spectrum of disease severity, including MCI and
mild-to-moderate AD.
</p>
<a href="http://arxiv.org/abs/2012.13455" target="_blank">arXiv:2012.13455</a> [<a href="http://arxiv.org/pdf/2012.13455" target="_blank">pdf</a>]

<h2>Towards Coordinated Robot Motions: End-to-End Learning of Motion Policies on Transform Trees. (arXiv:2012.13457v1 [cs.RO])</h2>
<h3>M. Asif Rana, Anqi Li, Dieter Fox, Sonia Chernova, Byron Boots, Nathan Ratliff</h3>
<p>Robotic tasks often require generation of motions that satisfy multiple
motion constraints, that may live on different parts of a robot's body. In this
paper, we address the challenge of learning motion policies to generate motions
for execution of such tasks. Additionally, to encode multiple motion
constraints and their synergies, we enforce structure in our motion policy.
Specifically, the structure results from decomposing a motion policy into
multiple subtask policies, whereby each subtask policy dictates a particular
subtask behavior. By learning the subtask policies together in an end-to-end
fashion, our formulation not only learns coordination between subtask
behaviors, but also learns how to trade them off against default behaviors that
may exist. Furthermore, due to our choice of parameterization for the
constituting subtask policies, our overall structured motion policy is
guaranteed to generate stable motions. To corroborate our theory, we also
present qualitative and quantitative evaluations on multiple robotic tasks.
</p>
<a href="http://arxiv.org/abs/2012.13457" target="_blank">arXiv:2012.13457</a> [<a href="http://arxiv.org/pdf/2012.13457" target="_blank">pdf</a>]

<h2>GraNet: Global Relation-aware Attentional Network for ALS Point Cloud Classification. (arXiv:2012.13466v1 [cs.CV])</h2>
<h3>Rong Huang, Yusheng Xu, Uwe Stilla</h3>
<p>In this work, we propose a novel neural network focusing on semantic labeling
of ALS point clouds, which investigates the importance of long-range spatial
and channel-wise relations and is termed as global relation-aware attentional
network (GraNet). GraNet first learns local geometric description and local
dependencies using a local spatial discrepancy attention convolution module
(LoSDA). In LoSDA, the orientation information, spatial distribution, and
elevation differences are fully considered by stacking several local spatial
geometric learning modules and the local dependencies are embedded by using an
attention pooling module. Then, a global relation-aware attention module (GRA),
consisting of a spatial relation-aware attention module (SRA) and a channel
relation aware attention module (CRA), are investigated to further learn the
global spatial and channel-wise relationship between any spatial positions and
feature vectors. The aforementioned two important modules are embedded in the
multi-scale network architecture to further consider scale changes in large
urban areas. We conducted comprehensive experiments on two ALS point cloud
datasets to evaluate the performance of our proposed framework. The results
show that our method can achieve higher classification accuracy compared with
other commonly used advanced classification methods. The overall accuracy (OA)
of our method on the ISPRS benchmark dataset can be improved to 84.5% to
classify nine semantic classes, with an average F1 measure (AvgF1) of 73.5%. In
detail, we have following F1 values for each object class: powerlines: 66.3%,
low vegetation: 82.8%, impervious surface: 91.8%, car: 80.7%, fence: 51.2%,
roof: 94.6%, facades: 62.1%, shrub: 49.9%, trees: 82.1%. Besides, experiments
were conducted using a new ALS point cloud dataset covering highly dense urban
areas.
</p>
<a href="http://arxiv.org/abs/2012.13466" target="_blank">arXiv:2012.13466</a> [<a href="http://arxiv.org/pdf/2012.13466" target="_blank">pdf</a>]

<h2>Prediction by Anticipation: An Action-Conditional Prediction Method based on Interaction Learning. (arXiv:2012.13478v1 [cs.LG])</h2>
<h3>Ershad Banijamali, Mohsen Rohani, Elmira Amirloo, Jun Luo, Pascal Poupart</h3>
<p>In autonomous driving (AD), accurately predicting changes in the environment
can effectively improve safety and comfort. Due to complex interactions among
traffic participants, however, it is very hard to achieve accurate prediction
for a long horizon. To address this challenge, we propose prediction by
anticipation, which views interaction in terms of a latent probabilistic
generative process wherein some vehicles move partly in response to the
anticipated motion of other vehicles. Under this view, consecutive data frames
can be factorized into sequential samples from an action-conditional
distribution that effectively generalizes to a wider range of actions and
driving situations. Our proposed prediction model, variational Bayesian in
nature, is trained to maximize the evidence lower bound (ELBO) of the
log-likelihood of this conditional distribution. Evaluations of our approach
with prominent AD datasets NGSIM I-80 and Argoverse show significant
improvement over current state-of-the-art in both accuracy and generalization.
</p>
<a href="http://arxiv.org/abs/2012.13478" target="_blank">arXiv:2012.13478</a> [<a href="http://arxiv.org/pdf/2012.13478" target="_blank">pdf</a>]

<h2>A Graph Convolutional Network with Signal Phasing Information for Arterial Traffic Prediction. (arXiv:2012.13479v1 [cs.LG])</h2>
<h3>Victor Chan, Qijian Gan, Alexandre Bayen</h3>
<p>Accurate and reliable prediction of traffic measurements plays a crucial role
in the development of modern intelligent transportation systems. Due to more
complex road geometries and the presence of signal control, arterial traffic
prediction is a level above freeway traffic prediction. Many existing studies
on arterial traffic prediction only consider temporal measurements of flow and
occupancy from loop sensors and neglect the rich spatial relationships between
upstream and downstream detectors. As a result, they often suffer large
prediction errors, especially for long horizons. We fill this gap by enhancing
a deep learning approach, Diffusion Convolutional Recurrent Neural Network,
with spatial information generated from signal timing plans at targeted
intersections. Traffic at signalized intersections is modeled as a diffusion
process with a transition matrix constructed from the phase splits of the
signal phase timing plan. We apply this novel method to predict traffic flow
from loop sensor measurements and signal timing plans at an arterial
intersection in Arcadia, CA. We demonstrate that our proposed method yields
superior forecasts; for a prediction horizon of 30 minutes, we cut the MAPE
down to 16% for morning peaks, 10% for off peaks, and even 8% for afternoon
peaks. In addition, we exemplify the robustness of our model through a number
of experiments with various settings in detector coverage, detector type, and
data quality.
</p>
<a href="http://arxiv.org/abs/2012.13479" target="_blank">arXiv:2012.13479</a> [<a href="http://arxiv.org/pdf/2012.13479" target="_blank">pdf</a>]

<h2>Whom to Test? Active Sampling Strategies for Managing COVID-19. (arXiv:2012.13483v1 [cs.LG])</h2>
<h3>Yingfei Wang, Inbal Yahav, Balaji Padmanabhan</h3>
<p>This paper presents methods to choose individuals to test for infection
during a pandemic such as COVID-19, characterized by high contagion and
presence of asymptomatic carriers. The smart-testing ideas presented here are
motivated by active learning and multi-armed bandit techniques in machine
learning. Our active sampling method works in conjunction with quarantine
policies, can handle different objectives, is dynamic and adaptive in the sense
that it continually adapts to changes in real-time data. The bandit algorithm
uses contact tracing, location-based sampling and random sampling in order to
select specific individuals to test. Using a data-driven agent-based model
simulating New York City we show that the algorithm samples individuals to test
in a manner that rapidly traces infected individuals. Experiments also suggest
that smart-testing can significantly reduce the death rates as compared to
current methods such as testing symptomatic individuals with or without contact
tracing.
</p>
<a href="http://arxiv.org/abs/2012.13483" target="_blank">arXiv:2012.13483</a> [<a href="http://arxiv.org/pdf/2012.13483" target="_blank">pdf</a>]

<h2>Learning Robust Representation for Clustering through Locality Preserving Variational Discriminative Network. (arXiv:2012.13489v1 [cs.LG])</h2>
<h3>Ruixuan Luo, Wei Li, Zhiyuan Zhang, Ruihan Bao, Keiko Harimoto, Xu Sun</h3>
<p>Clustering is one of the fundamental problems in unsupervised learning.
Recent deep learning based methods focus on learning clustering oriented
representations. Among those methods, Variational Deep Embedding achieves great
success in various clustering tasks by specifying a Gaussian Mixture prior to
the latent space. However, VaDE suffers from two problems: 1) it is fragile to
the input noise; 2) it ignores the locality information between the neighboring
data points. In this paper, we propose a joint learning framework that improves
VaDE with a robust embedding discriminator and a local structure constraint,
which are both helpful to improve the robustness of our model. Experiment
results on various vision and textual datasets demonstrate that our method
outperforms the state-of-the-art baseline models in all metrics. Further
detailed analysis shows that our proposed model is very robust to the
adversarial inputs, which is a desirable property for practical applications.
</p>
<a href="http://arxiv.org/abs/2012.13489" target="_blank">arXiv:2012.13489</a> [<a href="http://arxiv.org/pdf/2012.13489" target="_blank">pdf</a>]

<h2>Towards Continual Reinforcement Learning: A Review and Perspectives. (arXiv:2012.13490v1 [cs.LG])</h2>
<h3>Khimya Khetarpal, Matthew Riemer, Irina Rish, Doina Precup</h3>
<p>In this article, we aim to provide a literature review of different
formulations and approaches to continual reinforcement learning (RL), also
known as lifelong or non-stationary RL. We begin by discussing our perspective
on why RL is a natural fit for studying continual learning. We then provide a
taxonomy of different continual RL formulations and mathematically characterize
the non-stationary dynamics of each setting. We go on to discuss evaluation of
continual RL agents, providing an overview of benchmarks used in the literature
and important metrics for understanding agent performance. Finally, we
highlight open problems and challenges in bridging the gap between the current
state of continual RL and findings in neuroscience. While still in its early
days, the study of continual RL has the promise to develop better incremental
reinforcement learners that can function in increasingly realistic applications
where non-stationarity plays a vital role. These include applications such as
those in the fields of healthcare, education, logistics, and robotics.
</p>
<a href="http://arxiv.org/abs/2012.13490" target="_blank">arXiv:2012.13490</a> [<a href="http://arxiv.org/pdf/2012.13490" target="_blank">pdf</a>]

<h2>Self-supervised Pre-training with Hard Examples Improves Visual Representations. (arXiv:2012.13493v1 [cs.CV])</h2>
<h3>Chunyuan Li, Xiujun Li, Lei Zhang, Baolin Peng, Mingyuan Zhou, Jianfeng Gao</h3>
<p>Self-supervised pre-training (SSP) employs random image transformations to
generate training data for visual representation learning. In this paper, we
first present a modeling framework that unifies existing SSP methods as
learning to predict pseudo-labels. Then, we propose new data augmentation
methods of generating training examples whose pseudo-labels are harder to
predict than those generated via random image transformations. Specifically, we
use adversarial training and CutMix to create hard examples (HEXA) to be used
as augmented views for MoCo-v2 and DeepCluster-v2, leading to two variants
HEXA_{MoCo} and HEXA_{DCluster}, respectively. In our experiments, we pre-train
models on ImageNet and evaluate them on multiple public benchmarks. Our
evaluation shows that the two new algorithm variants outperform their original
counterparts, and achieve new state-of-the-art on a wide range of tasks where
limited task supervision is available for fine-tuning. These results verify
that hard examples are instrumental in improving the generalization of the
pre-trained models.
</p>
<a href="http://arxiv.org/abs/2012.13493" target="_blank">arXiv:2012.13493</a> [<a href="http://arxiv.org/pdf/2012.13493" target="_blank">pdf</a>]

<h2>1st Place Solution to VisDA-2020: Bias Elimination for Domain Adaptive Pedestrian Re-identification. (arXiv:2012.13498v1 [cs.CV])</h2>
<h3>Jianyang Gu, Hao Luo, Weihua Chen, Yiqi Jiang, Yuqi Zhang, Shuting He, Fan Wang, Hao Li, Wei Jiang</h3>
<p>This paper presents our proposed methods for domain adaptive pedestrian
re-identification (Re-ID) task in Visual Domain Adaptation Challenge
(VisDA-2020). Considering the large gap between the source domain and target
domain, we focused on solving two biases that influenced the performance on
domain adaptive pedestrian Re-ID and proposed a two-stage training procedure.
At the first stage, a baseline model is trained with images transferred from
source domain to target domain and from single camera to multiple camera
styles. Then we introduced a domain adaptation framework to train the model on
source data and target data simultaneously. Different pseudo label generation
strategies are adopted to continuously improve the discriminative ability of
the model. Finally, with multiple models ensembled and additional post
processing approaches adopted, our methods achieve 76.56% mAP and 84.25% rank-1
on the test set. Codes are available at
https://github.com/vimar-gu/Bias-Eliminate-DA-ReID
</p>
<a href="http://arxiv.org/abs/2012.13498" target="_blank">arXiv:2012.13498</a> [<a href="http://arxiv.org/pdf/2012.13498" target="_blank">pdf</a>]

<h2>A Cascaded Residual UNET for Fully Automated Segmentation of Prostate and Peripheral Zone in T2-weighted 3D Fast Spin Echo Images. (arXiv:2012.13501v1 [cs.CV])</h2>
<h3>Lavanya Umapathy, Wyatt Unger, Faryal Shareef, Hina Arif, Diego Martin, Maria Altbach, Ali Bilgin</h3>
<p>Multi-parametric MR images have been shown to be effective in the
non-invasive diagnosis of prostate cancer. Automated segmentation of the
prostate eliminates the need for manual annotation by a radiologist which is
time consuming. This improves efficiency in the extraction of imaging features
for the characterization of prostate tissues. In this work, we propose a fully
automated cascaded deep learning architecture with residual blocks, Cascaded
MRes-UNET, for segmentation of the prostate gland and the peripheral zone in
one pass through the network. The network yields high Dice scores
($0.91\pm.02$), precision ($0.91\pm.04$), and recall scores ($0.92\pm.03$) in
prostate segmentation compared to manual annotations by an experienced
radiologist. The average difference in total prostate volume estimation is less
than 5%.
</p>
<a href="http://arxiv.org/abs/2012.13501" target="_blank">arXiv:2012.13501</a> [<a href="http://arxiv.org/pdf/2012.13501" target="_blank">pdf</a>]

<h2>Generative VoxelNet: Learning Energy-Based Models for 3D Shape Synthesis and Analysis. (arXiv:2012.13522v1 [cs.CV])</h2>
<h3>Jianwen Xie, Zilong Zheng, Ruiqi Gao, Wenguan Wang, Song-Chun Zhu, Ying Nian Wu</h3>
<p>3D data that contains rich geometry information of objects and scenes is
valuable for understanding 3D physical world. With the recent emergence of
large-scale 3D datasets, it becomes increasingly crucial to have a powerful 3D
generative model for 3D shape synthesis and analysis. This paper proposes a
deep 3D energy-based model to represent volumetric shapes. The maximum
likelihood training of the model follows an "analysis by synthesis" scheme. The
benefits of the proposed model are six-fold: first, unlike GANs and VAEs, the
model training does not rely on any auxiliary models; second, the model can
synthesize realistic 3D shapes by Markov chain Monte Carlo (MCMC); third, the
conditional model can be applied to 3D object recovery and super resolution;
fourth, the model can serve as a building block in a multi-grid modeling and
sampling framework for high resolution 3D shape synthesis; fifth, the model can
be used to train a 3D generator via MCMC teaching; sixth, the unsupervisedly
trained model provides a powerful feature extractor for 3D data, which is
useful for 3D object classification. Experiments demonstrate that the proposed
model can generate high-quality 3D shape patterns and can be useful for a wide
variety of 3D shape analysis.
</p>
<a href="http://arxiv.org/abs/2012.13522" target="_blank">arXiv:2012.13522</a> [<a href="http://arxiv.org/pdf/2012.13522" target="_blank">pdf</a>]

<h2>Brain-inspired Search Engine Assistant based on Knowledge Graph. (arXiv:2012.13529v1 [cs.AI])</h2>
<h3>Xuejiao Zhao, Huanhuan Chen, Zhenchang Xing, Chunyan Miao</h3>
<p>Search engines can quickly response a hyperlink list according to query
keywords. However, when a query is complex, developers need to repeatedly
refine the search keywords and open a large number of web pages to find and
summarize answers. Many research works of question and answering (Q and A)
system attempt to assist search engines by providing simple, accurate and
understandable answers. However, without original semantic contexts, these
answers lack explainability, making them difficult for users to trust and
adopt. In this paper, a brain-inspired search engine assistant named
DeveloperBot based on knowledge graph is proposed, which aligns to the
cognitive process of human and has the capacity to answer complex queries with
explainability. Specifically, DeveloperBot firstly constructs a multi-layer
query graph by splitting a complex multi-constraint query into several ordered
constraints. Then it models the constraint reasoning process as subgraph search
process inspired by the spreading activation model of cognitive science. In the
end, novel features of the subgraph will be extracted for decision-making. The
corresponding reasoning subgraph and answer confidence will be derived as
explanations. The results of the decision-making demonstrate that DeveloperBot
can estimate the answers and answer confidences with high accuracy. We
implement a prototype and conduct a user study to evaluate whether and how the
direct answers and the explanations provided by DeveloperBot can assist
developers' information needs.
</p>
<a href="http://arxiv.org/abs/2012.13529" target="_blank">arXiv:2012.13529</a> [<a href="http://arxiv.org/pdf/2012.13529" target="_blank">pdf</a>]

<h2>More Powerful and General Selective Inference for Stepwise Feature Selection using the Homotopy Continuation Approach. (arXiv:2012.13545v1 [stat.ML])</h2>
<h3>Kazuya Sugiyama, Vo Nguyen Le Duy, Ichiro Takeuchi</h3>
<p>Conditional Selective Inference (SI) has been actively studied as a new
statistical inference framework for data-driven hypotheses. For example,
conditional SI framework enables exact (non-asymptotic) inference on the
features selected by stepwise feature selection (SFS) method. The basic idea of
conditional SI is to make inference conditional on the selection event. The
main limitation of existing conditional SI approach for SFS method is the loss
of power due to over-conditioning for computational tractability. In this
paper, we develop more powerful and general conditional SI method for SFS by
resolving the over-conditioning issue by homotopy continuation approach. We
conduct several experiments to demonstrate the effectiveness and efficiency of
our proposed method.
</p>
<a href="http://arxiv.org/abs/2012.13545" target="_blank">arXiv:2012.13545</a> [<a href="http://arxiv.org/pdf/2012.13545" target="_blank">pdf</a>]

<h2>Implicit Feature Pyramid Network for Object Detection. (arXiv:2012.13563v1 [cs.CV])</h2>
<h3>Tiancai Wang, Xiangyu Zhang, Jian Sun</h3>
<p>In this paper, we present an implicit feature pyramid network (i-FPN) for
object detection. Existing FPNs stack several cross-scale blocks to obtain
large receptive field. We propose to use an implicit function, recently
introduced in deep equilibrium model (DEQ), to model the transformation of FPN.
We develop a residual-like iteration to updates the hidden states efficiently.
Experimental results on MS COCO dataset show that i-FPN can significantly boost
detection performance compared to baseline detectors with ResNet-50-FPN: +3.4,
+3.2, +3.5, +4.2, +3.2 mAP on RetinaNet, Faster-RCNN, FCOS, ATSS and
AutoAssign, respectively.
</p>
<a href="http://arxiv.org/abs/2012.13563" target="_blank">arXiv:2012.13563</a> [<a href="http://arxiv.org/pdf/2012.13563" target="_blank">pdf</a>]

<h2>Toward Real-World BCI: CCSPNet, A Compact Subject-Independent Motor Imagery Framework. (arXiv:2012.13567v1 [cs.LG])</h2>
<h3>Mahbod Nouri, Faraz Moradi, Hafez Ghaemi, Ali Motie Nasrabadi</h3>
<p>A conventional brain-computer interface (BCI) requires a complete data
gathering, training, and calibration phase for each user before it can be used.
This preliminary phase is time-consuming and should be done under the
supervision of technical experts commonly in laboratories for the BCI to
function properly. In recent years, a number of subject-independent (SI) BCIs
have been developed. However, there are many problems preventing them from
being used in real-world BCI applications. A lower accuracy than the
subject-dependent (SD) approach and a relatively high run-time of models with a
large number of model parameters are the most important ones. Therefore, a
real-world BCI application would greatly benefit from a compact
subject-independent BCI framework, ready to use immediately after the user puts
it on, and suitable for low-power edge-computing and applications in the
emerging area of internet of things (IoT). We propose a novel
subject-independent BCI framework named CCSPNet (Convolutional Common Spatial
Pattern Network) that is trained on the motor imagery (MI) paradigm of a
large-scale EEG signals database consisting of 400 trials for every 54 subjects
performing two-class hand-movement MI tasks. The proposed framework applies a
wavelet kernel convolutional neural network (WKCNN) and a temporal
convolutional neural network (TCNN) in order to represent and extract the
diverse frequency behavior and spectral patterns of EEG signals. The
convolutional layers outputs go through a CSP algorithm for class
discrimination and spatial feature extraction. The number of CSP features is
reduced by a dense neural network, and the final class label is determined by
an LDA. The final SD and SI classification accuracies of the proposed framework
match the best results obtained on the largest motor-imagery dataset present in
the BCI literature, with 99.993 percent fewer model parameters.
</p>
<a href="http://arxiv.org/abs/2012.13567" target="_blank">arXiv:2012.13567</a> [<a href="http://arxiv.org/pdf/2012.13567" target="_blank">pdf</a>]

<h2>Using the Naive Bayes as a discriminative classifier. (arXiv:2012.13572v1 [stat.ML])</h2>
<h3>Elie Azeraf, Emmanuel Monfrini, Wojciech Pieczynski</h3>
<p>For classification tasks, probabilistic models can be categorized into two
disjoint classes: generative or discriminative. It depends on the posterior
probability computation of the label $x$ given the observation $y$, $p(x | y)$.
On the one hand, generative classifiers, like the Naive Bayes or the Hidden
Markov Model (HMM), need the computation of the joint probability $p(x, y)$,
before using the Bayes rule to compute $p(x | y)$. On the other hand,
discriminative classifiers compute $p(x | y)$ directly, regardless of the
observations' law. They are intensively used nowadays, with models as Logistic
Regression, Conditional Random Fields (CRF), and Artificial Neural Networks.
However, the recent Entropic Forward-Backward algorithm shows that the HMM,
considered as a generative model, can also match the discriminative one's
definition. This example leads to question if it is the case for other
generative models. In this paper, we show that the Naive Bayes classifier can
also match the discriminative classifier definition, so it can be used in
either a generative or a discriminative way. Moreover, this observation also
discusses the notion of Generative-Discriminative pairs, linking, for example,
Naive Bayes and Logistic Regression, or HMM and CRF. Related to this point, we
show that the Logistic Regression can be viewed as a particular case of the
Naive Bayes used in a discriminative way.
</p>
<a href="http://arxiv.org/abs/2012.13572" target="_blank">arXiv:2012.13572</a> [<a href="http://arxiv.org/pdf/2012.13572" target="_blank">pdf</a>]

<h2>Robustness, Privacy, and Generalization of Adversarial Training. (arXiv:2012.13573v1 [cs.LG])</h2>
<h3>Fengxiang He, Shaopeng Fu, Bohan Wang, Dacheng Tao</h3>
<p>Adversarial training can considerably robustify deep neural networks to
resist adversarial attacks. However, some works suggested that adversarial
training might comprise the privacy-preserving and generalization abilities.
This paper establishes and quantifies the privacy-robustness trade-off and
generalization-robustness trade-off in adversarial training from both
theoretical and empirical aspects. We first define a notion, {\it robustified
intensity} to measure the robustness of an adversarial training algorithm. This
measure can be approximate empirically by an asymptotically consistent
empirical estimator, {\it empirical robustified intensity}. Based on the
robustified intensity, we prove that (1) adversarial training is $(\varepsilon,
\delta)$-differentially private, where the magnitude of the differential
privacy has a positive correlation with the robustified intensity; and (2) the
generalization error of adversarial training can be upper bounded by an
$\mathcal O(\sqrt{\log N}/N)$ on-average bound and an $\mathcal O(1/\sqrt{N})$
high-probability bound, both of which have positive correlations with the
robustified intensity. Additionally, our generalization bounds do not
explicitly rely on the parameter size which would be prohibitively large in
deep learning. Systematic experiments on standard datasets, CIFAR-10 and
CIFAR-100, are in full agreement with our theories. The source code package is
available at \url{https://github.com/fshp971/RPG}.
</p>
<a href="http://arxiv.org/abs/2012.13573" target="_blank">arXiv:2012.13573</a> [<a href="http://arxiv.org/pdf/2012.13573" target="_blank">pdf</a>]

<h2>Technical Report: Flushing Strategies in Drinking Water Systems. (arXiv:2012.13574v1 [cs.AI])</h2>
<h3>Margarita Rebolledo, Sowmya Chandrasekaran, Thomas Bartz-Beielstein</h3>
<p>Drinking water supply and distribution systems are critical infrastructure
that has to be well maintained for the safety of the public. One important tool
in the maintenance of water distribution systems (WDS) is flushing. Flushing is
a process carried out in a periodic fashion to clean sediments and other
contaminants in the water pipes. Given the different topographies, water
composition and supply demand between WDS no single flushing strategy is
suitable for all of them. In this report a non-exhaustive overview of
optimization methods for flushing in WDS is given. Implementation of
optimization methods for the flushing procedure and the flushing planing are
presented. Suggestions are given as a possible option to optimise existing
flushing planing frameworks.
</p>
<a href="http://arxiv.org/abs/2012.13574" target="_blank">arXiv:2012.13574</a> [<a href="http://arxiv.org/pdf/2012.13574" target="_blank">pdf</a>]

<h2>Revisiting Edge Detection in Convolutional Neural Networks. (arXiv:2012.13576v1 [cs.CV])</h2>
<h3>Minh Le, Subhradeep Kayal</h3>
<p>The ability to detect edges is a fundamental attribute necessary to truly
capture visual concepts. In this paper, we prove that edges cannot be
represented properly in the first convolutional layer of a neural network, and
further show that they are poorly captured in popular neural network
architectures such as VGG-16 and ResNet. The neural networks are found to rely
on color information, which might vary in unexpected ways outside of the
datasets used for their evaluation. To improve their robustness, we propose
edge-detection units and show that they reduce performance loss and generate
qualitatively different representations. By comparing various models, we show
that the robustness of edge detection is an important factor contributing to
the robustness of models against color noise.
</p>
<a href="http://arxiv.org/abs/2012.13576" target="_blank">arXiv:2012.13576</a> [<a href="http://arxiv.org/pdf/2012.13576" target="_blank">pdf</a>]

<h2>Three-dimensional Simultaneous Shape and Pose Estimation for Extended Objects Using Spherical Harmonics. (arXiv:2012.13580v1 [cs.RO])</h2>
<h3>Gerhard Kurz, Florian Faion, Florian Pfaff, Antonio Zea, Uwe D. Hanebeck</h3>
<p>We propose a new recursive method for simultaneous estimation of both the
pose and the shape of a three-dimensional extended object. The key idea of the
presented method is to represent the shape of the object using spherical
harmonics, similar to the way Fourier series can be used in the two-dimensional
case. This allows us to derive a measurement equation that can be used within
the framework of nonlinear filters such as the UKF. We provide both simulative
and experimental evaluations of the novel techniques.
</p>
<a href="http://arxiv.org/abs/2012.13580" target="_blank">arXiv:2012.13580</a> [<a href="http://arxiv.org/pdf/2012.13580" target="_blank">pdf</a>]

<h2>Camouflaged Object Detection and Tracking: A Survey. (arXiv:2012.13581v1 [cs.CV])</h2>
<h3>Ajoy Mondal</h3>
<p>Moving object detection and tracking have various applications, including
surveillance, anomaly detection, vehicle navigation, etc. The literature on
object detection and tracking is rich enough, and several essential survey
papers exist. However, the research on camouflage object detection and tracking
limited due to the complexity of the problem. Existing work on this problem has
been done based on either biological characteristics of the camouflaged objects
or computer vision techniques. In this article, we review the existing
camouflaged object detection and tracking techniques using computer vision
algorithms from the theoretical point of view. This article also addresses
several issues of interest as well as future research direction on this area.
We hope this review will help the reader to learn the recent advances in
camouflaged object detection and tracking.
</p>
<a href="http://arxiv.org/abs/2012.13581" target="_blank">arXiv:2012.13581</a> [<a href="http://arxiv.org/pdf/2012.13581" target="_blank">pdf</a>]

<h2>Real-Time Adaptive Velocity Optimization for Autonomous Electric Cars at the Limits of Handling. (arXiv:2012.13586v1 [cs.RO])</h2>
<h3>Thomas Herrmann, Alexander Wischnewski, Leonhard Hermansdorfer, Johannes Betz, Markus Lienkamp</h3>
<p>With the evolution of self-driving cars, autonomous racing series like
Roborace and the Indy Autonomous Challenge are rapidly attracting growing
attention. Researchers participating in these competitions hope to subsequently
transfer their developed functionality to passenger vehicles, in order to
improve self-driving technology for reasons of safety, and due to environmental
and social benefits. The race track has the advantage of being a safe
environment where challenging situations for the algorithms are permanently
created. To achieve minimum lap times on the race track, it is important to
gather and process information about external influences including, e.g., the
position of other cars and the friction potential between the road and the
tires. Furthermore, the predicted behavior of the ego-car's propulsion system
is crucial for leveraging the available energy as efficiently as possible. In
this paper, we therefore present an optimization-based velocity planner,
mathematically formulated as a multi-parametric Sequential Quadratic Problem
(mpSQP). This planner can handle a spatially and temporally varying friction
coefficient, and transfer a race Energy Strategy (ES) to the road. It further
handles the velocity-profile-generation task for performance and emergency
trajectories in real time on the vehicle's Electronic Control Unit (ECU).
</p>
<a href="http://arxiv.org/abs/2012.13586" target="_blank">arXiv:2012.13586</a> [<a href="http://arxiv.org/pdf/2012.13586" target="_blank">pdf</a>]

<h2>Inception Convolution with Efficient Dilation Search. (arXiv:2012.13587v1 [cs.CV])</h2>
<h3>Jie Liu, Chuming Li, Feng Liang, Chen Lin, Ming Sun, Junjie Yan, Wanli Ouyang, Dong Xu</h3>
<p>Dilation convolution is a critical mutant of standard convolution neural
network to control effective receptive fields and handle large scale variance
of objects without introducing additional computation. However, fitting the
effective reception field to data with dilated convolution is less discussed in
the literature. To fully explore its potentials, we proposed a new mutant of
dilated convolution, namely inception (dilated) convolution where the
convolutions have independent dilation among different axes, channels and
layers. To explore a practical method for fitting the complex inception
convolution to the data, a simple while effective dilation search
algorithm(EDO) based on statistical optimization is developed. The search
method operates in a zero-cost manner which is extremely fast to apply on large
scale datasets. Empirical results reveal that our method obtains consistent
performance gains in an extensive range of benchmarks. For instance, by simply
replace the 3 x 3 standard convolutions in ResNet-50 backbone with inception
convolution, we improve the mAP of Faster-RCNN on MS-COCO from 36.4% to 39.2%.
Furthermore, using the same replacement in ResNet-101 backbone, we achieve a
huge improvement over AP score from 60.2% to 68.5% on COCO val2017 for the
bottom up human pose estimation.
</p>
<a href="http://arxiv.org/abs/2012.13587" target="_blank">arXiv:2012.13587</a> [<a href="http://arxiv.org/pdf/2012.13587" target="_blank">pdf</a>]

<h2>DNS Typo-squatting Domain Detection: A Data Analytics & Machine Learning Based Approach. (arXiv:2012.13604v1 [cs.LG])</h2>
<h3>Abdallah Moubayed, MohammadNoor Injadat, Abdallah Shami, Hanan Lutfiyya</h3>
<p>Domain Name System (DNS) is a crucial component of current IP-based networks
as it is the standard mechanism for name to IP resolution. However, due to its
lack of data integrity and origin authentication processes, it is vulnerable to
a variety of attacks. One such attack is Typosquatting. Detecting this attack
is particularly important as it can be a threat to corporate secrets and can be
used to steal information or commit fraud. In this paper, a machine
learning-based approach is proposed to tackle the typosquatting vulnerability.
To that end, exploratory data analytics is first used to better understand the
trends observed in eight domain name-based extracted features. Furthermore, a
majority voting-based ensemble learning classifier built using five
classification algorithms is proposed that can detect suspicious domains with
high accuracy. Moreover, the observed trends are validated by studying the same
features in an unlabeled dataset using K-means clustering algorithm and through
applying the developed ensemble learning classifier. Results show that
legitimate domains have a smaller domain name length and fewer unique
characters. Moreover, the developed ensemble learning classifier performs
better in terms of accuracy, precision, and F-score. Furthermore, it is shown
that similar trends are observed when clustering is used. However, the number
of domains identified as potentially suspicious is high. Hence, the ensemble
learning classifier is applied with results showing that the number of domains
identified as potentially suspicious is reduced by almost a factor of five
while still maintaining the same trends in terms of features' statistics.
</p>
<a href="http://arxiv.org/abs/2012.13604" target="_blank">arXiv:2012.13604</a> [<a href="http://arxiv.org/pdf/2012.13604" target="_blank">pdf</a>]

<h2>RoCUS: Robot Controller Understanding via Sampling. (arXiv:2012.13615v1 [cs.RO])</h2>
<h3>Yilun Zhou, Serena Booth, Nadia Figueroa, Julie Shah</h3>
<p>As robots are deployed in complex situations, engineers and end users must
develop a holistic understanding of their capabilities and behaviors. Existing
research focuses mainly on factors related to task completion, such as success
rate, completion time, or total energy consumption. Other factors like
collision avoidance behavior, trajectory smoothness, and motion legibility are
equally or more important for safe and trustworthy deployment. While methods
exist to analyze these quality factors for individual trajectories or
distributions of trajectories, these statistics may be insufficient to develop
a mental model of the controller's behaviors, especially uncommon behaviors. We
present RoCUS: a Bayesian sampling-based method to find situations that lead to
trajectories which exhibit certain behaviors. By analyzing these situations and
trajectories, we can gain important insights into the controller that are
easily missed in standard task-completion evaluations. On a 2D navigation
problem and a 7 degree-of-freedom (DoF) arm reaching problem, we analyze three
controllers: a rapidly exploring random tree (RRT) planner, a dynamical system
(DS) formulation, and a deep imitation learning (IL) or reinforcement learning
(RL) model. We show how RoCUS can uncover insights to further our understanding
about them beyond task-completion aspects. The code is available at
https://github.com/YilunZhou/RoCUS.
</p>
<a href="http://arxiv.org/abs/2012.13615" target="_blank">arXiv:2012.13615</a> [<a href="http://arxiv.org/pdf/2012.13615" target="_blank">pdf</a>]

<h2>On self-supervised multi-modal representation learning: An application to Alzheimer's disease. (arXiv:2012.13619v1 [cs.LG])</h2>
<h3>Alex Fedorov, Lei Wu, Tristan Sylvain, Margaux Luck, Thomas P. DeRamus, Dmitry Bleklov, Sergey M. Plis, Vince D. Calhoun</h3>
<p>Introspection of deep supervised predictive models trained on functional and
structural brain imaging may uncover novel markers of Alzheimer's disease (AD).
However, supervised training is prone to learning from spurious features
(shortcut learning) impairing its value in the discovery process. Deep
unsupervised and, recently, contrastive self-supervised approaches, not biased
to classification, are better candidates for the task. Their multimodal options
specifically offer additional regularization via modality interactions. In this
paper, we introduce a way to exhaustively consider multimodal architectures for
contrastive self-supervised fusion of fMRI and MRI of AD patients and controls.
We show that this multimodal fusion results in representations that improve the
results of the downstream classification for both modalities. We investigate
the fused self-supervised features projected into the brain space and introduce
a numerically stable way to do so.
</p>
<a href="http://arxiv.org/abs/2012.13619" target="_blank">arXiv:2012.13619</a> [<a href="http://arxiv.org/pdf/2012.13619" target="_blank">pdf</a>]

<h2>Teaching Robots Novel Objects by Pointing at Them. (arXiv:2012.13620v1 [cs.RO])</h2>
<h3>Sagar Gubbi Venkatesh, Raviteja Upadrashta, Shishir Kolathaya, Bharadwaj Amrutur</h3>
<p>Robots that must operate in novel environments and collaborate with humans
must be capable of acquiring new knowledge from human experts during operation.
We propose teaching a robot novel objects it has not encountered before by
pointing a hand at the new object of interest. An end-to-end neural network is
used to attend to the novel object of interest indicated by the pointing hand
and then to localize the object in new scenes. In order to attend to the novel
object indicated by the pointing hand, we propose a spatial attention
modulation mechanism that learns to focus on the highlighted object while
ignoring the other objects in the scene. We show that a robot arm can
manipulate novel objects that are highlighted by pointing a hand at them. We
also evaluate the performance of the proposed architecture on a synthetic
dataset constructed using emojis and on a real-world dataset of common objects.
</p>
<a href="http://arxiv.org/abs/2012.13620" target="_blank">arXiv:2012.13620</a> [<a href="http://arxiv.org/pdf/2012.13620" target="_blank">pdf</a>]

<h2>Taxonomy of multimodal self-supervised representation learning. (arXiv:2012.13623v1 [cs.LG])</h2>
<h3>Alex Fedorov, Tristan Sylvain, Margaux Luck, Lei Wu, Thomas P. DeRamus, Alex Kirilin, Dmitry Bleklov, Sergey M. Plis, Vince D. Calhoun</h3>
<p>Sensory input from multiple sources is crucial for robust and coherent human
perception. Different sources contribute complementary explanatory factors and
get combined based on factors they share. This system motivated the design of
powerful unsupervised representation-learning algorithms. In this paper, we
unify recent work on multimodal self-supervised learning under a single
framework. Observing that most self-supervised methods optimize similarity
metrics between a set of model components, we propose a taxonomy of all
reasonable ways to organize this process. We empirically show on two versions
of multimodal MNIST and a multimodal brain imaging dataset that (1) multimodal
contrastive learning has significant benefits over its unimodal counterpart,
(2) the specific composition of multiple contrastive objectives is critical to
performance on a downstream task, (3) maximization of the similarity between
representations has a regularizing effect on a neural network, which sometimes
can lead to reduced downstream performance but still can reveal multimodal
relations. Consequently, we outperform previous unsupervised encoder-decoder
methods based on CCA or variational mixtures MMVAE on various datasets on
linear evaluation protocol.
</p>
<a href="http://arxiv.org/abs/2012.13623" target="_blank">arXiv:2012.13623</a> [<a href="http://arxiv.org/pdf/2012.13623" target="_blank">pdf</a>]

<h2>Detecting the patient's need for help with machine learning. (arXiv:2012.13626v1 [cs.LG])</h2>
<h3>Lauri Lahti</h3>
<p>Developing machine learning models to support health analytics requires
increased understanding about statistical properties of self-rated expression
statements. We analyzed self-rated expression statements concerning the
coronavirus COVID-19 epidemic to identify statistically significant differences
between groups of respondents and to detect the patient's need for help with
machine learning. Our quantitative study gathered the "need for help" ratings
for twenty health-related expression statements concerning the coronavirus
epidemic on a 11-point Likert scale, and nine answers about the person's health
and wellbeing, sex and age. Online respondents between 30 May and 3 August 2020
were recruited from Finnish patient and disabled people's organizations, other
health-related organizations and professionals, and educational institutions
(n=673). We analyzed rating differences and dependencies with Kendall
rank-correlation and cosine similarity measures and tests of Wilcoxon rank-sum,
Kruskal-Wallis and one-way analysis of variance (ANOVA) between groups, and
carried out machine learning experiments with a basic implementation of a
convolutional neural network algorithm. We found statistically significant
correlations and high cosine similarity values between various health-related
expression statement pairs concerning the "need for help" ratings and a
background question pair. We also identified statistically significant rating
differences for several health-related expression statements in respect to
groupings based on the answer values of background questions, such as the
ratings of suspecting to have the coronavirus infection and having it depending
on the estimated health condition, quality of life and sex. Our experiments
with a convolutional neural network algorithm showed the applicability of
machine learning to support detecting the need for help in the patient's
expressions.
</p>
<a href="http://arxiv.org/abs/2012.13626" target="_blank">arXiv:2012.13626</a> [<a href="http://arxiv.org/pdf/2012.13626" target="_blank">pdf</a>]

<h2>A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via Adversarial Fine-tuning. (arXiv:2012.13628v1 [cs.CV])</h2>
<h3>Ahmadreza Jeddi, Mohammad Javad Shafiee, Alexander Wong</h3>
<p>Adversarial Training (AT) with Projected Gradient Descent (PGD) is an
effective approach for improving the robustness of the deep neural networks.
However, PGD AT has been shown to suffer from two main limitations: i) high
computational cost, and ii) extreme overfitting during training that leads to
reduction in model generalization. While the effect of factors such as model
capacity and scale of training data on adversarial robustness have been
extensively studied, little attention has been paid to the effect of a very
important parameter in every network optimization on adversarial robustness:
the learning rate. In particular, we hypothesize that effective learning rate
scheduling during adversarial training can significantly reduce the overfitting
issue, to a degree where one does not even need to adversarially train a model
from scratch but can instead simply adversarially fine-tune a pre-trained
model. Motivated by this hypothesis, we propose a simple yet very effective
adversarial fine-tuning approach based on a $\textit{slow start, fast decay}$
learning rate scheduling strategy which not only significantly decreases
computational cost required, but also greatly improves the accuracy and
robustness of a deep neural network. Experimental results show that the
proposed adversarial fine-tuning approach outperforms the state-of-the-art
methods on CIFAR-10, CIFAR-100 and ImageNet datasets in both test accuracy and
the robustness, while reducing the computational cost by 8-10$\times$.
Furthermore, a very important benefit of the proposed adversarial fine-tuning
approach is that it enables the ability to improve the robustness of any
pre-trained deep neural network without needing to train the model from
scratch, which to the best of the authors' knowledge has not been previously
demonstrated in research literature.
</p>
<a href="http://arxiv.org/abs/2012.13628" target="_blank">arXiv:2012.13628</a> [<a href="http://arxiv.org/pdf/2012.13628" target="_blank">pdf</a>]

<h2>Adaptively Solving the Local-Minimum Problem for Deep Neural Networks. (arXiv:2012.13632v1 [cs.LG])</h2>
<h3>Huachuan Wang, James Ting-Ho Lo</h3>
<p>This paper aims to overcome a fundamental problem in the theory and
application of deep neural networks (DNNs). We propose a method to solve the
local minimum problem in training DNNs directly. Our method is based on the
cross-entropy loss criterion's convexification by transforming the
cross-entropy loss into a risk averting error (RAE) criterion. To alleviate
numerical difficulties, a normalized RAE (NRAE) is employed. The convexity
region of the cross-entropy loss expands as its risk sensitivity index (RSI)
increases. Making the best use of the convexity region, our method starts
training with an extensive RSI, gradually reduces it, and switches to the RAE
as soon as the RAE is numerically feasible. After training converges, the
resultant deep learning machine is expected to be inside the attraction basin
of a global minimum of the cross-entropy loss. Numerical results are provided
to show the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2012.13632" target="_blank">arXiv:2012.13632</a> [<a href="http://arxiv.org/pdf/2012.13632" target="_blank">pdf</a>]

<h2>Detecting Road Obstacles by Erasing Them. (arXiv:2012.13633v1 [cs.CV])</h2>
<h3>Krzysztof Lis, Sina Honari, Pascal Fua, Mathieu Salzmann</h3>
<p>Vehicles can encounter a myriad of obstacles on the road, and it is not
feasible to record them all beforehand to train a detector. Our method selects
image patches and inpaints them with the surrounding road texture, which tends
to remove obstacles from those patches. It them uses a network trained to
recognize discrepancies between the original patch and the inpainted one, which
signals an erased obstacle.

We also contribute a new dataset for monocular road obstacle detection, and
show that our approach outperforms the state-of-the-art methods on both our new
dataset and the standard Fishyscapes Lost &amp; Found benchmark.
</p>
<a href="http://arxiv.org/abs/2012.13633" target="_blank">arXiv:2012.13633</a> [<a href="http://arxiv.org/pdf/2012.13633" target="_blank">pdf</a>]

<h2>Logic Tensor Networks. (arXiv:2012.13635v1 [cs.AI])</h2>
<h3>Samy Badreddine, Artur d&#x27;Avila Garcez, Luciano Serafini, Michael Spranger</h3>
<p>Artificial Intelligence agents are required to learn from their surroundings
and to reason about the knowledge that has been learned in order to make
decisions. While state-of-the-art learning from data typically uses
sub-symbolic distributed representations, reasoning is normally useful at a
higher level of abstraction with the use of a first-order logic language for
knowledge representation. As a result, attempts at combining symbolic AI and
neural computation into neural-symbolic systems have been on the increase. In
this paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism
and computational model that supports learning and reasoning through the
introduction of a many-valued, end-to-end differentiable first-order logic
called Real Logic as a representation language for deep learning. We show that
LTN provides a uniform language for the specification and the computation of
several AI tasks such as data clustering, multi-label classification,
relational learning, query answering, semi-supervised learning, regression and
embedding learning. We implement and illustrate each of the above tasks with a
number of simple explanatory examples using TensorFlow 2. Keywords:
Neurosymbolic AI, Deep Learning and Reasoning, Many-valued Logic.
</p>
<a href="http://arxiv.org/abs/2012.13635" target="_blank">arXiv:2012.13635</a> [<a href="http://arxiv.org/pdf/2012.13635" target="_blank">pdf</a>]

<h2>Graph Convolutional Networks for traffic anomaly. (arXiv:2012.13637v1 [cs.LG])</h2>
<h3>Yue Hu, Ao Qu, Dan Work</h3>
<p>Event detection has been an important task in transportation, whose task is
to detect points in time when large events disrupts a large portion of the
urban traffic network. Travel information {Origin-Destination} (OD) matrix data
by map service vendors has large potential to give us insights to discover
historic patterns and distinguish anomalies. However, to fully capture the
spatial and temporal traffic patterns remains a challenge, yet serves a crucial
role for effective anomaly detection. Meanwhile, existing anomaly detection
methods have not well-addressed the extreme data sparsity and high-dimension
challenges, which are common in OD matrix datasets. To tackle these challenges,
we formulate the problem in a novel way, as detecting anomalies in a set of
directed weighted graphs representing the traffic conditions at each time
interval. We further propose \textit{Context augmented Graph Autoencoder}
(\textbf{Con-GAE }), that leverages graph embedding and context embedding
techniques to capture the spatial traffic network patterns while working around
the data sparsity and high-dimensionality issue. Con-GAE adopts an autoencoder
framework and detect anomalies via semi-supervised learning. Extensive
experiments show that our method can achieve up can achieve a 0.1-0.4
improvements of the area under the curve (AUC) score over state-of-art anomaly
detection baselines, when applied on several real-world large scale OD matrix
datasets.
</p>
<a href="http://arxiv.org/abs/2012.13637" target="_blank">arXiv:2012.13637</a> [<a href="http://arxiv.org/pdf/2012.13637" target="_blank">pdf</a>]

<h2>Locally Persistent Exploration in Continuous Control Tasks with Sparse Rewards. (arXiv:2012.13658v1 [cs.LG])</h2>
<h3>Susan Amin (1 and 2), Maziar Gomrokchi (1 and 2), Hossein Aboutalebi (3), Harsh Satija (1 and 2), Doina Precup (1 and 2) ((1) McGill University, (2) Mila- Quebec Artificial Intelligence Institute, (3) University of Waterloo)</h3>
<p>A major challenge in reinforcement learning is the design of exploration
strategies, especially for environments with sparse reward structures and
continuous state and action spaces. Intuitively, if the reinforcement signal is
very scarce, the agent should rely on some form of short-term memory in order
to cover its environment efficiently. We propose a new exploration method,
based on two intuitions: (1) the choice of the next exploratory action should
depend not only on the (Markovian) state of the environment, but also on the
agent's trajectory so far, and (2) the agent should utilize a measure of spread
in the state space to avoid getting stuck in a small region. Our method
leverages concepts often used in statistical physics to provide explanations
for the behavior of simplified (polymer) chains, in order to generate
persistent (locally self-avoiding) trajectories in state space. We discuss the
theoretical properties of locally self-avoiding walks, and their ability to
provide a kind of short-term memory, through a decaying temporal correlation
within the trajectory. We provide empirical evaluations of our approach in a
simulated 2D navigation task, as well as higher-dimensional MuJoCo continuous
control locomotion tasks with sparse rewards.
</p>
<a href="http://arxiv.org/abs/2012.13658" target="_blank">arXiv:2012.13658</a> [<a href="http://arxiv.org/pdf/2012.13658" target="_blank">pdf</a>]

<h2>Coarse to Fine: Multi-label Image Classification with Global/Local Attention. (arXiv:2012.13662v1 [cs.CV])</h2>
<h3>Fan Lyu, Fuyuan Hu, Victor S. Sheng, Zhengtian Wu, Qiming Fu, Baochuan Fu</h3>
<p>In our daily life, the scenes around us are always with multiple labels
especially in a smart city, i.e., recognizing the information of city operation
to response and control. Great efforts have been made by using Deep Neural
Networks to recognize multi-label images. Since multi-label image
classification is very complicated, people seek to use the attention mechanism
to guide the classification process. However, conventional attention-based
methods always analyzed images directly and aggressively. It is difficult for
them to well understand complicated scenes. In this paper, we propose a
global/local attention method that can recognize an image from coarse to fine
by mimicking how human-beings observe images. Specifically, our global/local
attention method first concentrates on the whole image, and then focuses on
local specific objects in the image. We also propose a joint max-margin
objective function, which enforces that the minimum score of positive labels
should be larger than the maximum score of negative labels horizontally and
vertically. This function can further improve our multi-label image
classification method. We evaluate the effectiveness of our method on two
popular multi-label image datasets (i.e., Pascal VOC and MS-COCO). Our
experimental results show that our method outperforms state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.13662" target="_blank">arXiv:2012.13662</a> [<a href="http://arxiv.org/pdf/2012.13662" target="_blank">pdf</a>]

<h2>PaXNet: Dental Caries Detection in Panoramic X-ray using Ensemble Transfer Learning and Capsule Classifier. (arXiv:2012.13666v1 [cs.CV])</h2>
<h3>Arman Haghanifar, Mahdiyar Molahasani Majdabadi, Seok-Bum Ko</h3>
<p>Dental caries is one of the most chronic diseases involving the majority of
the population during their lifetime. Caries lesions are typically diagnosed by
radiologists relying only on their visual inspection to detect via dental
x-rays. In many cases, dental caries is hard to identify using x-rays and can
be misinterpreted as shadows due to different reasons such as low image
quality. Hence, developing a decision support system for caries detection has
been a topic of interest in recent years. Here, we propose an automatic
diagnosis system to detect dental caries in Panoramic images for the first
time, to the best of authors' knowledge. The proposed model benefits from
various pretrained deep learning models through transfer learning to extract
relevant features from x-rays and uses a capsule network to draw prediction
results. On a dataset of 470 Panoramic images used for features extraction,
including 240 labeled images for classification, our model achieved an accuracy
score of 86.05\% on the test set. The obtained score demonstrates acceptable
detection performance and an increase in caries detection speed, as long as the
challenges of using Panoramic x-rays of real patients are taken into account.
Among images with caries lesions in the test set, our model acquired recall
scores of 69.44\% and 90.52\% for mild and severe ones, confirming the fact
that severe caries spots are more straightforward to detect and efficient mild
caries detection needs a more robust and larger dataset. Considering the
novelty of current research study as using Panoramic images, this work is a
step towards developing a fully automated efficient decision support system to
assist domain experts.
</p>
<a href="http://arxiv.org/abs/2012.13666" target="_blank">arXiv:2012.13666</a> [<a href="http://arxiv.org/pdf/2012.13666" target="_blank">pdf</a>]

<h2>Deep Learning Framework Applied for Predicting Anomaly of Respiratory Sounds. (arXiv:2012.13668v1 [cs.LG])</h2>
<h3>Dat Ngo, Lam Pham, Anh Nguyen, Ben Phan, Khoa Tran, Truong Nguyen</h3>
<p>This paper proposes a robust deep learning framework used for classifying
anomaly of respiratory cycles. Initially, our framework starts with front-end
feature extraction step. This step aims to transform the respiratory input
sound into a two-dimensional spectrogram where both spectral and temporal
features are well presented. Next, an ensemble of C- DNN and Autoencoder
networks is then applied to classify into four categories of respiratory
anomaly cycles. In this work, we conducted experiments over 2017 Internal
Conference on Biomedical Health Informatics (ICBHI) benchmark dataset. As a
result, we achieve competitive performances with ICBHI average score of 0.49,
ICBHI harmonic score of 0.42.
</p>
<a href="http://arxiv.org/abs/2012.13668" target="_blank">arXiv:2012.13668</a> [<a href="http://arxiv.org/pdf/2012.13668" target="_blank">pdf</a>]

<h2>Robust Collaborative Learning with Noisy Labels. (arXiv:2012.13670v1 [cs.LG])</h2>
<h3>Mengying Sun, Jing Xing, Bin Chen, Jiayu Zhou</h3>
<p>Learning with curriculum has shown great effectiveness in tasks where the
data contains noisy (corrupted) labels, since the curriculum can be used to
re-weight or filter out noisy samples via proper design. However, obtaining
curriculum from a learner itself without additional supervision or feedback
deteriorates the effectiveness due to sample selection bias. Therefore, methods
that involve two or more networks have been recently proposed to mitigate such
bias. Nevertheless, these studies utilize the collaboration between networks in
a way that either emphasizes the disagreement or focuses on the agreement while
ignores the other. In this paper, we study the underlying mechanism of how
disagreement and agreement between networks can help reduce the noise in
gradients and develop a novel framework called Robust Collaborative Learning
(RCL) that leverages both disagreement and agreement among networks. We
demonstrate the effectiveness of RCL on both synthetic benchmark image data and
real-world large-scale bioinformatics data.
</p>
<a href="http://arxiv.org/abs/2012.13670" target="_blank">arXiv:2012.13670</a> [<a href="http://arxiv.org/pdf/2012.13670" target="_blank">pdf</a>]

<h2>Multidimensional Uncertainty-Aware Evidential Neural Networks. (arXiv:2012.13676v1 [cs.LG])</h2>
<h3>Yibo Hu, Yuzhe Ou, Xujiang Zhao, Jin-Hee Cho, Feng Chen</h3>
<p>Traditional deep neural networks (NNs) have significantly contributed to the
state-of-the-art performance in the task of classification under various
application domains. However, NNs have not considered inherent uncertainty in
data associated with the class probabilities where misclassification under
uncertainty may easily introduce high risk in decision making in real-world
contexts (e.g., misclassification of objects in roads leads to serious
accidents). Unlike Bayesian NN that indirectly infer uncertainty through weight
uncertainties, evidential NNs (ENNs) have been recently proposed to explicitly
model the uncertainty of class probabilities and use them for classification
tasks. An ENN offers the formulation of the predictions of NNs as subjective
opinions and learns the function by collecting an amount of evidence that can
form the subjective opinions by a deterministic NN from data. However, the ENN
is trained as a black box without explicitly considering inherent uncertainty
in data with their different root causes, such as vacuity (i.e., uncertainty
due to a lack of evidence) or dissonance (i.e., uncertainty due to conflicting
evidence). By considering the multidimensional uncertainty, we proposed a novel
uncertainty-aware evidential NN called WGAN-ENN (WENN) for solving an
out-of-distribution (OOD) detection problem. We took a hybrid approach that
combines Wasserstein Generative Adversarial Network (WGAN) with ENNs to jointly
train a model with prior knowledge of a certain class, which has high vacuity
for OOD samples. Via extensive empirical experiments based on both synthetic
and real-world datasets, we demonstrated that the estimation of uncertainty by
WENN can significantly help distinguish OOD samples from boundary samples. WENN
outperformed in OOD detection when compared with other competitive
counterparts.
</p>
<a href="http://arxiv.org/abs/2012.13676" target="_blank">arXiv:2012.13676</a> [<a href="http://arxiv.org/pdf/2012.13676" target="_blank">pdf</a>]

<h2>Improving the Generalization of End-to-End Driving through Procedural Generation. (arXiv:2012.13681v1 [cs.RO])</h2>
<h3>Quanyi Li, Zhenghao Peng, Qihang Zhang, Cong Qiu, Chunxiao Liu, Bolei Zhou</h3>
<p>Recently there is a growing interest in the end-to-end training of autonomous
driving where the entire driving pipeline from perception to control is modeled
as a neural network and jointly optimized. The end-to-end driving is usually
first developed and validated in simulators. However, most of the existing
driving simulators only contain a fixed set of maps and a limited number of
configurations. As a result the deep models are prone to overfitting training
scenarios. Furthermore it is difficult to assess how well the trained models
generalize to unseen scenarios. To better evaluate and improve the
generalization of end-to-end driving, we introduce an open-ended and highly
configurable driving simulator called PGDrive. PGDrive first defines multiple
basic road blocks such as ramp, fork, and roundabout with configurable
settings. Then a range of diverse maps can be assembled from those blocks with
procedural generation, which are further turned into interactive environments.
The experiments show that the driving agent trained by reinforcement learning
on a small fixed set of maps generalizes poorly to unseen maps. We further
validate that training with the increasing number of procedurally generated
maps significantly improves the generalization of the agent across scenarios of
different traffic densities and map structures. Code is available at:
https://decisionforce.github.io/pgdrive
</p>
<a href="http://arxiv.org/abs/2012.13681" target="_blank">arXiv:2012.13681</a> [<a href="http://arxiv.org/pdf/2012.13681" target="_blank">pdf</a>]

<h2>POPO: Pessimistic Offline Policy Optimization. (arXiv:2012.13682v1 [cs.LG])</h2>
<h3>Qiang He. Xinwen Hou</h3>
<p>Offline reinforcement learning (RL), also known as batch RL, aims to optimize
policy from a large pre-recorded dataset without interaction with the
environment. This setting offers the promise of utilizing diverse,
pre-collected datasets to obtain policies without costly, risky, active
exploration. However, commonly used off-policy algorithms based on Q-learning
or actor-critic perform poorly when learning from a static dataset. In this
work, we study why off-policy RL methods fail to learn in offline setting from
the value function view, and we propose a novel offline RL algorithm that we
call Pessimistic Offline Policy Optimization (POPO), which learns a pessimistic
value function to get a strong policy. We find that POPO performs surprisingly
well and scales to tasks with high-dimensional state and action space,
comparing or outperforming several state-of-the-art offline RL algorithms on
benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2012.13682" target="_blank">arXiv:2012.13682</a> [<a href="http://arxiv.org/pdf/2012.13682" target="_blank">pdf</a>]

<h2>Dual-Refinement: Joint Label and Feature Refinement for Unsupervised Domain Adaptive Person Re-Identification. (arXiv:2012.13689v1 [cs.CV])</h2>
<h3>Yongxing Dai, Jun Liu, Yan Bai, Zekun Tong, Ling-Yu Duan</h3>
<p>Unsupervised domain adaptive (UDA) person re-identification (re-ID) is a
challenging task due to the missing of labels for the target domain data. To
handle this problem, some recent works adopt clustering algorithms to off-line
generate pseudo labels, which can then be used as the supervision signal for
on-line feature learning in the target domain. However, the off-line generated
labels often contain lots of noise that significantly hinders the
discriminability of the on-line learned features, and thus limits the final UDA
re-ID performance. To this end, we propose a novel approach, called
Dual-Refinement, that jointly refines pseudo labels at the off-line clustering
phase and features at the on-line training phase, to alternatively boost the
label purity and feature discriminability in the target domain for more
reliable re-ID. Specifically, at the off-line phase, a new hierarchical
clustering scheme is proposed, which selects representative prototypes for
every coarse cluster. Thus, labels can be effectively refined by using the
inherent hierarchical information of person images. Besides, at the on-line
phase, we propose an instant memory spread-out (IM-spread-out) regularization,
that takes advantage of the proposed instant memory bank to store sample
features of the entire dataset and enable spread-out feature learning over the
entire training data instantly. Our Dual-Refinement method reduces the
influence of noisy labels and refines the learned features within the
alternative training process. Experiments demonstrate that our method
outperforms the state-of-the-art methods by a large margin.
</p>
<a href="http://arxiv.org/abs/2012.13689" target="_blank">arXiv:2012.13689</a> [<a href="http://arxiv.org/pdf/2012.13689" target="_blank">pdf</a>]

<h2>One-Shot Object Localization Using Learnt Visual Cues via Siamese Networks. (arXiv:2012.13690v1 [cs.CV])</h2>
<h3>Sagar Gubbi Venkatesh, Bharadwaj Amrutur</h3>
<p>A robot that can operate in novel and unstructured environments must be
capable of recognizing new, previously unseen, objects. In this work, a visual
cue is used to specify a novel object of interest which must be localized in
new environments. An end-to-end neural network equipped with a Siamese network
is used to learn the cue, infer the object of interest, and then to localize it
in new environments. We show that a simulated robot can pick-and-place novel
objects pointed to by a laser pointer. We also evaluate the performance of the
proposed approach on a dataset derived from the Omniglot handwritten character
dataset and on a small dataset of toys.
</p>
<a href="http://arxiv.org/abs/2012.13690" target="_blank">arXiv:2012.13690</a> [<a href="http://arxiv.org/pdf/2012.13690" target="_blank">pdf</a>]

<h2>Sparse Adversarial Attack to Object Detection. (arXiv:2012.13692v1 [cs.CV])</h2>
<h3>Jiayu Bao</h3>
<p>Adversarial examples have gained tons of attention in recent years. Many
adversarial attacks have been proposed to attack image classifiers, but few
work shift attention to object detectors. In this paper, we propose Sparse
Adversarial Attack (SAA) which enables adversaries to perform effective evasion
attack on detectors with bounded \emph{l$_{0}$} norm perturbation. We select
the fragile position of the image and designed evasion loss function for the
task. Experiment results on YOLOv4 and FasterRCNN reveal the effectiveness of
our method. In addition, our SAA shows great transferability across different
detectors in the black-box attack setting. Codes are available at
\emph{https://github.com/THUrssq/Tianchi04}.
</p>
<a href="http://arxiv.org/abs/2012.13692" target="_blank">arXiv:2012.13692</a> [<a href="http://arxiv.org/pdf/2012.13692" target="_blank">pdf</a>]

<h2>Spatial Reasoning from Natural Language Instructions for Robot Manipulation. (arXiv:2012.13693v1 [cs.RO])</h2>
<h3>Sagar Gubbi Venkatesh, Anirban Biswas, Raviteja Upadrashta, Vikram Srinivasan, Partha Talukdar, Bharadwaj Amrutur</h3>
<p>Robots that can manipulate objects in unstructured environments and
collaborate with humans can benefit immensely by understanding natural
language. We propose a pipelined architecture of two stages to perform spatial
reasoning on the text input. All the objects in the scene are first localized,
and then the instruction for the robot in natural language and the localized
co-ordinates are mapped to the start and end co-ordinates corresponding to the
locations where the robot must pick up and place the object respectively. We
show that representing the localized objects by quantizing their positions to a
binary grid is preferable to representing them as a list of 2D co-ordinates. We
also show that attention improves generalization and can overcome biases in the
dataset. The proposed method is used to pick-and-place playing cards using a
robot arm.
</p>
<a href="http://arxiv.org/abs/2012.13693" target="_blank">arXiv:2012.13693</a> [<a href="http://arxiv.org/pdf/2012.13693" target="_blank">pdf</a>]

<h2>Translating Natural Language Instructions to Computer Programs for Robot Manipulation. (arXiv:2012.13695v1 [cs.RO])</h2>
<h3>Sagar Gubbi Venkatesh, Raviteja Upadrashta, Bharadwaj Amrutur</h3>
<p>It is highly desirable for robots that work alongside humans to be able to
understand instructions in natural language. Existing language conditioned
imitation learning methods predict the actuator commands from the image
observation and the instruction text. Rather than directly predicting actuator
commands, we propose translating the natural language instruction to a Python
function which when executed queries the scene by accessing the output of the
object detector and controls the robot to perform the specified task. This
enables the use of non-differentiable modules such as a constraint solver when
computing commands to the robot. Moreover, the labels in this setup are
significantly more descriptive computer programs rather than teleoperated
demonstrations. We show that the proposed method performs better than training
a neural network to directly predict the robot actions.
</p>
<a href="http://arxiv.org/abs/2012.13695" target="_blank">arXiv:2012.13695</a> [<a href="http://arxiv.org/pdf/2012.13695" target="_blank">pdf</a>]

<h2>TSGCNet: Discriminative Geometric Feature Learning with Two-Stream GraphConvolutional Network for 3D Dental Model Segmentation. (arXiv:2012.13697v1 [cs.CV])</h2>
<h3>Lingming Zhang, Yue Zhao, Deyu Meng, Zhiming Cui, Chenqiang Gao, Xinbo Gao, Chunfeng Lian, Dinggang Shen</h3>
<p>The ability to segment teeth precisely from digitized 3D dental models is an
essential task in computer-aided orthodontic surgical planning. To date, deep
learning based methods have been popularly used to handle this task.
State-of-the-art methods directly concatenate the raw attributes of 3D inputs,
namely coordinates and normal vectors of mesh cells, to train a single-stream
network for fully-automated tooth segmentation. This, however, has the drawback
of ignoring the different geometric meanings provided by those raw attributes.
This issue might possibly confuse the network in learning discriminative
geometric features and result in many isolated false predictions on the dental
model. Against this issue, we propose a two-stream graph convolutional network
(TSGCNet) to learn multi-view geometric information from different geometric
attributes. Our TSGCNet adopts two graph-learning streams, designed in an
input-aware fashion, to extract more discriminative high-level geometric
representations from coordinates and normal vectors, respectively. These
feature representations learned from the designed two different streams are
further fused to integrate the multi-view complementary information for the
cell-wise dense prediction task. We evaluate our proposed TSGCNet on a
real-patient dataset of dental models acquired by 3D intraoral scanners, and
experimental results demonstrate that our method significantly outperforms
state-of-the-art methods for 3D shape segmentation.
</p>
<a href="http://arxiv.org/abs/2012.13697" target="_blank">arXiv:2012.13697</a> [<a href="http://arxiv.org/pdf/2012.13697" target="_blank">pdf</a>]

<h2>2-D Respiration Navigation Framework for 3-D Continuous Cardiac Magnetic Resonance Imaging. (arXiv:2012.13700v1 [cs.CV])</h2>
<h3>Elisabeth Hoppe, Jens Wetzl, Philipp Roser, Lina Felsner, Alexander Preuhs, Andreas Maier</h3>
<p>Continuous protocols for cardiac magnetic resonance imaging enable sampling
of the cardiac anatomy simultaneously resolved into cardiac phases. To avoid
respiration artifacts, associated motion during the scan has to be compensated
for during reconstruction. In this paper, we propose a sampling adaption to
acquire 2-D respiration information during a continuous scan. Further, we
develop a pipeline to extract the different respiration states from the
acquired signals, which are used to reconstruct data from one respiration
phase. Our results show the benefit of the proposed workflow on the image
quality compared to no respiration compensation, as well as a previous 1-D
respiration navigation approach.
</p>
<a href="http://arxiv.org/abs/2012.13700" target="_blank">arXiv:2012.13700</a> [<a href="http://arxiv.org/pdf/2012.13700" target="_blank">pdf</a>]

<h2>Hybrid and Non-Uniform quantization methods using retro synthesis data for efficient inference. (arXiv:2012.13716v1 [cs.CV])</h2>
<h3>Tej pratap GVSL, Raja Kumar</h3>
<p>Existing quantization aware training methods attempt to compensate for the
quantization loss by leveraging on training data, like most of the
post-training quantization methods, and are also time consuming. Both these
methods are not effective for privacy constraint applications as they are
tightly coupled with training data. In contrast, this paper proposes a
data-independent post-training quantization scheme that eliminates the need for
training data. This is achieved by generating a faux dataset, hereafter
referred to as Retro-Synthesis Data, from the FP32 model layer statistics and
further using it for quantization. This approach outperformed state-of-the-art
methods including, but not limited to, ZeroQ and DFQ on models with and without
Batch-Normalization layers for 8, 6, and 4 bit precisions on ImageNet and
CIFAR-10 datasets. We also introduced two futuristic variants of post-training
quantization methods namely Hybrid Quantization and Non-Uniform Quantization
</p>
<a href="http://arxiv.org/abs/2012.13716" target="_blank">arXiv:2012.13716</a> [<a href="http://arxiv.org/pdf/2012.13716" target="_blank">pdf</a>]

<h2>Ranking and Rejecting of Pre-Trained Deep Neural Networks in Transfer Learning based on Separation Index. (arXiv:2012.13717v1 [cs.LG])</h2>
<h3>Mostafa Kalhor, Ahmad Kalhor, Mehdi Rahmani</h3>
<p>Automated ranking of pre-trained Deep Neural Networks (DNNs) reduces the
required time for selecting optimal pre-trained DNN and boost the
classification performance in transfer learning. In this paper, we introduce a
novel algorithm to rank pre-trained DNNs by applying a straightforward
distance-based complexity measure named Separation Index (SI) to the target
dataset. For this purpose, at first, a background about the SI is given and
then the automated ranking algorithm is explained. In this algorithm, the SI is
computed for the target dataset which passes from the feature extracting parts
of pre-trained DNNs. Then, by descending sort of the computed SIs, the
pre-trained DNNs are ranked, easily. In this ranking method, the best DNN makes
maximum SI on the target dataset and a few pre-trained DNNs may be rejected in
the case of their sufficiently low computed SIs. The efficiency of the proposed
algorithm is evaluated by using three challenging datasets including Linnaeus
5, Breast Cancer Images, and COVID-CT. For the two first case studies, the
results of the proposed algorithm exactly match with the ranking of the trained
DNNs by the accuracy on the target dataset. For the third case study, despite
using different preprocessing on the target data, the ranking of the algorithm
has a high correlation with the ranking resulted from classification accuracy.
</p>
<a href="http://arxiv.org/abs/2012.13717" target="_blank">arXiv:2012.13717</a> [<a href="http://arxiv.org/pdf/2012.13717" target="_blank">pdf</a>]

<h2>Learning Inter- and Intra-frame Representations for Non-Lambertian Photometric Stereo. (arXiv:2012.13720v1 [cs.CV])</h2>
<h3>Yanlong Cao, Binjie Ding, Zewei He, Jiangxin Yang, Jingxi Chen, Yanpeng Cao, Xin Li</h3>
<p>In this paper, we build a two-stage Convolutional Neural Network (CNN)
architecture to construct inter- and intra-frame representations based on an
arbitrary number of images captured under different light directions,
performing accurate normal estimation of non-Lambertian objects. We
experimentally investigate numerous network design alternatives for identifying
the optimal scheme to deploy inter-frame and intra-frame feature extraction
modules for the photometric stereo problem. Moreover, we propose to utilize the
easily obtained object mask for eliminating adverse interference from invalid
background regions in intra-frame spatial convolutions, thus effectively
improve the accuracy of normal estimation for surfaces made of dark materials
or with cast shadows. Experimental results demonstrate that proposed masked
two-stage photometric stereo CNN model (MT-PS-CNN) performs favorably against
state-of-the-art photometric stereo techniques in terms of both accuracy and
efficiency. In addition, the proposed method is capable of predicting accurate
and rich surface normal details for non-Lambertian objects of complex geometry
and performs stably given inputs captured in both sparse and dense lighting
distributions.
</p>
<a href="http://arxiv.org/abs/2012.13720" target="_blank">arXiv:2012.13720</a> [<a href="http://arxiv.org/pdf/2012.13720" target="_blank">pdf</a>]

<h2>Assigning Apples to Individual Trees in Dense Orchards using 3D Color Point Clouds. (arXiv:2012.13721v1 [cs.CV])</h2>
<h3>Mouad Zine-El-Abidine, Helin Dutagaci, Gilles Galopin, David Rousseau</h3>
<p>We propose a 3D color point cloud processing pipeline to count apples on
individual apple trees in trellis structured orchards. Fruit counting at the
tree level requires separating trees, which is challenging in dense orchards.
We employ point clouds acquired from the leaf-off orchard in winter period,
where the branch structure is visible, to delineate tree crowns. We localize
apples in point clouds acquired in harvest period. Alignment of the two point
clouds enables mapping apple locations to the delineated winter cloud and
assigning each apple to its bearing tree. Our apple assignment method achieves
an accuracy rate higher than 95%. In addition to presenting a first proof of
feasibility, we also provide suggestions for further improvement on our apple
assignment pipeline.
</p>
<a href="http://arxiv.org/abs/2012.13721" target="_blank">arXiv:2012.13721</a> [<a href="http://arxiv.org/pdf/2012.13721" target="_blank">pdf</a>]

<h2>Faster and Accurate Compressed Video Action Recognition Straight from the Frequency Domain. (arXiv:2012.13726v1 [cs.CV])</h2>
<h3>Samuel Felipe dos Santos, Jurandy Almeida</h3>
<p>Human action recognition has become one of the most active field of research
in computer vision due to its wide range of applications, like surveillance,
medical, industrial environments, smart homes, among others. Recently, deep
learning has been successfully used to learn powerful and interpretable
features for recognizing human actions in videos. Most of the existing deep
learning approaches have been designed for processing video information as RGB
image sequences. For this reason, a preliminary decoding process is required,
since video data are often stored in a compressed format. However, a high
computational load and memory usage is demanded for decoding a video. To
overcome this problem, we propose a deep neural network capable of learning
straight from compressed video. Our approach was evaluated on two public
benchmarks, the UCF-101 and HMDB-51 datasets, demonstrating comparable
recognition performance to the state-of-the-art methods, with the advantage of
running up to 2 times faster in terms of inference speed.
</p>
<a href="http://arxiv.org/abs/2012.13726" target="_blank">arXiv:2012.13726</a> [<a href="http://arxiv.org/pdf/2012.13726" target="_blank">pdf</a>]

<h2>Image Synthesis with Adversarial Networks: a Comprehensive Survey and Case Studies. (arXiv:2012.13736v1 [cs.CV])</h2>
<h3>Pourya Shamsolmoali, Masoumeh Zareapoor, Eric Granger, Huiyu Zhou, Ruili Wang, M. Emre Celebi, Jie Yang</h3>
<p>Generative Adversarial Networks (GANs) have been extremely successful in
various application domains such as computer vision, medicine, and natural
language processing. Moreover, transforming an object or person to a desired
shape become a well-studied research in the GANs. GANs are powerful models for
learning complex distributions to synthesize semantically meaningful samples.
However, there is a lack of comprehensive review in this field, especially lack
of a collection of GANs loss-variant, evaluation metrics, remedies for diverse
image generation, and stable training. Given the current fast GANs development,
in this survey, we provide a comprehensive review of adversarial models for
image synthesis. We summarize the synthetic image generation methods, and
discuss the categories including image-to-image translation, fusion image
generation, label-to-image mapping, and text-to-image translation. We organize
the literature based on their base models, developed ideas related to
architectures, constraints, loss functions, evaluation metrics, and training
datasets. We present milestones of adversarial models, review an extensive
selection of previous works in various categories, and present insights on the
development route from the model-based to data-driven methods. Further, we
highlight a range of potential future research directions. One of the unique
features of this review is that all software implementations of these GAN
methods and datasets have been collected and made available in one place at
https://github.com/pshams55/GAN-Case-Study.
</p>
<a href="http://arxiv.org/abs/2012.13736" target="_blank">arXiv:2012.13736</a> [<a href="http://arxiv.org/pdf/2012.13736" target="_blank">pdf</a>]

<h2>Stability-Certified Reinforcement Learning via Spectral Normalization. (arXiv:2012.13744v1 [cs.AI])</h2>
<h3>Ryoichi Takase, Nobuyuki Yoshikawa, Toshisada Mariyama, Takeshi Tsuchiya</h3>
<p>In this article, two types of methods from different perspectives based on
spectral normalization are described for ensuring the stability of the system
controlled by a neural network. The first one is that the L2 gain of the
feedback system is bounded less than 1 to satisfy the stability condition
derived from the small-gain theorem. While explicitly including the stability
condition, the first method may provide an insufficient performance on the
neural network controller due to its strict stability condition. To overcome
this difficulty, the second one is proposed, which improves the performance
while ensuring the local stability with a larger region of attraction. In the
second method, the stability is ensured by solving linear matrix inequalities
after training the neural network controller. The spectral normalization
proposed in this article improves the feasibility of the a-posteriori stability
test by constructing tighter local sectors. The numerical experiments show that
the second method provides enough performance compared with the first one while
ensuring enough stability compared with the existing reinforcement learning
algorithms.
</p>
<a href="http://arxiv.org/abs/2012.13744" target="_blank">arXiv:2012.13744</a> [<a href="http://arxiv.org/pdf/2012.13744" target="_blank">pdf</a>]

<h2>Few Shot Learning With No Labels. (arXiv:2012.13751v1 [cs.CV])</h2>
<h3>Aditya Bharti, N.B. Vineeth, C.V. Jawahar</h3>
<p>Few-shot learners aim to recognize new categories given only a small number
of training samples. The core challenge is to avoid overfitting to the limited
data while ensuring good generalization to novel classes. Existing literature
makes use of vast amounts of annotated data by simply shifting the label
requirement from novel classes to base classes. Since data annotation is
time-consuming and costly, reducing the label requirement even further is an
important goal. To that end, our paper presents a more challenging few-shot
setting where no label access is allowed during training or testing. By
leveraging self-supervision for learning image representations and image
similarity for classification at test time, we achieve competitive baselines
while using \textbf{zero} labels, which is at least fewer labels than
state-of-the-art. We hope that this work is a step towards developing few-shot
learning methods which do not depend on annotated data at all. Our code will be
publicly released.
</p>
<a href="http://arxiv.org/abs/2012.13751" target="_blank">arXiv:2012.13751</a> [<a href="http://arxiv.org/pdf/2012.13751" target="_blank">pdf</a>]

<h2>Probabilistic 3D Multi-Modal, Multi-Object Tracking for Autonomous Driving. (arXiv:2012.13755v1 [cs.CV])</h2>
<h3>Hsu-kuang Chiu, Jie Li, Rares Ambrus, Jeannette Bohg</h3>
<p>Multi-object tracking is an important ability for an autonomous vehicle to
safely navigate a traffic scene. Current state-of-the-art follows the
tracking-by-detection paradigm where existing tracks are associated with
detected objects through some distance metric. The key challenges to increase
tracking accuracy lie in data association and track life cycle management. We
propose a probabilistic, multi-modal, multi-object tracking system consisting
of different trainable modules to provide robust and data-driven tracking
results. First, we learn how to fuse features from 2D images and 3D LiDAR point
clouds to capture the appearance and geometric information of an object.
Second, we propose to learn a metric that combines the Mahalanobis and feature
distances when comparing a track and a new detection in data association. And
third, we propose to learn when to initialize a track from an unmatched object
detection. Through extensive quantitative and qualitative results, we show that
our method outperforms current state-of-the-art on the NuScenes Tracking
dataset.
</p>
<a href="http://arxiv.org/abs/2012.13755" target="_blank">arXiv:2012.13755</a> [<a href="http://arxiv.org/pdf/2012.13755" target="_blank">pdf</a>]

<h2>Variance Reduction on Adaptive Stochastic Mirror Descent. (arXiv:2012.13760v1 [stat.ML])</h2>
<h3>Wenjie Li, Zhanyu Wang, Yichen Zhang, Guang Cheng</h3>
<p>We study the idea of variance reduction applied to adaptive stochastic mirror
descent algorithms in nonsmooth nonconvex finite-sum optimization problems. We
propose a simple yet generalized adaptive mirror descent algorithm with
variance reduction named SVRAMD and provide its convergence analysis in
different settings. We prove that variance reduction reduces the gradient
complexity of most adaptive mirror descent algorithms and boost their
convergence. In particular, our general theory implies variance reduction can
be applied to algorithms using time-varying step sizes and self-adaptive
algorithms such as AdaGrad and RMSProp. Moreover, our convergence rates recover
the best existing rates of non-adaptive algorithms. We check the validity of
our claims using experiments in deep learning.
</p>
<a href="http://arxiv.org/abs/2012.13760" target="_blank">arXiv:2012.13760</a> [<a href="http://arxiv.org/pdf/2012.13760" target="_blank">pdf</a>]

<h2>Direct Quantization for Training Highly Accurate Low Bit-width Deep Neural Networks. (arXiv:2012.13762v1 [cs.CV])</h2>
<h3>Tuan Hoang, Thanh-Toan Do, Tam V. Nguyen, Ngai-Man Cheung</h3>
<p>This paper proposes two novel techniques to train deep convolutional neural
networks with low bit-width weights and activations. First, to obtain low
bit-width weights, most existing methods obtain the quantized weights by
performing quantization on the full-precision network weights. However, this
approach would result in some mismatch: the gradient descent updates
full-precision weights, but it does not update the quantized weights. To
address this issue, we propose a novel method that enables {direct} updating of
quantized weights {with learnable quantization levels} to minimize the cost
function using gradient descent. Second, to obtain low bit-width activations,
existing works consider all channels equally. However, the activation
quantizers could be biased toward a few channels with high-variance. To address
this issue, we propose a method to take into account the quantization errors of
individual channels. With this approach, we can learn activation quantizers
that minimize the quantization errors in the majority of channels. Experimental
results demonstrate that our proposed method achieves state-of-the-art
performance on the image classification task, using AlexNet, ResNet and
MobileNetV2 architectures on CIFAR-100 and ImageNet datasets.
</p>
<a href="http://arxiv.org/abs/2012.13762" target="_blank">arXiv:2012.13762</a> [<a href="http://arxiv.org/pdf/2012.13762" target="_blank">pdf</a>]

<h2>Balance-Oriented Focal Loss with Linear Scheduling for Anchor Free Object Detection. (arXiv:2012.13763v1 [cs.CV])</h2>
<h3>Hopyong Gil, Sangwoo Park, Yusang Park, Wongoo Han, Juyean Hong, Juneyoung Jung</h3>
<p>Most existing object detectors suffer from class imbalance problems that
hinder balanced performance. In particular, anchor free object detectors have
to solve the background imbalance problem due to detection in a per-pixel
prediction fashion as well as foreground imbalance problem simultaneously. In
this work, we propose Balance-oriented focal loss that can induce balanced
learning by considering both background and foreground balance comprehensively.
This work aims to address imbalance problem in the situation of using a general
unbalanced data of non-extreme distribution not including few shot and the
focal loss for anchor free object detector. We use a batch-wise alpha-balanced
variant of the focal loss to deal with this imbalance problem elaborately. It
is a simple and practical solution using only re-weighting for general
unbalanced data. It does require neither additional learning cost nor
structural change during inference and grouping classes is also unnecessary.
Through extensive experiments, we show the performance improvement for each
component and analyze the effect of linear scheduling when using re-weighting
for the loss. By improving the focal loss in terms of balancing foreground
classes, our method achieves AP gains of +1.2 in MS-COCO for the anchor free
real-time detector.
</p>
<a href="http://arxiv.org/abs/2012.13763" target="_blank">arXiv:2012.13763</a> [<a href="http://arxiv.org/pdf/2012.13763" target="_blank">pdf</a>]

<h2>An Affine moment invariant for multi-component shapes. (arXiv:2012.13774v1 [cs.CV])</h2>
<h3>Jovisa Zunic, Milos Stojmenovic</h3>
<p>We introduce an image based algorithmic tool for analyzing multi-component
shapes here. Due to the generic concept of multi-component shapes, our method
can be applied to the analysis of a wide spectrum of applications where real
objects are analyzed based on their shapes - i.e. on their corresponded black
and white images. The method allocates a number to a shape, herein called a
multi-component shapes measure. This number/measure is invariant with respect
to affine transformations and is established based on the theoretical frame
developed in this paper. In addition, the method is easy to implement and is
robust (e.g. with respect to noise). We provide two small but illustrative
examples related to aerial image analysis and galaxy image analysis. Also, we
provide some synthetic examples for a better understanding of the measure
behavior.
</p>
<a href="http://arxiv.org/abs/2012.13774" target="_blank">arXiv:2012.13774</a> [<a href="http://arxiv.org/pdf/2012.13774" target="_blank">pdf</a>]

<h2>Towards sample-efficient episodic control with DAC-ML. (arXiv:2012.13779v1 [cs.AI])</h2>
<h3>Ismael T. Freire, Adri&#xe1;n F. Amil, Vasiliki Vouloutsi, Paul F.M.J. Verschure</h3>
<p>The sample-inefficiency problem in Artificial Intelligence refers to the
inability of current Deep Reinforcement Learning models to optimize action
policies within a small number of episodes. Recent studies have tried to
overcome this limitation by adding memory systems and architectural biases to
improve learning speed, such as in Episodic Reinforcement Learning. However,
despite achieving incremental improvements, their performance is still not
comparable to how humans learn behavioral policies. In this paper, we
capitalize on the design principles of the Distributed Adaptive Control (DAC)
theory of mind and brain to build a novel cognitive architecture (DAC-ML) that,
by incorporating a hippocampus-inspired sequential memory system, can rapidly
converge to effective action policies that maximize reward acquisition in a
challenging foraging task.
</p>
<a href="http://arxiv.org/abs/2012.13779" target="_blank">arXiv:2012.13779</a> [<a href="http://arxiv.org/pdf/2012.13779" target="_blank">pdf</a>]

<h2>Explainable Multi-class Classification of Medical Data. (arXiv:2012.13796v1 [cs.LG])</h2>
<h3>YuanZheng Hu, Marina Sokolova</h3>
<p>Machine Learning applications have brought new insights into a secondary
analysis of medical data. Machine Learning helps to develop new drugs, define
populations susceptible to certain illnesses, identify predictors of many
common diseases. At the same time, Machine Learning results depend on
convolution of many factors, including feature selection, class (im)balance,
algorithm preference, and performance metrics. In this paper, we present
explainable multi-class classification of a large medical data set. We in
details discuss knowledge-based feature engineering, data set balancing, best
model selection, and parameter tuning. Six algorithms are used in this study:
Support Vector Machine (SVM), Na\"ive Bayes, Gradient Boosting, Decision Trees,
Random Forest, and Logistic Regression. Our empirical evaluation is done on the
UCI Diabetes 130-US hospitals for years 1999-2008 dataset, with the task to
classify patient hospital re-admission stay into three classes: 0 days, &lt;30
days, or &gt; 30 days. Our results show that using 23 medication features in
learning experiments improves Recall of five out of the six applied learning
algorithms. This is a new result that expands the previous studies conducted on
the same data. Gradient Boosting and Random Forest outperformed other
algorithms in terms of the three-class classification Accuracy.
</p>
<a href="http://arxiv.org/abs/2012.13796" target="_blank">arXiv:2012.13796</a> [<a href="http://arxiv.org/pdf/2012.13796" target="_blank">pdf</a>]

<h2>A new class of generative classifiers based on staged tree models. (arXiv:2012.13798v1 [cs.AI])</h2>
<h3>Federico Carli, Manuele Leonelli, Gherardo Varando</h3>
<p>Generative models for classification use the joint probability distribution
of the class variable and the features to construct a decision rule. Among
generative models, Bayesian networks and naive Bayes classifiers are the most
commonly used and provide a clear graphical representation of the relationship
among all variables. However, these have the disadvantage of highly restricting
the type of relationships that could exist, by not allowing for
context-specific independences. Here we introduce a new class of generative
classifiers, called staged tree classifiers, which formally account for
context-specific independence. They are constructed by a partitioning of the
vertices of an event tree from which conditional independence can be formally
read. The naive staged tree classifier is also defined, which extends the
classic naive Bayes classifier whilst retaining the same complexity. An
extensive simulation study shows that the classification accuracy of staged
tree classifiers is competitive with those of state-of-the-art classifiers. An
applied analysis to predict the fate of the passengers of the Titanic
highlights the insights that the new class of generative classifiers can give.
</p>
<a href="http://arxiv.org/abs/2012.13798" target="_blank">arXiv:2012.13798</a> [<a href="http://arxiv.org/pdf/2012.13798" target="_blank">pdf</a>]

<h2>Achieving Real-Time LiDAR 3D Object Detection on a Mobile Device. (arXiv:2012.13801v1 [cs.CV])</h2>
<h3>Pu Zhao, Wei Niu, Geng Yuan, Yuxuan Cai, Hsin-Hsuan Sung, Wujie Wen, Sijia Liu, Xipeng Shen, Bin Ren, Yanzhi Wang, Xue Lin</h3>
<p>3D object detection is an important task, especially in the autonomous
driving application domain. However, it is challenging to support the real-time
performance with the limited computation and memory resources on edge-computing
devices in self-driving cars. To achieve this, we propose a compiler-aware
unified framework incorporating network enhancement and pruning search with the
reinforcement learning techniques, to enable real-time inference of 3D object
detection on the resource-limited edge-computing devices. Specifically, a
generator Recurrent Neural Network (RNN) is employed to provide the unified
scheme for both network enhancement and pruning search automatically, without
human expertise and assistance. And the evaluated performance of the unified
schemes can be fed back to train the generator RNN. The experimental results
demonstrate that the proposed framework firstly achieves real-time 3D object
detection on mobile devices (Samsung Galaxy S20 phone) with competitive
detection performance.
</p>
<a href="http://arxiv.org/abs/2012.13801" target="_blank">arXiv:2012.13801</a> [<a href="http://arxiv.org/pdf/2012.13801" target="_blank">pdf</a>]

<h2>Weighting-Based Treatment Effect Estimation via Distribution Learning. (arXiv:2012.13805v1 [cs.LG])</h2>
<h3>Dongcheng Zhang, Kunpeng Zhang</h3>
<p>Existing weighting methods for treatment effect estimation are often built
upon the idea of propensity scores or covariate balance. They usually impose
strong assumptions on treatment assignment or outcome model to obtain unbiased
estimation, such as linearity or specific functional forms, which easily leads
to the major drawback of model mis-specification. In this paper, we aim to
alleviate these issues by developing a distribution learning-based weighting
method. We first learn the true underlying distribution of covariates
conditioned on treatment assignment, then leverage the ratio of covariates'
density in the treatment group to that of the control group as the weight for
estimating treatment effects. Specifically, we propose to approximate the
distribution of covariates in both treatment and control groups through
invertible transformations via change of variables. To demonstrate the
superiority, robustness, and generalizability of our method, we conduct
extensive experiments using synthetic and real data. From the experiment
results, we find that our method for estimating average treatment effect on
treated (ATT) with observational data outperforms several cutting-edge
weighting-only benchmarking methods, and it maintains its advantage under a
doubly-robust estimation framework that combines weighting with some advanced
outcome modeling methods.
</p>
<a href="http://arxiv.org/abs/2012.13805" target="_blank">arXiv:2012.13805</a> [<a href="http://arxiv.org/pdf/2012.13805" target="_blank">pdf</a>]

<h2>Deep Learning Based Intelligent Inter-Vehicle Distance Control for 6G Enabled Cooperative Autonomous Driving. (arXiv:2012.13817v1 [cs.AI])</h2>
<h3>Xiaosha Chen, Supeng Leng, Jianhua He, Longyu Zhou</h3>
<p>Research on the sixth generation cellular networks (6G) is gaining huge
momentum to achieve ubiquitous wireless connectivity. Connected autonomous
driving (CAV) is a critical vertical envisioned for 6G, holding great
potentials of improving road safety, road and energy efficiency. However the
stringent service requirements of CAV applications on reliability, latency and
high speed communications will present big challenges to 6G networks. New
channel access algorithms and intelligent control schemes for connected
vehicles are needed for 6G supported CAV. In this paper, we investigated 6G
supported cooperative driving, which is an advanced driving mode through
information sharing and driving coordination. Firstly we quantify the delay
upper bounds of 6G vehicle to vehicle (V2V) communications with hybrid
communication and channel access technologies. A deep learning neural network
is developed and trained for fast computation of the delay bounds in real time
operations. Then, an intelligent strategy is designed to control the
inter-vehicle distance for cooperative autonomous driving. Furthermore, we
propose a Markov Chain based algorithm to predict the parameters of the system
states, and also a safe distance mapping method to enable smooth vehicular
speed changes. The proposed algorithms are implemented in the AirSim autonomous
driving platform. Simulation results show that the proposed algorithms are
effective and robust with safe and stable cooperative autonomous driving, which
greatly improve the road safety, capacity and efficiency.
</p>
<a href="http://arxiv.org/abs/2012.13817" target="_blank">arXiv:2012.13817</a> [<a href="http://arxiv.org/pdf/2012.13817" target="_blank">pdf</a>]

<h2>Skeleton-DML: Deep Metric Learning for Skeleton-Based One-Shot Action Recognition. (arXiv:2012.13823v1 [cs.CV])</h2>
<h3>Raphael Memmesheimer, Simon H&#xe4;ring, Nick Theisen, Dietrich Paulus</h3>
<p>One-shot action recognition allows the recognition of human-performed actions
with only a single training example. This can influence human-robot-interaction
positively by enabling the robot to react to previously unseen behaviour. We
formulate the one-shot action recognition problem as a deep metric learning
problem and propose a novel image-based skeleton representation that performs
well in a metric learning setting. Therefore, we train a model that projects
the image representations into an embedding space. In embedding space the
similar actions have a low euclidean distance while dissimilar actions have a
higher distance. The one-shot action recognition problem becomes a
nearest-neighbor search in a set of activity reference samples. We evaluate the
performance of our proposed representation against a variety of other
skeleton-based image representations. In addition, we present an ablation study
that shows the influence of different embedding vector sizes, losses and
augmentation. Our approach lifts the state-of-the-art by 3.3% for the one-shot
action recognition protocol on the NTU RGB+D 120 dataset under a comparable
training setup. With additional augmentation our result improved over 7.7%.
</p>
<a href="http://arxiv.org/abs/2012.13823" target="_blank">arXiv:2012.13823</a> [<a href="http://arxiv.org/pdf/2012.13823" target="_blank">pdf</a>]

<h2>Spatial Contrastive Learning for Few-Shot Classification. (arXiv:2012.13831v1 [cs.CV])</h2>
<h3>Yassine Ouali, C&#xe9;line Hudelot, Myriam Tami</h3>
<p>Existing few-shot classification methods rely to some degree on the
cross-entropy (CE) loss to learn transferable representations that facilitate
the test time adaptation to unseen classes with limited data. However, the CE
loss has several shortcomings, e.g., inducing representations with excessive
discrimination towards seen classes, which reduces their transferability to
unseen classes and results in sub-optimal generalization. In this work, we
explore contrastive learning as an additional auxiliary training objective,
acting as a data-dependent regularizer to promote more general and transferable
features. Instead of using the standard contrastive objective, which suppresses
local discriminative features, we propose a novel attention-based spatial
contrastive objective to learn locally discriminative and class-agnostic
features. With extensive experiments, we show that the proposed method
outperforms state-of-the-art approaches, confirming the importance of learning
good and transferable embeddings for few-shot learning.
</p>
<a href="http://arxiv.org/abs/2012.13831" target="_blank">arXiv:2012.13831</a> [<a href="http://arxiv.org/pdf/2012.13831" target="_blank">pdf</a>]

<h2>Understanding Decoupled and Early Weight Decay. (arXiv:2012.13841v1 [cs.LG])</h2>
<h3>Johan Bjorck, Kilian Weinberger, Carla Gomes</h3>
<p>Weight decay (WD) is a traditional regularization technique in deep learning,
but despite its ubiquity, its behavior is still an area of active research.
Golatkar et al. have recently shown that WD only matters at the start of the
training in computer vision, upending traditional wisdom. Loshchilov et al.
show that for adaptive optimizers, manually decaying weights can outperform
adding an $l_2$ penalty to the loss. This technique has become increasingly
popular and is referred to as decoupled WD. The goal of this paper is to
investigate these two recent empirical observations. We demonstrate that by
applying WD only at the start, the network norm stays small throughout
training. This has a regularizing effect as the effective gradient updates
become larger. However, traditional generalizations metrics fail to capture
this effect of WD, and we show how a simple scale-invariant metric can. We also
show how the growth of network weights is heavily influenced by the dataset and
its generalization properties. For decoupled WD, we perform experiments in NLP
and RL where adaptive optimizers are the norm. We demonstrate that the primary
issue that decoupled WD alleviates is the mixing of gradients from the
objective function and the $l_2$ penalty in the buffers of Adam (which stores
the estimates of the first-order moment). Adaptivity itself is not problematic
and decoupled WD ensures that the gradients from the $l_2$ term cannot "drown
out" the true objective, facilitating easier hyperparameter tuning.
</p>
<a href="http://arxiv.org/abs/2012.13841" target="_blank">arXiv:2012.13841</a> [<a href="http://arxiv.org/pdf/2012.13841" target="_blank">pdf</a>]

<h2>SparsePipe: Parallel Deep Learning for 3D Point Clouds. (arXiv:2012.13846v1 [cs.CV])</h2>
<h3>Keke Zhai, Pan He, Tania Banerjee, Anand Rangarajan, Sanjay Ranka</h3>
<p>We propose SparsePipe, an efficient and asynchronous parallelism approach for
handling 3D point clouds with multi-GPU training. SparsePipe is built to
support 3D sparse data such as point clouds. It achieves this by adopting
generalized convolutions with sparse tensor representation to build expressive
high-dimensional convolutional neural networks. Compared to dense solutions,
the new models can efficiently process irregular point clouds without densely
sliding over the entire space, significantly reducing the memory requirements
and allowing higher resolutions of the underlying 3D volumes for better
performance.

SparsePipe exploits intra-batch parallelism that partitions input data into
multiple processors and further improves the training throughput with
inter-batch pipelining to overlap communication and computing. Besides, it
suitably partitions the model when the GPUs are heterogeneous such that the
computing is load-balanced with reduced communication overhead.

Using experimental results on an eight-GPU platform, we show that SparsePipe
can parallelize effectively and obtain better performance on current point
cloud benchmarks for both training and inference, compared to its dense
solutions.
</p>
<a href="http://arxiv.org/abs/2012.13846" target="_blank">arXiv:2012.13846</a> [<a href="http://arxiv.org/pdf/2012.13846" target="_blank">pdf</a>]

<h2>ANL: Anti-Noise Learning for Cross-Domain Person Re-Identification. (arXiv:2012.13853v1 [cs.CV])</h2>
<h3>Hongliang Zhang, Shoudong Han, Xiaofeng Pan, Jun Zhao</h3>
<p>Due to the lack of labels and the domain diversities, it is a challenge to
study person re-identification in the cross-domain setting. An admirable method
is to optimize the target model by assigning pseudo-labels for unlabeled
samples through clustering. Usually, attributed to the domain gaps, the
pre-trained source domain model cannot extract appropriate target domain
features, which will dramatically affect the clustering performance and the
accuracy of pseudo-labels. Extensive label noise will lead to sub-optimal
solutions doubtlessly. To solve these problems, we propose an Anti-Noise
Learning (ANL) approach, which contains two modules. The Feature Distribution
Alignment (FDA) module is designed to gather the id-related samples and
disperse id-unrelated samples, through the camera-wise contrastive learning and
adversarial adaptation. Creating a friendly cross-feature foundation for
clustering that is to reduce clustering noise. Besides, the Reliable Sample
Selection (RSS) module utilizes an Auxiliary Model to correct noisy labels and
select reliable samples for the Main Model. In order to effectively utilize the
outlier information generated by the clustering algorithm and RSS module, we
train these samples at the instance-level. The experiments demonstrate that our
proposed ANL framework can effectively reduce the domain conflicts and
alleviate the influence of noisy samples, as well as superior performance
compared with the state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.13853" target="_blank">arXiv:2012.13853</a> [<a href="http://arxiv.org/pdf/2012.13853" target="_blank">pdf</a>]

<h2>Neural Closure Models for Dynamical Systems. (arXiv:2012.13869v1 [cs.LG])</h2>
<h3>Abhinav Gupta, Pierre F.J. Lermusiaux</h3>
<p>Complex dynamical systems are used for predictions in many applications.
Because of computational costs, models are however often truncated, coarsened,
or aggregated. As the neglected and unresolved terms along with their
interactions with the resolved ones become important, the usefulness of model
predictions diminishes. We develop a novel, versatile, and rigorous methodology
to learn non-Markovian closure parameterizations for low-fidelity models using
data from high-fidelity simulations. The new "neural closure models" augment
low-fidelity models with neural delay differential equations (nDDEs), motivated
by the Mori-Zwanzig formulation and the inherent delays in natural dynamical
systems. We demonstrate that neural closures efficiently account for truncated
modes in reduced-order-models, capture the effects of subgrid-scale processes
in coarse models, and augment the simplification of complex biochemical models.
We show that using non-Markovian over Markovian closures improves long-term
accuracy and requires smaller networks. We provide adjoint equation derivations
and network architectures needed to efficiently implement the new discrete and
distributed nDDEs. The performance of discrete over distributed delays in
closure models is explained using information theory, and we observe an optimal
amount of past information for a specified architecture. Finally, we analyze
computational complexity and explain the limited additional cost due to neural
closure models.
</p>
<a href="http://arxiv.org/abs/2012.13869" target="_blank">arXiv:2012.13869</a> [<a href="http://arxiv.org/pdf/2012.13869" target="_blank">pdf</a>]

<h2>Universal Approximation Theorem for Equivariant Maps by Group CNNs. (arXiv:2012.13882v1 [stat.ML])</h2>
<h3>Wataru Kumagai, Akiyoshi Sannai</h3>
<p>Group symmetry is inherent in a wide variety of data distributions. Data
processing that preserves symmetry is described as an equivariant map and often
effective in achieving high performance. Convolutional neural networks (CNNs)
have been known as models with equivariance and shown to approximate
equivariant maps for some specific groups. However, universal approximation
theorems for CNNs have been separately derived with individual techniques
according to each group and setting. This paper provides a unified method to
obtain universal approximation theorems for equivariant maps by CNNs in various
settings. As its significant advantage, we can handle non-linear equivariant
maps between infinite-dimensional spaces for non-compact groups.
</p>
<a href="http://arxiv.org/abs/2012.13882" target="_blank">arXiv:2012.13882</a> [<a href="http://arxiv.org/pdf/2012.13882" target="_blank">pdf</a>]

<h2>Federated Unlearning. (arXiv:2012.13891v1 [cs.LG])</h2>
<h3>Gaoyang Liu, Yang Yang, Xiaoqiang Ma, Chen Wang, Jiangchuan Liu</h3>
<p>Data removal from machine learning models has been paid more attentions due
to the demands of the "right to be forgotten" and countering data poisoning
attacks. In this paper, we frame the problem of federated unlearning, a
post-process operation of the federated learning models to remove the influence
of the specified training sample(s). We present FedEraser, the first federated
unlearning methodology that can eliminate the influences of a federated
client's data on the global model while significantly reducing the time
consumption used for constructing the unlearned model. The core idea of
FedEraser is to trade the central server's storage for unlearned model's
construction time. In particular, FedEraser reconstructs the unlearned model by
leveraging the historical parameter updates of federated clients that have been
retained at the central server during the training process of FL. A novel
calibration method is further developed to calibrate the retained client
updates, which can provide a significant speed-up to the reconstruction of the
unlearned model. Experiments on four realistic datasets demonstrate the
effectiveness of FedEraser, with an expected speed-up of $4\times$ compared
with retraining from the scratch.
</p>
<a href="http://arxiv.org/abs/2012.13891" target="_blank">arXiv:2012.13891</a> [<a href="http://arxiv.org/pdf/2012.13891" target="_blank">pdf</a>]

<h2>Adaptive Graph-based Generalized Regression Model for Unsupervised Feature Selection. (arXiv:2012.13892v1 [cs.LG])</h2>
<h3>Yanyong Huang, Zongxin Shen, Fuxu Cai, Tianrui Li, Fengmao Lv</h3>
<p>Unsupervised feature selection is an important method to reduce dimensions of
high dimensional data without labels, which is benefit to avoid ``curse of
dimensionality'' and improve the performance of subsequent machine learning
tasks, like clustering and retrieval. How to select the uncorrelated and
discriminative features is the key problem of unsupervised feature selection.
Many proposed methods select features with strong discriminant and high
redundancy, or vice versa. However, they only satisfy one of these two
criteria. Other existing methods choose the discriminative features with low
redundancy by constructing the graph matrix on the original feature space.
Since the original feature space usually contains redundancy and noise, it will
degrade the performance of feature selection. In order to address these issues,
we first present a novel generalized regression model imposed by an
uncorrelated constraint and the $\ell_{2,1}$-norm regularization. It can
simultaneously select the uncorrelated and discriminative features as well as
reduce the variance of these data points belonging to the same neighborhood,
which is help for the clustering task. Furthermore, the local intrinsic
structure of data is constructed on the reduced dimensional space by learning
the similarity-induced graph adaptively. Then the learnings of the graph
structure and the indicator matrix based on the spectral analysis are
integrated into the generalized regression model. Finally, we develop an
alternative iterative optimization algorithm to solve the objective function. A
series of experiments are carried out on nine real-world data sets to
demonstrate the effectiveness of the proposed method in comparison with other
competing approaches.
</p>
<a href="http://arxiv.org/abs/2012.13892" target="_blank">arXiv:2012.13892</a> [<a href="http://arxiv.org/pdf/2012.13892" target="_blank">pdf</a>]

<h2>Lidar and Camera Self-Calibration using CostVolume Network. (arXiv:2012.13901v1 [cs.CV])</h2>
<h3>Xudong Lv, Boya Wang, Dong Ye, Shuo Wang</h3>
<p>In this paper, we propose a novel online self-calibration approach for Light
Detection and Ranging (LiDAR) and camera sensors. Compared to the previous
CNN-based methods that concatenate the feature maps of the RGB image and
decalibrated depth image, we exploit the cost volume inspired by the PWC-Net
for feature matching. Besides the smooth L1-Loss of the predicted extrinsic
calibration parameters, an additional point cloud loss is applied. Instead of
regress the extrinsic parameters between LiDAR and camera directly, we predict
the decalibrated deviation from initial calibration to the ground truth. During
inference, the calibration error decreases further with the usage of iterative
refinement and the temporal filtering approach. The evaluation results on the
KITTI dataset illustrate that our approach outperforms CNN-based
state-of-the-art methods in terms of a mean absolute calibration error of
0.297cm in translation and 0.017{\deg} in rotation with miscalibration
magnitudes of up to 1.5m and 20{\deg}.
</p>
<a href="http://arxiv.org/abs/2012.13901" target="_blank">arXiv:2012.13901</a> [<a href="http://arxiv.org/pdf/2012.13901" target="_blank">pdf</a>]

<h2>Exploring Emotion Features and Fusion Strategies for Audio-Video Emotion Recognition. (arXiv:2012.13912v1 [cs.CV])</h2>
<h3>Hengshun Zhou, Debin Meng, Yuanyuan Zhang, Xiaojiang Peng, Jun Du, Kai Wang, Yu Qiao</h3>
<p>The audio-video based emotion recognition aims to classify a given video into
basic emotions. In this paper, we describe our approaches in EmotiW 2019, which
mainly explores emotion features and feature fusion strategies for audio and
visual modality. For emotion features, we explore audio feature with both
speech-spectrogram and Log Mel-spectrogram and evaluate several facial features
with different CNN models and different emotion pretrained strategies. For
fusion strategies, we explore intra-modal and cross-modal fusion methods, such
as designing attention mechanisms to highlights important emotion feature,
exploring feature concatenation and factorized bilinear pooling (FBP) for
cross-modal feature fusion. With careful evaluation, we obtain 65.5% on the
AFEW validation set and 62.48% on the test set and rank third in the challenge.
</p>
<a href="http://arxiv.org/abs/2012.13912" target="_blank">arXiv:2012.13912</a> [<a href="http://arxiv.org/pdf/2012.13912" target="_blank">pdf</a>]

<h2>Doubly Stochastic Generative Arrivals Modeling. (arXiv:2012.13940v1 [stat.ML])</h2>
<h3>Yufeng Zheng, Zeyu Zheng</h3>
<p>We propose a new framework named DS-WGAN that integrates the doubly
stochastic (DS) structure and the Wasserstein generative adversarial networks
(WGAN) to model, estimate, and simulate a wide class of arrival processes with
non-stationary and stochastic arrival rates. We prove statistical consistency
for the estimator solved by the DS-WGAN framework. We then discuss and address
challenges from the computational aspect in the model estimation procedures. We
show that the DS-WGAN framework can facilitate what-if simulation and
predictive simulation for scenarios that have never happened before in the
historical data. Numerical experiments with synthetic and real data sets are
implemented to demonstrate the performance of DS-WGAN, both from a statistical
perspective and from an operational performance evaluation perspective.
Numerical experiments suggest that the successful model estimation for DS-WGAN
only requires a moderate size of data, which can be appealing in the contexts
of operational management.
</p>
<a href="http://arxiv.org/abs/2012.13940" target="_blank">arXiv:2012.13940</a> [<a href="http://arxiv.org/pdf/2012.13940" target="_blank">pdf</a>]

<h2>ROS for Human-Robot Interaction. (arXiv:2012.13944v1 [cs.RO])</h2>
<h3>Youssef Mohamed, S&#xe9;verin Lemaignan</h3>
<p>Integrating real-time, complex social signal processing into robotic systems
-- especially in real-world, multi-party interaction situations -- is a
challenge faced by many in the Human-Robot Interaction (HRI) community. The
difficulty is compounded by the lack of any standard model for human
representation that would facilitate the development and interoperability of
social perception components and pipelines. We introduce in this paper a set of
conventions and standard interfaces for HRI scenarios, designed to be used with
the Robot Operating System (ROS). It directly aims at promoting
interoperability and re-usability of core functionality between the many
HRI-related software tools, from skeleton tracking, to face recognition, to
natural language processing. Importantly, these interfaces are designed to be
relevant to a broad range of HRI applications, from high-level crowd
simulation, to group-level social interaction modelling, to detailed modelling
of human kinematics. We demonstrate these interface by providing a reference
pipeline implementation, packaged to be easily downloaded and evaluated by the
community.
</p>
<a href="http://arxiv.org/abs/2012.13944" target="_blank">arXiv:2012.13944</a> [<a href="http://arxiv.org/pdf/2012.13944" target="_blank">pdf</a>]

<h2>A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v1 [cs.LG])</h2>
<h3>Felix Leibfried, Vincent Dutordoir, ST John, Nicolas Durrande</h3>
<p>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model can predict both the mean and variance of the posterior in closed form.
However, identifying the posterior GP scales cubically with the number of
training examples and requires to store all examples in memory. In order to
overcome these obstacles, sparse GPs have been proposed that approximate the
true posterior GP with pseudo-training examples. Importantly, the number of
pseudo-training examples is user-defined and enables control over computational
and memory complexity. In the general case, sparse GPs do not enjoy closed-form
solutions and one has to resort to approximate inference. In this context, a
convenient choice for approximate inference is variational inference (VI),
where the problem of Bayesian inference is cast as an optimization problem --
namely, to maximize a lower bound of the log marginal likelihood. This paves
the way for a powerful and versatile framework, where pseudo-training examples
are treated as optimization arguments of the approximate posterior that are
jointly identified together with hyperparameters of the generative model (i.e.
prior and likelihood). The framework can naturally handle a wide scope of
supervised learning problems, ranging from regression with heteroscedastic and
non-Gaussian likelihoods to classification problems with discrete labels, but
also multilabel problems. The purpose of this tutorial is to provide access to
the basic matter for readers without prior knowledge in both GPs and VI. A
proper exposition to the subject enables also access to more recent advances
(like importance-weighted VI as well as inderdomain, multioutput and deep GPs)
that can serve as an inspiration for new research ideas.
</p>
<a href="http://arxiv.org/abs/2012.13962" target="_blank">arXiv:2012.13962</a> [<a href="http://arxiv.org/pdf/2012.13962" target="_blank">pdf</a>]

<h2>Jacobian-based learning for inverse kinematics of soft robots. (arXiv:2012.13965v1 [cs.RO])</h2>
<h3>Guoxin Fang, Yingjun Tian, Zhi-Xin Yang, Jo M.P. Geraedts, Charlie C.L. Wang</h3>
<p>This paper presents a new method to solve the inverse kinematic (IK) problem
in real-time on soft robots with highly non-linear deformation. The major
challenge of efficiently computing IK for such robots is caused by the lack of
analytical formulation for either forward or inverse kinematics. To tackle this
challenge, we employ neural-networks to learn both the mapping function of
forward kinematics and also the Jacobian of this function. As a result,
Jacobian-based iteration can be applied to solve the IK problem. A sim-to-real
training transfer strategy is conducted to make this approach more practical.
We first generate large amount of samples in a simulation environment for
learning both the kinematic and the Jacobian networks of a soft robot design.
After that, a sim-to-real layer of differentiable neurons is employed to map
the results of simulation to the physical hardware, where this sim-to-real
layer can be learned from very limited number of training samples generated on
the hardware. The effectiveness of our approach has been verified on several
pneumatic-driven soft robots in the tasks of trajectory following and
interactive positioning.
</p>
<a href="http://arxiv.org/abs/2012.13965" target="_blank">arXiv:2012.13965</a> [<a href="http://arxiv.org/pdf/2012.13965" target="_blank">pdf</a>]

<h2>Time-Window Group-Correlation Support vs. Individual Features: A Detection of Abnormal Users. (arXiv:2012.13971v1 [cs.LG])</h2>
<h3>Lun-Pin Yuan, Euijin Choo, Ting Yu, Issa Khalil, Sencun Zhu</h3>
<p>Autoencoder-based anomaly detection methods have been used in identifying
anomalous users from large-scale enterprise logs with the assumption that
adversarial activities do not follow past habitual patterns. Most existing
approaches typically build models by reconstructing single-day and
individual-user behaviors. However, without capturing long-term signals and
group-correlation signals, the models cannot identify low-signal yet
long-lasting threats, and will wrongly report many normal users as anomalies on
busy days, which, in turn, lead to high false positive rate. In this paper, we
propose ACOBE, an Anomaly detection method based on COmpound BEhavior, which
takes into consideration long-term patterns and group behaviors. ACOBE
leverages a novel behavior representation and an ensemble of deep autoencoders
and produces an ordered investigation list. Our evaluation shows that ACOBE
outperforms prior work by a large margin in terms of precision and recall, and
our case study demonstrates that ACOBE is applicable in practice for
cyberattack detection.
</p>
<a href="http://arxiv.org/abs/2012.13971" target="_blank">arXiv:2012.13971</a> [<a href="http://arxiv.org/pdf/2012.13971" target="_blank">pdf</a>]

<h2>Recomposition vs. Prediction: A Novel Anomaly Detection for Discrete Events Based On Autoencoder. (arXiv:2012.13972v1 [cs.LG])</h2>
<h3>Lun-Pin Yuan, Peng Liu, Sencun Zhu</h3>
<p>One of the most challenging problems in the field of intrusion detection is
anomaly detection for discrete event logs. While most earlier work focused on
applying unsupervised learning upon engineered features, most recent work has
started to resolve this challenge by applying deep learning methodology to
abstraction of discrete event entries. Inspired by natural language processing,
LSTM-based anomaly detection models were proposed. They try to predict upcoming
events, and raise an anomaly alert when a prediction fails to meet a certain
criterion. However, such a predict-next-event methodology has a fundamental
limitation: event predictions may not be able to fully exploit the distinctive
characteristics of sequences. This limitation leads to high false positives
(FPs) and high false negatives (FNs). It is also critical to examine the
structure of sequences and the bi-directional causality among individual
events. To this end, we propose a new methodology: Recomposing event sequences
as anomaly detection. We propose DabLog, a Deep Autoencoder-Based anomaly
detection method for discrete event Logs. The fundamental difference is that,
rather than predicting upcoming events, our approach determines whether a
sequence is normal or abnormal by analyzing (encoding) and reconstructing
(decoding) the given sequence. Our evaluation results show that our new
methodology can significantly reduce the numbers of FPs and FNs, hence
achieving a higher $F_1$ score.
</p>
<a href="http://arxiv.org/abs/2012.13972" target="_blank">arXiv:2012.13972</a> [<a href="http://arxiv.org/pdf/2012.13972" target="_blank">pdf</a>]

<h2>Domain Generalisation with Domain Augmented Supervised Contrastive Learning (Student Abstract). (arXiv:2012.13973v1 [cs.LG])</h2>
<h3>Hoang Son Le, Rini Akmeliawati, Gustavo Carneiro</h3>
<p>Domain generalisation (DG) methods address the problem of domain shift, when
there is a mismatch between the distributions of training and target domains.
Data augmentation approaches have emerged as a promising alternative for DG.
However, data augmentation alone is not sufficient to achieve lower
generalisation errors. This project proposes a new method that combines data
augmentation and domain distance minimisation to address the problems
associated with data augmentation and provide a guarantee on the learning
performance, under an existing framework. Empirically, our method outperforms
baseline results on DG benchmarks.
</p>
<a href="http://arxiv.org/abs/2012.13973" target="_blank">arXiv:2012.13973</a> [<a href="http://arxiv.org/pdf/2012.13973" target="_blank">pdf</a>]

<h2>Power Normalizations in Fine-grained Image, Few-shot Image and Graph Classification. (arXiv:2012.13975v1 [cs.CV])</h2>
<h3>Piotr Koniusz, Hongguang Zhang</h3>
<p>Power Normalizations (PN) are useful non-linear operators which tackle
feature imbalances in classification problems. We study PNs in the deep
learning setup via a novel PN layer pooling feature maps. Our layer combines
the feature vectors and their respective spatial locations in the feature maps
produced by the last convolutional layer of CNN into a positive definite matrix
with second-order statistics to which PN operators are applied, forming
so-called Second-order Pooling (SOP). As the main goal of this paper is to
study Power Normalizations, we investigate the role and meaning of MaxExp and
Gamma, two popular PN functions. To this end, we provide probabilistic
interpretations of such element-wise operators and discover surrogates with
well-behaved derivatives for end-to-end training. Furthermore, we look at the
spectral applicability of MaxExp and Gamma by studying Spectral Power
Normalizations (SPN). We show that SPN on the autocorrelation/covariance matrix
and the Heat Diffusion Process (HDP) on a graph Laplacian matrix are closely
related, thus sharing their properties. Such a finding leads us to the
culmination of our work, a fast spectral MaxExp which is a variant of HDP for
covariances/autocorrelation matrices. We evaluate our ideas on fine-grained
recognition, scene recognition, and material classification, as well as in
few-shot learning and graph classification.
</p>
<a href="http://arxiv.org/abs/2012.13975" target="_blank">arXiv:2012.13975</a> [<a href="http://arxiv.org/pdf/2012.13975" target="_blank">pdf</a>]

<h2>Mathematical Models of Overparameterized Neural Networks. (arXiv:2012.13982v1 [cs.LG])</h2>
<h3>Cong Fang, Hanze Dong, Tong Zhang</h3>
<p>Deep learning has received considerable empirical successes in recent years.
However, while many ad hoc tricks have been discovered by practitioners, until
recently, there has been a lack of theoretical understanding for tricks
invented in the deep learning literature. Known by practitioners that
overparameterized neural networks are easy to learn, in the past few years
there have been important theoretical developments in the analysis of
overparameterized neural networks. In particular, it was shown that such
systems behave like convex systems under various restricted settings, such as
for two-layer NNs, and when learning is restricted locally in the so-called
neural tangent kernel space around specialized initializations. This paper
discusses some of these recent progresses leading to significant better
understanding of neural networks. We will focus on the analysis of two-layer
neural networks, and explain the key mathematical models, with their
algorithmic implications. We will then discuss challenges in understanding deep
neural networks and some current research directions.
</p>
<a href="http://arxiv.org/abs/2012.13982" target="_blank">arXiv:2012.13982</a> [<a href="http://arxiv.org/pdf/2012.13982" target="_blank">pdf</a>]

<h2>Modeling, Vibration Control, and Trajectory Tracking of a Kinematically Constrained Planar Hybrid Cable-Driven Parallel Robot. (arXiv:2012.14029v1 [cs.RO])</h2>
<h3>Ronghuai Qi, Amir Khajepour, William W. Melek</h3>
<p>This paper presents a kinematically constrained planar hybrid cable-driven
parallel robot (HCDPR) for warehousing applications as well as other potential
applications such as rehabilitation. The proposed HCDPR can harness the
strengths and benefits of serial and cable-driven parallel robots. Based on
this robotic platform, the goal in this paper is to develop an integrated
control system to reduce vibrations and improve the trajectory accuracy and
performance of the HCDPR, including deriving kinematic and dynamic equations,
proposing solutions for redundancy resolution and optimization of stiffness,
and developing two motion and vibration control strategies (controllers I and
II). Finally, different case studies are conducted to evaluate the control
performance, and the results show that the controller II can achieve the goal
better.
</p>
<a href="http://arxiv.org/abs/2012.14029" target="_blank">arXiv:2012.14029</a> [<a href="http://arxiv.org/pdf/2012.14029" target="_blank">pdf</a>]

<h2>Aerial Imagery Pile burn detection using Deep Learning: the FLAME dataset. (arXiv:2012.14036v1 [cs.CV])</h2>
<h3>Alireza Shamsoshoara, Fatemeh Afghah, Abolfazl Razi, Liming Zheng, Peter Z Ful&#xe9;, Erik Blasch</h3>
<p>Wildfires are one of the costliest and deadliest natural disasters in the US,
causing damage to millions of hectares of forest resources and threatening the
lives of people and animals. Of particular importance are risks to firefighters
and operational forces, which highlights the need for leveraging technology to
minimize danger to people and property. FLAME (Fire Luminosity Airborne-based
Machine learning Evaluation) offers a dataset of aerial images of fires along
with methods for fire detection and segmentation which can help firefighters
and researchers to develop optimal fire management strategies. This paper
provides a fire image dataset collected by drones during a prescribed burning
piled detritus in an Arizona pine forest. The dataset includes video recordings
and thermal heatmaps captured by infrared cameras. The captured videos and
images are annotated and labeled frame-wise to help researchers easily apply
their fire detection and modeling algorithms. The paper also highlights
solutions to two machine learning problems: (1) Binary classification of video
frames based on the presence [and absence] of fire flames. An Artificial Neural
Network (ANN) method is developed that achieved a 76% classification accuracy.
(2) Fire detection using segmentation methods to precisely determine fire
borders. A deep learning method is designed based on the U-Net up-sampling and
down-sampling approach to extract a fire mask from the video frames. Our FLAME
method approached a precision of 92% and a recall of 84%. Future research will
expand the technique for free burning broadcast fire using thermal images.
</p>
<a href="http://arxiv.org/abs/2012.14036" target="_blank">arXiv:2012.14036</a> [<a href="http://arxiv.org/pdf/2012.14036" target="_blank">pdf</a>]

<h2>Blackwell Online Learning for Markov Decision Processes. (arXiv:2012.14043v1 [cs.LG])</h2>
<h3>Tao Li, Guanze Peng, Quanyan Zhu</h3>
<p>This work provides a novel interpretation of Markov Decision Processes (MDP)
from the online optimization viewpoint. In such an online optimization context,
the policy of the MDP is viewed as the decision variable while the
corresponding value function is treated as payoff feedback from the
environment. Based on this interpretation, we construct a Blackwell game
induced by MDP, which bridges the gap among regret minimization, Blackwell
approachability theory, and learning theory for MDP. Specifically, from the
approachability theory, we propose 1) Blackwell value iteration for offline
planning and 2) Blackwell $Q-$learning for online learning in MDP, both of
which are shown to converge to the optimal solution. Our theoretical guarantees
are corroborated by numerical experiments.
</p>
<a href="http://arxiv.org/abs/2012.14043" target="_blank">arXiv:2012.14043</a> [<a href="http://arxiv.org/pdf/2012.14043" target="_blank">pdf</a>]

<h2>SPINS: Structure Priors aided Inertial Navigation System. (arXiv:2012.14053v1 [cs.RO])</h2>
<h3>Yang Lyu, Thien-Minh Nguyen, Liu Liu, Muqing Cao, Shenghai Yuan, Thien Hoang Nguyen, Lihua Xie</h3>
<p>Although Simultaneous Localization and Mapping (SLAM) has been an active
research topic for decades, current state-of-the-art methods still suffer from
instability or inaccuracy due to feature insufficiency or its inherent
estimation drift, in many civilian environments. To resolve these issues, we
propose a navigation system combing the SLAM and prior-map-based localization.
Specifically, we consider additional integration of line and plane features,
which are ubiquitous and more structurally salient in civilian environments,
into the SLAM to ensure feature sufficiency and localization robustness. More
importantly, we incorporate general prior map information into the SLAM to
restrain its drift and improve the accuracy. To avoid rigorous association
between prior information and local observations, we parameterize the prior
knowledge as low dimensional structural priors defined as relative
distances/angles between different geometric primitives. The localization is
formulated as a graph-based optimization problem that contains
sliding-window-based variables and factors, including IMU, heterogeneous
features, and structure priors. We also derive the analytical expressions of
Jacobians of different factors to avoid the automatic differentiation overhead.
To further alleviate the computation burden of incorporating structural prior
factors, a selection mechanism is adopted based on the so-called information
gain to incorporate only the most effective structure priors in the graph
optimization. Finally, the proposed framework is extensively tested on
synthetic data, public datasets, and, more importantly, on the real UAV flight
data obtained from a building inspection task. The results show that the
proposed scheme can effectively improve the accuracy and robustness of
localization for autonomous robots in civilian applications.
</p>
<a href="http://arxiv.org/abs/2012.14053" target="_blank">arXiv:2012.14053</a> [<a href="http://arxiv.org/pdf/2012.14053" target="_blank">pdf</a>]

<h2>Person Re-identification with Adversarial Triplet Embedding. (arXiv:2012.14057v1 [cs.CV])</h2>
<h3>Xinglu Wang</h3>
<p>Person re-identification is an important task and has widespread applications
in video surveillance for public security. In the past few years, deep learning
network with triplet loss has become popular for this problem. However, the
triplet loss usually suffers from poor local optimal and relies heavily on the
strategy of hard example mining. In this paper, we propose to address this
problem with a new deep metric learning method called Adversarial Triplet
Embedding (ATE), in which we simultaneously generate adversarial triplets and
discriminative feature embedding in an unified framework. In particular,
adversarial triplets are generated by introducing adversarial perturbations
into the training process. This adversarial game is converted into a minimax
problem so as to have an optimal solution from the theoretical view. Extensive
experiments on several benchmark datasets demonstrate the effectiveness of the
approach against the state-of-the-art literature.
</p>
<a href="http://arxiv.org/abs/2012.14057" target="_blank">arXiv:2012.14057</a> [<a href="http://arxiv.org/pdf/2012.14057" target="_blank">pdf</a>]

<h2>Convolutional Neural Networks in Multi-Class Classification of Medical Data. (arXiv:2012.14059v1 [cs.LG])</h2>
<h3>YuanZheng Hu, Marina Sokolova</h3>
<p>We report applications of Convolutional Neural Networks (CNN) to
multi-classification classification of a large medical data set. We discuss in
detail how changes in the CNN model and the data pre-processing impact the
classification results. In the end, we introduce an ensemble model that
consists of both deep learning (CNN) and shallow learning models (Gradient
Boosting). The method achieves Accuracy of 64.93, the highest three-class
classification accuracy we achieved in this study. Our results also show that
CNN and the ensemble consistently obtain a higher Recall than Precision. The
highest Recall is 68.87, whereas the highest Precision is 65.04.
</p>
<a href="http://arxiv.org/abs/2012.14059" target="_blank">arXiv:2012.14059</a> [<a href="http://arxiv.org/pdf/2012.14059" target="_blank">pdf</a>]

<h2>Adversarial Multi-scale Feature Learning for Person Re-identification. (arXiv:2012.14061v1 [cs.CV])</h2>
<h3>Xinglu Wang</h3>
<p>Person Re-identification (Person ReID) is an important topic in intelligent
surveillance and computer vision. It aims to accurately measure visual
similarities between person images for determining whether two images
correspond to the same person. The key to accurately measure visual
similarities is learning discriminative features, which not only captures clues
from different spatial scales, but also jointly inferences on multiple scales,
with the ability to determine reliability and ID-relativity of each clue. To
achieve these goals, we propose to improve Person ReID system performance from
two perspective: \textbf{1).} Multi-scale feature learning (MSFL), which
consists of Cross-scale information propagation (CSIP) and Multi-scale feature
fusion (MSFF), to dynamically fuse features cross different scales.\textbf{2).}
Multi-scale gradient regularizor (MSGR), to emphasize ID-related factors and
ignore irrelevant factors in an adversarial manner. Combining MSFL and MSGR,
our method achieves the state-of-the-art performance on four commonly used
person-ReID datasets with neglectable test-time computation overhead.
</p>
<a href="http://arxiv.org/abs/2012.14061" target="_blank">arXiv:2012.14061</a> [<a href="http://arxiv.org/pdf/2012.14061" target="_blank">pdf</a>]

<h2>Deep Learning with Heterogeneous Graph Embeddings for Mortality Prediction from Electronic Health Records. (arXiv:2012.14065v1 [cs.LG])</h2>
<h3>Tingyi Wanyan, Hossein Honarvar, Ariful Azad, Ying Ding, Benjamin S. Glicksberg</h3>
<p>Computational prediction of in-hospital mortality in the setting of an
intensive care unit can help clinical practitioners to guide care and make
early decisions for interventions. As clinical data are complex and varied in
their structure and components, continued innovation of modeling strategies is
required to identify architectures that can best model outcomes. In this work,
we train a Heterogeneous Graph Model (HGM) on Electronic Health Record data and
use the resulting embedding vector as additional information added to a
Convolutional Neural Network (CNN) model for predicting in-hospital mortality.
We show that the additional information provided by including time as a vector
in the embedding captures the relationships between medical concepts, lab
tests, and diagnoses, which enhances predictive performance. We find that
adding HGM to a CNN model increases the mortality prediction accuracy up to
4\%. This framework serves as a foundation for future experiments involving
different EHR data types on important healthcare prediction tasks.
</p>
<a href="http://arxiv.org/abs/2012.14065" target="_blank">arXiv:2012.14065</a> [<a href="http://arxiv.org/pdf/2012.14065" target="_blank">pdf</a>]

<h2>From Point to Space: 3D Moving Human Pose Estimation Using Commodity WiFi. (arXiv:2012.14066v1 [cs.CV])</h2>
<h3>Yiming Wang, Lingchao Guo, Zhaoming Lu, Xiangming Wen, Shuang Zhou, Wanyu Meng</h3>
<p>In this paper, we present Wi-Mose, the first 3D moving human pose estimation
system using commodity WiFi. Previous WiFi-based works have achieved 2D and 3D
pose estimation. These solutions either capture poses from one perspective or
construct poses of people who are at a fixed point, preventing their wide
adoption in daily scenarios. To reconstruct 3D poses of people who move
throughout the space rather than a fixed point, we fuse the amplitude and phase
into Channel State Information (CSI) images which can provide both pose and
position information. Besides, we design a neural network to extract features
that are only associated with poses from CSI images and then convert the
features into key-point coordinates. Experimental results show that Wi-Mose can
localize key-point with 29.7mm and 37.8mm Procrustes analysis Mean Per Joint
Position Error (P-MPJPE) in the Line of Sight (LoS) and Non-Line of Sight
(NLoS) scenarios, respectively, achieving higher performance than the
state-of-the-art method. The results indicate that Wi-Mose can capture
high-precision 3D human poses throughout the space.
</p>
<a href="http://arxiv.org/abs/2012.14066" target="_blank">arXiv:2012.14066</a> [<a href="http://arxiv.org/pdf/2012.14066" target="_blank">pdf</a>]

<h2>Generative Partial Visual-Tactile Fused Object Clustering. (arXiv:2012.14070v1 [cs.RO])</h2>
<h3>Tao Zhang, Yang Cong, Gan Sun, Jiahua Dong, Yuyang Liu, Zhengming Ding</h3>
<p>Visual-tactile fused sensing for object clustering has achieved significant
progresses recently, since the involvement of tactile modality can effectively
improve clustering performance. However, the missing data (i.e., partial data)
issues always happen due to occlusion and noises during the data collecting
process. This issue is not well solved by most existing partial multi-view
clustering methods for the heterogeneous modality challenge. Naively employing
these methods would inevitably induce a negative effect and further hurt the
performance. To solve the mentioned challenges, we propose a Generative Partial
Visual-Tactile Fused (i.e., GPVTF) framework for object clustering. More
specifically, we first do partial visual and tactile features extraction from
the partial visual and tactile data, respectively, and encode the extracted
features in modality-specific feature subspaces. A conditional cross-modal
clustering generative adversarial network is then developed to synthesize one
modality conditioning on the other modality, which can compensate missing
samples and align the visual and tactile modalities naturally by adversarial
learning. To the end, two pseudo-label based KL-divergence losses are employed
to update the corresponding modality-specific encoders. Extensive comparative
experiments on three public visual-tactile datasets prove the effectiveness of
our method.
</p>
<a href="http://arxiv.org/abs/2012.14070" target="_blank">arXiv:2012.14070</a> [<a href="http://arxiv.org/pdf/2012.14070" target="_blank">pdf</a>]

<h2>Human Expression Recognition using Facial Shape Based Fourier Descriptors Fusion. (arXiv:2012.14097v1 [cs.CV])</h2>
<h3>Ali Raza Shahid, Sheheryar Khan, Hong Yan</h3>
<p>Dynamic facial expression recognition has many useful applications in social
networks, multimedia content analysis, security systems and others. This
challenging process must be done under recurrent problems of image illumination
and low resolution which changes at partial occlusions. This paper aims to
produce a new facial expression recognition method based on the changes in the
facial muscles. The geometric features are used to specify the facial regions
i.e., mouth, eyes, and nose. The generic Fourier shape descriptor in
conjunction with elliptic Fourier shape descriptor is used as an attribute to
represent different emotions under frequency spectrum features. Afterwards a
multi-class support vector machine is applied for classification of seven human
expression. The statistical analysis showed our approach obtained overall
competent recognition using 5-fold cross validation with high accuracy on
well-known facial expression dataset.
</p>
<a href="http://arxiv.org/abs/2012.14097" target="_blank">arXiv:2012.14097</a> [<a href="http://arxiv.org/pdf/2012.14097" target="_blank">pdf</a>]

<h2>Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds Globally Optimal Policy. (arXiv:2012.14098v1 [cs.LG])</h2>
<h3>Han Zhong, Ethan X. Fang, Zhuoran Yang, Zhaoran Wang</h3>
<p>While deep reinforcement learning has achieved tremendous successes in
various applications, most existing works only focus on maximizing the expected
value of total return and thus ignore its inherent stochasticity. Such
stochasticity is also known as the aleatoric uncertainty and is closely related
to the notion of risk. In this work, we make the first attempt to study
risk-sensitive deep reinforcement learning under the average reward setting
with the variance risk criteria. In particular, we focus on a
variance-constrained policy optimization problem where the goal is to find a
policy that maximizes the expected value of the long-run average reward,
subject to a constraint that the long-run variance of the average reward is
upper bounded by a threshold. Utilizing Lagrangian and Fenchel dualities, we
transform the original problem into an unconstrained saddle-point policy
optimization problem, and propose an actor-critic algorithm that iteratively
and efficiently updates the policy, the Lagrange multiplier, and the Fenchel
dual variable. When both the value and policy functions are represented by
multi-layer overparameterized neural networks, we prove that our actor-critic
algorithm generates a sequence of policies that finds a globally optimal policy
at a sublinear rate.
</p>
<a href="http://arxiv.org/abs/2012.14098" target="_blank">arXiv:2012.14098</a> [<a href="http://arxiv.org/pdf/2012.14098" target="_blank">pdf</a>]

<h2>ACT: Asymptotic Conditional Transport. (arXiv:2012.14100v1 [stat.ML])</h2>
<h3>Huangjie Zheng, Mingyuan Zhou</h3>
<p>We propose conditional transport (CT) as a new divergence to measure the
difference between two probability distributions. The CT divergence consists of
the expected cost of a forward CT, which constructs a navigator to
stochastically transport a data point of one distribution to the other
distribution, and that of a backward CT which reverses the transport direction.
To apply it to the distributions whose probability density functions are
unknown but random samples are accessible, we further introduce asymptotic CT
(ACT), whose estimation only requires access to mini-batch based discrete
empirical distributions. Equipped with two navigators that amortize the
computation of conditional transport plans, the ACT divergence comes with
unbiased sample gradients that are straightforward to compute, making it
amenable to mini-batch stochastic gradient descent based optimization. When
applied to train a generative model, the ACT divergence is shown to strike a
good balance between mode covering and seeking behaviors and strongly resist
mode collapse. To model high-dimensional data, we show that it is sufficient to
modify the adversarial game of an existing generative adversarial network (GAN)
to a game played by a generator, a forward navigator, and a backward navigator,
which try to minimize a distribution-to-distribution transport cost by
optimizing both the distribution of the generator and conditional transport
plans specified by the navigators, versus a critic that does the opposite by
inflating the point-to-point transport cost. On a wide variety of benchmark
datasets for generative modeling, substituting the default statistical distance
of an existing GAN with the ACT divergence is shown to consistently improve the
performance.
</p>
<a href="http://arxiv.org/abs/2012.14100" target="_blank">arXiv:2012.14100</a> [<a href="http://arxiv.org/pdf/2012.14100" target="_blank">pdf</a>]

<h2>Towards A Category-extended Object Detector without Relabeling or Conflicts. (arXiv:2012.14115v1 [cs.CV])</h2>
<h3>Bowen Zhao, Chen Chen, Wanpeng Xiao, Xi Xiao, Qi Ju, Shutao Xia</h3>
<p>Object detectors are typically learned based on fully-annotated training data
with fixed pre-defined categories. However, not all possible categories of
interest can be known beforehand, as classes are often required to be increased
progressively in many realistic applications. In such scenario, only the
original training set annotated with the old classes and some new training data
labeled with the new classes are available. In this paper, we aim at leaning a
strong unified detector that can handle all categories based on the limited
datasets without extra manual labor. Vanilla joint training without considering
label ambiguity leads to heavy biases and poor performance due to the
incomplete annotations. To avoid such situation, we propose a practical
framework which focuses on three aspects: better base model, better unlabeled
ground-truth mining strategy and better retraining method with pseudo
annotations. First, a conflict-free loss is proposed to obtain a usable base
detector. Second, we employ Monte Carlo Dropout to calculate the localization
confidence, combined with the classification confidence, to mine more accurate
bounding boxes. Third, we explore several strategies for making better use of
pseudo annotations during retraining to achieve more powerful detectors.
Extensive experiments conducted on multiple datasets demonstrate the
effectiveness of our framework for category-extended object detectors.
</p>
<a href="http://arxiv.org/abs/2012.14115" target="_blank">arXiv:2012.14115</a> [<a href="http://arxiv.org/pdf/2012.14115" target="_blank">pdf</a>]

<h2>Spectral Analysis for Semantic Segmentation with Applications on Feature Truncation and Weak Annotation. (arXiv:2012.14123v1 [cs.CV])</h2>
<h3>Li-Wei Chen, Wei-Chen Chiu, Chin-Tien Wu</h3>
<p>The current neural networks for semantic segmentation usually predict the
pixel-wise semantics on the down-sampled grid of images to alleviate the
computational cost for dense maps. However, the accuracy of resultant
segmentation maps may also be down graded particularly in the regions near
object boundaries. In this paper, we advance to have a deeper investigation on
the sampling efficiency of the down-sampled grid. By applying the spectral
analysis that analyze on the network back propagation process in frequency
domain, we discover that cross-entropy is mainly contributed by the
low-frequency components of segmentation maps, as well as that of the feature
in CNNs. The network performance maintains as long as the resolution of the
down sampled grid meets the cut-off frequency. Such finding leads us to propose
a simple yet effective feature truncation method that limits the feature size
in CNNs and removes the associated high-frequency components. This method can
not only reduce the computational cost but also maintain the performance of
semantic segmentation networks. Moreover, one can seamlessly integrate this
method with the typical network pruning approaches for further model reduction.
On the other hand, we propose to employee a block-wise weak annotation for
semantic segmentation that captures the low-frequency information of the
segmentation map and is easy to collect. Using the proposed analysis scheme,
one can easily estimate the efficacy of the block-wise annotation and the
feature truncation method.
</p>
<a href="http://arxiv.org/abs/2012.14123" target="_blank">arXiv:2012.14123</a> [<a href="http://arxiv.org/pdf/2012.14123" target="_blank">pdf</a>]

<h2>Joint Intensity-Gradient Guided Generative Modeling for Colorization. (arXiv:2012.14130v1 [cs.CV])</h2>
<h3>Kai Hong, Jin Li, Wanyun Li, Cailian Yang, Minghui Zhang, Yuhao Wang, Qiegen Liu</h3>
<p>This paper proposes an iterative generative model for solving the automatic
colorization problem. Although previous researches have shown the capability to
generate plausible color, the edge color overflow and the requirement of the
reference images still exist. The starting point of the unsupervised learning
in this study is the ob?servation that the gradient map possesses latent
infor?mation of the image. Therefore, the inference process of the generative
modeling is conducted in joint intensity-gradient domain. Specifically, a set
of intensity-gradient formed high-dimensional tensors, as the network input,
are used to train a powerful noise conditional score network at the training
phase. Furthermore, the joint intensity-gradient constraint in data-fidelity
term is proposed to limit the degree of freedom within generative model at the
iterative colorization stage, and it is conducive to edge-preserving. Extensive
experiments demonstrated that the system out?performed state-of-the-art methods
whether in quantitative comparisons or user study.
</p>
<a href="http://arxiv.org/abs/2012.14130" target="_blank">arXiv:2012.14130</a> [<a href="http://arxiv.org/pdf/2012.14130" target="_blank">pdf</a>]

<h2>Deep Graph Normalizer: A Geometric Deep Learning Approach for Estimating Connectional Brain Templates. (arXiv:2012.14131v1 [cs.CV])</h2>
<h3>Mustafa Burak Gurbuz, Islem Rekik</h3>
<p>A connectional brain template (CBT) is a normalized graph-based
representation of a population of brain networks also regarded as an average
connectome. CBTs are powerful tools for creating representative maps of brain
connectivity in typical and atypical populations. Particularly, estimating a
well-centered and representative CBT for populations of multi-view brain
networks (MVBN) is more challenging since these networks sit on complex
manifolds and there is no easy way to fuse different heterogeneous network
views. This problem remains unexplored with the exception of a few recent works
rooted in the assumption that the relationship between connectomes are mostly
linear. However, such an assumption fails to capture complex patterns and
non-linear variation across individuals. Besides, existing methods are simply
composed of sequential MVBN processing blocks without any feedback mechanism,
leading to error accumulation. To address these issues, we propose Deep Graph
Normalizer (DGN), the first geometric deep learning (GDL) architecture for
normalizing a population of MVBNs by integrating them into a single
connectional brain template. Our end-to-end DGN learns how to fuse multi-view
brain networks while capturing non-linear patterns across subjects and
preserving brain graph topological properties by capitalizing on graph
convolutional neural networks. We also introduce a randomized weighted loss
function which also acts as a regularizer to minimize the distance between the
population of MVBNs and the estimated CBT, thereby enforcing its centeredness.
We demonstrate that DGN significantly outperforms existing state-of-the-art
methods on estimating CBTs on both small-scale and large-scale connectomic
datasets in terms of both representativeness and discriminability (i.e.,
identifying distinctive connectivities fingerprinting each brain network
population).
</p>
<a href="http://arxiv.org/abs/2012.14131" target="_blank">arXiv:2012.14131</a> [<a href="http://arxiv.org/pdf/2012.14131" target="_blank">pdf</a>]

<h2>Multiple Document Datasets Pre-training Improves Text Line Detection With Deep Neural Networks. (arXiv:2012.14163v1 [cs.CV])</h2>
<h3>M&#xe9;lodie Boillet, Christopher Kermorvant, Thierry Paquet</h3>
<p>In this paper, we introduce a fully convolutional network for the document
layout analysis task. While state-of-the-art methods are using models
pre-trained on natural scene images, our method Doc-UFCN relies on a U-shaped
model trained from scratch for detecting objects from historical documents. We
consider the line segmentation task and more generally the layout analysis
problem as a pixel-wise classification task then our model outputs a
pixel-labeling of the input images. We show that Doc-UFCN outperforms
state-of-the-art methods on various datasets and also demonstrate that the
pre-trained parts on natural scene images are not required to reach good
results. In addition, we show that pre-training on multiple document datasets
can improve the performances. We evaluate the models using various metrics to
have a fair and complete comparison between the methods.
</p>
<a href="http://arxiv.org/abs/2012.14163" target="_blank">arXiv:2012.14163</a> [<a href="http://arxiv.org/pdf/2012.14163" target="_blank">pdf</a>]

<h2>Manifold learning with arbitrary norms. (arXiv:2012.14172v1 [cs.LG])</h2>
<h3>Joe Kileel, Amit Moscovich, Nathan Zelesko, Amit Singer</h3>
<p>Manifold learning methods play a prominent role in nonlinear dimensionality
reduction and other tasks involving high-dimensional data sets with low
intrinsic dimensionality. Many of these methods are graph-based: they associate
a vertex with each data point and a weighted edge between each pair of close
points. Existing theory shows, under certain conditions, that the Laplacian
matrix of the constructed graph converges to the Laplace-Beltrami operator of
the data manifold. However, this result assumes the Euclidean norm is used for
measuring distances. In this paper, we determine the limiting differential
operator for graph Laplacians constructed using $\textit{any}$ norm. The proof
involves a subtle interplay between the second fundamental form of the
underlying manifold and the convex geometry of the norm's unit ball. To
motivate the use of non-Euclidean norms, we show in a numerical simulation that
manifold learning based on Earthmover's distances outperforms the standard
Euclidean variant for learning molecular shape spaces, in terms of both sample
complexity and computational complexity.
</p>
<a href="http://arxiv.org/abs/2012.14172" target="_blank">arXiv:2012.14172</a> [<a href="http://arxiv.org/pdf/2012.14172" target="_blank">pdf</a>]

<h2>Playing to distraction: towards a robust training of CNN classifiers through visual explanation techniques. (arXiv:2012.14173v1 [cs.CV])</h2>
<h3>David Morales, Estefania Talavera, Beatriz Remeseiro</h3>
<p>The field of deep learning is evolving in different directions, with still
the need for more efficient training strategies. In this work, we present a
novel and robust training scheme that integrates visual explanation techniques
in the learning process. Unlike the attention mechanisms that focus on the
relevant parts of images, we aim to improve the robustness of the model by
making it pay attention to other regions as well. Broadly speaking, the idea is
to distract the classifier in the learning process to force it to focus not
only on relevant regions but also on those that, a priori, are not so
informative for the discrimination of the class. We tested the proposed
approach by embedding it into the learning process of a convolutional neural
network for the analysis and classification of two well-known datasets, namely
Stanford cars and FGVC-Aircraft. Furthermore, we evaluated our model on a
real-case scenario for the classification of egocentric images, allowing us to
obtain relevant information about peoples' lifestyles. In particular, we work
on the challenging EgoFoodPlaces dataset, achieving state-of-the-art results
with a lower level of complexity. The obtained results indicate the suitability
of our proposed training scheme for image classification, improving the
robustness of the final model.
</p>
<a href="http://arxiv.org/abs/2012.14173" target="_blank">arXiv:2012.14173</a> [<a href="http://arxiv.org/pdf/2012.14173" target="_blank">pdf</a>]

<h2>Deep Visual Domain Adaptation. (arXiv:2012.14176v1 [cs.CV])</h2>
<h3>Gabriela Csurka</h3>
<p>Domain adaptation (DA) aims at improving the performance of a model on target
domains by transferring the knowledge contained in different but related source
domains. With recent advances in deep learning models which are extremely data
hungry, the interest for visual DA has significantly increased in the last
decade and the number of related work in the field exploded. The aim of this
paper, therefore, is to give a comprehensive overview of deep domain adaptation
methods for computer vision applications. First, we detail and compared
different possible ways of exploiting deep architectures for domain adaptation.
Then, we propose an overview of recent trends in deep visual DA. Finally, we
mention a few improvement strategies, orthogonal to these methods, that can be
applied to these models. While we mainly focus on image classification, we give
pointers to papers that extend these ideas for other applications such as
semantic segmentation, object detection, person re-identifications, and others.
</p>
<a href="http://arxiv.org/abs/2012.14176" target="_blank">arXiv:2012.14176</a> [<a href="http://arxiv.org/pdf/2012.14176" target="_blank">pdf</a>]

<h2>A cortical-inspired sub-Riemannian model for Poggendorff-type visual illusions. (arXiv:2012.14184v1 [cs.CV])</h2>
<h3>Emre Baspinar, Luca Calatroni, Valentina Franceschi, Dario Prandi</h3>
<p>We consider Wilson-Cowan-type models for the mathematical
orientation-dependent description of Poggendorff-like illusions. Our modelling
improves the cortical-inspired approaches used in [1,2] by encoding within the
neuronal interaction term the sub-Riemannian heat kernel, in agreement with the
intrinsically anisotropic functional architecture of V1 based both on local and
lateral connections. For the numerical realisation of both models, we consider
standard gradient descent algorithms combined with Fourier-based approaches for
the efficient computation of the sub-Laplacian evolution. Our numerical results
show that the use of the sub-Riemannian kernel allows to reproduce numerically
visual misperceptions and inpainting-type biases that standard approaches were
not able to replicate [3].
</p>
<a href="http://arxiv.org/abs/2012.14184" target="_blank">arXiv:2012.14184</a> [<a href="http://arxiv.org/pdf/2012.14184" target="_blank">pdf</a>]

<h2>Data augmentation and image understanding. (arXiv:2012.14185v1 [cs.LG])</h2>
<h3>Alex Hernandez-Garcia</h3>
<p>Interdisciplinary research is often at the core of scientific progress. This
dissertation explores some advantageous synergies between machine learning,
cognitive science and neuroscience. In particular, this thesis focuses on
vision and images. The human visual system has been widely studied from both
behavioural and neuroscientific points of view, as vision is the dominant sense
of most people. In turn, machine vision has also been an active area of
research, currently dominated by the use of artificial neural networks. This
work focuses on learning representations that are more aligned with visual
perception and the biological vision. For that purpose, I have studied tools
and aspects from cognitive science and computational neuroscience, and
attempted to incorporate them into machine learning models of vision.

A central subject of this dissertation is data augmentation, a commonly used
technique for training artificial neural networks to augment the size of data
sets through transformations of the images. Although often overlooked, data
augmentation implements transformations that are perceptually plausible, since
they correspond to the transformations we see in our visual world -- changes in
viewpoint or illumination, for instance. Furthermore, neuroscientists have
found that the brain invariantly represents objects under these
transformations. Throughout this dissertation, I use these insights to analyse
data augmentation as a particularly useful inductive bias, a more effective
regularisation method for artificial neural networks, and as the framework to
analyse and improve the invariance of vision models to perceptually plausible
transformations. Overall, this work aims to shed more light on the properties
of data augmentation and demonstrate the potential of interdisciplinary
research.
</p>
<a href="http://arxiv.org/abs/2012.14185" target="_blank">arXiv:2012.14185</a> [<a href="http://arxiv.org/pdf/2012.14185" target="_blank">pdf</a>]

<h2>Action Recognition with Kernel-based Graph Convolutional Networks. (arXiv:2012.14186v1 [cs.CV])</h2>
<h3>Hichem Sahbi</h3>
<p>Learning graph convolutional networks (GCNs) is an emerging field which aims
at generalizing deep learning to arbitrary non-regular domains. Most of the
existing GCNs follow a neighborhood aggregation scheme, where the
representation of a node is recursively obtained by aggregating its neighboring
node representations using averaging or sorting operations. However, these
operations are either ill-posed or weak to be discriminant or increase the
number of training parameters and thereby the computational complexity and the
risk of overfitting. In this paper, we introduce a novel GCN framework that
achieves spatial graph convolution in a reproducing kernel Hilbert space
(RKHS). The latter makes it possible to design, via implicit kernel
representations, convolutional graph filters in a high dimensional and more
discriminating space without increasing the number of training parameters. The
particularity of our GCN model also resides in its ability to achieve
convolutions without explicitly realigning nodes in the receptive fields of the
learned graph filters with those of the input graphs, thereby making
convolutions permutation agnostic and well defined. Experiments conducted on
the challenging task of skeleton-based action recognition show the superiority
of the proposed method against different baselines as well as the related work.
</p>
<a href="http://arxiv.org/abs/2012.14186" target="_blank">arXiv:2012.14186</a> [<a href="http://arxiv.org/pdf/2012.14186" target="_blank">pdf</a>]

<h2>Signed Graph Diffusion Network. (arXiv:2012.14191v1 [cs.LG])</h2>
<h3>Jinhong Jung, Jaemin Yoo, U Kang</h3>
<p>Given a signed social graph, how can we learn appropriate node
representations to infer the signs of missing edges? Signed social graphs have
received considerable attention to model trust relationships. Learning node
representations is crucial to effectively analyze graph data, and various
techniques such as network embedding and graph convolutional network (GCN) have
been proposed for learning signed graphs. However, traditional network
embedding methods are not end-to-end for a specific task such as link sign
prediction, and GCN-based methods suffer from a performance degradation problem
when their depth increases. In this paper, we propose Signed Graph Diffusion
Network (SGDNet), a novel graph neural network that achieves end-to-end node
representation learning for link sign prediction in signed social graphs. We
propose a random walk technique specially designed for signed graphs so that
SGDNet effectively diffuses hidden node features. Through extensive
experiments, we demonstrate that SGDNet outperforms state-of-the-art models in
terms of link sign prediction accuracy.
</p>
<a href="http://arxiv.org/abs/2012.14191" target="_blank">arXiv:2012.14191</a> [<a href="http://arxiv.org/pdf/2012.14191" target="_blank">pdf</a>]

<h2>Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization. (arXiv:2012.14193v1 [cs.LG])</h2>
<h3>Stanislaw Jastrzebski, Devansh Arpit, Oliver Astrand, Giancarlo Kerg, Huan Wang, Caiming Xiong, Richard Socher, Kyunghyun Cho, Krzysztof Geras</h3>
<p>The early phase of training has been shown to be important in two ways for
deep neural networks. First, the degree of regularization in this phase
significantly impacts the final generalization. Second, it is accompanied by a
rapid change in the local loss curvature influenced by regularization choices.
Connecting these two findings, we show that stochastic gradient descent (SGD)
implicitly penalizes the trace of the Fisher Information Matrix (FIM) from the
beginning of training. We argue it is an implicit regularizer in SGD by showing
that explicitly penalizing the trace of the FIM can significantly improve
generalization. We further show that the early value of the trace of the FIM
correlates strongly with the final generalization. We highlight that in the
absence of implicit or explicit regularization, the trace of the FIM can
increase to a large value early in training, to which we refer as catastrophic
Fisher explosion. Finally, to gain insight into the regularization effect of
penalizing the trace of the FIM, we show that 1) it limits memorization by
reducing the learning speed of examples with noisy labels more than that of the
clean examples, and 2) trajectories with a low initial trace of the FIM end in
flat minima, which are commonly associated with good generalization.
</p>
<a href="http://arxiv.org/abs/2012.14193" target="_blank">arXiv:2012.14193</a> [<a href="http://arxiv.org/pdf/2012.14193" target="_blank">pdf</a>]

<h2>TransPose: Towards Explainable Human Pose Estimation by Transformer. (arXiv:2012.14214v1 [cs.CV])</h2>
<h3>Sen Yang, Zhibin Quan, Mu Nie, Wankou Yang</h3>
<p>Deep Convolutional Neural Networks (CNNs) have made remarkable progress on
human pose estimation task. However, there is no explicit understanding of how
the locations of body keypoints are predicted by CNN, and it is also unknown
what spatial dependency relationships between structural variables are learned
in the model. To explore these questions, we construct an explainable model
named TransPose based on Transformer architecture and low-level convolutional
blocks. Given an image, the attention layers built in Transformer can capture
long-range spatial relationships between keypoints and explain what
dependencies the predicted keypoints locations highly rely on. We analyze the
rationality of using attention as the explanation to reveal the spatial
dependencies in this task. The revealed dependencies are image-specific and
variable across different keypoint types, layer depths, or trained models. The
experiments show that TransPose can accurately predict the positions of
keypoints. It achieves state-of-the-art performance on COCO dataset, while
being more interpretable, lightweight, and efficient than mainstream fully
convolutional architectures.
</p>
<a href="http://arxiv.org/abs/2012.14214" target="_blank">arXiv:2012.14214</a> [<a href="http://arxiv.org/pdf/2012.14214" target="_blank">pdf</a>]

<h2>Causal World Models by Unsupervised Deconfounding of Physical Dynamics. (arXiv:2012.14228v1 [cs.LG])</h2>
<h3>Minne Li, Mengyue Yang, Furui Liu, Xu Chen, Zhitang Chen, Jun Wang</h3>
<p>The capability of imagining internally with a mental model of the world is
vitally important for human cognition. If a machine intelligent agent can learn
a world model to create a "dream" environment, it can then internally ask
what-if questions -- simulate the alternative futures that haven't been
experienced in the past yet -- and make optimal decisions accordingly. Existing
world models are established typically by learning spatio-temporal regularities
embedded from the past sensory signal without taking into account confounding
factors that influence state transition dynamics. As such, they fail to answer
the critical counterfactual questions about "what would have happened" if a
certain action policy was taken. In this paper, we propose Causal World Models
(CWMs) that allow unsupervised modeling of relationships between the intervened
observations and the alternative futures by learning an estimator of the latent
confounding factors. We empirically evaluate our method and demonstrate its
effectiveness in a variety of physical reasoning environments. Specifically, we
show reductions in sample complexity for reinforcement learning tasks and
improvements in counterfactual physical reasoning.
</p>
<a href="http://arxiv.org/abs/2012.14228" target="_blank">arXiv:2012.14228</a> [<a href="http://arxiv.org/pdf/2012.14228" target="_blank">pdf</a>]

<h2>Longitudinal diffusion MRI analysis using Segis-Net: a single-step deep-learning framework for simultaneous segmentation and registration. (arXiv:2012.14230v1 [cs.CV])</h2>
<h3>Bo Li, Wiro J. Niessen, Stefan Klein, Marius de Groot, M. Arfan Ikram, Meike W. Vernooij, Esther E. Bron</h3>
<p>This work presents a single-step deep-learning framework for longitudinal
image analysis, coined Segis-Net. To optimally exploit information available in
longitudinal data, this method concurrently learns a multi-class segmentation
and nonlinear registration. Segmentation and registration are modeled using a
convolutional neural network and optimized simultaneously for their mutual
benefit. An objective function that optimizes spatial correspondence for the
segmented structures across time-points is proposed. We applied Segis-Net to
the analysis of white matter tracts from N=8045 longitudinal brain MRI datasets
of 3249 elderly individuals. Segis-Net approach showed a significant increase
in registration accuracy, spatio-temporal segmentation consistency, and
reproducibility comparing with two multistage pipelines. This also led to a
significant reduction in the sample-size that would be required to achieve the
same statistical power in analyzing tract-specific measures. Thus, we expect
that Segis-Net can serve as a new reliable tool to support longitudinal imaging
studies to investigate macro- and microstructural brain changes over time.
</p>
<a href="http://arxiv.org/abs/2012.14230" target="_blank">arXiv:2012.14230</a> [<a href="http://arxiv.org/pdf/2012.14230" target="_blank">pdf</a>]

<h2>DeepSurfels: Learning Online Appearance Fusion. (arXiv:2012.14240v1 [cs.CV])</h2>
<h3>Marko Mihajlovic, Silvan Weder, Marc Pollefeys, Martin R. Oswald</h3>
<p>We present DeepSurfels, a novel hybrid scene representation for geometry and
appearance information. DeepSurfels combines explicit and neural building
blocks to jointly encode geometry and appearance information. In contrast to
established representations, DeepSurfels better represents high-frequency
textures, is well-suited for online updates of appearance information, and can
be easily combined with machine learning methods. We further present an
end-to-end trainable online appearance fusion pipeline that fuses information
provided by RGB images into the proposed scene representation and is trained
using self-supervision imposed by the reprojection error with respect to the
input images. Our method compares favorably to classical texture mapping
approaches as well as recently proposed learning-based techniques. Moreover, we
demonstrate lower runtime, improved generalization capabilities, and better
scalability to larger scenes compared to existing methods.
</p>
<a href="http://arxiv.org/abs/2012.14240" target="_blank">arXiv:2012.14240</a> [<a href="http://arxiv.org/pdf/2012.14240" target="_blank">pdf</a>]

<h2>Testing for concept shift online. (arXiv:2012.14246v1 [cs.LG])</h2>
<h3>Vladimir Vovk</h3>
<p>This note continues study of exchangeability martingales, i.e., processes
that are martingales under any exchangeable distribution for the observations.
Such processes can be used for detecting violations of the IID assumption,
which is commonly made in machine learning. Violations of the IID assumption
are sometimes referred to as dataset shift, and dataset shift is sometimes
subdivided into concept shift, covariate shift, etc. Our primary interest is in
concept shift, but we will also discuss exchangeability martingales that
decompose perfectly into two components one of which detects concept shift and
the other detects what we call label shift. Our methods will be based on
techniques of conformal prediction.
</p>
<a href="http://arxiv.org/abs/2012.14246" target="_blank">arXiv:2012.14246</a> [<a href="http://arxiv.org/pdf/2012.14246" target="_blank">pdf</a>]

<h2>Lattice-Free MMI Adaptation Of Self-Supervised Pretrained Acoustic Models. (arXiv:2012.14252v1 [cs.LG])</h2>
<h3>Apoorv Vyas, Srikanth Madikeri, Herv&#xe9; Bourlard</h3>
<p>In this work, we propose lattice-free MMI (LFMMI) for supervised adaptation
of self-supervised pretrained acoustic model. We pretrain a Transformer model
on thousand hours of untranscribed Librispeech data followed by supervised
adaptation with LFMMI on three different datasets. Our results show that
fine-tuning with LFMMI, we consistently obtain relative WER improvements of 10%
and 35.3% on the clean and other test sets of Librispeech (100h), 10.8% on
Switchboard (300h), and 4.3% on Swahili (38h) and 4.4% on Tagalog (84h)
compared to the baseline trained only with supervised data.
</p>
<a href="http://arxiv.org/abs/2012.14252" target="_blank">arXiv:2012.14252</a> [<a href="http://arxiv.org/pdf/2012.14252" target="_blank">pdf</a>]

<h2>Instance Segmentation of Industrial Point Cloud Data. (arXiv:2012.14253v1 [cs.CV])</h2>
<h3>Eva Agapaki, Ioannis Brilakis</h3>
<p>The challenge that this paper addresses is how to efficiently minimize the
cost and manual labour for automatically generating object oriented geometric
Digital Twins (gDTs) of industrial facilities, so that the benefits provide
even more value compared to the initial investment to generate these models.
Our previous work achieved the current state-of-the-art class segmentation
performance (75% average accuracy per point and average AUC 90% in the CLOI
dataset classes) as presented in (Agapaki and Brilakis 2020) and directly
produces labelled point clusters of the most important to model objects (CLOI
classes) from laser scanned industrial data. CLOI stands for C-shapes,
L-shapes, O-shapes, I-shapes and their combinations. However, the problem of
automated segmentation of individual instances that can then be used to fit
geometric shapes remains unsolved. We argue that the use of instance
segmentation algorithms has the theoretical potential to provide the output
needed for the generation of gDTs. We solve instance segmentation in this paper
through (a) using a CLOI-Instance graph connectivity algorithm that segments
the point clusters of an object class into instances and (b) boundary
segmentation of points that improves step (a). Our method was tested on the
CLOI benchmark dataset (Agapaki et al. 2019) and segmented instances with
76.25% average precision and 70% average recall per point among all classes.
This proved that it is the first to automatically segment industrial point
cloud shapes with no prior knowledge other than the class point label and is
the bedrock for efficient gDT generation in cluttered industrial point clouds.
</p>
<a href="http://arxiv.org/abs/2012.14253" target="_blank">arXiv:2012.14253</a> [<a href="http://arxiv.org/pdf/2012.14253" target="_blank">pdf</a>]

<h2>Compositional Prototype Network with Multi-view Comparision for Few-Shot Point Cloud Semantic Segmentation. (arXiv:2012.14255v1 [cs.CV])</h2>
<h3>Xiaoyu Chen, Chi Zhang, Guosheng Lin, Jing Han</h3>
<p>Point cloud segmentation is a fundamental visual understanding task in 3D
vision. A fully supervised point cloud segmentation network often requires a
large amount of data with point-wise annotations, which is expensive to obtain.
In this work, we present the Compositional Prototype Network that can undertake
point cloud segmentation with only a few labeled training data. Inspired by the
few-shot learning literature in images, our network directly transfers label
information from the limited training data to unlabeled test data for
prediction. The network decomposes the representations of complex point cloud
data into a set of local regional representations and utilizes them to
calculate the compositional prototypes of a visual concept. Our network
includes a key Multi-View Comparison Component that exploits the redundant
views of the support set. To evaluate the proposed method, we create a new
segmentation benchmark dataset, ScanNet-$6^i$, which is built upon ScanNet
dataset. Extensive experiments show that our method outperforms baselines with
a significant advantage. Moreover, when we use our network to handle the
long-tail problem in a fully supervised point cloud segmentation dataset, it
can also effectively boost the performance of the few-shot classes.
</p>
<a href="http://arxiv.org/abs/2012.14255" target="_blank">arXiv:2012.14255</a> [<a href="http://arxiv.org/pdf/2012.14255" target="_blank">pdf</a>]

<h2>Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset. (arXiv:2012.14259v1 [cs.CV])</h2>
<h3>Cristina Palmero, Javier Selva, Sorina Smeureanu, Julio C. S. Jacques Junior, Albert Clap&#xe9;s, Alexa Mosegu&#xed;, Zejian Zhang, David Gallardo, Georgina Guilera, David Leiva, Sergio Escalera</h3>
<p>This paper introduces UDIVA, a new non-acted dataset of face-to-face dyadic
interactions, where interlocutors perform competitive and collaborative tasks
with different behavior elicitation and cognitive workload. The dataset
consists of 90.5 hours of dyadic interactions among 147 participants
distributed in 188 sessions, recorded using multiple audiovisual and
physiological sensors. Currently, it includes sociodemographic, self- and
peer-reported personality, internal state, and relationship profiling from
participants. As an initial analysis on UDIVA, we propose a transformer-based
method for self-reported personality inference in dyadic scenarios, which uses
audiovisual data and different sources of context from both interlocutors to
regress a target person's personality traits. Preliminary results from an
incremental study show consistent improvements when using all available context
information.
</p>
<a href="http://arxiv.org/abs/2012.14259" target="_blank">arXiv:2012.14259</a> [<a href="http://arxiv.org/pdf/2012.14259" target="_blank">pdf</a>]

<h2>A Survey on Neural Network Interpretability. (arXiv:2012.14261v1 [cs.LG])</h2>
<h3>Yu Zhang, Peter Ti&#x148;o, Ale&#x161; Leonardis, Ke Tang</h3>
<p>Along with the great success of deep neural networks, there is also growing
concern about their black-box nature. The interpretability issue affects
people's trust on deep learning systems. It is also related to many ethical
problems, e.g., algorithmic discrimination. Moreover, interpretability is a
desired property for deep networks to become powerful tools in other research
fields, e.g., drug discovery and genomics. In this survey, we conduct a
comprehensive review of the neural network interpretability research. We first
clarify the definition of interpretability as it has been used in many
different contexts. Then we elaborate on the importance of interpretability and
propose a novel taxonomy organized along three dimensions: type of engagement
(passive vs. active interpretation approaches), the type of explanation, and
the focus (from local to global interpretability). This taxonomy provides a
meaningful 3D view of distribution of papers from the relevant literature as
two of the dimensions are not simply categorical but allow ordinal
subcategories. Finally, we summarize the existing interpretability evaluation
methods and suggest possible research directions inspired by our new taxonomy.
</p>
<a href="http://arxiv.org/abs/2012.14261" target="_blank">arXiv:2012.14261</a> [<a href="http://arxiv.org/pdf/2012.14261" target="_blank">pdf</a>]

<h2>Lifelong Learning in Multi-Armed Bandits. (arXiv:2012.14264v1 [cs.LG])</h2>
<h3>Matthieu Jedor, Jonathan Lou&#xeb;dec, Vianney Perchet</h3>
<p>Continuously learning and leveraging the knowledge accumulated from prior
tasks in order to improve future performance is a long standing machine
learning problem. In this paper, we study the problem in the multi-armed bandit
framework with the objective to minimize the total regret incurred over a
series of tasks. While most bandit algorithms are designed to have a low
worst-case regret, we examine here the average regret over bandit instances
drawn from some prior distribution which may change over time. We specifically
focus on confidence interval tuning of UCB algorithms. We propose a bandit over
bandit approach with greedy algorithms and we perform extensive experimental
evaluations in both stationary and non-stationary environments. We further
apply our solution to the mortal bandit problem, showing empirical improvement
over previous work.
</p>
<a href="http://arxiv.org/abs/2012.14264" target="_blank">arXiv:2012.14264</a> [<a href="http://arxiv.org/pdf/2012.14264" target="_blank">pdf</a>]

<h2>UWB Propagation Characteristics of Human-to-Robot Communication in Automated Collaborative Warehouse. (arXiv:2012.14278v1 [cs.RO])</h2>
<h3>Branimir Iv&#x161;i&#x107;, Juraj Bartoli&#x107;, Zvonimir &#x160;ipu&#x161;, Josip Babi&#x107;</h3>
<p>Propagation of UWB Gaussian signal in a model of automated collaborative
warehouse is analyzed using ray tracing method. The transmitting antenna is
placed on the human body while the received power profiles in warehouse
containing empty racks and racks filled with different loads are calculated.
This gives rise to estimation of safe communication range between humans and
robots.
</p>
<a href="http://arxiv.org/abs/2012.14278" target="_blank">arXiv:2012.14278</a> [<a href="http://arxiv.org/pdf/2012.14278" target="_blank">pdf</a>]

<h2>Latent Compass: Creation by Navigation. (arXiv:2012.14283v1 [cs.AI])</h2>
<h3>Sarah Schwettmann, Hendrik Strobelt, Mauro Martino</h3>
<p>In Marius von Senden's Space and Sight, a newly sighted blind patient
describes the experience of a corner as lemon-like, because corners "prick"
sight like lemons prick the tongue. Prickliness, here, is a dimension in the
feature space of sensory experience, an effect of the perceived on the
perceiver that arises where the two interact. In the account of the newly
sighted, an effect familiar from one interaction translates to a novel context.
Perception serves as the vehicle for generalization, in that an effect shared
across different experiences produces a concrete abstraction grounded in those
experiences. Cezanne and the post-impressionists, fluent in the language of
experience translation, realized that the way to paint a concrete form that
best reflected reality was to paint not what they saw, but what it was like to
see. We envision a future of creation using AI where what it is like to see is
replicable, transferrable, manipulable - part of the artist's palette that is
both grounded in a particular context, and generalizable beyond it.

An active line of research maps human-interpretable features onto directions
in GAN latent space. Supervised and self-supervised approaches that search for
anticipated directions or use off-the-shelf classifiers to drive image
manipulation in embedding space are limited in the variety of features they can
uncover. Unsupervised approaches that discover useful new directions show that
the space of perceptually meaningful directions is nowhere close to being fully
mapped. As this space is broad and full of creative potential, we want tools
for direction discovery that capture the richness and generalizability of human
perception. Our approach puts creators in the discovery loop during real-time
tool use, in order to identify directions that are perceptually meaningful to
them, and generate interpretable image translations along those directions.
</p>
<a href="http://arxiv.org/abs/2012.14283" target="_blank">arXiv:2012.14283</a> [<a href="http://arxiv.org/pdf/2012.14283" target="_blank">pdf</a>]

<h2>Six Degree of Freedom Robotic Arm with Mimicking Mechanism. (arXiv:2012.14286v1 [cs.RO])</h2>
<h3>Param Kothari</h3>
<p>Multi-degree of freedom robots are playing very important role in different
applications of automation. They are providing much more accuracy in carrying
out a typical procedure as compared to the manual work done by human. In recent
years the design, fabrication and development of robotic arms have been active
research areas in robotics all around the world. This project describe a
mechanical system, design concept and prototype implementation of a 6 DOF
robotic arm, which should perform industrial task such as pick and place of
fragile objects operation. This robot arm being controlled by micro-controller
has base, shoulder, elbow, wrist rotation and a functional gripper. Gripper has
been built as end-effector and is capable of grasping diverse objects within
own workspace of the arm possible. I made an effort to endeavour one of the
best model possible out of the three concepts tried. The three concepts that I
undertook were dependent on the type of mechanism used to provide the movement.
The first concept was to provide the movement with the help of Pneumatics. The
idea of pneumatics did provide a feasible movement but I had to overcome the
barrier of the weight as the weight of either the storage of gas or the air
compressor would have affected the usage evidently. Similarly, in the second
concept, I dealt with the forces of Hydraulics. The forces exerted by
hydraulics, not only restricted the movement, but also annexed a certain amount
of delay in the time period in which the movement had to be done. In, the third
concept, I tried to provide the necessary movement with the help of Servo
Motors. The results achieved with servo motors in replacement of pneumatics and
hydraulics were impeccable. The motors not only provided the movement with
minimal lag but also did not impede the movement of the hand.
</p>
<a href="http://arxiv.org/abs/2012.14286" target="_blank">arXiv:2012.14286</a> [<a href="http://arxiv.org/pdf/2012.14286" target="_blank">pdf</a>]

<h2>Learning by Ignoring. (arXiv:2012.14288v1 [cs.LG])</h2>
<h3>Xingchen Zhao, Pengtao Xie</h3>
<p>Learning by ignoring, which identifies less important things and excludes
them from the learning process, is an effective learning technique in human
learning. There has been psychological studies showing that learning to ignore
certain things is a powerful tool for helping people focus. We are interested
in investigating whether this powerful learning technique can be borrowed from
humans to improve the learning abilities of machines. We propose a novel
learning approach called learning by ignoring (LBI). Our approach automatically
identifies pretraining data examples that have large domain shift from the
target distribution by learning an ignoring variable for each example and
excludes them from the pretraining process. We propose a three-level
optimization framework to formulate LBI which involves three stages of
learning: pretraining by minimizing the losses weighed by ignoring variables;
finetuning; updating the ignoring variables by minimizing the validation loss.
We develop an efficient algorithm to solve the LBI problem. Experiments on
various datasets demonstrate the effectiveness of our method.
</p>
<a href="http://arxiv.org/abs/2012.14288" target="_blank">arXiv:2012.14288</a> [<a href="http://arxiv.org/pdf/2012.14288" target="_blank">pdf</a>]

<h2>Causal Inference in Geosciences with Kernel Sensitivity Maps. (arXiv:2012.14303v1 [cs.LG])</h2>
<h3>Adri&#xe1;n P&#xe9;rez-Suay, Gustau Camps-Valls</h3>
<p>Establishing causal relations between random variables from observational
data is perhaps the most important challenge in today's Science. In remote
sensing and geosciences this is of special relevance to better understand the
Earth's system and the complex and elusive interactions between processes. In
this paper we explore a framework to derive cause-effect relations from pairs
of variables via regression and dependence estimation. We propose to focus on
the sensitivity (curvature) of the dependence estimator to account for the
asymmetry of the forward and inverse densities of approximation residuals.
Results in a large collection of 28 geoscience causal inference problems
demonstrate the good capabilities of the method.
</p>
<a href="http://arxiv.org/abs/2012.14303" target="_blank">arXiv:2012.14303</a> [<a href="http://arxiv.org/pdf/2012.14303" target="_blank">pdf</a>]

<h2>Adaptive Threshold for Better Performance of the Recognition and Re-identification Models. (arXiv:2012.14305v1 [cs.CV])</h2>
<h3>Bharat Bohara</h3>
<p>Choosing a decision threshold is one of the challenging job in any
classification tasks. How much the model is accurate, if the deciding boundary
is not picked up carefully, its entire performance would go in vain. On the
other hand, for imbalance classification where one of the classes is dominant
over another, relying on the conventional method of choosing threshold would
result in poor performance. Even if the threshold or decision boundary is
properly chosen based on machine learning strategies like SVM and decision
tree, it will fail at some point for dynamically varying databases and in case
of identity-features that are more or less similar, like in face recognition
and person re-identification models. Hence, with the need for adaptability of
the decision threshold selection for imbalanced classification and incremental
database size, an online optimization-based statistical feature learning
adaptive technique is developed and tested on the LFW datasets and
self-prepared athletes datasets. This method of adopting adaptive threshold
resulted in 12-45% improvement in the model accuracy compared to the fixed
threshold {0.3,0.5,0.7} that are usually taken via the hit-and-trial method in
any classification and identification tasks. Source code for the complete
algorithm is available at: https://github.com/Varat7v2/adaptive-threshold
</p>
<a href="http://arxiv.org/abs/2012.14305" target="_blank">arXiv:2012.14305</a> [<a href="http://arxiv.org/pdf/2012.14305" target="_blank">pdf</a>]

<h2>How to Train Your Differentiable Filter. (arXiv:2012.14313v1 [cs.LG])</h2>
<h3>Alina Kloss, Georg Martius, Jeannette Bohg</h3>
<p>In many robotic applications, it is crucial to maintain a belief about the
state of a system, which serves as input for planning and decision making and
provides feedback during task execution. Bayesian Filtering algorithms address
this state estimation problem, but they require models of process dynamics and
sensory observations and the respective noise characteristics of these models.
Recently, multiple works have demonstrated that these models can be learned by
end-to-end training through differentiable versions of recursive filtering
algorithms. In this work, we investigate the advantages of differentiable
filters (DFs) over both unstructured learning approaches and manually-tuned
filtering algorithms, and provide practical guidance to researchers interested
in applying such differentiable filters. For this, we implement DFs with four
different underlying filtering algorithms and compare them in extensive
experiments. Specifically, we (i) evaluate different implementation choices and
training approaches, (ii) investigate how well complex models of uncertainty
can be learned in DFs, (iii) evaluate the effect of end-to-end training through
DFs and (iv) compare the DFs among each other and to unstructured LSTM models.
</p>
<a href="http://arxiv.org/abs/2012.14313" target="_blank">arXiv:2012.14313</a> [<a href="http://arxiv.org/pdf/2012.14313" target="_blank">pdf</a>]

<h2>GAKP: GRU Association and Kalman Prediction for Multiple Object Tracking. (arXiv:2012.14314v1 [cs.CV])</h2>
<h3>Zhen Li, Sunzeng Cai, Xiaoyi Wang, Zhe Liu, Nian Xue</h3>
<p>Multiple Object Tracking (MOT) has been a useful yet challenging task in many
real-world applications such as video surveillance, intelligent retail, and
smart city. The challenge is how to model long-term temporal dependencies in an
efficient manner. Some recent works employ Recurrent Neural Networks (RNN) to
obtain good performance, which, however, requires a large amount of training
data. In this paper, we proposed a novel tracking method that integrates the
auto-tuning Kalman method for prediction and the Gated Recurrent Unit (GRU) and
achieves a near-optimum with a small amount of training data. Experimental
results show that our new algorithm can achieve competitive performance on the
challenging MOT benchmark, and faster and more robust than the state-of-the-art
RNN-based online MOT algorithms.
</p>
<a href="http://arxiv.org/abs/2012.14314" target="_blank">arXiv:2012.14314</a> [<a href="http://arxiv.org/pdf/2012.14314" target="_blank">pdf</a>]

<h2>Digital me ontology and ethics. (arXiv:2012.14325v1 [cs.AI])</h2>
<h3>Ljupco Kocarev, Jasna Koteska</h3>
<p>This paper addresses ontology and ethics of an AI agent called digital me. We
define digital me as autonomous, decision-making, and learning agent,
representing an individual and having practically immortal own life. It is
assumed that digital me is equipped with the big-five personality model,
ensuring that it provides a model of some aspects of a strong AI:
consciousness, free will, and intentionality. As computer-based personality
judgments are more accurate than those made by humans, digital me can judge the
personality of the individual represented by the digital me, other individuals'
personalities, and other digital me-s. We describe seven ontological qualities
of digital me: a) double-layer status of Digital Being versus digital me, b)
digital me versus real me, c) mind-digital me and body-digital me, d) digital
me versus doppelganger (shadow digital me), e) non-human time concept, f)
social quality, g) practical immortality. We argue that with the advancement of
AI's sciences and technologies, there exist two digital me thresholds. The
first threshold defines digital me having some (rudimentarily) form of
consciousness, free will, and intentionality. The second threshold assumes that
digital me is equipped with moral learning capabilities, implying that, in
principle, digital me could develop their own ethics which significantly
differs from human's understanding of ethics. Finally we discuss the
implications of digital me metaethics, normative and applied ethics, the
implementation of the Golden Rule in digital me-s, and we suggest two sets of
normative principles for digital me: consequentialist and duty based digital me
principles.
</p>
<a href="http://arxiv.org/abs/2012.14325" target="_blank">arXiv:2012.14325</a> [<a href="http://arxiv.org/pdf/2012.14325" target="_blank">pdf</a>]

<h2>Impact of Heterogeneity in Multi-Robot Systems on Collective Behaviors Studied Using a Search and Rescue Problem. (arXiv:2012.14329v1 [cs.RO])</h2>
<h3>Sanjay Sarma O V, Ramviyas Parasuraman, Ramana Pidaparti</h3>
<p>Many species in nature demonstrate symbiotic relationships leading to
emergent behaviors through cooperation, which are sometimes beyond the scope of
the partnerships within the same species. These symbiotic relationships are
classified as mutualism, commensalism, and parasitism based on the benefit
levels involved. While these partnerships are ubiquitous in nature, it is
imperative to understand the benefits of collective behaviors in designing
heterogeneous multi-robot systems (HMRS). In this paper, we investigate the
impact of heterogeneity on the performance of HMRS applied to a search and
rescue problem. The groups consisting of searchers and rescuers, varied in the
individual robot behaviors with multiple degrees of functionality overlap and
group compositions, demonstrating various levels of heterogeneity. We propose a
new technique to measure heterogeneity in the agents through the use of
Behavior Trees and use it to obtain heterogeneity informatics from our Monte
Carlo simulations. The results show a positive correlation between the group's
heterogeneity measure and the rescue efficiency demonstrating benefits in most
of the scenarios. However, we also see cases where heterogeneity may hamper the
group's abilities pointing to the need for determining the optimal
heterogeneity in group required to maximally benefit from HMRS in real-world
applications.
</p>
<a href="http://arxiv.org/abs/2012.14329" target="_blank">arXiv:2012.14329</a> [<a href="http://arxiv.org/pdf/2012.14329" target="_blank">pdf</a>]

<h2>A method to integrate and classify normals. (arXiv:2012.14331v1 [stat.ML])</h2>
<h3>Abhranil Das, Wilson S Geisler</h3>
<p>Univariate and multivariate normal probability distributions are widely used
when modeling decisions under uncertainty. Computing the performance of such
models requires integrating these distributions over specific domains, which
can vary widely across models. Besides some special cases where these integrals
are easy to calculate, there exists no general analytical expression, standard
numerical method or software tool for these integrals. Here we present
mathematical methods and software that provide (i) the probability in any
domain of a normal in any dimensions with any parameters, (ii) the probability
density, distribution, and percentage points of any scalar or vector function
of a normal vector, (iii) quantities, such as the error matrix and
discriminability, which summarize classification performance amongst any number
of normal distributions, (iv) dimension reduction and visualizations for all
such problems, and (v) tests for how reliably these methods can be used on
given data. We illustrate these tools with models for detecting occluding
targets in natural scenes and for detecting camouflage.
</p>
<a href="http://arxiv.org/abs/2012.14331" target="_blank">arXiv:2012.14331</a> [<a href="http://arxiv.org/pdf/2012.14331" target="_blank">pdf</a>]

<h2>Data-efficient Weakly-supervised Learning for On-line Object Detection under Domain Shift in Robotics. (arXiv:2012.14345v1 [cs.CV])</h2>
<h3>Elisa Maiettini, Raffaello Camoriano, Giulia Pasquale, Vadim Tikhanoff, Lorenzo Rosasco, Lorenzo Natale</h3>
<p>Several object detection methods have recently been proposed in the
literature, the vast majority based on Deep Convolutional Neural Networks
(DCNNs). Such architectures have been shown to achieve remarkable performance,
at the cost of computationally expensive batch training and extensive labeling.
These methods have important limitations for robotics: Learning solely on
off-line data may introduce biases (the so-called domain shift), and prevents
adaptation to novel tasks. In this work, we investigate how weakly-supervised
learning can cope with these problems. We compare several techniques for
weakly-supervised learning in detection pipelines to reduce model (re)training
costs without compromising accuracy. In particular, we show that diversity
sampling for constructing active learning queries and strong positives
selection for self-supervised learning enable significant annotation savings
and improve domain shift adaptation. By integrating our strategies into a
hybrid DCNN/FALKON on-line detection pipeline [1], our method is able to be
trained and updated efficiently with few labels, overcoming limitations of
previous work. We experimentally validate and benchmark our method on
challenging robotic object detection tasks under domain shift.
</p>
<a href="http://arxiv.org/abs/2012.14345" target="_blank">arXiv:2012.14345</a> [<a href="http://arxiv.org/pdf/2012.14345" target="_blank">pdf</a>]

<h2>Generalized Quantile Loss for Deep Neural Networks. (arXiv:2012.14348v1 [cs.LG])</h2>
<h3>Dvir Ben Or, Michael Kolomenkin, Gil Shabat</h3>
<p>This note presents a simple way to add a count (or quantile) constraint to a
regression neural net, such that given $n$ samples in the training set it
guarantees that the prediction of $m&lt;n$ samples will be larger than the actual
value (the label). Unlike standard quantile regression networks, the presented
method can be applied to any loss function and not necessarily to the standard
quantile regression loss, which minimizes the mean absolute differences. Since
this count constraint has zero gradients almost everywhere, it cannot be
optimized using standard gradient descent methods. To overcome this problem, an
alternation scheme, which is based on standard neural network optimization
procedures, is presented with some theoretical analysis.
</p>
<a href="http://arxiv.org/abs/2012.14348" target="_blank">arXiv:2012.14348</a> [<a href="http://arxiv.org/pdf/2012.14348" target="_blank">pdf</a>]

<h2>Analysis of Dominant Classes in Universal Adversarial Perturbations. (arXiv:2012.14352v1 [cs.LG])</h2>
<h3>Jon Vadillo, Roberto Santana, Jose A. Lozano</h3>
<p>The reasons why Deep Neural Networks are susceptible to being fooled by
adversarial examples remains an open discussion. Indeed, many different
strategies can be employed to efficiently generate adversarial attacks, some of
them relying on different theoretical justifications. Among these strategies,
universal (input-agnostic) perturbations are of particular interest, due to
their capability to fool a network independently of the input in which the
perturbation is applied. In this work, we investigate an intriguing phenomenon
of universal perturbations, which has been reported previously in the
literature, yet without a proven justification: universal perturbations change
the predicted classes for most inputs into one particular (dominant) class,
even if this behavior is not specified during the creation of the perturbation.
In order to justify the cause of this phenomenon, we propose a number of
hypotheses and experimentally test them using a speech command classification
problem in the audio domain as a testbed. Our analyses reveal interesting
properties of universal perturbations, suggest new methods to generate such
attacks and provide an explanation of dominant classes, under both a geometric
and a data-feature perspective.
</p>
<a href="http://arxiv.org/abs/2012.14352" target="_blank">arXiv:2012.14352</a> [<a href="http://arxiv.org/pdf/2012.14352" target="_blank">pdf</a>]

<h2>Commonsense Visual Sensemaking for Autonomous Driving: On Generalised Neurosymbolic Online Abduction Integrating Vision and Semantics. (arXiv:2012.14359v1 [cs.AI])</h2>
<h3>Jakob Suchan, Mehul Bhatt, Srikrishna Varadarajan</h3>
<p>We demonstrate the need and potential of systematically integrated vision and
semantics solutions for visual sensemaking in the backdrop of autonomous
driving. A general neurosymbolic method for online visual sensemaking using
answer set programming (ASP) is systematically formalised and fully
implemented. The method integrates state of the art in visual computing, and is
developed as a modular framework that is generally usable within hybrid
architectures for realtime perception and control. We evaluate and demonstrate
with community established benchmarks KITTIMOD, MOT-2017, and MOT-2020. As
use-case, we focus on the significance of human-centred visual sensemaking --
e.g., involving semantic representation and explainability, question-answering,
commonsense interpolation -- in safety-critical autonomous driving situations.
The developed neurosymbolic framework is domain-independent, with the case of
autonomous driving designed to serve as an exemplar for online visual
sensemaking in diverse cognitive interaction settings in the backdrop of select
human-centred AI technology design considerations.

Keywords: Cognitive Vision, Deep Semantics, Declarative Spatial Reasoning,
Knowledge Representation and Reasoning, Commonsense Reasoning, Visual
Abduction, Answer Set Programming, Autonomous Driving, Human-Centred Computing
and Design, Standardisation in Driving Technology, Spatial Cognition and AI.
</p>
<a href="http://arxiv.org/abs/2012.14359" target="_blank">arXiv:2012.14359</a> [<a href="http://arxiv.org/pdf/2012.14359" target="_blank">pdf</a>]

<h2>Lip-reading with Hierarchical Pyramidal Convolution and Self-Attention. (arXiv:2012.14360v1 [cs.CV])</h2>
<h3>Hang Chen, Jun Du, Yu Hu, Li-Rong Dai, Chin-Hui Lee, Bao-Cai Yin</h3>
<p>In this paper, we propose a novel deep learning architecture to improving
word-level lip-reading. On the one hand, we first introduce the multi-scale
processing into the spatial feature extraction for lip-reading. Specially, we
proposed hierarchical pyramidal convolution (HPConv) to replace the standard
convolution in original module, leading to improvements over the model's
ability to discover fine-grained lip movements. On the other hand, we merge
information in all time steps of the sequence by utilizing self-attention, to
make the model pay more attention to the relevant frames. These two advantages
are combined together to further enhance the model's classification power.
Experiments on the Lip Reading in the Wild (LRW) dataset show that our proposed
model has achieved 86.83% accuracy, yielding 1.53% absolute improvement over
the current state-of-the-art. We also conducted extensive experiments to better
understand the behavior of the proposed model.
</p>
<a href="http://arxiv.org/abs/2012.14360" target="_blank">arXiv:2012.14360</a> [<a href="http://arxiv.org/pdf/2012.14360" target="_blank">pdf</a>]

<h2>Counting the Number of Solutions to Constraints. (arXiv:2012.14366v1 [cs.AI])</h2>
<h3>Jian Zhang, Cunjing Ge, Feifei Ma</h3>
<p>Compared with constraint satisfaction problems, counting problems have
received less attention. In this paper, we survey research works on the
problems of counting the number of solutions to constraints. The constraints
may take various forms, including, formulas in the propositional logic, linear
inequalities over the reals or integers, Boolean combination of linear
constraints. We describe some techniques and tools for solving the counting
problems, as well as some applications (e.g., applications to automated
reasoning, program analysis, formal verification and information security).
</p>
<a href="http://arxiv.org/abs/2012.14366" target="_blank">arXiv:2012.14366</a> [<a href="http://arxiv.org/pdf/2012.14366" target="_blank">pdf</a>]

<h2>Byzantine-Resilient Non-Convex Stochastic Gradient Descent. (arXiv:2012.14368v1 [cs.LG])</h2>
<h3>Zeyuan Allen-Zhu, Faeze Ebrahimian, Jerry Li, Dan Alistarh</h3>
<p>We study adversary-resilient stochastic distributed optimization, in which
$m$ machines can independently compute stochastic gradients, and cooperate to
jointly optimize over their local objective functions. However, an
$\alpha$-fraction of the machines are $\textit{Byzantine}$, in that they may
behave in arbitrary, adversarial ways. We consider a variant of this procedure
in the challenging $\textit{non-convex}$ case. Our main result is a new
algorithm SafeguardSGD which can provably escape saddle points and find
approximate local minima of the non-convex objective. The algorithm is based on
a new concentration filtering technique, and its sample and time complexity
bounds match the best known theoretical bounds in the stochastic, distributed
setting when no Byzantine machines are present. Our algorithm is practical: it
improves upon the performance of prior methods when training deep neural
networks, it is relatively lightweight, and is the first method to withstand
two recently-proposed Byzantine attacks.
</p>
<a href="http://arxiv.org/abs/2012.14368" target="_blank">arXiv:2012.14368</a> [<a href="http://arxiv.org/pdf/2012.14368" target="_blank">pdf</a>]

<h2>Tensor Representations for Action Recognition. (arXiv:2012.14371v1 [cs.CV])</h2>
<h3>Piotr Koniusz, Lei Wang, Anoop Cherian</h3>
<p>Human actions in video sequences are characterized by the complex interplay
between spatial features and their temporal dynamics. In this paper, we propose
novel tensor representations for compactly capturing such higher-order
relationships between visual features for the task of action recognition. We
propose two tensor-based feature representations, viz. (i) sequence
compatibility kernel (SCK) and (ii) dynamics compatibility kernels (DCK); the
former capitalizing on the spatio-temporal correlations between features, while
the latter explicitly modeling the action dynamics of a sequence. We also
explore generalization of SCK, coined SCK+, that operates on subsequences to
capture the local-global interplay of correlations, as well as can incorporate
multi-modal inputs e.g., skeleton 3D body-joints and per-frame classifier
scores obtained from deep learning models trained on videos. We introduce
linearization of these kernels that lead to compact and fast descriptors. We
provide experiments on (i) 3D skeleton action sequences, (ii) fine-grained
video sequences, and (iii) standard non-fine-grained videos.

As our final representations are tensors that capture higher-order
relationships of features, they relate to co-occurrences for robust
fine-grained recognition. We use higher-order tensors and so-called Eigenvalue
Power Normalization (EPN) which have been long speculated to perform spectral
detection of higher-order occurrences; thus detecting fine-grained
relationships of features rather than merely count features in scenes. We prove
that a tensor of order r, built from Z* dim. features, coupled with EPN indeed
detects if at least one higher-order occurrence is `projected' into one of its
binom(Z*,r) subspaces of dim. r represented by the tensor; thus forming a
Tensor Power Normalization metric endowed with binom(Z*,r) such `detectors'.
</p>
<a href="http://arxiv.org/abs/2012.14371" target="_blank">arXiv:2012.14371</a> [<a href="http://arxiv.org/pdf/2012.14371" target="_blank">pdf</a>]

<h2>Enhanced Regularizers for Attributional Robustness. (arXiv:2012.14395v1 [cs.CV])</h2>
<h3>Anindya Sarkar, Anirban Sarkar, Vineeth N Balasubramanian</h3>
<p>Deep neural networks are the default choice of learning models for computer
vision tasks. Extensive work has been carried out in recent years on explaining
deep models for vision tasks such as classification. However, recent work has
shown that it is possible for these models to produce substantially different
attribution maps even when two very similar images are given to the network,
raising serious questions about trustworthiness. To address this issue, we
propose a robust attribution training strategy to improve attributional
robustness of deep neural networks. Our method carefully analyzes the
requirements for attributional robustness and introduces two new regularizers
that preserve a model's attribution map during attacks. Our method surpasses
state-of-the-art attributional robustness methods by a margin of approximately
3% to 9% in terms of attribution robustness measures on several datasets
including MNIST, FMNIST, Flower and GTSRB.
</p>
<a href="http://arxiv.org/abs/2012.14395" target="_blank">arXiv:2012.14395</a> [<a href="http://arxiv.org/pdf/2012.14395" target="_blank">pdf</a>]

<h2>Deep Neural Models for color discrimination and color constancy. (arXiv:2012.14402v1 [cs.CV])</h2>
<h3>Alban Flachot, Arash Akbarinia, Heiko H. Sch&#xfc;tt, Roland W. Fleming, Felix A. Wichmann, Karl R. Gegenfurtner</h3>
<p>Color constancy is our ability to perceive constant colors across varying
illuminations. Here, we trained deep neural networks to be color constant and
evaluated their performance with varying cues. Inputs to the networks consisted
of the cone excitations in 3D-rendered images of 2115 different 3D-shapes, with
spectral reflectances of 1600 different Munsell chips, illuminated under 278
different natural illuminations. The models were trained to classify the
reflectance of the objects. One network, Deep65, was trained under a fixed
daylight D65 illumination, while DeepCC was trained under varying
illuminations. Testing was done with 4 new illuminations with equally spaced
CIEL*a*b* chromaticities, 2 along the daylight locus and 2 orthogonal to it. We
found a high degree of color constancy for DeepCC, and constancy was higher
along the daylight locus. When gradually removing cues from the scene,
constancy decreased. High levels of color constancy were achieved with
different DNN architectures. Both ResNets and classical ConvNets of varying
degrees of complexity performed well. However, DeepCC, a convolutional network,
represented colors along the 3 color dimensions of human color vision, while
ResNets showed a more complex representation.
</p>
<a href="http://arxiv.org/abs/2012.14402" target="_blank">arXiv:2012.14402</a> [<a href="http://arxiv.org/pdf/2012.14402" target="_blank">pdf</a>]

<h2>dalex: Responsible Machine Learning with Interactive Explainability and Fairness in Python. (arXiv:2012.14406v1 [cs.LG])</h2>
<h3>Hubert Baniecki, Wojciech Kretowicz, Piotr Piatyszek, Jakub Wisniewski, Przemyslaw Biecek</h3>
<p>The increasing amount of available data, computing power, and the constant
pursuit for higher performance results in the growing complexity of predictive
models. Their black-box nature leads to opaqueness debt phenomenon inflicting
increased risks of discrimination, lack of reproducibility, and deflated
performance due to data drift. To manage these risks, good MLOps practices ask
for better validation of model performance and fairness, higher explainability,
and continuous monitoring. The necessity of deeper model transparency appears
not only from scientific and social domains, but also emerging laws and
regulations on artificial intelligence. To facilitate the development of
responsible machine learning models, we showcase dalex, a Python package which
implements the model-agnostic interface for interactive model exploration. It
adopts the design crafted through the development of various tools for
responsible machine learning; thus, it aims at the unification of the existing
solutions. This library's source code and documentation are available under
open license at https://python.drwhy.ai/.
</p>
<a href="http://arxiv.org/abs/2012.14406" target="_blank">arXiv:2012.14406</a> [<a href="http://arxiv.org/pdf/2012.14406" target="_blank">pdf</a>]

<h2>Stochastic Approximation for Online Tensorial Independent Component Analysis. (arXiv:2012.14415v1 [cs.LG])</h2>
<h3>Chris Junchi Li, Michael I. Jordan</h3>
<p>Independent component analysis (ICA) has been a popular dimension reduction
tool in statistical machine learning and signal processing. In this paper, we
present a convergence analysis for an online tensorial ICA algorithm, by
viewing the problem as a nonconvex stochastic approximation problem. For
estimating one component, we provide a dynamics-based analysis to prove that
our online tensorial ICA algorithm with a specific choice of stepsize achieves
a sharp finite-sample error bound. In particular, under a mild assumption on
the data-generating distribution and a scaling condition such that $d^4 / T$ is
sufficiently small up to a polylogarithmic factor of data dimension $d$ and
sample size $T$, a sharp finite-sample error bound of $\tilde O(\sqrt{d / T})$
can be obtained. As a by-product, we also design an online tensorial ICA
algorithm that estimates multiple independent components in parallel, achieving
desirable finite-sample error bound for each independent component estimator.
</p>
<a href="http://arxiv.org/abs/2012.14415" target="_blank">arXiv:2012.14415</a> [<a href="http://arxiv.org/pdf/2012.14415" target="_blank">pdf</a>]

<h2>Bag of Genres for Video Retrieval. (arXiv:1506.00051v2 [cs.CV] UPDATED)</h2>
<h3>Leonardo A. Duarte, Ot&#xe1;vio A. B. Penatti, Jurandy Almeida</h3>
<p>Often, videos are composed of multiple concepts or even genres. For instance,
news videos may contain sports, action, nature, etc. Therefore, encoding the
distribution of such concepts/genres in a compact and effective representation
is a challenging task. In this sense, we propose the Bag of Genres
representation, which is based on a visual dictionary defined by a genre
classifier. Each visual word corresponds to a region in the classification
space. The Bag of Genres video vector contains a summary of the activations of
each genre in the video content. We evaluate the proposed method for video
genre retrieval using the dataset of MediaEval Tagging Task of 2012 and for
video event retrieval using the EVVE dataset. Results show that the proposed
method achieves results comparable or superior to state-of-the-art methods,
with the advantage of providing a much more compact representation than
existing features.
</p>
<a href="http://arxiv.org/abs/1506.00051" target="_blank">arXiv:1506.00051</a> [<a href="http://arxiv.org/pdf/1506.00051" target="_blank">pdf</a>]

<h2>An Action Language for Multi-Agent Domains: Foundations. (arXiv:1511.01960v3 [cs.AI] UPDATED)</h2>
<h3>Chitta Baral, Gregory Gelfond, Enrico Pontelli, Tran Cao Son</h3>
<p>In multi-agent domains (MADs), an agent's action may not just change the
world and the agent's knowledge and beliefs about the world, but also may
change other agents' knowledge and beliefs about the world and their knowledge
and beliefs about other agents' knowledge and beliefs about the world. The
goals of an agent in a multi-agent world may involve manipulating the knowledge
and beliefs of other agents' and again, not just their knowledge/belief about
the world, but also their knowledge about other agents' knowledge about the
world. Our goal is to present an action language (mA+) that has the necessary
features to address the above aspects in representing and RAC in MADs. mA+
allows the representation of and reasoning about different types of actions
that an agent can perform in a domain where many other agents might be present
-- such as world-altering actions, sensing actions, and
announcement/communication actions. It also allows the specification of agents'
dynamic awareness of action occurrences which has future implications on what
agents' know about the world and other agents' knowledge about the world. mA+
considers three different types of awareness: full-, partial- awareness, and
complete oblivion of an action occurrence and its effects. This keeps the
language simple, yet powerful enough to address a large variety of knowledge
manipulation scenarios in MADs. The semantics of mA+ relies on the notion of
state, which is described by a pointed Kripke model and is used to encode the
agent's knowledge and the real state of the world. It is defined by a
transition function that maps pairs of actions and states into sets of states.
We illustrate properties of the action theories, including properties that
guarantee finiteness of the set of initial states and their practical
implementability. Finally, we relate mA+ to other related formalisms that
contribute to RAC in MADs.
</p>
<a href="http://arxiv.org/abs/1511.01960" target="_blank">arXiv:1511.01960</a> [<a href="http://arxiv.org/pdf/1511.01960" target="_blank">pdf</a>]

<h2>Sparse Principal Component Analysis via Variable Projection. (arXiv:1804.00341v3 [stat.ML] UPDATED)</h2>
<h3>N. Benjamin Erichson, Peng Zheng, Krithika Manohar, Steven L. Brunton, J. Nathan Kutz, Aleksandr Y. Aravkin</h3>
<p>Sparse principal component analysis (SPCA) has emerged as a powerful
technique for modern data analysis, providing improved interpretation of
low-rank structures by identifying localized spatial structures in the data and
disambiguating between distinct time scales. We demonstrate a robust and
scalable SPCA algorithm by formulating it as a value-function optimization
problem. This viewpoint leads to a flexible and computationally efficient
algorithm. Further, we can leverage randomized methods from linear algebra to
extend the approach to the large-scale (big data) setting. Our proposed
innovation also allows for a robust SPCA formulation which obtains meaningful
sparse principal components in spite of grossly corrupted input data. The
proposed algorithms are demonstrated using both synthetic and real world data,
and show exceptional computational efficiency and diagnostic performance.
</p>
<a href="http://arxiv.org/abs/1804.00341" target="_blank">arXiv:1804.00341</a> [<a href="http://arxiv.org/pdf/1804.00341" target="_blank">pdf</a>]

<h2>Renormalized Normalized Maximum Likelihood and Three-Part Code Criteria For Learning Gaussian Networks. (arXiv:1810.08749v2 [cs.LG] UPDATED)</h2>
<h3>Borzou Alipourfard, Jean X. Gao</h3>
<p>Score based learning (SBL) is a promising approach for learning Bayesian
networks in the discrete domain. However, when employing SBL in the continuous
domain, one is either forced to move the problem to the discrete domain or use
metrics such as BIC/AIC, and these approaches are often lacking. Discretization
can have an undesired impact on the accuracy of the results, and BIC/AIC can
fall short of achieving the desired accuracy. In this paper, we introduce two
new scoring metrics for scoring Bayesian networks in the continuous domain: the
three-part minimum description length and the renormalized normalized maximum
likelihood metric. We rely on the minimum description length principle in
formulating these metrics. The metrics proposed are free of hyperparameters,
decomposable, and are asymptotically consistent. We evaluate our solution by
studying the convergence rate of the learned graph to the generating network
and, also, the structural hamming distance of the learned graph to the
generating network. Our evaluations show that the proposed metrics outperform
their competitors, the BIC/AIC metrics. Furthermore, using the proposed RNML
metric, SBL will have the fastest rate of convergence with the smallest
structural hamming distance to the generating network.
</p>
<a href="http://arxiv.org/abs/1810.08749" target="_blank">arXiv:1810.08749</a> [<a href="http://arxiv.org/pdf/1810.08749" target="_blank">pdf</a>]

<h2>Learning Temporal Point Processes via Reinforcement Learning. (arXiv:1811.05016v2 [cs.LG] UPDATED)</h2>
<h3>Shuang Li, Shuai Xiao, Shixiang Zhu, Nan Du, Yao Xie, Le Song</h3>
<p>Social goods, such as healthcare, smart city, and information networks, often
produce ordered event data in continuous time. The generative processes of
these event data can be very complex, requiring flexible models to capture
their dynamics. Temporal point processes offer an elegant framework for
modeling event data without discretizing the time. However, the existing
maximum-likelihood-estimation (MLE) learning paradigm requires hand-crafting
the intensity function beforehand and cannot directly monitor the
goodness-of-fit of the estimated model in the process of training. To alleviate
the risk of model-misspecification in MLE, we propose to generate samples from
the generative model and monitor the quality of the samples in the process of
training until the samples and the real data are indistinguishable. We take
inspiration from reinforcement learning (RL) and treat the generation of each
event as the action taken by a stochastic policy. We parameterize the policy as
a flexible recurrent neural network and gradually improve the policy to mimic
the observed event distribution. Since the reward function is unknown in this
setting, we uncover an analytic and nonparametric form of the reward function
using an inverse reinforcement learning formulation. This new RL framework
allows us to derive an efficient policy gradient algorithm for learning
flexible point process models, and we show that it performs well in both
synthetic and real data.
</p>
<a href="http://arxiv.org/abs/1811.05016" target="_blank">arXiv:1811.05016</a> [<a href="http://arxiv.org/pdf/1811.05016" target="_blank">pdf</a>]

<h2>Accelerated MM Algorithms for Ranking Scores Inference from Comparison Data. (arXiv:1901.00150v3 [stat.ML] UPDATED)</h2>
<h3>Milan Vojnovic, Seyoung Yun, Kaifang Zhou</h3>
<p>In this paper, we study a popular method for inference of the Bradley-Terry
model parameters, namely the MM algorithm, for maximum likelihood estimation
and maximum a posteriori probability estimation. This class of models includes
the Bradley-Terry model of paired comparisons, the Rao-Kupper model of paired
comparisons allowing for tie outcomes, the Luce choice model, and the
Plackett-Luce ranking model. We establish tight characterizations of the
convergence rate for the MM algorithm, and show that it is essentially
equivalent to that of a gradient descent algorithm. For the maximum likelihood
estimation, the convergence is shown to be linear with the rate crucially
determined by the algebraic connectivity of the matrix of item pair
co-occurrences in observed comparison data. For the Bayesian inference, the
convergence rate is also shown to be linear, with the rate determined by a
parameter of the prior distribution in a way that can make the convergence
arbitrarily slow for small values of this parameter. We propose a simple
modification of the classical MM algorithm that avoids the observed slow
convergence issue and accelerates the convergence. The key component of the
accelerated MM algorithm is a parameter rescaling performed at each iteration
step that is carefully chosen based on theoretical analysis and
characterisation of the convergence rate.

Our experimental results, performed on both synthetic and real-world data,
demonstrate the identified slow convergence issue of the classic MM algorithm,
and show that significant efficiency gains can be obtained by our new proposed
method.
</p>
<a href="http://arxiv.org/abs/1901.00150" target="_blank">arXiv:1901.00150</a> [<a href="http://arxiv.org/pdf/1901.00150" target="_blank">pdf</a>]

<h2>Forensic shoe-print identification: a brief survey. (arXiv:1901.01431v3 [cs.CV] UPDATED)</h2>
<h3>Imad Rida, Lunke Fei, Hugo Proen&#xe7;a, Amine Nait-Ali, Abdenour Hadid</h3>
<p>As an advanced research topic in forensics science, automatic shoe-print
identification has been extensively studied in the last two decades, since shoe
marks are the clues most frequently left in a crime scene. Hence, these
impressions provide a pertinent evidence for the proper progress of
investigations in order to identify the potential criminals. The main goal of
this survey is to provide a cohesive overview of the research carried out in
forensic shoe-print identification and its basic background. Apart defining the
problem and describing the phases that typically compose the processing chain
of shoe-print identification, we provide a summary/comparison of the
state-of-the-art approaches, in order to guide the neophyte and help to advance
the research topic. This is done through introducing simple and basic
taxonomies as well as summaries of the state-of-the-art performance. Lastly, we
discuss the current open problems and challenges in this research topic, point
out for promising directions in this field.
</p>
<a href="http://arxiv.org/abs/1901.01431" target="_blank">arXiv:1901.01431</a> [<a href="http://arxiv.org/pdf/1901.01431" target="_blank">pdf</a>]

<h2>Cascade Submodular Maximization: Question Selection and Sequencing in Online Personality Quiz. (arXiv:1901.07708v4 [cs.LG] UPDATED)</h2>
<h3>Shaojie Tang, Jing Yuan</h3>
<p>Personality quiz is a powerful tool that enables costumer segmentation by
actively asking them questions, and marketers are using it as an effective
method of generating leads and increasing e-commerce sales. In this paper, we
study the problem of how to select and sequence a group of quiz questions so as
to optimize the quality of customer segmentation. We assume that the customer
will sequentially scan the list of questions. After reading a question, the
customer makes two, possibly correlated, random decisions: 1) she first decides
whether to answer this question or not, and then 2) decides whether to continue
reading the next question or not. We further assume that the utility of
questions that have been answered can be captured by a monotone and submodular
function. In general, our problem falls into the category of non-adaptive
active learning based customer profiling. Note that under the our model, the
probability of a question being answered depends on the location of that
question, as well as the set of other questions placed ahead of that question,
this makes our problem fundamentally different from existing studies on
submodular optimization. We develop a series of question selection and
sequencing strategies with provable performance bound. Although we focus on the
application of quiz design in this paper, our results apply to a broad range of
applications, including assortment optimization with position bias effect.
</p>
<a href="http://arxiv.org/abs/1901.07708" target="_blank">arXiv:1901.07708</a> [<a href="http://arxiv.org/pdf/1901.07708" target="_blank">pdf</a>]

<h2>ComplexFace: a Multi-Representation Approach for Image Classification with Small Dataset. (arXiv:1902.07902v2 [cs.CV] UPDATED)</h2>
<h3>Guiying Zhang, Yuxin Cui, Yong Zhao, Jianjun Hu</h3>
<p>State-of-the-art face recognition algorithms are able to achieve good
performance when sufficient training images are provided. Unfortunately, the
number of facial images is limited in some real face recognition applications.
In this paper, we propose ComplexFace, a novel and effective algorithm for face
recognition with limited samples using complex number based data augmentation.
The algorithm first generates new representations from original samples and
then fuse both into complex numbers, which avoids the difficulty of weight
setting in other fusion approaches. A test sample can then be expressed by the
linear combination of all the training samples, which mapped the sample to the
new representation space for classification by the kernel function. The
collaborative representation based classifier is then built to make
predictions. Extensive experiments on the Georgia Tech (GT) face database and
the ORL face database show that our algorithm significantly outperforms
existing methods: the average errors of previous approaches ranging from 31.66%
to 41.75% are reduced to 14.54% over the GT database; the average errors of
previous approaches ranging from 5.21% to 10.99% are reduced to 1.67% over the
ORL database. In other words, our algorithm has decreased the average errors by
up to 84.80% on the ORL database.
</p>
<a href="http://arxiv.org/abs/1902.07902" target="_blank">arXiv:1902.07902</a> [<a href="http://arxiv.org/pdf/1902.07902" target="_blank">pdf</a>]

<h2>Exploiting Relevance for Online Decision-Making in High-Dimensions. (arXiv:1907.00783v2 [cs.LG] UPDATED)</h2>
<h3>Eralp Turgay, Cem Bulucu, Cem Tekin</h3>
<p>Many sequential decision-making tasks require choosing at each decision step
the right action out of the vast set of possibilities by extracting actionable
intelligence from high-dimensional data streams. Most of the times, the
high-dimensionality of actions and data makes learning of the optimal actions
by traditional learning methods impracticable. In this work, we investigate how
to discover and leverage sparsity in actions and data to enable fast learning.
As our learning model, we consider a structured contextual multi-armed bandit
(CMAB) with high-dimensional arm (action) and context (data) sets, where the
rewards depend only on a few relevant dimensions of the joint context-arm set,
possibly in a non-linear way. We depart from the prior work by assuming a
high-dimensional, continuum set of arms, and allow relevant context dimensions
to vary for each arm. We propose a new online learning algorithm called {\em
CMAB with Relevance Learning} (CMAB-RL) and prove that its time-averaged regret
asymptotically goes to zero when the expected reward varies smoothly in
contexts and arms. CMAB-RL enjoys a substantially improved regret bound
compared to classical CMAB algorithms whose regrets depend on dimensions $d_x$
and $d_a$ of the context and arm sets. Importantly, we show that when the
learner has prior knowledge on sparsity, given in terms of upper bounds
$\overline{d}_x$ and $\overline{d}_a$ on the number of relevant dimensions,
then CMAB-RL achieves $\tilde{O}(T^{1-1/(2+2\overline{d}_x +\overline{d}_a)})$
regret. Finally, we illustrate how CMAB algorithms can be used for optimal
personalized blood glucose control in type 1 diabetes mellitus patients, and
show that CMAB-RL outperforms other contextual MAB algorithms in this task.
</p>
<a href="http://arxiv.org/abs/1907.00783" target="_blank">arXiv:1907.00783</a> [<a href="http://arxiv.org/pdf/1907.00783" target="_blank">pdf</a>]

<h2>Learning Algebraic Models of Quantum Entanglement. (arXiv:1908.10247v2 [cs.LG] UPDATED)</h2>
<h3>Hamza Jaffali, Luke Oeding</h3>
<p>We review supervised learning and deep neural network design for learning
membership on algebraic varieties. We demonstrate that these trained artificial
neural networks can predict the entanglement type for quantum states. We give
examples for detecting degenerate states, as well as border rank classification
for up to 5 binary qubits and 3 qutrits (ternary qubits).
</p>
<a href="http://arxiv.org/abs/1908.10247" target="_blank">arXiv:1908.10247</a> [<a href="http://arxiv.org/pdf/1908.10247" target="_blank">pdf</a>]

<h2>Student Engagement Detection Using Emotion Analysis, Eye Tracking and Head Movement with Machine Learning. (arXiv:1909.12913v4 [cs.CV] UPDATED)</h2>
<h3>Prabin Sharma, Shubham Joshi, Subash Gautam, Sneha Maharjan, Vitor Filipe, Manuel J. C. S. Reis</h3>
<p>With the increase of distance learning, in general, and e-learning, in
particular, having a system capable of determining the engagement of students
is of primordial importance, and one of the biggest challenges, both for
teachers, researchers and policy makers. Here, we present a system to detect
the engagement level of the students. It uses only information provided by the
typical built-in web-camera present in a laptop computer, and was designed to
work in real time. We combine information about the movements of the eyes and
head, and facial emotions to produce a concentration index with three classes
of engagement: "very engaged", "nominally engaged" and "not engaged at all".
The system was tested in a typical e-learning scenario, and the results show
that it correctly identifies each period of time where students were "very
engaged", "nominally engaged" and "not engaged at all". Additionally, the
results also show that the students with best scores also have higher
concentration indexes.
</p>
<a href="http://arxiv.org/abs/1909.12913" target="_blank">arXiv:1909.12913</a> [<a href="http://arxiv.org/pdf/1909.12913" target="_blank">pdf</a>]

<h2>Manhattan Room Layout Reconstruction from a Single 360 image: A Comparative Study of State-of-the-art Methods. (arXiv:1910.04099v3 [cs.CV] UPDATED)</h2>
<h3>Chuhang Zou, Jheng-Wei Su, Chi-Han Peng, Alex Colburn, Qi Shan, Peter Wonka, Hung-Kuo Chu, Derek Hoiem</h3>
<p>Recent approaches for predicting layouts from 360 panoramas produce excellent
results. These approaches build on a common framework consisting of three
steps: a pre-processing step based on edge-based alignment, prediction of
layout elements, and a post-processing step by fitting a 3D layout to the
layout elements. Until now, it has been difficult to compare the methods due to
multiple different design decisions, such as the encoding network (e.g. SegNet
or ResNet), type of elements predicted (e.g. corners, wall/floor boundaries, or
semantic segmentation), or method of fitting the 3D layout. To address this
challenge, we summarize and describe the common framework, the variants, and
the impact of the design decisions. For a complete evaluation, we also propose
extended annotations for the Matterport3D dataset [3], and introduce two
depth-based evaluation metrics.
</p>
<a href="http://arxiv.org/abs/1910.04099" target="_blank">arXiv:1910.04099</a> [<a href="http://arxiv.org/pdf/1910.04099" target="_blank">pdf</a>]

<h2>Sampling the "Inverse Set" of a Neuron: An Approach to Understanding Neural Nets. (arXiv:1910.04857v2 [cs.CV] UPDATED)</h2>
<h3>Suryabhan Singh Hada, Miguel &#xc1;. Carreira-Perpi&#xf1;&#xe1;n</h3>
<p>With the recent success of deep neural networks in computer vision, it is
important to understand the internal working of these networks. What does a
given neuron represent? The concepts captured by a neuron may be hard to
understand or express in simple terms. The approach we propose in this paper is
to characterize the region of input space that excites a given neuron to a
certain level; we call this the inverse set. This inverse set is a complicated
high dimensional object that we explore by an optimization-based sampling
approach. Inspection of samples of this set by a human can reveal regularities
that help to understand the neuron. This goes beyond approaches which were
limited to finding an image which maximally activates the neuron or using
Markov chain Monte Carlo to sample images, but this is very slow, generates
samples with little diversity and lacks control over the activation value of
the generated samples. Our approach also allows us to explore the intersection
of inverse sets of several neurons and other variations.
</p>
<a href="http://arxiv.org/abs/1910.04857" target="_blank">arXiv:1910.04857</a> [<a href="http://arxiv.org/pdf/1910.04857" target="_blank">pdf</a>]

<h2>Parametric Gaussian Process Regressors. (arXiv:1910.07123v3 [stat.ML] UPDATED)</h2>
<h3>Martin Jankowiak, Geoff Pleiss, Jacob R. Gardner</h3>
<p>The combination of inducing point methods with stochastic variational
inference has enabled approximate Gaussian Process (GP) inference on large
datasets. Unfortunately, the resulting predictive distributions often exhibit
substantially underestimated uncertainties. Notably, in the regression case the
predictive variance is typically dominated by observation noise, yielding
uncertainty estimates that make little use of the input-dependent function
uncertainty that makes GP priors attractive. In this work we propose two simple
methods for scalable GP regression that address this issue and thus yield
substantially improved predictive uncertainties. The first applies variational
inference to FITC (Fully Independent Training Conditional; Snelson
et.~al.~2006). The second bypasses posterior approximations and instead
directly targets the posterior predictive distribution. In an extensive
empirical comparison with a number of alternative methods for scalable GP
regression, we find that the resulting predictive distributions exhibit
significantly better calibrated uncertainties and higher log likelihoods--often
by as much as half a nat per datapoint.
</p>
<a href="http://arxiv.org/abs/1910.07123" target="_blank">arXiv:1910.07123</a> [<a href="http://arxiv.org/pdf/1910.07123" target="_blank">pdf</a>]

<h2>Zero-Shot Recognition via Optimal Transport. (arXiv:1910.09057v2 [cs.LG] UPDATED)</h2>
<h3>Wenlin Wang, Hongteng Xu, Guoyin Wang, Wenqi Wang, Lawrence Carin</h3>
<p>We propose an optimal transport (OT) framework for generalized zero-shot
learning (GZSL), seeking to distinguish samples for both seen and unseen
classes, with the assist of auxiliary attributes. The discrepancy between
features and attributes is minimized by solving an optimal transport problem.
{Specifically, we build a conditional generative model to generate features
from seen-class attributes, and establish an optimal transport between the
distribution of the generated features and that of the real features.} The
generative model and the optimal transport are optimized iteratively with an
attribute-based regularizer, that further enhances the discriminative power of
the generated features. A classifier is learned based on the features generated
for both the seen and unseen classes. In addition to generalized zero-shot
learning, our framework is also applicable to standard and transductive ZSL
problems. Experiments show that our optimal transport-based method outperforms
state-of-the-art methods on several benchmark datasets.
</p>
<a href="http://arxiv.org/abs/1910.09057" target="_blank">arXiv:1910.09057</a> [<a href="http://arxiv.org/pdf/1910.09057" target="_blank">pdf</a>]

<h2>vqSGD: Vector Quantized Stochastic Gradient Descent. (arXiv:1911.07971v4 [cs.LG] UPDATED)</h2>
<h3>Venkata Gandikota, Daniel Kane, Raj Kumar Maity, Arya Mazumdar</h3>
<p>In this work, we present a family of vector quantization schemes \emph{vqSGD}
(Vector-Quantized Stochastic Gradient Descent) that provide an asymptotic
reduction in the communication cost with convergence guarantees in first-order
distributed optimization. In the process we derive the following fundamental
information theoretic fact: $\Theta(\frac{d}{R^2})$ bits are necessary and
sufficient to describe an unbiased estimator ${\hat{g}}({g})$ for any ${g}$ in
the $d$-dimensional unit sphere, under the constraint that
$\|{\hat{g}}({g})\|_2\le R$ almost surely. In particular, we consider a
randomized scheme based on the convex hull of a point set, that returns an
unbiased estimator of a $d$-dimensional gradient vector with almost surely
bounded norm. We provide multiple efficient instances of our scheme, that are
near optimal, and require only $o(d)$ bits of communication at the expense of
tolerable increase in error. The instances of our quantization scheme are
obtained using the properties of binary error-correcting codes and provide a
smooth tradeoff between the communication and the estimation error of
quantization. Furthermore, we show that \emph{vqSGD} also offers strong privacy
guarantees.
</p>
<a href="http://arxiv.org/abs/1911.07971" target="_blank">arXiv:1911.07971</a> [<a href="http://arxiv.org/pdf/1911.07971" target="_blank">pdf</a>]

<h2>Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language. (arXiv:1912.03590v3 [cs.CV] UPDATED)</h2>
<h3>Songyang Zhang, Houwen Peng, Jianlong Fu, Jiebo Luo</h3>
<p>We address the problem of retrieving a specific moment from an untrimmed
video by a query sentence. This is a challenging problem because a target
moment may take place in relations to other temporal moments in the untrimmed
video. Existing methods cannot tackle this challenge well since they consider
temporal moments individually and neglect the temporal dependencies. In this
paper, we model the temporal relations between video moments by a
two-dimensional map, where one dimension indicates the starting time of a
moment and the other indicates the end time. This 2D temporal map can cover
diverse video moments with different lengths, while representing their adjacent
relations. Based on the 2D map, we propose a Temporal Adjacent Network
(2D-TAN), a single-shot framework for moment localization. It is capable of
encoding the adjacent temporal relation, while learning discriminative features
for matching video moments with referring expressions. We evaluate the proposed
2D-TAN on three challenging benchmarks, i.e., Charades-STA, ActivityNet
Captions, and TACoS, where our 2D-TAN outperforms the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/1912.03590" target="_blank">arXiv:1912.03590</a> [<a href="http://arxiv.org/pdf/1912.03590" target="_blank">pdf</a>]

<h2>Active Bayesian Assessment for Black-Box Classifiers. (arXiv:2002.06532v2 [stat.ML] UPDATED)</h2>
<h3>Disi Ji, Robert L. Logan IV, Padhraic Smyth, Mark Steyvers</h3>
<p>Recent advances in machine learning have led to increased deployment of
black-box classifiers across a wide variety of applications. In many such
situations there is a critical need to both reliably assess the performance of
these pre-trained models and to perform this assessment in a label-efficient
manner (given that labels may be scarce and costly to collect). In this paper,
we introduce an active Bayesian approach for assessment of classifier
performance to satisfy the desiderata of both reliability and label-efficiency.
We begin by developing inference strategies to quantify uncertainty for common
assessment metrics such as accuracy, misclassification cost, and calibration
error. We then propose a general framework for active Bayesian assessment using
inferred uncertainty to guide efficient selection of instances for labeling,
enabling better performance assessment with fewer labels. We demonstrate
significant gains from our proposed active Bayesian approach via a series of
systematic empirical experiments assessing the performance of modern neural
classifiers (e.g., ResNet and BERT) on several standard image and text
classification datasets.
</p>
<a href="http://arxiv.org/abs/2002.06532" target="_blank">arXiv:2002.06532</a> [<a href="http://arxiv.org/pdf/2002.06532" target="_blank">pdf</a>]

<h2>Theoretical Guarantees for Bridging Metric Measure Embedding and Optimal Transport. (arXiv:2002.08314v4 [stat.ML] UPDATED)</h2>
<h3>Mokhtar Z. Alaya, Maxime B&#xe9;rar, Gilles Gasso, Alain Rakotomamonjy</h3>
<p>We propose a novel approach for comparing distributions whose supports do not
necessarily lie on the same metric space. Unlike Gromov-Wasserstein (GW)
distance which compares pairwise distances of elements from each distribution,
we consider a method allowing to embed the metric measure spaces in a common
Euclidean space and compute an optimal transport (OT) on the embedded
distributions. This leads to what we call a sub-embedding robust Wasserstein
(SERW) distance. Under some conditions, SERW is a distance that considers an OT
distance of the (low-distorted) embedded distributions using a common metric.
In addition to this novel proposal that generalizes several recent OT works,
our contributions stand on several theoretical analyses: (i) we characterize
the embedding spaces to define SERW distance for distribution alignment; (ii)
we prove that SERW mimics almost the same properties of GW distance, and we
give a cost relation between GW and SERW. The paper also provides some
numerical illustrations of how SERW behaves on matching problems.
</p>
<a href="http://arxiv.org/abs/2002.08314" target="_blank">arXiv:2002.08314</a> [<a href="http://arxiv.org/pdf/2002.08314" target="_blank">pdf</a>]

<h2>Deep Sigma Point Processes. (arXiv:2002.09112v2 [stat.ML] UPDATED)</h2>
<h3>Martin Jankowiak, Geoff Pleiss, Jacob R. Gardner</h3>
<p>We introduce Deep Sigma Point Processes, a class of parametric models
inspired by the compositional structure of Deep Gaussian Processes (DGPs). Deep
Sigma Point Processes (DSPPs) retain many of the attractive features of
(variational) DGPs, including mini-batch training and predictive uncertainty
that is controlled by kernel basis functions. Importantly, since DSPPs admit a
simple maximum likelihood inference procedure, the resulting predictive
distributions are not degraded by any posterior approximations. In an extensive
empirical comparison on univariate and multivariate regression tasks we find
that the resulting predictive distributions are significantly better calibrated
than those obtained with other probabilistic methods for scalable regression,
including variational DGPs--often by as much as a nat per datapoint.
</p>
<a href="http://arxiv.org/abs/2002.09112" target="_blank">arXiv:2002.09112</a> [<a href="http://arxiv.org/pdf/2002.09112" target="_blank">pdf</a>]

<h2>Efficiency and Equity are Both Essential: A Generalized Traffic Signal Controller with Deep Reinforcement Learning. (arXiv:2003.04046v3 [cs.LG] UPDATED)</h2>
<h3>Shengchao Yan, Jingwei Zhang, Daniel B&#xfc;scher, Wolfram Burgard</h3>
<p>Traffic signal controllers play an essential role in today's traffic system.
However, the majority of them currently is not sufficiently flexible or
adaptive to generate optimal traffic schedules. In this paper we present an
approach to learning policies for signal controllers using deep reinforcement
learning aiming for optimized traffic flow. Our method uses a novel formulation
of the reward function that simultaneously considers efficiency and equity. We
furthermore present a general approach to find the bound for the proposed
equity factor and we introduce the adaptive discounting approach that greatly
stabilizes learning and helps to maintain a high flexibility of green light
duration. The experimental evaluations on both simulated and real-world data
demonstrate that our proposed algorithm achieves state-of-the-art performance
(previously held by traditional non-learning methods) on a wide range of
traffic situations.
</p>
<a href="http://arxiv.org/abs/2003.04046" target="_blank">arXiv:2003.04046</a> [<a href="http://arxiv.org/pdf/2003.04046" target="_blank">pdf</a>]

<h2>Computationally Efficient Obstacle Avoidance Trajectory Planner for UAVs Based on Heuristic Angular Search Method. (arXiv:2003.06136v4 [cs.RO] UPDATED)</h2>
<h3>Han Chen, Peng Lu</h3>
<p>For accomplishing a variety of missions in challenging environments, the
capability of navigating with full autonomy while avoiding unexpected obstacles
is the most crucial requirement for UAVs in real applications. In this paper,
we proposed such a computationally efficient obstacle avoidance trajectory
planner that can be used in cluttered unknown environments. Because of the
narrow view field of single depth camera on a UAV, the information of obstacles
around is quite limited thus the shortest entire path is difficult to achieve.
Therefore we focus on the time cost of the trajectory planner and safety rather
than other factors. This planner is mainly composed of a point cloud processor,
a waypoint publisher with Heuristic Angular Search(HAS) method and a motion
planner with minimum acceleration optimization. Furthermore, we propose several
techniques to enhance safety by making the possibility of finding a feasible
trajectory as big as possible. The proposed approach is implemented to run
onboard in real-time and is tested extensively in simulation and the average
control output calculating time of iteration steps is less than 18 ms.
</p>
<a href="http://arxiv.org/abs/2003.06136" target="_blank">arXiv:2003.06136</a> [<a href="http://arxiv.org/pdf/2003.06136" target="_blank">pdf</a>]

<h2>FedMAX: Mitigating Activation Divergence for Accurate and Communication-Efficient Federated Learning. (arXiv:2004.03657v2 [cs.LG] UPDATED)</h2>
<h3>Wei Chen, Kartikeya Bhardwaj, Radu Marculescu</h3>
<p>In this paper, we identify a new phenomenon called activation-divergence
which occurs in Federated Learning (FL) due to data heterogeneity (i.e., data
being non-IID) across multiple users. Specifically, we argue that the
activation vectors in FL can diverge, even if subsets of users share a few
common classes with data residing on different devices. To address the
activation-divergence issue, we introduce a prior based on the principle of
maximum entropy; this prior assumes minimal information about the per-device
activation vectors and aims at making the activation vectors of same classes as
similar as possible across multiple devices. Our results show that, for both
IID and non-IID settings, our proposed approach results in better accuracy (due
to the significantly more similar activation vectors across multiple devices),
and is more communication-efficient than state-of-the-art approaches in FL.
Finally, we illustrate the effectiveness of our approach on a few common
benchmarks and two large medical datasets.
</p>
<a href="http://arxiv.org/abs/2004.03657" target="_blank">arXiv:2004.03657</a> [<a href="http://arxiv.org/pdf/2004.03657" target="_blank">pdf</a>]

<h2>From Simulation to Real World Maneuver Execution using Deep Reinforcement Learning. (arXiv:2005.07023v3 [cs.RO] UPDATED)</h2>
<h3>Alessandro Paolo Capasso, Giulio Bacchiani, Alberto Broggi</h3>
<p>Deep Reinforcement Learning has proved to be able to solve many control tasks
in different fields, but the behavior of these systems is not always as
expected when deployed in real-world scenarios. This is mainly due to the lack
of domain adaptation between simulated and real-world data together with the
absence of distinction between train and test datasets. In this work, we
investigate these problems in the autonomous driving field, especially for a
maneuver planning module for roundabout insertions. In particular, we present a
system based on multiple environments in which agents are trained
simultaneously, evaluating the behavior of the model in different scenarios.
Finally, we analyze techniques aimed at reducing the gap between simulated and
real-world data showing that this increased the generalization capabilities of
the system both on unseen and real-world scenarios.
</p>
<a href="http://arxiv.org/abs/2005.07023" target="_blank">arXiv:2005.07023</a> [<a href="http://arxiv.org/pdf/2005.07023" target="_blank">pdf</a>]

<h2>Geodesics in fibered latent spaces: A geometric approach to learning correspondences between conditions. (arXiv:2005.07852v3 [stat.ML] UPDATED)</h2>
<h3>Tariq Daouda, Reda Chhaibi, Prudencio Tossou, Alexandra-Chlo&#xe9; Villani</h3>
<p>This work introduces a geometric framework and a novel network architecture
for creating correspondences between samples of different conditions. Under
this formalism, the latent space is a fiber bundle stratified into a base space
encoding conditions, and a fiber space encoding the variations within
conditions. Furthermore, this latent space is endowed with a natural pull-back
metric. The correspondences between conditions are obtained by minimizing an
energy functional, resulting in diffeomorphism flows between fibers.

We illustrate this approach using MNIST and Olivetti and benchmark its
performances on the task of batch correction, which is the problem of
integrating multiple biological datasets together.
</p>
<a href="http://arxiv.org/abs/2005.07852" target="_blank">arXiv:2005.07852</a> [<a href="http://arxiv.org/pdf/2005.07852" target="_blank">pdf</a>]

<h2>Fine-Grained 3D Shape Classification with Hierarchical Part-View Attentions. (arXiv:2005.12541v2 [cs.CV] UPDATED)</h2>
<h3>Xinhai Liu, Zhizhong Han, Yu-Shen Liu, Matthias Zwicker</h3>
<p>Fine-grained 3D shape classification is important for shape understanding and
analysis, which poses a challenging research problem. However, the studies on
the fine-grained 3D shape classification have rarely been explored, due to the
lack of fine-grained 3D shape benchmarks. To address this issue, we first
introduce a new 3D shape dataset (named FG3D dataset) with fine-grained class
labels, which consists of three categories including airplane, car and chair.
Each category consists of several subcategories at a fine-grained level.
According to our experiments under this fine-grained dataset, we find that
state-of-the-art methods are significantly limited by the small variance among
subcategories in the same category. To resolve this problem, we further propose
a novel fine-grained 3D shape classification method named FG3D-Net to capture
the fine-grained local details of 3D shapes from multiple rendered views.
Specifically, we first train a Region Proposal Network (RPN) to detect the
generally semantic parts inside multiple views under the benchmark of generally
semantic part detection. Then, we design a hierarchical part-view attention
aggregation module to learn a global shape representation by aggregating
generally semantic part features, which preserves the local details of 3D
shapes. The part-view attention module hierarchically leverages part-level and
view-level attention to increase the discriminability of our features. The
part-level attention highlights the important parts in each view while the
view-level attention highlights the discriminative views among all the views of
the same object. In addition, we integrate a Recurrent Neural Network (RNN) to
capture the spatial relationships among sequential views from different
viewpoints. Our results under the fine-grained 3D shape dataset show that our
method outperforms other state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2005.12541" target="_blank">arXiv:2005.12541</a> [<a href="http://arxiv.org/pdf/2005.12541" target="_blank">pdf</a>]

<h2>SPIN: Structure-Preserving Inner Offset Network for Scene Text Recognition. (arXiv:2005.13117v3 [cs.CV] UPDATED)</h2>
<h3>Chengwei Zhang, Yunlu Xu, Zhanzhan Cheng, Shiliang Pu, Yi Niu, Fei Wu, Futai Zou</h3>
<p>Arbitrary text appearance poses a great challenge in scene text recognition
tasks. Existing works mostly handle with the problem in consideration of the
shape distortion, including perspective distortions, line curvature or other
style variations. Therefore, methods based on spatial transformers are
extensively studied. However, chromatic difficulties in complex scenes have not
been paid much attention on. In this work, we introduce a new learnable
geometric-unrelated module, the Structure-Preserving Inner Offset Network
(SPIN), which allows the color manipulation of source data within the network.
This differentiable module can be inserted before any recognition architecture
to ease the downstream tasks, giving neural networks the ability to actively
transform input intensity rather than the existing spatial rectification. It
can also serve as a complementary module to known spatial transformations and
work in both independent and collaborative ways with them. Extensive
experiments show that the use of SPIN results in a significant improvement on
multiple text recognition benchmarks compared to the state-of-the-arts.
</p>
<a href="http://arxiv.org/abs/2005.13117" target="_blank">arXiv:2005.13117</a> [<a href="http://arxiv.org/pdf/2005.13117" target="_blank">pdf</a>]

<h2>Web page classification with Google Image Search results. (arXiv:2006.00226v2 [cs.CV] UPDATED)</h2>
<h3>Fahri Aydos, A. Murat &#xd6;zbayo&#x11f;lu, Yahya &#x15e;irin, M. Fatih Demirci</h3>
<p>In this paper, we introduce a novel method that combines multiple neural
network results to decide the class of the input. This is the first study which
used the method for web pages classification. In our model, each element is
represented by multiple descriptive images. After the training process of the
neural network model, each element is classified by calculating its descriptive
image results. We apply our idea to the web page classification problem using
Google Image Search results as descriptive images. We obtained a classification
rate of 94.90% on the WebScreenshots dataset that contains 20000 web sites in 4
classes. The method is easily applicable to similar problems.
</p>
<a href="http://arxiv.org/abs/2006.00226" target="_blank">arXiv:2006.00226</a> [<a href="http://arxiv.org/pdf/2006.00226" target="_blank">pdf</a>]

<h2>Neural Networks with Small Weights and Depth-Separation Barriers. (arXiv:2006.00625v4 [cs.LG] UPDATED)</h2>
<h3>Gal Vardi, Ohad Shamir</h3>
<p>In studying the expressiveness of neural networks, an important question is
whether there are functions which can only be approximated by sufficiently deep
networks, assuming their size is bounded. However, for constant depths,
existing results are limited to depths $2$ and $3$, and achieving results for
higher depths has been an important open question. In this paper, we focus on
feedforward ReLU networks, and prove fundamental barriers to proving such
results beyond depth $4$, by reduction to open problems and natural-proof
barriers in circuit complexity. To show this, we study a seemingly unrelated
problem of independent interest: Namely, whether there are polynomially-bounded
functions which require super-polynomial weights in order to approximate with
constant-depth neural networks. We provide a negative and constructive answer
to that question, by showing that if a function can be approximated by a
polynomially-sized, constant depth $k$ network with arbitrarily large weights,
it can also be approximated by a polynomially-sized, depth $3k+3$ network,
whose weights are polynomially bounded.
</p>
<a href="http://arxiv.org/abs/2006.00625" target="_blank">arXiv:2006.00625</a> [<a href="http://arxiv.org/pdf/2006.00625" target="_blank">pdf</a>]

<h2>Learning Multi-Modal Nonlinear Embeddings: Performance Bounds and an Algorithm. (arXiv:2006.02330v2 [cs.LG] UPDATED)</h2>
<h3>Semih Kaya, Elif Vural</h3>
<p>While many approaches exist in the literature to learn low-dimensional
representations for data collections in multiple modalities, the
generalizability of multi-modal nonlinear embeddings to previously unseen data
is a rather overlooked subject. In this work, we first present a theoretical
analysis of learning multi-modal nonlinear embeddings in a supervised setting.
Our performance bounds indicate that for successful generalization in
multi-modal classification and retrieval problems, the regularity of the
interpolation functions extending the embedding to the whole data space is as
important as the between-class separation and cross-modal alignment criteria.
We then propose a multi-modal nonlinear representation learning algorithm that
is motivated by these theoretical findings, where the embeddings of the
training samples are optimized jointly with the Lipschitz regularity of the
interpolators. Experimental comparison to recent multi-modal and single-modal
learning algorithms suggests that the proposed method yields promising
performance in multi-modal image classification and cross-modal image-text
retrieval applications.
</p>
<a href="http://arxiv.org/abs/2006.02330" target="_blank">arXiv:2006.02330</a> [<a href="http://arxiv.org/pdf/2006.02330" target="_blank">pdf</a>]

<h2>Counterfactual VQA: A Cause-Effect Look at Language Bias. (arXiv:2006.04315v3 [cs.CV] UPDATED)</h2>
<h3>Yulei Niu, Kaihua Tang, Hanwang Zhang, Zhiwu Lu, Xian-Sheng Hua, Ji-Rong Wen</h3>
<p>Recent VQA models may tend to rely on language bias as a shortcut and thus
fail to sufficiently learn the multi-modal knowledge from both vision and
language. In this paper, we investigate how to capture and mitigate language
bias in VQA. Motivated by causal effects, we proposed a novel counterfactual
inference framework, which enables us to capture the language bias as the
direct causal effect of questions on answers and reduce the language bias by
subtracting the direct language effect from the total causal effect.
Experiments demonstrate that our proposed counterfactual inference framework 1)
is general to various VQA backbones and fusion strategies, 2) achieves
competitive performance on the language-bias sensitive VQA-CP dataset while
performs robustly on the balanced VQA v2 dataset.
</p>
<a href="http://arxiv.org/abs/2006.04315" target="_blank">arXiv:2006.04315</a> [<a href="http://arxiv.org/pdf/2006.04315" target="_blank">pdf</a>]

<h2>Locally Private Graph Neural Networks. (arXiv:2006.05535v5 [cs.LG] UPDATED)</h2>
<h3>Sina Sajadmanesh, Daniel Gatica-Perez</h3>
<p>Graph Neural Networks (GNNs) have demonstrated superior performance in
learning graph representations for several subsequent downstream inference
tasks. However, learning over graph data can raise privacy concerns when nodes
represent people or human-related variables that involve personal information
about individuals. Previous works have presented various techniques for
privacy-preserving deep learning over non-relational data, such as image,
audio, video, and text, but there is less work addressing the privacy issues
involved in applying deep learning algorithms on graphs. As a result and for
the first time, in this paper, we develop a privacy-preserving GNN learning
algorithm with formal privacy guarantees based on Local Differential Privacy
(LDP) to tackle the problem of node-level privacy, where graph nodes have
potentially sensitive features that need to be kept private, but they could be
beneficial for an untrusted server to learn richer node representations.
Specifically, we propose an optimized LDP algorithm with an unbiased estimator,
using which a central server can communicate with the graph nodes to privately
collect their data and estimate the graph convolution layer of the GNN. To
further reduce the effect of the injected noise, we propose a simple graph
convolution layer based on the multi-hop aggregation of the nodes' features.
Extensive experiments conducted over real-world datasets demonstrate the
capability of our method in maintaining an appropriate privacy-accuracy
trade-off for privacy-preserving node classification.
</p>
<a href="http://arxiv.org/abs/2006.05535" target="_blank">arXiv:2006.05535</a> [<a href="http://arxiv.org/pdf/2006.05535" target="_blank">pdf</a>]

<h2>Class-Attentive Diffusion Network for Semi-Supervised Classification. (arXiv:2006.10222v2 [cs.LG] UPDATED)</h2>
<h3>Jongin Lim, Daeho Um, Hyung Jin Chang, Dae Ung Jo, Jin Young Choi</h3>
<p>Recently, graph neural networks for semi-supervised classification have been
widely studied. However, existing methods only use the information of limited
neighbors and do not deal with the inter-class connections in graphs. In this
paper, we propose Adaptive aggregation with Class-Attentive Diffusion (AdaCAD),
a new aggregation scheme that adaptively aggregates nodes probably of the same
class among K-hop neighbors. To this end, we first propose a novel stochastic
process, called Class-Attentive Diffusion (CAD), that strengthens attention to
intra-class nodes and attenuates attention to inter-class nodes. In contrast to
the existing diffusion methods with a transition matrix determined solely by
the graph structure, CAD considers both the node features and the graph
structure with the design of our class-attentive transition matrix that
utilizes a classifier. Then, we further propose an adaptive update scheme that
leverages different reflection ratios of the diffusion result for each node
depending on the local class-context. As the main advantage, AdaCAD alleviates
the problem of undesired mixing of inter-class features caused by discrepancies
between node labels and the graph topology. Built on AdaCAD, we construct a
simple model called Class-Attentive Diffusion Network (CAD-Net). Extensive
experiments on seven benchmark datasets consistently demonstrate the efficacy
of the proposed method and our CAD-Net significantly outperforms the
state-of-the-art methods. Code is available at
https://github.com/ljin0429/CAD-Net.
</p>
<a href="http://arxiv.org/abs/2006.10222" target="_blank">arXiv:2006.10222</a> [<a href="http://arxiv.org/pdf/2006.10222" target="_blank">pdf</a>]

<h2>PAC-Bayes Analysis Beyond the Usual Bounds. (arXiv:2006.13057v3 [stat.ML] UPDATED)</h2>
<h3>Omar Rivasplata, Ilja Kuzborskij, Csaba Szepesvari, John Shawe-Taylor</h3>
<p>We focus on a stochastic learning model where the learner observes a finite
set of training examples and the output of the learning process is a
data-dependent distribution over a space of hypotheses. The learned
data-dependent distribution is then used to make randomized predictions, and
the high-level theme addressed here is guaranteeing the quality of predictions
on examples that were not seen during training, i.e. generalization. In this
setting the unknown quantity of interest is the expected risk of the
data-dependent randomized predictor, for which upper bounds can be derived via
a PAC-Bayes analysis, leading to PAC-Bayes bounds.

Specifically, we present a basic PAC-Bayes inequality for stochastic kernels,
from which one may derive extensions of various known PAC-Bayes bounds as well
as novel bounds. We clarify the role of the requirements of fixed 'data-free'
priors, bounded losses, and i.i.d. data. We highlight that those requirements
were used to upper-bound an exponential moment term, while the basic PAC-Bayes
theorem remains valid without those restrictions. We present three bounds that
illustrate the use of data-dependent priors, including one for the unbounded
square loss.
</p>
<a href="http://arxiv.org/abs/2006.13057" target="_blank">arXiv:2006.13057</a> [<a href="http://arxiv.org/pdf/2006.13057" target="_blank">pdf</a>]

<h2>Unsupervised Deep Representation Learning and Few-Shot Classification of PolSAR Images. (arXiv:2006.15351v2 [cs.CV] UPDATED)</h2>
<h3>Lamei Zhang, Siyu Zhang, Bin Zou, Hongwei Dong</h3>
<p>Deep learning and convolutional neural networks (CNNs) have made progress in
polarimetric synthetic aperture radar (PolSAR) image classification over the
past few years. However, a crucial issue has not been addressed, i.e., the
requirement of CNNs for abundant labeled samples versus the insufficient human
annotations of PolSAR images. It is well-known that following the supervised
learning paradigm may lead to the overfitting of training data, and the lack of
supervision information of PolSAR images undoubtedly aggravates this problem,
which greatly affects the generalization performance of CNN-based classifiers
in large-scale applications. To handle this problem, in this paper, learning
transferrable representations from unlabeled PolSAR data through convolutional
architectures is explored for the first time. Specifically, a PolSAR-tailored
contrastive learning network (PCLNet) is proposed for unsupervised deep PolSAR
representation learning and few-shot classification. Different from the
utilization of optical processing methods, a diversity stimulation mechanism is
constructed to narrow the application gap between optics and PolSAR. Beyond the
conventional supervised methods, PCLNet develops an unsupervised pre-training
phase based on the proxy objective of instance discrimination to learn useful
representations from unlabeled PolSAR data. The acquired representations are
transferred to the downstream task, i.e., few-shot PolSAR classification.
Experiments on two widely-used PolSAR benchmark datasets confirm the validity
of PCLNet. Besides, this work may enlighten how to efficiently utilize the
massive unlabeled PolSAR data to alleviate the greedy demands of CNN-based
methods for human annotations.
</p>
<a href="http://arxiv.org/abs/2006.15351" target="_blank">arXiv:2006.15351</a> [<a href="http://arxiv.org/pdf/2006.15351" target="_blank">pdf</a>]

<h2>Efficient Marginalization of Discrete and Structured Latent Variables via Sparsity. (arXiv:2007.01919v3 [cs.LG] UPDATED)</h2>
<h3>Gon&#xe7;alo M. Correia, Vlad Niculae, Wilker Aziz, Andr&#xe9; F. T. Martins</h3>
<p>Training neural network models with discrete (categorical or structured)
latent variables can be computationally challenging, due to the need for
marginalization over large or combinatorial sets. To circumvent this issue, one
typically resorts to sampling-based approximations of the true marginal,
requiring noisy gradient estimators (e.g., score function estimator) or
continuous relaxations with lower-variance reparameterized gradients (e.g.,
Gumbel-Softmax). In this paper, we propose a new training strategy which
replaces these estimators by an exact yet efficient marginalization. To achieve
this, we parameterize discrete distributions over latent assignments using
differentiable sparse mappings: sparsemax and its structured counterparts. In
effect, the support of these distributions is greatly reduced, which enables
efficient marginalization. We report successful results in three tasks covering
a range of latent variable modeling applications: a semisupervised deep
generative model, a latent communication game, and a generative model with a
bit-vector latent representation. In all cases, we obtain good performance
while still achieving the practicality of sampling-based approximations.
</p>
<a href="http://arxiv.org/abs/2007.01919" target="_blank">arXiv:2007.01919</a> [<a href="http://arxiv.org/pdf/2007.01919" target="_blank">pdf</a>]

<h2>AEGCN: An Autoencoder-Constrained Graph Convolutional Network. (arXiv:2007.03424v2 [cs.LG] UPDATED)</h2>
<h3>Mingyuan Ma, Sen Na, Hongyu Wang</h3>
<p>We propose a novel neural network architecture, called
autoencoder-constrained graph convolutional network, to solve node
classification task on graph domains. As suggested by its name, the core of
this model is a convolutional network operating directly on graphs, whose
hidden layers are constrained by an autoencoder. Comparing with vanilla graph
convolutional networks, the autoencoder step is added to reduce the information
loss brought by Laplacian smoothing. We consider applying our model on both
homogeneous graphs and heterogeneous graphs. For homogeneous graphs, the
autoencoder approximates the adjacency matrix of the input graph by taking
hidden layer representations as encoder and another one-layer graph
convolutional network as decoder. For heterogeneous graphs, since there are
multiple adjacency matrices corresponding to different types of edges, the
autoencoder approximates the feature matrix of the input graph instead, and
changes the encoder to a particularly designed multi-channel pre-processing
network with two layers. In both cases, the error occurred in the autoencoder
approximation goes to the penalty term in the loss function. In extensive
experiments on citation networks and other heterogeneous graphs, we demonstrate
that adding autoencoder constraints significantly improves the performance of
graph convolutional networks. We also notice that such technique can be applied
on graph attention network to improve the performance as well. This reveals the
wide applicability of the proposed autoencoder technique.
</p>
<a href="http://arxiv.org/abs/2007.03424" target="_blank">arXiv:2007.03424</a> [<a href="http://arxiv.org/pdf/2007.03424" target="_blank">pdf</a>]

<h2>Good AI for the Present of Humanity Democratizing AI Governance. (arXiv:2007.04477v10 [cs.AI] UPDATED)</h2>
<h3>Nicholas Kluge Corr&#xea;a</h3>
<p>What does Cyberpunk and AI Ethics have to do with each other? Cyberpunk is a
sub-genre of science fiction that explores the post-human relationships between
human experience and technology. One similarity between AI Ethics and Cyberpunk
literature is that both seek a dialogue in which the reader may inquire about
the future and the ethical and social problems that our technological advance
may bring upon society. In recent years, an increasing number of ethical
matters involving AI have been pointed and debated, and several ethical
principles and guides have been suggested as governance policies for the tech
industry. However, would this be the role of AI Ethics? To serve as a soft and
ambiguous version of the law? I would like to promote in this article a more
Cyberpunk way of doing AI Ethics, whit a more anarchic way of governance. In
this study, I will seek to expose some of the deficits of the underlying power
structures of our society and suggest that AI governance be subject to public
opinion, so that good AI can become good AI for all.
</p>
<a href="http://arxiv.org/abs/2007.04477" target="_blank">arXiv:2007.04477</a> [<a href="http://arxiv.org/pdf/2007.04477" target="_blank">pdf</a>]

<h2>Time Perception: A Review on Psychological, Computational and Robotic Models. (arXiv:2007.11845v3 [cs.AI] UPDATED)</h2>
<h3>Hamit Basgol, Inci Ayhan, Emre Ugur</h3>
<p>Animals exploit time to survive in the world. Temporal information is
required for higher-level cognitive abilities such as planning, decision
making, communication, and effective cooperation. Since time is an inseparable
part of cognition, there is a growing interest in the artificial intelligence
approach to subjective time, which has a possibility of advancing the field.
The current survey study aims to provide researchers with an interdisciplinary
perspective on time perception. Firstly, we introduce a brief background from
the psychology and neuroscience literature, covering the characteristics and
models of time perception and related abilities. Secondly, we summarize the
emergent computational and robotic models of time perception. A general
overview to the literature reveals that a substantial amount of timing models
are based on a dedicated time processing like the emergence of a clock-like
mechanism from the neural network dynamics and reveal a relationship between
the embodiment and time perception. We also notice that most models of timing
are developed for either sensory timing (i.e. ability to assess an interval) or
motor timing (i.e. ability to reproduce an interval). The number of timing
models capable of retrospective timing, which is the ability to track time
without paying attention, is insufficient. In this light, we discuss the
possible research directions to promote interdisciplinary collaboration in the
field of time perception.
</p>
<a href="http://arxiv.org/abs/2007.11845" target="_blank">arXiv:2007.11845</a> [<a href="http://arxiv.org/pdf/2007.11845" target="_blank">pdf</a>]

<h2>Micro-expression spotting: A new benchmark. (arXiv:2007.12421v2 [cs.CV] UPDATED)</h2>
<h3>Thuong-Khanh Tran, Quang-Nhat Vo, Xiaopeng Hong, Xiaobai Li, Guoying Zhao</h3>
<p>Micro-expressions (MEs) are brief and involuntary facial expressions that
occur when people are trying to hide their true feelings or conceal their
emotions. Based on psychology research, MEs play an important role in
understanding genuine emotions, which leads to many potential applications.
Therefore, ME analysis has become an attractive topic for various research
areas, such as psychology, law enforcement, and psychotherapy. In the computer
vision field, the study of MEs can be divided into two main tasks, spotting and
recognition, which are used to identify positions of MEs in videos and
determine the emotion category of the detected MEs, respectively. Recently,
although much research has been done, no fully automatic system for analyzing
MEs has yet been constructed on a practical level for two main reasons: most of
the research on MEs only focuses on the recognition part, while abandoning the
spotting task; current public datasets for ME spotting are not challenging
enough to support developing a robust spotting algorithm. The contributions of
this paper are threefold: (1) we introduce an extension of the SMIC-E database,
namely the SMIC-E-Long database, which is a new challenging benchmark for ME
spotting; (2) we suggest a new evaluation protocol that standardizes the
comparison of various ME spotting techniques; (3) extensive experiments with
handcrafted and deep learning-based approaches on the SMIC-E-Long database are
performed for baseline evaluation.
</p>
<a href="http://arxiv.org/abs/2007.12421" target="_blank">arXiv:2007.12421</a> [<a href="http://arxiv.org/pdf/2007.12421" target="_blank">pdf</a>]

<h2>Weak Human Preference Supervision For Deep Reinforcement Learning. (arXiv:2007.12904v2 [cs.AI] UPDATED)</h2>
<h3>Zehong Cao, KaiChiu Wong, Chin-Teng Lin</h3>
<p>The current reward learning from human preferences could be used to resolve
complex reinforcement learning (RL) tasks without access to a reward function
by defining a single fixed preference between pairs of trajectory segments.
However, the judgement of preferences between trajectories is not dynamic and
still requires human input over thousands of iterations. In this study, we
proposed a weak human preference supervision framework, for which we developed
a human preference scaling model that naturally reflects the human perception
of the degree of weak choices between trajectories and established a
human-demonstration estimator via supervised learning to generate the predicted
preferences for reducing the number of human inputs. The proposed weak human
preference supervision framework can effectively solve complex RL tasks and
achieve higher cumulative rewards in simulated robot locomotion -- MuJoCo games
-- relative to the single fixed human preferences. Furthermore, our established
human-demonstration estimator requires human feedback only for less than 0.01\%
of the agent's interactions with the environment and significantly reduces the
cost of human inputs by up to 30\% compared with the existing approaches. To
present the flexibility of our approach, we released a video
(https://youtu.be/jQPe1OILT0M) showing comparisons of the behaviours of agents
trained on different types of human input. We believe that our naturally
inspired human preferences with weakly supervised learning are beneficial for
precise reward learning and can be applied to state-of-the-art RL systems, such
as human-autonomy teaming systems.
</p>
<a href="http://arxiv.org/abs/2007.12904" target="_blank">arXiv:2007.12904</a> [<a href="http://arxiv.org/pdf/2007.12904" target="_blank">pdf</a>]

<h2>Feature Guided Search for Creative Problem Solving Through Tool Construction. (arXiv:2008.10685v2 [cs.RO] UPDATED)</h2>
<h3>Lakshmi Nair, Sonia Chernova</h3>
<p>Robots in the real world should be able to adapt to unforeseen circumstances.
Particularly in the context of tool use, robots may not have access to the
tools they need for completing a task. In this paper, we focus on the problem
of tool construction in the context of task planning. We seek to enable robots
to construct replacements for missing tools using available objects, in order
to complete the given task. We introduce the Feature Guided Search (FGS)
algorithm that enables the application of existing heuristic search approaches
in the context of task planning, to perform tool construction efficiently. FGS
accounts for physical attributes of objects (e.g., shape, material) during the
search for a valid task plan. Our results demonstrate that FGS significantly
reduces the search effort over standard heuristic search approaches by
approximately 93% for tool construction.
</p>
<a href="http://arxiv.org/abs/2008.10685" target="_blank">arXiv:2008.10685</a> [<a href="http://arxiv.org/pdf/2008.10685" target="_blank">pdf</a>]

<h2>t-Soft Update of Target Network for Deep Reinforcement Learning. (arXiv:2008.10861v2 [cs.LG] UPDATED)</h2>
<h3>Taisuke Kobayashi, Wendyam Eric Lionel Ilboudo</h3>
<p>This paper proposes a new robust update rule of target network for deep
reinforcement learning (DRL), to replace the conventional update rule, given as
an exponential moving average. The target network is for smoothly generating
the reference signals for a main network in DRL, thereby reducing learning
variance. The problem with its conventional update rule is the fact that all
the parameters are smoothly copied with the same speed from the main network,
even when some of them are trying to update toward the wrong directions. This
behavior increases the risk of generating the wrong reference signals. Although
slowing down the overall update speed is a naive way to mitigate wrong updates,
it would decrease learning speed. To robustly update the parameters while
keeping learning speed, a t-soft update method, which is inspired by student-t
distribution, is derived with reference to the analogy between the exponential
moving average and the normal distribution. Through the analysis of the derived
t-soft update, we show that it takes over the properties of the student-t
distribution. Specifically, with a heavy-tailed property of the student-t
distribution, the t-soft update automatically excludes extreme updates that
differ from past experiences. In addition, when the updates are similar to the
past experiences, it can mitigate the learning delay by increasing the amount
of updates. In PyBullet robotics simulations for DRL, an online actor-critic
algorithm with the t-soft update outperformed the conventional methods in terms
of the obtained return and/or its variance. From the training process by the
t-soft update, we found that the t-soft update is globally consistent with the
standard soft update, and the update rates are locally adjusted for
acceleration or suppression.
</p>
<a href="http://arxiv.org/abs/2008.10861" target="_blank">arXiv:2008.10861</a> [<a href="http://arxiv.org/pdf/2008.10861" target="_blank">pdf</a>]

<h2>Self-Supervised Human Activity Recognition by Augmenting Generative Adversarial Networks. (arXiv:2008.11755v2 [cs.CV] UPDATED)</h2>
<h3>Mohammad Zaki Zadeh, Ashwin Ramesh Babu, Ashish Jaiswal, Fillia Makedon</h3>
<p>This article proposes a novel approach for augmenting generative adversarial
network (GAN) with a self-supervised task in order to improve its ability for
encoding video representations that are useful in downstream tasks such as
human activity recognition. In the proposed method, input video frames are
randomly transformed by different spatial transformations, such as rotation,
translation and shearing or temporal transformations such as shuffling temporal
order of frames. Then discriminator is encouraged to predict the applied
transformation by introducing an auxiliary loss. Subsequently, results prove
superiority of the proposed method over baseline methods for providing a useful
representation of videos used in human activity recognition performed on
datasets such as KTH, UCF101 and Ball-Drop. Ball-Drop dataset is a specifically
designed dataset for measuring executive functions in children through
physically and cognitively demanding tasks. Using features from proposed method
instead of baseline methods caused the top-1 classification accuracy to
increase by more then 4%. Moreover, ablation study was performed to investigate
the contribution of different transformations on downstream task.
</p>
<a href="http://arxiv.org/abs/2008.11755" target="_blank">arXiv:2008.11755</a> [<a href="http://arxiv.org/pdf/2008.11755" target="_blank">pdf</a>]

<h2>A Topological Framework for Deep Learning. (arXiv:2008.13697v11 [cs.LG] UPDATED)</h2>
<h3>Mustafa Hajij, Kyle Istvan</h3>
<p>We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.
</p>
<a href="http://arxiv.org/abs/2008.13697" target="_blank">arXiv:2008.13697</a> [<a href="http://arxiv.org/pdf/2008.13697" target="_blank">pdf</a>]

<h2>Distinctive 3D local deep descriptors. (arXiv:2009.00258v2 [cs.CV] UPDATED)</h2>
<h3>Fabio Poiesi, Davide Boscaini</h3>
<p>We present a simple but yet effective method for learning distinctive 3D
local deep descriptors (DIPs) that can be used to register point clouds without
requiring an initial alignment. Point cloud patches are extracted,
canonicalised with respect to their estimated local reference frame and encoded
into rotation-invariant compact descriptors by a PointNet-based deep neural
network. DIPs can effectively generalise across different sensor modalities
because they are learnt end-to-end from locally and randomly sampled points.
Because DIPs encode only local geometric information, they are robust to
clutter, occlusions and missing regions. We evaluate and compare DIPs against
alternative hand-crafted and deep descriptors on several indoor and outdoor
datasets consisting of point clouds reconstructed using different sensors.
Results show that DIPs (i) achieve comparable results to the state-of-the-art
on RGB-D indoor scenes (3DMatch dataset), (ii) outperform state-of-the-art by a
large margin on laser-scanner outdoor scenes (ETH dataset), and (iii)
generalise to indoor scenes reconstructed with the Visual-SLAM system of
Android ARCore. Source code: https://github.com/fabiopoiesi/dip.
</p>
<a href="http://arxiv.org/abs/2009.00258" target="_blank">arXiv:2009.00258</a> [<a href="http://arxiv.org/pdf/2009.00258" target="_blank">pdf</a>]

<h2>Oracle-Efficient Reinforcement Learning in Factored MDPs with Unknown Structure. (arXiv:2009.05986v2 [cs.LG] UPDATED)</h2>
<h3>Aviv Rosenberg, Yishay Mansour</h3>
<p>We study provably-efficient reinforcement learning in non-episodic factored
Markov decision processes (FMDPs). All previous regret minimization algorithms
in this setting made the strong assumption that the factored structure of the
FMDP is known to the learner in advance. In this paper, we provide the first
algorithm that learns the structure of the FMDP while minimizing the regret.
Our algorithm is based on the optimism in face of uncertainty principle,
combined with a simple statistical method for structure learning, and can be
implemented efficiently given oracle-access to an FMDP planner. In addition, we
give a variant of our algorithm that remains efficient even when the oracle is
limited to non-factored actions, which is the case with almost all existing
approximate planners. Finally, we also provide a novel lower bound for the
known structure case that matches the best known regret bound of Chen et al.
(2020).
</p>
<a href="http://arxiv.org/abs/2009.05986" target="_blank">arXiv:2009.05986</a> [<a href="http://arxiv.org/pdf/2009.05986" target="_blank">pdf</a>]

<h2>FLAME: Differentially Private Federated Learning in the Shuffle Model. (arXiv:2009.08063v3 [cs.LG] UPDATED)</h2>
<h3>Ruixuan Liu, Yang Cao, Hong Chen, Ruoyang Guo, Masatoshi Yoshikawa</h3>
<p>Federated Learning (FL) is a promising machine learning paradigm that enables
the analyzer to train a model without collecting users' raw data. To ensure
users' privacy, differentially private federated learning has been intensively
studied. The existing works are mainly based on the \textit{curator model} or
\textit{local model} of differential privacy. However, both of them have pros
and cons. The curator model allows greater accuracy but requires a trusted
analyzer. In the local model where users randomize local data before sending
them to the analyzer, a trusted analyzer is not required but the accuracy is
limited. In this work, by leveraging the \textit{privacy amplification} effect
in the recently proposed shuffle model of differential privacy, we achieve the
best of two worlds, i.e., accuracy in the curator model and strong privacy
without relying on any trusted party. We first propose an FL framework in the
shuffle model and a simple protocol (SS-Simple) extended from existing work. We
find that SS-Simple only provides an insufficient privacy amplification effect
in FL since the dimension of the model parameter is quite large. To solve this
challenge, we propose an enhanced protocol (SS-Double) to increase the privacy
amplification effect by subsampling. Furthermore, for boosting the utility when
the model size is greater than the user population, we propose an advanced
protocol (SS-Topk) with gradient sparsification techniques. We also provide
theoretical analysis and numerical evaluations of the privacy amplification of
the proposed protocols. Experiments on real-world dataset validate that SS-Topk
improves the testing accuracy by 60.7\% than the local model based FL.
</p>
<a href="http://arxiv.org/abs/2009.08063" target="_blank">arXiv:2009.08063</a> [<a href="http://arxiv.org/pdf/2009.08063" target="_blank">pdf</a>]

<h2>Multimodal Safety-Critical Scenarios Generation for Decision-Making Algorithms Evaluation. (arXiv:2009.08311v3 [cs.LG] UPDATED)</h2>
<h3>Wenhao Ding, Baiming Chen, Bo Li, Kim Ji Eun, Ding Zhao</h3>
<p>Existing neural network-based autonomous systems are shown to be vulnerable
against adversarial attacks, therefore sophisticated evaluation on their
robustness is of great importance. However, evaluating the robustness only
under the worst-case scenarios based on known attacks is not comprehensive, not
to mention that some of them even rarely occur in the real world. In addition,
the distribution of safety-critical data is usually multimodal, while most
traditional attacks and evaluation methods focus on a single modality. To solve
the above challenges, we propose a flow-based multimodal safety-critical
scenario generator for evaluating decisionmaking algorithms. The proposed
generative model is optimized with weighted likelihood maximization and a
gradient-based sampling procedure is integrated to improve the sampling
efficiency. The safety-critical scenarios are generated by querying the task
algorithms and the log-likelihood of the generated scenarios is in proportion
to the risk level. Experiments on a self-driving task demonstrate our
advantages in terms of testing efficiency and multimodal modeling capability.
We evaluate six Reinforcement Learning algorithms with our generated traffic
scenarios and provide empirical conclusions about their robustness.
</p>
<a href="http://arxiv.org/abs/2009.08311" target="_blank">arXiv:2009.08311</a> [<a href="http://arxiv.org/pdf/2009.08311" target="_blank">pdf</a>]

<h2>Explaining Convolutional Neural Networks through Attribution-Based Input Sampling and Block-Wise Feature Aggregation. (arXiv:2010.00672v2 [cs.CV] UPDATED)</h2>
<h3>Sam Sattarzadeh, Mahesh Sudhakar, Anthony Lem, Shervin Mehryar, K. N. Plataniotis, Jongseong Jang, Hyunwoo Kim, Yeonjeong Jeong, Sangmin Lee, Kyunghoon Bae</h3>
<p>As an emerging field in Machine Learning, Explainable AI (XAI) has been
offering remarkable performance in interpreting the decisions made by
Convolutional Neural Networks (CNNs). To achieve visual explanations for CNNs,
methods based on class activation mapping and randomized input sampling have
gained great popularity. However, the attribution methods based on these
techniques provide lower resolution and blurry explanation maps that limit
their explanation power. To circumvent this issue, visualization based on
various layers is sought. In this work, we collect visualization maps from
multiple layers of the model based on an attribution-based input sampling
technique and aggregate them to reach a fine-grained and complete explanation.
We also propose a layer selection strategy that applies to the whole family of
CNN-based models, based on which our extraction framework is applied to
visualize the last layers of each convolutional block of the model. Moreover,
we perform an empirical analysis of the efficacy of derived lower-level
information to enhance the represented attributions. Comprehensive experiments
conducted on shallow and deep models trained on natural and industrial
datasets, using both ground-truth and model-truth based evaluation metrics
validate our proposed algorithm by meeting or outperforming the
state-of-the-art methods in terms of explanation ability and visual quality,
demonstrating that our method shows stability regardless of the size of objects
or instances to be explained.
</p>
<a href="http://arxiv.org/abs/2010.00672" target="_blank">arXiv:2010.00672</a> [<a href="http://arxiv.org/pdf/2010.00672" target="_blank">pdf</a>]

<h2>Data-driven Operation of the Resilient Electric Grid: A Case of COVID-19. (arXiv:2010.01746v3 [cs.LG] UPDATED)</h2>
<h3>Hossein Noorazar, Anurag. k. Srivastava, K. Sadanandan Sajan, Sanjeev Pannala</h3>
<p>Electrical energy is a vital part of modern life, and expectations for grid
resilience to allow a continuous and reliable energy supply has tremendously
increased even during adverse events (e.g., Ukraine cyber-attack, Hurricane
Maria). The global pandemic COVID-19 has raised the electric energy reliability
risk due to potential workforce disruptions, supply chain interruptions, and
increased possible cybersecurity threats. The pandemic introduces a significant
degree of uncertainly to the grid operation in the presence of other extreme
events like natural disasters, unprecedented outages, aging power grids, high
proliferation of distributed generation, and cyber-attacks. This situation
increases the need for measures for the resiliency of power grids to mitigate
the impacts of the pandemic as well as simultaneous extreme events. Solutions
to manage such an adverse scenario will be multi-fold: a) emergency planning
and organizational support, b) following safety protocol, c) utilizing enhanced
automation and sensing for situational awareness, and d) integration of
advanced technologies and data points for ML-driven enhanced decision support.
Enhanced digitalization and automation resulted in better network visibility at
various levels, including generation, transmission, and distribution. These
data or information can be utilized to take advantage of advanced machine
learning techniques for automation and increased power grid resilience. In this
paper, a) we review the impact of COVID-19 on power grid operations and actions
taken by operators/organizations to minimize the impact of COVID-19, and b) we
have presented the recently developed tool and concepts using natural language
processing (NLP) in the domain of machine learning and artificial intelligence
that can be used for increasing resiliency of power systems in normal and in
extreme scenarios such as COVID-19 pandemics.
</p>
<a href="http://arxiv.org/abs/2010.01746" target="_blank">arXiv:2010.01746</a> [<a href="http://arxiv.org/pdf/2010.01746" target="_blank">pdf</a>]

<h2>Simplicial Neural Networks. (arXiv:2010.03633v2 [cs.LG] UPDATED)</h2>
<h3>Stefania Ebli, Micha&#xeb;l Defferrard, Gard Spreemann</h3>
<p>We present simplicial neural networks (SNNs), a generalization of graph
neural networks to data that live on a class of topological spaces called
simplicial complexes. These are natural multi-dimensional extensions of graphs
that encode not only pairwise relationships but also higher-order interactions
between vertices - allowing us to consider richer data, including vector fields
and $n$-fold collaboration networks. We define an appropriate notion of
convolution that we leverage to construct the desired convolutional neural
networks. We test the SNNs on the task of imputing missing data on coauthorship
complexes.
</p>
<a href="http://arxiv.org/abs/2010.03633" target="_blank">arXiv:2010.03633</a> [<a href="http://arxiv.org/pdf/2010.03633" target="_blank">pdf</a>]

<h2>RAT iLQR: A Risk Auto-Tuning Controller to Optimally Account for Stochastic Model Mismatch. (arXiv:2010.08174v2 [cs.RO] UPDATED)</h2>
<h3>Haruki Nishimura, Negar Mehr, Adrien Gaidon, Mac Schwager</h3>
<p>Successful robotic operation in stochastic environments relies on accurate
characterization of the underlying probability distributions, yet this is often
imperfect due to limited knowledge. This work presents a control algorithm that
is capable of handling such distributional mismatches. Specifically, we propose
a novel nonlinear MPC for distributionally robust control, which plans locally
optimal feedback policies against a worst-case distribution within a given KL
divergence bound from a Gaussian distribution. Leveraging mathematical
equivalence between distributionally robust control and risk-sensitive optimal
control, our framework also provides an algorithm to dynamically adjust the
risk-sensitivity level online for risk-sensitive control. The benefits of the
distributional robustness as well as the automatic risk-sensitivity adjustment
are demonstrated in a dynamic collision avoidance scenario where the predictive
distribution of human motion is erroneous.
</p>
<a href="http://arxiv.org/abs/2010.08174" target="_blank">arXiv:2010.08174</a> [<a href="http://arxiv.org/pdf/2010.08174" target="_blank">pdf</a>]

<h2>Towards Compact Neural Networks via End-to-End Training: A Bayesian Tensor Approach with Automatic Rank Determination. (arXiv:2010.08689v2 [cs.LG] UPDATED)</h2>
<h3>Cole Hawkins, Xing Liu, Zheng Zhang</h3>
<p>While post-training model compression can greatly reduce the inference cost
of a deep neural network, uncompressed training still consumes a huge amount of
hardware resources, run-time and energy. It is highly desirable to directly
train a compact neural network from scratch with low memory and low
computational cost. Low-rank tensor decomposition is one of the most effective
approaches to reduce the memory and computing requirements of large-size neural
networks. However, directly training a low-rank tensorized neural network is a
very challenging task because it is hard to determine a proper tensor rank {\it
a priori}, which controls the model complexity and compression ratio in the
training process. This paper presents a novel end-to-end framework for low-rank
tensorized training of neural networks. We first develop a flexible Bayesian
model that can handle various low-rank tensor formats (e.g., CP, Tucker, tensor
train and tensor-train matrix) that compress neural network parameters in
training. This model can automatically determine the tensor ranks inside a
nonlinear forward model, which is beyond the capability of existing Bayesian
tensor methods. We further develop a scalable stochastic variational inference
solver to estimate the posterior density of large-scale problems in training.
Our work provides the first general-purpose rank-adaptive framework for
end-to-end tensorized training. Our numerical results on various neural network
architectures show orders-of-magnitude parameter reduction and little accuracy
loss (or even better accuracy) in the training process. Specifically, on a very
large deep learning recommendation system with over $4.2\times 10^9$ model
parameters, our method can reduce the variables to only $1.6\times 10^5$
automatically in the training process (i.e., by $2.6\times 10^4$ times) while
achieving almost the same accuracy.
</p>
<a href="http://arxiv.org/abs/2010.08689" target="_blank">arXiv:2010.08689</a> [<a href="http://arxiv.org/pdf/2010.08689" target="_blank">pdf</a>]

<h2>Language and Visual Entity Relationship Graph for Agent Navigation. (arXiv:2010.09304v2 [cs.CV] UPDATED)</h2>
<h3>Yicong Hong, Cristian Rodriguez-Opazo, Yuankai Qi, Qi Wu, Stephen Gould</h3>
<p>Vision-and-Language Navigation (VLN) requires an agent to navigate in a
real-world environment following natural language instructions. From both the
textual and visual perspectives, we find that the relationships among the
scene, its objects,and directional clues are essential for the agent to
interpret complex instructions and correctly perceive the environment. To
capture and utilize the relationships, we propose a novel Language and Visual
Entity Relationship Graph for modelling the inter-modal relationships between
text and vision, and the intra-modal relationships among visual entities. We
propose a message passing algorithm for propagating information between
language elements and visual entities in the graph, which we then combine to
determine the next action to take. Experiments show that by taking advantage of
the relationships we are able to improve over state-of-the-art. On the
Room-to-Room (R2R) benchmark, our method achieves the new best performance on
the test unseen split with success rate weighted by path length (SPL) of 52%.
On the Room-for-Room (R4R) dataset, our method significantly improves the
previous best from 13% to 34% on the success weighted by normalized dynamic
time warping (SDTW). Code is available at:
https://github.com/YicongHong/Entity-Graph-VLN.
</p>
<a href="http://arxiv.org/abs/2010.09304" target="_blank">arXiv:2010.09304</a> [<a href="http://arxiv.org/pdf/2010.09304" target="_blank">pdf</a>]

<h2>FUEL: Fast UAV Exploration using Incremental Frontier Structure and Hierarchical Planning. (arXiv:2010.11561v2 [cs.RO] UPDATED)</h2>
<h3>Boyu Zhou, Yichen Zhang, Xinyi Chen, Shaojie Shen</h3>
<p>Autonomous exploration is a fundamental problem for various applications of
unmanned aerial vehicles. Existing methods, however, were demonstrated to
insufficient exploration rate, due to the lack of efficient global coverage,
conservative motion plans and low decision frequencies. In this paper, we
propose FUEL, a hierarchical framework that can support Fast UAV Exploration in
complex unknown environments. We maintain crucial information in the entire
space required by exploration planning by a frontier information structure
(FIS), which can be updated incrementally when the space is explored. Supported
by the FIS, a hierarchical planner plans exploration motions in three steps,
which find efficient global coverage paths, refine a local set of viewpoints
and generate minimum-time trajectories in sequence. We present extensive
benchmark and real-world tests, in which our method completes the exploration
tasks with unprecedented efficiency (3-8 times faster) compared to
state-of-the-art approaches. Our method will be made open source to benefit the
community.
</p>
<a href="http://arxiv.org/abs/2010.11561" target="_blank">arXiv:2010.11561</a> [<a href="http://arxiv.org/pdf/2010.11561" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games. (arXiv:2010.11655v3 [cs.LG] UPDATED)</h2>
<h3>Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Joey Tianyi Zhou, Chengqi Zhang</h3>
<p>We study reinforcement learning (RL) for text-based games, which are
interactive simulations in the context of natural language. While different
methods have been developed to represent the environment information and
language actions, existing RL agents are not empowered with any reasoning
capabilities to deal with textual games. In this work, we aim to conduct
explicit reasoning with knowledge graphs for decision making, so that the
actions of an agent are generated and supported by an interpretable inference
procedure. We propose a stacked hierarchical attention mechanism to construct
an explicit representation of the reasoning process by exploiting the structure
of the knowledge graph. We extensively evaluate our method on a number of
man-made benchmark games, and the experimental results demonstrate that our
method performs better than existing text-based agents.
</p>
<a href="http://arxiv.org/abs/2010.11655" target="_blank">arXiv:2010.11655</a> [<a href="http://arxiv.org/pdf/2010.11655" target="_blank">pdf</a>]

<h2>Recovery of sparse linear classifiers from mixture of responses. (arXiv:2010.12087v3 [stat.ML] UPDATED)</h2>
<h3>Venkata Gandikota, Arya Mazumdar, Soumyabrata Pal</h3>
<p>In the problem of learning a mixture of linear classifiers, the aim is to
learn a collection of hyperplanes from a sequence of binary responses. Each
response is a result of querying with a vector and indicates the side of a
randomly chosen hyperplane from the collection the query vector belongs to.
This model provides a rich representation of heterogeneous data with
categorical labels and has only been studied in some special settings. We look
at a hitherto unstudied problem of query complexity upper bound of recovering
all the hyperplanes, especially for the case when the hyperplanes are sparse.
This setting is a natural generalization of the extreme quantization problem
known as 1-bit compressed sensing. Suppose we have a set of $\ell$ unknown
$k$-sparse vectors. We can query the set with another vector $\boldsymbol{a}$,
to obtain the sign of the inner product of $\boldsymbol{a}$ and a randomly
chosen vector from the $\ell$-set. How many queries are sufficient to identify
all the $\ell$ unknown vectors? This question is significantly more challenging
than both the basic 1-bit compressed sensing problem (i.e., $\ell=1$ case) and
the analogous regression problem (where the value instead of the sign is
provided). We provide rigorous query complexity results (with efficient
algorithms) for this problem.
</p>
<a href="http://arxiv.org/abs/2010.12087" target="_blank">arXiv:2010.12087</a> [<a href="http://arxiv.org/pdf/2010.12087" target="_blank">pdf</a>]

<h2>Adversarial Robust Low Rank Matrix Estimation: Compressed Sensing and Matrix Completion. (arXiv:2010.13018v2 [stat.ML] UPDATED)</h2>
<h3>Takeyuki Sasai, Hironori Fujisawa</h3>
<p>We consider robust low rank matrix estimation when outputs are contaminated
by adversary. Our method covers matrix compressed sensing (including lasso as a
partial problem) and matrix completion. We attain fast convergence rates by
using convex estimators.
</p>
<a href="http://arxiv.org/abs/2010.13018" target="_blank">arXiv:2010.13018</a> [<a href="http://arxiv.org/pdf/2010.13018" target="_blank">pdf</a>]

<h2>Selective Classification Can Magnify Disparities Across Groups. (arXiv:2010.14134v2 [cs.LG] UPDATED)</h2>
<h3>Erik Jones, Shiori Sagawa, Pang Wei Koh, Ananya Kumar, Percy Liang</h3>
<p>Selective classification, in which models can abstain on uncertain
predictions, is a natural approach to improving accuracy in settings where
errors are costly but abstentions are manageable. In this paper, we find that
while selective classification can improve average accuracies, it can
simultaneously magnify existing accuracy disparities between various groups
within a population, especially in the presence of spurious correlations. We
observe this behavior consistently across five vision and NLP datasets.
Surprisingly, increasing abstentions can even decrease accuracies on some
groups. To better understand this phenomenon, we study the margin distribution,
which captures the model's confidences over all predictions. For symmetric
margin distributions, we prove that whether selective classification
monotonically improves or worsens accuracy is fully determined by the accuracy
at full coverage (i.e., without any abstentions) and whether the distribution
satisfies a property we term left-log-concavity. Our analysis also shows that
selective classification tends to magnify full-coverage accuracy disparities.
Motivated by our analysis, we train distributionally-robust models that achieve
similar full coverage accuracies across groups and show that selective
classification uniformly improves each group on these models. Altogether, our
results imply selective classification should be used with care and underscore
the importance of models that perform equally well across groups at full
coverage.
</p>
<a href="http://arxiv.org/abs/2010.14134" target="_blank">arXiv:2010.14134</a> [<a href="http://arxiv.org/pdf/2010.14134" target="_blank">pdf</a>]

<h2>Succinct and Robust Multi-Agent Communication With Temporal Message Control. (arXiv:2010.14391v2 [cs.AI] UPDATED)</h2>
<h3>Sai Qian Zhang, Jieyu Lin, Qi Zhang</h3>
<p>Recent studies have shown that introducing communication between agents can
significantly improve overall performance in cooperative Multi-agent
reinforcement learning (MARL). However, existing communication schemes often
require agents to exchange an excessive number of messages at run-time under a
reliable communication channel, which hinders its practicality in many
real-world situations. In this paper, we present \textit{Temporal Message
Control} (TMC), a simple yet effective approach for achieving succinct and
robust communication in MARL. TMC applies a temporal smoothing technique to
drastically reduce the amount of information exchanged between agents.
Experiments show that TMC can significantly reduce inter-agent communication
overhead without impacting accuracy. Furthermore, TMC demonstrates much better
robustness against transmission loss than existing approaches in lossy
networking environments.
</p>
<a href="http://arxiv.org/abs/2010.14391" target="_blank">arXiv:2010.14391</a> [<a href="http://arxiv.org/pdf/2010.14391" target="_blank">pdf</a>]

<h2>Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in Remote Sensing Imagery. (arXiv:2011.03247v7 [cs.CV] UPDATED)</h2>
<h3>Shiqi Tian, Ailong Ma, Zhuo Zheng, Yanfei Zhong</h3>
<p>With the acceleration of the urban expansion, urban change detection (UCD),
as a significant and effective approach, can provide the change information
with respect to geospatial objects for dynamical urban analysis. However,
existing datasets suffer from three bottlenecks: (1) lack of high spatial
resolution images; (2) lack of semantic annotation; (3) lack of long-range
multi-temporal images. In this paper, we propose a large scale benchmark
dataset, termed Hi-UCD. This dataset uses aerial images with a spatial
resolution of 0.1 m provided by the Estonia Land Board, including three-time
phases, and semantically annotated with nine classes of land cover to obtain
the direction of ground objects change. It can be used for detecting and
analyzing refined urban changes. We benchmark our dataset using some classic
methods in binary and multi-class change detection. Experimental results show
that Hi-UCD is challenging yet useful. We hope the Hi-UCD can become a strong
benchmark accelerating future research.
</p>
<a href="http://arxiv.org/abs/2011.03247" target="_blank">arXiv:2011.03247</a> [<a href="http://arxiv.org/pdf/2011.03247" target="_blank">pdf</a>]

<h2>Real-Time Decentralized knowledge Transfer at the Edge. (arXiv:2011.05961v2 [cs.LG] UPDATED)</h2>
<h3>Orpaz Goldstein, Mohammad Kachuee, Dereck Shiell, Majid Sarrafzadeh</h3>
<p>Proliferation of edge networks creates islands of learning agents working on
local streams of data. Transferring knowledge between these agents in real-time
without exposing private data allows for collaboration to decrease learning
time, and increase model confidence. Incorporating knowledge from data that was
not seen by a local model creates an ability to debias a local model, or add to
classification abilities on data never before seen. Transferring knowledge in a
decentralized approach allows for models to retain their local insights, in
turn allowing for local flavors of a machine learning model. This approach
suits the decentralized architecture of edge networks, as a local edge node
will serve a community of learning agents that will likely encounter similar
data. We propose a method based on knowledge distillation for pairwise
knowledge transfer pipelines, and compare to other popular knowledge transfer
methods. Additionally, we test different scenarios of knowledge transfer
network construction and show the practicality of our approach. Based on our
experiments we show knowledge transfer using our model outperforms common
methods in a real time transfer scenario.
</p>
<a href="http://arxiv.org/abs/2011.05961" target="_blank">arXiv:2011.05961</a> [<a href="http://arxiv.org/pdf/2011.05961" target="_blank">pdf</a>]

<h2>AmphibianDetector: adaptive computation for moving objects detection. (arXiv:2011.07513v2 [cs.CV] UPDATED)</h2>
<h3>David Svitov, Sergey Alyamkin</h3>
<p>Convolutional neural networks (CNN) allow achieving the highest accuracy for
the task of object detection in images. Major challenges in further development
of object detectors are false-positive detections and high demand of processing
power. In this paper, we propose an approach to object detection which makes it
possible to reduce the number of false-positive detections by processing only
moving objects and reduce the required processing power for algorithm
inference. The proposed approach is a modification of CNN already trained for
object detection task. This method can be used to improve the accuracy of an
existing system by applying minor changes to the algorithm. The efficiency of
the proposed approach was demonstrated on the open dataset "CDNet2014
pedestrian". The implementation of the method proposed in the article is
available on the GitHub: https://github.com/david-svitov/AmphibianDetector
</p>
<a href="http://arxiv.org/abs/2011.07513" target="_blank">arXiv:2011.07513</a> [<a href="http://arxiv.org/pdf/2011.07513" target="_blank">pdf</a>]

<h2>Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification. (arXiv:2012.00317v2 [cs.CV] UPDATED)</h2>
<h3>Youngwan Lee, Hyung-Il Kim, Kimin Yun, Jinyoung Moon</h3>
<p>Video classification researches that have recently attracted attention are
the fields of temporal modeling and 3D efficient architecture. However, the
temporal modeling methods are not efficient or the 3D efficient architecture is
less interested in temporal modeling. For bridging the gap between them, we
propose an efficient temporal modeling 3D architecture, called VoV3D, that
consists of a temporal one-shot aggregation (T-OSA) module and depthwise
factorized component, D(2+1)D. The T-OSA is devised to build a feature
hierarchy by aggregating temporal features with different temporal receptive
fields. Stacking this T-OSA enables the network itself to model short-range as
well as long-range temporal relationships across frames without any external
modules. Inspired by kernel factorization and channel factorization, we also
design a depthwise spatiotemporal factorization module, named, D(2+1)D that
decomposes a 3D depthwise convolution into two spatial and temporal depthwise
convolutions for making our network more lightweight and efficient. By using
the proposed temporal modeling method (T-OSA), and the efficient factorized
component (D(2+1)D), we construct two types of VoV3D networks, VoV3D-M and
VoV3D-L. Thanks to its efficiency and effectiveness of temporal modeling,
VoV3D-L has 6x fewer model parameters and 16x less computation, surpassing a
state-of-the-art temporal modeling method on both Something-Something and
Kinetics-400. Furthermore, VoV3D shows better temporal modeling ability than a
state-of-the-art efficient 3D architecture, X3D having comparable model
capacity. We hope that VoV3D can serve as a baseline for efficient video
classification.
</p>
<a href="http://arxiv.org/abs/2012.00317" target="_blank">arXiv:2012.00317</a> [<a href="http://arxiv.org/pdf/2012.00317" target="_blank">pdf</a>]

<h2>The Neural Coding Framework for Learning Generative Models. (arXiv:2012.03405v3 [cs.LG] UPDATED)</h2>
<h3>Alexander Ororbia, Daniel Kifer</h3>
<p>Neural generative models can be used to learn complex probability
distributions from data, to sample from them, and to produce probability
density estimates. We propose a novel neural generative model inspired by the
theory of predictive processing in the brain. According to predictive
processing theory, the neurons in the brain form a hierarchy in which neurons
in one level form expectations about sensory inputs from another level. These
neurons update their local models based on differences between their
expectations and the observed signals. In a similar way, artificial neurons in
our generative model predict what neighboring neurons will do, and adjust their
parameters based on how well the predictions matched reality. This neural
generative model performs very well in practice. On a variety of benchmark
datasets and metrics, it either remains competitive with or significantly
outperforms other generative models with similar functionality (such as the
variational auto-encoder).
</p>
<a href="http://arxiv.org/abs/2012.03405" target="_blank">arXiv:2012.03405</a> [<a href="http://arxiv.org/pdf/2012.03405" target="_blank">pdf</a>]

<h2>Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem. (arXiv:2012.04461v4 [cs.AI] UPDATED)</h2>
<h3>Jiongzhi Zheng, Kun He, Jianrong Zhou, Yan Jin, Chu-min Li</h3>
<p>We address the Traveling Salesman Problem (TSP), a famous NP-hard
combinatorial optimization problem. And we propose a variable strategy
reinforced approach, denoted as VSR-LKH, which combines three reinforcement
learning methods (Q-learning, Sarsa and Monte Carlo) with the well-known TSP
algorithm, called Lin-Kernighan-Helsgaun (LKH). VSR-LKH replaces the inflexible
traversal operation in LKH, and lets the program learn to make choice at each
search step by reinforcement learning. Experimental results on 111 TSP
benchmarks from the TSPLIB with up to 85,900 cities demonstrate the excellent
performance of the proposed method.
</p>
<a href="http://arxiv.org/abs/2012.04461" target="_blank">arXiv:2012.04461</a> [<a href="http://arxiv.org/pdf/2012.04461" target="_blank">pdf</a>]

<h2>Adversarial Linear Contextual Bandits with Graph-Structured Side Observations. (arXiv:2012.05756v2 [cs.LG] UPDATED)</h2>
<h3>Lingda Wang, Bingcong Li, Huozhi Zhou, Georgios B. Giannakis, Lav R. Varshney, Zhizhen Zhao</h3>
<p>This paper studies the adversarial graphical contextual bandits, a variant of
adversarial multi-armed bandits that leverage two categories of the most common
side information: \emph{contexts} and \emph{side observations}. In this
setting, a learning agent repeatedly chooses from a set of $K$ actions after
being presented with a $d$-dimensional context vector. The agent not only
incurs and observes the loss of the chosen action, but also observes the losses
of its neighboring actions in the observation structures, which are encoded as
a series of feedback graphs. This setting models a variety of applications in
social networks, where both contexts and graph-structured side observations are
available. Two efficient algorithms are developed based on \texttt{EXP3}. Under
mild conditions, our analysis shows that for undirected feedback graphs the
first algorithm, \texttt{EXP3-LGC-U}, achieves the regret of order
$\mathcal{O}(\sqrt{(K+\alpha(G)d)T\log{K}})$ over the time horizon $T$, where
$\alpha(G)$ is the average \emph{independence number} of the feedback graphs. A
slightly weaker result is presented for the directed graph setting as well. The
second algorithm, \texttt{EXP3-LGC-IX}, is developed for a special class of
problems, for which the regret is reduced to
$\mathcal{O}(\sqrt{\alpha(G)dT\log{K}\log(KT)})$ for both directed as well as
undirected feedback graphs. Numerical tests corroborate the efficiency of
proposed algorithms.
</p>
<a href="http://arxiv.org/abs/2012.05756" target="_blank">arXiv:2012.05756</a> [<a href="http://arxiv.org/pdf/2012.05756" target="_blank">pdf</a>]

<h2>A Study of Condition Numbers for First-Order Optimization. (arXiv:2012.05782v2 [cs.LG] UPDATED)</h2>
<h3>Charles Guille-Escuret, Baptiste Goujaud, Manuela Girotti, Ioannis Mitliagkas</h3>
<p>The study of first-order optimization algorithms (FOA) typically starts with
assumptions on the objective functions, most commonly smoothness and strong
convexity. These metrics are used to tune the hyperparameters of FOA. We
introduce a class of perturbations quantified via a new norm, called *-norm. We
show that adding a small perturbation to the objective function has an
equivalently small impact on the behavior of any FOA, which suggests that it
should have a minor impact on the tuning of the algorithm. However, we show
that smoothness and strong convexity can be heavily impacted by arbitrarily
small perturbations, leading to excessively conservative tunings and
convergence issues. In view of these observations, we propose a notion of
continuity of the metrics, which is essential for a robust tuning strategy.
Since smoothness and strong convexity are not continuous, we propose a
comprehensive study of existing alternative metrics which we prove to be
continuous. We describe their mutual relations and provide their guaranteed
convergence rates for the Gradient Descent algorithm accordingly tuned. Finally
we discuss how our work impacts the theoretical understanding of FOA and their
performances.
</p>
<a href="http://arxiv.org/abs/2012.05782" target="_blank">arXiv:2012.05782</a> [<a href="http://arxiv.org/pdf/2012.05782" target="_blank">pdf</a>]

<h2>Monitoring multimode processes: a modified PCA algorithm with continual learning ability. (arXiv:2012.07044v3 [stat.ML] UPDATED)</h2>
<h3>Jingxin Zhang, Donghua Zhou, Maoyin Chen</h3>
<p>For multimode processes, one has to establish local monitoring models
corresponding to local modes. However, the significant features of previous
modes may be catastrophically forgotten when a monitoring model for the current
mode is built. It would result in an abrupt performance decrease. Is it
possible to make local monitoring model remember the features of previous
modes? Choosing the principal component analysis (PCA) as a basic monitoring
model, we try to resolve this problem. A modified PCA algorithm is built with
continual learning ability for monitoring multimode processes, which adopts
elastic weight consolidation (EWC) to overcome catastrophic forgetting of PCA
for successive modes. It is called PCA-EWC, where the significant features of
previous modes are preserved when a PCA model is established for the current
mode. The computational complexity and key parameters are discussed to further
understand the relationship between PCA and the proposed algorithm. Numerical
case study and a practical industrial system in China are employed to
illustrate the effectiveness of the proposed algorithm.
</p>
<a href="http://arxiv.org/abs/2012.07044" target="_blank">arXiv:2012.07044</a> [<a href="http://arxiv.org/pdf/2012.07044" target="_blank">pdf</a>]

<h2>Bayes DistNet -- A Robust Neural Network for Algorithm Runtime Distribution Predictions. (arXiv:2012.07197v2 [cs.LG] UPDATED)</h2>
<h3>Jake Tuero, Michael Buro</h3>
<p>Randomized algorithms are used in many state-of-the-art solvers for
constraint satisfaction problems (CSP) and Boolean satisfiability (SAT)
problems. For many of these problems, there is no single solver which will
dominate others. Having access to the underlying runtime distributions (RTD) of
these solvers can allow for better use of algorithm selection, algorithm
portfolios, and restart strategies. Previous state-of-the-art methods directly
try to predict a fixed parametric distribution that the input instance follows.
In this paper, we extend RTD prediction models into the Bayesian setting for
the first time. This new model achieves robust predictive performance in the
low observation setting, as well as handling censored observations. This
technique also allows for richer representations which cannot be achieved by
the classical models which restrict their output representations. Our model
outperforms the previous state-of-the-art model in settings in which data is
scarce, and can make use of censored data such as lower bound time estimates,
where that type of data would otherwise be discarded. It can also quantify its
uncertainty in its predictions, allowing for algorithm portfolio models to make
better informed decisions about which algorithm to run on a particular
instance.
</p>
<a href="http://arxiv.org/abs/2012.07197" target="_blank">arXiv:2012.07197</a> [<a href="http://arxiv.org/pdf/2012.07197" target="_blank">pdf</a>]

<h2>Automated system to measure Tandem Gait to assess executive functions in children. (arXiv:2012.08662v2 [cs.CV] UPDATED)</h2>
<h3>Mohammad Zaki Zadeh, Ashwin Ramesh Babu, Ashish Jaiswal, Maria Kyrarini, Morris Bell, Fillia Makedon</h3>
<p>As mobile technologies have become ubiquitous in recent years, computer-based
cognitive tests have become more popular and efficient. In this work, we focus
on assessing motor function in children by analyzing their gait movements.
Although there has been a lot of research on designing automated assessment
systems for gait analysis, most of these efforts use obtrusive wearable sensors
for measuring body movements. We have devised a computer vision-based
assessment system that only requires a camera which makes it easier to employ
in school or home environments. A dataset has been created with 27 children
performing the test. Furthermore in order to improve the accuracy of the
system, a deep learning based model was pre-trained on NTU-RGB+D 120 dataset
and then it was fine-tuned on our gait dataset. The results highlight the
efficacy of proposed work for automating the assessment of children's
performances by achieving 76.61% classification accuracy.
</p>
<a href="http://arxiv.org/abs/2012.08662" target="_blank">arXiv:2012.08662</a> [<a href="http://arxiv.org/pdf/2012.08662" target="_blank">pdf</a>]

<h2>Applying Deutsch's concept of good explanations to artificial intelligence and neuroscience -- an initial exploration. (arXiv:2012.09318v2 [cs.AI] UPDATED)</h2>
<h3>Daniel C. Elton</h3>
<p>Artificial intelligence has made great strides since the deep learning
revolution, but AI systems still struggle to extrapolate outside of their
training data and adapt to new situations. For inspiration we look to the
domain of science, where scientists have been able to develop theories which
show remarkable ability to extrapolate and sometimes predict the existence of
phenomena which have never been observed before. According to David Deutsch,
this type of extrapolation, which he calls "reach", is due to scientific
theories being hard to vary. In this work we investigate Deutsch's hard-to-vary
principle and how it relates to more formalized principles in deep learning
such as the bias-variance trade-off and Occam's razor. We distinguish internal
variability, how much a model/theory can be varied internally while still
yielding the same predictions, with external variability, which is how much a
model must be varied to accurately predict new, out-of-distribution data. We
discuss how to measure internal variability using the size of the Rashomon set
and how to measure external variability using Kolmogorov complexity. We explore
what role hard-to-vary explanations play in intelligence by looking at the
human brain and distinguish two learning systems in the brain. The first system
operates similar to deep learning and likely underlies most of perception and
motor control while the second is a more creative system capable of generating
hard-to-vary explanations of the world. We argue that figuring out how
replicate this second system, which is capable of generating hard-to-vary
explanations, is a key challenge which needs to be solved in order to realize
artificial general intelligence. We make contact with the framework of
Popperian epistemology which rejects induction and asserts that knowledge
generation is an evolutionary process which proceeds through conjecture and
refutation.
</p>
<a href="http://arxiv.org/abs/2012.09318" target="_blank">arXiv:2012.09318</a> [<a href="http://arxiv.org/pdf/2012.09318" target="_blank">pdf</a>]

<h2>On graded semantics of abstract argumentation: Extension-based case. (arXiv:2012.10592v2 [cs.AI] UPDATED)</h2>
<h3>Lixing Tan, Zhaohui Zhu, Jinjin Zhang</h3>
<p>Based on Grossi and Modgil's recent work [1], this paper considers some
issues on extension-based semantics for abstract argumentation framework (AAF,
for short). First, an alternative fundamental lemma is given, which generalizes
the corresponding result obtained in [1]. This lemma plays a central role in
constructing some special extensions in terms of iterations of the defense
function. Applying this lemma, some flaws in [1] are corrected and a number of
structural properties of various extension-based semantics are given. Second,
the operator so-called reduced meet modulo an ultrafilter is presented. A
number of fundamental semantics for AAF, including conflict-free, admissible,
complete and stable semantics, are shown to be closed under this operator.
Based on this fact, we provide a concise and uniform proof method to establish
the universal definability of a family of range related semantics. Thirdly,
using model-theoretical tools, we characterize the class of extension-based
semantics that is closed under reduced meet modulo any ultrafilter, which
brings us a metatheorem concerning the universal definability of range related
semantics. Finally, in addition to range related semantics, some graded
variants of traditional semantics of AAF are also considered in this paper,
e.g., ideal semantics, eager semantics, etc.
</p>
<a href="http://arxiv.org/abs/2012.10592" target="_blank">arXiv:2012.10592</a> [<a href="http://arxiv.org/pdf/2012.10592" target="_blank">pdf</a>]

<h2>Space ML: Distributed Open-source Research with Citizen Scientists for the Advancement of Space Technology for NASA. (arXiv:2012.10610v2 [cs.CV] UPDATED)</h2>
<h3>Anirudh Koul, Siddha Ganju, Meher Kasam, James Parr</h3>
<p>Traditionally, academic labs conduct open-ended research with the primary
focus on discoveries with long-term value, rather than direct products that can
be deployed in the real world. On the other hand, research in the industry is
driven by its expected commercial return on investment, and hence focuses on a
real world product with short-term timelines. In both cases, opportunity is
selective, often available to researchers with advanced educational
backgrounds. Research often happens behind closed doors and may be kept
confidential until either its publication or product release, exacerbating the
problem of AI reproducibility and slowing down future research by others in the
field. As many research organizations tend to exclusively focus on specific
areas, opportunities for interdisciplinary research reduce. Undertaking
long-term bold research in unexplored fields with non-commercial yet great
public value is hard due to factors including the high upfront risk, budgetary
constraints, and a lack of availability of data and experts in niche fields.
Only a few companies or well-funded research labs can afford to do such
long-term research. With research organizations focused on an exploding array
of fields and resources spread thin, opportunities for the maturation of
interdisciplinary research reduce. Apart from these exigencies, there is also a
need to engage citizen scientists through open-source contributors to play an
active part in the research dialogue. We present a short case study of Space
ML, an extension of the Frontier Development Lab, an AI accelerator for NASA.
Space ML distributes open-source research and invites volunteer citizen
scientists to partake in development and deployment of high social value
products at the intersection of space and AI.
</p>
<a href="http://arxiv.org/abs/2012.10610" target="_blank">arXiv:2012.10610</a> [<a href="http://arxiv.org/pdf/2012.10610" target="_blank">pdf</a>]

<h2>Humanoid Robot Pitch Axis Stabilization using Linear Quadratic Regulator with Fuzzy Logic and Capture Point. (arXiv:2012.10867v2 [cs.RO] UPDATED)</h2>
<h3>Bagaskara Primastya Putra, Gabrielle Satya Mahardika, Muhammad Faris, Adha Imam Cahyadi</h3>
<p>This paper aims for a controller that can stabilize a position-controlled
humanoid robot when standing still or walking on synthetic grass even when
subjected to external disturbances. Two types of controllers are designed and
implemented: ankle strategy and stepping strategy. The robot's joints consist
of position-controlled servos which can be complicated to model analytically
due to nonlinearities and non-measurable parameters, hence the dynamic model of
the humanoid robot is acquired using a non-recursive least squares system
identification. This model is also used to design a Kalman Filter to estimate
the system states from noisy inertial measurement unit (IMU) sensor and design
a linear quadratic regulator (LQR) controller. To handle the nonlinearities,
the LQR controller is extended with fuzzy logic algorithm that changes the LQR
gain value based on angle and angular velocity membership functions. The
proposed control system can maintain the humanoid robot's stability around the
pitch axis when subject to pendulum disturbances or even restraining force from
a spring balance.
</p>
<a href="http://arxiv.org/abs/2012.10867" target="_blank">arXiv:2012.10867</a> [<a href="http://arxiv.org/pdf/2012.10867" target="_blank">pdf</a>]

<h2>Fairness, Welfare, and Equity in Personalized Pricing. (arXiv:2012.11066v2 [cs.LG] UPDATED)</h2>
<h3>Nathan Kallus, Angela Zhou</h3>
<p>We study the interplay of fairness, welfare, and equity considerations in
personalized pricing based on customer features. Sellers are increasingly able
to conduct price personalization based on predictive modeling of demand
conditional on covariates: setting customized interest rates, targeted
discounts of consumer goods, and personalized subsidies of scarce resources
with positive externalities like vaccines and bed nets. These different
application areas may lead to different concerns around fairness, welfare, and
equity on different objectives: price burdens on consumers, price envy, firm
revenue, access to a good, equal access, and distributional consequences when
the good in question further impacts downstream outcomes of interest. We
conduct a comprehensive literature review in order to disentangle these
different normative considerations and propose a taxonomy of different
objectives with mathematical definitions. We focus on observational metrics
that do not assume access to an underlying valuation distribution which is
either unobserved due to binary feedback or ill-defined due to overriding
behavioral concerns regarding interpreting revealed preferences. In the setting
of personalized pricing for the provision of goods with positive benefits, we
discuss how price optimization may provide unambiguous benefit by achieving a
"triple bottom line": personalized pricing enables expanding access, which in
turn may lead to gains in welfare due to heterogeneous utility, and improve
revenue or budget utilization. We empirically demonstrate the potential
benefits of personalized pricing in two settings: pricing subsidies for an
elective vaccine, and the effects of personalized interest rates on downstream
outcomes in microcredit.
</p>
<a href="http://arxiv.org/abs/2012.11066" target="_blank">arXiv:2012.11066</a> [<a href="http://arxiv.org/pdf/2012.11066" target="_blank">pdf</a>]

<h2>Human Action Recognition from Various Data Modalities: A Review. (arXiv:2012.11866v2 [cs.CV] UPDATED)</h2>
<h3>Zehua Sun, Jun Liu, Qiuhong Ke, Hossein Rahmani, Mohammed Bennamoun, Gang Wang</h3>
<p>Human Action Recognition (HAR), aiming to understand human behaviors and then
assign category labels, has a wide range of applications, and thus has been
attracting increasing attention in the field of computer vision. Generally,
human actions can be represented using various data modalities, such as RGB,
skeleton, depth, infrared sequence, point cloud, event stream, audio,
acceleration, radar, and WiFi, etc., which encode different sources of useful
yet distinct information and have various advantages and application scenarios.
Consequently, lots of existing works have attempted to investigate different
types of approaches for HAR using various modalities. In this paper, we give a
comprehensive survey for HAR from the perspective of the input data modalities.
Specifically, we review both the hand-crafted feature-based and deep
learning-based methods for single data modalities, and also review the methods
based on multiple modalities, including the fusion-based frameworks and the
co-learning-based approaches. The current benchmark datasets for HAR are also
introduced. Finally, we discuss some potentially important research directions
in this area.
</p>
<a href="http://arxiv.org/abs/2012.11866" target="_blank">arXiv:2012.11866</a> [<a href="http://arxiv.org/pdf/2012.11866" target="_blank">pdf</a>]

<h2>Query Answering via Decentralized Search. (arXiv:2012.12192v2 [cs.AI] UPDATED)</h2>
<h3>Liang Ma</h3>
<p>Expert networks are formed by a group of expert-professionals with different
specialties to collaboratively resolve specific queries posted to the network.
In such networks, when a query reaches an expert who does not have sufficient
expertise, this query needs to be routed to other experts for further
processing until it is completely solved; therefore, query answering efficiency
is sensitive to the underlying query routing mechanism being used. Among all
possible query routing mechanisms, decentralized search, operating purely on
each expert's local information without any knowledge of network global
structure, represents the most basic and scalable routing mechanism, which is
applicable to any network scenarios even in dynamic networks. However, there is
still a lack of fundamental understanding of the efficiency of decentralized
search in expert networks. In this regard, we investigate decentralized search
by quantifying its performance under a variety of network settings. Our key
findings reveal the existence of network conditions, under which decentralized
search can achieve significantly short query routing paths (i.e., between
$O(\log n)$ and $O(\log^2 n)$ hops, $n$: total number of experts in the
network). Based on such theoretical foundation, we further study how the unique
properties of decentralized search in expert networks is related to the
anecdotal small-world phenomenon. In addition, we demonstrate that
decentralized search is robust against estimation errors introduced by
misinterpreting the required expertise levels. To the best of our knowledge,
this is the first work studying fundamental behaviors of decentralized search
in expert networks. The developed performance bounds, confirmed by real
datasets, are able to assist in predicting network performance and designing
complex expert networks.
</p>
<a href="http://arxiv.org/abs/2012.12192" target="_blank">arXiv:2012.12192</a> [<a href="http://arxiv.org/pdf/2012.12192" target="_blank">pdf</a>]

<h2>Geometric robust descriptor for 3D point cloud. (arXiv:2012.12215v2 [cs.CV] UPDATED)</h2>
<h3>Seung Hwan Jung, Yeong-Gil Shin, Minyoung Chung</h3>
<p>We propose rotation robust and density robust local geometric descriptor.
Local geometric feature of point cloud is used in many applications, for
example, to find correspondences in 3D registration and to segment local
regions. Usually, application accuracy depends on the discriminative power of
the local geometric features. However, there are some problems such as point
sparsity, rotated point cloud, and so on. In this paper, we present new local
feature generation method to make a rotation robust and density robust
descriptor. First, we place kernels aligned around each point and align them to
the normal of the point. To avoid the sign problem of the normal vector, we use
symmetric kernel point distribution with respect to the tangent plane. Next,
from each kernel point, we estimate geometric information which is rotation
robust and discriminative. Finally, we operate convolution process with
consideration of kernel point structure, and aggregate all kernel features. We
experiment our local descriptors on the ModelNet40 dataset for registration and
classification, and the ShapeNet part dataset for segmentation. Our descriptor
shows discriminative power regardless of point distribution.
</p>
<a href="http://arxiv.org/abs/2012.12215" target="_blank">arXiv:2012.12215</a> [<a href="http://arxiv.org/pdf/2012.12215" target="_blank">pdf</a>]

<h2>SWA Object Detection. (arXiv:2012.12645v2 [cs.CV] UPDATED)</h2>
<h3>Haoyang Zhang, Ying Wang, Feras Dayoub, Niko S&#xfc;nderhauf</h3>
<p>Do you want to improve 1.0 AP for your object detector without any inference
cost and any change to your detector? Let us tell you such a recipe. It is
surprisingly simple: train your detector for an extra 12 epochs using cyclical
learning rates and then average these 12 checkpoints as your final detection
model. This potent recipe is inspired by Stochastic Weights Averaging (SWA),
which is proposed in arXiv:1803.05407 for improving generalization in deep
neural networks. We found it also very effective in object detection. In this
technique report, we systematically investigate the effects of applying SWA to
object detection as well as instance segmentation. Through extensive
experiments, we discover a good policy of performing SWA in object detection,
and we consistently achieve $\sim$1.0 AP improvement over various popular
detectors on the challenging COCO benchmark. We hope this work will make more
researchers in object detection know this technique and help them train better
object detectors. Code is available at:
https://github.com/hyz-xmaster/swa_object_detection .
</p>
<a href="http://arxiv.org/abs/2012.12645" target="_blank">arXiv:2012.12645</a> [<a href="http://arxiv.org/pdf/2012.12645" target="_blank">pdf</a>]

<h2>Hiding Among the Clones: A Simple and Nearly Optimal Analysis of Privacy Amplification by Shuffling. (arXiv:2012.12803v2 [cs.LG] UPDATED)</h2>
<h3>Vitaly Feldman, Audra McMillan, Kunal Talwar</h3>
<p>Recent work of Erlingsson, Feldman, Mironov, Raghunathan, Talwar, and
Thakurta [EFMRTT19] demonstrates that random shuffling amplifies differential
privacy guarantees of locally randomized data. Such amplification implies
substantially stronger privacy guarantees for systems in which data is
contributed anonymously [BEMMRLRKTS17] and has lead to significant interest in
the shuffle model of privacy [CSUZZ19,EFMRTT19].

We show that random shuffling of $n$ data records that are input to
$\varepsilon_0$-differentially private local randomizers results in an
$(O((1-e^{-\varepsilon_0})\sqrt{\frac{e^{\varepsilon_0}\log(1/\delta)}{n}}),
\delta)$-differentially private algorithm. This significantly improves over
previous work and achieves the asymptotically optimal dependence in
$\varepsilon_0$. Our result is based on a new approach that is simpler than
previous work and extends to approximate differential privacy with nearly the
same guarantees. Our work also yields an empirical method to derive tighter
bounds the resulting $\varepsilon$ and we show that it gets to within a small
constant factor of the optimal bound. As a direct corollary of our analysis, we
derive a simple and asymptotically optimal algorithm for discrete distribution
estimation in the shuffle model of privacy. We also observe that our result
implies the first asymptotically optimal privacy analysis of noisy stochastic
gradient descent that applies to sampling without replacement.
</p>
<a href="http://arxiv.org/abs/2012.12803" target="_blank">arXiv:2012.12803</a> [<a href="http://arxiv.org/pdf/2012.12803" target="_blank">pdf</a>]

<h2>Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks. (arXiv:2012.13085v2 [cs.LG] UPDATED)</h2>
<h3>Binghui Wang, Jinyuan Jia, Neil Zhenqiang Gong</h3>
<p>Semi-supervised node classification on graph-structured data has many
applications such as fraud detection, fake account and review detection, user's
private attribute inference in social networks, and community detection.
Various methods such as pairwise Markov Random Fields (pMRF) and graph neural
networks were developed for semi-supervised node classification. pMRF is more
efficient than graph neural networks. However, existing pMRF-based methods are
less accurate than graph neural networks, due to a key limitation that they
assume a heuristics-based constant edge potential for all edges. In this work,
we aim to address the key limitation of existing pMRF-based methods. In
particular, we propose to learn edge potentials for pMRF. Our evaluation
results on various types of graph datasets show that our optimized pMRF-based
method consistently outperforms existing graph neural networks in terms of both
accuracy and efficiency. Our results highlight that previous work may have
underestimated the power of pMRF for semi-supervised node classification.
</p>
<a href="http://arxiv.org/abs/2012.13085" target="_blank">arXiv:2012.13085</a> [<a href="http://arxiv.org/pdf/2012.13085" target="_blank">pdf</a>]

<h2>Auto-Agent-Distiller: Towards Efficient Deep Reinforcement Learning Agents via Neural Architecture Search. (arXiv:2012.13091v2 [cs.LG] UPDATED)</h2>
<h3>Yonggan Fu, Zhongzhi Yu, Yongan Zhang, Yingyan Lin</h3>
<p>AlphaGo's astonishing performance has ignited an explosive interest in
developing deep reinforcement learning (DRL) for numerous real-world
applications, such as intelligent robotics. However, the often prohibitive
complexity of DRL stands at the odds with the required real-time control and
constrained resources in many DRL applications, limiting the great potential of
DRL powered intelligent devices. While substantial efforts have been devoted to
compressing other deep learning models, existing works barely touch the surface
of compressing DRL. In this work, we first identify that there exists an
optimal model size of DRL that can maximize both the test scores and
efficiency, motivating the need for task-specific DRL agents. We therefore
propose an Auto-Agent-Distiller (A2D) framework, which to our best knowledge is
the first neural architecture search (NAS) applied to DRL to automatically
search for the optimal DRL agents for various tasks that optimize both the test
scores and efficiency. Specifically, we demonstrate that vanilla NAS can easily
fail in searching for the optimal agents, due to its resulting high variance in
DRL training stability, and then develop a novel distillation mechanism to
distill the knowledge from both the teacher agent's actor and critic to
stabilize the searching process and improve the searched agents' optimality.
Extensive experiments and ablation studies consistently validate our findings
and the advantages and general applicability of our A2D, outperforming manually
designed DRL in both the test scores and efficiency. All the codes will be
released upon acceptance.
</p>
<a href="http://arxiv.org/abs/2012.13091" target="_blank">arXiv:2012.13091</a> [<a href="http://arxiv.org/pdf/2012.13091" target="_blank">pdf</a>]

<h2>Memory-Efficient Hierarchical Neural Architecture Search for Image Restoration. (arXiv:2012.13212v2 [cs.CV] UPDATED)</h2>
<h3>Haokui Zhang, Ying Li, Chengrong Gong, Hao Chen, Zongwen Bai, Chunhua Shen</h3>
<p>Recently, much attention has been spent on neural architecture search (NAS)
approaches, which often outperform manually designed architectures on highlevel
vision tasks. Inspired by this, we attempt to leverage NAS technique to
automatically design efficient network architectures for low-level image
restoration tasks. In this paper, we propose a memory-efficient hierarchical
NAS HiNAS (HiNAS) and apply to two such tasks: image denoising and image
super-resolution. HiNAS adopts gradient based search strategies and builds an
flexible hierarchical search space, including inner search space and outer
search space, which in charge of designing cell architectures and deciding cell
widths, respectively. For inner search space, we propose layerwise architecture
sharing strategy (LWAS), resulting in more flexible architectures and better
performance. For outer search space, we propose cell sharing strategy to save
memory, and considerably accelerate the search speed. The proposed HiNAS is
both memory and computation efficient. With a single GTX1080Ti GPU, it takes
only about 1 hour for searching for denoising network on BSD 500 and 3.5 hours
for searching for the super-resolution structure on DIV2K. Experimental results
show that the architectures found by HiNAS have fewer parameters and enjoy a
faster inference speed, while achieving highly competitive performance compared
with state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.13212" target="_blank">arXiv:2012.13212</a> [<a href="http://arxiv.org/pdf/2012.13212" target="_blank">pdf</a>]

<h2>Pain Assessment based on fNIRS using Bidirectional LSTMs. (arXiv:2012.13231v2 [cs.LG] UPDATED)</h2>
<h3>Raul Fernandez Rojas, Julio Romero, Jehu Lopez-Aparicio, Keng-Liang Ou</h3>
<p>Assessing pain in patients unable to speak (also called non-verbal patients)
is extremely complicated and often is done by clinical judgement. However, this
method is not reliable since patients vital signs can fluctuate significantly
due to other underlying medical conditions. No objective diagnosis test exists
to date that can assist medical practitioners in the diagnosis of pain. In this
study we propose the use of functional near-infrared spectroscopy (fNIRS) and
deep learning for the assessment of human pain. The aim of this study is to
explore the use deep learning to automatically learn features from fNIRS raw
data to reduce the level of subjectivity and domain knowledge required in the
design of hand-crafted features. Four deep learning models were evaluated,
multilayer perceptron (MLP), forward and backward long short-term memory
net-works (LSTM), and bidirectional LSTM. The results showed that the Bi-LSTM
model achieved the highest accuracy (90.6%)and faster than the other three
models. These results advance knowledge in pain assessment using neuroimaging
as a method of diagnosis and represent a step closer to developing a
physiologically based diagnosis of human pain that will benefit vulnerable
populations who cannot self-report pain.
</p>
<a href="http://arxiv.org/abs/2012.13231" target="_blank">arXiv:2012.13231</a> [<a href="http://arxiv.org/pdf/2012.13231" target="_blank">pdf</a>]

<h2>Deep Semi-Supervised Embedded Clustering (DSEC) for Stratification of Heart Failure Patients. (arXiv:2012.13233v2 [cs.LG] UPDATED)</h2>
<h3>Oliver Carr, Stojan Jovanovic, Luca Albergante, Fernando Andreotti, Robert D&#xfc;richen, Nadia Lipunova, Janie Baxter, Rabia Khan, Benjamin Irving</h3>
<p>Determining phenotypes of diseases can have considerable benefits for
in-hospital patient care and to drug development. The structure of high
dimensional data sets such as electronic health records are often represented
through an embedding of the data, with clustering methods used to group data of
similar structure. If subgroups are known to exist within data, supervised
methods may be used to influence the clusters discovered. We propose to extend
deep embedded clustering to a semi-supervised deep embedded clustering
algorithm to stratify subgroups through known labels in the data. In this work
we apply deep semi-supervised embedded clustering to determine data-driven
patient subgroups of heart failure from the electronic health records of 4,487
heart failure and control patients. We find clinically relevant clusters from
an embedded space derived from heterogeneous data. The proposed algorithm can
potentially find new undiagnosed subgroups of patients that have different
outcomes, and, therefore, lead to improved treatments.
</p>
<a href="http://arxiv.org/abs/2012.13233" target="_blank">arXiv:2012.13233</a> [<a href="http://arxiv.org/pdf/2012.13233" target="_blank">pdf</a>]

<h2>Leave Zero Out: Towards a No-Cross-Validation Approach for Model Selection. (arXiv:2012.13309v2 [cs.LG] UPDATED)</h2>
<h3>Weikai Li, Chuanxing Geng, Songcan Chen</h3>
<p>As the main workhorse for model selection, Cross Validation (CV) has achieved
an empirical success due to its simplicity and intuitiveness. However, despite
its ubiquitous role, CV often falls into the following notorious dilemmas. On
the one hand, for small data cases, CV suffers a conservatively biased
estimation, since some part of the limited data has to hold out for validation.
On the other hand, for large data cases, CV tends to be extremely cumbersome,
e.g., intolerant time-consuming, due to the repeated training procedures.
Naturally, a straightforward ambition for CV is to validate the models with far
less computational cost, while making full use of the entire given data-set for
training. Thus, instead of holding out the given data, a cheap and
theoretically guaranteed auxiliary/augmented validation is derived
strategically in this paper. Such an embarrassingly simple strategy only needs
to train models on the entire given data-set once, making the model-selection
considerably efficient. In addition, the proposed validation approach is
suitable for a wide range of learning settings due to the independence of both
augmentation and out-of-sample estimation on learning process. In the end, we
demonstrate the accuracy and computational benefits of our proposed method by
extensive evaluation on multiple data-sets, models and tasks.
</p>
<a href="http://arxiv.org/abs/2012.13309" target="_blank">arXiv:2012.13309</a> [<a href="http://arxiv.org/pdf/2012.13309" target="_blank">pdf</a>]

<h2>An Active Learning Method for Diabetic Retinopathy Classification with Uncertainty Quantification. (arXiv:2012.13325v2 [cs.LG] UPDATED)</h2>
<h3>Muhammad Ahtazaz Ahsan, Adnan Qayyum, Junaid Qadir, Adeel Razi</h3>
<p>In recent years, deep learning (DL) techniques have provided state-of-the-art
performance on different medical imaging tasks. However, the availability of
good quality annotated medical data is very challenging due to involved time
constraints and the availability of expert annotators, e.g., radiologists. In
addition, DL is data-hungry and their training requires extensive computational
resources. Another problem with DL is their black-box nature and lack of
transparency on its inner working which inhibits causal understanding and
reasoning. In this paper, we jointly address these challenges by proposing a
hybrid model, which uses a Bayesian convolutional neural network (BCNN) for
uncertainty quantification, and an active learning approach for annotating the
unlabelled data. The BCNN is used as a feature descriptor and these features
are then used for training a model, in an active learning setting. We evaluate
the proposed framework for diabetic retinopathy classification problem and have
achieved state-of-the-art performance in terms of different metrics.
</p>
<a href="http://arxiv.org/abs/2012.13325" target="_blank">arXiv:2012.13325</a> [<a href="http://arxiv.org/pdf/2012.13325" target="_blank">pdf</a>]

<h2>A Physics-Informed Deep Learning Paradigm for Car-Following Models. (arXiv:2012.13376v2 [cs.LG] UPDATED)</h2>
<h3>Zhaobin Mo, Xuan Di, Rongye Shi</h3>
<p>Car-following behavior has been extensively studied using physics-based
models, such as the Intelligent Driver Model. These models successfully
interpret traffic phenomena observed in the real-world but may not fully
capture the complex cognitive process of driving. Deep learning models, on the
other hand, have demonstrated their power in capturing observed traffic
phenomena but require a large amount of driving data to train. This paper aims
to develop a family of neural network based car-following models that are
informed by physics-based models, which leverage the advantage of both
physics-based (being data-efficient and interpretable) and deep learning based
(being generalizable) models. We design physics-informed deep learning for
car-following (PIDL-CF) architectures encoded with two popular physics-based
models - IDM and OVM, on which acceleration is predicted for four traffic
regimes: acceleration, deceleration, cruising, and emergency braking. Two types
of PIDL-CFM problems are studied, one to predict acceleration only and the
other to jointly predict acceleration and discover model parameters. We also
demonstrate the superior performance of PIDL with the Next Generation
SIMulation (NGSIM) dataset over baselines, especially when the training data is
sparse. The results demonstrate the superior performance of neural networks
informed by physics over those without. The developed PIDL-CF framework holds
the potential for system identification of driving models and for the
development of driving-based controls for automated vehicles.
</p>
<a href="http://arxiv.org/abs/2012.13376" target="_blank">arXiv:2012.13376</a> [<a href="http://arxiv.org/pdf/2012.13376" target="_blank">pdf</a>]

<h2>Deep Learning-Based Human Pose Estimation: A Survey. (arXiv:2012.13392v2 [cs.CV] UPDATED)</h2>
<h3>Ce Zheng, Wenhan Wu, Taojiannan Yang, Sijie Zhu, Chen Chen, Ruixu Liu, Ju Shen, Nasser Kehtarnavaz, Mubarak Shah</h3>
<p>Human pose estimation aims to locate the human body parts and build human
body representation (e.g., body skeleton) from input data such as images and
videos. It has drawn increasing attention during the past decade and has been
utilized in a wide range of applications including human-computer interaction,
motion analysis, augmented reality, and virtual reality. Although the recently
developed deep learning-based solutions have achieved high performance in human
pose estimation, there still remain challenges due to insufficient training
data, depth ambiguities, and occlusion. The goal of this survey paper is to
provide a comprehensive review of recent deep learning-based solutions for both
2D and 3D pose estimation via a systematic analysis and comparison of these
solutions based on their input data and inference procedures. More than 240
research papers since 2014 are covered in this survey. Furthermore, 2D and 3D
human pose estimation datasets and evaluation metrics are included.
Quantitative performance comparisons of the reviewed methods on popular
datasets are summarized and discussed. Finally, the challenges involved,
applications, and future research directions are concluded. We also provide a
regularly updated project page: \url{https://github.com/zczcwh/DL-HPE}
</p>
<a href="http://arxiv.org/abs/2012.13392" target="_blank">arXiv:2012.13392</a> [<a href="http://arxiv.org/pdf/2012.13392" target="_blank">pdf</a>]

<h2>3D-OES: Viewpoint-Invariant Object-Factorized Environment Simulators. (arXiv:2011.06464v1 [cs.RO] CROSS LISTED)</h2>
<h3>Hsiao-Yu Fish Tung, Zhou Xian, Mihir Prabhudesai, Shamit Lal, Katerina Fragkiadaki</h3>
<p>We propose an action-conditioned dynamics model that predicts scene changes
caused by object and agent interactions in a viewpoint-invariant 3D neural
scene representation space, inferred from RGB-D videos. In this 3D feature
space, objects do not interfere with one another and their appearance persists
over time and across viewpoints. This permits our model to predict future
scenes long in the future by simply "moving" 3D object features based on
cumulative object motion predictions. Object motion predictions are computed by
a graph neural network that operates over the object features extracted from
the 3D neural scene representation. Our model's simulations can be decoded by a
neural renderer into2D image views from any desired viewpoint, which aids the
interpretability of our latent 3D simulation space. We show our model
generalizes well its predictions across varying number and appearances of
interacting objects as well as across camera viewpoints, outperforming existing
2D and 3D dynamics models. We further demonstrate sim-to-real transfer of the
learnt dynamics by applying our model trained solely in simulation to
model-based control for pushing objects to desired locations under clutter on a
real robotic setup
</p>
<a href="http://arxiv.org/abs/2011.06464" target="_blank">arXiv:2011.06464</a> [<a href="http://arxiv.org/pdf/2011.06464" target="_blank">pdf</a>]

<h2>Learning by Fixing: Solving Math Word Problems with Weak Supervision. (arXiv:2012.10582v1 [cs.AI] CROSS LISTED)</h2>
<h3>Yining Hong, Qing Li, Daniel Ciao, Siyuan Haung, Song-Chun Zhu</h3>
<p>Previous neural solvers of math word problems (MWPs) are learned with full
supervision and fail to generate diverse solutions. In this paper, we address
this issue by introducing a \textit{weakly-supervised} paradigm for learning
MWPs. Our method only requires the annotations of the final answers and can
generate various solutions for a single problem. To boost weakly-supervised
learning, we propose a novel \textit{learning-by-fixing} (LBF) framework, which
corrects the misperceptions of the neural network via symbolic reasoning.
Specifically, for an incorrect solution tree generated by the neural network,
the \textit{fixing} mechanism propagates the error from the root node to the
leaf nodes and infers the most probable fix that can be executed to get the
desired answer. To generate more diverse solutions, \textit{tree
regularization} is applied to guide the efficient shrinkage and exploration of
the solution space, and a \textit{memory buffer} is designed to track and save
the discovered various fixes for each problem. Experimental results on the
Math23K dataset show the proposed LBF framework significantly outperforms
reinforcement learning baselines in weakly-supervised learning. Furthermore, it
achieves comparable top-1 and much better top-3/5 answer accuracies than
fully-supervised methods, demonstrating its strength in producing diverse
solutions.
</p>
<a href="http://arxiv.org/abs/2012.10582" target="_blank">arXiv:2012.10582</a> [<a href="http://arxiv.org/pdf/2012.10582" target="_blank">pdf</a>]

<h2>Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments. (arXiv:1712.04802v5 [stat.ML] UPDATED)</h2>
<h3>Victor Chernozhukov, Mert Demirer, Esther Duflo, Iv&#xe1;n Fern&#xe1;ndez-Val</h3>
<p>We propose strategies to estimate and make inference on key features of
heterogeneous effects in randomized experiments. These key features include
best linear predictors of the effects on machine learning proxies, average
effects sorted by impact groups, and average characteristics of most and least
impacted units. The approach is valid in high dimensional settings, where the
effects are proxied by machine learning methods. We post-process these proxies
into the estimates of the key features. Our approach is generic, it can be used
in conjunction with penalized methods, deep and shallow neural networks,
canonical and new random forests, boosted trees, and ensemble methods.
Estimation and inference are based on repeated data splitting to avoid
overfitting and achieve validity. For inference, we take medians of p-values
and medians of confidence intervals, resulting from many different data splits,
and then adjust their nominal level to guarantee uniform validity. This
variational inference method, which quantifies the uncertainty coming from both
parameter estimation and data splitting, is shown to be uniformly valid for a
large class of data generating processes. We illustrate the use of the approach
with a randomized field experiment that evaluated a combination of nudges to
stimulate demand for immunization in India.
</p>
<a href="http://arxiv.org/abs/1712.04802" target="_blank">arXiv:1712.04802</a> [<a href="http://arxiv.org/pdf/1712.04802" target="_blank">pdf</a>]

