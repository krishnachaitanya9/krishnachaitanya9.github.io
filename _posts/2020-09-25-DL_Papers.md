---
title: Latest Deep Learning Papers
date: 2021-01-04 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (210 Articles)</h1>
<h2>Etat de l'art sur l'application des bandits multi-bras. (arXiv:2101.00001v1 [cs.LG])</h2>
<h3>Djallel Bouneffouf</h3>
<p>The Multi-armed bandit offer the advantage to learn and exploit the already
learnt knowledge at the same time. This capability allows this approach to be
applied in different domains, going from clinical trials where the goal is
investigating the effects of different experimental treatments while minimizing
patient losses, to adaptive routing where the goal is to minimize the delays in
a network. This article provides a review of the recent results on applying
bandit to real-life scenario and summarize the state of the art for each of
these fields. Different techniques has been proposed to solve this problem
setting, like epsilon-greedy, Upper confident bound (UCB) and Thompson Sampling
(TS). We are showing here how this algorithms were adapted to solve the
different problems of exploration exploitation.
</p>
<a href="http://arxiv.org/abs/2101.00001" target="_blank">arXiv:2101.00001</a> [<a href="http://arxiv.org/pdf/2101.00001" target="_blank">pdf</a>]

<h2>Automatic-differentiated Physics-Informed Echo State Network (API-ESN). (arXiv:2101.00002v1 [cs.LG])</h2>
<h3>Alberto Racca, Luca Magri</h3>
<p>We propose the Automatic-differentiated Physics-Informed Echo State Network
(API-ESN). The architecture constrains the knowledge of the physical equations
through the reservoir's exact time derivative, which is computed by automatic
differentiation. As compared to the original Physics-Informed Echo State
Network, the accuracy of the time derivative is increased by up to seven orders
of magnitude. This increased accuracy is key in chaotic dynamical systems,
where errors grows exponentially in time. The architecture is showcased in the
reconstruction of unmeasured (hidden) states of a chaotic system. The API-ESN
eliminates a source of error, which is present in existing physics-informed
echo state networks, in the computation of the time-derivative. This opens up
new possibilities for an accurate reconstruction of chaotic dynamical states.
</p>
<a href="http://arxiv.org/abs/2101.00002" target="_blank">arXiv:2101.00002</a> [<a href="http://arxiv.org/pdf/2101.00002" target="_blank">pdf</a>]

<h2>Random Embeddings with Optimal Accuracy. (arXiv:2101.00029v1 [cs.LG])</h2>
<h3>Maciej Skorski</h3>
<p>This work constructs Jonson-Lindenstrauss embeddings with best accuracy, as
measured by variance, mean-squared error and exponential concentration of the
length distortion. Lower bounds for any data and embedding dimensions are
determined, and accompanied by matching and efficiently samplable constructions
(built on orthogonal matrices). Novel techniques: a unit sphere
parametrization, the use of singular-value latent variables and Schur-convexity
are of independent interest.
</p>
<a href="http://arxiv.org/abs/2101.00029" target="_blank">arXiv:2101.00029</a> [<a href="http://arxiv.org/pdf/2101.00029" target="_blank">pdf</a>]

<h2>Modified Gaussian Process Regression Models for Cyclic Capacity Prediction of Lithium-ion Batteries. (arXiv:2101.00035v1 [cs.LG])</h2>
<h3>Kailong Liu, Xiaosong Hu, Zhongbao Wei, Yi Li, Yan Jiang</h3>
<p>This paper presents the development of machine learning-enabled data-driven
models for effective capacity predictions for lithium-ion batteries under
different cyclic conditions. To achieve this, a model structure is first
proposed with the considerations of battery ageing tendency and the
corresponding operational temperature and depth-of-discharge. Then based on a
systematic understanding of covariance functions within the Gaussian process
regression, two related data-driven models are developed. Specifically, by
modifying the isotropic squared exponential kernel with an automatic relevance
determination structure, 'Model A' could extract the highly relevant input
features for capacity predictions. Through coupling the Arrhenius law and a
polynomial equation into a compositional kernel, 'Model B' is capable of
considering the electrochemical and empirical knowledge of battery degradation.
The developed models are validated and compared on the Nickel Manganese Cobalt
Oxide (NMC) lithium-ion batteries with various cycling patterns. Experimental
results demonstrate that the modified Gaussian process regression model
considering the battery electrochemical and empirical ageing signature
outperforms other counterparts and is able to achieve satisfactory results for
both one-step and multi-step predictions. The proposed technique is promising
for battery capacity predictions under various cycling cases.
</p>
<a href="http://arxiv.org/abs/2101.00035" target="_blank">arXiv:2101.00035</a> [<a href="http://arxiv.org/pdf/2101.00035" target="_blank">pdf</a>]

<h2>Optimizing Optimizers: Regret-optimal gradient descent algorithms. (arXiv:2101.00041v1 [cs.LG])</h2>
<h3>Philippe Casgrain, Anastasis Kratsios</h3>
<p>The need for fast and robust optimization algorithms are of critical
importance in all areas of machine learning. This paper treats the task of
designing optimization algorithms as an optimal control problem. Using regret
as a metric for an algorithm's performance, we derive the necessary and
sufficient dynamics that regret-optimal algorithms must satisfy as a
discrete-time difference equation. We study the existence, uniqueness and
consistency of regret-optimal algorithms and derive bounds on rates of
convergence to solutions of convex optimization problems. Though closed-form
optimal dynamics cannot be obtained in general, we present fast numerical
methods for approximating them, generating optimization algorithms which
directly optimize their long-term regret. Lastly, these are benchmarked against
commonly used optimization algorithms to demonstrate their effectiveness.
</p>
<a href="http://arxiv.org/abs/2101.00041" target="_blank">arXiv:2101.00041</a> [<a href="http://arxiv.org/pdf/2101.00041" target="_blank">pdf</a>]

<h2>Long-Term Autonomy in Forest Environment using Self-Corrective SLAM. (arXiv:2101.00043v1 [cs.RO])</h2>
<h3>Paavo Nevalainen, Parisa Movahedi, Jorge Pe&#xf1;a Queralta, Tomi Westerlund, Jukka Heikkonen</h3>
<p>Vehicles with prolonged autonomous missions have to maintain environment
awareness by simultaneous localization and mapping (SLAM). Closed loop
correction is substituted by interpolation in rigid body transformation space
in order to systematically reduce the accumulated error over different scales.
The computation is divided to an edge computed lightweight SLAM and iterative
corrections in the cloud environment. Tree locations in the forest environment
are sent via a potentially limited communication bandwidths. Data from a real
forest site is used in the verification of the proposed algorithm. The
algorithm adds new iterative closest point (ICP) cases to the initial SLAM and
measures the resulting map quality by the mean of the root mean squared error
(RMSE) of individual tree clusters. Adding 4% more match cases yields the mean
RMSE 0.15 m on a large site with 180 m odometric distance.
</p>
<a href="http://arxiv.org/abs/2101.00043" target="_blank">arXiv:2101.00043</a> [<a href="http://arxiv.org/pdf/2101.00043" target="_blank">pdf</a>]

<h2>Federated Nonconvex Sparse Learning. (arXiv:2101.00052v1 [cs.LG])</h2>
<h3>Qianqian Tong, Guannan Liang, Tan Zhu, Jinbo Bi</h3>
<p>Nonconvex sparse learning plays an essential role in many areas, such as
signal processing and deep network compression. Iterative hard thresholding
(IHT) methods are the state-of-the-art for nonconvex sparse learning due to
their capability of recovering true support and scalability with large
datasets. Theoretical analysis of IHT is currently based on centralized IID
data. In realistic large-scale situations, however, data are distributed,
hardly IID, and private to local edge computing devices. It is thus necessary
to examine the property of IHT in federated settings, which update in parallel
on local devices and communicate with a central server only once in a while
without sharing local data.

In this paper, we propose two IHT methods: Federated Hard Thresholding
(Fed-HT) and Federated Iterative Hard Thresholding (FedIter-HT). We prove that
both algorithms enjoy a linear convergence rate and have strong guarantees to
recover the optimal sparse estimator, similar to traditional IHT methods, but
now with decentralized non-IID data. Empirical results demonstrate that the
Fed-HT and FedIter-HT outperform their competitor - a distributed IHT, in terms
of decreasing the objective values with lower requirements on communication
rounds and bandwidth.
</p>
<a href="http://arxiv.org/abs/2101.00052" target="_blank">arXiv:2101.00052</a> [<a href="http://arxiv.org/pdf/2101.00052" target="_blank">pdf</a>]

<h2>Conflict-driven Inductive Logic Programming. (arXiv:2101.00058v1 [cs.AI])</h2>
<h3>Mark Law</h3>
<p>The goal of Inductive Logic Programming (ILP) is to learn a program that
explains a set of examples. Until recently, most research on ILP targeted
learning Prolog programs. The ILASP system instead learns Answer Set Programs
(ASP). Learning such expressive programs widens the applicability of ILP
considerably; for example, enabling preference learning, learning common-sense
knowledge, including defaults and exceptions, and learning non-deterministic
theories.

Early versions of ILASP can be considered meta-level ILP approaches, which
encode a learning task as a logic program and delegate the search to an ASP
solver. More recently, ILASP has shifted towards a new method, inspired by
conflict-driven SAT and ASP solvers. The fundamental idea of the approach,
called Conflict-driven ILP (CDILP), is to iteratively interleave the search for
a hypothesis with the generation of constraints which explain why the current
hypothesis does not cover a particular example. These coverage constraints
allow ILASP to rule out not just the current hypothesis, but an entire class of
hypotheses that do not satisfy the coverage constraint.

This paper formalises the CDILP approach and presents the ILASP3 and ILASP4
systems for CDILP, which are demonstrated to be more scalable than previous
ILASP systems, particularly in the presence of noise.
</p>
<a href="http://arxiv.org/abs/2101.00058" target="_blank">arXiv:2101.00058</a> [<a href="http://arxiv.org/pdf/2101.00058" target="_blank">pdf</a>]

<h2>FGF-GAN: A Lightweight Generative Adversarial Network for Pansharpening via Fast Guided Filter. (arXiv:2101.00062v1 [cs.CV])</h2>
<h3>Zixiang Zhao, Jiangshe Zhang, Shuang Xu, Kai Sun, Lu Huang, Junmin Liu, Chunxia Zhang</h3>
<p>Pansharpening is a widely used image enhancement technique for remote
sensing. Its principle is to fuse the input high-resolution single-channel
panchromatic (PAN) image and low-resolution multi-spectral image and to obtain
a high-resolution multi-spectral (HRMS) image. The existing deep learning
pansharpening method has two shortcomings. First, features of two input images
need to be concatenated along the channel dimension to reconstruct the HRMS
image, which makes the importance of PAN images not prominent, and also leads
to high computational cost. Second, the implicit information of features is
difficult to extract through the manually designed loss function. To this end,
we propose a generative adversarial network via the fast guided filter (FGF)
for pansharpening. In generator, traditional channel concatenation is replaced
by FGF to better retain the spatial information while reducing the number of
parameters. Meanwhile, the fusion objects can be highlighted by the spatial
attention module. In addition, the latent information of features can be
preserved effectively through adversarial training. Numerous experiments
illustrate that our network generates high-quality HRMS images that can surpass
existing methods, and with fewer parameters.
</p>
<a href="http://arxiv.org/abs/2101.00062" target="_blank">arXiv:2101.00062</a> [<a href="http://arxiv.org/pdf/2101.00062" target="_blank">pdf</a>]

<h2>Explicit regularization and implicit bias in deep network classifiers trained with the square loss. (arXiv:2101.00072v1 [cs.LG])</h2>
<h3>Tomaso Poggio, Qianli Liao</h3>
<p>Deep ReLU networks trained with the square loss have been observed to perform
well in classification tasks. We provide here a theoretical justification based
on analysis of the associated gradient flow. We show that convergence to a
solution with the absolute minimum norm is expected when normalization
techniques such as Batch Normalization (BN) or Weight Normalization (WN) are
used together with Weight Decay (WD). The main property of the minimizers that
bounds their expected error is the norm: we prove that among all the
close-to-interpolating solutions, the ones associated with smaller Frobenius
norms of the unnormalized weight matrices have better margin and better bounds
on the expected classification error. With BN but in the absence of WD, the
dynamical system is singular. Implicit dynamical regularization -- that is
zero-initial conditions biasing the dynamics towards high margin solutions --
is also possible in the no-BN and no-WD case. The theory yields several
predictions, including the role of BN and weight decay, aspects of Papyan, Han
and Donoho's Neural Collapse and the constraints induced by BN on the network
weights.
</p>
<a href="http://arxiv.org/abs/2101.00072" target="_blank">arXiv:2101.00072</a> [<a href="http://arxiv.org/pdf/2101.00072" target="_blank">pdf</a>]

<h2>A Multi-modal Deep Learning Model for Video Thumbnail Selection. (arXiv:2101.00073v1 [cs.CV])</h2>
<h3>Zhifeng Yu, Nanchun Shi</h3>
<p>Thumbnail is the face of online videos. The explosive growth of videos both
in number and variety underpins the importance of a good thumbnail because it
saves potential viewers time to choose videos and even entice them to click on
them. A good thumbnail should be a frame that best represents the content of a
video while at the same time capturing viewers' attention. However, the
techniques and models in the past only focus on frames within a video, and we
believe such narrowed focus leave out much useful information that are part of
a video. In this paper, we expand the definition of content to include title,
description, and audio of a video and utilize information provided by these
modalities in our selection model. Specifically, our model will first sample
frames uniformly in time and return the top 1,000 frames in this subset with
the highest aesthetic scores by a Double-column Convolutional Neural Network,
to avoid the computational burden of processing all frames in downstream task.
Then, the model incorporates frame features extracted from VGG16, text features
from ELECTRA, and audio features from TRILL. These models were selected because
of their results on popular datasets as well as their competitive performances.
After feature extraction, the time-series features, frames and audio, will be
fed into Transformer encoder layers to return a vector representing their
corresponding modality. Each of the four features (frames, title, description,
audios) will pass through a context gating layer before concatenation. Finally,
our model will generate a vector in the latent space and select the frame that
is most similar to this vector in the latent space. To the best of our
knowledge, we are the first to propose a multi-modal deep learning model to
select video thumbnail, which beats the result from the previous
State-of-The-Art models.
</p>
<a href="http://arxiv.org/abs/2101.00073" target="_blank">arXiv:2101.00073</a> [<a href="http://arxiv.org/pdf/2101.00073" target="_blank">pdf</a>]

<h2>Graph Networks with Spectral Message Passing. (arXiv:2101.00079v1 [stat.ML])</h2>
<h3>Kimberly Stachenfeld, Jonathan Godwin, Peter Battaglia</h3>
<p>Graph Neural Networks (GNNs) are the subject of intense focus by the machine
learning community for problems involving relational reasoning. GNNs can be
broadly divided into spatial and spectral approaches. Spatial approaches use a
form of learned message-passing, in which interactions among vertices are
computed locally, and information propagates over longer distances on the graph
with greater numbers of message-passing steps. Spectral approaches use
eigendecompositions of the graph Laplacian to produce a generalization of
spatial convolutions to graph structured data which access information over
short and long time scales simultaneously. Here we introduce the Spectral Graph
Network, which applies message passing to both the spatial and spectral
domains. Our model projects vertices of the spatial graph onto the Laplacian
eigenvectors, which are each represented as vertices in a fully connected
"spectral graph", and then applies learned message passing to them. We apply
this model to various benchmark tasks including a graph-based variant of MNIST
classification, molecular property prediction on MoleculeNet and QM9, and
shortest path problems on random graphs. Our results show that the Spectral GN
promotes efficient training, reaching high performance with fewer training
iterations despite having more parameters. The model also provides robustness
to edge dropout and outperforms baselines for the classification tasks. We also
explore how these performance benefits depend on properties of the dataset.
</p>
<a href="http://arxiv.org/abs/2101.00079" target="_blank">arXiv:2101.00079</a> [<a href="http://arxiv.org/pdf/2101.00079" target="_blank">pdf</a>]

<h2>Bosonic Random Walk Networks for Graph Learning. (arXiv:2101.00082v1 [cs.LG])</h2>
<h3>Shiv Shankar, Don Towsley</h3>
<p>The development of Graph Neural Networks (GNNs) has led to great progress in
machine learning on graph-structured data. These networks operate via diffusing
information across the graph nodes while capturing the structure of the graph.
Recently there has also seen tremendous progress in quantum computing
techniques. In this work, we explore applications of multi-particle quantum
walks on diffusing information across graphs. Our model is based on learning
the operators that govern the dynamics of quantum random walkers on graphs. We
demonstrate the effectiveness of our method on classification and regression
tasks.
</p>
<a href="http://arxiv.org/abs/2101.00082" target="_blank">arXiv:2101.00082</a> [<a href="http://arxiv.org/pdf/2101.00082" target="_blank">pdf</a>]

<h2>Analysis of a new chaotic system, electronic realization and use in navigation of differential drive mobile robot. (arXiv:2101.00095v1 [cs.RO])</h2>
<h3>Christian Nwachioma, J. Humberto P&#xe9;rez-Cruz</h3>
<p>This paper presents a new chaotic system having four attractors, including
two fixed point attractors and two symmetrical chaotic strange attractors.
Dynamical properties of the system, viz. sensitive dependence on initial
conditions, Lyapunov spectrum, strangeness measure, attraction basin, including
the class and size of it, existence of strange attractor, bifurcation analysis,
multistability, electronic circuit design, and hardware implementation, are
rigorously treated. Numerical computations are used to compute the basin of
attraction and show that the system has a far-reaching composite basin of
attraction. Such a basin of attraction is vital for engineering applications.
Moreover, a circuit model of the system is realized using analog electronic
components. A procedure is detailed for converting the system parameters into
corresponding electronic component values such as the circuital resistances
while ensuring the dynamic ranges are bounded. Besides, the system is used as
the source of control inputs for independent navigation of a differential drive
mobile robot, which is subject to the Pfaffian velocity constraint. Due to the
properties of sensitivity on initial conditions and topological mixing, the
robot's path becomes unpredictable and guaranteed to scan the workspace,
respectively.
</p>
<a href="http://arxiv.org/abs/2101.00095" target="_blank">arXiv:2101.00095</a> [<a href="http://arxiv.org/pdf/2101.00095" target="_blank">pdf</a>]

<h2>Adaptive Surgical Robotic Training Using Real-Time Stylistic Behavior Feedback Through Haptic Cues. (arXiv:2101.00097v1 [cs.RO])</h2>
<h3>Marzieh Ershad, Robert Rege, Ann Majewicz Fey</h3>
<p>Surgical skill directly affects surgical procedure outcomes; thus, effective
training is needed to ensure satisfactory results. Many objective assessment
metrics have been developed and some are widely used in surgical training
simulators. These objective metrics provide the trainee with descriptive
feedback about their performance however, often lack feedback on how to proceed
to improve performance. The most effective training method is one that is
intuitive, easy to understand, personalized to the user and provided in a
timely manner. We propose a framework to enable user-adaptive training using
near-real-time detection of performance, based on intuitive styles of surgical
movements (e.g., fluidity, smoothness, crispness, etc.), and propose a haptic
feedback framework to assist with correcting styles of movement. We evaluate
the ability of three types of force feedback (spring, damping, and spring plus
damping feedback), computed based on prior user positions, to improve different
stylistic behaviors of the user during kinematically constrained reaching
movement tasks. The results indicate that four out of the six styles studied
here were statistically significantly improved (p&lt;0.05) using spring guidance
force feedback and a significant reduction in task time was also found using
spring feedback. The path straightness and targeting error in the task were
other task performance metrics studied which were improved significantly using
the spring-damping feedback. This study presents a groundwork for adaptive
training in robotic surgery based on near-real-time human-centric models of
surgical behavior.
</p>
<a href="http://arxiv.org/abs/2101.00097" target="_blank">arXiv:2101.00097</a> [<a href="http://arxiv.org/pdf/2101.00097" target="_blank">pdf</a>]

<h2>Generative Max-Mahalanobis Classifiers for Image Classification, Generation and More. (arXiv:2101.00122v1 [cs.CV])</h2>
<h3>Xiulong Yang, Hui Ye, Yang Ye, Xiang Li, Shihao Ji</h3>
<p>Joint Energy-based Model (JEM) of~\cite{jem} shows that a standard softmax
classifier can be reinterpreted as an energy-based model (EBM) for the joint
distribution $p(\boldsymbol{x}, y)$; the resulting model can be optimized with
an energy-based training to improve calibration, robustness and
out-of-distribution detection, while generating samples rivaling the quality of
recent GAN-based approaches. However, the softmax classifier that JEM exploits
is inherently discriminative and its latent feature space is not well
formulated as probabilistic distributions, which may hinder its potential for
image generation and incur training instability as observed in~\cite{jem}. We
hypothesize that generative classifiers, such as Linear Discriminant Analysis
(LDA), might be more suitable hybrid models for image generation since
generative classifiers model the data generation process explicitly. This paper
therefore investigates an LDA classifier for image classification and
generation. In particular, the Max-Mahalanobis Classifier
(MMC)~\cite{Pang2020Rethinking}, a special case of LDA, fits our goal very well
since MMC formulates the latent feature space explicitly as the Max-Mahalanobis
distribution~\cite{pang2018max}. We term our algorithm Generative MMC (GMMC),
and show that it can be trained discriminatively, generatively or jointly for
image classification and generation. Extensive experiments on multiple datasets
(CIFAR10, CIFAR100 and SVHN) show that GMMC achieves state-of-the-art
discriminative and generative performances, while outperforming JEM in
calibration, adversarial robustness and out-of-distribution detection by a
significant margin.
</p>
<a href="http://arxiv.org/abs/2101.00122" target="_blank">arXiv:2101.00122</a> [<a href="http://arxiv.org/pdf/2101.00122" target="_blank">pdf</a>]

<h2>DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue. (arXiv:2101.00151v1 [cs.AI])</h2>
<h3>Hung Le, Chinnadhurai Sankar, Seungwhan Moon, Ahmad Beirami, Alborz Geramifard, Satwik Kottur</h3>
<p>A video-grounded dialogue system is required to understand both dialogue,
which contains semantic dependencies from turn to turn, and video, which
contains visual cues of spatial and temporal scene variations. Building such
dialogue systems is a challenging problem involving complex multimodal and
temporal inputs, and studying them independently is hard with existing
datasets. Existing benchmarks do not have enough annotations to help analyze
dialogue systems and understand their linguistic and visual reasoning
capability and limitations in isolation. These benchmarks are also not
explicitly designed to minimize biases that models can exploit without actual
reasoning. To address these limitations, in this paper, we present a diagnostic
dataset that can test a range of reasoning abilities on videos and dialogues.
The dataset is designed to contain minimal biases and has detailed annotations
for the different types of reasoning each question requires, including
cross-turn video interval tracking and dialogue object tracking. We use our
dataset to analyze several dialogue system approaches, providing interesting
insights into their abilities and limitations. In total, the dataset contains
$10$ instances of $10$-round dialogues for each of $\sim11k$ synthetic videos,
resulting in more than $100k$ dialogues and $1M$ question-answer pairs. Our
code and dataset will be made public.
</p>
<a href="http://arxiv.org/abs/2101.00151" target="_blank">arXiv:2101.00151</a> [<a href="http://arxiv.org/pdf/2101.00151" target="_blank">pdf</a>]

<h2>Active Learning Under Malicious Mislabeling and Poisoning Attacks. (arXiv:2101.00157v1 [cs.LG])</h2>
<h3>Jing Lin, Ryan Luley, Kaiqi Xiong</h3>
<p>Deep neural networks usually require large labeled datasets for training to
achieve the start-of-the-art performance in many tasks, such as image
classification and natural language processing. Though a lot of data is created
each day by active Internet users through various distributed systems across
the world, most of these data are unlabeled and are vulnerable to data
poisoning attacks. In this paper, we develop an efficient active learning
method that requires fewer labeled instances and incorporates the technique of
adversarial retraining in which additional labeled artificial data are
generated without increasing the labeling budget. The generated adversarial
examples also provide a way to measure the vulnerability of the model. To check
the performance of the proposed method under an adversarial setting, i.e.,
malicious mislabeling and data poisoning attacks, we perform an extensive
evaluation on the reduced CIFAR-10 dataset, which contains only two classes:
'airplane' and 'frog' by using the private cloud on campus. Our experimental
results demonstrate that the proposed active learning method is efficient for
defending against malicious mislabeling and data poisoning attacks.
Specifically, whereas the baseline active learning method based on the random
sampling strategy performs poorly (about 50%) under a malicious mislabeling
attack, the proposed active learning method can achieve the desired accuracy of
89% using only one-third of the dataset on average.
</p>
<a href="http://arxiv.org/abs/2101.00157" target="_blank">arXiv:2101.00157</a> [<a href="http://arxiv.org/pdf/2101.00157" target="_blank">pdf</a>]

<h2>Fidel: Reconstructing Private Training Samples from Weight Updates in Federated Learning. (arXiv:2101.00159v1 [cs.LG])</h2>
<h3>David Enthoven, Zaid Al-Ars</h3>
<p>With the increasing number of data collectors such as smartphones, immense
amounts of data are available. Federated learning was developed to allow for
distributed learning on a massive scale whilst still protecting each users'
privacy. This privacy is claimed by the notion that the centralized server does
not have any access to a client's data, solely the client's model update. In
this paper, we evaluate a novel attack method within regular federated learning
which we name the First Dense Layer Attack (Fidel). The methodology of using
this attack is discussed, and as a proof of viability we show how this attack
method can be used to great effect for densely connected networks and
convolutional neural networks. We evaluate some key design decisions and show
that the usage of ReLu and Dropout are detrimental to the privacy of a client's
local dataset. We show how to recover on average twenty out of thirty private
data samples from a client's model update employing a fully connected neural
network with very little computational resources required. Similarly, we show
that over thirteen out of twenty samples can be recovered from a convolutional
neural network update.
</p>
<a href="http://arxiv.org/abs/2101.00159" target="_blank">arXiv:2101.00159</a> [<a href="http://arxiv.org/pdf/2101.00159" target="_blank">pdf</a>]

<h2>CIZSL++: Creativity Inspired Generative Zero-Shot Learning. (arXiv:2101.00173v1 [cs.CV])</h2>
<h3>Mohamed Elhoseiny, Kai Yi, Mohamed Elfeki</h3>
<p>Zero-shot learning (ZSL) aims at understanding unseen categories with no
training examples from class-level descriptions. To improve the discriminative
power of ZSL, we model the visual learning process of unseen categories with
inspiration from the psychology of human creativity for producing novel art.
First, we propose CIZSL-v1 as a creativity inspired model for generative ZSL.
We relate ZSL to human creativity by observing that ZSL is about recognizing
the unseen, and creativity is about creating a likable unseen. We introduce a
learning signal inspired by creativity literature that explores the unseen
space with hallucinated class-descriptions and encourages careful deviation of
their visual feature generations from seen classes while allowing knowledge
transfer from seen to unseen classes. Second, CIZSL-v2 is proposed as an
improved version of CIZSL-v1 for generative zero-shot learning. CIZSL-v2
consists of an investigation of additional inductive losses for unseen classes
along with a semantic guided discriminator. Empirically, we show consistently
that CIZSL losses can improve generative ZSL models on the challenging task of
generalized ZSL from a noisy text on CUB and NABirds datasets. We also show the
advantage of our approach to Attribute-based ZSL on AwA2, aPY, and SUN
datasets. We also show that CIZSL-v2 has improved performance compared to
CIZSL-v1.
</p>
<a href="http://arxiv.org/abs/2101.00173" target="_blank">arXiv:2101.00173</a> [<a href="http://arxiv.org/pdf/2101.00173" target="_blank">pdf</a>]

<h2>Early Prediction of Heart Disease Using PCA and Hybrid Genetic Algorithm with k-Means. (arXiv:2101.00183v1 [cs.LG])</h2>
<h3>Md. Touhidul Islam, Sanjida Reza Rafa, Md. Golam Kibria</h3>
<p>Worldwide research shows that millions of lives lost per year because of
heart disease. The healthcare sector produces massive volumes of data on heart
disease that are sadly not used to locate secret knowledge for successful
decision making. One of the most important aspects at this moment is detecting
heart disease at an early stage. Researchers have applied distinct techniques
to the UCI Machine Learning heart disease dataset. Many researchers have tried
to apply some complex techniques to this dataset, where detailed studies are
still missing. In this paper, Principal Component Analysis (PCA) has been used
to reduce attributes. Apart from a Hybrid genetic algorithm (HGA) with k-means
used for final clustering. Typically, the k-means method is using for
clustering the data. This type of clustering can get stuck in the local optima
because this method is heuristic. We used the Hybrid Genetic Algorithm (HGA)
for data clustering to avoid this problem. Our proposed method can predict
early heart disease with an accuracy of 94.06%.
</p>
<a href="http://arxiv.org/abs/2101.00183" target="_blank">arXiv:2101.00183</a> [<a href="http://arxiv.org/pdf/2101.00183" target="_blank">pdf</a>]

<h2>Inverse reinforcement learning for autonomous navigation via differentiable semantic mapping and planning. (arXiv:2101.00186v1 [cs.LG])</h2>
<h3>Tianyu Wang, Vikas Dhiman, Nikolay Atanasov</h3>
<p>This paper focuses on inverse reinforcement learning for autonomous
navigation using distance and semantic category observations. The objective is
to infer a cost function that explains demonstrated behavior while relying only
on the expert's observations and state-control trajectory. We develop a map
encoder, that infers semantic category probabilities from the observation
sequence, and a cost encoder, defined as a deep neural network over the
semantic features. Since the expert cost is not directly observable, the model
parameters can only be optimized by differentiating the error between
demonstrated controls and a control policy computed from the cost estimate. We
propose a new model of expert behavior that enables error minimization using a
closed-form subgradient computed only over a subset of promising states via a
motion planning algorithm. Our approach allows generalizing the learned
behavior to new environments with new spatial configurations of the semantic
categories. We analyze the different components of our model in a minigrid
environment. We also demonstrate that our approach learns to follow traffic
rules in the autonomous driving CARLA simulator by relying on semantic
observations of buildings, sidewalks, and road lanes.
</p>
<a href="http://arxiv.org/abs/2101.00186" target="_blank">arXiv:2101.00186</a> [<a href="http://arxiv.org/pdf/2101.00186" target="_blank">pdf</a>]

<h2>More than just an auxiliary loss: Anti-spoofing Backbone Training via Adversarial Pseudo-depth Generation. (arXiv:2101.00200v1 [cs.CV])</h2>
<h3>Chang Keun Paik, Naeun Ko, Youngjoon Yoo</h3>
<p>In this paper, a new method of training pipeline is discussed to achieve
significant performance on the task of anti-spoofing with RGB image. We explore
and highlight the impact of using pseudo-depth to pre-train a network that will
be used as the backbone to the final classifier. While the usage of
pseudo-depth for anti-spoofing task is not a new idea on its own, previous
endeavours utilize pseudo-depth simply as another medium to extract features
for performing prediction, or as part of many auxiliary losses in aiding the
training of the main classifier, normalizing the importance of pseudo-depth as
just another semantic information. Through this work, we argue that there
exists a significant advantage in training the final classifier can be gained
by the pre-trained generator learning to predict the corresponding pseudo-depth
of a given facial image, from a Generative Adversarial Network framework. Our
experimental results indicate that our method results in a much more adaptable
system that can generalize beyond intra-dataset samples, but to inter-dataset
samples, which it has never seen before during training. Quantitatively, our
method approaches the baseline performance of the current state of the art
anti-spoofing models with 15.8x less parameters used. Moreover, experiments
showed that the introduced methodology performs well only using basic binary
label without additional semantic information which indicates potential
benefits of this work in industrial and application based environment where
trade-off between additional labelling and resources are considered.
</p>
<a href="http://arxiv.org/abs/2101.00200" target="_blank">arXiv:2101.00200</a> [<a href="http://arxiv.org/pdf/2101.00200" target="_blank">pdf</a>]

<h2>B-SMALL: A Bayesian Neural Network approach to Sparse Model-Agnostic Meta-Learning. (arXiv:2101.00203v1 [cs.LG])</h2>
<h3>Anish Madan, Ranjitha Prasad</h3>
<p>There is a growing interest in the learning-to-learn paradigm, also known as
meta-learning, where models infer on new tasks using a few training examples.
Recently, meta-learning based methods have been widely used in few-shot
classification, regression, reinforcement learning, and domain adaptation. The
model-agnostic meta-learning (MAML) algorithm is a well-known algorithm that
obtains model parameter initialization at meta-training phase. In the meta-test
phase, this initialization is rapidly adapted to new tasks by using gradient
descent. However, meta-learning models are prone to overfitting since there are
insufficient training tasks resulting in over-parameterized models with poor
generalization performance for unseen tasks. In this paper, we propose a
Bayesian neural network based MAML algorithm, which we refer to as the B-SMALL
algorithm. The proposed framework incorporates a sparse variational loss term
alongside the loss function of MAML, which uses a sparsifying approximated KL
divergence as a regularizer. We demonstrate the performance of B-MAML using
classification and regression tasks, and highlight that training a sparsifying
BNN using MAML indeed improves the parameter footprint of the model while
performing at par or even outperforming the MAML approach. We also illustrate
applicability of our approach in distributed sensor networks, where sparsity
and meta-learning can be beneficial.
</p>
<a href="http://arxiv.org/abs/2101.00203" target="_blank">arXiv:2101.00203</a> [<a href="http://arxiv.org/pdf/2101.00203" target="_blank">pdf</a>]

<h2>A Hybrid MLP-SVM Model for Classification using Spatial-Spectral Features on Hyper-Spectral Images. (arXiv:2101.00214v1 [cs.CV])</h2>
<h3>Ginni Garg, Dheeraj Kumar, ArvinderPal, Yash Sonker, Ritu Garg</h3>
<p>There are many challenges in the classification of hyper spectral images such
as large dimensionality, scarcity of labeled data and spatial variability of
spectral signatures. In this proposed method, we make a hybrid classifier
(MLP-SVM) using multilayer perceptron (MLP) and support vector machine (SVM)
which aimed to improve the various classification parameters such as accuracy,
precision, recall, f-score and to predict the region without ground truth. In
proposed method, outputs from the last hidden layer of the neural net-ork
become the input to the SVM, which finally classifies into various desired
classes. In the present study, we worked on Indian Pines, U. Pavia and Salinas
dataset with 16, 9, 16 classes and 200, 103 and 204 reflectance bands
respectively, which is provided by AVIRIS and ROSIS sensor of NASA Jet
propulsion laboratory. The proposed method significantly increases the accuracy
on testing dataset to 93.22%, 96.87%, 93.81% as compare to 86.97%, 88.58%,
88.85% and 91.61%, 96.20%, 90.68% based on individual classifiers SVM and MLP
on Indian Pines, U. Pavia and Salinas datasets respectively.
</p>
<a href="http://arxiv.org/abs/2101.00214" target="_blank">arXiv:2101.00214</a> [<a href="http://arxiv.org/pdf/2101.00214" target="_blank">pdf</a>]

<h2>Improved Neural Network based Plant Diseases Identification. (arXiv:2101.00215v1 [cs.CV])</h2>
<h3>Ginni Garg, Mantosh Biswas</h3>
<p>The agriculture sector is essential for every country because it provides a
basic income to a large number of people and food as well, which is a
fundamental requirement to survive on this planet. We see as time passes,
significant changes come in the present era, which begins with Green
Revolution. Due to improper knowledge of plant diseases, farmers use
fertilizers in excess, which ultimately degrade the quality of food. Earlier
farmers use experts to determine the type of plant disease, which was expensive
and time-consuming. In today time, Image processing is used to recognize and
catalog plant diseases using the lesion region of plant leaf, and there are
different modus-operandi for plant disease scent from leaf using Neural
Networks (NN), Support Vector Machine (SVM), and others. In this paper, we
improving the architecture of the Neural Networking by working on ten different
types of training algorithms and the proper choice of neurons in the concealed
layer. Our proposed approach gives 98.30% accuracy on general plant leaf
disease and 100% accuracy on specific plant leaf disease based on Bayesian
regularization, automation of cluster and without over-fitting on considered
plant diseases over various other implemented methods.
</p>
<a href="http://arxiv.org/abs/2101.00215" target="_blank">arXiv:2101.00215</a> [<a href="http://arxiv.org/pdf/2101.00215" target="_blank">pdf</a>]

<h2>Brain Tumor Detection and Classification based on Hybrid Ensemble Classifier. (arXiv:2101.00216v1 [cs.CV])</h2>
<h3>Ginni Garg, Ritu Garg</h3>
<p>To improve patient survival and treatment outcomes, early diagnosis of brain
tumors is an essential task. It is a difficult task to evaluate the magnetic
resonance imaging (MRI) images manually. Thus, there is a need for digital
methods for tumor diagnosis with better accuracy. However, it is still a very
challenging task in assessing their shape, volume, boundaries, tumor detection,
size, segmentation, and classification. In this proposed work, we propose a
hybrid ensemble method using Random Forest (RF), K-Nearest Neighbour, and
Decision Tree (DT) (KNN-RF-DT) based on Majority Voting Method. It aims to
calculate the area of the tumor region and classify brain tumors as benign and
malignant. In the beginning, segmentation is done by using Otsu's Threshold
method. Feature Extraction is done by using Stationary Wavelet Transform (SWT),
Principle Component Analysis (PCA), and Gray Level Co-occurrence Matrix (GLCM),
which gives thirteen features for classification. The classification is done by
hybrid ensemble classifier (KNN-RF-DT) based on the Majority Voting method.
Overall it aimed at improving the performance by traditional classifiers
instead of going to deep learning. Traditional classifiers have an advantage
over deep learning algorithms because they require small datasets for training
and have low computational time complexity, low cost to the users, and can be
easily adopted by less skilled people. Overall, our proposed method is tested
upon dataset of 2556 images, which are used in 85:15 for training and testing
respectively and gives good accuracy of 97.305%.
</p>
<a href="http://arxiv.org/abs/2101.00216" target="_blank">arXiv:2101.00216</a> [<a href="http://arxiv.org/pdf/2101.00216" target="_blank">pdf</a>]

<h2>An iterative K-FAC algorithm for Deep Learning. (arXiv:2101.00218v1 [cs.LG])</h2>
<h3>Yingshi Chen</h3>
<p>Kronecker-factored Approximate Curvature (K-FAC) method is a high efficiency
second order optimizer for the deep learning. Its training time is less than
SGD(or other first-order method) with same accuracy in many large-scale
problems. The key of K-FAC is to approximates Fisher information matrix (FIM)
as a block-diagonal matrix where each block is an inverse of tiny Kronecker
factors. In this short note, we present CG-FAC -- an new iterative K-FAC
algorithm. It uses conjugate gradient method to approximate the nature
gradient. This CG-FAC method is matrix-free, that is, no need to generate the
FIM matrix, also no need to generate the Kronecker factors A and G. We prove
that the time and memory complexity of iterative CG-FAC is much less than that
of standard K-FAC algorithm.
</p>
<a href="http://arxiv.org/abs/2101.00218" target="_blank">arXiv:2101.00218</a> [<a href="http://arxiv.org/pdf/2101.00218" target="_blank">pdf</a>]

<h2>Adaptive Deconvolution-based stereo matching Net for Local Stereo Matching. (arXiv:2101.00221v1 [cs.CV])</h2>
<h3>Xin Ma, Zhicheng Zhang, Danfeng Wang, Yu Luo, Hui Yuan</h3>
<p>In deep learning-based local stereo matching methods, larger image patches
usually bring better stereo matching accuracy. However, it is unrealistic to
increase the size of the image patch size without restriction. Arbitrarily
extending the patch size will change the local stereo matching method into the
global stereo matching method, and the matching accuracy will be saturated. We
simplified the existing Siamese convolutional network by reducing the number of
network parameters and propose an efficient CNN based structure, namely
Adaptive Deconvolution-based disparity matching Net (ADSM net) by adding
deconvolution layers to learn how to enlarge the size of input feature map for
the following convolution layers. Experimental results on the KITTI 2012 and
2015 datasets demonstrate that the proposed method can achieve a good trade-off
between accuracy and complexity.
</p>
<a href="http://arxiv.org/abs/2101.00221" target="_blank">arXiv:2101.00221</a> [<a href="http://arxiv.org/pdf/2101.00221" target="_blank">pdf</a>]

<h2>Adam revisited: a weighted past gradients perspective. (arXiv:2101.00238v1 [cs.LG])</h2>
<h3>Hui Zhong, Zaiyi Chen, Chuan Qin, Zai Huang, Vincent W. Zheng, Tong Xu, Enhong Chen</h3>
<p>Adaptive learning rate methods have been successfully applied in many fields,
especially in training deep neural networks. Recent results have shown that
adaptive methods with exponential increasing weights on squared past gradients
(i.e., ADAM, RMSPROP) may fail to converge to the optimal solution. Though many
algorithms, such as AMSGRAD and ADAMNC, have been proposed to fix the
non-convergence issues, achieving a data-dependent regret bound similar to or
better than ADAGRAD is still a challenge to these methods. In this paper, we
propose a novel adaptive method weighted adaptive algorithm (WADA) to tackle
the non-convergence issues. Unlike AMSGRAD and ADAMNC, we consider using a
milder growing weighting strategy on squared past gradient, in which weights
grow linearly. Based on this idea, we propose weighted adaptive gradient method
framework (WAGMF) and implement WADA algorithm on this framework. Moreover, we
prove that WADA can achieve a weighted data-dependent regret bound, which could
be better than the original regret bound of ADAGRAD when the gradients decrease
rapidly. This bound may partially explain the good performance of ADAM in
practice. Finally, extensive experiments demonstrate the effectiveness of WADA
and its variants in comparison with several variants of ADAM on training convex
problems and deep neural networks.
</p>
<a href="http://arxiv.org/abs/2101.00238" target="_blank">arXiv:2101.00238</a> [<a href="http://arxiv.org/pdf/2101.00238" target="_blank">pdf</a>]

<h2>The Bayesian Method of Tensor Networks. (arXiv:2101.00245v1 [stat.ML])</h2>
<h3>Erdong Guo, David Draper</h3>
<p>Bayesian learning is a powerful learning framework which combines the
external information of the data (background information) with the internal
information (training data) in a logically consistent way in inference and
prediction. By Bayes rule, the external information (prior distribution) and
the internal information (training data likelihood) are combined coherently,
and the posterior distribution and the posterior predictive (marginal)
distribution obtained by Bayes rule summarize the total information needed in
the inference and prediction, respectively. In this paper, we study the
Bayesian framework of the Tensor Network from two perspective. First, we
introduce the prior distribution to the weights in the Tensor Network and
predict the labels of the new observations by the posterior predictive
(marginal) distribution. Since the intractability of the parameter integral in
the normalization constant computation, we approximate the posterior predictive
distribution by Laplace approximation and obtain the out-product approximation
of the hessian matrix of the posterior distribution of the Tensor Network
model. Second, to estimate the parameters of the stationary mode, we propose a
stable initialization trick to accelerate the inference process by which the
Tensor Network can converge to the stationary path more efficiently and stably
with gradient descent method. We verify our work on the MNIST, Phishing Website
and Breast Cancer data set. We study the Bayesian properties of the Bayesian
Tensor Network by visualizing the parameters of the model and the decision
boundaries in the two dimensional synthetic data set. For a application
purpose, our work can reduce the overfitting and improve the performance of
normal Tensor Network model.
</p>
<a href="http://arxiv.org/abs/2101.00245" target="_blank">arXiv:2101.00245</a> [<a href="http://arxiv.org/pdf/2101.00245" target="_blank">pdf</a>]

<h2>VisualSparta: Sparse Transformer Fragment-level Matching for Large-scale Text-to-Image Search. (arXiv:2101.00265v1 [cs.CV])</h2>
<h3>Xiaopeng Lu, Tiancheng Zhao, Kyusong Lee</h3>
<p>Text-to-image retrieval is an essential task in multi-modal information
retrieval, i.e. retrieving relevant images from a large and unlabelled image
dataset given textual queries. In this paper, we propose VisualSparta, a novel
text-to-image retrieval model that shows substantial improvement over existing
models on both accuracy and efficiency. We show that VisualSparta is capable of
outperforming all previous scalable methods in MSCOCO and Flickr30K. It also
shows substantial retrieving speed advantages, i.e. for an index with 1 million
images, VisualSparta gets over 391x speed up compared to standard vector
search. Experiments show that this speed advantage even gets bigger for larger
datasets because VisualSparta can be efficiently implemented as an inverted
index. To the best of our knowledge, VisualSparta is the first
transformer-based text-to-image retrieval model that can achieve real-time
searching for very large dataset, with significant accuracy improvement
compared to previous state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2101.00265" target="_blank">arXiv:2101.00265</a> [<a href="http://arxiv.org/pdf/2101.00265" target="_blank">pdf</a>]

<h2>A General Counterexample to Any Decision Theory and Some Responses. (arXiv:2101.00280v1 [cs.AI])</h2>
<h3>Joar Skalse</h3>
<p>In this paper I present an argument and a general schema which can be used to
construct a problem case for any decision theory, in a way that could be taken
to show that one cannot formulate a decision theory that is never outperformed
by any other decision theory. I also present and discuss a number of possible
responses to this argument. One of these responses raises the question of what
it means for two decision problems to be "equivalent" in the relevant sense,
and gives an answer to this question which would invalidate the first argument.
However, this position would have further consequences for how we compare
different decision theories in decision problems already discussed in the
literature (including e.g. Newcomb's problem).
</p>
<a href="http://arxiv.org/abs/2101.00280" target="_blank">arXiv:2101.00280</a> [<a href="http://arxiv.org/pdf/2101.00280" target="_blank">pdf</a>]

<h2>An Ontology Design Pattern for representing Recurrent Situations. (arXiv:2101.00286v1 [cs.AI])</h2>
<h3>Valentina Anita Carriero, Aldo Gangemi, Andrea Giovanni Nuzzolese, Valentina Presutti</h3>
<p>In this paper, we present an Ontology Design Pattern for representing
situations that recur at regular periods and share some invariant factors,
which unify them conceptually: we refer to this set of recurring situations as
recurrent situation series. The proposed pattern appears to be foundational,
since it can be generalised for modelling the top-level domain-independent
concept of recurrence, which is strictly associated with invariance. The
pattern reuses other foundational patterns such as Collection, Description and
Situation, Classification, Sequence. Indeed, a recurrent situation series is
formalised as both a collection of situations occurring regularly over time and
unified according to some properties that are common to all the members, and a
situation itself, which provides a relational context to its members that
satisfy a reference description. Besides including some exemplifying instances
of this pattern, we show how it has been implemented and specialised to model
recurrent cultural events and ceremonies in ArCo, the Knowledge Graph of
Italian cultural heritage.
</p>
<a href="http://arxiv.org/abs/2101.00286" target="_blank">arXiv:2101.00286</a> [<a href="http://arxiv.org/pdf/2101.00286" target="_blank">pdf</a>]

<h2>Design and Actuator Optimization of Lightweight and Compliant Knee Exoskeleton for Mobility Assistance of Children with Crouch Gait. (arXiv:2101.00289v1 [cs.RO])</h2>
<h3>Sainan Zhang, Tzu-Hao Huang, Chunhai Jiao, Mhairi MacLean, Junxi Zhu, Shuangyue Yu, Hao Su</h3>
<p>Pediatric exoskeletons offer great promise to increase mobility for children
with crouch gait caused by cerebral palsy. A lightweight, compliant and
user-specific actuator is critical for maximizing the benefits of an
exoskeleton to users. To date, pediatric exoskeletons generally use the same
actuators as adult exoskeletons, which are heavy and resistive to natural
movement. There is yet no easy way for robotic exoskeletons to accommodate the
changes in design requirements that occur as a child ages. We developed a
lightweight (1.65 kg unilateral mass) and compliant pediatric knee exoskeleton
with a bandwidth of 22.6 Hz that can provide torque assistance to children with
crouch gait using high torque density motor. Experimental results demonstrated
that the robot exhibited low mechanical impedance (1.79 Nm average backdrive
torque) under the unpowered condition and 0.32 Nm with zero-torque tracking
control. Root mean square (RMS) error of torque tracking result is less than
0.73 Nm (5.7% with respect to 12 Nm torque). To achieve optimal age-specific
performance, we proposed the first optimization framework that considered both
motor and transmission of the actuator system that can produce optimal settings
for children between 3 and 18 years old. The optimization generated an optimal
motor air gap radius that monotonically increases with age from 0.011 to 0.033
meters, and optimal gear ratio varies from 2.6 to 11.6 (3-13 years old) and
11.6 to 10.2 (13-18 years old), leading to actuators of minimal mass.
</p>
<a href="http://arxiv.org/abs/2101.00289" target="_blank">arXiv:2101.00289</a> [<a href="http://arxiv.org/pdf/2101.00289" target="_blank">pdf</a>]

<h2>Robot Adaptation for Generating Consistent Navigational Behaviors over Unstructured Off-Road Terrain. (arXiv:2101.00290v1 [cs.RO])</h2>
<h3>Sriram Siva, Maggie Wigness, John G. Rogers, Hao Zhang</h3>
<p>Terrain adaptation is an essential capability for a ground robot to
effectively traverse unstructured off-road terrain in real-world field
environments such as forests. However, the expected robot behaviors generated
by terrain adaptation methods cannot always be executed accurately due to
setbacks such as wheel slip and reduced tire pressure. To address this problem,
we propose a novel approach for consistent behavior generation that enables the
ground robot's actual behaviors to more accurately match expected behaviors
while adapting to a variety of unstructured off-road terrain. Our approach
learns offset behaviors that are used to compensate for the inconsistency
between the actual and expected behaviors without requiring the explicit
modeling of various setbacks. Our approach is also able to estimate the
importance of the multi-modal features to improve terrain representations for
better adaptation. In addition, we develop an algorithmic solver for our
formulated regularized optimization problem, which is guaranteed to converge to
the global optimal solution. To evaluate the method, we perform extensive
experiments using various unstructured off-road terrain in real-world field
environments. Experimental results have validated that our approach enables
robots to traverse complex unstructured off-road terrain with more navigational
behavior consistency, and it outperforms previous methods, particularly so on
challenging terrain.
</p>
<a href="http://arxiv.org/abs/2101.00290" target="_blank">arXiv:2101.00290</a> [<a href="http://arxiv.org/pdf/2101.00290" target="_blank">pdf</a>]

<h2>Iranis: A Large-scale Dataset of Farsi License Plate Characters. (arXiv:2101.00295v1 [cs.CV])</h2>
<h3>Ali Tourani, Sajjad Soroori, Asadollah Shahbahrami, Alireza Akoushideh</h3>
<p>Providing huge amounts of data is a fundamental demand when dealing with Deep
Neural Networks (DNNs). Employing these algorithms to solve computer vision
problems resulted in the advent of various image datasets to feed the most
common visual imagery deep structures, known as Convolutional Neural Networks
(CNNs). In this regard, some datasets can be found that contain hundreds or
even thousands of images for license plate detection and optical character
recognition purposes. However, no publicly available image dataset provides
such data for the recognition of Farsi characters used in car license plates.
The gap has to be filled due to the numerous advantages of developing accurate
deep learning-based systems for law enforcement and surveillance purposes. This
paper introduces a large-scale dataset that includes images of numbers and
characters used in Iranian car license plates. The dataset, named Iranis,
contains more than 83,000 images of Farsi numbers and letters collected from
real-world license plate images captured by various cameras. The variety of
instances in terms of camera shooting angle, illumination, resolution, and
contrast make the dataset a proper choice for training DNNs. Dataset images are
manually annotated for object detection and image classification. Finally, and
to build a baseline for Farsi character recognition, the paper provides a
performance analysis using a YOLO v.3 object detector.
</p>
<a href="http://arxiv.org/abs/2101.00295" target="_blank">arXiv:2101.00295</a> [<a href="http://arxiv.org/pdf/2101.00295" target="_blank">pdf</a>]

<h2>When Is Generalizable Reinforcement Learning Tractable?. (arXiv:2101.00300v1 [cs.LG])</h2>
<h3>Dhruv Malik, Yuanzhi Li, Pradeep Ravikumar</h3>
<p>Agents trained by reinforcement learning (RL) often fail to generalize beyond
the environment they were trained in, even when presented with new scenarios
that seem very similar to the training environment. We study the query
complexity required to train RL agents that can generalize to multiple
environments. Intuitively, tractable generalization is only possible when the
environments are similar or close in some sense. To capture this, we introduce
Strong Proximity, a structural condition which precisely characterizes the
relative closeness of different environments. We provide an algorithm which
exploits Strong Proximity to provably and efficiently generalize. We also show
that under a natural weakening of this condition, which we call Weak Proximity,
RL can require query complexity that is exponential in the horizon to
generalize. A key consequence of our theory is that even when the environments
share optimal trajectories, and have highly similar reward and transition
functions (as measured by classical metrics), tractable generalization is
impossible.
</p>
<a href="http://arxiv.org/abs/2101.00300" target="_blank">arXiv:2101.00300</a> [<a href="http://arxiv.org/pdf/2101.00300" target="_blank">pdf</a>]

<h2>Energy-constrained Self-training for Unsupervised Domain Adaptation. (arXiv:2101.00316v1 [cs.CV])</h2>
<h3>Xiaofeng Liu, Bo Hu, Xiongchang Liu, Jun Lu, Jane You, Lingsheng Kong</h3>
<p>Unsupervised domain adaptation (UDA) aims to transfer the knowledge on a
labeled source domain distribution to perform well on an unlabeled target
domain. Recently, the deep self-training involves an iterative process of
predicting on the target domain and then taking the confident predictions as
hard pseudo-labels for retraining. However, the pseudo-labels are usually
unreliable, and easily leading to deviated solutions with propagated errors. In
this paper, we resort to the energy-based model and constrain the training of
the unlabeled target sample with the energy function minimization objective. It
can be applied as a simple additional regularization. In this framework, it is
possible to gain the benefits of the energy-based model, while retaining strong
discriminative performance following a plug-and-play fashion. We deliver
extensive experiments on the most popular and large scale UDA benchmarks of
image classification as well as semantic segmentation to demonstrate its
generality and effectiveness.
</p>
<a href="http://arxiv.org/abs/2101.00316" target="_blank">arXiv:2101.00316</a> [<a href="http://arxiv.org/pdf/2101.00316" target="_blank">pdf</a>]

<h2>Identity-aware Facial Expression Recognition in Compressed Video. (arXiv:2101.00317v1 [cs.CV])</h2>
<h3>Xiaofeng Liu, Linghao Jin, Xu Han, Jun Lu, Jane You, Lingsheng Kong</h3>
<p>This paper targets to explore the inter-subject variations eliminated facial
expression representation in the compressed video domain. Most of the previous
methods process the RGB images of a sequence, while the off-the-shelf and
valuable expression-related muscle movement already embedded in the compression
format. In the up to two orders of magnitude compressed domain, we can
explicitly infer the expression from the residual frames and possible to
extract identity factors from the I frame with a pre-trained face recognition
network. By enforcing the marginal independent of them, the expression feature
is expected to be purer for the expression and be robust to identity shifts. We
do not need the identity label or multiple expression samples from the same
person for identity elimination. Moreover, when the apex frame is annotated in
the dataset, the complementary constraint can be further added to regularize
the feature-level game. In testing, only the compressed residual frames are
required to achieve expression prediction. Our solution can achieve comparable
or better performance than the recent decoded image based methods on the
typical FER benchmarks with about 3$\times$ faster inference with compressed
data.
</p>
<a href="http://arxiv.org/abs/2101.00317" target="_blank">arXiv:2101.00317</a> [<a href="http://arxiv.org/pdf/2101.00317" target="_blank">pdf</a>]

<h2>Subtype-aware Unsupervised Domain Adaptation for Medical Diagnosis. (arXiv:2101.00318v1 [cs.CV])</h2>
<h3>Xiaofeng Liu, Xiongchang Liu, Bo Hu, Wenxuan Ji, Fangxu Xing, Jun Lu, Jane You, C.-C. Jay Kuo, Georges El Fakhri, Jonghye Woo</h3>
<p>Recent advances in unsupervised domain adaptation (UDA) show that
transferable prototypical learning presents a powerful means for class
conditional alignment, which encourages the closeness of cross-domain class
centroids. However, the cross-domain inner-class compactness and the underlying
fine-grained subtype structure remained largely underexplored. In this work, we
propose to adaptively carry out the fine-grained subtype-aware alignment by
explicitly enforcing the class-wise separation and subtype-wise compactness
with intermediate pseudo labels. Our key insight is that the unlabeled subtypes
of a class can be divergent to one another with different conditional and label
shifts, while inheriting the local proximity within a subtype. The cases of
with or without the prior information on subtype numbers are investigated to
discover the underlying subtype structure in an online fashion. The proposed
subtype-aware dynamic UDA achieves promising results on medical diagnosis
tasks.
</p>
<a href="http://arxiv.org/abs/2101.00318" target="_blank">arXiv:2101.00318</a> [<a href="http://arxiv.org/pdf/2101.00318" target="_blank">pdf</a>]

<h2>TenIPS: Inverse Propensity Sampling for Tensor Completion. (arXiv:2101.00323v1 [stat.ML])</h2>
<h3>Chengrun Yang, Lijun Ding, Ziyang Wu, Madeleine Udell</h3>
<p>Tensors are widely used to represent multiway arrays of data. The recovery of
missing entries in a tensor has been extensively studied, generally under the
assumption that entries are missing completely at random (MCAR). However, in
most practical settings, observations are missing not at random (MNAR): the
probability that a given entry is observed (also called the propensity) may
depend on other entries in the tensor or even on the value of the missing
entry. In this paper, we study the problem of completing a partially observed
tensor with MNAR observations, without prior information about the
propensities. To complete the tensor, we assume that both the original tensor
and the tensor of propensities have low multilinear rank. The algorithm first
estimates the propensities using a convex relaxation and then predicts missing
values using a higher-order SVD approach, reweighting the observed tensor by
the inverse propensities. We provide finite-sample error bounds on the
resulting complete tensor. Numerical experiments demonstrate the effectiveness
of our approach.
</p>
<a href="http://arxiv.org/abs/2101.00323" target="_blank">arXiv:2101.00323</a> [<a href="http://arxiv.org/pdf/2101.00323" target="_blank">pdf</a>]

<h2>Neural Architecture Search via Combinatorial Multi-Armed Bandit. (arXiv:2101.00336v1 [cs.LG])</h2>
<h3>Hanxun Huang, Xingjun Ma, Sarah M. Erfani, James Bailey</h3>
<p>Neural Architecture Search (NAS) has gained significant popularity as an
effective tool for designing high performance deep neural networks (DNNs). NAS
can be performed via policy gradient, evolutionary algorithms, differentiable
architecture search or tree-search methods. While significant progress has been
made for both policy gradient and differentiable architecture search,
tree-search methods have so far failed to achieve comparable accuracy or search
efficiency. In this paper, we formulate NAS as a Combinatorial Multi-Armed
Bandit (CMAB) problem (CMAB-NAS). This allows the decomposition of a large
search space into smaller blocks where tree-search methods can be applied more
effectively and efficiently. We further leverage a tree-based method called
Nested Monte-Carlo Search to tackle the CMAB-NAS problem. On CIFAR-10, our
approach discovers a cell structure that achieves a low error rate that is
comparable to the state-of-the-art, using only 0.58 GPU days, which is 20 times
faster than current tree-search methods. Moreover, the discovered structure
transfers well to large-scale datasets such as ImageNet.
</p>
<a href="http://arxiv.org/abs/2101.00336" target="_blank">arXiv:2101.00336</a> [<a href="http://arxiv.org/pdf/2101.00336" target="_blank">pdf</a>]

<h2>Biologically Inspired Hexagonal Deep Learning for Hexagonal Image Generation. (arXiv:2101.00337v1 [cs.CV])</h2>
<h3>Tobias Schlosser, Frederik Beuth, Danny Kowerko</h3>
<p>Whereas conventional state-of-the-art image processing systems of recording
and output devices almost exclusively utilize square arranged methods,
biological models, however, suggest an alternative, evolutionarily-based
structure. Inspired by the human visual perception system, hexagonal image
processing in the context of machine learning offers a number of key advantages
that can benefit both researchers and users alike. The hexagonal deep learning
framework Hexnet leveraged in this contribution serves therefore the generation
of hexagonal images by utilizing hexagonal deep neural networks (H-DNN). As the
results of our created test environment show, the proposed models can surpass
current approaches of conventional image generation. While resulting in a
reduction of the models' complexity in the form of trainable parameters, they
furthermore allow an increase of test rates in comparison to their square
counterparts.
</p>
<a href="http://arxiv.org/abs/2101.00337" target="_blank">arXiv:2101.00337</a> [<a href="http://arxiv.org/pdf/2101.00337" target="_blank">pdf</a>]

<h2>An Artificial Intelligence System for Combined Fruit Detection and Georeferencing, Using RTK-Based Perspective Projection in Drone Imagery. (arXiv:2101.00339v1 [cs.CV])</h2>
<h3>Angus Baird, Stefano Giani</h3>
<p>This work presents an Artificial Intelligence (AI) system, based on the
Faster Region-Based Convolution Neural Network (Faster R-CNN) framework, which
detects and counts apples from oblique, aerial drone imagery of giant
commercial orchards. To reduce computational cost, a novel precursory stage to
the network is designed to preprocess raw imagery into cropped images of
individual trees. Unique geospatial identifiers are allocated to these using
the perspective projection model. This employs Real-Time Kinematic (RTK) data,
Digital Terrain and Surface Models (DTM and DSM), as well as internal and
external camera parameters. The bulk of experiments however focus on tuning
hyperparameters in the detection network itself. Apples which are on trees and
apples which are on the ground are treated as separate classes. A mean Average
Precision (mAP) metric, calibrated by the size of the two classes, is devised
to mitigate spurious results. Anchor box design is of key interest due to the
scale of the apples. As such, a k-means clustering approach, never before seen
in literature for Faster R-CNN, resulted in the most significant improvements
to calibrated mAP. Other experiments showed that the maximum number of box
proposals should be 225; the initial learning rate of 0.001 is best applied to
the adaptive RMS Prop optimiser; and ResNet 101 is the ideal base feature
extractor when considering mAP and, to a lesser extent, inference time. The
amalgamation of the optimal hyperparameters leads to a model with a calibrated
mAP of 0.7627.
</p>
<a href="http://arxiv.org/abs/2101.00339" target="_blank">arXiv:2101.00339</a> [<a href="http://arxiv.org/pdf/2101.00339" target="_blank">pdf</a>]

<h2>Minimum Viable Model Estimates for Machine Learning Projects. (arXiv:2101.00346v1 [cs.LG])</h2>
<h3>John Hawkins</h3>
<p>Prioritization of machine learning projects requires estimates of both the
potential ROI of the business case and the technical difficulty of building a
model with the required characteristics. In this work we present a technique
for estimating the minimum required performance characteristics of a predictive
model given a set of information about how it will be used. This technique will
result in robust, objective comparisons between potential projects. The
resulting estimates will allow data scientists and managers to evaluate whether
a proposed machine learning project is likely to succeed before any modelling
needs to be done.

The technique has been implemented into the open source application MinViME
(Minimum Viable Model Estimator) which can be installed via the PyPI python
package management system, or downloaded directly from the GitHub repository.
Available at https://github.com/john-hawkins/MinViME
</p>
<a href="http://arxiv.org/abs/2101.00346" target="_blank">arXiv:2101.00346</a> [<a href="http://arxiv.org/pdf/2101.00346" target="_blank">pdf</a>]

<h2>Multi-Image Steganography Using Deep Neural Networks. (arXiv:2101.00350v1 [cs.CV])</h2>
<h3>Abhishek Das, Japsimar Singh Wahi, Mansi Anand, Yugant Rana</h3>
<p>Steganography is the science of hiding a secret message within an ordinary
public message. Over the years, steganography has been used to encode a lower
resolution image into a higher resolution image by simple methods like LSB
manipulation. We aim to utilize deep neural networks for the encoding and
decoding of multiple secret images inside a single cover image of the same
resolution.
</p>
<a href="http://arxiv.org/abs/2101.00350" target="_blank">arXiv:2101.00350</a> [<a href="http://arxiv.org/pdf/2101.00350" target="_blank">pdf</a>]

<h2>Characterizing Fairness Over the Set of Good Models Under Selective Labels. (arXiv:2101.00352v1 [cs.LG])</h2>
<h3>Amanda Coston, Ashesh Rambachan, Alexandra Chouldechova</h3>
<p>Algorithmic risk assessments are increasingly used to make and inform
decisions in a wide variety of high-stakes settings. In practice, there is
often a multitude of predictive models that deliver similar overall
performance, an empirical phenomenon commonly known as the "Rashomon Effect."
While many competing models may perform similarly overall, they may have
different properties over various subgroups, and therefore have drastically
different predictive fairness properties. In this paper, we develop a framework
for characterizing predictive fairness properties over the set of models that
deliver similar overall performance, or "the set of good models." We provide
tractable algorithms to compute the range of attainable group-level predictive
disparities and the disparity minimizing model over the set of good models. We
extend our framework to address the empirically relevant challenge of
selectively labelled data in the setting where the selection decision and
outcome are unconfounded given the observed data features. We illustrate our
methods in two empirical applications. In a real world credit-scoring task, we
build a model with lower predictive disparities than the benchmark model, and
demonstrate the benefits of properly accounting for the selective labels
problem. In a recidivism risk prediction task, we audit an existing risk score,
and find that it generates larger predictive disparities than any model in the
set of good models.
</p>
<a href="http://arxiv.org/abs/2101.00352" target="_blank">arXiv:2101.00352</a> [<a href="http://arxiv.org/pdf/2101.00352" target="_blank">pdf</a>]

<h2>Integrated Optimization of Predictive and Prescriptive Tasks. (arXiv:2101.00354v1 [cs.LG])</h2>
<h3>Mehmet Kolcu, Alper E. Murat</h3>
<p>In traditional machine learning techniques, the degree of closeness between
true and predicted values generally measures the quality of predictions.
However, these learning algorithms do not consider prescription problems where
the predicted values will be used as input to decision problems. In this paper,
we efficiently leverage feature variables, and we propose a new framework
directly integrating predictive tasks under prescriptive tasks in order to
prescribe consistent decisions. We train the parameters of predictive algorithm
within a prescription problem via bilevel optimization techniques. We present
the structure of our method and demonstrate its performance using synthetic
data compared to classical methods like point-estimate-based, stochastic
optimization and recently developed machine learning based optimization
methods. In addition, we control generalization error using different penalty
approaches and optimize the integration over validation data set.
</p>
<a href="http://arxiv.org/abs/2101.00354" target="_blank">arXiv:2101.00354</a> [<a href="http://arxiv.org/pdf/2101.00354" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Flexibility Design Problems. (arXiv:2101.00355v1 [cs.LG])</h2>
<h3>Yehua Wei, Lei Zhang, Ruiyi Zhang, Shijing Si, Hao Zhang, Lawrence Carin</h3>
<p>Flexibility design problems are a class of problems that appear in strategic
decision-making across industries, where the objective is to design a ($e.g.$,
manufacturing) network that affords flexibility and adaptivity. The underlying
combinatorial nature and stochastic objectives make flexibility design problems
challenging for standard optimization methods. In this paper, we develop a
reinforcement learning (RL) framework for flexibility design problems.
Specifically, we carefully design mechanisms with noisy exploration and
variance reduction to ensure empirical success and show the unique advantage of
RL in terms of fast-adaptation. Empirical results show that the RL-based method
consistently finds better solutions compared to classical heuristics.
</p>
<a href="http://arxiv.org/abs/2101.00355" target="_blank">arXiv:2101.00355</a> [<a href="http://arxiv.org/pdf/2101.00355" target="_blank">pdf</a>]

<h2>Video Captioning in Compressed Video. (arXiv:2101.00359v1 [cs.CV])</h2>
<h3>Mingjian Zhu, Chenrui Duan, Changbin Yu</h3>
<p>Existing approaches in video captioning concentrate on exploring global frame
features in the uncompressed videos, while the free of charge and critical
saliency information already encoded in the compressed videos is generally
neglected. We propose a video captioning method which operates directly on the
stored compressed videos. To learn a discriminative visual representation for
video captioning, we design a residuals-assisted encoder (RAE), which spots
regions of interest in I-frames under the assistance of the residuals frames.
First, we obtain the spatial attention weights by extracting features of
residuals as the saliency value of each location in I-frame and design a
spatial attention module to refine the attention weights. We further propose a
temporal gate module to determine how much the attended features contribute to
the caption generation, which enables the model to resist the disturbance of
some noisy signals in the compressed videos. Finally, Long Short-Term Memory is
utilized to decode the visual representations into descriptions. We evaluate
our method on two benchmark datasets and demonstrate the effectiveness of our
approach.
</p>
<a href="http://arxiv.org/abs/2101.00359" target="_blank">arXiv:2101.00359</a> [<a href="http://arxiv.org/pdf/2101.00359" target="_blank">pdf</a>]

<h2>Image-based Textile Decoding. (arXiv:2101.00395v1 [cs.CV])</h2>
<h3>Siqiang Chen, Masahiro Toyoura, Takamasa Terada, Xiaoyang Mao, Gang Xu</h3>
<p>A textile fabric consists of countless parallel vertical yarns (warps) and
horizontal yarns (wefts). While common looms can weave repetitive patterns,
Jacquard looms can weave the patterns without repetition restrictions. A
pattern in which the warps and wefts cross on a grid is defined in a binary
matrix. The binary matrix can define which warp and weft is on top at each grid
point of the Jacquard fabric. The process can be regarded as encoding from
pattern to textile. In this work, we propose a decoding method that generates a
binary pattern from a textile fabric that has been already woven. We could not
use a deep neural network to learn the process based solely on the training set
of patterns and observed fabric images. The crossing points in the observed
image were not completely located on the grid points, so it was difficult to
take a direct correspondence between the fabric images and the pattern
represented by the matrix in the framework of deep learning. Therefore, we
propose a method that can apply the framework of deep learning via the
intermediate representation of patterns and images. We show how to convert a
pattern into an intermediate representation and how to reconvert the output
into a pattern and confirm its effectiveness. In this experiment, we confirmed
that 93% of correct pattern was obtained by decoding the pattern from the
actual fabric images and weaving them again.
</p>
<a href="http://arxiv.org/abs/2101.00395" target="_blank">arXiv:2101.00395</a> [<a href="http://arxiv.org/pdf/2101.00395" target="_blank">pdf</a>]

<h2>ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning. (arXiv:2101.00407v1 [cs.LG])</h2>
<h3>Liyuan Wang, Kuo Yang, Chongxuan Li, Lanqing Hong, Zhenguo Li, Jun Zhu</h3>
<p>Continual learning usually assumes the incoming data are fully labeled, which
might not be applicable in real applications. In this work, we consider
semi-supervised continual learning (SSCL) that incrementally learns from
partially labeled data. Observing that existing continual learning methods lack
the ability to continually exploit the unlabeled data, we propose deep Online
Replay with Discriminator Consistency (ORDisCo) to interdependently learn a
classifier with a conditional generative adversarial network (GAN), which
continually passes the learned data distribution to the classifier. In
particular, ORDisCo replays data sampled from the conditional generator to the
classifier in an online manner, exploiting unlabeled data in a time- and
storage-efficient way. Further, to explicitly overcome the catastrophic
forgetting of unlabeled data, we selectively stabilize parameters of the
discriminator that are important for discriminating the pairs of old unlabeled
data and their pseudo-labels predicted by the classifier. We extensively
evaluate ORDisCo on various semi-supervised learning benchmark datasets for
SSCL, and show that ORDisCo achieves significant performance improvement on
SVHN, CIFAR10 and Tiny-ImageNet, compared to strong baselines.
</p>
<a href="http://arxiv.org/abs/2101.00407" target="_blank">arXiv:2101.00407</a> [<a href="http://arxiv.org/pdf/2101.00407" target="_blank">pdf</a>]

<h2>Representation Learning of Reconstructed Graphs Using Random Walk Graph Convolutional Network. (arXiv:2101.00417v1 [cs.LG])</h2>
<h3>Xing Li, Wei Wei, Xiangnan Feng, Zhiming Zheng</h3>
<p>Graphs are often used to organize data because of their simple topological
structure, and therefore play a key role in machine learning. And it turns out
that the low-dimensional embedded representation obtained by graph
representation learning are extremely useful in various typical tasks, such as
node classification, content recommendation and link prediction. However, the
existing methods mostly start from the microstructure (i.e., the edges) in the
graph, ignoring the mesoscopic structure (high-order local structure). Here, we
propose wGCN -- a novel framework that utilizes random walk to obtain the
node-specific mesoscopic structures of the graph, and utilizes these mesoscopic
structures to reconstruct the graph And organize the characteristic information
of the nodes. Our method can effectively generate node embeddings for
previously unseen data, which has been proven in a series of experiments
conducted on citation networks and social networks (our method has advantages
over baseline methods). We believe that combining high-order local structural
information can more efficiently explore the potential of the network, which
will greatly improve the learning efficiency of graph neural network and
promote the establishment of new learning models.
</p>
<a href="http://arxiv.org/abs/2101.00417" target="_blank">arXiv:2101.00417</a> [<a href="http://arxiv.org/pdf/2101.00417" target="_blank">pdf</a>]

<h2>On the confidence of stereo matching in a deep-learning era: a quantitative evaluation. (arXiv:2101.00431v1 [cs.CV])</h2>
<h3>Matteo Poggi, Seungryong Kim, Fabio Tosi, Sunok Kim, Filippo Aleotti, Dongbo Min, Kwanghoon Sohn, Stefano Mattoccia</h3>
<p>Stereo matching is one of the most popular techniques to estimate dense depth
maps by finding the disparity between matching pixels on two, synchronized and
rectified images. Alongside with the development of more accurate algorithms,
the research community focused on finding good strategies to estimate the
reliability, i.e. the confidence, of estimated disparity maps. This information
proves to be a powerful cue to naively find wrong matches as well as to improve
the overall effectiveness of a variety of stereo algorithms according to
different strategies. In this paper, we review more than ten years of
developments in the field of confidence estimation for stereo matching. We
extensively discuss and evaluate existing confidence measures and their
variants, from hand-crafted ones to the most recent, state-of-the-art learning
based methods. We study the different behaviors of each measure when applied to
a pool of different stereo algorithms and, for the first time in literature,
when paired with a state-of-the-art deep stereo network. Our experiments,
carried out on five different standard datasets, provide a comprehensive
overview of the field, highlighting in particular both strengths and
limitations of learning-based strategies.
</p>
<a href="http://arxiv.org/abs/2101.00431" target="_blank">arXiv:2101.00431</a> [<a href="http://arxiv.org/pdf/2101.00431" target="_blank">pdf</a>]

<h2>Refining activation downsampling with SoftPool. (arXiv:2101.00440v1 [cs.CV])</h2>
<h3>Alexandros Stergiou, Ronald Poppe, Grigorios Kalliatakis</h3>
<p>Convolutional Neural Networks (CNNs) use pooling to decrease the size of
activation maps. This process is crucial to locally achieve spatial invariance
and to increase the receptive field of subsequent convolutions. Pooling
operations should minimize the loss of information in the activation maps. At
the same time, the computation and memory overhead should be limited. To meet
these requirements, we propose SoftPool: a fast and efficient method that sums
exponentially weighted activations. Compared to a range of other pooling
methods, SoftPool retains more information in the downsampled activation maps.
More refined downsampling leads to better classification accuracy. On
ImageNet1K, for a range of popular CNN architectures, replacing the original
pooling operations with SoftPool leads to consistent accuracy improvements in
the order of 1-2%. We also test SoftPool on video datasets for action
recognition. Again, replacing only the pooling layers consistently increases
accuracy while computational load and memory remain limited. These favorable
properties make SoftPool an excellent replacement for current pooling
operations, including max-pool and average-pool
</p>
<a href="http://arxiv.org/abs/2101.00440" target="_blank">arXiv:2101.00440</a> [<a href="http://arxiv.org/pdf/2101.00440" target="_blank">pdf</a>]

<h2>Semantics for Robotic Mapping, Perception and Interaction: A Survey. (arXiv:2101.00443v1 [cs.RO])</h2>
<h3>Sourav Garg, Niko S&#xfc;nderhauf, Feras Dayoub, Douglas Morrison, Akansel Cosgun, Gustavo Carneiro, Qi Wu, Tat-Jun Chin, Ian Reid, Stephen Gould, Peter Corke, Michael Milford</h3>
<p>For robots to navigate and interact more richly with the world around them,
they will likely require a deeper understanding of the world in which they
operate. In robotics and related research fields, the study of understanding is
often referred to as semantics, which dictates what does the world "mean" to a
robot, and is strongly tied to the question of how to represent that meaning.
With humans and robots increasingly operating in the same world, the prospects
of human-robot interaction also bring semantics and ontology of natural
language into the picture. Driven by need, as well as by enablers like
increasing availability of training data and computational resources, semantics
is a rapidly growing research area in robotics. The field has received
significant attention in the research literature to date, but most reviews and
surveys have focused on particular aspects of the topic: the technical research
issues regarding its use in specific robotic topics like mapping or
segmentation, or its relevance to one particular application domain like
autonomous driving. A new treatment is therefore required, and is also timely
because so much relevant research has occurred since many of the key surveys
were published. This survey therefore provides an overarching snapshot of where
semantics in robotics stands today. We establish a taxonomy for semantics
research in or relevant to robotics, split into four broad categories of
activity, in which semantics are extracted, used, or both. Within these broad
categories we survey dozens of major topics including fundamentals from the
computer vision field and key robotics research areas utilizing semantics,
including mapping, navigation and interaction with the world. The survey also
covers key practical considerations, including enablers like increased data
availability and improved computational hardware, and major application areas
where...
</p>
<a href="http://arxiv.org/abs/2101.00443" target="_blank">arXiv:2101.00443</a> [<a href="http://arxiv.org/pdf/2101.00443" target="_blank">pdf</a>]

<h2>Uncertainty-sensitive Activity Recognition: a Reliability Benchmark and the CARING Models. (arXiv:2101.00468v1 [cs.CV])</h2>
<h3>Alina Roitberg, Monica Haurilet, Manuel Martinez, Rainer Stiefelhagen</h3>
<p>Beyond assigning the correct class, an activity recognition model should also
be able to determine, how certain it is in its predictions. We present the
first study of how welthe confidence values of modern action recognition
architectures indeed reflect the probability of the correct outcome and propose
a learning-based approach for improving it. First, we extend two popular action
recognition datasets with a reliability benchmark in form of the expected
calibration error and reliability diagrams. Since our evaluation highlights
that confidence values of standard action recognition architectures do not
represent the uncertainty well, we introduce a new approach which learns to
transform the model output into realistic confidence estimates through an
additional calibration network. The main idea of our Calibrated Action
Recognition with Input Guidance (CARING) model is to learn an optimal scaling
parameter depending on the video representation. We compare our model with the
native action recognition networks and the temperature scaling approach - a
wide spread calibration method utilized in image classification. While
temperature scaling alone drastically improves the reliability of the
confidence values, our CARING method consistently leads to the best uncertainty
estimates in all benchmark settings.
</p>
<a href="http://arxiv.org/abs/2101.00468" target="_blank">arXiv:2101.00468</a> [<a href="http://arxiv.org/pdf/2101.00468" target="_blank">pdf</a>]

<h2>Securing Isosceles Triangular Formations under Heterogeneous Sensing and Mixed Constraints. (arXiv:2101.00474v1 [cs.RO])</h2>
<h3>Nelson P.K. Chan, Bayu Jayawardhana, Hector Garcia de Marina</h3>
<p>This paper focuses on securing a triangular shape (up to translation) for a
team of three mobile robots that uses heterogeneous sensing mechanism. Based on
the available local information, each robot employs the popular gradient-based
control law to attain the assigned individual task(s). In the current work,
robots are assigned either distance and signed area task(s) or bearing task(s).
We provide a sufficient condition on the gain ratio $R_{\text{Ad}}$ between the
signed area and the distance control term such that the desired formation
shape, an isosceles triangle, is reached from all feasible starting positions.
Numerical simulations are provided to support the theoretical analyses.
</p>
<a href="http://arxiv.org/abs/2101.00474" target="_blank">arXiv:2101.00474</a> [<a href="http://arxiv.org/pdf/2101.00474" target="_blank">pdf</a>]

<h2>DEVI: Open-source Human-Robot Interface for Interactive Receptionist Systems. (arXiv:2101.00479v1 [cs.RO])</h2>
<h3>Ramesha Karunasena, Piumi Sandarenu, Madushi Pinto, Achala Athukorala, Ranga Rodrigo, Peshala Jayasekara</h3>
<p>Humanoid robots that act as human-robot interfaces equipped with social
skills can assist people in many of their daily activities. Receptionist robots
are one such application where social skills and appearance are of utmost
importance. Many existing robot receptionist systems suffer from high cost and
they do not disclose internal architectures for further development for robot
researchers. Moreover, there does not exist customizable open-source robot
receptionist frameworks to be deployed for any given application. In this paper
we present an open-source robot receptionist intelligence core -- "DEVI"(means
'lady' in Sinhala), that provides researchers with ease of creating customized
robot receptionists according to the requirements (cost, external appearance,
and required processing power). Moreover, this paper also presents details on a
prototype implementation of a physical robot using the DEVI system. The robot
can give directional guidance with physical gestures, answer basic queries
using a speech recognition and synthesis system, recognize and greet known
people using face recognition and register new people in its database, using a
self-learning neural network. Experiments conducted with DEVI show the
effectiveness of the proposed system.
</p>
<a href="http://arxiv.org/abs/2101.00479" target="_blank">arXiv:2101.00479</a> [<a href="http://arxiv.org/pdf/2101.00479" target="_blank">pdf</a>]

<h2>Learning Rotation-Invariant Representations of Point Clouds Using Aligned Edge Convolutional Neural Networks. (arXiv:2101.00483v1 [cs.CV])</h2>
<h3>Junming Zhang, Ming-Yuan Yu, Ram Vasudevan, Matthew Johnson-Roberson</h3>
<p>Point cloud analysis is an area of increasing interest due to the development
of 3D sensors that are able to rapidly measure the depth of scenes accurately.
Unfortunately, applying deep learning techniques to perform point cloud
analysis is non-trivial due to the inability of these methods to generalize to
unseen rotations. To address this limitation, one usually has to augment the
training data, which can lead to extra computation and require larger model
complexity. This paper proposes a new neural network called the Aligned Edge
Convolutional Neural Network (AECNN) that learns a feature representation of
point clouds relative to Local Reference Frames (LRFs) to ensure invariance to
rotation. In particular, features are learned locally and aligned with respect
to the LRF of an automatically computed reference point. The proposed approach
is evaluated on point cloud classification and part segmentation tasks. This
paper illustrates that the proposed technique outperforms a variety of state of
the art approaches (even those trained on augmented datasets) in terms of
robustness to rotation without requiring any additional data augmentation.
</p>
<a href="http://arxiv.org/abs/2101.00483" target="_blank">arXiv:2101.00483</a> [<a href="http://arxiv.org/pdf/2101.00483" target="_blank">pdf</a>]

<h2>If You're Happy, Then You Know It: The Logic of Happiness... and Sadness. (arXiv:2101.00485v1 [cs.AI])</h2>
<h3>Sanaz Azimipour, Pavel Naumov</h3>
<p>The article proposes a formal semantics of happiness and sadness modalities
in imperfect information setting. It shows that these modalities are not
definable through each other and gives a sound and complete axiomatization of
their properties.
</p>
<a href="http://arxiv.org/abs/2101.00485" target="_blank">arXiv:2101.00485</a> [<a href="http://arxiv.org/pdf/2101.00485" target="_blank">pdf</a>]

<h2>A Provably Efficient Algorithm for Linear Markov Decision Process with Low Switching Cost. (arXiv:2101.00494v1 [cs.LG])</h2>
<h3>Minbo Gao, Tianle Xie, Simon S. Du, Lin F. Yang</h3>
<p>Many real-world applications, such as those in medical domains,
recommendation systems, etc, can be formulated as large state space
reinforcement learning problems with only a small budget of the number of
policy changes, i.e., low switching cost. This paper focuses on the linear
Markov Decision Process (MDP) recently studied in [Yang et al 2019, Jin et al
2020] where the linear function approximation is used for generalization on the
large state space. We present the first algorithm for linear MDP with a low
switching cost. Our algorithm achieves an
$\widetilde{O}\left(\sqrt{d^3H^4K}\right)$ regret bound with a near-optimal
$O\left(d H\log K\right)$ global switching cost where $d$ is the feature
dimension, $H$ is the planning horizon and $K$ is the number of episodes the
agent plays. Our regret bound matches the best existing polynomial algorithm by
[Jin et al 2020] and our switching cost is exponentially smaller than theirs.
When specialized to tabular MDP, our switching cost bound improves those in
[Bai et al 2019, Zhang et al 20020]. We complement our positive result with an
$\Omega\left(dH/\log d\right)$ global switching cost lower bound for any
no-regret algorithm.
</p>
<a href="http://arxiv.org/abs/2101.00494" target="_blank">arXiv:2101.00494</a> [<a href="http://arxiv.org/pdf/2101.00494" target="_blank">pdf</a>]

<h2>Regularization-based Continual Learning for Anomaly Detection in Discrete Manufacturing. (arXiv:2101.00509v1 [cs.LG])</h2>
<h3>Benjamin Maschler, Thi Thu Huong Pham, Michael Weyrich</h3>
<p>The early and robust detection of anomalies occurring in discrete
manufacturing processes allows operators to prevent harm, e.g. defects in
production machinery or products. While current approaches for data-driven
anomaly detection provide good results on the exact processes they were trained
on, they often lack the ability to flexibly adapt to changes, e.g. in products.
Continual learning promises such flexibility, allowing for an automatic
adaption of previously learnt knowledge to new tasks. Therefore, this article
discusses different continual learning approaches from the group of
regularization strategies, which are implemented, evaluated and compared based
on a real industrial metal forming dataset.
</p>
<a href="http://arxiv.org/abs/2101.00509" target="_blank">arXiv:2101.00509</a> [<a href="http://arxiv.org/pdf/2101.00509" target="_blank">pdf</a>]

<h2>Privacy Preserving Domain Adaptation for Semantic Segmentation of Medical Images. (arXiv:2101.00522v1 [cs.CV])</h2>
<h3>Serban Stan, Mohammad Rostami</h3>
<p>Convolutional neural networks (CNNs) have led to significant improvements in
tasks involving semantic segmentation of images. CNNs are vulnerable in the
area of biomedical image segmentation because of distributional gap between two
source and target domains with different data modalities which leads to domain
shift. Domain shift makes data annotations in new modalities necessary because
models must be retrained from scratch. Unsupervised domain adaptation (UDA) is
proposed to adapt a model to new modalities using solely unlabeled target
domain data. Common UDA algorithms require access to data points in the source
domain which may not be feasible in medical imaging due to privacy concerns. In
this work, we develop an algorithm for UDA in a privacy-constrained setting,
where the source domain data is inaccessible. Our idea is based on encoding the
information from the source samples into a prototypical distribution that is
used as an intermediate distribution for aligning the target domain
distribution with the source domain distribution. We demonstrate the
effectiveness of our algorithm by comparing it to state-of-the-art medical
image semantic segmentation approaches on two medical image semantic
segmentation datasets.
</p>
<a href="http://arxiv.org/abs/2101.00522" target="_blank">arXiv:2101.00522</a> [<a href="http://arxiv.org/pdf/2101.00522" target="_blank">pdf</a>]

<h2>One-shot Representational Learning for Joint Biometric and Device Authentication. (arXiv:2101.00524v1 [cs.CV])</h2>
<h3>Sudipta Banerjee, Arun Ross</h3>
<p>In this work, we propose a method to simultaneously perform (i) biometric
recognition (i.e., identify the individual), and (ii) device recognition,
(i.e., identify the device) from a single biometric image, say, a face image,
using a one-shot schema. Such a joint recognition scheme can be useful in
devices such as smartphones for enhancing security as well as privacy. We
propose to automatically learn a joint representation that encapsulates both
biometric-specific and sensor-specific features. We evaluate the proposed
approach using iris, face and periocular images acquired using near-infrared
iris sensors and smartphone cameras. Experiments conducted using 14,451 images
from 15 sensors resulted in a rank-1 identification accuracy of upto 99.81% and
a verification accuracy of upto 100% at a false match rate of 1%.
</p>
<a href="http://arxiv.org/abs/2101.00524" target="_blank">arXiv:2101.00524</a> [<a href="http://arxiv.org/pdf/2101.00524" target="_blank">pdf</a>]

<h2>VinVL: Making Visual Representations Matter in Vision-Language Models. (arXiv:2101.00529v1 [cs.CV])</h2>
<h3>Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang, Yejin Choi, Jianfeng Gao</h3>
<p>This paper presents a detailed study of improving visual representations for
vision language (VL) tasks and develops an improved object detection model to
provide object-centric representations of images. Compared to the most widely
used \emph{bottom-up and top-down} model \cite{anderson2018bottom}, the new
model is bigger, better-designed for VL tasks, and pre-trained on much larger
training corpora that combine multiple public annotated object detection
datasets. Therefore, it can generate representations of a richer collection of
visual objects and concepts. While previous VL research focuses mainly on
improving the vision-language fusion model and leaves the object detection
model improvement untouched, we show that visual features matter significantly
in VL models. In our experiments we feed the visual features generated by the
new object detection model into a Transformer-based VL fusion model \oscar
\cite{li2020oscar}, and utilize an improved approach \short\ to pre-train the
VL model and fine-tune it on a wide range of downstream VL tasks. Our results
show that the new visual features significantly improve the performance across
all VL tasks, creating new state-of-the-art results on seven public benchmarks.
We will release the new object detection model to public.
</p>
<a href="http://arxiv.org/abs/2101.00529" target="_blank">arXiv:2101.00529</a> [<a href="http://arxiv.org/pdf/2101.00529" target="_blank">pdf</a>]

<h2>Context-Aware Safe Reinforcement Learning for Non-Stationary Environments. (arXiv:2101.00531v1 [cs.LG])</h2>
<h3>Baiming Chen, Zuxin Liu, Jiacheng Zhu, Mengdi Xu, Wenhao Ding, Ding Zhao</h3>
<p>Safety is a critical concern when deploying reinforcement learning agents for
realistic tasks. Recently, safe reinforcement learning algorithms have been
developed to optimize the agent's performance while avoiding violations of
safety constraints. However, few studies have addressed the non-stationary
disturbances in the environments, which may cause catastrophic outcomes. In
this paper, we propose the context-aware safe reinforcement learning (CASRL)
method, a meta-learning framework to realize safe adaptation in non-stationary
environments. We use a probabilistic latent variable model to achieve fast
inference of the posterior environment transition distribution given the
context data. Safety constraints are then evaluated with uncertainty-aware
trajectory sampling. The high cost of safety violations leads to the rareness
of unsafe records in the dataset. We address this issue by enabling prioritized
sampling during model training and formulating prior safety constraints with
domain knowledge during constrained planning. The algorithm is evaluated in
realistic safety-critical environments with non-stationary disturbances.
Results show that the proposed algorithm significantly outperforms existing
baselines in terms of safety and robustness.
</p>
<a href="http://arxiv.org/abs/2101.00531" target="_blank">arXiv:2101.00531</a> [<a href="http://arxiv.org/pdf/2101.00531" target="_blank">pdf</a>]

<h2>A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization. (arXiv:2101.00545v1 [cs.CV])</h2>
<h3>Ashraful Islam, Chengjiang Long, Richard J. Radke</h3>
<p>Weakly supervised temporal action localization is a challenging vision task
due to the absence of ground-truth temporal locations of actions in the
training videos. With only video-level supervision during training, most
existing methods rely on a Multiple Instance Learning (MIL) framework to
predict the start and end frame of each action category in a video. However,
the existing MIL-based approach has a major limitation of only capturing the
most discriminative frames of an action, ignoring the full extent of an
activity. Moreover, these methods cannot model background activity effectively,
which plays an important role in localizing foreground activities. In this
paper, we present a novel framework named HAM-Net with a hybrid attention
mechanism which includes temporal soft, semi-soft and hard attentions to
address these issues. Our temporal soft attention module, guided by an
auxiliary background class in the classification module, models the background
activity by introducing an "action-ness" score for each video snippet.
Moreover, our temporal semi-soft and hard attention modules, calculating two
attention scores for each video snippet, help to focus on the less
discriminative frames of an action to capture the full action boundary. Our
proposed approach outperforms recent state-of-the-art methods by at least 3.8%
mAP at IoU threshold 0.5 on the THUMOS14 dataset, and by at least 1.3% mAP at
IoU threshold 0.75 on the ActivityNet1.2 dataset. Code can be found at:
https://github.com/asrafulashiq/hamnet.
</p>
<a href="http://arxiv.org/abs/2101.00545" target="_blank">arXiv:2101.00545</a> [<a href="http://arxiv.org/pdf/2101.00545" target="_blank">pdf</a>]

<h2>Six-channel Image Representation for Cross-domain Object Detection. (arXiv:2101.00561v1 [cs.CV])</h2>
<h3>Tianxiao Zhang, Wenchi Ma, Guanghui Wang</h3>
<p>Most deep learning models are data-driven and the excellent performance is
highly dependent on the abundant and diverse datasets. However, it is very hard
to obtain and label the datasets of some specific scenes or applications. If we
train the detector using the data from one domain, it cannot perform well on
the data from another domain due to domain shift, which is one of the big
challenges of most object detection models. To address this issue, some
image-to-image translation techniques are employed to generate some fake data
of some specific scenes to train the models. With the advent of Generative
Adversarial Networks (GANs), we could realize unsupervised image-to-image
translation in both directions from a source to a target domain and from the
target to the source domain. In this study, we report a new approach to making
use of the generated images. We propose to concatenate the original 3-channel
images and their corresponding GAN-generated fake images to form 6-channel
representations of the dataset, hoping to address the domain shift problem
while exploiting the success of available detection models. The idea of
augmented data representation may inspire further study on object detection and
other applications.
</p>
<a href="http://arxiv.org/abs/2101.00561" target="_blank">arXiv:2101.00561</a> [<a href="http://arxiv.org/pdf/2101.00561" target="_blank">pdf</a>]

<h2>Few-shot Image Classification: Just Use a Library of Pre-trained Feature Extractors and a Simple Classifier. (arXiv:2101.00562v1 [cs.CV])</h2>
<h3>Arkabandhu Chowdhury, Mingchao Jiang, Chris Jermaine</h3>
<p>Recent papers have suggested that transfer learning can outperform
sophisticated meta-learning methods for few-shot image classification. We take
this hypothesis to its logical conclusion, and suggest the use of an ensemble
of high-quality, pre-trained feature extractors for few-shot image
classification. We show experimentally that a library of pre-trained feature
extractors combined with a simple feed-forward network learned with an
L2-regularizer can be an excellent option for solving cross-domain few-shot
image classification. Our experimental results suggest that this simpler
sample-efficient approach far outperforms several well-established
meta-learning algorithms on a variety of few-shot tasks.
</p>
<a href="http://arxiv.org/abs/2101.00562" target="_blank">arXiv:2101.00562</a> [<a href="http://arxiv.org/pdf/2101.00562" target="_blank">pdf</a>]

<h2>Learning Neural Networks on SVD Boosted Latent Spaces for Semantic Classification. (arXiv:2101.00563v1 [cs.LG])</h2>
<h3>Sahil Sidheekh</h3>
<p>The availability of large amounts of data and compelling computation power
have made deep learning models much popular for text classification and
sentiment analysis. Deep neural networks have achieved competitive performance
on the above tasks when trained on naive text representations such as word
count, term frequency, and binary matrix embeddings. However, many of the above
representations result in the input space having a dimension of the order of
the vocabulary size, which is enormous. This leads to a blow-up in the number
of parameters to be learned, and the computational cost becomes infeasible when
scaling to domains that require retaining a colossal vocabulary. This work
proposes using singular value decomposition to transform the high dimensional
input space to a lower-dimensional latent space. We show that neural networks
trained on this lower-dimensional space are not only able to retain performance
while savoring significant reduction in the computational complexity but, in
many situations, also outperforms the classical neural networks trained on the
native input space.
</p>
<a href="http://arxiv.org/abs/2101.00563" target="_blank">arXiv:2101.00563</a> [<a href="http://arxiv.org/pdf/2101.00563" target="_blank">pdf</a>]

<h2>StarNet: Gradient-free Training of Deep Generative Models using Determined System of Linear Equations. (arXiv:2101.00574v1 [cs.LG])</h2>
<h3>Amir Zadeh, Santiago Benoit, Louis-Philippe Morency</h3>
<p>In this paper we present an approach for training deep generative models
solely based on solving determined systems of linear equations. A network that
uses this approach, called a StarNet, has the following desirable properties:
1) training requires no gradient as solution to the system of linear equations
is not stochastic, 2) is highly scalable when solving the system of linear
equations w.r.t the latent codes, and similarly for the parameters of the
model, and 3) it gives desirable least-square bounds for the estimation of
latent codes and network parameters within each layer.
</p>
<a href="http://arxiv.org/abs/2101.00574" target="_blank">arXiv:2101.00574</a> [<a href="http://arxiv.org/pdf/2101.00574" target="_blank">pdf</a>]

<h2>Improved Convergence Guarantees for Learning Gaussian Mixture Models by EM and Gradient EM. (arXiv:2101.00575v1 [cs.LG])</h2>
<h3>Nimrod Segol, Boaz Nadler</h3>
<p>We consider the problem of estimating the parameters a Gaussian Mixture Model
with K components of known weights, all with an identity covariance matrix. We
make two contributions. First, at the population level, we present a sharper
analysis of the local convergence of EM and gradient EM, compared to previous
works. Assuming a separation of $\Omega(\sqrt{\log K})$, we prove convergence
of both methods to the global optima from an initialization region larger than
those of previous works. Specifically, the initial guess of each component can
be as far as (almost) half its distance to the nearest Gaussian. This is
essentially the largest possible contraction region. Our second contribution
are improved sample size requirements for accurate estimation by EM and
gradient EM. In previous works, the required number of samples had a quadratic
dependence on the maximal separation between the K components, and the
resulting error estimate increased linearly with this maximal separation. In
this manuscript we show that both quantities depend only logarithmically on the
maximal separation.
</p>
<a href="http://arxiv.org/abs/2101.00575" target="_blank">arXiv:2101.00575</a> [<a href="http://arxiv.org/pdf/2101.00575" target="_blank">pdf</a>]

<h2>Multi-label Ranking: Mining Multi-label and Label Ranking Data. (arXiv:2101.00583v1 [cs.LG])</h2>
<h3>Lihi Dery</h3>
<p>We survey multi-label ranking tasks, specifically multi-label classification
and label ranking classification. We highlight the unique challenges, and
re-categorize the methods, as they no longer fit into the traditional
categories of transformation and adaptation. We survey developments in the last
demi-decade, with a special focus on state-of-the-art methods in deep learning
multi-label mining, extreme multi-label classification and label ranking. We
conclude by offering a few future research directions.
</p>
<a href="http://arxiv.org/abs/2101.00583" target="_blank">arXiv:2101.00583</a> [<a href="http://arxiv.org/pdf/2101.00583" target="_blank">pdf</a>]

<h2>UPSLAM: Union of Panoramas SLAM. (arXiv:2101.00585v1 [cs.RO])</h2>
<h3>Anthony Cowley, Ian D. Miller, Camillo Jose Taylor</h3>
<p>We present an empirical investigation of a new mapping system based on a
graph of panoramic depth images. Panoramic images efficiently capture range
measurements taken by a spinning lidar sensor, recording fine detail on the
order of a few centimeters within maps of expansive scope on the order of tens
of millions of cubic meters. The flexibility of the system is demonstrated by
running the same mapping software against data collected by hand-carrying a
sensor around a laboratory space at walking pace, moving it outdoors through a
campus environment at running pace, driving the sensor on a small wheeled
vehicle on- and off-road, flying the sensor through a forest, carrying it on
the back of a legged robot navigating an underground coal mine, and mounting it
on the roof of a car driven on public roads. The full 3D maps are built online
with a median update time of less than ten milliseconds on an embedded NVIDIA
Jetson AGX Xavier system.
</p>
<a href="http://arxiv.org/abs/2101.00585" target="_blank">arXiv:2101.00585</a> [<a href="http://arxiv.org/pdf/2101.00585" target="_blank">pdf</a>]

<h2>Style Normalization and Restitution for DomainGeneralization and Adaptation. (arXiv:2101.00588v1 [cs.CV])</h2>
<h3>Xin Jin, Cuiling Lan, Wenjun Zeng, Zhibo Chen</h3>
<p>For many practical computer vision applications, the learned models usually
have high performance on the datasets used for training but suffer from
significant performance degradation when deployed in new environments, where
there are usually style differences between the training images and the testing
images. An effective domain generalizable model is expected to be able to learn
feature representations that are both generalizable and discriminative. In this
paper, we design a novel Style Normalization and Restitution module (SNR) to
simultaneously ensure both high generalization and discrimination capability of
the networks. In the SNR module, particularly, we filter out the style
variations (e.g, illumination, color contrast) by performing Instance
Normalization (IN) to obtain style normalized features, where the discrepancy
among different samples and domains is reduced. However, such a process is
task-ignorant and inevitably removes some task-relevant discriminative
information, which could hurt the performance. To remedy this, we propose to
distill task-relevant discriminative features from the residual (i.e, the
difference between the original feature and the style normalized feature) and
add them back to the network to ensure high discrimination. Moreover, for
better disentanglement, we enforce a dual causality loss constraint in the
restitution step to encourage the better separation of task-relevant and
task-irrelevant features. We validate the effectiveness of our SNR on different
computer vision tasks, including classification, semantic segmentation, and
object detection. Experiments demonstrate that our SNR module is capable of
improving the performance of networks for domain generalization (DG) and
unsupervised domain adaptation (UDA) on many tasks. Code are available at
https://github.com/microsoft/SNR.
</p>
<a href="http://arxiv.org/abs/2101.00588" target="_blank">arXiv:2101.00588</a> [<a href="http://arxiv.org/pdf/2101.00588" target="_blank">pdf</a>]

<h2>diff-SAT -- A Software for Sampling and Probabilistic Reasoning for SAT and Answer Set Programming. (arXiv:2101.00589v1 [cs.AI])</h2>
<h3>Matthias Nickles</h3>
<p>This paper describes diff-SAT, an Answer Set and SAT solver which combines
regular solving with the capability to use probabilistic clauses, facts and
rules, and to sample an optimal world-view (multiset of satisfying Boolean
variable assignments or answer sets) subject to user-provided probabilistic
constraints. The sampling process minimizes a user-defined differentiable
objective function using a gradient descent based optimization method called
Differentiable Satisfiability Solving ($\partial\mathrm{SAT}$) respectively
Differentiable Answer Set Programming ($\partial\mathrm{ASP}$). Use cases are
i.a. probabilistic logic programming (in form of Probabilistic Answer Set
Programming), Probabilistic Boolean Satisfiability solving (PSAT), and
distribution-aware sampling of model multisets (answer sets or Boolean
interpretations).
</p>
<a href="http://arxiv.org/abs/2101.00589" target="_blank">arXiv:2101.00589</a> [<a href="http://arxiv.org/pdf/2101.00589" target="_blank">pdf</a>]

<h2>Consensus-Guided Correspondence Denoising. (arXiv:2101.00591v1 [cs.CV])</h2>
<h3>Chen Zhao, Yixiao Ge, Jiaqi Yang, Feng Zhu, Rui Zhao, Hongsheng Li</h3>
<p>Correspondence selection between two groups of feature points aims to
correctly recognize the consistent matches (inliers) from the initial noisy
matches. The selection is generally challenging since the initial matches are
generally extremely unbalanced, where outliers can easily dominate. Moreover,
random distributions of outliers lead to the limited robustness of previous
works when applied to different scenarios. To address this issue, we propose to
denoise correspondences with a local-to-global consensus learning framework to
robustly identify correspondence. A novel "pruning" block is introduced to
distill reliable candidates from initial matches according to their consensus
scores estimated by dynamic graphs from local to global regions. The proposed
correspondence denoising is progressively achieved by stacking multiple pruning
blocks sequentially. Our method outperforms state-of-the-arts on robust line
fitting, wide-baseline image matching and image localization benchmarks by
noticeable margins and shows promising generalization capability on different
distributions of initial matches.
</p>
<a href="http://arxiv.org/abs/2101.00591" target="_blank">arXiv:2101.00591</a> [<a href="http://arxiv.org/pdf/2101.00591" target="_blank">pdf</a>]

<h2>Copula Flows for Synthetic Data Generation. (arXiv:2101.00598v1 [stat.ML])</h2>
<h3>Sanket Kamthe, Samuel Assefa, Marc Deisenroth</h3>
<p>The ability to generate high-fidelity synthetic data is crucial when
available (real) data is limited or where privacy and data protection standards
allow only for limited use of the given data, e.g., in medical and financial
data-sets. Current state-of-the-art methods for synthetic data generation are
based on generative models, such as Generative Adversarial Networks (GANs).
Even though GANs have achieved remarkable results in synthetic data generation,
they are often challenging to interpret.Furthermore, GAN-based methods can
suffer when used with mixed real and categorical variables.Moreover, loss
function (discriminator loss) design itself is problem specific, i.e., the
generative model may not be useful for tasks it was not explicitly trained for.
In this paper, we propose to use a probabilistic model as a synthetic data
generator. Learning the probabilistic model for the data is equivalent to
estimating the density of the data. Based on the copula theory, we divide the
density estimation task into two parts, i.e., estimating univariate marginals
and estimating the multivariate copula density over the univariate marginals.
We use normalising flows to learn both the copula density and univariate
marginals. We benchmark our method on both simulated and real data-sets in
terms of density estimation as well as the ability to generate high-fidelity
synthetic data
</p>
<a href="http://arxiv.org/abs/2101.00598" target="_blank">arXiv:2101.00598</a> [<a href="http://arxiv.org/pdf/2101.00598" target="_blank">pdf</a>]

<h2>A Switched View of Retinex: Deep Self-Regularized Low-Light Image Enhancement. (arXiv:2101.00603v1 [cs.CV])</h2>
<h3>Zhuqing Jiang, Haotian Li, Liangjie Liu, Aidong Men, Haiying Wang</h3>
<p>Self-regularized low-light image enhancement does not require any
normal-light image in training, thereby freeing from the chains on paired or
unpaired low-/normal-images. However, existing methods suffer color deviation
and fail to generalize to various lighting conditions. This paper presents a
novel self-regularized method based on Retinex, which, inspired by HSV,
preserves all colors (Hue, Saturation) and only integrates Retinex theory into
brightness (Value). We build a reflectance estimation network by restricting
the consistency of reflectances embedded in both the original and a novel
random disturbed form of the brightness of the same scene. The generated
reflectance, which is assumed to be irrelevant of illumination by Retinex, is
treated as enhanced brightness. Our method is efficient as a low-light image is
decoupled into two subspaces, color and brightness, for better preservation and
enhancement. Extensive experiments demonstrate that our method outperforms
multiple state-of-the-art algorithms qualitatively and quantitatively and
adapts to more lighting conditions.
</p>
<a href="http://arxiv.org/abs/2101.00603" target="_blank">arXiv:2101.00603</a> [<a href="http://arxiv.org/pdf/2101.00603" target="_blank">pdf</a>]

<h2>Privacy-sensitive Objects Pixelation for Live Video Streaming. (arXiv:2101.00604v1 [cs.CV])</h2>
<h3>Jizhe Zhou, Chi-Man Pun, Yu Tong</h3>
<p>With the prevailing of live video streaming, establishing an online
pixelation method for privacy-sensitive objects is an urgency. Caused by the
inaccurate detection of privacy-sensitive objects, simply migrating the
tracking-by-detection structure into the online form will incur problems in
target initialization, drifting, and over-pixelation. To cope with the
inevitable but impacting detection issue, we propose a novel Privacy-sensitive
Objects Pixelation (PsOP) framework for automatic personal privacy filtering
during live video streaming. Leveraging pre-trained detection networks, our
PsOP is extendable to any potential privacy-sensitive objects pixelation.
Employing the embedding networks and the proposed Positioned Incremental
Affinity Propagation (PIAP) clustering algorithm as the backbone, our PsOP
unifies the pixelation of discriminating and indiscriminating pixelation
objects through trajectories generation. In addition to the pixelation accuracy
boosting, experiments on the streaming video data we built show that the
proposed PsOP can significantly reduce the over-pixelation ratio in
privacy-sensitive object pixelation.
</p>
<a href="http://arxiv.org/abs/2101.00604" target="_blank">arXiv:2101.00604</a> [<a href="http://arxiv.org/pdf/2101.00604" target="_blank">pdf</a>]

<h2>News Image Steganography: A Novel Architecture Facilitates the Fake News Identification. (arXiv:2101.00606v1 [cs.CV])</h2>
<h3>Jizhe Zhou, Chi-Man Pun, Yu Tong</h3>
<p>A larger portion of fake news quotes untampered images from other sources
with ulterior motives rather than conducting image forgery. Such elaborate
engraftments keep the inconsistency between images and text reports stealthy,
thereby, palm off the spurious for the genuine. This paper proposes an
architecture named News Image Steganography (NIS) to reveal the aforementioned
inconsistency through image steganography based on GAN. Extractive
summarization about a news image is generated based on its source texts, and a
learned steganographic algorithm encodes and decodes the summarization of the
image in a manner that approaches perceptual invisibility. Once an encoded
image is quoted, its source summarization can be decoded and further presented
as the ground truth to verify the quoting news. The pairwise encoder and
decoder endow images of the capability to carry along their imperceptible
summarization. Our NIS reveals the underlying inconsistency, thereby, according
to our experiments and investigations, contributes to the identification
accuracy of fake news that engrafts untampered images.
</p>
<a href="http://arxiv.org/abs/2101.00606" target="_blank">arXiv:2101.00606</a> [<a href="http://arxiv.org/pdf/2101.00606" target="_blank">pdf</a>]

<h2>AttnMove: History Enhanced Trajectory Recovery via Attentional Network. (arXiv:2101.00646v1 [cs.LG])</h2>
<h3>Tong Xia, Yunhan Qi, Jie Feng, Fengli Xu, Funing Sun, Diansheng Guo, Yong Li</h3>
<p>A considerable amount of mobility data has been accumulated due to the
proliferation of location-based service. Nevertheless, compared with mobility
data from transportation systems like the GPS module in taxis, this kind of
data is commonly sparse in terms of individual trajectories in the sense that
users do not access mobile services and contribute their data all the time.
Consequently, the sparsity inevitably weakens the practical value of the data
even it has a high user penetration rate. To solve this problem, we propose a
novel attentional neural network-based model, named AttnMove, to densify
individual trajectories by recovering unobserved locations at a fine-grained
spatial-temporal resolution. To tackle the challenges posed by sparsity, we
design various intra- and inter- trajectory attention mechanisms to better
model the mobility regularity of users and fully exploit the periodical pattern
from long-term history. We evaluate our model on two real-world datasets, and
extensive results demonstrate the performance gain compared with the
state-of-the-art methods. This also shows that, by providing high-quality
mobility data, our model can benefit a variety of mobility-oriented down-stream
applications.
</p>
<a href="http://arxiv.org/abs/2101.00646" target="_blank">arXiv:2101.00646</a> [<a href="http://arxiv.org/pdf/2101.00646" target="_blank">pdf</a>]

<h2>Depth as Attention for Face Representation Learning. (arXiv:2101.00652v1 [cs.CV])</h2>
<h3>Hardik Uppal, Alireza Sepas-Moghaddam, Michael Greenspan, Ali Etemad</h3>
<p>Face representation learning solutions have recently achieved great success
for various applications such as verification and identification. However, face
recognition approaches that are based purely on RGB images rely solely on
intensity information, and therefore are more sensitive to facial variations,
notably pose, occlusions, and environmental changes such as illumination and
background. A novel depth-guided attention mechanism is proposed for deep
multi-modal face recognition using low-cost RGB-D sensors. Our novel attention
mechanism directs the deep network "where to look" for visual features in the
RGB image by focusing the attention of the network using depth features
extracted by a Convolution Neural Network (CNN). The depth features help the
network focus on regions of the face in the RGB image that contains more
prominent person-specific information. Our attention mechanism then uses this
correlation to generate an attention map for RGB images from the depth features
extracted by CNN. We test our network on four public datasets, showing that the
features obtained by our proposed solution yield better results on the
Lock3DFace, CurtinFaces, IIIT-D RGB-D, and KaspAROV datasets which include
challenging variations in pose, occlusion, illumination, expression, and
time-lapse. Our solution achieves average (increased) accuracies of 87.3\%
(+5.0\%), 99.1\% (+0.9\%), 99.7\% (+0.6\%) and 95.3\%(+0.5\%) for the four
datasets respectively, thereby improving the state-of-the-art. We also perform
additional experiments with thermal images, instead of depth images, showing
the high generalization ability of our solution when adopting other modalities
for guiding the attention mechanism instead of depth information
</p>
<a href="http://arxiv.org/abs/2101.00652" target="_blank">arXiv:2101.00652</a> [<a href="http://arxiv.org/pdf/2101.00652" target="_blank">pdf</a>]

<h2>Combining Graph Neural Networks and Spatio-temporal Disease Models to Predict COVID-19 Cases in Germany. (arXiv:2101.00661v1 [cs.LG])</h2>
<h3>Cornelius Fritz, Emilio Dorigatti, David R&#xfc;gamer</h3>
<p>During 2020, the infection rate of COVID-19 has been investigated by many
scholars from different research fields. In this context, reliable and
interpretable forecasts of disease incidents are a vital tool for policymakers
to manage healthcare resources. Several experts have called for the necessity
to account for human mobility to explain the spread of COVID-19. Existing
approaches are often applying standard models of the respective research field.
This habit, however, often comes along with certain restrictions. For instance,
most statistical or epidemiological models cannot directly incorporate
unstructured data sources, including relational data that may encode human
mobility. In contrast, machine learning approaches may yield better predictions
by exploiting these data structures, yet lack intuitive interpretability as
they are often categorized as black-box models. We propose a trade-off between
both research directions and present a multimodal learning approach that
combines the advantages of statistical regression and machine learning models
for predicting local COVID-19 cases in Germany. This novel approach enables the
use of a richer collection of data types, including mobility flows and
colocation probabilities, and yields the lowest MSE scores throughout our
observational period in our benchmark study. The results corroborate the
necessity of including mobility data and showcase the flexibility and
interpretability of our approach.
</p>
<a href="http://arxiv.org/abs/2101.00661" target="_blank">arXiv:2101.00661</a> [<a href="http://arxiv.org/pdf/2101.00661" target="_blank">pdf</a>]

<h2>Weakly Supervised Multi-Object Tracking and Segmentation. (arXiv:2101.00667v1 [cs.CV])</h2>
<h3>Idoia Ruiz, Lorenzo Porzi, Samuel Rota Bul&#xf2;, Peter Kontschieder, Joan Serrat</h3>
<p>We introduce the problem of weakly supervised Multi-Object Tracking and
Segmentation, i.e. joint weakly supervised instance segmentation and
multi-object tracking, in which we do not provide any kind of mask annotation.
To address it, we design a novel synergistic training strategy by taking
advantage of multi-task learning, i.e. classification and tracking tasks guide
the training of the unsupervised instance segmentation. For that purpose, we
extract weak foreground localization information, provided by Grad-CAM
heatmaps, to generate a partial ground truth to learn from. Additionally, RGB
image level information is employed to refine the mask prediction at the edges
of the objects. We evaluate our method on KITTI MOTS, the most representative
benchmark for this task, reducing the performance gap on the MOTSP metric
between the fully supervised and weakly supervised approach to just 12% and
12.7% for cars and pedestrians, respectively.
</p>
<a href="http://arxiv.org/abs/2101.00667" target="_blank">arXiv:2101.00667</a> [<a href="http://arxiv.org/pdf/2101.00667" target="_blank">pdf</a>]

<h2>Past, Present, and Future of Swarm Robotics. (arXiv:2101.00671v1 [cs.RO])</h2>
<h3>Ahmad Reza Cheraghi, Sahdia Shahzad, Kalman Graffi</h3>
<p>Swarm Robotics is an emerging field of adapting the phenomenon of natural
swarms to robotics. It is a study of robots that are aimed to mimic natural
swarms, like ants and birds, to form a system that is scalable, flexible, and
robust. These robots show self-organization, autonomy, cooperation, and
coordination amongst themselves. The cost and design complexity factor is aimed
to keep low, hence trying to form systems that are very much similar to natural
swarms. The robots operate without any central entity to control them, and the
communication amongst the robots can either be direct (robot-to-robot) or
indirect (robot-to-environment). Swarm robotics has a wide range of application
fields, from simple household tasks to military missions. This paper reviews
the swarm robotics approach from its history to its future. It discusses the
basic idea of swarm robotics, its important features, simulators, projects,
real life applications and some future ideas.
</p>
<a href="http://arxiv.org/abs/2101.00671" target="_blank">arXiv:2101.00671</a> [<a href="http://arxiv.org/pdf/2101.00671" target="_blank">pdf</a>]

<h2>Learning optimal Bayesian prior probabilities from data. (arXiv:2101.00672v1 [cs.LG])</h2>
<h3>Ozan Kaan Kayaalp</h3>
<p>Noninformative uniform priors are staples of Bayesian inference, especially
in Bayesian machine learning. This study challenges the assumption that they
are optimal and their use in Bayesian inference yields optimal outcomes.
Instead of using arbitrary noninformative uniform priors, we propose a machine
learning based alternative method, learning optimal priors from data by
maximizing a target function of interest. Applying na\"ive Bayes text
classification methodology and a search algorithm developed for this study, our
system learned priors from data using the positive predictive value metric as
the target function. The task was to find Wikipedia articles that had not (but
should have) been categorized under certain Wikipedia categories. We conducted
five sets of experiments using separate Wikipedia categories. While the
baseline models used the popular Bayes-Laplace priors, the study models learned
the optimal priors for each set of experiments separately before using them.
The results showed that the study models consistently outperformed the baseline
models with a wide margin of statistical significance (p &lt; 0.001). The measured
performance improvement of the study model over the baseline was as high as
443% with the mean value of 193% over five Wikipedia categories.
</p>
<a href="http://arxiv.org/abs/2101.00672" target="_blank">arXiv:2101.00672</a> [<a href="http://arxiv.org/pdf/2101.00672" target="_blank">pdf</a>]

<h2>Sentiment Analysis for Open Domain Conversational Agent. (arXiv:2101.00675v1 [cs.AI])</h2>
<h3>Mohamad Alissa, Issa Haddad, Jonathan Meyer, Jade Obeid, Kostis Vilaetis, Nicolas Wiecek, Sukrit Wongariyakavee</h3>
<p>The applicability of common sentiment analysis models to open domain human
robot interaction is investigated within this paper. The models are used on a
dataset specific to user interaction with the Alana system (a Alexa prize
system) in order to determine which would be more appropriate for the task of
identifying sentiment when a user interacts with a non-human driven socialbot.
With the identification of a model, various improvements are attempted and
detailed prior to integration into the Alana system. The study showed that a
Random Forest Model with 25 trees trained on the dataset specific to user
interaction with the Alana system combined with the dataset present in NLTK
Vader outperforms other models. The new system (called 'Rob') matches it's
output utterance sentiment with the user's utterance sentiment. This method is
expected to improve user experience because it builds upon the overall
sentiment detection which makes it seem that new system sympathises with user
feelings. Furthermore, the results obtained from the user feedback confirms our
expectation.
</p>
<a href="http://arxiv.org/abs/2101.00675" target="_blank">arXiv:2101.00675</a> [<a href="http://arxiv.org/pdf/2101.00675" target="_blank">pdf</a>]

<h2>Fake Visual Content Detection Using Two-Stream Convolutional Neural Networks. (arXiv:2101.00676v1 [cs.CV])</h2>
<h3>Bilal Yousaf, Muhammad Usama, Waqas Sultani, Arif Mahmood, Junaid Qadir</h3>
<p>Rapid progress in adversarial learning has enabled the generation of
realistic-looking fake visual content. To distinguish between fake and real
visual content, several detection techniques have been proposed. The
performance of most of these techniques however drops off significantly if the
test and the training data are sampled from different distributions. This
motivates efforts towards improving the generalization of fake detectors. Since
current fake content generation techniques do not accurately model the
frequency spectrum of the natural images, we observe that the frequency
spectrum of the fake visual data contains discriminative characteristics that
can be used to detect fake content. We also observe that the information
captured in the frequency spectrum is different from that of the spatial
domain. Using these insights, we propose to complement frequency and spatial
domain features using a two-stream convolutional neural network architecture
called TwoStreamNet. We demonstrate the improved generalization of the proposed
two-stream network to several unseen generation architectures, datasets, and
techniques. The proposed detector has demonstrated significant performance
improvement compared to the current state-of-the-art fake content detectors and
fusing the frequency and spatial domain streams has also improved
generalization of the detector.
</p>
<a href="http://arxiv.org/abs/2101.00676" target="_blank">arXiv:2101.00676</a> [<a href="http://arxiv.org/pdf/2101.00676" target="_blank">pdf</a>]

<h2>An Evolution of CNN Object Classifiers on Low-Resolution Images. (arXiv:2101.00686v1 [cs.CV])</h2>
<h3>Md. Mohsin Kabir, Abu Quwsar Ohi, Md. Saifur Rahman, M. F. Mridha</h3>
<p>Object classification is a significant task in computer vision. It has become
an effective research area as an important aspect of image processing and the
building block of image localization, detection, and scene parsing. Object
classification from low-quality images is difficult for the variance of object
colors, aspect ratios, and cluttered backgrounds. The field of object
classification has seen remarkable advancements, with the development of deep
convolutional neural networks (DCNNs). Deep neural networks have been
demonstrated as very powerful systems for facing the challenge of object
classification from high-resolution images, but deploying such object
classification networks on the embedded device remains challenging due to the
high computational and memory requirements. Using high-quality images often
causes high computational and memory complexity, whereas low-quality images can
solve this issue. Hence, in this paper, we investigate an optimal architecture
that accurately classifies low-quality images using DCNNs architectures. To
validate different baselines on lowquality images, we perform experiments using
webcam captured image datasets of 10 different objects. In this research work,
we evaluate the proposed architecture by implementing popular CNN
architectures. The experimental results validate that the MobileNet
architecture delivers better than most of the available CNN architectures for
low-resolution webcam image datasets.
</p>
<a href="http://arxiv.org/abs/2101.00686" target="_blank">arXiv:2101.00686</a> [<a href="http://arxiv.org/pdf/2101.00686" target="_blank">pdf</a>]

<h2>Enhanced Pub/Sub Communications for Massive IoT Traffic with SARSA Reinforcement Learning. (arXiv:2101.00687v1 [cs.AI])</h2>
<h3>Carlos E. Arruda, Pedro F. Moraes, Nazim Agoulmine, Joberto S. B. Martins</h3>
<p>Sensors are being extensively deployed and are expected to expand at
significant rates in the coming years. They typically generate a large volume
of data on the internet of things (IoT) application areas like smart cities,
intelligent traffic systems, smart grid, and e-health. Cloud, edge and fog
computing are potential and competitive strategies for collecting, processing,
and distributing IoT data. However, cloud, edge, and fog-based solutions need
to tackle the distribution of a high volume of IoT data efficiently through
constrained and limited resource network infrastructures. This paper addresses
the issue of conveying a massive volume of IoT data through a network with
limited communications resources (bandwidth) using a cognitive communications
resource allocation based on Reinforcement Learning (RL) with SARSA algorithm.
The proposed network infrastructure (PSIoTRL) uses a Publish/ Subscribe
architecture to access massive and highly distributed IoT data. It is
demonstrated that the PSIoTRL bandwidth allocation for buffer flushing based on
SARSA enhances the IoT aggregator buffer occupation and network link
utilization. The PSIoTRL dynamically adapts the IoT aggregator traffic flushing
according to the Pub/Sub topic's priority and network constraint requirements.
</p>
<a href="http://arxiv.org/abs/2101.00687" target="_blank">arXiv:2101.00687</a> [<a href="http://arxiv.org/pdf/2101.00687" target="_blank">pdf</a>]

<h2>Learning General Policies from Small Examples Without Supervision. (arXiv:2101.00692v1 [cs.AI])</h2>
<h3>Guillem Franc&#xe8;s, Blai Bonet, Hector Geffner</h3>
<p>Generalized planning is concerned with the computation of general policies
that solve multiple instances of a planning domain all at once. It has been
recently shown that these policies can be computed in two steps: first, a
suitable abstraction in the form of a qualitative numerical planning problem
(QNP) is learned from sample plans, then the general policies are obtained from
the learned QNP using a planner. In this work, we introduce an alternative
approach for computing more expressive general policies which does not require
sample plans or a QNP planner. The new formulation is very simple and can be
cast in terms that are more standard in machine learning: a large but finite
pool of features is defined from the predicates in the planning examples using
a general grammar, and a small subset of features is sought for separating
"good" from "bad" state transitions, and goals from non-goals. The problems of
finding such a "separating surface" while labeling the transitions as "good" or
"bad" are jointly addressed as a single combinatorial optimization problem
expressed as a Weighted Max-SAT problem. The advantage of looking for the
simplest policy in the given feature space that solves the given examples,
possibly non-optimally, is that many domains have no general, compact policies
that are optimal. The approach yields general policies for a number of
benchmark domains.
</p>
<a href="http://arxiv.org/abs/2101.00692" target="_blank">arXiv:2101.00692</a> [<a href="http://arxiv.org/pdf/2101.00692" target="_blank">pdf</a>]

<h2>Neural Networks for Keyword Spotting on IoT Devices. (arXiv:2101.00693v1 [cs.LG])</h2>
<h3>Rakesh Dhakshinamurthy</h3>
<p>We explore Neural Networks (NNs) for keyword spotting (KWS) on IoT devices
like smart speakers and wearables. Since we target to execute our NN on a
constrained memory and computation footprint, we propose a CNN design that. (i)
uses a limited number of multiplies. (ii) uses a limited number of model
parameters.
</p>
<a href="http://arxiv.org/abs/2101.00693" target="_blank">arXiv:2101.00693</a> [<a href="http://arxiv.org/pdf/2101.00693" target="_blank">pdf</a>]

<h2>Cycle Registration in Persistent Homology with Applications in Topological Bootstrap. (arXiv:2101.00698v1 [cs.LG])</h2>
<h3>Yohai Reani, Omer Bobrowski</h3>
<p>In this article we propose a novel approach for comparing the persistent
homology representations of two spaces (filtrations). Commonly used methods are
based on numerical summaries such as persistence diagrams and persistence
landscapes, along with suitable metrics (e.g. Wasserstein). These summaries are
useful for computational purposes, but they are merely a marginal of the actual
topological information that persistent homology can provide. Instead, our
approach compares between two topological representations directly in the data
space. We do so by defining a correspondence relation between individual
persistent cycles of two different spaces, and devising a method for computing
this correspondence. Our matching of cycles is based on both the persistence
intervals and the spatial placement of each feature. We demonstrate our new
framework in the context of topological inference, where we use statistical
bootstrap methods in order to differentiate between real features and noise in
point cloud data.
</p>
<a href="http://arxiv.org/abs/2101.00698" target="_blank">arXiv:2101.00698</a> [<a href="http://arxiv.org/pdf/2101.00698" target="_blank">pdf</a>]

<h2>Automatic Defect Detection of Print Fabric Using Convolutional Neural Network. (arXiv:2101.00703v1 [cs.CV])</h2>
<h3>Samit Chakraborty, Marguerite Moore, Lisa Parrillo-Chapman</h3>
<p>Automatic defect detection is a challenging task because of the variability
in texture and type of fabric defects. An effective defect detection system
enables manufacturers to improve the quality of processes and products.
Automation across the textile manufacturing systems would reduce fabric wastage
and increase profitability by saving cost and resources. There are different
contemporary research on automatic defect detection systems using image
processing and machine learning techniques. These techniques differ from each
other based on the manufacturing processes and defect types. Researchers have
also been able to establish real-time defect detection system during weaving.
Although, there has been research on patterned fabric defect detection, these
defects are related to weaving faults such as holes, and warp and weft defects.
But, there has not been any research that is designed to detect defects that
arise during such as spot and print mismatch. This research has fulfilled this
gap by developing a print fabric database and implementing deep convolutional
neural network (CNN).
</p>
<a href="http://arxiv.org/abs/2101.00703" target="_blank">arXiv:2101.00703</a> [<a href="http://arxiv.org/pdf/2101.00703" target="_blank">pdf</a>]

<h2>Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex. (arXiv:1604.03640v2 [cs.LG] UPDATED)</h2>
<h3>Qianli Liao, Tomaso Poggio</h3>
<p>We discuss relations between Residual Networks (ResNet), Recurrent Neural
Networks (RNNs) and the primate visual cortex. We begin with the observation
that a special type of shallow RNN is exactly equivalent to a very deep ResNet
with weight sharing among the layers. A direct implementation of such a RNN,
although having orders of magnitude fewer parameters, leads to a performance
similar to the corresponding ResNet. We propose 1) a generalization of both RNN
and ResNet architectures and 2) the conjecture that a class of moderately deep
RNNs is a biologically-plausible model of the ventral stream in visual cortex.
We demonstrate the effectiveness of the architectures by testing them on the
CIFAR-10 and ImageNet dataset.
</p>
<a href="http://arxiv.org/abs/1604.03640" target="_blank">arXiv:1604.03640</a> [<a href="http://arxiv.org/pdf/1604.03640" target="_blank">pdf</a>]

<h2>Tutorial on Variational Autoencoders. (arXiv:1606.05908v3 [stat.ML] UPDATED)</h2>
<h3>Carl Doersch</h3>
<p>In just three years, Variational Autoencoders (VAEs) have emerged as one of
the most popular approaches to unsupervised learning of complicated
distributions. VAEs are appealing because they are built on top of standard
function approximators (neural networks), and can be trained with stochastic
gradient descent. VAEs have already shown promise in generating many kinds of
complicated data, including handwritten digits, faces, house numbers, CIFAR
images, physical models of scenes, segmentation, and predicting the future from
static images. This tutorial introduces the intuitions behind VAEs, explains
the mathematics behind them, and describes some empirical behavior. No prior
knowledge of variational Bayesian methods is assumed.
</p>
<a href="http://arxiv.org/abs/1606.05908" target="_blank">arXiv:1606.05908</a> [<a href="http://arxiv.org/pdf/1606.05908" target="_blank">pdf</a>]

<h2>Bayesian Pool-based Active Learning With Abstention Feedbacks. (arXiv:1705.08481v3 [stat.ML] UPDATED)</h2>
<h3>Cuong V. Nguyen, Lam Si Tung Ho, Huan Xu, Vu Dinh, Binh Nguyen</h3>
<p>We study pool-based active learning with abstention feedbacks, where a
labeler can abstain from labeling a queried example with some unknown
abstention rate. This is an important problem with many useful applications. We
take a Bayesian approach to the problem and develop two new greedy algorithms
that learn both the classification problem and the unknown abstention rate at
the same time. These are achieved by simply incorporating the estimated
abstention rate into the greedy criteria. We prove that both of our algorithms
have near-optimality guarantees: they respectively achieve a
${(1-\frac{1}{e})}$ constant factor approximation of the optimal expected or
worst-case value of a useful utility function. Our experiments show the
algorithms perform well in various practical scenarios.
</p>
<a href="http://arxiv.org/abs/1705.08481" target="_blank">arXiv:1705.08481</a> [<a href="http://arxiv.org/pdf/1705.08481" target="_blank">pdf</a>]

<h2>The Tsetlin Machine -- A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic. (arXiv:1804.01508v15 [cs.AI] UPDATED)</h2>
<h3>Ole-Christoffer Granmo</h3>
<p>Although simple individually, artificial neurons provide state-of-the-art
performance when interconnected in deep networks. Arguably, the Tsetlin
Automaton is an even simpler and more versatile learning mechanism, capable of
solving the multi-armed bandit problem. Merely by means of a single integer as
memory, it learns the optimal action in stochastic environments through
increment and decrement operations. In this paper, we introduce the Tsetlin
Machine, which solves complex pattern recognition problems with propositional
formulas, composed by a collective of Tsetlin Automata. To eliminate the
longstanding problem of vanishing signal-to-noise ratio, the Tsetlin Machine
orchestrates the automata using a novel game. Further, both inputs, patterns,
and outputs are expressed as bits, while recognition and learning rely on bit
manipulation, simplifying computation. Our theoretical analysis establishes
that the Nash equilibria of the game align with the propositional formulas that
provide optimal pattern recognition accuracy. This translates to learning
without local optima, only global ones. In five benchmarks, the Tsetlin Machine
provides competitive accuracy compared with SVMs, Decision Trees, Random
Forests, Naive Bayes Classifier, Logistic Regression, and Neural Networks. We
further demonstrate how the propositional formulas facilitate interpretation.
In conclusion, we believe the combination of high accuracy, interpretability,
and computational simplicity makes the Tsetlin Machine a promising tool for a
wide range of domains.
</p>
<a href="http://arxiv.org/abs/1804.01508" target="_blank">arXiv:1804.01508</a> [<a href="http://arxiv.org/pdf/1804.01508" target="_blank">pdf</a>]

<h2>Effective Occlusion Handling for Fast Correlation Filter-based Trackers. (arXiv:1807.04880v3 [cs.CV] UPDATED)</h2>
<h3>Zheng Zhang, T.T. Wong</h3>
<p>Correlation filter-based trackers heavily suffer from the problem of multiple
peaks in their response maps incurred by occlusions. Moreover, the whole
tracking pipeline may break down due to the uncertainties brought by shifting
among peaks, which will further lead to the degraded correlation filter model.
To alleviate the drift problem caused by occlusions, we propose a novel scheme
to choose the specific filter model according to different scenarios.
Specifically, an effective measurement function is designed to evaluate the
quality of filter response. A sophisticated strategy is employed to judge
whether occlusions occur, and then decide how to update the filter models. In
addition, we take advantage of both log-polar method and pyramid-like approach
to estimate the best scale of the target. We evaluate our proposed approach on
VOT2018 challenge and OTB100 dataset, whose experimental result shows that the
proposed tracker achieves the promising performance compared against the
state-of-the-art trackers.
</p>
<a href="http://arxiv.org/abs/1807.04880" target="_blank">arXiv:1807.04880</a> [<a href="http://arxiv.org/pdf/1807.04880" target="_blank">pdf</a>]

<h2>A Robust Color Edge Detection Algorithm Based on Quaternion Hardy Filter. (arXiv:1807.10586v3 [cs.CV] UPDATED)</h2>
<h3>Wenshan Bi Dong Cheng Wankai Liu, Kit Ian Kou</h3>
<p>This paper presents a robust filter called quaternion Hardy filter (QHF) for
color image edge detection. The QHF can be capable of color edge feature
enhancement and noise resistance. It is flexible to use QHF by selecting
suitable parameters to handle different levels of noise. In particular, the
quaternion analytic signal, which is an effective tool in color image
processing, can also be produced by quaternion Hardy filtering with specific
parameters. Based on the QHF and the improved Di Zenzo gradient operator, a
novel color edge detection algorithm is proposed. Importantly, it can be
efficiently implemented by using the fast discrete quaternion Fourier transform
technique. From the experimental results, we conclude that the minimum PSNR
improvement rate is 2.3% and minimum SSIM improvement rate is 30.2% on the
Dataset 3. The experiments demonstrate that the proposed algorithm outperforms
several widely used algorithms.
</p>
<a href="http://arxiv.org/abs/1807.10586" target="_blank">arXiv:1807.10586</a> [<a href="http://arxiv.org/pdf/1807.10586" target="_blank">pdf</a>]

<h2>Nonparametric Inference of Heterogeneous Treatment Effects with Two-Scale Distributional Nearest Neighbors. (arXiv:1808.08469v2 [stat.ML] UPDATED)</h2>
<h3>Emre Demirkaya, Yingying Fan, Lan Gao, Jinchi Lv, Patrick Vossler, Jingbo Wang</h3>
<p>Understanding heterogeneous treatment effects (HTE) plays a key role in many
contemporary causal inference applications arising from different areas. Most
of the existing works have focused on the estimation of HTE. Yet the
statistical inference aspect of the problem remains relatively undeveloped. In
this paper we investigate the inference of HTE in a nonparametric setting for
randomized experiments. We formulate the problem as two separate nonparametric
mean regressions, one for control group and the other for treatment group. For
each mean regression, we extend the tool of $k$-nearest neighbors to the
framework of distributional nearest neighbors (DNN). We show that the DNN
estimator has two equivalent representations of L-statistic and U-statistic,
where the former endorses easy and fast implementation, and the latter enables
us to obtain higher-order asymptotic expansion of bias and establish the
asymptotic normality. To reduce the finite sample bias of DNN, we further
suggest a new method of two-scale distributional nearest neighbors (TDNN).
Under some regularity conditions, we show through delicate higher-order
asymptotic expansions that the TDNN heterogeneous treatment effect estimator is
asymptotically normal. We further establish the consistency of the variance
estimates of the TDNN estimator with both jackknife and bootstrap, enabling
user-friendly inference tools for heterogeneous treatment effects. The
theoretical results and appealing finite-sample performance of the suggested
TDNN method are illustrated with several simulation examples and a children's
birth weight application.
</p>
<a href="http://arxiv.org/abs/1808.08469" target="_blank">arXiv:1808.08469</a> [<a href="http://arxiv.org/pdf/1808.08469" target="_blank">pdf</a>]

<h2>Rethinking Breiman's Dilemma in Neural Networks: Phase Transitions of Margin Dynamics. (arXiv:1810.03389v3 [cs.LG] UPDATED)</h2>
<h3>Weizhi Zhu, Yifei Huang, Yuan Yao</h3>
<p>Margin enlargement over training data has been an important strategy since
perceptrons in machine learning for the purpose of boosting the robustness of
classifiers toward a good generalization ability. Yet Breiman (1999) showed a
dilemma that a uniform improvement on margin distribution does NOT necessarily
reduces generalization errors. In this paper, we revisit Breiman's dilemma in
deep neural networks with recently proposed spectrally normalized margins, from
a novel perspective based on phase transitions of normalized margin
distributions in training dynamics. Normalized margin distribution of a
classifier over the data, can be divided into two parts: low/small margins such
as some negative margins for misclassified samples vs. high/large margins for
high confident correctly classified samples, that often behave differently
during the training process. Low margins for training and test datasets are
often effectively reduced in training, along with reductions of training and
test errors; while high margins may exhibit different dynamics, reflecting the
trade-off between expressive power of models and complexity of data. When data
complexity is comparable to the model expressiveness, high margin distributions
for both training and test data undergo similar decrease-increase phase
transitions during training. In such cases, one can predict the trend of
generalization or test error by margin-based generalization bounds with
restricted Rademacher complexities, shown in two ways in this paper with early
stopping time exploiting such phase transitions. On the other hand,
over-expressive models may have both low and high training margins undergoing
uniform improvements, with a distinct phase transition in test margin dynamics.
This reconfirms the Breiman's dilemma associated with overparameterized neural
networks where margins fail to predict overfitting.
</p>
<a href="http://arxiv.org/abs/1810.03389" target="_blank">arXiv:1810.03389</a> [<a href="http://arxiv.org/pdf/1810.03389" target="_blank">pdf</a>]

<h2>Attention, Please! Adversarial Defense via Attention Rectification and Preservation. (arXiv:1811.09831v3 [cs.CV] UPDATED)</h2>
<h3>Shangxi Wu, Jitao Sang, Kaiyuan Xu, Jiaming Zhang, Yanfeng Sun, Liping Jing, Jian Yu</h3>
<p>This study provides a new understanding of the adversarial attack problem by
examining the correlation between adversarial attack and visual attention
change. In particular, we observed that: (1) images with incomplete attention
regions are more vulnerable to adversarial attacks; and (2) successful
adversarial attacks lead to deviated and scattered attention map. Accordingly,
an attention-based adversarial defense framework is designed to simultaneously
rectify the attention map for prediction and preserve the attention area
between adversarial and original images. The problem of adding iteratively
attacked samples is also discussed in the context of visual attention change.
We hope the attention-related data analysis and defense solution in this study
will shed some light on the mechanism behind the adversarial attack and also
facilitate future adversarial defense/attack model design.
</p>
<a href="http://arxiv.org/abs/1811.09831" target="_blank">arXiv:1811.09831</a> [<a href="http://arxiv.org/pdf/1811.09831" target="_blank">pdf</a>]

<h2>Layer Flexible Adaptive Computational Time. (arXiv:1812.02335v5 [cs.LG] UPDATED)</h2>
<h3>Lida Zhang, Abdolghani Ebrahimi, Diego Klabjan</h3>
<p>Deep recurrent neural networks perform well on sequence data and are the
model of choice. However, it is a daunting task to decide the structure of the
networks, i.e. the number of layers, especially considering different
computational needs of a sequence. We propose a layer flexible recurrent neural
network with adaptive computation time, and expand it to a sequence to sequence
model. Different from the adaptive computation time model, our model has a
dynamic number of transmission states which vary by step and sequence. We
evaluate the model on a financial data set and Wikipedia language modeling.
Experimental results show the performance improvement of 7\% to 12\% and
indicate the model's ability to dynamically change the number of layers along
with the computational steps.
</p>
<a href="http://arxiv.org/abs/1812.02335" target="_blank">arXiv:1812.02335</a> [<a href="http://arxiv.org/pdf/1812.02335" target="_blank">pdf</a>]

<h2>Leveraging Outdoor Webcams for Local Descriptor Learning. (arXiv:1901.09780v2 [cs.CV] UPDATED)</h2>
<h3>Milan Pultar, Dmytro Mishkin, Ji&#x159;&#xed; Matas</h3>
<p>We present AMOS Patches, a large set of image cut-outs, intended primarily
for the robustification of trainable local feature descriptors to illumination
and appearance changes. Images contributing to AMOS Patches originate from the
AMOS dataset of recordings from a large set of outdoor webcams.

The semiautomatic method used to generate AMOS Patches is described. It
includes camera selection, viewpoint clustering and patch selection. For
training, we provide both the registered full source images as well as the
patches.

A new descriptor, trained on the AMOS Patches and 6Brown datasets, is
introduced. It achieves state-of-the-art in matching under illumination changes
on standard benchmarks.
</p>
<a href="http://arxiv.org/abs/1901.09780" target="_blank">arXiv:1901.09780</a> [<a href="http://arxiv.org/pdf/1901.09780" target="_blank">pdf</a>]

<h2>Variational Auto-Decoder: A Method for Neural Generative Modeling from Incomplete Data. (arXiv:1903.00840v6 [cs.LG] UPDATED)</h2>
<h3>Amir Zadeh, Yao-Chong Lim, Paul Pu Liang, Louis-Philippe Morency</h3>
<p>Learning a generative model from partial data (data with missingness) is a
challenging area of machine learning research. We study a specific
implementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, named
in this paper as a Variational Auto-Decoder (VAD). VAD is a generic framework
which uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods to
learn a generative model from partial data. The main distinction between VAD
and Variational Auto-Encoder (VAE) is the encoder component, as VAD does not
have one. Using a proposed efficient inference method from a multivariate
Gaussian approximate posterior, VAD models allow inference to be performed via
simple gradient ascent rather than MCMC sampling from a probabilistic decoder.
This technique reduces the inference computational cost, allows for using more
complex optimization techniques during latent space inference (which are shown
to be crucial due to a high degree of freedom in the VAD latent space), and
keeps the framework simple to implement. Through extensive experiments over
several datasets and different missing ratios, we show that encoders cannot
efficiently marginalize the input volatility caused by imputed missing values.
We study multimodal datasets in this paper, which is a particular area of
impact for VAD models.
</p>
<a href="http://arxiv.org/abs/1903.00840" target="_blank">arXiv:1903.00840</a> [<a href="http://arxiv.org/pdf/1903.00840" target="_blank">pdf</a>]

<h2>Small Data Challenges in Big Data Era: A Survey of Recent Progress on Unsupervised and Semi-Supervised Methods. (arXiv:1903.11260v2 [cs.CV] UPDATED)</h2>
<h3>Guo-Jun Qi, Jiebo Luo</h3>
<p>Representation learning with small labeled data have emerged in many
problems, since the success of deep neural networks often relies on the
availability of a huge amount of labeled data that is expensive to collect. To
address it, many efforts have been made on training sophisticated models with
few labeled data in an unsupervised and semi-supervised fashion. In this paper,
we will review the recent progresses on these two major categories of methods.
A wide spectrum of models will be categorized in a big picture, where we will
show how they interplay with each other to motivate explorations of new ideas.
We will review the principles of learning the transformation equivariant,
disentangled, self-supervised and semi-supervised representations, all of which
underpin the foundation of recent progresses. Many implementations of
unsupervised and semi-supervised generative models have been developed on the
basis of these criteria, greatly expanding the territory of existing
autoencoders, generative adversarial nets (GANs) and other deep networks by
exploring the distribution of unlabeled data for more powerful representations.
We will discuss emerging topics by revealing the intrinsic connections between
unsupervised and semi-supervised learning, and propose in future directions to
bridge the algorithmic and theoretical gap between transformation equivariance
for unsupervised learning and supervised invariance for supervised learning,
and unify unsupervised pretraining and supervised finetuning. We will also
provide a broader outlook of future directions to unify transformation and
instance equivariances for representation learning, connect unsupervised and
semi-supervised augmentations, and explore the role of the self-supervised
regularization for many learning problems.
</p>
<a href="http://arxiv.org/abs/1903.11260" target="_blank">arXiv:1903.11260</a> [<a href="http://arxiv.org/pdf/1903.11260" target="_blank">pdf</a>]

<h2>Multiway clustering via tensor block models. (arXiv:1906.03807v4 [stat.ML] UPDATED)</h2>
<h3>Miaoyan Wang, Yuchen Zeng</h3>
<p>We consider the problem of identifying multiway block structure from a large
noisy tensor. Such problems arise frequently in applications such as genomics,
recommendation system, topic modeling, and sensor network localization. We
propose a tensor block model, develop a unified least-square estimation, and
obtain the theoretical accuracy guarantees for multiway clustering. The
statistical convergence of the estimator is established, and we show that the
associated clustering procedure achieves partition consistency. A sparse
regularization is further developed for identifying important blocks with
elevated means. The proposal handles a broad range of data types, including
binary, continuous, and hybrid observations. Through simulation and application
to two real datasets, we demonstrate the outperformance of our approach over
previous methods.
</p>
<a href="http://arxiv.org/abs/1906.03807" target="_blank">arXiv:1906.03807</a> [<a href="http://arxiv.org/pdf/1906.03807" target="_blank">pdf</a>]

<h2>IR-VIC: Unsupervised Discovery of Sub-goals for Transfer in RL. (arXiv:1907.10580v5 [cs.LG] UPDATED)</h2>
<h3>Nirbhay Modhe, Prithvijit Chattopadhyay, Mohit Sharma, Abhishek Das, Devi Parikh, Dhruv Batra, Ramakrishna Vedantam</h3>
<p>We propose a novel framework to identify sub-goals useful for exploration in
sequential decision making tasks under partial observability. We utilize the
variational intrinsic control framework (Gregor et.al., 2016) which maximizes
empowerment -- the ability to reliably reach a diverse set of states and show
how to identify sub-goals as states with high necessary option information
through an information theoretic regularizer. Despite being discovered without
explicit goal supervision, our sub-goals provide better exploration and sample
complexity on challenging grid-world navigation tasks compared to supervised
counterparts in prior work.
</p>
<a href="http://arxiv.org/abs/1907.10580" target="_blank">arXiv:1907.10580</a> [<a href="http://arxiv.org/pdf/1907.10580" target="_blank">pdf</a>]

<h2>Information Aware Max-Norm Dirichlet Networks for Predictive Uncertainty Estimation. (arXiv:1910.04819v4 [cs.LG] UPDATED)</h2>
<h3>Theodoros Tsiligkaridis</h3>
<p>Precise estimation of uncertainty in predictions for AI systems is a critical
factor in ensuring trust and safety. Deep neural networks trained with a
conventional method are prone to over-confident predictions. In contrast to
Bayesian neural networks that learn approximate distributions on weights to
infer prediction confidence, we propose a novel method, Information Aware
Dirichlet networks, that learn an explicit Dirichlet prior distribution on
predictive distributions by minimizing a bound on the expected max norm of the
prediction error and penalizing information associated with incorrect outcomes.
Properties of the new cost function are derived to indicate how improved
uncertainty estimation is achieved. Experiments using real datasets show that
our technique outperforms, by a large margin, state-of-the-art neural networks
for estimating within-distribution and out-of-distribution uncertainty, and
detecting adversarial examples.
</p>
<a href="http://arxiv.org/abs/1910.04819" target="_blank">arXiv:1910.04819</a> [<a href="http://arxiv.org/pdf/1910.04819" target="_blank">pdf</a>]

<h2>Fast Exact Matrix Completion: A Unified Optimization Framework for Matrix Completion. (arXiv:1910.09092v2 [cs.LG] UPDATED)</h2>
<h3>Dimitris Bertsimas, Michael Lingzhi Li</h3>
<p>We formulate the problem of matrix completion with and without side
information as a non-convex optimization problem. We design fastImpute based on
non-convex gradient descent and show it converges to a global minimum that is
guaranteed to recover closely the underlying matrix while it scales to matrices
of sizes beyond $10^5 \times 10^5$. We report experiments on both synthetic and
real-world datasets that show fastImpute is competitive in both the accuracy of
the matrix recovered and the time needed across all cases. Furthermore, when a
high number of entries are missing, fastImpute is over $75\%$ lower in MAPE and
$15$ times faster than current state-of-the-art matrix completion methods in
both the case with side information and without.
</p>
<a href="http://arxiv.org/abs/1910.09092" target="_blank">arXiv:1910.09092</a> [<a href="http://arxiv.org/pdf/1910.09092" target="_blank">pdf</a>]

<h2>Revisiting Shadow Detection: A New Benchmark Dataset for Complex World. (arXiv:1911.06998v3 [cs.CV] UPDATED)</h2>
<h3>Xiaowei Hu, Tianyu Wang, Chi-Wing Fu, Yitong Jiang, Qiong Wang, Pheng-Ann Heng</h3>
<p>Shadow detection in general photos is a nontrivial problem, due to the
complexity of the real world. Though recent shadow detectors have already
achieved remarkable performance on various benchmark data, their performance is
still limited for general real-world situations. In this work, we collected
shadow images for multiple scenarios and compiled a new dataset of 10,500
shadow images, each with labeled ground-truth mask, for supporting shadow
detection in the complex world. Our dataset covers a rich variety of scene
categories, with diverse shadow sizes, locations, contrasts, and types.
Further, we comprehensively analyze the complexity of the dataset, present a
fast shadow detection network with a detail enhancement module to harvest
shadow details, and demonstrate the effectiveness of our method to detect
shadows in general situations.
</p>
<a href="http://arxiv.org/abs/1911.06998" target="_blank">arXiv:1911.06998</a> [<a href="http://arxiv.org/pdf/1911.06998" target="_blank">pdf</a>]

<h2>Deep Verifier Networks: Verification of Deep Discriminative Models with Deep Generative Models. (arXiv:1911.07421v3 [cs.CV] UPDATED)</h2>
<h3>Tong Che, Xiaofeng Liu, Site Li, Yubin Ge, Ruixiang Zhang, Caiming Xiong, Yoshua Bengio</h3>
<p>AI Safety is a major concern in many deep learning applications such as
autonomous driving. Given a trained deep learning model, an important natural
problem is how to reliably verify the model's prediction. In this paper, we
propose a novel framework -- deep verifier networks (DVN) to verify the inputs
and outputs of deep discriminative models with deep generative models. Our
proposed model is based on conditional variational auto-encoders with
disentanglement constraints. We give both intuitive and theoretical
justifications of the model. Our verifier network is trained independently with
the prediction model, which eliminates the need of retraining the verifier
network for a new model. We test the verifier network on out-of-distribution
detection and adversarial example detection problems, as well as anomaly
detection problems in structured prediction tasks such as image caption
generation. We achieve state-of-the-art results in all of these problems.
</p>
<a href="http://arxiv.org/abs/1911.07421" target="_blank">arXiv:1911.07421</a> [<a href="http://arxiv.org/pdf/1911.07421" target="_blank">pdf</a>]

<h2>A Novel Visual Fault Detection and Classification System for Semiconductor Manufacturing Using Stacked Hybrid Convolutional Neural Networks. (arXiv:1911.11250v4 [cs.LG] UPDATED)</h2>
<h3>Tobias Schlosser, Frederik Beuth, Michael Friedrich, Danny Kowerko</h3>
<p>Automated visual inspection in the semiconductor industry aims to detect and
classify manufacturing defects utilizing modern image processing techniques.
While an earliest possible detection of defect patterns allows quality control
and automation of manufacturing chains, manufacturers benefit from an increased
yield and reduced manufacturing costs. Since classical image processing systems
are limited in their ability to detect novel defect patterns, and machine
learning approaches often involve a tremendous amount of computational effort,
this contribution introduces a novel deep neural network-based hybrid approach.
Unlike classical deep neural networks, a multi-stage system allows the
detection and classification of the finest structures in pixel size within
high-resolution imagery. Consisting of stacked hybrid convolutional neural
networks (SH-CNN) and inspired by current approaches of visual attention, the
realized system draws the focus over the level of detail from its structures to
more task-relevant areas of interest. The results of our test environment show
that the SH-CNN outperforms current approaches of learning-based automated
visual inspection, whereas a distinction depending on the level of detail
enables the elimination of defect patterns in earlier stages of the
manufacturing process.
</p>
<a href="http://arxiv.org/abs/1911.11250" target="_blank">arXiv:1911.11250</a> [<a href="http://arxiv.org/pdf/1911.11250" target="_blank">pdf</a>]

<h2>Hexagonal Image Processing in the Context of Machine Learning: Conception of a Biologically Inspired Hexagonal Deep Learning Framework. (arXiv:1911.11251v6 [cs.LG] UPDATED)</h2>
<h3>Tobias Schlosser, Michael Friedrich, Danny Kowerko</h3>
<p>Inspired by the human visual perception system, hexagonal image processing in
the context of machine learning deals with the development of image processing
systems that combine the advantages of evolutionary motivated structures based
on biological models. While conventional state of the art image processing
systems of recording and output devices almost exclusively utilize square
arranged methods, their hexagonal counterparts offer a number of key advantages
that can benefit both researchers and users. This contribution serves as a
general application-oriented approach the synthesis of the therefore designed
hexagonal image processing framework, called Hexnet, the processing steps of
hexagonal image transformation, and dependent methods. The results of our
created test environment show that the realized framework surpasses current
approaches of hexagonal image processing systems, while hexagonal artificial
neural networks can benefit from the implemented hexagonal architecture. As
hexagonal lattice format based deep neural networks, also called H-DNN, can be
compared to their square counterparts by transforming classical square lattice
based data sets into their hexagonal representation, they can also result in a
reduction of trainable parameters as well as result in increased training and
test rates.
</p>
<a href="http://arxiv.org/abs/1911.11251" target="_blank">arXiv:1911.11251</a> [<a href="http://arxiv.org/pdf/1911.11251" target="_blank">pdf</a>]

<h2>Learning Structured Representations of Spatial and Interactive Dynamics for Trajectory Prediction in Crowded Scenes. (arXiv:1911.13044v6 [cs.LG] UPDATED)</h2>
<h3>Todor Davchev, Michael Burke, Subramanian Ramamoorthy</h3>
<p>Context plays a significant role in the generation of motion for dynamic
agents in interactive environments. This work proposes a modular method that
utilises a learned model of the environment for motion prediction. This
modularity explicitly allows for unsupervised adaptation of trajectory
prediction models to unseen environments and new tasks by relying on unlabelled
image data only. We model both the spatial and dynamic aspects of a given
environment alongside the per agent motions. This results in more informed
motion prediction and allows for performance comparable to the
state-of-the-art. We highlight the model's prediction capability using a
benchmark pedestrian prediction problem and a robot manipulation task and show
that we can transfer the predictor across these tasks in a completely
unsupervised way. The proposed approach allows for robust and label efficient
forward modelling, and relaxes the need for full model re-training in new
environments.
</p>
<a href="http://arxiv.org/abs/1911.13044" target="_blank">arXiv:1911.13044</a> [<a href="http://arxiv.org/pdf/1911.13044" target="_blank">pdf</a>]

<h2>GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural Network Representation of AIS Tracks and A Contrario Detection. (arXiv:1912.00682v2 [cs.LG] UPDATED)</h2>
<h3>Duong Nguyen, Rodolphe Vadaine, Guillaume Hajduch, Ren&#xe9; Garello, Ronan Fablet</h3>
<p>Representing maritime traffic patterns and detecting anomalies from them are
key to vessel monitoring and maritime situational awareness. We propose a novel
approach -- referred to as GeoTrackNet -- for maritime anomaly detection from
AIS data streams. Our model exploits state-of-the-art neural network schemes to
learn a probabilistic representation of AIS tracks, then uses a contrario
detection to detect abnormal events. The neural network helps us capture
complex and heterogeneous patterns in vessels' behaviors, while the a contrario
detector takes into account the fact that the learned distribution may be
location-dependent. Experiments on a real AIS dataset comprising more than 4.2
million AIS messages demonstrate the relevance of the proposed method.

Keywords: AIS, maritime surveillance, deep learning, anomaly detection,
variational recurrent neural networks, a contrario detection.
</p>
<a href="http://arxiv.org/abs/1912.00682" target="_blank">arXiv:1912.00682</a> [<a href="http://arxiv.org/pdf/1912.00682" target="_blank">pdf</a>]

<h2>SketchZooms: Deep multi-view descriptors for matching line drawings. (arXiv:1912.05019v2 [cs.CV] UPDATED)</h2>
<h3>Pablo Navarro, Jos&#xe9; Ignacio Orlando, Claudio Delrieux, Emmanuel Iarussi</h3>
<p>Finding point-wise correspondences between images is a long-standing problem
in image analysis. This becomes particularly challenging for sketch images, due
to the varying nature of human drawing style, projection distortions and
viewport changes. In this paper we present the first attempt to obtain a
learned descriptor for dense registration in line drawings. Based on recent
deep learning techniques for corresponding photographs, we designed descriptors
to locally match image pairs where the object of interest belongs to the same
semantic category, yet still differ drastically in shape, form, and projection
angle. To this end, we have specifically crafted a data set of synthetic
sketches using non-photorealistic rendering over a large collection of
part-based registered 3D models. After training, a neural network generates
descriptors for every pixel in an input image, which are shown to generalize
correctly in unseen sketches hand-drawn by humans. We evaluate our method
against a baseline of correspondences data collected from expert designers, in
addition to comparisons with other descriptors that have been proven effective
in sketches. Code, data and further resources will be publicly released by the
time of publication.
</p>
<a href="http://arxiv.org/abs/1912.05019" target="_blank">arXiv:1912.05019</a> [<a href="http://arxiv.org/pdf/1912.05019" target="_blank">pdf</a>]

<h2>Towards Contextual Learning in Few-shot Object Classification. (arXiv:1912.06679v3 [cs.CV] UPDATED)</h2>
<h3>Mathieu Pag&#xe9; Fortin, Brahim Chaib-draa</h3>
<p>Few-shot Learning (FSL) aims to classify new concepts from a small number of
examples. While there have been an increasing amount of work on few-shot object
classification in the last few years, most current approaches are limited to
images with only one centered object. On the opposite, humans are able to
leverage prior knowledge to quickly learn new concepts, such as semantic
relations with contextual elements. Inspired by the concept of contextual
learning in educational sciences, we propose to make a step towards adopting
this principle in FSL by studying the contribution that context can have in
object classification in a low-data regime. To this end, we first propose an
approach to perform FSL on images of complex scenes. We develop two
plug-and-play modules that can be incorporated into existing FSL methods to
enable them to leverage contextual learning. More specifically, these modules
are trained to weight the most important context elements while learning a
particular concept, and then use this knowledge to ground visual class
representations in context semantics. Extensive experiments on Visual Genome
and Open Images show the superiority of contextual learning over learning
individual objects in isolation.
</p>
<a href="http://arxiv.org/abs/1912.06679" target="_blank">arXiv:1912.06679</a> [<a href="http://arxiv.org/pdf/1912.06679" target="_blank">pdf</a>]

<h2>Online Reinforcement Learning of Optimal Threshold Policies for Markov Decision Processes. (arXiv:1912.10325v2 [cs.LG] UPDATED)</h2>
<h3>Arghyadip Roy, Vivek Borkar, Abhay Karandikar, Prasanna Chaporkar</h3>
<p>Markov Decision Process (MDP) problems can be solved using Dynamic
Programming (DP) methods which suffer from the curse of dimensionality and the
curse of modeling. To overcome these issues, Reinforcement Learning (RL)
methods are adopted in practice. In this paper, we aim to obtain the optimal
admission control policy in a system where different classes of customers are
present. Using DP techniques, we prove that it is optimal to admit the $i$ th
class of customers only upto a threshold $\tau(i)$ which is a non-increasing
function of $i$. Contrary to traditional RL algorithms which do not take into
account the structural properties of the optimal policy while learning, we
propose a structure-aware learning algorithm which exploits the threshold
structure of the optimal policy. We prove the asymptotic convergence of the
proposed algorithm to the optimal policy. Due to the reduction in the policy
space, the structure-aware learning algorithm provides remarkable improvements
in storage and computational complexities over classical RL algorithms.
Simulation results also establish the gain in the convergence rate of the
proposed algorithm over other RL algorithms. The techniques presented in the
paper can be applied to any general MDP problem covering various applications
such as inventory management, financial planning and communication networking.
</p>
<a href="http://arxiv.org/abs/1912.10325" target="_blank">arXiv:1912.10325</a> [<a href="http://arxiv.org/pdf/1912.10325" target="_blank">pdf</a>]

<h2>Fractional order graph neural network. (arXiv:2001.04026v2 [cs.LG] UPDATED)</h2>
<h3>Zijian Liu, Chunbo Luo, Shuai Li, Peng Ren, Geyong Min</h3>
<p>This paper proposes fractional order graph neural networks (FGNNs), optimized
by the approximation strategy to address the challenges of local optimum of
classic and fractional graph neural networks which are specialised at
aggregating information from the feature and adjacent matrices of connected
nodes and their neighbours to solve learning tasks on non-Euclidean data such
as graphs. Meanwhile the approximate calculation of fractional order gradients
also overcomes the high computational complexity of fractional order
derivations. We further prove that such an approximation is feasible and the
FGNN is unbiased towards global optimization solution. Extensive experiments on
citation networks show that FGNN achieves great advantage over baseline models
when selected appropriate fractional order.
</p>
<a href="http://arxiv.org/abs/2001.04026" target="_blank">arXiv:2001.04026</a> [<a href="http://arxiv.org/pdf/2001.04026" target="_blank">pdf</a>]

<h2>AutoLR: Layer-wise Pruning and Auto-tuning of Learning Rates in Fine-tuning of Deep Networks. (arXiv:2002.06048v3 [cs.CV] UPDATED)</h2>
<h3>Youngmin Ro, Jin Young Choi</h3>
<p>Existing fine-tuning methods use a single learning rate over all layers. In
this paper, first, we discuss that trends of layer-wise weight variations by
fine-tuning using a single learning rate do not match the well-known notion
that lower-level layers extract general features and higher-level layers
extract specific features. Based on our discussion, we propose an algorithm
that improves fine-tuning performance and reduces network complexity through
layer-wise pruning and auto-tuning of layer-wise learning rates. The proposed
algorithm has verified the effectiveness by achieving state-of-the-art
performance on the image retrieval benchmark datasets (CUB-200, Cars-196,
Stanford online product, and Inshop). Code is available at
https://github.com/youngminPIL/AutoLR.
</p>
<a href="http://arxiv.org/abs/2002.06048" target="_blank">arXiv:2002.06048</a> [<a href="http://arxiv.org/pdf/2002.06048" target="_blank">pdf</a>]

<h2>Panoptic Feature Fusion Net: A Novel Instance Segmentation Paradigm for Biomedical and Biological Images. (arXiv:2002.06345v2 [cs.CV] UPDATED)</h2>
<h3>Dongnan Liu, Donghao Zhang, Yang Song, Heng Huang, Weidong Cai</h3>
<p>Instance segmentation is an important task for biomedical and biological
image analysis. Due to the complicated background components, the high
variability of object appearances, numerous overlapping objects, and ambiguous
object boundaries, this task still remains challenging. Recently, deep learning
based methods have been widely employed to solve these problems and can be
categorized into proposal-free and proposal-based methods. However, both
proposal-free and proposal-based methods suffer from information loss, as they
focus on either global-level semantic or local-level instance features. To
tackle this issue, we present a Panoptic Feature Fusion Net (PFFNet) that
unifies the semantic and instance features in this work. Specifically, our
proposed PFFNet contains a residual attention feature fusion mechanism to
incorporate the instance prediction with the semantic features, in order to
facilitate the semantic contextual information learning in the instance branch.
Then, a mask quality sub-branch is designed to align the confidence score of
each object with the quality of the mask prediction. Furthermore, a consistency
regularization mechanism is designed between the semantic segmentation tasks in
the semantic and instance branches, for the robust learning of both tasks.
Extensive experiments demonstrate the effectiveness of our proposed PFFNet,
which outperforms several state-of-the-art methods on various biomedical and
biological datasets.
</p>
<a href="http://arxiv.org/abs/2002.06345" target="_blank">arXiv:2002.06345</a> [<a href="http://arxiv.org/pdf/2002.06345" target="_blank">pdf</a>]

<h2>Certified Defense to Image Transformations via Randomized Smoothing. (arXiv:2002.12463v3 [cs.LG] UPDATED)</h2>
<h3>Marc Fischer, Maximilian Baader, Martin Vechev</h3>
<p>We extend randomized smoothing to cover parameterized transformations (e.g.,
rotations, translations) and certify robustness in the parameter space (e.g.,
rotation angle). This is particularly challenging as interpolation and rounding
effects mean that image transformations do not compose, in turn preventing
direct certification of the perturbed image (unlike certification with $\ell^p$
norms). We address this challenge by introducing three different defenses, each
with a different guarantee (heuristic, distributional and individual) stemming
from the method used to bound the interpolation error. Importantly, in the
individual case, we show how to efficiently compute the inverse of an image
transformation, enabling us to provide individual guarantees in the online
setting. We provide an implementation of all methods at
https://github.com/eth-sri/transformation-smoothing.
</p>
<a href="http://arxiv.org/abs/2002.12463" target="_blank">arXiv:2002.12463</a> [<a href="http://arxiv.org/pdf/2002.12463" target="_blank">pdf</a>]

<h2>Policy-Aware Model Learning for Policy Gradient Methods. (arXiv:2003.00030v2 [cs.AI] UPDATED)</h2>
<h3>Romina Abachi, Mohammad Ghavamzadeh, Amir-massoud Farahmand</h3>
<p>This paper considers the problem of learning a model in model-based
reinforcement learning (MBRL). We examine how the planning module of an MBRL
algorithm uses the model, and propose that the model learning module should
incorporate the way the planner is going to use the model. This is in contrast
to conventional model learning approaches, such as those based on maximum
likelihood estimate, that learn a predictive model of the environment without
explicitly considering the interaction of the model and the planner. We focus
on policy gradient type of planning algorithms and derive new loss functions
for model learning that incorporate how the planner uses the model. We call
this approach Policy-Aware Model Learning (PAML). We theoretically analyze a
generic model-based policy gradient algorithm and provide a convergence
guarantee for the optimized policy. We also empirically evaluate PAML on some
benchmark problems, showing promising results.
</p>
<a href="http://arxiv.org/abs/2003.00030" target="_blank">arXiv:2003.00030</a> [<a href="http://arxiv.org/pdf/2003.00030" target="_blank">pdf</a>]

<h2>Selecting and Designing Grippers for an Assembly Task in a Structured Approach. (arXiv:2003.04087v3 [cs.RO] UPDATED)</h2>
<h3>Jingren Xu, Weiwei Wan, Keisuke Koyama, Yukiyasu Domae, Kensuke Harada</h3>
<p>In this paper, we present a structured approach to selecting and designing a
set of grippers for an assembly task. Compared to current experience-based
gripper design method, our approach accelerates the design process by
automatically generating a set of initial design options on gripper type and
parameters according to the CAD models of assembly components. We use mesh
segmentation techniques to segment the assembly components and fit the
segmented parts with shape primitives, according to the predefined
correspondence between primitive shape and gripper type, suitable gripper types
and parameters can be selected and extracted from the fitted shape primitives.
Moreover, we incorporate the assembly constraints in the further evaluation of
the initially obtained gripper types and parameters. Considering the affordance
of the segmented parts and the collision avoidance between the gripper and the
subassemblies, applicable gripper types and parameters can be filtered from the
initial options. Among the applicable gripper configurations, we further
optimize number of grippers for performing the assembly task, by exploring the
gripper that is able to handle multiple assembly components during the
assembly. Finally, the feasibility of the designed grippers is experimentally
verified by assembling a part of an industrial product.
</p>
<a href="http://arxiv.org/abs/2003.04087" target="_blank">arXiv:2003.04087</a> [<a href="http://arxiv.org/pdf/2003.04087" target="_blank">pdf</a>]

<h2>Improving the Backpropagation Algorithm with Consequentialism Weight Updates over Mini-Batches. (arXiv:2003.05164v2 [cs.LG] UPDATED)</h2>
<h3>Naeem Paeedeh, Kamaledin Ghiasi-Shirazi</h3>
<p>Many attempts took place to improve the adaptive filters that can also be
useful to improve backpropagation (BP). Normalized least mean squares (NLMS) is
one of the most successful algorithms derived from Least mean squares (LMS).
However, its extension to multi-layer neural networks has not happened before.
Here, we first show that it is possible to consider a multi-layer neural
network as a stack of adaptive filters. Additionally, we introduce more
comprehensible interpretations of NLMS than the complicated geometric
interpretation in affine projection algorithm (APA) for a single
fully-connected (FC) layer that can easily be generalized to, for instance,
convolutional neural networks and also works better with mini-batch training.
With this new viewpoint, we introduce a better algorithm by predicting then
emending the adverse consequences of the actions that take place in BP even
before they happen. Finally, the proposed method is compatible with stochastic
gradient descent (SGD) and applicable to momentum-based derivatives such as
RMSProp, Adam, and NAG. Our experiments show the usefulness of our algorithm in
the training of deep neural networks.
</p>
<a href="http://arxiv.org/abs/2003.05164" target="_blank">arXiv:2003.05164</a> [<a href="http://arxiv.org/pdf/2003.05164" target="_blank">pdf</a>]

<h2>Unsupervised Anomaly Detection with Adversarial Mirrored AutoEncoders. (arXiv:2003.10713v3 [cs.LG] UPDATED)</h2>
<h3>Gowthami Somepalli, Yexin Wu, Yogesh Balaji, Bhanukiran Vinzamuri, Soheil Feizi</h3>
<p>Detecting out of distribution (OOD) samples is of paramount importance in all
Machine Learning applications. Deep generative modeling has emerged as a
dominant paradigm to model complex data distributions without labels. However,
prior work has shown that generative models tend to assign higher likelihoods
to OOD samples compared to the data distribution on which they were trained.
First, we propose Adversarial Mirrored Autoencoder (AMA), a variant of
Adversarial Autoencoder, which uses a mirrored Wasserstein loss in the
discriminator to enforce better semantic-level reconstruction. We also propose
a latent space regularization to learn a compact manifold for in-distribution
samples. The use of AMA produces better feature representations that improve
anomaly detection performance. Second, we put forward an alternative measure of
anomaly score to replace the reconstruction-based metric which has been
traditionally used in generative model-based anomaly detection methods. Our
method outperforms the current state-of-the-art methods for anomaly detection
on several OOD detection benchmarks.
</p>
<a href="http://arxiv.org/abs/2003.10713" target="_blank">arXiv:2003.10713</a> [<a href="http://arxiv.org/pdf/2003.10713" target="_blank">pdf</a>]

<h2>Dimension Independent Generalization Error by Stochastic Gradient Descent. (arXiv:2003.11196v2 [stat.ML] UPDATED)</h2>
<h3>Xi Chen, Qiang Liu, Xin T. Tong</h3>
<p>One classical canon of statistics is that large models are prone to
overfitting, and model selection procedures are necessary for high dimensional
data. However, many overparameterized models, such as neural networks, perform
very well in practice, although they are often trained with simple online
methods and regularization. The empirical success of overparameterized models,
which is often known as benign overfitting, motivates us to have a new look at
the statistical generalization theory for online optimization. In particular,
we present a general theory on the generalization error of stochastic gradient
descent (SGD) solutions for both convex and locally convex loss functions. We
further discuss data and model conditions that lead to a ``low effective
dimension". Under these conditions, we show that the generalization error
either does not depend on the ambient dimension $p$ or depends on $p$ via a
poly-logarithmic factor. We also demonstrate that in several widely used
statistical models, the ``low effective dimension'' arises naturally in
overparameterized settings. The studied statistical applications include both
convex models such as linear regression and logistic regression and non-convex
models such as $M$-estimator and two-layer neural networks.
</p>
<a href="http://arxiv.org/abs/2003.11196" target="_blank">arXiv:2003.11196</a> [<a href="http://arxiv.org/pdf/2003.11196" target="_blank">pdf</a>]

<h2>Neural Architecture Generator Optimization. (arXiv:2004.01395v3 [cs.LG] UPDATED)</h2>
<h3>Binxin Ru, Pedro Esperanca, Fabio Carlucci</h3>
<p>Neural Architecture Search (NAS) was first proposed to achieve
state-of-the-art performance through the discovery of new architecture
patterns, without human intervention. An over-reliance on expert knowledge in
the search space design has however led to increased performance (local optima)
without significant architectural breakthroughs, thus preventing truly novel
solutions from being reached. In this work we 1) are the first to investigate
casting NAS as a problem of finding the optimal network generator and 2) we
propose a new, hierarchical and graph-based search space capable of
representing an extremely large variety of network types, yet only requiring
few continuous hyper-parameters. This greatly reduces the dimensionality of the
problem, enabling the effective use of Bayesian Optimisation as a search
strategy. At the same time, we expand the range of valid architectures,
motivating a multi-objective learning approach. We demonstrate the
effectiveness of this strategy on six benchmark datasets and show that our
search space generates extremely lightweight yet highly competitive models.
</p>
<a href="http://arxiv.org/abs/2004.01395" target="_blank">arXiv:2004.01395</a> [<a href="http://arxiv.org/pdf/2004.01395" target="_blank">pdf</a>]

<h2>Estimate of the Neural Network Dimension using Algebraic Topology and Lie Theory. (arXiv:2004.02881v11 [stat.ML] UPDATED)</h2>
<h3>Luciano Melodia, Richard Lenz</h3>
<p>In this paper we present an approach to determine the smallest possible
number of neurons in a layer of a neural network in such a way that the
topology of the input space can be learned sufficiently well. We introduce a
general procedure based on persistent homology to investigate topological
invariants of the manifold on which we suspect the data set. We specify the
required dimensions precisely, assuming that there is a smooth manifold on or
near which the data are located. Furthermore, we require that this space is
connected and has a commutative group structure in the mathematical sense.
These assumptions allow us to derive a decomposition of the underlying space
whose topology is well known. We use the representatives of the $k$-dimensional
homology groups from the persistence landscape to determine an integer
dimension for this decomposition. This number is the dimension of the embedding
that is capable of capturing the topology of the data manifold. We derive the
theory and validate it experimentally on toy data sets.
</p>
<a href="http://arxiv.org/abs/2004.02881" target="_blank">arXiv:2004.02881</a> [<a href="http://arxiv.org/pdf/2004.02881" target="_blank">pdf</a>]

<h2>End-to-end Learning Improves Static Object Geo-localization in Monocular Video. (arXiv:2004.05232v4 [cs.CV] UPDATED)</h2>
<h3>Mohamed Chaabane, Lionel Gueguen, Ameni Trabelsi, Ross Beveridge, Stephen O&#x27;Hara</h3>
<p>Accurately estimating the position of static objects, such as traffic lights,
from the moving camera of a self-driving car is a challenging problem. In this
work, we present a system that improves the localization of static objects by
jointly-optimizing the components of the system via learning. Our system is
comprised of networks that perform: 1) 5DoF object pose estimation from a
single image, 2) association of objects between pairs of frames, and 3)
multi-object tracking to produce the final geo-localization of the static
objects within the scene. We evaluate our approach using a publicly-available
data set, focusing on traffic lights due to data availability. For each
component, we compare against contemporary alternatives and show
significantly-improved performance. We also show that the end-to-end system
performance is further improved via joint-training of the constituent models.
</p>
<a href="http://arxiv.org/abs/2004.05232" target="_blank">arXiv:2004.05232</a> [<a href="http://arxiv.org/pdf/2004.05232" target="_blank">pdf</a>]

<h2>Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep Learning via Neural Architecture Search. (arXiv:2004.08546v4 [cs.LG] UPDATED)</h2>
<h3>Chaoyang He, Murali Annavaram, Salman Avestimehr</h3>
<p>Federated Learning (FL) has been proved to be an effective learning framework
when data cannot be centralized due to privacy, communication costs, and
regulatory restrictions. When training deep learning models under an FL
setting, people employ the predefined model architecture discovered in the
centralized environment. However, this predefined architecture may not be the
optimal choice because it may not fit data with non-identical and independent
distribution (non-IID). Thus, we advocate automating federated learning
(AutoFL) to improve model accuracy and reduce the manual design effort. We
specifically study AutoFL via Neural Architecture Search (NAS), which can
automate the design process. We propose a Federated NAS (FedNAS) algorithm to
help scattered workers collaboratively searching for a better architecture with
higher accuracy. We also build a system based on FedNAS. Our experiments on
non-IID dataset show that the architecture searched by FedNAS can outperform
the manually predefined architecture.
</p>
<a href="http://arxiv.org/abs/2004.08546" target="_blank">arXiv:2004.08546</a> [<a href="http://arxiv.org/pdf/2004.08546" target="_blank">pdf</a>]

<h2>Energy-Based Imitation Learning. (arXiv:2004.09395v3 [cs.LG] UPDATED)</h2>
<h3>Minghuan Liu, Tairan He, Minkai Xu, Weinan Zhang</h3>
<p>We tackle a common scenario in imitation learning (IL), where agents try to
recover the optimal policy from expert demonstrations without further access to
the expert or environment reward signals. Except the simple Behavior Cloning
(BC) that adopts supervised learning followed by the problem of compounding
error, previous solutions like inverse reinforcement learning (IRL) and recent
generative adversarial methods involve a bi-level or alternating optimization
for updating the reward function and the policy, suffering from high
computational cost and training instability. Inspired by recent progress in
energy-based model (EBM), in this paper, we propose a simplified IL framework
named Energy-Based Imitation Learning (EBIL). Instead of updating the reward
and policy iteratively, EBIL breaks out of the traditional IRL paradigm by a
simple and flexible two-stage solution: first estimating the expert energy as
the surrogate reward function through score matching, then utilizing such a
reward for learning the policy by reinforcement learning algorithms. EBIL
combines the idea of both EBM and occupancy measure matching, and via theoretic
analysis we reveal that EBIL and Max-Entropy IRL (MaxEnt IRL) approaches are
two sides of the same coin, and thus EBIL could be an alternative of
adversarial IRL methods. Extensive experiments on qualitative and quantitative
evaluations indicate that EBIL is able to recover meaningful and interpretative
reward signals while achieving effective and comparable performance against
existing algorithms on IL benchmarks.
</p>
<a href="http://arxiv.org/abs/2004.09395" target="_blank">arXiv:2004.09395</a> [<a href="http://arxiv.org/pdf/2004.09395" target="_blank">pdf</a>]

<h2>A Dual-Dimer Method for Training Physics-Constrained Neural Networks with Minimax Architecture. (arXiv:2005.00615v2 [cs.LG] UPDATED)</h2>
<h3>Dehao Liu, Yan Wang</h3>
<p>Data sparsity is a common issue to train machine learning tools such as
neural networks for engineering and scientific applications, where experiments
and simulations are expensive. Recently physics-constrained neural networks
(PCNNs) were developed to reduce the required amount of training data. However,
the weights of different losses from data and physical constraints are adjusted
empirically in PCNNs. In this paper, a new physics-constrained neural network
with the minimax architecture (PCNN-MM) is proposed so that the weights of
different losses can be adjusted systematically. The training of the PCNN-MM is
searching the high-order saddle points of the objective function. A novel
saddle point search algorithm called Dual-Dimer method is developed. It is
demonstrated that the Dual-Dimer method is computationally more efficient than
the gradient descent ascent method for nonconvex-nonconcave functions and
provides additional eigenvalue information to verify search results. A heat
transfer example also shows that the convergence of PCNN-MMs is faster than
that of traditional PCNNs.
</p>
<a href="http://arxiv.org/abs/2005.00615" target="_blank">arXiv:2005.00615</a> [<a href="http://arxiv.org/pdf/2005.00615" target="_blank">pdf</a>]

<h2>ForecastQA: A Question Answering Challenge for Event Forecasting. (arXiv:2005.00792v3 [cs.LG] UPDATED)</h2>
<h3>Woojeong Jin, Suji Kim, Rahul Khanna, Dong-Ho Lee, Fred Morstatter, Aram Galstyan, Xiang Ren</h3>
<p>Event forecasting is a challenging, yet consequential task, as humans seek to
constantly plan for the future. Existing automated forecasting approaches rely
mostly on structured data, such as time-series or event-based knowledge graphs,
to help predict future events. In this work, we formulate the forecasting
problem as a restricted-domain, multiple-choice, question-answering (QA) task
that simulates the forecasting scenario. To showcase the usefulness of this
task formulation, we introduce a dataset ForecastQA, a question-answering
dataset consisting of 10,392 event forecasting questions, which have been
collected and verified via crowdsourcing efforts. We also present our
experiments on ForecastQA using BERT-based models and find that our best model
achieves 61.0\% accuracy on the dataset, which is still far behind human
performance by about 18%. We hope ForecastQA will support future research
efforts in bridging this
gap.\footnote{\url{https://inklab.usc.edu/ForecastQA/}}
</p>
<a href="http://arxiv.org/abs/2005.00792" target="_blank">arXiv:2005.00792</a> [<a href="http://arxiv.org/pdf/2005.00792" target="_blank">pdf</a>]

<h2>Multi-agent Reinforcement Learning for Decentralized Stable Matching. (arXiv:2005.01117v2 [cs.LG] UPDATED)</h2>
<h3>Kshitija Taywade, Judy Goldsmith, Brent Harrison</h3>
<p>In the real world, people/entities usually find matches independently and
autonomously, such as finding jobs, partners, roommates, etc. It is possible
that this search for matches starts with no initial knowledge of the
environment. We propose the use of a multi-agent reinforcement learning (MARL)
paradigm for a spatially formulated decentralized two-sided matching market
with independent and autonomous agents. Having autonomous agents acting
independently makes our environment very dynamic and uncertain. Moreover,
agents lack the knowledge of preferences of other agents and have to explore
the environment and interact with other agents to discover their own
preferences through noisy rewards. We think such a setting better approximates
the real world and we study the usefulness of our MARL approach for it. Along
with conventional stable matching case where agents have strictly ordered
preferences, we check the applicability of our approach for stable matching
with incomplete lists and ties. We investigate our results for stability, level
of instability (for unstable results), and fairness. Our MARL approach mostly
yields stable and fair outcomes.
</p>
<a href="http://arxiv.org/abs/2005.01117" target="_blank">arXiv:2005.01117</a> [<a href="http://arxiv.org/pdf/2005.01117" target="_blank">pdf</a>]

<h2>Data Augmentation via Mixed Class Interpolation using Cycle-Consistent Generative Adversarial Networks Applied to Cross-Domain Imagery. (arXiv:2005.02436v2 [cs.CV] UPDATED)</h2>
<h3>Hiroshi Sasaki, Chris G. Willcocks, Toby P. Breckon</h3>
<p>Machine learning driven object detection and classification within
non-visible imagery has an important role in many fields such as night vision,
all-weather surveillance and aviation security. However, such applications
often suffer due to the limited quantity and variety of non-visible spectral
domain imagery, in contrast to the high data availability of visible-band
imagery that readily enables contemporary deep learning driven detection and
classification approaches. To address this problem, this paper proposes and
evaluates a novel data augmentation approach that leverages the more readily
available visible-band imagery via a generative domain transfer model. The
model can synthesise large volumes of non-visible domain imagery by
image-to-image (I2I) translation from the visible image domain. Furthermore, we
show that the generation of interpolated mixed class (non-visible domain) image
examples via our novel Conditional CycleGAN Mixup Augmentation (C2GMA)
methodology can lead to a significant improvement in the quality of non-visible
domain classification tasks that otherwise suffer due to limited data
availability. Focusing on classification within the Synthetic Aperture Radar
(SAR) domain, our approach is evaluated on a variation of the Statoil/C-CORE
Iceberg Classifier Challenge dataset and achieves 75.4% accuracy, demonstrating
a significant improvement when compared against traditional data augmentation
strategies (Rotation, Mixup, and MixCycleGAN).
</p>
<a href="http://arxiv.org/abs/2005.02436" target="_blank">arXiv:2005.02436</a> [<a href="http://arxiv.org/pdf/2005.02436" target="_blank">pdf</a>]

<h2>Provably Good Solutions to the Knapsack Problem via Neural Networks of Bounded Size. (arXiv:2005.14105v2 [cs.LG] UPDATED)</h2>
<h3>Christoph Hertrich, Martin Skutella</h3>
<p>The development of a satisfying and rigorous mathematical understanding of
the performance of neural networks is a major challenge in artificial
intelligence. Against this background, we study the expressive power of neural
networks through the example of the classical NP-hard Knapsack Problem. Our
main contribution is a class of recurrent neural networks (RNNs) with rectified
linear units that are iteratively applied to each item of a Knapsack instance
and thereby compute optimal or provably good solution values. We show that an
RNN of depth four and width depending quadratically on the profit of an optimum
Knapsack solution is sufficient to find optimum Knapsack solutions. We also
prove the following tradeoff between the size of an RNN and the quality of the
computed Knapsack solution: for Knapsack instances consisting of $n$ items, an
RNN of depth five and width $w$ computes a solution of value at least
$1-\mathcal{O}(n^2/\sqrt{w})$ times the optimum solution value. Our results
build upon a classical dynamic programming formulation of the Knapsack Problem
as well as a careful rounding of profit values that are also at the core of the
well-known fully polynomial-time approximation scheme for the Knapsack Problem.
A carefully conducted computational study qualitatively supports our
theoretical size bounds. Finally, we point out that our results can be
generalized to many other combinatorial optimization problems that admit
dynamic programming solution methods, such as various Shortest Path Problems,
the Longest Common Subsequence Problem, and the Traveling Salesperson Problem.
</p>
<a href="http://arxiv.org/abs/2005.14105" target="_blank">arXiv:2005.14105</a> [<a href="http://arxiv.org/pdf/2005.14105" target="_blank">pdf</a>]

<h2>The Value-Improvement Path: Towards Better Representations for Reinforcement Learning. (arXiv:2006.02243v2 [cs.LG] UPDATED)</h2>
<h3>Will Dabney, Andr&#xe9; Barreto, Mark Rowland, Robert Dadashi, John Quan, Marc G. Bellemare, David Silver</h3>
<p>In value-based reinforcement learning (RL), unlike in supervised learning,
the agent faces not a single, stationary, approximation problem, but a sequence
of value prediction problems. Each time the policy improves, the nature of the
problem changes, shifting both the distribution of states and their values. In
this paper we take a novel perspective, arguing that the value prediction
problems faced by an RL agent should not be addressed in isolation, but rather
as a single, holistic, prediction problem. An RL algorithm generates a sequence
of policies that, at least approximately, improve towards the optimal policy.
We explicitly characterize the associated sequence of value functions and call
it the value-improvement path. Our main idea is to approximate the
value-improvement path holistically, rather than to solely track the value
function of the current policy. Specifically, we discuss the impact that this
holistic view of RL has on representation learning. We demonstrate that a
representation that spans the past value-improvement path will also provide an
accurate value approximation for future policy improvements. We use this
insight to better understand existing approaches to auxiliary tasks and to
propose new ones. To test our hypothesis empirically, we augmented a standard
deep RL agent with an auxiliary task of learning the value-improvement path. In
a study of Atari 2600 games, the augmented agent achieved approximately double
the mean and median performance of the baseline agent.
</p>
<a href="http://arxiv.org/abs/2006.02243" target="_blank">arXiv:2006.02243</a> [<a href="http://arxiv.org/pdf/2006.02243" target="_blank">pdf</a>]

<h2>Decentralised Learning from Independent Multi-Domain Labels for Person Re-Identification. (arXiv:2006.04150v3 [cs.CV] UPDATED)</h2>
<h3>Guile Wu, Shaogang Gong</h3>
<p>Deep learning has been successful for many computer vision tasks due to the
availability of shared and centralised large-scale training data. However,
increasing awareness of privacy concerns poses new challenges to deep learning,
especially for human subject related recognition such as person
re-identification (Re-ID). In this work, we solve the Re-ID problem by
decentralised learning from non-shared private training data distributed at
multiple user sites of independent multi-domain label spaces. We propose a
novel paradigm called Federated Person Re-Identification (FedReID) to construct
a generalisable global model (a central server) by simultaneously learning with
multiple privacy-preserved local models (local clients). Specifically, each
local client receives global model updates from the server and trains a local
model using its local data independent from all the other clients. Then, the
central server aggregates transferrable local model updates to construct a
generalisable global feature embedding model without accessing local data so to
preserve local privacy. This client-server collaborative learning process is
iteratively performed under privacy control, enabling FedReID to realise
decentralised learning without sharing distributed data nor collecting any
centralised data. Extensive experiments on ten Re-ID benchmarks show that
FedReID achieves compelling generalisation performance beyond any locally
trained models without using shared training data, whilst inherently protects
the privacy of each local client. This is uniquely advantageous over
contemporary Re-ID methods.
</p>
<a href="http://arxiv.org/abs/2006.04150" target="_blank">arXiv:2006.04150</a> [<a href="http://arxiv.org/pdf/2006.04150" target="_blank">pdf</a>]

<h2>Statistical Efficiency of Thompson Sampling for Combinatorial Semi-Bandits. (arXiv:2006.06613v2 [stat.ML] UPDATED)</h2>
<h3>Pierre Perrault, Etienne Boursier, Vianney Perchet, Michal Valko</h3>
<p>We investigate stochastic combinatorial multi-armed bandit with semi-bandit
feedback (CMAB). In CMAB, the question of the existence of an efficient policy
with an optimal asymptotic regret (up to a factor poly-logarithmic with the
action size) is still open for many families of distributions, including
mutually independent outcomes, and more generally the multivariate sub-Gaussian
family. We propose to answer the above question for these two families by
analyzing variants of the Combinatorial Thompson Sampling policy (CTS). For
mutually independent outcomes in $[0,1]$, we propose a tight analysis of CTS
using Beta priors. We then look at the more general setting of multivariate
sub-Gaussian outcomes and propose a tight analysis of CTS using Gaussian
priors. This last result gives us an alternative to the Efficient Sampling for
Combinatorial Bandit policy (ESCB), which, although optimal, is not
computationally efficient.
</p>
<a href="http://arxiv.org/abs/2006.06613" target="_blank">arXiv:2006.06613</a> [<a href="http://arxiv.org/pdf/2006.06613" target="_blank">pdf</a>]

<h2>Fairness in Forecasting and Learning Linear Dynamical Systems. (arXiv:2006.07315v2 [cs.LG] UPDATED)</h2>
<h3>Quan Zhou, Jakub Marecek, Robert N. Shorten</h3>
<p>In machine learning, training data often capture the behaviour of multiple
subgroups of some underlying human population. When the amounts of training
data for the subgroups are not controlled carefully, under-representation bias
arises. We introduce two natural notions of subgroup fairness and instantaneous
fairness to address such under-representation bias in time-series forecasting
problems. In particular, we consider the subgroup-fair and instant-fair
learning of a linear dynamical system (LDS) from multiple trajectories of
varying lengths, and the associated forecasting problems. We provide globally
convergent methods for the learning problems using hierarchies of
convexifications of non-commutative polynomial optimisation problems. Our
empirical results on a biased data set motivated by insurance applications and
the well-known COMPAS data set demonstrate both the beneficial impact of
fairness considerations on statistical performance and encouraging effects of
exploiting sparsity on run time.
</p>
<a href="http://arxiv.org/abs/2006.07315" target="_blank">arXiv:2006.07315</a> [<a href="http://arxiv.org/pdf/2006.07315" target="_blank">pdf</a>]

<h2>Learning Bounds for Risk-sensitive Learning. (arXiv:2006.08138v2 [stat.ML] UPDATED)</h2>
<h3>Jaeho Lee, Sejun Park, Jinwoo Shin</h3>
<p>In risk-sensitive learning, one aims to find a hypothesis that minimizes a
risk-averse (or risk-seeking) measure of loss, instead of the standard expected
loss. In this paper, we propose to study the generalization properties of
risk-sensitive learning schemes whose optimand is described via optimized
certainty equivalents (OCE): our general scheme can handle various known risks,
e.g., the entropic risk, mean-variance, and conditional value-at-risk, as
special cases. We provide two learning bounds on the performance of empirical
OCE minimizer. The first result gives an OCE guarantee based on the Rademacher
average of the hypothesis space, which generalizes and improves existing
results on the expected loss and the conditional value-at-risk. The second
result, based on a novel variance-based characterization of OCE, gives an
expected loss guarantee with a suppressed dependence on the smoothness of the
selected OCE. Finally, we demonstrate the practical implications of the
proposed bounds via exploratory experiments on neural networks.
</p>
<a href="http://arxiv.org/abs/2006.08138" target="_blank">arXiv:2006.08138</a> [<a href="http://arxiv.org/pdf/2006.08138" target="_blank">pdf</a>]

<h2>On the training dynamics of deep networks with $L_2$ regularization. (arXiv:2006.08643v2 [stat.ML] UPDATED)</h2>
<h3>Aitor Lewkowycz, Guy Gur-Ari</h3>
<p>We study the role of $L_2$ regularization in deep learning, and uncover
simple relations between the performance of the model, the $L_2$ coefficient,
the learning rate, and the number of training steps. These empirical relations
hold when the network is overparameterized. They can be used to predict the
optimal regularization parameter of a given model. In addition, based on these
observations we propose a dynamical schedule for the regularization parameter
that improves performance and speeds up training. We test these proposals in
modern image classification settings. Finally, we show that these empirical
relations can be understood theoretically in the context of infinitely wide
networks. We derive the gradient flow dynamics of such networks, and compare
the role of $L_2$ regularization in this context with that of linear models.
</p>
<a href="http://arxiv.org/abs/2006.08643" target="_blank">arXiv:2006.08643</a> [<a href="http://arxiv.org/pdf/2006.08643" target="_blank">pdf</a>]

<h2>A Non-Asymptotic Analysis for Stein Variational Gradient Descent. (arXiv:2006.09797v4 [stat.ML] UPDATED)</h2>
<h3>Anna Korba, Adil Salim, Michael Arbel, Giulia Luise, Arthur Gretton</h3>
<p>We study the Stein Variational Gradient Descent (SVGD) algorithm, which
optimises a set of particles to approximate a target probability distribution
$\pi\propto e^{-V}$ on $\mathbb{R}^d$. In the population limit, SVGD performs
gradient descent in the space of probability distributions on the KL divergence
with respect to $\pi$, where the gradient is smoothed through a kernel integral
operator. In this paper, we provide a novel finite time analysis for the SVGD
algorithm. We provide a descent lemma establishing that the algorithm decreases
the objective at each iteration, and rates of convergence for the average Stein
Fisher divergence (also referred to as Kernel Stein Discrepancy). We also
provide a convergence result of the finite particle system corresponding to the
practical implementation of SVGD to its population version.
</p>
<a href="http://arxiv.org/abs/2006.09797" target="_blank">arXiv:2006.09797</a> [<a href="http://arxiv.org/pdf/2006.09797" target="_blank">pdf</a>]

<h2>Constraining Variational Inference with Geometric Jensen-Shannon Divergence. (arXiv:2006.10599v3 [cs.LG] UPDATED)</h2>
<h3>Jacob Deasy, Nikola Simidjievski, Pietro Li&#xf2;</h3>
<p>We examine the problem of controlling divergences for latent space
regularisation in variational autoencoders. Specifically, when aiming to
reconstruct example $x\in\mathbb{R}^{m}$ via latent space $z\in\mathbb{R}^{n}$
($n\leq m$), while balancing this against the need for generalisable latent
representations. We present a regularisation mechanism based on the
skew-geometric Jensen-Shannon divergence
$\left(\textrm{JS}^{\textrm{G}_{\alpha}}\right)$. We find a variation in
$\textrm{JS}^{\textrm{G}_{\alpha}}$, motivated by limiting cases, which leads
to an intuitive interpolation between forward and reverse KL in the space of
both distributions and divergences. We motivate its potential benefits for VAEs
through low-dimensional examples, before presenting quantitative and
qualitative results. Our experiments demonstrate that skewing our variant of
$\textrm{JS}^{\textrm{G}_{\alpha}}$, in the context of
$\textrm{JS}^{\textrm{G}_{\alpha}}$-VAEs, leads to better reconstruction and
generation when compared to several baseline VAEs. Our approach is entirely
unsupervised and utilises only one hyperparameter which can be easily
interpreted in latent space.
</p>
<a href="http://arxiv.org/abs/2006.10599" target="_blank">arXiv:2006.10599</a> [<a href="http://arxiv.org/pdf/2006.10599" target="_blank">pdf</a>]

<h2>D2P-Fed: Differentially Private Federated Learning With Efficient Communication. (arXiv:2006.13039v5 [stat.ML] UPDATED)</h2>
<h3>Lun Wang, Ruoxi Jia, Dawn Song</h3>
<p>In this paper, we propose the discrete Gaussian based differentially private
federated learning (D2P-Fed), a unified scheme to achieve both differential
privacy (DP) and communication efficiency in federated learning (FL). In
particular, compared with the only prior work taking care of both aspects,
D2P-Fed provides stronger privacy guarantee, better composability and smaller
communication cost. The key idea is to apply the discrete Gaussian noise to the
private data transmission. We provide complete analysis of the privacy
guarantee, communication cost and convergence rate of D2P-Fed. We evaluated
D2P-Fed on INFIMNIST and CIFAR10. The results show that D2P-Fed outperforms
the-state-of-the-art by 4.7% to 13.0% in terms of model accuracy while saving
one third of the communication cost.
</p>
<a href="http://arxiv.org/abs/2006.13039" target="_blank">arXiv:2006.13039</a> [<a href="http://arxiv.org/pdf/2006.13039" target="_blank">pdf</a>]

<h2>Feature-Dependent Cross-Connections in Multi-Path Neural Networks. (arXiv:2006.13904v2 [cs.CV] UPDATED)</h2>
<h3>Dumindu Tissera, Kasun Vithanage, Rukshan Wijesinghe, Kumara Kahatapitiya, Subha Fernando, Ranga Rodrigo</h3>
<p>Learning a particular task from a dataset, samples in which originate from
diverse contexts, is challenging, and usually addressed by deepening or
widening standard neural networks. As opposed to conventional network widening,
multi-path architectures restrict the quadratic increment of complexity to a
linear scale. However, existing multi-column/path networks or model ensembling
methods do not consider any feature-dependent allocation of parallel resources,
and therefore, tend to learn redundant features. Given a layer in a multi-path
network, if we restrict each path to learn a context-specific set of features
and introduce a mechanism to intelligently allocate incoming feature maps to
such paths, each path can specialize in a certain context, reducing the
redundancy and improving the quality of extracted features. This eventually
leads to better-optimized usage of parallel resources. To do this, we propose
inserting feature-dependent cross-connections between parallel sets of feature
maps in successive layers. The weighting coefficients of these
cross-connections are computed from the input features of the particular layer.
Our multi-path networks show improved image recognition accuracy at a similar
complexity compared to conventional and state-of-the-art methods for deepening,
widening and adaptive feature extracting, in both small and large scale
datasets.
</p>
<a href="http://arxiv.org/abs/2006.13904" target="_blank">arXiv:2006.13904</a> [<a href="http://arxiv.org/pdf/2006.13904" target="_blank">pdf</a>]

<h2>Online 3D Bin Packing with Constrained Deep Reinforcement Learning. (arXiv:2006.14978v2 [cs.LG] UPDATED)</h2>
<h3>Hang Zhao, Qijin She, Chenyang Zhu, Yin Yang, Kai Xu</h3>
<p>We solve a challenging yet practically useful variant of 3D Bin Packing
Problem (3D-BPP). In our problem, the agent has limited information about the
items to be packed into the bin, and an item must be packed immediately after
its arrival without buffering or readjusting. The item's placement also
subjects to the constraints of collision avoidance and physical stability. We
formulate this online 3D-BPP as a constrained Markov decision process. To solve
the problem, we propose an effective and easy-to-implement constrained deep
reinforcement learning (DRL) method under the actor-critic framework. In
particular, we introduce a feasibility predictor to predict the feasibility
mask for the placement actions and use it to modulate the action probabilities
output by the actor during training. Such supervisions and transformations to
DRL facilitate the agent to learn feasible policies efficiently. Our method can
also be generalized e.g., with the ability to handle lookahead or items with
different orientations. We have conducted extensive evaluation showing that the
learned policy significantly outperforms the state-of-the-art methods. A user
study suggests that our method attains a human-level performance.
</p>
<a href="http://arxiv.org/abs/2006.14978" target="_blank">arXiv:2006.14978</a> [<a href="http://arxiv.org/pdf/2006.14978" target="_blank">pdf</a>]

<h2>Submodular Combinatorial Information Measures with Applications in Machine Learning. (arXiv:2006.15412v5 [cs.LG] UPDATED)</h2>
<h3>Rishabh Iyer, Ninad Khargonkar, Jeff Bilmes, Himanshu Asnani</h3>
<p>Information-theoretic quantities like entropy and mutual information have
found numerous uses in machine learning. It is well known that there is a
strong connection between these entropic quantities and submodularity since
entropy over a set of random variables is submodular. In this paper, we study
combinatorial information measures that generalize independence, (conditional)
entropy, (conditional) mutual information, and total correlation defined over
sets of (not necessarily random) variables. These measures strictly generalize
the corresponding entropic measures since they are all parameterized via
submodular functions that themselves strictly generalize entropy. Critically,
we show that, unlike entropic mutual information in general, the submodular
mutual information is actually submodular in one argument, holding the other
fixed, for a large class of submodular functions whose third-order partial
derivatives satisfy a non-negativity property. This turns out to include a
number of practically useful cases such as the facility location and set-cover
functions. We study specific instantiations of the submodular information
measures on these, as well as the probabilistic coverage, graph-cut, and
saturated coverage functions, and see that they all have mathematically
intuitive and practically useful expressions. Regarding applications, we
connect the maximization of submodular (conditional) mutual information to
problems such as mutual-information-based, query-based, and privacy-preserving
summarization -- and we connect optimizing the multi-set submodular mutual
information to clustering and robust partitioning.
</p>
<a href="http://arxiv.org/abs/2006.15412" target="_blank">arXiv:2006.15412</a> [<a href="http://arxiv.org/pdf/2006.15412" target="_blank">pdf</a>]

<h2>MSNet: A Multilevel Instance Segmentation Network for Natural Disaster Damage Assessment in Aerial Videos. (arXiv:2006.16479v2 [cs.CV] UPDATED)</h2>
<h3>Xiaoyu Zhu, Junwei Liang, Alexander Hauptmann</h3>
<p>In this paper, we study the problem of efficiently assessing building damage
after natural disasters like hurricanes, floods or fires, through aerial video
analysis. We make two main contributions. The first contribution is a new
dataset, consisting of user-generated aerial videos from social media with
annotations of instance-level building damage masks. This provides the first
benchmark for quantitative evaluation of models to assess building damage using
aerial videos. The second contribution is a new model, namely MSNet, which
contains novel region proposal network designs and an unsupervised score
refinement network for confidence score calibration in both bounding box and
mask branches. We show that our model achieves state-of-the-art results
compared to previous methods in our dataset. We will release our data, models
and code.
</p>
<a href="http://arxiv.org/abs/2006.16479" target="_blank">arXiv:2006.16479</a> [<a href="http://arxiv.org/pdf/2006.16479" target="_blank">pdf</a>]

<h2>Point Set Voting for Partial Point Cloud Analysis. (arXiv:2007.04537v2 [cs.CV] UPDATED)</h2>
<h3>Junming Zhang, Weijia Chen, Yuping Wang, Ram Vasudevan, Matthew Johnson-Roberson</h3>
<p>The continual improvement of 3D sensors has driven the development of
algorithms to perform point cloud analysis. In fact, techniques for point cloud
classification and segmentation have in recent years achieved incredible
performance driven in part by leveraging large synthetic datasets.
Unfortunately these same state-of-the-art approaches perform poorly when
applied to incomplete point clouds. This limitation of existing algorithms is
particularly concerning since point clouds generated by 3D sensors in the real
world are usually incomplete due to perspective view or occlusion by other
objects. This paper proposes a general model for partial point clouds analysis
wherein the latent feature encoding a complete point clouds is inferred by
applying a local point set voting strategy. In particular, each local point set
constructs a vote that corresponds to a distribution in the latent space, and
the optimal latent feature is the one with the highest probability. This
approach ensures that any subsequent point cloud analysis is robust to partial
observation while simultaneously guaranteeing that the proposed model is able
to output multiple possible results. This paper illustrates that this proposed
method achieves state-of-the-art performance on shape classification, part
segmentation and point cloud completion.
</p>
<a href="http://arxiv.org/abs/2007.04537" target="_blank">arXiv:2007.04537</a> [<a href="http://arxiv.org/pdf/2007.04537" target="_blank">pdf</a>]

<h2>RT3D: Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices. (arXiv:2007.09835v2 [cs.LG] UPDATED)</h2>
<h3>Wei Niu, Mengshu Sun, Zhengang Li, Jou-An Chen, Jiexiong Guan, Xipeng Shen, Yanzhi Wang, Sijia Liu, Xue Lin, Bin Ren</h3>
<p>Mobile devices are becoming an important carrier for deep learning tasks, as
they are being equipped with powerful, high-end mobile CPUs and GPUs. However,
it is still a challenging task to execute 3D Convolutional Neural Networks
(CNNs) targeting for real-time performance, besides high inference accuracy.
The reason is more complex model structure and higher model dimensionality
overwhelm the available computation/storage resources on mobile devices. A
natural way may be turning to deep learning weight pruning techniques. However,
the direct generalization of existing 2D CNN weight pruning methods to 3D CNNs
is not ideal for fully exploiting mobile parallelism while achieving high
inference accuracy.

This paper proposes RT3D, a model compression and mobile acceleration
framework for 3D CNNs, seamlessly integrating neural network weight pruning and
compiler code generation techniques. We propose and investigate two structured
sparsity schemes i.e., the vanilla structured sparsity and kernel group
structured (KGS) sparsity that are mobile acceleration friendly. The vanilla
sparsity removes whole kernel groups, while KGS sparsity is a more fine-grained
structured sparsity that enjoys higher flexibility while exploiting full
on-device parallelism. We propose a reweighted regularization pruning algorithm
to achieve the proposed sparsity schemes. The inference time speedup due to
sparsity is approaching the pruning rate of the whole model FLOPs (floating
point operations). RT3D demonstrates up to 29.1$\times$ speedup in end-to-end
inference time comparing with current mobile frameworks supporting 3D CNNs,
with moderate 1%-1.5% accuracy loss. The end-to-end inference time for 16 video
frames could be within 150 ms, when executing representative C3D and R(2+1)D
models on a cellphone. For the first time, real-time execution of 3D CNNs is
achieved on off-the-shelf mobiles.
</p>
<a href="http://arxiv.org/abs/2007.09835" target="_blank">arXiv:2007.09835</a> [<a href="http://arxiv.org/pdf/2007.09835" target="_blank">pdf</a>]

<h2>Deep Preset: Blending and Retouching Photos with Color Style Transfer. (arXiv:2007.10701v2 [cs.CV] UPDATED)</h2>
<h3>Man M. Ho, Jinjia Zhou</h3>
<p>End-users, without knowledge in photography, desire to beautify their photos
to have a similar color style as a well-retouched reference. However, the
definition of style in recent image style transfer works is inappropriate. They
usually synthesize undesirable results due to transferring exact colors to the
wrong destination. It becomes even worse in sensitive cases such as portraits.
In this work, we concentrate on learning low-level image transformation,
especially color-shifting methods, rather than mixing contextual features, then
present a novel scheme to train color style transfer with ground-truth.
Furthermore, we propose a color style transfer named Deep Preset. It is
designed to 1) generalize the features representing the color transformation
from content with natural colors to retouched reference, then blend it into the
contextual features of content, 2) predict hyper-parameters (settings or
preset) of the applied low-level color transformation methods, 3) stylize
content to have a similar color style as reference. We script Lightroom, a
powerful tool in editing photos, to generate 600,000 training samples using
1,200 images from the Flick2K dataset and 500 user-generated presets with 69
settings. Experimental results show that our Deep Preset outperforms the
previous works in color style transfer quantitatively and qualitatively.
</p>
<a href="http://arxiv.org/abs/2007.10701" target="_blank">arXiv:2007.10701</a> [<a href="http://arxiv.org/pdf/2007.10701" target="_blank">pdf</a>]

<h2>A Survey on Concept Factorization: From Shallow to Deep Representation Learning. (arXiv:2007.15840v2 [cs.LG] UPDATED)</h2>
<h3>Zhao Zhang, Yan Zhang, Mingliang Xu, Li Zhang, Yi Yang, Shuicheng Yan</h3>
<p>The quality of learned features by representation learning determines the
performance of learning algorithms and the related application tasks (such as
high-dimensional data clustering). As a relatively new paradigm for
representation learning, Concept Factorization (CF) has attracted a great deal
of interests in the areas of machine learning and data mining for over a
decade. Lots of effective CF based methods have been proposed based on
different perspectives and properties, but note that it still remains not easy
to grasp the essential connections and figure out the underlying explanatory
factors from exiting studies. In this paper, we therefore survey the recent
advances on CF methodologies and the potential benchmarks by categorizing and
summarizing the current methods. Specifically, we first re-view the root CF
method, and then explore the advancement of CF-based representation learning
ranging from shallow to deep/multilayer cases. We also introduce the potential
application areas of CF-based methods. Finally, we point out some future
directions for studying the CF-based representation learning. Overall, this
survey provides an insightful overview of both theoretical basis and current
developments in the field of CF, which can also help the interested researchers
to understand the current trends of CF and find the most appropriate CF
techniques to deal with particular applications.
</p>
<a href="http://arxiv.org/abs/2007.15840" target="_blank">arXiv:2007.15840</a> [<a href="http://arxiv.org/pdf/2007.15840" target="_blank">pdf</a>]

<h2>The Kolmogorov-Arnold representation theorem revisited. (arXiv:2007.15884v2 [cs.LG] UPDATED)</h2>
<h3>Johannes Schmidt-Hieber</h3>
<p>There is a longstanding debate whether the Kolmogorov-Arnold representation
theorem can explain the use of more than one hidden layer in neural networks.
The Kolmogorov-Arnold representation decomposes a multivariate function into an
interior and an outer function and therefore has indeed a similar structure as
a neural network with two hidden layers. But there are distinctive differences.
One of the main obstacles is that the outer function depends on the represented
function and can be wildly varying even if the represented function is smooth.
We derive modifications of the Kolmogorov-Arnold representation that transfer
smoothness properties of the represented function to the outer function and can
be well approximated by ReLU networks. It appears that instead of two hidden
layers, a more natural interpretation of the Kolmogorov-Arnold representation
is that of a deep neural network where most of the layers are required to
approximate the interior function.
</p>
<a href="http://arxiv.org/abs/2007.15884" target="_blank">arXiv:2007.15884</a> [<a href="http://arxiv.org/pdf/2007.15884" target="_blank">pdf</a>]

<h2>node2coords: Graph Representation Learning with Wasserstein Barycenters. (arXiv:2007.16056v2 [cs.LG] UPDATED)</h2>
<h3>Effrosyni Simou, Dorina Thanou, Pascal Frossard</h3>
<p>In order to perform network analysis tasks, representations that capture the
most relevant information in the graph structure are needed. However, existing
methods do not learn representations that can be interpreted in a
straightforward way and that are robust to perturbations to the graph
structure. In this work, we address these two limitations by proposing
node2coords, a representation learning algorithm for graphs, which learns
simultaneously a low-dimensional space and coordinates for the nodes in that
space. The patterns that span the low dimensional space reveal the graph's most
important structural information. The coordinates of the nodes reveal the
proximity of their local structure to the graph structural patterns. In order
to measure this proximity by taking into account the underlying graph, we
propose to use Wasserstein distances. We introduce an autoencoder that employs
a linear layer in the encoder and a novel Wasserstein barycentric layer at the
decoder. Node connectivity descriptors, that capture the local structure of the
nodes, are passed through the encoder to learn the small set of graph
structural patterns. In the decoder, the node connectivity descriptors are
reconstructed as Wasserstein barycenters of the graph structural patterns. The
optimal weights for the barycenter representation of a node's connectivity
descriptor correspond to the coordinates of that node in the low-dimensional
space. Experimental results demonstrate that the representations learned with
node2coords are interpretable, lead to node embeddings that are stable to
perturbations of the graph structure and achieve competitive or superior
results compared to state-of-the-art methods in node classification.
</p>
<a href="http://arxiv.org/abs/2007.16056" target="_blank">arXiv:2007.16056</a> [<a href="http://arxiv.org/pdf/2007.16056" target="_blank">pdf</a>]

<h2>Detecting Beneficial Feature Interactions for Recommender Systems. (arXiv:2008.00404v4 [cs.LG] UPDATED)</h2>
<h3>Yixin Su, Rui Zhang, Sarah Erfani, Zhenghua Xu</h3>
<p>Feature interactions are essential for achieving high accuracy in recommender
systems. Many studies take into account the interaction between every pair of
features. However, this is suboptimal because some feature interactions may not
be that relevant to the recommendation result, and taking them into account may
introduce noise and decrease recommendation accuracy. To make the best out of
feature interactions, we propose a graph neural network approach to effectively
model them, together with a novel technique to automatically detect those
feature interactions that are beneficial in terms of recommendation accuracy.
The automatic feature interaction detection is achieved via edge prediction
with an L0 activation regularization. Our proposed model is proved to be
effective through the information bottleneck principle and statistical
interaction theory. Experimental results show that our model (i) outperforms
existing baselines in terms of accuracy, and (ii) automatically identifies
beneficial feature interactions.
</p>
<a href="http://arxiv.org/abs/2008.00404" target="_blank">arXiv:2008.00404</a> [<a href="http://arxiv.org/pdf/2008.00404" target="_blank">pdf</a>]

<h2>SCG-Net: Self-Constructing Graph Neural Networks for Semantic Segmentation. (arXiv:2009.01599v2 [cs.CV] UPDATED)</h2>
<h3>Qinghui Liu, Michael Kampffmeyer, Robert Jenssen, Arnt-B&#xf8;rre Salberg</h3>
<p>Capturing global contextual representations by exploiting long-range
pixel-pixel dependencies has shown to improve semantic segmentation
performance. However, how to do this efficiently is an open question as current
approaches of utilising attention schemes or very deep models to increase the
models field of view, result in complex models with large memory consumption.
Inspired by recent work on graph neural networks, we propose the
Self-Constructing Graph (SCG) module that learns a long-range dependency graph
directly from the image and uses it to propagate contextual information
efficiently to improve semantic segmentation. The module is optimised via a
novel adaptive diagonal enhancement method and a variational lower bound that
consists of a customized graph reconstruction term and a Kullback-Leibler
divergence regularization term. When incorporated into a neural network
(SCG-Net), semantic segmentation is performed in an end-to-end manner and
competitive performance (mean F1-scores of 92.0% and 89.8% respectively) on the
publicly available ISPRS Potsdam and Vaihingen datasets is achieved, with much
fewer parameters, and at a lower computational cost compared to related pure
convolutional neural network (CNN) based models.
</p>
<a href="http://arxiv.org/abs/2009.01599" target="_blank">arXiv:2009.01599</a> [<a href="http://arxiv.org/pdf/2009.01599" target="_blank">pdf</a>]

<h2>Learning from Multiple Datasets with Heterogeneous and Partial Labels for Universal Lesion Detection in CT. (arXiv:2009.02577v3 [cs.CV] UPDATED)</h2>
<h3>Ke Yan, Jinzheng Cai, Youjing Zheng, Adam P. Harrison, Dakai Jin, Youbao Tang, Yuxing Tang, Lingyun Huang, Jing Xiao, Le Lu</h3>
<p>Large-scale datasets with high-quality labels are desired for training
accurate deep learning models. However, due to the annotation cost, datasets in
medical imaging are often either partially-labeled or small. For example,
DeepLesion is such a large-scale CT image dataset with lesions of various
types, but it also has many unlabeled lesions (missing annotations). When
training a lesion detector on a partially-labeled dataset, the missing
annotations will generate incorrect negative signals and degrade the
performance. Besides DeepLesion, there are several small single-type datasets,
such as LUNA for lung nodules and LiTS for liver tumors. These datasets have
heterogeneous label scopes, i.e., different lesion types are labeled in
different datasets with other types ignored. In this work, we aim to develop a
universal lesion detection algorithm to detect a variety of lesions. The
problem of heterogeneous and partial labels is tackled. First, we build a
simple yet effective lesion detection framework named Lesion ENSemble (LENS).
LENS can efficiently learn from multiple heterogeneous lesion datasets in a
multi-task fashion and leverage their synergy by proposal fusion. Next, we
propose strategies to mine missing annotations from partially-labeled datasets
by exploiting clinical prior knowledge and cross-dataset knowledge transfer.
Finally, we train our framework on four public lesion datasets and evaluate it
on 800 manually-labeled sub-volumes in DeepLesion. Our method brings a relative
improvement of 49% compared to the current state-of-the-art approach in the
metric of average sensitivity. We have publicly released our manual 3D
annotations of DeepLesion in
https://github.com/viggin/DeepLesion_manual_test_set.
</p>
<a href="http://arxiv.org/abs/2009.02577" target="_blank">arXiv:2009.02577</a> [<a href="http://arxiv.org/pdf/2009.02577" target="_blank">pdf</a>]

<h2>Improved Exploration in Factored Average-Reward MDPs. (arXiv:2009.04575v2 [cs.LG] UPDATED)</h2>
<h3>Mohammad Sadegh Talebi, Anders Jonsson, Odalric-Ambrym Maillard</h3>
<p>We consider a regret minimization task under the average-reward criterion in
an unknown Factored Markov Decision Process (FMDP). More specifically, we
consider an FMDP where the state-action space $\mathcal X$ and the state-space
$\mathcal S$ admit the respective factored forms of $\mathcal X =
\otimes_{i=1}^n \mathcal X_i$ and $\mathcal S=\otimes_{i=1}^m \mathcal S_i$,
and the transition and reward functions are factored over $\mathcal X$ and
$\mathcal S$. Assuming known factorization structure, we introduce a novel
regret minimization strategy inspired by the popular UCRL2 strategy, called
DBN-UCRL, which relies on Bernstein-type confidence sets defined for individual
elements of the transition function. We show that for a generic factorization
structure, DBN-UCRL achieves a regret bound, whose leading term strictly
improves over existing regret bounds in terms of the dependencies on the size
of $\mathcal S_i$'s and the involved diameter-related terms. We further show
that when the factorization structure corresponds to the Cartesian product of
some base MDPs, the regret of DBN-UCRL is upper bounded by the sum of regret of
the base MDPs. We demonstrate, through numerical experiments on standard
environments, that DBN-UCRL enjoys a substantially improved regret empirically
over existing algorithms.
</p>
<a href="http://arxiv.org/abs/2009.04575" target="_blank">arXiv:2009.04575</a> [<a href="http://arxiv.org/pdf/2009.04575" target="_blank">pdf</a>]

<h2>Decision-based Universal Adversarial Attack. (arXiv:2009.07024v3 [cs.CV] UPDATED)</h2>
<h3>Jing Wu, Mingyi Zhou, Shuaicheng Liu, Yipeng Liu, Ce Zhu</h3>
<p>A single perturbation can pose the most natural images to be misclassified by
classifiers. In black-box setting, current universal adversarial attack methods
utilize substitute models to generate the perturbation, then apply the
perturbation to the attacked model. However, this transfer often produces
inferior results. In this study, we directly work in the black-box setting to
generate the universal adversarial perturbation. Besides, we aim to design an
adversary generating a single perturbation having texture like stripes based on
orthogonal matrix, as the top convolutional layers are sensitive to stripes. To
this end, we propose an efficient Decision-based Universal Attack (DUAttack).
With few data, the proposed adversary computes the perturbation based solely on
the final inferred labels, but good transferability has been realized not only
across models but also span different vision tasks. The effectiveness of
DUAttack is validated through comparisons with other state-of-the-art attacks.
The efficiency of DUAttack is also demonstrated on real world settings
including the Microsoft Azure. In addition, several representative defense
methods are struggling with DUAttack, indicating the practicability of the
proposed method.
</p>
<a href="http://arxiv.org/abs/2009.07024" target="_blank">arXiv:2009.07024</a> [<a href="http://arxiv.org/pdf/2009.07024" target="_blank">pdf</a>]

<h2>Demand Forecasting of Individual Probability Density Functions with Machine Learning. (arXiv:2009.07052v2 [cs.LG] UPDATED)</h2>
<h3>F. Wick, U. Kerzel, M. Hahn, M. Wolf, T. Singhal, D. Stemmer, J. Ernst, M. Feindt</h3>
<p>Demand forecasting is a central component of the replenishment process for
retailers, as it provides crucial input for subsequent decision making like
ordering processes. In contrast to point estimates, such as the conditional
mean of the underlying probability distribution, or confidence intervals,
forecasting complete probability density functions allows to investigate the
impact on operational metrics, which are important to define the business
strategy, over the full range of the expected demand. Whereas metrics
evaluating point estimates are widely used, methods for assessing the accuracy
of predicted distributions are rare, and this work proposes new techniques for
both qualitative and quantitative evaluation methods. Using the supervised
machine learning method "Cyclic Boosting", complete individual probability
density functions can be predicted such that each prediction is fully
explainable. This is of particular importance for practitioners, as it allows
to avoid "black-box" models and understand the contributing factors for each
individual prediction. Another crucial aspect in terms of both explainability
and generalizability of demand forecasting methods is the limitation of the
influence of temporal confounding, which is prevalent in most state of the art
approaches.
</p>
<a href="http://arxiv.org/abs/2009.07052" target="_blank">arXiv:2009.07052</a> [<a href="http://arxiv.org/pdf/2009.07052" target="_blank">pdf</a>]

<h2>Deep Learning for Predictive Business Process Monitoring: Review and Benchmark. (arXiv:2009.13251v3 [cs.LG] UPDATED)</h2>
<h3>Efr&#xe9;n Rama-Maneiro, Juan C. Vidal, Manuel Lama</h3>
<p>Predictive monitoring of business processes is concerned with the prediction
of ongoing cases on a business process. Lately, the popularity of deep learning
techniques has propitiated an ever-growing set of approaches focused on
predictive monitoring based on these techniques. However, the high disparity of
process logs and experimental setups used to evaluate these approaches makes it
especially difficult to make a fair comparison. Furthermore, it also difficults
the selection of the most suitable approach to solve a specific problem. In
this paper, we provide both a systematic literature review of approaches that
use deep learning to tackle the predictive monitoring tasks. In addition, we
performed an exhaustive experimental evaluation of 10 different approaches over
12 publicly available process logs.
</p>
<a href="http://arxiv.org/abs/2009.13251" target="_blank">arXiv:2009.13251</a> [<a href="http://arxiv.org/pdf/2009.13251" target="_blank">pdf</a>]

<h2>Training Data Augmentation for Deep Learning Radio Frequency Systems. (arXiv:2010.00178v4 [cs.LG] UPDATED)</h2>
<h3>William H. Clark IV, Steven Hauser, William C. Headley, Alan J. Michaels</h3>
<p>Applications of machine learning are subject to three major components that
contribute to the final performance metrics. Within the category of neural
networks, and deep learning specifically, the first two are the architecture
for the model being trained and the training approach used. This work focuses
on the third component, the data used during training. The primary questions
that arise are ``what is in the data'' and ``what within the data matters?''
Looking into the Radio Frequency Machine Learning (RFML) field of Automatic
Modulation Classification (AMC) as an example of a tool used for situational
awareness, the use of synthetic, captured, and augmented data are examined and
compared to provide insights about the quantity and quality of the available
data necessary to achieve desired performance levels. There are three questions
discussed within this work: (1) how useful a synthetically trained system is
expected to be when deployed without considering the environment within the
synthesis, (2) how can augmentation be leveraged within the RFML domain, and
lastly, (3) what impact knowledge of degradations to the signal caused by the
transmission channel contributes to the performance of a system. In general,
the examined data types each have useful contributions to a final application,
but captured data germane to the intended use case will always provide more
significant information and enable the greatest performance. Despite the
benefit of captured data, the difficulties and costs that arise from live
collection often make the quantity of data needed to achieve peak performance
impractical. This paper helps quantify the balance between real and synthetic
data, offering concrete examples where training data is parametrically varied
in size and source.
</p>
<a href="http://arxiv.org/abs/2010.00178" target="_blank">arXiv:2010.00178</a> [<a href="http://arxiv.org/pdf/2010.00178" target="_blank">pdf</a>]

<h2>Do Wider Neural Networks Really Help Adversarial Robustness?. (arXiv:2010.01279v2 [cs.LG] UPDATED)</h2>
<h3>Boxi Wu, Jinghui Chen, Deng Cai, Xiaofei He, Quanquan Gu</h3>
<p>Adversarial training is currently the most powerful defense against
adversarial examples. Previous empirical results suggest that adversarial
training requires wider networks for better performances. Yet, it remains
elusive how does neural network width affect model robustness. In this paper,
we carefully examine the relation between network width and model robustness.
We present an intriguing phenomenon that the increased network width may not
help robustness. Specifically, we show that the model robustness is closely
related to both natural accuracy and perturbation stability, a new metric
proposed in our paper to characterize the model's stability under adversarial
perturbations. While better natural accuracy can be achieved on wider neural
networks, the perturbation stability actually becomes worse, leading to a
potentially worse overall model robustness. To understand the origin of this
phenomenon, we further relate the perturbation stability with the network's
local Lipschitznesss. By leveraging recent results on neural tangent kernels,
we show that larger network width naturally leads to worse perturbation
stability. This suggests that to fully unleash the power of wide model
architecture, practitioners should adopt a larger regularization parameter for
training wider networks. Experiments on benchmark datasets confirm that this
strategy could indeed alleviate the perturbation stability issue and improve
the state-of-the-art robust models.
</p>
<a href="http://arxiv.org/abs/2010.01279" target="_blank">arXiv:2010.01279</a> [<a href="http://arxiv.org/pdf/2010.01279" target="_blank">pdf</a>]

<h2>Efficient computation of contrastive explanations. (arXiv:2010.02647v2 [cs.LG] UPDATED)</h2>
<h3>Andr&#xe9; Artelt, Barbara Hammer</h3>
<p>With the increasing deployment of machine learning systems in practice,
transparency and explainability have become serious issues. Contrastive
explanations are considered to be useful and intuitive, in particular when it
comes to explaining decisions to lay people, since they mimic the way in which
humans explain. Yet, so far, comparably little research has addressed
computationally feasible technologies, which allow guarantees on uniqueness and
optimality of the explanation and which enable an easy incorporation of
additional constraints. Here, we will focus on specific types of models rather
than black-box technologies. We study the relation of contrastive and
counterfactual explanations and propose mathematical formalizations as well as
a 2-phase algorithm for efficiently computing (plausible) pertinent positives
of many standard machine learning models.
</p>
<a href="http://arxiv.org/abs/2010.02647" target="_blank">arXiv:2010.02647</a> [<a href="http://arxiv.org/pdf/2010.02647" target="_blank">pdf</a>]

<h2>Intelligent Reference Curation for Visual Place Recognition via Bayesian Selective Fusion. (arXiv:2010.09228v2 [cs.CV] UPDATED)</h2>
<h3>Timothy L. Molloy, Tobias Fischer, Michael Milford, Girish N. Nair</h3>
<p>A key challenge in visual place recognition (VPR) is recognizing places
despite drastic visual appearance changes due to factors such as time of day,
season, weather or lighting conditions. Numerous approaches based on
deep-learnt image descriptors, sequence matching, domain translation, and
probabilistic localization have had success in addressing this challenge, but
most rely on the availability of carefully curated representative reference
images of the possible places. In this paper, we propose a novel approach,
dubbed Bayesian Selective Fusion, for actively selecting and fusing informative
reference images to determine the best place match for a given query image. The
selective element of our approach avoids the counterproductive fusion of every
reference image and enables the dynamic selection of informative reference
images in environments with changing visual conditions (such as indoors with
flickering lights, outdoors during sunshowers or over the day-night cycle). The
probabilistic element of our approach provides a means of fusing multiple
reference images that accounts for their varying uncertainty via a novel
training-free likelihood function for VPR. On difficult query images from two
benchmark datasets, we demonstrate that our approach matches and exceeds the
performance of several alternative fusion approaches along with
state-of-the-art techniques that are provided with prior (unfair) knowledge of
the best reference images. Our approach is well suited for long-term robot
autonomy where dynamic visual environments are commonplace since it is
training-free, descriptor-agnostic, and complements existing techniques such as
sequence matching.
</p>
<a href="http://arxiv.org/abs/2010.09228" target="_blank">arXiv:2010.09228</a> [<a href="http://arxiv.org/pdf/2010.09228" target="_blank">pdf</a>]

<h2>Hierarchical Conditional Relation Networks for Multimodal Video Question Answering. (arXiv:2010.10019v2 [cs.CV] UPDATED)</h2>
<h3>Thao Minh Le, Vuong Le, Svetha Venkatesh, Truyen Tran</h3>
<p>Video QA challenges modelers in multiple fronts. Modeling video necessitates
building not only spatio-temporal models for the dynamic visual channel but
also multimodal structures for associated information channels such as
subtitles or audio. Video QA adds at least two more layers of complexity -
selecting relevant content for each channel in the context of the linguistic
query, and composing spatio-temporal concepts and relations in response to the
query. To address these requirements, we start with two insights: (a) content
selection and relation construction can be jointly encapsulated into a
conditional computational structure, and (b) video-length structures can be
composed hierarchically. For (a) this paper introduces a general-reusable
neural unit dubbed Conditional Relation Network (CRN) taking as input a set of
tensorial objects and translating into a new set of objects that encode
relations of the inputs. The generic design of CRN helps ease the common
complex model building process of Video QA by simple block stacking with
flexibility in accommodating input modalities and conditioning features across
both different domains. As a result, we realize insight (b) by introducing
Hierarchical Conditional Relation Networks (HCRN) for Video QA. The HCRN
primarily aims at exploiting intrinsic properties of the visual content of a
video and its accompanying channels in terms of compositionality, hierarchy,
and near and far-term relation. HCRN is then applied for Video QA in two forms,
short-form where answers are reasoned solely from the visual content, and
long-form where associated information, such as subtitles, presented. Our
rigorous evaluations show consistent improvements over SOTAs on well-studied
benchmarks including large-scale real-world datasets such as TGIF-QA and TVQA,
demonstrating the strong capabilities of our CRN unit and the HCRN for complex
domains such as Video QA.
</p>
<a href="http://arxiv.org/abs/2010.10019" target="_blank">arXiv:2010.10019</a> [<a href="http://arxiv.org/pdf/2010.10019" target="_blank">pdf</a>]

<h2>Adversarial Robustness of Supervised Sparse Coding. (arXiv:2010.12088v2 [cs.LG] UPDATED)</h2>
<h3>Jeremias Sulam, Ramchandran Muthukumar, Raman Arora</h3>
<p>Several recent results provide theoretical insights into the phenomena of
adversarial examples. Existing results, however, are often limited due to a gap
between the simplicity of the models studied and the complexity of those
deployed in practice. In this work, we strike a better balance by considering a
model that involves learning a representation while at the same time giving a
precise generalization bound and a robustness certificate. We focus on the
hypothesis class obtained by combining a sparsity-promoting encoder coupled
with a linear classifier, and show an interesting interplay between the
expressivity and stability of the (supervised) representation map and a notion
of margin in the feature space. We bound the robust risk (to $\ell_2$-bounded
perturbations) of hypotheses parameterized by dictionaries that achieve a mild
encoder gap on training data. Furthermore, we provide a robustness certificate
for end-to-end classification. We demonstrate the applicability of our analysis
by computing certified accuracy on real data, and compare with other
alternatives for certified robustness.
</p>
<a href="http://arxiv.org/abs/2010.12088" target="_blank">arXiv:2010.12088</a> [<a href="http://arxiv.org/pdf/2010.12088" target="_blank">pdf</a>]

<h2>CNN-Driven Quasiconformal Model for Large Deformation Image Registration. (arXiv:2011.00731v2 [cs.CV] UPDATED)</h2>
<h3>Ho Law, Gary P. T. Choi, Ka Chun Lam, Lok Ming Lui</h3>
<p>Image registration has been widely studied over the past several decades,
with numerous applications in science, engineering and medicine. Most of the
conventional mathematical models for large deformation image registration rely
on prescribed landmarks, which usually require tedious manual labeling and are
prone to error. In recent years, there has been a surge of interest in the use
of machine learning for image registration. However, most learning-based
methods cannot ensure the bijectivity of the registration, which makes it
difficult to establish a 1-1 correspondence between the images. In this paper,
we develop a novel method for large deformation image registration by a fusion
of convolutional neural network (CNN) and quasiconformal theory. More
specifically, we propose a new fidelity term for incorporating the CNN features
in our quasiconformal energy minimization model, which enables us to obtain
meaningful registration results without prescribing any landmarks. Moreover,
unlike other learning-based methods, the bijectivity of our method is
guaranteed by quasiconformal theory. Experimental results are presented to
demonstrate the effectiveness of the proposed method. More broadly, our work
sheds light on how rigorous mathematical theories and practical machine
learning approaches can be integrated for developing computational methods with
improved performance.
</p>
<a href="http://arxiv.org/abs/2011.00731" target="_blank">arXiv:2011.00731</a> [<a href="http://arxiv.org/pdf/2011.00731" target="_blank">pdf</a>]

<h2>Neural Stochastic Contraction Metrics for Learning-based Control and Estimation. (arXiv:2011.03168v4 [cs.LG] UPDATED)</h2>
<h3>Hiroyasu Tsukamoto, Soon-Jo Chung, Jean-Jacques E. Slotine</h3>
<p>We present Neural Stochastic Contraction Metrics (NSCM), a new design
framework for provably-stable robust control and estimation for a class of
stochastic nonlinear systems. It uses a spectrally-normalized deep neural
network to construct a contraction metric, sampled via simplified convex
optimization in the stochastic setting. Spectral normalization constrains the
state-derivatives of the metric to be Lipschitz continuous, thereby ensuring
exponential boundedness of the mean squared distance of system trajectories
under stochastic disturbances. The NSCM framework allows autonomous agents to
approximate optimal stable control and estimation policies in real-time, and
outperforms existing nonlinear control and estimation techniques including the
state-dependent Riccati equation, iterative LQR, EKF, and the deterministic
neural contraction metric, as illustrated in simulation results.
</p>
<a href="http://arxiv.org/abs/2011.03168" target="_blank">arXiv:2011.03168</a> [<a href="http://arxiv.org/pdf/2011.03168" target="_blank">pdf</a>]

<h2>AdCo: Adversarial Contrast for Efficient Learning of Unsupervised Representations from Self-Trained Negative Adversaries. (arXiv:2011.08435v3 [cs.LG] UPDATED)</h2>
<h3>Qianjiang Hu, Xiao Wang, Wei Hu, Guo-Jun Qi</h3>
<p>Contrastive learning relies on constructing a collection of negative examples
that are sufficiently hard to discriminate against positive queries when their
representations are self-trained. Existing contrastive learning methods either
maintain a queue of negative samples over minibatches while only a small
portion of them are updated in an iteration, or only use the other examples
from the current minibatch as negatives. They could not closely track the
change of the learned representation over iterations by updating the entire
queue as a whole, or discard the useful information from the past minibatches.
Alternatively, we present to directly learn a set of negative adversaries
playing against the self-trained representation. Two players, the
representation network and negative adversaries, are alternately updated to
obtain the most challenging negative examples against which the representation
of positive queries will be trained to discriminate. We further show that the
negative adversaries are updated towards a weighted combination of positive
queries by maximizing the adversarial contrastive loss, thereby allowing them
to closely track the change of representations over time. Experiment results
demonstrate the proposed Adversarial Contrastive (AdCo) model not only achieves
superior performances (a top-1 accuracy of 73.2\% over 200 epochs and 75.7\%
over 800 epochs with linear evaluation on ImageNet), but also can be
pre-trained more efficiently with fewer epochs.
</p>
<a href="http://arxiv.org/abs/2011.08435" target="_blank">arXiv:2011.08435</a> [<a href="http://arxiv.org/pdf/2011.08435" target="_blank">pdf</a>]

<h2>Causal Contextual Prediction for Learned Image Compression. (arXiv:2011.09704v3 [cs.CV] UPDATED)</h2>
<h3>Zongyu Guo, Zhizheng Zhang, Runsen Feng, Zhibo Chen</h3>
<p>Over the past several years, we have witnessed impressive progress in the
field of learned image compression. Recent learned image codecs are commonly
based on autoencoders, that first encode an image into low-dimensional latent
representations and then decode them for reconstruction purposes. To capture
spatial dependencies in the latent space, prior works exploit hyperprior and
spatial context model to build an entropy model, which estimates the bit-rate
for end-to-end rate-distortion optimization. However, such an entropy model is
suboptimal from two aspects: (1) It fails to capture spatially global
correlations among the latents. (2) Cross-channel relationships of the latents
are still underexplored. In this paper, we propose the concept of separate
entropy coding to leverage a serial decoding process for causal contextual
entropy prediction in the latent space. A causal context model is proposed that
separates the latents across channels and makes use of cross-channel
relationships to generate highly informative contexts. Furthermore, we propose
a causal global prediction model, which is able to find global reference points
for accurate predictions of unknown points. Both these two models facilitate
entropy estimation without the transmission of overhead. In addition, we
further adopt a new separate attention module to build more powerful transform
networks. Experimental results demonstrate that our full image compression
model outperforms standard VVC/H.266 codec on Kodak dataset in terms of both
PSNR and MS-SSIM, yielding the state-of-the-art rate-distortion performance.
</p>
<a href="http://arxiv.org/abs/2011.09704" target="_blank">arXiv:2011.09704</a> [<a href="http://arxiv.org/pdf/2011.09704" target="_blank">pdf</a>]

<h2>A Formal Approach to the Co-Design of Embodied Intelligence. (arXiv:2011.10756v2 [cs.RO] UPDATED)</h2>
<h3>Gioele Zardini, Dejan Milojevic, Andrea Censi, Emilio Frazzoli</h3>
<p>We consider the problem of formally co-designing embodied intelligence as a
whole, from hardware components such as chassis and sensors to software modules
such as control and perception pipelines. We propose a principled approach to
formulate and solve complex embodied intelligence co-design problems,
leveraging a monotone co-design theory. The methods we propose are intuitive
and integrate heterogeneous engineering disciplines, allowing analytical and
simulation-based modeling techniques and enabling interdisciplinarity. We
illustrate through a case study how, given a set of desired behaviors, our
framework is able to compute Pareto efficient solutions for the entire hardware
and software stack of a self-driving vehicle.
</p>
<a href="http://arxiv.org/abs/2011.10756" target="_blank">arXiv:2011.10756</a> [<a href="http://arxiv.org/pdf/2011.10756" target="_blank">pdf</a>]

<h2>Hawkes Processes Modeling, Inference and Control: An Overview. (arXiv:2011.13073v2 [cs.LG] UPDATED)</h2>
<h3>Rafael Lima</h3>
<p>Hawkes Processes are a type of point process which models self-excitement
among time events. It has been used in a myriad of applications, ranging from
finance and earthquakes to crime rates and social network activity
analysis.Recently, a surge of different tools and algorithms have showed their
way up to top-tier Machine Learning conferences. This work aims to give a broad
view of the recent advances on the Hawkes Processes modeling and inference to a
newcomer to the field.
</p>
<a href="http://arxiv.org/abs/2011.13073" target="_blank">arXiv:2011.13073</a> [<a href="http://arxiv.org/pdf/2011.13073" target="_blank">pdf</a>]

<h2>A method for large diffeomorphic registration via broken geodesics. (arXiv:2011.14298v2 [cs.CV] UPDATED)</h2>
<h3>Alphin J. Thottupattu, Jayanthi Sivaswamy, Venkateswaran P. Krishnan</h3>
<p>Anatomical variabilities seen in longitudinal data or inter-subject data is
usually described by the underlying deformation, captured by non-rigid
registration of these images. Stationary Velocity Field (SVF) based non-rigid
registration algorithms are widely used for registration. SVF based methods
form a metric-free framework which captures a finite dimensional submanifold of
deformations embedded in the infinite dimensional smooth manifold of
diffeomorphisms. However, these methods cover only a limited degree of
deformations. In this paper, we address this limitation and define an
approximate metric space for the manifold of diffeomorphisms $\mathcal{G}$. We
propose a method to break down the large deformation into finite compositions
of small deformations. This results in a broken geodesic path on $\mathcal{G}$
and its length now forms an approximate registration metric. We illustrate the
method using a simple, intensity-based, log-demon implementation. Validation
results of the proposed method show that it can capture large and complex
deformations while producing qualitatively better results than the
state-of-the-art methods. The results also demonstrate that the proposed
registration metric is a good indicator of the degree of deformation.
</p>
<a href="http://arxiv.org/abs/2011.14298" target="_blank">arXiv:2011.14298</a> [<a href="http://arxiv.org/pdf/2011.14298" target="_blank">pdf</a>]

<h2>Reset-Free Lifelong Learning with Skill-Space Planning. (arXiv:2012.03548v2 [cs.LG] UPDATED)</h2>
<h3>Kevin Lu, Aditya Grover, Pieter Abbeel, Igor Mordatch</h3>
<p>The objective of lifelong reinforcement learning (RL) is to optimize agents
which can continuously adapt and interact in changing environments. However,
current RL approaches fail drastically when environments are non-stationary and
interactions are non-episodic. We propose Lifelong Skill Planning (LiSP), an
algorithmic framework for non-episodic lifelong RL based on planning in an
abstract space of higher-order skills. We learn the skills in an unsupervised
manner using intrinsic rewards and plan over the learned skills using a learned
dynamics model. Moreover, our framework permits skill discovery even from
offline data, thereby reducing the need for excessive real-world interactions.
We demonstrate empirically that LiSP successfully enables long-horizon planning
and learns agents that can avoid catastrophic failures even in challenging
non-stationary and non-episodic environments derived from gridworld and MuJoCo
benchmarks.
</p>
<a href="http://arxiv.org/abs/2012.03548" target="_blank">arXiv:2012.03548</a> [<a href="http://arxiv.org/pdf/2012.03548" target="_blank">pdf</a>]

<h2>A New Window Loss Function for Bone Fracture Detection and Localization in X-ray Images with Point-based Annotation. (arXiv:2012.04066v2 [cs.CV] UPDATED)</h2>
<h3>Xinyu Zhang, Yirui Wang, Chi-Tung Cheng, Le Lu, Adam P. Harrison, Jing Xiao, Chien-Hung Liao, Shun Miao</h3>
<p>Object detection methods are widely adopted for computer-aided diagnosis
using medical images. Anomalous findings are usually treated as objects that
are described by bounding boxes. Yet, many pathological findings, e.g., bone
fractures, cannot be clearly defined by bounding boxes, owing to considerable
instance, shape and boundary ambiguities. This makes bounding box annotations,
and their associated losses, highly ill-suited. In this work, we propose a new
bone fracture detection method for X-ray images, based on a labor effective and
flexible annotation scheme suitable for abnormal findings with no clear
object-level spatial extents or boundaries. Our method employs a simple,
intuitive, and informative point-based annotation protocol to mark localized
pathology information. To address the uncertainty in the fracture scales
annotated via point(s), we convert the annotations into pixel-wise supervision
that uses lower and upper bounds with positive, negative, and uncertain
regions. A novel Window Loss is subsequently proposed to only penalize the
predictions outside of the uncertain regions. Our method has been extensively
evaluated on 4410 pelvic X-ray images of unique patients. Experiments
demonstrate that our method outperforms previous state-of-the-art image
classification and object detection baselines by healthy margins, with an AUROC
of 0.983 and FROC score of 89.6%.
</p>
<a href="http://arxiv.org/abs/2012.04066" target="_blank">arXiv:2012.04066</a> [<a href="http://arxiv.org/pdf/2012.04066" target="_blank">pdf</a>]

<h2>Image Captioning with Context-Aware Auxiliary Guidance. (arXiv:2012.05545v2 [cs.CV] UPDATED)</h2>
<h3>Zeliang Song, Xiaofei Zhou, Zhendong Mao, Jianlong Tan</h3>
<p>Image captioning is a challenging computer vision task, which aims to
generate a natural language description of an image. Most recent researches
follow the encoder-decoder framework which depends heavily on the previous
generated words for the current prediction. Such methods can not effectively
take advantage of the future predicted information to learn complete semantics.
In this paper, we propose Context-Aware Auxiliary Guidance (CAAG) mechanism
that can guide the captioning model to perceive global contexts. Upon the
captioning model, CAAG performs semantic attention that selectively
concentrates on useful information of the global predictions to reproduce the
current generation. To validate the adaptability of the method, we apply CAAG
to three popular captioners and our proposal achieves competitive performance
on the challenging Microsoft COCO image captioning benchmark, e.g. 132.2
CIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official
online evaluation server.
</p>
<a href="http://arxiv.org/abs/2012.05545" target="_blank">arXiv:2012.05545</a> [<a href="http://arxiv.org/pdf/2012.05545" target="_blank">pdf</a>]

<h2>Crowd-Driven Mapping, Localization and Planning. (arXiv:2012.10099v3 [cs.RO] UPDATED)</h2>
<h3>Tingxiang Fan, Dawei Wang, Wenxi Liu, Jia Pan</h3>
<p>Navigation in dense crowds is a well-known open problem in robotics with many
challenges in mapping, localization, and planning. Traditional solutions
consider dense pedestrians as passive/active moving obstacles that are the
cause of all troubles: they negatively affect the sensing of static scene
landmarks and must be actively avoided for safety. In this paper, we provide a
new perspective: the crowd flow locally observed can be treated as a sensory
measurement about the surrounding scenario, encoding not only the scene's
traversability but also its social navigation preference. We demonstrate that
even using the crowd-flow measurement alone without any sensing about static
obstacles, our method still accomplishes good results for mapping,
localization, and social-aware planning in dense crowds. Videos of the
experiments are available at https://sites.google.com/view/crowdmapping.
</p>
<a href="http://arxiv.org/abs/2012.10099" target="_blank">arXiv:2012.10099</a> [<a href="http://arxiv.org/pdf/2012.10099" target="_blank">pdf</a>]

<h2>Can Everybody Sign Now? Exploring Sign Language Video Generation from 2D Poses. (arXiv:2012.10941v2 [cs.CV] UPDATED)</h2>
<h3>Lucas Ventura, Amanda Duarte, Xavier Giro-i-Nieto</h3>
<p>Recent work have addressed the generation of human poses represented by 2D/3D
coordinates of human joints for sign language. We use the state of the art in
Deep Learning for motion transfer and evaluate them on How2Sign, an American
Sign Language dataset, to generate videos of signers performing sign language
given a 2D pose skeleton. We evaluate the generated videos quantitatively and
qualitatively showing that the current models are not enough to generated
adequate videos for Sign Language due to lack of detail in hands.
</p>
<a href="http://arxiv.org/abs/2012.10941" target="_blank">arXiv:2012.10941</a> [<a href="http://arxiv.org/pdf/2012.10941" target="_blank">pdf</a>]

<h2>Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification. (arXiv:2012.11212v2 [cs.LG] UPDATED)</h2>
<h3>Siyuan Cheng, Yingqi Liu, Shiqing Ma, Xiangyu Zhang</h3>
<p>Trojan (backdoor) attack is a form of adversarial attack on deep neural
networks where the attacker provides victims with a model trained/retrained on
malicious data. The backdoor can be activated when a normal input is stamped
with a certain pattern called trigger, causing misclassification. Many existing
trojan attacks have their triggers being input space patches/objects (e.g., a
polygon with solid color) or simple input transformations such as Instagram
filters. These simple triggers are susceptible to recent backdoor detection
algorithms. We propose a novel deep feature space trojan attack with five
characteristics: effectiveness, stealthiness, controllability, robustness and
reliance on deep features. We conduct extensive experiments on 9 image
classifiers on various datasets including ImageNet to demonstrate these
properties and show that our attack can evade state-of-the-art defense.
</p>
<a href="http://arxiv.org/abs/2012.11212" target="_blank">arXiv:2012.11212</a> [<a href="http://arxiv.org/pdf/2012.11212" target="_blank">pdf</a>]

<h2>Multi-shot NAS for Discovering Adversarially Robust Convolutional Neural Architectures at Targeted Capacities. (arXiv:2012.11835v2 [cs.AI] UPDATED)</h2>
<h3>Xuefei Ning, Junbo Zhao, Wenshuo Li, Tianchen Zhao, Huazhong Yang, Yu Wang</h3>
<p>Convolutional neural networks (CNNs) are vulnerable to adversarial examples,
and studies show that increasing the model capacity of an architecture topology
(e.g., width expansion) can bring consistent robustness improvements. This
reveals a clear robustness-efficiency trade-off that should be considered in
architecture design. Recent studies have employed one-shot neural architecture
search (NAS) to discover adversarially robust architectures. However, since the
capacities of different topologies cannot be easily aligned during the search
process, current one-shot NAS methods might favor topologies with larger
capacity in the supernet. And the discovered topology might be sub-optimal when
aligned to the targeted capacity. This paper proposes a novel multi-shot NAS
method to explicitly search for adversarially robust architectures at a certain
targeted capacity. Specifically, we estimate the reward at the targeted
capacity using interior extra-polation of the rewards from multiple supernets.
Experimental results demonstrate the effectiveness of the proposed method. For
instance, at the targeted FLOPs of 1560M, the discovered MSRobNet-1560 (clean
84.8%, PGD100 52.9%) outperforms the recent NAS-discovered architecture
RobNet-free (clean 82.8%, PGD100 52.6%) with similar FLOPs. Codes are available
at https://github.com/walkerning/aw_nas.
</p>
<a href="http://arxiv.org/abs/2012.11835" target="_blank">arXiv:2012.11835</a> [<a href="http://arxiv.org/pdf/2012.11835" target="_blank">pdf</a>]

<h2>Deep Learning-Based Human Pose Estimation: A Survey. (arXiv:2012.13392v3 [cs.CV] UPDATED)</h2>
<h3>Ce Zheng, Wenhan Wu, Taojiannan Yang, Sijie Zhu, Chen Chen, Ruixu Liu, Ju Shen, Nasser Kehtarnavaz, Mubarak Shah</h3>
<p>Human pose estimation aims to locate the human body parts and build human
body representation (e.g., body skeleton) from input data such as images and
videos. It has drawn increasing attention during the past decade and has been
utilized in a wide range of applications including human-computer interaction,
motion analysis, augmented reality, and virtual reality. Although the recently
developed deep learning-based solutions have achieved high performance in human
pose estimation, there still remain challenges due to insufficient training
data, depth ambiguities, and occlusion. The goal of this survey paper is to
provide a comprehensive review of recent deep learning-based solutions for both
2D and 3D pose estimation via a systematic analysis and comparison of these
solutions based on their input data and inference procedures. More than 240
research papers since 2014 are covered in this survey. Furthermore, 2D and 3D
human pose estimation datasets and evaluation metrics are included.
Quantitative performance comparisons of the reviewed methods on popular
datasets are summarized and discussed. Finally, the challenges involved,
applications, and future research directions are concluded. We also provide a
regularly updated project page: \url{https://github.com/zczcwh/DL-HPE}
</p>
<a href="http://arxiv.org/abs/2012.13392" target="_blank">arXiv:2012.13392</a> [<a href="http://arxiv.org/pdf/2012.13392" target="_blank">pdf</a>]

<h2>Self-supervised Pre-training with Hard Examples Improves Visual Representations. (arXiv:2012.13493v2 [cs.CV] UPDATED)</h2>
<h3>Chunyuan Li, Xiujun Li, Lei Zhang, Baolin Peng, Mingyuan Zhou, Jianfeng Gao</h3>
<p>Self-supervised pre-training (SSP) employs random image transformations to
generate training data for visual representation learning. In this paper, we
first present a modeling framework that unifies existing SSP methods as
learning to predict pseudo-labels. Then, we propose new data augmentation
methods of generating training examples whose pseudo-labels are harder to
predict than those generated via random image transformations. Specifically, we
use adversarial training and CutMix to create hard examples (HEXA) to be used
as augmented views for MoCo-v2 and DeepCluster-v2, leading to two variants
HEXA_{MoCo} and HEXA_{DCluster}, respectively. In our experiments, we pre-train
models on ImageNet and evaluate them on multiple public benchmarks. Our
evaluation shows that the two new algorithm variants outperform their original
counterparts, and achieve new state-of-the-art on a wide range of tasks where
limited task supervision is available for fine-tuning. These results verify
that hard examples are instrumental in improving the generalization of the
pre-trained models.
</p>
<a href="http://arxiv.org/abs/2012.13493" target="_blank">arXiv:2012.13493</a> [<a href="http://arxiv.org/pdf/2012.13493" target="_blank">pdf</a>]

<h2>Toward Real-World BCI: CCSPNet, A Compact Subject-Independent Motor Imagery Framework. (arXiv:2012.13567v2 [cs.LG] UPDATED)</h2>
<h3>Mahbod Nouri, Faraz Moradi, Hafez Ghaemi, Ali Motie Nasrabadi</h3>
<p>A conventional brain-computer interface (BCI) requires a complete data
gathering, training, and calibration phase for each user before it can be used.
This preliminary phase is time-consuming and should be done under the
supervision of technical experts commonly in laboratories for the BCI to
function properly. In recent years, a number of subject-independent (SI) BCIs
have been developed. However, there are many problems preventing them from
being used in real-world BCI applications. A lower accuracy than the
subject-dependent (SD) approach and a relatively high run-time of models with a
large number of model parameters are the most important ones. Therefore, a
real-world BCI application would greatly benefit from a compact
subject-independent BCI framework, ready to use immediately after the user puts
it on, and suitable for low-power edge-computing and applications in the
emerging area of internet of things (IoT). We propose a novel
subject-independent BCI framework named CCSPNet (Convolutional Common Spatial
Pattern Network) that is trained on the motor imagery (MI) paradigm of a
large-scale EEG signals database consisting of 400 trials for every 54 subjects
performing two-class hand-movement MI tasks. The proposed framework applies a
wavelet kernel convolutional neural network (WKCNN) and a temporal
convolutional neural network (TCNN) in order to represent and extract the
diverse frequency behavior and spectral patterns of EEG signals. The
convolutional layers outputs go through a CSP algorithm for class
discrimination and spatial feature extraction. The number of CSP features is
reduced by a dense neural network, and the final class label is determined by
an LDA. The final SD and SI classification accuracies of the proposed framework
match the best results obtained on the largest motor-imagery dataset present in
the BCI literature, with 99.993 percent fewer model parameters.
</p>
<a href="http://arxiv.org/abs/2012.13567" target="_blank">arXiv:2012.13567</a> [<a href="http://arxiv.org/pdf/2012.13567" target="_blank">pdf</a>]

<h2>POPO: Pessimistic Offline Policy Optimization. (arXiv:2012.13682v2 [cs.LG] UPDATED)</h2>
<h3>Qiang He, Xinwen Hou</h3>
<p>Offline reinforcement learning (RL), also known as batch RL, aims to optimize
policy from a large pre-recorded dataset without interaction with the
environment. This setting offers the promise of utilizing diverse,
pre-collected datasets to obtain policies without costly, risky, active
exploration. However, commonly used off-policy algorithms based on Q-learning
or actor-critic perform poorly when learning from a static dataset. In this
work, we study why off-policy RL methods fail to learn in offline setting from
the value function view, and we propose a novel offline RL algorithm that we
call Pessimistic Offline Policy Optimization (POPO), which learns a pessimistic
value function to get a strong policy. We find that POPO performs surprisingly
well and scales to tasks with high-dimensional state and action space,
comparing or outperforming several state-of-the-art offline RL algorithms on
benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2012.13682" target="_blank">arXiv:2012.13682</a> [<a href="http://arxiv.org/pdf/2012.13682" target="_blank">pdf</a>]

<h2>A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v3 [cs.LG] UPDATED)</h2>
<h3>Felix Leibfried, Vincent Dutordoir, ST John, Nicolas Durrande</h3>
<p>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model enjoys a posterior in closed form. However, identifying the posterior GP
scales cubically with the number of training examples and requires to store all
examples in memory. In order to overcome these obstacles, sparse GPs have been
proposed that approximate the true posterior GP with pseudo-training examples.
Importantly, the number of pseudo-training examples is user-defined and enables
control over computational and memory complexity. In the general case, sparse
GPs do not enjoy closed-form solutions and one has to resort to approximate
inference. In this context, a convenient choice for approximate inference is
variational inference (VI), where the problem of Bayesian inference is cast as
an optimization problem -- namely, to maximize a lower bound of the log
marginal likelihood. This paves the way for a powerful and versatile framework,
where pseudo-training examples are treated as optimization arguments of the
approximate posterior that are jointly identified together with hyperparameters
of the generative model (i.e. prior and likelihood). The framework can
naturally handle a wide scope of supervised learning problems, ranging from
regression with heteroscedastic and non-Gaussian likelihoods to classification
problems with discrete labels, but also multilabel problems. The purpose of
this tutorial is to provide access to the basic matter for readers without
prior knowledge in both GPs and VI. A proper exposition to the subject enables
also access to more recent advances (like importance-weighted VI as well as
inderdomain, multioutput and deep GPs) that can serve as an inspiration for new
research ideas.
</p>
<a href="http://arxiv.org/abs/2012.13962" target="_blank">arXiv:2012.13962</a> [<a href="http://arxiv.org/pdf/2012.13962" target="_blank">pdf</a>]

<h2>TensorX: Extensible API for Neural Network Model Design and Deployment. (arXiv:2012.14539v2 [cs.LG] UPDATED)</h2>
<h3>Davide Nunes, Luis Antunes</h3>
<p>TensorX is a Python library for prototyping, design, and deployment of
complex neural network models in TensorFlow. A special emphasis is put on ease
of use, performance, and API consistency. It aims to make available high-level
components like neural network layers that are, in effect, stateful functions,
easy to compose and reuse. Its architecture allows for the expression of
patterns commonly found when building neural network models either on research
or industrial settings. Incorporating ideas from several other deep learning
libraries, it makes it easy to use components commonly found in
state-of-the-art models. The library design mixes functional dataflow
computation graphs with object-oriented neural network building blocks. TensorX
combines the dynamic nature of Python with the high-performance GPU-enabled
operations of TensorFlow.

This library has minimal core dependencies (TensorFlow and NumPy) and is
distributed under Apache License 2.0 licence, encouraging its use in both an
academic and commercial settings. Full documentation, source code, and binaries
can be found in https://tensorx.org/.
</p>
<a href="http://arxiv.org/abs/2012.14539" target="_blank">arXiv:2012.14539</a> [<a href="http://arxiv.org/pdf/2012.14539" target="_blank">pdf</a>]

<h2>Accelerated NMR Spectroscopy: Merge Optimization with Deep Learning. (arXiv:2012.14830v2 [cs.LG] UPDATED)</h2>
<h3>Zi Wang, Di Guo, Yihui Huang, Zhangren Tu, Vladislav Orekhov, Xiaobo Qu</h3>
<p>Multi-dimensional NMR spectroscopy is an invaluable biophysical tool in
studies of structure, interactions, and dynamics of large molecules like
proteins and nuclear acids. Non-uniform sampling is a powerful approach for
shortening measurement time and increasing spectra resolution. Several methods
have been established for spectra reconstruction from the undersampled data,
typical approaches include model-based optimization and data-driven deep
learning. The former is well theoretically grounded and provides high-quality
spectra, while the latter has a huge advantage in reconstruction time potential
and push further limits of spectra quality and analysis. Combining the merits
of the two, we propose a model-inspired deep learning, for reliable,
high-quality, and ultra-fast spectra reconstruction, exemplified by
multi-dimensional spectra of several representative proteins. We demonstrate
that the proposed network needs very few parameters, and shows very high
robustness in respect to dissimilarity of the training and target data in the
spectra size, type, and sampling level. This work can be considered as a
proof-of-concept of merging optimization with deep learning in NMR
spectroscopy.
</p>
<a href="http://arxiv.org/abs/2012.14830" target="_blank">arXiv:2012.14830</a> [<a href="http://arxiv.org/pdf/2012.14830" target="_blank">pdf</a>]

<h2>Dynamic Graph-Based Anomaly Detection in the Electrical Grid. (arXiv:2012.15006v2 [cs.LG] UPDATED)</h2>
<h3>Shimiao Li, Amritanshu Pandey, Bryan Hooi, Christos Faloutsos, Larry Pileggi</h3>
<p>Given sensor readings over time from a power grid, how can we accurately
detect when an anomaly occurs? A key part of achieving this goal is to use the
network of power grid sensors to quickly detect, in real-time, when any unusual
events, whether natural faults or malicious, occur on the power grid. Existing
bad-data detectors in the industry lack the sophistication to robustly detect
broad types of anomalies, especially those due to emerging cyber-attacks, since
they operate on a single measurement snapshot of the grid at a time. New ML
methods are more widely applicable, but generally do not consider the impact of
topology change on sensor measurements and thus cannot accommodate regular
topology adjustments in historical data. Hence, we propose DYNWATCH, a domain
knowledge based and topology-aware algorithm for anomaly detection using
sensors placed on a dynamic grid. Our approach is accurate, outperforming
existing approaches by 20% or more (F-measure) in experiments; and fast,
running in less than 1.7ms on average per time tick per sensor on a 60K+ branch
case using a laptop computer, and scaling linearly in the size of the graph.
</p>
<a href="http://arxiv.org/abs/2012.15006" target="_blank">arXiv:2012.15006</a> [<a href="http://arxiv.org/pdf/2012.15006" target="_blank">pdf</a>]

<h2>Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients. (arXiv:2012.15019v2 [cs.LG] UPDATED)</h2>
<h3>Chris Cundy, Stefano Ermon</h3>
<p>As reinforcement learning techniques are increasingly applied to real-world
decision problems, attention has turned to how these algorithms use potentially
sensitive information. We consider the task of training a policy that maximizes
reward while minimizing disclosure of certain sensitive state variables through
the actions. We give examples of how this setting covers real-world problems in
privacy for sequential decision-making. We solve this problem in the policy
gradients framework by introducing a regularizer based on the mutual
information (MI) between the sensitive state and the actions at a given
timestep. We develop a model-based stochastic gradient estimator for
optimization of privacy-constrained policies. We also discuss an alternative MI
regularizer that serves as an upper bound to our main MI regularizer and can be
optimized in a model-free setting. We contrast previous work in
differentially-private RL to our mutual-information formulation of information
disclosure. Experimental results show that our training method results in
policies which hide the sensitive state.
</p>
<a href="http://arxiv.org/abs/2012.15019" target="_blank">arXiv:2012.15019</a> [<a href="http://arxiv.org/pdf/2012.15019" target="_blank">pdf</a>]

<h2>A Versatile Keyframe-Based Structureless Filter for Visual Inertial Odometry. (arXiv:2012.15170v2 [cs.RO] UPDATED)</h2>
<h3>Jianzhu Huai, Yukai Lin, Charles Toth, Yuan Zhuang, Dong Chen</h3>
<p>Motion estimation by fusing data from at least a camera and an Inertial
Measurement Unit (IMU) enables many applications in robotics. However, among
the multitude of Visual Inertial Odometry (VIO) methods, few efficiently
estimate device motion with consistent covariance, and calibrate sensor
parameters online for handling data from consumer sensors. This paper addresses
the gap with a Keyframe-based Structureless Filter (KSF). For efficiency,
landmarks are not included in the filter's state vector. For robustness, KSF
associates feature observations and manages state variables using the concept
of keyframes. For flexibility, KSF supports anytime calibration of IMU
systematic errors, as well as extrinsic, intrinsic, and temporal parameters of
each camera. Estimator consistency and observability of sensor parameters were
analyzed by simulation. Sensitivity to design options, e.g., feature matching
method and camera count was studied with the EuRoC benchmark. Sensor parameter
estimation was evaluated on raw TUM VI sequences and smartphone data. Moreover,
pose estimation accuracy was evaluated on EuRoC and TUM VI sequences versus
recent VIO methods. These tests confirm that KSF reliably calibrates sensor
parameters when the data contain adequate motion, and consistently estimate
motion with accuracy rivaling recent VIO methods. Our implementation runs at 42
Hz with stereo camera images on a consumer laptop.
</p>
<a href="http://arxiv.org/abs/2012.15170" target="_blank">arXiv:2012.15170</a> [<a href="http://arxiv.org/pdf/2012.15170" target="_blank">pdf</a>]

<h2>Accelerating ODE-Based Neural Networks on Low-Cost FPGAs. (arXiv:2012.15465v2 [cs.LG] UPDATED)</h2>
<h3>Hirohisa Watanabe, Hiroki Matsutani</h3>
<p>ODENet is a deep neural network architecture in which a stacking structure of
ResNet is implemented with an ordinary differential equation (ODE) solver. It
can reduce the number of parameters and strike a balance between accuracy and
performance by selecting a proper solver. It is also possible to improve the
accuracy while keeping the same number of parameters on resource-limited edge
devices. In this paper, using Euler method as an ODE solver, a part of ODENet
is implemented as a dedicated logic on a low-cost FPGA (Field-Programmable Gate
Array) board, such as PYNQ-Z2 board. Two variants, one for high accuracy and
the other for performance, are proposed and implemented on the FPGA board as
well. They are evaluated in terms of parameter size, accuracy, execution time,
and resource utilization on the FPGA. The results show that an overall
execution time of ODENet and its variants is improved by up to 2.50 times
compared to a pure software execution when a part of convolution layers is
executed by the programmable logic.
</p>
<a href="http://arxiv.org/abs/2012.15465" target="_blank">arXiv:2012.15465</a> [<a href="http://arxiv.org/pdf/2012.15465" target="_blank">pdf</a>]

<h2>A CNN Approach to Simultaneously Count Plants and Detect Plantation-Rows from UAV Imagery. (arXiv:2012.15827v2 [cs.CV] UPDATED)</h2>
<h3>Lucas Prado Osco, Mauro dos Santos de Arruda, Diogo Nunes Gon&#xe7;alves, Alexandre Dias, Juliana Batistoti, Mauricio de Souza, Felipe David Georges Gomes, Ana Paula Marques Ramos, L&#xfa;cio Andr&#xe9; de Castro Jorge, Veraldo Liesenberg, Jonathan Li, Lingfei Ma, Jos&#xe9; Marcato Junior, Wesley Nunes Gon&#xe7;alves</h3>
<p>In this paper, we propose a novel deep learning method based on a
Convolutional Neural Network (CNN) that simultaneously detects and geolocates
plantation-rows while counting its plants considering highly-dense plantation
configurations. The experimental setup was evaluated in a cornfield with
different growth stages and in a Citrus orchard. Both datasets characterize
different plant density scenarios, locations, types of crops, sensors, and
dates. A two-branch architecture was implemented in our CNN method, where the
information obtained within the plantation-row is updated into the plant
detection branch and retro-feed to the row branch; which are then refined by a
Multi-Stage Refinement method. In the corn plantation datasets (with both
growth phases, young and mature), our approach returned a mean absolute error
(MAE) of 6.224 plants per image patch, a mean relative error (MRE) of 0.1038,
precision and recall values of 0.856, and 0.905, respectively, and an F-measure
equal to 0.876. These results were superior to the results from other deep
networks (HRNet, Faster R-CNN, and RetinaNet) evaluated with the same task and
dataset. For the plantation-row detection, our approach returned precision,
recall, and F-measure scores of 0.913, 0.941, and 0.925, respectively. To test
the robustness of our model with a different type of agriculture, we performed
the same task in the citrus orchard dataset. It returned an MAE equal to 1.409
citrus-trees per patch, MRE of 0.0615, precision of 0.922, recall of 0.911, and
F-measure of 0.965. For citrus plantation-row detection, our approach resulted
in precision, recall, and F-measure scores equal to 0.965, 0.970, and 0.964,
respectively. The proposed method achieved state-of-the-art performance for
counting and geolocating plants and plant-rows in UAV images from different
types of crops.
</p>
<a href="http://arxiv.org/abs/2012.15827" target="_blank">arXiv:2012.15827</a> [<a href="http://arxiv.org/pdf/2012.15827" target="_blank">pdf</a>]

<h2>Binary Graph Neural Networks. (arXiv:2012.15823v1 [cs.LG] CROSS LISTED)</h2>
<h3>Mehdi Bahri, Ga&#xe9;tan Bahl, Stefanos Zafeiriou</h3>
<p>Graph Neural Networks (GNNs) have emerged as a powerful and flexible
framework for representation learning on irregular data. As they generalize the
operations of classical CNNs on grids to arbitrary topologies, GNNs also bring
much of the implementation challenges of their Euclidean counterparts. Model
size, memory footprint, and energy consumption are common concerns for many
real-world applications. Network binarization allocates a single bit to network
parameters and activations, thus dramatically reducing the memory requirements
(up to 32x compared to single-precision floating-point parameters) and
maximizing the benefits of fast SIMD instructions of modern hardware for
measurable speedups. However, in spite of the large body of work on
binarization for classical CNNs, this area remains largely unexplored in
geometric deep learning. In this paper, we present and evaluate different
strategies for the binarization of graph neural networks. We show that through
careful design of the models, and control of the training process, binary graph
neural networks can be trained at only a moderate cost in accuracy on
challenging benchmarks. In particular, we present the first dynamic graph
neural network in Hamming space, able to leverage efficient $k$-NN search on
binary vectors to speed-up the construction of the dynamic graph. We further
verify that the binary models offer significant savings on embedded devices.
</p>
<a href="http://arxiv.org/abs/2012.15823" target="_blank">arXiv:2012.15823</a> [<a href="http://arxiv.org/pdf/2012.15823" target="_blank">pdf</a>]

<h2>Factor Analysis, Probabilistic Principal Component Analysis, Variational Inference, and Variational Autoencoder: Tutorial and Survey. (arXiv:2101.00734v1 [stat.ML])</h2>
<h3>Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley</h3>
<p>This is a tutorial and survey paper on factor analysis, probabilistic
Principal Component Analysis (PCA), variational inference, and Variational
Autoencoder (VAE). These methods, which are tightly related, are dimensionality
reduction and generative models. They asssume that every data point is
generated from or caused by a low-dimensional latent factor. By learning the
parameters of distribution of latent space, the corresponding low-dimensional
factors are found for the sake of dimensionality reduction. For their
stochastic and generative behaviour, these models can also be used for
generation of new data points in the data space. In this paper, we first start
with variational inference where we derive the Evidence Lower Bound (ELBO) and
Expectation Maximization (EM) for learning the parameters. Then, we introduce
factor analysis, derive its joint and marginal distributions, and work out its
EM steps. Probabilistic PCA is then explained, as a special case of factor
analysis, and its closed-form solutions are derived. Finally, VAE is explained
where the encoder, decoder and sampling from the latent space are introduced.
Training VAE using both EM and backpropagation are explained.
</p>
<a href="http://arxiv.org/abs/2101.00734" target="_blank">arXiv:2101.00734</a> [<a href="http://arxiv.org/pdf/2101.00734" target="_blank">pdf</a>]

<h2>Gaussian Function On Response Surface Estimation. (arXiv:2101.00772v1 [cs.LG])</h2>
<h3>Mohammadhossein Toutiaee, John Miller</h3>
<p>We propose a new framework for 2-D interpreting (features and samples)
black-box machine learning models via a metamodeling technique, by which we
study the output and input relationships of the underlying machine learning
model. The metamodel can be estimated from data generated via a trained complex
model by running the computer experiment on samples of data in the region of
interest. We utilize a Gaussian process as a surrogate to capture the response
surface of a complex model, in which we incorporate two parts in the process:
interpolated values that are modeled by a stationary Gaussian process Z
governed by a prior covariance function, and a mean function mu that captures
the known trends in the underlying model. The optimization procedure for the
variable importance parameter theta is to maximize the likelihood function.
This theta corresponds to the correlation of individual variables with the
target response. There is no need for any pre-assumed models since it depends
on empirical observations. Experiments demonstrate the potential of the
interpretable model through quantitative assessment of the predicted samples.
</p>
<a href="http://arxiv.org/abs/2101.00772" target="_blank">arXiv:2101.00772</a> [<a href="http://arxiv.org/pdf/2101.00772" target="_blank">pdf</a>]

<h2>AutoEncoder for Interpolation. (arXiv:2101.00853v1 [stat.ML])</h2>
<h3>Rahul Bhadani</h3>
<p>In physical science, sensor data are collected over time to produce
timeseries data. However, depending on the real-world condition and underlying
physics of the sensor, data might be noisy. Besides, the limitation of
sample-time on sensors may not allow collecting data over all the timepoints,
may require some form of interpolation. Interpolation may not be smooth enough,
fail to denoise data, and derivative operation on noisy sensor data may be poor
that do not reveal any high order dynamics. In this article, we propose to use
AutoEncoder to perform interpolation that also denoise data simultaneously. A
brief example using a real-world is also provided.
</p>
<a href="http://arxiv.org/abs/2101.00853" target="_blank">arXiv:2101.00853</a> [<a href="http://arxiv.org/pdf/2101.00853" target="_blank">pdf</a>]

<h2>Data driven Dirichlet sampling on manifolds. (arXiv:2101.00947v1 [stat.ML])</h2>
<h3>Luan S Prado, Thiago G Ritto</h3>
<p>This article presents a novel method to sampling on manifolds based on the
Dirichlet distribution. The proposed strategy allows to completely respect the
underlying manifold around which data is observed, and to do massive samplings
with low computational effort. This can be very helpful, for instance, in
neural networks training process, as well as in uncertainty analysis and
stochastic optimization. Due to its simplicity and efficiency, we believe that
the new method has great potential. Three manifolds (two dimensional ring,
Mobius strip and spider geometry) are considered to test the proposed
methodology, and then it is employed to an engineering application, related to
gas seal coefficients.
</p>
<a href="http://arxiv.org/abs/2101.00947" target="_blank">arXiv:2101.00947</a> [<a href="http://arxiv.org/pdf/2101.00947" target="_blank">pdf</a>]

<h2>Mangrove Geographic Distribution Over Time. (arXiv:2101.00967v1 [cs.LG])</h2>
<h3>Lynn Wahab, Ezzat Chebaro, Jad Ismail, Amir Nasrelddine, Ali El-Zein</h3>
<p>Climate change has always been an impending disaster, and is becoming an
issue of pressing concern more and more every year. Countless efforts have been
made to study the long-term effects of climate change, however this data is
multifaceted in nature, and can be studied from a variety of angles. The goal
of our research is to study the available data on the population of mangroves -
groups of shrubs, or small trees, living in saline coastal intertidal zones,
and studying the change in their distribution over time. The change in global
distribution was studied based on distribution in the previous year, as well as
ocean heat content, salinity, temperature, halosteric sea level, thermosteric
sea level, and total steric sea level. The predictive model that performed
significantly better than the rest was a support vector regressor, which
yielded an $r^2$ value of 0.9998.
</p>
<a href="http://arxiv.org/abs/2101.00967" target="_blank">arXiv:2101.00967</a> [<a href="http://arxiv.org/pdf/2101.00967" target="_blank">pdf</a>]

<h2>Local Competition and Stochasticity for Adversarial Robustness in Deep Learning. (arXiv:2101.01121v1 [cs.LG])</h2>
<h3>Konstantinos P. Panousis, Sotirios Chatzis, Antonios Alexos, Sergios Theodoridis</h3>
<p>This work addresses adversarial robustness in deep learning by considering
deep networks with stochastic local winner-takes-all (LWTA) nonlinearities.
This type of network units result in sparse representations from each model
layer, as the units are organized in blocks where only one unit generates
non-zero output. The main operating principle of the introduced units lies on
stochastic arguments, as the network performs posterior sampling over competing
units to select the winner. We combine these LWTA arguments with tools from the
field of Bayesian non-parametrics, specifically the stick-breaking construction
of the Indian Buffet Process, to allow for inferring the sub-part of each layer
that is essential for modeling the data at hand. Inference for the proposed
network is performed by means of stochastic variational Bayes. We perform a
thorough experimental evaluation of our model using benchmark datasets,
assuming gradient-based adversarial attacks. As we show, our method achieves
high robustness to adversarial perturbations, with state-of-the-art performance
in powerful white-box attacks.
</p>
<a href="http://arxiv.org/abs/2101.01121" target="_blank">arXiv:2101.01121</a> [<a href="http://arxiv.org/pdf/2101.01121" target="_blank">pdf</a>]

<h2>Does Invariant Risk Minimization Capture Invariance?. (arXiv:2101.01134v1 [stat.ML])</h2>
<h3>Pritish Kamath, Akilesh Tangella, Danica J. Sutherland, Nathan Srebro</h3>
<p>We show that the Invariant Risk Minimization (IRM) formulation of Arjovsky et
al. (2019) can fail to capture "natural" invariances, at least when used in its
practical "linear" form, and even on very simple problems which directly follow
the motivating examples for IRM. This can lead to worse generalization on new
environments, even when compared to unconstrained ERM. The issue stems from a
significant gap between the linear variant (as in their concrete method IRMv1)
and the full non-linear IRM formulation. Additionally, even when capturing the
"right" invariances, we show that it is possible for IRM to learn a sub-optimal
predictor, due to the loss function not being invariant across environments.
The issues arise even when measuring invariance on the population
distributions, but are exacerbated by the fact that IRM is extremely fragile to
sampling.
</p>
<a href="http://arxiv.org/abs/2101.01134" target="_blank">arXiv:2101.01134</a> [<a href="http://arxiv.org/pdf/2101.01134" target="_blank">pdf</a>]

<h2>Provable Generalization of SGD-trained Neural Networks of Any Width in the Presence of Adversarial Label Noise. (arXiv:2101.01152v1 [cs.LG])</h2>
<h3>Spencer Frei, Yuan Cao, Quanquan Gu</h3>
<p>We consider a one-hidden-layer leaky ReLU network of arbitrary width trained
by stochastic gradient descent following an arbitrary initialization. We prove
that stochastic gradient descent (SGD) produces neural networks that have
classification accuracy competitive with that of the best halfspace over the
distribution for a broad class of distributions that includes log-concave
isotropic and hard margin distributions. Equivalently, such networks can
generalize when the data distribution is linearly separable but corrupted with
adversarial label noise, despite the capacity to overfit. We conduct
experiments which suggest that for some distributions our generalization bounds
are nearly tight. This is the first result that shows that overparameterized
neural networks trained by SGD can generalize when the data is corrupted with
adversarial label noise.
</p>
<a href="http://arxiv.org/abs/2101.01152" target="_blank">arXiv:2101.01152</a> [<a href="http://arxiv.org/pdf/2101.01152" target="_blank">pdf</a>]

<h2>SmartDeal: Re-Modeling Deep Network Weights for Efficient Inference and Training. (arXiv:2101.01163v1 [cs.LG])</h2>
<h3>Xiaohan Chen, Yang Zhao, Yue Wang, Pengfei Xu, Haoran You, Chaojian Li, Yonggan Fu, Yingyan Lin, Zhangyang Wang</h3>
<p>The record-breaking performance of deep neural networks (DNNs) comes with
heavy parameterization, leading to external dynamic random-access memory (DRAM)
for storage. The prohibitive energy of DRAM accesses makes it non-trivial to
deploy DNN on resource-constrained devices, calling for minimizing the weight
and data movements to improve the energy efficiency. We present SmartDeal (SD),
an algorithm framework to trade higher-cost memory storage/access for
lower-cost computation, in order to aggressively boost the storage and energy
efficiency, for both inference and training. The core of SD is a novel weight
decomposition with structural constraints, carefully crafted to unleash the
hardware efficiency potential. Specifically, we decompose each weight tensor as
the product of a small basis matrix and a large structurally sparse coefficient
matrix whose non-zeros are quantized to power-of-2. The resulting sparse and
quantized DNNs enjoy greatly reduced energy for data movement and weight
storage, incurring minimal overhead to recover the original weights thanks to
the sparse bit-operations and cost-favorable computations. Beyond inference, we
take another leap to embrace energy-efficient training, introducing innovative
techniques to address the unique roadblocks arising in training while
preserving the SD structures. We also design a dedicated hardware accelerator
to fully utilize the SD structure to improve the real energy efficiency and
latency. We conduct experiments on both multiple tasks, models and datasets in
different settings. Results show that: 1) applied to inference, SD achieves up
to 2.44x energy efficiency as evaluated via real hardware implementations; 2)
applied to training, SD leads to 10.56x and 4.48x reduction in the storage and
training energy, with negligible accuracy loss compared to state-of-the-art
training baselines. Our source codes are available online.
</p>
<a href="http://arxiv.org/abs/2101.01163" target="_blank">arXiv:2101.01163</a> [<a href="http://arxiv.org/pdf/2101.01163" target="_blank">pdf</a>]

