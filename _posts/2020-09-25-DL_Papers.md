---
title: Latest Deep Learning Papers
date: 2021-02-21 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (140 Articles)</h1>
<h2>A Deep Embedded Refined Clustering Approach for Breast Cancer Distinction based on DNA Methylation. (arXiv:2102.09563v1 [cs.LG])</h2>
<h3>del Amor Roc&#xed;o, Colomer Adri&#xe1;n, Monteagudo Carlos, Naranjo Valery</h3>
<p>Epigenetic alterations have an important role in the development of several
types of cancer. Epigenetic studies generate a large amount of data, which
makes it essential to develop novel models capable of dealing with large-scale
data. In this work, we propose a deep embedded refined clustering method for
breast cancer differentiation based on DNA methylation. In concrete, the deep
learning system presented here uses the levels of CpG island methylation
between 0 and 1. The proposed approach is composed of two main stages. The
first stage consists in the dimensionality reduction of the methylation data
based on an autoencoder. The second stage is a clustering algorithm based on
the soft-assignment of the latent space provided by the autoencoder. The whole
method is optimized through a weighted loss function composed of two terms:
reconstruction and classification terms. To the best of the authors' knowledge,
no previous studies have focused on the dimensionality reduction algorithms
linked to classification trained end-to-end for DNA methylation analysis. The
proposed method achieves an unsupervised clustering accuracy of 0.9927 and an
error rate (%) of 0.73 on 137 breast tissue samples. After a second test of the
deep-learning-based method using a different methylation database, an accuracy
of 0.9343 and an error rate (%) of 6.57 on 45 breast tissue samples is
obtained. Based on these results, the proposed algorithm outperforms other
state-of-the-art methods evaluated under the same conditions for breast cancer
classification based on DNA methylation data.
</p>
<a href="http://arxiv.org/abs/2102.09563" target="_blank">arXiv:2102.09563</a> [<a href="http://arxiv.org/pdf/2102.09563" target="_blank">pdf</a>]

<h2>Benefits of Linear Conditioning for Segmentation using Metadata. (arXiv:2102.09582v1 [cs.CV])</h2>
<h3>Andreanne Lemay, Charley Gros, Olivier Vincent, Yaou Liu, Joseph Paul Cohen, Julien Cohen-Adad</h3>
<p>Medical images are often accompanied by metadata describing the image
(vendor, acquisition parameters) and the patient (disease type or severity,
demographics, genomics). This metadata is usually disregarded by image
segmentation methods. In this work, we adapt a linear conditioning method
called FiLM (Feature-wise Linear Modulation) for image segmentation tasks. This
FiLM adaptation enables integrating metadata into segmentation models for
better performance. We observed an average Dice score increase of 5.1% on
spinal cord tumor segmentation when incorporating the tumor type with FiLM. The
metadata modulates the segmentation process through low-cost affine
transformations applied on feature maps which can be included in any neural
network's architecture. Additionally, we assess the relevance of segmentation
FiLM layers for tackling common challenges in medical imaging: training with
limited or unbalanced number of annotated data, multi-class training with
missing segmentations, and model adaptation to multiple tasks. Our results
demonstrated the following benefits of FiLM for segmentation: FiLMed U-Net was
robust to missing labels and reached higher Dice scores with few labels (up to
16.7%) compared to single-task U-Net. The code is open-source and available at
www.ivadomed.org.
</p>
<a href="http://arxiv.org/abs/2102.09582" target="_blank">arXiv:2102.09582</a> [<a href="http://arxiv.org/pdf/2102.09582" target="_blank">pdf</a>]

<h2>Interpretable Stability Bounds for Spectral Graph Filters. (arXiv:2102.09587v1 [cs.LG])</h2>
<h3>Henry Kenlay, Dorina Thanou, Xiaowen Dong</h3>
<p>Graph-structured data arise in a variety of real-world context ranging from
sensor and transportation to biological and social networks. As a ubiquitous
tool to process graph-structured data, spectral graph filters have been used to
solve common tasks such as denoising and anomaly detection, as well as design
deep learning architectures such as graph neural networks. Despite being an
important tool, there is a lack of theoretical understanding of the stability
properties of spectral graph filters, which are important for designing robust
machine learning models. In this paper, we study filter stability and provide a
novel and interpretable upper bound on the change of filter output, where the
bound is expressed in terms of the endpoint degrees of the deleted and newly
added edges, as well as the spatial proximity of those edges. This upper bound
allows us to reason, in terms of structural properties of the graph, when a
spectral graph filter will be stable. We further perform extensive experiments
to verify intuition that can be gained from the bound.
</p>
<a href="http://arxiv.org/abs/2102.09587" target="_blank">arXiv:2102.09587</a> [<a href="http://arxiv.org/pdf/2102.09587" target="_blank">pdf</a>]

<h2>A Differential Geometry Perspective on Orthogonal Recurrent Models. (arXiv:2102.09589v1 [cs.LG])</h2>
<h3>Omri Azencot, N. Benjamin Erichson, Mirela Ben-Chen, Michael W. Mahoney</h3>
<p>Recently, orthogonal recurrent neural networks (RNNs) have emerged as
state-of-the-art models for learning long-term dependencies. This class of
models mitigates the exploding and vanishing gradients problem by design. In
this work, we employ tools and insights from differential geometry to offer a
novel perspective on orthogonal RNNs. We show that orthogonal RNNs may be
viewed as optimizing in the space of divergence-free vector fields.
Specifically, based on a well-known result in differential geometry that
relates vector fields and linear operators, we prove that every divergence-free
vector field is related to a skew-symmetric matrix. Motivated by this
observation, we study a new recurrent model, which spans the entire space of
vector fields. Our method parameterizes vector fields via the directional
derivatives of scalar functions. This requires the construction of latent inner
product, gradient, and divergence operators. In comparison to state-of-the-art
orthogonal RNNs, our approach achieves comparable or better results on a
variety of benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2102.09589" target="_blank">arXiv:2102.09589</a> [<a href="http://arxiv.org/pdf/2102.09589" target="_blank">pdf</a>]

<h2>Privacy-Preserving Teacher-Student Deep Reinforcement Learning. (arXiv:2102.09599v1 [cs.LG])</h2>
<h3>Parham Gohari, Bo Chen, Bo Wu, Matthew Hale, Ufuk Topcu</h3>
<p>Deep reinforcement learning agents may learn complex tasks more efficiently
when they coordinate with one another. We consider a teacher-student
coordination scheme wherein an agent may ask another agent for demonstrations.
Despite the benefits of sharing demonstrations, however, potential adversaries
may obtain sensitive information belonging to the teacher by observing the
demonstrations. In particular, deep reinforcement learning algorithms are known
to be vulnerable to membership attacks, which make accurate inferences about
the membership of the entries of training datasets. Therefore, there is a need
to safeguard the teacher against such privacy threats. We fix the teacher's
policy as the context of the demonstrations, which allows for different
internal models across the student and the teacher, and contrasts the existing
methods. We make the following two contributions. (i) We develop a
differentially private mechanism that protects the privacy of the teacher's
training dataset. (ii) We propose a proximal policy-optimization objective that
enables the student to benefit from the demonstrations despite the
perturbations of the privacy mechanism. We empirically show that the algorithm
improves the student's learning upon convergence rate and utility.
Specifically, compared with an agent who learns the same task on its own, we
observe that the student's policy converges faster, and the converging policy
accumulates higher rewards more robustly.
</p>
<a href="http://arxiv.org/abs/2102.09599" target="_blank">arXiv:2102.09599</a> [<a href="http://arxiv.org/pdf/2102.09599" target="_blank">pdf</a>]

<h2>Improving DeepFake Detection Using Dynamic Face Augmentation. (arXiv:2102.09603v1 [cs.CV])</h2>
<h3>Sowmen Das, Arup Datta, Md. Saiful Islam, Md. Ruhul Amin</h3>
<p>The creation of altered and manipulated faces has become more common due to
the improvement of DeepFake generation methods. Simultaneously, we have seen
detection models' development for differentiating between a manipulated and
original face from image or video content. We have observed that most publicly
available DeepFake detection datasets have limited variations, where a single
face is used in many videos, resulting in an oversampled training dataset. Due
to this, deep neural networks tend to overfit to the facial features instead of
learning to detect manipulation features of DeepFake content. As a result, most
detection architectures perform poorly when tested on unseen data. In this
paper, we provide a quantitative analysis to investigate this problem and
present a solution to prevent model overfitting due to the high volume of
samples generated from a small number of actors. We introduce Face-Cutout, a
data augmentation method for training Convolutional Neural Networks (CNN), to
improve DeepFake detection. In this method, training images with various
occlusions are dynamically generated using face landmark information
irrespective of orientation. Unlike other general-purpose augmentation methods,
it focuses on the facial information that is crucial for DeepFake detection.
Our method achieves a reduction in LogLoss of 15.2% to 35.3% on different
datasets, compared to other occlusion-based augmentation techniques. We show
that Face-Cutout can be easily integrated with any CNN-based recognition model
and improve detection performance.
</p>
<a href="http://arxiv.org/abs/2102.09603" target="_blank">arXiv:2102.09603</a> [<a href="http://arxiv.org/pdf/2102.09603" target="_blank">pdf</a>]

<h2>Modelling Paralinguistic Properties in Conversational Speech to Detect Bipolar Disorder and Borderline Personality Disorder. (arXiv:2102.09607v1 [cs.LG])</h2>
<h3>Bo Wang, Yue Wu, Nemanja Vaci, Maria Liakata, Terry Lyons, Kate E A Saunders</h3>
<p>Bipolar disorder (BD) and borderline personality disorder (BPD) are two
chronic mental health conditions that clinicians find challenging to
distinguish based on clinical interviews, due to their overlapping symptoms. In
this work, we investigate the automatic detection of these two conditions by
modelling both verbal and non-verbal cues in a set of interviews. We propose a
new approach of modelling short-term features with visibility-signature
transform, and compare it with widely used high-level statistical functions. We
demonstrate the superior performance of our proposed signature-based model.
Furthermore, we show the role of different sets of features in characterising
BD and BPD.
</p>
<a href="http://arxiv.org/abs/2102.09607" target="_blank">arXiv:2102.09607</a> [<a href="http://arxiv.org/pdf/2102.09607" target="_blank">pdf</a>]

<h2>A Simple Unified Framework for High Dimensional Bandit Problems. (arXiv:2102.09626v1 [cs.LG])</h2>
<h3>Wenjie Li, Adarsh Barik, Jean Honorio</h3>
<p>Stochastic high dimensional bandit problems with low dimensional structure
are useful in different applications such as online advertising and drug
discovery. In this work, we propose a simple unified algorithm for such
problems and present a general analysis framework for the regret upper bound of
our algorithm. We show that under some mild unified assumptions, our algorithm
can be applied to different high dimensional bandit problems. Our framework
utilizes the low dimensional structure to guide the parameter estimation in the
problem, therefore our algorithm achieves the best regret bounds in the LASSO
bandit, better bounds in the low-rank matrix bandit and the group sparse matrix
bandit, as well as a novel bound in the multi-agent LASSO bandit.
</p>
<a href="http://arxiv.org/abs/2102.09626" target="_blank">arXiv:2102.09626</a> [<a href="http://arxiv.org/pdf/2102.09626" target="_blank">pdf</a>]

<h2>Efficient Distributed Auto-Differentiation. (arXiv:2102.09631v1 [cs.LG])</h2>
<h3>Bradley T. Baker, Vince D. Calhoun, Barak Pearlmutter, Sergey M. Plis</h3>
<p>Although distributed machine learning has opened up numerous frontiers of
research, the separation of large models across different devices, nodes, and
sites can invite significant communication overhead, making reliable training
difficult.

The focus on gradients as the primary shared statistic during training has
led to a number of intuitive algorithms for distributed deep learning; however,
gradient-based algorithms for training large deep neural networks (DNNs) are
communication-heavy, often requiring additional modifications via sparsity
constraints, compression, quantization, and other similar approaches, to lower
bandwidth.

We introduce a surprisingly simple statistic for training distributed DNNs
that is more communication-friendly than the gradient. The error
backpropagation process can be modified to share these smaller intermediate
values instead of the gradient, reducing communication overhead with no impact
on accuracy. The process provides the flexibility of averaging gradients during
backpropagation, enabling novel flexible training schemas while leaving room
for further bandwidth reduction via existing gradient compression methods.
Finally, consideration of the matrices used to compute the gradient inspires a
new approach to compression via structured power iterations, which can not only
reduce bandwidth but also enable introspection into distributed training
dynamics, without significant performance loss.
</p>
<a href="http://arxiv.org/abs/2102.09631" target="_blank">arXiv:2102.09631</a> [<a href="http://arxiv.org/pdf/2102.09631" target="_blank">pdf</a>]

<h2>Control Variate Approximation for DNN Accelerators. (arXiv:2102.09642v1 [cs.LG])</h2>
<h3>Georgios Zervakis, Ourania Spantidi, Iraklis Anagnostopoulos, Hussam Amrouch, J&#xf6;rg Henkel</h3>
<p>In this work, we introduce a control variate approximation technique for low
error approximate Deep Neural Network (DNN) accelerators. The control variate
technique is used in Monte Carlo methods to achieve variance reduction. Our
approach significantly decreases the induced error due to approximate
multiplications in DNN inference, without requiring time-exhaustive retraining
compared to state-of-the-art. Leveraging our control variate method, we use
highly approximated multipliers to generate power-optimized DNN accelerators.
Our experimental evaluation on six DNNs, for Cifar-10 and Cifar-100 datasets,
demonstrates that, compared to the accurate design, our control variate
approximation achieves same performance and 24% power reduction for a merely
0.16% accuracy loss.
</p>
<a href="http://arxiv.org/abs/2102.09642" target="_blank">arXiv:2102.09642</a> [<a href="http://arxiv.org/pdf/2102.09642" target="_blank">pdf</a>]

<h2>Attempted Blind Constrained Descent Experiments. (arXiv:2102.09643v1 [cs.LG])</h2>
<h3>Prasad N R</h3>
<p>Blind Descent uses constrained but, guided approach to learn the weights. The
probability density function is non-zero in the infinite space of the dimension
(case in point: Gaussians and normal probability distribution functions). In
Blind Descent paper, some of the implicit ideas involving layer by layer
training and filter by filter training (with different batch sizes) were
proposed as probable greedy solutions. The results of similar experiments are
discussed. Octave (and proposed PyTorch variants) source code of the
experiments of this paper can be found at
https://github.com/PrasadNR/Attempted-Blind-Constrained-Descent-Experiments-ABCDE-
. This is compared against the ABCDE derivatives of the original PyTorch source
code of https://github.com/akshat57/Blind-Descent .
</p>
<a href="http://arxiv.org/abs/2102.09643" target="_blank">arXiv:2102.09643</a> [<a href="http://arxiv.org/pdf/2102.09643" target="_blank">pdf</a>]

<h2>SVRG Meets AdaGrad: Painless Variance Reduction. (arXiv:2102.09645v1 [cs.LG])</h2>
<h3>Benjamin Dubois-Taine, Sharan Vaswani, Reza Babanezhad, Mark Schmidt, Simon Lacoste-Julien</h3>
<p>Variance reduction (VR) methods for finite-sum minimization typically require
the knowledge of problem-dependent constants that are often unknown and
difficult to estimate. To address this, we use ideas from adaptive gradient
methods to propose AdaSVRG, which is a fully adaptive variant of SVRG, a common
VR method. AdaSVRG uses AdaGrad in the inner loop of SVRG, making it robust to
the choice of step-size, and allowing it to adaptively determine the length of
each inner-loop. When minimizing a sum of $n$ smooth convex functions, we prove
that AdaSVRG requires $O(n + 1/\epsilon)$ gradient evaluations to achieve an
$\epsilon$-suboptimality, matching the typical rate, but without needing to
know problem-dependent constants. However, VR methods including AdaSVRG are
slower than SGD when used with over-parameterized models capable of
interpolating the training data. Hence, we also propose a hybrid algorithm that
can adaptively switch from AdaGrad to AdaSVRG, achieving the best of both
stochastic gradient and VR methods, but without needing to tune their
step-sizes. Via experiments on synthetic and standard real-world datasets, we
validate the robustness and effectiveness of AdaSVRG, demonstrating its
superior performance over other "tune-free" VR methods.
</p>
<a href="http://arxiv.org/abs/2102.09645" target="_blank">arXiv:2102.09645</a> [<a href="http://arxiv.org/pdf/2102.09645" target="_blank">pdf</a>]

<h2>Angular Path Integration by Projection Filtering with Increment Observations. (arXiv:2102.09650v1 [cs.RO])</h2>
<h3>Anna Kutschireiter, Luke Rast, Jan Drugowitsch</h3>
<p>Angular path integration is the ability of a system to estimate its own
heading direction from potentially noisy angular velocity (or increment)
observations. Despite its importance for robot and animal navigation, current
algorithms for angular path integration lack probabilistic descriptions that
take into account the reliability of such observations, which is essential for
appropriately weighing one's current heading direction estimate against
incoming information. In a probabilistic setting, angular path integration can
be formulated as a continuous-time nonlinear filtering problem (circular
filtering) with increment observations. The circular symmetry of heading
direction makes this inference task inherently nonlinear, thereby precluding
the use of popular inference algorithms such as Kalman filters and rendering
the problem analytically inaccessible. Here, we derive an approximate solution
to circular continuous-time filtering, which integrates increment observations
while maintaining a fixed representation through both state propagation and
observational updates. Specifically, we extend the established
projection-filtering method to account for increment observations and apply
this framework to the circular filtering problem. We further propose a
generative model for continuous-time angular-valued direct observations of the
hidden state, which we integrate seamlessly into the projection filter.
Applying the resulting scheme to a model of probabilistic angular path
integration, we derive an algorithm for circular filtering, which we term the
circular Kalman filter. Importantly, this algorithm is analytically accessible,
interpretable, and outperforms an alternative filter based on a Gaussian
approximation.
</p>
<a href="http://arxiv.org/abs/2102.09650" target="_blank">arXiv:2102.09650</a> [<a href="http://arxiv.org/pdf/2102.09650" target="_blank">pdf</a>]

<h2>Smart Feasibility Pump: Reinforcement Learning for (Mixed) Integer Programming. (arXiv:2102.09663v1 [cs.LG])</h2>
<h3>Meng Qi, Mengxin Wang, Zuo-Jun Shen</h3>
<p>In this work, we propose a deep reinforcement learning (DRL) model for
finding a feasible solution for (mixed) integer programming (MIP) problems.
Finding a feasible solution for MIP problems is critical because many
successful heuristics rely on a known initial feasible solution. However, it is
in general NP-hard. Inspired by the feasibility pump (FP), a well-known
heuristic for searching feasible MIP solutions, we develop a smart feasibility
pump (SFP) method using DRL. In addition to multi-layer perception (MLP), we
propose a novel convolution neural network (CNN) structure for the policy
network to capture the hidden information of the constraint matrix of the MIP
problem. Numerical experiments on various problem instances show that SFP
significantly outperforms the classic FP in terms of the number of steps
required to reach the first feasible solution. Moreover, the CNN structure
works without the projection of the current solution as the input, which saves
the computational effort at each step of the FP algorithms to find projections.
This highlights the representational power of the CNN structure.
</p>
<a href="http://arxiv.org/abs/2102.09663" target="_blank">arXiv:2102.09663</a> [<a href="http://arxiv.org/pdf/2102.09663" target="_blank">pdf</a>]

<h2>On Connectivity of Solutions in Deep Learning: The Role of Over-parameterization and Feature Quality. (arXiv:2102.09671v1 [cs.LG])</h2>
<h3>Quynh Nguyen, Pierre Brechet, Marco Mondelli</h3>
<p>It has been empirically observed that, in deep neural networks, the solutions
found by stochastic gradient descent from different random initializations can
be often connected by a path with low loss. Recent works have shed light on
this intriguing phenomenon by assuming either the over-parameterization of the
network or the dropout stability of the solutions. In this paper, we reconcile
these two views and present a novel condition for ensuring the connectivity of
two arbitrary points in parameter space. This condition is provably milder than
dropout stability, and it provides a connection between the problem of finding
low-loss paths and the memorization capacity of neural nets. This last point
brings about a trade-off between the quality of features at each layer and the
over-parameterization of the network. As an extreme example of this trade-off,
we show that (i) if subsets of features at each layer are linearly separable,
then almost no over-parameterization is needed, and (ii) under generic
assumptions on the features at each layer, it suffices that the last two hidden
layers have $\Omega(\sqrt{N})$ neurons, $N$ being the number of samples.
Finally, we provide experimental evidence demonstrating that the presented
condition is satisfied in practical settings even when dropout stability does
not hold.
</p>
<a href="http://arxiv.org/abs/2102.09671" target="_blank">arXiv:2102.09671</a> [<a href="http://arxiv.org/pdf/2102.09671" target="_blank">pdf</a>]

<h2>Improved Denoising Diffusion Probabilistic Models. (arXiv:2102.09672v1 [cs.LG])</h2>
<h3>Alex Nichol, Prafulla Dhariwal</h3>
<p>Denoising diffusion probabilistic models (DDPM) are a class of generative
models which have recently been shown to produce excellent samples. We show
that with a few simple modifications, DDPMs can also achieve competitive
log-likelihoods while maintaining high sample quality. Additionally, we find
that learning variances of the reverse diffusion process allows sampling with
an order of magnitude fewer forward passes with a negligible difference in
sample quality, which is important for the practical deployment of these
models. We additionally use precision and recall to compare how well DDPMs and
GANs cover the target distribution. Finally, we show that the sample quality
and likelihood of these models scale smoothly with model capacity and training
compute, making them easily scalable. We release our code at
https://github.com/openai/improved-diffusion
</p>
<a href="http://arxiv.org/abs/2102.09672" target="_blank">arXiv:2102.09672</a> [<a href="http://arxiv.org/pdf/2102.09672" target="_blank">pdf</a>]

<h2>Robust non-parametric mortality and fertility modelling and forecasting: Gaussian process regression approaches. (arXiv:2102.09676v1 [stat.ML])</h2>
<h3>Ka Kin Lam, Bo Wang</h3>
<p>A rapid decline in mortality and fertility has become major issues in many
developed countries over the past few decades. A precise model for forecasting
demographic movements is important for decision making in social welfare
policies and resource budgeting among the government and many industry sectors.
This article introduces a novel non-parametric approach using Gaussian process
regression with a natural cubic spline mean function and a spectral mixture
covariance function for mortality and fertility modelling and forecasting.
Unlike most of the existing approaches in demographic modelling literature,
which rely on time parameters to decide the movements of the whole mortality or
fertility curve shifting from one year to another over time, we consider the
mortality and fertility curves from their components of all age-specific
mortality and fertility rates and assume each of them following a Gaussian
process over time to fit the whole curves in a discrete but intensive style.
The proposed Gaussian process regression approach shows significant
improvements in terms of preciseness and robustness compared to other
mainstream demographic modelling approaches in the short-, mid- and long-term
forecasting using the mortality and fertility data of several developed
countries in our numerical experiments.
</p>
<a href="http://arxiv.org/abs/2102.09676" target="_blank">arXiv:2102.09676</a> [<a href="http://arxiv.org/pdf/2102.09676" target="_blank">pdf</a>]

<h2>Causal Inference Q-Network: Toward Resilient Reinforcement Learning. (arXiv:2102.09677v1 [cs.LG])</h2>
<h3>Chao-Han Huck Yang, I-Te Danny Hung, Yi Ouyang, Pin-Yu Chen</h3>
<p>Deep reinforcement learning (DRL) has demonstrated impressive performance in
various gaming simulators and real-world applications. In practice, however, a
DRL agent may receive faulty observation by abrupt interferences such as
black-out, frozen-screen, and adversarial perturbation. How to design a
resilient DRL algorithm against these rare but mission-critical and
safety-crucial scenarios is an important yet challenging task. In this paper,
we consider a resilient DRL framework with observational interferences. Under
this framework, we discuss the importance of the causal relation and propose a
causal inference based DRL algorithm called causal inference Q-network (CIQ).
We evaluate the performance of CIQ in several benchmark DRL environments with
different types of interferences. Our experimental results show that the
proposed CIQ method could achieve higher performance and more resilience
against observational interferences.
</p>
<a href="http://arxiv.org/abs/2102.09677" target="_blank">arXiv:2102.09677</a> [<a href="http://arxiv.org/pdf/2102.09677" target="_blank">pdf</a>]

<h2>Convolutional Normalization. (arXiv:2102.09685v1 [cs.LG])</h2>
<h3>Massimiliano Esposito, Nader Ganaba</h3>
<p>As the deep neural networks are being applied to complex tasks, the size of
the networks and architecture increases and their topology becomes more
complicated too. At the same time, training becomes slow and at some instances
inefficient. This motivated the introduction of various normalization
techniques such as Batch Normalization and Layer Normalization. The
aforementioned normalization methods use arithmetic operations to compute an
approximation statistics (mainly the first and second moments) of the layer's
data and use it to normalize it. The aforementioned methods use plain Monte
Carlo method to approximate the statistics and such method fails when
approximating the statistics whose distribution is complex. Here, we propose an
approach that uses weighted sum, implemented using depth-wise convolutional
neural networks, to not only approximate the statistics, but to learn the
coefficients of the sum.
</p>
<a href="http://arxiv.org/abs/2102.09685" target="_blank">arXiv:2102.09685</a> [<a href="http://arxiv.org/pdf/2102.09685" target="_blank">pdf</a>]

<h2>SLIP Walking over Rough Terrain via H-LIP Stepping and Backstepping-Barrier Function Inspired Quadratic Program. (arXiv:2102.09691v1 [cs.RO])</h2>
<h3>Xiaobin Xiong, Aaron Ames</h3>
<p>We present an advanced and novel control method to enable actuated Spring
Loaded Inverted Pendulum model to walk over rough and challenging terrains. The
high-level philosophy is the decoupling of the controls of the vertical and
horizontal states. The vertical state is controlled via Backstepping-Barrier
Function (BBF) based quadratic programs: a combination of control Lyapunov
backstepping and control barrier function, both of which provide inequality
constraints on the inputs. The horizontal state is stabilized via Hybrid-Linear
Inverted Pendulum (H-LIP) based stepping, which has a closed-form formulation.
Therefore, the implementation is computationally-efficient. We evaluate our
method in simulation, which demonstrates the aSLIP walking over various
terrains, including slopes, stairs, and general rough terrains with
uncertainties.
</p>
<a href="http://arxiv.org/abs/2102.09691" target="_blank">arXiv:2102.09691</a> [<a href="http://arxiv.org/pdf/2102.09691" target="_blank">pdf</a>]

<h2>Fortify Machine Learning Production Systems: Detect and Classify Adversarial Attacks. (arXiv:2102.09695v1 [cs.LG])</h2>
<h3>Matthew Ciolino, Josh Kalin, David Noever</h3>
<p>Production machine learning systems are consistently under attack by
adversarial actors. Various deep learning models must be capable of accurately
detecting fake or adversarial input while maintaining speed. In this work, we
propose one piece of the production protection system: detecting an incoming
adversarial attack and its characteristics. Detecting types of adversarial
attacks has two primary effects: the underlying model can be trained in a
structured manner to be robust from those attacks and the attacks can be
potentially filtered out in realtime before causing any downstream damage. The
adversarial image classification space is explored for models commonly used in
transfer learning.
</p>
<a href="http://arxiv.org/abs/2102.09695" target="_blank">arXiv:2102.09695</a> [<a href="http://arxiv.org/pdf/2102.09695" target="_blank">pdf</a>]

<h2>AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods. (arXiv:2102.09700v1 [cs.LG])</h2>
<h3>Zheng Shi, Nicolas Loizou, Peter Richt&#xe1;rik, Martin Tak&#xe1;&#x10d;</h3>
<p>We present an adaptive stochastic variance reduced method with an implicit
approach for adaptivity. As a variant of SARAH, our method employs the
stochastic recursive gradient yet adjusts step-size based on local geometry. We
provide convergence guarantees for finite-sum minimization problems and show a
faster convergence than SARAH can be achieved if local geometry permits.
Furthermore, we propose a practical, fully adaptive variant, which does not
require any knowledge of local geometry and any effort of tuning the
hyper-parameters. This algorithm implicitly computes step-size and efficiently
estimates local Lipschitz smoothness of stochastic functions. The numerical
experiments demonstrate the algorithm's strong performance compared to its
classical counterparts and other state-of-the-art first-order methods.
</p>
<a href="http://arxiv.org/abs/2102.09700" target="_blank">arXiv:2102.09700</a> [<a href="http://arxiv.org/pdf/2102.09700" target="_blank">pdf</a>]

<h2>Center Smoothing for Certifiably Robust Vector-Valued Functions. (arXiv:2102.09701v1 [cs.LG])</h2>
<h3>Aounon Kumar, Tom Goldstein</h3>
<p>Randomized smoothing has been successfully applied in high-dimensional image
classification tasks to obtain models that are provably robust against input
perturbations of bounded size. We extend this technique to produce certifiable
robustness for vector-valued functions, i.e., bound the change in output caused
by a small change in input. These functions are used in many areas of machine
learning, such as image reconstruction, dimensionality reduction,
super-resolution, etc., but due to the enormous dimensionality of the output
space in these problems, generating meaningful robustness guarantees is
difficult. We design a smoothing procedure that can leverage the local,
potentially low-dimensional, behaviour of the function around an input to
obtain probabilistic robustness certificates. We demonstrate the effectiveness
of our method on multiple learning tasks involving vector-valued functions with
a wide range of input and output dimensionalities.
</p>
<a href="http://arxiv.org/abs/2102.09701" target="_blank">arXiv:2102.09701</a> [<a href="http://arxiv.org/pdf/2102.09701" target="_blank">pdf</a>]

<h2>Randomized Exploration is Near-Optimal for Tabular MDP. (arXiv:2102.09703v1 [cs.LG])</h2>
<h3>Zhihan Xiong, Ruoqi Shen, Simon S. Du</h3>
<p>We study exploration using randomized value functions in Thompson Sampling
(TS)-like algorithms in reinforcement learning. This type of algorithms enjoys
appealing empirical performance. We show that when we use 1) a single random
seed in each episode, and 2) a Bernstein-type magnitude of noise, we obtain a
worst-case $\widetilde{O}\left(H\sqrt{SAT}\right)$ regret bound for episodic
time-inhomogeneous Markov Decision Process where $S$ is the size of state
space, $A$ is the size of action space, $H$ is the planning horizon and $T$ is
the number of interactions. This bound polynomially improves all existing
bounds for TS-like algorithms based on randomized value functions, and for the
first time, matches the $\Omega\left(H\sqrt{SAT}\right)$ lower bound up to
logarithmic factors. Our result highlights that randomized exploration can be
near-optimal, which was previously only achieved by optimistic algorithms.
</p>
<a href="http://arxiv.org/abs/2102.09703" target="_blank">arXiv:2102.09703</a> [<a href="http://arxiv.org/pdf/2102.09703" target="_blank">pdf</a>]

<h2>Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem. (arXiv:2102.09704v1 [cs.LG])</h2>
<h3>Adarsh Barik, Jean Honorio</h3>
<p>In this paper, we study the problem of fair sparse regression on a biased
dataset where bias depends upon a hidden binary attribute. The presence of a
hidden attribute adds an extra layer of complexity to the problem by combining
sparse regression and clustering with unknown binary labels. The corresponding
optimization problem is combinatorial but we propose a novel relaxation of it
as an \emph{invex} optimization problem. To the best of our knowledge, this is
the first invex relaxation for a combinatorial problem. We show that the
inclusion of the debiasing/fairness constraint in our model has no adverse
effect on the performance. Rather, it enables the recovery of the hidden
attribute. The support of our recovered regression parameter vector matches
exactly with the true parameter vector. Moreover, we simultaneously solve the
clustering problem by recovering the exact value of the hidden attribute for
each sample. Our method uses carefully constructed primal dual witnesses to
solve the combinatorial problem. We provide theoretical guarantees which hold
as long as the number of samples is polynomial in terms of the dimension of the
regression parameter vector.
</p>
<a href="http://arxiv.org/abs/2102.09704" target="_blank">arXiv:2102.09704</a> [<a href="http://arxiv.org/pdf/2102.09704" target="_blank">pdf</a>]

<h2>Continual Learning for Blind Image Quality Assessment. (arXiv:2102.09717v1 [cs.CV])</h2>
<h3>Weixia Zhang, Dingquan Li, Chao Ma, Guangtao Zhai, Xiaokang Yang, Kede Ma</h3>
<p>The explosive growth of image data facilitates the fast development of image
processing and computer vision methods for emerging visual applications,
meanwhile introducing novel distortions to the processed images. This poses a
grand challenge to existing blind image quality assessment (BIQA) models,
failing to continually adapt to such subpopulation shift. Recent work suggests
training BIQA methods on the combination of all available human-rated IQA
datasets. However, this type of approach is not scalable to a large number of
datasets, and is cumbersome to incorporate a newly created dataset as well. In
this paper, we formulate continual learning for BIQA, where a model learns
continually from a stream of IQA datasets, building on what was learned from
previously seen data. We first identify five desiderata in the new setting with
a measure to quantify the plasticity-stability trade-off. We then propose a
simple yet effective method for learning BIQA models continually. Specifically,
based on a shared backbone network, we add a prediction head for a new dataset,
and enforce a regularizer to allow all prediction heads to evolve with new data
while being resistant to catastrophic forgetting of old data. We compute the
quality score by an adaptive weighted summation of estimates from all
prediction heads. Extensive experiments demonstrate the promise of the proposed
continual learning method in comparison to standard training techniques for
BIQA.
</p>
<a href="http://arxiv.org/abs/2102.09717" target="_blank">arXiv:2102.09717</a> [<a href="http://arxiv.org/pdf/2102.09717" target="_blank">pdf</a>]

<h2>Permutation-Based SGD: Is Random Optimal?. (arXiv:2102.09718v1 [cs.LG])</h2>
<h3>Shashank Rajput, Kangwook Lee, Dimitris Papailiopoulos</h3>
<p>A recent line of ground-breaking results for permutation-based SGD has
corroborated a widely observed phenomenon: random permutations offer faster
convergence than with-replacement sampling. However, is random optimal? We show
that this depends heavily on what functions we are optimizing, and the
convergence gap between optimal and random permutations can vary from
exponential to nonexistent. We first show that for 1-dimensional strongly
convex functions, with smooth second derivatives, there exist optimal
permutations that offer exponentially faster convergence compared to random.
However, for general strongly convex functions, random permutations are
optimal. Finally, we show that for quadratic, strongly-convex functions, there
are easy-to-construct permutations that lead to accelerated convergence
compared to random. Our results suggest that a general convergence
characterization of optimal permutations cannot capture the nuances of
individual function classes, and can mistakenly indicate that one cannot do
much better than random.
</p>
<a href="http://arxiv.org/abs/2102.09718" target="_blank">arXiv:2102.09718</a> [<a href="http://arxiv.org/pdf/2102.09718" target="_blank">pdf</a>]

<h2>One Shot Audio to Animated Video Generation. (arXiv:2102.09737v1 [cs.CV])</h2>
<h3>Neeraj Kumar, Srishti Goel, Ankur Narang, Brejesh Lall, Mujtaba Hasan, Pranshu Agarwal, Dipankar Sarkar</h3>
<p>We consider the challenging problem of audio to animated video generation. We
propose a novel method OneShotAu2AV to generate an animated video of arbitrary
length using an audio clip and a single unseen image of a person as an input.
The proposed method consists of two stages. In the first stage, OneShotAu2AV
generates the talking-head video in the human domain given an audio and a
person's image. In the second stage, the talking-head video from the human
domain is converted to the animated domain. The model architecture of the first
stage consists of spatially adaptive normalization based multi-level generator
and multiple multilevel discriminators along with multiple adversarial and
non-adversarial losses. The second stage leverages attention based
normalization driven GAN architecture along with temporal predictor based
recycle loss and blink loss coupled with lipsync loss, for unsupervised
generation of animated video. In our approach, the input audio clip is not
restricted to any specific language, which gives the method multilingual
applicability. OneShotAu2AV can generate animated videos that have: (a) lip
movements that are in sync with the audio, (b) natural facial expressions such
as blinks and eyebrow movements, (c) head movements. Experimental evaluation
demonstrates superior performance of OneShotAu2AV as compared to U-GAT-IT and
RecycleGan on multiple quantitative metrics including KID(Kernel Inception
Distance), Word error rate, blinks/sec
</p>
<a href="http://arxiv.org/abs/2102.09737" target="_blank">arXiv:2102.09737</a> [<a href="http://arxiv.org/pdf/2102.09737" target="_blank">pdf</a>]

<h2>Personalized Federated Learning: A Unified Framework and Universal Optimization Techniques. (arXiv:2102.09743v1 [cs.LG])</h2>
<h3>Filip Hanzely, Boxin Zhao, Mladen Kolar</h3>
<p>We study the optimization aspects of personalized Federated Learning (FL). We
develop a universal optimization theory applicable to all convex personalized
FL models in the literature. In particular, we propose a general personalized
objective capable of recovering essentially any existing personalized FL
objective as a special case. We design several optimization techniques to
minimize the general objective, namely a tailored variant of Local SGD and
variants of accelerated coordinate descent/accelerated SVRCD. We demonstrate
the practicality and/or optimality of our methods both in terms of
communication and local computation. Lastly, we argue about the implications of
our general optimization theory when applied to solve specific personalized FL
objectives.
</p>
<a href="http://arxiv.org/abs/2102.09743" target="_blank">arXiv:2102.09743</a> [<a href="http://arxiv.org/pdf/2102.09743" target="_blank">pdf</a>]

<h2>Trends in Vehicle Re-identification Past, Present, and Future: A Comprehensive Review. (arXiv:2102.09744v1 [cs.CV])</h2>
<h3>Zakria, Jianhua Deng, Muhammad Saddam Khokhar, Muhammad Umar Aftab, Jingye Cai, Rajesh Kumar, Jay Kumar</h3>
<p>Vehicle Re-identification (re-id) over surveillance camera network with
non-overlapping field of view is an exciting and challenging task in
intelligent transportation systems (ITS). Due to its versatile applicability in
metropolitan cities, it gained significant attention. Vehicle re-id matches
targeted vehicle over non-overlapping views in multiple camera network.
However, it becomes more difficult due to inter-class similarity, intra-class
variability, viewpoint changes, and spatio-temporal uncertainty. In order to
draw a detailed picture of vehicle re-id research, this paper gives a
comprehensive description of the various vehicle re-id technologies,
applicability, datasets, and a brief comparison of different methodologies. Our
paper specifically focuses on vision-based vehicle re-id approaches, including
vehicle appearance, license plate, and spatio-temporal characteristics. In
addition, we explore the main challenges as well as a variety of applications
in different domains. Lastly, a detailed comparison of current state-of-the-art
methods performances over VeRi-776 and VehicleID datasets is summarized with
future directions. We aim to facilitate future research by reviewing the work
being done on vehicle re-id till to date.
</p>
<a href="http://arxiv.org/abs/2102.09744" target="_blank">arXiv:2102.09744</a> [<a href="http://arxiv.org/pdf/2102.09744" target="_blank">pdf</a>]

<h2>Decentralized Deterministic Multi-Agent Reinforcement Learning. (arXiv:2102.09745v1 [cs.LG])</h2>
<h3>Antoine Grosnit, Desmond Cai, Laura Wynter</h3>
<p>[Zhang, ICML 2018] provided the first decentralized actor-critic algorithm
for multi-agent reinforcement learning (MARL) that offers convergence
guarantees. In that work, policies are stochastic and are defined on finite
action spaces. We extend those results to offer a provably-convergent
decentralized actor-critic algorithm for learning deterministic policies on
continuous action spaces. Deterministic policies are important in real-world
settings. To handle the lack of exploration inherent in deterministic policies,
we consider both off-policy and on-policy settings. We provide the expression
of a local deterministic policy gradient, decentralized deterministic
actor-critic algorithms and convergence guarantees for linearly-approximated
value functions. This work will help enable decentralized MARL in
high-dimensional action spaces and pave the way for more widespread use of
MARL.
</p>
<a href="http://arxiv.org/abs/2102.09745" target="_blank">arXiv:2102.09745</a> [<a href="http://arxiv.org/pdf/2102.09745" target="_blank">pdf</a>]

<h2>Symplectic Adjoint Method for Exact Gradient of Neural ODE with Minimal Memory. (arXiv:2102.09750v1 [cs.LG])</h2>
<h3>Takashi Matsubara, Yuto Miyatake, Takaharu Yaguchi</h3>
<p>A neural network model of a differential equation, namely neural ODE, has
enabled us to learn continuous-time dynamical systems and probabilistic
distributions with a high accuracy. It uses the same network repeatedly during
a numerical integration. Hence, the backpropagation algorithm requires a memory
footprint proportional to the number of uses times the network size. This is
true even if a checkpointing scheme divides the computational graph into
sub-graphs. Otherwise, the adjoint method obtains a gradient by a numerical
integration backward in time with a minimal memory footprint; however, it
suffers from numerical errors. This study proposes the symplectic adjoint
method, which obtains the exact gradient (up to rounding error) with a
footprint proportional to the number of uses plus the network size. The
experimental results demonstrate the symplectic adjoint method occupies the
smallest footprint in most cases, functions faster in some cases, and is robust
to a rounding error among competitive methods.
</p>
<a href="http://arxiv.org/abs/2102.09750" target="_blank">arXiv:2102.09750</a> [<a href="http://arxiv.org/pdf/2102.09750" target="_blank">pdf</a>]

<h2>VisuoSpatial Foresight for Physical Sequential Fabric Manipulation. (arXiv:2102.09754v1 [cs.RO])</h2>
<h3>Ryan Hoque, Daniel Seita, Ashwin Balakrishna, Aditya Ganapathi, Ajay Kumar Tanwani, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg</h3>
<p>Robotic fabric manipulation has applications in home robotics, textiles,
senior care and surgery. Existing fabric manipulation techniques, however, are
designed for specific tasks, making it difficult to generalize across different
but related tasks. We build upon the Visual Foresight framework to learn fabric
dynamics that can be efficiently reused to accomplish different sequential
fabric manipulation tasks with a single goal-conditioned policy. We extend our
earlier work on VisuoSpatial Foresight (VSF), which learns visual dynamics on
domain randomized RGB images and depth maps simultaneously and completely in
simulation. In this earlier work, we evaluated VSF on multi-step fabric
smoothing and folding tasks against 5 baseline methods in simulation and on the
da Vinci Research Kit (dVRK) surgical robot without any demonstrations at train
or test time. A key finding was that depth sensing significantly improves
performance: RGBD data yields an 80% improvement in fabric folding success rate
in simulation over pure RGB data. In this work, we vary 4 components of VSF,
including data generation, the choice of visual dynamics model, cost function,
and optimization procedure. Results suggest that training visual dynamics
models using longer, corner-based actions can improve the efficiency of fabric
folding by 76% and enable a physical sequential fabric folding task that VSF
could not previously perform with 90% reliability. Code, data, videos, and
supplementary material are available at
https://sites.google.com/view/fabric-vsf/.
</p>
<a href="http://arxiv.org/abs/2102.09754" target="_blank">arXiv:2102.09754</a> [<a href="http://arxiv.org/pdf/2102.09754" target="_blank">pdf</a>]

<h2>TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning. (arXiv:2102.09756v1 [cs.LG])</h2>
<h3>Minchao Wu, Michael Norrish, Christian Walder, Amir Dezfouli</h3>
<p>We propose a novel approach to interactive theorem-proving (ITP) using deep
reinforcement learning. Unlike previous work, our framework is able to prove
theorems both end-to-end and from scratch (i.e., without relying on example
proofs from human experts). We formulate the process of ITP as a Markov
decision process (MDP) in which each state represents a set of potential
derivation paths. The agent learns to select promising derivations as well as
appropriate tactics within each derivation using deep policy gradients. This
structure allows us to introduce a novel backtracking mechanism which enables
the agent to efficiently discard (predicted) dead-end derivations and restart
the derivation from promising alternatives. Experimental results show that the
framework provides comparable performance to that of the approaches that use
human experts, and that it is also capable of proving theorems that it has
never seen during training. We further elaborate the role of each component of
the framework using ablation studies.
</p>
<a href="http://arxiv.org/abs/2102.09756" target="_blank">arXiv:2102.09756</a> [<a href="http://arxiv.org/pdf/2102.09756" target="_blank">pdf</a>]

<h2>Serial-parallel Multi-Scale Feature Fusion for Anatomy-Oriented Hand Joint Detection. (arXiv:2102.09757v1 [cs.CV])</h2>
<h3>Bin Li, Hong Fu, Ruimin Li, Wendi Wang</h3>
<p>Accurate hand joints detection from images is a fundamental topic which is
essential for many applications in computer vision and human computer
interaction. This paper presents a two stage network for hand joints detection
from single unmarked image by using serial-parallel multi-scale feature fusion.
In stage I, the hand regions are located by a pre-trained network, and the
features of each detected hand region are extracted by a shallow spatial hand
features representation module. The extracted hand features are then fed into
stage II, which consists of serially connected feature extraction modules with
similar structures, called "multi-scale feature fusion" (MSFF). A MSFF contains
parallel multi-scale feature extraction branches, which generate initial hand
joint heatmaps. The initial heatmaps are then mutually reinforced by the
anatomic relationship between hand joints. The experimental results on five
hand joints datasets show that the proposed network overperforms the
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.09757" target="_blank">arXiv:2102.09757</a> [<a href="http://arxiv.org/pdf/2102.09757" target="_blank">pdf</a>]

<h2>Applications of deep learning in traffic congestion alleviation: A survey. (arXiv:2102.09759v1 [cs.LG])</h2>
<h3>Nishant Kumar, Martin Raubal</h3>
<p>Prediction tasks related to congestion are targeted at improving the level of
service of the transportation network. With increasing access to larger
datasets of higher resolution, the relevance of deep learning in such
prediction tasks, is increasing. Several comprehensive survey papers in recent
years have summarised the deep learning applications in the transportation
domain. However, the system dynamics of the transportation network vary greatly
between the non-congested state and the congested state -- thereby
necessitating the need for a clear understanding of the challenges specific to
congestion prediction. In this survey, we present the current state of deep
learning applications in the tasks related to detection, prediction and
propagation of congestion. Recurrent and non-recurrent congestion are discussed
separately. Our survey leads us to uncover inherent challenges and gaps in the
current state of research. Finally, we present some suggestions for future
research directions as answers to the identified challenges.
</p>
<a href="http://arxiv.org/abs/2102.09759" target="_blank">arXiv:2102.09759</a> [<a href="http://arxiv.org/pdf/2102.09759" target="_blank">pdf</a>]

<h2>Probabilistic Generating Circuits. (arXiv:2102.09768v1 [cs.AI])</h2>
<h3>Honghua Zhang, Brendan Juba, Guy Van den Broeck</h3>
<p>Generating functions, which are widely used in combinatorics and probability
theory, encode function values into the coefficients of a polynomial. In this
paper, we explore their use as a tractable probabilistic model, and propose
probabilistic generating circuits (PGCs) for their efficient representation.
PGCs strictly subsume many existing tractable probabilistic models, including
determinantal point processes (DPPs), probabilistic circuits (PCs) such as
sum-product networks, and tractable graphical models. We contend that PGCs are
not just a theoretical framework that unifies vastly different existing models,
but also show huge potential in modeling realistic data. We exhibit a simple
class of PGCs that are not trivially subsumed by simple combinations of PCs and
DPPs, and obtain competitive performance on a suite of density estimation
benchmarks. We also highlight PGCs' connection to the theory of strongly
Rayleigh distributions.
</p>
<a href="http://arxiv.org/abs/2102.09768" target="_blank">arXiv:2102.09768</a> [<a href="http://arxiv.org/pdf/2102.09768" target="_blank">pdf</a>]

<h2>On the Implicit Bias of Initialization Shape: Beyond Infinitesimal Mirror Descent. (arXiv:2102.09769v1 [cs.LG])</h2>
<h3>Shahar Azulay, Edward Moroshko, Mor Shpigel Nacson, Blake Woodworth, Nathan Srebro, Amir Globerson, Daniel Soudry</h3>
<p>Recent work has highlighted the role of initialization scale in determining
the structure of the solutions that gradient methods converge to. In
particular, it was shown that large initialization leads to the neural tangent
kernel regime solution, whereas small initialization leads to so called "rich
regimes". However, the initialization structure is richer than the overall
scale alone and involves relative magnitudes of different weights and layers in
the network. Here we show that these relative scales, which we refer to as
initialization shape, play an important role in determining the learned model.
We develop a novel technique for deriving the inductive bias of gradient-flow
and use it to obtain closed-form implicit regularizers for multiple cases of
interest.
</p>
<a href="http://arxiv.org/abs/2102.09769" target="_blank">arXiv:2102.09769</a> [<a href="http://arxiv.org/pdf/2102.09769" target="_blank">pdf</a>]

<h2>Regularized Recovery by Multi-order Partial Hypergraph Total Variation. (arXiv:2102.09771v1 [cs.LG])</h2>
<h3>Ruyuan Qu, Jiaqi He, Hui Feng, Chongbin Xu, Bo Hu</h3>
<p>Capturing complex high-order interactions among data is an important task in
many scenarios. A common way to model high-order interactions is to use
hypergraphs whose topology can be mathematically represented by tensors.
Existing methods use a fixed-order tensor to describe the topology of the whole
hypergraph, which ignores the divergence of different-order interactions. In
this work, we take this divergence into consideration, and propose a
multi-order hypergraph Laplacian and the corresponding total variation. Taking
this total variation as a regularization term, we can utilize the topology
information contained by it to smooth the hypergraph signal. This can help
distinguish different-order interactions and represent high-order interactions
accurately.
</p>
<a href="http://arxiv.org/abs/2102.09771" target="_blank">arXiv:2102.09771</a> [<a href="http://arxiv.org/pdf/2102.09771" target="_blank">pdf</a>]

<h2>A Deep Graph Wavelet Convolutional Neural Network for Semi-supervised Node Classification. (arXiv:2102.09780v1 [cs.LG])</h2>
<h3>Jingyi Wang, Zhidong Deng</h3>
<p>Graph convolutional neural network provides good solutions for node
classification and other tasks with non-Euclidean data. There are several graph
convolutional models that attempt to develop deep networks but do not cause
serious over-smoothing at the same time. Considering that the wavelet transform
generally has a stronger ability to extract useful information than the Fourier
transform, we propose a new deep graph wavelet convolutional network (DeepGWC)
for semi-supervised node classification tasks. Based on the optimized static
filtering matrix parameters of vanilla graph wavelet neural networks and the
combination of Fourier bases and wavelet ones, DeepGWC is constructed together
with the reuse of residual connection and identity mappings in network
architectures. Extensive experiments on three benchmark datasets including
Cora, Citeseer, and Pubmed are conducted. The experimental results demonstrate
that our DeepGWC outperforms existing graph deep models with the help of
additional wavelet bases and achieves new state-of-the-art performances
eventually.
</p>
<a href="http://arxiv.org/abs/2102.09780" target="_blank">arXiv:2102.09780</a> [<a href="http://arxiv.org/pdf/2102.09780" target="_blank">pdf</a>]

<h2>Learning Composable Behavior Embeddings for Long-horizon Visual Navigation. (arXiv:2102.09781v1 [cs.RO])</h2>
<h3>Xiangyun Meng, Yu Xiang, Dieter Fox</h3>
<p>Learning high-level navigation behaviors has important implications: it
enables robots to build compact visual memory for repeating demonstrations and
to build sparse topological maps for planning in novel environments. Existing
approaches only learn discrete, short-horizon behaviors. These standalone
behaviors usually assume a discrete action space with simple robot dynamics,
thus they cannot capture the intricacy and complexity of real-world
trajectories. To this end, we propose Composable Behavior Embedding (CBE), a
continuous behavior representation for long-horizon visual navigation. CBE is
learned in an end-to-end fashion; it effectively captures path geometry and is
robust to unseen obstacles. We show that CBE can be used to performing
memory-efficient path following and topological mapping, saving more than an
order of magnitude of memory than behavior-less approaches.
</p>
<a href="http://arxiv.org/abs/2102.09781" target="_blank">arXiv:2102.09781</a> [<a href="http://arxiv.org/pdf/2102.09781" target="_blank">pdf</a>]

<h2>Sequential- and Parallel- Constrained Max-value Entropy Search via Information Lower Bound. (arXiv:2102.09788v1 [cs.LG])</h2>
<h3>Shion Takeno, Tomoyuki Tamura, Kazuki Shitara, Masayuki Karasuyama</h3>
<p>Recently, several Bayesian optimization (BO) methods have been extended to
the expensive black-box optimization problem with unknown constraints, which is
an important problem that appears frequently in practice. We focus on an
information-theoretic approach called Max-value Entropy Search (MES) whose
superior performance has been repeatedly shown in BO literature. Since existing
MES-based constrained BO is restricted to only one constraint, we first extend
it to multiple constraints, but we found that this approach can cause negative
approximate values for the mutual information, which can result in unreasonable
decisions. In this paper, we employ a different approximation strategy that is
based on a lower bound of the mutual information, and propose a novel
constrained BO method called Constrained Max-value Entropy Search via
Information lower BOund (CMES-IBO). Our approximate mutual information derived
from the lower bound has a simple closed-form that is guaranteed to be
nonnegative, and we show that irrational behavior caused by the negative value
can be avoided. Furthermore, by using conditional mutual information, we extend
our methods to the parallel setting in which multiple queries can be issued
simultaneously. Finally, we demonstrate the effectiveness of our proposed
methods by benchmark functions and real-world applications to materials
science.
</p>
<a href="http://arxiv.org/abs/2102.09788" target="_blank">arXiv:2102.09788</a> [<a href="http://arxiv.org/pdf/2102.09788" target="_blank">pdf</a>]

<h2>Local Convergence of Adaptive Gradient Descent Optimizers. (arXiv:2102.09804v1 [cs.LG])</h2>
<h3>Sebastian Bock, Martin Georg Wei&#xdf;</h3>
<p>Adaptive Moment Estimation (ADAM) is a very popular training algorithm for
deep neural networks and belongs to the family of adaptive gradient descent
optimizers. However to the best of the authors knowledge no complete
convergence analysis exists for ADAM. The contribution of this paper is a
method for the local convergence analysis in batch mode for a deterministic
fixed training set, which gives necessary conditions for the hyperparameters of
the ADAM algorithm. Due to the local nature of the arguments the objective
function can be non-convex but must be at least twice continuously
differentiable. Then we apply this procedure to other adaptive gradient descent
algorithms and show for most of them local convergence with hyperparameter
bounds.
</p>
<a href="http://arxiv.org/abs/2102.09804" target="_blank">arXiv:2102.09804</a> [<a href="http://arxiv.org/pdf/2102.09804" target="_blank">pdf</a>]

<h2>Training cascaded networks for speeded decisions using a temporal-difference loss. (arXiv:2102.09808v1 [cs.LG])</h2>
<h3>Michael L. Iuzzolino, Michael C. Mozer, Samy Bengio</h3>
<p>Although deep feedforward neural networks share some characteristics with the
primate visual system, a key distinction is their dynamics. Deep nets typically
operate in sequential stages wherein each layer fully completes its computation
before processing begins in subsequent layers. In contrast, biological systems
have cascaded dynamics: information propagates from neurons at all layers in
parallel but transmission is gradual over time. In our work, we construct a
cascaded ResNet by introducing a propagation delay into each residual block and
updating all layers in parallel in a stateful manner. Because information
transmitted through skip connections avoids delays, the functional depth of the
architecture increases over time and yields a trade off between processing
speed and accuracy. We introduce a temporal-difference (TD) training loss that
achieves a strictly superior speed accuracy profile over standard losses. The
CascadedTD model has intriguing properties, including: typical instances are
classified more rapidly than atypical instances; CascadedTD is more robust to
both persistent and transient noise than is a conventional ResNet; and the
time-varying output trace of CascadedTD provides a signal that can be used by
`meta-cognitive' models for OOD detection and to determine when to terminate
processing.
</p>
<a href="http://arxiv.org/abs/2102.09808" target="_blank">arXiv:2102.09808</a> [<a href="http://arxiv.org/pdf/2102.09808" target="_blank">pdf</a>]

<h2>Deep Latent Competition: Learning to Race Using Visual Control Policies in Latent Space. (arXiv:2102.09812v1 [cs.LG])</h2>
<h3>Wilko Schwarting, Tim Seyde, Igor Gilitschenski, Lucas Liebenwein, Ryan Sander, Sertac Karaman, Daniela Rus</h3>
<p>Learning competitive behaviors in multi-agent settings such as racing
requires long-term reasoning about potential adversarial interactions. This
paper presents Deep Latent Competition (DLC), a novel reinforcement learning
algorithm that learns competitive visual control policies through self-play in
imagination. The DLC agent imagines multi-agent interaction sequences in the
compact latent space of a learned world model that combines a joint transition
function with opponent viewpoint prediction. Imagined self-play reduces costly
sample generation in the real world, while the latent representation enables
planning to scale gracefully with observation dimensionality. We demonstrate
the effectiveness of our algorithm in learning competitive behaviors on a novel
multi-agent racing benchmark that requires planning from image observations.
Code and videos available at
https://sites.google.com/view/deep-latent-competition.
</p>
<a href="http://arxiv.org/abs/2102.09812" target="_blank">arXiv:2102.09812</a> [<a href="http://arxiv.org/pdf/2102.09812" target="_blank">pdf</a>]

<h2>Sim-Env: Decoupling OpenAI Gym Environments from Simulation Models. (arXiv:2102.09824v1 [cs.LG])</h2>
<h3>Andreas Schuderer (1 and 2), Stefano Bromuri (1), Marko van Eekelen (1 and 3) ((1) Open University of the Netherlands, (2) APG Algemene Pensioen Groep N.V., (3) Radboud University)</h3>
<p>Reinforcement learning (RL) is one of the most active fields of AI research.
Despite the interest demonstrated by the research community in reinforcement
learning, the development methodology still lags behind, with a severe lack of
standard APIs to foster the development of RL applications. OpenAI Gym is
probably the most used environment to develop RL applications and simulations,
but most of the abstractions proposed in such a framework are still assuming a
semi-structured methodology. This is particularly relevant for agent-based
models whose purpose is to analyse adaptive behaviour displayed by
self-learning agents in the simulation. In order to bridge this gap, we present
a workflow and tools for the decoupled development and maintenance of
multi-purpose agent-based models and derived single-purpose reinforcement
learning environments, enabling the researcher to swap out environments with
ones representing different perspectives or different reward models, all while
keeping the underlying domain model intact and separate. The Sim-Env Python
library generates OpenAI-Gym-compatible reinforcement learning environments
that use existing or purposely created domain models as their simulation
back-ends. Its design emphasizes ease-of-use, modularity and code separation.
</p>
<a href="http://arxiv.org/abs/2102.09824" target="_blank">arXiv:2102.09824</a> [<a href="http://arxiv.org/pdf/2102.09824" target="_blank">pdf</a>]

<h2>Controller Synthesis for Golog Programs over Finite Domains with Metric Temporal Constraints. (arXiv:2102.09837v1 [cs.AI])</h2>
<h3>Till Hofmann, Gerhard Lakemeyer</h3>
<p>Executing a Golog program on an actual robot typically requires additional
steps to account for hardware or software details of the robot platform, which
can be formulated as constraints on the program. Such constraints are often
temporal, refer to metric time, and require modifications to the abstract Golog
program. We describe how to formulate such constraints based on a modal variant
of the Situation Calculus. These constraints connect the abstract program with
the platform models, which we describe using timed automata. We show that for
programs over finite domains and with fully known initial state, the problem of
synthesizing a controller that satisfies the constraints while preserving the
effects of the original program can be reduced to MTL synthesis. We do this by
constructing a timed automaton from the abstract program and synthesizing an
MTL controller from this automaton, the platform models, and the constraints.
We prove that the synthesized controller results in execution traces which are
the same as those of the original program, possibly interleaved with
platform-dependent actions, that they satisfy all constraints, and that they
have the same effects as the traces of the original program. By doing so, we
obtain a decidable procedure to synthesize a controller that satisfies the
specification while preserving the original program.
</p>
<a href="http://arxiv.org/abs/2102.09837" target="_blank">arXiv:2102.09837</a> [<a href="http://arxiv.org/pdf/2102.09837" target="_blank">pdf</a>]

<h2>Kinematic Control of compliant serial manipulators composed of dual-triangles. (arXiv:2102.09840v1 [cs.RO])</h2>
<h3>Wanda Zhao (LS2N, ReV), Anatol Pashkevich (LS2N, ReV), Alexandr Klimchik, Damien Chablat (ReV, LS2N)</h3>
<p>The paper focuses on the kinematics control of a compliant serial manipulator
composed of a new type of dualtriangle elastic segments. Some useful
optimization techniques were applied to solve the geometric redundancy problem,
ensure the stability of the manipulator configurations with respect to the
external forces/torques applied to the endeffector. The efficiency of the
developed control algorisms is confirmed by simulation.
</p>
<a href="http://arxiv.org/abs/2102.09840" target="_blank">arXiv:2102.09840</a> [<a href="http://arxiv.org/pdf/2102.09840" target="_blank">pdf</a>]

<h2>E(n) Equivariant Graph Neural Networks. (arXiv:2102.09844v1 [cs.LG])</h2>
<h3>Victor Garcia Satorras, Emiel Hoogeboom, Max Welling</h3>
<p>This paper introduces a new model to learn graph neural networks equivariant
to rotations, translations, reflections and permutations called
E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing
methods, our work does not require computationally expensive higher-order
representations in intermediate layers while it still achieves competitive or
better performance. In addition, whereas existing methods are limited to
equivariance on 3 dimensional spaces, our model is easily scaled to
higher-dimensional spaces. We demonstrate the effectiveness of our method on
dynamical systems modelling, representation learning in graph autoencoders and
predicting molecular properties.
</p>
<a href="http://arxiv.org/abs/2102.09844" target="_blank">arXiv:2102.09844</a> [<a href="http://arxiv.org/pdf/2102.09844" target="_blank">pdf</a>]

<h2>Model-Invariant State Abstractions for Model-Based Reinforcement Learning. (arXiv:2102.09850v1 [cs.LG])</h2>
<h3>Manan Tomar, Amy Zhang, Roberto Calandra, Matthew E. Taylor, Joelle Pineau</h3>
<p>Accuracy and generalization of dynamics models is key to the success of
model-based reinforcement learning (MBRL). As the complexity of tasks
increases, learning dynamics models becomes increasingly sample inefficient for
MBRL methods. However, many tasks also exhibit sparsity in the dynamics, i.e.,
actions have only a local effect on the system dynamics. In this paper, we
exploit this property with a causal invariance perspective in the single-task
setting, introducing a new type of state abstraction called
\textit{model-invariance}. Unlike previous forms of state abstractions, a
model-invariance state abstraction leverages causal sparsity over state
variables. This allows for generalization to novel combinations of unseen
values of state variables, something that non-factored forms of state
abstractions cannot do. We prove that an optimal policy can be learned over
this model-invariance state abstraction. Next, we propose a practical method to
approximately learn a model-invariant representation for complex domains. We
validate our approach by showing improved modeling performance over standard
maximum likelihood approaches on challenging tasks, such as the MuJoCo-based
Humanoid. Furthermore, within the MBRL setting we show strong performance gains
w.r.t. sample efficiency across a host of other continuous control tasks.
</p>
<a href="http://arxiv.org/abs/2102.09850" target="_blank">arXiv:2102.09850</a> [<a href="http://arxiv.org/pdf/2102.09850" target="_blank">pdf</a>]

<h2>Intrinsically Motivated Open-Ended Multi-Task Learning Using Transfer Learning to Discover Task Hierarchy. (arXiv:2102.09854v1 [cs.AI])</h2>
<h3>Nicolas Duminy (Lab-STICC), Sao Mai Nguyen (U2IS), Junshuai Zhu (IMT Atlantique), Dominique Duhaut (UBS), Jerome Kerdreux (Lab-STICC)</h3>
<p>In open-ended continuous environments, robots need to learn multiple
parameterised control tasks in hierarchical reinforcement learning. We
hypothesise that the most complex tasks can be learned more easily by
transferring knowledge from simpler tasks, and faster by adapting the
complexity of the actions to the task. We propose a task-oriented
representation of complex actions, called procedures, to learn online task
relationships and unbounded sequences of action primitives to control the
different observables of the environment. Combining both goal-babbling with
imitation learning, and active learning with transfer of knowledge based on
intrinsic motivation, our algorithm self-organises its learning process. It
chooses at any given time a task to focus on; and what, how, when and from whom
to transfer knowledge. We show with a simulation and a real industrial robot
arm, in cross-task and cross-learner transfer settings, that task composition
is key to tackle highly complex tasks. Task decomposition is also efficiently
transferred across different embodied learners and by active imitation, where
the robot requests just a small amount of demonstrations and the adequate type
of information. The robot learns and exploits task dependencies so as to learn
tasks of every complexity.
</p>
<a href="http://arxiv.org/abs/2102.09854" target="_blank">arXiv:2102.09854</a> [<a href="http://arxiv.org/pdf/2102.09854" target="_blank">pdf</a>]

<h2>ISCL: Interdependent Self-Cooperative Learning for Unpaired Image Denoising. (arXiv:2102.09858v1 [cs.CV])</h2>
<h3>Kanggeun Lee, Won-Ki Jeong</h3>
<p>With the advent of advances in self-supervised learning, paired clean-noisy
data are no longer required in deep learning-based image denoising. However,
existing blind denoising methods still require the assumption with regard to
noise characteristics, such as zero-mean noise distribution and pixel-wise
noise-signal independence; this hinders wide adaptation of the method in the
medical domain. On the other hand, unpaired learning can overcome limitations
related to the assumption on noise characteristics, which makes it more
feasible for collecting the training data in real-world scenarios. In this
paper, we propose a novel image denoising scheme, Interdependent
Self-Cooperative Learning (ISCL), that leverages unpaired learning by combining
cyclic adversarial learning with self-supervised residual learning. Unlike the
existing unpaired image denoising methods relying on matching data
distributions in different domains, the two architectures in ISCL, designed for
different tasks, complement each other and boost the learning process. To
assess the performance of the proposed method, we conducted extensive
experiments in various biomedical image degradation scenarios, such as noise
caused by physical characteristics of electron microscopy (EM) devices (film
and charging noise), and structural noise found in low-dose computer tomography
(CT). We demonstrate that the image quality of our method is superior to
conventional and current state-of-the-art deep learning-based image denoising
methods, including supervised learning.
</p>
<a href="http://arxiv.org/abs/2102.09858" target="_blank">arXiv:2102.09858</a> [<a href="http://arxiv.org/pdf/2102.09858" target="_blank">pdf</a>]

<h2>An Algorithm for Stochastic and Adversarial Bandits with Switching Costs. (arXiv:2102.09864v1 [cs.LG])</h2>
<h3>Chlo&#xe9; Rouyer, Yevgeny Seldin, Nicol&#xf2; Cesa-Bianchi</h3>
<p>We propose an algorithm for stochastic and adversarial multiarmed bandits
with switching costs, where the algorithm pays a price $\lambda$ every time it
switches the arm being played. Our algorithm is based on adaptation of the
Tsallis-INF algorithm of Zimmert and Seldin (2021) and requires no prior
knowledge of the regime or time horizon. In the oblivious adversarial setting
it achieves the minimax optimal regret bound of $O\big((\lambda K)^{1/3}T^{2/3}
+ \sqrt{KT}\big)$, where $T$ is the time horizon and $K$ is the number of arms.
In the stochastically constrained adversarial regime, which includes the
stochastic regime as a special case, it achieves a regret bound of
$O\left(\big((\lambda K)^{2/3} T^{1/3} + \ln T\big)\sum_{i \neq i^*}
\Delta_i^{-1}\right)$, where $\Delta_i$ are the suboptimality gaps and $i^*$ is
a unique optimal arm. In the special case of $\lambda = 0$ (no switching
costs), both bounds are minimax optimal within constants. We also explore
variants of the problem, where switching cost is allowed to change over time.
We provide experimental evaluation showing competitiveness of our algorithm
with the relevant baselines in the stochastic, stochastically constrained
adversarial, and adversarial regimes with fixed switching cost.
</p>
<a href="http://arxiv.org/abs/2102.09864" target="_blank">arXiv:2102.09864</a> [<a href="http://arxiv.org/pdf/2102.09864" target="_blank">pdf</a>]

<h2>Re-rank Coarse Classification with Local Region Enhanced Features for Fine-Grained Image Recognition. (arXiv:2102.09875v1 [cs.CV])</h2>
<h3>Shaokang Yang, Shuai Liu, Cheng Yang, Changhu Wang</h3>
<p>Fine-grained image recognition is very challenging due to the difficulty of
capturing both semantic global features and discriminative local features.
Meanwhile, these two features are not easy to be integrated, which are even
conflicting when used simultaneously. In this paper, a retrieval-based
coarse-to-fine framework is proposed, where we re-rank the TopN classification
results by using the local region enhanced embedding features to improve the
Top1 accuracy (based on the observation that the correct category usually
resides in TopN results). To obtain the discriminative regions for
distinguishing the fine-grained images, we introduce a weakly-supervised method
to train a box generating branch with only image-level labels. In addition, to
learn more effective semantic global features, we design a multi-level loss
over an automatically constructed hierarchical category structure. Experimental
results show that our method achieves state-of-the-art performance on three
benchmarks: CUB-200-2011, Stanford Cars, and FGVC Aircraft. Also,
visualizations and analysis are provided for better understanding.
</p>
<a href="http://arxiv.org/abs/2102.09875" target="_blank">arXiv:2102.09875</a> [<a href="http://arxiv.org/pdf/2102.09875" target="_blank">pdf</a>]

<h2>Anytime Diagnosis for Reconfiguration. (arXiv:2102.09880v1 [cs.AI])</h2>
<h3>Alexander Felfernig, Rouven Walter, Jose A. Galindo, David Benavides, Seda Polat-Erdeniz, Muesluem Atas, Stefan Reiterer</h3>
<p>Many domains require scalable algorithms that help to determine diagnoses
efficiently and often within predefined time limits. Anytime diagnosis is able
to determine solutions in such a way and thus is especially useful in real-time
scenarios such as production scheduling, robot control, and communication
networks management where diagnosis and corresponding reconfiguration
capabilities play a major role. Anytime diagnosis in many cases comes along
with a trade-off between diagnosis quality and the efficiency of diagnostic
reasoning. In this paper we introduce and analyze FlexDiag which is an anytime
direct diagnosis approach. We evaluate the algorithm with regard to performance
and diagnosis quality using a configuration benchmark from the domain of
feature models and an industrial configuration knowledge base from the
automotive domain. Results show that FlexDiag helps to significantly increase
the performance of direct diagnosis search with corresponding quality tradeoffs
in terms of minimality and accuracy.
</p>
<a href="http://arxiv.org/abs/2102.09880" target="_blank">arXiv:2102.09880</a> [<a href="http://arxiv.org/pdf/2102.09880" target="_blank">pdf</a>]

<h2>SLPC: a VRNN-based approach for stochastic lidar prediction and completion in autonomous driving. (arXiv:2102.09883v1 [cs.CV])</h2>
<h3>George Eskandar, Alexander Braun, Martin Meinke, Karim Armanious, Bin Yang</h3>
<p>Predicting future 3D LiDAR pointclouds is a challenging task that is useful
in many applications in autonomous driving such as trajectory prediction, pose
forecasting and decision making. In this work, we propose a new LiDAR
prediction framework that is based on generative models namely Variational
Recurrent Neural Networks (VRNNs), titled Stochastic LiDAR Prediction and
Completion (SLPC). Our algorithm is able to address the limitations of previous
video prediction frameworks when dealing with sparse data by spatially
inpainting the depth maps in the upcoming frames. Our contributions can thus be
summarized as follows: we introduce the new task of predicting and completing
depth maps from spatially sparse data, we present a sparse version of VRNNs and
an effective self-supervised training method that does not require any labels.
Experimental results illustrate the effectiveness of our framework in
comparison to the state of the art methods in video prediction.
</p>
<a href="http://arxiv.org/abs/2102.09883" target="_blank">arXiv:2102.09883</a> [<a href="http://arxiv.org/pdf/2102.09883" target="_blank">pdf</a>]

<h2>Condensed Composite Memory Continual Learning. (arXiv:2102.09890v1 [cs.LG])</h2>
<h3>Felix Wiewel, Bin Yang</h3>
<p>Deep Neural Networks (DNNs) suffer from a rapid decrease in performance when
trained on a sequence of tasks where only data of the most recent task is
available. This phenomenon, known as catastrophic forgetting, prevents DNNs
from accumulating knowledge over time. Overcoming catastrophic forgetting and
enabling continual learning is of great interest since it would enable the
application of DNNs in settings where unrestricted access to all the training
data at any time is not always possible, e.g. due to storage limitations or
legal issues. While many recently proposed methods for continual learning use
some training examples for rehearsal, their performance strongly depends on the
number of stored examples. In order to improve performance of rehearsal for
continual learning, especially for a small number of stored examples, we
propose a novel way of learning a small set of synthetic examples which capture
the essence of a complete dataset. Instead of directly learning these synthetic
examples, we learn a weighted combination of shared components for each example
that enables a significant increase in memory efficiency. We demonstrate the
performance of our method on commonly used datasets and compare it to recently
proposed related methods and baselines.
</p>
<a href="http://arxiv.org/abs/2102.09890" target="_blank">arXiv:2102.09890</a> [<a href="http://arxiv.org/pdf/2102.09890" target="_blank">pdf</a>]

<h2>A Variance Controlled Stochastic Method with Biased Estimation for Faster Non-convex Optimization. (arXiv:2102.09893v1 [cs.LG])</h2>
<h3>Jia Bi, Steve R.Gunn</h3>
<p>In this paper, we proposed a new technique, {\em variance controlled
stochastic gradient} (VCSG), to improve the performance of the stochastic
variance reduced gradient (SVRG) algorithm. To avoid over-reducing the variance
of gradient by SVRG, a hyper-parameter $\lambda$ is introduced in VCSG that is
able to control the reduced variance of SVRG. Theory shows that the
optimization method can converge by using an unbiased gradient estimator, but
in practice, biased gradient estimation can allow more efficient convergence to
the vicinity since an unbiased approach is computationally more expensive.
$\lambda$ also has the effect of balancing the trade-off between unbiased and
biased estimations. Secondly, to minimize the number of full gradient
calculations in SVRG, a variance-bounded batch is introduced to reduce the
number of gradient calculations required in each iteration. For smooth
non-convex functions, the proposed algorithm converges to an approximate
first-order stationary point (i.e.
$\mathbb{E}\|\nabla{f}(x)\|^{2}\leq\epsilon$) within
$\mathcal{O}(min\{1/\epsilon^{3/2},n^{1/4}/\epsilon\})$ number of stochastic
gradient evaluations, which improves the leading gradient complexity of
stochastic gradient-based method SCS
$(\mathcal{O}(min\{1/\epsilon^{5/3},n^{2/3}/\epsilon\})$. It is shown
theoretically and experimentally that VCSG can be deployed to improve
convergence.
</p>
<a href="http://arxiv.org/abs/2102.09893" target="_blank">arXiv:2102.09893</a> [<a href="http://arxiv.org/pdf/2102.09893" target="_blank">pdf</a>]

<h2>Self-Taught Semi-Supervised Anomaly Detection on Upper Limb X-rays. (arXiv:2102.09895v1 [cs.CV])</h2>
<h3>Antoine Spahr, Behzad Bozorgtabar, Jean-Philippe Thiran</h3>
<p>Detecting anomalies in musculoskeletal radiographs is of paramount importance
for large-scale screening in the radiology workflow. Supervised deep networks
take for granted a large number of annotations by radiologists, which is often
prohibitively very time-consuming to acquire. Moreover, supervised systems are
tailored to closed set scenarios, e.g., trained models suffer from overfitting
to previously seen rare anomalies at training. Instead, our approach's
rationale is to use task agnostic pretext tasks to leverage unlabeled data
based on a cross-sample similarity measure. Besides, we formulate a complex
distribution of data from normal class within our framework to avoid a
potential bias on the side of anomalies. Through extensive experiments, we show
that our method outperforms baselines across unsupervised and self-supervised
anomaly detection settings on a real-world medical dataset, the MURA dataset.
We also provide rich ablation studies to analyze each training stage's effect
and loss terms on the final performance.
</p>
<a href="http://arxiv.org/abs/2102.09895" target="_blank">arXiv:2102.09895</a> [<a href="http://arxiv.org/pdf/2102.09895" target="_blank">pdf</a>]

<h2>Scribble-Supervised Semantic Segmentation by Uncertainty Reduction on Neural Representation and Self-Supervision on Neural Eigenspace. (arXiv:2102.09896v1 [cs.CV])</h2>
<h3>Zhiyi Pan, Peng Jiang, Yunhai Wang, Changhe Tu, Anthony G. Cohn</h3>
<p>Scribble-supervised semantic segmentation has gained much attention recently
for its promising performance without high-quality annotations. Due to the lack
of supervision, confident and consistent predictions are usually hard to
obtain. Typically, people handle these problems to either adopt an auxiliary
task with the well-labeled dataset or incorporate the graphical model with
additional requirements on scribble annotations. Instead, this work aims to
achieve semantic segmentation by scribble annotations directly without extra
information and other limitations. Specifically, we propose holistic
operations, including minimizing entropy and a network embedded random walk on
neural representation to reduce uncertainty. Given the probabilistic transition
matrix of a random walk, we further train the network with self-supervision on
its neural eigenspace to impose consistency on predictions between related
images. Comprehensive experiments and ablation studies verify the proposed
approach, which demonstrates superiority over others; it is even comparable to
some full-label supervised ones and works well when scribbles are randomly
shrunk or dropped.
</p>
<a href="http://arxiv.org/abs/2102.09896" target="_blank">arXiv:2102.09896</a> [<a href="http://arxiv.org/pdf/2102.09896" target="_blank">pdf</a>]

<h2>Instrumental Variable Value Iteration for Causal Offline Reinforcement Learning. (arXiv:2102.09907v1 [stat.ML])</h2>
<h3>Luofeng Liao, Zuyue Fu, Zhuoran Yang, Mladen Kolar, Zhaoran Wang</h3>
<p>In offline reinforcement learning (RL) an optimal policy is learnt solely
from a priori collected observational data. However, in observational data,
actions are often confounded by unobserved variables. Instrumental variables
(IVs), in the context of RL, are the variables whose influence on the state
variables are all mediated through the action. When a valid instrument is
present, we can recover the confounded transition dynamics through
observational data. We study a confounded Markov decision process where the
transition dynamics admit an additive nonlinear functional form. Using IVs, we
derive a conditional moment restriction (CMR) through which we can identify
transition dynamics based on observational data. We propose a provably
efficient IV-aided Value Iteration (IVVI) algorithm based on a primal-dual
reformulation of CMR. To the best of our knowledge, this is the first provably
efficient algorithm for instrument-aided offline RL.
</p>
<a href="http://arxiv.org/abs/2102.09907" target="_blank">arXiv:2102.09907</a> [<a href="http://arxiv.org/pdf/2102.09907" target="_blank">pdf</a>]

<h2>Fundamentals of Semantic Numeration Systems. Can the Context be Calculated?. (arXiv:2102.09949v1 [cs.AI])</h2>
<h3>Alexander Chunikhin</h3>
<p>This work is the first to propose the concept of a semantic numeration system
(SNS) as a certain class of context-based numeration methods. The development
of the SNS concept required the introduction of fundamentally new concepts such
as a cardinal abstract entity, a cardinal semantic operator, a cardinal
abstract object, a numeration space and a multicardinal number. The main
attention is paid to the key elements of semantic numeration systems - cardinal
semantic operators. A classification of semantic numeration systems is given.
</p>
<a href="http://arxiv.org/abs/2102.09949" target="_blank">arXiv:2102.09949</a> [<a href="http://arxiv.org/pdf/2102.09949" target="_blank">pdf</a>]

<h2>A bi-level encoding scheme for the clustered shortest-path tree problem in multifactorial optimization. (arXiv:2102.09954v1 [cs.AI])</h2>
<h3>Huynh Thi Thanh Binh, Ta Bao Thang, Nguyen Duc Thai, Pham Dinh Thanh</h3>
<p>The Clustered Shortest-Path Tree Problem (CluSPT) plays an important role in
various types of optimization problems in real-life. Recently, some
Multifactorial Evolutionary Algorithm (MFEA) have been introduced to deal with
the CluSPT, however these researches still have some shortcomings such as
evolution operators only perform on complete graphs, huge resource consumption
for finding the solution on large search spaces. To overcome these limitations,
this paper describes a MFEA-based approach to solve the CluSPT. The proposed
algorithm utilizes Dijkstra's algorithm to construct the spanning trees in
clusters while using evolutionary operators for building the spanning tree
connecting clusters. This approach takes advantage of both exact and
approximate algorithms so it enables the algorithm to function efficiently on
complete and sparse graphs alike. Furthermore, evolutionary operators such as
individual encoding and decoding methods are also designed with great
consideration regarding performance and memory usage. We have included a proof
on the repairing method's efficacy in ensuring all solutions are valid. We have
conducted tests on various types of Euclidean instances to assess the
effectiveness of the proposed algorithm and methods. Experiment results point
out the effectiveness of the proposed algorithm existing heuristic algorithms
in most of the test cases. The impact of the proposed MFEA was analyzed and a
possible influential factor that may be useful for further study was also
pointed out.
</p>
<a href="http://arxiv.org/abs/2102.09954" target="_blank">arXiv:2102.09954</a> [<a href="http://arxiv.org/pdf/2102.09954" target="_blank">pdf</a>]

<h2>Subjective Assessments of Legibility in Ancient Manuscript Images -- The SALAMI Dataset. (arXiv:2102.09961v1 [cs.CV])</h2>
<h3>Simon Brenner, Robert Sablatnig</h3>
<p>The research field concerned with the digital restoration of degraded written
heritage lacks a quantitative metric for evaluating its results, which prevents
the comparison of relevant methods on large datasets. Thus, we introduce a
novel dataset of Subjective Assessments of Legibility in Ancient Manuscript
Images (SALAMI) to serve as a ground truth for the development of quantitative
evaluation metrics in the field of digital text restoration. This dataset
consists of 250 images of 50 manuscript regions with corresponding spatial maps
of mean legibility and uncertainty, which are based on a study conducted with
20 experts of philology and paleography. As this study is the first of its
kind, the validity and reliability of its design and the results obtained are
motivated statistically: we report a high intra- and inter-rater agreement and
show that the bulk of variation in the scores is introduced by the images
regions observed and not by controlled or uncontrolled properties of
participants and test environments, thus concluding that the legibility scores
measured are valid attributes of the underlying images.
</p>
<a href="http://arxiv.org/abs/2102.09961" target="_blank">arXiv:2102.09961</a> [<a href="http://arxiv.org/pdf/2102.09961" target="_blank">pdf</a>]

<h2>Gaussian Process Regression in Logarithmic Time. (arXiv:2102.09964v1 [cs.LG])</h2>
<h3>Adrien Corenflos, Zheng Zhao, Simo S&#xe4;rkk\&quot;</h3>
<p>The aim of this article is to present a novel parallelization method for
temporal Gaussian process (GP) regression problems. The method allows for
solving GP regression problems in logarithmic $O(\log N)$ time, where $N$ is
the number of time steps. Our approach uses the state-space representation of
GPs which in its original form allows for linear $O(N)$ time GP regression by
leveraging the Kalman filtering and smoothing methods. By using a recently
proposed parallelization method for Bayesian filters and smoothers, we are able
to reduce the linear computational complexity of the Kalman filter and smoother
solutions to the GP regression problems into logarithmic span complexity, which
transforms into logarithm time complexity when implemented in parallel hardware
such as a graphics processing unit (GPU). We experimentally demonstrate the
computational benefits one simulated and real datasets via our open-source
implementation leveraging the GPflow framework.
</p>
<a href="http://arxiv.org/abs/2102.09964" target="_blank">arXiv:2102.09964</a> [<a href="http://arxiv.org/pdf/2102.09964" target="_blank">pdf</a>]

<h2>Deluca -- A Differentiable Control Library: Environments, Methods, and Benchmarking. (arXiv:2102.09968v1 [cs.RO])</h2>
<h3>Paula Gradu, John Hallman, Daniel Suo, Alex Yu, Naman Agarwal, Udaya Ghai, Karan Singh, Cyril Zhang, Anirudha Majumdar, Elad Hazan</h3>
<p>We present an open-source library of natively differentiable physics and
robotics environments, accompanied by gradient-based control methods and a
benchmark-ing suite. The introduced environments allow auto-differentiation
through the simulation dynamics, and thereby permit fast training of
controllers. The library features several popular environments, including
classical control settings from OpenAI Gym. We also provide a novel
differentiable environment, based on deep neural networks, that simulates
medical ventilation. We give several use-cases of new scientific results
obtained using the library. This includes a medical ventilator simulator and
controller, an adaptive control method for time-varying linear dynamical
systems, and new gradient-based methods for control of linear dynamical systems
with adversarial perturbations.
</p>
<a href="http://arxiv.org/abs/2102.09968" target="_blank">arXiv:2102.09968</a> [<a href="http://arxiv.org/pdf/2102.09968" target="_blank">pdf</a>]

<h2>Implicit Regularization in Tensor Factorization. (arXiv:2102.09972v1 [cs.LG])</h2>
<h3>Noam Razin, Asaf Maman, Nadav Cohen</h3>
<p>Implicit regularization in deep learning is perceived as a tendency of
gradient-based optimization to fit training data with predictors of minimal
"complexity." The fact that only some types of data give rise to generalization
is understood to result from them being especially amenable to fitting with low
complexity predictors. A major challenge towards formalizing this intuition is
to define complexity measures that are quantitative yet capture the essence of
data that admits generalization. With an eye towards this challenge, we analyze
the implicit regularization in tensor factorization, equivalent to a certain
non-linear neural network. We characterize the dynamics that gradient descent
induces on the factorization, and establish a bias towards low tensor rank, in
compliance with existing empirical evidence. Then, motivated by tensor rank
capturing implicit regularization of a non-linear neural network, we
empirically explore it as a measure of complexity, and find that it stays
extremely low when fitting standard datasets. This leads us to believe that
tensor rank may pave way to explaining both implicit regularization of neural
networks, and the properties of real-world data translating it to
generalization.
</p>
<a href="http://arxiv.org/abs/2102.09972" target="_blank">arXiv:2102.09972</a> [<a href="http://arxiv.org/pdf/2102.09972" target="_blank">pdf</a>]

<h2>Discriminant Dynamic Mode Decomposition for Labeled Spatio-Temporal Data Collections. (arXiv:2102.09973v1 [cs.LG])</h2>
<h3>Naoya Takeishi, Keisuke Fujii, Koh Takeuchi, Yoshinobu Kawahara</h3>
<p>Extracting coherent patterns is one of the standard approaches towards
understanding spatio-temporal data. Dynamic mode decomposition (DMD) is a
powerful tool for extracting coherent patterns, but the original DMD and most
of its variants do not consider label information, which is often available as
side information of spatio-temporal data. In this work, we propose a new method
for extracting distinctive coherent patterns from labeled spatio-temporal data
collections, such that they contribute to major differences in a labeled set of
dynamics. We achieve such pattern extraction by incorporating discriminant
analysis into DMD. To this end, we define a kernel function on subspaces
spanned by sets of dynamic modes and develop an objective to take both
reconstruction goodness as DMD and class-separation goodness as discriminant
analysis into account. We illustrate our method using a synthetic dataset and
several real-world datasets. The proposed method can be a useful tool for
exploratory data analysis for understanding spatio-temporal data.
</p>
<a href="http://arxiv.org/abs/2102.09973" target="_blank">arXiv:2102.09973</a> [<a href="http://arxiv.org/pdf/2102.09973" target="_blank">pdf</a>]

<h2>Supporting Financial Inclusion with Graph Machine Learning and Super-App Alternative Data. (arXiv:2102.09974v1 [cs.LG])</h2>
<h3>Luisa Roa, Andr&#xe9;s Rodr&#xed;guez-Rey, Alejandro Correa-Bahnsen, Carlos Valencia</h3>
<p>The presence of Super-Apps have changed the way we think about the
interactions between users and commerce. It then comes as no surprise that it
is also redefining the way banking is done. The paper investigates how
different interactions between users within a Super-App provide a new source of
information to predict borrower behavior. To this end, two experiments with
different graph-based methodologies are proposed, the first uses graph based
features as input in a classification model and the second uses graph neural
networks. Our results show that variables of centrality, behavior of
neighboring users and transactionality of a user constituted new forms of
knowledge that enhance statistical and financial performance of credit risk
models. Furthermore, opportunities are identified for Super-Apps to redefine
the definition of credit risk by contemplating all the environment that their
platforms entail, leading to a more inclusive financial system.
</p>
<a href="http://arxiv.org/abs/2102.09974" target="_blank">arXiv:2102.09974</a> [<a href="http://arxiv.org/pdf/2102.09974" target="_blank">pdf</a>]

<h2>Analytics and Machine Learning in Vehicle Routing Research. (arXiv:2102.10012v1 [cs.LG])</h2>
<h3>Ruibin Bai, Xinan Chen, Zhi-Long Chen, Tianxiang Cui, Shuhui Gong, Wentao He, Xiaoping Jiang, Huan Jin, Jiahuan Jin, Graham Kendall, Jiawei Li, Zheng Lu, Jianfeng Ren, Paul Weng, Ning Xue, Huayan Zhang</h3>
<p>The Vehicle Routing Problem (VRP) is one of the most intensively studied
combinatorial optimisation problems for which numerous models and algorithms
have been proposed. To tackle the complexities, uncertainties and dynamics
involved in real-world VRP applications, Machine Learning (ML) methods have
been used in combination with analytical approaches to enhance problem
formulations and algorithmic performance across different problem solving
scenarios. However, the relevant papers are scattered in several traditional
research fields with very different, sometimes confusing, terminologies. This
paper presents a first, comprehensive review of hybrid methods that combine
analytical techniques with ML tools in addressing VRP problems. Specifically,
we review the emerging research streams on ML-assisted VRP modelling and
ML-assisted VRP optimisation. We conclude that ML can be beneficial in
enhancing VRP modelling, and improving the performance of algorithms for both
online and offline VRP optimisations. Finally, challenges and future
opportunities of VRP research are discussed.
</p>
<a href="http://arxiv.org/abs/2102.10012" target="_blank">arXiv:2102.10012</a> [<a href="http://arxiv.org/pdf/2102.10012" target="_blank">pdf</a>]

<h2>Information-Theoretic Abstractions for Resource-Constrained Agents via Mixed-Integer Linear Programming. (arXiv:2102.10015v1 [cs.RO])</h2>
<h3>Daniel T. Larsson, Dipankar Maity, Panagiotis Tsiotras</h3>
<p>In this paper, a mixed-integer linear programming formulation for the problem
of obtaining task-relevant, multi-resolution, graph abstractions for
resource-constrained agents is presented. The formulation leverages concepts
from information-theoretic signal compression, specifically the information
bottleneck (IB) method, to pose a graph abstraction problem as an optimal
encoder search over the space of multi-resolution trees. The abstractions
emerge in a task-relevant manner as a function of agent information-processing
constraints, and are not provided to the system a priori. We detail our
formulation and show how the problem can be realized as an integer linear
program. A non-trivial numerical example is presented to demonstrate the
utility in employing our approach to obtain hierarchical tree abstractions for
resource-limited agents.
</p>
<a href="http://arxiv.org/abs/2102.10015" target="_blank">arXiv:2102.10015</a> [<a href="http://arxiv.org/pdf/2102.10015" target="_blank">pdf</a>]

<h2>Resolving the Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information. (arXiv:2102.10019v1 [stat.ML])</h2>
<h3>Claire Lazar Reich</h3>
<p>Algorithmic risk assessments hold the promise of greatly advancing accurate
decision-making, but in practice, multiple real-world examples have been shown
to distribute errors disproportionately across demographic groups. In this
paper, we characterize why error disparities arise in the first place. We show
that predictive uncertainty often leads classifiers to systematically
disadvantage groups with lower-mean outcomes, assigning them smaller true and
false positive rates than their higher-mean counterparts. This can occur even
when prediction is group-blind. We prove that to avoid these error imbalances,
individuals in lower-mean groups must either be over-represented among positive
classifications or be assigned more accurate predictions than those in
higher-mean groups. We focus on the latter condition as a solution to bridge
error rate divides and show that data acquisition for low-mean groups can
increase access to opportunity. We call the strategy "affirmative information"
and compare it to traditional affirmative action in the classification task of
identifying creditworthy borrowers.
</p>
<a href="http://arxiv.org/abs/2102.10019" target="_blank">arXiv:2102.10019</a> [<a href="http://arxiv.org/pdf/2102.10019" target="_blank">pdf</a>]

<h2>Learning to Stop with Surprisingly Few Samples. (arXiv:2102.10025v1 [cs.LG])</h2>
<h3>Tianyi Zhang, Daniel Russo, Assaf Zeevi</h3>
<p>We consider a discounted infinite horizon optimal stopping problem. If the
underlying distribution is known a priori, the solution of this problem is
obtained via dynamic programming (DP) and is given by a well known threshold
rule. When information on this distribution is lacking, a natural (though
naive) approach is "explore-then-exploit," whereby the unknown distribution or
its parameters are estimated over an initial exploration phase, and this
estimate is then used in the DP to determine actions over the residual
exploitation phase. We show: (i) with proper tuning, this approach leads to
performance comparable to the full information DP solution; and (ii) despite
common wisdom on the sensitivity of such "plug in" approaches in DP due to
propagation of estimation errors, a surprisingly "short" (logarithmic in the
horizon) exploration horizon suffices to obtain said performance. In cases
where the underlying distribution is heavy-tailed, these observations are even
more pronounced: a ${\it single \, sample}$ exploration phase suffices.
</p>
<a href="http://arxiv.org/abs/2102.10025" target="_blank">arXiv:2102.10025</a> [<a href="http://arxiv.org/pdf/2102.10025" target="_blank">pdf</a>]

<h2>On Approximation in Deep Convolutional Networks: a Kernel Perspective. (arXiv:2102.10032v1 [stat.ML])</h2>
<h3>Alberto Bietti</h3>
<p>The success of deep convolutional networks on on tasks involving
high-dimensional data such as images or audio suggests that they are able to
efficiently approximate certain classes of functions that are not cursed by
dimensionality. In this paper, we study this theoretically and empirically
through the lens of kernel methods, by considering multi-layer convolutional
kernels, which have achieved good empirical performance on standard vision
datasets, and provide theoretical descriptions of over-parameterized
convolutional networks in certain regimes. We find that while expressive
kernels operating on input patches are important at the first layer, simpler
polynomial kernels can suffice in higher layers for good performance. For such
simplified models, we provide a precise functional description of the RKHS and
its regularization properties, highlighting the role of depth for capturing
interactions between different parts of the input signal, and the role of
pooling for encouraging smooth dependence on the global or relative positions
of such parts.
</p>
<a href="http://arxiv.org/abs/2102.10032" target="_blank">arXiv:2102.10032</a> [<a href="http://arxiv.org/pdf/2102.10032" target="_blank">pdf</a>]

<h2>Pose Guided Person Image Generation with Hidden p-Norm Regression. (arXiv:2102.10033v1 [cs.CV])</h2>
<h3>Ting-Yao Hu, Alexander G. Hauptmann</h3>
<p>In this paper, we propose a novel approach to solve the pose guided person
image generation task. We assume that the relation between pose and appearance
information can be described by a simple matrix operation in hidden space.
Based on this assumption, our method estimates a pose-invariant feature matrix
for each identity, and uses it to predict the target appearance conditioned on
the target pose. The estimation process is formulated as a p-norm regression
problem in hidden space. By utilizing the differentiation of the solution of
this regression problem, the parameters of the whole framework can be trained
in an end-to-end manner. While most previous works are only applicable to the
supervised training and single-shot generation scenario, our method can be
easily adapted to unsupervised training and multi-shot generation. Extensive
experiments on the challenging Market-1501 dataset show that our method yields
competitive performance in all the aforementioned variant scenarios.
</p>
<a href="http://arxiv.org/abs/2102.10033" target="_blank">arXiv:2102.10033</a> [<a href="http://arxiv.org/pdf/2102.10033" target="_blank">pdf</a>]

<h2>Continual Learning from Synthetic Data for a Humanoid Exercise Robot. (arXiv:2102.10034v1 [cs.RO])</h2>
<h3>Nicolas Duczek, Matthias Kerzel, Stefan Wermter</h3>
<p>In order to detect and correct physical exercises, a Grow-When-Required
Network (GWR) with recurrent connections, episodic memory and a novel subnode
mechanism is developed in order to learn spatiotemporal relationships of body
movements and poses. Once an exercise is performed, the information of pose and
movement per frame is stored in the GWR. For every frame, the current pose and
motion pair is compared against a predicted output of the GWR, allowing for
feedback not only on the pose but also on the velocity of the motion. In a
practical scenario, a physical exercise is performed by an expert like a
physiotherapist and then used as a reference for a humanoid robot like Pepper
to give feedback on a patient's execution of the same exercise. This approach,
however, comes with two challenges. First, the distance from the humanoid robot
and the position of the user in the camera's view of the humanoid robot have to
be considered by the GWR as well, requiring a robustness against the user's
positioning in the field of view of the humanoid robot. Second, since both the
pose and motion are dependent on the body measurements of the original
performer, the expert's exercise cannot be easily used as a reference. This
paper tackles the first challenge by designing an architecture that allows for
tolerances in translation and rotations regarding the center of the field of
view. For the second challenge, we allow the GWR to grow online on incremental
data. For evaluation, we created a novel exercise dataset with virtual avatars
called the Virtual-Squat dataset. Overall, we claim that our novel architecture
based on the GWR can use a learned exercise reference for different body
variations through continual online learning, while preventing catastrophic
forgetting, enabling for an engaging long-term human-robot interaction with a
humanoid robot.
</p>
<a href="http://arxiv.org/abs/2102.10034" target="_blank">arXiv:2102.10034</a> [<a href="http://arxiv.org/pdf/2102.10034" target="_blank">pdf</a>]

<h2>A Projection Algorithm for the Unitary Weights. (arXiv:2102.10052v1 [cs.LG])</h2>
<h3>Hao-Yuan Chang (University of California, Los Angeles)</h3>
<p>Unitary neural networks are promising alternatives for solving the exploding
and vanishing activation/gradient problem without the need for explicit
normalization that reduces the inference speed. However, they often require
longer training time due to the additional unitary constraints on their weight
matrices. Here we show a novel algorithm using a backpropagation technique with
Lie algebra for computing approximated unitary weights from their pre-trained,
non-unitary counterparts. The unitary networks initialized with these
approximations can reach the desired accuracies much faster, mitigating their
training time penalties while maintaining inference speedups. Our approach will
be instrumental in the adaptation of unitary networks, especially for those
neural architectures where pre-trained weights are freely available.
</p>
<a href="http://arxiv.org/abs/2102.10052" target="_blank">arXiv:2102.10052</a> [<a href="http://arxiv.org/pdf/2102.10052" target="_blank">pdf</a>]

<h2>Effective and Efficient Vote Attack on Capsule Networks. (arXiv:2102.10055v1 [cs.CV])</h2>
<h3>Jindong Gu, Baoyuan Wu, Volker Tresp</h3>
<p>Standard Convolutional Neural Networks (CNNs) can be easily fooled by images
with small quasi-imperceptible artificial perturbations. As alternatives to
CNNs, the recently proposed Capsule Networks (CapsNets) are shown to be more
robust to white-box attacks than CNNs under popular attack protocols. Besides,
the class-conditional reconstruction part of CapsNets is also used to detect
adversarial examples. In this work, we investigate the adversarial robustness
of CapsNets, especially how the inner workings of CapsNets change when the
output capsules are attacked. The first observation is that adversarial
examples misled CapsNets by manipulating the votes from primary capsules.
Another observation is the high computational cost, when we directly apply
multi-step attack methods designed for CNNs to attack CapsNets, due to the
computationally expensive routing mechanism. Motivated by these two
observations, we propose a novel vote attack where we attack votes of CapsNets
directly. Our vote attack is not only effective but also efficient by
circumventing the routing process. Furthermore, we integrate our vote attack
into the detection-aware attack paradigm, which can successfully bypass the
class-conditional reconstruction based detection method. Extensive experiments
demonstrate the superior attack performance of our vote attack on CapsNets.
</p>
<a href="http://arxiv.org/abs/2102.10055" target="_blank">arXiv:2102.10055</a> [<a href="http://arxiv.org/pdf/2102.10055" target="_blank">pdf</a>]

<h2>MolCLR: Molecular Contrastive Learning of Representations via Graph Neural Networks. (arXiv:2102.10056v1 [cs.LG])</h2>
<h3>Yuyang Wang, Jianren Wang, Zhonglin Cao, Amir Barati Farimani</h3>
<p>Molecular machine learning bears promise for efficient molecule property
prediction and drug discovery. However, due to the limited labeled data and the
giant chemical space, machine learning models trained via supervised learning
perform poorly in generalization. This greatly limits the applications of
machine learning methods for molecular design and discovery. In this work, we
present MolCLR: Molecular Contrastive Learning of Representations via Graph
Neural Networks (GNNs), a self-supervised learning framework for large
unlabeled molecule datasets. Specifically, we first build a molecular graph,
where each node represents an atom and each edge represents a chemical bond. A
GNN is then used to encode the molecule graph. We propose three novel molecule
graph augmentations: atom masking, bond deletion, and subgraph removal. A
contrastive estimator is utilized to maximize the agreement of different graph
augmentations from the same molecule. Experiments show that molecule
representations learned by MolCLR can be transferred to multiple downstream
molecular property prediction tasks. Our method thus achieves state-of-the-art
performance on many challenging datasets. We also prove the efficiency of our
proposed molecule graph augmentations on supervised molecular classification
tasks.
</p>
<a href="http://arxiv.org/abs/2102.10056" target="_blank">arXiv:2102.10056</a> [<a href="http://arxiv.org/pdf/2102.10056" target="_blank">pdf</a>]

<h2>Principled Simplicial Neural Networks for Trajectory Prediction. (arXiv:2102.10058v1 [cs.LG])</h2>
<h3>Nicholas Glaze, T. Mitchell Roddenberry, Santiago Segarra</h3>
<p>We consider the construction of neural network architectures for data on
simplicial complexes. In studying maps on the chain complex of a simplicial
complex, we define three desirable properties of a simplicial neural network
architecture: namely, permutation equivariance, orientation equivariance, and
simplicial awareness. The first two properties respectively account for the
fact that the node indexing and the simplex orientations in a simplicial
complex are arbitrary. The last property encodes the desirable feature that the
output of the neural network depends on the entire simplicial complex and not
on a subset of its dimensions. Based on these properties, we propose a simple
convolutional architecture, rooted in tools from algebraic topology, for the
problem of trajectory prediction, and show that it obeys all three of these
properties when an odd, nonlinear activation function is used. We then
demonstrate the effectiveness of this architecture in extrapolating
trajectories on synthetic and real datasets, with particular emphasis on the
gains in generalizability to unseen trajectories.
</p>
<a href="http://arxiv.org/abs/2102.10058" target="_blank">arXiv:2102.10058</a> [<a href="http://arxiv.org/pdf/2102.10058" target="_blank">pdf</a>]

<h2>A Review of Biomedical Datasets Relating to Drug Discovery: A Knowledge Graph Perspective. (arXiv:2102.10062v1 [cs.AI])</h2>
<h3>Stephen Bonner, Ian P Barrett, Cheng Ye, Rowan Swiers, Ola Engkvist, William Hamilton</h3>
<p>Drug discovery and development is an extremely complex process, with high
attrition contributing to the costs of delivering new medicines to patients.
Recently, various machine learning approaches have been proposed and
investigated to help improve the effectiveness and speed of multiple stages of
the drug discovery pipeline. Among these techniques, it is especially those
using Knowledge Graphs that are proving to have considerable promise across a
range of tasks, including drug repurposing, drug toxicity prediction and target
gene-disease prioritisation. In such a knowledge graph-based representation of
drug discovery domains, crucial elements including genes, diseases and drugs
are represented as entities or vertices, whilst relationships or edges between
them indicate some level of interaction. For example, an edge between a disease
and drug entity might represent a successful clinical trial, or an edge between
two drug entities could indicate a potentially harmful interaction.

In order to construct high-quality and ultimately informative knowledge
graphs however, suitable data and information is of course required. In this
review, we detail publicly available primary data sources containing
information suitable for use in constructing various drug discovery focused
knowledge graphs. We aim to help guide machine learning and knowledge graph
practitioners who are interested in applying new techniques to the drug
discovery field, but who may be unfamiliar with the relevant data sources.
Overall we hope this review will help motivate more machine learning
researchers to explore combining knowledge graphs and machine learning to help
solve key and emerging questions in the drug discovery domain.
</p>
<a href="http://arxiv.org/abs/2102.10062" target="_blank">arXiv:2102.10062</a> [<a href="http://arxiv.org/pdf/2102.10062" target="_blank">pdf</a>]

<h2>Probabilistically Guaranteed Satisfaction of Temporal Logic Constraints During Reinforcement Learning. (arXiv:2102.10063v1 [cs.RO])</h2>
<h3>Derya Aksaray, Yasin Yazicioglu, Ahmet Semi Asarkaya</h3>
<p>We present a novel reinforcement learning algorithm for finding optimal
policies in Markov Decision Processes while satisfying temporal logic
constraints with a desired probability throughout the learning process. An
automata-theoretic approach is proposed to ensure probabilistic satisfaction of
the constraint in each episode, which is different from penalizing violations
to achieve constraint satisfaction after a sufficiently large number of
episodes. The proposed approach is based on computing a lower bound on the
probability of constraint satisfaction and adjusting the exploration behavior
as needed. We present theoretical results on the probabilistic constraint
satisfaction achieved by the proposed approach. We also numerically demonstrate
the proposed idea in a drone scenario, where the constraint is to perform
periodically arriving pick-up and delivery tasks and the objective is to fly
over high-reward zones to simultaneously perform aerial monitoring.
</p>
<a href="http://arxiv.org/abs/2102.10063" target="_blank">arXiv:2102.10063</a> [<a href="http://arxiv.org/pdf/2102.10063" target="_blank">pdf</a>]

<h2>Rapid Multi-Physics Simulation for Electro-Thermal Origami Robotic Systems. (arXiv:2102.10078v1 [cs.RO])</h2>
<h3>Yi Zhu, Evgueni T. Filipov</h3>
<p>Electro-thermally actuated origami provides a novel method for creating 3-D
systems with advanced morphing and functional capabilities. However, it is
currently difficult to simulate the multi-physical behavior of such systems
because the electro-thermal actuation and large folding deformations are highly
interdependent. In this work, we introduce a rapid multi-physics simulation
framework for electro-thermal origami robotic systems that can capture:
thermo-mechancially coupled actuation, inter panel contact, heat transfer,
large deformation folding, and other complex loading applied onto the origami.
Comparisons with finite element simulations validate the proposed framework for
capturing origami heat transfer with different system geometries, materials,
and surrounding environments. Verification against physical electro-thermal
micro origami further demonstrates the validity of the proposed model.
Simulations of more complex origami patterns and a case study for origami
optimization are provided as application examples to show the capability and
efficiency of the model. The framework provides a novel simulation tool for
analysis, design, control, and optimization of active origami robotic systems,
pushing the boundary for feasible morphing and functional capability.
</p>
<a href="http://arxiv.org/abs/2102.10078" target="_blank">arXiv:2102.10078</a> [<a href="http://arxiv.org/pdf/2102.10078" target="_blank">pdf</a>]

<h2>Output-Weighted Sampling for Multi-Armed Bandits with Extreme Payoffs. (arXiv:2102.10085v1 [cs.LG])</h2>
<h3>Yibo Yang, Antoine Blanchard, Themistoklis Sapsis, Paris Perdikaris</h3>
<p>We present a new type of acquisition functions for online decision making in
multi-armed and contextual bandit problems with extreme payoffs. Specifically,
we model the payoff function as a Gaussian process and formulate a novel type
of upper confidence bound (UCB) acquisition function that guides exploration
towards the bandits that are deemed most relevant according to the variability
of the observed rewards. This is achieved by computing a tractable likelihood
ratio that quantifies the importance of the output relative to the inputs and
essentially acts as an \textit{attention mechanism} that promotes exploration
of extreme rewards. We demonstrate the benefits of the proposed methodology
across several synthetic benchmarks, as well as a realistic example involving
noisy sensor network data. Finally, we provide a JAX library for efficient
bandit optimization using Gaussian processes.
</p>
<a href="http://arxiv.org/abs/2102.10085" target="_blank">arXiv:2102.10085</a> [<a href="http://arxiv.org/pdf/2102.10085" target="_blank">pdf</a>]

<h2>Compact and adaptive multiplane images for view synthesis. (arXiv:2102.10086v1 [cs.CV])</h2>
<h3>Julia Navarro, Neus Sabater</h3>
<p>Recently, learning methods have been designed to create Multiplane Images
(MPIs) for view synthesis. While MPIs are extremely powerful and facilitate
high quality renderings, a great amount of memory is required, making them
impractical for many applications. In this paper, we propose a learning method
that optimizes the available memory to render compact and adaptive MPIs. Our
MPIs avoid redundant information and take into account the scene geometry to
determine the depth sampling.
</p>
<a href="http://arxiv.org/abs/2102.10086" target="_blank">arXiv:2102.10086</a> [<a href="http://arxiv.org/pdf/2102.10086" target="_blank">pdf</a>]

<h2>Mine Your Own vieW: Self-Supervised Learning Through Across-Sample Prediction. (arXiv:2102.10106v1 [cs.LG])</h2>
<h3>Mehdi Azabou, Mohammad Gheshlaghi Azar, Ran Liu, Chi-Heng Lin, Erik C. Johnson, Kiran Bhaskaran-Nair, Max Dabagia, Keith B. Hengen, William Gray-Roncal, Michal Valko, Eva L. Dyer</h3>
<p>State-of-the-art methods for self-supervised learning (SSL) build
representations by maximizing the similarity between different augmented
"views" of a sample. Because these approaches try to match views of the same
sample, they can be too myopic and fail to produce meaningful results when
augmentations are not sufficiently rich. This motivates the use of the dataset
itself to find similar, yet distinct, samples to serve as views for one
another. In this paper, we introduce Mine Your Own vieW (MYOW), a new approach
for building across-sample prediction into SSL. The idea behind our approach is
to actively mine views, finding samples that are close in the representation
space of the network, and then predict, from one sample's latent
representation, the representation of a nearby sample. In addition to showing
the promise of MYOW on standard datasets used in computer vision, we highlight
the power of this idea in a novel application in neuroscience where rich
augmentations are not already established. When applied to neural datasets,
MYOW outperforms other self-supervised approaches in all examples (in some
cases by more than 10%), and surpasses the supervised baseline for most
datasets. By learning to predict the latent representation of similar samples,
we show that it is possible to learn good representations in new domains where
augmentations are still limited.
</p>
<a href="http://arxiv.org/abs/2102.10106" target="_blank">arXiv:2102.10106</a> [<a href="http://arxiv.org/pdf/2102.10106" target="_blank">pdf</a>]

<h2>Quantum spectral analysis: frequency in time, with applications to signal and image processing. (arXiv:1611.02302v8 [cs.CV] UPDATED)</h2>
<h3>Mario Mastriani</h3>
<p>A quantum time-dependent spectrum analysis, or simply, quantum spectral
analysis (QSA) is presented in this work, and it is based on Schrodinger
equation, which is a partial differential equation that describes how the
quantum state of a non-relativistic physical system changes with time. In
classic world is named frequency in time (FIT), which is presented here in
opposition and as a complement of traditional spectral analysis
frequency-dependent based on Fourier theory. Besides, FIT is a metric, which
assesses the impact of the flanks of a signal on its frequency spectrum, which
is not taken into account by Fourier theory and even less in real time. Even
more, and unlike all derived tools from Fourier Theory (i.e., continuous,
discrete, fast, short-time, fractional and quantum Fourier Transform, as well
as, Gabor) FIT has the following advantages: a) compact support with excellent
energy output treatment, b) low computational cost, O(N) for signals and O(N2)
for images, c) it does not have phase uncertainties (indeterminate phase for
magnitude = 0) as Discrete and Fast Fourier Transform (DFT, FFT, respectively),
d) among others. In fact, FIT constitutes one side of a triangle (which from
now on is closed) and it consists of the original signal in time, spectral
analysis based on Fourier Theory and FIT. Thus a toolbox is completed, which it
is essential for all applications of Digital Signal Processing (DSP) and
Digital Image Processing (DIP); and, even, in the latter, FIT allows edge
detection (which is called flank detection in case of signals), denoising,
despeckling, compression, and superresolution of still images. Such
applications include signals intelligence and imagery intelligence. On the
other hand, we will present other DIP tools, which are also derived from the
Schrodinger equation.
</p>
<a href="http://arxiv.org/abs/1611.02302" target="_blank">arXiv:1611.02302</a> [<a href="http://arxiv.org/pdf/1611.02302" target="_blank">pdf</a>]

<h2>Dynamic Assortment Selection under the Nested Logit Models. (arXiv:1806.10410v2 [stat.ML] UPDATED)</h2>
<h3>Xi Chen, Chao Shi, Yining Wang, Yuan Zhou</h3>
<p>We study a stylized dynamic assortment planning problem during a selling
season of finite length $T$. At each time period, the seller offers an arriving
customer an assortment of substitutable products and the customer makes the
purchase among offered products according to a discrete choice model. The goal
of the seller is to maximize the expected revenue, or equivalently, to minimize
the worst-case expected regret. One key challenge is that utilities of products
are unknown to the seller and need to be learned. Although the dynamic
assortment planning problem has received increasing attention in revenue
management, most existing work is based on the multinomial logit choice models
(MNL). In this paper, we study the problem of dynamic assortment planning under
a more general choice model -- the nested logit model, which models
hierarchical choice behavior and is ``the most widely used member of the GEV
(generalized extreme value) family''. By leveraging the revenue-ordered
structure of the optimal assortment within each nest, we develop a novel upper
confidence bound (UCB) policy with an aggregated estimation scheme. Our policy
simultaneously learns customers' choice behavior and makes dynamic decisions on
assortments based on the current knowledge. It achieves the accumulated regret
at the order of $\tilde{O}(\sqrt{MNT})$, where $M$ is the number of nests and
$N$ is the number of products in each nest. We further provide a lower bound
result of $\Omega(\sqrt{MT})$, which shows the near optimality of the upper
bound when $T$ is much larger than $M$ and $N$. When the number of items per
nest $N$ is large, we further provide a discretization heuristic for better
performance of our algorithm. Numerical results are presented to demonstrate
the empirical performance of our proposed algorithms.
</p>
<a href="http://arxiv.org/abs/1806.10410" target="_blank">arXiv:1806.10410</a> [<a href="http://arxiv.org/pdf/1806.10410" target="_blank">pdf</a>]

<h2>Information Bottleneck Theory on Convolutional Neural Networks. (arXiv:1911.03722v2 [stat.ML] UPDATED)</h2>
<h3>Junjie Li, Ding Liu</h3>
<p>Recent years, many researches attempt to open the black box of deep neural
networks and propose a various of theories to understand it. Among them,
Information Bottleneck (IB) theory claims that there are two distinct phases
consisting of fitting phase and compression phase in the course of training.
This statement attracts many attentions since its success in explaining the
inner behavior of feedforward neural networks. In this paper, we employ IB
theory to understand the dynamic behavior of convolutional neural networks
(CNNs) and investigate how the fundamental features such as convolutional layer
width, kernel size, network depth, pooling layers and multi-fully connected
layer have impact on the performance of CNNs. In particular, through a series
of experimental analysis on benchmark of MNIST and Fashion-MNIST, we
demonstrate that the compression phase is not observed in all these cases. This
shows us the CNNs have a rather complicated behavior than feedforward neural
networks.
</p>
<a href="http://arxiv.org/abs/1911.03722" target="_blank">arXiv:1911.03722</a> [<a href="http://arxiv.org/pdf/1911.03722" target="_blank">pdf</a>]

<h2>StickyPillars: Robust and Efficient Feature Matching on Point Clouds using Graph Neural Networks. (arXiv:2002.03983v3 [cs.CV] UPDATED)</h2>
<h3>Kai Fischer, Martin Simon, Florian Oelsner, Stefan Milz, Horst-Michael Gross, Patrick Maeder</h3>
<p>Robust point cloud registration in real-time is an important prerequisite for
many mapping and localization algorithms. Traditional methods like ICP tend to
fail without good initialization, insufficient overlap or in the presence of
dynamic objects. Modern deep learning based registration approaches present
much better results, but suffer from a heavy run-time. We overcome these
drawbacks by introducing StickyPillars, a fast, accurate and extremely robust
deep middle-end 3D feature matching method on point clouds. It uses graph
neural networks and performs context aggregation on sparse 3D key-points with
the aid of transformer based multi-head self and cross-attention. The network
output is used as the cost for an optimal transport problem whose solution
yields the final matching probabilities. The system does not rely on hand
crafted feature descriptors or heuristic matching strategies. We present
state-of-art art accuracy results on the registration problem demonstrated on
the KITTI dataset while being four times faster then leading deep methods.
Furthermore, we integrate our matching system into a LiDAR odometry pipeline
yielding most accurate results on the KITTI odometry dataset. Finally, we
demonstrate robustness on KITTI odometry. Our method remains stable in accuracy
where state-of-the-art procedures fail on frame drops and higher speeds.
</p>
<a href="http://arxiv.org/abs/2002.03983" target="_blank">arXiv:2002.03983</a> [<a href="http://arxiv.org/pdf/2002.03983" target="_blank">pdf</a>]

<h2>Conceptual Game Expansion. (arXiv:2002.09636v3 [cs.AI] UPDATED)</h2>
<h3>Matthew Guzdial, Mark Riedl</h3>
<p>Automated game design is the problem of automatically producing games through
computational processes. Traditionally, these methods have relied on the
authoring of search spaces by a designer, defining the space of all possible
games for the system to author. In this paper, we instead learn representations
of existing games from gameplay video and use these to approximate a search
space of novel games. In a human subject study we demonstrate that these novel
games are indistinguishable from human games in terms of challenge, and that
one of the novel games was equivalent to one of the human games in terms of
fun, frustration, and likeability.
</p>
<a href="http://arxiv.org/abs/2002.09636" target="_blank">arXiv:2002.09636</a> [<a href="http://arxiv.org/pdf/2002.09636" target="_blank">pdf</a>]

<h2>Alternating the Population and Control Neural Networks to Solve High-Dimensional Stochastic Mean-Field Games. (arXiv:2002.10113v3 [cs.LG] UPDATED)</h2>
<h3>Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, Stanley J. Osher</h3>
<p>We present APAC-Net, an alternating population and agent control neural
network for solving stochastic mean field games (MFGs). Our algorithm is geared
toward high-dimensional instances of MFGs that are beyond reach with existing
solution methods. We achieve this in two steps. First, we take advantage of the
underlying variational primal-dual structure that MFGs exhibit and phrase it as
a convex-concave saddle point problem. Second, we parameterize the value and
density functions by two neural networks, respectively. By phrasing the problem
in this manner, solving the MFG can be interpreted as a special case of
training a generative adversarial network (GAN). We show the potential of our
method on up to 100-dimensional MFG problems.
</p>
<a href="http://arxiv.org/abs/2002.10113" target="_blank">arXiv:2002.10113</a> [<a href="http://arxiv.org/pdf/2002.10113" target="_blank">pdf</a>]

<h2>Using the Split Bregman Algorithm to Solve the Self-repelling Snake Model. (arXiv:2003.12693v2 [cs.CV] UPDATED)</h2>
<h3>Huizhu Pan, Jintao Song, Wanquan Liu, Ling Li, Guanglu Zhou, Lu Tan, Shichu Chen</h3>
<p>Preserving contour topology during image segmentation is useful in many
practical scenarios. By keeping the contours isomorphic, it is possible to
prevent over-segmentation and under-segmentation, as well as to adhere to given
topologies. The Self-repelling Snake model (SR) is a variational model that
preserves contour topology by combining a non-local repulsion term with the
geodesic active contour model (GAC). The SR is traditionally solved using the
additive operator splitting (AOS) scheme. In our paper, we propose an
alternative solution to the SR using the Split Bregman method. Our algorithm
breaks the problem down into simpler sub-problems to use lower-order evolution
equations and a simple projection scheme rather than re-initialization. The
sub-problems can be solved via fast Fourier transform (FFT) or an approximate
soft thresholding formula which maintains stability, shortening the convergence
time, and reduces the memory requirement. The Split Bregman and AOS algorithms
are compared theoretically and experimentally.
</p>
<a href="http://arxiv.org/abs/2003.12693" target="_blank">arXiv:2003.12693</a> [<a href="http://arxiv.org/pdf/2003.12693" target="_blank">pdf</a>]

<h2>Certifiable Relative Pose Estimation. (arXiv:2003.13732v2 [cs.CV] UPDATED)</h2>
<h3>Mercedes Garcia-Salguero, Jesus Briales, Javier Gonzalez-Jimenez</h3>
<p>In this paper we present the first fast optimality certifier for the
non-minimal version of the Relative Pose problem for calibrated cameras from
epipolar constraints. The proposed certifier is based on Lagrangian duality and
relies on a novel closed-form expression for dual points. We also leverage an
efficient solver that performs local optimization on the manifold of the
original problem's non-convex domain. The optimality of the solution is then
checked via our novel fast certifier. The extensive conducted experiments
demonstrate that, despite its simplicity, this certifiable solver performs
excellently on synthetic data, repeatedly attaining the (certified \textit{a
posteriori}) optimal solution and shows a satisfactory performance on real
data.
</p>
<a href="http://arxiv.org/abs/2003.13732" target="_blank">arXiv:2003.13732</a> [<a href="http://arxiv.org/pdf/2003.13732" target="_blank">pdf</a>]

<h2>A Weighted Difference of Anisotropic and Isotropic Total Variation for Relaxed Mumford-Shah Color and Multiphase Image Segmentation. (arXiv:2005.04401v3 [cs.CV] UPDATED)</h2>
<h3>Kevin Bui, Fredrick Park, Yifei Lou, Jack Xin</h3>
<p>In a class of piecewise-constant image segmentation models, we propose to
incorporate a weighted difference of anisotropic and isotropic total variation
(AITV) to regularize the partition boundaries in an image. In particular, we
replace the TV regularization in the Chan-Vese segmentation model and a fuzzy
region competition model by the proposed AITV. To deal with the nonconvex
nature of AITV, we apply the difference-of-convex algorithm (DCA), in which the
subproblems can be minimized by the primal-dual hybrid gradient method with
linesearch. The convergence of the DCA scheme is analyzed. In addition, a
generalization to color image segmentation is discussed. In the numerical
experiments, we compare the proposed models with the classic convex approaches
and the two-stage segmentation methods (smoothing and then thresholding) on
various images, showing that our models are effective in image segmentation and
robust with respect to impulsive noises.
</p>
<a href="http://arxiv.org/abs/2005.04401" target="_blank">arXiv:2005.04401</a> [<a href="http://arxiv.org/pdf/2005.04401" target="_blank">pdf</a>]

<h2>Mirror Descent Policy Optimization. (arXiv:2005.09814v4 [cs.LG] UPDATED)</h2>
<h3>Manan Tomar, Lior Shani, Yonathan Efroni, Mohammad Ghavamzadeh</h3>
<p>Mirror descent (MD), a well-known first-order method in constrained convex
optimization, has recently been shown as an important tool to analyze
trust-region algorithms in reinforcement learning (RL). Inspired by such
theoretical analyses, we propose an efficient RL algorithm, called {\em mirror
descent policy optimization} (MDPO). MDPO iteratively updates the policy by
approximately solving a trust-region problem, whose objective function consists
of two terms: a linearization of the standard RL objective and a proximity term
that restricts two consecutive policies to be close to each other. Each update
performs this approximation by taking multiple gradient steps on this objective
function. We derive {\em on-policy} and {\em off-policy} variants of MDPO,
while emphasizing important design choices motivated by the existing theory of
MD in RL. We highlight the connections between on-policy MDPO and two popular
trust-region RL algorithms: TRPO and PPO, and show that explicitly enforcing
the trust-region constraint is in fact {\em not} a necessity for high
performance gains in TRPO. We then show how the popular soft actor-critic (SAC)
algorithm can be derived by slight modifications of off-policy MDPO. Overall,
MDPO is derived from the MD principles, offers a unified approach to viewing a
number of popular RL algorithms, and performs better than or on-par with TRPO,
PPO, and SAC in a number of continuous control tasks.
</p>
<a href="http://arxiv.org/abs/2005.09814" target="_blank">arXiv:2005.09814</a> [<a href="http://arxiv.org/pdf/2005.09814" target="_blank">pdf</a>]

<h2>Conditional Sampling With Monotone GANs. (arXiv:2006.06755v2 [stat.ML] UPDATED)</h2>
<h3>Nikola Kovachki, Ricardo Baptista, Bamdad Hosseini, Youssef Marzouk</h3>
<p>We present a new approach for sampling conditional probability measures,
enabling consistent uncertainty quantification in supervised learning tasks. We
construct a mapping that transforms a reference measure to the measure of the
output conditioned on new inputs. The mapping is trained via a modification of
generative adversarial networks (GANs), called monotone GANs, that imposes
monotonicity and a block triangular structure. We present theoretical
guarantees for the consistency of our proposed method, as well as numerical
experiments demonstrating the ability of our method to accurately sample
conditional measures in applications ranging from inverse problems to image
in-painting.
</p>
<a href="http://arxiv.org/abs/2006.06755" target="_blank">arXiv:2006.06755</a> [<a href="http://arxiv.org/pdf/2006.06755" target="_blank">pdf</a>]

<h2>Adaptive Gradient Methods Converge Faster with Over-Parameterization (but you should do a line-search). (arXiv:2006.06835v3 [cs.LG] UPDATED)</h2>
<h3>Sharan Vaswani, Issam Laradji, Frederik Kunstner, Si Yi Meng, Mark Schmidt, Simon Lacoste-Julien</h3>
<p>Adaptive gradient methods are typically used for training over-parameterized
models. To better understand their behaviour, we study a simplistic setting --
smooth, convex losses with models over-parameterized enough to interpolate the
data. In this setting, we prove that AMSGrad with constant step-size and
momentum converges to the minimizer at a faster $O(1/T)$ rate. When
interpolation is only approximately satisfied, constant step-size AMSGrad
converges to a neighbourhood of the solution at the same rate, while AdaGrad is
robust to the violation of interpolation. However, even for simple convex
problems satisfying interpolation, the empirical performance of both methods
heavily depends on the step-size and requires tuning, questioning their
adaptivity. We alleviate this problem by automatically determining the
step-size using stochastic line-search or Polyak step-sizes. With these
techniques, we prove that both AdaGrad and AMSGrad retain their convergence
guarantees, without needing to know problem-dependent constants. Empirically,
we demonstrate that these techniques improve the convergence and generalization
of adaptive gradient methods across tasks, from binary classification with
kernel mappings to multi-class classification with deep networks.
</p>
<a href="http://arxiv.org/abs/2006.06835" target="_blank">arXiv:2006.06835</a> [<a href="http://arxiv.org/pdf/2006.06835" target="_blank">pdf</a>]

<h2>Stochastic Optimization for Performative Prediction. (arXiv:2006.06887v4 [cs.LG] UPDATED)</h2>
<h3>Celestine Mendler-D&#xfc;nner, Juan C. Perdomo, Tijana Zrnic, Moritz Hardt</h3>
<p>In performative prediction, the choice of a model influences the distribution
of future data, typically through actions taken based on the model's
predictions.

We initiate the study of stochastic optimization for performative prediction.
What sets this setting apart from traditional stochastic optimization is the
difference between merely updating model parameters and deploying the new
model. The latter triggers a shift in the distribution that affects future
data, while the former keeps the distribution as is.

Assuming smoothness and strong convexity, we prove rates of convergence for
both greedily deploying models after each stochastic update (greedy deploy) as
well as for taking several updates before redeploying (lazy deploy). In both
cases, our bounds smoothly recover the optimal $O(1/k)$ rate as the strength of
performativity decreases. Furthermore, they illustrate how depending on the
strength of performative effects, there exists a regime where either approach
outperforms the other. We experimentally explore the trade-off on both
synthetic data and a strategic classification simulator.
</p>
<a href="http://arxiv.org/abs/2006.06887" target="_blank">arXiv:2006.06887</a> [<a href="http://arxiv.org/pdf/2006.06887" target="_blank">pdf</a>]

<h2>Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels. (arXiv:2006.07556v2 [cs.LG] UPDATED)</h2>
<h3>Binxin Ru, Xingchen Wan, Xiaowen Dong, Michael Osborne</h3>
<p>Current neural architecture search (NAS) strategies focus only on finding a
single, good, architecture. They offer little insight into why a specific
network is performing well, or how we should modify the architecture if we want
further improvements. We propose a Bayesian optimisation (BO) approach for NAS
that combines the Weisfeiler-Lehman graph kernel with a Gaussian process
surrogate. Our method optimises the architecture in a highly data-efficient
manner: it is capable of capturing the topological structures of the
architectures and is scalable to large graphs, thus making the high-dimensional
and graph-like search spaces amenable to BO. More importantly, our method
affords interpretability by discovering useful network features and their
corresponding impact on the network performance. Indeed, we demonstrate
empirically that our surrogate model is capable of identifying useful motifs
which can guide the generation of new architectures. We finally show that our
method outperforms existing NAS approaches to achieve the state of the art on
both closed- and open-domain search spaces.
</p>
<a href="http://arxiv.org/abs/2006.07556" target="_blank">arXiv:2006.07556</a> [<a href="http://arxiv.org/pdf/2006.07556" target="_blank">pdf</a>]

<h2>Free-rider Attacks on Model Aggregation in Federated Learning. (arXiv:2006.11901v4 [cs.LG] UPDATED)</h2>
<h3>Yann Fraboni, Richard Vidal, Marco Lorenzi</h3>
<p>Free-rider attacks against federated learning consist in dissimulating
participation to the federated learning process with the goal of obtaining the
final aggregated model without actually contributing with any data. This kind
of attacks is critical in sensitive applications of federated learning, where
data is scarce and the model has high commercial value. We introduce here the
first theoretical and experimental analysis of free-rider attacks on federated
learning schemes based on iterative parameters aggregation, such as FedAvg or
FedProx, and provide formal guarantees for these attacks to converge to the
aggregated models of the fair participants. We first show that a
straightforward implementation of this attack can be simply achieved by not
updating the local parameters during the iterative federated optimization. As
this attack can be detected by adopting simple countermeasures at the server
level, we subsequently study more complex disguising schemes based on
stochastic updates of the free-rider parameters. We demonstrate the proposed
strategies on a number of experimental scenarios, in both iid and non-iid
settings. We conclude by providing recommendations to avoid free-rider attacks
in real world applications of federated learning, especially in sensitive
domains where security of data and models is critical.
</p>
<a href="http://arxiv.org/abs/2006.11901" target="_blank">arXiv:2006.11901</a> [<a href="http://arxiv.org/pdf/2006.11901" target="_blank">pdf</a>]

<h2>Learning to Segment from Scribbles using Multi-scale Adversarial Attention Gates. (arXiv:2007.01152v2 [cs.CV] UPDATED)</h2>
<h3>Gabriele Valvano, Andrea Leo, Sotirios A. Tsaftaris</h3>
<p>Large, fine-grained image segmentation datasets, annotated at pixel-level,
are difficult to obtain, particularly in medical imaging, where annotations
also require expert knowledge. Weakly-supervised learning can train models by
relying on weaker forms of annotation, such as scribbles. Here, we learn to
segment using scribble annotations in an adversarial game. With unpaired
segmentation masks, we train a multi-scale GAN to generate realistic
segmentation masks at multiple resolutions, while we use scribbles to learn
their correct position in the image. Central to the model's success is a novel
attention gating mechanism, which we condition with adversarial signals to act
as a shape prior, resulting in better object localization at multiple scales.
Subject to adversarial conditioning, the segmentor learns attention maps that
are semantic, suppress the noisy activations outside the objects, and reduce
the vanishing gradient problem in the deeper layers of the segmentor. We
evaluated our model on several medical (ACDC, LVSC, CHAOS) and non-medical
(PPSS) datasets, and we report performance levels matching those achieved by
models trained with fully annotated segmentation masks. We also demonstrate
extensions in a variety of settings: semi-supervised learning; combining
multiple scribble sources (a crowdsourcing scenario) and multi-task learning
(combining scribble and mask supervision). We release expert-made scribble
annotations for the ACDC dataset, and the code used for the experiments, at
https://vios-s.github.io/multiscale-adversarial-attention-gates.
</p>
<a href="http://arxiv.org/abs/2007.01152" target="_blank">arXiv:2007.01152</a> [<a href="http://arxiv.org/pdf/2007.01152" target="_blank">pdf</a>]

<h2>Ridge Regression with Over-Parametrized Two-Layer Networks Converge to Ridgelet Spectrum. (arXiv:2007.03441v2 [cs.LG] UPDATED)</h2>
<h3>Sho Sonoda, Isao Ishikawa, Masahiro Ikeda</h3>
<p>Characterization of local minima draws much attention in theoretical studies
of deep learning. In this study, we investigate the distribution of parameters
in an over-parametrized finite neural network trained by ridge regularized
empirical square risk minimization (RERM). We develop a new theory of ridgelet
transform, a wavelet-like integral transform that provides a powerful and
general framework for the theoretical study of neural networks involving not
only the ReLU but general activation functions. We show that the distribution
of the parameters converges to a spectrum of the ridgelet transform. This
result provides a new insight into the characterization of the local minima of
neural networks, and the theoretical background of an inductive bias theory
based on lazy regimes. We confirm the visual resemblance between the parameter
distribution trained by SGD, and the ridgelet spectrum calculated by numerical
integration through numerical experiments with finite models.
</p>
<a href="http://arxiv.org/abs/2007.03441" target="_blank">arXiv:2007.03441</a> [<a href="http://arxiv.org/pdf/2007.03441" target="_blank">pdf</a>]

<h2>Beyond Prioritized Replay: Sampling States in Model-Based Reinforcement Learning via Simulated Priorities. (arXiv:2007.09569v2 [cs.AI] UPDATED)</h2>
<h3>Jincheng Mei, Yangchen Pan, Amir-massoud Farahmand, Hengshuai Yao, Martha White</h3>
<p>The prioritized Experience Replay (ER) method has attracted great attention;
however, there is little theoretical understanding about why it can help and
its limitations. In this work, we take a deep look at the prioritized ER. In a
supervised learning setting, we show the equivalence between the error-based
prioritized sampling method for mean squared error and uniform sampling for
cubic power loss. We then provide theoretical insight into why it improves
convergence rate upon uniform sampling during early learning. Based on the
insight, we further point out two limitations of the prioritized ER method: 1)
outdated priorities and 2) insufficient coverage of the sample space. To
mitigate the limitations, we propose our model-based stochastic gradient
Langevin dynamics sampling method. We show that our method does provide states
distributed close to an ideal prioritized sampling distribution estimated by
the brute-force method, which does not suffer from the two limitations. We
conduct experiments on both discrete and continuous control problems to show
our approach's efficacy and examine the practical implication of our method in
an autonomous driving application.
</p>
<a href="http://arxiv.org/abs/2007.09569" target="_blank">arXiv:2007.09569</a> [<a href="http://arxiv.org/pdf/2007.09569" target="_blank">pdf</a>]

<h2>Adversarially Robust Learning via Entropic Regularization. (arXiv:2008.12338v2 [cs.LG] UPDATED)</h2>
<h3>Gauri Jagatap, Ameya Joshi, Animesh Basak Chowdhury, Siddharth Garg, Chinmay Hegde</h3>
<p>In this paper we propose a new family of algorithms, ATENT, for training
adversarially robust deep neural networks. We formulate a new loss function
that is equipped with an additional entropic regularization. Our loss function
considers the contribution of adversarial samples that are drawn from a
specially designed distribution in the data space that assigns high probability
to points with high loss and in the immediate neighborhood of training samples.
Our proposed algorithms optimize this loss to seek adversarially robust valleys
of the loss landscape. Our approach achieves competitive (or better)
performance in terms of robust classification accuracy as compared to several
state-of-the-art robust learning approaches on benchmark datasets such as MNIST
and CIFAR-10.
</p>
<a href="http://arxiv.org/abs/2008.12338" target="_blank">arXiv:2008.12338</a> [<a href="http://arxiv.org/pdf/2008.12338" target="_blank">pdf</a>]

<h2>Beyond variance reduction: Understanding the true impact of baselines on policy optimization. (arXiv:2008.13773v3 [cs.LG] UPDATED)</h2>
<h3>Wesley Chung, Valentin Thomas, Marlos C. Machado, Nicolas Le Roux</h3>
<p>Bandit and reinforcement learning (RL) problems can often be framed as
optimization problems where the goal is to maximize average performance while
having access only to stochastic estimates of the true gradient. Traditionally,
stochastic optimization theory predicts that learning dynamics are governed by
the curvature of the loss function and the noise of the gradient estimates. In
this paper we demonstrate that this is not the case for bandit and RL problems.
To allow our analysis to be interpreted in light of multi-step MDPs, we focus
on techniques derived from stochastic optimization principles (e.g., natural
policy gradient and EXP3) and we show that some standard assumptions from
optimization theory are violated in these problems. We present theoretical
results showing that, at least for bandit problems, curvature and noise are not
sufficient to explain the learning dynamics and that seemingly innocuous
choices like the baseline can determine whether an algorithm converges. These
theoretical findings match our empirical evaluation, which we extend to
multi-state MDPs.
</p>
<a href="http://arxiv.org/abs/2008.13773" target="_blank">arXiv:2008.13773</a> [<a href="http://arxiv.org/pdf/2008.13773" target="_blank">pdf</a>]

<h2>HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients. (arXiv:2010.01264v2 [cs.LG] UPDATED)</h2>
<h3>Enmao Diao, Jie Ding, Vahid Tarokh</h3>
<p>Federated Learning (FL) is a method of training machine learning models on
private data distributed over a large number of possibly heterogeneous clients
such as mobile phones and IoT devices. In this work, we propose a new federated
learning framework named HeteroFL to address heterogeneous clients equipped
with very different computation and communication capabilities. Our solution
can enable the training of heterogeneous local models with varying computation
complexities and still produce a single global inference model. For the first
time, our method challenges the underlying assumption of existing work that
local models have to share the same architecture as the global model. We
demonstrate several strategies to enhance FL training and conduct extensive
empirical evaluations, including five computation complexity levels of three
model architecture on three datasets. We show that adaptively distributing
subnetworks according to clients' capabilities is both computation and
communication efficient.
</p>
<a href="http://arxiv.org/abs/2010.01264" target="_blank">arXiv:2010.01264</a> [<a href="http://arxiv.org/pdf/2010.01264" target="_blank">pdf</a>]

<h2>Torchattacks: A PyTorch Repository for Adversarial Attacks. (arXiv:2010.01950v3 [cs.LG] UPDATED)</h2>
<h3>Hoki Kim</h3>
<p>Torchattacks is a PyTorch library that contains adversarial attacks to
generate adversarial examples and to verify the robustness of deep learning
models. The code can be found at
https://github.com/Harry24k/adversarial-attacks-pytorch.
</p>
<a href="http://arxiv.org/abs/2010.01950" target="_blank">arXiv:2010.01950</a> [<a href="http://arxiv.org/pdf/2010.01950" target="_blank">pdf</a>]

<h2>Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks. (arXiv:2010.04261v4 [cs.LG] UPDATED)</h2>
<h3>Yikai Wu, Xingyu Zhu, Chenwei Wu, Annie Wang, Rong Ge</h3>
<p>Hessian captures important properties of the deep neural network loss
landscape. Previous works have observed low rank structure in the Hessians of
neural networks. We make several new observations about the top eigenspace of
layer-wise Hessian -- top eigenspaces for different models have high overlap,
and top eigenvectors form low rank matrices when they are reshaped into the
same shape as the corresponding weight matrix. Towards formally explaining such
structures of the Hessian, we show that the new eigenspace structure can be
explained by approximating the Hessian using Kronecker factorization; we also
prove the low rank structure for random data at random initialization for
over-parametrized two-layer neural nets. Our new understanding can explain why
some of these structures become weaker when the network is trained with batch
normalization. The Kronecker factorization also leads to better explicit
generalization bounds.
</p>
<a href="http://arxiv.org/abs/2010.04261" target="_blank">arXiv:2010.04261</a> [<a href="http://arxiv.org/pdf/2010.04261" target="_blank">pdf</a>]

<h2>FOSS: Multi-Person Age Estimation with Focusing on Objects and Still Seeing Surroundings. (arXiv:2010.07544v2 [cs.CV] UPDATED)</h2>
<h3>Masakazu Yoshimura, Satoshi Ogata</h3>
<p>Age estimation from images can be used in many practical scenes. Most of the
previous works targeted on the estimation from images in which only one face
exists. Also, most of the open datasets for age estimation contain images like
that. However, in some situations, age estimation in the wild and for
multi-person is needed. Usually, such situations were solved by two separate
models; one is a face detector model which crops facial regions and the other
is an age estimation model which estimates from cropped images. In this work,
we propose a method that can detect and estimate the age of multi-person with a
single model which estimates age with focusing on faces and still seeing
surroundings. Also, we propose a training method which enables the model to
estimate multi-person well despite trained with images in which only one face
is photographed. In the experiments, we evaluated our proposed method compared
with the traditional approach using two separate models. As the result, the
accuracy could be enhanced with our proposed method. We also adapted our
proposed model to commonly used single person photographed age estimation
datasets and it is proved that our method is also effective to those images and
outperforms the state of the art accuracy.
</p>
<a href="http://arxiv.org/abs/2010.07544" target="_blank">arXiv:2010.07544</a> [<a href="http://arxiv.org/pdf/2010.07544" target="_blank">pdf</a>]

<h2>The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers. (arXiv:2010.08127v2 [cs.LG] UPDATED)</h2>
<h3>Preetum Nakkiran, Behnam Neyshabur, Hanie Sedghi</h3>
<p>We propose a new framework for reasoning about generalization in deep
learning. The core idea is to couple the Real World, where optimizers take
stochastic gradient steps on the empirical loss, to an Ideal World, where
optimizers take steps on the population loss. This leads to an alternate
decomposition of test error into: (1) the Ideal World test error plus (2) the
gap between the two worlds. If the gap (2) is universally small, this reduces
the problem of generalization in offline learning to the problem of
optimization in online learning. We then give empirical evidence that this gap
between worlds can be small in realistic deep learning settings, in particular
supervised image classification. For example, CNNs generalize better than MLPs
on image distributions in the Real World, but this is "because" they optimize
faster on the population loss in the Ideal World. This suggests our framework
is a useful tool for understanding generalization in deep learning, and lays a
foundation for future research in the area.
</p>
<a href="http://arxiv.org/abs/2010.08127" target="_blank">arXiv:2010.08127</a> [<a href="http://arxiv.org/pdf/2010.08127" target="_blank">pdf</a>]

<h2>Robust Imitation Learning from Noisy Demonstrations. (arXiv:2010.10181v3 [stat.ML] UPDATED)</h2>
<h3>Voot Tangkaratt, Nontawat Charoenphakdee, Masashi Sugiyama</h3>
<p>Robust learning from noisy demonstrations is a practical but highly
challenging problem in imitation learning. In this paper, we first
theoretically show that robust imitation learning can be achieved by optimizing
a classification risk with a symmetric loss. Based on this theoretical finding,
we then propose a new imitation learning method that optimizes the
classification risk by effectively combining pseudo-labeling with co-training.
Unlike existing methods, our method does not require additional labels or
strict assumptions about noise distributions. Experimental results on
continuous-control benchmarks show that our method is more robust compared to
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2010.10181" target="_blank">arXiv:2010.10181</a> [<a href="http://arxiv.org/pdf/2010.10181" target="_blank">pdf</a>]

<h2>Learning to Noise: Application-Agnostic Data Sharing with Local Differential Privacy. (arXiv:2010.12464v2 [cs.LG] UPDATED)</h2>
<h3>Alex Mansbridge, Gregory Barbour, Davide Piras, Christopher Frye, Ilya Feige, David Barber</h3>
<p>The collection and sharing of individuals' data has become commonplace in
many industries. Local differential privacy (LDP) is a rigorous approach to
preserving data privacy even from a database administrator, unlike the more
standard central differential privacy. To achieve LDP, one traditionally adds
noise directly to each data dimension, but for high-dimensional data the level
of noise required for sufficient anonymization all but entirely destroys the
data's utility. In this paper, we introduce a novel LDP mechanism that
leverages representation learning to overcome the prohibitive noise
requirements of direct methods. We demonstrate that, rather than simply
estimating aggregate statistics of the privatized data as is the norm in LDP
applications, our method enables the training of performant machine learning
models. Unique applications of our approach include private novel-class
classification and the augmentation of clean datasets with additional
privatized features. Methods that rely on central differential privacy are not
applicable to such tasks. Our approach achieves significant performance gains
on these tasks relative to state-of-the-art LDP benchmarks that noise data
directly.
</p>
<a href="http://arxiv.org/abs/2010.12464" target="_blank">arXiv:2010.12464</a> [<a href="http://arxiv.org/pdf/2010.12464" target="_blank">pdf</a>]

<h2>LEAD: Least-Action Dynamics for Min-Max Optimization. (arXiv:2010.13846v2 [cs.LG] UPDATED)</h2>
<h3>Reyhane Askari Hemmat, Amartya Mitra, Guillaume Lajoie, Ioannis Mitliagkas</h3>
<p>Adversarial formulations such as generative adversarial networks (GANs) have
rekindled interest in two-player min-max games. A central obstacle in the
optimization of such games is the rotational dynamics that hinder their
convergence. Existing methods typically employ intuitive, carefully
hand-designed mechanisms for controlling such rotations. In this paper, we take
a novel approach to address this issue by casting min-max optimization as a
physical system. We leverage tools from physics to introduce LEAD (Least-Action
Dynamics), a second-order optimizer for min-max games. Next, using Lyapunov
stability theory and spectral analysis, we study LEAD's convergence properties
in continuous and discrete-time settings for bilinear games to demonstrate
linear convergence to the Nash equilibrium. Finally, we empirically evaluate
our method on synthetic setups and CIFAR-10 image generation to demonstrate
improvements over baseline methods.
</p>
<a href="http://arxiv.org/abs/2010.13846" target="_blank">arXiv:2010.13846</a> [<a href="http://arxiv.org/pdf/2010.13846" target="_blank">pdf</a>]

<h2>Incorporating Symbolic Domain Knowledge into Graph Neural Networks. (arXiv:2010.13900v2 [cs.LG] UPDATED)</h2>
<h3>Tirtharaj Dash, Ashwin Srinivasan, Lovekesh Vig</h3>
<p>Our interest is in scientific problems with the following characteristics:
(1) Data are naturally represented as graphs; (2) The amount of data available
is typically small; and (3) There is significant domain-knowledge, usually
expressed in some symbolic form. These kinds of problems have been addressed
effectively in the past by Inductive Logic Programming (ILP), by virtue of 2
important characteristics: (a) The use of a representation language that easily
captures the relation encoded in graph-structured data, and (b) The inclusion
of prior information encoded as domain-specific relations, that can alleviate
problems of data scarcity, and construct new relations. Recent advances have
seen the emergence of deep neural networks specifically developed for
graph-structured data (Graph-based Neural Networks, or GNNs). While GNNs have
been shown to be able to handle graph-structured data, less has been done to
investigate the inclusion of domain-knowledge. Here we investigate this aspect
of GNNs empirically by employing an operation we term "vertex-enrichment" and
denote the corresponding GNNs as "VEGNNs". Using over 70 real-world datasets
and substantial amounts of symbolic domain-knowledge, we examine the result of
vertex-enrichment across 5 different variants of GNNs. Our results provide
support for the following: (a) Inclusion of domain-knowledge by
vertex-enrichment can significantly improve the performance of a GNN. That is,
the performance VEGNNs is significantly better than GNNs across all GNN
variants; (b) The inclusion of domain-specific relations constructed using ILP
improves the performance of VEGNNs, across all GNN variants. Taken together,
the results provide evidence that it is possible to incorporate symbolic domain
knowledge into a GNN, and that ILP can play an important role in providing
high-level relationships that are not easily discovered by a GNN.
</p>
<a href="http://arxiv.org/abs/2010.13900" target="_blank">arXiv:2010.13900</a> [<a href="http://arxiv.org/pdf/2010.13900" target="_blank">pdf</a>]

<h2>Exploring the limits of Concurrency in ML Training on Google TPUs. (arXiv:2011.03641v2 [cs.LG] UPDATED)</h2>
<h3>Sameer Kumar, James Bradbury, Cliff Young, Yu Emma Wang, Anselm Levskaya, Blake Hechtman, Dehao Chen, HyoukJoong Lee, Mehmet Deveci, Naveen Kumar, Pankaj Kanwar, Shibo Wang, Skye Wanderman-Milne, Steve Lacy, Tao Wang, Tayo Oguntebi, Yazhou Zu, Yuanzhong Xu, Andy Swing</h3>
<p>Recent results in language understanding using neural networks have required
training hardware of unprecedentedscale, with thousands of chips cooperating on
a single training run. This paper presents techniques to scaleML models on the
Google TPU Multipod, a mesh with 4096 TPU-v3 chips. We discuss model
parallelism toovercome scaling limitations from the fixed batch size in data
parallelism, communication/collective optimizations,distributed evaluation of
training metrics, and host input processing scaling optimizations. These
techniques aredemonstrated in both the TensorFlow and JAX programming
frameworks. We also present performance resultsfrom the recent Google
submission to the MLPerf-v0.7 benchmark contest, achieving record training
times from16 to 28 seconds in four MLPerf models on the Google TPU-v3 Multipod
machine.
</p>
<a href="http://arxiv.org/abs/2011.03641" target="_blank">arXiv:2011.03641</a> [<a href="http://arxiv.org/pdf/2011.03641" target="_blank">pdf</a>]

<h2>Omni-GAN: On the Secrets of cGANs and Beyond. (arXiv:2011.13074v2 [cs.CV] UPDATED)</h2>
<h3>Peng Zhou, Lingxi Xie, Bingbing Ni, Qi Tian</h3>
<p>It has been an important problem to design a proper discriminator for
conditional generative adversarial networks (cGANs). In this paper, we
investigate two popular choices, the projection-based and classification-based
discriminators, and reveal that both of them suffer some kind of drawbacks that
affect the learning ability of cGANs. Then, we present our solution that trains
a powerful discriminator and avoids over-fitting with regularization. In
addition, we unify multiple targets (class, domain, reality, etc.) into one
loss function to enable a wider range of applications. Our algorithm, named
\textbf{Omni-GAN}, by proposing a simple modification, improves the
projection-based cGAN performance significantly and achieves a new
state-of-the-art in generating mid/high-resolution images (a record-breaking IS
of $190.9$ on ImageNet $128\times128$). More importantly, we explain
experimentally why Omni-GAN is significantly better than the projection-based
cGAN, BigGAN, offering new possible directions for optimizing cGANs. Code is
available at https://github.com/PeterouZh/Omni-GAN-PyTorch.
</p>
<a href="http://arxiv.org/abs/2011.13074" target="_blank">arXiv:2011.13074</a> [<a href="http://arxiv.org/pdf/2011.13074" target="_blank">pdf</a>]

<h2>Unsupervised part representation by Flow Capsules. (arXiv:2011.13920v2 [cs.CV] UPDATED)</h2>
<h3>Sara Sabour, Andrea Tagliasacchi, Soroosh Yazdani, Geoffrey E. Hinton, David J. Fleet</h3>
<p>Capsule networks aim to parse images into a hierarchy of objects, parts and
relations. While promising, they remain limited by an inability to learn
effective low level part descriptions. To address this issue we propose a way
to learn primary capsule encoders that detect atomic parts from a single image.
During training we exploit motion as a powerful perceptual cue for part
definition, with an expressive decoder for part generation within a layered
image model with occlusion. Experiments demonstrate robust part discovery in
the presence of multiple objects, cluttered backgrounds, and occlusion. The
part decoder infers the underlying shape masks, effectively filling in occluded
regions of the detected shapes. We evaluate FlowCapsules on unsupervised part
segmentation and unsupervised image classification.
</p>
<a href="http://arxiv.org/abs/2011.13920" target="_blank">arXiv:2011.13920</a> [<a href="http://arxiv.org/pdf/2011.13920" target="_blank">pdf</a>]

<h2>Improved Online Learning Algorithm for Multinomial Logit Contextual Bandits. (arXiv:2011.14033v2 [cs.LG] UPDATED)</h2>
<h3>Priyank Agrawal, Vashist Avadhanula, Theja Tulabandhula</h3>
<p>In this paper, we consider the contextual variant of the MNL-Bandit problem.
More specifically, we consider a dynamic assortment optimization problem, where
in every round a decision maker offers a subset (assortment) of products to a
consumer, and observes their response. Consumers purchase products so as to
maximize their utility. We assume that the products are described by a set of
attributes and the mean utility of a product is linear in the values of these
attributes. We model consumer choice behavior by means of the widely used
Multinomial Logit (MNL) model, and consider the decision maker's problem of
dynamically learning the model parameters, while optimizing cumulative revenue
over the selling horizon $T$. Though this problem has attracted considerable
attention in recent times, many existing methods and their theoretical
performance depend on a problem dependent parameter which could be
prohibitively large. In particular, existing algorithms for this problem have
regret bounded by $O(\sqrt{\kappa d T})$, where $\kappa$ is a problem dependent
constant that can have exponential dependency on the number of attributes. In
this paper, we propose a new algorithm with a carefully designed exploration
strategy and show that the regret is bounded by $O(\sqrt{dT} + \kappa)$,
significantly improving the performance over existing methods.
</p>
<a href="http://arxiv.org/abs/2011.14033" target="_blank">arXiv:2011.14033</a> [<a href="http://arxiv.org/pdf/2011.14033" target="_blank">pdf</a>]

<h2>Curiosity-driven 3D Scene Structure from Single-image Self-supervision. (arXiv:2012.01230v2 [cs.CV] UPDATED)</h2>
<h3>David Griffiths, Jan Boehm, Tobias Ritschel</h3>
<p>Previous work has demonstrated learning isolated 3D objects (voxel grids,
point clouds, meshes, etc.) from 2D-only self-supervision. Here we set out to
extend this to entire 3D scenes made out of multiple objects, including their
location, orientation and type, and the scenes illumination. Once learned, we
can map arbitrary 2D images to 3D scene structure. We analyze why
analysis-by-synthesis-like losses for supervision of 3D scene structure using
differentiable rendering is not practical, as it almost always gets stuck in
local minima of visual ambiguities. This can be overcome by a novel form of
training: we use an additional network to steer the optimization itself to
explore the full gamut of possible solutions \ie to be curious, and hence, to
resolve those ambiguities and find workable minima. The resulting system
converts 2D images of different virtual or real images into complete 3D scenes,
learned only from 2D images of those scenes.
</p>
<a href="http://arxiv.org/abs/2012.01230" target="_blank">arXiv:2012.01230</a> [<a href="http://arxiv.org/pdf/2012.01230" target="_blank">pdf</a>]

<h2>Robust Unsupervised Learning via L-Statistic Minimization. (arXiv:2012.07399v3 [cs.LG] UPDATED)</h2>
<h3>Andreas Maurer, Daniela A. Parletta, Andrea Paudice, Massimiliano Pontil</h3>
<p>Designing learning algorithms that are resistant to perturbations of the
underlying data distribution is a problem of wide practical and theoretical
importance. We present a general approach to this problem focusing on
unsupervised learning. The key assumption is that the perturbing distribution
is characterized by larger losses relative to a given class of admissible
models. This is exploited by a general descent algorithm which minimizes an
$L$-statistic criterion over the model class, weighting small losses more. Our
analysis characterizes the robustness of the method in terms of bounds on the
reconstruction error relative to the underlying unperturbed distribution. As a
byproduct, we prove uniform convergence bounds with respect to the proposed
criterion for several popular models in unsupervised learning, a result which
may be of independent interest.Numerical experiments with kmeans clustering and
principal subspace analysis demonstrate the effectiveness of our approach.
</p>
<a href="http://arxiv.org/abs/2012.07399" target="_blank">arXiv:2012.07399</a> [<a href="http://arxiv.org/pdf/2012.07399" target="_blank">pdf</a>]

<h2>Learning Collision-Free Space Detection from Stereo Images: Homography Matrix Brings Better Data Augmentation. (arXiv:2012.07890v2 [cs.RO] UPDATED)</h2>
<h3>Rui Fan, Hengli Wang, Peide Cai, Jin Wu, Mohammud Junaid Bocus, Lei Qiao, Ming Liu</h3>
<p>Collision-free space detection is a critical component of autonomous vehicle
perception. The state-of-the-art algorithms are typically based on supervised
learning. The performance of such approaches is always dependent on the quality
and amount of labeled training data. Additionally, it remains an open challenge
to train deep convolutional neural networks (DCNNs) using only a small quantity
of training samples. Therefore, this paper mainly explores an effective
training data augmentation approach that can be employed to improve the overall
DCNN performance, when additional images captured from different views are
available. Due to the fact that the pixels of the collision-free space
(generally regarded as a planar surface) between two images captured from
different views can be associated by a homography matrix, the scenario of the
target image can be transformed into the reference view. This provides a simple
but effective way of generating training data from additional multi-view
images. Extensive experimental results, conducted with six state-of-the-art
semantic segmentation DCNNs on three datasets, demonstrate the effectiveness of
our proposed training data augmentation algorithm for enhancing collision-free
space detection performance. When validated on the KITTI road benchmark, our
approach provides the best results for stereo vision-based collision-free space
detection.
</p>
<a href="http://arxiv.org/abs/2012.07890" target="_blank">arXiv:2012.07890</a> [<a href="http://arxiv.org/pdf/2012.07890" target="_blank">pdf</a>]

<h2>Molecular machine learning with conformer ensembles. (arXiv:2012.08452v2 [cs.LG] UPDATED)</h2>
<h3>Simon Axelrod, Rafael Gomez-Bombarelli</h3>
<p>Virtual screening can accelerate drug discovery by identifying promising
candidates for experimental evaluation. Machine learning is a powerful method
for screening, as it can learn complex structure-property relationships from
experimental data and make rapid predictions over virtual libraries. Molecules
inherently exist as a three-dimensional ensemble and their biological action
typically occurs through supramolecular recognition. However, most deep
learning approaches to molecular property prediction use a 2D graph
representation as input, and in some cases a single 3D conformation. Here we
investigate how the 3D information of multiple conformers, traditionally known
as 4D information in the cheminformatics community, can improve molecular
property prediction in deep learning models. We introduce multiple deep
learning models that expand upon key architectures such as ChemProp and Schnet,
adding elements such as multiple-conformer inputs and conformer attention. We
then benchmark the performance trade-offs of these models on 2D, 3D and 4D
representations in the prediction of drug activity using a large training set
of geometrically resolved molecules. The new architectures perform
significantly better than 2D models, but their performance is often just as
strong with a single conformer as with many. We also find that 4D deep learning
models learn interpretable attention weights for each conformer.
</p>
<a href="http://arxiv.org/abs/2012.08452" target="_blank">arXiv:2012.08452</a> [<a href="http://arxiv.org/pdf/2012.08452" target="_blank">pdf</a>]

<h2>Rebuilding Trust in Active Learning with Actionable Metrics. (arXiv:2012.11365v3 [cs.LG] UPDATED)</h2>
<h3>Alexandre Abraham, L&#xe9;o Dreyfus-Schmidt</h3>
<p>Active Learning (AL) is an active domain of research, but is seldom used in
the industry despite the pressing needs. This is in part due to a misalignment
of objectives, while research strives at getting the best results on selected
datasets, the industry wants guarantees that Active Learning will perform
consistently and at least better than random labeling. The very one-off nature
of Active Learning makes it crucial to understand how strategy selection can be
carried out and what drives poor performance (lack of exploration, selection of
samples that are too hard to classify, ...).

To help rebuild trust of industrial practitioners in Active Learning, we
present various actionable metrics. Through extensive experiments on reference
datasets such as CIFAR100, Fashion-MNIST, and 20Newsgroups, we show that those
metrics brings interpretability to AL strategies that can be leveraged by the
practitioner.
</p>
<a href="http://arxiv.org/abs/2012.11365" target="_blank">arXiv:2012.11365</a> [<a href="http://arxiv.org/pdf/2012.11365" target="_blank">pdf</a>]

<h2>Bidirectional Mapping Coupled GAN for Generalized Zero-Shot Learning. (arXiv:2012.15054v2 [cs.CV] UPDATED)</h2>
<h3>Tasfia Shermin, Shyh Wei Teng, Ferdous Sohel, Manzur Murshed, Guojun Lu</h3>
<p>Bidirectional mapping-based generalized zero-shot learning (GZSL) methods
rely on the quality of synthesized features to recognize seen and unseen data.
Therefore, learning a joint distribution of seen-unseen domains and preserving
domain distinction is crucial for these methods. However, existing methods only
learn the underlying distribution of seen data, although unseen class semantics
are available in the GZSL problem setting. Most methods neglect retaining
domain distinction and use the learned distribution to recognize seen and
unseen data. Consequently, they do not perform well. In this work, we utilize
the available unseen class semantics alongside seen class semantics and learn
joint distribution through a strong visual-semantic coupling. We propose a
bidirectional mapping coupled generative adversarial network (BMCoGAN) by
extending the coupled generative adversarial network into a dual-domain
learning bidirectional mapping model. We further integrate a Wasserstein
generative adversarial optimization to supervise the joint distribution
learning. We design a loss optimization for retaining domain distinctive
information in the synthesized features and reducing bias towards seen classes,
which pushes synthesized seen features towards real seen features and pulls
synthesized unseen features away from real seen features. We evaluate BMCoGAN
on benchmark datasets and demonstrate its superior performance against
contemporary methods.
</p>
<a href="http://arxiv.org/abs/2012.15054" target="_blank">arXiv:2012.15054</a> [<a href="http://arxiv.org/pdf/2012.15054" target="_blank">pdf</a>]

<h2>Local Navigation and Docking of an Autonomous Robot Mower using Reinforcement Learning and Computer Vision. (arXiv:2101.06248v2 [cs.RO] UPDATED)</h2>
<h3>Ali Taghibakhshi, Nathan Ogden, Matthew West</h3>
<p>We demonstrate a successful navigation and docking control system for the
John Deere Tango autonomous mower, using only a single camera as the input.
This vision-only system is of interest because it is inexpensive, simple for
production, and requires no external sensing. This is in contrast to existing
systems that rely on integrated position sensors and global positioning system
(GPS) technologies. To produce our system we combined a state-of-the-art object
detection architecture, You Only Look Once (YOLO), with a reinforcement
learning (RL) architecture, Double Deep QNetworks (Double DQN). The object
detection network identifies features on the mower and passes its output to the
RL network, providing it with a low-dimensional representation that enables
rapid and robust training. Finally, the RL network learns how to navigate the
machine to the desired spot in a custom simulation environment. When tested on
mower hardware, the system is able to dock with centimeter-level accuracy from
arbitrary initial locations and orientations.
</p>
<a href="http://arxiv.org/abs/2101.06248" target="_blank">arXiv:2101.06248</a> [<a href="http://arxiv.org/pdf/2101.06248" target="_blank">pdf</a>]

<h2>BF++: a language for general-purpose program synthesis. (arXiv:2101.09571v3 [cs.AI] UPDATED)</h2>
<h3>Vadim Liventsev, Aki H&#xe4;rm&#xe4;, Milan Petkovi&#x107;</h3>
<p>Most state of the art decision systems based on Reinforcement Learning (RL)
are data-driven black-box neural models, where it is often difficult to
incorporate expert knowledge into the models or let experts review and validate
the learned decision mechanisms. Knowledge-insertion and model review are
important requirements in many applications involving human health and safety.
One way to bridge the gap between data and knowledge driven systems is program
synthesis: replacing a neural network that outputs decisions with a symbolic
program generated by a neural network or by means of genetic programming. We
propose a new programming language, BF++, designed specifically for automatic
programming of agents in a Partially Observable Markov Decision Process (POMDP)
setting and apply neural program synthesis to solve standard OpenAI Gym
benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.09571" target="_blank">arXiv:2101.09571</a> [<a href="http://arxiv.org/pdf/2101.09571" target="_blank">pdf</a>]

<h2>Variance-Aware Confidence Set: Variance-Dependent Bound for Linear Bandits and Horizon-Free Bound for Linear Mixture MDP. (arXiv:2101.12745v2 [cs.LG] UPDATED)</h2>
<h3>Zihan Zhang, Jiaqi Yang, Xiangyang Ji, Simon S. Du</h3>
<p>We show how to construct variance-aware confidence sets for linear bandits
and linear mixture Markov Decision Process (MDP). Our method yields the
following new regret bounds:

* For linear bandits, we obtain an $\widetilde{O}(\mathrm{poly}(d)\sqrt{1 +
\sum_{i=1}^{K}\sigma_i^2})$ regret bound, where $d$ is the feature dimension,
$K$ is the number of rounds, and $\sigma_i^2$ is the (unknown) variance of the
reward at the $i$-th round. This is the first regret bound that only scales
with the variance and the dimension, with no explicit polynomial dependency on
$K$.

* For linear mixture MDP, we obtain an $\widetilde{O}(\mathrm{poly}(d, \log
H)\sqrt{K})$ regret bound, where $d$ is the number of base models, $K$ is the
number of episodes, and $H$ is the planning horizon. This is the first regret
bound that only scales logarithmically with $H$ in the reinforcement learning
with linear function approximation setting, thus exponentially improving
existing results.

Our methods utilize three novel ideas that may be of independent interest: 1)
applications of the peeling techniques to the norm of input and the magnitude
of variance, 2) a recursion-based approach to estimate the variance, and 3) a
convex potential lemma that somewhat generalizes the seminal elliptical
potential lemma.
</p>
<a href="http://arxiv.org/abs/2101.12745" target="_blank">arXiv:2101.12745</a> [<a href="http://arxiv.org/pdf/2101.12745" target="_blank">pdf</a>]

<h2>Federated Reconstruction: Partially Local Federated Learning. (arXiv:2102.03448v2 [cs.LG] UPDATED)</h2>
<h3>Karan Singhal, Hakim Sidahmed, Zachary Garrett, Shanshan Wu, Keith Rush, Sushant Prakash</h3>
<p>Personalization methods in federated learning aim to balance the benefits of
federated and local training for data availability, communication cost, and
robustness to client heterogeneity. Approaches that require clients to
communicate all model parameters can be undesirable due to privacy and
communication constraints. Other approaches require always-available or
stateful clients, impractical in large-scale cross-device settings. We
introduce Federated Reconstruction, the first model-agnostic framework for
partially local federated learning suitable for training and inference at
scale. We motivate the framework via a connection to model-agnostic meta
learning, empirically demonstrate its performance over existing approaches for
collaborative filtering and next word prediction, and release an open-source
library for evaluating approaches in this setting. We also describe the
successful deployment of this approach at scale for federated collaborative
filtering in a mobile keyboard application.
</p>
<a href="http://arxiv.org/abs/2102.03448" target="_blank">arXiv:2102.03448</a> [<a href="http://arxiv.org/pdf/2102.03448" target="_blank">pdf</a>]

<h2>Adversarial Imaging Pipelines. (arXiv:2102.03728v2 [cs.CV] UPDATED)</h2>
<h3>Buu Phan, Fahim Mannan, Felix Heide</h3>
<p>Adversarial attacks play an essential role in understanding deep neural
network predictions and improving their robustness. Existing attack methods aim
to deceive convolutional neural network (CNN)-based classifiers by manipulating
RGB images that are fed directly to the classifiers. However, these approaches
typically neglect the influence of the camera optics and image processing
pipeline (ISP) that produce the network inputs. ISPs transform RAW measurements
to RGB images and traditionally are assumed to preserve adversarial patterns.
However, these low-level pipelines can, in fact, destroy, introduce or amplify
adversarial patterns that can deceive a downstream detector. As a result,
optimized patterns can become adversarial for the classifier after being
transformed by a certain camera ISP and optic but not for others. In this work,
we examine and develop such an attack that deceives a specific camera ISP while
leaving others intact, using the same down-stream classifier. We frame
camera-specific attacks as a multi-task optimization problem, relying on a
differentiable approximation for the ISP itself. We validate the proposed
method using recent state-of-the-art automotive hardware ISPs, achieving 92%
fooling rate when attacking a specific ISP. We demonstrate physical optics
attacks with 90% fooling rate for a specific camera lenses.
</p>
<a href="http://arxiv.org/abs/2102.03728" target="_blank">arXiv:2102.03728</a> [<a href="http://arxiv.org/pdf/2102.03728" target="_blank">pdf</a>]

<h2>Simple Agent, Complex Environment: Efficient Reinforcement Learning with Agent State. (arXiv:2102.05261v3 [cs.LG] UPDATED)</h2>
<h3>Shi Dong, Benjamin Van Roy, Zhengyuan Zhou</h3>
<p>We design a simple reinforcement learning agent that, with a specification
only of agent state dynamics and a reward function, can operate with some
degree of competence in any environment. The agent maintains only visitation
counts and value estimates for each agent-state-action pair. The value function
is updated incrementally in response to temporal differences and optimistic
boosts that encourage exploration. The agent executes actions that are greedy
with respect to this value function. We establish a regret bound demonstrating
convergence to near-optimal per-period performance, where the time taken to
achieve near-optimality is polynomial in the number of agent states and
actions, as well as the reward mixing time of the best policy within the
reference policy class, which is comprised of those that depend on history only
through agent state. Notably, there is no further dependence on the number of
environment states or mixing times associated with other policies or statistics
of history. Our result sheds light on the potential benefits of (deep)
representation learning, which has demonstrated the capability to extract
compact and relevant features from high-dimensional interaction histories.
</p>
<a href="http://arxiv.org/abs/2102.05261" target="_blank">arXiv:2102.05261</a> [<a href="http://arxiv.org/pdf/2102.05261" target="_blank">pdf</a>]

<h2>The Symmetry between Arms and Knapsacks: A Primal-Dual Approach for Bandits with Knapsacks. (arXiv:2102.06385v2 [cs.LG] UPDATED)</h2>
<h3>Xiaocheng Li, Chunlin Sun, Yinyu Ye</h3>
<p>In this paper, we study the bandits with knapsacks (BwK) problem and develop
a primal-dual based algorithm that achieves a problem-dependent logarithmic
regret bound. The BwK problem extends the multi-arm bandit (MAB) problem to
model the resource consumption associated with playing each arm, and the
existing BwK literature has been mainly focused on deriving asymptotically
optimal distribution-free regret bounds. We first study the primal and dual
linear programs underlying the BwK problem. From this primal-dual perspective,
we discover symmetry between arms and knapsacks, and then propose a new notion
of sub-optimality measure for the BwK problem. The sub-optimality measure
highlights the important role of knapsacks in determining algorithm regret and
inspires the design of our two-phase algorithm. In the first phase, the
algorithm identifies the optimal arms and the binding knapsacks, and in the
second phase, it exhausts the binding knapsacks via playing the optimal arms
through an adaptive procedure. Our regret upper bound involves the proposed
sub-optimality measure and it has a logarithmic dependence on length of horizon
$T$ and a polynomial dependence on $m$ (the numbers of arms) and $d$ (the
number of knapsacks). To the best of our knowledge, this is the first
problem-dependent logarithmic regret bound for solving the general BwK problem.
</p>
<a href="http://arxiv.org/abs/2102.06385" target="_blank">arXiv:2102.06385</a> [<a href="http://arxiv.org/pdf/2102.06385" target="_blank">pdf</a>]

<h2>Clustering Left-Censored Multivariate Time-Series. (arXiv:2102.07005v2 [stat.ML] UPDATED)</h2>
<h3>Irene Y. Chen, Rahul G. Krishnan, David Sontag</h3>
<p>Unsupervised learning seeks to uncover patterns in data. However, different
kinds of noise may impede the discovery of useful substructure from real-world
time-series data. In this work, we focus on mitigating the interference of
left-censorship in the task of clustering. We provide conditions under which
clusters and left-censorship may be identified; motivated by this result, we
develop a deep generative, continuous-time model of time-series data that
clusters while correcting for censorship time. We demonstrate accurate, stable,
and interpretable results on synthetic data that outperform several benchmarks.
To showcase the utility of our framework on real-world problems, we study how
left-censorship can adversely affect the task of disease phenotyping, resulting
in the often incorrect assumption that longitudinal patient data are aligned by
disease stage. In reality, patients at the time of diagnosis are at different
stages of the disease -- both late and early due to differences in when
patients seek medical care and such discrepancy can confound unsupervised
learning algorithms. On two clinical datasets, our model corrects for this form
of censorship and recovers known clinical subtypes.
</p>
<a href="http://arxiv.org/abs/2102.07005" target="_blank">arXiv:2102.07005</a> [<a href="http://arxiv.org/pdf/2102.07005" target="_blank">pdf</a>]

<h2>Bridging Graph Neural Networks and Statistical Relational Learning: Relational One-Class GCN. (arXiv:2102.07007v2 [cs.LG] UPDATED)</h2>
<h3>Devendra Singh Dhami (1), Siwen Yan (2), Sriraam Natarajan (2) ((1) TU Darmstadt, (2) The University of Texas at Dallas)</h3>
<p>We consider the problem of learning Graph Convolutional Networks (GCNs) for
relational data. Specifically, we consider the classic link prediction and node
classification problems as relational modeling tasks and develop a relational
extension to GCNs. Our method constructs a secondary graph using relational
density estimation techniques where vertices correspond to the target triples.
We emphasize the importance of learning features using the secondary graph and
the advantages of employing a distance matrix over the typically used adjacency
matrix. Our comprehensive empirical evaluation demonstrates the superiority of
our approach over $\mathbf{12}$ different GCN models, relational embedding
techniques, rule learning techniques and relational models.
</p>
<a href="http://arxiv.org/abs/2102.07007" target="_blank">arXiv:2102.07007</a> [<a href="http://arxiv.org/pdf/2102.07007" target="_blank">pdf</a>]

<h2>NeRF--: Neural Radiance Fields Without Known Camera Parameters. (arXiv:2102.07064v3 [cs.CV] UPDATED)</h2>
<h3>Zirui Wang, Shangzhe Wu, Weidi Xie, Min Chen, Victor Adrian Prisacariu</h3>
<p>This paper tackles the problem of novel view synthesis (NVS) from 2D images
without known camera poses and intrinsics. Among various NVS techniques, Neural
Radiance Field (NeRF) has recently gained popularity due to its remarkable
synthesis quality. Existing NeRF-based approaches assume that the camera
parameters associated with each input image are either directly accessible at
training, or can be accurately estimated with conventional techniques based on
correspondences, such as Structure-from-Motion. In this work, we propose an
end-to-end framework, termed NeRF--, for training NeRF models given only RGB
images, without pre-computed camera parameters. Specifically, we show that the
camera parameters, including both intrinsics and extrinsics, can be
automatically discovered via joint optimisation during the training of the NeRF
model. On the standard LLFF benchmark, our model achieves comparable novel view
synthesis results compared to the baseline trained with COLMAP pre-computed
camera parameters. We also conduct extensive analyses to understand the model
behaviour under different camera trajectories, and show that in scenarios where
COLMAP fails, our model still produces robust results.
</p>
<a href="http://arxiv.org/abs/2102.07064" target="_blank">arXiv:2102.07064</a> [<a href="http://arxiv.org/pdf/2102.07064" target="_blank">pdf</a>]

<h2>On Riemannian Stochastic Approximation Schemes with Fixed Step-Size. (arXiv:2102.07586v2 [stat.ML] UPDATED)</h2>
<h3>Alain Durmus, Pablo Jim&#xe9;nez, &#xc9;ric Moulines, Salem Said</h3>
<p>This paper studies fixed step-size stochastic approximation (SA) schemes,
including stochastic gradient schemes, in a Riemannian framework. It is
motivated by several applications, where geodesics can be computed explicitly,
and their use accelerates crude Euclidean methods. A fixed step-size scheme
defines a family of time-homogeneous Markov chains, parametrized by the
step-size. Here, using this formulation, non-asymptotic performance bounds are
derived, under Lyapunov conditions. Then, for any step-size, the corresponding
Markov chain is proved to admit a unique stationary distribution, and to be
geometrically ergodic. This result gives rise to a family of stationary
distributions indexed by the step-size, which is further shown to converge to a
Dirac measure, concentrated at the solution of the problem at hand, as the
step-size goes to 0. Finally, the asymptotic rate of this convergence is
established, through an asymptotic expansion of the bias, and a central limit
theorem.
</p>
<a href="http://arxiv.org/abs/2102.07586" target="_blank">arXiv:2102.07586</a> [<a href="http://arxiv.org/pdf/2102.07586" target="_blank">pdf</a>]

<h2>Feature Pyramid Network with Multi-Head Attention for Semantic Segmentation of Fine-Resolution Remotely Sensed Images. (arXiv:2102.07997v2 [cs.CV] UPDATED)</h2>
<h3>Rui Li, Shunyi Zheng, Chenxi Duan</h3>
<p>Semantic segmentation from fine-resolution remotely sensed images is an
urgent issue in satellite imagery processing. Due to the complicated
environment, automatic categorization and segmen-tation is a challenging matter
especially for images with a fine resolution. Solving it can help to surmount a
wide varied range of obstacles in urban planning, environmental protection, and
natural landscape monitoring, which paves the way for complete scene
understanding. However, the existing frequently-used encoder-decoder structure
is unable to effectively combine the extracted spatial and contextual features.
Therefore, in this paper, we introduce the Feature Pyramid Net-work (FPN) to
bridge the gap between the low-level and high-level features. Moreover, we
enhance the contextual information with the elaborate Multi-Head Attention
module and propose the Feature Pyramid Network with Multi-Head Attention
(FPN-MHA) for semantic segmentation of fine-resolution remotely sensed images.
Extensive experiments conducted on the ISPRS Potsdam and Vaihingen datasets
demonstrate the effectiveness of our FPN-MHA. Code is available at
https://github.com/lironui/FPN-MHA.
</p>
<a href="http://arxiv.org/abs/2102.07997" target="_blank">arXiv:2102.07997</a> [<a href="http://arxiv.org/pdf/2102.07997" target="_blank">pdf</a>]

<h2>Convex regularization in statistical inverse learning problems. (arXiv:2102.09526v2 [stat.ML] UPDATED)</h2>
<h3>Tatiana A. Bubba, Martin Burger, Tapio Helin, Luca Ratti</h3>
<p>We consider a statistical inverse learning problem, where the task is to
estimate a function $f$ based on noisy point evaluations of $Af$, where $A$ is
a linear operator. The function $Af$ is evaluated at i.i.d. random design
points $u_n$, $n=1,...,N$ generated by an unknown general probability
distribution. We consider Tikhonov regularization with general convex and
$p$-homogeneous penalty functionals and derive concentration rates of the
regularized solution to the ground truth measured in the symmetric Bregman
distance induced by the penalty functional. We derive concrete rates for Besov
norm penalties and numerically demonstrate the correspondence with the observed
rates in the context of X-ray tomography.
</p>
<a href="http://arxiv.org/abs/2102.09526" target="_blank">arXiv:2102.09526</a> [<a href="http://arxiv.org/pdf/2102.09526" target="_blank">pdf</a>]

<h2>Weed Density and Distribution Estimation for Precision Agriculture using Semi-Supervised Learning. (arXiv:2011.02193v2 [cs.CV] CROSS LISTED)</h2>
<h3>Shantam Shorewala, Armaan Ashfaque, Sidharth R, Ujjwal Verma</h3>
<p>Uncontrolled growth of weeds can severely affect the crop yield and quality.
Unrestricted use of herbicide for weed removal alters biodiversity and cause
environmental pollution. Instead, identifying weed-infested regions can aid
selective chemical treatment of these regions. Advances in analyzing farm
images have resulted in solutions to identify weed plants. However, a majority
of these approaches are based on supervised learning methods which requires
huge amount of manually annotated images. As a result, these supervised
approaches are economically infeasible for the individual farmer because of the
wide variety of plant species being cultivated. In this paper, we propose a
deep learning-based semi-supervised approach for robust estimation of weed
density and distribution across farmlands using only limited color images
acquired from autonomous robots. This weed density and distribution can be
useful in a site-specific weed management system for selective treatment of
infected areas using autonomous robots. In this work, the foreground vegetation
pixels containing crops and weeds are first identified using a Convolutional
Neural Network (CNN) based unsupervised segmentation. Subsequently, the weed
infected regions are identified using a fine-tuned CNN, eliminating the need
for designing hand-crafted features. The approach is validated on two datasets
of different crop/weed species (1) Crop Weed Field Image Dataset (CWFID), which
consists of carrot plant images and the (2) Sugar Beets dataset. The proposed
method is able to localize weed-infested regions a maximum recall of 0.99 and
estimate weed density with a maximum accuracy of 82.13%. Hence, the proposed
approach is shown to generalize to different plant species without the need for
extensive labeled data.
</p>
<a href="http://arxiv.org/abs/2011.02193" target="_blank">arXiv:2011.02193</a> [<a href="http://arxiv.org/pdf/2011.02193" target="_blank">pdf</a>]

<h2>Joint Characterization of Multiscale Information in High Dimensional Data. (arXiv:2102.09669v1 [stat.ML])</h2>
<h3>Daniel Sousa, Christopher Small</h3>
<p>High dimensional data can contain multiple scales of variance. Analysis tools
that preferentially operate at one scale can be ineffective at capturing all
the information present in this cross-scale complexity. We propose a multiscale
joint characterization approach designed to exploit synergies between global
and local approaches to dimensionality reduction. We illustrate this approach
using Principal Components Analysis (PCA) to characterize global variance
structure and t-stochastic neighbor embedding (t-sne) to characterize local
variance structure. Using both synthetic images and real-world imaging
spectroscopy data, we show that joint characterization is capable of detecting
and isolating signals which are not evident from either PCA or t-sne alone.
Broadly, t-sne is effective at rendering a randomly oriented low-dimensional
map of local clusters, and PCA renders this map interpretable by providing
global, physically meaningful structure. This approach is illustrated using
imaging spectroscopy data, and may prove particularly useful for other
geospatial data given robust local variance structure due to spatial
autocorrelation and physical interpretability of global variance structure due
to spectral properties of Earth surface materials. However, the fundamental
premise could easily be extended to other high dimensional datasets, including
image time series and non-image data.
</p>
<a href="http://arxiv.org/abs/2102.09669" target="_blank">arXiv:2102.09669</a> [<a href="http://arxiv.org/pdf/2102.09669" target="_blank">pdf</a>]

