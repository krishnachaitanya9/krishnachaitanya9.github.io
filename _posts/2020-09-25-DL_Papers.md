---
title: Latest Deep Learning Papers
date: 2021-02-01 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (238 Articles)</h1>
<h2>Gesture Recognition in Robotic Surgery: a Review. (arXiv:2102.00027v1 [cs.CV])</h2>
<h3>Beatrice van Amsterdam, Matthew J. Clarkson, Danail Stoyanov</h3>
<p>Objective: Surgical activity recognition is a fundamental step in
computer-assisted interventions. This paper reviews the state-of-the-art in
methods for automatic recognition of fine-grained gestures in robotic surgery
focusing on recent data-driven approaches and outlines the open questions and
future research directions. Methods: An article search was performed on 5
bibliographic databases with the following search terms: robotic,
robot-assisted, JIGSAWS, surgery, surgical, gesture, fine-grained, surgeme,
action, trajectory, segmentation, recognition, parsing. Selected articles were
classified based on the level of supervision required for training and divided
into different groups representing major frameworks for time series analysis
and data modelling. Results: A total of 52 articles were reviewed. The research
field is showing rapid expansion, with the majority of articles published in
the last 4 years. Deep-learning-based temporal models with discriminative
feature extraction and multi-modal data integration have demonstrated promising
results on small surgical datasets. Currently, unsupervised methods perform
significantly less well than the supervised approaches. Conclusion: The
development of large and diverse open-source datasets of annotated
demonstrations is essential for development and validation of robust solutions
for surgical gesture recognition. While new strategies for discriminative
feature extraction and knowledge transfer, or unsupervised and semi-supervised
approaches, can mitigate the need for data and labels, they have not yet been
demonstrated to achieve comparable performance. Important future research
directions include detection and forecast of gesture-specific errors and
anomalies. Significance: This paper is a comprehensive and structured analysis
of surgical gesture recognition methods aiming to summarize the status of this
rapidly evolving field.
</p>
<a href="http://arxiv.org/abs/2102.00027" target="_blank">arXiv:2102.00027</a> [<a href="http://arxiv.org/pdf/2102.00027" target="_blank">pdf</a>]

<h2>You Only Query Once: Effective Black Box Adversarial Attacks with Minimal Repeated Queries. (arXiv:2102.00029v1 [cs.LG])</h2>
<h3>Devin Willmott, Anit Kumar Sahu, Fatemeh Sheikholeslami, Filipe Condessa, Zico Kolter</h3>
<p>Researchers have repeatedly shown that it is possible to craft adversarial
attacks on deep classifiers (small perturbations that significantly change the
class label), even in the "black-box" setting where one only has query access
to the classifier. However, all prior work in the black-box setting attacks the
classifier by repeatedly querying the same image with minor modifications,
usually thousands of times or more, making it easy for defenders to detect an
ensuing attack. In this work, we instead show that it is possible to craft
(universal) adversarial perturbations in the black-box setting by querying a
sequence of different images only once. This attack prevents detection from
high number of similar queries and produces a perturbation that causes
misclassification when applied to any input to the classifier. In experiments,
we show that attacks that adhere to this restriction can produce untargeted
adversarial perturbations that fool the vast majority of MNIST and CIFAR-10
classifier inputs, as well as in excess of $60-70\%$ of inputs on ImageNet
classifiers. In the targeted setting, we exhibit targeted black-box universal
attacks on ImageNet classifiers with success rates above $20\%$ when only
allowed one query per image, and $66\%$ when allowed two queries per image.
</p>
<a href="http://arxiv.org/abs/2102.00029" target="_blank">arXiv:2102.00029</a> [<a href="http://arxiv.org/pdf/2102.00029" target="_blank">pdf</a>]

<h2>Optimistic Policy Iteration for MDPs with Acyclic Transient State Structure. (arXiv:2102.00030v1 [cs.LG])</h2>
<h3>Joseph Lubars, Anna Winnicki, Michael Livesay, R. Srikant</h3>
<p>We consider Markov Decision Processes (MDPs) in which every stationary policy
induces the same graph structure for the underlying Markov chain and further,
the graph has the following property: if we replace each recurrent class by a
node, then the resulting graph is acyclic. For such MDPs, we prove the
convergence of the stochastic dynamics associated with a version of optimistic
policy iteration (OPI), suggested in Tsitsiklis (2002), in which the values
associated with all the nodes visited during each iteration of the OPI are
updated.
</p>
<a href="http://arxiv.org/abs/2102.00030" target="_blank">arXiv:2102.00030</a> [<a href="http://arxiv.org/pdf/2102.00030" target="_blank">pdf</a>]

<h2>Model Adaptation for Image Reconstruction using Generalized Stein's Unbiased Risk Estimator. (arXiv:2102.00047v1 [cs.LG])</h2>
<h3>Hemant Kumar Aggarwal, Mathews Jacob</h3>
<p>Deep learning image reconstruction algorithms often suffer from model
mismatches when the acquisition scheme differs significantly from the forward
model used during training. We introduce a Generalized Stein's Unbiased Risk
Estimate (GSURE) loss metric to adapt the network to the measured k-space data
and minimize model misfit impact. Unlike current methods that rely on the mean
square error in kspace, the proposed metric accounts for noise in the
measurements. This makes the approach less vulnerable to overfitting, thus
offering improved reconstruction quality compared to schemes that rely on
mean-square error. This approach may be useful to rapidly adapt pre-trained
models to new acquisition settings (e.g., multi-site) and different contrasts
than training data
</p>
<a href="http://arxiv.org/abs/2102.00047" target="_blank">arXiv:2102.00047</a> [<a href="http://arxiv.org/pdf/2102.00047" target="_blank">pdf</a>]

<h2>Neural 3D Clothes Retargeting from a Single Image. (arXiv:2102.00062v1 [cs.CV])</h2>
<h3>Jae Shin Yoon, Kihwan Kim, Jan Kautz, Hyun Soo Park</h3>
<p>In this paper, we present a method of clothes retargeting; generating the
potential poses and deformations of a given 3D clothing template model to fit
onto a person in a single RGB image. The problem is fundamentally ill-posed as
attaining the ground truth data is impossible, i.e., images of people wearing
the different 3D clothing template model at exact same pose. We address this
challenge by utilizing large-scale synthetic data generated from physical
simulation, allowing us to map 2D dense body pose to 3D clothing deformation.
With the simulated data, we propose a semi-supervised learning framework that
validates the physical plausibility of the 3D deformation by matching with the
prescribed body-to-cloth contact points and clothing silhouette to fit onto the
unlabeled real images. A new neural clothes retargeting network (CRNet) is
designed to integrate the semi-supervised retargeting task in an end-to-end
fashion. In our evaluation, we show that our method can predict the realistic
3D pose and deformation field needed for retargeting clothes models in
real-world examples.
</p>
<a href="http://arxiv.org/abs/2102.00062" target="_blank">arXiv:2102.00062</a> [<a href="http://arxiv.org/pdf/2102.00062" target="_blank">pdf</a>]

<h2>A linearized framework and a new benchmark for model selection for fine-tuning. (arXiv:2102.00084v1 [cs.CV])</h2>
<h3>Aditya Deshpande, Alessandro Achille, Avinash Ravichandran, Hao Li, Luca Zancato, Charless Fowlkes, Rahul Bhotika, Stefano Soatto, Pietro Perona</h3>
<p>Fine-tuning from a collection of models pre-trained on different domains (a
"model zoo") is emerging as a technique to improve test accuracy in the
low-data regime. However, model selection, i.e. how to pre-select the right
model to fine-tune from a model zoo without performing any training, remains an
open topic. We use a linearized framework to approximate fine-tuning, and
introduce two new baselines for model selection -- Label-Gradient and
Label-Feature Correlation. Since all model selection algorithms in the
literature have been tested on different use-cases and never compared directly,
we introduce a new comprehensive benchmark for model selection comprising of:
i) A model zoo of single and multi-domain models, and ii) Many target tasks.
Our benchmark highlights accuracy gain with model zoo compared to fine-tuning
Imagenet models. We show our model selection baseline can select optimal models
to fine-tune in few selections and has the highest ranking correlation to
fine-tuning accuracy compared to existing algorithms.
</p>
<a href="http://arxiv.org/abs/2102.00084" target="_blank">arXiv:2102.00084</a> [<a href="http://arxiv.org/pdf/2102.00084" target="_blank">pdf</a>]

<h2>Stimuli-Sensitive Hawkes Processes for Personalized Student Procrastination Modeling. (arXiv:2102.00089v1 [cs.LG])</h2>
<h3>Mengfan Yao, Siqian Zhao, Shaghayegh Sahebi, Reza Feyzi Behnagh</h3>
<p>Student procrastination and cramming for deadlines are major challenges in
online learning environments, with negative educational and well-being side
effects. Modeling student activities in continuous time and predicting their
next study time are important problems that can help in creating personalized
timely interventions to mitigate these challenges. However, previous attempts
on dynamic modeling of student procrastination suffer from major issues: they
are unable to predict the next activity times, cannot deal with missing
activity history, are not personalized, and disregard important course
properties, such as assignment deadlines, that are essential in explaining the
cramming behavior. To resolve these problems, we introduce a new personalized
stimuli-sensitive Hawkes process model (SSHP), by jointly modeling all
student-assignment pairs and utilizing their similarities, to predict students'
next activity times even when there are no historical observations. Unlike
regular point processes that assume a constant external triggering effect from
the environment, we model three dynamic types of external stimuli, according to
assignment availabilities, assignment deadlines, and each student's time
management habits. Our experiments on two synthetic datasets and two real-world
datasets show a superior performance of future activity prediction, comparing
with state-of-the-art models. Moreover, we show that our model achieves a
flexible and accurate parameterization of activity intensities in students.
</p>
<a href="http://arxiv.org/abs/2102.00089" target="_blank">arXiv:2102.00089</a> [<a href="http://arxiv.org/pdf/2102.00089" target="_blank">pdf</a>]

<h2>Relaxed Clustered Hawkes Process for Procrastination Modeling in MOOCs. (arXiv:2102.00093v1 [cs.LG])</h2>
<h3>Mengfan Yao, Siqian Zhao, Shaghayegh Sahebi, Reza Feyzi Behnagh</h3>
<p>Hawkes processes have been shown to be efficient in modeling bursty sequences
in a variety of applications, such as finance and social network activity
analysis. Traditionally, these models parameterize each process independently
and assume that the history of each point process can be fully observed. Such
models could however be inefficient or even prohibited in certain real-world
applications, such as in the field of education, where such assumptions are
violated. Motivated by the problem of detecting and predicting student
procrastination in students Massive Open Online Courses (MOOCs) with missing
and partially observed data, in this work, we propose a novel personalized
Hawkes process model (RCHawkes-Gamma) that discovers meaningful student
behavior clusters by jointly learning all partially observed processes
simultaneously, without relying on auxiliary features. Our experiments on both
synthetic and real-world education datasets show that RCHawkes-Gamma can
effectively recover student clusters and their temporal procrastination
dynamics, resulting in better predictive performance of future student
activities. Our further analyses of the learned parameters and their
association with student delays show that the discovered student clusters
unveil meaningful representations of various procrastination behaviors in
students.
</p>
<a href="http://arxiv.org/abs/2102.00093" target="_blank">arXiv:2102.00093</a> [<a href="http://arxiv.org/pdf/2102.00093" target="_blank">pdf</a>]

<h2>Belief function-based semi-supervised learning for brain tumor segmentation. (arXiv:2102.00097v1 [cs.CV])</h2>
<h3>Ling Huang, Su Ruan, Thierry Denoeux</h3>
<p>Precise segmentation of a lesion area is important for optimizing its
treatment. Deep learning makes it possible to detect and segment a lesion field
using annotated data. However, obtaining precisely annotated data is very
challenging in the medical domain. Moreover, labeling uncertainty and
imprecision make segmentation results unreliable. In this paper, we address the
uncertain boundary problem by a new evidential neural network with an
information fusion strategy, and the scarcity of annotated data by
semi-supervised learning. Experimental results show that our proposal has
better performance than state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.00097" target="_blank">arXiv:2102.00097</a> [<a href="http://arxiv.org/pdf/2102.00097" target="_blank">pdf</a>]

<h2>Distributed Control of Multi-Robot Systems in the Presence of Deception and Denial of Service Attacks. (arXiv:2102.00098v1 [cs.RO])</h2>
<h3>Sangjun Lee, Byung-Cheol Min</h3>
<p>This research proposes a distributed switching control to secure multi-robot
systems in the presence of cyberattacks. Two major types of cyberattack are
considered: deception attack and denial of service (DoS) attack, which
compromise the integrity and availability of resources, respectively. First, a
residual-based attack detection scheme is introduced to identify the type of
attacks. Then, a switching control is designed to neutralize the effect of the
identified attacks, satisfying the performance guarantees required for state
consensus among robots. For the type of a deception attack, coordination-free
consensus protocols are designed to tune the weights of each robot in a way
that uncompromised robots gain more weight than compromised robots. For the
type of a DoS attack, leader-follower protocols that reconfigure the
communication topology are utilized to transform the compromised robots into
sub-robots following the leaders. The performance of the proposed approach is
evaluated on the Robotarium multi-robot testbed. A full demonstration with
extensive cases is available at https://youtu.be/eSj0XS2pdxI.
</p>
<a href="http://arxiv.org/abs/2102.00098" target="_blank">arXiv:2102.00098</a> [<a href="http://arxiv.org/pdf/2102.00098" target="_blank">pdf</a>]

<h2>Synthetic Data and Hierarchical Object Detection in Overhead Imagery. (arXiv:2102.00103v1 [cs.CV])</h2>
<h3>Nathan Clement, Alan Schoen, Arnold Boedihardjo, Andrew Jenkins</h3>
<p>The performance of neural network models is often limited by the availability
of big data sets. To treat this problem, we survey and develop novel synthetic
data generation and augmentation techniques for enhancing low/zero-sample
learning in satellite imagery. In addition to extending synthetic data
generation approaches, we propose a hierarchical detection approach to improve
the utility of synthetic training samples. We consider existing techniques for
producing synthetic imagery--3D models and neural style transfer--as well as
introducing our own adversarially trained reskinning network, the
GAN-Reskinner, to blend 3D models. Additionally, we test the value of synthetic
data in a two-stage, hierarchical detection/classification model of our own
construction. To test the effectiveness of synthetic imagery, we employ it in
the training of detection models and our two stage model, and evaluate the
resulting models on real satellite images. All modalities of synthetic data are
tested extensively on practical, geospatial analysis problems. Our experiments
show that synthetic data developed using our approach can often enhance
detection performance, particularly when combined with some real training
images. When the only source of data is synthetic, our GAN-Reskinner often
boosts performance over conventionally rendered 3D models and in all cases the
hierarchical model outperforms the baseline end-to-end detection architecture.
</p>
<a href="http://arxiv.org/abs/2102.00103" target="_blank">arXiv:2102.00103</a> [<a href="http://arxiv.org/pdf/2102.00103" target="_blank">pdf</a>]

<h2>SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent Prediction. (arXiv:2102.00109v1 [cs.CV])</h2>
<h3>Jasmine Sekhon, Cody Fleming</h3>
<p>Safe navigation of autonomous agents in human centric environments requires
the ability to understand and predict motion of neighboring pedestrians.
However, predicting pedestrian intent is a complex problem. Pedestrian motion
is governed by complex social navigation norms, is dependent on neighbors'
trajectories, and is multimodal in nature. In this work, we propose
\textbf{SCAN}, a \textbf{S}patial \textbf{C}ontext \textbf{A}ttentive
\textbf{N}etwork that can jointly predict socially-acceptable multiple future
trajectories for all pedestrians in a scene. SCAN encodes the influence of
spatially close neighbors using a novel spatial attention mechanism in a manner
that relies on fewer assumptions, is parameter efficient, and is more
interpretable compared to state-of-the-art spatial attention approaches.
Through experiments on several datasets we demonstrate that our approach can
also quantitatively outperform state of the art trajectory prediction methods
in terms of accuracy of predicted intent.
</p>
<a href="http://arxiv.org/abs/2102.00109" target="_blank">arXiv:2102.00109</a> [<a href="http://arxiv.org/pdf/2102.00109" target="_blank">pdf</a>]

<h2>Neutron-Induced, Single-Event Effects on Neuromorphic Event-based Vision Sensor: A First Step Towards Space Applications. (arXiv:2102.00112v1 [cs.CV])</h2>
<h3>Seth Roffe, Himanshu Akolkar, Alan D. George, Bernab&#xe9; Linares-barranco, Ryad Benosman</h3>
<p>This paper studies the suitability of neuromorphic event-based vision cameras
for spaceflight, and the effects of neutron radiation on their performance.
Neuromorphic event-based vision cameras are novel sensors that implement
asynchronous, clockless data acquisition, providing information about the
change in illuminance greater than 120dB with sub-millisecond temporal
precision. These sensors have huge potential for space applications as they
provide an extremely sparse representation of visual dynamics while removing
redundant information, thereby conforming to low-resource requirements. An
event-based sensor was irradiated under wide-spectrum neutrons at Los Alamos
Neutron Science Center and its effects were classified. We found that the
sensor had very fast recovery during radiation, showing high correlation of
noise event bursts with respect to source macro-pulses. No significant
differences were observed between the number of events induced at different
angles of incidence but significant differences were found in the spatial
structure of noise events at different angles. The results show that
event-based cameras are capable of functioning in a space-like, radiative
environment with a signal-to-noise ratio of 3.355. They also show that
radiation-induced noise does not affect event-level computation. We also
introduce the Event-based Radiation-Induced Noise Simulation Environment
(Event-RINSE), a simulation environment based on the noise-modelling we
conducted and capable of injecting the effects of radiation-induced noise from
the collected data to any stream of events in order to ensure that developed
code can operate in a radiative environment. To the best of our knowledge, this
is the first time such analysis of neutron-induced noise analysis has been
performed on a neuromorphic vision sensor, and this study shows the advantage
of using such sensors for space applications.
</p>
<a href="http://arxiv.org/abs/2102.00112" target="_blank">arXiv:2102.00112</a> [<a href="http://arxiv.org/pdf/2102.00112" target="_blank">pdf</a>]

<h2>On Data Efficiency of Meta-learning. (arXiv:2102.00127v1 [cs.LG])</h2>
<h3>Maruan Al-Shedivat, Liam Li, Eric Xing, Ameet Talwalkar</h3>
<p>Meta-learning has enabled learning statistical models that can be quickly
adapted to new prediction tasks. Motivated by use-cases in personalized
federated learning, we study the often overlooked aspect of the modern
meta-learning algorithms -- their data efficiency. To shed more light on which
methods are more efficient, we use techniques from algorithmic stability to
derive bounds on the transfer risk that have important practical implications,
indicating how much supervision is needed and how it must be allocated for each
method to attain the desired level of generalization. Further, we introduce a
new simple framework for evaluating meta-learning methods under a limit on the
available supervision, conduct an empirical study of MAML, Reptile, and
Protonets, and demonstrate the differences in the behavior of these methods on
few-shot and federated learning benchmarks. Finally, we propose active
meta-learning, which incorporates active data selection into learning-to-learn,
leading to better performance of all methods in the limited supervision regime.
</p>
<a href="http://arxiv.org/abs/2102.00127" target="_blank">arXiv:2102.00127</a> [<a href="http://arxiv.org/pdf/2102.00127" target="_blank">pdf</a>]

<h2>Policy Mirror Descent for Reinforcement Learning: Linear Convergence, New Sampling Complexity, and Generalized Problem Classes. (arXiv:2102.00135v1 [cs.LG])</h2>
<h3>Guanghui Lan</h3>
<p>We present new policy mirror descent (PMD) methods for solving reinforcement
learning (RL) problems with either strongly convex or general convex
regularizers. By exploring the structural properties of these overall highly
nonconvex problems we show that the PMD methods exhibit fast linear rate of
convergence to the global optimality. We develop stochastic counterparts of
these methods, and establish an ${\cal O}(1/\epsilon)$ (resp., ${\cal
O}(1/\epsilon^2)$) sampling complexity for solving these RL problems with
strongly (resp., general) convex regularizers using different sampling schemes,
where $\epsilon$ denote the target accuracy. We further show that the
complexity for computing the gradients of these regularizers, if necessary, can
be bounded by ${\cal O}\{(\log_\gamma \epsilon) [(1-\gamma)L/\mu]^{1/2}\log
(1/\epsilon)\}$ (resp., ${\cal O} \{(\log_\gamma \epsilon )
[(1-\gamma)L/\epsilon]^{1/2}\}$) for problems with strongly (resp., general)
convex regularizers. Here $\gamma$ denotes the discounting factor. To the best
of our knowledge, these complexity bounds, along with our algorithmic
developments, appear to be new in both optimization and RL literature. The
introduction of these convex regularizers also greatly expands the flexibility
and applicability of RL models.
</p>
<a href="http://arxiv.org/abs/2102.00135" target="_blank">arXiv:2102.00135</a> [<a href="http://arxiv.org/pdf/2102.00135" target="_blank">pdf</a>]

<h2>Latent-Space Inpainting for Packet Loss Concealment in Collaborative Object Detection. (arXiv:2102.00142v1 [cs.CV])</h2>
<h3>Ivan V. Baji&#x107;</h3>
<p>Edge devices, such as cameras and mobile units, are increasingly capable of
performing sophisticated computation in addition to their traditional roles in
sensing and communicating signals. The focus of this paper is on collaborative
object detection, where deep features computed on the edge device from input
images are transmitted to the cloud for further processing. We consider the
impact of packet loss on the transmitted features and examine several ways for
recovering the missing data. In particular, through theory and experiments, we
show that methods for image inpainting based on partial differential equations
work well for the recovery of missing features in the latent space. The
obtained results represent the new state of the art for missing data recovery
in collaborative object detection.
</p>
<a href="http://arxiv.org/abs/2102.00142" target="_blank">arXiv:2102.00142</a> [<a href="http://arxiv.org/pdf/2102.00142" target="_blank">pdf</a>]

<h2>DRIV100: In-The-Wild Multi-Domain Dataset and Evaluation for Real-World Domain Adaptation of Semantic Segmentation. (arXiv:2102.00150v1 [cs.CV])</h2>
<h3>Haruya Sakashita, Christoph Flothow, Noriko Takemura, Yusuke Sugano</h3>
<p>Together with the recent advances in semantic segmentation, many domain
adaptation methods have been proposed to overcome the domain gap between
training and deployment environments. However, most previous studies use
limited combinations of source/target datasets, and domain adaptation
techniques have never been thoroughly evaluated in a more challenging and
diverse set of target domains. This work presents a new multi-domain dataset
\datasetname~for benchmarking domain adaptation techniques on in-the-wild
road-scene videos collected from the Internet. The dataset consists of
pixel-level annotations for 100 videos selected to cover diverse scenes/domains
based on two criteria; human subjective judgment and an anomaly score judged
using an existing road-scene dataset. We provide multiple manually labeled
ground-truth frames for each video, enabling a thorough evaluation of
video-level domain adaptation where each video independently serves as the
target domain. Using the dataset, we quantify domain adaptation performances of
state-of-the-art methods and clarify the potential and novel challenges of
domain adaptation techniques. The dataset is available at
https://doi.org/10.5281/zenodo.4389243.
</p>
<a href="http://arxiv.org/abs/2102.00150" target="_blank">arXiv:2102.00150</a> [<a href="http://arxiv.org/pdf/2102.00150" target="_blank">pdf</a>]

<h2>Regression or Classification? New Methods to Evaluate No-Reference Picture and Video Quality Models. (arXiv:2102.00155v1 [cs.CV])</h2>
<h3>Zhengzhong Tu, Chia-Ju Chen, Li-Heng Chen, Yilin Wang, Neil Birkbeck, Balu Adsumilli, Alan C. Bovik</h3>
<p>Video and image quality assessment has long been projected as a regression
problem, which requires predicting a continuous quality score given an input
stimulus. However, recent efforts have shown that accurate quality score
regression on real-world user-generated content (UGC) is a very challenging
task. To make the problem more tractable, we propose two new methods - binary,
and ordinal classification - as alternatives to evaluate and compare
no-reference quality models at coarser levels. Moreover, the proposed new tasks
convey more practical meaning on perceptually optimized UGC transcoding, or for
preprocessing on media processing platforms. We conduct a comprehensive
benchmark experiment of popular no-reference quality models on recent
in-the-wild picture and video quality datasets, providing reliable baselines
for both evaluation methods to support further studies. We hope this work
promotes coarse-grained perceptual modeling and its applications to efficient
UGC processing.
</p>
<a href="http://arxiv.org/abs/2102.00155" target="_blank">arXiv:2102.00155</a> [<a href="http://arxiv.org/pdf/2102.00155" target="_blank">pdf</a>]

<h2>Deep Model Compression based on the Training History. (arXiv:2102.00160v1 [cs.CV])</h2>
<h3>S.H.Shabbeer Basha, Mohammad Farazuddin, Viswanath Pulabaigari, Shiv Ram Dubey, Snehasis Mukherjee</h3>
<p>Deep Convolutional Neural Networks (DCNNs) have shown promising results in
several visual recognition problems which motivated the researchers to propose
popular architectures such as LeNet, AlexNet, VGGNet, ResNet, and many more.
These architectures come at a cost of high computational complexity and
parameter storage. To get rid of storage and computational complexity, deep
model compression methods have been evolved. We propose a novel History Based
Filter Pruning (HBFP) method that utilizes network training history for filter
pruning. Specifically, we prune the redundant filters by observing similar
patterns in the L1-norms of filters (absolute sum of weights) over the training
epochs. We iteratively prune the redundant filters of a CNN in three steps.
First, we train the model and select the filter pairs with redundant filters in
each pair. Next, we optimize the network to increase the similarity between the
filters in a pair. It facilitates us to prune one filter from each pair based
on its importance without much information loss. Finally, we retrain the
network to regain the performance, which is dropped due to filter pruning. We
test our approach on popular architectures such as LeNet-5 on MNIST dataset and
VGG-16, ResNet-56, and ResNet-110 on CIFAR-10 dataset. The proposed pruning
method outperforms the state-of-the-art in terms of FLOPs reduction
(floating-point operations) by 97.98%, 83.42%, 78.43%, and 74.95% for LeNet-5,
VGG-16, ResNet-56, and ResNet-110 models, respectively, while maintaining the
less error rate.
</p>
<a href="http://arxiv.org/abs/2102.00160" target="_blank">arXiv:2102.00160</a> [<a href="http://arxiv.org/pdf/2102.00160" target="_blank">pdf</a>]

<h2>Stay Alive with Many Options: A Reinforcement Learning Approach for Autonomous Navigation. (arXiv:2102.00168v1 [cs.AI])</h2>
<h3>Ambedkar Dukkipati, Rajarshi Banerjee, Ranga Shaarad Ayyagari, Dhaval Parmar Udaybhai</h3>
<p>Hierarchical reinforcement learning approaches learn policies based on
hierarchical decision structures. However, training such methods in practice
may lead to poor generalization, with either sub-policies executing actions for
too few time steps or devolving into a single policy altogether. In our work,
we introduce an alternative approach to sequentially learn such skills without
using an overarching hierarchical policy, in the context of environments in
which an objective of the agent is to prolong the episode for as long as
possible, or in other words `stay alive'. We demonstrate the utility of our
approach in a simulated 3D navigation environment which we have built. We show
that our method outperforms prior methods such as Soft Actor Critic and Soft
Option Critic on our environment, as well as the Atari River Raid environment.
</p>
<a href="http://arxiv.org/abs/2102.00168" target="_blank">arXiv:2102.00168</a> [<a href="http://arxiv.org/pdf/2102.00168" target="_blank">pdf</a>]

<h2>On the Stability of Random Matrix Product with Markovian Noise: Application to Linear Stochastic Approximation and TD Learning. (arXiv:2102.00185v1 [stat.ML])</h2>
<h3>Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov, Hoi-To Wai</h3>
<p>This paper studies the exponential stability of random matrix products driven
by a general (possibly unbounded) state space Markov chain. It is a cornerstone
in the analysis of stochastic algorithms in machine learning (e.g. for
parameter tracking in online learning or reinforcement learning). The existing
results impose strong conditions such as uniform boundedness of the
matrix-valued functions and uniform ergodicity of the Markov chains. Our main
contribution is an exponential stability result for the $p$-th moment of random
matrix product, provided that (i) the underlying Markov chain satisfies a
super-Lyapunov drift condition, (ii) the growth of the matrix-valued functions
is controlled by an appropriately defined function (related to the drift
condition). Using this result, we give finite-time $p$-th moment bounds for
constant and decreasing stepsize linear stochastic approximation schemes with
Markovian noise on general state space. We illustrate these findings for linear
value-function estimation in reinforcement learning. We provide finite-time
$p$-th moment bound for various members of temporal difference (TD) family of
algorithms.
</p>
<a href="http://arxiv.org/abs/2102.00185" target="_blank">arXiv:2102.00185</a> [<a href="http://arxiv.org/pdf/2102.00185" target="_blank">pdf</a>]

<h2>Coupling innovation method and feasibility analysis of garbage classification. (arXiv:2102.00193v1 [cs.LG])</h2>
<h3>Zizhe Wang, Shaomeng Shen, Jiabei Mu</h3>
<p>In order to solve the recent defect in garbage classification - including low
level of intelligence, low accuracy and high cost of equipment, this paper
presents a series of methods in identification and judgment in intelligent
garbage classification, including a material identification based on thermal
principle and non-destructive laser irradiation, another material
identification based on optical diffraction and phase analysis, a profile
identification which utilizes a scenery thermal image after PCA and histogram
correction, another profile identification which utilizes computer vision with
innovated data sets and algorithms. Combining AHP and Bayesian formula, the
paper innovates a coupling algorithm which helps to make a comprehensive
judgment of the garbage sort, based on the material and profile identification.
This paper also proposes a method for real-time space measurement of garbage
cans, which based on the characteristics of air as fluid, and analyses the
functions of air cleaning and particle disposing. Instead of the single use of
garbage image recognition, this paper provides a comprehensive method to judge
the garbage sort by material and profile identifications, which greatly
enhancing the accuracy and intelligence in garbage classification.
</p>
<a href="http://arxiv.org/abs/2102.00193" target="_blank">arXiv:2102.00193</a> [<a href="http://arxiv.org/pdf/2102.00193" target="_blank">pdf</a>]

<h2>Linear Frequency Principle Model to Understand the Absence of Overfitting in Neural Networks. (arXiv:2102.00200v1 [cs.LG])</h2>
<h3>Yaoyu Zhang, Tao Luo, Zheng Ma, Zhi-Qin John Xu</h3>
<p>Why heavily parameterized neural networks (NNs) do not overfit the data is an
important long standing open question. We propose a phenomenological model of
the NN training to explain this non-overfitting puzzle. Our linear frequency
principle (LFP) model accounts for a key dynamical feature of NNs: they learn
low frequencies first, irrespective of microscopic details. Theory based on our
LFP model shows that low frequency dominance of target functions is the key
condition for the non-overfitting of NNs and is verified by experiments.
Furthermore, through an ideal two-layer NN, we unravel how detailed microscopic
NN training dynamics statistically gives rise to a LFP model with quantitative
prediction power.
</p>
<a href="http://arxiv.org/abs/2102.00200" target="_blank">arXiv:2102.00200</a> [<a href="http://arxiv.org/pdf/2102.00200" target="_blank">pdf</a>]

<h2>SNR-adaptive deep joint source-channel coding for wireless image transmission. (arXiv:2102.00202v1 [cs.AI])</h2>
<h3>Mingze Ding, Jiahui Li, Mengyao Ma, Xiaopeng Fan</h3>
<p>Considering the problem of joint source-channel coding (JSCC) for multi-user
transmission of images over noisy channels, an autoencoder-based novel deep
joint source-channel coding scheme is proposed in this paper. In the proposed
JSCC scheme, the decoder can estimate the signal-to-noise ratio (SNR) and use
it to adaptively decode the transmitted image. Experiments demonstrate that the
proposed scheme achieves impressive results in adaptability for different SNRs
and is robust to the decoder's estimation error of the SNR. To the best of our
knowledge, this is the first deep JSCC scheme that focuses on the adaptability
for different SNRs and can be applied to multi-user scenarios.
</p>
<a href="http://arxiv.org/abs/2102.00202" target="_blank">arXiv:2102.00202</a> [<a href="http://arxiv.org/pdf/2102.00202" target="_blank">pdf</a>]

<h2>A self-supervised learning-based 6-DOF grasp planning method for manipulator. (arXiv:2102.00205v1 [cs.RO])</h2>
<h3>Gang Peng, Zhenyu Ren, Hao Wang, Xinde Li</h3>
<p>To realize a robust robotic grasping system for unknown objects in an
unstructured environment, large amounts of grasp data and 3D model data for the
object are required, the sizes of which directly affect the rate of successful
grasps. To reduce the time cost of data acquisition and labeling and increase
the rate of successful grasps, we developed a self-supervised learning
mechanism to control grasp tasks performed by manipulators. First, a
manipulator automatically collects the point cloud for the objects from
multiple perspectives to increase the efficiency of data acquisition. The
complete point cloud for the objects is obtained by utilizing the hand-eye
vision of the manipulator, and the TSDF algorithm. Then, the point cloud data
for the objects is used to generate a series of six-degrees-of-freedom grasp
poses, and the force-closure decision algorithm is used to add the grasp
quality label to each grasp pose to realize the automatic labeling of grasp
data. Finally, the point cloud in the gripper closing area corresponding to
each grasp pose is obtained; it is then used to train the grasp-quality
classification model for the manipulator. The results of data acquisition
experiments demonstrate that the proposed method allows high-quality data to be
obtained. The simulated results prove the effectiveness of the proposed
grasp-data acquisition method. The results of performing actual grasping
experiments demonstrate that the proposed self-supervised learning method can
increase the rate of successful grasps for the manipulator.
</p>
<a href="http://arxiv.org/abs/2102.00205" target="_blank">arXiv:2102.00205</a> [<a href="http://arxiv.org/pdf/2102.00205" target="_blank">pdf</a>]

<h2>Time Series (re)sampling using Generative Adversarial Networks. (arXiv:2102.00208v1 [cs.LG])</h2>
<h3>Christian M. Dahl, Emil N. S&#xf8;rensen</h3>
<p>We propose a novel bootstrap procedure for dependent data based on Generative
Adversarial networks (GANs). We show that the dynamics of common stationary
time series processes can be learned by GANs and demonstrate that GANs trained
on a single sample path can be used to generate additional samples from the
process. We find that temporal convolutional neural networks provide a suitable
design for the generator and discriminator, and that convincing samples can be
generated on the basis of a vector of iid normal noise. We demonstrate the
finite sample properties of GAN sampling and the suggested bootstrap using
simulations where we compare the performance to circular block bootstrapping in
the case of resampling an AR(1) time series processes. We find that resampling
using the GAN can outperform circular block bootstrapping in terms of empirical
coverage.
</p>
<a href="http://arxiv.org/abs/2102.00208" target="_blank">arXiv:2102.00208</a> [<a href="http://arxiv.org/pdf/2102.00208" target="_blank">pdf</a>]

<h2>Resolution enhancement in the recovery of underdrawings via style transfer by generative adversarial deep neural networks. (arXiv:2102.00209v1 [cs.CV])</h2>
<h3>George Cann, Anthony Bourached, Ryan-Rhys Griffiths, David Stork</h3>
<p>We apply generative adversarial convolutional neural networks to the problem
of style transfer to underdrawings and ghost-images in x-rays of fine art
paintings with a special focus on enhancing their spatial resolution. We build
upon a neural architecture developed for the related problem of synthesizing
high-resolution photo-realistic image from semantic label maps. Our neural
architecture achieves high resolution through a hierarchy of generators and
discriminator sub-networks, working throughout a range of spatial resolutions.
This coarse-to-fine generator architecture can increase the effective
resolution by a factor of eight in each spatial direction, or an overall
increase in number of pixels by a factor of 64. We also show that even just a
few examples of human-generated image segmentations can greatly improve --
qualitatively and quantitatively -- the generated images. We demonstrate our
method on works such as Leonardo's Madonna of the carnation and the
underdrawing in his Virgin of the rocks, which pose several special problems in
style transfer, including the paucity of representative works from which to
learn and transfer style information.
</p>
<a href="http://arxiv.org/abs/2102.00209" target="_blank">arXiv:2102.00209</a> [<a href="http://arxiv.org/pdf/2102.00209" target="_blank">pdf</a>]

<h2>Monitoring the Impacts of a Tailings Dam Failure Using Satellite Images. (arXiv:2102.00212v1 [cs.CV])</h2>
<h3>Jaime Moraga (1), Gurbet Gurkan (1), Sebnem Duzgun (1) ((1) Colorado School of Mines, Golden, Colorado)</h3>
<p>Monitoring dam failures using satellite images provides first responders with
efficient management of early interventions. It is also equally important to
monitor spatial and temporal changes in the inundation area to track the
post-disaster recovery. On January 25th, 2019, the tailings dam of the
C\'orrego do Feij\~ao iron ore mine, located in Brumadinho, Brazil, collapsed.
This disaster caused more than 230 fatalities and 30 missing people leading to
damage on the order of multiple billions of dollars. This study uses Sentinel-2
satellite images to map the inundation area and assess and delineate the land
use and land cover impacted by the dam failure. The images correspond to data
captures from January 22nd (3 days before), and February 02 (7 days after the
collapse). Satellite images of the region were classified for before and
aftermath of the disaster implementing a machine learning algorithm. In order
to have sufficient land cover types to validate the quality and accuracy of the
algorithm, 7 classes were defined: mine, forest, build-up, river, agricultural,
clear water, and grassland. The developed classification algorithm yielded a
high accuracy (99%) for the image before the collapse. This paper determines
land cover impact using two different models, 1) by using the trained network
in the "after" image, and 2) by creating a second network, trained in a subset
of points of the "after" image, and then comparing the land cover results of
the two trained networks. In the first model, applying the trained network to
the "after" image, the accuracy is still high (86%), but lower than using the
second model (98%). This strategy can be applied at a low cost for monitoring
and assessment by using openly available satellite information and, in case of
dam collapse or with a larger budget, higher resolution and faster data can be
obtained by fly-overs on the area of concern.
</p>
<a href="http://arxiv.org/abs/2102.00212" target="_blank">arXiv:2102.00212</a> [<a href="http://arxiv.org/pdf/2102.00212" target="_blank">pdf</a>]

<h2>ObjectAug: Object-level Data Augmentation for Semantic Image Segmentation. (arXiv:2102.00221v1 [cs.CV])</h2>
<h3>Jiawei Zhang, Yanchun Zhang, Xiaowei Xu</h3>
<p>Semantic image segmentation aims to obtain object labels with precise
boundaries, which usually suffers from overfitting. Recently, various data
augmentation strategies like regional dropout and mix strategies have been
proposed to address the problem. These strategies have proved to be effective
for guiding the model to attend on less discriminative parts. However, current
strategies operate at the image level, and objects and the background are
coupled. Thus, the boundaries are not well augmented due to the fixed semantic
scenario. In this paper, we propose ObjectAug to perform object-level
augmentation for semantic image segmentation. ObjectAug first decouples the
image into individual objects and the background using the semantic labels.
Next, each object is augmented individually with commonly used augmentation
methods (e.g., scaling, shifting, and rotation). Then, the black area brought
by object augmentation is further restored using image inpainting. Finally, the
augmented objects and background are assembled as an augmented image. In this
way, the boundaries can be fully explored in the various semantic scenarios. In
addition, ObjectAug can support category-aware augmentation that gives various
possibilities to objects in each category, and can be easily combined with
existing image-level augmentation methods to further boost performance.
Comprehensive experiments are conducted on both natural image and medical image
datasets. Experiment results demonstrate that our ObjectAug can evidently
improve segmentation performance.
</p>
<a href="http://arxiv.org/abs/2102.00221" target="_blank">arXiv:2102.00221</a> [<a href="http://arxiv.org/pdf/2102.00221" target="_blank">pdf</a>]

<h2>The Impact of Virtual Reality and Viewpoints in Body Motion Based Drone Teleoperation. (arXiv:2102.00226v1 [cs.RO])</h2>
<h3>Matteo Macchini, Manana Lortkipanidze, Fabrizio Schiano, Dario Floreano</h3>
<p>The operation of telerobotic systems can be a challenging task, requiring
intuitive and efficient interfaces to enable inexperienced users to attain a
high level of proficiency. Body-Machine Interfaces (BoMI) represent a promising
alternative to standard control devices, such as joysticks, because they
leverage intuitive body motion and gestures. It has been shown that the use of
Virtual Reality (VR) and first-person view perspectives can increase the user's
sense of presence in avatars. However, it is unclear if these beneficial
effects occur also in the teleoperation of non-anthropomorphic robots that
display motion patterns different from those of humans. Here we describe
experimental results on teleoperation of a non-anthropomorphic drone showing
that VR correlates with a higher sense of spatial presence, whereas viewpoints
moving coherently with the robot are associated with a higher sense of
embodiment. Furthermore, the experimental results show that spontaneous body
motion patterns are affected by VR and viewpoint conditions in terms of
variability, amplitude, and robot correlates, suggesting that the design of
BoMIs for drone teleoperation must take into account the use of Virtual Reality
and the choice of the viewpoint.
</p>
<a href="http://arxiv.org/abs/2102.00226" target="_blank">arXiv:2102.00226</a> [<a href="http://arxiv.org/pdf/2102.00226" target="_blank">pdf</a>]

<h2>NL-CNN: A Resources-Constrained Deep Learning Model based on Nonlinear Convolution. (arXiv:2102.00227v1 [cs.AI])</h2>
<h3>Radu Dogaru, Ioana Dogaru</h3>
<p>A novel convolution neural network model, abbreviated NL-CNN is proposed,
where nonlinear convolution is emulated in a cascade of convolution +
nonlinearity layers. The code for its implementation and some trained models
are made publicly available. Performance evaluation for several widely known
datasets is provided, showing several relevant features: i) for small / medium
input image sizes the proposed network gives very good testing accuracy, given
a low implementation complexity and model size; ii) compares favorably with
other widely known resources-constrained models, for instance in comparison to
MobileNetv2 provides better accuracy with several times less training times and
up to ten times less parameters (memory occupied by the model); iii) has a
relevant set of hyper-parameters which can be easily and rapidly tuned due to
the fast training specific to it. All these features make NL-CNN suitable for
IoT, smart sensing, bio-medical portable instrumentation and other applications
where artificial intelligence must be deployed in energy-constrained
environments.
</p>
<a href="http://arxiv.org/abs/2102.00227" target="_blank">arXiv:2102.00227</a> [<a href="http://arxiv.org/pdf/2102.00227" target="_blank">pdf</a>]

<h2>MUSE: Multi-Scale Temporal Features Evolution for Knowledge Tracing. (arXiv:2102.00228v1 [cs.AI])</h2>
<h3>Chengwei Zhang, Yangzhou Jiang, Wei Zhang, Chengyu Gu</h3>
<p>Transformer based knowledge tracing model is an extensively studied problem
in the field of computer-aided education. By integrating temporal features into
the encoder-decoder structure, transformers can processes the exercise
information and student response information in a natural way. However, current
state-of-the-art transformer-based variants still share two limitations. First,
extremely long temporal features cannot well handled as the complexity of
self-attention mechanism is O(n2). Second, existing approaches track the
knowledge drifts under fixed a window size, without considering different
temporal-ranges. To conquer these problems, we propose MUSE, which is equipped
with multi-scale temporal sensor unit, that takes either local or global
temporal features into consideration. The proposed model is capable to capture
the dynamic changes in users knowledge states at different temporal-ranges, and
provides an efficient and powerful way to combine local and global features to
make predictions. Our method won the 5-th place over 3,395 teams in the Riiid
AIEd Challenge 2020.
</p>
<a href="http://arxiv.org/abs/2102.00228" target="_blank">arXiv:2102.00228</a> [<a href="http://arxiv.org/pdf/2102.00228" target="_blank">pdf</a>]

<h2>ICodeNet -- A Hierarchical Neural Network Approach for Source Code Author Identification. (arXiv:2102.00230v1 [cs.LG])</h2>
<h3>Pranali Bora, Tulika Awalgaonkar, Himanshu Palve, Raviraj Joshi, Purvi Goel</h3>
<p>With the open-source revolution, source codes are now more easily accessible
than ever. This has, however, made it easier for malicious users and
institutions to copy the code without giving regards to the license, or credit
to the original author. Therefore, source code author identification is a
critical task with paramount importance. In this paper, we propose ICodeNet - a
hierarchical neural network that can be used for source code file-level tasks.
The ICodeNet processes source code in image format and is employed for the task
of per file author identification. The ICodeNet consists of an ImageNet trained
VGG encoder followed by a shallow neural network. The shallow network is based
either on CNN or LSTM. Different variations of models are evaluated on a source
code author classification dataset. We have also compared our image-based
hierarchical neural network model with simple image-based CNN architecture and
text-based CNN and LSTM models to highlight its novelty and efficiency.
</p>
<a href="http://arxiv.org/abs/2102.00230" target="_blank">arXiv:2102.00230</a> [<a href="http://arxiv.org/pdf/2102.00230" target="_blank">pdf</a>]

<h2>SA-Net: Shuffle Attention for Deep Convolutional Neural Networks. (arXiv:2102.00240v1 [cs.CV])</h2>
<h3>Qing-Long Zhang Yu-Bin Yang</h3>
<p>Attention mechanisms, which enable a neural network to accurately focus on
all the relevant elements of the input, have become an essential component to
improve the performance of deep neural networks. There are mainly two attention
mechanisms widely used in computer vision studies, \textit{spatial attention}
and \textit{channel attention}, which aim to capture the pixel-level pairwise
relationship and channel dependency, respectively. Although fusing them
together may achieve better performance than their individual implementations,
it will inevitably increase the computational overhead. In this paper, we
propose an efficient Shuffle Attention (SA) module to address this issue, which
adopts Shuffle Units to combine two types of attention mechanisms effectively.
Specifically, SA first groups channel dimensions into multiple sub-features
before processing them in parallel. Then, for each sub-feature, SA utilizes a
Shuffle Unit to depict feature dependencies in both spatial and channel
dimensions. After that, all sub-features are aggregated and a "channel shuffle"
operator is adopted to enable information communication between different
sub-features. The proposed SA module is efficient yet effective, e.g., the
parameters and computations of SA against the backbone ResNet50 are 300 vs.
25.56M and 2.76e-3 GFLOPs vs. 4.12 GFLOPs, respectively, and the performance
boost is more than 1.34% in terms of Top-1 accuracy. Extensive experimental
results on common-used benchmarks, including ImageNet-1k for classification, MS
COCO for object detection, and instance segmentation, demonstrate that the
proposed SA outperforms the current SOTA methods significantly by achieving
higher accuracy while having lower model complexity. The code and models are
available at https://github.com/wofmanaf/SA-Net.
</p>
<a href="http://arxiv.org/abs/2102.00240" target="_blank">arXiv:2102.00240</a> [<a href="http://arxiv.org/pdf/2102.00240" target="_blank">pdf</a>]

<h2>A fast method for simultaneous reconstruction and segmentation in X-ray CT application. (arXiv:2102.00250v1 [cs.CV])</h2>
<h3>Yiqiu Dong, Chunlin Wu, Shi Yan</h3>
<p>In this paper, we propose a fast method for simultaneous reconstruction and
segmentation (SRS) in X-ray computed tomography (CT). Our work is based on the
SRS model where Bayes' rule and the maximum a posteriori (MAP) are used on
hidden Markov measure field model (HMMFM). The original method leads to a
logarithmic-summation (log-sum) term, which is non-separable to the
classification index. The minimization problem in the model was solved by using
constrained gradient descend method, Frank-Wolfe algorithm, which is very
time-consuming especially when dealing with large-scale CT problems. The
starting point of this paper is the commutativity of log-sum operations, where
the log-sum problem could be transformed into a sum-log problem by introducing
an auxiliary variable. The corresponding sum-log problem for the SRS model is
separable. After applying alternating minimization method, this problem turns
into several easy-to-solve convex sub-problems. In the paper, we also study an
improved model by adding Tikhonov regularization, and give some convergence
results. Experimental results demonstrate that the proposed algorithms could
produce comparable results with the original SRS method with much less CPU
time.
</p>
<a href="http://arxiv.org/abs/2102.00250" target="_blank">arXiv:2102.00250</a> [<a href="http://arxiv.org/pdf/2102.00250" target="_blank">pdf</a>]

<h2>Synthetic Dataset Generation of Driver Telematics. (arXiv:2102.00252v1 [stat.ML])</h2>
<h3>Banghee So, Jean-Philippe Boucher, Emiliano A. Valdez</h3>
<p>This article describes techniques employed in the production of a synthetic
dataset of driver telematics emulated from a similar real insurance dataset.
The synthetic dataset generated has 100,000 policies that included observations
about driver's claims experience together with associated classical risk
variables and telematics-related variables. This work is aimed to produce a
resource that can be used to advance models to assess risks for usage-based
insurance. It follows a three-stage process using machine learning algorithms.
The first stage is simulating values for the number of claims as multiple
binary classifications applying feedforward neural networks. The second stage
is simulating values for aggregated amount of claims as regression using
feedforward neural networks, with number of claims included in the set of
feature variables. In the final stage, a synthetic portfolio of the space of
feature variables is generated applying an extended $\texttt{SMOTE}$ algorithm.
The resulting dataset is evaluated by comparing the synthetic and real datasets
when Poisson and gamma regression models are fitted to the respective data.
Other visualization and data summarization produce remarkable similar
statistics between the two datasets. We hope that researchers interested in
obtaining telematics datasets to calibrate models or learning algorithms will
find our work valuable.
</p>
<a href="http://arxiv.org/abs/2102.00252" target="_blank">arXiv:2102.00252</a> [<a href="http://arxiv.org/pdf/2102.00252" target="_blank">pdf</a>]

<h2>Atlas Generative Models and Geodesic Interpolation. (arXiv:2102.00264v1 [cs.LG])</h2>
<h3>Jakob Stolberg-Larsen, Stefan Sommer</h3>
<p>Generative neural networks have a well recognized ability to estimate
underlying manifold structure of high dimensional data. However, if a simply
connected latent space is used, it is not possible to faithfully represent a
manifold with non-trivial homotopy type. In this work we define the general
class of Atlas Generative Models (AGMs), models with hybrid discrete-continuous
latent space that estimate an atlas on the underlying data manifold together
with a partition of unity on the data space. We identify existing examples of
models from various popular generative paradigms that fit into this class. Due
to the atlas interpretation, ideas from non-linear latent space analysis and
statistics, e.g. geodesic interpolation, which has previously only been
investigated for models with simply connected latent spaces, may be extended to
the entire class of AGMs in a natural way. We exemplify this by generalizing an
algorithm for graph based geodesic interpolation to the setting of AGMs, and
verify its performance experimentally.
</p>
<a href="http://arxiv.org/abs/2102.00264" target="_blank">arXiv:2102.00264</a> [<a href="http://arxiv.org/pdf/2102.00264" target="_blank">pdf</a>]

<h2>Hellinger Distance Weighted Ensemble for Imbalanced Data Stream Classification. (arXiv:2102.00266v1 [cs.CV])</h2>
<h3>Joanna Grzyb, Jakub Klikowski, Micha&#x142; Wo&#x17a;niak</h3>
<p>The imbalanced data classification remains a vital problem. The key is to
find such methods that classify both the minority and majority class correctly.
The paper presents the classifier ensemble for classifying binary,
non-stationary and imbalanced data streams where the Hellinger Distance is used
to prune the ensemble. The paper includes an experimental evaluation of the
method based on the conducted experiments. The first one checks the impact of
the base classifier type on the quality of the classification. In the second
experiment, the Hellinger Distance Weighted Ensemble (HDWE) method is compared
to selected state-of-the-art methods using a statistical test with two base
classifiers. The method was profoundly tested based on many imbalanced data
streams and obtained results proved the HDWE method's usefulness.
</p>
<a href="http://arxiv.org/abs/2102.00266" target="_blank">arXiv:2102.00266</a> [<a href="http://arxiv.org/pdf/2102.00266" target="_blank">pdf</a>]

<h2>Inertial Proximal Deep Learning Alternating Minimization for Efficient Neutral Network Training. (arXiv:2102.00267v1 [cs.LG])</h2>
<h3>Linbo Qiao, Tao Sun, Hengyue Pan, Dongsheng Li</h3>
<p>In recent years, the Deep Learning Alternating Minimization (DLAM), which is
actually the alternating minimization applied to the penalty form of the deep
neutral networks training, has been developed as an alternative algorithm to
overcome several drawbacks of Stochastic Gradient Descent (SGD) algorithms.
This work develops an improved DLAM by the well-known inertial technique,
namely iPDLAM, which predicts a point by linearization of current and last
iterates. To obtain further training speed, we apply a warm-up technique to the
penalty parameter, that is, starting with a small initial one and increasing it
in the iterations. Numerical results on real-world datasets are reported to
demonstrate the efficiency of our proposed algorithm.
</p>
<a href="http://arxiv.org/abs/2102.00267" target="_blank">arXiv:2102.00267</a> [<a href="http://arxiv.org/pdf/2102.00267" target="_blank">pdf</a>]

<h2>EmpathBERT: A BERT-based Framework for Demographic-aware Empathy Prediction. (arXiv:2102.00272v1 [cs.LG])</h2>
<h3>Bhanu Prakash Reddy Guda, Aparna Garimella, Niyati Chhaya</h3>
<p>Affect preferences vary with user demographics, and tapping into demographic
information provides important cues about the users' language preferences. In
this paper, we utilize the user demographics, and propose EmpathBERT, a
demographic-aware framework for empathy prediction based on BERT. Through
several comparative experiments, we show that EmpathBERT surpasses traditional
machine learning and deep learning models, and illustrate the importance of
user demographics to predict empathy and distress in user responses to
stimulative news articles. We also highlight the importance of affect
information in the responses by developing affect-aware models to predict user
demographic attributes.
</p>
<a href="http://arxiv.org/abs/2102.00272" target="_blank">arXiv:2102.00272</a> [<a href="http://arxiv.org/pdf/2102.00272" target="_blank">pdf</a>]

<h2>Deep Learning--Based Scene Simplification for Bionic Vision. (arXiv:2102.00297v1 [cs.CV])</h2>
<h3>Nicole Han (1), Sudhanshu Srivastava (1), Aiwen Xu (1), Devi Klein (1), Michael Beyeler (1) ((1) University of California, Santa Barbara)</h3>
<p>Retinal degenerative diseases cause profound visual impairment in more than
10 million people worldwide, and retinal prostheses are being developed to
restore vision to these individuals. Analogous to cochlear implants, these
devices electrically stimulate surviving retinal cells to evoke visual percepts
(phosphenes). However, the quality of current prosthetic vision is still
rudimentary. Rather than aiming to restore "natural" vision, there is potential
merit in borrowing state-of-the-art computer vision algorithms as image
processing techniques to maximize the usefulness of prosthetic vision. Here we
combine deep learning--based scene simplification strategies with a
psychophysically validated computational model of the retina to generate
realistic predictions of simulated prosthetic vision, and measure their ability
to support scene understanding of sighted subjects (virtual patients) in a
variety of outdoor scenarios. We show that object segmentation may better
support scene understanding than models based on visual saliency and monocular
depth estimation. In addition, we highlight the importance of basing
theoretical predictions on biologically realistic models of phosphene shape.
Overall, this work has the potential to drastically improve the utility of
prosthetic vision for people blinded from retinal degenerative diseases.
</p>
<a href="http://arxiv.org/abs/2102.00297" target="_blank">arXiv:2102.00297</a> [<a href="http://arxiv.org/pdf/2102.00297" target="_blank">pdf</a>]

<h2>Fairness through Optimization. (arXiv:2102.00311v1 [cs.AI])</h2>
<h3>Violet (Xinying) Chen, J.N. Hooker</h3>
<p>We propose optimization as a general paradigm for formalizing fairness in
AI-based decision models. We argue that optimization models allow formulation
of a wide range of fairness criteria as social welfare functions, while
enabling AI to take advantage of highly advanced solution technology. We show
how optimization models can assist fairness-oriented decision making in the
context of neural networks, support vector machines, and rule-based systems by
maximizing a social welfare function subject to appropriate constraints. In
particular, we state tractable optimization models for a variety of functions
that measure fairness or a combination of fairness and efficiency. These
include several inequality metrics, Rawlsian criteria, the McLoone and Hoover
indices, alpha fairness, the Nash and Kalai-Smorodinsky bargaining solutions,
combinations of Rawlsian and utilitarian criteria, and statistical bias
measures. All of these models can be efficiently solved by linear programming,
mixed integer/linear programming, or (in two cases) specialized convex
programming methods.
</p>
<a href="http://arxiv.org/abs/2102.00311" target="_blank">arXiv:2102.00311</a> [<a href="http://arxiv.org/pdf/2102.00311" target="_blank">pdf</a>]

<h2>Size and Depth Separation in Approximating Natural Functions with Neural Networks. (arXiv:2102.00314v1 [cs.LG])</h2>
<h3>Gal Vardi, Daniel Reichman, Toniann Pitassi, Ohad Shamir</h3>
<p>When studying the expressive power of neural networks, a main challenge is to
understand how the size and depth of the network affect its ability to
approximate real functions. However, not all functions are interesting from a
practical viewpoint: functions of interest usually have a polynomially-bounded
Lipschitz constant, and can be computed efficiently. We call functions that
satisfy these conditions "natural", and explore the benefits of size and depth
for approximation of natural functions with ReLU networks. As we show, this
problem is more challenging than the corresponding problem for non-natural
functions. We give barriers to showing depth-lower-bounds: Proving existence of
a natural function that cannot be approximated by polynomial-size networks of
depth $4$ would settle longstanding open problems in computational complexity.
It implies that beyond depth $4$ there is a barrier to showing depth-separation
for natural functions, even between networks of constant depth and networks of
nonconstant depth. We also study size-separation, namely, whether there are
natural functions that can be approximated with networks of size $O(s(d))$, but
not with networks of size $O(s'(d))$. We show a complexity-theoretic barrier to
proving such results beyond size $O(d\log^2(d))$, but also show an explicit
natural function, that can be approximated with networks of size $O(d)$ and not
with networks of size $o(d/\log d)$. For approximation in $L_\infty$ we achieve
such separation already between size $O(d)$ and size $o(d)$. Moreover, we show
superpolynomial size lower bounds and barriers to such lower bounds, depending
on the assumptions on the function. Our size-separation results rely on an
analysis of size lower bounds for Boolean functions, which is of independent
interest: We show linear size lower bounds for computing explicit Boolean
functions with neural networks and threshold circuits.
</p>
<a href="http://arxiv.org/abs/2102.00314" target="_blank">arXiv:2102.00314</a> [<a href="http://arxiv.org/pdf/2102.00314" target="_blank">pdf</a>]

<h2>Metalearning: Sparse Variable-Structure Automata. (arXiv:2102.00315v1 [cs.LG])</h2>
<h3>Pedram Fekri, Ali Akbar Safavi, Mehrdad Hosseini Zadeh, Peyman Setoodeh</h3>
<p>Dimension of the encoder output (i.e., the code layer) in an autoencoder is a
key hyper-parameter for representing the input data in a proper space. This
dimension must be carefully selected in order to guarantee the desired
reconstruction accuracy. Although overcomplete representation can address this
dimension issue, the computational complexity will increase with dimension.
Inspired by non-parametric methods, here, we propose a metalearning approach to
increase the number of basis vectors used in dynamic sparse coding on the fly.
An actor-critic algorithm is deployed to automatically choose an appropriate
dimension for feature vectors regarding the required level of accuracy. The
proposed method benefits from online dictionary learning and fast iterative
shrinkage-thresholding algorithm (FISTA) as the optimizer in the inference
phase. It aims at choosing the minimum number of bases for the overcomplete
representation regarding the reconstruction error threshold. This method allows
for online controlling of both the representation dimension and the
reconstruction error in a dynamic framework.
</p>
<a href="http://arxiv.org/abs/2102.00315" target="_blank">arXiv:2102.00315</a> [<a href="http://arxiv.org/pdf/2102.00315" target="_blank">pdf</a>]

<h2>Recurrent Submodular Welfare and Matroid Blocking Bandits. (arXiv:2102.00321v1 [cs.LG])</h2>
<h3>Orestis Papadigenopoulos, Constantine Caramanis</h3>
<p>A recent line of research focuses on the study of the stochastic multi-armed
bandits problem (MAB), in the case where temporal correlations of specific
structure are imposed between the player's actions and the reward distributions
of the arms (Kleinberg and Immorlica [FOCS18], Basu et al. [NIPS19]). As
opposed to the standard MAB setting, where the optimal solution in hindsight
can be trivially characterized, these correlations lead to (sub-)optimal
solutions that exhibit interesting dynamical patterns -- a phenomenon that
yields new challenges both from an algorithmic as well as a learning
perspective. In this work, we extend the above direction to a combinatorial
bandit setting and study a variant of stochastic MAB, where arms are subject to
matroid constraints and each arm becomes unavailable (blocked) for a fixed
number of rounds after each play. A natural common generalization of the
state-of-the-art for blocking bandits, and that for matroid bandits, yields a
$(1-\frac{1}{e})$-approximation for partition matroids, yet it only guarantees
a $\frac{1}{2}$-approximation for general matroids. In this paper we develop
new algorithmic ideas that allow us to obtain a polynomial-time $(1 -
\frac{1}{e})$-approximation algorithm (asymptotically and in expectation) for
any matroid, and thus allow us to control the $(1-\frac{1}{e})$-approximate
regret. A key ingredient is the technique of correlated (interleaved)
scheduling. Along the way, we discover an interesting connection to a variant
of Submodular Welfare Maximization, for which we provide (asymptotically)
matching upper and lower approximability bounds.
</p>
<a href="http://arxiv.org/abs/2102.00321" target="_blank">arXiv:2102.00321</a> [<a href="http://arxiv.org/pdf/2102.00321" target="_blank">pdf</a>]

<h2>A Supervised Learning Approach for Robust Health Monitoring using Face Videos. (arXiv:2102.00322v1 [cs.CV])</h2>
<h3>Mayank Gupta, Lingjun Chen, Denny Yu, Vaneet Aggarwal</h3>
<p>Monitoring of cardiovascular activity is highly desired and can enable novel
applications in diagnosing potential cardiovascular diseases and maintaining an
individual's well-being. Currently, such vital signs are measured using
intrusive contact devices such as an electrocardiogram (ECG), chest straps, and
pulse oximeters that require the patient or the health provider to manually
implement. Non-contact, device-free human sensing methods can eliminate the
need for specialized heart and blood pressure monitoring equipment. Non-contact
methods can have additional advantages since they are scalable with any
environment where video can be captured, can be used for continuous
measurements, and can be used on patients with varying levels of dexterity and
independence, from people with physical impairments to infants (e.g., baby
camera). In this paper, we used a non-contact method that only requires face
videos recorded using commercially-available webcams. These videos were
exploited to predict the health attributes like pulse rate and variance in
pulse rate. The proposed approach used facial recognition to detect the face in
each frame of the video using facial landmarks, followed by supervised learning
using deep neural networks to train the machine learning model. The videos
captured subjects performing different physical activities that result in
varying cardiovascular responses. The proposed method did not require training
data from every individual and thus the prediction can be obtained for the new
individuals for which there is no prior data; critical in approach
generalization. The approach was also evaluated on a dataset of people with
different ethnicity. The proposed approach had less than a 4.6\% error in
predicting the pulse rate.
</p>
<a href="http://arxiv.org/abs/2102.00322" target="_blank">arXiv:2102.00322</a> [<a href="http://arxiv.org/pdf/2102.00322" target="_blank">pdf</a>]

<h2>Video Reenactment as Inductive Bias for Content-Motion Disentanglement. (arXiv:2102.00324v1 [cs.CV])</h2>
<h3>Juan F. Hern&#xe1;ndez Albarrac&#xed;n, Ad&#xed;n Ram&#xed;rez Rivera</h3>
<p>We introduce a self-supervised motion-transfer VAE model to disentangle
motion and content from video. Unlike previous work regarding content-motion
disentanglement in videos, we adopt a chunk-wise modeling approach and take
advantage of the motion information contained in spatiotemporal neighborhoods.
Our model yields per-chunk representations that can be modeled independently
and preserve temporal consistency. Hence, we reconstruct whole videos in a
single forward-pass. We extend the ELBO's log-likelihood term and include a
Blind Reenactment Loss as inductive bias to leverage motion disentanglement,
under the assumption that swapping motion features yields reenactment between
two videos. We test our model on recently-proposed disentanglement metrics, and
show that it outperforms a variety of methods for video motion-content
disentanglement. Experiments on video reenactment show the effectiveness of our
disentanglement in the input space where our model outperforms the baselines in
reconstruction quality and motion alignment.
</p>
<a href="http://arxiv.org/abs/2102.00324" target="_blank">arXiv:2102.00324</a> [<a href="http://arxiv.org/pdf/2102.00324" target="_blank">pdf</a>]

<h2>Learning Interaction Kernels for Agent Systems on Riemannian Manifolds. (arXiv:2102.00327v1 [cs.LG])</h2>
<h3>Mauro Maggioni, Jason Miller, Hongda Qui, Ming Zhong</h3>
<p>Interacting agent and particle systems are extensively used to model complex
phenomena in science and engineering. We consider the problem of learning
interaction kernels in these dynamical systems constrained to evolve on
Riemannian manifolds from given trajectory data. Our approach generalizes the
theory and algorithms in [1] introduced in the Euclidean setting. The models we
consider are based on interaction kernels depending on pairwise Riemannian
distances between agents, with agents interacting locally along the direction
of the shortest geodesic connecting them. We show that our estimators converge
at a rate that is independent of the dimension of the manifold, and derive
bounds on the trajectory estimation error, on the manifold, between the
observed and estimated dynamics. We demonstrate highly accurate performance of
the learning algorithm on three classical first order interacting systems,
Opinion Dynamics, Lennard-Jones Dynamics, and a Predator-Swarm system, with
each system constrained on two prototypical manifolds, the $2$-dimensional
sphere and the Poincar\'e disk model of hyperbolic space.

[1] F. Lu, M. Zhong, S. Tang, M. Maggioni, Nonparametric Inference of
Interaction Laws in Systems of Agents from Trajectory Data, PNAS, 116 (2019),
pp. 14424 - 14433.
</p>
<a href="http://arxiv.org/abs/2102.00327" target="_blank">arXiv:2102.00327</a> [<a href="http://arxiv.org/pdf/2102.00327" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning-Based Product Recommender for Online Advertising. (arXiv:2102.00333v1 [cs.AI])</h2>
<h3>Milad Vaali Esfahaani, Yanbo Xue, Peyman Setoodeh</h3>
<p>In online advertising, recommender systems try to propose items from a list
of products to potential customers according to their interests. Such systems
have been increasingly deployed in E-commerce due to the rapid growth of
information technology and availability of large datasets. The ever-increasing
progress in the field of artificial intelligence has provided powerful tools
for dealing with such real-life problems. Deep reinforcement learning (RL) that
deploys deep neural networks as universal function approximators can be viewed
as a valid approach for design and implementation of recommender systems. This
paper provides a comparative study between value-based and policy-based deep RL
algorithms for designing recommender systems for online advertising. The
RecoGym environment is adopted for training these RL-based recommender systems,
where the long short term memory (LSTM) is deployed to build value and policy
networks in these two approaches, respectively. LSTM is used to take account of
the key role that order plays in the sequence of item observations by users.
The designed recommender systems aim at maximising the click-through rate (CTR)
for the recommended items. Finally, guidelines are provided for choosing proper
RL algorithms for different scenarios that the recommender system is expected
to handle.
</p>
<a href="http://arxiv.org/abs/2102.00333" target="_blank">arXiv:2102.00333</a> [<a href="http://arxiv.org/pdf/2102.00333" target="_blank">pdf</a>]

<h2>Enacted Visual Perception: A Computational Model based on Piaget Equilibrium. (arXiv:2102.00339v1 [cs.AI])</h2>
<h3>Aref Hakimzadeh, Yanbo Xue, Peyman Setoodeh</h3>
<p>In Maurice Merleau-Ponty's phenomenology of perception, analysis of
perception accounts for an element of intentionality, and in effect therefore,
perception and action cannot be viewed as distinct procedures. In the same line
of thinking, Alva No\"{e} considers perception as a thoughtful activity that
relies on capacities for action and thought. Here, by looking into psychology
as a source of inspiration, we propose a computational model for the action
involved in visual perception based on the notion of equilibrium as defined by
Jean Piaget. In such a model, Piaget's equilibrium reflects the mind's status,
which is used to control the observation process. The proposed model is built
around a modified version of convolutional neural networks (CNNs) with enhanced
filter performance, where characteristics of filters are adaptively adjusted
via a high-level control signal that accounts for the thoughtful activity in
perception. While the CNN plays the role of the visual system, the control
signal is assumed to be a product of mind.
</p>
<a href="http://arxiv.org/abs/2102.00339" target="_blank">arXiv:2102.00339</a> [<a href="http://arxiv.org/pdf/2102.00339" target="_blank">pdf</a>]

<h2>OAS-Net: Occlusion Aware Sampling Network for Accurate Optical Flow. (arXiv:2102.00364v1 [cs.CV])</h2>
<h3>Lingtong Kong, Xiaohang Yang, Jie Yang</h3>
<p>Optical flow estimation is an essential step for many real-world computer
vision tasks. Existing deep networks have achieved satisfactory results by
mostly employing a pyramidal coarse-to-fine paradigm, where a key process is to
adopt warped target feature based on previous flow prediction to correlate with
source feature for building 3D matching cost volume. However, the warping
operation can lead to troublesome ghosting problem that results in ambiguity.
Moreover, occluded areas are treated equally with non occluded regions in most
existing works, which may cause performance degradation. To deal with these
challenges, we propose a lightweight yet efficient optical flow network, named
OAS-Net (occlusion aware sampling network) for accurate optical flow. First, a
new sampling based correlation layer is employed without noisy warping
operation. Second, a novel occlusion aware module is presented to make raw cost
volume conscious of occluded regions. Third, a shared flow and occlusion
awareness decoder is adopted for structure compactness. Experiments on Sintel
and KITTI datasets demonstrate the effectiveness of proposed approaches.
</p>
<a href="http://arxiv.org/abs/2102.00364" target="_blank">arXiv:2102.00364</a> [<a href="http://arxiv.org/pdf/2102.00364" target="_blank">pdf</a>]

<h2>Fine-Grained Visual Classification via Simultaneously Learning of Multi-regional Multi-grained Features. (arXiv:2102.00367v1 [cs.CV])</h2>
<h3>Dongliang Chang, Yixiao Zheng, Zhanyu Ma, Ruoyi Du, Kongming Liang</h3>
<p>Fine-grained visual classification is a challenging task that recognizes the
sub-classes belonging to the same meta-class. Large inter-class similarity and
intra-class variance is the main challenge of this task. Most exiting methods
try to solve this problem by designing complex model structures to explore more
minute and discriminative regions. In this paper, we argue that mining
multi-regional multi-grained features is precisely the key to this task.
Specifically, we introduce a new loss function, termed top-down spatial
attention loss (TDSA-Loss), which contains a multi-stage channel constrained
module and a top-down spatial attention module. The multi-stage channel
constrained module aims to make the feature channels in different stages
category-aligned. Meanwhile, the top-down spatial attention module uses the
attention map generated by high-level aligned feature channels to make
middle-level aligned feature channels to focus on particular regions. Finally,
we can obtain multiple discriminative regions on high-level feature channels
and obtain multiple more minute regions within these discriminative regions on
middle-level feature channels. In summary, we obtain multi-regional
multi-grained features. Experimental results over four widely used fine-grained
image classification datasets demonstrate the effectiveness of the proposed
method. Ablative studies further show the superiority of two modules in the
proposed method. Codes are available at:
https://github.com/dongliangchang/Top-Down-Spatial-Attention-Loss.
</p>
<a href="http://arxiv.org/abs/2102.00367" target="_blank">arXiv:2102.00367</a> [<a href="http://arxiv.org/pdf/2102.00367" target="_blank">pdf</a>]

<h2>Spectral Roll-off Points: Estimating Useful Information Under the Basis of Low-frequency Data Representations. (arXiv:2102.00369v1 [cs.CV])</h2>
<h3>Yunkai Yu, Zhihong Yang, Yuyang You, Guozheng Liu, Peiyao Li, Zhicheng Yang, Wenjing Shan</h3>
<p>Useful information is the basis for model decisions. Estimating useful
information in feature maps promotes the understanding of the mechanisms of
neural networks. Low frequency is a prerequisite for useful information in data
representations, because downscaling operations reduce the communication
bandwidth. This study proposes the use of spectral roll-off points (SROPs) to
integrate the low-frequency condition when estimating useful information. The
computation of an SROP is extended from a 1-D signal to a 2-D image by the
required rotation invariance in image classification tasks. SROP statistics
across feature maps are implemented for layer-wise useful information
estimation. Sanity checks demonstrate that the variation of layer-wise SROP
distributions among model input can be used to recognize useful components that
support model decisions. Moreover, the variations of SROPs and accuracy, the
ground truth of useful information of models, are synchronous when adopting
sufficient training in various model structures. Therefore, SROP is an accurate
and convenient estimation of useful information. It promotes the explainability
of artificial intelligence with respect to frequency-domain knowledge.
</p>
<a href="http://arxiv.org/abs/2102.00369" target="_blank">arXiv:2102.00369</a> [<a href="http://arxiv.org/pdf/2102.00369" target="_blank">pdf</a>]

<h2>MLMA-Net: multi-level multi-attentional learning for multi-label object detection in textile defect images. (arXiv:2102.00376v1 [cs.CV])</h2>
<h3>Bing Wei (Student Member, IEEE), Kuangrong Hao (Member, IEEE), Lei Gao (Member, IEEE)</h3>
<p>For the sake of recognizing and classifying textile defects, deep
learning-based methods have been proposed and achieved remarkable success in
single-label textile images. However, detecting multi-label defects in a
textile image remains challenging due to the coexistence of multiple defects
and small-size defects. To address these challenges, a multi-level,
multi-attentional deep learning network (MLMA-Net) is proposed and built to 1)
increase the feature representation ability to detect small-size defects; 2)
generate a discriminative representation that maximizes the capability of
attending the defect status, which leverages higher-resolution feature maps for
multiple defects. Moreover, a multi-label object detection dataset (DHU-ML1000)
in textile defect images is built to verify the performance of the proposed
model. The results demonstrate that the network extracts more distinctive
features and has better performance than the state-of-the-art approaches on the
real-world industrial dataset.
</p>
<a href="http://arxiv.org/abs/2102.00376" target="_blank">arXiv:2102.00376</a> [<a href="http://arxiv.org/pdf/2102.00376" target="_blank">pdf</a>]

<h2>Classification Models for Partially Ordered Sequences. (arXiv:2102.00380v1 [cs.LG])</h2>
<h3>Stephanie Ger, Diego Klabjan, Jean Utke</h3>
<p>Many models such as Long Short Term Memory (LSTMs), Gated Recurrent Units
(GRUs) and transformers have been developed to classify time series data with
the assumption that events in a sequence are ordered. On the other hand, fewer
models have been developed for set based inputs, where order does not matter.
There are several use cases where data is given as partially-ordered sequences
because of the granularity or uncertainty of time stamps. We introduce a novel
transformer based model for such prediction tasks, and benchmark against
extensions of existing order invariant models. We also discuss how transition
probabilities between events in a sequence can be used to improve model
performance. We show that the transformer-based equal-time model outperforms
extensions of existing set models on three data sets.
</p>
<a href="http://arxiv.org/abs/2102.00380" target="_blank">arXiv:2102.00380</a> [<a href="http://arxiv.org/pdf/2102.00380" target="_blank">pdf</a>]

<h2>A Unified Light Framework for Real-time Fault Detection of Freight Train Images. (arXiv:2102.00381v1 [cs.CV])</h2>
<h3>Yang Zhang, Moyun Liu, Yang Yang, Yanwen Guo, Huiming Zhang</h3>
<p>Real-time fault detection for freight trains plays a vital role in
guaranteeing the security and optimal operation of railway transportation under
stringent resource requirements. Despite the promising results for deep
learning based approaches, the performance of these fault detectors on freight
train images, are far from satisfactory in both accuracy and efficiency. This
paper proposes a unified light framework to improve detection accuracy while
supporting a real-time operation with a low resource requirement. We firstly
design a novel lightweight backbone (RFDNet) to improve the accuracy and reduce
computational cost. Then, we propose a multi region proposal network using
multi-scale feature maps generated from RFDNet to improve the detection
performance. Finally, we present multi level position-sensitive score maps and
region of interest pooling to further improve accuracy with few redundant
computations. Extensive experimental results on public benchmark datasets
suggest that our RFDNet can significantly improve the performance of baseline
network with higher accuracy and efficiency. Experiments on six fault datasets
show that our method is capable of real-time detection at over 38 frames per
second and achieves competitive accuracy and lower computation than the
state-of-the-art detectors.
</p>
<a href="http://arxiv.org/abs/2102.00381" target="_blank">arXiv:2102.00381</a> [<a href="http://arxiv.org/pdf/2102.00381" target="_blank">pdf</a>]

<h2>Beyond the Signs: Nonparametric Tensor Completion via Sign Series. (arXiv:2102.00384v1 [stat.ML])</h2>
<h3>Chanwoo Lee, Miaoyan Wang</h3>
<p>We consider the problem of tensor estimation from noisy observations with
possibly missing entries. A nonparametric approach to tensor completion is
developed based on a new model which we coin as sign representable tensors. The
model represents the signal tensor of interest using a series of structured
sign tensors. Unlike earlier methods, the sign series representation
effectively addresses both low- and high-rank signals, while encompassing many
existing tensor models -- including CP models, Tucker models, single index
models, several hypergraphon models -- as special cases. We show that the sign
tensor series is theoretically characterized, and computationally estimable,
via classification tasks with carefully-specified weights. Excess risk bounds,
estimation error rates, and sample complexities are established. We demonstrate
the outperformance of our approach over previous methods on two datasets, one
on human brain connectivity networks and the other on topic data mining.
</p>
<a href="http://arxiv.org/abs/2102.00384" target="_blank">arXiv:2102.00384</a> [<a href="http://arxiv.org/pdf/2102.00384" target="_blank">pdf</a>]

<h2>AACP: Model Compression by Accurate and Automatic Channel Pruning. (arXiv:2102.00390v1 [cs.CV])</h2>
<h3>Lanbo Lin, Yujiu Yang, Zhenhua Guo</h3>
<p>Channel pruning is formulated as a neural architecture search (NAS) problem
recently. However, existing NAS-based methods are challenged by huge
computational cost and inflexibility of applications. How to deal with multiple
sparsity constraints simultaneously and speed up NAS-based channel pruning are
still open challenges. In this paper, we propose a novel Accurate and Automatic
Channel Pruning (AACP) method to address these problems. Firstly, AACP
represents the structure of a model as a structure vector and introduces a
pruning step vector to control the compressing granularity of each layer.
Secondly, AACP utilizes Pruned Structure Accuracy Estimator (PSAE) to speed up
the performance estimation process. Thirdly, AACP proposes Improved
Differential Evolution (IDE) algorithm to search the optimal structure vector
effectively. Because of IDE, AACP can deal with FLOPs constraint and model size
constraint simultaneously and efficiently. Our method can be easily applied to
various tasks and achieve state of the art performance. On CIFAR10, our method
reduces $65\%$ FLOPs of ResNet110 with an improvement of $0.26\%$ top-1
accuracy. On ImageNet, we reduce $42\%$ FLOPs of ResNet50 with a small loss of
$0.18\%$ top-1 accuracy and reduce $30\%$ FLOPs of MobileNetV2 with a small
loss of $0.7\%$ top-1 accuracy. The source code will be released after
publication.
</p>
<a href="http://arxiv.org/abs/2102.00390" target="_blank">arXiv:2102.00390</a> [<a href="http://arxiv.org/pdf/2102.00390" target="_blank">pdf</a>]

<h2>The distance between the weights of the neural network is meaningful. (arXiv:2102.00396v1 [cs.AI])</h2>
<h3>Liqun Yang, Yijun Yang, Yao Wang, Zhenyu Yang, Wei Zeng</h3>
<p>In the application of neural networks, we need to select a suitable model
based on the problem complexity and the dataset scale. To analyze the network's
capacity, quantifying the information learned by the network is necessary. This
paper proves that the distance between the neural network weights in different
training stages can be used to estimate the information accumulated by the
network in the training process directly. The experiment results verify the
utility of this method. An application of this method related to the label
corruption is shown at the end.
</p>
<a href="http://arxiv.org/abs/2102.00396" target="_blank">arXiv:2102.00396</a> [<a href="http://arxiv.org/pdf/2102.00396" target="_blank">pdf</a>]

<h2>Learning Interpretable Deep State Space Model for Probabilistic Time Series Forecasting. (arXiv:2102.00397v1 [cs.LG])</h2>
<h3>Longyuan Li, Junchi Yan, Xiaokang Yang, Yaohui Jin</h3>
<p>Probabilistic time series forecasting involves estimating the distribution of
future based on its history, which is essential for risk management in
downstream decision-making. We propose a deep state space model for
probabilistic time series forecasting whereby the non-linear emission model and
transition model are parameterized by networks and the dependency is modeled by
recurrent neural nets. We take the automatic relevance determination (ARD) view
and devise a network to exploit the exogenous variables in addition to time
series. In particular, our ARD network can incorporate the uncertainty of the
exogenous variables and eventually helps identify useful exogenous variables
and suppress those irrelevant for forecasting. The distribution of multi-step
ahead forecasts are approximated by Monte Carlo simulation. We show in
experiments that our model produces accurate and sharp probabilistic forecasts.
The estimated uncertainty of our forecasting also realistically increases over
time, in a spontaneous manner.
</p>
<a href="http://arxiv.org/abs/2102.00397" target="_blank">arXiv:2102.00397</a> [<a href="http://arxiv.org/pdf/2102.00397" target="_blank">pdf</a>]

<h2>Tone Mapping Based on Multi-scale Histogram Synthesis. (arXiv:2102.00408v1 [cs.CV])</h2>
<h3>Jie Yang, Ziyi Liu, Ulian Shahnovich, Orly Yadid-Pecht</h3>
<p>In this paper, we present a novel tone mapping algorithm that can be used for
displaying wide dynamic range (WDR) images on low dynamic range (LDR) devices.
The proposed algorithm is mainly motivated by the logarithmic response and
local adaptation features of the human visual system (HVS). HVS perceives
luminance differently when under different adaptation levels, and therefore our
algorithm uses functions built upon different scales to tone map pixels to
different values. Functions of large scales are used to maintain image
brightness consistency and functions of small scales are used to preserve local
detail and contrast. An efficient method using local variance has been proposed
to fuse the values of different scales and to remove artifacts. The algorithm
utilizes integral images and integral histograms to reduce computation
complexity and processing time. Experimental results show that the proposed
algorithm can generate high brightness, good contrast, and appealing images
that surpass the performance of many state-of-the-art tone mapping algorithms.
This project is available at
https://github.com/jieyang1987/ToneMapping-Based-on-Multi-scale-Histogram-Synthesis.
</p>
<a href="http://arxiv.org/abs/2102.00408" target="_blank">arXiv:2102.00408</a> [<a href="http://arxiv.org/pdf/2102.00408" target="_blank">pdf</a>]

<h2>Cascade Network with Guided Loss and Hybrid Attention for Finding Good Correspondences. (arXiv:2102.00411v1 [cs.CV])</h2>
<h3>Zhi Chen, Fan Yang, Wenbing Tao</h3>
<p>Finding good correspondences is a critical prerequisite in many feature based
tasks. Given a putative correspondence set of an image pair, we propose a
neural network which finds correct correspondences by a binary-class classifier
and estimates relative pose through classified correspondences. First, we
analyze that due to the imbalance in the number of correct and wrong
correspondences, the loss function has a great impact on the classification
results. Thus, we propose a new Guided Loss that can directly use evaluation
criterion (Fn-measure) as guidance to dynamically adjust the objective function
during training. We theoretically prove that the perfect negative correlation
between the Guided Loss and Fn-measure, so that the network is always trained
towards the direction of increasing Fn-measure to maximize it. We then propose
a hybrid attention block to extract feature, which integrates the Bayesian
attentive context normalization (BACN) and channel-wise attention (CA). BACN
can mine the prior information to better exploit global context and CA can
capture complex channel context to enhance the channel awareness of the
network. Finally, based on our Guided Loss and hybrid attention block, a
cascade network is designed to gradually optimize the result for more superior
performance. Experiments have shown that our network achieves the
state-of-the-art performance on benchmark datasets. Our code will be available
in https://github.com/wenbingtao/GLHA.
</p>
<a href="http://arxiv.org/abs/2102.00411" target="_blank">arXiv:2102.00411</a> [<a href="http://arxiv.org/pdf/2102.00411" target="_blank">pdf</a>]

<h2>Priority-based Post-Processing Bias Mitigation for Individual and Group Fairness. (arXiv:2102.00417v1 [cs.AI])</h2>
<h3>Pranay Lohia</h3>
<p>Previous post-processing bias mitigation algorithms on both group and
individual fairness don't work on regression models and datasets with
multi-class numerical labels. We propose a priority-based post-processing bias
mitigation on both group and individual fairness with the notion that similar
individuals should get similar outcomes irrespective of socio-economic factors
and more the unfairness, more the injustice. We establish this proposition by a
case study on tariff allotment in a smart grid. Our novel framework establishes
it by using a user segmentation algorithm to capture the consumption strategy
better. This process ensures priority-based fair pricing for group and
individual facing the maximum injustice. It upholds the notion of fair tariff
allotment to the entire population taken into consideration without modifying
the in-built process for tariff calculation. We also validate our method and
show superior performance to previous work on a real-world dataset in criminal
sentencing.
</p>
<a href="http://arxiv.org/abs/2102.00417" target="_blank">arXiv:2102.00417</a> [<a href="http://arxiv.org/pdf/2102.00417" target="_blank">pdf</a>]

<h2>Graph Neural Networks to Predict Customer Satisfaction Following Interactions with a Corporate Call Center. (arXiv:2102.00420v1 [cs.LG])</h2>
<h3>Teja Kanchinadam, Zihang Meng, Joseph Bockhorst, Vikas Singh Kim, Glenn Fung</h3>
<p>Customer satisfaction is an important factor in creating and maintaining
long-term relationships with customers. Near real-time identification of
potentially dissatisfied customers following phone calls can provide
organizations the opportunity to take meaningful interventions and to foster
ongoing customer satisfaction and loyalty. This work describes a fully
operational system we have developed at a large US company for predicting
customer satisfaction following incoming phone calls. The system takes as an
input speech-to-text transcriptions of calls and predicts call satisfaction
reported by customers on post-call surveys (scale from 1 to 10). Because of its
ordinal, subjective, and often highly-skewed nature, predicting survey scores
is not a trivial task and presents several modeling challenges. We introduce a
graph neural network (GNN) approach that takes into account the comparative
nature of the problem by considering the relative scores among batches, instead
of only pairs of calls when training. This approach produces more accurate
predictions than previous approaches including standard regression and
classification models that directly fit the survey scores with call data. Our
proposed approach can be easily generalized to other customer satisfaction
prediction problems.
</p>
<a href="http://arxiv.org/abs/2102.00420" target="_blank">arXiv:2102.00420</a> [<a href="http://arxiv.org/pdf/2102.00420" target="_blank">pdf</a>]

<h2>A Simple yet Brisk and Efficient Active Learning Platform for Text Classification. (arXiv:2102.00426v1 [cs.LG])</h2>
<h3>Teja Kanchinadam, Qian You, Keith Westpfahl, James Kim, Siva Gunda, Sebastian Seith, Glenn Fung</h3>
<p>In this work, we propose the use of a fully managed machine learning service,
which utilizes active learning to directly build models from unstructured data.
With this tool, business users can quickly and easily build machine learning
models and then directly deploy them into a production ready hosted environment
without much involvement from data scientists. Our approach leverages
state-of-the-art text representation like OpenAI's GPT2 and a fast
implementation of the active learning workflow that relies on a simple
construction of incremental learning using linear models, thus providing a
brisk and efficient labeling experience for the users. Experiments on both
publicly available and real-life insurance datasets empirically show why our
choices of simple and fast classification algorithms are ideal for the task at
hand.
</p>
<a href="http://arxiv.org/abs/2102.00426" target="_blank">arXiv:2102.00426</a> [<a href="http://arxiv.org/pdf/2102.00426" target="_blank">pdf</a>]

<h2>PyTorch-Hebbian: facilitating local learning in a deep learning framework. (arXiv:2102.00428v1 [cs.LG])</h2>
<h3>Jules Talloen, Joni Dambre, Alexander Vandesompele</h3>
<p>Recently, unsupervised local learning, based on Hebb's idea that change in
synaptic efficacy depends on the activity of the pre- and postsynaptic neuron
only, has shown potential as an alternative training mechanism to
backpropagation. Unfortunately, Hebbian learning remains experimental and
rarely makes it way into standard deep learning frameworks. In this work, we
investigate the potential of Hebbian learning in the context of standard deep
learning workflows. To this end, a framework for thorough and systematic
evaluation of local learning rules in existing deep learning pipelines is
proposed. Using this framework, the potential of Hebbian learned feature
extractors for image classification is illustrated. In particular, the
framework is used to expand the Krotov-Hopfield learning rule to standard
convolutional neural networks without sacrificing accuracy compared to
end-to-end backpropagation. The source code is available at
https://github.com/Joxis/pytorch-hebbian.
</p>
<a href="http://arxiv.org/abs/2102.00428" target="_blank">arXiv:2102.00428</a> [<a href="http://arxiv.org/pdf/2102.00428" target="_blank">pdf</a>]

<h2>Synergetic Learning of Heterogeneous Temporal Sequences for Multi-Horizon Probabilistic Forecasting. (arXiv:2102.00431v1 [cs.LG])</h2>
<h3>Longyuan Li, Jihai Zhang, Junchi Yan, Yaohui Jin, Yunhao Zhang, Yanjie Duan, Guangjian Tian</h3>
<p>Time-series is ubiquitous across applications, such as transportation,
finance and healthcare. Time-series is often influenced by external factors,
especially in the form of asynchronous events, making forecasting difficult.
However, existing models are mainly designated for either synchronous
time-series or asynchronous event sequence, and can hardly provide a synthetic
way to capture the relation between them. We propose Variational Synergetic
Multi-Horizon Network (VSMHN), a novel deep conditional generative model. To
learn complex correlations across heterogeneous sequences, a tailored encoder
is devised to combine the advances in deep point processes models and
variational recurrent neural networks. In addition, an aligned time coding and
an auxiliary transition scheme are carefully devised for batched training on
unaligned sequences. Our model can be trained effectively using stochastic
variational inference and generates probabilistic predictions with Monte-Carlo
simulation. Furthermore, our model produces accurate, sharp and more realistic
probabilistic forecasts. We also show that modeling asynchronous event
sequences is crucial for multi-horizon time-series forecasting.
</p>
<a href="http://arxiv.org/abs/2102.00431" target="_blank">arXiv:2102.00431</a> [<a href="http://arxiv.org/pdf/2102.00431" target="_blank">pdf</a>]

<h2>The Connection Between Approximation, Depth Separation and Learnability in Neural Networks. (arXiv:2102.00434v1 [cs.LG])</h2>
<h3>Eran Malach, Gilad Yehudai, Shai Shalev-Shwartz, Ohad Shamir</h3>
<p>Several recent works have shown separation results between deep neural
networks, and hypothesis classes with inferior approximation capacity such as
shallow networks or kernel classes. On the other hand, the fact that deep
networks can efficiently express a target function does not mean this target
function can be learned efficiently by deep neural networks. In this work we
study the intricate connection between learnability and approximation capacity.
We show that learnability with deep networks of a target function depends on
the ability of simpler classes to approximate the target. Specifically, we show
that a necessary condition for a function to be learnable by gradient descent
on deep neural networks is to be able to approximate the function, at least in
a weak sense, with shallow neural networks. We also show that a class of
functions can be learned by an efficient statistical query algorithm if and
only if it can be approximated in a weak sense by some kernel class. We give
several examples of functions which demonstrate depth separation, and conclude
that they cannot be efficiently learned, even by a hypothesis class that can
efficiently approximate them.
</p>
<a href="http://arxiv.org/abs/2102.00434" target="_blank">arXiv:2102.00434</a> [<a href="http://arxiv.org/pdf/2102.00434" target="_blank">pdf</a>]

<h2>Admix: Enhancing the Transferability of Adversarial Attacks. (arXiv:2102.00436v1 [cs.CV])</h2>
<h3>Xiaosen Wang, Xuanran He, Jingdong Wang, Kun He</h3>
<p>Although adversarial attacks have achieved incredible attack success rates
under the white-box setting, most existing adversaries often exhibit weak
transferability under the black-box setting. To address this issue, various
input transformations have been proposed to enhance the attack transferability.
In this work, We observe that all the existing transformations are applied on a
single image, which might limit the transferability of the crafted adversaries.
Hence, we propose a new input transformation based attack called Admix Attack
Method (AAM) that considers both the original image and an image randomly
picked from other categories. Instead of directly calculating the gradient on
the original input, AAM calculates the gradient on the admixed image
interpolated by the two images in order to craft adversaries with higher
transferablility. Empirical evaluations on the standard ImageNet dataset
demonstrate that AAM could achieve much higher transferability than the
existing input transformation methods. By incorporating with other input
transformations, our method could further improve the transferability and
outperform the state-of-the-art combination of input transformations by a clear
margin of 3.4% on average when attacking nine advanced defense models.
</p>
<a href="http://arxiv.org/abs/2102.00436" target="_blank">arXiv:2102.00436</a> [<a href="http://arxiv.org/pdf/2102.00436" target="_blank">pdf</a>]

<h2>M2FN: Multi-step Modality Fusion for Advertisement Image Assessment. (arXiv:2102.00441v1 [cs.CV])</h2>
<h3>Kyung-Wha Park (1), Jung-Woo Ha (2), JungHoon Lee (3), Sunyoung Kwon (4), Kyung-Min Kim (2), Byoung-Tak Zhang (1 and 5 and 6) ((1) Interdisciplinary Program in Neuroscience, Seoul National University., (2) NAVER AI LAB, NAVER CLOVA., (3) Statistics and Actuarial Science, Soongsil University., (4) School of Biomedical Convergence Engineering, Pusan National University., (5) Department of Computer Science and Engineering, Seoul National University., (6) Surromind Robotics.)</h3>
<p>Assessing advertisements, specifically on the basis of user preferences and
ad quality, is crucial to the marketing industry. Although recent studies have
attempted to use deep neural networks for this purpose, these studies have not
utilized image-related auxiliary attributes, which include embedded text
frequently found in ad images. We, therefore, investigated the influence of
these attributes on ad image preferences. First, we analyzed large-scale
real-world ad log data and, based on our findings, proposed a novel multi-step
modality fusion network (M2FN) that determines advertising images likely to
appeal to user preferences. Our method utilizes auxiliary attributes through
multiple steps in the network, which include conditional batch
normalization-based low-level fusion and attention-based high-level fusion. We
verified M2FN on the AVA dataset, which is widely used for aesthetic image
assessment, and then demonstrated that M2FN can achieve state-of-the-art
performance in preference prediction using a real-world ad dataset with rich
auxiliary attributes.
</p>
<a href="http://arxiv.org/abs/2102.00441" target="_blank">arXiv:2102.00441</a> [<a href="http://arxiv.org/pdf/2102.00441" target="_blank">pdf</a>]

<h2>Towards Imperceptible Query-limited Adversarial Attacks with Perceptual Feature Fidelity Loss. (arXiv:2102.00449v1 [cs.CV])</h2>
<h3>Pengrui Quan, Ruiming Guo, Mani Srivastava</h3>
<p>Recently, there has been a large amount of work towards fooling
deep-learning-based classifiers, particularly for images, via adversarial
inputs that are visually similar to the benign examples. However, researchers
usually use Lp-norm minimization as a proxy for imperceptibility, which
oversimplifies the diversity and richness of real-world images and human visual
perception. In this work, we propose a novel perceptual metric utilizing the
well-established connection between the low-level image feature fidelity and
human visual sensitivity, where we call it Perceptual Feature Fidelity Loss. We
show that our metric can robustly reflect and describe the imperceptibility of
the generated adversarial images validated in various conditions. Moreover, we
demonstrate that this metric is highly flexible, which can be conveniently
integrated into different existing optimization frameworks to guide the noise
distribution for better imperceptibility. The metric is particularly useful in
the challenging black-box attack with limited queries, where the
imperceptibility is hard to achieve due to the non-trivial perturbation power.
</p>
<a href="http://arxiv.org/abs/2102.00449" target="_blank">arXiv:2102.00449</a> [<a href="http://arxiv.org/pdf/2102.00449" target="_blank">pdf</a>]

<h2>Exponential Savings in Agnostic Active Learning through Abstention. (arXiv:2102.00451v1 [cs.LG])</h2>
<h3>Nikita Puchkin, Nikita Zhivotovskiy</h3>
<p>We show that in pool-based active classification without assumptions on the
underlying distribution, if the learner is given the power to abstain from some
predictions by paying the price marginally smaller than the average loss $1/2$
of a random guess, exponential savings in the number of label requests are
possible whenever they are possible in the corresponding realizable problem. We
extend this result to provide a necessary and sufficient condition for
exponential savings in pool-based active classification under the model
misspecification.
</p>
<a href="http://arxiv.org/abs/2102.00451" target="_blank">arXiv:2102.00451</a> [<a href="http://arxiv.org/pdf/2102.00451" target="_blank">pdf</a>]

<h2>Meta ordinal weighting net for improving lung nodule classification. (arXiv:2102.00456v1 [cs.CV])</h2>
<h3>Yiming Lei, Hongming Shan, Junping Zhang</h3>
<p>The progression of lung cancer implies the intrinsic ordinal relationship of
lung nodules at different stages-from benign to unsure then to malignant. This
problem can be solved by ordinal regression methods, which is between
classification and regression due to its ordinal label. However, existing
convolutional neural network (CNN)-based ordinal regression methods only focus
on modifying classification head based on a randomly sampled mini-batch of
data, ignoring the ordinal relationship resided in the data itself. In this
paper, we propose a Meta Ordinal Weighting Network (MOW-Net) to explicitly
align each training sample with a meta ordinal set (MOS) containing a few
samples from all classes. During the training process, the MOW-Net learns a
mapping from samples in MOS to the corresponding class-specific weight. In
addition, we further propose a meta cross-entropy (MCE) loss to optimize the
network in a meta-learning scheme. The experimental results demonstrate that
the MOW-Net achieves better accuracy than the state-of-the-art ordinal
regression methods, especially for the unsure class.
</p>
<a href="http://arxiv.org/abs/2102.00456" target="_blank">arXiv:2102.00456</a> [<a href="http://arxiv.org/pdf/2102.00456" target="_blank">pdf</a>]

<h2>MultiRocket: Effective summary statistics for convolutional outputs in time series classification. (arXiv:2102.00457v1 [cs.LG])</h2>
<h3>Chang Wei Tan, Angus Dempster, Christoph Bergmeir, Geoffrey I. Webb</h3>
<p>Rocket and MiniRocket, while two of the fastest methods for time series
classification, are both somewhat less accurate than the current most accurate
methods (namely, HIVE-COTE and its variants). We show that it is possible to
significantly improve the accuracy of MiniRocket (and Rocket), with some
additional computational expense, by expanding the set of features produced by
the transform, making MultiRocket (for MiniRocket with Multiple Features)
overall the single most accurate method on the datasets in the UCR archive,
while still being orders of magnitude faster than any algorithm of comparable
accuracy other than its precursors
</p>
<a href="http://arxiv.org/abs/2102.00457" target="_blank">arXiv:2102.00457</a> [<a href="http://arxiv.org/pdf/2102.00457" target="_blank">pdf</a>]

<h2>PV-RCNN++: Point-Voxel Feature Set Abstraction With Local Vector Representation for 3D Object Detection. (arXiv:2102.00463v1 [cs.CV])</h2>
<h3>Shaoshuai Shi, Li Jiang, Jiajun Deng, Zhe Wang, Chaoxu Guo, Jianping Shi, Xiaogang Wang, Hongsheng Li</h3>
<p>3D object detection is receiving increasing attention from both industry and
academia thanks to its wide applications in various fields. In this paper, we
propose the Point-Voxel Region based Convolution Neural Networks (PV-RCNNs) for
accurate 3D detection from point clouds. First, we propose a novel 3D object
detector, PV-RCNN-v1, which employs the voxel-to-keypoint scene encoding and
keypoint-to-grid RoI feature abstraction two novel steps. These two steps
deeply incorporate both 3D voxel CNN and PointNet-based set abstraction for
learning discriminative point-cloud features. Second, we propose a more
advanced framework, PV-RCNN-v2, for more efficient and accurate 3D detection.
It consists of two major improvements, where the first one is the sectorized
proposal-centric strategy for efficiently producing more representative and
uniformly distributed keypoints, and the second one is the VectorPool
aggregation to replace set abstraction for better aggregating local point-cloud
features with much less resource consumption. With these two major
modifications, our PV-RCNN-v2 runs more than twice as fast as the v1 version
while still achieving better performance on the large-scale Waymo Open Dataset
with 150m * 150m detection range. Extensive experiments demonstrate that our
proposed PV-RCNNs significantly outperform previous state-of-the-art 3D
detection methods on both the Waymo Open Dataset and the highly-competitive
KITTI benchmark.
</p>
<a href="http://arxiv.org/abs/2102.00463" target="_blank">arXiv:2102.00463</a> [<a href="http://arxiv.org/pdf/2102.00463" target="_blank">pdf</a>]

<h2>Information fusion between knowledge and data in Bayesian network structure learning. (arXiv:2102.00473v1 [cs.AI])</h2>
<h3>Anthony C. Constantinou, Zhigao Guo, Neville K. Kitson</h3>
<p>Bayesian Networks (BNs) have become a powerful technology for reasoning under
uncertainty, particularly in areas that require causal assumptions that enable
us to simulate the effect of intervention. The graphical structure of these
models can be determined by causal knowledge, learnt from data, or a
combination of both. While it seems plausible that the best approach in
constructing a causal graph involves combining knowledge with machine learning,
this approach remains underused in practice. This paper describes and evaluates
a set of information fusion methods that have been implemented in the
open-source Bayesys structure learning system. The methods enable users to
specify pre-existing knowledge and rule-based information that can be obtained
from heterogeneous sources, to constrain or guide structure learning. Each
method is assessed in terms of structure learning impact, including graphical
accuracy, model fitting, complexity and runtime. The results are illustrated
both with limited and big data, with application to three BN structure learning
algorithms available in Bayesys, and reveal interesting inconsistencies about
their effectiveness where the results obtained from graphical measures often
contradict those obtained from model fitting measures. While the overall
results show that information fusion methods become less effective with big
data due to higher learning accuracy rendering knowledge less important, some
information fusion methods do perform better with big data. Lastly, amongst the
main conclusions is the observation that reduced search space obtained from
knowledge constraints does not imply reduced computational complexity, which
can happen when the constraints set up a tension between what the data indicate
and what the constraints are trying to enforce.
</p>
<a href="http://arxiv.org/abs/2102.00473" target="_blank">arXiv:2102.00473</a> [<a href="http://arxiv.org/pdf/2102.00473" target="_blank">pdf</a>]

<h2>Fast Rates for the Regret of Offline Reinforcement Learning. (arXiv:2102.00479v1 [cs.LG])</h2>
<h3>Yichun Hu, Nathan Kallus, Masatoshi Uehara</h3>
<p>We study the regret of reinforcement learning from offline data generated by
a fixed behavior policy in an infinite-horizon discounted Markov decision
process (MDP). While existing analyses of common approaches, such as fitted
$Q$-iteration (FQI), suggest a $O(1/\sqrt{n})$ convergence for regret,
empirical behavior exhibits much faster convergence. In this paper, we present
a finer regret analysis that exactly characterizes this phenomenon by providing
fast rates for the regret convergence. First, we show that given any estimate
for the optimal quality function $Q^*$, the regret of the policy it defines
converges at a rate given by the exponentiation of the $Q^*$-estimate's
pointwise convergence rate, thus speeding it up. The level of exponentiation
depends on the level of noise in the decision-making problem, rather than the
estimation problem. We establish such noise levels for linear and tabular MDPs
as examples. Second, we provide new analyses of FQI and Bellman residual
minimization to establish the correct pointwise convergence guarantees. As
specific cases, our results imply $O(1/n)$ regret rates in linear cases and
$\exp(-\Omega(n))$ regret rates in tabular cases.
</p>
<a href="http://arxiv.org/abs/2102.00479" target="_blank">arXiv:2102.00479</a> [<a href="http://arxiv.org/pdf/2102.00479" target="_blank">pdf</a>]

<h2>Visualizing High-Dimensional Trajectories on the Loss-Landscape of ANNs. (arXiv:2102.00485v1 [cs.LG])</h2>
<h3>Stefan Horoi, Jessie Huang, Guy Wolf, Smita Krishnaswamy</h3>
<p>Training artificial neural networks requires the optimization of highly
non-convex loss functions. Throughout the years, the scientific community has
developed an extensive set of tools and architectures that render this
optimization task tractable and a general intuition has been developed for
choosing hyper parameters that help the models reach minima that generalize
well to unseen data. However, for the most part, the difference in trainability
in between architectures, tasks and even the gap in network generalization
abilities still remain unexplained. Visualization tools have played a key role
in uncovering key geometric characteristics of the loss-landscape of ANNs and
how they impact trainability and generalization capabilities. However, most
visualizations methods proposed so far have been relatively limited in their
capabilities since they are of linear nature and only capture features in a
limited number of dimensions. We propose the use of the modern dimensionality
reduction method PHATE which represents the SOTA in terms of capturing both
global and local structures of high-dimensional data. We apply this method to
visualize the loss landscape during and after training. Our visualizations
reveal differences in training trajectories and generalization capabilities
when used to make comparisons between optimization methods, initializations,
architectures, and datasets. Given this success we anticipate this method to be
used in making informed choices about these aspects of neural networks.
</p>
<a href="http://arxiv.org/abs/2102.00485" target="_blank">arXiv:2102.00485</a> [<a href="http://arxiv.org/pdf/2102.00485" target="_blank">pdf</a>]

<h2>Nonlinear Evolutionary PDE-Based Refinement of Optical Flow. (arXiv:2102.00487v1 [cs.CV])</h2>
<h3>Hirak Doshi, N. Uday Kiran</h3>
<p>The goal of this paper is propose a mathematical framework for optical flow
refinement with non-quadratic regularization using variational techniques. We
demonstrate how the model can be suitably adapted for both rigid and fluid
motion estimation. We study the problem as an abstract IVP using an
evolutionary PDE approach. We show that for a particular choice of constraint
our model approximates the continuity model with non-quadratic regularization
using augmented Lagrangian techniques. We subsequently show the results of our
algorithm on different datasets.
</p>
<a href="http://arxiv.org/abs/2102.00487" target="_blank">arXiv:2102.00487</a> [<a href="http://arxiv.org/pdf/2102.00487" target="_blank">pdf</a>]

<h2>Online Markov Decision Processes with Aggregate Bandit Feedback. (arXiv:2102.00490v1 [cs.LG])</h2>
<h3>Alon Cohen, Haim Kaplan, Tomer Koren, Yishay Mansour</h3>
<p>We study a novel variant of online finite-horizon Markov Decision Processes
with adversarially changing loss functions and initially unknown dynamics. In
each episode, the learner suffers the loss accumulated along the trajectory
realized by the policy chosen for the episode, and observes aggregate bandit
feedback: the trajectory is revealed along with the cumulative loss suffered,
rather than the individual losses encountered along the trajectory. Our main
result is a computationally efficient algorithm with $O(\sqrt{K})$ regret for
this setting, where $K$ is the number of episodes.

We establish this result via an efficient reduction to a novel bandit
learning setting we call Distorted Linear Bandits (DLB), which is a variant of
bandit linear optimization where actions chosen by the learner are
adversarially distorted before they are committed. We then develop a
computationally-efficient online algorithm for DLB for which we prove an
$O(\sqrt{T})$ regret bound, where $T$ is the number of time steps. Our
algorithm is based on online mirror descent with a self-concordant barrier
regularization that employs a novel increasing learning rate schedule.
</p>
<a href="http://arxiv.org/abs/2102.00490" target="_blank">arXiv:2102.00490</a> [<a href="http://arxiv.org/pdf/2102.00490" target="_blank">pdf</a>]

<h2>A Multiscale Environment for Learning by Diffusion. (arXiv:2102.00500v1 [cs.LG])</h2>
<h3>James M. Murphy, Sam L. Polk</h3>
<p>Clustering algorithms partition a dataset into groups of similar points. The
clustering problem is very general, and different partitions of the same
dataset could be considered correct and useful. To fully understand such data,
it must be considered at a variety of scales, ranging from coarse to fine. We
introduce the Multiscale Environment for Learning by Diffusion (MELD) data
model, which is a family of clusterings parameterized by nonlinear diffusion on
the dataset. We show that the MELD data model precisely captures latent
multiscale structure in data and facilitates its analysis. To efficiently learn
the multiscale structure observed in many real datasets, we introduce the
Multiscale Learning by Unsupervised Nonlinear Diffusion (M-LUND) clustering
algorithm, which is derived from a diffusion process at a range of temporal
scales. We provide theoretical guarantees for the algorithm's performance and
establish its computational efficiency. Finally, we show that the M-LUND
clustering algorithm detects the latent structure in a range of synthetic and
real datasets.
</p>
<a href="http://arxiv.org/abs/2102.00500" target="_blank">arXiv:2102.00500</a> [<a href="http://arxiv.org/pdf/2102.00500" target="_blank">pdf</a>]

<h2>Urban Change Detection by Fully Convolutional Siamese Concatenate Network with Attention. (arXiv:2102.00501v1 [cs.CV])</h2>
<h3>Farnoosh Heidary, Mehran Yazdi, Maryam Dehghani, Peyman Setoodeh</h3>
<p>Change detection (CD) is an important problem in remote sensing, especially
in disaster time for urban management. Most existing traditional methods for
change detection are categorized based on pixel or objects. Object-based models
are preferred to pixel-based methods for handling very high-resolution remote
sensing (VHR RS) images. Such methods can benefit from the ongoing research on
deep learning. In this paper, a fully automatic change-detection algorithm on
VHR RS images is proposed that deploys Fully Convolutional Siamese Concatenate
networks (FC-Siam-Conc). The proposed method uses preprocessing and an
attention gate layer to improve accuracy. Gaussian attention (GA) as a soft
visual attention mechanism is used for preprocessing. GA helps the network to
handle feature maps like biological visual systems. Since the GA parameters
cannot be adjusted during network training, an attention gate layer is
introduced to play the role of GA with parameters that can be tuned among other
network parameters. Experimental results obtained on Onera Satellite Change
Detection (OSCD) and RIVER-CD datasets confirm the superiority of the proposed
architecture over the state-of-the-art algorithms.
</p>
<a href="http://arxiv.org/abs/2102.00501" target="_blank">arXiv:2102.00501</a> [<a href="http://arxiv.org/pdf/2102.00501" target="_blank">pdf</a>]

<h2>Exact Recovery of Clusters in Finite Metric Spaces Using Oracle Queries. (arXiv:2102.00504v1 [cs.LG])</h2>
<h3>Marco Bressan, Nicol&#xf2; Cesa-Bianchi, Silvio Lattanzi, Andrea Paudice</h3>
<p>We investigate the problem of exact cluster recovery using oracle queries.
Previous results show that clusters in Euclidean spaces that are convex and
separated with a margin can be reconstructed exactly using only $O(\log n)$
same-cluster queries, where $n$ is the number of input points. In this work, we
study this problem in the more challenging non-convex setting. We introduce a
structural characterization of clusters, called $(\beta,\gamma)$-convexity,
that can be applied to any finite set of points equipped with a metric (or even
a semimetric, as the triangle inequality is not needed). Using
$(\beta,\gamma)$-convexity, we can translate natural density properties of
clusters (which include, for instance, clusters that are strongly non-convex in
$R^d$) into a graph-theoretic notion of convexity. By exploiting this convexity
notion, we design a deterministic algorithm that recovers
$(\beta,\gamma)$-convex clusters using $O(k^2 \log n + k^2
(\frac{6}{\beta\gamma})^{dens(X)})$ same-cluster queries, where $k$ is the
number of clusters and $dens(X)$ is the density dimension of the semimetric. We
show that an exponential dependence on the density dimension is necessary, and
we also show that, if we are allowed to make $O(k^2 + k \log n)$ additional
queries to a "cluster separation" oracle, then we can recover clusters that
have different and arbitrary scales, even when the scale of each cluster is
unknown.
</p>
<a href="http://arxiv.org/abs/2102.00504" target="_blank">arXiv:2102.00504</a> [<a href="http://arxiv.org/pdf/2102.00504" target="_blank">pdf</a>]

<h2>Fine-tuning Handwriting Recognition systems with Temporal Dropout. (arXiv:2102.00511v1 [cs.CV])</h2>
<h3>Edgard Chammas, Chafic Mokbel</h3>
<p>This paper introduces a novel method to fine-tune handwriting recognition
systems based on Recurrent Neural Networks (RNN). Long Short-Term Memory (LSTM)
networks are good at modeling long sequences but they tend to overfit over
time. To improve the system's ability to model sequences, we propose to drop
information at random positions in the sequence. We call our approach Temporal
Dropout (TD). We apply TD at the image level as well to internal network
representation. We show that TD improves the results on two different datasets.
Our method outperforms previous state-of-the-art on Rodrigo dataset.
</p>
<a href="http://arxiv.org/abs/2102.00511" target="_blank">arXiv:2102.00511</a> [<a href="http://arxiv.org/pdf/2102.00511" target="_blank">pdf</a>]

<h2>Improving Human Decision-Making by Discovering Efficient Strategies for Hierarchical Planning. (arXiv:2102.00521v1 [cs.AI])</h2>
<h3>Saksham Consul, Lovis Heindrich, Jugoslav Stojcheski, Falk Lieder</h3>
<p>To make good decisions in the real world people need efficient planning
strategies because their computational resources are limited. Knowing which
planning strategies would work best for people in different situations would be
very useful for understanding and improving human decision-making. But our
ability to compute those strategies used to be limited to very small and very
simple planning tasks. To overcome this computational bottleneck, we introduce
a cognitively-inspired reinforcement learning method that can overcome this
limitation by exploiting the hierarchical structure of human behavior. The
basic idea is to decompose sequential decision problems into two sub-problems:
setting a goal and planning how to achieve it. This hierarchical decomposition
enables us to discover optimal strategies for human planning in larger and more
complex tasks than was previously possible. The discovered strategies
outperform existing planning algorithms and achieve a super-human level of
computational efficiency. We demonstrate that teaching people to use those
strategies significantly improves their performance in sequential
decision-making tasks that require planning up to eight steps ahead. By
contrast, none of the previous approaches was able to improve human performance
on these problems. These findings suggest that our cognitively-informed
approach makes it possible to leverage reinforcement learning to improve human
decision-making in complex sequential decision-problems. Future work can
leverage our method to develop decision support systems that improve human
decision making in the real world.
</p>
<a href="http://arxiv.org/abs/2102.00521" target="_blank">arXiv:2102.00521</a> [<a href="http://arxiv.org/pdf/2102.00521" target="_blank">pdf</a>]

<h2>Co-Seg: An Image Segmentation Framework Against Label Corruption. (arXiv:2102.00523v1 [cs.LG])</h2>
<h3>Ziyi Huang, Haofeng Zhang, Andrew Laine, Elsa Angelini, Christine Hendon, Yu Gan</h3>
<p>Supervised deep learning performance is heavily tied to the availability of
high-quality labels for training. Neural networks can gradually overfit
corrupted labels if directly trained on noisy datasets, leading to severe
performance degradation at test time. In this paper, we propose a novel deep
learning framework, namely Co-Seg, to collaboratively train segmentation
networks on datasets which include low-quality noisy labels. Our approach first
trains two networks simultaneously to sift through all samples and obtain a
subset with reliable labels. Then, an efficient yet easily-implemented label
correction strategy is applied to enrich the reliable subset. Finally, using
the updated dataset, we retrain the segmentation network to finalize its
parameters. Experiments in two noisy labels scenarios demonstrate that our
proposed model can achieve results comparable to those obtained from supervised
learning trained on the noise-free labels. In addition, our framework can be
easily implemented in any segmentation algorithm to increase its robustness to
noisy labels.
</p>
<a href="http://arxiv.org/abs/2102.00523" target="_blank">arXiv:2102.00523</a> [<a href="http://arxiv.org/pdf/2102.00523" target="_blank">pdf</a>]

<h2>Computational Performance Predictions for Deep Neural Network Training: A Runtime-Based Approach. (arXiv:2102.00527v1 [cs.LG])</h2>
<h3>Geoffrey X. Yu, Yubo Gao, Pavel Golikov, Gennady Pekhimenko</h3>
<p>Deep learning researchers and practitioners usually leverage GPUs to help
train their deep neural networks (DNNs) faster. However, choosing which GPU to
use is challenging both because (i) there are many options, and (ii) users
grapple with competing concerns: maximizing compute performance while
minimizing costs. In this work, we present a new practical technique to help
users make informed and cost-efficient GPU selections: make performance
predictions using the help of a GPU that the user already has. Our technique
exploits the observation that, because DNN training consists of repetitive
compute steps, predicting the execution time of a single iteration is usually
enough to characterize the performance of an entire training process. We make
predictions by scaling the execution time of each operation in a training
iteration from one GPU to another using either (i) wave scaling, a technique
based on a GPU's execution model, or (ii) pre-trained multilayer perceptrons.
We implement our technique into a Python library called Surfer and find that it
makes accurate iteration execution time predictions on ResNet-50, Inception v3,
the Transformer, GNMT, and DCGAN across six different GPU architectures. Surfer
currently supports PyTorch, is easy to use, and requires only a few lines of
code.
</p>
<a href="http://arxiv.org/abs/2102.00527" target="_blank">arXiv:2102.00527</a> [<a href="http://arxiv.org/pdf/2102.00527" target="_blank">pdf</a>]

<h2>Deep Deterministic Information Bottleneck with Matrix-based Entropy Functional. (arXiv:2102.00533v1 [cs.LG])</h2>
<h3>Xi Yu, Shujian Yu, Jose C. Principe</h3>
<p>We introduce the matrix-based Renyi's $\alpha$-order entropy functional to
parameterize Tishby et al. information bottleneck (IB) principle with a neural
network. We term our methodology Deep Deterministic Information Bottleneck
(DIB), as it avoids variational inference and distribution assumption. We show
that deep neural networks trained with DIB outperform the variational objective
counterpart and those that are trained with other forms of regularization, in
terms of generalization performance and robustness to adversarial attack.Code
available at https://github.com/yuxi120407/DIB
</p>
<a href="http://arxiv.org/abs/2102.00533" target="_blank">arXiv:2102.00533</a> [<a href="http://arxiv.org/pdf/2102.00533" target="_blank">pdf</a>]

<h2>Generative and Discriminative Deep Belief Network Classifiers: Comparisons Under an Approximate Computing Framework. (arXiv:2102.00534v1 [cs.LG])</h2>
<h3>Siqiao Ruan, Ian Colbert, Ken Kreutz-Delgado, Srinjoy Das</h3>
<p>The use of Deep Learning hardware algorithms for embedded applications is
characterized by challenges such as constraints on device power consumption,
availability of labeled data, and limited internet bandwidth for frequent
training on cloud servers. To enable low power implementations, we consider
efficient bitwidth reduction and pruning for the class of Deep Learning
algorithms known as Discriminative Deep Belief Networks (DDBNs) for
embedded-device classification tasks. We train DDBNs with both generative and
discriminative objectives under an approximate computing framework and analyze
their power-at-performance for supervised and semi-supervised applications. We
also investigate the out-of-distribution performance of DDBNs when the
inference data has the same class structure yet is statistically different from
the training data owing to dynamic real-time operating environments. Based on
our analysis, we provide novel insights and recommendations for choice of
training objectives, bitwidth values, and accuracy sensitivity with respect to
the amount of labeled data for implementing DDBN inference with minimum power
consumption on embedded hardware platforms subject to accuracy tolerances.
</p>
<a href="http://arxiv.org/abs/2102.00534" target="_blank">arXiv:2102.00534</a> [<a href="http://arxiv.org/pdf/2102.00534" target="_blank">pdf</a>]

<h2>CODE-AE: A Coherent De-confounding Autoencoder for Predicting Patient-Specific Drug Response From Cell Line Transcriptomics. (arXiv:2102.00538v1 [cs.LG])</h2>
<h3>Di He, Lei Xie</h3>
<p>Accurate and robust prediction of patient's response to drug treatments is
critical for developing precision medicine. However, it is often difficult to
obtain a sufficient amount of coherent drug response data from patients
directly for training a generalized machine learning model. Although the
utilization of rich cell line data provides an alternative solution, it is
challenging to transfer the knowledge obtained from cell lines to patients due
to various confounding factors. Few existing transfer learning methods can
reliably disentangle common intrinsic biological signals from confounding
factors in the cell line and patient data. In this paper, we develop a Coherent
Deconfounding Autoencoder (CODE-AE) that can extract both common biological
signals shared by incoherent samples and private representations unique to each
data set, transfer knowledge learned from cell line data to tissue data, and
separate confounding factors from them. Extensive studies on multiple data sets
demonstrate that CODE-AE significantly improves the accuracy and robustness
over state-of-the-art methods in both predicting patient drug response and
de-confounding biological signals. Thus, CODE-AE provides a useful framework to
take advantage of in vitro omics data for developing generalized patient
predictive models. The source code is available at
https://github.com/XieResearchGroup/CODE-AE.
</p>
<a href="http://arxiv.org/abs/2102.00538" target="_blank">arXiv:2102.00538</a> [<a href="http://arxiv.org/pdf/2102.00538" target="_blank">pdf</a>]

<h2>GraphEBM: Molecular Graph Generation with Energy-Based Models. (arXiv:2102.00546v1 [cs.LG])</h2>
<h3>Meng Liu, Keqiang Yan, Bora Oztekin, Shuiwang Ji</h3>
<p>Molecular graph generation is an emerging area of research with numerous
applications. This problem remains challenging as molecular graphs are
discrete, irregular, and permutation invariant to node order. Notably, most
existing approaches fail to guarantee the intrinsic property of permutation
invariance, resulting in unexpected bias in generative models. In this work, we
propose GraphEBM to generate molecular graphs using energy-based models. In
particular, we parameterize the energy function in a permutation invariant
manner, thus making GraphEBM permutation invariant. We apply Langevin dynamics
to train the energy function by approximately maximizing likelihood and
generate samples with low energies. Furthermore, to generate molecules with a
specific desirable property, we propose a simple yet effective strategy, which
pushes down energies with flexible degrees according to the properties of
corresponding molecules. Finally, we explore the use of GraphEBM for generating
molecules with multiple objectives in a compositional manner. Comprehensive
experimental results on random, goal-directed, and compositional generation
tasks demonstrate the effectiveness of our proposed method.
</p>
<a href="http://arxiv.org/abs/2102.00546" target="_blank">arXiv:2102.00546</a> [<a href="http://arxiv.org/pdf/2102.00546" target="_blank">pdf</a>]

<h2>Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks. (arXiv:2102.00554v1 [cs.LG])</h2>
<h3>Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, Alexandra Peste</h3>
<p>The growing energy and performance costs of deep learning have driven the
community to reduce the size of neural networks by selectively pruning
components. Similarly to their biological counterparts, sparse networks
generalize just as well, if not better than, the original dense networks.
Sparsity can reduce the memory footprint of regular networks to fit mobile
devices, as well as shorten training time for ever growing networks. In this
paper, we survey prior work on sparsity in deep learning and provide an
extensive tutorial of sparsification for both inference and training. We
describe approaches to remove and add elements of neural networks, different
training strategies to achieve model sparsity, and mechanisms to exploit
sparsity in practice. Our work distills ideas from more than 300 research
papers and provides guidance to practitioners who wish to utilize sparsity
today, as well as to researchers whose goal is to push the frontier forward. We
include the necessary background on mathematical methods in sparsification,
describe phenomena such as early structure adaptation, the intricate relations
between sparsity and the training process, and show techniques for achieving
acceleration on real hardware. We also define a metric of pruned parameter
efficiency that could serve as a baseline for comparison of different sparse
networks. We close by speculating on how sparsity can improve future workloads
and outline major open problems in the field.
</p>
<a href="http://arxiv.org/abs/2102.00554" target="_blank">arXiv:2102.00554</a> [<a href="http://arxiv.org/pdf/2102.00554" target="_blank">pdf</a>]

<h2>CyclingNet: Detecting cycling near misses from video streams in complex urban scenes with deep learning. (arXiv:2102.00565v1 [cs.CV])</h2>
<h3>Mohamed R. Ibrahim, James Haworth, Nicola Christie, Tao Cheng</h3>
<p>Cycling is a promising sustainable mode for commuting and leisure in cities,
however, the fear of getting hit or fall reduces its wide expansion as a
commuting mode. In this paper, we introduce a novel method called CyclingNet
for detecting cycling near misses from video streams generated by a mounted
frontal camera on a bike regardless of the camera position, the conditions of
the built, the visual conditions and without any restrictions on the riding
behaviour. CyclingNet is a deep computer vision model based on convolutional
structure embedded with self-attention bidirectional long-short term memory
(LSTM) blocks that aim to understand near misses from both sequential images of
scenes and their optical flows. The model is trained on scenes of both safe
rides and near misses. After 42 hours of training on a single GPU, the model
shows high accuracy on the training, testing and validation sets. The model is
intended to be used for generating information that can draw significant
conclusions regarding cycling behaviour in cities and elsewhere, which could
help planners and policy-makers to better understand the requirement of safety
measures when designing infrastructure or drawing policies. As for future work,
the model can be pipelined with other state-of-the-art classifiers and object
detectors simultaneously to understand the causality of near misses based on
factors related to interactions of road-users, the built and the natural
environments.
</p>
<a href="http://arxiv.org/abs/2102.00565" target="_blank">arXiv:2102.00565</a> [<a href="http://arxiv.org/pdf/2102.00565" target="_blank">pdf</a>]

<h2>Using Recursive KMeans and Dijkstra Algorithm to Solve CVRP. (arXiv:2102.00567v1 [cs.AI])</h2>
<h3>Hassan Moussa</h3>
<p>Capacitated vehicle routing problem (CVRP) is being one of the most common
optimization problems in our days
</p>
<a href="http://arxiv.org/abs/2102.00567" target="_blank">arXiv:2102.00567</a> [<a href="http://arxiv.org/pdf/2102.00567" target="_blank">pdf</a>]

<h2>Interpretable Reinforcement Learning Inspired by Piaget's Theory of Cognitive Development. (arXiv:2102.00572v1 [cs.AI])</h2>
<h3>Aref Hakimzadeh, Yanbo Xue, Peyman Setoodeh</h3>
<p>Endeavors for designing robots with human-level cognitive abilities have led
to different categories of learning machines. According to Skinner's theory,
reinforcement learning (RL) plays a key role in human intuition and cognition.
Majority of the state-of-the-art methods including deep RL algorithms are
strongly influenced by the connectionist viewpoint. Such algorithms can
significantly benefit from theories of mind and learning in other disciplines.
This paper entertains the idea that theories such as language of thought
hypothesis (LOTH), script theory, and Piaget's cognitive development theory
provide complementary approaches, which will enrich the RL field. Following
this line of thinking, a general computational building block is proposed for
Piaget's schema theory that supports the notions of productivity,
systematicity, and inferential coherence as described by Fodor in contrast with
the connectionism theory. Abstraction in the proposed method is completely upon
the system itself and is not externally constrained by any predefined
architecture. The whole process matches the Neisser's perceptual cycle model.
Performed experiments on three typical control problems followed by behavioral
analysis confirm the interpretability of the proposed method and its
competitiveness compared to the state-of-the-art algorithms. Hence, the
proposed framework can be viewed as a step towards achieving human-like
cognition in artificial intelligent systems.
</p>
<a href="http://arxiv.org/abs/2102.00572" target="_blank">arXiv:2102.00572</a> [<a href="http://arxiv.org/pdf/2102.00572" target="_blank">pdf</a>]

<h2>"Grip-that-there": An Investigation of Explicit and Implicit Task Allocation Techniques for Human-Robot Collaboration. (arXiv:2102.00581v1 [cs.RO])</h2>
<h3>Karthik Mahadevan, Maur&#xed;cio Sousa, Anthony Tang, Tovi Grossman</h3>
<p>In ad-hoc human-robot collaboration (HRC), humans and robots work on a task
without pre-planning the robot's actions prior to execution; instead, task
allocation occurs in real-time. However, prior research has largely focused on
task allocations that are pre-planned - there has not been a comprehensive
exploration or evaluation of techniques where task allocation is adjusted in
real-time. Inspired by HCI research on territoriality and proxemics, we propose
a design space of novel task allocation techniques including both explicit
techniques, where the user maintains agency, and implicit techniques, where the
efficiency of automation can be leveraged. The techniques were implemented and
evaluated using a tabletop HRC simulation in VR. A 16-participant study, which
presented variations of a collaborative block stacking task, showed that
implicit techniques enable efficient task completion and task parallelization,
and should be augmented with explicit mechanisms to provide users with
fine-grained control.
</p>
<a href="http://arxiv.org/abs/2102.00581" target="_blank">arXiv:2102.00581</a> [<a href="http://arxiv.org/pdf/2102.00581" target="_blank">pdf</a>]

<h2>Multi-Agent Reinforcement Learning with Temporal Logic Specifications. (arXiv:2102.00582v1 [cs.AI])</h2>
<h3>Lewis Hammond, Alessandro Abate, Julian Gutierrez, Michael Wooldridge</h3>
<p>In this paper, we study the problem of learning to satisfy temporal logic
specifications with a group of agents in an unknown environment, which may
exhibit probabilistic behaviour. From a learning perspective these
specifications provide a rich formal language with which to capture tasks or
objectives, while from a logic and automated verification perspective the
introduction of learning capabilities allows for practical applications in
large, stochastic, unknown environments. The existing work in this area is,
however, limited. Of the frameworks that consider full linear temporal logic or
have correctness guarantees, all methods thus far consider only the case of a
single temporal logic specification and a single agent. In order to overcome
this limitation, we develop the first multi-agent reinforcement learning
technique for temporal logic specifications, which is also novel in its ability
to handle multiple specifications. We provide correctness and convergence
guarantees for our main algorithm - ALMANAC (Automaton/Logic Multi-Agent
Natural Actor-Critic) - even when using function approximation. Alongside our
theoretical results, we further demonstrate the applicability of our technique
via a set of preliminary experiments.
</p>
<a href="http://arxiv.org/abs/2102.00582" target="_blank">arXiv:2102.00582</a> [<a href="http://arxiv.org/pdf/2102.00582" target="_blank">pdf</a>]

<h2>Box Re-Ranking: Unsupervised False Positive Suppression for Domain Adaptive Pedestrian Detection. (arXiv:2102.00595v1 [cs.CV])</h2>
<h3>Weijie Chen, Yilu Guo, Shicai Yang, Zhaoyang Li, Zhenxin Ma, Binbin Chen, Long Zhao, Di Xie, Shiliang Pu, Yueting Zhuang</h3>
<p>False positive is one of the most serious problems brought by agnostic domain
shift in domain adaptive pedestrian detection. However, it is impossible to
label each box in countless target domains. Therefore, it yields our attention
to suppress false positive in each target domain in an unsupervised way. In
this paper, we model an object detection task into a ranking task among
positive and negative boxes innovatively, and thus transform a false positive
suppression problem into a box re-ranking problem elegantly, which makes it
feasible to solve without manual annotation. An attached problem during box
re-ranking appears that no labeled validation data is available for
cherrypicking. Considering we aim to keep the detection of true positive
unchanged, we propose box number alignment, a self-supervised evaluation
metric, to prevent the optimized model from capacity degeneration. Extensive
experiments conducted on cross-domain pedestrian detection datasets have
demonstrated the effectiveness of our proposed framework. Furthermore, the
extension to two general unsupervised domain adaptive object detection
benchmarks also supports our superiority to other state-of-the-arts.
</p>
<a href="http://arxiv.org/abs/2102.00595" target="_blank">arXiv:2102.00595</a> [<a href="http://arxiv.org/pdf/2102.00595" target="_blank">pdf</a>]

<h2>RoutingGAN: Routing Age Progression and Regression with Disentangled Learning. (arXiv:2102.00601v1 [cs.CV])</h2>
<h3>Zhizhong Huang, Junping Zhang, Hongming Shan</h3>
<p>Although impressive results have been achieved for age progression and
regression, there remain two major issues in generative adversarial networks
(GANs)-based methods: 1) conditional GANs (cGANs)-based methods can learn
various effects between any two age groups in a single model, but are
insufficient to characterize some specific patterns due to completely shared
convolutions filters; and 2) GANs-based methods can, by utilizing several
models to learn effects independently, learn some specific patterns, however,
they are cumbersome and require age label in advance. To address these
deficiencies and have the best of both worlds, this paper introduces a
dropout-like method based on GAN~(RoutingGAN) to route different effects in a
high-level semantic feature space. Specifically, we first disentangle the
age-invariant features from the input face, and then gradually add the effects
to the features by residual routers that assign the convolution filters to
different age groups by dropping out the outputs of others. As a result, the
proposed RoutingGAN can simultaneously learn various effects in a single model,
with convolution filters being shared in part to learn some specific effects.
Experimental results on two benchmarked datasets demonstrate superior
performance over existing methods both qualitatively and quantitatively.
</p>
<a href="http://arxiv.org/abs/2102.00601" target="_blank">arXiv:2102.00601</a> [<a href="http://arxiv.org/pdf/2102.00601" target="_blank">pdf</a>]

<h2>The Controllability of Planning, Responsibility, and Security in Automatic Driving Technology. (arXiv:2102.00617v1 [cs.AI])</h2>
<h3>Dan Wan, Hao Zhan</h3>
<p>People hope automated driving technology is always in a stable and
controllable state; specifically, it can be divided into controllable planning,
controllable responsibility, and controllable information. When this
controllability is undermined, it brings about the problems, e.g., trolley
dilemma, responsibility attribution, information leakage, and security. This
article discusses these three types of issues separately and clarifies the
misunderstandings.
</p>
<a href="http://arxiv.org/abs/2102.00617" target="_blank">arXiv:2102.00617</a> [<a href="http://arxiv.org/pdf/2102.00617" target="_blank">pdf</a>]

<h2>Spatiotemporal Ground Reaction Force Analysis using Convolutional Neural Networks to Analyze Parkinsonian Gait. (arXiv:2102.00628v1 [cs.LG])</h2>
<h3>Musthaq Ahamed, P.D.S.H. Gunawardane, Nimali T. Medagedara</h3>
<p>Parkinson's disease (PD) is a non-curable disease that commonly found among
elders that greatly reduce their quality of life. PD primarily affects the gait
pattern and slowly changes the walking gait from the normality to disability.
The early diagnosing of PD is important for treatments and gait pattern
analysis is used as a technique to diagnose PD. The present paper has
identified the raw spatiotemporal ground reaction force (GRF) as a key
parameter to identify the changes in human gait patterns associated with PD.
The changes in GRF are identified using a convolutional neural network through
pre-processing, conversion, recognition, and performance evaluation. The
proposed algorithm is capable of identifying the severity of the PD and
distinguishing the parkinsonian gait from the healthy gait. The technique has
shown a 97% of accuracy in automatic decision-making process.
</p>
<a href="http://arxiv.org/abs/2102.00628" target="_blank">arXiv:2102.00628</a> [<a href="http://arxiv.org/pdf/2102.00628" target="_blank">pdf</a>]

<h2>ConvNets for Counting: Object Detection of Transient Phenomena in Steelpan Drums. (arXiv:2102.00632v1 [cs.CV])</h2>
<h3>Scott H. Hawley, Andrew C. Morrison</h3>
<p>We train an object detector built from convolutional neural networks to count
interference fringes in elliptical antinode regions visible in frames of
high-speed video recordings of transient oscillations in Caribbean steelpan
drums illuminated by electronic speckle pattern interferometry (ESPI). The
annotations provided by our model, "SPNet" are intended to contribute to the
understanding of time-dependent behavior in such drums by tracking the
development of sympathetic vibration modes. The system is trained on a dataset
of crowdsourced human-annotated images obtained from the Zooniverse Steelpan
Vibrations Project. Due to the relatively small number of human-annotated
images, we also train on a large corpus of synthetic images whose visual
properties have been matched to those of the real images by using a Generative
Adversarial Network to perform style transfer. Applying the model to predict
annotations of thousands of unlabeled video frames, we can track features and
measure oscillations consistent with audio recordings of the same drum strikes.
One surprising result is that the machine-annotated video frames reveal
transitions between the first and second harmonics of drum notes that
significantly precede such transitions present in the audio recordings. As this
paper primarily concerns the development of the model, deeper physical insights
await its further application.
</p>
<a href="http://arxiv.org/abs/2102.00632" target="_blank">arXiv:2102.00632</a> [<a href="http://arxiv.org/pdf/2102.00632" target="_blank">pdf</a>]

<h2>Bridging Unpaired Facial Photos And Sketches By Line-drawings. (arXiv:2102.00635v1 [cs.CV])</h2>
<h3>Fei Gao, Meimei Shang, Xiang Li, Jingjie Zhu, Lingna Dai</h3>
<p>In this paper, we propose a novel method to learn face sketch synthesis
models by using unpaired data. Our main idea is bridging the photo domain
$\mathcal{X}$ and the sketch domain $Y$ by using the line-drawing domain
$\mathcal{Z}$. Specially, we map both photos and sketches to line-drawings by
using a neural style transfer method, i.e. $F: \mathcal{X}/\mathcal{Y} \mapsto
\mathcal{Z}$. Consequently, we obtain \textit{pseudo paired data}
$(\mathcal{Z}, \mathcal{Y})$, and can learn the mapping $G:\mathcal{Z} \mapsto
\mathcal{Y}$ in a supervised learning manner. In the inference stage, given a
facial photo, we can first transfer it to a line-drawing and then to a sketch
by $G \circ F$. Additionally, we propose a novel stroke loss for generating
different types of strokes. Our method, termed sRender, accords well with human
artists' rendering process. Experimental results demonstrate that sRender can
generate multi-style sketches, and significantly outperforms existing unpaired
image-to-image translation methods.
</p>
<a href="http://arxiv.org/abs/2102.00635" target="_blank">arXiv:2102.00635</a> [<a href="http://arxiv.org/pdf/2102.00635" target="_blank">pdf</a>]

<h2>Computing the Hazard Ratios Associated with Explanatory Variables Using Machine Learning Models of Survival Data. (arXiv:2102.00637v1 [cs.LG])</h2>
<h3>Sameer Sundrani, James Lu</h3>
<p>Purpose: The application of Cox Proportional Hazards (CoxPH) models to
survival data and the derivation of Hazard Ratio (HR) is well established.
While nonlinear, tree-based Machine Learning (ML) models have been developed
and applied to the survival analysis, no methodology exists for computing HRs
associated with explanatory variables from such models. We describe a novel way
to compute HRs from tree-based ML models using the Shapley additive explanation
(SHAP) values, which is a locally accurate and consistent methodology to
quantify explanatory variables' contribution to predictions.

Methods: We used three sets of publicly available survival data consisting of
patients with colon, breast or pan cancer and compared the performance of CoxPH
to the state-of-art ML model, XGBoost. To compute the HR for explanatory
variables from the XGBoost model, the SHAP values were exponentiated and the
ratio of the means over the two subgroups calculated. The confidence interval
was computed via bootstrapping the training data and generating the ML model
1000 times. Across the three data sets, we systematically compared HRs for all
explanatory variables. Open-source libraries in Python and R were used in the
analyses.

Results: For the colon and breast cancer data sets, the performance of CoxPH
and XGBoost were comparable and we showed good consistency in the computed HRs.
In the pan-cancer dataset, we showed agreement in most variables but also an
opposite finding in two of the explanatory variables between the CoxPH and
XGBoost result. Subsequent Kaplan-Meier plots supported the finding of the
XGBoost model.

Conclusion: Enabling the derivation of HR from ML models can help to improve
the identification of risk factors from complex survival datasets and enhance
the prediction of clinical trial outcomes.
</p>
<a href="http://arxiv.org/abs/2102.00637" target="_blank">arXiv:2102.00637</a> [<a href="http://arxiv.org/pdf/2102.00637" target="_blank">pdf</a>]

<h2>Control and Navigation Framework for a Hybrid Steel Bridge Inspection Robot. (arXiv:2102.00641v1 [cs.RO])</h2>
<h3>Hoang-Dung Bui, Hung Manh La</h3>
<p>Autonomous navigation of steel bridge inspection robots is essential for
proper maintenance. The majority of existing robotic solutions for steel bridge
inspection requires human intervention to assist in the control and navigation.
In this paper, a control and navigation framework has been proposed for the
steel bridge inspection robot developed by the Advanced Robotics and Automation
(ARA)to facilitate autonomous real-time navigation and minimize human
intervention. The ARA robot is designed to work in two modes: mobile and
inch-worm. The robot uses mobile mode when moving on a plane surface and
inch-worm mode when jumping from one surface to the other. To allow the ARA
robot to switch between mobile and inch-worm modes, a switching controller is
developed with 3D point cloud data based. The surface detection algorithm is
proposed to allow the robot to check the availability of steel surfaces (plane,
area, and height) to determine the transformation from mobile mode to inch-worm
one. To have the robot safely navigate and visit all steel members of the
bridge, four algorithms are developed to process the data from a depth camera,
segment it into clusters, estimate the boundaries, construct a graph
representing the structure, generate the shortest inspection path with any
starting and ending points, and determine available robot configuration for
path planning. Experiments on steel bridge structures setup highlight the
effective performance of the algorithms, and the potential to apply to the ARA
robot to run on real bridge structures.
</p>
<a href="http://arxiv.org/abs/2102.00641" target="_blank">arXiv:2102.00641</a> [<a href="http://arxiv.org/pdf/2102.00641" target="_blank">pdf</a>]

<h2>An End-to-End Food Image Analysis System. (arXiv:2102.00645v1 [cs.CV])</h2>
<h3>Jiangpeng He, Runyu Mao, Zeman Shao, Janine L. Wright, Deborah A. Kerr, Carol J. Boushey, Fengqing Zhu</h3>
<p>Modern deep learning techniques have enabled advances in image-based dietary
assessment such as food recognition and food portion size estimation. Valuable
information on the types of foods and the amount consumed are crucial for
prevention of many chronic diseases. However, existing methods for automated
image-based food analysis are neither end-to-end nor are capable of processing
multiple tasks (e.g., recognition and portion estimation) together, making it
difficult to apply to real life applications. In this paper, we propose an
image-based food analysis framework that integrates food localization,
classification and portion size estimation. Our proposed framework is
end-to-end, i.e., the input can be an arbitrary food image containing multiple
food items and our system can localize each single food item with its
corresponding predicted food type and portion size. We also improve the single
food portion estimation by consolidating localization results with a food
energy distribution map obtained by conditional GAN to generate a four-channel
RGB-Distribution image. Our end-to-end framework is evaluated on a real life
food image dataset collected from a nutrition feeding study.
</p>
<a href="http://arxiv.org/abs/2102.00645" target="_blank">arXiv:2102.00645</a> [<a href="http://arxiv.org/pdf/2102.00645" target="_blank">pdf</a>]

<h2>Rescuing Deep Hashing from Dead Bits Problem. (arXiv:2102.00648v1 [cs.CV])</h2>
<h3>Shu Zhao, Dayan Wu, Yucan Zhou, Bo Li, Weiping Wang</h3>
<p>Deep hashing methods have shown great retrieval accuracy and efficiency in
large-scale image retrieval. How to optimize discrete hash bits is always the
focus in deep hashing methods. A common strategy in these methods is to adopt
an activation function, e.g. $\operatorname{sigmoid}(\cdot)$ or
$\operatorname{tanh}(\cdot)$, and minimize a quantization loss to approximate
discrete values. However, this paradigm may make more and more hash bits stuck
into the wrong saturated area of the activation functions and never escaped. We
call this problem "Dead Bits Problem~(DBP)". Besides, the existing quantization
loss will aggravate DBP as well. In this paper, we propose a simple but
effective gradient amplifier which acts before activation functions to
alleviate DBP. Moreover, we devise an error-aware quantization loss to further
alleviate DBP. It avoids the negative effect of quantization loss based on the
similarity between two images. The proposed gradient amplifier and error-aware
quantization loss are compatible with a variety of deep hashing methods.
Experimental results on three datasets demonstrate the efficiency of the
proposed gradient amplifier and the error-aware quantization loss.
</p>
<a href="http://arxiv.org/abs/2102.00648" target="_blank">arXiv:2102.00648</a> [<a href="http://arxiv.org/pdf/2102.00648" target="_blank">pdf</a>]

<h2>Forecasting Action through Contact Representations from First Person Video. (arXiv:2102.00649v1 [cs.CV])</h2>
<h3>Eadom Dessalene, Chinmaya Devaraj, Michael Maynord, Cornelia Fermuller, Yiannis Aloimonos</h3>
<p>Human actions involving hand manipulations are structured according to the
making and breaking of hand-object contact, and human visual understanding of
action is reliant on anticipation of contact as is demonstrated by pioneering
work in cognitive science. Taking inspiration from this, we introduce
representations and models centered on contact, which we then use in action
prediction and anticipation. We annotate a subset of the EPIC Kitchens dataset
to include time-to-contact between hands and objects, as well as segmentations
of hands and objects. Using these annotations we train the Anticipation Module,
a module producing Contact Anticipation Maps and Next Active Object
Segmentations - novel low-level representations providing temporal and spatial
characteristics of anticipated near future action. On top of the Anticipation
Module we apply Egocentric Object Manipulation Graphs (Ego-OMG), a framework
for action anticipation and prediction. Ego-OMG models longer term temporal
semantic relations through the use of a graph modeling transitions between
contact delineated action states. Use of the Anticipation Module within Ego-OMG
produces state-of-the-art results, achieving 1st and 2nd place on the unseen
and seen test sets, respectively, of the EPIC Kitchens Action Anticipation
Challenge, and achieving state-of-the-art results on the tasks of action
anticipation and action prediction over EPIC Kitchens. We perform ablation
studies over characteristics of the Anticipation Module to evaluate their
utility.
</p>
<a href="http://arxiv.org/abs/2102.00649" target="_blank">arXiv:2102.00649</a> [<a href="http://arxiv.org/pdf/2102.00649" target="_blank">pdf</a>]

<h2>Rethinking Soft Labels for Knowledge Distillation: A Bias-Variance Tradeoff Perspective. (arXiv:2102.00650v1 [cs.LG])</h2>
<h3>Helong Zhou, Liangchen Song, Jiajie Chen, Ye Zhou, Guoli Wang, Junsong Yuan, Qian Zhang</h3>
<p>Knowledge distillation is an effective approach to leverage a well-trained
network or an ensemble of them, named as the teacher, to guide the training of
a student network. The outputs from the teacher network are used as soft labels
for supervising the training of a new network. Recent studies
\citep{muller2019does,yuan2020revisiting} revealed an intriguing property of
the soft labels that making labels soft serves as a good regularization to the
student network. From the perspective of statistical learning, regularization
aims to reduce the variance, however how bias and variance change is not clear
for training with soft labels. In this paper, we investigate the bias-variance
tradeoff brought by distillation with soft labels. Specifically, we observe
that during training the bias-variance tradeoff varies sample-wisely. Further,
under the same distillation temperature setting, we observe that the
distillation performance is negatively associated with the number of some
specific samples, which are named as regularization samples since these samples
lead to bias increasing and variance decreasing. Nevertheless, we empirically
find that completely filtering out regularization samples also deteriorates
distillation performance. Our discoveries inspired us to propose the novel
weighted soft labels to help the network adaptively handle the sample-wise
bias-variance tradeoff. Experiments on standard evaluation benchmarks validate
the effectiveness of our method. Our code is available at
\url{https://github.com/bellymonster/Weighted-Soft-Label-Distillation}.
</p>
<a href="http://arxiv.org/abs/2102.00650" target="_blank">arXiv:2102.00650</a> [<a href="http://arxiv.org/pdf/2102.00650" target="_blank">pdf</a>]

<h2>Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning. (arXiv:2102.00655v1 [cs.LG])</h2>
<h3>Syed Zawad, Ahsan Ali, Pin-Yu Chen, Ali Anwar, Yi Zhou, Nathalie Baracaldo, Yuan Tian, Feng Yan</h3>
<p>Data heterogeneity has been identified as one of the key features in
federated learning but often overlooked in the lens of robustness to
adversarial attacks. This paper focuses on characterizing and understanding its
impact on backdooring attacks in federated learning through comprehensive
experiments using synthetic and the LEAF benchmarks. The initial impression
driven by our experimental results suggests that data heterogeneity is the
dominant factor in the effectiveness of attacks and it may be a redemption for
defending against backdooring as it makes the attack less efficient, more
challenging to design effective attack strategies, and the attack result also
becomes less predictable. However, with further investigations, we found data
heterogeneity is more of a curse than a redemption as the attack effectiveness
can be significantly boosted by simply adjusting the client-side backdooring
timing. More importantly,data heterogeneity may result in overfitting at the
local training of benign clients, which can be utilized by attackers to
disguise themselves and fool skewed-feature based defenses. In addition,
effective attack strategies can be made by adjusting attack data distribution.
Finally, we discuss the potential directions of defending the curses brought by
data heterogeneity. The results and lessons learned from our extensive
experiments and analysis offer new insights for designing robust federated
learning methods and systems
</p>
<a href="http://arxiv.org/abs/2102.00655" target="_blank">arXiv:2102.00655</a> [<a href="http://arxiv.org/pdf/2102.00655" target="_blank">pdf</a>]

<h2>Towards Speeding up Adversarial Training in Latent Spaces. (arXiv:2102.00662v1 [cs.LG])</h2>
<h3>Yaguan Qian, Qiqi Shao, Tengteng Yao, Bin Wang, Shaoning Zeng, Zhaoquan Gu, Wassim Swaileh</h3>
<p>Adversarial training is wildly considered as the most effective way to defend
against adversarial examples. However, existing adversarial training methods
consume unbearable time cost, since they need to generate adversarial examples
in the input space, which accounts for the main part of total time-consuming.
For speeding up the training process, we propose a novel adversarial training
method that does not need to generate real adversarial examples. We notice that
a clean example is closer to the decision boundary of the class with the second
largest logit component than any other class besides its own class. Thus, by
adding perturbations to logits to generate Endogenous Adversarial
Examples(EAEs) -- adversarial examples in the latent space, it can avoid
calculating gradients to speed up the training process. We further gain a deep
insight into the existence of EAEs by the theory of manifold. To guarantee the
added perturbation is within the range of constraint, we use statistical
distributions to select seed examples to craft EAEs. Extensive experiments are
conducted on CIFAR-10 and ImageNet, and the results show that compare with
state-of-the-art "Free" and "Fast" methods, our EAE adversarial training not
only shortens the training time, but also enhances the robustness of the model.
Moreover, the EAE adversarial training has little impact on the accuracy of
clean examples than the existing methods.
</p>
<a href="http://arxiv.org/abs/2102.00662" target="_blank">arXiv:2102.00662</a> [<a href="http://arxiv.org/pdf/2102.00662" target="_blank">pdf</a>]

<h2>Probabilistic Learning Vector Quantization on Manifold of Symmetric Positive Definite Matrices. (arXiv:2102.00667v1 [cs.LG])</h2>
<h3>Fengzhen Tang, Haifeng Feng, Peter Tino, Bailu Si, Daxiong Ji</h3>
<p>In this paper, we develop a new classification method for manifold-valued
data in the framework of probabilistic learning vector quantization. In many
classification scenarios, the data can be naturally represented by symmetric
positive definite matrices, which are inherently points that live on a curved
Riemannian manifold. Due to the non-Euclidean geometry of Riemannian manifolds,
traditional Euclidean machine learning algorithms yield poor results on such
data. In this paper, we generalize the probabilistic learning vector
quantization algorithm for data points living on the manifold of symmetric
positive definite matrices equipped with Riemannian natural metric
(affine-invariant metric). By exploiting the induced Riemannian distance, we
derive the probabilistic learning Riemannian space quantization algorithm,
obtaining the learning rule through Riemannian gradient descent. Empirical
investigations on synthetic data, image data , and motor imagery EEG data
demonstrate the superior performance of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.00667" target="_blank">arXiv:2102.00667</a> [<a href="http://arxiv.org/pdf/2102.00667" target="_blank">pdf</a>]

<h2>Twice Mixing: A Rank Learning based Quality Assessment Approach for Underwater Image Enhancement. (arXiv:2102.00670v1 [cs.CV])</h2>
<h3>Zhenqi Fu, Xueyang Fu, Yue Huang, Xinghao Ding</h3>
<p>To improve the quality of underwater images, various kinds of underwater
image enhancement (UIE) operators have been proposed during the past few years.
However, the lack of effective objective evaluation methods limits the further
development of UIE techniques. In this paper, we propose a novel rank learning
guided no-reference quality assessment method for UIE. Our approach, termed
Twice Mixing, is motivated by the observation that a mid-quality image can be
generated by mixing a high-quality image with its low-quality version. Typical
mixup algorithms linearly interpolate a given pair of input data. However, the
human visual system is non-uniformity and non-linear in processing images.
Therefore, instead of directly training a deep neural network based on the
mixed images and their absolute scores calculated by linear combinations, we
propose to train a Siamese Network to learn their quality rankings. Twice
Mixing is trained based on an elaborately formulated self-supervision
mechanism. Specifically, before each iteration, we randomly generate two mixing
ratios which will be employed for both generating virtual images and guiding
the network training. In the test phase, a single branch of the network is
extracted to predict the quality rankings of different UIE outputs. We conduct
extensive experiments on both synthetic and real-world datasets. Experimental
results demonstrate that our approach outperforms the previous methods
significantly.
</p>
<a href="http://arxiv.org/abs/2102.00670" target="_blank">arXiv:2102.00670</a> [<a href="http://arxiv.org/pdf/2102.00670" target="_blank">pdf</a>]

<h2>Direct and Indirect Communication in Multi-Human Multi-Robot Interaction. (arXiv:2102.00672v1 [cs.RO])</h2>
<h3>Jayam Patel, Tyagaraja Ramaswamy, Zhi Li, Carlo Pinciroli</h3>
<p>How can multiple humans interact with multiple robots? The goal of our
research is to create an effective interface that allows multiple operators to
collaboratively control teams of robots in complex tasks. In this paper, we
focus on a key aspect that affects our exploration of the design space of
human-robot interfaces -- inter-human communication. More specifically, we
study the impact of direct and indirect communication on several metrics, such
as awareness, workload, trust, and interface usability. In our experiments, the
participants can engage directly through verbal communication, or indirectly by
representing their actions and intentions through our interface. We report the
results of a user study based on a collective transport task involving 18 human
subjects and 9 robots. Our study suggests that combining both direct and
indirect communication is the best approach for effective multi-human /
multi-robot interaction.
</p>
<a href="http://arxiv.org/abs/2102.00672" target="_blank">arXiv:2102.00672</a> [<a href="http://arxiv.org/pdf/2102.00672" target="_blank">pdf</a>]

<h2>Autonomous Navigation through intersections with Graph ConvolutionalNetworks and Conditional Imitation Learning for Self-driving Cars. (arXiv:2102.00675v1 [cs.RO])</h2>
<h3>Xiaodong Mei, Yuxiang Sun, Yuying Chen, Congcong Liu, Ming Liu</h3>
<p>In autonomous driving, navigation through unsignaled intersections with many
traffic participants moving around is a challenging task. To provide a solution
to this problem, we propose a novel branched network G-CIL for the navigation
policy learning. Specifically, we firstly represent such dynamic environments
as graph-structured data and propose an effective strategy for edge definition
to aggregate surrounding information for the ego-vehicle. Then graph
convolutional neural networks are used as the perception module to capture
global and geometric features from the environment. To generate safe and
efficient navigation policy, we further incorporate it with conditional
imitation learning algorithm, to learn driving behaviors directly from expert
demonstrations. Our proposed network is capable of handling a varying number of
surrounding vehicles and generating optimal control actions (e.g., steering
angle and throttle) according to the given high-level commands (e.g., turn left
towards the global goal). Evaluations on unsignaled intersections with various
traffic densities demonstrate that our end-to-end trainable neural network
outperforms the baselines with higher success rate and shorter navigation time.
</p>
<a href="http://arxiv.org/abs/2102.00675" target="_blank">arXiv:2102.00675</a> [<a href="http://arxiv.org/pdf/2102.00675" target="_blank">pdf</a>]

<h2>Underwater Image Enhancement via Learning Water Type Desensitized Representations. (arXiv:2102.00676v1 [cs.CV])</h2>
<h3>Zhenqi Fu, Xiaopeng Lin, Wu Wang, Yue Huang, Xinghao Ding</h3>
<p>For underwater applications, the effects of light absorption and scattering
result in image degradation. Moreover, the complex and changeable imaging
environment makes it difficult to provide a universal enhancement solution to
cope with the diversity of water types. In this letter, we present a novel
underwater image enhancement (UIE) framework termed SCNet to address the above
issues. SCNet is based on normalization schemes across both spatial and channel
dimensions with the key idea of learning water type desensitized features.
Considering the diversity of degradation is mainly rooted in the strong
correlation among pixels, we apply whitening to de-correlates activations
across spatial dimensions for each instance in a mini-batch. We also eliminate
channel-wise correlation by standardizing and re-injecting the first two
moments of the activations across channels. The normalization schemes of
spatial and channel dimensions are performed at each scale of the U-Net to
obtain multi-scale representations. With such latent encodings, the decoder can
easily reconstruct the clean signal, and unaffected by the distortion types
caused by the water. Experimental results on two real-world UIE datasets show
that the proposed approach can successfully enhance images with diverse water
types, and achieves competitive performance in visual quality improvement.
</p>
<a href="http://arxiv.org/abs/2102.00676" target="_blank">arXiv:2102.00676</a> [<a href="http://arxiv.org/pdf/2102.00676" target="_blank">pdf</a>]

<h2>Binary Classification from Multiple Unlabeled Datasets via Surrogate Set Classification. (arXiv:2102.00678v1 [cs.LG])</h2>
<h3>Shida Lei, Nan Lu, Gang Niu, Issei Sato, Masashi Sugiyama</h3>
<p>To cope with high annotation costs, training a classifier only from weakly
supervised data has attracted a great deal of attention these days. Among
various approaches, strengthening supervision from completely unsupervised
classification is a promising direction, which typically employs class priors
as the only supervision and trains a binary classifier from unlabeled (U)
datasets. While existing risk-consistent methods are theoretically grounded
with high flexibility, they can learn only from two U sets. In this paper, we
propose a new approach for binary classification from m U-sets for $m\ge2$. Our
key idea is to consider an auxiliary classification task called surrogate set
classification (SSC), which is aimed at predicting from which U set each
observed data is drawn. SSC can be solved by a standard (multi-class)
classification method, and we use the SSC solution to obtain the final binary
classifier through a certain linear-fractional transformation. We built our
method in a flexible and efficient end-to-end deep learning framework and prove
it to be classifier-consistent. Through experiments, we demonstrate the
superiority of our proposed method over state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.00678" target="_blank">arXiv:2102.00678</a> [<a href="http://arxiv.org/pdf/2102.00678" target="_blank">pdf</a>]

<h2>A NIR-to-VIS face recognition via part adaptive and relation attention module. (arXiv:2102.00689v1 [cs.CV])</h2>
<h3>Rushuang Xu, MyeongAh Cho, Sangyoun Lee</h3>
<p>In the face recognition application scenario, we need to process facial
images captured in various conditions, such as at night by near-infrared (NIR)
surveillance cameras. The illumination difference between NIR and visible-light
(VIS) causes a domain gap between facial images, and the variations in pose and
emotion also make facial matching more difficult. Heterogeneous face
recognition (HFR) has difficulties in domain discrepancy, and many studies have
focused on extracting domain-invariant features, such as facial part relational
information. However, when pose variation occurs, the facial component position
changes, and a different part relation is extracted. In this paper, we propose
a part relation attention module that crops facial parts obtained through a
semantic mask and performs relational modeling using each of these
representative features. Furthermore, we suggest component adaptive triplet
loss function using adaptive weights for each part to reduce the intra-class
identity regardless of the domain as well as pose. Finally, our method exhibits
a performance improvement in the CASIA NIR-VIS 2.0 and achieves superior result
in the BUAA-VisNir with large pose and emotion variations.
</p>
<a href="http://arxiv.org/abs/2102.00689" target="_blank">arXiv:2102.00689</a> [<a href="http://arxiv.org/pdf/2102.00689" target="_blank">pdf</a>]

<h2>Ground-aware Monocular 3D Object Detection for Autonomous Driving. (arXiv:2102.00690v1 [cs.CV])</h2>
<h3>Yuxuan Liu, Yuan Yixuan, Ming Liu</h3>
<p>Estimating the 3D position and orientation of objects in the environment with
a single RGB camera is a critical and challenging task for low-cost urban
autonomous driving and mobile robots. Most of the existing algorithms are based
on the geometric constraints in 2D-3D correspondence, which stems from generic
6D object pose estimation. We first identify how the ground plane provides
additional clues in depth reasoning in 3D detection in driving scenes. Based on
this observation, we then improve the processing of 3D anchors and introduce a
novel neural network module to fully utilize such application-specific priors
in the framework of deep learning. Finally, we introduce an efficient neural
network embedded with the proposed module for 3D object detection. We further
verify the power of the proposed module with a neural network designed for
monocular depth prediction. The two proposed networks achieve state-of-the-art
performances on the KITTI 3D object detection and depth prediction benchmarks,
respectively. The code will be published in
https://www.github.com/Owen-Liuyuxuan/visualDet3D
</p>
<a href="http://arxiv.org/abs/2102.00690" target="_blank">arXiv:2102.00690</a> [<a href="http://arxiv.org/pdf/2102.00690" target="_blank">pdf</a>]

<h2>Spatio-temporal Weather Forecasting and Attention Mechanism on Convolutional LSTMs. (arXiv:2102.00696v1 [cs.LG])</h2>
<h3>Selim Furkan Tekin, Oguzhan Karaahmetoglu, Fatih Ilhan, Ismail Balaban, Suleyman Serdar Kozat</h3>
<p>Numerical weather forecasting on high-resolution physical models consume
hours of computations on supercomputers. Application of deep learning and
machine learning methods in forecasting revealed new solutions in this area. In
this paper, we forecast high-resolution numeric weather data using both input
weather data and observations by providing a novel deep learning architecture.
We formulate the problem as spatio-temporal prediction. Our model is composed
of Convolutional Long-short Term Memory, and Convolutional Neural Network units
with encoder-decoder structure. We enhance the short-long term performance and
interpretability with an attention and a context matcher mechanism. We perform
experiments on high-scale, real-life, benchmark numerical weather dataset, ERA5
hourly data on pressure levels, and forecast the temperature. The results show
significant improvements in capturing both spatial and temporal correlations
with attention matrices focusing on different parts of the input series. Our
model obtains the best validation and the best test score among the baseline
models, including ConvLSTM forecasting network and U-Net. We provide
qualitative and quantitative results and show that our model forecasts 10 time
steps with 3 hour frequency with an average of 2 degrees error. Our code and
the data are publicly available.
</p>
<a href="http://arxiv.org/abs/2102.00696" target="_blank">arXiv:2102.00696</a> [<a href="http://arxiv.org/pdf/2102.00696" target="_blank">pdf</a>]

<h2>A reproducibility study of "Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space". (arXiv:2102.00700v1 [cs.LG])</h2>
<h3>Kevin Maik Jablonka, Fergus Mcilwaine, Susana Garcia, Berend Smit, Brian Yoo</h3>
<p>Nigam et al. reported a genetic algorithm (GA) utilizing the SELFIES
representation and also propose an adaptive, neural network-based, penalty that
is supposed to improve the diversity of the generated molecules. The main
claims of the paper are that this GA outperforms other generative techniques
(as measured by the penalized logP) and that a neural network-based adaptive
penalty increases the diversity of the generated molecules. In this work, we
investigated the reproducibility of their claims.

Overall, we were able to reproduce comparable results using the SELFIES-based
GA, but mostly by exploiting deficiencies of the (easily optimizable) fitness
function (i.e., generating long, sulfur containing, chains). In addition, we
also reproduce that the discriminator can be used to bias the generation of
molecules to ones that are similar to the reference set.

In addition, we also attempted to quantify the evolution of the diversity,
understand the influence of some hyperparameters, and propose improvements to
the adaptive penalty.
</p>
<a href="http://arxiv.org/abs/2102.00700" target="_blank">arXiv:2102.00700</a> [<a href="http://arxiv.org/pdf/2102.00700" target="_blank">pdf</a>]

<h2>Face Recognition Techniques: A Survey. (arXiv:1803.07288v6 [cs.CV] UPDATED)</h2>
<h3>Raunak Dave, Ankit Vyas, Nikita P Desai</h3>
<p>Nowadays research has expanded to extracting auxiliary information from
various biometric techniques like fingerprints, face, iris, palm and voice .
This information contains some major features like gender, age, beard,
mustache, scars, height, hair, skin color, glasses, weight, facial marks and
tattoos. All this information contributes strongly to identification of human.
The major challenges that come across face recognition are to find age &amp; gender
of the person. This paper contributes a survey of various face recognition
techniques for finding the age and gender. The existing techniques are
discussed based on their performances. This paper also provides future
directions for further research.
</p>
<a href="http://arxiv.org/abs/1803.07288" target="_blank">arXiv:1803.07288</a> [<a href="http://arxiv.org/pdf/1803.07288" target="_blank">pdf</a>]

<h2>Crick-net: A Convolutional Neural Network based Classification Approach for Detecting Waist High No Balls in Cricket. (arXiv:1805.05974v2 [cs.CV] UPDATED)</h2>
<h3>Md. Harun-Ur-Rashid, Shekina Khatun, Mehe Zabin Trisha, Nafis Neehal, Md. Zahid Hasan</h3>
<p>Cricket is undoubtedly one of the most popular games in this modern era. As
human beings are prone to error, there remains a constant need for automated
analysis and decision making of different events in this game. Simultaneously,
with advent and advances in Artificial Intelligence and Computer Vision,
application of these two in different domains has become an emerging trend.
Applying several computer vision techniques in analyzing different Cricket
events and automatically coming into decisions has become popular in recent
days. In this paper, we have deployed a CNN based classification method with
Inception V3 in order to automatically detect and differentiate waist high no
balls with fair balls. Our approach achieves an overall average accuracy of 88%
with a fairly low cross-entropy value.
</p>
<a href="http://arxiv.org/abs/1805.05974" target="_blank">arXiv:1805.05974</a> [<a href="http://arxiv.org/pdf/1805.05974" target="_blank">pdf</a>]

<h2>Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network. (arXiv:1808.03314v9 [cs.LG] UPDATED)</h2>
<h3>Alex Sherstinsky</h3>
<p>Because of their effectiveness in broad practical applications, LSTM networks
have received a wealth of coverage in scientific journals, technical blogs, and
implementation guides. However, in most articles, the inference formulas for
the LSTM network and its parent, RNN, are stated axiomatically, while the
training formulas are omitted altogether. In addition, the technique of
"unrolling" an RNN is routinely presented without justification throughout the
literature. The goal of this paper is to explain the essential RNN and LSTM
fundamentals in a single document. Drawing from concepts in signal processing,
we formally derive the canonical RNN formulation from differential equations.
We then propose and prove a precise statement, which yields the RNN unrolling
technique. We also review the difficulties with training the standard RNN and
address them by transforming the RNN into the "Vanilla LSTM" network through a
series of logical arguments. We provide all equations pertaining to the LSTM
system together with detailed descriptions of its constituent entities. Albeit
unconventional, our choice of notation and the method for presenting the LSTM
system emphasizes ease of understanding. As part of the analysis, we identify
new opportunities to enrich the LSTM system and incorporate these extensions
into the Vanilla LSTM network, producing the most general LSTM variant to date.
The target reader has already been exposed to RNNs and LSTM networks through
numerous available resources and is open to an alternative pedagogical
approach. A Machine Learning practitioner seeking guidance for implementing our
new augmented LSTM model in software for experimentation and research will find
the insights and derivations in this tutorial valuable as well.
</p>
<a href="http://arxiv.org/abs/1808.03314" target="_blank">arXiv:1808.03314</a> [<a href="http://arxiv.org/pdf/1808.03314" target="_blank">pdf</a>]

<h2>Learning Tractable Probabilistic Models for Moral Responsibility and Blame. (arXiv:1810.03736v3 [cs.AI] UPDATED)</h2>
<h3>Lewis Hammond, Vaishak Belle</h3>
<p>Moral responsibility is a major concern in autonomous systems, with
applications ranging from self-driving cars to kidney exchanges. Although there
have been recent attempts to formalise responsibility and blame, among similar
notions, the problem of learning within these formalisms has been unaddressed.
From the viewpoint of such systems, the urgent questions are: (a) How can
models of moral scenarios and blameworthiness be extracted and learnt
automatically from data? (b) How can judgements be computed effectively and
efficiently, given the split-second decision points faced by some systems? By
building on constrained tractable probabilistic learning, we propose and
implement a hybrid (between data-driven and rule-based methods) learning
framework for inducing models of such scenarios automatically from data and
reasoning tractably from them. We report on experiments that compare our system
with human judgement in three illustrative domains: lung cancer staging,
teamwork management, and trolley problems.
</p>
<a href="http://arxiv.org/abs/1810.03736" target="_blank">arXiv:1810.03736</a> [<a href="http://arxiv.org/pdf/1810.03736" target="_blank">pdf</a>]

<h2>Low-Rank Semidefinite Programs via Bilinear Factorization. (arXiv:1811.01198v6 [cs.LG] UPDATED)</h2>
<h3>En-Liang Hu</h3>
<p>Many machine learning problems can be reduced to learning a low-rank positive
semidefinite matrix (denoted as $Z$), which encounters semidefinite program
(SDP). Existing SDP solvers are often expensive for large-scale learning. To
avoid directly solving SDP, some works convert SDP into a nonconvex program by
factorizing $Z$ \textit{quadraticly} as $XX^\top$. However, this would bring
higher-order nonlinearity, resulting in scarcity of structure in subsequent
optimization. In this paper, we propose a novel surrogate for SDP learning, in
which the structure of subproblem is exploited. More specifically, we surrogate
unconstrained SDP by a biconvex problem, through factorizing $Z$
\textit{bilinearly} as $XY^\top$ and using a Courant penalty to penalize the
difference of $X$ and $Y$, in which the resultant subproblems in terms of $X$
and $Y$ are convex respectively. Furthermore, we provide a theoretical bound
for the associated penalty parameter under the assumption that the subobjective
function of $X$ or $Y$ is $L$-Lipschitz-smooth and $\sigma$-strongly convex,
such that the proposed surrogate will solve the original SDP when the penalty
parameter is larger than this bound (that is $\gamma&gt;\frac{1}{4}(L-\sigma)$).
Experiments on two SDP-related applications demonstrate that the proposed
algorithm is as accurate as the state-of-the-art, but is faster on large-scale
learning.
</p>
<a href="http://arxiv.org/abs/1811.01198" target="_blank">arXiv:1811.01198</a> [<a href="http://arxiv.org/pdf/1811.01198" target="_blank">pdf</a>]

<h2>Efficient Reinforcement Learning for StarCraft by Abstract Forward Models and Transfer Learning. (arXiv:1903.00715v3 [cs.LG] UPDATED)</h2>
<h3>Ruo-Ze Liu, Haifeng Guo, Xiaozhong Ji, Yang Yu, Zhen-Jia Pang, Zitai Xiao, Yuzhou Wu, Tong Lu</h3>
<p>Injecting human knowledge is an effective way to accelerate reinforcement
learning (RL). However, these methods are underexplored. This paper presents
our discovery that an abstract forward model (Thought-game (TG)) combined with
transfer learning is an effective way. We take StarCraft II as the study
environment. With the help of a designed TG, the agent can learn a 99\%
win-rate on a 64$\times$64 map against the Level-7 built-in AI, using only 1.08
hours in a single commercial machine. We also show that the TG method is not as
restrictive as it was thought to be. It can work with roughly designed TGs, and
can also be useful when the environment changes. Comparing with previous
model-based RL, we show TG is more effective. We also present a TG hypothesis
that gives the influence of fidelity levels of TG. For real games that have
unequal state and action spaces, we proposed a novel XfrNet of which usefulness
is validated while achieving a 90\% win-rate against the cheating Level-10 AI.
We argue the TG method might shed light on further studies of efficient RL with
human knowledge.
</p>
<a href="http://arxiv.org/abs/1903.00715" target="_blank">arXiv:1903.00715</a> [<a href="http://arxiv.org/pdf/1903.00715" target="_blank">pdf</a>]

<h2>Adversarial Learning of Disentangled and Generalizable Representations for Visual Attributes. (arXiv:1904.04772v3 [cs.CV] UPDATED)</h2>
<h3>James Oldfield, Yannis Panagakis, Mihalis A. Nicolaou</h3>
<p>Recently, a multitude of methods for image-to-image translation have
demonstrated impressive results on problems such as multi-domain or
multi-attribute transfer. The vast majority of such works leverages the
strengths of adversarial learning and deep convolutional autoencoders to
achieve realistic results by well-capturing the target data distribution.
Nevertheless, the most prominent representatives of this class of methods do
not facilitate semantic structure in the latent space, and usually rely on
binary domain labels for test-time transfer. This leads to rigid models, unable
to capture the variance of each domain label. In this light, we propose a novel
adversarial learning method that (i) facilitates the emergence of latent
structure by semantically disentangling sources of variation, and (ii)
encourages learning generalizable, continuous, and transferable latent codes
that enable flexible attribute mixing. This is achieved by introducing a novel
loss function that encourages representations to result in uniformly
distributed class posteriors for disentangled attributes. In tandem with an
algorithm for inducing generalizable properties, the resulting representations
can be utilized for a variety of tasks such as intensity-preserving
multi-attribute image translation and synthesis, without requiring labelled
test data. We demonstrate the merits of the proposed method by a set of
qualitative and quantitative experiments on popular databases such as MultiPIE,
RaFD, and BU-3DFE, where our method outperforms other, state-of-the-art methods
in tasks such as intensity-preserving multi-attribute transfer and synthesis.
</p>
<a href="http://arxiv.org/abs/1904.04772" target="_blank">arXiv:1904.04772</a> [<a href="http://arxiv.org/pdf/1904.04772" target="_blank">pdf</a>]

<h2>Leveraging Orientation for Weakly Supervised Object Detection with Application to Firearm Localization. (arXiv:1904.10032v2 [cs.CV] UPDATED)</h2>
<h3>Javed Iqbal, Muhammad Akhtar Munir, Arif Mahmood, Afsheen Rafaqat Ali, Mohsen Ali</h3>
<p>Automatic detection of firearms is important for enhancing the security and
safety of people, however, it is a challenging task owing to the wide
variations in shape, size, and appearance of firearms. Also, most of the
generic object detectors process axis-aligned rectangular areas though, a thin
and long rifle may actually cover only a small percentage of that area and the
rest may contain irrelevant details suppressing the required object signatures.
To handle these challenges, we propose a weakly supervised Orientation Aware
Object Detection (OAOD) algorithm which learns to detect oriented object
bounding boxes (OBB) while using AxisAligned Bounding Boxes (AABB) for
training. The proposed OAOD is different from the existing oriented object
detectors which strictly require OBB during training which may not always be
present. The goal of training on AABB and detection of OBB is achieved by
employing a multistage scheme, with Stage-1 predicting the AABB and Stage-2
predicting OBB. In-between the two stages, the oriented proposal generation
module along with the object aligned RoI pooling is designed to extract
features based on the predicted orientation and to make these features
orientation invariant. A diverse and challenging dataset consisting of eleven
thousand images is also proposed for firearm detection which is manually
annotated for firearm classification and localization. The proposed ITU Firearm
dataset (ITUF) contains a wide range of guns and rifles. The OAOD algorithm is
evaluated on the ITUF dataset and compared with current state-of-the-art object
detectors, including fully supervised oriented object detectors. OAOD has
outperformed both types of object detectors with a significant margin. The
experimental results (mAP: 88.3 on AABB &amp; mAP: 77.5 on OBB) demonstrate the
effectiveness of the proposed algorithm for firearm detection.
</p>
<a href="http://arxiv.org/abs/1904.10032" target="_blank">arXiv:1904.10032</a> [<a href="http://arxiv.org/pdf/1904.10032" target="_blank">pdf</a>]

<h2>Design Space Exploration as Quantified Satisfaction. (arXiv:1905.02303v3 [cs.AI] UPDATED)</h2>
<h3>Alexander Feldman, Johan de Kleer, Ion Matei</h3>
<p>We present novel algorithms for design and design space exploration. The
designs discovered by these algorithms are compositions of function types
specified in component libraries. Our algorithms reduce the design problem to
quantified satisfiability and use advanced solvers to find solutions that
represent useful systems.

The algorithms we present in this paper are sound and complete and are
guaranteed to discover correct designs of optimal size, if they exist. We apply
our method to the design of Boolean systems and discover new and more optimal
classical digital and quantum circuits for common arithmetic functions such as
addition and multiplication.

The performance of our algorithms is evaluated through extensive
experimentation. We created a benchmark consisting of specifications of
scalable synthetic digital circuits and real-world mirochips. We have generated
multiple circuits functionally equivalent to the ones in the benchmark. The
quantified satisfiability method shows more than four orders of magnitude
speed-up, compared to a generate and test method that enumerates all
non-isomorphic circuit topologies.

Our approach generalizes circuit optimization. It uses arbitrary component
libraries and has applications to areas such as digital circuit design,
diagnostics, abductive reasoning, test vector generation, and combinatorial
optimization.
</p>
<a href="http://arxiv.org/abs/1905.02303" target="_blank">arXiv:1905.02303</a> [<a href="http://arxiv.org/pdf/1905.02303" target="_blank">pdf</a>]

<h2>On The Radon-Nikodym Spectral Approach With Optimal Clustering. (arXiv:1906.00460v13 [cs.LG] UPDATED)</h2>
<h3>Vladislav Gennadievich Malyshkin</h3>
<p>Problems of interpolation, classification, and clustering are considered. In
the tenets of Radon--Nikodym approach $\langle f(\mathbf{x})\psi^2 \rangle /
\langle\psi^2\rangle$, where the $\psi(\mathbf{x})$ is a linear function on
input attributes, all the answers are obtained from a generalized eigenproblem
$|f|\psi^{[i]}\rangle = \lambda^{[i]} |\psi^{[i]}\rangle$. The solution to the
interpolation problem is a regular Radon-Nikodym derivative. The solution to
the classification problem requires prior and posterior probabilities that are
obtained using the Lebesgue quadrature[1] technique. Whereas in a Bayesian
approach new observations change only outcome probabilities, in the
Radon-Nikodym approach not only outcome probabilities but also the probability
space $|\psi^{[i]}\rangle$ change with new observations. This is a remarkable
feature of the approach: both the probabilities and the probability space are
constructed from the data. The Lebesgue quadrature technique can be also
applied to the optimal clustering problem. The problem is solved by
constructing a Gaussian quadrature on the Lebesgue measure. A distinguishing
feature of the Radon-Nikodym approach is the knowledge of the invariant group:
all the answers are invariant relatively any non-degenerated linear transform
of input vector $\mathbf{x}$ components. A software product implementing the
algorithms of interpolation, classification, and optimal clustering is
available from the authors.
</p>
<a href="http://arxiv.org/abs/1906.00460" target="_blank">arXiv:1906.00460</a> [<a href="http://arxiv.org/pdf/1906.00460" target="_blank">pdf</a>]

<h2>ACNe: Attentive Context Normalization for Robust Permutation-Equivariant Learning. (arXiv:1907.02545v5 [cs.CV] UPDATED)</h2>
<h3>Weiwei Sun, Wei Jiang, Eduard Trulls, Andrea Tagliasacchi, Kwang Moo Yi</h3>
<p>Many problems in computer vision require dealing with sparse, unordered data
in the form of point clouds. Permutation-equivariant networks have become a
popular solution-they operate on individual data points with simple perceptrons
and extract contextual information with global pooling. This can be achieved
with a simple normalization of the feature maps, a global operation that is
unaffected by the order. In this paper, we propose Attentive Context
Normalization (ACN), a simple yet effective technique to build
permutation-equivariant networks robust to outliers. Specifically, we show how
to normalize the feature maps with weights that are estimated within the
network, excluding outliers from this normalization. We use this mechanism to
leverage two types of attention: local and global-by combining them, our method
is able to find the essential data points in high-dimensional space to solve a
given task. We demonstrate through extensive experiments that our approach,
which we call Attentive Context Networks (ACNe), provides a significant leap in
performance compared to the state-of-the-art on camera pose estimation, robust
fitting, and point cloud classification under noise and outliers. Source code:
https://github.com/vcg-uvic/acne.
</p>
<a href="http://arxiv.org/abs/1907.02545" target="_blank">arXiv:1907.02545</a> [<a href="http://arxiv.org/pdf/1907.02545" target="_blank">pdf</a>]

<h2>Artificial Intelligence: A Child's Play. (arXiv:1907.04659v3 [cs.AI] UPDATED)</h2>
<h3>Ravi Kashyap</h3>
<p>We discuss the objectives of any endeavor in creating artificial
intelligence, AI, and provide a possible alternative. Intelligence might be an
unintended consequence of curiosity left to roam free, best exemplified by a
frolicking infant. This suggests that our attempts at AI could have been
misguided. What we actually need to strive for can be termed artificial
curiosity, AC, and intelligence happens as a consequence of those efforts. For
this unintentional yet welcome aftereffect to set in a foundational list of
guiding principles needs to be present. We start with the intuition for this
line of reasoning and formalize it with a series of definitions, assumptions,
ingredients, models and iterative improvements that will be necessary to make
the incubation of intelligence a reality. Our discussion provides conceptual
modifications to the Turing Test and to Searle's Chinese room argument. We
discuss the future implications for society as AI becomes an integral part of
life.

We provide a road-map for creating intelligence with the technical parts
relegated to the appendix so that the article is accessible to a wide audience.
The central techniques in our formal approach to creating intelligence draw
upon tools and concepts widely used in physics, cognitive science, psychology,
evolutionary biology, statistics, linguistics, communication systems, pattern
recognition, marketing, economics, finance, information science and
computational theory highlighting that solutions for creating artificial
intelligence have to transcend the artificial barriers between various fields
and be highly multi-disciplinary.
</p>
<a href="http://arxiv.org/abs/1907.04659" target="_blank">arXiv:1907.04659</a> [<a href="http://arxiv.org/pdf/1907.04659" target="_blank">pdf</a>]

<h2>$t$-$k$-means: A Robust and Stable $k$-means Variant. (arXiv:1907.07442v4 [cs.LG] UPDATED)</h2>
<h3>Yiming Li, Yang Zhang, Qingtao Tang, Weipeng Huang, Yong Jiang, Shu-Tao Xia</h3>
<p>$k$-means algorithm is one of the most classical clustering methods, which
has been widely and successfully used in signal processing. However, due to the
thin-tailed property of the Gaussian distribution, $k$-means algorithm suffers
from relatively poor performance on the dataset containing heavy-tailed data or
outliers. Besides, standard $k$-means algorithm also has relatively weak
stability, $i.e.$ its results have a large variance, which reduces its
credibility. In this paper, we propose a robust and stable $k$-means variant,
dubbed the $t$-$k$-means, as well as its fast version to alleviate those
problems. Theoretically, we derive the $t$-$k$-means and analyze its robustness
and stability from the aspect of the loss function and the expression of the
clustering center, respectively. Extensive experiments are also conducted,
which verify the effectiveness and efficiency of the proposed method. The code
for reproducing main results is available at
\url{https://github.com/THUYimingLi/t-k-means}.
</p>
<a href="http://arxiv.org/abs/1907.07442" target="_blank">arXiv:1907.07442</a> [<a href="http://arxiv.org/pdf/1907.07442" target="_blank">pdf</a>]

<h2>Quadratic Surface Support Vector Machine with L1 Norm Regularization. (arXiv:1908.08616v2 [cs.LG] UPDATED)</h2>
<h3>Ahmad Mousavi, Zheming Gao, Lanshan Han, Alvin Lim</h3>
<p>We propose $\ell_1$ norm regularized quadratic surface support vector machine
models for binary classification in supervised learning. We establish their
desired theoretical properties, including the existence and uniqueness of the
optimal solution, reduction to the standard SVMs over (almost) linearly
separable data sets, and detection of true sparsity pattern over (almost)
quadratically separable data sets if the penalty parameter of $\ell_1$ norm is
large enough. We also demonstrate their promising practical efficiency by
conducting various numerical experiments on both synthetic and publicly
available benchmark data sets.
</p>
<a href="http://arxiv.org/abs/1908.08616" target="_blank">arXiv:1908.08616</a> [<a href="http://arxiv.org/pdf/1908.08616" target="_blank">pdf</a>]

<h2>EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations. (arXiv:1911.09265v2 [cs.CV] UPDATED)</h2>
<h3>Xiao Wang, Daisuke Kihara, Jiebo Luo, Guo-Jun Qi</h3>
<p>Deep neural networks have been successfully applied to many real-world
applications. However, such successes rely heavily on large amounts of labeled
data that is expensive to obtain. Recently, many methods for semi-supervised
learning have been proposed and achieved excellent performance. In this study,
we propose a new EnAET framework to further improve existing semi-supervised
methods with self-supervised information. To our best knowledge, all current
semi-supervised methods improve performance with prediction consistency and
confidence ideas. We are the first to explore the role of {\bf self-supervised}
representations in {\bf semi-supervised} learning under a rich family of
transformations. Consequently, our framework can integrate the self-supervised
information as a regularization term to further improve {\it all} current
semi-supervised methods. In the experiments, we use MixMatch, which is the
current state-of-the-art method on semi-supervised learning, as a baseline to
test the proposed EnAET framework. Across different datasets, we adopt the same
hyper-parameters, which greatly improves the generalization ability of the
EnAET framework. Experiment results on different datasets demonstrate that the
proposed EnAET framework greatly improves the performance of current
semi-supervised algorithms. Moreover, this framework can also improve {\bf
supervised learning} by a large margin, including the extremely challenging
scenarios with only 10 images per class. The code and experiment records are
available in \url{https://github.com/maple-research-lab/EnAET}.
</p>
<a href="http://arxiv.org/abs/1911.09265" target="_blank">arXiv:1911.09265</a> [<a href="http://arxiv.org/pdf/1911.09265" target="_blank">pdf</a>]

<h2>Stigmergic Independent Reinforcement Learning for Multi-Agent Collaboration. (arXiv:1911.12504v3 [cs.AI] UPDATED)</h2>
<h3>Xing Xu, Rongpeng Li, Zhifeng Zhao, Honggang Zhang</h3>
<p>With the rapid evolution of wireless mobile devices, there emerges an
increased need to design effective collaboration mechanisms between intelligent
agents, so as to gradually approach the final collective objective through
continuously learning from the environment based on their individual
observations. In this regard, independent reinforcement learning (IRL) is often
deployed in multi-agent collaboration to alleviate the problem of a
non-stationary learning environment. However, behavioral strategies of
intelligent agents in IRL can only be formulated upon their local individual
observations of the global environment, and appropriate communication
mechanisms must be introduced to reduce their behavioral localities. In this
paper, we address the problem of communication between intelligent agents in
IRL by jointly adopting mechanisms with two different scales. For the large
scale, we introduce the stigmergy mechanism as an indirect communication bridge
between independent learning agents, and carefully design a mathematical method
to indicate the impact of digital pheromone. For the small scale, we propose a
conflict-avoidance mechanism between adjacent agents by implementing an
additionally embedded neural network to provide more opportunities for
participants with higher action priorities. In addition, we present a federal
training method to effectively optimize the neural network of each agent in a
decentralized manner. Finally, we establish a simulation scenario in which a
number of mobile agents in a certain area move automatically to form a
specified target shape. Extensive simulations demonstrate the effectiveness of
our proposed method.
</p>
<a href="http://arxiv.org/abs/1911.12504" target="_blank">arXiv:1911.12504</a> [<a href="http://arxiv.org/pdf/1911.12504" target="_blank">pdf</a>]

<h2>Universal Adversarial Perturbations for CNN Classifiers in EEG-Based BCIs. (arXiv:1912.01171v3 [cs.LG] UPDATED)</h2>
<h3>Zihan Liu, Lubin Meng, Xiao Zhang, Weili Fang, Hanbin Luo, Dongrui Wu, Lieyun Ding</h3>
<p>Multiple convolutional neural network (CNN) classifiers have been proposed
for electroencephalogram (EEG) based brain-computer interfaces (BCIs). However,
CNN models have been found vulnerable to universal adversarial perturbations
(UAPs), which are small and example-independent, yet powerful enough to degrade
the performance of a CNN model, when added to a benign example. This paper
proposes a novel total loss minimization (TLM) approach to generate UAPs for
EEG-based BCIs. Experimental results demonstrated the effectiveness of TLM on
three popular CNN classifiers for both target and non-target attacks. We also
verified the transferability of UAPs in EEG-based BCI systems. To our
knowledge, this is the first study on UAPs of CNN classifiers in EEG-based
BCIs, and also the first study on optimization based UAPs for target attacks.
UAPs are easy to construct, and can attack BCIs in real-time, exposing a
potentially critical security concern of BCIs.
</p>
<a href="http://arxiv.org/abs/1912.01171" target="_blank">arXiv:1912.01171</a> [<a href="http://arxiv.org/pdf/1912.01171" target="_blank">pdf</a>]

<h2>A Robust Spectral Clustering Algorithm for Sub-Gaussian Mixture Models with Outliers. (arXiv:1912.07546v3 [stat.ML] UPDATED)</h2>
<h3>Prateek R. Srivastava, Purnamrita Sarkar, Grani A. Hanasusanto</h3>
<p>We consider the problem of clustering datasets in the presence of arbitrary
outliers. Traditional clustering algorithms such as k-means and spectral
clustering are known to perform poorly for datasets contaminated with even a
small number of outliers. In this paper, we develop a provably robust spectral
clustering algorithm that applies a simple rounding scheme to denoise a
Gaussian kernel matrix built from the data points and uses vanilla spectral
clustering to recover the cluster labels of data points. We analyze the
performance of our algorithm under the assumption that the "good" data points
are generated from a mixture of sub-gaussians (we term these "inliers"), while
the outlier points can come from any arbitrary probability distribution. For
this general class of models, we show that the misclassification error decays
at an exponential rate in the signal-to-noise ratio, provided the number of
outliers is a small fraction of the inlier points. Surprisingly, this derived
error bound matches with the best-known bound for semidefinite programs (SDPs)
under the same setting without outliers. We conduct extensive experiments on a
variety of simulated and real-world datasets to demonstrate that our algorithm
is less sensitive to outliers compared to other state-of-the-art algorithms
proposed in the literature.
</p>
<a href="http://arxiv.org/abs/1912.07546" target="_blank">arXiv:1912.07546</a> [<a href="http://arxiv.org/pdf/1912.07546" target="_blank">pdf</a>]

<h2>Overcoming Long-term Catastrophic Forgetting through Adversarial Neural Pruning and Synaptic Consolidation. (arXiv:1912.09091v2 [cs.LG] UPDATED)</h2>
<h3>Jian Peng, Bo Tang, Hao Jiang, Zhuo Li, Yinjie Lei, Tao Lin, Haifeng Li</h3>
<p>Artificial neural networks face the well-known problem of catastrophic
forgetting. What's worse, the degradation of previously learned skills becomes
more severe as the task sequence increases, known as the long-term catastrophic
forgetting. It is due to two facts: first, as the model learns more tasks, the
intersection of the low-error parameter subspace satisfying for these tasks
becomes smaller or even does not exist; second, when the model learns a new
task, the cumulative error keeps increasing as the model tries to protect the
parameter configuration of previous tasks from interference. Inspired by the
memory consolidation mechanism in mammalian brains with synaptic plasticity, we
propose a confrontation mechanism in which Adversarial Neural Pruning and
synaptic Consolidation (ANPyC) is used to overcome the long-term catastrophic
forgetting issue. The neural pruning acts as long-term depression to prune
task-irrelevant parameters, while the novel synaptic consolidation acts as
long-term potentiation to strengthen task-relevant parameters. During the
training, this confrontation achieves a balance in that only crucial parameters
remain, and non-significant parameters are freed to learn subsequent tasks.
ANPyC avoids forgetting important information and makes the model efficient to
learn a large number of tasks. Specifically, the neural pruning iteratively
relaxes the current task's parameter conditions to expand the common parameter
subspace of the task; the synaptic consolidation strategy, which consists of a
structure-aware parameter-importance measurement and an element-wise parameter
updating strategy, decreases the cumulative error when learning new tasks. The
full source code is available at https://github.com/GeoX-Lab/ANPyC.
</p>
<a href="http://arxiv.org/abs/1912.09091" target="_blank">arXiv:1912.09091</a> [<a href="http://arxiv.org/pdf/1912.09091" target="_blank">pdf</a>]

<h2>Recommendations and User Agency: The Reachability of Collaboratively-Filtered Information. (arXiv:1912.10068v2 [cs.LG] UPDATED)</h2>
<h3>Sarah Dean, Sarah Rich, Benjamin Recht</h3>
<p>Recommender systems often rely on models which are trained to maximize
accuracy in predicting user preferences. When the systems are deployed, these
models determine the availability of content and information to different
users. The gap between these objectives gives rise to a potential for
unintended consequences, contributing to phenomena such as filter bubbles and
polarization. In this work, we consider directly the information availability
problem through the lens of user recourse. Using ideas of reachability, we
propose a computationally efficient audit for top-$N$ linear recommender
models. Furthermore, we describe the relationship between model complexity and
the effort necessary for users to exert control over their recommendations. We
use this insight to provide a novel perspective on the user cold-start problem.
Finally, we demonstrate these concepts with an empirical investigation of a
state-of-the-art model trained on a widely used movie ratings dataset.
</p>
<a href="http://arxiv.org/abs/1912.10068" target="_blank">arXiv:1912.10068</a> [<a href="http://arxiv.org/pdf/1912.10068" target="_blank">pdf</a>]

<h2>Regime Switching Bandits. (arXiv:2001.09390v3 [cs.LG] UPDATED)</h2>
<h3>Xiang Zhou, Yi Xiong, Ningyuan Chen, Xuefeng Gao</h3>
<p>We study a multi-armed bandit problem where the rewards exhibit regime
switching. Specifically, the distributions of the random rewards generated from
all arms are modulated by a common underlying state modeled as a finite-state
Markov chain. The agent does not observe the underlying state and has to learn
the transition matrix and the reward distributions. We propose a learning
algorithm for this problem, building on spectral method-of-moments estimations
for hidden Markov models, belief error control in partially observable Markov
decision processes and upper-confidence-bound methods for online learning. We
also establish an upper bound $O(T^{2/3}\sqrt{\log T})$ for the proposed
learning algorithm where $T$ is the learning horizon. Finally, we conduct
proof-of-concept experiments to illustrate the performance of the learning
algorithm.
</p>
<a href="http://arxiv.org/abs/2001.09390" target="_blank">arXiv:2001.09390</a> [<a href="http://arxiv.org/pdf/2001.09390" target="_blank">pdf</a>]

<h2>Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing. (arXiv:2002.07033v5 [cs.LG] UPDATED)</h2>
<h3>Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim, Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo</h3>
<p>Knowledge tracing, the act of modeling a student's knowledge through learning
activities, is an extensively studied problem in the field of computer-aided
education. Although models with attention mechanism have outperformed
traditional approaches such as Bayesian knowledge tracing and collaborative
filtering, they share two limitations. Firstly, the models rely on shallow
attention layers and fail to capture complex relations among exercises and
responses over time. Secondly, different combinations of queries, keys and
values for the self-attention layer for knowledge tracing were not extensively
explored. Usual practice of using exercises and interactions (exercise-response
pairs) as queries and keys/values respectively lacks empirical support. In this
paper, we propose a novel Transformer based model for knowledge tracing, SAINT:
Separated Self-AttentIve Neural Knowledge Tracing. SAINT has an encoder-decoder
structure where exercise and response embedding sequence separately enter the
encoder and the decoder respectively, which allows to stack attention layers
multiple times. To the best of our knowledge, this is the first work to suggest
an encoder-decoder model for knowledge tracing that applies deep self-attentive
layers to exercises and responses separately. The empirical evaluations on a
large-scale knowledge tracing dataset show that SAINT achieves the
state-of-the-art performance in knowledge tracing with the improvement of AUC
by 1.8% compared to the current state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2002.07033" target="_blank">arXiv:2002.07033</a> [<a href="http://arxiv.org/pdf/2002.07033" target="_blank">pdf</a>]

<h2>Causal Inference With Selectively Deconfounded Data. (arXiv:2002.11096v3 [stat.ML] UPDATED)</h2>
<h3>Kyra Gan, Andrew A. Li, Zachary C. Lipton, Sridhar Tayur</h3>
<p>Given only data generated by a standard confounding graph with unobserved
confounder, the Average Treatment Effect (ATE) is not identifiable. To estimate
the ATE, a practitioner must then either (a) collect deconfounded data;(b) run
a clinical trial; or (c) elucidate further properties of the causal graph that
might render the ATE identifiable. In this paper, we consider the benefit of
incorporating a large confounded observational dataset (confounder unobserved)
alongside a small deconfounded observational dataset (confounder revealed) when
estimating the ATE. Our theoretical results suggest that the inclusion of
confounded data can significantly reduce the quantity of deconfounded data
required to estimate the ATE to within a desired accuracy level. Moreover, in
some cases -- say, genetics -- we could imagine retrospectively selecting
samples to deconfound. We demonstrate that by actively selecting these samples
based upon the (already observed) treatment and outcome, we can reduce sample
complexity further. Our theoretical and empirical results establish that the
worst-case relative performance of our approach (vs. a natural benchmark) is
bounded while our best-case gains are unbounded. Finally, we demonstrate the
benefits of selective deconfounding using a large real-world dataset related to
genetic mutation in cancer.
</p>
<a href="http://arxiv.org/abs/2002.11096" target="_blank">arXiv:2002.11096</a> [<a href="http://arxiv.org/pdf/2002.11096" target="_blank">pdf</a>]

<h2>Self-Supervised 2D Image to 3D Shape Translation with Disentangled Representations. (arXiv:2003.10016v2 [cs.CV] UPDATED)</h2>
<h3>Berk Kaya, Radu Timofte</h3>
<p>We present a framework to translate between 2D image views and 3D object
shapes. Recent progress in deep learning enabled us to learn structure-aware
representations from a scene. However, the existing literature assumes that
pairs of images and 3D shapes are available for training in full supervision.
In this paper, we propose SIST, a Self-supervised Image to Shape Translation
framework that fulfills three tasks: (i) reconstructing the 3D shape from a
single image; (ii) learning disentangled representations for shape, appearance
and viewpoint; and (iii) generating a realistic RGB image from these
independent factors. In contrast to the existing approaches, our method does
not require image-shape pairs for training. Instead, it uses unpaired image and
shape datasets from the same object class and jointly trains image generator
and shape reconstruction networks. Our translation method achieves promising
results, comparable in quantitative and qualitative terms to the
state-of-the-art achieved by fully-supervised methods.
</p>
<a href="http://arxiv.org/abs/2003.10016" target="_blank">arXiv:2003.10016</a> [<a href="http://arxiv.org/pdf/2003.10016" target="_blank">pdf</a>]

<h2>Synergic Adversarial Label Learning for Grading Retinal Diseases via Knowledge Distillation and Multi-task Learning. (arXiv:2003.10607v4 [cs.CV] UPDATED)</h2>
<h3>Lie Ju, Xin Wang, Xin Zhao, Huimin Lu, Dwarikanath Mahapatra, Paul Bonnington, Zongyuan Ge</h3>
<p>The need for comprehensive and automated screening methods for retinal image
classification has long been recognized. Well-qualified doctors annotated
images are very expensive and only a limited amount of data is available for
various retinal diseases such as age-related macular degeneration (AMD) and
diabetic retinopathy (DR). Some studies show that AMD and DR share some common
features like hemorrhagic points and exudation but most classification
algorithms only train those disease models independently. Inspired by knowledge
distillation where additional monitoring signals from various sources is
beneficial to train a robust model with much fewer data. We propose a method
called synergic adversarial label learning (SALL) which leverages relevant
retinal disease labels in both semantic and feature space as additional signals
and train the model in a collaborative manner. Our experiments on DR and AMD
fundus image classification task demonstrate that the proposed method can
significantly improve the accuracy of the model for grading diseases. In
addition, we conduct additional experiments to show the effectiveness of SALL
from the aspects of reliability and interpretability in the context of medical
imaging application.
</p>
<a href="http://arxiv.org/abs/2003.10607" target="_blank">arXiv:2003.10607</a> [<a href="http://arxiv.org/pdf/2003.10607" target="_blank">pdf</a>]

<h2>EfficientPS: Efficient Panoptic Segmentation. (arXiv:2004.02307v3 [cs.CV] UPDATED)</h2>
<h3>Rohit Mohan, Abhinav Valada</h3>
<p>Understanding the scene in which an autonomous robot operates is critical for
its competent functioning. Such scene comprehension necessitates recognizing
instances of traffic participants along with general scene semantics which can
be effectively addressed by the panoptic segmentation task. In this paper, we
introduce the Efficient Panoptic Segmentation (EfficientPS) architecture that
consists of a shared backbone which efficiently encodes and fuses semantically
rich multi-scale features. We incorporate a new semantic head that aggregates
fine and contextual features coherently and a new variant of Mask R-CNN as the
instance head. We also propose a novel panoptic fusion module that congruously
integrates the output logits from both the heads of our EfficientPS
architecture to yield the final panoptic segmentation output. Additionally, we
introduce the KITTI panoptic segmentation dataset that contains panoptic
annotations for the popularly challenging KITTI benchmark. Extensive
evaluations on Cityscapes, KITTI, Mapillary Vistas and Indian Driving Dataset
demonstrate that our proposed architecture consistently sets the new
state-of-the-art on all these four benchmarks while being the most efficient
and fast panoptic segmentation architecture to date.
</p>
<a href="http://arxiv.org/abs/2004.02307" target="_blank">arXiv:2004.02307</a> [<a href="http://arxiv.org/pdf/2004.02307" target="_blank">pdf</a>]

<h2>Estimating the Probability that a Vehicle Reaches a Near-Term Goal State Using Multiple Lane Changes. (arXiv:2004.09558v2 [cs.RO] UPDATED)</h2>
<h3>Goodarz Mehr, Azim Eskandarian</h3>
<p>This paper proposes a model to estimate the probability of a vehicle reaching
a near-term goal state using one or multiple lane changes based on parameters
corresponding to traffic conditions and driving behavior. The proposed model
not only has broad application in path planning and autonomous vehicle
navigation, it can also be incorporated in advance warning systems to reduce
traffic delay during recurrent and non-recurrent congestion. The model is first
formulated for a two-lane road segment through systemic reduction of the number
of parameters and transforming the problem into an abstract statistical form,
for which the probability can be calculated numerically. It is then extended to
cases with a higher number of lanes using the law of total probability. VISSIM
simulations are used to validate the predictions of the model and study the
effect of different parameters on the probability. For most cases, simulation
results are within 4% of model predictions, and the effect of different
parameters such as driving behavior and traffic density on the probability
match our expectation. The model can be implemented with near real-time
performance, with computation time increasing linearly with the number of
lanes.
</p>
<a href="http://arxiv.org/abs/2004.09558" target="_blank">arXiv:2004.09558</a> [<a href="http://arxiv.org/pdf/2004.09558" target="_blank">pdf</a>]

<h2>Discovering Parametric Activation Functions. (arXiv:2006.03179v4 [cs.LG] UPDATED)</h2>
<h3>Garrett Bingham, Risto Miikkulainen</h3>
<p>Recent studies have shown that the choice of activation function can
significantly affect the performance of deep learning networks. However, the
benefits of novel activation functions have been inconsistent and task
dependent, and therefore the rectified linear unit (ReLU) is still the most
commonly used. This paper proposes a technique for customizing activation
functions automatically, resulting in reliable improvements in performance.
Evolutionary search is used to discover the general form of the function, and
gradient descent to optimize its parameters for different parts of the network
and over the learning process. Experiments with four different neural network
architectures on the CIFAR-10 and CIFAR-100 image classification datasets show
that this approach is effective. It discovers both general activation functions
and specialized functions for different architectures, consistently improving
accuracy over ReLU and other activation functions by significant margins. The
approach can therefore be used as an automated optimization step in applying
deep learning to new tasks.
</p>
<a href="http://arxiv.org/abs/2006.03179" target="_blank">arXiv:2006.03179</a> [<a href="http://arxiv.org/pdf/2006.03179" target="_blank">pdf</a>]

<h2>A Review of Incident Prediction, Resource Allocation, and Dispatch Models for Emergency Management. (arXiv:2006.04200v6 [cs.AI] UPDATED)</h2>
<h3>Ayan Mukhopadhyay, Geoffrey Pettet, Sayyed Vazirizade, Di Lu, Said El Said, Alex Jaimes, Hiba Baroud, Yevgeniy Vorobeychik, Mykel Kochenderfer, Abhishek Dubey</h3>
<p>In the last fifty years, researchers have developed statistical, data-driven,
analytical, and algorithmic approaches for designing and improving emergency
response management (ERM) systems. The problem is inherently difficult and
constitutes spatio-temporal decision making under uncertainty, which has been
addressed in the literature with varying assumptions and approaches. This
survey provides a detailed review of these approaches, focusing on the key
challenges and issues regarding three subprocesses that are part of this
problem (a) incident prediction, (b) resource allocation, and (c)
computer-aided dispatch to handle the emergency conditions. We highlight the
strengths and weaknesses of prior work in this domain and explore the
similarities and differences between different modeling paradigms. We conclude
by illustrating remain challenges and opportunities for future research in this
complex domain.
</p>
<a href="http://arxiv.org/abs/2006.04200" target="_blank">arXiv:2006.04200</a> [<a href="http://arxiv.org/pdf/2006.04200" target="_blank">pdf</a>]

<h2>Fair Bayesian Optimization. (arXiv:2006.05109v2 [stat.ML] UPDATED)</h2>
<h3>Valerio Perrone, Michele Donini, Muhammad Bilal Zafar, Robin Schmucker, Krishnaram Kenthapadi, C&#xe9;dric Archambeau</h3>
<p>Given the increasing importance of machine learning (ML) in our lives,
several algorithmic fairness techniques have been proposed to mitigate biases
in the outcomes of the ML models. However, most of these techniques are
specialized to cater to a single family of ML models and a specific definition
of fairness, limiting their adaptibility in practice. We introduce a general
constrained Bayesian optimization (BO) framework to optimize the performance of
any ML model while enforcing one or multiple fairness constraints. BO is a
model-agnostic optimization method that has been successfully applied to
automatically tune the hyperparameters of ML models. We apply BO with fairness
constraints to a range of popular models, including random forests, gradient
boosting, and neural networks, showing that we can obtain accurate and fair
solutions by acting solely on the hyperparameters. We also show empirically
that our approach is competitive with specialized techniques that enforce
model-specific fairness constraints, and outperforms preprocessing methods that
learn fair representations of the input data. Moreover, our method can be used
in synergy with such specialized fairness techniques to tune their
hyperparameters. Finally, we study the relationship between fairness and the
hyperparameters selected by BO. We observe a correlation between regularization
and unbiased models, explaining why acting on the hyperparameters leads to ML
models that generalize well and are fair.
</p>
<a href="http://arxiv.org/abs/2006.05109" target="_blank">arXiv:2006.05109</a> [<a href="http://arxiv.org/pdf/2006.05109" target="_blank">pdf</a>]

<h2>Model-Free Algorithm and Regret Analysis for MDPs with Long-Term Constraints. (arXiv:2006.05961v2 [cs.LG] UPDATED)</h2>
<h3>Qinbo Bai, Vaneet Aggarwal, Ather Gattami</h3>
<p>In the optimization of dynamical systems, the variables typically have
constraints. Such problems can be modeled as a constrained Markov Decision
Process (CMDP). This paper considers a model-free approach to the problem,
where the transition probabilities are not known. In the presence of long-term
(or average) constraints, the agent has to choose a policy that maximizes the
long-term average reward as well as satisfy the average constraints in each
episode. The key challenge with the long-term constraints is that the optimal
policy is not deterministic in general, and thus standard Q-learning approaches
cannot be directly used. This paper uses concepts from constrained optimization
and Q-learning to propose an algorithm for CMDP with long-term constraints. For
any $\gamma\in(0,\frac{1}{2})$, the proposed algorithm is shown to achieve
$O(T^{1/2+\gamma})$ regret bound for the obtained reward and
$O(T^{1-\gamma/2})$ regret bound for the constraint violation, where $T$ is the
total number of steps. We note that these are the first results on regret
analysis for MDP with long-term constraints, where the transition probabilities
are not known apriori.
</p>
<a href="http://arxiv.org/abs/2006.05961" target="_blank">arXiv:2006.05961</a> [<a href="http://arxiv.org/pdf/2006.05961" target="_blank">pdf</a>]

<h2>Double Double Descent: On Generalization Errors in Transfer Learning between Linear Regression Tasks. (arXiv:2006.07002v4 [cs.LG] UPDATED)</h2>
<h3>Yehuda Dar, Richard G. Baraniuk</h3>
<p>We study the transfer learning process between two linear regression
problems. An important and timely special case is when the regressors are
overparameterized and perfectly interpolate their training data. We examine a
parameter transfer mechanism whereby a subset of the parameters of the target
task solution are constrained to the values learned for a related source task.
We analytically characterize the generalization error of the target task in
terms of the salient factors in the transfer learning architecture, i.e., the
number of examples available, the number of (free) parameters in each of the
tasks, the number of parameters transferred from the source to target task, and
the correlation between the two tasks. Our non-asymptotic analysis shows that
the generalization error of the target task follows a two-dimensional double
descent trend (with respect to the number of free parameters in each of the
tasks) that is controlled by the transfer learning factors. Our analysis points
to specific cases where the transfer of parameters is beneficial. Specifically,
we show that transferring a specific set of parameters that generalizes well on
the respective part of the source task can soften the demand on the task
correlation level that is required for successful transfer learning. Moreover,
we show that the usefulness of a transfer learning setting is fragile and
depends on a delicate interplay among the set of transferred parameters, the
relation between the tasks, and the true solution.
</p>
<a href="http://arxiv.org/abs/2006.07002" target="_blank">arXiv:2006.07002</a> [<a href="http://arxiv.org/pdf/2006.07002" target="_blank">pdf</a>]

<h2>Robust Baggage Detection and Classification Based on Local Tri-directional Pattern. (arXiv:2006.07345v3 [cs.CV] UPDATED)</h2>
<h3>Shahbano, Muhammad Abdullah, Kashif Inayat</h3>
<p>In recent decades, the automatic video surveillance system has gained
significant importance in computer vision community. The crucial objective of
surveillance is monitoring and security in public places. In the traditional
Local Binary Pattern, the feature description is somehow inaccurate, and the
feature size is large enough. Therefore, to overcome these shortcomings, our
research proposed a detection algorithm for a human with or without carrying
baggage. The Local tri-directional pattern descriptor is exhibited to extract
features of different human body parts including head, trunk, and limbs. Then
with the help of support vector machine, extracted features are trained and
evaluated. Experimental results on INRIA and MSMT17 V1 datasets show that
LtriDP outperforms several state-of-the-art feature descriptors and validate
its effectiveness.
</p>
<a href="http://arxiv.org/abs/2006.07345" target="_blank">arXiv:2006.07345</a> [<a href="http://arxiv.org/pdf/2006.07345" target="_blank">pdf</a>]

<h2>Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning. (arXiv:2006.12777v2 [cs.LG] UPDATED)</h2>
<h3>A. Tuan Nguyen, Hyewon Jeong, Eunho Yang, Sung Ju Hwang</h3>
<p>Although recent multi-task learning methods have shown to be effective in
improving the generalization of deep neural networks, they should be used with
caution for safety-critical applications, such as clinical risk prediction.
This is because even if they achieve improved task-average performance, they
may still yield degraded performance on individual tasks, which may be critical
(e.g., prediction of mortality risk). Existing asymmetric multi-task learning
methods tackle this negative transfer problem by performing knowledge transfer
from tasks with low loss to tasks with high loss. However, using loss as a
measure of reliability is risky since it could be a result of overfitting. In
the case of time-series prediction tasks, knowledge learned for one task (e.g.,
predicting the sepsis onset) at a specific timestep may be useful for learning
another task (e.g., prediction of mortality) at a later timestep, but lack of
loss at each timestep makes it difficult to measure the reliability at each
timestep. To capture such dynamically changing asymmetric relationships between
tasks in time-series data, we propose a novel temporal asymmetric multi-task
learning model that performs knowledge transfer from certain tasks/timesteps to
relevant uncertain tasks, based on feature-level uncertainty. We validate our
model on multiple clinical risk prediction tasks against various deep learning
models for time-series prediction, which our model significantly outperforms,
without any sign of negative transfer. Further qualitative analysis of learned
knowledge graphs by clinicians shows that they are helpful in analyzing the
predictions of the model. Our final code is available at
https://github.com/anhtuan5696/TPAMTL.
</p>
<a href="http://arxiv.org/abs/2006.12777" target="_blank">arXiv:2006.12777</a> [<a href="http://arxiv.org/pdf/2006.12777" target="_blank">pdf</a>]

<h2>Scalable Spectral Clustering with Nystrom Approximation: Practical and Theoretical Aspects. (arXiv:2006.14470v2 [cs.LG] UPDATED)</h2>
<h3>Farhad Pourkamali-Anaraki</h3>
<p>Spectral clustering techniques are valuable tools in signal processing and
machine learning for partitioning complex data sets. The effectiveness of
spectral clustering stems from constructing a non-linear embedding based on
creating a similarity graph and computing the spectral decomposition of the
Laplacian matrix. However, spectral clustering methods fail to scale to large
data sets because of high computational cost and memory usage. A popular
approach for addressing these problems utilizes the Nystrom method, an
efficient sampling-based algorithm for computing low-rank approximations to
large positive semi-definite matrices. This paper demonstrates how the
previously popular approach of Nystrom-based spectral clustering has severe
limitations. Existing time-efficient methods ignore critical information by
prematurely reducing the rank of the similarity matrix associated with sampled
points. Also, current understanding is limited regarding how utilizing the
Nystrom approximation will affect the quality of spectral embedding
approximations. To address the limitations, this work presents a principled
spectral clustering algorithm that exploits spectral properties of the
similarity matrix associated with sampled points to regulate
accuracy-efficiency trade-offs. We provide theoretical results to reduce the
current gap and present numerical experiments with real and synthetic data.
Empirical results demonstrate the efficacy and efficiency of the proposed
method compared to existing spectral clustering techniques based on the Nystrom
method and other efficient methods. The overarching goal of this work is to
provide an improved baseline for future research directions to accelerate
spectral clustering.
</p>
<a href="http://arxiv.org/abs/2006.14470" target="_blank">arXiv:2006.14470</a> [<a href="http://arxiv.org/pdf/2006.14470" target="_blank">pdf</a>]

<h2>Reinforcement Learning and its Connections with Neuroscience and Psychology. (arXiv:2007.01099v3 [cs.LG] UPDATED)</h2>
<h3>Ajay Subramanian, Sharad Chitlangia, Veeky Baths</h3>
<p>Reinforcement learning methods have recently been very successful at
performing complex sequential tasks like playing Atari games, Go and Poker.
These algorithms have outperformed humans in several tasks by learning from
scratch, using only scalar rewards obtained through interaction with their
environment. While there certainly has been considerable independent innovation
in the area to produce such results, many core ideas in reinforcement learning
are inspired by phenomena of animal learning, psychology and neuroscience. In
this paper, we comprehensively review a number of findings in neuroscience and
psychology that provide evidence for the plausibility of reinforcement learning
being a promising model for phenomena in human learning, decision making and
behavior. We do so by a) exploring neuroscientific evidence for various classes
of RL algorithms along with their building blocks, and b) mapping specific RL
ideas to findings in neuroscience and psychology. Finally, we discuss the
implications of these findings and their role in advancing research in both AI
and brain science.
</p>
<a href="http://arxiv.org/abs/2007.01099" target="_blank">arXiv:2007.01099</a> [<a href="http://arxiv.org/pdf/2007.01099" target="_blank">pdf</a>]

<h2>The Impossibility Theorem of Machine Fairness -- A Causal Perspective. (arXiv:2007.06024v2 [cs.LG] UPDATED)</h2>
<h3>Kailash Karthik Saravanakumar</h3>
<p>With the increasing pervasive use of machine learning in social and economic
settings, there has been an interest in the notion of machine bias in the AI
community. Models trained on historic data reflect biases that exist in society
and propagated them to the future through their decisions. There are three
prominent metrics of machine fairness used in the community, and it has been
shown statistically that it is impossible to satisfy them all at the same time.
This has led to an ambiguity with regards to the definition of fairness. In
this report, a causal perspective to the impossibility theorem of fairness is
presented along with a causal goal for machine fairness.
</p>
<a href="http://arxiv.org/abs/2007.06024" target="_blank">arXiv:2007.06024</a> [<a href="http://arxiv.org/pdf/2007.06024" target="_blank">pdf</a>]

<h2>Conditional independences and causal relations implied by sets of equations. (arXiv:2007.07183v2 [cs.AI] UPDATED)</h2>
<h3>Tineke Blom, Mirthe M. van Diepen, Joris M. Mooij</h3>
<p>Real-world complex systems are often modelled by sets of equations with
endogenous and exogenous variables. What can we say about the causal and
probabilistic aspects of variables that appear in these equations without
explicitly solving the equations? We make use of Simon's causal ordering
algorithm (Simon, 1953) to construct a causal ordering graph and prove that it
expresses the effects of soft and perfect interventions on the equations under
certain unique solvability assumptions. We further construct a Markov ordering
graph and prove that it encodes conditional independences in the distribution
implied by the equations with independent random exogenous variables, under a
similar unique solvability assumption. We discuss how this approach reveals and
addresses some of the limitations of existing causal modelling frameworks, such
as causal Bayesian networks and structural causal models.
</p>
<a href="http://arxiv.org/abs/2007.07183" target="_blank">arXiv:2007.07183</a> [<a href="http://arxiv.org/pdf/2007.07183" target="_blank">pdf</a>]

<h2>Consensus-Aware Visual-Semantic Embedding for Image-Text Matching. (arXiv:2007.08883v2 [cs.CV] UPDATED)</h2>
<h3>Haoran Wang, Ying Zhang, Zhong Ji, Yanwei Pang, Lin Ma</h3>
<p>Image-text matching plays a central role in bridging vision and language.
Most existing approaches only rely on the image-text instance pair to learn
their representations, thereby exploiting their matching relationships and
making the corresponding alignments. Such approaches only exploit the
superficial associations contained in the instance pairwise data, with no
consideration of any external commonsense knowledge, which may hinder their
capabilities to reason the higher-level relationships between image and text.
In this paper, we propose a Consensus-aware Visual-Semantic Embedding (CVSE)
model to incorporate the consensus information, namely the commonsense
knowledge shared between both modalities, into image-text matching.
Specifically, the consensus information is exploited by computing the
statistical co-occurrence correlations between the semantic concepts from the
image captioning corpus and deploying the constructed concept correlation graph
to yield the consensus-aware concept (CAC) representations. Afterwards, CVSE
learns the associations and alignments between image and text based on the
exploited consensus as well as the instance-level representations for both
modalities. Extensive experiments conducted on two public datasets verify that
the exploited consensus makes significant contributions to constructing more
meaningful visual-semantic embeddings, with the superior performances over the
state-of-the-art approaches on the bidirectional image and text retrieval task.
Our code of this paper is available at: https://github.com/BruceW91/CVSE.
</p>
<a href="http://arxiv.org/abs/2007.08883" target="_blank">arXiv:2007.08883</a> [<a href="http://arxiv.org/pdf/2007.08883" target="_blank">pdf</a>]

<h2>Threat of Adversarial Attacks on Face Recognition: A Comprehensive Survey. (arXiv:2007.11709v2 [cs.CV] UPDATED)</h2>
<h3>Fatemeh Vakhshiteh, Raghavendra Ramachandra, Ahmad Nickabadi</h3>
<p>Face recognition (FR) systems have demonstrated outstanding verification
performance, suggesting suitability for real-world applications, ranging from
photo tagging in social media to automated border control (ABC). In an advanced
FR system with deep learning-based architecture, however, promoting the
recognition efficiency alone is not sufficient and the system should also
withstand potential kinds of attacks designed to target its proficiency. Recent
studies show that (deep) FR systems exhibit an intriguing vulnerability to
imperceptible or perceptible but natural-looking adversarial input images that
drive the model to incorrect output predictions. In this article, we present a
comprehensive survey on adversarial attacks against FR systems and elaborate on
the competence of new countermeasures against them. Further, we propose a
taxonomy of existing attack and defense strategies according to different
criteria. Finally, we compare the presented approaches according to techniques'
characteristics.
</p>
<a href="http://arxiv.org/abs/2007.11709" target="_blank">arXiv:2007.11709</a> [<a href="http://arxiv.org/pdf/2007.11709" target="_blank">pdf</a>]

<h2>K-Shot Contrastive Learning of Visual Features with Multiple Instance Augmentations. (arXiv:2007.13310v2 [cs.CV] UPDATED)</h2>
<h3>Haohang Xu, Hongkai Xiong, Guo-Jun Qi</h3>
<p>In this paper, we propose the $K$-Shot Contrastive Learning (KSCL) of visual
features by applying multiple augmentations to investigate the sample
variations within individual instances. It aims to combine the advantages of
inter-instance discrimination by learning discriminative features to
distinguish between different instances, as well as intra-instance variations
by matching queries against the variants of augmented samples over instances.
Particularly, for each instance, it constructs an instance subspace to model
the configuration of how the significant factors of variations in $K$-shot
augmentations can be combined to form the variants of augmentations. Given a
query, the most relevant variant of instances is then retrieved by projecting
the query onto their subspaces to predict the positive instance class. This
generalizes the existing contrastive learning that can be viewed as a special
one-shot case. An eigenvalue decomposition is performed to configure instance
subspaces, and the embedding network can be trained end-to-end through the
differentiable subspace configuration. Experiment results demonstrate the
proposed $K$-shot contrastive learning achieves superior performances to the
state-of-the-art unsupervised methods.
</p>
<a href="http://arxiv.org/abs/2007.13310" target="_blank">arXiv:2007.13310</a> [<a href="http://arxiv.org/pdf/2007.13310" target="_blank">pdf</a>]

<h2>Outlier-Robust Estimation: Hardness, Minimally-Tuned Algorithms, and Applications. (arXiv:2007.15109v2 [cs.CV] UPDATED)</h2>
<h3>Pasquale Antonante, Vasileios Tzoumas, Heng Yang, Luca Carlone</h3>
<p>Nonlinear estimation in robotics and vision is typically plagued with
outliers due to wrong data association, or to incorrect detections from signal
processing and machine learning methods. This paper introduces two unifying
formulations for outlier-robust estimation, Generalized Maximum Consensus (G-
MC) and Generalized Truncated Least Squares (G-TLS), and investigates
fundamental limits, practical algorithms, and applications. Our first
contribution is a proof that outlier-robust estimation is inapproximable: in
the worst case, it is impossible to (even approximately) find the set of
outliers, even with slower-than-polynomial-time algorithms (particularly,
algorithms running in quasi-polynomial time). As a second contribution, we
review and extend two general-purpose algorithms. The first, Adaptive Trimming
(ADAPT), is combinatorial, and is suitable for G-MC; the second, Graduated
Non-Convexity (GNC), is based on homotopy methods, and is suitable for G-TLS.
We extend ADAPT and GNC to the case where the user does not have prior
knowledge of the inlier-noise statistics (or the statistics may vary over time)
and is unable to guess a reasonable threshold to separate inliers from outliers
(as the one commonly used in RANSAC). We propose the first minimally-tuned
algorithms for outlier rejection, that dynamically decide how to separate
inliers from outliers. Our third contribution is an evaluation of the proposed
algorithms on robot perception problems: mesh registration, image-based object
detection (shape alignment), and pose graph optimization. ADAPT and GNC execute
in real-time, are deterministic, outperform RANSAC, and are robust up to 80-90%
outliers. Their minimally-tuned versions also compare favorably with the state
of the art, even though they do not rely on a noise bound for the inliers.
</p>
<a href="http://arxiv.org/abs/2007.15109" target="_blank">arXiv:2007.15109</a> [<a href="http://arxiv.org/pdf/2007.15109" target="_blank">pdf</a>]

<h2>Membership Leakage in Label-Only Exposures. (arXiv:2007.15528v2 [cs.LG] UPDATED)</h2>
<h3>Zheng Li, Yang Zhang</h3>
<p>Machine learning (ML) has been widely adopted in various privacy-critical
applications, e.g., face recognition and medical image analysis. However,
recent research has shown that ML models are vulnerable to attacks against
their training data. Membership inference is one major attack in this domain:
Given a data sample and model, an adversary aims to determine whether the
sample is part of the model's training set. Existing membership inference
attacks leverage the confidence scores returned by the model as their inputs
(score-based attacks). However, these attacks can be easily mitigated if the
model only exposes the predicted label, i.e., the final model decision.

In this paper, we propose decision-based membership inference attacks and
demonstrate that label-only exposures are also vulnerable to membership
leakage. In particular, we develop two types of decision-based attacks, namely
transfer-attack and boundary-attack. Empirical evaluation shows that our
decision-based attacks can achieve remarkable performance, and even outperform
the previous score-based attacks. We further present new insights on the
success of membership inference based on quantitative and qualitative analysis,
i.e., member samples of a model are more distant to the model's decision
boundary than non-member samples. Finally, we evaluate multiple defense
mechanisms against our decision-based attacks and show that our two types of
attacks can bypass most of these defenses.
</p>
<a href="http://arxiv.org/abs/2007.15528" target="_blank">arXiv:2007.15528</a> [<a href="http://arxiv.org/pdf/2007.15528" target="_blank">pdf</a>]

<h2>A Survey on Concept Factorization: From Shallow to Deep Representation Learning. (arXiv:2007.15840v3 [cs.LG] UPDATED)</h2>
<h3>Zhao Zhang, Yan Zhang, Mingliang Xu, Li Zhang, Yi Yang, Shuicheng Yan</h3>
<p>The quality of learned features by representation learning determines the
performance of learning algorithms and the related application tasks (such as
high-dimensional data clustering). As a relatively new paradigm for
representation learning, Concept Factorization (CF) has attracted a great deal
of interests in the areas of machine learning and data mining for over a
decade. Lots of effective CF based methods have been proposed based on
different perspectives and properties, but note that it still remains not easy
to grasp the essential connections and figure out the underlying explanatory
factors from exiting studies. In this paper, we therefore survey the recent
advances on CF methodologies and the potential benchmarks by categorizing and
summarizing the current methods. Specifically, we first re-view the root CF
method, and then explore the advancement of CF-based representation learning
ranging from shallow to deep/multilayer cases. We also introduce the potential
application areas of CF-based methods. Finally, we point out some future
directions for studying the CF-based representation learning. Overall, this
survey provides an insightful overview of both theoretical basis and current
developments in the field of CF, which can also help the interested researchers
to understand the current trends of CF and find the most appropriate CF
techniques to deal with particular applications.
</p>
<a href="http://arxiv.org/abs/2007.15840" target="_blank">arXiv:2007.15840</a> [<a href="http://arxiv.org/pdf/2007.15840" target="_blank">pdf</a>]

<h2>Compact Graph Architecture for Speech Emotion Recognition. (arXiv:2008.02063v3 [cs.CV] UPDATED)</h2>
<h3>A. Shirian, T. Guha</h3>
<p>We propose a deep graph approach to address the task of speech emotion
recognition. A compact, efficient and scalable way to represent data is in the
form of graphs. Following the theory of graph signal processing, we propose to
model speech signal as a cycle graph or a line graph. Such graph structure
enables us to construct a graph convolution network (GCN)-based architecture
that can perform an \emph{accurate} graph convolution in contrast to the
approximate convolution used in standard GCNs. We evaluated the performance of
our model for speech emotion recognition on the popular IEMOCAP database. Our
model outperforms standard GCN and other relevant deep graph architectures
indicating the effectiveness of our approach. When compared with existing
speech emotion recognition methods, our model achieves state-of-the-art
performance (4-class, $65.29\%$) with significantly fewer learnable parameters.
</p>
<a href="http://arxiv.org/abs/2008.02063" target="_blank">arXiv:2008.02063</a> [<a href="http://arxiv.org/pdf/2008.02063" target="_blank">pdf</a>]

<h2>VPC-Net: Completion of 3D Vehicles from MLS Point Clouds. (arXiv:2008.03404v2 [cs.CV] UPDATED)</h2>
<h3>Yan Xia, Yusheng Xu, Cheng Wang, Uwe Stilla</h3>
<p>As a dynamic and essential component in the road environment of urban
scenarios, vehicles are the most popular investigation targets. To monitor
their behavior and extract their geometric characteristics, an accurate and
instant measurement of vehicles plays a vital role in traffic and
transportation fields. Point clouds acquired from the mobile laser scanning
(MLS) system deliver 3D information of road scenes with unprecedented detail.
They have proven to be an adequate data source in the fields of intelligent
transportation and autonomous driving, especially for extracting vehicles.
However, acquired 3D point clouds of vehicles from MLS systems are inevitably
incomplete due to object occlusion or self-occlusion. To tackle this problem,
we proposed a neural network to synthesize complete, dense, and uniform point
clouds for vehicles from MLS data, named Vehicle Points Completion-Net
(VPC-Net). In this network, we introduce a new encoder module to extract global
features from the input instance, consisting of a spatial transformer network
and point feature enhancement layer. Moreover, a new refiner module is also
presented to preserve the vehicle details from inputs and refine the complete
outputs with fine-grained information. Given sparse and partial point clouds as
inputs, the network can generate complete and realistic vehicle structures and
keep the fine-grained details from the partial inputs. We evaluated the
proposed VPC-Net in different experiments using synthetic and real-scan
datasets and applied the results to 3D vehicle monitoring tasks. Quantitative
and qualitative experiments demonstrate the promising performance of the
proposed VPC-Net and show state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2008.03404" target="_blank">arXiv:2008.03404</a> [<a href="http://arxiv.org/pdf/2008.03404" target="_blank">pdf</a>]

<h2>Fast Dimension Independent Private AdaGrad on Publicly Estimated Subspaces. (arXiv:2008.06570v2 [cs.LG] UPDATED)</h2>
<h3>Peter Kairouz, M&#xf3;nica Ribero, Keith Rush, Abhradeep Thakurta</h3>
<p>We revisit the problem of empirical risk minimziation (ERM) with differential
privacy. We show that noisy AdaGrad, given appropriate knowledge and conditions
on the subspace from which gradients can be drawn, achieves a regret comparable
to traditional AdaGrad plus a well-controlled term due to noise. We show a
convergence rate of $O(\text{Tr}(G_T)/T)$, where $G_T$ captures the geometry of
the gradient subspace. Since $\text{Tr}(G_T)=O(\sqrt{T})$ we can obtain faster
rates for convex and Lipschitz functions, compared to the $O(1/\sqrt{T})$ rate
achieved by known versions of noisy (stochastic) gradient descent with
comparable noise variance. In particular, we show that if the gradients lie in
a known constant rank subspace, and assuming algorithmic access to an envelope
which bounds decaying sensitivity, one can achieve faster convergence to an
excess empirical risk of $\tilde O(1/\epsilon n)$, where $\epsilon$ is the
privacy budget and $n$ the number of samples. Letting $p$ be the problem
dimension, this result implies that, by running noisy Adagrad, we can bypass
the DP-SGD bound $\tilde O(\sqrt{p}/\epsilon n)$ in $T=(\epsilon
n)^{2/(1+2\alpha)}$ iterations, where $\alpha \geq 0$ is a parameter
controlling gradient norm decay, instead of the rate achieved by SGD of
$T=\epsilon^2n^2$. Our results operate with general convex functions in both
constrained and unconstrained minimization.

Along the way, we do a perturbation analysis of noisy AdaGrad of independent
interest. Our utility guarantee for the private ERM problem follows as a
corollary to the regret guarantee of noisy AdaGrad.
</p>
<a href="http://arxiv.org/abs/2008.06570" target="_blank">arXiv:2008.06570</a> [<a href="http://arxiv.org/pdf/2008.06570" target="_blank">pdf</a>]

<h2>Optimal Best-Arm Identification Methods for Tail-Risk Measures. (arXiv:2008.07606v2 [cs.LG] UPDATED)</h2>
<h3>Shubhada Agrawal, Wouter M. Koolen, Sandeep Juneja</h3>
<p>Conditional value-at-risk (CVaR) and value-at-risk (VaR) are popular
tail-risk measures in finance and insurance industries as well as in highly
reliable, safety-critical uncertain environments where often the underlying
probability distributions are heavy-tailed. We use the multi-armed bandit
best-arm identification framework and consider the problem of identifying the
arm-distribution from amongst finitely many that has the smallest CVaR or VaR.
We first show that in the special case of arm-distributions belonging to a
single-parameter exponential family, both these problems are equivalent to the
best mean-arm identification problem, which is widely studied in the
literature. This equivalence however is not true in general. We then propose
optimal $\delta$-correct algorithms that act on general arm-distributions,
including heavy-tailed distributions, that match the lower bound on the
expected number of samples needed, asymptotically (as $ \delta$ approaches
$0$). En-route, we also develop new non-asymptotic concentration inequalities
for certain functions of these risk measures for the empirical distribution,
that may have wider applicability.
</p>
<a href="http://arxiv.org/abs/2008.07606" target="_blank">arXiv:2008.07606</a> [<a href="http://arxiv.org/pdf/2008.07606" target="_blank">pdf</a>]

<h2>A general kernel boosting framework integrating pathways for predictive modeling based on genomic data. (arXiv:2008.11384v2 [stat.ML] UPDATED)</h2>
<h3>Li Zeng, Zhaolong Yu, Yiliang Zhang, Hongyu Zhao</h3>
<p>Predictive modeling based on genomic data has gained popularity in biomedical
research and clinical practice by allowing researchers and clinicians to
identify biomarkers and tailor treatment decisions more efficiently. Analysis
incorporating pathway information can boost discovery power and better connect
new findings with biological mechanisms. In this article, we propose a general
framework, Pathway-based Kernel Boosting (PKB), which incorporates clinical
information and prior knowledge about pathways for prediction of binary,
continuous and survival outcomes. We introduce appropriate loss functions and
optimization procedures for different outcome types. Our prediction algorithm
incorporates pathway knowledge by constructing kernel function spaces from the
pathways and use them as base learners in the boosting procedure. Through
extensive simulations and case studies in drug response and cancer survival
datasets, we demonstrate that PKB can substantially outperform other competing
methods, better identify biological pathways related to drug response and
patient survival, and provide novel insights into cancer pathogenesis and
treatment response.
</p>
<a href="http://arxiv.org/abs/2008.11384" target="_blank">arXiv:2008.11384</a> [<a href="http://arxiv.org/pdf/2008.11384" target="_blank">pdf</a>]

<h2>Online Class-Incremental Continual Learning with Adversarial Shapley Value. (arXiv:2009.00093v3 [cs.LG] UPDATED)</h2>
<h3>Dongsub Shim, Zheda Mai, Jihwan Jeong, Scott Sanner, Hyunwoo Kim, Jongseong Jang</h3>
<p>As image-based deep learning becomes pervasive on every device, from cell
phones to smart watches, there is a growing need to develop methods that
continually learn from data while minimizing memory footprint and power
consumption. While memory replay techniques have shown exceptional promise for
this task of continual learning, the best method for selecting which buffered
images to replay is still an open question. In this paper, we specifically
focus on the online class-incremental setting where a model needs to learn new
classes continually from an online data stream. To this end, we contribute a
novel Adversarial Shapley value scoring method that scores memory data samples
according to their ability to preserve latent decision boundaries for
previously observed classes (to maintain learning stability and avoid
forgetting) while interfering with latent decision boundaries of current
classes being learned (to encourage plasticity and optimal learning of new
class boundaries). Overall, we observe that our proposed ASER method provides
competitive or improved performance compared to state-of-the-art replay-based
continual learning methods on a variety of datasets.
</p>
<a href="http://arxiv.org/abs/2009.00093" target="_blank">arXiv:2009.00093</a> [<a href="http://arxiv.org/pdf/2009.00093" target="_blank">pdf</a>]

<h2>FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning. (arXiv:2009.01974v3 [cs.LG] UPDATED)</h2>
<h3>Hong-You Chen, Wei-Lun Chao</h3>
<p>Federated learning aims to collaboratively train a strong global model by
accessing users' locally trained models but not their own data. A crucial step
is therefore to aggregate local models into a global model, which has been
shown challenging when users have non-i.i.d. data. In this paper, we propose a
novel aggregation algorithm named FedBE, which takes a Bayesian inference
perspective by sampling higher-quality global models and combining them via
Bayesian model Ensemble, leading to much robust aggregation. We show that an
effective model distribution can be constructed by simply fitting a Gaussian or
Dirichlet distribution to the local models. Our empirical studies validate
FedBE's superior performance, especially when users' data are not i.i.d. and
when the neural networks go deeper. Moreover, FedBE is compatible with recent
efforts in regularizing users' model training, making it an easily applicable
module: you only need to replace the aggregation method but leave other parts
of your federated learning algorithm intact.
</p>
<a href="http://arxiv.org/abs/2009.01974" target="_blank">arXiv:2009.01974</a> [<a href="http://arxiv.org/pdf/2009.01974" target="_blank">pdf</a>]

<h2>On the implementation of a global optimization method for mixed-variable problems. (arXiv:2009.02183v4 [cs.LG] UPDATED)</h2>
<h3>Giacomo Nannicini</h3>
<p>We describe the optimization algorithm implemented in the open-source
derivative-free solver RBFOpt. The algorithm is based on the radial basis
function method of Gutmann and the metric stochastic response surface method of
Regis and Shoemaker. We propose several modifications aimed at generalizing and
improving these two algorithms: (i) the use of an extended space to represent
categorical variables in unary encoding; (ii) a refinement phase to locally
improve a candidate solution; (iii) interpolation models without the
unisolvence condition, to both help deal with categorical variables, and
initiate the optimization before a uniquely determined model is possible; (iv)
a master-worker framework to allow asynchronous objective function evaluations
in parallel. Numerical experiments show the effectiveness of these ideas.
</p>
<a href="http://arxiv.org/abs/2009.02183" target="_blank">arXiv:2009.02183</a> [<a href="http://arxiv.org/pdf/2009.02183" target="_blank">pdf</a>]

<h2>Towards Automatic Manipulation of Intra-cardiac Echocardiography Catheter. (arXiv:2009.05859v3 [cs.RO] UPDATED)</h2>
<h3>Young-Ho Kim, Jarrod Collins, Zhongyu Li, Ponraj Chinnadurai, Ankur Kapoor, C. Huie Lin, Tommaso Mansi</h3>
<p>Intra-cardiac Echocardiography (ICE) is a powerful imaging modality for
guiding electrophysiology and structural heart interventions. ICE provides
real-time observation of anatomy, catheters, and emergent complications.
However, this increased reliance on intraprocedural imaging creates a high
cognitive demand on physicians who can often serve as interventionalist and
imager. We present a robotic manipulator for ICE catheters to assist physicians
with imaging and serve as a platform for developing processes for procedural
automation. Herein, we introduce two application modules towards these goals:
(1) a view recovery process that allows physicians to save views during
intervention and automatically return with the push of a button and (2) a
data-driven approach to compensate kinematic model errors that result from
non-linear behaviors in catheter bending, providing more precise control of the
catheter tip. View recovery is validated by repeated catheter positioning in
cardiac phantom and animal experiments with position- and image-based analysis.
We present a simplified calibration approach for error compensation and verify
with complex rotation of the catheter in benchtop and phantom experiments under
varying realistic curvature conditions. Results support that a robotic
manipulator for ICE can provide an efficient and reproducible tool, potentially
reducing execution time and promoting greater utilization of ICE imaging.
</p>
<a href="http://arxiv.org/abs/2009.05859" target="_blank">arXiv:2009.05859</a> [<a href="http://arxiv.org/pdf/2009.05859" target="_blank">pdf</a>]

<h2>Online tensor factorization and CP-dictionary learning for Markovian data. (arXiv:2009.07612v2 [stat.ML] UPDATED)</h2>
<h3>Christopher Strohmeier, Hanbaek Lyu, Deanna Needell</h3>
<p>Online Tensor Factorization (OTF) is a fundamental tool in learning
low-dimensional interpretable features from streaming multi-modal data. While
various algorithmic and theoretical aspects of OTF have been investigated
recently, general convergence guarantee to stationary points of the objective
function without any incoherence or sparsity assumptions is still lacking even
for the i.i.d. case. In this work, we introduce a novel OTF algorithm that
learns a CANDECOMP/PARAFAC (CP) basis from a given stream of tensor-valued data
under general constraints, including nonnegativity constraints that induce
interpretability of learned CP basis. We prove that our algorithm converges
almost surely to the set of stationary points of the objective function under
the hypothesis that the sequence of data tensors is generated by some
underlying Markov chain. Our setting covers the classical i.i.d. case as well
as a wide range of application contexts including data streams generated by
independent or MCMC sampling. Our result closes a gap between OTF and Online
Matrix Factorization in global convergence analysis. Experimentally, we show
that our OTF algorithm converges much faster than standard algorithms for
nonnegative tensor factorization tasks on both synthetic and real-world data.
Also, we demonstrate the utility of our algorithm on a diverse set of examples
from image, video, and time-series data, illustrating how one may learn
qualitatively different CP-dictionaries from the same tensor data by exploiting
the tensor structure in multiple ways.
</p>
<a href="http://arxiv.org/abs/2009.07612" target="_blank">arXiv:2009.07612</a> [<a href="http://arxiv.org/pdf/2009.07612" target="_blank">pdf</a>]

<h2>On the Tractability of SHAP Explanations. (arXiv:2009.08634v2 [cs.AI] UPDATED)</h2>
<h3>Guy Van den Broeck, Anton Lykov, Maximilian Schleich, Dan Suciu</h3>
<p>SHAP explanations are a popular feature-attribution mechanism for explainable
AI. They use game-theoretic notions to measure the influence of individual
features on the prediction of a machine learning model. Despite a lot of recent
interest from both academia and industry, it is not known whether SHAP
explanations of common machine learning models can be computed efficiently. In
this paper, we establish the complexity of computing the SHAP explanation in
three important settings. First, we consider fully-factorized data
distributions, and show that the complexity of computing the SHAP explanation
is the same as the complexity of computing the expected value of the model.
This fully-factorized setting is often used to simplify the SHAP computation,
yet our results show that the computation can be intractable for commonly used
models such as logistic regression. Going beyond fully-factorized
distributions, we show that computing SHAP explanations is already intractable
for a very simple setting: computing SHAP explanations of trivial classifiers
over naive Bayes distributions. Finally, we show that even computing SHAP over
the empirical distribution is #P-hard.
</p>
<a href="http://arxiv.org/abs/2009.08634" target="_blank">arXiv:2009.08634</a> [<a href="http://arxiv.org/pdf/2009.08634" target="_blank">pdf</a>]

<h2>Efficient Certification of Spatial Robustness. (arXiv:2009.09318v2 [cs.LG] UPDATED)</h2>
<h3>Anian Ruoss, Maximilian Baader, Mislav Balunovi&#x107;, Martin Vechev</h3>
<p>Recent work has exposed the vulnerability of computer vision models to vector
field attacks. Due to the widespread usage of such models in safety-critical
applications, it is crucial to quantify their robustness against such spatial
transformations. However, existing work only provides empirical robustness
quantification against vector field deformations via adversarial attacks, which
lack provable guarantees. In this work, we propose novel convex relaxations,
enabling us, for the first time, to provide a certificate of robustness against
vector field transformations. Our relaxations are model-agnostic and can be
leveraged by a wide range of neural network verifiers. Experiments on various
network architectures and different datasets demonstrate the effectiveness and
scalability of our method.
</p>
<a href="http://arxiv.org/abs/2009.09318" target="_blank">arXiv:2009.09318</a> [<a href="http://arxiv.org/pdf/2009.09318" target="_blank">pdf</a>]

<h2>Expectation propagation on the diluted Bayesian classifier. (arXiv:2009.09545v2 [stat.ML] UPDATED)</h2>
<h3>Alfredo Braunstein, Thomas Gueudr&#xe9;, Andrea Pagnani, Mirko Pieropan</h3>
<p>Efficient feature selection from high-dimensional datasets is a very
important challenge in many data-driven fields of science and engineering. We
introduce a statistical mechanics inspired strategy that addresses the problem
of sparse feature selection in the context of binary classification by
leveraging a computational scheme known as expectation propagation (EP). The
algorithm is used in order to train a continuous-weights perceptron learning a
classification rule from a set of (possibly partly mislabeled) examples
provided by a teacher perceptron with diluted continuous weights. We test the
method in the Bayes optimal setting under a variety of conditions and compare
it to other state-of-the-art algorithms based on message passing and on
expectation maximization approximate inference schemes. Overall, our
simulations show that EP is a robust and competitive algorithm in terms of
variable selection properties, estimation accuracy and computational
complexity, especially when the student perceptron is trained from correlated
patterns that prevent other iterative methods from converging. Furthermore, our
numerical tests demonstrate that the algorithm is capable of learning online
the unknown values of prior parameters, such as the dilution level of the
weights of the teacher perceptron and the fraction of mislabeled examples,
quite accurately. This is achieved by means of a simple maximum likelihood
strategy that consists in minimizing the free energy associated with the EP
algorithm.
</p>
<a href="http://arxiv.org/abs/2009.09545" target="_blank">arXiv:2009.09545</a> [<a href="http://arxiv.org/pdf/2009.09545" target="_blank">pdf</a>]

<h2>A Gradient Flow Framework For Analyzing Network Pruning. (arXiv:2009.11839v3 [cs.LG] UPDATED)</h2>
<h3>Ekdeep Singh Lubana, Robert P. Dick</h3>
<p>Recent network pruning methods focus on pruning models early-on in training.
To estimate the impact of removing a parameter, these methods use importance
measures that were originally designed to prune trained models. Despite lacking
justification for their use early-on in training, such measures result in
surprisingly low accuracy loss. To better explain this behavior, we develop a
general framework that uses gradient flow to unify state-of-the-art importance
measures through the norm of model parameters. We use this framework to
determine the relationship between pruning measures and evolution of model
parameters, establishing several results related to pruning models early-on in
training: (i) magnitude-based pruning removes parameters that contribute least
to reduction in loss, resulting in models that converge faster than
magnitude-agnostic methods; (ii) loss-preservation based pruning preserves
first-order model evolution dynamics and is therefore appropriate for pruning
minimally trained models; and (iii) gradient-norm based pruning affects
second-order model evolution dynamics, such that increasing gradient norm via
pruning can produce poorly performing models. We validate our claims on several
VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100. Code
available at https://github.com/EkdeepSLubana/flowandprune.
</p>
<a href="http://arxiv.org/abs/2009.11839" target="_blank">arXiv:2009.11839</a> [<a href="http://arxiv.org/pdf/2009.11839" target="_blank">pdf</a>]

<h2>From Pixel to Patch: Synthesize Context-aware Features for Zero-shot Semantic Segmentation. (arXiv:2009.12232v3 [cs.CV] UPDATED)</h2>
<h3>Zhangxuan Gu, Siyuan Zhou, Li Niu, Zihan Zhao, Liqing Zhang</h3>
<p>Zero-shot learning has been actively studied for image classification task to
relieve the burden of annotating image labels. Interestingly, semantic
segmentation task requires more labor-intensive pixel-wise annotation, but
zero-shot semantic segmentation has only attracted limited research interest.
Thus, we focus on zero-shot semantic segmentation, which aims to segment unseen
objects with only category-level semantic representations provided for unseen
categories. In this paper, we propose a novel Context-aware feature Generation
Network (CaGNet), which can synthesize context-aware pixel-wise visual features
for unseen categories based on category-level semantic representations and
pixel-wise contextual information. The synthesized features are used to
finetune the classifier to enable segmenting unseen objects. Furthermore, we
extend pixel-wise feature generation and finetuning to patch-wise feature
generation and finetuning, which additionally considers inter-pixel
relationship. Experimental results on Pascal-VOC, Pascal-Context, and
COCO-stuff show that our method significantly outperforms the existing
zero-shot semantic segmentation methods. Code is available at
https://github.com/bcmi/CaGNetv2-Zero-Shot-Semantic-Segmentation.
</p>
<a href="http://arxiv.org/abs/2009.12232" target="_blank">arXiv:2009.12232</a> [<a href="http://arxiv.org/pdf/2009.12232" target="_blank">pdf</a>]

<h2>Analysing the impact of global demographic characteristics over the COVID-19 spread using class rule mining and pattern matching. (arXiv:2009.12923v3 [cs.LG] UPDATED)</h2>
<h3>Wasiq Khan, Abir Hussain, Sohail Ahmed Khan, Mohammed Al-Jumailey, Raheel Nawaz, Panos Liatsis</h3>
<p>Since the coronavirus disease (COVID-19) outbreak in December 2019, studies
have been addressing diverse aspects in relation to COVID-19 and Variant of
Concern 202012/01 (VOC 202012/01) such as potential symptoms and predictive
tools. However, limited work has been performed towards the modelling of
complex associations between the combined demographic attributes and varying
nature of the COVID-19 infections across the globe. This study presents an
intelligent approach to investigate the multi-dimensional associations between
demographic attributes and COVID-19 global variations. We gather multiple
demographic attributes and COVID-19 infection data (by 8 January 2021) from
reliable sources, which are then processed by intelligent algorithms to
identify the significant associations and patterns within the data. Statistical
results and experts' reports indicate strong associations between COVID-19
severity levels across the globe and certain demographic attributes, e.g.
female smokers, when combined together with other attributes. The outcomes will
aid the understanding of the dynamics of disease spread and its progression,
which in turn may support policy makers, medical specialists and society, in
better understanding and effective management of the disease.
</p>
<a href="http://arxiv.org/abs/2009.12923" target="_blank">arXiv:2009.12923</a> [<a href="http://arxiv.org/pdf/2009.12923" target="_blank">pdf</a>]

<h2>Apollo: An Adaptive Parameter-wise Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization. (arXiv:2009.13586v4 [cs.LG] UPDATED)</h2>
<h3>Xuezhe Ma</h3>
<p>In this paper, we introduce Apollo, a quasi-Newton method for nonconvex
stochastic optimization, which dynamically incorporates the curvature of the
loss function by approximating the Hessian via a diagonal matrix. Importantly,
the update and storage of the diagonal approximation of Hessian is as efficient
as adaptive first-order optimization methods with linear complexity for both
time and memory. To handle nonconvexity, we replace the Hessian with its
rectified absolute value, which is guaranteed to be positive-definite.
Experiments on three tasks of vision and language show that Apollo achieves
significant improvements over other stochastic optimization methods, including
SGD and variants of Adam, in term of both convergence speed and generalization
performance. The implementation of the algorithm is available at
https://github.com/XuezheMax/apollo.
</p>
<a href="http://arxiv.org/abs/2009.13586" target="_blank">arXiv:2009.13586</a> [<a href="http://arxiv.org/pdf/2009.13586" target="_blank">pdf</a>]

<h2>Uncovering Feature Interdependencies in High-Noise Environments with Stepwise Lookahead Decision Forests. (arXiv:2009.14572v4 [cs.LG] UPDATED)</h2>
<h3>Delilah Donick, Sandro Claudio Lera</h3>
<p>A "stepwise lookahead" variation of the random forest algorithm is presented
for its ability to better uncover feature interdependencies inherent in complex
systems. Conventionally, random forests are built from "greedy" decision trees
which each consider only one split at a time during their construction. In
contrast, the decision trees included in this random forest algorithm each
simultaneously consider three split nodes in tiers of depth two. It is
demonstrated on synthetic data and financial price time series that the
lookahead version significantly outperforms the greedy one if certain
non-linear relationships between feature-pairs are present. This outperformance
is particularly pronounced in regimes of low signal-to-noise ratio. A
long-short trading strategy for copper futures is then backtested by training
both greedy and non-greedy random forests to predict the signs of daily price
returns. The resulting superior performance of the lookahead algorithm is at
least partially explained by the presence of "XOR-like" relationships between
long-term and short-term technical indicators. More generally, across all
examined datasets, when no such relationships between features are present,
performance across random forests is similar. Given its enhanced ability to
understand the feature-interdependencies present in complex systems, this
lookahead variation is a useful extension to the toolkit of data scientists.
</p>
<a href="http://arxiv.org/abs/2009.14572" target="_blank">arXiv:2009.14572</a> [<a href="http://arxiv.org/pdf/2009.14572" target="_blank">pdf</a>]

<h2>DoubleEnsemble: A New Ensemble Method Based on Sample Reweighting and Feature Selection for Financial Data Analysis. (arXiv:2010.01265v3 [cs.LG] UPDATED)</h2>
<h3>Chuheng Zhang, Yuanqi Li, Xi Chen, Yifei Jin, Pingzhong Tang, Jian Li</h3>
<p>Modern machine learning models (such as deep neural networks and boosting
decision tree models) have become increasingly popular in financial market
prediction, due to their superior capacity to extract complex non-linear
patterns. However, since financial datasets have very low signal-to-noise ratio
and are non-stationary, complex models are often very prone to overfitting and
suffer from instability issues. Moreover, as various machine learning and data
mining tools become more widely used in quantitative trading, many trading
firms have been producing an increasing number of features (aka factors).
Therefore, how to automatically select effective features becomes an imminent
problem. To address these issues, we propose DoubleEnsemble, an ensemble
framework leveraging learning trajectory based sample reweighting and shuffling
based feature selection. Specifically, we identify the key samples based on the
training dynamics on each sample and elicit key features based on the ablation
impact of each feature via shuffling. Our model is applicable to a wide range
of base models, capable of extracting complex patterns, while mitigating the
overfitting and instability issues for financial market prediction. We conduct
extensive experiments, including price prediction for cryptocurrencies and
stock trading, using both DNN and gradient boosting decision tree as base
models. Our experiment results demonstrate that DoubleEnsemble achieves a
superior performance compared with several baseline methods.
</p>
<a href="http://arxiv.org/abs/2010.01265" target="_blank">arXiv:2010.01265</a> [<a href="http://arxiv.org/pdf/2010.01265" target="_blank">pdf</a>]

<h2>Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms. (arXiv:2010.05273v4 [cs.LG] UPDATED)</h2>
<h3>Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, Afshin Rostamizadeh</h3>
<p>Federated learning is typically approached as an optimization problem, where
the goal is to minimize a global loss function by distributing computation
across client devices that possess local data and specify different parts of
the global objective. We present an alternative perspective and formulate
federated learning as a posterior inference problem, where the goal is to infer
a global posterior distribution by having client devices each infer the
posterior of their local data. While exact inference is often intractable, this
perspective provides a principled way to search for global optima in federated
settings. Further, starting with the analysis of federated quadratic
objectives, we develop a computation- and communication-efficient approximate
posterior inference algorithm -- federated posterior averaging (FedPA). Our
algorithm uses MCMC for approximate inference of local posteriors on the
clients and efficiently communicates their statistics to the server, where the
latter uses them to refine a global estimate of the posterior mode. Finally, we
show that FedPA generalizes federated averaging (FedAvg), can similarly benefit
from adaptive optimizers, and yields state-of-the-art results on four realistic
and challenging benchmarks, converging faster, to better optima.
</p>
<a href="http://arxiv.org/abs/2010.05273" target="_blank">arXiv:2010.05273</a> [<a href="http://arxiv.org/pdf/2010.05273" target="_blank">pdf</a>]

<h2>Learning, compression, and leakage: Minimising classification error via meta-universal compression principles. (arXiv:2010.07382v2 [cs.LG] UPDATED)</h2>
<h3>Fernando E. Rosas, Pedro A.M. Mediano, Michael Gastpar</h3>
<p>Learning and compression are driven by the common aim of identifying and
exploiting statistical regularities in data, which opens the door for fertile
collaboration between these areas. A promising group of compression techniques
for learning scenarios is normalised maximum likelihood (NML) coding, which
provides strong guarantees for compression of small datasets - in contrast with
more popular estimators whose guarantees hold only in the asymptotic limit.
Here we consider a NML-based decision strategy for supervised classification
problems, and show that it attains heuristic PAC learning when applied to a
wide variety of models. Furthermore, we show that the misclassification rate of
our method is upper bounded by the maximal leakage, a recently proposed metric
to quantify the potential of data leakage in privacy-sensitive scenarios.
</p>
<a href="http://arxiv.org/abs/2010.07382" target="_blank">arXiv:2010.07382</a> [<a href="http://arxiv.org/pdf/2010.07382" target="_blank">pdf</a>]

<h2>Multi-Resolution 3D Mapping with Explicit Free Space Representation for Fast and Accurate Mobile Robot Motion Planning. (arXiv:2010.07929v5 [cs.RO] UPDATED)</h2>
<h3>Nils Funk, Juan Tarrio, Sotiris Papatheodorou, Marija Popovic, Pablo F. Alcantarilla, Stefan Leutenegger</h3>
<p>With the aim of bridging the gap between high quality reconstruction and
mobile robot motion planning, we propose an efficient system that leverages the
concept of adaptive-resolution volumetric mapping, which naturally integrates
with the hierarchical decomposition of space in an octree data structure.
Instead of a Truncated Signed Distance Function (TSDF), we adopt mapping of
occupancy probabilities in log-odds representation, which allows to represent
both surfaces, as well as the entire free, i.e. observed space, as opposed to
unobserved space. We introduce a method for choosing resolution -- on the fly
-- in real-time by means of a multi-scale max-min pooling of the input depth
image. The notion of explicit free space mapping paired with the spatial
hierarchy in the data structure, as well as map resolution, allows for
collision queries, as needed for robot motion planning, at unprecedented speed.
We quantitatively evaluate mapping accuracy, memory, runtime performance, and
planning performance showing improvements over the state of the art,
particularly in cases requiring high resolution maps.
</p>
<a href="http://arxiv.org/abs/2010.07929" target="_blank">arXiv:2010.07929</a> [<a href="http://arxiv.org/pdf/2010.07929" target="_blank">pdf</a>]

<h2>Decision Making Problems with Funnel Structure: A Multi-Task Learning Approach with Application to Email Marketing Campaigns. (arXiv:2010.08048v2 [stat.ML] UPDATED)</h2>
<h3>Ziping Xu, Amirhossein Meisami, Ambuj Tewari</h3>
<p>This paper studies the decision making problem with Funnel Structure. Funnel
structure, a well-known concept in the marketing field, occurs in those systems
where the decision maker interacts with the environment in a layered manner
receiving far fewer observations from deep layers than shallow ones. For
example, in the email marketing campaign application, the layers correspond to
Open, Click and Purchase events. Conversions from Click to Purchase happen very
infrequently because a purchase cannot be made unless the link in an email is
clicked on.

We formulate this challenging decision making problem as a contextual bandit
with funnel structure and develop a multi-task learning algorithm that
mitigates the lack of sufficient observations from deeper layers. We analyze
both the prediction error and the regret of our algorithms. We verify our
theory on prediction errors through a simple simulation. Experiments on both a
simulated environment and an environment based on real-world data from a major
email marketing company show that our algorithms offer significant improvement
over previous methods.
</p>
<a href="http://arxiv.org/abs/2010.08048" target="_blank">arXiv:2010.08048</a> [<a href="http://arxiv.org/pdf/2010.08048" target="_blank">pdf</a>]

<h2>PRIMAL2: Pathfinding via Reinforcement and Imitation Multi-Agent Learning -- Lifelong. (arXiv:2010.08184v2 [cs.RO] UPDATED)</h2>
<h3>Mehul Damani, Zhiyao Luo, Emerson Wenzel, Guillaume Sartoretti</h3>
<p>Multi-agent path finding (MAPF) is an indispensable component of large-scale
robot deployments in numerous domains ranging from airport management to
warehouse automation. In particular, this work addresses lifelong MAPF (LMAPF)
- an online variant of the problem where agents are immediately assigned a new
goal upon reaching their current one - in dense and highly structured
environments, typical of real-world warehouse operations. Effectively solving
LMAPF in such environments requires expensive coordination between agents as
well as frequent replanning abilities, a daunting task for existing coupled and
decoupled approaches alike. With the purpose of achieving considerable agent
coordination without any compromise on reactivity and scalability, we introduce
PRIMAL2, a distributed reinforcement learning framework for LMAPF where agents
learn fully decentralized policies to reactively plan paths online in a
partially observable world. We extend our previous work, which was effective in
low-density sparsely occupied worlds, to highly structured and constrained
worlds by identifying behaviors and conventions which improve implicit agent
coordination, and enable their learning through the construction of a novel
local agent observation and various training aids. We present extensive results
of PRIMAL2 in both MAPF and LMAPF environments and compare its performance to
state-of-the-art planners in terms of makespan and throughput. We show that
PRIMAL2 significantly surpasses our previous work and performs comparably to
these baselines, while allowing real-time re-planning and scaling up to 2048
agents.
</p>
<a href="http://arxiv.org/abs/2010.08184" target="_blank">arXiv:2010.08184</a> [<a href="http://arxiv.org/pdf/2010.08184" target="_blank">pdf</a>]

<h2>Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure. (arXiv:2010.13561v2 [cs.LG] UPDATED)</h2>
<h3>Ben Hutchinson, Andrew Smart, Alex Hanna, Emily Denton, Christina Greer, Oddur Kjartansson, Parker Barnes, Margaret Mitchell</h3>
<p>Rising concern for the societal implications of artificial intelligence
systems has inspired demands for greater transparency and accountability.
However the datasets which empower machine learning are often used, shared and
re-used with little visibility into the processes of deliberation which led to
their creation. Which stakeholder groups had their perspectives included when
the dataset was conceived? Which domain experts were consulted regarding how to
model subgroups and other phenomena? How were questions of representational
biases measured and addressed? Who labeled the data? In this paper, we
introduce a rigorous framework for dataset development transparency which
supports decision-making and accountability. The framework uses the cyclical,
infrastructural and engineering nature of dataset development to draw on best
practices from the software development lifecycle. Each stage of the data
development lifecycle yields a set of documents that facilitate improved
communication and decision-making, as well as drawing attention the value and
necessity of careful data work. The proposed framework is intended to
contribute to closing the accountability gap in artificial intelligence
systems, by making visible the often overlooked work that goes into dataset
creation.
</p>
<a href="http://arxiv.org/abs/2010.13561" target="_blank">arXiv:2010.13561</a> [<a href="http://arxiv.org/pdf/2010.13561" target="_blank">pdf</a>]

<h2>Handgun detection using combined human pose and weapon appearance. (arXiv:2010.13753v3 [cs.CV] UPDATED)</h2>
<h3>Jesus Ruiz-Santaquiteria, Alberto Velasco-Mata, Noelia Vallez, Gloria Bueno, Juan A. &#xc1;lvarez-Garc&#xed;a, Oscar Deniz</h3>
<p>Closed-circuit television (CCTV) systems are essential nowadays to prevent
security threats or dangerous situations, in which early detection is crucial.
Novel deep learning-based methods have allowed to develop automatic weapon
detectors with promising results. However, these approaches are based on visual
weapon appearance only. For handguns, body pose may be a useful cue, especially
in cases where the gun is barely visible. In this work, a novel method is
proposed to combine, in a single architecture, both weapon appearance and human
pose information. First, pose keypoints are estimated to extract hand regions
and generate binary pose images, which are the model inputs. Then, each input
is processed in different subnetworks to extract two feature maps. Finally,
this information is combined to produce the hand region prediction. Results
obtained show that the combined model improves overall performance with respect
to appearance alone as used by popular methods such as YOLOv3.
</p>
<a href="http://arxiv.org/abs/2010.13753" target="_blank">arXiv:2010.13753</a> [<a href="http://arxiv.org/pdf/2010.13753" target="_blank">pdf</a>]

<h2>Collective Knowledge: organizing research projects as a database of reusable components and portable workflows with common APIs. (arXiv:2011.01149v2 [cs.LG] UPDATED)</h2>
<h3>Grigori Fursin</h3>
<p>This article provides the motivation and overview of the Collective Knowledge
framework (CK or cKnowledge). The CK concept is to decompose research projects
into reusable components that encapsulate research artifacts and provide
unified application programming interfaces (APIs), command-line interfaces
(CLIs), meta descriptions and common automation actions for related artifacts.
The CK framework is used to organize and manage research projects as a database
of such components.

Inspired by the USB "plug and play" approach for hardware, CK also helps to
assemble portable workflows that can automatically plug in compatible
components from different users and vendors (models, datasets, frameworks,
compilers, tools). Such workflows can build and run algorithms on different
platforms and environments in a unified way using the universal CK program
pipeline with software detection plugins and the automatic installation of
missing packages.

This article presents a number of industrial projects in which the modular CK
approach was successfully validated in order to automate benchmarking,
auto-tuning and co-design of efficient software and hardware for machine
learning (ML) and artificial intelligence (AI) in terms of speed, accuracy,
energy, size and various costs. The CK framework also helped to automate the
artifact evaluation process at several computer science conferences as well as
to make it easier to reproduce, compare and reuse research techniques from
published papers, deploy them in production, and automatically adapt them to
continuously changing datasets, models and systems.

The long-term goal is to accelerate innovation by connecting researchers and
practitioners to share and reuse all their knowledge, best practices,
artifacts, workflows and experimental results in a common, portable and
reproducible format at https://cKnowledge.io .
</p>
<a href="http://arxiv.org/abs/2011.01149" target="_blank">arXiv:2011.01149</a> [<a href="http://arxiv.org/pdf/2011.01149" target="_blank">pdf</a>]

<h2>Learning a Generative Motion Model from Image Sequences based on a Latent Motion Matrix. (arXiv:2011.01741v2 [cs.CV] UPDATED)</h2>
<h3>Julian Krebs, Herv&#xe9; Delingette, Nicholas Ayache, Tommaso Mansi</h3>
<p>We propose to learn a probabilistic motion model from a sequence of images
for spatio-temporal registration. Our model encodes motion in a low-dimensional
probabilistic space - the motion matrix - which enables various motion analysis
tasks such as simulation and interpolation of realistic motion patterns
allowing for faster data acquisition and data augmentation. More precisely, the
motion matrix allows to transport the recovered motion from one subject to
another simulating for example a pathological motion in a healthy subject
without the need for inter-subject registration. The method is based on a
conditional latent variable model that is trained using amortized variational
inference. This unsupervised generative model follows a novel multivariate
Gaussian process prior and is applied within a temporal convolutional network
which leads to a diffeomorphic motion model. Temporal consistency and
generalizability is further improved by applying a temporal dropout training
scheme. Applied to cardiac cine-MRI sequences, we show improved registration
accuracy and spatio-temporally smoother deformations compared to three
state-of-the-art registration algorithms. Besides, we demonstrate the model's
applicability for motion analysis, simulation and super-resolution by an
improved motion reconstruction from sequences with missing frames compared to
linear and cubic interpolation.
</p>
<a href="http://arxiv.org/abs/2011.01741" target="_blank">arXiv:2011.01741</a> [<a href="http://arxiv.org/pdf/2011.01741" target="_blank">pdf</a>]

<h2>Non-linear Hysteresis Compensation of a Tendon-sheath-driven Robotic Manipulator using Motor Current. (arXiv:2011.01817v2 [cs.RO] UPDATED)</h2>
<h3>Dong-Ho Lee, Young-Ho Kim, Jarrod Collins, Ankur Kapoor, Dong-Soo Kwon, Tommaso Mansi</h3>
<p>Tendon-sheath-driven manipulators (TSM) are widely used in minimally invasive
surgical systems due to their long, thin shape, flexibility, and compliance
making them easily steerable in narrow or tortuous environments. Many
commercial TSM-based medical devices have non-linear phenomena resulting from
their composition such as backlash hysteresis and dead zone, which lead to a
considerable challenge for achieving precise control of the end effector pose.
However, many recent works in the literature do not consider the combined
effects and compensation of these phenomena, and less focus on practical ways
to identify model parameters in realistic conditions. This paper proposes a
simplified piecewise linear model to construct both backlash hysteresis and
dead zone compensators together. Further, a practical method is introduced to
identify model parameters using motor current from a robotic controller for the
TSM. Our proposed methods are validated with multiple Intra-cardiac
Echocardiography (ICE) catheters, which are typical commercial example of TSM,
by periodic and non-periodic motions. Our results show that the errors from
backlash hysteresis and dead zone are considerably reduced and therefore the
accuracy of robotic control is improved when applying the presented methods.
</p>
<a href="http://arxiv.org/abs/2011.01817" target="_blank">arXiv:2011.01817</a> [<a href="http://arxiv.org/pdf/2011.01817" target="_blank">pdf</a>]

<h2>Asymptotically Optimal Information-Directed Sampling. (arXiv:2011.05944v2 [stat.ML] UPDATED)</h2>
<h3>Johannes Kirschner, Tor Lattimore, Claire Vernade, Csaba Szepesv&#xe1;ri</h3>
<p>We introduce a simple and efficient algorithm for stochastic linear bandits
with finitely many actions that is asymptotically optimal and worst-case rate
optimal in finite time. The approach is based on the frequentist
information-directed sampling (IDS) framework, with a surrogate for the
information gain that is informed by the optimization problem that defines the
asymptotic lower bound. Our analysis sheds light on how IDS balances the
trade-off between regret and information. Moreover, we uncover a surprising
connection between the recently proposed primal-dual methods and the Bayesian
IDS algorithm. We demonstrate empirically that IDS is competitive with UCB in
finite-time, and can be significantly better in the asymptotic regime.
</p>
<a href="http://arxiv.org/abs/2011.05944" target="_blank">arXiv:2011.05944</a> [<a href="http://arxiv.org/pdf/2011.05944" target="_blank">pdf</a>]

<h2>Exploring intermediate representation for monocular vehicle pose estimation. (arXiv:2011.08464v2 [cs.CV] UPDATED)</h2>
<h3>Shichao Li, Zengqiang Yan, Hongyang Li, Kwang-Ting Cheng</h3>
<p>We present a new learning-based approach to recover egocentric 3D vehicle
pose from a single RGB image. In contrast to previous works that directly map
from local appearance to 3D angles, we explore a progressive approach by
extracting meaningful Intermediate Geometrical Representations (IGRs) for 3D
pose estimation. We design a deep model that transforms perceived intensities
to IGRs, which are mapped to a 3D representation encoding object orientation in
the camera coordinate system. To fulfill our goal, we need to specify what IGRs
to use and how to learn them more effectively. We answer the former question by
designing an interpolated cuboid representation that derives from primitive 3D
annotation readily. The latter question motivates us to incorporate geometry
knowledge by designing a new loss function based on a projective invariant.
This loss function allows unlabeled data to be used in the training stage which
is validated to improve representation learning. Our system outperforms
previous monocular RGB-based methods for joint vehicle detection and pose
estimation on the KITTI benchmark, achieving performance even comparable to
stereo methods. Code and pre-trained models will be available at the project
website.
</p>
<a href="http://arxiv.org/abs/2011.08464" target="_blank">arXiv:2011.08464</a> [<a href="http://arxiv.org/pdf/2011.08464" target="_blank">pdf</a>]

<h2>Generalized Continual Zero-Shot Learning. (arXiv:2011.08508v3 [cs.CV] UPDATED)</h2>
<h3>Chandan Gautam, Sethupathy Parameswaran, Ashish Mishra, Suresh Sundaram</h3>
<p>Recently, zero-shot learning (ZSL) emerged as an exciting topic and attracted
a lot of attention. ZSL aims to classify unseen classes by transferring the
knowledge from seen classes to unseen classes based on the class description.
Despite showing promising performance, ZSL approaches assume that the training
samples from all seen classes are available during the training, which is
practically not feasible. To address this issue, we propose a more generalized
and practical setup for ZSL, i.e., continual ZSL (CZSL), where classes arrive
sequentially in the form of a task and it actively learns from the changing
environment by leveraging the past experience. Further, to enhance the
reliability, we develop CZSL for a single head continual learning setting where
task identity is revealed during the training process but not during the
testing. To avoid catastrophic forgetting and intransigence, we use knowledge
distillation and storing and replay the few samples from previous tasks using a
small episodic memory. We develop baselines and evaluate generalized CZSL on
five ZSL benchmark datasets for two different settings of continual learning:
with and without class incremental. Moreover, CZSL is developed for two types
of variational autoencoders, which generates two types of features for
classification: (i) generated features at output space and (ii) generated
discriminative features at the latent space. The experimental results clearly
indicate the single head CZSL is more generalizable and suitable for practical
applications.
</p>
<a href="http://arxiv.org/abs/2011.08508" target="_blank">arXiv:2011.08508</a> [<a href="http://arxiv.org/pdf/2011.08508" target="_blank">pdf</a>]

<h2>Improving Augmentation and Evaluation Schemes for Semantic Image Synthesis. (arXiv:2011.12636v3 [cs.CV] UPDATED)</h2>
<h3>Prateek Katiyar, Anna Khoreva</h3>
<p>Despite data augmentation being a de facto technique for boosting the
performance of deep neural networks, little attention has been paid to
developing augmentation strategies for generative adversarial networks (GANs).
To this end, we introduce a novel augmentation scheme designed specifically for
GAN-based semantic image synthesis models. We propose to randomly warp object
shapes in the semantic label maps used as an input to the generator. The local
shape discrepancies between the warped and non-warped label maps and images
enable the GAN to learn better the structural and geometric details of the
scene and thus to improve the quality of generated images. While benchmarking
the augmented GAN models against their vanilla counterparts, we discover that
the quantification metrics reported in the previous semantic image synthesis
studies are strongly biased towards specific semantic classes as they are
derived via an external pre-trained segmentation network. We therefore propose
to improve the established semantic image synthesis evaluation scheme by
analyzing separately the performance of generated images on the biased and
unbiased classes for the given segmentation network. Finally, we show strong
quantitative and qualitative improvements obtained with our augmentation
scheme, on both class splits, using state-of-the-art semantic image synthesis
models across three different datasets. On average across COCO-Stuff, ADE20K
and Cityscapes datasets, the augmented models outperform their vanilla
counterparts by ~3 mIoU and ~10 FID points.
</p>
<a href="http://arxiv.org/abs/2011.12636" target="_blank">arXiv:2011.12636</a> [<a href="http://arxiv.org/pdf/2011.12636" target="_blank">pdf</a>]

<h2>IFSS-Net: Interactive Few-Shot Siamese Network for Faster Muscle Segmentation and Propagation in Volumetric Ultrasound. (arXiv:2011.13246v2 [cs.CV] UPDATED)</h2>
<h3>Dawood Al Chanti, Vanessa Gonzalez Duque, Marion Crouzier, Antoine Nordez, Lilian Lacourpaille, Diana Mateus</h3>
<p>We present an accurate, fast and efficient method for segmentation and muscle
mask propagation in 3D freehand ultrasound data, towards accurate volume
quantification. A deep Siamese 3D Encoder-Decoder network that captures the
evolution of the muscle appearance and shape for contiguous slices is deployed.
We uses it to propagate a reference mask annotated by a clinical expert. To
handle longer changes of the muscle shape over the entire volume and to provide
an accurate propagation, we devise a Bidirectional Long Short Term Memory
module. Also, to train our model with a minimal amount of training samples, we
propose a strategy combining learning from few annotated 2D ultrasound slices
with sequential pseudo-labeling of the unannotated slices. We introduce a
decremental update of the objective function to guide the model convergence in
the absence of large amounts of annotated data. After training with a small
number of volumes, the decremental update transitions from a weakly-supervised
training to a few-shot setting. Finally, to handle the class-imbalance between
foreground and background muscle pixels, we propose a parametric Tversky loss
function that learns to adaptively penalize false positives and false
negatives. We validate our approach for the segmentation, label propagation,
and volume computation of the three low-limb muscles on a dataset of 61600
images from 44 subjects. We achieve a Dice score coefficient of over $95~\%$
and a volumetric error \textcolor{black}{of} $1.6035 \pm 0.587~\%$.
</p>
<a href="http://arxiv.org/abs/2011.13246" target="_blank">arXiv:2011.13246</a> [<a href="http://arxiv.org/pdf/2011.13246" target="_blank">pdf</a>]

<h2>LABNet: Local Graph Aggregation Network with Class Balanced Loss for Vehicle Re-Identification. (arXiv:2011.14417v2 [cs.CV] UPDATED)</h2>
<h3>Abu Md Niamul Taufique, Andreas Savakis</h3>
<p>Vehicle re-identification is an important computer vision task where the
objective is to identify a specific vehicle among a set of vehicles seen at
various viewpoints. Recent methods based on deep learning utilize a global
average pooling layer after the backbone feature extractor, however, this
ignores any spatial reasoning on the feature map. In this paper, we propose
local graph aggregation on the backbone feature map, to learn associations of
local information and hence improve feature learning as well as reduce the
effects of partial occlusion and background clutter. Our local graph
aggregation network considers spatial regions of the feature map as nodes and
builds a local neighborhood graph that performs local feature aggregation
before the global average pooling layer. We further utilize a batch
normalization layer to improve the system effectiveness. Additionally, we
introduce a class balanced loss to compensate for the imbalance in the sample
distributions found in the most widely used vehicle re-identification datasets.
Finally, we evaluate our method in three popular benchmarks and show that our
approach outperforms many state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2011.14417" target="_blank">arXiv:2011.14417</a> [<a href="http://arxiv.org/pdf/2011.14417" target="_blank">pdf</a>]

<h2>DETR for Pedestrian Detection. (arXiv:2012.06785v2 [cs.CV] UPDATED)</h2>
<h3>Matthieu Lin, Chuming Li, Xingyuan Bu, Ming Sun, Chen Lin, Junjie Yan, Wanli Ouyang, Zhidong Deng</h3>
<p>Pedestrian detection in crowd scenes poses a challenging problem due to the
heuristic defined mapping from anchors to pedestrians and the conflict between
NMS and highly overlapped pedestrians. The recently proposed end-to-end
detectors(ED), DETR and deformable DETR, replace hand designed components such
as NMS and anchors using the transformer architecture, which gets rid of
duplicate predictions by computing all pairwise interactions between queries.
Inspired by these works, we explore their performance on crowd pedestrian
detection. Surprisingly, compared to Faster-RCNN with FPN, the results are
opposite to those obtained on COCO. Furthermore, the bipartite match of ED
harms the training efficiency due to the large ground truth number in crowd
scenes. In this work, we identify the underlying motives driving ED's poor
performance and propose a new decoder to address them. Moreover, we design a
mechanism to leverage the less occluded visible parts of pedestrian
specifically for ED, and achieve further improvements. A faster bipartite match
algorithm is also introduced to make ED training on crowd dataset more
practical. The proposed detector PED(Pedestrian End-to-end Detector)
outperforms both previous EDs and the baseline Faster-RCNN on CityPersons and
CrowdHuman. It also achieves comparable performance with state-of-the-art
pedestrian detection methods. Code will be released soon.
</p>
<a href="http://arxiv.org/abs/2012.06785" target="_blank">arXiv:2012.06785</a> [<a href="http://arxiv.org/pdf/2012.06785" target="_blank">pdf</a>]

<h2>Unsupervised Machine learning methods for city vitality index. (arXiv:2012.12082v2 [cs.LG] UPDATED)</h2>
<h3>Jean-S&#xe9;bastien Dessureault, Jonathan Simard, Daniel Massicotte</h3>
<p>This paper concerns the challenge to evaluate and predict a district vitality
index (VI) over the years. There is no standard method to do it, and it is even
more complicated to do it retroactively in the last decades. Although, it is
essential to evaluate and learn features of the past to predict a VI in the
future. This paper proposes a method to evaluate such a VI, based on a k-mean
clustering algorithm. The meta parameters of this unsupervised machine learning
technique are optimized by a genetic algorithm method. Based on the resulting
clusters and VI, a linear regression is applied to predict the VI of each
district of a city. The weights of each feature used in the clustering are
calculated using a random forest regressor algorithm. This method can be a
powerful insight for urbanists and inspire the redaction of a city plan in the
smart city context.
</p>
<a href="http://arxiv.org/abs/2012.12082" target="_blank">arXiv:2012.12082</a> [<a href="http://arxiv.org/pdf/2012.12082" target="_blank">pdf</a>]

<h2>A Survey on Visual Transformer. (arXiv:2012.12556v3 [cs.CV] UPDATED)</h2>
<h3>Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu, Yehui Tang, An Xiao, Chunjing Xu, Yixing Xu, Zhaohui Yang, Yiman Zhang, Dacheng Tao</h3>
<p>Transformer, first applied to the field of natural language processing, is a
type of deep neural network mainly based on the self-attention mechanism.
Thanks to its strong representation capabilities, researchers are looking at
ways to apply transformer to computer vision tasks. In a variety of visual
benchmarks, transformer-based models perform similar to or better than other
types of networks such as convolutional and recurrent networks. Given its high
performance and no need for human-defined inductive bias, transformer is
receiving more and more attention from the computer vision community. In this
paper, we review these visual transformer models by categorizing them in
different tasks and analyzing their advantages and disadvantages. The main
categories we explore include the backbone network, high/mid-level vision,
low-level vision, and video processing. We also take a brief look at the
self-attention mechanism in computer vision, as it is the base component in
transformer. Furthermore, we include efficient transformer methods for pushing
transformer into real device-based applications. Toward the end of this paper,
we discuss the challenges and provide several further research directions for
visual transformers.
</p>
<a href="http://arxiv.org/abs/2012.12556" target="_blank">arXiv:2012.12556</a> [<a href="http://arxiv.org/pdf/2012.12556" target="_blank">pdf</a>]

<h2>Temporal Contrastive Graph for Self-supervised Video Representation Learning. (arXiv:2101.00820v4 [cs.CV] UPDATED)</h2>
<h3>Yang Liu, Keze Wang, Haoyuan Lan, Liang Lin</h3>
<p>Attempt to fully explore the fine-grained temporal structure and global-local
chronological characteristics for self-supervised video representation
learning, this work takes a closer look at exploiting the temporal structure of
videos and further proposes a novel self-supervised method named Temporal
Contrastive Graph (TCG). In contrast to the existing methods that randomly
shuffle the video frames or video snippets within a video, our proposed TCG
roots in a hybrid graph contrastive learning strategy to regard the
inter-snippet and intra-snippet temporal relationships as self-supervision
signals for temporal representation learning. To increase the temporal
diversity of features more comprehensively and precisely, our proposed TCG
integrates the prior knowledge about the frame and snippet orders into temporal
contrastive graph structures, i.e., the intra-/inter- snippet temporal
contrastive graph modules. By randomly removing edges and masking node features
of the intra-snippet graphs or inter-snippet graphs, our TCG can generate
different correlated graph views. Then, specific contrastive losses are
designed to maximize the agreement between node embeddings in different views.
To learn the global context representation and recalibrate the channel-wise
features adaptively, we introduce an adaptive video snippet order prediction
module, which leverages the relational knowledge among video snippets to
predict the actual snippet orders.Experimental results demonstrate the
superiority of our TCG over the state-of-the-art methods on large-scale action
recognition and video retrieval benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.00820" target="_blank">arXiv:2101.00820</a> [<a href="http://arxiv.org/pdf/2101.00820" target="_blank">pdf</a>]

<h2>An Automatic System to Monitor the Physical Distance and Face Mask Wearing of Construction Workers in COVID-19 Pandemic. (arXiv:2101.01373v2 [cs.CV] UPDATED)</h2>
<h3>Moein Razavi, Hamed Alikhani, Vahid Janfaza, Benyamin Sadeghi, Ehsan Alikhani</h3>
<p>The COVID-19 pandemic has caused many shutdowns in different industries
around the world. Sectors such as infrastructure construction and maintenance
projects have not been suspended due to their significant effect on people's
routine life. In such projects, workers work close together that makes a high
risk of infection. The World Health Organization recommends wearing a face mask
and practicing physical distancing to mitigate the virus's spread. This paper
developed a computer vision system to automatically detect the violation of
face mask wearing and physical distancing among construction workers to assure
their safety on infrastructure projects during the pandemic. For the face mask
detection, the paper collected and annotated 1,000 images, including different
types of face mask wearing, and added them to a pre-existing face mask dataset
to develop a dataset of 1,853 images. Then trained and tested multiple
Tensorflow state-of-the-art object detection models on the face mask dataset
and chose the Faster R-CNN Inception ResNet V2 network that yielded the
accuracy of 99.8%. For physical distance detection, the paper employed the
Faster R-CNN Inception V2 to detect people. A transformation matrix was used to
eliminate the camera angle's effect on the object distances on the image. The
Euclidian distance used the pixels of the transformed image to compute the
actual distance between people. A threshold of six feet was considered to
capture physical distance violation. The paper also used transfer learning for
training the model. The final model was applied on four videos of road
maintenance projects in Houston, TX, that effectively detected the face mask
and physical distance. We recommend that construction owners use the proposed
system to enhance construction workers' safety in the pandemic situation.
</p>
<a href="http://arxiv.org/abs/2101.01373" target="_blank">arXiv:2101.01373</a> [<a href="http://arxiv.org/pdf/2101.01373" target="_blank">pdf</a>]

<h2>Characterizing Intersectional Group Fairness with Worst-Case Comparisons. (arXiv:2101.01673v3 [cs.LG] UPDATED)</h2>
<h3>Avijit Ghosh, Lea Genuit, Mary Reagan</h3>
<p>Machine Learning or Artificial Intelligence algorithms have gained
considerable scrutiny in recent times owing to their propensity towards
imitating and amplifying existing prejudices in society. This has led to a
niche but growing body of work that identifies and attempts to fix these
biases. A first step towards making these algorithms more fair is designing
metrics that measure unfairness. Most existing work in this field deals with
either a binary view of fairness (protected vs. unprotected groups) or
politically defined categories (race or gender). Such categorization misses the
important nuance of intersectionality - biases can often be amplified in
subgroups that combine membership from different categories, especially if such
a subgroup is particularly underrepresented in historical platforms of
opportunity.

In this paper, we discuss why fairness metrics need to be looked at under the
lens of intersectionality, identify existing work in intersectional fairness,
suggest a simple worst case comparison method to expand the definitions of
existing group fairness metrics to incorporate intersectionality, and finally
conclude with the social, legal and political framework to handle
intersectional fairness in the modern context.
</p>
<a href="http://arxiv.org/abs/2101.01673" target="_blank">arXiv:2101.01673</a> [<a href="http://arxiv.org/pdf/2101.01673" target="_blank">pdf</a>]

<h2>Navigation Framework for a Hybrid Steel Bridge Inspection Robot. (arXiv:2101.02282v2 [cs.RO] UPDATED)</h2>
<h3>Hoang-Dung Bui, Hung M. La</h3>
<p>Autonomous navigation is essential for steel bridge inspection robot to
monitor and maintain the working condition of steel bridges. Majority of
existing robotic solutions requires human support to navigate the robot doing
the inspection. In this paper, a navigation framework is proposed for ARA robot
[1], [2] to run on mobile mode. In this mode, the robot needs to cross and
inspect all the available steel bars. The most significant contributions of
this research are four algorithms, which can process the depth data, segment it
into clusters, estimate the boundaries, construct a graph to represent the
structure, generate a shortest inspection path with any starting and ending
points, and determine available robot configuration for path planning.
Experiments on steel bridge structures setup highlight the effective
performance of the algorithms, and the potential to apply to the ARA robot to
run on real bridge structures. We released our source code in Github for the
research community to use.
</p>
<a href="http://arxiv.org/abs/2101.02282" target="_blank">arXiv:2101.02282</a> [<a href="http://arxiv.org/pdf/2101.02282" target="_blank">pdf</a>]

<h2>Distribution-Free, Risk-Controlling Prediction Sets. (arXiv:2101.02703v2 [cs.LG] UPDATED)</h2>
<h3>Stephen Bates, Anastasios Angelopoulos, Lihua Lei, Jitendra Malik, Michael I. Jordan</h3>
<p>While improving prediction accuracy has been the focus of machine learning in
recent years, this alone does not suffice for reliable decision-making.
Deploying learning systems in consequential settings also requires calibrating
and communicating the uncertainty of predictions. To convey instance-wise
uncertainty for prediction tasks, we show how to generate set-valued
predictions from a black-box predictor that control the expected loss on future
test points at a user-specified level. Our approach provides explicit
finite-sample guarantees for any dataset by using a holdout set to calibrate
the size of the prediction sets. This framework enables simple,
distribution-free, rigorous error control for many tasks, and we demonstrate it
in five large-scale machine learning problems: (1) classification problems
where some mistakes are more costly than others; (2) multi-label
classification, where each observation has multiple associated labels; (3)
classification problems where the labels have a hierarchical structure; (4)
image segmentation, where we wish to predict a set of pixels containing an
object of interest; and (5) protein structure prediction. Lastly, we discuss
extensions to uncertainty quantification for ranking, metric learning and
distributionally robust learning.
</p>
<a href="http://arxiv.org/abs/2101.02703" target="_blank">arXiv:2101.02703</a> [<a href="http://arxiv.org/pdf/2101.02703" target="_blank">pdf</a>]

<h2>Quantum Mathematics in Artificial Intelligence. (arXiv:2101.04255v3 [cs.AI] UPDATED)</h2>
<h3>Dominic Widdows, Kirsty Kitto, Trevor Cohen</h3>
<p>In the decade since 2010, successes in artificial intelligence have been at
the forefront of computer science and technology, and vector space models have
solidified a position at the forefront of artificial intelligence. At the same
time, quantum computers have become much more powerful, and announcements of
major advances are frequently in the news.

The mathematical techniques underlying both these areas have more in common
than is sometimes realized. Vector spaces took a position at the axiomatic
heart of quantum mechanics in the 1930s, and this adoption was a key motivation
for the derivation of logic and probability from the linear geometry of vector
spaces. Quantum interactions between particles are modelled using the tensor
product, which is also used to express objects and operations in artificial
neural networks.

This paper describes some of these common mathematical areas, including
examples of how they are used in artificial intelligence (AI), particularly in
automated reasoning and natural language processing (NLP). Techniques discussed
include vector spaces, scalar products, subspaces and implication, orthogonal
projection and negation, dual vectors, density matrices, positive operators,
and tensor products. Application areas include information retrieval,
categorization and implication, modelling word-senses and disambiguation,
inference in knowledge bases, and semantic composition.

Some of these approaches can potentially be implemented on quantum hardware.
Many of the practical steps in this implementation are in early stages, and
some are already realized. Explaining some of the common mathematical tools can
help researchers in both AI and quantum computing further exploit these
overlaps, recognizing and exploring new directions along the way.
</p>
<a href="http://arxiv.org/abs/2101.04255" target="_blank">arXiv:2101.04255</a> [<a href="http://arxiv.org/pdf/2101.04255" target="_blank">pdf</a>]

<h2>MHT-X: Offline Multiple Hypothesis Tracking with Algorithm X. (arXiv:2101.05202v2 [cs.CV] UPDATED)</h2>
<h3>Peteris Zvejnieks, Mihails Birjukovs, Martins Klevs, Megumi Akashi, Sven Eckert, Andris Jakovics</h3>
<p>An efficient and versatile implementation of offline multiple hypothesis
tracking with Algorithm X for optimal association search was developed using
Python. The code is intended for scientific applications that do not require
online processing. Directed graph framework is used and multiple scans with
progressively increasing time window width are used for edge construction for
maximum likelihood trajectories. The current version of the code was developed
for applications in multiphase hydrodynamics, e.g. bubble and particle
tracking, and is capable of resolving object motion, merges and splits.
Feasible object associations and trajectory graph edge likelihoods are
determined using weak mass and momentum conservation laws translated to
statistical functions for object properties. The code is compatible with
n-dimensional motion with arbitrarily many tracked object properties. This
framework is easily extendable beyond the present application by replacing the
currently used heuristics with ones more appropriate for the problem at hand.
The code is open-source and will be continuously developed further.
</p>
<a href="http://arxiv.org/abs/2101.05202" target="_blank">arXiv:2101.05202</a> [<a href="http://arxiv.org/pdf/2101.05202" target="_blank">pdf</a>]

<h2>On Misspecification in Prediction Problems and Robustness via Improper Learning. (arXiv:2101.05234v2 [stat.ML] UPDATED)</h2>
<h3>Annie Marsden, John Duchi, Gregory Valiant</h3>
<p>We study probabilistic prediction games when the underlying model is
misspecified, investigating the consequences of predicting using an incorrect
parametric model. We show that for a broad class of loss functions and
parametric families of distributions, the regret of playing a "proper"
predictor -- one from the putative model class -- relative to the best
predictor in the same model class has lower bound scaling at least as
$\sqrt{\gamma n}$, where $\gamma$ is a measure of the model misspecification to
the true distribution in terms of total variation distance. In contrast, using
an aggregation-based (improper) learner, one can obtain regret $d \log n$ for
any underlying generating distribution, where $d$ is the dimension of the
parameter; we exhibit instances in which this is unimprovable even over the
family of all learners that may play distributions in the convex hull of the
parametric family. These results suggest that simple strategies for aggregating
multiple learners together should be more robust, and several experiments
conform to this hypothesis.
</p>
<a href="http://arxiv.org/abs/2101.05234" target="_blank">arXiv:2101.05234</a> [<a href="http://arxiv.org/pdf/2101.05234" target="_blank">pdf</a>]

<h2>A Unifying Generative Model for Graph Learning Algorithms: Label Propagation, Graph Convolutions, and Combinations. (arXiv:2101.07730v2 [cs.LG] UPDATED)</h2>
<h3>Junteng Jia, Austin R. Benson</h3>
<p>Semi-supervised learning on graphs is a widely applicable problem in network
science and machine learning. Two standard algorithms -- label propagation and
graph neural networks -- both operate by repeatedly passing information along
edges, the former by passing labels and the latter by passing node features,
modulated by neural networks. These two types of algorithms have largely
developed separately, and there is little understanding about the structure of
network data that would make one of these approaches work particularly well
compared to the other or when the approaches can be meaningfully combined.
Here, we develop a Markov random field model for the data generation process of
node attributes, based on correlations of attributes on and between vertices,
that motivates and unifies these algorithmic approaches. We show that label
propagation, a linearized graph convolutional network, and their combination
can all be derived as conditional expectations under our model, when
conditioning on different attributes. In addition, the data model highlights
deficiencies in existing graph neural networks (while producing new algorithmic
solutions), serves as a rigorous statistical framework for understanding graph
learning issues such as over-smoothing, creates a testbed for evaluating
inductive learning performance, and provides a way to sample graphs attributes
that resemble empirical data. We also find that a new algorithm derived from
our data generation model, which we call a Linear Graph Convolution, performs
extremely well in practice on empirical data, and provide theoretical
justification for why this is the case.
</p>
<a href="http://arxiv.org/abs/2101.07730" target="_blank">arXiv:2101.07730</a> [<a href="http://arxiv.org/pdf/2101.07730" target="_blank">pdf</a>]

<h2>1st Place Solution to ECCV-TAO-2020: Detect and Represent Any Object for Tracking. (arXiv:2101.08040v2 [cs.CV] UPDATED)</h2>
<h3>Fei Du, Bo Xu, Jiasheng Tang, Yuqi Zhang, Fan Wang, Hao Li</h3>
<p>We extend the classical tracking-by-detection paradigm to this
tracking-any-object task. Solid detection results are first extracted from TAO
dataset. Some state-of-the-art techniques like \textbf{BA}lanced-\textbf{G}roup
\textbf{S}oftmax (\textbf{BAGS}\cite{li2020overcoming}) and
DetectoRS\cite{qiao2020detectors} are integrated during detection. Then we
learned appearance features to represent any object by training feature
learning networks. We ensemble several models for improving detection and
feature representation. Simple linking strategies with most similar appearance
features and tracklet-level post association module are finally applied to
generate final tracking results. Our method is submitted as \textbf{AOA} on the
challenge website. Code is available at
https://github.com/feiaxyt/Winner_ECCV20_TAO.
</p>
<a href="http://arxiv.org/abs/2101.08040" target="_blank">arXiv:2101.08040</a> [<a href="http://arxiv.org/pdf/2101.08040" target="_blank">pdf</a>]

<h2>Anti-UAV: A Large Multi-Modal Benchmark for UAV Tracking. (arXiv:2101.08466v2 [cs.CV] UPDATED)</h2>
<h3>Nan Jiang, Kuiran Wang, Xiaoke Peng, Xuehui Yu, Qiang Wang, Junliang Xing, Guorong Li, Jian Zhao, Guodong Guo, Zhenjun Han</h3>
<p>Unmanned Aerial Vehicle (UAV) offers lots of applications in both commerce
and recreation. With this, monitoring the operation status of UAVs is crucially
important. In this work, we consider the task of tracking UAVs, providing rich
information such as location and trajectory. To facilitate research on this
topic, we propose a dataset, Anti-UAV, with more than 300 video pairs
containing over 580k manually annotated bounding boxes. The releasing of such a
large-scale dataset could be a useful initial step in research of tracking
UAVs. Furthermore, the advancement of addressing research challenges in
Anti-UAV can help the design of anti-UAV systems, leading to better
surveillance of UAVs. Besides, a novel approach named dual-flow semantic
consistency (DFSC) is proposed for UAV tracking. Modulated by the semantic flow
across video sequences, the tracker learns more robust class-level semantic
information and obtains more discriminative instance-level features.
Experimental results demonstrate that Anti-UAV is very challenging, and the
proposed method can effectively improve the tracker's performance. The Anti-UAV
benchmark and the code of the proposed approach will be publicly available at
https://github.com/ucas-vg/Anti-UAV.
</p>
<a href="http://arxiv.org/abs/2101.08466" target="_blank">arXiv:2101.08466</a> [<a href="http://arxiv.org/pdf/2101.08466" target="_blank">pdf</a>]

<h2>Cross Chest Graph for Disease Diagnosis with Structural Relational Reasoning. (arXiv:2101.08992v2 [cs.CV] UPDATED)</h2>
<h3>Gangming Zhao, Baolian Qi, Jinpeng Li</h3>
<p>Locating lesions is important in the computer-aided diagnosis of X-ray
images. However, box-level annotation is time-consuming and laborious. How to
locate lesions accurately with few, or even without careful annotations is an
urgent problem. Although several works have approached this problem with
weakly-supervised methods, the performance needs to be improved. One obstacle
is that general weakly-supervised methods have failed to consider the
characteristics of X-ray images, such as the highly-structural attribute. We
therefore propose the Cross-chest Graph (CCG), which improves the performance
of automatic lesion detection by imitating doctor's training and
decision-making process. CCG models the intra-image relationship between
different anatomical areas by leveraging the structural information to simulate
the doctor's habit of observing different areas. Meanwhile, the relationship
between any pair of images is modeled by a knowledge-reasoning module to
simulate the doctor's habit of comparing multiple images. We integrate
intra-image and inter-image information into a unified end-to-end framework.
Experimental results on the NIH Chest-14 database (112,120 frontal-view X-ray
images with 14 diseases) demonstrate that the proposed method achieves
state-of-the-art performance in weakly-supervised localization of lesions by
absorbing professional knowledge in the medical field.
</p>
<a href="http://arxiv.org/abs/2101.08992" target="_blank">arXiv:2101.08992</a> [<a href="http://arxiv.org/pdf/2101.08992" target="_blank">pdf</a>]

<h2>Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach. (arXiv:2101.09116v2 [cs.CV] UPDATED)</h2>
<h3>Yu Chen, Ji Zhao, Laurent Kneip</h3>
<p>We address rotation averaging (RA) and its application to real-world 3D
reconstruction. Local optimisation based approaches are the defacto choice,
though they only guarantee a local optimum. Global optimizers ensure global
optimality in low noise conditions, but they are inefficient and may easily
deviate under the influence of outliers or elevated noise levels. We push the
envelope of rotation averaging by leveraging the advantages of global RA method
and local RA method. Combined with a fast view graph filtering as
preprocessing, the proposed hybrid approach is robust to outliers. We apply the
proposed hybrid rotation averaging approach to incremental Structure from
Motion (SfM) by adding the resulting global rotations as regularizers to bundle
adjustment. Overall, we demonstrate high practicality of the proposed method as
bad camera poses are effectively corrected and drift is reduced.
</p>
<a href="http://arxiv.org/abs/2101.09116" target="_blank">arXiv:2101.09116</a> [<a href="http://arxiv.org/pdf/2101.09116" target="_blank">pdf</a>]

<h2>MultiFace: A Generic Training Mechanism for Boosting Face Recognition Performance. (arXiv:2101.09899v2 [cs.CV] UPDATED)</h2>
<h3>Jing Xu, Tszhang Guo, Zenglin Xu, Kun Bai</h3>
<p>Deep Convolutional Neural Networks (DCNNs) and their variants have been
widely used in large scale face recognition(FR) recently. Existing methods have
achieved good performance on many FR benchmarks. However, most of them suffer
from two major problems. First, these methods converge quite slowly since they
optimize the loss functions in a high-dimensional and sparse Gaussian Sphere.
Second, the high dimensionality of features, despite the powerful descriptive
ability, brings difficulty to the optimization, which may lead to a sub-optimal
local optimum. To address these problems, we propose a simple yet efficient
training mechanism called MultiFace, where we approximate the original
high-dimensional features by the ensemble of low-dimensional features. The
proposed mechanism is also generic and can be easily applied to many advanced
FR models. Moreover, it brings the benefits of good interpretability to FR
models via the clustering effect. In detail, the ensemble of these
low-dimensional features can capture complementary yet discriminative
information, which can increase the intra-class compactness and inter-class
separability. Experimental results show that the proposed mechanism can
accelerate 2-3 times with the softmax loss and 1.2-1.5 times with Arcface or
Cosface, while achieving state-of-the-art performances in several benchmark
datasets. Especially, the significant improvements on large-scale
datasets(e.g., IJB and MageFace) demonstrate the flexibility of our new
training mechanism.
</p>
<a href="http://arxiv.org/abs/2101.09899" target="_blank">arXiv:2101.09899</a> [<a href="http://arxiv.org/pdf/2101.09899" target="_blank">pdf</a>]

<h2>Gigapixel Histopathological Image Analysis using Attention-based Neural Networks. (arXiv:2101.09992v2 [cs.CV] UPDATED)</h2>
<h3>Nadia Brancati, Giuseppe De Pietro, Daniel Riccio, Maria Frucci</h3>
<p>Although CNNs are widely considered as the state-of-the-art models in various
applications of image analysis, one of the main challenges still open is the
training of a CNN on high resolution images. Different strategies have been
proposed involving either a rescaling of the image or an individual processing
of parts of the image. Such strategies cannot be applied to images, such as
gigapixel histopathological images, for which a high reduction in resolution
inherently effects a loss of discriminative information, and in respect of
which the analysis of single parts of the image suffers from a lack of global
information or implies a high workload in terms of annotating the training
images in such a way as to select significant parts. We propose a method for
the analysis of gigapixel histopathological images solely by using weak
image-level labels. In particular, two analysis tasks are taken into account: a
binary classification and a prediction of the tumor proliferation score. Our
method is based on a CNN structure consisting of a compressing path and a
learning path. In the compressing path, the gigapixel image is packed into a
grid-based feature map by using a residual network devoted to the feature
extraction of each patch into which the image has been divided. In the learning
path, attention modules are applied to the grid-based feature map, taking into
account spatial correlations of neighboring patch features to find regions of
interest, which are then used for the final whole slide analysis. Our method
integrates both global and local information, is flexible with regard to the
size of the input images and only requires weak image-level labels. Comparisons
with different methods of the state-of-the-art on two well known datasets,
Camelyon16 and TUPAC16, have been made to confirm the validity of the proposed
model.
</p>
<a href="http://arxiv.org/abs/2101.09992" target="_blank">arXiv:2101.09992</a> [<a href="http://arxiv.org/pdf/2101.09992" target="_blank">pdf</a>]

<h2>Universal Approximation Properties for ODENet and ResNet. (arXiv:2101.10229v2 [cs.LG] UPDATED)</h2>
<h3>Yuto Aizawa, Masato Kimura</h3>
<p>We prove a universal approximation property (UAP) for a class of ODENet and a
class of ResNet, which are used in many deep learning algorithms. The UAP can
be stated as follows. Let $n$ and $m$ be the dimension of input and output
data, and assume $m\leq n$. Then we show that ODENet width $n+m$ with any
non-polynomial continuous activation function can approximate any continuous
function on a compact subset on $\mathbb{R}^n$. We also show that ResNet has
the same property as the depth tends to infinity. Furthermore, we derive
explicitly the gradient of a loss function with respect to a certain tuning
variable. We use this to construct a learning algorithm for ODENet. To
demonstrate the usefulness of this algorithm, we apply it to a regression
problem, a binary classification, and a multinomial classification in MNIST.
</p>
<a href="http://arxiv.org/abs/2101.10229" target="_blank">arXiv:2101.10229</a> [<a href="http://arxiv.org/pdf/2101.10229" target="_blank">pdf</a>]

<h2>Reinforcement Learning Based Temporal Logic Control with Soft Constraints Using Limit-deterministic Generalized Buchi Automata. (arXiv:2101.10284v2 [cs.RO] UPDATED)</h2>
<h3>Mingyu Cai, Shaoping Xiao, Zhen Kan</h3>
<p>This paper studies the control synthesis of motion planning subject to
uncertainties. The uncertainties are considered in robot motion and environment
properties, giving rise to the probabilistic labeled Markov decision process
(MDP). A model-free reinforcement learning (RL) is developed to generate a
finite-memory control policy to satisfy high-level tasks expressed in linear
temporal logic (LTL) formulas. One of the novelties is to translate LTL into a
limit deterministic generalized B\"uchi automaton (LDGBA) and develop a
corresponding embedded LDGBA (E-LDGBA) by incorporating a tracking-frontier
function to overcome the issue of sparse accepting rewards, resulting in
improved learning performance without increasing computational complexity. Due
to potentially conflicting tasks, a relaxed product MDP is developed to allow
the agent to revise its motion plan without strictly following the desired LTL
constraints if the desired tasks can only be partially fulfilled. An expected
return composed of violation rewards and accepting rewards is developed. The
designed violation function quantifies the differences between the revised and
the desired motion planning, while the accepting rewards are designed to
enforce the satisfaction of the acceptance condition of the relaxed product
MDP. Rigorous analysis shows that any RL algorithm that optimizes the expected
return is guaranteed to find policies that, in decreasing order, can 1) satisfy
acceptance condition of relaxed product MDP and 2) reduce the violation cost
over long-term behaviors. Also, we validate the control synthesis approach via
simulation and experimental results.
</p>
<a href="http://arxiv.org/abs/2101.10284" target="_blank">arXiv:2101.10284</a> [<a href="http://arxiv.org/pdf/2101.10284" target="_blank">pdf</a>]

<h2>Toward Personalized Affect-Aware Socially Assistive Robot Tutors in Long-Term Interventions for Children with Autism. (arXiv:2101.10580v2 [cs.RO] UPDATED)</h2>
<h3>Zhonghao Shi, Thomas R Groechel, Shomik Jain, Kourtney Chima, Ognjen Rudovic, Maja J Matari&#x107;</h3>
<p>Affect-aware socially assistive robotics (SAR) has shown great potential for
augmenting interventions for children with autism spectrum disorders (ASD).
However, current SAR cannot yet perceive the unique and diverse set of atypical
cognitive-affective behaviors from children with ASD in an automatic and
personalized fashion in long-term (multi-session) real-world interactions. To
bridge this gap, this work designed and validated personalized models of
arousal and valence for children with ASD using a multi-session in-home dataset
of SAR interventions. By training machine learning (ML) algorithms with
supervised domain adaptation (s-DA), the personalized models were able to trade
off between the limited individual data and the more abundant less personal
data pooled from other study participants. We evaluated the effects of
personalization on a long-term multimodal dataset consisting of 4 children with
ASD with a total of 19 sessions, and derived inter-rater reliability (IR)
scores for binary arousal (IR = 83%) and valence (IR = 81%) labels between
human annotators. Our results show that personalized Gradient Boosted Decision
Trees (XGBoost) models with s-DA outperformed two non-personalized
individualized and generic model baselines not only on the weighted average of
all sessions, but also statistically (p &lt; .05) across individual sessions. This
work paves the way for the development of personalized autonomous SAR systems
tailored toward individuals with atypical cognitive-affective and
socio-emotional needs.
</p>
<a href="http://arxiv.org/abs/2101.10580" target="_blank">arXiv:2101.10580</a> [<a href="http://arxiv.org/pdf/2101.10580" target="_blank">pdf</a>]

<h2>CDSM -- Casual Inference using Deep Bayesian Dynamic Survival Models. (arXiv:2101.10643v2 [stat.ML] UPDATED)</h2>
<h3>Jie Zhu, Blanca Gallego</h3>
<p>A smart healthcare system that supports clinicians for risk-calibrated
treatment assessment typically requires the accurate modeling of time-to-event
outcomes. To tackle this sequential treatment effect estimation problem, we
developed causal dynamic survival model (CDSM) for causal inference with
survival outcomes using longitudinal electronic health record (EHR). CDSM has
impressive explanatory performance while maintaining the prediction capability
of conventional binary neural network predictors. It borrows the strength from
explanatory framework including the survival analysis and counterfactual
framework and integrates them with the prediction power from a deep Bayesian
recurrent neural network to extract implicit knowledge from EHR data. In two
large clinical cohort studies, our model identified the conditional average
treatment effect in accordance with previous literature yet detected individual
effect heterogeneity over time and patient subgroups. The model provides
individualized and clinically interpretable treatment effect estimations to
improve patient outcomes.
</p>
<a href="http://arxiv.org/abs/2101.10643" target="_blank">arXiv:2101.10643</a> [<a href="http://arxiv.org/pdf/2101.10643" target="_blank">pdf</a>]

<h2>Towards Universal Physical Attacks On Cascaded Camera-Lidar 3D Object Detection Models. (arXiv:2101.10747v2 [cs.CV] UPDATED)</h2>
<h3>Mazen Abdelfattah, Kaiwen Yuan, Z. Jane Wang, Rabab Ward</h3>
<p>We propose a universal and physically realizable adversarial attack on a
cascaded multi-modal deep learning network (DNN), in the context of
self-driving cars. DNNs have achieved high performance in 3D object detection,
but they are known to be vulnerable to adversarial attacks. These attacks have
been heavily investigated in the RGB image domain and more recently in the
point cloud domain, but rarely in both domains simultaneously - a gap to be
filled in this paper. We use a single 3D mesh and differentiable rendering to
explore how perturbing the mesh's geometry and texture can reduce the
robustness of DNNs to adversarial attacks. We attack a prominent cascaded
multi-modal DNN, the Frustum-Pointnet model. Using the popular KITTI benchmark,
we showed that the proposed universal multi-modal attack was successful in
reducing the model's ability to detect a car by nearly 73%. This work can aid
in the understanding of what the cascaded RGB-point cloud DNN learns and its
vulnerability to adversarial attacks.
</p>
<a href="http://arxiv.org/abs/2101.10747" target="_blank">arXiv:2101.10747</a> [<a href="http://arxiv.org/pdf/2101.10747" target="_blank">pdf</a>]

<h2>Adversarial Attacks on Uncertainty Enable Active Learning for Neural Network Potentials. (arXiv:2101.11588v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Schwalbe-Koda, Aik Rui Tan, Rafael G&#xf3;mez-Bombarelli</h3>
<p>Neural network (NN)-based interatomic potentials provide fast prediction of
potential energy surfaces with the accuracy of electronic structure methods.
However, NN predictions are only reliable within well-learned training domains,
with unknown behavior when extrapolating. Uncertainty quantification through NN
committees identify domains with low prediction confidence, but thoroughly
exploring the configuration space for training NN potentials often requires
slow atomistic simulations. Here, we employ adversarial attacks with a
differentiable uncertainty metric to sample new molecular geometries and
bootstrap NN potentials. In combination with an active learning loop, the
extrapolation power of NN potentials is improved beyond the original training
data with few additional samples. The framework is demonstrated on multiple
examples, leading to better sampling of kinetic barriers and collective
variables without extensive prior data on the relevant geometries. Adversarial
attacks are new ways to simultaneously sample the phase space and bootstrap NN
potentials, increasing their robustness and enabling a faster, accurate
prediction of potential energy landscapes.
</p>
<a href="http://arxiv.org/abs/2101.11588" target="_blank">arXiv:2101.11588</a> [<a href="http://arxiv.org/pdf/2101.11588" target="_blank">pdf</a>]

<h2>Exploring Cross-Image Pixel Contrast for Semantic Segmentation. (arXiv:2101.11939v2 [cs.CV] UPDATED)</h2>
<h3>Wenguan Wang, Tianfei Zhou, Fisher Yu, Jifeng Dai, Ender Konukoglu, Luc Van Gool</h3>
<p>Current semantic segmentation methods focus only on mining "local" context,
i.e., dependencies between pixels within individual images, by
context-aggregation modules (e.g., dilated convolution, neural attention) or
structure-aware optimization criteria (e.g., IoU-like loss). However, they
ignore "global" context of the training data, i.e., rich semantic relations
between pixels across different images. Inspired by the recent advance in
unsupervised contrastive representation learning, we propose a pixel-wise
contrastive framework for semantic segmentation in the fully supervised
setting. The core idea is to enforce pixel embeddings belonging to a same
semantic class to be more similar than embeddings from different classes. It
raises a pixel-wise metric learning paradigm for semantic segmentation, by
explicitly exploring the structures of labeled pixels, which are long ignored
in the field. Our method can be effortlessly incorporated into existing
segmentation frameworks without extra overhead during testing. We
experimentally show that, with famous segmentation models (i.e., DeepLabV3,
HRNet, OCR) and backbones (i.e., ResNet, HR-Net), our method brings consistent
performance improvements across diverse datasets (i.e., Cityscapes,
PASCAL-Context, COCO-Stuff). We expect this work will encourage our community
to rethink the current de facto training paradigm in fully supervised semantic
segmentation.
</p>
<a href="http://arxiv.org/abs/2101.11939" target="_blank">arXiv:2101.11939</a> [<a href="http://arxiv.org/pdf/2101.11939" target="_blank">pdf</a>]

<h2>VX2TEXT: End-to-End Learning of Video-Based Text Generation From Multimodal Inputs. (arXiv:2101.12059v2 [cs.CV] UPDATED)</h2>
<h3>Xudong Lin, Gedas Bertasius, Jue Wang, Shih-Fu Chang, Devi Parikh, Lorenzo Torresani</h3>
<p>We present \textsc{Vx2Text}, a framework for text generation from multimodal
inputs consisting of video plus text, speech, or audio. In order to leverage
transformer networks, which have been shown to be effective at modeling
language, each modality is first converted into a set of language embeddings by
a learnable tokenizer. This allows our approach to perform multimodal fusion in
the language space, thus eliminating the need for ad-hoc cross-modal fusion
modules. To address the non-differentiability of tokenization on continuous
inputs (e.g., video or audio), we utilize a relaxation scheme that enables
end-to-end training. Furthermore, unlike prior encoder-only models, our network
includes an autoregressive decoder to generate open-ended text from the
multimodal embeddings fused by the language encoder. This renders our approach
fully generative and makes it directly applicable to different "video+$x$ to
text" problems without the need to design specialized network heads for each
task. The proposed framework is not only conceptually simple but also
remarkably effective: experiments demonstrate that our approach based on a
single architecture outperforms the state-of-the-art on three video-based
text-generation tasks -- captioning, question answering and audio-visual
scene-aware dialog.
</p>
<a href="http://arxiv.org/abs/2101.12059" target="_blank">arXiv:2101.12059</a> [<a href="http://arxiv.org/pdf/2101.12059" target="_blank">pdf</a>]

<h2>Adjusting for Autocorrelated Errors in Neural Networks for Time Series Regression and Forecasting. (arXiv:2101.12578v2 [cs.LG] UPDATED)</h2>
<h3>Fan-Keng Sun, Christopher I. Lang, Duane S. Boning</h3>
<p>In many cases, it is difficult to generate highly accurate models for time
series data using a known parametric model structure. In response, an
increasing body of research focuses on using neural networks to model time
series approximately. A common assumption in training neural networks on time
series is that the errors at different time steps are uncorrelated. However,
due to the temporality of the data, errors are actually autocorrelated in many
cases, which makes such maximum likelihood estimation inaccurate. In this
paper, we propose to learn the autocorrelation coefficient jointly with the
model parameters in order to adjust for autocorrelated errors. For time series
regression, large-scale experiments indicate that our method outperforms the
Prais-Winsten method, especially when the autocorrelation is strong.
Furthermore, we broaden our method to time series forecasting and apply it with
various state-of-the-art models. Results across a wide range of real-world
datasets show that our method enhances performance in almost all cases.
</p>
<a href="http://arxiv.org/abs/2101.12578" target="_blank">arXiv:2101.12578</a> [<a href="http://arxiv.org/pdf/2101.12578" target="_blank">pdf</a>]

<h2>No-Regret Caching via Online Mirror Descent. (arXiv:2101.12588v2 [cs.LG] UPDATED)</h2>
<h3>Tareq Si Salem, Giovanni Neglia, Stratis Ioannidis</h3>
<p>We study an online caching problem in which requests can be served by a local
cache to avoid retrieval costs from a remote server. The cache can update its
state after a batch of requests and store an arbitrarily small fraction of each
content. We study no-regret algorithms based on Online Mirror Descent (OMD)
strategies. We show that the optimal OMD strategy depends on the request
diversity present in a batch. We also prove that, when the cache must store the
entire content, rather than a fraction, OMD strategies can be coupled with a
randomized rounding scheme that preserves regret guarantees.
</p>
<a href="http://arxiv.org/abs/2101.12588" target="_blank">arXiv:2101.12588</a> [<a href="http://arxiv.org/pdf/2101.12588" target="_blank">pdf</a>]

<h2>Federated Variance-Reduced Stochastic Gradient Descent with Robustness to Byzantine Attacks. (arXiv:1912.12716v1 [cs.LG] CROSS LISTED)</h2>
<h3>Zhaoxian Wu, Qing Ling, Tianyi Chen, Georgios B. Giannakis</h3>
<p>This paper deals with distributed finite-sum optimization for learning over
networks in the presence of malicious Byzantine attacks. To cope with such
attacks, most resilient approaches so far combine stochastic gradient descent
(SGD) with different robust aggregation rules. However, the sizeable
SGD-induced stochastic gradient noise makes it challenging to distinguish
malicious messages sent by the Byzantine attackers from noisy stochastic
gradients sent by the 'honest' workers. This motivates us to reduce the
variance of stochastic gradients as a means of robustifying SGD in the presence
of Byzantine attacks. To this end, the present work puts forth a Byzantine
attack resilient distributed (Byrd-) SAGA approach for learning tasks involving
finite-sum optimization over networks. Rather than the mean employed by
distributed SAGA, the novel Byrd- SAGA relies on the geometric median to
aggregate the corrected stochastic gradients sent by the workers. When less
than half of the workers are Byzantine attackers, the robustness of geometric
median to outliers enables Byrd-SAGA to attain provably linear convergence to a
neighborhood of the optimal solution, with the asymptotic learning error
determined by the number of Byzantine workers. Numerical tests corroborate the
robustness to various Byzantine attacks, as well as the merits of Byrd- SAGA
over Byzantine attack resilient distributed SGD.
</p>
<a href="http://arxiv.org/abs/1912.12716" target="_blank">arXiv:1912.12716</a> [<a href="http://arxiv.org/pdf/1912.12716" target="_blank">pdf</a>]

<h2>Generalized non-stationary bandits. (arXiv:2102.00725v1 [stat.ML])</h2>
<h3>Anne Gael Manegueu, Alexandra Carpentier, Yi Yu</h3>
<p>In this paper, we study a non-stationary stochastic bandit problem, which
generalizes the switching bandit problem. On top of the switching bandit
problem (\textbf{Case a}), we are interested in three concrete examples:
(\textbf{b}) the means of the arms are local polynomials, (\textbf{c}) the
means of the arms are locally smooth, and (\textbf{d}) the gaps of the arms
have a bounded number of inflexion points and where the highest arm mean cannot
vary too much in a short range. These three settings are very different, but
have in common the following: (i) the number of similarly-sized level sets of
the logarithm of the gaps can be controlled, and (ii) the highest mean has a
limited number of abrupt changes, and otherwise has limited variations. We
propose a single algorithm in this general setting, that in particular solves
in an efficient and unified way the four problems (a)-(d) mentioned.
</p>
<a href="http://arxiv.org/abs/2102.00725" target="_blank">arXiv:2102.00725</a> [<a href="http://arxiv.org/pdf/2102.00725" target="_blank">pdf</a>]

<h2>Stochastic Online Convex Optimization; Application to probabilistic time series forecasting. (arXiv:2102.00729v1 [cs.LG])</h2>
<h3>Olivier Wintenberger (LPSM UMR 8001)</h3>
<p>Stochastic regret bounds for online algorithms are usually derived from an
"online to batch" conversion. Inverting the reasoning, we start our analyze by
a "batch to online" conversion that applies in any Stochastic Online Convex
Optimization problem under stochastic exp-concavity condition. We obtain fast
rate stochastic regret bounds with high probability for non-convex loss
functions. Based on this approach, we provide prediction and probabilistic
forecasting methods for non-stationary unbounded time series.
</p>
<a href="http://arxiv.org/abs/2102.00729" target="_blank">arXiv:2102.00729</a> [<a href="http://arxiv.org/pdf/2102.00729" target="_blank">pdf</a>]

<h2>Super fast rates in structured prediction. (arXiv:2102.00760v1 [stat.ML])</h2>
<h3>Vivien Cabannes, Alessandro Rudi, Francis Bach</h3>
<p>Discrete supervised learning problems such as classification are often
tackled by introducing a continuous surrogate problem akin to regression.
Bounding the original error, between estimate and solution, by the surrogate
error endows discrete problems with convergence rates already shown for
continuous instances. Yet, current approaches do not leverage the fact that
discrete problems are essentially predicting a discrete output when continuous
problems are predicting a continuous value. In this paper, we tackle this issue
for general structured prediction problems, opening the way to "super fast"
rates, that is, convergence rates for the excess risk faster than $n^{-1}$,
where $n$ is the number of observations, with even exponential rates with the
strongest assumptions. We first illustrate it for predictors based on nearest
neighbors, generalizing rates known for binary classification to any discrete
problem within the framework of structured prediction. We then consider kernel
ridge regression where we improve known rates in $n^{-1/4}$ to arbitrarily fast
rates, depending on a parameter characterizing the hardness of the problem,
thus allowing, under smoothness assumptions, to bypass the curse of
dimensionality.
</p>
<a href="http://arxiv.org/abs/2102.00760" target="_blank">arXiv:2102.00760</a> [<a href="http://arxiv.org/pdf/2102.00760" target="_blank">pdf</a>]

<h2>Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms. (arXiv:2102.00815v1 [cs.LG])</h2>
<h3>Chi Jin, Qinghua Liu, Sobhan Miryoosefi</h3>
<p>Finding the minimal structural assumptions that empower sample-efficient
learning is one of the most important research directions in Reinforcement
Learning (RL). This paper advances our understanding of this fundamental
question by introducing a new complexity measure -- Bellman Eluder (BE)
dimension. We show that the family of RL problems of low BE dimension is
remarkably rich, which subsumes a vast majority of existing tractable RL
problems including but not limited to tabular MDPs, linear MDPs, reactive
POMDPs, low Bellman rank problems as well as low Eluder dimension problems.
This paper further designs a new optimization-based algorithm -- GOLF, and
reanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang
et al. (2017)). We prove that both algorithms learn the near-optimal policies
of low BE dimension problems in a number of samples that is polynomial in all
relevant parameters, but independent of the size of state-action space. Our
regret and sample complexity results match or improve the best existing results
for several well-known subclasses of low BE dimension problems.
</p>
<a href="http://arxiv.org/abs/2102.00815" target="_blank">arXiv:2102.00815</a> [<a href="http://arxiv.org/pdf/2102.00815" target="_blank">pdf</a>]

<h2>A Probabilistic Taylor Expansion with Applications in Filtering and Differential Equations. (arXiv:2102.00877v1 [cs.LG])</h2>
<h3>Toni Karvonen, Jon Cockayne, Filip Tronarp, Simo S&#xe4;rkk&#xe4;</h3>
<p>We study a class of Gaussian processes for which the posterior mean, for a
particular choice of data, replicates a truncated Taylor expansion of any
order. The data consists of derivative evaluations at the expansion point and
the prior covariance kernel belongs to the class of Taylor kernels, which can
be written in a certain power series form. This permits statistical modelling
of the uncertainty in a variety of algorithms that exploit first and second
order Taylor expansions. To demonstrate the utility of this Gaussian process
model we introduce new probabilistic versions of the classical extended Kalman
filter for non-linear state estimation and the Euler method for solving
ordinary differential equations.
</p>
<a href="http://arxiv.org/abs/2102.00877" target="_blank">arXiv:2102.00877</a> [<a href="http://arxiv.org/pdf/2102.00877" target="_blank">pdf</a>]

<h2>Semi-Supervised Disentanglement of Class-Related and Class-Independent Factors in VAE. (arXiv:2102.00892v1 [cs.LG])</h2>
<h3>Sina Hajimiri, Aryo Lotfi, Mahdieh Soleymani Baghshah</h3>
<p>In recent years, extending variational autoencoder's framework to learn
disentangled representations has received much attention. We address this
problem by proposing a framework capable of disentangling class-related and
class-independent factors of variation in data. Our framework employs an
attention mechanism in its latent space in order to improve the process of
extracting class-related factors from data. We also deal with the multimodality
of data distribution by utilizing mixture models as learnable prior
distributions, as well as incorporating the Bhattacharyya coefficient in the
objective function to prevent highly overlapping mixtures. Our model's encoder
is further trained in a semi-supervised manner, with a small fraction of
labeled data, to improve representations' interpretability. Experiments show
that our framework disentangles class-related and class-independent factors of
variation and learns interpretable features. Moreover, we demonstrate our
model's performance with quantitative and qualitative results on various
datasets.
</p>
<a href="http://arxiv.org/abs/2102.00892" target="_blank">arXiv:2102.00892</a> [<a href="http://arxiv.org/pdf/2102.00892" target="_blank">pdf</a>]

<h2>Information-Theoretic Generalization Bounds for Stochastic Gradient Descent. (arXiv:2102.00931v1 [cs.LG])</h2>
<h3>Gergely Neu</h3>
<p>We study the generalization properties of the popular stochastic gradient
descent method for optimizing general non-convex loss functions. Our main
contribution is providing upper bounds on the generalization error that depend
on local statistics of the stochastic gradients evaluated along the path of
iterates calculated by SGD. The key factors our bounds depend on are the
variance of the gradients (with respect to the data distribution) and the local
smoothness of the objective function along the SGD path, and the sensitivity of
the loss function to perturbations to the final output. Our key technical tool
is combining the information-theoretic generalization bounds previously used
for analyzing randomized variants of SGD with a perturbation analysis of the
iterates.
</p>
<a href="http://arxiv.org/abs/2102.00931" target="_blank">arXiv:2102.00931</a> [<a href="http://arxiv.org/pdf/2102.00931" target="_blank">pdf</a>]

<h2>CRPS Learning. (arXiv:2102.00968v1 [stat.ML])</h2>
<h3>Jonathan Berrisch, Florian Ziel</h3>
<p>Combination and aggregation techniques can improve forecast accuracy
substantially. This also holds for probabilistic forecasting methods where full
predictive distributions are combined. There are several time-varying and
adaptive weighting schemes like Bayesian model averaging (BMA). However, the
performance of different forecasters may vary not only over time but also in
parts of the distribution. So one may be more accurate in the center of the
distributions, and other ones perform better in predicting the distribution's
tails. Consequently, we introduce a new weighting procedure that considers both
varying performance across time and the distribution. We discuss pointwise
online aggregation algorithms that optimize with respect to the continuous
ranked probability score (CRPS). After analyzing the theoretical properties of
a fully adaptive Bernstein online aggregation (BOA) method, we introduce
smoothing procedures for pointwise CRPS learning. The properties are confirmed
and discussed using simulation studies. Additionally, we illustrate the
performance in a forecasting study for carbon markets. In detail, we predict
the distribution of European emission allowance prices.
</p>
<a href="http://arxiv.org/abs/2102.00968" target="_blank">arXiv:2102.00968</a> [<a href="http://arxiv.org/pdf/2102.00968" target="_blank">pdf</a>]

<h2>Estimation and Inference on Nonlinear and Heterogeneous Effects. (arXiv:1703.05849v3 [stat.ML] UPDATED)</h2>
<h3>Marc Ratkovic, Dustin Tingley</h3>
<p>Multiple regression has been the go-to method for data analysis for
generations of scholars due to its transparency, interpretability, and
desirable theoretical properties. However, the method's simplicity precludes
the discovery of complex heterogeneities in the data. We introduce the Method
of Direct Estimation and Inference (MDEI) that embraces these potential
complexities, is interpretable, has desirable theoretical guarantees, and,
unlike some existing methods, returns appropriate uncertainty estimates. The
proposed method uses a machine learning regression methodology to estimate the
observation-level effect of a treatment variable. Importantly, we introduce a
robust approach to uncertainty estimates. We provide simulation evidence and an
application illustrating the performance of the method.
</p>
<a href="http://arxiv.org/abs/1703.05849" target="_blank">arXiv:1703.05849</a> [<a href="http://arxiv.org/pdf/1703.05849" target="_blank">pdf</a>]

