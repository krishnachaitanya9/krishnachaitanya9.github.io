---
title: Latest Deep Learning Papers
date: 2020-09-25 13:36:24 +0800
featured-img: DL
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>A multi-stage deep learning based algorithm for multiscale modelreduction. (arXiv:2009.11341v1 [math.NA])</h2>
<h3>Eric Chung, Wing Tat Leung, Sai-Mang Pun, Zecheng Zhang</h3>
<p>In this work, we propose a multi-stage training strategy for the development
of deep learning algorithms applied to problems with multiscale features. Each
stage of the pro-posed strategy shares an (almost) identical network structure
and predicts the same reduced order model of the multiscale problem. The output
of the previous stage will be combined with an intermediate layer for the
current stage. We numerically show that using different reduced order models as
inputs of each stage can improve the training and we propose several ways of
adding different information into the systems. These methods include
mathematical multiscale model reductions and network approaches; but we found
that the mathematical approach is a systematical way of decoupling information
and gives the best result. We finally verified our training methodology on a
time dependent nonlinear problem and a steady state model
</p>
<a href="http://arxiv.org/abs/2009.11341">arXiv:2009.11341</a> [<a href="http://arxiv.org/pdf/2009.11341">pdf</a>]

<h2>ADMM-DIPTV: combining Total Variation and Deep Image Prior for image restoration. (arXiv:2009.11380v1 [eess.IV])</h2>
<h3>Pasquale Cascarano, Andrea Sebastiani, Maria Colomba Comes</h3>
<p>In the last decades, unsupervised deep learning based methods have caught
researchers attention, since in many applications collecting a great amount of
training examples is not always feasible. Moreover, the construction of a good
training set is time consuming and hard because the selected data have to be
enough representative for the task. In this paper, we mainly focus on the Deep
Image Prior (DIP) framework powered by adding the Total Variation regularizer
which promotes gradient-sparsity of the solution. Differently from other
existing approaches, we solve the arising minimization problem by using the
well known Alternating Direction Method of Multipliers (ADMM) framework,
decoupling the contribution of the DIP $L_{2}$-norm and Total Variation terms.
The promising performances of the proposed approach, in terms of PSNR and SSIM
values, are addressed by means of experiments for different image restoration
tasks on synthetic as well as on real data.
</p>
<a href="http://arxiv.org/abs/2009.11380">arXiv:2009.11380</a> [<a href="http://arxiv.org/pdf/2009.11380">pdf</a>]

<h2>Parameters for the best convergence of an optimization algorithm On-The-Fly. (arXiv:2009.11390v1 [math.OC])</h2>
<h3>Valdimir Pieter</h3>
<p>What really sparked my interest was how certain parameters worked better at
executing and optimization algorithm convergence even though the objective
formula had no significant differences. Thus the research question stated:
'Which parameters provides an upmost optimal convergence solution of an
Objective formula using the on-the-fly method?' This research was done in an
experimental concept in which five different algorithms were tested with
different objective functions to discover which parameter would result well for
the best convergence. To find the correct parameter a method called
'on-the-fly' was applied. I run the experiments with five different
optimization algorithms. One of the test runs showed that each parameter has an
increasing or decreasing convergence accuracy towards the subjective function
depending on which specific optimization algorithm you choose. Each parameter
has an increasing or decreasing convergence accuracy toward the subjective
function. One of the results in which evolutionary algorithm was applied with
only the recombination technique did well at finding the best optimization. As
well that some results have an increasing accuracy visualization by combing
mutation or several parameters in one test performance. In conclusion, each
algorithm has its own set of the parameter that converge differently. Also
depending on the target formula that is used. This confirms that the fly method
a suitable approach at finding the best parameter. This means manipulations and
observe the effects in process to find the right parameter works as long as the
learning cost rate decreases over time.
</p>
<a href="http://arxiv.org/abs/2009.11390">arXiv:2009.11390</a> [<a href="http://arxiv.org/pdf/2009.11390">pdf</a>]

<h2>An elementary approach for minimax estimation of Bernoulli proportion in the restricted parameter space. (arXiv:2009.11413v1 [math.ST])</h2>
<h3>Heejune Sheen, Yajun Mei</h3>
<p>We present an elementary mathematical method to find the minimax estimator of
the Bernoulli proportion $\theta$ under the squared error loss when $\theta$
belongs to the restricted parameter space of the form $\Omega = [0, \eta]$ for
some pre-specified constant $0 \leq \eta \leq 1$. This problem is inspired from
the problem of estimating the rate of positive COVID-19 tests. The presented
results and applications would be useful materials for both instructors and
students when teaching point estimation in statistical or machine learning
courses.
</p>
<a href="http://arxiv.org/abs/2009.11413">arXiv:2009.11413</a> [<a href="http://arxiv.org/pdf/2009.11413">pdf</a>]

<h2>Discovery of Governing Equations with Recursive Deep Neural Networks. (arXiv:2009.11500v1 [math.NA])</h2>
<h3>Jia Zhao, Jarrod Mau</h3>
<p>Model discovery based on existing data has been one of the major focuses of
mathematical modelers for decades. Despite tremendous achievements of model
identification from adequate data, how to unravel the models from limited data
is less resolved. In this paper, we focus on the model discovery problem when
the data is not efficiently sampled in time. This is common due to limited
experimental accessibility and labor/resource constraints. Specifically, we
introduce a recursive deep neural network (RDNN) for data-driven model
discovery. This recursive approach can retrieve the governing equation in a
simple and efficient manner, and it can significantly improve the approximation
accuracy by increasing the recursive stages. In particular, our proposed
approach shows superior power when the existing data are sampled with a large
time lag, from which the traditional approach might not be able to recover the
model well. Several widely used examples of dynamical systems are used to
benchmark this newly proposed recursive approach. Numerical comparisons confirm
the effectiveness of this recursive neural network for model discovery.
</p>
<a href="http://arxiv.org/abs/2009.11500">arXiv:2009.11500</a> [<a href="http://arxiv.org/pdf/2009.11500">pdf</a>]

<h2>Machine learning for UAV-Based networks. (arXiv:2009.11522v1 [eess.SP])</h2>
<h3>Mohamed-Amine Lahmeri, Mustafa A.Kishk, Mohamed-Slim Alouini</h3>
<p>Unmanned aerial vehicles (UAVs) are considered as one of the promising
technologies for the next-generation wireless communication networks. Their
mobility and their ability to establish a line of sight (LOS) links with the
users made them key solutions for many potential applications. In the same
vein, artificial intelligence is growing rapidly nowadays and has been very
successful, particularly due to the massive amount of the available data. As a
result, a significant part of the research community has started to integrate
intelligence at the core of UAVs networks by applying machine learning (ML)
algorithms in solving several problems in relation to drones. In this article,
we provide a comprehensive overview of some potential applications of ML in
UAV-Based networks. We will also highlight the limits of the existing works and
outline some potential future applications of ML for UAVs networks.
</p>
<a href="http://arxiv.org/abs/2009.11522">arXiv:2009.11522</a> [<a href="http://arxiv.org/pdf/2009.11522">pdf</a>]

<h2>Nonlinear biseparating maps. (arXiv:2009.11570v1 [math.FA])</h2>
<h3>Xianzhe Feng, Denny H. Leung</h3>
<p>An additive map $T$ acting between spaces of vector-valued functions is said
to be biseparating if $T$ is a bijection so that $f$ and $g$ are disjoint if
and only if $Tf$ and $Tg$ are disjoint. Note that an additive bijection retains
$\mathbb{Q}$-linearity. For a general nonlinear map $T$, the definition of
biseparating given above turns out to be too weak to determine the structure of
$T$. In this paper, we propose a revised definition of biseparating maps for
general nonlinear operators acting between spaces of vector-valued functions,
which coincides with the previous definition for additive maps. Under some mild
assumptions on the function spaces involved, it turns out that a map is
biseparating if and only if it is locally determined. We then delve deeply into
some specific function spaces -- spaces of continuous functions, uniformly
continuous functions and Lipschitz functions -- and characterize the
biseparating maps acting on them. As a by-product, certain forms of automatic
continuity are obtained. We also prove some finer properties of biseparating
maps in the cases of uniformly continuous and Lipschitz functions.
</p>
<a href="http://arxiv.org/abs/2009.11570">arXiv:2009.11570</a> [<a href="http://arxiv.org/pdf/2009.11570">pdf</a>]

<h2>The Deep Learning Galerkin Method for the General Stokes Equations. (arXiv:2009.11701v1 [math.NA])</h2>
<h3>Jian Li, Jing Yue, Wen Zhang, Wansuo Duan</h3>
<p>The finite element method, finite difference method, finite volume method and
spectral method have achieved great success in solving partial differential
equations. However, the high accuracy of traditional numerical methods is at
the cost of high efficiency. Especially in the face of high-dimensional
problems, the traditional numerical methods are often not feasible in the
subdivision of high-dimensional meshes and the differentiability and
integrability of high-order terms. In deep learning, neural network can deal
with high-dimensional problems by adding the number of layers or expanding the
number of neurons. Compared with traditional numerical methods, it has great
advantages. In this article, we consider the Deep Galerkin Method (DGM) for
solving the general Stokes equations by using deep neural network without
generating mesh grid. The DGM can reduce the computational complexity and
achieve the competitive results. Here, depending on the L2 error we construct
the objective function to control the performance of the approximation
solution. Then, we prove the convergence of the objective function and the
convergence of the neural network to the exact solution. Finally, the
effectiveness of the proposed framework is demonstrated through some numerical
experiments.
</p>
<a href="http://arxiv.org/abs/2009.11701">arXiv:2009.11701</a> [<a href="http://arxiv.org/pdf/2009.11701">pdf</a>]

<h2>Orthogonal Statistical Learning. (arXiv:1901.09036v3 [math.ST] UPDATED)</h2>
<h3>Dylan J. Foster, Vasilis Syrgkanis</h3>
<p>We provide non-asymptotic excess risk guarantees for statistical learning in
a setting where the population risk with respect to which we evaluate the
target parameter depends on an unknown nuisance parameter that must be
estimated from data. We analyze a two-stage sample splitting meta-algorithm
that takes as input two arbitrary estimation algorithms: one for the target
parameter and one for the nuisance parameter. We show that if the population
risk satisfies a condition called Neyman orthogonality, the impact of the
nuisance estimation error on the excess risk bound achieved by the
meta-algorithm is of second order. Our theorem is agnostic to the particular
algorithms used for the target and nuisance and only makes an assumption on
their individual performance. This enables the use of a plethora of existing
results from statistical learning and machine learning to give new guarantees
for learning with a nuisance component. Moreover, by focusing on excess risk
rather than parameter estimation, we can give guarantees under weaker
assumptions than in previous works and accommodate settings in which the target
parameter belongs to a complex nonparametric class. We provide conditions on
the metric entropy of the nuisance and target classes such that oracle
rates---rates of the same order as if we knew the nuisance parameter---are
achieved. We also derive new rates for specific estimation algorithms such as
variance-penalized empirical risk minimization, neural network estimation and
sparse high-dimensional linear model estimation. We highlight the applicability
of our results in four settings of central importance: 1) heterogeneous
treatment effect estimation, 2) offline policy optimization, 3) domain
adaptation, and 4) learning with missing data.
</p>
<a href="http://arxiv.org/abs/1901.09036">arXiv:1901.09036</a> [<a href="http://arxiv.org/pdf/1901.09036">pdf</a>]

<h2>Higgs bundles without geometry. (arXiv:1910.06099v3 [math.AG] UPDATED)</h2>
<h3>Steven Rayan, Laura P. Schaposnik</h3>
<p>Higgs bundles appeared a few decades ago as solutions to certain equations
from physics and have attracted much attention in geometry as well as other
areas of mathematics and physics. Here, we take a very informal stroll through
some aspects of linear algebra that anticipate the deeper structure in the
moduli space of Higgs bundles. (This note was produced for the MFO Snapshots of
Modern Mathematics series, which is "designed to promote the understanding and
appreciation of modern mathematics and mathematical research in the interested
public world-wide.")
</p>
<a href="http://arxiv.org/abs/1910.06099">arXiv:1910.06099</a> [<a href="http://arxiv.org/pdf/1910.06099">pdf</a>]

<h2>High dimensional regression for regenerative time-series: an application to road traffic modeling. (arXiv:1910.11095v4 [math.ST] UPDATED)</h2>
<h3>Mohammed Bouchouia, Fran&#xe7;ois Portier</h3>
<p>This paper investigates statistical models for road traffic modeling. The
proposed methodology considers road traffic as a (i) high-dimensional
time-series for which (ii) regeneration occurs at the end of each day. Since
(ii), prediction is based on a daily modeling of the road traffic using a
vector autoregressive model that combines linearly the past observations of the
day. Considering (i), the learning algorithm follows from an
$\ell_1$-penalization of the regression coefficients. Excess risk bounds are
established under the high-dimensional framework in which the number of road
sections goes to infinity with the number of observed days. Considering
floating car data observed in an urban area, the approach is compared to
state-of-the-art methods including neural networks. In addition of being very
competitive in terms of prediction, it enables to identify the most determinant
sections of the road network.
</p>
<a href="http://arxiv.org/abs/1910.11095">arXiv:1910.11095</a> [<a href="http://arxiv.org/pdf/1910.11095">pdf</a>]

<h2>Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for Non Convex Optimization. (arXiv:1911.07596v2 [math.OC] UPDATED)</h2>
<h3>Anas Barakat, Pascal Bianchi</h3>
<p>Although ADAM is a very popular algorithm for optimizing the weights of
neural networks, it has been recently shown that it can diverge even in simple
convex optimization examples. Several variants of ADAM have been proposed to
circumvent this convergence issue. In this work, we study the ADAM algorithm
for smooth nonconvex optimization under a boundedness assumption on the
adaptive learning rate. The bound on the adaptive step size depends on the
Lipschitz constant of the gradient of the objective function and provides safe
theoretical adaptive step sizes. Under this boundedness assumption, we show a
novel first order convergence rate result in both deterministic and stochastic
contexts. Furthermore, we establish convergence rates of the function value
sequence using the Kurdyka-Lojasiewicz property.
</p>
<a href="http://arxiv.org/abs/1911.07596">arXiv:1911.07596</a> [<a href="http://arxiv.org/pdf/1911.07596">pdf</a>]

<h2>Policies for elementary link generation in quantum networks. (arXiv:2007.03193v2 [quant-ph] UPDATED)</h2>
<h3>Sumeet Khatri</h3>
<p>Protocols in a quantum network involve multiple parties performing actions on
their quantum systems in a carefully orchestrated manner over time in order to
accomplish a given task. This sequence of actions over time is often referred
to as a strategy, or policy. In this work, we consider policy optimization in a
quantum network. Specifically, as a first step towards developing full-fledged
quantum network protocols, we consider policies for generating elementary links
in a quantum network. We start by casting elementary link generation as a
quantum partially observable Markov decision process, as defined in [Phys. Rev.
A 90, 032311 (2014)]. Then, we analyze in detail the commonly used memory
cutoff policy. Under this policy, once an elementary link is established it is
kept in quantum memory for some amount $t^{\star}$ of time, called the cutoff,
before it is discarded and the elementary link generation is reattempted. For
this policy, we determine the average quantum state of the elementary link as a
function of time for an arbitrary number of nodes in the link, as well as the
average fidelity of the link as a function of time for any noise model for the
quantum memories. Finally, we show how optimal policies can be obtained in the
finite-horizon setting using dynamic programming. By casting elementary link
generation as a quantum decision process, this work goes beyond the analytical
results derived here by providing the theoretical framework for performing
reinforcement learning of practical quantum network protocols.
</p>
<a href="http://arxiv.org/abs/2007.03193">arXiv:2007.03193</a> [<a href="http://arxiv.org/pdf/2007.03193">pdf</a>]

<h2>EXP4-DFDC: A Non-Stochastic Multi-Armed Bandit for Cache Replacement. (arXiv:2009.11330v1 [cs.LG])</h2>
<h3>Farzana Beente Yusuf, Camilo Valdes, Vitalii Stebliankin, Guiseppe Vietri, Giri Narasimhan</h3>
<p>In this work we study a variant of the well-known multi-armed bandit (MAB)
problem, which has the properties of a delay in feedback, and a loss that
declines over time. We introduce an algorithm, EXP4-DFDC, to solve this MAB
variant, and demonstrate that the regret vanishes as the time increases. We
also show that LeCaR, a previously published machine learning-based cache
replacement algorithm, is an instance of EXP4-DFDC. Our results can be used to
provide insight on the choice of hyperparameters, and optimize future LeCaR
instances.
</p>
<a href="http://arxiv.org/abs/2009.11330">arXiv:2009.11330</a> [<a href="http://arxiv.org/pdf/2009.11330">pdf</a>]

<h2>The importance of fillers for text representations of speech transcripts. (arXiv:2009.11340v1 [cs.CL])</h2>
<h3>Tanvi Dinkar, Pierre Colombo, Matthieu Labeau, Chlo&#xe9; Clavel</h3>
<p>While being an essential component of spoken language, fillers (e.g."um" or
"uh") often remain overlooked in Spoken Language Understanding (SLU) tasks. We
explore the possibility of representing them with deep contextualised
embeddings, showing improvements on modelling spoken language and two
downstream tasks - predicting a speaker's stance and expressed confidence.
</p>
<a href="http://arxiv.org/abs/2009.11340">arXiv:2009.11340</a> [<a href="http://arxiv.org/pdf/2009.11340">pdf</a>]

<h2>A multi-stage deep learning based algorithm for multiscale modelreduction. (arXiv:2009.11341v1 [math.NA])</h2>
<h3>Eric Chung, Wing Tat Leung, Sai-Mang Pun, Zecheng Zhang</h3>
<p>In this work, we propose a multi-stage training strategy for the development
of deep learning algorithms applied to problems with multiscale features. Each
stage of the pro-posed strategy shares an (almost) identical network structure
and predicts the same reduced order model of the multiscale problem. The output
of the previous stage will be combined with an intermediate layer for the
current stage. We numerically show that using different reduced order models as
inputs of each stage can improve the training and we propose several ways of
adding different information into the systems. These methods include
mathematical multiscale model reductions and network approaches; but we found
that the mathematical approach is a systematical way of decoupling information
and gives the best result. We finally verified our training methodology on a
time dependent nonlinear problem and a steady state model
</p>
<a href="http://arxiv.org/abs/2009.11341">arXiv:2009.11341</a> [<a href="http://arxiv.org/pdf/2009.11341">pdf</a>]

<h2>Dataset Optimization Strategies for MalwareTraffic Detection. (arXiv:2009.11347v1 [cs.LG])</h2>
<h3>Ivan Letteri, Antonio Di Cecco, Giuseppe Della Penna</h3>
<p>Machine learning is rapidly becoming one of the most important technology for
malware traffic detection, since the continuous evolution of malware requires a
constant adaptation and the ability to generalize. However, network traffic
datasets are usually oversized and contain redundant and irrelevant
information, and this may dramatically increase the computational cost and
decrease the accuracy of most classifiers, with the risk to introduce further
noise.

We propose two novel dataset optimization strategies which exploit and
combine several state-of-the-art approaches in order to achieve an effective
optimization of the network traffic datasets used to train malware detectors.
The first approach is a feature selection technique based on mutual information
measures and sensibility enhancement. The second is a dimensional reduction
technique based autoencoders. Both these approaches have been experimentally
applied on the MTA-KDD'19 dataset, and the optimized results evaluated and
compared using a Multi Layer Perceptron as machine learning model for malware
detection.
</p>
<a href="http://arxiv.org/abs/2009.11347">arXiv:2009.11347</a> [<a href="http://arxiv.org/pdf/2009.11347">pdf</a>]

<h2>Adversarial robustness via stochastic regularization of neural activation sensitivity. (arXiv:2009.11349v1 [cs.LG])</h2>
<h3>Gil Fidel, Ron Bitton, Ziv Katzir, Asaf Shabtai</h3>
<p>Recent works have shown that the input domain of any machine learning
classifier is bound to contain adversarial examples. Thus we can no longer hope
to immune classifiers against adversarial examples and instead can only aim to
achieve the following two defense goals: 1) making adversarial examples harder
to find, or 2) weakening their adversarial nature by pushing them further away
from correctly classified data points. Most if not all the previously suggested
defense mechanisms attend to just one of those two goals, and as such, could be
bypassed by adaptive attacks that take the defense mechanism into
consideration. In this work we suggest a novel defense mechanism that
simultaneously addresses both defense goals: We flatten the gradients of the
loss surface, making adversarial examples harder to find, using a novel
stochastic regularization term that explicitly decreases the sensitivity of
individual neurons to small input perturbations. In addition, we push the
decision boundary away from correctly classified inputs by leveraging Jacobian
regularization. We present a solid theoretical basis and an empirical testing
of our suggested approach, demonstrate its superiority over previously
suggested defense mechanisms, and show that it is effective against a wide
range of adaptive attacks.
</p>
<a href="http://arxiv.org/abs/2009.11349">arXiv:2009.11349</a> [<a href="http://arxiv.org/pdf/2009.11349">pdf</a>]

<h2>Structure Aware Negative Sampling in Knowledge Graphs. (arXiv:2009.11355v1 [cs.LG])</h2>
<h3>Kian Ahrabian, Aarash Feizi, Yasmin Salehi, William L. Hamilton, Avishek Joey Bose</h3>
<p>Learning low-dimensional representations for entities and relations in
knowledge graphs using contrastive estimation represents a scalable and
effective method for inferring connectivity patterns. A crucial aspect of
contrastive learning approaches is the choice of corruption distribution that
generates hard negative samples, which force the embedding model to learn
discriminative representations and find critical characteristics of observed
data. While earlier methods either employ too simple corruption distributions,
i.e. uniform, yielding easy uninformative negatives or sophisticated
adversarial distributions with challenging optimization schemes, they do not
explicitly incorporate known graph structure resulting in suboptimal negatives.
In this paper, we propose Structure Aware Negative Sampling (SANS), an
inexpensive negative sampling strategy that utilizes the rich graph structure
by selecting negative samples from a node's k-hop neighborhood. Empirically, we
demonstrate that SANS finds high-quality negatives that are highly competitive
with SOTA methods, and requires no additional parameters nor difficult
adversarial optimization.
</p>
<a href="http://arxiv.org/abs/2009.11355">arXiv:2009.11355</a> [<a href="http://arxiv.org/pdf/2009.11355">pdf</a>]

<h2>Low Complexity Neural Network Structures for Self-Interference Cancellation in Full-Duplex Radio. (arXiv:2009.11361v1 [eess.SP])</h2>
<h3>Mohamed Elsayed, Ahmad A. Aziz El-Banna, Octavia A. Dobre, Wanyi Shiu, Peiwei Wang</h3>
<p>Self-interference (SI) is considered as a main challenge in full-duplex (FD)
systems. Therefore, efficient SI cancelers are required for the influential
deployment of FD systems in beyond fifth-generation wireless networks. Existing
methods for SI cancellation have mostly considered the polynomial
representation of the SI signal at the receiver. These methods are shown to
operate well in practice while requiring high computational complexity.
Alternatively, neural networks (NNs) are envisioned as promising candidates for
modeling the SI signal with reduced computational complexity. Consequently, in
this paper, two novel low complexity NN structures, referred to as the
ladder-wise grid structure (LWGS) and moving-window grid structure (MWGS), are
proposed. The core idea of these two structures is to mimic the non-linearity
and memory effect introduced to the SI signal in order to achieve proper SI
cancellation while exhibiting low computational complexity. The simulation
results reveal that the LWGS and MWGS NN-based cancelers attain the same
cancellation performance of the polynomial-based canceler while providing
49.87% and 34.19% complexity reduction, respectively.
</p>
<a href="http://arxiv.org/abs/2009.11361">arXiv:2009.11361</a> [<a href="http://arxiv.org/pdf/2009.11361">pdf</a>]

<h2>Dense Forecasting of Wildfire Smoke Particulate Matter Using Sparsity Invariant Convolutional Neural Networks. (arXiv:2009.11362v1 [cs.CV])</h2>
<h3>Renhao Wang, Ashutosh Bhudia, Brandon Dos Remedios, Minnie Teng, Raymond Ng</h3>
<p>Accurate forecasts of fine particulate matter (PM 2.5) from wildfire smoke
are crucial to safeguarding cardiopulmonary public health. Existing forecasting
systems are trained on sparse and inaccurate ground truths, and do not take
sufficient advantage of important spatial inductive biases. In this work, we
present a convolutional neural network which preserves sparsity invariance
throughout, and leverages multitask learning to perform dense forecasts of PM
2.5values. We demonstrate that our model outperforms two existing smoke
forecasting systems during the 2018 and 2019 wildfire season in British
Columbia, Canada, predicting PM 2.5 at a grid resolution of 10 km, 24 hours in
advance with high fidelity. Most interestingly, our model also generalizes to
meaningful smoke dispersion patterns despite training with irregularly
distributed ground truth PM 2.5 values available in only 0.5% of grid cells.
</p>
<a href="http://arxiv.org/abs/2009.11362">arXiv:2009.11362</a> [<a href="http://arxiv.org/pdf/2009.11362">pdf</a>]

<h2>Fast Adaptation Nonlinear Observer for SLAM. (arXiv:2009.11374v1 [eess.SY])</h2>
<h3>Trevor P. Drayton, Abdul A. Jaiyeola, Nazmul Hoque, Mikhayla Maurer, Hashim A. Hashim</h3>
<p>The process of simultaneously mapping the environment in three dimensional
(3D) space and localizing a moving vehicle's pose (orientation and position) is
termed Simultaneous Localization and Mapping (SLAM). SLAM is a core task in
robotics applications. In the SLAM problem, each of the vehicle's pose and the
environment are assumed to be completely unknown. This paper takes the
conventional SLAM design as a basis and proposes a novel approach that ensures
fast adaptation of the nonlinear observer for SLAM. Due to the fact that the
true SLAM problem is nonlinear and is modeled on the Lie group of
$\mathbb{SLAM}_{n}\left(3\right)$, the proposed observer for SLAM is nonlinear
and modeled on $\mathbb{SLAM}_{n}\left(3\right)$. The proposed observer
compensates for unknown bias attached to velocity measurements. The results of
the simulation illustrate the robustness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2009.11374">arXiv:2009.11374</a> [<a href="http://arxiv.org/pdf/2009.11374">pdf</a>]

<h2>ADMM-DIPTV: combining Total Variation and Deep Image Prior for image restoration. (arXiv:2009.11380v1 [eess.IV])</h2>
<h3>Pasquale Cascarano, Andrea Sebastiani, Maria Colomba Comes</h3>
<p>In the last decades, unsupervised deep learning based methods have caught
researchers attention, since in many applications collecting a great amount of
training examples is not always feasible. Moreover, the construction of a good
training set is time consuming and hard because the selected data have to be
enough representative for the task. In this paper, we mainly focus on the Deep
Image Prior (DIP) framework powered by adding the Total Variation regularizer
which promotes gradient-sparsity of the solution. Differently from other
existing approaches, we solve the arising minimization problem by using the
well known Alternating Direction Method of Multipliers (ADMM) framework,
decoupling the contribution of the DIP $L_{2}$-norm and Total Variation terms.
The promising performances of the proposed approach, in terms of PSNR and SSIM
values, are addressed by means of experiments for different image restoration
tasks on synthetic as well as on real data.
</p>
<a href="http://arxiv.org/abs/2009.11380">arXiv:2009.11380</a> [<a href="http://arxiv.org/pdf/2009.11380">pdf</a>]

<h2>Multi-Pass Transformer for Machine Translation. (arXiv:2009.11382v1 [cs.CL])</h2>
<h3>Peng Gao, Chiori Hori, Shijie Geng, Takaaki Hori, Jonathan Le Roux</h3>
<p>In contrast with previous approaches where information flows only towards
deeper layers of a stack, we consider a multi-pass transformer (MPT)
architecture in which earlier layers are allowed to process information in
light of the output of later layers. To maintain a directed acyclic graph
structure, the encoder stack of a transformer is repeated along a new
multi-pass dimension, keeping the parameters tied, and information is allowed
to proceed unidirectionally both towards deeper layers within an encoder stack
and towards any layer of subsequent stacks. We consider both soft (i.e.,
continuous) and hard (i.e., discrete) connections between parallel encoder
stacks, relying on a neural architecture search to find the best connection
pattern in the hard case. We perform an extensive ablation study of the
proposed MPT architecture and compare it with other state-of-the-art
transformer architectures. Surprisingly, Base Transformer equipped with MPT can
surpass the performance of Large Transformer on the challenging machine
translation En-De and En-Fr datasets. In the hard connection case, the optimal
connection pattern found for En-De also leads to improved performance for
En-Fr.
</p>
<a href="http://arxiv.org/abs/2009.11382">arXiv:2009.11382</a> [<a href="http://arxiv.org/pdf/2009.11382">pdf</a>]

<h2>Parameters for the best convergence of an optimization algorithm On-The-Fly. (arXiv:2009.11390v1 [math.OC])</h2>
<h3>Valdimir Pieter</h3>
<p>What really sparked my interest was how certain parameters worked better at
executing and optimization algorithm convergence even though the objective
formula had no significant differences. Thus the research question stated:
'Which parameters provides an upmost optimal convergence solution of an
Objective formula using the on-the-fly method?' This research was done in an
experimental concept in which five different algorithms were tested with
different objective functions to discover which parameter would result well for
the best convergence. To find the correct parameter a method called
'on-the-fly' was applied. I run the experiments with five different
optimization algorithms. One of the test runs showed that each parameter has an
increasing or decreasing convergence accuracy towards the subjective function
depending on which specific optimization algorithm you choose. Each parameter
has an increasing or decreasing convergence accuracy toward the subjective
function. One of the results in which evolutionary algorithm was applied with
only the recombination technique did well at finding the best optimization. As
well that some results have an increasing accuracy visualization by combing
mutation or several parameters in one test performance. In conclusion, each
algorithm has its own set of the parameter that converge differently. Also
depending on the target formula that is used. This confirms that the fly method
a suitable approach at finding the best parameter. This means manipulations and
observe the effects in process to find the right parameter works as long as the
learning cost rate decreases over time.
</p>
<a href="http://arxiv.org/abs/2009.11390">arXiv:2009.11390</a> [<a href="http://arxiv.org/pdf/2009.11390">pdf</a>]

<h2>FluentNet: End-to-End Detection of Speech Disfluency with Deep Learning. (arXiv:2009.11394v1 [eess.AS])</h2>
<h3>Tedd Kourkounakis, Amirhossein Hajavi, Ali Etemad</h3>
<p>Strong presentation skills are valuable and sought-after in workplace and
classroom environments alike. Of the possible improvements to vocal
presentations, disfluencies and stutters in particular remain one of the most
common and prominent factors of someone's demonstration. Millions of people are
affected by stuttering and other speech disfluencies, with the majority of the
world having experienced mild stutters while communicating under stressful
conditions. While there has been much research in the field of automatic speech
recognition and language models, there lacks the sufficient body of work when
it comes to disfluency detection and recognition. To this end, we propose an
end-to-end deep neural network, FluentNet, capable of detecting a number of
different disfluency types. FluentNet consists of a Squeeze-and-Excitation
Residual convolutional neural network which facilitate the learning of strong
spectral frame-level representations, followed by a set of bidirectional long
short-term memory layers that aid in learning effective temporal relationships.
Lastly, FluentNet uses an attention mechanism to focus on the important parts
of speech to obtain a better performance. We perform a number of different
experiments, comparisons, and ablation studies to evaluate our model. Our model
achieves state-of-the-art results by outperforming other solutions in the field
on the publicly available UCLASS dataset. Additionally, we present
LibriStutter: a disfluency dataset based on the public LibriSpeech dataset with
synthesized stutters. We also evaluate FluentNet on this dataset, showing the
strong performance of our model versus a number of benchmark techniques.
</p>
<a href="http://arxiv.org/abs/2009.11394">arXiv:2009.11394</a> [<a href="http://arxiv.org/pdf/2009.11394">pdf</a>]

<h2>Detection of Iterative Adversarial Attacks via Counter Attack. (arXiv:2009.11397v1 [cs.LG])</h2>
<h3>Matthias Rottmann, Mathis Peyron, Natasa Krejic, Hanno Gottschalk</h3>
<p>Deep neural networks (DNNs) have proven to be powerful tools for processing
unstructured data. However for high-dimensional data, like images, they are
inherently vulnerable to adversarial attacks. Small almost invisible
perturbations added to the input can be used to fool DNNs. Various attacks,
hardening methods and detection methods have been introduced in recent years.
Notoriously, Carlini-Wagner (CW) type attacks computed by iterative
minimization belong to those that are most difficult to detect. In this work,
we demonstrate that such iterative minimization attacks can by used as
detectors themselves. Thus, in some sense we show that one can fight fire with
fire. This work also outlines a mathematical proof that under certain
assumptions this detector provides asymptotically optimal separation of
original and attacked images. In numerical experiments, we obtain AUROC values
up to 99.73% for our detection method. This distinctly surpasses state of the
art detection rates for CW attacks from the literature. We also give numerical
evidence that our method is robust against the attacker's choice of the method
of attack.
</p>
<a href="http://arxiv.org/abs/2009.11397">arXiv:2009.11397</a> [<a href="http://arxiv.org/pdf/2009.11397">pdf</a>]

<h2>CertRL: Formalizing Convergence Proofs for Value and Policy Iteration in Coq. (arXiv:2009.11403v1 [cs.AI])</h2>
<h3>Koundinya Vajjha, Avraham Shinnar, Vasily Pestun, Barry Trager, Nathan Fulton</h3>
<p>Reinforcement learning algorithms solve sequential decision-making problems
in probabilistic environments by optimizing for long-term reward. The desire to
use reinforcement learning in safety-critical settings inspires a recent line
of work on formally constrained reinforcement learning; however, these methods
place the implementation of the learning algorithm in their Trusted Computing
Base. The crucial correctness property of these implementations is a guarantee
that the learning algorithm converges to an optimal policy. This paper begins
the work of closing this gap by developing a Coq formalization of two canonical
reinforcement learning algorithms: value and policy iteration for finite state
Markov decision processes. The central results are a formalization of Bellman's
optimality principle and its proof, which uses a contraction property of
Bellman optimality operator to establish that a sequence converges in the
infinite horizon limit. The CertRL development exemplifies how the Giry monad
and mechanized metric coinduction streamline optimality proofs for
reinforcement learning algorithms. The CertRL library provides a general
framework for proving properties about Markov decision processes and
reinforcement learning algorithms, paving the way for further work on
formalization of reinforcement learning algorithms.
</p>
<a href="http://arxiv.org/abs/2009.11403">arXiv:2009.11403</a> [<a href="http://arxiv.org/pdf/2009.11403">pdf</a>]

<h2>Rank-Based Multi-task Learning for Fair Regression. (arXiv:2009.11405v1 [cs.LG])</h2>
<h3>Chen Zhao, Feng Chen</h3>
<p>In this work, we develop a novel fairness learning approach for multi-task
regression models based on a biased training dataset, using a popular
rank-based non-parametric independence test, i.e., Mann Whitney U statistic,
for measuring the dependency between target variable and protected variables.
To solve this learning problem efficiently, we first reformulate the problem as
a new non-convex optimization problem, in which a non-convex constraint is
defined based on group-wise ranking functions of individual objects. We then
develop an efficient model-training algorithm based on the framework of
non-convex alternating direction method of multipliers (NC-ADMM), in which one
of the main challenges is to implement an efficient projection oracle to the
preceding non-convex set defined based on ranking functions. Through the
extensive experiments on both synthetic and real-world datasets, we validated
the out-performance of our new approach against several state-of-the-art
competitive methods on several popular metrics relevant to fairness learning.
</p>
<a href="http://arxiv.org/abs/2009.11405">arXiv:2009.11405</a> [<a href="http://arxiv.org/pdf/2009.11405">pdf</a>]

<h2>Unfairness Discovery and Prevention For Few-Shot Regression. (arXiv:2009.11406v1 [cs.LG])</h2>
<h3>Chen Zhao, Feng Chen</h3>
<p>We study fairness in supervised few-shot meta-learning models that are
sensitive to discrimination (or bias) in historical data. A machine learning
model trained based on biased data tends to make unfair predictions for users
from minority groups. Although this problem has been studied before, existing
methods mainly aim to detect and control the dependency effect of the protected
variables (e.g. race, gender) on target prediction based on a large amount of
training data. These approaches carry two major drawbacks that (1) lacking
showing a global cause-effect visualization for all variables; (2) lacking
generalization of both accuracy and fairness to unseen tasks. In this work, we
first discover discrimination from data using a causal Bayesian knowledge graph
which not only demonstrates the dependency of the protected variable on target
but also indicates causal effects between all variables. Next, we develop a
novel algorithm based on risk difference in order to quantify the
discriminatory influence for each protected variable in the graph. Furthermore,
to protect prediction from unfairness, a fast-adapted bias-control approach in
meta-learning is proposed, which efficiently mitigates statistical disparity
for each task and it thus ensures independence of protected attributes on
predictions based on biased and few-shot data samples. Distinct from existing
meta-learning models, group unfairness of tasks are efficiently reduced by
leveraging the mean difference between (un)protected groups for regression
problems. Through extensive experiments on both synthetic and real-world data
sets, we demonstrate that our proposed unfairness discovery and prevention
approaches efficiently detect discrimination and mitigate biases on model
output as well as generalize both accuracy and fairness to unseen tasks with a
limited amount of training samples.
</p>
<a href="http://arxiv.org/abs/2009.11406">arXiv:2009.11406</a> [<a href="http://arxiv.org/pdf/2009.11406">pdf</a>]

<h2>Steering a Historical Disease Forecasting Model Under a Pandemic: Case of Flu and COVID-19. (arXiv:2009.11407v1 [cs.LG])</h2>
<h3>Alexander Rodriguez, Nikhil Muralidhar, Bijaya Adhikari, Anika Tabassum, Naren Ramakrishnan, B. Aditya Prakash</h3>
<p>Forecasting influenza in a timely manner aids health organizations and
policymakers in adequate preparation and decision making. However, effective
influenza forecasting still remains a challenge despite increasing research
interest. It is even more challenging amidst the COVID pandemic, when the
influenza-like illness (ILI) counts is affected by various factors such as
symptomatic similarities with COVID-19 and shift in healthcare seeking patterns
of the general population. We term the ILI values observed when it is
potentially affected as COVID-ILI. Under the current pandemic, historical
influenza models carry valuable expertise about the disease dynamics but face
difficulties adapting. Therefore, we propose CALI-NET, a neural transfer
learning architecture which allows us to 'steer' a historical disease
forecasting model to new scenarios where flu and COVID co-exist. Our framework
enables this adaptation by automatically learning when it is should emphasize
learning from COVID-related signals and when from the historical model. In such
way, we exploit representations learned from historical ILI data as well as the
limited COVID-related signals. Our experiments demonstrate that our approach is
successful in adapting a historical forecasting model to the current pandemic.
In addition, we show that success in our primary goal, adaptation, does not
sacrifice overall performance as compared with state-of-the-art influenza
forecasting approaches.
</p>
<a href="http://arxiv.org/abs/2009.11407">arXiv:2009.11407</a> [<a href="http://arxiv.org/pdf/2009.11407">pdf</a>]

<h2>Enhancing Mixup-based Semi-Supervised Learning with Explicit Lipschitz Regularization. (arXiv:2009.11416v1 [cs.LG])</h2>
<h3>Prashnna Kumar Gyawali, Sandesh Ghimire, Linwei Wang</h3>
<p>The success of deep learning relies on the availability of large-scale
annotated data sets, the acquisition of which can be costly, requiring expert
domain knowledge. Semi-supervised learning (SSL) mitigates this challenge by
exploiting the behavior of the neural function on large unlabeled data. The
smoothness of the neural function is a commonly used assumption exploited in
SSL. A successful example is the adoption of mixup strategy in SSL that
enforces the global smoothness of the neural function by encouraging it to
behave linearly when interpolating between training examples. Despite its
empirical success, however, the theoretical underpinning of how mixup
regularizes the neural function has not been fully understood. In this paper,
we offer a theoretically substantiated proposition that mixup improves the
smoothness of the neural function by bounding the Lipschitz constant of the
gradient function of the neural networks. We then propose that this can be
strengthened by simultaneously constraining the Lipschitz constant of the
neural function itself through adversarial Lipschitz regularization,
encouraging the neural function to behave linearly while also constraining the
slope of this linear function. On three benchmark data sets and one real-world
biomedical data set, we demonstrate that this combined regularization results
in improved generalization performance of SSL when learning from a small amount
of labeled data. We further demonstrate the robustness of the presented method
against single-step adversarial attacks. Our code is available at
https://github.com/Prasanna1991/Mixup-LR.
</p>
<a href="http://arxiv.org/abs/2009.11416">arXiv:2009.11416</a> [<a href="http://arxiv.org/pdf/2009.11416">pdf</a>]

<h2>Task-Oriented Dialogue as Dataflow Synthesis. (arXiv:2009.11423v1 [cs.CL])</h2>
<h3>Jacob Andreas, John Bufe, David Burkett, Charles Chen, Josh Clausman, Jean Crawford, Kate Crim, Jordan DeLoach, Leah Dorner, Jason Eisner, Hao Fang, Alan Guo, David Hall, Kristin Hayes, Kellie Hill, Diana Ho, Wendy Iwaszuk, Smriti Jha, Dan Klein, Jayant Krishnamurthy, Theo Lanman, Percy Liang, Christopher H Lin, Ilya Lintsbakh, Andy McGovern, Aleksandr Nisnevich, Adam Pauls, Dmitrij Petters, Brent Read, Dan Roth, Subhro Roy, Jesse Rusak, Beth Short, Div Slomin, Ben Snyder, Stephon Striplin, Yu Su, Zachary Tellman, Sam Thomson, Andrei Vorobev, Izabela Witoszko, Jason Wolfe, Abby Wray, Yuchen Zhang, Alexander Zotov</h3>
<p>We describe an approach to task-oriented dialogue in which dialogue state is
represented as a dataflow graph. A dialogue agent maps each user utterance to a
program that extends this graph. Programs include metacomputation operators for
reference and revision that reuse dataflow fragments from previous turns. Our
graph-based state enables the expression and manipulation of complex user
intents, and explicit metacomputation makes these intents easier for learned
models to predict. We introduce a new dataset, SMCalFlow, featuring complex
dialogues about events, weather, places, and people. Experiments show that
dataflow graphs and metacomputation substantially improve representability and
predictability in these natural dialogues. Additional experiments on the
MultiWOZ dataset show that our dataflow representation enables an otherwise
off-the-shelf sequence-to-sequence model to match the best existing
task-specific state tracking model. The SMCalFlow dataset and code for
replicating experiments are available at
https://www.microsoft.com/en-us/research/project/dataflow-based-dialogue-semantic-machines.
</p>
<a href="http://arxiv.org/abs/2009.11423">arXiv:2009.11423</a> [<a href="http://arxiv.org/pdf/2009.11423">pdf</a>]

<h2>FTN: Foreground-Guided Texture-Focused Person Re-Identification. (arXiv:2009.11425v1 [cs.CV])</h2>
<h3>Donghaisheng Liu, Shoudong Han, Yang Chen, Chenfei Xia, Jun Zhao</h3>
<p>Person re-identification (Re-ID) is a challenging task as persons are often
in different backgrounds. Most recent Re-ID methods treat the foreground and
background information equally for person discriminative learning, but can
easily lead to potential false alarm problems when different persons are in
similar backgrounds or the same person is in different backgrounds. In this
paper, we propose a Foreground-Guided Texture-Focused Network (FTN) for Re-ID,
which can weaken the representation of unrelated background and highlight the
attributes person-related in an end-to-end manner. FTN consists of a semantic
encoder (S-Enc) and a compact foreground attention module (CFA) for Re-ID task,
and a texture-focused decoder (TF-Dec) for reconstruction task. Particularly,
we build a foreground-guided semi-supervised learning strategy for TF-Dec
because the reconstructed ground-truths are only the inputs of FTN weighted by
the Gaussian mask and the attention mask generated by CFA. Moreover, a new
gradient loss is introduced to encourage the network to mine the texture
consistency between the inputs and the reconstructed outputs. Our FTN is
computationally efficient and extensive experiments on three commonly used
datasets Market1501, CUHK03 and MSMT17 demonstrate that the proposed method
performs favorably against the state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2009.11425">arXiv:2009.11425</a> [<a href="http://arxiv.org/pdf/2009.11425">pdf</a>]

<h2>Automatic identification of fossils and abiotic grains during carbonate microfacies analysis using deep convolutional neural networks. (arXiv:2009.11429v1 [cs.CV])</h2>
<h3>Xiaokang Liu, Haijun Song</h3>
<p>Petrographic analysis based on microfacies identification in thin sections is
widely used in sedimentary environment interpretation and paleoecological
reconstruction. Fossil recognition from microfacies is an essential procedure
for petrographers to complete this task. Distinguishing the morphological and
microstructural diversity of skeletal fragments requires extensive prior
knowledge of fossil morphotypes in microfacies and long training sessions under
the microscope. This requirement engenders certain challenges for
sedimentologists and paleontologists, especially novices. However, a machine
classifier can help address this challenge. We collected a microfacies image
dataset comprising both public data from 1,149 references and our own materials
(including a total of 30,815 images of 22 fossil and abiotic grain groups). We
employed a high-performance workstation to implement four classic deep
convolutional neural networks (DCNNs), which have proven to be highly efficient
in computer vision over the last several years. Our framework uses a transfer
learning technique, which reuses the pre-trained parameters that are trained on
a larger ImageNet dataset as initialization for the network to achieve high
accuracy with low computing costs. We obtained up to 95% of the top one and 99%
of the top three test accuracies in the Inception ResNet v2 architecture. The
machine classifier exhibited 0.99 precision on minerals, such as dolomite and
pyrite. Although it had some difficulty on samples having similar morphologies,
such as the bivalve, brachiopod, and ostracod, it nevertheless obtained 0.88
precision. Our machine learning framework demonstrated high accuracy with
reproducibility and bias avoidance that was comparable to those of human
classifiers. Its application can thus eliminate much of the tedious, manually
intensive efforts by human experts conducting routine identification.
</p>
<a href="http://arxiv.org/abs/2009.11429">arXiv:2009.11429</a> [<a href="http://arxiv.org/pdf/2009.11429">pdf</a>]

<h2>Unifying data for fine-grained visual species classification. (arXiv:2009.11433v1 [cs.CV])</h2>
<h3>Sayali Kulkarni, Tomer Gadot, Chen Luo, Tanya Birch, Eric Fegraus</h3>
<p>Wildlife monitoring is crucial to nature conservation and has been done by
manual observations from motion-triggered camera traps deployed in the field.
Widespread adoption of such in-situ sensors has resulted in unprecedented data
volumes being collected over the last decade. A significant challenge exists to
process and reliably identify what is in these images efficiently. Advances in
computer vision are poised to provide effective solutions with custom AI models
built to automatically identify images of interest and label the species in
them. Here we outline the data unification effort for the Wildlife Insights
platform from various conservation partners, and the challenges involved. Then
we present an initial deep convolutional neural network model, trained on 2.9M
images across 465 fine-grained species, with a goal to reduce the load on human
experts to classify species in images manually. The long-term goal is to enable
scientists to make conservation recommendations from near real-time analysis of
species abundance and population health.
</p>
<a href="http://arxiv.org/abs/2009.11433">arXiv:2009.11433</a> [<a href="http://arxiv.org/pdf/2009.11433">pdf</a>]

<h2>Effects of Word-frequency based Pre- and Post- Processings for Audio Captioning. (arXiv:2009.11436v1 [eess.AS])</h2>
<h3>Daiki Takeuchi, Yuma Koizumi, Yasunori Ohishi, Noboru Harada, Kunio Kashino</h3>
<p>The system we used for Task 6 (Automated Audio Captioning)of the Detection
and Classification of Acoustic Scenes and Events(DCASE) 2020 Challenge combines
three elements, namely, dataaugmentation, multi-task learning, and
post-processing, for audiocaptioning. The system received the highest
evaluation scores, butwhich of the individual elements most fully contributed
to its perfor-mance has not yet been clarified. Here, to asses their
contributions,we first conducted an element-wise ablation study on our systemto
estimate to what extent each element is effective. We then con-ducted a
detailed module-wise ablation study to further clarify thekey processing
modules for improving accuracy. The results showthat data augmentation and
post-processing significantly improvethe score in our system. In particular,
mix-up data augmentationand beam search in post-processing improve SPIDEr by
0.8 and 1.6points, respectively.
</p>
<a href="http://arxiv.org/abs/2009.11436">arXiv:2009.11436</a> [<a href="http://arxiv.org/pdf/2009.11436">pdf</a>]

<h2>Neurocoder: Learning General-Purpose Computation Using Stored Neural Programs. (arXiv:2009.11443v1 [cs.LG])</h2>
<h3>Hung Le, Svetha Venkatesh</h3>
<p>Artificial Neural Networks are uniquely adroit at machine learning by
processing data through a network of artificial neurons. The inter-neuronal
connection weights represent the learnt Neural Program that instructs the
network on how to compute the data. However, without an external memory to
store Neural Programs, they are restricted to only one, overwriting learnt
programs when trained on new data. This is functionally equivalent to a
special-purpose computer. Here we design Neurocoder, an entirely new class of
general-purpose conditional computational machines in which the neural network
"codes" itself in a data-responsive way by composing relevant programs from a
set of shareable, modular programs. This can be considered analogous to
building Lego structures from simple Lego bricks. Notably, our bricks change
their shape through learning. External memory is used to create, store and
retrieve modular programs. Like today's stored-program computers, Neurocoder
can now access diverse programs to process different data. Unlike manually
crafted computer programs, Neurocoder creates programs through training.
Integrating Neurocoder into current neural architectures, we demonstrate new
capacity to learn modular programs, handle severe pattern shifts and remember
old programs as new ones are learnt, and show substantial performance
improvement in solving object recognition, playing video games and continual
learning tasks. Such integration with Neurocoder increases the computation
capability of any current neural network and endows it with entirely new
capacity to reuse simple programs to build complex ones. For the first time a
Neural Program is treated as a datum in memory, paving the ways for modular,
recursive and procedural neural programming.
</p>
<a href="http://arxiv.org/abs/2009.11443">arXiv:2009.11443</a> [<a href="http://arxiv.org/pdf/2009.11443">pdf</a>]

<h2>3D Object Localization Using 2D Estimates for Computer Vision Applications. (arXiv:2009.11446v1 [cs.CV])</h2>
<h3>Taha Hasan Masood Siddique, Muhammad Usman</h3>
<p>A technique for object localization based on pose estimation and camera
calibration is presented. The 3-dimensional (3D) coordinates are estimated by
collecting multiple 2-dimensional (2D) images of the object and are utilized
for the calibration of the camera. The calibration steps involving a number of
parameter calculation including intrinsic and extrinsic parameters for the
removal of lens distortion, computation of object's size and camera's position
calculation are discussed. A transformation strategy to estimate the 3D pose
using the 2D images is presented. The proposed method is implemented on MATLAB
and validation experiments are carried out for both pose estimation and camera
calibration.
</p>
<a href="http://arxiv.org/abs/2009.11446">arXiv:2009.11446</a> [<a href="http://arxiv.org/pdf/2009.11446">pdf</a>]

<h2>BWCFace: Open-set Face Recognition using Body-worn Camera. (arXiv:2009.11458v1 [cs.CV])</h2>
<h3>Ali Almadan, Anoop Krishnan, Ajita Rattani</h3>
<p>With computer vision reaching an inflection point in the past decade, face
recognition technology has become pervasive in policing, intelligence
gathering, and consumer applications. Recently, face recognition technology has
been deployed on bodyworn cameras to keep officers safe, enabling situational
awareness and providing evidence for trial. However, limited academic research
has been conducted on this topic using traditional techniques on datasets with
small sample size. This paper aims to bridge the gap in the state-of-the-art
face recognition using bodyworn cameras (BWC). To this aim, the contribution of
this work is two-fold: (1) collection of a dataset called BWCFace consisting of
a total of 178K facial images of 132 subjects captured using the body-worn
camera in in-door and daylight conditions, and (2) open-set evaluation of the
latest deep-learning-based Convolutional Neural Network (CNN) architectures
combined with five different loss functions for face identification, on the
collected dataset. Experimental results on our BWCFace dataset suggest a
maximum of 33.89% Rank-1 accuracy obtained when facial features are extracted
using SENet-50 trained on a large scale VGGFace2 facial image dataset. However,
performance improved up to a maximum of 99.00% Rank-1 accuracy when pretrained
CNN models are fine-tuned on a subset of identities in our BWCFace dataset.
Equivalent performances were obtained across body-worn camera sensor models
used in existing face datasets. The collected BWCFace dataset and the
pretrained/ fine-tuned algorithms are publicly available to promote further
research and development in this area. A downloadable link of this dataset and
the algorithms is available by contacting the authors.
</p>
<a href="http://arxiv.org/abs/2009.11458">arXiv:2009.11458</a> [<a href="http://arxiv.org/pdf/2009.11458">pdf</a>]

<h2>Revisiting Graph Convolutional Network on Semi-Supervised Node Classification from an Optimization Perspective. (arXiv:2009.11469v1 [cs.LG])</h2>
<h3>Hongwei Zhang, Tijin Yan, Zenjun Xie, Yuanqing Xia, Yuan Zhang</h3>
<p>Graph convolutional networks (GCNs) have achieved promising performance on
various graph-based tasks. However they suffer from over-smoothing when
stacking more layers. In this paper, we present a quantitative study on this
observation and develop novel insights towards the deeper GCN. First, we
interpret the current graph convolutional operations from an optimization
perspective and argue that over-smoothing is mainly caused by the naive
first-order approximation of the solution to the optimization problem.
Subsequently, we introduce two metrics to measure the over-smoothing on
node-level tasks. Specifically, we calculate the fraction of the pairwise
distance between connected and disconnected nodes to the overall distance
respectively. Based on our theoretical and empirical analysis, we establish a
universal theoretical framework of GCN from an optimization perspective and
derive a novel convolutional kernel named GCN+ which has lower parameter amount
while relieving the over-smoothing inherently. Extensive experiments on
real-world datasets demonstrate the superior performance of GCN+ over
state-of-the-art baseline methods on the node classification tasks.
</p>
<a href="http://arxiv.org/abs/2009.11469">arXiv:2009.11469</a> [<a href="http://arxiv.org/pdf/2009.11469">pdf</a>]

<h2>AnchiBERT: A Pre-Trained Model for Ancient ChineseLanguage Understanding and Generation. (arXiv:2009.11473v1 [cs.CL])</h2>
<h3>Huishuang Tian, Kexin Yang, Dayiheng Liu, Jiancheng Lv</h3>
<p>Ancient Chinese is the essence of Chinese culture. There are several natural
language processing tasks of ancient Chinese domain, such as ancient-modern
Chinese translation, poem generation, and couplet generation. Previous studies
usually use the supervised models which deeply rely on parallel data. However,
it is difficult to obtain large-scale parallel data of ancient Chinese. In
order to make full use of the more easily available monolingual ancient Chinese
corpora, we release AnchiBERT, a pre-trained language model based on the
architecture of BERT, which is trained on large-scale ancient Chinese corpora.
We evaluate AnchiBERT on both language understanding and generation tasks,
including poem classification, ancient-modern Chinese translation, poem
generation, and couplet generation. The experimental results show that
AnchiBERT outperforms BERT as well as the non-pretrained models and achieves
state-of-the-art results in all cases.
</p>
<a href="http://arxiv.org/abs/2009.11473">arXiv:2009.11473</a> [<a href="http://arxiv.org/pdf/2009.11473">pdf</a>]

<h2>Theoretical Analysis of the Advantage of Deepening Neural Networks. (arXiv:2009.11479v1 [cs.LG])</h2>
<h3>Yasushi Esaki, Yuta Nakahara, Toshiyasu Matsushima</h3>
<p>We propose two new criteria to understand the advantage of deepening neural
networks. It is important to know the expressivity of functions computable by
deep neural networks in order to understand the advantage of deepening neural
networks. Unless deep neural networks have enough expressivity, they cannot
have good performance even though learning is successful. In this situation,
the proposed criteria contribute to understanding the advantage of deepening
neural networks since they can evaluate the expressivity independently from the
efficiency of learning. The first criterion shows the approximation accuracy of
deep neural networks to the target function. This criterion has the background
that the goal of deep learning is approximating the target function by deep
neural networks. The second criterion shows the property of linear regions of
functions computable by deep neural networks. This criterion has the background
that deep neural networks whose activation functions are piecewise linear are
also piecewise linear. Furthermore, by the two criteria, we show that to
increase layers is more effective than to increase units at each layer on
improving the expressivity of deep neural networks.
</p>
<a href="http://arxiv.org/abs/2009.11479">arXiv:2009.11479</a> [<a href="http://arxiv.org/pdf/2009.11479">pdf</a>]

<h2>Understanding Fairness of Gender Classification Algorithms Across Gender-Race Groups. (arXiv:2009.11491v1 [cs.CV])</h2>
<h3>Anoop Krishnan, Ali Almadan, Ajita Rattani</h3>
<p>Automated gender classification has important applications in many domains,
such as demographic research, law enforcement, online advertising, as well as
human-computer interaction. Recent research has questioned the fairness of this
technology across gender and race. Specifically, the majority of the studies
raised the concern of higher error rates of the face-based gender
classification system for darker-skinned people like African-American and for
women. However, to date, the majority of existing studies were limited to
African-American and Caucasian only. The aim of this paper is to investigate
the differential performance of the gender classification algorithms across
gender-race groups. To this aim, we investigate the impact of (a) architectural
differences in the deep learning algorithms and (b) training set imbalance, as
a potential source of bias causing differential performance across gender and
race. Experimental investigations are conducted on two latest large-scale
publicly available facial attribute datasets, namely, UTKFace and FairFace. The
experimental results suggested that the algorithms with architectural
differences varied in performance with consistency towards specific gender-race
groups. For instance, for all the algorithms used, Black females (Black race in
general) always obtained the least accuracy rates. Middle Eastern males and
Latino females obtained higher accuracy rates most of the time. Training set
imbalance further widens the gap in the unequal accuracy rates across all
gender-race groups. Further investigations using facial landmarks suggested
that facial morphological differences due to the bone structure influenced by
genetic and environmental factors could be the cause of the least performance
of Black females and Black race, in general.
</p>
<a href="http://arxiv.org/abs/2009.11491">arXiv:2009.11491</a> [<a href="http://arxiv.org/pdf/2009.11491">pdf</a>]

<h2>Discovery of Governing Equations with Recursive Deep Neural Networks. (arXiv:2009.11500v1 [math.NA])</h2>
<h3>Jia Zhao, Jarrod Mau</h3>
<p>Model discovery based on existing data has been one of the major focuses of
mathematical modelers for decades. Despite tremendous achievements of model
identification from adequate data, how to unravel the models from limited data
is less resolved. In this paper, we focus on the model discovery problem when
the data is not efficiently sampled in time. This is common due to limited
experimental accessibility and labor/resource constraints. Specifically, we
introduce a recursive deep neural network (RDNN) for data-driven model
discovery. This recursive approach can retrieve the governing equation in a
simple and efficient manner, and it can significantly improve the approximation
accuracy by increasing the recursive stages. In particular, our proposed
approach shows superior power when the existing data are sampled with a large
time lag, from which the traditional approach might not be able to recover the
model well. Several widely used examples of dynamical systems are used to
benchmark this newly proposed recursive approach. Numerical comparisons confirm
the effectiveness of this recursive neural network for model discovery.
</p>
<a href="http://arxiv.org/abs/2009.11500">arXiv:2009.11500</a> [<a href="http://arxiv.org/pdf/2009.11500">pdf</a>]

<h2>ThreatZoom: CVE2CWE using Hierarchical Neural Network. (arXiv:2009.11501v1 [cs.CR])</h2>
<h3>Ehsan Aghaei, Waseem Shadid, Ehab Al-Shaer</h3>
<p>The Common Vulnerabilities and Exposures (CVE) represent standard means for
sharing publicly known information security vulnerabilities. One or more CVEs
are grouped into the Common Weakness Enumeration (CWE) classes for the purpose
of understanding the software or configuration flaws and potential impacts
enabled by these vulnerabilities and identifying means to detect or prevent
exploitation. As the CVE-to-CWE classification is mostly performed manually by
domain experts, thousands of critical and new CVEs remain unclassified, yet
they are unpatchable. This significantly limits the utility of CVEs and slows
down proactive threat mitigation. This paper presents the first automatic tool
to classify CVEs to CWEs. ThreatZoom uses a novel learning algorithm that
employs an adaptive hierarchical neural network which adjusts its weights based
on text analytic scores and classification errors. It automatically estimates
the CWE classes corresponding to a CVE instance using both statistical and
semantic features extracted from the description of a CVE. This tool is
rigorously tested by various datasets provided by MITRE and the National
Vulnerability Database (NVD). The accuracy of classifying CVE instances to
their correct CWE classes are 92% (fine-grain) and 94% (coarse-grain) for NVD
dataset, and 75% (fine-grain) and 90% (coarse-grain) for MITRE dataset, despite
the small corpus.
</p>
<a href="http://arxiv.org/abs/2009.11501">arXiv:2009.11501</a> [<a href="http://arxiv.org/pdf/2009.11501">pdf</a>]

<h2>Improving Query Efficiency of Black-box Adversarial Attack. (arXiv:2009.11508v1 [cs.LG])</h2>
<h3>Yang Bai, Yuyuan Zeng, Yong Jiang, Yisen Wang, Shu-Tao Xia, Weiwei Guo</h3>
<p>Deep neural networks (DNNs) have demonstrated excellent performance on
various tasks, however they are under the risk of adversarial examples that can
be easily generated when the target model is accessible to an attacker
(white-box setting). As plenty of machine learning models have been deployed
via online services that only provide query outputs from inaccessible models
(e.g. Google Cloud Vision API2), black-box adversarial attacks (inaccessible
target model) are of critical security concerns in practice rather than
white-box ones. However, existing query-based black-box adversarial attacks
often require excessive model queries to maintain a high attack success rate.
Therefore, in order to improve query efficiency, we explore the distribution of
adversarial examples around benign inputs with the help of image structure
information characterized by a Neural Process, and propose a Neural Process
based black-box adversarial attack (NP-Attack) in this paper. Extensive
experiments show that NP-Attack could greatly decrease the query counts under
the black-box setting.
</p>
<a href="http://arxiv.org/abs/2009.11508">arXiv:2009.11508</a> [<a href="http://arxiv.org/pdf/2009.11508">pdf</a>]

<h2>Machine learning for UAV-Based networks. (arXiv:2009.11522v1 [eess.SP])</h2>
<h3>Mohamed-Amine Lahmeri, Mustafa A.Kishk, Mohamed-Slim Alouini</h3>
<p>Unmanned aerial vehicles (UAVs) are considered as one of the promising
technologies for the next-generation wireless communication networks. Their
mobility and their ability to establish a line of sight (LOS) links with the
users made them key solutions for many potential applications. In the same
vein, artificial intelligence is growing rapidly nowadays and has been very
successful, particularly due to the massive amount of the available data. As a
result, a significant part of the research community has started to integrate
intelligence at the core of UAVs networks by applying machine learning (ML)
algorithms in solving several problems in relation to drones. In this article,
we provide a comprehensive overview of some potential applications of ML in
UAV-Based networks. We will also highlight the limits of the existing works and
outline some potential future applications of ML for UAVs networks.
</p>
<a href="http://arxiv.org/abs/2009.11522">arXiv:2009.11522</a> [<a href="http://arxiv.org/pdf/2009.11522">pdf</a>]

<h2>Adversarial Brain Multiplex Prediction From a Single Network for High-Order Connectional Gender-Specific Brain Mapping. (arXiv:2009.11524v1 [eess.IV])</h2>
<h3>Ahmed Nebli, Islem Rekik</h3>
<p>Brain connectivity networks, derived from magnetic resonance imaging (MRI),
non-invasively quantify the relationship in function, structure, and morphology
between two brain regions of interest (ROIs) and give insights into
gender-related connectional differences. However, to the best of our knowledge,
studies on gender differences in brain connectivity were limited to
investigating pairwise (i.e., low-order) relationship ROIs, overlooking the
complex high-order interconnectedness of the brain as a network. To address
this limitation, brain multiplexes have been introduced to model the
relationship between at least two different brain networks. However, this
inhibits their application to datasets with single brain networks such as
functional networks. To fill this gap, we propose the first work on predicting
brain multiplexes from a source network to investigate gender differences.
Recently, generative adversarial networks (GANs) submerged the field of medical
data synthesis. However, although conventional GANs work well on images, they
cannot handle brain networks due to their non-Euclidean topological structure.
Differently, in this paper, we tap into the nascent field of geometric-GANs
(G-GAN) to design a deep multiplex prediction architecture comprising (i) a
geometric source to target network translator mimicking a U-Net architecture
with skip connections and (ii) a conditional discriminator which classifies
predicted target intra-layers by conditioning on the multiplex source
intra-layers. Such architecture simultaneously learns the latent source network
representation and the deep non-linear mapping from the source to target
multiplex intra-layers. Our experiments on a large dataset demonstrated that
predicted multiplexes significantly boost gender classification accuracy
compared with source networks and identifies both low and high-order
gender-specific multiplex connections.
</p>
<a href="http://arxiv.org/abs/2009.11524">arXiv:2009.11524</a> [<a href="http://arxiv.org/pdf/2009.11524">pdf</a>]

<h2>Residual Feature Distillation Network for Lightweight Image Super-Resolution. (arXiv:2009.11551v1 [eess.IV])</h2>
<h3>Jie Liu, Jie Tang, Gangshan Wu</h3>
<p>Recent advances in single image super-resolution (SISR) explored the power of
convolutional neural network (CNN) to achieve a better performance. Despite the
great success of CNN-based methods, it is not easy to apply these methods to
edge devices due to the requirement of heavy computation. To solve this
problem, various fast and lightweight CNN models have been proposed. The
information distillation network is one of the state-of-the-art methods, which
adopts the channel splitting operation to extract distilled features. However,
it is not clear enough how this operation helps in the design of efficient SISR
models. In this paper, we propose the feature distillation connection (FDC)
that is functionally equivalent to the channel splitting operation while being
more lightweight and flexible. Thanks to FDC, we can rethink the information
multi-distillation network (IMDN) and propose a lightweight and accurate SISR
model called residual feature distillation network (RFDN). RFDN uses multiple
feature distillation connections to learn more discriminative feature
representations. We also propose a shallow residual block (SRB) as the main
building block of RFDN so that the network can benefit most from residual
learning while still being lightweight enough. Extensive experimental results
show that the proposed RFDN achieve a better trade-off against the
state-of-the-art methods in terms of performance and model complexity.
Moreover, we propose an enhanced RFDN (E-RFDN) and won the first place in the
AIM 2020 efficient super-resolution challenge. Code will be available at
https://github.com/njulj/RFDN.
</p>
<a href="http://arxiv.org/abs/2009.11551">arXiv:2009.11551</a> [<a href="http://arxiv.org/pdf/2009.11551">pdf</a>]

<h2>Multi-View Brain HyperConnectome AutoEncoder For Brain State Classification. (arXiv:2009.11553v1 [cs.CV])</h2>
<h3>Alin Banka, Inis Buzi, Islem Rekik</h3>
<p>Graph embedding is a powerful method to represent graph neurological data
(e.g., brain connectomes) in a low dimensional space for brain connectivity
mapping, prediction and classification. However, existing embedding algorithms
have two major limitations. First, they primarily focus on preserving
one-to-one topological relationships between nodes (i.e., regions of interest
(ROIs) in a connectome), but they have mostly ignored many-to-many
relationships (i.e., set to set), which can be captured using a hyperconnectome
structure. Second, existing graph embedding techniques cannot be easily adapted
to multi-view graph data with heterogeneous distributions. In this paper, while
cross-pollinating adversarial deep learning with hypergraph theory, we aim to
jointly learn deep latent embeddings of subject0specific multi-view brain
graphs to eventually disentangle different brain states. First, we propose a
new simple strategy to build a hyperconnectome for each brain view based on
nearest neighbour algorithm to preserve the connectivities across pairs of
ROIs. Second, we design a hyperconnectome autoencoder (HCAE) framework which
operates directly on the multi-view hyperconnectomes based on hypergraph
convolutional layers to better capture the many-to-many relationships between
brain regions (i.e., nodes). For each subject, we further regularize the
hypergraph autoencoding by adversarial regularization to align the distribution
of the learned hyperconnectome embeddings with that of the input
hyperconnectomes. We formalize our hyperconnectome embedding within a geometric
deep learning framework to optimize for a given subject, thereby designing an
individual-based learning framework. Our experiments showed that the learned
embeddings by HCAE yield to better results for brain state classification
compared with other deep graph embedding methods methods.
</p>
<a href="http://arxiv.org/abs/2009.11553">arXiv:2009.11553</a> [<a href="http://arxiv.org/pdf/2009.11553">pdf</a>]

<h2>An Analysis of Concurrency Control Protocols for In-Memory Databases with CCBench (Extended Version). (arXiv:2009.11558v1 [cs.DB])</h2>
<h3>Takayuki Tanabe, Takashi Hoshino, Hideyuki Kawashima, Osamu Tatebe</h3>
<p>This paper presents yet another concurrency control analysis platform,
CCBench. CCBench supports seven protocols (Silo, TicToc, MOCC, Cicada, SI, SI
with latch-free SSN, 2PL) and seven versatile optimization methods and enables
the configuration of seven workload parameters. We analyzed the protocols and
optimization methods using various workload parameters and a thread count of
224. Previous studies focused on thread scalability and did not explore the
space analyzed here. We classified the optimization methods on the basis of
three performance factors: CPU cache, delay on conflict, and version lifetime.
Analyses using CCBench and 224 threads, produced six insights. (I1) The
performance of optimistic concurrency control protocol for a read only workload
rapidly degrades as cardinality increases even without L3 cache misses. (I2)
Silo can outperform TicToc for some write-intensive workloads by using
invisible reads optimization. (I3) The effectiveness of two approaches to
coping with conflict (wait and no-wait) depends on the situation. (I4) OCC
reads the same record two or more times if a concurrent transaction
interruption occurs, which can improve performance. (I5) Mixing different
implementations is inappropriate for deep analysis. (I6) Even a
state-of-the-art garbage collection method cannot improve the performance of
multi-version protocols if there is a single long transaction mixed into the
workload. On the basis of I4, we defined the read phase extension optimization
in which an artificial delay is added to the read phase. On the basis of I6, we
defined the aggressive garbage collection optimization in which even visible
versions are collected. The code for CCBench and all the data in this paper are
available online at GitHub.
</p>
<a href="http://arxiv.org/abs/2009.11558">arXiv:2009.11558</a> [<a href="http://arxiv.org/pdf/2009.11558">pdf</a>]

<h2>Local Context Attention for Salient Object Segmentation. (arXiv:2009.11562v1 [cs.CV])</h2>
<h3>Jing Tan, Pengfei Xiong, Yuwen He, Kuntao Xiao, Zhengyi Lv</h3>
<p>Salient object segmentation aims at distinguishing various salient objects
from backgrounds. Despite the lack of semantic consistency, salient objects
often have obvious texture and location characteristics in local area. Based on
this priori, we propose a novel Local Context Attention Network (LCANet) to
generate locally reinforcement feature maps in a uniform representational
architecture. The proposed network introduces an Attentional Correlation Filter
(ACF) module to generate explicit local attention by calculating the
correlation feature map between coarse prediction and global context. Then it
is expanded to a Local Context Block(LCB). Furthermore, an one-stage
coarse-to-fine structure is implemented based on LCB to adaptively enhance the
local context description ability. Comprehensive experiments are conducted on
several salient object segmentation datasets, demonstrating the superior
performance of the proposed LCANet against the state-of-the-art methods,
especially with 0.883 max F-score and 0.034 MAE on DUTS-TE dataset.
</p>
<a href="http://arxiv.org/abs/2009.11562">arXiv:2009.11562</a> [<a href="http://arxiv.org/pdf/2009.11562">pdf</a>]

<h2>Cloud Cover Nowcasting with Deep Learning. (arXiv:2009.11577v1 [cs.CV])</h2>
<h3>L&#xe9;a Berthomier, Bruno Pradel, Lior Perez</h3>
<p>Nowcasting is a field of meteorology which aims at forecasting weather on a
short term of up to a few hours. In the meteorology landscape, this field is
rather specific as it requires particular techniques, such as data
extrapolation, where conventional meteorology is generally based on physical
modeling. In this paper, we focus on cloud cover nowcasting, which has various
application areas such as satellite shots optimisation and photovoltaic energy
production forecast.

Following recent deep learning successes on multiple imagery tasks, we
applied deep convolutionnal neural networks on Meteosat satellite images for
cloud cover nowcasting. We present the results of several architectures
specialized in image segmentation and time series prediction. We selected the
best models according to machine learning metrics as well as meteorological
metrics. All selected architectures showed significant improvements over
persistence and the well-known U-Net surpasses AROME physical model.
</p>
<a href="http://arxiv.org/abs/2009.11577">arXiv:2009.11577</a> [<a href="http://arxiv.org/pdf/2009.11577">pdf</a>]

<h2>Bayesian Learning in Dynamic Non-atomic Routing Games. (arXiv:2009.11580v1 [econ.TH])</h2>
<h3>Emilien Macault, Marco Scarsini, Tristan Tomala</h3>
<p>We consider a discrete-time nonatomic routing game with variable demand and
uncertain costs. Given a fixed routing network with single origin and
destination, the costs functions on edges depend on some uncertain persistent
state parameter. Every period, a variable traffic demand routes through the
network. The experienced costs are publicly observed and the belief about the
state parameter is Bayesianly updated. This paper studies the dynamics of
equilibrium and beliefs. We say that there is strong learning when beliefs
converge to the truth and there is weak learning when equilibrium flows
converge to those under complete information. Our main result is a
characterization of the networks for which learning occurs for all increasing
cost functions, given highly variable demand. We prove that these networks have
a series-parallel structure and provide a counterexample to prove that the
condition is necessary.
</p>
<a href="http://arxiv.org/abs/2009.11580">arXiv:2009.11580</a> [<a href="http://arxiv.org/pdf/2009.11580">pdf</a>]

<h2>Transfer Learning by Cascaded Network to identify and classify lung nodules for cancer detection. (arXiv:2009.11587v1 [eess.IV])</h2>
<h3>Shah B. Shrey, Lukman Hakim, Muthusubash Kavitha, Hae Won Kim, Takio Kurita</h3>
<p>Lung cancer is one of the most deadly diseases in the world. Detecting such
tumors at an early stage can be a tedious task. Existing deep learning
architecture for lung nodule identification used complex architecture with
large number of parameters. This study developed a cascaded architecture which
can accurately segment and classify the benign or malignant lung nodules on
computed tomography (CT) images. The main contribution of this study is to
introduce a segmentation network where the first stage trained on a public data
set can help to recognize the images which included a nodule from any data set
by means of transfer learning. And the segmentation of a nodule improves the
second stage to classify the nodules into benign and malignant. The proposed
architecture outperformed the conventional methods with an area under curve
value of 95.67\%. The experimental results showed that the classification
accuracy of 97.96\% of our proposed architecture outperformed other simple and
complex architectures in classifying lung nodules for lung cancer detection.
</p>
<a href="http://arxiv.org/abs/2009.11587">arXiv:2009.11587</a> [<a href="http://arxiv.org/pdf/2009.11587">pdf</a>]

<h2>On the use of evidence theory in belief base revision. (arXiv:2009.11640v1 [cs.AI])</h2>
<h3>Ra&#xef;da Ktari, Mohamed Ayman Boujelben</h3>
<p>This paper deals with belief base revision that is a form of belief change
consisting of the incorporation of new facts into an agent's beliefs
represented by a finite set of propositional formulas. In the aim to guarantee
more reliability and rationality for real applications while performing
revision, we propose the idea of credible belief base revision yielding to
define two new formula-based revision operators using the suitable tools
offered by evidence theory. These operators, uniformly presented in the same
spirit of others in [9], stem from consistent subbases maximal with respect to
credibility instead of set inclusion and cardinality. Moreover, in between
these two extremes operators, evidence theory let us shed some light on a
compromise operator avoiding losing initial beliefs to the maximum extent
possible. Its idea captures maximal consistent sets stemming from all possible
intersections of maximal consistent subbases. An illustration of all these
operators and a comparison with others are inverstigated by examples.
</p>
<a href="http://arxiv.org/abs/2009.11640">arXiv:2009.11640</a> [<a href="http://arxiv.org/pdf/2009.11640">pdf</a>]

<h2>The COUGHVID crowdsourcing dataset: A corpus for the study of large-scale cough analysis algorithms. (arXiv:2009.11644v1 [cs.SD])</h2>
<h3>Lara Orlandic, Tomas Teijeiro, David Atienza</h3>
<p>Cough audio signal classification has been successfully used to diagnose a
variety of respiratory conditions, and there has been significant interest in
leveraging Machine Learning (ML) to provide widespread COVID-19 screening.
However, there is currently no validated database of cough sounds with which to
train such ML models. The COUGHVID dataset provides over 20,000 crowdsourced
cough recordings representing a wide range of subject ages, genders, geographic
locations, and COVID-19 statuses. First, we filtered the dataset using our
open-sourced cough detection algorithm. Second, experienced pulmonologists
labeled more than 2,000 recordings to diagnose medical abnormalities present in
the coughs, thereby contributing one of the largest expert-labeled cough
datasets in existence that can be used for a plethora of cough audio
classification tasks. Finally, we ensured that coughs labeled as symptomatic
and COVID-19 originate from countries with high infection rates, and that their
expert labels are consistent. As a result, the COUGHVID dataset contributes a
wealth of cough recordings for training ML models to address the world's most
urgent health crises.
</p>
<a href="http://arxiv.org/abs/2009.11644">arXiv:2009.11644</a> [<a href="http://arxiv.org/pdf/2009.11644">pdf</a>]

<h2>Best Practices for Managing Data Annotation Projects. (arXiv:2009.11654v1 [cs.CY])</h2>
<h3>Tina Tseng, Amanda Stent, Domenic Maida</h3>
<p>Annotation is the labeling of data by human effort. Annotation is critical to
modern machine learning, and Bloomberg has developed years of experience of
annotation at scale. This report captures a wealth of wisdom for applied
annotation projects, collected from more than 30 experienced annotation project
managers in Bloomberg's Global Data department.
</p>
<a href="http://arxiv.org/abs/2009.11654">arXiv:2009.11654</a> [<a href="http://arxiv.org/pdf/2009.11654">pdf</a>]

<h2>Heuristics based Mosaic of Social-Sensor Services for Scene Reconstruction. (arXiv:2009.11663v1 [cs.CV])</h2>
<h3>Tooba Aamir, Hai Dong, Athman Bouguettaya</h3>
<p>We propose a heuristics-based social-sensor cloud service selection and
composition model to reconstruct mosaic scenes. The proposed approach leverages
crowdsourced social media images to create an image mosaic to reconstruct a
scene at a designated location and an interval of time. The novel approach
relies on the set of features defined on the bases of the image metadata to
determine the relevance and composability of services. Novel heuristics are
developed to filter out non-relevant services. Multiple machine learning
strategies are employed to produce smooth service composition resulting in a
mosaic of relevant images indexed by geolocation and time. The preliminary
analytical results prove the feasibility of the proposed composition model.
</p>
<a href="http://arxiv.org/abs/2009.11663">arXiv:2009.11663</a> [<a href="http://arxiv.org/pdf/2009.11663">pdf</a>]

<h2>Eye Movement Feature Classification for Soccer Expertise Identification in Virtual Reality. (arXiv:2009.11676v1 [cs.HC])</h2>
<h3>Benedikt Hosp, Florian Schultz, Enkelejda Kasneci, Oliver H&#xf6;ner</h3>
<p>Latest research in expertise assessment of soccer players pronounced the
importance of perceptual skills. Former research focused either on high
experimental control or natural presentation mode. To assess perceptual skills
of athletes, in an optimized manner, we captured omnidirectional in-field
scenes, showed to 12 expert, 9 intermediate and 13 novice goalkeepers from
soccer on virtual reality glasses. All scenes where shown from the same natural
goalkeeper perspective and ended after the return pass to the goalkeeper. Based
on their responses and gaze behavior we classified their expertise with common
machine learning techniques. This pilot study shows promising results for
objective classification of goalkeepers expertise based on their gaze
behaviour.
</p>
<a href="http://arxiv.org/abs/2009.11676">arXiv:2009.11676</a> [<a href="http://arxiv.org/pdf/2009.11676">pdf</a>]

<h2>Legally grounded fairness objectives. (arXiv:2009.11677v1 [cs.LG])</h2>
<h3>Dylan Holden-Sim, Gavin Leech, Laurence Aitchison</h3>
<p>Recent work has identified a number of formally incompatible operational
measures for the unfairness of a machine learning (ML) system. As these
measures all capture intuitively desirable aspects of a fair system, choosing
"the one true" measure is not possible, and instead a reasonable approach is to
minimize a weighted combination of measures. However, this simply raises the
question of how to choose the weights. Here, we formulate Legally Grounded
Fairness Objectives (LGFO), which uses signals from the legal system to
non-arbitrarily measure the social cost of a specific degree of unfairness. The
LGFO is the expected damages under a putative lawsuit that might be awarded to
those who were wrongly classified, in the sense that the ML system made a
decision different to that which would have be made under the court's preferred
measure. Notably, the two quantities necessary to compute the LGFO, the court's
preferences about fairness measures, and the expected damages, are unknown but
well-defined, and can be estimated by legal advice. Further, as the damages
awarded by the legal system are designed to measure and compensate for the harm
caused to an individual by an unfair classification, the LGFO aligns closely
with society's estimate of the social cost.
</p>
<a href="http://arxiv.org/abs/2009.11677">arXiv:2009.11677</a> [<a href="http://arxiv.org/pdf/2009.11677">pdf</a>]

<h2>Privacy-preserving Transfer Learning via Secure Maximum Mean Discrepancy. (arXiv:2009.11680v1 [cs.LG])</h2>
<h3>Bin Zhang, Cen Chen, Li Wang</h3>
<p>The success of machine learning algorithms often relies on a large amount of
high-quality data to train well-performed models. However, data is a valuable
resource and are always held by different parties in reality. An effective
solution to such a data isolation problem is to employ federated learning,
which allows multiple parties to collaboratively train a model. In this paper,
we propose a Secure version of the widely used Maximum Mean Discrepancy (SMMD)
based on homomorphic encryption to enable effective knowledge transfer under
the data federation setting without compromising the data privacy. The proposed
SMMD is able to avoid the potential information leakage in transfer learning
when aligning the source and target data distribution. As a result, both the
source domain and target domain can fully utilize their data to build more
scalable models. Experimental results demonstrate that our proposed SMMD is
secure and effective.
</p>
<a href="http://arxiv.org/abs/2009.11680">arXiv:2009.11680</a> [<a href="http://arxiv.org/pdf/2009.11680">pdf</a>]

<h2>A Variational Auto-Encoder for Reservoir Monitoring. (arXiv:2009.11693v1 [cs.LG])</h2>
<h3>Kristian Gundersen, Seyyed A. Hosseini, Anna Oleynik, Guttorm Alendal</h3>
<p>Carbon dioxide Capture and Storage (CCS) is an important strategy in
mitigating anthropogenic CO$_2$ emissions. In order for CCS to be successful,
large quantities of CO$_2$ must be stored and the storage site conformance must
be monitored. Here we present a deep learning method to reconstruct pressure
fields and classify the flux out of the storage formation based on the pressure
data from Above Zone Monitoring Interval (AZMI) wells. The deep learning method
is a version of a semi conditional variational auto-encoder tailored to solve
two tasks: reconstruction of an incremental pressure field and leakage rate
classification. The method, predictions and associated uncertainty estimates
are illustrated on the synthetic data from a high-fidelity heterogeneous 2D
numerical reservoir model, which was used to simulate subsurface CO$_2$
movement and pressure changes in the AZMI due to a CO$_2$ leakage.
</p>
<a href="http://arxiv.org/abs/2009.11693">arXiv:2009.11693</a> [<a href="http://arxiv.org/pdf/2009.11693">pdf</a>]

<h2>Compressed imitation learning. (arXiv:2009.11697v1 [cs.LG])</h2>
<h3>Nathan Zhao, Beicheng Lou</h3>
<p>In analogy to compressed sensing, which allows sample-efficient signal
reconstruction given prior knowledge of its sparsity in frequency domain, we
propose to utilize policy simplicity (Occam's Razor) as a prior to enable
sample-efficient imitation learning. We first demonstrated the feasibility of
this scheme on linear case where state-value function can be sampled directly.
We also extended the scheme to scenarios where only actions are visible and
scenarios where the policy is obtained from nonlinear network. The method is
benchmarked against behavior cloning and results in significantly higher scores
with limited expert demonstrations.
</p>
<a href="http://arxiv.org/abs/2009.11697">arXiv:2009.11697</a> [<a href="http://arxiv.org/pdf/2009.11697">pdf</a>]

<h2>Principles and Practice of Explainable Machine Learning. (arXiv:2009.11698v1 [cs.LG])</h2>
<h3>Vaishak Belle, Ioannis Papantonis</h3>
<p>Artificial intelligence (AI) provides many opportunities to improve private
and public life. Discovering patterns and structures in large troves of data in
an automated manner is a core component of data science, and currently drives
applications in diverse areas such as computational biology, law and finance.
However, such a highly positive impact is coupled with significant challenges:
how do we understand the decisions suggested by these systems in order that we
can trust them? In this report, we focus specifically on data-driven methods --
machine learning (ML) and pattern recognition models in particular -- so as to
survey and distill the results and observations from the literature. The
purpose of this report can be especially appreciated by noting that ML models
are increasingly deployed in a wide range of businesses. However, with the
increasing prevalence and complexity of methods, business stakeholders in the
very least have a growing number of concerns about the drawbacks of models,
data-specific biases, and so on. Analogously, data science practitioners are
often not aware about approaches emerging from the academic literature, or may
struggle to appreciate the differences between different methods, so end up
using industry standards such as SHAP. Here, we have undertaken a survey to
help industry practitioners (but also data scientists more broadly) understand
the field of explainable machine learning better and apply the right tools. Our
latter sections build a narrative around a putative data scientist, and discuss
how she might go about explaining her models by asking the right questions.
</p>
<a href="http://arxiv.org/abs/2009.11698">arXiv:2009.11698</a> [<a href="http://arxiv.org/pdf/2009.11698">pdf</a>]

<h2>The Deep Learning Galerkin Method for the General Stokes Equations. (arXiv:2009.11701v1 [math.NA])</h2>
<h3>Jian Li, Jing Yue, Wen Zhang, Wansuo Duan</h3>
<p>The finite element method, finite difference method, finite volume method and
spectral method have achieved great success in solving partial differential
equations. However, the high accuracy of traditional numerical methods is at
the cost of high efficiency. Especially in the face of high-dimensional
problems, the traditional numerical methods are often not feasible in the
subdivision of high-dimensional meshes and the differentiability and
integrability of high-order terms. In deep learning, neural network can deal
with high-dimensional problems by adding the number of layers or expanding the
number of neurons. Compared with traditional numerical methods, it has great
advantages. In this article, we consider the Deep Galerkin Method (DGM) for
solving the general Stokes equations by using deep neural network without
generating mesh grid. The DGM can reduce the computational complexity and
achieve the competitive results. Here, depending on the L2 error we construct
the objective function to control the performance of the approximation
solution. Then, we prove the convergence of the objective function and the
convergence of the neural network to the exact solution. Finally, the
effectiveness of the proposed framework is demonstrated through some numerical
experiments.
</p>
<a href="http://arxiv.org/abs/2009.11701">arXiv:2009.11701</a> [<a href="http://arxiv.org/pdf/2009.11701">pdf</a>]

<h2>Gated Res2Net for Multivariate Time Series Analysis. (arXiv:2009.11705v1 [cs.LG])</h2>
<h3>Chao Yang, Mingxing Jiang, Zhongwen Guo, Yuan Liu</h3>
<p>Multivariate time series analysis is an important problem in data mining
because of its widespread applications. With the increase of time series data
available for training, implementing deep neural networks in the field of time
series analysis is becoming common. Res2Net, a recently proposed backbone, can
further improve the state-of-the-art networks as it improves the multi-scale
representation ability through connecting different groups of filters. However,
Res2Net ignores the correlations of the feature maps and lacks the control on
the information interaction process. To address that problem, in this paper, we
propose a backbone convolutional neural network based on the thought of gated
mechanism and Res2Net, namely Gated Res2Net (GRes2Net), for multivariate time
series analysis. The hierarchical residual-like connections are influenced by
gates whose values are calculated based on the original feature maps, the
previous output feature maps and the next input feature maps thus considering
the correlations between the feature maps more effectively. Through the
utilization of gated mechanism, the network can control the process of
information sending hence can better capture and utilize the both the temporal
information and the correlations between the feature maps. We evaluate the
GRes2Net on four multivariate time series datasets including two classification
datasets and two forecasting datasets. The results demonstrate that GRes2Net
have better performances over the state-of-the-art methods thus indicating the
superiority
</p>
<a href="http://arxiv.org/abs/2009.11705">arXiv:2009.11705</a> [<a href="http://arxiv.org/pdf/2009.11705">pdf</a>]

<h2>Online Structural Change-point Detection of High-dimensional Streaming Data via Dynamic Sparse Subspace Learning. (arXiv:2009.11713v1 [stat.ML])</h2>
<h3>Ruiyu Xu, Jianguo Wu, Xiaowei Yue, Yongxiang Li</h3>
<p>High-dimensional streaming data are becoming increasingly ubiquitous in many
fields. They often lie in multiple low-dimensional subspaces, and the manifold
structures may change abruptly on the time scale due to pattern shift or
occurrence of anomalies. However, the problem of detecting the structural
changes in a real-time manner has not been well studied. To fill this gap, we
propose a dynamic sparse subspace learning (DSSL) approach for online
structural change-point detection of high-dimensional streaming data. A novel
multiple structural change-point model is proposed and it is shown to be
equivalent to maximizing a posterior under certain conditions. The asymptotic
properties of the estimators are investigated. The penalty coefficients in our
model can be selected by AMDL criterion based on some historical data. An
efficient Pruned Exact Linear Time (PELT) based method is proposed for online
optimization and change-point detection. The effectiveness of the proposed
method is demonstrated through a simulation study and a real case study using
gesture data for motion tracking.
</p>
<a href="http://arxiv.org/abs/2009.11713">arXiv:2009.11713</a> [<a href="http://arxiv.org/pdf/2009.11713">pdf</a>]

<h2>Deep Neural Networks with Short Circuits for Improved Gradient Learning. (arXiv:2009.11719v1 [cs.LG])</h2>
<h3>Ming Yan, Xueli Xiao, Joey Tianyi Zhou, Yi Pan</h3>
<p>Deep neural networks have achieved great success both in computer vision and
natural language processing tasks. However, mostly state-of-art methods highly
rely on external training or computing to improve the performance. To alleviate
the external reliance, we proposed a gradient enhancement approach, conducted
by the short circuit neural connections, to improve the gradient learning of
deep neural networks. The proposed short circuit is a unidirectional connection
that single back propagates the sensitive from the deep layer to the shallows.
Moreover, the short circuit formulates to be a gradient truncation of its
crossing layers which can plug into the backbone deep neural networks without
introducing external training parameters. Extensive experiments demonstrate
deep neural networks with our short circuit gain a large margin over the
baselines on both computer vision and natural language processing tasks.
</p>
<a href="http://arxiv.org/abs/2009.11719">arXiv:2009.11719</a> [<a href="http://arxiv.org/pdf/2009.11719">pdf</a>]

<h2>Cloud2Edge Elastic AI Framework for Prototyping and Deployment of AI Inference Engines in Autonomous Vehicles. (arXiv:2009.11722v1 [cs.SE])</h2>
<h3>Sorin Grigorescu, Tiberiu Cocias, Bogdan Trasnea, Andrea Margheri, Federico Lombardi, Leonardo Aniello</h3>
<p>Self-driving cars and autonomous vehicles are revolutionizing the automotive
sector, shaping the future of mobility altogether. Although the integration of
novel technologies such as Artificial Intelligence (AI) and Cloud/Edge
computing provides golden opportunities to improve autonomous driving
applications, there is the need to modernize accordingly the whole prototyping
and deployment cycle of AI components. This paper proposes a novel framework
for developing so-called AI Inference Engines for autonomous driving
applications based on deep learning modules, where training tasks are deployed
elastically over both Cloud and Edge resources, with the purpose of reducing
the required network bandwidth, as well as mitigating privacy issues. Based on
our proposed data driven V-Model, we introduce a simple yet elegant solution
for the AI components development cycle, where prototyping takes place in the
cloud according to the Software-in-the-Loop (SiL) paradigm, while deployment
and evaluation on the target ECUs (Electronic Control Units) is performed as
Hardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework
is demonstrated using two real-world use-cases of AI inference engines for
autonomous vehicles, that is environment perception and most probable path
prediction.
</p>
<a href="http://arxiv.org/abs/2009.11722">arXiv:2009.11722</a> [<a href="http://arxiv.org/pdf/2009.11722">pdf</a>]

<h2>Evaluation of an indoor localization system for a mobile robot. (arXiv:2009.11726v1 [cs.RO])</h2>
<h3>Victor J. Exposito Jimenez, Christian Schwarzl, Helmut Martin</h3>
<p>Although indoor localization has been a wide researched topic, obtained
results may not fit the requirements that some domains need. Most approaches
are not able to precisely localize a fast moving object even with a complex
installation, which makes their implementation in the automated driving domain
complicated. In this publication, common technologies were analyzed and a
commercial product, called Marvelmind Indoor GPS, was chosen for our use case
in which both ultrasound and radio frequency communications are used. The
evaluation is given in a first moment on small indoor scenarios with static and
moving objects. Further tests were done on wider areas, where the system is
integrated within our Robotics Operating System (ROS)-based self-developed
'Smart PhysIcal Demonstration and evaluation Robot (SPIDER)' and the results of
these outdoor tests are compared with the obtained localization by the
installed GPS on the robot. Finally, the next steps to improve the results in
further developments are discussed.
</p>
<a href="http://arxiv.org/abs/2009.11726">arXiv:2009.11726</a> [<a href="http://arxiv.org/pdf/2009.11726">pdf</a>]

<h2>Interpreting and Boosting Dropout from a Game-Theoretic View. (arXiv:2009.11729v1 [cs.LG])</h2>
<h3>Hao Zhang, Sen Li, Yinchao Ma, Mingjie Li, Yichen Xie, Quanshi Zhang</h3>
<p>This paper aims to understand and improve the utility of the dropout
operation from the perspective of game-theoretic interactions. We prove that
dropout can suppress the strength of interactions between input variables of
deep neural networks (DNNs). The theoretical proof is also verified by various
experiments. Furthermore, we find that such interactions were strongly related
to the over-fitting problem in deep learning. Thus, the utility of dropout can
be regarded as decreasing interactions to alleviating the significance of
over-fitting. Based on this understanding, we propose an interaction loss to
further improve the utility of dropout. Experimental results have shown that
the interaction loss can effectively improve the utility of dropout and boost
the performance of DNNs.
</p>
<a href="http://arxiv.org/abs/2009.11729">arXiv:2009.11729</a> [<a href="http://arxiv.org/pdf/2009.11729">pdf</a>]

<h2>A Unifying Review of Deep and Shallow Anomaly Detection. (arXiv:2009.11732v1 [cs.LG])</h2>
<h3>Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, Gr&#xe9;goire Montavon, Wojciech Samek, Marius Kloft, Thomas G. Dietterich, Klaus-Robert M&#xfc;ller</h3>
<p>Deep learning approaches to anomaly detection have recently improved the
state of the art in detection performance on complex datasets such as large
collections of images or text. These results have sparked a renewed interest in
the anomaly detection problem and led to the introduction of a great variety of
new methods. With the emergence of numerous such methods, including approaches
based on generative models, one-class classification, and reconstruction, there
is a growing need to bring methods of this field into a systematic and unified
perspective. In this review we aim to identify the common underlying principles
as well as the assumptions that are often made implicitly by various methods.
In particular, we draw connections between classic 'shallow' and novel deep
approaches and show how this relation might cross-fertilize or extend both
directions. We further provide an empirical assessment of major existing
methods that is enriched by the use of recent explainability techniques, and
present specific worked-through examples together with practical advice.
Finally, we outline critical open challenges and identify specific paths for
future research in anomaly detection.
</p>
<a href="http://arxiv.org/abs/2009.11732">arXiv:2009.11732</a> [<a href="http://arxiv.org/pdf/2009.11732">pdf</a>]

<h2>Graph Sparsification with Generative Adversarial Network. (arXiv:2009.11736v1 [cs.SI])</h2>
<h3>Hang-Yang Wu, Yi-Ling Chen</h3>
<p>Graph sparsification aims to reduce the number of edges of a network while
maintaining its accuracy for given tasks. In this study, we propose a novel
method called GSGAN, which is able to sparsify networks for community detection
tasks. GSGAN is able to capture those relationships that are not shown in the
original graph but are relatively important, and creating artificial edges to
reflect these relationships and further increase the effectiveness of the
community detection task. We adopt GAN as the learning model and guide the
generator to produce random walks that are able to capture the structure of a
network. Specifically, during the training phase, in addition to judging the
authenticity of the random walk, discriminator also considers the relationship
between nodes at the same time. We design a reward function to guide the
generator creating random walks that contain useful hidden relation
information. These random walks are then combined to form a new social network
that is efficient and effective for community detection. Experiments with
real-world networks demonstrate that the proposed GSGAN is much more effective
than the baselines, and GSGAN can be applied and helpful to various clustering
algorithms of community detection.
</p>
<a href="http://arxiv.org/abs/2009.11736">arXiv:2009.11736</a> [<a href="http://arxiv.org/pdf/2009.11736">pdf</a>]

<h2>Learning Graph Normalization for Graph Neural Networks. (arXiv:2009.11746v1 [cs.LG])</h2>
<h3>Yihao Chen, Xin Tang, Xianbiao Qi, Chun-Guang Li, Rong Xiao</h3>
<p>Graph Neural Networks (GNNs) have attracted considerable attention and have
emerged as a new promising paradigm to process graph-structured data. GNNs are
usually stacked to multiple layers and the node representations in each layer
are computed through propagating and aggregating the neighboring node features
with respect to the graph. By stacking to multiple layers, GNNs are able to
capture the long-range dependencies among the data on the graph and thus bring
performance improvements. To train a GNN with multiple layers effectively, some
normalization techniques (e.g., node-wise normalization, batch-wise
normalization) are necessary. However, the normalization techniques for GNNs
are highly task-relevant and different application tasks prefer to different
normalization techniques, which is hard to know in advance. To tackle this
deficiency, in this paper, we propose to learn graph normalization by
optimizing a weighted combination of normalization techniques at four different
levels, including node-wise normalization, adjacency-wise normalization,
graph-wise normalization, and batch-wise normalization, in which the
adjacency-wise normalization and the graph-wise normalization are newly
proposed in this paper to take into account the local structure and the global
structure on the graph, respectively. By learning the optimal weights, we are
able to automatically select a single best or a best combination of multiple
normalizations for a specific task. We conduct extensive experiments on
benchmark datasets for different tasks, including node classification, link
prediction, graph classification and graph regression, and confirm that the
learned graph normalization leads to competitive results and that the learned
weights suggest the appropriate normalization techniques for the specific task.
Source code is released here https://github.com/cyh1112/GraphNormalization.
</p>
<a href="http://arxiv.org/abs/2009.11746">arXiv:2009.11746</a> [<a href="http://arxiv.org/pdf/2009.11746">pdf</a>]

<h2>Generating Commonsense Explanation by Extracting Bridge Concepts from Reasoning Paths. (arXiv:2009.11753v1 [cs.CL])</h2>
<h3>Haozhe Ji, Pei Ke, Shaohan Huang, Furu Wei, Minlie Huang</h3>
<p>Commonsense explanation generation aims to empower the machine's sense-making
capability by generating plausible explanations to statements against
commonsense. While this task is easy to human, the machine still struggles to
generate reasonable and informative explanations. In this work, we propose a
method that first extracts the underlying concepts which are served as
\textit{bridges} in the reasoning chain and then integrates these concepts to
generate the final explanation. To facilitate the reasoning process, we utilize
external commonsense knowledge to build the connection between a statement and
the bridge concepts by extracting and pruning multi-hop paths to build a
subgraph. We design a bridge concept extraction model that first scores the
triples, routes the paths in the subgraph, and further selects bridge concepts
with weak supervision at both the triple level and the concept level. We
conduct experiments on the commonsense explanation generation task and our
model outperforms the state-of-the-art baselines in both automatic and human
evaluation.
</p>
<a href="http://arxiv.org/abs/2009.11753">arXiv:2009.11753</a> [<a href="http://arxiv.org/pdf/2009.11753">pdf</a>]

<h2>Secure Data Sharing With Flow Model. (arXiv:2009.11762v1 [cs.LG])</h2>
<h3>Chenwei Wu, Chenzhuang Du, Yang Yuan</h3>
<p>In the classical multi-party computation setting, multiple parties jointly
compute a function without revealing their own input data. We consider a
variant of this problem, where the input data can be shared for machine
learning training purposes, but the data are also encrypted so that they cannot
be recovered by other parties. We present a rotation based method using flow
model, and theoretically justified its security. We demonstrate the
effectiveness of our method in different scenarios, including supervised secure
model training, and unsupervised generative model training. Our code is
available at https://github.com/ duchenzhuang/flowencrypt.
</p>
<a href="http://arxiv.org/abs/2009.11762">arXiv:2009.11762</a> [<a href="http://arxiv.org/pdf/2009.11762">pdf</a>]

<h2>Unsupervised Transfer Learning for Spatiotemporal Predictive Networks. (arXiv:2009.11763v1 [cs.LG])</h2>
<h3>Zhiyu Yao, Yunbo Wang, Mingsheng Long, Jianmin Wang</h3>
<p>This paper explores a new research problem of unsupervised transfer learning
across multiple spatiotemporal prediction tasks. Unlike most existing transfer
learning methods that focus on fixing the discrepancy between supervised tasks,
we study how to transfer knowledge from a zoo of unsupervisedly learned models
towards another predictive network. Our motivation is that models from
different sources are expected to understand the complex spatiotemporal
dynamics from different perspectives, thereby effectively supplementing the new
task, even if the task has sufficient training samples. Technically, we propose
a differentiable framework named transferable memory. It adaptively distills
knowledge from a bank of memory states of multiple pretrained RNNs, and applies
it to the target network via a novel recurrent structure called the
Transferable Memory Unit (TMU). Compared with finetuning, our approach yields
significant improvements on three benchmarks for spatiotemporal prediction, and
benefits the target task even from less relevant pretext ones.
</p>
<a href="http://arxiv.org/abs/2009.11763">arXiv:2009.11763</a> [<a href="http://arxiv.org/pdf/2009.11763">pdf</a>]

<h2>Scalable Recommendation of Wikipedia Articles to Editors Using Representation Learning. (arXiv:2009.11771v1 [cs.IR])</h2>
<h3>Oleksii Moskalenko, Denis Parra, Diego Saez-Trumper</h3>
<p>Wikipedia is edited by volunteer editors around the world. Considering the
large amount of existing content (e.g. over 5M articles in English Wikipedia),
deciding what to edit next can be difficult, both for experienced users that
usually have a huge backlog of articles to prioritize, as well as for newcomers
who that might need guidance in selecting the next article to contribute.
Therefore, helping editors to find relevant articles should improve their
performance and help in the retention of new editors. In this paper, we address
the problem of recommending relevant articles to editors. To do this, we
develop a scalable system on top of Graph Convolutional Networks and Doc2Vec,
learning how to represent Wikipedia articles and deliver personalized
recommendations for editors. We test our model on editors' histories,
predicting their most recent edits based on their prior edits. We outperform
competitive implicit-feedback collaborative-filtering methods such as WMRF
based on ALS, as well as a traditional IR-method such as content-based
filtering based on BM25. All of the data used on this paper is publicly
available, including graph embeddings for Wikipedia articles, and we release
our code to support replication of our experiments. Moreover, we contribute
with a scalable implementation of a state-of-art graph embedding algorithm as
current ones cannot efficiently handle the sheer size of the Wikipedia graph.
</p>
<a href="http://arxiv.org/abs/2009.11771">arXiv:2009.11771</a> [<a href="http://arxiv.org/pdf/2009.11771">pdf</a>]

<h2>Neural Identification for Control. (arXiv:2009.11782v1 [eess.SY])</h2>
<h3>Priyabrata Saha, Saibal Mukhopadhyay</h3>
<p>We present a new method for learning control law that stabilizes an unknown
nonlinear dynamical system at an equilibrium point. We formulate a system
identification task in a self-supervised learning setting that jointly learns a
controller and corresponding stable closed-loop dynamics hypothesis. The
open-loop input-output behavior of the underlying dynamical system is used as
the supervising signal to train the neural network-based system model and
controller. The method relies on the Lyapunov stability theory to generate a
stable closed-loop dynamics hypothesis and corresponding control law. We
demonstrate our method on various nonlinear control problems such as n-Link
pendulum balancing, pendulum on cart balancing, and wheeled vehicle path
following.
</p>
<a href="http://arxiv.org/abs/2009.11782">arXiv:2009.11782</a> [<a href="http://arxiv.org/pdf/2009.11782">pdf</a>]

<h2>Adapting BERT for Word Sense Disambiguation with Gloss Selection Objective and Example Sentences. (arXiv:2009.11795v1 [cs.CL])</h2>
<h3>Boon Peng Yap, Andrew Koh Jin Jie, Eng Siong Chng</h3>
<p>Domain adaptation or transfer learning using pre-trained language models such
as BERT has proven to be an effective approach for many natural language
processing tasks. In this work, we propose to formulate word sense
disambiguation as a relevance ranking task, and fine-tune BERT on sequence-pair
ranking task to select the most probable sense definition given a context
sentence and a list of candidate sense definitions. We also introduce a data
augmentation technique for WSD using existing example sentences from WordNet.
Using the proposed training objective and data augmentation technique, our
models are able to achieve state-of-the-art results on the English all-words
benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2009.11795">arXiv:2009.11795</a> [<a href="http://arxiv.org/pdf/2009.11795">pdf</a>]

<h2>Motion Planning by Reinforcement Learning for an Unmanned Aerial Vehicle in Virtual Open Space with Static Obstacles. (arXiv:2009.11799v1 [cs.RO])</h2>
<h3>Sanghyun Kim, Jongmin Park, Jae-Kwan Yun, Jiwon Seo</h3>
<p>In this study, we applied reinforcement learning based on the proximal policy
optimization algorithm to perform motion planning for an unmanned aerial
vehicle (UAV) in an open space with static obstacles. The application of
reinforcement learning through a real UAV has several limitations such as time
and cost; thus, we used the Gazebo simulator to train a virtual quadrotor UAV
in a virtual environment. As the reinforcement learning progressed, the mean
reward and goal rate of the model were increased. Furthermore, the test of the
trained model shows that the UAV reaches the goal with an 81% goal rate using
the simple reward function suggested in this work.
</p>
<a href="http://arxiv.org/abs/2009.11799">arXiv:2009.11799</a> [<a href="http://arxiv.org/pdf/2009.11799">pdf</a>]

<h2>Investigating Applications on the A64FX. (arXiv:2009.11806v1 [cs.PF])</h2>
<h3>Adrian Jackson, Mich&#xe8;le Weiland, Nick Brown, Andrew Turner, Mark Parsons</h3>
<p>The A64FX processor from Fujitsu, being designed for computational simulation
and machine learning applications, has the potential for unprecedented
performance in HPC systems. In this paper, we evaluate the A64FX by
benchmarking against a range of production HPC platforms that cover a number of
processor technologies. We investigate the performance of complex scientific
applications across multiple nodes, as well as single node and mini-kernel
benchmarks. This paper finds that the performance of the A64FX processor across
our chosen benchmarks often significantly exceeds other platforms, even without
specific application optimisations for the processor instruction set or
hardware. However, this is not true for all the benchmarks we have undertaken.
Furthermore, the specific configuration of applications can have an impact on
the runtime and performance experienced.
</p>
<a href="http://arxiv.org/abs/2009.11806">arXiv:2009.11806</a> [<a href="http://arxiv.org/pdf/2009.11806">pdf</a>]

<h2>Identifying noisy labels with a transductive semi-supervised leave-one-out filter. (arXiv:2009.11811v1 [cs.LG])</h2>
<h3>Bruno Klaus de Aquino Afonso, Lilian Berton</h3>
<p>Obtaining data with meaningful labels is often costly and error-prone. In
this situation, semi-supervised learning (SSL) approaches are interesting, as
they leverage assumptions about the unlabeled data to make up for the limited
amount of labels. However, in real-world situations, we cannot assume that the
labeling process is infallible, and the accuracy of many SSL classifiers
decreases significantly in the presence of label noise. In this work, we
introduce the LGC_LVOF, a leave-one-out filtering approach based on the Local
and Global Consistency (LGC) algorithm. Our method aims to detect and remove
wrong labels, and thus can be used as a preprocessing step to any SSL
classifier. Given the propagation matrix, detecting noisy labels takes O(cl)
per step, with c the number of classes and l the number of labels. Moreover,
one does not need to compute the whole propagation matrix, but only an $l$ by
$l$ submatrix corresponding to interactions between labeled instances. As a
result, our approach is best suited to datasets with a large amount of
unlabeled data but not many labels. Results are provided for a number of
datasets, including MNIST and ISOLET. LGCLVOF appears to be equally or more
precise than the adapted gradient-based filter. We show that the best-case
accuracy of the embedding of LGCLVOF into LGC yields performance comparable to
the best-case of $\ell_1$-based classifiers designed to be robust to label
noise. We provide a heuristic to choose the number of removed instances.
</p>
<a href="http://arxiv.org/abs/2009.11811">arXiv:2009.11811</a> [<a href="http://arxiv.org/pdf/2009.11811">pdf</a>]

<h2>Attribute Propagation Network for Graph Zero-shot Learning. (arXiv:2009.11816v1 [cs.CV])</h2>
<h3>Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang</h3>
<p>The goal of zero-shot learning (ZSL) is to train a model to classify samples
of classes that were not seen during training. To address this challenging
task, most ZSL methods relate unseen test classes to seen(training) classes via
a pre-defined set of attributes that can describe all classes in the same
semantic space, so the knowledge learned on the training classes can be adapted
to unseen classes. In this paper, we aim to optimize the attribute space for
ZSL by training a propagation mechanism to refine the semantic attributes of
each class based on its neighbors and related classes on a graph of classes. We
show that the propagated attributes can produce classifiers for zero-shot
classes with significantly improved performance in different ZSL settings. The
graph of classes is usually free or very cheap to acquire such as WordNet or
ImageNet classes. When the graph is not provided, given pre-defined semantic
embeddings of the classes, we can learn a mechanism to generate the graph in an
end-to-end manner along with the propagation mechanism. However, this
graph-aided technique has not been well-explored in the literature. In this
paper, we introduce the attribute propagation network (APNet), which is
composed of 1) a graph propagation model generating attribute vector for each
class and 2) a parameterized nearest neighbor (NN) classifier categorizing an
image to the class with the nearest attribute vector to the image's embedding.
For better generalization over unseen classes, different from previous methods,
we adopt a meta-learning strategy to train the propagation mechanism and the
similarity metric for the NN classifier on multiple sub-graphs, each associated
with a classification task over a subset of training classes. In experiments
with two zero-shot learning settings and five benchmark datasets, APNet
achieves either compelling performance or new state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2009.11816">arXiv:2009.11816</a> [<a href="http://arxiv.org/pdf/2009.11816">pdf</a>]

<h2>Semi-supervised sequence classification through change point detection. (arXiv:2009.11829v1 [cs.LG])</h2>
<h3>Nauman Ahad, Mark A. Davenport</h3>
<p>Sequential sensor data is generated in a wide variety of practical
applications. A fundamental challenge involves learning effective classifiers
for such sequential data. While deep learning has led to impressive performance
gains in recent years in domains such as speech, this has relied on the
availability of large datasets of sequences with high-quality labels. In many
applications, however, the associated class labels are often extremely limited,
with precise labelling/segmentation being too expensive to perform at a high
volume. However, large amounts of unlabeled data may still be available. In
this paper we propose a novel framework for semi-supervised learning in such
contexts. In an unsupervised manner, change point detection methods can be used
to identify points within a sequence corresponding to likely class changes. We
show that change points provide examples of similar/dissimilar pairs of
sequences which, when coupled with labeled, can be used in a semi-supervised
classification setting. Leveraging the change points and labeled data, we form
examples of similar/dissimilar sequences to train a neural network to learn
improved representations for classification. We provide extensive synthetic
simulations and show that the learned representations are superior to those
learned through an autoencoder and obtain improved results on both simulated
and real-world human activity recognition datasets.
</p>
<a href="http://arxiv.org/abs/2009.11829">arXiv:2009.11829</a> [<a href="http://arxiv.org/pdf/2009.11829">pdf</a>]

<h2>Game theory to enhance stock management of personal protective equipment (PPE) supply during the COVID-19 outbreak. (arXiv:2009.11838v1 [cs.CY])</h2>
<h3>Khaled Abedrabboh, Matthias Pilz, Zaid Al-Fagih, Othman S. Al-Fagih, Jean-Christophe Nebel, Luluwah Al-Fagih</h3>
<p>Since the outbreak of the COVID-19 pandemic, many healthcare facilities have
suffered from shortages in medical resources, particularly in Personal
Protective Equipment (PPE). In this paper, we propose a game-theoretic approach
to schedule PPE orders among healthcare facilities. In this PPE game, each
independent healthcare facility optimises its own storage utilisation in order
to keep its PPE cost at a minimum. Such a model can reduce peak demand
considerably when applied to a fluctuating PPE consumption profile. Experiments
conducted for NHS England regions using actual data confirm that the challenge
of securing PPE supply during disasters such as COVID-19 can be eased if proper
stock management procedures are adopted. These procedures can include early
stockpiling, increasing storage capacities and implementing measures that can
prolong the time period between successive infection waves, such as social
distancing measures. Simulation results suggest that the provision of PPE
dedicated storage space can be a viable solution to avoid straining PPE supply
chains in case a second wave of COVID-19 infections occurs.
</p>
<a href="http://arxiv.org/abs/2009.11838">arXiv:2009.11838</a> [<a href="http://arxiv.org/pdf/2009.11838">pdf</a>]

<h2>A Gradient Flow Framework For Analyzing Network Pruning. (arXiv:2009.11839v1 [cs.LG])</h2>
<h3>Ekdeep Singh Lubana, Robert P. Dick</h3>
<p>Recent network pruning methods focus on pruning models early-on in training.
To estimate the impact of removing a parameter, these methods use importance
measures that were originally designed for pruning trained models. Despite
lacking justification for their use early-on in training, models pruned using
such measures result in surprisingly minimal accuracy loss. To better explain
this behavior, we develop a general, gradient-flow based framework that relates
state-of-the-art importance measures through an order of time-derivative of the
norm of model parameters. We use this framework to determine the relationship
between pruning measures and evolution of model parameters, establishing
several findings related to pruning models early-on in training: (i)
magnitude-based pruning removes parameters that contribute least to reduction
in loss, resulting in models that converge faster than magnitude-agnostic
methods; (ii) loss-preservation based pruning preserves first-order model
evolution dynamics and is well-motivated for pruning minimally trained models;
and (iii) gradient-norm based pruning affects second-order model evolution
dynamics, and increasing gradient norm via pruning can produce poorly
performing models. We validate our claims on several VGG-13, MobileNet-V1, and
ResNet-56 models trained on CIFAR-10 and CIFAR-100. Code available at
https://github.com/EkdeepSLubana/flowandprune.
</p>
<a href="http://arxiv.org/abs/2009.11839">arXiv:2009.11839</a> [<a href="http://arxiv.org/pdf/2009.11839">pdf</a>]

<h2>ECOVNet: An Ensemble of Deep Convolutional Neural Networks Based on EfficientNet to Detect COVID-19 From Chest X-rays. (arXiv:2009.11850v1 [eess.IV])</h2>
<h3>Nihad Karim Chowdhury, Md. Muhtadir Rahman, Noortaz Rezoana, Muhammad Ashad Kabir</h3>
<p>This paper proposed an ensemble of deep convolutional neural networks (CNN)
based on EfficientNet, named ECOVNet, to detect COVID-19 using a large chest
X-ray data set. At first, the open-access large chest X-ray collection is
augmented, and then ImageNet pre-trained weights for EfficientNet is
transferred with some customized fine-tuning top layers that are trained,
followed by an ensemble of model snapshots to classify chest X-rays
corresponding to COVID-19, normal, and pneumonia. The predictions of the model
snapshots, which are created during a single training, are combined through two
ensemble strategies, i.e., hard ensemble and soft ensemble to ameliorate
classification performance and generalization in the related task of
classifying chest X-rays.
</p>
<a href="http://arxiv.org/abs/2009.11850">arXiv:2009.11850</a> [<a href="http://arxiv.org/pdf/2009.11850">pdf</a>]

<h2>Learning Equality Constraints for Motion Planning on Manifolds. (arXiv:2009.11852v1 [cs.RO])</h2>
<h3>Giovanni Sutanto, Isabel M. Rayas Fern&#xe1;ndez, Peter Englert, Ragesh K. Ramachandran, Gaurav S. Sukhatme</h3>
<p>Constrained robot motion planning is a widely used technique to solve complex
robot tasks. We consider the problem of learning representations of constraints
from demonstrations with a deep neural network, which we call Equality
Constraint Manifold Neural Network (ECoMaNN). The key idea is to learn a
level-set function of the constraint suitable for integration into a
constrained sampling-based motion planner. Learning proceeds by aligning
subspaces in the network with subspaces of the data. We combine both learned
constraints and analytically described constraints into the planner and use a
projection-based strategy to find valid points. We evaluate ECoMaNN on its
representation capabilities of constraint manifolds, the impact of its
individual loss terms, and the motions produced when incorporated into a
planner.
</p>
<a href="http://arxiv.org/abs/2009.11852">arXiv:2009.11852</a> [<a href="http://arxiv.org/pdf/2009.11852">pdf</a>]

<h2>How Many Factors Influence Minima in SGD?. (arXiv:2009.11858v1 [cs.LG])</h2>
<h3>Victor Luo, Yazhen Wang</h3>
<p>Stochastic gradient descent (SGD) is often applied to train Deep Neural
Networks (DNNs), and research efforts have been devoted to investigate the
convergent dynamics of SGD and minima found by SGD. The influencing factors
identified in the literature include learning rate, batch size, Hessian, and
gradient covariance, and stochastic differential equations are used to model
SGD and establish the relationships among these factors for characterizing
minima found by SGD. It has been found that the ratio of batch size to learning
rate is a main factor in highlighting the underlying SGD dynamics; however, the
influence of other important factors such as the Hessian and gradient
covariance is not entirely agreed upon. This paper describes the factors and
relationships in the recent literature and presents numerical findings on the
relationships. In particular, it confirms the four-factor and general
relationship results obtained in Wang (2019), while the three-factor and
associated relationship results found in Jastrz\c{e}bski et al. (2018) may not
hold beyond the considered special case.
</p>
<a href="http://arxiv.org/abs/2009.11858">arXiv:2009.11858</a> [<a href="http://arxiv.org/pdf/2009.11858">pdf</a>]

<h2>Multi Sensor-based Implicit User Identification. (arXiv:1706.01739v3 [cs.CR] UPDATED)</h2>
<h3>Muhammad Ahmad, Ali Kashif Bashir, Adil Mehmood Khan, Manuel Mazzara, Salvatore Distefano, Shahzad Sarfraz</h3>
<p>Smartphones have ubiquitously integrated into our home and work environments,
however, users normally rely on explicit but inefficient identification
processes in a controlled environment. Therefore, when a device is stolen, a
thief can have access to the owner's personal information and services against
the stored passwords. As a result of this potential scenario, this work
proposes an automatic legitimate user identification system based on gait
biometrics extracted from user walking patterns captured by a smartphone. A set
of preprocessing schemes is applied to calibrate noisy and invalid samples and
augment the gait-induced time and frequency domain features, then further
optimized using a non-linear unsupervised feature selection method. The
selected features create an underlying gait biometric representation able to
discriminate among individuals and identify them uniquely. Different
classifiers (i.e. Support Vector Machine (SVM), K-Nearest Neighbors (KNN),
Bagging, and Extreme Learning Machine (ELM)) are adopted to achieve accurate
legitimate user identification. Extensive experiments on a group of $16$
individuals in an indoor environment show the effectiveness of the proposed
solution: with $5$ to $70$ samples per window, KNN and bagging classifiers
achieve $87-99\%$ accuracy, $82-98\%$ for ELM, and $81-94\%$ for SVM. The
proposed pipeline achieves a $100\%$ true positive and $0\%$ false-negative
rate for almost all classifiers.
</p>
<a href="http://arxiv.org/abs/1706.01739">arXiv:1706.01739</a> [<a href="http://arxiv.org/pdf/1706.01739">pdf</a>]

<h2>Zero-Shot Learning -- A Comprehensive Evaluation of the Good, the Bad and the Ugly. (arXiv:1707.00600v4 [cs.CV] UPDATED)</h2>
<h3>Yongqin Xian, Christoph H. Lampert, Bernt Schiele, Zeynep Akata</h3>
<p>Due to the importance of zero-shot learning, i.e. classifying images where
there is a lack of labeled training data, the number of proposed approaches has
recently increased steadily. We argue that it is time to take a step back and
to analyze the status quo of the area. The purpose of this paper is three-fold.
First, given the fact that there is no agreed upon zero-shot learning
benchmark, we first define a new benchmark by unifying both the evaluation
protocols and data splits of publicly available datasets used for this task.
This is an important contribution as published results are often not comparable
and sometimes even flawed due to, e.g. pre-training on zero-shot test classes.
Moreover, we propose a new zero-shot learning dataset, the Animals with
Attributes 2 (AWA2) dataset which we make publicly available both in terms of
image features and the images themselves. Second, we compare and analyze a
significant number of the state-of-the-art methods in depth, both in the
classic zero-shot setting but also in the more realistic generalized zero-shot
setting. Finally, we discuss in detail the limitations of the current status of
the area which can be taken as a basis for advancing it.
</p>
<a href="http://arxiv.org/abs/1707.00600">arXiv:1707.00600</a> [<a href="http://arxiv.org/pdf/1707.00600">pdf</a>]

<h2>A Comprehensive Analysis of Deep Regression. (arXiv:1803.08450v3 [cs.CV] UPDATED)</h2>
<h3>St&#xe9;phane Lathuili&#xe8;re, Pablo Mesejo, Xavier Alameda-Pineda, Radu Horaud</h3>
<p>Deep learning revolutionized data science, and recently its popularity has
grown exponentially, as did the amount of papers employing deep networks.
Vision tasks, such as human pose estimation, did not escape from this trend.
There is a large number of deep models, where small changes in the network
architecture, or in the data pre-processing, together with the stochastic
nature of the optimization procedures, produce notably different results,
making extremely difficult to sift methods that significantly outperform
others. This situation motivates the current study, in which we perform a
systematic evaluation and statistical analysis of vanilla deep regression, i.e.
convolutional neural networks with a linear regression top layer. This is the
first comprehensive analysis of deep regression techniques. We perform
experiments on four vision problems, and report confidence intervals for the
median performance as well as the statistical significance of the results, if
any. Surprisingly, the variability due to different data pre-processing
procedures generally eclipses the variability due to modifications in the
network architecture. Our results reinforce the hypothesis according to which,
in general, a general-purpose network (e.g. VGG-16 or ResNet-50) adequately
tuned can yield results close to the state-of-the-art without having to resort
to more complex and ad-hoc regression models.
</p>
<a href="http://arxiv.org/abs/1803.08450">arXiv:1803.08450</a> [<a href="http://arxiv.org/pdf/1803.08450">pdf</a>]

<h2>Envy-Free Classification. (arXiv:1809.08700v2 [cs.LG] UPDATED)</h2>
<h3>Maria-Florina Balcan, Travis Dick, Ritesh Noothigattu, Ariel D. Procaccia</h3>
<p>In classic fair division problems such as cake cutting and rent division,
envy-freeness requires that each individual (weakly) prefer his allocation to
anyone else's. On a conceptual level, we argue that envy-freeness also provides
a compelling notion of fairness for classification tasks. Our technical focus
is the generalizability of envy-free classification, i.e., understanding
whether a classifier that is envy free on a sample would be almost envy free
with respect to the underlying distribution with high probability. Our main
result establishes that a small sample is sufficient to achieve such
guarantees, when the classifier in question is a mixture of deterministic
classifiers that belong to a family of low Natarajan dimension.
</p>
<a href="http://arxiv.org/abs/1809.08700">arXiv:1809.08700</a> [<a href="http://arxiv.org/pdf/1809.08700">pdf</a>]

<h2>Euler Transformation of Polyhedral Complexes. (arXiv:1812.02412v2 [cs.CG] UPDATED)</h2>
<h3>Prashant Gupta, Bala Krishnamoorthy</h3>
<p>We propose an Euler transformation that transforms a given $d$-dimensional
cell complex $K$ for $d=2,3$ into a new $d$-complex $\hat{K}$ in which every
vertex is part of a uniform even number of edges. Hence every vertex in the
graph $\hat{G}$ that is the $1$-skeleton of $\hat{K}$ has an even degree, which
makes $\hat{G}$ Eulerian, i.e., it is guaranteed to contain an Eulerian tour.
Meshes whose edges admit Eulerian tours are crucial in coverage problems
arising in several applications including 3D printing and robotics.

For $2$-complexes in $\mathbb{R}^2$ ($d=2$) under mild assumptions (that no
two adjacent edges of a $2$-cell in $K$ are boundary edges), we show that the
Euler transformed $2$-complex $\hat{K}$ has a geometric realization in
$\mathbb{R}^2$, and that each vertex in its $1$-skeleton has degree $4$. We
bound the numbers of vertices, edges, and $2$-cells in $\hat{K}$ as small
scalar multiples of the corresponding numbers in $K$. We prove corresponding
results for $3$-complexes in $\mathbb{R}^3$ under an additional assumption that
the degree of a vertex in each $3$-cell containing it is $3$. In this setting,
every vertex in $\hat{G}$ is shown to have a degree of $6$.

We also present bounds on parameters measuring geometric quality (aspect
ratios, minimum edge length, and maximum angle) of $\hat{K}$ in terms of the
corresponding parameters of $K$ (for $d=2, 3$). Finally, we illustrate a direct
application of the proposed Euler transformation in additive manufacturing.
</p>
<a href="http://arxiv.org/abs/1812.02412">arXiv:1812.02412</a> [<a href="http://arxiv.org/pdf/1812.02412">pdf</a>]

<h2>Orthogonal Statistical Learning. (arXiv:1901.09036v3 [math.ST] UPDATED)</h2>
<h3>Dylan J. Foster, Vasilis Syrgkanis</h3>
<p>We provide non-asymptotic excess risk guarantees for statistical learning in
a setting where the population risk with respect to which we evaluate the
target parameter depends on an unknown nuisance parameter that must be
estimated from data. We analyze a two-stage sample splitting meta-algorithm
that takes as input two arbitrary estimation algorithms: one for the target
parameter and one for the nuisance parameter. We show that if the population
risk satisfies a condition called Neyman orthogonality, the impact of the
nuisance estimation error on the excess risk bound achieved by the
meta-algorithm is of second order. Our theorem is agnostic to the particular
algorithms used for the target and nuisance and only makes an assumption on
their individual performance. This enables the use of a plethora of existing
results from statistical learning and machine learning to give new guarantees
for learning with a nuisance component. Moreover, by focusing on excess risk
rather than parameter estimation, we can give guarantees under weaker
assumptions than in previous works and accommodate settings in which the target
parameter belongs to a complex nonparametric class. We provide conditions on
the metric entropy of the nuisance and target classes such that oracle
rates---rates of the same order as if we knew the nuisance parameter---are
achieved. We also derive new rates for specific estimation algorithms such as
variance-penalized empirical risk minimization, neural network estimation and
sparse high-dimensional linear model estimation. We highlight the applicability
of our results in four settings of central importance: 1) heterogeneous
treatment effect estimation, 2) offline policy optimization, 3) domain
adaptation, and 4) learning with missing data.
</p>
<a href="http://arxiv.org/abs/1901.09036">arXiv:1901.09036</a> [<a href="http://arxiv.org/pdf/1901.09036">pdf</a>]

<h2>Neural-encoding Human Experts' Domain Knowledge to Warm Start Reinforcement Learning. (arXiv:1902.06007v4 [cs.LG] UPDATED)</h2>
<h3>Andrew Silva, Matthew Gombolay</h3>
<p>Deep reinforcement learning has been successful in a variety of tasks, such
as game playing and robotic manipulation. However, attempting to learn
\textit{tabula rasa} disregards the logical structure of many domains as well
as the wealth of readily available knowledge from domain experts that could
help "warm start" the learning process. We present a novel reinforcement
learning technique that allows for intelligent initialization of a neural
network weights and architecture. Our approach permits the encoding domain
knowledge directly into a neural decision tree, and improves upon that
knowledge with policy gradient updates. We empirically validate our approach on
two OpenAI Gym tasks and two modified StarCraft 2 tasks, showing that our novel
architecture outperforms multilayer-perceptron and recurrent architectures. Our
knowledge-based framework finds superior policies compared to imitation
learning-based and prior knowledge-based approaches. Importantly, we
demonstrate that our approach can be used by untrained humans to initially
provide &gt;80% increase in expected reward relative to baselines prior to
training (p &lt; 0.001), which results in a &gt;60% increase in expected reward after
policy optimization (p = 0.011).
</p>
<a href="http://arxiv.org/abs/1902.06007">arXiv:1902.06007</a> [<a href="http://arxiv.org/pdf/1902.06007">pdf</a>]

<h2>Tag2Vec: Learning Tag Representations in Tag Networks. (arXiv:1905.03041v2 [cs.SI] UPDATED)</h2>
<h3>Junshan Wang, Zhicong Lu, Guojie Song, Yue Fan, Lun Du, Wei Lin</h3>
<p>Network embedding is a method to learn low-dimensional representation vectors
for nodes in complex networks. In real networks, nodes may have multiple tags
but existing methods ignore the abundant semantic and hierarchical information
of tags. This information is useful to many network applications and usually
very stable. In this paper, we propose a tag representation learning model,
Tag2Vec, which mixes nodes and tags into a hybrid network. Firstly, for tag
networks, we define semantic distance as the proximity between tags and design
a novel strategy, parameterized random walk, to generate context with semantic
and hierarchical information of tags adaptively. Then, we propose hyperbolic
Skip-gram model to express the complex hierarchical structure better with lower
output dimensions. We evaluate our model on the NBER U.S. patent dataset and
WordNet dataset. The results show that our model can learn tag representations
with rich semantic information and it outperforms other baselines.
</p>
<a href="http://arxiv.org/abs/1905.03041">arXiv:1905.03041</a> [<a href="http://arxiv.org/pdf/1905.03041">pdf</a>]

<h2>An Attention-Guided Deep Regression Model for Landmark Detection in Cephalograms. (arXiv:1906.07549v2 [eess.IV] UPDATED)</h2>
<h3>Zhusi Zhong, Jie Li, Zhenxi Zhang, Zhicheng Jiao, Xinbo Gao</h3>
<p>Cephalometric tracing method is usually used in orthodontic diagnosis and
treat-ment planning. In this paper, we propose a deep learning based framework
to au-tomatically detect anatomical landmarks in cephalometric X-ray images. We
train the deep encoder-decoder for landmark detection, and combine global
landmark configuration with local high-resolution feature responses. The
proposed frame-work is based on 2-stage u-net, regressing the multi-channel
heatmaps for land-mark detection. In this framework, we embed attention
mechanism with global stage heatmaps, guiding the local stage inferring, to
regress the local heatmap patches in a high resolution. Besides, the Expansive
Exploration strategy im-proves robustness while inferring, expanding the
searching scope without in-creasing model complexity. We have evaluated our
framework in the most wide-ly-used public dataset of landmark detection in
cephalometric X-ray images. With less computation and manually tuning, our
framework achieves state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/1906.07549">arXiv:1906.07549</a> [<a href="http://arxiv.org/pdf/1906.07549">pdf</a>]

<h2>Learning in Volatile Environments with the Bayes Factor Surprise. (arXiv:1907.02936v3 [stat.ML] UPDATED)</h2>
<h3>Vasiliki Liakoni, Alireza Modirshanechi, Wulfram Gerstner, Johanni Brea</h3>
<p>Surprise-based learning allows agents to rapidly adapt to non-stationary
stochastic environments characterized by sudden changes. We show that exact
Bayesian inference in a hierarchical model gives rise to a surprise-modulated
trade-off between forgetting old observations and integrating them with the new
ones. The modulation depends on a probability ratio, which we call "Bayes
Factor Surprise", that tests the prior belief against the current belief. We
demonstrate that in several existing approximate algorithms the Bayes Factor
Surprise modulates the rate of adaptation to new observations. We derive three
novel surprised-based algorithms, one in the family of particle filters, one in
the family of variational learning, and the other in the family of message
passing, that have constant scaling in observation sequence length and
particularly simple update dynamics for any distribution in the exponential
family. Empirical results show that these surprise-based algorithms estimate
parameters better than alternative approximate approaches and reach levels of
performance comparable to computationally more expensive algorithms. The Bayes
Factor Surprise is related to but different from Shannon Surprise. In two
hypothetical experiments, we make testable predictions for physiological
indicators that dissociate the Bayes Factor Surprise from Shannon Surprise. The
theoretical insight of casting various approaches as surprise-based learning,
as well as the proposed online algorithms, may be applied to the analysis of
animal and human behavior, and to reinforcement learning in non-stationary
environments.
</p>
<a href="http://arxiv.org/abs/1907.02936">arXiv:1907.02936</a> [<a href="http://arxiv.org/pdf/1907.02936">pdf</a>]

<h2>On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift. (arXiv:1908.00261v4 [cs.LG] UPDATED)</h2>
<h3>Alekh Agarwal, Sham M. Kakade, Jason D. Lee, Gaurav Mahajan</h3>
<p>Policy gradient methods are among the most effective methods in challenging
reinforcement learning problems with large state and/or action spaces. However,
little is known about even their most basic theoretical convergence properties,
including: if and how fast they converge to a globally optimal solution or how
they cope with approximation error due to using a restricted class of
parametric policies. This work provides provable characterizations of the
computational, approximation, and sample size properties of policy gradient
methods in the context of discounted Markov Decision Processes (MDPs). We focus
on both: "tabular" policy parameterizations, where the optimal policy is
contained in the class and where we show global convergence to the optimal
policy; and parametric policy classes (considering both log-linear and neural
policy classes), which may not contain the optimal policy and where we provide
agnostic learning results. One central contribution of this work is in
providing approximation guarantees that are average case -- which avoid
explicit worst-case dependencies on the size of state space -- by making a
formal connection to supervised learning under distribution shift. This
characterization shows an important interplay between estimation error,
approximation error, and exploration (as characterized through a precisely
defined condition number).
</p>
<a href="http://arxiv.org/abs/1908.00261">arXiv:1908.00261</a> [<a href="http://arxiv.org/pdf/1908.00261">pdf</a>]

<h2>Deep neural network solution of the electronic Schr\"odinger equation. (arXiv:1909.08423v5 [physics.comp-ph] UPDATED)</h2>
<h3>Jan Hermann, Zeno Sch&#xe4;tzle, Frank No&#xe9;</h3>
<p>[New and updated results were published in Nature Chemistry,
doi:10.1038/s41557-020-0544-y.] The electronic Schr\"odinger equation describes
fundamental properties of molecules and materials, but can only be solved
analytically for the hydrogen atom. The numerically exact full
configuration-interaction method is exponentially expensive in the number of
electrons. Quantum Monte Carlo is a possible way out: it scales well to large
molecules, can be parallelized, and its accuracy has, as yet, only been limited
by the flexibility of the used wave function ansatz. Here we propose PauliNet,
a deep-learning wave function ansatz that achieves nearly exact solutions of
the electronic Schr\"odinger equation. PauliNet has a multireference
Hartree-Fock solution built in as a baseline, incorporates the physics of valid
wave functions, and is trained using variational quantum Monte Carlo (VMC).
PauliNet outperforms comparable state-of-the-art VMC ansatzes for atoms,
diatomic molecules and a strongly-correlated hydrogen chain by a margin and is
yet computationally efficient. We anticipate that thanks to the favourable
scaling with system size, this method may become a new leading method for
highly accurate electronic-strucutre calculations on medium-sized molecular
systems.
</p>
<a href="http://arxiv.org/abs/1909.08423">arXiv:1909.08423</a> [<a href="http://arxiv.org/pdf/1909.08423">pdf</a>]

<h2>Benchmarking Tropical Cyclone Rapid Intensification with Satellite Images and Attention-based Deep Models. (arXiv:1909.11616v2 [cs.LG] UPDATED)</h2>
<h3>Ching-Yuan Bai, Buo-Fu Chen, Hsuan-Tien Lin</h3>
<p>Rapid intensification (RI) of tropical cyclones often causes major
destruction to human civilization due to short response time. It is an
important yet challenging task to accurately predict this kind of extreme
weather event in advance. Traditionally, meteorologists tackle the task with
human-driven feature extraction and predictor correction procedures.
Nevertheless, these procedures do not leverage the power of modern machine
learning models and abundant sensor data, such as satellite images. In
addition, the human-driven nature of such an approach makes it difficult to
reproduce and benchmark prediction models. In this study, we build a benchmark
for RI prediction using only satellite images, which are underutilized in
traditional techniques. The benchmark follows conventional data science
practices, making it easier for data scientists to contribute to RI prediction.
We demonstrate the usefulness of the benchmark by designing a domain-inspired
spatiotemporal deep learning model. The results showcase the promising
performance of deep learning in solving complex meteorological problems such as
RI prediction.
</p>
<a href="http://arxiv.org/abs/1909.11616">arXiv:1909.11616</a> [<a href="http://arxiv.org/pdf/1909.11616">pdf</a>]

<h2>On the Detection of Digital Face Manipulation. (arXiv:1910.01717v4 [cs.CV] UPDATED)</h2>
<h3>Hao Dang, Feng Liu, Joel Stehouwer, Xiaoming Liu, Anil Jain</h3>
<p>Detecting manipulated facial images and videos is an increasingly important
topic in digital media forensics. As advanced face synthesis and manipulation
methods are made available, new types of fake face representations are being
created which have raised significant concerns for their use in social media.
Hence, it is crucial to detect manipulated face images and localize manipulated
regions. Instead of simply using multi-task learning to simultaneously detect
manipulated images and predict the manipulated mask (regions), we propose to
utilize an attention mechanism to process and improve the feature maps for the
classification task. The learned attention maps highlight the informative
regions to further improve the binary classification (genuine face v. fake
face), and also visualize the manipulated regions. To enable our study of
manipulated face detection and localization, we collect a large-scale database
that contains numerous types of facial forgeries. With this dataset, we perform
a thorough analysis of data-driven fake face detection. We show that the use of
an attention mechanism improves facial forgery detection and manipulated region
localization.
</p>
<a href="http://arxiv.org/abs/1910.01717">arXiv:1910.01717</a> [<a href="http://arxiv.org/pdf/1910.01717">pdf</a>]

<h2>SentiLARE: Sentiment-Aware Language Representation Learning with Linguistic Knowledge. (arXiv:1911.02493v3 [cs.CL] UPDATED)</h2>
<h3>Pei Ke, Haozhe Ji, Siyang Liu, Xiaoyan Zhu, Minlie Huang</h3>
<p>Most of the existing pre-trained language representation models neglect to
consider the linguistic knowledge of texts, which can promote language
understanding in NLP tasks. To benefit the downstream tasks in sentiment
analysis, we propose a novel language representation model called SentiLARE,
which introduces word-level linguistic knowledge including part-of-speech tag
and sentiment polarity (inferred from SentiWordNet) into pre-trained models. We
first propose a context-aware sentiment attention mechanism to acquire the
sentiment polarity of each word with its part-of-speech tag by querying
SentiWordNet. Then, we devise a new pre-training task called label-aware masked
language model to construct knowledge-aware language representation.
Experiments show that SentiLARE obtains new state-of-the-art performance on a
variety of sentiment analysis tasks.
</p>
<a href="http://arxiv.org/abs/1911.02493">arXiv:1911.02493</a> [<a href="http://arxiv.org/pdf/1911.02493">pdf</a>]

<h2>Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for Non Convex Optimization. (arXiv:1911.07596v2 [math.OC] UPDATED)</h2>
<h3>Anas Barakat, Pascal Bianchi</h3>
<p>Although ADAM is a very popular algorithm for optimizing the weights of
neural networks, it has been recently shown that it can diverge even in simple
convex optimization examples. Several variants of ADAM have been proposed to
circumvent this convergence issue. In this work, we study the ADAM algorithm
for smooth nonconvex optimization under a boundedness assumption on the
adaptive learning rate. The bound on the adaptive step size depends on the
Lipschitz constant of the gradient of the objective function and provides safe
theoretical adaptive step sizes. Under this boundedness assumption, we show a
novel first order convergence rate result in both deterministic and stochastic
contexts. Furthermore, we establish convergence rates of the function value
sequence using the Kurdyka-Lojasiewicz property.
</p>
<a href="http://arxiv.org/abs/1911.07596">arXiv:1911.07596</a> [<a href="http://arxiv.org/pdf/1911.07596">pdf</a>]

<h2>Identifying nearby sources of ultra-high-energy cosmic rays with deep learning. (arXiv:1912.00625v3 [astro-ph.HE] UPDATED)</h2>
<h3>Oleg Kalashev, Maxim Pshirkov, Mikhail Zotov</h3>
<p>We present a method to analyse arrival directions of ultra-high-energy cosmic
rays (UHECRs) using a classifier defined by a deep convolutional neural network
trained on a HEALPix grid. To illustrate a high effectiveness of the method, we
employ it to estimate prospects of detecting a large-scale anisotropy of UHECRs
induced by a nearby source with an (orbital) detector having a uniform exposure
of the celestial sphere and compare the results with our earlier calculations
based on the angular power spectrum. A minimal model for extragalactic cosmic
rays and neutrinos by Kachelrie{\ss}, Kalashev, Ostapchenko and Semikoz (2017)
is assumed for definiteness and nearby active galactic nuclei Centaurus A, M82,
NGC 253, M87 and Fornax A are considered as possible sources of UHECRs. We
demonstrate that the proposed method drastically improves sensitivity of an
experiment by decreasing the minimal required amount of detected UHECRs or the
minimal detectable fraction of from-source events several times compared to the
approach based on the angular power spectrum. We also test robustness of the
neural networks against different models of the large-scale Galactic magnetic
fields and variations of the mass composition of UHECRs, and consider
situations when there are two nearby sources or the dominating source is not
known a~priori. In all cases, the neural networks demonstrate good performance
unless the test models strongly deviate from those used for training. The
method can be readily applied to the analysis of data of the Telescope Array,
the Pierre Auger Observatory and other cosmic ray experiments.
</p>
<a href="http://arxiv.org/abs/1912.00625">arXiv:1912.00625</a> [<a href="http://arxiv.org/pdf/1912.00625">pdf</a>]

<h2>Are cookie banners indeed compliant with the law? Deciphering EU legal requirements on consent and technical means to verify compliance of cookie banners. (arXiv:1912.07144v2 [cs.CR] UPDATED)</h2>
<h3>Cristiana Santos, Nataliia Bielova, C&#xe9;lestin Matte</h3>
<p>In this work, we analyze the legal requirements on how cookie banners are
supposed to be implemented to be fully compliant with the e-Privacy Directive
and the General Data Protection Regulation. Our contribution resides in the
definition of seventeen operational and fine-grained requirements on cookie
banner design that are legally compliant, and moreover, we define whether and
when the verification of compliance of each requirement is technically
feasible. The definition of requirements emerges from a joint interdisciplinary
analysis composed of lawyers and computer scientists in the domain of web
tracking technologies. As such, while some requirements are provided by
explicitly codified legal sources, others result from the domain-expertise of
computer scientists. In our work, we match each requirement against existing
cookie banners design of websites. For each requirement, we exemplify with
compliant and non-compliant cookie banners. As an outcome of a technical
assessment, we verify per requirement if technical (with computer science
tools) or manual (with any human operator) verification is needed to assess
compliance of consent and we also show which requirements are impossible to
verify with certainty in the current architecture of the Web. For example, we
explain how the requirement for revocable consent could be implemented in
practice: when consent is revoked, the publisher should delete the consent
cookie and communicate the withdrawal to all third parties who have previously
received consent. With this approach we aim to support practically-minded
parties (compliance officers, regulators, researchers, and computer scientists)
to assess compliance and detect violations in cookie banner design and
implementation, specially under the current revision of the European Union
e-Privacy framework.
</p>
<a href="http://arxiv.org/abs/1912.07144">arXiv:1912.07144</a> [<a href="http://arxiv.org/pdf/1912.07144">pdf</a>]

<h2>Learning to Impute: A General Framework for Semi-supervised Learning. (arXiv:1912.10364v3 [cs.LG] UPDATED)</h2>
<h3>Wei-Hong Li, Chuan-Sheng Foo, Hakan Bilen</h3>
<p>Recent semi-supervised learning methods have shown to achieve comparable
results to their supervised counterparts while using only a small portion of
labels in image classification tasks thanks to their regularization strategies.
In this paper, we take a more direct approach for semi-supervised learning and
propose learning to impute the labels of unlabeled samples such that a network
achieves better generalization when it is trained on these labels. We pose the
problem in a learning-to-learn formulation which can easily be incorporated to
the state-of-the-art semi-supervised techniques and boost their performance
especially when the labels are limited. We demonstrate that our method is
applicable to both classification and regression problems including image
classification and facial landmark detection tasks.
</p>
<a href="http://arxiv.org/abs/1912.10364">arXiv:1912.10364</a> [<a href="http://arxiv.org/pdf/1912.10364">pdf</a>]

<h2>Co-VeGAN: Complex-Valued Generative Adversarial Network for Compressive Sensing MR Image Reconstruction. (arXiv:2002.10523v3 [eess.IV] UPDATED)</h2>
<h3>Bhavya Vasudeva, Puneesh Deora, Saumik Bhattacharya, Pyari Mohan Pradhan</h3>
<p>Compressive sensing (CS) is widely used to reduce the acquisition time of
magnetic resonance imaging (MRI). Although state-of-the-art deep learning based
methods have been able to obtain fast, high-quality reconstruction of CS-MR
images, their main drawback is that they treat complex-valued MRI data as
real-valued entities. Most methods either extract the magnitude from the
complex-valued entities or concatenate them as two real-valued channels. In
both the cases, the phase content, which links the real and imaginary parts of
the complex-valued entities, is discarded. In order to address the fundamental
problem of real-valued deep networks, i.e. their inability to process
complex-valued data, we propose a novel framework based on a complex-valued
generative adversarial network (Co-VeGAN). Our model can process complex-valued
input, which enables it to perform high-quality reconstruction of the CS-MR
images. Further, considering that phase is a crucial component of
complex-valued entities, we propose a novel complex-valued activation function,
which is sensitive to the phase of the input. Extensive evaluation of the
proposed approach on different datasets using various sampling masks
demonstrates that the proposed model significantly outperforms the existing
CS-MRI reconstruction techniques in terms of peak signal-to-noise ratio as well
as structural similarity index. Further, it uses significantly fewer trainable
parameters to do so, as compared to the real-valued deep learning based
methods.
</p>
<a href="http://arxiv.org/abs/2002.10523">arXiv:2002.10523</a> [<a href="http://arxiv.org/pdf/2002.10523">pdf</a>]

<h2>Learning Algebraic Multigrid Using Graph Neural Networks. (arXiv:2003.05744v2 [cs.LG] UPDATED)</h2>
<h3>Ilay Luz, Meirav Galun, Haggai Maron, Ronen Basri, Irad Yavneh</h3>
<p>Efficient numerical solvers for sparse linear systems are crucial in science
and engineering. One of the fastest methods for solving large-scale sparse
linear systems is algebraic multigrid (AMG). The main challenge in the
construction of AMG algorithms is the selection of the prolongation operator --
a problem-dependent sparse matrix which governs the multiscale hierarchy of the
solver and is critical to its efficiency. Over many years, numerous methods
have been developed for this task, and yet there is no known single right
answer except in very special cases. Here we propose a framework for learning
AMG prolongation operators for linear systems with sparse symmetric positive
(semi-) definite matrices. We train a single graph neural network to learn a
mapping from an entire class of such matrices to prolongation operators, using
an efficient unsupervised loss function. Experiments on a broad class of
problems demonstrate improved convergence rates compared to classical AMG,
demonstrating the potential utility of neural networks for developing sparse
system solvers.
</p>
<a href="http://arxiv.org/abs/2003.05744">arXiv:2003.05744</a> [<a href="http://arxiv.org/pdf/2003.05744">pdf</a>]

<h2>J$\hat{\text{A}}$A-Net: Joint Facial Action Unit Detection and Face Alignment via Adaptive Attention. (arXiv:2003.08834v3 [cs.CV] UPDATED)</h2>
<h3>Zhiwen Shao, Zhilei Liu, Jianfei Cai, Lizhuang Ma</h3>
<p>Facial action unit (AU) detection and face alignment are two highly
correlated tasks, since facial landmarks can provide precise AU locations to
facilitate the extraction of meaningful local features for AU detection.
However, most existing AU detection works handle the two tasks independently by
treating face alignment as a preprocessing, and often use landmarks to
predefine a fixed region or attention for each AU. In this paper, we propose a
novel end-to-end deep learning framework for joint AU detection and face
alignment, which has not been explored before. In particular, multi-scale
shared feature is learned firstly, and high-level feature of face alignment is
fed into AU detection. Moreover, to extract precise local features, we propose
an adaptive attention learning module to refine the attention map of each AU
adaptively. Finally, the assembled local features are integrated with face
alignment feature and global feature for AU detection. Extensive experiments
demonstrate that our framework (i) significantly outperforms the
state-of-the-art AU detection methods on the challenging BP4D, DISFA, GFT and
BP4D+ benchmarks, (ii) can adaptively capture the irregular region of each AU,
(iii) achieves competitive performance for face alignment, and (iv) also works
well under partial occlusions and non-frontal poses. The code for our method is
available at https://github.com/ZhiwenShao/PyTorch-JAANet.
</p>
<a href="http://arxiv.org/abs/2003.08834">arXiv:2003.08834</a> [<a href="http://arxiv.org/pdf/2003.08834">pdf</a>]

<h2>Adversarial Augmentation Policy Search for Domain and Cross-Lingual Generalization in Reading Comprehension. (arXiv:2004.06076v3 [cs.CL] UPDATED)</h2>
<h3>Adyasha Maharana, Mohit Bansal</h3>
<p>Reading comprehension models often overfit to nuances of training datasets
and fail at adversarial evaluation. Training with adversarially augmented
dataset improves robustness against those adversarial attacks but hurts
generalization of the models. In this work, we present several effective
adversaries and automated data augmentation policy search methods with the goal
of making reading comprehension models more robust to adversarial evaluation,
but also improving generalization to the source domain as well as new domains
and languages. We first propose three new methods for generating QA
adversaries, that introduce multiple points of confusion within the context,
show dependence on insertion location of the distractor, and reveal the
compounding effect of mixing adversarial strategies with syntactic and semantic
paraphrasing methods. Next, we find that augmenting the training datasets with
uniformly sampled adversaries improves robustness to the adversarial attacks
but leads to decline in performance on the original unaugmented dataset. We
address this issue via RL and more efficient Bayesian policy search methods for
automatically learning the best augmentation policy combinations of the
transformation probability for each adversary in a large search space. Using
these learned policies, we show that adversarial training can lead to
significant improvements in in-domain, out-of-domain, and cross-lingual
(German, Russian, Turkish) generalization.
</p>
<a href="http://arxiv.org/abs/2004.06076">arXiv:2004.06076</a> [<a href="http://arxiv.org/pdf/2004.06076">pdf</a>]

<h2>Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models. (arXiv:2004.14601v2 [cs.CL] UPDATED)</h2>
<h3>Isabel Papadimitriou, Dan Jurafsky</h3>
<p>We propose transfer learning as a method for analyzing the encoding of
grammatical structure in neural language models. We train LSTMs on
non-linguistic data and evaluate their performance on natural language to
assess which kinds of data induce generalizable structural features that LSTMs
can use for natural language. We find that training on non-linguistic data with
latent structure (MIDI music or Java code) improves test performance on natural
language, despite no overlap in surface form or vocabulary. Training on
artificial languages containing recursion (hierarchical structure) also
improves performance on natural language, again with no vocabulary overlap.
Surprisingly, training on artificial languages consisting of sets of separated
pairs of words, but with no recursion, improves performance on natural language
as well as recursive languages do. Experiments on transfer between natural
languages show that zero-shot performance on a test language is highly
correlated with typological syntactic similarity to the training language,
suggesting that representations induced from natural languages correspond to
the cross-linguistic syntactic properties studied in linguistic typology. Our
results provide insights into the ways that neural models represent abstract
syntactic structure, and also about the kind of structural inductive biases
which a learner needs to model language.
</p>
<a href="http://arxiv.org/abs/2004.14601">arXiv:2004.14601</a> [<a href="http://arxiv.org/pdf/2004.14601">pdf</a>]

<h2>From industry-wide parameters to aircraft-centric on-flight inference: improving aeronautics performance prediction with machine learning. (arXiv:2005.05286v2 [stat.AP] UPDATED)</h2>
<h3>Florent Dewez, Benjamin Guedj, Vincent Vandewalle</h3>
<p>Aircraft performance models play a key role in airline operations, especially
in planning a fuel-efficient flight. In practice, manufacturers provide
guidelines which are slightly modified throughout the aircraft life cycle via
the tuning of a single factor, enabling better fuel predictions. However this
has limitations, in particular they do not reflect the evolution of each
feature impacting the aircraft performance. Our goal here is to overcome this
limitation. The key contribution of the present article is to foster the use of
machine learning to leverage the massive amounts of data continuously recorded
during flights performed by an aircraft and provide models reflecting its
actual and individual performance. We illustrate our approach by focusing on
the estimation of the drag and lift coefficients from recorded flight data. As
these coefficients are not directly recorded, we resort to aerodynamics
approximations. As a safety check, we provide bounds to assess the accuracy of
both the aerodynamics approximation and the statistical performance of our
approach. We provide numerical results on a collection of machine learning
algorithms. We report excellent accuracy on real-life data and exhibit
empirical evidence to support our modelling, in coherence with aerodynamics
principles.
</p>
<a href="http://arxiv.org/abs/2005.05286">arXiv:2005.05286</a> [<a href="http://arxiv.org/pdf/2005.05286">pdf</a>]

<h2>Artificial neural networks for neuroscientists: A primer. (arXiv:2006.01001v2 [q-bio.NC] UPDATED)</h2>
<h3>Guangyu Robert Yang, Xiao-Jing Wang</h3>
<p>Artificial neural networks (ANNs) are essential tools in machine learning
that have drawn increasing attention in neuroscience. Besides offering powerful
techniques for data analysis, ANNs provide a new approach for neuroscientists
to build models for complex behaviors, heterogeneous neural activity and
circuit connectivity, as well as to explore optimization in neural systems, in
ways that traditional models are not designed for. In this pedagogical Primer,
we introduce ANNs and demonstrate how they have been fruitfully deployed to
study neuroscientific questions. We first discuss basic concepts and methods of
ANNs. Then, with a focus on bringing this mathematical framework closer to
neurobiology, we detail how to customize the analysis, structure, and learning
of ANNs to better address a wide range of challenges in brain research. To help
the readers garner hands-on experience, this Primer is accompanied with
tutorial-style code in PyTorch and Jupyter Notebook, covering major topics.
</p>
<a href="http://arxiv.org/abs/2006.01001">arXiv:2006.01001</a> [<a href="http://arxiv.org/pdf/2006.01001">pdf</a>]

<h2>EDropout: Energy-Based Dropout and Pruning of Deep Neural Networks. (arXiv:2006.04270v3 [cs.LG] UPDATED)</h2>
<h3>Hojjat Salehinejad, Shahrokh Valaee</h3>
<p>Dropout is a well-known regularization method by sampling a sub-network from
a larger deep neural network and training different sub-networks on different
subsets of the data. Inspired by the dropout concept, we propose EDropout as an
energy-based framework for pruning neural networks in classification tasks. In
this approach, a set of binary pruning state vectors (population) represents a
set of corresponding sub-networks from an arbitrary provided original neural
network. An energy loss function assigns a scalar energy loss value to each
pruning state. The energy-based model stochastically evolves the population to
find states with lower energy loss. The best pruning state is then selected and
applied to the original network. Similar to dropout, the kept weights are
updated using backpropagation in a probabilistic model. The energy-based model
again searches for better pruning states and the cycle continuous. Indeed, this
procedure is in fact switching between the energy model, which manages the
pruning states, and the probabilistic model, which updates the temporarily
unpruned weights, in each iteration. The population can dynamically converge to
a pruning state. This can be interpreted as dropout leading to pruning the
network. From an implementation perspective, EDropout can prune typical neural
networks without modification of the network architecture. We evaluated the
proposed method on different flavours of ResNets, AlexNet, and SqueezeNet on
the Kuzushiji, Fashion, CIFAR-10, CIFAR-100, and Flowers datasets, and compared
the pruning rate and classification performance of the models. On average the
networks trained with \textit{EDropout} achieved a pruning rate of more than
$50\%$ of the trainable parameters with approximately $&lt;5\%$ and $&lt;1\%$ drop of
Top-1 and Top-5 classification accuracy, respectively.
</p>
<a href="http://arxiv.org/abs/2006.04270">arXiv:2006.04270</a> [<a href="http://arxiv.org/pdf/2006.04270">pdf</a>]

<h2>3D Reconstruction of Novel Object Shapes from Single Images. (arXiv:2006.07752v2 [cs.CV] UPDATED)</h2>
<h3>Anh Thai, Stefan Stojanov, Vijay Upadhya, James M. Rehg</h3>
<p>The key challenge in single image 3D shape reconstruction is to ensure that
deep models can generalize to shapes which were not part of the training set.
This is difficult because the algorithm must infer the occluded portion of the
surface by leveraging the shape characteristics of the training data, and can
therefore be vulnerable to overfitting. Such generalization to unseen
categories of objects is a function of architecture design and training
approaches. This paper introduces SDFNet, a novel shape prediction architecture
and training approach which supports effective generalization. We provide an
extensive investigation of the factors which influence generalization accuracy
and its measurement, ranging from the consistent use of 3D shape metrics to the
choice of rendering approach and the large-scale evaluation on unseen shapes
using ShapeNetCore.v2 and ABC. We show that SDFNet provides state-of-the-art
performance on seen and unseen shapes relative to existing baseline methods
GenRe and OccNet. We provide the first large-scale experimental evaluation of
generalization performance. The codebase released with this article will allow
for the consistent evaluation and comparison of methods for single image shape
reconstruction.
</p>
<a href="http://arxiv.org/abs/2006.07752">arXiv:2006.07752</a> [<a href="http://arxiv.org/pdf/2006.07752">pdf</a>]

<h2>Guaranteed Performance Nonlinear Observer for Simultaneous Localization and Mapping. (arXiv:2006.11858v2 [eess.SY] UPDATED)</h2>
<h3>Hashim A. Hashim</h3>
<p>A geometric nonlinear observer algorithm for Simultaneous Localization and
Mapping (SLAM) developed on the Lie group of \mathbb{SLAM}_{n}\left(3\right) is
proposed. The presented novel solution estimates the vehicle's pose (i.e.
attitude and position) with respect to landmarks simultaneously positioning the
reference features in the global frame. The proposed estimator on manifold is
characterized by predefined measures of transient and steady-state performance.
Dynamically reducing boundaries guide the error function of the system to
reduce asymptotically to the origin from its starting position within a large
given set. The proposed observer has the ability to use the available velocity
and feature measurements directly. Also, it compensates for unknown constant
bias attached to velocity measurements. Unit-qauternion of the proposed
observer is presented. Numerical results reveal effectiveness of the proposed
observer. Keywords: Nonlinear filter algorithm, Nonlinear observer for
Simultaneous Localization and Mapping, Nonlinear estimator, nonlinear SLAM
observer on manifold, nonlinear SLAM filter on matrix Lie Group, observer
design, asymptotic stability, systematic convergence, Prescribed performance
function, pose estimation, attitude filter, position filter, feature filter,
landmark filter, gradient based SLAM observer, gradient based observer for
SLAM, adaptive estimate, SLAM observer, observer SLAM framework, equivariant
observer, inertial vision unit, visual, SLAM filter, SE(3), SO(3).
</p>
<a href="http://arxiv.org/abs/2006.11858">arXiv:2006.11858</a> [<a href="http://arxiv.org/pdf/2006.11858">pdf</a>]

<h2>Fanoos: Multi-Resolution, Multi-Strength, Interactive Explanations for Learned Systems. (arXiv:2006.12453v2 [cs.AI] UPDATED)</h2>
<h3>David Bayani (1), Stefan Mitsch (1) ((1) Carnegie Mellon University)</h3>
<p>Machine learning becomes increasingly important to tune or even synthesize
the behavior of safety-critical components in highly non-trivial environments,
where the inability to understand learned components in general, and neural
nets in particular, poses serious obstacles to their adoption. Explainability
and interpretability methods for learned systems have gained considerable
academic attention, but the focus of current approaches on only one aspect of
explanation, at a fixed level of abstraction, and limited if any formal
guarantees, prevents those explanations from being digestible by the relevant
stakeholders (e.g., end users, certification authorities, engineers) with their
diverse backgrounds and situation-specific needs. We introduce Fanoos, a
flexible framework for combining formal verification techniques, heuristic
search, and user interaction to explore explanations at the desired level of
granularity and fidelity. We demonstrate the ability of Fanoos to produce and
adjust the abstractness of explanations in response to user requests on a
learned controller for an inverted double pendulum and on a learned CPU usage
model.
</p>
<a href="http://arxiv.org/abs/2006.12453">arXiv:2006.12453</a> [<a href="http://arxiv.org/pdf/2006.12453">pdf</a>]

<h2>Policies for elementary link generation in quantum networks. (arXiv:2007.03193v2 [quant-ph] UPDATED)</h2>
<h3>Sumeet Khatri</h3>
<p>Protocols in a quantum network involve multiple parties performing actions on
their quantum systems in a carefully orchestrated manner over time in order to
accomplish a given task. This sequence of actions over time is often referred
to as a strategy, or policy. In this work, we consider policy optimization in a
quantum network. Specifically, as a first step towards developing full-fledged
quantum network protocols, we consider policies for generating elementary links
in a quantum network. We start by casting elementary link generation as a
quantum partially observable Markov decision process, as defined in [Phys. Rev.
A 90, 032311 (2014)]. Then, we analyze in detail the commonly used memory
cutoff policy. Under this policy, once an elementary link is established it is
kept in quantum memory for some amount $t^{\star}$ of time, called the cutoff,
before it is discarded and the elementary link generation is reattempted. For
this policy, we determine the average quantum state of the elementary link as a
function of time for an arbitrary number of nodes in the link, as well as the
average fidelity of the link as a function of time for any noise model for the
quantum memories. Finally, we show how optimal policies can be obtained in the
finite-horizon setting using dynamic programming. By casting elementary link
generation as a quantum decision process, this work goes beyond the analytical
results derived here by providing the theoretical framework for performing
reinforcement learning of practical quantum network protocols.
</p>
<a href="http://arxiv.org/abs/2007.03193">arXiv:2007.03193</a> [<a href="http://arxiv.org/pdf/2007.03193">pdf</a>]

<h2>Knowledge Distillation for Multi-task Learning. (arXiv:2007.06889v2 [cs.CV] UPDATED)</h2>
<h3>Wei-Hong Li, Hakan Bilen</h3>
<p>Multi-task learning (MTL) is to learn one single model that performs multiple
tasks for achieving good performance on all tasks and lower cost on
computation. Learning such a model requires to jointly optimize losses of a set
of tasks with different difficulty levels, magnitudes, and characteristics
(e.g. cross-entropy, Euclidean loss), leading to the imbalance problem in
multi-task learning. To address the imbalance problem, we propose a knowledge
distillation based method in this work. We first learn a task-specific model
for each task. We then learn the multi-task model for minimizing task-specific
loss and for producing the same feature with task-specific models. As the
task-specific network encodes different features, we introduce small
task-specific adaptors to project multi-task features to the task-specific
features. In this way, the adaptors align the task-specific feature and the
multi-task feature, which enables a balanced parameter sharing across tasks.
Extensive experimental results demonstrate that our method can optimize a
multi-task learning model in a more balanced way and achieve better overall
performance.
</p>
<a href="http://arxiv.org/abs/2007.06889">arXiv:2007.06889</a> [<a href="http://arxiv.org/pdf/2007.06889">pdf</a>]

<h2>Fair and autonomous sharing of federate learning models in mobile Internet of Things. (arXiv:2007.10650v2 [cs.CR] UPDATED)</h2>
<h3>Xiaohan Hao, Wei Ren, Ruoting Xiong, Xianghan Zheng, Tianqing Zhu, Neal N. Xiong</h3>
<p>Federate learning can conduct machine learning as well as protect the privacy
of self-owned training data on corresponding ends, instead of having to upload
to a central trusted data aggregation server. In mobile scenarios, a
centralized trusted server may not be existing, and even though it exists, the
delay will not be manageable, e.g., smart driving cars. Thus, mobile federate
learning at the edge with privacy-awareness is attracted more and more
attentions. It then imposes a problem - after data are trained on a mobile
terminal to obtain a learned model, how to share the model parameters among
others to create more accurate and robust accumulative final model. This kind
of model sharing confronts several challenges, e.g., the sharing must be
conducted without a third trusted party (autonomously), and the sharing must be
fair as model training (by training data)is valuable. To tackle the above
challenges, we propose a smart contract and IPFS (Inter-Planetary File System)
based model sharing protocol and algorithms to address the challenges. The
proposed protocol does not rely on a trusted third party, where
individual-learned models are shared/stored in corresponding ends. Conducted
through extensive experiments, three main steps of the proposed protocol are
evaluated. The average executive time of the three steps are 0.059s, 0.060s and
0.032s, demonstrating its efficiency.
</p>
<a href="http://arxiv.org/abs/2007.10650">arXiv:2007.10650</a> [<a href="http://arxiv.org/pdf/2007.10650">pdf</a>]

<h2>Comparative Analysis of Polynomial and Rational Approximations of Hyperbolic Tangent Function for VLSI Implementation. (arXiv:2007.11976v2 [cs.AR] UPDATED)</h2>
<h3>Mahesh Chandra</h3>
<p>Deep neural networks yield the state-of-the-art results in many computer
vision and human machine interface applications such as object detection,
speech recognition etc. Since, these networks are computationally expensive,
customized accelerators are designed for achieving the required performance at
lower cost and power. One of the key building blocks of these neural networks
is non-linear activation function such as sigmoid, hyperbolic tangent (tanh),
and ReLU. A low complexity accurate hardware implementation of the activation
function is required to meet the performance and area targets of the neural
network accelerators. Even though, various methods and implementations of tanh
activation function have been published, a comparative study is missing. This
paper presents comparative analysis of polynomial and rational methods and
their hardware implementation.
</p>
<a href="http://arxiv.org/abs/2007.11976">arXiv:2007.11976</a> [<a href="http://arxiv.org/pdf/2007.11976">pdf</a>]

<h2>Evolve To Control: Evolution-based Soft Actor-Critic for Scalable Reinforcement Learning. (arXiv:2007.13690v2 [cs.LG] UPDATED)</h2>
<h3>Karush Suri, Xiao Qi Shi, Konstantinos N. Plataniotis, Yuri A. Lawryshyn</h3>
<p>Advances in Reinforcement Learning (RL) have successfully tackled sample
efficiency and overestimation bias. However, these methods often fall short of
scalable performance. On the other hand, genetic methods provide scalability
but depict hyperparameter sensitivity to evolutionary operations. We present
the Evolution-based Soft Actor-Critic (ESAC), a scalable RL algorithm. Our
contributions are threefold; ESAC (1) abstracts exploration from exploitation
by combining Evolution Strategies (ES) with Soft Actor-Critic (SAC), (2)
provides dominant skill transfer between offsprings by making use of soft
winner selections and genetic crossovers in hindsight and (3) improves
hyperparameter sensitivity in evolutions using Automatic Mutation Tuning (AMT).
AMT gradually replaces the entropy framework of SAC allowing the population to
succeed at the task while acting as randomly as possible, without making use of
backpropagation updates. On a range of challenging control tasks consisting of
high-dimensional action spaces and sparse rewards, ESAC demonstrates
state-of-the-art performance and sample efficiency equivalent to SAC. ESAC
demonstrates scalability comparable to ES on the basis of hardware resources
and algorithm overhead. A complete implementation of ESAC with notes on
reproducibility and videos can be found at the project website
https://karush17.github.io/esac-web/.
</p>
<a href="http://arxiv.org/abs/2007.13690">arXiv:2007.13690</a> [<a href="http://arxiv.org/pdf/2007.13690">pdf</a>]

<h2>Presentation and Analysis of a Multimodal Dataset for Grounded LanguageLearning. (arXiv:2007.14987v3 [cs.RO] UPDATED)</h2>
<h3>Patrick Jenkins, Rishabh Sachdeva, Gaoussou Youssouf Kebe, Padraig Higgins, Kasra Darvish, Edward Raff, Don Engel, John Winder, Francis Ferraro, Cynthia Matuszek</h3>
<p>Grounded language acquisition -- learning how language-based interactions
refer to the world around them -- is amajor area of research in robotics, NLP,
and HCI. In practice the data used for learning consists almost entirely of
textual descriptions, which tend to be cleaner, clearer, and more grammatical
than actual human interactions. In this work, we present the Grounded Language
Dataset (GoLD), a multimodal dataset of common household objects described by
people using either spoken or written language. We analyze the differences and
present an experiment showing how the different modalities affect language
learning from human in-put. This will enable researchers studying the
intersection of robotics, NLP, and HCI to better investigate how the multiple
modalities of image, text, and speech interact, as well as show differences in
the vernacular of these modalities impact results.
</p>
<a href="http://arxiv.org/abs/2007.14987">arXiv:2007.14987</a> [<a href="http://arxiv.org/pdf/2007.14987">pdf</a>]

<h2>Sybil-Resilient, Egalitarian and Just Digital Currency. (arXiv:2007.15536v3 [cs.SI] UPDATED)</h2>
<h3>Avigail Gurin-Schleifer, Ouri Poupko, Ehud Shapiro, Nimrod Talmon</h3>
<p>We envision a self-sovereign, grassroots, digital community that grows in a
bottom up, decentralized manner, and aim to integrate for it the following
previously-proposed building blocks: a mechanism that accepts members into the
community while keeping a bounded number of sybils; digital social contracts
that define the possible interactions of a community bounded by such a
contract; a design for a fault-tolerant distributed ledger implementation of
digital social contracts; and a digital social contract for the egalitarian and
just minting of digital currency, which also offers a form of universal basic
income. We augment these building blocks with a mechanism that allows the
community to maintain sovereignty over the economy, by making it
sybil-resilient. To do so, we assume that the community has the means for
exposing sybils and we extend the basic egalitarian currency digital social
contract with means to balance the economy so that money minted by sybils is
eventually retrieved and burned. This leads---asymptotically---to distributive
justice among the genuine agents, with the amount of money minted being equal
to the number of genuine agents, multiplied by the time each agent was a member
of the community. We then argue that this approach constitutes a mechanism that
deters the creation of sybils and incentivizes sybil hunting.
</p>
<a href="http://arxiv.org/abs/2007.15536">arXiv:2007.15536</a> [<a href="http://arxiv.org/pdf/2007.15536">pdf</a>]

<h2>Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks. (arXiv:2008.04495v4 [cs.CR] UPDATED)</h2>
<h3>Jinyuan Jia, Xiaoyu Cao, Neil Zhenqiang Gong</h3>
<p>In a \emph{data poisoning attack}, an attacker modifies, deletes, and/or
inserts some training examples to corrupt the learnt machine learning model.
\emph{Bootstrap Aggregating (bagging)} is a well-known ensemble learning
method, which trains multiple base models on random subsamples of a training
dataset using a base learning algorithm and uses majority vote to predict
labels of testing examples. We prove the intrinsic certified robustness of
bagging against data poisoning attacks. Specifically, we show that bagging with
an arbitrary base learning algorithm provably predicts the same label for a
testing example when the number of modified, deleted, and/or inserted training
examples is bounded by a threshold. Moreover, we show that our derived
threshold is tight if no assumptions on the base learning algorithm are made.
We evaluate our method on MNIST and CIFAR10. For instance, our method achieves
a certified accuracy of $91.1\%$ on MNIST when arbitrarily modifying, deleting,
and/or inserting 100 training examples.
</p>
<a href="http://arxiv.org/abs/2008.04495">arXiv:2008.04495</a> [<a href="http://arxiv.org/pdf/2008.04495">pdf</a>]

<h2>Soft Tissue Sarcoma Co-Segmentation in Combined MRI and PET/CT Data. (arXiv:2008.12544v2 [eess.IV] UPDATED)</h2>
<h3>Theresa Neubauer, Maria Wimmer, Astrid Berg, David Major, Dimitrios Lenis, Thomas Beyer, Jelena Saponjski, Katja B&#xfc;hler</h3>
<p>Tumor segmentation in multimodal medical images has seen a growing trend
towards deep learning based methods. Typically, studies dealing with this topic
fuse multimodal image data to improve the tumor segmentation contour for a
single imaging modality. However, they do not take into account that tumor
characteristics are emphasized differently by each modality, which affects the
tumor delineation. Thus, the tumor segmentation is modality- and
task-dependent. This is especially the case for soft tissue sarcomas, where,
due to necrotic tumor tissue, the segmentation differs vastly. Closing this
gap, we develop a modalityspecific sarcoma segmentation model that utilizes
multimodal image data to improve the tumor delineation on each individual
modality. We propose a simultaneous co-segmentation method, which enables
multimodal feature learning through modality-specific encoder and decoder
branches, and the use of resource-effcient densely connected convolutional
layers. We further conduct experiments to analyze how different input
modalities and encoder-decoder fusion strategies affect the segmentation
result. We demonstrate the effectiveness of our approach on public soft tissue
sarcoma data, which comprises MRI (T1 and T2 sequence) and PET/CT scans. The
results show that our multimodal co-segmentation model provides better
modality-specific tumor segmentation than models using only the PET or MRI (T1
and T2) scan as input.
</p>
<a href="http://arxiv.org/abs/2008.12544">arXiv:2008.12544</a> [<a href="http://arxiv.org/pdf/2008.12544">pdf</a>]

<h2>Why I'm not Answering: Understanding Determinants of Classification of an Abstaining Classifier for Cancer Pathology Reports. (arXiv:2009.05094v4 [cs.LG] UPDATED)</h2>
<h3>Sayera Dhaubhadel, Jamaludin Mohd-Yusof, Kumkum Ganguly, Gopinath Chennupati, Sunil Thulasidasan, Nicolas Hengartner, Brent J. Mumphrey, Eric B. Durban, Jennifer A. Doherty, Mireille Lemieux, Noah Schaefferkoetter, Georgia Tourassi, Linda Coyle, Lynne Penberthy, Benjamin McMahon, Tanmoy Bhattacharya</h3>
<p>Safe deployment of deep learning systems in critical real world applications
requires models to make few mistakes, and only under predictable circumstances.
Development of such a model is not yet possible, in general. In this work, we
address this problem with an abstaining classifier tuned to have $&gt;$95%
accuracy, and identify the determinants of abstention with LIME (the Local
Interpretable Model-agnostic Explanations method). Essentially, we are training
our model to learn the attributes of pathology reports that are likely to lead
to incorrect classifications, albeit at the cost of reduced sensitivity. We
demonstrate our method in a multitask setting to classify cancer pathology
reports from the NCI SEER cancer registries on six tasks of greatest
importance. For these tasks, we reduce the classification error rate by factors
of 2-5 by abstaining on 25-45% of the reports. For the specific case of cancer
site, we are able to identify metastasis and reports involving lymph nodes as
responsible for many of the classification mistakes, and that the extent and
types of mistakes vary systematically with cancer site (eg. breast, lung, and
prostate). When combining across three of the tasks, our model classifies 50%
of the reports with an accuracy greater than 95% for three of the six tasks and
greater than 85% for all six tasks on the retained samples. By using this
information, we expect to define work flows that incorporate machine learning
only in the areas where it is sufficiently robust and accurate, saving human
attention to areas where it is required.
</p>
<a href="http://arxiv.org/abs/2009.05094">arXiv:2009.05094</a> [<a href="http://arxiv.org/pdf/2009.05094">pdf</a>]

<h2>TREX: Tree-Ensemble Representer-Point Explanations. (arXiv:2009.05530v2 [cs.LG] UPDATED)</h2>
<h3>Jonathan Brophy, Daniel Lowd</h3>
<p>How can we identify the training examples that contribute most to the
prediction of a tree ensemble? In this paper, we introduce TREX, an explanation
system that provides instance-attribution explanations for tree ensembles, such
as random forests and gradient boosted trees. TREX builds on the representer
point framework previously developed for explaining deep neural networks. Since
tree ensembles are non-differentiable, we define a kernel that captures the
structure of the specific tree ensemble. By using this kernel in kernel
logistic regression or a support vector machine, TREX builds a surrogate model
that approximates the original tree ensemble. The weights in the kernel
expansion of the surrogate model are used to define the global or local
importance of each training example.

Our experiments show that TREX's surrogate model accurately approximates the
tree ensemble; its global importance weights are more effective in dataset
debugging than the previous state-of-the-art; its explanations identify the
most influential samples better than alternative methods under the remove and
retrain evaluation framework; it runs orders of magnitude faster than
alternative methods; and its local explanations can identify and explain errors
due to domain mismatch.
</p>
<a href="http://arxiv.org/abs/2009.05530">arXiv:2009.05530</a> [<a href="http://arxiv.org/pdf/2009.05530">pdf</a>]

<h2>Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes' Rule. (arXiv:2009.07783v2 [cs.CL] UPDATED)</h2>
<h3>Shuhei Kurita, Kyunghyun Cho</h3>
<p>Vision-and-language navigation (VLN) is a task in which an agent is embodied
in a realistic 3D environment and follows an instruction to reach the goal
node. While most of the previous studies have built and investigated a
discriminative approach, we notice that there are in fact two possible
approaches to building such a VLN agent: discriminative and generative. In this
paper, we design and investigate a generative language-grounded policy which
computes the distribution over all possible instructions given action and the
transition history. In experiments, we show that the proposed generative
approach outperforms the discriminative approach in the Room-2-Room (R2R)
dataset, especially in the unseen environments. We further show that the
combination of the generative and discriminative policies achieves close to the
state-of-the art results in the R2R dataset, demonstrating that the generative
and discriminative policies capture the different aspects of VLN.
</p>
<a href="http://arxiv.org/abs/2009.07783">arXiv:2009.07783</a> [<a href="http://arxiv.org/pdf/2009.07783">pdf</a>]

<h2>Transfer Learning in Deep Reinforcement Learning: A Survey. (arXiv:2009.07888v2 [cs.LG] UPDATED)</h2>
<h3>Zhuangdi Zhu, Kaixiang Lin, Jiayu Zhou</h3>
<p>This paper surveys the field of transfer learning in the problem setting of
Reinforcement Learning (RL). RL has been a key solution to sequential
decision-making problems. Along with the fast advances of RL in various
domains, such as robotics and game-playing, transfer learning arises as an
important technique to assist RL by leveraging and transferring external
expertise to boost the learning process of RL. In this survey, we review the
central issues of transfer learning in the RL domain, providing a systematic
categorization of its state-of-the-art techniques. We analyze their goals,
methodologies, applications, and the RL frameworks under which the transfer
learning techniques are approachable. We discuss the relationship between
transfer learning and other relevant topics from the RL perspective and also
explore the potential challenges as well as future development directions for
transfer learning in RL.
</p>
<a href="http://arxiv.org/abs/2009.07888">arXiv:2009.07888</a> [<a href="http://arxiv.org/pdf/2009.07888">pdf</a>]

<h2>DLBCL-Morph: Morphological features computed using deep learning for an annotated digital DLBCL image set. (arXiv:2009.08123v3 [cs.CV] UPDATED)</h2>
<h3>Damir Vrabac, Akshay Smit, Rebecca Rojansky, Yasodha Natkunam, Ranjana H. Advani, Andrew Y. Ng, Sebastian Fernandez-Pol, Pranav Rajpurkar</h3>
<p>Diffuse Large B-Cell Lymphoma (DLBCL) is the most common non-Hodgkin
lymphoma. Though histologically DLBCL shows varying morphologies, no
morphologic features have been consistently demonstrated to correlate with
prognosis. We present a morphologic analysis of histology sections from 209
DLBCL cases with associated clinical and cytogenetic data. Duplicate tissue
core sections were arranged in tissue microarrays (TMAs), and replicate
sections were stained with H&amp;E and immunohistochemical stains for CD10, BCL6,
MUM1, BCL2, and MYC. The TMAs are accompanied by pathologist-annotated
regions-of-interest (ROIs) that identify areas of tissue representative of
DLBCL. We used a deep learning model to segment all tumor nuclei in the ROIs,
and computed several geometric features for each segmented nucleus. We fit a
Cox proportional hazards model to demonstrate the utility of these geometric
features in predicting survival outcome, and found that it achieved a C-index
(95% CI) of 0.635 (0.574,0.691). Our finding suggests that geometric features
computed from tumor nuclei are of prognostic importance, and should be
validated in prospective studies.
</p>
<a href="http://arxiv.org/abs/2009.08123">arXiv:2009.08123</a> [<a href="http://arxiv.org/pdf/2009.08123">pdf</a>]

<h2>Data-Driven Distributed State Estimation and Behavior Modeling in Sensor Networks. (arXiv:2009.10827v2 [cs.RO] UPDATED)</h2>
<h3>Rui Yu, Zhenyuan Yuan, Minghui Zhu, Zihan Zhou</h3>
<p>Nowadays, the prevalence of sensor networks has enabled tracking of the
states of dynamic objects for a wide spectrum of applications from autonomous
driving to environmental monitoring and urban planning. However, tracking
real-world objects often faces two key challenges: First, due to the limitation
of individual sensors, state estimation needs to be solved in a collaborative
and distributed manner. Second, the objects' movement behavior is unknown, and
needs to be learned using sensor observations. In this work, for the first
time, we formally formulate the problem of simultaneous state estimation and
behavior learning in a sensor network. We then propose a simple yet effective
solution to this new problem by extending the Gaussian process-based Bayes
filters (GP-BayesFilters) to an online, distributed setting. The effectiveness
of the proposed method is evaluated on tracking objects with unknown movement
behaviors using both synthetic data and data collected from a multi-robot
platform.
</p>
<a href="http://arxiv.org/abs/2009.10827">arXiv:2009.10827</a> [<a href="http://arxiv.org/pdf/2009.10827">pdf</a>]

<h2>CLASS: Cross-Level Attention and Supervision for Salient Objects Detection. (arXiv:2009.10916v2 [cs.CV] UPDATED)</h2>
<h3>Lv Tang, Bo Li</h3>
<p>Salient object detection (SOD) is a fundamental computer vision task.
Recently, with the revival of deep neural networks, SOD has made great
progresses. However, there still exist two thorny issues that cannot be well
addressed by existing methods, indistinguishable regions and complex
structures. To address these two issues, in this paper we propose a novel deep
network for accurate SOD, named CLASS. First, in order to leverage the
different advantages of low-level and high-level features, we propose a novel
non-local cross-level attention (CLA), which can capture the long-range feature
dependencies to enhance the distinction of complete salient object. Second, a
novel cross-level supervision (CLS) is designed to learn complementary context
for complex structures through pixel-level, region-level and object-level. Then
the fine structures and boundaries of salient objects can be well restored. In
experiments, with the proposed CLA and CLS, our CLASS net. consistently
outperforms 13 state-of-the-art methods on five datasets.
</p>
<a href="http://arxiv.org/abs/2009.10916">arXiv:2009.10916</a> [<a href="http://arxiv.org/pdf/2009.10916">pdf</a>]

<h2>Scene Graph to Image Generation with Contextualized Object Layout Refinement. (arXiv:2009.10939v2 [cs.CV] UPDATED)</h2>
<h3>Maor Ivgi, Yaniv Benny, Avichai Ben-David, Jonathan Berant, Lior Wolf</h3>
<p>Generating high-quality images from scene graphs, that is, graphs that
describe multiple entities in complex relations, is a challenging task that
attracted substantial interest recently. Prior work trained such models by
using supervised learning, where the goal is to produce the exact target image
layout for each scene graph. It relied on predicting object locations and
shapes independently and in parallel. However, scene graphs are underspecified,
and thus the same scene graph often occurs with many target images in the
training data. This leads to generated images with high inter-object overlap,
empty areas, blurry objects, and overall compromised quality. In this work, we
propose a method that alleviates these issues by generating all object layouts
together and reducing the reliance on such supervision. Our model predicts
layouts directly from embeddings (without predicting intermediate boxes) by
gradually upsampling, refining and contextualizing object layouts. It is
trained with a novel adversarial loss, that optimizes the interaction between
object pairs. This improves coverage and removes overlaps, while maintaining
sensible contours and respecting objects relations. We empirically show on the
COCO-STUFF dataset that our proposed approach substantially improves the
quality of generated layouts as well as the overall image quality. Our
evaluation shows that we improve layout coverage by almost 20 points, and drop
object overlap to negligible amounts. This leads to better image generation,
relation fulfillment and objects quality.
</p>
<a href="http://arxiv.org/abs/2009.10939">arXiv:2009.10939</a> [<a href="http://arxiv.org/pdf/2009.10939">pdf</a>]

<h2>Attention with Multiple Sources Knowledges for COVID-19 from CT Images. (arXiv:2009.11008v2 [eess.IV] UPDATED)</h2>
<h3>Duy M. H. Nguyen, Duy M. Nguyen, Huong Vu, Binh T. Nguyen, Fabrizio Nunnari, Daniel Sonntag</h3>
<p>Until now, Coronavirus SARS-CoV-2 has caused more than 850,000 deaths and
infected more than 27 million individuals in over 120 countries. Besides
principal polymerase chain reaction (PCR) tests, automatically identifying
positive samples based on computed tomography (CT) scans can present a
promising option in the early diagnosis of COVID-19. Recently, there have been
increasing efforts to utilize deep networks for COVID-19 diagnosis based on CT
scans. While these approaches mostly focus on introducing novel architectures,
transfer learning techniques, or construction large scale data, we propose a
novel strategy to improve the performance of several baselines by leveraging
multiple useful information sources relevant to doctors' judgments.
Specifically, infected regions and heat maps extracted from learned networks
are integrated with the global image via an attention mechanism during the
learning process. This procedure not only makes our system more robust to noise
but also guides the network focusing on local lesion areas. Extensive
experiments illustrate the superior performance of our approach compared to
recent baselines. Furthermore, our learned network guidance presents an
explainable feature to doctors as we can understand the connection between
input and output in a grey-box model.
</p>
<a href="http://arxiv.org/abs/2009.11008">arXiv:2009.11008</a> [<a href="http://arxiv.org/pdf/2009.11008">pdf</a>]

<h2>A Fleet Learning Architecture for Enhanced Behavior Predictions during Challenging External Conditions. (arXiv:2009.11221v2 [cs.RO] UPDATED)</h2>
<h3>Florian Wirthm&#xfc;ller, Marvin Klimke, Julian Schlechtriemen, Jochen Hipp, Manfred Reichert</h3>
<p>Already today, driver assistance systems help to make daily traffic more
comfortable and safer. However, there are still situations that are quite rare
but are hard to handle at the same time. In order to cope with these situations
and to bridge the gap towards fully automated driving, it becomes necessary to
not only collect enormous amounts of data but rather the right ones. This data
can be used to develop and validate the systems through machine learning and
simulation pipelines. Along this line this paper presents a fleet
learning-based architecture that enables continuous improvements of systems
predicting the movement of surrounding traffic participants. Moreover, the
presented architecture is applied to a testing vehicle in order to prove the
fundamental feasibility of the system. Finally, it is shown that the system
collects meaningful data which are helpful to improve the underlying prediction
systems.
</p>
<a href="http://arxiv.org/abs/2009.11221">arXiv:2009.11221</a> [<a href="http://arxiv.org/pdf/2009.11221">pdf</a>]

<h2>Deep multi-stations weather forecasting: explainable recurrent convolutional neural networks. (arXiv:2009.11239v2 [cs.LG] UPDATED)</h2>
<h3>Ismail Alaoui Abdellaoui, Siamak Mehrkanoon</h3>
<p>Deep learning applied to weather forecasting has started gaining popularity
because of the progress achieved by data-driven models. The present paper
compares four different deep learning architectures to perform weather
prediction on daily data gathered from 18 cities across Europe and spanned over
a period of 15 years. The four proposed models investigate the different type
of input representations (i.e. tensorial unistream vs. multi-stream matrices)
as well as the combination of convolutional neural networks and LSTM (i.e.
cascaded vs. ConvLSTM). In particular, we show that a model that uses a
multi-stream input representation and that processes each lag individually
combined with a cascaded convolution and LSTM is capable of better forecasting
than the other compared models. In addition, we show that visualization
techniques such as occlusion analysis and score maximization can give an
additional insight on the most important features and cities for predicting a
particular target feature and city.
</p>
<a href="http://arxiv.org/abs/2009.11239">arXiv:2009.11239</a> [<a href="http://arxiv.org/pdf/2009.11239">pdf</a>]

<h2>Stock Price Prediction Using Machine Learning and LSTM-Based Deep Learning Models. (arXiv:2009.10819v1 [q-fin.ST] CROSS LISTED)</h2>
<h3>Sidra Mehtab, Jaydip Sen, Abhishek Dutta</h3>
<p>Prediction of stock prices has been an important area of research for a long
time. While supporters of the efficient market hypothesis believe that it is
impossible to predict stock prices accurately, there are formal propositions
demonstrating that accurate modeling and designing of appropriate variables may
lead to models using which stock prices and stock price movement patterns can
be very accurately predicted. In this work, we propose an approach of hybrid
modeling for stock price prediction building different machine learning and
deep learning-based models. For the purpose of our study, we have used NIFTY 50
index values of the National Stock Exchange (NSE) of India, during the period
December 29, 2014 till July 31, 2020. We have built eight regression models
using the training data that consisted of NIFTY 50 index records during
December 29, 2014 till December 28, 2018. Using these regression models, we
predicted the open values of NIFTY 50 for the period December 31, 2018 till
July 31, 2020. We, then, augment the predictive power of our forecasting
framework by building four deep learning-based regression models using long-and
short-term memory (LSTM) networks with a novel approach of walk-forward
validation. We exploit the power of LSTM regression models in forecasting the
future NIFTY 50 open values using four different models that differ in their
architecture and in the structure of their input data. Extensive results are
presented on various metrics for the all the regression models. The results
clearly indicate that the LSTM-based univariate model that uses one-week prior
data as input for predicting the next week open value of the NIFTY 50 time
series is the most accurate model.
</p>
<a href="http://arxiv.org/abs/2009.10819">arXiv:2009.10819</a> [<a href="http://arxiv.org/pdf/2009.10819">pdf</a>]

<h2>EXP4-DFDC: A Non-Stochastic Multi-Armed Bandit for Cache Replacement. (arXiv:2009.11330v1 [cs.LG])</h2>
<h3>Farzana Beente Yusuf, Camilo Valdes, Vitalii Stebliankin, Guiseppe Vietri, Giri Narasimhan</h3>
<p>In this work we study a variant of the well-known multi-armed bandit (MAB)
problem, which has the properties of a delay in feedback, and a loss that
declines over time. We introduce an algorithm, EXP4-DFDC, to solve this MAB
variant, and demonstrate that the regret vanishes as the time increases. We
also show that LeCaR, a previously published machine learning-based cache
replacement algorithm, is an instance of EXP4-DFDC. Our results can be used to
provide insight on the choice of hyperparameters, and optimize future LeCaR
instances.
</p>
<a href="http://arxiv.org/abs/2009.11330">arXiv:2009.11330</a> [<a href="http://arxiv.org/pdf/2009.11330">pdf</a>]

<h2>Dataset Optimization Strategies for MalwareTraffic Detection. (arXiv:2009.11347v1 [cs.LG])</h2>
<h3>Ivan Letteri, Antonio Di Cecco, Giuseppe Della Penna</h3>
<p>Machine learning is rapidly becoming one of the most important technology for
malware traffic detection, since the continuous evolution of malware requires a
constant adaptation and the ability to generalize. However, network traffic
datasets are usually oversized and contain redundant and irrelevant
information, and this may dramatically increase the computational cost and
decrease the accuracy of most classifiers, with the risk to introduce further
noise.

We propose two novel dataset optimization strategies which exploit and
combine several state-of-the-art approaches in order to achieve an effective
optimization of the network traffic datasets used to train malware detectors.
The first approach is a feature selection technique based on mutual information
measures and sensibility enhancement. The second is a dimensional reduction
technique based autoencoders. Both these approaches have been experimentally
applied on the MTA-KDD'19 dataset, and the optimized results evaluated and
compared using a Multi Layer Perceptron as machine learning model for malware
detection.
</p>
<a href="http://arxiv.org/abs/2009.11347">arXiv:2009.11347</a> [<a href="http://arxiv.org/pdf/2009.11347">pdf</a>]

<h2>Structure Aware Negative Sampling in Knowledge Graphs. (arXiv:2009.11355v1 [cs.LG])</h2>
<h3>Kian Ahrabian, Aarash Feizi, Yasmin Salehi, William L. Hamilton, Avishek Joey Bose</h3>
<p>Learning low-dimensional representations for entities and relations in
knowledge graphs using contrastive estimation represents a scalable and
effective method for inferring connectivity patterns. A crucial aspect of
contrastive learning approaches is the choice of corruption distribution that
generates hard negative samples, which force the embedding model to learn
discriminative representations and find critical characteristics of observed
data. While earlier methods either employ too simple corruption distributions,
i.e. uniform, yielding easy uninformative negatives or sophisticated
adversarial distributions with challenging optimization schemes, they do not
explicitly incorporate known graph structure resulting in suboptimal negatives.
In this paper, we propose Structure Aware Negative Sampling (SANS), an
inexpensive negative sampling strategy that utilizes the rich graph structure
by selecting negative samples from a node's k-hop neighborhood. Empirically, we
demonstrate that SANS finds high-quality negatives that are highly competitive
with SOTA methods, and requires no additional parameters nor difficult
adversarial optimization.
</p>
<a href="http://arxiv.org/abs/2009.11355">arXiv:2009.11355</a> [<a href="http://arxiv.org/pdf/2009.11355">pdf</a>]

<h2>Detection of Iterative Adversarial Attacks via Counter Attack. (arXiv:2009.11397v1 [cs.LG])</h2>
<h3>Matthias Rottmann, Mathis Peyron, Natasa Krejic, Hanno Gottschalk</h3>
<p>Deep neural networks (DNNs) have proven to be powerful tools for processing
unstructured data. However for high-dimensional data, like images, they are
inherently vulnerable to adversarial attacks. Small almost invisible
perturbations added to the input can be used to fool DNNs. Various attacks,
hardening methods and detection methods have been introduced in recent years.
Notoriously, Carlini-Wagner (CW) type attacks computed by iterative
minimization belong to those that are most difficult to detect. In this work,
we demonstrate that such iterative minimization attacks can by used as
detectors themselves. Thus, in some sense we show that one can fight fire with
fire. This work also outlines a mathematical proof that under certain
assumptions this detector provides asymptotically optimal separation of
original and attacked images. In numerical experiments, we obtain AUROC values
up to 99.73% for our detection method. This distinctly surpasses state of the
art detection rates for CW attacks from the literature. We also give numerical
evidence that our method is robust against the attacker's choice of the method
of attack.
</p>
<a href="http://arxiv.org/abs/2009.11397">arXiv:2009.11397</a> [<a href="http://arxiv.org/pdf/2009.11397">pdf</a>]

<h2>Rank-Based Multi-task Learning for Fair Regression. (arXiv:2009.11405v1 [cs.LG])</h2>
<h3>Chen Zhao, Feng Chen</h3>
<p>In this work, we develop a novel fairness learning approach for multi-task
regression models based on a biased training dataset, using a popular
rank-based non-parametric independence test, i.e., Mann Whitney U statistic,
for measuring the dependency between target variable and protected variables.
To solve this learning problem efficiently, we first reformulate the problem as
a new non-convex optimization problem, in which a non-convex constraint is
defined based on group-wise ranking functions of individual objects. We then
develop an efficient model-training algorithm based on the framework of
non-convex alternating direction method of multipliers (NC-ADMM), in which one
of the main challenges is to implement an efficient projection oracle to the
preceding non-convex set defined based on ranking functions. Through the
extensive experiments on both synthetic and real-world datasets, we validated
the out-performance of our new approach against several state-of-the-art
competitive methods on several popular metrics relevant to fairness learning.
</p>
<a href="http://arxiv.org/abs/2009.11405">arXiv:2009.11405</a> [<a href="http://arxiv.org/pdf/2009.11405">pdf</a>]

<h2>Unfairness Discovery and Prevention For Few-Shot Regression. (arXiv:2009.11406v1 [cs.LG])</h2>
<h3>Chen Zhao, Feng Chen</h3>
<p>We study fairness in supervised few-shot meta-learning models that are
sensitive to discrimination (or bias) in historical data. A machine learning
model trained based on biased data tends to make unfair predictions for users
from minority groups. Although this problem has been studied before, existing
methods mainly aim to detect and control the dependency effect of the protected
variables (e.g. race, gender) on target prediction based on a large amount of
training data. These approaches carry two major drawbacks that (1) lacking
showing a global cause-effect visualization for all variables; (2) lacking
generalization of both accuracy and fairness to unseen tasks. In this work, we
first discover discrimination from data using a causal Bayesian knowledge graph
which not only demonstrates the dependency of the protected variable on target
but also indicates causal effects between all variables. Next, we develop a
novel algorithm based on risk difference in order to quantify the
discriminatory influence for each protected variable in the graph. Furthermore,
to protect prediction from unfairness, a fast-adapted bias-control approach in
meta-learning is proposed, which efficiently mitigates statistical disparity
for each task and it thus ensures independence of protected attributes on
predictions based on biased and few-shot data samples. Distinct from existing
meta-learning models, group unfairness of tasks are efficiently reduced by
leveraging the mean difference between (un)protected groups for regression
problems. Through extensive experiments on both synthetic and real-world data
sets, we demonstrate that our proposed unfairness discovery and prevention
approaches efficiently detect discrimination and mitigate biases on model
output as well as generalize both accuracy and fairness to unseen tasks with a
limited amount of training samples.
</p>
<a href="http://arxiv.org/abs/2009.11406">arXiv:2009.11406</a> [<a href="http://arxiv.org/pdf/2009.11406">pdf</a>]

<h2>Steering a Historical Disease Forecasting Model Under a Pandemic: Case of Flu and COVID-19. (arXiv:2009.11407v1 [cs.LG])</h2>
<h3>Alexander Rodriguez, Nikhil Muralidhar, Bijaya Adhikari, Anika Tabassum, Naren Ramakrishnan, B. Aditya Prakash</h3>
<p>Forecasting influenza in a timely manner aids health organizations and
policymakers in adequate preparation and decision making. However, effective
influenza forecasting still remains a challenge despite increasing research
interest. It is even more challenging amidst the COVID pandemic, when the
influenza-like illness (ILI) counts is affected by various factors such as
symptomatic similarities with COVID-19 and shift in healthcare seeking patterns
of the general population. We term the ILI values observed when it is
potentially affected as COVID-ILI. Under the current pandemic, historical
influenza models carry valuable expertise about the disease dynamics but face
difficulties adapting. Therefore, we propose CALI-NET, a neural transfer
learning architecture which allows us to 'steer' a historical disease
forecasting model to new scenarios where flu and COVID co-exist. Our framework
enables this adaptation by automatically learning when it is should emphasize
learning from COVID-related signals and when from the historical model. In such
way, we exploit representations learned from historical ILI data as well as the
limited COVID-related signals. Our experiments demonstrate that our approach is
successful in adapting a historical forecasting model to the current pandemic.
In addition, we show that success in our primary goal, adaptation, does not
sacrifice overall performance as compared with state-of-the-art influenza
forecasting approaches.
</p>
<a href="http://arxiv.org/abs/2009.11407">arXiv:2009.11407</a> [<a href="http://arxiv.org/pdf/2009.11407">pdf</a>]

<h2>An elementary approach for minimax estimation of Bernoulli proportion in the restricted parameter space. (arXiv:2009.11413v1 [math.ST])</h2>
<h3>Heejune Sheen, Yajun Mei</h3>
<p>We present an elementary mathematical method to find the minimax estimator of
the Bernoulli proportion $\theta$ under the squared error loss when $\theta$
belongs to the restricted parameter space of the form $\Omega = [0, \eta]$ for
some pre-specified constant $0 \leq \eta \leq 1$. This problem is inspired from
the problem of estimating the rate of positive COVID-19 tests. The presented
results and applications would be useful materials for both instructors and
students when teaching point estimation in statistical or machine learning
courses.
</p>
<a href="http://arxiv.org/abs/2009.11413">arXiv:2009.11413</a> [<a href="http://arxiv.org/pdf/2009.11413">pdf</a>]

<h2>Enhancing Mixup-based Semi-Supervised Learning with Explicit Lipschitz Regularization. (arXiv:2009.11416v1 [cs.LG])</h2>
<h3>Prashnna Kumar Gyawali, Sandesh Ghimire, Linwei Wang</h3>
<p>The success of deep learning relies on the availability of large-scale
annotated data sets, the acquisition of which can be costly, requiring expert
domain knowledge. Semi-supervised learning (SSL) mitigates this challenge by
exploiting the behavior of the neural function on large unlabeled data. The
smoothness of the neural function is a commonly used assumption exploited in
SSL. A successful example is the adoption of mixup strategy in SSL that
enforces the global smoothness of the neural function by encouraging it to
behave linearly when interpolating between training examples. Despite its
empirical success, however, the theoretical underpinning of how mixup
regularizes the neural function has not been fully understood. In this paper,
we offer a theoretically substantiated proposition that mixup improves the
smoothness of the neural function by bounding the Lipschitz constant of the
gradient function of the neural networks. We then propose that this can be
strengthened by simultaneously constraining the Lipschitz constant of the
neural function itself through adversarial Lipschitz regularization,
encouraging the neural function to behave linearly while also constraining the
slope of this linear function. On three benchmark data sets and one real-world
biomedical data set, we demonstrate that this combined regularization results
in improved generalization performance of SSL when learning from a small amount
of labeled data. We further demonstrate the robustness of the presented method
against single-step adversarial attacks. Our code is available at
https://github.com/Prasanna1991/Mixup-LR.
</p>
<a href="http://arxiv.org/abs/2009.11416">arXiv:2009.11416</a> [<a href="http://arxiv.org/pdf/2009.11416">pdf</a>]

<h2>Revisiting Graph Convolutional Network on Semi-Supervised Node Classification from an Optimization Perspective. (arXiv:2009.11469v1 [cs.LG])</h2>
<h3>Hongwei Zhang, Tijin Yan, Zenjun Xie, Yuanqing Xia, Yuan Zhang</h3>
<p>Graph convolutional networks (GCNs) have achieved promising performance on
various graph-based tasks. However they suffer from over-smoothing when
stacking more layers. In this paper, we present a quantitative study on this
observation and develop novel insights towards the deeper GCN. First, we
interpret the current graph convolutional operations from an optimization
perspective and argue that over-smoothing is mainly caused by the naive
first-order approximation of the solution to the optimization problem.
Subsequently, we introduce two metrics to measure the over-smoothing on
node-level tasks. Specifically, we calculate the fraction of the pairwise
distance between connected and disconnected nodes to the overall distance
respectively. Based on our theoretical and empirical analysis, we establish a
universal theoretical framework of GCN from an optimization perspective and
derive a novel convolutional kernel named GCN+ which has lower parameter amount
while relieving the over-smoothing inherently. Extensive experiments on
real-world datasets demonstrate the superior performance of GCN+ over
state-of-the-art baseline methods on the node classification tasks.
</p>
<a href="http://arxiv.org/abs/2009.11469">arXiv:2009.11469</a> [<a href="http://arxiv.org/pdf/2009.11469">pdf</a>]

<h2>Theoretical Analysis of the Advantage of Deepening Neural Networks. (arXiv:2009.11479v1 [cs.LG])</h2>
<h3>Yasushi Esaki, Yuta Nakahara, Toshiyasu Matsushima</h3>
<p>We propose two new criteria to understand the advantage of deepening neural
networks. It is important to know the expressivity of functions computable by
deep neural networks in order to understand the advantage of deepening neural
networks. Unless deep neural networks have enough expressivity, they cannot
have good performance even though learning is successful. In this situation,
the proposed criteria contribute to understanding the advantage of deepening
neural networks since they can evaluate the expressivity independently from the
efficiency of learning. The first criterion shows the approximation accuracy of
deep neural networks to the target function. This criterion has the background
that the goal of deep learning is approximating the target function by deep
neural networks. The second criterion shows the property of linear regions of
functions computable by deep neural networks. This criterion has the background
that deep neural networks whose activation functions are piecewise linear are
also piecewise linear. Furthermore, by the two criteria, we show that to
increase layers is more effective than to increase units at each layer on
improving the expressivity of deep neural networks.
</p>
<a href="http://arxiv.org/abs/2009.11479">arXiv:2009.11479</a> [<a href="http://arxiv.org/pdf/2009.11479">pdf</a>]

<h2>Improving Query Efficiency of Black-box Adversarial Attack. (arXiv:2009.11508v1 [cs.LG])</h2>
<h3>Yang Bai, Yuyuan Zeng, Yong Jiang, Yisen Wang, Shu-Tao Xia, Weiwei Guo</h3>
<p>Deep neural networks (DNNs) have demonstrated excellent performance on
various tasks, however they are under the risk of adversarial examples that can
be easily generated when the target model is accessible to an attacker
(white-box setting). As plenty of machine learning models have been deployed
via online services that only provide query outputs from inaccessible models
(e.g. Google Cloud Vision API2), black-box adversarial attacks (inaccessible
target model) are of critical security concerns in practice rather than
white-box ones. However, existing query-based black-box adversarial attacks
often require excessive model queries to maintain a high attack success rate.
Therefore, in order to improve query efficiency, we explore the distribution of
adversarial examples around benign inputs with the help of image structure
information characterized by a Neural Process, and propose a Neural Process
based black-box adversarial attack (NP-Attack) in this paper. Extensive
experiments show that NP-Attack could greatly decrease the query counts under
the black-box setting.
</p>
<a href="http://arxiv.org/abs/2009.11508">arXiv:2009.11508</a> [<a href="http://arxiv.org/pdf/2009.11508">pdf</a>]

<h2>Legally grounded fairness objectives. (arXiv:2009.11677v1 [cs.LG])</h2>
<h3>Dylan Holden-Sim, Gavin Leech, Laurence Aitchison</h3>
<p>Recent work has identified a number of formally incompatible operational
measures for the unfairness of a machine learning (ML) system. As these
measures all capture intuitively desirable aspects of a fair system, choosing
"the one true" measure is not possible, and instead a reasonable approach is to
minimize a weighted combination of measures. However, this simply raises the
question of how to choose the weights. Here, we formulate Legally Grounded
Fairness Objectives (LGFO), which uses signals from the legal system to
non-arbitrarily measure the social cost of a specific degree of unfairness. The
LGFO is the expected damages under a putative lawsuit that might be awarded to
those who were wrongly classified, in the sense that the ML system made a
decision different to that which would have be made under the court's preferred
measure. Notably, the two quantities necessary to compute the LGFO, the court's
preferences about fairness measures, and the expected damages, are unknown but
well-defined, and can be estimated by legal advice. Further, as the damages
awarded by the legal system are designed to measure and compensate for the harm
caused to an individual by an unfair classification, the LGFO aligns closely
with society's estimate of the social cost.
</p>
<a href="http://arxiv.org/abs/2009.11677">arXiv:2009.11677</a> [<a href="http://arxiv.org/pdf/2009.11677">pdf</a>]

<h2>Privacy-preserving Transfer Learning via Secure Maximum Mean Discrepancy. (arXiv:2009.11680v1 [cs.LG])</h2>
<h3>Bin Zhang, Cen Chen, Li Wang</h3>
<p>The success of machine learning algorithms often relies on a large amount of
high-quality data to train well-performed models. However, data is a valuable
resource and are always held by different parties in reality. An effective
solution to such a data isolation problem is to employ federated learning,
which allows multiple parties to collaboratively train a model. In this paper,
we propose a Secure version of the widely used Maximum Mean Discrepancy (SMMD)
based on homomorphic encryption to enable effective knowledge transfer under
the data federation setting without compromising the data privacy. The proposed
SMMD is able to avoid the potential information leakage in transfer learning
when aligning the source and target data distribution. As a result, both the
source domain and target domain can fully utilize their data to build more
scalable models. Experimental results demonstrate that our proposed SMMD is
secure and effective.
</p>
<a href="http://arxiv.org/abs/2009.11680">arXiv:2009.11680</a> [<a href="http://arxiv.org/pdf/2009.11680">pdf</a>]

<h2>A Variational Auto-Encoder for Reservoir Monitoring. (arXiv:2009.11693v1 [cs.LG])</h2>
<h3>Kristian Gundersen, Seyyed A. Hosseini, Anna Oleynik, Guttorm Alendal</h3>
<p>Carbon dioxide Capture and Storage (CCS) is an important strategy in
mitigating anthropogenic CO$_2$ emissions. In order for CCS to be successful,
large quantities of CO$_2$ must be stored and the storage site conformance must
be monitored. Here we present a deep learning method to reconstruct pressure
fields and classify the flux out of the storage formation based on the pressure
data from Above Zone Monitoring Interval (AZMI) wells. The deep learning method
is a version of a semi conditional variational auto-encoder tailored to solve
two tasks: reconstruction of an incremental pressure field and leakage rate
classification. The method, predictions and associated uncertainty estimates
are illustrated on the synthetic data from a high-fidelity heterogeneous 2D
numerical reservoir model, which was used to simulate subsurface CO$_2$
movement and pressure changes in the AZMI due to a CO$_2$ leakage.
</p>
<a href="http://arxiv.org/abs/2009.11693">arXiv:2009.11693</a> [<a href="http://arxiv.org/pdf/2009.11693">pdf</a>]

<h2>Compressed imitation learning. (arXiv:2009.11697v1 [cs.LG])</h2>
<h3>Nathan Zhao, Beicheng Lou</h3>
<p>In analogy to compressed sensing, which allows sample-efficient signal
reconstruction given prior knowledge of its sparsity in frequency domain, we
propose to utilize policy simplicity (Occam's Razor) as a prior to enable
sample-efficient imitation learning. We first demonstrated the feasibility of
this scheme on linear case where state-value function can be sampled directly.
We also extended the scheme to scenarios where only actions are visible and
scenarios where the policy is obtained from nonlinear network. The method is
benchmarked against behavior cloning and results in significantly higher scores
with limited expert demonstrations.
</p>
<a href="http://arxiv.org/abs/2009.11697">arXiv:2009.11697</a> [<a href="http://arxiv.org/pdf/2009.11697">pdf</a>]

<h2>Principles and Practice of Explainable Machine Learning. (arXiv:2009.11698v1 [cs.LG])</h2>
<h3>Vaishak Belle, Ioannis Papantonis</h3>
<p>Artificial intelligence (AI) provides many opportunities to improve private
and public life. Discovering patterns and structures in large troves of data in
an automated manner is a core component of data science, and currently drives
applications in diverse areas such as computational biology, law and finance.
However, such a highly positive impact is coupled with significant challenges:
how do we understand the decisions suggested by these systems in order that we
can trust them? In this report, we focus specifically on data-driven methods --
machine learning (ML) and pattern recognition models in particular -- so as to
survey and distill the results and observations from the literature. The
purpose of this report can be especially appreciated by noting that ML models
are increasingly deployed in a wide range of businesses. However, with the
increasing prevalence and complexity of methods, business stakeholders in the
very least have a growing number of concerns about the drawbacks of models,
data-specific biases, and so on. Analogously, data science practitioners are
often not aware about approaches emerging from the academic literature, or may
struggle to appreciate the differences between different methods, so end up
using industry standards such as SHAP. Here, we have undertaken a survey to
help industry practitioners (but also data scientists more broadly) understand
the field of explainable machine learning better and apply the right tools. Our
latter sections build a narrative around a putative data scientist, and discuss
how she might go about explaining her models by asking the right questions.
</p>
<a href="http://arxiv.org/abs/2009.11698">arXiv:2009.11698</a> [<a href="http://arxiv.org/pdf/2009.11698">pdf</a>]

<h2>Online Structural Change-point Detection of High-dimensional Streaming Data via Dynamic Sparse Subspace Learning. (arXiv:2009.11713v1 [stat.ML])</h2>
<h3>Ruiyu Xu, Jianguo Wu, Xiaowei Yue, Yongxiang Li</h3>
<p>High-dimensional streaming data are becoming increasingly ubiquitous in many
fields. They often lie in multiple low-dimensional subspaces, and the manifold
structures may change abruptly on the time scale due to pattern shift or
occurrence of anomalies. However, the problem of detecting the structural
changes in a real-time manner has not been well studied. To fill this gap, we
propose a dynamic sparse subspace learning (DSSL) approach for online
structural change-point detection of high-dimensional streaming data. A novel
multiple structural change-point model is proposed and it is shown to be
equivalent to maximizing a posterior under certain conditions. The asymptotic
properties of the estimators are investigated. The penalty coefficients in our
model can be selected by AMDL criterion based on some historical data. An
efficient Pruned Exact Linear Time (PELT) based method is proposed for online
optimization and change-point detection. The effectiveness of the proposed
method is demonstrated through a simulation study and a real case study using
gesture data for motion tracking.
</p>
<a href="http://arxiv.org/abs/2009.11713">arXiv:2009.11713</a> [<a href="http://arxiv.org/pdf/2009.11713">pdf</a>]

<h2>Interpreting and Boosting Dropout from a Game-Theoretic View. (arXiv:2009.11729v1 [cs.LG])</h2>
<h3>Hao Zhang, Sen Li, Yinchao Ma, Mingjie Li, Yichen Xie, Quanshi Zhang</h3>
<p>This paper aims to understand and improve the utility of the dropout
operation from the perspective of game-theoretic interactions. We prove that
dropout can suppress the strength of interactions between input variables of
deep neural networks (DNNs). The theoretical proof is also verified by various
experiments. Furthermore, we find that such interactions were strongly related
to the over-fitting problem in deep learning. Thus, the utility of dropout can
be regarded as decreasing interactions to alleviating the significance of
over-fitting. Based on this understanding, we propose an interaction loss to
further improve the utility of dropout. Experimental results have shown that
the interaction loss can effectively improve the utility of dropout and boost
the performance of DNNs.
</p>
<a href="http://arxiv.org/abs/2009.11729">arXiv:2009.11729</a> [<a href="http://arxiv.org/pdf/2009.11729">pdf</a>]

<h2>A Unifying Review of Deep and Shallow Anomaly Detection. (arXiv:2009.11732v1 [cs.LG])</h2>
<h3>Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, Gr&#xe9;goire Montavon, Wojciech Samek, Marius Kloft, Thomas G. Dietterich, Klaus-Robert M&#xfc;ller</h3>
<p>Deep learning approaches to anomaly detection have recently improved the
state of the art in detection performance on complex datasets such as large
collections of images or text. These results have sparked a renewed interest in
the anomaly detection problem and led to the introduction of a great variety of
new methods. With the emergence of numerous such methods, including approaches
based on generative models, one-class classification, and reconstruction, there
is a growing need to bring methods of this field into a systematic and unified
perspective. In this review we aim to identify the common underlying principles
as well as the assumptions that are often made implicitly by various methods.
In particular, we draw connections between classic 'shallow' and novel deep
approaches and show how this relation might cross-fertilize or extend both
directions. We further provide an empirical assessment of major existing
methods that is enriched by the use of recent explainability techniques, and
present specific worked-through examples together with practical advice.
Finally, we outline critical open challenges and identify specific paths for
future research in anomaly detection.
</p>
<a href="http://arxiv.org/abs/2009.11732">arXiv:2009.11732</a> [<a href="http://arxiv.org/pdf/2009.11732">pdf</a>]

<h2>Secure Data Sharing With Flow Model. (arXiv:2009.11762v1 [cs.LG])</h2>
<h3>Chenwei Wu, Chenzhuang Du, Yang Yuan</h3>
<p>In the classical multi-party computation setting, multiple parties jointly
compute a function without revealing their own input data. We consider a
variant of this problem, where the input data can be shared for machine
learning training purposes, but the data are also encrypted so that they cannot
be recovered by other parties. We present a rotation based method using flow
model, and theoretically justified its security. We demonstrate the
effectiveness of our method in different scenarios, including supervised secure
model training, and unsupervised generative model training. Our code is
available at https://github.com/ duchenzhuang/flowencrypt.
</p>
<a href="http://arxiv.org/abs/2009.11762">arXiv:2009.11762</a> [<a href="http://arxiv.org/pdf/2009.11762">pdf</a>]

<h2>Unsupervised Transfer Learning for Spatiotemporal Predictive Networks. (arXiv:2009.11763v1 [cs.LG])</h2>
<h3>Zhiyu Yao, Yunbo Wang, Mingsheng Long, Jianmin Wang</h3>
<p>This paper explores a new research problem of unsupervised transfer learning
across multiple spatiotemporal prediction tasks. Unlike most existing transfer
learning methods that focus on fixing the discrepancy between supervised tasks,
we study how to transfer knowledge from a zoo of unsupervisedly learned models
towards another predictive network. Our motivation is that models from
different sources are expected to understand the complex spatiotemporal
dynamics from different perspectives, thereby effectively supplementing the new
task, even if the task has sufficient training samples. Technically, we propose
a differentiable framework named transferable memory. It adaptively distills
knowledge from a bank of memory states of multiple pretrained RNNs, and applies
it to the target network via a novel recurrent structure called the
Transferable Memory Unit (TMU). Compared with finetuning, our approach yields
significant improvements on three benchmarks for spatiotemporal prediction, and
benefits the target task even from less relevant pretext ones.
</p>
<a href="http://arxiv.org/abs/2009.11763">arXiv:2009.11763</a> [<a href="http://arxiv.org/pdf/2009.11763">pdf</a>]

<h2>Identifying noisy labels with a transductive semi-supervised leave-one-out filter. (arXiv:2009.11811v1 [cs.LG])</h2>
<h3>Bruno Klaus de Aquino Afonso, Lilian Berton</h3>
<p>Obtaining data with meaningful labels is often costly and error-prone. In
this situation, semi-supervised learning (SSL) approaches are interesting, as
they leverage assumptions about the unlabeled data to make up for the limited
amount of labels. However, in real-world situations, we cannot assume that the
labeling process is infallible, and the accuracy of many SSL classifiers
decreases significantly in the presence of label noise. In this work, we
introduce the LGC_LVOF, a leave-one-out filtering approach based on the Local
and Global Consistency (LGC) algorithm. Our method aims to detect and remove
wrong labels, and thus can be used as a preprocessing step to any SSL
classifier. Given the propagation matrix, detecting noisy labels takes O(cl)
per step, with c the number of classes and l the number of labels. Moreover,
one does not need to compute the whole propagation matrix, but only an $l$ by
$l$ submatrix corresponding to interactions between labeled instances. As a
result, our approach is best suited to datasets with a large amount of
unlabeled data but not many labels. Results are provided for a number of
datasets, including MNIST and ISOLET. LGCLVOF appears to be equally or more
precise than the adapted gradient-based filter. We show that the best-case
accuracy of the embedding of LGCLVOF into LGC yields performance comparable to
the best-case of $\ell_1$-based classifiers designed to be robust to label
noise. We provide a heuristic to choose the number of removed instances.
</p>
<a href="http://arxiv.org/abs/2009.11811">arXiv:2009.11811</a> [<a href="http://arxiv.org/pdf/2009.11811">pdf</a>]

<h2>Semi-supervised sequence classification through change point detection. (arXiv:2009.11829v1 [cs.LG])</h2>
<h3>Nauman Ahad, Mark A. Davenport</h3>
<p>Sequential sensor data is generated in a wide variety of practical
applications. A fundamental challenge involves learning effective classifiers
for such sequential data. While deep learning has led to impressive performance
gains in recent years in domains such as speech, this has relied on the
availability of large datasets of sequences with high-quality labels. In many
applications, however, the associated class labels are often extremely limited,
with precise labelling/segmentation being too expensive to perform at a high
volume. However, large amounts of unlabeled data may still be available. In
this paper we propose a novel framework for semi-supervised learning in such
contexts. In an unsupervised manner, change point detection methods can be used
to identify points within a sequence corresponding to likely class changes. We
show that change points provide examples of similar/dissimilar pairs of
sequences which, when coupled with labeled, can be used in a semi-supervised
classification setting. Leveraging the change points and labeled data, we form
examples of similar/dissimilar sequences to train a neural network to learn
improved representations for classification. We provide extensive synthetic
simulations and show that the learned representations are superior to those
learned through an autoencoder and obtain improved results on both simulated
and real-world human activity recognition datasets.
</p>
<a href="http://arxiv.org/abs/2009.11829">arXiv:2009.11829</a> [<a href="http://arxiv.org/pdf/2009.11829">pdf</a>]

<h2>A Gradient Flow Framework For Analyzing Network Pruning. (arXiv:2009.11839v1 [cs.LG])</h2>
<h3>Ekdeep Singh Lubana, Robert P. Dick</h3>
<p>Recent network pruning methods focus on pruning models early-on in training.
To estimate the impact of removing a parameter, these methods use importance
measures that were originally designed for pruning trained models. Despite
lacking justification for their use early-on in training, models pruned using
such measures result in surprisingly minimal accuracy loss. To better explain
this behavior, we develop a general, gradient-flow based framework that relates
state-of-the-art importance measures through an order of time-derivative of the
norm of model parameters. We use this framework to determine the relationship
between pruning measures and evolution of model parameters, establishing
several findings related to pruning models early-on in training: (i)
magnitude-based pruning removes parameters that contribute least to reduction
in loss, resulting in models that converge faster than magnitude-agnostic
methods; (ii) loss-preservation based pruning preserves first-order model
evolution dynamics and is well-motivated for pruning minimally trained models;
and (iii) gradient-norm based pruning affects second-order model evolution
dynamics, and increasing gradient norm via pruning can produce poorly
performing models. We validate our claims on several VGG-13, MobileNet-V1, and
ResNet-56 models trained on CIFAR-10 and CIFAR-100. Code available at
https://github.com/EkdeepSLubana/flowandprune.
</p>
<a href="http://arxiv.org/abs/2009.11839">arXiv:2009.11839</a> [<a href="http://arxiv.org/pdf/2009.11839">pdf</a>]

<h2>How Many Factors Influence Minima in SGD?. (arXiv:2009.11858v1 [cs.LG])</h2>
<h3>Victor Luo, Yazhen Wang</h3>
<p>Stochastic gradient descent (SGD) is often applied to train Deep Neural
Networks (DNNs), and research efforts have been devoted to investigate the
convergent dynamics of SGD and minima found by SGD. The influencing factors
identified in the literature include learning rate, batch size, Hessian, and
gradient covariance, and stochastic differential equations are used to model
SGD and establish the relationships among these factors for characterizing
minima found by SGD. It has been found that the ratio of batch size to learning
rate is a main factor in highlighting the underlying SGD dynamics; however, the
influence of other important factors such as the Hessian and gradient
covariance is not entirely agreed upon. This paper describes the factors and
relationships in the recent literature and presents numerical findings on the
relationships. In particular, it confirms the four-factor and general
relationship results obtained in Wang (2019), while the three-factor and
associated relationship results found in Jastrz\c{e}bski et al. (2018) may not
hold beyond the considered special case.
</p>
<a href="http://arxiv.org/abs/2009.11858">arXiv:2009.11858</a> [<a href="http://arxiv.org/pdf/2009.11858">pdf</a>]

<h2>Envy-Free Classification. (arXiv:1809.08700v2 [cs.LG] UPDATED)</h2>
<h3>Maria-Florina Balcan, Travis Dick, Ritesh Noothigattu, Ariel D. Procaccia</h3>
<p>In classic fair division problems such as cake cutting and rent division,
envy-freeness requires that each individual (weakly) prefer his allocation to
anyone else's. On a conceptual level, we argue that envy-freeness also provides
a compelling notion of fairness for classification tasks. Our technical focus
is the generalizability of envy-free classification, i.e., understanding
whether a classifier that is envy free on a sample would be almost envy free
with respect to the underlying distribution with high probability. Our main
result establishes that a small sample is sufficient to achieve such
guarantees, when the classifier in question is a mixture of deterministic
classifiers that belong to a family of low Natarajan dimension.
</p>
<a href="http://arxiv.org/abs/1809.08700">arXiv:1809.08700</a> [<a href="http://arxiv.org/pdf/1809.08700">pdf</a>]

<h2>Orthogonal Statistical Learning. (arXiv:1901.09036v3 [math.ST] UPDATED)</h2>
<h3>Dylan J. Foster, Vasilis Syrgkanis</h3>
<p>We provide non-asymptotic excess risk guarantees for statistical learning in
a setting where the population risk with respect to which we evaluate the
target parameter depends on an unknown nuisance parameter that must be
estimated from data. We analyze a two-stage sample splitting meta-algorithm
that takes as input two arbitrary estimation algorithms: one for the target
parameter and one for the nuisance parameter. We show that if the population
risk satisfies a condition called Neyman orthogonality, the impact of the
nuisance estimation error on the excess risk bound achieved by the
meta-algorithm is of second order. Our theorem is agnostic to the particular
algorithms used for the target and nuisance and only makes an assumption on
their individual performance. This enables the use of a plethora of existing
results from statistical learning and machine learning to give new guarantees
for learning with a nuisance component. Moreover, by focusing on excess risk
rather than parameter estimation, we can give guarantees under weaker
assumptions than in previous works and accommodate settings in which the target
parameter belongs to a complex nonparametric class. We provide conditions on
the metric entropy of the nuisance and target classes such that oracle
rates---rates of the same order as if we knew the nuisance parameter---are
achieved. We also derive new rates for specific estimation algorithms such as
variance-penalized empirical risk minimization, neural network estimation and
sparse high-dimensional linear model estimation. We highlight the applicability
of our results in four settings of central importance: 1) heterogeneous
treatment effect estimation, 2) offline policy optimization, 3) domain
adaptation, and 4) learning with missing data.
</p>
<a href="http://arxiv.org/abs/1901.09036">arXiv:1901.09036</a> [<a href="http://arxiv.org/pdf/1901.09036">pdf</a>]

<h2>Neural-encoding Human Experts' Domain Knowledge to Warm Start Reinforcement Learning. (arXiv:1902.06007v4 [cs.LG] UPDATED)</h2>
<h3>Andrew Silva, Matthew Gombolay</h3>
<p>Deep reinforcement learning has been successful in a variety of tasks, such
as game playing and robotic manipulation. However, attempting to learn
\textit{tabula rasa} disregards the logical structure of many domains as well
as the wealth of readily available knowledge from domain experts that could
help "warm start" the learning process. We present a novel reinforcement
learning technique that allows for intelligent initialization of a neural
network weights and architecture. Our approach permits the encoding domain
knowledge directly into a neural decision tree, and improves upon that
knowledge with policy gradient updates. We empirically validate our approach on
two OpenAI Gym tasks and two modified StarCraft 2 tasks, showing that our novel
architecture outperforms multilayer-perceptron and recurrent architectures. Our
knowledge-based framework finds superior policies compared to imitation
learning-based and prior knowledge-based approaches. Importantly, we
demonstrate that our approach can be used by untrained humans to initially
provide &gt;80% increase in expected reward relative to baselines prior to
training (p &lt; 0.001), which results in a &gt;60% increase in expected reward after
policy optimization (p = 0.011).
</p>
<a href="http://arxiv.org/abs/1902.06007">arXiv:1902.06007</a> [<a href="http://arxiv.org/pdf/1902.06007">pdf</a>]

<h2>Tag2Vec: Learning Tag Representations in Tag Networks. (arXiv:1905.03041v2 [cs.SI] UPDATED)</h2>
<h3>Junshan Wang, Zhicong Lu, Guojie Song, Yue Fan, Lun Du, Wei Lin</h3>
<p>Network embedding is a method to learn low-dimensional representation vectors
for nodes in complex networks. In real networks, nodes may have multiple tags
but existing methods ignore the abundant semantic and hierarchical information
of tags. This information is useful to many network applications and usually
very stable. In this paper, we propose a tag representation learning model,
Tag2Vec, which mixes nodes and tags into a hybrid network. Firstly, for tag
networks, we define semantic distance as the proximity between tags and design
a novel strategy, parameterized random walk, to generate context with semantic
and hierarchical information of tags adaptively. Then, we propose hyperbolic
Skip-gram model to express the complex hierarchical structure better with lower
output dimensions. We evaluate our model on the NBER U.S. patent dataset and
WordNet dataset. The results show that our model can learn tag representations
with rich semantic information and it outperforms other baselines.
</p>
<a href="http://arxiv.org/abs/1905.03041">arXiv:1905.03041</a> [<a href="http://arxiv.org/pdf/1905.03041">pdf</a>]

<h2>An Attention-Guided Deep Regression Model for Landmark Detection in Cephalograms. (arXiv:1906.07549v2 [eess.IV] UPDATED)</h2>
<h3>Zhusi Zhong, Jie Li, Zhenxi Zhang, Zhicheng Jiao, Xinbo Gao</h3>
<p>Cephalometric tracing method is usually used in orthodontic diagnosis and
treat-ment planning. In this paper, we propose a deep learning based framework
to au-tomatically detect anatomical landmarks in cephalometric X-ray images. We
train the deep encoder-decoder for landmark detection, and combine global
landmark configuration with local high-resolution feature responses. The
proposed frame-work is based on 2-stage u-net, regressing the multi-channel
heatmaps for land-mark detection. In this framework, we embed attention
mechanism with global stage heatmaps, guiding the local stage inferring, to
regress the local heatmap patches in a high resolution. Besides, the Expansive
Exploration strategy im-proves robustness while inferring, expanding the
searching scope without in-creasing model complexity. We have evaluated our
framework in the most wide-ly-used public dataset of landmark detection in
cephalometric X-ray images. With less computation and manually tuning, our
framework achieves state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/1906.07549">arXiv:1906.07549</a> [<a href="http://arxiv.org/pdf/1906.07549">pdf</a>]

<h2>Learning in Volatile Environments with the Bayes Factor Surprise. (arXiv:1907.02936v3 [stat.ML] UPDATED)</h2>
<h3>Vasiliki Liakoni, Alireza Modirshanechi, Wulfram Gerstner, Johanni Brea</h3>
<p>Surprise-based learning allows agents to rapidly adapt to non-stationary
stochastic environments characterized by sudden changes. We show that exact
Bayesian inference in a hierarchical model gives rise to a surprise-modulated
trade-off between forgetting old observations and integrating them with the new
ones. The modulation depends on a probability ratio, which we call "Bayes
Factor Surprise", that tests the prior belief against the current belief. We
demonstrate that in several existing approximate algorithms the Bayes Factor
Surprise modulates the rate of adaptation to new observations. We derive three
novel surprised-based algorithms, one in the family of particle filters, one in
the family of variational learning, and the other in the family of message
passing, that have constant scaling in observation sequence length and
particularly simple update dynamics for any distribution in the exponential
family. Empirical results show that these surprise-based algorithms estimate
parameters better than alternative approximate approaches and reach levels of
performance comparable to computationally more expensive algorithms. The Bayes
Factor Surprise is related to but different from Shannon Surprise. In two
hypothetical experiments, we make testable predictions for physiological
indicators that dissociate the Bayes Factor Surprise from Shannon Surprise. The
theoretical insight of casting various approaches as surprise-based learning,
as well as the proposed online algorithms, may be applied to the analysis of
animal and human behavior, and to reinforcement learning in non-stationary
environments.
</p>
<a href="http://arxiv.org/abs/1907.02936">arXiv:1907.02936</a> [<a href="http://arxiv.org/pdf/1907.02936">pdf</a>]

<h2>On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift. (arXiv:1908.00261v4 [cs.LG] UPDATED)</h2>
<h3>Alekh Agarwal, Sham M. Kakade, Jason D. Lee, Gaurav Mahajan</h3>
<p>Policy gradient methods are among the most effective methods in challenging
reinforcement learning problems with large state and/or action spaces. However,
little is known about even their most basic theoretical convergence properties,
including: if and how fast they converge to a globally optimal solution or how
they cope with approximation error due to using a restricted class of
parametric policies. This work provides provable characterizations of the
computational, approximation, and sample size properties of policy gradient
methods in the context of discounted Markov Decision Processes (MDPs). We focus
on both: "tabular" policy parameterizations, where the optimal policy is
contained in the class and where we show global convergence to the optimal
policy; and parametric policy classes (considering both log-linear and neural
policy classes), which may not contain the optimal policy and where we provide
agnostic learning results. One central contribution of this work is in
providing approximation guarantees that are average case -- which avoid
explicit worst-case dependencies on the size of state space -- by making a
formal connection to supervised learning under distribution shift. This
characterization shows an important interplay between estimation error,
approximation error, and exploration (as characterized through a precisely
defined condition number).
</p>
<a href="http://arxiv.org/abs/1908.00261">arXiv:1908.00261</a> [<a href="http://arxiv.org/pdf/1908.00261">pdf</a>]

<h2>Deep neural network solution of the electronic Schr\"odinger equation. (arXiv:1909.08423v5 [physics.comp-ph] UPDATED)</h2>
<h3>Jan Hermann, Zeno Sch&#xe4;tzle, Frank No&#xe9;</h3>
<p>[New and updated results were published in Nature Chemistry,
doi:10.1038/s41557-020-0544-y.] The electronic Schr\"odinger equation describes
fundamental properties of molecules and materials, but can only be solved
analytically for the hydrogen atom. The numerically exact full
configuration-interaction method is exponentially expensive in the number of
electrons. Quantum Monte Carlo is a possible way out: it scales well to large
molecules, can be parallelized, and its accuracy has, as yet, only been limited
by the flexibility of the used wave function ansatz. Here we propose PauliNet,
a deep-learning wave function ansatz that achieves nearly exact solutions of
the electronic Schr\"odinger equation. PauliNet has a multireference
Hartree-Fock solution built in as a baseline, incorporates the physics of valid
wave functions, and is trained using variational quantum Monte Carlo (VMC).
PauliNet outperforms comparable state-of-the-art VMC ansatzes for atoms,
diatomic molecules and a strongly-correlated hydrogen chain by a margin and is
yet computationally efficient. We anticipate that thanks to the favourable
scaling with system size, this method may become a new leading method for
highly accurate electronic-strucutre calculations on medium-sized molecular
systems.
</p>
<a href="http://arxiv.org/abs/1909.08423">arXiv:1909.08423</a> [<a href="http://arxiv.org/pdf/1909.08423">pdf</a>]

<h2>Benchmarking Tropical Cyclone Rapid Intensification with Satellite Images and Attention-based Deep Models. (arXiv:1909.11616v2 [cs.LG] UPDATED)</h2>
<h3>Ching-Yuan Bai, Buo-Fu Chen, Hsuan-Tien Lin</h3>
<p>Rapid intensification (RI) of tropical cyclones often causes major
destruction to human civilization due to short response time. It is an
important yet challenging task to accurately predict this kind of extreme
weather event in advance. Traditionally, meteorologists tackle the task with
human-driven feature extraction and predictor correction procedures.
Nevertheless, these procedures do not leverage the power of modern machine
learning models and abundant sensor data, such as satellite images. In
addition, the human-driven nature of such an approach makes it difficult to
reproduce and benchmark prediction models. In this study, we build a benchmark
for RI prediction using only satellite images, which are underutilized in
traditional techniques. The benchmark follows conventional data science
practices, making it easier for data scientists to contribute to RI prediction.
We demonstrate the usefulness of the benchmark by designing a domain-inspired
spatiotemporal deep learning model. The results showcase the promising
performance of deep learning in solving complex meteorological problems such as
RI prediction.
</p>
<a href="http://arxiv.org/abs/1909.11616">arXiv:1909.11616</a> [<a href="http://arxiv.org/pdf/1909.11616">pdf</a>]

<h2>High dimensional regression for regenerative time-series: an application to road traffic modeling. (arXiv:1910.11095v4 [math.ST] UPDATED)</h2>
<h3>Mohammed Bouchouia, Fran&#xe7;ois Portier</h3>
<p>This paper investigates statistical models for road traffic modeling. The
proposed methodology considers road traffic as a (i) high-dimensional
time-series for which (ii) regeneration occurs at the end of each day. Since
(ii), prediction is based on a daily modeling of the road traffic using a
vector autoregressive model that combines linearly the past observations of the
day. Considering (i), the learning algorithm follows from an
$\ell_1$-penalization of the regression coefficients. Excess risk bounds are
established under the high-dimensional framework in which the number of road
sections goes to infinity with the number of observed days. Considering
floating car data observed in an urban area, the approach is compared to
state-of-the-art methods including neural networks. In addition of being very
competitive in terms of prediction, it enables to identify the most determinant
sections of the road network.
</p>
<a href="http://arxiv.org/abs/1910.11095">arXiv:1910.11095</a> [<a href="http://arxiv.org/pdf/1910.11095">pdf</a>]

<h2>Convergence Analysis of a Momentum Algorithm with Adaptive Step Size for Non Convex Optimization. (arXiv:1911.07596v2 [math.OC] UPDATED)</h2>
<h3>Anas Barakat, Pascal Bianchi</h3>
<p>Although ADAM is a very popular algorithm for optimizing the weights of
neural networks, it has been recently shown that it can diverge even in simple
convex optimization examples. Several variants of ADAM have been proposed to
circumvent this convergence issue. In this work, we study the ADAM algorithm
for smooth nonconvex optimization under a boundedness assumption on the
adaptive learning rate. The bound on the adaptive step size depends on the
Lipschitz constant of the gradient of the objective function and provides safe
theoretical adaptive step sizes. Under this boundedness assumption, we show a
novel first order convergence rate result in both deterministic and stochastic
contexts. Furthermore, we establish convergence rates of the function value
sequence using the Kurdyka-Lojasiewicz property.
</p>
<a href="http://arxiv.org/abs/1911.07596">arXiv:1911.07596</a> [<a href="http://arxiv.org/pdf/1911.07596">pdf</a>]

<h2>Learning Algebraic Multigrid Using Graph Neural Networks. (arXiv:2003.05744v2 [cs.LG] UPDATED)</h2>
<h3>Ilay Luz, Meirav Galun, Haggai Maron, Ronen Basri, Irad Yavneh</h3>
<p>Efficient numerical solvers for sparse linear systems are crucial in science
and engineering. One of the fastest methods for solving large-scale sparse
linear systems is algebraic multigrid (AMG). The main challenge in the
construction of AMG algorithms is the selection of the prolongation operator --
a problem-dependent sparse matrix which governs the multiscale hierarchy of the
solver and is critical to its efficiency. Over many years, numerous methods
have been developed for this task, and yet there is no known single right
answer except in very special cases. Here we propose a framework for learning
AMG prolongation operators for linear systems with sparse symmetric positive
(semi-) definite matrices. We train a single graph neural network to learn a
mapping from an entire class of such matrices to prolongation operators, using
an efficient unsupervised loss function. Experiments on a broad class of
problems demonstrate improved convergence rates compared to classical AMG,
demonstrating the potential utility of neural networks for developing sparse
system solvers.
</p>
<a href="http://arxiv.org/abs/2003.05744">arXiv:2003.05744</a> [<a href="http://arxiv.org/pdf/2003.05744">pdf</a>]

<h2>From industry-wide parameters to aircraft-centric on-flight inference: improving aeronautics performance prediction with machine learning. (arXiv:2005.05286v2 [stat.AP] UPDATED)</h2>
<h3>Florent Dewez, Benjamin Guedj, Vincent Vandewalle</h3>
<p>Aircraft performance models play a key role in airline operations, especially
in planning a fuel-efficient flight. In practice, manufacturers provide
guidelines which are slightly modified throughout the aircraft life cycle via
the tuning of a single factor, enabling better fuel predictions. However this
has limitations, in particular they do not reflect the evolution of each
feature impacting the aircraft performance. Our goal here is to overcome this
limitation. The key contribution of the present article is to foster the use of
machine learning to leverage the massive amounts of data continuously recorded
during flights performed by an aircraft and provide models reflecting its
actual and individual performance. We illustrate our approach by focusing on
the estimation of the drag and lift coefficients from recorded flight data. As
these coefficients are not directly recorded, we resort to aerodynamics
approximations. As a safety check, we provide bounds to assess the accuracy of
both the aerodynamics approximation and the statistical performance of our
approach. We provide numerical results on a collection of machine learning
algorithms. We report excellent accuracy on real-life data and exhibit
empirical evidence to support our modelling, in coherence with aerodynamics
principles.
</p>
<a href="http://arxiv.org/abs/2005.05286">arXiv:2005.05286</a> [<a href="http://arxiv.org/pdf/2005.05286">pdf</a>]

<h2>Evolve To Control: Evolution-based Soft Actor-Critic for Scalable Reinforcement Learning. (arXiv:2007.13690v2 [cs.LG] UPDATED)</h2>
<h3>Karush Suri, Xiao Qi Shi, Konstantinos N. Plataniotis, Yuri A. Lawryshyn</h3>
<p>Advances in Reinforcement Learning (RL) have successfully tackled sample
efficiency and overestimation bias. However, these methods often fall short of
scalable performance. On the other hand, genetic methods provide scalability
but depict hyperparameter sensitivity to evolutionary operations. We present
the Evolution-based Soft Actor-Critic (ESAC), a scalable RL algorithm. Our
contributions are threefold; ESAC (1) abstracts exploration from exploitation
by combining Evolution Strategies (ES) with Soft Actor-Critic (SAC), (2)
provides dominant skill transfer between offsprings by making use of soft
winner selections and genetic crossovers in hindsight and (3) improves
hyperparameter sensitivity in evolutions using Automatic Mutation Tuning (AMT).
AMT gradually replaces the entropy framework of SAC allowing the population to
succeed at the task while acting as randomly as possible, without making use of
backpropagation updates. On a range of challenging control tasks consisting of
high-dimensional action spaces and sparse rewards, ESAC demonstrates
state-of-the-art performance and sample efficiency equivalent to SAC. ESAC
demonstrates scalability comparable to ES on the basis of hardware resources
and algorithm overhead. A complete implementation of ESAC with notes on
reproducibility and videos can be found at the project website
https://karush17.github.io/esac-web/.
</p>
<a href="http://arxiv.org/abs/2007.13690">arXiv:2007.13690</a> [<a href="http://arxiv.org/pdf/2007.13690">pdf</a>]

<h2>TREX: Tree-Ensemble Representer-Point Explanations. (arXiv:2009.05530v2 [cs.LG] UPDATED)</h2>
<h3>Jonathan Brophy, Daniel Lowd</h3>
<p>How can we identify the training examples that contribute most to the
prediction of a tree ensemble? In this paper, we introduce TREX, an explanation
system that provides instance-attribution explanations for tree ensembles, such
as random forests and gradient boosted trees. TREX builds on the representer
point framework previously developed for explaining deep neural networks. Since
tree ensembles are non-differentiable, we define a kernel that captures the
structure of the specific tree ensemble. By using this kernel in kernel
logistic regression or a support vector machine, TREX builds a surrogate model
that approximates the original tree ensemble. The weights in the kernel
expansion of the surrogate model are used to define the global or local
importance of each training example.

Our experiments show that TREX's surrogate model accurately approximates the
tree ensemble; its global importance weights are more effective in dataset
debugging than the previous state-of-the-art; its explanations identify the
most influential samples better than alternative methods under the remove and
retrain evaluation framework; it runs orders of magnitude faster than
alternative methods; and its local explanations can identify and explain errors
due to domain mismatch.
</p>
<a href="http://arxiv.org/abs/2009.05530">arXiv:2009.05530</a> [<a href="http://arxiv.org/pdf/2009.05530">pdf</a>]

<h2>Transfer Learning in Deep Reinforcement Learning: A Survey. (arXiv:2009.07888v2 [cs.LG] UPDATED)</h2>
<h3>Zhuangdi Zhu, Kaixiang Lin, Jiayu Zhou</h3>
<p>This paper surveys the field of transfer learning in the problem setting of
Reinforcement Learning (RL). RL has been a key solution to sequential
decision-making problems. Along with the fast advances of RL in various
domains, such as robotics and game-playing, transfer learning arises as an
important technique to assist RL by leveraging and transferring external
expertise to boost the learning process of RL. In this survey, we review the
central issues of transfer learning in the RL domain, providing a systematic
categorization of its state-of-the-art techniques. We analyze their goals,
methodologies, applications, and the RL frameworks under which the transfer
learning techniques are approachable. We discuss the relationship between
transfer learning and other relevant topics from the RL perspective and also
explore the potential challenges as well as future development directions for
transfer learning in RL.
</p>
<a href="http://arxiv.org/abs/2009.07888">arXiv:2009.07888</a> [<a href="http://arxiv.org/pdf/2009.07888">pdf</a>]

<h2>Deep multi-stations weather forecasting: explainable recurrent convolutional neural networks. (arXiv:2009.11239v2 [cs.LG] UPDATED)</h2>
<h3>Ismail Alaoui Abdellaoui, Siamak Mehrkanoon</h3>
<p>Deep learning applied to weather forecasting has started gaining popularity
because of the progress achieved by data-driven models. The present paper
compares four different deep learning architectures to perform weather
prediction on daily data gathered from 18 cities across Europe and spanned over
a period of 15 years. The four proposed models investigate the different type
of input representations (i.e. tensorial unistream vs. multi-stream matrices)
as well as the combination of convolutional neural networks and LSTM (i.e.
cascaded vs. ConvLSTM). In particular, we show that a model that uses a
multi-stream input representation and that processes each lag individually
combined with a cascaded convolution and LSTM is capable of better forecasting
than the other compared models. In addition, we show that visualization
techniques such as occlusion analysis and score maximization can give an
additional insight on the most important features and cities for predicting a
particular target feature and city.
</p>
<a href="http://arxiv.org/abs/2009.11239">arXiv:2009.11239</a> [<a href="http://arxiv.org/pdf/2009.11239">pdf</a>]
