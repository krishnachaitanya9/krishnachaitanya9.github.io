---
title: Latest Deep Learning Papers
date: 2021-02-09 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (169 Articles)</h1>
<h2>Concentrated Document Topic Model. (arXiv:2102.04449v1 [stat.ML])</h2>
<h3>Hao Lei, Ying Chen</h3>
<p>We propose a Concentrated Document Topic Model(CDTM) for unsupervised text
classification, which is able to produce a concentrated and sparse document
topic distribution. In particular, an exponential entropy penalty is imposed on
the document topic distribution. Documents that have diverse topic
distributions are penalized more, while those having concentrated topics are
penalized less. We apply the model to the benchmark NIPS dataset and observe
more coherent topics and more concentrated and sparse document-topic
distributions than Latent Dirichlet Allocation(LDA).
</p>
<a href="http://arxiv.org/abs/2102.04449" target="_blank">arXiv:2102.04449</a> [<a href="http://arxiv.org/pdf/2102.04449" target="_blank">pdf</a>]

<h2>Noise Optimization for Artificial Neural Networks. (arXiv:2102.04450v1 [cs.LG])</h2>
<h3>Li Xiao, Zeliang Zhang, Yijie Peng</h3>
<p>Adding noises to artificial neural network(ANN) has been shown to be able to
improve robustness in previous work. In this work, we propose a new technique
to compute the pathwise stochastic gradient estimate with respect to the
standard deviation of the Gaussian noise added to each neuron of the ANN. By
our proposed technique, the gradient estimate with respect to noise levels is a
byproduct of the backpropagation algorithm for estimating gradient with respect
to synaptic weights in ANN. Thus, the noise level for each neuron can be
optimized simultaneously in the processing of training the synaptic weights at
nearly no extra computational cost. In numerical experiments, our proposed
method can achieve significant performance improvement on robustness of several
popular ANN structures under both black box and white box attacks tested in
various computer vision datasets.
</p>
<a href="http://arxiv.org/abs/2102.04450" target="_blank">arXiv:2102.04450</a> [<a href="http://arxiv.org/pdf/2102.04450" target="_blank">pdf</a>]

<h2>Common Spatial Generative Adversarial Networks based EEG Data Augmentation for Cross-Subject Brain-Computer Interface. (arXiv:2102.04456v1 [cs.LG])</h2>
<h3>Yonghao Song, Lie Yang, Xueyu Jia, Longhan Xie</h3>
<p>The cross-subject application of EEG-based brain-computer interface (BCI) has
always been limited by large individual difference and complex characteristics
that are difficult to perceive. Therefore, it takes a long time to collect the
training data of each user for calibration. Even transfer learning method
pre-training with amounts of subject-independent data cannot decode different
EEG signal categories without enough subject-specific data. Hence, we proposed
a cross-subject EEG classification framework with a generative adversarial
networks (GANs) based method named common spatial GAN (CS-GAN), which used
adversarial training between a generator and a discriminator to obtain
high-quality data for augmentation. A particular module in the discriminator
was employed to maintain the spatial features of the EEG signals and increase
the difference between different categories, with two losses for further
enhancement. Through adaptive training with sufficient augmentation data, our
cross-subject classification accuracy yielded a significant improvement of
15.85% than leave-one subject-out (LOO) test and 8.57% than just adapting 100
original samples on the dataset 2a of BCI competition IV. Moreover, We designed
a convolutional neural networks (CNNs) based classification method as a
benchmark with a similar spatial enhancement idea, which achieved remarkable
results to classify motor imagery EEG data. In summary, our framework provides
a promising way to deal with the cross-subject problem and promote the
practical application of BCI.
</p>
<a href="http://arxiv.org/abs/2102.04456" target="_blank">arXiv:2102.04456</a> [<a href="http://arxiv.org/pdf/2102.04456" target="_blank">pdf</a>]

<h2>Learning-augmented count-min sketches via Bayesian nonparametrics. (arXiv:2102.04462v1 [stat.ML])</h2>
<h3>Emanuele Dolera, Stefano Favaro, Stefano Peluchetti</h3>
<p>The count-min sketch (CMS) is a time and memory efficient randomized data
structure that provides estimates of tokens' frequencies in a data stream, i.e.
point queries, based on random hashed data. Learning-augmented CMSs improve the
CMS by learning models that allow to better exploit data properties. In this
paper, we focus on the learning-augmented CMS of Cai, Mitzenmacher and Adams
(\textit{NeurIPS} 2018), which relies on Bayesian nonparametric (BNP) modeling
of a data stream via Dirichlet process (DP) priors. This is referred to as the
CMS-DP, and it leads to BNP estimates of a point query as posterior means of
the point query given the hashed data. While BNPs is proved to be a powerful
tool for developing robust learning-augmented CMSs, ideas and methods behind
the CMS-DP are tailored to point queries under DP priors, and they can not be
used for other priors or more general queries. In this paper, we present an
alternative, and more flexible, derivation of the CMS-DP such that: i) it
allows to make use of the Pitman-Yor process (PYP) prior, which is arguably the
most popular generalization of the DP prior; ii) it can be readily applied to
the more general problem of estimating range queries. This leads to develop a
novel learning-augmented CMS under power-law data streams, referred to as the
CMS-PYP, which relies on BNP modeling of the stream via PYP priors.
Applications to synthetic and real data show that the CMS-PYP outperforms the
CMS and the CMS-DP in the estimation of low-frequency tokens; this known to be
a critical feature in natural language processing, where it is indeed common to
encounter power-law data streams.
</p>
<a href="http://arxiv.org/abs/2102.04462" target="_blank">arXiv:2102.04462</a> [<a href="http://arxiv.org/pdf/2102.04462" target="_blank">pdf</a>]

<h2>Adaptive Quantization of Model Updates for Communication-Efficient Federated Learning. (arXiv:2102.04487v1 [cs.LG])</h2>
<h3>Divyansh Jhunjhunwala, Advait Gadhikar, Gauri Joshi, Yonina C. Eldar</h3>
<p>Communication of model updates between client nodes and the central
aggregating server is a major bottleneck in federated learning, especially in
bandwidth-limited settings and high-dimensional models. Gradient quantization
is an effective way of reducing the number of bits required to communicate each
model update, albeit at the cost of having a higher error floor due to the
higher variance of the stochastic gradients. In this work, we propose an
adaptive quantization strategy called AdaQuantFL that aims to achieve
communication efficiency as well as a low error floor by changing the number of
quantization levels during the course of training. Experiments on training deep
neural networks show that our method can converge in much fewer communicated
bits as compared to fixed quantization level setups, with little or no impact
on training and test accuracy.
</p>
<a href="http://arxiv.org/abs/2102.04487" target="_blank">arXiv:2102.04487</a> [<a href="http://arxiv.org/pdf/2102.04487" target="_blank">pdf</a>]

<h2>VS-Quant: Per-vector Scaled Quantization for Accurate Low-Precision Neural Network Inference. (arXiv:2102.04503v1 [cs.LG])</h2>
<h3>Steve Dai, Rangharajan Venkatesan, Haoxing Ren, Brian Zimmer, William J. Dally, Brucek Khailany</h3>
<p>Quantization enables efficient acceleration of deep neural networks by
reducing model memory footprint and exploiting low-cost integer math hardware
units. Quantization maps floating-point weights and activations in a trained
model to low-bitwidth integer values using scale factors. Excessive
quantization, reducing precision too aggressively, results in accuracy
degradation. When scale factors are shared at a coarse granularity across many
dimensions of each tensor, effective precision of individual elements within
the tensor are limited. To reduce quantization-related accuracy loss, we
propose using a separate scale factor for each small vector of ($\approx$16-64)
elements within a single dimension of a tensor. To achieve an efficient
hardware implementation, the per-vector scale factors can be implemented with
low-bitwidth integers when calibrated using a two-level quantization scheme. We
find that per-vector scaling consistently achieves better inference accuracy at
low precision compared to conventional scaling techniques for popular neural
networks without requiring retraining. We also modify a deep learning
accelerator hardware design to study the area and energy overheads of
per-vector scaling support. Our evaluation demonstrates that per-vector scaled
quantization with 4-bit weights and activations achieves 37% area saving and
24% energy saving while maintaining over 75% accuracy for ResNet50 on ImageNet.
4-bit weights and 8-bit activations achieve near-full-precision accuracy for
both BERT-base and BERT-large on SQuAD while reducing area by 26% compared to
an 8-bit baseline.
</p>
<a href="http://arxiv.org/abs/2102.04503" target="_blank">arXiv:2102.04503</a> [<a href="http://arxiv.org/pdf/2102.04503" target="_blank">pdf</a>]

<h2>Oops I Took A Gradient: Scalable Sampling for Discrete Distributions. (arXiv:2102.04509v1 [cs.LG])</h2>
<h3>Will Grathwohl, Kevin Swersky, Milad Hashemi, David Duvenaud, Chris J. Maddison</h3>
<p>We propose a general and scalable approximate sampling strategy for
probabilistic models with discrete variables. Our approach uses gradients of
the likelihood function with respect to its discrete inputs to propose updates
in a Metropolis-Hastings sampler. We show empirically that this approach
outperforms generic samplers in a number of difficult settings including Ising
models, Potts models, restricted Boltzmann machines, and factorial hidden
Markov models. We also demonstrate the use of our improved sampler for training
deep energy-based models on high dimensional discrete data. This approach
outperforms variational auto-encoders and existing energy-based models.
Finally, we give bounds showing that our approach is near-optimal in the class
of samplers which propose local updates.
</p>
<a href="http://arxiv.org/abs/2102.04509" target="_blank">arXiv:2102.04509</a> [<a href="http://arxiv.org/pdf/2102.04509" target="_blank">pdf</a>]

<h2>Leaf Image-based Plant Disease Identification using Color and Texture Features. (arXiv:2102.04515v1 [cs.CV])</h2>
<h3>Nisar Ahmed, Hafiz Muhammad Shahzad Asif, Gulshan Saleem</h3>
<p>Identification of plant disease is usually done through visual inspection or
during laboratory examination which causes delays resulting in yield loss by
the time identification is complete. On the other hand, complex deep learning
models perform the task with reasonable performance but due to their large size
and high computational requirements, they are not suited to mobile and handheld
devices. Our proposed approach contributes automated identification of plant
diseases which follows a sequence of steps involving pre-processing,
segmentation of diseased leaf area, calculation of features based on the
Gray-Level Co-occurrence Matrix (GLCM), feature selection and classification.
In this study, six color features and twenty-two texture features have been
calculated. Support vector machines is used to perform one-vs-one
classification of plant disease. The proposed model of disease identification
provides an accuracy of 98.79% with a standard deviation of 0.57 on 10-fold
cross-validation. The accuracy on a self-collected dataset is 82.47% for
disease identification and 91.40% for healthy and diseased classification. The
reported performance measures are better or comparable to the existing
approaches and highest among the feature-based methods, presenting it as the
most suitable method to automated leaf-based plant disease identification. This
prototype system can be extended by adding more disease categories or targeting
specific crop or disease categories.
</p>
<a href="http://arxiv.org/abs/2102.04515" target="_blank">arXiv:2102.04515</a> [<a href="http://arxiv.org/pdf/2102.04515" target="_blank">pdf</a>]

<h2>A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks. (arXiv:2102.04518v1 [cs.AI])</h2>
<h3>Forest Agostinelli, Alexander Shmakov, Stephen McAleer, Roy Fox, Pierre Baldi</h3>
<p>A* search is an informed search algorithm that uses a heuristic function to
guide the order in which nodes are expanded. Since the computation required to
expand a node and compute the heuristic values for all of its generated
children grows linearly with the size of the action space, A* search can become
impractical for problems with large action spaces. This computational burden
becomes even more apparent when heuristic functions are learned by general, but
computationally expensive, deep neural networks. To address this problem, we
introduce DeepCubeAQ, a deep reinforcement learning and search algorithm that
builds on the DeepCubeA algorithm and deep Q-networks. DeepCubeAQ learns a
heuristic function that, with a single forward pass through a deep neural
network, computes the sum of the transition cost and the heuristic value of all
of the children of a node without explicitly generating any of the children,
eliminating the need for node expansions. DeepCubeAQ then uses a novel variant
of A* search, called AQ* search, that uses the deep Q-network to guide search.
We use DeepCubeAQ to solve the Rubik's cube when formulated with a large action
space that includes 1872 meta-actions and show that this 157-fold increase in
the size of the action space incurs less than a 4-fold increase in computation
time when performing AQ* search and that AQ* search is orders of magnitude
faster than A* search.
</p>
<a href="http://arxiv.org/abs/2102.04518" target="_blank">arXiv:2102.04518</a> [<a href="http://arxiv.org/pdf/2102.04518" target="_blank">pdf</a>]

<h2>Multi-Objective Learning to Predict Pareto Fronts Using Hypervolume Maximization. (arXiv:2102.04523v1 [cs.LG])</h2>
<h3>Timo M. Deist, Monika Grewal, Frank J.W.M. Dankers, Tanja Alderliesten, Peter A.N. Bosman</h3>
<p>Real-world problems are often multi-objective with decision-makers unable to
specify a priori which trade-off between the conflicting objectives is
preferable. Intuitively, building machine learning solutions in such cases
would entail providing multiple predictions that span and uniformly cover the
Pareto front of all optimal trade-off solutions. We propose a novel learning
approach to estimate the Pareto front by maximizing the dominated hypervolume
(HV) of the average loss vectors corresponding to a set of learners, leveraging
established multi-objective optimization methods. In our approach, the set of
learners are trained multi-objectively with a dynamic loss function, wherein
each learner's losses are weighted by their HV maximizing gradients.
Consequently, the learners get trained according to different trade-offs on the
Pareto front, which otherwise is not guaranteed for fixed linear scalarizations
or when optimizing for specific trade-offs per learner without knowing the
shape of the Pareto front. Experiments on three different multi-objective tasks
show that the outputs of the set of learners are indeed well-spread on the
Pareto front. Further, the outputs corresponding to validation samples are also
found to closely follow the trade-offs that were learned from training samples
for our set of benchmark problems.
</p>
<a href="http://arxiv.org/abs/2102.04523" target="_blank">arXiv:2102.04523</a> [<a href="http://arxiv.org/pdf/2102.04523" target="_blank">pdf</a>]

<h2>(AF)2-S3Net: Attentive Feature Fusion with Adaptive Feature Selection for Sparse Semantic Segmentation Network. (arXiv:2102.04530v1 [cs.CV])</h2>
<h3>Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, Bingbing Liu</h3>
<p>Autonomous robotic systems and self driving cars rely on accurate perception
of their surroundings as the safety of the passengers and pedestrians is the
top priority. Semantic segmentation is one the essential components of
environmental perception that provides semantic information of the scene.
Recently, several methods have been introduced for 3D LiDAR semantic
segmentation. While, they can lead to improved performance, they are either
afflicted by high computational complexity, therefore are inefficient, or lack
fine details of smaller instances. To alleviate this problem, we propose
AF2-S3Net, an end-to-end encoder-decoder CNN network for 3D LiDAR semantic
segmentation. We present a novel multi-branch attentive feature fusion module
in the encoder and a unique adaptive feature selection module with feature map
re-weighting in the decoder. Our AF2-S3Net fuses the voxel based learning and
point-based learning into a single framework to effectively process the large
3D scene. Our experimental results show that the proposed method outperforms
the state-of-the-art approaches on the large-scale SemanticKITTI benchmark,
ranking 1st on the competitive public leaderboard competition upon publication.
</p>
<a href="http://arxiv.org/abs/2102.04530" target="_blank">arXiv:2102.04530</a> [<a href="http://arxiv.org/pdf/2102.04530" target="_blank">pdf</a>]

<h2>Learning from Shader Program Traces. (arXiv:2102.04533v1 [cs.LG])</h2>
<h3>Yuting Yang, Connelly Barnes, Adam Finkelstein</h3>
<p>Deep networks for image processing typically learn from RGB pixels. This
paper proposes instead to learn from program traces, the intermediate values
computed during program execution. We study this idea in the context of
pixel~shaders -- programs that generate images, typically running in parallel
(for each pixel) on GPU hardware. The intermediate values computed at each
pixel during program execution form the input to the learned model. In a
variety of applications, models learned from program traces outperform baseline
models learned from RGB, even when augmented with hand-picked shader-specific
features. We also investigate strategies for selecting a subset of trace
features for learning; using just a small subset of the trace still outperforms
the baselines.
</p>
<a href="http://arxiv.org/abs/2102.04533" target="_blank">arXiv:2102.04533</a> [<a href="http://arxiv.org/pdf/2102.04533" target="_blank">pdf</a>]

<h2>A modular framework for extreme weather generation. (arXiv:2102.04534v1 [cs.LG])</h2>
<h3>Bianca Zadrozny, Campbell D. Watson, Daniela Szwarcman, Daniel Civitarese, Dario Oliveira, Eduardo Rodrigues, Jorge Guevara</h3>
<p>Extreme weather events have an enormous impact on society and are expected to
become more frequent and severe with climate change. In this context,
resilience planning becomes crucial for risk mitigation and coping with these
extreme events. Machine learning techniques can play a critical role in
resilience planning through the generation of realistic extreme weather event
scenarios that can be used to evaluate possible mitigation actions. This paper
proposes a modular framework that relies on interchangeable components to
produce extreme weather event scenarios. We discuss possible alternatives for
each of the components and show initial results comparing two approaches on the
task of generating precipitation scenarios.
</p>
<a href="http://arxiv.org/abs/2102.04534" target="_blank">arXiv:2102.04534</a> [<a href="http://arxiv.org/pdf/2102.04534" target="_blank">pdf</a>]

<h2>Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-horizon Competitive Markov Games. (arXiv:2102.04540v1 [cs.LG])</h2>
<h3>Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo</h3>
<p>We study infinite-horizon discounted two-player zero-sum Markov games, and
develop a decentralized algorithm that provably converges to the set of Nash
equilibria under self-play. Our algorithm is based on running an Optimistic
Gradient Descent Ascent algorithm on each state to learn the policies, with a
critic that slowly learns the value of each state. To the best of our
knowledge, this is the first algorithm in this setting that is simultaneously
rational (converging to the opponent's best response when it uses a stationary
policy), convergent (converging to the set of Nash equilibria under self-play),
agnostic (no need to know the actions played by the opponent), symmetric
(players taking symmetric roles in the algorithm), and enjoying a finite-time
last-iterate convergence guarantee, all of which are desirable properties of
decentralized algorithms.
</p>
<a href="http://arxiv.org/abs/2102.04540" target="_blank">arXiv:2102.04540</a> [<a href="http://arxiv.org/pdf/2102.04540" target="_blank">pdf</a>]

<h2>A Ranking Approach to Fair Classification. (arXiv:2102.04565v1 [cs.LG])</h2>
<h3>Jakob Schoeffer, Niklas Kuehl, Isabel Valera</h3>
<p>Algorithmic decision systems are increasingly used in areas such as hiring,
school admission, or loan approval. Typically, these systems rely on labeled
data for training a classification model. However, in many scenarios,
ground-truth labels are unavailable, and instead we have only access to
imperfect labels as the result of (potentially biased) human-made decisions.
Despite being imperfect, historical decisions often contain some useful
information on the unobserved true labels. In this paper, we focus on scenarios
where only imperfect labels are available and propose a new fair ranking-based
decision system, as an alternative to traditional classification algorithms.
Our approach is both intuitive and easy to implement, and thus particularly
suitable for adoption in real-world settings. More in detail, we introduce a
distance-based decision criterion, which incorporates useful information from
historical decisions and accounts for unwanted correlation between protected
and legitimate features. Through extensive experiments on synthetic and
real-world data, we show that our method is fair, as it a) assigns the
desirable outcome to the most qualified individuals, and b) removes the effect
of stereotypes in decision-making, thereby outperforming traditional
classification algorithms. Additionally, we are able to show theoretically that
our method is consistent with a prominent concept of individual fairness which
states that "similar individuals should be treated similarly."
</p>
<a href="http://arxiv.org/abs/2102.04565" target="_blank">arXiv:2102.04565</a> [<a href="http://arxiv.org/pdf/2102.04565" target="_blank">pdf</a>]

<h2>Semantic Segmentation with Labeling Uncertainty and Class Imbalance. (arXiv:2102.04566v1 [cs.CV])</h2>
<h3>Patrik Ol&#xe3; Bressan, Jos&#xe9; Marcato Junior, Jos&#xe9; Augusto Correa Martins, Diogo Nunes Gon&#xe7;alves, Daniel Matte Freitas, Lucas Prado Osco, Jonathan de Andrade Silva, Zhipeng Luo, Jonathan Li, Raymundo Cordero Garcia, Wesley Nunes Gon&#xe7;alves</h3>
<p>Recently, methods based on Convolutional Neural Networks (CNN) achieved
impressive success in semantic segmentation tasks. However, challenges such as
the class imbalance and the uncertainty in the pixel-labeling process are not
completely addressed. As such, we present a new approach that calculates a
weight for each pixel considering its class and uncertainty during the labeling
process. The pixel-wise weights are used during training to increase or
decrease the importance of the pixels. Experimental results show that the
proposed approach leads to significant improvements in three challenging
segmentation tasks in comparison to baseline methods. It was also proved to be
more invariant to noise. The approach presented here may be used within a wide
range of semantic segmentation methods to improve their robustness.
</p>
<a href="http://arxiv.org/abs/2102.04566" target="_blank">arXiv:2102.04566</a> [<a href="http://arxiv.org/pdf/2102.04566" target="_blank">pdf</a>]

<h2>RMOPP: Robust Multi-Objective Post-Processing for Effective Object Detection. (arXiv:2102.04582v1 [cs.CV])</h2>
<h3>Mayuresh Savargaonkar, Abdallah Chehade, Samir Rawashdeh</h3>
<p>Over the last few decades, many architectures have been developed that
harness the power of neural networks to detect objects in near real-time.
Training such systems requires substantial time across multiple GPUs and
massive labeled training datasets. Although the goal of these systems is
generalizability, they are often impractical in real-life applications due to
flexibility, robustness, or speed issues. This paper proposes RMOPP: A robust
multi-objective post-processing algorithm to boost the performance of fast
pre-trained object detectors with a negligible impact on their speed.
Specifically, RMOPP is a statistically driven, post-processing algorithm that
allows for simultaneous optimization of precision and recall. A unique feature
of RMOPP is the Pareto frontier that identifies dominant possible
post-processed detectors to optimize for both precision and recall. RMOPP
explores the full potential of a pre-trained object detector and is deployable
for near real-time predictions. We also provide a compelling test case on
YOLOv2 using the MS-COCO dataset.
</p>
<a href="http://arxiv.org/abs/2102.04582" target="_blank">arXiv:2102.04582</a> [<a href="http://arxiv.org/pdf/2102.04582" target="_blank">pdf</a>]

<h2>UVTomo-GAN: An adversarial learning based approach for unknown view X-ray tomographic reconstruction. (arXiv:2102.04590v1 [cs.CV])</h2>
<h3>Mona Zehni, Zhizhen Zhao</h3>
<p>Tomographic reconstruction recovers an unknown image given its projections
from different angles. State-of-the-art methods addressing this problem assume
the angles associated with the projections are known a-priori. Given this
knowledge, the reconstruction process is straightforward as it can be
formulated as a convex problem. Here, we tackle a more challenging setting: 1)
the projection angles are unknown, 2) they are drawn from an unknown
probability distribution. In this set-up our goal is to recover the image and
the projection angle distribution using an unsupervised adversarial learning
approach. For this purpose, we formulate the problem as a distribution matching
between the real projection lines and the generated ones from the estimated
image and projection distribution. This is then solved by reaching the
equilibrium in a min-max game between a generator and a discriminator. Our
novel contribution is to recover the unknown projection distribution and the
image simultaneously using adversarial learning. To accommodate this, we use
Gumbel-softmax approximation of samples from categorical distribution to
approximate the generator's loss as a function of the unknown image and the
projection distribution. Our approach can be generalized to different inverse
problems. Our simulation results reveal the ability of our method in
successfully recovering the image and the projection distribution in various
settings.
</p>
<a href="http://arxiv.org/abs/2102.04590" target="_blank">arXiv:2102.04590</a> [<a href="http://arxiv.org/pdf/2102.04590" target="_blank">pdf</a>]

<h2>Regularized Generative Adversarial Network. (arXiv:2102.04593v1 [cs.LG])</h2>
<h3>Gabriele Di Cerbo, Ali Hirsa, Ahmad Shayaan</h3>
<p>We propose a framework for generating samples from a probability distribution
that differs from the probability distribution of the training set. We use an
adversarial process that simultaneously trains three networks, a generator and
two discriminators. We refer to this new model as regularized generative
adversarial network (RegGAN). We evaluate RegGAN on a synthetic dataset
composed of gray scale images and we further show that it can be used to learn
some pre-specified notions in topology (basic topology properties). The work is
motivated by practical problems encountered while using generative methods in
the art world.
</p>
<a href="http://arxiv.org/abs/2102.04593" target="_blank">arXiv:2102.04593</a> [<a href="http://arxiv.org/pdf/2102.04593" target="_blank">pdf</a>]

<h2>Behavioral Economics Approach to Interpretable Deep Image Classification. Rationally Inattentive Utility Maximization Explains Deep Image Classification. (arXiv:2102.04594v1 [cs.LG])</h2>
<h3>Kunal Pattanayak, Vikram Krishnamurthy</h3>
<p>Are deep convolutional neural networks (CNNs) for image classification
consistent with utility maximization behavior with information acquisition
costs? This paper demonstrates the remarkable result that a deep CNN behaves
equivalently (in terms of necessary and sufficient conditions) to a rationally
inattentive utility maximizer, a model extensively used in behavioral economics
to explain human decision making. This implies that a deep CNN has a
parsimonious representation in terms of simple intuitive human-like decision
parameters, namely, a utility function and an information acquisition cost.
Also the reconstructed utility function that rationalizes the decisions of the
deep CNNs, yields a useful preference order amongst the image classes
(hypotheses).
</p>
<a href="http://arxiv.org/abs/2102.04594" target="_blank">arXiv:2102.04594</a> [<a href="http://arxiv.org/pdf/2102.04594" target="_blank">pdf</a>]

<h2>SwiftNet: Real-time Video Object Segmentation. (arXiv:2102.04604v1 [cs.CV])</h2>
<h3>Haochen Wang, Xiaolong Jiang, Haibing Ren, Yao Hu, Song Bai</h3>
<p>In this work we present SwiftNet for real-time semi-supervised video object
segmentation (one-shot VOS), which reports 77.8% J&amp;F and 70 FPS on DAVIS 2017
validation dataset, leading all present solutions in overall accuracy and speed
performance. We achieve this by elaborately compressing spatiotemporal
redundancy in matching-based VOS via Pixel-Adaptive Memory (PAM). Temporally,
PAM adaptively triggers memory updates on frames where objects display
noteworthy inter-frame variations. Spatially, PAM selectively performs memory
update and match on dynamic pixels while ignoring the static ones,
significantly reducing redundant computations wasted on segmentation-irrelevant
pixels. To promote efficient reference encoding, light-aggregation encoder is
also introduced in SwiftNet deploying reversed sub-pixel. We hope SwiftNet
could set a strong and efficient baseline for real-time VOS and facilitate its
application in mobile vision.
</p>
<a href="http://arxiv.org/abs/2102.04604" target="_blank">arXiv:2102.04604</a> [<a href="http://arxiv.org/pdf/2102.04604" target="_blank">pdf</a>]

<h2>A New Framework for Variance-Reduced Hamiltonian Monte Carlo. (arXiv:2102.04613v1 [cs.LG])</h2>
<h3>Zhengmian Hu, Feihu Huang, Heng Huang</h3>
<p>We propose a new framework of variance-reduced Hamiltonian Monte Carlo (HMC)
methods for sampling from an $L$-smooth and $m$-strongly log-concave
distribution, based on a unified formulation of biased and unbiased variance
reduction methods. We study the convergence properties for HMC with gradient
estimators which satisfy the Mean-Squared-Error-Bias (MSEB) property. We show
that the unbiased gradient estimators, including SAGA and SVRG, based HMC
methods achieve highest gradient efficiency with small batch size under high
precision regime, and require $\tilde{O}(N + \kappa^2 d^{\frac{1}{2}}
\varepsilon^{-1} + N^{\frac{2}{3}} \kappa^{\frac{4}{3}} d^{\frac{1}{3}}
\varepsilon^{-\frac{2}{3}} )$ gradient complexity to achieve
$\epsilon$-accuracy in 2-Wasserstein distance. Moreover, our HMC methods with
biased gradient estimators, such as SARAH and SARGE, require
$\tilde{O}(N+\sqrt{N} \kappa^2 d^{\frac{1}{2}} \varepsilon^{-1})$ gradient
complexity, which has the same dependency on condition number $\kappa$ and
dimension $d$ as full gradient method, but improves the dependency of sample
size $N$ for a factor of $N^\frac{1}{2}$. Experimental results on both
synthetic and real-world benchmark data show that our new framework
significantly outperforms the full gradient and stochastic gradient HMC
approaches. The earliest version of this paper was submitted to ICML 2020 with
three weak accept but was not finally accepted.
</p>
<a href="http://arxiv.org/abs/2102.04613" target="_blank">arXiv:2102.04613</a> [<a href="http://arxiv.org/pdf/2102.04613" target="_blank">pdf</a>]

<h2>Benford's law: what does it say on adversarial images?. (arXiv:2102.04615v1 [cs.CV])</h2>
<h3>Jo&#xe3;o G. Zago, Fabio L. Baldissera, Eric A. Antonelo, Rodrigo T. Saad</h3>
<p>Convolutional neural networks (CNNs) are fragile to small perturbations in
the input images. These networks are thus prone to malicious attacks that
perturb the inputs to force a misclassification. Such slightly manipulated
images aimed at deceiving the classifier are known as adversarial images. In
this work, we investigate statistical differences between natural images and
adversarial ones. More precisely, we show that employing a proper image
transformation and for a class of adversarial attacks, the distribution of the
leading digit of the pixels in adversarial images deviates from Benford's law.
The stronger the attack, the more distant the resulting distribution is from
Benford's law. Our analysis provides a detailed investigation of this new
approach that can serve as a basis for alternative adversarial example
detection methods that do not need to modify the original CNN classifier
neither work on the raw high-dimensional pixels as features to defend against
attacks.
</p>
<a href="http://arxiv.org/abs/2102.04615" target="_blank">arXiv:2102.04615</a> [<a href="http://arxiv.org/pdf/2102.04615" target="_blank">pdf</a>]

<h2>TraND: Transferable Neighborhood Discovery for Unsupervised Cross-domain Gait Recognition. (arXiv:2102.04621v1 [cs.CV])</h2>
<h3>Jinkai Zheng, Xinchen Liu, Chenggang Yan, Jiyong Zhang, Wu Liu, Xiaoping Zhang, Tao Mei</h3>
<p>Gait, i.e., the movement pattern of human limbs during locomotion, is a
promising biometric for the identification of persons. Despite significant
improvement in gait recognition with deep learning, existing studies still
neglect a more practical but challenging scenario -- unsupervised cross-domain
gait recognition which aims to learn a model on a labeled dataset then adapts
it to an unlabeled dataset. Due to the domain shift and class gap, directly
applying a model trained on one source dataset to other target datasets usually
obtains very poor results. Therefore, this paper proposes a Transferable
Neighborhood Discovery (TraND) framework to bridge the domain gap for
unsupervised cross-domain gait recognition. To learn effective prior knowledge
for gait representation, we first adopt a backbone network pre-trained on the
labeled source data in a supervised manner. Then we design an end-to-end
trainable approach to automatically discover the confident neighborhoods of
unlabeled samples in the latent space. During training, the class consistency
indicator is adopted to select confident neighborhoods of samples based on
their entropy measurements. Moreover, we explore a high-entropy-first neighbor
selection strategy, which can effectively transfer prior knowledge to the
target domain. Our method achieves state-of-the-art results on two public
datasets, i.e., CASIA-B and OU-LP.
</p>
<a href="http://arxiv.org/abs/2102.04621" target="_blank">arXiv:2102.04621</a> [<a href="http://arxiv.org/pdf/2102.04621" target="_blank">pdf</a>]

<h2>Demystifying Code Summarization Models. (arXiv:2102.04625v1 [cs.LG])</h2>
<h3>Yu Wang, Fengjuan Gao, Linzhang Wang</h3>
<p>The last decade has witnessed a rapid advance in machine learning models.
While the black-box nature of these systems allows powerful predictions, it
cannot be directly explained, posing a threat to the continuing democratization
of machine learning technology.

Tackling the challenge of model explainability, research has made significant
progress in demystifying the image classification models. In the same spirit of
these works, this paper studies code summarization models, particularly, given
an input program for which a model makes a prediction, our goal is to reveal
the key features that the model uses for predicting the label of the program.
We realize our approach in HouYi, which we use to evaluate four prominent code
summarization models: extreme summarizer, code2vec, code2seq, and sequence GNN.
Results show that all models base their predictions on syntactic and lexical
properties with little to none semantic implication. Based on this finding, we
present a novel approach to explaining the predictions of code summarization
models through the lens of training data.

Our work opens up this exciting, new direction of studying what models have
learned from source code.
</p>
<a href="http://arxiv.org/abs/2102.04625" target="_blank">arXiv:2102.04625</a> [<a href="http://arxiv.org/pdf/2102.04625" target="_blank">pdf</a>]

<h2>Federated Deep AUC Maximization for Heterogeneous Data with a Constant Communication Complexity. (arXiv:2102.04635v1 [cs.LG])</h2>
<h3>Zhuoning Yuan, Zhishuai Guo, Yi Xu, Yiming Ying, Tianbao Yang</h3>
<p>\underline{D}eep \underline{A}UC (area under the ROC curve)
\underline{M}aximization (DAM) has attracted much attention recently due to its
great potential for imbalanced data classification. However, the research on
\underline{F}ederated \underline{D}eep \underline{A}UC \underline{M}aximization
(FDAM) is still limited. Compared with standard federated learning (FL)
approaches that focus on decomposable minimization objectives, FDAM is more
complicated due to its minimization objective is non-decomposable over
individual examples. In this paper, we propose improved FDAM algorithms for
heterogeneous data by solving the popular non-convex strongly-concave min-max
formulation of DAM in a distributed fashion. A striking result of this paper is
that the communication complexity of the proposed algorithm is a constant
independent of the number of machines and also independent of the accuracy
level, which improves an existing result by orders of magnitude. Of independent
interest, the proposed algorithm can also be applied to a class of
non-convex-strongly-concave min-max problems. The experiments have demonstrated
the effectiveness of our FDAM algorithm on benchmark datasets, and on medical
chest X-ray images from different organizations. Our experiment shows that the
performance of FDAM using data from multiple hospitals can improve the AUC
score on testing data from a single hospital for detecting life-threatening
diseases based on chest radiographs.
</p>
<a href="http://arxiv.org/abs/2102.04635" target="_blank">arXiv:2102.04635</a> [<a href="http://arxiv.org/pdf/2102.04635" target="_blank">pdf</a>]

<h2>Absolute 3D Pose Estimation and Length Measurement of Severely Deformed Fish from Monocular Videos in Longline Fishing. (arXiv:2102.04639v1 [cs.CV])</h2>
<h3>Jie Mei, Jenq-Neng Hwang, Suzanne Romain, Craig Rose, Braden Moore, Kelsey Magrane</h3>
<p>Monocular absolute 3D fish pose estimation allows for efficient fish length
measurement in the longline fisheries, where fishes are under severe
deformation during the catching process. This task is challenging since it
requires locating absolute 3D fish keypoints based on a short monocular video
clip. Unlike related works, which either require expensive 3D ground-truth data
and/or multiple-view images to provide depth information, or are limited to
rigid objects, we propose a novel frame-based method to estimate the absolute
3D fish pose and fish length from a single-view 2D segmentation mask. We first
introduce a relative 3D fish template. By minimizing an objective function, our
method systematically estimates the relative 3D pose of the target fish and
fish 2D keypoints in the image. Finally, with a closed-form solution, the
relative 3D fish pose can help locate absolute 3D keypoints, resulting in the
frame-based absolute fish length measurement, which is further refined based on
the statistical temporal inference for the optimal fish length measurement from
the video clip. Our experiments show that this method can accurately estimate
the absolute 3D fish pose and further measure the absolute length, even
outperforming the state-of-the-art multi-view method.
</p>
<a href="http://arxiv.org/abs/2102.04639" target="_blank">arXiv:2102.04639</a> [<a href="http://arxiv.org/pdf/2102.04639" target="_blank">pdf</a>]

<h2>Large Scale Long-tailed Product Recognition System at Alibaba. (arXiv:2102.04652v1 [cs.CV])</h2>
<h3>Xiangzeng Zhou, Pan Pan, Yun Zheng, Yinghui Xu, Rong Jin</h3>
<p>A practical large scale product recognition system suffers from the
phenomenon of long-tailed imbalanced training data under the E-commercial
circumstance at Alibaba. Besides product images at Alibaba, plenty of image
related side information (e.g. title, tags) reveal rich semantic information
about images. Prior works mainly focus on addressing the long tail problem in
visual perspective only, but lack of consideration of leveraging the side
information. In this paper, we present a novel side information based large
scale visual recognition co-training~(SICoT) system to deal with the long tail
problem by leveraging the image related side information. In the proposed
co-training system, we firstly introduce a bilinear word attention module
aiming to construct a semantic embedding over the noisy side information. A
visual feature and semantic embedding co-training scheme is then designed to
transfer knowledge from classes with abundant training data (head classes) to
classes with few training data (tail classes) in an end-to-end fashion.
Extensive experiments on four challenging large scale datasets, whose numbers
of classes range from one thousand to one million, demonstrate the scalable
effectiveness of the proposed SICoT system in alleviating the long tail
problem. In the visual search platform
Pailitao\footnote{this http URL} at Alibaba, we settle a practical
large scale product recognition application driven by the proposed SICoT
system, and achieve a significant gain of unique visitor~(UV) conversion rate.
</p>
<a href="http://arxiv.org/abs/2102.04652" target="_blank">arXiv:2102.04652</a> [<a href="http://arxiv.org/pdf/2102.04652" target="_blank">pdf</a>]

<h2>Training Federated GANs with Theoretical Guarantees: A Universal Aggregation Approach. (arXiv:2102.04655v1 [cs.LG])</h2>
<h3>Yikai Zhang, Hui Qu, Qi Chang, Huidong Liu, Dimitris Metaxas, Chao Chen</h3>
<p>Recently, Generative Adversarial Networks (GANs) have demonstrated their
potential in federated learning, i.e., learning a centralized model from data
privately hosted by multiple sites. A federatedGAN jointly trains a centralized
generator and multiple private discriminators hosted at different sites. A
major theoretical challenge for the federated GAN is the heterogeneity of the
local data distributions. Traditional approaches cannot guarantee to learn the
target distribution, which isa mixture of the highly different local
distributions. This paper tackles this theoretical challenge, and for the first
time, provides a provably correct framework for federated GAN. We propose a new
approach called Universal Aggregation, which simulates a centralized
discriminator via carefully aggregating the mixture of all private
discriminators. We prove that a generator trained with this simulated
centralized discriminator can learn the desired target distribution. Through
synthetic and real datasets, we show that our method can learn the mixture of
largely different distributions where existing federated GAN methods fail.
</p>
<a href="http://arxiv.org/abs/2102.04655" target="_blank">arXiv:2102.04655</a> [<a href="http://arxiv.org/pdf/2102.04655" target="_blank">pdf</a>]

<h2>Virtual ID Discovery from E-commerce Media at Alibaba: Exploiting Richness of User Click Behavior for Visual Search Relevance. (arXiv:2102.04667v1 [cs.CV])</h2>
<h3>Yanhao Zhang, Pan Pan, Yun Zheng, Kang Zhao, Jianmin Wu, Yinghui Xu, Rong Jin</h3>
<p>Visual search plays an essential role for E-commerce. To meet the search
demands of users and promote shopping experience at Alibaba, visual search
relevance of real-shot images is becoming the bottleneck. Traditional visual
search paradigm is usually based upon supervised learning with labeled data.
However, large-scale categorical labels are required with expensive human
annotations, which limits its applicability and also usually fails in
distinguishing the real-shot images. In this paper, we propose to discover
Virtual ID from user click behavior to improve visual search relevance at
Alibaba. As a totally click-data driven approach, we collect various types of
click data for training deep networks without any human annotations at all. In
particular, Virtual ID are learned as classification supervision with co-click
embedding, which explores image relationship from user co-click behaviors to
guide category prediction and feature learning. Concretely, we deploy Virtual
ID Category Network by integrating first-clicks and switch-clicks as
regularizer. Incorporating triplets and list constraints, Virtual ID Feature
Network is trained in a joint classification and ranking manner. Benefiting
from exploration of user click data, our networks are more effective to encode
richer supervision and better distinguish real-shot images in terms of category
and feature. To validate our method for visual search relevance, we conduct an
extensive set of offline and online experiments on the collected real-shot
images. We consistently achieve better experimental results across all
components, compared with alternative and state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.04667" target="_blank">arXiv:2102.04667</a> [<a href="http://arxiv.org/pdf/2102.04667" target="_blank">pdf</a>]

<h2>MALI: A memory efficient and reverse accurate integrator for Neural ODEs. (arXiv:2102.04668v1 [cs.LG])</h2>
<h3>Juntang Zhuang, Nicha C. Dvornek, Sekhar Tatikonda, James S. Duncan</h3>
<p>Neural ordinary differential equations (Neural ODEs) are a new family of
deep-learning models with continuous depth. However, the numerical estimation
of the gradient in the continuous case is not well solved: existing
implementations of the adjoint method suffer from inaccuracy in reverse-time
trajectory, while the naive method and the adaptive checkpoint adjoint method
(ACA) have a memory cost that grows with integration time. In this project,
based on the asynchronous leapfrog (ALF) solver, we propose the
Memory-efficient ALF Integrator (MALI), which has a constant memory cost
\textit{w.r.t} number of solver steps in integration similar to the adjoint
method, and guarantees accuracy in reverse-time trajectory (hence accuracy in
gradient estimation). We validate MALI in various tasks: on image recognition
tasks, to our knowledge, MALI is the first to enable feasible training of a
Neural ODE on ImageNet and outperform a well-tuned ResNet, while existing
methods fail due to either heavy memory burden or inaccuracy; for time series
modeling, MALI significantly outperforms the adjoint method; and for continuous
generative models, MALI achieves new state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2102.04668" target="_blank">arXiv:2102.04668</a> [<a href="http://arxiv.org/pdf/2102.04668" target="_blank">pdf</a>]

<h2>Visual Search at Alibaba. (arXiv:2102.04674v1 [cs.CV])</h2>
<h3>Yanhao Zhang, Pan Pan, Yun Zheng, Kang Zhao, Yingya Zhang, Xiaofeng Ren, Rong Jin</h3>
<p>This paper introduces the large scale visual search algorithm and system
infrastructure at Alibaba. The following challenges are discussed under the
E-commercial circumstance at Alibaba (a) how to handle heterogeneous image data
and bridge the gap between real-shot images from user query and the online
images. (b) how to deal with large scale indexing for massive updating data.
(c) how to train deep models for effective feature representation without huge
human annotations. (d) how to improve the user engagement by considering the
quality of the content. We take advantage of large image collection of Alibaba
and state-of-the-art deep learning techniques to perform visual search at
scale. We present solutions and implementation details to overcome those
problems and also share our learnings from building such a large scale
commercial visual search engine. Specifically, model and search-based fusion
approach is introduced to effectively predict categories. Also, we propose a
deep CNN model for joint detection and feature learning by mining user click
behavior. The binary index engine is designed to scale up indexing without
compromising recall and precision. Finally, we apply all the stages into an
end-to-end system architecture, which can simultaneously achieve highly
efficient and scalable performance adapting to real-shot images. Extensive
experiments demonstrate the advancement of each module in our system. We hope
visual search at Alibaba becomes more widely incorporated into today's
commercial applications.
</p>
<a href="http://arxiv.org/abs/2102.04674" target="_blank">arXiv:2102.04674</a> [<a href="http://arxiv.org/pdf/2102.04674" target="_blank">pdf</a>]

<h2>Meta-Learning for Koopman Spectral Analysis with Short Time-series. (arXiv:2102.04683v1 [stat.ML])</h2>
<h3>Tomoharu Iwata, Yoshinobu Kawahara</h3>
<p>Koopman spectral analysis has attracted attention for nonlinear dynamical
systems since we can analyze nonlinear dynamics with a linear regime by
embedding data into a Koopman space by a nonlinear function. For the analysis,
we need to find appropriate embedding functions. Although several neural
network-based methods have been proposed for learning embedding functions,
existing methods require long time-series for training neural networks. This
limitation prohibits performing Koopman spectral analysis in applications where
only short time-series are available. In this paper, we propose a meta-learning
method for estimating embedding functions from unseen short time-series by
exploiting knowledge learned from related but different time-series. With the
proposed method, a representation of a given short time-series is obtained by a
bidirectional LSTM for extracting its properties. The embedding function of the
short time-series is modeled by a neural network that depends on the
time-series representation. By sharing the LSTM and neural networks across
multiple time-series, we can learn common knowledge from different time-series
while modeling time-series-specific embedding functions with the time-series
representation. Our model is trained such that the expected test prediction
error is minimized with the episodic training framework. We experimentally
demonstrate that the proposed method achieves better performance in terms of
eigenvalue estimation and future prediction than existing methods.
</p>
<a href="http://arxiv.org/abs/2102.04683" target="_blank">arXiv:2102.04683</a> [<a href="http://arxiv.org/pdf/2102.04683" target="_blank">pdf</a>]

<h2>CorrDetector: A Framework for Structural Corrosion Detection from Drone Images using Ensemble Deep Learning. (arXiv:2102.04686v1 [cs.CV])</h2>
<h3>Abdur Rahim Mohammad Forkan, Yong-Bin Kang, Prem Prakash Jayaraman, Kewen Liao, Rohit Kaul, Graham Morgan, Rajiv Ranjan, Samir Sinha</h3>
<p>In this paper, we propose a new technique that applies automated image
analysis in the area of structural corrosion monitoring and demonstrate
improved efficacy compared to existing approaches. Structural corrosion
monitoring is the initial step of the risk-based maintenance philosophy and
depends on an engineer's assessment regarding the risk of building failure
balanced against the fiscal cost of maintenance. This introduces the
opportunity for human error which is further complicated when restricted to
assessment using drone captured images for those areas not reachable by humans
due to many background noises. The importance of this problem has promoted an
active research community aiming to support the engineer through the use of
artificial intelligence (AI) image analysis for corrosion detection. In this
paper, we advance this area of research with the development of a framework,
CorrDetector. CorrDetector uses a novel ensemble deep learning approach
underpinned by convolutional neural networks (CNNs) for structural
identification and corrosion feature extraction. We provide an empirical
evaluation using real-world images of a complicated structure (e.g.
telecommunication tower) captured by drones, a typical scenario for engineers.
Our study demonstrates that the ensemble approach of \model significantly
outperforms the state-of-the-art in terms of classification accuracy.
</p>
<a href="http://arxiv.org/abs/2102.04686" target="_blank">arXiv:2102.04686</a> [<a href="http://arxiv.org/pdf/2102.04686" target="_blank">pdf</a>]

<h2>Graph-Aided Online Multi-Kernel Learning. (arXiv:2102.04690v1 [cs.LG])</h2>
<h3>Pouya M Ghari, Yanning Shen</h3>
<p>Multi-kernel learning (MKL) has been widely used in function approximation
tasks. The key problem of MKL is to combine kernels in a prescribed dictionary.
Inclusion of irrelevant kernels in the dictionary can deteriorate accuracy of
MKL, and increase the computational complexity. To improve the accuracy of
function approximation and reduce the computational complexity, the present
paper studies data-driven selection of kernels from the dictionary that provide
satisfactory function approximations. Specifically, based on the similarities
among kernels, the novel framework constructs and refines a graph to assist
choosing a subset of kernels. In addition, random feature approximation is
utilized to enable online implementation for sequentially obtained data.
Theoretical analysis shows that our proposed algorithms enjoy tighter
sub-linear regret bound compared with state-of-art graph-based online MKL
alternatives. Experiments on a number of real datasets also showcase the
advantages of our novel graph-aided framework.
</p>
<a href="http://arxiv.org/abs/2102.04690" target="_blank">arXiv:2102.04690</a> [<a href="http://arxiv.org/pdf/2102.04690" target="_blank">pdf</a>]

<h2>Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive Multi-Step Bootstrap. (arXiv:2102.04692v1 [cs.LG])</h2>
<h3>Haike Xu, Tengyu Ma, Simon S. Du</h3>
<p>This paper presents a new model-free algorithm for episodic finite-horizon
Markov Decision Processes (MDP), Adaptive Multi-step Bootstrap (AMB), which
enjoys a stronger gap-dependent regret bound. The first innovation is to
estimate the optimal $Q$-function by combining an optimistic bootstrap with an
adaptive multi-step Monte Carlo rollout. The second innovation is to select the
action with the largest confidence interval length among admissible actions
that are not dominated by any other actions. We show when each state has a
unique optimal action, AMB achieves a gap-dependent regret bound that only
scales with the sum of the inverse of the sub-optimality gaps. In contrast,
Simchowitz and Jamieson (2019) showed all upper-confidence-bound (UCB)
algorithms suffer an additional $\Omega\left(\frac{S}{\Delta_{min}}\right)$
regret due to over-exploration where $\Delta_{min}$ is the minimum
sub-optimality gap and $S$ is the number of states. We further show that for
general MDPs, AMB suffers an additional $\frac{|Z_{mul}|}{\Delta_{min}}$
regret, where $Z_{mul}$ is the set of state-action pairs $(s,a)$'s satisfying
$a$ is a non-unique optimal action for $s$. We complement our upper bound with
a lower bound showing the dependency on $\frac{|Z_{mul}|}{\Delta_{min}}$ is
unavoidable for any consistent algorithm. This lower bound also implies a
separation between reinforcement learning and contextual bandits.
</p>
<a href="http://arxiv.org/abs/2102.04692" target="_blank">arXiv:2102.04692</a> [<a href="http://arxiv.org/pdf/2102.04692" target="_blank">pdf</a>]

<h2>Learning Unsupervised Cross-domain Image-to-Image Translation Using a Shared Discriminator. (arXiv:2102.04699v1 [cs.CV])</h2>
<h3>Rajiv Kumar, Rishabh Dabral, G. Sivakumar</h3>
<p>Unsupervised image-to-image translation is used to transform images from a
source domain to generate images in a target domain without using source-target
image pairs. Promising results have been obtained for this problem in an
adversarial setting using two independent GANs and attention mechanisms. We
propose a new method that uses a single shared discriminator between the two
GANs, which improves the overall efficacy. We assess the qualitative and
quantitative results on image transfiguration, a cross-domain translation task,
in a setting where the target domain shares similar semantics to the source
domain. Our results indicate that even without adding attention mechanisms, our
method performs at par with attention-based methods and generates images of
comparable quality.
</p>
<a href="http://arxiv.org/abs/2102.04699" target="_blank">arXiv:2102.04699</a> [<a href="http://arxiv.org/pdf/2102.04699" target="_blank">pdf</a>]

<h2>Loss Function Discovery for Object Detection via Convergence-Simulation Driven Search. (arXiv:2102.04700v1 [cs.CV])</h2>
<h3>Peidong Liu, Gengwei Zhang, Bochao Wang, Hang Xu, Xiaodan Liang, Yong Jiang, Zhenguo Li</h3>
<p>Designing proper loss functions for vision tasks has been a long-standing
research direction to advance the capability of existing models. For object
detection, the well-established classification and regression loss functions
have been carefully designed by considering diverse learning challenges.
Inspired by the recent progress in network architecture search, it is
interesting to explore the possibility of discovering new loss function
formulations via directly searching the primitive operation combinations. So
that the learned losses not only fit for diverse object detection challenges to
alleviate huge human efforts, but also have better alignment with evaluation
metric and good mathematical convergence property. Beyond the previous
auto-loss works on face recognition and image classification, our work makes
the first attempt to discover new loss functions for the challenging object
detection from primitive operation levels. We propose an effective
convergence-simulation driven evolutionary search algorithm, called
CSE-Autoloss, for speeding up the search progress by regularizing the
mathematical rationality of loss candidates via convergence property
verification and model optimization simulation. CSE-Autoloss involves the
search space that cover a wide range of the possible variants of existing
losses and discovers best-searched loss function combination within a short
time (around 1.5 wall-clock days). We conduct extensive evaluations of loss
function search on popular detectors and validate the good generalization
capability of searched losses across diverse architectures and datasets. Our
experiments show that the best-discovered loss function combinations outperform
default combinations by 1.1% and 0.8% in terms of mAP for two-stage and
one-stage detectors on COCO respectively. Our searched losses are available at
https://github.com/PerdonLiu/CSE-Autoloss.
</p>
<a href="http://arxiv.org/abs/2102.04700" target="_blank">arXiv:2102.04700</a> [<a href="http://arxiv.org/pdf/2102.04700" target="_blank">pdf</a>]

<h2>AttDMM: An Attentive Deep Markov Model for Risk Scoring in Intensive Care Units. (arXiv:2102.04702v1 [cs.LG])</h2>
<h3>Yilmazcan &#xd6;zyurt, Mathias Kraus, Tobias Hatt, Stefan Feuerriegel</h3>
<p>Clinical practice in intensive care units (ICUs) requires early warnings when
a patient's condition is about to deteriorate so that preventive measures can
be undertaken. To this end, prediction algorithms have been developed that
estimate the risk of mortality in ICUs. In this work, we propose a novel
generative deep probabilistic model for real-time risk scoring in ICUs.
Specifically, we develop an attentive deep Markov model called AttDMM. To the
best of our knowledge, AttDMM is the first ICU prediction model that jointly
learns both long-term disease dynamics (via attention) and different disease
states in health trajectory (via a latent variable model). Our evaluations were
based on an established baseline dataset (MIMIC-III) with 53,423 ICU stays. The
results confirm that compared to state-of-the-art baselines, our AttDMM was
superior: AttDMM achieved an area under the receiver operating characteristic
curve (AUROC) of 0.876, which yielded an improvement over the state-of-the-art
method by 2.2%. In addition, the risk score from the AttDMM provided warnings
several hours earlier. Thereby, our model shows a path towards identifying
patients at risk so that health practitioners can intervene early and save
patient lives.
</p>
<a href="http://arxiv.org/abs/2102.04702" target="_blank">arXiv:2102.04702</a> [<a href="http://arxiv.org/pdf/2102.04702" target="_blank">pdf</a>]

<h2>Inapproximability of Minimizing a Pair of DNFs or Binary Decision Trees Defining a Partial Boolean Function. (arXiv:2102.04703v1 [cs.LG])</h2>
<h3>David Stein, Bjoern Andres</h3>
<p>The desire to apply machine learning techniques in safety-critical
environments has renewed interest in the learning of partial functions for
distinguishing between positive, negative and unclear observations. We
contribute to the understanding of the hardness of this problem. Specifically,
we consider partial Boolean functions defined by a pair of Boolean functions
$f, g \colon \{0,1\}^J \to \{0,1\}$ such that $f \cdot g = 0$ and such that $f$
and $g$ are defined by disjunctive normal forms or binary decision trees. We
show: Minimizing the sum of the lengths or depths of these forms while
separating disjoint sets $A \cup B = S \subseteq \{0,1\}^J$ such that $f(A) =
\{1\}$ and $g(B) = \{1\}$ is inapproximable to within $(1 - \epsilon) \ln
(|S|-1)$ for any $\epsilon &gt; 0$, unless P=NP.
</p>
<a href="http://arxiv.org/abs/2102.04703" target="_blank">arXiv:2102.04703</a> [<a href="http://arxiv.org/pdf/2102.04703" target="_blank">pdf</a>]

<h2>Output Perturbation for Differentially Private Convex Optimization with Improved Population Loss Bounds, Runtimes and Applications to Private Adversarial Training. (arXiv:2102.04704v1 [cs.LG])</h2>
<h3>Andrew Lowy, Meisam Razaviyayn</h3>
<p>Finding efficient, easily implementable differentially private (DP)
algorithms that offer strong excess risk bounds is an important problem in
modern machine learning. To date, most work has focused on private empirical
risk minimization (ERM) or private population loss minimization. However, there
are often other objectives--such as fairness, adversarial robustness, or
sensitivity to outliers--besides average performance that are not captured in
the classical ERM setup. To this end, we study a completely general family of
convex, Lipschitz loss functions and establish the first known DP excess risk
and runtime bounds for optimizing this broad class. We provide similar bounds
under additional assumptions of smoothness and/or strong convexity. We also
address private stochastic convex optimization (SCO). While $(\epsilon,
\delta)$-DP ($\delta &gt; 0$) has been the focus of much recent work in private
SCO, proving tight population loss bounds and runtime bounds for $(\epsilon,
0)$-DP remains a challenging open problem. We provide the tightest known
$(\epsilon, 0)$-DP population loss bounds and fastest runtimes under the
presence of (or lack of) smoothness and strong convexity. Our methods extend to
the $\delta &gt; 0$ setting, where we offer the unique benefit of ensuring
differential privacy for arbitrary $\epsilon &gt; 0$ by incorporating a new form
of Gaussian noise. Finally, we apply our theory to two learning frameworks:
tilted ERM and adversarial learning. In particular, our theory quantifies
tradeoffs between adversarial robustness, privacy, and runtime. Our results are
achieved using perhaps the simplest DP algorithm: output perturbation. Although
this method is not novel conceptually, our novel implementation scheme and
analysis show that the power of this method to achieve strong privacy, utility,
and runtime guarantees has not been fully appreciated in prior works.
</p>
<a href="http://arxiv.org/abs/2102.04704" target="_blank">arXiv:2102.04704</a> [<a href="http://arxiv.org/pdf/2102.04704" target="_blank">pdf</a>]

<h2>Interrogating the Black Box: Transparency through Information-Seeking Dialogues. (arXiv:2102.04714v1 [cs.AI])</h2>
<h3>Andrea Aler Tubella, Andreas Theodorou, Juan Carlos Nieves</h3>
<p>This paper is preoccupied with the following question: given a (possibly
opaque) learning system, how can we understand whether its behaviour adheres to
governance constraints? The answer can be quite simple: we just need to "ask"
the system about it. We propose to construct an investigator agent to query a
learning agent -- the suspect agent -- to investigate its adherence to a given
ethical policy in the context of an information-seeking dialogue, modeled in
formal argumentation settings. This formal dialogue framework is the main
contribution of this paper. Through it, we break down compliance checking
mechanisms into three modular components, each of which can be tailored to
various needs in a vast amount of ways: an investigator agent, a suspect agent,
and an acceptance protocol determining whether the responses of the suspect
agent comply with the policy. This acceptance protocol presents a fundamentally
different approach to aggregation: rather than using quantitative methods to
deal with the non-determinism of a learning system, we leverage the use of
argumentation semantics to investigate the notion of properties holding
consistently. Overall, we argue that the introduced formal dialogue framework
opens many avenues both in the area of compliance checking and in the analysis
of properties of opaque systems.
</p>
<a href="http://arxiv.org/abs/2102.04714" target="_blank">arXiv:2102.04714</a> [<a href="http://arxiv.org/pdf/2102.04714" target="_blank">pdf</a>]

<h2>Provable Defense Against Delusive Poisoning. (arXiv:2102.04716v1 [cs.LG])</h2>
<h3>Lue Tao, Lei Feng, Jinfeng Yi, Sheng-Jun Huang, Songcan Chen</h3>
<p>Delusive poisoning is a special kind of attack to obstruct learning, where
the learning performance could be significantly deteriorated by only
manipulating (even slightly) the features of correctly labeled training
examples. By formalizing this malicious attack as finding the worst-case
distribution shift at training time within a specific $\infty$-Wasserstein
ball, we show that minimizing adversarial risk on the poison data is equivalent
to optimizing an upper bound of natural risk on the original data. This implies
that adversarial training can be a principled defense method against delusive
poisoning. To further understand the internal mechanism of the defense, we
disclose that adversarial training can resist the training distribution shift
by preventing the learner from overly relying on non-robust features in a
natural setting. Finally, we complement our theoretical findings with a set of
experiments on popular benchmark datasets, which shows that the defense
withstands six different practical attacks. Both theoretical and empirical
results vote for adversarial training when confronted with delusive poisoning.
</p>
<a href="http://arxiv.org/abs/2102.04716" target="_blank">arXiv:2102.04716</a> [<a href="http://arxiv.org/pdf/2102.04716" target="_blank">pdf</a>]

<h2>Classification of Imbalanced Credit scoring data sets Based on Ensemble Method with the Weighted-Hybrid-Sampling. (arXiv:2102.04721v1 [stat.ML])</h2>
<h3>Xiaofan Liua, Zuoquan Zhanga, Di Wanga</h3>
<p>In the era of big data, the utilization of credit-scoring models to determine
the credit risk of applicants accurately becomes a trend in the future. The
conventional machine learning on credit scoring data sets tends to have poor
classification for the minority class, which may bring huge commercial harm to
banks. In order to classify imbalanced data sets, we propose a new ensemble
algorithm, namely, Weighted-Hybrid-Sampling-Boost (WHSBoost). In data sampling,
we process the imbalanced data sets with weights by the Weighted-SMOTE method
and the Weighted-Under-Sampling method, and thus obtain a balanced training
sample data set with equal weight. In ensemble algorithm, each time we train
the base classifier, the balanced data set is given by the method above. In
order to verify the applicability and robustness of the WHSBoost algorithm, we
performed experiments on the simulation data sets, real benchmark data sets and
real credit scoring data sets, comparing WHSBoost with SMOTE, SMOTEBoost and
HSBoost based on SVM, BPNN, DT and KNN.
</p>
<a href="http://arxiv.org/abs/2102.04721" target="_blank">arXiv:2102.04721</a> [<a href="http://arxiv.org/pdf/2102.04721" target="_blank">pdf</a>]

<h2>Fashion Focus: Multi-modal Retrieval System for Video Commodity Localization in E-commerce. (arXiv:2102.04727v1 [cs.CV])</h2>
<h3>Yanhao Zhang, Qiang Wang, Pan Pan, Yun Zheng, Cheng Da, Siyang Sun, Yinghui Xu</h3>
<p>Nowadays, live-stream and short video shopping in E-commerce have grown
exponentially. However, the sellers are required to manually match images of
the selling products to the timestamp of exhibition in the untrimmed video,
resulting in a complicated process. To solve the problem, we present an
innovative demonstration of multi-modal retrieval system called "Fashion
Focus", which enables to exactly localize the product images in the online
video as the focuses. Different modality contributes to the community
localization, including visual content, linguistic features and interaction
context are jointly investigated via presented multi-modal learning. Our system
employs two procedures for analysis, including video content structuring and
multi-modal retrieval, to automatically achieve accurate video-to-shop
matching. Fashion Focus presents a unified framework that can orientate the
consumers towards relevant product exhibitions during watching videos and help
the sellers to effectively deliver the products over search and recommendation.
</p>
<a href="http://arxiv.org/abs/2102.04727" target="_blank">arXiv:2102.04727</a> [<a href="http://arxiv.org/pdf/2102.04727" target="_blank">pdf</a>]

<h2>Reverb: A Framework For Experience Replay. (arXiv:2102.04736v1 [cs.LG])</h2>
<h3>Albin Cassirer, Gabriel Barth-Maron, Eugene Brevdo, Sabela Ramos, Toby Boyd, Thibault Sottiaux, Manuel Kroiss</h3>
<p>A central component of training in Reinforcement Learning (RL) is Experience:
the data used for training. The mechanisms used to generate and consume this
data have an important effect on the performance of RL algorithms.

In this paper, we introduce Reverb: an efficient, extensible, and easy to use
system designed specifically for experience replay in RL. Reverb is designed to
work efficiently in distributed configurations with up to thousands of
concurrent clients.

The flexible API provides users with the tools to easily and accurately
configure the replay buffer. It includes strategies for selecting and removing
elements from the buffer, as well as options for controlling the ratio between
sampled and inserted elements. This paper presents the core design of Reverb,
gives examples of how it can be applied, and provides empirical results of
Reverb's performance characteristics.
</p>
<a href="http://arxiv.org/abs/2102.04736" target="_blank">arXiv:2102.04736</a> [<a href="http://arxiv.org/pdf/2102.04736" target="_blank">pdf</a>]

<h2>Federated Learning with Local Differential Privacy: Trade-offs between Privacy, Utility, and Communication. (arXiv:2102.04737v1 [cs.LG])</h2>
<h3>Muah Kim, Onur G&#xfc;nl&#xfc;, Rafael F. Schaefer</h3>
<p>Federated learning (FL) allows to train a massive amount of data privately
due to its decentralized structure. Stochastic gradient descent (SGD) is
commonly used for FL due to its good empirical performance, but sensitive user
information can still be inferred from weight updates shared during FL
iterations. We consider Gaussian mechanisms to preserve local differential
privacy (LDP) of user data in the FL model with SGD. The trade-offs between
user privacy, global utility, and transmission rate are proved by defining
appropriate metrics for FL with LDP. Compared to existing results, the query
sensitivity used in LDP is defined as a variable and a tighter privacy
accounting method is applied. The proposed utility bound allows heterogeneous
parameters over all users. Our bounds characterize how much utility decreases
and transmission rate increases if a stronger privacy regime is targeted.
Furthermore, given a target privacy level, our results guarantee a
significantly larger utility and a smaller transmission rate as compared to
existing privacy accounting methods.
</p>
<a href="http://arxiv.org/abs/2102.04737" target="_blank">arXiv:2102.04737</a> [<a href="http://arxiv.org/pdf/2102.04737" target="_blank">pdf</a>]

<h2>End-to-End Deep Learning of Lane Detection and Path Prediction for Real-Time Autonomous Driving. (arXiv:2102.04738v1 [cs.CV])</h2>
<h3>Der-Hau Lee, Jinn-Liang Liu</h3>
<p>We propose an end-to-end three-task convolutional neural network (3TCNN)
having two regression branches of bounding boxes and Hu moments and one
classification branch of object masks for lane detection and road recognition.
The Hu-moment regressor performs lane localization and road guidance using
local and global Hu moments of segmented lane objects, respectively. Based on
3TCNN, we then propose lateral offset and path prediction (PP) algorithms to
form an integrated model (3TCNN-PP) that can predict driving path with dynamic
estimation of lane centerline and path curvature for real-time autonomous
driving. We also develop a CNN-PP simulator that can be used to train a CNN by
real or artificial traffic images, test it by artificial images, quantify its
dynamic errors, and visualize its qualitative performance. Simulation results
show that 3TCNN-PP is comparable to related CNNs and better than a previous
CNN-PP, respectively. The code, annotated data, and simulation videos of this
work can be found on our website for further research on NN-PP algorithms of
autonomous driving.
</p>
<a href="http://arxiv.org/abs/2102.04738" target="_blank">arXiv:2102.04738</a> [<a href="http://arxiv.org/pdf/2102.04738" target="_blank">pdf</a>]

<h2>Where is my hand? Deep hand segmentation for visual self-recognition in humanoid robots. (arXiv:2102.04750v1 [cs.RO])</h2>
<h3>Alexandre Almeida, Pedro Vicente, Alexandre Bernardino</h3>
<p>The ability to distinguish between the self and the background is of
paramount importance for robotic tasks. The particular case of hands, as the
end effectors of a robotic system that more often enter into contact with other
elements of the environment, must be perceived and tracked with precision to
execute the intended tasks with dexterity and without colliding with obstacles.
They are fundamental for several applications, from Human-Robot Interaction
tasks to object manipulation. Modern humanoid robots are characterized by high
number of degrees of freedom which makes their forward kinematics models very
sensitive to uncertainty. Thus, resorting to vision sensing can be the only
solution to endow these robots with a good perception of the self, being able
to localize their body parts with precision. In this paper, we propose the use
of a Convolution Neural Network (CNN) to segment the robot hand from an image
in an egocentric view. It is known that CNNs require a huge amount of data to
be trained. To overcome the challenge of labeling real-world images, we propose
the use of simulated datasets exploiting domain randomization techniques. We
fine-tuned the Mask-RCNN network for the specific task of segmenting the hand
of the humanoid robot Vizzy. We focus our attention on developing a methodology
that requires low amounts of data to achieve reasonable performance while
giving detailed insight on how to properly generate variability in the training
dataset. Moreover, we analyze the fine-tuning process within the complex model
of Mask-RCNN, understanding which weights should be transferred to the new task
of segmenting robot hands. Our final model was trained solely on synthetic
images and achieves an average IoU of 82% on synthetic validation data and
56.3% on real test data. These results were achieved with only 1000 training
images and 3 hours of training time using a single GPU.
</p>
<a href="http://arxiv.org/abs/2102.04750" target="_blank">arXiv:2102.04750</a> [<a href="http://arxiv.org/pdf/2102.04750" target="_blank">pdf</a>]

<h2>Improving Visual Reasoning by Exploiting The Knowledge in Texts. (arXiv:2102.04760v1 [cs.CV])</h2>
<h3>Sahand Sharifzadeh, Sina Moayed Baharlou, Martin Schmitt, Hinrich Sch&#xfc;tze, Volker Tresp</h3>
<p>This paper presents a new framework for training image-based classifiers from
a combination of texts and images with very few labels. We consider a
classification framework with three modules: a backbone, a relational reasoning
component, and a classification component. While the backbone can be trained
from unlabeled images by self-supervised learning, we can fine-tune the
relational reasoning and the classification components from external sources of
knowledge instead of annotated images. By proposing a transformer-based model
that creates structured knowledge from textual input, we enable the utilization
of the knowledge in texts. We show that, compared to the supervised baselines
with 1% of the annotated images, we can achieve ~8x more accurate results in
scene graph classification, ~3x in object classification, and ~1.5x in
predicate classification.
</p>
<a href="http://arxiv.org/abs/2102.04760" target="_blank">arXiv:2102.04760</a> [<a href="http://arxiv.org/pdf/2102.04760" target="_blank">pdf</a>]

<h2>Quasi-Global Momentum: Accelerating Decentralized Deep Learning on Heterogeneous Data. (arXiv:2102.04761v1 [cs.LG])</h2>
<h3>Tao Lin, Sai Praneeth Karimireddy, Sebastian U. Stich, Martin Jaggi</h3>
<p>Decentralized training of deep learning models is a key element for enabling
data privacy and on-device learning over networks. In realistic learning
scenarios, the presence of heterogeneity across different clients' local
datasets poses an optimization challenge and may severely deteriorate the
generalization performance.

In this paper, we investigate and identify the limitation of several
decentralized optimization algorithms for different degrees of data
heterogeneity. We propose a novel momentum-based method to mitigate this
decentralized training difficulty. We show in extensive empirical experiments
on various CV/NLP datasets (CIFAR-10, ImageNet, AG News, and SST2) and several
network topologies (Ring and Social Network) that our method is much more
robust to the heterogeneity of clients' data than other existing methods, by a
significant improvement in test performance ($1\% \!-\! 20\%$).
</p>
<a href="http://arxiv.org/abs/2102.04761" target="_blank">arXiv:2102.04761</a> [<a href="http://arxiv.org/pdf/2102.04761" target="_blank">pdf</a>]

<h2>Referring Segmentation in Images and Videos with Cross-Modal Self-Attention Network. (arXiv:2102.04762v1 [cs.CV])</h2>
<h3>Linwei Ye, Mrigank Rochan, Zhi Liu, Xiaoqin Zhang, Yang Wang</h3>
<p>We consider the problem of referring segmentation in images and videos with
natural language. Given an input image (or video) and a referring expression,
the goal is to segment the entity referred by the expression in the image or
video. In this paper, we propose a cross-modal self-attention (CMSA) module to
utilize fine details of individual words and the input image or video, which
effectively captures the long-range dependencies between linguistic and visual
features. Our model can adaptively focus on informative words in the referring
expression and important regions in the visual input. We further propose a
gated multi-level fusion (GMLF) module to selectively integrate self-attentive
cross-modal features corresponding to different levels of visual features. This
module controls the feature fusion of information flow of features at different
levels with high-level and low-level semantic information related to different
attentive words. Besides, we introduce cross-frame self-attention (CFSA) module
to effectively integrate temporal information in consecutive frames which
extends our method in the case of referring segmentation in videos. Experiments
on benchmark datasets of four referring image datasets and two actor and action
video segmentation datasets consistently demonstrate that our proposed approach
outperforms existing state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.04762" target="_blank">arXiv:2102.04762</a> [<a href="http://arxiv.org/pdf/2102.04762" target="_blank">pdf</a>]

<h2>$k$-Anonymity in Practice: How Generalisation and Suppression Affect Machine Learning Classifiers. (arXiv:2102.04763v1 [cs.LG])</h2>
<h3>Djordje Slijep&#x10d;evi&#x107;, Maximilian Henzl, Lukas Daniel Klausner, Tobias Dam, Peter Kieseberg, Matthias Zeppelzauer</h3>
<p>The protection of private information is a crucial issue in data-driven
research and business contexts. Typically, techniques like anonymisation or
(selective) deletion are introduced in order to allow data sharing, \eg\ in the
case of collaborative research endeavours. For use with anonymisation
techniques, the $k$-anonymity criterion is one of the most popular, with
numerous scientific publications on different algorithms and metrics.
Anonymisation techniques often require changing the data and thus necessarily
affect the results of machine learning models trained on the underlying data.
In this work, we conduct a systematic comparison and detailed investigation
into the effects of different $k$-anonymisation algorithms on the results of
machine learning models. We investigate a set of popular $k$-anonymisation
algorithms with different classifiers and evaluate them on different real-world
datasets. Our systematic evaluation shows that with an increasingly strong
$k$-anonymity constraint, the classification performance generally degrades,
but to varying degrees and strongly depending on the dataset and anonymisation
method. Furthermore, Mondrian can be considered as the method with the most
appealing properties for subsequent classification.
</p>
<a href="http://arxiv.org/abs/2102.04763" target="_blank">arXiv:2102.04763</a> [<a href="http://arxiv.org/pdf/2102.04763" target="_blank">pdf</a>]

<h2>Continuous-Time Model-Based Reinforcement Learning. (arXiv:2102.04764v1 [cs.LG])</h2>
<h3>&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z, Markus Heinonen, Harri L&#xe4;hdesm&#xe4;ki</h3>
<p>Model-based reinforcement learning (MBRL) approaches rely on discrete-time
state transition models whereas physical systems and the vast majority of
control tasks operate in continuous-time. To avoid time-discretization
approximation of the underlying process, we propose a continuous-time MBRL
framework based on a novel actor-critic method. Our approach also infers the
unknown state evolution differentials with Bayesian neural ordinary
differential equations (ODE) to account for epistemic uncertainty. We implement
and test our method on a new ODE-RL suite that explicitly solves
continuous-time control systems. Our experiments illustrate that the model is
robust against irregular and noisy data, is sample-efficient, and can solve
control problems which pose challenges to discrete-time MBRL methods.
</p>
<a href="http://arxiv.org/abs/2102.04764" target="_blank">arXiv:2102.04764</a> [<a href="http://arxiv.org/pdf/2102.04764" target="_blank">pdf</a>]

<h2>COLOGNE: Coordinated Local Graph Neighborhood Sampling. (arXiv:2102.04770v1 [cs.LG])</h2>
<h3>Konstantin Kutzkov</h3>
<p>Representation learning for graphs enables the application of standard
machine learning algorithms and data analysis tools to graph data. Replacing
discrete unordered objects such as graph nodes by real-valued vectors is at the
heart of many approaches to learning from graph data. Such vector
representations, or embeddings, capture the discrete relationships in the
original data by representing nodes as vectors in a high-dimensional space.

In most applications graphs model the relationship between real-life objects
and often nodes contain valuable meta-information about the original objects.
While being a powerful machine learning tool, embeddings are not able to
preserve such node attributes. We address this shortcoming and consider the
problem of learning discrete node embeddings such that the coordinates of the
node vector representations are graph nodes. This opens the door to designing
interpretable machine learning algorithms for graphs as all attributes
originally present in the nodes are preserved.

We present a framework for coordinated local graph neighborhood sampling
(COLOGNE) such that each node is represented by a fixed number of graph nodes,
together with their attributes. Individual samples are coordinated and they
preserve the similarity between node neighborhoods. We consider different
notions of similarity for which we design scalable algorithms. We show
theoretical results for all proposed algorithms. Experiments on benchmark
graphs evaluate the quality of the designed embeddings and demonstrate how the
proposed embeddings can be used in training interpretable machine learning
algorithms for graph data.
</p>
<a href="http://arxiv.org/abs/2102.04770" target="_blank">arXiv:2102.04770</a> [<a href="http://arxiv.org/pdf/2102.04770" target="_blank">pdf</a>]

<h2>Structured Diversification Emergence via Reinforced Organization Control and Hierarchical Consensus Learning. (arXiv:2102.04775v1 [cs.LG])</h2>
<h3>Wenhao Li, Xiangfeng Wang, Bo Jin, Junjie Sheng, Yun Hua, Hongyuan Zha</h3>
<p>When solving a complex task, humans will spontaneously form teams and to
complete different parts of the whole task, respectively. Meanwhile, the
cooperation between teammates will improve efficiency. However, for current
cooperative MARL methods, the cooperation team is constructed through either
heuristics or end-to-end blackbox optimization. In order to improve the
efficiency of cooperation and exploration, we propose a structured
diversification emergence MARL framework named {\sc{Rochico}} based on
reinforced organization control and hierarchical consensus learning.
{\sc{Rochico}} first learns an adaptive grouping policy through the
organization control module, which is established by independent multi-agent
reinforcement learning. Further, the hierarchical consensus module based on the
hierarchical intentions with consensus constraint is introduced after team
formation. Simultaneously, utilizing the hierarchical consensus module and a
self-supervised intrinsic reward enhanced decision module, the proposed
cooperative MARL algorithm {\sc{Rochico}} can output the final diversified
multi-agent cooperative policy. All three modules are organically combined to
promote the structured diversification emergence. Comparative experiments on
four large-scale cooperation tasks show that {\sc{Rochico}} is significantly
better than the current SOTA algorithms in terms of exploration efficiency and
cooperation strength.
</p>
<a href="http://arxiv.org/abs/2102.04775" target="_blank">arXiv:2102.04775</a> [<a href="http://arxiv.org/pdf/2102.04775" target="_blank">pdf</a>]

<h2>Generative Models as Distributions of Functions. (arXiv:2102.04776v1 [cs.LG])</h2>
<h3>Emilien Dupont, Yee Whye Teh, Arnaud Doucet</h3>
<p>Generative models are typically trained on grid-like data such as images. As
a result, the size of these models usually scales directly with the underlying
grid resolution. In this paper, we abandon discretized grids and instead
parameterize individual data points by continuous functions. We then build
generative models by learning distributions over such functions. By treating
data points as functions, we can abstract away from the specific type of data
we train on and construct models that scale independently of signal resolution
and dimension. To train our model, we use an adversarial approach with a
discriminator that acts directly on continuous signals. Through experiments on
both images and 3D shapes, we demonstrate that our model can learn rich
distributions of functions independently of data type and resolution.
</p>
<a href="http://arxiv.org/abs/2102.04776" target="_blank">arXiv:2102.04776</a> [<a href="http://arxiv.org/pdf/2102.04776" target="_blank">pdf</a>]

<h2>Diverse Single Image Generation with Controllable Global Structure though Self-Attention. (arXiv:2102.04780v1 [cs.CV])</h2>
<h3>Sutharsan Mahendren, Chamira Edussooriya, Ranga Rodrigo</h3>
<p>Image generation from a single image using generative adversarial networks is
quite interesting due to the realism of generated images. However, recent
approaches need improvement for such realistic and diverse image generation,
when the global context of the image is important such as in face, animal, and
architectural image generation. This is mainly due to the use of fewer
convolutional layers for mainly capturing the patch statistics and, thereby,
not being able to capture global statistics very well. We solve this problem by
using attention blocks at selected scales and feeding a random Gaussian blurred
image to the discriminator for training. Our results are visually better than
the state-of-the-art particularly in generating images that require global
context. The diversity of our image generation, measured using the average
standard deviation of pixels, is also better.
</p>
<a href="http://arxiv.org/abs/2102.04780" target="_blank">arXiv:2102.04780</a> [<a href="http://arxiv.org/pdf/2102.04780" target="_blank">pdf</a>]

<h2>Fast discovery of multidimensional subsequences for robust trajectory classification. (arXiv:2102.04781v1 [cs.LG])</h2>
<h3>Tarlis Portela, Jonata Tyska, Vania Bogorny</h3>
<p>Trajectory classification tasks became more complex as large volumes of
mobility data are being generated every day and enriched with new sources of
information, such as social networks and IoT sensors. Fast classification
algorithms are essential for discovering knowledge in trajectory data for real
applications. In this work we propose a method for fast discovery of
subtrajectories with the reduction of the search space and the optimization of
the MASTERMovelets method, which has proven to be effective for discovering
interpretable patterns in classification problems.
</p>
<a href="http://arxiv.org/abs/2102.04781" target="_blank">arXiv:2102.04781</a> [<a href="http://arxiv.org/pdf/2102.04781" target="_blank">pdf</a>]

<h2>Distribution Adaptive INT8 Quantization for Training CNNs. (arXiv:2102.04782v1 [cs.CV])</h2>
<h3>Kang Zhao, Sida Huang, Pan Pan, Yinghan Li, Yingya Zhang, Zhenyu Gu, Yinghui Xu</h3>
<p>Researches have demonstrated that low bit-width (e.g., INT8) quantization can
be employed to accelerate the inference process. It makes the gradient
quantization very promising since the backward propagation requires
approximately twice more computation than forward one. Due to the variability
and uncertainty of gradient distribution, a lot of methods have been proposed
to attain training stability. However, most of them ignore the channel-wise
gradient distributions and the impact of gradients with different magnitudes,
resulting in the degradation of final accuracy. In this paper, we propose a
novel INT8 quantization training framework for convolutional neural network to
address the above issues. Specifically, we adopt Gradient Vectorized
Quantization to quantize the gradient, based on the observation that layer-wise
gradients contain multiple distributions along the channel dimension. Then,
Magnitude-aware Clipping Strategy is introduced by taking the magnitudes of
gradients into consideration when minimizing the quantization error, and we
present a theoretical derivation to solve the quantization parameters of
different distributions. Experimental results on broad range of computer vision
tasks, such as image classification, object detection and video classification,
demonstrate that the proposed Distribution Adaptive INT8 Quantization training
method has achieved almost lossless training accuracy for different backbones,
including ResNet, MobileNetV2, InceptionV3, VGG and AlexNet, which is superior
to the state-of-the-art techniques. Moreover, we further implement the INT8
kernel that can accelerate the training iteration more than 200% under the
latest Turing architecture, i.e., our method excels on both training accuracy
and speed.
</p>
<a href="http://arxiv.org/abs/2102.04782" target="_blank">arXiv:2102.04782</a> [<a href="http://arxiv.org/pdf/2102.04782" target="_blank">pdf</a>]

<h2>Ensembling object detectors for image and video data analysis. (arXiv:2102.04798v1 [cs.CV])</h2>
<h3>Kateryna Chumachenko, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj</h3>
<p>In this paper, we propose a method for ensembling the outputs of multiple
object detectors for improving detection performance and precision of bounding
boxes on image data. We further extend it to video data by proposing a
two-stage tracking-based scheme for detection refinement. The proposed method
can be used as a standalone approach for improving object detection
performance, or as a part of a framework for faster bounding box annotation in
unseen datasets, assuming that the objects of interest are those present in
some common public datasets.
</p>
<a href="http://arxiv.org/abs/2102.04798" target="_blank">arXiv:2102.04798</a> [<a href="http://arxiv.org/pdf/2102.04798" target="_blank">pdf</a>]

<h2>Automatic variational inference with cascading flows. (arXiv:2102.04801v1 [stat.ML])</h2>
<h3>Luca Ambrogioni, Gianluigi Silvestri, Marcel van Gerven</h3>
<p>The automation of probabilistic reasoning is one of the primary aims of
machine learning. Recently, the confluence of variational inference and deep
learning has led to powerful and flexible automatic inference methods that can
be trained by stochastic gradient descent. In particular, normalizing flows are
highly parameterized deep models that can fit arbitrarily complex posterior
densities. However, normalizing flows struggle in highly structured
probabilistic programs as they need to relearn the forward-pass of the program.
Automatic structured variational inference (ASVI) remedies this problem by
constructing variational programs that embed the forward-pass. Here, we combine
the flexibility of normalizing flows and the prior-embedding property of ASVI
in a new family of variational programs, which we named cascading flows. A
cascading flows program interposes a newly designed highway flow architecture
in between the conditional distributions of the prior program such as to steer
it toward the observed data. These programs can be constructed automatically
from an input probabilistic program and can also be amortized automatically. We
evaluate the performance of the new variational programs in a series of
structured inference problems. We find that cascading flows have much higher
performance than both normalizing flows and ASVI in a large set of structured
inference problems.
</p>
<a href="http://arxiv.org/abs/2102.04801" target="_blank">arXiv:2102.04801</a> [<a href="http://arxiv.org/pdf/2102.04801" target="_blank">pdf</a>]

<h2>DetCo: Unsupervised Contrastive Learning for Object Detection. (arXiv:2102.04803v1 [cs.CV])</h2>
<h3>Enze Xie, Jian Ding, Wenhai Wang, Xiaohang Zhan, Hang Xu, Zhenguo Li, Ping Luo</h3>
<p>Unsupervised contrastive learning achieves great success in learning image
representations with CNN. Unlike most recent methods that focused on improving
accuracy of image classification, we present a novel contrastive learning
approach, named DetCo, which fully explores the contrasts between global image
and local image patches to learn discriminative representations for object
detection. DetCo has several appealing benefits. (1) It is carefully designed
by investigating the weaknesses of current self-supervised methods, which
discard important representations for object detection. (2) DetCo builds
hierarchical intermediate contrastive losses between global image and local
patches to improve object detection, while maintaining global representations
for image recognition. Theoretical analysis shows that the local patches
actually remove the contextual information of an image, improving the lower
bound of mutual information for better contrastive learning. (3) Extensive
experiments on PASCAL VOC, COCO and Cityscapes demonstrate that DetCo not only
outperforms state-of-the-art methods on object detection, but also on
segmentation, pose estimation, and 3D shape prediction, while it is still
competitive on image classification. For example, on PASCAL VOC, DetCo-100ep
achieves 57.4 mAP, which is on par with the result of MoCov2-800ep. Moreover,
DetCo consistently outperforms supervised method by 1.6/1.2/1.0 AP on Mask
RCNN-C4/FPN/RetinaNet with 1x schedule. Code will be released at
\href{https://github.com/xieenze/DetCo}{\color{blue}{\tt
github.com/xieenze/DetCo}} and
\href{https://github.com/open-mmlab/OpenSelfSup}{\color{blue}{\tt
github.com/open-mmlab/OpenSelfSup}}.
</p>
<a href="http://arxiv.org/abs/2102.04803" target="_blank">arXiv:2102.04803</a> [<a href="http://arxiv.org/pdf/2102.04803" target="_blank">pdf</a>]

<h2>Classification of Handwritten Names of Cities and Handwritten Text Recognition using Various Deep Learning Models. (arXiv:2102.04816v1 [cs.CV])</h2>
<h3>Daniyar Nurseitov, Kairat Bostanbekov, Maksat Kanatov, Anel Alimova, Abdelrahman Abdallah, Galymzhan Abdimanap</h3>
<p>This article discusses the problem of handwriting recognition in Kazakh and
Russian languages. This area is poorly studied since in the literature there
are almost no works in this direction. We have tried to describe various
approaches and achievements of recent years in the development of handwritten
recognition models in relation to Cyrillic graphics. The first model uses deep
convolutional neural networks (CNNs) for feature extraction and a fully
connected multilayer perceptron neural network (MLP) for word classification.
The second model, called SimpleHTR, uses CNN and recurrent neural network (RNN)
layers to extract information from images. We also proposed the Bluechet and
Puchserver models to compare the results. Due to the lack of available open
datasets in Russian and Kazakh languages, we carried out work to collect data
that included handwritten names of countries and cities from 42 different
Cyrillic words, written more than 500 times in different handwriting. We also
used a handwritten database of Kazakh and Russian languages (HKR). This is a
new database of Cyrillic words (not only countries and cities) for the Russian
and Kazakh languages, created by the authors of this work.
</p>
<a href="http://arxiv.org/abs/2102.04816" target="_blank">arXiv:2102.04816</a> [<a href="http://arxiv.org/pdf/2102.04816" target="_blank">pdf</a>]

<h2>A Multi-Arm Bandit Approach To Subset Selection Under Constraints. (arXiv:2102.04824v1 [cs.LG])</h2>
<h3>Ayush Deva, Kumar Abhishek, Sujit Gujar</h3>
<p>We explore the class of problems where a central planner needs to select a
subset of agents, each with different quality and cost. The planner wants to
maximize its utility while ensuring that the average quality of the selected
agents is above a certain threshold. When the agents' quality is known, we
formulate our problem as an integer linear program (ILP) and propose a
deterministic algorithm, namely \dpss\ that provides an exact solution to our
ILP.

We then consider the setting when the qualities of the agents are unknown. We
model this as a Multi-Arm Bandit (MAB) problem and propose \newalgo\ to learn
the qualities over multiple rounds. We show that after a certain number of
rounds, $\tau$, \newalgo\ outputs a subset of agents that satisfy the average
quality constraint with a high probability. Next, we provide bounds on $\tau$
and prove that after $\tau$ rounds, the algorithm incurs a regret of $O(\ln
T)$, where $T$ is the total number of rounds. We further illustrate the
efficacy of \newalgo\ through simulations.

To overcome the computational limitations of \dpss, we propose a
polynomial-time greedy algorithm, namely \greedy, that provides an approximate
solution to our ILP. We also compare the performance of \dpss\ and \greedy\
through experiments.
</p>
<a href="http://arxiv.org/abs/2102.04824" target="_blank">arXiv:2102.04824</a> [<a href="http://arxiv.org/pdf/2102.04824" target="_blank">pdf</a>]

<h2>Consensus Control for Decentralized Deep Learning. (arXiv:2102.04828v1 [cs.LG])</h2>
<h3>Lingjing Kong, Tao Lin, Anastasia Koloskova, Martin Jaggi, Sebastian U. Stich</h3>
<p>Decentralized training of deep learning models enables on-device learning
over networks, as well as efficient scaling to large compute clusters.
Experiments in earlier works reveal that, even in a data-center setup,
decentralized training often suffers from the degradation in the quality of the
model: the training and test performance of models trained in a decentralized
fashion is in general worse than that of models trained in a centralized
fashion, and this performance drop is impacted by parameters such as network
size, communication topology and data partitioning.

We identify the changing consensus distance between devices as a key
parameter to explain the gap between centralized and decentralized training. We
show in theory that when the training consensus distance is lower than a
critical quantity, decentralized training converges as fast as the centralized
counterpart. We empirically validate that the relation between generalization
performance and consensus distance is consistent with this theoretical
observation. Our empirical insights allow the principled design of better
decentralized training schemes that mitigate the performance drop. To this end,
we propose practical training guidelines for the data-center setup as the
important first step.
</p>
<a href="http://arxiv.org/abs/2102.04828" target="_blank">arXiv:2102.04828</a> [<a href="http://arxiv.org/pdf/2102.04828" target="_blank">pdf</a>]

<h2>Target Training Does Adversarial Training Without Adversarial Samples. (arXiv:2102.04836v1 [cs.LG])</h2>
<h3>Blerta Lindqvist</h3>
<p>Neural network classifiers are vulnerable to misclassification of adversarial
samples, for which the current best defense trains classifiers with adversarial
samples. However, adversarial samples are not optimal for steering attack
convergence, based on the minimization at the core of adversarial attacks. The
minimization perturbation term can be minimized towards $0$ by replacing
adversarial samples in training with duplicated original samples, labeled
differently only for training. Using only original samples, Target Training
eliminates the need to generate adversarial samples for training against all
attacks that minimize perturbation. In low-capacity classifiers and without
using adversarial samples, Target Training exceeds both default CIFAR10
accuracy ($84.3$%) and current best defense accuracy (below $25$%) with $84.8$%
against CW-L$_2$($\kappa=0$) attack, and $86.6$% against DeepFool. Using
adversarial samples against attacks that do not minimize perturbation, Target
Training exceeds current best defense ($69.1$%) with $76.4$% against
CW-L$_2$($\kappa=40$) in CIFAR10.
</p>
<a href="http://arxiv.org/abs/2102.04836" target="_blank">arXiv:2102.04836</a> [<a href="http://arxiv.org/pdf/2102.04836" target="_blank">pdf</a>]

<h2>A Histogram Thresholding Improvement to Mask R-CNN for Scalable Segmentation of New and Old Rural Buildings. (arXiv:2102.04838v1 [cs.CV])</h2>
<h3>Ying Li, Weipan Xu, Haohui Chen, Junhao Jiang, Xun Li</h3>
<p>Mapping new and old buildings are of great significance for understanding
socio-economic development in rural areas. In recent years, deep neural
networks have achieved remarkable building segmentation results in
high-resolution remote sensing images. However, the scarce training data and
the varying geographical environments have posed challenges for scalable
building segmentation. This study proposes a novel framework based on Mask
R-CNN, named HTMask R-CNN, to extract new and old rural buildings even when the
label is scarce. The framework adopts the result of single-object instance
segmentation from the orthodox Mask R-CNN. Further, it classifies the rural
buildings into new and old ones based on a dynamic grayscale threshold inferred
from the result of a two-object instance segmentation task where training data
is scarce. We found that the framework can extract more buildings and achieve a
much higher mean Average Precision (mAP) than the orthodox Mask R-CNN model. We
tested the novel framework's performance with increasing training data and
found that it converged even when the training samples were limited. This
framework's main contribution is to allow scalable segmentation by using
significantly fewer training samples than traditional machine learning
practices. That makes mapping China's new and old rural buildings viable.
</p>
<a href="http://arxiv.org/abs/2102.04838" target="_blank">arXiv:2102.04838</a> [<a href="http://arxiv.org/pdf/2102.04838" target="_blank">pdf</a>]

<h2>Train a One-Million-Way Instance Classifier for Unsupervised Visual Representation Learning. (arXiv:2102.04848v1 [cs.CV])</h2>
<h3>Yu Liu, Lianghua Huang, Pan Pan, Bin Wang, Yinghui Xu, Rong Jin</h3>
<p>This paper presents a simple unsupervised visual representation learning
method with a pretext task of discriminating all images in a dataset using a
parametric, instance-level classifier. The overall framework is a replica of a
supervised classification model, where semantic classes (e.g., dog, bird, and
ship) are replaced by instance IDs. However, scaling up the classification task
from thousands of semantic labels to millions of instance labels brings
specific challenges including 1) the large-scale softmax computation; 2) the
slow convergence due to the infrequent visiting of instance samples; and 3) the
massive number of negative classes that can be noisy. This work presents
several novel techniques to handle these difficulties. First, we introduce a
hybrid parallel training framework to make large-scale training feasible.
Second, we present a raw-feature initialization mechanism for classification
weights, which we assume offers a contrastive prior for instance discrimination
and can clearly speed up converge in our experiments. Finally, we propose to
smooth the labels of a few hardest classes to avoid optimizing over very
similar negative pairs. While being conceptually simple, our framework achieves
competitive or superior performance compared to state-of-the-art unsupervised
approaches, i.e., SimCLR, MoCoV2, and PIC under ImageNet linear evaluation
protocol and on several downstream visual tasks, verifying that full instance
classification is a strong pretraining technique for many semantic visual
tasks.
</p>
<a href="http://arxiv.org/abs/2102.04848" target="_blank">arXiv:2102.04848</a> [<a href="http://arxiv.org/pdf/2102.04848" target="_blank">pdf</a>]

<h2>Learning a powerful SVM using piece-wise linear loss functions. (arXiv:2102.04849v1 [cs.LG])</h2>
<h3>Pritam Anand</h3>
<p>In this paper, we have considered general k-piece-wise linear convex loss
functions in SVM model for measuring the empirical risk. The resulting
k-Piece-wise Linear loss Support Vector Machine (k-PL-SVM) model is an adaptive
SVM model which can learn a suitable piece-wise linear loss function according
to nature of the given training set. The k-PL-SVM models are general SVM models
and existing popular SVM models, like C-SVM, LS-SVM and Pin-SVM models, are
their particular cases. We have performed the extensive numerical experiments
with k-PL-SVM models for k = 2 and 3 and shown that they are improvement over
existing SVM models.
</p>
<a href="http://arxiv.org/abs/2102.04849" target="_blank">arXiv:2102.04849</a> [<a href="http://arxiv.org/pdf/2102.04849" target="_blank">pdf</a>]

<h2>An underwater binocular stereo matching algorithm based on the best search domain. (arXiv:2102.04860v1 [cs.CV])</h2>
<h3>Yimin Peng, Yunlong Li, Zijing Fang</h3>
<p>Binocular stereo vision is an important branch of machine vision, which
imitates the human eye and matches the left and right images captured by the
camera based on epipolar constraints. The matched disparity map can be
calculated according to the camera imaging model to obtain a depth map, and
then the depth map is converted to a point cloud image to obtain spatial point
coordinates, thereby achieving the purpose of ranging. However, due to the
influence of illumination under water, the captured images no longer meet the
epipolar constraints, and the changes in imaging models make traditional
calibration methods no longer applicable. Therefore, this paper proposes a new
underwater real-time calibration method and a matching method based on the best
search domain to improve the accuracy of underwater distance measurement using
binoculars.
</p>
<a href="http://arxiv.org/abs/2102.04860" target="_blank">arXiv:2102.04860</a> [<a href="http://arxiv.org/pdf/2102.04860" target="_blank">pdf</a>]

<h2>Residue Density Segmentation for Monitoring and Optimizing Tillage Practices. (arXiv:2102.04866v1 [cs.CV])</h2>
<h3>Jennifer Hobbs, Ivan Dozier, Naira Hovakimyan</h3>
<p>"No-till" and cover cropping are often identified as the leading simple, best
management practices for carbon sequestration in agriculture. However, the root
of the problem is more complex, with the potential benefits of these approaches
depending on numerous factors including a field's soil type(s), topography, and
management history. Instead of using computer vision approaches to simply
classify a field a still vs. no-till, we instead seek to identify the degree of
residue coverage across afield through a probabilistic deep learning
segmentation approach to enable more accurate analysis of carbon holding
potential and realization. This approach will not only provide more precise
insights into currently implemented practices, but also enable a more accurate
identification process of fields with the greatest potential for adopting new
practices to significantly impact carbon sequestration in agriculture.
</p>
<a href="http://arxiv.org/abs/2102.04866" target="_blank">arXiv:2102.04866</a> [<a href="http://arxiv.org/pdf/2102.04866" target="_blank">pdf</a>]

<h2>The Factory Must Grow: Automation in Factorio. (arXiv:2102.04871v1 [cs.AI])</h2>
<h3>Kenneth N. Reid, Iliya Miralavy, Stephen Kelly, Wolfgang Banzhaf, Cedric Gondro</h3>
<p>Efficient optimization of resources is paramount to success in many problems
faced today. In the field of operational research the efficient scheduling of
employees; packing of vans; routing of vehicles; logistics of airlines and
transport of materials can be the difference between emission reduction or
excess, profits or losses and feasibility or unworkable solutions. The video
game Factorio, by Wube Software, has a myriad of problems which are analogous
to such real-world problems, and is a useful simulator for developing solutions
for these problems. In this paper we define the logistic transport belt problem
and define mathematical integer programming model of it. We developed an
interface to allow optimizers in any programming language to interact with
Factorio, and we provide an initial benchmark of logistic transport belt
problems. We present results for Simulated Annealing, quick Genetic Programming
and Evolutionary Reinforcement Learning, three different meta-heuristic
techniques to optimize this novel problem.
</p>
<a href="http://arxiv.org/abs/2102.04871" target="_blank">arXiv:2102.04871</a> [<a href="http://arxiv.org/pdf/2102.04871" target="_blank">pdf</a>]

<h2>Noisy Recurrent Neural Networks. (arXiv:2102.04877v1 [stat.ML])</h2>
<h3>Soon Hoe Lim, N. Benjamin Erichson, Liam Hodgkinson, Michael W. Mahoney</h3>
<p>We provide a general framework for studying recurrent neural networks (RNNs)
trained by injecting noise into hidden states. Specifically, we consider RNNs
that can be viewed as discretizations of stochastic differential equations
driven by input data. This framework allows us to study the implicit
regularization effect of general noise injection schemes by deriving an
approximate explicit regularizer in the small noise regime. We find that, under
reasonable assumptions, this implicit regularization promotes flatter minima;
it biases towards models with more stable dynamics; and, in classification
tasks, it favors models with larger classification margin. Sufficient
conditions for global stability are obtained, highlighting the phenomenon of
stochastic stabilization, where noise injection can improve stability during
training. Our theory is supported by empirical results which demonstrate
improved robustness with respect to various input perturbations, while
maintaining state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2102.04877" target="_blank">arXiv:2102.04877</a> [<a href="http://arxiv.org/pdf/2102.04877" target="_blank">pdf</a>]

<h2>Measuring Progress in Deep Reinforcement Learning Sample Efficiency. (arXiv:2102.04881v1 [cs.LG])</h2>
<h3>Florian E. Dorner</h3>
<p>Sampled environment transitions are a critical input to deep reinforcement
learning (DRL) algorithms. Current DRL benchmarks often allow for the cheap and
easy generation of large amounts of samples such that perceived progress in DRL
does not necessarily correspond to improved sample efficiency. As simulating
real world processes is often prohibitively hard and collecting real world
experience is costly, sample efficiency is an important indicator for
economically relevant applications of DRL. We investigate progress in sample
efficiency on Atari games and continuous control tasks by comparing the number
of samples that a variety of algorithms need to reach a given performance level
according to training curves in the corresponding publications. We find
exponential progress in sample efficiency with estimated doubling times of
around 10 to 18 months on Atari, 5 to 24 months on state-based continuous
control and of around 4 to 9 months on pixel-based continuous control depending
on the specific task and performance level.
</p>
<a href="http://arxiv.org/abs/2102.04881" target="_blank">arXiv:2102.04881</a> [<a href="http://arxiv.org/pdf/2102.04881" target="_blank">pdf</a>]

<h2>On Theory-training Neural Networks to Infer the Solution of Highly Coupled Differential Equations. (arXiv:2102.04890v1 [cs.LG])</h2>
<h3>M. Torabi Rad, A. Viardin, M. Apel</h3>
<p>Deep neural networks are transforming fields ranging from computer vision to
computational medicine, and we recently extended their application to the field
of phase-change heat transfer by introducing theory-trained neural networks
(TTNs) for a solidification problem \cite{TTN}. Here, we present general,
in-depth, and empirical insights into theory-training networks for learning the
solution of highly coupled differential equations. We analyze the deteriorating
effects of the oscillating loss on the ability of a network to satisfy the
equations at the training data points, measured by the final training loss, and
on the accuracy of the inferred solution. We introduce a theory-training
technique that, by leveraging regularization, eliminates those oscillations,
decreases the final training loss, and improves the accuracy of the inferred
solution, with no additional computational cost. Then, we present guidelines
that allow a systematic search for the network that has the optimal training
time and inference accuracy for a given set of equations; following these
guidelines can reduce the number of tedious training iterations in that search.
Finally, a comparison between theory-training and the rival, conventional
method of solving differential equations using discretization attests to the
advantages of theory-training not being necessarily limited to high-dimensional
sets of equations. The comparison also reveals a limitation of the current
theory-training framework that may limit its application in domains where
extreme accuracies are necessary.
</p>
<a href="http://arxiv.org/abs/2102.04890" target="_blank">arXiv:2102.04890</a> [<a href="http://arxiv.org/pdf/2102.04890" target="_blank">pdf</a>]

<h2>Learning State Representations from Random Deep Action-conditional Predictions. (arXiv:2102.04897v1 [cs.LG])</h2>
<h3>Zeyu Zheng, Vivek Veeriah, Risto Vuorio, Richard Lewis, Satinder Singh</h3>
<p>In this work, we study auxiliary prediction tasks defined by
temporal-difference networks (TD networks); these networks are a language for
expressing a rich space of general value function (GVF) prediction targets that
may be learned efficiently with TD. Through analysis in an illustrative domain
we show the benefits to learning state representations of exploiting the full
richness of TD networks, including both action-conditional predictions and
temporally deep predictions. Our main (and perhaps surprising) result is that
deep action-conditional TD networks with random structures that create random
prediction-questions about random features yield state representations that are
competitive with state-of-the-art hand-crafted value prediction and pixel
control auxiliary tasks in both Atari games and DeepMind Lab tasks. We also
show through stop-gradient experiments that learning the state representations
solely via these unsupervised random TD network prediction tasks yield agents
that outperform the end-to-end-trained actor-critic baseline.
</p>
<a href="http://arxiv.org/abs/2102.04897" target="_blank">arXiv:2102.04897</a> [<a href="http://arxiv.org/pdf/2102.04897" target="_blank">pdf</a>]

<h2>Dynamic Neural Networks: A Survey. (arXiv:2102.04906v1 [cs.CV])</h2>
<h3>Yizeng Han, Gao Huang, Shiji Song, Le Yang, Honghui Wang, Yulin Wang</h3>
<p>Dynamic neural network is an emerging research topic in deep learning.
Compared to static models which have fixed computational graphs and parameters
at the inference stage, dynamic networks can adapt their structures or
parameters to different inputs, leading to notable advantages in terms of
accuracy, computational efficiency, adaptiveness, etc. In this survey, we
comprehensively review this rapidly developing area by dividing dynamic
networks into three main categories: 1) instance-wise dynamic models that
process each instance with data-dependent architectures or parameters; 2)
spatial-wise dynamic networks that conduct adaptive computation with respect to
different spatial locations of image data and 3) temporal-wise dynamic models
that perform adaptive inference along the temporal dimension for sequential
data such as videos and texts. The important research problems of dynamic
networks, e.g., architecture design, decision making scheme, optimization
technique and applications, are reviewed systematically. Finally, we discuss
the open problems in this field together with interesting future research
directions.
</p>
<a href="http://arxiv.org/abs/2102.04906" target="_blank">arXiv:2102.04906</a> [<a href="http://arxiv.org/pdf/2102.04906" target="_blank">pdf</a>]

<h2>rl_reach: Reproducible Reinforcement Learning Experiments for Robotic Reaching Tasks. (arXiv:2102.04916v1 [cs.LG])</h2>
<h3>Pierre Aumjaud, David McAuliffe, Francisco Javier Rodr&#xed;guez Lera, Philip Cardiff</h3>
<p>Training reinforcement learning agents at solving a given task is highly
dependent on identifying optimal sets of hyperparameters and selecting suitable
environment input / output configurations. This tedious process could be eased
with a straightforward toolbox allowing its user to quickly compare different
training parameter sets. We present rl_reach, a self-contained, open-source and
easy-to-use software package designed to run reproducible reinforcement
learning experiments for customisable robotic reaching tasks. rl_reach packs
together training environments, agents, hyperparameter optimisation tools and
policy evaluation scripts, allowing its users to quickly investigate and
identify optimal training configurations. rl_reach is publicly available at
this URL: https://github.com/PierreExeter/rl_reach.
</p>
<a href="http://arxiv.org/abs/2102.04916" target="_blank">arXiv:2102.04916</a> [<a href="http://arxiv.org/pdf/2102.04916" target="_blank">pdf</a>]

<h2>Affordance-Based Mobile Robot Navigation Among Movable Obstacles. (arXiv:2102.04918v1 [cs.RO])</h2>
<h3>Maozhen Wang, Rui Luo, Aykut Ozgun Onol, Taskin Padir</h3>
<p>Avoiding obstacles in the perceived world has been the classical approach to
autonomous mobile robot navigation. However, this usually leads to unnatural
and inefficient motions that significantly differ from the way humans move in
tight and dynamic spaces, as we do not refrain interacting with the environment
around us when necessary. Inspired by this observation, we propose a framework
for autonomous robot navigation among movable obstacles (NAMO) that is based on
the theory of affordances and contact-implicit motion planning. We consider a
realistic scenario in which a mobile service robot negotiates unknown obstacles
in the environment while navigating to a goal state. An affordance extraction
procedure is performed for novel obstacles to detect their movability, and a
contact-implicit trajectory optimization method is used to enable the robot to
interact with movable obstacles to improve the task performance or to complete
an otherwise infeasible task. We demonstrate the performance of the proposed
framework by hardware experiments with Toyota's Human Support Robot.
</p>
<a href="http://arxiv.org/abs/2102.04918" target="_blank">arXiv:2102.04918</a> [<a href="http://arxiv.org/pdf/2102.04918" target="_blank">pdf</a>]

<h2>More Is More -- Narrowing the Generalization Gap by Adding Classification Heads. (arXiv:2102.04924v1 [cs.LG])</h2>
<h3>Roee Cates, Daphna Weinshall</h3>
<p>Overfit is a fundamental problem in machine learning in general, and in deep
learning in particular. In order to reduce overfit and improve generalization
in the classification of images, some employ invariance to a group of
transformations, such as rotations and reflections. However, since not all
objects exhibit necessarily the same invariance, it seems desirable to allow
the network to learn the useful level of invariance from the data. To this end,
motivated by self-supervision, we introduce an architecture enhancement for
existing neural network models based on input transformations, termed
'TransNet', together with a training algorithm suitable for it. Our model can
be employed during training time only and then pruned for prediction, resulting
in an equivalent architecture to the base model. Thus pruned, we show that our
model improves performance on various data-sets while exhibiting improved
generalization, which is achieved in turn by enforcing soft invariance on the
convolutional kernels of the last layer in the base model. Theoretical analysis
is provided to support the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.04924" target="_blank">arXiv:2102.04924</a> [<a href="http://arxiv.org/pdf/2102.04924" target="_blank">pdf</a>]

<h2>Sparsification via Compressed Sensing for Automatic Speech Recognition. (arXiv:2102.04932v1 [cs.LG])</h2>
<h3>Kai Zhen (1 and 2), Hieu Duy Nguyen (2), Feng-Ju Chang (2), Athanasios Mouchtaris (2), Ariya Rastrow (2). ((1) Indiana University Bloomington, (2) Alexa Machine Learning, Amazon, USA)</h3>
<p>In order to achieve high accuracy for machine learning (ML) applications, it
is essential to employ models with a large number of parameters. Certain
applications, such as Automatic Speech Recognition (ASR), however, require
real-time interactions with users, hence compelling the model to have as low
latency as possible. Deploying large scale ML applications thus necessitates
model quantization and compression, especially when running ML models on
resource constrained devices. For example, by forcing some of the model weight
values into zero, it is possible to apply zero-weight compression, which
reduces both the model size and model reading time from the memory. In the
literature, such methods are referred to as sparse pruning. The fundamental
questions are when and which weights should be forced to zero, i.e. be pruned.
In this work, we propose a compressed sensing based pruning (CSP) approach to
effectively address those questions. By reformulating sparse pruning as a
sparsity inducing and compression-error reduction dual problem, we introduce
the classic compressed sensing process into the ML model training process.
Using ASR task as an example, we show that CSP consistently outperforms
existing approaches in the literature.
</p>
<a href="http://arxiv.org/abs/2102.04932" target="_blank">arXiv:2102.04932</a> [<a href="http://arxiv.org/pdf/2102.04932" target="_blank">pdf</a>]

<h2>RL for Latent MDPs: Regret Guarantees and a Lower Bound. (arXiv:2102.04939v1 [cs.LG])</h2>
<h3>Jeongyeol Kwon, Yonathan Efroni, Constantine Caramanis, Shie Mannor</h3>
<p>In this work, we consider the regret minimization problem for reinforcement
learning in latent Markov Decision Processes (LMDP). In an LMDP, an MDP is
randomly drawn from a set of $M$ possible MDPs at the beginning of the
interaction, but the identity of the chosen MDP is not revealed to the agent.
We first show that a general instance of LMDPs requires at least
$\Omega((SA)^M)$ episodes to even approximate the optimal policy. Then, we
consider sufficient assumptions under which learning good policies requires
polynomial number of episodes. We show that the key link is a notion of
separation between the MDP system dynamics. With sufficient separation, we
provide an efficient algorithm with local guarantee, {\it i.e.,} providing a
sublinear regret guarantee when we are given a good initialization. Finally, if
we are given standard statistical sufficiency assumptions common in the
Predictive State Representation (PSR) literature (e.g., Boots et al.) and a
reachability assumption, we show that the need for initialization can be
removed.
</p>
<a href="http://arxiv.org/abs/2102.04939" target="_blank">arXiv:2102.04939</a> [<a href="http://arxiv.org/pdf/2102.04939" target="_blank">pdf</a>]

<h2>Robust Motion In-betweening. (arXiv:2102.04942v1 [cs.CV])</h2>
<h3>F&#xe9;lix G. Harvey, Mike Yurick, Derek Nowrouzezahrai, Christopher Pal</h3>
<p>In this work we present a novel, robust transition generation technique that
can serve as a new tool for 3D animators, based on adversarial recurrent neural
networks. The system synthesizes high-quality motions that use
temporally-sparse keyframes as animation constraints. This is reminiscent of
the job of in-betweening in traditional animation pipelines, in which an
animator draws motion frames between provided keyframes. We first show that a
state-of-the-art motion prediction model cannot be easily converted into a
robust transition generator when only adding conditioning information about
future keyframes. To solve this problem, we then propose two novel additive
embedding modifiers that are applied at each timestep to latent representations
encoded inside the network's architecture. One modifier is a time-to-arrival
embedding that allows variations of the transition length with a single model.
The other is a scheduled target noise vector that allows the system to be
robust to target distortions and to sample different transitions given fixed
keyframes. To qualitatively evaluate our method, we present a custom
MotionBuilder plugin that uses our trained model to perform in-betweening in
production scenarios. To quantitatively evaluate performance on transitions and
generalizations to longer time horizons, we present well-defined in-betweening
benchmarks on a subset of the widely used Human3.6M dataset and on LaFAN1, a
novel high quality motion capture dataset that is more appropriate for
transition generation. We are releasing this new dataset along with this work,
with accompanying code for reproducing our baseline results.
</p>
<a href="http://arxiv.org/abs/2102.04942" target="_blank">arXiv:2102.04942</a> [<a href="http://arxiv.org/pdf/2102.04942" target="_blank">pdf</a>]

<h2>MISO-wiLDCosts: Multi Information Source Optimization with Location Dependent Costs. (arXiv:2102.04951v1 [cs.LG])</h2>
<h3>Antonio Candelieri, Francesco Archetti</h3>
<p>This paper addresses black-box optimization over multiple information sources
whose both fidelity and query cost change over the search space, that is they
are location dependent. The approach uses: (i) an Augmented Gaussian Process,
recently proposed in multi-information source optimization as a single model of
the objective function over search space and sources, and (ii) a Gaussian
Process to model the location-dependent cost of each source. The former is used
into a Confidence Bound based acquisition function to select the next source
and location to query, while the latter is used to penalize the value of the
acquisition depending on the expected query cost for any source-location pair.
The proposed approach is evaluated on a set of Hyperparameters Optimization
tasks, consisting of two Machine Learning classifiers and three datasets of
different sizes.
</p>
<a href="http://arxiv.org/abs/2102.04951" target="_blank">arXiv:2102.04951</a> [<a href="http://arxiv.org/pdf/2102.04951" target="_blank">pdf</a>]

<h2>Radar-to-Lidar: Heterogeneous Place Recognition via Joint Learning. (arXiv:2102.04960v1 [cs.CV])</h2>
<h3>Huan Yin, Xuecheng Xu, Yue Wang, Rong Xiong</h3>
<p>Place recognition is critical for both offline mapping and online
localization. However, current single-sensor based place recognition still
remains challenging in adverse conditions. In this paper, a heterogeneous
measurements based framework is proposed for long-term place recognition, which
retrieves the query radar scans from the existing lidar maps. To achieve this,
a deep neural network is built with joint training in the learning stage, and
then in the testing stage, shared embeddings of radar and lidar are extracted
for heterogeneous place recognition. To validate the effectiveness of the
proposed method, we conduct tests and generalization on the multi-session
public datasets compared to other competitive methods. The experimental results
indicate that our model is able to perform multiple place recognitions:
lidar-to-lidar, radar-to-radar and radar-to-lidar, while the learned model is
trained only once. We also release the source code publicly.
</p>
<a href="http://arxiv.org/abs/2102.04960" target="_blank">arXiv:2102.04960</a> [<a href="http://arxiv.org/pdf/2102.04960" target="_blank">pdf</a>]

<h2>How Unique Is a Face: An Investigative Study. (arXiv:2102.04965v1 [cs.CV])</h2>
<h3>Michal Balazia, S L Happy, Francois Bremond, Antitza Dantcheva</h3>
<p>Face recognition has been widely accepted as a means of identification in
applications ranging from border control to security in the banking sector.
Surprisingly, while widely accepted, we still lack the understanding of
uniqueness or distinctiveness of faces as biometric modality. In this work, we
study the impact of factors such as image resolution, feature representation,
database size, age and gender on uniqueness denoted by the Kullback-Leibler
divergence between genuine and impostor distributions. Towards understanding
the impact, we present experimental results on the datasets AT&amp;T, LFW,
IMDb-Face, as well as ND-TWINS, with the feature extraction algorithms VGGFace,
VGG16, ResNet50, InceptionV3, MobileNet and DenseNet121, that reveal the
quantitative impact of the named factors. While these are early results, our
findings indicate the need for a better understanding of the concept of
biometric uniqueness and its implication on face recognition.
</p>
<a href="http://arxiv.org/abs/2102.04965" target="_blank">arXiv:2102.04965</a> [<a href="http://arxiv.org/pdf/2102.04965" target="_blank">pdf</a>]

<h2>Semantic Borrowing for Generalized Zero-Shot Learning. (arXiv:2102.04969v1 [cs.LG])</h2>
<h3>Xiao-wei Chen (Sun Yat-sen University)</h3>
<p>Generalized zero-shot learning (GZSL) is one of the most realistic problems,
but also one of the most challenging problems due to the partiality of the
classifier to supervised classes. Instance-borrowing methods and synthesizing
methods solve this problem to some extent with the help of testing semantics,
but therefore neither can be used under the class-inductive instance-inductive
(CIII) training setting where testing data are not available, and the latter
require the training process of a classifier after generating examples. In
contrast, a novel method called Semantic Borrowing for improving GZSL methods
with compatibility metric learning under CIII is proposed in this paper. It
borrows similar semantics in the training set, so that the classifier can model
the relationship between the semantics of zero-shot and supervised classes more
accurately during training. In practice, the information of semantics of unseen
or unknown classes would not be available for training while this approach does
NOT need any information of semantics of unseen or unknown classes. The
experimental results on representative GZSL benchmark datasets show that it can
reduce the partiality of the classifier to supervised classes and improve the
performance of generalized zero-shot classification.
</p>
<a href="http://arxiv.org/abs/2102.04969" target="_blank">arXiv:2102.04969</a> [<a href="http://arxiv.org/pdf/2102.04969" target="_blank">pdf</a>]

<h2>Principles of Explanation in Human-AI Systems. (arXiv:2102.04972v1 [cs.AI])</h2>
<h3>Shane T. Mueller, Elizabeth S. Veinott, Robert R. Hoffman, Gary Klein, Lamia Alam, Tauseef Mamun, William J. Clancey</h3>
<p>Explainable Artificial Intelligence (XAI) has re-emerged in response to the
development of modern AI and ML systems. These systems are complex and
sometimes biased, but they nevertheless make decisions that impact our lives.
XAI systems are frequently algorithm-focused; starting and ending with an
algorithm that implements a basic untested idea about explainability. These
systems are often not tested to determine whether the algorithm helps users
accomplish any goals, and so their explainability remains unproven. We propose
an alternative: to start with human-focused principles for the design, testing,
and implementation of XAI systems, and implement algorithms to serve that
purpose. In this paper, we review some of the basic concepts that have been
used for user-centered XAI systems over the past 40 years of research. Based on
these, we describe the "Self-Explanation Scorecard", which can help developers
understand how they can empower users by enabling self-explanation. Finally, we
present a set of empirically-grounded, user-centered design principles that may
guide developers to create successful explainable systems.
</p>
<a href="http://arxiv.org/abs/2102.04972" target="_blank">arXiv:2102.04972</a> [<a href="http://arxiv.org/pdf/2102.04972" target="_blank">pdf</a>]

<h2>Benchmarking Deep Graph Generative Models for Optimizing New Drug Molecules for COVID-19. (arXiv:2102.04977v1 [cs.LG])</h2>
<h3>Logan Ward, Jenna A. Bilbrey, Sutanay Choudhury, Neeraj Kumar, Ganesh Sivaraman</h3>
<p>Design of new drug compounds with target properties is a key area of research
in generative modeling. We present a small drug molecule design pipeline based
on graph-generative models and a comparison study of two state-of-the-art graph
generative models for designing COVID-19 targeted drug candidates: 1) a
variational autoencoder-based approach (VAE) that uses prior knowledge of
molecules that have been shown to be effective for earlier coronavirus
treatments and 2) a deep Q-learning method (DQN) that generates optimized
molecules without any proximity constraints. We evaluate the novelty of the
automated molecule generation approaches by validating the candidate molecules
with drug-protein binding affinity models. The VAE method produced two novel
molecules with similar structures to the antiretroviral protease inhibitor
Indinavir that show potential binding affinity for the SARS-CoV-2 protein
target 3-chymotrypsin-like protease (3CL-protease).
</p>
<a href="http://arxiv.org/abs/2102.04977" target="_blank">arXiv:2102.04977</a> [<a href="http://arxiv.org/pdf/2102.04977" target="_blank">pdf</a>]

<h2>Telling the What while Pointing the Where: Fine-grained Mouse Trace and Language Supervision for Improved Image Retrieval. (arXiv:2102.04980v1 [cs.CV])</h2>
<h3>Soravit Changpinyo, Jordi Pont-Tuset, Vittorio Ferrari, Radu Soricut</h3>
<p>Existing image retrieval systems use text queries to provide a natural and
practical way for users to express what they are looking for. However,
fine-grained image retrieval often requires the ability to also express the
where in the image the content they are looking for is. The textual modality
can only cumbersomely express such localization preferences, whereas pointing
would be a natural fit. In this paper, we describe an image retrieval setup
where the user simultaneously describes an image using both spoken natural
language (the "what") and mouse traces over an empty canvas (the "where") to
express the characteristics of the desired target image. To this end, we learn
an image retrieval model using the Localized Narratives dataset, which is
capable of performing early fusion between text descriptions and synchronized
mouse traces. Qualitative and quantitative experiments show that our model is
capable of taking this spatial guidance into account, and provides more
accurate retrieval results compared to text-only equivalent systems.
</p>
<a href="http://arxiv.org/abs/2102.04980" target="_blank">arXiv:2102.04980</a> [<a href="http://arxiv.org/pdf/2102.04980" target="_blank">pdf</a>]

<h2>SG2Caps: Revisiting Scene Graphs for Image Captioning. (arXiv:2102.04990v1 [cs.CV])</h2>
<h3>Subarna Tripathi, Kien Nguyen, Tanaya Guha, Bang Du, Truong Q. Nguyen</h3>
<p>The mainstream image captioning models rely on Convolutional Neural Network
(CNN) image features with an additional attention to salient regions and
objects to generate captions via recurrent models. Recently, scene graph
representations of images have been used to augment captioning models so as to
leverage their structural semantics, such as object entities, relationships and
attributes. Several studies have noted that naive use of scene graphs from a
black-box scene graph generator harms image caption-ing performance, and scene
graph-based captioning mod-els have to incur the overhead of explicit use of
image features to generate decent captions. Addressing these challenges, we
propose a framework, SG2Caps, that utilizes only the scene graph labels for
competitive image caption-ing performance. The basic idea is to close the
semantic gap between two scene graphs - one derived from the input image and
the other one from its caption. In order to achieve this, we leverage the
spatial location of objects and the Human-Object-Interaction (HOI) labels as an
additional HOI graph. Our framework outperforms existing scene graph-only
captioning models by a large margin (CIDEr score of 110 vs 71) indicating scene
graphs as a promising representation for image captioning. Direct utilization
of the scene graph labels avoids expensive graph convolutions over
high-dimensional CNN features resulting in 49%fewer trainable parameters.
</p>
<a href="http://arxiv.org/abs/2102.04990" target="_blank">arXiv:2102.04990</a> [<a href="http://arxiv.org/pdf/2102.04990" target="_blank">pdf</a>]

<h2>Deep Neural Network based Cough Detection using Bed-mounted Accelerometer Measurements. (arXiv:2102.04997v1 [cs.LG])</h2>
<h3>Madhurananda Pahar, Igor Miranda, Andreas Diacon, Thomas Niesler</h3>
<p>We have performed cough detection based on measurements from an accelerometer
attached to the patient's bed. This form of monitoring is less intrusive than
body-attached accelerometer sensors, and sidesteps privacy concerns encountered
when using audio for cough detection. For our experiments, we have compiled a
manually-annotated dataset containing the acceleration signals of approximately
6000 cough and 68000 non-cough events from 14 adult male patients in a
tuberculosis clinic. As classifiers, we have considered convolutional neural
networks (CNN), long-short-term-memory (LSTM) networks, and a residual neural
network (Resnet50). We find that all classifiers are able to distinguish
between the acceleration signals due to coughing and those due to other
activities including sneezing, throat-clearing and movement in the bed with
high accuracy. The Resnet50 performs the best, achieving an area under the ROC
curve (AUC) exceeding 0.98 in cross-validation experiments. We conclude that
high-accuracy cough monitoring based only on measurements from the
accelerometer in a consumer smartphone is possible. Since the need to gather
audio is avoided and therefore privacy is inherently protected, and since the
accelerometer is attached to the bed and not worn, this form of monitoring may
represent a more convenient and readily accepted method of long-term patient
cough monitoring.
</p>
<a href="http://arxiv.org/abs/2102.04997" target="_blank">arXiv:2102.04997</a> [<a href="http://arxiv.org/pdf/2102.04997" target="_blank">pdf</a>]

<h2>When does gradient descent with logistic loss interpolate using deep networks with smoothed ReLU activations?. (arXiv:2102.04998v1 [stat.ML])</h2>
<h3>Niladri S. Chatterji, Philip M. Long, Peter L. Bartlett</h3>
<p>We establish conditions under which gradient descent applied to fixed-width
deep networks drives the logistic loss to zero, and prove bounds on the rate of
convergence. Our analysis applies for smoothed approximations to the ReLU, such
as Swish and the Huberized ReLU, proposed in previous applied work. We provide
two sufficient conditions for convergence. The first is simply a bound on the
loss at initialization. The second is a data separation condition used in prior
analyses.
</p>
<a href="http://arxiv.org/abs/2102.04998" target="_blank">arXiv:2102.04998</a> [<a href="http://arxiv.org/pdf/2102.04998" target="_blank">pdf</a>]

<h2>Pairwise Weights for Temporal Credit Assignment. (arXiv:2102.04999v1 [cs.LG])</h2>
<h3>Zeyu Zheng, Risto Vuorio, Richard Lewis, Satinder Singh</h3>
<p>How much credit (or blame) should an action taken in a state get for a future
reward? This is the fundamental temporal credit assignment problem in
Reinforcement Learning (RL). One of the earliest and still most widely used
heuristics is to assign this credit based on a scalar coefficient $\lambda$
(treated as a hyperparameter) raised to the power of the time interval between
the state-action and the reward. In this empirical paper, we explore heuristics
based on more general pairwise weightings that are functions of the state in
which the action was taken, the state at the time of the reward, as well as the
time interval between the two. Of course it isn't clear what these pairwise
weight functions should be, and because they are too complex to be treated as
hyperparameters we develop a metagradient procedure for learning these weight
functions during the usual RL training of a policy. Our empirical work shows
that it is often possible to learn these pairwise weight functions during
learning of the policy to achieve better performance than competing approaches.
</p>
<a href="http://arxiv.org/abs/2102.04999" target="_blank">arXiv:2102.04999</a> [<a href="http://arxiv.org/pdf/2102.04999" target="_blank">pdf</a>]

<h2>An application of a pseudo-parabolic modeling to texture image recognition. (arXiv:2102.05001v1 [cs.CV])</h2>
<h3>Joao B. Florindo, Eduardo Abreu</h3>
<p>In this work, we present a novel methodology for texture image recognition
using a partial differential equation modeling. More specifically, we employ
the pseudo-parabolic Buckley-Leverett equation to provide a dynamics to the
digital image representation and collect local descriptors from those images
evolving in time. For the local descriptors we employ the magnitude and signal
binary patterns and a simple histogram of these features was capable of
achieving promising results in a classification task. We compare the accuracy
over well established benchmark texture databases and the results demonstrate
competitiveness, even with the most modern deep learning approaches. The
achieved results open space for future investigation on this type of modeling
for image analysis, especially when there is no large amount of data for
training deep learning models and therefore model-based approaches arise as
suitable alternatives.
</p>
<a href="http://arxiv.org/abs/2102.05001" target="_blank">arXiv:2102.05001</a> [<a href="http://arxiv.org/pdf/2102.05001" target="_blank">pdf</a>]

<h2>Mars Image Content Classification: Three Years of NASA Deployment and Recent Advances. (arXiv:2102.05011v1 [cs.LG])</h2>
<h3>Kiri Wagstaff (1), Steven Lu (1), Emily Dunkel (1), Kevin Grimes (1), Brandon Zhao (2), Jesse Cai (3), Shoshanna B. Cole (4), Gary Doran (1), Raymond Francis (1), Jake Lee (1), Lukas Mandrake (1) ((1) Jet Propulsion Laboratory, California Institute of Technology, (2) Duke University, (3) California Institute of Technology, (4) Space Science Institute)</h3>
<p>The NASA Planetary Data System hosts millions of images acquired from the
planet Mars. To help users quickly find images of interest, we have developed
and deployed content-based classification and search capabilities for Mars
orbital and surface images. The deployed systems are publicly accessible using
the PDS Image Atlas. We describe the process of training, evaluating,
calibrating, and deploying updates to two CNN classifiers for images collected
by Mars missions. We also report on three years of deployment including usage
statistics, lessons learned, and plans for the future.
</p>
<a href="http://arxiv.org/abs/2102.05011" target="_blank">arXiv:2102.05011</a> [<a href="http://arxiv.org/pdf/2102.05011" target="_blank">pdf</a>]

<h2>Spherical Message Passing for 3D Graph Networks. (arXiv:2102.05013v1 [cs.LG])</h2>
<h3>Yi Liu, Limei Wang, Meng Liu, Xuan Zhang, Bora Oztekin, Shuiwang Ji</h3>
<p>We consider representation learning from 3D graphs in which each node is
associated with a spatial position in 3D. This is an under explored area of
research, and a principled framework is currently lacking. In this work, we
propose a generic framework, known as the 3D graph network (3DGN), to provide a
unified interface at different levels of granularity for 3D graphs. Built on
3DGN, we propose the spherical message passing (SMP) as a novel and specific
scheme for realizing the 3DGN framework in the spherical coordinate system
(SCS). We conduct formal analyses and show that the relative location of each
node in 3D graphs is uniquely defined in the SMP scheme. Thus, our SMP
represents a complete and accurate architecture for learning from 3D graphs in
the SCS. We derive physically-based representations of geometric information
and propose the SphereNet for learning representations of 3D graphs. We show
that existing 3D deep models can be viewed as special cases of the SphereNet.
Experimental results demonstrate that the use of complete and accurate 3D
information in 3DGN and SphereNet leads to significant performance improvements
in prediction tasks.
</p>
<a href="http://arxiv.org/abs/2102.05013" target="_blank">arXiv:2102.05013</a> [<a href="http://arxiv.org/pdf/2102.05013" target="_blank">pdf</a>]

<h2>Robust Bandit Learning with Imperfect Context. (arXiv:2102.05018v1 [cs.LG])</h2>
<h3>Jianyi Yang, Shaolei Ren</h3>
<p>A standard assumption in contextual multi-arm bandit is that the true context
is perfectly known before arm selection. Nonetheless, in many practical
applications (e.g., cloud resource management), prior to arm selection, the
context information can only be acquired by prediction subject to errors or
adversarial modification. In this paper, we study a contextual bandit setting
in which only imperfect context is available for arm selection while the true
context is revealed at the end of each round. We propose two robust arm
selection algorithms: MaxMinUCB (Maximize Minimum UCB) which maximizes the
worst-case reward, and MinWD (Minimize Worst-case Degradation) which minimizes
the worst-case regret. Importantly, we analyze the robustness of MaxMinUCB and
MinWD by deriving both regret and reward bounds compared to an oracle that
knows the true context. Our results show that as time goes on, MaxMinUCB and
MinWD both perform as asymptotically well as their optimal counterparts that
know the reward function. Finally, we apply MaxMinUCB and MinWD to online edge
datacenter selection, and run synthetic simulations to validate our theoretical
analysis.
</p>
<a href="http://arxiv.org/abs/2102.05018" target="_blank">arXiv:2102.05018</a> [<a href="http://arxiv.org/pdf/2102.05018" target="_blank">pdf</a>]

<h2>Consensus Based Multi-Layer Perceptrons for Edge Computing. (arXiv:2102.05021v1 [cs.LG])</h2>
<h3>Haimonti Dutta, Nitin Nataraj, Saurabh Amarnath Mahindre</h3>
<p>In recent years, storing large volumes of data on distributed devices has
become commonplace. Applications involving sensors, for example, capture data
in different modalities including image, video, audio, GPS and others. Novel
algorithms are required to learn from this rich distributed data. In this
paper, we present consensus based multi-layer perceptrons for
resource-constrained devices. Assuming nodes (devices) in the distributed
system are arranged in a graph and contain vertically partitioned data, the
goal is to learn a global function that minimizes the loss. Each node learns a
feed-forward multi-layer perceptron and obtains a loss on data stored locally.
It then gossips with a neighbor, chosen uniformly at random, and exchanges
information about the loss. The updated loss is used to run a back propagation
algorithm and adjust weights appropriately. This method enables nodes to learn
the global function without exchange of data in the network. Empirical results
reveal that the consensus algorithm converges to the centralized model and has
performance comparable to centralized multi-layer perceptrons and tree-based
algorithms including random forests and gradient boosted decision trees.
</p>
<a href="http://arxiv.org/abs/2102.05021" target="_blank">arXiv:2102.05021</a> [<a href="http://arxiv.org/pdf/2102.05021" target="_blank">pdf</a>]

<h2>SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks. (arXiv:2102.05034v1 [cs.LG])</h2>
<h3>Bahare Fatemi, Layla El Asri, Seyed Mehran Kazemi</h3>
<p>Graph neural networks (GNNs) work well when the graph structure is provided.
However, this structure may not always be available in real-world applications.
One solution to this problem is to infer a task-specific latent structure and
then apply a GNN to the inferred graph. Unfortunately, the space of possible
graph structures grows super-exponentially with the number of nodes and so the
task-specific supervision may be insufficient for learning both the structure
and the GNN parameters. In this work, we propose the Simultaneous Learning of
Adjacency and GNN Parameters with Self-supervision, or SLAPS, a method that
provides more supervision for inferring a graph structure through
self-supervision. A comprehensive experimental study demonstrates that SLAPS
scales to large graphs with hundreds of thousands of nodes and outperforms
several models that have been proposed to learn a task-specific graph structure
on established benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.05034" target="_blank">arXiv:2102.05034</a> [<a href="http://arxiv.org/pdf/2102.05034" target="_blank">pdf</a>]

<h2>Sparse hierarchical interaction learning with epigraphical projection. (arXiv:1705.07817v5 [cs.LG] UPDATED)</h2>
<h3>Mingyuan Jiu, Nelly Pustelnik, Stefan Janaqi, M&#xe9;riam Chebre, Lin Qi, Philippe Ricoux</h3>
<p>This work focuses on learning optimization problems with quadratical
interactions between variables, which go beyond the additive models of
traditional linear learning. We investigate more specifically two different
methods encountered in the literature to deal with this problem: "hierNet" and
structured-sparsity regularization, and study their connections. We propose a
primal-dual proximal algorithm based on an epigraphical projection to optimize
a general formulation of these learning problems. The experimental setting
first highlights the improvement of the proposed procedure compared to
state-of-the-art methods based on fast iterative shrinkage-thresholding
algorithm (i.e. FISTA) or alternating direction method of multipliers (i.e.
ADMM), and then, using the proposed flexible optimization framework, we provide
fair comparisons between the different hierarchical penalizations and their
improvement over the standard $\ell_1$-norm penalization. The experiments are
conducted both on synthetic and real data, and they clearly show that the
proposed primal-dual proximal algorithm based on epigraphical projection is
efficient and effective to solve and investigate the problem of hierarchical
interaction learning.
</p>
<a href="http://arxiv.org/abs/1705.07817" target="_blank">arXiv:1705.07817</a> [<a href="http://arxiv.org/pdf/1705.07817" target="_blank">pdf</a>]

<h2>Ranking with Features: Algorithm and A Graph Theoretic Analysis. (arXiv:1808.03857v2 [cs.LG] UPDATED)</h2>
<h3>Aadirupa Saha, Arun Rajkumar</h3>
<p>We consider the problem of ranking a set of items from pairwise comparisons
in the presence of features associated with the items. Recent works have
established that $O(n\log(n))$ samples are needed to rank well when there is no
feature information present. However, this might be sub-optimal in the presence
of associated features. We introduce a new probabilistic preference model
called feature-Bradley-Terry-Luce (f-BTL) model that generalizes the standard
BTL model to incorporate feature information. We present a new least squares
based algorithm called fBTL-LS which we show requires much lesser than
$O(n\log(n))$ pairs to obtain a good ranking -- precisely our new sample
complexity bound is of $O(\alpha\log \alpha)$, where $\alpha$ denotes the
number of `independent items' of the set, in general $\alpha &lt;&lt; n$. Our
analysis is novel and makes use of tools from classical graph matching theory
to provide tighter bounds that sheds light on the true complexity of the
ranking problem, capturing the item dependencies in terms of their feature
representations. This was not possible with earlier matrix completion based
tools used for this problem. We also prove an information theoretic lower bound
on the required sample complexity for recovering the underlying ranking, which
essentially shows the tightness of our proposed algorithms. The efficacy of our
proposed algorithms are validated through extensive experimental evaluations on
a variety of synthetic and real world datasets.
</p>
<a href="http://arxiv.org/abs/1808.03857" target="_blank">arXiv:1808.03857</a> [<a href="http://arxiv.org/pdf/1808.03857" target="_blank">pdf</a>]

<h2>Stein Neural Sampler. (arXiv:1810.03545v2 [stat.ML] UPDATED)</h2>
<h3>Tianyang Hu, Zixiang Chen, Hanxi Sun, Jincheng Bai, Mao Ye, Guang Cheng</h3>
<p>We propose two novel samplers to generate high-quality samples from a given
(un-normalized) probability density. Motivated by the success of generative
adversarial networks, we construct our samplers using deep neural networks that
transform a reference distribution to the target distribution. Training schemes
are developed to minimize two variations of the Stein discrepancy, which is
designed to work with un-normalized densities. Once trained, our samplers are
able to generate samples instantaneously. We show that the proposed methods are
theoretically sound and experience fewer convergence issues compared with
traditional sampling approaches according to our empirical studies.
</p>
<a href="http://arxiv.org/abs/1810.03545" target="_blank">arXiv:1810.03545</a> [<a href="http://arxiv.org/pdf/1810.03545" target="_blank">pdf</a>]

<h2>Distributionally Robust and Multi-Objective Nonnegative Matrix Factorization. (arXiv:1901.10757v3 [cs.LG] UPDATED)</h2>
<h3>Nicolas Gillis, Le Thi Khanh Hien, Valentin Leplat, Vincent Y. F. Tan</h3>
<p>Nonnegative matrix factorization (NMF) is a linear dimensionality reduction
technique for analyzing nonnegative data. A key aspect of NMF is the choice of
the objective function that depends on the noise model (or statistics of the
noise) assumed on the data. In many applications, the noise model is unknown
and difficult to estimate. In this paper, we define a multi-objective NMF
(MO-NMF) problem, where several objectives are combined within the same NMF
model. We propose to use Lagrange duality to judiciously optimize for a set of
weights to be used within the framework of the weighted-sum approach, that is,
we minimize a single objective function which is a weighted sum of the all
objective functions. We design a simple algorithm based on multiplicative
updates to minimize this weighted sum. We show how this can be used to find
distributionally robust NMF (DR-NMF) solutions, that is, solutions that
minimize the largest error among all objectives, using a dual approach solved
via a heuristic inspired from the Frank-Wolfe algorithm. We illustrate the
effectiveness of this approach on synthetic, document and audio data sets. The
results show that DR-NMF is robust to our incognizance of the noise model of
the NMF problem.
</p>
<a href="http://arxiv.org/abs/1901.10757" target="_blank">arXiv:1901.10757</a> [<a href="http://arxiv.org/pdf/1901.10757" target="_blank">pdf</a>]

<h2>Semi-Supervised Few-Shot Learning with Prototypical Random Walks. (arXiv:1903.02164v3 [cs.LG] UPDATED)</h2>
<h3>Ahmed Ayyad, Yuchen Li, Nassir Navab, Shadi Albarqouni, Mohamed Elhoseiny</h3>
<p>Recent progress has shown that few-shot learning can be improved with access
to unlabelled data, known as semi-supervised few-shot learning(SS-FSL). We
introduce an SS-FSL approach, dubbed as Prototypical Random Walk
Networks(PRWN), built on top of Prototypical Networks (PN). We develop a random
walk semi-supervised loss that enables the network to learn representations
that are compact and well-separated. Our work is related to the very recent
development of graph-based approaches for few-shot learning. However, we show
that compact and well-separated class representations can be achieved by
modeling our prototypical random walk notion without needing additional
graph-NN parameters or requiring a transductive setting where a collective test
set is provided. Our model outperforms baselines in most benchmarks with
significant improvements in some cases. Our model, trained with 40$\%$ of the
data as labeled, compares competitively against fully supervised prototypical
networks, trained on 100$\%$ of the labels, even outperforming it in the 1-shot
mini-Imagenet case with 50.89$\%$ to 49.4$\%$ accuracy. We also show that our
loss is resistant to distractors, unlabeled data that does not belong to any of
the training classes, and hence reflecting robustness to labeled/unlabeled
class distribution mismatch. Associated GitHub page can be found at
https://prototypical-random-walk.github.io.
</p>
<a href="http://arxiv.org/abs/1903.02164" target="_blank">arXiv:1903.02164</a> [<a href="http://arxiv.org/pdf/1903.02164" target="_blank">pdf</a>]

<h2>SpecNet: Spectral Domain Convolutional Neural Network. (arXiv:1905.10915v6 [cs.CV] UPDATED)</h2>
<h3>Bochen Guan, Jinnian Zhang, William A. Sethares, Richard Kijowski, Fang Liu</h3>
<p>The memory consumption of most Convolutional Neural Network (CNN)
architectures grows rapidly with increasing depth of the network, which is a
major constraint for efficient network training on modern GPUs with limited
memory, embedded systems, and mobile devices. Several studies show that the
feature maps (as generated after the convolutional layers) are the main
bottleneck in this memory problem. Often, these feature maps mimic natural
photographs in the sense that their energy is concentrated in the spectral
domain. Although embedding CNN architectures in the spectral domain is widely
exploited to accelerate the training process, we demonstrate that it is also
possible to use the spectral domain to reduce the memory footprint, a method we
call Spectral Domain Convolutional Neural Network (SpecNet) that performs both
the convolution and the activation operations in the spectral domain. The
performance of SpecNet is evaluated on three competitive object recognition
benchmark tasks (CIFAR-10, SVHN, and ImageNet), and compared with several
state-of-the-art implementations. Overall, SpecNet is able to reduce memory
consumption by about 60% without significant loss of performance for all tested
networks.
</p>
<a href="http://arxiv.org/abs/1905.10915" target="_blank">arXiv:1905.10915</a> [<a href="http://arxiv.org/pdf/1905.10915" target="_blank">pdf</a>]

<h2>Robust Navigation of a Soft Growing Robot by Exploiting Contact with the Environment. (arXiv:1908.08645v2 [cs.RO] UPDATED)</h2>
<h3>Joseph D. Greer, Laura H. Blumenschein, Ron Alterovitz, Elliot W. Hawkes, Allison M. Okamura</h3>
<p>Navigation and motion control of a robot to a destination are tasks that have
historically been performed with the assumption that contact with the
environment is harmful. This makes sense for rigid-bodied robots where obstacle
collisions are fundamentally dangerous. However, because many soft robots have
bodies that are low-inertia and compliant, obstacle contact is inherently safe.
As a result, constraining paths of the robot to not interact with the
environment is not necessary and may be limiting. In this paper, we
mathematically formalize interactions of a soft growing robot with a planar
environment in an empirical kinematic model. Using this interaction model, we
develop a method to plan paths for the robot to a destination. Rather than
avoiding contact with the environment, the planner exploits obstacle contact
when beneficial for navigation. We find that a planner that takes into account
and capitalizes on environmental contact produces paths that are more robust to
uncertainty than a planner that avoids all obstacle contact.
</p>
<a href="http://arxiv.org/abs/1908.08645" target="_blank">arXiv:1908.08645</a> [<a href="http://arxiv.org/pdf/1908.08645" target="_blank">pdf</a>]

<h2>ABCDP: Approximate Bayesian Computation with Differential Privacy. (arXiv:1910.05103v3 [stat.ML] UPDATED)</h2>
<h3>Mijung Park, Margarita Vinaroz, Wittawat Jitkrittum</h3>
<p>We develop a novel approximate Bayesian computation (ABC) framework, ABCDP,
that produces differentially private (DP) and approximate posterior samples.
Our framework takes advantage of the Sparse Vector Technique (SVT), widely
studied in the differential privacy literature. SVT incurs the privacy cost
only when a condition (whether a quantity of interest is above/below a
threshold) is met. If the condition is met sparsely during the repeated
queries, SVT can drastically reduces the cumulative privacy loss, unlike the
usual case where every query incurs the privacy loss. In ABC, the quantity of
interest is the distance between observed and simulated data, and only when the
distance is below a threshold, we take the corresponding prior sample as a
posterior sample. Hence, applying SVT to ABC is an organic way to transform an
ABC algorithm to a privacy-preserving variant with minimal modification, but
yields the posterior samples with a high privacy level. We theoretically
analyze the interplay between the noise added for privacy and the accuracy of
the posterior samples.
</p>
<a href="http://arxiv.org/abs/1910.05103" target="_blank">arXiv:1910.05103</a> [<a href="http://arxiv.org/pdf/1910.05103" target="_blank">pdf</a>]

<h2>Biometrics Recognition Using Deep Learning: A Survey. (arXiv:1912.00271v3 [cs.CV] UPDATED)</h2>
<h3>Shervin Minaee, Amirali Abdolrashidi, Hang Su, Mohammed Bennamoun, David Zhang</h3>
<p>Deep learning-based models have been very successful in achieving
state-of-the-art results in many of the computer vision, speech recognition,
and natural language processing tasks in the last few years. These models seem
a natural fit for handling the ever-increasing scale of biometric recognition
problems, from cellphone authentication to airport security systems. Deep
learning-based models have increasingly been leveraged to improve the accuracy
of different biometric recognition systems in recent years. In this work, we
provide a comprehensive survey of more than 120 promising works on biometric
recognition (including face, fingerprint, iris, palmprint, ear, voice,
signature, and gait recognition), which deploy deep learning models, and show
their strengths and potentials in different applications. For each biometric,
we first introduce the available datasets that are widely used in the
literature and their characteristics. We will then talk about several promising
deep learning works developed for that biometric, and show their performance on
popular public benchmarks. We will also discuss some of the main challenges
while using these models for biometric recognition, and possible future
directions to which research in this area is headed.
</p>
<a href="http://arxiv.org/abs/1912.00271" target="_blank">arXiv:1912.00271</a> [<a href="http://arxiv.org/pdf/1912.00271" target="_blank">pdf</a>]

<h2>GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural Network Representation of AIS Tracks and A Contrario Detection. (arXiv:1912.00682v5 [cs.LG] UPDATED)</h2>
<h3>Duong Nguyen, Rodolphe Vadaine, Guillaume Hajduch, Ren&#xe9; Garello, Ronan Fablet</h3>
<p>Representing maritime traffic patterns and detecting anomalies from them are
key to vessel monitoring and maritime situational awareness. We propose a novel
approach -- referred to as GeoTrackNet -- for maritime anomaly detection from
AIS data streams. Our model exploits state-of-the-art neural network schemes to
learn a probabilistic representation of AIS tracks and a contrario detection to
detect abnormal events. The neural network provides a new means to capture
complex and heterogeneous patterns in vessels' behaviours, while the \textit{a
contrario} detector takes into account the fact that the learnt distribution
may be location-dependent. Experiments on a real AIS dataset comprising more
than 4.2 million AIS messages demonstrate the relevance of the proposed method
compared with state-of-the-art schemes.
</p>
<a href="http://arxiv.org/abs/1912.00682" target="_blank">arXiv:1912.00682</a> [<a href="http://arxiv.org/pdf/1912.00682" target="_blank">pdf</a>]

<h2>Dense Residual Network: Enhancing Global Dense Feature Flow for Character Recognition. (arXiv:2001.09021v4 [cs.CV] UPDATED)</h2>
<h3>Zhao Zhang, Zemin Tang, Yang Wang, Zheng Zhang, Choujun Zhan, Zhengjun Zha, Meng Wang</h3>
<p>Deep Convolutional Neural Networks (CNNs), such as Dense Convolutional
Networks (DenseNet), have achieved great success for image representation by
discovering deep hierarchical information. However, most existing networks
simply stacks the convolutional layers and hence failing to fully discover
local and global feature information among layers. In this paper, we mainly
explore how to enhance the local and global dense feature flow by exploiting
hierarchical features fully from all the convolution layers. Technically, we
propose an efficient and effective CNN framework, i.e., Fast Dense Residual
Network (FDRN), for text recognition. To construct FDRN, we propose a new fast
residual dense block (f-RDB) to retain the ability of local feature fusion and
local residual learning of original RDB, which can reduce the computing efforts
at the same time. After fully learning local residual dense features, we
utilize the sum operation and several f-RDBs to define a new block termed
global dense block (GDB) by imitating the construction of dense blocks to learn
global dense residual features adaptively in a holistic way. Finally, we use
two convolution layers to construct a down-sampling block to reduce the global
feature size and extract deeper features. Extensive simulations show that FDRN
obtains the enhanced recognition results, compared with other related models.
</p>
<a href="http://arxiv.org/abs/2001.09021" target="_blank">arXiv:2001.09021</a> [<a href="http://arxiv.org/pdf/2001.09021" target="_blank">pdf</a>]

<h2>Automatic structured variational inference. (arXiv:2002.00643v2 [stat.ML] UPDATED)</h2>
<h3>Luca Ambrogioni, Max Hinne, Marcel van Gerven</h3>
<p>Stochastic variational inference offers an attractive option as a default
method for differentiable probabilistic programming. However, the performance
of the variational approach depends on the choice of an appropriate variational
family. Here, we introduce automatic structured variational inference (ASVI), a
fully automated method for constructing structured variational families,
inspired by the closed-form update in conjugate Bayesian models. These
convex-update families incorporate the forward pass of the input probabilistic
program and can therefore capture complex statistical dependencies.
Convex-update families have the same space and time complexity as the input
probabilistic program and are therefore tractable for a very large family of
models including both continuous and discrete variables. We validate our
automatic variational method on a wide range of low- and high-dimensional
inference problems. We find that ASVI provides a clear improvement in
performance when compared with other popular approaches such as the mean-field
approach and inverse autoregressive flows. We provide an open source
implementation of ASVI in TensorFlow Probability.
</p>
<a href="http://arxiv.org/abs/2002.00643" target="_blank">arXiv:2002.00643</a> [<a href="http://arxiv.org/pdf/2002.00643" target="_blank">pdf</a>]

<h2>Fast Predictive Uncertainty for Classification with Bayesian Deep Networks. (arXiv:2003.01227v2 [cs.LG] UPDATED)</h2>
<h3>Marius Hobbhahn, Agustinus Kristiadi, Philipp Hennig</h3>
<p>In Bayesian Deep Learning, distributions over the output of classification
neural networks are approximated by first constructing a Gaussian distribution
over the weights, then sampling from it to receive a distribution over the
categorical output distribution. This is costly. We reconsider old work to
construct a Dirichlet approximation of this output distribution, which yields
an analytic map between Gaussian distributions in logit space and Dirichlet
distributions (the conjugate prior to the categorical) in the output space. We
argue that the resulting Dirichlet distribution has theoretical and practical
advantages, in particular more efficient computation of the uncertainty
estimate, scaling to large datasets and networks like ImageNet and DenseNet. We
demonstrate the use of this Dirichlet approximation by using it to construct a
lightweight uncertainty-aware output ranking for the ImageNet setup.
</p>
<a href="http://arxiv.org/abs/2003.01227" target="_blank">arXiv:2003.01227</a> [<a href="http://arxiv.org/pdf/2003.01227" target="_blank">pdf</a>]

<h2>Interactive Constrained MAP-Elites: Analysis and Evaluation of the Expressiveness of the Feature Dimensions. (arXiv:2003.03377v2 [cs.AI] UPDATED)</h2>
<h3>Alberto Alvarez, Steve Dahlskog, Jose Font, Julian Togelius</h3>
<p>We propose the Interactive Constrained MAP-Elites, a quality-diversity
solution for game content generation, implemented as a new feature of the
Evolutionary Dungeon Designer: a mixed-initiative co-creativity tool for
designing dungeons. The feature uses the MAP-Elites algorithm, an illumination
algorithm that segregates the population among several cells depending on their
scores with respect to different behavioral dimensions. Users can flexibly and
dynamically alternate between these dimensions anytime, thus guiding the
evolutionary process in an intuitive way, and then incorporate suggestions
produced by the algorithm in their room designs. At the same time, any
modifications performed by the human user will feed back into MAP-Elites,
closing a circular workflow of constant mutual inspiration. This paper presents
the algorithm followed by an in-depth analysis of its behaviour, with the aims
of evaluating the expressive range of all possible dimension combinations in
several scenarios, as well as discussing their influence in the fitness
landscape and in the overall performance of the mixed-initiative procedural
content generation.
</p>
<a href="http://arxiv.org/abs/2003.03377" target="_blank">arXiv:2003.03377</a> [<a href="http://arxiv.org/pdf/2003.03377" target="_blank">pdf</a>]

<h2>Ground Truth Evaluation of Neural Network Explanations with CLEVR-XAI. (arXiv:2003.07258v2 [cs.CV] UPDATED)</h2>
<h3>Leila Arras, Ahmed Osman, Wojciech Samek</h3>
<p>The rise of deep learning in today's applications entailed an increasing need
in explaining the model's decisions beyond prediction performances in order to
foster trust and accountability. Recently, the field of explainable AI (XAI)
has developed methods that provide such explanations for already trained neural
networks. In computer vision tasks such explanations, termed heatmaps,
visualize the contributions of individual pixels to the prediction. So far XAI
methods along with their heatmaps were mainly validated qualitatively via
human-based assessment, or evaluated through auxiliary proxy tasks such as
pixel perturbation, weak object localization or randomization tests. Due to the
lack of an objective and commonly accepted quality measure for heatmaps, it was
debatable which XAI method performs best and whether explanations can be
trusted at all. In the present work, we tackle the problem by proposing a
ground truth based evaluation framework for XAI methods based on the CLEVR
visual question answering task. Our framework provides a (1) selective, (2)
controlled and (3) realistic testbed for the evaluation of neural network
explanations. We compare ten different explanation methods, resulting in new
insights about the quality and properties of XAI methods, sometimes
contradicting with conclusions from previous comparative studies. The CLEVR-XAI
dataset and the benchmarking code can be found at
https://github.com/ahmedmagdiosman/clevr-xai.
</p>
<a href="http://arxiv.org/abs/2003.07258" target="_blank">arXiv:2003.07258</a> [<a href="http://arxiv.org/pdf/2003.07258" target="_blank">pdf</a>]

<h2>Conditional Gaussian Distribution Learning for Open Set Recognition. (arXiv:2003.08823v4 [cs.LG] UPDATED)</h2>
<h3>Xin Sun, Zhenning Yang, Chi Zhang, Guohao Peng, Keck-Voon Ling</h3>
<p>Deep neural networks have achieved state-of-the-art performance in a wide
range of recognition/classification tasks. However, when applying deep learning
to real-world applications, there are still multiple challenges. A typical
challenge is that unknown samples may be fed into the system during the testing
phase and traditional deep neural networks will wrongly recognize the unknown
sample as one of the known classes. Open set recognition is a potential
solution to overcome this problem, where the open set classifier should have
the ability to reject unknown samples as well as maintain high classification
accuracy on known classes. The variational auto-encoder (VAE) is a popular
model to detect unknowns, but it cannot provide discriminative representations
for known classification. In this paper, we propose a novel method, Conditional
Gaussian Distribution Learning (CGDL), for open set recognition. In addition to
detecting unknown samples, this method can also classify known samples by
forcing different latent features to approximate different Gaussian models.
Meanwhile, to avoid information hidden in the input vanishing in the middle
layers, we also adopt the probabilistic ladder architecture to extract
high-level abstract features. Experiments on several standard image datasets
reveal that the proposed method significantly outperforms the baseline method
and achieves new state-of-the-art results.
</p>
<a href="http://arxiv.org/abs/2003.08823" target="_blank">arXiv:2003.08823</a> [<a href="http://arxiv.org/pdf/2003.08823" target="_blank">pdf</a>]

<h2>Semantic Domain Adversarial Networks for Unsupervised Domain Adaptation. (arXiv:2003.13274v3 [cs.CV] UPDATED)</h2>
<h3>Dapeng Hu, Jian Liang, Qibin Hou, Hanshu Yan, Yunpeng Chen, Shuicheng Yan, Jiashi Feng</h3>
<p>Domain adversarial training has become a prevailing and effective paradigm
for unsupervised domain adaptation (UDA). To successfully align the multi-modal
data structures across domains, the following works exploit discriminative
information in the adversarial training process, e.g., using multiple
class-wise discriminators and introducing conditional information in input or
output of the domain discriminator. However, these methods either require
non-trivial model designs or are inefficient for UDA tasks. In this work, we
attempt to address this dilemma by devising simple and compact conditional
domain adversarial training methods. We first show that the previous failure of
the concatenation conditioning strategy mainly accounts for the weak support of
the conditioning. Thus we propose an effective concatenation conditioning
strategy by introducing a norm control factor to strengthen the conditioning
and term the derived method as \underline{S}emantic \underline{D}omain
\underline{A}dversarial \underline{N}etworks~(SDAN). However, directly applying
predictions for conditional domain alignment, SDAN still suffers from
inaccurate target predictions. We further propose a novel structure-aware
conditioning strategy to enhance SDAN by conditioning the cross-domain feature
alignment in the structure-aware semantic space rather than in the prediction
space. We term the enhanced method as \underline{S}tructure-aware
\underline{S}emantic \underline{D}omain \underline{A}dversarial
\underline{N}etworks~(SSDAN). Experiments on both object recognition and
semantic segmentation show that SDAN effectively aligns the multi-modal
structures across domains and even outperforms state-of-the-art domain
adversarial training methods. With structure-aware semantic conditioning, SSDAN
further improves the adaptation performance over SDAN on multiple object
recognition benchmarks for UDA.
</p>
<a href="http://arxiv.org/abs/2003.13274" target="_blank">arXiv:2003.13274</a> [<a href="http://arxiv.org/pdf/2003.13274" target="_blank">pdf</a>]

<h2>Fast Learning in Reproducing Kernel Krein Spaces via Signed Measures. (arXiv:2006.00247v3 [cs.LG] UPDATED)</h2>
<h3>Fanghui Liu, Xiaolin Huang, Yingyi Chen, Johan A.K. Suykens</h3>
<p>In this paper, we attempt to solve a long-lasting open question for
non-positive definite (non-PD) kernels in machine learning community: can a
given non-PD kernel be decomposed into the difference of two PD kernels (termed
as positive decomposition)? We cast this question as a distribution view by
introducing the \emph{signed measure}, which transforms positive decomposition
to measure decomposition: a series of non-PD kernels can be associated with the
linear combination of specific finite Borel measures. In this manner, our
distribution-based framework provides a sufficient and necessary condition to
answer this open question. Specifically, this solution is also computationally
implementable in practice to scale non-PD kernels in large sample cases, which
allows us to devise the first random features algorithm to obtain an unbiased
estimator. Experimental results on several benchmark datasets verify the
effectiveness of our algorithm over the existing methods.
</p>
<a href="http://arxiv.org/abs/2006.00247" target="_blank">arXiv:2006.00247</a> [<a href="http://arxiv.org/pdf/2006.00247" target="_blank">pdf</a>]

<h2>Deterministic Neural SDEs for Affordable Uncertainty Quantification. (arXiv:2006.08973v2 [cs.LG] UPDATED)</h2>
<h3>Andreas Look, Melih Kandemir, Jan Peters</h3>
<p>Neural Stochastic Differential Equations (NSDEs) model the drift and
diffusion functions of a stochastic process as neural networks. While NSDEs are
known to predict time series accurately, their uncertainty quantification
properties remain unexplored. We report the empirical finding that obtaining
well-calibrated uncertainty estimations from NSDEs is computationally
prohibitive. As a remedy, we develop a computationally affordable deterministic
scheme for expressing the likelihood of a sequence, when dynamics is governed
by a NSDE, which is applicable to both training and prediction. Our method
introduces a bidirectional moment matching scheme, one vertical along the
neural net layers, and one horizontal along the time direction, which benefits
from an original combination of effective approximations. We observe in
multiple experiments that the uncertainty calibration quality of our method can
be matched by Monte Carlo sampling only after introducing at least five times
more computation cost. Thanks to the numerical stability of deterministic
training, our method also provides improvement in prediction accuracy.
</p>
<a href="http://arxiv.org/abs/2006.08973" target="_blank">arXiv:2006.08973</a> [<a href="http://arxiv.org/pdf/2006.08973" target="_blank">pdf</a>]

<h2>Optimization and Generalization of Regularization-Based Continual Learning: a Loss Approximation Viewpoint. (arXiv:2006.10974v3 [cs.LG] UPDATED)</h2>
<h3>Dong Yin, Mehrdad Farajtabar, Ang Li, Nir Levine, Alex Mott</h3>
<p>Neural networks have achieved remarkable success in many cognitive tasks.
However, when they are trained sequentially on multiple tasks without access to
old data, their performance on early tasks tend to drop significantly. This
problem is often referred to as catastrophic forgetting, a key challenge in
continual learning of neural networks. The regularization-based approach is one
of the primary classes of methods to alleviate catastrophic forgetting. In this
paper, we provide a novel viewpoint of regularization-based continual learning
by formulating it as a second-order Taylor approximation of the loss function
of each task. This viewpoint leads to a unified framework that can be
instantiated to derive many existing algorithms such as Elastic Weight
Consolidation and Kronecker factored Laplace approximation. Based on this
viewpoint, we study the optimization aspects (i.e., convergence) as well as
generalization properties (i.e., finite-sample guarantees) of
regularization-based continual learning. Our theoretical results indicate the
importance of accurate approximation of the Hessian matrix. The experimental
results on several benchmarks provide empirical validation of our theoretical
findings.
</p>
<a href="http://arxiv.org/abs/2006.10974" target="_blank">arXiv:2006.10974</a> [<a href="http://arxiv.org/pdf/2006.10974" target="_blank">pdf</a>]

<h2>A deep primal-dual proximal network for image restoration. (arXiv:2007.00959v2 [cs.CV] UPDATED)</h2>
<h3>Mingyuan Jiu, Nelly Pustelnik</h3>
<p>Image restoration remains a challenging task in image processing. Numerous
methods tackle this problem, often solved by minimizing a non-smooth penalized
co-log-likelihood function. Although the solution is easily interpretable with
theoretic guarantees, its estimation relies on an optimization process that can
take time. Considering the research effort in deep learning for image
classification and segmentation, this class of methods offers a serious
alternative to perform image restoration but stays challenging to solve inverse
problems. In this work, we design a deep network, named DeepPDNet, built from
primal-dual proximal iterations associated with the minimization of a standard
penalized likelihood with an analysis prior, allowing us to take advantage of
both worlds.

We reformulate a specific instance of the Condat-Vu primal-dual hybrid
gradient (PDHG) algorithm as a deep network with fixed layers. The learned
parameters are both the PDHG algorithm step-sizes and the analysis linear
operator involved in the penalization (including the regularization parameter).
These parameters are allowed to vary from a layer to another one. Two different
learning strategies: "Full learning" and "Partial learning" are proposed, the
first one is the most efficient numerically while the second one relies on
standard constraints ensuring convergence in the standard PDHG iterations.
Moreover, global and local sparse analysis prior are studied to seek a better
feature representation. We apply the proposed methods to image restoration on
the MNIST and BSD68 datasets and to single image super-resolution on the BSD100
and SET14 datasets. Extensive results show that the proposed DeepPDNet
demonstrates excellent performance on the MNIST and the more complex BSD68,
BSD100, and SET14 datasets for image restoration and single image
super-resolution task.
</p>
<a href="http://arxiv.org/abs/2007.00959" target="_blank">arXiv:2007.00959</a> [<a href="http://arxiv.org/pdf/2007.00959" target="_blank">pdf</a>]

<h2>Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Distribution Shift. (arXiv:2007.02931v3 [cs.LG] UPDATED)</h2>
<h3>Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, Chelsea Finn</h3>
<p>A fundamental assumption of most machine learning algorithms is that the
training and test data are drawn from the same underlying distribution.
However, this assumption is violated in almost all practical applications:
machine learning systems are regularly tested under distribution shift, due to
changing temporal correlations, atypical end users, or other factors. In this
work, we consider the setting where the training data are structured into
groups and there may be multiple test time shifts, corresponding to new groups
or group distributions. Most prior methods aim to learn a single robust model
or invariant feature space to tackle this group shift. In contrast, we aim to
learn models that adapt at test time to shift using unlabeled test points. Our
primary contribution is to introduce the framework of adaptive risk
minimization (ARM), in which models are optimized for post adaptation
performance on training batches sampled from different groups, which simulate
group shifts that may occur at test time. We use meta-learning to solve the ARM
problem, and compared to prior methods for robustness, invariance, and
adaptation, ARM methods provide consistent gains of 1-4% test accuracy on image
classification problems exhibiting group shift.
</p>
<a href="http://arxiv.org/abs/2007.02931" target="_blank">arXiv:2007.02931</a> [<a href="http://arxiv.org/pdf/2007.02931" target="_blank">pdf</a>]

<h2>Multiple Descent: Design Your Own Generalization Curve. (arXiv:2008.01036v5 [cs.LG] UPDATED)</h2>
<h3>Lin Chen, Yifei Min, Mikhail Belkin, Amin Karbasi</h3>
<p>This paper explores the generalization loss of linear regression in variably
parameterized families of models, both under-parameterized and
over-parameterized. We show that the generalization curve can have an arbitrary
number of peaks, and moreover, locations of those peaks can be explicitly
controlled. Our results highlight the fact that both classical U-shaped
generalization curve and the recently observed double descent curve are not
intrinsic properties of the model family. Instead, their emergence is due to
the interaction between the properties of the data and the inductive biases of
learning algorithms.
</p>
<a href="http://arxiv.org/abs/2008.01036" target="_blank">arXiv:2008.01036</a> [<a href="http://arxiv.org/pdf/2008.01036" target="_blank">pdf</a>]

<h2>Open Set Recognition with Conditional Probabilistic Generative Models. (arXiv:2008.05129v2 [cs.CV] UPDATED)</h2>
<h3>Xin Sun, Chi Zhang, Guosheng Lin, Keck-Voon Ling</h3>
<p>Deep neural networks have made breakthroughs in a wide range of visual
understanding tasks. A typical challenge that hinders their real-world
applications is that unknown samples may be fed into the system during the
testing phase, but traditional deep neural networks will wrongly recognize
these unknown samples as one of the known classes. Open set recognition (OSR)
is a potential solution to overcome this problem, where the open set classifier
should have the flexibility to reject unknown samples and meanwhile maintain
high classification accuracy in known classes. Probabilistic generative models,
such as Variational Autoencoders (VAE) and Adversarial Autoencoders (AAE), are
popular methods to detect unknowns, but they cannot provide discriminative
representations for known classification. In this paper, we propose a novel
framework, called Conditional Probabilistic Generative Models (CPGM), for open
set recognition. The core insight of our work is to add discriminative
information into the probabilistic generative models, such that the proposed
models can not only detect unknown samples but also classify known classes by
forcing different latent features to approximate conditional Gaussian
distributions. We discuss many model variants and provide comprehensive
experiments to study their characteristics. Experiment results on multiple
benchmark datasets reveal that the proposed method significantly outperforms
the baselines and achieves new state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2008.05129" target="_blank">arXiv:2008.05129</a> [<a href="http://arxiv.org/pdf/2008.05129" target="_blank">pdf</a>]

<h2>3D Collision-Force-Map for Safe Human-Robot Collaboration. (arXiv:2009.01036v3 [cs.RO] UPDATED)</h2>
<h3>Petr Svarny, Jakub Rozlivek, Lukas Rustler, Matej Hoffmann</h3>
<p>The need to guarantee the safety of collaborative robots limits their
performance, in particular, their speed and hence cycle time. In this work, we
measure the forces exerted by two collaborative manipulators (UR10e and KUKA
LBR iiwa) on an impact measuring device. Our contributions are the following:
(i) a new data-driven model predicting impact forces from velocity, distance
from robot base, and, newly, the height in the workspace; (ii) demonstration
that the model can be trained on a limited number of data points; (iii)
analysis of the force evolution upon impact. The standard ISO/TS 15066 defines
the Power and Force Limiting operation mode and prescribes force thresholds
that a moving robot is allowed to exert on human body parts during impact (for
the back of the hand, 280 N for transient and 140 N for quasi-static contact),
along with a simple formula to obtain maximum allowed speed of the robot in the
whole workspace. Applying this to our scenario where the impact has a clamping
nature, the allowed end effector speed on the whole robot workspace would be
only 0.13 and 0.16 m/s for the UR10e and KUKA LBR iiwa, respectively. Our
measurements reveal that if the task is performed for example 0.8 m away and
0.4 m above the robot base, speeds of 0.16 m/s (UR10e) and 0.20 m/s (KUKA LBR
iiwa) can be safely operated, staying within the prescribed force limit.
Furthermore, the force evolution during impact for the UR10e reveals that
clamping never occurs. With the 280 N limit, 0.36 m/s will still be safe with
the UR10e. The formulas relating robot mass, velocity, and impact forces from
ISO/TS 15066 are insufficient -- leading both to significant underestimation
and overestimation of velocities/forces, and thus to unnecessarily long cycle
times or even dangerous applications.
</p>
<a href="http://arxiv.org/abs/2009.01036" target="_blank">arXiv:2009.01036</a> [<a href="http://arxiv.org/pdf/2009.01036" target="_blank">pdf</a>]

<h2>PCA Reduced Gaussian Mixture Models with Applications in Superresolution. (arXiv:2009.07520v2 [stat.ML] UPDATED)</h2>
<h3>Johannes Hertrich, Dang Phoung Lan Nguyen, Jean-Fancois Aujol, Dominique Bernard, Yannick Berthoumieu, Abdellatif Saadaldin, Gabriele Steidl</h3>
<p>Despite the rapid development of computational hardware, the treatment of
large and high dimensional data sets is still a challenging problem. This paper
provides a twofold contribution to the topic. First, we propose a Gaussian
Mixture Model in conjunction with a reduction of the dimensionality of the data
in each component of the model by principal component analysis, called PCA-GMM.
To learn the (low dimensional) parameters of the mixture model we propose an EM
algorithm whose M-step requires the solution of constrained optimization
problems. Fortunately, these constrained problems do not depend on the usually
large number of samples and can be solved efficiently by an (inertial) proximal
alternating linearized minimization algorithm. Second, we apply our PCA-GMM for
the superresolution of 2D and 3D material images based on the approach of
Sandeep and Jacob. Numerical results confirm the moderate influence of the
dimensionality reduction on the overall superresolution result.
</p>
<a href="http://arxiv.org/abs/2009.07520" target="_blank">arXiv:2009.07520</a> [<a href="http://arxiv.org/pdf/2009.07520" target="_blank">pdf</a>]

<h2>Symbolic Relational Deep Reinforcement Learning based on Graph Neural Networks. (arXiv:2009.12462v2 [cs.LG] UPDATED)</h2>
<h3>Jarom&#xed;r Janisch, Tom&#xe1;&#x161; Pevn&#xfd;, Viliam Lis&#xfd;</h3>
<p>We focus on reinforcement learning (RL) in relational problems that are
naturally defined in terms of objects, their relations, and manipulations.
These problems are characterized by variable state and action spaces, and
finding a fixed-length representation, required by most existing RL methods, is
difficult, if not impossible. We present a deep RL framework based on graph
neural networks and auto-regressive policy decomposition that naturally works
with these problems and is completely domain-independent. We demonstrate the
framework in three very distinct domains. In goal-oriented BlockWorld, we
demonstrate multi-parameter actions with pre-conditions. In SysAdmin, we show
how to select multiple objects simultaneously. In all three domains, we report
the method's competitive performance and impressive zero-shot generalization
over different problem sizes. For example, in the classical planning domain of
Sokoban, the method trained exclusively on 10x10 problems with three boxes
solves 89% of 15x15 problems with five boxes.
</p>
<a href="http://arxiv.org/abs/2009.12462" target="_blank">arXiv:2009.12462</a> [<a href="http://arxiv.org/pdf/2009.12462" target="_blank">pdf</a>]

<h2>VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models. (arXiv:2010.00654v2 [cs.LG] UPDATED)</h2>
<h3>Zhisheng Xiao, Karsten Kreis, Jan Kautz, Arash Vahdat</h3>
<p>Energy-based models (EBMs) have recently been successful in representing
complex distributions of small images. However, sampling from them requires
expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high
dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate
samples quickly and are equipped with a latent space that enables fast
traversal of the data manifold. However, VAEs tend to assign high probability
density to regions in data space outside the actual data distribution and often
fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic
composition of a VAE and an EBM that offers the best of both worlds. VAEBM
captures the overall mode structure of the data distribution using a
state-of-the-art VAE and it relies on its EBM component to explicitly exclude
non-data-like regions from the model and refine the image samples. Moreover,
the VAE component in VAEBM allows us to speed up MCMC updates by
reparameterizing them in the VAE's latent space. Our experimental results show
that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on
several benchmark image datasets by a large margin. It can generate
high-quality images as large as 256$\times$256 pixels with short MCMC chains.
We also demonstrate that VAEBM provides complete mode coverage and performs
well in out-of-distribution detection.
</p>
<a href="http://arxiv.org/abs/2010.00654" target="_blank">arXiv:2010.00654</a> [<a href="http://arxiv.org/pdf/2010.00654" target="_blank">pdf</a>]

<h2>An Efficient Algorithm for Cooperative Semi-Bandits. (arXiv:2010.01818v2 [cs.LG] UPDATED)</h2>
<h3>Riccardo Della Vecchia (BIDSA), Tommaso Cesari (TSE)</h3>
<p>We consider the problem of asynchronous online combinatorial optimization on
a network of communicating agents. At each time step, some of the agents are
stochastically activated, requested to make a prediction, and the system pays
the corresponding loss. Then, neighbors of active agents receive semi-bandit
feedback and exchange some succinct local information. The goal is to minimize
the network regret, defined as the difference between the cumulative loss of
the predictions of active agents and that of the best action in hindsight,
selected from a combinatorial decision set. The main challenge in such a
context is to control the computational complexity of the resulting algorithm
while retaining minimax optimal regret guarantees. We introduce Coop-FTPL, a
cooperative version of the well-known Follow The Perturbed Leader algorithm,
that implements a new loss estimation procedure generalizing the Geometric
Resampling of Neu and Bart{\'o}k [2013] to our setting. Assuming that the
elements of the decision set are k-dimensional binary vectors with at most m
non-zero entries and $\alpha$ 1 is the independence number of the network, we
show that the expected regret of our algorithm after T time steps is of order Q
mkT log(k)(k$\alpha$ 1 /Q + m), where Q is the total activation probability
mass. Furthermore, we prove that this is only $\sqrt$ k log k-away from the
best achievable rate and that Coop-FTPL has a state-of-the-art T 3/2 worst-case
computational complexity.
</p>
<a href="http://arxiv.org/abs/2010.01818" target="_blank">arXiv:2010.01818</a> [<a href="http://arxiv.org/pdf/2010.01818" target="_blank">pdf</a>]

<h2>Representation learning from videos in-the-wild: An object-centric approach. (arXiv:2010.02808v2 [cs.CV] UPDATED)</h2>
<h3>Rob Romijnders, Aravindh Mahendran, Michael Tschannen, Josip Djolonga, Marvin Ritter, Neil Houlsby, Mario Lucic</h3>
<p>We propose a method to learn image representations from uncurated videos. We
combine a supervised loss from off-the-shelf object detectors and
self-supervised losses which naturally arise from the video-shot-frame-object
hierarchy present in each video. We report competitive results on 19 transfer
learning tasks of the Visual Task Adaptation Benchmark (VTAB), and on 8
out-of-distribution-generalization tasks, and discuss the benefits and
shortcomings of the proposed approach. In particular, it improves over the
baseline on all 18/19 few-shot learning tasks and 8/8 out-of-distribution
generalization tasks. Finally, we perform several ablation studies and analyze
the impact of the pretrained object detector on the performance across this
suite of tasks.
</p>
<a href="http://arxiv.org/abs/2010.02808" target="_blank">arXiv:2010.02808</a> [<a href="http://arxiv.org/pdf/2010.02808" target="_blank">pdf</a>]

<h2>HydroDeep -- A Knowledge Guided Deep Neural Network for Geo-Spatiotemporal Data Analysis. (arXiv:2010.04328v2 [cs.LG] UPDATED)</h2>
<h3>Aishwarya Sarkar, Jien Zhang, Chaoqun Lu, Ali Jannesari</h3>
<p>Due to limited evidence and complex causes of regional climate change, the
confidence in predicting fluvial floods remains low. Understanding the
fundamental mechanisms intrinsic to geo-spatiotemporal information is crucial
to improve the prediction accuracy. This paper demonstrates a hybrid neural
network architecture - HydroDeep, that couples a process-based hydro-ecological
model with a combination of Deep Convolutional Neural Network (CNN) and Long
Short-Term Memory (LSTM) Network. HydroDeep outperforms the independent CNN's
and LSTM's performance by 1.6% and 10.5% respectively in Nash-Sutcliffe
efficiency. Also, we show that HydroDeep pre-trained in one region is adept at
passing on its knowledge to distant places via unique transfer learning
approaches that minimize HydroDeep's training duration for a new region by
learning its regional geo-spatiotemporal features in a reduced number of
iterations.
</p>
<a href="http://arxiv.org/abs/2010.04328" target="_blank">arXiv:2010.04328</a> [<a href="http://arxiv.org/pdf/2010.04328" target="_blank">pdf</a>]

<h2>PAC$^m$-Bayes: Narrowing the Empirical Risk Gap in the Misspecified Bayesian Regime. (arXiv:2010.09629v2 [cs.LG] UPDATED)</h2>
<h3>Warren R. Morningstar, Alexander A. Alemi, Joshua V. Dillon</h3>
<p>While the decision-theoretic optimality of the Bayesian formalism under
correct model specification is well-known (Berger 2013), the Bayesian case
becomes less clear under model misspecification (Grunwald 2017; Ramamoorthi
2015; Fushiki 2005). To formally understand the consequences of Bayesian
misspecification, this work examines the relationship between posterior
predictive risk and its sensitivity to correct model assumptions, i.e., choice
of likelihood and prior. We present the multisample PAC$^m$-Bayes risk. This
risk is justified by theoretical analysis based on PAC-Bayes as well as
empirical study on a number of toy problems. The PAC$^m$-Bayes risk is
appealing in that it entails direct minimization of the Monte-Carlo
approximated posterior predictive risk yet recovers both the Bayesian formalism
as well as the MLE in its limits. Our work is heavily influenced by Masegosa
(2019); our contributions are to align training and generalization risks while
offering a tighter bound which empirically performs at least as well and
sometimes much better.
</p>
<a href="http://arxiv.org/abs/2010.09629" target="_blank">arXiv:2010.09629</a> [<a href="http://arxiv.org/pdf/2010.09629" target="_blank">pdf</a>]

<h2>Edge Bias in Federated Learning and its Solution by Buffered Knowledge Distillation. (arXiv:2010.10338v3 [cs.LG] UPDATED)</h2>
<h3>Sangho Lee, Kiyoon Yoo, Nojun Kwak</h3>
<p>Federated learning (FL), which utilizes communication between the server
(core) and local devices (edges) to indirectly learn from more data, is an
emerging field in deep learning research. Recently, Knowledge
Distillation-based FL methods with notable performance and high applicability
have been suggested. In this paper, we choose knowledge distillation-based FL
method as our baseline and tackle a challenging problem that ensues from using
these methods. Especially, we focus on the problem incurred in the server model
that tries to mimic different datasets, each of which is unique to an
individual edge device. We dub the problem 'edge bias', which occurs when
multiple teacher models trained on different datasets are used individually to
distill knowledge. We introduce this nuisance that occurs in certain scenarios
of FL, and to alleviate it, we propose a simple yet effective distillation
scheme named 'buffered distillation'. In addition, we also experimentally show
that this scheme is effective in mitigating the straggler problem caused by
delayed edges.
</p>
<a href="http://arxiv.org/abs/2010.10338" target="_blank">arXiv:2010.10338</a> [<a href="http://arxiv.org/pdf/2010.10338" target="_blank">pdf</a>]

<h2>Maximum Mean Discrepancy is Aware of Adversarial Attacks. (arXiv:2010.11415v2 [cs.LG] UPDATED)</h2>
<h3>Ruize Gao, Feng Liu, Jingfeng Zhang, Bo Han, Tongliang Liu, Gang Niu, Masashi Sugiyama</h3>
<p>The maximum mean discrepancy (MMD) test, as a representative two-sample test,
could in principle detect any distributional discrepancy between two datasets.
However, it has been shown that MMD is unaware of adversarial attacks -- MMD
failed to detect the discrepancy between natural data and adversarial data.
Given this phenomenon, we raise a question: are natural and adversarial data
really from different distributions but the previous use of MMD on the purpose
missed some key factors? The answer is affirmative. We find the previous use
missed three factors and accordingly we propose three components: (a) Gaussian
kernel has limited representation power, and we replace it with an effective
semantic-aware deep kernel; (b) test power of MMD was neglected, and we
maximize it in order to optimize our deep kernel; (c) adversarial data may be
non-independent, and to this end, we apply wild bootstrap for the correctness
of the test power. By taking care of the three factors, we verify that MMD is
aware of adversarial attacks based on extensive experiments, which lights up a
novel road for adversarial attack detection based on two-sample tests.
</p>
<a href="http://arxiv.org/abs/2010.11415" target="_blank">arXiv:2010.11415</a> [<a href="http://arxiv.org/pdf/2010.11415" target="_blank">pdf</a>]

<h2>Graph and graphon neural network stability. (arXiv:2010.12529v3 [cs.LG] UPDATED)</h2>
<h3>Luana Ruiz, Zhiyang Wang, Alejandro Ribeiro</h3>
<p>Graph neural networks (GNNs) are learning architectures that rely on
knowledge of the graph structure to generate meaningful representations of
large-scale network data. GNN stability is thus important as in real-world
scenarios there are typically uncertainties associated with the graph. We
analyze GNN stability using kernel objects called graphons. Graphons are both
limits of convergent graph sequences and generating models for deterministic
and stochastic graphs. Building upon the theory of graphon signal processing,
we define graphon neural networks and analyze their stability to graphon
perturbations. We then extend this analysis by interpreting the graphon neural
network as a generating model for GNNs on deterministic and stochastic graphs
instantiated from the original and perturbed graphons. We observe that GNNs are
stable to graphon perturbations with a stability bound that decreases
asymptotically with the size of the graph. This asymptotic behavior is further
demonstrated in an experiment of movie recommendation.
</p>
<a href="http://arxiv.org/abs/2010.12529" target="_blank">arXiv:2010.12529</a> [<a href="http://arxiv.org/pdf/2010.12529" target="_blank">pdf</a>]

<h2>Measuring and Harnessing Transference in Multi-Task Learning. (arXiv:2010.15413v2 [cs.LG] UPDATED)</h2>
<h3>Christopher Fifty, Ehsan Amid, Zhe Zhao, Tianhe Yu, Rohan Anil, Chelsea Finn</h3>
<p>Multi-task learning can leverage information learned by one task to benefit
the training of other tasks. Despite this capacity, naive formulations often
degrade performance and in particular, identifying the tasks that would benefit
from co-training remains a challenging design question. In this paper, we
analyze the dynamics of information transfer, or transference, across tasks
throughout training. Specifically, we develop a similarity measure that can
quantify transference among tasks and use this quantity to both better
understand the optimization dynamics of multi-task learning as well as improve
overall learning performance. In the latter case, we propose two methods to
leverage our transference metric. The first operates at a macro-level by
selecting which tasks should train together while the second functions at a
micro-level by determining how to combine task gradients at each training step.
We find these methods can lead to significant improvement over prior work on
three supervised multi-task learning benchmarks and one multi-task
reinforcement learning paradigm.
</p>
<a href="http://arxiv.org/abs/2010.15413" target="_blank">arXiv:2010.15413</a> [<a href="http://arxiv.org/pdf/2010.15413" target="_blank">pdf</a>]

<h2>Scalable Graph Neural Networks via Bidirectional Propagation. (arXiv:2010.15421v2 [cs.LG] UPDATED)</h2>
<h3>Ming Chen, Zhewei Wei, Bolin Ding, Yaliang Li, Ye Yuan, Xiaoyong Du, Ji-Rong Wen</h3>
<p>Graph Neural Networks (GNN) is an emerging field for learning on
non-Euclidean data. Recently, there has been increased interest in designing
GNN that scales to large graphs. Most existing methods use "graph sampling" or
"layer-wise sampling" techniques to reduce training time. However, these
methods still suffer from degrading performance and scalability problems when
applying to graphs with billions of edges. This paper presents GBP, a scalable
GNN that utilizes a localized bidirectional propagation process from both the
feature vectors and the training/testing nodes. Theoretical analysis shows that
GBP is the first method that achieves sub-linear time complexity for both the
precomputation and the training phases. An extensive empirical study
demonstrates that GBP achieves state-of-the-art performance with significantly
less training/testing time. Most notably, GBP can deliver superior performance
on a graph with over 60 million nodes and 1.8 billion edges in less than half
an hour on a single machine. The codes of GBP can be found at
https://github.com/chennnM/GBP .
</p>
<a href="http://arxiv.org/abs/2010.15421" target="_blank">arXiv:2010.15421</a> [<a href="http://arxiv.org/pdf/2010.15421" target="_blank">pdf</a>]

<h2>Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning. (arXiv:2011.00517v2 [cs.LG] UPDATED)</h2>
<h3>Valerie Chen, Abhinav Gupta, Kenneth Marino</h3>
<p>Complex, multi-task problems have proven to be difficult to solve efficiently
in a sparse-reward reinforcement learning setting. In order to be sample
efficient, multi-task learning requires reuse and sharing of low-level
policies. To facilitate the automatic decomposition of hierarchical tasks, we
propose the use of step-by-step human demonstrations in the form of natural
language instructions and action trajectories. We introduce a dataset of such
demonstrations in a crafting-based grid world. Our model consists of a
high-level language generator and low-level policy, conditioned on language. We
find that human demonstrations help solve the most complex tasks. We also find
that incorporating natural language allows the model to generalize to unseen
tasks in a zero-shot setting and to learn quickly from a few demonstrations.
Generalization is not only reflected in the actions of the agent, but also in
the generated natural language instructions in unseen tasks. Our approach also
gives our trained agent interpretable behaviors because it is able to generate
a sequence of high-level descriptions of its actions.
</p>
<a href="http://arxiv.org/abs/2011.00517" target="_blank">arXiv:2011.00517</a> [<a href="http://arxiv.org/pdf/2011.00517" target="_blank">pdf</a>]

<h2>An HVS-Oriented Saliency Map Prediction Modeling. (arXiv:2011.04076v4 [cs.CV] UPDATED)</h2>
<h3>Qiang Li</h3>
<p>Visual attention is one of the most significant characteristics for selecting
and understanding the outside redundancy world. The nature complex scenes,
including larger redundancy and human vision, cannot be processing all
information simultaneously because of the information bottleneck. The human
visual system mainly focuses on dominant parts of the scenes to reduce the
input visual redundancy information. It is commonly known as visual attention
prediction or visual saliency map. This paper proposes a new saliency
prediction architecture WECSF which inspired by human low-level visual cortex
function. The model consists of opponent color channels, wavelet transform,
wavelet energy map, and contrast sensitivity function for extracting low-level
image features and maximum approximation to the human visual system. The
proposed model is evaluated several datasets, including MIT1003, MIT300,
TORONTO, SID4VAM and UCF Sports dataset to explain its efficiency. The proposed
model results are quantitatively and qualitatively compared to other
state-of-the-art salience prediction models. Compared with the baseline model,
our model achieved very good performance. Secondly, we also confirmed
Fourier/Spectral inspired saliency prediction models has the best prediction
scores compared to other start-of-the-art non-neural network and even deep
neural network models on the simple image features saliency prediction.
Finally, the model also can be applied to spatial-temporal saliency prediction
and got better performance.
</p>
<a href="http://arxiv.org/abs/2011.04076" target="_blank">arXiv:2011.04076</a> [<a href="http://arxiv.org/pdf/2011.04076" target="_blank">pdf</a>]

<h2>A Quantitative Perspective on Values of Domain Knowledge for Machine Learning. (arXiv:2011.08450v2 [cs.LG] UPDATED)</h2>
<h3>Jianyi Yang, Shaolei Ren</h3>
<p>With the exploding popularity of machine learning, domain knowledge in
various forms has been playing a crucial role in improving the learning
performance, especially when training data is limited. Nonetheless, there is
little understanding of to what extent domain knowledge can affect a machine
learning task from a quantitative perspective. To increase the transparency and
rigorously explain the role of domain knowledge in machine learning, we study
the problem of quantifying the values of domain knowledge in terms of its
contribution to the learning performance in the context of informed machine
learning. We propose a quantification method based on Shapley value that fairly
attributes the overall learning performance improvement to different domain
knowledge. We also present Monte-Carlo sampling to approximate the fair value
of domain knowledge with a polynomial time complexity. We run experiments of
injecting symbolic domain knowledge into semi-supervised learning tasks on both
MNIST and CIFAR10 datasets, providing quantitative values of different symbolic
knowledge and rigorously explaining how it affects the machine learning
performance in terms of test accuracy.
</p>
<a href="http://arxiv.org/abs/2011.08450" target="_blank">arXiv:2011.08450</a> [<a href="http://arxiv.org/pdf/2011.08450" target="_blank">pdf</a>]

<h2>A Discussion on Practical Considerations with Sparse Regression Methodologies. (arXiv:2011.09362v2 [cs.LG] UPDATED)</h2>
<h3>Owais Sarwar, Benjamin Sauk, Nikolaos V. Sahinidis</h3>
<p>Sparse linear regression is a vast field and there are many different
algorithms available to build models. Two new papers published in Statistical
Science study the comparative performance of several sparse regression
methodologies, including the lasso and subset selection. Comprehensive
empirical analyses allow the researchers to demonstrate the relative merits of
each estimator and provide guidance to practitioners. In this discussion, we
summarize and compare the two studies and we examine points of agreement and
divergence, aiming to provide clarity and value to users. The authors have
started a highly constructive dialogue, our goal is to continue it.
</p>
<a href="http://arxiv.org/abs/2011.09362" target="_blank">arXiv:2011.09362</a> [<a href="http://arxiv.org/pdf/2011.09362" target="_blank">pdf</a>]

<h2>Stable Weight Decay Regularization. (arXiv:2011.11152v3 [cs.LG] UPDATED)</h2>
<h3>Zeke Xie, Issei Sato, Masashi Sugiyama</h3>
<p>Weight decay is a popular regularization technique for training of deep
neural networks. Modern deep learning libraries mainly use $L_{2}$
regularization as the default implementation of weight decay.
\citet{loshchilov2018decoupled} demonstrated that $L_{2}$ regularization is not
identical to weight decay for adaptive gradient methods, such as Adaptive
Momentum Estimation (Adam), and proposed Adam with Decoupled Weight Decay
(AdamW). However, we found that the popular implementations of weight decay,
including $L_{2}$ regularization and decoupled weight decay, in modern deep
learning libraries usually damage performance. First, the $L_{2}$
regularization is unstable weight decay for all optimizers that use Momentum,
such as stochastic gradient descent (SGD). Second, decoupled weight decay is
highly unstable for all adaptive gradient methods. We further propose the
Stable Weight Decay (SWD) method to fix the unstable weight decay problem from
a dynamical perspective. The proposed SWD method makes significant improvements
over $L_{2}$ regularization and decoupled weight decay in our experiments.
Simply fixing weight decay in Adam by SWD, with no extra hyperparameter, can
usually outperform complex Adam variants, which have more hyperparameters.
</p>
<a href="http://arxiv.org/abs/2011.11152" target="_blank">arXiv:2011.11152</a> [<a href="http://arxiv.org/pdf/2011.11152" target="_blank">pdf</a>]

<h2>Time-series Change Point Detection with Self-Supervised Contrastive Predictive Coding. (arXiv:2011.14097v3 [cs.LG] UPDATED)</h2>
<h3>Shohreh Deldari, Daniel V. Smith, Hao Xue, Flora D. Salim</h3>
<p>Change Point Detection (CPD) methods identify changes in the trends and
properties of time series data in order to describe the underlying behaviour of
the system. Detecting changes and anomalies in the web services, the trend of
application usage, and sensor data can provide valuable insights into the
system. We propose TS-CP2 a novel self-supervised approach for CPD that is
based upon contrastive representation learning with a Temporal Convolutional
Network (TCN). TS-CP2 is the first CPD approach to employ a contrastive
learning strategy. Through extensive evaluations, we demonstrate that our
method outperforms five different state-of-the-art CPD methods, including those
adopting either unsupervised or semi-supervised approach. TS-CP2 is shown to
improve both non-Deep learning- and Deep learning-based methods by 0.28 and0.12
in terms of average F1-score across three datasets, respectively.
</p>
<a href="http://arxiv.org/abs/2011.14097" target="_blank">arXiv:2011.14097</a> [<a href="http://arxiv.org/pdf/2011.14097" target="_blank">pdf</a>]

<h2>When Do Curricula Work?. (arXiv:2012.03107v3 [cs.LG] UPDATED)</h2>
<h3>Xiaoxia Wu, Ethan Dyer, Behnam Neyshabur</h3>
<p>Inspired by human learning, researchers have proposed ordering examples
during training based on their difficulty. Both curriculum learning, exposing a
network to easier examples early in training, and anti-curriculum learning,
showing the most difficult examples first, have been suggested as improvements
to the standard i.i.d. training. In this work, we set out to investigate the
relative benefits of ordered learning. We first investigate the \emph{implicit
curricula} resulting from architectural and optimization bias and find that
samples are learned in a highly consistent order. Next, to quantify the benefit
of \emph{explicit curricula}, we conduct extensive experiments over thousands
of orderings spanning three kinds of learning: curriculum, anti-curriculum, and
random-curriculum -- in which the size of the training dataset is dynamically
increased over time, but the examples are randomly ordered. We find that for
standard benchmark datasets, curricula have only marginal benefits, and that
randomly ordered samples perform as well or better than curricula and
anti-curricula, suggesting that any benefit is entirely due to the dynamic
training set size. Inspired by common use cases of curriculum learning in
practice, we investigate the role of limited training time budget and noisy
data in the success of curriculum learning. Our experiments demonstrate that
curriculum, but not anti-curriculum can indeed improve the performance either
with limited training time budget or in existence of noisy data.
</p>
<a href="http://arxiv.org/abs/2012.03107" target="_blank">arXiv:2012.03107</a> [<a href="http://arxiv.org/pdf/2012.03107" target="_blank">pdf</a>]

<h2>Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL. (arXiv:2012.08005v2 [cs.LG] UPDATED)</h2>
<h3>Andrea Zanette</h3>
<p>Several practical applications of reinforcement learning involve an agent
learning from past data without the possibility of further exploration. Often
these applications require us to 1) identify a near optimal policy or to 2)
estimate the value of a target policy. For both tasks we derive
\emph{exponential} information-theoretic lower bounds in discounted infinite
horizon MDPs with a linear function representation for the action value
function even if 1) \emph{realizability} holds, 2) the batch algorithm observes
the exact reward and transition \emph{functions}, and 3) the batch algorithm is
given the \emph{best} a priori data distribution for the problem class.
Furthermore, if the dataset does not come from policy rollouts then the lower
bounds hold even if the action-value function of \emph{every} policy admits a
linear representation.

If the objective is to find a near-optimal policy, we discover that these
hard instances are easily solved by an \emph{online} algorithm, showing that
there exist RL problems where \emph{batch RL is exponentially harder than
online RL} even under the most favorable batch data distribution. In other
words, online exploration is critical to enable sample efficient RL with
function approximation. A second corollary is the exponential separation
between finite and infinite horizon batch problems under our assumptions. On a
technical level, this work helps formalize the issue known as \emph{deadly
triad} and explains that the \emph{bootstrapping} problem
\citep{sutton2018reinforcement} is potentially more severe than the
\emph{extrapolation} issue for RL because unlike the latter, bootstrapping
cannot be mitigated by adding more samples.
</p>
<a href="http://arxiv.org/abs/2012.08005" target="_blank">arXiv:2012.08005</a> [<a href="http://arxiv.org/pdf/2012.08005" target="_blank">pdf</a>]

<h2>Rebuilding Trust in Active Learning with Actionable Metrics. (arXiv:2012.11365v2 [cs.LG] UPDATED)</h2>
<h3>Alexandre Abraham, L&#xe9;o Dreyfus-Schmidt</h3>
<p>Active Learning (AL) is an active domain of research, but is seldom used in
the industry despite the pressing needs. This is in part due to a misalignment
of objectives, while research strives at getting the best results on selected
datasets, the industry wants guarantees that Active Learning will perform
consistently and at least better than random labeling. The very one-off nature
of Active Learning makes it crucial to understand how strategy selection can be
carried out and what drives poor performance (lack of exploration, selection of
samples that are too hard to classify, ...).

To help rebuild trust of industrial practitioners in Active Learning, we
present various actionable metrics. Through extensive experiments on reference
datasets such as CIFAR100, Fashion-MNIST, and 20Newsgroups, we show that those
metrics brings interpretability to AL strategies that can be leveraged by the
practitioner.
</p>
<a href="http://arxiv.org/abs/2012.11365" target="_blank">arXiv:2012.11365</a> [<a href="http://arxiv.org/pdf/2012.11365" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning Optimizes Graphene Nanopores for Efficient Desalination. (arXiv:2101.07399v2 [cs.LG] UPDATED)</h2>
<h3>Yuyang Wang, Zhonglin Cao, Amir Barati Farimani</h3>
<p>Two-dimensional nanomaterials, such as graphene, have been extensively
studied because of their outstanding physical properties. Structure and
geometry optimization of nanopores on such materials is beneficial for their
performances in real-world engineering applications, like water desalination.
However, the optimization process often involves very large number of
experiments or simulations which are expensive and time-consuming. In this
work, we propose a graphene nanopore optimization framework via the combination
of deep reinforcement learning (DRL) and convolutional neural network (CNN) for
efficient water desalination. The DRL agent controls the growth of nanopore by
determining the atom to be removed at each timestep, while the CNN predicts the
performance of nanoporus graphene for water desalination: the water flux and
ion rejection at a certain external pressure. With the synchronous feedback
from CNN-accelerated desalination performance prediction, our DRL agent can
optimize the nanoporous graphene efficiently in an online manner. Molecular
dynamics (MD) simulations on promising DRL-designed graphene nanopores show
that they have higher water flux while maintaining rival ion rejection rate
compared to the normal circular nanopores. Semi-oval shape with rough edges
geometry of DRL-designed pores is found to be the key factor for their high
water desalination performance. Ultimately, this study shows that DRL can be a
powerful tool for material design.
</p>
<a href="http://arxiv.org/abs/2101.07399" target="_blank">arXiv:2101.07399</a> [<a href="http://arxiv.org/pdf/2101.07399" target="_blank">pdf</a>]

<h2>Towards Latent Space Based Manipulation of Elastic Rods using Autoencoder Models and Robust Centerline Extractions. (arXiv:2101.07513v2 [cs.RO] UPDATED)</h2>
<h3>Jiaming Qi, Guangfu Ma, Peng Zhou, Haibo Zhang, Yueyong Lyu, David Navarro-Alarcon</h3>
<p>The automatic shape control of deformable objects is a challenging (and
currently hot) manipulation problem due to their high-dimensional geometric
features and complex physical properties. In this study, a new methodology to
manipulate elastic rods automatically into 2D desired shapes is presented. An
efficient vision-based controller that uses a deep autoencoder network is
designed to compute a compact representation of the object's
infinite-dimensional shape. An online algorithm that approximates the
sensorimotor mapping between the robot's configuration and the object's shape
features is used to deal with the latter's (typically unknown) mechanical
properties. The proposed approach computes the rod's centerline from raw visual
data in real-time by introducing an adaptive algorithm on the basis of a
self-organizing network. Its effectiveness is thoroughly validated with
simulations and experiments.
</p>
<a href="http://arxiv.org/abs/2101.07513" target="_blank">arXiv:2101.07513</a> [<a href="http://arxiv.org/pdf/2101.07513" target="_blank">pdf</a>]

<h2>Distilling Interpretable Models into Human-Readable Code. (arXiv:2101.08393v2 [cs.LG] UPDATED)</h2>
<h3>Walker Ravina, Ethan Sterling, Olexiy Oryeshko, Nathan Bell, Honglei Zhuang, Xuanhui Wang, Yonghui Wu, Alexander Grushetsky</h3>
<p>The goal of model distillation is to faithfully transfer teacher model
knowledge to a model which is faster, more generalizable, more interpretable,
or possesses other desirable characteristics. Human-readability is an important
and desirable standard for machine-learned model interpretability. Readable
models are transparent and can be reviewed, manipulated, and deployed like
traditional source code. As a result, such models can be improved outside the
context of machine learning and manually edited if desired. Given that directly
training such models is difficult, we propose to train interpretable models
using conventional methods, and then distill them into concise, human-readable
code.

The proposed distillation methodology approximates a model's univariate
numerical functions with piecewise-linear curves in a localized manner. The
resulting curve model representations are accurate, concise, human-readable,
and well-regularized by construction. We describe a piecewise-linear
curve-fitting algorithm that produces high-quality results efficiently and
reliably across a broad range of use cases. We demonstrate the effectiveness of
the overall distillation technique and our curve-fitting algorithm using four
datasets across the tasks of classification, regression, and ranking.
</p>
<a href="http://arxiv.org/abs/2101.08393" target="_blank">arXiv:2101.08393</a> [<a href="http://arxiv.org/pdf/2101.08393" target="_blank">pdf</a>]

<h2>Breaking the Deadly Triad with a Target Network. (arXiv:2101.08862v3 [cs.LG] UPDATED)</h2>
<h3>Shangtong Zhang, Hengshuai Yao, Shimon Whiteson</h3>
<p>The deadly triad refers to the instability of a reinforcement learning
algorithm when it employs off-policy learning, function approximation, and
bootstrapping simultaneously. In this paper, we investigate the target network
as a tool for breaking the deadly triad, providing theoretical support for the
conventional wisdom that a target network stabilizes training. We first propose
and analyze a novel target network update rule which augments the commonly used
Polyak-averaging style update with two projections. We then apply the target
network and ridge regularization in several divergent algorithms and show their
convergence to regularized TD fixed points. Those algorithms are off-policy
with linear function approximation and bootstrapping, spanning both policy
evaluation and control, as well as both discounted and average-reward settings.
In particular, we provide the first convergent linear $Q$-learning algorithms
under nonrestrictive and changing behavior policies without bi-level
optimization.
</p>
<a href="http://arxiv.org/abs/2101.08862" target="_blank">arXiv:2101.08862</a> [<a href="http://arxiv.org/pdf/2101.08862" target="_blank">pdf</a>]

<h2>Prior Preference Learning from Experts:Designing a Reward with Active Inference. (arXiv:2101.08937v2 [cs.LG] UPDATED)</h2>
<h3>Jinyoung Shin, Cheolhyeong Kim, Hyung Ju Hwang</h3>
<p>Active inference may be defined as Bayesian modeling of a brain with a
biologically plausible model of the agent. Its primary idea relies on the free
energy principle and the prior preference of the agent. An agent will choose an
action that leads to its prior preference for a future observation. In this
paper, we claim that active inference can be interpreted using reinforcement
learning (RL) algorithms and find a theoretical connection between them. We
extend the concept of expected free energy (EFE), which is a core quantity in
active inference, and claim that EFE can be treated as a negative value
function. Motivated by the concept of prior preference and a theoretical
connection, we propose a simple but novel method for learning a prior
preference from experts. This illustrates that the problem with inverse RL can
be approached with a new perspective of active inference. Experimental results
of prior preference learning show the possibility of active inference with
EFE-based rewards and its application to an inverse RL problem.
</p>
<a href="http://arxiv.org/abs/2101.08937" target="_blank">arXiv:2101.08937</a> [<a href="http://arxiv.org/pdf/2101.08937" target="_blank">pdf</a>]

<h2>Context-Specific Likelihood Weighting. (arXiv:2101.09791v2 [cs.AI] UPDATED)</h2>
<h3>Nitesh Kumar, Ond&#x159;ej Ku&#x17e;elka</h3>
<p>Sampling is a popular method for approximate inference when exact inference
is impractical. Generally, sampling algorithms do not exploit context-specific
independence (CSI) properties of probability distributions. We introduce
context-specific likelihood weighting (CS-LW), a new sampling methodology,
which besides exploiting the classical conditional independence properties,
also exploits CSI properties. Unlike the standard likelihood weighting, CS-LW
is based on partial assignments of random variables and requires fewer samples
for convergence due to the sampling variance reduction. Furthermore, the speed
of generating samples increases. Our novel notion of contextual assignments
theoretically justifies CS-LW. We empirically show that CS-LW is competitive
with state-of-the-art algorithms for approximate inference in the presence of a
significant amount of CSIs.
</p>
<a href="http://arxiv.org/abs/2101.09791" target="_blank">arXiv:2101.09791</a> [<a href="http://arxiv.org/pdf/2101.09791" target="_blank">pdf</a>]

<h2>Optimal Approximation Rates and Metric Entropy of ReLU$^k$ and Cosine Networks. (arXiv:2101.12365v2 [stat.ML] UPDATED)</h2>
<h3>Jonathan W. Siegel, Jinchao Xu</h3>
<p>This article addresses several fundamental issues associated with the
approximation theory of neural networks, including the characterization of
approximation spaces, the determination of the metric entropy of these spaces,
and approximation rates of neural networks. For any activation function
$\sigma$, we show that the largest Banach space of functions which can be
efficiently approximated by the corresponding shallow neural networks is the
space whose norm is given by the gauge of the closed convex hull of the set
$\{\pm\sigma(\omega\cdot x + b)\}$. We characterize this space for the ReLU$^k$
and cosine activation functions and, in particular, show that the resulting
gauge space is equivalent to the spectral Barron space if $\sigma=\cos$ and is
equivalent to the Barron space when $\sigma={\rm ReLU}$. Our main result
establishes the precise asymptotics of the $L^2$-metric entropy of the unit
ball of these guage spaces and, as a consequence, the optimal approximation
rates for shallow ReLU$^k$ networks. The sharpest previous results hold only in
the special case that $k=0$ and $d=2$, where the metric entropy has been
determined up to logarithmic factors. When $k &gt; 0$ or $d &gt; 2$, there is a
significant gap between the previous best upper and lower bounds. We close all
of these gaps and determine the precise asymptotics of the metric entropy for
all $k \geq 0$ and $d\geq 2$, including removing the logarithmic factors
previously mentioned. Finally, we use these results to quantify how much is
lost by Barron's spectral condition relative to the convex hull of
$\{\pm\sigma(\omega\cdot x + b)\}$ when $\sigma={\rm ReLU}^k$.
</p>
<a href="http://arxiv.org/abs/2101.12365" target="_blank">arXiv:2101.12365</a> [<a href="http://arxiv.org/pdf/2101.12365" target="_blank">pdf</a>]

<h2>M2FN: Multi-step Modality Fusion for Advertisement Image Assessment. (arXiv:2102.00441v4 [cs.CV] UPDATED)</h2>
<h3>Kyung-Wha Park (1), Jung-Woo Ha (2), JungHoon Lee (3), Sunyoung Kwon (4), Kyung-Min Kim (2), Byoung-Tak Zhang (1 and 5 and 6) ((1) Interdisciplinary Program in Neuroscience, Seoul National University., (2) NAVER AI LAB, NAVER CLOVA., (3) Statistics and Actuarial Science, Soongsil University., (4) School of Biomedical Convergence Engineering, Pusan National University., (5) Department of Computer Science and Engineering, Seoul National University., (6) Surromind Robotics.)</h3>
<p>Assessing advertisements, specifically on the basis of user preferences and
ad quality, is crucial to the marketing industry. Although recent studies have
attempted to use deep neural networks for this purpose, these studies have not
utilized image-related auxiliary attributes, which include embedded text
frequently found in ad images. We, therefore, investigated the influence of
these attributes on ad image preferences. First, we analyzed large-scale
real-world ad log data and, based on our findings, proposed a novel multi-step
modality fusion network (M2FN) that determines advertising images likely to
appeal to user preferences. Our method utilizes auxiliary attributes through
multiple steps in the network, which include conditional batch
normalization-based low-level fusion and attention-based high-level fusion. We
verified M2FN on the AVA dataset, which is widely used for aesthetic image
assessment, and then demonstrated that M2FN can achieve state-of-the-art
performance in preference prediction using a real-world ad dataset with rich
auxiliary attributes.
</p>
<a href="http://arxiv.org/abs/2102.00441" target="_blank">arXiv:2102.00441</a> [<a href="http://arxiv.org/pdf/2102.00441" target="_blank">pdf</a>]

<h2>Multi-Agent Reinforcement Learning with Temporal Logic Specifications. (arXiv:2102.00582v2 [cs.AI] UPDATED)</h2>
<h3>Lewis Hammond, Alessandro Abate, Julian Gutierrez, Michael Wooldridge</h3>
<p>In this paper, we study the problem of learning to satisfy temporal logic
specifications with a group of agents in an unknown environment, which may
exhibit probabilistic behaviour. From a learning perspective these
specifications provide a rich formal language with which to capture tasks or
objectives, while from a logic and automated verification perspective the
introduction of learning capabilities allows for practical applications in
large, stochastic, unknown environments. The existing work in this area is,
however, limited. Of the frameworks that consider full linear temporal logic or
have correctness guarantees, all methods thus far consider only the case of a
single temporal logic specification and a single agent. In order to overcome
this limitation, we develop the first multi-agent reinforcement learning
technique for temporal logic specifications, which is also novel in its ability
to handle multiple specifications. We provide correctness and convergence
guarantees for our main algorithm - ALMANAC (Automaton/Logic Multi-Agent
Natural Actor-Critic) - even when using function approximation. Alongside our
theoretical results, we further demonstrate the applicability of our technique
via a set of preliminary experiments.
</p>
<a href="http://arxiv.org/abs/2102.00582" target="_blank">arXiv:2102.00582</a> [<a href="http://arxiv.org/pdf/2102.00582" target="_blank">pdf</a>]

<h2>Stability and Generalization of the Decentralized Stochastic Gradient Descent. (arXiv:2102.01302v2 [stat.ML] UPDATED)</h2>
<h3>Tao Sun, Dongsheng Li, Bao Wang</h3>
<p>The stability and generalization of stochastic gradient-based methods provide
valuable insights into understanding the algorithmic performance of machine
learning models. As the main workhorse for deep learning, stochastic gradient
descent has received a considerable amount of studies. Nevertheless, the
community paid little attention to its decentralized variants. In this paper,
we provide a novel formulation of the decentralized stochastic gradient
descent. Leveraging this formulation together with (non)convex optimization
theory, we establish the first stability and generalization guarantees for the
decentralized stochastic gradient descent. Our theoretical results are built on
top of a few common and mild assumptions and reveal that the decentralization
deteriorates the stability of SGD for the first time. We verify our theoretical
findings by using a variety of decentralized settings and benchmark machine
learning models.
</p>
<a href="http://arxiv.org/abs/2102.01302" target="_blank">arXiv:2102.01302</a> [<a href="http://arxiv.org/pdf/2102.01302" target="_blank">pdf</a>]

<h2>Size Matters. (arXiv:2102.01582v2 [cs.LG] UPDATED)</h2>
<h3>Mats L. Richter, Wolf Byttner, Ulf Krumnack, Ludwdig Schallner, Justin Shenk</h3>
<p>Fully convolutional neural networks can process input of arbitrary size by
applying a combination of downsampling and pooling. However, we find that fully
convolutional image classifiers are not agnostic to the input size but rather
show significant differences in performance: presenting the same image at
different scales can result in different outcomes. A closer look reveals that
there is no simple relationship between input size and model performance (no
`bigger is better'), but that each each network has a preferred input size, for
which it shows best results. We investigate this phenomenon by applying
different methods, including spectral analysis of layer activations and probe
classifiers, showing that there are characteristic features depending on the
network architecture. From this we find that the size of discriminatory
features is critically influencing how the inference process is distributed
among the layers.
</p>
<a href="http://arxiv.org/abs/2102.01582" target="_blank">arXiv:2102.01582</a> [<a href="http://arxiv.org/pdf/2102.01582" target="_blank">pdf</a>]

<h2>Keep it Simple: Data-efficient Learning for Controlling Complex Systems with Simple Models. (arXiv:2102.02493v2 [cs.RO] UPDATED)</h2>
<h3>Thomas Power, Dmitry Berenson</h3>
<p>When manipulating a novel object with complex dynamics, a state
representation is not always available, for example for deformable objects.
Learning both a representation and dynamics from observations requires large
amounts of data. We propose Learned Visual Similarity Predictive Control
(LVSPC), a novel method for data-efficient learning to control systems with
complex dynamics and high-dimensional state spaces from images. LVSPC leverages
a given simple model approximation from which image observations can be
generated. We use these images to train a perception model that estimates the
simple model state from observations of the complex system online. We then use
data from the complex system to fit the parameters of the simple model and
learn where this model is inaccurate, also online. Finally, we use Model
Predictive Control and bias the controller away from regions where the simple
model is inaccurate and thus where the controller is less reliable. We evaluate
LVSPC on two tasks; manipulating a tethered mass and a rope. We find that our
method performs comparably to state-of-the-art reinforcement learning methods
with an order of magnitude less data. LVSPC also completes the rope
manipulation task on a real robot with 80% success rate after only 10 trials,
despite using a perception system trained only on images from simulation.
</p>
<a href="http://arxiv.org/abs/2102.02493" target="_blank">arXiv:2102.02493</a> [<a href="http://arxiv.org/pdf/2102.02493" target="_blank">pdf</a>]

<h2>Understanding Emails and Drafting Responses -- An Approach Using GPT-3. (arXiv:2102.03062v2 [cs.AI] UPDATED)</h2>
<h3>Jonas Thiergart, Stefan Huber, Thomas &#xdc;bellacker</h3>
<p>Providing computer systems with the ability to understand and generate
natural language has long been a challenge of engineers. Recent progress in
natural language processing (NLP), like the GPT-3 language model released by
OpenAI, has made both possible to an extent. In this paper, we explore the
possibility of rationalising email communication using GPT-3. First, we
demonstrate the technical feasibility of understanding incoming emails and
generating responses, drawing on literature from the disciplines of software
engineering as well as data science. Second, we apply knowledge from both
business studies and, again, software engineering to identify ways to tackle
challenges we encountered. Third, we argue for the economic viability of such a
solution by analysing costs and market demand. We conclude that applying GPT-3
to rationalising email communication is feasible both technically and
economically.
</p>
<a href="http://arxiv.org/abs/2102.03062" target="_blank">arXiv:2102.03062</a> [<a href="http://arxiv.org/pdf/2102.03062" target="_blank">pdf</a>]

<h2>Understanding the Interaction of Adversarial Training with Noisy Labels. (arXiv:2102.03482v2 [cs.LG] UPDATED)</h2>
<h3>Jianing Zhu, Jingfeng Zhang, Bo Han, Tongliang Liu, Gang Niu, Hongxia Yang, Mohan Kankanhalli, Masashi Sugiyama</h3>
<p>Noisy labels (NL) and adversarial examples both undermine trained models, but
interestingly they have hitherto been studied independently. A recent
adversarial training (AT) study showed that the number of projected gradient
descent (PGD) steps to successfully attack a point (i.e., find an adversarial
example in its proximity) is an effective measure of the robustness of this
point. Given that natural data are clean, this measure reveals an intrinsic
geometric property -- how far a point is from its class boundary. Based on this
breakthrough, in this paper, we figure out how AT would interact with NL.
Firstly, we find if a point is too close to its noisy-class boundary (e.g., one
step is enough to attack it), this point is likely to be mislabeled, which
suggests to adopt the number of PGD steps as a new criterion for sample
selection for correcting NL. Secondly, we confirm AT with strong smoothing
effects suffers less from NL (without NL corrections) than standard training
(ST), which suggests AT itself is an NL correction. Hence, AT with NL is
helpful for improving even the natural accuracy, which again illustrates the
superiority of AT as a general-purpose robust learning criterion.
</p>
<a href="http://arxiv.org/abs/2102.03482" target="_blank">arXiv:2102.03482</a> [<a href="http://arxiv.org/pdf/2102.03482" target="_blank">pdf</a>]

<h2>An Autonomous Negotiating Agent Framework with Reinforcement Learning Based Strategies and Adaptive Strategy Switching Mechanism. (arXiv:2102.03588v2 [cs.AI] UPDATED)</h2>
<h3>Ayan Sengupta, Yasser Mohammad, Shinji Nakadai</h3>
<p>Despite abundant negotiation strategies in literature, the complexity of
automated negotiation forbids a single strategy from being dominant against all
others in different negotiation scenarios. To overcome this, one approach is to
use mixture of experts, but at the same time, one problem of this method is the
selection of experts, as this approach is limited by the competency of the
experts selected. Another problem with most negotiation strategies is their
incapability of adapting to dynamic variation of the opponent's behaviour
within a single negotiation session resulting in poor performance. This work
focuses on both, solving the problem of expert selection and adapting to the
opponent's behaviour with our Autonomous Negotiating Agent Framework. This
framework allows real-time classification of opponent's behaviour and provides
a mechanism to select, switch or combine strategies within a single negotiation
session. Additionally, our framework has a reviewer component which enables
self-enhancement capability by deciding to include new strategies or replace
old ones with better strategies periodically. We demonstrate an instance of our
framework by implementing maximum entropy reinforcement learning based
strategies with a deep learning based opponent classifier. Finally, we evaluate
the performance of our agent against state-of-the-art negotiators under varied
negotiation scenarios.
</p>
<a href="http://arxiv.org/abs/2102.03588" target="_blank">arXiv:2102.03588</a> [<a href="http://arxiv.org/pdf/2102.03588" target="_blank">pdf</a>]

<h2>Bootstrapping Statistical Inference for Off-Policy Evaluation. (arXiv:2102.03607v2 [stat.ML] UPDATED)</h2>
<h3>Botao Hao, Xiang Ji, Yaqi Duan, Hao Lu, Csaba Szepesv&#xe1;ri, Mengdi Wang</h3>
<p>Bootstrapping provides a flexible and effective approach for assessing the
quality of batch reinforcement learning, yet its theoretical property is less
understood. In this paper, we study the use of bootstrapping in off-policy
evaluation (OPE), and in particular, we focus on the fitted Q-evaluation (FQE)
that is known to be minimax-optimal in the tabular and linear-model cases. We
propose a bootstrapping FQE method for inferring the distribution of the policy
evaluation error and show that this method is asymptotically efficient and
distributionally consistent for off-policy statistical inference. To overcome
the computation limit of bootstrapping, we further adapt a subsampling
procedure that improves the runtime by an order of magnitude. We numerically
evaluate the bootrapping method in classical RL environments for confidence
interval estimation, estimating the variance of off-policy evaluator, and
estimating the correlation between multiple off-policy evaluators.
</p>
<a href="http://arxiv.org/abs/2102.03607" target="_blank">arXiv:2102.03607</a> [<a href="http://arxiv.org/pdf/2102.03607" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning with Dynamic Optimism. (arXiv:2102.03765v2 [cs.LG] UPDATED)</h2>
<h3>Ted Moskovitz, Jack Parker-Holder, Aldo Pacchiano, Michael Arbel</h3>
<p>In recent years, deep off-policy actor-critic algorithms have become a
dominant approach to reinforcement learning for continuous control. This comes
after a series of breakthroughs to address function approximation errors, which
previously led to poor performance. These insights encourage the use of
pessimistic value updates. However, this discourages exploration and runs
counter to theoretical support for the efficacy of optimism in the face of
uncertainty. So which approach is best? In this work, we show that the optimal
degree of optimism can vary both across tasks and over the course of learning.
Inspired by this insight, we introduce a novel deep actor-critic algorithm,
Dynamic Optimistic and Pessimistic Estimation (DOPE) to switch between
optimistic and pessimistic value learning online by formulating the selection
as a multi-arm bandit problem. We show in a series of challenging continuous
control tasks that DOPE outperforms existing state-of-the-art methods, which
rely on a fixed degree of optimism. Since our changes are simple to implement,
we believe these insights can be extended to a number of off-policy algorithms.
</p>
<a href="http://arxiv.org/abs/2102.03765" target="_blank">arXiv:2102.03765</a> [<a href="http://arxiv.org/pdf/2102.03765" target="_blank">pdf</a>]

<h2>Functional Optimal Transport: Mapping Estimation and Domain Adaptation for Functional data. (arXiv:2102.03895v2 [stat.ML] UPDATED)</h2>
<h3>Jiacheng Zhu, Aritra Guha, Mengdi Xu, Yingchen Ma, Rayleigh Lei, Vincenzo Loffredo, XuanLong Nguyen, Ding Zhao</h3>
<p>Optimal transport (OT) has generated much recent interest by its capability
of finding mappings that transport mass from one distribution to another, and
found useful roles in machine learning tasks such as unsupervised learning,
domain adaptation and transfer learning. On the other hand, in many
applications data are generated by complex mechanisms involving convoluted
spaces of functions, curves and surfaces in high dimensions. Functional data
analysis provides a useful framework of treatment for such domains. In this
paper we introduce a novel formulation of optimal transport problem in
functional spaces and develop an efficient learning algorithm for finding the
stochastic map between functional domains. We apply our method to synthetic
datasets and study the geometric properties of the transport map. Experiments
on real-world datasets of robot arm trajectories and digit numbers further
demonstrate the effectiveness of our method on applications of domain
adaptation and generative modeling.
</p>
<a href="http://arxiv.org/abs/2102.03895" target="_blank">arXiv:2102.03895</a> [<a href="http://arxiv.org/pdf/2102.03895" target="_blank">pdf</a>]

<h2>Meta-Learning with Neural Tangent Kernels. (arXiv:2102.03909v2 [cs.LG] UPDATED)</h2>
<h3>Yufan Zhou, Zhenyi Wang, Jiayi Xian, Changyou Chen, Jinhui Xu</h3>
<p>Model Agnostic Meta-Learning (MAML) has emerged as a standard framework for
meta-learning, where a meta-model is learned with the ability of fast adapting
to new tasks. However, as a double-looped optimization problem, MAML needs to
differentiate through the whole inner-loop optimization path for every
outer-loop training step, which may lead to both computational inefficiency and
sub-optimal solutions. In this paper, we generalize MAML to allow meta-learning
to be defined in function spaces, and propose the first meta-learning paradigm
in the Reproducing Kernel Hilbert Space (RKHS) induced by the meta-model's
Neural Tangent Kernel (NTK). Within this paradigm, we introduce two
meta-learning algorithms in the RKHS, which no longer need a sub-optimal
iterative inner-loop adaptation as in the MAML framework. We achieve this goal
by 1) replacing the adaptation with a fast-adaptive regularizer in the RKHS;
and 2) solving the adaptation analytically based on the NTK theory. Extensive
experimental studies demonstrate advantages of our paradigm in both efficiency
and quality of solutions compared to related meta-learning algorithms. Another
interesting feature of our proposed methods is that they are demonstrated to be
more robust to adversarial attacks and out-of-distribution adaptation than
popular baselines, as demonstrated in our experiments.
</p>
<a href="http://arxiv.org/abs/2102.03909" target="_blank">arXiv:2102.03909</a> [<a href="http://arxiv.org/pdf/2102.03909" target="_blank">pdf</a>]

<h2>Single-Shot Cuboids: Geodesics-based End-to-end Manhattan Aligned Layout Estimation from Spherical Panoramas. (arXiv:2102.03939v2 [cs.CV] UPDATED)</h2>
<h3>Nikolaos Zioulis, Federico Alvarez, Dimitrios Zarpalas, Petros Daras</h3>
<p>It has been shown that global scene understanding tasks like layout
estimation can benefit from wider field of views, and specifically spherical
panoramas. While much progress has been made recently, all previous approaches
rely on intermediate representations and postprocessing to produce
Manhattan-aligned estimates. In this work we show how to estimate full room
layouts in a single-shot, eliminating the need for postprocessing. Our work is
the first to directly infer Manhattan-aligned outputs. To achieve this, our
data-driven model exploits direct coordinate regression and is supervised
end-to-end. As a result, we can explicitly add quasi-Manhattan constraints,
which set the necessary conditions for a homography-based Manhattan alignment
module. Finally, we introduce the geodesic heatmaps and loss and a
boundary-aware center of mass calculation that facilitate higher quality
keypoint estimation in the spherical domain. Our models and code are publicly
available at https://vcl3d.github.io/SingleShotCuboids/.
</p>
<a href="http://arxiv.org/abs/2102.03939" target="_blank">arXiv:2102.03939</a> [<a href="http://arxiv.org/pdf/2102.03939" target="_blank">pdf</a>]

<h2>Reliable Probabilistic Face Embeddings in the Wild. (arXiv:2102.04075v2 [cs.CV] UPDATED)</h2>
<h3>Kai Chen, Qi Lv, Taihe Yi, Zhengming Yi</h3>
<p>Probabilistic Face Embeddings (PFE) can improve face recognition performance
in unconstrained scenarios by integrating data uncertainty into the feature
representation. However, existing PFE methods tend to be over-confident in
estimating uncertainty and is too slow to apply to large-scale face matching.
This paper proposes a regularized probabilistic face embedding method to
improve the robustness and speed of PFE. Specifically, the mutual likelihood
score (MLS) metric used in PFE is simplified to speedup the matching of face
feature pairs. Then, an output-constraint loss is proposed to penalize the
variance of the uncertainty output, which can regularize the output of the
neural network. In addition, an identification preserving loss is proposed to
improve the discriminative of the MLS metric, and a multi-layer feature fusion
module is proposed to improve the neural network's uncertainty estimation
ability. Comprehensive experiments show that the proposed method can achieve
comparable or better results in 8 benchmarks than the state-of-the-art methods,
and can improve the performance of risk-controlled face recognition. The code
of ProbFace is publicly available in GitHub
(https://github.com/KaenChan/ProbFace).
</p>
<a href="http://arxiv.org/abs/2102.04075" target="_blank">arXiv:2102.04075</a> [<a href="http://arxiv.org/pdf/2102.04075" target="_blank">pdf</a>]

<h2>MetaTune: Meta-Learning Based Cost Model for Fast and Efficient Auto-tuning Frameworks. (arXiv:2102.04199v2 [cs.LG] UPDATED)</h2>
<h3>Jaehun Ryu, Hyojin Sung</h3>
<p>Deep learning compiler frameworks are gaining ground as a more portable
back-end for deep learning applications on increasingly diverse hardware.
However, they face the daunting challenge of matching performance offered by
hand-tuned target-specific libraries. While auto-tuning frameworks with
statistical cost models can provide dynamic and efficient code optimization,
they suffer from large space exploration and cost model training overheads.
This paper proposes MetaTune, a meta-learning based cost model that more
quickly and accurately predicts the performance of optimized codes with
pre-trained model parameters. MetaTune encodes convolution kernel codes as
structurally similar graphs to facilitate meta-learning, meta-trains a GNN
model with a very small input data set, and then predicts optimization
parameters for unseen convolution operations with varying sizes and structures
during compilation. The resulting framework with MetaTune provides 8 to 13%
better inference time on average for four CNN models with comparable or lower
optimization time while outperforming transfer learning by 10% in
cross-platform cases.
</p>
<a href="http://arxiv.org/abs/2102.04199" target="_blank">arXiv:2102.04199</a> [<a href="http://arxiv.org/pdf/2102.04199" target="_blank">pdf</a>]

