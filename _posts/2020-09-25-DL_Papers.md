---
title: Latest Deep Learning Papers
date: 2021-02-03 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (119 Articles)</h1>
<h2>Apollo: Transferable Architecture Exploration. (arXiv:2102.01723v1 [cs.LG])</h2>
<h3>Amir Yazdanbakhsh, Christof Angermueller, Berkin Akin, Yanqi Zhou, Albin Jones, Milad Hashemi, Kevin Swersky, Satrajit Chatterjee, Ravi Narayanaswami, James Laudon</h3>
<p>The looming end of Moore's Law and ascending use of deep learning drives the
design of custom accelerators that are optimized for specific neural
architectures. Architecture exploration for such accelerators forms a
challenging constrained optimization problem over a complex, high-dimensional,
and structured input space with a costly to evaluate objective function.
Existing approaches for accelerator design are sample-inefficient and do not
transfer knowledge between related optimizations tasks with different design
constraints, such as area and/or latency budget, or neural architecture
configurations. In this work, we propose a transferable architecture
exploration framework, dubbed Apollo, that leverages recent advances in
black-box function optimization for sample-efficient accelerator design. We use
this framework to optimize accelerator configurations of a diverse set of
neural architectures with alternative design constraints. We show that our
framework finds high reward design configurations (up to 24.6% speedup) more
sample-efficiently than a baseline black-box optimization approach. We further
show that by transferring knowledge between target architectures with different
design constraints, Apollo is able to find optimal configurations faster and
often with better objective value (up to 25% improvements). This encouraging
outcome portrays a promising path forward to facilitate generating higher
quality accelerators.
</p>
<a href="http://arxiv.org/abs/2102.01723" target="_blank">arXiv:2102.01723</a> [<a href="http://arxiv.org/pdf/2102.01723" target="_blank">pdf</a>]

<h2>Majorizing Measures, Sequential Complexities, and Online Learning. (arXiv:2102.01729v1 [stat.ML])</h2>
<h3>Adam Block, Yuval Dagan, Sasha Rakhlin</h3>
<p>We introduce the technique of generic chaining and majorizing measures for
controlling sequential Rademacher complexity. We relate majorizing measures to
the notion of fractional covering numbers, which we show to be dominated in
terms of sequential scale-sensitive dimensions in a horizon-independent way,
and, under additional complexity assumptions establish a tight control on
worst-case sequential Rademacher complexity in terms of the integral of
sequential scale-sensitive dimension. Finally, we establish a tight contraction
inequality for worst-case sequential Rademacher complexity. The above
constitutes the resolution of a number of outstanding open problems in
extending the classical theory of empirical processes to the sequential case,
and, in turn, establishes sharp results for online learning.
</p>
<a href="http://arxiv.org/abs/2102.01729" target="_blank">arXiv:2102.01729</a> [<a href="http://arxiv.org/pdf/2102.01729" target="_blank">pdf</a>]

<h2>Truly Sparse Neural Networks at Scale. (arXiv:2102.01732v1 [cs.LG])</h2>
<h3>Selima Curci, Decebal Constantin Mocanu, Mykola Pechenizkiyi</h3>
<p>Recently, sparse training methods have started to be established as a de
facto approach for training and inference efficiency in artificial neural
networks. Yet, this efficiency is just in theory. In practice, everyone uses a
binary mask to simulate sparsity since the typical deep learning software and
hardware are optimized for dense matrix operations. In this paper, we take an
orthogonal approach, and we show that we can train truly sparse neural networks
to harvest their full potential. To achieve this goal, we introduce three novel
contributions, specially designed for sparse neural networks: (1) a parallel
training algorithm and its corresponding sparse implementation from scratch,
(2) an activation function with non-trainable parameters to favour the gradient
flow, and (3) a hidden neurons importance metric to eliminate redundancies. All
in one, we are able to break the record and to train the largest neural network
ever trained in terms of representational power -- reaching the bat brain size.
The results show that our approach has state-of-the-art performance while
opening the path for an environmentally friendly artificial intelligence era.
</p>
<a href="http://arxiv.org/abs/2102.01732" target="_blank">arXiv:2102.01732</a> [<a href="http://arxiv.org/pdf/2102.01732" target="_blank">pdf</a>]

<h2>FedProf: Optimizing Federated Learning with Dynamic Data Profiling. (arXiv:2102.01733v1 [cs.LG])</h2>
<h3>Wentai Wu, Ligang He, Weiwei Lin, Rui Mao, Chenlin Huang, Wei Song</h3>
<p>Federated Learning (FL) has shown great potential as a privacy-preserving
solution to learning from decentralized data which are only accessible locally
on end devices (i.e., clients). In many scenarios, however, a large proportion
of the clients are probably in possession of only low-quality data that are
biased, noisy or even irrelevant. As a result, they could significantly degrade
the quality of the global model we aim to build and slow down its convergence
in the course of FL. In light of this, we propose a novel approach to
optimizing FL under such circumstances without breaching data privacy. The key
of our approach is a dynamic data profiling method for generating model-data
footprints on each client and the server. The footprint encodes the
representation of the global model on the corresponding data partition based on
the output distribution of the model's first fully-connected layer (FC-1). By
matching the footprints from clients and the server, we adaptively adjust each
client's opportunity of participation in each FL round to mitigate the impact
from the clients with low-quality data. We have conducted extensive experiments
on public data sets using various FL settings. Results show that our method
significantly reduces the number of rounds (by up to 75\%) and overall time (by
up to 68\%) required to have the global model converge whiling increasing the
global model's accuracy by up to 2.5\%.
</p>
<a href="http://arxiv.org/abs/2102.01733" target="_blank">arXiv:2102.01733</a> [<a href="http://arxiv.org/pdf/2102.01733" target="_blank">pdf</a>]

<h2>Reliability Analysis of Artificial Intelligence Systems Using Recurrent Events Data from Autonomous Vehicles. (arXiv:2102.01740v1 [cs.AI])</h2>
<h3>Yili Hong, Jie Min, Caleb B. King, William Q. Meeker</h3>
<p>Artificial intelligence (AI) systems have become increasingly common and the
trend will continue. Examples of AI systems include autonomous vehicles (AV),
computer vision, natural language processing, and AI medical experts. To allow
for safe and effective deployment of AI systems, the reliability of such
systems needs to be assessed. Traditionally, reliability assessment is based on
reliability test data and the subsequent statistical modeling and analysis. The
availability of reliability data for AI systems, however, is limited because
such data are typically sensitive and proprietary. The California Department of
Motor Vehicles (DMV) oversees and regulates an AV testing program, in which
many AV manufacturers are conducting AV road tests. Manufacturers participating
in the program are required to report recurrent disengagement events to
California DMV. This information is being made available to the public. In this
paper, we use recurrent disengagement events as a representation of the
reliability of the AI system in AV, and propose a statistical framework for
modeling and analyzing the recurrent events data from AV driving tests. We use
traditional parametric models in software reliability and propose a new
nonparametric model based on monotonic splines to describe the event process.
We develop inference procedures for selecting the best models, quantifying
uncertainty, and testing heterogeneity in the event process. We then analyze
the recurrent events data from four AV manufacturers, and make inferences on
the reliability of the AI systems in AV. We also describe how the proposed
analysis can be applied to assess the reliability of other AI systems.
</p>
<a href="http://arxiv.org/abs/2102.01740" target="_blank">arXiv:2102.01740</a> [<a href="http://arxiv.org/pdf/2102.01740" target="_blank">pdf</a>]

<h2>Near-Optimal Offline Reinforcement Learning via Double Variance Reduction. (arXiv:2102.01748v1 [cs.LG])</h2>
<h3>Ming Yin, Yu Bai, Yu-Xiang Wang</h3>
<p>We consider the problem of offline reinforcement learning (RL) -- a
well-motivated setting of RL that aims at policy optimization using only
historical data. Despite its wide applicability, theoretical understandings of
offline RL, such as its optimal sample complexity, remain largely open even in
basic settings such as \emph{tabular} Markov Decision Processes (MDPs).

In this paper, we propose Off-Policy Double Variance Reduction (OPDVR), a new
variance reduction based algorithm for offline RL. Our main result shows that
OPDVR provably identifies an $\epsilon$-optimal policy with
$\widetilde{O}(H^2/d_m\epsilon^2)$ episodes of offline data in the
finite-horizon stationary transition setting, where $H$ is the horizon length
and $d_m$ is the minimal marginal state-action distribution induced by the
behavior policy. This improves over the best known upper bound by a factor of
$H$. Moreover, we establish an information-theoretic lower bound of
$\Omega(H^2/d_m\epsilon^2)$ which certifies that OPDVR is optimal up to
logarithmic factors. Lastly, we show that OPDVR also achieves rate-optimal
sample complexity under alternative settings such as the finite-horizon MDPs
with non-stationary transitions and the infinite horizon MDPs with discounted
rewards.
</p>
<a href="http://arxiv.org/abs/2102.01748" target="_blank">arXiv:2102.01748</a> [<a href="http://arxiv.org/pdf/2102.01748" target="_blank">pdf</a>]

<h2>Vehicle trajectory prediction in top-view image sequences based on deep learning method. (arXiv:2102.01749v1 [cs.CV])</h2>
<h3>Zahra Salahshoori Nejad, Hamed Heravi, Ali Rahimpour Jounghani, Abdollah Shahrezaie, Afshin Ebrahimi</h3>
<p>Annually, a large number of injuries and deaths around the world are related
to motor vehicle accidents. This value has recently been reduced to some
extent, via the use of driver-assistance systems. Developing driver-assistance
systems (i.e., automated driving systems) can play a crucial role in reducing
this number. Estimating and predicting surrounding vehicles' movement is
essential for an automated vehicle and advanced safety systems. Moreover,
predicting the trajectory is influenced by numerous factors, such as drivers'
behavior during accidents, history of the vehicle's movement and the
surrounding vehicles, and their position on the traffic scene. The vehicle must
move over a safe path in traffic and react to other drivers' unpredictable
behaviors in the shortest time. Herein, to predict automated vehicles' path, a
model with low computational complexity is proposed, which is trained by images
taken from the road's aerial image. Our method is based on an encoder-decoder
model that utilizes a social tensor to model the effect of the surrounding
vehicles' movement on the target vehicle. The proposed model can predict the
vehicle's future path in any freeway only by viewing the images related to the
history of the target vehicle's movement and its neighbors. Deep learning was
used as a tool for extracting the features of these images. Using the HighD
database, an image dataset of the road's aerial image was created, and the
model's performance was evaluated on this new database. We achieved the RMSE of
1.91 for the next 5 seconds and found that the proposed method had less error
than the best path-prediction methods in previous studies.
</p>
<a href="http://arxiv.org/abs/2102.01749" target="_blank">arXiv:2102.01749</a> [<a href="http://arxiv.org/pdf/2102.01749" target="_blank">pdf</a>]

<h2>Continuous Wasserstein-2 Barycenter Estimation without Minimax Optimization. (arXiv:2102.01752v1 [cs.LG])</h2>
<h3>Alexander Korotin, Lingxiao Li, Justin Solomon, Evgeny Burnaev</h3>
<p>Wasserstein barycenters provide a geometric notion of the weighted average of
probability measures based on optimal transport. In this paper, we present a
scalable algorithm to compute Wasserstein-2 barycenters given sample access to
the input measures, which are not restricted to being discrete. While past
approaches rely on entropic or quadratic regularization, we employ input convex
neural networks and cycle-consistency regularization to avoid introducing bias.
As a result, our approach does not resort to minimax optimization. We provide
theoretical analysis on error bounds as well as empirical evidence of the
effectiveness of the proposed approach in low-dimensional qualitative scenarios
and high-dimensional quantitative experiments.
</p>
<a href="http://arxiv.org/abs/2102.01752" target="_blank">arXiv:2102.01752</a> [<a href="http://arxiv.org/pdf/2102.01752" target="_blank">pdf</a>]

<h2>Automatic analysis of artistic paintings using information-based measures. (arXiv:2102.01767v1 [cs.CV])</h2>
<h3>Jorge Miguel Silva, Diogo Pratas, Rui Antunes, S&#xe9;rgio Matos, Armando J. Pinho</h3>
<p>The artistic community is increasingly relying on automatic computational
analysis for authentication and classification of artistic paintings. In this
paper, we identify hidden patterns and relationships present in artistic
paintings by analysing their complexity, a measure that quantifies the sum of
characteristics of an object. Specifically, we apply Normalized Compression
(NC) and the Block Decomposition Method (BDM) to a dataset of 4,266 paintings
from 91 authors and examine the potential of these information-based measures
as descriptors of artistic paintings. Both measures consistently described the
equivalent types of paintings, authors, and artistic movements. Moreover,
combining the NC with a measure of the roughness of the paintings creates an
efficient stylistic descriptor. Furthermore, by quantifying the local
information of each painting, we define a fingerprint that describes critical
information regarding the artists' style, their artistic influences, and shared
techniques. More fundamentally, this information describes how each author
typically composes and distributes the elements across the canvas and,
therefore, how their work is perceived. Finally, we demonstrate that regional
complexity and two-point height difference correlation function are useful
auxiliary features that improve current methodologies in style and author
classification of artistic paintings. The whole study is supported by an
extensive website (this http URL) for fast author characterization
and authentication.
</p>
<a href="http://arxiv.org/abs/2102.01767" target="_blank">arXiv:2102.01767</a> [<a href="http://arxiv.org/pdf/2102.01767" target="_blank">pdf</a>]

<h2>A metaheuristic for crew scheduling in a pickup-and-delivery problem with time windows. (arXiv:2102.01780v1 [cs.AI])</h2>
<h3>Mauro Lucci, Daniel Sever&#xed;n, Paula Zabala</h3>
<p>A vehicle routing and crew scheduling problem (VRCSP) consists of
simultaneously planning the routes of a fleet of vehicles and scheduling the
crews, where the vehicle-crew correspondence is not fixed through time. This
allows a greater planning flexibility and a more efficient use of the fleet,
but in counterpart, a high synchronisation is demanded. In this work, we
present a VRCSP where pickup-and-delivery requests with time windows have to be
fulfilled over a given planning horizon by using trucks and drivers. Crews can
be composed of 1 or 2 drivers and any of them can be relieved in a given set of
locations. Moreover, they are allowed to travel among locations with
non-company shuttles, at an additional cost that is minimised. As our problem
considers distinct routes for trucks and drivers, we have an additional
flexibility not contemplated in other previous VRCSP given in the literature
where a crew is handled as an indivisible unit. We tackle this problem with a
two-stage sequential approach: a set of truck routes is computed in the first
stage and a set of driver routes consistent with the truck routes is obtained
in the second one. We design and evaluate the performance of a metaheuristic
based algorithm for the latter stage. Our algorithm is mainly a GRASP with a
perturbation procedure that allows reusing solutions already found in case the
search for new solutions becomes difficult. This procedure together with other
to repair infeasible solutions allow us to find high-quality solutions on
instances of 100 requests spread across 15 cities with a fleet of 12-32 trucks
(depending on the planning horizon) in less than an hour. We also conclude that
the possibility of carrying an additional driver leads to a decrease of the
cost of external shuttles by about 60% on average with respect to individual
crews and, in some cases, to remove this cost completely.
</p>
<a href="http://arxiv.org/abs/2102.01780" target="_blank">arXiv:2102.01780</a> [<a href="http://arxiv.org/pdf/2102.01780" target="_blank">pdf</a>]

<h2>Recurrent Neural Network for MoonBoard Climbing Route Classification and Generation. (arXiv:2102.01788v1 [cs.LG])</h2>
<h3>Yi-Shiou Duh, Ray Chang</h3>
<p>Classifying the difficulties of climbing routes and generating new routes are
both challenging. Existing machine learning models not only fail to accurately
predict a problem's difficulty, but they are also unable to generate reasonable
problems. In this work, we introduced "BetaMove", a new move preprocessing
pipeline we developed, in order to mimic a human climber's hand sequence. The
preprocessed move sequences were then used to train both a route generator and
a grade predictor. By preprocessing a MoonBoard problem into a proper move
sequence, the accuracy of our grade predictor reaches near human-level
performance, and our route generator produces new routes of much better quality
compared to previous work. We demonstrated that with BetaMove, we are able to
inject human insights into the machine learning problems, and this can be the
foundations for future transfer learning on climbing style classification
problems.
</p>
<a href="http://arxiv.org/abs/2102.01788" target="_blank">arXiv:2102.01788</a> [<a href="http://arxiv.org/pdf/2102.01788" target="_blank">pdf</a>]

<h2>A Survey on Understanding, Visualizations, and Explanation of Deep Neural Networks. (arXiv:2102.01792v1 [cs.LG])</h2>
<h3>Atefeh Shahroudnejad</h3>
<p>Recent advancements in machine learning and signal processing domains have
resulted in an extensive surge of interest in Deep Neural Networks (DNNs) due
to their unprecedented performance and high accuracy for different and
challenging problems of significant engineering importance. However, when such
deep learning architectures are utilized for making critical decisions such as
the ones that involve human lives (e.g., in control systems and medical
applications), it is of paramount importance to understand, trust, and in one
word "explain" the argument behind deep models' decisions. In many
applications, artificial neural networks (including DNNs) are considered as
black-box systems, which do not provide sufficient clue on their internal
processing actions. Although some recent efforts have been initiated to explain
the behaviors and decisions of deep networks, explainable artificial
intelligence (XAI) domain, which aims at reasoning about the behavior and
decisions of DNNs, is still in its infancy. The aim of this paper is to provide
a comprehensive overview on Understanding, Visualization, and Explanation of
the internal and overall behavior of DNNs.
</p>
<a href="http://arxiv.org/abs/2102.01792" target="_blank">arXiv:2102.01792</a> [<a href="http://arxiv.org/pdf/2102.01792" target="_blank">pdf</a>]

<h2>The Ethical Implications of Shared Medical Decision Making without Providing Adequate Computational Support to the Care Provider and to the Patient. (arXiv:2102.01811v1 [cs.AI])</h2>
<h3>Yuval Shahar</h3>
<p>There is a clear need to involve patients in medical decisions. However,
cognitive psychological research has highlighted the cognitive limitations of
humans with respect to 1. Probabilistic assessment of the patient state and of
potential outcomes of various decisions, 2. Elicitation of the patient utility
function, and 3. Integration of the probabilistic knowledge and of patient
preferences to determine the optimal strategy. Therefore, without adequate
computational support, current shared decision models have severe ethical
deficiencies. An informed consent model unfairly transfers the responsibility
to a patient who does not have the necessary knowledge, nor the integration
capability. A paternalistic model endows with exaggerated power a physician who
might not be aware of the patient preferences, is prone to multiple cognitive
biases, and whose computational integration capability is bounded. Recent
progress in Artificial Intelligence suggests adding a third agent: a computer,
in all deliberative medical decisions: Non emergency medical decisions in which
more than one alternative exists, the patient preferences can be elicited, the
therapeutic alternatives might be influenced by these preferences, medical
knowledge exists regarding the likelihood of the decision outcomes, and there
is sufficient decision time. Ethical physicians should exploit computational
decision support technologies, neither making the decisions solely on their
own, nor shirking their duty and shifting the responsibility to patients in the
name of informed consent. The resulting three way (patient, care provider,
computer) human machine model that we suggest emphasizes the patient
preferences, the physician knowledge, and the computational integration of both
aspects, does not diminish the physician role, but rather brings out the best
in human and machine.
</p>
<a href="http://arxiv.org/abs/2102.01811" target="_blank">arXiv:2102.01811</a> [<a href="http://arxiv.org/pdf/2102.01811" target="_blank">pdf</a>]

<h2>Task Planning on Stochastic Aisle Graphs for Precision Agriculture. (arXiv:2102.01825v1 [cs.RO])</h2>
<h3>Xinyue Kan, Thomas C. Thayer, Stefano Carpin, Konstantinos Karydis</h3>
<p>This work addresses task planning under uncertainty for precision agriculture
applications whereby task costs are uncertain and the gain of completing a task
is proportional to resource consumption (such as water consumption in precision
irrigation). The goal is to complete all tasks while prioritizing those that
are more urgent, and subject to diverse budget thresholds and stochastic costs
for tasks. To describe agriculture-related environments that incorporate
stochastic costs to complete tasks, a new Stochastic-Vertex-Cost Aisle Graph
(SAG) is introduced. Then, a task allocation algorithm, termed Next-Best-Action
Planning (NBA-P), is proposed. NBA-P utilizes the underlying structure enabled
by SAG, and tackles the task planning problem by simultaneously determining the
optimal tasks to perform and an optimal time to exit (i.e. return to a base
station), at run-time. The proposed approach is tested with both simulated data
and real-world experimental datasets collected in a commercial vineyard, in
both single- and multi-robot scenarios. In all cases, NBA-P outperforms other
evaluated methods in terms of return per visited vertex, wasted resources
resulting from aborted tasks (i.e. when a budget threshold is exceeded), and
total visited vertices.
</p>
<a href="http://arxiv.org/abs/2102.01825" target="_blank">arXiv:2102.01825</a> [<a href="http://arxiv.org/pdf/2102.01825" target="_blank">pdf</a>]

<h2>Organization of a Latent Space structure in VAE/GAN trained by navigation data. (arXiv:2102.01852v1 [cs.LG])</h2>
<h3>Hiroki Kojima, Takashi Ikegami</h3>
<p>We present a novel artificial cognitive mapping system using generative deep
neural networks (VAE/GAN), which can map input images to latent vectors and
generate temporal sequences internally. The results show that the distance of
the predicted image is reflected in the distance of the corresponding latent
vector after training. This indicates that the latent space is constructed to
reflect the proximity structure of the data set, and may provide a mechanism by
which many aspects of cognition are spatially represented. The present study
allows the network to internally generate temporal sequences analogous to
hippocampal replay/pre-play, where VAE produces only near-accurate replays of
past experiences, but by introducing GANs, latent vectors of temporally close
images are closely aligned and sequence acquired some instability. This may be
the origin of the generation of the new sequences found in the hippocampus.
</p>
<a href="http://arxiv.org/abs/2102.01852" target="_blank">arXiv:2102.01852</a> [<a href="http://arxiv.org/pdf/2102.01852" target="_blank">pdf</a>]

<h2>L2C: Describing Visual Differences Needs Semantic Understanding of Individuals. (arXiv:2102.01860v1 [cs.CV])</h2>
<h3>An Yan, Xin Eric Wang, Tsu-Jui Fu, William Yang Wang</h3>
<p>Recent advances in language and vision push forward the research of
captioning a single image to describing visual differences between image pairs.
Suppose there are two images, I_1 and I_2, and the task is to generate a
description W_{1,2} comparing them, existing methods directly model { I_1, I_2
} -&gt; W_{1,2} mapping without the semantic understanding of individuals. In this
paper, we introduce a Learning-to-Compare (L2C) model, which learns to
understand the semantic structures of these two images and compare them while
learning to describe each one. We demonstrate that L2C benefits from a
comparison between explicit semantic representations and single-image captions,
and generalizes better on the new testing image pairs. It outperforms the
baseline on both automatic evaluation and human evaluation for the
Birds-to-Words dataset.
</p>
<a href="http://arxiv.org/abs/2102.01860" target="_blank">arXiv:2102.01860</a> [<a href="http://arxiv.org/pdf/2102.01860" target="_blank">pdf</a>]

<h2>Towards Robust Neural Networks via Close-loop Control. (arXiv:2102.01862v1 [cs.LG])</h2>
<h3>Zhuotong Chen, Qianxiao Li, Zheng Zhang</h3>
<p>Despite their success in massive engineering applications, deep neural
networks are vulnerable to various perturbations due to their black-box nature.
Recent study has shown that a deep neural network can misclassify the data even
if the input data is perturbed by an imperceptible amount. In this paper, we
address the robustness issue of neural networks by a novel close-loop control
method from the perspective of dynamic systems. Instead of modifying the
parameters in a fixed neural network architecture, a close-loop control process
is added to generate control signals adaptively for the perturbed or corrupted
data. We connect the robustness of neural networks with optimal control using
the geometrical information of underlying data to design the control objective.
The detailed analysis shows how the embedding manifolds of state trajectory
affect error estimation of the proposed method. Our approach can simultaneously
maintain the performance on clean data and improve the robustness against many
types of data perturbations. It can also further improve the performance of
robustly trained neural networks against different perturbations. To the best
of our knowledge, this is the first work that improves the robustness of neural
networks with close-loop control.
</p>
<a href="http://arxiv.org/abs/2102.01862" target="_blank">arXiv:2102.01862</a> [<a href="http://arxiv.org/pdf/2102.01862" target="_blank">pdf</a>]

<h2>Deep CNNs for large scale species classification. (arXiv:2102.01863v1 [cs.CV])</h2>
<h3>Raj Prateek Kosaraju</h3>
<p>Large Scale image classification is a challenging problem within the field of
computer vision. As the real world contains billions of different objects,
understanding the performance of popular techniques and models is vital in
order to apply them to real world tasks. In this paper, we evaluate techniques
and popular CNN based deep learning architectures to perform large scale
species classification on the dataset from iNaturalist 2019 Challenge. Methods
utilizing dataset pruning and transfer learning are shown to outperform models
trained without either of the two techniques. The ResNext based classifier
outperforms other model architectures over 10 epochs and achieves a top-one
validation error of 0.68 when classifying amongst the 1,010 species.
</p>
<a href="http://arxiv.org/abs/2102.01863" target="_blank">arXiv:2102.01863</a> [<a href="http://arxiv.org/pdf/2102.01863" target="_blank">pdf</a>]

<h2>Impact of Data Processing on Fairness in Supervised Learning. (arXiv:2102.01867v1 [cs.LG])</h2>
<h3>Sajad Khodadadian, AmirEmad Ghassami, Negar Kiyavash</h3>
<p>We study the impact of pre and post processing for reducing discrimination in
data-driven decision makers. We first analyze the fundamental trade-off between
fairness and accuracy in a pre-processing approach, and propose a design for a
pre-processing module based on a convex optimization program, which can be
added before the original classifier. This leads to a fundamental lower bound
on attainable discrimination, given any acceptable distortion in the outcome.
Furthermore, we reformulate an existing post-processing method in terms of our
accuracy and fairness measures, which allows comparing post-processing and
pre-processing approaches. We show that under some mild conditions,
pre-processing outperforms post-processing. Finally, we show that by
appropriate choice of the discrimination measure, the optimization problem for
both pre and post processing approaches will reduce to a linear program and
hence can be solved efficiently.
</p>
<a href="http://arxiv.org/abs/2102.01867" target="_blank">arXiv:2102.01867</a> [<a href="http://arxiv.org/pdf/2102.01867" target="_blank">pdf</a>]

<h2>Learning to identify image manipulations in scientific publications. (arXiv:2102.01874v1 [cs.CV])</h2>
<h3>Ghazal Mazaheri, Kevin Urrutia Avila, Amit K. Roy-Chowdhury</h3>
<p>Adherence to scientific community standards ensures objectivity, clarity,
reproducibility, and helps prevent bias, fabrication, falsification, and
plagiarism. To help scientific integrity officers and journal/publisher
reviewers monitor if researchers stick with these standards, it is important to
have a solid procedure to detect duplication as one of the most frequent types
of manipulation in scientific papers. Images in scientific papers are used to
support the experimental description and the discussion of the findings.
Therefore, in this work we focus on detecting the duplications in images as one
of the most important parts of a scientific paper. We propose a framework that
combines image processing and deep learning methods to classify images in the
articles as duplicated or unduplicated ones. We show that our method leads to a
90% accuracy rate of detecting duplicated images, a ~ 13% improvement in
detection accuracy in comparison to other manipulation detection methods. We
also show how effective the pre-processing steps are by comparing our method to
other state-of-art manipulation detectors which lack these steps.
</p>
<a href="http://arxiv.org/abs/2102.01874" target="_blank">arXiv:2102.01874</a> [<a href="http://arxiv.org/pdf/2102.01874" target="_blank">pdf</a>]

<h2>AHAR: Adaptive CNN for Energy-efficient Human Activity Recognition in Low-power Edge Devices. (arXiv:2102.01875v1 [cs.LG])</h2>
<h3>Nafiul Rashid, Berken Utku Demirel, Mohammad Abdullah Al Faruque</h3>
<p>Human Activity Recognition (HAR) is one of the key applications of health
monitoring that requires continuous use of wearable devices to track daily
activities. State-of-the-art works using wearable devices have been following
fog/cloud computing architecture where the data is classified at the mobile
phones/remote servers. This kind of approach suffers from energy, latency, and
privacy issues. Therefore, we follow edge computing architecture where the
wearable device solutions provide adequate performance while being energy and
memory-efficient. This paper proposes an Adaptive CNN for energy-efficient HAR
(AHAR) suitable for low-power edge devices. AHAR uses a novel adaptive
architecture that selects a portion of the baseline architecture to use during
the inference phase. We validate our methodology in classifying locomotion
activities from two datasets- Opportunity and w-HAR. Compared to the fog/cloud
computing approaches for the Opportunity dataset, our baseline and adaptive
architecture shows a comparable weighted F1 score of 91.79%, and 91.57%,
respectively. For the w-HAR dataset, our baseline and adaptive architecture
outperforms the state-of-the-art works with a weighted F1 score of 97.55%, and
97.64%, respectively. Evaluation on real hardware shows that our baseline
architecture is significantly energy-efficient (422.38x less) and
memory-efficient (14.29x less) compared to the works on the Opportunity
dataset. For the w-HAR dataset, our baseline architecture requires 2.04x less
energy and 2.18x less memory compared to the state-of-the-art work. Moreover,
experimental results show that our adaptive architecture is 12.32%
(Opportunity) and 11.14% (w-HAR) energy-efficient than our baseline while
providing similar (Opportunity) or better (w-HAR) performance with no
significant memory overhead.
</p>
<a href="http://arxiv.org/abs/2102.01875" target="_blank">arXiv:2102.01875</a> [<a href="http://arxiv.org/pdf/2102.01875" target="_blank">pdf</a>]

<h2>Evaluation of Point Pattern Features for Anomaly Detection of Defect within Random Finite Set Framework. (arXiv:2102.01882v1 [cs.CV])</h2>
<h3>Ammar Mansoor Kamoona, Amirali Khodadadian Gostar, Alireza Bab-Hadiashar, Reza Hoseinnezhad</h3>
<p>Defect detection in the manufacturing industry is of utmost importance for
product quality inspection. Recently, optical defect detection has been
investigated as an anomaly detection using different deep learning methods.
However, the recent works do not explore the use of point pattern features,
such as SIFT for anomaly detection using the recently developed set-based
methods. In this paper, we present an evaluation of different point pattern
feature detectors and descriptors for defect detection application. The
evaluation is performed within the random finite set framework. Handcrafted
point pattern features, such as SIFT as well as deep features are used in this
evaluation. Random finite set-based defect detection is compared with
state-of-the-arts anomaly detection methods. The results show that using point
pattern features, such as SIFT as data points for random finite set-based
anomaly detection achieves the most consistent defect detection accuracy on the
MVTec-AD dataset.
</p>
<a href="http://arxiv.org/abs/2102.01882" target="_blank">arXiv:2102.01882</a> [<a href="http://arxiv.org/pdf/2102.01882" target="_blank">pdf</a>]

<h2>Learning Diverse-Structured Networks for Adversarial Robustness. (arXiv:2102.01886v1 [cs.LG])</h2>
<h3>Xuefeng Du, Jingfeng Zhang, Bo Han, Tongliang Liu, Yu Rong, Gang Niu, Junzhou Huang, Masashi Sugiyama</h3>
<p>In adversarial training (AT), the main focus has been the objective and
optimizer while the model is less studied, so that the models being used are
still those classic ones in standard training (ST). Classic network
architectures (NA) are generally worse than searched NA in ST, which should be
the same in AT. In this paper, we argue that NA and AT cannot be handled
independently, since given a dataset, the optimal NA in ST would be no longer
optimal in AT. That being said, AT is time-consuming itself; if we directly
search NA in AT over large search spaces, the computation will be practically
infeasible. Thus, we propose a diverse-structured network (DS-Net), to
significantly reduce the size of the search space: instead of low-level
operations, we only consider predefined atomic blocks, where an atomic block is
a time-tested building block like the residual block. There are only a few
atomic blocks and thus we can weight all atomic blocks rather than find the
best atomic block in a searched block of DS-Net, which is an essential
trade-off between exploring diverse structures and exploiting the best
structures. Empirical results demonstrate the advantages of DS-Net, i.e.,
weighting the atomic blocks.
</p>
<a href="http://arxiv.org/abs/2102.01886" target="_blank">arXiv:2102.01886</a> [<a href="http://arxiv.org/pdf/2102.01886" target="_blank">pdf</a>]

<h2>Multi-Instance Learning by Utilizing Structural Relationship among Instances. (arXiv:2102.01889v1 [cs.LG])</h2>
<h3>Yangling Ma, Zhouwang Yang</h3>
<p>Multi-Instance Learning(MIL) aims to learn the mapping between a bag of
instances and the bag-level label. Therefore, the relationships among instances
are very important for learning the mapping. In this paper, we propose an MIL
algorithm based on a graph built by structural relationship among instances
within a bag. Then, Graph Convolutional Network(GCN) and the graph-attention
mechanism are used to learn bag-embedding. In the task of medical image
classification, our GCN-based MIL algorithm makes full use of the structural
relationships among patches(instances) in an original image space domain, and
experimental results verify that our method is more suitable for handling
medical high-resolution images. We also verify experimentally that the proposed
method achieves better results than previous methods on five bechmark MIL
datasets and four medical image datasets.
</p>
<a href="http://arxiv.org/abs/2102.01889" target="_blank">arXiv:2102.01889</a> [<a href="http://arxiv.org/pdf/2102.01889" target="_blank">pdf</a>]

<h2>Relaxed Transformer Decoders for Direct Action Proposal Generation. (arXiv:2102.01894v1 [cs.CV])</h2>
<h3>Jing Tan, Jiaqi Tang, Limin Wang, Gangshan Wu</h3>
<p>Temporal action proposal generation is an important and challenging task in
video understanding, which aims at detecting all temporal segments containing
action instances of interest. The existing proposal generation approaches are
generally based on pre-defined anchor windows or heuristic bottom-up boundary
matching strategies. This paper presents a simple and end-to-end learnable
framework (RTD-Net) for direct action proposal generation, by re-purposing a
Transformer-alike architecture. To tackle the essential visual difference
between time and space, we make three important improvements over the original
transformer detection framework (DETR). First, to deal with slowness prior in
videos, we replace the original Transformer encoder with a boundary attentive
module to better capture temporal information. Second, due to the ambiguous
temporal boundary and relatively sparse annotations, we present a relaxed
matching loss to relieve the strict criteria of single assignment to each
groundtruth. Finally, we devise a three-branch head to further improve the
proposal confidence estimation by explicitly predicting its completeness.
Extensive experiments on THUMOS14 and ActivityNet-1.3 benchmarks demonstrate
the effectiveness of RTD-Net, on both tasks of temporal action proposal
generation and temporal action detection. Moreover, due to its simplicity in
design, our RTD-Net is more efficient than previous proposal generation methods
without non-maximum suppression post-processing. The code will be available at
\url{https://github.com/MCG-NJU/RTD-Action}.
</p>
<a href="http://arxiv.org/abs/2102.01894" target="_blank">arXiv:2102.01894</a> [<a href="http://arxiv.org/pdf/2102.01894" target="_blank">pdf</a>]

<h2>A Scalable Two Stage Approach to Computing Optimal Decision Sets. (arXiv:2102.01904v1 [cs.AI])</h2>
<h3>Alexey Ignatiev, Edward Lam, Peter J. Stuckey, Joao Marques-Silva</h3>
<p>Machine learning (ML) is ubiquitous in modern life. Since it is being
deployed in technologies that affect our privacy and safety, it is often
crucial to understand the reasoning behind its decisions, warranting the need
for explainable AI. Rule-based models, such as decision trees, decision lists,
and decision sets, are conventionally deemed to be the most interpretable.
Recent work uses propositional satisfiability (SAT) solving (and its
optimization variants) to generate minimum-size decision sets. Motivated by
limited practical scalability of these earlier methods, this paper proposes a
novel approach to learn minimum-size decision sets by enumerating individual
rules of the target decision set independently of each other, and then solving
a set cover problem to select a subset of rules. The approach makes use of
modern maximum satisfiability and integer linear programming technologies.
Experiments on a wide range of publicly available datasets demonstrate the
advantage of the new approach over the state of the art in SAT-based decision
set learning.
</p>
<a href="http://arxiv.org/abs/2102.01904" target="_blank">arXiv:2102.01904</a> [<a href="http://arxiv.org/pdf/2102.01904" target="_blank">pdf</a>]

<h2>Do Not Forget to Attend to Uncertainty while Mitigating Catastrophic Forgetting. (arXiv:2102.01906v1 [cs.LG])</h2>
<h3>Vinod K Kurmi, Badri N. Patro, Venkatesh K. Subramanian, Vinay P. Namboodiri</h3>
<p>One of the major limitations of deep learning models is that they face
catastrophic forgetting in an incremental learning scenario. There have been
several approaches proposed to tackle the problem of incremental learning. Most
of these methods are based on knowledge distillation and do not adequately
utilize the information provided by older task models, such as uncertainty
estimation in predictions. The predictive uncertainty provides the
distributional information can be applied to mitigate catastrophic forgetting
in a deep learning framework. In the proposed work, we consider a Bayesian
formulation to obtain the data and model uncertainties. We also incorporate
self-attention framework to address the incremental learning problem. We define
distillation losses in terms of aleatoric uncertainty and self-attention. In
the proposed work, we investigate different ablation analyses on these losses.
Furthermore, we are able to obtain better results in terms of accuracy on
standard benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.01906" target="_blank">arXiv:2102.01906</a> [<a href="http://arxiv.org/pdf/2102.01906" target="_blank">pdf</a>]

<h2>Answer Questions with Right Image Regions: A Visual Attention Regularization Approach. (arXiv:2102.01916v1 [cs.CV])</h2>
<h3>Yibing Liu, Yangyang Guo, Jianhua Yin, Xuemeng Song, Weifeng Liu, Liqiang Nie</h3>
<p>Visual attention in Visual Question Answering (VQA) targets at locating the
right image regions regarding the answer prediction. However, recent studies
have pointed out that the highlighted image regions from the visual attention
are often irrelevant to the given question and answer, leading to model
confusion for correct visual reasoning. To tackle this problem, existing
methods mostly resort to aligning the visual attention weights with human
attentions. Nevertheless, gathering such human data is laborious and expensive,
making it burdensome to adapt well-developed models across datasets. To address
this issue, in this paper, we devise a novel visual attention regularization
approach, namely AttReg, for better visual grounding in VQA. Specifically,
AttReg firstly identifies the image regions which are essential for question
answering yet unexpectedly ignored (i.e., assigned with low attention weights)
by the backbone model. And then a mask-guided learning scheme is leveraged to
regularize the visual attention to focus more on these ignored key regions. The
proposed method is very flexible and model-agnostic, which can be integrated
into most visual attention-based VQA models and require no human attention
supervision. Extensive experiments over three benchmark datasets, i.e., VQA-CP
v2, VQA-CP v1, and VQA v2, have been conducted to evaluate the effectiveness of
AttReg. As a by-product, when incorporating AttReg into the strong baseline
LMH, our approach can achieve a new state-of-the-art accuracy of 59.92% with an
absolute performance gain of 6.93% on the VQA-CP v2 benchmark dataset. In
addition to the effectiveness validation, we recognize that the faithfulness of
the visual attention in VQA has not been well explored in literature. In the
light of this, we propose to empirically validate such property of visual
attention and compare it with the prevalent gradient-based approaches.
</p>
<a href="http://arxiv.org/abs/2102.01916" target="_blank">arXiv:2102.01916</a> [<a href="http://arxiv.org/pdf/2102.01916" target="_blank">pdf</a>]

<h2>Regularization Strategy for Point Cloud via Rigidly Mixed Sample. (arXiv:2102.01929v1 [cs.CV])</h2>
<h3>Dogyoon Lee, Jaeha Lee, Junhyeop Lee, Hyeongmin Lee, Minhyeok Lee, Sungmin Woo, Sangyoun Lee</h3>
<p>Data augmentation is an effective regularization strategy to alleviate the
overfitting, which is an inherent drawback of the deep neural networks.
However, data augmentation is rarely considered for point cloud processing
despite many studies proposing various augmentation methods for image data.
Actually, regularization is essential for point clouds since lack of generality
is more likely to occur in point cloud due to small datasets. This paper
proposes a Rigid Subset Mix (RSMix), a novel data augmentation method for point
clouds that generates a virtual mixed sample by replacing part of the sample
with shape-preserved subsets from another sample. RSMix preserves structural
information of the point cloud sample by extracting subsets from each sample
without deformation using a neighboring function. The neighboring function was
carefully designed considering unique properties of point cloud, unordered
structure and non-grid. Experiments verified that RSMix successfully
regularized the deep neural networks with remarkable improvement for shape
classification. We also analyzed various combinations of data augmentations
including RSMix with single and multi-view evaluations, based on abundant
ablation studies.
</p>
<a href="http://arxiv.org/abs/2102.01929" target="_blank">arXiv:2102.01929</a> [<a href="http://arxiv.org/pdf/2102.01929" target="_blank">pdf</a>]

<h2>Roughly Collected Dataset for Contact Force Sensing Catheter. (arXiv:2102.01932v1 [cs.RO])</h2>
<h3>Seunghyuk Cho, Minsoo Koo, Dongwoo Kim, Juyong Lee, Yeonwoo Jung, Kibyung Nam, Changmo Hwang</h3>
<p>With rise of interventional cardiology, Catheter Ablation Therapy (CAT) has
established itself as a first-line solution to treat cardiac arrhythmia.
Although CAT is a promising technique, cardiologist lacks vision inside the
body during the procedure, which may cause serious clinical syndromes. To
support accurate clinical procedure, Contact Force Sensing (CFS) system is
developed to find a position of the catheter tip through the measure of contact
force between catheter and heart tissue. However, the practical usability of
commercialized CFS systems is not fully understood due to inaccuracy in the
measurement. To support the development of more accurate system, we develop a
full pipeline of CFS system with newly collected benchmark dataset through a
contact force sensing catheter in simplest hardware form. Our dataset was
roughly collected with human noise to increase data diversity. Through the
analysis of the dataset, we identify a problem defined as Shift of Reference
(SoR), which prevents accurate measurement of contact force. To overcome the
problem, we conduct the contact force estimation via standard deep neural
networks including for Recurrent Neural Network (RNN), Fully Convolutional
Network (FCN) and Transformer. An average error in measurement for RNN, FCN and
Transformer are, respectively, 2.46g, 3.03g and 3.01g. Through these studies,
we try to lay a groundwork, serve a performance criteria for future CFS system
research and open a publicly available dataset to public.
</p>
<a href="http://arxiv.org/abs/2102.01932" target="_blank">arXiv:2102.01932</a> [<a href="http://arxiv.org/pdf/2102.01932" target="_blank">pdf</a>]

<h2>Noise-robust classification with hypergraph neural network. (arXiv:2102.01934v1 [stat.ML])</h2>
<h3>Nguyen Trinh Vu Dang, Loc Tran, Linh Tran</h3>
<p>This paper presents a novel version of the hypergraph neural network method.
This method is utilized to solve the noisy label learning problem. First, we
apply the PCA dimensional reduction technique to the feature matrices of the
image datasets in order to reduce the "noise" and the redundant features in the
feature matrices of the image datasets and to reduce the runtime constructing
the hypergraph of the hypergraph neural network method. Then, the classic
graph-based semi-supervised learning method, the classic hypergraph based
semi-supervised learning method, the graph neural network, the hypergraph
neural network, and our proposed hypergraph neural network are employed to
solve the noisy label learning problem. The accuracies of these five methods
are evaluated and compared. Experimental results show that the hypergraph
neural network methods achieve the best performance when the noise level
increases. Moreover, the hypergraph neural network methods are at least as good
as the graph neural network.
</p>
<a href="http://arxiv.org/abs/2102.01934" target="_blank">arXiv:2102.01934</a> [<a href="http://arxiv.org/pdf/2102.01934" target="_blank">pdf</a>]

<h2>A Bayesian Federated Learning Framework with Multivariate Gaussian Product. (arXiv:2102.01936v1 [cs.LG])</h2>
<h3>Liangxi Liu, Feng Zheng</h3>
<p>Federated learning (FL) allows multiple clients to collaboratively learn a
globally shared model through cycles of model aggregation and local model
training without the need to share data. In this paper, we comprehensively
study a new problem named aggregation error (AE), arising from the model
aggregation stage on a server, which is mainly induced by the heterogeneity of
the client data. Due to the large discrepancies between local models, the
accompanying large AE generally results in a slow convergence and an expected
reduction of accuracy for FL. In order to reduce AE, we propose a novel
federated learning framework from a Bayesian perspective, in which a
multivariate Gaussian product mechanism is employed to aggregate the local
models. It is worth noting that the product of Gaussians is still a Gaussian.
This property allows us to directly aggregate local expectations and
covariances in a definitely convex form, thereby greatly reducing the AE.
Accordingly, on the clients, we develop a new Federated Online Laplace
Approximation (FOLA) method, which can estimate the parameters of the local
posterior by repeatedly accumulating priors. Specifically, in every round, the
global posterior distributed from the server can be treated as the priors, and
thus the local posterior can also be effectively approximated by a Gaussian
using FOLA. Experimental results on benchmarks reach state-of-the-arts
performance and clearly demonstrate the advantages of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.01936" target="_blank">arXiv:2102.01936</a> [<a href="http://arxiv.org/pdf/2102.01936" target="_blank">pdf</a>]

<h2>Multi-Scale Cost Volumes Cascade Network for Stereo Matching. (arXiv:2102.01940v1 [cs.CV])</h2>
<h3>Xiaogang Jia, Wei Chen, Zhengfa Liang, Yusong Tan, Mingfei Wu</h3>
<p>Stereo matching is essential for robot navigation. However, the accuracy of
current widely used traditional methods is low, while methods based on CNN need
expensive computational cost and running time. This is because different cost
volumes play a crucial role in balancing speed and accuracy. Thus we propose
MSCVNet, which combines traditional methods and CNN to improve the quality of
cost volume. Concretely, our network first generates multiple 3D cost volumes
with different resolutions and then uses 2D convolutions to construct a novel
cascade hourglass network for cost aggregation. Meanwhile, we design an
algorithm to distinguish and calculate the loss for discontinuous areas of
disparity result. According to the KITTI official website, our network is much
faster than most top-performing methods(24*than CSPN, 44*than GANet, etc.).
Meanwhile, compared to traditional methods(SPS-St, SGM) and other real-time
stereo matching networks(Fast DS-CS, DispNetC, and RTSNet, etc.), our network
achieves a big improvement in accuracy, demonstrating the effectiveness of our
proposed method.
</p>
<a href="http://arxiv.org/abs/2102.01940" target="_blank">arXiv:2102.01940</a> [<a href="http://arxiv.org/pdf/2102.01940" target="_blank">pdf</a>]

<h2>Predictive coding feedback results in perceived illusory contours in a recurrent neural network. (arXiv:2102.01955v1 [cs.CV])</h2>
<h3>Zhaoyang Pang, Callum Biggs O&#x27;May, Bhavin Choksi, Rufin VanRullen</h3>
<p>Modern feedforward convolutional neural networks (CNNs) can now solve some
computer vision tasks at super-human levels. However, these networks only
roughly mimic human visual perception. One difference from human vision is that
they do not appear to perceive illusory contours (e.g. Kanizsa squares) in the
same way humans do. Physiological evidence from visual cortex suggests that the
perception of illusory contours could involve feedback connections. Would
recurrent feedback neural networks perceive illusory contours like humans? In
this work we equip a deep feedforward convolutional network with brain-inspired
recurrent dynamics. The network was first pretrained with an unsupervised
reconstruction objective on a natural image dataset, to expose it to natural
object contour statistics. Then, a classification decision layer was added and
the model was finetuned on a form discrimination task: squares vs. randomly
oriented inducer shapes (no illusory contour). Finally, the model was tested
with the unfamiliar "illusory contour" configuration: inducer shapes oriented
to form an illusory square. Compared with feedforward baselines, the iterative
"predictive coding" feedback resulted in more illusory contours being
classified as physical squares. The perception of the illusory contour was
measurable in the luminance profile of the image reconstructions produced by
the model, demonstrating that the model really "sees" the illusion. Ablation
studies revealed that natural image pretraining and feedback error correction
are both critical to the perception of the illusion. Finally we validated our
conclusions in a deeper network (VGG): adding the same predictive coding
feedback dynamics again leads to the perception of illusory contours.
</p>
<a href="http://arxiv.org/abs/2102.01955" target="_blank">arXiv:2102.01955</a> [<a href="http://arxiv.org/pdf/2102.01955" target="_blank">pdf</a>]

<h2>Time Series Classification via Topological Data Analysis. (arXiv:2102.01956v1 [stat.ML])</h2>
<h3>Alperen Karan, Atabey Kaygun</h3>
<p>In this paper, we develop topological data analysis methods for
classification tasks on univariate time series. As an application we perform
binary and ternary classification tasks on two public datasets that consist of
physiological signals collected under stress and non-stress conditions. We
accomplish our goal by using persistent homology to engineer stable topological
features after we use a time delay embedding of the signals and perform a
subwindowing instead of using windows of fixed length. The combination of
methods we use can be applied to any univariate time series and in this
application allows us to reduce noise and use long window sizes without
incurring an extra computational cost. We then use machine learning models on
the features we algorithmically engineered to obtain higher accuracies with
fewer features.
</p>
<a href="http://arxiv.org/abs/2102.01956" target="_blank">arXiv:2102.01956</a> [<a href="http://arxiv.org/pdf/2102.01956" target="_blank">pdf</a>]

<h2>Local Critic Training for Model-Parallel Learning of Deep Neural Networks. (arXiv:2102.01963v1 [cs.LG])</h2>
<h3>Hojung Lee, Cho-Jui Hsieh, Jong-Seok Lee</h3>
<p>In this paper, we propose a novel model-parallel learning method, called
local critic training, which trains neural networks using additional modules
called local critic networks. The main network is divided into several layer
groups and each layer group is updated through error gradients estimated by the
corresponding local critic network. We show that the proposed approach
successfully decouples the update process of the layer groups for both
convolutional neural networks (CNNs) and recurrent neural networks (RNNs). In
addition, we demonstrate that the proposed method is guaranteed to converge to
a critical point. We also show that trained networks by the proposed method can
be used for structural optimization. Experimental results show that our method
achieves satisfactory performance, reduces training time greatly, and decreases
memory consumption per machine. Code is available at
https://github.com/hjdw2/Local-critic-training.
</p>
<a href="http://arxiv.org/abs/2102.01963" target="_blank">arXiv:2102.01963</a> [<a href="http://arxiv.org/pdf/2102.01963" target="_blank">pdf</a>]

<h2>A Neurorobotic Embodiment for Exploring the Dynamical Interactions of a Spiking Cerebellar Model and a Robot Arm During Vision-based Manipulation Tasks. (arXiv:2102.01966v1 [cs.RO])</h2>
<h3>Omar Zahra, David Navarro-Alarcon, Silvia Tolu</h3>
<p>While the original goal for developing robots is replacing humans in
dangerous and tedious tasks, the final target shall be completely mimicking the
human cognitive and motor behaviour. Hence, building detailed computational
models for the human brain is one of the reasonable ways to attain this. The
cerebellum is one of the key players in our neural system to guarantee
dexterous manipulation and coordinated movements as concluded from lesions in
that region. Studies suggest that it acts as a forward model providing
anticipatory corrections for the sensory signals based on observed
discrepancies from the reference values. While most studies consider providing
the teaching signal as error in joint-space, few studies consider the error in
task-space and even fewer consider the spiking nature of the cerebellum on the
cellular-level. In this study, a detailed cellular-level forward cerebellar
model is developed, including modeling of Golgi and Basket cells which are
usually neglected in previous studies. To preserve the biological features of
the cerebellum in the developed model, a hyperparameter optimization method
tunes the network accordingly. The efficiency and biological plausibility of
the proposed cerebellar-based controller is then demonstrated under different
robotic manipulation tasks reproducing motor behaviour observed in human
reaching experiments.
</p>
<a href="http://arxiv.org/abs/2102.01966" target="_blank">arXiv:2102.01966</a> [<a href="http://arxiv.org/pdf/2102.01966" target="_blank">pdf</a>]

<h2>A Bayesian Neural Network based on Dropout Regulation. (arXiv:2102.01968v1 [cs.LG])</h2>
<h3>Claire Theobald (LORIA), Fr&#xe9;d&#xe9;ric Pennerath (LORIA), Brieuc Conan-Guez (LORIA), Miguel Couceiro (LORIA), Amedeo Napoli (LORIA)</h3>
<p>Bayesian Neural Networks (BNN) have recently emerged in the Deep Learning
world for dealing with uncertainty estimation in classification tasks, and are
used in many application domains such as astrophysics, autonomous driving...BNN
assume a prior over the weights of a neural network instead of point estimates,
enabling in this way the estimation of both aleatoric and epistemic uncertainty
of the model prediction.Moreover, a particular type of BNN, namely MC Dropout,
assumes a Bernoulli distribution on the weights by using Dropout.Several
attempts to optimize the dropout rate exist, e.g. using a variational
approach.In this paper, we present a new method called "Dropout Regulation"
(DR), which consists of automatically adjusting the dropout rate during
training using a controller as used in automation.DR allows for a precise
estimation of the uncertainty which is comparable to the state-of-the-art while
remaining simple to implement.
</p>
<a href="http://arxiv.org/abs/2102.01968" target="_blank">arXiv:2102.01968</a> [<a href="http://arxiv.org/pdf/2102.01968" target="_blank">pdf</a>]

<h2>Key Technology Considerations in Developing and Deploying Machine Learning Models in Clinical Radiology Practice. (arXiv:2102.01979v1 [cs.LG])</h2>
<h3>Viraj Kulkarni, Manish Gawali, Amit Kharat</h3>
<p>The use of machine learning to develop intelligent software tools for
interpretation of radiology images has gained widespread attention in recent
years. The development, deployment, and eventual adoption of these models in
clinical practice, however, remains fraught with challenges. In this paper, we
propose a list of key considerations that machine learning researchers must
recognize and address to make their models accurate, robust, and usable in
practice. Namely, we discuss: insufficient training data, decentralized
datasets, high cost of annotations, ambiguous ground truth, imbalance in class
representation, asymmetric misclassification costs, relevant performance
metrics, generalization of models to unseen datasets, model decay, adversarial
attacks, explainability, fairness and bias, and clinical validation. We
describe each consideration and identify techniques to address it. Although
these techniques have been discussed in prior research literature, by freshly
examining them in the context of medical imaging and compiling them in the form
of a laundry list, we hope to make them more accessible to researchers,
software developers, radiologists, and other stakeholders.
</p>
<a href="http://arxiv.org/abs/2102.01979" target="_blank">arXiv:2102.01979</a> [<a href="http://arxiv.org/pdf/2102.01979" target="_blank">pdf</a>]

<h2>Variance Penalized On-Policy and Off-Policy Actor-Critic. (arXiv:2102.01985v1 [cs.LG])</h2>
<h3>Arushi Jain, Gandharv Patil, Ayush Jain, Khimya Khetarpal, Doina Precup</h3>
<p>Reinforcement learning algorithms are typically geared towards optimizing the
expected return of an agent. However, in many practical applications, low
variance in the return is desired to ensure the reliability of an algorithm. In
this paper, we propose on-policy and off-policy actor-critic algorithms that
optimize a performance criterion involving both mean and variance in the
return. Previous work uses the second moment of return to estimate the variance
indirectly. Instead, we use a much simpler recently proposed direct variance
estimator which updates the estimates incrementally using temporal difference
methods. Using the variance-penalized criterion, we guarantee the convergence
of our algorithm to locally optimal policies for finite state action Markov
decision processes. We demonstrate the utility of our algorithm in tabular and
continuous MuJoCo domains. Our approach not only performs on par with
actor-critic and prior variance-penalization baselines in terms of expected
return, but also generates trajectories which have lower variance in the
return.
</p>
<a href="http://arxiv.org/abs/2102.01985" target="_blank">arXiv:2102.01985</a> [<a href="http://arxiv.org/pdf/2102.01985" target="_blank">pdf</a>]

<h2>Learning Graph Embeddings for Compositional Zero-shot Learning. (arXiv:2102.01987v1 [cs.CV])</h2>
<h3>Muhammad Ferjad Naeem, Yongqin Xian, Federico Tombari, Zeynep Akata</h3>
<p>In compositional zero-shot learning, the goal is to recognize unseen
compositions (e.g. old dog) of observed visual primitives states (e.g. old,
cute) and objects (e.g. car, dog) in the training set. This is challenging
because the same state can for example alter the visual appearance of a dog
drastically differently from a car. As a solution, we propose a novel graph
formulation called Compositional Graph Embedding (CGE) that learns image
features, compositional classifiers, and latent representations of visual
primitives in an end-to-end manner. The key to our approach is exploiting the
dependency between states, objects, and their compositions within a graph
structure to enforce the relevant knowledge transfer from seen to unseen
compositions. By learning a joint compatibility that encodes semantics between
concepts, our model allows for generalization to unseen compositions without
relying on an external knowledge base like WordNet. We show that in the
challenging generalized compositional zero-shot setting our CGE significantly
outperforms the state of the art on MIT-States and UT-Zappos. We also propose a
new benchmark for this task based on the recent GQA dataset.
</p>
<a href="http://arxiv.org/abs/2102.01987" target="_blank">arXiv:2102.01987</a> [<a href="http://arxiv.org/pdf/2102.01987" target="_blank">pdf</a>]

<h2>A Deep Learning-Based Approach to Extracting Periosteal and Endosteal Contours of Proximal Femur in Quantitative CT Images. (arXiv:2102.01990v1 [cs.CV])</h2>
<h3>Yu Deng, Ling Wang, Chen Zhao, Shaojie Tang, Xiaoguang Cheng, Hong-Wen Deng, Weihua Zhou</h3>
<p>Automatic CT segmentation of proximal femur is crucial for the diagnosis and
risk stratification of orthopedic diseases; however, current methods for the
femur CT segmentation mainly rely on manual interactive segmentation, which is
time-consuming and has limitations in both accuracy and reproducibility. In
this study, we proposed an approach based on deep learning for the automatic
extraction of the periosteal and endosteal contours of proximal femur in order
to differentiate cortical and trabecular bone compartments. A three-dimensional
(3D) end-to-end fully convolutional neural network, which can better combine
the information between neighbor slices and get more accurate segmentation
results, was developed for our segmentation task. 100 subjects aged from 50 to
87 years with 24,399 slices of proximal femur CT images were enrolled in this
study. The separation of cortical and trabecular bone derived from the QCT
software MIAF-Femur was used as the segmentation reference. We randomly divided
the whole dataset into a training set with 85 subjects for 10-fold
cross-validation and a test set with 15 subjects for evaluating the performance
of models. Two models with the same network structures were trained and they
achieved a dice similarity coefficient (DSC) of 97.87% and 96.49% for the
periosteal and endosteal contours, respectively. To verify the excellent
performance of our model for femoral segmentation, we measured the volume of
different parts of the femur and compared it with the ground truth and the
relative errors between predicted result and ground truth are all less than 5%.
It demonstrated a strong potential for clinical use, including the hip fracture
risk prediction and finite element analysis.
</p>
<a href="http://arxiv.org/abs/2102.01990" target="_blank">arXiv:2102.01990</a> [<a href="http://arxiv.org/pdf/2102.01990" target="_blank">pdf</a>]

<h2>Unbox the Black-box for the Medical Explainable AI via Multi-modal and Multi-centre Data Fusion: A Mini-Review, Two Showcases and Beyond. (arXiv:2102.01998v1 [cs.AI])</h2>
<h3>Guang Yang, Qinghao Ye, Jun Xia</h3>
<p>Explainable Artificial Intelligence (XAI) is an emerging research topic of
machine learning aimed at unboxing how AI systems' black-box choices are made.
This research field inspects the measures and models involved in
decision-making and seeks solutions to explain them explicitly. Many of the
machine learning algorithms can not manifest how and why a decision has been
cast. This is particularly true of the most popular deep neural network
approaches currently in use. Consequently, our confidence in AI systems can be
hindered by the lack of explainability in these black-box models. The XAI
becomes more and more crucial for deep learning powered applications,
especially for medical and healthcare studies, although in general these deep
neural networks can return an arresting dividend in performance. The
insufficient explainability and transparency in most existing AI systems can be
one of the major reasons that successful implementation and integration of AI
tools into routine clinical practice are uncommon. In this study, we first
surveyed the current progress of XAI and in particular its advances in
healthcare applications. We then introduced our solutions for XAI leveraging
multi-modal and multi-centre data fusion, and subsequently validated in two
showcases following real clinical scenarios. Comprehensive quantitative and
qualitative analyses can prove the efficacy of our proposed XAI solutions, from
which we can envisage successful applications in a broader range of clinical
questions.
</p>
<a href="http://arxiv.org/abs/2102.01998" target="_blank">arXiv:2102.01998</a> [<a href="http://arxiv.org/pdf/2102.01998" target="_blank">pdf</a>]

<h2>A generalised feature for low level vision. (arXiv:2102.02000v1 [cs.CV])</h2>
<h3>Dr David Sinclair, Dr Christopher Town</h3>
<p>This papers presents a novel quantised transform (the Sinclair-Town or ST
transform for short) that subsumes the rolls of both edge-detector, MSER style
region detector and corner detector. The transform is similar to the $unsharp$
transform but the difference from the local mean is quantised to 3 values
(dark-neutral-light). The transform naturally leads to the definition of an
appropriate local scale. A range of methods for extracting shape features form
the transformed image are presented. The generalized feature provides a robust
basis for establishing correspondence between images. The transform readily
admits more complicated kernel behaviour including multi-scale and asymmetric
elements to prefer shorter scale or oriented local features.
</p>
<a href="http://arxiv.org/abs/2102.02000" target="_blank">arXiv:2102.02000</a> [<a href="http://arxiv.org/pdf/2102.02000" target="_blank">pdf</a>]

<h2>Robust pedestrian detection in thermal imagery using synthesized images. (arXiv:2102.02005v1 [cs.CV])</h2>
<h3>My Kieu, Lorenzo Berlincioni, Leonardo Galteri, Marco Bertini, Andrew D. Bagdanov, Alberto Del Bimbo</h3>
<p>In this paper we propose a method for improving pedestrian detection in the
thermal domain using two stages: first, a generative data augmentation approach
is used, then a domain adaptation method using generated data adapts an RGB
pedestrian detector. Our model, based on the Least-Squares Generative
Adversarial Network, is trained to synthesize realistic thermal versions of
input RGB images which are then used to augment the limited amount of labeled
thermal pedestrian images available for training. We apply our generative data
augmentation strategy in order to adapt a pretrained YOLOv3 pedestrian detector
to detection in the thermal-only domain. Experimental results demonstrate the
effectiveness of our approach: using less than 50\% of available real thermal
training data, and relying on synthesized data generated by our model in the
domain adaptation phase, our detector achieves state-of-the-art results on the
KAIST Multispectral Pedestrian Detection Benchmark; even if more real thermal
data is available adding GAN generated images to the training data results in
improved performance, thus showing that these images act as an effective form
of data augmentation. To the best of our knowledge, our detector achieves the
best single-modality detection results on KAIST with respect to the
state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.02005" target="_blank">arXiv:2102.02005</a> [<a href="http://arxiv.org/pdf/2102.02005" target="_blank">pdf</a>]

<h2>Social Network Analysis of Hadith Narrators from Sahih Bukhari. (arXiv:2102.02009v1 [cs.AI])</h2>
<h3>Tanvir Alam, Jens Schneider</h3>
<p>The ahadith, prophetic traditions for the Muslims around the world, are
narrations originating from the sayings and the deeds of Prophet Muhammad
(pbuh). They are considered one of the fundamental sources of Islamic
legislation along with the Quran. The list of persons involved in the narration
of each hadith is carefully scrutinized by scholars studying the hadith, with
respect to their reputation and authenticity of the hadith. This is due to the
its legislative importance in Islamic principles. There were many narrators who
contributed to this responsibility of preserving prophetic narrations over the
centuries. But to date, no systematic and comprehensive study, based on the
social network, has been adapted to understand the contribution of early hadith
narrators and the propagation of hadith across generations. In this study, we
represented the chain of narrators of the hadith collection from Sahih Bukhari
as a social graph. Based on social network analysis (SNA) on this graph, we
found that the network of narrators is a scale-free network. We identified a
list of influential narrators from the companions as well as the narrators from
the second and third-generation who contribute significantly in the propagation
of hadith collected in Sahih Bukhari. We discovered sixteen communities from
the narrators of Sahih Bukhari. In each of these communities, there are other
narrators who contributed significantly to the propagation of prophetic
narrations. We also found that most narrators were centered in Makkah and
Madinah in the era of companions and, then, gradually the center of hadith
narrators shifted towards Kufa, Baghdad and central Asia over a period of time.
To the best of our knowledge, this the first comprehensive and systematic study
based on SNA, representing the narrators as a social graph to analyze their
contribution to the preservation and propagation of hadith.
</p>
<a href="http://arxiv.org/abs/2102.02009" target="_blank">arXiv:2102.02009</a> [<a href="http://arxiv.org/pdf/2102.02009" target="_blank">pdf</a>]

<h2>Learning Graph Representations. (arXiv:2102.02026v1 [cs.LG])</h2>
<h3>Rucha Bhalchandra Joshi, Subhankar Mishra</h3>
<p>Social and information networks are gaining huge popularity recently due to
their various applications. Knowledge representation through graphs in the form
of nodes and edges should preserve as many characteristics of the original data
as possible. Some of the interesting and useful applications on these graphs
are graph classification, node classification, link prediction, etc. The Graph
Neural Networks have evolved over the last few years. Graph Neural Networks
(GNNs) are efficient ways to get insight into large and dynamic graph datasets
capturing relationships among billions of entities also known as knowledge
graphs.

In this paper, we discuss the graph convolutional neural networks graph
autoencoders and spatio-temporal graph neural networks. The representations of
the graph in lower dimensions can be learned using these methods. The
representations in lower dimensions can be used further for downstream machine
learning tasks.
</p>
<a href="http://arxiv.org/abs/2102.02026" target="_blank">arXiv:2102.02026</a> [<a href="http://arxiv.org/pdf/2102.02026" target="_blank">pdf</a>]

<h2>Isometric Propagation Network for Generalized Zero-shot Learning. (arXiv:2102.02038v1 [cs.CV])</h2>
<h3>Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Xuanyi Dong, Chengqi Zhang</h3>
<p>Zero-shot learning (ZSL) aims to classify images of an unseen class only
based on a few attributes describing that class but no access to any training
sample. A popular strategy is to learn a mapping between the semantic space of
class attributes and the visual space of images based on the seen classes and
their data. Thus, an unseen class image can be ideally mapped to its
corresponding class attributes. The key challenge is how to align the
representations in the two spaces. For most ZSL settings, the attributes for
each seen/unseen class are only represented by a vector while the seen-class
data provide much more information. Thus, the imbalanced supervision from the
semantic and the visual space can make the learned mapping easily overfitting
to the seen classes. To resolve this problem, we propose Isometric Propagation
Network (IPN), which learns to strengthen the relation between classes within
each space and align the class dependency in the two spaces. Specifically, IPN
learns to propagate the class representations on an auto-generated graph within
each space. In contrast to only aligning the resulted static representation, we
regularize the two dynamic propagation procedures to be isometric in terms of
the two graphs' edge weights per step by minimizing a consistency loss between
them. IPN achieves state-of-the-art performance on three popular ZSL
benchmarks. To evaluate the generalization capability of IPN, we further build
two larger benchmarks with more diverse unseen classes and demonstrate the
advantages of IPN on them.
</p>
<a href="http://arxiv.org/abs/2102.02038" target="_blank">arXiv:2102.02038</a> [<a href="http://arxiv.org/pdf/2102.02038" target="_blank">pdf</a>]

<h2>On Query-efficient Planning in MDPs under Linear Realizability of the Optimal State-value Function. (arXiv:2102.02049v1 [cs.LG])</h2>
<h3>Gellert Weisz, Philip Amortila, Barnab&#xe1;s Janzer, Yasin Abbasi-Yadkori, Nan Jiang, Csaba Szepesv&#xe1;ri</h3>
<p>We consider the problem of local planning in fixed-horizon Markov Decision
Processes (MDPs) with a generative model under the assumption that the optimal
value function lies in the span of a feature map that is accessible through the
generative model. As opposed to previous work where linear realizability of all
policies was assumed, we consider the significantly relaxed assumption of a
single linearly realizable (deterministic) policy. A recent lower bound
established that the related problem when the action-value function of the
optimal policy is linearly realizable requires an exponential number of
queries, either in H (the horizon of the MDP) or d (the dimension of the
feature mapping). Their construction crucially relies on having an
exponentially large action set. In contrast, in this work, we establish that
poly$(H, d)$ learning is possible (with state value function realizability)
whenever the action set is small (i.e. O(1)). In particular, we present the
TensorPlan algorithm which uses poly$((dH/\delta)^A)$ queries to find a
$\delta$-optimal policy relative to any deterministic policy for which the
value function is linearly realizable with a parameter from a fixed radius ball
around zero. This is the first algorithm to give a polynomial query complexity
guarantee using only linear-realizability of a single competing value function.
Whether the computation cost is similarly bounded remains an interesting open
question. The upper bound is complemented by a lower bound which proves that in
the infinite-horizon episodic setting, planners that achieve constant
suboptimality need exponentially many queries, either in the dimension or the
number of actions.
</p>
<a href="http://arxiv.org/abs/2102.02049" target="_blank">arXiv:2102.02049</a> [<a href="http://arxiv.org/pdf/2102.02049" target="_blank">pdf</a>]

<h2>Trusted Multi-View Classification. (arXiv:2102.02051v1 [cs.LG])</h2>
<h3>Zongbo Han, Changqing Zhang, Huazhu Fu, Joey Tianyi Zhou</h3>
<p>Multi-view classification (MVC) generally focuses on improving classification
accuracy by using information from different views, typically integrating them
into a unified comprehensive representation for downstream tasks. However, it
is also crucial to dynamically assess the quality of a view for different
samples in order to provide reliable uncertainty estimations, which indicate
whether predictions can be trusted. To this end, we propose a novel multi-view
classification method, termed trusted multi-view classification, which provides
a new paradigm for multi-view learning by dynamically integrating different
views at an evidence level. The algorithm jointly utilizes multiple views to
promote both classification reliability and robustness by integrating evidence
from each view. To achieve this, the Dirichlet distribution is used to model
the distribution of the class probabilities, parameterized with evidence from
different views and integrated with the Dempster-Shafer theory. The unified
learning framework induces accurate uncertainty and accordingly endows the
model with both reliability and robustness for out-of-distribution samples.
Extensive experimental results validate the effectiveness of the proposed model
in accuracy, reliability and robustness.
</p>
<a href="http://arxiv.org/abs/2102.02051" target="_blank">arXiv:2102.02051</a> [<a href="http://arxiv.org/pdf/2102.02051" target="_blank">pdf</a>]

<h2>Federated Learning on Non-IID Data Silos: An Experimental Study. (arXiv:2102.02079v1 [cs.LG])</h2>
<h3>Qinbin Li, Yiqun Diao, Quan Chen, Bingsheng He</h3>
<p>Machine learning services have been emerging in many data-intensive
applications, and their effectiveness highly relies on large-volume
high-quality training data. However, due to the increasing privacy concerns and
data regulations, training data have been increasingly fragmented, forming
distributed databases of multiple data silos (e.g., within different
organizations and countries). To develop effective machine learning services,
there is a must to exploit data from such distributed databases without
exchanging the raw data. Recently, federated learning (FL) has been a solution
with growing interests, which enables multiple parties to collaboratively train
a machine learning model without exchanging their local data. A key and common
challenge on distributed databases is the heterogeneity of the data
distribution (i.e., non-IID) among the parties. There have been many FL
algorithms to address the learning effectiveness under non-IID data settings.
However, there lacks an experimental study on systematically understanding
their advantages and disadvantages, as previous studies have very rigid data
partitioning strategies among parties, which are hardly representative and
thorough. In this paper, to help researchers better understand and study the
non-IID data setting in federated learning, we propose comprehensive data
partitioning strategies to cover the typical non-IID data cases. Moreover, we
conduct extensive experiments to evaluate state-of-the-art FL algorithms. We
find that non-IID does bring significant challenges in learning accuracy of FL
algorithms, and none of the existing state-of-the-art FL algorithms outperforms
others in all cases. Our experiments provide insights for future studies of
addressing the challenges in data silos.
</p>
<a href="http://arxiv.org/abs/2102.02079" target="_blank">arXiv:2102.02079</a> [<a href="http://arxiv.org/pdf/2102.02079" target="_blank">pdf</a>]

<h2>PARAFAC2 AO-ADMM: Constraints in all modes. (arXiv:2102.02087v1 [cs.LG])</h2>
<h3>Marie Roald, Carla Schenker, Jeremy E. Cohen, Evrim Acar</h3>
<p>The PARAFAC2 model provides a flexible alternative to the popular
CANDECOMP/PARAFAC (CP) model for tensor decompositions. Unlike CP, PARAFAC2
allows factor matrices in one mode (i.e., evolving mode) to change across
tensor slices, which has proven useful for applications in different domains
such as chemometrics, and neuroscience. However, the evolving mode of the
PARAFAC2 model is traditionally modelled implicitly, which makes it challenging
to regularise it. Currently, the only way to apply regularisation on that mode
is with a flexible coupling approach, which finds the solution through
regularised least-squares subproblems. In this work, we instead propose an
alternating direction method of multipliers (ADMM)-based algorithm for fitting
PARAFAC2 and widen the possible regularisation penalties to any proximable
function. Our numerical experiments demonstrate that the proposed ADMM-based
approach for PARAFAC2 can accurately recover the underlying components from
simulated data while being both computationally efficient and flexible in terms
of imposing constraints.
</p>
<a href="http://arxiv.org/abs/2102.02087" target="_blank">arXiv:2102.02087</a> [<a href="http://arxiv.org/pdf/2102.02087" target="_blank">pdf</a>]

<h2>Investigating Critical Risk Factors in Liver Cancer Prediction. (arXiv:2102.02088v1 [cs.LG])</h2>
<h3>Jinpeng Li, Yaling Tao, Ting Cai</h3>
<p>We exploit liver cancer prediction model using machine learning algorithms
based on epidemiological data of over 55 thousand peoples from 2014 to the
present. The best performance is an AUC of 0.71. We analyzed model parameters
to investigate critical risk factors that contribute the most to prediction.
</p>
<a href="http://arxiv.org/abs/2102.02088" target="_blank">arXiv:2102.02088</a> [<a href="http://arxiv.org/pdf/2102.02088" target="_blank">pdf</a>]

<h2>Uncertain Time Series Classification With Shapelet Transform. (arXiv:2102.02090v1 [cs.LG])</h2>
<h3>Michael Franklin Mbouopda, Engelbert Mephu Nguifo</h3>
<p>Time series classification is a task that aims at classifying chronological
data. It is used in a diverse range of domains such as meteorology, medicine
and physics. In the last decade, many algorithms have been built to perform
this task with very appreciable accuracy. However, applications where time
series have uncertainty has been under-explored. Using uncertainty propagation
techniques, we propose a new uncertain dissimilarity measure based on Euclidean
distance. We then propose the uncertain shapelet transform algorithm for the
classification of uncertain time series. The large experiments we conducted on
state of the art datasets show the effectiveness of our contribution. The
source code of our contribution and the datasets we used are all available on a
public repository.
</p>
<a href="http://arxiv.org/abs/2102.02090" target="_blank">arXiv:2102.02090</a> [<a href="http://arxiv.org/pdf/2102.02090" target="_blank">pdf</a>]

<h2>Object and Relation Centric Representations for Push Effect Prediction. (arXiv:2102.02100v1 [cs.RO])</h2>
<h3>Ahmet E. Tekden, Aykut Erdem, Erkut Erdem, Tamim Asfour, Emre Ugur</h3>
<p>Pushing is an essential non-prehensile manipulation skill used for tasks
ranging from pre-grasp manipulation to scene rearrangement, reasoning about
object relations in the scene, and thus pushing actions have been widely
studied in robotics. The effective use of pushing actions often requires an
understanding of the dynamics of the manipulated objects and adaptation to the
discrepancies between prediction and reality. For this reason, effect
prediction and parameter estimation with pushing actions have been heavily
investigated in the literature. However, current approaches are limited because
they either model systems with a fixed number of objects or use image-based
representations whose outputs are not very interpretable and quickly accumulate
errors. In this paper, we propose a graph neural network based framework for
effect prediction and parameter estimation of pushing actions by modeling
object relations based on contacts or articulations. Our framework is validated
both in real and simulated environments containing different shaped multi-part
objects connected via different types of joints and objects with different
masses. Our approach enables the robot to predict and adapt the effect of a
pushing action as it observes the scene. Further, we demonstrate 6D effect
prediction in the lever-up action in the context of robot-based hard-disk
disassembly.
</p>
<a href="http://arxiv.org/abs/2102.02100" target="_blank">arXiv:2102.02100</a> [<a href="http://arxiv.org/pdf/2102.02100" target="_blank">pdf</a>]

<h2>Learning a Compact State Representation for Navigation Tasks by Autoencoding 2D-Lidar Scans. (arXiv:2102.02127v1 [cs.RO])</h2>
<h3>Christopher Gebauer, Maren Bennewitz</h3>
<p>In this paper, we address the problem of generating a compact representation
of 2D-lidar scans for reinforcement learning in navigation tasks. By now only
little work focuses on the compactness of the provided state, which is a
necessary condition to successfully and efficiently train a navigation agent.
Our approach works in three stages. First, we propose a novel preprocessing of
the distance measurements and compute a local, egocentric, binary grid map
based on the current range measurements. We then autoencode the local map using
a variational autoencoder, where the latent space serves as state
representation. An important key for a compact and, at the same time,
meaningful representation is the degree of disentanglement, which describes the
correlation between each latent dimension. Therefore, we finally apply
state-of-the-art disentangling methods to improve the representation power.
Furthermore, we investige the possibilities of incorporating time-dependent
information into the latent space. In particular, we incorporate the relation
of consecutive scans, especially ego-motion, by applying a memory model. We
implemented our approach in python using tensorflow. Our datasets are simulated
with pybullet as well as recorded using a slamtec rplidar A3. The experiments
show the capability of our approach to highly compress lidar data, maintain a
meaningful distribution of the latent space, and even incorporate time-depended
information.
</p>
<a href="http://arxiv.org/abs/2102.02127" target="_blank">arXiv:2102.02127</a> [<a href="http://arxiv.org/pdf/2102.02127" target="_blank">pdf</a>]

<h2>IWA: Integrated Gradient based White-box Attacks for Fooling Deep Neural Networks. (arXiv:2102.02128v1 [cs.LG])</h2>
<h3>Yixiang Wang, Jiqiang Liu, Xiaolin Chang, Jelena Mi&#x161;i&#x107;, Vojislav B. Mi&#x161;i&#x107;</h3>
<p>The widespread application of deep neural network (DNN) techniques is being
challenged by adversarial examples, the legitimate input added with
imperceptible and well-designed perturbations that can fool DNNs easily in the
DNN testing/deploying stage. Previous adversarial example generation algorithms
for adversarial white-box attacks used Jacobian gradient information to add
perturbations. This information is too imprecise and inexplicit, which will
cause unnecessary perturbations when generating adversarial examples. This
paper aims to address this issue. We first propose to apply a more informative
and distilled gradient information, namely integrated gradient, to generate
adversarial examples. To further make the perturbations more imperceptible, we
propose to employ the restriction combination of $L_0$ and $L_1/L_2$ secondly,
which can restrict the total perturbations and perturbation points
simultaneously. Meanwhile, to address the non-differentiable problem of $L_1$,
we explore a proximal operation of $L_1$ thirdly. Based on these three works,
we propose two Integrated gradient based White-box Adversarial example
generation algorithms (IWA): IFPA and IUA. IFPA is suitable for situations
where there are a determined number of points to be perturbed. IUA is suitable
for situations where no perturbation point number is preset in order to obtain
more adversarial examples. We verify the effectiveness of the proposed
algorithms on both structured and unstructured datasets, and we compare them
with five baseline generation algorithms. The results show that our proposed
algorithms do craft adversarial examples with more imperceptible perturbations
and satisfactory crafting rate. $L_2$ restriction is more suitable for
unstructured dataset and $L_1$ restriction performs better in structured
dataset.
</p>
<a href="http://arxiv.org/abs/2102.02128" target="_blank">arXiv:2102.02128</a> [<a href="http://arxiv.org/pdf/2102.02128" target="_blank">pdf</a>]

<h2>The Archerfish Hunting Optimizer: a novel metaheuristic algorithm for global optimization. (arXiv:2102.02134v1 [cs.AI])</h2>
<h3>Farouq Zitouni, Saad Harous, Abdelghani Belkeram, Lokman Elhakim Baba Hammou</h3>
<p>Global optimization solves real-world problems numerically or analytically by
minimizing their objective functions. Most of the analytical algorithms are
greedy and computationally intractable. Metaheuristics are nature-inspired
optimization algorithms. They numerically find a near-optimal solution for
optimization problems in a reasonable amount of time. We propose a novel
metaheuristic algorithm for global optimization. It is based on the shooting
and jumping behaviors of the archerfish for hunting aerial insects. We name it
the Archerfish Hunting Optimizer (AHO). We Perform two sorts of comparisons to
validate the proposed algorithm's performance. First, AHO is compared to the 12
recent metaheuristic algorithms (the accepted algorithms for the 2020's
competition on single objective bound-constrained numerical optimization) on
ten test functions of the benchmark CEC 2020 for unconstrained optimization.
Second, the performance of AHO and 3 recent metaheuristic algorithms, is
evaluated using five engineering design problems taken from the benchmark CEC
2020 for non-convex constrained optimization. The experimental results are
evaluated using the Wilcoxon signed-rank and the Friedman tests. The
statistical indicators illustrate that the Archerfish Hunting Optimizer has an
excellent ability to accomplish higher performance in competition with the
well-established optimizers.
</p>
<a href="http://arxiv.org/abs/2102.02134" target="_blank">arXiv:2102.02134</a> [<a href="http://arxiv.org/pdf/2102.02134" target="_blank">pdf</a>]

<h2>BeFair: Addressing Fairness in the Banking Sector. (arXiv:2102.02137v1 [cs.LG])</h2>
<h3>Riccardo Crupi, Giulia Del Gamba, Greta Greco, Aisha Naseer, Daniele Regoli, Beatriz San Miguel Gonzalez</h3>
<p>Algorithmic bias mitigation has been one of the most difficult conundrums for
the data science community and Machine Learning (ML) experts. Over several
years, there have appeared enormous efforts in the field of fairness in ML.
Despite the progress toward identifying biases and designing fair algorithms,
translating them into the industry remains a major challenge. In this paper, we
present the initial results of an industrial open innovation project in the
banking sector: we propose a general roadmap for fairness in ML and the
implementation of a toolkit called BeFair that helps to identify and mitigate
bias. Results show that training a model without explicit constraints may lead
to bias exacerbation in the predictions.
</p>
<a href="http://arxiv.org/abs/2102.02137" target="_blank">arXiv:2102.02137</a> [<a href="http://arxiv.org/pdf/2102.02137" target="_blank">pdf</a>]

<h2>Adversarially Robust Learning with Unknown Perturbation Sets. (arXiv:2102.02145v1 [cs.LG])</h2>
<h3>Omar Montasser, Steve Hanneke, Nathan Srebro</h3>
<p>We study the problem of learning predictors that are robust to adversarial
examples with respect to an unknown perturbation set, relying instead on
interaction with an adversarial attacker or access to attack oracles, examining
different models for such interactions. We obtain upper bounds on the sample
complexity and upper and lower bounds on the number of required interactions,
or number of successful attacks, in different interaction models, in terms of
the VC and Littlestone dimensions of the hypothesis class of predictors, and
without any assumptions on the perturbation set.
</p>
<a href="http://arxiv.org/abs/2102.02145" target="_blank">arXiv:2102.02145</a> [<a href="http://arxiv.org/pdf/2102.02145" target="_blank">pdf</a>]

<h2>Fixed-point Quantization of Convolutional Neural Networks for Quantized Inference on Embedded Platforms. (arXiv:2102.02147v1 [cs.CV])</h2>
<h3>Rishabh Goyal, Joaquin Vanschoren, Victor van Acht, Stephan Nijssen</h3>
<p>Convolutional Neural Networks (CNNs) have proven to be a powerful
state-of-the-art method for image classification tasks. One drawback however is
the high computational complexity and high memory consumption of CNNs which
makes them unfeasible for execution on embedded platforms which are constrained
on physical resources needed to support CNNs. Quantization has often been used
to efficiently optimize CNNs for memory and computational complexity at the
cost of a loss of prediction accuracy. We therefore propose a method to
optimally quantize the weights, biases and activations of each layer of a
pre-trained CNN while controlling the loss in inference accuracy to enable
quantized inference. We quantize the 32-bit floating-point precision parameters
to low bitwidth fixed-point representations thereby finding optimal bitwidths
and fractional offsets for parameters of each layer of a given CNN. We quantize
parameters of a CNN post-training without re-training it. Our method is
designed to quantize parameters of a CNN taking into account how other
parameters are quantized because ignoring quantization errors due to other
quantized parameters leads to a low precision CNN with accuracy losses of up to
50% which is far beyond what is acceptable. Our final method therefore gives a
low precision CNN with accuracy losses of less than 1%. As compared to a method
used by commercial tools that quantize all parameters to 8-bits, our approach
provides quantized CNN with averages of 53% lower memory consumption and 77.5%
lower cost of executing multiplications for the two CNNs trained on the four
datasets that we tested our work on. We find that layer-wise quantization of
parameters significantly helps in this process.
</p>
<a href="http://arxiv.org/abs/2102.02147" target="_blank">arXiv:2102.02147</a> [<a href="http://arxiv.org/pdf/2102.02147" target="_blank">pdf</a>]

<h2>Fast Concept Mapping: The Emergence of Human Abilities in Artificial Neural Networks when Learning Embodied and Self-Supervised. (arXiv:2102.02153v1 [cs.LG])</h2>
<h3>Viviane Clay, Peter K&#xf6;nig, Gordon Pipa, Kai-Uwe K&#xfc;hnberger</h3>
<p>Most artificial neural networks used for object detection and recognition are
trained in a fully supervised setup. This is not only very resource consuming
as it requires large data sets of labeled examples but also very different from
how humans learn. We introduce a setup in which an artificial agent first
learns in a simulated world through self-supervised exploration. Following
this, the representations learned through interaction with the world can be
used to associate semantic concepts such as different types of doors. To do
this, we use a method we call fast concept mapping which uses correlated firing
patterns of neurons to define and detect semantic concepts. This association
works instantaneous with very few labeled examples, similar to what we observe
in humans in a phenomenon called fast mapping. Strikingly, this method already
identifies objects with as little as one labeled example which highlights the
quality of the encoding learned self-supervised through embodiment using
curiosity-driven exploration. It therefor presents a feasible strategy for
learning concepts without much supervision and shows that through pure
interaction with the world meaningful representations of an environment can be
learned.
</p>
<a href="http://arxiv.org/abs/2102.02153" target="_blank">arXiv:2102.02153</a> [<a href="http://arxiv.org/pdf/2102.02153" target="_blank">pdf</a>]

<h2>The Instability of Accelerated Gradient Descent. (arXiv:2102.02167v1 [cs.LG])</h2>
<h3>Amit Attia, Tomer Koren</h3>
<p>We study the algorithmic stability of Nesterov's accelerated gradient method.
For convex quadratic objectives, \citet{chen2018stability} proved that the
uniform stability of the method grows quadratically with the number of
optimization steps, and conjectured that the same is true for the general
convex and smooth case. We disprove this conjecture and show, for two notions
of stability, that the stability of Nesterov's accelerated method in fact
deteriorates \emph{exponentially fast} with the number of gradient steps. This
stands in sharp contrast to the bounds in the quadratic case, but also to known
results for non-accelerated gradient methods where stability typically grows
linearly with the number of steps.
</p>
<a href="http://arxiv.org/abs/2102.02167" target="_blank">arXiv:2102.02167</a> [<a href="http://arxiv.org/pdf/2102.02167" target="_blank">pdf</a>]

<h2>Outlier-Robust Learning of Ising Models Under Dobrushin's Condition. (arXiv:2102.02171v1 [cs.LG])</h2>
<h3>Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart, Yuxin Sun</h3>
<p>We study the problem of learning Ising models satisfying Dobrushin's
condition in the outlier-robust setting where a constant fraction of the
samples are adversarially corrupted. Our main result is to provide the first
computationally efficient robust learning algorithm for this problem with
near-optimal error guarantees. Our algorithm can be seen as a special case of
an algorithm for robustly learning a distribution from a general exponential
family. To prove its correctness for Ising models, we establish new
anti-concentration results for degree-$2$ polynomials of Ising models that may
be of independent interest.
</p>
<a href="http://arxiv.org/abs/2102.02171" target="_blank">arXiv:2102.02171</a> [<a href="http://arxiv.org/pdf/2102.02171" target="_blank">pdf</a>]

<h2>Embodied Intelligence via Learning and Evolution. (arXiv:2102.02202v1 [cs.LG])</h2>
<h3>Agrim Gupta, Silvio Savarese, Surya Ganguli, Li Fei-Fei</h3>
<p>The intertwined processes of learning and evolution in complex environmental
niches have resulted in a remarkable diversity of morphological forms.
Moreover, many aspects of animal intelligence are deeply embodied in these
evolved morphologies. However, the principles governing relations between
environmental complexity, evolved morphology, and the learnability of
intelligent control, remain elusive, partially due to the substantial challenge
of performing large-scale in silico experiments on evolution and learning. We
introduce Deep Evolutionary Reinforcement Learning (DERL): a novel
computational framework which can evolve diverse agent morphologies to learn
challenging locomotion and manipulation tasks in complex environments using
only low level egocentric sensory information. Leveraging DERL we demonstrate
several relations between environmental complexity, morphological intelligence
and the learnability of control. First, environmental complexity fosters the
evolution of morphological intelligence as quantified by the ability of a
morphology to facilitate the learning of novel tasks. Second, evolution rapidly
selects morphologies that learn faster, thereby enabling behaviors learned late
in the lifetime of early ancestors to be expressed early in the lifetime of
their descendants. In agents that learn and evolve in complex environments,
this result constitutes the first demonstration of a long-conjectured
morphological Baldwin effect. Third, our experiments suggest a mechanistic
basis for both the Baldwin effect and the emergence of morphological
intelligence through the evolution of morphologies that are more physically
stable and energy efficient, and can therefore facilitate learning and control.
</p>
<a href="http://arxiv.org/abs/2102.02202" target="_blank">arXiv:2102.02202</a> [<a href="http://arxiv.org/pdf/2102.02202" target="_blank">pdf</a>]

<h2>Efficient kernel-based variable selection with sparsistency. (arXiv:1802.09246v3 [stat.ML] UPDATED)</h2>
<h3>Xin He, Junhui Wang, Shaogao Lv</h3>
<p>Variable selection is central to high-dimensional data analysis, and various
algorithms have been developed. Ideally, a variable selection algorithm shall
be flexible, scalable, and with theoretical guarantee, yet most existing
algorithms cannot attain these properties at the same time. In this article, a
three-step variable selection algorithm is developed, involving kernel-based
estimation of the regression function and its gradient functions as well as a
hard thresholding. Its key advantage is that it assumes no explicit model
assumption, admits general predictor effects, allows for scalable computation,
and attains desirable asymptotic sparsistency. The proposed algorithm can be
adapted to any reproducing kernel Hilbert space (RKHS) with different kernel
functions, and can be extended to interaction selection with slight
modification. Its computational cost is only linear in the data dimension, and
can be further improved through parallel computing. The sparsistency of the
proposed algorithm is established for general RKHS under mild conditions,
including linear and Gaussian kernels as special cases. Its effectiveness is
also supported by a variety of simulated and real examples.
</p>
<a href="http://arxiv.org/abs/1802.09246" target="_blank">arXiv:1802.09246</a> [<a href="http://arxiv.org/pdf/1802.09246" target="_blank">pdf</a>]

<h2>A Unified Approach to Translate Classical Bandit Algorithms to the Structured Bandit Setting. (arXiv:1810.08164v7 [stat.ML] UPDATED)</h2>
<h3>Samarth Gupta, Shreyas Chaudhari, Subhojyoti Mukherjee, Gauri Joshi, Osman Ya&#x11f;an</h3>
<p>We consider a finite-armed structured bandit problem in which mean rewards of
different arms are known functions of a common hidden parameter $\theta^*$.
Since we do not place any restrictions of these functions, the problem setting
subsumes several previously studied frameworks that assume linear or invertible
reward functions. We propose a novel approach to gradually estimate the hidden
$\theta^*$ and use the estimate together with the mean reward functions to
substantially reduce exploration of sub-optimal arms. This approach enables us
to fundamentally generalize any classic bandit algorithm including UCB and
Thompson Sampling to the structured bandit setting. We prove via regret
analysis that our proposed UCB-C algorithm (structured bandit versions of UCB)
pulls only a subset of the sub-optimal arms $O(\log T)$ times while the other
sub-optimal arms (referred to as non-competitive arms) are pulled $O(1)$ times.
As a result, in cases where all sub-optimal arms are non-competitive, which can
happen in many practical scenarios, the proposed algorithms achieve bounded
regret. We also conduct simulations on the Movielens recommendations dataset to
demonstrate the improvement of the proposed algorithms over existing structured
bandit algorithms.
</p>
<a href="http://arxiv.org/abs/1810.08164" target="_blank">arXiv:1810.08164</a> [<a href="http://arxiv.org/pdf/1810.08164" target="_blank">pdf</a>]

<h2>Structured Neural Summarization. (arXiv:1811.01824v4 [cs.LG] UPDATED)</h2>
<h3>Patrick Fernandes, Miltiadis Allamanis, Marc Brockschmidt</h3>
<p>Summarization of long sequences into a concise statement is a core problem in
natural language processing, requiring non-trivial understanding of the input.
Based on the promising results of graph neural networks on highly structured
data, we develop a framework to extend existing sequence encoders with a graph
component that can reason about long-distance relationships in weakly
structured data such as text. In an extensive evaluation, we show that the
resulting hybrid sequence-graph models outperform both pure sequence models as
well as pure graph models on a range of summarization tasks.
</p>
<a href="http://arxiv.org/abs/1811.01824" target="_blank">arXiv:1811.01824</a> [<a href="http://arxiv.org/pdf/1811.01824" target="_blank">pdf</a>]

<h2>Spread Divergences. (arXiv:1811.08968v4 [stat.ML] UPDATED)</h2>
<h3>Mingtian Zhang, Peter Hayes, Tom Bird, Raza Habib, David Barber</h3>
<p>For distributions p and q with different supports, the divergence D(p|q) may
not exist. We define a spread divergence on modified p and q and describe
sufficient conditions for the existence of such a divergence. We demonstrate
how to maximize the discriminatory power of a given divergence by
parameterizing and learning the spread. We also give examples of using a spread
divergence to train and improve implicit generative models, including linear
models (Independent Components Analysis) and non-linear models (Deep Generative
Networks).
</p>
<a href="http://arxiv.org/abs/1811.08968" target="_blank">arXiv:1811.08968</a> [<a href="http://arxiv.org/pdf/1811.08968" target="_blank">pdf</a>]

<h2>Real-Time Trajectory Planning for AGV in the Presence of Moving Obstacles: A First-Search-Then-Optimization Approach. (arXiv:1902.06201v5 [cs.RO] UPDATED)</h2>
<h3>Bai Li</h3>
<p>This paper proposes a unified and fast trajectory planning method for an
autonomous vehicle with avoidance of static obstacles in the off-road
scenarios. Nominally, an optimal control problem should be used to cover
generic off-road planning cases. However, the scale of the formulated optimal
control problem is intractable, because the ego vehicle has to avoid collision
with every obstacle at every moment. To address this issue, we aim to discard
the redundant collision-avoidance constraints, because the vehicle may not
really have chances to collide with all of the obstacles at every moment.
Concretely, with the help of a reference trajectory derived by hybrid A*
algorithm, we develop a spatiotemporal tunnel-based strategy such that the ego
vehicle is restricted to move within a sequence of tunnels during different
periods of the entire dynamic process. Through this, the collision-avoidance
constraints are replaced by the within-tunnel constraints, thereby making the
scale of the optimal control problem completely irrelevant to the complexity of
the environment.
</p>
<a href="http://arxiv.org/abs/1902.06201" target="_blank">arXiv:1902.06201</a> [<a href="http://arxiv.org/pdf/1902.06201" target="_blank">pdf</a>]

<h2>Deep Learning in Cardiology. (arXiv:1902.11122v3 [cs.CV] UPDATED)</h2>
<h3>Paschalis Bizopoulos, Dimitrios Koutsouris</h3>
<p>The medical field is creating large amount of data that physicians are unable
to decipher and use efficiently. Moreover, rule-based expert systems are
inefficient in solving complicated medical tasks or for creating insights using
big data. Deep learning has emerged as a more accurate and effective technology
in a wide range of medical problems such as diagnosis, prediction and
intervention. Deep learning is a representation learning method that consists
of layers that transform the data non-linearly, thus, revealing hierarchical
relationships and structures. In this review we survey deep learning
application papers that use structured data, signal and imaging modalities from
cardiology. We discuss the advantages and limitations of applying deep learning
in cardiology that also apply in medicine in general, while proposing certain
directions as the most viable for clinical use.
</p>
<a href="http://arxiv.org/abs/1902.11122" target="_blank">arXiv:1902.11122</a> [<a href="http://arxiv.org/pdf/1902.11122" target="_blank">pdf</a>]

<h2>Data-driven Estimation of Sinusoid Frequencies. (arXiv:1906.00823v3 [cs.LG] UPDATED)</h2>
<h3>Gautier Izacard, Sreyas Mohan, Carlos Fernandez-Granda</h3>
<p>Frequency estimation is a fundamental problem in signal processing, with
applications in radar imaging, underwater acoustics, seismic imaging, and
spectroscopy. The goal is to estimate the frequency of each component in a
multisinusoidal signal from a finite number of noisy samples. A recent
machine-learning approach uses a neural network to output a learned
representation with local maxima at the position of the frequency estimates. In
this work, we propose a novel neural-network architecture that produces a
significantly more accurate representation, and combine it with an additional
neural-network module trained to detect the number of frequencies. This yields
a fast, fully-automatic method for frequency estimation that achieves
state-of-the-art results. In particular, it outperforms existing techniques by
a substantial margin at medium-to-high noise levels.
</p>
<a href="http://arxiv.org/abs/1906.00823" target="_blank">arXiv:1906.00823</a> [<a href="http://arxiv.org/pdf/1906.00823" target="_blank">pdf</a>]

<h2>Outlier Exposure with Confidence Control for Out-of-Distribution Detection. (arXiv:1906.03509v4 [cs.LG] UPDATED)</h2>
<h3>Aristotelis-Angelos Papadopoulos, Mohammad Reza Rajati, Nazim Shaikh, Jiamian Wang</h3>
<p>Deep neural networks have achieved great success in classification tasks
during the last years. However, one major problem to the path towards
artificial intelligence is the inability of neural networks to accurately
detect samples from novel class distributions and therefore, most of the
existent classification algorithms assume that all classes are known prior to
the training stage. In this work, we propose a methodology for training a
neural network that allows it to efficiently detect out-of-distribution (OOD)
examples without compromising much of its classification accuracy on the test
examples from known classes. We propose a novel loss function that gives rise
to a novel method, Outlier Exposure with Confidence Control (OECC), which
achieves superior results in OOD detection with OE both on image and text
classification tasks without requiring access to OOD samples. Additionally, we
experimentally show that the combination of OECC with state-of-the-art
post-training OOD detection methods, like the Mahalanobis Detector (MD) and the
Gramian Matrices (GM) methods, further improves their performance in the OOD
detection task, demonstrating the potential of combining training and
post-training methods for OOD detection.
</p>
<a href="http://arxiv.org/abs/1906.03509" target="_blank">arXiv:1906.03509</a> [<a href="http://arxiv.org/pdf/1906.03509" target="_blank">pdf</a>]

<h2>Sparsely Activated Networks. (arXiv:1907.06592v4 [cs.LG] UPDATED)</h2>
<h3>Paschalis Bizopoulos, Dimitrios Koutsouris</h3>
<p>Previous literature on unsupervised learning focused on designing structural
priors with the aim of learning meaningful features. However, this was done
without considering the description length of the learned representations which
is a direct and unbiased measure of the model complexity. In this paper, first
we introduce the $\varphi$ metric that evaluates unsupervised models based on
their reconstruction accuracy and the degree of compression of their internal
representations. We then present and define two activation functions (Identity,
ReLU) as base of reference and three sparse activation functions (top-k
absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize
the previously defined $\varphi$. We lastly present Sparsely Activated Networks
(SANs) that consist of kernels with shared weights that, during encoding, are
convolved with the input and then passed through a sparse activation function.
During decoding, the same weights are convolved with the sparse activation map
and subsequently the partial reconstructions from each weight are summed to
reconstruct the input. We compare SANs using the five previously defined
activation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST,
FMNIST) and show that models that are selected using $\varphi$ have small
description representation length and consist of interpretable kernels.
</p>
<a href="http://arxiv.org/abs/1907.06592" target="_blank">arXiv:1907.06592</a> [<a href="http://arxiv.org/pdf/1907.06592" target="_blank">pdf</a>]

<h2>Smoothness-Adaptive Contextual Bandits. (arXiv:1910.09714v4 [cs.LG] UPDATED)</h2>
<h3>Yonatan Gur, Ahmadreza Momeni, Stefan Wager</h3>
<p>We study a non-parametric multi-armed bandit problem with stochastic
covariates, where a key complexity driver is the smoothness of payoff functions
with respect to covariates. Previous studies have focused on deriving
minimax-optimal algorithms in cases where it is a priori known how smooth the
payoff functions are. In practice, however, the smoothness of payoff functions
is typically not known in advance, and misspecification of smoothness may
severely deteriorate the performance of existing methods. In this work, we
consider a framework where the smoothness of payoff functions is not known, and
study when and how algorithms may adapt to unknown smoothness. First, we
establish that designing algorithms that adapt to unknown smoothness of payoff
functions is, in general, impossible. However, under a self-similarity
condition (which does not reduce the minimax complexity of the dynamic
optimization problem at hand), we establish that adapting to unknown smoothness
is possible, and further devise a general policy for achieving
smoothness-adaptive performance. Our policy infers the smoothness of payoffs
throughout the decision-making process, while leveraging the structure of
non-adaptive off-the-shelf policies. We establish that for problem settings
with either differentiable or non-differentiable payoff functions this policy
matches (up to a logarithmic scale) the regret rate that is achievable when the
smoothness of payoffs is known a priori.
</p>
<a href="http://arxiv.org/abs/1910.09714" target="_blank">arXiv:1910.09714</a> [<a href="http://arxiv.org/pdf/1910.09714" target="_blank">pdf</a>]

<h2>Asymptotics of Reinforcement Learning with Neural Networks. (arXiv:1911.07304v3 [cs.LG] UPDATED)</h2>
<h3>Justin Sirignano, Konstantinos Spiliopoulos</h3>
<p>We prove that a single-layer neural network trained with the Q-learning
algorithm converges in distribution to a random ordinary differential equation
as the size of the model and the number of training steps become large.
Analysis of the limit differential equation shows that it has a unique
stationary solution which is the solution of the Bellman equation, thus giving
the optimal control for the problem. In addition, we study the convergence of
the limit differential equation to the stationary solution. As a by-product of
our analysis, we obtain the limiting behavior of single-layer neural networks
when trained on i.i.d. data with stochastic gradient descent under the
widely-used Xavier initialization.
</p>
<a href="http://arxiv.org/abs/1911.07304" target="_blank">arXiv:1911.07304</a> [<a href="http://arxiv.org/pdf/1911.07304" target="_blank">pdf</a>]

<h2>Federated Variance-Reduced Stochastic Gradient Descent with Robustness to Byzantine Attacks. (arXiv:1912.12716v2 [cs.LG] UPDATED)</h2>
<h3>Zhaoxian Wu, Qing Ling, Tianyi Chen, Georgios B. Giannakis</h3>
<p>This paper deals with distributed finite-sum optimization for learning over
networks in the presence of malicious Byzantine attacks. To cope with such
attacks, most resilient approaches so far combine stochastic gradient descent
(SGD) with different robust aggregation rules. However, the sizeable
SGD-induced stochastic gradient noise makes it challenging to distinguish
malicious messages sent by the Byzantine attackers from noisy stochastic
gradients sent by the 'honest' workers. This motivates us to reduce the
variance of stochastic gradients as a means of robustifying SGD in the presence
of Byzantine attacks. To this end, the present work puts forth a Byzantine
attack resilient distributed (Byrd-) SAGA approach for learning tasks involving
finite-sum optimization over networks. Rather than the mean employed by
distributed SAGA, the novel Byrd- SAGA relies on the geometric median to
aggregate the corrected stochastic gradients sent by the workers. When less
than half of the workers are Byzantine attackers, the robustness of geometric
median to outliers enables Byrd-SAGA to attain provably linear convergence to a
neighborhood of the optimal solution, with the asymptotic learning error
determined by the number of Byzantine workers. Numerical tests corroborate the
robustness to various Byzantine attacks, as well as the merits of Byrd- SAGA
over Byzantine attack resilient distributed SGD.
</p>
<a href="http://arxiv.org/abs/1912.12716" target="_blank">arXiv:1912.12716</a> [<a href="http://arxiv.org/pdf/1912.12716" target="_blank">pdf</a>]

<h2>Exploiting Database Management Systems and Treewidth for Counting. (arXiv:2001.04191v2 [cs.AI] UPDATED)</h2>
<h3>Johannes K. Fichte, Markus Hecher, Patrick Thier, Stefan Woltran</h3>
<p>Bounded treewidth is one of the most cited combinatorial invariants, which
was applied in the literature for solving several counting problems
efficiently. A canonical counting problem is #SAT, which asks to count the
satisfying assignments of a Boolean formula. Recent work shows that
benchmarking instances for #SAT often have reasonably small treewidth. This
paper deals with counting problems for instances of small treewidth. We
introduce a general framework to solve counting questions based on
state-of-the-art database management systems (DBMS). Our framework takes
explicitly advantage of small treewidth by solving instances using dynamic
programming (DP) on tree decompositions (TD). Therefore, we implement the
concept of DP into a DBMS (PostgreSQL), since DP algorithms are already often
given in terms of table manipulations in theory. This allows for elegant
specifications of DP algorithms and the use of SQL to manipulate records and
tables, which gives us a natural approach to bring DP algorithms into practice.
To the best of our knowledge, we present the first approach to employ a DBMS
for algorithms on TDs. A key advantage of our approach is that DBMS naturally
allow to deal with huge tables with a limited amount of main memory (RAM),
parallelization, as well as suspending computation.
</p>
<a href="http://arxiv.org/abs/2001.04191" target="_blank">arXiv:2001.04191</a> [<a href="http://arxiv.org/pdf/2001.04191" target="_blank">pdf</a>]

<h2>SPACE: Structured Compression and Sharing of Representational Space for Continual Learning. (arXiv:2001.08650v4 [cs.LG] UPDATED)</h2>
<h3>Gobinda Saha, Isha Garg, Aayush Ankit, Kaushik Roy</h3>
<p>Humans learn adaptively and efficiently throughout their lives. However,
incrementally learning tasks causes artificial neural networks to overwrite
relevant information learned about older tasks, resulting in 'Catastrophic
Forgetting'. Efforts to overcome this phenomenon often utilize resources
poorly, for instance, by growing the network architecture or needing to save
parametric importance scores, or violate data privacy between tasks. To tackle
this, we propose SPACE, an algorithm that enables a network to learn
continually and efficiently by partitioning the learnt space into a Core space,
that serves as the condensed knowledge base over previously learned tasks, and
a Residual space, which is akin to a scratch space for learning the current
task. After learning each task, the Residual is analyzed for redundancy, both
within itself and with the learnt Core space. A minimal number of extra
dimensions required to explain the current task are added to the Core space and
the remaining Residual is freed up for learning the next task. We evaluate our
algorithm on P-MNIST, CIFAR and a sequence of 8 different datasets, and achieve
comparable accuracy to the state-of-the-art methods while overcoming
catastrophic forgetting. Additionally, our algorithm is well suited for
practical use. The partitioning algorithm analyzes all layers in one shot,
ensuring scalability to deeper networks. Moreover, the analysis of dimensions
translates to filter-level sparsity, and the structured nature of the resulting
architecture gives us up to 5x improvement in energy efficiency during task
inference over the current state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2001.08650" target="_blank">arXiv:2001.08650</a> [<a href="http://arxiv.org/pdf/2001.08650" target="_blank">pdf</a>]

<h2>Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders. (arXiv:2004.02596v3 [cs.AI] UPDATED)</h2>
<h3>Bhushan Kotnis, Carolin Lawrence, Mathias Niepert</h3>
<p>Representation learning for knowledge graphs (KGs) has focused on the problem
of answering simple link prediction queries. In this work we address the more
ambitious challenge of predicting the answers of conjunctive queries with
multiple missing entities. We propose Bi-Directional Query Embedding (BIQE), a
method that embeds conjunctive queries with models based on bi-directional
attention mechanisms. Contrary to prior work, bidirectional self-attention can
capture interactions among all the elements of a query graph. We introduce a
new dataset for predicting the answer of conjunctive query and conduct
experiments that show BIQE significantly outperforming state of the art
baselines.
</p>
<a href="http://arxiv.org/abs/2004.02596" target="_blank">arXiv:2004.02596</a> [<a href="http://arxiv.org/pdf/2004.02596" target="_blank">pdf</a>]

<h2>Sub-Image Anomaly Detection with Deep Pyramid Correspondences. (arXiv:2005.02357v3 [cs.CV] UPDATED)</h2>
<h3>Niv Cohen, Yedid Hoshen</h3>
<p>Nearest neighbor (kNN) methods utilizing deep pre-trained features exhibit
very strong anomaly detection performance when applied to entire images. A
limitation of kNN methods is the lack of segmentation map describing where the
anomaly lies inside the image. In this work we present a novel anomaly
segmentation approach based on alignment between an anomalous image and a
constant number of the similar normal images. Our method, Semantic Pyramid
Anomaly Detection (SPADE) uses correspondences based on a multi-resolution
feature pyramid. SPADE is shown to achieve state-of-the-art performance on
unsupervised anomaly detection and localization while requiring virtually no
training time.
</p>
<a href="http://arxiv.org/abs/2005.02357" target="_blank">arXiv:2005.02357</a> [<a href="http://arxiv.org/pdf/2005.02357" target="_blank">pdf</a>]

<h2>Continual General Chunking Problem and SyncMap. (arXiv:2006.07853v3 [cs.AI] UPDATED)</h2>
<h3>Danilo Vasconcellos Vargas, Toshitake Asabuki</h3>
<p>Humans possess an inherent ability to chunk sequences into their constituent
parts. In fact, this ability is thought to bootstrap language skills and
learning of image patterns which might be a key to a more animal-like type of
intelligence. Here, we propose a continual generalization of the chunking
problem (an unsupervised problem), encompassing fixed and probabilistic chunks,
discovery of temporal and causal structures and their continual variations.
Additionally, we propose an algorithm called SyncMap that can learn and adapt
to changes in the problem by creating a dynamic map which preserves the
correlation between variables. Results of SyncMap suggest that the proposed
algorithm learn near optimal solutions, despite the presence of many types of
structures and their continual variation. When compared to Word2vec, PARSER and
MRIL, SyncMap surpasses or ties with the best algorithm on $66\%$ of the
scenarios while being the second best in the remaining $34\%$. SyncMap's
model-free simple dynamics and the absence of loss functions reveal that,
perhaps surprisingly, much can be done with self-organization alone.
</p>
<a href="http://arxiv.org/abs/2006.07853" target="_blank">arXiv:2006.07853</a> [<a href="http://arxiv.org/pdf/2006.07853" target="_blank">pdf</a>]

<h2>Time Series Extrinsic Regression. (arXiv:2006.12672v3 [cs.LG] UPDATED)</h2>
<h3>Chang Wei Tan, Christoph Bergmeir, Francois Petitjean, Geoffrey I. Webb</h3>
<p>This paper studies Time Series Extrinsic Regression (TSER): a regression task
of which the aim is to learn the relationship between a time series and a
continuous scalar variable; a task closely related to time series
classification (TSC), which aims to learn the relationship between a time
series and a categorical class label. This task generalizes time series
forecasting (TSF), relaxing the requirement that the value predicted be a
future value of the input series or primarily depend on more recent values.

In this paper, we motivate and study this task, and benchmark existing
solutions and adaptations of TSC algorithms on a novel archive of 19 TSER
datasets which we have assembled. Our results show that the state-of-the-art
TSC algorithm Rocket, when adapted for regression, achieves the highest overall
accuracy compared to adaptations of other TSC algorithms and state-of-the-art
machine learning (ML) algorithms such as XGBoost, Random Forest and Support
Vector Regression. More importantly, we show that much research is needed in
this field to improve the accuracy of ML models. We also find evidence that
further research has excellent prospects of improving upon these
straightforward baselines.
</p>
<a href="http://arxiv.org/abs/2006.12672" target="_blank">arXiv:2006.12672</a> [<a href="http://arxiv.org/pdf/2006.12672" target="_blank">pdf</a>]

<h2>ContraGAN: Contrastive Learning for Conditional Image Generation. (arXiv:2006.12681v3 [cs.CV] UPDATED)</h2>
<h3>Minguk Kang, Jaesik Park</h3>
<p>Conditional image generation is the task of generating diverse images using
class label information. Although many conditional Generative Adversarial
Networks (GAN) have shown realistic results, such methods consider pairwise
relations between the embedding of an image and the embedding of the
corresponding label (data-to-class relations) as the conditioning losses. In
this paper, we propose ContraGAN that considers relations between multiple
image embeddings in the same batch (data-to-data relations) as well as the
data-to-class relations by using a conditional contrastive loss. The
discriminator of ContraGAN discriminates the authenticity of given samples and
minimizes a contrastive objective to learn the relations between training
images. Simultaneously, the generator tries to generate realistic images that
deceive the authenticity and have a low contrastive loss. The experimental
results show that ContraGAN outperforms state-of-the-art-models by 7.3% and
7.7% on Tiny ImageNet and ImageNet datasets, respectively. Besides, we
experimentally demonstrate that contrastive learning helps to relieve the
overfitting of the discriminator. For a fair comparison, we re-implement twelve
state-of-the-art GANs using the PyTorch library. The software package is
available at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN.
</p>
<a href="http://arxiv.org/abs/2006.12681" target="_blank">arXiv:2006.12681</a> [<a href="http://arxiv.org/pdf/2006.12681" target="_blank">pdf</a>]

<h2>Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning. (arXiv:2006.12777v3 [cs.LG] UPDATED)</h2>
<h3>A. Tuan Nguyen, Hyewon Jeong, Eunho Yang, Sung Ju Hwang</h3>
<p>Although recent multi-task learning methods have shown to be effective in
improving the generalization of deep neural networks, they should be used with
caution for safety-critical applications, such as clinical risk prediction.
This is because even if they achieve improved task-average performance, they
may still yield degraded performance on individual tasks, which may be critical
(e.g., prediction of mortality risk). Existing asymmetric multi-task learning
methods tackle this negative transfer problem by performing knowledge transfer
from tasks with low loss to tasks with high loss. However, using loss as a
measure of reliability is risky since it could be a result of overfitting. In
the case of time-series prediction tasks, knowledge learned for one task (e.g.,
predicting the sepsis onset) at a specific timestep may be useful for learning
another task (e.g., prediction of mortality) at a later timestep, but lack of
loss at each timestep makes it difficult to measure the reliability at each
timestep. To capture such dynamically changing asymmetric relationships between
tasks in time-series data, we propose a novel temporal asymmetric multi-task
learning model that performs knowledge transfer from certain tasks/timesteps to
relevant uncertain tasks, based on feature-level uncertainty. We validate our
model on multiple clinical risk prediction tasks against various deep learning
models for time-series prediction, which our model significantly outperforms,
without any sign of negative transfer. Further qualitative analysis of learned
knowledge graphs by clinicians shows that they are helpful in analyzing the
predictions of the model. Our final code is available at
https://github.com/anhtuan5696/TPAMTL.
</p>
<a href="http://arxiv.org/abs/2006.12777" target="_blank">arXiv:2006.12777</a> [<a href="http://arxiv.org/pdf/2006.12777" target="_blank">pdf</a>]

<h2>Compositional Explanations of Neurons. (arXiv:2006.14032v2 [cs.LG] UPDATED)</h2>
<h3>Jesse Mu, Jacob Andreas</h3>
<p>We describe a procedure for explaining neurons in deep representations by
identifying compositional logical concepts that closely approximate neuron
behavior. Compared to prior work that uses atomic labels as explanations,
analyzing neurons compositionally allows us to more precisely and expressively
characterize their behavior. We use this procedure to answer several questions
on interpretability in models for vision and natural language processing.
First, we examine the kinds of abstractions learned by neurons. In image
classification, we find that many neurons learn highly abstract but
semantically coherent visual concepts, while other polysemantic neurons detect
multiple unrelated features; in natural language inference (NLI), neurons learn
shallow lexical heuristics from dataset biases. Second, we see whether
compositional explanations give us insight into model performance: vision
neurons that detect human-interpretable concepts are positively correlated with
task performance, while NLI neurons that fire for shallow heuristics are
negatively correlated with task performance. Finally, we show how compositional
explanations provide an accessible way for end users to produce simple
"copy-paste" adversarial examples that change model behavior in predictable
ways.
</p>
<a href="http://arxiv.org/abs/2006.14032" target="_blank">arXiv:2006.14032</a> [<a href="http://arxiv.org/pdf/2006.14032" target="_blank">pdf</a>]

<h2>Hallucinating Saliency Maps for Fine-Grained Image Classification for Limited Data Domains. (arXiv:2007.12562v3 [cs.CV] UPDATED)</h2>
<h3>Carola Figueroa-Flores, Bogdan Raducanu, David Berga, Joost van de Weijer</h3>
<p>Most of the saliency methods are evaluated on their ability to generate
saliency maps, and not on their functionality in a complete vision pipeline,
like for instance, image classification. In the current paper, we propose an
approach which does not require explicit saliency maps to improve image
classification, but they are learned implicitely, during the training of an
end-to-end image classification task. We show that our approach obtains similar
results as the case when the saliency maps are provided explicitely. Combining
RGB data with saliency maps represents a significant advantage for object
recognition, especially for the case when training data is limited. We validate
our method on several datasets for fine-grained classification tasks (Flowers,
Birds and Cars). In addition, we show that our saliency estimation method,
which is trained without any saliency groundtruth data, obtains competitive
results on real image saliency benchmark (Toronto), and outperforms deep
saliency models with synthetic images (SID4VAM).
</p>
<a href="http://arxiv.org/abs/2007.12562" target="_blank">arXiv:2007.12562</a> [<a href="http://arxiv.org/pdf/2007.12562" target="_blank">pdf</a>]

<h2>Privacy Enhancing Machine Learning via Removal of Unwanted Dependencies. (arXiv:2007.15710v3 [cs.LG] UPDATED)</h2>
<h3>Mert Al, Semih Yagli, Sun-Yuan Kung</h3>
<p>The rapid rise of IoT and Big Data has facilitated copious data driven
applications to enhance our quality of life. However, the omnipresent and
all-encompassing nature of the data collection can generate privacy concerns.
Hence, there is a strong need to develop techniques that ensure the data serve
only the intended purposes, giving users control over the information they
share. To this end, this paper studies new variants of supervised and
adversarial learning methods, which remove the sensitive information in the
data before they are sent out for a particular application. The explored
methods optimize privacy preserving feature mappings and predictive models
simultaneously in an end-to-end fashion. Additionally, the models are built
with an emphasis on placing little computational burden on the user side so
that the data can be desensitized on device in a cheap manner. Experimental
results on mobile sensing and face datasets demonstrate that our models can
successfully maintain the utility performances of predictive models while
causing sensitive predictions to perform poorly.
</p>
<a href="http://arxiv.org/abs/2007.15710" target="_blank">arXiv:2007.15710</a> [<a href="http://arxiv.org/pdf/2007.15710" target="_blank">pdf</a>]

<h2>A Technique for Determining Relevance Scores of Process Activities using Graph-based Neural Networks. (arXiv:2008.03110v2 [cs.LG] UPDATED)</h2>
<h3>Matthias Stierle, Sven Weinzierl, Maximilian Harl, Martin Matzner</h3>
<p>Process models generated through process mining depict the as-is state of a
process. Through annotations with metrics such as the frequency or duration of
activities, these models provide generic information to the process analyst. To
improve business processes with respect to performance measures, process
analysts require further guidance from the process model. In this study, we
design Graph Relevance Miner (GRM), a technique based on graph neural networks,
to determine the relevance scores for process activities with respect to
performance measures. Annotating process models with such relevance scores
facilitates a problem-focused analysis of the business process, placing these
problems at the centre of the analysis. We quantitatively evaluate the
predictive quality of our technique using four datasets from different domains,
to demonstrate the faithfulness of the relevance scores. Furthermore, we
present the results of a case study, which highlight the utility of the
technique for organisations. Our work has important implications both for
research and business applications, because process model-based analyses
feature shortcomings that need to be urgently addressed to realise successful
process mining at an enterprise level.
</p>
<a href="http://arxiv.org/abs/2008.03110" target="_blank">arXiv:2008.03110</a> [<a href="http://arxiv.org/pdf/2008.03110" target="_blank">pdf</a>]

<h2>Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition. (arXiv:2009.04724v3 [cs.CV] UPDATED)</h2>
<h3>Siteng Huang, Min Zhang, Yachen Kang, Donglin Wang</h3>
<p>The purpose of few-shot recognition is to recognize novel categories with a
limited number of labeled examples in each class. To encourage learning from a
supplementary view, recent approaches have introduced auxiliary semantic
modalities into effective metric-learning frameworks that aim to learn a
feature similarity between training samples (support set) and test samples
(query set). However, these approaches only augment the representations of
samples with available semantics while ignoring the query set, which loses the
potential for the improvement and may lead to a shift between the modalities
combination and the pure-visual representation. In this paper, we devise an
attributes-guided attention module (AGAM) to utilize human-annotated attributes
and learn more discriminative features. This plug-and-play module enables
visual contents and corresponding attributes to collectively focus on important
channels and regions for the support set. And the feature selection is also
achieved for query set with only visual information while the attributes are
not available. Therefore, representations from both sets are improved in a
fine-grained manner. Moreover, an attention alignment mechanism is proposed to
distill knowledge from the guidance of attributes to the pure-visual branch for
samples without attributes. Extensive experiments and analysis show that our
proposed module can significantly improve simple metric-based approaches to
achieve state-of-the-art performance on different datasets and settings.
</p>
<a href="http://arxiv.org/abs/2009.04724" target="_blank">arXiv:2009.04724</a> [<a href="http://arxiv.org/pdf/2009.04724" target="_blank">pdf</a>]

<h2>Massively Parallel and Asynchronous Tsetlin Machine Architecture Supporting Almost Constant-Time Scaling. (arXiv:2009.04861v3 [cs.AI] UPDATED)</h2>
<h3>K. Darshana Abeyrathna, Bimal Bhattarai, Morten Goodwin, Saeed Gorji, Ole-Christoffer Granmo, Lei Jiao, Rupsa Saha, Rohan K. Yadav</h3>
<p>Using logical clauses to represent patterns, Tsetlin Machines (TMs) have
recently obtained competitive performance in terms of accuracy, memory
footprint, energy, and learning speed on several benchmarks. Each TM clause
votes for or against a particular class, with classification resolved using a
majority vote. While the evaluation of clauses is fast, being based on binary
operators, the voting makes it necessary to synchronize the clause evaluation,
impeding parallelization. In this paper, we propose a novel scheme for
desynchronizing the evaluation of clauses, eliminating the voting bottleneck.
In brief, every clause runs in its own thread for massive native parallelism.
For each training example, we keep track of the class votes obtained from the
clauses in local voting tallies. The local voting tallies allow us to detach
the processing of each clause from the rest of the clauses, supporting
decentralized learning. This means that the TM most of the time will operate on
outdated voting tallies. We evaluated the proposed parallelization across
diverse learning tasks and it turns out that our decentralized TM learning
algorithm copes well with working on outdated data, resulting in no significant
loss in learning accuracy. Furthermore, we show that the proposed approach
provides up to 50 times faster learning. Finally, learning time is almost
constant for reasonable clause amounts (employing from 20 to 7000 clauses on a
Tesla V100 GPU). For sufficiently large clause numbers, computation time
increases approximately proportionally. Our parallel and asynchronous
architecture thus allows processing of massive datasets and operating with more
clauses for higher accuracy.
</p>
<a href="http://arxiv.org/abs/2009.04861" target="_blank">arXiv:2009.04861</a> [<a href="http://arxiv.org/pdf/2009.04861" target="_blank">pdf</a>]

<h2>Evaluating and Mitigating Bias in Image Classifiers: A Causal Perspective Using Counterfactuals. (arXiv:2009.08270v3 [cs.CV] UPDATED)</h2>
<h3>Saloni Dash, Vineeth N Balasubramanian, Amit Sharma</h3>
<p>Recent studies have reported biases in machine learning image classifiers,
especially against particular demographic groups. Counterfactual examples for
an input -- perturbations that change specific features but not others -- have
been shown to be useful for evaluating explainability and fairness of machine
learning models. However, generating counterfactual examples for images is
non-trivial due to the underlying causal structure governing the various
features of an image. To be meaningful, generated perturbations need to satisfy
constraints implied by the causal model. We present a method for generating
counterfactuals by incorporating a structural causal model (SCM) in a novel
improved variant of Adversarially Learned Inference (ALI), that generates
counterfactuals in accordance with the causal relationships between different
attributes of an image. Based on the generated counterfactuals, we show how to
evaluate bias and explain a pre-trained machine learning classifier. We also
propose a counterfactual regularizer that can mitigate bias in the classifier.
On the Morpho-MNIST dataset, our method generates counterfactuals comparable in
quality to prior work on SCM-based counterfactuals. Our method also works on
the more complex CelebA faces dataset; generated counterfactuals are
indistinguishable from original images in a human evaluation experiment. As a
downstream task, we use counterfactuals to evaluate a standard classifier
trained on CelebA data and show that it is biased w.r.t. skin and hair color,
and show how counterfactual regularization can be used to remove the identified
biases.
</p>
<a href="http://arxiv.org/abs/2009.08270" target="_blank">arXiv:2009.08270</a> [<a href="http://arxiv.org/pdf/2009.08270" target="_blank">pdf</a>]

<h2>Interpreting and Boosting Dropout from a Game-Theoretic View. (arXiv:2009.11729v3 [cs.LG] UPDATED)</h2>
<h3>Hao Zhang, Sen Li, Yinchao Ma, Mingjie Li, Yichen Xie, Quanshi Zhang</h3>
<p>This paper aims to understand and improve the utility of the dropout
operation from the perspective of game-theoretic interactions. We prove that
dropout can suppress the strength of interactions between input variables of
deep neural networks (DNNs). The theoretic proof is also verified by various
experiments. Furthermore, we find that such interactions were strongly related
to the over-fitting problem in deep learning. Thus, the utility of dropout can
be regarded as decreasing interactions to alleviate the significance of
over-fitting. Based on this understanding, we propose an interaction loss to
further improve the utility of dropout. Experimental results have shown that
the interaction loss can effectively improve the utility of dropout and boost
the performance of DNNs.
</p>
<a href="http://arxiv.org/abs/2009.11729" target="_blank">arXiv:2009.11729</a> [<a href="http://arxiv.org/pdf/2009.11729" target="_blank">pdf</a>]

<h2>Position-Based Multiple-Play Bandits with Thompson Sampling. (arXiv:2009.13181v2 [cs.LG] UPDATED)</h2>
<h3>Camille-Sovanneary Gauthier, Romaric Gaudel, Elisa Fromont</h3>
<p>Multiple-play bandits aim at displaying relevant items at relevant positions
on a web page. We introduce a new bandit-based algorithm, PB-MHB, for online
recommender systems which uses the Thompson sampling framework. This algorithm
handles a display setting governed by the position-based model. Our sampling
method does not require as input the probability of a user to look at a given
position in the web page which is, in practice, very difficult to obtain.
Experiments on simulated and real datasets show that our method, with fewer
prior information, deliver better recommendations than state-of-the-art
algorithms.
</p>
<a href="http://arxiv.org/abs/2009.13181" target="_blank">arXiv:2009.13181</a> [<a href="http://arxiv.org/pdf/2009.13181" target="_blank">pdf</a>]

<h2>Interpreting Multivariate Shapley Interactions in DNNs. (arXiv:2010.05045v4 [cs.LG] UPDATED)</h2>
<h3>Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, Quanshi Zhang</h3>
<p>This paper aims to explain deep neural networks (DNNs) from the perspective
of multivariate interactions. In this paper, we define and quantify the
significance of interactions among multiple input variables of the DNN. Input
variables with strong interactions usually form a coalition and reflect
prototype features, which are memorized and used by the DNN for inference. We
define the significance of interactions based on the Shapley value, which is
designed to assign the attribution value of each input variable to the
inference. We have conducted experiments with various DNNs. Experimental
results have demonstrated the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2010.05045" target="_blank">arXiv:2010.05045</a> [<a href="http://arxiv.org/pdf/2010.05045" target="_blank">pdf</a>]

<h2>NEO: A Novel Expeditious Optimisation Algorithm for Reactive Motion Control of Manipulators. (arXiv:2010.08686v2 [cs.RO] UPDATED)</h2>
<h3>Jesse Haviland, Peter Corke</h3>
<p>We present NEO, a fast and purely reactive motion controller for manipulators
which can avoid static and dynamic obstacles while moving to the desired
end-effector pose. Additionally, our controller maximises the manipulability of
the robot during the trajectory, while avoiding joint position and velocity
limits. NEO is wrapped into a strictly convex quadratic programme which, when
considering obstacles, joint limits, and manipulability on a 7
degree-of-freedom robot, is generally solved in a few ms. While NEO is not
intended to replace state-of-the-art motion planners, our experiments show that
it is a viable alternative for scenes with moderate complexity while also being
capable of reactive control. For more complex scenes, NEO is better suited as a
reactive local controller, in conjunction with a global motion planner. We
compare NEO to motion planners on a standard benchmark in simulation and
additionally illustrate and verify its operation on a physical robot in a
dynamic environment. We provide an open-source library which implements our
controller.
</p>
<a href="http://arxiv.org/abs/2010.08686" target="_blank">arXiv:2010.08686</a> [<a href="http://arxiv.org/pdf/2010.08686" target="_blank">pdf</a>]

<h2>TAMPC: A Controller for Escaping Traps in Novel Environments. (arXiv:2010.12516v3 [cs.RO] UPDATED)</h2>
<h3>Sheng Zhong (1), Zhenyuan Zhang (1), Nima Fazeli (1), Dmitry Berenson (1) ((1) Robotics Institute, University of Michigan)</h3>
<p>We propose an approach to online model adaptation and control in the
challenging case of hybrid and discontinuous dynamics where actions may lead to
difficult-to-escape "trap" states, under a given controller. We first learn
dynamics for a system without traps from a randomly collected training set
(since we do not know what traps will be encountered online). These "nominal"
dynamics allow us to perform tasks in scenarios where the dynamics matches the
training data, but when unexpected traps arise in execution, we must find a way
to adapt our dynamics and control strategy and continue attempting the task.
Our approach, Trap-Aware Model Predictive Control (TAMPC), is a two-level
hierarchical control algorithm that reasons about traps and non-nominal
dynamics to decide between goal-seeking and recovery policies. An important
requirement of our method is the ability to recognize nominal dynamics even
when we encounter data that is out-of-distribution w.r.t the training data. We
achieve this by learning a representation for dynamics that exploits invariance
in the nominal environment, thus allowing better generalization. We evaluate
our method on simulated planar pushing and peg-in-hole as well as real robot
peg-in-hole problems against adaptive control, reinforcement learning,
trap-handling baselines, where traps arise due to unexpected obstacles that we
only observe through contact. Our results show that our method outperforms the
baselines on difficult tasks, and is comparable to prior trap-handling methods
on easier tasks.
</p>
<a href="http://arxiv.org/abs/2010.12516" target="_blank">arXiv:2010.12516</a> [<a href="http://arxiv.org/pdf/2010.12516" target="_blank">pdf</a>]

<h2>Technical Note: Game-Theoretic Interactions of Different Orders. (arXiv:2010.14978v2 [cs.LG] UPDATED)</h2>
<h3>Hao Zhang, Xu Cheng, Yiting Chen, Quanshi Zhang</h3>
<p>In this study, we define interaction components of different orders between
two input variables based on game theory. We further prove that interaction
components of different orders satisfy several desirable properties.
</p>
<a href="http://arxiv.org/abs/2010.14978" target="_blank">arXiv:2010.14978</a> [<a href="http://arxiv.org/pdf/2010.14978" target="_blank">pdf</a>]

<h2>Towards Unifying Feature Attribution and Counterfactual Explanations: Different Means to the Same End. (arXiv:2011.04917v2 [cs.LG] UPDATED)</h2>
<h3>Ramaravind K. Mothilal, Divyat Mahajan, Chenhao Tan, Amit Sharma</h3>
<p>To explain a machine learning model, there are two main approaches: feature
attributions that assign an importance score to each input feature, and
counterfactual explanations that provide input examples with minimal changes to
alter the model's prediction. To unify these approaches, we provide an
interpretation based on the actual causality framework and present two key
results in terms of their use. First, we present a method to generate feature
attribution explanations from a set of counterfactual examples. These feature
attributions convey how important a feature is to changing the classification
outcome of a model, especially on whether a subset of features is necessary
and/or sufficient for that change, which feature attribution methods are unable
to provide. Second, we show how counterfactual examples can be used to evaluate
the goodness of an attribution-based explanation in terms of its necessity and
sufficiency. As a result, we highlight the complementarity of these two
approaches. Our evaluation on three benchmark datasets -- Adult-Income,
LendingClub, and German-Credit -- confirms the complementarity. Feature
attribution methods like LIME and SHAP and counterfactual explanation methods
like Wachter et al. and DiCE often do not agree on feature importance rankings.
In addition, by restricting the features that can be modified for generating
counterfactual examples, we find that the top-k features from LIME or SHAP are
often neither necessary nor sufficient explanations of a model's prediction.
Finally, we present a case study of different explanation methods on a
real-world hospital triage problem.
</p>
<a href="http://arxiv.org/abs/2011.04917" target="_blank">arXiv:2011.04917</a> [<a href="http://arxiv.org/pdf/2011.04917" target="_blank">pdf</a>]

<h2>Continuum Limit of Lipschitz Learning on Graphs. (arXiv:2012.03772v2 [cs.LG] UPDATED)</h2>
<h3>Tim Roith, Leon Bungert</h3>
<p>Tackling semi-supervised learning problems with graph-based methods have
become a trend in recent years since graphs can represent all kinds of data and
provide a suitable framework for studying continuum limits, e.g., of
differential operators. A popular strategy here is $p$-Laplacian learning,
which poses a smoothness condition on the sought inference function on the set
of unlabeled data. For $p&lt;\infty$ continuum limits of this approach were
studied using tools from $\Gamma$-convergence. For the case $p=\infty$, which
is referred to as Lipschitz learning, continuum limits of the related
infinity-Laplacian equation were studied using the concept of viscosity
solutions.

In this work, we prove continuum limits of Lipschitz learning using
$\Gamma$-convergence. In particular, we define a sequence of functionals which
approximate the largest local Lipschitz constant of a graph function and prove
$\Gamma$-convergence in the $L^\infty$-topology to the supremum norm of the
gradient as the graph becomes denser. Furthermore, we show compactness of the
functionals which implies convergence of minimizers. In our analysis we allow a
varying set of labeled data which converges to a general closed set in the
Hausdorff distance. We apply our results to nonlinear ground states and, as a
by-product, prove convergence of graph distance functions to geodesic distance
functions.
</p>
<a href="http://arxiv.org/abs/2012.03772" target="_blank">arXiv:2012.03772</a> [<a href="http://arxiv.org/pdf/2012.03772" target="_blank">pdf</a>]

<h2>On-Road Motion Planning for Automated Vehicles at Ulm University. (arXiv:2012.04028v2 [cs.RO] UPDATED)</h2>
<h3>Maximilian Graf, Oliver Speidel, Jona Ruof, Klaus Dietmayer</h3>
<p>The Institute of Measurement, Control and Microtechnology at Ulm University
investigates advanced driver assistance systems for decades and concentrates in
large parts on autonomous driving. It is well known that motion planning is a
key technology for autonomous driving. It is first and foremost responsible for
the safety of the vehicle passengers as well as of all surrounding traffic
participants. However, a further task consists in providing a smooth and
comfortable driving behavior. In Ulm, we have the grateful opportunity to test
our algorithms under real conditions in public traffic and diversified
scenarios. In this paper, we would like to give the readers an insight of our
work, about the vehicle, the test track, as well as of the related problems,
challenges and solutions. Therefore, we will describe the motion planning
system and explain the implemented functionalities. Furthermore, we will show
how our vehicle moves through public road traffic and how it deals with
challenging scenarios like e.g. driving through roundabouts and intersections.
</p>
<a href="http://arxiv.org/abs/2012.04028" target="_blank">arXiv:2012.04028</a> [<a href="http://arxiv.org/pdf/2012.04028" target="_blank">pdf</a>]

<h2>Analysis and Optimal Edge Assignment For Hierarchical Federated Learning on Non-IID Data. (arXiv:2012.05622v2 [cs.LG] UPDATED)</h2>
<h3>Naram Mhaisen, Alaa Awad, Amr Mohamed, Aiman Erbad, Mohsen Guizani</h3>
<p>Distributed learning algorithms aim to leverage distributed and diverse data
stored at users' devices to learn a global phenomena by performing training
amongst participating devices and periodically aggregating their local models'
parameters into a global model. Federated learning is a promising paradigm that
allows for extending local training among the participant devices before
aggregating the parameters, offering better communication efficiency. However,
in the cases where the participants' data are strongly skewed (i.e., non-IID),
the local models can overfit local data, leading to low performing global
model. In this paper, we first show that a major cause of the performance drop
is the weighted distance between the distribution over classes on users'
devices and the global distribution. Then, to face this challenge, we leverage
the edge computing paradigm to design a hierarchical learning system that
performs Federated Gradient Descent on the user-edge layer and Federated
Averaging on the edge-cloud layer. In this hierarchical architecture, we
formalize and optimize this user-edge assignment problem such that edge-level
data distributions turn to be similar (i.e., close to IID), which enhances the
Federated Averaging performance. Our experiments on multiple real-world
datasets show that the proposed optimized assignment is tractable and leads to
faster convergence of models towards a better accuracy value.
</p>
<a href="http://arxiv.org/abs/2012.05622" target="_blank">arXiv:2012.05622</a> [<a href="http://arxiv.org/pdf/2012.05622" target="_blank">pdf</a>]

<h2>Optimistic and Adaptive Lagrangian Hedging. (arXiv:2101.09603v2 [cs.LG] UPDATED)</h2>
<h3>Ryan D&#x27;Orazio, Ruitong Huang</h3>
<p>In online learning an algorithm plays against an environment with losses
possibly picked by an adversary at each round. The generality of this framework
includes problems that are not adversarial, for example offline optimization,
or saddle point problems (i.e. min max optimization). However, online
algorithms are typically not designed to leverage additional structure present
in non-adversarial problems. Recently, slight modifications to well-known
online algorithms such as optimism and adaptive step sizes have been used in
several domains to accelerate online learning -- recovering optimal rates in
offline smooth optimization, and accelerating convergence to saddle points or
social welfare in smooth games. In this work we introduce optimism and adaptive
stepsizes to Lagrangian hedging, a class of online algorithms that includes
regret-matching, and hedge (i.e. multiplicative weights). Our results include:
a general general regret bound; a path length regret bound for a fixed smooth
loss, applicable to an optimistic variant of regret-matching and
regret-matching+; optimistic regret bounds for $\Phi$ regret, a framework that
includes external, internal, and swap regret; and optimistic bounds for a
family of algorithms that includes regret-matching+ as a special case.
</p>
<a href="http://arxiv.org/abs/2101.09603" target="_blank">arXiv:2101.09603</a> [<a href="http://arxiv.org/pdf/2101.09603" target="_blank">pdf</a>]

<h2>AdderNet and its Minimalist Hardware Design for Energy-Efficient Artificial Intelligence. (arXiv:2101.10015v2 [cs.LG] UPDATED)</h2>
<h3>Yunhe Wang, Mingqiang Huang, Kai Han, Hanting Chen, Wei Zhang, Chunjing Xu, Dacheng Tao</h3>
<p>Convolutional neural networks (CNN) have been widely used for boosting the
performance of many machine intelligence tasks. However, the CNN models are
usually computationally intensive and energy consuming, since they are often
designed with numerous multiply-operations and considerable parameters for the
accuracy reason. Thus, it is difficult to directly apply them in the
resource-constrained environments such as 'Internet of Things' (IoT) devices
and smart phones. To reduce the computational complexity and energy burden,
here we present a novel minimalist hardware architecture using adder
convolutional neural network (AdderNet), in which the original convolution is
replaced by adder kernel using only additions. To maximally excavate the
potential energy consumption, we explore the low-bit quantization algorithm for
AdderNet with shared-scaling-factor method, and we design both specific and
general-purpose hardware accelerators for AdderNet. Experimental results show
that the adder kernel with int8/int16 quantization also exhibits high
performance, meanwhile consuming much less resources (theoretically ~81% off).
In addition, we deploy the quantized AdderNet on FPGA (Field Programmable Gate
Array) platform. The whole AdderNet can practically achieve 16% enhancement in
speed, 67.6%-71.4% decrease in logic resource utilization and 47.85%-77.9%
decrease in power consumption compared to CNN under the same circuit
architecture. With a comprehensive comparison on the performance, power
consumption, hardware resource consumption and network generalization
capability, we conclude the AdderNet is able to surpass all the other
competitors including the classical CNN, novel memristor-network, XNOR-Net and
the shift-kernel based network, indicating its great potential in future high
performance and energy-efficient artificial intelligence applications.
</p>
<a href="http://arxiv.org/abs/2101.10015" target="_blank">arXiv:2101.10015</a> [<a href="http://arxiv.org/pdf/2101.10015" target="_blank">pdf</a>]

<h2>Deep Image Retrieval: A Survey. (arXiv:2101.11282v2 [cs.CV] UPDATED)</h2>
<h3>Wei Chen, Yu Liu, Weiping Wang, Erwin Bakker, Theodoros Georgiou, Paul Fieguth, Li Liu, Michael S. Lew</h3>
<p>In recent years a vast amount of visual content has been generated and shared
from various fields, such as social media platforms, medical images, and
robotics. This abundance of content creation and sharing has introduced new
challenges. In particular, searching databases for similar content, i.e.content
based image retrieval (CBIR), is a long-established research area, and more
efficient and accurate methods are needed for real time retrieval. Artificial
intelligence has made progress in CBIR and has significantly facilitated the
process of intelligent search. In this survey we organize and review recent
CBIR works that are developed based on deep learning algorithms and techniques,
including insights and techniques from recent papers. We identify and present
the commonly-used benchmarks and evaluation methods used in the field. We
collect common challenges and propose promising future directions. More
specifically, we focus on image retrieval with deep learning and organize the
state of the art methods according to the types of deep network structure, deep
features, feature enhancement methods, and network fine-tuning strategies. Our
survey considers a wide variety of recent methods, aiming to promote a global
view of the field of instance-based CBIR.
</p>
<a href="http://arxiv.org/abs/2101.11282" target="_blank">arXiv:2101.11282</a> [<a href="http://arxiv.org/pdf/2101.11282" target="_blank">pdf</a>]

<h2>Open World Compositional Zero-Shot Learning. (arXiv:2101.12609v2 [cs.CV] UPDATED)</h2>
<h3>Massimiliano Mancini, Muhammad Ferjad Naeem, Yongqin Xian, Zeynep Akata</h3>
<p>Compositional Zero-Shot learning (CZSL) requires to recognize state-object
compositions unseen during training. In this work, instead of assuming the
presence of prior knowledge about the unseen compositions, we operate on the
open world setting, where the search space includes a large number of unseen
compositions some of which might be unfeasible. In this setting, we start from
the cosine similarity between visual features and compositional embeddings.
After estimating the feasibility score of each composition, we use these scores
to either directly mask the output space or as a margin for the cosine
similarity between visual features and compositional embeddings during
training. Our experiments on two standard CZSL benchmarks show that all the
methods suffer severe performance degradation when applied in the open world
setting. While our simple CZSL model achieves state-of-the-art performances in
the closed world scenario, our feasibility scores boost the performance of our
approach in the open world setting, clearly outperforming the previous state of
the art.
</p>
<a href="http://arxiv.org/abs/2101.12609" target="_blank">arXiv:2101.12609</a> [<a href="http://arxiv.org/pdf/2101.12609" target="_blank">pdf</a>]

<h2>Size and Depth Separation in Approximating Natural Functions with Neural Networks. (arXiv:2102.00314v2 [cs.LG] UPDATED)</h2>
<h3>Gal Vardi, Daniel Reichman, Toniann Pitassi, Ohad Shamir</h3>
<p>When studying the expressive power of neural networks, a main challenge is to
understand how the size and depth of the network affect its ability to
approximate real functions. However, not all functions are interesting from a
practical viewpoint: functions of interest usually have a polynomially-bounded
Lipschitz constant, and can be computed efficiently. We call functions that
satisfy these conditions "natural", and explore the benefits of size and depth
for approximation of natural functions with ReLU networks. As we show, this
problem is more challenging than the corresponding problem for non-natural
functions. We give barriers to showing depth-lower-bounds: Proving existence of
a natural function that cannot be approximated by polynomial-size networks of
depth $4$ would settle longstanding open problems in computational complexity.
It implies that beyond depth $4$ there is a barrier to showing depth-separation
for natural functions, even between networks of constant depth and networks of
nonconstant depth. We also study size-separation, namely, whether there are
natural functions that can be approximated with networks of size $O(s(d))$, but
not with networks of size $O(s'(d))$. We show a complexity-theoretic barrier to
proving such results beyond size $O(d\log^2(d))$, but also show an explicit
natural function, that can be approximated with networks of size $O(d)$ and not
with networks of size $o(d/\log d)$. For approximation in $L_\infty$ we achieve
such separation already between size $O(d)$ and size $o(d)$. Moreover, we show
superpolynomial size lower bounds and barriers to such lower bounds, depending
on the assumptions on the function. Our size-separation results rely on an
analysis of size lower bounds for Boolean functions, which is of independent
interest: We show linear size lower bounds for computing explicit Boolean
functions with neural networks and threshold circuits.
</p>
<a href="http://arxiv.org/abs/2102.00314" target="_blank">arXiv:2102.00314</a> [<a href="http://arxiv.org/pdf/2102.00314" target="_blank">pdf</a>]

<h2>M2FN: Multi-step Modality Fusion for Advertisement Image Assessment. (arXiv:2102.00441v3 [cs.CV] UPDATED)</h2>
<h3>Kyung-Wha Park (1), Jung-Woo Ha (2), JungHoon Lee (3), Sunyoung Kwon (4), Kyung-Min Kim (2), Byoung-Tak Zhang (1 and 5 and 6) ((1) Interdisciplinary Program in Neuroscience, Seoul National University., (2) NAVER AI LAB, NAVER CLOVA., (3) Statistics and Actuarial Science, Soongsil University., (4) School of Biomedical Convergence Engineering, Pusan National University., (5) Department of Computer Science and Engineering, Seoul National University., (6) Surromind Robotics.)</h3>
<p>Assessing advertisements, specifically on the basis of user preferences and
ad quality, is crucial to the marketing industry. Although recent studies have
attempted to use deep neural networks for this purpose, these studies have not
utilized image-related auxiliary attributes, which include embedded text
frequently found in ad images. We, therefore, investigated the influence of
these attributes on ad image preferences. First, we analyzed large-scale
real-world ad log data and, based on our findings, proposed a novel multi-step
modality fusion network (M2FN) that determines advertising images likely to
appeal to user preferences. Our method utilizes auxiliary attributes through
multiple steps in the network, which include conditional batch
normalization-based low-level fusion and attention-based high-level fusion. We
verified M2FN on the AVA dataset, which is widely used for aesthetic image
assessment, and then demonstrated that M2FN can achieve state-of-the-art
performance in preference prediction using a real-world ad dataset with rich
auxiliary attributes.
</p>
<a href="http://arxiv.org/abs/2102.00441" target="_blank">arXiv:2102.00441</a> [<a href="http://arxiv.org/pdf/2102.00441" target="_blank">pdf</a>]

<h2>"Grip-that-there": An Investigation of Explicit and Implicit Task Allocation Techniques for Human-Robot Collaboration. (arXiv:2102.00581v2 [cs.RO] UPDATED)</h2>
<h3>Karthik Mahadevan, Maur&#xed;cio Sousa, Anthony Tang, Tovi Grossman</h3>
<p>In ad-hoc human-robot collaboration (HRC), humans and robots work on a task
without pre-planning the robot's actions prior to execution; instead, task
allocation occurs in real-time. However, prior research has largely focused on
task allocations that are pre-planned - there has not been a comprehensive
exploration or evaluation of techniques where task allocation is adjusted in
real-time. Inspired by HCI research on territoriality and proxemics, we propose
a design space of novel task allocation techniques including both explicit
techniques, where the user maintains agency, and implicit techniques, where the
efficiency of automation can be leveraged. The techniques were implemented and
evaluated using a tabletop HRC simulation in VR. A 16-participant study, which
presented variations of a collaborative block stacking task, showed that
implicit techniques enable efficient task completion and task parallelization,
and should be augmented with explicit mechanisms to provide users with
fine-grained control.
</p>
<a href="http://arxiv.org/abs/2102.00581" target="_blank">arXiv:2102.00581</a> [<a href="http://arxiv.org/pdf/2102.00581" target="_blank">pdf</a>]

<h2>Bridging Unpaired Facial Photos And Sketches By Line-drawings. (arXiv:2102.00635v2 [cs.CV] UPDATED)</h2>
<h3>Meimei Shang, Fei Gao, Xiang Li, Jingjie Zhu, Lingna Dai</h3>
<p>In this paper, we propose a novel method to learn face sketch synthesis
models by using unpaired data. Our main idea is bridging the photo domain
$\mathcal{X}$ and the sketch domain $Y$ by using the line-drawing domain
$\mathcal{Z}$. Specially, we map both photos and sketches to line-drawings by
using a neural style transfer method, i.e. $F: \mathcal{X}/\mathcal{Y} \mapsto
\mathcal{Z}$. Consequently, we obtain \textit{pseudo paired data}
$(\mathcal{Z}, \mathcal{Y})$, and can learn the mapping $G:\mathcal{Z} \mapsto
\mathcal{Y}$ in a supervised learning manner. In the inference stage, given a
facial photo, we can first transfer it to a line-drawing and then to a sketch
by $G \circ F$. Additionally, we propose a novel stroke loss for generating
different types of strokes. Our method, termed sRender, accords well with human
artists' rendering process. Experimental results demonstrate that sRender can
generate multi-style sketches, and significantly outperforms existing unpaired
image-to-image translation methods.
</p>
<a href="http://arxiv.org/abs/2102.00635" target="_blank">arXiv:2102.00635</a> [<a href="http://arxiv.org/pdf/2102.00635" target="_blank">pdf</a>]

<h2>A reproducibility study of "Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space". (arXiv:2102.00700v2 [cs.LG] UPDATED)</h2>
<h3>Kevin Maik Jablonka, Fergus Mcilwaine, Susana Garcia, Berend Smit, Brian Yoo</h3>
<p>Nigam et al. reported a genetic algorithm (GA) utilizing the SELFIES
representation and also propose an adaptive, neural network-based penalty that
is supposed to improve the diversity of the generated molecules. The main
claims of the paper are that this GA outperforms other generative techniques
(as measured by the penalized logP) and that a neural network-based adaptive
penalty increases the diversity of the generated molecules. In this work, we
investigated the reproducibility of their claims. Overall, we were able to
reproduce comparable results using the SELFIES-based GA, but mostly by
exploiting deficiencies of the (easily optimizable) fitness function (i.e.,
generating long, sulfur containing chains). In addition, we also reproduce
results showing that the discriminator can be used to bias the generation of
molecules to ones that are similar to the reference set. Moreover, we also
attempted to quantify the evolution of the diversity, understand the influence
of some hyperparameters, and propose improvements to the adaptive penalty.
</p>
<a href="http://arxiv.org/abs/2102.00700" target="_blank">arXiv:2102.00700</a> [<a href="http://arxiv.org/pdf/2102.00700" target="_blank">pdf</a>]

<h2>Semantic Grouping Network for Video Captioning. (arXiv:2102.00831v2 [cs.CV] UPDATED)</h2>
<h3>Hobin Ryu, Sunghun Kang, Haeyong Kang, Chang D. Yoo</h3>
<p>This paper considers a video caption generating network referred to as
Semantic Grouping Network (SGN) that attempts (1) to group video frames with
discriminating word phrases of partially decoded caption and then (2) to decode
those semantically aligned groups in predicting the next word. As consecutive
frames are not likely to provide unique information, prior methods have focused
on discarding or merging repetitive information based only on the input video.
The SGN learns an algorithm to capture the most discriminating word phrases of
the partially decoded caption and a mapping that associates each phrase to the
relevant video frames - establishing this mapping allows semantically related
frames to be clustered, which reduces redundancy. In contrast to the prior
methods, the continuous feedback from decoded words enables the SGN to
dynamically update the video representation that adapts to the partially
decoded caption. Furthermore, a contrastive attention loss is proposed to
facilitate accurate alignment between a word phrase and video frames without
manual annotations. The SGN achieves state-of-the-art performances by
outperforming runner-up methods by a margin of 2.1%p and 2.4%p in a CIDEr-D
score on MSVD and MSR-VTT datasets, respectively. Extensive experiments
demonstrate the effectiveness and interpretability of the SGN.
</p>
<a href="http://arxiv.org/abs/2102.00831" target="_blank">arXiv:2102.00831</a> [<a href="http://arxiv.org/pdf/2102.00831" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Decision-Making and Control in Power Systems: Tutorial, Review, and Vision. (arXiv:2102.01168v2 [cs.LG] UPDATED)</h2>
<h3>Xin Chen, Guannan Qu, Yujie Tang, Steven Low, Na Li</h3>
<p>With large-scale integration of renewable generation and ubiquitous
distributed energy resources (DERs), modern power systems confront a series of
new challenges in operation and control, such as growing complexity, increasing
uncertainty, and aggravating volatility. While the upside is that more and more
data are available owing to the widely-deployed smart meters, smart sensors,
and upgraded communication networks. As a result, data-driven control
techniques, especially reinforcement learning (RL), have attracted surging
attention in recent years. In this paper, we focus on RL and aim to provide a
tutorial on various RL techniques and how they can be applied to the
decision-making and control in power systems. In particular, we select three
key applications, including frequency regulation, voltage control, and energy
management, for illustration, and present the typical ways to model and tackle
them with RL methods. We conclude by emphasizing two critical issues in the
application of RL, i.e., safety and scalability. Several potential future
directions are discussed as well.
</p>
<a href="http://arxiv.org/abs/2102.01168" target="_blank">arXiv:2102.01168</a> [<a href="http://arxiv.org/pdf/2102.01168" target="_blank">pdf</a>]

<h2>Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation. (arXiv:2102.01187v2 [cs.CV] UPDATED)</h2>
<h3>Peiye Zhuang, Oluwasanmi Koyejo, Alexander G. Schwing</h3>
<p>Controllable semantic image editing enables a user to change entire image
attributes with few clicks, e.g., gradually making a summer scene look like it
was taken in winter. Classic approaches for this task use a Generative
Adversarial Net (GAN) to learn a latent space and suitable latent-space
transformations. However, current approaches often suffer from attribute edits
that are entangled, global image identity changes, and diminished
photo-realism. To address these concerns, we learn multiple attribute
transformations simultaneously, we integrate attribute regression into the
training of transformation functions, apply a content loss and an adversarial
loss that encourage the maintenance of image identity and photo-realism. We
propose quantitative evaluation strategies for measuring controllable editing
performance, unlike prior work which primarily focuses on qualitative
evaluation. Our model permits better control for both single- and
multiple-attribute editing, while also preserving image identity and realism
during transformation. We provide empirical results for both real and synthetic
images, highlighting that our model achieves state-of-the-art performance for
targeted image manipulation.
</p>
<a href="http://arxiv.org/abs/2102.01187" target="_blank">arXiv:2102.01187</a> [<a href="http://arxiv.org/pdf/2102.01187" target="_blank">pdf</a>]

<h2>Time Adaptive Gaussian Model. (arXiv:2102.01238v2 [stat.ML] UPDATED)</h2>
<h3>Federico Ciech, Veronica Tozzo</h3>
<p>Multivariate time series analysis is becoming an integral part of data
analysis pipelines. Understanding the individual time point connections between
covariates as well as how these connections change in time is non-trivial. To
this aim, we propose a novel method that leverages on Hidden Markov Models and
Gaussian Graphical Models -- Time Adaptive Gaussian Model (TAGM). Our model is
a generalization of state-of-the-art methods for the inference of temporal
graphical models, its formulation leverages on both aspects of these models
providing better results than current methods. In particular,it performs
pattern recognition by clustering data points in time; and, it finds
probabilistic (and possibly causal) relationships among the observed variables.
Compared to current methods for temporal network inference, it reduces the
basic assumptions while still showing good inference performances.
</p>
<a href="http://arxiv.org/abs/2102.01238" target="_blank">arXiv:2102.01238</a> [<a href="http://arxiv.org/pdf/2102.01238" target="_blank">pdf</a>]

<h2>Predicting the Time Until a Vehicle Changes the Lane Using LSTM-based Recurrent Neural Networks. (arXiv:2102.01431v2 [cs.LG] UPDATED)</h2>
<h3>Florian Wirthm&#xfc;ller, Marvin Klimke, Julian Schlechtriemen, Jochen Hipp, Manfred Reichert</h3>
<p>To plan safe and comfortable trajectories for automated vehicles on highways,
accurate predictions of traffic situations are needed. So far, a lot of
research effort has been spent on detecting lane change maneuvers rather than
on estimating the point in time a lane change actually happens. In practice,
however, this temporal information might be even more useful. This paper deals
with the development of a system that accurately predicts the time to the next
lane change of surrounding vehicles on highways using long short-term
memory-based recurrent neural networks. An extensive evaluation based on a
large real-world data set shows that our approach is able to make reliable
predictions, even in the most challenging situations, with a root mean squared
error around 0.7 seconds. Already 3.5 seconds prior to lane changes the
predictions become highly accurate, showing a median error of less than 0.25
seconds. In summary, this article forms a fundamental step towards downstreamed
highly accurate position predictions.
</p>
<a href="http://arxiv.org/abs/2102.01431" target="_blank">arXiv:2102.01431</a> [<a href="http://arxiv.org/pdf/2102.01431" target="_blank">pdf</a>]

<h2>Occluded Video Instance Segmentation. (arXiv:2102.01558v2 [cs.CV] UPDATED)</h2>
<h3>Jiyang Qi, Yan Gao, Yao Hu, Xinggang Wang, Xiaoyu Liu, Xiang Bai, Serge Belongie, Alan Yuille, Philip H.S. Torr, Song Bai</h3>
<p>Can our video understanding systems perceive objects when a heavy occlusion
exists in a scene?

To answer this question, we collect a large scale dataset called OVIS for
occluded video instance segmentation, that is, to simultaneously detect,
segment, and track instances in occluded scenes. OVIS consists of 296k
high-quality instance masks from 25 semantic categories, where object
occlusions usually occur. While our human vision systems can understand those
occluded instances by contextual reasoning and association, our experiments
suggest that current video understanding systems are not satisfying. On the
OVIS dataset, the highest AP achieved by state-of-the-art algorithms is only
14.4, which reveals that we are still at a nascent stage for understanding
objects, instances, and videos in a real-world scenario. Moreover, to
complement missing object cues caused by occlusion, we propose a plug-and-play
module called temporal feature calibration. Built upon MaskTrack R-CNN and
SipMask, we report an AP of 15.2 and 15.0 respectively. The OVIS dataset is
released at this http URL , and the project code will be available
soon.
</p>
<a href="http://arxiv.org/abs/2102.01558" target="_blank">arXiv:2102.01558</a> [<a href="http://arxiv.org/pdf/2102.01558" target="_blank">pdf</a>]

<h2>Depth separation beyond radial functions. (arXiv:2102.01621v2 [cs.LG] UPDATED)</h2>
<h3>Luca Venturi, Samy Jelassi, Tristan Ozuch, Joan Bruna</h3>
<p>High-dimensional depth separation results for neural networks show that
certain functions can be efficiently approximated by two-hidden-layer networks
but not by one-hidden-layer ones in high-dimensions $d$. Existing results of
this type mainly focus on functions with an underlying radial or
one-dimensional structure, which are usually not encountered in practice. The
first contribution of this paper is to extend such results to a more general
class of functions, namely functions with piece-wise oscillatory structure, by
building on the proof strategy of (Eldan and Shamir, 2016). We complement these
results by showing that, if the domain radius and the rate of oscillation of
the objective function are constant, then approximation by one-hidden-layer
networks holds at a $\mathrm{poly}(d)$ rate for any fixed error threshold.

A common theme in the proof of such results is the fact that one-hidden-layer
networks fail to approximate high-energy functions whose Fourier representation
is spread in the domain. On the other hand, existing approximation results of a
function by one-hidden-layer neural networks rely on the function having a
sparse Fourier representation. The choice of the domain also represents a
source of gaps between upper and lower approximation bounds. Focusing on a
fixed approximation domain, namely the sphere $\mathbb{S}^{d-1}$ in dimension
$d$, we provide a characterization of both functions which are efficiently
approximable by one-hidden-layer networks and of functions which are provably
not, in terms of their Fourier expansion.
</p>
<a href="http://arxiv.org/abs/2102.01621" target="_blank">arXiv:2102.01621</a> [<a href="http://arxiv.org/pdf/2102.01621" target="_blank">pdf</a>]

<h2>Pyramid-Focus-Augmentation: Medical Image Segmentation with Step-Wise Focus. (arXiv:2012.07430v1 [cs.CV] CROSS LISTED)</h2>
<h3>Vajira Thambawita, Steven Hicks, P&#xe5;l Halvorsen, Michael A. Riegler</h3>
<p>Segmentation of findings in the gastrointestinal tract is a challenging but
also an important task which is an important building stone for sufficient
automatic decision support systems. In this work, we present our solution for
the Medico 2020 task, which focused on the problem of colon polyp segmentation.
We present our simple but efficient idea of using an augmentation method that
uses grids in a pyramid-like manner (large to small) for segmentation. Our
results show that the proposed methods work as indented and can also lead to
comparable results when competing with other methods.
</p>
<a href="http://arxiv.org/abs/2012.07430" target="_blank">arXiv:2012.07430</a> [<a href="http://arxiv.org/pdf/2012.07430" target="_blank">pdf</a>]

