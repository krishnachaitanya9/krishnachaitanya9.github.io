---
title: Latest Deep Learning Papers
date: 2021-01-12 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (122 Articles)</h1>
<h2>From Tinkering to Engineering: Measurements in Tensorflow Playground. (arXiv:2101.04141v1 [cs.LG])</h2>
<h3>Henrik Hoeiness, Axel Harstad, Gerald Friedland</h3>
<p>In this article, we present an extension of the Tensorflow Playground, called
Tensorflow Meter (short TFMeter). TFMeter is an interactive neural network
architecting tool that allows the visual creation of different architectures of
neural networks. In addition to its ancestor, the playground, our tool shows
information-theoretic measurements while constructing, training, and testing
the network. As a result, each change results in a change in at least one of
the measurements, providing for a better engineering intuition of what
different architectures are able to learn. The measurements are derived from
various places in the literature. In this demo, we describe our web application
that is available online at this http URL and argue that in
the same way that the original Playground is meant to build an intuition about
neural networks, our extension educates users on available measurements, which
we hope will ultimately improve experimental design and reproducibility in the
field.
</p>
<a href="http://arxiv.org/abs/2101.04141" target="_blank">arXiv:2101.04141</a> [<a href="http://arxiv.org/pdf/2101.04141" target="_blank">pdf</a>]

<h2>First-Order Problem Solving through Neural MCTS based Reinforcement Learning. (arXiv:2101.04167v1 [cs.AI])</h2>
<h3>Ruiyang Xu, Prashank Kadam, Karl Lieberherr</h3>
<p>The formal semantics of an interpreted first-order logic (FOL) statement can
be given in Tarskian Semantics or a basically equivalent Game Semantics. The
latter maps the statement and the interpretation into a two-player semantic
game. Many combinatorial problems can be described using interpreted FOL
statements and can be mapped into a semantic game. Therefore, learning to play
a semantic game perfectly leads to the solution of a specific instance of a
combinatorial problem. We adapt the AlphaZero algorithm so that it becomes
better at learning to play semantic games that have different characteristics
than Go and Chess. We propose a general framework, Persephone, to map the FOL
description of a combinatorial problem to a semantic game so that it can be
solved through a neural MCTS based reinforcement learning algorithm. Our goal
for Persephone is to make it tabula-rasa, mapping a problem stated in
interpreted FOL to a solution without human intervention.
</p>
<a href="http://arxiv.org/abs/2101.04167" target="_blank">arXiv:2101.04167</a> [<a href="http://arxiv.org/pdf/2101.04167" target="_blank">pdf</a>]

<h2>Learning with Comparison Feedback: Online Estimation of Sample Statistics. (arXiv:2101.04176v1 [cs.LG])</h2>
<h3>Michela Meister, Sloan Nietert</h3>
<p>We study an online version of the noisy binary search problem where feedback
is generated by a non-stochastic adversary rather than perturbed by random
noise. We reframe this as maintaining an accurate estimate for the median of an
adversarial sequence of integers, $x_1, x_2, \dots$, in a model where each
number $x_t$ can only be accessed through a single threshold query of the form
${1(x_t \leq q_t)}$. In this online comparison feedback model, we explore
estimation of general sample statistics, providing robust algorithms for
median, CDF, and mean estimation with nearly matching lower bounds. We conclude
with several high-dimensional generalizations.
</p>
<a href="http://arxiv.org/abs/2101.04176" target="_blank">arXiv:2101.04176</a> [<a href="http://arxiv.org/pdf/2101.04176" target="_blank">pdf</a>]

<h2>Action Priors for Large Action Spaces in Robotics. (arXiv:2101.04178v1 [cs.RO])</h2>
<h3>Ondrej Biza, Dian Wang, Robert Platt, Jan-Willem van de Meent, Lawson L. S. Wong</h3>
<p>In robotics, it is often not possible to learn useful policies using pure
model-free reinforcement learning without significant reward shaping or
curriculum learning. As a consequence, many researchers rely on expert
demonstrations to guide learning. However, acquiring expert demonstrations can
be expensive. This paper proposes an alternative approach where the solutions
of previously solved tasks are used to produce an action prior that can
facilitate exploration in future tasks. The action prior is a probability
distribution over actions that summarizes the set of policies found solving
previous tasks. Our results indicate that this approach can be used to solve
robotic manipulation problems that would otherwise be infeasible without expert
demonstrations.
</p>
<a href="http://arxiv.org/abs/2101.04178" target="_blank">arXiv:2101.04178</a> [<a href="http://arxiv.org/pdf/2101.04178" target="_blank">pdf</a>]

<h2>PEng4NN: An Accurate Performance Estimation Engine for Efficient Automated Neural Network Architecture Search. (arXiv:2101.04185v1 [cs.LG])</h2>
<h3>Ariel Keller Rorabaugh (1), Silvina Ca&#xed;no-Lores (1), Michael R. Wyatt II (1), Travis Johnston (2), Michela Taufer (1) ((1) University of Tennessee, Knoxville, USA, (2) Oak Ridge National Lab, Oak Ridge, USA)</h3>
<p>Neural network (NN) models are increasingly used in scientific simulations,
AI, and other high performance computing (HPC) fields to extract knowledge from
datasets. Each dataset requires tailored NN model architecture, but designing
structures by hand is a time-consuming and error-prone process. Neural
architecture search (NAS) automates the design of NN architectures. NAS
attempts to find well-performing NN models for specialized datsets, where
performance is measured by key metrics that capture the NN capabilities (e.g.,
accuracy of classification of samples in a dataset). Existing NAS methods are
resource intensive, especially when searching for highly accurate models for
larger and larger datasets.

To address this problem, we propose a performance estimation strategy that
reduces the resources for training NNs and increases NAS throughput without
jeopardizing accuracy. We implement our strategy via an engine called PEng4NN
that plugs into existing NAS methods; in doing so, PEng4NN predicts the final
accuracy of NNs early in the training process, informs the NAS of NN
performance, and thus enables the NAS to terminate training NNs early. We
assess our engine on three diverse datasets (i.e., CIFAR-100, Fashion MNIST,
and SVHN). By reducing the training epochs needed, our engine achieves
substantial throughput gain; on average, our engine saves $61\%$ to $82\%$ of
training epochs, increasing throughput by a factor of 2.5 to 5 compared to a
state-of-the-art NAS method. We achieve this gain without compromising
accuracy, as we demonstrate with two key outcomes. First, across all our tests,
between $74\%$ and $97\%$ of the ground truth best models lie in our set of
predicted best models. Second, the accuracy distributions of the ground truth
best models and our predicted best models are comparable, with the mean
accuracy values differing by at most .7 percentage points across all tests.
</p>
<a href="http://arxiv.org/abs/2101.04185" target="_blank">arXiv:2101.04185</a> [<a href="http://arxiv.org/pdf/2101.04185" target="_blank">pdf</a>]

<h2>Where you live matters: a spatial analysis of COVID-19 mortality. (arXiv:2101.04199v1 [cs.CV])</h2>
<h3>Behzad Javaheri</h3>
<p>The COVID-19 pandemic has caused ~ 2 million fatalities. Significant progress
has been made in advancing our understanding of the disease process, one of the
unanswered questions, however, is the anomaly in the case/mortality ratio with
Mexico as a clear example. Herein, this anomaly is explored by spatial analysis
and whether mortality varies locally according to local factors. To address
this, hexagonal cartogram maps (hexbin) used to spatially map COVID-19
mortality and visualise association with patient-level data on demographics and
pre-existing health conditions. This was further interrogated at local Mexico
City level by choropleth mapping. Our data show that the use of hexagonal
cartograms is a better approach for spatial mapping of COVID-19 data in Mexico
as it addresses bias in area size and population. We report sex/age-related
spatial relationship with mortality amongst the Mexican states and a trend
between health conditions and mortality at the state level. Within Mexico City,
there is a clear south, north divide with higher mortality in the northern
municipalities. Deceased patients in these northern municipalities have the
highest pre-existing health conditions. Taken together, this study provides an
improved presentation of COVID-19 mapping in Mexico and demonstrates spatial
divergence of the mortality in Mexico.
</p>
<a href="http://arxiv.org/abs/2101.04199" target="_blank">arXiv:2101.04199</a> [<a href="http://arxiv.org/pdf/2101.04199" target="_blank">pdf</a>]

<h2>TrackMPNN: A Message Passing Graph Neural Architecture for Multi-Object Tracking. (arXiv:2101.04206v1 [cs.CV])</h2>
<h3>Akshay Rangesh, Pranav Maheshwari, Mez Gebre, Siddhesh Mhatre, Vahid Ramezani, Mohan M. Trivedi</h3>
<p>This study follows many previous approaches to multi-object tracking (MOT)
that model the problem using graph-based data structures, and adapts this
formulation to make it amenable to modern neural networks. Our main
contributions in this work are the creation of a framework based on dynamic
undirected graphs that represent the data association problem over multiple
timesteps, and a message passing graph neural network (GNN) that operates on
these graphs to produce the desired likelihood for every association therein.
We further provide solutions and propositions for the computational problems
that need to be addressed to create a memory-efficient, real-time, online
algorithm that can reason over multiple timesteps, correct previous mistakes,
update beliefs, possess long-term memory, and handle missed/false detections.
In addition to this, our framework provides flexibility in the choice of
temporal window sizes to operate on and the losses used for training. In
essence, this study provides a framework for any kind of graph based neural
network to be trained using conventional techniques from supervised learning,
and then use these trained models to infer on new sequences in an online,
real-time, computationally tractable manner. To demonstrate the efficacy and
robustness of our approach, we only use the 2D box location and object category
to construct the descriptor for each object instance. Despite this, our model
performs on par with state-of-the-art approaches that make use of multiple
hand-crafted and/or learned features. Experiments, qualitative examples and
competitive results on popular MOT benchmarks for autonomous driving
demonstrate the promise and uniqueness of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.04206" target="_blank">arXiv:2101.04206</a> [<a href="http://arxiv.org/pdf/2101.04206" target="_blank">pdf</a>]

<h2>PyHealth: A Python Library for Health Predictive Models. (arXiv:2101.04209v1 [cs.LG])</h2>
<h3>Yue Zhao, Zhi Qiao, Cao Xiao, Lucas Glass, Jimeng Sun</h3>
<p>Despite the explosion of interest in healthcare AI research, the
reproducibility and benchmarking of those research works are often limited due
to the lack of standard benchmark datasets and diverse evaluation metrics. To
address this reproducibility challenge, we develop PyHealth, an open-source
Python toolbox for developing various predictive models on healthcare data.

PyHealth consists of data preprocessing module, predictive modeling module,
and evaluation module. The target users of PyHealth are both computer science
researchers and healthcare data scientists. With PyHealth, they can conduct
complex machine learning pipelines on healthcare datasets with fewer than ten
lines of code. The data preprocessing module enables the transformation of
complex healthcare datasets such as longitudinal electronic health records,
medical images, continuous signals (e.g., electrocardiogram), and clinical
notes into machine learning friendly formats. The predictive modeling module
provides more than 30 machine learning models, including established ensemble
trees and deep neural network-based approaches, via a unified but extendable
API designed for both researchers and practitioners. The evaluation module
provides various evaluation strategies (e.g., cross-validation and
train-validation-test split) and predictive model metrics.

With robustness and scalability in mind, best practices such as unit testing,
continuous integration, code coverage, and interactive examples are introduced
in the library's development. PyHealth can be installed through the Python
Package Index (PyPI) or https://github.com/yzhao062/PyHealth .
</p>
<a href="http://arxiv.org/abs/2101.04209" target="_blank">arXiv:2101.04209</a> [<a href="http://arxiv.org/pdf/2101.04209" target="_blank">pdf</a>]

<h2>Multimodal Engagement Analysis from Facial Videos in the Classroom. (arXiv:2101.04215v1 [cs.CV])</h2>
<h3>&#xd6;mer S&#xfc;mer, Patricia Goldberg, Sidney D&#x27;Mello, Peter Gerjets, Ulrich Trautwein, Enkelejda Kasneci</h3>
<p>Student engagement is a key construct for learning and teaching. While most
of the literature explored the student engagement analysis on computer-based
settings, this paper extends that focus to classroom instruction. To best
examine student visual engagement in the classroom, we conducted a study
utilizing the audiovisual recordings of classes at a secondary school over one
and a half month's time, acquired continuous engagement labeling per student
(N=15) in repeated sessions, and explored computer vision methods to classify
engagement levels from faces in the classroom. We trained deep embeddings for
attentional and emotional features, training Attention-Net for head pose
estimation and Affect-Net for facial expression recognition. We additionally
trained different engagement classifiers, consisting of Support Vector
Machines, Random Forest, Multilayer Perceptron, and Long Short-Term Memory, for
both features. The best performing engagement classifiers achieved AUCs of .620
and .720 in Grades 8 and 12, respectively. We further investigated fusion
strategies and found score-level fusion either improves the engagement
classifiers or is on par with the best performing modality. We also
investigated the effect of personalization and found that using only 60-seconds
of person-specific data selected by margin uncertainty of the base classifier
yielded an average AUC improvement of .084.
</p>
<a href="http://arxiv.org/abs/2101.04215" target="_blank">arXiv:2101.04215</a> [<a href="http://arxiv.org/pdf/2101.04215" target="_blank">pdf</a>]

<h2>Exploiting Multiple Timescales in Hierarchical Echo State Networks. (arXiv:2101.04223v1 [cs.LG])</h2>
<h3>Luca Manneschi, Matt O. A. Ellis, Guido Gigante, Andrew C. Lin, Paolo Del Giudice, Eleni Vasilaki</h3>
<p>Echo state networks (ESNs) are a powerful form of reservoir computing that
only require training of linear output weights whilst the internal reservoir is
formed of fixed randomly connected neurons. With a correctly scaled
connectivity matrix, the neurons' activity exhibits the echo-state property and
responds to the input dynamics with certain timescales. Tuning the timescales
of the network can be necessary for treating certain tasks, and some
environments require multiple timescales for an efficient representation. Here
we explore the timescales in hierarchical ESNs, where the reservoir is
partitioned into two smaller linked reservoirs with distinct properties. Over
three different tasks (NARMA10, a reconstruction task in a volatile
environment, and psMNIST), we show that by selecting the hyper-parameters of
each partition such that they focus on different timescales, we achieve a
significant performance improvement over a single ESN. Through a linear
analysis, and under the assumption that the timescales of the first partition
are much shorter than the second's (typically corresponding to optimal
operating conditions), we interpret the feedforward coupling of the partitions
in terms of an effective representation of the input signal, provided by the
first partition to the second, whereby the instantaneous input signal is
expanded into a weighted combination of its time derivatives. Furthermore, we
propose a data-driven approach to optimise the hyper-parameters through a
gradient descent optimisation method that is an online approximation of
backpropagation through time. We demonstrate the application of the online
learning rule across all the tasks considered.
</p>
<a href="http://arxiv.org/abs/2101.04223" target="_blank">arXiv:2101.04223</a> [<a href="http://arxiv.org/pdf/2101.04223" target="_blank">pdf</a>]

<h2>Challenges and approaches to time-series forecasting in data center telemetry: A Survey. (arXiv:2101.04224v1 [cs.LG])</h2>
<h3>Shruti Jadon, Jan Kanty Milczek, Ajit Patnakar</h3>
<p>Time-series forecasting has been an important research domain for so many
years. Its applications include ECG predictions, sales forecasting, weather
conditions, even COVID-19 spread predictions. These applications have motivated
many researchers to figure out an optimal forecasting approach, but the
modeling approach also changes as the application domain changes. This work has
focused on reviewing different forecasting approaches for telemetry data
predictions collected at data centers. Forecasting of telemetry data is a
critical feature of network and data center management products. However, there
are multiple options of forecasting approaches that range from a simple linear
statistical model to high capacity deep learning architectures. In this paper,
we attempted to summarize and evaluate the performance of well known time
series forecasting techniques. We hope that this evaluation provides a
comprehensive summary to innovate in forecasting approaches for telemetry data.
</p>
<a href="http://arxiv.org/abs/2101.04224" target="_blank">arXiv:2101.04224</a> [<a href="http://arxiv.org/pdf/2101.04224" target="_blank">pdf</a>]

<h2>A deep learning modeling framework to capture mixing patterns in reactive-transport systems. (arXiv:2101.04227v1 [cs.LG])</h2>
<h3>N. V. Jagtap, M. K. Mudunuru, K. B. Nakshatrala</h3>
<p>Prediction and control of chemical mixing are vital for many scientific areas
such as subsurface reactive transport, climate modeling, combustion,
epidemiology, and pharmacology. Due to the complex nature of mixing in
heterogeneous and anisotropic media, the mathematical models related to this
phenomenon are not analytically tractable. Numerical simulations often provide
a viable route to predict chemical mixing accurately. However, contemporary
modeling approaches for mixing cannot utilize available spatial-temporal data
to improve the accuracy of the future prediction and can be compute-intensive,
especially when the spatial domain is large and for long-term temporal
predictions. To address this knowledge gap, we will present in this paper a
deep-learning (DL) modeling framework applied to predict the progress of
chemical mixing under fast bimolecular reactions. This framework uses
convolutional neural networks (CNN) for capturing spatial patterns and long
short-term memory (LSTM) networks for forecasting temporal variations in
mixing. By careful design of the framework -- placement of non-negative
constraint on the weights of the CNN and the selection of activation function,
the framework ensures non-negativity of the chemical species at all spatial
points and for all times. Our DL-based framework is fast, accurate, and
requires minimal data for training.
</p>
<a href="http://arxiv.org/abs/2101.04227" target="_blank">arXiv:2101.04227</a> [<a href="http://arxiv.org/pdf/2101.04227" target="_blank">pdf</a>]

<h2>Explaining the Black-box Smoothly- A Counterfactual Approach. (arXiv:2101.04230v1 [cs.CV])</h2>
<h3>Sumedha Singla, Brian Pollack, Stephen Wallace, Kayhan Batmanghelich</h3>
<p>We propose a BlackBox \emph{Counterfactual Explainer} that is explicitly
developed for medical imaging applications. Classical approaches (e.g. saliency
maps) assessing feature importance do not explain \emph{how} and \emph{why}
variations in a particular anatomical region is relevant to the outcome, which
is crucial for transparent decision making in healthcare application. Our
framework explains the outcome by gradually \emph{exaggerating} the semantic
effect of the given outcome label. Given a query input to a classifier,
Generative Adversarial Networks produce a progressive set of perturbations to
the query image that gradually changes the posterior probability from its
original class to its negation. We design the loss function to ensure that
essential and potentially relevant details, such as support devices, are
preserved in the counterfactually generated images. We provide an extensive
evaluation of different classification tasks on the chest X-Ray images. Our
experiments show that a counterfactually generated visual explanation is
consistent with the disease's clinical relevant measurements, both
quantitatively and qualitatively.
</p>
<a href="http://arxiv.org/abs/2101.04230" target="_blank">arXiv:2101.04230</a> [<a href="http://arxiv.org/pdf/2101.04230" target="_blank">pdf</a>]

<h2>Independent Policy Gradient Methods for Competitive Reinforcement Learning. (arXiv:2101.04233v1 [cs.LG])</h2>
<h3>Constantinos Daskalakis, Dylan J. Foster, Noah Golowich</h3>
<p>We obtain global, non-asymptotic convergence guarantees for independent
learning algorithms in competitive reinforcement learning settings with two
agents (i.e., zero-sum stochastic games). We consider an episodic setting where
in each episode, each player independently selects a policy and observes only
their own actions and rewards, along with the state. We show that if both
players run policy gradient methods in tandem, their policies will converge to
a min-max equilibrium of the game, as long as their learning rates follow a
two-timescale rule (which is necessary). To the best of our knowledge, this
constitutes the first finite-sample convergence result for independent policy
gradient methods in competitive RL; prior work has largely focused on
centralized, coordinated procedures for equilibrium computation.
</p>
<a href="http://arxiv.org/abs/2101.04233" target="_blank">arXiv:2101.04233</a> [<a href="http://arxiv.org/pdf/2101.04233" target="_blank">pdf</a>]

<h2>Solving Common-Payoff Games with Approximate Policy Iteration. (arXiv:2101.04237v1 [cs.AI])</h2>
<h3>Samuel Sokota, Edward Lockhart, Finbarr Timbers, Elnaz Davoodi, Ryan D&#x27;Orazio, Neil Burch, Martin Schmid, Michael Bowling, Marc Lanctot</h3>
<p>For artificially intelligent learning systems to have widespread
applicability in real-world settings, it is important that they be able to
operate decentrally. Unfortunately, decentralized control is difficult --
computing even an epsilon-optimal joint policy is a NEXP complete problem.
Nevertheless, a recently rediscovered insight -- that a team of agents can
coordinate via common knowledge -- has given rise to algorithms capable of
finding optimal joint policies in small common-payoff games. The Bayesian
action decoder (BAD) leverages this insight and deep reinforcement learning to
scale to games as large as two-player Hanabi. However, the approximations it
uses to do so prevent it from discovering optimal joint policies even in games
small enough to brute force optimal solutions. This work proposes CAPI, a novel
algorithm which, like BAD, combines common knowledge with deep reinforcement
learning. However, unlike BAD, CAPI prioritizes the propensity to discover
optimal joint policies over scalability. While this choice precludes CAPI from
scaling to games as large as Hanabi, empirical results demonstrate that, on the
games to which CAPI does scale, it is capable of discovering optimal joint
policies even when other modern multi-agent reinforcement learning algorithms
are unable to do so. Code is available at https://github.com/ssokota/capi .
</p>
<a href="http://arxiv.org/abs/2101.04237" target="_blank">arXiv:2101.04237</a> [<a href="http://arxiv.org/pdf/2101.04237" target="_blank">pdf</a>]

<h2>Lesion2Vec: Deep Metric Learning for Few Shot Multiple Lesions Recognition in Wireless Capsule Endoscopy. (arXiv:2101.04240v1 [cs.CV])</h2>
<h3>Sodiq Adewole, Philip Fernandez, James Jablonski, Sana Syed, Andrew Copland, Michael Porter, Donald Brown</h3>
<p>In this work, we present a unique approach for multiple lesion recognition in
Wireless Capsule Endoscopy (WCE) video data. Few-shot Learning (FSL) aims to
identify new concepts from only a small number of examples. Just as large
amount of ground truth data may not be easily obtained for each class in a
facial recognition nor biometric identification task, we leverage similar
concept to develop a lesion recognition model based on Deep Metric Learning
(DML) using Convolutional Siamese Neural Network (CSNN). We learned an
embedding mapping function for each lesion category from only a few examples
and then applied the learnt embedding mapping to identify lesions on a larger
WCE video dataset. We demonstrated the efficacy of our method on real patient
capsule endoscopy data and we bench-marked the performance with standard
baseline classification models. We also showed that this approach can
generalize to additional categories that the model never saw during training,
obviating the need for fine-tuning the model parameters.
</p>
<a href="http://arxiv.org/abs/2101.04240" target="_blank">arXiv:2101.04240</a> [<a href="http://arxiv.org/pdf/2101.04240" target="_blank">pdf</a>]

<h2>On the Convergence of Deep Networks with Sample Quadratic Overparameterization. (arXiv:2101.04243v1 [cs.LG])</h2>
<h3>Asaf Noy, Yi Xu, Yonathan Aflalo, Rong Jin</h3>
<p>The remarkable ability of deep neural networks to perfectly fit training data
when optimized by gradient-based algorithms is yet to be fully explained
theoretically. Explanations by recent theoretical works rely on the networks to
be wider by orders of magnitude than the ones used in practice. In this work,
we take a step towards closing the gap between theory and practice. We show
that a randomly initialized deep neural network with ReLU activation converges
to a global minimum in a logarithmic number of gradient-descent iterations,
under a considerably milder condition on its width. Our analysis is based on a
novel technique of training a network with fixed activation patterns. We study
the unique properties of the technique that allow an improved convergence, and
can be transformed at any time to an equivalent ReLU network of a reasonable
size. We derive a tight finite-width Neural Tangent Kernel (NTK) equivalence,
suggesting that neural networks trained with our technique generalize well at
least as good as its NTK, and it can be used to study generalization as well.
</p>
<a href="http://arxiv.org/abs/2101.04243" target="_blank">arXiv:2101.04243</a> [<a href="http://arxiv.org/pdf/2101.04243" target="_blank">pdf</a>]

<h2>Quantum Mathematics in Artificial Intelligence. (arXiv:2101.04255v1 [cs.AI])</h2>
<h3>Dominic Widdows, Kirsty Kitto, Trevor Cohen</h3>
<p>In the decade since 2010, successes in artificial intelligence have been at
the forefront of computer science and technology, and vector space models have
solidified a position at the forefront of artificial intelligence. At the same
time, quantum computers have become much more powerful, and announcements of
major advances are frequently in the news.

The mathematical techniques underlying both these areas have more in common
than is sometimes realized. Vector spaces took a position at the axiomatic
heart of quantum mechanics in the 1930s, and this adoption was a key motivation
for the derivation of logic and probability from the linear geometry of vector
spaces. Quantum interactions between particles are modelled using the tensor
product, which is also used to express objects and operations in artificial
neural networks.

This paper describes some of these common mathematical areas, including
examples of how they are used in artificial intelligence (AI), particularly in
automated reasoning and natural language processing (NLP). Techniques discussed
include vector spaces, scalar products, subspaces and implication, orthogonal
projection and negation, dual vectors, density matrices, positive operators,
and tensor products. Application areas include information retrieval,
categorization and implication, modelling word-senses and disambiguation,
inference in knowledge bases, and semantic composition.

Some of these approaches can potentially be implemented on quantum hardware.
Many of the practical steps in this implementation are in early stages, and
some are already realized. Explaining some of the common mathematical tools can
help researchers in both AI and quantum computing further exploit these
overlaps, recognizing and exploring new directions along the way.
</p>
<a href="http://arxiv.org/abs/2101.04255" target="_blank">arXiv:2101.04255</a> [<a href="http://arxiv.org/pdf/2101.04255" target="_blank">pdf</a>]

<h2>Clutter Slices Approach for Identification-on-the-fly of Indoor Spaces. (arXiv:2101.04262v1 [cs.RO])</h2>
<h3>Upinder Kaur, Praveen Abbaraju, Harrison McCarty, Richard M. Voyles</h3>
<p>Construction spaces are constantly evolving, dynamic environments in need of
continuous surveying, inspection, and assessment. Traditional manual inspection
of such spaces proves to be an arduous and time-consuming activity. Automation
using robotic agents can be an effective solution. Robots, with perception
capabilities can autonomously classify and survey indoor construction spaces.
In this paper, we present a novel identification-on-the-fly approach for coarse
classification of indoor spaces using the unique signature of clutter. Using
the context granted by clutter, we recognize common indoor spaces such as
corridors, staircases, shared spaces, and restrooms. The proposed clutter
slices pipeline achieves a maximum accuracy of 93.6% on the presented clutter
slices dataset. This sensor independent approach can be generalized to various
domains to equip intelligent autonomous agents in better perceiving their
environment.
</p>
<a href="http://arxiv.org/abs/2101.04262" target="_blank">arXiv:2101.04262</a> [<a href="http://arxiv.org/pdf/2101.04262" target="_blank">pdf</a>]

<h2>HighAir: A Hierarchical Graph Neural Network-Based Air Quality Forecasting Method. (arXiv:2101.04264v1 [cs.LG])</h2>
<h3>Jiahui Xu, Ling Chen, Mingqi Lv, Chaoqun Zhan, Sanjian Chen, Jian Chang</h3>
<p>Accurately forecasting air quality is critical to protecting general public
from lung and heart diseases. This is a challenging task due to the complicated
interactions among distinct pollution sources and various other influencing
factors. Existing air quality forecasting methods cannot effectively model the
diffusion processes of air pollutants between cities and monitoring stations,
which may suddenly deteriorate the air quality of a region. In this paper, we
propose HighAir, i.e., a hierarchical graph neural network-based air quality
forecasting method, which adopts an encoder-decoder architecture and considers
complex air quality influencing factors, e.g., weather and land usage.
Specifically, we construct a city-level graph and station-level graphs from a
hierarchical perspective, which can consider city-level and station-level
patterns, respectively. We design two strategies, i.e., upper delivery and
lower updating, to implement the inter-level interactions, and introduce
message passing mechanism to implement the intra-level interactions. We
dynamically adjust edge weights based on wind direction to model the
correlations between dynamic factors and air quality. We compare HighAir with
the state-of-the-art air quality forecasting methods on the dataset of Yangtze
River Delta city group, which covers 10 major cities within 61,500 km2. The
experimental results show that HighAir significantly outperforms other methods.
</p>
<a href="http://arxiv.org/abs/2101.04264" target="_blank">arXiv:2101.04264</a> [<a href="http://arxiv.org/pdf/2101.04264" target="_blank">pdf</a>]

<h2>CleftNet: Augmented Deep Learning for Synaptic Cleft Detection from Brain Electron Microscopy. (arXiv:2101.04266v1 [cs.CV])</h2>
<h3>Yi Liu, Shuiwang Ji</h3>
<p>Detecting synaptic clefts is a crucial step to investigate the biological
function of synapses. The volume electron microscopy (EM) allows the
identification of synaptic clefts by photoing EM images with high resolution
and fine details. Machine learning approaches have been employed to
automatically predict synaptic clefts from EM images. In this work, we propose
a novel and augmented deep learning model, known as CleftNet, for improving
synaptic cleft detection from brain EM images. We first propose two novel
network components, known as the feature augmentor and the label augmentor, for
augmenting features and labels to improve cleft representations. The feature
augmentor can fuse global information from inputs and learn common
morphological patterns in clefts, leading to augmented cleft features. In
addition, it can generate outputs with varying dimensions, making it flexible
to be integrated in any deep network. The proposed label augmentor augments the
label of each voxel from a value to a vector, which contains both the
segmentation label and boundary label. This allows the network to learn
important shape information and to produce more informative cleft
representations. Based on the proposed feature augmentor and label augmentor,
We build the CleftNet as a U-Net like network. The effectiveness of our methods
is evaluated on both online and offline tasks. Our CleftNet currently ranks \#1
on the online task of the CREMI open challenge. In addition, both quantitative
and qualitative results in the offline tasks show that our method outperforms
the baseline approaches significantly.
</p>
<a href="http://arxiv.org/abs/2101.04266" target="_blank">arXiv:2101.04266</a> [<a href="http://arxiv.org/pdf/2101.04266" target="_blank">pdf</a>]

<h2>Pneumonia Detection on Chest X-ray using Radiomic Features and Contrastive Learning. (arXiv:2101.04269v1 [cs.CV])</h2>
<h3>Yan Han, Chongyan Chen, Ahmed H Tewfik, Ying Ding, Yifan Peng</h3>
<p>Chest X-ray becomes one of the most common medical diagnoses due to its
noninvasiveness. The number of chest X-ray images has skyrocketed, but reading
chest X-rays still have been manually performed by radiologists, which creates
huge burnouts and delays. Traditionally, radiomics, as a subfield of radiology
that can extract a large number of quantitative features from medical images,
demonstrates its potential to facilitate medical imaging diagnosis before the
deep learning era. With the rise of deep learning, the explainability of deep
neural networks on chest X-ray diagnosis remains opaque. In this study, we
proposed a novel framework that leverages radiomics features and contrastive
learning to detect pneumonia in chest X-ray. Experiments on the RSNA Pneumonia
Detection Challenge dataset show that our model achieves superior results to
several state-of-the-art models (&gt; 10% in F1-score) and increases the model's
interpretability.
</p>
<a href="http://arxiv.org/abs/2101.04269" target="_blank">arXiv:2101.04269</a> [<a href="http://arxiv.org/pdf/2101.04269" target="_blank">pdf</a>]

<h2>Enhanced Information Fusion Network for Crowd Counting. (arXiv:2101.04279v1 [cs.CV])</h2>
<h3>Geng Chen, Peirong Guo</h3>
<p>In recent years, crowd counting, a technique for predicting the number of
people in an image, becomes a challenging task in computer vision. In this
paper, we propose a cross-column feature fusion network to solve the problem of
information redundancy in columns. We introduce the Information Fusion Module
(IFM) which provides a channel for information flow to help different columns
to obtain significant information from another column. Through this channel,
different columns exchange information with each other and extract useful
features from the other column to enhance key information. Hence, there is no
need for columns to pay attention to all areas in the image. Each column can be
responsible for different regions, thereby reducing the burden of each column.
In experiments, the generalizability of our model is more robust and the
results of transferring between different datasets acheive the comparable
results with the state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2101.04279" target="_blank">arXiv:2101.04279</a> [<a href="http://arxiv.org/pdf/2101.04279" target="_blank">pdf</a>]

<h2>Temporally Guided Articulated Hand Pose Tracking in Surgical Videos. (arXiv:2101.04281v1 [cs.CV])</h2>
<h3>Nathan Louis, Luowei Zhou, Steven J. Yule, Roger D. Dias, Milisa Manojlovich, Francis D. Pagani, Donald S. Likosky, Jason J. Corso</h3>
<p>Articulated hand pose tracking is an underexplored problem that carries the
potential for use in an extensive number of applications, especially in the
medical domain. With a robust and accurate tracking system on in-vivo surgical
videos, the motion dynamics and movement patterns of the hands can be captured
and analyzed for rich tasks including skills assessment, training surgical
residents, and temporal action recognition. In this work, we propose a novel
hand pose estimation model, Res152- CondPose, which improves tracking accuracy
by incorporating a hand pose prior into its pose prediction. We show
improvements over state-of-the-art methods which provide frame-wise independent
predictions, by following a temporally guided approach that effectively
leverages past predictions. Additionally, we collect the first dataset,
Surgical Hands, that provides multi-instance articulated hand pose annotations
for in-vivo videos. Our dataset contains 76 video clips from 28 publicly
available surgical videos and over 8.1k annotated hand pose instances. We
provide bounding boxes, articulated hand pose annotations, and tracking IDs to
enable multi-instance area-based and articulated tracking. When evaluated on
Surgical Hands, we show our method outperforms the state-of-the-art method
using mean Average Precision (mAP), to measure pose estimation accuracy, and
Multiple Object Tracking Accuracy (MOTA), to assess pose tracking performance.
</p>
<a href="http://arxiv.org/abs/2101.04281" target="_blank">arXiv:2101.04281</a> [<a href="http://arxiv.org/pdf/2101.04281" target="_blank">pdf</a>]

<h2>A Brief Survey of Associations Between Meta-Learning and General AI. (arXiv:2101.04283v1 [cs.AI])</h2>
<h3>Huimin Peng</h3>
<p>This paper briefly reviews the history of meta-learning and describes its
contribution to general AI. Meta-learning improves model generalization
capacity and devises general algorithms applicable to both in-distribution and
out-of-distribution tasks potentially. General AI replaces task-specific models
with general algorithmic systems introducing higher level of automation in
solving diverse tasks using AI. We summarize main contributions of
meta-learning to the developments in general AI, including memory module,
meta-learner, coevolution, curiosity, forgetting and AI-generating algorithm.
We present connections between meta-learning and general AI and discuss how
meta-learning can be used to formulate general AI algorithms.
</p>
<a href="http://arxiv.org/abs/2101.04283" target="_blank">arXiv:2101.04283</a> [<a href="http://arxiv.org/pdf/2101.04283" target="_blank">pdf</a>]

<h2>Explainable Deep Behavioral Sequence Clustering for Transaction Fraud Detection. (arXiv:2101.04285v1 [cs.LG])</h2>
<h3>Wei Min, Weiming Liang, Hang Yin, Zhurong Wang, Mei Li, Alok Lal</h3>
<p>In e-commerce industry, user behavior sequence data has been widely used in
many business units such as search and merchandising to improve their products.
However, it is rarely used in financial services not only due to its 3V
characteristics - i.e. Volume, Velocity and Variety - but also due to its
unstructured nature. In this paper, we propose a Financial Service scenario
Deep learning based Behavior data representation method for Clustering
(FinDeepBehaviorCluster) to detect fraudulent transactions. To utilize the
behavior sequence data, we treat click stream data as event sequence, use time
attention based Bi-LSTM to learn the sequence embedding in an unsupervised
fashion, and combine them with intuitive features generated by risk experts to
form a hybrid feature representation. We also propose a GPU powered HDBSCAN
(pHDBSCAN) algorithm, which is an engineering optimization for the original
HDBSCAN algorithm based on FAISS project, so that clustering can be carried out
on hundreds of millions of transactions within a few minutes. The computation
efficiency of the algorithm has increased 500 times compared with the original
implementation, which makes flash fraud pattern detection feasible. Our
experimental results show that the proposed FinDeepBehaviorCluster framework is
able to catch missed fraudulent transactions with considerable business values.
In addition, rule extraction method is applied to extract patterns from risky
clusters using intuitive features, so that narrative descriptions can be
attached to the risky clusters for case investigation, and unknown risk
patterns can be mined for real-time fraud detection. In summary,
FinDeepBehaviorCluster as a complementary risk management strategy to the
existing real-time fraud detection engine, can further increase our fraud
detection and proactive risk defense capabilities.
</p>
<a href="http://arxiv.org/abs/2101.04285" target="_blank">arXiv:2101.04285</a> [<a href="http://arxiv.org/pdf/2101.04285" target="_blank">pdf</a>]

<h2>3D-ANAS: 3D Asymmetric Neural Architecture Search for Fast Hyperspectral Image Classification. (arXiv:2101.04287v1 [cs.CV])</h2>
<h3>Haokui Zhang, Chengrong Gong, Yunpeng Bai, Zongwen Bai, Ying Li</h3>
<p>Hyperspectral images involve abundant spectral and spatial information,
playing an irreplaceable role in land-cover classification. Recently, based on
deep learning technologies, an increasing number of HSI classification
approaches have been proposed, which demonstrate promising performance.
However, previous studies suffer from two major drawbacks: 1) the architecture
of most deep learning models is manually designed, relies on specialized
knowledge, and is relatively tedious. Moreover, in HSI classifications,
datasets captured by different sensors have different physical properties.
Correspondingly, different models need to be designed for different datasets,
which further increases the workload of designing architectures; 2) the
mainstream framework is a patch-to-pixel framework. The overlap regions of
patches of adjacent pixels are calculated repeatedly, which increases
computational cost and time cost. Besides, the classification accuracy is
sensitive to the patch size, which is artificially set based on extensive
investigation experiments. To overcome the issues mentioned above, we firstly
propose a 3D asymmetric neural network search algorithm and leverage it to
automatically search for efficient architectures for HSI classifications. By
analysing the characteristics of HSIs, we specifically build a 3D asymmetric
decomposition search space, where spectral and spatial information are
processed with different decomposition convolutions. Furthermore, we propose a
new fast classification framework, i,e., pixel-to-pixel classification
framework, which has no repetitive operations and reduces the overall cost.
Experiments on three public HSI datasets captured by different sensors
demonstrate the networks designed by our 3D-ANAS achieve competitive
performance compared to several state-of-the-art methods, while having a much
faster inference speed.
</p>
<a href="http://arxiv.org/abs/2101.04287" target="_blank">arXiv:2101.04287</a> [<a href="http://arxiv.org/pdf/2101.04287" target="_blank">pdf</a>]

<h2>A Robotic System for Implant Modification in Single-stage Cranioplasty. (arXiv:2101.04303v1 [cs.RO])</h2>
<h3>Shuya Liu, Wei-Lun Huang, Chad Gordon, Mehran Armand</h3>
<p>Craniomaxillofacial reconstruction with patient-specific customized
craniofacial implants (CCIs) is most commonly performed for large-sized
skeletal defects. Because the exact size of skull resection may not be known
prior to the surgery, in the single-stage cranioplasty, a large CCI is
prefabricated and resized intraoperatively with a manual-cutting process
provided by a surgeon. The manual resizing, however, may be inaccurate and
significantly add to the operating time. This paper introduces a fast and
non-contact approach for intraoperatively determining the exact contour of the
skull resection and automatically resizing the implant to fit the resection
area. Our approach includes four steps: First, a patient's defect information
is acquired by a 3D scanner. Second, the scanned defect is aligned to the CCI
by registering the scanned defect to the reconstructed CT model. Third, a
cutting toolpath is generated from the contour of the scanned defect. Lastly,
the large CCI is resized by a cutting robot to fit the resection area according
to the given toolpath. To evaluate the resizing performance of our method, six
different resection shapes were used in the cutting experiments. We compared
the performance of our method to the performances of surgeon's manual resizing
and an existing technique which collects the defect contour with an optical
tracking system and projects the contour on the CCI to guide the manual
modification. The results show that our proposed method improves the resizing
accuracy by 56% compared to the surgeon's manual modification and 42% compared
to the projection method.
</p>
<a href="http://arxiv.org/abs/2101.04303" target="_blank">arXiv:2101.04303</a> [<a href="http://arxiv.org/pdf/2101.04303" target="_blank">pdf</a>]

<h2>Regret Analysis of Distributed Gaussian Process Estimation and Coverage. (arXiv:2101.04306v1 [cs.RO])</h2>
<h3>Lai Wei, Andrew McDonald, Vaibhav Srivastava</h3>
<p>We study the problem of distributed multi-robot coverage over an unknown,
nonuniform sensory field. Modeling the sensory field as a realization of a
Gaussian Process and using Bayesian techniques, we devise a policy which aims
to balance the tradeoff between learning the sensory function and covering the
environment. We propose an adaptive coverage algorithm called Deterministic
Sequencing of Learning and Coverage (DSLC) that schedules learning and coverage
epochs such that its emphasis gradually shifts from exploration to exploitation
while never fully ceasing to learn. Using a novel definition of coverage regret
which characterizes overall coverage performance of a multi-robot team over a
time horizon $T$, we analyze DSLC to provide an upper bound on expected
cumulative coverage regret. Finally, we illustrate the empirical performance of
the algorithm through simulations of the coverage task over an unknown
distribution of wildfires.
</p>
<a href="http://arxiv.org/abs/2101.04306" target="_blank">arXiv:2101.04306</a> [<a href="http://arxiv.org/pdf/2101.04306" target="_blank">pdf</a>]

<h2>LLA: Loss-aware Label Assignment for Dense Pedestrian Detection. (arXiv:2101.04307v1 [cs.CV])</h2>
<h3>Zheng Ge, Jianfeng Wang, Xin Huang, Songtao Liu, Osamu Yoshie</h3>
<p>Label assignment has been widely studied in general object detection because
of its great impact on detectors' performance. However, none of these works
focus on label assignment in dense pedestrian detection. In this paper, we
propose a simple yet effective assigning strategy called Loss-aware Label
Assignment (LLA) to boost the performance of pedestrian detectors in crowd
scenarios. LLA first calculates classification (cls) and regression (reg)
losses between each anchor and ground-truth (GT) pair. A joint loss is then
defined as the weighted summation of cls and reg losses as the assigning
indicator. Finally, anchors with top K minimum joint losses for a certain GT
box are assigned as its positive anchors. Anchors that are not assigned to any
GT box are considered negative. Loss-aware label assignment is based on an
observation that anchors with lower joint loss usually contain richer semantic
information and thus can better represent their corresponding GT boxes.
Experiments on CrowdHuman and CityPersons show that such a simple label
assigning strategy can boost MR by 9.53% and 5.47% on two famous one-stage
detectors - RetinaNet and FCOS, respectively, demonstrating the effectiveness
of LLA.
</p>
<a href="http://arxiv.org/abs/2101.04307" target="_blank">arXiv:2101.04307</a> [<a href="http://arxiv.org/pdf/2101.04307" target="_blank">pdf</a>]

<h2>A Multimodal Eye Movement Dataset and a Multimodal Eye Movement Segmentation Analysis. (arXiv:2101.04318v1 [cs.CV])</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>We present a new dataset with annotated eye movements. The dataset consists
of over 800,000 gaze points recorded during a car ride in the real world and in
the simulator. In total, the eye movements of 19 subjects were annotated. In
this dataset there are several data sources such as the eyelid closure, the
pupil center, the optical vector, and a vector into the pupil center starting
from the center of the eye corners. These different data sources are analyzed
and evaluated individually as well as in combination with respect to their
goodness of fit for eye movement classification. These results will help
developers of real-time systems and algorithms to find the best data sources
for their application. Also, new algorithms can be trained and evaluated on
this data set. The data and the Matlab code can be downloaded here
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/?p=%2FA%20Multimodal%20Eye%20Movement%20Dataset%20and%20...&amp;mode=list
</p>
<a href="http://arxiv.org/abs/2101.04318" target="_blank">arXiv:2101.04318</a> [<a href="http://arxiv.org/pdf/2101.04318" target="_blank">pdf</a>]

<h2>Random Transformation of Image Brightness for Adversarial Attack. (arXiv:2101.04321v1 [cs.CV])</h2>
<h3>Bo Yang, Kaiyong Xu, Hengjun Wang, Hengwei Zhang</h3>
<p>Deep neural networks are vulnerable to adversarial examples, which are
crafted by adding small, human-imperceptible perturbations to the original
images, but make the model output inaccurate predictions. Before deep neural
networks are deployed, adversarial attacks can thus be an important method to
evaluate and select robust models in safety-critical applications. However,
under the challenging black-box setting, the attack success rate, i.e., the
transferability of adversarial examples, still needs to be improved. Based on
image augmentation methods, we found that random transformation of image
brightness can eliminate overfitting in the generation of adversarial examples
and improve their transferability. To this end, we propose an adversarial
example generation method based on this phenomenon, which can be integrated
with Fast Gradient Sign Method (FGSM)-related methods to build a more robust
gradient-based attack and generate adversarial examples with better
transferability. Extensive experiments on the ImageNet dataset demonstrate the
method's effectiveness. Whether on normally or adversarially trained networks,
our method has a higher success rate for black-box attacks than other attack
methods based on data augmentation. We hope that this method can help to
evaluate and improve the robustness of models.
</p>
<a href="http://arxiv.org/abs/2101.04321" target="_blank">arXiv:2101.04321</a> [<a href="http://arxiv.org/pdf/2101.04321" target="_blank">pdf</a>]

<h2>Seed Stocking Via Multi-Task Learning. (arXiv:2101.04333v1 [cs.LG])</h2>
<h3>Yunhe Feng, Wenjun Zhou</h3>
<p>Sellers of crop seeds need to plan for the variety and quantity of seeds to
stock at least a year in advance. There are a large number of seed varieties of
one crop, and each can perform best under different growing conditions. Given
the unpredictability of weather, farmers need to make decisions that balance
high yield and low risk. A seed vendor needs to be able to anticipate the needs
of farmers and have them ready. In this study, we propose an analytical
framework for estimating seed demand with three major steps. First, we will
estimate the yield and risk of each variety as if they were planted at each
location. Since past experiments performed with different seed varieties are
highly unbalanced across varieties, and the combination of growing conditions
is sparse, we employ multi-task learning to borrow information from similar
varieties. Second, we will determine the best mix of seeds for each location by
seeking a tradeoff between yield and risk. Third, we will aggregate such mix
and pick the top five varieties to re-balance the yield and risk for each
growing location. We find that multi-task learning provides a viable solution
for yield prediction, and our overall analytical framework has resulted in a
good performance.
</p>
<a href="http://arxiv.org/abs/2101.04333" target="_blank">arXiv:2101.04333</a> [<a href="http://arxiv.org/pdf/2101.04333" target="_blank">pdf</a>]

<h2>Blind Modulation Classification via Combined Machine Learning and Signal Feature Extraction. (arXiv:2101.04337v1 [cs.LG])</h2>
<h3>Jafar Norolahi, Paeiz Azmi</h3>
<p>In this study, an algorithm to blind and automatic modulation classification
has been proposed. It well benefits combined machine leaning and signal feature
extraction to recognize diverse range of modulation in low signal power to
noise ratio (SNR). The presented algorithm contains four. First, it advantages
spectrum analyzing to branching modulated signal based on regular and irregular
spectrum character. Seconds, a nonlinear soft margin support vector (NS SVM)
problem is applied to received signal, and its symbols are classified to
correct and incorrect (support vectors) symbols. The NS SVM employment leads to
discounting in physical layer noise effect on modulated signal. After that, a
k-center clustering can find center of each class. finally, in correlation
function estimation of scatter diagram is correlated with pre-saved ideal
scatter diagram of modulations. The correlation outcome is classification
result. For more evaluation, success rate, performance, and complexity in
compare to many published methods are provided. The simulation prove that the
proposed algorithm can classified the modulated signal in less SNR. For
example, it can recognize 4-QAM in SNR=-4.2 dB, and 4-FSK in SNR=2.1 dB with
%99 success rate. Moreover, due to using of kernel function in dual problem of
NS SVM and feature base function, the proposed algorithm has low complexity and
simple implementation in practical issues.
</p>
<a href="http://arxiv.org/abs/2101.04337" target="_blank">arXiv:2101.04337</a> [<a href="http://arxiv.org/pdf/2101.04337" target="_blank">pdf</a>]

<h2>Take More Positives: A Contrastive Learning Framework for Unsupervised Person Re-Identification. (arXiv:2101.04340v1 [cs.CV])</h2>
<h3>Xuanyu He, Wei Zhang, Ran Song, Xiangyuan Lan</h3>
<p>Exploring the relationship between examples without manual annotations is a
core problem in the field of unsupervised person re-identification (re-ID). In
the unsupervised scenario, no ground truth is provided for bringing instances
of the same identity closer and spreading samples of different identities
apart. In this paper, we introduce a contrastive learning framework for
unsupervised person re-ID, which we call Take More Positives (TMP). In an
iterative manner, TMP generates pseudo-labels by clustering samples, and
updates itself with such pseudo-labels and the proposed contrastive loss. By
considering more positive examples, the framework of TMP outperforms the
state-of-the-art methods for unsupervised person re-ID. On the Market-1501
benchmark, TMP achieves 88.3% Rank-1 accuracy and 70.4% mean average precision.
Our code will be made publicly available.
</p>
<a href="http://arxiv.org/abs/2101.04340" target="_blank">arXiv:2101.04340</a> [<a href="http://arxiv.org/pdf/2101.04340" target="_blank">pdf</a>]

<h2>Mixup Without Hesitation. (arXiv:2101.04342v1 [cs.CV])</h2>
<h3>Hao Yu, Huanyu Wang, Jianxin Wu</h3>
<p>Mixup linearly interpolates pairs of examples to form new samples, which is
easy to implement and has been shown to be effective in image classification
tasks. However, there are two drawbacks in mixup: one is that more training
epochs are needed to obtain a well-trained model; the other is that mixup
requires tuning a hyper-parameter to gain appropriate capacity but that is a
difficult task. In this paper, we find that mixup constantly explores the
representation space, and inspired by the exploration-exploitation dilemma in
reinforcement learning, we propose mixup Without hesitation (mWh), a concise,
effective, and easy-to-use training algorithm. We show that mWh strikes a good
balance between exploration and exploitation by gradually replacing mixup with
basic data augmentation. It can achieve a strong baseline with less training
time than original mixup and without searching for optimal hyper-parameter,
i.e., mWh acts as mixup without hesitation. mWh can also transfer to CutMix,
and gain consistent improvement on other machine learning and computer vision
tasks such as object detection. Our code is open-source and available at
https://github.com/yuhao318/mwh
</p>
<a href="http://arxiv.org/abs/2101.04342" target="_blank">arXiv:2101.04342</a> [<a href="http://arxiv.org/pdf/2101.04342" target="_blank">pdf</a>]

<h2>Proceedings of the NeurIPS 2020 Workshop on Machine Learning for the Developing World: Improving Resilience. (arXiv:2101.04347v1 [cs.LG])</h2>
<h3>Tejumade Afonja, Konstantin Klemmer, Aya Salama, Paula Rodriguez Diaz, Niveditha Kalavakonda, Oluwafemi Azeez</h3>
<p>These are the proceedings of the 4th workshop on Machine Learning for the
Developing World (ML4D), held as part of the Thirty-fourth Conference on Neural
Information Processing Systems (NeurIPS) on Saturday, December 12th 2020.
</p>
<a href="http://arxiv.org/abs/2101.04347" target="_blank">arXiv:2101.04347</a> [<a href="http://arxiv.org/pdf/2101.04347" target="_blank">pdf</a>]

<h2>Phase Retrieval using Expectation Consistent Signal Recovery Algorithm based on Hypernetwork. (arXiv:2101.04348v1 [cs.LG])</h2>
<h3>Chang-Jen Wang, Chao-Kai Wen, Shang-Ho (Lawrence) Tsai, Shi Jin, Geoffrey Ye Li</h3>
<p>Phase retrieval (PR) is an important component in modern computational
imaging systems. Many algorithms have been developed over the past half
century. Recent advances in deep learning have opened up a new possibility for
robust and fast PR. An emerging technique, called deep unfolding, provides a
systematic connection between conventional model-based iterative algorithms and
modern data-based deep learning. Unfolded algorithms, powered by data learning,
have shown remarkable performance and convergence speed improvement over the
original algorithms. Despite their potential, most existing unfolded algorithms
are strictly confined to a fixed number of iterations when employing
layer-dependent parameters. In this study, we develop a novel framework for
deep unfolding to overcome the existing limitations. Even if our framework can
be widely applied to general inverse problems, we take PR as an example in the
paper. Our development is based on an unfolded generalized expectation
consistent signal recovery (GEC-SR) algorithm, wherein damping factors are left
for data-driven learning. In particular, we introduce a hypernetwork to
generate the damping factors for GEC-SR. Instead of directly learning a set of
optimal damping factors, the hypernetwork learns how to generate the optimal
damping factors according to the clinical settings, thus ensuring its
adaptivity to different scenarios. To make the hypernetwork work adapt to
varying layer numbers, we use a recurrent architecture to develop a dynamic
hypernetwork, which generates a damping factor that can vary online across
layers. We also exploit a self-attention mechanism to enhance the robustness of
the hypernetwork. Extensive experiments show that the proposed algorithm
outperforms existing ones in convergence speed and accuracy, and still works
well under very harsh settings, that many classical PR algorithms unstable or
even fail.
</p>
<a href="http://arxiv.org/abs/2101.04348" target="_blank">arXiv:2101.04348</a> [<a href="http://arxiv.org/pdf/2101.04348" target="_blank">pdf</a>]

<h2>Automated Detection of Patellofemoral Osteoarthritis from Knee Lateral View Radiographs Using Deep Learning: Data from the Multicenter Osteoarthritis Study (MOST). (arXiv:2101.04350v1 [cs.CV])</h2>
<h3>Neslihan Bayramoglu, Miika T. Nieminen, Simo Saarakkala</h3>
<p>Objective: To assess the ability of imaging-based deep learning to predict
radiographic patellofemoral osteoarthritis (PFOA) from knee lateral view
radiographs.

Design: Knee lateral view radiographs were extracted from The Multicenter
Osteoarthritis Study (MOST) (n = 18,436 knees). Patellar region-of-interest
(ROI) was first automatically detected, and subsequently, end-to-end deep
convolutional neural networks (CNNs) were trained and validated to detect the
status of patellofemoral OA. Patellar ROI was detected using
deep-learning-based object detection method. Manual PFOA status assessment
provided in the MOST dataset was used as a classification outcome for the CNNs.
Performance of prediction models was assessed using the area under the receiver
operating characteristic curve (ROC AUC) and the average precision (AP)
obtained from the precision-recall (PR) curve in the stratified 5-fold cross
validation setting.

Results: Of the 18,436 knees, 3,425 (19%) had PFOA. AUC and AP for the
reference model including age, sex, body mass index (BMI), the total Western
Ontario and McMaster Universities Arthritis Index (WOMAC) score, and
tibiofemoral Kellgren-Lawrence (KL) grade to predict PFOA were 0.806 and 0.478,
respectively. The CNN model that used only image data significantly improved
the prediction of PFOA status (ROC AUC= 0.958, AP= 0.862).

Conclusion: We present the first machine learning based automatic PFOA
detection method. Furthermore, our deep learning based model trained on patella
region from knee lateral view radiographs performs better at predicting PFOA
than models based on patient characteristics and clinical assessments.
</p>
<a href="http://arxiv.org/abs/2101.04350" target="_blank">arXiv:2101.04350</a> [<a href="http://arxiv.org/pdf/2101.04350" target="_blank">pdf</a>]

<h2>Activation Density based Mixed-Precision Quantization for Energy Efficient Neural Networks. (arXiv:2101.04354v1 [cs.LG])</h2>
<h3>Karina Vasquez, Yeshwanth Venkatesha, Abhiroop Bhattacharjee, Abhishek Moitra, Priyadarshini Panda</h3>
<p>As neural networks gain widespread adoption in embedded devices, there is a
need for model compression techniques to facilitate deployment in
resource-constrained environments. Quantization is one of the go-to methods
yielding state-of-the-art model compression. Most approaches take a fully
trained model, apply different heuristics to determine the optimal
bit-precision for different layers of the network, and retrain the network to
regain any drop in accuracy. Based on Activation Density (AD)-the proportion of
non-zero activations in a layer-we propose an in-training quantization method.
Our method calculates bit-width for each layer during training yielding a mixed
precision model with competitive accuracy. Since we train lower precision
models during training, our approach yields the final quantized model at lower
training complexity and also eliminates the need for re-training. We run
experiments on benchmark datasets like CIFAR-10, CIFAR-100, TinyImagenet on
VGG19/ResNet18 architectures and report the accuracy and energy estimates for
the same. We achieve ~4.5x benefit in terms of estimated
multiply-and-accumulate (MAC) reduction while reducing the training complexity
by 50% in our experiments. To further evaluate the energy benefits of our
proposed method, we develop a mixed-precision scalable Process In Memory (PIM)
hardware accelerator platform. The hardware platform incorporates shift-add
functionality for handling multi-bit precision neural network models.
Evaluating the quantized models obtained with our proposed method on the PIM
platform yields ~5x energy reduction compared to 16-bit models. Additionally,
we find that integrating AD based quantization with AD based pruning (both
conducted during training) yields up to ~198x and ~44x energy reductions for
VGG19 and ResNet18 architectures respectively on PIM platform compared to
baseline 16-bit precision, unpruned models.
</p>
<a href="http://arxiv.org/abs/2101.04354" target="_blank">arXiv:2101.04354</a> [<a href="http://arxiv.org/pdf/2101.04354" target="_blank">pdf</a>]

<h2>Rethinking Interactive Image Segmentation: Feature Space Annotation. (arXiv:2101.04378v1 [cs.CV])</h2>
<h3>Jord&#xe3;o Bragantini (UNICAMP), Alexandre Falc&#xe3;o (UNICAMP), Laurent Najman (ligm)</h3>
<p>Despite the progress of interactive image segmentation methods, high-quality
pixel-level annotation is still time-consuming and laborious -- a bottleneck
for several deep learning applications. We take a step back to propose
interactive and simultaneous segment annotation from multiple images guided by
feature space projection and optimized by metric learning as the labeling
progresses. This strategy is in stark contrast to existing interactive
segmentation methodologies, which perform annotation in the image domain. We
show that our approach can surpass the accuracy of state-of-the-art methods in
foreground segmentation datasets: iCoSeg, DAVIS, and Rooftop. Moreover, it
achieves 91.5\% accuracy in a known semantic segmentation dataset, Cityscapes,
being 74.75 times faster than the original annotation procedure. The appendix
presents additional qualitative results. Code and video demonstration will be
released upon publication.
</p>
<a href="http://arxiv.org/abs/2101.04378" target="_blank">arXiv:2101.04378</a> [<a href="http://arxiv.org/pdf/2101.04378" target="_blank">pdf</a>]

<h2>Robustness of on-device Models: Adversarial Attack to Deep Learning Models on Android Apps. (arXiv:2101.04401v1 [cs.LG])</h2>
<h3>Yujin Huang, Han Hu, Chunyang Chen</h3>
<p>Deep learning has shown its power in many applications, including object
detection in images, natural-language understanding, and speech recognition. To
make it more accessible to end users, many deep learning models are now
embedded in mobile apps. Compared to offloading deep learning from smartphones
to the cloud, performing machine learning on-device can help improve latency,
connectivity, and power consumption. However, most deep learning models within
Android apps can easily be obtained via mature reverse engineering, while the
models' exposure may invite adversarial attacks. In this study, we propose a
simple but effective approach to hacking deep learning models using adversarial
attacks by identifying highly similar pre-trained models from TensorFlow Hub.
All 10 real-world Android apps in the experiment are successfully attacked by
our approach. Apart from the feasibility of the model attack, we also carry out
an empirical study that investigates the characteristics of deep learning
models used by hundreds of Android apps on Google Play. The results show that
many of them are similar to each other and widely use fine-tuning techniques to
pre-trained models on the Internet.
</p>
<a href="http://arxiv.org/abs/2101.04401" target="_blank">arXiv:2101.04401</a> [<a href="http://arxiv.org/pdf/2101.04401" target="_blank">pdf</a>]

<h2>FaceX-Zoo: A PyTorh Toolbox for Face Recognition. (arXiv:2101.04407v1 [cs.CV])</h2>
<h3>Jun Wang, Yinglu Liu, Yibo Hu, Hailin Shi, Tao Mei</h3>
<p>Deep learning based face recognition has achieved significant progress in
recent years. Yet, the practical model production and further research of deep
face recognition are in great need of corresponding public support. For
example, the production of face representation network desires a modular
training scheme to consider the proper choice from various candidates of
state-of-the-art backbone and training supervision subject to the real-world
face recognition demand; for performance analysis and comparison, the standard
and automatic evaluation with a bunch of models on multiple benchmarks will be
a desired tool as well; besides, a public groundwork is welcomed for deploying
the face recognition in the shape of holistic pipeline. Furthermore, there are
some newly-emerged challenges, such as the masked face recognition caused by
the recent world-wide COVID-19 pandemic, which draws increasing attention in
practical applications. A feasible and elegant solution is to build an
easy-to-use unified framework to meet the above demands. To this end, we
introduce a novel open-source framework, named FaceX-Zoo, which is oriented to
the research-development community of face recognition. Resorting to the highly
modular and scalable design, FaceX-Zoo provides a training module with various
supervisory heads and backbones towards state-of-the-art face recognition, as
well as a standardized evaluation module which enables to evaluate the models
in most of the popular benchmarks just by editing a simple configuration. Also,
a simple yet fully functional face SDK is provided for the validation and
primary application of the trained models. Rather than including as many as
possible of the prior techniques, we enable FaceX-Zoo to easily upgrade and
extend along with the development of face related domains. The source code and
models are available at https://github.com/JDAI-CV/FaceX-Zoo.
</p>
<a href="http://arxiv.org/abs/2101.04407" target="_blank">arXiv:2101.04407</a> [<a href="http://arxiv.org/pdf/2101.04407" target="_blank">pdf</a>]

<h2>Reliable Fleet Analytics for Edge IoT Solutions. (arXiv:2101.04414v1 [cs.LG])</h2>
<h3>Emmanuel Raj, Magnus Westerlund, Leonardo Espinosa-Leal</h3>
<p>In recent years we have witnessed a boom in Internet of Things (IoT) device
deployments, which has resulted in big data and demand for low-latency
communication. This shift in the demand for infrastructure is also enabling
real-time decision making using artificial intelligence for IoT applications.
Artificial Intelligence of Things (AIoT) is the combination of Artificial
Intelligence (AI) technologies and the IoT infrastructure to provide robust and
efficient operations and decision making. Edge computing is emerging to enable
AIoT applications. Edge computing enables generating insights and making
decisions at or near the data source, reducing the amount of data sent to the
cloud or a central repository. In this paper, we propose a framework for
facilitating machine learning at the edge for AIoT applications, to enable
continuous delivery, deployment, and monitoring of machine learning models at
the edge (Edge MLOps). The contribution is an architecture that includes
services, tools, and methods for delivering fleet analytics at scale. We
present a preliminary validation of the framework by performing experiments
with IoT devices on a university campus's rooms. For the machine learning
experiments, we forecast multivariate time series for predicting air quality in
the respective rooms by using the models deployed in respective edge devices.
By these experiments, we validate the proposed fleet analytics framework for
efficiency and robustness.
</p>
<a href="http://arxiv.org/abs/2101.04414" target="_blank">arXiv:2101.04414</a> [<a href="http://arxiv.org/pdf/2101.04414" target="_blank">pdf</a>]

<h2>Continental-scale streamflow modeling of basins with reservoirs: a demonstration of effectiveness and a delineation of challenges. (arXiv:2101.04423v1 [cs.LG])</h2>
<h3>Wenyu Ouyang, Kathryn Lawson, Dapeng Feng, Lei Ye, Chi Zhang, Chaopeng Shen</h3>
<p>A large fraction of major waterways have dams influencing streamflow, which
must be accounted for in large-scale hydrologic modeling. However, daily
streamflow prediction for basins with dams is challenging for various modeling
approaches, especially at large scales. Here we took a divide-and-conquer
approach to examine which types of basins could be well represented by a long
short-term memory (LSTM) deep learning model using only readily-available
information. We analyzed data from 3557 basins (83% dammed) over the contiguous
United States and noted strong impacts of reservoir purposes,
capacity-to-runoff ratio (dor), and diversion on streamflow on streamflow
modeling. Surprisingly, while the LSTM model trained on a widely-used
reference-basin dataset performed poorly for more non-reference basins, the
model trained on the whole dataset presented a median test Nash-Sutcliffe
efficiency coefficient (NSE) of 0.74, reaching benchmark-level performance. The
zero-dor, small-dor, and large-dor basins were found to have distinct
behaviors, so migrating models between categories yielded catastrophic results.
However, training with pooled data from different sets yielded optimal median
NSEs of 0.73, 0.78, and 0.71 for these groups, respectively, showing noticeable
advantages over existing models. These results support a coherent, mixed
modeling strategy where smaller dams are modeled as part of rainfall-runoff
processes, but dammed basins must not be treated as reference ones and must be
included in the training set; then, large-dor reservoirs can be represented
explicitly and future work should examine modeling reservoirs for fire
protection and irrigation, followed by those for hydroelectric power
generation, and flood control, etc.
</p>
<a href="http://arxiv.org/abs/2101.04423" target="_blank">arXiv:2101.04423</a> [<a href="http://arxiv.org/pdf/2101.04423" target="_blank">pdf</a>]

<h2>Ergodic Exploration using Tensor Train: Applications in Insertion Tasks. (arXiv:2101.04428v1 [cs.RO])</h2>
<h3>Suhan Shetty, Jo&#xe3;o Silv&#xe9;rio, Sylvain Calinon</h3>
<p>By generating control policies that create natural search behaviors in
autonomous systems, ergodic control provides a principled solution to address
tasks that require exploration. A large class of ergodic control algorithms
relies on spectral analysis, which suffers from the curse of dimensionality,
both in storage and computation. This drawback has prohibited the application
of ergodic control in robot manipulation since it often requires exploration in
state space with more than 2 dimensions. Indeed, the original ergodic control
formulation will typically not allow exploratory behaviors to be generated for
a complete 6D end-effector pose. In this paper, we propose a solution for
ergodic exploration based on the spectral analysis in multidimensional spaces
using low-rank tensor approximation techniques. We rely on tensor train
decomposition, a recent approach from multilinear algebra for low-rank
approximation and efficient computation of multidimensional arrays. The
proposed solution is efficient both computationally and storage-wise, hence
making it suitable for its online implementation in robotic systems. The
approach is applied to a peg-in-hole insertion task using a 7-axis Franka Emika
Panda robot, where ergodic exploration allows the task to be achieved without
requiring the use of force/torque sensors.
</p>
<a href="http://arxiv.org/abs/2101.04428" target="_blank">arXiv:2101.04428</a> [<a href="http://arxiv.org/pdf/2101.04428" target="_blank">pdf</a>]

<h2>Automatic Extrinsic Calibration Method for LiDAR and Camera Sensor Setups. (arXiv:2101.04431v1 [cs.RO])</h2>
<h3>Jorge Beltr&#xe1;n, Carlos Guindel, Fernando Garc&#xed;a</h3>
<p>Most sensor setups for onboard autonomous perception are composed of LiDARs
and vision systems, as they provide complementary information that improves the
reliability of the different algorithms necessary to obtain a robust scene
understanding. However, the effective use of information from different sources
requires an accurate calibration between the sensors involved, which usually
implies a tedious and burdensome process. We present a method to calibrate the
extrinsic parameters of any pair of sensors involving LiDARs, monocular or
stereo cameras, of the same or different modalities. The procedure is composed
of two stages: first, reference points belonging to a custom calibration target
are extracted from the data provided by the sensors to be calibrated, and
second, the optimal rigid transformation is found through the registration of
both point sets. The proposed approach can handle devices with very different
resolutions and poses, as usually found in vehicle setups. In order to assess
the performance of the proposed method, a novel evaluation suite built on top
of a popular simulation framework is introduced. Experiments on the synthetic
environment show that our calibration algorithm significantly outperforms
existing methods, whereas real data tests corroborate the results obtained in
the evaluation suite. Open-source code is available at
https://github.com/beltransen/velo2cam_calibration
</p>
<a href="http://arxiv.org/abs/2101.04431" target="_blank">arXiv:2101.04431</a> [<a href="http://arxiv.org/pdf/2101.04431" target="_blank">pdf</a>]

<h2>Developing an OpenAI Gym-compatible framework and simulation environment for testing Deep Reinforcement Learning agents solving the Ambulance Location Problem. (arXiv:2101.04434v1 [cs.LG])</h2>
<h3>Michael Allen, Kerry Pearn, Tom Monks</h3>
<p>Background and motivation: Deep Reinforcement Learning (Deep RL) is a rapidly
developing field. Historically most application has been made to games (such as
chess, Atari games, and go). Deep RL is now reaching the stage where it may
offer value in real world problems, including optimisation of healthcare
systems. One such problem is where to locate ambulances between calls in order
to minimise time from emergency call to ambulance on-scene. This is known as
the Ambulance Location problem.

Aim: To develop an OpenAI Gym-compatible framework and simulation environment
for testing Deep RL agents.

Methods: A custom ambulance dispatch simulation environment was developed
using OpenAI Gym and SimPy. Deep RL agents were built using PyTorch. The
environment is a simplification of the real world, but allows control over the
number of clusters of incident locations, number of possible dispatch
locations, number of hospitals, and creating incidents that occur at different
locations throughout each day.

Results: A range of Deep RL agents based on Deep Q networks were tested in
this custom environment. All reduced time to respond to emergency calls
compared with random allocation to dispatch points. Bagging Noisy Duelling Deep
Q networks gave the most consistence performance. All methods had a tendency to
lose performance if trained for too long, and so agents were saved at their
optimal performance (and tested on independent simulation runs).

Conclusion: Deep RL agents, developed using simulated environments, have the
potential to offer a novel approach to optimise the Ambulance Location problem.
Creating open simulation environments should allow more rapid progress in this
field.
</p>
<a href="http://arxiv.org/abs/2101.04434" target="_blank">arXiv:2101.04434</a> [<a href="http://arxiv.org/pdf/2101.04434" target="_blank">pdf</a>]

<h2>Joint Demosaicking and Denoising in the Wild: The Case of Training Under Ground Truth Uncertainty. (arXiv:2101.04442v1 [cs.CV])</h2>
<h3>Jierun Chen, Song Wen, S.-H. Gary Chan</h3>
<p>Image demosaicking and denoising are the two key fundamental steps in digital
camera pipelines, aiming to reconstruct clean color images from noisy luminance
readings. In this paper, we propose and study Wild-JDD, a novel learning
framework for joint demosaicking and denoising in the wild. In contrast to
previous works which generally assume the ground truth of training data is a
perfect reflection of the reality, we consider here the more common imperfect
case of ground truth uncertainty in the wild. We first illustrate its
manifestation as various kinds of artifacts including zipper effect, color
moire and residual noise. Then we formulate a two-stage data degradation
process to capture such ground truth uncertainty, where a conjugate prior
distribution is imposed upon a base distribution. After that, we derive an
evidence lower bound (ELBO) loss to train a neural network that approximates
the parameters of the conjugate prior distribution conditioned on the degraded
input. Finally, to further enhance the performance for out-of-distribution
input, we design a simple but effective fine-tuning strategy by taking the
input as a weakly informative prior. Taking into account ground truth
uncertainty, Wild-JDD enjoys good interpretability during optimization.
Extensive experiments validate that it outperforms state-of-the-art schemes on
joint demosaicking and denoising tasks on both synthetic and realistic raw
datasets.
</p>
<a href="http://arxiv.org/abs/2101.04442" target="_blank">arXiv:2101.04442</a> [<a href="http://arxiv.org/pdf/2101.04442" target="_blank">pdf</a>]

<h2>Sound Event Detection with Binary Neural Networks on Tightly Power-Constrained IoT Devices. (arXiv:2101.04446v1 [cs.LG])</h2>
<h3>Gianmarco Cerutti, Renzo Andri, Lukas Cavigelli, Michele Magno, Elisabetta Farella, Luca Benini</h3>
<p>Sound event detection (SED) is a hot topic in consumer and smart city
applications. Existing approaches based on Deep Neural Networks are very
effective, but highly demanding in terms of memory, power, and throughput when
targeting ultra-low power always-on devices.

Latency, availability, cost, and privacy requirements are pushing recent IoT
systems to process the data on the node, close to the sensor, with a very
limited energy supply, and tight constraints on the memory size and processing
capabilities precluding to run state-of-the-art DNNs.

In this paper, we explore the combination of extreme quantization to a
small-footprint binary neural network (BNN) with the highly energy-efficient,
RISC-V-based (8+1)-core GAP8 microcontroller. Starting from an existing CNN for
SED whose footprint (815 kB) exceeds the 512 kB of memory available on our
platform, we retrain the network using binary filters and activations to match
these memory constraints. (Fully) binary neural networks come with a natural
drop in accuracy of 12-18% on the challenging ImageNet object recognition
challenge compared to their equivalent full-precision baselines. This BNN
reaches a 77.9% accuracy, just 7% lower than the full-precision version, with
58 kB (7.2 times less) for the weights and 262 kB (2.4 times less) memory in
total. With our BNN implementation, we reach a peak throughput of 4.6 GMAC/s
and 1.5 GMAC/s over the full network, including preprocessing with Mel bins,
which corresponds to an efficiency of 67.1 GMAC/s/W and 31.3 GMAC/s/W,
respectively. Compared to the performance of an ARM Cortex-M4 implementation,
our system has a 10.3 times faster execution time and a 51.1 times higher
energy-efficiency.
</p>
<a href="http://arxiv.org/abs/2101.04446" target="_blank">arXiv:2101.04446</a> [<a href="http://arxiv.org/pdf/2101.04446" target="_blank">pdf</a>]

<h2>Two-stage CNN-based wood log recognition. (arXiv:2101.04450v1 [cs.CV])</h2>
<h3>Georg Wimmer, Rudolf Schraml, Heinz Hofbauer, Alexander Petutschnigg, Andreas Uhl</h3>
<p>The proof of origin of logs is becoming increasingly important. In the
context of Industry 4.0 and to combat illegal logging there is an increasing
motivation to track each individual log. Our previous works in this field
focused on log tracking using digital log end images based on methods inspired
by fingerprint and iris-recognition. This work presents a convolutional neural
network (CNN) based approach which comprises a CNN-based segmentation of the
log end combined with a final CNN-based recognition of the segmented log end
using the triplet loss function for CNN training. Results show that the
proposed two-stage CNN-based approach outperforms traditional approaches.
</p>
<a href="http://arxiv.org/abs/2101.04450" target="_blank">arXiv:2101.04450</a> [<a href="http://arxiv.org/pdf/2101.04450" target="_blank">pdf</a>]

<h2>Learning Intuitive Physics with Multimodal Generative Models. (arXiv:2101.04454v1 [cs.LG])</h2>
<h3>Sahand Rezaei-Shoshtari, Francois Robert Hogan, Michael Jenkin, David Meger, Gregory Dudek</h3>
<p>Predicting the future interaction of objects when they come into contact with
their environment is key for autonomous agents to take intelligent and
anticipatory actions. This paper presents a perception framework that fuses
visual and tactile feedback to make predictions about the expected motion of
objects in dynamic scenes. Visual information captures object properties such
as 3D shape and location, while tactile information provides critical cues
about interaction forces and resulting object motion when it makes contact with
the environment. Utilizing a novel See-Through-your-Skin (STS) sensor that
provides high resolution multimodal sensing of contact surfaces, our system
captures both the visual appearance and the tactile properties of objects. We
interpret the dual stream signals from the sensor using a Multimodal
Variational Autoencoder (MVAE), allowing us to capture both modalities of
contacting objects and to develop a mapping from visual to tactile interaction
and vice-versa. Additionally, the perceptual system can be used to infer the
outcome of future physical interactions, which we validate through simulated
and real-world experiments in which the resting state of an object is predicted
from given initial conditions.
</p>
<a href="http://arxiv.org/abs/2101.04454" target="_blank">arXiv:2101.04454</a> [<a href="http://arxiv.org/pdf/2101.04454" target="_blank">pdf</a>]

<h2>Type4Py: Deep Similarity Learning-Based Type Inference for Python. (arXiv:2101.04470v1 [cs.LG])</h2>
<h3>Amir M. Mir, Evaldas Latoskinas, Sebastian Proksch, Georgios Gousios</h3>
<p>Dynamic languages, such as Python and Javascript, trade static typing for
developer flexibility. While this allegedly enables greater productivity, lack
of static typing can cause runtime exceptions, type inconsistencies, and is a
major factor for weak IDE support. To alleviate these issues, PEP 484
introduced optional type annotations for Python. As retrofitting types to
existing codebases is error-prone and laborious, learning-based approaches have
been proposed to enable automatic type annotations based on existing, partially
annotated codebases. However, the prediction of rare and user-defined types is
still challenging. In this paper, we present Type4Py, a deep similarity
learning-based type inference model for Python. We design a hierarchical neural
network model that learns to discriminate between types of the same kind and
dissimilar types in a high-dimensional space, which results in clusters of
types. Nearest neighbor search suggests likely type signatures of given Python
functions. The types visible to analyzed modules are surfaced using lightweight
dependency analysis. The results of quantitative and qualitative evaluation
indicate that Type4Py significantly outperforms state-of-the-art approaches at
the type prediction task. Considering the Top-1 prediction, Type4Py obtains
19.33% and 13.49% higher precision than Typilus and TypeWriter, respectively,
while utilizing a much bigger vocabulary.
</p>
<a href="http://arxiv.org/abs/2101.04470" target="_blank">arXiv:2101.04470</a> [<a href="http://arxiv.org/pdf/2101.04470" target="_blank">pdf</a>]

<h2>PvDeConv: Point-Voxel Deconvolution for Autoencoding CAD Construction in 3D. (arXiv:2101.04493v1 [cs.CV])</h2>
<h3>Kseniya Cherenkova, Djamila Aouada, Gleb Gusev</h3>
<p>We propose a Point-Voxel DeConvolution (PVDeConv) module for 3D data
autoencoder. To demonstrate its efficiency we learn to synthesize
high-resolution point clouds of 10k points that densely describe the underlying
geometry of Computer Aided Design (CAD) models. Scanning artifacts, such as
protrusions, missing parts, smoothed edges and holes, inevitably appear in real
3D scans of fabricated CAD objects. Learning the original CAD model
construction from a 3D scan requires a ground truth to be available together
with the corresponding 3D scan of an object. To solve the gap, we introduce a
new dedicated dataset, the CC3D, containing 50k+ pairs of CAD models and their
corresponding 3D meshes. This dataset is used to learn a convolutional
autoencoder for point clouds sampled from the pairs of 3D scans - CAD models.
The challenges of this new dataset are demonstrated in comparison with other
generative point cloud sampling models trained on ShapeNet. The CC3D
autoencoder is efficient with respect to memory consumption and training time
as compared to stateof-the-art models for 3D data generation.
</p>
<a href="http://arxiv.org/abs/2101.04493" target="_blank">arXiv:2101.04493</a> [<a href="http://arxiv.org/pdf/2101.04493" target="_blank">pdf</a>]

<h2>UFA-FUSE: A novel deep supervised and hybrid model for multi-focus image fusion. (arXiv:2101.04506v1 [cs.CV])</h2>
<h3>Yongsheng Zang, Dongming Zhou, Changcheng Wang, Rencan Nie, Yanbu Guo</h3>
<p>Traditional and deep learning-based fusion methods generated the intermediate
decision map to obtain the fusion image through a series of post-processing
procedures. However, the fusion results generated by these methods are easy to
lose some source image details or results in artifacts. Inspired by the image
reconstruction techniques based on deep learning, we propose a multi-focus
image fusion network framework without any post-processing to solve these
problems in the end-to-end and supervised learning way. To sufficiently train
the fusion model, we have generated a large-scale multi-focus image dataset
with ground-truth fusion images. What's more, to obtain a more informative
fusion image, we further designed a novel fusion strategy based on unity fusion
attention, which is composed of a channel attention module and a spatial
attention module. Specifically, the proposed fusion approach mainly comprises
three key components: feature extraction, feature fusion and image
reconstruction. We firstly utilize seven convolutional blocks to extract the
image features from source images. Then, the extracted convolutional features
are fused by the proposed fusion strategy in the feature fusion layer. Finally,
the fused image features are reconstructed by four convolutional blocks.
Experimental results demonstrate that the proposed approach for multi-focus
image fusion achieves remarkable fusion performance compared to 19
state-of-the-art fusion methods.
</p>
<a href="http://arxiv.org/abs/2101.04506" target="_blank">arXiv:2101.04506</a> [<a href="http://arxiv.org/pdf/2101.04506" target="_blank">pdf</a>]

<h2>A Unified Framework for Online Trip Destination Prediction. (arXiv:2101.04520v1 [cs.LG])</h2>
<h3>Victor Eberstein, Jonas Sj&#xf6;blom, Nikolce Murgovski, Morteza Haghir Chehreghani</h3>
<p>Trip destination prediction is an area of increasing importance in many
applications such as trip planning, autonomous driving and electric vehicles.
Even though this problem could be naturally addressed in an online learning
paradigm where data is arriving in a sequential fashion, the majority of
research has rather considered the offline setting. In this paper, we present a
unified framework for trip destination prediction in an online setting, which
is suitable for both online training and online prediction. For this purpose,
we develop two clustering algorithms and integrate them within two online
prediction models for this problem.

We investigate the different configurations of clustering algorithms and
prediction models on a real-world dataset. By using traditional clustering
metrics and accuracy, we demonstrate that both the clustering and the entire
framework yield consistent results compared to the offline setting. Finally, we
propose a novel regret metric for evaluating the entire online framework in
comparison to its offline counterpart. This metric makes it possible to relate
the source of erroneous predictions to either the clustering or the prediction
model. Using this metric, we show that the proposed methods converge to a
probability distribution resembling the true underlying distribution and enjoy
a lower regret than all of the baselines.
</p>
<a href="http://arxiv.org/abs/2101.04520" target="_blank">arXiv:2101.04520</a> [<a href="http://arxiv.org/pdf/2101.04520" target="_blank">pdf</a>]

<h2>Measuring Recommender System Effects with Simulated Users. (arXiv:2101.04526v1 [cs.LG])</h2>
<h3>Sirui Yao, Yoni Halpern, Nithum Thain, Xuezhi Wang, Kang Lee, Flavien Prost, Ed H. Chi, Jilin Chen, Alex Beutel</h3>
<p>Imagine a food recommender system -- how would we check if it is
\emph{causing} and fostering unhealthy eating habits or merely reflecting
users' interests? How much of a user's experience over time with a recommender
is caused by the recommender system's choices and biases, and how much is based
on the user's preferences and biases? Popularity bias and filter bubbles are
two of the most well-studied recommender system biases, but most of the prior
research has focused on understanding the system behavior in a single
recommendation step. How do these biases interplay with user behavior, and what
types of user experiences are created from repeated interactions?

In this work, we offer a simulation framework for measuring the impact of a
recommender system under different types of user behavior. Using this
simulation framework, we can (a) isolate the effect of the recommender system
from the user preferences, and (b) examine how the system performs not just on
average for an "average user" but also the extreme experiences under atypical
user behavior. As part of the simulation framework, we propose a set of
evaluation metrics over the simulations to understand the recommender system's
behavior. Finally, we present two empirical case studies -- one on traditional
collaborative filtering in MovieLens and one on a large-scale production
recommender system -- to understand how popularity bias manifests over time.
</p>
<a href="http://arxiv.org/abs/2101.04526" target="_blank">arXiv:2101.04526</a> [<a href="http://arxiv.org/pdf/2101.04526" target="_blank">pdf</a>]

<h2>Data augmentation and feature selection for automatic model recommendation in computational physics. (arXiv:2101.04530v1 [stat.ML])</h2>
<h3>Thomas Daniel, Fabien Casenave, Nissrine Akkari, David Ryckelynck</h3>
<p>Classification algorithms have recently found applications in computational
physics for the selection of numerical methods or models adapted to the
environment and the state of the physical system. For such classification
tasks, labeled training data come from numerical simulations and generally
correspond to physical fields discretized on a mesh. Three challenging
difficulties arise: the lack of training data, their high dimensionality, and
the non-applicability of common data augmentation techniques to physics data.
This article introduces two algorithms to address these issues, one for
dimensionality reduction via feature selection, and one for data augmentation.
These algorithms are combined with a wide variety of classifiers for their
evaluation. When combined with a stacking ensemble made of six multilayer
perceptrons and a ridge logistic regression, they enable reaching an accuracy
of 90% on our classification problem for nonlinear structural mechanics.
</p>
<a href="http://arxiv.org/abs/2101.04530" target="_blank">arXiv:2101.04530</a> [<a href="http://arxiv.org/pdf/2101.04530" target="_blank">pdf</a>]

<h2>Adversary Instantiation: Lower Bounds for Differentially Private Machine Learning. (arXiv:2101.04535v1 [cs.LG])</h2>
<h3>Milad Nasr, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, Nicholas Carlini</h3>
<p>Differentially private (DP) machine learning allows us to train models on
private data while limiting data leakage. DP formalizes this data leakage
through a cryptographic game, where an adversary must predict if a model was
trained on a dataset D, or a dataset D' that differs in just one example.If
observing the training algorithm does not meaningfully increase the adversary's
odds of successfully guessing which dataset the model was trained on, then the
algorithm is said to be differentially private. Hence, the purpose of privacy
analysis is to upper bound the probability that any adversary could
successfully guess which dataset the model was trained on.In our paper, we
instantiate this hypothetical adversary in order to establish lower bounds on
the probability that this distinguishing game can be won. We use this adversary
to evaluate the importance of the adversary capabilities allowed in the privacy
analysis of DP training algorithms.For DP-SGD, the most common method for
training neural networks with differential privacy, our lower bounds are tight
and match the theoretical upper bound. This implies that in order to prove
better upper bounds, it will be necessary to make use of additional
assumptions. Fortunately, we find that our attacks are significantly weaker
when additional (realistic)restrictions are put in place on the adversary's
capabilities.Thus, in the practical setting common to many real-world
deployments, there is a gap between our lower bounds and the upper bounds
provided by the analysis: differential privacy is conservative and adversaries
may not be able to leak as much information as suggested by the theoretical
bound.
</p>
<a href="http://arxiv.org/abs/2101.04535" target="_blank">arXiv:2101.04535</a> [<a href="http://arxiv.org/pdf/2101.04535" target="_blank">pdf</a>]

<h2>Resolution invariant person reid based on feature transformation and self-weighted attention. (arXiv:2101.04544v1 [cs.CV])</h2>
<h3>Ziyue Zhang, Shuai Jiang, Congzhentao Huang, Richard Yi Da Xu</h3>
<p>Person Re-identification (ReID) is a critical computer vision task that aims
to match the same person in images or video sequences. Most current works focus
on settings where resolution is kept the same. However, the resolution is a
crucial factor in person ReID when the cameras are at different distances from
the person or the camera's model are different from each other. In this paper,
we propose a novel two-stream network with a lightweight resolution association
ReID feature transformation (RAFT) module and a self-weighted attention (SWA)
ReID module to evaluate features under different resolutions. RAFT transforms
the low resolution features to corresponding high resolution features. SWA
evaluates both features to get weight factors for the person ReID. Both modules
are jointly trained to get a resolution invariant representation. Extensive
experiments on five benchmark datasets show the effectiveness of our method.
For instance, we achieve Rank-1 accuracy of 43.3% and 83.2% on CAVIAR and
MLR-CUHK03, outperforming the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2101.04544" target="_blank">arXiv:2101.04544</a> [<a href="http://arxiv.org/pdf/2101.04544" target="_blank">pdf</a>]

<h2>Fine-grained Semantic Constraint in Image Synthesis. (arXiv:2101.04558v1 [cs.CV])</h2>
<h3>Pengyang Li, Donghui Wang</h3>
<p>In this paper, we propose a multi-stage and high-resolution model for image
synthesis that uses fine-grained attributes and masks as input. With a
fine-grained attribute, the proposed model can detailedly constrain the
features of the generated image through rich and fine-grained semantic
information in the attribute. With mask as prior, the model in this paper is
constrained so that the generated images conform to visual senses, which will
reduce the unexpected diversity of samples generated from the generative
adversarial network. This paper also proposes a scheme to improve the
discriminator of the generative adversarial network by simultaneously
discriminating the total image and sub-regions of the image. In addition, we
propose a method for optimizing the labeled attribute in datasets, which
reduces the manual labeling noise. Extensive quantitative results show that our
image synthesis model generates more realistic images.
</p>
<a href="http://arxiv.org/abs/2101.04558" target="_blank">arXiv:2101.04558</a> [<a href="http://arxiv.org/pdf/2101.04558" target="_blank">pdf</a>]

<h2>Hyperbolic Deep Neural Networks: A Survey. (arXiv:2101.04562v1 [cs.LG])</h2>
<h3>Wei Peng, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, Guoying Zhao</h3>
<p>Recently, there has been a raising surge of momentum for deep representation
learning in hyperbolic spaces due to theirhigh capacity of modeling data like
knowledge graphs or synonym hierarchies, possessing hierarchical structure. We
refer it ashyperbolic deep neural network in this paper. Such a hyperbolic
neural architecture potentially leads to drastically compact models withmuch
more physical interpretability than its counterpart in Euclidean space. To
stimulate future research, this paper presents acoherent and comprehensive
review of the literature around the neural components in the construction of
hyperbolic deep neuralnetworks, as well as the generalization of the leading
deep approaches to the Hyperbolic space. It also presents current
applicationsaround various machine learning tasks on several publicly available
datasets, together with insightful observations and identifying openquestions
and promising future directions.
</p>
<a href="http://arxiv.org/abs/2101.04562" target="_blank">arXiv:2101.04562</a> [<a href="http://arxiv.org/pdf/2101.04562" target="_blank">pdf</a>]

<h2>Discriminative Noise Robust Sparse Orthogonal Label Regression-based Domain Adaptation. (arXiv:2101.04563v1 [cs.CV])</h2>
<h3>Lingkun Luo, Liming Chen, Shiqiang Hu</h3>
<p>Domain adaptation (DA) aims to enable a learning model trained from a source
domain to generalize well on a target domain, despite the mismatch of data
distributions between the two domains. State-of-the-art DA methods have so far
focused on the search of a latent shared feature space where source and target
domain data can be aligned either statistically and/or geometrically. In this
paper, we propose a novel unsupervised DA method, namely Discriminative Noise
Robust Sparse Orthogonal Label Regression-based Domain Adaptation (DOLL-DA).
The proposed DOLL-DA derives from a novel integrated model which searches a
shared feature subspace where source and target domain data are, through
optimization of some repulse force terms, discriminatively aligned
statistically, while at same time regresses orthogonally data labels thereof
using a label embedding trick. Furthermore, in minimizing a novel Noise Robust
Sparse Orthogonal Label Regression(NRS_OLR) term, the proposed model explicitly
accounts for data outliers to avoid negative transfer and introduces the
property of sparsity when regressing data labels.

Due to the character restriction. Please read our detailed abstract in our
paper.
</p>
<a href="http://arxiv.org/abs/2101.04563" target="_blank">arXiv:2101.04563</a> [<a href="http://arxiv.org/pdf/2101.04563" target="_blank">pdf</a>]

<h2>Superpixel-based Refinement for Object Proposal Generation. (arXiv:2101.04574v1 [cs.CV])</h2>
<h3>Christian Wilms, Simone Frintrop</h3>
<p>Precise segmentation of objects is an important problem in tasks like
class-agnostic object proposal generation or instance segmentation. Deep
learning-based systems usually generate segmentations of objects based on
coarse feature maps, due to the inherent downsampling in CNNs. This leads to
segmentation boundaries not adhering well to the object boundaries in the
image. To tackle this problem, we introduce a new superpixel-based refinement
approach on top of the state-of-the-art object proposal system AttentionMask.
The refinement utilizes superpixel pooling for feature extraction and a novel
superpixel classifier to determine if a high precision superpixel belongs to an
object or not. Our experiments show an improvement of up to 26.0% in terms of
average recall compared to original AttentionMask. Furthermore, qualitative and
quantitative analyses of the segmentations reveal significant improvements in
terms of boundary adherence for the proposed refinement compared to various
deep learning-based state-of-the-art object proposal generation systems.
</p>
<a href="http://arxiv.org/abs/2101.04574" target="_blank">arXiv:2101.04574</a> [<a href="http://arxiv.org/pdf/2101.04574" target="_blank">pdf</a>]

<h2>Machine Learning for Initial Value Problems of Parameter-Dependent Dynamical Systems. (arXiv:2101.04595v1 [cs.LG])</h2>
<h3>Roland Pulch, Maha Youssef</h3>
<p>We consider initial value problems of nonlinear dynamical systems, which
include physical parameters. A quantity of interest depending on the solution
is observed. A discretisation yields the trajectories of the quantity of
interest in many time points. We examine the mapping from the set of parameters
to the discrete values of the trajectories. An evaluation of this mapping
requires to solve an initial value problem. Alternatively, we determine an
approximation, where the evaluation requires low computation work, using a
concept of machine learning. We employ feedforward neural networks, which are
fitted to data from samples of the trajectories. Results of numerical
computations are presented for a test example modelling an electric circuit.
</p>
<a href="http://arxiv.org/abs/2101.04595" target="_blank">arXiv:2101.04595</a> [<a href="http://arxiv.org/pdf/2101.04595" target="_blank">pdf</a>]

<h2>Predicting Relative Depth between Objects from Semantic Features. (arXiv:2101.04626v1 [cs.CV])</h2>
<h3>Stefan Cassar, Adrian Muscat, Dylan Seychell</h3>
<p>Vision and language tasks such as Visual Relation Detection and Visual
Question Answering benefit from semantic features that afford proper grounding
of language. The 3D depth of objects depicted in 2D images is one such feature.
However it is very difficult to obtain accurate depth information without
learning the appropriate features, which are scene dependent. The state of the
art in this area are complex Neural Network models trained on stereo image data
to predict depth per pixel. Fortunately, in some tasks, its only the relative
depth between objects that is required. In this paper the extent to which
semantic features can predict course relative depth is investigated. The
problem is casted as a classification one and geometrical features based on
object bounding boxes, object labels and scene attributes are computed and used
as inputs to pattern recognition models to predict relative depth. i.e behind,
in-front and neutral. The results are compared to those obtained from averaging
the output of the monodepth neural network model, which represents the
state-of-the art. An overall increase of 14% in relative depth accuracy over
relative depth computed from the monodepth model derived results is achieved.
</p>
<a href="http://arxiv.org/abs/2101.04626" target="_blank">arXiv:2101.04626</a> [<a href="http://arxiv.org/pdf/2101.04626" target="_blank">pdf</a>]

<h2>Queue-Learning: A Reinforcement Learning Approach for Providing Quality of Service. (arXiv:2101.04627v1 [cs.LG])</h2>
<h3>Majid Raeis, Ali Tizghadam, Alberto Leon-Garcia</h3>
<p>End-to-end delay is a critical attribute of quality of service (QoS) in
application domains such as cloud computing and computer networks. This metric
is particularly important in tandem service systems, where the end-to-end
service is provided through a chain of services. Service-rate control is a
common mechanism for providing QoS guarantees in service systems. In this
paper, we introduce a reinforcement learning-based (RL-based) service-rate
controller that provides probabilistic upper-bounds on the end-to-end delay of
the system, while preventing the overuse of service resources. In order to have
a general framework, we use queueing theory to model the service systems.
However, we adopt an RL-based approach to avoid the limitations of
queueing-theoretic methods. In particular, we use Deep Deterministic Policy
Gradient (DDPG) to learn the service rates (action) as a function of the queue
lengths (state) in tandem service systems. In contrast to existing RL-based
methods that quantify their performance by the achieved overall reward, which
could be hard to interpret or even misleading, our proposed controller provides
explicit probabilistic guarantees on the end-to-end delay of the system. The
evaluations are presented for a tandem queueing system with non-exponential
inter-arrival and service times, the results of which validate our controller's
capability in meeting QoS constraints.
</p>
<a href="http://arxiv.org/abs/2101.04627" target="_blank">arXiv:2101.04627</a> [<a href="http://arxiv.org/pdf/2101.04627" target="_blank">pdf</a>]

<h2>Context Matters: Self-Attention for Sign Language Recognition. (arXiv:2101.04632v1 [cs.CV])</h2>
<h3>Fares Ben Slimane, Mohamed Bouguessa</h3>
<p>This paper proposes an attentional network for the task of Continuous Sign
Language Recognition. The proposed approach exploits co-independent streams of
data to model the sign language modalities. These different channels of
information can share a complex temporal structure between each other. For that
reason, we apply attention to synchronize and help capture entangled
dependencies between the different sign language components. Even though Sign
Language is multi-channel, handshapes represent the central entities in sign
interpretation. Seeing handshapes in their correct context defines the meaning
of a sign. Taking that into account, we utilize the attention mechanism to
efficiently aggregate the hand features with their appropriate spatio-temporal
context for better sign recognition. We found that by doing so the model is
able to identify the essential Sign Language components that revolve around the
dominant hand and the face areas. We test our model on the benchmark dataset
RWTH-PHOENIX-Weather 2014, yielding competitive results.
</p>
<a href="http://arxiv.org/abs/2101.04632" target="_blank">arXiv:2101.04632</a> [<a href="http://arxiv.org/pdf/2101.04632" target="_blank">pdf</a>]

<h2>Automated Respiratory Event Detection Using Deep Neural Networks. (arXiv:2101.04635v1 [cs.LG])</h2>
<h3>Thijs E Nassi, Wolfgang Ganglberger, Haoqi Sun, Abigail A Bucklin, Siddharth Biswal, Michel J A M van Putten, Robert J Thomas, M Brandon Westover</h3>
<p>The gold standard to assess respiration during sleep is polysomnography; a
technique that is burdensome, expensive (both in analysis time and measurement
costs), and difficult to repeat. Automation of respiratory analysis can improve
test efficiency and enable accessible implementation opportunities worldwide.
Using 9,656 polysomnography recordings from the Massachusetts General Hospital
(MGH), we trained a neural network (WaveNet) based on a single respiratory
effort belt to detect obstructive apnea, central apnea, hypopnea and
respiratory-effort related arousals. Performance evaluation included
event-based and recording-based metrics - using an apnea-hypopnea index
analysis. The model was further evaluated on a public dataset, the
Sleep-Heart-Health-Study-1, containing 8,455 polysomnographic recordings. For
binary apnea event detection in the MGH dataset, the neural network obtained an
accuracy of 95%, an apnea-hypopnea index $r^2$ of 0.89 and area under the curve
for the receiver operating characteristics curve and precision-recall curve of
0.93 and 0.74, respectively. For the multiclass task, we obtained varying
performances: 81% of all labeled central apneas were correctly classified,
whereas this metric was 46% for obstructive apneas, 29% for respiratory effort
related arousals and 16% for hypopneas. The majority of false predictions were
misclassifications as another type of respiratory event. Our fully automated
method can detect respiratory events and assess the apnea-hypopnea index with
sufficient accuracy for clinical utilization. Differentiation of event types is
more difficult and may reflect in part the complexity of human respiratory
output and some degree of arbitrariness in the clinical thresholds and criteria
used during manual annotation.
</p>
<a href="http://arxiv.org/abs/2101.04635" target="_blank">arXiv:2101.04635</a> [<a href="http://arxiv.org/pdf/2101.04635" target="_blank">pdf</a>]

<h2>The Multimodal Driver Monitoring Database: A Naturalistic Corpus to Study Driver Attention. (arXiv:2101.04639v1 [cs.CV])</h2>
<h3>Sumit Jha, Mohamed F. Marzban, Tiancheng Hu, Mohamed H. Mahmoud, Naofal Al-Dhahir Carlos Busso</h3>
<p>A smart vehicle should be able to monitor the actions and behaviors of the
human driver to provide critical warnings or intervene when necessary. Recent
advancements in deep learning and computer vision have shown great promise in
monitoring human behaviors and activities. While these algorithms work well in
a controlled environment, naturalistic driving conditions add new challenges
such as illumination variations, occlusions and extreme head poses. A vast
amount of in-domain data is required to train models that provide high
performance in predicting driving related tasks to effectively monitor driver
actions and behaviors. Toward building the required infrastructure, this paper
presents the multimodal driver monitoring (MDM) dataset, which was collected
with 59 subjects that were recorded performing various tasks. We use the Fi-
Cap device that continuously tracks the head movement of the driver using
fiducial markers, providing frame-based annotations to train head pose
algorithms in naturalistic driving conditions. We ask the driver to look at
predetermined gaze locations to obtain accurate correlation between the
driver's facial image and visual attention. We also collect data when the
driver performs common secondary activities such as navigation using a smart
phone and operating the in-car infotainment system. All of the driver's
activities are recorded with high definition RGB cameras and time-of-flight
depth camera. We also record the controller area network-bus (CAN-Bus),
extracting important information. These high quality recordings serve as the
ideal resource to train various efficient algorithms for monitoring the driver,
providing further advancements in the field of in-vehicle safety systems.
</p>
<a href="http://arxiv.org/abs/2101.04639" target="_blank">arXiv:2101.04639</a> [<a href="http://arxiv.org/pdf/2101.04639" target="_blank">pdf</a>]

<h2>Dimensions of Commonsense Knowledge. (arXiv:2101.04640v1 [cs.AI])</h2>
<h3>Filip Ilievski, Alessandro Oltramari, Kaixin Ma, Bin Zhang, Deborah L. McGuinness, Pedro Szekely</h3>
<p>Commonsense knowledge is essential for many AI applications, including those
in natural language processing, visual processing, and planning. Consequently,
many sources that include commonsense knowledge have been designed and
constructed over the past decades. Recently, the focus has been on large
text-based sources, which facilitate easier integration with neural (language)
models and application on textual tasks, typically at the expense of the
semantics of the sources. Such practice prevents the harmonization of these
sources, understanding their coverage and gaps, and may hinder the semantic
alignment of their knowledge with downstream tasks. Efforts to consolidate
commonsense knowledge have yielded partial success, but provide no clear path
towards a comprehensive consolidation of existing commonsense knowledge.

The ambition of this paper is to organize these sources around a common set
of dimensions of commonsense knowledge. For this purpose, we survey a wide
range of popular commonsense sources with a special focus on their relations.
We consolidate these relations into 13 knowledge dimensions, each abstracting
over more specific relations found in sources. This consolidation allows us to
unify the separate sources and to compute indications of their coverage,
overlap, and gaps with respect to the knowledge dimensions. Moreover, we
analyze the impact of each dimension on downstream reasoning tasks that require
commonsense knowledge, observing that the temporal and desire/goal dimensions
are very beneficial for reasoning on current downstream tasks, while
distinctness and lexical knowledge have little impact. These results reveal
focus towards some dimensions in current evaluation, and potential neglect of
others.
</p>
<a href="http://arxiv.org/abs/2101.04640" target="_blank">arXiv:2101.04640</a> [<a href="http://arxiv.org/pdf/2101.04640" target="_blank">pdf</a>]

<h2>Double-Adversarial Activation Anomaly Detection: Adversarial Autoencoders are Anomaly Generators. (arXiv:2101.04645v1 [cs.LG])</h2>
<h3>J.-P. Schulze, P. Sperl, K. B&#xf6;ttinger</h3>
<p>Anomaly detection is a challenging task for machine learning algorithms due
to the inherent class imbalance. It is costly and time-demanding to manually
analyse the observed data, thus usually only few known anomalies if any are
available. Inspired by generative models and the analysis of the hidden
activations of neural networks, we introduce a novel unsupervised anomaly
detection method called DA3D. Here, we use adversarial autoencoders to generate
anomalous counterexamples based on the normal data only. These artificial
anomalies used during training allow the detection of real, yet unseen
anomalies. With our novel generative approach, we transform the unsupervised
task of anomaly detection to a supervised one, which is more tractable by
machine learning and especially deep learning methods. DA3D surpasses the
performance of state-of-the-art anomaly detection methods in a purely
data-driven way, where no domain knowledge is required.
</p>
<a href="http://arxiv.org/abs/2101.04645" target="_blank">arXiv:2101.04645</a> [<a href="http://arxiv.org/pdf/2101.04645" target="_blank">pdf</a>]

<h2>Benchmarking Simulation-Based Inference. (arXiv:2101.04653v1 [stat.ML])</h2>
<h3>Jan-Matthis Lueckmann, Jan Boelts, David S. Greenberg, Pedro J. Gon&#xe7;alves, Jakob H. Macke</h3>
<p>Recent advances in probabilistic modelling have led to a large number of
simulation-based inference algorithms which do not require numerical evaluation
of likelihoods. However, a public benchmark with appropriate performance
metrics for such 'likelihood-free' algorithms has been lacking. This has made
it difficult to compare algorithms and identify their strengths and weaknesses.
We set out to fill this gap: We provide a benchmark with inference tasks and
suitable performance metrics, with an initial selection of algorithms including
recent approaches employing neural networks and classical Approximate Bayesian
Computation methods. We found that the choice of performance metric is
critical, that even state-of-the-art algorithms have substantial room for
improvement, and that sequential estimation improves sample efficiency. Neural
network-based approaches generally exhibit better performance, but there is no
uniformly best algorithm. We provide practical advice and highlight the
potential of the benchmark to diagnose problems and improve algorithms. The
results can be explored interactively on a companion website. All code is open
source, making it possible to contribute further benchmark tasks and inference
algorithms.
</p>
<a href="http://arxiv.org/abs/2101.04653" target="_blank">arXiv:2101.04653</a> [<a href="http://arxiv.org/pdf/2101.04653" target="_blank">pdf</a>]

<h2>SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities. (arXiv:1807.06756v3 [cs.LG] UPDATED)</h2>
<h3>Zhen Li, Deqing Zou, Shouhuai Xu, Hai Jin, Yawei Zhu, Zhaoxuan Chen</h3>
<p>The detection of software vulnerabilities (or vulnerabilities for short) is
an important problem that has yet to be tackled, as manifested by the many
vulnerabilities reported on a daily basis. This calls for machine learning
methods for vulnerability detection. Deep learning is attractive for this
purpose because it alleviates the requirement to manually define features.
Despite the tremendous success of deep learning in other application domains,
its applicability to vulnerability detection is not systematically understood.
In order to fill this void, we propose the first systematic framework for using
deep learning to detect vulnerabilities in C/C++ programs with source code. The
framework, dubbed Syntax-based, Semantics-based, and Vector Representations
(SySeVR), focuses on obtaining program representations that can accommodate
syntax and semantic information pertinent to vulnerabilities. Our experiments
with 4 software products demonstrate the usefulness of the framework: we detect
15 vulnerabilities that are not reported in the National Vulnerability
Database. Among these 15 vulnerabilities, 7 are unknown and have been reported
to the vendors, and the other 8 have been "silently" patched by the vendors
when releasing newer versions of the pertinent software products.
</p>
<a href="http://arxiv.org/abs/1807.06756" target="_blank">arXiv:1807.06756</a> [<a href="http://arxiv.org/pdf/1807.06756" target="_blank">pdf</a>]

<h2>Lightweight and Scalable Particle Tracking and Motion Clustering of 3D Cell Trajectories. (arXiv:1908.03775v3 [cs.CV] UPDATED)</h2>
<h3>Mojtaba S. Fazli, Rachel V. Stadler, BahaaEddin Alaila, Stephen A. Vella, Silvia N. J. Moreno, Gary E. Ward, Shannon Quinn</h3>
<p>Tracking cell particles in 3D microscopy videos is a challenging task but is
of great significance for modeling the motion of cells. Proper characterization
of the cell's shape, evolution, and their movement over time is crucial to
understanding and modeling the mechanobiology of cell migration in many
diseases. One in particular, toxoplasmosis is the disease caused by the
parasite Toxoplasma gondii. Roughly, one-third of the world's population tests
positive for T. gondii. Its virulence is linked to its lytic cycle, predicated
on its motility and ability to enter and exit nucleated cells; therefore,
studies elucidating its motility patterns are critical to the eventual
development of therapeutic strategies. Here, we present a computational
framework for fast and scalable detection, tracking, and identification of T.
gondii motion phenotypes in 3D videos, in a completely unsupervised fashion.
Our pipeline consists of several different modules including preprocessing,
sparsification, cell detection, cell tracking, trajectories extraction,
parametrization of the trajectories; and finally, a clustering step.
Additionally, we identified the computational bottlenecks, and developed a
lightweight and highly scalable pipeline through a combination of task
distribution and parallelism. Our results prove both the accuracy and
performance of our method.
</p>
<a href="http://arxiv.org/abs/1908.03775" target="_blank">arXiv:1908.03775</a> [<a href="http://arxiv.org/pdf/1908.03775" target="_blank">pdf</a>]

<h2>On the Estimation of Network Complexity: Dimension of Graphons. (arXiv:1909.02900v2 [stat.ML] UPDATED)</h2>
<h3>Yann Issartel</h3>
<p>Network complexity has been studied for over half a century and has found a
wide range of applications. Many methods have been developed to characterize
and estimate the complexity of networks. However, there has been little
research with statistical guarantees. In this paper, we develop a statistical
theory of graph complexity in a general model of random graphs, the so-called
graphon model.

Given a graphon, we endow the latent space of the nodes with the neighborhood
distance that measures the propensity of two nodes to be connected with similar
nodes. Our complexity index is then based on the covering number and the
Minkowski dimension of (a purified version of) this metric space. Although the
latent space is not identifiable, these indices turn out to be identifiable.
This notion of complexity has simple interpretations on popular examples of
random graphs: it matches the number of communities in stochastic block models;
the dimension of the Euclidean space in random geometric graphs; the regularity
of the link function in H\"older graphon models.

From a single observation of the graph, we construct an estimator of the
neighborhood-distance and show universal non-asymptotic bounds for its risk,
matching minimax lower bounds. Based on this estimated distance, we compute the
corresponding covering number and Minkowski dimension and we provide optimal
non-asymptotic error bounds for these two plug-in estimators.
</p>
<a href="http://arxiv.org/abs/1909.02900" target="_blank">arXiv:1909.02900</a> [<a href="http://arxiv.org/pdf/1909.02900" target="_blank">pdf</a>]

<h2>Predicting Attributes of Nodes Using Network Structure. (arXiv:1912.12264v3 [cs.LG] UPDATED)</h2>
<h3>Sarwan Ali, Muhammad Haroon Shakeel, Imdadullah Khan, Safiullah Faizullah, Muhammad Asad Khan</h3>
<p>In many graphs such as social networks, nodes have associated attributes
representing their behavior. Predicting node attributes in such graphs is an
important problem with applications in many domains like recommendation
systems, privacy preservation, and targeted advertisement. Attributes values
can be predicted by analyzing patterns and correlations among attributes and
employing classification/regression algorithms. However, these approaches do
not utilize readily available network topology information. In this regard,
interconnections between different attributes of nodes can be exploited to
improve the prediction accuracy. In this paper, we propose an approach to
represent a node by a feature map with respect to an attribute $a_i$ (which is
used as input for machine learning algorithms) using all attributes of
neighbors to predict attributes values for $a_i$. We perform extensive
experimentation on ten real-world datasets and show that the proposed feature
map significantly improves the prediction accuracy as compared to baseline
approaches on these datasets.
</p>
<a href="http://arxiv.org/abs/1912.12264" target="_blank">arXiv:1912.12264</a> [<a href="http://arxiv.org/pdf/1912.12264" target="_blank">pdf</a>]

<h2>Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework. (arXiv:1912.12970v5 [cs.LG] UPDATED)</h2>
<h3>Wanxin Jin, Zhaoran Wang, Zhuoran Yang, Shaoshuai Mou</h3>
<p>This paper develops a Pontryagin Differentiable Programming (PDP)
methodology, which establishes a unified framework to solve a broad class of
learning and control tasks. The PDP distinguishes from existing methods by two
novel techniques: first, we differentiate through Pontryagin's Maximum
Principle, and this allows to obtain the analytical derivative of a trajectory
with respect to tunable parameters within an optimal control system, enabling
end-to-end learning of dynamics, policies, or/and control objective functions;
and second, we propose an auxiliary control system in the backward pass of the
PDP framework, and the output of this auxiliary control system is the
analytical derivative of the original system's trajectory with respect to the
parameters, which can be iteratively solved using standard control tools. We
investigate three learning modes of the PDP: inverse reinforcement learning,
system identification, and control/planning. We demonstrate the capability of
the PDP in each learning mode on different high-dimensional systems, including
multi-link robot arm, 6-DoF maneuvering quadrotor, and 6-DoF rocket powered
landing.
</p>
<a href="http://arxiv.org/abs/1912.12970" target="_blank">arXiv:1912.12970</a> [<a href="http://arxiv.org/pdf/1912.12970" target="_blank">pdf</a>]

<h2>Training Normalizing Flows with the Information Bottleneck for Competitive Generative Classification. (arXiv:2001.06448v5 [cs.LG] UPDATED)</h2>
<h3>Lynton Ardizzone, Radek Mackowiak, Carsten Rother, Ullrich K&#xf6;the</h3>
<p>The Information Bottleneck (IB) objective uses information theory to
formulate a task-performance versus robustness trade-off. It has been
successfully applied in the standard discriminative classification setting. We
pose the question whether the IB can also be used to train generative
likelihood models such as normalizing flows. Since normalizing flows use
invertible network architectures (INNs), they are information-preserving by
construction. This seems contradictory to the idea of a bottleneck. In this
work, firstly, we develop the theory and methodology of IB-INNs, a class of
conditional normalizing flows where INNs are trained using the IB objective:
Introducing a small amount of {\em controlled} information loss allows for an
asymptotically exact formulation of the IB, while keeping the INN's generative
capabilities intact. Secondly, we investigate the properties of these models
experimentally, specifically used as generative classifiers. This model class
offers advantages such as improved uncertainty quantification and
out-of-distribution detection, but traditional generative classifier solutions
suffer considerably in classification accuracy. We find the trade-off parameter
in the IB controls a mix of generative capabilities and accuracy close to
standard classifiers. Empirically, our uncertainty estimates in this mixed
regime compare favourably to conventional generative and discriminative
classifiers.
</p>
<a href="http://arxiv.org/abs/2001.06448" target="_blank">arXiv:2001.06448</a> [<a href="http://arxiv.org/pdf/2001.06448" target="_blank">pdf</a>]

<h2>Harmonic Convolutional Networks based on Discrete Cosine Transform. (arXiv:2001.06570v2 [cs.CV] UPDATED)</h2>
<h3>Matej Ulicny, Vladimir A. Krylov, Rozenn Dahyot</h3>
<p>Convolutional neural networks (CNNs) learn filters in order to capture local
correlation patterns in feature space. We propose to learn these filters as
combinations of preset spectral filters defined by the Discrete Cosine
Transform (DCT). Our proposed DCT-based harmonic blocks replace conventional
convolutional layers to produce partially or fully harmonic versions of new or
existing CNN architectures. Using DCT energy compaction properties, we
demonstrate how the harmonic networks can be efficiently compressed by
truncating high-frequency information in harmonic blocks thanks to the
redundancies in the spectral domain. We report extensive experimental
validation demonstrating benefits of the introduction of harmonic blocks into
state-of-the-art CNN models in image classification, object detection and
semantic segmentation applications.
</p>
<a href="http://arxiv.org/abs/2001.06570" target="_blank">arXiv:2001.06570</a> [<a href="http://arxiv.org/pdf/2001.06570" target="_blank">pdf</a>]

<h2>AI-GAN: Attack-Inspired Generation of Adversarial Examples. (arXiv:2002.02196v2 [cs.LG] UPDATED)</h2>
<h3>Tao Bai, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, Bo Li, Alex Kot</h3>
<p>Deep neural networks (DNNs) are vulnerable to adversarial examples, which are
crafted by adding imperceptible perturbations to inputs. Recently different
attacks and strategies have been proposed, but how to generate adversarial
examples perceptually realistic and more efficiently remains unsolved. This
paper proposes a novel framework called Attack-Inspired GAN (AI-GAN), where a
generator, a discriminator, and an attacker are trained jointly. Once trained,
it can generate adversarial perturbations efficiently given input images and
target classes. Through extensive experiments on several popular datasets \eg
MNIST and CIFAR-10, AI-GAN achieves high attack success rates and reduces
generation time significantly in various settings. Moreover, for the first
time, AI-GAN successfully scales to complicated datasets \eg CIFAR-100 with
around $90\%$ success rates among all classes.
</p>
<a href="http://arxiv.org/abs/2002.02196" target="_blank">arXiv:2002.02196</a> [<a href="http://arxiv.org/pdf/2002.02196" target="_blank">pdf</a>]

<h2>Deep Survival Machines: Fully Parametric Survival Regression and Representation Learning for Censored Data with Competing Risks. (arXiv:2003.01176v2 [cs.LG] UPDATED)</h2>
<h3>Chirag Nagpal, Xinyu Li, Artur Dubrawski</h3>
<p>We describe a new approach to estimating relative risks in time-to-event
prediction problems with censored data in a fully parametric manner. Our
approach does not require making strong assumptions of constant proportional
hazard of the underlying survival distribution, as required by the
Cox-proportional hazard model. By jointly learning deep nonlinear
representations of the input covariates, we demonstrate the benefits of our
approach when used to estimate survival risks through extensive experimentation
on multiple real world datasets with different levels of censoring. We further
demonstrate advantages of our model in the competing risks scenario. To the
best of our knowledge, this is the first work involving fully parametric
estimation of survival times with competing risks in the presence of censoring.
</p>
<a href="http://arxiv.org/abs/2003.01176" target="_blank">arXiv:2003.01176</a> [<a href="http://arxiv.org/pdf/2003.01176" target="_blank">pdf</a>]

<h2>HEMlets PoSh: Learning Part-Centric Heatmap Triplets for 3D Human Pose and Shape Estimation. (arXiv:2003.04894v3 [cs.CV] UPDATED)</h2>
<h3>Kun Zhou, Xiaoguang Han, Nianjuan Jiang, Kui Jia, Jiangbo Lu</h3>
<p>Estimating 3D human pose from a single image is a challenging task. This work
attempts to address the uncertainty of lifting the detected 2D joints to the 3D
space by introducing an intermediate state-Part-Centric Heatmap Triplets
(HEMlets), which shortens the gap between the 2D observation and the 3D
interpretation. The HEMlets utilize three joint-heatmaps to represent the
relative depth information of the end-joints for each skeletal body part. In
our approach, a Convolutional Network (ConvNet) is first trained to predict
HEMlets from the input image, followed by a volumetric joint-heatmap
regression. We leverage on the integral operation to extract the joint
locations from the volumetric heatmaps, guaranteeing end-to-end learning.
Despite the simplicity of the network design, the quantitative comparisons show
a significant performance improvement over the best-of-grade methods (e.g.
$20\%$ on Human3.6M). The proposed method naturally supports training with
"in-the-wild" images, where only weakly-annotated relative depth information of
skeletal joints is available. This further improves the generalization ability
of our model, as validated by qualitative comparisons on outdoor images.
Leveraging the strength of the HEMlets pose estimation, we further design and
append a shallow yet effective network module to regress the SMPL parameters of
the body pose and shape. We term the entire HEMlets-based human pose and shape
recovery pipeline HEMlets PoSh. Extensive quantitative and qualitative
experiments on the existing human body recovery benchmarks justify the
state-of-the-art results obtained with our HEMlets PoSh approach.
</p>
<a href="http://arxiv.org/abs/2003.04894" target="_blank">arXiv:2003.04894</a> [<a href="http://arxiv.org/pdf/2003.04894" target="_blank">pdf</a>]

<h2>Towards Automatic Bayesian Optimization: A first step involving acquisition functions. (arXiv:2003.09643v2 [cs.AI] UPDATED)</h2>
<h3>Eduardo C. Garrido Merch&#xe1;n, Luis C. Jariego P&#xe9;rez</h3>
<p>Bayesian Optimization is the state of the art technique for the optimization
of black boxes, i.e., functions where we do not have access to their analytical
expression nor its gradients, they are expensive to evaluate and its evaluation
is noisy. The most popular application of bayesian optimization is the
automatic hyperparameter tuning of machine learning algorithms, where we obtain
the best configuration of machine learning algorithms by optimizing the
estimation of the generalization error of these algorithms. Despite being
applied with success, bayesian optimization methodologies also have
hyperparameters that need to be configured such as the probabilistic surrogate
model or the acquisition function used. A bad decision over the configuration
of these hyperparameters implies obtaining bad quality results. Typically,
these hyperparameters are tuned by making assumptions of the objective function
that we want to evaluate but there are scenarios where we do not have any prior
information about the objective function. In this paper, we propose a first
attempt over automatic bayesian optimization by exploring several heuristics
that automatically tune the acquisition function of bayesian optimization. We
illustrate the effectiveness of these heurisitcs in a set of benchmark problems
and a hyperparameter tuning problem of a machine learning algorithm.
</p>
<a href="http://arxiv.org/abs/2003.09643" target="_blank">arXiv:2003.09643</a> [<a href="http://arxiv.org/pdf/2003.09643" target="_blank">pdf</a>]

<h2>Effect of Annotation Errors on Drone Detection with YOLOv3. (arXiv:2004.01059v4 [cs.CV] UPDATED)</h2>
<h3>Aybora Koksal, Kutalmis Gokalp Ince, A. Aydin Alatan</h3>
<p>Following the recent advances in deep networks, object detection and tracking
algorithms with deep learning backbones have been improved significantly;
however, this rapid development resulted in the necessity of large amounts of
annotated labels. Even if the details of such semi-automatic annotation
processes for most of these datasets are not known precisely, especially for
the video annotations, some automated labeling processes are usually employed.
Unfortunately, such approaches might result with erroneous annotations. In this
work, different types of annotation errors for object detection problem are
simulated and the performance of a popular state-of-the-art object detector,
YOLOv3, with erroneous annotations during training and testing stages is
examined. Moreover, some inevitable annotation errors in CVPR-2020 Anti-UAV
Challenge dataset is also examined in this manner, while proposing a solution
to correct such annotation errors of this valuable data set.
</p>
<a href="http://arxiv.org/abs/2004.01059" target="_blank">arXiv:2004.01059</a> [<a href="http://arxiv.org/pdf/2004.01059" target="_blank">pdf</a>]

<h2>Single Pair Cross-Modality Super Resolution. (arXiv:2004.09965v3 [cs.CV] UPDATED)</h2>
<h3>Guy Shacht, Sharon Fogel, Dov Danon, Daniel Cohen-Or, Ilya Leizerson</h3>
<p>Non-visual imaging sensors are widely used in the industry for different
purposes. Those sensors are more expensive than visual (RGB) sensors, and
usually produce images with lower resolution. To this end, Cross-Modality
Super-Resolution methods were introduced, where an RGB image of a
high-resolution assists in increasing the resolution of the low-resolution
modality. However, fusing images from different modalities is not a trivial
task; the output must be artifact-free and remain loyal to the characteristics
of the target modality. Moreover, the input images are never perfectly aligned,
which results in further artifacts during the fusion process.

We present CMSR, a deep network for Cross-Modality Super-Resolution, which
unlike previous methods, is designed to deal with weakly aligned images. The
network is trained on the two input images only, learns their internal
statistics and correlations, and applies them to up-sample the target modality.
CMSR contains an internal transformer that is trained on-the-fly together with
the up-sampling process itself, without explicit supervision. We show that CMSR
succeeds to increase the resolution of the input image, gaining valuable
information from its RGB counterpart, yet in a conservative way, without
introducing artifacts or irrelevant details.
</p>
<a href="http://arxiv.org/abs/2004.09965" target="_blank">arXiv:2004.09965</a> [<a href="http://arxiv.org/pdf/2004.09965" target="_blank">pdf</a>]

<h2>Time Series to Images: Monitoring the Condition of Industrial Assets with Deep Learning Image Processing Algorithms. (arXiv:2005.07031v3 [cs.LG] UPDATED)</h2>
<h3>Gabriel Rodriguez Garcia, Gabriel Michau, M&#xe9;lanie Ducoffe, Jayant Sen Gupta, Olga Fink</h3>
<p>The ability to detect anomalies in time series is considered highly valuable
in numerous application domains. The sequential nature of time series objects
is responsible for an additional feature complexity, ultimately requiring
specialized approaches in order to solve the task. Essential characteristics of
time series, situated outside the time domain, are often difficult to capture
with state-of-the-art anomaly detection methods when no transformations have
been applied to the time series. Inspired by the success of deep learning
methods in computer vision, several studies have proposed transforming time
series into image-like representations, used as inputs for deep learning
models, and have led to very promising results in classification tasks.

In this paper, we first review the signal to image encoding approaches found
in the literature. Second, we propose modifications to some of their original
formulations to make them more robust to the variability in large datasets.
Third, we compare them on the basis of a common unsupervised task to
demonstrate how the choice of the encoding can impact the results when used in
the same deep learning architecture. We thus provide a comparison between six
encoding algorithms with and without the proposed modifications. The selected
encoding methods are Gramian Angular Field, Markov Transition Field, recurrence
plot, grey scale encoding, spectrogram, and scalogram. We also compare the
results achieved with the raw signal used as input for another deep learning
model. We demonstrate that some encodings have a competitive advantage and
might be worth considering within a deep learning framework.

The comparison is performed on a dataset collected and released by Airbus
SAS, containing highly complex vibration measurements from real helicopter
flight tests. The different encodings provide competitive results for anomaly
detection.
</p>
<a href="http://arxiv.org/abs/2005.07031" target="_blank">arXiv:2005.07031</a> [<a href="http://arxiv.org/pdf/2005.07031" target="_blank">pdf</a>]

<h2>A Generalised Linear Model Framework for $\beta$-Variational Autoencoders based on Exponential Dispersion Families. (arXiv:2006.06267v2 [cs.LG] UPDATED)</h2>
<h3>Robert Sicks, Ralf Korn, Stefanie Schwaar</h3>
<p>Although variational autoencoders (VAE) are successfully used to obtain
meaningful low-dimensional representations for high-dimensional data, the
characterization of critical points of the loss function for general
observation models is not fully understood. We introduce a theoretical
framework that is based on a connection between $\beta$-VAE and generalized
linear models (GLM). The equality between the activation function of a
$\beta$-VAE and the inverse of the link function of a GLM enables us to provide
a systematic generalization of the loss analysis for $\beta$-VAE based on the
assumption that the observation model distribution belongs to an exponential
dispersion family (EDF). As a result, we can initialize $\beta$-VAE nets by
maximum likelihood estimates (MLE) that enhance the training performance on
both synthetic and real world data sets. As a further consequence, we
analytically describe the auto-pruning property inherent in the $\beta$-VAE
objective and reason for posterior collapse.
</p>
<a href="http://arxiv.org/abs/2006.06267" target="_blank">arXiv:2006.06267</a> [<a href="http://arxiv.org/pdf/2006.06267" target="_blank">pdf</a>]

<h2>Quasi-Dense Similarity Learning for Multiple Object Tracking. (arXiv:2006.06664v3 [cs.CV] UPDATED)</h2>
<h3>Jiangmiao Pang, Linlu Qiu, Xia Li, Haofeng Chen, Qi Li, Trevor Darrell, Fisher Yu</h3>
<p>Similarity learning has been recognized as a crucial step for object
tracking. However, existing multiple object tracking methods only use sparse
ground truth matching as the training objective, while ignoring the majority of
the informative regions on the images. In this paper, we present Quasi-Dense
Similarity Learning, which densely samples hundreds of region proposals on a
pair of images for contrastive learning. We can directly combine this
similarity learning with existing detection methods to build Quasi-Dense
Tracking (QDTrack) without turning to displacement regression or motion priors.
We also find that the resulting distinctive feature space admits a simple
nearest neighbor search at the inference time. Despite its simplicity, QDTrack
outperforms all existing methods on MOT, BDD100K, Waymo, and TAO tracking
benchmarks. It achieves 68.7 MOTA at 20.3 FPS on MOT17 without using external
training data. Compared to methods with similar detectors, it boosts almost 10
points of MOTA and significantly decreases the number of ID switches on BDD100K
and Waymo datasets. The code is available at https://github.com/SysCV/qdtrack
</p>
<a href="http://arxiv.org/abs/2006.06664" target="_blank">arXiv:2006.06664</a> [<a href="http://arxiv.org/pdf/2006.06664" target="_blank">pdf</a>]

<h2>Federated and continual learning for classification tasks in a society of devices. (arXiv:2006.07129v2 [cs.LG] UPDATED)</h2>
<h3>Fernando E. Casado, Dylan Lema, Roberto Iglesias, Carlos V. Regueiro, Sen&#xe9;n Barro</h3>
<p>Today we live in a context in which devices are increasingly interconnected
and sensorized and are almost ubiquitous. Deep learning has become in recent
years a popular way to extract knowledge from the huge amount of data that
these devices are able to collect. Nevertheless, centralized state-of-the-art
learning methods have a number of drawbacks when facing real distributed
problems, in which the available information is usually private, partial,
biased and evolving over time. Federated learning is a popular framework that
allows multiple distributed devices to train models remotely, collaboratively,
and preserving data privacy. However, the current proposals in federated
learning focus on deep architectures that in many cases are not feasible to
implement in non-dedicated devices such as smartphones. Also, little research
has been done regarding the scenario where data distribution changes over time
in unforeseen ways, causing what is known as concept drift. Therefore, in this
work we want to present Light Federated and Continual Consensus (LFedCon2), a
new federated and continual architecture that uses light, traditional learners.
Our method allows powerless devices (such as smartphones or robots) to learn in
real time, locally, continuously, autonomously and from users, but also
improving models globally, in the cloud, combining what is learned locally, in
the devices. In order to test our proposal, we have applied it in a
heterogeneous community of smartphone users to solve the problem of walking
recognition. The results show the advantages that LFedCon2 provides with
respect to other state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2006.07129" target="_blank">arXiv:2006.07129</a> [<a href="http://arxiv.org/pdf/2006.07129" target="_blank">pdf</a>]

<h2>The Influence of Shape Constraints on the Thresholding Bandit Problem. (arXiv:2006.10006v2 [cs.LG] UPDATED)</h2>
<h3>James Cheshire, Pierre Menard, Alexandra Carpentier</h3>
<p>We investigate the stochastic Thresholding Bandit problem (TBP) under several
shape constraints. On top of (i) the vanilla, unstructured TBP, we consider the
case where (ii) the sequence of arm's means $(\mu_k)_k$ is monotonically
increasing MTBP, (iii) the case where $(\mu_k)_k$ is unimodal UTBP and (iv) the
case where $(\mu_k)_k$ is concave CTBP. In the TBP problem the aim is to
output, at the end of the sequential game, the set of arms whose means are
above a given threshold. The regret is the highest gap between a misclassified
arm and the threshold. In the fixed budget setting, we provide problem
independent minimax rates for the expected regret in all settings, as well as
associated algorithms. We prove that the minimax rates for the regret are (i)
$\sqrt{\log(K)K/T}$ for TBP, (ii) $\sqrt{\log(K)/T}$ for MTBP, (iii)
$\sqrt{K/T}$ for UTBP and (iv) $\sqrt{\log\log K/T}$ for CTBP, where $K$ is the
number of arms and $T$ is the budget. These rates demonstrate that the
dependence on $K$ of the minimax regret varies significantly depending on the
shape constraint. This highlights the fact that the shape constraints modify
fundamentally the nature of the TBP.
</p>
<a href="http://arxiv.org/abs/2006.10006" target="_blank">arXiv:2006.10006</a> [<a href="http://arxiv.org/pdf/2006.10006" target="_blank">pdf</a>]

<h2>Feature Expansive Reward Learning: Rethinking Human Input. (arXiv:2006.13208v2 [cs.RO] UPDATED)</h2>
<h3>Andreea Bobu, Marius Wiggert, Claire Tomlin, Anca D. Dragan</h3>
<p>When a person is not satisfied with how a robot performs a task, they can
intervene to correct it. Reward learning methods enable the robot to adapt its
reward function online based on such human input, but they rely on handcrafted
features. When the correction cannot be explained by these features, recent
work in deep Inverse Reinforcement Learning (IRL) suggests that the robot could
ask for task demonstrations and recover a reward defined over the raw state
space. Our insight is that rather than implicitly learning about the missing
feature(s) from demonstrations, the robot should instead ask for data that
explicitly teaches it about what it is missing. We introduce a new type of
human input in which the person guides the robot from states where the feature
being taught is highly expressed to states where it is not. We propose an
algorithm for learning the feature from the raw state space and integrating it
into the reward function. By focusing the human input on the missing feature,
our method decreases sample complexity and improves generalization of the
learned reward over the above deep IRL baseline. We show this in experiments
with a physical 7DOF robot manipulator, as well as in a user study conducted in
a simulated environment.
</p>
<a href="http://arxiv.org/abs/2006.13208" target="_blank">arXiv:2006.13208</a> [<a href="http://arxiv.org/pdf/2006.13208" target="_blank">pdf</a>]

<h2>Neural Non-Rigid Tracking. (arXiv:2006.13240v2 [cs.CV] UPDATED)</h2>
<h3>Alja&#x17e; Bo&#x17e;i&#x10d;, Pablo Palafox, Michael Zollh&#xf6;fer, Angela Dai, Justus Thies, Matthias Nie&#xdf;ner</h3>
<p>We introduce a novel, end-to-end learnable, differentiable non-rigid tracker
that enables state-of-the-art non-rigid reconstruction by a learned robust
optimization. Given two input RGB-D frames of a non-rigidly moving object, we
employ a convolutional neural network to predict dense correspondences and
their confidences. These correspondences are used as constraints in an
as-rigid-as-possible (ARAP) optimization problem. By enabling gradient
back-propagation through the weighted non-linear least squares solver, we are
able to learn correspondences and confidences in an end-to-end manner such that
they are optimal for the task of non-rigid tracking. Under this formulation,
correspondence confidences can be learned via self-supervision, informing a
learned robust optimization, where outliers and wrong correspondences are
automatically down-weighted to enable effective tracking. Compared to
state-of-the-art approaches, our algorithm shows improved reconstruction
performance, while simultaneously achieving 85 times faster correspondence
prediction than comparable deep-learning based methods. We make our code
available.
</p>
<a href="http://arxiv.org/abs/2006.13240" target="_blank">arXiv:2006.13240</a> [<a href="http://arxiv.org/pdf/2006.13240" target="_blank">pdf</a>]

<h2>A Nearest Neighbor Characterization of Lebesgue Points in Metric Measure Spaces. (arXiv:2007.03937v4 [cs.LG] UPDATED)</h2>
<h3>Tommaso Cesari (TSE), Roberto Colomboni (IIT)</h3>
<p>The property of almost every point being a Lebesgue point has proven to be
crucial for the consistency of several classification algorithms based on
nearest neighbors. We characterize Lebesgue points in terms of a 1-Nearest
Neighbor regression algorithm for pointwise estimation, fleshing out the role
played by tie-breaking rules in the corresponding convergence problem. We then
give an application of our results, proving the convergence of the risk of a
large class of 1-Nearest Neighbor classification algorithms in general metric
spaces where almost every point is a Lebesgue point.
</p>
<a href="http://arxiv.org/abs/2007.03937" target="_blank">arXiv:2007.03937</a> [<a href="http://arxiv.org/pdf/2007.03937" target="_blank">pdf</a>]

<h2>Learning to Reweight with Deep Interactions. (arXiv:2007.04649v2 [cs.LG] UPDATED)</h2>
<h3>Yang Fan, Yingce Xia, Lijun Wu, Shufang Xie, Weiqing Liu, Jiang Bian, Tao Qin, Xiang-Yang Li</h3>
<p>Recently, the concept of teaching has been introduced into machine learning,
in which a teacher model is used to guide the training of a student model
(which will be used in real tasks) through data selection, loss function
design, etc. Learning to reweight, which is a specific kind of teaching that
reweights training data using a teacher model, receives much attention due to
its simplicity and effectiveness. In existing learning to reweight works, the
teacher model only utilizes shallow/surface information such as training
iteration number and loss/accuracy of the student model from
training/validation sets, but ignores the internal states of the student model,
which limits the potential of learning to reweight. In this work, we propose an
improved data reweighting algorithm, in which the student model provides its
internal states to the teacher model, and the teacher model returns adaptive
weights of training samples to enhance the training of the student model. The
teacher model is jointly trained with the student model using meta gradients
propagated from a validation set. Experiments on image classification with
clean/noisy labels and neural machine translation empirically demonstrate that
our algorithm makes significant improvement over previous methods.
</p>
<a href="http://arxiv.org/abs/2007.04649" target="_blank">arXiv:2007.04649</a> [<a href="http://arxiv.org/pdf/2007.04649" target="_blank">pdf</a>]

<h2>Reverse Annealing for Nonnegative/Binary Matrix Factorization. (arXiv:2007.05565v2 [cs.LG] UPDATED)</h2>
<h3>John Golden, Daniel O&#x27;Malley</h3>
<p>It was recently shown that quantum annealing can be used as an effective,
fast subroutine in certain types of matrix factorization algorithms. The
quantum annealing algorithm performed best for quick, approximate answers, but
performance rapidly plateaued. In this paper, we utilize reverse annealing
instead of forward annealing in the quantum annealing subroutine for
nonnegative/binary matrix factorization problems. After an initial global
search with forward annealing, reverse annealing performs a series of local
searches that refine existing solutions. The combination of forward and reverse
annealing significantly improves performance compared to forward annealing
alone for all but the shortest run times.
</p>
<a href="http://arxiv.org/abs/2007.05565" target="_blank">arXiv:2007.05565</a> [<a href="http://arxiv.org/pdf/2007.05565" target="_blank">pdf</a>]

<h2>GeoStat Representations of Time Series for Fast Classification. (arXiv:2007.06682v3 [cs.LG] UPDATED)</h2>
<h3>Robert J. Ravier, Mohammadreza Soltani, Miguel Sim&#xf5;es, Denis Garagic, Vahid Tarokh</h3>
<p>Recent advances in time series classification have largely focused on methods
that either employ deep learning or utilize other machine learning models for
feature extraction. Though successful, their power often comes at the
requirement of computational complexity. In this paper, we introduce GeoStat
representations for time series. GeoStat representations are based off of a
generalization of recent methods for trajectory classification, and summarize
the information of a time series in terms of comprehensive statistics of
(possibly windowed) distributions of easy to compute differential geometric
quantities, requiring no dynamic time warping. The features used are intuitive
and require minimal parameter tuning. We perform an exhaustive evaluation of
GeoStat on a number of real datasets, showing that simple KNN and SVM
classifiers trained on these representations exhibit surprising performance
relative to modern single model methods requiring significant computational
power, achieving state of the art results in many cases. In particular, we show
that this methodology achieves good performance on a challenging dataset
involving the classification of fishing vessels, where our methods achieve good
performance relative to the state of the art despite only having access to
approximately two percent of the dataset used in training and evaluating this
state of the art.
</p>
<a href="http://arxiv.org/abs/2007.06682" target="_blank">arXiv:2007.06682</a> [<a href="http://arxiv.org/pdf/2007.06682" target="_blank">pdf</a>]

<h2>Right for the Right Reason: Making Image Classification Robust. (arXiv:2007.11924v2 [cs.CV] UPDATED)</h2>
<h3>Anna Nguyen, Adrian Oberf&#xf6;ll, Michael F&#xe4;rber</h3>
<p>The effectiveness of Convolutional Neural Networks (CNNs)in classifying image
data has been thoroughly demonstrated. In order to explain the classification
to humans, methods for visualizing classification evidence have been developed
in recent years. These explanations reveal that sometimes images are classified
correctly, but for the wrong reasons,i.e., based on incidental evidence. Of
course, it is desirable that images are classified correctly for the right
reasons, i.e., based on the actual evidence. To this end, we propose a new
explanation quality metric to measure object aligned explanation in image
classification which we refer to as theObAlExmetric. Using object detection
approaches, explanation approaches, and ObAlEx, we quantify the focus of CNNs
on the actual evidence. Moreover, we show that additional training of the CNNs
can improve the focus of CNNs without decreasing their accuracy.
</p>
<a href="http://arxiv.org/abs/2007.11924" target="_blank">arXiv:2007.11924</a> [<a href="http://arxiv.org/pdf/2007.11924" target="_blank">pdf</a>]

<h2>Learning discrete distributions: user vs item-level privacy. (arXiv:2007.13660v3 [cs.LG] UPDATED)</h2>
<h3>Yuhan Liu, Ananda Theertha Suresh, Felix Yu, Sanjiv Kumar, Michael Riley</h3>
<p>Much of the literature on differential privacy focuses on item-level privacy,
where loosely speaking, the goal is to provide privacy per item or training
example. However, recently many practical applications such as federated
learning require preserving privacy for all items of a single user, which is
much harder to achieve. Therefore understanding the theoretical limit of
user-level privacy becomes crucial.

We study the fundamental problem of learning discrete distributions over $k$
symbols with user-level differential privacy. If each user has $m$ samples, we
show that straightforward applications of Laplace or Gaussian mechanisms
require the number of users to be $\mathcal{O}(k/(m\alpha^2) +
k/\epsilon\alpha)$ to achieve an $\ell_1$ distance of $\alpha$ between the true
and estimated distributions, with the privacy-induced penalty
$k/\epsilon\alpha$ independent of the number of samples per user $m$. Moreover,
we show that any mechanism that only operates on the final aggregate counts
should require a user complexity of the same order. We then propose a mechanism
such that the number of users scales as $\tilde{\mathcal{O}}(k/(m\alpha^2) +
k/\sqrt{m}\epsilon\alpha)$ and hence the privacy penalty is
$\tilde{\Theta}(\sqrt{m})$ times smaller compared to the standard mechanisms in
certain settings of interest. We further show that the proposed mechanism is
nearly-optimal under certain regimes.

We also propose general techniques for obtaining lower bounds on restricted
differentially private estimators and a lower bound on the total variation
between binomial distributions, both of which might be of independent interest.
</p>
<a href="http://arxiv.org/abs/2007.13660" target="_blank">arXiv:2007.13660</a> [<a href="http://arxiv.org/pdf/2007.13660" target="_blank">pdf</a>]

<h2>Compensation Tracker: Reprocessing for Lost Object. (arXiv:2008.12052v3 [cs.CV] UPDATED)</h2>
<h3>Zhibo Zou, Junjie Huang, Ping Luo</h3>
<p>At present, the main research direction of multi-object tracking framework is
tracking by detection. Although the detection-based tracking framework can
achieve good results, it is very dependent on the performance of the detector.
The tracking results will be affected to a certain extent when the detector has
the behaviors of omission and error detection. Therefore, in order to solve the
problem of missing detection, we designs a compensation tracker based on motion
compensation and objects selection. Besides the tracker can be embedded into
other non-end-to-end tracking frameworks. Experiments show that after using the
compensation tracker designed in this paper, evaluation indicators have
improved in varying degrees on MOT Challenge datasets. With limit cost, the
compensation tracker haves reached 66% MOTA and 67% IDF1 in the 2020 datasets
of dense scenarios. This shows that the proposed method can effectively improve
the tracking performance of the model.
</p>
<a href="http://arxiv.org/abs/2008.12052" target="_blank">arXiv:2008.12052</a> [<a href="http://arxiv.org/pdf/2008.12052" target="_blank">pdf</a>]

<h2>Nonholonomic Yaw Control of an Underactuated Flying Robot with Model-based Reinforcement Learning. (arXiv:2009.01221v2 [cs.RO] UPDATED)</h2>
<h3>Nathan Lambert, Craig Schindler, Daniel Drew, Kristofer Pister</h3>
<p>Nonholonomic control is a candidate to control nonlinear systems with
path-dependant states. We investigate an underactuated flying
micro-aerial-vehicle, the ionocraft, that requires nonholonomic control in the
yaw-direction for complete attitude control. Deploying an analytical control
law involves substantial engineering design and is sensitive to inaccuracy in
the system model. With specific assumptions on assembly and system dynamics, we
derive a Lie bracket for yaw control of the ionocraft. As a comparison to the
significant engineering effort required for an analytic control law, we
implement a data-driven model-based reinforcement learning yaw controller in a
simulated flight task. We demonstrate that a simple model-based reinforcement
learning framework can match the derived Lie bracket control (in yaw rate and
chosen actions) in a few minutes of flight data, without a pre-defined dynamics
function. This paper shows that learning-based approaches are useful as a tool
for synthesis of nonlinear control laws previously only addressable through
expert-based design.
</p>
<a href="http://arxiv.org/abs/2009.01221" target="_blank">arXiv:2009.01221</a> [<a href="http://arxiv.org/pdf/2009.01221" target="_blank">pdf</a>]

<h2>Communication Efficient Distributed Learning with Censored, Quantized, and Generalized Group ADMM. (arXiv:2009.06459v2 [cs.LG] UPDATED)</h2>
<h3>Chaouki Ben Issaid, Anis Elgabli, Jihong Park, Mehdi Bennis, M&#xe9;rouane Debbah</h3>
<p>In this paper, we propose a communication-efficiently decentralized machine
learning framework that solves a consensus optimization problem defined over a
network of inter-connected workers. The proposed algorithm, Censored and
Quantized Generalized GADMM (CQ-GGADMM), leverages the worker grouping and
decentralized learning ideas of Group Alternating Direction Method of
Multipliers (GADMM), and pushes the frontier in communication efficiency by
extending its applicability to generalized network topologies, while
incorporating link censoring for negligible updates after quantization. We
theoretically prove that CQ-GGADMM achieves the linear convergence rate when
the local objective functions are strongly convex under some mild assumptions.
Numerical simulations corroborate that CQ-GGADMM exhibits higher communication
efficiency in terms of the number of communication rounds and transmit energy
consumption without compromising the accuracy and convergence speed, compared
to the censored decentralized ADMM, and the worker grouping method of GADMM.
</p>
<a href="http://arxiv.org/abs/2009.06459" target="_blank">arXiv:2009.06459</a> [<a href="http://arxiv.org/pdf/2009.06459" target="_blank">pdf</a>]

<h2>Neuro-symbolic Neurodegenerative Disease Modeling as Probabilistic Programmed Deep Kernels. (arXiv:2009.07738v3 [cs.LG] UPDATED)</h2>
<h3>Alexander Lavin</h3>
<p>We present a probabilistic programmed deep kernel learning approach to
personalized, predictive modeling of neurodegenerative diseases. Our analysis
considers a spectrum of neural and symbolic machine learning approaches, which
we assess for predictive performance and important medical AI properties such
as interpretability, uncertainty reasoning, data-efficiency, and leveraging
domain knowledge. Our Bayesian approach combines the flexibility of Gaussian
processes with the structural power of neural networks to model biomarker
progressions, without needing clinical labels for training. We run evaluations
on the problem of Alzheimer's disease prediction, yielding results that surpass
deep learning in both accuracy and timeliness of predicting neurodegeneration,
and with the practical advantages of Bayesian nonparametrics and probabilistic
programming.
</p>
<a href="http://arxiv.org/abs/2009.07738" target="_blank">arXiv:2009.07738</a> [<a href="http://arxiv.org/pdf/2009.07738" target="_blank">pdf</a>]

<h2>A Framework of Learning Through Empirical Gain Maximization. (arXiv:2009.14250v2 [cs.LG] UPDATED)</h2>
<h3>Yunlong Feng, Qiang Wu</h3>
<p>We develop in this paper a framework of empirical gain maximization (EGM) to
address the robust regression problem where heavy-tailed noise or outliers may
present in the response variable. The idea of EGM is to approximate the density
function of the noise distribution instead of approximating the truth function
directly as usual. Unlike the classical maximum likelihood estimation that
encourages equal importance of all observations and could be problematic in the
presence of abnormal observations, EGM schemes can be interpreted from a
minimum distance estimation viewpoint and allow the ignorance of those
observations. Furthermore, it is shown that several well-known robust nonconvex
regression paradigms, such as Tukey regression and truncated least square
regression, can be reformulated into this new framework. We then develop a
learning theory for EGM, by means of which a unified analysis can be conducted
for these well-established but not fully-understood regression approaches.
Resulting from the new framework, a novel interpretation of existing bounded
nonconvex loss functions can be concluded. Within this new framework, the two
seemingly irrelevant terminologies, the well-known Tukey's biweight loss for
robust regression and the triweight kernel for nonparametric smoothing, are
closely related. More precisely, it is shown that the Tukey's biweight loss can
be derived from the triweight kernel. Similarly, other frequently employed
bounded nonconvex loss functions in machine learning such as the truncated
square loss, the Geman-McClure loss, and the exponential squared loss can also
be reformulated from certain smoothing kernels in statistics. In addition, the
new framework enables us to devise new bounded nonconvex loss functions for
robust learning.
</p>
<a href="http://arxiv.org/abs/2009.14250" target="_blank">arXiv:2009.14250</a> [<a href="http://arxiv.org/pdf/2009.14250" target="_blank">pdf</a>]

<h2>Policy Learning Using Weak Supervision. (arXiv:2010.01748v2 [cs.LG] UPDATED)</h2>
<h3>Jingkang Wang, Hongyi Guo, Zhaowei Zhu, Yang Liu</h3>
<p>Most existing policy learning solutions require the learning agents to
receive high-quality supervision signals, e.g., rewards in reinforcement
learning (RL) or high-quality expert's demonstrations in behavioral cloning
(BC). These quality supervisions are either infeasible or prohibitively
expensive to obtain in practice. We aim for a unified framework that leverages
the weak supervisions to perform policy learning efficiently. To handle this
problem, we treat the "weak supervisions" as imperfect information coming from
a peer agent, and evaluate the learning agent's policy based on a "correlated
agreement" with the peer agent's policy (instead of simple agreements). Our way
of leveraging peer agent's information offers us a family of solutions that
learn effectively from weak supervisions with theoretical guarantees. Extensive
evaluations on tasks including RL with noisy reward, BC with weak
demonstrations and standard policy co-training (RL + BC) show that the proposed
approach leads to substantial improvements, especially when the complexity or
the noise of the learning environments grows.
</p>
<a href="http://arxiv.org/abs/2010.01748" target="_blank">arXiv:2010.01748</a> [<a href="http://arxiv.org/pdf/2010.01748" target="_blank">pdf</a>]

<h2>k-simplex2vec: a simplicial extension of node2vec. (arXiv:2010.05636v2 [cs.LG] UPDATED)</h2>
<h3>Celia Hacker</h3>
<p>We present a novel method of associating Euclidean features to simplicial
complexes, providing a way to use them as input to statistical and machine
learning tools. This method extends the node2vec algorithm to simplices of
higher dimensions, providing insight into the structure of a simplicial
complex, or into the higher-order interactions in a graph.
</p>
<a href="http://arxiv.org/abs/2010.05636" target="_blank">arXiv:2010.05636</a> [<a href="http://arxiv.org/pdf/2010.05636" target="_blank">pdf</a>]

<h2>Reducing the Teacher-Student Gap via Spherical Knowledge Disitllation. (arXiv:2010.07485v5 [cs.LG] UPDATED)</h2>
<h3>Jia Guo, Minghao Chen, Yao Hu, Chen Zhu, Xiaofei He, Deng Cai</h3>
<p>Knowledge distillation aims at obtaining a compact and effective model by
learning the mapping function from a much larger one. Due to the limited
capacity of the student, the student would underfit the teacher. Therefore,
student performance would unexpectedly drop when distilling from an oversized
teacher, termed the capacity gap problem. We investigate this problem by study
the gap of confidence between teacher and student. We find that the magnitude
of confidence is not necessary for knowledge distillation and could harm the
student performance if the student are forced to learn confidence. We propose
Spherical Knowledge Distillation to eliminate this gap explicitly, which eases
the underfitting problem. We find this novel knowledge representation can
improve compact models with much larger teachers and is robust to temperature.
We conducted experiments on both CIFAR100 and ImageNet, and achieve significant
improvement. Specifically, we train ResNet18 to 73.0 accuracy, which is a
substantial improvement over previous SOTA and is on par with resnet34 almost
twice the student size. The implementation has been shared at
https://github.com/forjiuzhou/Spherical-Knowledge-Distillation.
</p>
<a href="http://arxiv.org/abs/2010.07485" target="_blank">arXiv:2010.07485</a> [<a href="http://arxiv.org/pdf/2010.07485" target="_blank">pdf</a>]

<h2>Applicability and Challenges of Deep Reinforcement Learning for Satellite Frequency Plan Design. (arXiv:2010.08015v2 [cs.LG] UPDATED)</h2>
<h3>Juan Jose Garau Luis, Edward Crawley, Bruce Cameron</h3>
<p>The study and benchmarking of Deep Reinforcement Learning (DRL) models has
become a trend in many industries, including aerospace engineering and
communications. Recent studies in these fields propose these kinds of models to
address certain complex real-time decision-making problems in which classic
approaches do not meet time requirements or fail to obtain optimal solutions.
While the good performance of DRL models has been proved for specific use cases
or scenarios, most studies do not discuss the compromises and generalizability
of such models during real operations. In this paper we explore the tradeoffs
of different elements of DRL models and how they might impact the final
performance. To that end, we choose the Frequency Plan Design (FPD) problem in
the context of multibeam satellite constellations as our use case and propose a
DRL model to address it. We identify 6 different core elements that have a
major effect in its performance: the policy, the policy optimizer, the state,
action, and reward representations, and the training environment. We analyze
different alternatives for each of these elements and characterize their
effect. We also use multiple environments to account for different scenarios in
which we vary the dimensionality or make the environment nonstationary. Our
findings show that DRL is a potential method to address the FPD problem in real
operations, especially because of its speed in decision-making. However, no
single DRL model is able to outperform the rest in all scenarios, and the best
approach for each of the 6 core elements depends on the features of the
operation environment. While we agree on the potential of DRL to solve future
complex problems in the aerospace industry, we also reflect on the importance
of designing appropriate models and training procedures, understanding the
applicability of such models, and reporting the main performance tradeoffs.
</p>
<a href="http://arxiv.org/abs/2010.08015" target="_blank">arXiv:2010.08015</a> [<a href="http://arxiv.org/pdf/2010.08015" target="_blank">pdf</a>]

<h2>Self-supervised Co-training for Video Representation Learning. (arXiv:2010.09709v2 [cs.CV] UPDATED)</h2>
<h3>Tengda Han, Weidi Xie, Andrew Zisserman</h3>
<p>The objective of this paper is visual-only self-supervised video
representation learning. We make the following contributions: (i) we
investigate the benefit of adding semantic-class positives to instance-based
Info Noise Contrastive Estimation (InfoNCE) training, showing that this form of
supervised contrastive learning leads to a clear improvement in performance;
(ii) we propose a novel self-supervised co-training scheme to improve the
popular infoNCE loss, exploiting the complementary information from different
views, RGB streams and optical flow, of the same data source by using one view
to obtain positive class samples for the other; (iii) we thoroughly evaluate
the quality of the learnt representation on two different downstream tasks:
action recognition and video retrieval. In both cases, the proposed approach
demonstrates state-of-the-art or comparable performance with other
self-supervised approaches, whilst being significantly more efficient to train,
i.e. requiring far less training data to achieve similar performance.
</p>
<a href="http://arxiv.org/abs/2010.09709" target="_blank">arXiv:2010.09709</a> [<a href="http://arxiv.org/pdf/2010.09709" target="_blank">pdf</a>]

<h2>TAMPC: A Controller for Escaping Traps in Novel Environments. (arXiv:2010.12516v2 [cs.RO] UPDATED)</h2>
<h3>Sheng Zhong (1), Zhenyuan Zhang (1), Nima Fazeli (1), Dmitry Berenson (1) ((1) Robotics Institute, University of Michigan)</h3>
<p>We propose an approach to online model adaptation and control in the
challenging case of hybrid and discontinuous dynamics where actions may lead to
difficult-to-escape "trap" states, under a given controller. We first learn
dynamics for a system without traps from a randomly collected training set
(since we do not know what traps will be encountered online). These "nominal"
dynamics allow us to perform tasks in scenarios where the dynamics matches the
training data, but when unexpected traps arise in execution, we must find a way
to adapt our dynamics and control strategy and continue attempting the task.
Our approach, Trap-Aware Model Predictive Control (TAMPC), is a two-level
hierarchical control algorithm that reasons about traps and non-nominal
dynamics to decide between goal-seeking and recovery policies. An important
requirement of our method is the ability to recognize nominal dynamics even
when we encounter data that is out-of-distribution w.r.t the training data. We
achieve this by learning a representation for dynamics that exploits invariance
in the nominal environment, thus allowing better generalization. We evaluate
our method on simulated planar pushing and peg-in-hole as well as real robot
peg-in-hole problems against adaptive control, reinforcement learning,
trap-handling baselines, where traps arise due to unexpected obstacles that we
only observe through contact. Our results show that our method outperforms the
baselines on difficult tasks, and is comparable to prior trap-handling methods
on easier tasks.
</p>
<a href="http://arxiv.org/abs/2010.12516" target="_blank">arXiv:2010.12516</a> [<a href="http://arxiv.org/pdf/2010.12516" target="_blank">pdf</a>]

<h2>Exemplary Natural Images Explain CNN Activations Better than Feature Visualizations. (arXiv:2010.12606v2 [cs.CV] UPDATED)</h2>
<h3>Judy Borowski, Roland S. Zimmermann, Judith Schepers, Robert Geirhos, Thomas S. A. Wallis, Matthias Bethge, Wieland Brendel</h3>
<p>Feature visualizations such as synthetic maximally activating images are a
widely used explanation method to better understand the information processing
of convolutional neural networks (CNNs). At the same time, there are concerns
that these visualizations might not accurately represent CNNs' inner workings.
Here, we measure how much extremely activating images help humans to predict
CNN activations. Using a well-controlled psychophysical paradigm, we compare
the informativeness of synthetic images by Olah et al. 2017 with a simple
baseline visualization, namely exemplary natural images that also strongly
activate a specific feature map. Given either synthetic or natural reference
images, human participants choose which of two query images leads to strong
positive activation. The experiment is designed to maximize participants'
performance, and is the first to probe intermediate instead of final layer
representations. We find that synthetic images indeed provide helpful
information about feature map activations ($82\pm4\%$ accuracy; chance would be
$50\%$). However, natural images - originally intended to be a baseline -
outperform these synthetic images by a wide margin ($92\pm2\%$). Additionally,
participants are faster and more confident for natural images. The higher
informativeness of natural images holds across most layers, for both expert and
lay participants as well as for hand- and randomly-picked feature
visualizations. Even if only a single reference image is given, synthetic
images provide less information than natural images ($65\pm5\%$ vs.
$73\pm4\%$). In summary, synthetic images from a popular feature visualization
method are significantly less informative for assessing CNN activations than
natural images. We argue that visualization methods should improve over this
simple baseline.
</p>
<a href="http://arxiv.org/abs/2010.12606" target="_blank">arXiv:2010.12606</a> [<a href="http://arxiv.org/pdf/2010.12606" target="_blank">pdf</a>]

<h2>REDE: End-to-end Object 6D Pose Robust Estimation Using Differentiable Outliers Elimination. (arXiv:2010.12807v2 [cs.CV] UPDATED)</h2>
<h3>Weitong Hua, Zhongxiang Zhou, Jun Wu, Yue Wang, Rong Xiong</h3>
<p>Object 6D pose estimation is a fundamental task in many applications.
Conventional methods solve the task by detecting and matching the keypoints,
then estimating the pose. Recent efforts bringing deep learning into the
problem mainly overcome the vulnerability of conventional methods to
environmental variation due to the hand-crafted feature design. However, these
methods cannot achieve end-to-end learning and good interpretability at the
same time. In this paper, we propose REDE, a novel end-to-end object pose
estimator using RGB-D data, which utilizes network for keypoint regression, and
a differentiable geometric pose estimator for pose error back-propagation.
Besides, to achieve better robustness when outlier keypoint prediction occurs,
we further propose a differentiable outliers elimination method that regresses
the candidate result and the confidence simultaneously. Via confidence weighted
aggregation of multiple candidates, we can reduce the effect from the outliers
in the final estimation. Finally, following the conventional method, we apply a
learnable refinement process to further improve the estimation. The
experimental results on three benchmark datasets show that REDE slightly
outperforms the state-of-the-art approaches and is more robust to object
occlusion.
</p>
<a href="http://arxiv.org/abs/2010.12807" target="_blank">arXiv:2010.12807</a> [<a href="http://arxiv.org/pdf/2010.12807" target="_blank">pdf</a>]

<h2>CircuitBot: Learning to Survive with Robotic Circuit Drawing. (arXiv:2011.04987v2 [cs.RO] UPDATED)</h2>
<h3>Xianglong Tan, Weijie Lyu, Andre Rosendo</h3>
<p>Robots with the ability to actively acquire power from surroundings will be
greatly beneficial for long-term autonomy, and to survive in dynamic, uncertain
environments. In this work, a scenario is presented where a robot has limited
energy, and the only way to survive is to access the energy from a power
source. With no cables or wires available, the robot learns to construct an
electrical path and avoid potential obstacles during the connection. We present
this robot, capable of drawing connected circuit patterns with graphene-based
conductive ink. A state-of-the-art Mix-Variable Bayesian Optimization is
adopted to optimize the placement of conductive shapes to maximize the power
this robot receives. Our results show that, within a small number of trials,
the robot learns to build parallel circuits to maximize the voltage received
and avoid obstacles which steal energy from the robot.
</p>
<a href="http://arxiv.org/abs/2011.04987" target="_blank">arXiv:2011.04987</a> [<a href="http://arxiv.org/pdf/2011.04987" target="_blank">pdf</a>]

<h2>Sensorimotor representation learning for an "active self" in robots: A model survey. (arXiv:2011.12860v2 [cs.RO] UPDATED)</h2>
<h3>Phuong D.H. Nguyen, Yasmin Kim Georgie, Ezgi Kayhan, Manfred Eppe, Verena Vanessa Hafner, Stefan Wermter</h3>
<p>Safe human-robot interactions require robots to be able to learn how to
behave appropriately in \sout{humans' world} \rev{spaces populated by people}
and thus to cope with the challenges posed by our dynamic and unstructured
environment, rather than being provided a rigid set of rules for operations. In
humans, these capabilities are thought to be related to our ability to perceive
our body in space, sensing the location of our limbs during movement, being
aware of other objects and agents, and controlling our body parts to interact
with them intentionally. Toward the next generation of robots with bio-inspired
capacities, in this paper, we first review the developmental processes of
underlying mechanisms of these abilities: The sensory representations of body
schema, peripersonal space, and the active self in humans. Second, we provide a
survey of robotics models of these sensory representations and robotics models
of the self; and we compare these models with the human counterparts. Finally,
we analyse what is missing from these robotics models and propose a theoretical
computational framework, which aims to allow the emergence of the sense of self
in artificial agents by developing sensory representations through
self-exploration.
</p>
<a href="http://arxiv.org/abs/2011.12860" target="_blank">arXiv:2011.12860</a> [<a href="http://arxiv.org/pdf/2011.12860" target="_blank">pdf</a>]

<h2>Towards Generalized Implementation of Wasserstein Distance in GANs. (arXiv:2012.03420v2 [cs.LG] UPDATED)</h2>
<h3>Minkai Xu, Zhiming Zhou, Guansong Lu, Jian Tang, Weinan Zhang, Yong Yu</h3>
<p>Wasserstein GANs (WGANs), built upon the Kantorovich-Rubinstein (KR) duality
of Wasserstein distance, is one of the most theoretically sound GAN models.
However, in practice it does not always outperform other variants of GANs. This
is mostly due to the imperfect implementation of the Lipschitz condition
required by the KR duality. Extensive work has been done in the community with
different implementations of the Lipschitz constraint, which, however, is still
hard to satisfy the restriction perfectly in practice. In this paper, we argue
that the strong Lipschitz constraint might be unnecessary for optimization.
Instead, we take a step back and try to relax the Lipschitz constraint.
Theoretically, we first demonstrate a more general dual form of the Wasserstein
distance called the Sobolev duality, which relaxes the Lipschitz constraint but
still maintains the favorable gradient property of the Wasserstein distance.
Moreover, we show that the KR duality is actually a special case of the Sobolev
duality. Based on the relaxed duality, we further propose a generalized WGAN
training scheme named Sobolev Wasserstein GAN (SWGAN), and empirically
demonstrate the improvement of SWGAN over existing methods with extensive
experiments.
</p>
<a href="http://arxiv.org/abs/2012.03420" target="_blank">arXiv:2012.03420</a> [<a href="http://arxiv.org/pdf/2012.03420" target="_blank">pdf</a>]

<h2>Molecule Optimization via Fragment-based Generative Models. (arXiv:2012.04231v2 [cs.LG] UPDATED)</h2>
<h3>Ziqi Chen, Martin Renqiang Min, Srinivasan Parthasarathy, Xia Ning</h3>
<p>In drug discovery, molecule optimization is an important step in order to
modify drug candidates into better ones in terms of desired drug properties.
With the recent advance of Artificial Intelligence, this traditionally in vitro
process has been increasingly facilitated by in silico approaches. We present
an innovative in silico approach to computationally optimizing molecules and
formulate the problem as to generate optimized molecular graphs via deep
generative models. Our generative models follow the key idea of fragment-based
drug design, and optimize molecules by modifying their small fragments. Our
models learn how to identify the to-be-optimized fragments and how to modify
such fragments by learning from the difference of molecules that have good and
bad properties. In optimizing a new molecule, our models apply the learned
signals to decode optimized fragments at the predicted location of the
fragments. We also construct multiple such models into a pipeline such that
each of the models in the pipeline is able to optimize one fragment, and thus
the entire pipeline is able to modify multiple fragments of molecule if needed.
We compare our models with other state-of-the-art methods on benchmark datasets
and demonstrate that our methods significantly outperform others with more than
80% property improvement under moderate molecular similarity constraints, and
more than 10% property improvement under high molecular similarity constraints.
</p>
<a href="http://arxiv.org/abs/2012.04231" target="_blank">arXiv:2012.04231</a> [<a href="http://arxiv.org/pdf/2012.04231" target="_blank">pdf</a>]

<h2>Joint Search of Data Augmentation Policies and Network Architectures. (arXiv:2012.09407v2 [cs.LG] UPDATED)</h2>
<h3>Taiga Kashima, Yoshihiro Yamada, Shunta Saito</h3>
<p>The common pipeline of training deep neural networks consists of several
building blocks such as data augmentation and network architecture selection.
AutoML is a research field that aims at automatically designing those parts,
but most methods explore each part independently because it is more challenging
to simultaneously search all the parts. In this paper, we propose a joint
optimization method for data augmentation policies and network architectures to
bring more automation to the design of training pipeline. The core idea of our
approach is to make the whole part differentiable. The proposed method combines
differentiable methods for augmentation policy search and network architecture
search to jointly optimize them in the end-to-end manner. The experimental
results show our method achieves competitive or superior performance to the
independently searched results.
</p>
<a href="http://arxiv.org/abs/2012.09407" target="_blank">arXiv:2012.09407</a> [<a href="http://arxiv.org/pdf/2012.09407" target="_blank">pdf</a>]

<h2>IIRC: Incremental Implicitly-Refined Classification. (arXiv:2012.12477v2 [cs.CV] UPDATED)</h2>
<h3>Mohamed Abdelsalam, Mojtaba Faramarzi, Shagun Sodhani, Sarath Chandar</h3>
<p>We introduce the "Incremental Implicitly-Refined Classi-fication (IIRC)"
setup, an extension to the class incremental learning setup where the incoming
batches of classes have two granularity levels. i.e., each sample could have a
high-level (coarse) label like "bear" and a low-level (fine) label like "polar
bear". Only one label is provided at a time, and the model has to figure out
the other label if it has already learnfed it. This setup is more aligned with
real-life scenarios, where a learner usually interacts with the same family of
entities multiple times, discovers more granularity about them, while still
trying not to forget previous knowledge. Moreover, this setup enables
evaluating models for some important lifelong learning challenges that cannot
be easily addressed under the existing setups. These challenges can be
motivated by the example "if a model was trained on the class bear in one task
and on polar bear in another task, will it forget the concept of bear, will it
rightfully infer that a polar bear is still a bear? and will it wrongfully
associate the label of polar bear to other breeds of bear?". We develop a
standardized benchmark that enables evaluating models on the IIRC setup. We
evaluate several state-of-the-art lifelong learning algorithms and highlight
their strengths and limitations. For example, distillation-based methods
perform relatively well but are prone to incorrectly predicting too many labels
per image. We hope that the proposed setup, along with the benchmark, would
provide a meaningful problem setting to the practitioners
</p>
<a href="http://arxiv.org/abs/2012.12477" target="_blank">arXiv:2012.12477</a> [<a href="http://arxiv.org/pdf/2012.12477" target="_blank">pdf</a>]

<h2>Semantic Modeling with SUMO. (arXiv:2012.15835v3 [cs.AI] UPDATED)</h2>
<h3>Robert B. Allen</h3>
<p>We explore using the Suggested Upper Merged Ontology (SUMO) to develop a
semantic simulation. We provide two proof-of-concept demonstrations modeling
transitions in a simulated gasoline engine using a general-purpose programming
language. Rather than focusing on computationally highly intensive techniques,
we explore a less computationally intensive approach related to familiar
software engineering testing procedures. In addition, we propose structured
representations of terms based on linguistic approaches to lexicography.
</p>
<a href="http://arxiv.org/abs/2012.15835" target="_blank">arXiv:2012.15835</a> [<a href="http://arxiv.org/pdf/2012.15835" target="_blank">pdf</a>]

<h2>Latency Overhead of ROS2 for Modular Time-Critical Systems. (arXiv:2101.02074v2 [cs.RO] UPDATED)</h2>
<h3>Tobias Kronauer, Joshwa Pohlmann, Maximilian Matthe, Till Smejkal, Gerhard Fettweis</h3>
<p>Robot Operating System 2 (ROS2) targets distributed real-time systems.
Especially in tight real-time control loops, latency in data processing and
communication can lead to instabilities. As ROS2 encourages splitting of the
data-processing pipelines into several modules, it is important to understand
the latency implications of such modularization. In this paper, we investigate
the end-to-end latency of ROS2 data-processing pipeline with different Data
Distribution Service (DDS) middlewares. In addition, we profile the ROS2 stack
and point out latency bottlenecks. Our findings indicate that end-to-end
latency strongly depends on the used DDS middleware. Moreover, we show that
ROS2 can lead to 50 % latency overhead compared to using low-level DDS
communications. Our results imply guidelines for designing modular ROS2
architectures and indicate possibilities for reducing the ROS2 overhead.
</p>
<a href="http://arxiv.org/abs/2101.02074" target="_blank">arXiv:2101.02074</a> [<a href="http://arxiv.org/pdf/2101.02074" target="_blank">pdf</a>]

<h2>RethNet: Object-by-Object Learning for Detecting Facial Skin Problems. (arXiv:2101.02127v2 [cs.CV] UPDATED)</h2>
<h3>Shohrukh Bekmirzaev, Seoyoung Oh, Sangwook Yoo</h3>
<p>Semantic segmentation is a hot topic in computer vision where the most
challenging tasks of object detection and recognition have been handling by the
success of semantic segmentation approaches. We propose a concept of
object-by-object learning technique to detect 11 types of facial skin lesions
using semantic segmentation methods. Detecting individual skin lesion in a
dense group is a challenging task, because of ambiguities in the appearance of
the visual data. We observe that there exist co-occurrent visual relations
between object classes (e.g., wrinkle and age spot, or papule and whitehead,
etc.). In fact, rich contextual information significantly helps to handle the
issue. Therefore, we propose REthinker blocks that are composed of the locally
constructed convLSTM/Conv3D layers and SE module as a one-shot attention
mechanism whose responsibility is to increase network's sensitivity in the
local and global contextual representation that supports to capture ambiguously
appeared objects and co-occurrence interactions between object classes.
Experiments show that our proposed model reached MIoU of 79.46% on the test of
a prepared dataset, representing a 15.34% improvement over Deeplab v3+ (MIoU of
64.12%).
</p>
<a href="http://arxiv.org/abs/2101.02127" target="_blank">arXiv:2101.02127</a> [<a href="http://arxiv.org/pdf/2101.02127" target="_blank">pdf</a>]

<h2>Unchain the Search Space with Hierarchical Differentiable Architecture Search. (arXiv:2101.04028v2 [cs.CV] UPDATED)</h2>
<h3>Guanting Liu, Yujie Zhong, Sheng Guo, Matthew R. Scott, Weilin Huang</h3>
<p>Differentiable architecture search (DAS) has made great progress in searching
for high-performance architectures with reduced computational cost. However,
DAS-based methods mainly focus on searching for a repeatable cell structure,
which is then stacked sequentially in multiple stages to form the networks.
This configuration significantly reduces the search space, and ignores the
importance of connections between the cells. To overcome this limitation, in
this paper, we propose a Hierarchical Differentiable Architecture Search
(H-DAS) that performs architecture search both at the cell level and at the
stage level. Specifically, the cell-level search space is relaxed so that the
networks can learn stage-specific cell structures. For the stage-level search,
we systematically study the architectures of stages, including the number of
cells in each stage and the connections between the cells. Based on insightful
observations, we design several search rules and losses, and mange to search
for better stage-level architectures. Such hierarchical search space greatly
improves the performance of the networks without introducing expensive search
cost. Extensive experiments on CIFAR10 and ImageNet demonstrate the
effectiveness of the proposed H-DAS. Moreover, the searched stage-level
architectures can be combined with the cell structures searched by existing DAS
methods to further boost the performance. Code is available at:
https://github.com/MalongTech/research-HDAS
</p>
<a href="http://arxiv.org/abs/2101.04028" target="_blank">arXiv:2101.04028</a> [<a href="http://arxiv.org/pdf/2101.04028" target="_blank">pdf</a>]

