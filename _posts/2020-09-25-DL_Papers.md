---
title: Latest Deep Learning Papers
date: 2021-01-18 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (282 Articles)</h1>
<h2>Catching Out-of-Context Misinformation with Self-supervised Learning. (arXiv:2101.06278v1 [cs.CV])</h2>
<h3>Shivangi Aneja, Christoph Bregler, Matthias Nie&#xdf;ner</h3>
<p>Despite the recent attention to DeepFakes and other forms of image
manipulations, one of the most prevalent ways to mislead audiences is the use
of unaltered images in a new but false context. To address these challenges and
support fact-checkers, we propose a new method that automatically detects
out-of-context image and text pairs. Our core idea is a self-supervised
training strategy where we only need images with matching (and non-matching)
captions from different sources. At train time, our method learns to
selectively align individual objects in an image with textual claims, without
explicit supervision. At test time, we check for a given text pair if both
texts correspond to same object(s) in the image but semantically convey
different descriptions, which allows us to make fairly accurate out-of-context
predictions. Our method achieves 82% out-of-context detection accuracy. To
facilitate training our method, we created a large-scale dataset of 203,570
images which we match with 456,305 textual captions from a variety of news
websites, blogs, and social media posts; i.e., for each image, we obtained
several captions.
</p>
<a href="http://arxiv.org/abs/2101.06278" target="_blank">arXiv:2101.06278</a> [<a href="http://arxiv.org/pdf/2101.06278" target="_blank">pdf</a>]

<h2>Sensitivity Prewarping for Local Surrogate Modeling. (arXiv:2101.06296v1 [stat.ML])</h2>
<h3>Nathan Wycoff, Micka&#xeb;l Binois, Robert B. Gramacy</h3>
<p>In the continual effort to improve product quality and decrease operations
costs, computational modeling is increasingly being deployed to determine
feasibility of product designs or configurations. Surrogate modeling of these
computer experiments via local models, which induce sparsity by only
considering short range interactions, can tackle huge analyses of complicated
input-output relationships. However, narrowing focus to local scale means that
global trends must be re-learned over and over again. In this article, we
propose a framework for incorporating information from a global sensitivity
analysis into the surrogate model as an input rotation and rescaling
preprocessing step. We discuss the relationship between several sensitivity
analysis methods based on kernel regression before describing how they give
rise to a transformation of the input variables. Specifically, we perform an
input warping such that the "warped simulator" is equally sensitive to all
input directions, freeing local models to focus on local dynamics. Numerical
experiments on observational data and benchmark test functions, including a
high-dimensional computer simulator from the automotive industry, provide
empirical validation.
</p>
<a href="http://arxiv.org/abs/2101.06296" target="_blank">arXiv:2101.06296</a> [<a href="http://arxiv.org/pdf/2101.06296" target="_blank">pdf</a>]

<h2>Fundamental Tradeoffs in Distributionally Adversarial Training. (arXiv:2101.06309v1 [cs.LG])</h2>
<h3>Mohammad Mehrabi, Adel Javanmard, Ryan A. Rossi, Anup Rao, Tung Mai</h3>
<p>Adversarial training is among the most effective techniques to improve the
robustness of models against adversarial perturbations. However, the full
effect of this approach on models is not well understood. For example, while
adversarial training can reduce the adversarial risk (prediction error against
an adversary), it sometimes increase standard risk (generalization error when
there is no adversary). Even more, such behavior is impacted by various
elements of the learning problem, including the size and quality of training
data, specific forms of adversarial perturbations in the input, model
overparameterization, and adversary's power, among others. In this paper, we
focus on \emph{distribution perturbing} adversary framework wherein the
adversary can change the test distribution within a neighborhood of the
training data distribution. The neighborhood is defined via Wasserstein
distance between distributions and the radius of the neighborhood is a measure
of adversary's manipulative power. We study the tradeoff between standard risk
and adversarial risk and derive the Pareto-optimal tradeoff, achievable over
specific classes of models, in the infinite data limit with features dimension
kept fixed. We consider three learning settings: 1) Regression with the class
of linear models; 2) Binary classification under the Gaussian mixtures data
model, with the class of linear classifiers; 3) Regression with the class of
random features model (which can be equivalently represented as two-layer
neural network with random first-layer weights). We show that a tradeoff
between standard and adversarial risk is manifested in all three settings. We
further characterize the Pareto-optimal tradeoff curves and discuss how a
variety of factors, such as features correlation, adversary's power or the
width of two-layer neural network would affect this tradeoff.
</p>
<a href="http://arxiv.org/abs/2101.06309" target="_blank">arXiv:2101.06309</a> [<a href="http://arxiv.org/pdf/2101.06309" target="_blank">pdf</a>]

<h2>Automated Diagnosis of Intestinal Parasites: A new hybrid approach and its benefits. (arXiv:2101.06310v1 [cs.CV])</h2>
<h3>D. Osaku, C. F. Cuba, Celso T.N. Suzuki, J.F. Gomes, A.X. Falc&#xe3;o</h3>
<p>Intestinal parasites are responsible for several diseases in human beings. In
order to eliminate the error-prone visual analysis of optical microscopy
slides, we have investigated automated, fast, and low-cost systems for the
diagnosis of human intestinal parasites. In this work, we present a hybrid
approach that combines the opinion of two decision-making systems with
complementary properties: ($DS_1$) a simpler system based on very fast
handcrafted image feature extraction and support vector machine classification
and ($DS_2$) a more complex system based on a deep neural network, Vgg-16, for
image feature extraction and classification. $DS_1$ is much faster than $DS_2$,
but it is less accurate than $DS_2$. Fortunately, the errors of $DS_1$ are not
the same of $DS_2$. During training, we use a validation set to learn the
probabilities of misclassification by $DS_1$ on each class based on its
confidence values. When $DS_1$ quickly classifies all images from a microscopy
slide, the method selects a number of images with higher chances of
misclassification for characterization and reclassification by $DS_2$. Our
hybrid system can improve the overall effectiveness without compromising
efficiency, being suitable for the clinical routine -- a strategy that might be
suitable for other real applications. As demonstrated on large datasets, the
proposed system can achieve, on average, 94.9%, 87.8%, and 92.5% of Cohen's
Kappa on helminth eggs, helminth larvae, and protozoa cysts, respectively.
</p>
<a href="http://arxiv.org/abs/2101.06310" target="_blank">arXiv:2101.06310</a> [<a href="http://arxiv.org/pdf/2101.06310" target="_blank">pdf</a>]

<h2>Machine-Learning Mathematical Structures. (arXiv:2101.06317v1 [cs.LG])</h2>
<h3>Yang-Hui He</h3>
<p>We review, for a general audience, a variety of recent experiments on
extracting structure from machine-learning mathematical data that have been
compiled over the years. Focusing on supervised machine-learning on labeled
data from different fields ranging from geometry to representation theory, from
combinatorics to number theory, we present a comparative study of the
accuracies on different problems. The paradigm should be useful for conjecture
formulation, finding more efficient methods of computation, as well as probing
into certain hierarchy of structures in mathematics.
</p>
<a href="http://arxiv.org/abs/2101.06317" target="_blank">arXiv:2101.06317</a> [<a href="http://arxiv.org/pdf/2101.06317" target="_blank">pdf</a>]

<h2>In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label Selection Framework for Semi-Supervised Learning. (arXiv:2101.06329v1 [cs.LG])</h2>
<h3>Mamshad Nayeem Rizve, Kevin Duarte, Yogesh S Rawat, Mubarak Shah</h3>
<p>The recent research in semi-supervised learning (SSL) is mostly dominated by
consistency regularization based methods which achieve strong performance.
However, they heavily rely on domain-specific data augmentations, which are not
easy to generate for all data modalities. Pseudo-labeling (PL) is a general SSL
approach that does not have this constraint but performs relatively poorly in
its original formulation. We argue that PL underperforms due to the erroneous
high confidence predictions from poorly calibrated models; these predictions
generate many incorrect pseudo-labels, leading to noisy training. We propose an
uncertainty-aware pseudo-label selection (UPS) framework which improves pseudo
labeling accuracy by drastically reducing the amount of noise encountered in
the training process. Furthermore, UPS generalizes the pseudo-labeling process,
allowing for the creation of negative pseudo-labels; these negative
pseudo-labels can be used for multi-label classification as well as negative
learning to improve the single-label classification. We achieve strong
performance when compared to recent SSL methods on the CIFAR-10 and CIFAR-100
datasets. Also, we demonstrate the versatility of our method on the video
dataset UCF-101 and the multi-label dataset Pascal VOC.
</p>
<a href="http://arxiv.org/abs/2101.06329" target="_blank">arXiv:2101.06329</a> [<a href="http://arxiv.org/pdf/2101.06329" target="_blank">pdf</a>]

<h2>Optical Flow Estimation via Motion Feature Recovery. (arXiv:2101.06333v1 [cs.CV])</h2>
<h3>Yang Jiao, Guangming Shi, Trac D. Tran</h3>
<p>Optical flow estimation with occlusion or large displacement is a problematic
challenge due to the lost of corresponding pixels between consecutive frames.
In this paper, we discover that the lost information is related to a large
quantity of motion features (more than 40%) computed from the popular
discriminative cost-volume feature would completely vanish due to invalid
sampling, leading to the low efficiency of optical flow learning. We call this
phenomenon the Vanishing Cost Volume Problem. Inspired by the fact that local
motion tends to be highly consistent within a short temporal window, we propose
a novel iterative Motion Feature Recovery (MFR) method to address the vanishing
cost volume via modeling motion consistency across multiple frames. In each MFR
iteration, invalid entries from original motion features are first determined
based on the current flow. Then, an efficient network is designed to adaptively
learn the motion correlation to recover invalid features for lost-information
restoration. The final optical flow is then decoded from the recovered motion
features. Experimental results on Sintel and KITTI show that our method
achieves state-of-the-art performances. In fact, MFR currently ranks second on
Sintel public website.
</p>
<a href="http://arxiv.org/abs/2101.06333" target="_blank">arXiv:2101.06333</a> [<a href="http://arxiv.org/pdf/2101.06333" target="_blank">pdf</a>]

<h2>Slider: On the Design and Modeling of a 2D Floating Satellite Platform. (arXiv:2101.06335v1 [cs.RO])</h2>
<h3>Avijit Banerjee, Jakub Haluska, Sumeet G. Satpute, Dariusz Kominiak, George Nikolakopoulos (Robotics and Artificial Intelligence, Department of Computer, Electrical and Space Engineering, Lule&#xe5; University of Technology, Lule&#xe5;)</h3>
<p>In this article, a floating robotic emulation platform for a virtual
demonstration of satellite motion in space is presented. The robotic platform
design is characterized by its friction-less, levitating, yet planar motion
over a hyper-smooth surface. The robotic platform, integrated with sensor and
actuator units, is fully designed and manufactured from the Robotics and
Artificial Intelligence Team at Lule\aa\ University of Technology. A detailed
design description along with the mathematical modeling describing the
platform's dynamic motion is formulated. Finally, the proposed design is
validated in extensive simulation studies, while the overall test bed
experimental setup, as well as the vehicle hardware and software architectures,
are discussed in detail. Furthermore, the entire design, including 3D printing
CAD model and different testbed elements, is provided in an open-source
repository and a test campaign is used to showcase its capabilities and
illustrate its operations.
</p>
<a href="http://arxiv.org/abs/2101.06335" target="_blank">arXiv:2101.06335</a> [<a href="http://arxiv.org/pdf/2101.06335" target="_blank">pdf</a>]

<h2>Exponential Kernels with Latency in Hawkes Processes: Applications in Finance. (arXiv:2101.06348v1 [stat.ML])</h2>
<h3>Marcos Costa Santos Carreira</h3>
<p>The Tick library allows researchers in market microstructure to simulate and
learn Hawkes process in high-frequency data, with optimized parametric and
non-parametric learners. But one challenge is to take into account the correct
causality of order book events considering latency: the only way one order book
event can influence another is if the time difference between them (by the
central order book timestamps) is greater than the minimum amount of time for
an event to be (i) published in the order book, (ii) reach the trader
responsible for the second event, (iii) influence the decision (processing time
at the trader) and (iv) the 2nd event reach the order book and be processed.
For this we can use exponential kernels shifted to the right by the latency
amount. We derive the expression for the log-likelihood to be minimized for the
1-D and the multidimensional cases, and test this method with simulated data
and real data. On real data we find that, although not all decays are the same,
the latency itself will determine most of the decays. We also show how the
decays are related to the latency. Code is available on GitHub at
https://github.com/MarcosCarreira/Hawkes-With-Latency.
</p>
<a href="http://arxiv.org/abs/2101.06348" target="_blank">arXiv:2101.06348</a> [<a href="http://arxiv.org/pdf/2101.06348" target="_blank">pdf</a>]

<h2>NNStreamer: Efficient and Agile Development of On-Device AI Systems. (arXiv:2101.06371v1 [cs.LG])</h2>
<h3>MyungJoo Ham, Jijoong Moon, Geunsik Lim, Jaeyun Jung, Hyoungjoo Ahn, Wook Song, Sangjung Woo, Parichay Kapoor, Dongju Chae, Gichan Jang, Yongjoo Ahn, Jihoon Lee</h3>
<p>We propose NNStreamer, a software system that handles neural networks as
filters of stream pipelines, applying the stream processing paradigm to deep
neural network applications. A new trend with the wide-spread of deep neural
network applications is on-device AI. It is to process neural networks on
mobile devices or edge/IoT devices instead of cloud servers. Emerging privacy
issues, data transmission costs, and operational costs signify the need for
on-device AI, especially if we deploy a massive number of devices. NNStreamer
efficiently handles neural networks with complex data stream pipelines on
devices, significantly improving the overall performance with minimal efforts.
Besides, NNStreamer simplifies implementations and allows reusing off-the-shelf
media filters directly, which reduces developmental costs significantly. We are
already deploying NNStreamer for a wide range of products and platforms,
including the Galaxy series and various consumer electronic devices. The
experimental results suggest a reduction in developmental costs and enhanced
performance of pipeline architectures and NNStreamer. It is an open-source
project incubated by Linux Foundation AI, available to the public and
applicable to various hardware and software platforms.
</p>
<a href="http://arxiv.org/abs/2101.06371" target="_blank">arXiv:2101.06371</a> [<a href="http://arxiv.org/pdf/2101.06371" target="_blank">pdf</a>]

<h2>An Empirical Comparison of Deep Learning Models for Knowledge Tracing on Large-Scale Dataset. (arXiv:2101.06373v1 [cs.AI])</h2>
<h3>Shalini Pandey, George Karypis, Jaideep Srivastava</h3>
<p>Knowledge tracing (KT) is the problem of modeling each student's mastery of
knowledge concepts (KCs) as (s)he engages with a sequence of learning
activities. It is an active research area to help provide learners with
personalized feedback and materials. Various deep learning techniques have been
proposed for solving KT. Recent release of large-scale student performance
dataset \cite{choi2019ednet} motivates the analysis of performance of deep
learning approaches that have been proposed to solve KT. Our analysis can help
understand which method to adopt when large dataset related to student
performance is available. We also show that incorporating contextual
information such as relation between exercises and student forget behavior
further improves the performance of deep learning models.
</p>
<a href="http://arxiv.org/abs/2101.06373" target="_blank">arXiv:2101.06373</a> [<a href="http://arxiv.org/pdf/2101.06373" target="_blank">pdf</a>]

<h2>TridentNet: A Conditional Generative Model for Dynamic Trajectory Generation. (arXiv:2101.06374v1 [cs.RO])</h2>
<h3>David Paz, Hengyuan Zhang, Henrik I. Christensen</h3>
<p>In recent years, various state of the art autonomous vehicle systems and
architectures have been introduced. These methods include planners that depend
on high-definition (HD) maps and models that learn an autonomous agent's
controls in an end-to-end fashion. While end-to-end models are geared towards
solving the scalability constraints from HD maps, they do not generalize for
different vehicles and sensor configurations. To address these shortcomings, we
introduce an approach that leverages lightweight map representations,
explicitly enforcing geometric constraints, and learns feasible trajectories
using a conditional generative model. Additional contributions include a new
dataset that is used to verify our proposed models quantitatively. The results
indicate low relative errors that can potentially translate to traversable
trajectories. The dataset created as part of this work has been made available
online.
</p>
<a href="http://arxiv.org/abs/2101.06374" target="_blank">arXiv:2101.06374</a> [<a href="http://arxiv.org/pdf/2101.06374" target="_blank">pdf</a>]

<h2>Data-Driven Protection Levels for Camera and 3D Map-based Safe Urban Localization. (arXiv:2101.06379v1 [cs.RO])</h2>
<h3>Shubh Gupta, Grace X. Gao</h3>
<p>Reliably assessing the error in an estimated vehicle position is integral for
ensuring the vehicle's safety in urban environments. Many existing approaches
use GNSS measurements to characterize protection levels (PLs) as probabilistic
upper bounds on the position error. However, GNSS signals might be reflected or
blocked in urban environments, and thus additional sensor modalities need to be
considered to determine PLs. In this paper, we propose a novel approach for
computing PLs by matching camera image measurements to a LiDAR-based 3D map of
the environment. We specify a Gaussian mixture model probability distribution
of position error using deep neural network-based data-driven models and
statistical outlier weighting techniques. From the probability distribution, we
compute the PLs by evaluating the position error bound using numerical
line-search methods. Through experimental validation with real-world data, we
demonstrate that the PLs computed from our method are reliable bounds on the
position error in urban environments.
</p>
<a href="http://arxiv.org/abs/2101.06379" target="_blank">arXiv:2101.06379</a> [<a href="http://arxiv.org/pdf/2101.06379" target="_blank">pdf</a>]

<h2>A New Particle Filter Framework for Bayesian Receiver Autonomous Integrity Monitoring in Urban Environments. (arXiv:2101.06380v1 [cs.RO])</h2>
<h3>Shubh Gupta, Grace X. Gao</h3>
<p>Existing urban navigation algorithms employ integrity monitoring (IM) to
mitigate the impact of measurement bias errors and determine system
availability when estimating the position of a receiver. Many IM techniques,
such as receiver autonomous integrity monitoring (RAIM), utilize measurement
residuals associated with a single receiver position to provide integrity.
However, identifying a single correct receiver position is often challenging in
urban environments due to low satellite visibility and multiple measurements
with bias errors. To address this, we propose Particle RAIM as a novel
framework for robust state estimation and IM using GNSS and odometry
measurements. Particle RAIM integrates residual-based RAIM with a particle
filter and Gaussian mixture model likelihood to jointly perform state
estimation and fault mitigation using a multimodal probability distribution of
the receiver state. Our experiments on simulated and real-world data show that
Particle RAIM achieves smaller positioning errors as well as smaller
probability of false alarm and probability of missed-identification in
determining system availability than existing urban localization and IM
approaches in challenging environments with a relatively small computation
overhead.
</p>
<a href="http://arxiv.org/abs/2101.06380" target="_blank">arXiv:2101.06380</a> [<a href="http://arxiv.org/pdf/2101.06380" target="_blank">pdf</a>]

<h2>Diversified Patch-based Style Transfer with Shifted Style Normalization. (arXiv:2101.06381v1 [cs.CV])</h2>
<h3>Zhizhong Wang, Lei Zhao, Haibo Chen, Zhiwen Zuo, Ailin Li, Wei Xing, Dongming Lu</h3>
<p>Gram-based and patch-based approaches are two important research lines of
image style transfer. Recent diversified Gram-based methods have been able to
produce multiple and diverse reasonable solutions for the same content and
style inputs. However, as another popular research interest, the diversity of
patch-based methods remains challenging due to the stereotyped style swapping
process based on nearest patch matching. To resolve this dilemma, in this
paper, we dive into the core style swapping process of patch-based style
transfer and explore possible ways to diversify it. What stands out is an
operation called shifted style normalization (SSN), the most effective and
efficient way to empower existing patch-based methods to generate diverse
results for arbitrary styles. The key insight is to use an important intuition
that neural patches with higher activation values could contribute more to
diversity. Theoretical analyses and extensive experiments are conducted to
demonstrate the effectiveness of our method, and compared with other possible
options and state-of-the-art algorithms, it shows remarkable superiority in
both diversity and efficiency.
</p>
<a href="http://arxiv.org/abs/2101.06381" target="_blank">arXiv:2101.06381</a> [<a href="http://arxiv.org/pdf/2101.06381" target="_blank">pdf</a>]

<h2>Informative core identification in complex networks. (arXiv:2101.06388v1 [stat.ML])</h2>
<h3>Ruizhong Miao, Tianxi Li</h3>
<p>In network analysis, the core structure of modeling interest is usually
hidden in a larger network in which most structures are not informative. The
noise and bias introduced by the non-informative component in networks can
obscure the salient structure and limit many network modeling procedures'
effectiveness. This paper introduces a novel core-periphery model for the
non-informative periphery structure of networks without imposing a specific
form for the informative core structure. We propose spectral algorithms for
core identification as a data preprocessing step for general downstream network
analysis tasks based on the model. The algorithm enjoys a strong theoretical
guarantee of accuracy and is scalable for large networks. We evaluate the
proposed method by extensive simulation studies demonstrating various
advantages over many traditional core-periphery methods. The method is applied
to extract the informative core structure from a citation network and give more
informative results in the downstream hierarchical community detection.
</p>
<a href="http://arxiv.org/abs/2101.06388" target="_blank">arXiv:2101.06388</a> [<a href="http://arxiv.org/pdf/2101.06388" target="_blank">pdf</a>]

<h2>GridTracer: Automatic Mapping of Power Grids using Deep Learning and Overhead Imagery. (arXiv:2101.06390v1 [cs.CV])</h2>
<h3>Bohao Huang, Jichen Yang, Artem Streltsov, Kyle Bradbury, Leslie M. Collins, Jordan Malof</h3>
<p>Energy system information valuable for electricity access planning such as
the locations and connectivity of electricity transmission and distribution
towers, termed the power grid, is often incomplete, outdated, or altogether
unavailable. Furthermore, conventional means for collecting this information is
costly and limited. We propose to automatically map the grid in overhead
remotely sensed imagery using deep learning. Towards this goal, we develop and
publicly-release a large dataset ($263km^2$) of overhead imagery with ground
truth for the power grid, to our knowledge this is the first dataset of its
kind in the public domain. Additionally, we propose scoring metrics and
baseline algorithms for two grid mapping tasks: (1) tower recognition and (2)
power line interconnection (i.e., estimating a graph representation of the
grid). We hope the availability of the training data, scoring metrics, and
baselines will facilitate rapid progress on this important problem to help
decision-makers address the energy needs of societies around the world.
</p>
<a href="http://arxiv.org/abs/2101.06390" target="_blank">arXiv:2101.06390</a> [<a href="http://arxiv.org/pdf/2101.06390" target="_blank">pdf</a>]

<h2>Unsupervised Noisy Tracklet Person Re-identification. (arXiv:2101.06391v1 [cs.CV])</h2>
<h3>Minxian Li, Xiatian Zhu, Shaogang Gong</h3>
<p>Existing person re-identification (re-id) methods mostly rely on supervised
model learning from a large set of person identity labelled training data per
domain. This limits their scalability and usability in large scale deployments.
In this work, we present a novel selective tracklet learning (STL) approach
that can train discriminative person re-id models from unlabelled tracklet data
in an unsupervised manner. This avoids the tedious and costly process of
exhaustively labelling person image/tracklet true matching pairs across camera
views. Importantly, our method is particularly more robust against arbitrary
noisy data of raw tracklets therefore scalable to learning discriminative
models from unconstrained tracking data. This differs from a handful of
existing alternative methods that often assume the existence of true matches
and balanced tracklet samples per identity class. This is achieved by
formulating a data adaptive image-to-tracklet selective matching loss function
explored in a multi-camera multi-task deep learning model structure. Extensive
comparative experiments demonstrate that the proposed STL model surpasses
significantly the state-of-the-art unsupervised learning and one-shot learning
re-id methods on three large tracklet person re-id benchmarks.
</p>
<a href="http://arxiv.org/abs/2101.06391" target="_blank">arXiv:2101.06391</a> [<a href="http://arxiv.org/pdf/2101.06391" target="_blank">pdf</a>]

<h2>Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles. (arXiv:2101.06393v1 [cs.CV])</h2>
<h3>Ashish Kumar, James R. McBride, Gaurav Pandey</h3>
<p>We propose an end-to-end real time framework to generate high resolution
graphics grade textured 3D map of urban environment. The generated detailed map
finds its application in the precise localization and navigation of autonomous
vehicles. It can also serve as a virtual test bed for various vision and
planning algorithms as well as a background map in the computer games. In this
paper, we focus on two important issues: (i) incrementally generating a map
with coherent 3D surface, in real time and (ii) preserving the quality of color
texture. To handle the above issues, firstly, we perform a pose-refinement
procedure which leverages camera image information, Delaunay triangulation and
existing scan matching techniques to produce high resolution 3D map from the
sparse input LIDAR scan. This 3D map is then texturized and accumulated by
using a novel technique of ray-filtering which handles occlusion and
inconsistencies in pose-refinement. Further, inspired by human fovea, we
introduce foveal-processing which significantly reduces the computation time
and also assists ray-filtering to maintain consistency in color texture and
coherency in 3D surface of the output map. Moreover, we also introduce texture
error (TE) and mean texture mapping error (MTME), which provides quantitative
measure of texturing and overall quality of the textured maps.
</p>
<a href="http://arxiv.org/abs/2101.06393" target="_blank">arXiv:2101.06393</a> [<a href="http://arxiv.org/pdf/2101.06393" target="_blank">pdf</a>]

<h2>Free Lunch for Few-shot Learning: Distribution Calibration. (arXiv:2101.06395v1 [cs.LG])</h2>
<h3>Shuo Yang, Lu Liu, Min Xu</h3>
<p>Learning from a limited number of samples is challenging since the learned
model can easily become overfitted based on the biased distribution formed by
only a few training examples. In this paper, we calibrate the distribution of
these few-sample classes by transferring statistics from the classes with
sufficient examples, then an adequate number of examples can be sampled from
the calibrated distribution to expand the inputs to the classifier. We assume
every dimension in the feature representation follows a Gaussian distribution
so that the mean and the variance of the distribution can borrow from that of
similar classes whose statistics are better estimated with an adequate number
of samples. Our method can be built on top of off-the-shelf pretrained feature
extractors and classification models without extra parameters. We show that a
simple logistic regression classifier trained using the features sampled from
our calibrated distribution can outperform the state-of-the-art accuracy on two
datasets (~5% improvement on miniImageNet compared to the next best). The
visualization of these generated features demonstrates that our calibrated
distribution is an accurate estimation.
</p>
<a href="http://arxiv.org/abs/2101.06395" target="_blank">arXiv:2101.06395</a> [<a href="http://arxiv.org/pdf/2101.06395" target="_blank">pdf</a>]

<h2>Latent Variable Models for Visual Question Answering. (arXiv:2101.06399v1 [cs.CV])</h2>
<h3>Zixu Wang, Yishu Miao, Lucia Specia</h3>
<p>Conventional models for Visual Question Answering (VQA) explore deterministic
approaches with various types of image features, question features, and
attention mechanisms. However, there exist other modalities that can be
explored in addition to image and question pairs to bring extra information to
the models. In this work, we propose latent variable models for VQA where extra
information (e.g. captions and answer categories) are incorporated as latent
variables to improve inference, which in turn benefits question-answering
performance. Experiments on the VQA v2.0 benchmarking dataset demonstrate the
effectiveness of our proposed models in that they improve over strong
baselines, especially those that do not rely on extensive language-vision
pre-training.
</p>
<a href="http://arxiv.org/abs/2101.06399" target="_blank">arXiv:2101.06399</a> [<a href="http://arxiv.org/pdf/2101.06399" target="_blank">pdf</a>]

<h2>Semi Supervised Deep Quick Instance Detection and Segmentation. (arXiv:2101.06405v1 [cs.CV])</h2>
<h3>Ashish Kumar, L. Behera</h3>
<p>In this paper, we present a semi supervised deep quick learning framework for
instance detection and pixel-wise semantic segmentation of images in a dense
clutter of items. The framework can quickly and incrementally learn novel items
in an online manner by real-time data acquisition and generating corresponding
ground truths on its own. To learn various combinations of items, it can
synthesize cluttered scenes, in real time. The overall approach is based on the
tutor-child analogy in which a deep network (tutor) is pretrained for
class-agnostic object detection which generates labeled data for another deep
network (child). The child utilizes a customized convolutional neural network
head for the purpose of quick learning. There are broadly four key components
of the proposed framework semi supervised labeling, occlusion aware clutter
synthesis, a customized convolutional neural network head, and instance
detection. The initial version of this framework was implemented during our
participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked
3rd, 4th and 5th worldwide in pick, stow-pick and stow task respectively. The
proposed framework is an improved version over ARC17 where novel features such
as instance detection and online learning has been added.
</p>
<a href="http://arxiv.org/abs/2101.06405" target="_blank">arXiv:2101.06405</a> [<a href="http://arxiv.org/pdf/2101.06405" target="_blank">pdf</a>]

<h2>ACP: Automatic Channel Pruning via Clustering and Swarm Intelligence Optimization for CNN. (arXiv:2101.06407v1 [cs.CV])</h2>
<h3>Jingfei Chang, Yang Lu, Ping Xue, Yiqun Xu, Zhen Wei</h3>
<p>As the convolutional neural network (CNN) gets deeper and wider in recent
years, the requirements for the amount of data and hardware resources have
gradually increased. Meanwhile, CNN also reveals salient redundancy in several
tasks. The existing magnitude-based pruning methods are efficient, but the
performance of the compressed network is unpredictable. While the accuracy loss
after pruning based on the structure sensitivity is relatively slight, the
process is time-consuming and the algorithm complexity is notable. In this
article, we propose a novel automatic channel pruning method (ACP).
Specifically, we firstly perform layer-wise channel clustering via the
similarity of the feature maps to perform preliminary pruning on the network.
Then a population initialization method is introduced to transform the pruned
structure into a candidate population. Finally, we conduct searching and
optimizing iteratively based on the particle swarm optimization (PSO) to find
the optimal compressed structure. The compact network is then retrained to
mitigate the accuracy loss from pruning. Our method is evaluated against
several state-of-the-art CNNs on three different classification datasets
CIFAR-10/100 and ILSVRC-2012. On the ILSVRC-2012, when removing 64.36%
parameters and 63.34% floating-point operations (FLOPs) of ResNet-50, the Top-1
and Top-5 accuracy drop are less than 0.9%. Moreover, we demonstrate that
without harming overall performance it is possible to compress SSD by more than
50% on the target detection dataset PASCAL VOC. It further verifies that the
proposed method can also be applied to other CNNs and application scenarios.
</p>
<a href="http://arxiv.org/abs/2101.06407" target="_blank">arXiv:2101.06407</a> [<a href="http://arxiv.org/pdf/2101.06407" target="_blank">pdf</a>]

<h2>Shape Back-Projection In 3D Scenes. (arXiv:2101.06409v1 [cs.CV])</h2>
<h3>Ashish Kumar, L. Behera</h3>
<p>In this work, we propose a novel framework shape back-projection for
computationally efficient point cloud processing in a probabilistic manner. The
primary component of the technique is shape histogram and a back-projection
procedure. The technique measures similarity between 3D surfaces, by analyzing
their geometrical properties. It is analogous to color back-projection which
measures similarity between images, simply by looking at their color
distributions. In the overall process, first, shape histogram of a sample
surface (e.g. planar) is computed, which captures the profile of surface
normals around a point in form of a probability distribution. Later, the
histogram is back-projected onto a test surface and a likelihood score is
obtained. The score depicts that how likely a point in the test surface behaves
similar to the sample surface, geometrically. Shape back-projection finds its
application in binary surface classification, high curvature edge detection in
unorganized point cloud, automated point cloud labeling for 3D-CNNs
(convolutional neural network) etc. The algorithm can also be used for
real-time robotic operations such as autonomous object picking in warehouse
automation, ground plane extraction for autonomous vehicles and can be deployed
easily on computationally limited platforms (UAVs).
</p>
<a href="http://arxiv.org/abs/2101.06409" target="_blank">arXiv:2101.06409</a> [<a href="http://arxiv.org/pdf/2101.06409" target="_blank">pdf</a>]

<h2>DeepMI: A Mutual Information Based Framework For Unsupervised Deep Learning of Tasks. (arXiv:2101.06411v1 [cs.CV])</h2>
<h3>Ashish Kumar, Laxmidhar Behera</h3>
<p>In this work, we propose an information theory based framework DeepMI to
train deep neural networks (DNN) using Mutual Information (MI). The DeepMI
framework is especially targeted but not limited to the learning of real world
tasks in an unsupervised manner. The primary motivation behind this work is the
insufficiency of traditional loss functions for unsupervised task learning.
Moreover, directly using MI for the training purpose is quite challenging to
deal because of its unbounded above nature. Hence, we develop an alternative
linearized representation of MI as a part of the framework. Contributions of
this paper are three fold: i) investigation of MI to train deep neural
networks, ii) novel loss function LLMI, and iii) a fuzzy logic based end-to-end
differentiable pipeline to integrate DeepMI into deep learning framework. We
choose a few unsupervised learning tasks for our experimental study. We
demonstrate that L LM I alone provides better gradients to achieve a neural
network better performance over the cases when multiple loss functions are used
for a given task.
</p>
<a href="http://arxiv.org/abs/2101.06411" target="_blank">arXiv:2101.06411</a> [<a href="http://arxiv.org/pdf/2101.06411" target="_blank">pdf</a>]

<h2>Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in GPS-Denied Environments. (arXiv:2101.06414v1 [cs.RO])</h2>
<h3>Ashish Kumar, Mohit Vohra, Ravi Prakash, L. Behera</h3>
<p>In this work, we present a pragmatic approach to enable unmanned aerial
vehicle (UAVs) to autonomously perform highly complicated tasks of object pick
and place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is
primarily focused on the task of assembling large 3D structures in outdoors and
GPS-denied environments. Primary contributions of this system are: (i) a novel
computationally efficient deep learning based unified multi-task visual
perception system for target localization, part segmentation, and tracking,
(ii) a novel deep learning based grasp state estimation, (iii) a retracting
electromagnetic gripper design, (iv) a remote computing approach which exploits
state-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the
UAVs to execute compute intensive tasks on remote high end compute servers, and
(v) system integration in which several system components are weaved together
in order to develop an optimized software stack. We use DJI Matrice-600 Pro, a
hex-rotor UAV and interface it with the custom designed gripper. Our framework
is deployed on the specified UAV in order to report the performance analysis of
the individual modules. Apart from the manipulation system, we also highlight
several hidden challenges associated with the UAVs in this context.
</p>
<a href="http://arxiv.org/abs/2101.06414" target="_blank">arXiv:2101.06414</a> [<a href="http://arxiv.org/pdf/2101.06414" target="_blank">pdf</a>]

<h2>Bayesian Inference Forgetting. (arXiv:2101.06417v1 [cs.LG])</h2>
<h3>Shaopeng Fu, Fengxiang He, Yue Xu, Dacheng Tao</h3>
<p>The right to be forgotten has been legislated in many countries but the
enforcement in machine learning would cause unbearable costs: companies may
need to delete whole models trained from massive resources because of single
individual requests. Existing works propose to remove the influence of the
requested datums on the learned models via its influence function which is no
longer naturally well-defined in Bayesian inference. To address this problem,
this paper proposes a {\it Bayesian inference forgetting} (BIF) framework to
extend the applicable domain to Bayesian inference. In the BIF framework, we
develop forgetting algorithms for variational inference and Markov chain Monte
Carlo. We show that our algorithms can provably remove the influence of single
datums on the learned models. Theoretical analysis demonstrates that our
algorithms have guaranteed generalizability. Experiments of Gaussian mixture
models on the synthetic dataset and Bayesian neural networks on the
Fashion-MNIST dataset verify the feasibility of our methods. The source code
package is available at \url{https://github.com/fshp971/BIF}.
</p>
<a href="http://arxiv.org/abs/2101.06417" target="_blank">arXiv:2101.06417</a> [<a href="http://arxiv.org/pdf/2101.06417" target="_blank">pdf</a>]

<h2>JITuNE: Just-In-Time Hyperparameter Tuning for Network Embedding Algorithms. (arXiv:2101.06427v1 [cs.LG])</h2>
<h3>Mengying Guo, Yuqing Zhu, Tao Yi, Yungang Bao</h3>
<p>Network embedding (NE) can generate succinct node representations for
massive-scale networks and enable direct applications of common machine
learning methods to the network structure. Various NE algorithms have been
proposed and used in a number of applications, such as node classification and
link prediction. NE algorithms typically contain hyperparameters that are key
to performance, but the hyperparameter tuning process can be time consuming. It
is desirable to have the hyperparameters tuned within a specified length of
time. Although AutoML methods have been applied to the hyperparameter tuning of
NE algorithms, the problem of how to tune hyperparameters in a given period of
time is not studied for NE algorithms before. In this paper, we propose JITuNE,
a just-in-time hyperparameter tuning framework for NE algorithms. Our JITuNE
framework enables the time-constrained hyperparameter tuning for NE algorithms
by employing the tuning over hierarchical network synopses and transferring the
knowledge obtained on synopses to the whole network. The hierarchical
generation of synopsis and a time-constrained tuning method enable the
constraining of overall tuning time. Extensive experiments demonstrate that
JITuNE can significantly improve performances of NE algorithms, outperforming
state-of-the-art methods within the same number of algorithm runs.
</p>
<a href="http://arxiv.org/abs/2101.06427" target="_blank">arXiv:2101.06427</a> [<a href="http://arxiv.org/pdf/2101.06427" target="_blank">pdf</a>]

<h2>Adaptive Remote Sensing Image Attribute Learning for Active Object Detection. (arXiv:2101.06438v1 [cs.CV])</h2>
<h3>Nuo Xu, Chunlei Huo, Jiacheng Guo, Yiwei Liu, Jian Wang, Chunhong Pan</h3>
<p>In recent years, deep learning methods bring incredible progress to the field
of object detection. However, in the field of remote sensing image processing,
existing methods neglect the relationship between imaging configuration and
detection performance, and do not take into account the importance of detection
performance feedback for improving image quality. Therefore, detection
performance is limited by the passive nature of the conventional object
detection framework. In order to solve the above limitations, this paper takes
adaptive brightness adjustment and scale adjustment as examples, and proposes
an active object detection method based on deep reinforcement learning. The
goal of adaptive image attribute learning is to maximize the detection
performance. With the help of active object detection and image attribute
adjustment strategies, low-quality images can be converted into high-quality
images, and the overall performance is improved without retraining the
detector.
</p>
<a href="http://arxiv.org/abs/2101.06438" target="_blank">arXiv:2101.06438</a> [<a href="http://arxiv.org/pdf/2101.06438" target="_blank">pdf</a>]

<h2>Predicting Hyperkalemia in the ICU and Evaluation of Generalizability and Interpretability. (arXiv:2101.06443v1 [cs.LG])</h2>
<h3>Gloria Hyunjung Kwak, Christina Chen, Lowell Ling, Erina Gosh, Leo Anthony Celi, Pan Hui</h3>
<p>Hyperkalemia is a potentially life-threatening condition that can lead to
fatal arrhythmias. Early identification of high risk patients can inform
clinical care to mitigate the risk. While hyperkalemia is often a complication
of acute kidney injury (AKI), it also occurs in the absence of AKI. We
developed predictive models to identify intensive care unit (ICU) patients at
risk of developing hyperkalemia by using the Medical Information Mart for
Intensive Care (MIMIC) and the eICU Collaborative Research Database (eICU-CRD).
Our methodology focused on building multiple models, optimizing for
interpretability through model selection, and simulating various clinical
scenarios.

In order to determine if our models perform accurately on patients with and
without AKI, we evaluated the following clinical cases: (i) predicting
hyperkalemia after AKI within 14 days of ICU admission, (ii) predicting
hyperkalemia within 14 days of ICU admission regardless of AKI status, and
compared different lead times for (i) and (ii). Both clinical scenarios were
modeled using logistic regression (LR), random forest (RF), and XGBoost.

Using observations from the first day in the ICU, our models were able to
predict hyperkalemia with an AUC of (i) 0.79, 0.81, 0.81 and (ii) 0.81, 0.85,
0.85 for LR, RF, and XGBoost respectively. We found that 4 out of the top 5
features were consistent across the models. AKI stage was significant in the
models that included all patients with or without AKI, but not in the models
which only included patients with AKI. This suggests that while AKI is
important for hyperkalemia, the specific stage of AKI may not be as important.
Our findings require further investigation and confirmation.
</p>
<a href="http://arxiv.org/abs/2101.06443" target="_blank">arXiv:2101.06443</a> [<a href="http://arxiv.org/pdf/2101.06443" target="_blank">pdf</a>]

<h2>Robustness to Augmentations as a Generalization metric. (arXiv:2101.06459v1 [cs.LG])</h2>
<h3>Sumukh Aithal K, Dhruva Kashyap, Natarajan Subramanyam</h3>
<p>Generalization is the ability of a model to predict on unseen domains and is
a fundamental task in machine learning. Several generalization bounds, both
theoretical and empirical have been proposed but they do not provide tight
bounds .In this work, we propose a simple yet effective method to predict the
generalization performance of a model by using the concept that models that are
robust to augmentations are more generalizable than those which are not. We
experiment with several augmentations and composition of augmentations to check
the generalization capacity of a model. We also provide a detailed motivation
behind the proposed method. The proposed generalization metric is calculated
based on the change in the output of the model after augmenting the input. The
proposed method was the first runner up solution for the NeurIPS competition on
Predicting Generalization in Deep Learning.
</p>
<a href="http://arxiv.org/abs/2101.06459" target="_blank">arXiv:2101.06459</a> [<a href="http://arxiv.org/pdf/2101.06459" target="_blank">pdf</a>]

<h2>Dual-Level Collaborative Transformer for Image Captioning. (arXiv:2101.06462v1 [cs.CV])</h2>
<h3>Yunpeng Luo, Jiayi Ji, Xiaoshuai Sun, Liujuan Cao, Yongjian Wu, Feiyue Huang, Chia-Wen Lin, Rongrong Ji</h3>
<p>Descriptive region features extracted by object detection networks have
played an important role in the recent advancements of image captioning.
However, they are still criticized for the lack of contextual information and
fine-grained details, which in contrast are the merits of traditional grid
features. In this paper, we introduce a novel Dual-Level Collaborative
Transformer (DLCT) network to realize the complementary advantages of the two
features. Concretely, in DLCT, these two features are first processed by a
novelDual-way Self Attenion (DWSA) to mine their intrinsic properties, where a
Comprehensive Relation Attention component is also introduced to embed the
geometric information. In addition, we propose a Locality-Constrained Cross
Attention module to address the semantic noises caused by the direct fusion of
these two features, where a geometric alignment graph is constructed to
accurately align and reinforce region and grid features. To validate our model,
we conduct extensive experiments on the highly competitive MS-COCO dataset, and
achieve new state-of-the-art performance on both local and online test sets,
i.e., 133.8% CIDEr-D on Karpathy split and 135.4% CIDEr on the official split.
Code is available at https://github.com/luo3300612/image-captioning-DLCT.
</p>
<a href="http://arxiv.org/abs/2101.06462" target="_blank">arXiv:2101.06462</a> [<a href="http://arxiv.org/pdf/2101.06462" target="_blank">pdf</a>]

<h2>Learning the Implicit Semantic Representation on Graph-Structured Data. (arXiv:2101.06471v1 [cs.AI])</h2>
<h3>Likang Wu, Zhi Li, Hongke Zhao, Qi Liu, Jun Wang, Mengdi Zhang, Enhong Chen</h3>
<p>Existing representation learning methods in graph convolutional networks are
mainly designed by describing the neighborhood of each node as a perceptual
whole, while the implicit semantic associations behind highly complex
interactions of graphs are largely unexploited. In this paper, we propose a
Semantic Graph Convolutional Networks (SGCN) that explores the implicit
semantics by learning latent semantic-paths in graphs. In previous work, there
are explorations of graph semantics via meta-paths. However, these methods
mainly rely on explicit heterogeneous information that is hard to be obtained
in a large amount of graph-structured data. SGCN first breaks through this
restriction via leveraging the semantic-paths dynamically and automatically
during the node aggregating process. To evaluate our idea, we conduct
sufficient experiments on several standard datasets, and the empirical results
show the superior performance of our model.
</p>
<a href="http://arxiv.org/abs/2101.06471" target="_blank">arXiv:2101.06471</a> [<a href="http://arxiv.org/pdf/2101.06471" target="_blank">pdf</a>]

<h2>Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks. (arXiv:2101.06475v1 [cs.LG])</h2>
<h3>Maxwell Mbabilla Aladago, Lorenzo Torresani</h3>
<p>In contrast to traditional weight optimization in a continuous space, we
demonstrate the existence of effective random networks whose weights are never
updated. By selecting a weight among a fixed set of random values for each
individual connection, our method uncovers combinations of random weights that
match the performance of traditionally-trained networks of the same capacity.
We refer to our networks as "slot machines" where each reel (connection)
contains a fixed set of symbols (random values). Our backpropagation algorithm
"spins" the reels to seek "winning" combinations, i.e., selections of random
weight values that minimize the given loss. Quite surprisingly, we find that
allocating just a few random values to each connection (e.g., 8 values per
connection) yields highly competitive combinations despite being dramatically
more constrained compared to traditionally learned weights. Moreover,
finetuning these combinations often improves performance over the trained
baselines. A randomly initialized VGG-19 with 8 values per connection contains
a combination that achieves 90% test accuracy on CIFAR-10. Our method also
achieves an impressive performance of 98.1% on MNIST for neural networks
containing only random weights.
</p>
<a href="http://arxiv.org/abs/2101.06475" target="_blank">arXiv:2101.06475</a> [<a href="http://arxiv.org/pdf/2101.06475" target="_blank">pdf</a>]

<h2>Visual Analytics approach for finding spatiotemporal patterns from COVID19. (arXiv:2101.06476v1 [cs.LG])</h2>
<h3>Arunav Das</h3>
<p>Bounce Back Loan is amongst a number of UK business financial support schemes
launched by UK Government in 2020 amidst pandemic lockdown. Through these
schemes, struggling businesses are provided financial support to weather
economic slowdown from pandemic lockdown. {\pounds}43.5bn loan value has been
provided as of 17th Dec2020. However, with no major checks for granting these
loans and looming prospect of loan losses from write-offs from failed
businesses and fraud, this paper theorizes prospect of applying spatiotemporal
modelling technique to explore if geospatial patterns and temporal analysis
could aid design of loan grant criteria for schemes. Application of Clustering
and Visual Analytics framework to business demographics, survival rate and
Sector concentration shows Inner and Outer London spatial patterns which
historic business failures and reversal of the patterns under COVID-19 implying
sector influence on spatial clusters. Combination of unsupervised clustering
technique with multinomial logistic regression modelling on research datasets
complimented by additional datasets on other support schemes, business
structure and financial crime, is recommended for modelling business
vulnerability to certain types of financial market or economic condition. The
limitations of clustering technique for high dimensional is discussed along
with relevance of an applicable model for continuing the research through next
steps.
</p>
<a href="http://arxiv.org/abs/2101.06476" target="_blank">arXiv:2101.06476</a> [<a href="http://arxiv.org/pdf/2101.06476" target="_blank">pdf</a>]

<h2>Wearable Sensors for Spatio-Temporal Grip Force Profiling. (arXiv:2101.06479v1 [cs.RO])</h2>
<h3>Rongrong Liu, Florent Nageotte, Philippe Zanne, Michel de Mathelin, Birgitta Dresp-Langley</h3>
<p>Wearable biosensor technology enables real-time, convenient, and continuous
monitoring of users behavioral signals. Such include signals relative to body
motion, body temperature, biological or biochemical markers, and individual
grip forces, which are studied in this paper. A four step pick and drop image
guided and robot assisted precision task has been designed for exploiting a
wearable wireless sensor glove system. Individual spatio temporal grip forces
are analyzed on the basis of thousands of individual sensor data, collected
from different locations on the dominant and non-dominant hands of each of
three users in ten successive task sessions. Statistical comparisons reveal
specific differences between grip force profiles of the individual users as a
function of task skill level (expertise) and time.
</p>
<a href="http://arxiv.org/abs/2101.06479" target="_blank">arXiv:2101.06479</a> [<a href="http://arxiv.org/pdf/2101.06479" target="_blank">pdf</a>]

<h2>SelfMatch: Combining Contrastive Self-Supervision and Consistency for Semi-Supervised Learning. (arXiv:2101.06480v1 [cs.LG])</h2>
<h3>Byoungjip Kim, Jinho Choo, Yeong-Dae Kwon, Seongho Joe, Seungjai Min, Youngjune Gwon</h3>
<p>This paper introduces SelfMatch, a semi-supervised learning method that
combines the power of contrastive self-supervised learning and consistency
regularization. SelfMatch consists of two stages: (1) self-supervised
pre-training based on contrastive learning and (2) semi-supervised fine-tuning
based on augmentation consistency regularization. We empirically demonstrate
that SelfMatch achieves the state-of-the-art results on standard benchmark
datasets such as CIFAR-10 and SVHN. For example, for CIFAR-10 with 40 labeled
examples, SelfMatch achieves 93.19% accuracy that outperforms the strong
previous methods such as MixMatch (52.46%), UDA (70.95%), ReMixMatch (80.9%),
and FixMatch (86.19%). We note that SelfMatch can close the gap between
supervised learning (95.87%) and semi-supervised learning (93.19%) by using
only a few labels for each class.
</p>
<a href="http://arxiv.org/abs/2101.06480" target="_blank">arXiv:2101.06480</a> [<a href="http://arxiv.org/pdf/2101.06480" target="_blank">pdf</a>]

<h2>The Connection between Discrete- and Continuous-Time Descriptions of Gaussian Continuous Processes. (arXiv:2101.06482v1 [stat.ML])</h2>
<h3>Federica Ferretti, Victor Chard&#xe8;s, Thierry Mora, Aleksandra M Walczak, Irene Giardina</h3>
<p>Learning the continuous equations of motion from discrete observations is a
common task in all areas of physics. However, not any discretization of a
Gaussian continuous-time stochastic process can be adopted in parametric
inference. We show that discretizations yielding consistent estimators have the
property of `invariance under coarse-graining', and correspond to fixed points
of a renormalization group map on the space of autoregressive moving average
(ARMA) models (for linear processes). This result explains why combining
differencing schemes for derivatives reconstruction and local-in-time inference
approaches does not work for time series analysis of second or higher order
stochastic differential equations, even if the corresponding integration
schemes may be acceptably good for numerical simulations.
</p>
<a href="http://arxiv.org/abs/2101.06482" target="_blank">arXiv:2101.06482</a> [<a href="http://arxiv.org/pdf/2101.06482" target="_blank">pdf</a>]

<h2>From hand to brain and back: Grip forces deliver insight into the functional plasticity of somatosensory processes. (arXiv:2101.06483v1 [cs.RO])</h2>
<h3>Birgitta Dresp-Langley</h3>
<p>The human somatosensory cortex is intimately linked to other central brain
functions such as vision, audition, mechanoreception, and motor planning and
control. These links are established through brain learning, and display a
considerable functional plasticity. This latter fulfills an important adaptive
role and ensures, for example, that humans are able to reliably manipulate and
control objects in the physical world under constantly changing conditions in
their immediate sensory environment. Variations in human grip force are a
direct reflection of this specific kind of functional plasticity. Data from
preliminary experiments where wearable wireless sensor technology (sensor
gloves) was exploited to measure human grip force variations under varying
sensory input conditions (eyes open or shut, soft music or hard music during
gripping) are discussed here to show the extent to which grip force sensing
permits quantifying somatosensory brain interactions and their functional
plasticity. Experiments to take this preliminary work further are suggested.
Implications for robotics, in particular the development of end-effector robots
for upper limb movement planning and control, are brought forward.
</p>
<a href="http://arxiv.org/abs/2101.06483" target="_blank">arXiv:2101.06483</a> [<a href="http://arxiv.org/pdf/2101.06483" target="_blank">pdf</a>]

<h2>Artificial Intelligence for Emotion-Semantic Trending and People Emotion Detection During COVID-19 Social Isolation. (arXiv:2101.06484v1 [cs.AI])</h2>
<h3>Hamed Jelodar, Rita Orji, Stan Matwin, Swarna Weerasinghe, Oladapo Oyebode, Yongli Wang</h3>
<p>Taking advantage of social media platforms, such as Twitter, this paper
provides an effective framework for emotion detection among those who are
quarantined. Early detection of emotional feelings and their trends help
implement timely intervention strategies. Given the limitations of medical
diagnosis of early emotional change signs during the quarantine period,
artificial intelligence models provide effective mechanisms in uncovering early
signs, symptoms and escalating trends. Novelty of the approach presented herein
is a multitask methodological framework of text data processing, implemented as
a pipeline for meaningful emotion detection and analysis, based on the
Plutchik/Ekman approach to emotion detection and trend detection. We present an
evaluation of the framework and a pilot system. Results of confirm the
effectiveness of the proposed framework for topic trends and emotion detection
of COVID-19 tweets. Our findings revealed Stay-At-Home restrictions result in
people expressing on twitter both negative and positive emotional semantics.
Semantic trends of safety issues related to staying at home rapidly decreased
within the 28 days and also negative feelings related to friends dying and
quarantined life increased in some days. These findings have potential to
impact public health policy decisions through monitoring trends of emotional
feelings of those who are quarantined. The framework presented here has
potential to assist in such monitoring by using as an online emotion detection
tool kit.
</p>
<a href="http://arxiv.org/abs/2101.06484" target="_blank">arXiv:2101.06484</a> [<a href="http://arxiv.org/pdf/2101.06484" target="_blank">pdf</a>]

<h2>Bladder segmentation based on deep learning approaches: current limitations and lessons. (arXiv:2101.06498v1 [cs.CV])</h2>
<h3>Mark G. Bandyk, Dheeraj R Gopireddy, Chandana Lall, K.C. Balaji, Jose Dolz</h3>
<p>Precise determination and assessment of bladder cancer (BC) extent of muscle
invasion involvement guides proper risk stratification and personalized therapy
selection. In this context, segmentation of both bladder walls and cancer are
of pivotal importance, as it provides invaluable information to stage the
primary tumour. Hence, multi region segmentation on patients presenting with
symptoms of bladder tumours using deep learning heralds a new level of staging
accuracy and prediction of the biologic behaviour of the tumour. Nevertheless,
despite the success of these models in other medical problems, progress in
multi region bladder segmentation is still at a nascent stage, with just a
handful of works tackling a multi region scenario. Furthermore, most existing
approaches systematically follow prior literature in other clinical problems,
without casting a doubt on the validity of these methods on bladder
segmentation, which may present different challenges. Inspired by this, we
provide an in-depth look at bladder cancer segmentation using deep learning
models. The critical determinants for accurate differentiation of muscle
invasive disease, current status of deep learning based bladder segmentation,
lessons and limitations of prior work are highlighted.
</p>
<a href="http://arxiv.org/abs/2101.06498" target="_blank">arXiv:2101.06498</a> [<a href="http://arxiv.org/pdf/2101.06498" target="_blank">pdf</a>]

<h2>Multi-objective Search of Robust Neural Architectures against Multiple Types of Adversarial Attacks. (arXiv:2101.06507v1 [cs.LG])</h2>
<h3>Jia Liu, Yaochu Jin</h3>
<p>Many existing deep learning models are vulnerable to adversarial examples
that are imperceptible to humans. To address this issue, various methods have
been proposed to design network architectures that are robust to one particular
type of adversarial attacks. It is practically impossible, however, to predict
beforehand which type of attacks a machine learn model may suffer from. To
address this challenge, we propose to search for deep neural architectures that
are robust to five types of well-known adversarial attacks using a
multi-objective evolutionary algorithm. To reduce the computational cost, a
normalized error rate of a randomly chosen attack is calculated as the
robustness for each newly generated neural architecture at each generation. All
non-dominated network architectures obtained by the proposed method are then
fully trained against randomly chosen adversarial attacks and tested on two
widely used datasets. Our experimental results demonstrate the superiority of
optimized neural architectures found by the proposed approach over
state-of-the-art networks that are widely used in the literature in terms of
the classification accuracy under different adversarial attacks.
</p>
<a href="http://arxiv.org/abs/2101.06507" target="_blank">arXiv:2101.06507</a> [<a href="http://arxiv.org/pdf/2101.06507" target="_blank">pdf</a>]

<h2>Phases of learning dynamics in artificial neural networks: with or without mislabeled data. (arXiv:2101.06509v1 [cs.LG])</h2>
<h3>Yu Feng, Yuhai Tu</h3>
<p>Despite tremendous success of deep neural network in machine learning, the
underlying reason for its superior learning capability remains unclear. Here,
we present a framework based on statistical physics to study dynamics of
stochastic gradient descent (SGD) that drives learning in neural networks. By
using the minibatch gradient ensemble, we construct order parameters to
characterize dynamics of weight updates in SGD. Without mislabeled data, we
find that the SGD learning dynamics transitions from a fast learning phase to a
slow exploration phase, which is associated with large changes in order
parameters that characterize the alignment of SGD gradients and their mean
amplitude. In the case with randomly mislabeled samples, SGD learning dynamics
falls into four distinct phases. The system first finds solutions for the
correctly labeled samples in phase I, it then wanders around these solutions in
phase II until it finds a direction to learn the mislabeled samples during
phase III, after which it finds solutions that satisfy all training samples
during phase IV. Correspondingly, the test error decreases during phase I and
remains low during phase II; however, it increases during phase III and reaches
a high plateau during phase IV. The transitions between different phases can be
understood by changes of order parameters that characterize the alignment of
mean gradients for the correctly and incorrectly labeled samples and their
(relative) strength during learning. We find that individual sample losses for
the two datasets are most separated during phase II, which leads to a cleaning
process to eliminate mislabeled samples for improving generalization.
</p>
<a href="http://arxiv.org/abs/2101.06509" target="_blank">arXiv:2101.06509</a> [<a href="http://arxiv.org/pdf/2101.06509" target="_blank">pdf</a>]

<h2>Towards Searching Efficient and Accurate Neural Network Architectures in Binary Classification Problems. (arXiv:2101.06511v1 [cs.LG])</h2>
<h3>Yigit Alparslan, Ethan Jacob Moyer, Isamu Mclean Isozaki, Daniel Schwartz, Adam Dunlop, Shesh Dave, Edward Kim</h3>
<p>In recent years, deep neural networks have had great success in machine
learning and pattern recognition. Architecture size for a neural network
contributes significantly to the success of any neural network. In this study,
we optimize the selection process by investigating different search algorithms
to find a neural network architecture size that yields the highest accuracy. We
apply binary search on a very well-defined binary classification network search
space and compare the results to those of linear search. We also propose how to
relax some of the assumptions regarding the dataset so that our solution can be
generalized to any binary classification problem. We report a 100-fold running
time improvement over the naive linear search when we apply the binary search
method to our datasets in order to find the best architecture candidate. By
finding the optimal architecture size for any binary classification problem
quickly, we hope that our research contributes to discovering intelligent
algorithms for optimizing architecture size selection in machine learning.
</p>
<a href="http://arxiv.org/abs/2101.06511" target="_blank">arXiv:2101.06511</a> [<a href="http://arxiv.org/pdf/2101.06511" target="_blank">pdf</a>]

<h2>Evaluating Online and Offline Accuracy Traversal Algorithms for k-Complete Neural Network Architectures. (arXiv:2101.06518v1 [cs.LG])</h2>
<h3>Yigit Alparslan, Ethan Jacob Moyer, Edward Kim</h3>
<p>Architecture sizes for neural networks have been studied widely and several
search methods have been offered to find the best architecture size in the
shortest amount of time possible. In this paper, we study compact neural
network architectures for binary classification and investigate improvements in
speed and accuracy when favoring overcomplete architecture candidates that have
a very high-dimensional representation of the input. We hypothesize that an
overcomplete model architecture that creates a relatively high-dimensional
representation of the input will be not only be more accurate but would also be
easier and faster to find. In an NxM search space, we propose an online
traversal algorithm that finds the best architecture candidate in O(1) time for
best case and O(N) amortized time for average case for any compact binary
classification problem by using k-completeness as heuristics in our search. The
two other offline search algorithms we implement are brute force traversal and
diagonal traversal, which both find the best architecture candidate in O(NxM)
time. We compare our new algorithm to brute force and diagonal searching as a
baseline and report search time improvement of 52.1% over brute force and of
15.4% over diagonal search to find the most accurate neural network
architecture when given the same dataset. In all cases discussed in the paper,
our online traversal algorithm can find an accurate, if not better,
architecture in significantly shorter amount of time.
</p>
<a href="http://arxiv.org/abs/2101.06518" target="_blank">arXiv:2101.06518</a> [<a href="http://arxiv.org/pdf/2101.06518" target="_blank">pdf</a>]

<h2>Hierarchical Reinforcement Learning By Discovering Intrinsic Options. (arXiv:2101.06521v1 [cs.LG])</h2>
<h3>Jesse Zhang, Haonan Yu, Wei Xu</h3>
<p>We propose a hierarchical reinforcement learning method, HIDIO, that can
learn task-agnostic options in a self-supervised manner while jointly learning
to utilize them to solve sparse-reward tasks. Unlike current hierarchical RL
approaches that tend to formulate goal-reaching low-level tasks or pre-define
ad hoc lower-level policies, HIDIO encourages lower-level option learning that
is independent of the task at hand, requiring few assumptions or little
knowledge about the task structure. These options are learned through an
intrinsic entropy minimization objective conditioned on the option
sub-trajectories. The learned options are diverse and task-agnostic. In
experiments on sparse-reward robotic manipulation and navigation tasks, HIDIO
achieves higher success rates with greater sample efficiency than regular RL
baselines and two state-of-the-art hierarchical RL methods.
</p>
<a href="http://arxiv.org/abs/2101.06521" target="_blank">arXiv:2101.06521</a> [<a href="http://arxiv.org/pdf/2101.06521" target="_blank">pdf</a>]

<h2>Deep Cox Mixtures for Survival Regression. (arXiv:2101.06536v1 [cs.LG])</h2>
<h3>Chirag Nagpal, Steve Yadlowsky, Negar Rostamzadeh, Katherine Heller</h3>
<p>Survival analysis is a challenging variation of regression modeling because
of the presence of censoring, where the outcome measurement is only partially
known, due to, for example, loss to follow up. Such problems come up frequently
in medical applications, making survival analysis a key endeavor in
biostatistics and machine learning for healthcare, with Cox regression models
being amongst the most commonly employed models. We describe a new approach for
survival analysis regression models, based on learning mixtures of Cox
regressions to model individual survival distributions. We propose an
approximation to the Expectation Maximization algorithm for this model that
does hard assignments to mixture groups to make optimization efficient. In each
group assignment, we fit the hazard ratios within each group using deep neural
networks, and the baseline hazard for each mixture component
non-parametrically.

We perform experiments on multiple real world datasets, and look at the
mortality rates of patients across ethnicity and gender. We emphasize the
importance of calibration in healthcare settings and demonstrate that our
approach outperforms classical and modern survival analysis baselines, both in
terms of discriminative performance and calibration, with large gains in
performance on the minority demographics.
</p>
<a href="http://arxiv.org/abs/2101.06536" target="_blank">arXiv:2101.06536</a> [<a href="http://arxiv.org/pdf/2101.06536" target="_blank">pdf</a>]

<h2>SceneGen: Learning to Generate Realistic Traffic Scenes. (arXiv:2101.06541v1 [cs.CV])</h2>
<h3>Shuhan Tan, Kelvin Wong, Shenlong Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun</h3>
<p>We consider the problem of generating realistic traffic scenes automatically.
Existing methods typically insert actors into the scene according to a set of
hand-crafted heuristics and are limited in their ability to model the true
complexity and diversity of real traffic scenes, thus inducing a content gap
between synthesized traffic scenes versus real ones. As a result, existing
simulators lack the fidelity necessary to train and test self-driving vehicles.
To address this limitation, we present SceneGen, a neural autoregressive model
of traffic scenes that eschews the need for rules and heuristics. In
particular, given the ego-vehicle state and a high definition map of
surrounding area, SceneGen inserts actors of various classes into the scene and
synthesizes their sizes, orientations, and velocities. We demonstrate on two
large-scale datasets SceneGen's ability to faithfully model distributions of
real traffic scenes. Moreover, we show that SceneGen coupled with sensor
simulation can be used to train perception models that generalize to the real
world.
</p>
<a href="http://arxiv.org/abs/2101.06541" target="_blank">arXiv:2101.06541</a> [<a href="http://arxiv.org/pdf/2101.06541" target="_blank">pdf</a>]

<h2>GeoSim: Photorealistic Image Simulation with Geometry-Aware Composition. (arXiv:2101.06543v1 [cs.CV])</h2>
<h3>Yun Chen, Frieda Rong, Shivam Duggal, Shenlong Wang, Xinchen Yan, Sivabalan Manivasagam, Shangjie Xue, Ersin Yumer, Raquel Urtasun</h3>
<p>Scalable sensor simulation is an important yet challenging open problem for
safety-critical domains such as self-driving. Current work in image simulation
either fail to be photorealistic or do not model the 3D environment and the
dynamic objects within, losing high-level control and physical realism. In this
paper, we present GeoSim, a geometry-aware image composition process that
synthesizes novel urban driving scenes by augmenting existing images with
dynamic objects extracted from other scenes and rendered at novel poses.
Towards this goal, we first build a diverse bank of 3D objects with both
realistic geometry and appearance from sensor data. During simulation, we
perform a novel geometry-aware simulation-by-composition procedure which 1)
proposes plausible and realistic object placements into a given scene, 2)
renders novel views of dynamic objects from the asset bank, and 3) composes and
blends the rendered image segments. The resulting synthetic images are
photorealistic, traffic-aware, and geometrically consistent, allowing image
simulation to scale to complex use cases. We demonstrate two such important
applications: long-range realistic video simulation across multiple camera
sensors, and synthetic data generation for data augmentation on downstream
segmentation tasks.
</p>
<a href="http://arxiv.org/abs/2101.06543" target="_blank">arXiv:2101.06543</a> [<a href="http://arxiv.org/pdf/2101.06543" target="_blank">pdf</a>]

<h2>VideoClick: Video Object Segmentation with a Single Click. (arXiv:2101.06545v1 [cs.CV])</h2>
<h3>Namdar Homayounfar, Justin Liang, Wei-Chiu Ma, Raquel Urtasun</h3>
<p>Annotating videos with object segmentation masks typically involves a two
stage procedure of drawing polygons per object instance for all the frames and
then linking them through time. While simple, this is a very tedious, time
consuming and expensive process, making the creation of accurate annotations at
scale only possible for well-funded labs. What if we were able to segment an
object in the full video with only a single click? This will enable video
segmentation at scale with a very low budget opening the door to many
applications. Towards this goal, in this paper we propose a bottom up approach
where given a single click for each object in a video, we obtain the
segmentation masks of these objects in the full video. In particular, we
construct a correlation volume that assigns each pixel in a target frame to
either one of the objects in the reference frame or the background. We then
refine this correlation volume via a recurrent attention module and decode the
final segmentation. To evaluate the performance, we label the popular and
challenging Cityscapes dataset with video object segmentations. Results on this
new CityscapesVideo dataset show that our approach outperforms all the
baselines in this challenging setting.
</p>
<a href="http://arxiv.org/abs/2101.06545" target="_blank">arXiv:2101.06545</a> [<a href="http://arxiv.org/pdf/2101.06545" target="_blank">pdf</a>]

<h2>LookOut: Diverse Multi-Future Prediction and Planning for Self-Driving. (arXiv:2101.06547v1 [cs.RO])</h2>
<h3>Alexander Cui, Abbas Sadat, Sergio Casas, Renjie Liao, Raquel Urtasun</h3>
<p>Self-driving vehicles need to anticipate a diverse set of future traffic
scenarios in order to safely share the road with other traffic participants
that may exhibit rare but dangerous driving. In this paper, we present LookOut,
an approach to jointly perceive the environment and predict a diverse set of
futures from sensor data, estimate their probability, and optimize a
contingency plan over these diverse future realizations. In particular, we
learn a diverse joint distribution over multi-agent future trajectories in a
traffic scene that allows us to cover a wide range of future modes with high
sample efficiency while leveraging the expressive power of generative models.
Unlike previous work in diverse motion forecasting, our diversity objective
explicitly rewards sampling future scenarios that require distinct reactions
from the self-driving vehicle for improved safety. Our contingency planner then
finds comfortable trajectories that ensure safe reactions to a wide range of
future scenarios. Through extensive evaluations, we show that our model
demonstrates significantly more diverse and sample-efficient motion forecasting
in a large-scale self-driving dataset as well as safer and more comfortable
motion plans in long-term closed-loop simulations than current state-of-the-art
models.
</p>
<a href="http://arxiv.org/abs/2101.06547" target="_blank">arXiv:2101.06547</a> [<a href="http://arxiv.org/pdf/2101.06547" target="_blank">pdf</a>]

<h2>AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles. (arXiv:2101.06549v1 [cs.RO])</h2>
<h3>Jingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren, Raquel Urtasun</h3>
<p>As self-driving systems become better, simulating scenarios where the
autonomy stack is likely to fail becomes of key importance. Traditionally,
those scenarios are generated for a few scenes with respect to the planning
module that takes ground-truth actor states as input. This does not scale and
cannot identify all possible autonomy failures, such as perception failures due
to occlusion. In this paper, we propose AdvSim, an adversarial framework to
generate safety-critical scenarios for any LiDAR-based autonomy system. Given
an initial traffic scenario, AdvSim modifies the actors' trajectories in a
physically plausible manner and updates the LiDAR sensor data to create
realistic observations of the perturbed world. Importantly, by simulating
directly from sensor data, we obtain adversarial scenarios that are
safety-critical for the full autonomy stack. Our experiments show that our
approach is general and can identify thousands of semantically meaningful
safety-critical scenarios for a wide range of modern self-driving systems.
Furthermore, we show that the robustness and safety of these autonomy systems
can be further improved by training them with scenarios generated by AdvSim.
</p>
<a href="http://arxiv.org/abs/2101.06549" target="_blank">arXiv:2101.06549</a> [<a href="http://arxiv.org/pdf/2101.06549" target="_blank">pdf</a>]

<h2>A multilevel clustering technique for community detection. (arXiv:2101.06551v1 [cs.LG])</h2>
<h3>Isa Inuwa-Dutse, Mark Liptrott, Yannis Korkontzelos</h3>
<p>A network is a composition of many communities, i.e., sets of nodes and edges
with stronger relationships, with distinct and overlapping properties.
Community detection is crucial for various reasons, such as serving as a
functional unit of a network that captures local interactions among nodes.
Communities come in various forms and types, ranging from biologically to
technology-induced ones. As technology-induced communities, social media
networks such as Twitter and Facebook connect a myriad of diverse users,
leading to a highly connected and dynamic ecosystem. Although many algorithms
have been proposed for detecting socially cohesive communities on Twitter,
mining and related tasks remain challenging. This study presents a novel
detection method based on a scalable framework to identify related communities
in a network. We propose a multilevel clustering technique (MCT) that leverages
structural and textual information to identify local communities termed
microcosms. Experimental evaluation on benchmark models and datasets
demonstrate the efficacy of the approach. This study contributes a new
dimension for the detection of cohesive communities in social networks. The
approach offers a better understanding and clarity toward describing how
low-level communities evolve and behave on Twitter. From an application point
of view, identifying such communities can better inform recommendation, among
other benefits.
</p>
<a href="http://arxiv.org/abs/2101.06551" target="_blank">arXiv:2101.06551</a> [<a href="http://arxiv.org/pdf/2101.06551" target="_blank">pdf</a>]

<h2>Self-Supervised Representation Learning from Flow Equivariance. (arXiv:2101.06553v1 [cs.CV])</h2>
<h3>Yuwen Xiong, Mengye Ren, Wenyuan Zeng, Raquel Urtasun</h3>
<p>Self-supervised representation learning is able to learn semantically
meaningful features; however, much of its recent success relies on multiple
crops of an image with very few objects. Instead of learning view-invariant
representation from simple images, humans learn representations in a complex
world with changing scenes by observing object movement, deformation, pose
variation, and ego motion. Motivated by this ability, we present a new
self-supervised learning representation framework that can be directly deployed
on a video stream of complex scenes with many moving objects. Our framework
features a simple flow equivariance objective that encourages the network to
predict the features of another frame by applying a flow transformation to the
features of the current frame. Our representations, learned from
high-resolution raw video, can be readily used for downstream tasks on static
images. Readout experiments on challenging semantic segmentation, instance
segmentation, and object detection benchmarks show that we are able to
outperform representations obtained from previous state-of-the-art methods
including SimCLR and BYOL.
</p>
<a href="http://arxiv.org/abs/2101.06553" target="_blank">arXiv:2101.06553</a> [<a href="http://arxiv.org/pdf/2101.06553" target="_blank">pdf</a>]

<h2>Diverse Complexity Measures for Dataset Curation in Self-driving. (arXiv:2101.06554v1 [cs.LG])</h2>
<h3>Abbas Sadat, Sean Segal, Sergio Casas, James Tu, Bin Yang, Raquel Urtasun, Ersin Yumer</h3>
<p>Modern self-driving autonomy systems heavily rely on deep learning. As a
consequence, their performance is influenced significantly by the quality and
richness of the training data. Data collecting platforms can generate many
hours of raw data in a daily basis, however, it is not feasible to label
everything. It is thus of key importance to have a mechanism to identify "what
to label". Active learning approaches identify examples to label, but their
interestingness is tied to a fixed model performing a particular task. These
assumptions are not valid in self-driving, where we have to solve a diverse set
of tasks (i.e., perception, and motion forecasting) and our models evolve over
time frequently. In this paper we introduce a novel approach and propose a new
data selection method that exploits a diverse set of criteria that quantize
interestingness of traffic scenes. Our experiments on a wide range of tasks and
models show that the proposed curation pipeline is able to select datasets that
lead to better generalization and higher performance.
</p>
<a href="http://arxiv.org/abs/2101.06554" target="_blank">arXiv:2101.06554</a> [<a href="http://arxiv.org/pdf/2101.06554" target="_blank">pdf</a>]

<h2>TrafficSim: Learning to Simulate Realistic Multi-Agent Behaviors. (arXiv:2101.06557v1 [cs.RO])</h2>
<h3>Simon Suo, Sebastian Regalado, Sergio Casas, Raquel Urtasun</h3>
<p>Simulation has the potential to massively scale evaluation of self-driving
systems enabling rapid development as well as safe deployment. To close the gap
between simulation and the real world, we need to simulate realistic
multi-agent behaviors. Existing simulation environments rely on heuristic-based
models that directly encode traffic rules, which cannot capture irregular
maneuvers (e.g., nudging, U-turns) and complex interactions (e.g., yielding,
merging). In contrast, we leverage real-world data to learn directly from human
demonstration and thus capture a more diverse set of actor behaviors. To this
end, we propose TrafficSim, a multi-agent behavior model for realistic traffic
simulation. In particular, we leverage an implicit latent variable model to
parameterize a joint actor policy that generates socially-consistent plans for
all actors in the scene jointly. To learn a robust policy amenable for long
horizon simulation, we unroll the policy in training and optimize through the
fully differentiable simulation across time. Our learning objective
incorporates both human demonstrations as well as common sense. We show
TrafficSim generates significantly more realistic and diverse traffic scenarios
as compared to a diverse set of baselines. Notably, we can exploit trajectories
generated by TrafficSim as effective data augmentation for training better
motion planner.
</p>
<a href="http://arxiv.org/abs/2101.06557" target="_blank">arXiv:2101.06557</a> [<a href="http://arxiv.org/pdf/2101.06557" target="_blank">pdf</a>]

<h2>Deep-Mobility: A Deep Learning Approach for an Efficient and Reliable 5G Handover. (arXiv:2101.06558v1 [cs.LG])</h2>
<h3>Rahul Arun Paropkari, Anurag Thantharate, Cory Beard</h3>
<p>5G cellular networks are being deployed all over the world and this
architecture supports ultra-dense network (UDN) deployment. Small cells have a
very important role in providing 5G connectivity to the end users. Exponential
increases in devices, data and network demands make it mandatory for the
service providers to manage handovers better, to cater to the services that a
user desire. In contrast to any traditional handover improvement scheme, we
develop a 'Deep-Mobility' model by implementing a deep learning neural network
(DLNN) to manage network mobility, utilizing in-network deep learning and
prediction. We use network key performance indicators (KPIs) to train our model
to analyze network traffic and handover requirements. In this method, RF signal
conditions are continuously observed and tracked using deep learning neural
networks such as the Recurrent neural network (RNN) or Long Short-Term Memory
network (LSTM) and system level inputs are also considered in conjunction, to
take a collective decision for a handover. We can study multiple parameters and
interactions between system events along with the user mobility, which would
then trigger a handoff in any given scenario. Here, we show the fundamental
modeling approach and demonstrate usefulness of our model while investigating
impacts and sensitivities of certain KPIs from the user equipment (UE) and
network side.
</p>
<a href="http://arxiv.org/abs/2101.06558" target="_blank">arXiv:2101.06558</a> [<a href="http://arxiv.org/pdf/2101.06558" target="_blank">pdf</a>]

<h2>Adversarial Attacks On Multi-Agent Communication. (arXiv:2101.06560v1 [cs.LG])</h2>
<h3>James Tu, Tsunhsuan Wang, Jingkang Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun</h3>
<p>Growing at a very fast pace, modern autonomous systems will soon be deployed
at scale, opening up the possibility for cooperative multi-agent systems. By
sharing information and distributing workloads, autonomous agents can better
perform their tasks and enjoy improved computation efficiency. However, such
advantages rely heavily on communication channels which have been shown to be
vulnerable to security breaches. Thus, communication can be compromised to
execute adversarial attacks on deep learning models which are widely employed
in modern systems. In this paper, we explore such adversarial attacks in a
novel multi-agent setting where agents communicate by sharing learned
intermediate representations. We observe that an indistinguishable adversarial
message can severely degrade performance, but becomes weaker as the number of
benign agents increase. Furthermore, we show that transfer attacks are more
difficult in this setting when compared to directly perturbing the inputs, as
it is necessary to align the distribution of communication messages with domain
adaptation. Finally, we show that low-budget online attacks can be achieved by
exploiting the temporal consistency of streaming sensory inputs.
</p>
<a href="http://arxiv.org/abs/2101.06560" target="_blank">arXiv:2101.06560</a> [<a href="http://arxiv.org/pdf/2101.06560" target="_blank">pdf</a>]

<h2>Asynchronous Multi-View SLAM. (arXiv:2101.06562v1 [cs.RO])</h2>
<h3>Anqi Joyce Yang, Can Cui, Ioan Andrei B&#xe2;rsan, Raquel Urtasun, Shenlong Wang</h3>
<p>Existing multi-camera SLAM systems assume synchronized shutters for all
cameras, which is often not the case in practice. In this work, we propose a
generalized multi-camera SLAM formulation which accounts for asynchronous
sensor observations. Our framework integrates a continuous-time motion model to
relate information across asynchronous multi-frames during tracking, local
mapping, and loop closing. For evaluation, we collected AMV-Bench, a
challenging new SLAM dataset covering 482 km of driving recorded using our
asynchronous multi-camera robotic platform. AMV-Bench is over an order of
magnitude larger than previous multi-view HD outdoor SLAM datasets, and covers
diverse and challenging motions and environments. Our experiments emphasize the
necessity of asynchronous sensor modeling, and show that the use of multiple
cameras is critical towards robust and accurate SLAM in challenging outdoor
scenes.
</p>
<a href="http://arxiv.org/abs/2101.06562" target="_blank">arXiv:2101.06562</a> [<a href="http://arxiv.org/pdf/2101.06562" target="_blank">pdf</a>]

<h2>Stereo Camera Visual SLAM with Hierarchical Masking and Motion-state Classification at Outdoor Construction Sites Containing Large Dynamic Objects. (arXiv:2101.06563v1 [cs.RO])</h2>
<h3>Runqiu Bao, Ren Komatsu, Renato Miyagusuku, Masaki Chino, Atsushi Yamashita, Hajime Asama</h3>
<p>At modern construction sites, utilizing GNSS (Global Navigation Satellite
System) to measure the real-time location and orientation (i.e. pose) of
construction machines and navigate them is very common. However, GNSS is not
always available. Replacing GNSS with on-board cameras and visual simultaneous
localization and mapping (visual SLAM) to navigate the machines is a
cost-effective solution. Nevertheless, at construction sites, multiple
construction machines will usually work together and side-by-side, causing
large dynamic occlusions in the cameras' view. Standard visual SLAM cannot
handle large dynamic occlusions well. In this work, we propose a motion
segmentation method to efficiently extract static parts from crowded dynamic
scenes to enable robust tracking of camera ego-motion. Our method utilizes
semantic information combined with object-level geometric constraints to
quickly detect the static parts of the scene. Then, we perform a two-step
coarse-to-fine ego-motion tracking with reference to the static parts. This
leads to a novel dynamic visual SLAM formation. We test our proposals through a
real implementation based on ORB-SLAM2, and datasets we collected from real
construction sites. The results show that when standard visual SLAM fails, our
method can still retain accurate camera ego-motion tracking in real-time.
Comparing to state-of-the-art dynamic visual SLAM methods, ours shows
outstanding efficiency and competitive result trajectory accuracy.
</p>
<a href="http://arxiv.org/abs/2101.06563" target="_blank">arXiv:2101.06563</a> [<a href="http://arxiv.org/pdf/2101.06563" target="_blank">pdf</a>]

<h2>Privacy-Preserving Learning of Human Activity Predictors in Smart Environments. (arXiv:2101.06564v1 [cs.LG])</h2>
<h3>Sharare Zehtabian, Siavash Khodadadeh, Ladislau B&#xf6;l&#xf6;ni, Damla Turgut</h3>
<p>The daily activities performed by a disabled or elderly person can be
monitored by a smart environment, and the acquired data can be used to learn a
predictive model of user behavior. To speed up the learning, several
researchers designed collaborative learning systems that use data from multiple
users. However, disclosing the daily activities of an elderly or disabled user
raises privacy concerns. In this paper, we use state-of-the-art deep neural
network-based techniques to learn predictive human activity models in the
local, centralized, and federated learning settings. A novel aspect of our work
is that we carefully track the temporal evolution of the data available to the
learner and the data shared by the user. In contrast to previous work where
users shared all their data with the centralized learner, we consider users
that aim to preserve their privacy. Thus, they choose between approaches in
order to achieve their goals of predictive accuracy while minimizing the shared
data. To help users make decisions before disclosing any data, we use machine
learning to predict the degree to which a user would benefit from collaborative
learning. We validate our approaches on real-world data.
</p>
<a href="http://arxiv.org/abs/2101.06564" target="_blank">arXiv:2101.06564</a> [<a href="http://arxiv.org/pdf/2101.06564" target="_blank">pdf</a>]

<h2>A Literature Review of Recent Graph Embedding Techniques for Biomedical Data. (arXiv:2101.06569v1 [cs.AI])</h2>
<h3>Yankai Chen, Yaozu Wu, Shicheng Ma, Irwin King</h3>
<p>With the rapid development of biomedical software and hardware, a large
amount of relational data interlinking genes, proteins, chemical components,
drugs, diseases, and symptoms has been collected for modern biomedical
research. Many graph-based learning methods have been proposed to analyze such
type of data, giving a deeper insight into the topology and knowledge behind
the biomedical data, which greatly benefit to both academic research and
industrial application for human healthcare. However, the main difficulty is
how to handle high dimensionality and sparsity of the biomedical graphs.
Recently, graph embedding methods provide an effective and efficient way to
address the above issues. It converts graph-based data into a low dimensional
vector space where the graph structural properties and knowledge information
are well preserved. In this survey, we conduct a literature review of recent
developments and trends in applying graph embedding methods for biomedical
data. We also introduce important applications and tasks in the biomedical
domain as well as associated public biomedical datasets.
</p>
<a href="http://arxiv.org/abs/2101.06569" target="_blank">arXiv:2101.06569</a> [<a href="http://arxiv.org/pdf/2101.06569" target="_blank">pdf</a>]

<h2>Membership Inference Attack on Graph Neural Networks. (arXiv:2101.06570v1 [cs.LG])</h2>
<h3>Iyiola E. Olatunji, Wolfgang Nejdl, Megha Khosla</h3>
<p>Graph Neural Networks (GNNs), which generalize traditional deep neural
networks or graph data, have achieved state of the art performance on several
graph analytical tasks like node classification, link prediction or graph
classification. We focus on how trained GNN models could leak information about
the \emph{member} nodes that they were trained on. In particular, we focus on
answering the question: given a graph, can we determine which nodes were used
for training the GNN model? We operate in the inductive settings for node
classification, which means that none of the nodes in the test set (or the
\emph{non-member} nodes) were seen during the training. We propose a simple
attack model which is able to distinguish between the member and non-member
nodes while just having a black-box access to the model. We experimentally
compare the privacy risks of four representative GNN models. Our results show
that all the studied GNN models are vulnerable to privacy leakage. While in
traditional machine learning models, overfitting is considered the main cause
of such leakage, we show that in GNNs the additional structural information is
the major contributing factor.
</p>
<a href="http://arxiv.org/abs/2101.06570" target="_blank">arXiv:2101.06570</a> [<a href="http://arxiv.org/pdf/2101.06570" target="_blank">pdf</a>]

<h2>S3: Neural Shape, Skeleton, and Skinning Fields for 3D Human Modeling. (arXiv:2101.06571v1 [cs.CV])</h2>
<h3>Ze Yang, Shenlong Wang, Sivabalan Manivasagam, Zeng Huang, Wei-Chiu Ma, Xinchen Yan, Ersin Yumer, Raquel Urtasun</h3>
<p>Constructing and animating humans is an important component for building
virtual worlds in a wide variety of applications such as virtual reality or
robotics testing in simulation. As there are exponentially many variations of
humans with different shape, pose and clothing, it is critical to develop
methods that can automatically reconstruct and animate humans at scale from
real world data. Towards this goal, we represent the pedestrian's shape, pose
and skinning weights as neural implicit functions that are directly learned
from data. This representation enables us to handle a wide variety of different
pedestrian shapes and poses without explicitly fitting a human parametric body
model, allowing us to handle a wider range of human geometries and topologies.
We demonstrate the effectiveness of our approach on various datasets and show
that our reconstructions outperform existing state-of-the-art methods.
Furthermore, our re-animation experiments show that we can generate 3D human
animations at scale from a single RGB image (and/or an optional LiDAR sweep) as
input.
</p>
<a href="http://arxiv.org/abs/2101.06571" target="_blank">arXiv:2101.06571</a> [<a href="http://arxiv.org/pdf/2101.06571" target="_blank">pdf</a>]

<h2>Understanding in Artificial Intelligence. (arXiv:2101.06573v1 [cs.AI])</h2>
<h3>Stefan Maetschke, David Martinez Iraola, Pieter Barnard, Elaheh ShafieiBavani, Peter Zhong, Ying Xu, Antonio Jimeno Yepes</h3>
<p>Current Artificial Intelligence (AI) methods, most based on deep learning,
have facilitated progress in several fields, including computer vision and
natural language understanding. The progress of these AI methods is measured
using benchmarks designed to solve challenging tasks, such as visual question
answering. A question remains of how much understanding is leveraged by these
methods and how appropriate are the current benchmarks to measure understanding
capabilities. To answer these questions, we have analysed existing benchmarks
and their understanding capabilities, defined by a set of understanding
capabilities, and current research streams. We show how progress has been made
in benchmark development to measure understanding capabilities of AI methods
and we review as well how current methods develop understanding capabilities.
</p>
<a href="http://arxiv.org/abs/2101.06573" target="_blank">arXiv:2101.06573</a> [<a href="http://arxiv.org/pdf/2101.06573" target="_blank">pdf</a>]

<h2>Physics-Informed Deep Learning for Traffic State Estimation. (arXiv:2101.06580v1 [cs.LG])</h2>
<h3>Rongye Shi, Zhaobin Mo, Kuang Huang, Xuan Di, Qiang Du</h3>
<p>Traffic state estimation (TSE), which reconstructs the traffic variables
(e.g., density) on road segments using partially observed data, plays an
important role on efficient traffic control and operation that intelligent
transportation systems (ITS) need to provide to people. Over decades, TSE
approaches bifurcate into two main categories, model-driven approaches and
data-driven approaches. However, each of them has limitations: the former
highly relies on existing physical traffic flow models, such as
Lighthill-Whitham-Richards (LWR) models, which may only capture limited
dynamics of real-world traffic, resulting in low-quality estimation, while the
latter requires massive data in order to perform accurate and generalizable
estimation. To mitigate the limitations, this paper introduces a
physics-informed deep learning (PIDL) framework to efficiently conduct
high-quality TSE with small amounts of observed data. PIDL contains both
model-driven and data-driven components, making possible the integration of the
strong points of both approaches while overcoming the shortcomings of either.
This paper focuses on highway TSE with observed data from loop detectors, using
traffic density as the traffic variables. We demonstrate the use of PIDL to
solve (with data from loop detectors) two popular physical traffic flow models,
i.e., Greenshields-based LWR and three-parameter-based LWR, and discover the
model parameters. We then evaluate the PIDL-based highway TSE using the Next
Generation SIMulation (NGSIM) dataset. The experimental results show the
advantages of the PIDL-based approach in terms of estimation accuracy and data
efficiency over advanced baseline TSE methods.
</p>
<a href="http://arxiv.org/abs/2101.06580" target="_blank">arXiv:2101.06580</a> [<a href="http://arxiv.org/pdf/2101.06580" target="_blank">pdf</a>]

<h2>Auto4D: Learning to Label 4D Objects from Sequential Point Clouds. (arXiv:2101.06586v1 [cs.CV])</h2>
<h3>Bin Yang, Min Bai, Ming Liang, Wenyuan Zeng, Raquel Urtasun</h3>
<p>In the past few years we have seen great advances in 3D object detection
thanks to deep learning methods. However, they typically rely on large amounts
of high-quality labels to achieve good performance, which often require
time-consuming and expensive work by human annotators. To address this we
propose an automatic annotation pipeline that generates accurate object
trajectories in 3D (ie, 4D labels) from LiDAR point clouds. Different from
previous works that consider single frames at a time, our approach directly
operates on sequential point clouds to combine richer object observations. The
key idea is to decompose the 4D label into two parts: the 3D size of the
object, and its motion path describing the evolution of the object's pose
through time. More specifically, given a noisy but easy-to-get object track as
initialization, our model first estimates the object size from temporally
aggregated observations, and then refines its motion path by considering both
frame-wise observations as well as temporal motion cues. We validate the
proposed method on a large-scale driving dataset and show that our approach
achieves significant improvements over the baselines. We also showcase the
benefits of our approach under the annotator-in-the-loop setting.
</p>
<a href="http://arxiv.org/abs/2101.06586" target="_blank">arXiv:2101.06586</a> [<a href="http://arxiv.org/pdf/2101.06586" target="_blank">pdf</a>]

<h2>Cost-Efficient Online Hyperparameter Optimization. (arXiv:2101.06590v1 [cs.LG])</h2>
<h3>Jingkang Wang, Mengye Ren, Ilija Bogunovic, Yuwen Xiong, Raquel Urtasun</h3>
<p>Recent work on hyperparameters optimization (HPO) has shown the possibility
of training certain hyperparameters together with regular parameters. However,
these online HPO algorithms still require running evaluation on a set of
validation examples at each training step, steeply increasing the training
cost. To decide when to query the validation loss, we model online HPO as a
time-varying Bayesian optimization problem, on top of which we propose a novel
\textit{costly feedback} setting to capture the concept of the query cost.
Under this setting, standard algorithms are cost-inefficient as they evaluate
on the validation set at every round. In contrast, the cost-efficient GP-UCB
algorithm proposed in this paper queries the unknown function only when the
model is less confident about current decisions. We evaluate our proposed
algorithm by tuning hyperparameters online for VGG and ResNet on CIFAR-10 and
ImageNet100. Our proposed online HPO algorithm reaches human expert-level
performance within a single run of the experiment, while incurring only modest
computational overhead compared to regular training.
</p>
<a href="http://arxiv.org/abs/2101.06590" target="_blank">arXiv:2101.06590</a> [<a href="http://arxiv.org/pdf/2101.06590" target="_blank">pdf</a>]

<h2>PLUME: Efficient 3D Object Detection from Stereo Images. (arXiv:2101.06594v1 [cs.CV])</h2>
<h3>Yan Wang, Bin Yang, Rui Hu, Ming Liang, Raquel Urtasun</h3>
<p>3D object detection plays a significant role in various robotic applications
including self-driving. While many approaches rely on expensive 3D sensors like
LiDAR to produce accurate 3D estimates, stereo-based methods have recently
shown promising results at a lower cost. Existing methods tackle the problem in
two steps: first depth estimation is performed, a pseudo LiDAR point cloud
representation is computed from the depth estimates, and then object detection
is performed in 3D space. However, because the two separate tasks are optimized
in different metric spaces, the depth estimation is biased towards big objects
and may cause sub-optimal performance of 3D detection. In this paper we propose
a model that unifies these two tasks in the same metric space for the first
time. Specifically, our model directly constructs a pseudo LiDAR feature volume
(PLUME) in 3D space, which is used to solve both occupancy estimation and
object detection tasks. PLUME achieves state-of-the-art performance on the
challenging KITTI benchmark, with significantly reduced inference time compared
with existing methods.
</p>
<a href="http://arxiv.org/abs/2101.06594" target="_blank">arXiv:2101.06594</a> [<a href="http://arxiv.org/pdf/2101.06594" target="_blank">pdf</a>]

<h2>MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization. (arXiv:2101.06605v1 [cs.CV])</h2>
<h3>Jiahui Huang, He Wang, Tolga Birdal, Minhyuk Sung, Federica Arrigoni, Shi-Min Hu, Leonidas Guibas</h3>
<p>We present MultiBodySync, a novel, end-to-end trainable multi-body motion
segmentation and rigid registration framework for multiple input 3D point
clouds. The two non-trivial challenges posed by this multi-scan multibody
setting that we investigate are: (i) guaranteeing correspondence and
segmentation consistency across multiple input point clouds capturing different
spatial arrangements of bodies or body parts; and (ii) obtaining robust
motion-based rigid body segmentation applicable to novel object categories. We
propose an approach to address these issues that incorporates spectral
synchronization into an iterative deep declarative network, so as to
simultaneously recover consistent correspondences as well as motion
segmentation. At the same time, by explicitly disentangling the correspondence
and motion segmentation estimation modules, we achieve strong generalizability
across different object categories. Our extensive evaluations demonstrate that
our method is effective on various datasets ranging from rigid parts in
articulated objects to individually moving objects in a 3D scene, be it
single-view or full point clouds.
</p>
<a href="http://arxiv.org/abs/2101.06605" target="_blank">arXiv:2101.06605</a> [<a href="http://arxiv.org/pdf/2101.06605" target="_blank">pdf</a>]

<h2>Network Automatic Pruning: Start NAP and Take a Nap. (arXiv:2101.06608v1 [cs.CV])</h2>
<h3>Wenyuan Zeng, Yuwen Xiong, Raquel Urtasun</h3>
<p>Network pruning can significantly reduce the computation and memory footprint
of large neural networks. To achieve a good trade-off between model size and
performance, popular pruning techniques usually rely on hand-crafted heuristics
and require manually setting the compression ratio for each layer. This process
is typically time-consuming and requires expert knowledge to achieve good
results. In this paper, we propose NAP, a unified and automatic pruning
framework for both fine-grained and structured pruning. It can find out
unimportant components of a network and automatically decide appropriate
compression ratios for different layers, based on a theoretically sound
criterion. Towards this goal, NAP uses an efficient approximation of the
Hessian for evaluating the importances of components, based on a
Kronecker-factored Approximate Curvature method. Despite its simpleness to use,
NAP outperforms previous pruning methods by large margins. For fine-grained
pruning, NAP can compress AlexNet and VGG16 by 25x, and ResNet-50 by 6.7x
without loss in accuracy on ImageNet. For structured pruning (e.g. channel
pruning), it can reduce flops of VGG16 by 5.4x and ResNet-50 by 2.3x with only
1% accuracy drop. More importantly, this method is almost free from
hyper-parameter tuning and requires no expert knowledge. You can start NAP and
then take a nap!
</p>
<a href="http://arxiv.org/abs/2101.06608" target="_blank">arXiv:2101.06608</a> [<a href="http://arxiv.org/pdf/2101.06608" target="_blank">pdf</a>]

<h2>Predictive Processing in Cognitive Robotics: a Review. (arXiv:2101.06611v1 [cs.RO])</h2>
<h3>Alejandra Ciria, Guido Schillaci, Giovanni Pezzulo, Verena V. Hafner, Bruno Lara</h3>
<p>Predictive processing has become an influential framework in cognitive
sciences. This framework turns the traditional view of perception upside down,
claiming that the main flow of information processing is realized in a top-down
hierarchical manner. Furthermore, it aims at unifying perception, cognition,
and action as a single inferential process. However, in the related literature,
the predictive processing framework and its associated schemes such as
predictive coding, active inference, perceptual inference, free-energy
principle, tend to be used interchangeably.

In the field of cognitive robotics there is no clear-cut distinction on which
schemes have been implemented and under which assumptions. In this paper,
working definitions are set with the main aim of analyzing the state of the art
in cognitive robotics research working under the predictive processing
framework as well as some related non-robotic models.

The analysis suggests that, first, both research in cognitive robotics
implementations and non-robotic models needs to be extended to the study of how
multiple exteroceptive modalities can be integrated into prediction error
minimization schemes. Second, a relevant distinction found here is that
cognitive robotics implementations tend to emphasize the learning of a
generative model, while in non-robotics models it is almost absent. Third,
despite the relevance for active inference, few cognitive robotics
implementations examine the issues around control and whether it should result
from the substitution of inverse models with proprioceptive predictions.

Finally, limited attention has been placed on precision weighting and the
tracking of prediction error dynamics. These mechanisms should help to explore
more complex behaviors and tasks in cognitive robotics research under the
predictive processing framework.
</p>
<a href="http://arxiv.org/abs/2101.06611" target="_blank">arXiv:2101.06611</a> [<a href="http://arxiv.org/pdf/2101.06611" target="_blank">pdf</a>]

<h2>Disentangling Observed Causal Effects from Latent Confounders using Method of Moments. (arXiv:2101.06614v1 [cs.LG])</h2>
<h3>Anqi Liu, Hao Liu, Tongxin Li, Saeed Karimi-Bidhendi, Yisong Yue, Anima Anandkumar</h3>
<p>Discovering the complete set of causal relations among a group of variables
is a challenging unsupervised learning problem. Often, this challenge is
compounded by the fact that there are latent or hidden confounders. When only
observational data is available, the problem is ill-posed, i.e. the causal
relationships are non-identifiable unless strong modeling assumptions are made.
When interventions are available, we provide guarantees on identifiability and
learnability under mild assumptions. We assume a linear structural equation
model (SEM) with independent latent factors and directed acyclic graph (DAG)
relationships among the observables. Since the latent variable inference is
based on independent component analysis (ICA), we call this model SEM-ICA. We
use the method of moments principle to establish model identifiability. We
develop efficient algorithms based on coupled tensor decomposition with linear
constraints to obtain scalable and guaranteed solutions. Thus, we provide a
principled approach to tackling the joint problem of causal discovery and
latent variable inference.
</p>
<a href="http://arxiv.org/abs/2101.06614" target="_blank">arXiv:2101.06614</a> [<a href="http://arxiv.org/pdf/2101.06614" target="_blank">pdf</a>]

<h2>Online Robust Sliding-Windowed LiDAR SLAM in Natural Environments. (arXiv:2101.06615v1 [cs.RO])</h2>
<h3>Ha Pham-Quang, Huy Tran-Ngoc, Toan Nguyen-Thanh, Duc Ho-Tran-Minh, Vu Dinh-Quang</h3>
<p>Despite the growing interest for autonomous environmental monitoring,
effective SLAM realization in native habitats remains largely unsolved. In this
paper, we fill this gap by presenting a novel online graph-based SLAM system
for 2D LiDAR sensor in natural environments. By taking advantage of robust
weighting scheme, sliding-windowed optimization, fast scan-matcher and parallel
computing, our system not only delivers stable performance in cluttered
surroudings but also meets real-time constraint. Simulated and experimental
results confirm the feasibility and efficiency in the overall design of the
proposed system.
</p>
<a href="http://arxiv.org/abs/2101.06615" target="_blank">arXiv:2101.06615</a> [<a href="http://arxiv.org/pdf/2101.06615" target="_blank">pdf</a>]

<h2>A relic sketch extraction framework based on detail-aware hierarchical deep network. (arXiv:2101.06616v1 [cs.CV])</h2>
<h3>Jinye Peng, Jiaxin Wang, Jun Wang, Erlei Zhang, Qunxi Zhang, Yongqin Zhang, Xianlin Peng, Kai Yu</h3>
<p>As the first step of the restoration process of painted relics, sketch
extraction plays an important role in cultural research. However, sketch
extraction suffers from serious disease corrosion, which results in broken
lines and noise. To overcome these problems, we propose a deep learning-based
hierarchical sketch extraction framework for painted cultural relics. We design
the sketch extraction process into two stages: coarse extraction and fine
extraction. In the coarse extraction stage, we develop a novel detail-aware
bi-directional cascade network that integrates flow-based
difference-of-Gaussians (FDoG) edge detection and a bi-directional cascade
network (BDCN) under a transfer learning framework. It not only uses the
pre-trained strategy to extenuate the requirements of large datasets for deep
network training but also guides the network to learn the detail
characteristics by the prior knowledge from FDoG. For the fine extraction
stage, we design a new multiscale U-Net (MSU-Net) to effectively remove disease
noise and refine the sketch. Specifically, all the features extracted from
multiple intermediate layers in the decoder of MSU-Net are fused for sketch
predication. Experimental results showed that the proposed method outperforms
the other seven state-of-the-art methods in terms of visual and quantitative
metrics and can also deal with complex backgrounds.
</p>
<a href="http://arxiv.org/abs/2101.06616" target="_blank">arXiv:2101.06616</a> [<a href="http://arxiv.org/pdf/2101.06616" target="_blank">pdf</a>]

<h2>Solving QSAT problems with neural MCTS. (arXiv:2101.06619v1 [cs.AI])</h2>
<h3>Ruiyang Xu, Karl Lieberherr</h3>
<p>Recent achievements from AlphaZero using self-play has shown remarkable
performance on several board games. It is plausible to think that self-play,
starting from zero knowledge, can gradually approximate a winning strategy for
certain two-player games after an amount of training. In this paper, we try to
leverage the computational power of neural Monte Carlo Tree Search (neural
MCTS), the core algorithm from AlphaZero, to solve Quantified Boolean Formula
Satisfaction (QSAT) problems, which are PSPACE complete. Knowing that every
QSAT problem is equivalent to a QSAT game, the game outcome can be used to
derive the solutions of the original QSAT problems. We propose a way to encode
Quantified Boolean Formulas (QBFs) as graphs and apply a graph neural network
(GNN) to embed the QBFs into the neural MCTS. After training, an off-the-shelf
QSAT solver is used to evaluate the performance of the algorithm. Our result
shows that, for problems within a limited size, the algorithm learns to solve
the problem correctly merely from self-play.
</p>
<a href="http://arxiv.org/abs/2101.06619" target="_blank">arXiv:2101.06619</a> [<a href="http://arxiv.org/pdf/2101.06619" target="_blank">pdf</a>]

<h2>Regional Attention Network (RAN) for Head Pose and Fine-grained Gesture Recognition. (arXiv:2101.06634v1 [cs.CV])</h2>
<h3>Ardhendu Behera, Zachary Wharton, Morteza Ghahremani, Swagat Kumar, Nik Bessis</h3>
<p>Affect is often expressed via non-verbal body language such as
actions/gestures, which are vital indicators for human behaviors. Recent
studies on recognition of fine-grained actions/gestures in monocular images
have mainly focused on modeling spatial configuration of body parts
representing body pose, human-objects interactions and variations in local
appearance. The results show that this is a brittle approach since it relies on
accurate body parts/objects detection. In this work, we argue that there exist
local discriminative semantic regions, whose "informativeness" can be evaluated
by the attention mechanism for inferring fine-grained gestures/actions. To this
end, we propose a novel end-to-end \textbf{Regional Attention Network (RAN)},
which is a fully Convolutional Neural Network (CNN) to combine multiple
contextual regions through attention mechanism, focusing on parts of the images
that are most relevant to a given task. Our regions consist of one or more
consecutive cells and are adapted from the strategies used in computing HOG
(Histogram of Oriented Gradient) descriptor. The model is extensively evaluated
on ten datasets belonging to 3 different scenarios: 1) head pose recognition,
2) drivers state recognition, and 3) human action and facial expression
recognition. The proposed approach outperforms the state-of-the-art by a
considerable margin in different metrics.
</p>
<a href="http://arxiv.org/abs/2101.06634" target="_blank">arXiv:2101.06634</a> [<a href="http://arxiv.org/pdf/2101.06634" target="_blank">pdf</a>]

<h2>Context-aware Attentional Pooling (CAP) for Fine-grained Visual Classification. (arXiv:2101.06635v1 [cs.CV])</h2>
<h3>Ardhendu Behera, Zachary Wharton, Pradeep Hewage, Asish Bera</h3>
<p>Deep convolutional neural networks (CNNs) have shown a strong ability in
mining discriminative object pose and parts information for image recognition.
For fine-grained recognition, context-aware rich feature representation of
object/scene plays a key role since it exhibits a significant variance in the
same subcategory and subtle variance among different subcategories. Finding the
subtle variance that fully characterizes the object/scene is not
straightforward. To address this, we propose a novel context-aware attentional
pooling (CAP) that effectively captures subtle changes via sub-pixel gradients,
and learns to attend informative integral regions and their importance in
discriminating different subcategories without requiring the bounding-box
and/or distinguishable part annotations. We also introduce a novel feature
encoding by considering the intrinsic consistency between the informativeness
of the integral regions and their spatial structures to capture the semantic
correlation among them. Our approach is simple yet extremely effective and can
be easily applied on top of a standard classification backbone network. We
evaluate our approach using six state-of-the-art (SotA) backbone networks and
eight benchmark datasets. Our method significantly outperforms the SotA
approaches on six datasets and is very competitive with the remaining two.
</p>
<a href="http://arxiv.org/abs/2101.06635" target="_blank">arXiv:2101.06635</a> [<a href="http://arxiv.org/pdf/2101.06635" target="_blank">pdf</a>]

<h2>Coarse Temporal Attention Network (CTA-Net) for Driver's Activity Recognition. (arXiv:2101.06636v1 [cs.CV])</h2>
<h3>Zachary Wharton, Ardhendu Behera, Yonghuai Liu, Nik Bessis</h3>
<p>There is significant progress in recognizing traditional human activities
from videos focusing on highly distinctive actions involving discriminative
body movements, body-object and/or human-human interactions. Driver's
activities are different since they are executed by the same subject with
similar body parts movements, resulting in subtle changes. To address this, we
propose a novel framework by exploiting the spatiotemporal attention to model
the subtle changes. Our model is named Coarse Temporal Attention Network
(CTA-Net), in which coarse temporal branches are introduced in a trainable
glimpse network. The goal is to allow the glimpse to capture high-level
temporal relationships, such as 'during', 'before' and 'after' by focusing on a
specific part of a video. These branches also respect the topology of the
temporal dynamics in the video, ensuring that different branches learn
meaningful spatial and temporal changes. The model then uses an innovative
attention mechanism to generate high-level action specific contextual
information for activity recognition by exploring the hidden states of an LSTM.
The attention mechanism helps in learning to decide the importance of each
hidden state for the recognition task by weighing them when constructing the
representation of the video. Our approach is evaluated on four publicly
accessible datasets and significantly outperforms the state-of-the-art by a
considerable margin with only RGB video as input.
</p>
<a href="http://arxiv.org/abs/2101.06636" target="_blank">arXiv:2101.06636</a> [<a href="http://arxiv.org/pdf/2101.06636" target="_blank">pdf</a>]

<h2>Removing Undesirable Feature Contributions Using Out-of-Distribution Data. (arXiv:2101.06639v1 [cs.LG])</h2>
<h3>Saehyung Lee, Changhwa Park, Hyungyu Lee, Jihun Yi, Jonghyun Lee, Sungroh Yoon</h3>
<p>Several data augmentation methods deploy unlabeled-in-distribution (UID) data
to bridge the gap between the training and inference of neural networks.
However, these methods have clear limitations in terms of availability of UID
data and dependence of algorithms on pseudo-labels. Herein, we propose a data
augmentation method to improve generalization in both adversarial and standard
learning by using out-of-distribution (OOD) data that are devoid of the
abovementioned issues. We show how to improve generalization theoretically
using OOD data in each learning scenario and complement our theoretical
analysis with experiments on CIFAR-10, CIFAR-100, and a subset of ImageNet. The
results indicate that undesirable features are shared even among image data
that seem to have little correlation from a human point of view. We also
present the advantages of the proposed method through comparison with other
data augmentation methods, which can be used in the absence of UID data.
Furthermore, we demonstrate that the proposed method can further improve the
existing state-of-the-art adversarial training.
</p>
<a href="http://arxiv.org/abs/2101.06639" target="_blank">arXiv:2101.06639</a> [<a href="http://arxiv.org/pdf/2101.06639" target="_blank">pdf</a>]

<h2>Estimating informativeness of samples with Smooth Unique Information. (arXiv:2101.06640v1 [cs.LG])</h2>
<h3>Hrayr Harutyunyan, Alessandro Achille, Giovanni Paolini, Orchid Majumder, Avinash Ravichandran, Rahul Bhotika, Stefano Soatto</h3>
<p>We define a notion of information that an individual sample provides to the
training of a neural network, and we specialize it to measure both how much a
sample informs the final weights and how much it informs the function computed
by the weights. Though related, we show that these quantities have a
qualitatively different behavior. We give efficient approximations of these
quantities using a linearized network and demonstrate empirically that the
approximation is accurate for real-world architectures, such as pre-trained
ResNets. We apply these measures to several problems, such as dataset
summarization, analysis of under-sampled classes, comparison of informativeness
of different data sources, and detection of adversarial and corrupted examples.
Our work generalizes existing frameworks but enjoys better computational
properties for heavily over-parametrized models, which makes it possible to
apply it to real-world networks.
</p>
<a href="http://arxiv.org/abs/2101.06640" target="_blank">arXiv:2101.06640</a> [<a href="http://arxiv.org/pdf/2101.06640" target="_blank">pdf</a>]

<h2>HySTER: A Hybrid Spatio-Temporal Event Reasoner. (arXiv:2101.06644v1 [cs.CV])</h2>
<h3>Theophile Sautory, Nuri Cingillioglu, Alessandra Russo</h3>
<p>The task of Video Question Answering (VideoQA) consists in answering natural
language questions about a video and serves as a proxy to evaluate the
performance of a model in scene sequence understanding. Most methods designed
for VideoQA up-to-date are end-to-end deep learning architectures which
struggle at complex temporal and causal reasoning and provide limited
transparency in reasoning steps. We present the HySTER: a Hybrid
Spatio-Temporal Event Reasoner to reason over physical events in videos. Our
model leverages the strength of deep learning methods to extract information
from video frames with the reasoning capabilities and explainability of
symbolic artificial intelligence in an answer set programming framework. We
define a method based on general temporal, causal and physics rules which can
be transferred across tasks. We apply our model to the CLEVRER dataset and
demonstrate state-of-the-art results in question answering accuracy. This work
sets the foundations for the incorporation of inductive logic programming in
the field of VideoQA.
</p>
<a href="http://arxiv.org/abs/2101.06644" target="_blank">arXiv:2101.06644</a> [<a href="http://arxiv.org/pdf/2101.06644" target="_blank">pdf</a>]

<h2>Generalized Image Reconstruction over T-Algebra. (arXiv:2101.06650v1 [cs.CV])</h2>
<h3>Liang Liao, Xuechun Zhang, Xinqiang Wang, Sen Lin, Xin Liu</h3>
<p>Principal Component Analysis (PCA) is well known for its capability of
dimension reduction and data compression. However, when using PCA for
compressing/reconstructing images, images need to be recast to vectors. The
vectorization of images makes some correlation constraints of neighboring
pixels and spatial information lost. To deal with the drawbacks of the
vectorizations adopted by PCA, we used small neighborhoods of each pixel to
form compounded pixels and use a tensorial version of PCA, called TPCA
(Tensorial Principal Component Analysis), to compress and reconstruct a
compounded image of compounded pixels. Our experiments on public data show that
TPCA compares favorably with PCA in compressing and reconstructing images. We
also show in our experiments that the performance of TPCA increases when the
order of compounded pixels increases.
</p>
<a href="http://arxiv.org/abs/2101.06650" target="_blank">arXiv:2101.06650</a> [<a href="http://arxiv.org/pdf/2101.06650" target="_blank">pdf</a>]

<h2>LaneRCNN: Distributed Representations for Graph-Centric Motion Forecasting. (arXiv:2101.06653v1 [cs.CV])</h2>
<h3>Wenyuan Zeng, Ming Liang, Renjie Liao, Raquel Urtasun</h3>
<p>Forecasting the future behaviors of dynamic actors is an important task in
many robotics applications such as self-driving. It is extremely challenging as
actors have latent intentions and their trajectories are governed by complex
interactions between the other actors, themselves, and the maps. In this paper,
we propose LaneRCNN, a graph-centric motion forecasting model. Importantly,
relying on a specially designed graph encoder, we learn a local lane graph
representation per actor (LaneRoI) to encode its past motions and the local map
topology. We further develop an interaction module which permits efficient
message passing among local graph representations within a shared global lane
graph. Moreover, we parameterize the output trajectories based on lane graphs,
a more amenable prediction parameterization. Our LaneRCNN captures the
actor-to-actor and the actor-to-map relations in a distributed and map-aware
manner. We demonstrate the effectiveness of our approach on the large-scale
Argoverse Motion Forecasting Benchmark. We achieve the 1st place on the
leaderboard and significantly outperform previous best results.
</p>
<a href="http://arxiv.org/abs/2101.06653" target="_blank">arXiv:2101.06653</a> [<a href="http://arxiv.org/pdf/2101.06653" target="_blank">pdf</a>]

<h2>Trilevel Neural Architecture Search for Efficient Single Image Super-Resolution. (arXiv:2101.06658v1 [cs.CV])</h2>
<h3>Yan Wu, Zhiwu Huang, Suryansh Kumar, Rhea Sanjay Sukthanker, Radu Timofte, Luc Van Gool</h3>
<p>This paper proposes a trilevel neural architecture search (NAS) method for
efficient single image super-resolution (SR). For that, we first define the
discrete search space at three-level, i.e., at network-level, cell-level, and
kernel-level (convolution-kernel). For modeling the discrete search space, we
apply a new continuous relaxation on the discrete search spaces to build a
hierarchical mixture of network-path, cell-operations, and kernel-width. Later
an efficient search algorithm is proposed to perform optimization in a
hierarchical supernet manner that provides a globally optimized and compressed
network via joint convolution kernel width pruning, cell structure search, and
network path optimization. Unlike current NAS methods, we exploit a sorted
sparsestmax activation to let the three-level neural structures contribute
sparsely. Consequently, our NAS optimization progressively converges to those
neural structures with dominant contributions to the supernet. Additionally,
our proposed optimization construction enables a simultaneous search and
training in a single phase, which dramatically reduces search and train time
compared to the traditional NAS algorithms. Experiments on the standard
benchmark datasets demonstrate that our NAS algorithm provides SR models that
are significantly lighter in terms of the number of parameters and FLOPS with
PSNR value comparable to the current state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2101.06658" target="_blank">arXiv:2101.06658</a> [<a href="http://arxiv.org/pdf/2101.06658" target="_blank">pdf</a>]

<h2>Identifying Treatment Effects under Unobserved Confounding by Causal Representation Learning. (arXiv:2101.06662v1 [stat.ML])</h2>
<h3>Pengzhou Wu, Kenji Fukumizu</h3>
<p>As an important problem of causal inference, we discuss the estimation of
treatment effects under the existence of unobserved confounding. By
representing the confounder as a latent variable, we propose Counterfactual
VAE, a new variant of variational autoencoder, based on recent advances in
identifiability of representation learning. Combining the identifiability and
classical identification results of causal inference, under mild assumptions on
the generative model and with small noise on the outcome, we theoretically show
that the confounder is identifiable up to an affine transformation and then the
treatment effects can be identified. Experiments on synthetic and
semi-synthetic datasets demonstrate that our method matches the
state-of-the-art, even under settings violating our formal assumptions.
</p>
<a href="http://arxiv.org/abs/2101.06662" target="_blank">arXiv:2101.06662</a> [<a href="http://arxiv.org/pdf/2101.06662" target="_blank">pdf</a>]

<h2>Separable Batch Normalization for Robust Facial Landmark Localization with Cross-protocol Network Training. (arXiv:2101.06663v1 [cs.CV])</h2>
<h3>Shuangping Jin, Zhenhua Feng, Wankou Yang, Josef Kittler</h3>
<p>A big, diverse and balanced training data is the key to the success of deep
neural network training. However, existing publicly available datasets used in
facial landmark localization are usually much smaller than those for other
computer vision tasks. A small dataset without diverse and balanced training
samples cannot support the training of a deep network effectively. To address
the above issues, this paper presents a novel Separable Batch Normalization
(SepBN) module with a Cross-protocol Network Training (CNT) strategy for robust
facial landmark localization. Different from the standard BN layer that uses
all the training data to calculate a single set of parameters, SepBN considers
that the samples of a training dataset may belong to different sub-domains.
Accordingly, the proposed SepBN module uses multiple sets of parameters, each
corresponding to a specific sub-domain. However, the selection of an
appropriate branch in the inference stage remains a challenging task because
the sub-domain of a test sample is unknown. To mitigate this difficulty, we
propose a novel attention mechanism that assigns different weights to each
branch for automatic selection in an effective style. As a further innovation,
the proposed CNT strategy trains a network using multiple datasets having
different facial landmark annotation systems, boosting the performance and
enhancing the generalization capacity of the trained network. The experimental
results obtained on several well-known datasets demonstrate the effectiveness
of the proposed method.
</p>
<a href="http://arxiv.org/abs/2101.06663" target="_blank">arXiv:2101.06663</a> [<a href="http://arxiv.org/pdf/2101.06663" target="_blank">pdf</a>]

<h2>End-to-end Interpretable Neural Motion Planner. (arXiv:2101.06679v1 [cs.CV])</h2>
<h3>Wenyuan Zeng, Wenjie Luo, Simon Suo, Abbas Sadat, Bin Yang, Sergio Casas, Raquel Urtasun</h3>
<p>In this paper, we propose a neural motion planner (NMP) for learning to drive
autonomously in complex urban scenarios that include traffic-light handling,
yielding, and interactions with multiple road-users. Towards this goal, we
design a holistic model that takes as input raw LIDAR data and a HD map and
produces interpretable intermediate representations in the form of 3D
detections and their future trajectories, as well as a cost volume defining the
goodness of each position that the self-driving car can take within the
planning horizon. We then sample a set of diverse physically possible
trajectories and choose the one with the minimum learned cost. Importantly, our
cost volume is able to naturally capture multi-modality. We demonstrate the
effectiveness of our approach in real-world driving data captured in several
cities in North America. Our experiments show that the learned cost volume can
generate safer planning than all the baselines.
</p>
<a href="http://arxiv.org/abs/2101.06679" target="_blank">arXiv:2101.06679</a> [<a href="http://arxiv.org/pdf/2101.06679" target="_blank">pdf</a>]

<h2>KCP: Kernel Cluster Pruning for Dense Labeling Neural Networks. (arXiv:2101.06686v1 [cs.CV])</h2>
<h3>Po-Hsiang Yu, Sih-Sian Wu, Liang-Gee Chen</h3>
<p>Pruning has become a promising technique used to compress and accelerate
neural networks. Existing methods are mainly evaluated on spare labeling
applications. However, dense labeling applications are those closer to real
world problems that require real-time processing on resource-constrained mobile
devices. Pruning for dense labeling applications is still a largely unexplored
field. The prevailing filter channel pruning method removes the entire filter
channel. Accordingly, the interaction between each kernel in one filter channel
is ignored.

In this study, we proposed kernel cluster pruning (KCP) to prune dense
labeling networks. We developed a clustering technique to identify the least
representational kernels in each layer. By iteratively removing those kernels,
the parameter that can better represent the entire network is preserved; thus,
we achieve better accuracy with a decent model size and computation reduction.
When evaluated on stereo matching and semantic segmentation neural networks,
our method can reduce more than 70% of FLOPs with less than 1% of accuracy
drop. Moreover, for ResNet-50 on ILSVRC-2012, our KCP can reduce more than 50%
of FLOPs reduction with 0.13% Top-1 accuracy gain. Therefore, KCP achieves
state-of-the-art pruning results.
</p>
<a href="http://arxiv.org/abs/2101.06686" target="_blank">arXiv:2101.06686</a> [<a href="http://arxiv.org/pdf/2101.06686" target="_blank">pdf</a>]

<h2>Deep Learning based Virtual Point Tracking for Real-Time Target-less Dynamic Displacement Measurement in Railway Applications. (arXiv:2101.06702v1 [cs.CV])</h2>
<h3>Dachuan Shi, Eldar Sabanovic, Luca Rizzetto, Viktor Skrickij, Roberto Oliverio, Nadia Kaviani, Yunguang Ye, Gintautas Bureika, Stefano Ricci, Markus Hecht</h3>
<p>In the application of computer-vision based displacement measurement, an
optical target is usually required to prove the reference. In the case that the
optical target cannot be attached to the measuring objective, edge detection,
feature matching and template matching are the most common approaches in
target-less photogrammetry. However, their performance significantly relies on
parameter settings. This becomes problematic in dynamic scenes where
complicated background texture exists and varies over time. To tackle this
issue, we propose virtual point tracking for real-time target-less dynamic
displacement measurement, incorporating deep learning techniques and domain
knowledge. Our approach consists of three steps: 1) automatic calibration for
detection of region of interest; 2) virtual point detection for each video
frame using deep convolutional neural network; 3) domain-knowledge based rule
engine for point tracking in adjacent frames. The proposed approach can be
executed on an edge computer in a real-time manner (i.e. over 30 frames per
second). We demonstrate our approach for a railway application, where the
lateral displacement of the wheel on the rail is measured during operation. We
also implement an algorithm using template matching and line detection as the
baseline for comparison. The numerical experiments have been performed to
evaluate the performance and the latency of our approach in the harsh railway
environment with noisy and varying backgrounds.
</p>
<a href="http://arxiv.org/abs/2101.06702" target="_blank">arXiv:2101.06702</a> [<a href="http://arxiv.org/pdf/2101.06702" target="_blank">pdf</a>]

<h2>Adversarial Interaction Attack: Fooling AI to Misinterpret Human Intentions. (arXiv:2101.06704v1 [cs.AI])</h2>
<h3>Nodens Koren, Qiuhong Ke, Yisen Wang, James Bailey, Xingjun Ma</h3>
<p>Understanding the actions of both humans and artificial intelligence (AI)
agents is important before modern AI systems can be fully integrated into our
daily life. In this paper, we show that, despite their current huge success,
deep learning based AI systems can be easily fooled by subtle adversarial noise
to misinterpret the intention of an action in interaction scenarios. Based on a
case study of skeleton-based human interactions, we propose a novel adversarial
attack on interactions, and demonstrate how DNN-based interaction models can be
tricked to predict the participants' reactions in unexpected ways. From a
broader perspective, the scope of our proposed attack method is not confined to
problems related to skeleton data but can also be extended to any type of
problems involving sequential regressions. Our study highlights potential risks
in the interaction loop with AI and humans, which need to be carefully
addressed when deploying AI systems in safety-critical applications.
</p>
<a href="http://arxiv.org/abs/2101.06704" target="_blank">arXiv:2101.06704</a> [<a href="http://arxiv.org/pdf/2101.06704" target="_blank">pdf</a>]

<h2>Human Activity Recognition Using Multichannel Convolutional Neural Network. (arXiv:2101.06709v1 [cs.CV])</h2>
<h3>Niloy Sikder, Md. Sanaullah Chowdhury, Abu Shamim Mohammad Arif, Abdullah-Al Nahid</h3>
<p>Human Activity Recognition (HAR) simply refers to the capacity of a machine
to perceive human actions. HAR is a prominent application of advanced Machine
Learning and Artificial Intelligence techniques that utilize computer vision to
understand the semantic meanings of heterogeneous human actions. This paper
describes a supervised learning method that can distinguish human actions based
on data collected from practical human movements. The primary challenge while
working with HAR is to overcome the difficulties that come with the
cyclostationary nature of the activity signals. This study proposes a HAR
classification model based on a two-channel Convolutional Neural Network (CNN)
that makes use of the frequency and power features of the collected human
action signals. The model was tested on the UCI HAR dataset, which resulted in
a 95.25% classification accuracy. This approach will help to conduct further
researches on the recognition of human activities based on their biomedical
signals.
</p>
<a href="http://arxiv.org/abs/2101.06709" target="_blank">arXiv:2101.06709</a> [<a href="http://arxiv.org/pdf/2101.06709" target="_blank">pdf</a>]

<h2>Heterogeneous Hand Guise Classification Based on Surface Electromyographic Signals Using Multichannel Convolutional Neural Network. (arXiv:2101.06715v1 [cs.CV])</h2>
<h3>Niloy Sikder, Abu Shamim Mohammad Arif, Abdullah-Al Nahid</h3>
<p>Electromyography (EMG) is a way of measuring the bioelectric activities that
take place inside the muscles. EMG is usually performed to detect abnormalities
within the nerves or muscles of a target area. The recent developments in the
field of Machine Learning allow us to use EMG signals to teach machines the
complex properties of human movements. Modern machines are capable of detecting
numerous human activities and distinguishing among them solely based on the EMG
signals produced by those activities. However, success in accomplishing this
task mostly depends on the learning technique used by the machine to analyze
EMG signals; and even the latest algorithms do not result in flawless
classification. In this study, a novel classification method has been described
employing a multichannel Convolutional Neural Network (CNN) that interprets
surface EMG signals by the properties they exhibit in the power domain. The
proposed method was tested on a well-established EMG dataset, and the result
yields very high classification accuracy. This learning model will help
researchers to develop prosthetic arms capable of detecting various hand
gestures to mimic them afterwards.
</p>
<a href="http://arxiv.org/abs/2101.06715" target="_blank">arXiv:2101.06715</a> [<a href="http://arxiv.org/pdf/2101.06715" target="_blank">pdf</a>]

<h2>Deep Multi-Task Learning for Joint Localization, Perception, and Prediction. (arXiv:2101.06720v1 [cs.CV])</h2>
<h3>John Phillips, Julieta Martinez, Ioan Andrei B&#xe2;rsan, Sergio Casas, Abbas Sadat, Raquel Urtasun</h3>
<p>Over the last few years, we have witnessed tremendous progress on many
subtasks of autonomous driving, including perception, motion forecasting, and
motion planning. % methods. However, these systems often assume that the car is
accurately localized against a high-definition map. In this paper we question
this assumption, and investigate the issues that arise in state-of-the-art
autonomy stacks under localization error. Based on our observations, we design
a system that jointly performs perception, prediction, and localization. Our
architecture is able to reuse computation between both tasks, and is thus able
to correct localization errors efficiently. We show experiments on a
large-scale autonomy dataset, demonstrating the efficiency and accuracy of our
proposed approach.
</p>
<a href="http://arxiv.org/abs/2101.06720" target="_blank">arXiv:2101.06720</a> [<a href="http://arxiv.org/pdf/2101.06720" target="_blank">pdf</a>]

<h2>Energy-based Dropout in Restricted Boltzmann Machines: Why not go random. (arXiv:2101.06741v1 [cs.LG])</h2>
<h3>Mateus Roder, Gustavo H. de Rosa, Victor Hugo C. de Albuquerque, Andr&#xe9; L. D. Rossi, Jo&#xe3;o P. Papa</h3>
<p>Deep learning architectures have been widely fostered throughout the last
years, being used in a wide range of applications, such as object recognition,
image reconstruction, and signal processing. Nevertheless, such models suffer
from a common problem known as overfitting, which limits the network from
predicting unseen data effectively. Regularization approaches arise in an
attempt to address such a shortcoming. Among them, one can refer to the
well-known Dropout, which tackles the problem by randomly shutting down a set
of neurons and their connections according to a certain probability. Therefore,
this approach does not consider any additional knowledge to decide which units
should be disconnected. In this paper, we propose an energy-based Dropout
(E-Dropout) that makes conscious decisions whether a neuron should be dropped
or not. Specifically, we design this regularization method by correlating
neurons and the model's energy as an importance level for further applying it
to energy-based models, such as Restricted Boltzmann Machines (RBMs). The
experimental results over several benchmark datasets revealed the proposed
approach's suitability compared to the traditional Dropout and the standard
RBMs.
</p>
<a href="http://arxiv.org/abs/2101.06741" target="_blank">arXiv:2101.06741</a> [<a href="http://arxiv.org/pdf/2101.06741" target="_blank">pdf</a>]

<h2>Deep Parametric Continuous Convolutional Neural Networks. (arXiv:2101.06742v1 [cs.CV])</h2>
<h3>Shenlong Wang, Simon Suo, Wei-Chiu Ma, Andrei Pokrovsky, Raquel Urtasun</h3>
<p>Standard convolutional neural networks assume a grid structured input is
available and exploit discrete convolutions as their fundamental building
blocks. This limits their applicability to many real-world applications. In
this paper we propose Parametric Continuous Convolution, a new learnable
operator that operates over non-grid structured data. The key idea is to
exploit parameterized kernel functions that span the full continuous vector
space. This generalization allows us to learn over arbitrary data structures as
long as their support relationship is computable. Our experiments show
significant improvement over the state-of-the-art in point cloud segmentation
of indoor and outdoor scenes, and lidar motion estimation of driving scenes.
</p>
<a href="http://arxiv.org/abs/2101.06742" target="_blank">arXiv:2101.06742</a> [<a href="http://arxiv.org/pdf/2101.06742" target="_blank">pdf</a>]

<h2>Intestinal Parasites Classification Using Deep Belief Networks. (arXiv:2101.06747v1 [cs.CV])</h2>
<h3>Mateus Roder, Leandro A. Passos, Luiz Carlos Felix Ribeiro, Barbara Caroline Benato, Alexandre Xavier Falc&#xe3;o, Jo&#xe3;o Paulo Papa</h3>
<p>Currently, approximately $4$ billion people are infected by intestinal
parasites worldwide. Diseases caused by such infections constitute a public
health problem in most tropical countries, leading to physical and mental
disorders, and even death to children and immunodeficient individuals. Although
subjected to high error rates, human visual inspection is still in charge of
the vast majority of clinical diagnoses. In the past years, some works
addressed intelligent computer-aided intestinal parasites classification, but
they usually suffer from misclassification due to similarities between
parasites and fecal impurities. In this paper, we introduce Deep Belief
Networks to the context of automatic intestinal parasites classification.
Experiments conducted over three datasets composed of eggs, larvae, and
protozoa provided promising results, even considering unbalanced classes and
also fecal impurities.
</p>
<a href="http://arxiv.org/abs/2101.06747" target="_blank">arXiv:2101.06747</a> [<a href="http://arxiv.org/pdf/2101.06747" target="_blank">pdf</a>]

<h2>A Layer-Wise Information Reinforcement Approach to Improve Learning in Deep Belief Networks. (arXiv:2101.06749v1 [cs.AI])</h2>
<h3>Mateus Roder, Leandro A. Passos, Luiz Carlos Felix Ribeiro, Clayton Pereira, Jo&#xe3;o Paulo Papa</h3>
<p>With the advent of deep learning, the number of works proposing new methods
or improving existent ones has grown exponentially in the last years. In this
scenario, "very deep" models were emerging, once they were expected to extract
more intrinsic and abstract features while supporting a better performance.
However, such models suffer from the gradient vanishing problem, i.e.,
backpropagation values become too close to zero in their shallower layers,
ultimately causing learning to stagnate. Such an issue was overcome in the
context of convolution neural networks by creating "shortcut connections"
between layers, in a so-called deep residual learning framework. Nonetheless, a
very popular deep learning technique called Deep Belief Network still suffers
from gradient vanishing when dealing with discriminative tasks. Therefore, this
paper proposes the Residual Deep Belief Network, which considers the
information reinforcement layer-by-layer to improve the feature extraction and
knowledge retaining, that support better discriminative performance.
Experiments conducted over three public datasets demonstrate its robustness
concerning the task of binary image classification.
</p>
<a href="http://arxiv.org/abs/2101.06749" target="_blank">arXiv:2101.06749</a> [<a href="http://arxiv.org/pdf/2101.06749" target="_blank">pdf</a>]

<h2>Multi-view Data Visualisation via Manifold Learning. (arXiv:2101.06763v1 [stat.ML])</h2>
<h3>Theodoulos Rodosthenous, Vahid Shahrezaei, Marina Evangelou</h3>
<p>Manifold learning approaches, such as Stochastic Neighbour Embedding (SNE),
Locally Linear Embedding (LLE) and Isometric Feature Mapping (ISOMAP) have been
proposed for performing non-linear dimensionality reduction. These methods aim
to produce two or three latent embeddings, in order to visualise the data in
intelligible representations. This manuscript proposes extensions of Student's
t-distributed SNE (t-SNE), LLE and ISOMAP, to allow for dimensionality
reduction and subsequent visualisation of multi-view data.

Nowadays, it is very common to have multiple data-views on the same samples.
Each data-view contains a set of features describing different aspects of the
samples. For example, in biomedical studies it is possible to generate multiple
OMICS data sets for the same individuals, such as transcriptomics, genomics,
epigenomics, enabling better understanding of the relationships between the
different biological processes.

Through the analysis of real and simulated datasets, the visualisation
performance of the proposed methods is illustrated. Data visualisations have
been often utilised for identifying any potential clusters in the data sets. We
show that by incorporating the low-dimensional embeddings obtained via the
multi-view manifold learning approaches into the K-means algorithm, clusters of
the samples are accurately identified. Our proposed multi-SNE method
outperforms the corresponding multi-ISOMAP and multi-LLE proposed methods.
Interestingly, multi-SNE is found to have comparable performance with methods
proposed in the literature for performing multi-view clustering.
</p>
<a href="http://arxiv.org/abs/2101.06763" target="_blank">arXiv:2101.06763</a> [<a href="http://arxiv.org/pdf/2101.06763" target="_blank">pdf</a>]

<h2>Spatial Network Decomposition for Fast and Scalable AC-OPF Learning. (arXiv:2101.06768v1 [cs.LG])</h2>
<h3>Minas Chatzos, Terrence W.K. Mak, Pascal Van Hentenryck</h3>
<p>This paper proposes a novel machine-learning approach for predicting AC-OPF
solutions that features a fast and scalable training. It is motivated by the
two critical considerations: (1) the fact that topology optimization and the
stochasticity induced by renewable energy sources may lead to fundamentally
different AC-OPF instances; and (2) the significant training time needed by
existing machine-learning approaches for predicting AC-OPF. The proposed
approach is a 2-stage methodology that exploits a spatial decomposition of the
power network that is viewed as a set of regions. The first stage learns to
predict the flows and voltages on the buses and lines coupling the regions, and
the second stage trains, in parallel, the machine-learning models for each
region. Experimental results on the French transmission system (up to 6,700
buses and 9,000 lines) demonstrate the potential of the approach. Within a
short training time, the approach predicts AC-OPF solutions with very high
fidelity and minor constraint violations, producing significant improvements
over the state-of-the-art. The results also show that the predictions can seed
a load flow optimization to return a feasible solution within 0.03% of the
AC-OPF objective, while reducing running times significantly.
</p>
<a href="http://arxiv.org/abs/2101.06768" target="_blank">arXiv:2101.06768</a> [<a href="http://arxiv.org/pdf/2101.06768" target="_blank">pdf</a>]

<h2>Improving Apparel Detection with Category Grouping and Multi-grained Branches. (arXiv:2101.06770v1 [cs.CV])</h2>
<h3>Qing Tian, Sampath Chanda, K C Amit Kumar, Douglas Gray</h3>
<p>Training an accurate object detector is expensive and time-consuming. One
main reason lies in the laborious labeling process, i.e., annotating category
and bounding box information for all instances in every image. In this paper,
we examine ways to improve performance of deep object detectors without extra
labeling. We first explore to group existing categories of high visual and
semantic similarities together as one super category (or, a superclass). Then,
we study how this knowledge of hierarchical categories can be exploited to
better detect object using multi-grained RCNN top branches. Experimental
results on DeepFashion2 and OpenImagesV4-Clothing reveal that the proposed
detection heads with multi-grained branches can boost the overall performance
by 2.3 mAP for DeepFashion2 and 2.5 mAP for OpenImagesV4-Clothing with no
additional time-consuming annotations. More importantly, classes that have
fewer training samples tend to benefit more from the proposed multi-grained
heads with superclass grouping. In particular, we improve the mAP for last 30%
categories (in terms of training sample number) by 2.6 and 4.6 for DeepFashion2
and OpenImagesV4-Clothing, respectively.
</p>
<a href="http://arxiv.org/abs/2101.06770" target="_blank">arXiv:2101.06770</a> [<a href="http://arxiv.org/pdf/2101.06770" target="_blank">pdf</a>]

<h2>Temporal Spatial-Adaptive Interpolation with Deformable Refinement for Electron Microscopic Images. (arXiv:2101.06771v1 [cs.CV])</h2>
<h3>Zejin Wang, Guodong Sun, Lina Zhang, Guoqing Li, Hua Han</h3>
<p>Recently, flow-based methods have achieved promising success in video frame
interpolation. However, electron microscopic (EM) images suffer from unstable
image quality, low PSNR, and disorderly deformation. Existing flow-based
interpolation methods cannot precisely compute optical flow for EM images since
only predicting each position's unique offset. To overcome these problems, we
propose a novel interpolation framework for EM images that progressively
synthesizes interpolated features in a coarse-to-fine manner. First, we extract
missing intermediate features by the proposed temporal spatial-adaptive (TSA)
interpolation module. The TSA interpolation module aggregates temporal contexts
and then adaptively samples the spatial-related features with the proposed
residual spatial adaptive block. Second, we introduce a stacked deformable
refinement block (SDRB) further enhance the reconstruction quality, which is
aware of the matching positions and relevant features from input frames with
the feedback mechanism. Experimental results demonstrate the superior
performance of our approach compared to previous works, both quantitatively and
qualitatively.
</p>
<a href="http://arxiv.org/abs/2101.06771" target="_blank">arXiv:2101.06771</a> [<a href="http://arxiv.org/pdf/2101.06771" target="_blank">pdf</a>]

<h2>Generating Attribution Maps with Disentangled Masked Backpropagation. (arXiv:2101.06773v1 [cs.CV])</h2>
<h3>Adria Ruiz, Antonio Agudo, Francesc Moreno</h3>
<p>Attribution map visualization has arisen as one of the most effective
techniques to understand the underlying inference process of Convolutional
Neural Networks. In this task, the goal is to compute an score for each image
pixel related with its contribution to the final network output. In this paper,
we introduce Disentangled Masked Backpropagation (DMBP), a novel gradient-based
method that leverages on the piecewise linear nature of ReLU networks to
decompose the model function into different linear mappings. This decomposition
aims to disentangle the positive, negative and nuisance factors from the
attribution maps by learning a set of variables masking the contribution of
each filter during back-propagation. A thorough evaluation over standard
architectures (ResNet50 and VGG16) and benchmark datasets (PASCAL VOC and
ImageNet) demonstrates that DMBP generates more visually interpretable
attribution maps than previous approaches. Additionally, we quantitatively show
that the maps produced by our method are more consistent with the true
contribution of each pixel to the final network output.
</p>
<a href="http://arxiv.org/abs/2101.06773" target="_blank">arXiv:2101.06773</a> [<a href="http://arxiv.org/pdf/2101.06773" target="_blank">pdf</a>]

<h2>Learning from pandemics: using extraordinary events can improve disease now-casting models. (arXiv:2101.06774v1 [cs.LG])</h2>
<h3>Sara Mesquita, Cl&#xe1;udio Haupt Vieira, L&#xed;lia Perfeito, Joana Gon&#xe7;alves-S&#xe1;</h3>
<p>Online searches have been used to study different health-related behaviours,
including monitoring disease outbreaks. An obvious caveat is that several
reasons can motivate individuals to seek online information and models that are
blind to people's motivations are of limited use and can even mislead. This is
particularly true during extraordinary public health crisis, such as the
ongoing pandemic, when fear, curiosity and many other reasons can lead
individuals to search for health-related information, masking the
disease-driven searches. However, health crisis can also offer an opportunity
to disentangle between different drivers and learn about human behavior. Here,
we focus on the two pandemics of the 21st century (2009-H1N1 flu and Covid-19)
and propose a methodology to discriminate between search patterns linked to
general information seeking (media driven) and search patterns possibly more
associated with actual infection (disease driven). We show that by learning
from such pandemic periods, with high anxiety and media hype, it is possible to
select online searches and improve model performance both in pandemic and
seasonal settings. Moreover, and despite the common claim that more data is
always better, our results indicate that lower volume of the right data can be
better than including large volumes of apparently similar data, especially in
the long run. Our work provides a general framework that can be applied beyond
specific events and diseases, and argues that algorithms can be improved simply
by using less (better) data. This has important consequences, for example, to
solve the accuracy-explainability trade-off in machine-learning.
</p>
<a href="http://arxiv.org/abs/2101.06774" target="_blank">arXiv:2101.06774</a> [<a href="http://arxiv.org/pdf/2101.06774" target="_blank">pdf</a>]

<h2>A Safe Hierarchical Planning Framework for Complex Driving Scenarios based on Reinforcement Learning. (arXiv:2101.06778v1 [cs.RO])</h2>
<h3>Jinning Li, Liting Sun, Masayoshi Tomizuka, Wei Zhan</h3>
<p>Autonomous vehicles need to handle various traffic conditions and make safe
and efficient decisions and maneuvers. However, on the one hand, a single
optimization/sampling-based motion planner cannot efficiently generate safe
trajectories in real time, particularly when there are many interactive
vehicles near by. On the other hand, end-to-end learning methods cannot assure
the safety of the outcomes. To address this challenge, we propose a
hierarchical behavior planning framework with a set of low-level safe
controllers and a high-level reinforcement learning algorithm (H-CtRL) as a
coordinator for the low-level controllers. Safety is guaranteed by the
low-level optimization/sampling-based controllers, while the high-level
reinforcement learning algorithm makes H-CtRL an adaptive and efficient
behavior planner. To train and test our proposed algorithm, we built a
simulator that can reproduce traffic scenes using real-world datasets. The
proposed H-CtRL is proved to be effective in various realistic simulation
scenarios, with satisfying performance in terms of both safety and efficiency.
</p>
<a href="http://arxiv.org/abs/2101.06778" target="_blank">arXiv:2101.06778</a> [<a href="http://arxiv.org/pdf/2101.06778" target="_blank">pdf</a>]

<h2>Exploring Adversarial Robustness of Multi-Sensor Perception Systems in Self Driving. (arXiv:2101.06784v1 [cs.CV])</h2>
<h3>James Tu, Huichen Li, Xinchen Yan, Mengye Ren, Yun Chen, Ming Liang, Eilyan Bitar, Ersin Yumer, Raquel Urtasun</h3>
<p>Modern self-driving perception systems have been shown to improve upon
processing complementary inputs such as LiDAR with images. In isolation, 2D
images have been found to be extremely vulnerable to adversarial attacks. Yet,
there have been limited studies on the adversarial robustness of multi-modal
models that fuse LiDAR features with image features. Furthermore, existing
works do not consider physically realizable perturbations that are consistent
across the input modalities. In this paper, we showcase practical
susceptibilities of multi-sensor detection by placing an adversarial object on
top of a host vehicle. We focus on physically realizable and input-agnostic
attacks as they are feasible to execute in practice, and show that a single
universal adversary can hide different host vehicles from state-of-the-art
multi-modal detectors. Our experiments demonstrate that successful attacks are
primarily caused by easily corrupted image features. Furthermore, we find that
in modern sensor fusion methods which project image features into 3D,
adversarial attacks can exploit the projection process to generate false
positives across distant regions in 3D. Towards more robust multi-modal
perception systems, we show that adversarial training with feature denoising
can boost robustness to such attacks significantly. However, we find that
standard adversarial defenses still struggle to prevent false positives which
are also caused by inaccurate associations between 3D LiDAR points and 2D
pixels.
</p>
<a href="http://arxiv.org/abs/2101.06784" target="_blank">arXiv:2101.06784</a> [<a href="http://arxiv.org/pdf/2101.06784" target="_blank">pdf</a>]

<h2>MPC-MPNet: Model-Predictive Motion Planning Networks for Fast, Near-Optimal Planning under Kinodynamic Constraints. (arXiv:2101.06798v1 [cs.RO])</h2>
<h3>Linjun Li, Yinglong Miao, Ahmed H. Qureshi, Michael C. Yip</h3>
<p>Kinodynamic Motion Planning (KMP) is to find a robot motion subject to
concurrent kinematics and dynamics constraints. To date, quite a few methods
solve KMP problems and those that exist struggle to find near-optimal solutions
and exhibit high computational complexity as the planning space dimensionality
increases. To address these challenges, we present a scalable, imitation
learning-based, Model-Predictive Motion Planning Networks framework that
quickly finds near-optimal path solutions with worst-case theoretical
guarantees under kinodynamic constraints for practical underactuated systems.
Our framework introduces two algorithms built on a neural generator,
discriminator, and a parallelizable Model Predictive Controller (MPC). The
generator outputs various informed states towards the given target, and the
discriminator selects the best possible subset from them for the extension. The
MPC locally connects the selected informed states while satisfying the given
constraints leading to feasible, near-optimal solutions. We evaluate our
algorithms on a range of cluttered, kinodynamically constrained, and
underactuated planning problems with results indicating significant
improvements in computation times, path qualities, and success rates over
existing methods.
</p>
<a href="http://arxiv.org/abs/2101.06798" target="_blank">arXiv:2101.06798</a> [<a href="http://arxiv.org/pdf/2101.06798" target="_blank">pdf</a>]

<h2>Heterogeneous Similarity Graph Neural Network on Electronic Health Records. (arXiv:2101.06800v1 [cs.LG])</h2>
<h3>Zheng Liu, Xiaohan Li, Hao Peng, Lifang He, Philip S. Yu</h3>
<p>Mining Electronic Health Records (EHRs) becomes a promising topic because of
the rich information they contain. By learning from EHRs, machine learning
models can be built to help human experts to make medical decisions and thus
improve healthcare quality. Recently, many models based on sequential or graph
models are proposed to achieve this goal. EHRs contain multiple entities and
relations and can be viewed as a heterogeneous graph. However, previous studies
ignore the heterogeneity in EHRs. On the other hand, current heterogeneous
graph neural networks cannot be simply used on an EHR graph because of the
existence of hub nodes in it. To address this issue, we propose Heterogeneous
Similarity Graph Neural Network (HSGNN) analyze EHRs with a novel heterogeneous
GNN. Our framework consists of two parts: one is a preprocessing method and the
other is an end-to-end GNN. The preprocessing method normalizes edges and
splits the EHR graph into multiple homogeneous graphs while each homogeneous
graph contains partial information of the original EHR graph. The GNN takes all
homogeneous graphs as input and fuses all of them into one graph to make a
prediction. Experimental results show that HSGNN outperforms other baselines in
the diagnosis prediction task.
</p>
<a href="http://arxiv.org/abs/2101.06800" target="_blank">arXiv:2101.06800</a> [<a href="http://arxiv.org/pdf/2101.06800" target="_blank">pdf</a>]

<h2>Measure-conditional Discriminator with Stationary Optimum for GANs and Statistical Distance Surrogates. (arXiv:2101.06802v1 [cs.LG])</h2>
<h3>Liu Yang, Tingwei Meng, George Em Karniadakis</h3>
<p>We propose a simple but effective modification of the discriminators, namely
measure-conditional discriminators, as a plug-and-play module for different
GANs. By taking the generated distributions as part of input so that the target
optimum for the discriminator is stationary, the proposed discriminator is more
robust than the vanilla one. A variant of the measure-conditional discriminator
can also handle multiple target distributions, or act as a surrogate model of
statistical distances such as KL divergence with applications to transfer
learning.
</p>
<a href="http://arxiv.org/abs/2101.06802" target="_blank">arXiv:2101.06802</a> [<a href="http://arxiv.org/pdf/2101.06802" target="_blank">pdf</a>]

<h2>MP3: A Unified Model to Map, Perceive, Predict and Plan. (arXiv:2101.06806v1 [cs.RO])</h2>
<h3>Sergio Casas, Abbas Sadat, Raquel Urtasun</h3>
<p>High-definition maps (HD maps) are a key component of most modern
self-driving systems due to their valuable semantic and geometric information.
Unfortunately, building HD maps has proven hard to scale due to their cost as
well as the requirements they impose in the localization system that has to
work everywhere with centimeter-level accuracy. Being able to drive without an
HD map would be very beneficial to scale self-driving solutions as well as to
increase the failure tolerance of existing ones (e.g., if localization fails or
the map is not up-to-date). Towards this goal, we propose MP3, an end-to-end
approach to mapless driving where the input is raw sensor data and a high-level
command (e.g., turn left at the intersection). MP3 predicts intermediate
representations in the form of an online map and the current and future state
of dynamic agents, and exploits them in a novel neural motion planner to make
interpretable decisions taking into account uncertainty. We show that our
approach is significantly safer, more comfortable, and can follow commands
better than the baselines in challenging long-term closed-loop simulations, as
well as when compared to an expert driver in a large-scale real-world dataset.
</p>
<a href="http://arxiv.org/abs/2101.06806" target="_blank">arXiv:2101.06806</a> [<a href="http://arxiv.org/pdf/2101.06806" target="_blank">pdf</a>]

<h2>Fast and accurate learned multiresolution dynamical downscaling for precipitation. (arXiv:2101.06813v1 [cs.LG])</h2>
<h3>Jiali Wang, Zhengchun Liu, Ian Foster, Won Chang, Rajkumar Kettimuthu, Rao Kotamarthi</h3>
<p>This study develops a neural network-based approach for emulating
high-resolution modeled precipitation data with comparable statistical
properties but at greatly reduced computational cost. The key idea is to use
combination of low- and high- resolution simulations to train a neural network
to map from the former to the latter. Specifically, we define two types of
CNNs, one that stacks variables directly and one that encodes each variable
before stacking, and we train each CNN type both with a conventional loss
function, such as mean square error (MSE), and with a conditional generative
adversarial network (CGAN), for a total of four CNN variants. We compare the
four new CNN-derived high-resolution precipitation results with precipitation
generated from original high resolution simulations, a bilinear interpolater
and the state-of-the-art CNN-based super-resolution (SR) technique. Results
show that the SR technique produces results similar to those of the bilinear
interpolator with smoother spatial and temporal distributions and smaller data
variabilities and extremes than the original high resolution simulations. While
the new CNNs trained by MSE generate better results over some regions than the
interpolator and SR technique do, their predictions are still not as close as
the original high resolution simulations. The CNNs trained by CGAN generate
more realistic and physically reasonable results, better capturing not only
data variability in time and space but also extremes such as intense and
long-lasting storms. The new proposed CNN-based downscaling approach can
downscale precipitation from 50~km to 12~km in 14~min for 30~years once the
network is trained (training takes 4~hours using 1~GPU), while the conventional
dynamical downscaling would take 1~month using 600 CPU cores to generate
simulations at the resolution of 12~km over contiguous United States.
</p>
<a href="http://arxiv.org/abs/2101.06813" target="_blank">arXiv:2101.06813</a> [<a href="http://arxiv.org/pdf/2101.06813" target="_blank">pdf</a>]

<h2>Chaotic-to-Fine Clustering for Unlabeled Plant Disease Images. (arXiv:2101.06820v1 [cs.CV])</h2>
<h3>Uno Fang, Jianxin Li, Xuequan Lu, Mumtaz Ali, Longxiang Gao, Yong Xiang</h3>
<p>Current annotation for plant disease images depends on manual sorting and
handcrafted features by agricultural experts, which is time-consuming and
labour-intensive. In this paper, we propose a self-supervised clustering
framework for grouping plant disease images based on the vulnerability of
Kernel K-means. The main idea is to establish a cross iterative
under-clustering algorithm based on Kernel K-means to produce the
pseudo-labeled training set and a chaotic cluster to be further classified by a
deep learning module. In order to verify the effectiveness of our proposed
framework, we conduct extensive experiments on three different plant disease
datatsets with five plants and 17 plant diseases. The experimental results show
the high superiority of our method to do image-based plant disease
classification over balanced and unbalanced datasets by comparing with five
state-of-the-art existing works in terms of different metrics.
</p>
<a href="http://arxiv.org/abs/2101.06820" target="_blank">arXiv:2101.06820</a> [<a href="http://arxiv.org/pdf/2101.06820" target="_blank">pdf</a>]

<h2>HyperNTF: A Hypergraph Regularized Nonnegative Tensor Factorization for Dimensionality Reduction. (arXiv:2101.06827v1 [cs.LG])</h2>
<h3>Wanguang Yin, Zhengming Ma, Quanying Liu</h3>
<p>Most methods for dimensionality reduction are based on either tensor
representation or local geometry learning. However, the tensor-based methods
severely rely on the assumption of global and multilinear structures in
high-dimensional data; and the manifold learning methods suffer from the
out-of-sample problem. In this paper, bridging the tensor decomposition and
manifold learning, we propose a novel method, called Hypergraph Regularized
Nonnegative Tensor Factorization (HyperNTF). HyperNTF can preserve
nonnegativity in tensor factorization, and uncover the higher-order
relationship among the nearest neighborhoods. Clustering analysis with HyperNTF
has low computation and storage costs. The experiments on four synthetic data
show a desirable property of hypergraph in uncovering the high-order
correlation to unfold the curved manifolds. Moreover, the numerical experiments
on six real datasets suggest that HyperNTF robustly outperforms
state-of-the-art algorithms in clustering analysis.
</p>
<a href="http://arxiv.org/abs/2101.06827" target="_blank">arXiv:2101.06827</a> [<a href="http://arxiv.org/pdf/2101.06827" target="_blank">pdf</a>]

<h2>Deep Structured Reactive Planning. (arXiv:2101.06832v1 [cs.CV])</h2>
<h3>Jerry Liu, Wenyuan Zeng, Raquel Urtasun, Ersin Yumer</h3>
<p>An intelligent agent operating in the real-world must balance achieving its
goal with maintaining the safety and comfort of not only itself, but also other
participants within the surrounding scene. This requires jointly reasoning
about the behavior of other actors while deciding its own actions as these two
processes are inherently intertwined - a vehicle will yield to us if we decide
to proceed first at the intersection but will proceed first if we decide to
yield. However, this is not captured in most self-driving pipelines, where
planning follows prediction. In this paper we propose a novel data-driven,
reactive planning objective which allows a self-driving vehicle to jointly
reason about its own plans as well as how other actors will react to them. We
formulate the problem as an energy-based deep structured model that is learned
from observational data and encodes both the planning and prediction problems.
Through simulations based on both real-world driving and synthetically
generated dense traffic, we demonstrate that our reactive model outperforms a
non-reactive variant in successfully completing highly complex maneuvers (lane
merges/turns in traffic) faster, without trading off collision rate.
</p>
<a href="http://arxiv.org/abs/2101.06832" target="_blank">arXiv:2101.06832</a> [<a href="http://arxiv.org/pdf/2101.06832" target="_blank">pdf</a>]

<h2>Fast and Accurate Multi-Body Simulation with Stiff Viscoelastic Contacts. (arXiv:2101.06846v1 [cs.RO])</h2>
<h3>Bilal Hammoud, Luca Olivieri, Ludovic Righetti, Justin Carpentier, Andrea Del Prete</h3>
<p>The simulation of multi-body systems with frictional contacts is a
fundamental tool for many fields, such as robotics, computer graphics, and
mechanics. Hard frictional contacts are particularly troublesome to simulate
because they make the differential equations stiff, calling for computationally
demanding implicit integration schemes. We suggest to tackle this issue by
using exponential integrators, a long-standing class of integration schemes
(first introduced in the 60's) that in recent years has enjoyed a resurgence of
interest. We show that this scheme can be easily applied to multi-body systems
subject to stiff viscoelastic contacts, producing accurate results at lower
computational cost than classic explicit schemes. In our tests with quadruped
and biped robots, our method demonstrated stable behaviors with large time
steps (10 ms) and stiff contacts ($10^5$ N/m). Its excellent properties,
especially for fast and coarse simulations, make it a valuable candidate for
many applications in robotics, such as simulation, Model Predictive Control,
Reinforcement Learning, and controller design.
</p>
<a href="http://arxiv.org/abs/2101.06846" target="_blank">arXiv:2101.06846</a> [<a href="http://arxiv.org/pdf/2101.06846" target="_blank">pdf</a>]

<h2>On the Differentially Private Nature of Perturbed Gradient Descent. (arXiv:2101.06847v1 [cs.LG])</h2>
<h3>Thulasi Tholeti, Sheetal Kalyani</h3>
<p>We consider the problem of empirical risk minimization given a database,
using the gradient descent algorithm. We note that the function to be optimized
may be non-convex, consisting of saddle points which impede the convergence of
the algorithm. A perturbed gradient descent algorithm is typically employed to
escape these saddle points. We show that this algorithm, that perturbs the
gradient, inherently preserves the privacy of the data. We then employ the
differential privacy framework to quantify the privacy hence achieved. We also
analyze the change in privacy with varying parameters such as problem dimension
and the distance between the databases.
</p>
<a href="http://arxiv.org/abs/2101.06847" target="_blank">arXiv:2101.06847</a> [<a href="http://arxiv.org/pdf/2101.06847" target="_blank">pdf</a>]

<h2>Faster Convergence in Deep-Predictive-Coding Networks to Learn Deeper Representations. (arXiv:2101.06848v1 [cs.AI])</h2>
<h3>Isaac J. Sledge, Jose C. Principe</h3>
<p>Deep-predictive-coding networks (DPCNs) are hierarchical, generative models
that rely on feed-forward and feed-back connections to modulate latent feature
representations of stimuli in a dynamic and context-sensitive manner. A crucial
element of DPCNs is a forward-backward inference procedure to uncover sparse
states of a dynamic model, which are used for invariant feature extraction.
However, this inference and the corresponding backwards network parameter
updating are major computational bottlenecks. They severely limit the network
depths that can be reasonably implemented and easily trained. We therefore
propose a optimization strategy, with better empirical and theoretical
convergence, based on accelerated proximal gradients.

We demonstrate that the ability to construct deeper DPCNs leads to receptive
fields that capture well the entire notions of objects on which the networks
are trained. This improves the feature representations. It yields completely
unsupervised classifiers that surpass convolutional and convolutional-recurrent
autoencoders and are on par with convolutional networks trained in a supervised
manner. This is despite the DPCNs having orders of magnitude fewer parameters.
</p>
<a href="http://arxiv.org/abs/2101.06848" target="_blank">arXiv:2101.06848</a> [<a href="http://arxiv.org/pdf/2101.06848" target="_blank">pdf</a>]

<h2>CFC-Net: A Critical Feature Capturing Network for Arbitrary-Oriented Object Detection in Remote Sensing Images. (arXiv:2101.06849v1 [cs.CV])</h2>
<h3>Qi Ming, Lingjuan Miao, Zhiqiang Zhou, Yunpeng Dong</h3>
<p>Object detection in optical remote sensing images is an important and
challenging task. In recent years, the methods based on convolutional neural
networks have made good progress. However, due to the large variation in object
scale, aspect ratio, and arbitrary orientation, the detection performance is
difficult to be further improved. In this paper, we discuss the role of
discriminative features in object detection, and then propose a Critical
Feature Capturing Network (CFC-Net) to improve detection accuracy from three
aspects: building powerful feature representation, refining preset anchors, and
optimizing label assignment. Specifically, we first decouple the classification
and regression features, and then construct robust critical features adapted to
the respective tasks through the Polarization Attention Module (PAM). With the
extracted discriminative regression features, the Rotation Anchor Refinement
Module (R-ARM) performs localization refinement on preset horizontal anchors to
obtain superior rotation anchors. Next, the Dynamic Anchor Learning (DAL)
strategy is given to adaptively select high-quality anchors based on their
ability to capture critical features. The proposed framework creates more
powerful semantic representations for objects in remote sensing images and
achieves high-performance real-time object detection. Experimental results on
three remote sensing datasets including HRSC2016, DOTA, and UCAS-AOD show that
our method achieves superior detection performance compared with many
state-of-the-art approaches. Code and models are available at
https://github.com/ming71/CFC-Net.
</p>
<a href="http://arxiv.org/abs/2101.06849" target="_blank">arXiv:2101.06849</a> [<a href="http://arxiv.org/pdf/2101.06849" target="_blank">pdf</a>]

<h2>Stacked LSTM Based Deep Recurrent Neural Network with Kalman Smoothing for Blood Glucose Prediction. (arXiv:2101.06850v1 [cs.LG])</h2>
<h3>Md Fazle Rabby, Yazhou Tu, Md Imran Hossen, Insup Le, Anthony S Maida, Xiali Hei</h3>
<p>Blood glucose (BG) management is crucial for type-1 diabetes patients
resulting in the necessity of reliable artificial pancreas or insulin infusion
systems. In recent years, deep learning techniques have been utilized for a
more accurate BG level prediction system. However, continuous glucose
monitoring (CGM) readings are susceptible to sensor errors. As a result,
inaccurate CGM readings would affect BG prediction and make it unreliable, even
if the most optimal machine learning model is used. In this work, we propose a
novel approach to predicting blood glucose level with a stacked Long short-term
memory (LSTM) based deep recurrent neural network (RNN) model considering
sensor fault. We use the Kalman smoothing technique for the correction of the
inaccurate CGM readings due to sensor error. For the OhioT1DM dataset,
containing eight weeks' data from six different patients, we achieve an average
RMSE of 6.45 and 17.24 mg/dl for 30 minutes and 60 minutes of prediction
horizon (PH), respectively. To the best of our knowledge, this is the leading
average prediction accuracy for the ohioT1DM dataset. Different physiological
information, e.g., Kalman smoothed CGM data, carbohydrates from the meal, bolus
insulin, and cumulative step counts in a fixed time interval, are crafted to
represent meaningful features used as input to the model. The goal of our
approach is to lower the difference between the predicted CGM values and the
fingerstick blood glucose readings - the ground truth. Our results indicate
that the proposed approach is feasible for more reliable BG forecasting that
might improve the performance of the artificial pancreas and insulin infusion
system for T1D diabetes management.
</p>
<a href="http://arxiv.org/abs/2101.06850" target="_blank">arXiv:2101.06850</a> [<a href="http://arxiv.org/pdf/2101.06850" target="_blank">pdf</a>]

<h2>GraphAttacker: A General Multi-Task GraphAttack Framework. (arXiv:2101.06855v1 [cs.LG])</h2>
<h3>Jinyin Chen, Dunjie Zhang, Zhaoyan Ming, Kejie Huang</h3>
<p>Graph Neural Networks (GNNs) have been successfully exploited in graph
analysis tasks in many real-world applications. However, GNNs have been shown
to have potential security issues imposed by adversarial samples generated by
attackers, which achieved great attack performance with almost imperceptible
perturbations. What limit the wide application of these attackers are their
methods' specificity on a certain graph analysis task, such as node
classification or link prediction. We thus propose GraphAttacker, a novel
generic graph attack framework that can flexibly adjust the structures and the
attack strategies according to the graph analysis tasks. Based on the
Generative Adversarial Network (GAN), GraphAttacker generates adversarial
samples through alternate training on three key components, the Multi-strategy
Attack Generator (MAG), the Similarity Discriminator (SD), and the Attack
Discriminator(AD). Furthermore, to achieve attackers within perturbation
budget, we propose a novel Similarity Modification Rate (SMR) to quantify the
similarity between nodes thus constrain the attack budget. We carry out
extensive experiments and the results show that GraphAttacker can achieve
state-of-the-art attack performance on graph analysis tasks of node
classification, graph classification, and link prediction. Besides, we also
analyze the unique characteristics of each task and their specific response in
the unified attack framework. We will release GraphAttacker as an open-source
simulation platform for future attack researches.
</p>
<a href="http://arxiv.org/abs/2101.06855" target="_blank">arXiv:2101.06855</a> [<a href="http://arxiv.org/pdf/2101.06855" target="_blank">pdf</a>]

<h2>Secrets of 3D Implicit Object Shape Reconstruction in the Wild. (arXiv:2101.06860v1 [cs.CV])</h2>
<h3>Shivam Duggal, Zihao Wang, Wei-Chiu Ma, Sivabalan Manivasagam, Justin Liang, Shenlong Wang, Raquel Urtasun</h3>
<p>Reconstructing high-fidelity 3D objects from sparse, partial observation is
of crucial importance for various applications in computer vision, robotics,
and graphics. While recent neural implicit modeling methods show promising
results on synthetic or dense datasets, they perform poorly on real-world data
that is sparse and noisy. This paper analyzes the root cause of such deficient
performance of a popular neural implicit model. We discover that the
limitations are due to highly complicated objectives, lack of regularization,
and poor initialization. To overcome these issues, we introduce two simple yet
effective modifications: (i) a deep encoder that provides a better and more
stable initialization for latent code optimization; and (ii) a deep
discriminator that serves as a prior model to boost the fidelity of the shape.
We evaluate our approach on two real-wold self-driving datasets and show
superior performance over state-of-the-art 3D object reconstruction methods.
</p>
<a href="http://arxiv.org/abs/2101.06860" target="_blank">arXiv:2101.06860</a> [<a href="http://arxiv.org/pdf/2101.06860" target="_blank">pdf</a>]

<h2>Discrete Graph Structure Learning for Forecasting Multiple Time Series. (arXiv:2101.06861v1 [cs.LG])</h2>
<h3>Chao Shang, Jie Chen, Jinbo Bi</h3>
<p>Time series forecasting is an extensively studied subject in statistics,
economics, and computer science. Exploration of the correlation and causation
among the variables in a multivariate time series shows promise in enhancing
the performance of a time series model. When using deep neural networks as
forecasting models, we hypothesize that exploiting the pairwise information
among multiple (multivariate) time series also improves their forecast. If an
explicit graph structure is known, graph neural networks (GNNs) have been
demonstrated as powerful tools to exploit the structure. In this work, we
propose learning the structure simultaneously with the GNN if the graph is
unknown. We cast the problem as learning a probabilistic graph model through
optimizing the mean performance over the graph distribution. The distribution
is parameterized by a neural network so that discrete graphs can be sampled
differentiably through reparameterization. Empirical evaluations show that our
method is simpler, more efficient, and better performing than a recently
proposed bilevel learning approach for graph structure learning, as well as a
broad array of forecasting models, either deep or non-deep learning based, and
graph or non-graph based.
</p>
<a href="http://arxiv.org/abs/2101.06861" target="_blank">arXiv:2101.06861</a> [<a href="http://arxiv.org/pdf/2101.06861" target="_blank">pdf</a>]

<h2>Non-parametric Memory for Spatio-Temporal Segmentation of Construction Zones for Self-Driving. (arXiv:2101.06865v1 [cs.CV])</h2>
<h3>Min Bai, Shenlong Wang, Kelvin Wong, Ersin Yumer, Raquel Urtasun</h3>
<p>In this paper, we introduce a non-parametric memory representation for
spatio-temporal segmentation that captures the local space and time around an
autonomous vehicle (AV). Our representation has three important properties: (i)
it remembers what it has seen in the past, (ii) it reinforces and (iii) forgets
its past beliefs based on new evidence. Reinforcing is important as the first
time we see an element we might be uncertain, e.g, if the element is heavily
occluded or at range. Forgetting is desirable, as otherwise false positives
will make the self driving vehicle behave erratically. Our process is informed
by 3D reasoning, as occlusion is key to distinguishing between the desire to
forget and to remember. We show how our method can be used as an online
component to complement static world representations such as HD maps by
detecting and remembering changes that should be superimposed on top of this
static view due to such events.
</p>
<a href="http://arxiv.org/abs/2101.06865" target="_blank">arXiv:2101.06865</a> [<a href="http://arxiv.org/pdf/2101.06865" target="_blank">pdf</a>]

<h2>CheXtransfer: Performance and Parameter Efficiency of ImageNet Models for Chest X-Ray Interpretation. (arXiv:2101.06871v1 [cs.CV])</h2>
<h3>Alexander Ke, William Ellsworth, Oishi Banerjee, Andrew Y. Ng, Pranav Rajpurkar</h3>
<p>Deep learning methods for chest X-ray interpretation typically rely on
pretrained models developed for ImageNet. This paradigm assumes that better
ImageNet architectures perform better on chest X-ray tasks and that
ImageNet-pretrained weights provide a performance boost over random
initialization. In this work, we compare the transfer performance and parameter
efficiency of 16 popular convolutional architectures on a large chest X-ray
dataset (CheXpert) to investigate these assumptions. First, we find no
relationship between ImageNet performance and CheXpert performance for both
models without pretraining and models with pretraining. Second, we find that,
for models without pretraining, the choice of model family influences
performance more than size within a family for medical imaging tasks. Third, we
observe that ImageNet pretraining yields a statistically significant boost in
performance across architectures, with a higher boost for smaller
architectures. Fourth, we examine whether ImageNet architectures are
unnecessarily large for CheXpert by truncating final blocks from pretrained
models, and find that we can make models 3.25x more parameter-efficient on
average without a statistically significant drop in performance. Our work
contributes new experimental evidence about the relation of ImageNet to chest
x-ray interpretation performance.
</p>
<a href="http://arxiv.org/abs/2101.06871" target="_blank">arXiv:2101.06871</a> [<a href="http://arxiv.org/pdf/2101.06871" target="_blank">pdf</a>]

<h2>CaEGCN: Cross-Attention Fusion based Enhanced Graph Convolutional Network for Clustering. (arXiv:2101.06883v1 [cs.AI])</h2>
<h3>Guangyu Huo, Yong Zhang, Junbin Gao, Boyue Wang, Yongli Hu, Baocai Yin</h3>
<p>With the powerful learning ability of deep convolutional networks, deep
clustering methods can extract the most discriminative information from
individual data and produce more satisfactory clustering results. However,
existing deep clustering methods usually ignore the relationship between the
data. Fortunately, the graph convolutional network can handle such
relationship, opening up a new research direction for deep clustering. In this
paper, we propose a cross-attention based deep clustering framework, named
Cross-Attention Fusion based Enhanced Graph Convolutional Network (CaEGCN),
which contains four main modules: the cross-attention fusion module which
innovatively concatenates the Content Auto-encoder module (CAE) relating to the
individual data and Graph Convolutional Auto-encoder module (GAE) relating to
the relationship between the data in a layer-by-layer manner, and the
self-supervised model that highlights the discriminative information for
clustering tasks. While the cross-attention fusion module fuses two kinds of
heterogeneous representation, the CAE module supplements the content
information for the GAE module, which avoids the over-smoothing problem of GCN.
In the GAE module, two novel loss functions are proposed that reconstruct the
content and relationship between the data, respectively. Finally, the
self-supervised module constrains the distributions of the middle layer
representations of CAE and GAE to be consistent. Experimental results on
different types of datasets prove the superiority and robustness of the
proposed CaEGCN.
</p>
<a href="http://arxiv.org/abs/2101.06883" target="_blank">arXiv:2101.06883</a> [<a href="http://arxiv.org/pdf/2101.06883" target="_blank">pdf</a>]

<h2>Transferring model structure in Bayesian transfer learning for Gaussian process regression. (arXiv:2101.06884v1 [cs.LG])</h2>
<h3>Milan Pape&#x17e;, Anthony Quinn</h3>
<p>Bayesian transfer learning (BTL) is defined in this paper as the task of
conditioning a target probability distribution on a transferred source
distribution. The target globally models the interaction between the source and
target, and conditions on a probabilistic data predictor made available by an
independent local source modeller. Fully probabilistic design is adopted to
solve this optimal decision-making problem in the target. By successfully
transferring higher moments of the source, the target can reject unreliable
source knowledge (i.e. it achieves robust transfer). This dual-modeller
framework means that the source's local processing of raw data into a
transferred predictive distribution -- with compressive possibilities -- is
enriched by (the possible expertise of) the local source model. In addition,
the introduction of the global target modeller allows correlation between the
source and target tasks -- if known to the target -- to be accounted for.
Important consequences emerge. Firstly, the new scheme attains the performance
of fully modelled (i.e. conventional) multitask learning schemes in (those
rare) cases where target model misspecification is avoided. Secondly, and more
importantly, the new dual-modeller framework is robust to the model
misspecification that undermines conventional multitask learning. We thoroughly
explore these issues in the key context of interacting Gaussian process
regression tasks. Experimental evidence from both synthetic and real data
settings validates our technical findings: that the proposed BTL framework
enjoys robustness in transfer while also being robust to model
misspecification.
</p>
<a href="http://arxiv.org/abs/2101.06884" target="_blank">arXiv:2101.06884</a> [<a href="http://arxiv.org/pdf/2101.06884" target="_blank">pdf</a>]

<h2>Deep Learning for Moving Blockage Predictionusing Real Millimeter Wave Measurements. (arXiv:2101.06886v1 [cs.LG])</h2>
<h3>Shunyao Wu, Muhammad Alrabeiah, Andrew Hredzak, Chaitali Chakrabarti, Ahmed Alkhateeb</h3>
<p>Millimeter wave (mmWave) communication is being seriously considered for the
next generation communication systems because of its ability to support high
bandwidth and high data rates. Unfortunately, these systems perform badly in
the presence of blockage. A sudden blockage in the line of sight(LOS) link
leads to communication disconnection, which causes a reliability problem. Also,
searching alternative base stations(BS) for re-connection results in latency
overhead. In this paper, we tackle these problems by predicting the time of
blockage occurrence using a machine learning (ML) technique. In our approach,
BS learns how to predict that a certain link will experience blockage in the
near future using the received signal power. Simulation results on a real
dataset show that blockage occurrence can be predicted with 85% accuracy and
the exact time instance of blockage occurrence can be obtained with low error.
Thus the proposed method reduces the communication disconnections in mmWave
communication, thereby increasing reliability and reducing latency of such
systems.
</p>
<a href="http://arxiv.org/abs/2101.06886" target="_blank">arXiv:2101.06886</a> [<a href="http://arxiv.org/pdf/2101.06886" target="_blank">pdf</a>]

<h2>Cooperative and Competitive Biases for Multi-Agent Reinforcement Learning. (arXiv:2101.06890v1 [cs.LG])</h2>
<h3>Heechang Ryu, Hayong Shin, Jinkyoo Park</h3>
<p>Training a multi-agent reinforcement learning (MARL) algorithm is more
challenging than training a single-agent reinforcement learning algorithm,
because the result of a multi-agent task strongly depends on the complex
interactions among agents and their interactions with a stochastic and dynamic
environment. We propose an algorithm that boosts MARL training using the biased
action information of other agents based on a friend-or-foe concept. For a
cooperative and competitive environment, there are generally two groups of
agents: cooperative-agents and competitive-agents. In the proposed algorithm,
each agent updates its value function using its own action and the biased
action information of other agents in the two groups. The biased joint action
of cooperative agents is computed as the sum of their actual joint action and
the imaginary cooperative joint action, by assuming all the cooperative agents
jointly maximize the target agent's value function. The biased joint action of
competitive agents can be computed similarly. Each agent then updates its own
value function using the biased action information, resulting in a biased value
function and corresponding biased policy. Subsequently, the biased policy of
each agent is inevitably subjected to recommend an action to cooperate and
compete with other agents, thereby introducing more active interactions among
agents and enhancing the MARL policy learning. We empirically demonstrate that
our algorithm outperforms existing algorithms in various mixed
cooperative-competitive environments. Furthermore, the introduced biases
gradually decrease as the training proceeds and the correction based on the
imaginary assumption vanishes.
</p>
<a href="http://arxiv.org/abs/2101.06890" target="_blank">arXiv:2101.06890</a> [<a href="http://arxiv.org/pdf/2101.06890" target="_blank">pdf</a>]

<h2>Kimera: from SLAM to Spatial Perception with 3D Dynamic Scene Graphs. (arXiv:2101.06894v1 [cs.RO])</h2>
<h3>Antoni Rosinol, Andrew Violette, Marcus Abate, Nathan Hughes, Yun Chang, Jingnan Shi, Arjun Gupta, Luca Carlone</h3>
<p>Humans are able to form a complex mental model of the environment they move
in. This mental model captures geometric and semantic aspects of the scene,
describes the environment at multiple levels of abstractions (e.g., objects,
rooms, buildings), includes static and dynamic entities and their relations
(e.g., a person is in a room at a given time). In contrast, current robots'
internal representations still provide a partial and fragmented understanding
of the environment, either in the form of a sparse or dense set of geometric
primitives (e.g., points, lines, planes, voxels) or as a collection of objects.
This paper attempts to reduce the gap between robot and human perception by
introducing a novel representation, a 3D Dynamic Scene Graph(DSG), that
seamlessly captures metric and semantic aspects of a dynamic environment. A DSG
is a layered graph where nodes represent spatial concepts at different levels
of abstraction, and edges represent spatio-temporal relations among nodes. Our
second contribution is Kimera, the first fully automatic method to build a DSG
from visual-inertial data. Kimera includes state-of-the-art techniques for
visual-inertial SLAM, metric-semantic 3D reconstruction, object localization,
human pose and shape estimation, and scene parsing. Our third contribution is a
comprehensive evaluation of Kimera in real-life datasets and photo-realistic
simulations, including a newly released dataset, uHumans2, which simulates a
collection of crowded indoor and outdoor scenes. Our evaluation shows that
Kimera achieves state-of-the-art performance in visual-inertial SLAM, estimates
an accurate 3D metric-semantic mesh model in real-time, and builds a DSG of a
complex indoor environment with tens of objects and humans in minutes. Our
final contribution shows how to use a DSG for real-time hierarchical semantic
path-planning. The core modules in Kimera are open-source.
</p>
<a href="http://arxiv.org/abs/2101.06894" target="_blank">arXiv:2101.06894</a> [<a href="http://arxiv.org/pdf/2101.06894" target="_blank">pdf</a>]

<h2>Multi-Source Data Fusion for Cyberattack Detection in Power Systems. (arXiv:2101.06897v1 [cs.LG])</h2>
<h3>Abhijeet Sahu, Zeyu Mao, Patrick Wlazlo, Hao Huang, Katherine Davis, Ana Goulart, Saman Zonouz</h3>
<p>Cyberattacks can cause a severe impact on power systems unless detected
early. However, accurate and timely detection in critical infrastructure
systems presents challenges, e.g., due to zero-day vulnerability exploitations
and the cyber-physical nature of the system coupled with the need for high
reliability and resilience of the physical system. Conventional rule-based and
anomaly-based intrusion detection system (IDS) tools are insufficient for
detecting zero-day cyber intrusions in the industrial control system (ICS)
networks. Hence, in this work, we show that fusing information from multiple
data sources can help identify cyber-induced incidents and reduce false
positives. Specifically, we present how to recognize and address the barriers
that can prevent the accurate use of multiple data sources for fusion-based
detection. We perform multi-source data fusion for training IDS in a
cyber-physical power system testbed where we collect cyber and physical side
data from multiple sensors emulating real-world data sources that would be
found in a utility and synthesizes these into features for algorithms to detect
intrusions. Results are presented using the proposed data fusion application to
infer False Data and Command injection-based Man-in- The-Middle (MiTM) attacks.
Post collection, the data fusion application uses time-synchronized merge and
extracts features followed by pre-processing such as imputation and encoding
before training supervised, semi-supervised, and unsupervised learning models
to evaluate the performance of the IDS. A major finding is the improvement of
detection accuracy by fusion of features from cyber, security, and physical
domains. Additionally, we observed the co-training technique performs at par
with supervised learning methods when fed with our features.
</p>
<a href="http://arxiv.org/abs/2101.06897" target="_blank">arXiv:2101.06897</a> [<a href="http://arxiv.org/pdf/2101.06897" target="_blank">pdf</a>]

<h2>What Do Deep Nets Learn? Class-wise Patterns Revealed in the Input Space. (arXiv:2101.06898v1 [cs.CV])</h2>
<h3>Shihao Zhao, Xingjun Ma, Yisen Wang, James Bailey, Bo Li, Yu-Gang Jiang</h3>
<p>Deep neural networks (DNNs) have been widely adopted in different
applications to achieve state-of-the-art performance. However, they are often
applied as a black box with limited understanding of what the model has learned
from the data. In this paper, we focus on image classification and propose a
method to visualize and understand the class-wise patterns learned by DNNs
trained under three different settings including natural, backdoored and
adversarial. Different from existing class-wise deep representation
visualizations, our method searches for a single predictive pattern in the
input (i.e. pixel) space for each class. Based on the proposed method, we show
that DNNs trained on natural (clean) data learn abstract shapes along with some
texture, and backdoored models learn a small but highly predictive pattern for
the backdoor target class. Interestingly, the existence of class-wise
predictive patterns in the input space indicates that even DNNs trained on
clean data can have backdoors, and the class-wise patterns identified by our
method can be readily applied to "backdoor" attack the model. In the
adversarial setting, we show that adversarially trained models learn more
simplified shape patterns. Our method can serve as a useful tool to better
understand DNNs trained on different datasets under different settings.
</p>
<a href="http://arxiv.org/abs/2101.06898" target="_blank">arXiv:2101.06898</a> [<a href="http://arxiv.org/pdf/2101.06898" target="_blank">pdf</a>]

<h2>Soft Constrained Autonomous Vehicle Navigation using Gaussian Processes and Instance Segmentation. (arXiv:2101.06901v1 [cs.RO])</h2>
<h3>Bruno H. Groenner Barbosa, Neel P. Bhatt, Amir Khajepour, Ehsan Hashemi</h3>
<p>This paper presents a generic feature-based navigation framework for
autonomous vehicles using a soft constrained Particle Filter. Selected map
features, such as road and landmark locations, and vehicle states are used for
designing soft constraints. After obtaining features of mapped landmarks in
instance-based segmented images acquired from a monocular camera,
vehicle-to-landmark distances are predicted using Gaussian Process Regression
(GPR) models in a mixture of experts approach. Both mean and variance outputs
of GPR models are used for implementing adaptive constraints. Experimental
results confirm that the use of image segmentation features improves the
vehicle-to-landmark distance prediction notably, and that the proposed soft
constrained approach reliably localizes the vehicle even with reduced number of
landmarks and noisy observations.
</p>
<a href="http://arxiv.org/abs/2101.06901" target="_blank">arXiv:2101.06901</a> [<a href="http://arxiv.org/pdf/2101.06901" target="_blank">pdf</a>]

<h2>Blockchain Assisted Decentralized Federated Learning (BLADE-FL): Performance Analysis and Resource Allocation. (arXiv:2101.06905v1 [cs.LG])</h2>
<h3>Jun Li, Yumeng Shao, Kang Wei, Ming Ding, Chuan Ma, Long Shi, Zhu Han, H. Vincent Poor</h3>
<p>Federated learning (FL), as a distributed machine learning paradigm, promotes
personal privacy by clients' processing raw data locally. However, relying on a
centralized server for model aggregation, standard FL is vulnerable to server
malfunctions, untrustworthy server, and external attacks. To address this
issue, we propose a decentralized FL framework by integrating blockchain into
FL, namely, blockchain assisted decentralized federated learning (BLADE-FL). In
a round of the proposed BLADE-FL, each client broadcasts its trained model to
other clients, competes to generate a block based on the received models, and
then aggregates the models from the generated block before its local training
of the next round. We evaluate the learning performance of BLADE-FL, and
develop an upper bound on the global loss function. Then we verify that this
bound is convex with respect to the number of overall rounds K, and optimize
the computing resource allocation for minimizing the upper bound. We also note
that there is a critical problem of training deficiency, caused by lazy clients
who plagiarize others' trained models and add artificial noises to disguise
their cheating behaviors. Focusing on this problem, we explore the impact of
lazy clients on the learning performance of BLADE-FL, and characterize the
relationship among the optimal K, the learning parameters, and the proportion
of lazy clients. Based on the MNIST and Fashion-MNIST datasets, we show that
the experimental results are consistent with the analytical ones. To be
specific, the gap between the developed upper bound and experimental results is
lower than 5%, and the optimized K based on the upper bound can effectively
minimize the loss function.
</p>
<a href="http://arxiv.org/abs/2101.06905" target="_blank">arXiv:2101.06905</a> [<a href="http://arxiv.org/pdf/2101.06905" target="_blank">pdf</a>]

<h2>Stable deep reinforcement learning method by predicting uncertainty in rewards as a subtask. (arXiv:2101.06906v1 [cs.LG])</h2>
<h3>Kanata Suzuki, Tetsuya Ogata</h3>
<p>In recent years, a variety of tasks have been accomplished by deep
reinforcement learning (DRL). However, when applying DRL to tasks in a
real-world environment, designing an appropriate reward is difficult. Rewards
obtained via actual hardware sensors may include noise, misinterpretation, or
failed observations. The learning instability caused by these unstable signals
is a problem that remains to be solved in DRL. In this work, we propose an
approach that extends existing DRL models by adding a subtask to directly
estimate the variance contained in the reward signal. The model then takes the
feature map learned by the subtask in a critic network and sends it to the
actor network. This enables stable learning that is robust to the effects of
potential noise. The results of experiments in the Atari game domain with
unstable reward signals show that our method stabilizes training convergence.
We also discuss the extensibility of the model by visualizing feature maps.
This approach has the potential to make DRL more practical for use in noisy,
real-world scenarios.
</p>
<a href="http://arxiv.org/abs/2101.06906" target="_blank">arXiv:2101.06906</a> [<a href="http://arxiv.org/pdf/2101.06906" target="_blank">pdf</a>]

<h2>TLU-Net: A Deep Learning Approach for Automatic Steel Surface Defect Detection. (arXiv:2101.06915v1 [cs.CV])</h2>
<h3>Praveen Damacharla, Achuth Rao M. V., Jordan Ringenberg, Ahmad Y Javaid</h3>
<p>Visual steel surface defect detection is an essential step in steel sheet
manufacturing. Several machine learning-based automated visual inspection (AVI)
methods have been studied in recent years. However, most steel manufacturing
industries still use manual visual inspection due to training time and
inaccuracies involved with AVI methods. Automatic steel defect detection
methods could be useful in less expensive and faster quality control and
feedback. But preparing the annotated training data for segmentation and
classification could be a costly process. In this work, we propose to use the
Transfer Learning-based U-Net (TLU-Net) framework for steel surface defect
detection. We use a U-Net architecture as the base and explore two kinds of
encoders: ResNet and DenseNet. We compare these nets' performance using random
initialization and the pre-trained networks trained using the ImageNet data
set. The experiments are performed using Severstal data. The results
demonstrate that the transfer learning performs 5% (absolute) better than that
of the random initialization in defect classification. We found that the
transfer learning performs 26% (relative) better than that of the random
initialization in defect segmentation. We also found the gain of transfer
learning increases as the training data decreases, and the convergence rate
with transfer learning is better than that of the random initialization.
</p>
<a href="http://arxiv.org/abs/2101.06915" target="_blank">arXiv:2101.06915</a> [<a href="http://arxiv.org/pdf/2101.06915" target="_blank">pdf</a>]

<h2>Detection of Insider Attacks in Distributed Projected Subgradient Algorithms. (arXiv:2101.06917v1 [cs.LG])</h2>
<h3>Sissi Xiaoxiao Wu, Gangqiang Li, Shengli Zhang, Xiaohui Lin</h3>
<p>The gossip-based distributed algorithms are widely used to solve
decentralized optimization problems in various multi-agent applications, while
they are generally vulnerable to data injection attacks by internal malicious
agents as each agent locally estimates its decent direction without an
authorized supervision. In this work, we explore the application of artificial
intelligence (AI) technologies to detect internal attacks. We show that a
general neural network is particularly suitable for detecting and localizing
the malicious agents, as they can effectively explore nonlinear relationship
underlying the collected data. Moreover, we propose to adopt one of the
state-of-art approaches in federated learning, i.e., a collaborative
peer-to-peer machine learning protocol, to facilitate training our neural
network models by gossip exchanges. This advanced approach is expected to make
our model more robust to challenges with insufficient training data, or
mismatched test data. In our simulations, a least-squared problem is considered
to verify the feasibility and effectiveness of AI-based methods. Simulation
results demonstrate that the proposed AI-based methods are beneficial to
improve performance of detecting and localizing malicious agents over
score-based methods, and the peer-to-peer neural network model is indeed robust
to target issues.
</p>
<a href="http://arxiv.org/abs/2101.06917" target="_blank">arXiv:2101.06917</a> [<a href="http://arxiv.org/pdf/2101.06917" target="_blank">pdf</a>]

<h2>Is Intelligence Artificial?. (arXiv:1403.1076v6 [cs.AI] UPDATED)</h2>
<h3>Kieran Greer</h3>
<p>Our understanding of intelligence is directed primarily at the human level.
This paper attempts to give a more unifying definition that can be applied to
the natural world in general. The definition would be used more to verify a
degree of intelligence, not to quantify it and might help when making
judgements on the matter. While correct behaviour is the preferred definition,
a metric that is grounded in Kolmogorov's Complexity Theory is suggested, which
leads to a measurement about entropy. A version of an accepted AI test is then
put forward as the 'acid test' and might be what a free-thinking program would
try to achieve. Recent work by the author has been more from a direction of
mechanical processes, or ones that might operate automatically. This paper will
not try to question the idea of intelligence, in the sense of a pro-active or
conscious event, but try to put it into a more passive, automatic and
mechanical context. The paper also suggests looking at intelligence and
consciousness as being slightly different.
</p>
<a href="http://arxiv.org/abs/1403.1076" target="_blank">arXiv:1403.1076</a> [<a href="http://arxiv.org/pdf/1403.1076" target="_blank">pdf</a>]

<h2>Predicting Shot Making in Basketball Learnt from Adversarial Multiagent Trajectories. (arXiv:1609.04849v5 [stat.ML] UPDATED)</h2>
<h3>Mark Harmon, Abdolghani Ebrahimi, Patrick Lucey, Diego Klabjan</h3>
<p>In this paper, we predict the likelihood of a player making a shot in
basketball from multiagent trajectories. Previous approaches to similar
problems center on hand-crafting features to capture domain specific knowledge.
Although intuitive, recent work in deep learning has shown this approach is
prone to missing important predictive features. To circumvent this issue, we
present a convolutional neural network (CNN) approach where we initially
represent the multiagent behavior as an image. To encode the adversarial nature
of basketball, we use a multi-channel image which we then feed into a CNN.
Additionally, to capture the temporal aspect of the trajectories we "fade" the
player trajectories. We find that this approach is superior to a traditional
FFN model. By using gradient ascent to create images using an already trained
CNN, we discover what features the CNN filters learn. Last, we find that a
combined CNN+FFN is the best performing network with an error rate of 39%.
</p>
<a href="http://arxiv.org/abs/1609.04849" target="_blank">arXiv:1609.04849</a> [<a href="http://arxiv.org/pdf/1609.04849" target="_blank">pdf</a>]

<h2>XCSP3: An Integrated Format for Benchmarking Combinatorial Constrained Problems. (arXiv:1611.03398v3 [cs.AI] UPDATED)</h2>
<h3>Frederic Boussemart, Christophe Lecoutre, Gilles Audemard, C&#xe9;dric Piette</h3>
<p>We propose a major revision of the format XCSP 2.1, called XCSP3, to build
integrated representations of combinatorial constrained problems. This new
format is able to deal with mono/multi optimization, many types of variables,
cost functions, reification, views, annotations, variable quantification,
distributed, probabilistic and qualitative reasoning. The new format is made
compact, highly readable, and rather easy to parse. Interestingly, it captures
the structure of the problem models, through the possibilities of declaring
arrays of variables, and identifying syntactic and semantic groups of
constraints. The number of constraints is kept under control by introducing a
limited set of basic constraint forms, and producing almost automatically some
of their variations through lifting, restriction, sliding, logical combination
and relaxation mechanisms. As a result, XCSP3 encompasses practically all
constraints that can be found in major constraint solvers developed by the CP
community. A website, which is developed conjointly with the format, contains
many models and series of instances. The user can make sophisticated queries
for selecting instances from very precise criteria. The objective of XCSP3 is
to ease the effort required to test and compare different algorithms by
providing a common test-bed of combinatorial constrained instances.
</p>
<a href="http://arxiv.org/abs/1611.03398" target="_blank">arXiv:1611.03398</a> [<a href="http://arxiv.org/pdf/1611.03398" target="_blank">pdf</a>]

<h2>Asynchronous Announcements. (arXiv:1705.03392v4 [cs.AI] UPDATED)</h2>
<h3>Philippe Balbiani, Hans van Ditmarsch, Sa&#xfa;l Fern&#xe1;ndez Gonz&#xe1;lez</h3>
<p>We propose a multi-agent epistemic logic of asynchronous announcements, where
truthful announcements are publicly sent but individually received by agents,
and in the order in which they were sent. Additional to epistemic modalities
the logic contains dynamic modalities for making announcements and for
receiving them. What an agent believes is a function of her initial uncertainty
and of the announcements she has received. Beliefs need not be truthful,
because announcements already made may not yet have been received. As
announcements are true when sent, certain message sequences can be ruled out,
just like inconsistent cuts in distributed computing.

We provide a complete axiomatization for this \emph{asynchronous announcement
logic} (AA). It is a reduction system that also demonstrates that any formula
in $AA$ is equivalent to one without dynamic modalities, just as for public
announcement logic. A detailed example modelling message exchanging processes
in distributed computing in $AA$ closes our investigation.
</p>
<a href="http://arxiv.org/abs/1705.03392" target="_blank">arXiv:1705.03392</a> [<a href="http://arxiv.org/pdf/1705.03392" target="_blank">pdf</a>]

<h2>MARGIN: Uncovering Deep Neural Networks using Graph Signal Analysis. (arXiv:1711.05407v4 [stat.ML] UPDATED)</h2>
<h3>Rushil Anirudh, Jayaraman J. Thiagarajan, Rahul Sridhar, Peer-Timo Bremer</h3>
<p>Interpretability has emerged as a crucial aspect of building trust in machine
learning systems, aimed at providing insights into the working of complex
neural networks that are otherwise opaque to a user. There are a plethora of
existing solutions addressing various aspects of interpretability ranging from
identifying prototypical samples in a dataset to explaining image predictions
or explaining mis-classifications. While all of these diverse techniques
address seemingly different aspects of interpretability, we hypothesize that a
large family of interepretability tasks are variants of the same central
problem which is identifying \emph{relative} change in a model's prediction.
This paper introduces MARGIN, a simple yet general approach to address a large
set of interpretability tasks MARGIN exploits ideas rooted in graph signal
analysis to determine influential nodes in a graph, which are defined as those
nodes that maximally describe a function defined on the graph. By carefully
defining task-specific graphs and functions, we demonstrate that MARGIN
outperforms existing approaches in a number of disparate interpretability
challenges.
</p>
<a href="http://arxiv.org/abs/1711.05407" target="_blank">arXiv:1711.05407</a> [<a href="http://arxiv.org/pdf/1711.05407" target="_blank">pdf</a>]

<h2>Tsallis-INF: An Optimal Algorithm for Stochastic and Adversarial Bandits. (arXiv:1807.07623v5 [cs.LG] UPDATED)</h2>
<h3>Julian Zimmert, Yevgeny Seldin</h3>
<p>We derive an algorithm that achieves the optimal (within constants)
pseudo-regret in both adversarial and stochastic multi-armed bandits without
prior knowledge of the regime and time horizon. The algorithm is based on
online mirror descent (OMD) with Tsallis entropy regularization with power
$\alpha=1/2$ and reduced-variance loss estimators. More generally, we define an
adversarial regime with a self-bounding constraint, which includes stochastic
regime, stochastically constrained adversarial regime (Wei and Luo), and
stochastic regime with adversarial corruptions (Lykouris et al.) as special
cases, and show that the algorithm achieves logarithmic regret guarantee in
this regime and all of its special cases simultaneously with the adversarial
regret guarantee.} The algorithm also achieves adversarial and stochastic
optimality in the utility-based dueling bandit setting. We provide empirical
evaluation of the algorithm demonstrating that it significantly outperforms
UCB1 and EXP3 in stochastic environments. We also provide examples of
adversarial environments, where UCB1 and Thompson Sampling exhibit almost
linear regret, whereas our algorithm suffers only logarithmic regret. To the
best of our knowledge, this is the first example demonstrating vulnerability of
Thompson Sampling in adversarial environments. Last, but not least, we present
a general stochastic analysis and a general adversarial analysis of OMD
algorithms with Tsallis entropy regularization for $\alpha\in[0,1]$ and explain
the reason why $\alpha=1/2$ works best.
</p>
<a href="http://arxiv.org/abs/1807.07623" target="_blank">arXiv:1807.07623</a> [<a href="http://arxiv.org/pdf/1807.07623" target="_blank">pdf</a>]

<h2>On a Sparse Shortcut Topology of Artificial Neural Networks. (arXiv:1811.09003v3 [cs.LG] UPDATED)</h2>
<h3>Fenglei Fan, Dayang Wang, Hengtao Guo, Qikui Zhu, Pingkun Yan, Ge Wang, Hengyong Yu</h3>
<p>Over recent years, deep learning has become the mainstream data-driven
approach to solve many important real-world problems. In the successful network
architectures, shortcut connections are well established to take the outputs of
earlier layers as additional inputs to later layers, which have produced
excellent results. Despite the extraordinary effectiveness of shortcuts, there
remain important questions on the underlying mechanism and associated
functionalities. For example, why are shortcuts powerful? Why shortcuts
generalize well? To address these questions, we investigate the representation
and generalization ability of a sparse shortcut topology. Specifically, we
first demonstrate that this topology can empower a one-neuron-wide deep network
to approximate any univariate continuous function. Then, we present a novel
width-bounded universal approximator in contrast to depth-bounded universal
approximators, and also extend the approximation result to a family of networks
such that in the view of approximation ability, these networks are equally
competent. Furthermore, we use the generalization bound theory to show that the
investigated shortcut topology enjoys an excellent generalizability. Finally,
we corroborate our theoretical analyses with experiments on some well-known
benchmarks.
</p>
<a href="http://arxiv.org/abs/1811.09003" target="_blank">arXiv:1811.09003</a> [<a href="http://arxiv.org/pdf/1811.09003" target="_blank">pdf</a>]

<h2>On the Benefit of Width for Neural Networks: Disappearance of Bad Basins. (arXiv:1812.11039v5 [cs.LG] UPDATED)</h2>
<h3>Dawei Li, Tian Ding, Ruoyu Sun</h3>
<p>Wide networks are often believed to have nice optimization landscape, but
what rigorous results can we prove? To understand the benefit of width, it is
important to identify the difference between wide and narrow networks. In this
work, we prove that from narrow to wide networks, there is a phase transition
from having sub-optimal basins to no sub-optimal basins. Specifically, we prove
two results: on the positive side, for any continuous activation functions, the
loss surface of a class of wide networks has no sub-optimal basin, where
"basin" is defined as the set-wise strict local minimum; on the negative side,
for a large class of networks with width below a threshold, we construct strict
local minima that are not global. These two results together show the phase
transition from narrow to wide networks.
</p>
<a href="http://arxiv.org/abs/1812.11039" target="_blank">arXiv:1812.11039</a> [<a href="http://arxiv.org/pdf/1812.11039" target="_blank">pdf</a>]

<h2>High Fidelity Face Manipulation with Extreme Poses and Expressions. (arXiv:1903.12003v4 [cs.CV] UPDATED)</h2>
<h3>Chaoyou Fu, Yibo Hu, Xiang Wu, Guoli Wang, Qian Zhang, Ran He</h3>
<p>Face manipulation has shown remarkable advances with the flourish of
Generative Adversarial Networks. However, due to the difficulties of
controlling structures and textures, it is challenging to model poses and
expressions simultaneously, especially for the extreme manipulation at
high-resolution. In this paper, we propose a novel framework that simplifies
face manipulation into two correlated stages: a boundary prediction stage and a
disentangled face synthesis stage. The first stage models poses and expressions
jointly via boundary images. Specifically, a conditional encoder-decoder
network is employed to predict the boundary image of the target face in a
semi-supervised way. Pose and expression estimators are introduced to improve
the prediction performance. In the second stage, the predicted boundary image
and the input face image are encoded into the structure and the texture latent
space by two encoder networks, respectively. A proxy network and a feature
threshold loss are further imposed to disentangle the latent space.
Furthermore, due to the lack of high-resolution face manipulation databases to
verify the effectiveness of our method, we collect a new high-quality
Multi-View Face (MVF-HQ) database. It contains 120,283 images at 6000x4000
resolution from 479 identities with diverse poses, expressions, and
illuminations. MVF-HQ is much larger in scale and much higher in resolution
than publicly available high-resolution face manipulation databases. We will
release MVF-HQ soon to push forward the advance of face manipulation.
Qualitative and quantitative experiments on four databases show that our method
dramatically improves the synthesis quality.
</p>
<a href="http://arxiv.org/abs/1903.12003" target="_blank">arXiv:1903.12003</a> [<a href="http://arxiv.org/pdf/1903.12003" target="_blank">pdf</a>]

<h2>Adversarial Policies: Attacking Deep Reinforcement Learning. (arXiv:1905.10615v3 [cs.LG] UPDATED)</h2>
<h3>Adam Gleave, Michael Dennis, Cody Wild, Neel Kant, Sergey Levine, Stuart Russell</h3>
<p>Deep reinforcement learning (RL) policies are known to be vulnerable to
adversarial perturbations to their observations, similar to adversarial
examples for classifiers. However, an attacker is not usually able to directly
modify another agent's observations. This might lead one to wonder: is it
possible to attack an RL agent simply by choosing an adversarial policy acting
in a multi-agent environment so as to create natural observations that are
adversarial? We demonstrate the existence of adversarial policies in zero-sum
games between simulated humanoid robots with proprioceptive observations,
against state-of-the-art victims trained via self-play to be robust to
opponents. The adversarial policies reliably win against the victims but
generate seemingly random and uncoordinated behavior. We find that these
policies are more successful in high-dimensional environments, and induce
substantially different activations in the victim policy network than when the
victim plays against a normal opponent. Videos are available at
https://adversarialpolicies.github.io/.
</p>
<a href="http://arxiv.org/abs/1905.10615" target="_blank">arXiv:1905.10615</a> [<a href="http://arxiv.org/pdf/1905.10615" target="_blank">pdf</a>]

<h2>How to gamble with non-stationary $\mathcal{X}$-armed bandits and have no regrets. (arXiv:1908.07636v3 [stat.ML] UPDATED)</h2>
<h3>Valeriy Avanesov</h3>
<p>In $\mathcal{X}$-armed bandit problem an agent sequentially interacts with
environment which yields a reward based on the vector input the agent provides.
The agent's goal is to maximise the sum of these rewards across some number of
time steps. The problem and its variations have been a subject of numerous
studies, suggesting sub-linear and some times optimal strategies. The given
paper introduces a novel variation of the problem. We consider an environment,
which can abruptly change its behaviour an unknown number of times. To that end
we propose a novel strategy and prove it attains sub-linear cumulative regret.
Moreover, in case of highly smooth relation between an action and the
corresponding reward, the method is nearly optimal. The theoretical result are
supported by experimental study.
</p>
<a href="http://arxiv.org/abs/1908.07636" target="_blank">arXiv:1908.07636</a> [<a href="http://arxiv.org/pdf/1908.07636" target="_blank">pdf</a>]

<h2>Learning without feedback: Fixed random learning signals allow for feedforward training of deep neural networks. (arXiv:1909.01311v2 [stat.ML] UPDATED)</h2>
<h3>Charlotte Frenkel, Martin Lefebvre, David Bol</h3>
<p>While the backpropagation of error algorithm enables deep neural network
training, it implies (i) bidirectional synaptic weight transport and (ii)
update locking until the forward and backward passes are completed. Not only do
these constraints preclude biological plausibility, but they also hinder the
development of low-cost adaptive smart sensors at the edge, as they severely
constrain memory accesses and entail buffering overhead. In this work, we show
that the one-hot-encoded labels provided in supervised classification problems,
denoted as targets, can be viewed as a proxy for the error sign. Therefore,
their fixed random projections enable a layerwise feedforward training of the
hidden layers, thus solving the weight transport and update locking problems
while relaxing the computational and memory requirements. Based on these
observations, we propose the direct random target projection (DRTP) algorithm
and demonstrate that it provides a tradeoff between accuracy and computational
cost that is suitable for adaptive edge computing devices.
</p>
<a href="http://arxiv.org/abs/1909.01311" target="_blank">arXiv:1909.01311</a> [<a href="http://arxiv.org/pdf/1909.01311" target="_blank">pdf</a>]

<h2>An Efficient and Layout-Independent Automatic License Plate Recognition System Based on the YOLO detector. (arXiv:1909.01754v3 [cs.CV] UPDATED)</h2>
<h3>Rayson Laroca, Luiz A. Zanlorensi, Gabriel R. Gon&#xe7;alves, Eduardo Todt, William Robson Schwartz, David Menotti</h3>
<p>In this paper, we present an efficient and layout-independent Automatic
License Plate Recognition (ALPR) system based on the state-of-the-art YOLO
object detector that contains a unified approach for license plate (LP)
detection and layout classification to improve the recognition results using
post-processing rules. The system is conceived by evaluating and optimizing
different models with various modifications, aiming at achieving the best
speed/accuracy trade-off at each stage. The networks are trained using images
from several datasets, with the addition of various data augmentation
techniques, so that they are robust under different conditions. The proposed
system achieved an average end-to-end recognition rate of 96.8% across eight
public datasets (from five different regions) used in the experiments,
outperforming both previous works and commercial systems in the ChineseLP,
OpenALPR-EU, SSIG-SegPlate and UFPR-ALPR datasets. In the other datasets, the
proposed approach achieved competitive results to those attained by the
baselines. Our system also achieved impressive frames per second (FPS) rates on
a high-end GPU, being able to perform in real time even when there are four
vehicles in the scene. An additional contribution is that we manually labeled
38,334 bounding boxes on 6,237 images from public datasets and made the
annotations publicly available to the research community.
</p>
<a href="http://arxiv.org/abs/1909.01754" target="_blank">arXiv:1909.01754</a> [<a href="http://arxiv.org/pdf/1909.01754" target="_blank">pdf</a>]

<h2>Learning Hierarchically Structured Concepts. (arXiv:1909.04559v4 [cs.AI] UPDATED)</h2>
<h3>Nancy Lynch, Frederik Mallmann-Trenn</h3>
<p>We study the question of how concepts that have structure get represented in
the brain. Specifically, we introduce a model for hierarchically structured
concepts and we show how a biologically plausible neural network can recognize
these concepts, and how it can learn them in the first place. Our main goal is
to introduce a general framework for these tasks and prove formally how both
(recognition and learning) can be achieved.

We show that both tasks can be accomplished even in presence of noise. For
learning, we analyze Oja's rule formally, a well-known biologically-plausible
rule for adjusting the weights of synapses. We complement the learning results
with lower bounds asserting that, in order to recognize concepts of a certain
hierarchical depth, neural networks must have a corresponding number of layers.
</p>
<a href="http://arxiv.org/abs/1909.04559" target="_blank">arXiv:1909.04559</a> [<a href="http://arxiv.org/pdf/1909.04559" target="_blank">pdf</a>]

<h2>Bayesian Optimization for Iterative Learning. (arXiv:1909.09593v5 [cs.LG] UPDATED)</h2>
<h3>Vu Nguyen, Sebastian Schulze, Michael A Osborne</h3>
<p>The performance of deep (reinforcement) learning systems crucially depends on
the choice of hyperparameters. Their tuning is notoriously expensive, typically
requiring an iterative training process to run for numerous steps to
convergence. Traditional tuning algorithms only consider the final performance
of hyperparameters acquired after many expensive iterations and ignore
intermediate information from earlier training steps. In this paper, we present
a Bayesian optimization (BO) approach which exploits the iterative structure of
learning algorithms for efficient hyperparameter tuning. We propose to learn an
evaluation function compressing learning progress at any stage of the training
process into a single numeric score according to both training success and
stability. Our BO framework is then balancing the benefit of assessing a
hyperparameter setting over additional training steps against their computation
cost. We further increase model efficiency by selectively including scores from
different training steps for any evaluated hyperparameter set. We demonstrate
the efficiency of our algorithm by tuning hyperparameters for the training of
deep reinforcement learning agents and convolutional neural networks. Our
algorithm outperforms all existing baselines in identifying optimal
hyperparameters in minimal time.
</p>
<a href="http://arxiv.org/abs/1909.09593" target="_blank">arXiv:1909.09593</a> [<a href="http://arxiv.org/pdf/1909.09593" target="_blank">pdf</a>]

<h2>Interpreting Knowledge Graph Relation Representation from Word Embeddings. (arXiv:1909.11611v2 [cs.LG] UPDATED)</h2>
<h3>Carl Allen, Ivana Bala&#x17e;evi&#x107;, Timothy Hospedales</h3>
<p>Many models learn representations of knowledge graph data by exploiting its
low-rank latent structure, encoding known relations between entities and
enabling unknown facts to be inferred. To predict whether a relation holds
between entities, embeddings are typically compared in the latent space
following a relation-specific mapping. Whilst their predictive performance has
steadily improved, how such models capture the underlying latent structure of
semantic information remains unexplained. Building on recent theoretical
understanding of word embeddings, we categorise knowledge graph relations into
three types and for each derive explicit requirements of their representations.
We show that empirical properties of relation representations and the relative
performance of leading knowledge graph representation methods are justified by
our analysis.
</p>
<a href="http://arxiv.org/abs/1909.11611" target="_blank">arXiv:1909.11611</a> [<a href="http://arxiv.org/pdf/1909.11611" target="_blank">pdf</a>]

<h2>Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions. (arXiv:1909.13403v5 [cs.LG] UPDATED)</h2>
<h3>Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, Vyas Sekar</h3>
<p>Limited data access is a longstanding barrier to data-driven research and
development in the networked systems community. In this work, we explore if and
how generative adversarial networks (GANs) can be used to incentivize data
sharing by enabling a generic framework for sharing synthetic datasets with
minimal expert knowledge. As a specific target, our focus in this paper is on
time series datasets with metadata (e.g., packet loss rate measurements with
corresponding ISPs). We identify key challenges of existing GAN approaches for
such workloads with respect to fidelity (e.g., long-term dependencies, complex
multidimensional relationships, mode collapse) and privacy (i.e., existing
guarantees are poorly understood and can sacrifice fidelity). To improve
fidelity, we design a custom workflow called DoppelGANger (DG) and demonstrate
that across diverse real-world datasets (e.g., bandwidth measurements, cluster
requests, web sessions) and use cases (e.g., structural characterization,
predictive modeling, algorithm comparison), DG achieves up to 43% better
fidelity than baseline models. Although we do not resolve the privacy problem
in this work, we identify fundamental challenges with both classical notions of
privacy and recent advances to improve the privacy properties of GANs, and
suggest a potential roadmap for addressing these challenges. By shedding light
on the promise and challenges, we hope our work can rekindle the conversation
on workflows for data sharing.
</p>
<a href="http://arxiv.org/abs/1909.13403" target="_blank">arXiv:1909.13403</a> [<a href="http://arxiv.org/pdf/1909.13403" target="_blank">pdf</a>]

<h2>Sparsification as a Remedy for Staleness in Distributed Asynchronous SGD. (arXiv:1910.09466v3 [cs.LG] UPDATED)</h2>
<h3>Rosa Candela, Giulio Franzese, Maurizio Filippone, Pietro Michiardi</h3>
<p>Large scale machine learning is increasingly relying on distributed
optimization, whereby several machines contribute to the training process of a
statistical model. In this work we study the performance of asynchronous,
distributed settings, when applying sparsification, a technique used to reduce
communication overheads. In particular, for the first time in an asynchronous,
non-convex setting, we theoretically prove that, in presence of staleness,
sparsification does not harm SGD performance: the ergodic convergence rate
matches the known result of standard SGD, that is $\mathcal{O} \left(
1/\sqrt{T} \right)$. We also carry out an empirical study to complement our
theory, and confirm that the effects of sparsification on the convergence rate
are negligible, when compared to 'vanilla' SGD, even in the challenging
scenario of an asynchronous, distributed system.
</p>
<a href="http://arxiv.org/abs/1910.09466" target="_blank">arXiv:1910.09466</a> [<a href="http://arxiv.org/pdf/1910.09466" target="_blank">pdf</a>]

<h2>PolyTransform: Deep Polygon Transformer for Instance Segmentation. (arXiv:1912.02801v4 [cs.CV] UPDATED)</h2>
<h3>Justin Liang, Namdar Homayounfar, Wei-Chiu Ma, Yuwen Xiong, Rui Hu, Raquel Urtasun</h3>
<p>In this paper, we propose PolyTransform, a novel instance segmentation
algorithm that produces precise, geometry-preserving masks by combining the
strengths of prevailing segmentation approaches and modern polygon-based
methods. In particular, we first exploit a segmentation network to generate
instance masks. We then convert the masks into a set of polygons that are then
fed to a deforming network that transforms the polygons such that they better
fit the object boundaries. Our experiments on the challenging Cityscapes
dataset show that our PolyTransform significantly improves the performance of
the backbone instance segmentation network and ranks 1st on the Cityscapes
test-set leaderboard. We also show impressive gains in the interactive
annotation setting. We release the code at
https://github.com/uber-research/PolyTransform.
</p>
<a href="http://arxiv.org/abs/1912.02801" target="_blank">arXiv:1912.02801</a> [<a href="http://arxiv.org/pdf/1912.02801" target="_blank">pdf</a>]

<h2>Multi-Object Rearrangement with Monte Carlo Tree Search:A Case Study on Planar Nonprehensile Sorting. (arXiv:1912.07024v3 [cs.RO] UPDATED)</h2>
<h3>Haoran Song, Joshua A. Haustein, Weihao Yuan, Kaiyu Hang, Michael Yu Wang, Danica Kragic, Johannes A. Stork</h3>
<p>In this work, we address a planar non-prehensile sorting task. Here, a robot
needs to push many densely packed objects belonging to different classes into a
configuration where these classes are clearly separated from each other. To
achieve this, we propose to employ Monte Carlo tree search equipped with a
task-specific heuristic function. We evaluate the algorithm on various
simulated and real-world sorting tasks. We observe that the algorithm is
capable to reliably sort large numbers of convex and non-convex objects, as
well as convex objects in the presence of immovable obstacles.
</p>
<a href="http://arxiv.org/abs/1912.07024" target="_blank">arXiv:1912.07024</a> [<a href="http://arxiv.org/pdf/1912.07024" target="_blank">pdf</a>]

<h2>Exploring the Capacity of an Orderless Box Discretization Network for Multi-orientation Scene Text Detection. (arXiv:1912.09629v3 [cs.CV] UPDATED)</h2>
<h3>Yuliang Liu, Tong He, Hao Chen, Xinyu Wang, Canjie Luo, Shuaitao Zhang, Chunhua Shen, Lianwen Jin</h3>
<p>Multi-orientation scene text detection has recently gained significant
research attention. Previous methods directly predict words or text lines,
typically by using quadrilateral shapes. However, many of these methods neglect
the significance of consistent labeling, which is important for maintaining a
stable training process, especially when it comprises a large amount of data.
Here we solve this problem by proposing a new method, Orderless Box
Discretization (OBD), which first discretizes the quadrilateral box into
several key edges containing all potential horizontal and vertical positions.
To decode accurate vertex positions, a simple yet effective matching procedure
is proposed for reconstructing the quadrilateral bounding boxes. Our method
solves the ambiguity issue, which has a significant impact on the learning
process. Extensive ablation studies are conducted to validate the effectiveness
of our proposed method quantitatively. More importantly, based on OBD, we
provide a detailed analysis of the impact of a collection of refinements, which
may inspire others to build state-of-the-art text detectors. Combining both OBD
and these useful refinements, we achieve state-of-the-art performance on
various benchmarks, including ICDAR 2015 and MLT. Our method also won the first
place in the text detection task at the recent ICDAR2019 Robust Reading
Challenge for Reading Chinese Text on Signboards, further demonstrating its
superior performance. The code is available at https://git.io/TextDet.
</p>
<a href="http://arxiv.org/abs/1912.09629" target="_blank">arXiv:1912.09629</a> [<a href="http://arxiv.org/pdf/1912.09629" target="_blank">pdf</a>]

<h2>Generalized Visual Information Analysis via Tensorial Algebra. (arXiv:2001.11708v2 [cs.CV] UPDATED)</h2>
<h3>Liang Liao, Stephen John Maybank</h3>
<p>Higher order data is modeled using matrices whose entries are numerical
arrays of a fixed size. These arrays, called t-scalars, form a commutative ring
under the convolution product. Matrices with elements in the ring of t-scalars
are referred to as t-matrices. The t-matrices can be scaled, added and
multiplied in the usual way. There are t-matrix generalizations of positive
matrices, orthogonal matrices and Hermitian symmetric matrices. With the
t-matrix model, it is possible to generalize many well-known matrix algorithms.
In particular, the t-matrices are used to generalize the SVD (Singular Value
Decomposition), HOSVD (High Order SVD), PCA (Principal Component Analysis),
2DPCA (Two Dimensional PCA) and GCA (Grassmannian Component Analysis). The
generalized t-matrix algorithms, namely TSVD, THOSVD,TPCA, T2DPCA and TGCA, are
applied to low-rank approximation, reconstruction,and supervised classification
of images. Experiments show that the t-matrix algorithms compare favorably with
standard matrix algorithms.
</p>
<a href="http://arxiv.org/abs/2001.11708" target="_blank">arXiv:2001.11708</a> [<a href="http://arxiv.org/pdf/2001.11708" target="_blank">pdf</a>]

<h2>PLLay: Efficient Topological Layer based on Persistence Landscapes. (arXiv:2002.02778v4 [cs.LG] UPDATED)</h2>
<h3>Kwangho Kim, Jisu Kim, Manzil Zaheer, Joon Sik Kim, Frederic Chazal, Larry Wasserman</h3>
<p>We propose PLLay, a novel topological layer for general deep learning models
based on persistence landscapes, in which we can efficiently exploit the
underlying topological features of the input data structure. In this work, we
show differentiability with respect to layer inputs, for a general persistent
homology with arbitrary filtration. Thus, our proposed layer can be placed
anywhere in the network and feed critical information on the topological
features of input data into subsequent layers to improve the learnability of
the networks toward a given task. A task-optimal structure of PLLay is learned
during training via backpropagation, without requiring any input featurization
or data preprocessing. We provide a novel adaptation for the DTM function-based
filtration, and show that the proposed layer is robust against noise and
outliers through a stability analysis. We demonstrate the effectiveness of our
approach by classification experiments on various datasets.
</p>
<a href="http://arxiv.org/abs/2002.02778" target="_blank">arXiv:2002.02778</a> [<a href="http://arxiv.org/pdf/2002.02778" target="_blank">pdf</a>]

<h2>Random Features Strengthen Graph Neural Networks. (arXiv:2002.03155v3 [cs.LG] UPDATED)</h2>
<h3>Ryoma Sato, Makoto Yamada, Hisashi Kashima</h3>
<p>Graph neural networks (GNNs) are powerful machine learning models for various
graph learning tasks. Recently, the limitations of the expressive power of
various GNN models have been revealed. For example, GNNs cannot distinguish
some non-isomorphic graphs and they cannot learn efficient graph algorithms. In
this paper, we demonstrate that GNNs become powerful just by adding a random
feature to each node. We prove that the random features enable GNNs to learn
almost optimal polynomial-time approximation algorithms for the minimum
dominating set problem and maximum matching problem in terms of approximation
ratios. The main advantage of our method is that it can be combined with
off-the-shelf GNN models with slight modifications. Through experiments, we
show that the addition of random features enables GNNs to solve various
problems that normal GNNs, including the graph convolutional networks (GCNs)
and graph isomorphism networks (GINs), cannot solve.
</p>
<a href="http://arxiv.org/abs/2002.03155" target="_blank">arXiv:2002.03155</a> [<a href="http://arxiv.org/pdf/2002.03155" target="_blank">pdf</a>]

<h2>Intra-Camera Supervised Person Re-Identification. (arXiv:2002.05046v3 [cs.CV] UPDATED)</h2>
<h3>Xiangping Zhu, Xiatian Zhu, Minxian Li, Pietro Morerio, Vittorio Murino, Shaogang Gong</h3>
<p>Existing person re-identification (re-id) methods mostly exploit a large set
of cross-camera identity labelled training data. This requires a tedious data
collection and annotation process, leading to poor scalability in practical
re-id applications. On the other hand unsupervised re-id methods do not need
identity label information, but they usually suffer from much inferior and
insufficient model performance. To overcome these fundamental limitations, we
propose a novel person re-identification paradigm based on an idea of
independent per-camera identity annotation. This eliminates the most
time-consuming and tedious inter-camera identity labelling process,
significantly reducing the amount of human annotation efforts. Consequently, it
gives rise to a more scalable and more feasible setting, which we call
Intra-Camera Supervised (ICS) person re-id, for which we formulate a Multi-tAsk
mulTi-labEl (MATE) deep learning method. Specifically, MATE is designed for
self-discovering the cross-camera identity correspondence in a per-camera
multi-task inference framework. Extensive experiments demonstrate the
cost-effectiveness superiority of our method over the alternative approaches on
three large person re-id datasets. For example, MATE yields 88.7% rank-1 score
on Market-1501 in the proposed ICS person re-id setting, significantly
outperforming unsupervised learning models and closely approaching conventional
fully supervised learning competitors.
</p>
<a href="http://arxiv.org/abs/2002.05046" target="_blank">arXiv:2002.05046</a> [<a href="http://arxiv.org/pdf/2002.05046" target="_blank">pdf</a>]

<h2>Fully Convolutional Neural Networks for Raw Eye Tracking Data Segmentation, Generation, and Reconstruction. (arXiv:2002.10905v3 [cs.CV] UPDATED)</h2>
<h3>Wolfgang Fuhl, Yao Rong, Enkelejda Kasneci</h3>
<p>In this paper, we use fully convolutional neural networks for the semantic
segmentation of eye tracking data. We also use these networks for
reconstruction, and in conjunction with a variational auto-encoder to generate
eye movement data. The first improvement of our approach is that no input
window is necessary, due to the use of fully convolutional networks and
therefore any input size can be processed directly. The second improvement is
that the used and generated data is raw eye tracking data (position X, Y and
time) without preprocessing. This is achieved by pre-initializing the filters
in the first layer and by building the input tensor along the z axis. We
evaluated our approach on three publicly available datasets and compare the
results to the state of the art.
</p>
<a href="http://arxiv.org/abs/2002.10905" target="_blank">arXiv:2002.10905</a> [<a href="http://arxiv.org/pdf/2002.10905" target="_blank">pdf</a>]

<h2>Attention-guided Chained Context Aggregation for Semantic Segmentation. (arXiv:2002.12041v2 [cs.CV] UPDATED)</h2>
<h3>Quan Tang, Fagui Liu, Tong Zhang, Jun Jiang, Yu Zhang</h3>
<p>The way features propagate in Fully Convolutional Networks is of momentous
importance to capture multi-scale contexts for obtaining precise segmentation
masks. This paper proposes a novel series-parallel hybrid paradigm called the
Chained Context Aggregation Module (CAM) to diversify feature propagation. CAM
gains features of various spatial scales through chain-connected ladder-style
information flows and fuses them in a two-stage process, namely pre-fusion and
re-fusion. The serial flow continuously increases receptive fields of output
neurons and those in parallel encode different region-based contexts. Each
information flow is a shallow encoder-decoder with appropriate down-sampling
scales to sufficiently capture contextual information. We further adopt an
attention model in CAM to guide feature re-fusion. Based on these developments,
we construct the Chained Context Aggregation Network (CANet), which employs an
asymmetric decoder to recover precise spatial details of prediction maps. We
conduct extensive experiments on six challenging datasets, including Pascal VOC
2012, Pascal Context, Cityscapes, CamVid, SUN-RGBD and GATECH. Results evidence
that CANet achieves state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2002.12041" target="_blank">arXiv:2002.12041</a> [<a href="http://arxiv.org/pdf/2002.12041" target="_blank">pdf</a>]

<h2>Advances in centerline estimation for autonomous lateral control. (arXiv:2002.12685v2 [cs.RO] UPDATED)</h2>
<h3>Paolo Cudrano, Simone Mentasti, Matteo Matteucci, Mattia Bersani, Stefano Arrigoni, Federico Cheli</h3>
<p>The ability of autonomous vehicles to maintain an accurate trajectory within
their road lane is crucial for safe operation. This requires detecting the road
lines and estimating the car relative pose within its lane. Lateral lines are
usually retrieved from camera images. Still, most of the works on line
detection are limited to image mask retrieval and do not provide a usable
representation in world coordinates. What we propose in this paper is a
complete perception pipeline based on monocular vision and able to retrieve all
the information required by a vehicle lateral control system: road lines
equation, centerline, vehicle heading and lateral displacement. We evaluate our
system by acquiring data with accurate geometric ground truth. To act as a
benchmark for further research, we make this new dataset publicly available at
this http URL
</p>
<a href="http://arxiv.org/abs/2002.12685" target="_blank">arXiv:2002.12685</a> [<a href="http://arxiv.org/pdf/2002.12685" target="_blank">pdf</a>]

<h2>Dynamic Queue-Jump Lane for Emergency Vehicles under Partially Connected Settings: A Multi-Agent Deep Reinforcement Learning Approach. (arXiv:2003.01025v3 [cs.AI] UPDATED)</h2>
<h3>Haoran Su, Kejian Shi, Joseph. Y.J. Chow, Li Jin</h3>
<p>Emergency vehicle (EMV) service is a key function of cities and is
exceedingly challenging due to urban traffic congestion. The main reason behind
EMV service delay is the lack of communication and cooperation between vehicles
blocking EMVs. In this paper, we study the improvement of EMV service under V2X
connectivity. We consider the establishment of dynamic queue jump lanes (DQJLs)
based on real-time coordination of connected vehicles in the presence of
non-connected human-driven vehicles. We develop a novel Markov decision process
formulation for the DQJL coordination strategies, which explicitly accounts for
the uncertainty of drivers' yielding pattern to approaching EMVs. Based on
pairs of neural networks representing actors and critics for agent vehicles, we
develop a multi-agent actor-critic deep reinforcement learning algorithm that
handles a varying number of vehicles and a random proportion of connected
vehicles in the traffic. Approaching the optimal coordination strategies via
indirect and direct reinforcement learning, we present two schemata to address
multi-agent reinforcement learning on this connected vehicle application. Both
approaches are validated, on a micro-simulation testbed SUMO, to establish a
DQJL fast and safely. Validation results reveal that, with DQJL coordination
strategies, it saves up to 30% time for EMVs to pass a link-level intelligent
urban roadway than the baseline scenario.
</p>
<a href="http://arxiv.org/abs/2003.01025" target="_blank">arXiv:2003.01025</a> [<a href="http://arxiv.org/pdf/2003.01025" target="_blank">pdf</a>]

<h2>Unpaired Image-to-Image Translation using Adversarial Consistency Loss. (arXiv:2003.04858v7 [cs.CV] UPDATED)</h2>
<h3>Yihao Zhao, Ruihai Wu, Hao Dong</h3>
<p>Unpaired image-to-image translation is a class of vision problems whose goal
is to find the mapping between different image domains using unpaired training
data. Cycle-consistency loss is a widely used constraint for such problems.
However, due to the strict pixel-level constraint, it cannot perform geometric
changes, remove large objects, or ignore irrelevant texture. In this paper, we
propose a novel adversarial-consistency loss for image-to-image translation.
This loss does not require the translated image to be translated back to be a
specific source image but can encourage the translated images to retain
important features of the source images and overcome the drawbacks of
cycle-consistency loss noted above. Our method achieves state-of-the-art
results on three challenging tasks: glasses removal, male-to-female
translation, and selfie-to-anime translation.
</p>
<a href="http://arxiv.org/abs/2003.04858" target="_blank">arXiv:2003.04858</a> [<a href="http://arxiv.org/pdf/2003.04858" target="_blank">pdf</a>]

<h2>PiP: Planning-informed Trajectory Prediction for Autonomous Driving. (arXiv:2003.11476v2 [cs.CV] UPDATED)</h2>
<h3>Haoran Song, Wenchao Ding, Yuxuan Chen, Shaojie Shen, Michael Yu Wang, Qifeng Chen</h3>
<p>It is critical to predict the motion of surrounding vehicles for self-driving
planning, especially in a socially compliant and flexible way. However, future
prediction is challenging due to the interaction and uncertainty in driving
behaviors. We propose planning-informed trajectory prediction (PiP) to tackle
the prediction problem in the multi-agent setting. Our approach is
differentiated from the traditional manner of prediction, which is only based
on historical information and decoupled with planning. By informing the
prediction process with the planning of ego vehicle, our method achieves the
state-of-the-art performance of multi-agent forecasting on highway datasets.
Moreover, our approach enables a novel pipeline which couples the prediction
and planning, by conditioning PiP on multiple candidate trajectories of the ego
vehicle, which is highly beneficial for autonomous driving in interactive
scenarios.
</p>
<a href="http://arxiv.org/abs/2003.11476" target="_blank">arXiv:2003.11476</a> [<a href="http://arxiv.org/pdf/2003.11476" target="_blank">pdf</a>]

<h2>Semantic Implicit Neural Scene Representations With Semi-Supervised Training. (arXiv:2003.12673v2 [cs.CV] UPDATED)</h2>
<h3>Amit Kohli, Vincent Sitzmann, Gordon Wetzstein</h3>
<p>The recent success of implicit neural scene representations has presented a
viable new method for how we capture and store 3D scenes. Unlike conventional
3D representations, such as point clouds, which explicitly store scene
properties in discrete, localized units, these implicit representations encode
a scene in the weights of a neural network which can be queried at any
coordinate to produce these same scene properties. Thus far, implicit
representations have primarily been optimized to estimate only the appearance
and/or 3D geometry information in a scene. We take the next step and
demonstrate that an existing implicit representation (SRNs) is actually
multi-modal; it can be further leveraged to perform per-point semantic
segmentation while retaining its ability to represent appearance and geometry.
To achieve this multi-modal behavior, we utilize a semi-supervised learning
strategy atop the existing pre-trained scene representation. Our method is
simple, general, and only requires a few tens of labeled 2D segmentation masks
in order to achieve dense 3D semantic segmentation. We explore two novel
applications for this semantically aware implicit neural scene representation:
3D novel view and semantic label synthesis given only a single input RGB image
or 2D label mask, as well as 3D interpolation of appearance and semantics.
</p>
<a href="http://arxiv.org/abs/2003.12673" target="_blank">arXiv:2003.12673</a> [<a href="http://arxiv.org/pdf/2003.12673" target="_blank">pdf</a>]

<h2>Intention Propagation for Multi-agent Reinforcement Learning. (arXiv:2004.08883v3 [cs.LG] UPDATED)</h2>
<h3>Chao Qu, Hui Li, Chang Liu, Junwu Xiong, James Zhang, Wei Chu, Weiqiang Wang, Yuan Qi, Le Song</h3>
<p>A hallmark of an AI agent is to mimic human beings to understand and interact
with others. In this paper, we propose a collaborative multi-agent
reinforcement learning algorithm to learn a \emph{joint} policy through the
interactions over agents. To make a joint decision over the group, each agent
makes an initial decision and tells its policy to its neighbors. Then each
agent modifies its own policy properly based on received messages and spreads
out its plan. As this intention propagation procedure goes on, we prove that it
converges to a mean-field approximation of the joint policy with the framework
of neural embedded probabilistic inference. We evaluate our algorithm on
several large scale challenging tasks and demonstrate that it outperforms
previous state-of-the-arts.
</p>
<a href="http://arxiv.org/abs/2004.08883" target="_blank">arXiv:2004.08883</a> [<a href="http://arxiv.org/pdf/2004.08883" target="_blank">pdf</a>]

<h2>Learning Deformable Image Registration from Optimization: Perspective, Modules, Bilevel Training and Beyond. (arXiv:2004.14557v2 [cs.CV] UPDATED)</h2>
<h3>Risheng Liu, Zi Li, Xin Fan, Chenying Zhao, Hao Huang, Zhongxuan Luo</h3>
<p>Conventional deformable registration methods aim at solving an optimization
model carefully designed on image pairs and their computational costs are
exceptionally high. In contrast, recent deep learning based approaches can
provide fast deformation estimation. These heuristic network architectures are
fully data-driven and thus lack explicit geometric constraints, e.g.,
topology-preserving, which are indispensable to generate plausible
deformations. We design a new deep learning based framework to optimize a
diffeomorphic model via multi-scale propagation in order to integrate
advantages and avoid limitations of these two categories of approaches.
Specifically, we introduce a generic optimization model to formulate
diffeomorphic registration and develop a series of learnable architectures to
obtain propagative updating in the coarse-to-fine feature space. Moreover, we
propose a novel bilevel self-tuned training strategy, allowing efficient search
of task-specific hyper-parameters. This training strategy increases the
flexibility to various types of data while reduces computational and human
burdens. We conduct two groups of image registration experiments on 3D volume
datasets including image-to-atlas registration on brain MRI data and
image-to-image registration on liver CT data. Extensive results demonstrate the
state-of-the-art performance of the proposed method with diffeomorphic
guarantee and extreme efficiency. We also apply our framework to challenging
multi-modal image registration, and investigate how our registration to support
the down-streaming tasks for medical image analysis including multi-modal
fusion and image segmentation.
</p>
<a href="http://arxiv.org/abs/2004.14557" target="_blank">arXiv:2004.14557</a> [<a href="http://arxiv.org/pdf/2004.14557" target="_blank">pdf</a>]

<h2>Visualizing Deep Learning-based Radio Modulation Classifier. (arXiv:2005.02175v2 [cs.LG] UPDATED)</h2>
<h3>Liang Huang (Member, IEEE), You Zhang, Weijian Pan, Jinyin Chen, Li Ping Qian (Senior Member, IEEE), Yuan Wu (Senior Member, IEEE)</h3>
<p>Deep learning has recently been successfully applied in automatic modulation
classification by extracting and classifying radio features in an end-to-end
way. However, deep learning-based radio modulation classifiers are lack of
interpretability, and there is little explanation or visibility into what kinds
of radio features are extracted and chosen for classification. In this paper,
we visualize different deep learning-based radio modulation classifiers by
introducing a class activation vector. Specifically, both convolutional neural
networks (CNN) based classifier and long short-term memory (LSTM) based
classifier are separately studied, and their extracted radio features are
visualized. Extensive numerical results show both the CNN-based classifier and
LSTM-based classifier extract similar radio features relating to modulation
reference points. In particular, for the LSTM-based classifier, its obtained
radio features are similar to the knowledge of human experts. Our numerical
results indicate the radio features extracted by deep learning-based
classifiers greatly depend on the contents carried by radio signals, and a
short radio sample may lead to misclassification.
</p>
<a href="http://arxiv.org/abs/2005.02175" target="_blank">arXiv:2005.02175</a> [<a href="http://arxiv.org/pdf/2005.02175" target="_blank">pdf</a>]

<h2>Machine Learning on Graphs: A Model and Comprehensive Taxonomy. (arXiv:2005.03675v2 [cs.LG] UPDATED)</h2>
<h3>Ines Chami, Sami Abu-El-Haija, Bryan Perozzi, Christopher R&#xe9;, Kevin Murphy</h3>
<p>There has been a surge of recent interest in learning representations for
graph-structured data. Graph representation learning methods have generally
fallen into three main categories, based on the availability of labeled data.
The first, network embedding (such as shallow graph embedding or graph
auto-encoders), focuses on learning unsupervised representations of relational
structure. The second, graph regularized neural networks, leverages graphs to
augment neural network losses with a regularization objective for
semi-supervised learning. The third, graph neural networks, aims to learn
differentiable functions over discrete topologies with arbitrary structure.
However, despite the popularity of these areas there has been surprisingly
little work on unifying the three paradigms. Here, we aim to bridge the gap
between graph neural networks, network embedding and graph regularization
models. We propose a comprehensive taxonomy of representation learning methods
for graph-structured data, aiming to unify several disparate bodies of work.
Specifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which
generalizes popular algorithms for semi-supervised learning on graphs (e.g.
GraphSage, Graph Convolutional Networks, Graph Attention Networks), and
unsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc)
into a single consistent approach. To illustrate the generality of this
approach, we fit over thirty existing methods into this framework. We believe
that this unifying view both provides a solid foundation for understanding the
intuition behind these methods, and enables future research in the area.
</p>
<a href="http://arxiv.org/abs/2005.03675" target="_blank">arXiv:2005.03675</a> [<a href="http://arxiv.org/pdf/2005.03675" target="_blank">pdf</a>]

<h2>A Smooth Representation of Belief over SO(3) for Deep Rotation Learning with Uncertainty. (arXiv:2006.01031v4 [cs.CV] UPDATED)</h2>
<h3>Valentin Peretroukhin, Matthew Giamou, David M. Rosen, W. Nicholas Greene, Nicholas Roy, Jonathan Kelly</h3>
<p>Accurate rotation estimation is at the heart of robot perception tasks such
as visual odometry and object pose estimation. Deep neural networks have
provided a new way to perform these tasks, and the choice of rotation
representation is an important part of network design. In this work, we present
a novel symmetric matrix representation of the 3D rotation group, SO(3), with
two important properties that make it particularly suitable for learned models:
(1) it satisfies a smoothness property that improves convergence and
generalization when regressing large rotation targets, and (2) it encodes a
symmetric Bingham belief over the space of unit quaternions, permitting the
training of uncertainty-aware models. We empirically validate the benefits of
our formulation by training deep neural rotation regressors on two data
modalities. First, we use synthetic point-cloud data to show that our
representation leads to superior predictive accuracy over existing
representations for arbitrary rotation targets. Second, we use image data
collected onboard ground and aerial vehicles to demonstrate that our
representation is amenable to an effective out-of-distribution (OOD) rejection
technique that significantly improves the robustness of rotation estimates to
unseen environmental effects and corrupted input images, without requiring the
use of an explicit likelihood loss, stochastic sampling, or an auxiliary
classifier. This capability is key for safety-critical applications where
detecting novel inputs can prevent catastrophic failure of learned models.
</p>
<a href="http://arxiv.org/abs/2006.01031" target="_blank">arXiv:2006.01031</a> [<a href="http://arxiv.org/pdf/2006.01031" target="_blank">pdf</a>]

<h2>A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions. (arXiv:2006.02903v2 [cs.LG] UPDATED)</h2>
<h3>Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Xiaojiang Chen, Xin Wang</h3>
<p>Deep learning has made breakthroughs and substantial in many fields due to
its powerful automatic representation capabilities. It has been proven that
neural architecture design is crucial to the feature representation of data and
the final performance. However, the design of the neural architecture heavily
relies on the researchers' prior knowledge and experience. And due to the
limitations of human' inherent knowledge, it is difficult for people to jump
out of their original thinking paradigm and design an optimal model. Therefore,
an intuitive idea would be to reduce human intervention as much as possible and
let the algorithm automatically design the neural architecture. Neural
Architecture Search (NAS) is just such a revolutionary algorithm, and the
related research work is complicated and rich. Therefore, a comprehensive and
systematic survey on the NAS is essential. Previously related surveys have
begun to classify existing work mainly based on the key components of NAS:
search space, search strategy, and evaluation strategy. While this
classification method is more intuitive, it is difficult for readers to grasp
the challenges and the landmark work involved. Therefore, in this survey, we
provide a new perspective: beginning with an overview of the characteristics of
the earliest NAS algorithms, summarizing the problems in these early NAS
algorithms, and then providing solutions for subsequent related research work.
Besides, we conduct a detailed and comprehensive analysis, comparison, and
summary of these works. Finally, we provide some possible future research
directions.
</p>
<a href="http://arxiv.org/abs/2006.02903" target="_blank">arXiv:2006.02903</a> [<a href="http://arxiv.org/pdf/2006.02903" target="_blank">pdf</a>]

<h2>PIVEN: A Deep Neural Network for Prediction Intervals with Specific Value Prediction. (arXiv:2006.05139v2 [cs.LG] UPDATED)</h2>
<h3>Eli Simhayev, Gilad Katz, Lior Rokach</h3>
<p>Improving the robustness of neural nets in regression tasks is key to their
application in multiple domains. Deep learning-based approaches aim to achieve
this goal either by improving their prediction of specific values (i.e., point
prediction), or by producing prediction intervals (PIs) that quantify
uncertainty. We present PIVEN, a deep neural network for producing both a PI
and a prediction of specific values. Unlike previous studies, PIVEN makes no
assumptions regarding data distribution inside the PI, making its point
prediction more effective for various real-world problems. Benchmark
experiments show that our approach produces tighter uncertainty bounds than the
current state-of-the-art approach for producing PIs, while maintaining
comparable performance to the state-of-the-art approach for specific
value-prediction. Additional evaluation on large image datasets further support
our conclusions.
</p>
<a href="http://arxiv.org/abs/2006.05139" target="_blank">arXiv:2006.05139</a> [<a href="http://arxiv.org/pdf/2006.05139" target="_blank">pdf</a>]

<h2>Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning. (arXiv:2006.06119v5 [cs.CV] UPDATED)</h2>
<h3>Ruozi Huang, Huang Hu, Wei Wu, Kei Sawada, Mi Zhang, Daxin Jiang</h3>
<p>Dancing to music is one of human's innate abilities since ancient times. In
machine learning research, however, synthesizing dance movements from music is
a challenging problem. Recently, researchers synthesize human motion sequences
through autoregressive models like recurrent neural network (RNN). Such an
approach often generates short sequences due to an accumulation of prediction
errors that are fed back into the neural network. This problem becomes even
more severe in the long motion sequence generation. Besides, the consistency
between dance and music in terms of style, rhythm and beat is yet to be taken
into account during modeling. In this paper, we formalize the music-driven
dance generation as a sequence-to-sequence learning problem and devise a novel
seq2seq architecture to efficiently process long sequences of music features
and capture the fine-grained correspondence between music and dance.
Furthermore, we propose a novel curriculum learning strategy to alleviate error
accumulation of autoregressive models in long motion sequence generation, which
gently changes the training process from a fully guided teacher-forcing scheme
using the previous ground-truth movements, towards a less guided autoregressive
scheme mostly using the generated movements instead. Extensive experiments show
that our approach significantly outperforms the existing state-of-the-arts on
automatic metrics and human evaluation. We also make a demo video in the
supplementary material to demonstrate the superior performance of our proposed
approach.
</p>
<a href="http://arxiv.org/abs/2006.06119" target="_blank">arXiv:2006.06119</a> [<a href="http://arxiv.org/pdf/2006.06119" target="_blank">pdf</a>]

<h2>Interpretable, similarity-driven multi-view embeddings from high-dimensional biomedical data. (arXiv:2006.06545v2 [stat.ML] UPDATED)</h2>
<h3>Brian B. Avants, Nicholas J. Tustison, James R. Stone</h3>
<p>Similarity-driven multi-view linear reconstruction (SiMLR) is an algorithm
that exploits inter-modality relationships to transform large scientific
datasets into smaller, more well-powered and interpretable low-dimensional
spaces. SiMLR contributes a novel objective function for identifying joint
signal, regularization based on sparse matrices representing prior
within-modality relationships and an implementation that permits application to
joint reduction of large data matrices, each of which may have millions of
entries. We demonstrate that SiMLR outperforms closely related methods on
supervised learning problems in simulation data, a multi-omics cancer survival
prediction dataset and multiple modality neuroimaging datasets. Taken together,
this collection of results shows that SiMLR may be applied with default
parameters to joint signal estimation from disparate modalities and may yield
practically useful results in a variety of application domains.
</p>
<a href="http://arxiv.org/abs/2006.06545" target="_blank">arXiv:2006.06545</a> [<a href="http://arxiv.org/pdf/2006.06545" target="_blank">pdf</a>]

<h2>Multi Layer Neural Networks as Replacement for Pooling Operations. (arXiv:2006.06969v4 [cs.CV] UPDATED)</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>Pooling operations, which can be calculated at low cost and serve as a linear
or nonlinear transfer function for data reduction, are found in almost every
modern neural network. Countless modern approaches have already tackled
replacing the common maximum value selection and mean value operations, not to
mention providing a function that allows different functions to be selected
through changing parameters. Additional neural networks are used to estimate
the parameters of these pooling functions.Consequently, pooling layers may
require supplementary parameters to increase the complexity of the whole model.
In this work, we show that one perceptron can already be used effectively as a
pooling operation without increasing the complexity of the model. This kind of
pooling allows for the integration of multi-layer neural networks directly into
a model as a pooling operation by restructuring the data and, as a result,
learnin complex pooling operations. We compare our approach to tensor
convolution with strides as a pooling operation and show that our approach is
both effective and reduces complexity. The restructuring of the data in
combination with multiple perceptrons allows for our approach to be used for
upscaling, which can then be utilized for transposed convolutions in semantic
segmentation.
</p>
<a href="http://arxiv.org/abs/2006.06969" target="_blank">arXiv:2006.06969</a> [<a href="http://arxiv.org/pdf/2006.06969" target="_blank">pdf</a>]

<h2>D-square-B: Deep Distribution Bound for Natural-looking Adversarial Attack. (arXiv:2006.07258v2 [cs.LG] UPDATED)</h2>
<h3>Qiuling Xu, Guanhong Tao, Xiangyu Zhang</h3>
<p>We propose a novel technique that can generate natural-looking adversarial
examples by bounding the variations induced for internal activation values in
some deep layer(s), through a distribution quantile bound and a polynomial
barrier loss function. By bounding model internals instead of individual
pixels, our attack admits perturbations closely coupled with the existing
features of the original input, allowing the generated examples to be
natural-looking while having diverse and often substantial pixel distances from
the original input. Enforcing per-neuron distribution quantile bounds allows
addressing the non-uniformity of internal activation values. Our evaluation on
ImageNet and five different model architecture demonstrates that our attack is
quite effective. Compared to the state-of-the-art pixel space attack, semantic
attack, and feature space attack, our attack can achieve the same attack
success/confidence level while having much more natural-looking adversarial
perturbations. These perturbations piggy-back on existing local features and do
not have any fixed pixel bounds.
</p>
<a href="http://arxiv.org/abs/2006.07258" target="_blank">arXiv:2006.07258</a> [<a href="http://arxiv.org/pdf/2006.07258" target="_blank">pdf</a>]

<h2>AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights. (arXiv:2006.08217v3 [cs.LG] UPDATED)</h2>
<h3>Byeongho Heo, Sanghyuk Chun, Seong Joon Oh, Dongyoon Han, Sangdoo Yun, Gyuwan Kim, Youngjung Uh, Jung-Woo Ha</h3>
<p>Normalization techniques are a boon for modern deep learning. They let
weights converge more quickly with often better generalization performances. It
has been argued that the normalization-induced scale invariance among the
weights provides an advantageous ground for gradient descent (GD) optimizers:
the effective step sizes are automatically reduced over time, stabilizing the
overall training procedure. It is often overlooked, however, that the
additional introduction of momentum in GD optimizers results in a far more
rapid reduction in effective step sizes for scale-invariant weights, a
phenomenon that has not yet been studied and may have caused unwanted side
effects in the current practice. This is a crucial issue because arguably the
vast majority of modern deep neural networks consist of (1) momentum-based GD
(e.g. SGD or Adam) and (2) scale-invariant parameters. In this paper, we verify
that the widely-adopted combination of the two ingredients lead to the
premature decay of effective step sizes and sub-optimal model performances. We
propose a simple and effective remedy, SGDP and AdamP: get rid of the radial
component, or the norm-increasing direction, at each optimizer step. Because of
the scale invariance, this modification only alters the effective step sizes
without changing the effective update directions, thus enjoying the original
convergence properties of GD optimizers. Given the ubiquity of momentum GD and
scale invariance in machine learning, we have evaluated our methods against the
baselines on 13 benchmarks. They range from vision tasks like classification
(e.g. ImageNet), retrieval (e.g. CUB and SOP), and detection (e.g. COCO) to
language modelling (e.g. WikiText) and audio classification (e.g. DCASE) tasks.
We verify that our solution brings about uniform gains in those benchmarks.
Source code is available at https://github.com/clovaai/AdamP.
</p>
<a href="http://arxiv.org/abs/2006.08217" target="_blank">arXiv:2006.08217</a> [<a href="http://arxiv.org/pdf/2006.08217" target="_blank">pdf</a>]

<h2>Mitigating Gender Bias in Captioning Systems. (arXiv:2006.08315v3 [cs.CV] UPDATED)</h2>
<h3>Ruixiang Tang, Mengnan Du, Yuening Li, Zirui Liu, Xia Hu</h3>
<p>Image captioning has made substantial progress with huge supporting image
collections sourced from the web. However, recent studies have pointed out that
captioning datasets, such as COCO, contain gender bias found in web corpora. As
a result, learning models could heavily rely on the learned priors and image
context for gender identification, leading to incorrect or even offensive
errors. To encourage models to learn correct gender features, we reorganize the
COCO dataset and present two new splits COCO-GB V1 and V2 datasets where the
train and test sets have different gender-context joint distribution. Models
relying on contextual cues will suffer from huge gender prediction errors on
the anti-stereotypical test data. Benchmarking experiments reveal that most
captioning models learn gender bias, leading to high gender prediction errors,
especially for women. To alleviate the unwanted bias, we propose a new Guided
Attention Image Captioning model (GAIC) which provides self-guidance on visual
attention to encourage the model to capture correct gender visual evidence.
Experimental results validate that GAIC can significantly reduce gender
prediction errors with a competitive caption quality. Our codes and the
designed benchmark datasets are available at
https://github.com/CaptionGenderBias2020.
</p>
<a href="http://arxiv.org/abs/2006.08315" target="_blank">arXiv:2006.08315</a> [<a href="http://arxiv.org/pdf/2006.08315" target="_blank">pdf</a>]

<h2>Uncertainty in Gradient Boosting via Ensembles. (arXiv:2006.10562v3 [cs.LG] UPDATED)</h2>
<h3>Andrey Malinin, Liudmila Prokhorenkova, Aleksei Ustimenko</h3>
<p>For many practical, high-risk applications, it is essential to quantify
uncertainty in a model's predictions to avoid costly mistakes. While predictive
uncertainty is widely studied for neural networks, the topic seems to be
under-explored for models based on gradient boosting. However, gradient
boosting often achieves state-of-the-art results on tabular data. This work
examines a probabilistic ensemble-based framework for deriving uncertainty
estimates in the predictions of gradient boosting classification and regression
models. We conducted experiments on a range of synthetic and real datasets and
investigated the applicability of ensemble approaches to gradient boosting
models that are themselves ensembles of decision trees. Our analysis shows that
ensembles of gradient boosting models successfully detect anomaly inputs while
having limited ability to improve the predicted total uncertainty. Importantly,
we also propose a concept of a \emph{virtual} ensemble to get the benefits of
an ensemble via only \emph{one} gradient boosting model, which significantly
reduces complexity.
</p>
<a href="http://arxiv.org/abs/2006.10562" target="_blank">arXiv:2006.10562</a> [<a href="http://arxiv.org/pdf/2006.10562" target="_blank">pdf</a>]

<h2>Understanding Recurrent Neural Networks Using Nonequilibrium Response Theory. (arXiv:2006.11052v2 [stat.ML] UPDATED)</h2>
<h3>Soon Hoe Lim</h3>
<p>Recurrent neural networks (RNNs) are brain-inspired models widely used in
machine learning for analyzing sequential data. The present work is a
contribution towards a deeper understanding of how RNNs process input signals
using the response theory from nonequilibrium statistical mechanics. For a
class of continuous-time stochastic RNNs (SRNNs) driven by an input signal, we
derive a Volterra type series representation for their output. This
representation is interpretable and disentangles the input signal from the SRNN
architecture. The kernels of the series are certain recursively defined
correlation functions with respect to the unperturbed dynamics that completely
determine the output. Exploiting connections of this representation and its
implications to rough paths theory, we identify a universal feature -- the
response feature, which turns out to be the signature of tensor product of the
input signal and a natural support basis. In particular, we show that SRNNs,
with only the weights in the readout layer optimized and the weights in the
hidden layer kept fixed and not optimized, can be viewed as kernel machines
operating on a reproducing kernel Hilbert space associated with the response
feature.
</p>
<a href="http://arxiv.org/abs/2006.11052" target="_blank">arXiv:2006.11052</a> [<a href="http://arxiv.org/pdf/2006.11052" target="_blank">pdf</a>]

<h2>Langevin Dynamics for Adaptive Inverse Reinforcement Learning of Stochastic Gradient Algorithms. (arXiv:2006.11674v2 [cs.LG] UPDATED)</h2>
<h3>Vikram Krishnamurthy, George Yin</h3>
<p>Inverse reinforcement learning (IRL) aims to estimate the reward function of
optimizing agents by observing their response (estimates or actions). This
paper considers IRL when noisy estimates of the gradient of a reward function
generated by multiple stochastic gradient agents are observed. We present a
generalized Langevin dynamics algorithm to estimate the reward function
$R(\theta)$; specifically, the resulting Langevin algorithm asymptotically
generates samples from the distribution proportional to $\exp(R(\theta))$. The
proposed IRL algorithms use kernel-based passive learning schemes. We also
construct multi-kernel passive Langevin algorithms for IRL which are suitable
for high dimensional data. The performance of the proposed IRL algorithms are
illustrated on examples in adaptive Bayesian learning, logistic regression
(high dimensional problem) and constrained Markov decision processes. We prove
weak convergence of the proposed IRL algorithms using martingale averaging
methods. We also analyze the tracking performance of the IRL algorithms in
non-stationary environments where the utility function $R(\theta)$ jump changes
over time as a slow Markov chain.
</p>
<a href="http://arxiv.org/abs/2006.11674" target="_blank">arXiv:2006.11674</a> [<a href="http://arxiv.org/pdf/2006.11674" target="_blank">pdf</a>]

<h2>The Depth-to-Width Interplay in Self-Attention. (arXiv:2006.12467v3 [cs.LG] UPDATED)</h2>
<h3>Yoav Levine, Noam Wies, Or Sharir, Hofit Bata, Amnon Shashua</h3>
<p>Self-attention architectures, which are rapidly pushing the frontier in
natural language processing, demonstrate a surprising depth-inefficient
behavior: previous works indicate that increasing the internal representation
(network width) is just as useful as increasing the number of self-attention
layers (network depth). We theoretically predict a width-dependent transition
between depth-efficiency and depth-inefficiency in self-attention. We conduct
systematic empirical ablations on networks of depths 6 to 48 that clearly
reveal the theoretically predicted behaviors, and provide explicit quantitative
suggestions regarding the optimal depth-to-width allocation for a given
self-attention network size. The race towards beyond 1-Trillion parameter
language models renders informed guidelines for increasing self-attention depth
and width in tandem an essential ingredient. Our guidelines elucidate the
depth-to-width trade-off in self-attention networks of sizes up to the scale of
GPT3 (which we project to be too deep for its size), and beyond, marking an
unprecedented width of 30K as optimal for a 1-Trillion parameter network.
</p>
<a href="http://arxiv.org/abs/2006.12467" target="_blank">arXiv:2006.12467</a> [<a href="http://arxiv.org/pdf/2006.12467" target="_blank">pdf</a>]

<h2>RP2K: A Large-Scale Retail Product Dataset for Fine-Grained Image Classification. (arXiv:2006.12634v5 [cs.CV] UPDATED)</h2>
<h3>Jingtian Peng, Chang Xiao, Yifan Li</h3>
<p>We introduce RP2K, a new large-scale retail product dataset for fine-grained
image classification. Unlike previous datasets focusing on relatively few
products, we collect more than 500,000 images of retail products on shelves
belonging to 2000 different products. Our dataset aims to advance the research
in retail object recognition, which has massive applications such as automatic
shelf auditing and image-based product information retrieval. Our dataset
enjoys following properties: (1) It is by far the largest scale dataset in
terms of product categories. (2) All images are captured manually in physical
retail stores with natural lightings, matching the scenario of real
applications. (3) We provide rich annotations to each object, including the
sizes, shapes and flavors/scents. We believe our dataset could benefit both
computer vision research and retail industry. Our dataset is publicly available
at https://www.pinlandata.com/rp2k_dataset.
</p>
<a href="http://arxiv.org/abs/2006.12634" target="_blank">arXiv:2006.12634</a> [<a href="http://arxiv.org/pdf/2006.12634" target="_blank">pdf</a>]

<h2>Differentiable Segmentation of Sequences. (arXiv:2006.13105v2 [cs.LG] UPDATED)</h2>
<h3>Erik Scharw&#xe4;chter, Jonathan Lennartz, Emmanuel M&#xfc;ller</h3>
<p>Segmented models are widely used to describe non-stationary sequential data
with discrete change points. Their estimation usually requires solving a mixed
discrete-continuous optimization problem, where the segmentation is the
discrete part and all other model parameters are continuous. A number of
estimation algorithms have been developed that are highly specialized for their
specific model assumptions. The dependence on non-standard algorithms makes it
hard to integrate segmented models in state-of-the-art deep learning
architectures that critically depend on gradient-based optimization techniques.
In this work, we formulate a relaxed variant of segmented models that enables
joint estimation of all model parameters, including the segmentation, with
gradient descent. We build on recent advances in learning continuous warping
functions and propose a novel family of warping functions based on the
two-sided power (TSP) distribution. TSP-based warping functions are
differentiable, have simple closed-form expressions, and can represent
segmentation functions exactly. Our formulation includes the important class of
segmented generalized linear models as a special case, which makes it highly
versatile. We use our approach to model the spread of COVID-19 with Poisson
regression, apply it on a change point detection task, and learn classification
models with concept drift. The experiments show that our approach effectively
learns all these tasks with standard algorithms for gradient descent.
</p>
<a href="http://arxiv.org/abs/2006.13105" target="_blank">arXiv:2006.13105</a> [<a href="http://arxiv.org/pdf/2006.13105" target="_blank">pdf</a>]

<h2>Calibrated Adversarial Refinement for Stochastic Semantic Segmentation. (arXiv:2006.13144v2 [cs.CV] UPDATED)</h2>
<h3>Elias Kassapis, Georgi Dikov, Deepak K. Gupta, Cedric Nugteren</h3>
<p>Ambiguities in images or unsystematic annotation can lead to multiple valid
solutions in semantic segmentation. To learn a distribution over predictions,
recent work has explored the use of probabilistic networks. However, these do
not necessarily capture the empirical distribution accurately. In this work, we
aim to learn a multimodal predictive distribution, where the empirical
frequency of the sampled predictions closely reflects that of the corresponding
labels in the training set. To this end, we propose a novel two-stage, cascaded
strategy for calibrated adversarial refinement. In the first stage, we
explicitly model the data with a categorical likelihood. In the second, we
train an adversarial network to sample from it an arbitrary number of coherent
predictions. The model can be used independently or integrated into any
black-box segmentation framework to facilitate learning of calibrated
stochastic mappings. We demonstrate the utility and versatility of the approach
by attaining state-of-the-art results on the multigrader LIDC dataset and a
modified Cityscapes dataset. In addition, we use a toy regression dataset to
show that our framework is not confined to semantic segmentation, and the core
design can be adapted to other tasks requiring learning a calibrated predictive
distribution.
</p>
<a href="http://arxiv.org/abs/2006.13144" target="_blank">arXiv:2006.13144</a> [<a href="http://arxiv.org/pdf/2006.13144" target="_blank">pdf</a>]

<h2>Graph Convolutional Network for Recommendation with Low-pass Collaborative Filters. (arXiv:2006.15516v3 [cs.LG] UPDATED)</h2>
<h3>Wenhui Yu, Zheng Qin</h3>
<p>\textbf{G}raph \textbf{C}onvolutional \textbf{N}etwork (\textbf{GCN}) is
widely used in graph data learning tasks such as recommendation. However, when
facing a large graph, the graph convolution is very computationally expensive
thus is simplified in all existing GCNs, yet is seriously impaired due to the
oversimplification. To address this gap, we leverage the \textit{original graph
convolution} in GCN and propose a \textbf{L}ow-pass \textbf{C}ollaborative
\textbf{F}ilter (\textbf{LCF}) to make it applicable to the large graph. LCF is
designed to remove the noise caused by exposure and quantization in the
observed data, and it also reduces the complexity of graph convolution in an
unscathed way. Experiments show that LCF improves the effectiveness and
efficiency of graph convolution and our GCN outperforms existing GCNs
significantly. Codes are available on \url{https://github.com/Wenhui-Yu/LCFN}.
</p>
<a href="http://arxiv.org/abs/2006.15516" target="_blank">arXiv:2006.15516</a> [<a href="http://arxiv.org/pdf/2006.15516" target="_blank">pdf</a>]

<h2>See, Hear, Explore: Curiosity via Audio-Visual Association. (arXiv:2007.03669v2 [cs.LG] UPDATED)</h2>
<h3>Victoria Dean, Shubham Tulsiani, Abhinav Gupta</h3>
<p>Exploration is one of the core challenges in reinforcement learning. A common
formulation of curiosity-driven exploration uses the difference between the
real future and the future predicted by a learned model. However, predicting
the future is an inherently difficult task which can be ill-posed in the face
of stochasticity. In this paper, we introduce an alternative form of curiosity
that rewards novel associations between different senses. Our approach exploits
multiple modalities to provide a stronger signal for more efficient
exploration. Our method is inspired by the fact that, for humans, both sight
and sound play a critical role in exploration. We present results on several
Atari environments and Habitat (a photorealistic navigation simulator), showing
the benefits of using an audio-visual association model for intrinsically
guiding learning agents in the absence of external rewards. For videos and
code, see https://vdean.github.io/audio-curiosity.html.
</p>
<a href="http://arxiv.org/abs/2007.03669" target="_blank">arXiv:2007.03669</a> [<a href="http://arxiv.org/pdf/2007.03669" target="_blank">pdf</a>]

<h2>Personalized Cross-Silo Federated Learning on Non-IID Data. (arXiv:2007.03797v4 [cs.LG] UPDATED)</h2>
<h3>Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei, Yong Zhang</h3>
<p>Non-IID data present a tough challenge for federated learning. In this paper,
we explore a novel idea of facilitating pairwise collaborations between clients
with similar data. We propose FedAMP, a new method employing federated
attentive message passing to facilitate similar clients to collaborate more. We
establish the convergence of FedAMP for both convex and non-convex models, and
propose a heuristic method to further improve the performance of FedAMP when
clients adopt deep neural networks as personalized models. Our extensive
experiments on benchmark data sets demonstrate the superior performance of the
proposed methods.
</p>
<a href="http://arxiv.org/abs/2007.03797" target="_blank">arXiv:2007.03797</a> [<a href="http://arxiv.org/pdf/2007.03797" target="_blank">pdf</a>]

<h2>Lossless Compression of Structured Convolutional Models via Lifting. (arXiv:2007.06567v2 [cs.LG] UPDATED)</h2>
<h3>Gustav Sourek, Filip Zelezny, Ondrej Kuzelka</h3>
<p>Lifting is an efficient technique to scale up graphical models generalized to
relational domains by exploiting the underlying symmetries. Concurrently,
neural models are continuously expanding from grid-like tensor data into
structured representations, such as various attributed graphs and relational
databases. To address the irregular structure of the data, the models typically
extrapolate on the idea of convolution, effectively introducing parameter
sharing in their, dynamically unfolded, computation graphs. The computation
graphs themselves then reflect the symmetries of the underlying data, similarly
to the lifted graphical models. Inspired by lifting, we introduce a simple and
efficient technique to detect the symmetries and compress the neural models
without loss of any information. We demonstrate through experiments that such
compression can lead to significant speedups of structured convolutional
models, such as various Graph Neural Networks, across various tasks, such as
molecule classification and knowledge-base completion.
</p>
<a href="http://arxiv.org/abs/2007.06567" target="_blank">arXiv:2007.06567</a> [<a href="http://arxiv.org/pdf/2007.06567" target="_blank">pdf</a>]

<h2>Explicit Regularisation in Gaussian Noise Injections. (arXiv:2007.07368v5 [stat.ML] UPDATED)</h2>
<h3>Alexander Camuto, Matthew Willetts, Umut &#x15e;im&#x15f;ekli, Stephen Roberts, Chris Holmes</h3>
<p>We study the regularisation induced in neural networks by Gaussian noise
injections (GNIs). Though such injections have been extensively studied when
applied to data, there have been few studies on understanding the regularising
effect they induce when applied to network activations. Here we derive the
explicit regulariser of GNIs, obtained by marginalising out the injected noise,
and show that it penalises functions with high-frequency components in the
Fourier domain; particularly in layers closer to a neural network's output. We
show analytically and empirically that such regularisation produces calibrated
classifiers with large classification margins.
</p>
<a href="http://arxiv.org/abs/2007.07368" target="_blank">arXiv:2007.07368</a> [<a href="http://arxiv.org/pdf/2007.07368" target="_blank">pdf</a>]

<h2>Concept Learners for Few-Shot Learning. (arXiv:2007.07375v2 [cs.LG] UPDATED)</h2>
<h3>Kaidi Cao, Maria Brbic, Jure Leskovec</h3>
<p>Developing algorithms that are able to generalize to a novel task given only
a few labeled examples represents a fundamental challenge in closing the gap
between machine- and human-level performance. The core of human cognition lies
in the structured, reusable concepts that help us to rapidly adapt to new tasks
and provide reasoning behind our decisions. However, existing meta-learning
methods learn complex representations across prior labeled tasks without
imposing any structure on the learned representations. Here we propose COMET, a
meta-learning method that improves generalization ability by learning to learn
along human-interpretable concept dimensions. Instead of learning a joint
unstructured metric space, COMET learns mappings of high-level concepts into
semi-structured metric spaces, and effectively combines the outputs of
independent concept learners. We evaluate our model on few-shot tasks from
diverse domains, including fine-grained image classification, document
categorization and cell type annotation on a novel dataset from a biological
domain developed in our work. COMET significantly outperforms strong
meta-learning baselines, achieving 6-15% relative improvement on the most
challenging 1-shot learning tasks, while unlike existing methods providing
interpretations behind the model's predictions.
</p>
<a href="http://arxiv.org/abs/2007.07375" target="_blank">arXiv:2007.07375</a> [<a href="http://arxiv.org/pdf/2007.07375" target="_blank">pdf</a>]

<h2>Dealing with Nuisance Parameters using Machine Learning in High Energy Physics: a Review. (arXiv:2007.09121v2 [stat.ML] UPDATED)</h2>
<h3>Tommaso Dorigo, Pablo de Castro</h3>
<p>In this work we discuss the impact of nuisance parameters on the
effectiveness of machine learning in high-energy physics problems, and provide
a review of techniques that allow to include their effect and reduce their
impact in the search for optimal selection criteria and variable
transformations. The introduction of nuisance parameters complicates the
supervised learning task and its correspondence with the data analysis goal,
due to their contribution degrading the model performances in real data, and
the necessary addition of uncertainties in the resulting statistical inference.
The approaches discussed include nuisance-parameterized models, modified or
adversary losses, semi-supervised learning approaches, and inference-aware
techniques.
</p>
<a href="http://arxiv.org/abs/2007.09121" target="_blank">arXiv:2007.09121</a> [<a href="http://arxiv.org/pdf/2007.09121" target="_blank">pdf</a>]

<h2>Regularizing Deep Networks with Semantic Data Augmentation. (arXiv:2007.10538v3 [cs.CV] UPDATED)</h2>
<h3>Yulin Wang, Gao Huang, Shiji Song, Xuran Pan, Yitong Xia, Cheng Wu</h3>
<p>Data augmentation is widely known as a simple yet surprisingly effective
technique for regularizing deep networks. Conventional data augmentation
schemes, e.g., flipping, translation or rotation, are low-level,
data-independent and class-agnostic operations, leading to limited diversity
for augmented samples. To this end, we propose a novel semantic data
augmentation algorithm to complement traditional approaches. The proposed
method is inspired by the intriguing property that deep networks are effective
in learning linearized features, i.e., certain directions in the deep feature
space correspond to meaningful semantic transformations, e.g., changing the
background or view angle of an object. Based on this observation, translating
training samples along many such directions in the feature space can
effectively augment the dataset for more diversity. To implement this idea, we
first introduce a sampling based method to obtain semantically meaningful
directions efficiently. Then, an upper bound of the expected cross-entropy (CE)
loss on the augmented training set is derived by assuming the number of
augmented samples goes to infinity, yielding a highly efficient algorithm. In
fact, we show that the proposed implicit semantic data augmentation (ISDA)
algorithm amounts to minimizing a novel robust CE loss, which adds minimal
extra computational cost to a normal training procedure. In addition to
supervised learning, ISDA can be applied to semi-supervised learning tasks
under the consistency regularization framework, where ISDA amounts to
minimizing the upper bound of the expected KL-divergence between the augmented
features and the original features. Although being simple, ISDA consistently
improves the generalization performance of popular deep models (e.g., ResNets
and DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN,
ImageNet, and Cityscapes.
</p>
<a href="http://arxiv.org/abs/2007.10538" target="_blank">arXiv:2007.10538</a> [<a href="http://arxiv.org/pdf/2007.10538" target="_blank">pdf</a>]

<h2>Accounting for Unobserved Confounding in Domain Generalization. (arXiv:2007.10653v3 [stat.ML] UPDATED)</h2>
<h3>Alexis Bellot, Mihaela van der Schaar</h3>
<p>The ability to extrapolate, or generalize, from observed to new related
environments is central to any form of reliable machine learning, yet most
methods fail when moving beyond $i.i.d$ data. In some cases, the reason lies in
a misappreciation of the causal structure that governs the data, and in
particular as a consequence of the influence of unobserved confounders that
drive changes in observed distributions and distort correlations. In this
paper, we argue for defining generalization with respect to a broader class of
distribution shifts (defined as arising from interventions in the underlying
causal model), including changes in observed, unobserved and target variable
distributions. We propose a new robust learning principle that may be paired
with any gradient-based learning algorithm. This learning principle has
explicit generalization guarantees, and relates robustness with certain
invariances in the causal model, clarifying why, in some cases, test
performance lags training performance. We demonstrate the empirical performance
of our approach on healthcare data from different modalities, including image
and speech data.
</p>
<a href="http://arxiv.org/abs/2007.10653" target="_blank">arXiv:2007.10653</a> [<a href="http://arxiv.org/pdf/2007.10653" target="_blank">pdf</a>]

<h2>Solving Linear Inverse Problems Using the Prior Implicit in a Denoiser. (arXiv:2007.13640v2 [cs.CV] UPDATED)</h2>
<h3>Zahra Kadkhodaie, Eero P. Simoncelli</h3>
<p>Prior probability models are a fundamental component of many image processing
problems, but density estimation is notoriously difficult for high-dimensional
signals such as photographic images. Deep neural networks have provided
state-of-the-art solutions for problems such as denoising, which implicitly
rely on a prior probability model of natural images. Here, we develop a robust
and general methodology for making use of this implicit prior. We rely on a
little-known statistical result due to Miyasawa (1961), who showed that the
least-squares solution for removing additive Gaussian noise can be written
directly in terms of the gradient of the log of the noisy signal density. We
use this fact to develop a stochastic coarse-to-fine gradient ascent procedure
for drawing high-probability samples from the implicit prior embedded within a
CNN trained to perform blind (i.e., unknown noise level) least-squares
denoising. A generalization of this algorithm to constrained sampling provides
a method for using the implicit prior to solve any linear inverse problem, with
no additional training. We demonstrate this general form of transfer learning
in multiple applications, using the same algorithm to produce high-quality
solutions for deblurring, super-resolution, inpainting, and compressive
sensing.
</p>
<a href="http://arxiv.org/abs/2007.13640" target="_blank">arXiv:2007.13640</a> [<a href="http://arxiv.org/pdf/2007.13640" target="_blank">pdf</a>]

<h2>Maximum Mutation Reinforcement Learning for Scalable Control. (arXiv:2007.13690v7 [cs.LG] UPDATED)</h2>
<h3>Karush Suri, Xiao Qi Shi, Konstantinos N. Plataniotis, Yuri A. Lawryshyn</h3>
<p>Advances in Reinforcement Learning (RL) have demonstrated data efficiency and
optimal control over large state spaces at the cost of scalable performance.
Genetic methods, on the other hand, provide scalability but depict
hyperparameter sensitivity towards evolutionary operations. However, a
combination of the two methods has recently demonstrated success in scaling RL
agents to high-dimensional action spaces. Parallel to recent developments, we
present the Evolution-based Soft Actor-Critic (ESAC), a scalable RL algorithm.
We abstract exploration from exploitation by combining Evolution Strategies
(ES) with Soft Actor-Critic (SAC). Through this lens, we enable dominant skill
transfer between offsprings by making use of soft winner selections and genetic
crossovers in hindsight and simultaneously improve hyperparameter sensitivity
in evolutions using the novel Automatic Mutation Tuning (AMT). AMT gradually
replaces the entropy framework of SAC allowing the population to succeed at the
task while acting as randomly as possible, without making use of
backpropagation updates. In a study of challenging locomotion tasks consisting
of high-dimensional action spaces and sparse rewards, ESAC demonstrates
improved performance and sample efficiency in comparison to the Maximum Entropy
framework. Additionally, ESAC presents efficacious use of hardware resources
and algorithm overhead. A complete implementation of ESAC can be found at
karush17.github.io/esac-web/.
</p>
<a href="http://arxiv.org/abs/2007.13690" target="_blank">arXiv:2007.13690</a> [<a href="http://arxiv.org/pdf/2007.13690" target="_blank">pdf</a>]

<h2>TrajGAIL: Generating Urban Vehicle Trajectories using Generative Adversarial Imitation Learning. (arXiv:2007.14189v4 [cs.LG] UPDATED)</h2>
<h3>Seongjin Choi, Jiwon Kim, Hwasoo Yeo</h3>
<p>Recently, an abundant amount of urban vehicle trajectory data has been
collected in road networks. Many studies have used machine learning algorithms
to analyze patterns in vehicle trajectories to predict location sequences of
individual travelers. Unlike the previous studies that used a discriminative
modeling approach, this research suggests a generative modeling approach to
learn the underlying distributions of urban vehicle trajectory data. A
generative model for urban vehicle trajectories can better generalize from
training data by learning the underlying distribution of the training data and,
thus, produce synthetic vehicle trajectories similar to real vehicle
trajectories with limited observations. Synthetic trajectories can provide
solutions to data sparsity or data privacy issues in using location data. This
research proposesTrajGAIL, a generative adversarial imitation learning
framework for the urban vehicle trajectory generation. In TrajGAIL, learning
location sequences in observed trajectories is formulated as an imitation
learning problem in a partially observable Markov decision process. The model
is trained by the generative adversarial framework, which uses the reward
function from the adversarial discriminator. The model is tested with both
simulation and real-world datasets, and the results show that the proposed
model obtained significant performance gains compared to existing models in
sequence modeling.
</p>
<a href="http://arxiv.org/abs/2007.14189" target="_blank">arXiv:2007.14189</a> [<a href="http://arxiv.org/pdf/2007.14189" target="_blank">pdf</a>]

<h2>Deep Sketch-guided Cartoon Video Inbetweening. (arXiv:2008.04149v2 [cs.CV] UPDATED)</h2>
<h3>Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander</h3>
<p>We propose a novel framework to produce cartoon videos by fetching the color
information from two input keyframes while following the animated motion guided
by a user sketch. The key idea of the proposed approach is to estimate the
dense cross-domain correspondence between the sketch and cartoon video frames,
and employ a blending module with occlusion estimation to synthesize the middle
frame guided by the sketch. After that, the input frames and the synthetic
frame equipped with established correspondence are fed into an arbitrary-time
frame interpolation pipeline to generate and refine additional inbetween
frames. Finally, a module to preserve temporal consistency is employed.
Compared to common frame interpolation methods, our approach can address frames
with relatively large motion and also has the flexibility to enable users to
control the generated video sequences by editing the sketch guidance. By
explicitly considering the correspondence between frames and the sketch, we can
achieve higher quality results than other image synthesis methods. Our results
show that our system generalizes well to different movie frames, achieving
better results than existing solutions.
</p>
<a href="http://arxiv.org/abs/2008.04149" target="_blank">arXiv:2008.04149</a> [<a href="http://arxiv.org/pdf/2008.04149" target="_blank">pdf</a>]

<h2>Ordinal Pattern Kernel for Brain Connectivity Network Classification. (arXiv:2008.07719v2 [cs.LG] UPDATED)</h2>
<h3>Kai Ma, Biao Jie, Daoqiang Zhang</h3>
<p>Brain connectivity networks, which characterize the functional or structural
interaction of brain regions, has been widely used for brain disease
classification. Kernel-based method, such as graph kernel (i.e., kernel defined
on graphs), has been proposed for measuring the similarity of brain networks,
and yields the promising classification performance. However, most of graph
kernels are built on unweighted graph (i.e., network) with edge present or not,
and neglecting the valuable weight information of edges in brain connectivity
network, with edge weights conveying the strengths of temporal correlation or
fiber connection between brain regions. Accordingly, in this paper, we present
an ordinal pattern kernel for brain connectivity network classification.
Different with existing graph kernels that measures the topological similarity
of unweighted graphs, the proposed ordinal pattern kernels calculate the
similarity of weighted networks by comparing ordinal patterns from weighted
networks.

To evaluate the effectiveness of the proposed ordinal kernel, we further
develop a depth-first-based ordinal pattern kernel, and perform extensive
experiments in a real dataset of brain disease from ADNI database. The results
demonstrate that our proposed ordinal pattern kernel can achieve better
classification performance compared with state-of-the-art graph kernels.
</p>
<a href="http://arxiv.org/abs/2008.07719" target="_blank">arXiv:2008.07719</a> [<a href="http://arxiv.org/pdf/2008.07719" target="_blank">pdf</a>]

<h2>Bayesian geoacoustic inversion using mixture density network. (arXiv:2008.07902v3 [stat.ML] UPDATED)</h2>
<h3>Guoli Wu, Hefeng Dong, Junqiang Song, Jingya Zhang</h3>
<p>Bayesian geoacoustic inversion problems are conventionally solved by Markov
chain Monte Carlo methods or its variants, which are computationally expensive.
This paper extends the classic Bayesian geoacoustic inversion framework by
deriving important geoacoustic statistics of Bayesian geoacoustic inversion
from the multidimensional posterior probability density (PPD) using the mixture
density network (MDN) theory. These statistics make it convenient to train the
network directly on the whole parameter space and get the multidimensional PPD
of model parameters. The present approach provides a much more efficient way to
solve geoacoustic inversion problems in Bayesian inference framework. The
network is trained on a simulated dataset of surface-wave dispersion curves
with shear-wave velocities as labels and tested on both synthetic and real data
cases. The results show that the network gives reliable predictions and has
good generalization performance on unseen data. Once trained, the network can
rapidly (within seconds) give a fully probabilistic solution which is
comparable to Monte Carlo methods. It provides an promising approach for
real-time inversion.
</p>
<a href="http://arxiv.org/abs/2008.07902" target="_blank">arXiv:2008.07902</a> [<a href="http://arxiv.org/pdf/2008.07902" target="_blank">pdf</a>]

<h2>A Topological Framework for Deep Learning. (arXiv:2008.13697v12 [cs.LG] UPDATED)</h2>
<h3>Mustafa Hajij, Kyle Istvan</h3>
<p>We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.
</p>
<a href="http://arxiv.org/abs/2008.13697" target="_blank">arXiv:2008.13697</a> [<a href="http://arxiv.org/pdf/2008.13697" target="_blank">pdf</a>]

<h2>XCSP3-core: A Format for Representing Constraint Satisfaction/Optimization Problems. (arXiv:2009.00514v2 [cs.AI] UPDATED)</h2>
<h3>Fr&#xe9;d&#xe9;ric Boussemart, Christophe Lecoutre, Gilles Audemard, C&#xe9;dric Piette</h3>
<p>In this document, we introduce XCSP3-core, a subset of XCSP3 that allows us
to represent constraint satisfaction/optimization problems. The interest of
XCSP3-core is multiple: (i) focusing on the most popular frameworks (CSP and
COP) and constraints, (ii) facilitating the parsing process by means of
dedicated XCSP3-core parsers written in Java and C++ (using callback
functions), (iii) and defining a core format for comparisons (competitions) of
constraint solvers.
</p>
<a href="http://arxiv.org/abs/2009.00514" target="_blank">arXiv:2009.00514</a> [<a href="http://arxiv.org/pdf/2009.00514" target="_blank">pdf</a>]

<h2>VacSIM: Learning Effective Strategies for COVID-19 Vaccine Distribution using Reinforcement Learning. (arXiv:2009.06602v2 [cs.AI] UPDATED)</h2>
<h3>Raghav Awasthi, Keerat Kaur Guliani, Saif Ahmad Khan, Aniket Vashishtha, Mehrab Singh Gill, Arshita Bhatt, Aditya Nagori, Aniket Gupta, Ponnurangam Kumaraguru, Tavpritesh Sethi</h3>
<p>A COVID-19 vaccine is our best bet for mitigating the ongoing onslaught of
the pandemic. However, vaccine is also expected to be a limited resource. An
optimal allocation strategy, especially in countries with access inequities and
temporal separation of hot-spots, might be an effective way of halting the
disease spread. We approach this problem by proposing a novel pipeline VacSIM
that dovetails Sequential Decision based RL models into a Contextual Bandits
approach for optimizing the distribution of COVID-19 vaccine. Whereas the
Reinforcement Learning models suggest better actions and rewards, Contextual
Bandits allow online modifications that may need to be implemented on a
day-to-day basis in the real world scenario. We evaluate this framework against
a naive allocation approach of distributing vaccine proportional to the
incidence of COVID-19 cases in five different States across India and
demonstrate up to 9039 additional lives potentially saved and a significant
increase in the efficacy of limiting the spread over a period of 45 days
through the VacSIM approach. We also propose novel evaluation strategies
including standard compartmental model-based projections and a causality
preserving evaluation of our model. Finally, we contribute a new Open-AI
environment meant for the vaccine distribution scenario and open-source VacSIM
for wide testing and applications across the
globe(this http URL).
</p>
<a href="http://arxiv.org/abs/2009.06602" target="_blank">arXiv:2009.06602</a> [<a href="http://arxiv.org/pdf/2009.06602" target="_blank">pdf</a>]

<h2>Deep Momentum Uncertainty Hashing. (arXiv:2009.08012v2 [cs.CV] UPDATED)</h2>
<h3>Chaoyou Fu, Guoli Wang, Xiang Wu, Qian Zhang, Ran He</h3>
<p>Discrete optimization is one of the most intractable problems in deep
hashing. Previous methods usually mitigate this problem by binary
approximation, substituting binary codes for real-values via activation
functions or regularizations. However, such approximation leads to uncertainty
between real-values and binary ones, degrading retrieval performance. In this
paper, we propose a novel Deep Momentum Uncertainty Hashing (DMUH). It
explicitly estimates the uncertainty during training and leverages the
uncertainty information to guide the approximation process. Specifically, we
model bit-level uncertainty via measuring the discrepancy between the output of
a hashing network and that of a momentum-updated network. The discrepancy of
each bit indicates the uncertainty of the hashing network to the approximate
output of that bit. Meanwhile, the mean discrepancy of all bits in a hashing
code can be regarded as image-level uncertainty. It embodies the uncertainty of
the hashing network to the corresponding input image. The hashing bit and image
with higher uncertainty are paid more attention during optimization. To the
best of our knowledge, this is the first work to study the uncertainty in
hashing bits. Extensive experiments are conducted on four datasets to verify
the superiority of our method, including CIFAR-10, NUS-WIDE, MS-COCO, and a
million-scale dataset Clothing1M. Our method achieves the best performance on
all of the datasets and surpasses existing state-of-the-art methods by a large
margin, especially on Clothing1M.
</p>
<a href="http://arxiv.org/abs/2009.08012" target="_blank">arXiv:2009.08012</a> [<a href="http://arxiv.org/pdf/2009.08012" target="_blank">pdf</a>]

<h2>Multiplayer Support for the Arcade Learning Environment. (arXiv:2009.09341v2 [cs.LG] UPDATED)</h2>
<h3>Justin K. Terry, Benjamin Black, Luis Santos</h3>
<p>The Arcade Learning Environment ("ALE") is a widely used library in the
reinforcement learning community that allows easy programmatic interfacing with
Atari 2600 games, via the Stella emulator. We introduce a publicly available
extension to the ALE that extends its support to multiplayer games and game
modes. This interface is additionally integrated with PettingZoo to allow for a
simple Gym-like interface in Python to interact with these games. We
additionally introduce experimental baselines for all environments included.
</p>
<a href="http://arxiv.org/abs/2009.09341" target="_blank">arXiv:2009.09341</a> [<a href="http://arxiv.org/pdf/2009.09341" target="_blank">pdf</a>]

<h2>DVG-Face: Dual Variational Generation for Heterogeneous Face Recognition. (arXiv:2009.09399v2 [cs.CV] UPDATED)</h2>
<h3>Chaoyou Fu, Xiang Wu, Yibo Hu, Huaibo Huang, Ran He</h3>
<p>Heterogeneous Face Recognition (HFR) refers to matching cross-domain faces
and plays a crucial role in public security. Nevertheless, HFR is confronted
with challenges from large domain discrepancy and insufficient heterogeneous
data. In this paper, we formulate HFR as a dual generation problem, and tackle
it via a novel Dual Variational Generation (DVG-Face) framework. Specifically,
a dual variational generator is elaborately designed to learn the joint
distribution of paired heterogeneous images. However, the small-scale paired
heterogeneous training data may limit the identity diversity of sampling. In
order to break through the limitation, we propose to integrate abundant
identity information of large-scale visible data into the joint distribution.
Furthermore, a pairwise identity preserving loss is imposed on the generated
paired heterogeneous images to ensure their identity consistency. As a
consequence, massive new diverse paired heterogeneous images with the same
identity can be generated from noises. The identity consistency and identity
diversity properties allow us to employ these generated images to train the HFR
network via a contrastive learning mechanism, yielding both domain-invariant
and discriminative embedding features. Concretely, the generated paired
heterogeneous images are regarded as positive pairs, and the images obtained
from different samplings are considered as negative pairs. Our method achieves
superior performances over state-of-the-art methods on seven challenging
databases belonging to five HFR tasks, including NIR-VIS, Sketch-Photo,
Profile-Frontal Photo, Thermal-VIS, and ID-Camera. The related code will be
released at https://github.com/BradyFU.
</p>
<a href="http://arxiv.org/abs/2009.09399" target="_blank">arXiv:2009.09399</a> [<a href="http://arxiv.org/pdf/2009.09399" target="_blank">pdf</a>]

<h2>Energy-based Surprise Minimization for Multi-Agent Value Factorization. (arXiv:2009.09842v4 [cs.LG] UPDATED)</h2>
<h3>Karush Suri, Xiao Qi Shi, Konstantinos Plataniotis, Yuri Lawryshyn</h3>
<p>Multi-Agent Reinforcement Learning (MARL) has demonstrated significant
success in training decentralised policies in a centralised manner by making
use of value factorization methods. However, addressing surprise across
spurious states and approximation bias remain open problems for multi-agent
settings. Towards this goal, we introduce the Energy-based MIXer (EMIX), an
algorithm which minimizes surprise utilizing the energy across agents. Our
contributions are threefold; (1) EMIX introduces a novel surprise minimization
technique across multiple agents in the case of multi-agent
partially-observable settings. (2) EMIX highlights a practical use of energy
functions in MARL with theoretical guarantees and experiment validations of the
energy operator. Lastly, (3) EMIX extends Maxmin Q-learning for addressing
overestimation bias across agents in MARL. In a study of challenging StarCraft
II micromanagement scenarios, EMIX demonstrates consistent stable performance
for multiagent surprise minimization. Moreover, our ablation study highlights
the necessity of the energy-based scheme and the need for elimination of
overestimation bias in MARL. Our implementation of EMIX can be found at
karush17.github.io/emix-web/.
</p>
<a href="http://arxiv.org/abs/2009.09842" target="_blank">arXiv:2009.09842</a> [<a href="http://arxiv.org/pdf/2009.09842" target="_blank">pdf</a>]

<h2>Explainable Online Validation of Machine Learning Models for Practical Applications. (arXiv:2010.00821v3 [cs.LG] UPDATED)</h2>
<h3>Wolfgang Fuhl, Yao Rong, Thomas Motz, Michael Scheidt, Andreas Hartel, Andreas Koch, Enkelejda Kasneci</h3>
<p>We present a reformulation of the regression and classification, which aims
to validate the result of a machine learning algorithm. Our reformulation
simplifies the original problem and validates the result of the machine
learning algorithm using the training data. Since the validation of machine
learning algorithms must always be explainable, we perform our experiments with
the kNN algorithm as well as with an algorithm based on conditional
probabilities, which is proposed in this work. For the evaluation of our
approach, three publicly available data sets were used and three classification
and two regression problems were evaluated. The presented algorithm based on
conditional probabilities is also online capable and requires only a fraction
of memory compared to the kNN algorithm.
</p>
<a href="http://arxiv.org/abs/2010.00821" target="_blank">arXiv:2010.00821</a> [<a href="http://arxiv.org/pdf/2010.00821" target="_blank">pdf</a>]

<h2>Weight and Gradient Centralization in Deep Neural Networks. (arXiv:2010.00866v3 [cs.CV] UPDATED)</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>Batch normalization is currently the most widely used variant of internal
normalization for deep neural networks. Additional work has shown that the
normalization of weights and additional conditioning as well as the
normalization of gradients further improve the generalization. In this work, we
combine several of these methods and thereby increase the generalization of the
networks. The advantage of the newer methods compared to the batch
normalization is not only increased generalization, but also that these methods
only have to be applied during training and, therefore, do not influence the
running time during use. Link to CUDA code
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/
</p>
<a href="http://arxiv.org/abs/2010.00866" target="_blank">arXiv:2010.00866</a> [<a href="http://arxiv.org/pdf/2010.00866" target="_blank">pdf</a>]

<h2>Rotated Ring, Radial and Depth Wise Separable Radial Convolutions. (arXiv:2010.00873v3 [cs.CV] UPDATED)</h2>
<h3>Wolfgang Fuhl, Enkelejda Kasneci</h3>
<p>Simple image rotations significantly reduce the accuracy of deep neural
networks. Moreover, training with all possible rotations increases the data
set, which also increases the training duration. In this work, we address
trainable rotation invariant convolutions as well as the construction of nets,
since fully connected layers can only be rotation invariant with a
one-dimensional input. On the one hand, we show that our approach is
rotationally invariant for different models and on different public data sets.
We also discuss the influence of purely rotational invariant features on
accuracy. The rotationally adaptive convolution models presented in this work
are more computationally intensive than normal convolution models. Therefore,
we also present a depth wise separable approach with radial convolution. Link
to CUDA code
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/
</p>
<a href="http://arxiv.org/abs/2010.00873" target="_blank">arXiv:2010.00873</a> [<a href="http://arxiv.org/pdf/2010.00873" target="_blank">pdf</a>]

<h2>A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms. (arXiv:2010.01069v2 [cs.AI] UPDATED)</h2>
<h3>Shangtong Zhang, Romain Laroche, Harm van Seijen, Shimon Whiteson, Remi Tachet des Combes</h3>
<p>We investigate the discounting mismatch in actor-critic algorithm
implementations from a representation learning perspective. Theoretically,
actor-critic algorithms usually have discounting for both actor and critic,
i.e., there is a $\gamma^t$ term in the actor update for the transition
observed at time $t$ in a trajectory and the critic is a discounted value
function. Practitioners, however, usually ignore the discounting ($\gamma^t$)
for the actor while using a discounted critic. We investigate this mismatch in
two scenarios. In the first scenario, we consider optimizing an undiscounted
objective $(\gamma = 1)$ where $\gamma^t$ disappears naturally $(1^t = 1)$. We
then propose to interpret the discounting in critic in terms of a
bias-variance-representation trade-off and provide supporting empirical
results. In the second scenario, we consider optimizing a discounted objective
($\gamma &lt; 1$) and propose to interpret the omission of the discounting in the
actor update from an auxiliary task perspective and provide supporting
empirical results.
</p>
<a href="http://arxiv.org/abs/2010.01069" target="_blank">arXiv:2010.01069</a> [<a href="http://arxiv.org/pdf/2010.01069" target="_blank">pdf</a>]

<h2>Learning Mesh-Based Simulation with Graph Networks. (arXiv:2010.03409v3 [cs.LG] UPDATED)</h2>
<h3>Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, Peter W. Battaglia</h3>
<p>Mesh-based simulations are central to modeling complex physical systems in
many disciplines across science and engineering. Mesh representations support
powerful numerical integration methods and their resolution can be adapted to
strike favorable trade-offs between accuracy and efficiency. However,
high-dimensional scientific simulations are very expensive to run, and solvers
and parameters must often be tuned individually to each system studied. Here we
introduce MeshGraphNets, a framework for learning mesh-based simulations using
graph neural networks. Our model can be trained to pass messages on a mesh
graph and to adapt the mesh discretization during forward simulation. Our
results show it can accurately predict the dynamics of a wide range of physical
systems, including aerodynamics, structural mechanics, and cloth. The model's
adaptivity supports learning resolution-independent dynamics and can scale to
more complex state spaces at test time. Our method is also highly efficient,
running 1-2 orders of magnitude faster than the simulation on which it is
trained. Our approach broadens the range of problems on which neural network
simulators can operate and promises to improve the efficiency of complex,
scientific modeling tasks.
</p>
<a href="http://arxiv.org/abs/2010.03409" target="_blank">arXiv:2010.03409</a> [<a href="http://arxiv.org/pdf/2010.03409" target="_blank">pdf</a>]

<h2>Robust Behavioral Cloning for Autonomous Vehicles using End-to-End Imitation Learning. (arXiv:2010.04767v2 [cs.RO] UPDATED)</h2>
<h3>Tanmay Vilas Samak, Chinmay Vilas Samak, Sivanathan Kandhasamy</h3>
<p>In this work, we present a lightweight pipeline for robust behavioral cloning
of a human driver using end-to-end imitation learning. The proposed pipeline
was employed to train and deploy three distinct driving behavior models onto a
simulated vehicle. The training phase comprised of data collection, balancing,
augmentation, preprocessing and training a neural network, following which, the
trained model was deployed onto the ego vehicle to predict steering commands
based on the feed from an onboard camera. A novel coupled control law was
formulated to generate longitudinal control commands on-the-go based on the
predicted steering angle and other parameters such as actual speed of the ego
vehicle and the prescribed constraints for speed and steering. We analyzed
computational efficiency of the pipeline and evaluated robustness of the
trained models through exhaustive experimentation during the deployment phase.
We also compared our approach against state-of-the-art implementation in order
to comment on its validity.
</p>
<a href="http://arxiv.org/abs/2010.04767" target="_blank">arXiv:2010.04767</a> [<a href="http://arxiv.org/pdf/2010.04767" target="_blank">pdf</a>]

<h2>Interpreting Multivariate Shapley Interactions in DNNs. (arXiv:2010.05045v3 [cs.LG] UPDATED)</h2>
<h3>Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, Quanshi Zhang</h3>
<p>This paper aims to explain deep neural networks (DNNs) from the perspective
of multivariate interactions. In this paper, we define and quantify the
significance of interactions among multiple input variables of the DNN. Input
variables with strong interactions usually form a coalition and reflect
prototype features, which are memorized and used by the DNN for inference. We
define the significance of interactions based on the Shapley value, which is
designed to assign the attribution value of each input variable to the
inference. We have conducted experiments with various DNNs. Experimental
results have demonstrated the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2010.05045" target="_blank">arXiv:2010.05045</a> [<a href="http://arxiv.org/pdf/2010.05045" target="_blank">pdf</a>]

<h2>Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions. (arXiv:2010.05180v2 [cs.AI] UPDATED)</h2>
<h3>Zhengxian Lin, Kim-Ho Lam, Alan Fern</h3>
<p>We investigate a deep reinforcement learning (RL) architecture that supports
explaining why a learned agent prefers one action over another. The key idea is
to learn action-values that are directly represented via human-understandable
properties of expected futures. This is realized via the embedded
self-prediction (ESP)model, which learns said properties in terms of human
provided features. Action preferences can then be explained by contrasting the
future properties predicted for each action. To address cases where there are a
large number of features, we develop a novel method for computing minimal
sufficient explanations from anESP. Our case studies in three domains,
including a complex strategy game, show that ESP models can be effectively
learned and support insightful explanations.
</p>
<a href="http://arxiv.org/abs/2010.05180" target="_blank">arXiv:2010.05180</a> [<a href="http://arxiv.org/pdf/2010.05180" target="_blank">pdf</a>]

<h2>Explain2Attack: Text Adversarial Attacks via Cross-Domain Interpretability. (arXiv:2010.06812v4 [cs.LG] UPDATED)</h2>
<h3>Mahmoud Hossam, Trung Le, He Zhao, Dinh Phung</h3>
<p>Training robust deep learning models for down-stream tasks is a critical
challenge. Research has shown that down-stream models can be easily fooled with
adversarial inputs that look like the training data, but slightly perturbed, in
a way imperceptible to humans. Understanding the behavior of natural language
models under these attacks is crucial to better defend these models against
such attacks. In the black-box attack setting, where no access to model
parameters is available, the attacker can only query the output information
from the targeted model to craft a successful attack. Current black-box
state-of-the-art models are costly in both computational complexity and number
of queries needed to craft successful adversarial examples. For real world
scenarios, the number of queries is critical, where less queries are desired to
avoid suspicion towards an attacking agent. In this paper, we propose
Explain2Attack, a black-box adversarial attack on text classification task.
Instead of searching for important words to be perturbed by querying the target
model, Explain2Attack employs an interpretable substitute model from a similar
domain to learn word importance scores. We show that our framework either
achieves or out-performs attack rates of the state-of-the-art models, yet with
lower queries cost and higher efficiency.
</p>
<a href="http://arxiv.org/abs/2010.06812" target="_blank">arXiv:2010.06812</a> [<a href="http://arxiv.org/pdf/2010.06812" target="_blank">pdf</a>]

<h2>Scalable Graph Networks for Particle Simulations. (arXiv:2010.06948v2 [cs.LG] UPDATED)</h2>
<h3>Karolis Martinkus, Aurelien Lucchi, Nathana&#xeb;l Perraudin</h3>
<p>Learning system dynamics directly from observations is a promising direction
in machine learning due to its potential to significantly enhance our ability
to understand physical systems. However, the dynamics of many real-world
systems are challenging to learn due to the presence of nonlinear potentials
and a number of interactions that scales quadratically with the number of
particles $N$, as in the case of the N-body problem. In this work, we introduce
an approach that transforms a fully-connected interaction graph into a
hierarchical one which reduces the number of edges to $O(N)$. This results in
linear time and space complexity while the pre-computation of the hierarchical
graph requires $O(N\log (N))$ time and $O(N)$ space. Using our approach, we are
able to train models on much larger particle counts, even on a single GPU. We
evaluate how the phase space position accuracy and energy conservation depend
on the number of simulated particles. Our approach retains high accuracy and
efficiency even on large-scale gravitational N-body simulations which are
impossible to run on a single machine if a fully-connected graph is used.
Similar results are also observed when simulating Coulomb interactions.
Furthermore, we make several important observations regarding the performance
of this new hierarchical model, including: i) its accuracy tends to improve
with the number of particles in the simulation and ii) its generalisation to
unseen particle counts is also much better than for models that use all
$O(N^2)$ interactions.
</p>
<a href="http://arxiv.org/abs/2010.06948" target="_blank">arXiv:2010.06948</a> [<a href="http://arxiv.org/pdf/2010.06948" target="_blank">pdf</a>]

<h2>Pose Refinement Graph Convolutional Network for Skeleton-based Action Recognition. (arXiv:2010.07367v2 [cs.CV] UPDATED)</h2>
<h3>Shijie Li, Jinhui Yi, Yazan Abu Farha, Juergen Gall</h3>
<p>With the advances in capturing 2D or 3D skeleton data, skeleton-based action
recognition has received an increasing interest over the last years. As
skeleton data is commonly represented by graphs, graph convolutional networks
have been proposed for this task. While current graph convolutional networks
accurately recognize actions, they are too expensive for robotics applications
where limited computational resources are available. In this paper, we
therefore propose a highly efficient graph convolutional network that addresses
the limitations of previous works. This is achieved by a parallel structure
that gradually fuses motion and spatial information and by reducing the
temporal resolution as early as possible. Furthermore, we explicitly address
the issue that human poses can contain errors. To this end, the network first
refines the poses before they are further processed to recognize the action. We
therefore call the network Pose Refinement Graph Convolutional Network.
Compared to other graph convolutional networks, our network requires 86\%-93\%
less parameters and reduces the floating point operations by 89%-96% while
achieving a comparable accuracy. It therefore provides a much better trade-off
between accuracy, memory footprint and processing time, which makes it suitable
for robotics applications.
</p>
<a href="http://arxiv.org/abs/2010.07367" target="_blank">arXiv:2010.07367</a> [<a href="http://arxiv.org/pdf/2010.07367" target="_blank">pdf</a>]

<h2>Harnessing Uncertainty in Domain Adaptation for MRI Prostate Lesion Segmentation. (arXiv:2010.07411v2 [cs.CV] UPDATED)</h2>
<h3>Eleni Chiou, Francesco Giganti, Shonit Punwani, Iasonas Kokkinos, Eleftheria Panagiotaki</h3>
<p>The need for training data can impede the adoption of novel imaging
modalities for learning-based medical image analysis. Domain adaptation methods
partially mitigate this problem by translating training data from a related
source domain to a novel target domain, but typically assume that a one-to-one
translation is possible. Our work addresses the challenge of adapting to a more
informative target domain where multiple target samples can emerge from a
single source sample. In particular we consider translating from mp-MRI to
VERDICT, a richer MRI modality involving an optimized acquisition protocol for
cancer characterization. We explicitly account for the inherent uncertainty of
this mapping and exploit it to generate multiple outputs conditioned on a
single input. Our results show that this allows us to extract systematically
better image representations for the target domain, when used in tandem with
both simple, CycleGAN-based baselines, as well as more powerful approaches that
integrate discriminative segmentation losses and/or residual adapters. When
compared to its deterministic counterparts, our approach yields substantial
improvements across a broad range of dataset sizes, increasingly strong
baselines, and evaluation measures.
</p>
<a href="http://arxiv.org/abs/2010.07411" target="_blank">arXiv:2010.07411</a> [<a href="http://arxiv.org/pdf/2010.07411" target="_blank">pdf</a>]

<h2>Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI. (arXiv:2010.07487v2 [cs.AI] UPDATED)</h2>
<h3>Alon Jacovi, Ana Marasovi&#x107;, Tim Miller, Yoav Goldberg</h3>
<p>Trust is a central component of the interaction between people and AI, in
that 'incorrect' levels of trust may cause misuse, abuse or disuse of the
technology. But what, precisely, is the nature of trust in AI? What are the
prerequisites and goals of the cognitive mechanism of trust, and how can we
promote them, or assess whether they are being satisfied in a given
interaction? This work aims to answer these questions. We discuss a model of
trust inspired by, but not identical to, sociology's interpersonal trust (i.e.,
trust between people). This model rests on two key properties of the
vulnerability of the user and the ability to anticipate the impact of the AI
model's decisions. We incorporate a formalization of 'contractual trust', such
that trust between a user and an AI is trust that some implicit or explicit
contract will hold, and a formalization of 'trustworthiness' (which detaches
from the notion of trustworthiness in sociology), and with it concepts of
'warranted' and 'unwarranted' trust. We then present the possible causes of
warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how
to design trustworthy AI, how to evaluate whether trust has manifested, and
whether it is warranted. Finally, we elucidate the connection between trust and
XAI using our formalization.
</p>
<a href="http://arxiv.org/abs/2010.07487" target="_blank">arXiv:2010.07487</a> [<a href="http://arxiv.org/pdf/2010.07487" target="_blank">pdf</a>]

<h2>Task-Adaptive Robot Learning from Demonstration with Gaussian Process Models under Replication. (arXiv:2010.07795v2 [cs.RO] UPDATED)</h2>
<h3>Miguel Arduengo, Adri&#xe0; Colom&#xe9;, J&#xfa;lia Borr&#xe0;s, Luis Sentis, Carme Torras</h3>
<p>Learning from Demonstration (LfD) is a paradigm that allows robots to learn
complex manipulation tasks that can not be easily scripted, but can be
demonstrated by a human teacher. One of the challenges of LfD is to enable
robots to acquire skills that can be adapted to different scenarios. In this
paper, we propose to achieve this by exploiting the variations in the
demonstrations to retrieve an adaptive and robust policy, using Gaussian
Process (GP) models. Adaptability is enhanced by incorporating task parameters
into the model, which encode different specifications within the same task.
With our formulation, these parameters can be either real, integer, or
categorical. Furthermore, we propose a GP design that exploits the structure of
replications, i.e., repeated demonstrations with identical conditions within
data. Our method significantly reduces the computational cost of model fitting
in complex tasks, where replications are essential to obtain a robust model. We
illustrate our approach through several experiments on a handwritten letter
demonstration dataset.
</p>
<a href="http://arxiv.org/abs/2010.07795" target="_blank">arXiv:2010.07795</a> [<a href="http://arxiv.org/pdf/2010.07795" target="_blank">pdf</a>]

<h2>RAT iLQR: A Risk Auto-Tuning Controller to Optimally Account for Stochastic Model Mismatch. (arXiv:2010.08174v3 [cs.RO] UPDATED)</h2>
<h3>Haruki Nishimura, Negar Mehr, Adrien Gaidon, Mac Schwager</h3>
<p>Successful robotic operation in stochastic environments relies on accurate
characterization of the underlying probability distributions, yet this is often
imperfect due to limited knowledge. This work presents a control algorithm that
is capable of handling such distributional mismatches. Specifically, we propose
a novel nonlinear MPC for distributionally robust control, which plans locally
optimal feedback policies against a worst-case distribution within a given KL
divergence bound from a Gaussian distribution. Leveraging mathematical
equivalence between distributionally robust control and risk-sensitive optimal
control, our framework also provides an algorithm to dynamically adjust the
risk-sensitivity level online for risk-sensitive control. The benefits of the
distributional robustness as well as the automatic risk-sensitivity adjustment
are demonstrated in a dynamic collision avoidance scenario where the predictive
distribution of human motion is erroneous.
</p>
<a href="http://arxiv.org/abs/2010.08174" target="_blank">arXiv:2010.08174</a> [<a href="http://arxiv.org/pdf/2010.08174" target="_blank">pdf</a>]

<h2>Autonomous Robotic Suction to Clear the Surgical Field for Hemostasis using Image-based Blood Flow Detection. (arXiv:2010.08441v2 [cs.RO] UPDATED)</h2>
<h3>Florian Richter, Shihao Shen, Fei Liu, Jingbin Huang, Emily K. Funk, Ryan K. Orosco, Michael C. Yip</h3>
<p>Autonomous robotic surgery has seen significant progression over the last
decade with the aims of reducing surgeon fatigue, improving procedural
consistency, and perhaps one day take over surgery itself. However, automation
has not been applied to the critical surgical task of controlling tissue and
blood vessel bleeding--known as hemostasis. The task of hemostasis covers a
spectrum of bleeding sources and a range of blood velocity, trajectory, and
volume. In an extreme case, an un-controlled blood vessel fills the surgical
field with flowing blood. In this work, we present the first, automated
solution for hemostasis through development of a novel probabilistic blood flow
detection algorithm and a trajectory generation technique that guides
autonomous suction tools towards pooling blood. The blood flow detection
algorithm is tested in both simulated scenes and in a real-life trauma scenario
involving a hemorrhage that occurred during thyroidectomy. The complete
solution is tested in a physical lab setting with the da Vinci Research Kit
(dVRK) and a simulated surgical cavity for blood to flow through. The results
show that our automated solution has accurate detection, a fast reaction time,
and effective removal of the flowing blood. Therefore, the proposed methods are
powerful tools to clearing the surgical field which can be followed by either a
surgeon or future robotic automation developments to close the vessel rupture.
</p>
<a href="http://arxiv.org/abs/2010.08441" target="_blank">arXiv:2010.08441</a> [<a href="http://arxiv.org/pdf/2010.08441" target="_blank">pdf</a>]

<h2>Evidential Sparsification of Multimodal Latent Spaces in Conditional Variational Autoencoders. (arXiv:2010.09164v3 [cs.LG] UPDATED)</h2>
<h3>Masha Itkina, Boris Ivanovic, Ransalu Senanayake, Mykel J. Kochenderfer, Marco Pavone</h3>
<p>Discrete latent spaces in variational autoencoders have been shown to
effectively capture the data distribution for many real-world problems such as
natural language understanding, human intent prediction, and visual scene
representation. However, discrete latent spaces need to be sufficiently large
to capture the complexities of real-world data, rendering downstream tasks
computationally challenging. For instance, performing motion planning in a
high-dimensional latent representation of the environment could be intractable.
We consider the problem of sparsifying the discrete latent space of a trained
conditional variational autoencoder, while preserving its learned
multimodality. As a post hoc latent space reduction technique, we use
evidential theory to identify the latent classes that receive direct evidence
from a particular input condition and filter out those that do not. Experiments
on diverse tasks, such as image generation and human behavior prediction,
demonstrate the effectiveness of our proposed technique at reducing the
discrete latent sample space size of a model while maintaining its learned
multimodality.
</p>
<a href="http://arxiv.org/abs/2010.09164" target="_blank">arXiv:2010.09164</a> [<a href="http://arxiv.org/pdf/2010.09164" target="_blank">pdf</a>]

<h2>Survey on Causal-based Machine Learning Fairness Notions. (arXiv:2010.09553v3 [cs.LG] UPDATED)</h2>
<h3>Karima Makhlouf, Sami Zhioua, Catuscia Palamidessi</h3>
<p>Addressing the problem of fairness is crucial to safely use machine learning
algorithms to support decisions with a critical impact on people's lives such
as job hiring, child maltreatment, disease diagnosis, loan granting, etc.
Several notions of fairness have been defined and examined in the past decade,
such as, statistical parity and equalized odds. The most recent fairness
notions, however, are causal-based and reflect the now widely accepted idea
that using causality is necessary to appropriately address the problem of
fairness. This paper examines an exhaustive list of causal-based fairness
notions, in particular their applicability in real-world scenarios. As the
majority of causal-based fairness notions are defined in terms of
non-observable quantities (e.g. interventions and counterfactuals), their
applicability depends heavily on the identifiability of those quantities from
observational data. In this paper, we compile the most relevant identifiability
criteria for the problem of fairness from the extensive literature on
identifiability theory. These criteria are then used to decide about the
applicability of causal-based fairness notions in concrete discrimination
scenarios.
</p>
<a href="http://arxiv.org/abs/2010.09553" target="_blank">arXiv:2010.09553</a> [<a href="http://arxiv.org/pdf/2010.09553" target="_blank">pdf</a>]

<h2>Robot Design With Neural Networks, MILP Solvers and Active Learning. (arXiv:2010.09842v3 [cs.AI] UPDATED)</h2>
<h3>Sanjai Narain, Emily Mak, Dana Chee, Todd Huster, Jeremy Cohen, Kishore Pochiraju, Brendan Englot, Niraj K. Jha, Karthik Narayan</h3>
<p>Central to the design of many robot systems and their controllers is solving
a constrained blackbox optimization problem. This paper presents CNMA, a new
method of solving this problem that is conservative in the number of
potentially expensive blackbox function evaluations; allows specifying complex,
even recursive constraints directly rather than as hard-to-design penalty or
barrier functions; and is resilient to the non-termination of function
evaluations. CNMA leverages the ability of neural networks to approximate any
continuous function, their transformation into equivalent mixed integer linear
programs (MILPs) and their optimization subject to constraints with industrial
strength MILP solvers. A new learning-from-failure step guides the learning to
be relevant to solving the constrained optimization problem. Thus, the amount
of learning is orders of magnitude smaller than that needed to learn functions
over their entire domains. CNMA is illustrated with the design of several
robotic systems: wave-energy propelled boat, lunar lander, hexapod, cartpole,
acrobot and parallel parking. These range from 6 real-valued dimensions to 36.
We show that CNMA surpasses the Nelder-Mead, Gaussian and Random Search
optimization methods against the metric of number of function evaluations.
</p>
<a href="http://arxiv.org/abs/2010.09842" target="_blank">arXiv:2010.09842</a> [<a href="http://arxiv.org/pdf/2010.09842" target="_blank">pdf</a>]

<h2>Assembly Sequences Based on Multiple Criteria Against Products with Deformable Parts. (arXiv:2010.10846v3 [cs.RO] UPDATED)</h2>
<h3>Takuya Kiyokawa, Jun Takamatsu, Tsukasa Ogasawara</h3>
<p>Aiming to generate easy-to-handle assembly sequences for robotic assembly,
this study tackles assembly sequence generation by considering two tradeoff
objectives: (1) insertion conditions and (2) degrees of constraints among
assembled parts. We propose a multiobjective genetic algorithm to balance these
two objectives for generating assembly sequences. Furthermore, the method of
extracting part relation matrices including interference-free, insertion, and
degree of constraint matrices is extended for application to 3D computer-aided
design (CAD) models, including deformable parts. The interference of deformable
parts with other parts can be easily investigated by scaling parts. A
simulation experiment was conducted using the proposed method, and the results
show the possibility of obtaining Pareto-optimal solutions of assembly
sequences for a 3D CAD model with 33 parts including a deformable part. This
approach can potentially be extended to handle various types of deformable
parts and to explore graspable sequences during assembly operations.
</p>
<a href="http://arxiv.org/abs/2010.10846" target="_blank">arXiv:2010.10846</a> [<a href="http://arxiv.org/pdf/2010.10846" target="_blank">pdf</a>]

<h2>Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition. (arXiv:2010.11757v3 [cs.CV] UPDATED)</h2>
<h3>Chun-Fu Chen, Rameswar Panda, Kandan Ramakrishnan, Rogerio Feris, John Cohn, Aude Oliva, Quanfu Fan</h3>
<p>In recent years, a number of approaches based on 2D CNNs and 3D CNNs have
emerged for video action recognition, achieving state-of-the-art results on
several large-scale benchmark datasets. In this paper, we carry out an in-depth
comparative analysis to better understand the differences between these
approaches and the progress made by them. To this end, we develop a unified
framework for both 2D-CNN and 3D-CNN action models, which enables us to remove
bells and whistles and provides a common ground for a fair comparison. We then
conduct an effort towards a large-scale analysis involving over 300 action
recognition models. Our comprehensive analysis reveals that a) a significant
leap is made in efficiency for action recognition, but not in accuracy; b)
2D-CNN and 3D-CNN models behave similarly in terms of spatio-temporal
representation abilities and transferability. Our analysis also shows that
recent action models seem to be able to learn data-dependent temporality
flexibly as needed. Our codes and models are available on
https://github.com/IBM/action-recognition-pytorch.
</p>
<a href="http://arxiv.org/abs/2010.11757" target="_blank">arXiv:2010.11757</a> [<a href="http://arxiv.org/pdf/2010.11757" target="_blank">pdf</a>]

<h2>Sharper convergence bounds of Monte Carlo Rademacher Averages through Self-Bounding functions. (arXiv:2010.12103v2 [cs.LG] UPDATED)</h2>
<h3>Leonardo Pellegrina</h3>
<p>We derive sharper probabilistic concentration bounds for the Monte Carlo
Empirical Rademacher Averages (MCERA), which are proved through recent results
on the concentration of self-bounding functions. Our novel bounds are
characterized by convergence rates that depend on data-dependent characteristic
quantities of the set of functions under consideration, such as the empirical
wimpy variance, an essential improvement w.r.t. standard bounds based on the
methods of bounded differences. For this reason, our new results are applicable
to yield sharper bounds to (Local) Rademacher Averages. We also derive improved
novel variance-dependent bounds for the special case where only one vector of
Rademacher random variables is used to compute the MCERA, through the
application of Bousquet's inequality and novel data-dependent bounds to the
wimpy variance. Then, we leverage the framework of self-bounding functions to
derive novel probabilistic bounds to the supremum deviations, that may be of
independent interest.
</p>
<a href="http://arxiv.org/abs/2010.12103" target="_blank">arXiv:2010.12103</a> [<a href="http://arxiv.org/pdf/2010.12103" target="_blank">pdf</a>]

<h2>Handgun detection using combined human pose and weapon appearance. (arXiv:2010.13753v2 [cs.CV] UPDATED)</h2>
<h3>Jesus Ruiz-Santaquiteria, Alberto Velasco-Mata, Noelia Vallez, Gloria Bueno, Juan A. &#xc1;lvarez-Garc&#xed;a, Oscar Deniz</h3>
<p>CCTV surveillance systems are essential nowadays to prevent and mitigate
security threats or dangerous situations such as mass shootings or terrorist
attacks, in which early detection is crucial. These solutions are manually
supervised by a security operator, which has significant limitations. Novel
deep learning-based methods have allowed to develop automatic and real time
weapon detectors with promising results. However, these approaches are based on
visual weapon appearance only and no additional contextual information is
exploited. For handguns, body pose may be a useful cue, especially in cases
where the gun is barely visible and also as a way to reduce false positives. In
this work, a novel method is proposed to combine, in a single architecture,
both weapon appearance and 2D human pose information. First, pose keypoints are
estimated to extract hand regions and generate binary pose images, which are
the model inputs. Then, each input is processed with a different subnetwork to
extract two feature maps. Finally, this information is combined to produce the
hand region prediction (handgun vs no-handgun). A new dataset composed of
samples collected from different sources has been used to evaluate model
performance under different situations. Moreover, the robustness of the model
to different brightness and weapon size conditions (simulating conditions in
which appearance is degraded by low light and distance to the camera) have also
been tested. Results obtained show that the combined model improves overall
performance substantially with respect to appearance alone as used by other
popular methods such as YOLOv3.
</p>
<a href="http://arxiv.org/abs/2010.13753" target="_blank">arXiv:2010.13753</a> [<a href="http://arxiv.org/pdf/2010.13753" target="_blank">pdf</a>]

<h2>Neural Architecture Search of SPD Manifold Networks. (arXiv:2010.14535v2 [cs.LG] UPDATED)</h2>
<h3>Rhea Sanjay Sukthanker, Zhiwu Huang, Suryansh Kumar, Erik Goron Endsjo, Yan Wu, Luc Van Gool</h3>
<p>In this paper, we propose a new neural architecture search (NAS) problem of
Symmetric Positive Definite (SPD) manifold networks. Unlike the conventional
NAS problem, our problem requires to search for a unique computational cell
called the SPD cell. This SPD cell serves as a basic building block of SPD
neural architectures. An efficient solution to our problem is important to
minimize the extraneous manual effort in the SPD neural architecture design. To
accomplish this goal, we first introduce a geometrically rich and diverse SPD
neural architecture search space for an efficient SPD cell design. Further, we
model our new NAS problem using the supernet strategy, which models the
architecture search problem as a one-shot training process of a single
supernet. Based on the supernet modeling, we exploit a differentiable NAS
algorithm on our relaxed continuous search space for SPD neural architecture
search. Statistical evaluation of our method on drone, action, and emotion
recognition tasks mostly provides better results than the state-of-the-art SPD
networks and NAS algorithms. Empirical results show that our algorithm excels
in discovering better SPD network design and providing models that are more
than 3 times lighter than searched by state-of-the-art NAS algorithms.
</p>
<a href="http://arxiv.org/abs/2010.14535" target="_blank">arXiv:2010.14535</a> [<a href="http://arxiv.org/pdf/2010.14535" target="_blank">pdf</a>]

<h2>Socially-Compatible Behavior Design of Autonomous Vehicles with Verification on Real Human Data. (arXiv:2010.14712v3 [cs.RO] UPDATED)</h2>
<h3>Letian Wang, Liting Sun, Masayoshi Tomizuka, Wei Zhan</h3>
<p>As more and more autonomous vehicles (AVs) are being deployed on public
roads, designing socially compatible behaviors for them is of critical
importance. Based on observations, AVs need to predict the future behaviors of
other traffic participants, and be aware of the uncertainties associated with
such prediction so that safe, efficient, and human-like motions can be
generated. In this paper, we propose an integrated prediction and planning
framework that allows the AVs to online infer the characteristics of other road
users and generate behaviors optimizing not only their own rewards, but also
their courtesy to others, as well as their confidence on the consequences in
the presence of uncertainties. Based on the definitions of courtesy and
confidence, we explore the influences of such factors on the behaviors of AVs
in interactive driving scenarios. Moreover, we evaluate the proposed algorithm
on naturalistic human driving data by comparing the generated behavior with the
ground truth. Results show that the online inference can significantly improve
the human-likeness of the generated behaviors. Furthermore, we find that human
drivers show great courtesy to others, even for those without right-of-way.
</p>
<a href="http://arxiv.org/abs/2010.14712" target="_blank">arXiv:2010.14712</a> [<a href="http://arxiv.org/pdf/2010.14712" target="_blank">pdf</a>]

<h2>Compensating data shortages in manufacturing with monotonicity knowledge. (arXiv:2010.15955v2 [cs.LG] UPDATED)</h2>
<h3>Martin von Kurnatowski, Jochen Schmid, Patrick Link, Rebekka Zache, Lukas Morand, Torsten Kraft, Ingo Schmidt, Anke Stoll</h3>
<p>Optimization in engineering requires appropriate models. In this article, a
regression method for enhancing the predictive power of a model by exploiting
expert knowledge in the form of shape constraints, or more specifically,
monotonicity constraints, is presented. Incorporating such information is
particularly useful when the available data sets are small or do not cover the
entire input space, as is often the case in manufacturing applications. The
regression subject to the considered monotonicity constraints is set up as a
semi-infinite optimization problem, and an adaptive solution algorithm is
proposed. The method is applicable in multiple dimensions and can be extended
to more general shape constraints. It is tested and validated on two real-world
manufacturing processes, namely laser glass bending and press hardening of
sheet metal. It is found that the resulting models both comply well with the
expert's monotonicity knowledge and predict the training data accurately. The
suggested approach leads to lower root-mean-squared errors than comparative
methods from the literature for the sparse data sets considered in this work.
</p>
<a href="http://arxiv.org/abs/2010.15955" target="_blank">arXiv:2010.15955</a> [<a href="http://arxiv.org/pdf/2010.15955" target="_blank">pdf</a>]

<h2>PREGAN: Pose Randomization and Estimation for Weakly Paired Image Style Translation. (arXiv:2011.00301v2 [cs.CV] UPDATED)</h2>
<h3>Zexi Chen, Jiaxin Guo, Xuecheng Xu, Yunkai Wang, Yue Wang, Rong Xiong</h3>
<p>Utilizing the trained model under different conditions without data
annotation is attractive for robot applications. Towards this goal, one class
of methods is to translate the image style from another environment to the one
on which models are trained. In this paper, we propose a weakly-paired setting
for the style translation, where the content in the two images is aligned with
errors in poses. These images could be acquired by different sensors in
different conditions that share an overlapping region, e.g. with LiDAR or
stereo cameras, from sunny days or foggy nights. We consider this setting to be
more practical with: (i) easier labeling than the paired data; (ii) better
interpretability and detail retrieval than the unpaired data. To translate
across such images, we propose PREGAN to train a style translator by
intentionally transforming the two images with a random pose, and to estimate
the given random pose by differentiable non-trainable pose estimator given that
the more aligned in style, the better the estimated result is. Such adversarial
training enforces the network to learn the style translation, avoiding being
entangled with other variations. Finally, PREGAN is validated on both simulated
and real-world collected data to show the effectiveness. Results on down-stream
tasks, classification, road segmentation, object detection, and feature
matching show its potential for real applications.
https://github.com/wrld/PRoGAN
</p>
<a href="http://arxiv.org/abs/2011.00301" target="_blank">arXiv:2011.00301</a> [<a href="http://arxiv.org/pdf/2011.00301" target="_blank">pdf</a>]

<h2>Event-Based Signal Temporal Logic Synthesis for Single and Multi-Robot Tasks. (arXiv:2011.00370v2 [cs.RO] UPDATED)</h2>
<h3>David Gundana, Hadas Kress-Gazit</h3>
<p>We propose a new specification language and control synthesis technique for
single and multi-robot high-level tasks; these tasks include timing constraints
and reaction to environmental events. Specifically, we define Event-based
Signal Temporal Logic (STL) and use it to encode tasks that are reactive to
uncontrolled environment events. Our control synthesis approach to Event-based
STL tasks combines automata and control barrier functions to produce robot
behaviors that satisfy the specification when possible. Our method
automatically provides feedback to the user if an Event-based STL task can not
be achieved. We demonstrate the effectiveness of the framework through
simulations and physical demonstrations of multi-robot tasks.
</p>
<a href="http://arxiv.org/abs/2011.00370" target="_blank">arXiv:2011.00370</a> [<a href="http://arxiv.org/pdf/2011.00370" target="_blank">pdf</a>]

<h2>Modular-Relatedness for Continual Learning. (arXiv:2011.01272v2 [cs.LG] UPDATED)</h2>
<h3>Ammar Shaker, Shujian Yu, Francesco Alesiani</h3>
<p>In this paper, we propose a continual learning (CL) technique that is
beneficial to sequential task learners by improving their retained accuracy and
reducing catastrophic forgetting. The principal target of our approach is the
automatic extraction of modular parts of the neural network and then estimating
the relatedness between the tasks given these modular components. This
technique is applicable to different families of CL methods such as
regularization-based (e.g., the Elastic Weight Consolidation) or the
rehearsal-based (e.g., the Gradient Episodic Memory) approaches where episodic
memory is needed. Empirical results demonstrate remarkable performance gain (in
terms of robustness to forgetting) for methods such as EWC and GEM based on our
technique, especially when the memory budget is very limited.
</p>
<a href="http://arxiv.org/abs/2011.01272" target="_blank">arXiv:2011.01272</a> [<a href="http://arxiv.org/pdf/2011.01272" target="_blank">pdf</a>]

<h2>An SMT-Based Approach for Verifying Binarized Neural Networks. (arXiv:2011.02948v2 [cs.LG] UPDATED)</h2>
<h3>Guy Amir, Haoze Wu, Clark Barrett, Guy Katz</h3>
<p>Deep learning has emerged as an effective approach for creating modern
software systems, with neural networks often surpassing hand-crafted systems.
Unfortunately, neural networks are known to suffer from various safety and
security issues. Formal verification is a promising avenue for tackling this
difficulty, by formally certifying that networks are correct. We propose an
SMT-based technique for verifying Binarized Neural Networks - a popular kind of
neural network, where some weights have been binarized in order to render the
neural network more memory and energy efficient, and quicker to evaluate. One
novelty of our technique is that it allows the verification of neural networks
that include both binarized and non-binarized components. Neural network
verification is computationally very difficult, and so we propose here various
optimizations, integrated into our SMT procedure as deduction steps, as well as
an approach for parallelizing verification queries. We implement our technique
as an extension to the Marabou framework, and use it to evaluate the approach
on popular binarized neural network architectures.
</p>
<a href="http://arxiv.org/abs/2011.02948" target="_blank">arXiv:2011.02948</a> [<a href="http://arxiv.org/pdf/2011.02948" target="_blank">pdf</a>]

<h2>Performance of Bounded-Rational Agents With the Ability to Self-Modify. (arXiv:2011.06275v2 [cs.AI] UPDATED)</h2>
<h3>Jakub T&#x11b;tek, Marek Sklenka, Tom&#xe1;&#x161; Gaven&#x10d;iak</h3>
<p>Self-modification of agents embedded in complex environments is hard to
avoid, whether it happens via direct means (e.g. own code modification) or
indirectly (e.g. influencing the operator, exploiting bugs or the environment).
It has been argued that intelligent agents have an incentive to avoid modifying
their utility function so that their future instances work towards the same
goals.

Everitt et al. (2016) formally show that providing an option to self-modify
is harmless for perfectly rational agents. We show that this result is no
longer true for agents with bounded rationality. In such agents,
self-modification may cause exponential deterioration in performance and
gradual misalignment of a previously aligned agent. We investigate how the size
of this effect depends on the type and magnitude of imperfections in the
agent's rationality (1-4 below). We also discuss model assumptions and the
wider problem and framing space.

We examine four ways in which an agent can be bounded-rational: it either (1)
doesn't always choose the optimal action, (2) is not perfectly aligned with
human values, (3) has an inaccurate model of the environment, or (4) uses the
wrong temporal discounting factor. We show that while in the cases (2)-(4) the
misalignment caused by the agent's imperfection does not increase over time,
with (1) the misalignment may grow exponentially.
</p>
<a href="http://arxiv.org/abs/2011.06275" target="_blank">arXiv:2011.06275</a> [<a href="http://arxiv.org/pdf/2011.06275" target="_blank">pdf</a>]

<h2>Functorial Manifold Learning. (arXiv:2011.07435v2 [cs.LG] UPDATED)</h2>
<h3>Dan Shiebler</h3>
<p>We adapt previous research on category theory and topological unsupervised
learning to develop a functorial perspective on manifold learning. We first
characterize manifold learning algorithms as functors that map pseudometric
spaces to optimization objectives and factor through hierachical clustering
functors. We then use this characterization to prove refinement bounds on
manifold learning loss functions and construct a hierarchy of manifold learning
algorithms based on their invariants. We express several popular manifold
learning algorithms as functors at different levels of this hierarchy,
including Metric Multidimensional Scaling, IsoMap, Laplacian Eigenmaps, and
UMAP. Next, we use interleaving distance to study the stability of a broad
class of manifold learning algorithms. We present bounds on how closely the
embeddings these algorithms produce from noisy data approximate the embeddings
they would learn from noiseless data. Finally, we use our framework to derive a
set of novel manifold learning algorithms, which we experimentally demonstrate
are competitive with the state of the art.
</p>
<a href="http://arxiv.org/abs/2011.07435" target="_blank">arXiv:2011.07435</a> [<a href="http://arxiv.org/pdf/2011.07435" target="_blank">pdf</a>]

<h2>Challenges in Deploying Machine Learning: a Survey of Case Studies. (arXiv:2011.09926v2 [cs.LG] UPDATED)</h2>
<h3>Andrei Paleyes, Raoul-Gabriel Urma, Neil D. Lawrence</h3>
<p>In recent years, machine learning has received increased interest both as an
academic research field and as a solution for real-world business problems.
However, the deployment of machine learning models in production systems can
present a number of issues and concerns. This survey reviews published reports
of deploying machine learning solutions in a variety of use cases, industries
and applications and extracts practical considerations corresponding to stages
of the machine learning deployment workflow. Our survey shows that
practitioners face challenges at each stage of the deployment. The goal of this
paper is to layout a research agenda to explore approaches addressing these
challenges.
</p>
<a href="http://arxiv.org/abs/2011.09926" target="_blank">arXiv:2011.09926</a> [<a href="http://arxiv.org/pdf/2011.09926" target="_blank">pdf</a>]

<h2>Learning to Assist Drone Landings. (arXiv:2011.13146v2 [cs.RO] UPDATED)</h2>
<h3>Kal Backman, Dana Kuli&#x107;, Hoam Chung</h3>
<p>Unmanned aerial vehicles (UAVs) are often used for navigating dangerous
terrains, however they are difficult to pilot. Due to complex input-output
mapping schemes, limited perception, the complex system dynamics and the need
to maintain a safe operation distance, novice pilots experience difficulties in
performing safe landings in obstacle filled environments. In this work we
propose a shared autonomy approach that assists novice pilots to perform safe
landings on one of several elevated platforms at a proficiency equal to or
greater than experienced pilots. Our approach consists of two modules, a
perceptual module and a policy module. The perceptual module compresses high
dimensionality RGB-D images into a latent vector trained with a cross-modal
variational auto-encoder. The policy module provides assistive control inputs
trained with the reinforcement algorithm TD3. We conduct a user study (n=33)
where participants land a simulated drone with and without the use of the
assistant. Despite the goal platform not being known to the assistant,
participants of all skill levels were able to outperform experienced
participants while assisted in the task.
</p>
<a href="http://arxiv.org/abs/2011.13146" target="_blank">arXiv:2011.13146</a> [<a href="http://arxiv.org/pdf/2011.13146" target="_blank">pdf</a>]

<h2>Semi-supervised Learning for Analysing the Risk of Urinary Tract Infections in People with Dementia. (arXiv:2011.13916v2 [cs.LG] UPDATED)</h2>
<h3>Honglin Li, Payam Barnaghi, Severin Skillman, David Sharp, Ramin Nilforooshan, Helen Rostill</h3>
<p>Machine learning techniques combined with in-home monitoring technologies
provide a unique opportunity to automate diagnosis and early detection of
adverse health conditions in long-term conditions such as dementia. However,
accessing sufficient labelled training samples and integrating high-quality,
routinely collected data from heterogeneous in-home monitoring technologies are
main obstacles hindered utilising these technologies in real-world medicine.
This work presents a semi-supervised model that can continuously learn from
routinely collected in-home observation and measurement data. We show how our
model can process highly imbalanced and dynamic data to make robust predictions
in analysing the risk of Urinary Tract Infections (UTIs) in dementia. UTIs are
common in older adults and constitute one of the main causes of avoidable
hospital admissions in people with dementia (PwD). Health-related conditions,
such as UTI, have a lower prevalence in individuals, which classifies them as
sporadic cases (i.e. rare or scattered, yet important events). This limits the
access to sufficient training data, without which the supervised learning
models risk becoming overfitted or biased. We introduce a probabilistic
semi-supervised learning framework to address these issues. The proposed method
produces a risk analysis score for UTIs using routinely collected data by
in-home sensing technologies.
</p>
<a href="http://arxiv.org/abs/2011.13916" target="_blank">arXiv:2011.13916</a> [<a href="http://arxiv.org/pdf/2011.13916" target="_blank">pdf</a>]

<h2>Use of Remote Sensing Data to Identify Air Pollution Signatures in India. (arXiv:2012.00402v2 [cs.LG] UPDATED)</h2>
<h3>Sivaramakrishnan KN, Lipika Deka, Manik Gupta</h3>
<p>Air quality has major impact on a country's socio-economic position and
identifying major air pollution sources is at the heart of tackling the issue.
Spatially and temporally distributed air quality data acquisition across a
country as varied as India has been a challenge to such analysis. The launch of
the Sentinel-5P satellite has helped in the observation of a wider variety of
air pollutants than measured before at a global scale on a daily basis. In this
chapter, spatio-temporal multi pollutant data retrieved from Sentinel-5P
satellite is used to cluster states as well as districts in India and
associated average monthly pollution signature and trends depicted by each of
the clusters are derived and presented.The clustering signatures can be used to
identify states and districts based on the types of pollutants emitted by
various pollution sources.
</p>
<a href="http://arxiv.org/abs/2012.00402" target="_blank">arXiv:2012.00402</a> [<a href="http://arxiv.org/pdf/2012.00402" target="_blank">pdf</a>]

<h2>DONE: Distributed Approximate Newton-type Method for Federated Edge Learning. (arXiv:2012.05625v2 [cs.LG] UPDATED)</h2>
<h3>Canh T. Dinh, Nguyen H. Tran, Tuan Dung Nguyen, Wei Bao, Amir Rezaei Balef</h3>
<p>There is growing interest in applying distributed machine learning to edge
computing, forming federated edge learning. Federated edge learning faces
non-i.i.d and heterogeneous data, and the communication between edge workers,
possibly through distant locations and with unstable wireless networks, is more
costly than their local computational overhead. Here, we propose DONE, a
distributed approximate Newton-type algorithm with fast convergence rate for
communication-efficient federated edge learning. First, with strongly convex
and smooth loss functions, DONE can approximately produce the Newton direction
in a distributed manner by using the classical Richardson iteration on each
edge worker. Second, we prove that DONE has linear-quadratic convergence and
analyze its computation and communication complexities. Finally, the
experimental results with non-i.i.d. and heterogeneous data show that DONE
attains comparable performance to the Newton's method. Notably, DONE requires
fewer communication iterations compared to distributed gradient descent and
outperforms DANE, a similar and state-of-the-art approach, in the case of
non-quadratic loss functions.
</p>
<a href="http://arxiv.org/abs/2012.05625" target="_blank">arXiv:2012.05625</a> [<a href="http://arxiv.org/pdf/2012.05625" target="_blank">pdf</a>]

<h2>Pseudo Shots: Few-Shot Learning with Auxiliary Data. (arXiv:2012.07176v2 [cs.LG] UPDATED)</h2>
<h3>Reza Esfandiarpoor, Mohsen Hajabdollahi, Stephen H. Bach</h3>
<p>In many practical few-shot learning problems, even though labeled examples
are scarce, there are abundant auxiliary data sets that potentially contain
useful information. We propose a framework to address the challenges of
efficiently selecting and effectively using auxiliary data in image
classification. Given an auxiliary dataset and a notion of semantic similarity
among classes, we automatically select pseudo shots, which are labeled examples
from other classes related to the target task. We show that naively assuming
that these additional examples come from the same distribution as the target
task examples does not significantly improve accuracy. Instead, we propose a
masking module that adjusts the features of auxiliary data to be more similar
to those of the target classes. We show that this masking module can improve
accuracy by up to 18 accuracy points, particularly when the auxiliary data is
semantically distant from the target task. We also show that incorporating
pseudo shots improves over the current state-of-the-art few-shot image
classification scores by an average of 4.81 percentage points of accuracy on
1-shot tasks and an average of 0.31 percentage points on 5-shot tasks.
</p>
<a href="http://arxiv.org/abs/2012.07176" target="_blank">arXiv:2012.07176</a> [<a href="http://arxiv.org/pdf/2012.07176" target="_blank">pdf</a>]

<h2>One-Shot Learning with Triplet Loss for Vegetation Classification Tasks. (arXiv:2012.07403v2 [cs.CV] UPDATED)</h2>
<h3>Alexander Uzhinskiy (1), Gennady Ososkov (1), Pavel Goncharov (1), Andrey Nechaevskiy (1), Artem Smetanin (2) ((1) Joint Institute for Nuclear Research, Dubna, Moscow region, Russia, (2) ITMO University, Saint Petersburg, Russia)</h3>
<p>Triplet loss function is one of the options that can significantly improve
the accuracy of the One-shot Learning tasks. Starting from 2015, many projects
use Siamese networks and this kind of loss for face recognition and object
classification. In our research, we focused on two tasks related to vegetation.
The first one is plant disease detection on 25 classes of five crops (grape,
cotton, wheat, cucumbers, and corn). This task is motivated because harvest
losses due to diseases is a serious problem for both large farming structures
and rural families. The second task is the identification of moss species (5
classes). Mosses are natural bioaccumulators of pollutants; therefore, they are
used in environmental monitoring programs. The identification of moss species
is an important step in the sample preprocessing. In both tasks, we used
self-collected image databases. We tried several deep learning architectures
and approaches. Our Siamese network architecture with a triplet loss function
and MobileNetV2 as a base network showed the most impressive results in both
above-mentioned tasks. The average accuracy for plant disease detection
amounted to over 97.8% and 97.6% for moss species classification.
</p>
<a href="http://arxiv.org/abs/2012.07403" target="_blank">arXiv:2012.07403</a> [<a href="http://arxiv.org/pdf/2012.07403" target="_blank">pdf</a>]

<h2>Policy Gradient RL Algorithms as Directed Acyclic Graphs. (arXiv:2012.07763v2 [cs.LG] UPDATED)</h2>
<h3>Juan Jose Garau Luis</h3>
<p>Meta Reinforcement Learning (RL) methods focus on automating the design of RL
algorithms that generalize to a wide range of environments. The framework
introduced in (Anonymous, 2020) addresses the problem by representing different
RL algorithms as Directed Acyclic Graphs (DAGs), and using an evolutionary meta
learner to modify these graphs and find good agent update rules. While the
search language used to generate graphs in the paper serves to represent
numerous already-existing RL algorithms (e.g., DQN, DDQN), it has limitations
when it comes to representing Policy Gradient algorithms. In this work we try
to close this gap by extending the original search language and proposing
graphs for five different Policy Gradient algorithms: VPG, PPO, DDPG, TD3, and
SAC.
</p>
<a href="http://arxiv.org/abs/2012.07763" target="_blank">arXiv:2012.07763</a> [<a href="http://arxiv.org/pdf/2012.07763" target="_blank">pdf</a>]

<h2>Noisy Linear Convergence of Stochastic Gradient Descent for CV@R Statistical Learning under Polyak-{\L}ojasiewicz Conditions. (arXiv:2012.07785v2 [cs.LG] UPDATED)</h2>
<h3>Dionysios S. Kalogerias</h3>
<p>Conditional Value-at-Risk ($\mathrm{CV@R}$) is one of the most popular
measures of risk, which has been recently considered as a performance criterion
in supervised statistical learning, as it is related to desirable operational
features in modern applications, such as safety, fairness, distributional
robustness, and prediction error stability. However, due to its variational
definition, $\mathrm{CV@R}$ is commonly believed to result in difficult
optimization problems, even for smooth and strongly convex loss functions. We
disprove this statement by establishing noisy (i.e., fixed-accuracy) linear
convergence of stochastic gradient descent for sequential $\mathrm{CV@R}$
learning, for a large class of not necessarily strongly-convex (or even convex)
loss functions satisfying a set-restricted Polyak-Lojasiewicz inequality. This
class contains all smooth and strongly convex losses, confirming that classical
problems, such as linear least squares regression, can be solved efficiently
under the $\mathrm{CV@R}$ criterion, just as their risk-neutral versions. Our
results are illustrated numerically on such a risk-aware ridge regression task,
also verifying their validity in practice.
</p>
<a href="http://arxiv.org/abs/2012.07785" target="_blank">arXiv:2012.07785</a> [<a href="http://arxiv.org/pdf/2012.07785" target="_blank">pdf</a>]

<h2>Graph Neural Networks: Taxonomy, Advances and Trends. (arXiv:2012.08752v2 [cs.LG] UPDATED)</h2>
<h3>Yu Zhou, Haixia Zheng, Xin Huang</h3>
<p>Graph neural networks provide a powerful toolkit for embedding real-world
graphs into low-dimensional spaces according to specific tasks. Up to now,
there have been several surveys on this topic. However, they usually lay
emphasis on different angles so that the readers can not see a panorama of the
graph neural networks. This survey aims to overcome this limitation, and
provide a comprehensive review on the graph neural networks. First of all, we
provide a novel taxonomy for the graph neural networks, and then refer to up to
400 relevant literatures to show the panorama of the graph neural networks. All
of them are classified into the corresponding categories. In order to drive the
graph neural networks into a new stage, we summarize four future research
directions so as to overcome the facing challenges. It is expected that more
and more scholars can understand and exploit the graph neural networks, and use
them in their research community.
</p>
<a href="http://arxiv.org/abs/2012.08752" target="_blank">arXiv:2012.08752</a> [<a href="http://arxiv.org/pdf/2012.08752" target="_blank">pdf</a>]

<h2>GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning. (arXiv:2012.10630v3 [cs.LG] UPDATED)</h2>
<h3>Krishnateja Killamsetty, Durga Sivasubramanian, Ganesh Ramakrishnan, Rishabh Iyer</h3>
<p>Large scale machine learning and deep models are extremely data-hungry.
Unfortunately, obtaining large amounts of labeled data is expensive, and
training state-of-the-art models (with hyperparameter tuning) requires
significant computing resources and time. Secondly, real-world data is noisy
and imbalanced. As a result, several recent papers try to make the training
process more efficient and robust. However, most existing work either focuses
on robustness or efficiency, but not both. In this work, we introduce Glister,
a GeneraLIzation based data Subset selecTion for Efficient and Robust learning
framework. We formulate Glister as a mixed discrete-continuous bi-level
optimization problem to select a subset of the training data, which maximizes
the log-likelihood on a held-out validation set. Next, we propose an iterative
online algorithm Glister-Online, which performs data selection iteratively
along with the parameter updates and can be applied to any loss-based learning
algorithm. We then show that for a rich class of loss functions including
cross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete
data selection is an instance of (weakly) submodular optimization, and we
analyze conditions for which Glister-Online reduces the validation loss and
converges. Finally, we propose Glister-Active, an extension to batch active
learning, and we empirically demonstrate the performance of Glister on a wide
range of tasks including, (a) data selection to reduce training time, (b)
robust learning under label noise and imbalance settings, and (c) batch-active
learning with several deep and shallow models. We show that our framework
improves upon state of the art both in efficiency and accuracy (in cases (a)
and (c)) and is more efficient compared to other state-of-the-art robust
learning algorithms in case (b).
</p>
<a href="http://arxiv.org/abs/2012.10630" target="_blank">arXiv:2012.10630</a> [<a href="http://arxiv.org/pdf/2012.10630" target="_blank">pdf</a>]

<h2>AsymptoticNG: A regularized natural gradient optimization algorithm with look-ahead strategy. (arXiv:2012.13077v2 [cs.LG] UPDATED)</h2>
<h3>Zedong Tang, Fenlong Jiang, Junke Song, Maoguo Gong, Hao Li, Fan Yu, Zidong Wang, Min Wang</h3>
<p>Optimizers that further adjust the scale of gradient, such as Adam, Natural
Gradient (NG), etc., despite widely concerned and used by the community, are
often found poor generalization performance, compared with Stochastic Gradient
Descent (SGD). They tend to converge excellently at the beginning of training
but are weak at the end. An immediate idea is to complement the strengths of
these algorithms with SGD. However, a truncated replacement of optimizer often
leads to a crash of the update pattern, and new algorithms often require many
iterations to stabilize their search direction. Driven by this idea and to
address this problem, we design and present a regularized natural gradient
optimization algorithm with look-ahead strategy, named asymptotic natural
gradient (ANG). According to the total iteration step, ANG dynamic assembles NG
and Euclidean gradient, and updates parameters along the new direction using
the intensity of NG. Validation experiments on CIFAR10 and CIFAR100 data sets
show that ANG can update smoothly and stably at the second-order speed, and
achieve better generalization performance.
</p>
<a href="http://arxiv.org/abs/2012.13077" target="_blank">arXiv:2012.13077</a> [<a href="http://arxiv.org/pdf/2012.13077" target="_blank">pdf</a>]

<h2>Deep Semi-Supervised Embedded Clustering (DSEC) for Stratification of Heart Failure Patients. (arXiv:2012.13233v3 [cs.LG] UPDATED)</h2>
<h3>Oliver Carr, Stojan Jovanovic, Luca Albergante, Fernando Andreotti, Robert D&#xfc;richen, Nadia Lipunova, Janie Baxter, Rabia Khan, Benjamin Irving</h3>
<p>Determining phenotypes of diseases can have considerable benefits for
in-hospital patient care and to drug development. The structure of high
dimensional data sets such as electronic health records are often represented
through an embedding of the data, with clustering methods used to group data of
similar structure. If subgroups are known to exist within data, supervised
methods may be used to influence the clusters discovered. We propose to extend
deep embedded clustering to a semi-supervised deep embedded clustering
algorithm to stratify subgroups through known labels in the data. In this work
we apply deep semi-supervised embedded clustering to determine data-driven
patient subgroups of heart failure from the electronic health records of 4,487
heart failure and control patients. We find clinically relevant clusters from
an embedded space derived from heterogeneous data. The proposed algorithm can
potentially find new undiagnosed subgroups of patients that have different
outcomes, and, therefore, lead to improved treatments.
</p>
<a href="http://arxiv.org/abs/2012.13233" target="_blank">arXiv:2012.13233</a> [<a href="http://arxiv.org/pdf/2012.13233" target="_blank">pdf</a>]

<h2>Logic Tensor Networks. (arXiv:2012.13635v3 [cs.AI] UPDATED)</h2>
<h3>Samy Badreddine, Artur d&#x27;Avila Garcez, Luciano Serafini, Michael Spranger</h3>
<p>Artificial Intelligence agents are required to learn from their surroundings
and to reason about the knowledge that has been learned in order to make
decisions. While state-of-the-art learning from data typically uses
sub-symbolic distributed representations, reasoning is normally useful at a
higher level of abstraction with the use of a first-order logic language for
knowledge representation. As a result, attempts at combining symbolic AI and
neural computation into neural-symbolic systems have been on the increase. In
this paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism
and computational model that supports learning and reasoning through the
introduction of a many-valued, end-to-end differentiable first-order logic
called Real Logic as a representation language for deep learning. We show that
LTN provides a uniform language for the specification and the computation of
several AI tasks such as data clustering, multi-label classification,
relational learning, query answering, semi-supervised learning, regression and
embedding learning. We implement and illustrate each of the above tasks with a
number of simple explanatory examples using TensorFlow 2. Keywords:
Neurosymbolic AI, Deep Learning and Reasoning, Many-valued Logic.
</p>
<a href="http://arxiv.org/abs/2012.13635" target="_blank">arXiv:2012.13635</a> [<a href="http://arxiv.org/pdf/2012.13635" target="_blank">pdf</a>]

<h2>Dual-Refinement: Joint Label and Feature Refinement for Unsupervised Domain Adaptive Person Re-Identification. (arXiv:2012.13689v2 [cs.CV] UPDATED)</h2>
<h3>Yongxing Dai, Jun Liu, Yan Bai, Zekun Tong, Ling-Yu Duan</h3>
<p>Unsupervised domain adaptive (UDA) person re-identification (re-ID) is a
challenging task due to the missing of labels for the target domain data. To
handle this problem, some recent works adopt clustering algorithms to off-line
generate pseudo labels, which can then be used as the supervision signal for
on-line feature learning in the target domain. However, the off-line generated
labels often contain lots of noise that significantly hinders the
discriminability of the on-line learned features, and thus limits the final UDA
re-ID performance. To this end, we propose a novel approach, called
Dual-Refinement, that jointly refines pseudo labels at the off-line clustering
phase and features at the on-line training phase, to alternatively boost the
label purity and feature discriminability in the target domain for more
reliable re-ID. Specifically, at the off-line phase, a new hierarchical
clustering scheme is proposed, which selects representative prototypes for
every coarse cluster. Thus, labels can be effectively refined by using the
inherent hierarchical information of person images. Besides, at the on-line
phase, we propose an instant memory spread-out (IM-spread-out) regularization,
that takes advantage of the proposed instant memory bank to store sample
features of the entire dataset and enable spread-out feature learning over the
entire training data instantly. Our Dual-Refinement method reduces the
influence of noisy labels and refines the learned features within the
alternative training process. Experiments demonstrate that our method
outperforms the state-of-the-art methods by a large margin.
</p>
<a href="http://arxiv.org/abs/2012.13689" target="_blank">arXiv:2012.13689</a> [<a href="http://arxiv.org/pdf/2012.13689" target="_blank">pdf</a>]

<h2>Detecting Anomalous Invoice Line Items in the Legal Case Lifecycle. (arXiv:2012.14511v2 [cs.LG] UPDATED)</h2>
<h3>Valentino Constantinou, Mori Kabiri</h3>
<p>The United States is the largest distributor of legal services in the world,
representing a \$437 billion market. Of this, corporate legal departments pay
law firms \$80 billion for their services. Every month, legal departments
receive and process invoices from these law firms and legal service providers.
Legal invoice review is and has been a pain point for corporate legal
department leaders. Complex and intricate, legal invoices often contain several
hundred line-items that account for anything from tasks such as hands-on legal
work to expenses such as copying, meals, and travel. The man-hours and scrutiny
involved in the invoice review process can be overwhelming. Even with common
safeguards in place, such as established billing guidelines, experienced
invoice reviewers (typically highly paid in-house attorneys), and rule based
electronic billing tools ("e-billing"), many discrepancies go undetected. Using
machine learning, our goal is to demonstrate the current flaws of, and to
explore improvements to, the legal invoice review process for invoices
submitted by law firms to their corporate clients. In this work, we detail our
approach, applying several machine learning model architectures, for detecting
anomalous invoice line-items based on their suitability in the legal case's
lifecycle (modeled using a set of case level and invoice line-item-level
features). We illustrate our approach, which works in the absence of labeled
data, by utilizing a combination of subject matter expertise ("SME") and
synthetic data generation for model training. We characterize our method's
performance using a set of model architectures. We demonstrate how this process
advances solving anomaly detection problems, specifically when the
characteristics of the anomalies are well known, and offer lessons learned from
applying our approach to real-world data.
</p>
<a href="http://arxiv.org/abs/2012.14511" target="_blank">arXiv:2012.14511</a> [<a href="http://arxiv.org/pdf/2012.14511" target="_blank">pdf</a>]

<h2>Gradient Descent Averaging and Primal-dual Averaging for Strongly Convex Optimization. (arXiv:2012.14558v2 [cs.LG] UPDATED)</h2>
<h3>Wei Tao, Wei Li, Zhisong Pan, Qing Tao</h3>
<p>Averaging scheme has attracted extensive attention in deep learning as well
as traditional machine learning. It achieves theoretically optimal convergence
and also improves the empirical model performance. However, there is still a
lack of sufficient convergence analysis for strongly convex optimization.
Typically, the convergence about the last iterate of gradient descent methods,
which is referred to as individual convergence, fails to attain its optimality
due to the existence of logarithmic factor. In order to remove this factor, we
first develop gradient descent averaging (GDA), which is a general
projection-based dual averaging algorithm in the strongly convex setting. We
further present primal-dual averaging for strongly convex cases (SC-PDA), where
primal and dual averaging schemes are simultaneously utilized. We prove that
GDA yields the optimal convergence rate in terms of output averaging, while
SC-PDA derives the optimal individual convergence. Several experiments on SVMs
and deep learning models validate the correctness of theoretical analysis and
effectiveness of algorithms.
</p>
<a href="http://arxiv.org/abs/2012.14558" target="_blank">arXiv:2012.14558</a> [<a href="http://arxiv.org/pdf/2012.14558" target="_blank">pdf</a>]

<h2>Design, Characterization, and Control of a Size Adaptable In-pipe Robot for Water Distribution Systems. (arXiv:2012.15236v2 [cs.RO] UPDATED)</h2>
<h3>Saber Kazeminasab, Ali Akbari, Roozbeh Jafari, M. Katherine Banks</h3>
<p>Leak detection and water quality monitoring are requirements and challenging
tasks in Water Distribution Systems (WDS). In-line robots are designed for this
aim. In our previous work, we designed an in-pipe robot [1]. In this research,
we present the design of the central processor, characterize and control the
robot based on the condition of operation in a highly pressurized environment
of pipelines with the presence of high-speed flow. To this aim, an extreme
operation condition is simulated with computational fluid dynamics (CFD) and
the spring mechanism is characterized to ensure sufficient stabilizing force
during operation based on the extreme operating condition. Also, an end-to-end
method is suggested for power considerations for our robot that calculates
minimum battery capacity and operation duration in the extreme operating
condition. Finally, we design a novel LQR-PID based controller based on the
system auxiliary matrices that retain the robot stability inside the pipeline
against disturbances and uncertainties during operation. The ADAMS-MATLAB
co-simulation of the robot-controller shows the rotational velocity with -4
degree/sec and +3 degree/sec margin around x, y, and z axes while the system
tracks different desired velocities in pipelines (i.e. 0.12m/s, 0.17m/s, and
0.35m/s). Also, experimental results for four iterations in a 14-inch diameter
PVC pipe show that the controller brings initial values of stabilizing states
to zero and oscillate around it with a margin of 2 degrees and the system
tracks desired velocities of 0.1m/s, 0.2m/s, 0.3m/s, and 0.35m/s in which makes
the robot dexterous in uncertain and highly disturbed the environment of
pipelines during operation.
</p>
<a href="http://arxiv.org/abs/2012.15236" target="_blank">arXiv:2012.15236</a> [<a href="http://arxiv.org/pdf/2012.15236" target="_blank">pdf</a>]

<h2>xERTE: Explainable Reasoning on Temporal Knowledge Graphs for Forecasting Future Links. (arXiv:2012.15537v2 [cs.LG] UPDATED)</h2>
<h3>Zhen Han, Peng Chen, Yunpu Ma, Volker Tresp</h3>
<p>Interest has been rising lately towards modeling time-evolving knowledge
graphs (KGs). Recently, graph representation learning approaches have become
the dominant paradigm for link prediction on temporal KGs. However, the
embedding-based approaches largely operate in a black-box fashion, lacking the
ability to judge the results' reliability. This paper provides a future link
forecasting framework that reasons over query-relevant subgraphs of temporal
KGs and jointly models the graph structures and the temporal context
information. Especially, we propose a temporal relational attention mechanism
and a novel reverse representation update scheme to guide the extraction of an
enclosing subgraph around the query. The subgraph is expanded by an iterative
sampling of temporal neighbors and attention propagation. As a result, our
approach provides human-understandable arguments for the prediction. We
evaluate our model on four benchmark temporal knowledge graphs for the link
forecasting task. While being more explainable, our model also obtains a
relative improvement of up to 17.7 $\%$ on MRR compared to the previous best KG
forecasting methods. We also conduct a survey with 53 respondents, and the
results show that the reasoning arguments extracted by the model for link
forecasting are aligned with human understanding.
</p>
<a href="http://arxiv.org/abs/2012.15537" target="_blank">arXiv:2012.15537</a> [<a href="http://arxiv.org/pdf/2012.15537" target="_blank">pdf</a>]

<h2>Reinforcement Learning for Flexibility Design Problems. (arXiv:2101.00355v2 [cs.LG] UPDATED)</h2>
<h3>Yehua Wei, Lei Zhang, Ruiyi Zhang, Shijing Si, Hao Zhang, Lawrence Carin</h3>
<p>Flexibility design problems are a class of problems that appear in strategic
decision-making across industries, where the objective is to design a ($e.g.$,
manufacturing) network that affords flexibility and adaptivity. The underlying
combinatorial nature and stochastic objectives make flexibility design problems
challenging for standard optimization methods. In this paper, we develop a
reinforcement learning (RL) framework for flexibility design problems.
Specifically, we carefully design mechanisms with noisy exploration and
variance reduction to ensure empirical success and show the unique advantage of
RL in terms of fast-adaptation. Empirical results show that the RL-based method
consistently finds better solutions compared to classical heuristics.
</p>
<a href="http://arxiv.org/abs/2101.00355" target="_blank">arXiv:2101.00355</a> [<a href="http://arxiv.org/pdf/2101.00355" target="_blank">pdf</a>]

<h2>Characterizing Intersectional Group Fairness with Worst-Case Comparisons. (arXiv:2101.01673v2 [cs.LG] UPDATED)</h2>
<h3>Avijit Ghosh, Lea Genuit, Mary Reagan</h3>
<p>Machine Learning or Artificial Intelligence algorithms have gained
considerable scrutiny in recent times owing to their propensity towards
imitating and amplifying existing prejudices in society. This has led to a
niche but growing body of work that identifies and attempts to fix these
biases. A first step towards making these algorithms more fair is designing
metrics that measure unfairness. Most existing work in this field deals with
either a binary view of fairness (protected vs. unprotected groups) or
politically defined categories (race or gender). Such categorization misses the
important nuance of intersectionality - biases can often be amplified in
subgroups that combine membership from different categories, especially if such
a subgroup is particularly underrepresented in historical platforms of
opportunity.

In this paper, we discuss why fairness metrics need to be looked at under the
lens of intersectionality, identify existing work in intersectional fairness,
suggest a simple worst case comparison method to expand the definitions of
existing group fairness metrics to incorporate intersectionality, and finally
conclude with the social, legal and political framework to handle
intersectional fairness in the modern context.
</p>
<a href="http://arxiv.org/abs/2101.01673" target="_blank">arXiv:2101.01673</a> [<a href="http://arxiv.org/pdf/2101.01673" target="_blank">pdf</a>]

<h2>Multistage BiCross Encoder: Team GATE Entry for MLIA Multilingual Semantic Search Task 2. (arXiv:2101.03013v2 [cs.AI] UPDATED)</h2>
<h3>Iknoor Singh, Carolina Scarton, Kalina Bontcheva</h3>
<p>The Coronavirus (COVID-19) pandemic has led to a rapidly growing `infodemic'
online. Thus, the accurate retrieval of reliable relevant data from millions of
documents about COVID-19 has become urgently needed for the general public as
well as for other stakeholders. The COVID-19 Multilingual Information Access
(MLIA) initiative is a joint effort to ameliorate exchange of COVID-19 related
information by developing applications and services through research and
community participation. In this work, we present a search system called
Multistage BiCross Encoder, developed by team GATE for the MLIA task 2
Multilingual Semantic Search. Multistage BiCross-Encoder is a sequential three
stage pipeline which uses the Okapi BM25 algorithm and a transformer based
bi-encoder and cross-encoder to effectively rank the documents with respect to
the query. The results of round 1 show that our models achieve state-of-the-art
performance for all ranking metrics for both monolingual and bilingual runs.
</p>
<a href="http://arxiv.org/abs/2101.03013" target="_blank">arXiv:2101.03013</a> [<a href="http://arxiv.org/pdf/2101.03013" target="_blank">pdf</a>]

<h2>Good Students Play Big Lottery Better. (arXiv:2101.03255v2 [cs.LG] UPDATED)</h2>
<h3>Haoyu Ma, Tianlong Chen, Ting-Kuei Hu, Chenyu You, Xiaohui Xie, Zhangyang Wang</h3>
<p>Lottery ticket hypothesis suggests that a dense neural network contains a
sparse sub-network that can match the test accuracy of the original dense net
when trained in isolation from (the same) random initialization. However, the
hypothesis failed to generalize to larger dense networks such as ResNet-50. As
a remedy, recent studies demonstrate that a sparse sub-network can still be
obtained by using a rewinding technique, which is to re-train it from
early-phase training weights or learning rates of the dense model, rather than
from random initialization.

Is rewinding the only or the best way to scale up lottery tickets? This paper
proposes a new, simpler and yet powerful technique for re-training the
sub-network, called "Knowledge Distillation ticket" (KD ticket). Rewinding
exploits the value of inheriting knowledge from the early training phase to
improve lottery tickets in large networks. In comparison, KD ticket addresses a
complementary possibility - inheriting useful knowledge from the late training
phase of the dense model. It is achieved by leveraging the soft labels
generated by the trained dense model to re-train the sub-network, instead of
the hard labels. Extensive experiments are conducted using several large deep
networks (e.g ResNet-50 and ResNet-110) on CIFAR-10 and ImageNet datasets.
Without bells and whistles, when applied by itself, KD ticket performs on par
or better than rewinding, while being nearly free of hyperparameters or ad-hoc
selection. KD ticket can be further applied together with rewinding, yielding
state-of-the-art results for large-scale lottery tickets.
</p>
<a href="http://arxiv.org/abs/2101.03255" target="_blank">arXiv:2101.03255</a> [<a href="http://arxiv.org/pdf/2101.03255" target="_blank">pdf</a>]

<h2>Compliant Fins for Locomotion in Granular Media. (arXiv:2101.03624v2 [cs.RO] UPDATED)</h2>
<h3>Dongting Li, Sichuan Huang, Yong Tang, Junliang Tao, Hamidreza Marvi, Daniel M. Aukes</h3>
<p>In this paper, we present an approach to study the behavior of compliant
plates in granular media and optimize the performance of a robot that utilizes
this technique for mobility. From previous work and fundamental tests on thin
plate force generation inside granular media, we introduce an origami-inspired
mechanism with non-linear compliance in the joints that can be used in granular
propulsion. This concept utilizes one-sided joint limits to create an
asymmetric gait cycle that avoids more complicated alternatives often found in
other swimming/digging robots. To analyze its locomotion as well as its shape
and propulsive force, we utilize granular Resistive Force Theory (RFT) as a
starting point. Adding compliance to this theory enables us to predict the
time-based evolution of compliant plates when they are dragged and rotated. It
also permits more rational design of swimming robots where fin design variables
may be optimized against the characteristics of the granular medium. This is
done using a Python-based dynamic simulation library to model the deformation
of the plates and optimize aspects of the robot's gait. Finally, we prototype
and test robot with a gait optimized using the modelling techniques mentioned
above.
</p>
<a href="http://arxiv.org/abs/2101.03624" target="_blank">arXiv:2101.03624</a> [<a href="http://arxiv.org/pdf/2101.03624" target="_blank">pdf</a>]

<h2>The Gaze and Mouse Signal as additional Source for User Fingerprints in Browser Applications. (arXiv:2101.03793v2 [cs.CV] UPDATED)</h2>
<h3>Wolfgang Fuhl, Nikolai Sanamrad, Enkelejda Kasneci</h3>
<p>In this work we inspect different data sources for browser fingerprints. We
show which disadvantages and limitations browser statistics have and how this
can be avoided with other data sources. Since human visual behavior is a rich
source of information and also contains person specific information, it is a
valuable source for browser fingerprints. However, human gaze acquisition in
the browser also has disadvantages, such as inaccuracies via webcam and the
restriction that the user must first allow access to the camera. However, it is
also known that the mouse movements and the human gaze correlate and therefore,
the mouse movements can be used instead of the gaze signal. In our evaluation
we show the influence of all possible combinations of the three information
sources for user recognition and describe our simple approach in detail. The
data and the Matlab code can be downloaded here
https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/?p=%2FThe%20Gaze%20and%20Mouse%20Signal%20as%20additional%20Source%20...&amp;mode=list
</p>
<a href="http://arxiv.org/abs/2101.03793" target="_blank">arXiv:2101.03793</a> [<a href="http://arxiv.org/pdf/2101.03793" target="_blank">pdf</a>]

<h2>Lesion2Vec: Deep Metric Learning for Few-Shot Multiple Lesions Recognition in Wireless Capsule Endoscopy Video. (arXiv:2101.04240v2 [cs.CV] UPDATED)</h2>
<h3>Sodiq Adewole, Philip Fernandez, Michelle Yeghyayan, James Jablonski, Andrew Copland, Michael Porter, Sana Syed, Donald Brown</h3>
<p>Effective and rapid detection of lesions in the Gastrointestinal tract is
critical to gastroenterologist's response to some life-threatening diseases.
Wireless Capsule Endoscopy (WCE) has revolutionized traditional endoscopy
procedure by allowing gastroenterologists visualize the entire GI tract
non-invasively. Once the tiny capsule is swallowed, it sequentially capture
images of the GI tract at about 2 to 6 frames per second (fps). A single video
can last up to 8 hours producing between 30,000 to 100,000 images. Automating
the detection of frames containing specific lesion in WCE video would relieve
gastroenterologists the arduous task of reviewing the entire video before
making diagnosis. While the WCE produces large volume of images, only about 5\%
of the frames contain lesions that aid the diagnosis process. Convolutional
Neural Network (CNN) based models have been very successful in various image
classification tasks. However, they suffer excessive parameters, are sample
inefficient and rely on very large amount of training data. Deploying a CNN
classifier for lesion detection task will require time-to-time fine-tuning to
generalize to any unforeseen category. In this paper, we propose a metric-based
learning framework followed by a few-shot lesion recognition in WCE data.
Metric-based learning is a meta-learning framework designed to establish
similarity or dissimilarity between concepts while few-shot learning (FSL) aims
to identify new concepts from only a small number of examples. We train a
feature extractor to learn a representation for different small bowel lesions
using metric-based learning. At the testing stage, the category of an unseen
sample is predicted from only a few support examples, thereby allowing the
model to generalize to a new category that has never been seen before. We
demonstrated the efficacy of this method on real patient capsule endoscopy
data.
</p>
<a href="http://arxiv.org/abs/2101.04240" target="_blank">arXiv:2101.04240</a> [<a href="http://arxiv.org/pdf/2101.04240" target="_blank">pdf</a>]

<h2>Resolution-invariant Person ReID Based on Feature Transformation and Self-weighted Attention. (arXiv:2101.04544v2 [cs.CV] UPDATED)</h2>
<h3>Ziyue Zhang, Shuai Jiang, Congzhentao Huang, Richard Yi Da Xu</h3>
<p>Person Re-identification (ReID) is a critical computer vision task which aims
to match the same person in images or video sequences. Most current works focus
on settings where the resolution of images is kept the same. However, the
resolution is a crucial factor in person ReID, especially when the cameras are
at different distances from the person or the camera's models are different
from each other. In this paper, we propose a novel two-stream network with a
lightweight resolution association ReID feature transformation (RAFT) module
and a self-weighted attention (SWA) ReID module to evaluate features under
different resolutions. RAFT transforms the low resolution features to
corresponding high resolution features. SWA evaluates both features to get
weight factors for the person ReID. Both modules are jointly trained to get a
resolution-invariant representation. Extensive experiments on five benchmark
datasets show the effectiveness of our method. For instance, we achieve Rank-1
accuracy of 43.3% and 83.2% on CAVIAR and MLR-CUHK03, outperforming the
state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2101.04544" target="_blank">arXiv:2101.04544</a> [<a href="http://arxiv.org/pdf/2101.04544" target="_blank">pdf</a>]

<h2>Random Shadows and Highlights: A new data augmentation method for extreme lighting conditions. (arXiv:2101.05361v2 [cs.CV] UPDATED)</h2>
<h3>Osama Mazhar, Jens Kober</h3>
<p>In this paper, we propose a new data augmentation method, Random Shadows and
Highlights (RSH) to acquire robustness against lighting perturbations. Our
method creates random shadows and highlights on images, thus challenging the
neural network during the learning process such that it acquires immunity
against such input corruptions in real world applications. It is a
parameter-learning free method which can be integrated into most vision related
learning applications effortlessly. With extensive experimentation, we
demonstrate that RSH not only increases the robustness of the models against
lighting perturbations, but also reduces over-fitting significantly. Thus RSH
should be considered essential for all vision related learning systems. Code is
available at: https://github.com/OsamaMazhar/Random-Shadows-Highlights.
</p>
<a href="http://arxiv.org/abs/2101.05361" target="_blank">arXiv:2101.05361</a> [<a href="http://arxiv.org/pdf/2101.05361" target="_blank">pdf</a>]

<h2>Understanding the Role of Scene Graphs in Visual Question Answering. (arXiv:2101.05479v2 [cs.CV] UPDATED)</h2>
<h3>Vinay Damodaran, Sharanya Chakravarthy, Akshay Kumar, Anjana Umapathy, Teruko Mitamura, Yuta Nakashima, Noa Garcia, Chenhui Chu</h3>
<p>Visual Question Answering (VQA) is of tremendous interest to the research
community with important applications such as aiding visually impaired users
and image-based search. In this work, we explore the use of scene graphs for
solving the VQA task. We conduct experiments on the GQA dataset which presents
a challenging set of questions requiring counting, compositionality and
advanced reasoning capability, and provides scene graphs for a large number of
images. We adopt image + question architectures for use with scene graphs,
evaluate various scene graph generation techniques for unseen images, propose a
training curriculum to leverage human-annotated and auto-generated scene
graphs, and build late fusion architectures to learn from multiple image
representations. We present a multi-faceted study into the use of scene graphs
for VQA, making this work the first of its kind.
</p>
<a href="http://arxiv.org/abs/2101.05479" target="_blank">arXiv:2101.05479</a> [<a href="http://arxiv.org/pdf/2101.05479" target="_blank">pdf</a>]

<h2>Road Surface Translation Under Snow-covered and Semantic Segmentation for Snow Hazard Index. (arXiv:2101.05616v2 [cs.CV] UPDATED)</h2>
<h3>Yasuno Takato, Fujii Junichiro, Sugawara Hiroaki, Amakata Masazumi</h3>
<p>In 2020, record heavy snowfall have been occurred owing to climate change.
Actually, 2,000 vehicles on the highway could get stuck for three days. Due to
the freezing of the road surface, 10 vehicles could have a billiard accident.
Road managers are required to provide them immediately in order to alert
drivers to snow cover at hazardous location. This paper proposes a deep
learning application with CCTV image post-processing to automatically calculate
a snow hazard indicator. First, the road surface of hidden region under
snow-covered is translated using generative adversarial network, pix2pix.
Second, snow-covered and road surface classes are detected using semantic
segmentation, DeepLabv3+ under backbone MobileNet. Based on these trained
networks, we enable to automatically compute the road to snow rate hazard index
how much snow is covered on the road surface. We demonstrate the applied
results to 1,000 CCTV snow images on Hokkaido and North Tohoku area in Japan.
We mention the usefulness and the practical robustness.
</p>
<a href="http://arxiv.org/abs/2101.05616" target="_blank">arXiv:2101.05616</a> [<a href="http://arxiv.org/pdf/2101.05616" target="_blank">pdf</a>]

<h2>Analysis of hidden feedback loops in continuous machine learning systems. (arXiv:2101.05673v2 [cs.LG] UPDATED)</h2>
<h3>Anton Khritankov</h3>
<p>In this concept paper, we discuss intricacies of specifying and verifying the
quality of continuous and lifelong learning artificial intelligence systems as
they interact with and influence their environment causing a so-called concept
drift. We signify a problem of implicit feedback loops, demonstrate how they
intervene with user behavior on an exemplary housing prices prediction system.
Based on a preliminary model, we highlight conditions when such feedback loops
arise and discuss possible solution approaches.
</p>
<a href="http://arxiv.org/abs/2101.05673" target="_blank">arXiv:2101.05673</a> [<a href="http://arxiv.org/pdf/2101.05673" target="_blank">pdf</a>]

<h2>Supervised Transfer Learning at Scale for Medical Imaging. (arXiv:2101.05913v2 [cs.CV] UPDATED)</h2>
<h3>Basil Mustafa, Aaron Loh, Jan Freyberg, Patricia MacWilliams, Alan Karthikesalingam, Neil Houlsby, Vivek Natarajan</h3>
<p>Transfer learning is a standard technique to improve performance on tasks
with limited data. However, for medical imaging, the value of transfer learning
is less clear. This is likely due to the large domain mismatch between the
usual natural-image pre-training (e.g. ImageNet) and medical images. However,
recent advances in transfer learning have shown substantial improvements from
scale. We investigate whether modern methods can change the fortune of transfer
learning for medical imaging. For this, we study the class of large-scale
pre-trained networks presented by Kolesnikov et al. on three diverse imaging
tasks: chest radiography, mammography, and dermatology. We study both transfer
performance and critical properties for the deployment in the medical domain,
including: out-of-distribution generalization, data-efficiency, sub-group
fairness, and uncertainty estimation. Interestingly, we find that for some of
these properties transfer from natural to medical images is indeed extremely
effective, but only when performed at sufficient scale.
</p>
<a href="http://arxiv.org/abs/2101.05913" target="_blank">arXiv:2101.05913</a> [<a href="http://arxiv.org/pdf/2101.05913" target="_blank">pdf</a>]

<h2>Complexity Results and Algorithms for Bipolar Argumentation. (arXiv:1903.01964v1 [cs.AI] CROSS LISTED)</h2>
<h3>Amin Karamlou, Kristijonas &#x10c;yras, Francesca Toni</h3>
<p>Bipolar Argumentation Frameworks (BAFs) admit several interpretations of the
support relation and diverging definitions of semantics. Recently, several
classes of BAFs have been captured as instances of bipolar Assumption-Based
Argumentation, a class of Assumption-Based Argumentation (ABA). In this paper,
we establish the complexity of bipolar ABA, and consequently of several classes
of BAFs. In addition to the standard five complexity problems, we analyse the
rarely-addressed extension enumeration problem too. We also advance
backtracking-driven algorithms for enumerating extensions of bipolar ABA
frameworks, and consequently of BAFs under several interpretations. We prove
soundness and completeness of our algorithms, describe their implementation and
provide a scalability evaluation. We thus contribute to the study of the as yet
uninvestigated complexity problems of (variously interpreted) BAFs as well as
of bipolar ABA, and provide the lacking implementations thereof.
</p>
<a href="http://arxiv.org/abs/1903.01964" target="_blank">arXiv:1903.01964</a> [<a href="http://arxiv.org/pdf/1903.01964" target="_blank">pdf</a>]

<h2>Stabilizing Differentiable Architecture Search via Perturbation-based Regularization. (arXiv:2002.05283v3 [cs.LG] CROSS LISTED)</h2>
<h3>Xiangning Chen, Cho-Jui Hsieh</h3>
<p>Differentiable architecture search (DARTS) is a prevailing NAS solution to
identify architectures. Based on the continuous relaxation of the architecture
space, DARTS learns a differentiable architecture weight and largely reduces
the search cost. However, its stability has been challenged for yielding
deteriorating architectures as the search proceeds. We find that the
precipitous validation loss landscape, which leads to a dramatic performance
drop when distilling the final architecture, is an essential factor that causes
instability. Based on this observation, we propose a perturbation-based
regularization - SmoothDARTS (SDARTS), to smooth the loss landscape and improve
the generalizability of DARTS-based methods. In particular, our new
formulations stabilize DARTS-based methods by either random smoothing or
adversarial attack. The search trajectory on NAS-Bench-1Shot1 demonstrates the
effectiveness of our approach and due to the improved stability, we achieve
performance gain across various search spaces on 4 datasets. Furthermore, we
mathematically show that SDARTS implicitly regularizes the Hessian norm of the
validation loss, which accounts for a smoother loss landscape and improved
performance.
</p>
<a href="http://arxiv.org/abs/2002.05283" target="_blank">arXiv:2002.05283</a> [<a href="http://arxiv.org/pdf/2002.05283" target="_blank">pdf</a>]

<h2>Machine Reasoning Explainability. (arXiv:2009.00418v2 [cs.AI] CROSS LISTED)</h2>
<h3>Kristijonas Cyras, Ramamurthy Badrinath, Swarup Kumar Mohalik, Anusha Mujumdar, Alexandros Nikou, Alessandro Previti, Vaishnavi Sundararajan, Aneta Vulgarakis Feljan</h3>
<p>As a field of AI, Machine Reasoning (MR) uses largely symbolic means to
formalize and emulate abstract reasoning. Studies in early MR have notably
started inquiries into Explainable AI (XAI) -- arguably one of the biggest
concerns today for the AI community. Work on explainable MR as well as on MR
approaches to explainability in other areas of AI has continued ever since. It
is especially potent in modern MR branches, such as argumentation, constraint
and logic programming, planning. We hereby aim to provide a selective overview
of MR explainability techniques and studies in hopes that insights from this
long track of research will complement well the current XAI landscape. This
document reports our work in-progress on MR explainability.
</p>
<a href="http://arxiv.org/abs/2009.00418" target="_blank">arXiv:2009.00418</a> [<a href="http://arxiv.org/pdf/2009.00418" target="_blank">pdf</a>]

<h2>On Data-Augmentation and Consistency-Based Semi-Supervised Learning. (arXiv:2101.06967v1 [stat.ML])</h2>
<h3>Atin Ghosh, Alexandre H. Thiery</h3>
<p>Recently proposed consistency-based Semi-Supervised Learning (SSL) methods
such as the $\Pi$-model, temporal ensembling, the mean teacher, or the virtual
adversarial training, have advanced the state of the art in several SSL tasks.
These methods can typically reach performances that are comparable to their
fully supervised counterparts while using only a fraction of labelled examples.
Despite these methodological advances, the understanding of these methods is
still relatively limited. In this text, we analyse (variations of) the
$\Pi$-model in settings where analytically tractable results can be obtained.
We establish links with Manifold Tangent Classifiers and demonstrate that the
quality of the perturbations is key to obtaining reasonable SSL performances.
Importantly, we propose a simple extension of the Hidden Manifold Model that
naturally incorporates data-augmentation schemes and offers a framework for
understanding and experimenting with SSL methods.
</p>
<a href="http://arxiv.org/abs/2101.06967" target="_blank">arXiv:2101.06967</a> [<a href="http://arxiv.org/pdf/2101.06967" target="_blank">pdf</a>]

<h2>Interactive slice visualization for exploring machine learning models. (arXiv:2101.06986v1 [stat.ML])</h2>
<h3>Catherine B. Hurley, Mark O&#x27;Connell, Katarina Domijan</h3>
<p>Machine learning models fit complex algorithms to arbitrarily large datasets.
These algorithms are well-known to be high on performance and low on
interpretability. We use interactive visualization of slices of predictor space
to address the interpretability deficit; in effect opening up the black-box of
machine learning algorithms, for the purpose of interrogating, explaining,
validating and comparing model fits. Slices are specified directly through
interaction, or using various touring algorithms designed to visit
high-occupancy sections or regions where the model fits have interesting
properties. The methods presented here are implemented in the R package
\pkg{condvis2}.
</p>
<a href="http://arxiv.org/abs/2101.06986" target="_blank">arXiv:2101.06986</a> [<a href="http://arxiv.org/pdf/2101.06986" target="_blank">pdf</a>]

<h2>Regularized Policies are Reward Robust. (arXiv:2101.07012v1 [cs.LG])</h2>
<h3>Hisham Husain, Kamil Ciosek, Ryota Tomioka</h3>
<p>Entropic regularization of policies in Reinforcement Learning (RL) is a
commonly used heuristic to ensure that the learned policy explores the
state-space sufficiently before overfitting to a local optimal policy. The
primary motivation for using entropy is for exploration and disambiguating
optimal policies; however, the theoretical effects are not entirely understood.
In this work, we study the more general regularized RL objective and using
Fenchel duality; we derive the dual problem which takes the form of an
adversarial reward problem. In particular, we find that the optimal policy
found by a regularized objective is precisely an optimal policy of a
reinforcement learning problem under a worst-case adversarial reward. Our
result allows us to reinterpret the popular entropic regularization scheme as a
form of robustification. Furthermore, due to the generality of our results, we
apply to other existing regularization schemes. Our results thus give insights
into the effects of regularization of policies and deepen our understanding of
exploration through robust rewards at large.
</p>
<a href="http://arxiv.org/abs/2101.07012" target="_blank">arXiv:2101.07012</a> [<a href="http://arxiv.org/pdf/2101.07012" target="_blank">pdf</a>]

<h2>Mind the Gap when Conditioning Amortised Inference in Sequential Latent-Variable Models. (arXiv:2101.07046v1 [cs.LG])</h2>
<h3>Justin Bayer, Maximilian Soelch, Atanas Mirchev, Baris Kayalibay, Patrick van der Smagt</h3>
<p>Amortised inference enables scalable learning of sequential latent-variable
models (LVMs) with the evidence lower bound (ELBO). In this setting,
variational posteriors are often only partially conditioned. While the true
posteriors depend, e.g., on the entire sequence of observations, approximate
posteriors are only informed by past observations. This mimics the Bayesian
filter -- a mixture of smoothing posteriors. Yet, we show that the ELBO
objective forces partially-conditioned amortised posteriors to approximate
products of smoothing posteriors instead. Consequently, the learned generative
model is compromised. We demonstrate these theoretical findings in three
scenarios: traffic flow, handwritten digits, and aerial vehicle dynamics. Using
fully-conditioned approximate posteriors, performance improves in terms of
generative modelling and multi-step prediction.
</p>
<a href="http://arxiv.org/abs/2101.07046" target="_blank">arXiv:2101.07046</a> [<a href="http://arxiv.org/pdf/2101.07046" target="_blank">pdf</a>]

<h2>Reducing bias and increasing utility by federated generative modeling of medical images using a centralized adversary. (arXiv:2101.07235v1 [stat.ML])</h2>
<h3>Jean-Francois Rajotte, Sumit Mukherjee, Caleb Robinson, Anthony Ortiz, Christopher West, Juan Lavista Ferres, Raymond T Ng</h3>
<p>We introduce FELICIA (FEderated LearnIng with a CentralIzed Adversary) a
generative mechanism enabling collaborative learning. In particular, we show
how a data owner with limited and biased data could benefit from other data
owners while keeping data from all the sources private. This is a common
scenario in medical image analysis where privacy legislation prevents data from
being shared outside local premises. FELICIA works for a large family of
Generative Adversarial Networks (GAN) architectures including vanilla and
conditional GANs as demonstrated in this work. We show that by using the
FELICIA mechanism, a data owner with limited image samples can generate
high-quality synthetic images with high utility while neither data owners has
to provide access to its data. The sharing happens solely through a central
discriminator that has access limited to synthetic data. Here, utility is
defined as classification performance on a real test set. We demonstrate these
benefits on several realistic healthcare scenarions using benchmark image
datasets (MNIST, CIFAR-10) as well as on medical images for the task of skin
lesion classification. With multiple experiments, we show that even in the
worst cases, combining FELICIA with real data gracefully achieves performance
on par with real data while most results significantly improves the utility.
</p>
<a href="http://arxiv.org/abs/2101.07235" target="_blank">arXiv:2101.07235</a> [<a href="http://arxiv.org/pdf/2101.07235" target="_blank">pdf</a>]

