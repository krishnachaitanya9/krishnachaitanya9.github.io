---
title: Latest Deep Learning Papers
date: 2020-10-23 21:08:06 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Precise Statistical Analysis of Classification Accuracies for Adversarial Training. (arXiv:2010.11213v1 [stat.ML])</h2>
<h3>Adel Javanmard, Mahdi Soltanolkotabi</h3>
<p>Despite the wide empirical success of modern machine learning algorithms and
models in a multitude of applications, they are known to be highly susceptible
to seemingly small indiscernible perturbations to the input data known as
adversarial attacks. A variety of recent adversarial training procedures have
been proposed to remedy this issue. Despite the success of such procedures at
increasing accuracy on adversarially perturbed inputs or robust accuracy, these
techniques often reduce accuracy on natural unperturbed inputs or standard
accuracy. Complicating matters further the effect and trend of adversarial
training procedures on standard and robust accuracy is rather counter intuitive
and radically dependent on a variety of factors including the perceived form of
the perturbation during training, size/quality of data, model
overparameterization, etc. In this paper we focus on binary classification
problems where the data is generated according to the mixture of two Gaussians
with general anisotropic covariance matrices and derive a precise
characterization of the standard and robust accuracy for a class of minimax
adversarially trained models. We consider a general norm-based adversarial
model, where the adversary can add perturbations of bounded $\ell_p$ norm to
each input data, for an arbitrary $p\ge 1$. Our comprehensive analysis allows
us to theoretically explain several intriguing empirical phenomena and provide
a precise understanding of the role of different problem parameters on standard
and robust accuracies.
</p>
<a href="http://arxiv.org/abs/2010.11213" target="_blank">arXiv:2010.11213</a> [<a href="http://arxiv.org/pdf/2010.11213" target="_blank">pdf</a>]

<h2>Full-Duplex and Dynamic-TDD: Pushing the Limits of Spectrum Reuse in Multi-Cell Communications. (arXiv:2010.11317v1 [cs.IT])</h2>
<h3>Jos&#xe9; Mairton B. da Silva Jr., Gustav Wikstr&#xf6;m, Ratheesh K. Mungara, Carlo Fischione</h3>
<p>Although in cellular networks full-duplex and dynamic time-division duplexing
promise increased spectrum efficiency, their potential is so far challenged by
increased interference. While previous studies have shown that
self-interference can be suppressed to a sufficient level, we show that the
cross-link interference for both duplexing modes, especially from base station
to base station, is the remaining challenge in multi-cell networks, restricting
the uplink performance. Using beamforming techniques of low-complexity, we show
that this interference can be mitigated, and that full-duplex and dynamic
time-division duplexing can substantially increase the capacity of multi-cell
networks. Our results suggest that if we can control the cross link
interference in full-duplex, then we can almost double the multi cell network
capacity as well as user throughput. Therefore, the techniques in this paper
have the potentiality to enable a smooth introduction of full-duplex into
cellular systems.
</p>
<a href="http://arxiv.org/abs/2010.11317" target="_blank">arXiv:2010.11317</a> [<a href="http://arxiv.org/pdf/2010.11317" target="_blank">pdf</a>]

<h2>MRI Image Recovery using Damped Denoising Vector AMP. (arXiv:2010.11321v1 [cs.IT])</h2>
<h3>Subrata Sarkar, Rizwan Ahmad, Philip Schniter</h3>
<p>Motivated by image recovery in magnetic resonance imaging (MRI), we propose a
new approach to solving linear inverse problems based on iteratively calling a
deep neural-network, sometimes referred to as plug-and-play recovery. Our
approach is based on the vector approximate message passing (VAMP) algorithm,
which is known for mean-squared error (MSE)-optimal recovery under certain
conditions. The forward operator in MRI, however, does not satisfy these
conditions, and thus we design new damping and initialization schemes to help
VAMP. The resulting DD-VAMP++ algorithm is shown to outperform existing
algorithms in convergence speed and accuracy when recovering images from the
fastMRI database for the practical case of Cartesian sampling.
</p>
<a href="http://arxiv.org/abs/2010.11321" target="_blank">arXiv:2010.11321</a> [<a href="http://arxiv.org/pdf/2010.11321" target="_blank">pdf</a>]

<h2>Density of States Graph Kernels. (arXiv:2010.11341v1 [cs.LG])</h2>
<h3>Leo Huang, Andrew Graven, David Bindel</h3>
<p>An important problem on graph-structured data is that of quantifying
similarity between graphs. Graph kernels are an established technique for such
tasks; in particular, those based on random walks and return probabilities have
proven to be effective in wide-ranging applications, from bioinformatics to
social networks to computer vision. However, random walk kernels generally
suffer from slowness and tottering, an effect which causes walks to
overemphasize local graph topology, undercutting the importance of global
structure. To correct for these issues, we recast return probability graph
kernels under the more general framework of density of states -- a framework
which uses the lens of spectral analysis to uncover graph motifs and properties
hidden within the interior of the spectrum -- and use our interpretation to
construct scalable, composite density of states based graph kernels which
balance local and global information, leading to higher classification
accuracies on a host of benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2010.11341" target="_blank">arXiv:2010.11341</a> [<a href="http://arxiv.org/pdf/2010.11341" target="_blank">pdf</a>]

<h2>Sample Efficient Reinforcement Learning with REINFORCE. (arXiv:2010.11364v1 [cs.LG])</h2>
<h3>Junzi Zhang, Jongho Kim, Brendan O&#x27;Donoghue, Stephen Boyd</h3>
<p>Policy gradient methods are among the most effective methods for large-scale
reinforcement learning, and their empirical success has prompted several works
that develop the foundation of their global convergence theory. However, prior
works have either required exact gradients or state-action visitation measure
based mini-batch stochastic gradients with a diverging batch size, which limit
their applicability in practical scenarios. In this paper, we consider
classical policy gradient methods that compute an approximate gradient with a
single trajectory or a fixed size mini-batch of trajectories, along with the
widely-used REINFORCE gradient estimation procedure. By controlling the number
of "bad" episodes and resorting to the classical doubling trick, we establish
an anytime sub-linear high probability regret bound as well as almost sure
global convergence of the average regret with an asymptotically sub-linear
rate. These provide the first set of global convergence and sample efficiency
results for the well-known REINFORCE algorithm and contribute to a better
understanding of its performance in practice.
</p>
<a href="http://arxiv.org/abs/2010.11364" target="_blank">arXiv:2010.11364</a> [<a href="http://arxiv.org/pdf/2010.11364" target="_blank">pdf</a>]

<h2>The Minkowski problem based on the (p,q)-mixed quermassintegrals. (arXiv:2010.11373v1 [math.DG])</h2>
<h3>Bin Chen, Weidong Wang, Peibiao Zhao</h3>
<p>Lutwak, Yang and Zhang [23] introduced the concept of Lp dual curvature
measure for convex bodies and star bodies, and studied the Minkowski problem.
We in this paper establish a new unified concept, in briefly, the (p,q)-mixed
quermassintegrals, via (p,q)-dual mixed curvature measure, and further have a
deep discussion on Minkowski problem with respect to the (p,q)-dual mixed
curvature measure. By the way, we derive at some important properties and
geometric inequalities for (p,q)-mixed quermassintegrals.
</p>
<a href="http://arxiv.org/abs/2010.11373" target="_blank">arXiv:2010.11373</a> [<a href="http://arxiv.org/pdf/2010.11373" target="_blank">pdf</a>]

<h2>Nonvacuous Loss Bounds with Fast Rates for Neural Networks via Conditional Information Measures. (arXiv:2010.11552v1 [cs.LG])</h2>
<h3>Fredrik Hellstr&#xf6;m, Giuseppe Durisi</h3>
<p>We present a framework to derive bounds on the test loss of randomized
learning algorithms for the case of bounded loss functions. This framework
leads to bounds that depend on the conditional information density between the
the output hypothesis and the choice of the training set, given a larger set of
data samples from which the training set is formed. Furthermore, the bounds
pertain to the average test loss as well as to its tail probability, both for
the PAC-Bayesian and the single-draw settings. If the conditional information
density is bounded uniformly in the size $n$ of the training set, our bounds
decay as $1/n$, which is referred to as a fast rate. This is in contrast with
the tail bounds involving conditional information measures available in the
literature, which have a less benign $1/\sqrt{n}$ dependence. We demonstrate
the usefulness of our tail bounds by showing that they lead to estimates of the
test loss achievable with several neural network architectures trained on MNIST
and Fashion-MNIST that match the state-of-the-art bounds available in the
literature.
</p>
<a href="http://arxiv.org/abs/2010.11552" target="_blank">arXiv:2010.11552</a> [<a href="http://arxiv.org/pdf/2010.11552" target="_blank">pdf</a>]

<h2>Learning Graph Laplacian with MCP. (arXiv:2010.11559v1 [cs.LG])</h2>
<h3>Yangjing Zhang, Kim-Chuan Toh, Defeng Sun</h3>
<p>Motivated by the observation that the ability of the $\ell_1$ norm in
promoting sparsity in graphical models with Laplacian constraints is much
weakened, this paper proposes to learn graph Laplacian with a non-convex
penalty: minimax concave penalty (MCP). For solving the MCP penalized graphical
model, we design an inexact proximal difference-of-convex algorithm (DCA) and
prove its convergence to critical points. We note that each subproblem of the
proximal DCA enjoys the nice property that the objective function in its dual
problem is continuously differentiable with a semismooth gradient. Therefore,
we apply an efficient semismooth Newton method to subproblems of the proximal
DCA. Numerical experiments on various synthetic and real data sets demonstrate
the effectiveness of the non-convex penalty MCP in promoting sparsity. Compared
with the state-of-the-art method \cite[Algorithm~1]{ying2020does}, our method
is demonstrated to be more efficient and reliable for learning graph Laplacian
with MCP.
</p>
<a href="http://arxiv.org/abs/2010.11559" target="_blank">arXiv:2010.11559</a> [<a href="http://arxiv.org/pdf/2010.11559" target="_blank">pdf</a>]

<h2>Performance Analysis and Optimization for the MAC Protocol in UAV-based IoT Network. (arXiv:2010.11623v1 [cs.IT])</h2>
<h3>Bin Li, Xianzhen Guo, Ruonan Zhang, Xiaojiang Du (Fellow, IEEE), Mohsen Guizani (Fellow, IEEE)</h3>
<p>Unmanned aerial vehicles (UAVs) have played an important role in air-ground
integration network. Especially in Internet of Things (IoT) services, UAV
equipped with communication equipments is widely adopted as a mobile base
station (BS) for data collection from IoT devices on the ground. In this paper,
we consider an air-ground network in which the UAV flies straightly to collect
information from the IoT devices in a 2-D plane based on the CSMA/CA protocol.
Due to UAV's continuous mobility, the communication durations of devices in
different locations with UAV are not only time-limited, but also vary from each
other. To analyze the throughput performance of uplink multiple access control
(MAC) protocol, we propose a new analysis model to deal with the communications
heterogeneity in the network. Firstly, we divide the devices in the coverage
into different clusters according to their communication durations. Then, a
quitting probability indicating the probability that a device quits the UAV's
coverage at each time slot is clarified. A modified three-dimensional Markov
chain model adopting the quitting probability and cluster division is developed
for the performance analysis. Besides, we also propose a modified CSMA/CA
protocol which fully considers the heterogeneity of the access time and
adaptively allocates the time resource among the devices in different clusters.
Finally, the effects of retry limit, initial contention window size, the
density of the devices, UAVs speed and coverage area are discussed in the
simulation section.
</p>
<a href="http://arxiv.org/abs/2010.11623" target="_blank">arXiv:2010.11623</a> [<a href="http://arxiv.org/pdf/2010.11623" target="_blank">pdf</a>]

<h2>Efficient Projection-Free Algorithms for Saddle Point Problems. (arXiv:2010.11737v1 [math.OC])</h2>
<h3>Cheng Chen, Luo Luo, Weinan Zhang, Yong Yu</h3>
<p>The Frank-Wolfe algorithm is a classic method for constrained optimization
problems. It has recently been popular in many machine learning applications
because its projection-free property leads to more efficient iterations. In
this paper, we study projection-free algorithms for convex-strongly-concave
saddle point problems with complicated constraints. Our method combines
Conditional Gradient Sliding with Mirror-Prox and shows that it only requires
$\tilde{O}(1/\sqrt{\epsilon})$ gradient evaluations and
$\tilde{O}(1/\epsilon^2)$ linear optimizations in the batch setting. We also
extend our method to the stochastic setting and propose first stochastic
projection-free algorithms for saddle point problems. Experimental results
demonstrate the effectiveness of our algorithms and verify our theoretical
guarantees.
</p>
<a href="http://arxiv.org/abs/2010.11737" target="_blank">arXiv:2010.11737</a> [<a href="http://arxiv.org/pdf/2010.11737" target="_blank">pdf</a>]

<h2>What are the Statistical Limits of Offline RL with Linear Function Approximation?. (arXiv:2010.11895v1 [cs.LG])</h2>
<h3>Ruosong Wang, Dean P. Foster, Sham M. Kakade</h3>
<p>Offline reinforcement learning seeks to utilize offline (observational) data
to guide the learning of (causal) sequential decision making strategies. The
hope is that offline reinforcement learning coupled with function approximation
methods (to deal with the curse of dimensionality) can provide a means to help
alleviate the excessive sample complexity burden in modern sequential decision
making problems. However, the extent to which this broader approach can be
effective is not well understood, where the literature largely consists of
sufficient conditions.

This work focuses on the basic question of what are necessary
representational and distributional conditions that permit provable
sample-efficient offline reinforcement learning. Perhaps surprisingly, our main
result shows that even if: i) we have realizability in that the true value
function of \emph{every} policy is linear in a given set of features and 2) our
off-policy data has good coverage over all features (under a strong spectral
condition), then any algorithm still (information-theoretically) requires a
number of offline samples that is exponential in the problem horizon in order
to non-trivially estimate the value of \emph{any} given policy. Our results
highlight that sample-efficient offline policy evaluation is simply not
possible unless significantly stronger conditions hold; such conditions include
either having low distribution shift (where the offline data distribution is
close to the distribution of the policy to be evaluated) or significantly
stronger representational conditions (beyond realizability).
</p>
<a href="http://arxiv.org/abs/2010.11895" target="_blank">arXiv:2010.11895</a> [<a href="http://arxiv.org/pdf/2010.11895" target="_blank">pdf</a>]

<h2>Contrastive Self-Supervised Learning for Wireless Power Control. (arXiv:2010.11909v1 [eess.SP])</h2>
<h3>Navid Naderializadeh</h3>
<p>We propose a new approach for power control in wireless networks using
self-supervised learning. We partition a multi-layer perceptron that takes as
input the channel matrix and outputs the power control decisions into a
backbone and a head, and we show how we can use contrastive learning to
pre-train the backbone so that it produces similar embeddings at its output for
similar channel matrices and vice versa, where similarity is defined in an
information-theoretic sense by identifying the interference links that can be
optimally treated as noise. The backbone and the head are then fine-tuned using
a limited number of labeled samples. Simulation results show the effectiveness
of the proposed approach, demonstrating significant gains over pure supervised
learning methods in both sum-throughput and sample efficiency.
</p>
<a href="http://arxiv.org/abs/2010.11909" target="_blank">arXiv:2010.11909</a> [<a href="http://arxiv.org/pdf/2010.11909" target="_blank">pdf</a>]

<h2>Admissibility of solution estimators for stochastic optimization. (arXiv:1901.06976v6 [math.OC] UPDATED)</h2>
<h3>Amitabh Basu, Tu Nguyen, Ao Sun</h3>
<p>We look at stochastic optimization problems through the lens of statistical
decision theory. In particular, we address admissibility, in the statistical
decision theory sense, of the natural sample average estimator for a stochastic
optimization problem (which is also known as the empirical risk minimization
(ERM) rule in learning literature). It is well known that for some simple
stochastic optimization problems, the sample average estimator may not be
admissible. This is known as {\em Stein's paradox} in the statistics
literature. We show in this paper that for optimizing stochastic linear
functions over compact sets, the sample average estimator is admissible.
Moreover, we study problems with convex quadratic objectives subject to box
constraints. Stein's paradox holds when there are no constraints and the
dimension of the problem is at least three. We show that in the presence of box
constraints, admissibility is recovered for dimensions 3 and 4.
</p>
<a href="http://arxiv.org/abs/1901.06976" target="_blank">arXiv:1901.06976</a> [<a href="http://arxiv.org/pdf/1901.06976" target="_blank">pdf</a>]

<h2>Dying ReLU and Initialization: Theory and Numerical Examples. (arXiv:1903.06733v3 [stat.ML] UPDATED)</h2>
<h3>Lu Lu, Yeonjong Shin, Yanhui Su, George Em Karniadakis</h3>
<p>The dying ReLU refers to the problem when ReLU neurons become inactive and
only output 0 for any input. There are many empirical and heuristic
explanations of why ReLU neurons die. However, little is known about its
theoretical analysis. In this paper, we rigorously prove that a deep ReLU
network will eventually die in probability as the depth goes to infinite.
Several methods have been proposed to alleviate the dying ReLU. Perhaps, one of
the simplest treatments is to modify the initialization procedure. One common
way of initializing weights and biases uses symmetric probability
distributions, which suffers from the dying ReLU. We thus propose a new
initialization procedure, namely, a randomized asymmetric initialization. We
prove that the new initialization can effectively prevent the dying ReLU. All
parameters required for the new initialization are theoretically designed.
Numerical examples are provided to demonstrate the effectiveness of the new
initialization procedure.
</p>
<a href="http://arxiv.org/abs/1903.06733" target="_blank">arXiv:1903.06733</a> [<a href="http://arxiv.org/pdf/1903.06733" target="_blank">pdf</a>]

<h2>Minimax Regret of Switching-Constrained Online Convex Optimization: No Phase Transition. (arXiv:1910.10873v3 [cs.LG] UPDATED)</h2>
<h3>Lin Chen, Qian Yu, Hannah Lawrence, Amin Karbasi</h3>
<p>We study the problem of switching-constrained online convex optimization
(OCO), where the player has a limited number of opportunities to change her
action. While the discrete analog of this online learning task has been studied
extensively, previous work in the continuous setting has neither established
the minimax rate nor algorithmically achieved it. In this paper, we show that $
T $-round switching-constrained OCO with fewer than $ K $ switches has a
minimax regret of $ \Theta(\frac{T}{\sqrt{K}}) $. In particular, it is at least
$ \frac{T}{\sqrt{2K}} $ for one dimension and at least $ \frac{T}{\sqrt{K}} $
for higher dimensions. The lower bound in higher dimensions is attained by an
orthogonal subspace argument. In one dimension, a novel adversarial strategy
yields the lower bound of $O(\frac{T}{\sqrt{K}})$, but a precise minimax
analysis including constants is more involved. To establish the tighter
one-dimensional result, we introduce the \emph{fugal game} relaxation, whose
minimax regret lower bounds that of switching-constrained OCO. We show that the
minimax regret of the fugal game is at least $ \frac{T}{\sqrt{2K}} $ and
thereby establish the optimal minimax lower bound in one dimension. To
establish the dimension-independent upper bound, we next show that a
mini-batching algorithm provides an $ O(\frac{T}{\sqrt{K}}) $ upper bound, and
therefore conclude that the minimax regret of switching-constrained OCO is $
\Theta(\frac{T}{\sqrt{K}}) $ for any $K$. This is in sharp contrast to its
discrete counterpart, the switching-constrained prediction-from-experts
problem, which exhibits a phase transition in minimax regret between the
low-switching and high-switching regimes.
</p>
<a href="http://arxiv.org/abs/1910.10873" target="_blank">arXiv:1910.10873</a> [<a href="http://arxiv.org/pdf/1910.10873" target="_blank">pdf</a>]

<h2>Learning under Model Misspecification: Applications to Variational and Ensemble methods. (arXiv:1912.08335v5 [cs.LG] UPDATED)</h2>
<h3>Andres R. Masegosa</h3>
<p>Virtually any model we use in machine learning to make predictions does not
perfectly represent reality. So, most of the learning happens under model
misspecification. In this work, we present a novel analysis of the
generalization performance of Bayesian model averaging under model
misspecification and i.i.d. data using a new family of second-order PAC-Bayes
bounds. This analysis shows, in simple and intuitive terms, that Bayesian model
averaging provides suboptimal generalization performance when the model is
misspecified. In consequence, we provide strong theoretical arguments showing
that Bayesian methods are not optimal for learning predictive models, unless
the model class is perfectly specified. Using novel second-order PAC-Bayes
bounds, we derive a new family of Bayesian-like algorithms, which can be
implemented as variational and ensemble methods. The output of these algorithms
is a new posterior distribution, different from the Bayesian posterior, which
induces a posterior predictive distribution with better generalization
performance. Experiments with Bayesian neural networks illustrate these
findings.
</p>
<a href="http://arxiv.org/abs/1912.08335" target="_blank">arXiv:1912.08335</a> [<a href="http://arxiv.org/pdf/1912.08335" target="_blank">pdf</a>]

<h2>Discrete Signal Processing with Set Functions. (arXiv:2001.10290v2 [cs.IT] UPDATED)</h2>
<h3>Markus P&#xfc;schel, Chris Wendler</h3>
<p>Set functions are functions (or signals) indexed by the powerset (set of all
subsets) of a finite set N. They are fundamental and ubiquitous in many
application domains and have been used, for example, to formally describe or
quantify loss functions for semantic image segmentation, the informativeness of
sensors in sensor networks the utility of sets of items in recommender systems,
cooperative games in game theory, or bidders in combinatorial auctions. In
particular, the subclass of submodular functions occurs in many optimization
and machine learning problems. In this paper, we derive discrete-set signal
processing (SP), a novel shift-invariant linear signal processing framework for
set functions. Discrete-set SP considers different notions of shift obtained
from set union and difference operations. For each shift it provides associated
notions of shift-invariant filters, convolution, Fourier transform, and
frequency response. We provide intuition for our framework using the concept of
generalized coverage function that we define, identify multivariate mutual
information as a special case of a discrete-set spectrum, and motivate
frequency ordering. Our work brings a new set of tools for analyzing and
processing set functions, and, in particular, for dealing with their
exponential nature. We show two prototypical applications and experiments:
compression in submodular function optimization and sampling for preference
elicitation in combinatorial auctions.
</p>
<a href="http://arxiv.org/abs/2001.10290" target="_blank">arXiv:2001.10290</a> [<a href="http://arxiv.org/pdf/2001.10290" target="_blank">pdf</a>]

<h2>Finite-Sample Analysis of Contractive Stochastic Approximation Using Smooth Convex Envelopes. (arXiv:2002.00874v4 [cs.LG] UPDATED)</h2>
<h3>Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, Karthikeyan Shanmugam</h3>
<p>Stochastic Approximation (SA) is a popular approach for solving fixed-point
equations where the information is corrupted by noise. In this paper, we
consider an SA involving a contraction mapping with respect to an arbitrary
norm, and show its finite-sample error bounds while using different stepsizes.
The idea is to construct a smooth Lyapunov function using the generalized
Moreau envelope, and show that the iterates of SA have negative drift with
respect to that Lyapunov function. Our result is applicable in Reinforcement
Learning (RL). In particular, we use it to establish the first-known
convergence rate of the V-trace algorithm for off-policy TD-learning.
Importantly, our construction results in only a logarithmic dependence of the
convergence bound on the size of the state-space.
</p>
<a href="http://arxiv.org/abs/2002.00874" target="_blank">arXiv:2002.00874</a> [<a href="http://arxiv.org/pdf/2002.00874" target="_blank">pdf</a>]

<h2>On the convergence of physics informed neural networks for linear second-order elliptic and parabolic type PDEs. (arXiv:2004.01806v2 [math.NA] UPDATED)</h2>
<h3>Yeonjong Shin, Jerome Darbon, George Em Karniadakis</h3>
<p>Physics informed neural networks (PINNs) are deep learning based techniques
for solving partial differential equations (PDEs) encounted in computational
science and engineering. Guided by data and physical laws, PINNs find a neural
network that approximates the solution to a system of PDEs. Such a neural
network is obtained by minimizing a loss function in which any prior knowledge
of PDEs and data are encoded. Despite its remarkable empirical success in one,
two or three dimensional problems, there is little theoretical justification
for PINNs.

As the number of data grows, PINNs generate a sequence of minimizers which
correspond to a sequence of neural networks. We want to answer the question:
Does the sequence of minimizers converge to the solution to the PDE? We
consider two classes of PDEs: linear second-order elliptic and parabolic. By
adapting the Schauder approach and the maximum principle, we show that the
sequence of minimizers strongly converges to the PDE solution in $C^0$.
Furthermore, we show that if each minimizer satisfies the initial/boundary
conditions, the convergence mode becomes $H^1$. Computational examples are
provided to illustrate our theoretical findings. To the best of our knowledge,
this is the first theoretical work that shows the consistency of PINNs.
</p>
<a href="http://arxiv.org/abs/2004.01806" target="_blank">arXiv:2004.01806</a> [<a href="http://arxiv.org/pdf/2004.01806" target="_blank">pdf</a>]

<h2>Optimizing Neural Networks via Koopman Operator Theory. (arXiv:2006.02361v3 [cs.NE] UPDATED)</h2>
<h3>Akshunna S. Dogra, William T Redman</h3>
<p>Koopman operator theory, a powerful framework for discovering the underlying
dynamics of nonlinear dynamical systems, was recently shown to be intimately
connected with neural network training. In this work, we take the first steps
in making use of this connection. As Koopman operator theory is a linear
theory, a successful implementation of it in evolving network weights and
biases offers the promise of accelerated training, especially in the context of
deep networks, where optimization is inherently a non-convex problem. We show
that Koopman operator theoretic methods allow for accurate predictions of
weights and biases of feedforward, fully connected deep networks over a
non-trivial range of training time. During this window, we find that our
approach is &gt;10x faster than various gradient descent based methods (e.g. Adam,
Adadelta, Adagrad), in line with our complexity analysis. We end by
highlighting open questions in this exciting intersection between dynamical
systems and neural network theory. We highlight additional methods by which our
results could be expanded to broader classes of networks and larger training
intervals, which shall be the focus of future work.
</p>
<a href="http://arxiv.org/abs/2006.02361" target="_blank">arXiv:2006.02361</a> [<a href="http://arxiv.org/pdf/2006.02361" target="_blank">pdf</a>]

<h2>Condensation and extremes for a fluctuating number of independent random variables. (arXiv:2006.04076v2 [cond-mat.stat-mech] UPDATED)</h2>
<h3>Claude Godr&#xe8;che</h3>
<p>We address the question of condensation and extremes for three classes of
intimately related stochastic processes: (a) random allocation models and
zero-range processes, (b) tied-down renewal processes, (c) free renewal
processes. While for the former class the number of components of the system is
kept fixed, for the two other classes it is a fluctuating quantity. Studies of
these topics are scattered in the literature and usually dressed up in other
clothing. We give a stripped-down account of the subject in the language of
sums of independent random variables in order to free ourselves of the
consideration of particular models and highlight the essentials. Besides giving
a unified presentation of the theory, this work investigates facets so far
unexplored in previous studies. Specifically, we show how the study of the
class of random allocation models and zero-range processes can serve as a
backdrop for the study of the two other classes of processes central to the
present work---tied-down and free renewal processes. We then present new
insights on the extreme value statistics of these three classes of processes
which allow a deeper understanding of the mechanism of condensation and the
quantitative analysis of the fluctuations of the condensate.
</p>
<a href="http://arxiv.org/abs/2006.04076" target="_blank">arXiv:2006.04076</a> [<a href="http://arxiv.org/pdf/2006.04076" target="_blank">pdf</a>]

<h2>Variance reduction for Random Coordinate Descent-Langevin Monte Carlo. (arXiv:2006.06068v4 [stat.ML] UPDATED)</h2>
<h3>Zhiyan Ding, Qin Li</h3>
<p>Sampling from a log-concave distribution function is one core problem that
has wide applications in Bayesian statistics and machine learning. While most
gradient free methods have slow convergence rate, the Langevin Monte Carlo
(LMC) that provides fast convergence requires the computation of gradients. In
practice one uses finite-differencing approximations as surrogates, and the
method is expensive in high-dimensions.

A natural strategy to reduce computational cost in each iteration is to
utilize random gradient approximations, such as random coordinate descent (RCD)
or simultaneous perturbation stochastic approximation (SPSA). We show by a
counter-example that blindly applying RCD does not achieve the goal in the most
general setting. The high variance induced by the randomness means a larger
number of iterations are needed, and this balances out the saving in each
iteration.

We then introduce a new variance reduction approach, termed Randomized
Coordinates Averaging Descent (RCAD), and incorporate it with both overdamped
and underdamped LMC. The methods are termed RCAD-O-LMC and RCAD-U-LMC
respectively. The methods still sit in the random gradient approximation
framework, and thus the computational cost in each iteration is low. However,
by employing RCAD, the variance is reduced, so the methods converge within the
same number of iterations as the classical overdamped and underdamped LMC. This
leads to a computational saving overall.
</p>
<a href="http://arxiv.org/abs/2006.06068" target="_blank">arXiv:2006.06068</a> [<a href="http://arxiv.org/pdf/2006.06068" target="_blank">pdf</a>]

<h2>Multiple Descent: Design Your Own Generalization Curve. (arXiv:2008.01036v3 [cs.LG] UPDATED)</h2>
<h3>Lin Chen, Yifei Min, Mikhail Belkin, Amin Karbasi</h3>
<p>This paper explores the generalization loss of linear regression in variably
parameterized families of models, both under-parameterized and
over-parameterized. We show that the generalization curve can have an arbitrary
number of peaks, and moreover, locations of those peaks can be explicitly
controlled. Our results highlight the fact that both classical U-shaped
generalization curve and the recently observed double descent curve are not
intrinsic properties of the model family. Instead, their emergence is due to
the interaction between the properties of the data and the inductive biases of
learning algorithms.
</p>
<a href="http://arxiv.org/abs/2008.01036" target="_blank">arXiv:2008.01036</a> [<a href="http://arxiv.org/pdf/2008.01036" target="_blank">pdf</a>]

<h2>On the Suboptimality of Negative Momentum for Minimax Optimization. (arXiv:2008.07459v3 [math.OC] UPDATED)</h2>
<h3>Guodong Zhang, Yuanhao Wang</h3>
<p>Smooth game optimization has recently attracted great interest in machine
learning as it generalizes the single-objective optimization paradigm. However,
game dynamics is more complex due to the interaction between different players
and is therefore fundamentally different from minimization, posing new
challenges for algorithm design. Notably, it has been shown that negative
momentum is preferred due to its ability to reduce oscillation in game
dynamics. Nevertheless, existing analysis about negative momentum was
restricted to simple bilinear games. In this paper, we extend the analysis to
smooth and strongly-convex strongly-concave minimax games by taking the
variational inequality formulation. By connecting momentum method with
Chebyshev polynomials, we show that negative momentum accelerates convergence
of game dynamics locally, though with a suboptimal rate. To the best of our
knowledge, this is the \emph{first work} that provides an explicit convergence
rate for negative momentum in this setting.
</p>
<a href="http://arxiv.org/abs/2008.07459" target="_blank">arXiv:2008.07459</a> [<a href="http://arxiv.org/pdf/2008.07459" target="_blank">pdf</a>]

<h2>Learning Time Varying Risk Preferences from Investment Portfolios using Inverse Optimization with Applications on Mutual Funds. (arXiv:2010.01687v2 [q-fin.PM] UPDATED)</h2>
<h3>Shi Yu, Yuxin Chen, Chaosheng Dong</h3>
<p>The fundamental principle in Modern Portfolio Theory (MPT) is based on the
quantification of the portfolio's risk related to performance. Although MPT has
made huge impacts on the investment world and prompted the success and
prevalence of passive investing, it still has shortcomings in real-world
applications. One of the main challenges is that the level of risk an investor
can endure, known as \emph{risk-preference}, is a subjective choice that is
tightly related to psychology and behavioral science in decision making. This
paper presents a novel approach of measuring risk preference from existing
portfolios using inverse optimization on the mean-variance portfolio allocation
framework. Our approach allows the learner to continuously estimate real-time
risk preferences using concurrent observed portfolios and market price data. We
demonstrate our methods on real market data that consists of 20 years of asset
pricing and 10 years of mutual fund portfolio holdings. Moreover, the
quantified risk preference parameters are validated with two well-known risk
measurements currently applied in the field. The proposed methods could lead to
practical and fruitful innovations in automated/personalized portfolio
management, such as Robo-advising, to augment financial advisors' decision
intelligence in a long-term investment horizon.
</p>
<a href="http://arxiv.org/abs/2010.01687" target="_blank">arXiv:2010.01687</a> [<a href="http://arxiv.org/pdf/2010.01687" target="_blank">pdf</a>]

<h2>Regret Guarantees for Online Receding Horizon Control. (arXiv:2010.07269v3 [math.OC] UPDATED)</h2>
<h3>Deepan Muthirayan, Jianjun Yuan, Pramod P. Khargonekar</h3>
<p>In this paper we provide provable regret guarantees for an online receding
horizon type control policy in a setting where the system to be controlled is
an unknown linear dynamical system, the cost for the controller is a general
additive function over a finite period $T$, and there exist control input
constraints that when violated incur an additional cost. We show that the
learning based receding horizon control policy achieves the regret of
$O(T^{3/4})$ for both the controller's cost and cumulative constraint violation
w.r.t the baseline receding horizon control policy that has full knowledge of
the system.
</p>
<a href="http://arxiv.org/abs/2010.07269" target="_blank">arXiv:2010.07269</a> [<a href="http://arxiv.org/pdf/2010.07269" target="_blank">pdf</a>]

<h2>Information-Theoretic Bounds on Transfer Generalization Gap Based on Jensen-Shannon Divergence. (arXiv:2010.09484v3 [cs.LG] UPDATED)</h2>
<h3>Sharu Theresa Jose, Osvaldo Simeone</h3>
<p>In transfer learning, training and testing data sets are drawn from different
data distributions. The transfer generalization gap is the difference between
the population loss on the target data distribution and the training loss. The
training data set generally includes data drawn from both source and target
distributions. This work presents novel information-theoretic upper bounds on
the average transfer generalization gap that capture $(i)$ the domain shift
between the target data distribution $P'_Z$ and the source distribution $P_Z$
through a two-parameter family of generalized
$(\alpha_1,\alpha_2)$-Jensen-Shannon (JS) divergences; and $(ii)$ the
sensitivity of the transfer learner output $W$ to each individual sample of the
data set $Z_i$ via the mutual information $I(W;Z_i)$. For $\alpha_1 \in (0,1)$,
the $(\alpha_1,\alpha_2)$-JS divergence can be bounded even when the support of
$P_Z$ is not included in that of $P'_Z$. This contrasts the Kullback-Leibler
(KL) divergence $D_{KL}(P_Z||P'_Z)$-based bounds of Wu et al. [1], which are
vacuous under this assumption. Moreover, the obtained bounds hold for unbounded
loss functions with bounded cumulant generating functions, unlike the
$\phi$-divergence based bound of Wu et al. [1]. We also obtain new upper bounds
on the average transfer excess risk in terms of the $(\alpha_1,\alpha_2)$-JS
divergence for empirical weighted risk minimization (EWRM), which minimizes the
weighted average training losses over source and target data sets. Finally, we
provide a numerical example to illustrate the merits of the introduced bounds.
</p>
<a href="http://arxiv.org/abs/2010.09484" target="_blank">arXiv:2010.09484</a> [<a href="http://arxiv.org/pdf/2010.09484" target="_blank">pdf</a>]

<h2>Learning from students' perception on professors through opinion mining. (arXiv:2008.11183v1 [cs.CL] CROSS LISTED)</h2>
<h3>Vladimir Vargas-Calder&#xf3;n, Juan S. Fl&#xf3;rez, Leonel F. Ardila, Nicolas Parra-A., Jorge E. Camargo, Nelson Vargas</h3>
<p>Students' perception of classes measured through their opinions on teaching
surveys allows to identify deficiencies and problems, both in the environment
and in the learning methodologies. The purpose of this paper is to study,
through sentiment analysis using natural language processing (NLP) and machine
learning (ML) techniques, those opinions in order to identify topics that are
relevant for students, as well as predicting the associated sentiment via
polarity analysis. As a result, it is implemented, trained and tested two
algorithms to predict the associated sentiment as well as the relevant topics
of such opinions. The combination of both approaches then becomes useful to
identify specific properties of the students' opinions associated with each
sentiment label (positive, negative or neutral opinions) and topic.
Furthermore, we explore the possibility that students' perception surveys are
carried out without closed questions, relying on the information that students
can provide through open questions where they express their opinions about
their classes.
</p>
<a href="http://arxiv.org/abs/2008.11183" target="_blank">arXiv:2008.11183</a> [<a href="http://arxiv.org/pdf/2008.11183" target="_blank">pdf</a>]

<h2>Learning Speaker Embedding from Text-to-Speech. (arXiv:2010.11221v1 [eess.AS])</h2>
<h3>Jaejin Cho, Piotr Zelasko, Jesus Villalba, Shinji Watanabe, Najim Dehak</h3>
<p>Zero-shot multi-speaker Text-to-Speech (TTS) generates target speaker voices
given an input text and the corresponding speaker embedding. In this work, we
investigate the effectiveness of the TTS reconstruction objective to improve
representation learning for speaker verification. We jointly trained end-to-end
Tacotron 2 TTS and speaker embedding networks in a self-supervised fashion. We
hypothesize that the embeddings will contain minimal phonetic information since
the TTS decoder will obtain that information from the textual input. TTS
reconstruction can also be combined with speaker classification to enhance
these embeddings further. Once trained, the speaker encoder computes
representations for the speaker verification task, while the rest of the TTS
blocks are discarded. We investigated training TTS from either manual or
ASR-generated transcripts. The latter allows us to train embeddings on datasets
without manual transcripts. We compared ASR transcripts and Kaldi phone
alignments as TTS inputs, showing that the latter performed better due to their
finer resolution. Unsupervised TTS embeddings improved EER by 2.06\% absolute
with regard to i-vectors for the LibriTTS dataset. TTS with speaker
classification loss improved EER by 0.28\% and 0.73\% absolutely from a model
using only speaker classification loss in LibriTTS and Voxceleb1 respectively.
</p>
<a href="http://arxiv.org/abs/2010.11221" target="_blank">arXiv:2010.11221</a> [<a href="http://arxiv.org/pdf/2010.11221" target="_blank">pdf</a>]

<h2>Meta-trained agents implement Bayes-optimal agents. (arXiv:2010.11223v1 [cs.AI])</h2>
<h3>Vladimir Mikulik, Gr&#xe9;goire Del&#xe9;tang, Tom McGrath, Tim Genewein, Miljan Martic, Shane Legg, Pedro A. Ortega</h3>
<p>Memory-based meta-learning is a powerful technique to build agents that adapt
fast to any task within a target distribution. A previous theoretical study has
argued that this remarkable performance is because the meta-training protocol
incentivises agents to behave Bayes-optimally. We empirically investigate this
claim on a number of prediction and bandit tasks. Inspired by ideas from
theoretical computer science, we show that meta-learned and Bayes-optimal
agents not only behave alike, but they even share a similar computational
structure, in the sense that one agent system can approximately simulate the
other. Furthermore, we show that Bayes-optimal agents are fixed points of the
meta-learning dynamics. Our results suggest that memory-based meta-learning
might serve as a general technique for numerically approximating Bayes-optimal
agents - that is, even for task distributions for which we currently don't
possess tractable models.
</p>
<a href="http://arxiv.org/abs/2010.11223" target="_blank">arXiv:2010.11223</a> [<a href="http://arxiv.org/pdf/2010.11223" target="_blank">pdf</a>]

<h2>Self-Supervised Contrastive Learning for Efficient User Satisfaction Prediction in Conversational Agents. (arXiv:2010.11230v1 [cs.LG])</h2>
<h3>Mohammad Kachuee, Hao Yuan, Young-Bum Kim, Sungjin Lee</h3>
<p>Turn-level user satisfaction is one of the most important performance metrics
for conversational agents. It can be used to monitor the agent's performance
and provide insights about defective user experiences. Moreover, a powerful
satisfaction model can be used as an objective function that a conversational
agent continuously optimizes for. While end-to-end deep learning has shown
promising results, having access to a large number of reliable annotated
samples required by these methods remains challenging. In a large-scale
conversational system, there is a growing number of newly developed skills,
making the traditional data collection, annotation, and modeling process
impractical due to the required annotation costs as well as the turnaround
times. In this paper, we suggest a self-supervised contrastive learning
approach that leverages the pool of unlabeled data to learn user-agent
interactions. We show that the pre-trained models using the self-supervised
objective are transferable to the user satisfaction prediction. In addition, we
propose a novel few-shot transfer learning approach that ensures better
transferability for very small sample sizes. The suggested few-shot method does
not require any inner loop optimization process and is scalable to very large
datasets and complex models. Based on our experiments using real-world data
from a large-scale commercial system, the suggested approach is able to
significantly reduce the required number of annotations, while improving the
generalization on unseen out-of-domain skills.
</p>
<a href="http://arxiv.org/abs/2010.11230" target="_blank">arXiv:2010.11230</a> [<a href="http://arxiv.org/pdf/2010.11230" target="_blank">pdf</a>]

<h2>Learning Spring Mass Locomotion: Guiding Policies with a Reduced-Order Model. (arXiv:2010.11234v1 [cs.RO])</h2>
<h3>Kevin Green, Yesh Godse, Jeremy Dao, Ross L. Hatton, Alan Fern, Jonathan Hurst</h3>
<p>In this paper, we describe an approach to achieve dynamic legged locomotion
on physical robots which combines existing methods for control with
reinforcement learning. Specifically, our goal is a control hierarchy in which
highest-level behaviors are planned through reduced-order models, which
describe the fundamental physics of legged locomotion, and lower level
controllers utilize a learned policy that can bridge the gap between the
idealized, simple model and the complex, full order robot. The high-level
planner can use a model of the environment and be task specific, while the
low-level learned controller can execute a wide range of motions so that it
applies to many different tasks. In this letter we describe this learned
dynamic walking controller and show that a range of walking motions from
reduced-order models can be used as the command and primary training signal for
learned policies. The resulting policies do not attempt to naively track the
motion (as a traditional trajectory tracking controller would) but instead
balance immediate motion tracking with long term stability. The resulting
controller is demonstrated on a human scale, unconstrained, untethered bipedal
robot at speeds up to 1.2 m/s. This letter builds the foundation of a generic,
dynamic learned walking controller that can be applied to many different tasks.
</p>
<a href="http://arxiv.org/abs/2010.11234" target="_blank">arXiv:2010.11234</a> [<a href="http://arxiv.org/pdf/2010.11234" target="_blank">pdf</a>]

<h2>On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries. (arXiv:2010.11246v1 [cs.CL])</h2>
<h3>Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daum&#xe9; III, Lillian Lee</h3>
<p>Large-scale semantic parsing datasets annotated with logical forms have
enabled major advances in supervised approaches. But can richer supervision
help even more? To explore the utility of fine-grained, lexical-level
supervision, we introduce Squall, a dataset that enriches 11,276
WikiTableQuestions English-language questions with manually created SQL
equivalents plus alignments between SQL and question fragments. Our annotation
enables new training possibilities for encoder-decoder models, including
approaches from machine translation previously precluded by the absence of
alignments. We propose and test two methods: (1) supervised attention; (2)
adopting an auxiliary objective of disambiguating references in the input
queries to table columns. In 5-fold cross validation, these strategies improve
over strong baselines by 4.4% execution accuracy. Oracle experiments suggest
that annotated alignments can support further accuracy gains of up to 23.9%.
</p>
<a href="http://arxiv.org/abs/2010.11246" target="_blank">arXiv:2010.11246</a> [<a href="http://arxiv.org/pdf/2010.11246" target="_blank">pdf</a>]

<h2>Neural Star Domain as Primitive Representation. (arXiv:2010.11248v1 [cs.CV])</h2>
<h3>Yuki Kawana, Yusuke Mukuta, Tatsuya Harada</h3>
<p>Reconstructing 3D objects from 2D images is a fundamental task in computer
vision. Accurate structured reconstruction by parsimonious and semantic
primitive representation further broadens its application. When reconstructing
a target shape with multiple primitives, it is preferable that one can
instantly access the union of basic properties of the shape such as collective
volume and surface, treating the primitives as if they are one single shape.
This becomes possible by primitive representation with unified implicit and
explicit representations. However, primitive representations in current
approaches do not satisfy all of the above requirements at the same time. To
solve this problem, we propose a novel primitive representation named neural
star domain (NSD) that learns primitive shapes in the star domain. We show that
NSD is a universal approximator of the star domain and is not only parsimonious
and semantic but also an implicit and explicit shape representation. We
demonstrate that our approach outperforms existing methods in image
reconstruction tasks, semantic capabilities, and speed and quality of sampling
high-resolution meshes.
</p>
<a href="http://arxiv.org/abs/2010.11248" target="_blank">arXiv:2010.11248</a> [<a href="http://arxiv.org/pdf/2010.11248" target="_blank">pdf</a>]

<h2>Learning Quadrupedal Locomotion over Challenging Terrain. (arXiv:2010.11251v1 [cs.RO])</h2>
<h3>Joonho Lee, Jemin Hwangbo, Lorenz Wellhausen, Vladlen Koltun, Marco Hutter</h3>
<p>Some of the most challenging environments on our planet are accessible to
quadrupedal animals but remain out of reach for autonomous machines. Legged
locomotion can dramatically expand the operational domains of robotics.
However, conventional controllers for legged locomotion are based on elaborate
state machines that explicitly trigger the execution of motion primitives and
reflexes. These designs have escalated in complexity while falling short of the
generality and robustness of animal locomotion. Here we present a radically
robust controller for legged locomotion in challenging natural environments. We
present a novel solution to incorporating proprioceptive feedback in locomotion
control and demonstrate remarkable zero-shot generalization from simulation to
natural environments. The controller is trained by reinforcement learning in
simulation. It is based on a neural network that acts on a stream of
proprioceptive signals. The trained controller has taken two generations of
quadrupedal ANYmal robots to a variety of natural environments that are beyond
the reach of prior published work in legged locomotion. The controller retains
its robustness under conditions that have never been encountered during
training: deformable terrain such as mud and snow, dynamic footholds such as
rubble, and overground impediments such as thick vegetation and gushing water.
The presented work opens new frontiers for robotics and indicates that radical
robustness in natural environments can be achieved by training in much simpler
domains.
</p>
<a href="http://arxiv.org/abs/2010.11251" target="_blank">arXiv:2010.11251</a> [<a href="http://arxiv.org/pdf/2010.11251" target="_blank">pdf</a>]

<h2>Sobolev training of thermodynamic-informed neural networks for smoothed elasto-plasticity models with level set hardening. (arXiv:2010.11265v1 [cs.LG])</h2>
<h3>Nikolaos N. Vlassis, WaiChing Sun</h3>
<p>We introduce a deep learning framework designed to train smoothed
elastoplasticity models with interpretable components, such as a smoothed
stored elastic energy function, a yield surface, and a plastic flow that are
evolved based on a set of deep neural network predictions. By recasting the
yield function as an evolving level set, we introduce a machine learning
approach to predict the solutions of the Hamilton-Jacobi equation that governs
the hardening mechanism. This machine learning hardening law may recover
classical hardening models and discover new mechanisms that are otherwise very
difficult to anticipate and hand-craft. This treatment enables us to use
supervised machine learning to generate models that are thermodynamically
consistent, interpretable, but also exhibit excellent learning capacity. Using
a 3D FFT solver to create a polycrystal database, numerical experiments are
conducted and the implementations of each component of the models are
individually verified. Our numerical experiments reveal that this new approach
provides more robust and accurate forward predictions of cyclic stress paths
than these obtained from black-box deep neural network models such as a
recurrent GRU neural network, a 1D convolutional neural network, and a
multi-step feedforward model.
</p>
<a href="http://arxiv.org/abs/2010.11265" target="_blank">arXiv:2010.11265</a> [<a href="http://arxiv.org/pdf/2010.11265" target="_blank">pdf</a>]

<h2>MicroNets: Neural Network Architectures for Deploying TinyML Applications on Commodity Microcontrollers. (arXiv:2010.11267v1 [cs.LG])</h2>
<h3>Colby Banbury, Chuteng Zhou, Igor Fedorov, Ramon Matas Navarro, Urmish Thakkar, Dibakar Gope, Vijay Janapa Reddi, Matthew Mattina, Paul N. Whatmough</h3>
<p>Executing machine learning workloads locally on resource constrained
microcontrollers (MCUs) promises to drastically expand the application space of
IoT. However, so-called TinyML presents severe technical challenges, as deep
neural network inference demands a large compute and memory budget. To address
this challenge, neural architecture search (NAS) promises to help design
accurate ML models that meet the tight MCU memory, latency and energy
constraints. A key component of NAS algorithms is their latency/energy model,
i.e., the mapping from a given neural network architecture to its inference
latency/energy on an MCU. In this paper, we observe an intriguing property of
NAS search spaces for MCU model design: on average, model latency varies
linearly with model operation (op) count under a uniform prior over models in
the search space. Exploiting this insight, we employ differentiable NAS (DNAS)
to search for models with low memory usage and low op count, where op count is
treated as a viable proxy to latency. Experimental results validate our
methodology, yielding our MicroNet models, which we deploy on MCUs using
Tensorflow Lite Micro, a standard open-source NN inference runtime widely used
in the TinyML community. MicroNets demonstrate state-of-the-art results for all
three TinyMLperf industry-standard benchmark tasks: visual wake words, audio
keyword spotting, and anomaly detection.
</p>
<a href="http://arxiv.org/abs/2010.11267" target="_blank">arXiv:2010.11267</a> [<a href="http://arxiv.org/pdf/2010.11267" target="_blank">pdf</a>]

<h2>Deep-Reinforcement-Learning-Based Scheduling with Contiguous Resource Allocation for Next-Generation Cellular Systems. (arXiv:2010.11269v1 [cs.NI])</h2>
<h3>Shu Sun, Xiaofeng Li</h3>
<p>In this work, we propose a novel scheduling algorithm with contiguous
frequency-domain resource allocation (FDRA) based on deep reinforcement
learning (DRL) that jointly selects users and allocates resource blocks (RBs).
The scheduling problem is modeled as a Markov decision process, and a DRL agent
determines which user and how many consecutive RBs for that user should be
scheduled at each RB allocation step. The state, action, and reward sets are
delicately designed to train the DRL network. More specifically, the originally
quasicontinuous action space, which is inherent to contiguous FDRA, is refined
into a finite and discrete action space to obtain a tradeoff between the
inference latency and system performance. Simulation results show that the
proposed DRL-based algorithm outperforms other representative baseline schemes
while having lower online computational complexity.
</p>
<a href="http://arxiv.org/abs/2010.11269" target="_blank">arXiv:2010.11269</a> [<a href="http://arxiv.org/pdf/2010.11269" target="_blank">pdf</a>]

<h2>Learning second order coupled differential equations that are subject to non-conservative forces. (arXiv:2010.11270v1 [cs.LG])</h2>
<h3>Roger Alexander M&#xfc;ller, Jonathan Laflamme-Janssen, Jaime Camacaro, Carolina Bessega</h3>
<p>In this article we address the question whether it is possible to learn the
differential equations describing the physical properties of a dynamical
system, subject to non-conservative forces, from observations of its realspace
trajectory(ies) only. We introduce a network that incorporates a difference
approximation for the second order derivative in terms of residual connections
between convolutional blocks, whose shared weights represent the coefficients
of a second order ordinary differential equation. We further combine this
solver-like architecture with a convolutional network, capable of learning the
relation between trajectories of coupled oscillators and therefore allows us to
make a stable forecast even if the system is only partially observed. We
optimize this map together with the solver network, while sharing their
weights, to form a powerful framework capable of learning the complex physical
properties of a dissipative dynamical system.
</p>
<a href="http://arxiv.org/abs/2010.11270" target="_blank">arXiv:2010.11270</a> [<a href="http://arxiv.org/pdf/2010.11270" target="_blank">pdf</a>]

<h2>Robustness-aware 2-bit quantization with real-time performance for neural network. (arXiv:2010.11271v1 [cs.LG])</h2>
<h3>Xiaobin Li, Hongxu Jiang, Shuangxi Huang, Fangzheng Tian</h3>
<p>Quantized neural network (NN) with a reduced bit precision is an effective
solution to reduces the computational and memory resource requirements and
plays a vital role in machine learning. However, it is still challenging to
avoid the significant accuracy degradation due to its numerical approximation
and lower redundancy. In this paper, a novel robustness-aware 2-bit
quantization scheme is proposed for NN base on binary NN and generative
adversarial network(GAN), witch improves the performance by enriching the
information of binary NN, efficiently extract the structural information and
considering the robustness of the quantized NN. Specifically, using shift
addition operation to replace the multiply-accumulate in the quantization
process witch can effectively speed the NN. Meanwhile, a structural loss
between the original NN and quantized NN is proposed to such that the
structural information of data is preserved after quantization. The structural
information learned from NN not only plays an important role in improving the
performance but also allows for further fine tuning of the quantization network
by applying the Lipschitz constraint to the structural loss. In addition, we
also for the first time take the robustness of the quantized NN into
consideration and propose a non-sensitive perturbation loss function by
introducing an extraneous term of spectral norm. The experiments are conducted
on CIFAR-10 and ImageNet datasets with popular NN( such as MoblieNetV2,
SqueezeNet, ResNet20, etc). The experimental results show that the proposed
algorithm is more competitive under 2-bit-precision than the state-of-the-art
quantization methods. Meanwhile, the experimental results also demonstrate that
the proposed method is robust under the FGSM adversarial samples attack.
</p>
<a href="http://arxiv.org/abs/2010.11271" target="_blank">arXiv:2010.11271</a> [<a href="http://arxiv.org/pdf/2010.11271" target="_blank">pdf</a>]

<h2>Predicting Chemical Properties using Self-Attention Multi-task Learning based on SMILES Representation. (arXiv:2010.11272v1 [cs.LG])</h2>
<h3>Sangrak Lim, Yong Oh Lee</h3>
<p>In the computational prediction of chemical compound properties, molecular
descriptors and fingerprints encoded to low dimensional vectors are used. The
selection of proper molecular descriptors and fingerprints is both important
and challenging as the performance of such models is highly dependent on
descriptors. To overcome this challenge, natural language processing models
that utilize simplified molecular input line-entry system as input were
studied, and several transformer-variant models achieved superior results when
compared with conventional methods. In this study, we explored the structural
differences of the transformer-variant model and proposed a new self-attention
based model. The representation learning performance of the self-attention
module was evaluated in a multi-task learning environment using imbalanced
chemical datasets. The experiment results showed that our model achieved
competitive outcomes on several benchmark datasets. The source code of our
experiment is available at https://github.com/arwhirang/sa-mtl and the dataset
is available from the same URL.
</p>
<a href="http://arxiv.org/abs/2010.11272" target="_blank">arXiv:2010.11272</a> [<a href="http://arxiv.org/pdf/2010.11272" target="_blank">pdf</a>]

<h2>Deep Surrogate Q-Learning for Autonomous Driving. (arXiv:2010.11278v1 [cs.LG])</h2>
<h3>Maria Huegle, Gabriel Kalweit, Moritz Werling, Joschka Boedecker</h3>
<p>Challenging problems of deep reinforcement learning systems with regard to
the application on real systems are their adaptivity to changing environments
and their efficiency w.r.t. computational resources and data. In the
application of learning lane-change behavior for autonomous driving, agents
have to deal with a varying number of surrounding vehicles. Furthermore, the
number of required transitions imposes a bottleneck, since test drivers cannot
perform an arbitrary amount of lane changes in the real world. In the
off-policy setting, additional information on solving the task can be gained by
observing actions from others. While in the classical RL setup this knowledge
remains unused, we use other drivers as surrogates to learn the agent's value
function more efficiently. We propose Surrogate Q-learning that deals with the
aforementioned problems and reduces the required driving time drastically. We
further propose an efficient implementation based on a permutation-equivariant
deep neural network architecture of the Q-function to estimate action-values
for a variable number of vehicles in sensor range. We show that the
architecture leads to a novel replay sampling technique we call Scene-centric
Experience Replay and evaluate the performance of Surrogate Q-learning and
Scene-centric Experience Replay in the open traffic simulator SUMO.
Additionally, we show that our methods enhance real-world applicability of RL
systems by learning policies on the real highD dataset.
</p>
<a href="http://arxiv.org/abs/2010.11278" target="_blank">arXiv:2010.11278</a> [<a href="http://arxiv.org/pdf/2010.11278" target="_blank">pdf</a>]

<h2>Shedding Light on Blind Spots: Developing a Reference Architecture to Leverage Video Data for Process Mining. (arXiv:2010.11289v1 [cs.CV])</h2>
<h3>Wolfgang Kratsch, Fabian K&#xf6;nig, Maximilian R&#xf6;glinger</h3>
<p>Process mining is one of the most active research streams in business process
management. In recent years, numerous methods have been proposed for analyzing
structured process data. Yet, in many cases, it is only the digitized parts of
processes that are directly captured from process-aware information systems,
and manual activities often result in blind spots. While the use of video
cameras to observe these activities could help to fill this gap, a standardized
approach to extracting event logs from unstructured video data remains lacking.
Here, we propose a reference architecture to bridge the gap between computer
vision and process mining. Various evaluation activities (i.e., competing
artifact analysis, prototyping, and real-world application) ensured that the
proposed reference architecture allows flexible, use-case-driven, and
context-specific instantiations. Our results also show that an exemplary
software prototype instantiation of the proposed reference architecture is
capable of automatically extracting most of the process-relevant events from
unstructured video data.
</p>
<a href="http://arxiv.org/abs/2010.11289" target="_blank">arXiv:2010.11289</a> [<a href="http://arxiv.org/pdf/2010.11289" target="_blank">pdf</a>]

<h2>Unrolling of Deep Graph Total Variation for Image Denoising. (arXiv:2010.11290v1 [cs.CV])</h2>
<h3>Huy Vu, Gene Cheung, Yonina C. Eldar</h3>
<p>While deep learning (DL) architectures like convolutional neural networks
(CNNs) have enabled effective solutions in image denoising, in general their
implementations overly rely on training data, lack interpretability, and
require tuning of a large parameter set. In this paper, we combine classical
graph signal filtering with deep feature learning into a competitive hybrid
design---one that utilizes interpretable analytical low-pass graph filters and
employs 80% fewer network parameters than state-of-the-art DL denoising scheme
DnCNN. Specifically, to construct a suitable similarity graph for graph
spectral filtering, we first adopt a CNN to learn feature representations per
pixel, and then compute feature distances to establish edge weights. Given a
constructed graph, we next formulate a convex optimization problem for
denoising using a graph total variation (GTV) prior. Via a $l_1$ graph
Laplacian reformulation, we interpret its solution in an iterative procedure as
a graph low-pass filter and derive its frequency response. For fast filter
implementation, we realize this response using a Lanczos approximation.
Experimental results show that in the case of statistical mistmatch, our
algorithm outperformed DnCNN by up to 3dB in PSNR.
</p>
<a href="http://arxiv.org/abs/2010.11290" target="_blank">arXiv:2010.11290</a> [<a href="http://arxiv.org/pdf/2010.11290" target="_blank">pdf</a>]

<h2>Bidirectional Microrocker Bots with Sharp Tips Actuated by a Single Electromagnet. (arXiv:2010.11295v1 [cs.RO])</h2>
<h3>DeaGyu Kim, Tony Wang, Yifan Shi, Zhijian Hao, Azadeh Ansari</h3>
<p>The recent advancements in nanoscale 3D printing and microfabrication
techniques have reinvigorated research on microrobotics and nanomachines.
However, precise control of the robot motion and navigation on biological
environments have remained challenging to date. This work presents the first
demonstration of magnetic microscale rocker robot (microrocker bot) capable of
bidirectional movement on flat as well as biological surfaces, when actuated by
a single compact electromagnet. The 100um by 113um by 36um robot was 3D printed
via two-photon lithography and subsequently coated with a nickel (Ni) thin
film. When actuated by an externally applied magnetic sawtooth field, the robot
demonstrated stick-slip motion enabled by its rockers. The controllable
bidirectional motion is enabled by adjusting the DC offset of the waveform,
which tilts the robot and biases it towards either forward or backward motion.
The microrocker bots are further equipped with sharp tips that can get engaged
via application of DC-only or low frequency magnetic fields. This novel control
method offers an attractive solution to replace the multiple bulky coils
traditionally used for magnetic actuation and control, as well as allows for a
more flexible and simple approach towards microrobotics motion control. When
the frequency and offset of the sawtooth waveform are optimized, the robot
travels up to 87ums (0.87 body length per second) forward and backward with
minor deviance from linear trajectories. Finally, to prove the robot's
capabilities in direct contact with biological environments, we demonstrate the
microbot's ability to traverse forward and backward on the surface of a
Dracaena Fragrans (corn plant), as well as upend on its mechanical tip.
</p>
<a href="http://arxiv.org/abs/2010.11295" target="_blank">arXiv:2010.11295</a> [<a href="http://arxiv.org/pdf/2010.11295" target="_blank">pdf</a>]

<h2>System Design and Control of an Apple Harvesting Robot. (arXiv:2010.11296v1 [cs.RO])</h2>
<h3>Kaixiang Zhang, Kyle Lammers, Pengyu Chu, Zhaojian Li, Renfu Lu</h3>
<p>There is a growing need for robotic apple harvesting due to decreasing
availability and rising cost in labor. Towards the goal of developing a viable
robotic system for apple harvesting, this paper presents synergistic
mechatronic design and motion control of a robotic apple harvesting prototype,
which lays a critical foundation for future advancements. Specifically, we
develop a deep learning-based fruit detection and localization system using an
RGB-D camera. A three degree-of-freedom manipulator is then designed with a
hybrid pneumatic/motor actuation mechanism to achieve fast and dexterous
movements. A vacuum-based end-effector is used for apple detaching. These three
components are integrated into a robotic apple harvesting prototype with
simplicity, compactness, and robustness. Moreover, a nonlinear velocity-based
control scheme is developed for the manipulator to achieve accurate and agile
motion control. Test experiments are conducted to demonstrate the performance
of the developed apple harvesting robot.
</p>
<a href="http://arxiv.org/abs/2010.11296" target="_blank">arXiv:2010.11296</a> [<a href="http://arxiv.org/pdf/2010.11296" target="_blank">pdf</a>]

<h2>Performance Prediction for Convolutional Neural Networks in Edge Devices. (arXiv:2010.11297v1 [cs.CV])</h2>
<h3>Halima Bouzidi, Hamza Ouarnoughi, Smail Niar, Abdessamad Ait El Cadi</h3>
<p>Running Convolutional Neural Network (CNN) based applications on edge devices
near the source of data can meet the latency and privacy challenges. However
due to their reduced computing resources and their energy constraints, these
edge devices can hardly satisfy CNN needs in processing and data storage. For
these platforms, choosing the CNN with the best trade-off between accuracy and
execution time while respecting Hardware constraints is crucial. In this paper,
we present and compare five (5) of the widely used Machine Learning based
methods for execution time prediction of CNNs on two (2) edge GPU platforms.
For these 5 methods, we also explore the time needed for their training and
tuning their corresponding hyperparameters. Finally, we compare times to run
the prediction models on different platforms. The utilization of these methods
will highly facilitate design space exploration by providing quickly the best
CNN on a target edge GPU. Experimental results show that eXtreme Gradient
Boosting (XGBoost) provides a less than 14.73% average prediction error even
for unexplored and unseen CNN models' architectures. Random Forest (RF) depicts
comparable accuracy but needs more effort and time to be trained. The other 3
approaches (OLS, MLP and SVR) are less accurate for CNN performances
estimation.
</p>
<a href="http://arxiv.org/abs/2010.11297" target="_blank">arXiv:2010.11297</a> [<a href="http://arxiv.org/pdf/2010.11297" target="_blank">pdf</a>]

<h2>Mixed-Precision Embedding Using a Cache. (arXiv:2010.11305v1 [cs.LG])</h2>
<h3>Jie (Amy) Yang, Jianyu Huang, Jongsoo Park, Ping Tak Peter Tang, Andrew Tulloch</h3>
<p>In recommendation systems, practitioners observed that increase in the number
of embedding tables and their sizes often leads to significant improvement in
model performances. Given this and the business importance of these models to
major internet companies, embedding tables for personalization tasks have grown
to terabyte scale and continue to grow at a significant rate. Meanwhile, these
large-scale models are often trained with GPUs where high-performance memory is
a scarce resource, thus motivating numerous work on embedding table compression
during training. We propose a novel change to embedding tables using a cache
memory architecture, where the majority of rows in an embedding is trained in
low precision, and the most frequently or recently accessed rows cached and
trained in full precision. The proposed architectural change works in
conjunction with standard precision reduction and computer arithmetic
techniques such as quantization and stochastic rounding. For an open source
deep learning recommendation model (DLRM) running with Criteo-Kaggle dataset,
we achieve 3x memory reduction with INT8 precision embedding tables and
full-precision cache whose size are 5% of the embedding tables, while
maintaining accuracy. For an industrial scale model and dataset, we achieve
even higher &gt;7x memory reduction with INT4 precision and cache size 1% of
embedding tables, while maintaining accuracy, and 16% end-to-end training
speedup by reducing GPU-to-host data transfers.
</p>
<a href="http://arxiv.org/abs/2010.11305" target="_blank">arXiv:2010.11305</a> [<a href="http://arxiv.org/pdf/2010.11305" target="_blank">pdf</a>]

<h2>Speculative Container Scheduling for Deep Learning Applications in a Kubernetes Cluster. (arXiv:2010.11307v1 [cs.DC])</h2>
<h3>Ying Mao, Yuqi Fu, Wenjia Zheng, Long Cheng, Qingzhi Liu, Dingwen Tao</h3>
<p>In the past decade, we have witnessed a dramatically increasing volume of
data collected from varied sources. The explosion of data has transformed the
world as more information is available for collection and analysis than ever
before. To maximize the utilization, various machine and deep learning models
have been developed, e.g. CNN [1] and RNN [2], to study data and extract
valuable information from different perspectives. While data-driven
applications improve countless products, training models for hyperparameter
tuning is still a time-consuming and resource-intensive process. Cloud
computing provides infrastructure support for the training of deep learning
applications. The cloud service providers, such as Amazon Web Services [3],
create an isolated virtual environment (virtual machines and containers) for
clients, who share physical resources, e.g., CPU and memory. On the cloud,
resource management schemes are implemented to enable better sharing among
users and boost the system-wide performance. However, general scheduling
approaches, such as spread priority and balanced resource schedulers, do not
work well with deep learning workloads. In this project, we propose SpeCon, a
novel container scheduler that is optimized for shortlived deep learning
applications. Based on virtualized containers, such as Kubernetes [4] and
Docker [5], SpeCon analyzes the common characteristics of training processes.
We design a suite of algorithms to monitor the progress of the training and
speculatively migrate the slow-growing models to release resources for
fast-growing ones. Specifically, the extensive experiments demonstrate that
SpeCon improves the completion time of an individual job by up to 41.5%, 14.8%
system-wide and 24.7% in terms of makespan.
</p>
<a href="http://arxiv.org/abs/2010.11307" target="_blank">arXiv:2010.11307</a> [<a href="http://arxiv.org/pdf/2010.11307" target="_blank">pdf</a>]

<h2>Uncertainty-Aware Deep Ensembles for Reliable and Explainable Predictions of Clinical Time Series. (arXiv:2010.11310v1 [cs.LG])</h2>
<h3>Kristoffer Wickstr&#xf8;m, Karl &#xd8;yvind Mikalsen, Michael Kampffmeyer, Arthur Revhaug, Robert Jenssen</h3>
<p>Deep learning-based support systems have demonstrated encouraging results in
numerous clinical applications involving the processing of time series data.
While such systems often are very accurate, they have no inherent mechanism for
explaining what influenced the predictions, which is critical for clinical
tasks. However, existing explainability techniques lack an important component
for trustworthy and reliable decision support, namely a notion of uncertainty.
In this paper, we address this lack of uncertainty by proposing a deep ensemble
approach where a collection of DNNs are trained independently. A measure of
uncertainty in the relevance scores is computed by taking the standard
deviation across the relevance scores produced by each model in the ensemble,
which in turn is used to make the explanations more reliable. The class
activation mapping method is used to assign a relevance score for each time
step in the time series. Results demonstrate that the proposed ensemble is more
accurate in locating relevant time steps and is more consistent across random
initializations, thus making the model more trustworthy. The proposed
methodology paves the way for constructing trustworthy and dependable support
systems for processing clinical time series for healthcare related tasks.
</p>
<a href="http://arxiv.org/abs/2010.11310" target="_blank">arXiv:2010.11310</a> [<a href="http://arxiv.org/pdf/2010.11310" target="_blank">pdf</a>]

<h2>Learning to Summarize Long Texts with Memory Compression and Transfer. (arXiv:2010.11322v1 [cs.CL])</h2>
<h3>Jaehong Park, Jonathan Pilault, Christopher Pal</h3>
<p>We introduce Mem2Mem, a memory-to-memory mechanism for hierarchical recurrent
neural network based encoder decoder architectures and we explore its use for
abstractive document summarization. Mem2Mem transfers "memories" via
readable/writable external memory modules that augment both the encoder and
decoder. Our memory regularization compresses an encoded input article into a
more compact set of sentence representations. Most importantly, the memory
compression step performs implicit extraction without labels, sidestepping
issues with suboptimal ground-truth data and exposure bias of hybrid
extractive-abstractive summarization techniques. By allowing the decoder to
read/write over the encoded input memory, the model learns to read salient
information about the input article while keeping track of what has been
generated. Our Mem2Mem approach yields results that are competitive with state
of the art transformer based summarization methods, but with 16 times fewer
parameters
</p>
<a href="http://arxiv.org/abs/2010.11322" target="_blank">arXiv:2010.11322</a> [<a href="http://arxiv.org/pdf/2010.11322" target="_blank">pdf</a>]

<h2>Learning to Plan Optimally with Flow-based Motion Planner. (arXiv:2010.11323v1 [cs.RO])</h2>
<h3>Tin Lai, Fabio Ramos</h3>
<p>Sampling-based motion planning is the predominant paradigm in many real-world
robotic applications, but its performance is immensely dependent on the quality
of the samples. The majority of traditional planners are inefficient as they
use uninformative sampling distributions as opposed to exploiting structures
and patterns in the problem to guide better sampling strategies. Moreover, most
current learning-based planners are susceptible to posterior collapse or mode
collapse due to the sparsity and highly varying nature of C-Space and motion
plan configurations. In this work, we introduce a conditional normalising flow
based distribution learned through previous experiences to improve sampling of
these methods. Our distribution can be conditioned on the current problem
instance to provide an informative prior for sampling configurations within
promising regions. When we train our sampler with an expert planner, the
resulting distribution is often near-optimal, and the planner can find a
solution faster, with less invalid samples, and less initial cost. The
normalising flow based distribution uses simple invertible transformations that
are very computationally efficient, and our optimisation formulation explicitly
avoids mode collapse in contrast to other existing learning-based planners.
Finally, we provide a formulation and theoretical foundation to efficiently
sample from the distribution; and demonstrate experimentally that, by using our
normalising flow based distribution, a solution can be found faster, with less
samples and better overall runtime performance.
</p>
<a href="http://arxiv.org/abs/2010.11323" target="_blank">arXiv:2010.11323</a> [<a href="http://arxiv.org/pdf/2010.11323" target="_blank">pdf</a>]

<h2>Probing and Fine-tuning Reading Comprehension Models for Few-shot Event Extraction. (arXiv:2010.11325v1 [cs.CL])</h2>
<h3>Rui Feng, Jie Yuan, Chao Zhang</h3>
<p>We study the problem of event extraction from text data, which requires both
detecting target event types and their arguments. Typically, both the event
detection and argument detection subtasks are formulated as supervised sequence
labeling problems. We argue that the event extraction models so trained are
inherently label-hungry, and can generalize poorly across domains and text
genres.We propose a reading comprehension framework for event
extraction.Specifically, we formulate event detection as a textual entailment
prediction problem, and argument detection as a question answer-ing problem. By
constructing proper query templates, our approach can effectively distill rich
knowledge about tasks and label semantics from pretrained reading comprehension
models. Moreover, our model can be fine-tuned with a small amount of data to
boost its performance. Our experiment results show that our method performs
strongly for zero-shot and few-shot event extraction, and it achieves
state-of-the-art performance on the ACE 2005 benchmark when trained with full
supervision.
</p>
<a href="http://arxiv.org/abs/2010.11325" target="_blank">arXiv:2010.11325</a> [<a href="http://arxiv.org/pdf/2010.11325" target="_blank">pdf</a>]

<h2>Fast and Robust Bio-inspired Teach and Repeat Navigation. (arXiv:2010.11326v1 [cs.RO])</h2>
<h3>Dominic Dall&#x27;Osto, Tobias Fischer, Michael Milford</h3>
<p>Fully autonomous mobile robots have a multitude of potential applications,
but guaranteeing robust navigation performance remains an open research
problem. For many tasks such as repeated infrastructure inspection, item
delivery or inventory transport, a route repeating capability rather than full
navigation stack can be sufficient and offers potential practical advantages.
Previous teach and repeat research has achieved high performance in difficult
conditions generally by using sophisticated, often expensive sensors, and has
often had high computational requirements. Biological systems, such as small
animals and insects like seeing ants, offer a proof of concept that robust and
generalisable navigation can be achieved with extremely limited visual systems
and computing power. In this work we create a novel asynchronous formulation
for teach and repeat navigation that fully utilises odometry information,
paired with a correction signal driven by much more computationally lightweight
visual processing than is typically required. This correction signal is also
decoupled from the robot's motor control, allowing its rate to be modulated by
the available computing capacity. We evaluate this approach with extensive
experimentation on two different robotic platforms, the Consequential Robotics
Miro and the Clearpath Jackal robots, across navigation trials totalling more
than 6000 metres in a range of challenging indoor and outdoor environments. Our
approach is more robust and requires significantly less compute than the
state-of-the-art. It is also capable of intervention-free -- no parameter
changes required -- cross-platform generalisation, learning to navigate a route
on one robot and repeating that route on a different type of robot with
different camera.
</p>
<a href="http://arxiv.org/abs/2010.11326" target="_blank">arXiv:2010.11326</a> [<a href="http://arxiv.org/pdf/2010.11326" target="_blank">pdf</a>]

<h2>Meta-Learning Guarantees for Online Receding Horizon Control. (arXiv:2010.11327v1 [eess.SY])</h2>
<h3>Deepan Muthirayan, Pramod P. Khargonekar</h3>
<p>In this paper we provide provable regret guarantees for an online
meta-learning receding horizon control algorithm in an iterative control
setting, where in each iteration the system to be controlled is a linear
deterministic system that is different and unknown, the cost for the controller
in an iteration is a general additive cost function and the control input is
required to be constrained, which if violated incurs an additional cost. We
prove (i) that the algorithm achieves a regret for the controller cost and
constraint violation that are $O(T^{3/4})$ for an episode of duration $T$ with
respect to the best policy that satisfies the control input control constraints
and (ii) that the average of the regret for the controller cost and constraint
violation with respect to the same policy vary as $O((1+1/\sqrt{N})T^{3/4})$
with the number of iterations $N$, showing that the worst regret for the
learning within an iteration continuously improves with experience of more
iterations.
</p>
<a href="http://arxiv.org/abs/2010.11327" target="_blank">arXiv:2010.11327</a> [<a href="http://arxiv.org/pdf/2010.11327" target="_blank">pdf</a>]

<h2>A General Multi-Task Learning Framework to Leverage Text Data for Speech to Text Tasks. (arXiv:2010.11338v1 [cs.CL])</h2>
<h3>Yun Tang, Juan Pino, Changhan Wang, Xutai Ma, Dmitriy Genzel</h3>
<p>Attention-based sequence-to-sequence modeling provides a powerful and elegant
solution for applications that need to map one sequence to a different
sequence. Its success heavily relies on the availability of large amounts of
training data. This presents a challenge for speech applications where labelled
speech data is very expensive to obtain, such as automatic speech recognition
(ASR) and speech translation (ST). In this study, we propose a general
multi-task learning framework to leverage text data for ASR and ST tasks. Two
auxiliary tasks, a denoising autoencoder task and machine translation task, are
proposed to be co-trained with ASR and ST tasks respectively. We demonstrate
that representing text input as phoneme sequences can reduce the difference
between speech and text inputs, and enhance the knowledge transfer from text
corpora to the speech to text tasks. Our experiments show that the proposed
method achieves a relative 10~15% word error rate reduction on the English
Librispeech task, and improves the speech translation quality on the MuST-C
tasks by 4.2~11.1 BLEU.
</p>
<a href="http://arxiv.org/abs/2010.11338" target="_blank">arXiv:2010.11338</a> [<a href="http://arxiv.org/pdf/2010.11338" target="_blank">pdf</a>]

<h2>Trajectory Prediction using Equivariant Continuous Convolution. (arXiv:2010.11344v1 [cs.LG])</h2>
<h3>Robin Walters, Jinxi Li, Rose Yu</h3>
<p>Trajectory prediction is a critical part of many AI applications, for
example, the safe operation of autonomous vehicles. However, current methods
are prone to making inconsistent and physically unrealistic predictions. We
leverage insights from fluid dynamics to overcome this limitation by
considering internal symmetry in trajectories. We propose a novel model,
Equivariant Continous COnvolution (ECCO) for improved trajectory prediction.
ECCO uses rotationally-equivariant continuous convolutions to embed the
symmetries of the system. On two real-world vehicle and pedestrian trajectory
datasets, ECCO attains competitive accuracy with significantly fewer
parameters. It is also more sample efficient, generalizing automatically from
few data points in any orientation. Lastly, ECCO improves generalization with
equivariance, resulting in more physically consistent predictions. Our method
provides a fresh perspective towards increasing trust and transparency in deep
learning models.
</p>
<a href="http://arxiv.org/abs/2010.11344" target="_blank">arXiv:2010.11344</a> [<a href="http://arxiv.org/pdf/2010.11344" target="_blank">pdf</a>]

<h2>Deep Learning for Efficient Reconstruction of High-Resolution Turbulent DNS Data. (arXiv:2010.11348v1 [physics.flu-dyn])</h2>
<h3>Pranshu Pant, Amir Barati Farimani</h3>
<p>Within the domain of Computational Fluid Dynamics, Direct Numerical
Simulation (DNS) is used to obtain highly accurate numerical solutions for
fluid flows. However, this approach for numerically solving the Navier-Stokes
equations is extremely computationally expensive mostly due to the requirement
of greatly refined grids. Large Eddy Simulation (LES) presents a more
computationally efficient approach for solving fluid flows on lower-resolution
(LR) grids but results in an overall reduction in solution fidelity. Through
this paper, we introduce a novel deep learning framework SR-DNS Net, which aims
to mitigate this inherent trade-off between solution fidelity and computational
complexity by leveraging deep learning techniques used in image
super-resolution. Using our model, we wish to learn the mapping from a coarser
LR solution to a refined high-resolution (HR) DNS solution so as to eliminate
the need for DNS simulations on highly refined grids. Our model efficiently
reconstructs the high-fidelity DNS data from the LES like low-resolution
solutions while yielding good reconstruction metrics. Thus our implementation
improves the solution accuracy of LR solutions while incurring only a marginal
increase in computational cost required for deploying the trained deep learning
model.
</p>
<a href="http://arxiv.org/abs/2010.11348" target="_blank">arXiv:2010.11348</a> [<a href="http://arxiv.org/pdf/2010.11348" target="_blank">pdf</a>]

<h2>Class-Conditional Defense GAN Against End-to-End Speech Attacks. (arXiv:2010.11352v1 [cs.SD])</h2>
<h3>Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich</h3>
<p>In this paper we propose a novel defense approach against end-to-end
adversarial attacks developed to fool advanced speech-to-text systems such as
DeepSpeech and Lingvo. Unlike conventional defense approaches, the proposed
approach does not directly employ low-level transformations such as
autoencoding a given input signal aiming at removing potential adversarial
perturbation. Instead of that, we find an optimal input vector for a class
conditional generative adversarial network through minimizing the relative
chordal distance adjustment between a given test input and the generator
network. Then, we reconstruct the 1D signal from the synthesized spectrogram
and the original phase information derived from the given input signal. Hence,
this reconstruction does not add any extra noise to the signal and according to
our experimental results, our defense-GAN considerably outperforms conventional
defense algorithms both in terms of word error rate and sentence level
recognition accuracy.
</p>
<a href="http://arxiv.org/abs/2010.11352" target="_blank">arXiv:2010.11352</a> [<a href="http://arxiv.org/pdf/2010.11352" target="_blank">pdf</a>]

<h2>PHEW: Paths with higher edge-weights give "winning tickets" without training data. (arXiv:2010.11354v1 [cs.LG])</h2>
<h3>Shreyas Malakarjun Patil, Constantine Dovrolis</h3>
<p>Sparse neural networks have generated substantial interest recently because
they can be more efficient in learning and inference, without any significant
drop in performance. The "lottery ticket hypothesis" has showed the existence
of such sparse subnetworks at initialization. Given a fully-connected
initialized architecture, our aim is to find such "winning ticket" networks,
without any training data. We first show the advantages of forming input-output
paths, over pruning individual connections, to avoid bottlenecks in gradient
propagation. Then, we show that Paths with Higher Edge-Weights (PHEW) at
initialization have higher loss gradient magnitude, resulting in more efficient
training. Selecting such paths can be performed without any data. We
empirically validate the effectiveness of the proposed approach against
pruning-before-training methods on CIFAR10, CIFAR100 and Tiny-ImageNet for
VGG-Net and ResNet. PHEW achieves significant improvements on the current
state-of-the-art methods at 10\%, 5\% and 2\% network density. We also evaluate
the structural similarity relationship between PHEW networks and pruned
networks constructed through Iterated Magnitude Pruning (IMP), concluding that
the former belong in the family of winning tickets networks.
</p>
<a href="http://arxiv.org/abs/2010.11354" target="_blank">arXiv:2010.11354</a> [<a href="http://arxiv.org/pdf/2010.11354" target="_blank">pdf</a>]

<h2>QISTA-Net: DNN Architecture to Solve $\ell_q$-norm Minimization Problem and Image Compressed Sensing. (arXiv:2010.11363v1 [cs.CV])</h2>
<h3>Gang-Xuan Lin, Shih-Wei Hu, Chun-Shien Lu</h3>
<p>In this paper, we reformulate the non-convex $\ell_q$-norm minimization
problem with $q\in(0,1)$ into a 2-step problem, which consists of one convex
and one non-convex subproblems, and propose a novel iterative algorithm called
QISTA ($\ell_q$-ISTA) to solve the $\left(\ell_q\right)$-problem. By taking
advantage of deep learning in accelerating optimization algorithms, together
with the speedup strategy that using the momentum from all previous layers in
the network, we propose a learning-based method, called QISTA-Net-s, to solve
the sparse signal reconstruction problem. Extensive experimental comparisons
demonstrate that the QISTA-Net-s yield better reconstruction qualities than
state-of-the-art $\ell_1$-norm optimization (plus learning) algorithms even if
the original sparse signal is noisy. On the other hand, based on the network
architecture associated with QISTA, with considering the use of convolution
layers, we proposed the QISTA-Net-n for solving the image CS problem, and the
performance of the reconstruction still outperforms most of the
state-of-the-art natural images reconstruction methods. QISTA-Net-n is designed
in unfolding QISTA and adding the convolutional operator as the dictionary.
This makes QISTA-Net-s interpretable. We provide complete experimental results
that QISTA-Net-s and QISTA-Net-n contribute the better reconstruction
performance than the competing.
</p>
<a href="http://arxiv.org/abs/2010.11363" target="_blank">arXiv:2010.11363</a> [<a href="http://arxiv.org/pdf/2010.11363" target="_blank">pdf</a>]

<h2>On a Guided Nonnegative Matrix Factorization. (arXiv:2010.11365v1 [cs.LG])</h2>
<h3>Joshua Vendrow, Jamie Haddock, Elizaveta Rebrova, Deanna Needell</h3>
<p>Fully unsupervised topic models have found fantastic success in document
clustering and classification. However, these models often suffer from the
tendency to learn less-than-meaningful or even redundant topics when the data
is biased towards a set of features. For this reason, we propose an approach
based upon the nonnegative matrix factorization (NMF) model, deemed
\textit{Guided NMF}, that incorporates user-designed seed word supervision. Our
experimental results demonstrate the promise of this model and illustrate that
it is competitive with other methods of this ilk with only very little
supervision information.
</p>
<a href="http://arxiv.org/abs/2010.11365" target="_blank">arXiv:2010.11365</a> [<a href="http://arxiv.org/pdf/2010.11365" target="_blank">pdf</a>]

<h2>TeX-Graph: Coupled tensor-matrix knowledge-graph embedding for COVID-19 drug repurposing. (arXiv:2010.11367v1 [cs.SI])</h2>
<h3>Charilaos I. Kanatsoulis, Nicholas D. Sidiropoulos</h3>
<p>Knowledge graphs (KGs) are powerful tools that codify relational behaviour
between entities in knowledge bases. KGs can simultaneously model many
different types of subject-predicate-object and higher-order relations. As
such, they offer a flexible modeling framework that has been applied to many
areas, including biology and pharmacology -- most recently, in the fight
against COVID-19. The flexibility of KG modeling is both a blessing and a
challenge from the learning point of view. In this paper we propose a novel
coupled tensor-matrix framework for KG embedding. We leverage tensor
factorization tools to learn concise representations of entities and relations
in knowledge bases and employ these representations to perform drug repurposing
for COVID-19. Our proposed framework is principled, elegant, and achieves 100%
improvement over the best baseline in the COVID-19 drug repurposing task using
a recently developed biological KG.
</p>
<a href="http://arxiv.org/abs/2010.11367" target="_blank">arXiv:2010.11367</a> [<a href="http://arxiv.org/pdf/2010.11367" target="_blank">pdf</a>]

<h2>Learning Graph-Based Priors for Generalized Zero-Shot Learning. (arXiv:2010.11369v1 [cs.CV])</h2>
<h3>Colin Samplawski, Jannik Wolff, Tassilo Klein, Moin Nabi</h3>
<p>The task of zero-shot learning (ZSL) requires correctly predicting the label
of samples from classes which were unseen at training time. This is achieved by
leveraging side information about class labels, such as label attributes or
word embeddings. Recently, attention has shifted to the more realistic task of
generalized ZSL (GZSL) where test sets consist of seen and unseen samples.
Recent approaches to GZSL have shown the value of generative models, which are
used to generate samples from unseen classes. In this work, we incorporate an
additional source of side information in the form of a relation graph over
labels. We leverage this graph in order to learn a set of prior distributions,
which encourage an aligned variational autoencoder (VAE) model to learn
embeddings which respect the graph structure. Using this approach we are able
to achieve improved performance on the CUB and SUN benchmarks over a strong
baseline.
</p>
<a href="http://arxiv.org/abs/2010.11369" target="_blank">arXiv:2010.11369</a> [<a href="http://arxiv.org/pdf/2010.11369" target="_blank">pdf</a>]

<h2>Deep Learning for Distinguishing Normal versus Abnormal Chest Radiographs and Generalization to Unseen Diseases. (arXiv:2010.11375v1 [eess.IV])</h2>
<h3>Zaid Nabulsi, Andrew Sellergren, Shahar Jamshy, Charles Lau, Eddie Santos, Atilla P. Kiraly, Wenxing Ye, Jie Yang, Sahar Kazemzadeh, Jin Yu, Raju Kalidindi, Mozziyar Etemadi, Florencia Garcia Vicente, David Melnick, Greg S. Corrado, Lily Peng, Krish Eswaran, Daniel Tse, Neeral Beladia, Yun Liu, Po-Hsuan Cameron Chen, Shravya Shetty</h3>
<p>Chest radiography (CXR) is the most widely-used thoracic clinical imaging
modality and is crucial for guiding the management of cardiothoracic
conditions. The detection of specific CXR findings has been the main focus of
several artificial intelligence (AI) systems. However, the wide range of
possible CXR abnormalities makes it impractical to build specific systems to
detect every possible condition. In this work, we developed and evaluated an AI
system to classify CXRs as normal or abnormal. For development, we used a
de-identified dataset of 248,445 patients from a multi-city hospital network in
India. To assess generalizability, we evaluated our system using 6
international datasets from India, China, and the United States. Of these
datasets, 4 focused on diseases that the AI was not trained to detect: 2
datasets with tuberculosis and 2 datasets with coronavirus disease 2019. Our
results suggest that the AI system generalizes to new patient populations and
abnormalities. In a simulated workflow where the AI system prioritized abnormal
cases, the turnaround time for abnormal cases reduced by 7-28%. These results
represent an important step towards evaluating whether AI can be safely used to
flag cases in a general setting where previously unseen abnormalities exist.
</p>
<a href="http://arxiv.org/abs/2010.11375" target="_blank">arXiv:2010.11375</a> [<a href="http://arxiv.org/pdf/2010.11375" target="_blank">pdf</a>]

<h2>Learning Occupancy Function from Point Clouds for Surface Reconstruction. (arXiv:2010.11378v1 [cs.CV])</h2>
<h3>Meng Jia, Matthew Kyan</h3>
<p>Implicit function based surface reconstruction has been studied for a long
time to recover 3D shapes from point clouds sampled from surfaces. Recently,
Signed Distance Functions (SDFs) and Occupany Functions are adopted in
learning-based shape reconstruction methods as implicit 3D shape
representation. This paper proposes a novel method for learning occupancy
functions from sparse point clouds and achieves better performance on
challenging surface reconstruction tasks. Unlike the previous methods, which
predict point occupancy with fully-connected multi-layer networks, we adapt the
point cloud deep learning architecture, Point Convolution Neural Network
(PCNN), to build our learning model. Specifically, we create a sampling
operator and insert it into PCNN to continuously sample the feature space at
the points where occupancy states need to be predicted. This method natively
obtains point cloud data's geometric nature, and it's invariant to point
permutation. Our occupancy function learning can be easily fit into procedures
of point cloud up-sampling and surface reconstruction. Our experiments show
state-of-the-art performance for reconstructing With ShapeNet dataset and
demonstrate this method's well-generalization by testing it with McGill 3D
dataset \cite{siddiqi2008retrieving}. Moreover, we find the learned occupancy
function is relatively more rotation invariant than previous shape learning
methods.
</p>
<a href="http://arxiv.org/abs/2010.11378" target="_blank">arXiv:2010.11378</a> [<a href="http://arxiv.org/pdf/2010.11378" target="_blank">pdf</a>]

<h2>Query strategies for priced information, revisited. (arXiv:2010.11381v1 [cs.DS])</h2>
<h3>Guy Blanc, Jane Lange, Li-Yang Tan</h3>
<p>We consider the problem of designing query strategies for priced information,
introduced by Charikar et al. In this problem the algorithm designer is given a
function $f : \{0,1\}^n \to \{-1,1\}$ and a price associated with each of the
$n$ coordinates. The goal is to design a query strategy for determining $f$'s
value on unknown inputs for minimum cost.

Prior works on this problem have focused on specific classes of functions. We
analyze a simple and natural strategy that applies to all functions $f$, and
show that its performance relative to the optimal strategy can be expressed in
terms of a basic complexity measure of $f$, its influence. For $\varepsilon \in
(0,\frac1{2})$, writing $\mathsf{opt}$ to denote the expected cost of the
optimal strategy that errs on at most an $\varepsilon$-fraction of inputs, our
strategy has expected cost $\mathsf{opt} \cdot \mathrm{Inf}(f)/\varepsilon^2$
and also errs on at most an $O(\varepsilon)$-fraction of inputs. This
connection yields new guarantees that complement existing ones for a number of
function classes that have been studied in this context, as well as new
guarantees for new classes.

Finally, we show that improving on the parameters that we achieve will
require making progress on the longstanding open problem of properly learning
decision trees.
</p>
<a href="http://arxiv.org/abs/2010.11381" target="_blank">arXiv:2010.11381</a> [<a href="http://arxiv.org/pdf/2010.11381" target="_blank">pdf</a>]

<h2>Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses. (arXiv:2010.11387v1 [cs.CL])</h2>
<h3>George Boateng</h3>
<p>Introductory hands-on courses such as our smartphone-based coding courses,
SuaCode require a lot of support for students to accomplish learning goals.
Online environments make it even more difficult to get assistance especially
more recently because of COVID-19. Given the multilingual context of our
students (learners across 38 African countries), in this work, we developed an
AI Teaching Assistant (Kwame) that provides answers to students' coding
questions from our SuaCode courses in English and French. Kwame is a
Sentence-BERT(SBERT)-based question-answering (QA) system that we trained and
evaluated using question-answer pairs created from our course's quizzes and
students' questions in past cohorts. It finds the paragraph most semantically
similar to the question via cosine similarity. We compared the system with
TF-IDF and Universal Sentence Encoder. Our results showed that SBERT performed
the worst for the duration of 6 secs per question but the best for accuracy and
fine-tuning on our course data improved the result.
</p>
<a href="http://arxiv.org/abs/2010.11387" target="_blank">arXiv:2010.11387</a> [<a href="http://arxiv.org/pdf/2010.11387" target="_blank">pdf</a>]

<h2>Adversarial Attacks on Deep Algorithmic Trading Policies. (arXiv:2010.11388v1 [cs.LG])</h2>
<h3>Yaser Faghan, Nancirose Piazza, Vahid Behzadan, Ali Fathi</h3>
<p>Deep Reinforcement Learning (DRL) has become an appealing solution to
algorithmic trading such as high frequency trading of stocks and
cyptocurrencies. However, DRL have been shown to be susceptible to adversarial
attacks. It follows that algorithmic trading DRL agents may also be compromised
by such adversarial techniques, leading to policy manipulation. In this paper,
we develop a threat model for deep trading policies, and propose two attack
techniques for manipulating the performance of such policies at test-time.
Furthermore, we demonstrate the effectiveness of the proposed attacks against
benchmark and real-world DQN trading agents.
</p>
<a href="http://arxiv.org/abs/2010.11388" target="_blank">arXiv:2010.11388</a> [<a href="http://arxiv.org/pdf/2010.11388" target="_blank">pdf</a>]

<h2>UNITE: Uncertainty-based Health Risk Prediction Leveraging Multi-sourced Data. (arXiv:2010.11389v1 [cs.LG])</h2>
<h3>Chacha Chen, Junjie Liang, Fenglong Ma, Lucas M. Glass, Jimeng Sun, Cao Xiao</h3>
<p>Successful health risk prediction demands accuracy and reliability of the
model. Existing predictive models mainly depend on mining electronic health
records (EHR) with advanced deep learning techniques to improve model accuracy.
However, they all ignore the importance of publicly available online health
data, especially socioeconomic status, environmental factors, and detailed
demographic information for each location, which are all strong predictive
signals and can definitely augment precision medicine. To achieve model
reliability, the model needs to provide accurate prediction and uncertainty
score of the prediction. However, existing uncertainty estimation approaches
often failed in handling high-dimensional data, which are present in
multi-sourced data. To fill the gap, we propose UNcertaInTy-based hEalth risk
prediction (UNITE) model. Building upon an adaptive multimodal deep kernel and
a stochastic variational inference module, UNITE provides accurate disease risk
prediction and uncertainty estimation leveraging multi-sourced health data
including EHR data, patient demographics, and public health data collected from
the web. We evaluate UNITE on real-world disease risk prediction tasks:
nonalcoholic fatty liver disease (NASH) and Alzheimer's disease (AD). UNITE
achieves up to 0.841 in F1 score for AD detection, up to 0.609 in PR-AUC for
NASH detection, and outperforms various state-of-the-art baselines by up to
$19\%$ over the best baseline. We also show UNITE can model meaningful
uncertainties and can provide evidence-based clinical support by clustering
similar patients.
</p>
<a href="http://arxiv.org/abs/2010.11389" target="_blank">arXiv:2010.11389</a> [<a href="http://arxiv.org/pdf/2010.11389" target="_blank">pdf</a>]

<h2>When Machine Learning Meets Congestion Control: A Survey and Comparison. (arXiv:2010.11397v1 [cs.NI])</h2>
<h3>Huiling Jiang, Qing Li, Yong Jiang, Gengbiao Shen, Richard Sinnott, Chen Tian, Mingwei Xu</h3>
<p>Machine learning (ML) has seen a significant surge and uptake across many
diverse applications. The high flexibility, adaptability and computing
capabilities it provides extends traditional approaches used in multiple fields
including network operation and management. Numerous surveys have explored ML
in the context of networking, such as traffic engineering, performance
optimization and network security. Many ML approaches focus on clustering,
classification, regression and reinforcement learning (RL). The innovation of
this research and contribution of this paper lies in the detailed summary and
comparison of learning-based congestion control (CC) approaches. Compared with
traditional CC algorithms which are typically rule-based, capabilities to learn
from historical experience are highly desirable. From the literature, it is
observed that RL is a crucial trend among learning-based CC algorithms. In this
paper, we explore the performance of RL-based CC algorithms and present current
problems with RL-based CC algorithms. We outline challenges and trends related
to learning-based CC algorithms.
</p>
<a href="http://arxiv.org/abs/2010.11397" target="_blank">arXiv:2010.11397</a> [<a href="http://arxiv.org/pdf/2010.11397" target="_blank">pdf</a>]

<h2>DPD-InfoGAN: Differentially Private Distributed InfoGAN. (arXiv:2010.11398v1 [cs.LG])</h2>
<h3>Vaikkunth Mugunthan, Vignesh Gokul, Lalana Kagal, Shlomo Dubnov</h3>
<p>Generative Adversarial Networks (GANs) are deep learning architectures
capable of generating synthetic datasets. Despite producing high-quality
synthetic images, the default GAN has no control over the kinds of images it
generates. The Information Maximizing GAN (InfoGAN) is a variant of the default
GAN that introduces feature-control variables that are automatically learned by
the framework, hence providing greater control over the different kinds of
images produced. Due to the high model complexity of InfoGAN, the generative
distribution tends to be concentrated around the training data points. This is
a critical problem as the models may inadvertently expose the sensitive and
private information present in the dataset. To address this problem, we propose
a differentially private version of InfoGAN (DP-InfoGAN). We also extend our
framework to a distributed setting (DPD-InfoGAN) to allow clients to learn
different attributes present in other clients' datasets in a privacy-preserving
manner. In our experiments, we show that both DP-InfoGAN and DPD-InfoGAN can
synthesize high-quality images with flexible control over image attributes
while preserving privacy.
</p>
<a href="http://arxiv.org/abs/2010.11398" target="_blank">arXiv:2010.11398</a> [<a href="http://arxiv.org/pdf/2010.11398" target="_blank">pdf</a>]

<h2>Learning Transferrable Parameters for Long-tailed Sequential User Behavior Modeling. (arXiv:2010.11401v1 [cs.AI])</h2>
<h3>Jianwen Yin, Chenghao Liu, Weiqing Wang, Jianling Sun, Steven C.H. Hoi</h3>
<p>Sequential user behavior modeling plays a crucial role in online
user-oriented services, such as product purchasing, news feed consumption, and
online advertising. The performance of sequential modeling heavily depends on
the scale and quality of historical behaviors. However, the number of user
behaviors inherently follows a long-tailed distribution, which has been seldom
explored. In this work, we argue that focusing on tail users could bring more
benefits and address the long tails issue by learning transferrable parameters
from both optimization and feature perspectives. Specifically, we propose a
gradient alignment optimizer and adopt an adversarial training scheme to
facilitate knowledge transfer from the head to the tail. Such methods can also
deal with the cold-start problem of new users. Moreover, it could be directly
adaptive to various well-established sequential models. Extensive experiments
on four real-world datasets verify the superiority of our framework compared
with the state-of-the-art baselines.
</p>
<a href="http://arxiv.org/abs/2010.11401" target="_blank">arXiv:2010.11401</a> [<a href="http://arxiv.org/pdf/2010.11401" target="_blank">pdf</a>]

<h2>Value Cards: An Educational Toolkit for Teaching Social Impacts of Machine Learning through Deliberation. (arXiv:2010.11411v1 [cs.CY])</h2>
<h3>Hong Shen, Wesley Deng, Aditi Chattopadhyay, Steven Wu, Xu Wang, Haiyi Zhu</h3>
<p>Recently, there have been increasing calls for computer science curricula to
complement existing technical training with topics related to Fairness,
Accountability, Transparency, and Ethics. In this paper, we present Value Card,
an educational toolkit to inform students and practitioners of the social
impacts of different machine learning models via deliberation. This paper
presents an early use of our approach in a college-level computer science
course. Through an in-class activity, we report empirical data for the initial
effectiveness of our approach. Our results suggest that the use of the Value
Cards toolkit can improve students' understanding of both the technical
definitions and trade-offs of performance metrics and apply them in real-world
contexts, help them recognize the significance of considering diverse social
values in the development of deployment of algorithmic systems, and enable them
to communicate, negotiate and synthesize the perspectives of diverse
stakeholders. Our study also demonstrates a number of caveats we need to
consider when using the different variants of the Value Cards toolkit. Finally,
we discuss the challenges as well as future applications of our approach.
</p>
<a href="http://arxiv.org/abs/2010.11411" target="_blank">arXiv:2010.11411</a> [<a href="http://arxiv.org/pdf/2010.11411" target="_blank">pdf</a>]

<h2>Maximum Mean Discrepancy is Aware of Adversarial Attacks. (arXiv:2010.11415v1 [cs.LG])</h2>
<h3>Ruize Gao, Feng Liu, Jingfeng Zhang, Bo Han, Tongliang Liu, Gang Niu, Masashi Sugiyama</h3>
<p>The maximum mean discrepancy (MMD) test, as a representative two-sample test,
could in principle detect any distributional discrepancy between two datasets.
However, it has been shown that MMD is unaware of adversarial attacks---MMD
failed to detect the discrepancy between natural data and adversarial data
generated by adversarial attacks. Given this phenomenon, we raise a question:
are natural and adversarial data really from different distributions but
previous use of MMD on the purpose missed some key factors? The answer is
affirmative. We find the previous use missed three factors and accordingly we
propose three components: (a) Gaussian kernel has limited representation power,
and we replace it with a novel semantic-aware deep kernel; (b) test power of
MMD was neglected, and we maximize it in order to optimize our deep kernel; (c)
adversarial data may be non-independent, and to this end we apply wild
bootstrap for validity of the test power. By taking care of the three factors,
we validate that MMD is aware of adversarial attacks, which lights up a novel
road for adversarial attack detection based on two-sample tests.
</p>
<a href="http://arxiv.org/abs/2010.11415" target="_blank">arXiv:2010.11415</a> [<a href="http://arxiv.org/pdf/2010.11415" target="_blank">pdf</a>]

<h2>Pool-based sequential active learning with multi kernels. (arXiv:2010.11421v1 [cs.LG])</h2>
<h3>Jeongmin Chae, Songnam Hong</h3>
<p>We study a pool-based sequential active learning (AL), in which one sample is
queried at each time from a large pool of unlabeled data according to a
selection criterion. For this framework, we propose two selection criteria,
named expected-kernel-discrepancy (EKD) and expected-kernel-loss (EKL), by
leveraging the particular structure of multiple kernel learning (MKL). Also, it
is identified that the proposed EKD and EKL successfully generalize the
concepts of popular query-by-committee (QBC) and expected-model-change (EMC),
respectively. Via experimental results with real-data sets, we verify the
effectiveness of the proposed criteria compared with the existing methods.
</p>
<a href="http://arxiv.org/abs/2010.11421" target="_blank">arXiv:2010.11421</a> [<a href="http://arxiv.org/pdf/2010.11421" target="_blank">pdf</a>]

<h2>Learning Loss for Test-Time Augmentation. (arXiv:2010.11422v1 [cs.CV])</h2>
<h3>Ildoo Kim, Younghoon Kim, Sungwoong Kim</h3>
<p>Data augmentation has been actively studied for robust neural networks. Most
of the recent data augmentation methods focus on augmenting datasets during the
training phase. At the testing phase, simple transformations are still widely
used for test-time augmentation. This paper proposes a novel instance-level
test-time augmentation that efficiently selects suitable transformations for a
test input. Our proposed method involves an auxiliary module to predict the
loss of each possible transformation given the input. Then, the transformations
having lower predicted losses are applied to the input. The network obtains the
results by averaging the prediction results of augmented inputs. Experimental
results on several image classification benchmarks show that the proposed
instance-aware test-time augmentation improves the model's robustness against
various corruptions.
</p>
<a href="http://arxiv.org/abs/2010.11422" target="_blank">arXiv:2010.11422</a> [<a href="http://arxiv.org/pdf/2010.11422" target="_blank">pdf</a>]

<h2>DeepCSR: A 3D Deep Learning Approach for Cortical Surface Reconstruction. (arXiv:2010.11423v1 [eess.IV])</h2>
<h3>Rodrigo Santa Cruz, Leo Lebrat, Pierrick Bourgeat, Clinton Fookes, Jurgen Fripp, Olivier Salvado</h3>
<p>The study of neurodegenerative diseases relies on the reconstruction and
analysis of the brain cortex from magnetic resonance imaging (MRI). Traditional
frameworks for this task like FreeSurfer demand lengthy runtimes, while its
accelerated variant FastSurfer still relies on a voxel-wise segmentation which
is limited by its resolution to capture narrow continuous objects as cortical
surfaces. Having these limitations in mind, we propose DeepCSR, a 3D deep
learning framework for cortical surface reconstruction from MRI. Towards this
end, we train a neural network model with hypercolumn features to predict
implicit surface representations for points in a brain template space. After
training, the cortical surface at a desired level of detail is obtained by
evaluating surface representations at specific coordinates, and subsequently
applying a topology correction algorithm and an isosurface extraction method.
Thanks to the continuous nature of this approach and the efficacy of its
hypercolumn features scheme, DeepCSR efficiently reconstructs cortical surfaces
at high resolution capturing fine details in the cortical folding. Moreover,
DeepCSR is as accurate, more precise, and faster than the widely used
FreeSurfer toolbox and its deep learning powered variant FastSurfer on
reconstructing cortical surfaces from MRI which should facilitate large-scale
medical studies and new healthcare applications.
</p>
<a href="http://arxiv.org/abs/2010.11423" target="_blank">arXiv:2010.11423</a> [<a href="http://arxiv.org/pdf/2010.11423" target="_blank">pdf</a>]

<h2>Differentially-Private Federated Linear Bandits. (arXiv:2010.11425v1 [cs.LG])</h2>
<h3>Abhimanyu Dubey, Alex Pentland</h3>
<p>The rapid proliferation of decentralized learning systems mandates the need
for differentially-private cooperative learning. In this paper, we study this
in context of the contextual linear bandit: we consider a collection of agents
cooperating to solve a common contextual bandit, while ensuring that their
communication remains private. For this problem, we devise \textsc{FedUCB}, a
multiagent private algorithm for both centralized and decentralized
(peer-to-peer) federated learning. We provide a rigorous technical analysis of
its utility in terms of regret, improving several results in cooperative bandit
learning, and provide rigorous privacy guarantees as well. Our algorithms
provide competitive performance both in terms of pseudoregret bounds and
empirical benchmark performance in various multi-agent settings.
</p>
<a href="http://arxiv.org/abs/2010.11425" target="_blank">arXiv:2010.11425</a> [<a href="http://arxiv.org/pdf/2010.11425" target="_blank">pdf</a>]

<h2>Efficient Scale-Permuted Backbone with Learned Resource Distribution. (arXiv:2010.11426v1 [cs.CV])</h2>
<h3>Xianzhi Du, Tsung-Yi Lin, Pengchong Jin, Yin Cui, Mingxing Tan, Quoc Le, Xiaodan Song</h3>
<p>Recently, SpineNet has demonstrated promising results on object detection and
image classification over ResNet model. However, it is unclear if the
improvement adds up when combining scale-permuted backbone with advanced
efficient operations and compound scaling. Furthermore, SpineNet is built with
a uniform resource distribution over operations. While this strategy seems to
be prevalent for scale-decreased models, it may not be an optimal design for
scale-permuted models. In this work, we propose a simple technique to combine
efficient operations and compound scaling with a previously learned
scale-permuted architecture. We demonstrate the efficiency of scale-permuted
model can be further improved by learning a resource distribution over the
entire network. The resulting efficient scale-permuted models outperform
state-of-the-art EfficientNet-based models on object detection and achieve
competitive performance on image classification and semantic segmentation. Code
and models will be open-sourced soon.
</p>
<a href="http://arxiv.org/abs/2010.11426" target="_blank">arXiv:2010.11426</a> [<a href="http://arxiv.org/pdf/2010.11426" target="_blank">pdf</a>]

<h2>Confidence Estimation for Attention-based Sequence-to-sequence Models for Speech Recognition. (arXiv:2010.11428v1 [eess.AS])</h2>
<h3>Qiujia Li, David Qiu, Yu Zhang, Bo Li, Yanzhang He, Philip C. Woodland, Liangliang Cao, Trevor Strohman</h3>
<p>For various speech-related tasks, confidence scores from a speech recogniser
are a useful measure to assess the quality of transcriptions. In traditional
hidden Markov model-based automatic speech recognition (ASR) systems,
confidence scores can be reliably obtained from word posteriors in decoding
lattices. However, for an ASR system with an auto-regressive decoder, such as
an attention-based sequence-to-sequence model, computing word posteriors is
difficult. An obvious alternative is to use the decoder softmax probability as
the model confidence. In this paper, we first examine how some commonly used
regularisation methods influence the softmax-based confidence scores and study
the overconfident behaviour of end-to-end models. Then we propose a lightweight
and effective approach named confidence estimation module (CEM) on top of an
existing end-to-end ASR model. Experiments on LibriSpeech show that CEM can
mitigate the overconfidence problem and can produce more reliable confidence
scores with and without shallow fusion of a language model. Further analysis
shows that CEM generalises well to speech from a moderately mismatched domain
and can potentially improve downstream tasks such as semi-supervised learning.
</p>
<a href="http://arxiv.org/abs/2010.11428" target="_blank">arXiv:2010.11428</a> [<a href="http://arxiv.org/pdf/2010.11428" target="_blank">pdf</a>]

<h2>Unsupervised Representation Learning for Speaker Recognition via Contrastive Equilibrium Learning. (arXiv:2010.11433v1 [eess.AS])</h2>
<h3>Sung Hwan Mun, Woo Hyun Kang, Min Hyun Han, Nam Soo Kim</h3>
<p>In this paper, we propose a simple but powerful unsupervised learning method
for speaker recognition, namely Contrastive Equilibrium Learning (CEL), which
increases the uncertainty on nuisance factors latent in the embeddings by
employing the uniformity loss. Also, to preserve speaker discriminability, a
contrastive similarity loss function is used together. Experimental results
showed that the proposed CEL significantly outperforms the state-of-the-art
unsupervised speaker verification systems and the best performing model
achieved 8.01% and 4.01% EER on VoxCeleb1 and VOiCES evaluation sets,
respectively. On top of that, the performance of the supervised speaker
embedding networks trained with initial parameters pre-trained via CEL showed
better performance than those trained with randomly initialized parameters.
</p>
<a href="http://arxiv.org/abs/2010.11433" target="_blank">arXiv:2010.11433</a> [<a href="http://arxiv.org/pdf/2010.11433" target="_blank">pdf</a>]

<h2>Task-Adaptive Feature Transformer for Few-Shot Segmentation. (arXiv:2010.11437v1 [cs.CV])</h2>
<h3>Jun Seo, Young-Hyun Park, Sung-Whan Yoon, Jaekyun Moon</h3>
<p>Few-shot learning allows machines to classify novel classes using only a few
labeled samples. Recently, few-shot segmentation aiming at semantic
segmentation on low sample data has also seen great interest. In this paper, we
propose a learnable module for few-shot segmentation, the task-adaptive feature
transformer (TAFT). TAFT linearly transforms task-specific high-level features
to a set of task-agnostic features well-suited to the segmentation job. Using
this task-conditioned feature transformation, the model is shown to effectively
utilize the semantic information in novel classes to generate tight
segmentation masks. The proposed TAFT module can be easily plugged into
existing semantic segmentation algorithms to achieve few-shot segmentation
capability with only a few added parameters. We combine TAFT with Deeplab V3+,
a well-known segmentation architecture; experiments on the PASCAL-$5^i$ dataset
confirm that this combination successfully adds few-shot learning capability to
the segmentation algorithm, achieving the state-of-the-art few-shot
segmentation performance in some key representative cases.
</p>
<a href="http://arxiv.org/abs/2010.11437" target="_blank">arXiv:2010.11437</a> [<a href="http://arxiv.org/pdf/2010.11437" target="_blank">pdf</a>]

<h2>GAN based Unsupervised Segmentation: Should We Match the Exact Number of Objects. (arXiv:2010.11438v1 [cs.CV])</h2>
<h3>Quan Liu, Isabella M. Gaeta, Bryan A. Millis, Matthew J. Tyska, Yuankai Huo</h3>
<p>The unsupervised segmentation is an increasingly popular topic in biomedical
image analysis. The basic idea is to approach the supervised segmentation task
as an unsupervised synthesis problem, where the intensity images can be
transferred to the annotation domain using cycle-consistent adversarial
learning. The previous studies have shown that the macro-level (global
distribution level) matching on the number of the objects (e.g., cells,
tissues, protrusions etc.) between two domains resulted in better segmentation
performance. However, no prior studies have exploited whether the unsupervised
segmentation performance would be further improved when matching the exact
number of objects at micro-level (mini-batch level). In this paper, we propose
a deep learning based unsupervised segmentation method for segmenting highly
overlapped and dynamic sub-cellular microvilli. With this challenging task,
both micro-level and macro-level matching strategies were evaluated. To match
the number of objects at the micro-level, the novel fluorescence-based
micro-level matching approach was presented. From the experimental results, the
micro-level matching did not improve the segmentation performance, compared
with the simpler macro-level matching.
</p>
<a href="http://arxiv.org/abs/2010.11438" target="_blank">arXiv:2010.11438</a> [<a href="http://arxiv.org/pdf/2010.11438" target="_blank">pdf</a>]

<h2>Optimal Robustness-Consistency Trade-offs for Learning-Augmented Online Algorithms. (arXiv:2010.11443v1 [cs.LG])</h2>
<h3>Alexander Wei, Fred Zhang</h3>
<p>We study the problem of improving the performance of online algorithms by
incorporating machine-learned predictions. The goal is to design algorithms
that are both consistent and robust, meaning that the algorithm performs well
when predictions are accurate and maintains worst-case guarantees. Such
algorithms have been studied in a recent line of works due to Lykouris and
Vassilvitskii (ICML '18) and Purohit et al (NeurIPS '18). They provide
robustness-consistency trade-offs for a variety of online problems. However,
they leave open the question of whether these trade-offs are tight, i.e., to
what extent to such trade-offs are necessary. In this paper, we provide the
first set of non-trivial lower bounds for competitive analysis using
machine-learned predictions. We focus on the classic problems of ski-rental and
non-clairvoyant scheduling and provide optimal trade-offs in various settings.
</p>
<a href="http://arxiv.org/abs/2010.11443" target="_blank">arXiv:2010.11443</a> [<a href="http://arxiv.org/pdf/2010.11443" target="_blank">pdf</a>]

<h2>Optimal Approximation -- Smoothness Tradeoffs for Soft-Max Functions. (arXiv:2010.11450v1 [cs.LG])</h2>
<h3>Alessandro Epasto, Mohammad Mahdian, Vahab Mirrokni, Manolis Zampetakis</h3>
<p>A soft-max function has two main efficiency measures: (1) approximation -
which corresponds to how well it approximates the maximum function, (2)
smoothness - which shows how sensitive it is to changes of its input. Our goal
is to identify the optimal approximation-smoothness tradeoffs for different
measures of approximation and smoothness. This leads to novel soft-max
functions, each of which is optimal for a different application. The most
commonly used soft-max function, called exponential mechanism, has optimal
tradeoff between approximation measured in terms of expected additive
approximation and smoothness measured with respect to R\'enyi Divergence. We
introduce a soft-max function, called "piecewise linear soft-max", with optimal
tradeoff between approximation, measured in terms of worst-case additive
approximation and smoothness, measured with respect to $\ell_q$-norm. The
worst-case approximation guarantee of the piecewise linear mechanism enforces
sparsity in the output of our soft-max function, a property that is known to be
important in Machine Learning applications [Martins et al. '16, Laha et al.
'18] and is not satisfied by the exponential mechanism. Moreover, the
$\ell_q$-smoothness is suitable for applications in Mechanism Design and Game
Theory where the piecewise linear mechanism outperforms the exponential
mechanism. Finally, we investigate another soft-max function, called power
mechanism, with optimal tradeoff between expected \textit{multiplicative}
approximation and smoothness with respect to the R\'enyi Divergence, which
provides improved theoretical and practical results in differentially private
submodular optimization.
</p>
<a href="http://arxiv.org/abs/2010.11450" target="_blank">arXiv:2010.11450</a> [<a href="http://arxiv.org/pdf/2010.11450" target="_blank">pdf</a>]

<h2>Machine Learning-Based Early Detection of IoT Botnets Using Network-Edge Traffic. (arXiv:2010.11453v1 [cs.CR])</h2>
<h3>Ayush Kumar, Mrinalini Shridhar, Sahithya Swaminathan, Teng Joon Lim</h3>
<p>In this work, we present a lightweight IoT botnet detection solution, EDIMA,
which is designed to be deployed at the edge gateway installed in home networks
and targets early detection of botnets prior to the launch of an attack. EDIMA
includes a novel two-stage Machine Learning (ML)-based detector developed
specifically for IoT bot detection at the edge gateway. The ML-based bot
detector first employs ML algorithms for aggregate traffic classification and
subsequently Autocorrelation Function (ACF)-based tests to detect individual
bots. The EDIMA architecture also comprises a malware traffic database, a
policy engine, a feature extractor and a traffic parser. Performance evaluation
results show that EDIMA achieves high bot scanning and bot-CnC traffic
detection accuracies with very low false positive rates. The detection
performance is also shown to be robust to an increase in the number of IoT
devices connected to the edge gateway where EDIMA is deployed. Further, the
runtime performance analysis of a Python implementation of EDIMA deployed on a
Raspberry Pi reveals low bot detection delays and low RAM consumption. EDIMA is
also shown to outperform existing detection techniques for bot scanning traffic
and bot-CnC server communication.
</p>
<a href="http://arxiv.org/abs/2010.11453" target="_blank">arXiv:2010.11453</a> [<a href="http://arxiv.org/pdf/2010.11453" target="_blank">pdf</a>]

<h2>Momentum Contrast Speaker Representation Learning. (arXiv:2010.11457v1 [eess.AS])</h2>
<h3>Jangho Lee, Jaihyun Koh, Sungroh Yoon</h3>
<p>Unsupervised representation learning has shown remarkable achievement by
reducing the performance gap with supervised feature learning, especially in
the image domain. In this study, to extend the technique of unsupervised
learning to the speech domain, we propose the Momentum Contrast for VoxCeleb
(MoCoVox) as a form of learning mechanism. We pre-trained the MoCoVox on the
VoxCeleb1 by implementing instance discrimination. Applying MoCoVox for speaker
verification revealed that it outperforms the state-of-the-art metric
learning-based approach by a large margin. We also empirically demonstrate the
features of contrastive learning in the speech domain by analyzing the
distribution of learned representations. Furthermore, we explored which pretext
task is adequate for speaker verification. We expect that learning speaker
representation without human supervision helps to address the open-set speaker
recognition.
</p>
<a href="http://arxiv.org/abs/2010.11457" target="_blank">arXiv:2010.11457</a> [<a href="http://arxiv.org/pdf/2010.11457" target="_blank">pdf</a>]

<h2>A Framework for Contrastive and Generative Learning of Audio Representations. (arXiv:2010.11459v1 [cs.SD])</h2>
<h3>Prateek Verma, Julius Smith</h3>
<p>In this paper, we present a framework for contrastive learning for audio
representations, in a self supervised frame work without access to any ground
truth labels. The core idea in self supervised contrastive learning is to map
an audio signal and its various augmented versions (representative of salient
aspects of audio like pitch, timbre etc.) to a space where they are close
together, and are separated from other different signals. In addition we also
explore generative models based on state of the art transformer based
architectures for learning latent spaces for audio signals, without access to
any labels. Here, we map audio signals on a smaller scale to discrete
dictionary elements and train transformers to predict the next dictionary
element. We only use data as a method of supervision, bypassing the need of
labels needed to act as a supervision for training the deep neural networks. We
then use a linear classifier head in order to evaluate the performance of our
models, for both self supervised contrastive and generative transformer based
representations that are learned. Our system achieves considerable performance,
compared to a fully supervised method, with access to ground truth labels to
train the neural network model. These representations, with avail-ability of
large scale audio data show promise in various tasks for audio understanding
tasks
</p>
<a href="http://arxiv.org/abs/2010.11459" target="_blank">arXiv:2010.11459</a> [<a href="http://arxiv.org/pdf/2010.11459" target="_blank">pdf</a>]

<h2>MixCon: Adjusting the Separability of Data Representations for Harder Data Recovery. (arXiv:2010.11463v1 [cs.LG])</h2>
<h3>Xiaoxiao Li, Yangsibo Huang, Binghui Peng, Zhao Song, Kai Li</h3>
<p>To address the issue that deep neural networks (DNNs) are vulnerable to model
inversion attacks, we design an objective function, which adjusts the
separability of the hidden data representations, as a way to control the
trade-off between data utility and vulnerability to inversion attacks. Our
method is motivated by the theoretical insights of data separability in neural
networking training and results on the hardness of model inversion.
Empirically, by adjusting the separability of data representation, we show that
there exist sweet-spots for data separability such that it is difficult to
recover data during inference while maintaining data utility.
</p>
<a href="http://arxiv.org/abs/2010.11463" target="_blank">arXiv:2010.11463</a> [<a href="http://arxiv.org/pdf/2010.11463" target="_blank">pdf</a>]

<h2>Novel View Synthesis from only a 6-DoF Camera Pose by Two-stage Networks. (arXiv:2010.11468v1 [cs.CV])</h2>
<h3>Xiang Guo, Bo Li, Yuchao Dai, Tongxin Zhang, Hui Deng</h3>
<p>Novel view synthesis is a challenging problem in computer vision and
robotics. Different from the existing works, which need the reference images or
3D models of the scene to generate images under novel views, we propose a novel
paradigm to this problem. That is, we synthesize the novel view from only a
6-DoF camera pose directly. Although this setting is the most straightforward
way, there are few works addressing it. While, our experiments demonstrate
that, with a concise CNN, we could get a meaningful parametric model that could
reconstruct the correct scenery images only from the 6-DoF pose. To this end,
we propose a two-stage learning strategy, which consists of two consecutive
CNNs: GenNet and RefineNet. GenNet generates a coarse image from a camera pose.
RefineNet is a generative adversarial network that refines the coarse image. In
this way, we decouple the geometric relationship between mapping and texture
detail rendering. Extensive experiments conducted on the public datasets prove
the effectiveness of our method. We believe this paradigm is of high research
and application value and could be an important direction in novel view
synthesis.
</p>
<a href="http://arxiv.org/abs/2010.11468" target="_blank">arXiv:2010.11468</a> [<a href="http://arxiv.org/pdf/2010.11468" target="_blank">pdf</a>]

<h2>An explainable deep vision system for animal classification and detection in trail-camera images with automatic post-deployment retraining. (arXiv:2010.11472v1 [cs.CV])</h2>
<h3>Golnaz Moallem (1), Don Pathirage (1), Joel Reznick (1), James Gallagher (2), Hamed Sari-Sarraf (1) ((1) Applied Vision Lab Texas Tech University (2) Texas Parks and Wildlife Department)</h3>
<p>This paper introduces an automated vision system for animal detection in
trail-camera images taken from a field under the administration of the Texas
Parks and Wildlife Department. As traditional wildlife counting techniques are
intrusive and labor intensive to conduct, trail-camera imaging is a
comparatively non-intrusive method for capturing wildlife activity. However,
given the large volume of images produced from trail-cameras, manual analysis
of the images remains time-consuming and inefficient. We implemented a
two-stage deep convolutional neural network pipeline to find animal-containing
images in the first stage and then process these images to detect birds in the
second stage. The animal classification system classifies animal images with
more than 87% sensitivity and 96% specificity. The bird detection system
achieves better than 93% sensitivity, 92% specificity, and 68% average
Intersection-over-Union rate. The entire pipeline processes an image in less
than 0.5 seconds as opposed to an average 30 seconds for a human labeler. We
also addressed post-deployment issues related to data drift for the animal
classification system as image features vary with seasonal changes. This system
utilizes an automatic retraining algorithm to detect data drift and update the
system. We introduce a novel technique for detecting drifted images and
triggering the retraining procedure. Two statistical experiments are also
presented to explain the prediction behavior of the animal classification
system. These experiments investigate the cues that steers the system towards a
particular decision. Statistical hypothesis testing demonstrates that the
presence of an animal in the input image significantly contributes to the
system's decisions.
</p>
<a href="http://arxiv.org/abs/2010.11472" target="_blank">arXiv:2010.11472</a> [<a href="http://arxiv.org/pdf/2010.11472" target="_blank">pdf</a>]

<h2>Similarity Analysis of Self-Supervised Speech Representations. (arXiv:2010.11481v1 [eess.AS])</h2>
<h3>Yu-An Chung, Yonatan Belinkov, James Glass</h3>
<p>Self-supervised speech representation learning has recently been a prosperous
research topic. Many algorithms have been proposed for learning useful
representations from large-scale unlabeled data, and their applications to a
wide range of speech tasks have also been investigated. However, there has been
little research focusing on understanding the properties of existing
approaches. In this work, we aim to provide a comparative study of some of the
most representative self-supervised algorithms. Specifically, we quantify the
similarities between different self-supervised representations using existing
similarity measures. We also design probing tasks to study the correlation
between the models' pre-training loss and the amount of specific speech
information contained in their learned representations. In addition to showing
how various self-supervised models behave differently given the same input, our
study also finds that the training objective has a higher impact on
representation similarity than architectural choices such as building blocks
(RNN/Transformer/CNN) and directionality (uni/bidirectional). Our results also
suggest that there exists a strong correlation between pre-training loss and
downstream performance for some self-supervised algorithms.
</p>
<a href="http://arxiv.org/abs/2010.11481" target="_blank">arXiv:2010.11481</a> [<a href="http://arxiv.org/pdf/2010.11481" target="_blank">pdf</a>]

<h2>The NTU-AISG Text-to-speech System for Blizzard Challenge 2020. (arXiv:2010.11489v1 [eess.AS])</h2>
<h3>Haobo Zhang, Tingzhi Mao, Haihua Xu, Hao Huang</h3>
<p>We report our NTU-AISG Text-to-speech (TTS) entry systems for the Blizzard
Challenge 2020 in this paper. There are two TTS tasks in this year's challenge,
one is a Mandarin TTS task, the other is a Shanghai dialect TTS task. We have
participated both. One of the main challenges is to build TTS systems with
low-resource constraints, particularly for the case of Shanghai dialect, of
which about three hours data are available to participants. To overcome the
constraint, we adopt an average-speaker modeling method. That is, we first
employ external Mandarin data to train both End-to-end acoustic model and
WaveNet vocoder, then we use Shanghai dialect to tune the acoustic model and
WaveNet vocoder respectively. Apart from this, we have no Shanghai dialect
lexicon despite syllable transcripts are provided for the training data. Since
we are not sure if similar syllable transcripts are provided for the evaluation
data during the training stage, we use Mandarin lexicon for Shanghai dialect
instead. With the letter, as decomposed from the corresponding Mandarin
syllable, as input, though the naturalness and original speaker similarity of
the synthesized speech are good, subjective evaluation results indicate the
intelligibility of the synthesized speech is deeply undermined for the Shanghai
dialect TTS system.
</p>
<a href="http://arxiv.org/abs/2010.11489" target="_blank">arXiv:2010.11489</a> [<a href="http://arxiv.org/pdf/2010.11489" target="_blank">pdf</a>]

<h2>On the Effects of Using word2vec Representations in Neural Networks for Dialogue Act Recognition. (arXiv:2010.11490v1 [cs.CL])</h2>
<h3>Christophe Cerisara (SYNALP), Pavel Kral, Ladislav Lenc</h3>
<p>Dialogue act recognition is an important component of a large number of
natural language processing pipelines. Many research works have been carried
out in this area, but relatively few investigate deep neural networks and word
embeddings. This is surprising, given that both of these techniques have proven
exceptionally good in most other language-related domains. We propose in this
work a new deep neural network that explores recurrent models to capture word
sequences within sentences, and further study the impact of pretrained word
embeddings. We validate this model on three languages: English, French and
Czech. The performance of the proposed approach is consistent across these
languages and it is comparable to the state-of-the-art results in English. More
importantly, we confirm that deep neural networks indeed outperform a Maximum
Entropy classifier, which was expected. However , and this is more surprising,
we also found that standard word2vec em-beddings do not seem to bring valuable
information for this task and the proposed model, whatever the size of the
training corpus is. We thus further analyse the resulting embeddings and
conclude that a possible explanation may be related to the mismatch between the
type of lexical-semantic information captured by the word2vec embeddings, and
the kind of relations between words that is the most useful for the dialogue
act recognition task.
</p>
<a href="http://arxiv.org/abs/2010.11490" target="_blank">arXiv:2010.11490</a> [<a href="http://arxiv.org/pdf/2010.11490" target="_blank">pdf</a>]

<h2>Cluster-and-Conquer: When Randomness Meets Graph Locality. (arXiv:2010.11497v1 [cs.DB])</h2>
<h3>George Giakkoupis (WIDE), Anne-Marie Kermarrec (EPFL), Olivier Ruas (SPIRALS), Fran&#xe7;ois Ta&#xef;ani (WIDE, IRISA)</h3>
<p>K-Nearest-Neighbors (KNN) graphs are central to many emblematic data mining
and machine-learning applications. Some of the most efficient KNN graph
algorithms are incremental and local: they start from a random graph, which
they incrementally improve by traversing neighbors-of-neighbors links.
Paradoxically, this random start is also one of the key weaknesses of these
algorithms: nodes are initially connected to dissimilar neighbors, that lie far
away according to the similarity metric. As a result, incremental algorithms
must first laboriously explore spurious potential neighbors before they can
identify similar nodes, and start converging. In this paper, we remove this
drawback with Cluster-and-Conquer (C 2 for short). Cluster-and-Conquer boosts
the starting configuration of greedy algorithms thanks to a novel lightweight
clustering mechanism, dubbed FastRandomHash. FastRandomHash leverages
random-ness and recursion to pre-cluster similar nodes at a very low cost. Our
extensive evaluation on real datasets shows that Cluster-and-Conquer
significantly outperforms existing approaches, including LSH, yielding
speed-ups of up to x4.42 while incurring only a negligible loss in terms of KNN
quality.
</p>
<a href="http://arxiv.org/abs/2010.11497" target="_blank">arXiv:2010.11497</a> [<a href="http://arxiv.org/pdf/2010.11497" target="_blank">pdf</a>]

<h2>3D Meta-Registration: Learning to Learn Registration of 3D Point Clouds. (arXiv:2010.11504v1 [cs.CV])</h2>
<h3>Lingjing Wang, Yu Hao, Xiang Li, Yi Fang</h3>
<p>Deep learning-based point cloud registration models are often generalized
from extensive training over a large volume of data to learn the ability to
predict the desired geometric transformation to register 3D point clouds. In
this paper, we propose a meta-learning based 3D registration model, named 3D
Meta-Registration, that is capable of rapidly adapting and well generalizing to
new 3D registration tasks for unseen 3D point clouds. Our 3D Meta-Registration
gains a competitive advantage by training over a variety of 3D registration
tasks, which leads to an optimized model for the best performance on the
distribution of registration tasks including potentially unseen tasks.
Specifically, the proposed 3D Meta-Registration model consists of two modules:
3D registration learner and 3D registration meta-learner. During the training,
the 3D registration learner is trained to complete a specific registration task
aiming to determine the desired geometric transformation that aligns the source
point cloud with the target one. In the meantime, the 3D registration
meta-learner is trained to provide the optimal parameters to update the 3D
registration learner based on the learned task distribution. After training,
the 3D registration meta-learner, which is learned with the optimized coverage
of distribution of 3D registration tasks, is able to dynamically update 3D
registration learners with desired parameters to rapidly adapt to new
registration tasks. We tested our model on synthesized dataset ModelNet and
FlyingThings3D, as well as real-world dataset KITTI. Experimental results
demonstrate that 3D Meta-Registration achieves superior performance over other
previous techniques (e.g. FlowNet3D).
</p>
<a href="http://arxiv.org/abs/2010.11504" target="_blank">arXiv:2010.11504</a> [<a href="http://arxiv.org/pdf/2010.11504" target="_blank">pdf</a>]

<h2>Malaria detection from RBC images using shallow Convolutional Neural Networks. (arXiv:2010.11521v1 [eess.IV])</h2>
<h3>Subrata Sarkar, Rati Sharma, Kushal Shah</h3>
<p>The advent of Deep Learning models like VGG-16 and Resnet-50 has considerably
revolutionized the field of image classification, and by using these
Convolutional Neural Networks (CNN) architectures, one can get a high
classification accuracy on a wide variety of image datasets. However, these
Deep Learning models have a very high computational complexity and so incur a
high computational cost of running these algorithms as well as make it hard to
interpret the results. In this paper, we present a shallow CNN architecture
which gives the same classification accuracy as the VGG-16 and Resnet-50 models
for thin blood smear RBC slide images for detection of malaria, while
decreasing the computational run time by an order of magnitude. This can offer
a significant advantage for commercial deployment of these algorithms,
especially in poorer countries in Africa and some parts of the Indian
subcontinent, where the menace of malaria is quite severe.
</p>
<a href="http://arxiv.org/abs/2010.11521" target="_blank">arXiv:2010.11521</a> [<a href="http://arxiv.org/pdf/2010.11521" target="_blank">pdf</a>]

<h2>An Industry Evaluation of Embedding-based Entity Alignment. (arXiv:2010.11522v1 [cs.CL])</h2>
<h3>Ziheng Zhang, Jiaoyan Chen, Xi Chen, Hualuo Liu, Yuejia Xiang, Bo Liu, Yefeng Zheng</h3>
<p>Embedding-based entity alignment has been widely investigated in recent
years, but most proposed methods still rely on an ideal supervised learning
setting with a large number of unbiased seed mappings for training and
validation, which significantly limits their usage. In this study, we evaluate
those state-of-the-art methods in an industrial context, where the impact of
seed mappings with different sizes and different biases is explored. Besides
the popular benchmarks from DBpedia and Wikidata, we contribute and evaluate a
new industrial benchmark that is extracted from two heterogeneous knowledge
graphs (KGs) under deployment for medical applications. The experimental
results enable the analysis of the advantages and disadvantages of these
alignment methods and the further discussion of suitable strategies for their
industrial deployment.
</p>
<a href="http://arxiv.org/abs/2010.11522" target="_blank">arXiv:2010.11522</a> [<a href="http://arxiv.org/pdf/2010.11522" target="_blank">pdf</a>]

<h2>Defense-guided Transferable Adversarial Attacks. (arXiv:2010.11535v1 [cs.LG])</h2>
<h3>Zifei Zhang, Kai Qiao, Jian Chen</h3>
<p>Though deep neural networks perform challenging tasks excellently, they are
susceptible to adversarial exmaples, which mislead classifiers by applying
human-imperceptible perturbations on clean inputs. Under the query-free
black-box scenario, adversarial examples are hard to transfer to unknown
models, and several methods have been proposed with low transferability. To
settle such issue, we design a max-min framework inspired by input
transformations, which are benificial to both the adversarial attack and
defense. Explicitly, we decrease loss values with affline transformations as a
defense in the minimum procedure, and then increase loss values with the
momentum iterative algorithm as an attack in the maximum procedure. To further
promote transferability, we determine transformed values with the max-min
theory. Extensive experiments on Imagenet demonstrate that our defense-guided
transferable attacks achieve impressive increase on transferability.
Experimentally, our best black-box attack fools normally trained models at an
85.3% attack success rate and adversarially trained models at a 40.43% attack
success rate on average, respectively. Additionally, we provide elucidative
insights on the improvement of transferability, and our method is expected to
be a benchmark for assessing the robustness of deep models.
</p>
<a href="http://arxiv.org/abs/2010.11535" target="_blank">arXiv:2010.11535</a> [<a href="http://arxiv.org/pdf/2010.11535" target="_blank">pdf</a>]

<h2>Efficient RDF Graph Storage based on Reinforcement Learning. (arXiv:2010.11538v1 [cs.DB])</h2>
<h3>Lei Zheng, Ziming Shen, Hongzhi Wang</h3>
<p>Knowledge graph is an important cornerstone of artificial intelligence. The
construction and release of large-scale knowledge graphs in various fields pose
new challenges to knowledge graph data management. Due to the maturity and
stability, relational database is also suitable for RDF data storage. However,
the complex structure of RDF graph brings challenges to storage structure
design for RDF graph in the relational database. To address the difficult
problem, this paper adopts reinforcement learning (RL) to optimize the storage
partition method of RDF graph based on the relational database. We transform
the graph storage into a Markov decision process, and develop the reinforcement
learning algorithm for graph storage design. For effective RL-based storage
design, we propose the data feature extraction method of RDF tables and the
query rewriting priority policy during model training. The extensive
experimental results demonstrate that our approach outperforms existing RDF
storage design methods.
</p>
<a href="http://arxiv.org/abs/2010.11538" target="_blank">arXiv:2010.11538</a> [<a href="http://arxiv.org/pdf/2010.11538" target="_blank">pdf</a>]

<h2>Online Structured Meta-learning. (arXiv:2010.11545v1 [cs.LG])</h2>
<h3>Huaxiu Yao, Yingbo Zhou, Mehrdad Mahdavi, Zhenhui Li, Richard Socher, Caiming Xiong</h3>
<p>Learning quickly is of great importance for machine intelligence deployed in
online platforms. With the capability of transferring knowledge from learned
tasks, meta-learning has shown its effectiveness in online scenarios by
continuously updating the model with the learned prior. However, current online
meta-learning algorithms are limited to learn a globally-shared meta-learner,
which may lead to sub-optimal results when the tasks contain heterogeneous
information that are distinct by nature and difficult to share. We overcome
this limitation by proposing an online structured meta-learning (OSML)
framework. Inspired by the knowledge organization of human and hierarchical
feature representation, OSML explicitly disentangles the meta-learner as a
meta-hierarchical graph with different knowledge blocks. When a new task is
encountered, it constructs a meta-knowledge pathway by either utilizing the
most relevant knowledge blocks or exploring new blocks. Through the
meta-knowledge pathway, the model is able to quickly adapt to the new task. In
addition, new knowledge is further incorporated into the selected blocks.
Experiments on three datasets demonstrate the effectiveness and
interpretability of our proposed framework in the context of both homogeneous
and heterogeneous tasks.
</p>
<a href="http://arxiv.org/abs/2010.11545" target="_blank">arXiv:2010.11545</a> [<a href="http://arxiv.org/pdf/2010.11545" target="_blank">pdf</a>]

<h2>TLGAN: document Text Localization using Generative Adversarial Nets. (arXiv:2010.11547v1 [cs.CV])</h2>
<h3>Dongyoung Kim, Myungsung Kwak, Eunji Won, Sejung Shin, Jeongyeon Nam</h3>
<p>Text localization from the digital image is the first step for the optical
character recognition task. Conventional image processing based text
localization performs adequately for specific examples. Yet, a general text
localization are only archived by recent deep-learning based modalities. Here
we present document Text Localization Generative Adversarial Nets (TLGAN) which
are deep neural networks to perform the text localization from digital image.
TLGAN is an versatile and easy-train text localization model requiring a small
amount of data. Training only ten labeled receipt images from Robust Reading
Challenge on Scanned Receipts OCR and Information Extraction (SROIE), TLGAN
achieved 99.83% precision and 99.64% recall for SROIE test data. Our TLGAN is a
practical text localization solution requiring minimal effort for data labeling
and model training and producing a state-of-art performance.
</p>
<a href="http://arxiv.org/abs/2010.11547" target="_blank">arXiv:2010.11547</a> [<a href="http://arxiv.org/pdf/2010.11547" target="_blank">pdf</a>]

<h2>Method of noun phrase detection in Ukrainian texts. (arXiv:2010.11548v1 [cs.CL])</h2>
<h3>S.D. Pogorilyy, A.A. Kramov</h3>
<p>Introduction. The area of natural language processing considers AI-complete
tasks that cannot be solved using traditional algorithmic actions. Such tasks
are commonly implemented with the usage of machine learning methodology and
means of computer linguistics. One of the preprocessing tasks of a text is the
search of noun phrases. The accuracy of this task has implications for the
effectiveness of many other tasks in the area of natural language processing.
In spite of the active development of research in the area of natural language
processing, the investigation of the search for noun phrases within Ukrainian
texts are still at an early stage. Results. The different methods of noun
phrases detection have been analyzed. The expediency of the representation of
sentences as a tree structure has been justified. The key disadvantage of many
methods of noun phrase detection is the severe dependence of the effectiveness
of their detection from the features of a certain language. Taking into account
the unified format of sentence processing and the availability of the trained
model for the building of sentence trees for Ukrainian texts, the Universal
Dependency model has been chosen. The complex method of noun phrases detection
in Ukrainian texts utilizing Universal Dependencies means and named-entity
recognition model has been suggested. Experimental verification of the
effectiveness of the suggested method on the corpus of Ukrainian news has been
performed. Different metrics of method accuracy have been calculated.
Conclusions. The results obtained can indicate that the suggested method can be
used to find noun phrases in Ukrainian texts. An accuracy increase of the
method can be made with the usage of appropriate named-entity recognition
models according to a subject area.
</p>
<a href="http://arxiv.org/abs/2010.11548" target="_blank">arXiv:2010.11548</a> [<a href="http://arxiv.org/pdf/2010.11548" target="_blank">pdf</a>]

<h2>Learning Dual Semantic Relations with Graph Attention for Image-Text Matching. (arXiv:2010.11550v1 [cs.CV])</h2>
<h3>Keyu Wen, Xiaodong Gu, Qingrong Cheng</h3>
<p>Image-Text Matching is one major task in cross-modal information processing.
The main challenge is to learn the unified visual and textual representations.
Previous methods that perform well on this task primarily focus on not only the
alignment between region features in images and the corresponding words in
sentences, but also the alignment between relations of regions and relational
words. However, the lack of joint learning of regional features and global
features will cause the regional features to lose contact with the global
context, leading to the mismatch with those non-object words which have global
meanings in some sentences. In this work, in order to alleviate this issue, it
is necessary to enhance the relations between regions and the relations between
regional and global concepts to obtain a more accurate visual representation so
as to be better correlated to the corresponding text. Thus, a novel multi-level
semantic relations enhancement approach named Dual Semantic Relations Attention
Network(DSRAN) is proposed which mainly consists of two modules, separate
semantic relations module and the joint semantic relations module. DSRAN
performs graph attention in both modules respectively for region-level
relations enhancement and regional-global relations enhancement at the same
time. With these two modules, different hierarchies of semantic relations are
learned simultaneously, thus promoting the image-text matching process by
providing more information for the final visual representation. Quantitative
experimental results have been performed on MS-COCO and Flickr30K and our
method outperforms previous approaches by a large margin due to the
effectiveness of the dual semantic relations learning scheme. Codes are
available at https://github.com/kywen1119/DSRAN.
</p>
<a href="http://arxiv.org/abs/2010.11550" target="_blank">arXiv:2010.11550</a> [<a href="http://arxiv.org/pdf/2010.11550" target="_blank">pdf</a>]

<h2>Incorporating Stylistic Lexical Preferences in Generative Language Models. (arXiv:2010.11553v1 [cs.CL])</h2>
<h3>Hrituraj Singh, Gaurav Verma, Balaji Vasan Srinivasan</h3>
<p>While recent advances in language modeling have resulted in powerful
generation models, their generation style remains implicitly dependent on the
training data and can not emulate a specific target style. Leveraging the
generative capabilities of a transformer-based language models, we present an
approach to induce certain target-author attributes by incorporating continuous
multi-dimensional lexical preferences of an author into generative language
models. We introduce rewarding strategies in a reinforcement learning framework
that encourages the use of words across multiple categorical dimensions, to
varying extents. Our experiments demonstrate that the proposed approach can
generate text that distinctively aligns with a given target author's lexical
style. We conduct quantitative and qualitative comparisons with competitive and
relevant baselines to illustrate the benefits of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2010.11553" target="_blank">arXiv:2010.11553</a> [<a href="http://arxiv.org/pdf/2010.11553" target="_blank">pdf</a>]

<h2>Deep Learning is Singular, and That's Good. (arXiv:2010.11560v1 [cs.LG])</h2>
<h3>Daniel Murfet, Susan Wei, Mingming Gong, Hui Li, Jesse Gell-Redman, Thomas Quella</h3>
<p>In singular models, the optimal set of parameters forms an analytic set with
singularities and classical statistical inference cannot be applied to such
models. This is significant for deep learning as neural networks are singular
and thus "dividing" by the determinant of the Hessian or employing the Laplace
approximation are not appropriate. Despite its potential for addressing
fundamental issues in deep learning, singular learning theory appears to have
made little inroads into the developing canon of deep learning theory. Via a
mix of theory and experiment, we present an invitation to singular learning
theory as a vehicle for understanding deep learning and suggest important
future work to make singular learning theory directly applicable to how deep
learning is performed in practice.
</p>
<a href="http://arxiv.org/abs/2010.11560" target="_blank">arXiv:2010.11560</a> [<a href="http://arxiv.org/pdf/2010.11560" target="_blank">pdf</a>]

<h2>Bilinear Fusion of Commonsense Knowledge with Attention-Based NLI Models. (arXiv:2010.11562v1 [cs.CL])</h2>
<h3>Amit Gajbhiye, Thomas Winterbottom, Noura Al Moubayed, Steven Bradley</h3>
<p>We consider the task of incorporating real-world commonsense knowledge into
deep Natural Language Inference (NLI) models. Existing external knowledge
incorporation methods are limited to lexical level knowledge and lack
generalization across NLI models, datasets, and commonsense knowledge sources.
To address these issues, we propose a novel NLI model-independent neural
framework, BiCAM. BiCAM incorporates real-world commonsense knowledge into NLI
models. Combined with convolutional feature detectors and bilinear feature
fusion, BiCAM provides a conceptually simple mechanism that generalizes well.
Quantitative evaluations with two state-of-the-art NLI baselines on SNLI and
SciTail datasets in conjunction with ConceptNet and Aristo Tuple KGs show that
BiCAM considerably improves the accuracy the incorporated NLI baselines. For
example, our BiECAM model, an instance of BiCAM, on the challenging SciTail
dataset, improves the accuracy of incorporated baselines by 7.0% with
ConceptNet, and 8.0% with Aristo Tuple KG.
</p>
<a href="http://arxiv.org/abs/2010.11562" target="_blank">arXiv:2010.11562</a> [<a href="http://arxiv.org/pdf/2010.11562" target="_blank">pdf</a>]

<h2>DBNET: DOA-driven beamforming network for end-to-end farfield sound source separation. (arXiv:2010.11566v1 [eess.AS])</h2>
<h3>Ali Aroudi, Sebastian Braun</h3>
<p>Many deep learning techniques are available to perform source separation and
reduce background noise. However, designing an end-to-end multi-channel source
separation method using deep learning and conventional acoustic signal
processing techniques still remains challenging. In this paper we propose a
direction-of-arrival-driven beamforming network (DBnet) consisting of
direction-of-arrival (DOA) estimation and beamforming layers for end-to-end
source separation. We propose to train DBnet using loss functions that are
solely based on the distances between the separated speech signals and the
target speech signals, without a need for the ground-truth DOAs of speakers. To
improve the source separation performance, we also propose end-to-end
extensions of DBnet which incorporate post masking networks. We evaluate the
proposed DBnet and its extensions on a very challenging dataset, targeting
realistic far-field sound source separation in reverberant and noisy
environments. The experimental results show that the proposed extended DBnet
using a convolutional-recurrent post masking network outperforms
state-of-the-art source separation methods.
</p>
<a href="http://arxiv.org/abs/2010.11566" target="_blank">arXiv:2010.11566</a> [<a href="http://arxiv.org/pdf/2010.11566" target="_blank">pdf</a>]

<h2>Investigating the True Performance of Transformers in Low-Resource Languages: A Case Study in Automatic Corpus Creation. (arXiv:2010.11574v1 [cs.CL])</h2>
<h3>Jan Christian Blaise Cruz, Jose Kristian Resabal, James Lin, Dan John Velasco, Charibeth Cheng</h3>
<p>Transformers represent the state-of-the-art in Natural Language Processing
(NLP) in recent years, proving effective even in tasks done in low-resource
languages. While pretrained transformers for these languages can be made, it is
challenging to measure their true performance and capacity due to the lack of
hard benchmark datasets, as well as the difficulty and cost of producing them.
In this paper, we present three contributions: First, we propose a methodology
for automatically producing Natural Language Inference (NLI) benchmark datasets
for low-resource languages using published news articles. Through this, we
create and release NewsPH-NLI, the first sentence entailment benchmark dataset
in the low-resource Filipino language. Second, we produce new pretrained
transformers based on the ELECTRA technique to further alleviate the resource
scarcity in Filipino, benchmarking them on our dataset against other
commonly-used transfer learning techniques. Lastly, we perform analyses on
transfer learning techniques to shed light on their true performance when
operating in low-data domains through the use of degradation tests.
</p>
<a href="http://arxiv.org/abs/2010.11574" target="_blank">arXiv:2010.11574</a> [<a href="http://arxiv.org/pdf/2010.11574" target="_blank">pdf</a>]

<h2>Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization. (arXiv:2010.11594v1 [cs.CV])</h2>
<h3>Yuanhao Zhai, Le Wang, Wei Tang, Qilin Zhang, Junsong Yuan, Gang Hua</h3>
<p>Weakly-supervised Temporal Action Localization (W-TAL) aims to classify and
localize all action instances in an untrimmed video under only video-level
supervision. However, without frame-level annotations, it is challenging for
W-TAL methods to identify false positive action proposals and generate action
proposals with precise temporal boundaries. In this paper, we present a
Two-Stream Consensus Network (TSCN) to simultaneously address these challenges.
The proposed TSCN features an iterative refinement training method, where a
frame-level pseudo ground truth is iteratively updated, and used to provide
frame-level supervision for improved model training and false positive action
proposal elimination. Furthermore, we propose a new attention normalization
loss to encourage the predicted attention to act like a binary selection, and
promote the precise localization of action instance boundaries. Experiments
conducted on the THUMOS14 and ActivityNet datasets show that the proposed TSCN
outperforms current state-of-the-art methods, and even achieves comparable
results with some recent fully-supervised methods.
</p>
<a href="http://arxiv.org/abs/2010.11594" target="_blank">arXiv:2010.11594</a> [<a href="http://arxiv.org/pdf/2010.11594" target="_blank">pdf</a>]

<h2>Early Anomaly Detection in Time Series: A Hierarchical Approach for Predicting Critical Health Episodes. (arXiv:2010.11595v1 [stat.ML])</h2>
<h3>Vitor Cerqueira, Luis Torgo, Carlos Soares</h3>
<p>The early detection of anomalous events in time series data is essential in
many domains of application. In this paper we deal with critical health events,
which represent a significant cause of mortality in intensive care units of
hospitals. The timely prediction of these events is crucial for mitigating
their consequences and improving healthcare. One of the most common approaches
to tackle early anomaly detection problems is standard classification methods.
In this paper we propose a novel method that uses a layered learning
architecture to address these tasks. One key contribution of our work is the
idea of pre-conditional events, which denote arbitrary but computable relaxed
versions of the event of interest. We leverage this idea to break the original
problem into two hierarchical layers, which we hypothesize are easier to solve.
The results suggest that the proposed approach leads to a better performance
relative to state of the art approaches for critical health episode prediction.
</p>
<a href="http://arxiv.org/abs/2010.11595" target="_blank">arXiv:2010.11595</a> [<a href="http://arxiv.org/pdf/2010.11595" target="_blank">pdf</a>]

<h2>On the Power of Deep but Naive Partial Label Learning. (arXiv:2010.11600v1 [cs.LG])</h2>
<h3>Junghoon Seo, Joon Suk Huh</h3>
<p>Partial label learning (PLL) is a class of weakly supervised learning where
each training instance consists of a data and a set of candidate labels
containing a unique ground truth label. To tackle this problem, a majority of
current state-of-the-art methods employs either label disambiguation or
averaging strategies. So far, PLL methods without such techniques have been
considered impractical. In this paper, we challenge this view by revealing the
hidden power of the oldest and naivest PLL method when it is instantiated with
deep neural networks. Specifically, we show that, with deep neural networks,
the naive model can achieve competitive performances against the other
state-of-the-art methods, suggesting it as a strong baseline for PLL. We also
address the question of how and why such a naive model works well with deep
neural networks. Our empirical results indicate that deep neural networks
trained on partially labeled examples generalize very well even in the
over-parametrized regime and without label disambiguations or regularizations.
We point out that existing learning theories on PLL are vacuous in the
over-parametrized regime. Hence they cannot explain why the deep naive method
works. We propose an alternative theory on how deep learning generalize in PLL
problems.
</p>
<a href="http://arxiv.org/abs/2010.11600" target="_blank">arXiv:2010.11600</a> [<a href="http://arxiv.org/pdf/2010.11600" target="_blank">pdf</a>]

<h2>Hierarchical Federated Learning through LAN-WAN Orchestration. (arXiv:2010.11612v1 [cs.LG])</h2>
<h3>Jinliang Yuan, Mengwei Xu, Xiao Ma, Ao Zhou, Xuanzhe Liu, Shangguang Wang</h3>
<p>Federated learning (FL) was designed to enable mobile phones to
collaboratively learn a global model without uploading their private data to a
cloud server. However, exiting FL protocols has a critical communication
bottleneck in a federated network coupled with privacy concerns, usually
powered by a wide-area network (WAN). Such a WAN-driven FL design leads to
significantly high cost and much slower model convergence. In this work, we
propose an efficient FL protocol, which involves a hierarchical aggregation
mechanism in the local-area network (LAN) due to its abundant bandwidth and
almost negligible monetary cost than WAN. Our proposed FL can accelerate the
learning process and reduce the monetary cost with frequent local aggregation
in the same LAN and infrequent global aggregation on a cloud across WAN. We
further design a concrete FL platform, namely LanFL, that incorporates several
key techniques to handle those challenges introduced by LAN: cloud-device
aggregation architecture, intra-LAN peer-to-peer (p2p) topology generation,
inter-LAN bandwidth capacity heterogeneity. We evaluate LanFL on 2 typical
Non-IID datasets, which reveals that LanFL can significantly accelerate FL
training (1.5x-6.0x), save WAN traffic (18.3x-75.6x), and reduce monetary cost
(3.8x-27.2x) while preserving the model accuracy.
</p>
<a href="http://arxiv.org/abs/2010.11612" target="_blank">arXiv:2010.11612</a> [<a href="http://arxiv.org/pdf/2010.11612" target="_blank">pdf</a>]

<h2>Self-Supervised Shadow Removal. (arXiv:2010.11619v1 [cs.CV])</h2>
<h3>Florin-Alexandru Vasluianu, Andres Romero, Luc Van Gool, Radu Timofte</h3>
<p>Shadow removal is an important computer vision task aiming at the detection
and successful removal of the shadow produced by an occluded light source and a
photo-realistic restoration of the image contents. Decades of re-search
produced a multitude of hand-crafted restoration techniques and, more recently,
learned solutions from shad-owed and shadow-free training image pairs. In this
work,we propose an unsupervised single image shadow removal solution via
self-supervised learning by using a conditioned mask. In contrast to existing
literature, we do not require paired shadowed and shadow-free images, instead
we rely on self-supervision and jointly learn deep models to remove and add
shadows to images. We validate our approach on the recently introduced ISTD and
USR datasets. We largely improve quantitatively and qualitatively over the
compared methods and set a new state-of-the-art performance in single image
shadow removal.
</p>
<a href="http://arxiv.org/abs/2010.11619" target="_blank">arXiv:2010.11619</a> [<a href="http://arxiv.org/pdf/2010.11619" target="_blank">pdf</a>]

<h2>Learning Augmented Energy Minimization via Speed Scaling. (arXiv:2010.11629v1 [cs.LG])</h2>
<h3>&#xc9;tienne Bamas, Andreas Maggiori, Lars Rohwedder, Ola Svensson</h3>
<p>As power management has become a primary concern in modern data centers,
computing resources are being scaled dynamically to minimize energy
consumption. We initiate the study of a variant of the classic online speed
scaling problem, in which machine learning predictions about the future can be
integrated naturally. Inspired by recent work on learning-augmented online
algorithms, we propose an algorithm which incorporates predictions in a
black-box manner and outperforms any online algorithm if the accuracy is high,
yet maintains provable guarantees if the prediction is very inaccurate. We
provide both theoretical and experimental evidence to support our claims.
</p>
<a href="http://arxiv.org/abs/2010.11629" target="_blank">arXiv:2010.11629</a> [<a href="http://arxiv.org/pdf/2010.11629" target="_blank">pdf</a>]

<h2>LaSAFT: Latent Source Attentive Frequency Transformation for Conditioned Source Separation. (arXiv:2010.11631v1 [cs.SD])</h2>
<h3>Woosung Choi, Minseok Kim, Jaehwa Chung, Soonyoung Jung</h3>
<p>Recent deep-learning approaches have shown that Frequency Transformation (FT)
blocks can significantly improve spectrogram-based single-source separation
models by capturing frequency patterns. The goal of this paper is to extend the
FT block to fit the multi-source task. We propose the Latent Source Attentive
Frequency Transformation (LaSAFT) block to capture source-dependent frequency
patterns. We also propose the Gated Point-wise Convolutional Modulation
(GPoCM), an extension of Feature-wise Linear Modulation (FiLM), to modulate
internal features. By employing these two novel methods, we extend the
Conditioned-U-Net (CUNet) for multi-source separation, and the experimental
results indicate that our LaSAFT and GPoCM can improve the CUNet's performance,
achieving state-of-the-art SDR performance on several MUSDB18 source separation
tasks.
</p>
<a href="http://arxiv.org/abs/2010.11631" target="_blank">arXiv:2010.11631</a> [<a href="http://arxiv.org/pdf/2010.11631" target="_blank">pdf</a>]

<h2>The Primal-Dual method for Learning Augmented Algorithms. (arXiv:2010.11632v1 [cs.LG])</h2>
<h3>&#xc9;tienne Bamas, Andreas Maggiori, Ola Svensson</h3>
<p>The extension of classical online algorithms when provided with predictions
is a new and active research area. In this paper, we extend the primal-dual
method for online algorithms in order to incorporate predictions that advise
the online algorithm about the next action to take. We use this framework to
obtain novel algorithms for a variety of online covering problems. We compare
our algorithms to the cost of the true and predicted offline optimal solutions
and show that these algorithms outperform any online algorithm when the
prediction is accurate while maintaining good guarantees when the prediction is
misleading.
</p>
<a href="http://arxiv.org/abs/2010.11632" target="_blank">arXiv:2010.11632</a> [<a href="http://arxiv.org/pdf/2010.11632" target="_blank">pdf</a>]

<h2>Online Time-Varying Topology Identification via Prediction-Correction Algorithms. (arXiv:2010.11634v1 [eess.SP])</h2>
<h3>Alberto Natali, Mario Coutino, Elvin Isufi, Geert Leus</h3>
<p>Signal processing and machine learning algorithms for data supported over
graphs, require the knowledge of the graph topology. Unless this information is
given by the physics of the problem (e.g., water supply networks, power grids),
the topology has to be learned from data. Topology identification is a
challenging task, as the problem is often ill-posed, and becomes even harder
when the graph structure is time-varying. In this paper, we address the problem
of dynamic topology identification by building on recent results from
time-varying optimization, devising a general-purpose online algorithm
operating in non-stationary environments. Because of its iteration-constrained
nature, the proposed approach exhibits an intrinsic temporal-regularization of
the graph topology without explicitly enforcing it. As a case-study, we
specialize our method to the Gaussian graphical model (GGM) problem and
corroborate its performance.
</p>
<a href="http://arxiv.org/abs/2010.11634" target="_blank">arXiv:2010.11634</a> [<a href="http://arxiv.org/pdf/2010.11634" target="_blank">pdf</a>]

<h2>Continual Learning in Low-rank Orthogonal Subspaces. (arXiv:2010.11635v1 [cs.LG])</h2>
<h3>Arslan Chaudhry, Naeemullah Khan, Puneet K. Dokania, Philip H. S. Torr</h3>
<p>In continual learning (CL), a learner is faced with a sequence of tasks,
arriving one after the other, and the goal is to remember all the tasks once
the continual learning experience is finished. The prior art in CL uses
episodic memory, parameter regularization or extensible network structures to
reduce interference among tasks, but in the end, all the approaches learn
different tasks in a joint vector space. We believe this invariably leads to
interference among different tasks. We propose to learn tasks in different
(low-rank) vector subspaces that are kept orthogonal to each other in order to
minimize interference. Further, to keep the gradients of different tasks coming
from these subspaces orthogonal to each other, we learn isometric mappings by
posing network training as an optimization problem over the Stiefel manifold.
To the best of our understanding, we report, for the first time, strong results
over experience-replay baseline with and without memory on standard
classification benchmarks in continual learning. The code is made publicly
available.
</p>
<a href="http://arxiv.org/abs/2010.11635" target="_blank">arXiv:2010.11635</a> [<a href="http://arxiv.org/pdf/2010.11635" target="_blank">pdf</a>]

<h2>Pseudoscientific Content on YouTube: Assessing the Effects of Watch History on the Recommendation Algorithm. (arXiv:2010.11638v1 [cs.CY])</h2>
<h3>Kostantinos Papadamou, Savvas Zannettou, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca Stringhini, Michael Sirivianos</h3>
<p>YouTube has revolutionized the way people discover and consume videos,
becoming one of the primary news sources for Internet users. Since content on
YouTube is generated by its users, the platform is particularly vulnerable to
misinformative and conspiratorial videos. Even worse, the role played by
YouTube's recommendation algorithm in unwittingly promoting questionable
content is not well understood, and could potentially make the problem even
worse. This can have dire real-world consequences, especially when
pseudoscientific content is promoted to users at critical times, e.g., during
the COVID-19 pandemic.

In this paper, we set out to characterize and detect pseudoscientific
misinformation on YouTube. We collect 6.6K videos related to COVID-19, the flat
earth theory, the anti-vaccination, and anti-mask movements; using
crowdsourcing, we annotate them as pseudoscience, legitimate science, or
irrelevant. We then train a deep learning classifier to detect pseudoscientific
videos with an accuracy of 76.1%. Next, we quantify user exposure to this
content on various parts of the platform (i.e., a user's homepage, recommended
videos while watching a specific video, or search results) and how this
exposure changes based on the user's watch history. We find that YouTube's
recommendation algorithm is more aggressive in suggesting pseudoscientific
content when users are searching for specific topics, while these
recommendations are less common on a user's homepage or when actively watching
pseudoscientific videos. Finally, we shed light on how a user's watch history
substantially affects the type of recommended videos.
</p>
<a href="http://arxiv.org/abs/2010.11638" target="_blank">arXiv:2010.11638</a> [<a href="http://arxiv.org/pdf/2010.11638" target="_blank">pdf</a>]

<h2>Towards Fully Bilingual Deep Language Modeling. (arXiv:2010.11639v1 [cs.CL])</h2>
<h3>Li-Hsin Chang, Sampo Pyysalo, Jenna Kanerva, Filip Ginter</h3>
<p>Language models based on deep neural networks have facilitated great advances
in natural language processing and understanding tasks in recent years. While
models covering a large number of languages have been introduced, their
multilinguality has come at a cost in terms of monolingual performance, and the
best-performing models at most tasks not involving cross-lingual transfer
remain monolingual. In this paper, we consider the question of whether it is
possible to pre-train a bilingual model for two remotely related languages
without compromising performance at either language. We collect pre-training
data, create a Finnish-English bilingual BERT model and evaluate its
performance on datasets used to evaluate the corresponding monolingual models.
Our bilingual model performs on par with Google's original English BERT on GLUE
and nearly matches the performance of monolingual Finnish BERT on a range of
Finnish NLP tasks, clearly outperforming multilingual BERT. We find that when
the model vocabulary size is increased, the BERT-Base architecture has
sufficient capacity to learn two remotely related languages to a level where it
achieves comparable performance with monolingual models, demonstrating the
feasibility of training fully bilingual deep language models. The model and all
tools involved in its creation are freely available at
https://github.com/TurkuNLP/biBERT
</p>
<a href="http://arxiv.org/abs/2010.11639" target="_blank">arXiv:2010.11639</a> [<a href="http://arxiv.org/pdf/2010.11639" target="_blank">pdf</a>]

<h2>Object-Attribute Biclustering for Elimination of Missing Genotypes in Ischemic Stroke Genome-Wide Data. (arXiv:2010.11641v1 [cs.LG])</h2>
<h3>Dmitry I. Ignatov, Gennady V. Khvorykh, Andrey V. Khrunin, Stefan Nikoli&#x107;, Makhmud Shaban, Elizaveta A. Petrova, Evgeniya A. Koltsova, Fouzi Takelait, Dmitrii Egurnov</h3>
<p>Missing genotypes can affect the efficacy of machine learning approaches to
identify the risk genetic variants of common diseases and traits. The problem
occurs when genotypic data are collected from different experiments with
different DNA microarrays, each being characterised by its pattern of uncalled
(missing) genotypes. This can prevent the machine learning classifier from
assigning the classes correctly. To tackle this issue, we used well-developed
notions of object-attribute biclusters and formal concepts that correspond to
dense subrelations in the binary relation $\textit{patients} \times
\textit{SNPs}$. The paper contains experimental results on applying a
biclustering algorithm to a large real-world dataset collected for studying the
genetic bases of ischemic stroke. The algorithm could identify large dense
biclusters in the genotypic matrix for further processing, which in return
significantly improved the quality of machine learning classifiers. The
proposed algorithm was also able to generate biclusters for the whole dataset
without size constraints in comparison to the In-Close4 algorithm for
generation of formal concepts.
</p>
<a href="http://arxiv.org/abs/2010.11641" target="_blank">arXiv:2010.11641</a> [<a href="http://arxiv.org/pdf/2010.11641" target="_blank">pdf</a>]

<h2>The Role of Mutual Information in Variational Classifiers. (arXiv:2010.11642v1 [stat.ML])</h2>
<h3>Matias Vera, Leonardo Rey Vega, Pablo Piantanida</h3>
<p>Overfitting data is a well-known phenomenon related with the generation of a
model that mimics too closely (or exactly) a particular instance of data, and
may therefore fail to predict future observations reliably. In practice, this
behaviour is controlled by various--sometimes heuristics--regularization
techniques, which are motivated by developing upper bounds to the
generalization error. In this work, we study the generalization error of
classifiers relying on stochastic encodings trained on the cross-entropy loss,
which is often used in deep learning for classification problems. We derive
bounds to the generalization error showing that there exists a regime where the
generalization error is bounded by the mutual information between input
features and the corresponding representations in the latent space, which are
randomly generated according to the encoding distribution. Our bounds provide
an information-theoretic understanding of generalization in the so-called class
of variational classifiers, which are regularized by a Kullback-Leibler (KL)
divergence term. These results give theoretical grounds for the highly popular
KL term in variational inference methods that was already recognized to act
effectively as a regularization penalty. We further observe connections with
well studied notions such as Variational Autoencoders, Information Dropout,
Information Bottleneck and Boltzmann Machines. Finally, we perform numerical
experiments on MNIST and CIFAR datasets and show that mutual information is
indeed highly representative of the behaviour of the generalization error.
</p>
<a href="http://arxiv.org/abs/2010.11642" target="_blank">arXiv:2010.11642</a> [<a href="http://arxiv.org/pdf/2010.11642" target="_blank">pdf</a>]

<h2>Theory-based residual neural networks: A synergy of discrete choice models and deep neural networks. (arXiv:2010.11644v1 [cs.LG])</h2>
<h3>Shenhao Wang, Baichuan Mo, Jinhua Zhao</h3>
<p>Researchers often treat data-driven and theory-driven models as two disparate
or even conflicting methods in travel behavior analysis. However, the two
methods are highly complementary because data-driven methods are more
predictive but less interpretable and robust, while theory-driven methods are
more interpretable and robust but less predictive. Using their complementary
nature, this study designs a theory-based residual neural network (TB-ResNet)
framework, which synergizes discrete choice models (DCMs) and deep neural
networks (DNNs) based on their shared utility interpretation. The TB-ResNet
framework is simple, as it uses a ($\delta$, 1-$\delta$) weighting to take
advantage of DCMs' simplicity and DNNs' richness, and to prevent underfitting
from the DCMs and overfitting from the DNNs. This framework is also flexible:
three instances of TB-ResNets are designed based on multinomial logit model
(MNL-ResNets), prospect theory (PT-ResNets), and hyperbolic discounting
(HD-ResNets), which are tested on three data sets. Compared to pure DCMs, the
TB-ResNets provide greater prediction accuracy and reveal a richer set of
behavioral mechanisms owing to the utility function augmented by the DNN
component in the TB-ResNets. Compared to pure DNNs, the TB-ResNets can modestly
improve prediction and significantly improve interpretation and robustness,
because the DCM component in the TB-ResNets stabilizes the utility functions
and input gradients. Overall, this study demonstrates that it is both feasible
and desirable to synergize DCMs and DNNs by combining their utility
specifications under a TB-ResNet framework. Although some limitations remain,
this TB-ResNet framework is an important first step to create mutual benefits
between DCMs and DNNs for travel behavior modeling, with joint improvement in
prediction, interpretation, and robustness.
</p>
<a href="http://arxiv.org/abs/2010.11644" target="_blank">arXiv:2010.11644</a> [<a href="http://arxiv.org/pdf/2010.11644" target="_blank">pdf</a>]

<h2>Quaternion-Valued Variational Autoencoder. (arXiv:2010.11647v1 [cs.LG])</h2>
<h3>Eleonora Grassucci, Danilo Comminiello, Aurelio Uncini</h3>
<p>Deep probabilistic generative models have achieved incredible success in many
fields of application. Among such models, variational autoencoders (VAEs) have
proved their ability in modeling a generative process by learning a latent
representation of the input. In this paper, we propose a novel VAE defined in
the quaternion domain, which exploits the properties of quaternion algebra to
improve performance while significantly reducing the number of parameters
required by the network. The success of the proposed quaternion VAE with
respect to traditional VAEs relies on the ability to leverage the internal
relations between quaternion-valued input features and on the properties of
second-order statistics which allow to define the latent variables in the
augmented quaternion domain. In order to show the advantages due to such
properties, we define a plain convolutional VAE in the quaternion domain and we
evaluate it in comparison with its real-valued counterpart on the CelebA face
dataset.
</p>
<a href="http://arxiv.org/abs/2010.11647" target="_blank">arXiv:2010.11647</a> [<a href="http://arxiv.org/pdf/2010.11647" target="_blank">pdf</a>]

<h2>Learning to Sort Image Sequences via Accumulated Temporal Differences. (arXiv:2010.11649v1 [cs.CV])</h2>
<h3>Gagan Kanojia, Shanmuganathan Raman</h3>
<p>Consider a set of n images of a scene with dynamic objects captured with a
static or a handheld camera. Let the temporal order in which these images are
captured be unknown. There can be n! possibilities for the temporal order in
which these images could have been captured. In this work, we tackle the
problem of temporally sequencing the unordered set of images of a dynamic scene
captured with a hand-held camera. We propose a convolutional block which
captures the spatial information through 2D convolution kernel and captures the
temporal information by utilizing the differences present among the feature
maps extracted from the input images. We evaluate the performance of the
proposed approach on the dataset extracted from a standard action recognition
dataset, UCF101. We show that the proposed approach outperforms the
state-of-the-art methods by a significant margin. We show that the network
generalizes well by evaluating it on a dataset extracted from the DAVIS
dataset, a dataset meant for video object segmentation, when the same network
was trained with a dataset extracted from UCF101, a dataset meant for action
recognition.
</p>
<a href="http://arxiv.org/abs/2010.11649" target="_blank">arXiv:2010.11649</a> [<a href="http://arxiv.org/pdf/2010.11649" target="_blank">pdf</a>]

<h2>CoinDICE: Off-Policy Confidence Interval Estimation. (arXiv:2010.11652v1 [cs.LG])</h2>
<h3>Bo Dai, Ofir Nachum, Yinlam Chow, Lihong Li, Csaba Szepesv&#xe1;ri, Dale Schuurmans</h3>
<p>We study high-confidence behavior-agnostic off-policy evaluation in
reinforcement learning, where the goal is to estimate a confidence interval on
a target policy's value, given only access to a static experience dataset
collected by unknown behavior policies. Starting from a function space
embedding of the linear program formulation of the $Q$-function, we obtain an
optimization problem with generalized estimating equation constraints. By
applying the generalized empirical likelihood method to the resulting
Lagrangian, we propose CoinDICE, a novel and efficient algorithm for computing
confidence intervals. Theoretically, we prove the obtained confidence intervals
are valid, in both asymptotic and finite-sample regimes. Empirically, we show
in a variety of benchmarks that the confidence interval estimates are tighter
and more accurate than existing methods.
</p>
<a href="http://arxiv.org/abs/2010.11652" target="_blank">arXiv:2010.11652</a> [<a href="http://arxiv.org/pdf/2010.11652" target="_blank">pdf</a>]

<h2>Graph Neural Network for Large-Scale Network Localization. (arXiv:2010.11653v1 [cs.LG])</h2>
<h3>Wenzhong Yan, Di Jin, Zhidi Lin, Feng Yin</h3>
<p>Graph neural networks (GNNs) are popular to use for classifying structured
data in the context of machine learning. But surprisingly, they are rarely
applied to regression problems. In this work, we adopt GNN for a classic but
challenging nonlinear regression problem, namely the network localization. Our
main findings are in order. First, GNN is potentially the best solution to
large-scale network localization in terms of accuracy, robustness and
computational time. Second, thresholding of the communication range is
essential to its superior performance. Simulation results corroborate that the
proposed GNN based method outperforms all benchmarks by far. Such inspiring
results are further justified theoretically in terms of data aggregation,
non-line-of-sight (NLOS) noise removal and lowpass filtering effect, all
affected by the threshold for neighbor selection. Code is available at
https://github.com/Yanzongzi/GNN-For-localization.
</p>
<a href="http://arxiv.org/abs/2010.11653" target="_blank">arXiv:2010.11653</a> [<a href="http://arxiv.org/pdf/2010.11653" target="_blank">pdf</a>]

<h2>Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games. (arXiv:2010.11655v1 [cs.LG])</h2>
<h3>Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Joey Tianyi Zhou, Chengqi Zhang</h3>
<p>We study reinforcement learning (RL) for text-based games, which are
interactive simulations in the context of natural language. While different
methods have been developed to represent the environment information and
language actions, existing RL agents are not empowered with any reasoning
capabilities to deal with textual games. In this work, we aim to conduct
explicit reasoning with knowledge graphs for decision making, so that the
actions of an agent are generated and supported by an interpretable inference
procedure. We propose a stacked hierarchical attention mechanism to construct
an explicit representation of the reasoning process by exploiting the structure
of the knowledge graph. We extensively evaluate our method on a number of
man-made benchmark games, and the experimental results demonstrate that our
method performs better than existing text-based agents.
</p>
<a href="http://arxiv.org/abs/2010.11655" target="_blank">arXiv:2010.11655</a> [<a href="http://arxiv.org/pdf/2010.11655" target="_blank">pdf</a>]

<h2>Neural Network-based Acoustic Vehicle Counting. (arXiv:2010.11659v1 [cs.SD])</h2>
<h3>Slobodan Djukanovi&#x107;, Yash Patel, Ji&#x159;i Matas, Tuomas Virtanen</h3>
<p>This paper addresses acoustic vehicle counting using one-channel audio. We
predict the pass-by instants of vehicles from local minima of a
vehicle-to-microphone distance predicted from audio. The distance is predicted
via a two-stage (coarse-fine) regression, both realised using neural networks
(NNs). Experiments show that the NN-based distance regression outperforms by
far the previously proposed support vector regression. The $ 95\% $ confidence
interval for the mean of vehicle counting error is within $[0.28\%, -0.55\%]$.
Besides the minima-based counting, we propose a deep learning counting which
operates on the predicted distance without detecting local minima. Results also
show that removing low frequencies in features improves the counting
performance.
</p>
<a href="http://arxiv.org/abs/2010.11659" target="_blank">arXiv:2010.11659</a> [<a href="http://arxiv.org/pdf/2010.11659" target="_blank">pdf</a>]

<h2>Drift Detection in Episodic Data: Detect When Your Agent Starts Faltering. (arXiv:2010.11660v1 [cs.LG])</h2>
<h3>Ido Greenberg, Shie Mannor</h3>
<p>Detection of deterioration of agent performance in dynamic environments is
challenging due to the non-i.i.d nature of the observed performance. We
consider an episodic framework, where the objective is to detect when an agent
begins to falter. We devise a hypothesis testing procedure for non-i.i.d
rewards, which is optimal under certain conditions. To apply the procedure
sequentially in an online manner, we also suggest a novel Bootstrap mechanism
for False Alarm Rate control (BFAR). We demonstrate our procedure in problems
where the rewards are not independent, nor identically-distributed, nor
normally-distributed. The statistical power of the new testing procedure is
shown to outperform alternative tests - often by orders of magnitude - for a
variety of environment modifications (which cause deterioration in agent
performance). Our detection method is entirely external to the agent, and in
particular does not require model-based learning. Furthermore, it can be
applied to detect changes or drifts in any episodic signal.
</p>
<a href="http://arxiv.org/abs/2010.11660" target="_blank">arXiv:2010.11660</a> [<a href="http://arxiv.org/pdf/2010.11660" target="_blank">pdf</a>]

<h2>Efficient Generalized Spherical CNNs. (arXiv:2010.11661v1 [cs.CV])</h2>
<h3>Oliver J. Cobb, Christopher G. R. Wallis, Augustine N. Mavor-Parker, Augustin Marignier, Matthew A. Price, Mayeul d&#x27;Avezac, Jason D. McEwen</h3>
<p>Many problems across computer vision and the natural sciences require the
analysis of spherical data, for which representations may be learned
efficiently by encoding equivariance to rotational symmetries. We present a
generalized spherical CNN framework that encompasses various existing
approaches and allows them to be leveraged alongside each other. The only
existing non-linear spherical CNN layer that is strictly equivariant has
complexity $\mathcal{O}(C^2L^5)$, where $C$ is a measure of representational
capacity and $L$ the spherical harmonic bandlimit. Such a high computational
cost often prohibits the use of strictly equivariant spherical CNNs. We develop
two new strictly equivariant layers with reduced complexity $\mathcal{O}(CL^4)$
and $\mathcal{O}(CL^3 \log L)$, making larger, more expressive models
computationally feasible. Moreover, we adopt efficient sampling theory to
achieve further computational savings. We show that these developments allow
the construction of more expressive hybrid models that achieve state-of-the-art
accuracy and parameter efficiency on spherical benchmark problems.
</p>
<a href="http://arxiv.org/abs/2010.11661" target="_blank">arXiv:2010.11661</a> [<a href="http://arxiv.org/pdf/2010.11661" target="_blank">pdf</a>]

<h2>CycleGAN-VC3: Examining and Improving CycleGAN-VCs for Mel-spectrogram Conversion. (arXiv:2010.11672v1 [cs.SD])</h2>
<h3>Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Nobukatsu Hojo</h3>
<p>Non-parallel voice conversion (VC) is a technique for learning mappings
between source and target speeches without using a parallel corpus. Recently,
cycle-consistent adversarial network (CycleGAN)-VC and CycleGAN-VC2 have shown
promising results regarding this problem and have been widely used as benchmark
methods. However, owing to the ambiguity of the effectiveness of
CycleGAN-VC/VC2 for mel-spectrogram conversion, they are typically used for
mel-cepstrum conversion even when comparative methods employ mel-spectrogram as
a conversion target. To address this, we examined the applicability of
CycleGAN-VC/VC2 to mel-spectrogram conversion. Through initial experiments, we
discovered that their direct applications compromised the time-frequency
structure that should be preserved during conversion. To remedy this, we
propose CycleGAN-VC3, an improvement of CycleGAN-VC2 that incorporates
time-frequency adaptive normalization (TFAN). Using TFAN, we can adjust the
scale and bias of the converted features while reflecting the time-frequency
structure of the source mel-spectrogram. We evaluated CycleGAN-VC3 on
inter-gender and intra-gender non-parallel VC. A subjective evaluation of
naturalness and similarity showed that for every VC pair, CycleGAN-VC3
outperforms or is competitive with the two types of CycleGAN-VC2, one of which
was applied to mel-cepstrum and the other to mel-spectrogram. Audio samples are
available at
this http URL
</p>
<a href="http://arxiv.org/abs/2010.11672" target="_blank">arXiv:2010.11672</a> [<a href="http://arxiv.org/pdf/2010.11672" target="_blank">pdf</a>]

<h2>Optimization-Based Visual-Inertial SLAM Tightly Coupled with Raw GNSS Measurements. (arXiv:2010.11675v1 [cs.RO])</h2>
<h3>Jinxu Liu, Wei Gao, Zhanyi Hu</h3>
<p>Fusing vision, Inertial Measurement Unit (IMU) and Global Navigation
Satellite System (GNSS) information is a promising solution for accurate global
positioning in complex urban scenes, because of the complementarity of the
different sensors. Unlike the loose coupling approaches and the EKF-based
approaches in the literature, we propose an optimization-based visual-inertial
SLAM tightly coupled with raw GNSS measurements, including pseudoranges and
Doppler shift, which is the first of such approaches to our knowledge.
Reprojection error, IMU pre-integration error and raw GNSS measurement error
are jointly optimized using bundle adjustment in a sliding window, and the
asynchronism between images and raw GNSS measurements is considered.
Marginalization is performed in the sliding window, and some methods dealing
with noisy measurements and vulnerable situations are employed. Experimental
results on public dataset in complex urban scenes prove that our proposed
approach outperforms state-of-the-art visual-inertial SLAM, GNSS single point
positioning, as well as a loose coupling approach, both in the scenes that
mainly contain low-rise buildings and the scenes that contain urban canyons.
</p>
<a href="http://arxiv.org/abs/2010.11675" target="_blank">arXiv:2010.11675</a> [<a href="http://arxiv.org/pdf/2010.11675" target="_blank">pdf</a>]

<h2>DPAttack: Diffused Patch Attacks against Universal Object Detection. (arXiv:2010.11679v1 [cs.CV])</h2>
<h3>Shudeng Wu, Tao Dai, Shu-Tao Xia</h3>
<p>Recently, deep neural networks (DNNs) have been widely and successfully used
in Object Detection, e.g. Faster RCNN, YOLO, CenterNet. However, recent studies
have shown that DNNs are vulnerable to adversarial attacks. Adversarial attacks
against object detection can be divided into two categories, whole-pixel
attacks and patch attacks. While these attacks add perturbations to a large
number of pixels in images, we proposed a diffused patch attack
(\textbf{DPAttack}) to successfully fool object detectors by diffused patches
of asteroid-shaped or grid-shape, which only change a small number of pixels.
Experiments show that our DPAttack can successfully fool most object detectors
with diffused patches and we get the second place in the Alibaba Tianchi
competition: Alibaba-Tsinghua Adversarial Challenge on Object Detection. Our
code can be obtained from https://github.com/Wu-Shudeng/DPAttack.
</p>
<a href="http://arxiv.org/abs/2010.11679" target="_blank">arXiv:2010.11679</a> [<a href="http://arxiv.org/pdf/2010.11679" target="_blank">pdf</a>]

<h2>Learning Panoptic Segmentation from Instance Contours. (arXiv:2010.11681v1 [cs.CV])</h2>
<h3>Sumanth Chennupati, Venkatraman Narayanan, Ganesh Sistu, Senthil Yogamani, Samir A Rawashdeh</h3>
<p>Panoptic Segmentation aims to provide an understanding of background (stuff)
and instances of objects (things) at a pixel level. It combines the separate
tasks of semantic segmentation (pixel-level classification) and instance
segmentation to build a single unified scene understanding task. Typically,
panoptic segmentation is derived by combining semantic and instance
segmentation tasks that are learned separately or jointly (multi-task
networks). In general, instance segmentation networks are built by adding a
foreground mask estimation layer on top of object detectors or using instance
clustering methods that assign a pixel to an instance center. In this work, we
present a fully convolution neural network that learns instance segmentation
from semantic segmentation and instance contours (boundaries of things).
Instance contours along with semantic segmentation yield a boundary-aware
semantic segmentation of things. Connected component labeling on these results
produces instance segmentation. We merge semantic and instance segmentation
results to output panoptic segmentation. We evaluate our proposed method on the
CityScapes dataset to demonstrate qualitative and quantitative performances
along with several ablation studies.
</p>
<a href="http://arxiv.org/abs/2010.11681" target="_blank">arXiv:2010.11681</a> [<a href="http://arxiv.org/pdf/2010.11681" target="_blank">pdf</a>]

<h2>Lung Nodule Classification Using Biomarkers, Volumetric Radiomics and 3D CNNs. (arXiv:2010.11682v1 [eess.IV])</h2>
<h3>Kushal Mehta, Arshita Jain, Jayalakshmi Mangalagiri, Sumeet Menon, Phuong Nguyen, David R. Chapman</h3>
<p>We present a hybrid algorithm to estimate lung nodule malignancy that
combines imaging biomarkers from Radiologist's annotation with image
classification of CT scans. Our algorithm employs a 3D Convolutional Neural
Network (CNN) as well as a Random Forest in order to combine CT imagery with
biomarker annotation and volumetric radiomic features. We analyze and compare
the performance of the algorithm using only imagery, only biomarkers, combined
imagery + biomarkers, combined imagery + volumetric radiomic features and
finally the combination of imagery + biomarkers + volumetric features in order
to classify the suspicion level of nodule malignancy. The National Cancer
Institute (NCI) Lung Image Database Consortium (LIDC) IDRI dataset is used to
train and evaluate the classification task. We show that the incorporation of
semi-supervised learning by means of K-Nearest-Neighbors (KNN) can increase the
available training sample size of the LIDC-IDRI thereby further improving the
accuracy of malignancy estimation of most of the models tested although there
is no significant improvement with the use of KNN semi-supervised learning if
image classification with CNNs and volumetric features are combined with
descriptive biomarkers. Unexpectedly, we also show that a model using image
biomarkers alone is more accurate than one that combines biomarkers with
volumetric radiomics, 3D CNNs, and semi-supervised learning. We discuss the
possibility that this result may be influenced by cognitive bias in LIDC-IDRI
because malignancy estimates were recorded by the same radiologist panel as
biomarkers, as well as future work to incorporate pathology information over a
subset of study participants.
</p>
<a href="http://arxiv.org/abs/2010.11682" target="_blank">arXiv:2010.11682</a> [<a href="http://arxiv.org/pdf/2010.11682" target="_blank">pdf</a>]

<h2>Disentangling Action Sequences: Discovering Correlated Samples. (arXiv:2010.11684v1 [cs.LG])</h2>
<h3>Jiantao Wu, Lin Wang</h3>
<p>Disentanglement is a highly desirable property of representation due to its
similarity with human's understanding and reasoning. This improves
interpretability, enables the performance of down-stream tasks, and enables
controllable generative models. However, this domain is challenged by the
abstract notion and incomplete theories to support unsupervised disentanglement
learning. We demonstrate the data itself, such as the orientation of images,
plays a crucial role in disentanglement and instead of the factors, and the
disentangled representations align the latent variables with the action
sequences. We further introduce the concept of disentangling action sequences
which facilitates the description of the behaviours of the existing
disentangling approaches. An analogy for this process is to discover the
commonality between the things and categorizing them. Furthermore, we analyze
the inductive biases on the data and find that the latent information
thresholds are correlated with the significance of the actions. For the
supervised and unsupervised settings, we respectively introduce two methods to
measure the thresholds. We further propose a novel framework, fractional
variational autoencoder (FVAE), to disentangle the action sequences with
different significance step-by-step. Experimental results on dSprites and 3D
Chairs show that FVAE improves the stability of disentanglement.
</p>
<a href="http://arxiv.org/abs/2010.11684" target="_blank">arXiv:2010.11684</a> [<a href="http://arxiv.org/pdf/2010.11684" target="_blank">pdf</a>]

<h2>Cross-Spectral Iris Matching Using Conditional Coupled GAN. (arXiv:2010.11689v1 [cs.CV])</h2>
<h3>Moktari Mostofa, Fariborz Taherkhani, Jeremy Dawson, Nasser M. Nasrabadi</h3>
<p>Cross-spectral iris recognition is emerging as a promising biometric approach
to authenticating the identity of individuals. However, matching iris images
acquired at different spectral bands shows significant performance degradation
when compared to single-band near-infrared (NIR) matching due to the spectral
gap between iris images obtained in the NIR and visual-light (VIS) spectra.
Although researchers have recently focused on deep-learning-based approaches to
recover invariant representative features for more accurate recognition
performance, the existing methods cannot achieve the expected accuracy required
for commercial applications. Hence, in this paper, we propose a conditional
coupled generative adversarial network (CpGAN) architecture for cross-spectral
iris recognition by projecting the VIS and NIR iris images into a
low-dimensional embedding domain to explore the hidden relationship between
them. The conditional CpGAN framework consists of a pair of GAN-based networks,
one responsible for retrieving images in the visible domain and other
responsible for retrieving images in the NIR domain. Both networks try to map
the data into a common embedding subspace to ensure maximum pair-wise
similarity between the feature vectors from the two iris modalities of the same
subject. To prove the usefulness of our proposed approach, extensive
experimental results obtained on the PolyU dataset are compared to existing
state-of-the-art cross-spectral recognition methods.
</p>
<a href="http://arxiv.org/abs/2010.11689" target="_blank">arXiv:2010.11689</a> [<a href="http://arxiv.org/pdf/2010.11689" target="_blank">pdf</a>]

<h2>Conversion and Implementation of State-of-the-Art Deep Learning Algorithms for the Classification of Diabetic Retinopathy. (arXiv:2010.11692v1 [cs.CV])</h2>
<h3>Mihir Rao, Michelle Zhu, Tianyang Wang</h3>
<p>Diabetic retinopathy (DR) is a retinal microvascular condition that emerges
in diabetic patients. DR will continue to be a leading cause of blindness
worldwide, with a predicted 191.0 million globally diagnosed patients in 2030.
Microaneurysms, hemorrhages, exudates, and cotton wool spots are common signs
of DR. However, they can be small and hard for human eyes to detect. Early
detection of DR is crucial for effective clinical treatment. Existing methods
to classify images require much time for feature extraction and selection, and
are limited in their performance. Convolutional Neural Networks (CNNs), as an
emerging deep learning (DL) method, have proven their potential in image
classification tasks. In this paper, comprehensive experimental studies of
implementing state-of-the-art CNNs for the detection and classification of DR
are conducted in order to determine the top performing classifiers for the
task. Five CNN classifiers, namely Inception-V3, VGG19, VGG16, ResNet50, and
InceptionResNetV2, are evaluated through experiments. They categorize medical
images into five different classes based on DR severity. Data augmentation and
transfer learning techniques are applied since annotated medical images are
limited and imbalanced. Experimental results indicate that the ResNet50
classifier has top performance for binary classification and that the
InceptionResNetV2 classifier has top performance for multi-class DR
classification.
</p>
<a href="http://arxiv.org/abs/2010.11692" target="_blank">arXiv:2010.11692</a> [<a href="http://arxiv.org/pdf/2010.11692" target="_blank">pdf</a>]

<h2>Unsupervised Representation Learning by InvariancePropagation. (arXiv:2010.11694v1 [cs.CV])</h2>
<h3>Feng Wang, Huaping Liu, Di Guo, Fuchun Sun</h3>
<p>Unsupervised learning methods based on contrastive learning have drawn
increasing attention and achieved promising results. Most of them aim to learn
representations invariant to instance-level variations, which are provided by
different views of the same instance. In this paper, we propose Invariance
Propagation to focus on learning representations invariant to category-level
variations, which are provided by different instances from the same category.
Our method recursively discovers semantically consistent samples residing in
the same high-density regions in representation space. We demonstrate a hard
sampling strategy to concentrate on maximizing the agreement between the anchor
sample and its hard positive samples, which provide more intra-class variations
to help capture more abstract invariance. As a result, with a ResNet-50 as the
backbone, our method achieves 71.3% top-1 accuracy on ImageNet linear
classification and 78.2% top-5 accuracy fine-tuning on only 1% labels,
surpassing previous results. We also achieve state-of-the-art performance on
other downstream tasks, including linear classification on Places205 and Pascal
VOC, and transfer learning on small scale datasets.
</p>
<a href="http://arxiv.org/abs/2010.11694" target="_blank">arXiv:2010.11694</a> [<a href="http://arxiv.org/pdf/2010.11694" target="_blank">pdf</a>]

<h2>Automatic Data Augmentation for 3D Medical Image Segmentation. (arXiv:2010.11695v1 [eess.IV])</h2>
<h3>Ju Xu, Mengzhang Li, Zhanxing Zhu</h3>
<p>Data augmentation is an effective and universal technique for improving
generalization performance of deep neural networks. It could enrich diversity
of training samples that is essential in medical image segmentation tasks
because 1) the scale of medical image dataset is typically smaller, which may
increase the risk of overfitting; 2) the shape and modality of different
objects such as organs or tumors are unique, thus requiring customized data
augmentation policy. However, most data augmentation implementations are
hand-crafted and suboptimal in medical image processing. To fully exploit the
potential of data augmentation, we propose an efficient algorithm to
automatically search for the optimal augmentation strategies. We formulate the
coupled optimization w.r.t. network weights and augmentation parameters into a
differentiable form by means of stochastic relaxation. This formulation allows
us to apply alternative gradient-based methods to solve it, i.e. stochastic
natural gradient method with adaptive step-size. To the best of our knowledge,
it is the first time that differentiable automatic data augmentation is
employed in medical image segmentation tasks. Our numerical experiments
demonstrate that the proposed approach significantly outperforms existing
build-in data augmentation of state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2010.11695" target="_blank">arXiv:2010.11695</a> [<a href="http://arxiv.org/pdf/2010.11695" target="_blank">pdf</a>]

<h2>BlendTorch: A Real-Time, Adaptive Domain Randomization Library. (arXiv:2010.11696v1 [cs.CV])</h2>
<h3>Christoph Heindl, Lukas Brunner, Sebastian Zambal, Josef Scharinger</h3>
<p>Solving complex computer vision tasks by deep learning techniques relies on
large amounts of (supervised) image data, typically unavailable in industrial
environments. The lack of training data starts to impede the successful
transfer of state-of-the-art methods in computer vision to industrial
applications. We introduce BlendTorch, an adaptive Domain Randomization (DR)
library, to help creating infinite streams of synthetic training data.
BlendTorch generates data by massively randomizing low-fidelity simulations and
takes care of distributing artificial training data for model learning in
real-time. We show that models trained with BlendTorch repeatedly perform
better in an industrial object detection task than those trained on real or
photo-realistic datasets.
</p>
<a href="http://arxiv.org/abs/2010.11696" target="_blank">arXiv:2010.11696</a> [<a href="http://arxiv.org/pdf/2010.11696" target="_blank">pdf</a>]

<h2>A Data Set and a Convolutional Model for Iconography Classification in Paintings. (arXiv:2010.11697v1 [cs.CV])</h2>
<h3>Federico Milani, Piero Fraternali</h3>
<p>Iconography in art is the discipline that studies the visual content of
artworks to determine their motifs and themes andto characterize the way these
are represented. It is a subject of active research for a variety of purposes,
including the interpretation of meaning, the investigation of the origin and
diffusion in time and space of representations, and the study of influences
across artists and art works. With the proliferation of digital archives of art
images, the possibility arises of applying Computer Vision techniques to the
analysis of art images at an unprecedented scale, which may support iconography
research and education. In this paper we introduce a novel paintings data set
for iconography classification and present the quantitativeand qualitative
results of applying a Convolutional Neural Network (CNN) classifier to the
recognition of the iconography of artworks. The proposed classifier achieves
good performances (71.17% Precision, 70.89% Recall, 70.25% F1-Score and 72.73%
Average Precision) in the task of identifying saints in Christian religious
paintings, a task made difficult by the presence of classes with very similar
visual features. Qualitative analysis of the results shows that the CNN focuses
on the traditional iconic motifs that characterize the representation of each
saint and exploits such hints to attain correct identification. The ultimate
goal of our work is to enable the automatic extraction, decomposition, and
comparison of iconography elements to support iconographic studies and
automatic art work annotation.
</p>
<a href="http://arxiv.org/abs/2010.11697" target="_blank">arXiv:2010.11697</a> [<a href="http://arxiv.org/pdf/2010.11697" target="_blank">pdf</a>]

<h2>OCT-GAN: Single Step Shadow and Noise Removal from Optical Coherence Tomography Images of the Human Optic Nerve Head. (arXiv:2010.11698v1 [eess.IV])</h2>
<h3>Haris Cheong, Sripad Krishna Devalla, Thanadet Chuangsuwanich, Tin A. Tun, Xiaofei Wang, Tin Aung, Leopold Schmetterer, Martin L. Buist, Craig Boote, Alexandre H. Thi&#xe9;ry, Micha&#xeb;l J. A. Girard</h3>
<p>Speckle noise and retinal shadows within OCT B-scans occlude important edges,
fine textures and deep tissues, preventing accurate and robust diagnosis by
algorithms and clinicians. We developed a single process that successfully
removed both noise and retinal shadows from unseen single-frame B-scans within
10.4ms. Mean average gradient magnitude (AGM) for the proposed algorithm was
57.2% higher than current state-of-the-art, while mean peak signal to noise
ratio (PSNR), contrast to noise ratio (CNR), and structural similarity index
metric (SSIM) increased by 11.1%, 154% and 187% respectively compared to
single-frame B-scans. Mean intralayer contrast (ILC) improvement for the
retinal nerve fiber layer (RNFL), photoreceptor layer (PR) and retinal pigment
epithelium (RPE) layers decreased from 0.362 \pm 0.133 to 0.142 \pm 0.102,
0.449 \pm 0.116 to 0.0904 \pm 0.0769, 0.381 \pm 0.100 to 0.0590 \pm 0.0451
respectively. The proposed algorithm reduces the necessity for long image
acquisition times, minimizes expensive hardware requirements and reduces motion
artifacts in OCT images.
</p>
<a href="http://arxiv.org/abs/2010.11698" target="_blank">arXiv:2010.11698</a> [<a href="http://arxiv.org/pdf/2010.11698" target="_blank">pdf</a>]

<h2>On Benchmarking Iris Recognition within a Head-mounted Display for AR/VR Application. (arXiv:2010.11700v1 [cs.CV])</h2>
<h3>Fadi Boutros, Naser Damer, Kiran Raja, Raghavendra Ramachandra, Florian Kirchbuchner, Arjan Kuijper</h3>
<p>Augmented and virtual reality is being deployed in different fields of
applications. Such applications might involve accessing or processing critical
and sensitive information, which requires strict and continuous access control.
Given that Head-Mounted Displays (HMD) developed for such applications commonly
contains internal cameras for gaze tracking purposes, we evaluate the
suitability of such setup for verifying the users through iris recognition. In
this work, we first evaluate a set of iris recognition algorithms suitable for
HMD devices by investigating three well-established handcrafted feature
extraction approaches, and to complement it, we also present the analysis using
four deep learning models. While taking into consideration the minimalistic
hardware requirements of stand-alone HMD, we employ and adapt a recently
developed miniature segmentation model (EyeMMS) for segmenting the iris.
Further, to account for non-ideal and non-collaborative capture of iris, we
define a new iris quality metric that we termed as Iris Mask Ratio (IMR) to
quantify the iris recognition performance. Motivated by the performance of iris
recognition, we also propose the continuous authentication of users in a
non-collaborative capture setting in HMD. Through the experiments on a publicly
available OpenEDS dataset, we show that performance with EER = 5% can be
achieved using deep learning methods in a general setting, along with high
accuracy for continuous user authentication.
</p>
<a href="http://arxiv.org/abs/2010.11700" target="_blank">arXiv:2010.11700</a> [<a href="http://arxiv.org/pdf/2010.11700" target="_blank">pdf</a>]

<h2>Spatial Attention as an Interface for Image Captioning Models. (arXiv:2010.11701v1 [cs.CV])</h2>
<h3>Philipp Sadler</h3>
<p>The internal workings of modern deep learning models stay often unclear to an
external observer, although spatial attention mechanisms are involved. The idea
of this work is to translate these spatial attentions into natural language to
provide a simpler access to the model's function. Thus, I took a neural image
captioning model and measured the reactions to external modification in its
spatial attention for three different interface methods: a fixation over the
whole generation process, a fixation for the first time-steps and an addition
to the generator's attention. The experimental results for bounding box based
spatial attention vectors have shown that the captioning model reacts to method
dependent changes in up to 52.65% and includes in 9.00% of the cases object
categories, which were otherwise unmentioned. Afterwards, I established such a
link to a hierarchical co-attention network for visual question answering by
extraction of its word, phrase and question level spatial attentions. Here,
generated captions for the word level included details of the question-answer
pairs in up to 55.20% of the cases. This work indicates that spatial attention
seen as an external interface for image caption generators is an useful method
to access visual functions in natural language.
</p>
<a href="http://arxiv.org/abs/2010.11701" target="_blank">arXiv:2010.11701</a> [<a href="http://arxiv.org/pdf/2010.11701" target="_blank">pdf</a>]

<h2>Fast and Incremental Loop Closure Detection with Deep Features and Proximity Graphs. (arXiv:2010.11703v1 [cs.CV])</h2>
<h3>Shan An, Haogang Zhu, Dong Wei, Konstantinos A. Tsintotas</h3>
<p>In recent years, methods concerning the place recognition task have been
extensively examined from the robotics community within the scope of
simultaneous localization and mapping applications. In this article, an
appearance-based loop closure detection pipeline is proposed, entitled "FILD++"
(Fast and Incremental Loop closure Detection). When the incoming camera
observation arrives, global and local visual features are extracted through two
passes of a single convolutional neural network. Subsequently, a modified
hierarchical-navigable small-world graph incrementally generates a visual
database that represents the robot's traversed path based on global features.
Given the query sensor measurement, similar locations from the trajectory are
retrieved using these representations, while an image-to-image pairing is
further evaluated thanks to the spatial information provided by the local
features. Exhaustive experiments on several publicly-available datasets exhibit
the system's high performance and low execution time compared to other
contemporary state-of-the-art pipelines.
</p>
<a href="http://arxiv.org/abs/2010.11703" target="_blank">arXiv:2010.11703</a> [<a href="http://arxiv.org/pdf/2010.11703" target="_blank">pdf</a>]

<h2>Using Conditional Generative Adversarial Networks to Reduce the Effects of Latency in Robotic Telesurgery. (arXiv:2010.11704v1 [cs.CV])</h2>
<h3>Neil Sachdeva, Misha Klopukh, Rachel St. Clair, William Hahn</h3>
<p>The introduction of surgical robots brought about advancements in surgical
procedures. The applications of remote telesurgery range from building medical
clinics in underprivileged areas, to placing robots abroad in military
hot-spots where accessibility and diversity of medical experience may be
limited. Poor wireless connectivity may result in a prolonged delay, referred
to as latency, between a surgeon's input and action a robot takes. In surgery,
any micro-delay can injure a patient severely and in some cases, result in
fatality. One was to increase safety is to mitigate the effects of latency
using deep learning aided computer vision. While the current surgical robots
use calibrated sensors to measure the position of the arms and tools, in this
work we present a purely optical approach that provides a measurement of the
tool position in relation to the patient's tissues. This research aimed to
produce a neural network that allowed a robot to detect its own mechanical
manipulator arms. A conditional generative adversarial networks (cGAN) was
trained on 1107 frames of mock gastrointestinal robotic surgery data from the
2015 EndoVis Instrument Challenge and corresponding hand-drawn labels for each
frame. When run on new testing data, the network generated near-perfect labels
of the input images which were visually consistent with the hand-drawn labels
and was able to do this in 299 milliseconds. These accurately generated labels
can then be used as simplified identifiers for the robot to track its own
controlled tools. These results show potential for conditional GANs as a
reaction mechanism such that the robot can detect when its arms move outside
the operating area within a patient. This system allows for more accurate
monitoring of the position of surgical instruments in relation to the patient's
tissue, increasing safety measures that are integral to successful telesurgery
systems.
</p>
<a href="http://arxiv.org/abs/2010.11704" target="_blank">arXiv:2010.11704</a> [<a href="http://arxiv.org/pdf/2010.11704" target="_blank">pdf</a>]

<h2>Multi-view Graph Contrastive Representation Learning for Drug-Drug Interaction Prediction. (arXiv:2010.11711v1 [cs.LG])</h2>
<h3>Yingheng Wang, Yaosen Min, Xin Chen, Ji Wu</h3>
<p>Potential Drug-Drug Interaction(DDI) occurring while treating complex or
co-existing diseases with drug combinations may cause changes in drugs'
pharmacological activity. Therefore, DDI prediction has been an important task
in the medical healthy machine learning community. Graph-based learning methods
have recently aroused widespread interest and are proved to be a priority for
this task. However, these methods are often limited to exploiting the
inter-view drug molecular structure and ignoring the drug's intra-view
interaction relationship, vital to capturing the complex DDI patterns. This
study presents a new method, multi-view graph contrastive representation
learning for drug-drug interaction prediction, MIRACLE for brevity, to capture
inter-view molecule structure and intra-view interactions between molecules
simultaneously. MIRACLE treats a DDI network as a multi-view graph where each
node in the interaction graph itself is a drug molecular graph instance. We use
GCN to encode DDI relationships and a bond-aware attentive message propagating
method to capture drug molecular structure information in the MIRACLE learning
stage. Also, we propose a novel unsupervised contrastive learning component to
balance and integrate the multi-view information. Comprehensive experiments on
multiple real datasets show that MIRACLE outperforms the state-of-the-art DDI
prediction models consistently.
</p>
<a href="http://arxiv.org/abs/2010.11711" target="_blank">arXiv:2010.11711</a> [<a href="http://arxiv.org/pdf/2010.11711" target="_blank">pdf</a>]

<h2>Restoring Negative Information in Few-Shot Object Detection. (arXiv:2010.11714v1 [cs.CV])</h2>
<h3>Yukuan Yang, Fangyu Wei, Miaojing Shi, Guoqi Li</h3>
<p>Few-shot learning has recently emerged as a new challenge in the deep
learning field: unlike conventional methods that train the deep neural networks
(DNNs) with a large number of labeled data, it asks for the generalization of
DNNs on new classes with few annotated samples. Recent advances in few-shot
learning mainly focus on image classification while in this paper we focus on
object detection. The initial explorations in few-shot object detection tend to
simulate a classification scenario by using the positive proposals in images
with respect to certain object class while discarding the negative proposals of
that class. Negatives, especially hard negatives, however, are essential to the
embedding space learning in few-shot object detection. In this paper, we
restore the negative information in few-shot object detection by introducing a
new negative- and positive-representative based metric learning framework and a
new inference scheme with negative and positive representatives. We build our
work on a recent few-shot pipeline RepMet with several new modules to encode
negative information for both training and testing. Extensive experiments on
ImageNet-LOC and PASCAL VOC show our method substantially improves the
state-of-the-art few-shot object detection solutions. Our code is available at
https://github.com/yang-yk/NP-RepMet.
</p>
<a href="http://arxiv.org/abs/2010.11714" target="_blank">arXiv:2010.11714</a> [<a href="http://arxiv.org/pdf/2010.11714" target="_blank">pdf</a>]

<h2>Multifaceted Context Representation using Dual Attention for Ontology Alignment. (arXiv:2010.11721v1 [cs.AI])</h2>
<h3>Vivek Iyer, Arvind Agarwal, Harshit Kumar</h3>
<p>Ontology Alignment is an important research problem that finds application in
various fields such as data integration, data transfer, data preparation etc.
State-of-the-art (SOTA) architectures in Ontology Alignment typically use naive
domain-dependent approaches with handcrafted rules and manually assigned
values, making them unscalable and inefficient. Deep Learning approaches for
ontology alignment use domain-specific architectures that are not only
in-extensible to other datasets and domains, but also typically perform worse
than rule-based approaches due to various limitations including over-fitting of
models, sparsity of datasets etc. In this work, we propose VeeAlign, a Deep
Learning based model that uses a dual-attention mechanism to compute the
contextualized representation of a concept in order to learn alignments. By
doing so, not only does our approach exploit both syntactic and semantic
structure of ontologies, it is also, by design, flexible and scalable to
different domains with minimal effort. We validate our approach on various
datasets from different domains and in multilingual settings, and show its
superior performance over SOTA methods.
</p>
<a href="http://arxiv.org/abs/2010.11721" target="_blank">arXiv:2010.11721</a> [<a href="http://arxiv.org/pdf/2010.11721" target="_blank">pdf</a>]

<h2>Learning from Suboptimal Demonstration via Self-Supervised Reward Regression. (arXiv:2010.11723v1 [cs.RO])</h2>
<h3>Letian Chen, Rohan Paleja, Matthew Gombolay</h3>
<p>Learning from Demonstration (LfD) seeks to democratize robotics by enabling
non-roboticist end-users to teach robots to perform a task by providing a human
demonstration. However, modern LfD techniques, such as inverse reinforcement
learning (IRL), assume users provide at least stochastically optimal
demonstrations. This assumption fails to hold in all but the most isolated,
controlled scenarios, reducing the ability to achieve the goal of empowering
real end-users. Recent attempts to learn from sub-optimal demonstration
leverage pairwise rankings through Preference-based Reinforcement Learning
(PbRL) to infer a more optimal policy than the demonstration. However, we show
that these approaches make incorrect assumptions and, consequently, suffer from
brittle, degraded performance. In this paper, we overcome the limitations of
prior work by developing a novel computational technique that infers an
idealized reward function from suboptimal demonstration and bootstraps
suboptimal demonstrations to synthesize optimality-parameterized training data
for training our reward function. We empirically validate we can learn an
idealized reward function with $\sim0.95$ correlation with the ground truth
reward versus only $\sim 0.75$ for prior work. We can then train policies
achieving $\sim 200\%$ improvement over the suboptimal demonstration and $\sim
90\%$ improvement over prior work. Finally, we present a real-world
implementation for teaching a robot to hit a topspin shot in table tennis
better than user demonstration.
</p>
<a href="http://arxiv.org/abs/2010.11723" target="_blank">arXiv:2010.11723</a> [<a href="http://arxiv.org/pdf/2010.11723" target="_blank">pdf</a>]

<h2>LID 2020: The Learning from Imperfect Data Challenge Results. (arXiv:2010.11724v1 [cs.CV])</h2>
<h3>Yunchao Wei, Shuai Zheng, Ming-Ming Cheng, Hang Zhao, Liwei Wang, Errui Ding, Yi Yang, Antonio Torralba, Ting Liu, Guolei Sun, Wenguan Wang, Luc Van Gool, Wonho Bae, Junhyug Noh, Jinhwan Seo, Gunhee Kim, Hao Zhao, Ming Lu, Anbang Yao, Yiwen Guo, Yurong Chen, Li Zhang, Chuangchuang Tan, Tao Ruan, Guanghua Gu, Shikui Wei, Yao Zhao, Mariia Dobko, Ostap Viniavskyi, Oles Dobosevych, Zhendong Wang, Zhenyuan Chen, Chen Gong, Huanqing Yan, Jun He</h3>
<p>Learning from imperfect data becomes an issue in many industrial applications
after the research community has made profound progress in supervised learning
from perfectly annotated datasets. The purpose of the Learning from Imperfect
Data (LID) workshop is to inspire and facilitate the research in developing
novel approaches that would harness the imperfect data and improve the
data-efficiency during training. A massive amount of user-generated data
nowadays available on multiple internet services. How to leverage those and
improve the machine learning models is a high impact problem. We organize the
challenges in conjunction with the workshop. The goal of these challenges is to
find the state-of-the-art approaches in the weakly supervised learning setting
for object detection, semantic segmentation, and scene parsing. There are three
tracks in the challenge, i.e., weakly supervised semantic segmentation (Track
1), weakly supervised scene parsing (Track 2), and weakly supervised object
localization (Track 3). In Track 1, based on ILSVRC DET, we provide pixel-level
annotations of 15K images from 200 categories for evaluation. In Track 2, we
provide point-based annotations for the training set of ADE20K. In Track 3,
based on ILSVRC CLS-LOC, we provide pixel-level annotations of 44,271 images
for evaluation. Besides, we further introduce a new evaluation metric proposed
by \cite{zhang2020rethinking}, i.e., IoU curve, to measure the quality of the
generated object localization maps. This technical report summarizes the
highlights from the challenge. The challenge submission server and the
leaderboard will continue to open for the researchers who are interested in it.
More details regarding the challenge and the benchmarks are available at
https://lidchallenge.github.io
</p>
<a href="http://arxiv.org/abs/2010.11724" target="_blank">arXiv:2010.11724</a> [<a href="http://arxiv.org/pdf/2010.11724" target="_blank">pdf</a>]

<h2>Vision-Based Layout Detection from Scientific Literature using Recurrent Convolutional Neural Networks. (arXiv:2010.11727v1 [cs.CV])</h2>
<h3>Huichen Yang, William H. Hsu</h3>
<p>We present an approach for adapting convolutional neural networks for object
recognition and classification to scientific literature layout detection
(SLLD), a shared subtask of several information extraction problems. Scientific
publications contain multiple types of information sought by researchers in
various disciplines, organized into an abstract, bibliography, and sections
documenting related work, experimental methods, and results; however, there is
no effective way to extract this information due to their diverse layout. In
this paper, we present a novel approach to developing an end-to-end learning
framework to segment and classify major regions of a scientific document. We
consider scientific document layout analysis as an object detection task over
digital images, without any additional text features that need to be added into
the network during the training process. Our technical objective is to
implement transfer learning via fine-tuning of pre-trained networks and thereby
demonstrate that this deep learning architecture is suitable for tasks that
lack very large document corpora for training ab initio. As part of the
experimental test bed for empirical evaluation of this approach, we created a
merged multi-corpus data set for scientific publication layout detection tasks.
Our results show good improvement with fine-tuning of a pre-trained base
network using this merged data set, compared to the baseline convolutional
neural network architecture.
</p>
<a href="http://arxiv.org/abs/2010.11727" target="_blank">arXiv:2010.11727</a> [<a href="http://arxiv.org/pdf/2010.11727" target="_blank">pdf</a>]

<h2>Improving BERT Performance for Aspect-Based Sentiment Analysis. (arXiv:2010.11731v1 [cs.CL])</h2>
<h3>Akbar Karimi, Leonardo Rossi, Andrea Prati</h3>
<p>Aspect-Based Sentiment Analysis (ABSA) studies the consumer opinion on the
market products. It involves examining the type of sentiments as well as
sentiment targets expressed in product reviews. Analyzing the language used in
a review is a difficult task that requires a deep understanding of the
language. In recent years, deep language models, such as BERT
\cite{devlin2019bert}, have shown great progress in this regard. In this work,
we propose two simple modules called Parallel Aggregation and Hierarchical
Aggregation to be utilized on top of BERT for two main ABSA tasks namely Aspect
Extraction (AE) and Aspect Sentiment Classification (ASC) in order to improve
the model's performance. We show that applying the proposed models eliminates
the need for further training of the BERT model. The source code is available
on the Web for further research and reproduction of the results.
</p>
<a href="http://arxiv.org/abs/2010.11731" target="_blank">arXiv:2010.11731</a> [<a href="http://arxiv.org/pdf/2010.11731" target="_blank">pdf</a>]

<h2>A Cluster-Matching-Based Method for Video Face Recognition. (arXiv:2010.11732v1 [cs.CV])</h2>
<h3>Paulo R C Mendes, Antonio J G Busson, S&#xe9;rgio Colcher, Daniel Schwabe, &#xc1;lan L V Guedes, Carlos Laufer</h3>
<p>Face recognition systems are present in many modern solutions and thousands
of applications in our daily lives. However, current solutions are not easily
scalable, especially when it comes to the addition of new targeted people. We
propose a cluster-matching-based approach for face recognition in video. In our
approach, we use unsupervised learning to cluster the faces present in both the
dataset and targeted videos selected for face recognition. Moreover, we design
a cluster matching heuristic to associate clusters in both sets that is also
capable of identifying when a face belongs to a non-registered person. Our
method has achieved a recall of 99.435% and a precision of 99.131% in the task
of video face recognition. Besides performing face recognition, it can also be
used to determine the video segments where each person is present.
</p>
<a href="http://arxiv.org/abs/2010.11732" target="_blank">arXiv:2010.11732</a> [<a href="http://arxiv.org/pdf/2010.11732" target="_blank">pdf</a>]

<h2>Multi-Radar Tracking Optimization for Collaborative Combat. (arXiv:2010.11733v1 [cs.AI])</h2>
<h3>Nouredine Nour, Reda Belhaj-Soullami, C&#xe9;dric Buron, Alain Peres, Fr&#xe9;d&#xe9;ric Barbaresco</h3>
<p>Smart Grids of collaborative netted radars accelerate kill chains through
more efficient cross-cueing over centralized command and control. In this
paper, we propose two novel reward-based learning approaches to decentralized
netted radar coordination based on black-box optimization and Reinforcement
Learning (RL). To make the RL approach tractable, we use a simplification of
the problem that we proved to be equivalent to the initial formulation. We
apply these techniques on a simulation where radars can follow multiple targets
at the same time and show they can learn implicit cooperation by comparing them
to a greedy baseline.
</p>
<a href="http://arxiv.org/abs/2010.11733" target="_blank">arXiv:2010.11733</a> [<a href="http://arxiv.org/pdf/2010.11733" target="_blank">pdf</a>]

<h2>Identification of deep breath while moving forward based on multiple body regions and graph signal analysis. (arXiv:2010.11734v1 [cs.CV])</h2>
<h3>Yunlu Wang, Cheng Yang, Menghan Hu, Jian Zhang, Qingli Li, Guangtao Zhai, Xiao-Ping Zhang</h3>
<p>This paper presents an unobtrusive solution that can automatically identify
deep breath when a person is walking past the global depth camera. Existing
non-contact breath assessments achieve satisfactory results under restricted
conditions when human body stays relatively still. When someone moves forward,
the breath signals detected by depth camera are hidden within signals of trunk
displacement and deformation, and the signal length is short due to the short
stay time, posing great challenges for us to establish models. To overcome
these challenges, multiple region of interests (ROIs) based signal extraction
and selection method is proposed to automatically obtain the signal informative
to breath from depth video. Subsequently, graph signal analysis (GSA) is
adopted as a spatial-temporal filter to wipe the components unrelated to
breath. Finally, a classifier for identifying deep breath is established based
on the selected breath-informative signal. In validation experiments, the
proposed approach outperforms the comparative methods with the accuracy,
precision, recall and F1 of 75.5%, 76.2%, 75.0% and 75.2%, respectively. This
system can be extended to public places to provide timely and ubiquitous help
for those who may have or are going through physical or mental trouble.
</p>
<a href="http://arxiv.org/abs/2010.11734" target="_blank">arXiv:2010.11734</a> [<a href="http://arxiv.org/pdf/2010.11734" target="_blank">pdf</a>]

<h2>Self-Supervised Learning of Part Mobility from Point Cloud Sequence. (arXiv:2010.11735v1 [cs.CV])</h2>
<h3>Yahao Shi, Xinyu Cao, Bin Zhou</h3>
<p>Part mobility analysis is a significant aspect required to achieve a
functional understanding of 3D objects. It would be natural to obtain part
mobility from the continuous part motion of 3D objects. In this study, we
introduce a self-supervised method for segmenting motion parts and predicting
their motion attributes from a point cloud sequence representing a dynamic
object. To sufficiently utilize spatiotemporal information from the point cloud
sequence, we generate trajectories by using correlations among successive
frames of the sequence instead of directly processing the point clouds. We
propose a novel neural network architecture called PointRNN to learn feature
representations of trajectories along with their part rigid motions. We
evaluate our method on various tasks including motion part segmentation, motion
axis prediction and motion range estimation. The results demonstrate that our
method outperforms previous techniques on both synthetic and real datasets.
Moreover, our method has the ability to generalize to new and unseen objects.
It is important to emphasize that it is not required to know any prior shape
structure, prior shape category information, or shape orientation. To the best
of our knowledge, this is the first study on deep learning to extract part
mobility from point cloud sequence of a dynamic object.
</p>
<a href="http://arxiv.org/abs/2010.11735" target="_blank">arXiv:2010.11735</a> [<a href="http://arxiv.org/pdf/2010.11735" target="_blank">pdf</a>]

<h2>Optimising Stochastic Routing for Taxi Fleets with Model Enhanced Reinforcement Learning. (arXiv:2010.11738v1 [cs.LG])</h2>
<h3>Shen Ren, Qianxiao Li, Liye Zhang, Zheng Qin, Bo Yang</h3>
<p>The future of mobility-as-a-Service (Maas)should embrace an integrated system
of ride-hailing, street-hailing and ride-sharing with optimised intelligent
vehicle routing in response to a real-time, stochastic demand pattern. We aim
to optimise routing policies for a large fleet of vehicles for street-hailing
services, given a stochastic demand pattern in small to medium-sized road
networks. A model-based dispatch algorithm, a high performance model-free
reinforcement learning based algorithm and a novel hybrid algorithm combining
the benefits of both the top-down approach and the model-free reinforcement
learning have been proposed to route the \emph{vacant} vehicles. We design our
reinforcement learning based routing algorithm using proximal policy
optimisation and combined intrinsic and extrinsic rewards to strike a balance
between exploration and exploitation. Using a large-scale agent-based
microscopic simulation platform to evaluate our proposed algorithms, our
model-free reinforcement learning and hybrid algorithm show excellent
performance on both artificial road network and community-based Singapore road
network with empirical demands, and our hybrid algorithm can significantly
accelerate the model-free learner in the process of learning.
</p>
<a href="http://arxiv.org/abs/2010.11738" target="_blank">arXiv:2010.11738</a> [<a href="http://arxiv.org/pdf/2010.11738" target="_blank">pdf</a>]

<h2>Ultra-low power on-chip learning of speech commands with phase-change memories. (arXiv:2010.11741v1 [eess.AS])</h2>
<h3>Venkata Pavan Kumar Miriyala, Masatoshi Ishii</h3>
<p>Embedding artificial intelligence at the edge (edge-AI) is an elegant
solution to tackle the power and latency issues in the rapidly expanding
Internet of Things. As edge devices typically spend most of their time in sleep
mode and only wake-up infrequently to collect and process sensor data,
non-volatile in-memory computing (NVIMC) is a promising approach to design the
next generation of edge-AI devices. Recently, we proposed an NVIMC-based
neuromorphic accelerator using the phase change memories (PCMs), which we call
as Raven. In this work, we demonstrate the ultra-low-power on-chip training and
inference of speech commands using Raven. We showed that Raven can be trained
on-chip with power consumption as low as 30~uW, which is suitable for edge
applications. Furthermore, we showed that at iso-accuracies, Raven needs 70.36x
and 269.23x less number of computations to be performed than a deep neural
network (DNN) during inference and training, respectively. Owing to such low
power and computational requirements, Raven provides a promising pathway
towards ultra-low-power training and inference at the edge.
</p>
<a href="http://arxiv.org/abs/2010.11741" target="_blank">arXiv:2010.11741</a> [<a href="http://arxiv.org/pdf/2010.11741" target="_blank">pdf</a>]

<h2>Learning Black-Box Attackers with Transferable Priors and Query Feedback. (arXiv:2010.11742v1 [cs.CR])</h2>
<h3>Jiancheng Yang, Yangzhou Jiang, Xiaoyang Huang, Bingbing Ni, Chenglong Zhao</h3>
<p>This paper addresses the challenging black-box adversarial attack problem,
where only classification confidence of a victim model is available. Inspired
by consistency of visual saliency between different vision models, a surrogate
model is expected to improve the attack performance via transferability. By
combining transferability-based and query-based black-box attack, we propose a
surprisingly simple baseline approach (named SimBA++) using the surrogate
model, which significantly outperforms several state-of-the-art methods.
Moreover, to efficiently utilize the query feedback, we update the surrogate
model in a novel learning scheme, named High-Order Gradient Approximation
(HOGA). By constructing a high-order gradient computation graph, we update the
surrogate model to approximate the victim model in both forward and backward
pass. The SimBA++ and HOGA result in Learnable Black-Box Attack (LeBA), which
surpasses previous state of the art by considerable margins: the proposed LeBA
significantly reduces queries, while keeping higher attack success rates close
to 100% in extensive ImageNet experiments, including attacking vision
benchmarks and defensive models. Code is open source at
https://github.com/TrustworthyDL/LeBA.
</p>
<a href="http://arxiv.org/abs/2010.11742" target="_blank">arXiv:2010.11742</a> [<a href="http://arxiv.org/pdf/2010.11742" target="_blank">pdf</a>]

<h2>The Role of Machine Learning for Trajectory Prediction in Cooperative Driving. (arXiv:2010.11743v1 [cs.LG])</h2>
<h3>Luis Sequeira, Toktam Mahmoodi</h3>
<p>In this paper, we study the role that machine learning can play in
cooperative driving. Given the increasing rate of connectivity in modern
vehicles, and road infrastructure, cooperative driving is a promising first
step in automated driving. The example scenario we explored in this paper, is
coordinated lane merge, with data collection, test and evaluation all conducted
in an automotive test track. The assumption is that vehicles are a mix of those
equipped with communication units on board, i.e. connected vehicles, and those
that are not connected. However, roadside cameras are connected and can capture
all vehicles including those without connectivity. We develop a Traffic
Orchestrator that suggests trajectories based on these two sources of
information, i.e. connected vehicles, and connected roadside cameras.
Recommended trajectories are built, which are then communicated back to the
connected vehicles. We explore the use of different machine learning techniques
in accurately and timely prediction of trajectories.
</p>
<a href="http://arxiv.org/abs/2010.11743" target="_blank">arXiv:2010.11743</a> [<a href="http://arxiv.org/pdf/2010.11743" target="_blank">pdf</a>]

<h2>CUNI Systems for the Unsupervised and Very Low Resource Translation Task in WMT20. (arXiv:2010.11747v1 [cs.CL])</h2>
<h3>Ivana Kvapil&#xed;kov&#xe1;, Tom Kocmi, Ond&#x159;ej Bojar</h3>
<p>This paper presents a description of CUNI systems submitted to the WMT20 task
on unsupervised and very low-resource supervised machine translation between
German and Upper Sorbian. We experimented with training on synthetic data and
pre-training on a related language pair. In the fully unsupervised scenario, we
achieved 25.5 and 23.7 BLEU translating from and into Upper Sorbian,
respectively. Our low-resource systems relied on transfer learning from
German-Czech parallel data and achieved 57.4 BLEU and 56.1 BLEU, which is an
improvement of 10 BLEU points over the baseline trained only on the available
small German-Upper Sorbian parallel corpus.
</p>
<a href="http://arxiv.org/abs/2010.11747" target="_blank">arXiv:2010.11747</a> [<a href="http://arxiv.org/pdf/2010.11747" target="_blank">pdf</a>]

<h2>Classification with Rejection Based on Cost-sensitive Classification. (arXiv:2010.11748v1 [stat.ML])</h2>
<h3>Nontawat Charoenphakdee, Zhenghang Cui, Yivan Zhang, Masashi Sugiyama</h3>
<p>The goal of classification with rejection is to avoid risky misclassification
in error-critical applications such as medical diagnosis and product
inspection. In this paper, based on the relationship between classification
with rejection and cost-sensitive classification, we propose a novel method of
classification with rejection by learning an ensemble of cost-sensitive
classifiers, which satisfies all the following properties for the first time:
(i) it can avoid estimating class-posterior probabilities, resulting in
improved classification accuracy. (ii) it allows a flexible choice of losses
including non-convex ones, (iii) it does not require complicated modifications
when using different losses, (iv) it is applicable to both binary and
multiclass cases, and (v) it is theoretically justifiable for any
classification-calibrated loss. Experimental results demonstrate the usefulness
of our proposed approach in clean-labeled, noisy-labeled, and
positive-unlabeled classification.
</p>
<a href="http://arxiv.org/abs/2010.11748" target="_blank">arXiv:2010.11748</a> [<a href="http://arxiv.org/pdf/2010.11748" target="_blank">pdf</a>]

<h2>Sharp Bias-variance Tradeoffs of Hard Parameter Sharing in High-dimensional Linear Regression. (arXiv:2010.11750v1 [stat.ML])</h2>
<h3>Hongyang R. Zhang, Fan Yang, Sen Wu, Weijie J. Su, Christopher R&#xe9;</h3>
<p>Hard parameter sharing for multi-task learning is widely used in empirical
research despite the fact that its generalization properties have not been well
established in many cases. This paper studies its generalization properties in
a fundamental setting: How does hard parameter sharing work given multiple
linear regression tasks? We develop new techniques and establish a number of
new results in the high-dimensional setting, where the sample size and feature
dimension increase at a fixed ratio. First, we show a sharp bias-variance
decomposition of hard parameter sharing, given multiple tasks with the same
features. Second, we characterize the asymptotic bias-variance limit for two
tasks, even when they have arbitrarily different sample size ratios and
covariate shifts. We also demonstrate that these limiting estimates for the
empirical loss are incredibly accurate in moderate dimensions. Finally, we
explain an intriguing phenomenon where increasing one task's sample size helps
another task initially by reducing variance but hurts eventually due to
increasing bias. This suggests progressively adding data for optimizing hard
parameter sharing, and we validate its efficiency in text classification tasks.
</p>
<a href="http://arxiv.org/abs/2010.11750" target="_blank">arXiv:2010.11750</a> [<a href="http://arxiv.org/pdf/2010.11750" target="_blank">pdf</a>]

<h2>Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition. (arXiv:2010.11757v1 [cs.CV])</h2>
<h3>Chun-Fu Chen, Rameswar Panda, Kandan Ramakrishnan, Rogerio Feris, John Cohn, Aude Oliva, Quanfu Fan</h3>
<p>In recent years, a number of approaches based on 2D CNNs and 3D CNNs have
emerged for video action recognition, achieving state-of-the-art results on
several large-scale benchmark datasets. In this paper, we carry out an in-depth
comparative analysis to better understand the differences between these
approaches and the progress made by them. To this end, we develop a unified
framework for both 2D-CNN and 3D-CNN action models, which enables us to remove
bells and whistles and provides a common ground for a fair comparison. We then
conduct an effort towards a large-scale analysis involving over 300 action
recognition models. Our comprehensive analysis reveals that a) a significant
leap is made in efficiency for action recognition, but not in accuracy; b)
2D-CNN and 3D-CNN models behave similarly in terms of spatio-temporal
representation abilities and transferability. Our analysis also shows that
recent action models seem to be able to learn data-dependent temporality
flexibly as needed. Our codes and models are available on
\url{https://github.com/IBM/action-recognition-pytorch}.
</p>
<a href="http://arxiv.org/abs/2010.11757" target="_blank">arXiv:2010.11757</a> [<a href="http://arxiv.org/pdf/2010.11757" target="_blank">pdf</a>]

<h2>Identifying Learning Rules From Neural Network Observables. (arXiv:2010.11765v1 [q-bio.NC])</h2>
<h3>Aran Nayebi, Sanjana Srivastava, Surya Ganguli, Daniel L.K. Yamins</h3>
<p>The brain modifies its synaptic strengths during learning in order to better
adapt to its environment. However, the underlying plasticity rules that govern
learning are unknown. Many proposals have been suggested, including Hebbian
mechanisms, explicit error backpropagation, and a variety of alternatives. It
is an open question as to what specific experimental measurements would need to
be made to determine whether any given learning rule is operative in a real
biological system. In this work, we take a "virtual experimental" approach to
this problem. Simulating idealized neuroscience experiments with artificial
neural networks, we generate a large-scale dataset of learning trajectories of
aggregate statistics measured in a variety of neural network architectures,
loss functions, learning rule hyperparameters, and parameter initializations.
We then take a discriminative approach, training linear and simple non-linear
classifiers to identify learning rules from features based on these
observables. We show that different classes of learning rules can be separated
solely on the basis of aggregate statistics of the weights, activations, or
instantaneous layer-wise activity changes, and that these results generalize to
limited access to the trajectory and held-out architectures and learning
curricula. We identify the statistics of each observable that are most relevant
for rule identification, finding that statistics from network activities across
training are more robust to unit undersampling and measurement noise than those
obtained from the synaptic strengths. Our results suggest that activation
patterns, available from electrophysiological recordings of post-synaptic
activities on the order of several hundred units, frequently measured at wider
intervals over the course of learning, may provide a good basis on which to
identify learning rules.
</p>
<a href="http://arxiv.org/abs/2010.11765" target="_blank">arXiv:2010.11765</a> [<a href="http://arxiv.org/pdf/2010.11765" target="_blank">pdf</a>]

<h2>Deep learning prediction of patient response time course from early data via neural-pharmacokinetic/pharmacodynamic modeling. (arXiv:2010.11769v1 [cs.LG])</h2>
<h3>James Lu, Brendan Bender, Jin Y. Jin, Yuanfang Guan</h3>
<p>The longitudinal analysis of patient response time course following doses of
therapeutics is currently performed using Pharmacokinetic/Pharmacodynamic
(PK/PD) methodologies, which requires significant human experience and
expertise in the modeling of dynamical systems. By utilizing recent
advancements in deep learning, we show that the governing differential
equations can be learnt directly from longitudinal patient data. In particular,
we propose a novel neural-PK/PD framework that combines key pharmacological
principles with neural ordinary differential equations. We applied it to an
analysis of drug concentration and platelet response from a clinical dataset
consisting of over 600 patients. We show that the neural-PK/PD model improves
upon a state-of-the-art model with respect to metrics for temporal prediction.
Furthermore, by incorporating key PK/PD concepts into its architecture, the
model can generalize and enable the simulations of patient responses to
untested dosing regimens. These results demonstrate the potential of
neural-PK/PD for automated predictive analytics of patient response time
course.
</p>
<a href="http://arxiv.org/abs/2010.11769" target="_blank">arXiv:2010.11769</a> [<a href="http://arxiv.org/pdf/2010.11769" target="_blank">pdf</a>]

<h2>On Resource-Efficient Bayesian Network Classifiers and Deep Neural Networks. (arXiv:2010.11773v1 [cs.LG])</h2>
<h3>Wolfgang Roth, G&#xfc;nther Schindler, Holger Fr&#xf6;ning, Franz Pernkopf</h3>
<p>We present two methods to reduce the complexity of Bayesian network (BN)
classifiers. First, we introduce quantization-aware training using the
straight-through gradient estimator to quantize the parameters of BNs to few
bits. Second, we extend a recently proposed differentiable tree-augmented naive
Bayes (TAN) structure learning approach by also considering the model size.
Both methods are motivated by recent developments in the deep learning
community, and they provide effective means to trade off between model size and
prediction accuracy, which is demonstrated in extensive experiments.
Furthermore, we contrast quantized BN classifiers with quantized deep neural
networks (DNNs) for small-scale scenarios which have hardly been investigated
in the literature. We show Pareto optimal models with respect to model size,
number of operations, and test error and find that both model classes are
viable options.
</p>
<a href="http://arxiv.org/abs/2010.11773" target="_blank">arXiv:2010.11773</a> [<a href="http://arxiv.org/pdf/2010.11773" target="_blank">pdf</a>]

<h2>FasterRCNN Monitoring of Road Damages: Competition and Deployment. (arXiv:2010.11780v1 [cs.CV])</h2>
<h3>Hascoet Tristan, Yihao Zhang, Persch Andreas, Ryoichi Takashima, Tetsuya Takiguchi, Yasuo Ariki</h3>
<p>Maintaining aging infrastructure is a challenge currently faced by local and
national administrators all around the world. An important prerequisite for
efficient infrastructure maintenance is to continuously monitor (i.e., quantify
the level of safety and reliability) the state of very large structures.
Meanwhile, computer vision has made impressive strides in recent years, mainly
due to successful applications of deep learning models. These novel progresses
are allowing the automation of vision tasks, which were previously impossible
to automate, offering promising possibilities to assist administrators in
optimizing their infrastructure maintenance operations. In this context, the
IEEE 2020 global Road Damage Detection (RDD) Challenge is giving an opportunity
for deep learning and computer vision researchers to get involved and help
accurately track pavement damages on road networks. This paper proposes two
contributions to that topic: In a first part, we detail our solution to the RDD
Challenge. In a second part, we present our efforts in deploying our model on a
local road network, explaining the proposed methodology and encountered
challenges.
</p>
<a href="http://arxiv.org/abs/2010.11780" target="_blank">arXiv:2010.11780</a> [<a href="http://arxiv.org/pdf/2010.11780" target="_blank">pdf</a>]

<h2>Self-alignment Pre-training for Biomedical Entity Representations. (arXiv:2010.11784v1 [cs.CL])</h2>
<h3>Fangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco Basaldella, Nigel Collier</h3>
<p>Despite the widespread success of self-supervised learning via masked
language models, learning representations directly from text to accurately
capture complex and fine-grained semantic relationships in the biomedical
domain remains as a challenge. Addressing this is of paramount importance for
tasks such as entity linking where complex relational knowledge is pivotal. We
propose SapBERT, a pre-training scheme based on BERT. It self-aligns the
representation space of biomedical entities with a metric learning objective
function leveraging UMLS, a collection of biomedical ontologies with &gt;4M
concepts. Our experimental results on six medical entity linking benchmarking
datasets demonstrate that SapBERT outperforms many domain-specific BERT-based
variants such as BioBERT, BlueBERT and PubMedBERT, achieving the
state-of-the-art (SOTA) performances.
</p>
<a href="http://arxiv.org/abs/2010.11784" target="_blank">arXiv:2010.11784</a> [<a href="http://arxiv.org/pdf/2010.11784" target="_blank">pdf</a>]

<h2>Prediction of Rainfall in Rajasthan, India using Deep and Wide Neural Network. (arXiv:2010.11787v1 [cs.LG])</h2>
<h3>Vikas Bajpai, Anukriti Bansal, Kshitiz Verma, Sanjay Agarwal</h3>
<p>Rainfall is a natural process which is of utmost importance in various areas
including water cycle, ground water recharging, disaster management and
economic cycle. Accurate prediction of rainfall intensity is a challenging task
and its exact prediction helps in every aspect. In this paper, we propose a
deep and wide rainfall prediction model (DWRPM) and evaluate its effectiveness
to predict rainfall in Indian state of Rajasthan using historical time-series
data. For wide network, instead of using rainfall intensity values directly, we
are using features obtained after applying a convolutional layer. For deep
part, a multi-layer perceptron (MLP) is used. Information of geographical
parameters (latitude and longitude) are included in a unique way. It gives the
model a generalization ability, which helps a single model to make rainfall
predictions in different geographical conditions. We compare our results with
various deep-learning approaches like MLP, LSTM and CNN, which are observed to
work well in sequence-based predictions. Experimental analysis and comparison
shows the applicability of our proposed method for rainfall prediction in
Rajasthan.
</p>
<a href="http://arxiv.org/abs/2010.11787" target="_blank">arXiv:2010.11787</a> [<a href="http://arxiv.org/pdf/2010.11787" target="_blank">pdf</a>]

<h2>ConVEx: Data-Efficient and Few-Shot Slot Labeling. (arXiv:2010.11791v1 [cs.CL])</h2>
<h3>Matthew Henderson, Ivan Vuli&#x107;</h3>
<p>We propose ConVEx (Conversational Value Extractor), an efficient pretraining
and fine-tuning neural approach for slot-labeling dialog tasks. Instead of
relying on more general pretraining objectives from prior work (e.g., language
modeling, response selection), ConVEx's pretraining objective, a novel pairwise
cloze task using Reddit data, is well aligned with its intended usage on
sequence labeling tasks. This enables learning domain-specific slot labelers by
simply fine-tuning decoding layers of the pretrained general-purpose sequence
labeling model, while the majority of the pretrained model's parameters are
kept frozen. We report state-of-the-art performance of ConVEx across a range of
diverse domains and data sets for dialog slot-labeling, with the largest gains
in the most challenging, few-shot setups. We believe that ConVEx's reduced
pretraining times (i.e., only 18 hours on 12 GPUs) and cost, along with its
efficient fine-tuning and strong performance, promise wider portability and
scalability for data-efficient sequence-labeling tasks in general.
</p>
<a href="http://arxiv.org/abs/2010.11791" target="_blank">arXiv:2010.11791</a> [<a href="http://arxiv.org/pdf/2010.11791" target="_blank">pdf</a>]

<h2>Castle in the Sky: Dynamic Sky Replacement and Harmonization in Videos. (arXiv:2010.11800v1 [cs.CV])</h2>
<h3>Zhengxia Zou</h3>
<p>This paper proposes a vision-based method for video sky replacement and
harmonization, which can automatically generate realistic and dramatic sky
backgrounds in videos with controllable styles. Different from previous sky
editing methods that either focus on static photos or require inertial
measurement units integrated in smartphones on shooting videos, our method is
purely vision-based, without any requirements on the capturing devices, and can
be well applied to either online or offline processing scenarios. Our method
runs in real-time and is free of user interactions. We decompose this artistic
creation process into a couple of proxy tasks including sky matting, motion
estimation, and image blending. Experiments are conducted on videos diversely
captured in the wild by handheld smartphones and dash cameras, and show high
fidelity and good generalization of our method in both visual quality and
lighting/motion dynamics. Our code and animated results are available at
\url{https://jiupinjia.github.io/skyar/}.
</p>
<a href="http://arxiv.org/abs/2010.11800" target="_blank">arXiv:2010.11800</a> [<a href="http://arxiv.org/pdf/2010.11800" target="_blank">pdf</a>]

<h2>Factorized Neural Processes for Neural Processes: $K$-Shot Prediction of Neural Responses. (arXiv:2010.11810v1 [q-bio.NC])</h2>
<h3>R. James Cotton, Fabian H. Sinz, Andreas S. Tolias</h3>
<p>In recent years, artificial neural networks have achieved state-of-the-art
performance for predicting the responses of neurons in the visual cortex to
natural stimuli. However, they require a time consuming parameter optimization
process for accurately modeling the tuning function of newly observed neurons,
which prohibits many applications including real-time, closed-loop experiments.
We overcome this limitation by formulating the problem as $K$-shot prediction
to directly infer a neuron's tuning function from a small set of
stimulus-response pairs using a Neural Process. This required us to developed a
Factorized Neural Process, which embeds the observed set into a latent space
partitioned into the receptive field location and the tuning function
properties. We show on simulated responses that the predictions and
reconstructed receptive fields from the Factorized Neural Process approach
ground truth with increasing number of trials. Critically, the latent
representation that summarizes the tuning function of a neuron is inferred in a
quick, single forward pass through the network. Finally, we validate this
approach on real neural data from visual cortex and find that the predictive
accuracy is comparable to -- and for small $K$ even greater than --
optimization based approaches, while being substantially faster. We believe
this novel deep learning systems identification framework will facilitate
better real-time integration of artificial neural network modeling into
neuroscience experiments.
</p>
<a href="http://arxiv.org/abs/2010.11810" target="_blank">arXiv:2010.11810</a> [<a href="http://arxiv.org/pdf/2010.11810" target="_blank">pdf</a>]

<h2>Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness and Accuracy for Free. (arXiv:2010.11828v1 [cs.CV])</h2>
<h3>Haotao Wang, Tianlong Chen, Shupeng Gui, Ting-Kuei Hu, Ji Liu, Zhangyang Wang</h3>
<p>Adversarial training and its many variants substantially improve deep network
robustness, yet at the cost of compromising standard accuracy. Moreover, the
training process is heavy and hence it becomes impractical to thoroughly
explore the trade-off between accuracy and robustness. This paper asks this new
question: how to quickly calibrate a trained model in-situ, to examine the
achievable trade-offs between its standard and robust accuracies, without
(re-)training it many times? Our proposed framework, Once-for-all Adversarial
Training (OAT), is built on an innovative model-conditional training framework,
with a controlling hyper-parameter as the input. The trained model could be
adjusted among different standard and robust accuracies "for free" at testing
time. As an important knob, we exploit dual batch normalization to separate
standard and adversarial feature statistics, so that they can be learned in one
model without degrading performance. We further extend OAT to a Once-for-all
Adversarial Training and Slimming (OATS) framework, that allows for the joint
trade-off among accuracy, robustness and runtime efficiency. Experiments show
that, without any re-training nor ensembling, OAT/OATS achieve similar or even
superior performance compared to dedicatedly trained models at various
configurations. Our codes and pretrained models are available at:
https://github.com/VITA-Group/Once-for-All-Adversarial-Training.
</p>
<a href="http://arxiv.org/abs/2010.11828" target="_blank">arXiv:2010.11828</a> [<a href="http://arxiv.org/pdf/2010.11828" target="_blank">pdf</a>]

<h2>Shape related constraints aware generation of Mechanical Designs through Deep Convolutional GAN. (arXiv:2010.11833v1 [cs.CE])</h2>
<h3>Waad Almasri, Dimitri Bettebghor, Fakhreddine Ababsa, Florence Danglade</h3>
<p>Mechanical product engineering often must comply with manufacturing or
geometric constraints related to the shaping process. Mechanical design hence
should rely on robust and fast tools to explore complex shapes, typically for
design for additive manufacturing (DfAM). Topology optimization is such a
powerful tool, yet integrating geometric constraints (shape-related) into it is
hard. In this work, we leverage machine learning capability to handle complex
geometric and spatial correlations to integrate into the mechanical design
process geometry-related constraints at the conceptual level. More precisely,
we explore the generative capabilities of recent Deep Learning architectures to
enhance mechanical designs, typically for additive manufacturing. In this work,
we build a generative Deep-Learning-based approach of topology optimization
integrating mechanical conditions in addition to one typical manufacturing
condition (the complexity of a design i.e. a geometrical condition). The
approach is a dual-discriminator GAN: a generator that takes as input the
mechanical and geometrical conditions and outputs a 2D structure and two
discriminators, one to ensure that the generated structure follows the
mechanical constraints and the other to assess the geometrical constraint. We
also explore the generation of designs with a non-uniform material distribution
and show promising results. Finally, We evaluate the generated designs with an
objective evaluation of all wanted aspects: the mechanical as well as the
geometrical constraints.
</p>
<a href="http://arxiv.org/abs/2010.11833" target="_blank">arXiv:2010.11833</a> [<a href="http://arxiv.org/pdf/2010.11833" target="_blank">pdf</a>]

<h2>Blind Video Temporal Consistency via Deep Video Prior. (arXiv:2010.11838v1 [cs.CV])</h2>
<h3>Chenyang Lei, Yazhou Xing, Qifeng Chen</h3>
<p>Applying image processing algorithms independently to each video frame often
leads to temporal inconsistency in the resulting video. To address this issue,
we present a novel and general approach for blind video temporal consistency.
Our method is only trained on a pair of original and processed videos directly
instead of a large dataset. Unlike most previous methods that enforce temporal
consistency with optical flow, we show that temporal consistency can be
achieved by training a convolutional network on a video with the Deep Video
Prior. Moreover, a carefully designed iteratively reweighted training strategy
is proposed to address the challenging multimodal inconsistency problem. We
demonstrate the effectiveness of our approach on 7 computer vision tasks on
videos. Extensive quantitative and perceptual experiments show that our
approach obtains superior performance than state-of-the-art methods on blind
video temporal consistency. Our source codes are publicly available at
github.com/ChenyangLEI/deep-video-prior.
</p>
<a href="http://arxiv.org/abs/2010.11838" target="_blank">arXiv:2010.11838</a> [<a href="http://arxiv.org/pdf/2010.11838" target="_blank">pdf</a>]

<h2>Does it Pay Off to Learn a New Skill? Revealing the Economic Benefits of Cross-Skilling. (arXiv:2010.11841v1 [econ.GN])</h2>
<h3>Fabian Stephany</h3>
<p>This work examines the economic benefits of learning a new skill from a
different domain: cross-skilling. To assess this, a network of skills from the
job profiles of 4,810 online freelancers is constructed. Based on this skill
network, relationships between 3,525 different skills are revealed and marginal
effects of learning a new skill can be calculated via workers' wages. The
results indicate that the added economic value of learning a new skill strongly
depends on the already existing skill bundle but that acquiring a skill from a
different domain is often beneficial. As technological and social
transformation is reshuffling jobs' task profiles at a fast pace, the findings
of this study help to clarify skill sets required for mastering new
technologies and designing individual training pathways. This can help to
increase employability and reduce labour market shortages.
</p>
<a href="http://arxiv.org/abs/2010.11841" target="_blank">arXiv:2010.11841</a> [<a href="http://arxiv.org/pdf/2010.11841" target="_blank">pdf</a>]

<h2>Spatio-temporal Features for Generalized Detection of Deepfake Videos. (arXiv:2010.11844v1 [cs.CV])</h2>
<h3>Ipek Ganiyusufoglu, L. Minh Ng&#xf4;, Nedko Savov, Sezer Karaoglu, Theo Gevers</h3>
<p>For deepfake detection, video-level detectors have not been explored as
extensively as image-level detectors, which do not exploit temporal data. In
this paper, we empirically show that existing approaches on image and sequence
classifiers generalize poorly to new manipulation techniques. To this end, we
propose spatio-temporal features, modeled by 3D CNNs, to extend the
generalization capabilities to detect new sorts of deepfake videos. We show
that spatial features learn distinct deepfake-method-specific attributes, while
spatio-temporal features capture shared attributes between deepfake methods. We
provide an in-depth analysis of how the sequential and spatio-temporal video
encoders are utilizing temporal information using DFDC dataset
arXiv:2006.07397. Thus, we unravel that our approach captures local
spatio-temporal relations and inconsistencies in the deepfake videos while
existing sequence encoders are indifferent to it. Through large scale
experiments conducted on the FaceForensics++ arXiv:1901.08971 and Deeper
Forensics arXiv:2001.03024 datasets, we show that our approach outperforms
existing methods in terms of generalization capabilities.
</p>
<a href="http://arxiv.org/abs/2010.11844" target="_blank">arXiv:2010.11844</a> [<a href="http://arxiv.org/pdf/2010.11844" target="_blank">pdf</a>]

<h2>Hawkes Process Classification through Discriminative Modeling of Text. (arXiv:2010.11851v1 [cs.SI])</h2>
<h3>Rohan Tondulkar, Manisha Dubey, P.K. Srijith, Michal Lukasik</h3>
<p>Social media has provided a platform for users to gather and share
information and stay updated with the news. Such networks also provide a
platform to users where they can engage in conversations. However, such
micro-blogging platforms like Twitter restricts the length of text. Due to
paucity of sufficient word occurrences in such posts, classification of this
information is a challenging task using standard tools of natural language
processing (NLP). Moreover, high complexity and dynamics of the posts in social
media makes text classification a challenging problem. However, considering
additional cues in the form of past labels and times associated with the post
can be potentially helpful for performing text classification in a better way.
To address this problem, we propose models based on the Hawkes process (HP)
which can naturally incorporate the temporal features and past labels along
with textual features for improving short text classification. In particular,
we propose a discriminative approach to model text in HP where the text
features parameterize the base intensity and/or the triggering kernel. Another
major contribution is to consider kernel to be a function of both time and
text, and further use a neural network to model the kernel. This enables
modelling and effectively learning the text along with the historical
influences for tweet classification. We demonstrate the advantages of the
proposed techniques on standard benchmarks for rumour stance classification.
</p>
<a href="http://arxiv.org/abs/2010.11851" target="_blank">arXiv:2010.11851</a> [<a href="http://arxiv.org/pdf/2010.11851" target="_blank">pdf</a>]

<h2>STAR: A Schema-Guided Dialog Dataset for Transfer Learning. (arXiv:2010.11853v1 [cs.CL])</h2>
<h3>Johannes E. M. Mosig, Shikib Mehri, Thomas Kober</h3>
<p>We present STAR, a schema-guided task-oriented dialog dataset consisting of
127,833 utterances and knowledge base queries across 5,820 task-oriented
dialogs in 13 domains that is especially designed to facilitate task and domain
transfer learning in task-oriented dialog. Furthermore, we propose a scalable
crowd-sourcing paradigm to collect arbitrarily large datasets of the same
quality as STAR. Moreover, we introduce novel schema-guided dialog models that
use an explicit description of the task(s) to generalize from known to unknown
tasks. We demonstrate the effectiveness of these models, particularly for
zero-shot generalization across tasks and domains.
</p>
<a href="http://arxiv.org/abs/2010.11853" target="_blank">arXiv:2010.11853</a> [<a href="http://arxiv.org/pdf/2010.11853" target="_blank">pdf</a>]

<h2>Detecting and Exorcising Statistical Demons from Language Models with Anti-Models of Negative Data. (arXiv:2010.11855v1 [cs.CL])</h2>
<h3>Michael L. Wick, Kate Silverstein, Jean-Baptiste Tristan, Adam Pocock, Mark Johnson</h3>
<p>It's been said that "Language Models are Unsupervised Multitask Learners."
Indeed, self-supervised language models trained on "positive" examples of
English text generalize in desirable ways to many natural language tasks. But
if such models can stray so far from an initial self-supervision objective, a
wayward model might generalize in undesirable ways too, say to nonsensical
"negative" examples of unnatural language. A key question in this work is: do
language models trained on (positive) training data also generalize to
(negative) test data? We use this question as a contrivance to assess the
extent to which language models learn undesirable properties of text, such as
n-grams, that might interfere with the learning of more desirable properties of
text, such as syntax. We find that within a model family, as the number of
parameters, training epochs, and data set size increase, so does a model's
ability to generalize to negative n-gram data, indicating standard
self-supervision generalizes too far. We propose a form of inductive bias that
attenuates such undesirable signals with negative data distributions
automatically learned from positive data. We apply the method to remove n-gram
signals from LSTMs and find that doing so causes them to favor syntactic
signals, as demonstrated by large error reductions (up to 46% on the hardest
cases) on a syntactic subject-verb agreement task.
</p>
<a href="http://arxiv.org/abs/2010.11855" target="_blank">arXiv:2010.11855</a> [<a href="http://arxiv.org/pdf/2010.11855" target="_blank">pdf</a>]

<h2>Perceptual Loss based Speech Denoising with an ensemble of Audio Pattern Recognition and Self-Supervised Models. (arXiv:2010.11860v1 [eess.AS])</h2>
<h3>Saurabh Kataria, Jes&#xfa;s Villalba, Najim Dehak</h3>
<p>Deep learning based speech denoising still suffers from the challenge of
improving perceptual quality of enhanced signals. We introduce a generalized
framework called Perceptual Ensemble Regularization Loss (PERL) built on the
idea of perceptual losses. Perceptual loss discourages distortion to certain
speech properties and we analyze it using six large-scale pre-trained models:
speaker classification, acoustic model, speaker embedding, emotion
classification, and two self-supervised speech encoders (PASE+, wav2vec 2.0).
We first build a strong baseline (w/o PERL) using Conformer Transformer
Networks on the popular enhancement benchmark called VCTK-DEMAND. Using
auxiliary models one at a time, we find acoustic event and self-supervised
model PASE+ to be most effective. Our best model (PERL-AE) only uses acoustic
event model (utilizing AudioSet) to outperform state-of-the-art methods on
major perceptual metrics. To explore if denoising can leverage full framework,
we use all networks but find that our seven-loss formulation suffers from the
challenges of Multi-Task Learning. Finally, we report a critical observation
that state-of-the-art Multi-Task weight learning methods cannot outperform hand
tuning, perhaps due to challenges of domain mismatch and weak complementarity
of losses.
</p>
<a href="http://arxiv.org/abs/2010.11860" target="_blank">arXiv:2010.11860</a> [<a href="http://arxiv.org/pdf/2010.11860" target="_blank">pdf</a>]

<h2>Position-Agnostic Multi-Microphone Speech Dereverberation. (arXiv:2010.11875v1 [eess.AS])</h2>
<h3>Yochai Yemini, Ethan Fetaya, Haggai Maron, Sharon Gannot</h3>
<p>Neural networks (NNs) have been widely applied in speech processing tasks,
and, in particular, those employing microphone arrays. Nevertheless, most of
the existing NN architectures can only deal with fixed and position-specific
microphone arrays. In this paper, we present an NN architecture that can cope
with microphone arrays on which no prior knowledge is presumed, and demonstrate
its applicability on the speech dereverberation problem. To this end, our
approach harnesses recent advances in the Deep Sets framework to design an
architecture that enhances the reverberant log-spectrum. We provide a setup for
training and testing such a network. Our experiments, using REVERB challenge
datasets, show that the proposed position-agnostic setup performs comparably
with the position-aware framework and sometimes slightly better, even with
fewer microphones. In addition, it substantially improves performance over a
single microphone architecture.
</p>
<a href="http://arxiv.org/abs/2010.11875" target="_blank">arXiv:2010.11875</a> [<a href="http://arxiv.org/pdf/2010.11875" target="_blank">pdf</a>]

<h2>Error Bounds of Imitating Policies and Environments. (arXiv:2010.11876v1 [cs.LG])</h2>
<h3>Tian Xu, Ziniu Li, Yang Yu</h3>
<p>Imitation learning trains a policy by mimicking expert demonstrations.
Various imitation methods were proposed and empirically evaluated, meanwhile,
their theoretical understanding needs further studies. In this paper, we
firstly analyze the value gap between the expert policy and imitated policies
by two imitation methods, behavioral cloning and generative adversarial
imitation. The results support that generative adversarial imitation can reduce
the compounding errors compared to behavioral cloning, and thus has a better
sample complexity. Noticed that by considering the environment transition model
as a dual agent, imitation learning can also be used to learn the environment
model. Therefore, based on the bounds of imitating policies, we further analyze
the performance of imitating environments. The results show that environment
models can be more effectively imitated by generative adversarial imitation
than behavioral cloning, suggesting a novel application of adversarial
imitation for model-based reinforcement learning. We hope these results could
inspire future advances in imitation learning and model-based reinforcement
learning.
</p>
<a href="http://arxiv.org/abs/2010.11876" target="_blank">arXiv:2010.11876</a> [<a href="http://arxiv.org/pdf/2010.11876" target="_blank">pdf</a>]

<h2>Learning Invariances in Neural Networks. (arXiv:2010.11882v1 [cs.LG])</h2>
<h3>Gregory Benton, Marc Finzi, Pavel Izmailov, Andrew Gordon Wilson</h3>
<p>Invariances to translations have imbued convolutional neural networks with
powerful generalization properties. However, we often do not know a priori what
invariances are present in the data, or to what extent a model should be
invariant to a given symmetry group. We show how to \emph{learn} invariances
and equivariances by parameterizing a distribution over augmentations and
optimizing the training loss simultaneously with respect to the network
parameters and augmentation parameters. With this simple procedure we can
recover the correct set and extent of invariances on image classification,
regression, segmentation, and molecular property prediction from a large space
of augmentations, on training data alone.
</p>
<a href="http://arxiv.org/abs/2010.11882" target="_blank">arXiv:2010.11882</a> [<a href="http://arxiv.org/pdf/2010.11882" target="_blank">pdf</a>]

<h2>AEGIS: A real-time multimodal augmented reality computer vision based system to assist facial expression recognition for individuals with autism spectrum disorder. (arXiv:2010.11884v1 [cs.CV])</h2>
<h3>James Ren Hou Lee, Alexander Wong</h3>
<p>The ability to interpret social cues comes naturally for most people, but for
those living with Autism Spectrum Disorder (ASD), some experience a deficiency
in this area. This paper presents the development of a multimodal augmented
reality (AR) system which combines the use of computer vision and deep
convolutional neural networks (CNN) in order to assist individuals with the
detection and interpretation of facial expressions in social settings. The
proposed system, which we call AEGIS (Augmented-reality Expression Guided
Interpretation System), is an assistive technology deployable on a variety of
user devices including tablets, smartphones, video conference systems, or
smartglasses, showcasing its extreme flexibility and wide range of use cases,
to allow integration into daily life with ease. Given a streaming video camera
source, each real-world frame is passed into AEGIS, processed for facial
bounding boxes, and then fed into our novel deep convolutional time windowed
neural network (TimeConvNet). We leverage both spatial and temporal information
in order to provide an accurate expression prediction, which is then converted
into its corresponding visualization and drawn on top of the original video
frame. The system runs in real-time, requires minimal set up and is simple to
use. With the use of AEGIS, we can assist individuals living with ASD to learn
to better identify expressions and thus improve their social experiences.
</p>
<a href="http://arxiv.org/abs/2010.11884" target="_blank">arXiv:2010.11884</a> [<a href="http://arxiv.org/pdf/2010.11884" target="_blank">pdf</a>]

<h2>VLSTM: Very Long Short-Term Memory Networks for High-Frequency Trading. (arXiv:1809.01506v3 [cs.LG] UPDATED)</h2>
<h3>Prakhar Ganesh, Puneet Rakheja</h3>
<p>Financial trading is at the forefront of time-series analysis, and has grown
hand-in-hand with it. The advent of electronic trading has allowed complex
machine learning solutions to enter the field of financial trading. Financial
markets have both long term and short term signals and thus a good predictive
model in financial trading should be able to incorporate them together. One of
the most sought after forms of electronic trading is high-frequency trading
(HFT), typically known for microsecond sensitive changes, which results in a
tremendous amount of data. LSTMs are one of the most capable variants of the
RNN family that can handle long-term dependencies, but even they are not
equipped to handle such long sequences of the order of thousands of data points
like in HFT. We propose very-long short term memory networks, or VLSTMs, to
deal with such extreme length sequences. We explore the importance of VLSTMs in
the context of HFT. We compare our model on publicly available dataset and got
a 3.14\% increase in F1-score over the existing state-of-the-art time-series
forecasting models. We also show that our model has great parallelization
potential, which is essential for practical purposes when trading on such
markets.
</p>
<a href="http://arxiv.org/abs/1809.01506" target="_blank">arXiv:1809.01506</a> [<a href="http://arxiv.org/pdf/1809.01506" target="_blank">pdf</a>]

<h2>End-to-End Classification of Reverberant Rooms using DNNs. (arXiv:1812.09324v4 [eess.AS] UPDATED)</h2>
<h3>Constantinos Papayiannis, Christine Evers, Patrick A. Naylor</h3>
<p>Reverberation is present in our workplaces, our homes, concert halls and
theatres. This paper investigates how deep learning can use the effect of
reverberation on speech to classify a recording in terms of the room in which
it was recorded. Existing approaches in the literature rely on domain expertise
to manually select acoustic parameters as inputs to classifiers. Estimation of
these parameters from reverberant speech is adversely affected by estimation
errors, impacting the classification accuracy. In order to overcome the
limitations of previously proposed methods, this paper shows how DNNs can
perform the classification by operating directly on reverberant speech spectra
and a CRNN with an attention-mechanism is proposed for the task. The
relationship is investigated between the reverberant speech representations
learned by the DNNs and acoustic parameters. For evaluation, AIRs are used from
the ACE-challenge dataset that were measured in 7 real rooms. The
classification accuracy of the CRNN classifier in the experiments is 78% when
using 5 hours of training data and 90% when using 10 hours.
</p>
<a href="http://arxiv.org/abs/1812.09324" target="_blank">arXiv:1812.09324</a> [<a href="http://arxiv.org/pdf/1812.09324" target="_blank">pdf</a>]

<h2>A Survey on Deep Learning-based Non-Invasive Brain Signals:Recent Advances and New Frontiers. (arXiv:1905.04149v5 [cs.HC] UPDATED)</h2>
<h3>Xiang Zhang, Lina Yao, Xianzhi Wang, Jessica Monaghan, David Mcalpine, Yu Zhang</h3>
<p>Brain-Computer Interface (BCI) bridges the human's neural world and the outer
physical world by decoding individuals' brain signals into commands
recognizable by computer devices. Deep learning has lifted the performance of
brain-computer interface systems significantly in recent years. In this
article, we systematically investigate brain signal types for BCI and related
deep learning concepts for brain signal analysis. We then present a
comprehensive survey of deep learning techniques used for BCI, by summarizing
over 230 contributions most published in the past five years. Finally, we
discuss the applied areas, opening challenges, and future directions for deep
learning-based BCI.
</p>
<a href="http://arxiv.org/abs/1905.04149" target="_blank">arXiv:1905.04149</a> [<a href="http://arxiv.org/pdf/1905.04149" target="_blank">pdf</a>]

<h2>Body Shape Privacy in Images: Understanding Privacy and Preventing Automatic Shape Extraction. (arXiv:1905.11503v3 [cs.CV] UPDATED)</h2>
<h3>Hosnieh Sattar, Katharina Krombholz, Gerard Pons-Moll, Mario Fritz</h3>
<p>Modern approaches to pose and body shape estimation have recently achieved
strong performance even under challenging real-world conditions. Even from a
single image of a clothed person, a realistic looking body shape can be
inferred that captures a users' weight group and body shape type well. This
opens up a whole spectrum of applications -- in particular in fashion -- where
virtual try-on and recommendation systems can make use of these new and
automatized cues. However, a realistic depiction of the undressed body is
regarded highly private and therefore might not be consented by most people.
Hence, we ask if the automatic extraction of such information can be
effectively evaded. While adversarial perturbations have been shown to be
effective for manipulating the output of machine learning models -- in
particular, end-to-end deep learning approaches -- state of the art shape
estimation methods are composed of multiple stages. We perform the first
investigation of different strategies that can be used to effectively
manipulate the automatic shape estimation while preserving the overall
appearance of the original image.
</p>
<a href="http://arxiv.org/abs/1905.11503" target="_blank">arXiv:1905.11503</a> [<a href="http://arxiv.org/pdf/1905.11503" target="_blank">pdf</a>]

<h2>Neural Markov Logic Networks. (arXiv:1905.13462v3 [cs.LG] UPDATED)</h2>
<h3>Giuseppe Marra, Ond&#x159;ej Ku&#x17e;elka</h3>
<p>We introduce neural Markov logic networks (NMLNs), a statistical relational
learning system that borrows ideas from Markov logic. Like Markov logic
networks (MLNs), NMLNs are an exponential-family model for modelling
distributions over possible worlds, but unlike MLNs, they do not rely on
explicitly specified first-order logic rules. Instead, NMLNs learn an implicit
representation of such rules as a neural network that acts as a potential
function on fragments of the relational structure. Similarly to many neural
symbolic methods, NMLNs can exploit embeddings of constants but, unlike them,
NMLNs work well also in their absence. This is extremely important for
predicting in settings other than the transductive one. We showcase the
potential of NMLNs on knowledge-base completion, triple classification and on
generation of molecular (graph) data.
</p>
<a href="http://arxiv.org/abs/1905.13462" target="_blank">arXiv:1905.13462</a> [<a href="http://arxiv.org/pdf/1905.13462" target="_blank">pdf</a>]

<h2>Mutual exclusivity as a challenge for deep neural networks. (arXiv:1906.10197v3 [cs.CL] UPDATED)</h2>
<h3>Kanishk Gandhi, Brenden M. Lake</h3>
<p>Strong inductive biases allow children to learn in fast and adaptable ways.
Children use the mutual exclusivity (ME) bias to help disambiguate how words
map to referents, assuming that if an object has one label then it does not
need another. In this paper, we investigate whether or not standard neural
architectures have an ME bias, demonstrating that they lack this learning
assumption. Moreover, we show that their inductive biases are poorly matched to
lifelong learning formulations of classification and translation. We
demonstrate that there is a compelling case for designing neural networks that
reason by mutual exclusivity, which remains an open challenge.
</p>
<a href="http://arxiv.org/abs/1906.10197" target="_blank">arXiv:1906.10197</a> [<a href="http://arxiv.org/pdf/1906.10197" target="_blank">pdf</a>]

<h2>A Baseline for Few-Shot Image Classification. (arXiv:1909.02729v5 [cs.LG] UPDATED)</h2>
<h3>Guneet S. Dhillon, Pratik Chaudhari, Avinash Ravichandran, Stefano Soatto</h3>
<p>Fine-tuning a deep network trained with the standard cross-entropy loss is a
strong baseline for few-shot learning. When fine-tuned transductively, this
outperforms the current state-of-the-art on standard datasets such as
Mini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100 with the same
hyper-parameters. The simplicity of this approach enables us to demonstrate the
first few-shot learning results on the ImageNet-21k dataset. We find that using
a large number of meta-training classes results in high few-shot accuracies
even for a large number of few-shot classes. We do not advocate our approach as
the solution for few-shot learning, but simply use the results to highlight
limitations of current benchmarks and few-shot protocols. We perform extensive
studies on benchmark datasets to propose a metric that quantifies the
"hardness" of a few-shot episode. This metric can be used to report the
performance of few-shot algorithms in a more systematic way.
</p>
<a href="http://arxiv.org/abs/1909.02729" target="_blank">arXiv:1909.02729</a> [<a href="http://arxiv.org/pdf/1909.02729" target="_blank">pdf</a>]

<h2>Effective training of deep convolutional neural networks for hyperspectral image classification through artificial labeling. (arXiv:1909.05507v2 [cs.NE] UPDATED)</h2>
<h3>Wojciech Masarczyk, Przemys&#x142;aw G&#x142;omb, Bartosz Grabowski, Mateusz Ostaszewski</h3>
<p>Hyperspectral imaging is a rich source of data, allowing for multitude of
effective applications. However, such imaging remains challenging because of
large data dimension and, typically, small pool of available training examples.
While deep learning approaches have been shown to be successful in providing
effective classification solutions, especially for high dimensional problems,
unfortunately they work best with a lot of labelled examples available. To
alleviate the second requirement for a particular dataset the transfer learning
approach can be used: first the network is pre-trained on some dataset with
large amount of training labels available, then the actual dataset is used to
fine-tune the network. This strategy is not straightforward to apply with
hyperspectral images, as it is often the case that only one particular image of
some type or characteristic is available. In this paper, we propose and
investigate a simple and effective strategy of transfer learning that uses
unsupervised pre-training step without label information. This approach can be
applied to many of the hyperspectral classification problems. Performed
experiments show that it is very effective at improving the classification
accuracy without being restricted to a particular image type or neural network
architecture. The experiments were carried out on several deep neural network
architectures and various sizes of labeled training sets. The greatest
improvement in overall accuracy on the Indian Pines and Pavia University
datasets is over 21 and 13 percentage points, respectively. An additional
advantage of the proposed approach is the unsupervised nature of the
pre-training step, which can be done immediately after image acquisition,
without the need of the potentially costly expert's time.
</p>
<a href="http://arxiv.org/abs/1909.05507" target="_blank">arXiv:1909.05507</a> [<a href="http://arxiv.org/pdf/1909.05507" target="_blank">pdf</a>]

<h2>Modular Meta-Learning with Shrinkage. (arXiv:1909.05557v4 [cs.LG] UPDATED)</h2>
<h3>Yutian Chen, Abram L. Friesen, Feryal Behbahani, Arnaud Doucet, David Budden, Matthew W. Hoffman, Nando de Freitas</h3>
<p>Many real-world problems, including multi-speaker text-to-speech synthesis,
can greatly benefit from the ability to meta-learn large models with only a few
task-specific components. Updating only these task-specific modules then allows
the model to be adapted to low-data tasks for as many steps as necessary
without risking overfitting. Unfortunately, existing meta-learning methods
either do not scale to long adaptation or else rely on handcrafted
task-specific architectures. Here, we propose a meta-learning approach that
obviates the need for this often sub-optimal hand-selection. In particular, we
develop general techniques based on Bayesian shrinkage to automatically
discover and learn both task-specific and general reusable modules.
Empirically, we demonstrate that our method discovers a small set of meaningful
task-specific modules and outperforms existing meta-learning approaches in
domains like few-shot text-to-speech that have little task data and long
adaptation horizons. We also show that existing meta-learning methods including
MAML, iMAML, and Reptile emerge as special cases of our method.
</p>
<a href="http://arxiv.org/abs/1909.05557" target="_blank">arXiv:1909.05557</a> [<a href="http://arxiv.org/pdf/1909.05557" target="_blank">pdf</a>]

<h2>Selective Network Discovery via Deep Reinforcement Learning on Embedded Spaces. (arXiv:1909.07294v2 [cs.LG] UPDATED)</h2>
<h3>Peter Morales, Rajmonda Sulo Caceres, Tina Eliassi-Rad</h3>
<p>Complex networks are often either too large for full exploration, partially
accessible, or partially observed. Downstream learning tasks on these
incomplete networks can produce low quality results. In addition, reducing the
incompleteness of the network can be costly and nontrivial. As a result,
network discovery algorithms optimized for specific downstream learning tasks
given resource collection constraints are of great interest. In this paper, we
formulate the task-specific network discovery problem in an incomplete network
setting as a sequential decision making problem. Our downstream task is
selective harvesting, the optimal collection of vertices with a particular
attribute. We propose a framework, called Network Actor Critic (NAC), which
learns a policy and notion of future reward in an offline setting via a deep
reinforcement learning algorithm. The NAC paradigm utilizes a task-specific
network embedding to reduce the state space complexity. A detailed comparative
analysis of popular network embeddings is presented with respect to their role
in supporting offline planning. Furthermore, a quantitative study is presented
on several synthetic and real benchmarks using NAC and several baselines. We
show that offline models of reward and network discovery policies lead to
significantly improved performance when compared to competitive online
discovery algorithms. Finally, we outline learning regimes where planning is
critical in addressing sparse and changing reward signals.
</p>
<a href="http://arxiv.org/abs/1909.07294" target="_blank">arXiv:1909.07294</a> [<a href="http://arxiv.org/pdf/1909.07294" target="_blank">pdf</a>]

<h2>Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory. (arXiv:1910.02029v3 [cs.CV] UPDATED)</h2>
<h3>Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool</h3>
<p>The role of robots in society keeps expanding, bringing with it the necessity
of interacting and communicating with humans. In order to keep such interaction
intuitive, we provide automatic wayfinding based on verbal navigational
instructions. Our first contribution is the creation of a large-scale dataset
with verbal navigation instructions. To this end, we have developed an
interactive visual navigation environment based on Google Street View; we
further design an annotation method to highlight mined anchor landmarks and
local directions between them in order to help annotators formulate typical,
human references to those. The annotation task was crowdsourced on the AMT
platform, to construct a new Talk2Nav dataset with $10,714$ routes. Our second
contribution is a new learning method. Inspired by spatial cognition research
on the mental conceptualization of navigational instructions, we introduce a
soft dual attention mechanism defined over the segmented language instructions
to jointly extract two partial instructions -- one for matching the next
upcoming visual landmark and the other for matching the local directions to the
next landmark. On the similar lines, we also introduce spatial memory scheme to
encode the local directional transitions. Our work takes advantage of the
advance in two lines of research: mental formalization of verbal navigational
instructions and training neural network agents for automatic way finding.
Extensive experiments show that our method significantly outperforms previous
navigation methods. For demo video, dataset and code, please refer to our
project page: https://www.trace.ethz.ch/publications/2019/talk2nav/index.html
</p>
<a href="http://arxiv.org/abs/1910.02029" target="_blank">arXiv:1910.02029</a> [<a href="http://arxiv.org/pdf/1910.02029" target="_blank">pdf</a>]

<h2>A mathematical theory of cooperative communication. (arXiv:1910.02822v2 [cs.LG] UPDATED)</h2>
<h3>Pei Wang, Junqi Wang, Pushpi Paranamana, Patrick Shafto</h3>
<p>Cooperative communication plays a central role in theories of human
cognition, language, development, culture, and human-robot interaction. Prior
models of cooperative communication are algorithmic in nature and do not shed
light on why cooperation may yield effective belief transmission and what
limitations may arise due to differences between beliefs of agents. Through a
connection to the theory of optimal transport, we establishing a mathematical
framework for cooperative communication. We derive prior models as special
cases, statistical interpretations of belief transfer plans, and proofs of
robustness and instability. Computational simulations support and elaborate our
theoretical results, and demonstrate fit to human behavior. The results show
that cooperative communication provably enables effective, robust belief
transmission which is required to explain feats of human learning and improve
human-machine interaction.
</p>
<a href="http://arxiv.org/abs/1910.02822" target="_blank">arXiv:1910.02822</a> [<a href="http://arxiv.org/pdf/1910.02822" target="_blank">pdf</a>]

<h2>OffWorld Gym: open-access physical robotics environment for real-world reinforcement learning benchmark and research. (arXiv:1910.08639v3 [cs.LG] UPDATED)</h2>
<h3>Ashish Kumar, Toby Buckley, John B. Lanier, Qiaozhi Wang, Alicia Kavelaars, Ilya Kuzovkin</h3>
<p>Success stories of applied machine learning can be traced back to the
datasets and environments that were put forward as challenges for the
community. The challenge that the community sets as a benchmark is usually the
challenge that the community eventually solves. The ultimate challenge of
reinforcement learning research is to train real agents to operate in the real
environment, but until now there has not been a common real-world RL benchmark.
In this work, we present a prototype real-world environment from OffWorld Gym
-- a collection of real-world environments for reinforcement learning in
robotics with free public remote access. Close integration into existing
ecosystem allows the community to start using OffWorld Gym without any prior
experience in robotics and takes away the burden of managing a physical
robotics system, abstracting it under a familiar API. We introduce a navigation
task, where a robot has to reach a visual beacon on an uneven terrain using
only the camera input and provide baseline results in both the real environment
and the simulated replica. To start training, visit https://gym.offworld.ai
</p>
<a href="http://arxiv.org/abs/1910.08639" target="_blank">arXiv:1910.08639</a> [<a href="http://arxiv.org/pdf/1910.08639" target="_blank">pdf</a>]

<h2>BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning. (arXiv:1910.12179v3 [cs.LG] UPDATED)</h2>
<h3>Xinyue Chen, Zijian Zhou, Zheng Wang, Che Wang, Yanqiu Wu, Keith Ross</h3>
<p>There has recently been a surge in research in batch Deep Reinforcement
Learning (DRL), which aims for learning a high-performing policy from a given
dataset without additional interactions with the environment. We propose a new
algorithm, Best-Action Imitation Learning (BAIL), which strives for both
simplicity and performance. BAIL learns a V function, uses the V function to
select actions it believes to be high-performing, and then uses those actions
to train a policy network using imitation learning. For the MuJoCo benchmark,
we provide a comprehensive experimental study of BAIL, comparing its
performance to four other batch Q-learning and imitation-learning schemes for a
large variety of batch datasets. Our experiments show that BAIL's performance
is much higher than the other schemes, and is also computationally much faster
than the batch Q-learning schemes.
</p>
<a href="http://arxiv.org/abs/1910.12179" target="_blank">arXiv:1910.12179</a> [<a href="http://arxiv.org/pdf/1910.12179" target="_blank">pdf</a>]

<h2>Understanding Static Code Warnings: an Incremental AI Approach. (arXiv:1911.01387v3 [cs.SE] UPDATED)</h2>
<h3>Xueqi Yang, Zhe Yu, Junjie Wang, Tim Menzies</h3>
<p>Knowledge-based systems reason over some knowledge base. Hence, an important
issue for such systems is how to acquire the knowledge needed for their
inference. This paper assesses active learning methods for acquiring knowledge
for "static code warnings".

Static code analysis is a widely-used method for detecting bugs and security
vulnerabilities in software systems. As software becomes more complex, analysis
tools also report lists of increasingly complex warnings that developers need
to address on a daily basis. Such static code analysis tools are usually
over-cautious; i.e. they often offer many warnings about spurious issues.
Previous research work shows that about 35% to 91% of warnings reported as bugs
by SA tools are actually unactionable (i.e., warnings that would not be acted
on by developers because they are falsely suggested as bugs).

Experienced developers know which errors are important and which can be
safely ignored. How can we capture that experience? This paper reports on an
incremental AI tool that watches humans reading false alarm reports. Using an
incremental support vector machine mechanism, this AI tool can quickly learn to
distinguish spurious false alarms from more serious matters that deserve
further attention.

In this work, nine open-source projects are employed to evaluate our proposed
model on the features extracted by previous researchers and identify the
actionable warnings in a priority order given by our algorithm. We observe that
our model can identify over 90% of actionable warnings when our methods tell
humans to ignore 70 to 80% of the warnings.
</p>
<a href="http://arxiv.org/abs/1911.01387" target="_blank">arXiv:1911.01387</a> [<a href="http://arxiv.org/pdf/1911.01387" target="_blank">pdf</a>]

<h2>Fourier Spectrum Discrepancies in Deep Network Generated Images. (arXiv:1911.06465v3 [eess.IV] UPDATED)</h2>
<h3>Tarik Dzanic, Karan Shah, Freddie Witherden</h3>
<p>Advancements in deep generative models such as generative adversarial
networks and variational autoencoders have resulted in the ability to generate
realistic images that are visually indistinguishable from real images, which
raises concerns about their potential malicious usage. In this paper, we
present an analysis of the high-frequency Fourier modes of real and deep
network generated images and show that deep network generated images share an
observable, systematic shortcoming in replicating the attributes of these
high-frequency modes. Using this, we propose a detection method based on the
frequency spectrum of the images which is able to achieve an accuracy of up to
99.2% in classifying real and deep network generated images from various GAN
and VAE architectures on a dataset of 5000 images with as few as 8 training
examples. Furthermore, we show the impact of image transformations such as
compression, cropping, and resolution reduction on the classification accuracy
and suggest a method for modifying the high-frequency attributes of deep
network generated images to mimic real images.
</p>
<a href="http://arxiv.org/abs/1911.06465" target="_blank">arXiv:1911.06465</a> [<a href="http://arxiv.org/pdf/1911.06465" target="_blank">pdf</a>]

<h2>Glyph: Fast and Accurately Training Deep Neural Networks on Encrypted Data. (arXiv:1911.07101v3 [cs.LG] UPDATED)</h2>
<h3>Qian Lou, Bo Feng, Geoffrey C. Fox, Lei Jiang</h3>
<p>Big data is one of the cornerstones to enabling and training deep neural
networks (DNNs). Because of the lack of expertise, to gain benefits from their
data, average users have to rely on and upload their private data to big data
companies they may not trust. Due to the compliance, legal, or privacy
constraints, most users are willing to contribute only their encrypted data,
and lack interests or resources to join the training of DNNs in cloud. To train
a DNN on encrypted data in a completely non-interactive way, a recent work
proposes a fully homomorphic encryption (FHE)-based technique implementing all
activations in the neural network by \textit{Brakerski-Gentry-Vaikuntanathan
(BGV)}-based lookup tables. However, such inefficient lookup-table-based
activations significantly prolong the training latency of privacy-preserving
DNNs.

In this paper, we propose, Glyph, a FHE-based scheme to fast and accurately
train DNNs on encrypted data by switching between TFHE (Fast Fully Homomorphic
Encryption over the Torus) and BGV cryptosystems. Glyph uses
logic-operation-friendly TFHE to implement nonlinear activations, while adopts
vectorial-arithmetic-friendly BGV to perform multiply-accumulation (MAC)
operations. Glyph further applies transfer learning on the training of DNNs to
improve the test accuracy and reduce the number of MAC operations between
ciphertext and ciphertext in convolutional layers. Our experimental results
show Glyph obtains the state-of-the-art test accuracy, but reduces the training
latency by $99\%$ over the prior FHE-based technique on various encrypted
datasets.
</p>
<a href="http://arxiv.org/abs/1911.07101" target="_blank">arXiv:1911.07101</a> [<a href="http://arxiv.org/pdf/1911.07101" target="_blank">pdf</a>]

<h2>ISP4ML: Understanding the Role of Image Signal Processing in Efficient Deep Learning Vision Systems. (arXiv:1911.07954v3 [eess.IV] UPDATED)</h2>
<h3>Patrick Hansen, Alexey Vilkin, Yury Khrustalev, James Imber, David Hanwell, Matthew Mattina, Paul N. Whatmough</h3>
<p>Convolutional neural networks (CNNs) are now predominant components in a
variety of computer vision (CV) systems. These systems typically include an
image signal processor (ISP), even though the ISP is traditionally designed to
produce images that look appealing to humans. In CV systems, it is not clear
what the role of the ISP is, or if it is even required at all for accurate
prediction. In this work, we investigate the efficacy of the ISP in CNN
classification tasks, and outline the system-level trade-offs between
prediction accuracy and computational cost. To do so, we build software models
of a configurable ISP and an imaging sensor in order to train CNNs on ImageNet
with a range of different ISP settings and functionality. Results on ImageNet
show that an ISP improves accuracy by 4.6%-12.2% on MobileNet architectures of
different widths. Results using ResNets demonstrate that these trends also
generalize to deeper networks. An ablation study of the various processing
stages in a typical ISP reveals that the tone mapper is the most significant
stage when operating on high dynamic range (HDR) images, by providing 5.8%
average accuracy improvement alone. Overall, the ISP benefits system efficiency
because the memory and computational costs of the ISP is minimal compared to
the cost of using a larger CNN to achieve the same accuracy.
</p>
<a href="http://arxiv.org/abs/1911.07954" target="_blank">arXiv:1911.07954</a> [<a href="http://arxiv.org/pdf/1911.07954" target="_blank">pdf</a>]

<h2>Convolutional Neural Network and decision support in medical imaging: case study of the recognition of blood cell subtypes. (arXiv:1911.08010v2 [eess.IV] UPDATED)</h2>
<h3>Daouda Diouf, Djibril Seck, Mountaga Diop, Abdoulye Ba</h3>
<p>Identifying and characterizing the patient's blood samples is indispensable
in diagnostics of malignance suspicious. A painstaking and sometimes subjective
task is used in laboratories to manually classify white blood cells. Neural
mathematical methods as deep learnings can be very useful in the automated
recognition of blood cells. This study uses a particular type of deep learning
i.e., convolutional neural networks (CNNs or ConvNets) for image recognition of
the four (4) blood cell types (neutrophil, eosinophil, lymphocyte and monocyte)
and to enable it to tag them employing a dataset of blood cells with labels for
the corresponding cell types. The elements of the database are the input of our
CNN and they allowed us to create learning models for the image
recognition/classification of the blood cells. We evaluated the recognition
performance and outputs learned by the networks in order to implement a neural
image recognition model capable of distinguishing polynuclear cells (neutrophil
and eosinophil) from those of mononuclear cells (lymphocyte and monocyte). The
validation accuracy is 97.77%.
</p>
<a href="http://arxiv.org/abs/1911.08010" target="_blank">arXiv:1911.08010</a> [<a href="http://arxiv.org/pdf/1911.08010" target="_blank">pdf</a>]

<h2>Attention Deep Model with Multi-Scale Deep Supervision for Person Re-Identification. (arXiv:1911.10335v3 [cs.CV] UPDATED)</h2>
<h3>Di Wu, Chao Wang, Yong Wu, De-Shuang Huang</h3>
<p>In recent years, person re-identification (PReID) has become a hot topic in
computer vision duo to it is an important part in intelligent surveillance.
Many state-of-the-art PReID methods are attention-based or multi-scale feature
learning deep models. However, introducing attention mechanism may lead to some
important feature information losing issue. Besides, most of the multi-scale
models embedding the multi-scale feature learning block into the feature
extraction deep network, which reduces the efficiency of inference network. To
address these issue, in this study, we introduce an attention deep architecture
with multi-scale deep supervision for PReID. Technically, we contribute a
reverse attention block to complement the attention block, and a novel
multi-scale layer with deep supervision operator for training the backbone
network. The proposed block and operator are only used for training, and
discard in test phase. Experiments have been performed on Market-1501,
DukeMTMC-reID and CUHK03 datasets. All the experiment results show that the
proposed model significantly outperforms the other competitive state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/1911.10335" target="_blank">arXiv:1911.10335</a> [<a href="http://arxiv.org/pdf/1911.10335" target="_blank">pdf</a>]

<h2>HRFA: High-Resolution Feature-based Attack. (arXiv:2001.07631v2 [cs.LG] UPDATED)</h2>
<h3>Zhixing Ye, Sizhe Chen, Peidong Zhang, Chengjin Sun, Xiaolin Huang</h3>
<p>Adversarial attacks have long been developed for revealing the vulnerability
of Deep Neural Networks (DNNs) by adding imperceptible perturbations to the
input. Most methods generate perturbations like normal noise, which is not
interpretable and without semantic meaning. In this paper, we propose
High-Resolution Feature-based Attack (HRFA), yielding authentic adversarial
examples with up to $1024 \times 1024$ resolution. HRFA exerts attack by
modifying the latent feature representation of the image, i.e., the gradients
back propagate not only through the victim DNN, but also through the generative
model that maps the feature space to the image space. In this way, HRFA
generates adversarial examples that are in high-resolution, realistic,
noise-free, and hence is able to evade several denoising-based defenses. In the
experiment, the effectiveness of HRFA is validated by attacking the object
classification and face verification tasks with BigGAN and StyleGAN,
respectively. The advantages of HRFA are verified from the high quality, high
authenticity, and high attack success rate faced with defenses.
</p>
<a href="http://arxiv.org/abs/2001.07631" target="_blank">arXiv:2001.07631</a> [<a href="http://arxiv.org/pdf/2001.07631" target="_blank">pdf</a>]

<h2>Extreme Algorithm Selection With Dyadic Feature Representation. (arXiv:2001.10741v2 [cs.LG] UPDATED)</h2>
<h3>Alexander Tornede, Marcel Wever, Eyke H&#xfc;llermeier</h3>
<p>Algorithm selection (AS) deals with selecting an algorithm from a fixed set
of candidate algorithms most suitable for a specific instance of an algorithmic
problem, e.g., choosing solvers for SAT problems. Benchmark suites for AS
usually comprise candidate sets consisting of at most tens of algorithms,
whereas in combined algorithm selection and hyperparameter optimization
problems the number of candidates becomes intractable, impeding to learn
effective meta-models and thus requiring costly online performance evaluations.
Therefore, here we propose the setting of extreme algorithm selection (XAS)
where we consider fixed sets of thousands of candidate algorithms, facilitating
meta learning. We assess the applicability of state-of-the-art AS techniques to
the XAS setting and propose approaches leveraging a dyadic feature
representation in which both problem instances and algorithms are described. We
find the latter to improve significantly over the current state of the art in
various metrics.
</p>
<a href="http://arxiv.org/abs/2001.10741" target="_blank">arXiv:2001.10741</a> [<a href="http://arxiv.org/pdf/2001.10741" target="_blank">pdf</a>]

<h2>Inverse Learning of Symmetries. (arXiv:2002.02782v2 [cs.LG] UPDATED)</h2>
<h3>Mario Wieser, Sonali Parbhoo, Aleksander Wieczorek, Volker Roth</h3>
<p>Symmetry transformations induce invariances which are frequently described
with deep latent variable models. In many complex domains, such as the chemical
space, invariances can be observed, yet the corresponding symmetry
transformation cannot be formulated analytically. We propose to learn the
symmetry transformation with a model consisting of two latent subspaces, where
the first subspace captures the target and the second subspace the remaining
invariant information. Our approach is based on the deep information bottleneck
in combination with a continuous mutual information regulariser. Unlike
previous methods, we focus on the challenging task of minimising mutual
information in continuous domains. To this end, we base the calculation of
mutual information on correlation matrices in combination with a bijective
variable transformation. Extensive experiments demonstrate that our model
outperforms state-of-the-art methods on artificial and molecular datasets.
</p>
<a href="http://arxiv.org/abs/2002.02782" target="_blank">arXiv:2002.02782</a> [<a href="http://arxiv.org/pdf/2002.02782" target="_blank">pdf</a>]

<h2>Deep reconstruction of strange attractors from time series. (arXiv:2002.05909v3 [cs.LG] UPDATED)</h2>
<h3>William Gilpin</h3>
<p>Experimental measurements of physical systems often have a limited number of
independent channels, causing essential dynamical variables to remain
unobserved. However, many popular methods for unsupervised inference of latent
dynamics from experimental data implicitly assume that the measurements have
higher intrinsic dimensionality than the underlying system---making coordinate
identification a dimensionality reduction problem. Here, we study the opposite
limit, in which hidden governing coordinates must be inferred from only a
low-dimensional time series of measurements. Inspired by classical analysis
techniques for partial observations of chaotic attractors, we introduce a
general embedding technique for univariate and multivariate time series,
consisting of an autoencoder trained with a novel latent-space loss function.
We show that our technique reconstructs the strange attractors of synthetic and
real-world systems better than existing techniques, and that it creates
consistent, predictive representations of even stochastic systems. We conclude
by using our technique to discover dynamical attractors in diverse systems such
as patient electrocardiograms, household electricity usage, neural spiking, and
eruptions of the Old Faithful geyser---demonstrating diverse applications of
our technique for exploratory data analysis.
</p>
<a href="http://arxiv.org/abs/2002.05909" target="_blank">arXiv:2002.05909</a> [<a href="http://arxiv.org/pdf/2002.05909" target="_blank">pdf</a>]

<h2>Decision-Making with Auto-Encoding Variational Bayes. (arXiv:2002.07217v3 [stat.ML] UPDATED)</h2>
<h3>Romain Lopez, Pierre Boyeau, Nir Yosef, Michael I. Jordan, Jeffrey Regier</h3>
<p>To make decisions based on a model fit with auto-encoding variational Bayes
(AEVB), practitioners often let the variational distribution serve as a
surrogate for the posterior distribution. This approach yields biased estimates
of the expected risk, and therefore leads to poor decisions for two reasons.
First, the model fit with AEVB may not equal the underlying data distribution.
Second, the variational distribution may not equal the posterior distribution
under the fitted model. We explore how fitting the variational distribution
based on several objective functions other than the ELBO, while continuing to
fit the generative model based on the ELBO, affects the quality of downstream
decisions. For the probabilistic principal component analysis model, we
investigate how importance sampling error, as well as the bias of the model
parameter estimates, varies across several approximate posteriors when used as
proposal distributions. Our theoretical results suggest that a posterior
approximation distinct from the variational distribution should be used for
making decisions. Motivated by these theoretical results, we propose learning
several approximate proposals for the best model and combining them using
multiple importance sampling for decision-making. In addition to toy examples,
we present a full-fledged case study of single-cell RNA sequencing. In this
challenging instance of multiple hypothesis testing, our proposed approach
surpasses the current state of the art.
</p>
<a href="http://arxiv.org/abs/2002.07217" target="_blank">arXiv:2002.07217</a> [<a href="http://arxiv.org/pdf/2002.07217" target="_blank">pdf</a>]

<h2>Simple and Scalable Sparse k-means Clustering via Feature Ranking. (arXiv:2002.08541v2 [stat.ML] UPDATED)</h2>
<h3>Zhiyue Zhang, Kenneth Lange, Jason Xu</h3>
<p>Clustering, a fundamental activity in unsupervised learning, is notoriously
difficult when the feature space is high-dimensional. Fortunately, in many
realistic scenarios, only a handful of features are relevant in distinguishing
clusters. This has motivated the development of sparse clustering techniques
that typically rely on k-means within outer algorithms of high computational
complexity. Current techniques also require careful tuning of shrinkage
parameters, further limiting their scalability. In this paper, we propose a
novel framework for sparse k-means clustering that is intuitive, simple to
implement, and competitive with state-of-the-art algorithms. We show that our
algorithm enjoys consistency and convergence guarantees. Our core method
readily generalizes to several task-specific algorithms such as clustering on
subsets of attributes and in partially observed data settings. We showcase
these contributions thoroughly via simulated experiments and real data
benchmarks, including a case study on protein expression in trisomic mice.
</p>
<a href="http://arxiv.org/abs/2002.08541" target="_blank">arXiv:2002.08541</a> [<a href="http://arxiv.org/pdf/2002.08541" target="_blank">pdf</a>]

<h2>Lipschitz standardization for multivariate learning. (arXiv:2002.11369v3 [cs.LG] UPDATED)</h2>
<h3>Adri&#xe1;n Javaloy, Isabel Valera</h3>
<p>Probabilistic learning is increasingly being tackled as an optimization
problem, with gradient-based approaches as predominant methods. When modelling
multivariate likelihoods, a usual but undesirable outcome is that the learned
model fits only a subset of the observed variables, overlooking the rest. In
this work, we study this problem through the lens of multitask learning (MTL),
where similar effects have been broadly studied. While MTL solutions do not
directly apply in the probabilistic setting (as they cannot handle the
likelihood constraints) we show that similar ideas may be leveraged during data
preprocessing. First, we show that data standardization often helps under
common continuous likelihoods, but it is not enough in the general case,
specially under mixed continuous and discrete likelihood models. In order for
balance multivariate learning, we then propose a novel data preprocessing,
Lipschitz standardization, which balances the local Lipschitz smoothness across
variables. Our experiments on real-world datasets show that Lipschitz
standardization leads to more accurate multivariate models than the ones
learned using existing data preprocessing techniques. The models and datasets
employed in the experiments can be found in
https://github.com/adrianjav/lipschitz-standardization.
</p>
<a href="http://arxiv.org/abs/2002.11369" target="_blank">arXiv:2002.11369</a> [<a href="http://arxiv.org/pdf/2002.11369" target="_blank">pdf</a>]

<h2>CinemAirSim: A Camera-Realistic Robotics Simulator for Cinematographic Purposes. (arXiv:2003.07664v2 [cs.RO] UPDATED)</h2>
<h3>Pablo Pueyo, Eric Cristofalo, Eduardo Montijano, Mac Schwager</h3>
<p>Drones and Unmanned Aerial Vehicles (UAV's) are becoming increasingly popular
in the film and entertainment industries in part because of their
maneuverability and the dynamic shots and perspectives they enable. While there
exists methods for controlling the position and orientation of the drones for
visibility, other artistic elements of the filming process, such as focal blur
and light control, remain unexplored in the robotics community. The lack of
cinemetographic robotics solutions is partly due to the cost associated with
the cameras and devices used in the filming industry, but also because
state-of-the-art photo-realistic robotics simulators only utilize a full
in-focus pinhole camera model which does incorporate these desired artistic
attributes. To overcome this, the main contribution of this work is to endow
the well-known drone simulator, AirSim, with a cinematic camera as well as
extended its API to control all of its parameters in real time, including
various filming lenses and common cinematographic properties. In this paper, we
detail the implementation of our AirSim modification, CinemAirSim, present
examples that illustrate the potential of the new tool, and highlight the new
research opportunities that the use of cinematic cameras can bring to research
in robotics and control. https://github.com/ppueyor/CinematicAirSim
</p>
<a href="http://arxiv.org/abs/2003.07664" target="_blank">arXiv:2003.07664</a> [<a href="http://arxiv.org/pdf/2003.07664" target="_blank">pdf</a>]

<h2>Visual link retrieval and knowledge discovery in painting datasets. (arXiv:2003.08476v2 [cs.CV] UPDATED)</h2>
<h3>Giovanna Castellano, Eufemia Lella, Gennaro Vessio</h3>
<p>Visual arts are of inestimable importance for the cultural, historic and
economic growth of our society. One of the building blocks of most analysis in
visual arts is to find similarity relationships among paintings of different
artists and painting schools. To help art historians better understand visual
arts, this paper presents a framework for visual link retrieval and knowledge
discovery in digital painting datasets. Visual link retrieval is accomplished
by using a deep convolutional neural network to perform feature extraction and
a fully unsupervised nearest neighbor mechanism to retrieve links among
digitized paintings. Historical knowledge discovery is achieved by performing a
graph analysis that makes it possible to study influences among artists. An
experimental evaluation on a database collecting paintings by very popular
artists shows the effectiveness of the method. The unsupervised strategy makes
the method interesting especially in cases where metadata are scarce,
unavailable or difficult to collect.
</p>
<a href="http://arxiv.org/abs/2003.08476" target="_blank">arXiv:2003.08476</a> [<a href="http://arxiv.org/pdf/2003.08476" target="_blank">pdf</a>]

<h2>Deep convolutional embedding for digitized painting clustering. (arXiv:2003.08597v2 [cs.CV] UPDATED)</h2>
<h3>Giovanna Castellano, Gennaro Vessio</h3>
<p>Clustering artworks is difficult for several reasons. On the one hand,
recognizing meaningful patterns in accordance with domain knowledge and visual
perception is extremely difficult. On the other hand, applying traditional
clustering and feature reduction techniques to the highly dimensional pixel
space can be ineffective. To address these issues, we propose to use a deep
convolutional embedding model for digitized painting clustering, in which the
task of mapping the raw input data to an abstract, latent space is jointly
optimized with the task of finding a set of cluster centroids in this latent
feature space. Quantitative and qualitative experimental results show the
effectiveness of the proposed method. The model is also capable of
outperforming other state-of-the-art deep clustering approaches to the same
problem. The proposed method can be useful for several art-related tasks, in
particular visual link retrieval and historical knowledge discovery in painting
datasets.
</p>
<a href="http://arxiv.org/abs/2003.08597" target="_blank">arXiv:2003.08597</a> [<a href="http://arxiv.org/pdf/2003.08597" target="_blank">pdf</a>]

<h2>PLOP: Probabilistic poLynomial Objects trajectory Planning for autonomous driving. (arXiv:2003.08744v3 [cs.CV] UPDATED)</h2>
<h3>Thibault Buhet, Emilie Wirbel, Andrei Bursuc, Xavier Perrotton</h3>
<p>To navigate safely in urban environments, an autonomous vehicle (ego vehicle)
must understand and anticipate its surroundings, in particular the behavior and
intents of other road users (neighbors). Most of the times, multiple decision
choices are acceptable for all road users (e.g., turn right or left, or
different ways of avoiding an obstacle), leading to a highly uncertain and
multi-modal decision space. We focus here on predicting multiple feasible
future trajectories for both ego vehicle and neighbors through a probabilistic
framework. We rely on a conditional imitation learning algorithm, conditioned
by a navigation command for the ego vehicle (e.g., "turn right"). Our model
processes ego vehicle front-facing camera images and bird-eye view grid,
computed from Lidar point clouds, with detections of past and present objects,
in order to generate multiple trajectories for both ego vehicle and its
neighbors. Our approach is computationally efficient and relies only on
on-board sensors. We evaluate our method offline on the publicly available
dataset nuScenes, achieving state-of-the-art performance, investigate the
impact of our architecture choices on online simulated experiments and show
preliminary insights for real vehicle control
</p>
<a href="http://arxiv.org/abs/2003.08744" target="_blank">arXiv:2003.08744</a> [<a href="http://arxiv.org/pdf/2003.08744" target="_blank">pdf</a>]

<h2>SOLOv2: Dynamic, Faster and Stronger. (arXiv:2003.10152v2 [cs.CV] UPDATED)</h2>
<h3>Xinlong Wang, Rufeng Zhang, Tao Kong, Lei Li, Chunhua Shen</h3>
<p>In this work, we aim at building a simple, direct, and fast instance
segmentation framework with strong performance. We follow the principle of the
SOLO method of Wang et al. "SOLO: segmenting objects by locations".
Importantly, we take one step further by dynamically learning the mask head of
the object segmenter such that the mask head is conditioned on the location.
Specifically, the mask branch is decoupled into a mask kernel branch and mask
feature branch, which are responsible for learning the convolution kernel and
the convolved features respectively. Moreover, we propose Matrix NMS (non
maximum suppression) to significantly reduce the inference time overhead due to
NMS of masks. Our Matrix NMS performs NMS with parallel matrix operations in
one shot, and yields better results. We demonstrate a simple direct instance
segmentation system, outperforming a few state-of-the-art methods in both speed
and accuracy. A light-weight version of SOLOv2 executes at 31.3 FPS and yields
37.1% AP. Moreover, our state-of-the-art results in object detection (from our
mask byproduct) and panoptic segmentation show the potential to serve as a new
strong baseline for many instance-level recognition tasks besides instance
segmentation. Code is available at: https://git.io/AdelaiDet
</p>
<a href="http://arxiv.org/abs/2003.10152" target="_blank">arXiv:2003.10152</a> [<a href="http://arxiv.org/pdf/2003.10152" target="_blank">pdf</a>]

<h2>Dark Experience for General Continual Learning: a Strong, Simple Baseline. (arXiv:2004.07211v2 [stat.ML] UPDATED)</h2>
<h3>Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, Simone Calderara</h3>
<p>Continual Learning has inspired a plethora of approaches and evaluation
settings; however, the majority of them overlooks the properties of a practical
scenario, where the data stream cannot be shaped as a sequence of tasks and
offline training is not viable. We work towards General Continual Learning
(GCL), where task boundaries blur and the domain and class distributions shift
either gradually or suddenly. We address it through mixing rehearsal with
knowledge distillation and regularization; our simple baseline, Dark Experience
Replay, matches the network's logits sampled throughout the optimization
trajectory, thus promoting consistency with its past. By conducting an
extensive analysis on both standard benchmarks and a novel GCL evaluation
setting (MNIST-360), we show that such a seemingly simple baseline outperforms
consolidated approaches and leverages limited resources. We further explore the
generalization capabilities of our objective, showing its regularization being
beneficial beyond mere performance.
</p>
<a href="http://arxiv.org/abs/2004.07211" target="_blank">arXiv:2004.07211</a> [<a href="http://arxiv.org/pdf/2004.07211" target="_blank">pdf</a>]

<h2>Causal Modeling with Stochastic Confounders. (arXiv:2004.11497v3 [stat.ML] UPDATED)</h2>
<h3>Thanh Vinh Vo, Pengfei Wei, Wicher Bergsma, Tze-Yun Leong</h3>
<p>This work extends causal inference with stochastic confounders. We propose a
new approach to variational estimation for causal inference based on a
representer theorem with a random input space. We estimate causal effects
involving latent confounders that may be interdependent and time-varying from
sequential, repeated measurements in an observational study. Our approach
extends current work that assumes independent, non-temporal latent confounders,
with potentially biased estimators. We introduce a simple yet elegant algorithm
without parametric specification on model components. Our method avoids the
need for expensive and careful parameterization in deploying complex models,
such as deep neural networks, for causal inference in existing approaches. We
demonstrate the effectiveness of our approach on various benchmark temporal
datasets.
</p>
<a href="http://arxiv.org/abs/2004.11497" target="_blank">arXiv:2004.11497</a> [<a href="http://arxiv.org/pdf/2004.11497" target="_blank">pdf</a>]

<h2>How to Learn a Useful Critic? Model-based Action-Gradient-Estimator Policy Optimization. (arXiv:2004.14309v2 [cs.AI] UPDATED)</h2>
<h3>Pierluca D&#x27;Oro, Wojciech Ja&#x15b;kowski</h3>
<p>Deterministic-policy actor-critic algorithms for continuous control improve
the actor by plugging its actions into the critic and ascending the
action-value gradient, which is obtained by chaining the actor's Jacobian
matrix with the gradient of the critic with respect to input actions. However,
instead of gradients, the critic is, typically, only trained to accurately
predict expected returns, which, on their own, are useless for policy
optimization. In this paper, we propose MAGE, a model-based actor-critic
algorithm, grounded in the theory of policy gradients, which explicitly learns
the action-value gradient. MAGE backpropagates through the learned dynamics to
compute gradient targets in temporal difference learning, leading to a critic
tailored for policy improvement. On a set of MuJoCo continuous-control tasks,
we demonstrate the efficiency of the algorithm in comparison to model-free and
model-based state-of-the-art baselines.
</p>
<a href="http://arxiv.org/abs/2004.14309" target="_blank">arXiv:2004.14309</a> [<a href="http://arxiv.org/pdf/2004.14309" target="_blank">pdf</a>]

<h2>Open Graph Benchmark: Datasets for Machine Learning on Graphs. (arXiv:2005.00687v5 [cs.LG] UPDATED)</h2>
<h3>Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, Jure Leskovec</h3>
<p>We present the Open Graph Benchmark (OGB), a diverse set of challenging and
realistic benchmark datasets to facilitate scalable, robust, and reproducible
graph machine learning (ML) research. OGB datasets are large-scale, encompass
multiple important graph ML tasks, and cover a diverse range of domains,
ranging from social and information networks to biological networks, molecular
graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a
unified evaluation protocol using meaningful application-specific data splits
and evaluation metrics. In addition to building the datasets, we also perform
extensive benchmark experiments for each dataset. Our experiments suggest that
OGB datasets present significant challenges of scalability to large-scale
graphs and out-of-distribution generalization under realistic data splits,
indicating fruitful opportunities for future research. Finally, OGB provides an
automated end-to-end graph ML pipeline that simplifies and standardizes the
process of graph data loading, experimental setup, and model evaluation. OGB
will be regularly updated and welcomes inputs from the community. OGB datasets
as well as data loaders, evaluation scripts, baseline code, and leaderboards
are publicly available at https://ogb.stanford.edu .
</p>
<a href="http://arxiv.org/abs/2005.00687" target="_blank">arXiv:2005.00687</a> [<a href="http://arxiv.org/pdf/2005.00687" target="_blank">pdf</a>]

<h2>SEPAR: Towards Regulating Future of Work Multi-Platform Crowdworking Environments with Privacy Guarantees. (arXiv:2005.01038v2 [cs.DB] UPDATED)</h2>
<h3>Mohammad Javad Amiri, Joris Dugu&#xe9;p&#xe9;roux, Tristan Allard, Divyakant Agrawal, Amr El Abbadi</h3>
<p>Crowdworking platforms provide the opportunity for diverse workers to execute
tasks for different requesters. The popularity of the "gig" economy has given
rise to independent platforms that provide competing and complementary
services. Workers as well as requesters with specific tasks may need to work
for or avail from the services of multiple platforms resulting in the rise of
multi-platform crowdworking systems. Recently, there has been increasing
interest by governmental, legal and social institutions to enforce regulations,
such as minimal and maximal work hours, on crowdworking platforms. Platforms
within multi-platform crowdworking systems, therefore, need to collaborate to
enforce cross-platform regulations. While collaborating to enforce global
regulations requires the transparent sharing of information about tasks and
their participants, the privacy of all participants needs to be preserved. In
this paper, we propose an overall vision exploring the regulation, privacy, and
architecture dimensions for the future of work multi-platform crowdworking
environments. We then present SEPAR, a multi-platform crowdworking system that
enforces a large sub-space of practical global regulations on a set of
distributed independent platforms in a privacy-preserving manner. SEPAR,
enforces privacy using lightweight and anonymous tokens, while transparency is
achieved using fault-tolerant blockchains shared across multiple platforms. The
privacy guarantees of SEPAR against covert adversaries are formalized and
thoroughly demonstrated, while the experiments reveal the efficiency of SEPAR
in terms of performance and scalability.
</p>
<a href="http://arxiv.org/abs/2005.01038" target="_blank">arXiv:2005.01038</a> [<a href="http://arxiv.org/pdf/2005.01038" target="_blank">pdf</a>]

<h2>Selecting Data Augmentation for Simulating Interventions. (arXiv:2005.01856v3 [stat.ML] UPDATED)</h2>
<h3>Maximilian Ilse, Jakub M. Tomczak, Patrick Forr&#xe9;</h3>
<p>Machine learning models trained with purely observational data and the
principle of empirical risk minimization (Vapnik, 1992) can fail to generalize
to unseen domains. In this paper, we focus on the case where the problem arises
through spurious correlation between the observed domains and the actual task
labels. We find that many domain generalization methods do not explicitly take
this spurious correlation into account. Instead, especially in more
application-oriented research areas like medical imaging or robotics, data
augmentation techniques that are based on heuristics are used to learn domain
invariant features. To bridge the gap between theory and practice, we develop a
causal perspective on the problem of domain generalization. We argue that
causal concepts can be used to explain the success of data augmentation by
describing how they can weaken the spurious correlation between the observed
domains and the task labels. We demonstrate that data augmentation can serve as
a tool for simulating interventional data. Lastly, but unsurprisingly, we show
that augmenting data improperly can cause a significant decrease in
performance.
</p>
<a href="http://arxiv.org/abs/2005.01856" target="_blank">arXiv:2005.01856</a> [<a href="http://arxiv.org/pdf/2005.01856" target="_blank">pdf</a>]

<h2>Dual-Signal Transformation LSTM Network for Real-Time Noise Suppression. (arXiv:2005.07551v2 [eess.AS] UPDATED)</h2>
<h3>Nils L. Westhausen, Bernd T. Meyer</h3>
<p>This paper introduces a dual-signal transformation LSTM network (DTLN) for
real-time speech enhancement as part of the Deep Noise Suppression Challenge
(DNS-Challenge). This approach combines a short-time Fourier transform (STFT)
and a learned analysis and synthesis basis in a stacked-network approach with
less than one million parameters. The model was trained on 500 h of noisy
speech provided by the challenge organizers. The network is capable of
real-time processing (one frame in, one frame out) and reaches competitive
results. Combining these two types of signal transformations enables the DTLN
to robustly extract information from magnitude spectra and incorporate phase
information from the learned feature basis. The method shows state-of-the-art
performance and outperforms the DNS-Challenge baseline by 0.24 points absolute
in terms of the mean opinion score (MOS).
</p>
<a href="http://arxiv.org/abs/2005.07551" target="_blank">arXiv:2005.07551</a> [<a href="http://arxiv.org/pdf/2005.07551" target="_blank">pdf</a>]

<h2>Iterative Network for Image Super-Resolution. (arXiv:2005.09964v2 [eess.IV] UPDATED)</h2>
<h3>Yuqing Liu, Shiqi Wang, Jian Zhang, Shanshe Wang, Siwei Ma, Wen Gao</h3>
<p>Single image super-resolution (SISR), as a traditional ill-conditioned
inverse problem, has been greatly revitalized by the recent development of
convolutional neural networks (CNN). These CNN-based methods generally map a
low-resolution image to its corresponding high-resolution version with
sophisticated network structures and loss functions, showing impressive
performances. This paper proposes a substantially different approach relying on
the iterative optimization on HR space with an iterative super-resolution
network (ISRN). We first analyze the observation model of image SR problem,
inspiring a feasible solution by mimicking and fusing each iteration in a more
general and efficient manner. Considering the drawbacks of batch normalization,
we propose a feature normalization (FNorm) method to regulate the features in
network. Furthermore, a novel block with F-Norm is developed to improve the
network representation, termed as FNB. Residual-in-residual structure is
proposed to form a very deep network, which groups FNBs with a long skip
connection for better information delivery and stabling the training phase.
Extensive experimental results on testing benchmarks with bicubic (BI)
degradation show our ISRN can not only recover more structural information, but
also achieve competitive or better PSNR/SSIM results with much fewer parameters
compared to other works. Besides BI, we simulate the real-world degradation
with blur-downscale (BD) and downscalenoise (DN). ISRN and its extension ISRN+
both achieve better performance than others with BD and DN degradation models.
</p>
<a href="http://arxiv.org/abs/2005.09964" target="_blank">arXiv:2005.09964</a> [<a href="http://arxiv.org/pdf/2005.09964" target="_blank">pdf</a>]

<h2>Beyond the Mean-Field: Structured Deep Gaussian Processes Improve the Predictive Uncertainties. (arXiv:2005.11110v2 [stat.ML] UPDATED)</h2>
<h3>Jakob Lindinger, David Reeb, Christoph Lippert, Barbara Rakitsch</h3>
<p>Deep Gaussian Processes learn probabilistic data representations for
supervised learning by cascading multiple Gaussian Processes. While this model
family promises flexible predictive distributions, exact inference is not
tractable. Approximate inference techniques trade off the ability to closely
resemble the posterior distribution against speed of convergence and
computational efficiency. We propose a novel Gaussian variational family that
allows for retaining covariances between latent processes while achieving fast
convergence by marginalising out all global latent variables. After providing a
proof of how this marginalisation can be done for general covariances, we
restrict them to the ones we empirically found to be most important in order to
also achieve computational efficiency. We provide an efficient implementation
of our new approach and apply it to several benchmark datasets. It yields
excellent results and strikes a better balance between accuracy and calibrated
uncertainty estimates than its state-of-the-art alternatives.
</p>
<a href="http://arxiv.org/abs/2005.11110" target="_blank">arXiv:2005.11110</a> [<a href="http://arxiv.org/pdf/2005.11110" target="_blank">pdf</a>]

<h2>Noise Robust TTS for Low Resource Speakers using Pre-trained Model and Speech Enhancement. (arXiv:2005.12531v2 [eess.AS] UPDATED)</h2>
<h3>Dongyang Dai, Li Chen, Yuping Wang, Mu Wang, Rui Xia, Xuchen Song, Zhiyong Wu, Yuxuan Wang</h3>
<p>With the popularity of deep neural network, speech synthesis task has
achieved significant improvements based on the end-to-end encoder-decoder
framework in the recent days. More and more applications relying on speech
synthesis technology have been widely used in our daily life. Robust speech
synthesis model depends on high quality and customized data which needs lots of
collecting efforts. It is worth investigating how to take advantage of
low-quality and low resource voice data which can be easily obtained from the
Internet for usage of synthesizing personalized voice. In this paper, the
proposed end-to-end speech synthesis model uses both speaker embedding and
noise representation as conditional inputs to model speaker and noise
information respectively. Firstly, the speech synthesis model is pre-trained
with both multi-speaker clean data and noisy augmented data; then the
pre-trained model is adapted on noisy low-resource new speaker data; finally,
by setting the clean speech condition, the model can synthesize the new
speaker's clean voice. Experimental results show that the speech generated by
the proposed approach has better subjective evaluation results than the method
directly fine-tuning pre-trained multi-speaker speech synthesis model with
denoised new speaker data.
</p>
<a href="http://arxiv.org/abs/2005.12531" target="_blank">arXiv:2005.12531</a> [<a href="http://arxiv.org/pdf/2005.12531" target="_blank">pdf</a>]

<h2>Machine learning in spectral domain. (arXiv:2005.14436v2 [cs.LG] UPDATED)</h2>
<h3>Lorenzo Giambagli, Lorenzo Buffoni, Timoteo Carletti, Walter Nocentini, Duccio Fanelli</h3>
<p>Deep neural networks are usually trained in the space of the nodes, by
adjusting the weights of existing links via suitable optimization protocols. We
here propose a radically new approach which anchors the learning process to
reciprocal space. Specifically, the training acts on the spectral domain and
seeks to modify the eigenvalues and eigenvectors of transfer operators in
direct space. The proposed method is ductile and can be tailored to return
either linear or non-linear classifiers. Adjusting the eigenvalues, when
freezing the eigenvectors entries, yields performances which are superior to
those attained with standard methods {\it restricted} to a operate with an
identical number of free parameters. Tuning the eigenvalues correspond in fact
to performing a global training of the neural network, a procedure which
promotes (resp. inhibits) collective modes on which an effective information
processing relies. This is at variance with the usual approach to learning
which implements instead a local modulation of the weights associated to
pairwise links. Interestingly, spectral learning limited to the eigenvalues
returns a distribution of the predicted weights which is close to that obtained
when training the neural network in direct space, with no restrictions on the
parameters to be tuned. Based on the above, it is surmised that spectral
learning bound to the eigenvalues could be also employed for pre-training of
deep neural networks, in conjunction with conventional machine-learning
schemes. Changing the eigenvectors to a different non-orthogonal basis alters
the topology of the network in direct space and thus allows to export the
spectral learning strategy to other frameworks, as e.g. reservoir computing.
</p>
<a href="http://arxiv.org/abs/2005.14436" target="_blank">arXiv:2005.14436</a> [<a href="http://arxiv.org/pdf/2005.14436" target="_blank">pdf</a>]

<h2>Coresets via Bilevel Optimization for Continual Learning and Streaming. (arXiv:2006.03875v2 [cs.LG] UPDATED)</h2>
<h3>Zal&#xe1;n Borsos, Mojm&#xed;r Mutn&#xfd;, Andreas Krause</h3>
<p>Coresets are small data summaries that are sufficient for model training.
They can be maintained online, enabling efficient handling of large data
streams under resource constraints. However, existing constructions are limited
to simple models such as k-means and logistic regression. In this work, we
propose a novel coreset construction via cardinality-constrained bilevel
optimization. We show how our framework can efficiently generate coresets for
deep neural networks, and demonstrate its empirical benefits in continual
learning and in streaming settings.
</p>
<a href="http://arxiv.org/abs/2006.03875" target="_blank">arXiv:2006.03875</a> [<a href="http://arxiv.org/pdf/2006.03875" target="_blank">pdf</a>]

<h2>Deep active inference agents using Monte-Carlo methods. (arXiv:2006.04176v2 [q-bio.NC] UPDATED)</h2>
<h3>Zafeirios Fountas, Noor Sajid, Pedro A.M. Mediano, Karl Friston</h3>
<p>Active inference is a Bayesian framework for understanding biological
intelligence. The underlying theory brings together perception and action under
one single imperative: minimizing free energy. However, despite its theoretical
utility in explaining intelligence, computational implementations have been
restricted to low-dimensional and idealized situations. In this paper, we
present a neural architecture for building deep active inference agents
operating in complex, continuous state-spaces using multiple forms of
Monte-Carlo (MC) sampling. For this, we introduce a number of techniques, novel
to active inference. These include: i) selecting free-energy-optimal policies
via MC tree search, ii) approximating this optimal policy distribution via a
feed-forward `habitual' network, iii) predicting future parameter belief
updates using MC dropouts and, finally, iv) optimizing state transition
precision (a high-end form of attention). Our approach enables agents to learn
environmental dynamics efficiently, while maintaining task performance, in
relation to reward-based counterparts. We illustrate this in a new toy
environment, based on the dSprites data-set, and demonstrate that active
inference agents automatically create disentangled representations that are apt
for modeling state transitions. In a more complex Animal-AI environment, our
agents (using the same neural architecture) are able to simulate future state
transitions and actions (i.e., plan), to evince reward-directed navigation -
despite temporary suspension of visual input. These results show that deep
active inference - equipped with MC methods - provides a flexible framework to
develop biologically-inspired intelligent agents, with applications in both
machine learning and cognitive science.
</p>
<a href="http://arxiv.org/abs/2006.04176" target="_blank">arXiv:2006.04176</a> [<a href="http://arxiv.org/pdf/2006.04176" target="_blank">pdf</a>]

<h2>Speaker Diarization as a Fully Online Learning Problem in MiniVox. (arXiv:2006.04376v3 [cs.LG] UPDATED)</h2>
<h3>Baihan Lin, Xinxin Zhang</h3>
<p>We proposed a novel machine learning framework to conduct real-time
multi-speaker diarization and recognition without prior registration and
pretraining in a fully online learning setting. Our contributions are two-fold.
First, we proposed a new benchmark to evaluate the rarely studied fully online
speaker diarization problem. We built upon existing datasets of real world
utterances to automatically curate MiniVox, an experimental environment which
generates infinite configurations of continuous multi-speaker speech stream.
Second, we considered the practical problem of online learning with
episodically revealed rewards and introduced a solution based on
semi-supervised and self-supervised learning methods. Additionally, we provided
a workable web-based recognition system which interactively handles the cold
start problem of new user's addition by transferring representations of old
arms to new ones with an extendable contextual bandit. We demonstrated that our
proposed method obtained robust performance in the online MiniVox framework.
</p>
<a href="http://arxiv.org/abs/2006.04376" target="_blank">arXiv:2006.04376</a> [<a href="http://arxiv.org/pdf/2006.04376" target="_blank">pdf</a>]

<h2>mEBAL: A Multimodal Database for Eye Blink Detection and Attention Level Estimation. (arXiv:2006.05327v2 [cs.CV] UPDATED)</h2>
<h3>Roberto Daza, Aythami Morales, Julian Fierrez, Ruben Tolosana</h3>
<p>This work presents mEBAL, a multimodal database for eye blink detection and
attention level estimation. The eye blink frequency is related to the cognitive
activity and automatic detectors of eye blinks have been proposed for many
tasks including attention level estimation, analysis of neuro-degenerative
diseases, deception recognition, drive fatigue detection, or face
anti-spoofing. However, most existing databases and algorithms in this area are
limited to experiments involving only a few hundred samples and individual
sensors like face cameras. The proposed mEBAL improves previous databases in
terms of acquisition sensors and samples. In particular, three different
sensors are simultaneously considered: Near Infrared (NIR) and RGB cameras to
capture the face gestures and an Electroencephalography (EEG) band to capture
the cognitive activity of the user and blinking events. Regarding the size of
mEBAL, it comprises 6,000 samples and the corresponding attention level from 38
different students while conducting a number of e-learning tasks of varying
difficulty. In addition to presenting mEBAL, we also include preliminary
experiments on: i) eye blink detection using Convolutional Neural Networks
(CNN) with the facial images, and ii) attention level estimation of the
students based on their eye blink frequency.
</p>
<a href="http://arxiv.org/abs/2006.05327" target="_blank">arXiv:2006.05327</a> [<a href="http://arxiv.org/pdf/2006.05327" target="_blank">pdf</a>]

<h2>Self-Supervised Relational Reasoning for Representation Learning. (arXiv:2006.05849v2 [cs.LG] UPDATED)</h2>
<h3>Massimiliano Patacchiola, Amos Storkey</h3>
<p>In self-supervised learning, a system is tasked with achieving a surrogate
objective by defining alternative targets on a set of unlabeled data. The aim
is to build useful representations that can be used in downstream tasks,
without costly manual annotation. In this work, we propose a novel
self-supervised formulation of relational reasoning that allows a learner to
bootstrap a signal from information implicit in unlabeled data. Training a
relation head to discriminate how entities relate to themselves
(intra-reasoning) and other entities (inter-reasoning), results in rich and
descriptive representations in the underlying neural network backbone, which
can be used in downstream tasks such as classification and image retrieval. We
evaluate the proposed method following a rigorous experimental procedure, using
standard datasets, protocols, and backbones. Self-supervised relational
reasoning outperforms the best competitor in all conditions by an average 14%
in accuracy, and the most recent state-of-the-art model by 3%. We link the
effectiveness of the method to the maximization of a Bernoulli log-likelihood,
which can be considered as a proxy for maximizing the mutual information,
resulting in a more efficient objective with respect to the commonly used
contrastive losses.
</p>
<a href="http://arxiv.org/abs/2006.05849" target="_blank">arXiv:2006.05849</a> [<a href="http://arxiv.org/pdf/2006.05849" target="_blank">pdf</a>]

<h2>COVID-19-CT-CXR: a freely accessible and weakly labeled chest X-ray and CT image collection on COVID-19 from biomedical literature. (arXiv:2006.06177v2 [eess.IV] UPDATED)</h2>
<h3>Yifan Peng, Yu-Xing Tang, Sungwon Lee, Yingying Zhu, Ronald M. Summers, Zhiyong Lu</h3>
<p>The latest threat to global health is the COVID-19 outbreak. Although there
exist large datasets of chest X-rays (CXR) and computed tomography (CT) scans,
few COVID-19 image collections are currently available due to patient privacy.
At the same time, there is a rapid growth of COVID-19-relevant articles in the
biomedical literature. Here, we present COVID-19-CT-CXR, a public database of
COVID-19 CXR and CT images, which are automatically extracted from
COVID-19-relevant articles from the PubMed Central Open Access (PMC-OA) Subset.
We extracted figures, associated captions, and relevant figure descriptions in
the article and separated compound figures into subfigures. We also designed a
deep-learning model to distinguish them from other figure types and to classify
them accordingly. The final database includes 1,327 CT and 263 CXR images (as
of May 9, 2020) with their relevant text. To demonstrate the utility of
COVID-19-CT-CXR, we conducted four case studies. (1) We show that
COVID-19-CT-CXR, when used as additional training data, is able to contribute
to improved DL performance for the classification of COVID-19 and non-COVID-19
CT. (2) We collected CT images of influenza and trained a DL baseline to
distinguish a diagnosis of COVID-19, influenza, or normal or other types of
diseases on CT. (3) We trained an unsupervised one-class classifier from
non-COVID-19 CXR and performed anomaly detection to detect COVID-19 CXR. (4)
From text-mined captions and figure descriptions, we compared clinical symptoms
and clinical findings of COVID-19 vs. those of influenza to demonstrate the
disease differences in the scientific publications. We believe that our work is
complementary to existing resources and hope that it will contribute to medical
image analysis of the COVID-19 pandemic. The dataset, code, and DL models are
publicly available at https://github.com/ncbi-nlp/COVID-19-CT-CXR.
</p>
<a href="http://arxiv.org/abs/2006.06177" target="_blank">arXiv:2006.06177</a> [<a href="http://arxiv.org/pdf/2006.06177" target="_blank">pdf</a>]

<h2>Smoothed Geometry for Robust Attribution. (arXiv:2006.06643v2 [cs.LG] UPDATED)</h2>
<h3>Zifan Wang, Haofan Wang, Shakul Ramkumar, Matt Fredrikson, Piotr Mardziel, Anupam Datta</h3>
<p>Feature attributions are a popular tool for explaining the behavior of Deep
Neural Networks (DNNs), but have recently been shown to be vulnerable to
attacks that produce divergent explanations for nearby inputs. This lack of
robustness is especially problematic in high-stakes applications where
adversarially-manipulated explanations could impair safety and trustworthiness.
Building on a geometric understanding of these attacks presented in recent
work, we identify Lipschitz continuity conditions on models' gradient that lead
to robust gradient-based attributions, and observe that smoothness may also be
related to the ability of an attack to transfer across multiple attribution
methods. To mitigate these attacks in practice, we propose an inexpensive
regularization method that promotes these conditions in DNNs, as well as a
stochastic smoothing technique that does not require re-training. Our
experiments on a range of image models demonstrate that both of these
mitigations consistently improve attribution robustness, and confirm the role
that smooth geometry plays in these attacks on real, large-scale models.
</p>
<a href="http://arxiv.org/abs/2006.06643" target="_blank">arXiv:2006.06643</a> [<a href="http://arxiv.org/pdf/2006.06643" target="_blank">pdf</a>]

<h2>Ensemble Distillation for Robust Model Fusion in Federated Learning. (arXiv:2006.07242v2 [cs.LG] UPDATED)</h2>
<h3>Tao Lin, Lingjing Kong, Sebastian U. Stich, Martin Jaggi</h3>
<p>Federated Learning (FL) is a machine learning setting where many devices
collaboratively train a machine learning model while keeping the training data
decentralized. In most of the current training schemes the central model is
refined by averaging the parameters of the server model and the updated
parameters from the client side. However, directly averaging model parameters
is only possible if all models have the same structure and size, which could be
a restrictive constraint in many scenarios.

In this work we investigate more powerful and more flexible aggregation
schemes for FL. Specifically, we propose ensemble distillation for model
fusion, i.e. training the central classifier through unlabeled data on the
outputs of the models from the clients. This knowledge distillation technique
mitigates privacy risk and cost to the same extent as the baseline FL
algorithms, but allows flexible aggregation over heterogeneous client models
that can differ e.g. in size, numerical precision or structure. We show in
extensive empirical experiments on various CV/NLP datasets (CIFAR-10/100,
ImageNet, AG News, SST2) and settings (heterogeneous models/data) that the
server model can be trained much faster, requiring fewer communication rounds
than any existing FL technique so far.
</p>
<a href="http://arxiv.org/abs/2006.07242" target="_blank">arXiv:2006.07242</a> [<a href="http://arxiv.org/pdf/2006.07242" target="_blank">pdf</a>]

<h2>Residual Force Control for Agile Human Behavior Imitation and Extended Motion Synthesis. (arXiv:2006.07364v2 [cs.RO] UPDATED)</h2>
<h3>Ye Yuan, Kris Kitani</h3>
<p>Reinforcement learning has shown great promise for synthesizing realistic
human behaviors by learning humanoid control policies from motion capture data.
However, it is still very challenging to reproduce sophisticated human skills
like ballet dance, or to stably imitate long-term human behaviors with complex
transitions. The main difficulty lies in the dynamics mismatch between the
humanoid model and real humans. That is, motions of real humans may not be
physically possible for the humanoid model. To overcome the dynamics mismatch,
we propose a novel approach, residual force control (RFC), that augments a
humanoid control policy by adding external residual forces into the action
space. During training, the RFC-based policy learns to apply residual forces to
the humanoid to compensate for the dynamics mismatch and better imitate the
reference motion. Experiments on a wide range of dynamic motions demonstrate
that our approach outperforms state-of-the-art methods in terms of convergence
speed and the quality of learned motions. Notably, we showcase a physics-based
virtual character empowered by RFC that can perform highly agile ballet dance
moves such as pirouette, arabesque and jet\'e. Furthermore, we propose a
dual-policy control framework, where a kinematic policy and an RFC-based policy
work in tandem to synthesize multi-modal infinite-horizon human motions without
any task guidance or user input. Our approach is the first humanoid control
method that successfully learns from a large-scale human motion dataset
(Human3.6M) and generates diverse long-term motions. Code and videos are
available at https://www.ye-yuan.com/rfc.
</p>
<a href="http://arxiv.org/abs/2006.07364" target="_blank">arXiv:2006.07364</a> [<a href="http://arxiv.org/pdf/2006.07364" target="_blank">pdf</a>]

<h2>COT-GAN: Generating Sequential Data via Causal Optimal Transport. (arXiv:2006.08571v2 [stat.ML] UPDATED)</h2>
<h3>Tianlin Xu, Li K. Wenliang, Michael Munn, Beatrice Acciaio</h3>
<p>We introduce COT-GAN, an adversarial algorithm to train implicit generative
models optimized for producing sequential data. The loss function of this
algorithm is formulated using ideas from Causal Optimal Transport (COT), which
combines classic optimal transport methods with an additional temporal
causality constraint. Remarkably, we find that this causality condition
provides a natural framework to parameterize the cost function that is learned
by the discriminator as a robust (worst-case) distance, and an ideal mechanism
for learning time dependent data distributions. Following Genevay et al.\
(2018), we also include an entropic penalization term which allows for the use
of the Sinkhorn algorithm when computing the optimal transport cost. Our
experiments show effectiveness and stability of COT-GAN when generating both
low- and high-dimensional time series data. The success of the algorithm also
relies on a new, improved version of the Sinkhorn divergence which demonstrates
less bias in learning.
</p>
<a href="http://arxiv.org/abs/2006.08571" target="_blank">arXiv:2006.08571</a> [<a href="http://arxiv.org/pdf/2006.08571" target="_blank">pdf</a>]

<h2>Regularized ERM on random subspaces. (arXiv:2006.10016v2 [stat.ML] UPDATED)</h2>
<h3>Andrea Della Vecchia, Jaouad Mourtada, Ernesto De Vito, Lorenzo Rosasco</h3>
<p>We study a natural extension of classical empirical risk minimization, where
the hypothesis space is a random subspace of a given space. In particular, we
consider possibly data dependent subspaces spanned by a random subset of the
data, recovering as a special case Nystr\"om approaches for kernel methods.
Considering random subspaces naturally leads to computational savings, but the
question is whether the corresponding learning accuracy is degraded. These
statistical-computational tradeoffs have been recently explored for the least
squares loss and self-concordant loss functions, such as the logistic loss.
Here, we work to extend these results to convex Lipschitz loss functions, that
might not be smooth, such as the hinge loss used in support vector machines.
This extension requires developing new proofs, that use different technical
tools. Our main results show the existence of different settings, depending on
how hard the learning problem is, for which computational efficiency can be
improved with no loss in performance. Theoretical results are illustrated with
simple numerical experiments.
</p>
<a href="http://arxiv.org/abs/2006.10016" target="_blank">arXiv:2006.10016</a> [<a href="http://arxiv.org/pdf/2006.10016" target="_blank">pdf</a>]

<h2>Mat\'ern Gaussian processes on Riemannian manifolds. (arXiv:2006.10160v2 [stat.ML] UPDATED)</h2>
<h3>Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky, Marc Peter Deisenroth</h3>
<p>Gaussian processes are an effective model class for learning unknown
functions, particularly in settings where accurately representing predictive
uncertainty is of key importance. Motivated by applications in the physical
sciences, the widely-used Mat\'ern class of Gaussian processes has recently
been generalized to model functions whose domains are Riemannian manifolds, by
re-expressing said processes as solutions of stochastic partial differential
equations. In this work, we propose techniques for computing the kernels of
these processes on compact Riemannian manifolds via spectral theory of the
Laplace-Beltrami operator in a fully constructive manner, thereby allowing them
to be trained via standard scalable techniques such as inducing point methods.
We also extend the generalization from the Mat\'ern to the widely-used squared
exponential Gaussian process. By allowing Riemannian Mat\'ern Gaussian
processes to be trained using well-understood techniques, our work enables
their use in mini-batch, online, and non-conjugate settings, and makes them
more accessible to machine learning practitioners.
</p>
<a href="http://arxiv.org/abs/2006.10160" target="_blank">arXiv:2006.10160</a> [<a href="http://arxiv.org/pdf/2006.10160" target="_blank">pdf</a>]

<h2>When OT meets MoM: Robust estimation of Wasserstein Distance. (arXiv:2006.10325v2 [stat.ML] UPDATED)</h2>
<h3>Guillaume Staerman, Pierre Laforgue, Pavlo Mozharovskyi, Florence d&#x27;Alch&#xe9;-Buc</h3>
<p>Issued from Optimal Transport, the Wasserstein distance has gained importance
in Machine Learning due to its appealing geometrical properties and the
increasing availability of efficient approximations. In this work, we consider
the problem of estimating the Wasserstein distance between two probability
distributions when observations are polluted by outliers. To that end, we
investigate how to leverage Medians of Means (MoM) estimators to robustify the
estimation of Wasserstein distance. Exploiting the dual Kantorovitch
formulation of Wasserstein distance, we introduce and discuss novel MoM-based
robust estimators whose consistency is studied under a data contamination model
and for which convergence rates are provided. These MoM estimators enable to
make Wasserstein Generative Adversarial Network (WGAN) robust to outliers, as
witnessed by an empirical study on two benchmarks CIFAR10 and Fashion MNIST.
Eventually, we discuss how to combine MoM with the entropy-regularized
approximation of the Wasserstein distance and propose a simple MoM-based
re-weighting scheme that could be used in conjunction with the Sinkhorn
algorithm.
</p>
<a href="http://arxiv.org/abs/2006.10325" target="_blank">arXiv:2006.10325</a> [<a href="http://arxiv.org/pdf/2006.10325" target="_blank">pdf</a>]

<h2>Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning. (arXiv:2006.10800v2 [cs.LG] UPDATED)</h2>
<h3>Tabish Rashid, Gregory Farquhar, Bei Peng, Shimon Whiteson</h3>
<p>QMIX is a popular $Q$-learning algorithm for cooperative MARL in the
centralised training and decentralised execution paradigm. In order to enable
easy decentralisation, QMIX restricts the joint action $Q$-values it can
represent to be a monotonic mixing of each agent's utilities. However, this
restriction prevents it from representing value functions in which an agent's
ordering over its actions can depend on other agents' actions. To analyse this
representational limitation, we first formalise the objective QMIX optimises,
which allows us to view QMIX as an operator that first computes the
$Q$-learning targets and then projects them into the space representable by
QMIX. This projection returns a representable $Q$-value that minimises the
unweighted squared error across all joint actions. We show in particular that
this projection can fail to recover the optimal policy even with access to
$Q^*$, which primarily stems from the equal weighting placed on each joint
action. We rectify this by introducing a weighting into the projection, in
order to place more importance on the better joint actions. We propose two
weighting schemes and prove that they recover the correct maximal action for
any joint action $Q$-values, and therefore for $Q^*$ as well. Based on our
analysis and results in the tabular setting, we introduce two scalable versions
of our algorithm, Centrally-Weighted (CW) QMIX and Optimistically-Weighted (OW)
QMIX and demonstrate improved performance on both predator-prey and challenging
multi-agent StarCraft benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2006.10800" target="_blank">arXiv:2006.10800</a> [<a href="http://arxiv.org/pdf/2006.10800" target="_blank">pdf</a>]

<h2>Automatically Learning Compact Quality-aware Surrogates for Optimization Problems. (arXiv:2006.10815v2 [cs.LG] UPDATED)</h2>
<h3>Kai Wang, Bryan Wilder, Andrew Perrault, Milind Tambe</h3>
<p>Solving optimization problems with unknown parameters often requires learning
a predictive model to predict the values of the unknown parameters and then
solving the problem using these values. Recent work has shown that including
the optimization problem as a layer in the model training pipeline results in
predictions of the unobserved parameters that lead to higher decision quality.
Unfortunately, this process comes at a large computational cost because the
optimization problem must be solved and differentiated through in each training
iteration; furthermore, it may also sometimes fail to improve solution quality
due to non-smoothness issues that arise when training through a complex
optimization layer. To address these shortcomings, we learn a low-dimensional
surrogate model of a large optimization problem by representing the feasible
space in terms of meta-variables, each of which is a linear combination of the
original variables. By training a low-dimensional surrogate model end-to-end,
and jointly with the predictive model, we achieve: i) a large reduction in
training and inference time; and ii) improved performance by focusing attention
on the more important variables in the optimization and learning in a smoother
space. Empirically, we demonstrate these improvements on a non-convex adversary
modeling task, a submodular recommendation task and a convex portfolio
optimization task.
</p>
<a href="http://arxiv.org/abs/2006.10815" target="_blank">arXiv:2006.10815</a> [<a href="http://arxiv.org/pdf/2006.10815" target="_blank">pdf</a>]

<h2>wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations. (arXiv:2006.11477v3 [cs.CL] UPDATED)</h2>
<h3>Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli</h3>
<p>We show for the first time that learning powerful representations from speech
audio alone followed by fine-tuning on transcribed speech can outperform the
best semi-supervised methods while being conceptually simpler. wav2vec 2.0
masks the speech input in the latent space and solves a contrastive task
defined over a quantization of the latent representations which are jointly
learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER
on the clean/other test sets. When lowering the amount of labeled data to one
hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour
subset while using 100 times less labeled data. Using just ten minutes of
labeled data and pre-training on 53k hours of unlabeled data still achieves
4.8/8.2 WER. This demonstrates the feasibility of speech recognition with
limited amounts of labeled data.
</p>
<a href="http://arxiv.org/abs/2006.11477" target="_blank">arXiv:2006.11477</a> [<a href="http://arxiv.org/pdf/2006.11477" target="_blank">pdf</a>]

<h2>On the Theory of Transfer Learning: The Importance of Task Diversity. (arXiv:2006.11650v2 [cs.LG] UPDATED)</h2>
<h3>Nilesh Tripuraneni, Michael I. Jordan, Chi Jin</h3>
<p>We provide new statistical guarantees for transfer learning via
representation learning--when transfer is achieved by learning a feature
representation shared across different tasks. This enables learning on new
tasks using far less data than is required to learn them in isolation.
Formally, we consider $t+1$ tasks parameterized by functions of the form $f_j
\circ h$ in a general function class $\mathcal{F} \circ \mathcal{H}$, where
each $f_j$ is a task-specific function in $\mathcal{F}$ and $h$ is the shared
representation in $\mathcal{H}$. Letting $C(\cdot)$ denote the complexity
measure of the function class, we show that for diverse training tasks (1) the
sample complexity needed to learn the shared representation across the first
$t$ training tasks scales as $C(\mathcal{H}) + t C(\mathcal{F})$, despite no
explicit access to a signal from the feature representation and (2) with an
accurate estimate of the representation, the sample complexity needed to learn
a new task scales only with $C(\mathcal{F})$. Our results depend upon a new
general notion of task diversity--applicable to models with general tasks,
features, and losses--as well as a novel chain rule for Gaussian complexities.
Finally, we exhibit the utility of our general framework in several models of
importance in the literature.
</p>
<a href="http://arxiv.org/abs/2006.11650" target="_blank">arXiv:2006.11650</a> [<a href="http://arxiv.org/pdf/2006.11650" target="_blank">pdf</a>]

<h2>Generative causal explanations of black-box classifiers. (arXiv:2006.13913v2 [cs.LG] UPDATED)</h2>
<h3>Matthew O&#x27;Shaughnessy, Gregory Canal, Marissa Connor, Mark Davenport, Christopher Rozell</h3>
<p>We develop a method for generating causal post-hoc explanations of black-box
classifiers based on a learned low-dimensional representation of the data. The
explanation is causal in the sense that changing learned latent factors
produces a change in the classifier output statistics. To construct these
explanations, we design a learning framework that leverages a generative model
and information-theoretic measures of causal influence. Our objective function
encourages both the generative model to faithfully represent the data
distribution and the latent factors to have a large causal influence on the
classifier output. Our method learns both global and local explanations, is
compatible with any classifier that admits class probabilities and a gradient,
and does not require labeled attributes or knowledge of causal structure. Using
carefully controlled test cases, we provide intuition that illuminates the
function of our objective. We then demonstrate the practical utility of our
method on image recognition tasks.
</p>
<a href="http://arxiv.org/abs/2006.13913" target="_blank">arXiv:2006.13913</a> [<a href="http://arxiv.org/pdf/2006.13913" target="_blank">pdf</a>]

<h2>Supermasks in Superposition. (arXiv:2006.14769v3 [cs.LG] UPDATED)</h2>
<h3>Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason Yosinski, Ali Farhadi</h3>
<p>We present the Supermasks in Superposition (SupSup) model, capable of
sequentially learning thousands of tasks without catastrophic forgetting. Our
approach uses a randomly initialized, fixed base network and for each task
finds a subnetwork (supermask) that achieves good performance. If task identity
is given at test time, the correct subnetwork can be retrieved with minimal
memory usage. If not provided, SupSup can infer the task using gradient-based
optimization to find a linear superposition of learned supermasks which
minimizes the output entropy. In practice we find that a single gradient step
is often sufficient to identify the correct mask, even among 2500 tasks. We
also showcase two promising extensions. First, SupSup models can be trained
entirely without task identity information, as they may detect when they are
uncertain about new data and allocate an additional supermask for the new
training distribution. Finally the entire, growing set of supermasks can be
stored in a constant-sized reservoir by implicitly storing them as attractors
in a fixed-sized Hopfield network.
</p>
<a href="http://arxiv.org/abs/2006.14769" target="_blank">arXiv:2006.14769</a> [<a href="http://arxiv.org/pdf/2006.14769" target="_blank">pdf</a>]

<h2>Beyond accuracy: quantifying trial-by-trial behaviour of CNNs and humans by measuring error consistency. (arXiv:2006.16736v2 [cs.CV] UPDATED)</h2>
<h3>Robert Geirhos, Kristof Meding, Felix A. Wichmann</h3>
<p>A central problem in cognitive science and behavioural neuroscience as well
as in machine learning and artificial intelligence research is to ascertain
whether two or more decision makers (be they brains or algorithms) use the same
strategy. Accuracy alone cannot distinguish between strategies: two systems may
achieve similar accuracy with very different strategies. The need to
differentiate beyond accuracy is particularly pressing if two systems are near
ceiling performance, like Convolutional Neural Networks (CNNs) and humans on
visual object recognition. Here we introduce trial-by-trial error consistency,
a quantitative analysis for measuring whether two decision making systems
systematically make errors on the same inputs. Making consistent errors on a
trial-by-trial basis is a necessary condition for similar processing strategies
between decision makers. Our analysis is applicable to compare algorithms with
algorithms, humans with humans, and algorithms with humans. When applying error
consistency to object recognition we obtain three main findings: (1.)
Irrespective of architecture, CNNs are remarkably consistent with one another.
(2.) The consistency between CNNs and human observers, however, is little above
what can be expected by chance alone---indicating that humans and CNNs are
likely implementing very different strategies. (3.) CORnet-S, a recurrent model
termed the "current best model of the primate ventral visual stream", fails to
capture essential characteristics of human behavioural data and behaves
essentially like a standard purely feedforward ResNet-50 in our analysis. Taken
together, error consistency analysis suggests that the strategies used by human
and machine vision are still very different---but we envision our
general-purpose error consistency analysis to serve as a fruitful tool for
quantifying future progress.
</p>
<a href="http://arxiv.org/abs/2006.16736" target="_blank">arXiv:2006.16736</a> [<a href="http://arxiv.org/pdf/2006.16736" target="_blank">pdf</a>]

<h2>Future Urban Scenes Generation Through Vehicles Synthesis. (arXiv:2007.00323v2 [cs.CV] UPDATED)</h2>
<h3>Alessandro Simoni, Luca Bergamini, Andrea Palazzi, Simone Calderara, Rita Cucchiara</h3>
<p>In this work we propose a deep learning pipeline to predict the visual future
appearance of an urban scene. Despite recent advances, generating the entire
scene in an end-to-end fashion is still far from being achieved. Instead, here
we follow a two stages approach, where interpretable information is included in
the loop and each actor is modelled independently. We leverage a per-object
novel view synthesis paradigm; i.e. generating a synthetic representation of an
object undergoing a geometrical roto-translation in the 3D space. Our model can
be easily conditioned with constraints (e.g. input trajectories) provided by
state-of-the-art tracking methods or by the user itself. This allows us to
generate a set of diverse realistic futures starting from the same input in a
multi-modal fashion. We visually and quantitatively show the superiority of
this approach over traditional end-to-end scene-generation methods on CityFlow,
a challenging real world dataset.
</p>
<a href="http://arxiv.org/abs/2007.00323" target="_blank">arXiv:2007.00323</a> [<a href="http://arxiv.org/pdf/2007.00323" target="_blank">pdf</a>]

<h2>Noise-Robust Adaptation Control for Supervised Acoustic System Identification Exploiting A Noise Dictionary. (arXiv:2007.01579v2 [eess.AS] UPDATED)</h2>
<h3>Thomas Haubner, Andreas Brendel, Mohamed Elminshawi, Walter Kellermann</h3>
<p>We present a noise-robust adaptation control strategy for block-online
supervised acoustic system identification by exploiting a noise dictionary. The
proposed algorithm takes advantage of the pronounced spectral structure which
characterizes many types of interfering noise signals. We model the noisy
observations by a linear Gaussian Discrete Fourier Transform-domain state space
model whose parameters are estimated by an online generalized
Expectation-Maximization algorithm. Unlike all other state-of-the-art
approaches we suggest to model the covariance matrix of the observation
probability density function by a dictionary model. We propose to learn the
noise dictionary from training data, which can be gathered either offline or
online whenever the system is not excited, while we infer the activations
continuously. The proposed algorithm represents a novel machine-learning based
approach to noise-robust adaptation control which allows for faster convergence
in applications characterized by high-level and non-stationary interfering
noise signals and abrupt system changes.
</p>
<a href="http://arxiv.org/abs/2007.01579" target="_blank">arXiv:2007.01579</a> [<a href="http://arxiv.org/pdf/2007.01579" target="_blank">pdf</a>]

<h2>Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2007.02529v2 [cs.LG] UPDATED)</h2>
<h3>Meng Zhou, Ziyu Liu, Pengwei Sui, Yixuan Li, Yuk Ying Chung</h3>
<p>We present a multi-agent actor-critic method that aims to implicitly address
the credit assignment problem under fully cooperative settings. Our key
motivation is that credit assignment among agents may not require an explicit
formulation as long as (1) the policy gradients derived from a centralized
critic carry sufficient information for the decentralized agents to maximize
their joint action value through optimal cooperation and (2) a sustained level
of exploration is enforced throughout training. Under the centralized training
with decentralized execution (CTDE) paradigm, we achieve the former by
formulating the centralized critic as a hypernetwork such that a latent state
representation is integrated into the policy gradients through its
multiplicative association with the stochastic policies; to achieve the latter,
we derive a simple technique called adaptive entropy regularization where
magnitudes of the entropy gradients are dynamically rescaled based on the
current policy stochasticity to encourage consistent levels of exploration. Our
algorithm, referred to as LICA, is evaluated on several benchmarks including
the multi-agent particle environments and a set of challenging StarCraft II
micromanagement tasks, and we show that LICA significantly outperforms previous
methods.
</p>
<a href="http://arxiv.org/abs/2007.02529" target="_blank">arXiv:2007.02529</a> [<a href="http://arxiv.org/pdf/2007.02529" target="_blank">pdf</a>]

<h2>Faster Graph Embeddings via Coarsening. (arXiv:2007.02817v3 [cs.LG] UPDATED)</h2>
<h3>Matthew Fahrbach, Gramoz Goranci, Richard Peng, Sushant Sachdeva, Chi Wang</h3>
<p>Graph embeddings are a ubiquitous tool for machine learning tasks, such as
node classification and link prediction, on graph-structured data. However,
computing the embeddings for large-scale graphs is prohibitively inefficient
even if we are interested only in a small subset of relevant vertices. To
address this, we present an efficient graph coarsening approach, based on Schur
complements, for computing the embedding of the relevant vertices. We prove
that these embeddings are preserved exactly by the Schur complement graph that
is obtained via Gaussian elimination on the non-relevant vertices. As computing
Schur complements is expensive, we give a nearly-linear time algorithm that
generates a coarsened graph on the relevant vertices that provably matches the
Schur complement in expectation in each iteration. Our experiments involving
prediction tasks on graphs demonstrate that computing embeddings on the
coarsened graph, rather than the entire graph, leads to significant time
savings without sacrificing accuracy.
</p>
<a href="http://arxiv.org/abs/2007.02817" target="_blank">arXiv:2007.02817</a> [<a href="http://arxiv.org/pdf/2007.02817" target="_blank">pdf</a>]

<h2>Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting. (arXiv:2007.02842v2 [cs.LG] UPDATED)</h2>
<h3>Lei Bai, Lina Yao, Can Li, Xianzhi Wang, Can Wang</h3>
<p>Modeling complex spatial and temporal correlations in the correlated time
series data is indispensable for understanding the traffic dynamics and
predicting the future status of an evolving traffic system. Recent works focus
on designing complicated graph neural network architectures to capture shared
patterns with the help of pre-defined graphs. In this paper, we argue that
learning node-specific patterns is essential for traffic forecasting while the
pre-defined graph is avoidable. To this end, we propose two adaptive modules
for enhancing Graph Convolutional Network (GCN) with new capabilities: 1) a
Node Adaptive Parameter Learning (NAPL) module to capture node-specific
patterns; 2) a Data Adaptive Graph Generation (DAGG) module to infer the
inter-dependencies among different traffic series automatically. We further
propose an Adaptive Graph Convolutional Recurrent Network (AGCRN) to capture
fine-grained spatial and temporal correlations in traffic series automatically
based on the two modules and recurrent networks. Our experiments on two
real-world traffic datasets show AGCRN outperforms state-of-the-art by a
significant margin without pre-defined graphs about spatial connections.
</p>
<a href="http://arxiv.org/abs/2007.02842" target="_blank">arXiv:2007.02842</a> [<a href="http://arxiv.org/pdf/2007.02842" target="_blank">pdf</a>]

<h2>Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding. (arXiv:2007.02914v2 [cs.LG] UPDATED)</h2>
<h3>Lin Lan, Pinghui Wang, Xuefeng Du, Kaikai Song, Jing Tao, Xiaohong Guan</h3>
<p>We study the problem of node classification on graphs with few-shot novel
labels, which has two distinctive properties: (1) There are novel labels to
emerge in the graph; (2) The novel labels have only a few representative nodes
for training a classifier. The study of this problem is instructive and
corresponds to many applications such as recommendations for newly formed
groups with only a few users in online social networks. To cope with this
problem, we propose a novel Meta Transformed Network Embedding framework
(MetaTNE), which consists of three modules: (1) A \emph{structural module}
provides each node a latent representation according to the graph structure.
(2) A \emph{meta-learning module} captures the relationships between the graph
structure and the node labels as prior knowledge in a meta-learning manner.
Additionally, we introduce an \emph{embedding transformation function} that
remedies the deficiency of the straightforward use of meta-learning.
Inherently, the meta-learned prior knowledge can be used to facilitate the
learning of few-shot novel labels. (3) An \emph{optimization module} employs a
simple yet effective scheduling strategy to train the above two modules with a
balance between graph structure learning and meta-learning. Experiments on four
real-world datasets show that MetaTNE brings a huge improvement over the
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2007.02914" target="_blank">arXiv:2007.02914</a> [<a href="http://arxiv.org/pdf/2007.02914" target="_blank">pdf</a>]

<h2>Adversarially-learned Inference via an Ensemble of Discrete Undirected Graphical Models. (arXiv:2007.05033v3 [cs.LG] UPDATED)</h2>
<h3>Adarsh K. Jeewajee, Leslie P. Kaelbling</h3>
<p>Undirected graphical models are compact representations of joint probability
distributions over random variables. To solve inference tasks of interest,
graphical models of arbitrary topology can be trained using empirical risk
minimization. However, to solve inference tasks that were not seen during
training, these models (EGMs) often need to be re-trained. Instead, we propose
an inference-agnostic adversarial training framework which produces an
infinitely-large ensemble of graphical models (AGMs). The ensemble is optimized
to generate data within the GAN framework, and inference is performed using a
finite subset of these models. AGMs perform comparably with EGMs on inference
tasks that the latter were specifically optimized for. Most importantly, AGMs
show significantly better generalization to unseen inference tasks compared to
EGMs, as well as deep neural architectures like GibbsNet and VAEAC which allow
arbitrary conditioning. Finally, AGMs allow fast data sampling, competitive
with Gibbs sampling from EGMs.
</p>
<a href="http://arxiv.org/abs/2007.05033" target="_blank">arXiv:2007.05033</a> [<a href="http://arxiv.org/pdf/2007.05033" target="_blank">pdf</a>]

<h2>An Equivalence between Loss Functions and Non-Uniform Sampling in Experience Replay. (arXiv:2007.06049v2 [cs.LG] UPDATED)</h2>
<h3>Scott Fujimoto, David Meger, Doina Precup</h3>
<p>Prioritized Experience Replay (PER) is a deep reinforcement learning
technique in which agents learn from transitions sampled with non-uniform
probability proportionate to their temporal-difference error. We show that any
loss function evaluated with non-uniformly sampled data can be transformed into
another uniformly sampled loss function with the same expected gradient.
Surprisingly, we find in some environments PER can be replaced entirely by this
new loss function without impact to empirical performance. Furthermore, this
relationship suggests a new branch of improvements to PER by correcting its
uniformly sampled loss function equivalent. We demonstrate the effectiveness of
our proposed modifications to PER and the equivalent loss function in several
MuJoCo and Atari environments.
</p>
<a href="http://arxiv.org/abs/2007.06049" target="_blank">arXiv:2007.06049</a> [<a href="http://arxiv.org/pdf/2007.06049" target="_blank">pdf</a>]

<h2>Lifelong Policy Gradient Learning of Factored Policies for Faster Training Without Forgetting. (arXiv:2007.07011v2 [cs.LG] UPDATED)</h2>
<h3>Jorge A. Mendez, Boyu Wang, Eric Eaton</h3>
<p>Policy gradient methods have shown success in learning control policies for
high-dimensional dynamical systems. Their biggest downside is the amount of
exploration they require before yielding high-performing policies. In a
lifelong learning setting, in which an agent is faced with multiple consecutive
tasks over its lifetime, reusing information from previously seen tasks can
substantially accelerate the learning of new tasks. We provide a novel method
for lifelong policy gradient learning that trains lifelong function
approximators directly via policy gradients, allowing the agent to benefit from
accumulated knowledge throughout the entire training process. We show
empirically that our algorithm learns faster and converges to better policies
than single-task and lifelong learning baselines, and completely avoids
catastrophic forgetting on a variety of challenging domains.
</p>
<a href="http://arxiv.org/abs/2007.07011" target="_blank">arXiv:2007.07011</a> [<a href="http://arxiv.org/pdf/2007.07011" target="_blank">pdf</a>]

<h2>Fine-Tune Longformer for Jointly Predicting Rumor Stance and Veracity. (arXiv:2007.07803v2 [cs.CL] UPDATED)</h2>
<h3>Anant Khandelwal</h3>
<p>Increased usage of social media caused the popularity of news and events
which are not even verified, resulting in spread of rumors allover the web. Due
to widely available social media platforms and increased usage caused the data
to be available in huge amounts.The manual methods to process such large data
is costly and time-taking, so there has been an increased attention to process
and verify such content automatically for the presence of rumors. A lot of
research studies reveal that to identify the stances of posts in the discussion
thread of such events and news is an important preceding step before identify
the rumor veracity. In this paper,we propose a multi-task learning framework
for jointly predicting rumor stance and veracity on the dataset released at
SemEval 2019 RumorEval: Determining rumor veracity and support for
rumors(SemEval 2019 Task 7), which includes social media rumors stem from a
variety of breaking news stories from Reddit as well as Twit-ter. Our framework
consists of two parts: a) The bottom part of our framework classifies the
stance for each post in the conversation thread discussing a rumor via
modelling the multi-turn conversation and make each post aware of its
neighboring posts. b) The upper part predicts the rumor veracity of the
conversation thread with stance evolution obtained from the bottom part.
Experimental results on SemEval 2019 Task 7 dataset show that our method
outperforms previous methods on both rumor stance classification and veracity
prediction
</p>
<a href="http://arxiv.org/abs/2007.07803" target="_blank">arXiv:2007.07803</a> [<a href="http://arxiv.org/pdf/2007.07803" target="_blank">pdf</a>]

<h2>Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis. (arXiv:2007.08095v2 [cs.LG] UPDATED)</h2>
<h3>Kavi Gupta, Peter Ebert Christensen, Xinyun Chen, Dawn Song</h3>
<p>The use of deep learning techniques has achieved significant progress for
program synthesis from input-output examples. However, when the program
semantics become more complex, it still remains a challenge to synthesize
programs that are consistent with the specification. In this work, we propose
SED, a neural program generation framework that incorporates synthesis,
execution, and debugging stages. Instead of purely relying on the neural
program synthesizer to generate the final program, SED first produces initial
programs using the neural program synthesizer component, then utilizes a neural
program debugger to iteratively repair the generated programs. The integration
of the debugger component enables SED to modify the programs based on the
execution results and specification, which resembles the coding process of
human programmers. On Karel, a challenging input-output program synthesis
benchmark, SED reduces the error rate of the neural program synthesizer itself
by a considerable margin, and outperforms the standard beam search for
decoding.
</p>
<a href="http://arxiv.org/abs/2007.08095" target="_blank">arXiv:2007.08095</a> [<a href="http://arxiv.org/pdf/2007.08095" target="_blank">pdf</a>]

<h2>Region-based Non-local Operation for Video Classification. (arXiv:2007.09033v3 [cs.CV] UPDATED)</h2>
<h3>Guoxi Huang, Adrian G. Bors</h3>
<p>Convolutional Neural Networks (CNNs) model long-range dependencies by deeply
stacking convolution operations with small window sizes, which makes the
optimizations difficult. This paper presents region-based non-local (RNL)
operations as a family of self-attention mechanisms, which can directly capture
long-range dependencies without using a deep stack of local operations. Given
an intermediate feature map, our method recalibrates the feature at a position
by aggregating the information from the neighboring regions of all positions.
By combining a channel attention module with the proposed RNL, we design an
attention chain, which can be integrated into the off-the-shelf CNNs for
end-to-end training. We evaluate our method on two video classification
benchmarks. The experimental results of our method outperform other attention
mechanisms, and we achieve state-of-the-art performance on the
Something-Something V1 dataset.
</p>
<a href="http://arxiv.org/abs/2007.09033" target="_blank">arXiv:2007.09033</a> [<a href="http://arxiv.org/pdf/2007.09033" target="_blank">pdf</a>]

<h2>Progressive Multi-Scale Residual Network for Single Image Super-Resolution. (arXiv:2007.09552v2 [eess.IV] UPDATED)</h2>
<h3>Yuqing Liu, Xinfeng Zhang, Shanshe Wang, Siwei Ma, Wen Gao</h3>
<p>Super-resolution is a classical issue in image restoration field. In recent
years, deep learning methods have achieved significant success in
super-resolution topic, which concentrate on different elaborate network
designs to exploit the image features more effectively. However, most of the
networks focus on increasing the depth or width for superior capacities with a
large number of parameters, which cause a high computation complexity cost and
seldom focus on the inherent correlation of different features. This paper
proposes a progressive multi-scale residual network (PMRN) for single image
super-resolution problem by sequentially exploiting features with restricted
parameters. Specifically, we design a progressive multi-scale residual block
(PMRB) to progressively explore the multi-scale features with different layer
combinations, aiming to consider the correlations of different scales. The
combinations for feature exploitation are defined in a recursive fashion for
introducing the non-linearity and better feature representation with limited
parameters. Furthermore, we investigate a joint channel-wise and pixel-wise
attention mechanism for comprehensive correlation exploration, termed as CPA,
which is utilized in PMRB by considering both scale and bias factors for
features in parallel. Experimental results show that proposed PMRN recovers
structural textures more effectively with superior PSNR/SSIM results than other
lightweight works. The extension model PMRN+ with self-ensemble achieves
competitive or better results than large networks with much fewer parameters
and lower computation complexity.
</p>
<a href="http://arxiv.org/abs/2007.09552" target="_blank">arXiv:2007.09552</a> [<a href="http://arxiv.org/pdf/2007.09552" target="_blank">pdf</a>]

<h2>DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation. (arXiv:2007.11301v3 [cs.CV] UPDATED)</h2>
<h3>Alexandre Carlier, Martin Danelljan, Alexandre Alahi, Radu Timofte</h3>
<p>Scalable Vector Graphics (SVG) are ubiquitous in modern 2D interfaces due to
their ability to scale to different resolutions. However, despite the success
of deep learning-based models applied to rasterized images, the problem of
vector graphics representation learning and generation remains largely
unexplored. In this work, we propose a novel hierarchical generative network,
called DeepSVG, for complex SVG icons generation and interpolation. Our
architecture effectively disentangles high-level shapes from the low-level
commands that encode the shape itself. The network directly predicts a set of
shapes in a non-autoregressive fashion. We introduce the task of complex SVG
icons generation by releasing a new large-scale dataset along with an
open-source library for SVG manipulation. We demonstrate that our network
learns to accurately reconstruct diverse vector graphics, and can serve as a
powerful animation tool by performing interpolations and other latent space
operations. Our code is available at https://github.com/alexandre01/deepsvg.
</p>
<a href="http://arxiv.org/abs/2007.11301" target="_blank">arXiv:2007.11301</a> [<a href="http://arxiv.org/pdf/2007.11301" target="_blank">pdf</a>]

<h2>Self-supervised Learning for Large-scale Item Recommendations. (arXiv:2007.12865v3 [cs.LG] UPDATED)</h2>
<h3>Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix Yu, Ting Chen, Aditya Menon, Lichan Hong, Ed H. Chi, Steve Tjoa, Jieqi Kang, Evan Ettinger</h3>
<p>Large scale recommender models find most relevant items from huge catalogs,
and they play a critical role in modern search and recommendation systems. To
model the input space with large-vocab categorical features, a typical
recommender model learns a joint embedding space through neural networks for
both queries and items from user feedback data. However, with millions to
billions of items, the power-law user feedback makes labels very sparse for a
large amount of long-tail items.

Inspired by the recent success in self-supervised representation learning
research in both computer vision and natural language understanding, we propose
a multi-task self-supervised learning (SSL) framework for large-scale item
recommendations. The framework is designed to tackle the label sparsity problem
by learning more robust item representations. Furthermore, we propose two
self-supervised tasks applicable to models with categorical features within the
proposed framework: (i) Feature Masking (FM) and (ii) Feature Dropout (FD).

We evaluate our framework using two large-scale datasets with 500M and 1B
training examples respectively. Our results demonstrate that the proposed
framework outperforms traditional supervised learning only models and
state-of-the-art regularization techniques in the context of item
recommendations. The SSL framework shows larger improvement with less
supervision compared to the counterparts. We also apply the proposed techniques
to a web-scale commercial app-to-app recommendation system, and significantly
improve top-tier business metrics via A/B experiments on live traffic. Our
online results also verify our hypothesis that our framework indeed improves
model performance on slices that lack supervision.
</p>
<a href="http://arxiv.org/abs/2007.12865" target="_blank">arXiv:2007.12865</a> [<a href="http://arxiv.org/pdf/2007.12865" target="_blank">pdf</a>]

<h2>Neural Kalman Filtering for Speech Enhancement. (arXiv:2007.13962v2 [eess.AS] UPDATED)</h2>
<h3>Wei Xue, Gang Quan, Chao Zhang, Guohong Ding, Xiaodong He, Bowen Zhou</h3>
<p>Statistical signal processing based speech enhancement methods adopt expert
knowledge to design the statistical models and linear filters, which is
complementary to the deep neural network (DNN) based methods which are
data-driven. In this paper, by using expert knowledge from statistical signal
processing for network design and optimization, we extend the conventional
Kalman filtering (KF) to the supervised learning scheme, and propose the neural
Kalman filtering (NKF) for speech enhancement. Two intermediate clean speech
estimates are first produced from recurrent neural networks (RNN) and linear
Wiener filtering (WF) separately and are then linearly combined by a learned
NKF gain to yield the NKF output. Supervised joint training is applied to NKF
to learn to automatically trade-off between the instantaneous linear estimation
made by the WF and the long-term non-linear estimation made by the RNN. The NKF
method can be seen as using expert knowledge from WF to regularize the RNN
estimations to improve its generalization ability to the noise conditions
unseen in the training. Experiments in different noisy conditions show that the
proposed method outperforms the baseline methods both in terms of objective
evaluation metrics and automatic speech recognition (ASR) word error rates
(WERs).
</p>
<a href="http://arxiv.org/abs/2007.13962" target="_blank">arXiv:2007.13962</a> [<a href="http://arxiv.org/pdf/2007.13962" target="_blank">pdf</a>]

<h2>Transformer based unsupervised pre-training for acoustic representation learning. (arXiv:2007.14602v2 [eess.AS] UPDATED)</h2>
<h3>Ruixiong Zhang, Haiwei Wu, Wubo Li, Dongwei Jiang, Wei Zou, Xiangang Li</h3>
<p>Recently, a variety of acoustic tasks and related applications arised. For
many acoustic tasks, the labeled data size may be limited. To handle this
problem, we propose an unsupervised pre-training method using Transformer based
encoder to learn a general and robust high-level representation for all
acoustic tasks. Experiments have been conducted on three kinds of acoustic
tasks: speech emotion recognition, sound event detection and speech
translation. All the experiments have shown that pre-training using its own
training data can significantly improve the performance. With a larger
pre-training data combining MuST-C, Librispeech and ESC-US datasets, for speech
emotion recognition, the UAR can further improve absolutely 4.3% on IEMOCAP
dataset. For sound event detection, the F1 score can further improve absolutely
1.7% on DCASE2018 task5 development set and 2.4% on evaluation set. For speech
translation, the BLEU score can further improve relatively 12.2% on En-De
dataset and 8.4% on En-Fr dataset.
</p>
<a href="http://arxiv.org/abs/2007.14602" target="_blank">arXiv:2007.14602</a> [<a href="http://arxiv.org/pdf/2007.14602" target="_blank">pdf</a>]

<h2>Meta-Learning with Context-Agnostic Initialisations. (arXiv:2007.14658v2 [cs.CV] UPDATED)</h2>
<h3>Toby Perrett, Alessandro Masullo, Tilo Burghardt, Majid Mirmehdi, Dima Damen</h3>
<p>Meta-learning approaches have addressed few-shot problems by finding
initialisations suited for fine-tuning to target tasks. Often there are
additional properties within training data (which we refer to as context), not
relevant to the target task, which act as a distractor to meta-learning,
particularly when the target task contains examples from a novel context not
seen during training. We address this oversight by incorporating a
context-adversarial component into the meta-learning process. This produces an
initialisation for fine-tuning to target which is both context-agnostic and
task-generalised. We evaluate our approach on three commonly used meta-learning
algorithms and two problems. We demonstrate our context-agnostic meta-learning
improves results in each case. First, we report on Omniglot few-shot character
classification, using alphabets as context. An average improvement of 4.3% is
observed across methods and tasks when classifying characters from an unseen
alphabet. Second, we evaluate on a dataset for personalised energy expenditure
predictions from video, using participant knowledge as context. We demonstrate
that context-agnostic meta-learning decreases the average mean square error by
30%.
</p>
<a href="http://arxiv.org/abs/2007.14658" target="_blank">arXiv:2007.14658</a> [<a href="http://arxiv.org/pdf/2007.14658" target="_blank">pdf</a>]

<h2>Self-supervised learning through the eyes of a child. (arXiv:2007.16189v2 [cs.CV] UPDATED)</h2>
<h3>A. Emin Orhan, Vaibhav V. Gupta, Brenden M. Lake</h3>
<p>Within months of birth, children develop meaningful expectations about the
world around them. How much of this early knowledge can be explained through
generic learning mechanisms applied to sensory data, and how much of it
requires more substantive innate inductive biases? Addressing this fundamental
question in its full generality is currently infeasible, but we can hope to
make real progress in more narrowly defined domains, such as the development of
high-level visual categories, thanks to improvements in data collecting
technology and recent progress in deep learning. In this paper, our goal is
precisely to achieve such progress by utilizing modern self-supervised deep
learning methods and a recent longitudinal, egocentric video dataset recorded
from the perspective of three young children (Sullivan et al., 2020). Our
results demonstrate the emergence of powerful, high-level visual
representations from developmentally realistic natural videos using generic
self-supervised learning objectives.
</p>
<a href="http://arxiv.org/abs/2007.16189" target="_blank">arXiv:2007.16189</a> [<a href="http://arxiv.org/pdf/2007.16189" target="_blank">pdf</a>]

<h2>Functional Regularization for Representation Learning: A Unified Theoretical Perspective. (arXiv:2008.02447v3 [cs.LG] UPDATED)</h2>
<h3>Siddhant Garg, Yingyu Liang</h3>
<p>Unsupervised and self-supervised learning approaches have become a crucial
tool to learn representations for downstream prediction tasks. While these
approaches are widely used in practice and achieve impressive empirical gains,
their theoretical understanding largely lags behind. Towards bridging this gap,
we present a unifying perspective where several such approaches can be viewed
as imposing a regularization on the representation via a learnable function
using unlabeled data. We propose a discriminative theoretical framework for
analyzing the sample complexity of these approaches, which generalizes the
framework of (Balcan and Blum, 2010) to allow learnable regularization
functions. Our sample complexity bounds show that, with carefully chosen
hypothesis classes to exploit the structure in the data, these learnable
regularization functions can prune the hypothesis space, and help reduce the
amount of labeled data needed. We then provide two concrete examples of
functional regularization, one using auto-encoders and the other using masked
self-supervision, and apply our framework to quantify the reduction in the
sample complexity bound of labeled data. We also provide complementary
empirical results to support our analysis.
</p>
<a href="http://arxiv.org/abs/2008.02447" target="_blank">arXiv:2008.02447</a> [<a href="http://arxiv.org/pdf/2008.02447" target="_blank">pdf</a>]

<h2>nPrint: Standard Packet-level Network Traffic Analysis. (arXiv:2008.02695v3 [cs.CR] UPDATED)</h2>
<h3>Jordan Holland, Paul Schmitt, Nick Feamster, Prateek Mittal</h3>
<p>This paper presents nPrint, a standard, packet-based representation of
network traffic. nPrint enables machine learning on network traffic without
manual feature engineering. We combine nPrint with automated machine learning
(AutoML) to demonstrate that nPrint can generate a standard traffic
representation across a variety of machine learning tasks and models. We
present the design and implementation of nPrint, describe how we integrate it
with AutoML, and apply the pipeline to three common network traffic
classification problems: operating system detection, device fingerprinting, and
application identification.

Our evaluation shows that models trained on nPrint achieve higher performance
than the state-of-the-art tools for these tasks, without relying on manually
engineered rules or features. nPrint's contribution is thus in its generality,
as it lowers the barrier to applying machine learning techniques for a variety
of network traffic analysis problems. We have implemented and released nPrint
as open-source software. Our performance evaluation demonstrates that nPrint
can be deployed many settings, from offline transformation of standard packet
capture formats to online streaming deployments.
</p>
<a href="http://arxiv.org/abs/2008.02695" target="_blank">arXiv:2008.02695</a> [<a href="http://arxiv.org/pdf/2008.02695" target="_blank">pdf</a>]

<h2>Compositional Generalization via Neural-Symbolic Stack Machines. (arXiv:2008.06662v2 [cs.LG] UPDATED)</h2>
<h3>Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou</h3>
<p>Despite achieving tremendous success, existing deep learning models have
exposed limitations in compositional generalization, the capability to learn
compositional rules and apply them to unseen cases in a systematic manner. To
tackle this issue, we propose the Neural-Symbolic Stack Machine (NeSS). It
contains a neural network to generate traces, which are then executed by a
symbolic stack machine enhanced with sequence manipulation operations. NeSS
combines the expressive power of neural sequence models with the recursion
supported by the symbolic stack machine. Without training supervision on
execution traces, NeSS achieves 100% generalization performance in four
domains: the SCAN benchmark of language-driven navigation tasks, the task of
few-shot learning of compositional instructions, the compositional machine
translation benchmark, and context-free grammar parsing tasks.
</p>
<a href="http://arxiv.org/abs/2008.06662" target="_blank">arXiv:2008.06662</a> [<a href="http://arxiv.org/pdf/2008.06662" target="_blank">pdf</a>]

<h2>Provably Efficient Reward-Agnostic Navigation with Linear Value Iteration. (arXiv:2008.07737v2 [cs.LG] UPDATED)</h2>
<h3>Andrea Zanette, Alessandro Lazaric, Mykel J. Kochenderfer, Emma Brunskill</h3>
<p>There has been growing progress on theoretical analyses for provably
efficient learning in MDPs with linear function approximation, but much of the
existing work has made strong assumptions to enable exploration by conventional
exploration frameworks. Typically these assumptions are stronger than what is
needed to find good solutions in the batch setting. In this work, we show how
under a more standard notion of low inherent Bellman error, typically employed
in least-square value iteration-style algorithms, we can provide strong PAC
guarantees on learning a near optimal value function provided that the linear
space is sufficiently "explorable". We present a computationally tractable
algorithm for the reward-free setting and show how it can be used to learn a
near optimal policy for any (linear) reward function, which is revealed only
once learning has completed. If this reward function is also estimated from the
samples gathered during pure exploration, our results also provide same-order
PAC guarantees on the performance of the resulting policy for this setting.
</p>
<a href="http://arxiv.org/abs/2008.07737" target="_blank">arXiv:2008.07737</a> [<a href="http://arxiv.org/pdf/2008.07737" target="_blank">pdf</a>]

<h2>Improving predictions of Bayesian neural networks via local linearization. (arXiv:2008.08400v2 [stat.ML] UPDATED)</h2>
<h3>Alexander Immer, Maciej Korzepa, Matthias Bauer</h3>
<p>The generalized Gauss-Newton (GGN) approximation is often used to make
practical Bayesian deep learning approaches scalable by replacing a second
order derivative with a product of first order derivatives. In this paper we
argue that the GGN approximation should be understood as a local linearization
of the underlying Bayesian neural network (BNN), which turns the BNN into a
generalized linear model (GLM). Because we use this linearized model for
posterior inference, we should also predict using this modified model instead
of the original one. We refer to this modified predictive as "GLM predictive"
and show that it effectively resolves common underfitting problems of the
Laplace approximation. It extends previous results in this vein to general
likelihoods and has an equivalent Gaussian process formulation, which enables
alternative inference schemes for BNNs in function space. We demonstrate the
effectiveness of our approach on several standard classification datasets and
on out-of-distribution detection.
</p>
<a href="http://arxiv.org/abs/2008.08400" target="_blank">arXiv:2008.08400</a> [<a href="http://arxiv.org/pdf/2008.08400" target="_blank">pdf</a>]

<h2>Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake Claim Classification. (arXiv:2009.01047v2 [cs.CL] UPDATED)</h2>
<h3>Bibek Upadhayay, Vahid Behzadan</h3>
<p>The rampant integration of social media in our every day lives and culture
has given rise to fast and easier access to the flow of information than ever
in human history. However, the inherently unsupervised nature of social media
platforms has also made it easier to spread false information and fake news.
Furthermore, the high volume and velocity of information flow in such platforms
make manual supervision and control of information propagation infeasible. This
paper aims to address this issue by proposing a novel deep learning approach
for automated detection of false short-text claims on social media. We first
introduce Sentimental LIAR, which extends the LIAR dataset of short claims by
adding features based on sentiment and emotion analysis of claims. Furthermore,
we propose a novel deep learning architecture based on the BERT-Base language
model for classification of claims as genuine or fake. Our results demonstrate
that the proposed architecture trained on Sentimental LIAR can achieve an
accuracy of 70%, which is an improvement of ~30% over previously reported
results for the LIAR benchmark.
</p>
<a href="http://arxiv.org/abs/2009.01047" target="_blank">arXiv:2009.01047</a> [<a href="http://arxiv.org/pdf/2009.01047" target="_blank">pdf</a>]

<h2>Rotated Binary Neural Network. (arXiv:2009.13055v3 [cs.CV] UPDATED)</h2>
<h3>Mingbao Lin, Rongrong Ji, Zihan Xu, Baochang Zhang, Yan Wang, Yongjian Wu, Feiyue Huang, Chia-Wen Lin</h3>
<p>Binary Neural Network (BNN) shows its predominance in reducing the complexity
of deep neural networks. However, it suffers severe performance degradation.
One of the major impediments is the large quantization error between the
full-precision weight vector and its binary vector. Previous works focus on
compensating for the norm gap while leaving the angular bias hardly touched. In
this paper, for the first time, we explore the influence of angular bias on the
quantization error and then introduce a Rotated Binary Neural Network (RBNN),
which considers the angle alignment between the full-precision weight vector
and its binarized version. At the beginning of each training epoch, we propose
to rotate the full-precision weight vector to its binary vector to reduce the
angular bias. To avoid the high complexity of learning a large rotation matrix,
we further introduce a bi-rotation formulation that learns two smaller rotation
matrices. In the training stage, we devise an adjustable rotated weight vector
for binarization to escape the potential local optimum. Our rotation leads to
around 50% weight flips which maximize the information gain. Finally, we
propose a training-aware approximation of the sign function for the gradient
backward. Experiments on CIFAR-10 and ImageNet demonstrate the superiorities of
RBNN over many state-of-the-arts. Our source code, experimental settings,
training logs and binary models are available at
https://github.com/lmbxmu/RBNN.
</p>
<a href="http://arxiv.org/abs/2009.13055" target="_blank">arXiv:2009.13055</a> [<a href="http://arxiv.org/pdf/2009.13055" target="_blank">pdf</a>]

<h2>Landscape of R packages for eXplainable Artificial Intelligence. (arXiv:2009.13248v2 [cs.LG] UPDATED)</h2>
<h3>Szymon Maksymiuk, Alicja Gosiewska, Przemyslaw Biecek</h3>
<p>The growing availability of data and computing power fuels the development of
predictive models. In order to ensure the safe and effective functioning of
such models, we need methods for exploration, debugging, and validation. New
methods and tools for this purpose are being developed within the eXplainable
Artificial Intelligence (XAI) subdomain of machine learning. In this work (1)
we present the taxonomy of methods for model explanations, (2) we identify and
compare 27 packages available in R to perform XAI analysis, (3) we present an
example of an application of particular packages, (4) we acknowledge recent
trends in XAI. The article is primarily devoted to the tools available in R,
but since it is easy to integrate the Python code, we will also show examples
for the most popular libraries from Python.
</p>
<a href="http://arxiv.org/abs/2009.13248" target="_blank">arXiv:2009.13248</a> [<a href="http://arxiv.org/pdf/2009.13248" target="_blank">pdf</a>]

<h2>Fast Design Space Adaptation with Deep Reinforcement Learning for Analog Circuit Sizing. (arXiv:2009.13772v3 [cs.LG] UPDATED)</h2>
<h3>Kai-En Yang, Chia-Yu Tsai, Hung-Hao Shen, Chen-Feng Chiang, Feng-Ming Tsai, Chung-An Wang, Yiju Ting, Chia-Shun Yeh, Chin-Tang Lai</h3>
<p>We present a novel framework for design space search on analog circuit sizing
using deep reinforcement learning (DRL). Nowadays, analog circuit design is a
manual routine that requires heavy design efforts due to the absence of
automation tools, motivating the urge to develop one. Prior approaches cast
this process as an optimization problem. They use global search strategies
based on DRL with complex network architectures. Nonetheless, the models are
hard to converge and neglected various working conditions of PVT (process,
voltage, temperature).In this work, we reduce the problem to a constraint
satisfaction problem, where a local strategy is adopted. Thus, a simple
feed-forward network with few layers can be used to implement a model-based
reinforcement learning agent. To evaluate the value of the our framework in
production, we cooperate with R&amp;Ds in an IC design company. On circuits with
TSMC advanced 5 and 6nm process, our agents can deliver PPA (performance,
power, area) beyond human level. Furthermore, the product will be taped out in
the near future.
</p>
<a href="http://arxiv.org/abs/2009.13772" target="_blank">arXiv:2009.13772</a> [<a href="http://arxiv.org/pdf/2009.13772" target="_blank">pdf</a>]

<h2>Understanding Self-supervised Learning with Dual Deep Networks. (arXiv:2010.00578v3 [cs.LG] UPDATED)</h2>
<h3>Yuandong Tian, Lantao Yu, Xinlei Chen, Surya Ganguli</h3>
<p>We propose a novel theoretical framework to understand self-supervised
learning methods that employ dual pairs of deep ReLU networks (e.g., SimCLR,
BYOL). First, we prove that in each SGD update of SimCLR, the weights at each
layer are updated by a \emph{covariance operator} that specifically amplifies
initial random selectivities that vary across data samples but survive averages
over data augmentations, which we show leads to the emergence of hierarchical
features, if the input data are generated from a hierarchical latent tree
model. With the same framework, we also show analytically that in BYOL, the
usage of BatchNorm and a predictor creates an implicit contrastive term, acting
as an approximate covariance operator. The term is formed by the inter-play
between the zero-mean operation of BatchNorm and the extra predictor in the
online network. Extensive ablation studies justify our theoretical findings.
</p>
<a href="http://arxiv.org/abs/2010.00578" target="_blank">arXiv:2010.00578</a> [<a href="http://arxiv.org/pdf/2010.00578" target="_blank">pdf</a>]

<h2>Homography Estimation with Convolutional Neural Networks Under Conditions of Variance. (arXiv:2010.01041v2 [cs.CV] UPDATED)</h2>
<h3>David Niblick, Avinash Kak</h3>
<p>Planar homography estimation is foundational to many computer vision
problems, such as Simultaneous Localization and Mapping (SLAM) and Augmented
Reality (AR). However, conditions of high variance confound even the
state-of-the-art algorithms. In this report, we analyze the performance of two
recently published methods using Convolutional Neural Networks (CNNs) that are
meant to replace the more traditional feature-matching based approaches to the
estimation of homography. Our evaluation of the CNN based methods focuses
particularly on measuring the performance under conditions of significant
noise, illumination shift, and occlusion. We also measure the benefits of
training CNNs to varying degrees of noise. Additionally, we compare the effect
of using color images instead of grayscale images for inputs to CNNs. Finally,
we compare the results against baseline feature-matching based homography
estimation methods using SIFT, SURF, and ORB. We find that CNNs can be trained
to be more robust against noise, but at a small cost to accuracy in the
noiseless case. Additionally, CNNs perform significantly better in conditions
of extreme variance than their feature-matching based counterparts. With regard
to color inputs, we conclude that with no change in the CNN architecture to
take advantage of the additional information in the color planes, the
difference in performance using color inputs or grayscale inputs is negligible.
About the CNNs trained with noise-corrupted inputs, we show that training a CNN
to a specific magnitude of noise leads to a "Goldilocks Zone" with regard to
the noise levels where that CNN performs best.
</p>
<a href="http://arxiv.org/abs/2010.01041" target="_blank">arXiv:2010.01041</a> [<a href="http://arxiv.org/pdf/2010.01041" target="_blank">pdf</a>]

<h2>Long-Tail Zero and Few-Shot Learning via Contrastive Pretraining on and for Small Data. (arXiv:2010.01061v2 [cs.CL] UPDATED)</h2>
<h3>Nils Rethmeier, Isabelle Augenstein</h3>
<p>For natural language processing (NLP) tasks such as sentiment or topic
classification, currently prevailing approaches heavily rely on pretraining
large self-supervised models on massive external data resources. However, this
methodology is being critiqued for: exceptional compute and pretraining data
requirements; diminishing returns on both large and small datasets; and
importantly, favourable evaluation settings that overestimate performance
differences. The core belief behind current methodology, coined `the bitter
lesson' by R. Sutton, is that `compute scale-up beats data and
compute-efficient algorithms', neglecting that progress in compute hardware
scale-up is based almost entirely on the miniaturisation of resource
consumption. We thus approach pretraining from a miniaturisation perspective,
such as not to require massive external data sources and models, or learned
translations from continuous input embeddings to discrete labels. To minimise
overly favourable evaluation, we examine learning on a long-tailed,
low-resource, multi-label text classification dataset with noisy, highly sparse
labels and many rare concepts. To this end, we propose a novel
`dataset-internal' contrastive autoencoding approach to self-supervised
pretraining and demonstrate marked improvements in zero-shot, few-shot and
solely supervised learning performance; even under an unfavorable low-resource
scenario, and without defaulting to large-scale external datasets for
self-supervision. We also find empirical evidence that zero and few-shot
learning markedly benefit from adding more `dataset-internal', self-supervised
training signals, which is of practical importance when retrieving or computing
on large external sources of such signals is infeasible.
</p>
<a href="http://arxiv.org/abs/2010.01061" target="_blank">arXiv:2010.01061</a> [<a href="http://arxiv.org/pdf/2010.01061" target="_blank">pdf</a>]

<h2>QarSUMO: A Parallel, Congestion-optimized Traffic Simulator. (arXiv:2010.03289v2 [cs.DC] UPDATED)</h2>
<h3>Hao Chen, Ke Yang, Stefano Giovanni Rizzo, Giovanna Vantini, Phillip Taylor, Xiaosong Ma, Sanjay Chawla</h3>
<p>Traffic simulators are important tools for tasks such as urban planning and
transportation management. Microscopic simulators allow per-vehicle movement
simulation, but require longer simulation time. The simulation overhead is
exacerbated when there is traffic congestion and most vehicles move slowly.
This in particular hurts the productivity of emerging urban computing studies
based on reinforcement learning, where traffic simulations are heavily and
repeatedly used for designing policies to optimize traffic related tasks.

In this paper, we develop QarSUMO, a parallel, congestion-optimized version
of the popular SUMO open-source traffic simulator. QarSUMO performs high-level
parallelization on top of SUMO, to utilize powerful multi-core servers and
enables future extension to multi-node parallel simulation if necessary. The
proposed design, while partly sacrificing speedup, makes QarSUMO compatible
with future SUMO improvements. We further contribute such an improvement by
modifying the SUMO simulation engine for congestion scenarios where the update
computation of consecutive and slow-moving vehicles can be simplified.

We evaluate QarSUMO with both real-world and synthetic road network and
traffic data, and examine its execution time as well as simulation accuracy
relative to the original, sequential SUMO.
</p>
<a href="http://arxiv.org/abs/2010.03289" target="_blank">arXiv:2010.03289</a> [<a href="http://arxiv.org/pdf/2010.03289" target="_blank">pdf</a>]

<h2>Decentralize the feedback infrastructure!. (arXiv:2010.03356v3 [cs.CY] UPDATED)</h2>
<h3>Pedro Garcia Lopez</h3>
<p>The decentralized architecture of Internet sparkled techno-utopian visions of
a virtual freedom space for humanity. Peer-to-peer systems, collaborative
creation (wikipedia), open source software (Linux), universal shared knowledge,
and the hopes for disintermediation contributed to this major vision.

However, the reality is bleak: centralization is reigning in the cyberspace,
with huge technological corporations controlling our data, and
re-intermediation and control are stronger than ever in the so-called "sharing"
economy. The Internet is also fragmented by countries, with many states
imposing heavy controls to information and communication services.

The XXI century will witness the major clash between centralization and
decentralization in human history. And the major struggle will be around the
communication and feedback technologies that will intermediate and govern every
interaction in our lives.

Unlike previous approaches that propose to socialize the feedback
infrastructure or to use anti-monopoly laws to break Big Tech companies, in
this article we advocate for the decentralization of the information and
communication infrastructure. And the key to this decentralization is the
creation of standards enabling interoperability between data platforms. This
will in turn produce a true disintermediation from well established
technological players and open competition to small third parties. In this
article, we sketch such a decentralized open infrastructure including
communication, sharing, matchmaking, and reputation services that can be
constructed over open source technologies and standards.
</p>
<a href="http://arxiv.org/abs/2010.03356" target="_blank">arXiv:2010.03356</a> [<a href="http://arxiv.org/pdf/2010.03356" target="_blank">pdf</a>]

<h2>Machine learning for recovery factor estimation of an oil reservoir: a tool for de-risking at a hydrocarbon asset evaluation. (arXiv:2010.03408v2 [stat.AP] UPDATED)</h2>
<h3>Ivan Makhotin, Denis Orlov, Dmitry Koroteev, Evgeny Burnaev, Aram Karapetyan, Dmitry Antonenko</h3>
<p>Well known oil recovery factor estimation techniques such as analogy,
volumetric calculations, material balance, decline curve analysis, hydrodynamic
simulations have certain limitations. Those techniques are time-consuming,
require specific data and expert knowledge. Besides, though uncertainty
estimation is highly desirable for this problem, the methods above do not
include this by default. In this work, we present a data-driven technique for
oil recovery factor of hydrocarbon reservoirs using parameters and various
representative statistics. We apply advanced machine learning methods using
extensive historical worldwide oilfields datasets (more than 2000 oil
reservoirs). The data-driven model might be used as a general tool for rapid
and completely objective estimation of the oil recovery factor. In addition, it
includes the ability to work with partial input data and to estimate the
prediction interval of the oil recovery factor. We perform the evaluation in
terms of accuracy and prediction intervals coverage for several tree-based
machine learning techniques in application to the following two cases: (1)
using parameters only related to geometry, geology, transport, storage and
fluid properties, (2) using an extended set of parameters including development
and production data. For both cases model proved itself to be robust and
reliable. We conclude that the proposed data-driven approach overcomes several
limitations of the traditional methods and is suitable for rapid, reliable and
objective estimation of oil recovery factor for hydrocarbon reservoir.
</p>
<a href="http://arxiv.org/abs/2010.03408" target="_blank">arXiv:2010.03408</a> [<a href="http://arxiv.org/pdf/2010.03408" target="_blank">pdf</a>]

<h2>All for One and One for All: Improving Music Separation by Bridging Networks. (arXiv:2010.04228v2 [eess.AS] UPDATED)</h2>
<h3>Ryosuke Sawata, Stefan Uhlich, Shusuke Takahashi, Yuki Mitsufuji</h3>
<p>This paper proposes several improvements for music separation with deep
neural networks(DNNs), namely a multi-domain loss(MDL) and two combination
schemes. First, by using MDL we take advantage of the frequency and time domain
representation of audio signals. Next, we utilize the relationship among
instruments by jointly considering them. We do this on the one hand by
modifying the network architecture and introducing a CrossNet structure. On the
other hand, we consider combinations of instrument estimates by using a new
combination loss(CL). MDL and CL can easily be applied to many existing
DNN-based separation methods as they are merely loss functions which are only
used during training and which do not affect the inference step. Experimental
results show that the performance of Open-Unmix (UMX), a well-known and
state-of-the-art open source library for music separation, can be improved by
utilizing our above schemes. Our modifications of UMX will be open-sourced
together with this paper.
</p>
<a href="http://arxiv.org/abs/2010.04228" target="_blank">arXiv:2010.04228</a> [<a href="http://arxiv.org/pdf/2010.04228" target="_blank">pdf</a>]

<h2>Neural Enhancement in Content Delivery Systems: The State-of-the-Art and Future Directions. (arXiv:2010.05838v2 [cs.CV] UPDATED)</h2>
<h3>Royson Lee, Stylianos I. Venieris, Nicholas D. Lane</h3>
<p>Internet-enabled smartphones and ultra-wide displays are transforming a
variety of visual apps spanning from on-demand movies and 360-degree videos to
video-conferencing and live streaming. However, robustly delivering visual
content under fluctuating networking conditions on devices of diverse
capabilities remains an open problem. In recent years, advances in the field of
deep learning on tasks such as super-resolution and image enhancement have led
to unprecedented performance in generating high-quality images from low-quality
ones, a process we refer to as neural enhancement. In this paper, we survey
state-of-the-art content delivery systems that employ neural enhancement as a
key component in achieving both fast response time and high visual quality. We
first present the deployment challenges of neural enhancement models. We then
cover systems targeting diverse use-cases and analyze their design decisions in
overcoming technical challenges. Moreover, we present promising directions
based on the latest insights from deep learning research to further boost the
quality of experience of these systems.
</p>
<a href="http://arxiv.org/abs/2010.05838" target="_blank">arXiv:2010.05838</a> [<a href="http://arxiv.org/pdf/2010.05838" target="_blank">pdf</a>]

<h2>BayReL: Bayesian Relational Learning for Multi-omics Data Integration. (arXiv:2010.05895v3 [cs.LG] UPDATED)</h2>
<h3>Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna R Narayanan, Xiaoning Qian</h3>
<p>High-throughput molecular profiling technologies have produced
high-dimensional multi-omics data, enabling systematic understanding of living
systems at the genome scale. Studying molecular interactions across different
data types helps reveal signal transduction mechanisms across different classes
of molecules. In this paper, we develop a novel Bayesian representation
learning method that infers the relational interactions across multi-omics data
types. Our method, Bayesian Relational Learning (BayReL) for multi-omics data
integration, takes advantage of a priori known relationships among the same
class of molecules, modeled as a graph at each corresponding view, to learn
view-specific latent variables as well as a multi-partite graph that encodes
the interactions across views. Our experiments on several real-world datasets
demonstrate enhanced performance of BayReL in inferring meaningful interactions
compared to existing baselines.
</p>
<a href="http://arxiv.org/abs/2010.05895" target="_blank">arXiv:2010.05895</a> [<a href="http://arxiv.org/pdf/2010.05895" target="_blank">pdf</a>]

<h2>Chatbot Interaction with Artificial Intelligence: Human Data Augmentation with T5 and Language Transformer Ensemble for Text Classification. (arXiv:2010.05990v2 [cs.CL] UPDATED)</h2>
<h3>Jordan J. Bird, Anik&#xf3; Ek&#xe1;rt, Diego R. Faria</h3>
<p>In this work, we present the Chatbot Interaction with Artificial Intelligence
(CI-AI) framework as an approach to the training of deep learning chatbots for
task classification. The intelligent system augments human-sourced data via
artificial paraphrasing in order to generate a large set of training data for
further classical, attention, and language transformation-based learning
approaches for Natural Language Processing. Human beings are asked to
paraphrase commands and questions for task identification for further execution
of a machine. The commands and questions are split into training and validation
sets. A total of 483 responses were recorded. Secondly, the training set is
paraphrased by the T5 model in order to augment it with further data. Seven
state-of-the-art transformer-based text classification algorithms (BERT,
DistilBERT, RoBERTa, DistilRoBERTa, XLM, XLM-RoBERTa, and XLNet) are
benchmarked for both sets after fine-tuning on the training data for two
epochs. We find that all models are improved when training data is augmented by
the T5 model, with an average increase of classification accuracy by 4.01%. The
best result was the RoBERTa model trained on T5 augmented data which achieved
98.96% classification accuracy. Finally, we found that an ensemble of the five
best-performing transformer models via Logistic Regression of output label
predictions led to an accuracy of 99.59% on the dataset of human responses. A
highly-performing model allows the intelligent system to interpret human
commands at the social-interaction level through a chatbot-like interface (e.g.
"Robot, can we have a conversation?") and allows for better accessibility to AI
by non-technical users.
</p>
<a href="http://arxiv.org/abs/2010.05990" target="_blank">arXiv:2010.05990</a> [<a href="http://arxiv.org/pdf/2010.05990" target="_blank">pdf</a>]

<h2>AMPA-Net: Optimization-Inspired Attention Neural Network for Deep Compressed Sensing. (arXiv:2010.06907v4 [cs.CV] UPDATED)</h2>
<h3>Nanyu Li, Charles C. Zhou</h3>
<p>Compressed sensing (CS) is a challenging problem in image processing due to
reconstructing an almost complete image from a limited measurement. To achieve
fast and accurate CS reconstruction, we synthesize the advantages of two
well-known methods (neural network and optimization algorithm) to propose a
novel optimization inspired neural network which dubbed AMP-Net. AMP-Net
realizes the fusion of the Approximate Message Passing (AMP) algorithm and
neural network. All of its parameters are learned automatically. Furthermore,
we propose an AMPA-Net which uses three attention networks to improve the
representation ability of AMP-Net. Finally, We demonstrate the effectiveness of
AMP-Net and AMPA-Net on four standard CS reconstruction benchmark data sets.
</p>
<a href="http://arxiv.org/abs/2010.06907" target="_blank">arXiv:2010.06907</a> [<a href="http://arxiv.org/pdf/2010.06907" target="_blank">pdf</a>]

<h2>Practical guidelines to developing a regulatory package for a medical AI product. (arXiv:2010.07038v2 [cs.CY] UPDATED)</h2>
<h3>David Higgins</h3>
<p>Medical AI products require certification before deployment in most
jurisdictions. To date, no clear pathways for regulating medical AI exist. I
present guidelines for development of such a regulatory package. This approach
is predicated on the translation between a statistical risk perspective,
typical of medical device regulators, and a deep understanding of machine
learning methodologies. This work of translation will enable medical device
regulators and machine learning experts to communicate more clearly, and thus
lead to the development of standardised pathways for medical AI regulation.
</p>
<a href="http://arxiv.org/abs/2010.07038" target="_blank">arXiv:2010.07038</a> [<a href="http://arxiv.org/pdf/2010.07038" target="_blank">pdf</a>]

<h2>Unsupervised Self-training Algorithm Based on Deep Learning for Optical Aerial Images Change Detection. (arXiv:2010.07469v2 [cs.CV] UPDATED)</h2>
<h3>Yuan Zhou, Xiangrui Li</h3>
<p>Optical aerial images change detection is an important task in earth
observation and has been extensively investigated in the past few decades.
Generally, the supervised change detection methods with superior performance
require a large amount of labeled training data which is obtained by manual
annotation with high cost. In this paper, we present a novel unsupervised
self-training algorithm (USTA) for optical aerial images change detection. The
traditional method such as change vector analysis is used to generate the
pseudo labels. We use these pseudo labels to train a well designed
convolutional neural network. The network is used as a teacher to classify the
original multitemporal images to generate another set of pseudo labels. Then
two set of pseudo labels are used to jointly train a student network with the
same structure as the teacher. The final change detection result can be
obtained by the trained student network. Besides, we design an image filter to
control the usage of change information in the pseudo labels in the training
process of the network. The whole process of the algorithm is an unsupervised
process without manually marked labels. Experimental results on the real
datasets demonstrate competitive performance of our proposed method.
</p>
<a href="http://arxiv.org/abs/2010.07469" target="_blank">arXiv:2010.07469</a> [<a href="http://arxiv.org/pdf/2010.07469" target="_blank">pdf</a>]

<h2>Learning Monocular Dense Depth from Events. (arXiv:2010.08350v2 [cs.CV] UPDATED)</h2>
<h3>Javier Hidalgo-Carri&#xf3;, Daniel Gehrig, Davide Scaramuzza</h3>
<p>Event cameras are novel sensors that output brightness changes in the form of
a stream of asynchronous events instead of intensity frames. Compared to
conventional image sensors, they offer significant advantages: high temporal
resolution, high dynamic range, no motion blur, and much lower bandwidth.
Recently, learning-based approaches have been applied to event-based data, thus
unlocking their potential and making significant progress in a variety of
tasks, such as monocular depth prediction. Most existing approaches use
standard feed-forward architectures to generate network predictions, which do
not leverage the temporal consistency presents in the event stream. We propose
a recurrent architecture to solve this task and show significant improvement
over standard feed-forward methods. In particular, our method generates dense
depth predictions using a monocular setup, which has not been shown previously.
We pretrain our model using a new dataset containing events and depth maps
recorded in the CARLA simulator. We test our method on the Multi Vehicle Stereo
Event Camera Dataset (MVSEC). Quantitative experiments show up to 50%
improvement in average depth error with respect to previous event-based
methods.
</p>
<a href="http://arxiv.org/abs/2010.08350" target="_blank">arXiv:2010.08350</a> [<a href="http://arxiv.org/pdf/2010.08350" target="_blank">pdf</a>]

<h2>Improving significance of binary black hole mergers in Advanced LIGO data using deep learning : Confirmation of GW151216. (arXiv:2010.08584v2 [gr-qc] UPDATED)</h2>
<h3>Shreejit Jadhav, Nikhil Mukund, Bhooshan Gadre, Sanjit Mitra, Sheelu Abraham</h3>
<p>We present a novel Machine Learning (ML) based strategy to search for compact
binary coalescences (CBCs) in data from ground-based gravitational wave (GW)
observatories. This is the first ML-based search that not only recovers all the
binary black hole mergers in the first GW transients calalog (GWTC-1), but also
makes a clean detection of GW151216, which was not significant enough to be
included in the catalogue. Moreover, we achieve this by only adding a new
coincident ranking statistic (MLStat) to a standard analysis that was used for
GWTC-1. In CBC searches, reducing contamination by terrestrial and instrumental
transients, which create a loud noise background by triggering numerous false
alarms, is crucial to improving the sensitivity for detecting true events. The
sheer volume of data and and large number of expected detections also prompts
the use of ML techniques. We perform transfer learning to train "InceptionV3",
a pre-trained deep neural network, along with curriculum learning to
distinguish GW signals from noisy events by analysing their continuous wavelet
transform (CWT) maps. MLStat incorporates information from this ML classifier
into the standard coincident search likelihood used by the conventional search.
This leads to at least an order of magnitude improvement in the inverse
false-alarm-rate (IFAR) for the previously "low significance" events GW151012,
GW170729 and GW151216. The confidence in detection of GW151216 is further
strengthened by performing its parameter estimation using SEOBNRv4HM_ROM.
Considering the impressive ability of the statistic to distinguish signals from
glitches, the list of marginal events from MLStat could be quite reliable for
astrophysical population studies and further follow-up. This work demonstrates
the immense potential and readiness of MLStat for finding new sources in
current data and possibility of its adaptation in similar searches.
</p>
<a href="http://arxiv.org/abs/2010.08584" target="_blank">arXiv:2010.08584</a> [<a href="http://arxiv.org/pdf/2010.08584" target="_blank">pdf</a>]

<h2>L-RED: Efficient Post-Training Detection of Imperceptible Backdoor Attacks without Access to the Training Set. (arXiv:2010.09987v2 [cs.CV] UPDATED)</h2>
<h3>Zhen Xiang, David J. Miller, George Kesidis</h3>
<p>Backdoor attacks (BAs) are an emerging form of adversarial attack typically
against deep neural network image classifiers. The attacker aims to have the
classifier learn to classify to a target class when test images from one or
more source classes contain a backdoor pattern, while maintaining high accuracy
on all clean test images. Reverse-Engineering-based Defenses (REDs) against BAs
do not require access to the training set but only to an independent clean
dataset. Unfortunately, most existing REDs rely on an unrealistic assumption
that all classes except the target class are source classes of the attack. REDs
that do not rely on this assumption often require a large set of clean images
and heavy computation. In this paper, we propose a Lagrangian-based RED (L-RED)
that does not require knowledge of the number of source classes (or whether an
attack is present). Our defense requires very few clean images to effectively
detect BAs and is computationally efficient. Notably, we detect 56 out of 60
BAs using only two clean images per class in our experiments on CIFAR-10.
</p>
<a href="http://arxiv.org/abs/2010.09987" target="_blank">arXiv:2010.09987</a> [<a href="http://arxiv.org/pdf/2010.09987" target="_blank">pdf</a>]

<h2>Federated Bayesian Optimization via Thompson Sampling. (arXiv:2010.10154v3 [cs.LG] UPDATED)</h2>
<h3>Zhongxiang Dai, Kian Hsiang Low, Patrick Jaillet</h3>
<p>Bayesian optimization (BO) is a prominent approach to optimizing
expensive-to-evaluate black-box functions. The massive computational capability
of edge devices such as mobile phones, coupled with privacy concerns, has led
to a surging interest in federated learning (FL) which focuses on collaborative
training of deep neural networks (DNNs) via first-order optimization
techniques. However, some common machine learning tasks such as hyperparameter
tuning of DNNs lack access to gradients and thus require zeroth-order/black-box
optimization. This hints at the possibility of extending BO to the FL setting
(FBO) for agents to collaborate in these black-box optimization tasks. This
paper presents federated Thompson sampling (FTS) which overcomes a number of
key challenges of FBO and FL in a principled way: We (a) use random Fourier
features to approximate the Gaussian process surrogate model used in BO, which
naturally produces the parameters to be exchanged between agents, (b) design
FTS based on Thompson sampling, which significantly reduces the number of
parameters to be exchanged, and (c) provide a theoretical convergence guarantee
that is robust against heterogeneous agents, which is a major challenge in FL
and FBO. We empirically demonstrate the effectiveness of FTS in terms of
communication efficiency, computational efficiency, and practical performance.
</p>
<a href="http://arxiv.org/abs/2010.10154" target="_blank">arXiv:2010.10154</a> [<a href="http://arxiv.org/pdf/2010.10154" target="_blank">pdf</a>]

<h2>The Detection of Thoracic Abnormalities ChestX-Det10 Challenge Results. (arXiv:2010.10298v2 [eess.IV] UPDATED)</h2>
<h3>Jie Lian, Jingyu Liu, Yizhou Yu, Mengyuan Ding, Yaoci Lu, Yi Lu, Jie Cai, Deshou Lin, Miao Zhang, Zhe Wang, Kai He, Yijie Yu</h3>
<p>The detection of thoracic abnormalities challenge is organized by the
Deepwise AI Lab. The challenge is divided into two rounds. In this paper, we
present the results of 6 teams which reach the second round. The challenge
adopts the ChestX-Det10 dateset proposed by the Deepwise AI Lab. ChestX-Det10
is the first chest X-Ray dataset with instance-level annotations, including 10
categories of disease/abnormality of 3,543 images. The annotations are located
at https://github.com/Deepwise-AILab/ChestX-Det10-Dataset. In the challenge, we
randomly split all data into 3001 images for training and 542 images for
testing.
</p>
<a href="http://arxiv.org/abs/2010.10298" target="_blank">arXiv:2010.10298</a> [<a href="http://arxiv.org/pdf/2010.10298" target="_blank">pdf</a>]

<h2>Asynchronous Edge Learning using Cloned Knowledge Distillation. (arXiv:2010.10338v2 [cs.LG] UPDATED)</h2>
<h3>Sang-ho Lee, Kiyoon Yoo, Nojun Kwak</h3>
<p>With the increasing demand for more and more data, the federated learning
(FL) methods, which try to utilize highly distributed on-device local data in
the training process, have been proposed.However, fledgling services provided
by startup companies not only have limited number of clients, but also have
minimal resources for constant communications between the server and multiple
clients. In addition, in a real-world environment where the user pool changes
dynamically, the FL system must be able to efficiently utilize rapid inflow and
outflow of users, while at the same time experience minimal bottleneck due to
network delays of multiple users. In this respect, we amend the federated
learning scenario to a more flexible asynchronous edge learning. To solve the
aforementioned learning problems, we propose an asynchronous model-based
communication method with knowledge distillation. In particular, we dub our
knowledge distillation scheme as "cloned distillation" and explain how it is
different from other knowledge distillation method. In brief, we found that in
knowledge distillation between the teacher and the student there exist two
contesting traits in the student: to attend to the teacher's knowledge or to
retain its own knowledge exclusive to the teacher. And in this edge learning
scenario, the attending property should be amplified rather than the retaining
property, because teachers are dispatched to the users to learn from them and
recollected at the server to teach the core model. Our asynchronous edge
learning method can elastically handle the dynamic inflow and outflow of users
in a service with minimal communication cost, operate with essentially no
bottleneck due to user delay, and protect user's privacy. Also we found that it
is robust to users who behave abnormally or maliciously.
</p>
<a href="http://arxiv.org/abs/2010.10338" target="_blank">arXiv:2010.10338</a> [<a href="http://arxiv.org/pdf/2010.10338" target="_blank">pdf</a>]

<h2>ConjNLI: Natural Language Inference Over Conjunctive Sentences. (arXiv:2010.10418v2 [cs.CL] UPDATED)</h2>
<h3>Swarnadeep Saha, Yixin Nie, Mohit Bansal</h3>
<p>Reasoning about conjuncts in conjunctive sentences is important for a deeper
understanding of conjunctions in English and also how their usages and
semantics differ from conjunctive and disjunctive boolean logic. Existing NLI
stress tests do not consider non-boolean usages of conjunctions and use
templates for testing such model knowledge. Hence, we introduce ConjNLI, a
challenge stress-test for natural language inference over conjunctive
sentences, where the premise differs from the hypothesis by conjuncts removed,
added, or replaced. These sentences contain single and multiple instances of
coordinating conjunctions ("and", "or", "but", "nor") with quantifiers,
negations, and requiring diverse boolean and non-boolean inferences over
conjuncts. We find that large-scale pre-trained language models like RoBERTa do
not understand conjunctive semantics well and resort to shallow heuristics to
make inferences over such sentences. As some initial solutions, we first
present an iterative adversarial fine-tuning method that uses synthetically
created training data based on boolean and non-boolean heuristics. We also
propose a direct model advancement by making RoBERTa aware of predicate
semantic roles. While we observe some performance gains, ConjNLI is still
challenging for current methods, thus encouraging interesting future work for
better understanding of conjunctions. Our data and code are publicly available
at: https://github.com/swarnaHub/ConjNLI
</p>
<a href="http://arxiv.org/abs/2010.10418" target="_blank">arXiv:2010.10418</a> [<a href="http://arxiv.org/pdf/2010.10418" target="_blank">pdf</a>]

<h2>Gender Prediction Based on Vietnamese Names with Machine Learning Techniques. (arXiv:2010.10852v2 [cs.CL] UPDATED)</h2>
<h3>Huy Quoc To, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen, Anh Gia-Tuan Nguyen</h3>
<p>As biological gender is one of the aspects of presenting individual human,
much work has been done on gender classification based on people names. The
proposals for English and Chinese languages are tremendous; still, there have
been few works done for Vietnamese so far. We propose a new dataset for gender
prediction based on Vietnamese names. This dataset comprises over 26,000 full
names annotated with genders. This dataset is available on our website for
research purposes. In addition, this paper describes six machine learning
algorithms (Support Vector Machine, Multinomial Naive Bayes, Bernoulli Naive
Bayes, Decision Tree, Random Forrest and Logistic Regression) and a deep
learning model (LSTM) with fastText word embedding for gender prediction on
Vietnamese names. We create a dataset and investigate the impact of each name
component on detecting gender. As a result, the best F1-score that we have
achieved is up to 96\% on LSTM model and we generate a web API based on our
trained model.
</p>
<a href="http://arxiv.org/abs/2010.10852" target="_blank">arXiv:2010.10852</a> [<a href="http://arxiv.org/pdf/2010.10852" target="_blank">pdf</a>]

<h2>PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation. (arXiv:2010.10866v2 [cs.CL] UPDATED)</h2>
<h3>Cl&#xe9;ment Rebuffel, Laure Soulier, Geoffrey Scoutheeten, Patrick Gallinari</h3>
<p>In language generation models conditioned by structured data, the classical
training via maximum likelihood almost always leads models to pick up on
dataset divergence (i.e., hallucinations or omissions), and to incorporate them
erroneously in their own generations at inference. In this work, we build ontop
of previous Reinforcement Learning based approaches and show that a
model-agnostic framework relying on the recently introduced PARENT metric is
efficient at reducing both hallucinations and omissions. Evaluations on the
widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this
framework compared to state-of-the-art models.
</p>
<a href="http://arxiv.org/abs/2010.10866" target="_blank">arXiv:2010.10866</a> [<a href="http://arxiv.org/pdf/2010.10866" target="_blank">pdf</a>]

<h2>Product Manifold Learning. (arXiv:2010.09908v1 [cs.LG] CROSS LISTED)</h2>
<h3>Sharon Zhang, Amit Moscovich, Amit Singer</h3>
<p>We consider problems of dimensionality reduction and learning data
representations for continuous spaces with two or more independent degrees of
freedom. Such problems occur, for example, when observing shapes with several
components that move independently. Mathematically, if the parameter space of
each continuous independent motion is a manifold, then their combination is
known as a product manifold. In this paper, we present a new paradigm for
non-linear independent component analysis called manifold factorization. Our
factorization algorithm is based on spectral graph methods for manifold
learning and the separability of the Laplacian operator on product spaces.
Recovering the factors of a manifold yields meaningful lower-dimensional
representations and provides a new way to focus on particular aspects of the
data space while ignoring others. We demonstrate the potential use of our
method for an important and challenging problem in structural biology: mapping
the motions of proteins and other large molecules using cryo-electron
microscopy datasets.
</p>
<a href="http://arxiv.org/abs/2010.09908" target="_blank">arXiv:2010.09908</a> [<a href="http://arxiv.org/pdf/2010.09908" target="_blank">pdf</a>]

<h2>Integrated causal-predictive machine learning models for tropical cyclone epidemiology. (arXiv:2010.11330v1 [stat.AP])</h2>
<h3>Rachel C. Nethery, Nina Katz-Christy, Marianthi-Anna Kioumourtzoglou, Robbie M. Parks, Andrea Schumacher, G. Brooke Anderson</h3>
<p>Strategic preparedness has been shown to reduce the adverse health impacts of
hurricanes and tropical storms, referred to collectively as tropical cyclones
(TCs), but its protective impact could be enhanced by a more comprehensive and
rigorous characterization of TC epidemiology. To generate the insights and
tools necessary for high-precision TC preparedness, we develop and apply a
novel Bayesian machine learning approach that standardizes estimation of
historic TC health impacts, discovers common patterns and sources of
heterogeneity in those health impacts, and enables identification of
communities at highest health risk for future TCs. The model integrates (1) a
causal inference component to quantify the immediate health impacts of recent
historic TCs at high spatial resolution and (2) a predictive component that
captures how TC meteorological features and socioeconomic/demographic
characteristics of impacted communities are associated with health impacts. We
apply it to a rich data platform containing detailed historic TC exposure
information and Medicare claims data. The health outcomes used in our analyses
are all-cause mortality and cardiovascular- and respiratory-related
hospitalizations. We report a high degree of heterogeneity in the acute health
impacts of historic TCs at both the TC level and the community level, with
substantial increases in respiratory hospitalizations, on average, during a
two-week period surrounding TCs. TC sustained windspeeds are found to be the
primary driver of increased mortality and respiratory risk. Our modeling
approach has broader utility for predicting the health impacts of many types of
extreme climate events.
</p>
<a href="http://arxiv.org/abs/2010.11330" target="_blank">arXiv:2010.11330</a> [<a href="http://arxiv.org/pdf/2010.11330" target="_blank">pdf</a>]

<h2>Model updating after interventions paradoxically introduces bias. (arXiv:2010.11530v1 [stat.ML])</h2>
<h3>James Liley, Samuel R Emerson, Bilal A Mateen, Catalina A Vallejos, Louis J M Aslett, Sebastian J Vollmer</h3>
<p>Machine learning is increasingly being used to generate prediction models for
use in a number of real-world settings, from credit risk assessment to clinical
decision support. Recent discussions have highlighted potential problems in the
updating of a predictive score for a binary outcome when an existing predictive
score forms part of the standard workflow, driving interventions. In this
setting, the existing score induces an additional causative pathway which leads
to miscalibration when the original score is replaced. We propose a general
causal framework to describe and address this problem, and demonstrate an
equivalent formulation as a partially observed Markov decision process. We use
this model to demonstrate the impact of such `naive updating' when performed
repeatedly. Namely, we show that successive predictive scores may converge to a
point where they predict their own effect, or may eventually oscillate between
two values, and we argue that neither outcome is desirable. Furthermore, we
demonstrate that even if model-fitting procedures improve, actual performance
may worsen. We complement these findings with a discussion of several potential
routes to overcome these problems.
</p>
<a href="http://arxiv.org/abs/2010.11530" target="_blank">arXiv:2010.11530</a> [<a href="http://arxiv.org/pdf/2010.11530" target="_blank">pdf</a>]

<h2>In Search of Robust Measures of Generalization. (arXiv:2010.11924v1 [cs.LG])</h2>
<h3>Gintare Karolina Dziugaite, Alexandre Drouin, Brady Neal, Nitarshan Rajkumar, Ethan Caballero, Linbo Wang, Ioannis Mitliagkas, Daniel M. Roy</h3>
<p>One of the principal scientific challenges in deep learning is explaining
generalization, i.e., why the particular way the community now trains networks
to achieve small training error also leads to small error on held-out data from
the same population. It is widely appreciated that some worst-case theories --
such as those based on the VC dimension of the class of predictors induced by
modern neural network architectures -- are unable to explain empirical
performance. A large volume of work aims to close this gap, primarily by
developing bounds on generalization error, optimization error, and excess risk.
When evaluated empirically, however, most of these bounds are numerically
vacuous. Focusing on generalization bounds, this work addresses the question of
how to evaluate such bounds empirically. Jiang et al. (2020) recently described
a large-scale empirical study aimed at uncovering potential causal
relationships between bounds/measures and generalization. Building on their
study, we highlight where their proposed methods can obscure failures and
successes of generalization measures in explaining generalization. We argue
that generalization measures should instead be evaluated within the framework
of distributional robustness.
</p>
<a href="http://arxiv.org/abs/2010.11924" target="_blank">arXiv:2010.11924</a> [<a href="http://arxiv.org/pdf/2010.11924" target="_blank">pdf</a>]

<h2>P\'olya Urn Latent Dirichlet Allocation: a doubly sparse massively parallel sampler. (arXiv:1704.03581v7 [stat.ML] UPDATED)</h2>
<h3>Alexander Terenin, M&#xe5;ns Magnusson, Leif Jonsson, David Draper</h3>
<p>Latent Dirichlet Allocation (LDA) is a topic model widely used in natural
language processing and machine learning. Most approaches to training the model
rely on iterative algorithms, which makes it difficult to run LDA on big
corpora that are best analyzed in parallel and distributed computational
environments. Indeed, current approaches to parallel inference either don't
converge to the correct posterior or require storage of large dense matrices in
memory. We present a novel sampler that overcomes both problems, and we show
that this sampler is faster, both empirically and theoretically, than previous
Gibbs samplers for LDA. We do so by employing a novel P\'olya-urn-based
approximation in the sparse partially collapsed sampler for LDA. We prove that
the approximation error vanishes with data size, making our algorithm
asymptotically exact, a property of importance for large-scale topic models. In
addition, we show, via an explicit example, that - contrary to popular belief
in the topic modeling literature - partially collapsed samplers can be more
efficient than fully collapsed samplers. We conclude by comparing the
performance of our algorithm with that of other approaches on well-known
corpora.
</p>
<a href="http://arxiv.org/abs/1704.03581" target="_blank">arXiv:1704.03581</a> [<a href="http://arxiv.org/pdf/1704.03581" target="_blank">pdf</a>]

