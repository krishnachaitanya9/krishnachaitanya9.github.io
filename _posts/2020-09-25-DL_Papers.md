---
title: Latest Deep Learning Papers
date: 2020-10-28 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed</h1>
<h2>Classification and image processing with a semi-discrete scheme for fidelity forced Allen--Cahn on graphs. (arXiv:2010.14556v1 [math.NA])</h2>
<h3>Jeremy Budd, Yves van Gennip, Jonas Latz</h3>
<p>This paper introduces a semi-discrete implicit Euler (SDIE) scheme for the
Allen-Cahn equation (ACE) with fidelity forcing on graphs. Bertozzi and Flenner
(2012) pioneered the use of this differential equation as a method for graph
classification problems, such as semi-supervised learning and image
segmentation. In Merkurjev, Kosti\'c, and Bertozzi (2013), a
Merriman-Bence-Osher (MBO) scheme with fidelity forcing was used instead, as
the MBO scheme is heuristically similar to the ACE. This paper rigorously
establishes the graph MBO scheme with fidelity forcing as a special case of an
SDIE scheme for the graph ACE with fidelity forcing. This connection requires
using the double-obstacle potential in the ACE, as was shown in Budd and Van
Gennip (2020) for ACE without fidelity forcing. We also prove that solutions of
the SDIE scheme converge to solutions of the graph ACE with fidelity forcing as
the SDIE time step tends to zero.

Next, we develop the SDIE scheme as a classification algorithm. We also
introduce some innovations into the algorithms for the SDIE and MBO schemes.
For large graphs, we use a QR decomposition method to compute an
eigendecomposition from a Nystr\"om extension, which outperforms the method
used in e.g. Bertozzi and Flenner (2012) in accuracy, stability, and speed.
Moreover, we replace the Euler discretisation for the scheme's diffusion step
by a computation based on the Strang formula for matrix exponentials. We apply
this algorithm to a number of image segmentation problems, and compare the
performance of the SDIE and MBO schemes. We find that whilst the general SDIE
scheme does not perform better than the MBO special case at this task, our
other innovations lead to a significantly better segmentation than that from
previous literature. We also empirically quantify the uncertainty that this
segmentation inherits from the randomness in the Nystr\"om extension.
</p>
<a href="http://arxiv.org/abs/2010.14556" target="_blank">arXiv:2010.14556</a> [<a href="http://arxiv.org/pdf/2010.14556" target="_blank">pdf</a>]

<h2>Why Does MAML Outperform ERM? An Optimization Perspective. (arXiv:2010.14672v1 [cs.LG])</h2>
<h3>Liam Collins, Aryan Mokhtari, Sanjay Shakkottai</h3>
<p>Model-Agnostic Meta-Learning (MAML) has demonstrated widespread success in
training models that can quickly adapt to new tasks via one or few stochastic
gradient descent steps. However, the MAML objective is significantly more
difficult to optimize compared to standard Empirical Risk Minimization (ERM),
and little is understood about how much MAML improves over ERM in terms of the
fast adaptability of their solutions in various scenarios. We analytically
address this issue in a linear regression setting consisting of a mixture of
easy and hard tasks, where hardness is determined by the number of gradient
steps required to solve the task. Specifically, we prove that for
$\Omega(d_{\text{eff}})$ labelled test samples (for gradient-based fine-tuning)
where $d_{\text{eff}}$ is the effective dimension of the problem, in order for
MAML to achieve substantial gain over ERM, the optimal solutions of the hard
tasks must be closely packed together with the center far from the center of
the easy task optimal solutions. We show that these insights also apply in a
low-dimensional feature space when both MAML and ERM learn a representation of
the tasks, which reduces the effective problem dimension. Further, our few-shot
image classification experiments suggest that our results generalize beyond
linear regression.
</p>
<a href="http://arxiv.org/abs/2010.14672" target="_blank">arXiv:2010.14672</a> [<a href="http://arxiv.org/pdf/2010.14672" target="_blank">pdf</a>]

<h2>Deep Learning for Individual Heterogeneity. (arXiv:2010.14694v1 [econ.EM])</h2>
<h3>Max H. Farrell, Tengyuan Liang, Sanjog Misra</h3>
<p>We propose a methodology for effectively modeling individual heterogeneity
using deep learning while still retaining the interpretability and economic
discipline of classical models. We pair a transparent, interpretable modeling
structure with rich data environments and machine learning methods to estimate
heterogeneous parameters based on potentially high dimensional or complex
observable characteristics. Our framework is widely-applicable, covering
numerous settings of economic interest. We recover, as special cases,
well-known examples such as average treatment effects and parametric components
of partially linear models. However, we also seamlessly deliver new results for
diverse examples such as price elasticities, willingness-to-pay, and surplus
measures in choice models, average marginal and partial effects of continuous
treatment variables, fractional outcome models, count data, heterogeneous
production function components, and more. Deep neural networks are well-suited
to structured modeling of heterogeneity: we show how the network architecture
can be designed to match the global structure of the economic model, giving
novel methodology for deep learning as well as, more formally, improved rates
of convergence. Our results on deep learning have consequences for other
structured modeling environments and applications, such as for additive models.
Our inference results are based on an influence function we derive, which we
show to be flexible enough to to encompass all settings with a single, unified
calculation, removing any requirement for case-by-case derivations. The
usefulness of the methodology in economics is shown in two empirical
applications: the response of 410(k) participation rates to firm matching and
the impact of prices on subscription choices for an online service. Extensions
to instrumental variables and multinomial choices are shown.
</p>
<a href="http://arxiv.org/abs/2010.14694" target="_blank">arXiv:2010.14694</a> [<a href="http://arxiv.org/pdf/2010.14694" target="_blank">pdf</a>]

<h2>Data-driven prediction of multistable systems from sparse measurements. (arXiv:2010.14706v1 [math.DS])</h2>
<h3>Bryan Chu, Mohammad Farazmand</h3>
<p>We develop a data-driven method, based on semi-supervised classification, to
predict the asymptotic state of multistable systems when only sparse spatial
measurements of the system are feasible. Our method predicts the asymptotic
behavior of an observed state by quantifying its proximity to the states in a
precomputed library of data. To quantify this proximity, we introduce a
sparsity-promoting metric-learning (SPML) optimization, which learns a metric
directly from the precomputed data. The resulting metric has two important
properties: (i) It is compatible with the precomputed library, and (ii) It is
computable from sparse measurements. We demonstrate the application of this
method on a multistable reaction-diffusion equation which has four
asymptotically stable steady states. Classifications based on SPML predict the
asymptotic behavior of initial conditions, based on two-point measurements,
with over $89\%$ accuracy. The learned optimal metric also determines where
these measurements need to be made to ensure accurate predictions.
</p>
<a href="http://arxiv.org/abs/2010.14706" target="_blank">arXiv:2010.14706</a> [<a href="http://arxiv.org/pdf/2010.14706" target="_blank">pdf</a>]

<h2>Explore-Before-Talk: Multichannel Selection Diversity for Uplink Transmissions in Machine-Type Communication. (arXiv:2010.14755v1 [cs.IT])</h2>
<h3>Jinho Choi, Jihong Park, Shiva Pokhrel</h3>
<p>Improving the data rate of machine-type communication (MTC) is essential in
supporting emerging Internet of things (IoT) applications ranging from
real-time surveillance to edge machine learning. To this end, in this paper we
propose a resource allocation approach for uplink transmissions within a random
access procedure in MTC by exploiting multichannel selection diversity, coined
explore-before-talk (EBT). Each user in EBT first sends pilot signals through
multiple channels that are initially allocated by a base station (BS) for
exploration, and then the BS informs a subset of initially allocated channels
that are associated with high signal-to-noise ratios (SNRs) for data packet
transmission by the user while releasing the rest of the channels for other
users. Consequently, EBT exploits a multichannel selection diversity gain
during data packet transmission, at the cost of exploration during pilot
transmission. We optimize this exploration-exploitation trade-off, by deriving
closed-form mean data rate and resource outage probability expressions.
Numerical results corroborate that EBT achieves a higher mean data rate while
satisfying the same outage constraint, compared to a conventional MTC protocol
without exploration.
</p>
<a href="http://arxiv.org/abs/2010.14755" target="_blank">arXiv:2010.14755</a> [<a href="http://arxiv.org/pdf/2010.14755" target="_blank">pdf</a>]

<h2>Deep Networks from the Principle of Rate Reduction. (arXiv:2010.14765v1 [cs.LG])</h2>
<h3>Kwan Ho Ryan Chan, Yaodong Yu, Chong You, Haozhi Qi, John Wright, Yi Ma</h3>
<p>This work attempts to interpret modern deep (convolutional) networks from the
principles of rate reduction and (shift) invariant classification. We show that
the basic iterative gradient ascent scheme for optimizing the rate reduction of
learned features naturally leads to a multi-layer deep network, one iteration
per layer. The layered architectures, linear and nonlinear operators, and even
parameters of the network are all explicitly constructed layer-by-layer in a
forward propagation fashion by emulating the gradient scheme. All components of
this "white box" network have precise optimization, statistical, and geometric
interpretation. This principled framework also reveals and justifies the role
of multi-channel lifting and sparse coding in early stage of deep networks.
Moreover, all linear operators of the so-derived network naturally become
multi-channel convolutions when we enforce classification to be rigorously
shift-invariant. The derivation also indicates that such a convolutional
network is significantly more efficient to construct and learn in the spectral
domain. Our preliminary simulations and experiments indicate that so
constructed deep network can already learn a good discriminative representation
even without any back propagation training.
</p>
<a href="http://arxiv.org/abs/2010.14765" target="_blank">arXiv:2010.14765</a> [<a href="http://arxiv.org/pdf/2010.14765" target="_blank">pdf</a>]

<h2>High-dimensional inference: a statistical mechanics perspective. (arXiv:2010.14863v1 [cond-mat.dis-nn])</h2>
<h3>Jean Barbier</h3>
<p>Statistical inference is the science of drawing conclusions about some system
from data. In modern signal processing and machine learning, inference is done
in very high dimension: very many unknown characteristics about the system have
to be deduced from a lot of high-dimensional noisy data. This "high-dimensional
regime" is reminiscent of statistical mechanics, which aims at describing the
macroscopic behavior of a complex system based on the knowledge of its
microscopic interactions. It is by now clear that there are many connections
between inference and statistical physics. This article aims at emphasizing
some of the deep links connecting these apparently separated disciplines
through the description of paradigmatic models of high-dimensional inference in
the language of statistical mechanics. This article has been published in the
issue on artificial intelligence of Ithaca, an Italian
popularization-of-science journal. The selected topics and references are
highly biased and not intended to be exhaustive in any ways. Its purpose is to
serve as introduction to statistical mechanics of inference through a very
specific angle that corresponds to my own tastes and limited knowledge.
</p>
<a href="http://arxiv.org/abs/2010.14863" target="_blank">arXiv:2010.14863</a> [<a href="http://arxiv.org/pdf/2010.14863" target="_blank">pdf</a>]

<h2>Tree-structured Ising models can be learned efficiently. (arXiv:2010.14864v1 [cs.LG])</h2>
<h3>Constantinos Daskalakis, Qinxuan Pan</h3>
<p>We provide the first polynomial-sample and polynomial-time algorithm for
learning tree-structured Ising models. In particular, we show that $n$-variable
tree-structured Ising models can be learned computationally-efficiently to
within total variation distance~$\epsilon$ from an optimal $O(n \log
n/\epsilon^2)$ samples, where $O(.)$ hides an absolute constant which does not
depend on the model being learned -- neither its tree nor the magnitude of its
edge strengths, on which we place no assumptions. Our guarantees hold, in fact,
for the celebrated Chow-Liu [1968] algorithm, using the plug-in estimator for
mutual information. While this (or any other) algorithm may fail to identify
the structure of the underlying model correctly from a finite sample, we show
that it will still learn a tree-structured model that is close to the true one
in TV distance, a guarantee called "proper learning."

Prior to our work there were no known sample- and time-efficient algorithms
for learning (properly or non-properly) arbitrary tree-structured graphical
models. In particular, our guarantees cannot be derived from known results for
the Chow-Liu algorithm and the ensuing literature on learning graphical models,
including a recent renaissance of algorithms on this learning challenge, which
only yield asymptotic consistency results, or sample-inefficient and/or
time-inefficient algorithms, unless further assumptions are placed on the
graphical model, such as bounds on the "strengths" of the model's edges. While
we establish guarantees for a widely known and simple algorithm, the analysis
that this algorithm succeeds is quite complex, requiring a hierarchical
classification of the edges into layers with different reconstruction
guarantees, depending on their strength, combined with delicate uses of the
subadditivity of the squared Hellinger distance over graphical models to
control the error accumulation.
</p>
<a href="http://arxiv.org/abs/2010.14864" target="_blank">arXiv:2010.14864</a> [<a href="http://arxiv.org/pdf/2010.14864" target="_blank">pdf</a>]

<h2>Finite-Time Analysis of Decentralized Stochastic Approximation with Applications in Multi-Agent and Multi-Task Learning. (arXiv:2010.15088v1 [cs.LG])</h2>
<h3>Sihan Zeng, Thinh T. Doan, Justin Romberg</h3>
<p>Stochastic approximation, a data-driven approach for finding the fixed point
of an unknown operator, provides a unified framework for treating many problems
in stochastic optimization and reinforcement learning. Motivated by a growing
interest in multi-agent and multi-task learning, we consider in this paper a
decentralized variant of stochastic approximation. A network of agents, each
with their own unknown operator and data observations, cooperatively find the
fixed point of the aggregate operator. The agents work by running a local
stochastic approximation algorithm using noisy samples from their operators
while averaging their iterates with their neighbors' on a decentralized
communication graph. Our main contribution provides a finite-time analysis of
this decentralized stochastic approximation algorithm and characterizes the
impacts of the underlying communication topology between agents. Our model for
the data observed at each agent is that it is sampled from a Markov processes;
this lack of independence makes the iterates biased and (potentially)
unbounded. Under mild assumptions on the Markov processes, we show that the
convergence rate of the proposed methods is essentially the same as if the
samples were independent, differing only by a log factor that represents the
mixing time of the Markov process. We also present applications of the proposed
method on a number of interesting learning problems in multi-agent systems,
including a decentralized variant of Q-learning for solving multi-task
reinforcement learning.
</p>
<a href="http://arxiv.org/abs/2010.15088" target="_blank">arXiv:2010.15088</a> [<a href="http://arxiv.org/pdf/2010.15088" target="_blank">pdf</a>]

<h2>On Graph Neural Networks versus Graph-Augmented MLPs. (arXiv:2010.15116v1 [cs.LG])</h2>
<h3>Lei Chen, Zhengdao Chen, Joan Bruna</h3>
<p>From the perspective of expressive power, this work compares multi-layer
Graph Neural Networks (GNNs) with a simplified alternative that we call
Graph-Augmented Multi-Layer Perceptrons (GA-MLPs), which first augments node
features with certain multi-hop operators on the graph and then applies an MLP
in a node-wise fashion. From the perspective of graph isomorphism testing, we
show both theoretically and numerically that GA-MLPs with suitable operators
can distinguish almost all non-isomorphic graphs, just like the
Weifeiler-Lehman (WL) test. However, by viewing them as node-level functions
and examining the equivalence classes they induce on rooted graphs, we prove a
separation in expressive power between GA-MLPs and GNNs that grows
exponentially in depth. In particular, unlike GNNs, GA-MLPs are unable to count
the number of attributed walks. We also demonstrate via community detection
experiments that GA-MLPs can be limited by their choice of operator family, as
compared to GNNs with higher flexibility in learning.
</p>
<a href="http://arxiv.org/abs/2010.15116" target="_blank">arXiv:2010.15116</a> [<a href="http://arxiv.org/pdf/2010.15116" target="_blank">pdf</a>]

<h2>Conformal Symplectic and Relativistic Optimization. (arXiv:1903.04100v6 [math.OC] UPDATED)</h2>
<h3>Guilherme Fran&#xe7;a, Jeremias Sulam, Daniel P. Robinson, Ren&#xe9; Vidal</h3>
<p>Arguably, the two most popular accelerated or momentum-based optimization
methods in machine learning are Nesterov's accelerated gradient and Polyaks's
heavy ball, both corresponding to different discretizations of a particular
second order differential equation with friction. Such connections with
continuous-time dynamical systems have been instrumental in demystifying
acceleration phenomena in optimization. Here we study structure-preserving
discretizations for a certain class of dissipative (conformal) Hamiltonian
systems, allowing us to analyze the symplectic structure of both Nesterov and
heavy ball, besides providing several new insights into these methods.
Moreover, we propose a new algorithm based on a dissipative relativistic system
that normalizes the momentum and may result in more stable/faster optimization.
Importantly, such a method generalizes both Nesterov and heavy ball, each being
recovered as distinct limiting cases, and has potential advantages at no
additional cost.
</p>
<a href="http://arxiv.org/abs/1903.04100" target="_blank">arXiv:1903.04100</a> [<a href="http://arxiv.org/pdf/1903.04100" target="_blank">pdf</a>]

<h2>A Method for Geodesic Distance on Subdivision of Trees with Arbitrary Orders and Their Applications. (arXiv:1909.13410v2 [math.CO] UPDATED)</h2>
<h3>Fei Ma, Ping Wang, Xudong Luo</h3>
<p>Geodesic distance, sometimes called shortest path length, has proven useful
in a great variety of applications, such as information retrieval on networks
including treelike networked models. Here, our goal is to analytically
determine the exact solutions to geodesic distances on two different families
of growth trees which are recursively created upon an arbitrary tree
$\mathcal{T}$ using two types of well-known operations, first-order subdivision
and ($1,m$)-star-fractal operation. Different from commonly-used methods, for
instance, spectral techniques, for addressing such a problem on growth trees
using a single edge as seed in the literature, we propose a novel method for
deriving closed-form solutions on the presented trees completely. Meanwhile,
our technique is more general and convenient to implement compared to those
previous methods mainly because there are not complicated calculations needed.
In addition, the closed-form expression of mean first-passage time ($MFPT$) for
random walk on each member in tree families is also readily obtained according
to connection of our obtained results to effective resistance of corresponding
electric networks. The results suggest that the two topological operations
above are sharply different from each other due to $MFPT$ for random walks,
and, however, have likely to show the similar performance, at least, on
geodesic distance.
</p>
<a href="http://arxiv.org/abs/1909.13410" target="_blank">arXiv:1909.13410</a> [<a href="http://arxiv.org/pdf/1909.13410" target="_blank">pdf</a>]

<h2>Morse shellability and triangulations. (arXiv:1910.13241v2 [math.AT] UPDATED)</h2>
<h3>Nermin Salepci (AGL), Jean-Yves Welschinger (AGL)</h3>
<p>We introduce a notion of Morse shellings (and tilings) on finite simplicial
complexes which extends the classical one and its relation to discrete Morse
theory.Skeletons and barycentric subdivisions of Morse shellable (or tileable)
simplicial complexes are Morse shellable (or tileable). Moreover, every
triangulated closed surface is Morse shellable while every closed
three-manifold carries Morse shellable triangulations. Finally, any shelling
encodes a class of discrete Morse functions whose critical points are in
one-to-one correspondence, preserving the index, with the critical tiles of the
shelling.
</p>
<a href="http://arxiv.org/abs/1910.13241" target="_blank">arXiv:1910.13241</a> [<a href="http://arxiv.org/pdf/1910.13241" target="_blank">pdf</a>]

<h2>Semialgebraic Optimization for Lipschitz Constants of ReLU Networks. (arXiv:2002.03657v4 [math.OC] UPDATED)</h2>
<h3>Tong Chen, Jean-Bernard Lasserre, Victor Magron, Edouard Pauwels</h3>
<p>The Lipschitz constant of a network plays an important role in many
applications of deep learning, such as robustness certification and Wasserstein
Generative Adversarial Network. We introduce a semidefinite programming
hierarchy to estimate the global and local Lipschitz constant of a multiple
layer deep neural network. The novelty is to combine a polynomial lifting for
ReLU functions derivatives with a weak generalization of Putinar's positivity
certificate. This idea could also apply to other, nearly sparse, polynomial
optimization problems in machine learning. We empirically demonstrate that our
method provides a trade-off with respect to state of the art linear programming
approach, and in some cases we obtain better bounds in less time.
</p>
<a href="http://arxiv.org/abs/2002.03657" target="_blank">arXiv:2002.03657</a> [<a href="http://arxiv.org/pdf/2002.03657" target="_blank">pdf</a>]

<h2>Chance-Constrained Trajectory Optimization for Safe Exploration and Learning of Nonlinear Systems. (arXiv:2005.04374v3 [cs.RO] UPDATED)</h2>
<h3>Yashwanth Kumar Nakka, Anqi Liu, Guanya Shi, Anima Anandkumar, Yisong Yue, Soon-Jo Chung</h3>
<p>Learning-based control algorithms require data collection with abundant
supervision for training. Safe exploration algorithms ensure the safety of this
data collection process even when only partial knowledge is available. We
present a new approach for optimal motion planning with safe exploration that
integrates chance-constrained stochastic optimal control with dynamics learning
and feedback control. We derive an iterative convex optimization algorithm that
solves an \underline{Info}rmation-cost \underline{S}tochastic
\underline{N}onlinear \underline{O}ptimal \underline{C}ontrol problem
(Info-SNOC). The optimization objective encodes control cost for performance
and exploration cost for learning, and the safety is incorporated as
distributionally robust chance constraints. The dynamics are predicted from a
robust regression model that is learned from data. The Info-SNOC algorithm is
used to compute a sub-optimal pool of safe motion plans that aid in exploration
for learning unknown residual dynamics under safety constraints. A stable
feedback controller is used to execute the motion plan and collect data for
model learning. We prove the safety of rollout from our exploration method and
reduction in uncertainty over epochs, thereby guaranteeing the consistency of
our learning method. We validate the effectiveness of Info-SNOC by designing
and implementing a pool of safe trajectories for a planar robot. We demonstrate
that our approach has higher success rate in ensuring safety when compared to a
deterministic trajectory optimization approach.
</p>
<a href="http://arxiv.org/abs/2005.04374" target="_blank">arXiv:2005.04374</a> [<a href="http://arxiv.org/pdf/2005.04374" target="_blank">pdf</a>]

<h2>Practical Quasi-Newton Methods for Training Deep Neural Networks. (arXiv:2006.08877v2 [cs.LG] UPDATED)</h2>
<h3>Donald Goldfarb, Yi Ren, Achraf Bahamou</h3>
<p>We consider the development of practical stochastic quasi-Newton, and in
particular Kronecker-factored block-diagonal BFGS and L-BFGS methods, for
training deep neural networks (DNNs). In DNN training, the number of variables
and components of the gradient $n$ is often of the order of tens of millions
and the Hessian has $n^2$ elements. Consequently, computing and storing a full
$n \times n$ BFGS approximation or storing a modest number of (step, change in
gradient) vector pairs for use in an L-BFGS implementation is out of the
question. In our proposed methods, we approximate the Hessian by a
block-diagonal matrix and use the structure of the gradient and Hessian to
further approximate these blocks, each of which corresponds to a layer, as the
Kronecker product of two much smaller matrices. This is analogous to the
approach in KFAC, which computes a Kronecker-factored block-diagonal
approximation to the Fisher matrix in a stochastic natural gradient method.
Because the indefinite and highly variable nature of the Hessian in a DNN, we
also propose a new damping approach to keep the upper as well as the lower
bounds of the BFGS and L-BFGS approximations bounded. In tests on autoencoder
feed-forward neural network models with either nine or thirteen layers applied
to three datasets, our methods outperformed or performed comparably to KFAC and
state-of-the-art first-order stochastic methods.
</p>
<a href="http://arxiv.org/abs/2006.08877" target="_blank">arXiv:2006.08877</a> [<a href="http://arxiv.org/pdf/2006.08877" target="_blank">pdf</a>]

<h2>Information theoretic limits of learning a sparse rule. (arXiv:2006.11313v2 [cs.IT] UPDATED)</h2>
<h3>Cl&#xe9;ment Luneau, Jean Barbier, Nicolas Macris</h3>
<p>We consider generalized linear models in regimes where the number of nonzero
components of the signal and accessible data points are sublinear with respect
to the size of the signal. We prove a variational formula for the asymptotic
mutual information per sample when the system size grows to infinity. This
result allows us to derive an expression for the minimum mean-square error
(MMSE) of the Bayesian estimator when the signal entries have a discrete
distribution with finite support. We find that, for such signals and suitable
vanishing scalings of the sparsity and sampling rate, the MMSE is nonincreasing
piecewise constant. In specific instances the MMSE even displays an
all-or-nothing phase transition, that is, the MMSE sharply jumps from its
maximum value to zero at a critical sampling rate. The all-or-nothing
phenomenon has previously been shown to occur in high-dimensional linear
regression. Our analysis goes beyond the linear case and applies to learning
the weights of a perceptron with general activation function in a
teacher-student scenario. In particular, we discuss an all-or-nothing
phenomenon for the generalization error with a sublinear set of training
examples.
</p>
<a href="http://arxiv.org/abs/2006.11313" target="_blank">arXiv:2006.11313</a> [<a href="http://arxiv.org/pdf/2006.11313" target="_blank">pdf</a>]

<h2>The State of Industrial Robotics: Emerging Technologies, Challenges, and Key Research Directions. (arXiv:2010.14537v1 [cs.RO])</h2>
<h3>Lindsay Sanneman, Christopher Fourie, Julie A. Shah</h3>
<p>Robotics and related technologies are central to the ongoing digitization and
advancement of manufacturing. In recent years, a variety of strategic
initiatives around the world including "Industry 4.0", introduced in Germany in
2011 have aimed to improve and connect manufacturing technologies in order to
optimize production processes. In this work, we study the changing
technological landscape of robotics and "internet-of-things" (IoT)-based
connective technologies over the last 7-10 years in the wake of Industry 4.0.
We interviewed key players within the European robotics ecosystem, including
robotics manufacturers and integrators, original equipment manufacturers
(OEMs), and applied industrial research institutions and synthesize our
findings in this paper. We first detail the state-of-the-art robotics and IoT
technologies we observed and that the companies discussed during our
interviews. We then describe the processes the companies follow when deciding
whether and how to integrate new technologies, the challenges they face when
integrating these technologies, and some immediate future technological avenues
they are exploring in robotics and IoT. Finally, based on our findings, we
highlight key research directions for the robotics community that can enable
improved capabilities in the context of manufacturing.
</p>
<a href="http://arxiv.org/abs/2010.14537" target="_blank">arXiv:2010.14537</a> [<a href="http://arxiv.org/pdf/2010.14537" target="_blank">pdf</a>]

<h2>Perception for Autonomous Systems (PAZ). (arXiv:2010.14541v1 [cs.CV])</h2>
<h3>Octavio Arriaga, Matias Valdenegro-Toro, Mohandass Muthuraja, Sushma Devaramani, Frank Kirchner</h3>
<p>In this paper we introduce the Perception for Autonomous Systems (PAZ)
software library. PAZ is a hierarchical perception library that allow users to
manipulate multiple levels of abstraction in accordance to their requirements
or skill level. More specifically, PAZ is divided into three hierarchical
levels which we refer to as pipelines, processors, and backends. These
abstractions allows users to compose functions in a hierarchical modular scheme
that can be applied for preprocessing, data-augmentation, prediction and
postprocessing of inputs and outputs of machine learning (ML) models. PAZ uses
these abstractions to build reusable training and prediction pipelines for
multiple robot perception tasks such as: 2D keypoint estimation, 2D object
detection, 3D keypoint discovery, 6D pose estimation, emotion classification,
face recognition, instance segmentation, and attention mechanisms.
</p>
<a href="http://arxiv.org/abs/2010.14541" target="_blank">arXiv:2010.14541</a> [<a href="http://arxiv.org/pdf/2010.14541" target="_blank">pdf</a>]

<h2>Unsupervised Domain Adaptation for Visual Navigation. (arXiv:2010.14543v1 [cs.LG])</h2>
<h3>Shangda Li, Devendra Singh Chaplot, Yao-Hung Hubert Tsai, Yue Wu, Louis-Philippe Morency, Ruslan Salakhutdinov</h3>
<p>Advances in visual navigation methods have led to intelligent embodied
navigation agents capable of learning meaningful representations from raw RGB
images and perform a wide variety of tasks involving structural and semantic
reasoning. However, most learning-based navigation policies are trained and
tested in simulation environments. In order for these policies to be
practically useful, they need to be transferred to the real-world. In this
paper, we propose an unsupervised domain adaptation method for visual
navigation. Our method translates the images in the target domain to the source
domain such that the translation is consistent with the representations learned
by the navigation policy. The proposed method outperforms several baselines
across two different navigation tasks in simulation. We further show that our
method can be used to transfer the navigation policies learned in simulation to
the real world.
</p>
<a href="http://arxiv.org/abs/2010.14543" target="_blank">arXiv:2010.14543</a> [<a href="http://arxiv.org/pdf/2010.14543" target="_blank">pdf</a>]

<h2>Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning. (arXiv:2010.14551v1 [cs.CV])</h2>
<h3>Iro Laina, Ruth C. Fong, Andrea Vedaldi</h3>
<p>The increasing impact of black box models, and particularly of unsupervised
ones, comes with an increasing interest in tools to understand and interpret
them. In this paper, we consider in particular how to characterise visual
groupings discovered automatically by deep neural networks, starting with
state-of-the-art clustering methods. In some cases, clusters readily correspond
to an existing labelled dataset. However, often they do not, yet they still
maintain an "intuitive interpretability". We introduce two concepts, visual
learnability and describability, that can be used to quantify the
interpretability of arbitrary image groupings, including unsupervised ones. The
idea is to measure (1) how well humans can learn to reproduce a grouping by
measuring their ability to generalise from a small set of visual examples
(learnability) and (2) whether the set of visual examples can be replaced by a
succinct, textual description (describability). By assessing human annotators
as classifiers, we remove the subjective quality of existing evaluation
metrics. For better scalability, we finally propose a class-level captioning
system to generate descriptions for visual groupings automatically and compare
it to human annotators using the describability metric.
</p>
<a href="http://arxiv.org/abs/2010.14551" target="_blank">arXiv:2010.14551</a> [<a href="http://arxiv.org/pdf/2010.14551" target="_blank">pdf</a>]

<h2>Remixing Music with Visual Conditioning. (arXiv:2010.14565v1 [cs.SD])</h2>
<h3>Li-Chia Yang, Alexander Lerch</h3>
<p>We propose a visually conditioned music remixing system by incorporating deep
visual and audio models. The method is based on a state of the art audio-visual
source separation model which performs music instrument source separation with
video information. We modified the model to work with user-selected images
instead of videos as visual input during inference to enable separation of
audio-only content. Furthermore, we propose a remixing engine that generalizes
the task of source separation into music remixing. The proposed method is able
to achieve improved audio quality compared to remixing performed by the
separate-and-add method with a state-of-the-art audio-visual source separation
model.
</p>
<a href="http://arxiv.org/abs/2010.14565" target="_blank">arXiv:2010.14565</a> [<a href="http://arxiv.org/pdf/2010.14565" target="_blank">pdf</a>]

<h2>Strongly Incremental Constituency Parsing with Graph Neural Networks. (arXiv:2010.14568v1 [cs.CL])</h2>
<h3>Kaiyu Yang, Jia Deng</h3>
<p>Parsing sentences into syntax trees can benefit downstream applications in
NLP. Transition-based parsers build trees by executing actions in a state
transition system. They are computationally efficient, and can leverage machine
learning to predict actions based on partial trees. However, existing
transition-based parsers are predominantly based on the shift-reduce transition
system, which does not align with how humans are known to parse sentences.
Psycholinguistic research suggests that human parsing is strongly incremental:
humans grow a single parse tree by adding exactly one token at each step. In
this paper, we propose a novel transition system called attach-juxtapose. It is
strongly incremental; it represents a partial sentence using a single tree;
each action adds exactly one token into the partial tree. Based on our
transition system, we develop a strongly incremental parser. At each step, it
encodes the partial tree using a graph neural network and predicts an action.
We evaluate our parser on Penn Treebank (PTB) and Chinese Treebank (CTB). On
PTB, it outperforms existing parsers trained with only constituency trees; and
it performs on par with state-of-the-art parsers that use dependency trees as
additional training data. On CTB, our parser establishes a new state of the
art. Code is available at
https://github.com/princeton-vl/attach-juxtapose-parser.
</p>
<a href="http://arxiv.org/abs/2010.14568" target="_blank">arXiv:2010.14568</a> [<a href="http://arxiv.org/pdf/2010.14568" target="_blank">pdf</a>]

<h2>Addressing Purchase-Impression Gap through a Sequential Re-ranker. (arXiv:2010.14570v1 [cs.IR])</h2>
<h3>Shubhangi Tandon, Saratchandra Indrakanti, Amit Jaiswal, Svetlana Strunjas, Manojkumar Rangasamy Kannadasan</h3>
<p>Large scale eCommerce platforms such as eBay carry a wide variety of
inventory and provide several buying choices to online shoppers. It is critical
for eCommerce search engines to showcase in the top results the variety and
selection of inventory available, specifically in the context of the various
buying intents that may be associated with a search query. Search rankers are
most commonly powered by learning-to-rank models which learn the preference
between items during training. However, they score items independent of other
items at runtime. Although the items placed at top of the results by such
scoring functions may be independently optimal, they can be sub-optimal as a
set. This may lead to a mismatch between the ideal distribution of items in the
top results vs what is actually impressed. In this paper, we present methods to
address the purchase-impression gap observed in top search results on eCommerce
sites. We establish the ideal distribution of items based on historic shopping
patterns. We then present a sequential reranker that methodically reranks top
search results produced by a conventional pointwise scoring ranker. The
reranker produces a reordered list by sequentially selecting candidates trading
off between their independent relevance and potential to address the
purchase-impression gap by utilizing specially constructed features that
capture impression distribution of items already added to a reranked list. The
sequential reranker enables addressing purchase impression gap with respect to
multiple item aspects. Early version of the reranker showed promising lifts in
conversion and engagement metrics at eBay. Based on experiments on randomly
sampled validation datasets, we observe that the reranking methodology
presented produces around 10% reduction in purchase-impression gap at an
average for the top 20 results, while making improvements to conversion
metrics.
</p>
<a href="http://arxiv.org/abs/2010.14570" target="_blank">arXiv:2010.14570</a> [<a href="http://arxiv.org/pdf/2010.14570" target="_blank">pdf</a>]

<h2>Learning Time Reduction Using Warm Start Methods for a Reinforcement Learning Based Supervisory Control in Hybrid Electric Vehicle Applications. (arXiv:2010.14575v1 [cs.RO])</h2>
<h3>Bin Xu, Jun Hou, Junzhe Shi, Huayi Li, Dhruvang Rathod, Zhe Wang, Zoran Filipi</h3>
<p>Reinforcement Learning (RL) is widely utilized in the field of robotics, and
as such, it is gradually being implemented in the Hybrid Electric Vehicle (HEV)
supervisory control. Even though RL exhibits excellent performance in terms of
fuel consumption minimization in simulation, the large learning iteration
number needs a long learning time, making it hardly applicable in real-world
vehicles. In addition, the fuel consumption of initial learning phases is much
worse than baseline controls. This study aims to reduce the learning iterations
of Q-learning in HEV application and improve fuel consumption in initial
learning phases utilizing warm start methods. Different from previous studies,
which initiated Q-learning with zero or random Q values, this study initiates
the Q-learning with different supervisory controls (i.e., Equivalent
Consumption Minimization Strategy control and heuristic control), and detailed
analysis is given. The results show that the proposed warm start Q-learning
requires 68.8% fewer iterations than cold start Q-learning. The trained
Q-learning is validated in two different driving cycles, and the results show
10-16% MPG improvement when compared to Equivalent Consumption Minimization
Strategy control. Furthermore, real-time feasibility is analyzed, and the
guidance of vehicle implementation is provided. The results of this study can
be used to facilitate the deployment of RL in vehicle supervisory control
applications.
</p>
<a href="http://arxiv.org/abs/2010.14575" target="_blank">arXiv:2010.14575</a> [<a href="http://arxiv.org/pdf/2010.14575" target="_blank">pdf</a>]

<h2>HOPPY: An open-source and low-cost kit for dynamic robotics education. (arXiv:2010.14580v1 [cs.RO])</h2>
<h3>Joao Ramos, Yanran Ding, Young-woo Sim, Kevin Murphy, Daniel Block</h3>
<p>This letter introduces HOPPY, an open-source, low-cost, robust, and modular
kit for robotics education. The robot dynamically hops around a rotating gantry
with a fixed base. The kit lowers the entry barrier for studying dynamic robots
and legged locomotion in real systems. The kit bridges the theoretical content
of fundamental robotic courses and real dynamic robots by facilitating and
guiding the software and hardware integration. This letter describes the topics
which can be studied using the kit, lists its components, discusses best
practices for implementation, presents results from experiments with the
simulator and the real system, and suggests further improvements. A simple
controller is described to achieve velocities up to 2m/s, navigate small
objects, and mitigate external disturbances (kicks). HOPPY was utilized as the
topic of a semester-long project for the Robot Dynamics and Control course at
the University of Illinois at Urbana-Champaign. Students provided an
overwhelmingly positive feedback from the hands-on activities during the course
and the instructors will continue to improve the kit for upcoming semesters.
</p>
<a href="http://arxiv.org/abs/2010.14580" target="_blank">arXiv:2010.14580</a> [<a href="http://arxiv.org/pdf/2010.14580" target="_blank">pdf</a>]

<h2>Predicting Themes within Complex Unstructured Texts: A Case Study on Safeguarding Reports. (arXiv:2010.14584v1 [cs.CL])</h2>
<h3>Aleksandra Edwards, David Rogers, Jose Camacho-Collados, H&#xe9;l&#xe8;ne de Ribaupierre</h3>
<p>The task of text and sentence classification is associated with the need for
large amounts of labelled training data. The acquisition of high volumes of
labelled datasets can be expensive or unfeasible, especially for
highly-specialised domains for which documents are hard to obtain. Research on
the application of supervised classification based on small amounts of training
data is limited. In this paper, we address the combination of state-of-the-art
deep learning and classification methods and provide an insight into what
combination of methods fit the needs of small, domain-specific, and
terminologically-rich corpora. We focus on a real-world scenario related to a
collection of safeguarding reports comprising learning experiences and
reflections on tackling serious incidents involving children and vulnerable
adults. The relatively small volume of available reports and their use of
highly domain-specific terminology makes the application of automated
approaches difficult. We focus on the problem of automatically identifying the
main themes in a safeguarding report using supervised classification
approaches. Our results show the potential of deep learning models to simulate
subject-expert behaviour even for complex tasks with limited labelled data.
</p>
<a href="http://arxiv.org/abs/2010.14584" target="_blank">arXiv:2010.14584</a> [<a href="http://arxiv.org/pdf/2010.14584" target="_blank">pdf</a>]

<h2>On the diminishing return of labeling clinical reports. (arXiv:2010.14587v1 [cs.CL])</h2>
<h3>Jean-Baptiste Lamare, Tobi Olatunji, Li Yao</h3>
<p>Ample evidence suggests that better machine learning models may be steadily
obtained by training on increasingly larger datasets on natural language
processing (NLP) problems from non-medical domains. Whether the same holds true
for medical NLP has by far not been thoroughly investigated. This work shows
that this is indeed not always the case. We reveal the somehow
counter-intuitive observation that performant medical NLP models may be
obtained with small amount of labeled data, quite the opposite to the common
belief, most likely due to the domain specificity of the problem. We show
quantitatively the effect of training data size on a fixed test set composed of
two of the largest public chest x-ray radiology report datasets on the task of
abnormality classification. The trained models not only make use of the
training data efficiently, but also outperform the current state-of-the-art
rule-based systems by a significant margin.
</p>
<a href="http://arxiv.org/abs/2010.14587" target="_blank">arXiv:2010.14587</a> [<a href="http://arxiv.org/pdf/2010.14587" target="_blank">pdf</a>]

<h2>Nested Grassmanns for Dimensionality Reduction. (arXiv:2010.14589v1 [cs.CV])</h2>
<h3>Chun-Hao Yang, Baba C. Vemuri</h3>
<p>Grassmann manifolds have been widely used to represent the geometry of
feature spaces in a variety of problems in computer vision including but not
limited to face recognition, action recognition, subspace clustering and motion
segmentation. For these problems, the features usually lie in a very
high-dimensional Grassmann manifold and hence an appropriate dimensionality
reduction technique is called for in order to curtail the computational burden.
To this end, the Principal Geodesic Analysis (PGA), a nonlinear extension of
the well known principal component analysis, is applicable as a general tool to
many Riemannian manifolds. In this paper, we propose a novel dimensionality
reduction framework suited for Grassmann manifolds by utilizing the geometry of
the manifold. Specifically, we project points in a Grassmann manifold to an
embedded lower dimensional Grassmann manifold. A salient feature of our method
is that it leads to higher expressed variance compared to PGA which we
demonstrate via synthetic and real data experiments.
</p>
<a href="http://arxiv.org/abs/2010.14589" target="_blank">arXiv:2010.14589</a> [<a href="http://arxiv.org/pdf/2010.14589" target="_blank">pdf</a>]

<h2>Shapley Flow: A Graph-based Approach to Interpreting Model Predictions. (arXiv:2010.14592v1 [cs.LG])</h2>
<h3>Jiaxuan Wang, Jenna Wiens, Scott Lundberg</h3>
<p>Many existing approaches for estimating feature importance are problematic
because they ignore or hide dependencies among features. A causal graph, which
encodes the relationships among input variables, can aid in assigning feature
importance. However, current approaches that assign credit to nodes in the
causal graph fail to explain the entire graph. In light of these limitations,
we propose Shapley Flow, a novel approach to interpreting machine learning
models. It considers the entire causal graph, and assigns credit to
\textit{edges} instead of treating nodes as the fundamental unit of credit
assignment. Shapley Flow is the unique solution to a generalization of the
Shapley value axioms to directed acyclic graphs. We demonstrate the benefit of
using Shapley Flow to reason about the impact of a model's input on its output.
In addition to maintaining insights from existing approaches, Shapley Flow
extends the flat, set-based, view prevalent in game theory based explanation
methods to a deeper, \textit{graph-based}, view. This graph-based view enables
users to understand the flow of importance through a system, and reason about
potential interventions.
</p>
<a href="http://arxiv.org/abs/2010.14592" target="_blank">arXiv:2010.14592</a> [<a href="http://arxiv.org/pdf/2010.14592" target="_blank">pdf</a>]

<h2>Learning to Generate Cost-to-Go Functions for Efficient Motion Planning. (arXiv:2010.14597v1 [cs.RO])</h2>
<h3>Jinwook Huh, Galen Xing, Ziyun Wang, Volkan Isler, Daniel D. Lee</h3>
<p>Traditional motion planning is computationally burdensome for practical
robots, involving extensive collision checking and considerable iterative
propagation of cost values. We present a novel neural network architecture
which can directly generate the cost-to-go (c2g) function for a given
configuration space and a goal configuration. The output of the network is a
continuous function whose gradient in configuration space can be directly used
to generate trajectories in motion planning without the need for protracted
iterations or extensive collision checking. This higher order function (i.e. a
function generating another function) representation lies at the core of our
motion planning architecture, c2g-HOF, which can take a workspace as input, and
generate the cost-to-go function over the configuration space map (C-map).
Simulation results for 2D and 3D environments show that c2g-HOF can be orders
of magnitude faster at execution time than methods which explore the
configuration space during execution. We also present an implementation of
c2g-HOF which generates trajectories for robot manipulators directly from an
overhead image of the workspace.
</p>
<a href="http://arxiv.org/abs/2010.14597" target="_blank">arXiv:2010.14597</a> [<a href="http://arxiv.org/pdf/2010.14597" target="_blank">pdf</a>]

<h2>CopyPaste: An Augmentation Method for Speech Emotion Recognition. (arXiv:2010.14602v1 [cs.SD])</h2>
<h3>Raghavendra Pappagari, Jes&#xfa;s Villalba, Piotr &#x17b;elasko, Laureano Moro-Velazquez, Najim Dehak</h3>
<p>Data augmentation is a widely used strategy for training robust machine
learning models. It partially alleviates the problem of limited data for tasks
like speech emotion recognition (SER), where collecting data is expensive and
challenging. This study proposes CopyPaste, a perceptually motivated novel
augmentation procedure for SER. Assuming that the presence of emotions other
than neutral dictates a speaker's overall perceived emotion in a recording,
concatenation of an emotional (emotion E) and a neutral utterance can still be
labeled with emotion E. We hypothesize that SER performance can be improved
using these concatenated utterances in model training. To verify this, three
CopyPaste schemes are tested on two deep learning models: one trained
independently and another using transfer learning from an x-vector model, a
speaker recognition model. We observed that all three CopyPaste schemes improve
SER performance on all the three datasets considered: MSP-Podcast, Crema-D, and
IEMOCAP. Additionally, CopyPaste performs better than noise augmentation and,
using them together improves the SER performance further. Our experiments on
noisy test sets suggested that CopyPaste is effective even in noisy test
conditions.
</p>
<a href="http://arxiv.org/abs/2010.14602" target="_blank">arXiv:2010.14602</a> [<a href="http://arxiv.org/pdf/2010.14602" target="_blank">pdf</a>]

<h2>Learning to be Safe: Deep RL with a Safety Critic. (arXiv:2010.14603v1 [cs.LG])</h2>
<h3>Krishnan Srinivasan, Benjamin Eysenbach, Sehoon Ha, Jie Tan, Chelsea Finn</h3>
<p>Safety is an essential component for deploying reinforcement learning (RL)
algorithms in real-world scenarios, and is critical during the learning process
itself. A natural first approach toward safe RL is to manually specify
constraints on the policy's behavior. However, just as learning has enabled
progress in large-scale development of AI systems, learning safety
specifications may also be necessary to ensure safety in messy open-world
environments where manual safety specifications cannot scale. Akin to how
humans learn incrementally starting in child-safe environments, we propose to
learn how to be safe in one set of tasks and environments, and then use that
learned intuition to constrain future behaviors when learning new, modified
tasks. We empirically study this form of safety-constrained transfer learning
in three challenging domains: simulated navigation, quadruped locomotion, and
dexterous in-hand manipulation. In comparison to standard deep RL techniques
and prior approaches to safe RL, we find that our method enables the learning
of new tasks and in new environments with both substantially fewer safety
incidents, such as falling or dropping an object, and faster, more stable
learning. This suggests a path forward not only for safer RL systems, but also
for more effective RL systems.
</p>
<a href="http://arxiv.org/abs/2010.14603" target="_blank">arXiv:2010.14603</a> [<a href="http://arxiv.org/pdf/2010.14603" target="_blank">pdf</a>]

<h2>Beyond Accuracy: Cost-Aware Data Representation Exploration for Network Traffic Model Performance. (arXiv:2010.14605v1 [cs.NI])</h2>
<h3>Francesco Bronzino, Paul Schmitt, Sara Ayoubi, Hyojoon Kim, Renata Teixeira, Nick Feamster</h3>
<p>In this paper, we explore how different representations of network traffic
affect the performance of machine learning models for a range of network
management tasks, including application performance diagnosis and attack
detection. We study the relationship between the systems-level costs of
different representations of network traffic to the ultimate target performance
metric -- e.g., accuracy -- of the models trained from these representations.
We demonstrate the benefit of exploring a range of representations of network
traffic and present Network Microscope, a proof-of-concept reference
implementation that both monitors network traffic at high speed and transforms
the traffic in real time to produce a variety of representations for input to
machine learning models. Systems like Network Microscope can ultimately help
network operators better explore the design space of data representation for
learning, balancing systems costs related to feature extraction and model
training against resulting model performance.
</p>
<a href="http://arxiv.org/abs/2010.14605" target="_blank">arXiv:2010.14605</a> [<a href="http://arxiv.org/pdf/2010.14605" target="_blank">pdf</a>]

<h2>Deformable Convolutional LSTM for Human Body Emotion Recognition. (arXiv:2010.14607v1 [cs.CV])</h2>
<h3>Peyman Tahghighi, Abbas Koochari, Masoume Jalali</h3>
<p>People represent their emotions in a myriad of ways. Among the most important
ones is whole body expressions which have many applications in different fields
such as human-computer interaction (HCI). One of the most important challenges
in human emotion recognition is that people express the same feeling in various
ways using their face and their body. Recently many methods have tried to
overcome these challenges using Deep Neural Networks (DNNs). However, most of
these methods were based on images or on facial expressions only and did not
consider deformation that may happen in the images such as scaling and rotation
which can adversely affect the recognition accuracy. In this work, motivated by
recent researches on deformable convolutions, we incorporate the deformable
behavior into the core of convolutional long short-term memory (ConvLSTM) to
improve robustness to these deformations in the image and, consequently,
improve its accuracy on the emotion recognition task from videos of arbitrary
length. We did experiments on the GEMEP dataset and achieved state-of-the-art
accuracy of 98.8% on the task of whole human body emotion recognition on the
validation set.
</p>
<a href="http://arxiv.org/abs/2010.14607" target="_blank">arXiv:2010.14607</a> [<a href="http://arxiv.org/pdf/2010.14607" target="_blank">pdf</a>]

<h2>Hybrid Backpropagation Parallel Reservoir Networks. (arXiv:2010.14611v1 [cs.NE])</h2>
<h3>Matthew Evanusa, Snehesh Shrestha, Michelle Girvan, Cornelia Ferm&#xfc;ller, Yiannis Aloimonos</h3>
<p>In many real-world applications, fully-differentiable RNNs such as LSTMs and
GRUs have been widely deployed to solve time series learning tasks. These
networks train via Backpropagation Through Time, which can work well in
practice but involves a biologically unrealistic unrolling of the network in
time for gradient updates, are computationally expensive, and can be hard to
tune. A second paradigm, Reservoir Computing, keeps the recurrent weight matrix
fixed and random. Here, we propose a novel hybrid network, which we call Hybrid
Backpropagation Parallel Echo State Network (HBP-ESN) which combines the
effectiveness of learning random temporal features of reservoirs with the
readout power of a deep neural network with batch normalization. We demonstrate
that our new network outperforms LSTMs and GRUs, including multi-layer "deep"
versions of these networks, on two complex real-world multi-dimensional time
series datasets: gesture recognition using skeleton keypoints from ChaLearn,
and the DEAP dataset for emotion recognition from EEG measurements. We show
also that the inclusion of a novel meta-ring structure, which we call HBP-ESN
M-Ring, achieves similar performance to one large reservoir while decreasing
the memory required by an order of magnitude. We thus offer this new hybrid
reservoir deep learning paradigm as a new alternative direction for RNN
learning of temporal or sequential data.
</p>
<a href="http://arxiv.org/abs/2010.14611" target="_blank">arXiv:2010.14611</a> [<a href="http://arxiv.org/pdf/2010.14611" target="_blank">pdf</a>]

<h2>Lineage Evolution Reinforcement Learning. (arXiv:2010.14616v1 [cs.NE])</h2>
<h3>Zeyu Zhang, Guisheng Yin</h3>
<p>We propose a general agent population learning system, and on this basis, we
propose lineage evolution reinforcement learning algorithm. Lineage evolution
reinforcement learning is a kind of derivative algorithm which accords with the
general agent population learning system. We take the agents in DQN and its
related variants as the basic agents in the population, and add the selection,
mutation and crossover modules in the genetic algorithm to the reinforcement
learning algorithm. In the process of agent evolution, we refer to the
characteristics of natural genetic behavior, add lineage factor to ensure the
retention of potential performance of agent, and comprehensively consider the
current performance and lineage value when evaluating the performance of agent.
Without changing the parameters of the original reinforcement learning
algorithm, lineage evolution reinforcement learning can optimize different
reinforcement learning algorithms. Our experiments show that the idea of
evolution with lineage improves the performance of original reinforcement
learning algorithm in some games in Atari 2600.
</p>
<a href="http://arxiv.org/abs/2010.14616" target="_blank">arXiv:2010.14616</a> [<a href="http://arxiv.org/pdf/2010.14616" target="_blank">pdf</a>]

<h2>From Artificial Intelligence to Brain Intelligence: The basis learning and memory algorithm for brain-like intelligence. (arXiv:2010.14617v1 [cs.NE])</h2>
<h3>Yifei Mao</h3>
<p>The algorithm of brain learning and memory is still undetermined. The
backpropagation algorithm of artificial neural networks was thought not
suitable for brain cortex, and there is a lack of algorithm for memory engram.
We designed a brain version of backpropagation algorithm, which are
biologically plausible and could be implemented with virtual neurons to
complete image classification task. An encoding algorithm that can
automatically allocate engram cells is proposed, which is an algorithm
implementation for memory engram theory, and could simulate how hippocampus
achieve fast associative memory. The role of the LTP and LTD in the cerebellum
is also explained in algorithm level. Our results proposed a method for the
brain to deploy backpropagation algorithm, and sparse coding method for memory
engram theory.
</p>
<a href="http://arxiv.org/abs/2010.14617" target="_blank">arXiv:2010.14617</a> [<a href="http://arxiv.org/pdf/2010.14617" target="_blank">pdf</a>]

<h2>A computationally and cognitively plausible model of supervised and unsupervised learning. (arXiv:2010.14618v1 [cs.NE])</h2>
<h3>David M W Powers</h3>
<p>Both empirical and mathematical demonstrations of the importance of
chance-corrected measures are discussed, and a new model of learning is
proposed based on empirical psychological results on association learning. Two
forms of this model are developed, the Informatron as a chance-corrected
Perceptron, and AdaBook as a chance-corrected AdaBoost procedure. Computational
results presented show chance correction facilitates learning.
</p>
<a href="http://arxiv.org/abs/2010.14618" target="_blank">arXiv:2010.14618</a> [<a href="http://arxiv.org/pdf/2010.14618" target="_blank">pdf</a>]

<h2>Ensembles of Spiking Neural Networks. (arXiv:2010.14619v1 [cs.NE])</h2>
<h3>Georgiana Neculae, Gavin Brown</h3>
<p>This paper demonstrates that ensembles of spiking neural networks can be
constructed so that the ensemble performance is guaranteed to be better than
the average performance of a single model. Spiking neural networks have not
challenged the performance obtained by conventional neural networks on the same
problems. Ensemble learning is a framework that has been used extensively to
improve the performance of machine learning models. In this paper, we show how
to construct ensembles of spiking neural networks that both produce
state-of-the-art results, and achieve this with less than 50% of the parameters
of the original models. We establish the methodology on combining model
predictions such that performance improvements are guaranteed for spiking
ensembles. For this, we formalize spiking neural networks as GLM predictors,
identifying a suitable representation for their target domain. Further, we show
how the diversity of our spiking ensembles can be measured using the Ambiguity
Decomposition.
</p>
<a href="http://arxiv.org/abs/2010.14619" target="_blank">arXiv:2010.14619</a> [<a href="http://arxiv.org/pdf/2010.14619" target="_blank">pdf</a>]

<h2>Improving Text Relationship Modeling with Artificial Data. (arXiv:2010.14640v1 [cs.DL])</h2>
<h3>Peter Organisciak, Maggie Ryan</h3>
<p>Data augmentation uses artificially-created examples to support supervised
machine learning, adding robustness to the resulting models and helping to
account for limited availability of labelled data. We apply and evaluate a
synthetic data approach to relationship classification in digital libraries,
generating artificial books with relationships that are common in digital
libraries but not easier inferred from existing metadata. We find that for
classification on whole-part relationships between books, synthetic data
improves a deep neural network classifier by 91%. Further, we consider the
ability of synthetic data to learn a useful new text relationship class from
fully artificial training data.
</p>
<a href="http://arxiv.org/abs/2010.14640" target="_blank">arXiv:2010.14640</a> [<a href="http://arxiv.org/pdf/2010.14640" target="_blank">pdf</a>]

<h2>Learning to Plan Optimistically: Uncertainty-Guided Deep Exploration via Latent Model Ensembles. (arXiv:2010.14641v1 [cs.LG])</h2>
<h3>Tim Seyde, Wilko Schwarting, Sertac Karaman, Daniela Rus</h3>
<p>Learning complex behaviors through interaction requires coordinated long-term
planning. Random exploration and novelty search lack task-centric guidance and
waste effort on non-informative interactions. Instead, decision making should
target samples with the potential to optimize performance far into the future,
while only reducing uncertainty where conducive to this objective. This paper
presents latent optimistic value exploration (LOVE), a strategy that enables
deep exploration through optimism in the face of uncertain long-term rewards.
We combine finite horizon rollouts from a latent model with value function
estimates to predict infinite horizon returns and recover associated
uncertainty through ensembling. Policy training then proceeds on an upper
confidence bound (UCB) objective to identify and select the interactions most
promising to improve long-term performance. We apply LOVE to visual control
tasks in continuous state-action spaces and demonstrate improved sample
complexity on a selection of benchmarking tasks.
</p>
<a href="http://arxiv.org/abs/2010.14641" target="_blank">arXiv:2010.14641</a> [<a href="http://arxiv.org/pdf/2010.14641" target="_blank">pdf</a>]

<h2>Learning Contextualised Cross-lingual Word Embeddings for Extremely Low-Resource Languages Using Parallel Corpora. (arXiv:2010.14649v1 [cs.CL])</h2>
<h3>Takashi Wada, Tomoharu Iwata, Yuji Matsumoto, Timothy Baldwin, Jey Han Lau</h3>
<p>We propose a new approach for learning contextualised cross-lingual word
embeddings based only on a small parallel corpus (e.g. a few hundred sentence
pairs). Our method obtains word embeddings via an LSTM-based encoder-decoder
model that performs bidirectional translation and reconstruction of the input
sentence. Through sharing model parameters among different languages, our model
jointly trains the word embeddings in a common multilingual space. We also
propose a simple method to combine word and subword embeddings to make use of
orthographic similarities across different languages. We base our experiments
on real-world data from endangered languages, namely Yongning Na,
Shipibo-Konibo and Griko. Our experiments on bilingual lexicon induction and
word alignment tasks show that our model outperforms existing methods by a
large margin for most language pairs. These results demonstrate that, contrary
to common belief, an encoder-decoder translation model is beneficial for
learning cross-lingual representations, even in extremely low-resource
scenarios.
</p>
<a href="http://arxiv.org/abs/2010.14649" target="_blank">arXiv:2010.14649</a> [<a href="http://arxiv.org/pdf/2010.14649" target="_blank">pdf</a>]

<h2>Temporal Difference Learning as Gradient Splitting. (arXiv:2010.14657v1 [cs.LG])</h2>
<h3>Rui Liu, Alex Olshevsky</h3>
<p>Temporal difference learning with linear function approximation is a popular
method to obtain a low-dimensional approximation of the value function of a
policy in a Markov Decision Process. We give a new interpretation of this
method in terms of a splitting of the gradient of an appropriately chosen
function. As a consequence of this interpretation, convergence proofs for
gradient descent can be applied almost verbatim to temporal difference
learning. Beyond giving a new, fuller explanation of why temporal difference
works, our interpretation also yields improved convergence times. We consider
the setting with $1/\sqrt{T}$ step-size, where previous comparable finite-time
convergence time bounds for temporal difference learning had the multiplicative
factor $1/(1-\gamma)$ in front of the bound, with $\gamma$ being the discount
factor. We show that a minor variation on TD learning which estimates the mean
of the value function separately has a convergence time where $1/(1-\gamma)$
only multiplies an asymptotically negligible term.
</p>
<a href="http://arxiv.org/abs/2010.14657" target="_blank">arXiv:2010.14657</a> [<a href="http://arxiv.org/pdf/2010.14657" target="_blank">pdf</a>]

<h2>DualTKB: A Dual Learning Bridge between Text and Knowledge Base. (arXiv:2010.14660v1 [cs.CL])</h2>
<h3>Pierre L. Dognin, Igor Melnyk, Inkit Padhi, Cicero Nogueira dos Santos, Payel Das</h3>
<p>In this work, we present a dual learning approach for unsupervised text to
path and path to text transfers in Commonsense Knowledge Bases (KBs). We
investigate the impact of weak supervision by creating a weakly supervised
dataset and show that even a slight amount of supervision can significantly
improve the model performance and enable better-quality transfers. We examine
different model architectures, and evaluation metrics, proposing a novel
Commonsense KB completion metric tailored for generative models. Extensive
experimental results show that the proposed method compares very favorably to
the existing baselines. This approach is a viable step towards a more advanced
system for automatic KB construction/expansion and the reverse operation of KB
conversion to coherent textual descriptions.
</p>
<a href="http://arxiv.org/abs/2010.14660" target="_blank">arXiv:2010.14660</a> [<a href="http://arxiv.org/pdf/2010.14660" target="_blank">pdf</a>]

<h2>System Identification via Meta-Learning in Linear Time-Varying Environments. (arXiv:2010.14664v1 [cs.LG])</h2>
<h3>Sen Lin, Hang Wang, Junshan Zhang</h3>
<p>System identification is a fundamental problem in reinforcement learning,
control theory and signal processing, and the non-asymptotic analysis of the
corresponding sample complexity is challenging and elusive, even for linear
time-varying (LTV) systems. To tackle this challenge, we develop an episodic
block model for the LTV system where the model parameters remain constant
within each block but change from block to block. Based on the observation that
the model parameters across different blocks are related, we treat each
episodic block as a learning task and then run meta-learning over many blocks
for system identification, using two steps, namely offline meta-learning and
online adaptation. We carry out a comprehensive non-asymptotic analysis of the
performance of meta-learning based system identification. To deal with the
technical challenges rooted in the sample correlation and small sample sizes in
each block, we devise a new two-scale martingale small-ball approach for
offline meta-learning, for arbitrary model correlation structure across blocks.
We then quantify the finite time error of online adaptation by leveraging
recent advances in linear stochastic approximation with correlated samples.
</p>
<a href="http://arxiv.org/abs/2010.14664" target="_blank">arXiv:2010.14664</a> [<a href="http://arxiv.org/pdf/2010.14664" target="_blank">pdf</a>]

<h2>Equivariant Filter (EqF). (arXiv:2010.14666v1 [eess.SY])</h2>
<h3>Pieter van Goor, Tarek Hamel, Robert Mahony</h3>
<p>The kinematics of many systems encountered in robotics, mechatronics, and
avionics are naturally posed on homogeneous spaces, that is, their state lies
in a smooth manifold equipped with a transitive Lie-group symmetry. This paper
shows that all such systems can be embedded in an equivariant system using a
velocity extension. We propose a novel filter, the Equivariant Filter (EqF), by
linearising global error dynamics derived from the equivariance of the
embedding system and applying a Riccati observer to these error dynamics. In
cases where the system output is also equivariant the EqF leads to linearised
dynamics with a constant output matrix. The work is motivated by an example
application that is intractable to prior published invariant filter design
methodologies.
</p>
<a href="http://arxiv.org/abs/2010.14666" target="_blank">arXiv:2010.14666</a> [<a href="http://arxiv.org/pdf/2010.14666" target="_blank">pdf</a>]

<h2>Online Learning with Primary and Secondary Losses. (arXiv:2010.14670v1 [cs.LG])</h2>
<h3>Avrim Blum, Han Shao</h3>
<p>We study the problem of online learning with primary and secondary losses.
For example, a recruiter making decisions of which job applicants to hire might
weigh false positives and false negatives equally (the primary loss) but the
applicants might weigh false negatives much higher (the secondary loss). We
consider the following question: Can we combine "expert advice" to achieve low
regret with respect to the primary loss, while at the same time performing {\em
not much worse than the worst expert} with respect to the secondary loss?
Unfortunately, we show that this goal is unachievable without any bounded
variance assumption on the secondary loss. More generally, we consider the goal
of minimizing the regret with respect to the primary loss and bounding the
secondary loss by a linear threshold. On the positive side, we show that
running any switching-limited algorithm can achieve this goal if all experts
satisfy the assumption that the secondary loss does not exceed the linear
threshold by $o(T)$ for any time interval. If not all experts satisfy this
assumption, our algorithms can achieve this goal given access to some external
oracles which determine when to deactivate and reactivate experts.
</p>
<a href="http://arxiv.org/abs/2010.14670" target="_blank">arXiv:2010.14670</a> [<a href="http://arxiv.org/pdf/2010.14670" target="_blank">pdf</a>]

<h2>What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation. (arXiv:2010.14678v1 [cs.CL])</h2>
<h3>Amir Pouran Ben Veyseh, Franck Dernoncourt, Quan Hung Tran, Thien Huu Nguyen</h3>
<p>Acronyms are the short forms of phrases that facilitate conveying lengthy
sentences in documents and serve as one of the mainstays of writing. Due to
their importance, identifying acronyms and corresponding phrases (i.e., acronym
identification (AI)) and finding the correct meaning of each acronym (i.e.,
acronym disambiguation (AD)) are crucial for text understanding. Despite the
recent progress on this task, there are some limitations in the existing
datasets which hinder further improvement. More specifically, limited size of
manually annotated AI datasets or noises in the automatically created acronym
identification datasets obstruct designing advanced high-performing acronym
identification models. Moreover, the existing datasets are mostly limited to
the medical domain and ignore other domains. In order to address these two
limitations, we first create a manually annotated large AI dataset for
scientific domain. This dataset contains 17,506 sentences which is
substantially larger than previous scientific AI datasets. Next, we prepare an
AD dataset for scientific domain with 62,441 samples which is significantly
larger than the previous scientific AD dataset. Our experiments show that the
existing state-of-the-art models fall far behind human-level performance on
both datasets proposed by this work. In addition, we propose a new deep
learning model that utilizes the syntactical structure of the sentence to
expand an ambiguous acronym in a sentence. The proposed model outperforms the
state-of-the-art models on the new AD dataset, providing a strong baseline for
future research on this dataset.
</p>
<a href="http://arxiv.org/abs/2010.14678" target="_blank">arXiv:2010.14678</a> [<a href="http://arxiv.org/pdf/2010.14678" target="_blank">pdf</a>]

<h2>Learning to Represent Action Values as a Hypergraph on the Action Vertices. (arXiv:2010.14680v1 [cs.LG])</h2>
<h3>Arash Tavakoli, Mehdi Fatemi, Petar Kormushev</h3>
<p>Action-value estimation is a critical component of many reinforcement
learning (RL) methods whereby sample complexity relies heavily on how fast a
good estimator for action value can be learned. By viewing this problem through
the lens of representation learning, good representations of both state and
action can facilitate action-value estimation. While advances in deep learning
have seamlessly driven progress in learning state representations, given the
specificity of the notion of agency to RL, little attention has been paid to
learning action representations. We conjecture that leveraging the
combinatorial structure of multi-dimensional action spaces is a key ingredient
for learning good representations of action. To test this, we set forth the
action hypergraph networks framework---a class of functions for learning action
representations with a relational inductive bias. Using this framework we
realise an agent class based on a combination with deep Q-networks, which we
dub hypergraph Q-networks. We show the effectiveness of our approach on a
myriad of domains: illustrative prediction problems under minimal confounding
effects, Atari 2600 games, and physical control benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.14680" target="_blank">arXiv:2010.14680</a> [<a href="http://arxiv.org/pdf/2010.14680" target="_blank">pdf</a>]

<h2>Parameterized Neural Ordinary Differential Equations: Applications to Computational Physics Problems. (arXiv:2010.14685v1 [physics.comp-ph])</h2>
<h3>Kookjin Lee, Eric J. Parish</h3>
<p>This work proposes an extension of neural ordinary differential equations
(NODEs) by introducing an additional set of ODE input parameters to NODEs. This
extension allows NODEs to learn multiple dynamics specified by the input
parameter instances. Our extension is inspired by the concept of parameterized
ordinary differential equations, which are widely investigated in computational
science and engineering contexts, where characteristics of the governing
equations vary over the input parameters. We apply the proposed parameterized
NODEs (PNODEs) for learning latent dynamics of complex dynamical processes that
arise in computational physics, which is an essential component for enabling
rapid numerical simulations for time-critical physics applications. For this,
we propose an encoder-decoder-type framework, which models latent dynamics as
PNODEs. We demonstrate the effectiveness of PNODEs with important benchmark
problems from computational physics.
</p>
<a href="http://arxiv.org/abs/2010.14685" target="_blank">arXiv:2010.14685</a> [<a href="http://arxiv.org/pdf/2010.14685" target="_blank">pdf</a>]

<h2>Expressive yet Tractable Bayesian Deep Learning via Subnetwork Inference. (arXiv:2010.14689v1 [cs.LG])</h2>
<h3>Erik Daxberger, Eric Nalisnick, James Urquhart Allingham, Javier Antor&#xe1;n, Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</h3>
<p>The Bayesian paradigm has the potential to solve some of the core issues in
modern deep learning, such as poor calibration, data inefficiency, and
catastrophic forgetting. However, scaling Bayesian inference to the
high-dimensional parameter spaces of deep neural networks requires restrictive
approximations. In this paper, we propose performing inference over only a
small subset of the model parameters while keeping all others as point
estimates. This enables us to use expressive posterior approximations that
would otherwise be intractable for the full model. In particular, we develop a
practical and scalable Bayesian deep learning method that first trains a point
estimate, and then infers a full covariance Gaussian posterior approximation
over a subnetwork. We propose a subnetwork selection procedure which aims to
optimally preserve posterior uncertainty. We empirically demonstrate the
effectiveness of our approach compared to point-estimated networks and methods
that use less expressive posterior approximations over the full network.
</p>
<a href="http://arxiv.org/abs/2010.14689" target="_blank">arXiv:2010.14689</a> [<a href="http://arxiv.org/pdf/2010.14689" target="_blank">pdf</a>]

<h2>Optimal Textures: Fast and Robust Texture Synthesis and Style Transfer through Optimal Transport. (arXiv:2010.14702v1 [cs.GR])</h2>
<h3>Eric Risser</h3>
<p>This paper presents a light-weight, high-quality texture synthesis algorithm
that easily generalizes to other applications such as style transfer and
texture mixing. We represent texture features through the deep neural
activation vectors within the bottleneck layer of an auto-encoder and frame the
texture synthesis problem as optimal transport between the activation values of
the image being synthesized and those of an exemplar texture. To find this
optimal transport mapping, we utilize an N-dimensional probability density
function (PDF) transfer process that iterates over multiple random rotations of
the PDF basis and matches the 1D marginal distributions across each dimension.
This achieves quality and flexibility on par with expensive back-propagation
based neural texture synthesis methods, but with the potential of achieving
interactive rates. We demonstrate that first order statistics offer a more
robust representation for texture than the second order statistics that are
used today. We propose an extension of this algorithm that reduces the
dimensionality of the neural feature space. We utilize a multi-scale
coarse-to-fine synthesis pyramid to capture and preserve larger image features;
unify color and style transfer under one framework; and further augment this
system with a novel masking scheme that re-samples and re-weights the feature
distribution for user-guided texture painting and targeted style transfer.
</p>
<a href="http://arxiv.org/abs/2010.14702" target="_blank">arXiv:2010.14702</a> [<a href="http://arxiv.org/pdf/2010.14702" target="_blank">pdf</a>]

<h2>Melody-Conditioned Lyrics Generation with SeqGANs. (arXiv:2010.14709v1 [cs.SD])</h2>
<h3>Yihao Chen, Alexander Lerch</h3>
<p>Automatic lyrics generation has received attention from both music and AI
communities for years. Early rule-based approaches have~---due to increases in
computational power and evolution in data-driven models---~mostly been replaced
with deep-learning-based systems. Many existing approaches, however, either
rely heavily on prior knowledge in music and lyrics writing or oversimplify the
task by largely discarding melodic information and its relationship with the
text. We propose an end-to-end melody-conditioned lyrics generation system
based on Sequence Generative Adversarial Networks (SeqGAN), which generates a
line of lyrics given the corresponding melody as the input. Furthermore, we
investigate the performance of the generator with an additional input
condition: the theme or overarching topic of the lyrics to be generated. We
show that the input conditions have no negative impact on the evaluation
metrics while enabling the network to produce more meaningful results.
</p>
<a href="http://arxiv.org/abs/2010.14709" target="_blank">arXiv:2010.14709</a> [<a href="http://arxiv.org/pdf/2010.14709" target="_blank">pdf</a>]

<h2>CompRess: Self-Supervised Learning by Compressing Representations. (arXiv:2010.14713v1 [cs.CV])</h2>
<h3>Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash</h3>
<p>Self-supervised learning aims to learn good representations with unlabeled
data. Recent works have shown that larger models benefit more from
self-supervised learning than smaller models. As a result, the gap between
supervised and self-supervised learning has been greatly reduced for larger
models. In this work, instead of designing a new pseudo task for
self-supervised learning, we develop a model compression method to compress an
already learned, deep self-supervised model (teacher) to a smaller one
(student). We train the student model so that it mimics the relative similarity
between the data points in the teacher's embedding space. For AlexNet, our
method outperforms all previous methods including the fully supervised model on
ImageNet linear evaluation (59.0% compared to 56.5%) and on nearest neighbor
evaluation (50.7% compared to 41.4%). To the best of our knowledge, this is the
first time a self-supervised AlexNet has outperformed supervised one on
ImageNet classification. Our code is available here:
https://github.com/UMBCvision/CompRess
</p>
<a href="http://arxiv.org/abs/2010.14713" target="_blank">arXiv:2010.14713</a> [<a href="http://arxiv.org/pdf/2010.14713" target="_blank">pdf</a>]

<h2>Second-Order Unsupervised Neural Dependency Parsing. (arXiv:2010.14720v1 [cs.CL])</h2>
<h3>Songlin Yang, Yong Jiang, Wenjuan Han, Kewei Tu</h3>
<p>Most of the unsupervised dependency parsers are based on first-order
probabilistic generative models that only consider local parent-child
information. Inspired by second-order supervised dependency parsing, we
proposed a second-order extension of unsupervised neural dependency models that
incorporate grandparent-child or sibling information. We also propose a novel
design of the neural parameterization and optimization methods of the
dependency models. In second-order models, the number of grammar rules grows
cubically with the increase of vocabulary size, making it difficult to train
lexicalized models that may contain thousands of words. To circumvent this
problem while still benefiting from both second-order parsing and
lexicalization, we use the agreement-based learning framework to jointly train
a second-order unlexicalized model and a first-order lexicalized model.
Experiments on multiple datasets show the effectiveness of our second-order
models compared with recent state-of-the-art methods. Our joint model achieves
a 10% improvement over the previous state-of-the-art parser on the full WSJ
test set
</p>
<a href="http://arxiv.org/abs/2010.14720" target="_blank">arXiv:2010.14720</a> [<a href="http://arxiv.org/pdf/2010.14720" target="_blank">pdf</a>]

<h2>MultiMix: Sparingly Supervised, Extreme Multitask Learning From Medical Images. (arXiv:2010.14731v1 [cs.CV])</h2>
<h3>Ayaan Haque, Abdullah-Al-Zubaer Imran, Adam Wang, Demetri Terzopoulos</h3>
<p>Semi-supervised learning via learning from limited quantities of labeled data
has been investigated as an alternative to supervised counterparts. Maximizing
knowledge gains from copious unlabeled data benefit semi-supervised learning
settings. Moreover, learning multiple tasks within the same model further
improves model generalizability. We propose a novel multitask learning model,
namely MultiMix, which jointly learns disease classification and anatomical
segmentation in a sparingly supervised manner, while preserving explainability
through bridge saliency between the two tasks. Our extensive experimentation
with varied quantities of labeled data in the training sets justify the
effectiveness of our multitasking model for the classification of pneumonia and
segmentation of lungs from chest X-ray images. Moreover, both in-domain and
cross-domain evaluations across the tasks further showcase the potential of our
model to adapt to challenging generalization scenarios.
</p>
<a href="http://arxiv.org/abs/2010.14731" target="_blank">arXiv:2010.14731</a> [<a href="http://arxiv.org/pdf/2010.14731" target="_blank">pdf</a>]

<h2>ElderSim: A Synthetic Data Generation Platform for Human Action Recognition in Eldercare Applications. (arXiv:2010.14742v1 [cs.CV])</h2>
<h3>Hochul Hwang, Cheongjae Jang, Geonwoo Park, Junghyun Cho, Ig-Jae Kim</h3>
<p>To train deep learning models for vision-based action recognition of elders'
daily activities, we need large-scale activity datasets acquired under various
daily living environments and conditions. However, most public datasets used in
human action recognition either differ from or have limited coverage of elders'
activities in many aspects, making it challenging to recognize elders' daily
activities well by only utilizing existing datasets. Recently, such limitations
of available datasets have actively been compensated by generating synthetic
data from realistic simulation environments and using those data to train deep
learning models. In this paper, based on these ideas we develop ElderSim, an
action simulation platform that can generate synthetic data on elders' daily
activities. For 55 kinds of frequent daily activities of the elders, ElderSim
generates realistic motions of synthetic characters with various adjustable
data-generating options, and provides different output modalities including RGB
videos, two- and three-dimensional skeleton trajectories. We then generate KIST
SynADL, a large-scale synthetic dataset of elders' activities of daily living,
from ElderSim and use the data in addition to real datasets to train three
state-of the-art human action recognition models. From the experiments
following several newly proposed scenarios that assume different real and
synthetic dataset configurations for training, we observe a noticeable
performance improvement by augmenting our synthetic data. We also offer
guidance with insights for the effective utilization of synthetic data to help
recognize elders' daily activities.
</p>
<a href="http://arxiv.org/abs/2010.14742" target="_blank">arXiv:2010.14742</a> [<a href="http://arxiv.org/pdf/2010.14742" target="_blank">pdf</a>]

<h2>Generalized Nonlinear and Finsler Geometry for Robotics. (arXiv:2010.14745v1 [cs.RO])</h2>
<h3>Nathan D. Ratliff, Karl Van Wyk, Mandy Xie, Anqi Li, Asif Muhammad Rana</h3>
<p>Robotics research has found numerous important applications of Riemannian
geometry, despite the background mathematical material being strikingly
challenging. This material is often remains inaccessible to roboticists, and
despite many natural generalizations within the mathematical literature, there
remain very few applications of modern highly-relevant geometric
generalizations such as spray or Finsler geometry. This paper presents an
entire re-derivation of generalized spray and Finsler geometries focusing on
building the ideas from familiar concepts in advanced calculus and the calculus
of variations. We focus on the pragmatic and calculable results and avoid the
use of tensor notation to appeal to a broader audience. We have already used
these derivations for important advances in our own work (for instance,
geometric fabrics); it is our hope that they will contribute to an increased
understanding of these ideas within the robotics community and inspire future
research into applications of generalized nonlinear, Finsler, and even
Riemannian geometries.
</p>
<a href="http://arxiv.org/abs/2010.14745" target="_blank">arXiv:2010.14745</a> [<a href="http://arxiv.org/pdf/2010.14745" target="_blank">pdf</a>]

<h2>Continuous Chaotic Nonlinear System and Lyapunov controller Optimization using Deep Learning. (arXiv:2010.14746v1 [eess.SY])</h2>
<h3>Amr Mahmoud, Youmna Ismaeil, Mohamed Zohdy</h3>
<p>The introduction of unexpected system disturbances and new system dynamics
does not allow initially selected static system and controller parameters to
guarantee continued system stability and performance. In this research we
present a novel approach for detecting early failure indicators of non-linear
highly chaotic system and accordingly predict the best parameter calibrations
to offset such instability using deep machine learning regression model. The
approach proposed continuously monitors the system and controller signals. The
Re-calibration of the system and controller parameters is triggered according
to a set of conditions designed to maintain system stability without compromise
to the system speed, intended outcome or required processing power. The deep
neural model predicts the parameter values that would best counteract the
expected system in-stability. To demonstrate the effectiveness of the proposed
approach, it is applied to the non-linear complex combination of Duffing Van
der pol oscillators. The approach is also tested under different scenarios the
system and controller parameters are initially chosen incorrectly or the system
parameters are changed while running or new system dynamics are introduced
while running to measure effectiveness and reaction time.
</p>
<a href="http://arxiv.org/abs/2010.14746" target="_blank">arXiv:2010.14746</a> [<a href="http://arxiv.org/pdf/2010.14746" target="_blank">pdf</a>]

<h2>An iterative framework for self-supervised deep speaker representation learning. (arXiv:2010.14751v1 [eess.AS])</h2>
<h3>Danwei Cai, Weiqing Wang, Ming Li</h3>
<p>In this paper, we propose an iterative framework for self-supervised speaker
representation learning based on a deep neural network (DNN). The framework
starts with training a self-supervision speaker embedding network by maximizing
agreement between different segments within an utterance via a contrastive
loss. Taking advantage of DNN's ability to learn from data with label noise, we
propose to cluster the speaker embedding obtained from the previous speaker
network and use the subsequent class assignments as pseudo labels to train a
new DNN. Moreover, we iteratively train the speaker network with pseudo labels
generated from the previous step to bootstrap the discriminative power of a
DNN. Speaker verification experiments are conducted on the VoxCeleb dataset.
The results show that our proposed iterative self-supervised learning framework
outperformed previous works using self-supervision. The speaker network after 5
iterations obtains a 61% performance gain over the speaker embedding model
trained with contrastive loss.
</p>
<a href="http://arxiv.org/abs/2010.14751" target="_blank">arXiv:2010.14751</a> [<a href="http://arxiv.org/pdf/2010.14751" target="_blank">pdf</a>]

<h2>A short note on the decision tree based neural turing machine. (arXiv:2010.14753v1 [cs.LG])</h2>
<h3>Yingshi Chen</h3>
<p>Turing machine and decision tree have developed independently for a long
time. With the recent development of differentiable models, there is an
intersection between them. Neural turing machine(NTM) opens door for the memory
network. It use differentiable attention mechanism to read/write external
memory bank. Differentiable forest brings differentiable properties to
classical decision tree. In this short note, we show the deep connection
between these two models. That is: differentiable forest is a special case of
NTM. Differentiable forest is actually decision tree based neural turing
machine. Based on this deep connection, we propose a response augmented
differential forest (RaDF). The controller of RaDF is differentiable forest,
the external memory of RaDF are response vectors which would be read/write by
leaf nodes.
</p>
<a href="http://arxiv.org/abs/2010.14753" target="_blank">arXiv:2010.14753</a> [<a href="http://arxiv.org/pdf/2010.14753" target="_blank">pdf</a>]

<h2>Fine-grained Information Status Classification Using Discourse Context-Aware BERT. (arXiv:2010.14759v1 [cs.CL])</h2>
<h3>Yufang Hou</h3>
<p>Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the
problem as a subtask of learning fine-grained information status (IS). However,
these systems heavily depend on many hand-crafted linguistic features. In this
paper, we propose a simple discourse context-aware BERT model for fine-grained
IS classification. On the ISNotes corpus (Markert et al., 2012), our model
achieves new state-of-the-art performance on fine-grained IS classification,
obtaining a 4.8 absolute overall accuracy improvement compared to Hou et al.
(2013a). More importantly, we also show an improvement of 10.5 F1 points for
bridging anaphora recognition without using any complex hand-crafted semantic
features designed for capturing the bridging phenomenon. We further analyze the
trained model and find that the most attended signals for each IS category
correspond well to linguistic notions of information status.
</p>
<a href="http://arxiv.org/abs/2010.14759" target="_blank">arXiv:2010.14759</a> [<a href="http://arxiv.org/pdf/2010.14759" target="_blank">pdf</a>]

<h2>A Sober Look at the Unsupervised Learning of Disentangled Representations and their Evaluation. (arXiv:2010.14766v1 [cs.LG])</h2>
<h3>Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar R&#xe4;tsch, Sylvain Gelly, Bernhard Sch&#xf6;lkopf, Olivier Bachem</h3>
<p>The idea behind the \emph{unsupervised} learning of \emph{disentangled}
representations is that real-world data is generated by a few explanatory
factors of variation which can be recovered by unsupervised learning
algorithms. In this paper, we provide a sober look at recent progress in the
field and challenge some common assumptions. We first theoretically show that
the unsupervised learning of disentangled representations is fundamentally
impossible without inductive biases on both the models and the data. Then, we
train over $14000$ models covering most prominent methods and evaluation
metrics in a reproducible large-scale experimental study on eight data sets. We
observe that while the different methods successfully enforce properties
"encouraged" by the corresponding losses, well-disentangled models seemingly
cannot be identified without supervision. Furthermore, different evaluation
metrics do not always agree on what should be considered "disentangled" and
exhibit systematic differences in the estimation. Finally, increased
disentanglement does not seem to necessarily lead to a decreased sample
complexity of learning for downstream tasks. Our results suggest that future
work on disentanglement learning should be explicit about the role of inductive
biases and (implicit) supervision, investigate concrete benefits of enforcing
disentanglement of the learned representations, and consider a reproducible
experimental setup covering several data sets.
</p>
<a href="http://arxiv.org/abs/2010.14766" target="_blank">arXiv:2010.14766</a> [<a href="http://arxiv.org/pdf/2010.14766" target="_blank">pdf</a>]

<h2>Batch Reinforcement Learning with a Nonparametric Off-Policy Policy Gradient. (arXiv:2010.14771v1 [cs.LG])</h2>
<h3>Samuele Tosatto, Jo&#xe3;o Carvalho, Jan Peters</h3>
<p>Off-policy Reinforcement Learning (RL) holds the promise of better data
efficiency as it allows sample reuse and potentially enables safe interaction
with the environment. Current off-policy policy gradient methods either suffer
from high bias or high variance, delivering often unreliable estimates. The
price of inefficiency becomes evident in real-world scenarios such as
interaction-driven robot learning, where the success of RL has been rather
limited, and a very high sample cost hinders straightforward application. In
this paper, we propose a nonparametric Bellman equation, which can be solved in
closed form. The solution is differentiable w.r.t the policy parameters and
gives access to an estimation of the policy gradient. In this way, we avoid the
high variance of importance sampling approaches, and the high bias of
semi-gradient methods. We empirically analyze the quality of our gradient
estimate against state-of-the-art methods, and show that it outperforms the
baselines in terms of sample efficiency on classical control tasks.
</p>
<a href="http://arxiv.org/abs/2010.14771" target="_blank">arXiv:2010.14771</a> [<a href="http://arxiv.org/pdf/2010.14771" target="_blank">pdf</a>]

<h2>Structural Causal Model with Expert Augmented Knowledge to Estimate the Effect of Oxygen Therapy on Mortality in the ICU. (arXiv:2010.14774v1 [cs.LG])</h2>
<h3>Md Osman Gani, Shravan Kethireddy, Marvi Bikak, Paul Griffin, Mohammad Adibuzzaman</h3>
<p>Recent advances in causal inference techniques, more specifically, in the
theory of structural causal models, provide the framework for identification of
causal effects from observational data in the cases where the causal graph is
identifiable, i.e., the data generating mechanism can be recovered from the
joint distribution. However, no such studies have been done to demonstrate this
concept with a clinical example. We present a complete framework to estimate
the causal effect from observational data by augmenting expert knowledge in the
model development phase and with a practical clinical application. Our clinical
application entails a timely and important research question, i.e., the effect
of oxygen therapy intervention in the intensive care unit (ICU); the result of
this project is useful in a variety of disease conditions, including severe
acute respiratory syndrome coronavirus-2 (SARS-CoV-2) patients in the ICU. We
used data from the MIMIC III database, a standard database in the machine
learning community that contains 58,976 admissions from an ICU in Boston, MA,
for estimating the oxygen therapy effect on morality. We also identified the
covariate-specific effect to oxygen therapy from the model for more
personalized intervention.
</p>
<a href="http://arxiv.org/abs/2010.14774" target="_blank">arXiv:2010.14774</a> [<a href="http://arxiv.org/pdf/2010.14774" target="_blank">pdf</a>]

<h2>DNA: Differentiable Network-Accelerator Co-Search. (arXiv:2010.14778v1 [cs.LG])</h2>
<h3>Yongan Zhang, Yonggan Fu, Weiwen Jiang, Chaojian Li, Haoran You, Meng Li, Vikas Chandra, Yingyan Lin</h3>
<p>Powerful yet complex deep neural networks (DNNs) have fueled a booming demand
for efficient DNN solutions to bring DNN-powered intelligence into numerous
applications. Jointly optimizing the networks and their accelerators are
promising in providing optimal performance. However, the great potential of
such solutions have yet to be unleashed due to the challenge of simultaneously
exploring the vast and entangled, yet different design spaces of the networks
and their accelerators. To this end, we propose DNA, a Differentiable
Network-Accelerator co-search framework for automatically searching for matched
networks and accelerators to maximize both the task accuracy and acceleration
efficiency. Specifically, DNA integrates two enablers: (1) a generic design
space for DNN accelerators that is applicable to both FPGA- and ASIC-based DNN
accelerators and compatible with DNN frameworks such as PyTorch to enable
algorithmic exploration for more efficient DNNs and their accelerators; and (2)
a joint DNN network and accelerator co-search algorithm that enables
simultaneously searching for optimal DNN structures and their accelerators'
micro-architectures and mapping methods to maximize both the task accuracy and
acceleration efficiency. Experiments and ablation studies based on FPGA
measurements and ASIC synthesis show that the matched networks and accelerators
generated by DNA consistently outperform state-of-the-art (SOTA) DNNs and DNN
accelerators (e.g., 3.04x better FPS with a 5.46% higher accuracy on ImageNet),
while requiring notably reduced search time (up to 1234.3x) over SOTA
co-exploration methods, when evaluated over ten SOTA baselines on three
datasets. All codes will be released upon acceptance.
</p>
<a href="http://arxiv.org/abs/2010.14778" target="_blank">arXiv:2010.14778</a> [<a href="http://arxiv.org/pdf/2010.14778" target="_blank">pdf</a>]

<h2>Classification Beats Regression: Counting of Cells from Greyscale Microscopic Images based on Annotation-free Training Samples. (arXiv:2010.14782v1 [eess.IV])</h2>
<h3>Xin Ding, Qiong Zhang, William J. Welch</h3>
<p>Modern methods often formulate the counting of cells from microscopic images
as a regression problem and more or less rely on expensive, manually annotated
training images (e.g., dot annotations indicating the centroids of cells or
segmentation masks identifying the contours of cells). This work proposes a
supervised learning framework based on classification-oriented convolutional
neural networks (CNNs) to count cells from greyscale microscopic images without
using annotated training images. In this framework, we formulate the cell
counting task as an image classification problem, where the cell counts are
taken as class labels. This formulation has its limitation when some cell
counts in the test stage do not appear in the training data. Moreover, the
ordinal relation among cell counts is not utilized. To deal with these
limitations, we propose a simple but effective data augmentation (DA) method to
synthesize images for the unseen cell counts. We also introduce an ensemble
method, which can not only moderate the influence of unseen cell counts but
also utilize the ordinal information to improve the prediction accuracy. This
framework outperforms many modern cell counting methods and won the data
analysis competition (Case Study 1: Counting Cells From Microscopic Images
https://ssc.ca/en/case-study/case-study-1-counting-cells-microscopic-images) of
the 47th Annual Meeting of the Statistical Society of Canada (SSC). Our code is
available at https://github.com/anno2020/CellCount_TinyBBBC005.
</p>
<a href="http://arxiv.org/abs/2010.14782" target="_blank">arXiv:2010.14782</a> [<a href="http://arxiv.org/pdf/2010.14782" target="_blank">pdf</a>]

<h2>A Chinese Text Classification Method With Low Hardware Requirement Based on Improved Model Concatenation. (arXiv:2010.14784v1 [cs.CL])</h2>
<h3>Yuanhao Zhuo</h3>
<p>In order to improve the accuracy performance of Chinese text classification
models with low hardware requirements, an improved concatenation-based model is
designed in this paper, which is a concatenation of 5 different sub-models,
including TextCNN, LSTM, and Bi-LSTM. Compared with the existing ensemble
learning method, for a text classification mission, this model's accuracy is 2%
higher. Meanwhile, the hardware requirements of this model are much lower than
the BERT-based model.
</p>
<a href="http://arxiv.org/abs/2010.14784" target="_blank">arXiv:2010.14784</a> [<a href="http://arxiv.org/pdf/2010.14784" target="_blank">pdf</a>]

<h2>Designing Interpretable Approximations to Deep Reinforcement Learning with Soft Decision Trees. (arXiv:2010.14785v1 [cs.LG])</h2>
<h3>Nathan Dahlin, Krishna Chaitanya Kalagarla, Nikhil Naik, Rahul Jain, Pierluigi Nuzzo</h3>
<p>In an ever expanding set of research and application areas, deep neural
networks (DNNs) set the bar for algorithm performance. However, depending upon
additional constraints such as processing power and execution time limits, or
requirements such as verifiable safety guarantees, it may not be feasible to
actually use such high-performing DNNs in practice. Many techniques have been
developed in recent years to compress or distill complex DNNs into smaller,
faster or more understandable models and controllers. This work seeks to
provide a quantitative framework with metrics to systematically evaluate the
outcome of such conversion processes, and identify reduced models that not only
preserve a desired performance level, but also, for example, succinctly explain
the latent knowledge represented by a DNN. We illustrate the effectiveness of
the proposed approach on the evaluation of decision tree variants in the
context of benchmark reinforcement learning tasks.
</p>
<a href="http://arxiv.org/abs/2010.14785" target="_blank">arXiv:2010.14785</a> [<a href="http://arxiv.org/pdf/2010.14785" target="_blank">pdf</a>]

<h2>Class-Agnostic Segmentation Loss and Its Application to Salient Object Detection and Segmentation. (arXiv:2010.14793v1 [cs.CV])</h2>
<h3>Angira Sharma, Naeemullah Khan, Ganesh Sundaramoorthi, Philip Torr</h3>
<p>In this paper we present a novel loss function, called class-agnostic
segmentation (CAS) loss. With CAS loss the class descriptors are learned during
training of the network. We don't require to define the label of a class
a-priori, rather the CAS loss clusters regions with similar appearance together
in a weakly-supervised manner. Furthermore, we show that the CAS loss function
is sparse, bounded, and robust to class-imbalance. We apply our CAS loss
function with fully-convolutional ResNet101 and DeepLab-v3 architectures to the
binary segmentation problem of salient object detection. We investigate the
performance against the state-of-the-art methods in two settings of low and
high-fidelity training data on seven salient object detection datasets. For
low-fidelity training data (incorrect class label) class-agnostic segmentation
loss outperforms the state-of-the-art methods on salient object detection
datasets by staggering margins of around 50%. For high-fidelity training data
(correct class labels) class-agnostic segmentation models perform as good as
the state-of-the-art approaches while beating the state-of-the-art methods on
most datasets. In order to show the utility of the loss function across
different domains we also test on general segmentation dataset, where
class-agnostic segmentation loss outperforms cross-entropy based loss by huge
margins on both region and edge metrics.
</p>
<a href="http://arxiv.org/abs/2010.14793" target="_blank">arXiv:2010.14793</a> [<a href="http://arxiv.org/pdf/2010.14793" target="_blank">pdf</a>]

<h2>SFU-Store-Nav: A Multimodal Dataset for Indoor Human Navigation. (arXiv:2010.14802v1 [cs.CV])</h2>
<h3>Zhitian Zhang, Jimin Rhim, Taher Ahmadi, Kefan Yang, Angelica Lim, Mo Chen</h3>
<p>This article describes a dataset collected in a set of experiments that
involves human participants and a robot. The set of experiments was conducted
in the computing science robotics lab in Simon Fraser University, Burnaby, BC,
Canada, and its aim is to gather data containing common gestures, movements,
and other behaviours that may indicate humans' navigational intent relevant for
autonomous robot navigation. The experiment simulates a shopping scenario where
human participants come in to pick up items from his/her shopping list and
interact with a Pepper robot that is programmed to help the human participant.
We collected visual data and motion capture data from 108 human participants.
The visual data contains live recordings of the experiments and the motion
capture data contains the position and orientation of the human participants in
world coordinates. This dataset could be valuable for researchers in the
robotics, machine learning and computer vision community.
</p>
<a href="http://arxiv.org/abs/2010.14802" target="_blank">arXiv:2010.14802</a> [<a href="http://arxiv.org/pdf/2010.14802" target="_blank">pdf</a>]

<h2>PPG-based singing voice conversion with adversarial representation learning. (arXiv:2010.14804v1 [cs.SD])</h2>
<h3>Zhonghao Li, Benlai Tang, Xiang Yin, Yuan Wan, Ling Xu, Chen Shen, Zejun Ma</h3>
<p>Singing voice conversion (SVC) aims to convert the voice of one singer to
that of other singers while keeping the singing content and melody. On top of
recent voice conversion works, we propose a novel model to steadily convert
songs while keeping their naturalness and intonation. We build an end-to-end
architecture, taking phonetic posteriorgrams (PPGs) as inputs and generating
mel spectrograms. Specifically, we implement two separate encoders: one encodes
PPGs as content, and the other compresses mel spectrograms to supply acoustic
and musical information. To improve the performance on timbre and melody, an
adversarial singer confusion module and a mel-regressive representation
learning module are designed for the model. Objective and subjective
experiments are conducted on our private Chinese singing corpus. Comparing with
the baselines, our methods can significantly improve the conversion performance
in terms of naturalness, melody, and voice similarity. Moreover, our PPG-based
method is proved to be robust for noisy sources.
</p>
<a href="http://arxiv.org/abs/2010.14804" target="_blank">arXiv:2010.14804</a> [<a href="http://arxiv.org/pdf/2010.14804" target="_blank">pdf</a>]

<h2>Large-Scale MIDI-based Composer Classification. (arXiv:2010.14805v1 [cs.SD])</h2>
<h3>Qiuqiang Kong, Keunwoo Choi, Yuxuan Wang</h3>
<p>Music classification is a task to classify a music piece into labels such as
genres or composers. We propose large-scale MIDI based composer classification
systems using GiantMIDI-Piano, a transcription-based dataset. We propose to use
piano rolls, onset rolls, and velocity rolls as input representations and use
deep neural networks as classifiers. To our knowledge, we are the first to
investigate the composer classification problem with up to 100 composers. By
using convolutional recurrent neural networks as models, our MIDI based
composer classification system achieves a 10-composer and a 100-composer
classification accuracies of 0.648 and 0.385 (evaluated on 30-second clips) and
0.739 and 0.489 (evaluated on music pieces), respectively. Our MIDI based
composer system outperforms several audio-based baseline classification
systems, indicating the effectiveness of using compact MIDI representations for
composer classification.
</p>
<a href="http://arxiv.org/abs/2010.14805" target="_blank">arXiv:2010.14805</a> [<a href="http://arxiv.org/pdf/2010.14805" target="_blank">pdf</a>]

<h2>The Volctrans Machine Translation System for WMT20. (arXiv:2010.14806v1 [cs.CL])</h2>
<h3>Liwei Wu, Xiao Pan, Zehui Lin, Yaoming Zhu, Mingxuan Wang, Lei Li</h3>
<p>This paper describes our VolcTrans system on WMT20 shared news translation
task. We participated in 8 translation directions. Our basic systems are based
on Transformer, with several variants (wider or deeper Transformers, dynamic
convolutions). The final system includes text pre-process, data selection,
synthetic data generation, advanced model ensemble, and multilingual
pre-training.
</p>
<a href="http://arxiv.org/abs/2010.14806" target="_blank">arXiv:2010.14806</a> [<a href="http://arxiv.org/pdf/2010.14806" target="_blank">pdf</a>]

<h2>AbdomenCT-1K: Is Abdominal Organ Segmentation A Solved Problem?. (arXiv:2010.14808v1 [cs.CV])</h2>
<h3>Jun Ma, Yao Zhang, Song Gu, Yichi Zhang, Cheng Zhu, Qiyuan Wang, Xin Liu, Xingle An, Cheng Ge, Shucheng Cao, Qi Zhang, Shangqing Liu, Yunpeng Wang, Yuhui Li, Congcong Wang, Jian He, Xiaoping Yang</h3>
<p>With the unprecedented developments in deep learning, automatic segmentation
of main abdominal organs (i.e., liver, kidney, and spleen) seems to be a solved
problem as the state-of-the-art (SOTA) methods have achieved comparable results
with inter-observer variability on existing benchmark datasets. However, most
of the existing abdominal organ segmentation benchmark datasets only contain
single-center, single-phase, single-vendor, or single-disease cases, thus, it
is unclear whether the excellent performance can generalize on more diverse
datasets. In this paper, we present a large and diverse abdominal CT organ
segmentation dataset, termed as AbdomenCT-1K, with more than 1000 (1K) CT scans
from 11 countries, including multi-center, multi-phase, multi-vendor, and
multi-disease cases. Furthermore, we conduct a large-scale study for liver,
kidney, spleen, and pancreas segmentation, as well as reveal the unsolved
segmentation problems of the SOTA method, such as the limited generalization
ability on distinct medical centers, phases, and unseen diseases. To advance
the unsolved problems, we build four organ segmentation benchmarks for fully
supervised, semi-supervised, weakly supervised, and continual learning, which
are currently challenging and active research topics. Accordingly, we develop a
simple and effective method for each benchmark, which can be used as
out-of-the-box methods and strong baselines. We believe the introduction of the
AbdomenCT-1K dataset will promote future in-depth research towards clinical
applicable abdominal organ segmentation methods. Moreover, the datasets, codes,
and trained models of baseline methods will be publicly available at
https://github.com/JunMa11/AbdomenCT-1K.
</p>
<a href="http://arxiv.org/abs/2010.14808" target="_blank">arXiv:2010.14808</a> [<a href="http://arxiv.org/pdf/2010.14808" target="_blank">pdf</a>]

<h2>Cycle-Contrast for Self-Supervised Video Representation Learning. (arXiv:2010.14810v1 [cs.CV])</h2>
<h3>Quan Kong, Wenpeng Wei, Ziwei Deng, Tomoaki Yoshinaga, Tomokazu Murakami</h3>
<p>We present Cycle-Contrastive Learning (CCL), a novel self-supervised method
for learning video representation. Following a nature that there is a belong
and inclusion relation of video and its frames, CCL is designed to find
correspondences across frames and videos considering the contrastive
representation in their domains respectively. It is different from recent
approaches that merely learn correspondences across frames or clips. In our
method, the frame and video representations are learned from a single network
based on an R3D architecture, with a shared non-linear transformation for
embedding both frame and video features before the cycle-contrastive loss. We
demonstrate that the video representation learned by CCL can be transferred
well to downstream tasks of video understanding, outperforming previous methods
in nearest neighbour retrieval and action recognition tasks on UCF101, HMDB51
and MMAct.
</p>
<a href="http://arxiv.org/abs/2010.14810" target="_blank">arXiv:2010.14810</a> [<a href="http://arxiv.org/pdf/2010.14810" target="_blank">pdf</a>]

<h2>No Perfect Outdoors: Towards A Deep Profiling of GNSS-based Location Contexts. (arXiv:2010.14811v1 [cs.NI])</h2>
<h3>Feng Li, Jin Wang, Jun Luo</h3>
<p>While both outdoor and indoor localization methods are flourishing, how to
properly marry them to offer pervasive localizability in urban areas remains
open. Recently proposals on indoor-outdoor detection make the first step
towards such an integration, yet complicated urban environments render such a
binary classification incompetent. In this paper, we intend to fully explore
raw GNSS measurements in order to better characterize the diversified urban
environments. Essentially, we tackle the challenges introduced by the complex
GNSS data and apply a deep learning model to identify representations for
respective location contexts. We further develop two preliminary applications
of our deep profiling. On one hand, we offer a more fine-grained semantic
classification than binary indoor-outdoor detection. On the other hand, we
derive a GPS error indicator more meaningful than that provided by Google Maps.
These results are all corroborated by our extensive data collection and
trace-driven evaluations.
</p>
<a href="http://arxiv.org/abs/2010.14811" target="_blank">arXiv:2010.14811</a> [<a href="http://arxiv.org/pdf/2010.14811" target="_blank">pdf</a>]

<h2>Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets. (arXiv:2010.14819v1 [cs.CV])</h2>
<h3>Kai Han, Yunhe Wang, Qiulin Zhang, Wei Zhang, Chunjing Xu, Tong Zhang</h3>
<p>To obtain excellent deep neural architectures, a series of techniques are
carefully designed in EfficientNets. The giant formula for simultaneously
enlarging the resolution, depth and width provides us a Rubik's cube for neural
networks. So that we can find networks with high efficiency and excellent
performance by twisting the three dimensions. This paper aims to explore the
twisting rules for obtaining deep neural networks with minimum model sizes and
computational costs. Different from the network enlarging, we observe that
resolution and depth are more important than width for tiny networks.
Therefore, the original method, i.e., the compound scaling in EfficientNet is
no longer suitable. To this end, we summarize a tiny formula for downsizing
neural architectures through a series of smaller models derived from the
EfficientNet-B0 with the FLOPs constraint. Experimental results on the ImageNet
benchmark illustrate that our TinyNet performs much better than the smaller
version of EfficientNets using the inversed giant formula. For instance, our
TinyNet-E achieves a 59.9% Top-1 accuracy with only 24M FLOPs, which is about
1.9% higher than that of the previous best MobileNetV3 with similar
computational cost. Code will be available at
https://github.com/huawei-noah/CV-Backbones/tree/main/tinynet, and
https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/tinynet.
</p>
<a href="http://arxiv.org/abs/2010.14819" target="_blank">arXiv:2010.14819</a> [<a href="http://arxiv.org/pdf/2010.14819" target="_blank">pdf</a>]

<h2>Explainable Artificial Intelligence for Manufacturing Cost Estimation and Machining Feature Visualization. (arXiv:2010.14824v1 [cs.CG])</h2>
<h3>Soyoung Yoo, Namwoo Kang</h3>
<p>Studies on manufacturing cost prediction based on deep learning have begun in
recent years, but the cost prediction rationale cannot be explained because the
models are still used as a black box. This study aims to propose a
manufacturing cost prediction process for 3D computer-aided design (CAD) models
using explainable artificial intelligence. The proposed process can visualize
the machining features of the 3D CAD model that are influencing the increase in
manufacturing costs. The proposed process consists of (1) data collection and
pre-processing, (2) 3D deep learning architecture exploration, and (3)
visualization to explain the prediction results. The proposed deep learning
model shows high predictability of manufacturing cost for the computer
numerical control (CNC) machined parts. In particular, using 3D
gradient-weighted class activation mapping proves that the proposed model not
only can detect the CNC machining features but also can differentiate the
machining difficulty for the same feature. Using the proposed process, we can
provide a design guidance to engineering designers in reducing manufacturing
costs during the conceptual design phase. We can also provide real-time
quotations and redesign proposals to online manufacturing platform customers.
</p>
<a href="http://arxiv.org/abs/2010.14824" target="_blank">arXiv:2010.14824</a> [<a href="http://arxiv.org/pdf/2010.14824" target="_blank">pdf</a>]

<h2>Deep Manifold Computing and Visualization. (arXiv:2010.14831v1 [cs.LG])</h2>
<h3>Stan Z. Li, Zelin Zang, Lirong Wu</h3>
<p>The ability to preserve local geometry of highly nonlinear manifolds in high
dimensional spaces and properly unfold them into lower dimensional hyperplanes
is the key to the success of manifold computing, nonlinear dimensionality
reduction (NLDR) and visualization. This paper proposes a novel method, called
elastic locally isometric smoothness (ELIS), to empower deep neural networks
with such an ability. ELIS requires that a desired metric between points should
be preserved across layers in order to preserve local geometry; such a
smoothness constraint effectively regularizes vector-based transformations to
become well-behaved local metric-preserving homeomorphisms. Moreover, ELIS
requires that the smoothness should be imposed in a way to render sufficient
flexibility for tackling complicated nonlinearity and non-Euclideanity; this is
achieved layer-wisely via nonlinearity in both the similarity and activation
functions. The ELIS method incorporates a class of suitable nonlinear
similarity functions into a two-way divergence loss and uses hyperparameter
continuation in finding optimal solutions. Extensive experiments, comparisons,
and ablation study demonstrate that ELIS can deliver results not only superior
to UMAP and t-SNE for and visualization but also better than other leading
counterparts of manifold and autoencoder learning for NLDR and manifold data
generation.
</p>
<a href="http://arxiv.org/abs/2010.14831" target="_blank">arXiv:2010.14831</a> [<a href="http://arxiv.org/pdf/2010.14831" target="_blank">pdf</a>]

<h2>DeepQ Stepper: A framework for reactive dynamic walking on uneven terrain. (arXiv:2010.14834v1 [cs.RO])</h2>
<h3>Avadesh Meduri, Majid Khadiv, Ludovic Righetti</h3>
<p>Reactive stepping and push recovery for biped robots is often restricted to
flat terrains because of the difficulty in computing capture regions for
nonlinear dynamic models. In this paper, we address this limitation by using
reinforcement learning to approximately learn the 3D capture region for such
systems. We propose a novel 3D reactive stepper, The DeepQ stepper, that
computes optimal step locations for walking at different velocities using the
3D capture regions approximated by the action-value function. We demonstrate
the ability of the approach to learn stepping with a simplified 3D pendulum
model and a full robot dynamics. Further, the stepper achieves a higher
performance when it learns approximate capture regions while taking into
account the entire dynamics of the robot that are often ignored in existing
reactive steppers based on simplified models. The DeepQ stepper can handle non
convex terrain with obstacles, walk on restricted surfaces like stepping stones
and recover from external disturbances for a constant computational cost.
</p>
<a href="http://arxiv.org/abs/2010.14834" target="_blank">arXiv:2010.14834</a> [<a href="http://arxiv.org/pdf/2010.14834" target="_blank">pdf</a>]

<h2>Dynamically Feasible Deep Reinforcement Learning Policy for Robot Navigation in Dense Mobile Crowds. (arXiv:2010.14838v1 [cs.RO])</h2>
<h3>Utsav Patel, Nithish Kumar, Adarsh Jagan Sathyamoorthy, Dinesh Manocha</h3>
<p>We present a novel Deep Reinforcement Learning (DRL) based policy for mobile
robot navigation in dynamic environments that computes dynamically feasible and
spatially aware robot velocities. Our method addresses two primary issues
associated with the Dynamic Window Approach (DWA) and DRL-based navigation
policies and solves them by using the benefits of one method to fix the issues
of the other. The issues are: 1. DWA not utilizing the time evolution of the
environment while choosing velocities from the dynamically feasible velocity
set leading to sub-optimal dynamic collision avoidance behaviors, and 2.
DRL-based navigation policies computing velocities that often violate the
dynamics constraints such as the non-holonomic and acceleration constraints of
the robot. Our DRL-based method generates velocities that are dynamically
feasible while accounting for the motion of the obstacles in the environment.
This is done by embedding the changes in the environment's state in a novel
observation space and a reward function formulation that reinforces spatially
aware obstacle avoidance maneuvers. We evaluate our method in realistic 3-D
simulation and on a real differential drive robot in challenging indoor
scenarios with crowds of varying densities. We make comparisons with
traditional and current state-of-the-art collision avoidance methods and
observe significant improvements in terms of collision rate, number of dynamics
constraint violations and smoothness. We also conduct ablation studies to
highlight the advantages and explain the rationale behind our observation space
construction, reward structure and network architecture.
</p>
<a href="http://arxiv.org/abs/2010.14838" target="_blank">arXiv:2010.14838</a> [<a href="http://arxiv.org/pdf/2010.14838" target="_blank">pdf</a>]

<h2>Micro Stripes Analyses for Iris Presentation Attack Detection. (arXiv:2010.14850v1 [cs.CV])</h2>
<h3>Meiling Fang, Naser Damer, Florian Kirchbuchner, Arjan Kuijper</h3>
<p>Iris recognition systems are vulnerable to the presentation attacks, such as
textured contact lenses or printed images. In this paper, we propose a
lightweight framework to detect iris presentation attacks by extracting
multiple micro-stripes of expanded normalized iris textures. In this procedure,
a standard iris segmentation is modified. For our presentation attack detection
network to better model the classification problem, the segmented area is
processed to provide lower dimensional input segments and a higher number of
learning samples. Our proposed Micro Stripes Analyses (MSA) solution samples
the segmented areas as individual stripes. Then, the majority vote makes the
final classification decision of those micro-stripes. Experiments are
demonstrated on five databases, where two databases (IIITD-WVU and Notre Dame)
are from the LivDet-2017 Iris competition. An in-depth experimental evaluation
of this framework reveals a superior performance compared with state-of-the-art
algorithms. Moreover, our solution minimizes the confusion between textured
(attack) and soft (bona fide) contact lens presentations.
</p>
<a href="http://arxiv.org/abs/2010.14850" target="_blank">arXiv:2010.14850</a> [<a href="http://arxiv.org/pdf/2010.14850" target="_blank">pdf</a>]

<h2>Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation. (arXiv:2010.14851v1 [cs.CV])</h2>
<h3>Jianyuan Wang, Yiran Zhong, Yuchao Dai, Kaihao Zhang, Pan Ji, Hongdong Li</h3>
<p>Learning matching costs has been shown to be critical to the success of the
state-of-the-art deep stereo matching methods, in which 3D convolutions are
applied on a 4D feature volume to learn a 3D cost volume. However, this
mechanism has never been employed for the optical flow task. This is mainly due
to the significantly increased search dimension in the case of optical flow
computation, ie, a straightforward extension would require dense 4D
convolutions in order to process a 5D feature volume, which is computationally
prohibitive. This paper proposes a novel solution that is able to bypass the
requirement of building a 5D feature volume while still allowing the network to
learn suitable matching costs from data. Our key innovation is to decouple the
connection between 2D displacements and learn the matching costs at each 2D
displacement hypothesis independently, ie, displacement-invariant cost
learning. Specifically, we apply the same 2D convolution-based matching net
independently on each 2D displacement hypothesis to learn a 4D cost volume.
Moreover, we propose a displacement-aware projection layer to scale the learned
cost volume, which reconsiders the correlation between different displacement
candidates and mitigates the multi-modal problem in the learned cost volume.
The cost volume is then projected to optical flow estimation through a 2D
soft-argmin layer. Extensive experiments show that our approach achieves
state-of-the-art accuracy on various datasets, and outperforms all published
optical flow methods on the Sintel benchmark.
</p>
<a href="http://arxiv.org/abs/2010.14851" target="_blank">arXiv:2010.14851</a> [<a href="http://arxiv.org/pdf/2010.14851" target="_blank">pdf</a>]

<h2>The Evidence Lower Bound of Variational Autoencoders Converges to a Sum of Three Entropies. (arXiv:2010.14860v1 [stat.ML])</h2>
<h3>J&#xf6;rg L&#xfc;cke, Dennis Forster, Zhenwen Dai</h3>
<p>The central objective function of a variational autoencoder (VAE) is its
variational lower bound. Here we show that for standard VAEs the variational
bound is at convergence equal to the sum of three entropies: the (negative)
entropy of the latent distribution, the expected (negative) entropy of the
observable distribution, and the average entropy of the variational
distributions. Our derived analytical results are exact and apply for small as
well as complex neural networks for decoder and encoder. Furthermore, they
apply for finite and infinitely many data points and at any stationary point
(including local and global maxima). As a consequence, we show that the
variance parameters of encoder and decoder play the key role in determining the
values of variational bounds at convergence. Furthermore, the obtained results
can allow for closed-form analytical expressions at convergence, which may be
unexpected as neither variational bounds of VAEs nor log-likelihoods of VAEs
are closed-form during learning. As our main contribution, we provide the
proofs for convergence of standard VAEs to sums of entropies. Furthermore, we
numerically verify our analytical results and discuss some potential
applications. The obtained equality to entropy sums provides novel information
on those points in parameter space that variational learning converges to. As
such, we believe they can potentially significantly contribute to our
understanding of established as well as novel VAE approaches.
</p>
<a href="http://arxiv.org/abs/2010.14860" target="_blank">arXiv:2010.14860</a> [<a href="http://arxiv.org/pdf/2010.14860" target="_blank">pdf</a>]

<h2>Bayesian Methods for Semi-supervised Text Annotation. (arXiv:2010.14872v1 [cs.CL])</h2>
<h3>Kristian Miok, Gregor Pirs, Marko Robnik-Sikonja</h3>
<p>Human annotations are an important source of information in the development
of natural language understanding approaches. As under the pressure of
productivity annotators can assign different labels to a given text, the
quality of produced annotations frequently varies. This is especially the case
if decisions are difficult, with high cognitive load, requires awareness of
broader context, or careful consideration of background knowledge. To alleviate
the problem, we propose two semi-supervised methods to guide the annotation
process: a Bayesian deep learning model and a Bayesian ensemble method. Using a
Bayesian deep learning method, we can discover annotations that cannot be
trusted and might require reannotation. A recently proposed Bayesian ensemble
method helps us to combine the annotators' labels with predictions of trained
models. According to the results obtained from three hate speech detection
experiments, the proposed Bayesian methods can improve the annotations and
prediction performance of BERT models.
</p>
<a href="http://arxiv.org/abs/2010.14872" target="_blank">arXiv:2010.14872</a> [<a href="http://arxiv.org/pdf/2010.14872" target="_blank">pdf</a>]

<h2>Fighting Copycat Agents in Behavioral Cloning from Observation Histories. (arXiv:2010.14876v1 [cs.LG])</h2>
<h3>Chuan Wen, Jierui Lin, Trevor Darrell, Dinesh Jayaraman, Yang Gao</h3>
<p>Imitation learning trains policies to map from input observations to the
actions that an expert would choose. In this setting, distribution shift
frequently exacerbates the effect of misattributing expert actions to nuisance
correlates among the observed variables. We observe that a common instance of
this causal confusion occurs in partially observed settings when expert actions
are strongly correlated over time: the imitator learns to cheat by predicting
the expert's previous action, rather than the next action. To combat this
"copycat problem", we propose an adversarial approach to learn a feature
representation that removes excess information about the previous expert action
nuisance correlate, while retaining the information necessary to predict the
next action. In our experiments, our approach improves performance
significantly across a variety of partially observed imitation learning tasks.
</p>
<a href="http://arxiv.org/abs/2010.14876" target="_blank">arXiv:2010.14876</a> [<a href="http://arxiv.org/pdf/2010.14876" target="_blank">pdf</a>]

<h2>Hierarchical Gaussian Processes with Wasserstein-2 Kernels. (arXiv:2010.14877v1 [stat.ML])</h2>
<h3>Sebastian Popescu, David Sharp, James Cole, Ben Glocker</h3>
<p>We investigate the usefulness of Wasserstein-2 kernels in the context of
hierarchical Gaussian Processes. Stemming from an observation that stacking
Gaussian Processes severely diminishes the model's ability to detect outliers,
which when combined with non-zero mean functions, further extrapolates low
variance to regions with low training data density, we posit that directly
taking into account the variance in the computation of Wasserstein-2 kernels is
of key importance towards maintaining outlier status as we progress through the
hierarchy. We propose two new models operating in Wasserstein space which can
be seen as equivalents to Deep Kernel Learning and Deep GPs. Through extensive
experiments, we show improved performance on large scale datasets and improved
out-of-distribution detection on both toy and real data.
</p>
<a href="http://arxiv.org/abs/2010.14877" target="_blank">arXiv:2010.14877</a> [<a href="http://arxiv.org/pdf/2010.14877" target="_blank">pdf</a>]

<h2>An Optimal Control Approach to Learning in SIDARTHE Epidemic model. (arXiv:2010.14878v1 [cs.LG])</h2>
<h3>Andrea Zugarini, Enrico Meloni, Alessandro Betti, Andrea Panizza, Marco Corneli, Marco Gori</h3>
<p>The COVID-19 outbreak has stimulated the interest in the proposal of novel
epidemiological models to predict the course of the epidemic so as to help
planning effective control strategies. In particular, in order to properly
interpret the available data, it has become clear that one must go beyond most
classic epidemiological models and consider models that, like the recently
proposed SIDARTHE, offer a richer description of the stages of infection. The
problem of learning the parameters of these models is of crucial importance
especially when assuming that they are time-variant, which further enriches
their effectiveness. In this paper we propose a general approach for learning
time-variant parameters of dynamic compartmental models from epidemic data. We
formulate the problem in terms of a functional risk that depends on the
learning variables through the solutions of a dynamic system. The resulting
variational problem is then solved by using a gradient flow on a suitable,
regularized functional. We forecast the epidemic evolution in Italy and France.
Results indicate that the model provides reliable and challenging predictions
over all available data as well as the fundamental role of the chosen strategy
on the time-variant parameters.
</p>
<a href="http://arxiv.org/abs/2010.14878" target="_blank">arXiv:2010.14878</a> [<a href="http://arxiv.org/pdf/2010.14878" target="_blank">pdf</a>]

<h2>Medical Deep Learning -- A systematic Meta-Review. (arXiv:2010.14881v1 [eess.IV])</h2>
<h3>Jan Egger, Christina Gsxaner, Antonio Pepe, Jianning Li</h3>
<p>Deep learning had a remarkable impact in different scientific disciplines
during the last years. This was demonstrated in numerous tasks, where deep
learning algorithms were able to outperform the state-of-art methods, also in
image processing and analysis. Moreover, deep learning delivers good results in
tasks like autonomous driving, which could not have been performed
automatically before. There are even applications where deep learning
outperformed humans, like object recognition or games. Another field in which
this development is showing a huge potential is the medical domain. With the
collection of large quantities of patient records and data, and a trend towards
personalized treatments, there is a great need for an automatic and reliable
processing and analysis of this information. Patient data is not only collected
in clinical centres, like hospitals, but it relates also to data coming from
general practitioners, healthcare smartphone apps or online websites, just to
name a few. This trend resulted in new, massive research efforts during the
last years. In Q2/2020, the search engine PubMed returns already over 11.000
results for the search term $'$deep learning$'$, and around 90% of these
publications are from the last three years. Hence, a complete overview of the
field of $'$medical deep learning$'$ is almost impossible to obtain and getting
a full overview of medical sub-fields gets increasingly more difficult.
Nevertheless, several review and survey articles about medical deep learning
have been presented within the last years. They focused, in general, on
specific medical scenarios, like the analysis of medical images containing
specific pathologies. With these surveys as foundation, the aim of this
contribution is to provide a very first high-level, systematic meta-review of
medical deep learning surveys.
</p>
<a href="http://arxiv.org/abs/2010.14881" target="_blank">arXiv:2010.14881</a> [<a href="http://arxiv.org/pdf/2010.14881" target="_blank">pdf</a>]

<h2>Morphological Development at the Evolutionary Timescale: Robotic Developmental Evolution. (arXiv:2010.14894v1 [cs.NE])</h2>
<h3>Fabien C. Y. Benureau, Jun Tani</h3>
<p>Evolution and development operate at different timescales; generations for
the one, a lifetime for the other. These two processes, the basis of much of
life on earth, interact in many non-trivial ways, but their temporal
hierarchy---evolution overarching development---is observed for all
multicellular lifeforms. When designing robots however, this tenet lifts: it
becomes---however natural---a design choice. We propose to inverse this
temporal hierarchy and design a developmental process happening at the
phylogenetic timescale. Over a classic evolutionary search aimed at finding
good gaits for a tentacle robot, we add a developmental process over the
robots' morphologies. In each generation, the morphology of the robots does not
change. But from one generation to the next, the morphology develops. Much like
we become bigger, stronger and heavier as we age, our robots are bigger,
stronger and heavier with each passing generation. Our robots start with baby
morphologies, and a few thousand generations later, end-up with adult ones. We
show that this produces better and qualitatively different gaits than an
evolutionary search with only adult robots, and that it prevents premature
convergence by fostering exploration. This method is conceptually simple, and
can be effective on small or large populations of robots, and intrinsic to the
robot and its morphology, and thus not specific to the task and the fitness
function it is evaluated on. Furthermore, by recasting the evolutionary search
as a learning process, these results can be viewed in the context of
developmental learning robotics.
</p>
<a href="http://arxiv.org/abs/2010.14894" target="_blank">arXiv:2010.14894</a> [<a href="http://arxiv.org/pdf/2010.14894" target="_blank">pdf</a>]

<h2>A general method for estimating the prevalence of Influenza-Like-Symptoms with Wikipedia data. (arXiv:2010.14903v1 [cs.CY])</h2>
<h3>Giovanni De Toni, Cristian Consonni, Alberto Montresor</h3>
<p>Influenza is an acute respiratory seasonal disease that affects millions of
people worldwide and causes thousands of deaths in Europe alone. Being able to
estimate in a fast and reliable way the impact of an illness on a given country
is essential to plan and organize effective countermeasures, which is now
possible by leveraging unconventional data sources like web searches and
visits. In this study, we show the feasibility of exploiting information about
Wikipedia's page views of a selected group of articles and machine learning
models to obtain accurate estimates of influenza-like illnesses incidence in
four European countries: Italy, Germany, Belgium, and the Netherlands. We
propose a novel language-agnostic method, based on two algorithms, Personalized
PageRank and CycleRank, to automatically select the most relevant Wikipedia
pages to be monitored without the need for expert supervision. We then show how
our model is able to reach state-of-the-art results by comparing it with
previous solutions.
</p>
<a href="http://arxiv.org/abs/2010.14903" target="_blank">arXiv:2010.14903</a> [<a href="http://arxiv.org/pdf/2010.14903" target="_blank">pdf</a>]

<h2>Online feature selection for rapid, low-overhead learning in networked systems. (arXiv:2010.14907v1 [cs.LG])</h2>
<h3>Xiaoxuan Wang (1), Forough Shahab Samani (1 and 2), Rolf Stadler (1 and 2) ((1) KTH Royal Institute of Technology, Sweden (2) RISE Research Institutes of Sweden)</h3>
<p>Data-driven functions for operation and management often require measurements
collected through monitoring for model training and prediction. The number of
data sources can be very large, which requires a significant communication and
computing overhead to continuously extract and collect this data, as well as to
train and update the machine-learning models. We present an online algorithm,
called OSFS, that selects a small feature set from a large number of available
data sources, which allows for rapid, low-overhead, and effective learning and
prediction. OSFS is instantiated with a feature ranking algorithm and applies
the concept of a stable feature set, which we introduce in the paper. We
perform extensive, experimental evaluation of our method on data from an
in-house testbed. We find that OSFS requires several hundreds measurements to
reduce the number of data sources by two orders of magnitude, from which models
are trained with acceptable prediction accuracy. While our method is heuristic
and can be improved in many ways, the results clearly suggests that many
learning tasks do not require a lengthy monitoring phase and expensive offline
training.
</p>
<a href="http://arxiv.org/abs/2010.14907" target="_blank">arXiv:2010.14907</a> [<a href="http://arxiv.org/pdf/2010.14907" target="_blank">pdf</a>]

<h2>Visually Guided Balloon Popping with an Autonomous MAV at MBZIRC 2020. (arXiv:2010.14913v1 [cs.RO])</h2>
<h3>Marius Beul, Simon Bultmann, Andre Rochow, Radu Alexandru Rosu, Daniel Schleich, Malte Splietker, Sven Behnke</h3>
<p>Visually guided control of micro aerial vehicles (MAV) demands for robust
real-time perception, fast trajectory generation, and a capable flight
platform. We present a fully autonomous MAV that is able to pop balloons,
relying only on onboard sensing and computing. The system is evaluated with
real robot experiments during the Mohamed Bin Zayed International Robotics
Challenge (MBZIRC) 2020 where it showed its resilience and speed. In all three
competition runs we were able to pop all five balloons in less than two minutes
flight time with a single MAV.
</p>
<a href="http://arxiv.org/abs/2010.14913" target="_blank">arXiv:2010.14913</a> [<a href="http://arxiv.org/pdf/2010.14913" target="_blank">pdf</a>]

<h2>Transferable Universal Adversarial Perturbations Using Generative Models. (arXiv:2010.14919v1 [cs.CV])</h2>
<h3>Atiye Sadat Hashemi, Andreas B&#xe4;r, Saeed Mozaffari, Tim Fingscheidt</h3>
<p>Deep neural networks tend to be vulnerable to adversarial perturbations,
which by adding to a natural image can fool a respective model with high
confidence. Recently, the existence of image-agnostic perturbations, also known
as universal adversarial perturbations (UAPs), were discovered. However,
existing UAPs still lack a sufficiently high fooling rate, when being applied
to an unknown target model. In this paper, we propose a novel deep learning
technique for generating more transferable UAPs. We utilize a perturbation
generator and some given pretrained networks so-called source models to
generate UAPs using the ImageNet dataset. Due to the similar feature
representation of various model architectures in the first layer, we propose a
loss formulation that focuses on the adversarial energy only in the respective
first layer of the source models. This supports the transferability of our
generated UAPs to any other target model. We further empirically analyze our
generated UAPs and demonstrate that these perturbations generalize very well
towards different target models. Surpassing the current state of the art in
both, fooling rate and model-transferability, we can show the superiority of
our proposed approach. Using our generated non-targeted UAPs, we obtain an
average fooling rate of 93.36% on the source models (state of the art: 82.16%).
Generating our UAPs on the deep ResNet-152, we obtain about a 12% absolute
fooling rate advantage vs. cutting-edge methods on VGG-16 and VGG-19 target
models.
</p>
<a href="http://arxiv.org/abs/2010.14919" target="_blank">arXiv:2010.14919</a> [<a href="http://arxiv.org/pdf/2010.14919" target="_blank">pdf</a>]

<h2>Bridging the Modality Gap for Speech-to-Text Translation. (arXiv:2010.14920v1 [cs.CL])</h2>
<h3>Yuchen Liu, Junnan Zhu, Jiajun Zhang, Chengqing Zong</h3>
<p>End-to-end speech translation aims to translate speech in one language into
text in another language via an end-to-end way. Most existing methods employ an
encoder-decoder structure with a single encoder to learn acoustic
representation and semantic information simultaneously, which ignores the
speech-and-text modality differences and makes the encoder overloaded, leading
to great difficulty in learning such a model. To address these issues, we
propose a Speech-to-Text Adaptation for Speech Translation (STAST) model which
aims to improve the end-to-end model performance by bridging the modality gap
between speech and text. Specifically, we decouple the speech translation
encoder into three parts and introduce a shrink mechanism to match the length
of speech representation with that of the corresponding text transcription. To
obtain better semantic representation, we completely integrate a text-based
translation model into the STAST so that two tasks can be trained in the same
latent space. Furthermore, we introduce a cross-modal adaptation method to
close the distance between speech and text representation. Experimental results
on English-French and English-German speech translation corpora have shown that
our model significantly outperforms strong baselines, and achieves the new
state-of-the-art performance.
</p>
<a href="http://arxiv.org/abs/2010.14920" target="_blank">arXiv:2010.14920</a> [<a href="http://arxiv.org/pdf/2010.14920" target="_blank">pdf</a>]

<h2>Comparison Analysis of Tree Based and Ensembled Regression Algorithms for Traffic Accident Severity Prediction. (arXiv:2010.14921v1 [cs.OH])</h2>
<h3>Muhammad Umer, Saima Sadiq, Abid Ishaq, Saleem Ullah, Najia Saher, Hamza Ahmad Madni</h3>
<p>Rapid increase of traffic volume on urban roads over time has changed the
traffic scenario globally. It has also increased the ratio of road accidents
that can be severe and fatal in the worst case. To improve traffic safety and
its management on urban roads, there is a need for prediction of severity level
of accidents. Various machine learning models are being used for accident
prediction. In this study, tree based ensemble models (Random Forest, AdaBoost,
Extra Tree, and Gradient Boosting) and ensemble of two statistical models
(Logistic Regression Stochastic Gradient Descent) as voting classifiers are
compared for prediction of road accident severity. Significant features that
are strongly correlated with the accident severity are identified by Random
Forest. Analysis proved Random Forest as the best performing model with highest
classification results with 0.974 accuracy, 0.954 precision, 0.930 recall and
0.942 F-score using 20 most significant features as compared to other
techniques classification of road accidents severity.
</p>
<a href="http://arxiv.org/abs/2010.14921" target="_blank">arXiv:2010.14921</a> [<a href="http://arxiv.org/pdf/2010.14921" target="_blank">pdf</a>]

<h2>Multimodal End-to-End Learning for Autonomous Steering in Adverse Road and Weather Conditions. (arXiv:2010.14924v1 [cs.CV])</h2>
<h3>Jyri Maanp&#xe4;&#xe4;, Josef Taher, Petri Manninen, Leo Pakola, Iaroslav Melekhov, Juha Hyypp&#xe4;</h3>
<p>Autonomous driving is challenging in adverse road and weather conditions in
which there might not be lane lines, the road might be covered in snow and the
visibility might be poor. We extend the previous work on end-to-end learning
for autonomous steering to operate in these adverse real-life conditions with
multimodal data. We collected 28 hours of driving data in several road and
weather conditions and trained convolutional neural networks to predict the car
steering wheel angle from front-facing color camera images and lidar range and
reflectance data. We compared the CNN model performances based on the different
modalities and our results show that the lidar modality improves the
performances of different multimodal sensor-fusion models. We also performed
on-road tests with different models and they support this observation.
</p>
<a href="http://arxiv.org/abs/2010.14924" target="_blank">arXiv:2010.14924</a> [<a href="http://arxiv.org/pdf/2010.14924" target="_blank">pdf</a>]

<h2>MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis. (arXiv:2010.14925v1 [cs.CV])</h2>
<h3>Jiancheng Yang, Rui Shi, Bingbing Ni</h3>
<p>We present MedMNIST, a collection of 10 pre-processed medical open datasets.
MedMNIST is standardized to perform classification tasks on lightweight 28x28
images, which requires no background knowledge. Covering the primary data
modalities in medical image analysis, it is diverse on data scale (from 100 to
100,000) and tasks (binary/multi-class, ordinal regression and multi-label).
MedMNIST could be used for educational purpose, rapid prototyping, multi-modal
machine learning or AutoML in medical image analysis. Moreover, MedMNIST
Classification Decathlon is designed to benchmark AutoML algorithms on all 10
datasets; We have compared several baseline methods, including open-source or
commercial AutoML tools. The datasets, evaluation code and baseline methods for
MedMNIST are publicly available at https://medmnist.github.io/.
</p>
<a href="http://arxiv.org/abs/2010.14925" target="_blank">arXiv:2010.14925</a> [<a href="http://arxiv.org/pdf/2010.14925" target="_blank">pdf</a>]

<h2>Graph Contrastive Learning with Adaptive Augmentation. (arXiv:2010.14945v1 [cs.LG])</h2>
<h3>Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, Liang Wang</h3>
<p>Recently, contrastive learning (CL) has emerged as a successful method for
unsupervised graph representation learning. Most graph CL methods first perform
stochastic augmentation on the input graph to obtain two graph views and
maximize the agreement of representations in the two views. Despite the
prosperous development of graph CL methods, the design of graph augmentation
schemes---a crucial component in CL---remains rarely explored. We argue that
the data augmentation schemes should preserve intrinsic structural and
attribute information of graphs, which will force the model to learn
representations that are insensitive to perturbation on unimportant nodes and
edges. However, most existing methods adopt uniform data augmentation schemes,
like uniformly dropping edges and uniformly shuffling features, leading to
suboptimal performance. In this paper, we propose a novel graph contrastive
representation learning method with adaptive augmentation that incorporates
various priors for topological and semantic aspects of the graph. Specifically,
on the topology level, we design augmentation schemes based on node centrality
measures to highlight important connective structures. On the node attribute
level, we corrupt node features by adding more noise to unimportant node
features, to enforce the model to recognize underlying semantic information. We
perform extensive experiments of node classification on a variety of real-world
datasets. Experimental results demonstrate that our proposed method
consistently outperforms existing state-of-the-art methods and even surpasses
some supervised counterparts, which validates the effectiveness of the proposed
contrastive framework with adaptive augmentation.
</p>
<a href="http://arxiv.org/abs/2010.14945" target="_blank">arXiv:2010.14945</a> [<a href="http://arxiv.org/pdf/2010.14945" target="_blank">pdf</a>]

<h2>Smart Anomaly Detection in Sensor Systems. (arXiv:2010.14946v1 [cs.LG])</h2>
<h3>L. Erhan, M. Ndubuaku, M. Di Mauro, W. Song, M. Chen, G. Fortino, O. Bagdasar, A. Liotta</h3>
<p>Anomaly detection is concerned with identifying data patterns that deviate
remarkably from the expected behaviour. This is an important research problem,
due to its broad set of application domains, from data analysis to e-health,
cybersecurity, predictive maintenance, fault prevention, and industrial
automation. Herein, we review state-of-the-art methods that may be employed to
detect anomalies in the specific area of sensor systems, which poses hard
challenges in terms of information fusion, data volumes, data speed, and
network/energy efficiency, to mention but the most pressing ones. In this
context, anomaly detection is a particularly hard problem, given the need to
find computing-energy accuracy trade-offs in a constrained environment. We
taxonomize methods ranging from conventional techniques (statistical methods,
time-series analysis, signal processing, etc.) to data-driven techniques
(supervised learning, reinforcement learning, deep learning, etc.). We also
look at the impact that different architectural environments (Cloud, Fog, Edge)
can have on the sensors ecosystem. The review points to the most promising
intelligent-sensing methods, and pinpoints a set of interesting open issues and
challenges.
</p>
<a href="http://arxiv.org/abs/2010.14946" target="_blank">arXiv:2010.14946</a> [<a href="http://arxiv.org/pdf/2010.14946" target="_blank">pdf</a>]

<h2>Leveraging Visual Question Answering to Improve Text-to-Image Synthesis. (arXiv:2010.14953v1 [cs.CV])</h2>
<h3>Stanislav Frolov, Shailza Jolly, J&#xf6;rn Hees, Andreas Dengel</h3>
<p>Generating images from textual descriptions has recently attracted a lot of
interest. While current models can generate photo-realistic images of
individual objects such as birds and human faces, synthesising images with
multiple objects is still very difficult. In this paper, we propose an
effective way to combine Text-to-Image (T2I) synthesis with Visual Question
Answering (VQA) to improve the image quality and image-text alignment of
generated images by leveraging the VQA 2.0 dataset. We create additional
training samples by concatenating question and answer (QA) pairs and employ a
standard VQA model to provide the T2I model with an auxiliary learning signal.
We encourage images generated from QA pairs to look realistic and additionally
minimize an external VQA loss. Our method lowers the FID from 27.84 to 25.38
and increases the R-prec. from 83.82% to 84.79% when compared to the baseline,
which indicates that T2I synthesis can successfully be improved using a
standard VQA model.
</p>
<a href="http://arxiv.org/abs/2010.14953" target="_blank">arXiv:2010.14953</a> [<a href="http://arxiv.org/pdf/2010.14953" target="_blank">pdf</a>]

<h2>Object Hider: Adversarial Patch Attack Against Object Detectors. (arXiv:2010.14974v1 [cs.CV])</h2>
<h3>Yusheng Zhao, Huanqian Yan, Xingxing Wei</h3>
<p>Deep neural networks have been widely used in many computer vision tasks.
However, it is proved that they are susceptible to small, imperceptible
perturbations added to the input. Inputs with elaborately designed
perturbations that can fool deep learning models are called adversarial
examples, and they have drawn great concerns about the safety of deep neural
networks. Object detection algorithms are designed to locate and classify
objects in images or videos and they are the core of many computer vision
tasks, which have great research value and wide applications. In this paper, we
focus on adversarial attack on some state-of-the-art object detection models.
As a practical alternative, we use adversarial patches for the attack. Two
adversarial patch generation algorithms have been proposed: the heatmap-based
algorithm and the consensus-based algorithm. The experiment results have shown
that the proposed methods are highly effective, transferable and generic.
Additionally, we have applied the proposed methods to competition "Adversarial
Challenge on Object Detection" that is organized by Alibaba on the Tianchi
platform and won top 7 in 1701 teams. Code is available at:
https://github.com/FenHua/DetDak
</p>
<a href="http://arxiv.org/abs/2010.14974" target="_blank">arXiv:2010.14974</a> [<a href="http://arxiv.org/pdf/2010.14974" target="_blank">pdf</a>]

<h2>Real-time Tropical Cyclone Intensity Estimation by Handling Temporally Heterogeneous Satellite Data. (arXiv:2010.14977v1 [cs.CV])</h2>
<h3>Boyo Chen, Buo-Fu Chen, Yun-Nung Chen</h3>
<p>Analyzing big geophysical observational data collected by multiple advanced
sensors on various satellite platforms promotes our understanding of the
geophysical system. For instance, convolutional neural networks (CNN) have
achieved great success in estimating tropical cyclone (TC) intensity based on
satellite data with fixed temporal frequency (e.g., 3 h). However, to achieve
more timely (under 30 min) and accurate TC intensity estimates, a deep learning
model is demanded to handle temporally-heterogeneous satellite observations.
Specifically, infrared (IR1) and water vapor (WV) images are available under
every 15 minutes, while passive microwave rain rate (PMW) is available for
about every 3 hours. Meanwhile, the visible (VIS) channel is severely affected
by noise and sunlight intensity, making it difficult to be utilized. Therefore,
we propose a novel framework that combines generative adversarial network (GAN)
with CNN. The model utilizes all data, including VIS and PMW information,
during the training phase and eventually uses only the high-frequent IR1 and WV
data for providing intensity estimates during the predicting phase.
Experimental results demonstrate that the hybrid GAN-CNN framework achieves
comparable precision to the state-of-the-art models, while possessing the
capability of increasing the maximum estimation frequency from 3 hours to less
than 15 minutes.
</p>
<a href="http://arxiv.org/abs/2010.14977" target="_blank">arXiv:2010.14977</a> [<a href="http://arxiv.org/pdf/2010.14977" target="_blank">pdf</a>]

<h2>Toyota Smarthome Untrimmed: Real-World Untrimmed Videos for Activity Detection. (arXiv:2010.14982v1 [cs.CV])</h2>
<h3>Rui Dai, Srijan Das, Saurav Sharma, Luca Minciullo, Lorenzo Garattoni, Francois Bremond, Gianpiero Francesca</h3>
<p>This work aims at building a large scale dataset with daily-living activities
performed in a natural manner. Activities performed in a spontaneous manner
lead to many real-world challenges that are often ignored by the vision
community. This includes low inter-class due to the presence of similar
activities and high intra-class variance, low camera framing, low resolution,
long-tail distribution of activities, and occlusions. To this end, we propose
the Toyota Smarthome Untrimmed (TSU) dataset, which provides spontaneous
activities with rich and dense annotations to address the detection of complex
activities in real-world scenarios.
</p>
<a href="http://arxiv.org/abs/2010.14982" target="_blank">arXiv:2010.14982</a> [<a href="http://arxiv.org/pdf/2010.14982" target="_blank">pdf</a>]

<h2>Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?. (arXiv:2010.14986v1 [cs.LG])</h2>
<h3>Anna-Kathrin Kopetzki, Bertrand Charpentier, Daniel Z&#xfc;gner, Sandhya Giri, Stephan G&#xfc;nnemann</h3>
<p>Robustness to adversarial perturbations and accurate uncertainty estimation
are crucial for reliable application of deep learning in real world settings.
Dirichlet-based uncertainty (DBU) models are a family of models that predict
the parameters of a Dirichlet distribution (instead of a categorical one) and
promise to signal when not to trust their predictions. Untrustworthy
predictions are obtained on unknown or ambiguous samples and marked with a high
uncertainty by the models. In this work, we show that DBU models with standard
training are not robust w.r.t. three important tasks in the field of
uncertainty estimation. In particular, we evaluate how useful the uncertainty
estimates are to (1) indicate correctly classified samples, and (2) to detect
adversarial examples that try to fool classification. We further evaluate the
reliability of DBU models on the task of (3) distinguishing between
in-distribution (ID) and out-of-distribution (OOD) data. To this end, we
present the first study of certifiable robustness for DBU models. Furthermore,
we propose novel uncertainty attacks that fool models into assigning high
confidence to OOD data and low confidence to ID data, respectively. Based on
our results, we explore the first approaches to make DBU models more robust. We
use adversarial training procedures based on label attacks, uncertainty
attacks, or random noise and demonstrate how they affect robustness of DBU
models on ID data and OOD data.
</p>
<a href="http://arxiv.org/abs/2010.14986" target="_blank">arXiv:2010.14986</a> [<a href="http://arxiv.org/pdf/2010.14986" target="_blank">pdf</a>]

<h2>Geometric Scattering Attention Networks. (arXiv:2010.15010v1 [cs.LG])</h2>
<h3>Yimeng Min, Frederik Wenkel, Guy Wolf</h3>
<p>Geometric scattering has recently gained recognition in graph representation
learning, and recent work has shown that integrating scattering features in
graph convolution networks (GCNs) can alleviate the typical oversmoothing of
features in node representation learning. However, scattering methods often
rely on handcrafted design, requiring careful selection of frequency bands via
a cascade of wavelet transforms, as well as an effective weight sharing scheme
to combine together low- and band-pass information. Here, we introduce a new
attention-based architecture to produce adaptive task-driven node
representations by implicitly learning node-wise weights for combining multiple
scattering and GCN channels in the network. We show the resulting geometric
scattering attention network (GSAN) outperforms previous networks in
semi-supervised node classification, while also enabling a spectral study of
extracted information by examining node-wise attention weights.
</p>
<a href="http://arxiv.org/abs/2010.15010" target="_blank">arXiv:2010.15010</a> [<a href="http://arxiv.org/pdf/2010.15010" target="_blank">pdf</a>]

<h2>Towards Supporting Programming Education at Scale via Live Streaming. (arXiv:2010.15015v1 [cs.HC])</h2>
<h3>Yan Chen, Walter S. Lasecki, Tao Dong</h3>
<p>Live streaming, which allows streamers to broadcast their work to live
viewers, is an emerging practice for teaching and learning computer
programming. Participation in live streaming is growing rapidly, despite
several apparent challenges, such as a general lack of training in pedagogy
among streamers and scarce signals about a stream's characteristics (e.g.,
difficulty, style, and usefulness) to help viewers decide what to watch. To
understand why people choose to participate in live streaming for teaching or
learning programming, and how they cope with both apparent and non-obvious
challenges, we interviewed 14 streamers and 12 viewers about their experience
with live streaming programming. Among other results, we found that the casual
and impromptu nature of live streaming makes it easier to prepare than
pre-recorded videos, and viewers have the opportunity to shape the content and
learning experience via real-time communication with both the streamer and each
other. Nonetheless, we identified several challenges that limit the potential
of live streaming as a learning medium. For example, streamers voiced privacy
and harassment concerns, and existing streaming platforms do not adequately
support viewer-streamer interactions, adaptive learning, and discovery and
selection of streaming content. Based on these findings, we suggest specialized
tools to facilitate knowledge sharing among people teaching and learning
computer programming online, and we offer design recommendations that promote a
healthy, safe, and engaging learning environment.
</p>
<a href="http://arxiv.org/abs/2010.15015" target="_blank">arXiv:2010.15015</a> [<a href="http://arxiv.org/pdf/2010.15015" target="_blank">pdf</a>]

<h2>Provably Efficient Online Agnostic Learning in Markov Games. (arXiv:2010.15020v1 [cs.LG])</h2>
<h3>Yi Tian, Yuanhao Wang, Tiancheng Yu, Suvrit Sra</h3>
<p>We study online agnostic learning, a problem that arises in episodic
multi-agent reinforcement learning where the actions of the opponents are
unobservable. We show that in this challenging setting, achieving sublinear
regret against the best response in hindsight is statistically hard. We then
consider a weaker notion of regret, and present an algorithm that achieves
after $K$ episodes a sublinear $\tilde{\mathcal{O}}(K^{3/4})$ regret. This is
the first sublinear regret bound (to our knowledge) in the online agnostic
setting. Importantly, our regret bound is independent of the size of the
opponents' action spaces. As a result, even when the opponents' actions are
fully observable, our regret bound improves upon existing analysis (e.g., (Xie
et al., 2020)) by an exponential factor in the number of opponents.
</p>
<a href="http://arxiv.org/abs/2010.15020" target="_blank">arXiv:2010.15020</a> [<a href="http://arxiv.org/pdf/2010.15020" target="_blank">pdf</a>]

<h2>DeepRite: Deep Recurrent Inverse TreatmEnt Weighting for Adjusting Time-varying Confounding in Modern Longitudinal Observational Data. (arXiv:2010.15028v1 [cs.LG])</h2>
<h3>Yanbo Xu, Cao Xiao, Jimeng Sun</h3>
<p>Counterfactual prediction is about predicting outcome of the unobserved
situation from the data. For example, given patient is on drug A, what would be
the outcome if she switch to drug B. Most of existing works focus on modeling
counterfactual outcome based on static data. However, many applications have
time-varying confounding effects such as multiple treatments over time. How to
model such time-varying effects from longitudinal observational data? How to
model complex high-dimensional dependency in the data? To address these
challenges, we propose Deep Recurrent Inverse TreatmEnt weighting (DeepRite) by
incorporating recurrent neural networks into two-phase adjustments for the
existence of time-varying confounding in modern longitudinal data. In phase I
cohort reweighting we fit one network for emitting time dependent inverse
probabilities of treatment, use them to generate a pseudo balanced cohort. In
phase II outcome progression, we input the adjusted data to the subsequent
predictive network for making counterfactual predictions. We evaluate DeepRite
on both synthetic data and a real data collected from sepsis patients in the
intensive care units. DeepRite is shown to recover the ground truth from
synthetic data, and estimate unbiased treatment effects from real data that can
be better aligned with the standard guidelines for management of sepsis thanks
to its applicability to create balanced cohorts.
</p>
<a href="http://arxiv.org/abs/2010.15028" target="_blank">arXiv:2010.15028</a> [<a href="http://arxiv.org/pdf/2010.15028" target="_blank">pdf</a>]

<h2>On Learning Continuous Pairwise Markov Random Fields. (arXiv:2010.15031v1 [cs.LG])</h2>
<h3>Abhin Shah, Devavrat Shah, Gregory W. Wornell</h3>
<p>We consider learning a sparse pairwise Markov Random Field (MRF) with
continuous-valued variables from i.i.d samples. We adapt the algorithm of
Vuffray et al. (2019) to this setting and provide finite-sample analysis
revealing sample complexity scaling logarithmically with the number of
variables, as in the discrete and Gaussian settings. Our approach is applicable
to a large class of pairwise MRFs with continuous variables and also has
desirable asymptotic properties, including consistency and normality under mild
conditions. Further, we establish that the population version of the
optimization criterion employed in Vuffray et al. (2019) can be interpreted as
local maximum likelihood estimation (MLE). As part of our analysis, we
introduce a robust variation of sparse linear regression a` la Lasso, which may
be of interest in its own right.
</p>
<a href="http://arxiv.org/abs/2010.15031" target="_blank">arXiv:2010.15031</a> [<a href="http://arxiv.org/pdf/2010.15031" target="_blank">pdf</a>]

<h2>Benchmarking Parallelism in FaaS Platforms. (arXiv:2010.15032v1 [cs.DC])</h2>
<h3>Daniel Barcelona-Pons, Pedro Garc&#xed;a-L&#xf3;pez</h3>
<p>Serverless computing has seen a myriad of work exploring its potential. Some
systems tackle Function-as-a-Service (FaaS) properties on automatic elasticity
and scale to run highly-parallel computing jobs. However, they focus on
specific platforms and convey that their ideas can be extrapolated to any FaaS
runtime.

An important question arises: do all FaaS platforms fit parallel
computations? In this paper, we argue that not all of them provide the
necessary means to host highly-parallel applications. To validate our
hypothesis, we create a comparative framework and categorize the architectures
of four cloud FaaS offerings, with emphasis on parallel performance. We attest
and extend this description with an empirical experiment that consists in
plotting in deep detail the evolution of a parallel computing job on each
service.

The analysis of our results evinces that FaaS is not inherently good for
parallel computations and architectural differences across platforms are
decisive to categorize their performance. A key insight is the importance of
virtualization technologies and the scheduling approach of FaaS platforms.
Parallelism improves with lighter virtualization and proactive scheduling due
to finer resource allocation and faster elasticity. This causes some platforms
like AWS and IBM to perform well for highly-parallel computations, while others
such as Azure present difficulties to achieve the required parallelism degree.
Consequently, the information in this paper becomes of special interest to help
users choose the most adequate infrastructure for their parallel applications.
</p>
<a href="http://arxiv.org/abs/2010.15032" target="_blank">arXiv:2010.15032</a> [<a href="http://arxiv.org/pdf/2010.15032" target="_blank">pdf</a>]

<h2>A Comprehensive Survey on Word Representation Models: From Classical to State-Of-The-Art Word Representation Language Models. (arXiv:2010.15036v1 [cs.CL])</h2>
<h3>Usman Naseem, Imran Razzak, Shah Khalid Khan, Mukesh Prasad</h3>
<p>Word representation has always been an important research area in the history
of natural language processing (NLP). Understanding such complex text data is
imperative, given that it is rich in information and can be used widely across
various applications. In this survey, we explore different word representation
models and its power of expression, from the classical to modern-day
state-of-the-art word representation language models (LMS). We describe a
variety of text representation methods, and model designs have blossomed in the
context of NLP, including SOTA LMs. These models can transform large volumes of
text into effective vector representations capturing the same semantic
information. Further, such representations can be utilized by various machine
learning (ML) algorithms for a variety of NLP related tasks. In the end, this
survey briefly discusses the commonly used ML and DL based classifiers,
evaluation metrics and the applications of these word embeddings in different
NLP tasks.
</p>
<a href="http://arxiv.org/abs/2010.15036" target="_blank">arXiv:2010.15036</a> [<a href="http://arxiv.org/pdf/2010.15036" target="_blank">pdf</a>]

<h2>Data Agnostic Filter Gating for Efficient Deep Networks. (arXiv:2010.15041v1 [cs.CV])</h2>
<h3>Xiu Su, Shan You, Tao Huang, Hongyan Xu, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</h3>
<p>To deploy a well-trained CNN model on low-end computation edge devices, it is
usually supposed to compress or prune the model under certain computation
budget (e.g., FLOPs). Current filter pruning methods mainly leverage feature
maps to generate important scores for filters and prune those with smaller
scores, which ignores the variance of input batches to the difference in sparse
structure over filters. In this paper, we propose a data agnostic filter
pruning method that uses an auxiliary network named Dagger module to induce
pruning and takes pretrained weights as input to learn the importance of each
filter. In addition, to help prune filters with certain FLOPs constraints, we
leverage an explicit FLOPs-aware regularization to directly promote pruning
filters toward target FLOPs. Extensive experimental results on CIFAR-10 and
ImageNet datasets indicate our superiority to other state-of-the-art filter
pruning methods. For example, our 50\% FLOPs ResNet-50 can achieve 76.1\% Top-1
accuracy on ImageNet dataset, surpassing many other filter pruning methods.
</p>
<a href="http://arxiv.org/abs/2010.15041" target="_blank">arXiv:2010.15041</a> [<a href="http://arxiv.org/pdf/2010.15041" target="_blank">pdf</a>]

<h2>A multi-agent model for growing spiking neural networks. (arXiv:2010.15045v1 [cs.NE])</h2>
<h3>Javier Lopez Randulfe, Leon Bonde Larsen</h3>
<p>Artificial Intelligence has looked into biological systems as a source of
inspiration. Although there are many aspects of the brain yet to be discovered,
neuroscience has found evidence that the connections between neurons
continuously grow and reshape as a part of the learning process. This differs
from the design of Artificial Neural Networks, that achieve learning by
evolving the weights in the synapses between them and their topology stays
unaltered through time.

This project has explored rules for growing the connections between the
neurons in Spiking Neural Networks as a learning mechanism. These rules have
been implemented on a multi-agent system for creating simple logic functions,
that establish a base for building up more complex systems and architectures.
Results in a simulation environment showed that for a given set of parameters
it is possible to reach topologies that reproduce the tested functions.

This project also opens the door to the usage of techniques like genetic
algorithms for obtaining the best suited values for the model parameters, and
hence creating neural networks that can adapt to different functions.
</p>
<a href="http://arxiv.org/abs/2010.15045" target="_blank">arXiv:2010.15045</a> [<a href="http://arxiv.org/pdf/2010.15045" target="_blank">pdf</a>]

<h2>Image Representations Learned With Unsupervised Pre-Training Contain Human-like Biases. (arXiv:2010.15052v1 [cs.CY])</h2>
<h3>Ryan Steed, Aylin Caliskan</h3>
<p>Recent advances in machine learning leverage massive datasets of unlabeled
images from the web to learn general-purpose image representations for tasks
from image classification to face recognition. But do unsupervised computer
vision models automatically learn implicit patterns and embed social biases
that could have harmful downstream effects? For the first time, we develop a
novel method for quantifying biased associations between representations of
social concepts and attributes in images. We find that state-of-the-art
unsupervised models trained on ImageNet, a popular benchmark image dataset
curated from internet images, automatically learn racial, gender, and
intersectional biases. We replicate 8 of 15 documented human biases from social
psychology, from the innocuous, as with insects and flowers, to the potentially
harmful, as with race and gender. For the first time in the image domain, we
replicate human-like biases about skin-tone and weight. Our results also
closely match three hypotheses about intersectional bias from social
psychology. When compared with statistical patterns in online image datasets,
our findings suggest that machine learning models can automatically learn bias
from the way people are stereotypically portrayed on the web.
</p>
<a href="http://arxiv.org/abs/2010.15052" target="_blank">arXiv:2010.15052</a> [<a href="http://arxiv.org/pdf/2010.15052" target="_blank">pdf</a>]

<h2>Self-awareness in Intelligent Vehicles: Experience Based Abnormality Detection. (arXiv:2010.15056v1 [cs.LG])</h2>
<h3>Divya Kanapram, Pablo Marin-Plaza, Lucio Marcenaro, David Martin, Arturo de la Escalera, Carlo Regazzoni</h3>
<p>The evolution of Intelligent Transportation System in recent times
necessitates the development of self-driving agents: the self-awareness
consciousness. This paper aims to introduce a novel method to detect
abnormalities based on internal cross-correlation parameters of the vehicle.
Before the implementation of Machine Learning, the detection of abnormalities
were manually programmed by checking every variable and creating huge nested
conditions that are very difficult to track. Nowadays, it is possible to train
a Dynamic Bayesian Network (DBN) model to automatically evaluate and detect
when the vehicle is potentially misbehaving. In this paper, different scenarios
have been set in order to train and test a switching DBN for Perimeter
Monitoring Task using a semantic segmentation for the DBN model and Hellinger
Distance metric for abnormality measurements.
</p>
<a href="http://arxiv.org/abs/2010.15056" target="_blank">arXiv:2010.15056</a> [<a href="http://arxiv.org/pdf/2010.15056" target="_blank">pdf</a>]

<h2>Fixed-Length Protein Embeddings using Contextual Lenses. (arXiv:2010.15065v1 [q-bio.BM])</h2>
<h3>Amir Shanehsazzadeh, David Belanger, David Dohan</h3>
<p>The Basic Local Alignment Search Tool (BLAST) is currently the most popular
method for searching databases of biological sequences. BLAST compares
sequences via similarity defined by a weighted edit distance, which results in
it being computationally expensive. As opposed to working with edit distance, a
vector similarity approach can be accelerated substantially using modern
hardware or hashing techniques. Such an approach would require fixed-length
embeddings for biological sequences. There has been recent interest in learning
fixed-length protein embeddings using deep learning models under the hypothesis
that the hidden layers of supervised or semi-supervised models could produce
potentially useful vector embeddings. We consider transformer (BERT) protein
language models that are pretrained on the TrEMBL data set and learn
fixed-length embeddings on top of them with contextual lenses. The embeddings
are trained to predict the family a protein belongs to for sequences in the
Pfam database. We show that for nearest-neighbor family classification,
pretraining offers a noticeable boost in performance and that the corresponding
learned embeddings are competitive with BLAST. Furthermore, we show that the
raw transformer embeddings, obtained via static pooling, do not perform well on
nearest-neighbor family classification, which suggests that learning embeddings
in a supervised manner via contextual lenses may be a compute-efficient
alternative to fine-tuning.
</p>
<a href="http://arxiv.org/abs/2010.15065" target="_blank">arXiv:2010.15065</a> [<a href="http://arxiv.org/pdf/2010.15065" target="_blank">pdf</a>]

<h2>Generative Adversarial Networks in Human Emotion Synthesis:A Review. (arXiv:2010.15075v1 [cs.CV])</h2>
<h3>Noushin Hajarolasvadi, Miguel Arjona Ram&#xed;rez, Hasan Demirel</h3>
<p>Synthesizing realistic data samples is of great value for both academic and
industrial communities. Deep generative models have become an emerging topic in
various research areas like computer vision and signal processing. Affective
computing, a topic of a broad interest in computer vision society, has been no
exception and has benefited from generative models. In fact, affective
computing observed a rapid derivation of generative models during the last two
decades. Applications of such models include but are not limited to emotion
recognition and classification, unimodal emotion synthesis, and cross-modal
emotion synthesis. As a result, we conducted a review of recent advances in
human emotion synthesis by studying available databases, advantages, and
disadvantages of the generative models along with the related training
strategies considering two principal human communication modalities, namely
audio and video. In this context, facial expression synthesis, speech emotion
synthesis, and the audio-visual (cross-modal) emotion synthesis is reviewed
extensively under different application scenarios. Gradually, we discuss open
research problems to push the boundaries of this research area for future
works.
</p>
<a href="http://arxiv.org/abs/2010.15075" target="_blank">arXiv:2010.15075</a> [<a href="http://arxiv.org/pdf/2010.15075" target="_blank">pdf</a>]

<h2>Handling Class Imbalance in Low-Resource Dialogue Systems by Combining Few-Shot Classification and Interpolation. (arXiv:2010.15090v1 [cs.CL])</h2>
<h3>Vishal Sunder, Eric Fosler-Lussier</h3>
<p>Utterance classification performance in low-resource dialogue systems is
constrained by an inevitably high degree of data imbalance in class labels. We
present a new end-to-end pairwise learning framework that is designed
specifically to tackle this phenomenon by inducing a few-shot classification
capability in the utterance representations and augmenting data through an
interpolation of utterance representations. Our approach is a general purpose
training methodology, agnostic to the neural architecture used for encoding
utterances. We show significant improvements in macro-F1 score over standard
cross-entropy training for three different neural architectures, demonstrating
improvements on a Virtual Patient dialogue dataset as well as a low-resourced
emulation of the Switchboard dialogue act classification dataset.
</p>
<a href="http://arxiv.org/abs/2010.15090" target="_blank">arXiv:2010.15090</a> [<a href="http://arxiv.org/pdf/2010.15090" target="_blank">pdf</a>]

<h2>Evaluating Model Robustness to Dataset Shift. (arXiv:2010.15100v1 [cs.LG])</h2>
<h3>Adarsh Subbaswamy, Roy Adams, Suchi Saria</h3>
<p>As the use of machine learning in safety-critical domains becomes widespread,
the importance of evaluating their safety has increased. An important aspect of
this is evaluating how robust a model is to changes in setting or population,
which typically requires applying the model to multiple, independent datasets.
Since the cost of collecting such datasets is often prohibitive, in this paper,
we propose a framework for evaluating this type of robustness using a single,
fixed evaluation dataset. We use the original evaluation data to define an
uncertainty set of possible evaluation distributions and estimate the
algorithm's performance on the "worst-case" distribution within this set.
Specifically, we consider distribution shifts defined by conditional
distributions, allowing some distributions to shift while keeping other
portions of the data distribution fixed. This results in finer-grained control
over the considered shifts and more plausible worst-case distributions than
previous approaches based on covariate shifts. To address the challenges
associated with estimation in complex, high-dimensional distributions, we
derive a "debiased" estimator which maintains $\sqrt{N}$-consistency even when
machine learning methods with slower convergence rates are used to estimate the
nuisance parameters. In experiments on a real medical risk prediction task, we
show that this estimator can be used to evaluate robustness and accounts for
realistic shifts that cannot be expressed as covariate shift. The proposed
framework provides a means for practitioners to proactively evaluate the safety
of their models using a single validation dataset.
</p>
<a href="http://arxiv.org/abs/2010.15100" target="_blank">arXiv:2010.15100</a> [<a href="http://arxiv.org/pdf/2010.15100" target="_blank">pdf</a>]

<h2>Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel. (arXiv:2010.15110v1 [cs.LG])</h2>
<h3>Stanislav Fort, Gintare Karolina Dziugaite, Mansheej Paul, Sepideh Kharaghani, Daniel M. Roy, Surya Ganguli</h3>
<p>In suitably initialized wide networks, small learning rates transform deep
neural networks (DNNs) into neural tangent kernel (NTK) machines, whose
training dynamics is well-approximated by a linear weight expansion of the
network at initialization. Standard training, however, diverges from its
linearization in ways that are poorly understood. We study the relationship
between the training dynamics of nonlinear deep networks, the geometry of the
loss landscape, and the time evolution of a data-dependent NTK. We do so
through a large-scale phenomenological analysis of training, synthesizing
diverse measures characterizing loss landscape geometry and NTK dynamics. In
multiple neural architectures and datasets, we find these diverse measures
evolve in a highly correlated manner, revealing a universal picture of the deep
learning process. In this picture, deep network training exhibits a highly
chaotic rapid initial transient that within 2 to 3 epochs determines the final
linearly connected basin of low loss containing the end point of training.
During this chaotic transient, the NTK changes rapidly, learning useful
features from the training data that enables it to outperform the standard
initial NTK by a factor of 3 in less than 3 to 4 epochs. After this rapid
chaotic transient, the NTK changes at constant velocity, and its performance
matches that of full network training in 15% to 45% of training time. Overall,
our analysis reveals a striking correlation between a diverse set of metrics
over training time, governed by a rapid chaotic to stable transition in the
first few epochs, that together poses challenges and opportunities for the
development of more accurate theories of deep learning.
</p>
<a href="http://arxiv.org/abs/2010.15110" target="_blank">arXiv:2010.15110</a> [<a href="http://arxiv.org/pdf/2010.15110" target="_blank">pdf</a>]

<h2>Evaluating data augmentation for financial time series classification. (arXiv:2010.15111v1 [q-fin.ST])</h2>
<h3>Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane, Alexandros Iosifidis</h3>
<p>Data augmentation methods in combination with deep neural networks have been
used extensively in computer vision on classification tasks, achieving great
success; however, their use in time series classification is still at an early
stage. This is even more so in the field of financial prediction, where data
tends to be small, noisy and non-stationary. In this paper we evaluate several
augmentation methods applied to stocks datasets using two state-of-the-art deep
learning models. The results show that several augmentation methods
significantly improve financial performance when used in combination with a
trading strategy. For a relatively small dataset ($\approx30K$ samples),
augmentation methods achieve up to $400\%$ improvement in risk adjusted return
performance; for a larger stock dataset ($\approx300K$ samples), results show
up to $40\%$ improvement.
</p>
<a href="http://arxiv.org/abs/2010.15111" target="_blank">arXiv:2010.15111</a> [<a href="http://arxiv.org/pdf/2010.15111" target="_blank">pdf</a>]

<h2>Deep Multiple Instance Learning for Airplane Detection in High Resolution Imagery. (arXiv:1808.06178v2 [cs.CV] UPDATED)</h2>
<h3>Mohammad Reza Mohammadi</h3>
<p>Automatic airplane detection in aerial imagery has a variety of applications.
Two of the significant challenges in this task are variations in the scale and
direction of the airplanes. To solve these challenges, we present a
rotation-and-scale invariant airplane proposal generator. We call this
generator symmetric line segments (SLS) that is developed based on the
symmetric and regular boundaries of airplanes from the top view. Then, the
generated proposals are used to train a deep convolutional neural network for
removing non-airplane proposals. Since each airplane can have multiple SLS
proposals, where some of them are not in the direction of the fuselage, we
collect all proposals corresponding to one ground-truth as a positive bag and
the others as the negative instances. To have multiple instance deep learning,
we modify the loss function of the network to learn from each positive bag at
least one instance as well as all negative instances. Finally, we employ
non-maximum suppression to remove duplicate detections. Our experiments on NWPU
VHR-10 and DOTA datasets show that our method is a promising approach for
automatic airplane detection in very high-resolution images. Moreover, we
estimate the direction of the airplanes using box-level annotations as an extra
achievement.
</p>
<a href="http://arxiv.org/abs/1808.06178" target="_blank">arXiv:1808.06178</a> [<a href="http://arxiv.org/pdf/1808.06178" target="_blank">pdf</a>]

<h2>Parabolic Approximation Line Search for DNNs. (arXiv:1903.11991v4 [cs.LG] UPDATED)</h2>
<h3>Maximus Mutschler, Andreas Zell</h3>
<p>A major challenge in current optimization research for deep learning is to
automatically find optimal step sizes for each update step. The optimal step
size is closely related to the shape of the loss in the update step direction.
However, this shape has not yet been examined in detail. This work shows
empirically that the batch loss over lines in negative gradient direction is
mostly convex locally and well suited for one-dimensional parabolic
approximations. By exploiting this parabolic property we introduce a simple and
robust line search approach, which performs loss-shape dependent update steps.
Our approach combines well-known methods such as parabolic approximation, line
search and conjugate gradient, to perform efficiently. It surpasses other step
size estimating methods and competes with common optimization methods on a
large variety of experiments without the need of hand-designed step size
schedules. Thus, it is of interest for objectives where step-size schedules are
unknown or do not perform well. Our extensive evaluation includes multiple
comprehensive hyperparameter grid searches on several datasets and
architectures. Finally, we provide a general investigation of exact line
searches in the context of batch losses and exact losses, including their
relation to our line search approach.
</p>
<a href="http://arxiv.org/abs/1903.11991" target="_blank">arXiv:1903.11991</a> [<a href="http://arxiv.org/pdf/1903.11991" target="_blank">pdf</a>]

<h2>Shredder: Learning Noise Distributions to Protect Inference Privacy. (arXiv:1905.11814v3 [cs.CR] UPDATED)</h2>
<h3>Fatemehsadat Mireshghallah, Mohammadkazem Taram, Prakash Ramrakhyani, Dean Tullsen, Hadi Esmaeilzadeh</h3>
<p>A wide variety of deep neural applications increasingly rely on the cloud to
perform their compute-heavy inference. This common practice requires sending
private and privileged data over the network to remote servers, exposing it to
the service provider and potentially compromising its privacy. Even if the
provider is trusted, the data can still be vulnerable over communication
channels or via side-channel attacks in the cloud. To that end, this paper aims
to reduce the information content of the communicated data with as little as
possible compromise on the inference accuracy by making the sent data noisy. An
undisciplined addition of noise can significantly reduce the accuracy of
inference, rendering the service unusable. To address this challenge, this
paper devises Shredder, an end-to-end framework, that, without altering the
topology or the weights of a pre-trained network, learns additive noise
distributions that significantly reduce the information content of communicated
data while maintaining the inference accuracy. The key idea is finding the
additive noise distributions by casting it as a disjoint offline learning
process with a loss function that strikes a balance between accuracy and
information degradation. The loss function also exposes a knob for a
disciplined and controlled asymmetric trade-off between privacy and accuracy.
Experimentation with six real-world DNNs from text processing and image
classification shows that Shredder reduces the mutual information between the
input and the communicated data to the cloud by 74.70% compared to the original
execution while only sacrificing 1.58% loss in accuracy. On average, Shredder
also offers a speedup of 1.79x over Wi-Fi and 2.17x over LTE compared to
cloud-only execution when using an off-the-shelf mobile GPU (Tegra X2) on the
edge.
</p>
<a href="http://arxiv.org/abs/1905.11814" target="_blank">arXiv:1905.11814</a> [<a href="http://arxiv.org/pdf/1905.11814" target="_blank">pdf</a>]

<h2>Disentangling neural mechanisms for perceptual grouping. (arXiv:1906.01558v2 [cs.CV] UPDATED)</h2>
<h3>Junkyung Kim, Drew Linsley, Kalpit Thakkar, Thomas Serre</h3>
<p>Forming perceptual groups and individuating objects in visual scenes is an
essential step towards visual intelligence. This ability is thought to arise in
the brain from computations implemented by bottom-up, horizontal, and top-down
connections between neurons. However, the relative contributions of these
connections to perceptual grouping are poorly understood. We address this
question by systematically evaluating neural network architectures featuring
combinations bottom-up, horizontal, and top-down connections on two synthetic
visual tasks, which stress low-level "Gestalt" vs. high-level object cues for
perceptual grouping. We show that increasing the difficulty of either task
strains learning for networks that rely solely on bottom-up connections.
Horizontal connections resolve straining on tasks with Gestalt cues by
supporting incremental grouping, whereas top-down connections rescue learning
on tasks with high-level object cues by modifying coarse predictions about the
position of the target object. Our findings dissociate the computational roles
of bottom-up, horizontal and top-down connectivity, and demonstrate how a model
featuring all of these interactions can more flexibly learn to form perceptual
groups.
</p>
<a href="http://arxiv.org/abs/1906.01558" target="_blank">arXiv:1906.01558</a> [<a href="http://arxiv.org/pdf/1906.01558" target="_blank">pdf</a>]

<h2>Learning Adaptive Classifiers Synthesis for Generalized Few-Shot Learning. (arXiv:1906.02944v4 [cs.CV] UPDATED)</h2>
<h3>Han-Jia Ye, Hexiang Hu, De-Chuan Zhan, Fei Sha</h3>
<p>Object recognition in the real-world requires handling long-tailed or even
open-ended data. An ideal visual system needs to recognize the populated head
visual concepts reliably and meanwhile efficiently learn about emerging new
tail categories with a few training instances. Class-balanced many-shot
learning and few-shot learning tackle one side of this problem, by either
learning strong classifiers for head or learning to learn few-shot classifiers
for the tail. In this paper, we investigate the problem of generalized few-shot
learning (GFSL) -- a model during the deployment is required to learn about
tail categories with few shots and simultaneously classify the head classes. We
propose the ClAssifier SynThesis LEarning (CASTLE), a learning framework that
learns how to synthesize calibrated few-shot classifiers in addition to the
multi-class classifiers of head classes with a shared neural dictionary,
shedding light upon the inductive GFSL. Furthermore, we propose an adaptive
version of CASTLE (ACASTLE) that adapts the head classifiers conditioned on the
incoming tail training examples, yielding a framework that allows effective
backward knowledge transfer. As a consequence, ACASTLE can handle GFSL with
classes from heterogeneous domains effectively. CASTLE and ACASTLE demonstrate
superior performances than existing GFSL algorithms and strong baselines on
MiniImageNet as well as TieredImageNet datasets. More interestingly, they
outperform previous state-of-the-art methods when evaluated with standard
few-shot learning criteria.
</p>
<a href="http://arxiv.org/abs/1906.02944" target="_blank">arXiv:1906.02944</a> [<a href="http://arxiv.org/pdf/1906.02944" target="_blank">pdf</a>]

<h2>Deep neural network for fringe pattern filtering and normalisation. (arXiv:1906.06224v2 [eess.IV] UPDATED)</h2>
<h3>Alan Reyes-Figueroa, Mariano Rivera</h3>
<p>We propose a new framework for processing Fringe Patterns (FP). Our novel
approach builds upon the hypothesis that the denoising and normalisation of FPs
can be learned by a deep neural network if enough pairs of corrupted and ideal
FPs are provided. The main contributions of this paper are the following: (1)
We propose the use of the U-net neural network architecture for FP
normalisation tasks; (2) we propose a modification for the distribution of
weights in the U-net, called here the V-net model, which is more convenient for
reconstruction tasks, and we conduct extensive experimental evidence in which
the V-net produces high-quality results for FP filtering and normalisation. (3)
We also propose two modifications of the V-net scheme, namely, a residual
version called ResV-net and a fast operating version of the V-net, to evaluate
the potential improvements when modify our proposal. We evaluate the
performance of our methods in various scenarios: FPs corrupted with different
degrees of noise, and corrupted with different noise distributions. We compare
our methodology versus other state-of-the-art methods. The experimental results
(on both synthetic and real data) demonstrate the capabilities and potential of
this new paradigm for processing interferograms.
</p>
<a href="http://arxiv.org/abs/1906.06224" target="_blank">arXiv:1906.06224</a> [<a href="http://arxiv.org/pdf/1906.06224" target="_blank">pdf</a>]

<h2>A Transfer Learning Approach for Automated Segmentation of Prostate Whole Gland and Transition Zone in Diffusion Weighted MRI. (arXiv:1909.09541v2 [eess.IV] UPDATED)</h2>
<h3>Saman Motamed, Isha Gujrathi, Dominik Deniffel, Anton Oentoro, Masoom A. Haider, Farzad Khalvati</h3>
<p>The segmentation of prostate whole gland and transition zone in Diffusion
Weighted MRI (DWI) are the first step in designing computer-aided detection
algorithms for prostate cancer. However, variations in MRI acquisition
parameters and scanner manufacturing result in different appearances of
prostate tissue in the images. Convolutional neural networks (CNNs) which have
shown to be successful in various medical image analysis tasks including
segmentation are typically sensitive to the variations in imaging parameters.
This sensitivity leads to poor segmentation performance of CNNs trained on a
source cohort and tested on a target cohort from a different scanner and hence,
it limits the applicability of CNNs for cross-cohort training and testing.
Contouring prostate whole gland and transition zone in DWI images are
time-consuming and expensive. Thus, it is important to enable CNNs pretrained
on images of source domain, to segment images of target domain with minimum
requirement for manual segmentation of images from the target domain. In this
work, we propose a transfer learning method based on a modified U-net
architecture and loss function, for segmentation of prostate whole gland and
transition zone in DWIs using a CNN pretrained on a source dataset and tested
on the target dataset. We explore the effect of the size of subset of target
dataset used for fine-tuning the pre-trained CNN on the overall segmentation
accuracy. Our results show that with a fine-tuning data as few as 30 patients
from the target domain, the proposed transfer learning-based algorithm can
reach dice score coefficient of 0.80 for both prostate whole gland and
transition zone segmentation. Using a fine-tuning data of 115 patients from the
target domain, dice score coefficient of 0.85 and 0.84 are achieved for
segmentation of whole gland and transition zone, respectively, in the target
domain.
</p>
<a href="http://arxiv.org/abs/1909.09541" target="_blank">arXiv:1909.09541</a> [<a href="http://arxiv.org/pdf/1909.09541" target="_blank">pdf</a>]

<h2>Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking. (arXiv:1910.03544v4 [cs.CL] UPDATED)</h2>
<h3>Jian-Guo Zhang, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S. Yu, Richard Socher, Caiming Xiong</h3>
<p>Dialog state tracking (DST) is a core component in task-oriented dialog
systems. Existing approaches for DST mainly fall into one of two categories,
namely, ontology-based and ontology-free methods. An ontology-based method
selects a value from a candidate-value list for each target slot, while an
ontology-free method extracts spans from dialog contexts. Recent work
introduced a BERT-based model to strike a balance between the two methods by
pre-defining categorical and non-categorical slots. However, it is not clear
enough which slots are better handled by either of the two slot types, and the
way to use the pre-trained model has not been well investigated. In this paper,
we propose a simple yet effective dual-strategy model for DST, by adapting a
single BERT-style reading comprehension model to jointly handle both the
categorical and non-categorical slots. Our experiments on the MultiWOZ datasets
show that our method significantly outperforms the BERT-based counterpart,
finding that the key is a deep interaction between the domain-slot and context
information. When evaluated on noisy (MultiWOZ 2.0) and cleaner (MultiWOZ 2.1)
settings, our method performs competitively and robustly across the two
different settings. Our method sets the new state of the art in the noisy
setting, while performing more robustly than the best model in the cleaner
setting. We also conduct a comprehensive error analysis on the dataset,
including the effects of the dual strategy for each slot, to facilitate future
research.
</p>
<a href="http://arxiv.org/abs/1910.03544" target="_blank">arXiv:1910.03544</a> [<a href="http://arxiv.org/pdf/1910.03544" target="_blank">pdf</a>]

<h2>How to Better Distinguish Security Bug Reports (using Dual Hyperparameter Optimization. (arXiv:1911.02476v2 [cs.SE] UPDATED)</h2>
<h3>Rui Shu, Tianpei Xia, Jianfeng Chen, Laurie Williams, Tim Menzies</h3>
<p>Background: In order that the general public is not vulnerable to hackers,
security bug reports need to be handled by small groups of engineers before
being widely discussed. But learning how to distinguish the security bug
reports from other bug reports is challenging since they may occur rarely. Data
mining methods that can find such scarce targets require extensive optimization
effort.

Goal: The goal of this research is to aid practitioners as they struggle to
optimize methods that try to distinguish between rare security bug reports and
other bug reports.

Method: Our proposed method, called Swift, is a dual optimizer that optimizes
both learner and pre-processor options. Since this is a large space of options,
Swift uses a technique called epsilon-dominance that learns how to avoid
operations that do not significantly improve performance.

Result: When compared to recent state-of-the-art results (from FARSEC which
is published in TSE'18), we find that the Swift's dual optimization of both
pre-processor and learner is more useful than optimizing each of them
individually. For example, in a study of security bug reports from the Chromium
dataset, the median recalls of FARSEC and Swift were 15.7% and 77.4%,
respectively. For another example, in experiments with data from the Ambari
project, the median recalls improved from 21.5% to 85.7% (FARSEC to SWIFT).

Conclusion: Overall, our approach can quickly optimize models that achieve
better recalls than the prior state-of-the-art. These increases in recall are
associated with moderate increases in false positive rates (from 8% to 24%,
median). For future work, these results suggest that dual optimization is both
practical and useful.
</p>
<a href="http://arxiv.org/abs/1911.02476" target="_blank">arXiv:1911.02476</a> [<a href="http://arxiv.org/pdf/1911.02476" target="_blank">pdf</a>]

<h2>Dense networks with scale-free feature. (arXiv:1912.08923v2 [cs.SI] UPDATED)</h2>
<h3>Fei Ma, Xiaomin Wang, Ping Wang, Xudong Luo</h3>
<p>While previous works have shown that an overwhelming number of scale-free
networks are sparse, there still exist some real-world networks including
social networks, urban networks, information networks, which are by observation
dense. In this paper, we propose a novel framework for generating scale-free
graphs with dense feature using two simple yet helpful operations, first-order
subdivision and Line-operation. From the theoretical point of view, our method
can be used not only to produce desired scale-free graphs with density feature,
i.e. power-law exponent $\gamma$ falling into the interval $1&lt;\gamma\leq2$, but
also to establish many other unexpected networked models, for instance,
power-law models having large diameter. In addition, the networked models
generated upon our framework show especially assortative structure. That is,
their own Pearson correlation coefficients are able to achieve the theoretical
upper bound. Last but not the least, we find the sizes of community in the
proposed models to follow power-law in form with respect to modularity
maximization.
</p>
<a href="http://arxiv.org/abs/1912.08923" target="_blank">arXiv:1912.08923</a> [<a href="http://arxiv.org/pdf/1912.08923" target="_blank">pdf</a>]

<h2>Detect and Correct Bias in Multi-Site Neuroimaging Datasets. (arXiv:2002.05049v2 [cs.CV] UPDATED)</h2>
<h3>Christian Wachinger, Anna Rieckmann, Sebastian P&#xf6;lsterl</h3>
<p>The desire to train complex machine learning algorithms and to increase the
statistical power in association studies drives neuroimaging research to use
ever-larger datasets. The most obvious way to increase sample size is by
pooling scans from independent studies. However, simple pooling is often
ill-advised as selection, measurement, and confounding biases may creep in and
yield spurious correlations. In this work, we combine 35,320 magnetic resonance
images of the brain from 17 studies to examine bias in neuroimaging. In the
first experiment, Name That Dataset, we provide empirical evidence for the
presence of bias by showing that scans can be correctly assigned to their
respective dataset with 71.5% accuracy. Given such evidence, we take a closer
look at confounding bias, which is often viewed as the main shortcoming in
observational studies. In practice, we neither know all potential confounders
nor do we have data on them. Hence, we model confounders as unknown, latent
variables. Kolmogorov complexity is then used to decide whether the confounded
or the causal model provides the simplest factorization of the graphical model.
Finally, we present methods for dataset harmonization and study their ability
to remove bias in imaging features. In particular, we propose an extension of
the recently introduced ComBat algorithm to control for global variation across
image features, inspired by adjusting for population stratification in
genetics. Our results demonstrate that harmonization can reduce
dataset-specific information in image features. Further, confounding bias can
be reduced and even turned into a causal relationship. However, harmonziation
also requires caution as it can easily remove relevant subject-specific
information. Code is available at https://github.com/ai-med/Dataset-Bias.
</p>
<a href="http://arxiv.org/abs/2002.05049" target="_blank">arXiv:2002.05049</a> [<a href="http://arxiv.org/pdf/2002.05049" target="_blank">pdf</a>]

<h2>A Deep Unsupervised Feature Learning Spiking Neural Network with Binarized Classification Layers for EMNIST Classification using SpykeFlow. (arXiv:2002.11843v4 [cs.NE] UPDATED)</h2>
<h3>Ruthvik Vaila, John Chiasson, Vishal Saxena</h3>
<p>End user AI is trained on large server farms with data collected from the
users. With ever increasing demand for IOT devices, there is a need for deep
learning approaches that can be implemented (at the edge) in an energy
efficient manner. In this work we approach this using spiking neural networks.
The unsupervised learning technique of spike timing dependent plasticity (STDP)
using binary activations are used to extract features from spiking input data.
Gradient descent (backpropagation) is used only on the output layer to perform
the training for classification. The accuracies obtained for the balanced
EMNIST data set compare favorably with other approaches. The effect of
stochastic gradient descent (SGD) approximations on learning capabilities of
our network are also explored.
</p>
<a href="http://arxiv.org/abs/2002.11843" target="_blank">arXiv:2002.11843</a> [<a href="http://arxiv.org/pdf/2002.11843" target="_blank">pdf</a>]

<h2>A Simple Convergence Proof of Adam and Adagrad. (arXiv:2003.02395v2 [stat.ML] UPDATED)</h2>
<h3>Alexandre D&#xe9;fossez, L&#xe9;on Bottou, Francis Bach, Nicolas Usunier</h3>
<p>We provide a simple proof of convergence covering both the Adam and Adagrad
adaptive optimization algorithms when applied to smooth (possibly non-convex)
objective functions with bounded gradients. We show that in expectation, the
squared norm of the objective gradient averaged over the trajectory has an
upper-bound which is explicit in the constants of the problem, parameters of
the optimizer and the total number of iterations $N$. This bound can be made
arbitrarily small: Adam with a learning rate $\alpha=1/\sqrt{N}$ and a momentum
parameter on squared gradients $\beta_2=1-1/N$ achieves the same rate of
convergence $O(\ln(N)/\sqrt{N})$ as Adagrad. Finally, we obtain the tightest
dependency on the heavy ball momentum among all previous convergence bounds for
non-convex Adam and Adagrad, improving from $O((1-\beta_1)^{-3})$ to
$O((1-\beta_1)^{-1})$. Our technique also improves the best known dependency
for standard SGD by a factor $1 - \beta_1$.
</p>
<a href="http://arxiv.org/abs/2003.02395" target="_blank">arXiv:2003.02395</a> [<a href="http://arxiv.org/pdf/2003.02395" target="_blank">pdf</a>]

<h2>What went wrong and when? Instance-wise Feature Importance for Time-series Models. (arXiv:2003.02821v3 [cs.LG] UPDATED)</h2>
<h3>Sana Tonekaboni, Shalmali Joshi, Kieran Campbell, David Duvenaud, Anna Goldenberg</h3>
<p>Explanations of time series models are useful for high stakes applications
like healthcare but have received little attention in machine learning
literature. We propose FIT, a framework that evaluates the importance of
observations for a multivariate time-series black-box model by quantifying the
shift in the predictive distribution over time. FIT defines the importance of
an observation based on its contribution to the distributional shift under a
KL-divergence that contrasts the predictive distribution against a
counterfactual where the rest of the features are unobserved. We also
demonstrate the need to control for time-dependent distribution shifts. We
compare with state-of-the-art baselines on simulated and real-world clinical
data and demonstrate that our approach is superior in identifying important
time points and observations throughout the time series.
</p>
<a href="http://arxiv.org/abs/2003.02821" target="_blank">arXiv:2003.02821</a> [<a href="http://arxiv.org/pdf/2003.02821" target="_blank">pdf</a>]

<h2>When Deep Learning Meets Data Alignment: A Review on Deep Registration Networks (DRNs). (arXiv:2003.03167v2 [cs.CV] UPDATED)</h2>
<h3>Victor Villena-Martinez, Sergiu Oprea, Marcelo Saval-Calvo, Jorge Azorin-Lopez, Andres Fuster-Guillo, Robert B. Fisher</h3>
<p>Registration is the process that computes the transformation that aligns sets
of data. Commonly, a registration process can be divided into four main steps:
target selection, feature extraction, feature matching, and transform
computation for the alignment. The accuracy of the result depends on multiple
factors, the most significant are the quantity of input data, the presence of
noise, outliers and occlusions, the quality of the extracted features,
real-time requirements and the type of transformation, especially those ones
defined by multiple parameters, like non-rigid deformations. Recent
advancements in machine learning could be a turning point in these issues,
particularly with the development of deep learning (DL) techniques, which are
helping to improve multiple computer vision problems through an abstract
understanding of the input data. In this paper, a review of deep learning-based
registration methods is presented. We classify the different papers proposing a
framework extracted from the traditional registration pipeline to analyse the
new learning-based proposal strengths. Deep Registration Networks (DRNs) try to
solve the alignment task either replacing part of the traditional pipeline with
a network or fully solving the registration problem. The main conclusions
extracted are, on the one hand, 1) learning-based registration techniques
cannot always be clearly classified in the traditional pipeline. 2) These
approaches allow more complex inputs like conceptual models as well as the
traditional 3D datasets. 3) In spite of the generality of learning, the current
proposals are still ad hoc solutions. Finally, 4) this is a young topic that
still requires a large effort to reach general solutions able to cope with the
problems that affect traditional approaches.
</p>
<a href="http://arxiv.org/abs/2003.03167" target="_blank">arXiv:2003.03167</a> [<a href="http://arxiv.org/pdf/2003.03167" target="_blank">pdf</a>]

<h2>Wide-minima Density Hypothesis and the Explore-Exploit Learning Rate Schedule. (arXiv:2003.03977v3 [cs.LG] UPDATED)</h2>
<h3>Nikhil Iyer, V Thejas, Nipun Kwatra, Ramachandran Ramjee, Muthian Sivathanu</h3>
<p>Several papers argue that wide minima generalize better than narrow minima.
In this paper, through detailed experiments that not only corroborate the
generalization properties of wide minima, we also provide empirical evidence
for a new hypothesis that the density of wide minima is likely lower than the
density of narrow minima. Further, motivated by this hypothesis, we design a
novel explore-exploit learning rate schedule. On a variety of image and natural
language datasets, compared to their original hand-tuned learning rate
baselines, we show that our explore-exploit schedule can result in either up to
0.84\% higher absolute accuracy using the original training budget or up to
57\% reduced training time while achieving the original reported accuracy. For
example, we achieve state-of-the-art (SOTA) accuracy for IWSLT'14 (DE-EN) and
WMT'14 (DE-EN) datasets by just modifying the learning rate schedule of a high
performing model.
</p>
<a href="http://arxiv.org/abs/2003.03977" target="_blank">arXiv:2003.03977</a> [<a href="http://arxiv.org/pdf/2003.03977" target="_blank">pdf</a>]

<h2>Adversarial Feature Hallucination Networks for Few-Shot Learning. (arXiv:2003.13193v2 [cs.CV] UPDATED)</h2>
<h3>Kai Li, Yulun Zhang, Kunpeng Li, Yun Fu</h3>
<p>The recent flourish of deep learning in various tasks is largely accredited
to the rich and accessible labeled data. Nonetheless, massive supervision
remains a luxury for many real applications, boosting great interest in
label-scarce techniques such as few-shot learning (FSL), which aims to learn
concept of new classes with a few labeled samples. A natural approach to FSL is
data augmentation and many recent works have proved the feasibility by
proposing various data synthesis models. However, these models fail to well
secure the discriminability and diversity of the synthesized data and thus
often produce undesirable results. In this paper, we propose Adversarial
Feature Hallucination Networks (AFHN) which is based on conditional Wasserstein
Generative Adversarial networks (cWGAN) and hallucinates diverse and
discriminative features conditioned on the few labeled samples. Two novel
regularizers, i.e., the classification regularizer and the anti-collapse
regularizer, are incorporated into AFHN to encourage discriminability and
diversity of the synthesized features, respectively. Ablation study verifies
the effectiveness of the proposed cWGAN based feature hallucination framework
and the proposed regularizers. Comparative results on three common benchmark
datasets substantiate the superiority of AFHN to existing data augmentation
based FSL approaches and other state-of-the-art ones.
</p>
<a href="http://arxiv.org/abs/2003.13193" target="_blank">arXiv:2003.13193</a> [<a href="http://arxiv.org/pdf/2003.13193" target="_blank">pdf</a>]

<h2>Learning to Place Objects onto Flat Surfaces in Upright Orientations. (arXiv:2004.00249v2 [cs.RO] UPDATED)</h2>
<h3>Rhys Newbury, Kerry He, Akansel Cosgun, Tom Drummond</h3>
<p>We study the problem of placing a grasped object on an empty flat surface in
an upright orientation, such as placing a cup on its bottom rather than on its
side. We aim to find the required object rotation such that when the gripper is
opened after the object makes a contact with the surface, the object would be
stably placed in the upright orientation. We use two neural networks in an
iterative fashion. At every iteration, we use a convolutional neural network to
estimate the required object rotation which is executed by the robot, and then
a separate convolutional neural network to estimate if the object would be
stable if it is placed in its current orientation. In simulation experiments,
our approach places previously unseen objects in upright orientations with a
success rate of 98.1% in free space and 90.3% with a simulated robotic arm,
using a dataset of 50 everyday objects. A real world implementation is
presented, which serves as a proof-of-concept for direct sim-to-real transfer.
</p>
<a href="http://arxiv.org/abs/2004.00249" target="_blank">arXiv:2004.00249</a> [<a href="http://arxiv.org/pdf/2004.00249" target="_blank">pdf</a>]

<h2>Joint Routing and Scheduling for Large-Scale Deterministic IP Networks. (arXiv:2004.02717v2 [cs.NI] UPDATED)</h2>
<h3>Jonatan Krolikowski, Sebastien Martin, Paolo Medagliani, Jeremie Leguay, Shuang Chen, Xiaodong Chang, Xuesong Geng</h3>
<p>With the advent of 5G and the evolution of Internet protocols, industrial
applications are moving from vertical solutions to general purpose IP-based
infrastructures that need to meet deterministic Quality of Service (QoS)
requirements. The IETF DetNet working group aims at providing an answer to this
need with support for (i) deterministic worst-case latency and jitter, and (ii)
zero packet loss for time-sensitive traffic. In this paper we focus on the
joint routing and scheduling problem in large scale deterministic networks
using Cycle Specified Queuing and Forwarding (CSQF), an extension of Cyclic
Queuing and Forwarding (CQF) with multiple transmission queues and support of
segment routing. In this context, we present two centralized algorithms to
maximize traffic acceptance for network planning and online flow admission. We
propose an effective solution based on column generation and dynamic
programming. Thanks to the reinforcement of the model with valid inequalities,
we improve the upper bound and the solution. We demonstrate on realistic
instances that we reach an optimality gap smaller than 10% in a few seconds.
Finally, we also derive an ultra-fast adaptive greedy algorithm to solve the
problem at the cost of a small extra gap.
</p>
<a href="http://arxiv.org/abs/2004.02717" target="_blank">arXiv:2004.02717</a> [<a href="http://arxiv.org/pdf/2004.02717" target="_blank">pdf</a>]

<h2>Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete Space. (arXiv:2004.08046v2 [cs.CL] UPDATED)</h2>
<h3>Dongyu Ru, Jiangtao Feng, Lin Qiu, Hao Zhou, Mingxuan Wang, Weinan Zhang, Yong Yu, Lei Li</h3>
<p>Active learning for sentence understanding aims at discovering informative
unlabeled data for annotation and therefore reducing the demand for labeled
data. We argue that the typical uncertainty sampling method for active learning
is time-consuming and can hardly work in real-time, which may lead to
ineffective sample selection. We propose adversarial uncertainty sampling in
discrete space (AUSDS) to retrieve informative unlabeled samples more
efficiently. AUSDS maps sentences into latent space generated by the popular
pre-trained language models, and discover informative unlabeled text samples
for annotation via adversarial attack. The proposed approach is extremely
efficient compared with traditional uncertainty sampling with more than 10x
speedup. Experimental results on five datasets show that AUSDS outperforms
strong baselines on effectiveness.
</p>
<a href="http://arxiv.org/abs/2004.08046" target="_blank">arXiv:2004.08046</a> [<a href="http://arxiv.org/pdf/2004.08046" target="_blank">pdf</a>]

<h2>Why and when should you pool? Analyzing Pooling in Recurrent Architectures. (arXiv:2005.00159v2 [cs.CL] UPDATED)</h2>
<h3>Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam</h3>
<p>Pooling-based recurrent neural architectures consistently outperform their
counterparts without pooling. However, the reasons for their enhanced
performance are largely unexamined. In this work, we examine three commonly
used pooling techniques (mean-pooling, max-pooling, and attention), and propose
max-attention, a novel variant that effectively captures interactions among
predictive tokens in a sentence. We find that pooling-based architectures
substantially differ from their non-pooling equivalents in their learning
ability and positional biases--which elucidate their performance benefits. By
analyzing the gradient propagation, we discover that pooling facilitates better
gradient flow compared to BiLSTMs. Further, we expose how BiLSTMs are
positionally biased towards tokens in the beginning and the end of a sequence.
Pooling alleviates such biases. Consequently, we identify settings where
pooling offers large benefits: (i) in low resource scenarios, and (ii) when
important words lie towards the middle of the sentence. Among the pooling
techniques studied, max-attention is the most effective, resulting in
significant performance gains on several text classification tasks.
</p>
<a href="http://arxiv.org/abs/2005.00159" target="_blank">arXiv:2005.00159</a> [<a href="http://arxiv.org/pdf/2005.00159" target="_blank">pdf</a>]

<h2>Neural Unsupervised Domain Adaptation in NLP---A Survey. (arXiv:2006.00632v2 [cs.CL] UPDATED)</h2>
<h3>Alan Ramponi, Barbara Plank</h3>
<p>Deep neural networks excel at learning from labeled data and achieve
state-of-the-art resultson a wide array of Natural Language Processing tasks.
In contrast, learning from unlabeled data, especially under domain shift,
remains a challenge. Motivated by the latest advances, in this survey we review
neural unsupervised domain adaptation techniques which do not require labeled
target domain data. This is a more challenging yet a more widely applicable
setup. We outline methods, from early traditional non-neural methods to
pre-trained model transfer. We also revisit the notion of domain, and we
uncover a bias in the type of Natural Language Processing tasks which received
most attention. Lastly, we outline future directions, particularly the broader
need for out-of-distribution generalization of future NLP.
</p>
<a href="http://arxiv.org/abs/2006.00632" target="_blank">arXiv:2006.00632</a> [<a href="http://arxiv.org/pdf/2006.00632" target="_blank">pdf</a>]

<h2>Sparse and Continuous Attention Mechanisms. (arXiv:2006.07214v2 [cs.LG] UPDATED)</h2>
<h3>Andr&#xe9; F. T. Martins, Marcos Treviso, Ant&#xf3;nio Farinhas, Vlad Niculae, M&#xe1;rio A. T. Figueiredo, Pedro M. Q. Aguiar</h3>
<p>Exponential families are widely used in machine learning; they include many
distributions in continuous and discrete domains (e.g., Gaussian, Dirichlet,
Poisson, and categorical distributions via the softmax transformation).
Distributions in each of these families have fixed support. In contrast, for
finite domains, there has been recent work on sparse alternatives to softmax
(e.g. sparsemax and alpha-entmax), which have varying support, being able to
assign zero probability to irrelevant categories. This paper expands that work
in two directions: first, we extend alpha-entmax to continuous domains,
revealing a link with Tsallis statistics and deformed exponential families.
Second, we introduce continuous-domain attention mechanisms, deriving efficient
gradient backpropagation algorithms for alpha in {1,2}. Experiments on
attention-based text classification, machine translation, and visual question
answering illustrate the use of continuous attention in 1D and 2D, showing that
it allows attending to time intervals and compact regions.
</p>
<a href="http://arxiv.org/abs/2006.07214" target="_blank">arXiv:2006.07214</a> [<a href="http://arxiv.org/pdf/2006.07214" target="_blank">pdf</a>]

<h2>Gaussian Processes on Graphs via Spectral Kernel Learning. (arXiv:2006.07361v3 [cs.LG] UPDATED)</h2>
<h3>Yin-Cong Zhi, Yin Cheng Ng, Xiaowen Dong</h3>
<p>We propose a graph spectrum-based Gaussian process for prediction of signals
defined on nodes of the graph. The model is designed to capture various graph
signal structures through a highly adaptive kernel that incorporates a flexible
polynomial function in the graph spectral domain. Unlike most existing
approaches, we propose to learn such a spectral kernel, where the polynomial
setup enables learning without the need for eigen-decomposition of the graph
Laplacian. In addition, this kernel has the interpretability of graph filtering
achieved by a bespoke maximum likelihood learning algorithm that enforces the
positivity of the spectrum. We demonstrate the interpretability of the model in
synthetic experiments from which we show the various ground truth spectral
filters can be accurately recovered, and the adaptability translates to
superior performances in the prediction of real-world graph data of various
characteristics.
</p>
<a href="http://arxiv.org/abs/2006.07361" target="_blank">arXiv:2006.07361</a> [<a href="http://arxiv.org/pdf/2006.07361" target="_blank">pdf</a>]

<h2>The DeepFake Detection Challenge (DFDC) Dataset. (arXiv:2006.07397v4 [cs.CV] UPDATED)</h2>
<h3>Brian Dolhansky, Joanna Bitton, Ben Pflaum, Jikuo Lu, Russ Howes, Menglin Wang, Cristian Canton Ferrer</h3>
<p>Deepfakes are a recent off-the-shelf manipulation technique that allows
anyone to swap two identities in a single video. In addition to Deepfakes, a
variety of GAN-based face swapping methods have also been published with
accompanying code. To counter this emerging threat, we have constructed an
extremely large face swap video dataset to enable the training of detection
models, and organized the accompanying DeepFake Detection Challenge (DFDC)
Kaggle competition. Importantly, all recorded subjects agreed to participate in
and have their likenesses modified during the construction of the face-swapped
dataset. The DFDC dataset is by far the largest currently and publicly
available face swap video dataset, with over 100,000 total clips sourced from
3,426 paid actors, produced with several Deepfake, GAN-based, and non-learned
methods. In addition to describing the methods used to construct the dataset,
we provide a detailed analysis of the top submissions from the Kaggle contest.
We show although Deepfake detection is extremely difficult and still an
unsolved problem, a Deepfake detection model trained only on the DFDC can
generalize to real "in-the-wild" Deepfake videos, and such a model can be a
valuable analysis tool when analyzing potentially Deepfaked videos. Training,
validation and testing corpuses can be downloaded from
https://ai.facebook.com/datasets/dfdc.
</p>
<a href="http://arxiv.org/abs/2006.07397" target="_blank">arXiv:2006.07397</a> [<a href="http://arxiv.org/pdf/2006.07397" target="_blank">pdf</a>]

<h2>Better Parameter-free Stochastic Optimization with ODE Updates for Coin-Betting. (arXiv:2006.07507v2 [cs.LG] UPDATED)</h2>
<h3>Keyi Chen, John Langford, Francesco Orabona</h3>
<p>Parameter-free stochastic gradient descent (PFSGD) algorithms do not require
setting learning rates while achieving optimal theoretical performance. In
practical applications, however, there remains an empirical gap between tuned
stochastic gradient descent (SGD) and PFSGD. In this paper, we close the
empirical gap with a new parameter-free algorithm based on continuous-time
Coin-Betting on truncated models. The new update is derived through the
solution of an Ordinary Differential Equation (ODE) and solved in a closed
form. We show empirically that this new parameter-free algorithm outperforms
algorithms with the "best default" learning rates and almost matches the
performance of finely tuned baselines without anything to tune.
</p>
<a href="http://arxiv.org/abs/2006.07507" target="_blank">arXiv:2006.07507</a> [<a href="http://arxiv.org/pdf/2006.07507" target="_blank">pdf</a>]

<h2>GNNGuard: Defending Graph Neural Networks against Adversarial Attacks. (arXiv:2006.08149v3 [cs.LG] UPDATED)</h2>
<h3>Xiang Zhang, Marinka Zitnik</h3>
<p>Deep learning methods for graphs achieve remarkable performance across a
variety of domains. However, recent findings indicate that small, unnoticeable
perturbations of graph structure can catastrophically reduce performance of
even the strongest and most popular Graph Neural Networks (GNNs). Here, we
develop GNNGuard, a general algorithm to defend against a variety of
training-time attacks that perturb the discrete graph structure. GNNGuard can
be straight-forwardly incorporated into any GNN. Its core principle is to
detect and quantify the relationship between the graph structure and node
features, if one exists, and then exploit that relationship to mitigate
negative effects of the attack.GNNGuard learns how to best assign higher
weights to edges connecting similar nodes while pruning edges between unrelated
nodes. The revised edges allow for robust propagation of neural messages in the
underlying GNN. GNNGuard introduces two novel components, the neighbor
importance estimation, and the layer-wise graph memory, and we show empirically
that both components are necessary for a successful defense. Across five GNNs,
three defense methods, and five datasets,including a challenging human disease
graph, experiments show that GNNGuard outperforms existing defense approaches
by 15.3% on average. Remarkably, GNNGuard can effectively restore
state-of-the-art performance of GNNs in the face of various adversarial
attacks, including targeted and non-targeted attacks, and can defend against
attacks on heterophily graphs.
</p>
<a href="http://arxiv.org/abs/2006.08149" target="_blank">arXiv:2006.08149</a> [<a href="http://arxiv.org/pdf/2006.08149" target="_blank">pdf</a>]

<h2>Calibrated Reliable Regression using Maximum Mean Discrepancy. (arXiv:2006.10255v2 [cs.LG] UPDATED)</h2>
<h3>Peng Cui, Wenbo Hu, Jun Zhu</h3>
<p>Accurate quantification of uncertainty is crucial for real-world applications
of machine learning. However, modern deep neural networks still produce
unreliable predictive uncertainty, often yielding over-confident predictions.
In this paper, we are concerned with getting well-calibrated predictions in
regression tasks. We propose the calibrated regression method using the maximum
mean discrepancy by minimizing the kernel embedding measure. Theoretically, the
calibration error of our method asymptotically converges to zero when the
sample size is large enough. Experiments on non-trivial real datasets show that
our method can produce well-calibrated and sharp prediction intervals, which
outperforms the related state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2006.10255" target="_blank">arXiv:2006.10255</a> [<a href="http://arxiv.org/pdf/2006.10255" target="_blank">pdf</a>]

<h2>Deep Transformation-Invariant Clustering. (arXiv:2006.11132v2 [cs.CV] UPDATED)</h2>
<h3>Tom Monnier, Thibault Groueix, Mathieu Aubry</h3>
<p>Recent advances in image clustering typically focus on learning better deep
representations. In contrast, we present an orthogonal approach that does not
rely on abstract features but instead learns to predict image transformations
and performs clustering directly in image space. This learning process
naturally fits in the gradient-based training of K-means and Gaussian mixture
model, without requiring any additional loss or hyper-parameters. It leads us
to two new deep transformation-invariant clustering frameworks, which jointly
learn prototypes and transformations. More specifically, we use deep learning
modules that enable us to resolve invariance to spatial, color and
morphological transformations. Our approach is conceptually simple and comes
with several advantages, including the possibility to easily adapt the desired
invariance to the task and a strong interpretability of both cluster centers
and assignments to clusters. We demonstrate that our novel approach yields
competitive and highly promising results on standard image clustering
benchmarks. Finally, we showcase its robustness and the advantages of its
improved interpretability by visualizing clustering results over real
photograph collections.
</p>
<a href="http://arxiv.org/abs/2006.11132" target="_blank">arXiv:2006.11132</a> [<a href="http://arxiv.org/pdf/2006.11132" target="_blank">pdf</a>]

<h2>The GCE in a New Light: Disentangling the $\gamma$-ray Sky with Bayesian Graph Convolutional Neural Networks. (arXiv:2006.12504v2 [astro-ph.HE] UPDATED)</h2>
<h3>Florian List, Nicholas L. Rodd, Geraint F. Lewis, Ishaan Bhat</h3>
<p>A fundamental question regarding the Galactic Center Excess (GCE) is whether
the underlying structure is point-like or smooth. This debate, often framed in
terms of a millisecond pulsar or annihilating dark matter (DM) origin for the
emission, awaits a conclusive resolution. In this work we weigh in on the
problem using Bayesian graph convolutional neural networks. In simulated data,
our neural network (NN) is able to reconstruct the flux of inner Galaxy
emission components to on average $\sim$0.5%, comparable to the non-Poissonian
template fit (NPTF). When applied to the actual $\textit{Fermi}$-LAT data, we
find that the NN estimates for the flux fractions from the background templates
are consistent with the NPTF; however, the GCE is almost entirely attributed to
smooth emission. While suggestive, we do not claim a definitive resolution for
the GCE, as the NN tends to underestimate the flux of point-sources peaked near
the 1$\sigma$ detection threshold. Yet the technique displays robustness to a
number of systematics, including reconstructing injected DM, diffuse
mismodeling, and unmodeled north-south asymmetries. So while the NN is hinting
at a smooth origin for the GCE at present, with further refinements we argue
that Bayesian Deep Learning is well placed to resolve this DM mystery.
</p>
<a href="http://arxiv.org/abs/2006.12504" target="_blank">arXiv:2006.12504</a> [<a href="http://arxiv.org/pdf/2006.12504" target="_blank">pdf</a>]

<h2>Sparse Symplectically Integrated Neural Networks. (arXiv:2006.12972v2 [cs.LG] UPDATED)</h2>
<h3>Daniel M. DiPietro, Shiying Xiong, Bo Zhu</h3>
<p>We introduce Sparse Symplectically Integrated Neural Networks (SSINNs), a
novel model for learning Hamiltonian dynamical systems from data. SSINNs
combine fourth-order symplectic integration with a learned parameterization of
the Hamiltonian obtained using sparse regression through a mathematically
elegant function space. This allows for interpretable models that incorporate
symplectic inductive biases and have low memory requirements. We evaluate
SSINNs on four classical Hamiltonian dynamical problems: the H\'enon-Heiles
system, nonlinearly coupled oscillators, a multi-particle mass-spring system,
and a pendulum system. Our results demonstrate promise in both system
prediction and conservation of energy, often outperforming the current
state-of-the-art black-box prediction techniques by an order of magnitude.
Further, SSINNs successfully converge to true governing equations from highly
limited and noisy data, demonstrating potential applicability in the discovery
of new physical governing equations.
</p>
<a href="http://arxiv.org/abs/2006.12972" target="_blank">arXiv:2006.12972</a> [<a href="http://arxiv.org/pdf/2006.12972" target="_blank">pdf</a>]

<h2>Adai: Separating the Effects of Adaptive Learning Rate and Momentum Inertia. (arXiv:2006.15815v7 [cs.LG] UPDATED)</h2>
<h3>Zeke Xie, Xinrui Wang, Huishuai Zhang, Issei Sato, Masashi Sugiyama</h3>
<p>Adaptive Momentum Estimation (Adam), which combines Adaptive Learning Rate
and Momentum, is the most popular stochastic optimizer for accelerating
training of deep neural networks. But Adam often generalizes significantly
worse than Stochastic Gradient Descent (SGD). It is still mathematically
unclear how Adaptive Learning Rate and Momentum affect saddle-point escaping
and minima selection. Based on the diffusion theoretical framework, we decouple
the effects of Adaptive Learning Rate and Momentum on saddle-point escaping and
minima selection. We prove that Adaptive Learning Rate can escape saddle points
efficiently, but cannot select flat minima as SGD does. In contrast, Momentum
provides a momentum drift effect to help passing through saddle points, and
almost does not affect flat minima selection. This mathematically explains why
SGD (with Momentum) generalizes better, while Adam generalizes worse but
converges faster. We design a novel adaptive optimizer named Adaptive Inertia
Estimation (Adai), which uses parameter-wise adaptive inertia to accelerate
training and provably favors flat minima as much as SGD. Our real-world
experiments demonstrate that Adai can significantly outperform SGD and existing
Adam variants.
</p>
<a href="http://arxiv.org/abs/2006.15815" target="_blank">arXiv:2006.15815</a> [<a href="http://arxiv.org/pdf/2006.15815" target="_blank">pdf</a>]

<h2>Ultrahyperbolic Representation Learning. (arXiv:2007.00211v4 [cs.LG] UPDATED)</h2>
<h3>Marc T. Law, Jos Stam</h3>
<p>In machine learning, data is usually represented in a (flat) Euclidean space
where distances between points are along straight lines. Researchers have
recently considered more exotic (non-Euclidean) Riemannian manifolds such as
hyperbolic space which is well suited for tree-like data. In this paper, we
propose a representation living on a pseudo-Riemannian manifold of constant
nonzero curvature. It is a generalization of hyperbolic and spherical
geometries where the non-degenerate metric tensor need not be positive
definite. We provide the necessary learning tools in this geometry and extend
gradient method optimization techniques. More specifically, we provide
closed-form expressions for distances via geodesics and define a descent
direction to minimize some objective function. Our novel framework is applied
to graph representations.
</p>
<a href="http://arxiv.org/abs/2007.00211" target="_blank">arXiv:2007.00211</a> [<a href="http://arxiv.org/pdf/2007.00211" target="_blank">pdf</a>]

<h2>Learning Utilities and Equilibria in Non-Truthful Auctions. (arXiv:2007.01722v2 [cs.GT] UPDATED)</h2>
<h3>Hu Fu, Tao Lin</h3>
<p>In non-truthful auctions, agents' utility for a strategy depends on the
strategies of the opponents and also the prior distribution over their private
types; the set of Bayes Nash equilibria generally has an intricate dependence
on the prior. Using the First Price Auction as our main demonstrating example,
we show that $\tilde O(n / \epsilon^2)$ samples from the prior with $n$ agents
suffice for an algorithm to learn the interim utilities for all monotone
bidding strategies. As a consequence, this number of samples suffice for
learning all approximate equilibria. We give almost matching (up to polylog
factors) lower bound on the sample complexity for learning utilities. We also
consider a setting where agents must pay a search cost to discover their own
types. Drawing on a connection between this setting and the first price
auction, discovered recently by Kleinberg et al. (2016), we show that $\tilde
O(n / \epsilon^2)$ samples suffice for utilities and equilibria to be estimated
in a near welfare-optimal descending auction in this setting. En route, we
improve the sample complexity bound, recently obtained by Guo et al. (2020),
for the Pandora's Box problem, which is a classical model for sequential
consumer search.
</p>
<a href="http://arxiv.org/abs/2007.01722" target="_blank">arXiv:2007.01722</a> [<a href="http://arxiv.org/pdf/2007.01722" target="_blank">pdf</a>]

<h2>Learning from Noisy Labels with Deep Neural Networks: A Survey. (arXiv:2007.08199v3 [cs.LG] UPDATED)</h2>
<h3>Hwanjun Song, Minseok Kim, Dongmin Park, Jae-Gil Lee</h3>
<p>Deep learning has achieved remarkable success in numerous domains with help
from large amounts of big data. However, the quality of data labels is a
concern because of the lack of high-quality labels in many real-world
scenarios. As noisy labels severely degrade the generalization performance of
deep neural networks, learning from noisy labels (robust training) is becoming
an important task in modern deep learning applications. In this survey, we
first describe the problem of learning with label noise from a supervised
learning perspective. Next, we provide a comprehensive review of 46
state-of-the-art robust training methods, all of which are categorized into
seven groups according to their methodological difference, followed by a
systematic comparison of six properties used to evaluate their superiority.
Subsequently, we summarize the typically used evaluation methodology, including
public noisy datasets and evaluation metrics. Finally, we present several
promising research directions that can serve as a guideline for future studies.
</p>
<a href="http://arxiv.org/abs/2007.08199" target="_blank">arXiv:2007.08199</a> [<a href="http://arxiv.org/pdf/2007.08199" target="_blank">pdf</a>]

<h2>Smart Choices and the Selection Monad. (arXiv:2007.08926v2 [cs.LO] UPDATED)</h2>
<h3>Martin Abadi, Gordon Plotkin</h3>
<p>Describing systems in terms of choices and of the resulting costs and rewards
offers the promise of freeing algorithm designers and programmers from
specifying how those choices should be made; in implementations, the choices
can be realized by optimization techniques and, increasingly, by machine
learning methods. We study this approach from a programming-language
perspective. We define two small languages that support decision-making
abstractions: one with choices and rewards, and the other additionally with
probabilities. We give both operational and denotational semantics. In the case
of the second language we consider three denotational semantics, with varying
degrees of correlation between the final values and the expected rewards. The
operational semantics combine the usual semantics of standard constructs with
optimization over spaces of possible execution strategies. The denotational
semantics, which are compositional and can also be viewed as an implementation
by translation to a simpler language, rely on the selection monad, to handle
choice, combined with an auxiliary monad, to handle other effects such as
reward or probability. We establish adequacy theorems that the two semantics
coincide in all cases. We also prove full abstraction at ground types, with
varying notions of observation in the probabilistic case corresponding to the
various degrees of correlation. We present axioms for choice combined with
reward and probability, establishing completeness at ground types for the case
of rewards without probability.
</p>
<a href="http://arxiv.org/abs/2007.08926" target="_blank">arXiv:2007.08926</a> [<a href="http://arxiv.org/pdf/2007.08926" target="_blank">pdf</a>]

<h2>Moving fast and slow: Analysis of representations and post-processing in speech-driven automatic gesture generation. (arXiv:2007.09170v2 [cs.CV] UPDATED)</h2>
<h3>Taras Kucherenko, Dai Hasegawa, Naoshi Kaneko, Gustav Eje Henter, Hedvig Kjellstr&#xf6;m</h3>
<p>This paper presents a novel framework for speech-driven gesture production,
applicable to virtual agents to enhance human-computer interaction.
Specifically, we extend recent deep-learning-based, data-driven methods for
speech-driven gesture generation by incorporating representation learning. Our
model takes speech as input and produces gestures as output, in the form of a
sequence of 3D coordinates. We provide an analysis of different representations
for the input (speech) and the output (motion) of the network by both objective
and subjective evaluations. We also analyse the importance of smoothing of the
produced motion. Our results indicated that the proposed method improved on our
baseline in terms of objective measures. For example, it better captured the
motion dynamics and better matched the motion-speed distribution. Moreover, we
performed user studies on two different datasets. The studies confirmed that
our proposed method is perceived as more natural than the baseline, although
the difference in the studies was eliminated by appropriate post-processing:
hip-centering and smoothing. We conclude that it is important to take both
feature representation, model architecture and post-processing into account
when designing an automatic gesture-production method.
</p>
<a href="http://arxiv.org/abs/2007.09170" target="_blank">arXiv:2007.09170</a> [<a href="http://arxiv.org/pdf/2007.09170" target="_blank">pdf</a>]

<h2>Robust Template Matching via Hierarchical Convolutional Features from a Shape Biased CNN. (arXiv:2007.15817v2 [cs.CV] UPDATED)</h2>
<h3>Bo Gao, M. W. Spratling</h3>
<p>Finding a template in a search image is an important task underlying many
computer vision applications. Recent approaches perform template matching in a
deep feature space, produced by a convolutional neural network (CNN), which is
found to provide more tolerance to changes in appearance. In this article we
investigate if enhancing the CNN's encoding of shape information can produce
more distinguishable features that improve the performance of template
matching. This investigation results in a new template matching method that
produces state-of-the-art results on a standard benchmark. To confirm these
results we also create a new benchmark and show that the proposed method also
outperforms existing techniques on this new dataset. We further applied the
proposed method to tracking and achieved more robust results.
</p>
<a href="http://arxiv.org/abs/2007.15817" target="_blank">arXiv:2007.15817</a> [<a href="http://arxiv.org/pdf/2007.15817" target="_blank">pdf</a>]

<h2>Active Classification with Uncertainty Comparison Queries. (arXiv:2008.00645v2 [cs.LG] UPDATED)</h2>
<h3>Zhenghang Cui, Issei Sato</h3>
<p>Noisy pairwise comparison feedback has been incorporated to improve the
overall query complexity of interactively learning binary classifiers. The
\textit{positivity comparison oracle} is used to provide feedback on which is
more likely to be positive given a pair of data points. Because it is
impossible to infer accurate labels using this oracle alone \textit{without
knowing the classification threshold}, existing methods still rely on the
traditional \textit{explicit labeling oracle}, which directly answers the label
given a data point. Existing methods conduct sorting on all data points and use
explicit labeling oracle to find the classification threshold. The current
methods, however, have two drawbacks: (1) they needs unnecessary sorting for
label inference; (2) quick sort is naively adapted to noisy feedback and
negatively affects practical performance. In order to avoid this inefficiency
and acquire information of the classification threshold, we propose a new
pairwise comparison oracle concerning uncertainties. This oracle receives two
data points as input and answers which one has higher uncertainty. We then
propose an efficient adaptive labeling algorithm using the proposed oracle and
the positivity comparison oracle. In addition, we also address the situation
where the labeling budget is insufficient compared to the dataset size, which
can be dealt with by plugging the proposed algorithm into an active learning
algorithm. Furthermore, we confirm the feasibility of the proposed oracle and
the performance of the proposed algorithm theoretically and empirically.
</p>
<a href="http://arxiv.org/abs/2008.00645" target="_blank">arXiv:2008.00645</a> [<a href="http://arxiv.org/pdf/2008.00645" target="_blank">pdf</a>]

<h2>Implicit Regularization via Neural Feature Alignment. (arXiv:2008.00938v2 [cs.LG] UPDATED)</h2>
<h3>Aristide Baratin, Thomas George, C&#xe9;sar Laurent, R Devon Hjelm, Guillaume Lajoie, Pascal Vincent, Simon Lacoste-Julien</h3>
<p>We approach the problem of implicit regularization in deep learning from a
geometrical viewpoint. We highlight a regularization effect induced by a
dynamical alignment of the neural tangent features introduced by Jacot et al,
along a small number of task-relevant directions. This can be interpreted as a
combined mechanism of feature selection and model compression. By extrapolating
a new analysis of Rademacher complexity bounds for linear models, we motivate
and study a heuristic complexity measure that captures this phenomenon, in
terms of sequences of tangent kernel classes along the optimization paths.
</p>
<a href="http://arxiv.org/abs/2008.00938" target="_blank">arXiv:2008.00938</a> [<a href="http://arxiv.org/pdf/2008.00938" target="_blank">pdf</a>]

<h2>Optimal control towards sustainable wastewater treatment plants based on deep reinforcement learning. (arXiv:2008.10417v2 [eess.SP] UPDATED)</h2>
<h3>Kehua Chen, Hongcheng Wang, Borja Valverde Perezc, Luca Vezzaro, Aijie Wang</h3>
<p>Wastewater treatment plants (WWTPs) are designed to eliminate pollutants and
alleviate environmental pollution resulting from human activities. However, the
construction and operation of WWTPs still have negative impacts. WWTPs are
complex to control and optimize because of high non-linearity and variation.
This study used a novel technique, multi-agent deep reinforcement learning
(MADRL), to optimize dissolved oxygen (DO) and chemical dosage in a WWTP. The
reward function is specially designed as life cycle assessment (LCA)-based form
to achieve sustainability optimization. Five scenarios are considered:
baseline, LCA-oriented Class I-A, LCA-oriented Class I-B, cost-oriented and
LCA-oriented SurfaceWater IV. The result shows that optimization based on LCA
has lower environmental impacts compared to baseline scenario. The
cost-oriented control strategy owns comparable performance to the LCA-driven
strategy, but with less extendability. It is worth mentioning that the
retrofitting of WWTPs based on resources should be implemented with the
consideration of impact transfer. The major contributors of each indicators are
identified for future study and improvement. Last, we discuss that novel
dynamic control strategies require advanced sensors or a large amount of data,
so the selection of control strategies should also consider economic and
ecological conditions. In a nutshell, there are still limits and shortcomings
of this work and future studies are required.
</p>
<a href="http://arxiv.org/abs/2008.10417" target="_blank">arXiv:2008.10417</a> [<a href="http://arxiv.org/pdf/2008.10417" target="_blank">pdf</a>]

<h2>Learning to summarize from human feedback. (arXiv:2009.01325v2 [cs.CL] UPDATED)</h2>
<h3>Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano</h3>
<p>As language models become more powerful, training and evaluation are
increasingly bottlenecked by the data and metrics used for a particular task.
For example, summarization models are often trained to predict human reference
summaries and evaluated using ROUGE, but both of these metrics are rough
proxies for what we really care about---summary quality. In this work, we show
that it is possible to significantly improve summary quality by training a
model to optimize for human preferences. We collect a large, high-quality
dataset of human comparisons between summaries, train a model to predict the
human-preferred summary, and use that model as a reward function to fine-tune a
summarization policy using reinforcement learning. We apply our method to a
version of the TL;DR dataset of Reddit posts and find that our models
significantly outperform both human reference summaries and much larger models
fine-tuned with supervised learning alone. Our models also transfer to CNN/DM
news articles, producing summaries nearly as good as the human reference
without any news-specific fine-tuning. We conduct extensive analyses to
understand our human feedback dataset and fine-tuned models We establish that
our reward model generalizes to new datasets, and that optimizing our reward
model results in better summaries than optimizing ROUGE according to humans. We
hope the evidence from our paper motivates machine learning researchers to pay
closer attention to how their training loss affects the model behavior they
actually want.
</p>
<a href="http://arxiv.org/abs/2009.01325" target="_blank">arXiv:2009.01325</a> [<a href="http://arxiv.org/pdf/2009.01325" target="_blank">pdf</a>]

<h2>Integration of AI and mechanistic modeling in generative adversarial networks for stochastic inverse problems. (arXiv:2009.08267v2 [stat.ML] UPDATED)</h2>
<h3>Jaimit Parikh, James Kozloski, Viatcheslav Gurev</h3>
<p>Stochastic inverse problems (SIP) address the behavior of a set of objects of
the same kind but with variable properties, such as a population of cells.
Using a population of mechanistic models from a single parametric family, SIP
explains population variability by transferring real-world observations into
the latent space of model parameters. Previous research in SIP focused on
solving the parameter inference problem for a single population using Markov
chain Monte Carlo methods. Here we extend SIP to address multiple related
populations simultaneously. Specifically, we simulate control and treatment
populations in experimental protocols by discovering two related latent spaces
of model parameters. Instead of taking a Bayesian approach, our two-population
SIP is reformulated as the constrained-optimization problem of finding
distributions of model parameters. To minimize the divergence between
distributions of experimental observations and model outputs, we developed
novel deep learning models based on generative adversarial networks (GANs)
which have the structure of our underlying constrained-optimization problem.
The flexibility of GANs allowed us to build computationally scalable solutions
and tackle complex model input parameter inference scenarios, which appear
routinely in physics, biophysics, economics and other areas, and which can not
be handled with existing methods. Specifically, we demonstrate two scenarios of
parameter inference over a control population and a treatment population whose
treatment either selectively affects only a subset of model parameters with
some uncertainty or has a deterministic effect on all model parameters.
</p>
<a href="http://arxiv.org/abs/2009.08267" target="_blank">arXiv:2009.08267</a> [<a href="http://arxiv.org/pdf/2009.08267" target="_blank">pdf</a>]

<h2>Low-Rank Matrix Recovery from Noise via an MDL Framework-based Atomic Norm. (arXiv:2009.08297v2 [cs.CV] UPDATED)</h2>
<h3>Anyong Qin, Lina Xian, Yongliang Yang, Taiping Zhang, Yuan Yan Tang</h3>
<p>The recovery of the underlying low-rank structure of clean data corrupted
with sparse noise/outliers is attracting increasing interest. However, in many
low-level vision problems, the exact target rank of the underlying structure
and the particular locations and values of the sparse outliers are not known.
Thus, the conventional methods cannot separate the low-rank and sparse
components completely, especially in the case of gross outliers or deficient
observations. Therefore, in this study, we employ the minimum description
length (MDL) principle and atomic norm for low-rank matrix recovery to overcome
these limitations. First, we employ the atomic norm to find all the candidate
atoms of low-rank and sparse terms, and then we minimize the description length
of the model in order to select the appropriate atoms of low-rank and the
sparse matrices, respectively. Our experimental analyses show that the proposed
approach can obtain a higher success rate than the state-of-the-art methods,
even when the number of observations is limited or the corruption ratio is
high. Experimental results utilizing synthetic data and real sensing
applications (high dynamic range imaging, background modeling, removing noise
and shadows) demonstrate the effectiveness, robustness and efficiency of the
proposed method.
</p>
<a href="http://arxiv.org/abs/2009.08297" target="_blank">arXiv:2009.08297</a> [<a href="http://arxiv.org/pdf/2009.08297" target="_blank">pdf</a>]

<h2>An Attention Mechanism with Multiple Knowledge Sources for COVID-19 Detection from CT Images. (arXiv:2009.11008v3 [eess.IV] UPDATED)</h2>
<h3>Duy M. H. Nguyen, Duy M. Nguyen, Huong Vu, Binh T. Nguyen, Fabrizio Nunnari, Daniel Sonntag</h3>
<p>Until now, Coronavirus SARS-CoV-2 has caused more than 850,000 deaths and
infected more than 27 million individuals in over 120 countries. Besides
principal polymerase chain reaction (PCR) tests, automatically identifying
positive samples based on computed tomography (CT) scans can present a
promising option in the early diagnosis of COVID-19. Recently, there have been
increasing efforts to utilize deep networks for COVID-19 diagnosis based on CT
scans. While these approaches mostly focus on introducing novel architectures,
transfer learning techniques, or construction large scale data, we propose a
novel strategy to improve the performance of several baselines by leveraging
multiple useful information sources relevant to doctors' judgments.
Specifically, infected regions and heat maps extracted from learned networks
are integrated with the global image via an attention mechanism during the
learning process. This procedure not only makes our system more robust to noise
but also guides the network focusing on local lesion areas. Extensive
experiments illustrate the superior performance of our approach compared to
recent baselines. Furthermore, our learned network guidance presents an
explainable feature to doctors as we can understand the connection between
input and output in a grey-box model.
</p>
<a href="http://arxiv.org/abs/2009.11008" target="_blank">arXiv:2009.11008</a> [<a href="http://arxiv.org/pdf/2009.11008" target="_blank">pdf</a>]

<h2>Enhancing MRI Brain Tumor Segmentation with an Additional Classification Network. (arXiv:2009.12111v2 [eess.IV] UPDATED)</h2>
<h3>Hieu T. Nguyen, Tung T. Le, Thang V. Nguyen, Nhan T. Nguyen</h3>
<p>Brain tumor segmentation plays an essential role in medical image analysis.
In recent studies, deep convolution neural networks (DCNNs) are extremely
powerful to tackle tumor segmentation tasks. We propose in this paper a novel
training method that enhances the segmentation results by adding an additional
classification branch to the network. The whole network was trained end-to-end
on the Multimodal Brain Tumor Segmentation Challenge (BraTS) 2020 training
dataset. On the BraTS's validation set, it achieved an average Dice score of
78.43%, 89.99%, and 84.22% respectively for the enhancing tumor, the whole
tumor, and the tumor core.
</p>
<a href="http://arxiv.org/abs/2009.12111" target="_blank">arXiv:2009.12111</a> [<a href="http://arxiv.org/pdf/2009.12111" target="_blank">pdf</a>]

<h2>XDA: Accurate, Robust Disassembly with Transfer Learning. (arXiv:2010.00770v2 [cs.CR] UPDATED)</h2>
<h3>Kexin Pei, Jonas Guan, David Williams-King, Junfeng Yang, Suman Jana</h3>
<p>Accurate and robust disassembly of stripped binaries is challenging. The root
of the difficulty is that high-level structures, such as instruction and
function boundaries, are absent in stripped binaries and must be recovered
based on incomplete information. Current disassembly approaches rely on
heuristics or simple pattern matching to approximate the recovery, but these
methods are often inaccurate and brittle, especially across different compiler
optimizations.

We present XDA, a transfer-learning-based disassembly framework that learns
different contextual dependencies present in machine code and transfers this
knowledge for accurate and robust disassembly. We design a self-supervised
learning task motivated by masked Language Modeling to learn interactions among
byte sequences in binaries. The outputs from this task are byte embeddings that
encode sophisticated contextual dependencies between input binaries' byte
tokens, which can then be finetuned for downstream disassembly tasks.

We evaluate XDA's performance on two disassembly tasks, recovering function
boundaries and assembly instructions, on a collection of 3,121 binaries taken
from SPEC CPU2017, SPEC CPU2006, and the BAP corpus. The binaries are compiled
by GCC, ICC, and MSVC on x86/x64 Windows and Linux platforms over 4
optimization levels. XDA achieves 99.0% and 99.7% F1 score at recovering
function boundaries and instructions, respectively, surpassing the previous
state-of-the-art on both tasks. It also maintains speed on par with the fastest
ML-based approach and is up to 38x faster than hand-written disassemblers like
IDA Pro.
</p>
<a href="http://arxiv.org/abs/2010.00770" target="_blank">arXiv:2010.00770</a> [<a href="http://arxiv.org/pdf/2010.00770" target="_blank">pdf</a>]

<h2>On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach. (arXiv:2010.01079v3 [econ.TH] UPDATED)</h2>
<h3>Junpei Komiyama, Shunya Noda</h3>
<p>We analyze statistical discrimination using a multi-armed bandit model where
myopic firms face candidate workers arriving with heterogeneous observable
characteristics. The association between the worker's skill and characteristics
is unknown ex ante; thus, firms need to learn it. In such an environment,
laissez-faire may result in a highly unfair and inefficient outcome---myopic
firms are reluctant to hire minority workers because the lack of data about
minority workers prevents accurate estimation of their performance.
Consequently, minority groups could be perpetually underestimated---they are
never hired, and therefore, data about them is never accumulated. We proved
that this problem becomes more serious when the population ratio is imbalanced,
as is the case in many extant discrimination problems. We consider two
affirmative-action policies for solving this dilemma: One is a subsidy rule
that is based on the popular upper confidence bound algorithm, and another is
the Rooney Rule, which requires firms to interview at least one minority worker
for each hiring opportunity. Our results indicate temporary affirmative actions
are effective for statistical discrimination caused by data insufficiency.
</p>
<a href="http://arxiv.org/abs/2010.01079" target="_blank">arXiv:2010.01079</a> [<a href="http://arxiv.org/pdf/2010.01079" target="_blank">pdf</a>]

<h2>Revisiting Batch Normalization for Training Low-latency Deep Spiking Neural Networks from Scratch. (arXiv:2010.01729v2 [cs.CV] UPDATED)</h2>
<h3>Youngeun Kim, Priyadarshini Panda</h3>
<p>Spiking Neural Networks (SNNs) have recently emerged as an alternative to
deep learning owing to sparse, asynchronous and binary event (or spike) driven
processing, that can yield huge energy efficiency benefits on neuromorphic
hardware. Most existing approaches to create SNNs either convert the weights
from pre-trained Artificial Neural Networks (ANNs) or directly train SNNs with
surrogate gradient backpropagation. Each approach presents its pros and cons.
The ANN-to-SNN conversion method requires at least hundreds of time-steps for
inference to yield competitive accuracy that in turn reduces the energy
savings. Training SNNs with surrogate gradients from scratch reduces the
latency or total number of time-steps, but the training becomes
slow/problematic and has convergence issues. Thus, the latter approach of
training SNNs has been limited to shallow networks on simple datasets. To
address this training issue in SNNs, we revisit batch normalization and propose
a temporal Batch Normalization Through Time (BNTT) technique. Most prior SNN
works till now have disregarded batch normalization deeming it ineffective for
training temporal SNNs. Different from previous works, our proposed BNTT
decouples the parameters in a BNTT layer along the time axis to capture the
temporal dynamics of spikes. The temporally evolving learnable parameters in
BNTT allow a neuron to control its spike rate through different time-steps,
enabling low-latency and low-energy training from scratch. We conduct
experiments on CIFAR-10, CIFAR-100, Tiny-ImageNet and event-driven DVS-CIFAR10
datasets. BNTT allows us to train deep SNN architectures from scratch, for the
first time, on complex datasets with just few 25-30 time-steps. We also propose
an early exit algorithm using the distribution of parameters in BNTT to reduce
the latency at inference, that further improves the energy-efficiency.
</p>
<a href="http://arxiv.org/abs/2010.01729" target="_blank">arXiv:2010.01729</a> [<a href="http://arxiv.org/pdf/2010.01729" target="_blank">pdf</a>]

<h2>Contrastive Representation Learning: A Framework and Review. (arXiv:2010.05113v2 [cs.LG] UPDATED)</h2>
<h3>Phuc H. Le-Khac, Graham Healy, Alan F. Smeaton</h3>
<p>Contrastive Learning has recently received interest due to its success in
self-supervised representation learning in the computer vision domain. However,
the origins of Contrastive Learning date as far back as the 1990s and its
development has spanned across many fields and domains including Metric
Learning and natural language processing. In this paper we provide a
comprehensive literature review and we propose a general Contrastive
Representation Learning framework that simplifies and unifies many different
contrastive learning methods. We also provide a taxonomy for each of the
components of contrastive learning in order to summarise it and distinguish it
from other forms of machine learning. We then discuss the inductive biases
which are present in any contrastive learning system and we analyse our
framework under different views from various sub-fields of Machine Learning.
Examples of how contrastive learning has been applied in computer vision,
natural language processing, audio processing, and others, as well as in
Reinforcement Learning are also presented. Finally, we discuss the challenges
and some of the most promising future research directions ahead.
</p>
<a href="http://arxiv.org/abs/2010.05113" target="_blank">arXiv:2010.05113</a> [<a href="http://arxiv.org/pdf/2010.05113" target="_blank">pdf</a>]

<h2>Neural-Symbolic Reasoning on Knowledge Graphs. (arXiv:2010.05446v2 [cs.AI] UPDATED)</h2>
<h3>Jing Zhang, Bo Chen, Lingxi Zhang, Xirui Ke, Haipeng Ding</h3>
<p>Knowledge graph reasoning is the fundamental component to support machine
learning applications such as information extraction, information retrieval and
recommendation. Since knowledge graph can be viewed as the discrete symbolic
representations of knowledge, reasoning on knowledge graphs can naturally
leverage the symbolic techniques. However, symbolic reasoning is intolerant of
the ambiguous and noisy data. On the contrary, the recent advances of deep
learning promote neural reasoning on knowledge graphs, which is robust to the
ambiguous and noisy data, but lacks interpretability compared to symbolic
reasoning. Considering the advantages and disadvantages of both methodologies,
recent efforts have been made on combining the two reasoning methods. In this
survey, we take a thorough look at the development of the symbolic reasoning,
neural reasoning and the neural-symbolic reasoning on knowledge graphs. We
survey two specific reasoning tasks, knowledge graph completion and question
answering on knowledge graphs, and explain them in a unified reasoning
framework. We also briefly discuss the future directions for knowledge graph
reasoning.
</p>
<a href="http://arxiv.org/abs/2010.05446" target="_blank">arXiv:2010.05446</a> [<a href="http://arxiv.org/pdf/2010.05446" target="_blank">pdf</a>]

<h2>From Hero to Z\'eroe: A Benchmark of Low-Level Adversarial Attacks. (arXiv:2010.05648v2 [cs.CL] UPDATED)</h2>
<h3>Steffen Eger, Yannik Benz</h3>
<p>Adversarial attacks are label-preserving modifications to inputs of machine
learning classifiers designed to fool machines but not humans. Natural Language
Processing (NLP) has mostly focused on high-level attack scenarios such as
paraphrasing input texts. We argue that these are less realistic in typical
application scenarios such as in social media, and instead focus on low-level
attacks on the character-level. Guided by human cognitive abilities and human
robustness, we propose the first large-scale catalogue and benchmark of
low-level adversarial attacks, which we dub Z\'eroe, encompassing nine
different attack modes including visual and phonetic adversaries. We show that
RoBERTa, NLP's current workhorse, fails on our attacks. Our dataset provides a
benchmark for testing robustness of future more human-like NLP models.
</p>
<a href="http://arxiv.org/abs/2010.05648" target="_blank">arXiv:2010.05648</a> [<a href="http://arxiv.org/pdf/2010.05648" target="_blank">pdf</a>]

<h2>CAPT: Contrastive Pre-Training for Learning Denoised Sequence Representations. (arXiv:2010.06351v2 [cs.CL] UPDATED)</h2>
<h3>Fuli Luo, Pengcheng Yang, Shicheng Li, Xuancheng Ren, Xu Sun</h3>
<p>Pre-trained self-supervised models such as BERT have achieved striking
success in learning sequence representations, especially for natural language
processing. These models typically corrupt the given sequences with certain
types of noise, such as masking, shuffling, or substitution, and then try to
recover the original input. However, such pre-training approaches are prone to
learning representations that are covariant with the noise, leading to the
discrepancy between the pre-training and fine-tuning stage. To remedy this, we
present ContrAstive Pre-Training (CAPT) to learn noise invariant sequence
representations. The proposed CAPT encourages the consistency between
representations of the original sequence and its corrupted version via
unsupervised instance-wise training signals. In this way, it not only
alleviates the pretrain-finetune discrepancy induced by the noise of
pre-training, but also aids the pre-trained model in better capturing global
semantics of the input via more effective sentence-level supervision. Different
from most prior work that focuses on a particular modality, comprehensive
empirical evidence on 11 natural language understanding and cross-modal tasks
illustrates that CAPT is applicable for both language and vision-language
tasks, and obtains surprisingly consistent improvement, including 0.6% absolute
gain on GLUE benchmarks and 0.8% absolute increment on NLVR.
</p>
<a href="http://arxiv.org/abs/2010.06351" target="_blank">arXiv:2010.06351</a> [<a href="http://arxiv.org/pdf/2010.06351" target="_blank">pdf</a>]

<h2>A Systematic Review on Online Exams Solutions in E-learning: Techniques, Tools, and Global Adoption. (arXiv:2010.07086v2 [cs.CY] UPDATED)</h2>
<h3>Abdul Wahab Muzaffar, Muhammad Tahir, Muhammad Waseem Anwar, Qaiser Chaudry, Shamaila Rasheed Mir</h3>
<p>E-learning in higher education is exponentially increased during the past
decade due to its inevitable benefits in critical situations like natural
disasters, and pandemic. The reliable, fair, and seamless execution of online
exams in E-learning is highly significant. Particularly, online exams are
conducted on E-learning platforms without the physical presence of students and
instructors at the same place. This poses several issues like integrity and
security during online exams. To address such issues, researchers frequently
proposed different techniques and tools. However, a study summarizing and
analyzing latest developments, particularly in the area of online examination,
is hard to find in the literature. In this article, an SLR for online
examination is performed to select and analyze 53 studies published during the
last five years. Subsequently, five leading online exams features targeted in
the selected studies are identified and underlying development approaches for
the implementation of online exams solutions are explored. Furthermore, 16
important techniques and 11 datasets are presented. In addition, 21 online
exams tools proposed in the selected studies are identified. Additionally, 25
leading existing tools used in the selected studies are also presented.
Finally, the participation of countries in online exam research is
investigated. Key factors for the global adoption of online exams are
identified and investigated. This facilitates the selection of right online
exam system for a particular country on the basis of existing E-learning
infrastructure and overall cost. To conclude, the findings of this article
provide a solid platform for the researchers and practitioners of the domain to
select appropriate features along with underlying development approaches, tools
and techniques for the implementation of a particular online exams solution as
per given requirements.
</p>
<a href="http://arxiv.org/abs/2010.07086" target="_blank">arXiv:2010.07086</a> [<a href="http://arxiv.org/pdf/2010.07086" target="_blank">pdf</a>]

<h2>Learning Deep Features in Instrumental Variable Regression. (arXiv:2010.07154v2 [cs.LG] UPDATED)</h2>
<h3>Liyuan Xu, Yutian Chen, Siddarth Srinivasan, Nando de Freitas, Arnaud Doucet, Arthur Gretton</h3>
<p>Instrumental variable (IV) regression is a standard strategy for learning
causal relationships between confounded treatment and outcome variables from
observational data by utilizing an instrumental variable, which affects the
outcome only through the treatment. In classical IV regression, learning
proceeds in two stages: stage 1 performs linear regression from the instrument
to the treatment; and stage 2 performs linear regression from the treatment to
the outcome, conditioned on the instrument. We propose a novel method, deep
feature instrumental variable regression (DFIV), to address the case where
relations between instruments, treatments, and outcomes may be nonlinear. In
this case, deep neural nets are trained to define informative nonlinear
features on the instruments and treatments. We propose an alternating training
regime for these features to ensure good end-to-end performance when composing
stages 1 and 2, thus obtaining highly flexible feature maps in a
computationally efficient manner. DFIV outperforms recent state-of-the-art
methods on challenging IV benchmarks, including settings involving high
dimensional image data. DFIV also exhibits competitive performance in
off-policy policy evaluation for reinforcement learning, which can be
understood as an IV regression task.
</p>
<a href="http://arxiv.org/abs/2010.07154" target="_blank">arXiv:2010.07154</a> [<a href="http://arxiv.org/pdf/2010.07154" target="_blank">pdf</a>]

<h2>Model-based Policy Optimization with Unsupervised Model Adaptation. (arXiv:2010.09546v2 [cs.LG] UPDATED)</h2>
<h3>Jian Shen, Han Zhao, Weinan Zhang, Yong Yu</h3>
<p>Model-based reinforcement learning methods learn a dynamics model with real
data sampled from the environment and leverage it to generate simulated data to
derive an agent. However, due to the potential distribution mismatch between
simulated data and real data, this could lead to degraded performance. Despite
much effort being devoted to reducing this distribution mismatch, existing
methods fail to solve it explicitly. In this paper, we investigate how to
bridge the gap between real and simulated data due to inaccurate model
estimation for better policy optimization. To begin with, we first derive a
lower bound of the expected return, which naturally inspires a bound
maximization algorithm by aligning the simulated and real data distributions.
To this end, we propose a novel model-based reinforcement learning framework
AMPO, which introduces unsupervised model adaptation to minimize the integral
probability metric (IPM) between feature distributions from real and simulated
data. Instantiating our framework with Wasserstein-1 distance gives a practical
model-based approach. Empirically, our approach achieves state-of-the-art
performance in terms of sample efficiency on a range of continuous control
benchmark tasks.
</p>
<a href="http://arxiv.org/abs/2010.09546" target="_blank">arXiv:2010.09546</a> [<a href="http://arxiv.org/pdf/2010.09546" target="_blank">pdf</a>]

<h2>Multi-Window Data Augmentation Approach for Speech Emotion Recognition. (arXiv:2010.09895v2 [cs.SD] UPDATED)</h2>
<h3>Sarala Padi, Dinesh Manocha, Ram D.Sriram</h3>
<p>We present a novel, Multi-Window Data Augmentation (MWA-SER) approach for
speech emotion recognition. MWA-SER is a unimodal approach that focuses on two
key concepts; designing the speech augmentation method to generate additional
data samples and building the deep learning models to recognize the underlying
emotion of an audio signal. The multi-window augmentation method extracts more
audio features from the speech signal by employing multiple window sizes in the
audio feature extraction process. We show that our proposed augmentation
method, combined with a deep learning model, improves the speech emotion
recognition performance. We evaluate the performance of our MWA-SER approach on
the IEMOCAP corpus and show that our proposed method achieves state-of-the-art
results. Furthermore, the proposed system demonstrated 70% and 88% accuracy
while recognizing the emotions for the SAVEE and RAVDESS datasets,
respectively.
</p>
<a href="http://arxiv.org/abs/2010.09895" target="_blank">arXiv:2010.09895</a> [<a href="http://arxiv.org/pdf/2010.09895" target="_blank">pdf</a>]

<h2>Heterogeneous Hypergraph Embedding for Graph Classification. (arXiv:2010.10728v2 [cs.SI] UPDATED)</h2>
<h3>Xiangguo Sun, Hongzhi Yin, Bo Liu, Hongxu Chen, Jiuxin Cao, Yingxia Shao, Nguyen Quoc Viet Hung</h3>
<p>Recently, graph neural networks have been widely used for network embedding
because of their prominent performance in pairwise relationship learning. In
the real world, a more natural and common situation is the coexistence of
pairwise relationships and complex non-pairwise relationships, which is,
however, rarely studied. In light of this, we propose a graph neural
network-based representation learning framework for heterogeneous hypergraphs,
an extension of conventional graphs, which can well characterize multiple
non-pairwise relations. Our framework first projects the heterogeneous
hypergraph into a series of snapshots and then we take the Wavelet basis to
perform localized hypergraph convolution. Since the Wavelet basis is usually
much sparser than the Fourier basis, we develop an efficient polynomial
approximation to the basis to replace the time-consuming Laplacian
decomposition. Extensive evaluations have been conducted and the experimental
results show the superiority of our method. In addition to the standard tasks
of network embedding evaluation such as node classification, we also apply our
method to the task of spammers detection and the superior performance of our
framework shows that relationships beyond pairwise are also advantageous in the
spammer detection.
</p>
<a href="http://arxiv.org/abs/2010.10728" target="_blank">arXiv:2010.10728</a> [<a href="http://arxiv.org/pdf/2010.10728" target="_blank">pdf</a>]

<h2>Does it Pay Off to Learn a New Skill? Revealing the Economic Benefits of Cross-Skilling. (arXiv:2010.11841v2 [econ.GN] UPDATED)</h2>
<h3>Fabian Stephany</h3>
<p>This work examines the economic benefits of learning a new skill from a
different domain: cross-skilling. To assess this, a network of skills from the
job profiles of 4,810 online freelancers is constructed. Based on this skill
network, relationships between 3,525 different skills are revealed and marginal
effects of learning a new skill can be calculated via workers' wages. The
results indicate that the added economic value of learning a new skill strongly
depends on the already existing skill bundle but that acquiring a skill from a
different domain is often beneficial. Likewise, the data illustrate how to
reveal valuable skills required for new and opaque technology domains, such as
Artificial Intelligence. As technological and social transformation is
reshuffling jobs' task profiles at a fast pace, the findings of this study help
to clarify skill sets required for mastering new technologies and designing
individual training pathways. This can help to increase employability and
reduce labour market shortages.
</p>
<a href="http://arxiv.org/abs/2010.11841" target="_blank">arXiv:2010.11841</a> [<a href="http://arxiv.org/pdf/2010.11841" target="_blank">pdf</a>]

<h2>Neural Audio Fingerprint for High-specific Audio Retrieval based on Contrastive Learning. (arXiv:2010.11910v3 [cs.SD] UPDATED)</h2>
<h3>Sungkyun Chang, Donmoon Lee, Jeongsoo Park, Hyungui Lim, Kyogu Lee, Karam Ko, Yoonchang Han</h3>
<p>Most of existing audio fingerprinting systems have limitations to be used for
high-specific audio retrieval at scale. In this work, we generate a
low-dimensional representation from a short unit segment of audio, and couple
this fingerprint with a fast maximum inner-product search. To this end, we
present a contrastive learning framework that derives from the segment-level
search objective. Each update in training uses a batch consisting of a set of
pseudo labels, randomly selected original samples, and their augmented
replicas. These replicas can simulate the degrading effects on original audio
signals by applying small time offsets and various types of distortions, such
as background noise and room/microphone impulse responses. In the segment-level
search task, where the conventional audio fingerprinting systems used to fail,
our system using 10x smaller storage has shown promising results. Our code and
dataset will be available.
</p>
<a href="http://arxiv.org/abs/2010.11910" target="_blank">arXiv:2010.11910</a> [<a href="http://arxiv.org/pdf/2010.11910" target="_blank">pdf</a>]

<h2>Beyond the Deep Metric Learning: Enhance the Cross-Modal Matching with Adversarial Discriminative Domain Regularization. (arXiv:2010.12126v2 [cs.CV] UPDATED)</h2>
<h3>Li Ren, Kai Li, LiQiang Wang, Kien Hua</h3>
<p>Matching information across image and text modalities is a fundamental
challenge for many applications that involve both vision and natural language
processing. The objective is to find efficient similarity metrics to compare
the similarity between visual and textual information. Existing approaches
mainly match the local visual objects and the sentence words in a shared space
with attention mechanisms. The matching performance is still limited because
the similarity computation is based on simple comparisons of the matching
features, ignoring the characteristics of their distribution in the data. In
this paper, we address this limitation with an efficient learning objective
that considers the discriminative feature distributions between the visual
objects and sentence words. Specifically, we propose a novel Adversarial
Discriminative Domain Regularization (ADDR) learning framework, beyond the
paradigm metric learning objective, to construct a set of discriminative data
domains within each image-text pairs. Our approach can generally improve the
learning efficiency and the performance of existing metrics learning frameworks
by regulating the distribution of the hidden space between the matching pairs.
The experimental results show that this new approach significantly improves the
overall performance of several popular cross-modal matching techniques (SCAN,
VSRN, BFAN) on the MS-COCO and Flickr30K benchmarks.
</p>
<a href="http://arxiv.org/abs/2010.12126" target="_blank">arXiv:2010.12126</a> [<a href="http://arxiv.org/pdf/2010.12126" target="_blank">pdf</a>]

<h2>Unclicked User Behaviors Enhanced Sequential Recommendation. (arXiv:2010.12837v2 [cs.IR] UPDATED)</h2>
<h3>Fuyu Lv, Mengxue Li, Tonglei Guo, Changlong Yu, Fei Sun, Taiwei Jin, Keping Yang</h3>
<p>Deep learning-based sequential recommender systems have recently attracted
increasing attention from both academia and industry. Among them, how to
comprehensively capture sequential user interest is a fundamental problem.
However, most existing sequential recommendation models take as input clicked
or purchased behavior sequences from user-item interactions. This leads to
incomprehensive user representation and sub-optimal model performance, since
they ignore the complete user behavior exposure data, i.e., impressed yet
unclicked items. In this work, we attempt to incorporate and model those
unclicked item sequences using a new learning approach in order to explore
better sequential recommendation technique. An efficient triplet metric
learning algorithm is proposed to appropriately learn the representation of
unclicked items. Our method can be simply integrated with existing sequential
recommendation models by a confidence fusion network and further gain better
user representation. We name our algorithm SRU2B (short for Sequential
Recommendation with Unclicked User Behaviors). The experimental results based
on real-world E-commerce data demonstrate the effectiveness of SRU2B and verify
the importance of unclicked items in sequential recommendation.
</p>
<a href="http://arxiv.org/abs/2010.12837" target="_blank">arXiv:2010.12837</a> [<a href="http://arxiv.org/pdf/2010.12837" target="_blank">pdf</a>]

<h2>Adaptive In-network Collaborative Caching for Enhanced Ensemble Deep Learning at Edge. (arXiv:2010.12899v2 [cs.NI] UPDATED)</h2>
<h3>Yana Qin, Danye Wu, Zhiwei Xu, Jie Tian, Yujun Zhang</h3>
<p>To enhance the quality and speed of data processing and protect the privacy
and security of the data, edge computing has been extensively applied to
support data-intensive intelligent processing services at edge. Among these
data-intensive services, ensemble learning-based services can in natural
leverage the distributed computation and storage resources at edge devices to
achieve efficient data collection, processing, analysis.

Collaborative caching has been applied in edge computing to support services
close to the data source, in order to take the limited resources at edge
devices to support high-performance ensemble learning solutions. To achieve
this goal, we propose an adaptive in-network collaborative caching scheme for
ensemble learning at edge. First, an efficient data representation structure is
proposed to record cached data among different nodes. In addition, we design a
collaboration scheme to facilitate edge nodes to cache valuable data for local
ensemble learning, by scheduling local caching according to a summarization of
data representations from different edge nodes. Our extensive simulations
demonstrate the high performance of the proposed collaborative caching scheme,
which significantly reduces the learning latency and the transmission overhead.
</p>
<a href="http://arxiv.org/abs/2010.12899" target="_blank">arXiv:2010.12899</a> [<a href="http://arxiv.org/pdf/2010.12899" target="_blank">pdf</a>]

<h2>An Improved Event-Independent Network for Polyphonic Sound Event Localization and Detection. (arXiv:2010.13092v2 [cs.SD] UPDATED)</h2>
<h3>Yin Cao, Turab Iqbal, Qiuqiang Kong, Fengyan An, Wenwu Wang, Mark D. Plumbley</h3>
<p>Polyphonic sound event localization and detection (SELD), which jointly
performs sound event detection (SED) and direction-of-arrival (DoA) estimation,
has better real-world applicability than separate SED or DoA estimation. It
detects the type and occurrence time of sound events as well as their
corresponding DoA angles simultaneously. We study the SELD task from a
multi-task learning perspective. Two open problems are addressed in the paper.
Firstly, to detect overlapping sound events of the same type but with different
DoAs, we propose to use a trackwise output format and solve the accompanying
track permutation problem with permutation-invariant training. Multi-head
self-attention is further used to separate tracks. Secondly, a previous finding
is that, by using hard parameter-sharing, SELD suffers from a performance loss
compared with learning the subtasks separately. This is solved by a soft
parameter-sharing scheme. We term the proposed method as Event Independent
Network V2 (EINV2), which is an improved version of our previously-proposed
method and an end-to-end network for SELD. We show that our proposed EINV2 for
joint SED and DoA estimation outperforms previous methods by a large margin. In
addition, a single EINV2 model with a VGG-style architecture has comparable
performance to state-of-the-art ensemble models. Source code is available.
</p>
<a href="http://arxiv.org/abs/2010.13092" target="_blank">arXiv:2010.13092</a> [<a href="http://arxiv.org/pdf/2010.13092" target="_blank">pdf</a>]

<h2>Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce Model. (arXiv:2010.13118v2 [cs.CV] UPDATED)</h2>
<h3>Julian Lienen, Eyke H&#xfc;llermeier</h3>
<p>In many real-world applications, the relative depth of objects in an image is
crucial for scene understanding, e.g., to calculate occlusions in augmented
reality scenes. Predicting depth in monocular images has recently been tackled
using machine learning methods, mainly by treating the problem as a regression
task. Yet, being interested in an order relation in the first place, ranking
methods suggest themselves as a natural alternative to regression, and indeed,
ranking approaches leveraging pairwise comparisons as training information
("object A is closer to the camera than B") have shown promising performance on
this problem. In this paper, we elaborate on the use of so-called listwise
ranking as a generalization of the pairwise approach. Listwise ranking goes
beyond pairwise comparisons between objects and considers rankings of arbitrary
length as training information. Our approach is based on the Plackett-Luce
model, a probability distribution on rankings, which we combine with a
state-of-the-art neural network architecture and a sampling strategy to reduce
training complexity. An empirical evaluation on benchmark data in a "zero-shot"
setting demonstrates the effectiveness of our proposal compared to existing
ranking and regression methods.
</p>
<a href="http://arxiv.org/abs/2010.13118" target="_blank">arXiv:2010.13118</a> [<a href="http://arxiv.org/pdf/2010.13118" target="_blank">pdf</a>]

<h2>High Acceleration Reinforcement Learning for Real-World Juggling with Binary Rewards. (arXiv:2010.13483v2 [cs.RO] UPDATED)</h2>
<h3>Kai Ploeger, Michael Lutter, Jan Peters</h3>
<p>Robots that can learn in the physical world will be important to en-able
robots to escape their stiff and pre-programmed movements. For dynamic
high-acceleration tasks, such as juggling, learning in the real-world is
particularly challenging as one must push the limits of the robot and its
actuation without harming the system, amplifying the necessity of sample
efficiency and safety for robot learning algorithms. In contrast to prior work
which mainly focuses on the learning algorithm, we propose a learning system,
that directly incorporates these requirements in the design of the policy
representation, initialization, and optimization. We demonstrate that this
system enables the high-speed Barrett WAM manipulator to learn juggling two
balls from 56 minutes of experience with a binary reward signal. The final
policy juggles continuously for up to 33 minutes or about 4500 repeated
catches. The videos documenting the learning process and the evaluation can be
found at https://sites.google.com/view/jugglingbot
</p>
<a href="http://arxiv.org/abs/2010.13483" target="_blank">arXiv:2010.13483</a> [<a href="http://arxiv.org/pdf/2010.13483" target="_blank">pdf</a>]

<h2>Enforcing Interpretability and its Statistical Impacts: Trade-offs between Accuracy and Interpretability. (arXiv:2010.13764v2 [cs.LG] UPDATED)</h2>
<h3>Gintare Karolina Dziugaite, Shai Ben-David, Daniel M. Roy</h3>
<p>To date, there has been no formal study of the statistical cost of
interpretability in machine learning. As such, the discourse around potential
trade-offs is often informal and misconceptions abound. In this work, we aim to
initiate a formal study of these trade-offs. A seemingly insurmountable
roadblock is the lack of any agreed upon definition of interpretability.
Instead, we propose a shift in perspective. Rather than attempt to define
interpretability, we propose to model the \emph{act} of \emph{enforcing}
interpretability. As a starting point, we focus on the setting of empirical
risk minimization for binary classification, and view interpretability as a
constraint placed on learning. That is, we assume we are given a subset of
hypothesis that are deemed to be interpretable, possibly depending on the data
distribution and other aspects of the context. We then model the act of
enforcing interpretability as that of performing empirical risk minimization
over the set of interpretable hypotheses. This model allows us to reason about
the statistical implications of enforcing interpretability, using known results
in statistical learning theory. Focusing on accuracy, we perform a case
analysis, explaining why one may or may not observe a trade-off between
accuracy and interpretability when the restriction to interpretable classifiers
does or does not come at the cost of some excess statistical risk. We close
with some worked examples and some open problems, which we hope will spur
further theoretical development around the tradeoffs involved in
interpretability.
</p>
<a href="http://arxiv.org/abs/2010.13764" target="_blank">arXiv:2010.13764</a> [<a href="http://arxiv.org/pdf/2010.13764" target="_blank">pdf</a>]

<h2>Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive Patterns in Vowel Acoustics. (arXiv:1701.06078v2 [cs.SD] CROSS LISTED)</h2>
<h3>Sungkyun Chang, Kyogu Lee</h3>
<p>Most of the previous approaches to lyrics-to-audio alignment used a
pre-developed automatic speech recognition (ASR) system that innately suffered
from several difficulties to adapt the speech model to individual singers. A
significant aspect missing in previous works is the self-learnability of
repetitive vowel patterns in the singing voice, where the vowel part used is
more consistent than the consonant part. Based on this, our system first learns
a discriminative subspace of vowel sequences, based on weighted symmetric
non-negative matrix factorization (WS-NMF), by taking the self-similarity of a
standard acoustic feature as an input. Then, we make use of canonical time
warping (CTW), derived from a recent computer vision technique, to find an
optimal spatiotemporal transformation between the text and the acoustic
sequences. Experiments with Korean and English data sets showed that deploying
this method after a pre-developed, unsupervised, singing source separation
achieved more promising results than other state-of-the-art unsupervised
approaches and an existing ASR-based system.
</p>
<a href="http://arxiv.org/abs/1701.06078" target="_blank">arXiv:1701.06078</a> [<a href="http://arxiv.org/pdf/1701.06078" target="_blank">pdf</a>]

<h2>Audio Cover Song Identification using Convolutional Neural Network. (arXiv:1712.00166v2 [cs.SD] CROSS LISTED)</h2>
<h3>Sungkyun Chang, Juheon Lee, Sang Keun Choe, Kyogu Lee</h3>
<p>In this paper, we propose a new approach to cover song identification using a
CNN (convolutional neural network). Most previous studies extract the feature
vectors that characterize the cover song relation from a pair of songs and used
it to compute the (dis)similarity between the two songs. Based on the
observation that there is a meaningful pattern between cover songs and that
this can be learned, we have reformulated the cover song identification problem
in a machine learning framework. To do this, we first build the CNN using as an
input a cross-similarity matrix generated from a pair of songs. We then
construct the data set composed of cover song pairs and non-cover song pairs,
which are used as positive and negative training samples, respectively. The
trained CNN outputs the probability of being in the cover song relation given a
cross-similarity matrix generated from any two pieces of music and identifies
the cover song by ranking on the probability. Experimental results show that
the proposed algorithm achieves performance better than or comparable to the
state-of-the-art.
</p>
<a href="http://arxiv.org/abs/1712.00166" target="_blank">arXiv:1712.00166</a> [<a href="http://arxiv.org/pdf/1712.00166" target="_blank">pdf</a>]

<h2>Stock Price Prediction Using CNN and LSTM-Based Deep Learning Models. (arXiv:2010.13891v1 [q-fin.CP] CROSS LISTED)</h2>
<h3>Sidra Mehtab, Jaydip Sen</h3>
<p>Designing robust and accurate predictive models for stock price prediction
has been an active area of research for a long time. While on one side, the
supporters of the efficient market hypothesis claim that it is impossible to
forecast stock prices accurately, many researchers believe otherwise. There
exist propositions in the literature that have demonstrated that if properly
designed and optimized, predictive models can very accurately and reliably
predict future values of stock prices. This paper presents a suite of deep
learning based models for stock price prediction. We use the historical records
of the NIFTY 50 index listed in the National Stock Exchange of India, during
the period from December 29, 2008 to July 31, 2020, for training and testing
the models. Our proposition includes two regression models built on
convolutional neural networks and three long and short term memory network
based predictive models. To forecast the open values of the NIFTY 50 index
records, we adopted a multi step prediction technique with walk forward
validation. In this approach, the open values of the NIFTY 50 index are
predicted on a time horizon of one week, and once a week is over, the actual
index values are included in the training set before the model is trained
again, and the forecasts for the next week are made. We present detailed
results on the forecasting accuracies for all our proposed models. The results
show that while all the models are very accurate in forecasting the NIFTY 50
open values, the univariate encoder decoder convolutional LSTM with the
previous two weeks data as the input is the most accurate model. On the other
hand, a univariate CNN model with previous one week data as the input is found
to be the fastest model in terms of its execution speed.
</p>
<a href="http://arxiv.org/abs/2010.13891" target="_blank">arXiv:2010.13891</a> [<a href="http://arxiv.org/pdf/2010.13891" target="_blank">pdf</a>]

<h2>Improving seasonal forecast using probabilistic deep learning. (arXiv:2010.14610v1 [physics.geo-ph])</h2>
<h3>Baoxiang Pan, Gemma J. Anderson, AndrE Goncalves, Donald D. Lucas, CEline J.W. Bonfils, Jiwoo Lee</h3>
<p>The path toward realizing the potential of seasonal forecasting and its
socioeconomic benefits depends heavily on improving general circulation model
based dynamical forecasting systems. To improve dynamical seasonal forecast, it
is crucial to set up forecast benchmarks, and clarify forecast limitations
posed by model initialization errors, formulation deficiencies, and internal
climate variability. With huge cost in generating large forecast ensembles, and
limited observations for forecast verification, the seasonal forecast
benchmarking and diagnosing task proves challenging. In this study, we develop
a probabilistic deep neural network model, drawing on a wealth of existing
climate simulations to enhance seasonal forecast capability and forecast
diagnosis. By leveraging complex physical relationships encoded in climate
simulations, our probabilistic forecast model demonstrates favorable
deterministic and probabilistic skill compared to state-of-the-art dynamical
forecast systems in quasi-global seasonal forecast of precipitation and
near-surface temperature. We apply this probabilistic forecast methodology to
quantify the impacts of initialization errors and model formulation
deficiencies in a dynamical seasonal forecasting system. We introduce the
saliency analysis approach to efficiently identify the key predictors that
influence seasonal variability. Furthermore, by explicitly modeling uncertainty
using variational Bayes, we give a more definitive answer to how the El
Nino/Southern Oscillation, the dominant mode of seasonal variability, modulates
global seasonal predictability.
</p>
<a href="http://arxiv.org/abs/2010.14610" target="_blank">arXiv:2010.14610</a> [<a href="http://arxiv.org/pdf/2010.14610" target="_blank">pdf</a>]

<h2>Machine learning of solvent effects on molecular spectra and reactions. (arXiv:2010.14942v1 [physics.chem-ph])</h2>
<h3>Michael Gastegger, Kristof T. Sch&#xfc;tt, Klaus-Robert M&#xfc;ller</h3>
<p>Fast and accurate simulation of complex chemical systems in environments such
as solutions is a long standing challenge in theoretical chemistry. In recent
years, machine learning has extended the boundaries of quantum chemistry by
providing highly accurate and efficient surrogate models of electronic
structure theory, which previously have been out of reach for conventional
approaches. Those models have long been restricted to closed molecular systems
without accounting for environmental influences, such as external electric and
magnetic fields or solvent effects. Here, we introduce the deep neural network
FieldSchNet for modeling the interaction of molecules with arbitrary external
fields. FieldSchNet offers access to a wealth of molecular response properties,
enabling it to simulate a wide range of molecular spectra, such as infrared,
Raman and nuclear magnetic resonance. Beyond that, it is able to describe
implicit and explicit molecular environments, operating as a polarizable
continuum model for solvation or in a quantum mechanics / molecular mechanics
setup. We employ FieldSchNet to study the influence of solvent effects on
molecular spectra and a Claisen rearrangement reaction. Based on these results,
we use FieldSchNet to design an external environment capable of lowering the
activation barrier of the rearrangement reaction significantly, demonstrating
promising venues for inverse chemical design.
</p>
<a href="http://arxiv.org/abs/2010.14942" target="_blank">arXiv:2010.14942</a> [<a href="http://arxiv.org/pdf/2010.14942" target="_blank">pdf</a>]

<h2>Automatic selection of eye tracking variables in visual categorization in adults and infants. (arXiv:2010.15047v1 [q-bio.QM])</h2>
<h3>Samuel Rivera, Catherine A. Best, Hyungwook Yim, Dirk B. Walther, Vladimir M. Sloutsky, Aleix M. Martinez</h3>
<p>Visual categorization and learning of visual categories exhibit early onset,
however the underlying mechanisms of early categorization are not well
understood. The main limiting factor for examining these mechanisms is the
limited duration of infant cooperation (10-15 minutes), which leaves little
room for multiple test trials. With its tight link to visual attention, eye
tracking is a promising method for getting access to the mechanisms of category
learning. But how should researchers decide which aspects of the rich eye
tracking data to focus on? To date, eye tracking variables are generally
handpicked, which may lead to biases in the eye tracking data. Here, we propose
an automated method for selecting eye tracking variables based on analyses of
their usefulness to discriminate learners from non-learners of visual
categories. We presented infants and adults with a category learning task and
tracked their eye movements. We then extracted an over-complete set of eye
tracking variables encompassing durations, probabilities, latencies, and the
order of fixations and saccadic eye movements. We compared three statistical
techniques for identifying those variables among this large set that are useful
for discriminating learners form non-learners: ANOVA ranking, Bayes ranking,
and L1 regularized logistic regression. We found remarkable agreement between
these methods in identifying a small set of discriminant variables. Moreover,
the same eye tracking variables allow us to classify category learners from
non-learners among adults and 6- to 8-month-old infants with accuracies above
71%.
</p>
<a href="http://arxiv.org/abs/2010.15047" target="_blank">arXiv:2010.15047</a> [<a href="http://arxiv.org/pdf/2010.15047" target="_blank">pdf</a>]

<h2>Jet Flavour Classification Using DeepJet. (arXiv:2008.10519v2 [hep-ex] UPDATED)</h2>
<h3>Emil Bols, Jan Kieseler, Mauro Verzetti, Markus Stoye, Anna Stakia</h3>
<p>Jet flavour classification is of paramount importance for a broad range of
applications in modern-day high-energy-physics experiments, particularly at the
LHC. In this paper we propose a novel architecture for this task that exploits
modern deep learning techniques. This new model, called DeepJet, overcomes the
limitations in input size that affected previous approaches. As a result, the
heavy flavour classification performance improves, and the model is extended to
also perform quark-gluon tagging.
</p>
<a href="http://arxiv.org/abs/2008.10519" target="_blank">arXiv:2008.10519</a> [<a href="http://arxiv.org/pdf/2008.10519" target="_blank">pdf</a>]

