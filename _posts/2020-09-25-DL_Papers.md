---
title: Latest Deep Learning Papers
date: 2020-12-21 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (300 Articles)</h1>
<h2>Minimax Active Learning. (arXiv:2012.10467v1 [cs.CV])</h2>
<h3>Sayna Ebrahimi, William Gan, Kamyar Salahi, Trevor Darrell</h3>
<p>Active learning aims to develop label-efficient algorithms by querying the
most representative samples to be labeled by a human annotator. Current active
learning techniques either rely on model uncertainty to select the most
uncertain samples or use clustering or reconstruction to choose the most
diverse set of unlabeled examples. While uncertainty-based strategies are
susceptible to outliers, solely relying on sample diversity does not capture
the information available on the main task. In this work, we develop a
semi-supervised minimax entropy-based active learning algorithm that leverages
both uncertainty and diversity in an adversarial manner. Our model consists of
an entropy minimizing feature encoding network followed by an entropy
maximizing classification layer. This minimax formulation reduces the
distribution gap between the labeled/unlabeled data, while a discriminator is
simultaneously trained to distinguish the labeled/unlabeled data. The highest
entropy samples from the classifier that the discriminator predicts as
unlabeled are selected for labeling. We extensively evaluate our method on
various image classification and semantic segmentation benchmark datasets and
show superior performance over the state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.10467" target="_blank">arXiv:2012.10467</a> [<a href="http://arxiv.org/pdf/2012.10467" target="_blank">pdf</a>]

<h2>A Survey on the Visual Perceptions of Gaussian Noise Filtering on Photography. (arXiv:2012.10472v1 [cs.CV])</h2>
<h3>Aidan Draper, Laura L. Taylor</h3>
<p>Statisticians, as well as machine learning and computer vision experts, have
been studying image reconstitution through denoising different domains of
photography, such as textual documentation, tomographic, astronomical, and
low-light photography. In this paper, we apply common inferential kernel
filters in the R and python languages, as well as Adobe Lightroom's denoise
filter, and compare their effectiveness in removing noise from JPEG images. We
ran standard benchmark tests to evaluate each method's effectiveness for
removing noise. In doing so, we also surveyed students at Elon University about
their opinion of a single filtered photo from a collection of photos processed
by the various filter methods. Many scientists believe that noise filters cause
blurring and image quality loss so we analyzed whether or not people felt as
though denoising causes any quality loss as compared to their noiseless images.
Individuals assigned scores indicating the image quality of a denoised photo
compared to its noiseless counterpart on a 1 to 10 scale. Survey scores are
compared across filters to evaluate whether there were significant differences
in image quality scores received. Benchmark scores were compared to the visual
perception scores. Then, an analysis of covariance test was run to identify
whether or not survey training scores explained any unplanned variation in
visual scores assigned by students across the filter methods.
</p>
<a href="http://arxiv.org/abs/2012.10472" target="_blank">arXiv:2012.10472</a> [<a href="http://arxiv.org/pdf/2012.10472" target="_blank">pdf</a>]

<h2>State Estimation of Power Flows for Smart Grids via Belief Propagation. (arXiv:2012.10473v1 [cs.AI])</h2>
<h3>Tim Ritmeester, Hildegard Meyer-Ortmanns</h3>
<p>Belief propagation is an algorithm that is known from statistical physics and
computer science. It provides an efficient way of calculating marginals that
involve large sums of products which are efficiently rearranged into nested
products of sums to approximate the marginals. It allows a reliable estimation
of the state and its variance of power grids that is needed for the control and
forecast of power grid management. At prototypical examples of IEEE-grids we
show that belief propagation not only scales linearly with the grid size for
the state estimation itself, but also facilitates and accelerates the retrieval
of missing data and allows an optimized positioning of measurement units. Based
on belief propagation, we give a criterion for how to assess whether other
algorithms, using only local information, are adequate for state estimation for
a given grid. We also demonstrate how belief propagation can be utilized for
coarse-graining power grids towards representations that reduce the
computational effort when the coarse-grained version is integrated into a
larger grid. It provides a criterion for partitioning power grids into areas in
order to minimize the error of flow estimates between different areas.
</p>
<a href="http://arxiv.org/abs/2012.10473" target="_blank">arXiv:2012.10473</a> [<a href="http://arxiv.org/pdf/2012.10473" target="_blank">pdf</a>]

<h2>Reinforcement Learning based Multi-Robot Classification via Scalable Communication Structure. (arXiv:2012.10480v1 [cs.RO])</h2>
<h3>Guangyi Liu, Arash Amini, Martin Tak&#xe1;&#x10d;, H&#xe9;ctor Mu&#xf1;oz-Avila, Nader Motee</h3>
<p>In the multi-robot collaboration domain, training with Reinforcement Learning
(RL) can become intractable, and performance starts to deteriorate drastically
as the number of robots increases. In this work, we proposed a distributed
multi-robot learning architecture with a scalable communication structure
capable of learning a robust communication policy for time-varying
communication topology. We construct the communication structure with
Long-Short Term Memory (LSTM) cells and star graphs, in which the computational
complexity of the proposed learning algorithm scales linearly with the number
of robots and suitable for application with a large number of robots. The
proposed methodology is validated with a map classification problem in the
simulated environment. It is shown that the proposed architecture achieves a
comparable classification accuracy with the centralized methods, maintains high
performance with various numbers of robots without additional training cost,
and robust to hacking and loss of the robots in the network.
</p>
<a href="http://arxiv.org/abs/2012.10480" target="_blank">arXiv:2012.10480</a> [<a href="http://arxiv.org/pdf/2012.10480" target="_blank">pdf</a>]

<h2>RAILS: A Robust Adversarial Immune-inspired Learning System. (arXiv:2012.10485v1 [cs.LG])</h2>
<h3>Ren Wang, Tianqi Chen, Stephen Lindsly, Alnawaz Rehemtulla, Alfred Hero, Indika Rajapakse</h3>
<p>Adversarial attacks against deep neural networks are continuously evolving.
Without effective defenses, they can lead to catastrophic failure. The
long-standing and arguably most powerful natural defense system is the
mammalian immune system, which has successfully defended against attacks by
novel pathogens for millions of years. In this paper, we propose a new
adversarial defense framework, called the Robust Adversarial Immune-inspired
Learning System (RAILS). RAILS incorporates an Adaptive Immune System Emulation
(AISE), which emulates in silico the biological mechanisms that are used to
defend the host against attacks by pathogens. We use RAILS to harden Deep
k-Nearest Neighbor (DkNN) architectures against evasion attacks. Evolutionary
programming is used to simulate processes in the natural immune system: B-cell
flocking, clonal expansion, and affinity maturation. We show that the RAILS
learning curve exhibits similar diversity-selection learning phases as observed
in our in vitro biological experiments. When applied to adversarial image
classification on three different datasets, RAILS delivers an additional
5.62%/12.56%/4.74% robustness improvement as compared to applying DkNN alone,
without appreciable loss of accuracy on clean data.
</p>
<a href="http://arxiv.org/abs/2012.10485" target="_blank">arXiv:2012.10485</a> [<a href="http://arxiv.org/pdf/2012.10485" target="_blank">pdf</a>]

<h2>XAI4Wind: A Multimodal Knowledge Graph Database for Explainable Decision Support in Operations & Maintenance of Wind Turbines. (arXiv:2012.10489v1 [cs.AI])</h2>
<h3>Joyjit Chatterjee, Nina Dethlefs</h3>
<p>Condition-based monitoring (CBM) has been widely utilised in the wind
industry for monitoring operational inconsistencies and failures in turbines,
with techniques ranging from signal processing and vibration analysis to
artificial intelligence (AI) models using Supervisory Control &amp; Acquisition
(SCADA) data. However, existing studies do not present a concrete basis to
facilitate explainable decision support in operations and maintenance (O&amp;M),
particularly for automated decision support through recommendation of
appropriate maintenance action reports corresponding to failures predicted by
CBM techniques. Knowledge graph databases (KGs) model a collection of
domain-specific information and have played an intrinsic role for real-world
decision support in domains such as healthcare and finance, but have seen very
limited attention in the wind industry. We propose XAI4Wind, a multimodal
knowledge graph for explainable decision support in real-world operational
turbines and demonstrate through experiments several use-cases of the proposed
KG towards O&amp;M planning through interactive query and reasoning and providing
novel insights using graph data science algorithms. The proposed KG combines
multimodal knowledge like SCADA parameters and alarms with natural language
maintenance actions, images etc. By integrating our KG with an Explainable AI
model for anomaly prediction, we show that it can provide effective
human-intelligible O&amp;M strategies for predicted operational inconsistencies in
various turbine sub-components. This can help instil better trust and
confidence in conventionally black-box AI models. We make our KG publicly
available and envisage that it can serve as the building ground for providing
autonomous decision support in the wind industry.
</p>
<a href="http://arxiv.org/abs/2012.10489" target="_blank">arXiv:2012.10489</a> [<a href="http://arxiv.org/pdf/2012.10489" target="_blank">pdf</a>]

<h2>Sensor-Based Temporal Logic Planning in Uncertain Semantic Maps. (arXiv:2012.10490v1 [cs.RO])</h2>
<h3>Yiannis Kantaros, Qi Jin, George J. Pappas</h3>
<p>This paper addresses a multi-robot mission planning problem in uncertain
semantic environments. The environment is modeled by static labeled landmarks
with uncertain positions and classes giving rise to an uncertain semantic map
generated by semantic SLAM algorithms. Our goal is to design control policies
for sensing robots so that they can accomplish complex collaborative high level
tasks captured by global temporal logic specifications. To account for
environmental and sensing uncertainty, we extend Linear Temporal Logic (LTL) by
including sensor-based predicates allowing us to incorporate uncertainty and
probabilistic satisfaction requirements directly into the task specification.
The sensor-based LTL planning problem gives rise to an optimal control problem,
solved by a novel sampling-based algorithm, that generates open-loop control
policies that can be updated online to adapt to the map that is continuously
learned by existing semantic SLAM methods. We provide extensive experiments
that corroborate the theoretical analysis and show that the proposed algorithm
can address large-scale planning tasks in the presence of uncertainty.
</p>
<a href="http://arxiv.org/abs/2012.10490" target="_blank">arXiv:2012.10490</a> [<a href="http://arxiv.org/pdf/2012.10490" target="_blank">pdf</a>]

<h2>ShineOn: Illuminating Design Choices for Practical Video-based Virtual Clothing Try-on. (arXiv:2012.10495v1 [cs.CV])</h2>
<h3>Gaurav Kuppa, Andrew Jong, Vera Liu, Ziwei Liu, Teng Moh</h3>
<p>Virtual try-on has garnered interest as a neural rendering benchmark task to
evaluate complex object transfer and scene composition. Recent works in virtual
clothing try-on feature a plethora of possible architectural and data
representation choices. However, they present little clarity on quantifying the
isolated visual effect of each choice, nor do they specify the hyperparameter
details that are key to experimental reproduction. Our work, ShineOn,
approaches the try-on task from a bottom-up approach and aims to shine light on
the visual and quantitative effects of each experiment. We build a series of
scientific experiments to isolate effective design choices in video synthesis
for virtual clothing try-on. Specifically, we investigate the effect of
different pose annotations, self-attention layer placement, and activation
functions on the quantitative and qualitative performance of video virtual
try-on. We find that DensePose annotations not only enhance face details but
also decrease memory usage and training time. Next, we find that attention
layers improve face and neck quality. Finally, we show that GELU and ReLU
activation functions are the most effective in our experiments despite the
appeal of newer activations such as Swish and Sine. We will release a
well-organized code base, hyperparameters, and model checkpoints to support the
reproducibility of our results. We expect our extensive experiments and code to
greatly inform future design choices in video virtual try-on. Our code may be
accessed at https://github.com/andrewjong/ShineOn-Virtual-Tryon.
</p>
<a href="http://arxiv.org/abs/2012.10495" target="_blank">arXiv:2012.10495</a> [<a href="http://arxiv.org/pdf/2012.10495" target="_blank">pdf</a>]

<h2>Simulation Environment for Safety Assessment of CEAV Deployment in Linden. (arXiv:2012.10498v1 [cs.RO])</h2>
<h3>Levent Guvenc, Bilin Aksun-Guvenc, Xinchen Li, Aravind Chandradoss Arul Doss, Karina Meneses-Cime, Sukru Yaren Gelbal</h3>
<p>This report presents a simulation environment for pre-deployment testing of
the autonomous shuttles that will operate in the Linden Residential Area. An
autonomous shuttle deployment was already successfully launched and operated in
the city of Columbus and ended recently. This report focuses on the second
autonomous shuttle deployment planned to start in December, 2019, using a route
that will help to solve first-mile / last-mile mobility challenges in the
Linden neighborhood of Columbus by providing free rides between St. Stephens
Community House, Douglas Community Recreation Center, Rosewind Resident Council
and Linden Transit Center. This document presents simulation testing
environments in two open source simulators and a commercial simulator for this
residential area route and how they can be used for model-in-the-loop and
hardware-in-the-loop simulation testing of autonomous shuttle operation before
the actual deployment.
</p>
<a href="http://arxiv.org/abs/2012.10498" target="_blank">arXiv:2012.10498</a> [<a href="http://arxiv.org/pdf/2012.10498" target="_blank">pdf</a>]

<h2>CityLearn: Standardizing Research in Multi-Agent Reinforcement Learning for Demand Response and Urban Energy Management. (arXiv:2012.10504v1 [cs.LG])</h2>
<h3>Jose R Vazquez-Canteli, Sourav Dey, Gregor Henze, Zoltan Nagy</h3>
<p>Rapid urbanization, increasing integration of distributed renewable energy
resources, energy storage, and electric vehicles introduce new challenges for
the power grid. In the US, buildings represent about 70% of the total
electricity demand and demand response has the potential for reducing peaks of
electricity by about 20%. Unlocking this potential requires control systems
that operate on distributed systems, ideally data-driven and model-free. For
this, reinforcement learning (RL) algorithms have gained increased interest in
the past years. However, research in RL for demand response has been lacking
the level of standardization that propelled the enormous progress in RL
research in the computer science community. To remedy this, we created
CityLearn, an OpenAI Gym Environment which allows researchers to implement,
share, replicate, and compare their implementations of RL for demand response.
Here, we discuss this environment and The CityLearn Challenge, a RL competition
we organized to propel further progress in this field.
</p>
<a href="http://arxiv.org/abs/2012.10504" target="_blank">arXiv:2012.10504</a> [<a href="http://arxiv.org/pdf/2012.10504" target="_blank">pdf</a>]

<h2>Territory Design for Dynamic Multi-Period Vehicle Routing Problem with Time Windows. (arXiv:2012.10506v1 [cs.AI])</h2>
<h3>Hern&#xe1;n Lespay, Karol Suchan</h3>
<p>This study introduces the Territory Design for Dynamic Multi-Period Vehicle
Routing Problem with Time Windows (TD-DMPVRPTW), motivated by a real-world
application at a food company's distribution center. This problem deals with
the design of contiguous and compact territories for delivery of orders from a
depot to a set of customers, with time windows, over a multi-period planning
horizon. Customers and their demands vary dynamically over time. The problem is
modeled as a mixed-integer linear program (MILP) and solved by a proposed
heuristic. The heuristic solutions are compared with the proposed MILP
solutions on a set of small artificial instances and the food company's
solutions on a set of real-world instances. Computational results show that the
proposed algorithm can yield high-quality solutions within moderate running
times.
</p>
<a href="http://arxiv.org/abs/2012.10506" target="_blank">arXiv:2012.10506</a> [<a href="http://arxiv.org/pdf/2012.10506" target="_blank">pdf</a>]

<h2>Computer Vision based Tomography of Structures Using 3D Digital Image Correlation. (arXiv:2012.10516v1 [cs.CV])</h2>
<h3>Mehrdad Shafiei Dizaji, Devin Harris</h3>
<p>Internal properties of a sample can be observed by medical imaging tools,
such as ultrasound devices, magnetic resonance imaging (MRI) and optical
coherence tomography (OCT) which are based on relying on changes in material
density or chemical composition [1-21]. As a preliminary investigation, the
feasibility to detect interior defects inferred from the discrepancy in
elasticity modulus distribution of a three-dimensional heterogeneous sample
using only surface full-field measurements and finite element model updating as
an inverse optimization algorithm without any assumption about local
homogeneities and also the elasticity modulus distribution is investigated.
Recently, the authors took advantages of the digital image correlation
technique as a full field measurement in constitutive property identification
of a full-scale steel component [22-27]. To the extension of previous works, in
this brief technical note, the new idea intended at recovering unseen
volumetric defect distributions within the interior of three-dimensional
heterogeneous space of the structural component using 3D-Digital Image
Correlation for structural identification [28-57]. As a proof of concept, the
results of this paper illustrate the potential to identify invisible internal
defect by the proposed computer vision technique establishes the potential for
new opportunities to characterize internal heterogeneous materials for their
mechanical property distribution and condition state.
</p>
<a href="http://arxiv.org/abs/2012.10516" target="_blank">arXiv:2012.10516</a> [<a href="http://arxiv.org/pdf/2012.10516" target="_blank">pdf</a>]

<h2>Machine learning applications using diffusion tensor imaging of human brain: A PubMed literature review. (arXiv:2012.10517v1 [cs.LG])</h2>
<h3>Ashirbani Saha, Pantea Fadaiefard, Jessica E. Rabski, Alireza Sadeghian, Michael D. Cusimano</h3>
<p>We performed a PubMed search to find 148 papers published between January
2010 and December 2019 related to human brain, Diffusion Tensor Imaging (DTI),
and Machine Learning (ML). The studies focused on healthy cohorts (n = 15),
mental health disorders (n = 25), tumor (n = 19), trauma (n = 5), dementia (n =
24), developmental disorders (n = 5), movement disorders (n = 9), other
neurological disorders (n = 27), miscellaneous non-neurological disorders, or
without stating the disease of focus (n = 7), and multiple combinations of the
aforementioned categories (n = 12). Classification of patients using
information from DTI stands out to be the most commonly (n = 114) performed ML
application. A significant number (n = 93) of studies used support vector
machines (SVM) as the preferred choice of ML model for classification. A
significant portion (31/44) of publications in the recent years (2018-2019)
continued to use SVM, support vector regression, and random forest which are a
part of traditional ML. Though many types of applications across various health
conditions (including healthy) were conducted, majority of the studies were
based on small cohorts (less than 100) and did not conduct independent/external
validation on test sets.
</p>
<a href="http://arxiv.org/abs/2012.10517" target="_blank">arXiv:2012.10517</a> [<a href="http://arxiv.org/pdf/2012.10517" target="_blank">pdf</a>]

<h2>Human 3D keypoints via spatial uncertainty modeling. (arXiv:2012.10518v1 [cs.CV])</h2>
<h3>Francis Williams, Or Litany, Avneesh Sud, Kevin Swersky, Andrea Tagliasacchi</h3>
<p>We introduce a technique for 3D human keypoint estimation that directly
models the notion of spatial uncertainty of a keypoint. Our technique employs a
principled approach to modelling spatial uncertainty inspired from techniques
in robust statistics. Furthermore, our pipeline requires no 3D ground truth
labels, relying instead on (possibly noisy) 2D image-level keypoints. Our
method achieves near state-of-the-art performance on Human3.6m while being
efficient to evaluate and straightforward to
</p>
<a href="http://arxiv.org/abs/2012.10518" target="_blank">arXiv:2012.10518</a> [<a href="http://arxiv.org/pdf/2012.10518" target="_blank">pdf</a>]

<h2>Dynamic Traffic Modeling From Overhead Imagery. (arXiv:2012.10530v1 [cs.CV])</h2>
<h3>Scott Workman, Nathan Jacobs</h3>
<p>Our goal is to use overhead imagery to understand patterns in traffic flow,
for instance answering questions such as how fast could you traverse Times
Square at 3am on a Sunday. A traditional approach for solving this problem
would be to model the speed of each road segment as a function of time.
However, this strategy is limited in that a significant amount of data must
first be collected before a model can be used and it fails to generalize to new
areas. Instead, we propose an automatic approach for generating dynamic maps of
traffic speeds using convolutional neural networks. Our method operates on
overhead imagery, is conditioned on location and time, and outputs a local
motion model that captures likely directions of travel and corresponding travel
speeds. To train our model, we take advantage of historical traffic data
collected from New York City. Experimental results demonstrate that our method
can be applied to generate accurate city-scale traffic models.
</p>
<a href="http://arxiv.org/abs/2012.10530" target="_blank">arXiv:2012.10530</a> [<a href="http://arxiv.org/pdf/2012.10530" target="_blank">pdf</a>]

<h2>A Graph Attention Based Approach for Trajectory Prediction in Multi-agent Sports Games. (arXiv:2012.10531v1 [cs.LG])</h2>
<h3>Ding Ding, H. Howie Huang</h3>
<p>This work investigates the problem of multi-agents trajectory prediction.
Prior approaches lack of capability of capturing fine-grained dependencies
among coordinated agents. In this paper, we propose a spatial-temporal
trajectory prediction approach that is able to learn the strategy of a team
with multiple coordinated agents. In particular, we use graph-based attention
model to learn the dependency of the agents. In addition, instead of utilizing
the recurrent networks (e.g., VRNN, LSTM), our method uses a Temporal
Convolutional Network (TCN) as the sequential model to support long effective
history and provide important features such as parallelism and stable
gradients. We demonstrate the validation and effectiveness of our approach on
two different sports game datasets: basketball and soccer datasets. The result
shows that compared to related approaches, our model that infers the dependency
of players yields substantially improved performance. Code is available at
https://github.com/iHeartGraph/predict
</p>
<a href="http://arxiv.org/abs/2012.10531" target="_blank">arXiv:2012.10531</a> [<a href="http://arxiv.org/pdf/2012.10531" target="_blank">pdf</a>]

<h2>Biomedical Knowledge Graph Refinement and Completion using Graph Representation Learning and Top-K Similarity Measure. (arXiv:2012.10540v1 [cs.LG])</h2>
<h3>Islam Akef Ebeid, Majdi Hassan, Tingyi Wanyan, Jack Roper, Abhik Seal, Ying Ding</h3>
<p>Knowledge Graphs have been one of the fundamental methods for integrating
heterogeneous data sources. Integrating heterogeneous data sources is crucial,
especially in the biomedical domain, where central data-driven tasks such as
drug discovery rely on incorporating information from different biomedical
databases. These databases contain various biological entities and relations
such as proteins (PDB), genes (Gene Ontology), drugs (DrugBank), diseases
(DDB), and protein-protein interactions (BioGRID). The process of semantically
integrating heterogeneous biomedical databases is often riddled with
imperfections. The quality of data-driven drug discovery relies on the accuracy
of the mining methods used and the data's quality as well. Thus, having
complete and refined biomedical knowledge graphs is central to achieving more
accurate drug discovery outcomes. Here we propose using the latest graph
representation learning and embedding models to refine and complete biomedical
knowledge graphs. This preliminary work demonstrates learning discrete
representations of the integrated biomedical knowledge graph Chem2Bio2RD [3].
We perform a knowledge graph completion and refinement task using a simple
top-K cosine similarity measure between the learned embedding vectors to
predict missing links between drugs and targets present in the data. We show
that this simple procedure can be used alternatively to binary classifiers in
link prediction.
</p>
<a href="http://arxiv.org/abs/2012.10540" target="_blank">arXiv:2012.10540</a> [<a href="http://arxiv.org/pdf/2012.10540" target="_blank">pdf</a>]

<h2>Data Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses. (arXiv:2012.10544v1 [cs.LG])</h2>
<h3>Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein</h3>
<p>As machine learning systems consume more and more data, practitioners are
increasingly forced to automate and outsource the curation of training data in
order to meet their data demands. This absence of human supervision over the
data collection process exposes organizations to security vulnerabilities:
malicious agents can insert poisoned examples into the training set to exploit
the machine learning systems that are trained on it. Motivated by the emergence
of this paradigm, there has been a surge in work on data poisoning including a
variety of threat models as well as attack and defense methods. The goal of
this work is to systematically categorize and discuss a wide range of data
poisoning and backdoor attacks, approaches to defending against these threats,
and an array of open problems in this space. In addition to describing these
methods and the relationships among them in detail, we develop their unified
taxonomy.
</p>
<a href="http://arxiv.org/abs/2012.10544" target="_blank">arXiv:2012.10544</a> [<a href="http://arxiv.org/pdf/2012.10544" target="_blank">pdf</a>]

<h2>A 3D GAN for Improved Large-pose Facial Recognition. (arXiv:2012.10545v1 [cs.CV])</h2>
<h3>Richard T. Marriott, Sami Romdhani, Liming Chen</h3>
<p>Facial recognition using deep convolutional neural networks relies on the
availability of large datasets of face images. Many examples of identities are
needed, and for each identity, a large variety of images are needed in order
for the network to learn robustness to intra-class variation. In practice, such
datasets are difficult to obtain, particularly those containing adequate
variation of pose. Generative Adversarial Networks (GANs) provide a potential
solution to this problem due to their ability to generate realistic, synthetic
images. However, recent studies have shown that current methods of
disentangling pose from identity are inadequate. In this work we incorporate a
3D morphable model into the generator of a GAN in order to learn a nonlinear
texture model from in-the-wild images. This allows generation of new, synthetic
identities, and manipulation of pose and expression without compromising the
identity. Our synthesised data is used to augment training of facial
recognition networks with performance evaluated on the challenging CFPW and
Cross-Pose LFW datasets.
</p>
<a href="http://arxiv.org/abs/2012.10545" target="_blank">arXiv:2012.10545</a> [<a href="http://arxiv.org/pdf/2012.10545" target="_blank">pdf</a>]

<h2>NN-EMD: Efficiently Training Neural Networks using Encrypted Multi-sourced Datasets. (arXiv:2012.10547v1 [cs.LG])</h2>
<h3>Runhua Xu, James Joshi, Chao Li</h3>
<p>Training a machine learning model over an encrypted dataset is an existing
promising approach to address the privacy-preserving machine learning task,
however, it is extremely challenging to efficiently train a deep neural network
(DNN) model over encrypted data for two reasons: first, it requires large-scale
computation over huge datasets; second, the existing solutions for computation
over encrypted data, such as homomorphic encryption, is inefficient. Further,
for an enhanced performance of a DNN model, we also need to use huge training
datasets composed of data from multiple data sources that may not have
pre-established trust relationships among each other. We propose a novel
framework, NN-EMD, to train DNN over multiple encrypted datasets collected from
multiple sources. Toward this, we propose a set of secure computation protocols
using hybrid functional encryption schemes. We evaluate our framework for
performance with regards to the training time and model accuracy on the MNIST
datasets. Compared to other existing frameworks, our proposed NN-EMD framework
can significantly reduce the training time, while providing comparable model
accuracy and privacy guarantees as well as supporting multiple data sources.
Furthermore, the depth and complexity of neural networks do not affect the
training time despite introducing a privacy-preserving NN-EMD setting.
</p>
<a href="http://arxiv.org/abs/2012.10547" target="_blank">arXiv:2012.10547</a> [<a href="http://arxiv.org/pdf/2012.10547" target="_blank">pdf</a>]

<h2>Robustness of Facial Recognition to GAN-based Face-morphing Attacks. (arXiv:2012.10548v1 [cs.CV])</h2>
<h3>Richard T. Marriott, Sami Romdhani, St&#xe9;phane Gentric, Liming Chen</h3>
<p>Face-morphing attacks have been a cause for concern for a number of years.
Striving to remain one step ahead of attackers, researchers have proposed many
methods of both creating and detecting morphed images. These detection methods,
however, have generally proven to be inadequate. In this work we identify two
new, GAN-based methods that an attacker may already have in his arsenal. Each
method is evaluated against state-of-the-art facial recognition (FR) algorithms
and we demonstrate that improvements to the fidelity of FR algorithms do lead
to a reduction in the success rate of attacks provided morphed images are
considered when setting operational acceptance thresholds.
</p>
<a href="http://arxiv.org/abs/2012.10548" target="_blank">arXiv:2012.10548</a> [<a href="http://arxiv.org/pdf/2012.10548" target="_blank">pdf</a>]

<h2>An Assessment of GANs for Identity-related Applications. (arXiv:2012.10553v1 [cs.CV])</h2>
<h3>Richard T. Marriott, Safa Madiouni, Sami Romdhani, St&#xe9;phane Gentric, Liming Chen</h3>
<p>Generative Adversarial Networks (GANs) are now capable of producing synthetic
face images of exceptionally high visual quality. In parallel to the
development of GANs themselves, efforts have been made to develop metrics to
objectively assess the characteristics of the synthetic images, mainly focusing
on visual quality and the variety of images. Little work has been done,
however, to assess overfitting of GANs and their ability to generate new
identities. In this paper we apply a state of the art biometric network to
various datasets of synthetic images and perform a thorough assessment of their
identity-related characteristics. We conclude that GANs can indeed be used to
generate new, imagined identities meaning that applications such as
anonymisation of image sets and augmentation of training datasets with
distractor images are viable applications. We also assess the ability of GANs
to disentangle identity from other image characteristics and propose a novel
GAN triplet loss that we show to improve this disentanglement.
</p>
<a href="http://arxiv.org/abs/2012.10553" target="_blank">arXiv:2012.10553</a> [<a href="http://arxiv.org/pdf/2012.10553" target="_blank">pdf</a>]

<h2>Computer-aided abnormality detection in chest radiographs in a clinical setting via domain-adaptation. (arXiv:2012.10564v1 [cs.CV])</h2>
<h3>Abhishek K Dubey, Michael T Young, Christopher Stanley, Dalton Lunga, Jacob Hinkle</h3>
<p>Deep learning (DL) models are being deployed at medical centers to aid
radiologists for diagnosis of lung conditions from chest radiographs. Such
models are often trained on a large volume of publicly available labeled
radiographs. These pre-trained DL models' ability to generalize in clinical
settings is poor because of the changes in data distributions between publicly
available and privately held radiographs. In chest radiographs, the
heterogeneity in distributions arises from the diverse conditions in X-ray
equipment and their configurations used for generating the images. In the
machine learning community, the challenges posed by the heterogeneity in the
data generation source is known as domain shift, which is a mode shift in the
generative model. In this work, we introduce a domain-shift detection and
removal method to overcome this problem. Our experimental results show the
proposed method's effectiveness in deploying a pre-trained DL model for
abnormality detection in chest radiographs in a clinical setting.
</p>
<a href="http://arxiv.org/abs/2012.10564" target="_blank">arXiv:2012.10564</a> [<a href="http://arxiv.org/pdf/2012.10564" target="_blank">pdf</a>]

<h2>No Shadow Left Behind: Removing Objects and their Shadows using Approximate Lighting and Geometry. (arXiv:2012.10565v1 [cs.CV])</h2>
<h3>Edward Zhang, Ricardo Martin-Brualla, Janne Kontkanen, Brian Curless</h3>
<p>Removing objects from images is a challenging problem that is important for
many applications, including mixed reality. For believable results, the shadows
that the object casts should also be removed. Current inpainting-based methods
only remove the object itself, leaving shadows behind, or at best require
specifying shadow regions to inpaint. We introduce a deep learning pipeline for
removing a shadow along with its caster. We leverage rough scene models in
order to remove a wide variety of shadows (hard or soft, dark or subtle, large
or thin) from surfaces with a wide variety of textures. We train our pipeline
on synthetically rendered data, and show qualitative and quantitative results
on both synthetic and real scenes.
</p>
<a href="http://arxiv.org/abs/2012.10565" target="_blank">arXiv:2012.10565</a> [<a href="http://arxiv.org/pdf/2012.10565" target="_blank">pdf</a>]

<h2>Communication-Aware Collaborative Learning. (arXiv:2012.10569v1 [cs.LG])</h2>
<h3>Avrim Blum, Shelby Heinecke, Lev Reyzin</h3>
<p>Algorithms for noiseless collaborative PAC learning have been analyzed and
optimized in recent years with respect to sample complexity. In this paper, we
study collaborative PAC learning with the goal of reducing communication cost
at essentially no penalty to the sample complexity. We develop communication
efficient collaborative PAC learning algorithms using distributed boosting. We
then consider the communication cost of collaborative learning in the presence
of classification noise. As an intermediate step, we show how collaborative PAC
learning algorithms can be adapted to handle classification noise. With this
insight, we develop communication efficient algorithms for collaborative PAC
learning robust to classification noise.
</p>
<a href="http://arxiv.org/abs/2012.10569" target="_blank">arXiv:2012.10569</a> [<a href="http://arxiv.org/pdf/2012.10569" target="_blank">pdf</a>]

<h2>Identifying Invariant Texture Violation for Robust Deepfake Detection. (arXiv:2012.10580v1 [cs.CV])</h2>
<h3>Xinwei Sun, Botong Wu, Wei Chen</h3>
<p>Existing deepfake detection methods have reported promising in-distribution
results, by accessing published large-scale dataset. However, due to the
non-smooth synthesis method, the fake samples in this dataset may expose
obvious artifacts (e.g., stark visual contrast, non-smooth boundary), which
were heavily relied on by most of the frame-level detection methods above. As
these artifacts do not come up in real media forgeries, the above methods can
suffer from a large degradation when applied to fake images that close to
reality. To improve the robustness for high-realism fake data, we propose the
Invariant Texture Learning (InTeLe) framework, which only accesses the
published dataset with low visual quality. Our method is based on the prior
that the microscopic facial texture of the source face is inevitably violated
by the texture transferred from the target person, which can hence be regarded
as the invariant characterization shared among all fake images. To learn such
an invariance for deepfake detection, our InTeLe introduces an auto-encoder
framework with different decoders for pristine and fake images, which are
further appended with a shallow classifier in order to separate out the obvious
artifact-effect. Equipped with such a separation, the extracted embedding by
encoder can capture the texture violation in fake images, followed by the
classifier for the final pristine/fake prediction. As a theoretical guarantee,
we prove the identifiability of such an invariance texture violation, i.e., to
be precisely inferred from observational data. The effectiveness and utility of
our method are demonstrated by promising generalization ability from
low-quality images with obvious artifacts to fake images with high realism.
</p>
<a href="http://arxiv.org/abs/2012.10580" target="_blank">arXiv:2012.10580</a> [<a href="http://arxiv.org/pdf/2012.10580" target="_blank">pdf</a>]

<h2>Learning by Fixing: Solving Math Word Problems with Weak Supervision. (arXiv:2012.10582v1 [cs.AI])</h2>
<h3>Yining Hong, Qing Li, Daniel Ciao, Siyuan Haung, Song-Chun Zhu</h3>
<p>Previous neural solvers of math word problems (MWPs) are learned with full
supervision and fail to generate diverse solutions. In this paper, we address
this issue by introducing a \textit{weakly-supervised} paradigm for learning
MWPs. Our method only requires the annotations of the final answers and can
generate various solutions for a single problem. To boost weakly-supervised
learning, we propose a novel \textit{learning-by-fixing} (LBF) framework, which
corrects the misperceptions of the neural network via symbolic reasoning.
Specifically, for an incorrect solution tree generated by the neural network,
the \textit{fixing} mechanism propagates the error from the root node to the
leaf nodes and infers the most probable fix that can be executed to get the
desired answer. To generate more diverse solutions, \textit{tree
regularization} is applied to guide the efficient shrinkage and exploration of
the solution space, and a \textit{memory buffer} is designed to track and save
the discovered various fixes for each problem. Experimental results on the
Math23K dataset show the proposed LBF framework significantly outperforms
reinforcement learning baselines in weakly-supervised learning. Furthermore, it
achieves comparable top-1 and much better top-3/5 answer accuracies than
fully-supervised methods, demonstrating its strength in producing diverse
solutions.
</p>
<a href="http://arxiv.org/abs/2012.10582" target="_blank">arXiv:2012.10582</a> [<a href="http://arxiv.org/pdf/2012.10582" target="_blank">pdf</a>]

<h2>A Comparison of Three Measurement Models for the Wheel-mounted MEMS IMU-based Dead Reckoning System. (arXiv:2012.10589v1 [cs.RO])</h2>
<h3>Yibin Wu, Xiaoji Niu, Jian Kuang</h3>
<p>A self-contained autonomous navigation system is desired to complement the
Global Navigation Satellite System (GNSS) for land vehicles, for which odometer
aided inertial navigation system (ODO/INS) is a classical solution. In this
study, we use a wheel-mounted MEMS IMU (Wheel-IMU) to substitute the
conventional odometer, and further, investigate three types of measurement
models, including the velocity measurement, displacement increment measurement,
and contact point zero-velocity measurement, in the Wheel-IMU based dead
reckoning (DR) system. The three measurements, along with the non-holonomic
constraints (NHCs) are fused with INS by an extended Kalman filter (EKF).
Theoretical discussion and field tests illustrate their feasibility and
equivalence in overall positioning performance, which have the maximum
horizontal position drifts less than 2% of the total travelled distance.
However, the displacement increment measurement model is less sensitive to the
installation lever arm between the Wheel-IMU and wheel center.
</p>
<a href="http://arxiv.org/abs/2012.10589" target="_blank">arXiv:2012.10589</a> [<a href="http://arxiv.org/pdf/2012.10589" target="_blank">pdf</a>]

<h2>On graded semantics of abstract argumentation: extension-based case. (arXiv:2012.10592v1 [cs.AI])</h2>
<h3>Lixing Tan, Zhaohui Zhua, Jinjin Zhang</h3>
<p>Based on Grossi and Modgil's recent work [1], this paper considers some
issues on extension-based semantics for abstract argumentation framework (AAF,
for short). First, an alternative fundamental lemma is given, which generalizes
the corresponding result obtained in [1]. This lemma plays a central role in
constructing some special extensions in terms of iterations of the defense
function. Applying this lemma, some flaws in [1] are corrected and a number of
structural properties of various extension-based semantics are given. Second,
the operator so-called reduced meet modulo an ultrafilter is presented. A
number of fundamental semantics for AAF, including conflict-free, admissible,
complete and stable semantics, are shown to be closed under this operator.
Based on this fact, we provide a concise and uniform proof method to establish
the universal definability of a family of range related semantics. Thirdly,
using model-theoretical tools, we characterize the class of extension-based
semantics that is closed under reduced meet modulo any ultrafilter, which
brings us a metatheorem concerning the universal definability of range related
semantics. Finally, in addition to range related semantics, some graded
variants of traditional semantics of AAF are also considered in this paper,
e.g., ideal semantics, eager semantics, etc.
</p>
<a href="http://arxiv.org/abs/2012.10592" target="_blank">arXiv:2012.10592</a> [<a href="http://arxiv.org/pdf/2012.10592" target="_blank">pdf</a>]

<h2>Wheel-INS2: Multiple MEMS IMU-based Dead Reckoning System for Wheeled Robots with Evaluation of Different IMU Configurations. (arXiv:2012.10593v1 [cs.RO])</h2>
<h3>Yibin Wu, Jian Kuang, Xiaoji Niu</h3>
<p>A reliable self-contained navigation system is essential for autonomous
vehicles. In this study, we propose a multiple microelectromechanical system
(MEMS) inertial measurement unit (IMU)-based dead reckoning (DR) solution for
wheeled vehicles. The IMUs are located at different places on the wheeled
vehicle to acquire various dynamic information. In the proposed system, at
least one IMU has to be mounted at the wheel to measure the wheel velocity,
thus, replacing the traditional odometer. The other IMUs can be mounted on
either the remaining wheels or the vehicle body. The system is implemented
through a decentralized extended Kalman filter structure in which each
subsystem (corresponding to each IMU) retains and updates its own states
separately. The relative position constraint between the IMUs is exploited by
fusing the IMU positions to calculate the coordinates of the reference point,
which is treated as an external observation of the subsystems. Specially, we
present the DR systems based on dual wheel-mounted IMUs (Wheel-IMUs), one
Wheel-IMU plus one vehicle body-mounted IMU (Body-IMU), and dual Wheel-IMUs
plus one Body-IMU as examples for analysis and experiments. Field tests
illustrate that the proposed multiple IMU-based DR system statistically
outperforms the single Wheel-IMU based DR system in positioning and heading
accuracy. Moreover, of the three multi-IMU configurations, the one Body IMU
plus one Wheel-IMU design obtains the minimum drift rate.
</p>
<a href="http://arxiv.org/abs/2012.10593" target="_blank">arXiv:2012.10593</a> [<a href="http://arxiv.org/pdf/2012.10593" target="_blank">pdf</a>]

<h2>T-GAP: Learning to Walk across Time for Temporal Knowledge Graph Completion. (arXiv:2012.10595v1 [cs.LG])</h2>
<h3>Jaehun Jung, Jinhong Jung, U Kang</h3>
<p>Temporal knowledge graphs (TKGs) inherently reflect the transient nature of
real-world knowledge, as opposed to static knowledge graphs. Naturally,
automatic TKG completion has drawn much research interests for a more realistic
modeling of relational reasoning. However, most of the existing mod-els for TKG
completion extend static KG embeddings that donot fully exploit TKG structure,
thus lacking in 1) account-ing for temporally relevant events already residing
in the lo-cal neighborhood of a query, and 2) path-based inference that
facilitates multi-hop reasoning and better interpretability. In this paper, we
propose T-GAP, a novel model for TKG completion that maximally utilizes both
temporal information and graph structure in its encoder and decoder. T-GAP
encodes query-specific substructure of TKG by focusing on the temporal
displacement between each event and the query times-tamp, and performs
path-based inference by propagating attention through the graph. Our empirical
experiments demonstrate that T-GAP not only achieves superior performance
against state-of-the-art baselines, but also competently generalizes to queries
with unseen timestamps. Through extensive qualitative analyses, we also show
that T-GAP enjoys from transparent interpretability, and follows human
intuition in its reasoning process.
</p>
<a href="http://arxiv.org/abs/2012.10595" target="_blank">arXiv:2012.10595</a> [<a href="http://arxiv.org/pdf/2012.10595" target="_blank">pdf</a>]

<h2>Scalable and Provably Accurate Algorithms for Differentially Private Distributed Decision Tree Learning. (arXiv:2012.10602v1 [cs.LG])</h2>
<h3>Kaiwen Wang, Travis Dick, Maria-Florina Balcan</h3>
<p>This paper introduces the first provably accurate algorithms for
differentially private, top-down decision tree learning in the distributed
setting (Balcan et al., 2012). We propose DP-TopDown, a general privacy
preserving decision tree learning algorithm, and present two distributed
implementations. Our first method NoisyCounts naturally extends the single
machine algorithm by using the Laplace mechanism. Our second method LocalRNM
significantly reduces communication and added noise by performing local
optimization at each data holder. We provide the first utility guarantees for
differentially private top-down decision tree learning in both the single
machine and distributed settings. These guarantees show that the error of the
privately-learned decision tree quickly goes to zero provided that the dataset
is sufficiently large. Our extensive experiments on real datasets illustrate
the trade-offs of privacy, accuracy and generalization when learning private
decision trees in the distributed setting.
</p>
<a href="http://arxiv.org/abs/2012.10602" target="_blank">arXiv:2012.10602</a> [<a href="http://arxiv.org/pdf/2012.10602" target="_blank">pdf</a>]

<h2>Space ML: Distributed Open-source Research with Citizen Scientists for the Advancement of Space Technology for NASA. (arXiv:2012.10610v1 [cs.CV])</h2>
<h3>Anirudh Koul, Siddha Ganju, Meher Kasam, James Parr</h3>
<p>Traditionally, academic labs conduct open-ended research with the primary
focus on discoveries with long-term value, rather than direct products that can
be deployed in the real world. On the other hand, research in the industry is
driven by its expected commercial return on investment, and hence focuses on a
real world product with short-term timelines. In both cases, opportunity is
selective, often available to researchers with advanced educational
backgrounds. Research often happens behind closed doors and may be kept
confidential until either its publication or product release, exacerbating the
problem of AI reproducibility and slowing down future research by others in the
field. As many research organizations tend to exclusively focus on specific
areas, opportunities for interdisciplinary research reduce. Undertaking
long-term bold research in unexplored fields with non-commercial yet great
public value is hard due to factors including the high upfront risk, budgetary
constraints, and a lack of availability of data and experts in niche fields.
Only a few companies or well-funded research labs can afford to do such
long-term research. With research organizations focused on an exploding array
of fields and resources spread thin, opportunities for the maturation of
interdisciplinary research reduce. Apart from these exigencies, there is also a
need to engage citizen scientists through open-source contributors to play an
active part in the research dialogue. We present a short case study of Space
ML, an extension of the Frontier Development Lab, an AI accelerator for NASA.
Space ML distributes open-source research and invites volunteer citizen
scientists to partake in development and deployment of high social value
products at the intersection of space and AI.
</p>
<a href="http://arxiv.org/abs/2012.10610" target="_blank">arXiv:2012.10610</a> [<a href="http://arxiv.org/pdf/2012.10610" target="_blank">pdf</a>]

<h2>A pipeline for fair comparison of graph neural networks in node classification tasks. (arXiv:2012.10619v1 [cs.LG])</h2>
<h3>Wentao Zhao, Dalin Zhou, Xinguo Qiu, Wei Jiang</h3>
<p>Graph neural networks (GNNs) have been investigated for potential
applicability in multiple fields that employ graph data. However, there are no
standard training settings to ensure fair comparisons among new methods,
including different model architectures and data augmentation techniques. We
introduce a standard, reproducible benchmark to which the same training
settings can be applied for node classification. For this benchmark, we
constructed 9 datasets, including both small- and medium-scale datasets from
different fields, and 7 different models. We design a k-fold model assessment
strategy for small datasets and a standard set of model training procedures for
all datasets, enabling a standard experimental pipeline for GNNs to help ensure
fair model architecture comparisons. We use node2vec and Laplacian eigenvectors
to perform data augmentation to investigate how input features affect the
performance of the models. We find topological information is important for
node classification tasks. Increasing the number of model layers does not
improve the performance except on the PATTERN and CLUSTER datasets, in which
the graphs are not connected. Data augmentation is highly useful, especially
using node2vec in the baseline, resulting in a substantial baseline performance
improvement.
</p>
<a href="http://arxiv.org/abs/2012.10619" target="_blank">arXiv:2012.10619</a> [<a href="http://arxiv.org/pdf/2012.10619" target="_blank">pdf</a>]

<h2>GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning. (arXiv:2012.10630v1 [cs.LG])</h2>
<h3>Krishnateja Killamsetty (1), Durga Sivasubramanian (2), Ganesh Ramakrishnan (2), Rishabh Iyer (1 and 2) ((1) University of Texas at Dallas, (2) Indian Institute of Technology Bombay) ((1) Institution One, (2) Institution Two)</h3>
<p>Large scale machine learning and deep models are extremely data-hungry.
Unfortunately, obtaining large amounts of labeled data is expensive, and
training state-of-the-art models (with hyperparameter tuning) requires
significant computing resources and time. Secondly, real-world data is noisy
and imbalanced. As a result, several recent papers try to make the training
process more efficient and robust. However, most existing work either focuses
on robustness or efficiency, but not both. In this work, we introduce Glister,
a GeneraLIzation based data Subset selecTion for Efficient and Robust learning
framework. We formulate Glister as a mixed discrete-continuous bi-level
optimization problem to select a subset of the training data, which maximizes
the log-likelihood on a held-out validation set. Next, we propose an iterative
online algorithm Glister-Online, which performs data selection iteratively
along with the parameter updates and can be applied to any loss-based learning
algorithm. We then show that for a rich class of loss functions including
cross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete
data selection is an instance of (weakly) submodular optimization, and we
analyze conditions for which Glister-Online reduces the validation loss and
converges. Finally, we propose Glister-Active, an extension to batch active
learning, and we empirically demonstrate the performance of Glister on a wide
range of tasks including, (a) data selection to reduce training time, (b)
robust learning under label noise and imbalance settings, and (c) batch-active
learning with several deep and shallow models. We show that our framework
improves upon state of the art both in efficiency and accuracy (in cases (a)
and (c)) and is more efficient compared to other state-of-the-art robust
learning algorithms in case (b).
</p>
<a href="http://arxiv.org/abs/2012.10630" target="_blank">arXiv:2012.10630</a> [<a href="http://arxiv.org/pdf/2012.10630" target="_blank">pdf</a>]

<h2>BAF-Detector: An Efficient CNN-Based Detector for Photovoltaic Solar Cell Defect Detection. (arXiv:2012.10631v1 [cs.CV])</h2>
<h3>Binyi Su, Haiyong Chen, Zhong Zhou</h3>
<p>The multi-scale defect detection for solar cell electroluminescence (EL)
images is a challenging task, due to the feature vanishing as network deepens.
To address this problem, a novel Bidirectional Attention Feature Pyramid
Network (BAFPN) is designed by combining the novel multi-head cosine non-local
attention module with top-down and bottom-up feature pyramid networks through
bidirectional cross-scale connections, which can make all layers of the pyramid
share similar semantic features. In multi-head cosine non-local attention
module, cosine function is applied to compute the similarity matrix of the
input features. Furthermore, a novel object detector is proposed, called
BAF-Detector, which embeds BAFPN into Region Proposal Network (RPN) in Faster
RCNN+FPN to improve the detection effect of multi-scale defects in solar cell
EL images. Finally, some experimental results on a large-scale EL dataset
including 3629 images, 2129 of which are defective, show that the proposed
method performs much better than other methods in terms of multi-scale defects
classification and detection results in raw solar cell EL images.
</p>
<a href="http://arxiv.org/abs/2012.10631" target="_blank">arXiv:2012.10631</a> [<a href="http://arxiv.org/pdf/2012.10631" target="_blank">pdf</a>]

<h2>Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle Routing Problems. (arXiv:2012.10638v1 [cs.LG])</h2>
<h3>Liang Xin, Wen Song, Zhiguang Cao, Jie Zhang</h3>
<p>We present a novel deep reinforcement learning method to learn construction
heuristics for vehicle routing problems. In specific, we propose a
Multi-Decoder Attention Model (MDAM) to train multiple diverse policies, which
effectively increases the chance of finding good solutions compared with
existing methods that train only one policy. A customized beam search strategy
is designed to fully exploit the diversity of MDAM. In addition, we propose an
Embedding Glimpse layer in MDAM based on the recursive nature of construction,
which can improve the quality of each policy by providing more informative
embeddings. Extensive experiments on six different routing problems show that
our method significantly outperforms the state-of-the-art deep learning based
models.
</p>
<a href="http://arxiv.org/abs/2012.10638" target="_blank">arXiv:2012.10638</a> [<a href="http://arxiv.org/pdf/2012.10638" target="_blank">pdf</a>]

<h2>Dense Multiscale Feature Fusion Pyramid Networks for Object Detection in UAV-Captured Images. (arXiv:2012.10643v1 [cs.CV])</h2>
<h3>Yingjie Liu</h3>
<p>Although much significant progress has been made in the research field of
object detection with deep learning, there still exists a challenging task for
the objects with small size, which is notably pronounced in UAV-captured
images. Addressing these issues, it is a critical need to explore the feature
extraction methods that can extract more sufficient feature information of
small objects. In this paper, we propose a novel method called Dense Multiscale
Feature Fusion Pyramid Networks(DMFFPN), which is aimed at obtaining rich
features as much as possible, improving the information propagation and reuse.
Specifically, the dense connection is designed to fully utilize the
representation from the different convolutional layers. Furthermore, cascade
architecture is applied in the second stage to enhance the localization
capability. Experiments on the drone-based datasets named VisDrone-DET suggest
a competitive performance of our method.
</p>
<a href="http://arxiv.org/abs/2012.10643" target="_blank">arXiv:2012.10643</a> [<a href="http://arxiv.org/pdf/2012.10643" target="_blank">pdf</a>]

<h2>Towards Coarse and Fine-grained Multi-Graph Multi-Label Learning. (arXiv:2012.10650v1 [cs.LG])</h2>
<h3>Yejiang Wang, Yuhai Zhao, Zhengkui Wang, Chengqi Zhang</h3>
<p>Multi-graph multi-label learning (\textsc{Mgml}) is a supervised learning
framework, which aims to learn a multi-label classifier from a set of labeled
bags each containing a number of graphs. Prior techniques on the \textsc{Mgml}
are developed based on transfering graphs into instances and focus on learning
the unseen labels only at the bag level. In this paper, we propose a
\textit{coarse} and \textit{fine-grained} Multi-graph Multi-label (cfMGML)
learning framework which directly builds the learning model over the graphs and
empowers the label prediction at both the \textit{coarse} (aka. bag) level and
\textit{fine-grained} (aka. graph in each bag) level. In particular, given a
set of labeled multi-graph bags, we design the scoring functions at both graph
and bag levels to model the relevance between the label and data using specific
graph kernels. Meanwhile, we propose a thresholding rank-loss objective
function to rank the labels for the graphs and bags and minimize the
hamming-loss simultaneously at one-step, which aims to addresses the error
accumulation issue in traditional rank-loss algorithms. To tackle the
non-convex optimization problem, we further develop an effective sub-gradient
descent algorithm to handle high-dimensional space computation required in
cfMGML. Experiments over various real-world datasets demonstrate cfMGML
achieves superior performance than the state-of-arts algorithms.
</p>
<a href="http://arxiv.org/abs/2012.10650" target="_blank">arXiv:2012.10650</a> [<a href="http://arxiv.org/pdf/2012.10650" target="_blank">pdf</a>]

<h2>Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances. (arXiv:2012.10658v1 [cs.LG])</h2>
<h3>Zhang-Hua Fu, Kai-Bin Qiu, Hongyuan Zha</h3>
<p>For the traveling salesman problem (TSP), the existing supervised learning
based algorithms suffer seriously from the lack of generalization ability. To
overcome this drawback, this paper tries to train (in supervised manner) a
small-scale model, which could be repetitively used to build heat maps for TSP
instances of arbitrarily large size, based on a series of techniques such as
graph sampling, graph converting and heat maps merging. Furthermore, the heat
maps are fed into a reinforcement learning approach (Monte Carlo tree search),
to guide the search of high-quality solutions. Experimental results based on a
large number of instances (with up to 10,000 vertices) show that, this new
approach clearly outperforms the existing machine learning based TSP
algorithms, and significantly improves the generalization ability of the
trained model.
</p>
<a href="http://arxiv.org/abs/2012.10658" target="_blank">arXiv:2012.10658</a> [<a href="http://arxiv.org/pdf/2012.10658" target="_blank">pdf</a>]

<h2>The importance of silhouette optimization in 3D shape reconstruction system from multiple object scenes. (arXiv:2012.10660v1 [cs.CV])</h2>
<h3>Waqqas-ur-Rehman Butt, Martin Servin</h3>
<p>This paper presents a multi stage 3D shape reconstruction system of multiple
object scenes by considering the silhouette inconsistencies in shape-from
silhouette SFS method. These inconsistencies are common in multiple view images
due to object occlusions in different views, segmentation and shadows or
reflection due to objects or light directions. These factors raise huge
challenges when attempting to construct the 3D shape by using existing
approaches which reconstruct only that part of the volume which projects
consistently in all the silhouettes, leaving the rest unreconstructed. As a
result, final shape are not robust due to multi view objects occlusion and
shadows. In this regard, we consider the primary factors affecting
reconstruction by analyzing the multiple images and perform pre-processing
steps to optimize the silhouettes. Finally, the 3D shape is reconstructed by
using the volumetric approach SFS. Theory and experimental results show that,
the performance of the modified algorithm was efficiently improved, which can
improve the accuracy of the reconstructed shape and being robust to errors in
the silhouettes, volume and computational inexpensive.
</p>
<a href="http://arxiv.org/abs/2012.10660" target="_blank">arXiv:2012.10660</a> [<a href="http://arxiv.org/pdf/2012.10660" target="_blank">pdf</a>]

<h2>SMART Frame Selection for Action Recognition. (arXiv:2012.10671v1 [cs.CV])</h2>
<h3>Shreyank N Gowda, Marcus Rohrbach, Laura Sevilla-Lara</h3>
<p>Action recognition is computationally expensive. In this paper, we address
the problem of frame selection to improve the accuracy of action recognition.
In particular, we show that selecting good frames helps in action recognition
performance even in the trimmed videos domain. Recent work has successfully
leveraged frame selection for long, untrimmed videos, where much of the content
is not relevant, and easy to discard. In this work, however, we focus on the
more standard short, trimmed action recognition problem. We argue that good
frame selection can not only reduce the computational cost of action
recognition but also increase the accuracy by getting rid of frames that are
hard to classify. In contrast to previous work, we propose a method that
instead of selecting frames by considering one at a time, considers them
jointly. This results in a more efficient selection, where good frames are more
effectively distributed over the video, like snapshots that tell a story. We
call the proposed frame selection SMART and we test it in combination with
different backbone architectures and on multiple benchmarks (Kinetics,
Something-something, UCF101). We show that the SMART frame selection
consistently improves the accuracy compared to other frame selection strategies
while reducing the computational cost by a factor of 4 to 10 times.
Additionally, we show that when the primary goal is recognition performance,
our selection strategy can improve over recent state-of-the-art models and
frame selection strategies on various benchmarks (UCF101, HMDB51, FCVID, and
ActivityNet).
</p>
<a href="http://arxiv.org/abs/2012.10671" target="_blank">arXiv:2012.10671</a> [<a href="http://arxiv.org/pdf/2012.10671" target="_blank">pdf</a>]

<h2>Camera-aware Proxies for Unsupervised Person Re-Identification. (arXiv:2012.10674v1 [cs.CV])</h2>
<h3>Menglin Wang, Baisheng Lai, Jianqiang Huang, Xiaojin Gong, Xian-Sheng Hua</h3>
<p>This paper tackles the purely unsupervised person re-identification (Re-ID)
problem that requires no annotations. Some previous methods adopt clustering
techniques to generate pseudo labels and use the produced labels to train Re-ID
models progressively. These methods are relatively simple but effective.
However, most clustering-based methods take each cluster as a pseudo identity
class, neglecting the large intra-ID variance caused mainly by the change of
camera views. To address this issue, we propose to split each single cluster
into multiple proxies and each proxy represents the instances coming from the
same camera. These camera-aware proxies enable us to deal with large intra-ID
variance and generate more reliable pseudo labels for learning. Based on the
camera-aware proxies, we design both intra- and inter-camera contrastive
learning components for our Re-ID model to effectively learn the ID
discrimination ability within and across cameras. Meanwhile, a proxy-balanced
sampling strategy is also designed, which facilitates our learning further.
Extensive experiments on three large-scale Re-ID datasets show that our
proposed approach outperforms most unsupervised methods by a significant
margin. Especially, on the challenging MSMT17 dataset, we gain $14.3\%$ Rank-1
and $10.2\%$ mAP improvements when compared to the second place.
</p>
<a href="http://arxiv.org/abs/2012.10674" target="_blank">arXiv:2012.10674</a> [<a href="http://arxiv.org/pdf/2012.10674" target="_blank">pdf</a>]

<h2>Unsupervised Scale-Invariant Multispectral Shape Matching. (arXiv:2012.10685v1 [cs.CV])</h2>
<h3>Idan Pazi, Dvir Ginzburg, Dan Raviv</h3>
<p>Alignment between non-rigid stretchable structures is one of the hardest
tasks in computer vision, as the invariant properties are hard to define on one
hand, and on the other hand no labelled data exists for real datasets. We
present unsupervised neural network architecture based upon the spectrum of
scale-invariant geometry. We build ontop the functional maps architecture, but
show that learning local features, as done until now, is not enough once the
isometric assumption breaks but can be solved using scale-invariant geometry.
Our method is agnostic to local-scale deformations and shows superior
performance for matching shapes from different domains when compared to
existing spectral state-of-the-art solutions.
</p>
<a href="http://arxiv.org/abs/2012.10685" target="_blank">arXiv:2012.10685</a> [<a href="http://arxiv.org/pdf/2012.10685" target="_blank">pdf</a>]

<h2>Top-$k$ Ranking Bayesian Optimization. (arXiv:2012.10688v1 [cs.LG])</h2>
<h3>Quoc Phong Nguyen, Sebastian Tay, Bryan Kian Hsiang Low, Patrick Jaillet</h3>
<p>This paper presents a novel approach to top-$k$ ranking Bayesian optimization
(top-$k$ ranking BO) which is a practical and significant generalization of
preferential BO to handle top-$k$ ranking and tie/indifference observations. We
first design a surrogate model that is not only capable of catering to the
above observations, but is also supported by a classic random utility model.
Another equally important contribution is the introduction of the first
information-theoretic acquisition function in BO with preferential observation
called multinomial predictive entropy search (MPES) which is flexible in
handling these observations and optimized for all inputs of a query jointly.
MPES possesses superior performance compared with existing acquisition
functions that select the inputs of a query one at a time greedily. We
empirically evaluate the performance of MPES using several synthetic benchmark
functions, CIFAR-$10$ dataset, and SUSHI preference dataset.
</p>
<a href="http://arxiv.org/abs/2012.10688" target="_blank">arXiv:2012.10688</a> [<a href="http://arxiv.org/pdf/2012.10688" target="_blank">pdf</a>]

<h2>An Information-Theoretic Framework for Unifying Active Learning Problems. (arXiv:2012.10695v1 [cs.LG])</h2>
<h3>Quoc Phong Nguyen, Bryan Kian Hsiang Low, Patrick Jaillet</h3>
<p>This paper presents an information-theoretic framework for unifying active
learning problems: level set estimation (LSE), Bayesian optimization (BO), and
their generalized variant. We first introduce a novel active learning criterion
that subsumes an existing LSE algorithm and achieves state-of-the-art
performance in LSE problems with a continuous input domain. Then, by exploiting
the relationship between LSE and BO, we design a competitive
information-theoretic acquisition function for BO that has interesting
connections to upper confidence bound and max-value entropy search (MES). The
latter connection reveals a drawback of MES which has important implications on
not only MES but also on other MES-based acquisition functions. Finally, our
unifying information-theoretic framework can be applied to solve a generalized
problem of LSE and BO involving multiple level sets in a data-efficient manner.
We empirically evaluate the performance of our proposed algorithms using
synthetic benchmark functions, a real-world dataset, and in hyperparameter
tuning of machine learning models.
</p>
<a href="http://arxiv.org/abs/2012.10695" target="_blank">arXiv:2012.10695</a> [<a href="http://arxiv.org/pdf/2012.10695" target="_blank">pdf</a>]

<h2>Minimax Strikes Back. (arXiv:2012.10700v1 [cs.AI])</h2>
<h3>Quentin Cohen-Solal, Tristan Cazenave</h3>
<p>Deep Reinforcement Learning (DRL) reaches a superhuman level of play in many
complete information games. The state of the art search algorithm used in
combination with DRL is Monte Carlo Tree Search (MCTS). We take another
approach to DRL using a Minimax algorithm instead of MCTS and learning only the
evaluation of states, not the policy. We show that for multiple games it is
competitive with the state of the art DRL for the learning performances and for
the confrontations.
</p>
<a href="http://arxiv.org/abs/2012.10700" target="_blank">arXiv:2012.10700</a> [<a href="http://arxiv.org/pdf/2012.10700" target="_blank">pdf</a>]

<h2>Self-supervised monocular depth estimation from oblique UAV videos. (arXiv:2012.10704v1 [cs.CV])</h2>
<h3>Logambal Madhuanand, Francesco Nex, Michael Ying Yang</h3>
<p>UAVs have become an essential photogrammetric measurement as they are
affordable, easily accessible and versatile. Aerial images captured from UAVs
have applications in small and large scale texture mapping, 3D modelling,
object detection tasks, DTM and DSM generation etc. Photogrammetric techniques
are routinely used for 3D reconstruction from UAV images where multiple images
of the same scene are acquired. Developments in computer vision and deep
learning techniques have made Single Image Depth Estimation (SIDE) a field of
intense research. Using SIDE techniques on UAV images can overcome the need for
multiple images for 3D reconstruction. This paper aims to estimate depth from a
single UAV aerial image using deep learning. We follow a self-supervised
learning approach, Self-Supervised Monocular Depth Estimation (SMDE), which
does not need ground truth depth or any extra information other than images for
learning to estimate depth. Monocular video frames are used for training the
deep learning model which learns depth and pose information jointly through two
different networks, one each for depth and pose. The predicted depth and pose
are used to reconstruct one image from the viewpoint of another image utilising
the temporal information from videos. We propose a novel architecture with two
2D CNN encoders and a 3D CNN decoder for extracting information from
consecutive temporal frames. A contrastive loss term is introduced for
improving the quality of image generation. Our experiments are carried out on
the public UAVid video dataset. The experimental results demonstrate that our
model outperforms the state-of-the-art methods in estimating the depths.
</p>
<a href="http://arxiv.org/abs/2012.10704" target="_blank">arXiv:2012.10704</a> [<a href="http://arxiv.org/pdf/2012.10704" target="_blank">pdf</a>]

<h2>Siamese Anchor Proposal Network for High-Speed Aerial Tracking. (arXiv:2012.10706v1 [cs.CV])</h2>
<h3>Changhong Fu, Ziang Cao, Yiming Li, Junjie Ye, Chen Feng</h3>
<p>In the domain of visual tracking, most deep learning-based trackers highlight
the accuracy but casting aside efficiency, thereby impeding their real-world
deployment on mobile platforms like the unmanned aerial vehicle (UAV). In this
work, a novel two-stage siamese network-based method is proposed for aerial
tracking, \textit{i.e.}, stage-1 for high-quality anchor proposal generation,
stage-2 for refining the anchor proposal. Different from anchor-based methods
with numerous pre-defined fixed-sized anchors, our no-prior method can 1) make
tracker robust and general to different objects with various sizes, especially
to small, occluded, and fast-moving objects, under complex scenarios in light
of the adaptive anchor generation, 2) make calculation feasible due to the
substantial decrease of anchor numbers. In addition, compared to anchor-free
methods, our framework has better performance owing to refinement at stage-2.
Comprehensive experiments on three benchmarks have proven the state-of-the-art
performance of our approach, with a speed of around 200 frames/s.
</p>
<a href="http://arxiv.org/abs/2012.10706" target="_blank">arXiv:2012.10706</a> [<a href="http://arxiv.org/pdf/2012.10706" target="_blank">pdf</a>]

<h2>Static object detection and segmentation in videos based on dual foregrounds difference with noise filtering. (arXiv:2012.10708v1 [cs.CV])</h2>
<h3>Waqqas-ur-Rehman Butt, Martin Servin</h3>
<p>This paper presents static object detection and segmentation method in videos
from cluttered scenes. Robust static object detection is still challenging task
due to presence of moving objects in many surveillance applications. The level
of difficulty is extremely influenced by on how you label the object to be
identified as static that do not establish the original background but appeared
in the video at different time. In this context, background subtraction
technique based on the frame difference concept is applied to the
identification of static objects. Firstly, we estimate a frame differencing
foreground mask image by computing the difference of each frame with respect to
a static reference frame. The Mixture of Gaussian MOG method is applied to
detect the moving particles and then outcome foreground mask is subtracted from
frame differencing foreground mask. Pre-processing techniques, illumination
equalization and de-hazing methods are applied to handle low contrast and to
reduce the noise from scattered materials in the air e.g. water droplets and
dust particles. Finally, a set of mathematical morphological operation and
largest connected-component analysis is applied to segment the object and
suppress the noise. The proposed method was built for rock breaker station
application and effectively validated with real, synthetic and two public data
sets. The results demonstrate the proposed approach can robustly detect,
segmented the static objects without any prior information of tracking.
</p>
<a href="http://arxiv.org/abs/2012.10708" target="_blank">arXiv:2012.10708</a> [<a href="http://arxiv.org/pdf/2012.10708" target="_blank">pdf</a>]

<h2>Fundamental Limits and Tradeoffs in Invariant Representation Learning. (arXiv:2012.10713v1 [cs.LG])</h2>
<h3>Han Zhao, Chen Dan, Bryon Aragam, Tommi S. Jaakkola, Geoffrey J. Gordon, Pradeep Ravikumar</h3>
<p>Many machine learning applications involve learning representations that
achieve two competing goals: To maximize information or accuracy with respect
to a subset of features (e.g.\ for prediction) while simultaneously maximizing
invariance or independence with respect to another, potentially overlapping,
subset of features (e.g.\ for fairness, privacy, etc). Typical examples include
privacy-preserving learning, domain adaptation, and algorithmic fairness, just
to name a few. In fact, all of the above problems admit a common minimax
game-theoretic formulation, whose equilibrium represents a fundamental tradeoff
between accuracy and invariance. Despite its abundant applications in the
aforementioned domains, theoretical understanding on the limits and tradeoffs
of invariant representations is severely lacking.

In this paper, we provide an information-theoretic analysis of this general
and important problem under both classification and regression settings. In
both cases, we analyze the inherent tradeoffs between accuracy and invariance
by providing a geometric characterization of the feasible region in the
information plane, where we connect the geometric properties of this feasible
region to the fundamental limitations of the tradeoff problem. In the
regression setting, we also derive a tight lower bound on the Lagrangian
objective that quantifies the tradeoff between accuracy and invariance. This
lower bound leads to a better understanding of the tradeoff via the spectral
properties of the joint distribution. In both cases, our results shed new light
on this fundamental problem by providing insights on the interplay between
accuracy and invariance. These results deepen our understanding of this
fundamental problem and may be useful in guiding the design of adversarial
representation learning algorithms.
</p>
<a href="http://arxiv.org/abs/2012.10713" target="_blank">arXiv:2012.10713</a> [<a href="http://arxiv.org/pdf/2012.10713" target="_blank">pdf</a>]

<h2>A Light Field Front-end for Robust SLAM in Dynamic Environments. (arXiv:2012.10714v1 [cs.RO])</h2>
<h3>Pushyami Kaveti, Hanumant Singh</h3>
<p>There is a general expectation that robots should operate in urban
environments often consisting of potentially dynamic entities including people,
furniture and automobiles. Dynamic objects pose challenges to visual SLAM
algorithms by introducing errors into the front-end. This paper presents a
Light Field SLAM front-end which is robust to dynamic environments. A Light
Field captures a bundle of light rays emerging from a single point in space,
allowing us to see through dynamic objects occluding the static background via
Synthetic Aperture Imaging(SAI). We detect apriori dynamic objects using
semantic segmentation and perform semantic guided SAI on the Light Field
acquired from a linear camera array. We simultaneously estimate both the depth
map and the refocused image of the static background in a single step
eliminating the need for static scene initialization. The GPU implementation of
the algorithm facilitates running at close to real time speeds of 4 fps. We
demonstrate that our method results in improved robustness and accuracy of pose
estimation in dynamic environments by comparing it with state of the art SLAM
algorithms.
</p>
<a href="http://arxiv.org/abs/2012.10714" target="_blank">arXiv:2012.10714</a> [<a href="http://arxiv.org/pdf/2012.10714" target="_blank">pdf</a>]

<h2>Model-Based Actor-Critic with Chance Constraint for Stochastic System. (arXiv:2012.10716v1 [cs.LG])</h2>
<h3>Baiyu Peng, Yao Mu, Yang Guan, Shengbo Eben Li, Yuming Yin, Jianyu Chen</h3>
<p>Safety constraints are essential for reinforcement learning (RL) applied in
real-world situations. Chance constraints are suitable to represent the safety
requirements in stochastic systems. Most existing RL methods with chance
constraints have a low convergence rate, and only learn a conservative policy.
In this paper, we propose a model-based chance constrained actor-critic (CCAC)
algorithm which can efficiently learn a safe and non-conservative policy.
Different from existing methods that optimize a conservative lower bound, CCAC
directly solves the original chance constrained problems, where the objective
function and safe probability is simultaneously optimized with adaptive
weights. In order to improve the convergence rate, CCAC utilizes the gradient
of dynamic model to accelerate policy optimization. The effectiveness of CCAC
is demonstrated by an aggressive car-following task. Experiments indicate that
compared with previous methods, CCAC improves the performance by 57.6% while
guaranteeing safety, with a five times faster convergence rate.
</p>
<a href="http://arxiv.org/abs/2012.10716" target="_blank">arXiv:2012.10716</a> [<a href="http://arxiv.org/pdf/2012.10716" target="_blank">pdf</a>]

<h2>Analysis of NARXNN for State of Charge Estimation for Li-ion Batteries on various Drive Cycles. (arXiv:2012.10725v1 [cs.LG])</h2>
<h3>Aniruddh Herle, Janamejaya Channegowda, Kali Naraharisetti</h3>
<p>Electric Vehicles (EVs) are rapidly increasing in popularity as they are
environment friendly. Lithium Ion batteries are at the heart of EV technology
and contribute to most of the weight and cost of an EV. State of Charge (SOC)
is a very important metric which helps to predict the range of an EV. There is
a need to accurately estimate available battery capacity in a battery pack such
that the available range in a vehicle can be determined. There are various
techniques available to estimate SOC. In this paper, a data driven approach is
selected and a Nonlinear Autoregressive Network with Exogenous Inputs Neural
Network (NARXNN) is explored to accurately estimate SOC. NARXNN has been shown
to be superior to conventional Machine Learning techniques available in the
literature. The NARXNN model is developed and tested on various EV Drive Cycles
like LA92, US06, UDDS and HWFET to test its performance on real world
scenarios. The model is shown to outperform conventional statistical machine
learning methods and achieve a Mean Squared Error (MSE) in the 1e-5 range.
</p>
<a href="http://arxiv.org/abs/2012.10725" target="_blank">arXiv:2012.10725</a> [<a href="http://arxiv.org/pdf/2012.10725" target="_blank">pdf</a>]

<h2>Political Posters Identification with Appearance-Text Fusion. (arXiv:2012.10728v1 [cs.CV])</h2>
<h3>Xuan Qin, Meizhu Liu, Yifan Hu, Christina Moo, Christian M. Riblet, Changwei Hu, Kevin Yen, Haibin Ling</h3>
<p>In this paper, we propose a method that efficiently utilizes appearance
features and text vectors to accurately classify political posters from other
similar political images. The majority of this work focuses on political
posters that are designed to serve as a promotion of a certain political event,
and the automated identification of which can lead to the generation of
detailed statistics and meets the judgment needs in a variety of areas.
Starting with a comprehensive keyword list for politicians and political
events, we curate for the first time an effective and practical political
poster dataset containing 13K human-labeled political images, including 3K
political posters that explicitly support a movement or a campaign. Second, we
make a thorough case study for this dataset and analyze common patterns and
outliers of political posters. Finally, we propose a model that combines the
power of both appearance and text information to classify political posters
with significantly high accuracy.
</p>
<a href="http://arxiv.org/abs/2012.10728" target="_blank">arXiv:2012.10728</a> [<a href="http://arxiv.org/pdf/2012.10728" target="_blank">pdf</a>]

<h2>(Decision and regression) tree ensemble based kernels for regression and classification. (arXiv:2012.10737v1 [stat.ML])</h2>
<h3>Dai Feng, Richard Baumgartner</h3>
<p>Tree based ensembles such as Breiman's random forest (RF) and Gradient
Boosted Trees (GBT) can be interpreted as implicit kernel generators, where the
ensuing proximity matrix represents the data-driven tree ensemble kernel.
Kernel perspective on the RF has been used to develop a principled framework
for theoretical investigation of its statistical properties. Recently, it has
been shown that the kernel interpretation is germane to other tree-based
ensembles e.g. GBTs. However, practical utility of the links between kernels
and the tree ensembles has not been widely explored and systematically
evaluated.

Focus of our work is investigation of the interplay between kernel methods
and the tree based ensembles including the RF and GBT. We elucidate the
performance and properties of the RF and GBT based kernels in a comprehensive
simulation study comprising of continuous and binary targets. We show that for
continuous targets, the RF/GBT kernels are competitive to their respective
ensembles in higher dimensional scenarios, particularly in cases with larger
number of noisy features. For the binary target, the RF/GBT kernels and their
respective ensembles exhibit comparable performance. We provide the results
from real life data sets for regression and classification to show how these
insights may be leveraged in practice. Overall, our results support the tree
ensemble based kernels as a valuable addition to the practitioner's toolbox.

Finally, we discuss extensions of the tree ensemble based kernels for
survival targets, interpretable prototype and landmarking classification and
regression. We outline future line of research for kernels furnished by
Bayesian counterparts of the frequentist tree ensembles.
</p>
<a href="http://arxiv.org/abs/2012.10737" target="_blank">arXiv:2012.10737</a> [<a href="http://arxiv.org/pdf/2012.10737" target="_blank">pdf</a>]

<h2>GlocalNet: Class-aware Long-term Human Motion Synthesis. (arXiv:2012.10744v1 [cs.CV])</h2>
<h3>Neeraj Battan, Yudhik Agrawal, Veeravalli Saisooryarao, Aman Goel, Avinash Sharma</h3>
<p>Synthesis of long-term human motion skeleton sequences is essential to aid
human-centric video generation with potential applications in Augmented
Reality, 3D character animations, pedestrian trajectory prediction, etc.
Long-term human motion synthesis is a challenging task due to multiple factors
like, long-term temporal dependencies among poses, cyclic repetition across
poses, bi-directional and multi-scale dependencies among poses, variable speed
of actions, and a large as well as partially overlapping space of temporal pose
variations across multiple class/types of human activities. This paper aims to
address these challenges to synthesize a long-term (&gt; 6000 ms) human motion
trajectory across a large variety of human activity classes (&gt;50). We propose a
two-stage activity generation method to achieve this goal, where the first
stage deals with learning the long-term global pose dependencies in activity
sequences by learning to synthesize a sparse motion trajectory while the second
stage addresses the generation of dense motion trajectories taking the output
of the first stage. We demonstrate the superiority of the proposed method over
SOTA methods using various quantitative evaluation metrics on publicly
available datasets.
</p>
<a href="http://arxiv.org/abs/2012.10744" target="_blank">arXiv:2012.10744</a> [<a href="http://arxiv.org/pdf/2012.10744" target="_blank">pdf</a>]

<h2>Image-based Intraluminal Contact Force Monitoring in Robotic Vascular Navigation. (arXiv:2012.10762v1 [cs.RO])</h2>
<h3>Masoud Razban, Javad Dargahi, Benoit Boulet</h3>
<p>Embolization, stroke, ischaemic lesion, and perforation remain significant
concerns in endovascular interventions. Sensing catheter interaction inside the
artery is advantageous to minimize such complications and enhances navigation
safety. Intraluminal information is currently limited due to the lack of
intravascular contact sensing technologies. We present monitoring of the
intraluminal catheter interaction with the arterial wall using an image-based
estimation approach within vascular robotic navigation. The proposed
image-based method employs continuous finite element simulation of the catheter
motion using imaging data to estimate multi-point forces along catheter-vessel
interaction. We implemented imaging algorithms to detect and track contacts and
compute catheter pose measurements. The catheter model is constructed based on
the nonlinear beam element and flexural rigidity distribution. During remote
cannulation of aortic arteries, intraluminal monitoring achieved tracking local
contact forces, building contour map of force on the arterial wall, and
estimating structural stress of catheter. Shape estimation error was within 2%
range. Results suggest that high-risk intraluminal forces may happen even in
low insertion forces. The presented online monitoring tool delivers insight
into the intraluminal behavior of catheters and is well-suited for
intraoperative visual guidance of clinicians, robotic control vascular system,
and optimizing interventional device design.
</p>
<a href="http://arxiv.org/abs/2012.10762" target="_blank">arXiv:2012.10762</a> [<a href="http://arxiv.org/pdf/2012.10762" target="_blank">pdf</a>]

<h2>Augmentation Inside the Network. (arXiv:2012.10769v1 [cs.CV])</h2>
<h3>Maciej Sypetkowski, Jakub Jasiulewicz, Zbigniew Wojna</h3>
<p>In this paper, we present augmentation inside the network, a method that
simulates data augmentation techniques for computer vision problems on
intermediate features of a convolutional neural network. We perform these
transformations, changing the data flow through the network, and sharing common
computations when it is possible. Our method allows us to obtain smoother
speed-accuracy trade-off adjustment and achieves better results than using
standard test-time augmentation (TTA) techniques. Additionally, our approach
can improve model performance even further when coupled with test-time
augmentation. We validate our method on the ImageNet-2012 and CIFAR-100
datasets for image classification. We propose a modification that is 30% faster
than the flip test-time augmentation and achieves the same results for
CIFAR-100.
</p>
<a href="http://arxiv.org/abs/2012.10769" target="_blank">arXiv:2012.10769</a> [<a href="http://arxiv.org/pdf/2012.10769" target="_blank">pdf</a>]

<h2>Optimising Placement of Pollution Sensors in Windy Environments. (arXiv:2012.10770v1 [cs.LG])</h2>
<h3>Sigrid Passano Hellan, Christopher G. Lucas, Nigel H. Goddard</h3>
<p>Air pollution is one of the most important causes of mortality in the world.
Monitoring air pollution is useful to learn more about the link between health
and pollutants, and to identify areas for intervention. Such monitoring is
expensive, so it is important to place sensors as efficiently as possible.
Bayesian optimisation has proven useful in choosing sensor locations, but
typically relies on kernel functions that neglect the statistical structure of
air pollution, such as the tendency of pollution to propagate in the prevailing
wind direction. We describe two new wind-informed kernels and investigate their
advantage for the task of actively learning locations of maximum pollution
using Bayesian optimisation.
</p>
<a href="http://arxiv.org/abs/2012.10770" target="_blank">arXiv:2012.10770</a> [<a href="http://arxiv.org/pdf/2012.10770" target="_blank">pdf</a>]

<h2>Forming Human-Robot Cooperation for Tasks with General Goal using Evolutionary Value Learning. (arXiv:2012.10773v1 [cs.RO])</h2>
<h3>Lingfeng Tao, Michael Bowman, Jiucai Zhang, Xiaoli Zhang</h3>
<p>In human-robot cooperation, the robot cooperates with the human to accomplish
the task together. Existing approaches assume the human has a specific goal
during the cooperation, and the robot infers and acts toward it. However, in
real-world environments, a human usually only has a general goal (e.g., general
direction or area in motion planning) at the beginning of the cooperation which
needs to be clarified to a specific goal (e.g., an exact position) during
cooperation. The specification process is interactive and dynamic, which
depends on the environment and the behavior of the partners. The robot that
does not consider the goal specification process may cause frustration to the
human partner, elongate the time to come to an agreement, and compromise or
fail team performance. We present Evolutionary Value Learning (EVL) approach
which uses a State-based Multivariate Bayesian Inference method to model the
dynamics of goal specification process in HRC, and an Evolutionary Value
Updating method to actively enhance the process of goal specification and
cooperation formation. This enables the robot to simultaneously help the human
to specify the goal and learn a cooperative policy in a Reinforcement Learning
manner. In experiments with real human subjects, the robot equipped with EVL
outperforms existing methods with faster goal specification processes and
better team performance.
</p>
<a href="http://arxiv.org/abs/2012.10773" target="_blank">arXiv:2012.10773</a> [<a href="http://arxiv.org/pdf/2012.10773" target="_blank">pdf</a>]

<h2>Three Ways to Improve Semantic Segmentation with Self-Supervised Depth Estimation. (arXiv:2012.10782v1 [cs.CV])</h2>
<h3>Lukas Hoyer, Dengxin Dai, Yuhua Chen, Adrian K&#xf6;ring, Suman Saha, Luc Van Gool</h3>
<p>Training deep networks for semantic segmentation requires large amounts of
labeled training data, which presents a major challenge in practice, as
labeling segmentation masks is a highly labor-intensive process. To address
this issue, we present a framework for semi-supervised semantic segmentation,
which is enhanced by self-supervised monocular depth estimation from unlabeled
images. In particular, we propose three key contributions: (1) We transfer
knowledge from features learned during self-supervised depth estimation to
semantic segmentation, (2) we implement a strong data augmentation by blending
images and labels using the structure of the scene, and (3) we utilize the
depth feature diversity as well as the level of difficulty of learning depth in
a student-teacher framework to select the most useful samples to be annotated
for semantic segmentation. We validate the proposed model on the Cityscapes
dataset, where all three modules demonstrate significant performance gains, and
we achieve state-of-the-art results for semi-supervised semantic segmentation.
The implementation is available at
https://github.com/lhoyer/improving_segmentation_with_selfsupervised_depth.
</p>
<a href="http://arxiv.org/abs/2012.10782" target="_blank">arXiv:2012.10782</a> [<a href="http://arxiv.org/pdf/2012.10782" target="_blank">pdf</a>]

<h2>Rapid and High-Fidelity Subsurface Exploration with Multiple Aerial Robots. (arXiv:2012.10788v1 [cs.RO])</h2>
<h3>Kshitij Goel, Wennie Tabib, Nathan Michael</h3>
<p>This paper develops a communication-efficient distributed mapping approach
for rapid exploration of a cave by a multi-robot team. Subsurface planetary
exploration is an unsolved problem challenged by communication, power, and
compute constraints. Prior works have addressed the problems of rapid
exploration and leveraging multiple systems to increase exploration rate;
however, communication considerations have been left largely unaddressed. This
paper bridges this gap in the state of the art by developing distributed
perceptual modeling that enables high-fidelity mapping while remaining amenable
to low-bandwidth communication channels. The approach yields significant gains
in exploration rate for multi-robot teams as compared to state-of-the-art
approaches. The work is evaluated through simulation studies and hardware
experiments in a wild cave in West Virginia.
</p>
<a href="http://arxiv.org/abs/2012.10788" target="_blank">arXiv:2012.10788</a> [<a href="http://arxiv.org/pdf/2012.10788" target="_blank">pdf</a>]

<h2>Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region Approach. (arXiv:2012.10791v1 [cs.LG])</h2>
<h3>James Queeney, Ioannis Ch. Paschalidis, Christos G. Cassandras</h3>
<p>In order for reinforcement learning techniques to be useful in real-world
decision making processes, they must be able to produce robust performance from
limited data. Deep policy optimization methods have achieved impressive results
on complex tasks, but their real-world adoption remains limited because they
often require significant amounts of data to succeed. When combined with small
sample sizes, these methods can result in unstable learning due to their
reliance on high-dimensional sample-based estimates. In this work, we develop
techniques to control the uncertainty introduced by these estimates. We
leverage these techniques to propose a deep policy optimization approach
designed to produce stable performance even when data is scarce. The resulting
algorithm, Uncertainty-Aware Trust Region Policy Optimization, generates robust
policy updates that adapt to the level of uncertainty present throughout the
learning process.
</p>
<a href="http://arxiv.org/abs/2012.10791" target="_blank">arXiv:2012.10791</a> [<a href="http://arxiv.org/pdf/2012.10791" target="_blank">pdf</a>]

<h2>On the Power of Localized Perceptron for Label-Optimal Learning of Halfspaces with Adversarial Noise. (arXiv:2012.10793v1 [cs.LG])</h2>
<h3>Jie Shen</h3>
<p>We study {\em online} active learning of homogeneous $s$-sparse halfspaces in
$\mathbb{R}^d$ with adversarial noise \cite{kearns1992toward}, where the
overall probability of a noisy label is constrained to be at most $\nu$ and the
marginal distribution over unlabeled data is unchanged. Our main contribution
is a state-of-the-art online active learning algorithm that achieves
near-optimal attribute efficiency, label and sample complexity under mild
distributional assumptions. In particular, under the conditions that the
marginal distribution is isotropic log-concave and $\nu = \Omega(\epsilon)$,
where $\epsilon \in (0, 1)$ is the target error rate, we show that our
algorithm PAC learns the underlying halfspace in polynomial time with
near-optimal label complexity bound of $\tilde{O}\big(s \cdot polylog(d,
\frac{1}{\epsilon})\big)$ and sample complexity bound of
$\tilde{O}\big(\frac{s}{\epsilon} \cdot polylog(d)\big)$. Prior to this work,
existing online algorithms designed for tolerating the adversarial noise are
either subject to label complexity polynomial in $d$ or $\frac{1}{\epsilon}$,
or work under the restrictive uniform marginal distribution. As an immediate
corollary of our main result, we show that under the more challenging agnostic
model \cite{kearns1992toward} where no assumption is made on the noise rate,
our active learner achieves an error rate of $O(OPT) + \epsilon$ with the same
running time and label and sample complexity, where $OPT$ is the best possible
error rate achievable by any homogeneous $s$-sparse halfspace. Our algorithm
builds upon the celebrated Perceptron while leveraging novel localized sampling
and semi-random gradient update to tolerate the adversarial noise. We believe
that our algorithmic design and analysis are of independent interest, and may
shed light on learning halfspaces with broader noise models.
</p>
<a href="http://arxiv.org/abs/2012.10793" target="_blank">arXiv:2012.10793</a> [<a href="http://arxiv.org/pdf/2012.10793" target="_blank">pdf</a>]

<h2>Sample Complexity of Adversarially Robust Linear Classification on Separated Data. (arXiv:2012.10794v1 [cs.LG])</h2>
<h3>Robi Bhattacharjee, Somesh Jha, Kamalika Chaudhuri</h3>
<p>We consider the sample complexity of learning with adversarial robustness.
Most prior theoretical results for this problem have considered a setting where
different classes in the data are close together or overlapping. Motivated by
some real applications, we consider, in contrast, the well-separated case where
there exists a classifier with perfect accuracy and robustness, and show that
the sample complexity narrates an entirely different story. Specifically, for
linear classifiers, we show a large class of well-separated distributions where
the expected robust loss of any algorithm is at least $\Omega(\frac{d}{n})$,
whereas the max margin algorithm has expected standard loss $O(\frac{1}{n})$.
This shows a gap in the standard and robust losses that cannot be obtained via
prior techniques. Additionally, we present an algorithm that, given an instance
where the robustness radius is much smaller than the gap between the classes,
gives a solution with expected robust loss is $O(\frac{1}{n})$. This shows that
for very well-separated data, convergence rates of $O(\frac{1}{n})$ are
achievable, which is not the case otherwise. Our results apply to robustness
measured in any $\ell_p$ norm with $p &gt; 1$ (including $p = \infty$).
</p>
<a href="http://arxiv.org/abs/2012.10794" target="_blank">arXiv:2012.10794</a> [<a href="http://arxiv.org/pdf/2012.10794" target="_blank">pdf</a>]

<h2>Probabilistic Dependency Graphs. (arXiv:2012.10800v1 [cs.AI])</h2>
<h3>Oliver Richardson, Joseph Y Halpern</h3>
<p>We introduce Probabilistic Dependency Graphs (PDGs), a new class of directed
graphical models. PDGs can capture inconsistent beliefs in a natural way and
are more modular than Bayesian Networks (BNs), in that they make it easier to
incorporate new information and restructure the representation. We show by
example how PDGs are an especially natural modeling tool. We provide three
semantics for PDGs, each of which can be derived from a scoring function (on
joint distributions over the variables in the network) that can be viewed as
representing a distribution's incompatibility with the PDG. For the PDG
corresponding to a BN, this function is uniquely minimized by the distribution
the BN represents, showing that PDG semantics extend BN semantics. We show
further that factor graphs and their exponential families can also be
faithfully represented as PDGs, while there are significant barriers to
modeling a PDG with a factor graph.
</p>
<a href="http://arxiv.org/abs/2012.10800" target="_blank">arXiv:2012.10800</a> [<a href="http://arxiv.org/pdf/2012.10800" target="_blank">pdf</a>]

<h2>Rethinking Road Surface 3D Reconstruction and Pothole Detection: From Perspective Transformation to Disparity Map Segmentation. (arXiv:2012.10802v1 [cs.CV])</h2>
<h3>Rui Fan, Umar Ozgunalp, Yuan Wang, Ming Liu, Ioannis Pitas</h3>
<p>Potholes are one of the most common forms of road damage, which can severely
affect driving comfort, road safety and vehicle condition. Pothole detection is
typically performed by either structural engineers or certified inspectors.
This task is, however, not only hazardous for the personnel but also extremely
time-consuming. This paper presents an efficient pothole detection algorithm
based on road disparity map estimation and segmentation. We first generalize
the perspective transformation by incorporating the stereo rig roll angle. The
road disparities are then estimated using semi-global matching. A disparity map
transformation algorithm is then performed to better distinguish the damaged
road areas. Finally, we utilize simple linear iterative clustering to group the
transformed disparities into a collection of superpixels. The potholes are then
detected by finding the superpixels, whose values are lower than an adaptively
determined threshold. The proposed algorithm is implemented on an NVIDIA RTX
2080 Ti GPU in CUDA. The experiments demonstrate the accuracy and efficiency of
our proposed road pothole detection algorithm, where an accuracy of 99.6% and
an F-score of 89.4% are achieved.
</p>
<a href="http://arxiv.org/abs/2012.10802" target="_blank">arXiv:2012.10802</a> [<a href="http://arxiv.org/pdf/2012.10802" target="_blank">pdf</a>]

<h2>Quantum Optical Convolutional Neural Network: A Novel Image Recognition Framework for Quantum Computing. (arXiv:2012.10812v1 [cs.CV])</h2>
<h3>Rishab Parthasarathy, Rohan Bhowmik</h3>
<p>Large machine learning models based on Convolutional Neural Networks (CNNs)
with rapidly increasing number of parameters, trained with massive amounts of
data, are being deployed in a wide array of computer vision tasks from
self-driving cars to medical imaging. The insatiable demand for computing
resources required to train these models is fast outpacing the advancement of
classical computing hardware, and new frameworks including Optical Neural
Networks (ONNs) and quantum computing are being explored as future
alternatives.

In this work, we report a novel quantum computing based deep learning model,
the Quantum Optical Convolutional Neural Network (QOCNN), to alleviate the
computational bottleneck in future computer vision applications. Using the
popular MNIST dataset, we have benchmarked this new architecture against a
traditional CNN based on the seminal LeNet model. We have also compared the
performance with previously reported ONNs, namely the GridNet and ComplexNet,
as well as a Quantum Optical Neural Network (QONN) that we built by combining
the ComplexNet with quantum based sinusoidal nonlinearities. In essence, our
work extends the prior research on QONN by adding quantum convolution and
pooling layers preceding it.

We have evaluated all the models by determining their accuracies, confusion
matrices, Receiver Operating Characteristic (ROC) curves, and Matthews
Correlation Coefficients. The performance of the models were similar overall,
and the ROC curves indicated that the new QOCNN model is robust. Finally, we
estimated the gains in computational efficiencies from executing this novel
framework on a quantum computer. We conclude that switching to a quantum
computing based approach to deep learning may result in comparable accuracies
to classical models, while achieving unprecedented boosts in computational
performances and drastic reduction in power consumption.
</p>
<a href="http://arxiv.org/abs/2012.10812" target="_blank">arXiv:2012.10812</a> [<a href="http://arxiv.org/pdf/2012.10812" target="_blank">pdf</a>]

<h2>AdnFM: An Attentive DenseNet based Factorization Machine for CTR Prediction. (arXiv:2012.10820v1 [cs.AI])</h2>
<h3>Kai Wang, Chunxu Shen, Wenye Ma</h3>
<p>In this paper, we consider the Click-Through-Rate (CTR) prediction problem.
Factorization Machines and their variants consider pair-wise feature
interactions, but normally we won't do high-order feature interactions using FM
due to high time complexity. Given the success of deep neural networks (DNNs)
in many fields, researchers have proposed several DNN-based models to learn
high-order feature interactions. Multi-layer perceptrons (MLP) have been widely
employed to learn reliable mappings from feature embeddings to final logits. In
this paper, we aim to explore more about these high-order features
interactions. However, high-order feature interaction deserves more attention
and further development. Inspired by the great achievements of Densely
Connected Convolutional Networks (DenseNet) in computer vision, we propose a
novel model called Attentive DenseNet based Factorization Machines (AdnFM).
AdnFM can extract more comprehensive deep features by using all the hidden
layers from a feed-forward neural network as implicit high-order features, then
selects dominant features via an attention mechanism. Also, high-order
interactions in the implicit way using DNNs are more cost-efficient than in the
explicit way, for example in FM. Extensive experiments on two real-world
datasets show that the proposed model can effectively improve the performance
of CTR prediction.
</p>
<a href="http://arxiv.org/abs/2012.10820" target="_blank">arXiv:2012.10820</a> [<a href="http://arxiv.org/pdf/2012.10820" target="_blank">pdf</a>]

<h2>Transductive Visual Verb Sense Disambiguation. (arXiv:2012.10821v1 [cs.CV])</h2>
<h3>Sebastiano Vascon, Sinem Aslan, Gianluca Bigaglia, Lorenzo Giudice, Marcello Pelillo</h3>
<p>Verb Sense Disambiguation is a well-known task in NLP, the aim is to find the
correct sense of a verb in a sentence. Recently, this problem has been extended
in a multimodal scenario, by exploiting both textual and visual features of
ambiguous verbs leading to a new problem, the Visual Verb Sense Disambiguation
(VVSD). Here, the sense of a verb is assigned considering the content of an
image paired with it rather than a sentence in which the verb appears.
Annotating a dataset for this task is more complex than textual disambiguation,
because assigning the correct sense to a pair of $&lt;$image, verb$&gt;$ requires
both non-trivial linguistic and visual skills. In this work, differently from
the literature, the VVSD task will be performed in a transductive
semi-supervised learning (SSL) setting, in which only a small amount of labeled
information is required, reducing tremendously the need for annotated data. The
disambiguation process is based on a graph-based label propagation method which
takes into account mono or multimodal representations for $&lt;$image, verb$&gt;$
pairs. Experiments have been carried out on the recently published dataset
VerSe, the only available dataset for this task. The achieved results
outperform the current state-of-the-art by a large margin while using only a
small fraction of labeled samples per sense. Code available:
https://github.com/GiBg1aN/TVVSD.
</p>
<a href="http://arxiv.org/abs/2012.10821" target="_blank">arXiv:2012.10821</a> [<a href="http://arxiv.org/pdf/2012.10821" target="_blank">pdf</a>]

<h2>Suspicious Massive Registration Detection via Dynamic Heterogeneous Graph Neural Networks. (arXiv:2012.10831v1 [cs.LG])</h2>
<h3>Susie Xi Rao, Shuai Zhang, Zhichao Han, Zitao Zhang, Wei Min, Mo Cheng, Yinan Shan, Yang Zhao, Ce Zhang</h3>
<p>Massive account registration has raised concerns on risk management in
e-commerce companies, especially when registration increases rapidly within a
short time frame. To monitor these registrations constantly and minimize the
potential loss they might incur, detecting massive registration and predicting
their riskiness are necessary. In this paper, we propose a Dynamic
Heterogeneous Graph Neural Network framework to capture suspicious massive
registrations (DHGReg). We first construct a dynamic heterogeneous graph from
the registration data, which is composed of a structural subgraph and a
temporal subgraph. Then, we design an efficient architecture to predict
suspicious/benign accounts. Our proposed model outperforms the baseline models
and is computationally efficient in processing a dynamic heterogeneous graph
constructed from a real-world dataset. In practice, the DHGReg framework would
benefit the detection of suspicious registration behaviors at an early stage.
</p>
<a href="http://arxiv.org/abs/2012.10831" target="_blank">arXiv:2012.10831</a> [<a href="http://arxiv.org/pdf/2012.10831" target="_blank">pdf</a>]

<h2>Analyzing the Performance of Graph Neural Networks with Pipe Parallelism. (arXiv:2012.10840v1 [cs.LG])</h2>
<h3>Matthew T. Dearing, Xiaoyan (Angela) Wang</h3>
<p>Many interesting datasets ubiquitous in machine learning and deep learning
can be described via graphs. As the scale and complexity of graph-structured
datasets increase, such as in expansive social networks, protein folding,
chemical interaction networks, and material phase transitions, improving the
efficiency of the machine learning techniques applied to these is crucial. In
this study, we focus on Graph Neural Networks (GNN), which have found great
success in tasks such as node or edge classification and link prediction.
However, standard GNN models have scaling limits due to necessary recursive
calculations performed through dense graph relationships that lead to memory
and runtime bottlenecks. While new approaches for processing larger networks
are needed to advance graph techniques, and several have been proposed, we
study how GNNs could be parallelized using existing tools and frameworks that
are already known to be successful in the deep learning community. In
particular, we investigate applying pipeline parallelism to GNN models with
GPipe, introduced by Google in 2018.
</p>
<a href="http://arxiv.org/abs/2012.10840" target="_blank">arXiv:2012.10840</a> [<a href="http://arxiv.org/pdf/2012.10840" target="_blank">pdf</a>]

<h2>PTN: A Poisson Transfer Network for Semi-supervised Few-shot Learning. (arXiv:2012.10844v1 [cs.CV])</h2>
<h3>Huaxi Huang, Junjie Zhang, Jian Zhang, Qiang Wu, Chang Xu</h3>
<p>The predicament in semi-supervised few-shot learning (SSFSL) is to maximize
the value of the extra unlabeled data to boost the few-shot learner. In this
paper, we propose a Poisson Transfer Network (PTN) to mine the unlabeled
information for SSFSL from two aspects. First, the Poisson Merriman Bence Osher
(MBO) model builds a bridge for the communications between labeled and
unlabeled examples. This model serves as a more stable and informative
classifier than traditional graph-based SSFSL methods in the message-passing
process of the labels. Second, the extra unlabeled samples are employed to
transfer the knowledge from base classes to novel classes through contrastive
learning. Specifically, we force the augmented positive pairs close while push
the negative ones distant. Our contrastive transfer scheme implicitly learns
the novel-class embeddings to alleviate the over-fitting problem on the few
labeled data. Thus, we can mitigate the degeneration of embedding generality in
novel classes. Extensive experiments indicate that PTN outperforms the
state-of-the-art few-shot and SSFSL models on miniImageNet and tieredImageNet
benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2012.10844" target="_blank">arXiv:2012.10844</a> [<a href="http://arxiv.org/pdf/2012.10844" target="_blank">pdf</a>]

<h2>Visual Speech Enhancement Without A Real Visual Stream. (arXiv:2012.10852v1 [cs.CV])</h2>
<h3>Sindhu B Hegde, K R Prajwal, Rudrabha Mukhopadhyay, Vinay Namboodiri, C.V. Jawahar</h3>
<p>In this work, we re-think the task of speech enhancement in unconstrained
real-world environments. Current state-of-the-art methods use only the audio
stream and are limited in their performance in a wide range of real-world
noises. Recent works using lip movements as additional cues improve the quality
of generated speech over "audio-only" methods. But, these methods cannot be
used for several applications where the visual stream is unreliable or
completely absent. We propose a new paradigm for speech enhancement by
exploiting recent breakthroughs in speech-driven lip synthesis. Using one such
model as a teacher network, we train a robust student network to produce
accurate lip movements that mask away the noise, thus acting as a "visual noise
filter". The intelligibility of the speech enhanced by our pseudo-lip approach
is comparable (&lt; 3% difference) to the case of using real lips. This implies
that we can exploit the advantages of using lip movements even in the absence
of a real video stream. We rigorously evaluate our model using quantitative
metrics as well as human evaluations. Additional ablation studies and a demo
video on our website containing qualitative comparisons and results clearly
illustrate the effectiveness of our approach. We provide a demo video which
clearly illustrates the effectiveness of our proposed approach on our website:
\url{this http URL}.
The code and models are also released for future research:
\url{https://github.com/Sindhu-Hegde/pseudo-visual-speech-denoising}.
</p>
<a href="http://arxiv.org/abs/2012.10852" target="_blank">arXiv:2012.10852</a> [<a href="http://arxiv.org/pdf/2012.10852" target="_blank">pdf</a>]

<h2>eTREE: Learning Tree-structured Embeddings. (arXiv:2012.10853v1 [cs.LG])</h2>
<h3>Faisal M. Almutairi, Yunlong Wang, Dong Wang, Emily Zhao, Nicholas D. Sidiropoulos</h3>
<p>Matrix factorization (MF) plays an important role in a wide range of machine
learning and data mining models. MF is commonly used to obtain item embeddings
and feature representations due to its ability to capture correlations and
higher-order statistical dependencies across dimensions. In many applications,
the categories of items exhibit a hierarchical tree structure. For instance,
human diseases can be divided into coarse categories, e.g., bacterial, and
viral. These categories can be further divided into finer categories, e.g.,
viral infections can be respiratory, gastrointestinal, and exanthematous viral
diseases. In e-commerce, products, movies, books, etc., are grouped into
hierarchical categories, e.g., clothing items are divided by gender, then by
type (formal, casual, etc.). While the tree structure and the categories of the
different items may be known in some applications, they have to be learned
together with the embeddings in many others. In this work, we propose eTREE, a
model that incorporates the (usually ignored) tree structure to enhance the
quality of the embeddings. We leverage the special uniqueness properties of
Nonnegative MF (NMF) to prove identifiability of eTREE. The proposed model not
only exploits the tree structure prior, but also learns the hierarchical
clustering in an unsupervised data-driven fashion. We derive an efficient
algorithmic solution and a scalable implementation of eTREE that exploits
parallel computing, computation caching, and warm start strategies. We showcase
the effectiveness of eTREE on real data from various application domains:
healthcare, recommender systems, and education. We also demonstrate the
meaningfulness of the tree obtained from eTREE by means of domain experts
interpretation.
</p>
<a href="http://arxiv.org/abs/2012.10853" target="_blank">arXiv:2012.10853</a> [<a href="http://arxiv.org/pdf/2012.10853" target="_blank">pdf</a>]

<h2>Geometric Scene Refocusing. (arXiv:2012.10856v1 [cs.CV])</h2>
<h3>Parikshit Sakurikar, P. J. Narayanan</h3>
<p>An image captured with a wide-aperture camera exhibits a finite
depth-of-field, with focused and defocused pixels. A compact and robust
representation of focus and defocus helps analyze and manipulate such images.
In this work, we study the fine characteristics of images with a shallow
depth-of-field in the context of focal stacks. We present a composite measure
for focus that is a combination of existing measures. We identify in-focus
pixels, dual-focus pixels, pixels that exhibit bokeh and spatially-varying blur
kernels between focal slices. We use these to build a novel representation that
facilitates easy manipulation of focal stacks. We present a comprehensive
algorithm for post-capture refocusing in a geometrically correct manner. Our
approach can refocus the scene at high fidelity while preserving fine aspects
of focus and defocus blur.
</p>
<a href="http://arxiv.org/abs/2012.10856" target="_blank">arXiv:2012.10856</a> [<a href="http://arxiv.org/pdf/2012.10856" target="_blank">pdf</a>]

<h2>Reinforcement Learning-based Product Delivery Frequency Control. (arXiv:2012.10858v1 [cs.LG])</h2>
<h3>Yang Liu, Zhengxing Chen, Kittipat Virochsiri, Juan Wang, Jiahao Wu, Feng Liang</h3>
<p>Frequency control is an important problem in modern recommender systems. It
dictates the delivery frequency of recommendations to maintain product quality
and efficiency. For example, the frequency of delivering promotional
notifications impacts daily metrics as well as the infrastructure resource
consumption (e.g. CPU and memory usage). There remain open questions on what
objective we should optimize to represent business values in the long term
best, and how we should balance between daily metrics and resource consumption
in a dynamically fluctuating environment. We propose a personalized methodology
for the frequency control problem, which combines long-term value optimization
using reinforcement learning (RL) with a robust volume control technique we
termed "Effective Factor". We demonstrate statistically significant improvement
in daily metrics and resource efficiency by our method in several notification
applications at a scale of billions of users. To our best knowledge, our study
represents the first deep RL application on the frequency control problem at
such an industrial scale.
</p>
<a href="http://arxiv.org/abs/2012.10858" target="_blank">arXiv:2012.10858</a> [<a href="http://arxiv.org/pdf/2012.10858" target="_blank">pdf</a>]

<h2>Anchor-Based Spatial-Temporal Attention Convolutional Networks for Dynamic 3D Point Cloud Sequences. (arXiv:2012.10860v1 [cs.CV])</h2>
<h3>Guangming Wang, Hanwen Liu, Muyao Chen, Yehui Yang, Zhe Liu, Hesheng Wang</h3>
<p>Recently, learning based methods for the robot perception from the image or
video have much developed, but deep learning methods for dynamic 3D point cloud
sequences are underexplored. With the widespread application of 3D sensors such
as LiDAR and depth camera, efficient and accurate perception of the 3D
environment from 3D sequence data is pivotal to autonomous driving and service
robots. An Anchor-based Spatial-Temporal Attention Convolution operation
(ASTAConv) is proposed in this paper to process dynamic 3D point cloud
sequences. The proposed convolution operation builds a regular receptive field
around each point by setting several virtual anchors around each point. The
features of neighborhood points are firstly aggregated to each anchor based on
spatial-temporal attention mechanism. Then, anchor-based sparse 3D convolution
is adopted to aggregate the features of these anchors to the core points. The
proposed method makes better use of the structured information within the local
region, and learn spatial-temporal embedding features from dynamic 3D point
cloud sequences. Then Anchor-based Spatial-Temporal Attention Convolutional
Neural Networks (ASTACNNs) are proposed for classification and segmentation
tasks and are evaluated on action recognition and semantic segmentation tasks.
The experimental results on MSRAction3D and Synthia datasets demonstrate that
the higher accuracy can be achieved than the previous state-of-the-art method
by our novel strategy of multi-frame fusion.
</p>
<a href="http://arxiv.org/abs/2012.10860" target="_blank">arXiv:2012.10860</a> [<a href="http://arxiv.org/pdf/2012.10860" target="_blank">pdf</a>]

<h2>Path Planning and Obstacle Avoidance Scheme for Autonomous Robots using Raspberry Pi. (arXiv:2012.10863v1 [cs.RO])</h2>
<h3>R. N. Somarathna</h3>
<p>With the incremental development of robotic platforms to automate the manual
processes, path planning has become a critical domain with or without the
knowledge of the indoor and outdoor environment. The algorithms can be
intelligent or pre-structured and should optimally reach the destination
efficiently. The major challenge in this domain is to find a path which is free
from static obstacles as well as dynamic obstacles. In this paper, a
methodology is proposed with the implementation details of the robotic platform
to cover the critical key points and to arrive at the original key point in a
dynamic environment. The main computation is happening inside a Raspberry Pi B+
module, and compass, wheel encoders and ultrasonic sensors were used in the
implementation for the localization of the robot to relevant key points.
</p>
<a href="http://arxiv.org/abs/2012.10863" target="_blank">arXiv:2012.10863</a> [<a href="http://arxiv.org/pdf/2012.10863" target="_blank">pdf</a>]

<h2>Humanoid Robot Pitch Axis Stabilization using Linear Quadratic Regulator with Fuzzy Logic and Capture Point. (arXiv:2012.10867v1 [cs.RO])</h2>
<h3>Bagaskara Primastya Putra, Gabrielle Satya Mahardika, Muhammad Faris, Adha Imam Cahyadi</h3>
<p>This paper aims for a controller that can stabilize a position-controlled
humanoid robot when standing still or walking on synthetic grass even when
subjected to external disturbances. Two types of controllers are designed and
implemented: ankle strategy and stepping strategy. The robot's joints consist
of position-controlled servos which can be complicated to model analytically
due to nonlinearities and non-measurable parameters, hence the dynamic model of
the humanoid robot is acquired using a non-recursive least squares system
identification. This model is also used to design a Kalman Filter to estimate
the system states from noisy inertial measurement unit (IMU) sensor and design
a linear quadratic regulator (LQR) controller. To handle the nonlinearities,
the LQR controller is extended with fuzzy logic algorithm that changes the LQR
gain value based on angle and angular velocity membership functions. The
proposed control system can maintain the humanoid robot's stability around the
pitch axis when subject to pendulum disturbances or even restraining force from
a spring balance.
</p>
<a href="http://arxiv.org/abs/2012.10867" target="_blank">arXiv:2012.10867</a> [<a href="http://arxiv.org/pdf/2012.10867" target="_blank">pdf</a>]

<h2>Computer Vision based Accident Detection for Autonomous Vehicles. (arXiv:2012.10870v1 [cs.CV])</h2>
<h3>Dhananjai Chand, Savyasachi Gupta, Ilaiah Kavati</h3>
<p>Numerous Deep Learning and sensor-based models have been developed to detect
potential accidents with an autonomous vehicle. However, a self-driving car
needs to be able to detect accidents between other vehicles in its path and
take appropriate actions such as to slow down or stop and inform the concerned
authorities. In this paper, we propose a novel support system for self-driving
cars that detects vehicular accidents through a dashboard camera. The system
leverages the Mask R-CNN framework for vehicle detection and a centroid
tracking algorithm to track the detected vehicle. Additionally, the framework
calculates various parameters such as speed, acceleration, and trajectory to
determine whether an accident has occurred between any of the tracked vehicles.
The framework has been tested on a custom dataset of dashcam footage and
achieves a high accident detection rate while maintaining a low false alarm
rate.
</p>
<a href="http://arxiv.org/abs/2012.10870" target="_blank">arXiv:2012.10870</a> [<a href="http://arxiv.org/pdf/2012.10870" target="_blank">pdf</a>]

<h2>Sequence-to-Sequence Contrastive Learning for Text Recognition. (arXiv:2012.10873v1 [cs.CV])</h2>
<h3>Aviad Aberdam, Ron Litman, Shahar Tsiper, Oron Anschel, Ron Slossberg, Shai Mazor, R. Manmatha, Pietro Perona</h3>
<p>We propose a framework for sequence-to-sequence contrastive learning (SeqCLR)
of visual representations, which we apply to text recognition. To account for
the sequence-to-sequence structure, each feature map is divided into different
instances over which the contrastive loss is computed. This operation enables
us to contrast in a sub-word level, where from each image we extract several
positive pairs and multiple negative examples. To yield effective visual
representations for text recognition, we further suggest novel augmentation
heuristics, different encoder architectures and custom projection heads.
Experiments on handwritten text and on scene text show that when a text decoder
is trained on the learned representations, our method outperforms
non-sequential contrastive methods. In addition, when the amount of supervision
is reduced, SeqCLR significantly improves performance compared with supervised
training, and when fine-tuned with 100% of the labels, our method achieves
state-of-the-art results on standard handwritten text recognition benchmarks.
</p>
<a href="http://arxiv.org/abs/2012.10873" target="_blank">arXiv:2012.10873</a> [<a href="http://arxiv.org/pdf/2012.10873" target="_blank">pdf</a>]

<h2>Computer Vision based Animal Collision Avoidance Framework for Autonomous Vehicles. (arXiv:2012.10878v1 [cs.CV])</h2>
<h3>Savyasachi Gupta, Dhananjai Chand, Ilaiah Kavati</h3>
<p>Animals have been a common sighting on roads in India which leads to several
accidents between them and vehicles every year. This makes it vital to develop
a support system for driverless vehicles that assists in preventing these forms
of accidents. In this paper, we propose a neoteric framework for avoiding
vehicle-to-animal collisions by developing an efficient approach for the
detection of animals on highways using deep learning and computer vision
techniques on dashcam video. Our approach leverages the Mask R-CNN model for
detecting and identifying various commonly found animals. Then, we perform lane
detection to deduce whether a detected animal is on the vehicle's lane or not
and track its location and direction of movement using a centroid based object
tracking algorithm. This approach ensures that the framework is effective at
determining whether an animal is obstructing the path or not of an autonomous
vehicle in addition to predicting its movement and giving feedback accordingly.
This system was tested under various lighting and weather conditions and was
observed to perform relatively well, which leads the way for prominent
driverless vehicle's support systems for avoiding vehicular collisions with
animals on Indian roads in real-time.
</p>
<a href="http://arxiv.org/abs/2012.10878" target="_blank">arXiv:2012.10878</a> [<a href="http://arxiv.org/pdf/2012.10878" target="_blank">pdf</a>]

<h2>Where, What, Whether: Multi-modal Learning Meets Pedestrian Detection. (arXiv:2012.10880v1 [cs.CV])</h2>
<h3>Yan Luo, Chongyang Zhang, Muming Zhao, Hao Zhou, Jun Sun</h3>
<p>Pedestrian detection benefits greatly from deep convolutional neural networks
(CNNs). However, it is inherently hard for CNNs to handle situations in the
presence of occlusion and scale variation. In this paper, we propose W$^3$Net,
which attempts to address above challenges by decomposing the pedestrian
detection task into \textbf{\textit{W}}here, \textbf{\textit{W}}hat and
\textbf{\textit{W}}hether problem directing against pedestrian localization,
scale prediction and classification correspondingly. Specifically, for a
pedestrian instance, we formulate its feature by three steps. i) We generate a
bird view map, which is naturally free from occlusion issues, and scan all
points on it to look for suitable locations for each pedestrian instance. ii)
Instead of utilizing pre-fixed anchors, we model the interdependency between
depth and scale aiming at generating depth-guided scales at different locations
for better matching instances of different sizes. iii) We learn a latent vector
shared by both visual and corpus space, by which false positives with similar
vertical structure but lacking human partial features would be filtered out. We
achieve state-of-the-art results on widely used datasets (Citypersons and
Caltech). In particular. when evaluating on heavy occlusion subset, our results
reduce MR$^{-2}$ from 49.3$\%$ to 18.7$\%$ on Citypersons, and from 45.18$\%$
to 28.33$\%$ on Caltech.
</p>
<a href="http://arxiv.org/abs/2012.10880" target="_blank">arXiv:2012.10880</a> [<a href="http://arxiv.org/pdf/2012.10880" target="_blank">pdf</a>]

<h2>LieTransformer: Equivariant self-attention for Lie Groups. (arXiv:2012.10885v1 [cs.LG])</h2>
<h3>Michael Hutchinson, Charline Le Lan, Sheheryar Zaidi, Emilien Dupont, Yee Whye Teh, Hyunjik Kim</h3>
<p>Group equivariant neural networks are used as building blocks of group
invariant neural networks, which have been shown to improve generalisation
performance and data efficiency through principled parameter sharing. Such
works have mostly focused on group equivariant convolutions, building on the
result that group equivariant linear maps are necessarily convolutions. In this
work, we extend the scope of the literature to non-linear neural network
modules, namely self-attention, that is emerging as a prominent building block
of deep learning models. We propose the LieTransformer, an architecture
composed of LieSelfAttention layers that are equivariant to arbitrary Lie
groups and their discrete subgroups. We demonstrate the generality of our
approach by showing experimental results that are competitive to baseline
methods on a wide range of tasks: shape counting on point clouds, molecular
property regression and modelling particle trajectories under Hamiltonian
dynamics.
</p>
<a href="http://arxiv.org/abs/2012.10885" target="_blank">arXiv:2012.10885</a> [<a href="http://arxiv.org/pdf/2012.10885" target="_blank">pdf</a>]

<h2>PPGN: Phrase-Guided Proposal Generation Network For Referring Expression Comprehension. (arXiv:2012.10890v1 [cs.CV])</h2>
<h3>Chao Yang, Guoqing Wang, Dongsheng Li, Huawei Shen, Su Feng, Bin Jiang</h3>
<p>Reference expression comprehension (REC) aims to find the location that the
phrase refer to in a given image. Proposal generation and proposal
representation are two effective techniques in many two-stage REC methods.
However, most of the existing works only focus on proposal representation and
neglect the importance of proposal generation. As a result, the low-quality
proposals generated by these methods become the performance bottleneck in REC
tasks. In this paper, we reconsider the problem of proposal generation, and
propose a novel phrase-guided proposal generation network (PPGN). The main
implementation principle of PPGN is refining visual features with text and
generate proposals through regression. Experiments show that our method is
effective and achieve SOTA performance in benchmark datasets.
</p>
<a href="http://arxiv.org/abs/2012.10890" target="_blank">arXiv:2012.10890</a> [<a href="http://arxiv.org/pdf/2012.10890" target="_blank">pdf</a>]

<h2>Multi-Head Linear Attention Generative Adversarial Network for Thin Cloud Removal. (arXiv:2012.10898v1 [cs.CV])</h2>
<h3>Chenxi Duan, Rui Li</h3>
<p>In remote sensing images, the existence of the thin cloud is an inevitable
and ubiquitous phenomenon that crucially reduces the quality of imageries and
limits the scenarios of application. Therefore, thin cloud removal is an
indispensable procedure to enhance the utilization of remote sensing images.
Generally, even though contaminated by thin clouds, the pixels still retain
more or less surface information. Hence, different from thick cloud removal,
thin cloud removal algorithms normally concentrate on inhibiting the cloud
influence rather than substituting the cloud-contaminated pixels. Meanwhile,
considering the surface features obscured by the cloud are usually similar to
adjacent areas, the dependency between each pixel of the input is useful to
reconstruct contaminated areas. In this paper, to make full use of the
dependencies between pixels of the image, we propose a Multi-Head Linear
Attention Generative Adversarial Network (MLAGAN) for Thin Cloud Removal. The
MLA-GAN is based on the encoding-decoding framework consisting of multiple
attention-based layers and deconvolutional layers. Compared with six deep
learning-based thin cloud removal benchmarks, the experimental results on the
RICE1 and RICE2 datasets demonstrate that the proposed framework MLA-GAN has
dominant advantages in thin cloud removal.
</p>
<a href="http://arxiv.org/abs/2012.10898" target="_blank">arXiv:2012.10898</a> [<a href="http://arxiv.org/pdf/2012.10898" target="_blank">pdf</a>]

<h2>Learning to Localize Using a LiDAR Intensity Map. (arXiv:2012.10902v1 [cs.CV])</h2>
<h3>Ioan Andrei B&#xe2;rsan, Shenlong Wang, Andrei Pokrovsky, Raquel Urtasun</h3>
<p>In this paper we propose a real-time, calibration-agnostic and effective
localization system for self-driving cars. Our method learns to embed the
online LiDAR sweeps and intensity map into a joint deep embedding space.
Localization is then conducted through an efficient convolutional matching
between the embeddings. Our full system can operate in real-time at 15Hz while
achieving centimeter level accuracy across different LiDAR sensors and
environments. Our experiments illustrate the performance of the proposed
approach over a large-scale dataset consisting of over 4000km of driving.
</p>
<a href="http://arxiv.org/abs/2012.10902" target="_blank">arXiv:2012.10902</a> [<a href="http://arxiv.org/pdf/2012.10902" target="_blank">pdf</a>]

<h2>Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud. (arXiv:2012.10921v1 [cs.CV])</h2>
<h3>Mutian Xu, Junhao Zhang, Zhipeng Zhou, Mingye Xu, Xiaojuan Qi, Yu Qiao</h3>
<p>In 2D image processing, some attempts decompose images into high and low
frequency components for describing edge and smooth parts respectively.
Similarly, the contour and flat area of 3D objects, such as the boundary and
seat area of a chair, describe different but also complementary geometries.
However, such investigation is lost in previous deep networks that understand
point clouds by directly treating all points or local patches equally. To solve
this problem, we propose Geometry-Disentangled Attention Network (GDANet).
GDANet introduces Geometry-Disentangle Module to dynamically disentangle point
clouds into the contour and flat part of 3D objects, respectively denoted by
sharp and gentle variation components. Then GDANet exploits Sharp-Gentle
Complementary Attention Module that regards the features from sharp and gentle
variation components as two holistic representations, and pays different
attentions to them while fusing them respectively with original point cloud
features. In this way, our method captures and refines the holistic and
complementary 3D geometric semantics from two distinct disentangled components
to supplement the local information. Extensive experiments on 3D object
classification and segmentation benchmarks demonstrate that GDANet achieves the
state-of-the-arts with fewer parameters.
</p>
<a href="http://arxiv.org/abs/2012.10921" target="_blank">arXiv:2012.10921</a> [<a href="http://arxiv.org/pdf/2012.10921" target="_blank">pdf</a>]

<h2>Towards Trustworthy Predictions from Deep Neural Networks with Fast Adversarial Calibration. (arXiv:2012.10923v1 [cs.LG])</h2>
<h3>Christian Tomani, Florian Buettner</h3>
<p>To facilitate a wide-spread acceptance of AI systems guiding decision making
in real-world applications, trustworthiness of deployed models is key. That is,
it is crucial for predictive models to be uncertainty-aware and yield
well-calibrated (and thus trustworthy) predictions for both in-domain samples
as well as under domain shift. Recent efforts to account for predictive
uncertainty include post-processing steps for trained neural networks, Bayesian
neural networks as well as alternative non-Bayesian approaches such as ensemble
approaches and evidential deep learning. Here, we propose an efficient yet
general modelling approach for obtaining well-calibrated, trustworthy
probabilities for samples obtained after a domain shift. We introduce a new
training strategy combining an entropy-encouraging loss term with an
adversarial calibration loss term and demonstrate that this results in
well-calibrated and technically trustworthy predictions for a wide range of
domain drifts. We comprehensively evaluate previously proposed approaches on
different data modalities, a large range of data sets including sequence data,
network architectures and perturbation strategies. We observe that our
modelling approach substantially outperforms existing state-of-the-art
approaches, yielding well-calibrated predictions under domain drift.
</p>
<a href="http://arxiv.org/abs/2012.10923" target="_blank">arXiv:2012.10923</a> [<a href="http://arxiv.org/pdf/2012.10923" target="_blank">pdf</a>]

<h2>Explaining Black-box Models for Biomedical Text Classification. (arXiv:2012.10928v1 [cs.AI])</h2>
<h3>Milad Moradi, Matthias Samwald</h3>
<p>In this paper, we propose a novel method named Biomedical Confident Itemsets
Explanation (BioCIE), aiming at post-hoc explanation of black-box machine
learning models for biomedical text classification. Using sources of domain
knowledge and a confident itemset mining method, BioCIE discretizes the
decision space of a black-box into smaller subspaces and extracts semantic
relationships between the input text and class labels in different subspaces.
Confident itemsets discover how biomedical concepts are related to class labels
in the black-box's decision space. BioCIE uses the itemsets to approximate the
black-box's behavior for individual predictions. Optimizing fidelity,
interpretability, and coverage measures, BioCIE produces class-wise
explanations that represent decision boundaries of the black-box. Results of
evaluations on various biomedical text classification tasks and black-box
models demonstrated that BioCIE can outperform perturbation-based and decision
set methods in terms of producing concise, accurate, and interpretable
explanations. BioCIE improved the fidelity of instance-wise and class-wise
explanations by 11.6% and 7.5%, respectively. It also improved the
interpretability of explanations by 8%. BioCIE can be effectively used to
explain how a black-box biomedical text classification model semantically
relates input texts to class labels. The source code and supplementary material
are available at https://github.com/mmoradi-iut/BioCIE.
</p>
<a href="http://arxiv.org/abs/2012.10928" target="_blank">arXiv:2012.10928</a> [<a href="http://arxiv.org/pdf/2012.10928" target="_blank">pdf</a>]

<h2>Automated Clustering of High-dimensional Data with a Feature Weighted Mean Shift Algorithm. (arXiv:2012.10929v1 [cs.LG])</h2>
<h3>Saptarshi Chakraborty, Debolina Paul, Swagatam Das</h3>
<p>Mean shift is a simple interactive procedure that gradually shifts data
points towards the mode which denotes the highest density of data points in the
region. Mean shift algorithms have been effectively used for data denoising,
mode seeking, and finding the number of clusters in a dataset in an automated
fashion. However, the merits of mean shift quickly fade away as the data
dimensions increase and only a handful of features contain useful information
about the cluster structure of the data. We propose a simple yet elegant
feature-weighted variant of mean shift to efficiently learn the feature
importance and thus, extending the merits of mean shift to high-dimensional
data. The resulting algorithm not only outperforms the conventional mean shift
clustering procedure but also preserves its computational simplicity. In
addition, the proposed method comes with rigorous theoretical convergence
guarantees and a convergence rate of at least a cubic order. The efficacy of
our proposal is thoroughly assessed through experimental comparison against
baseline and state-of-the-art clustering methods on synthetic as well as
real-world datasets.
</p>
<a href="http://arxiv.org/abs/2012.10929" target="_blank">arXiv:2012.10929</a> [<a href="http://arxiv.org/pdf/2012.10929" target="_blank">pdf</a>]

<h2>Guidance Module Network for Video Captioning. (arXiv:2012.10930v1 [cs.CV])</h2>
<h3>Xiao Zhang, Chunsheng Liu, Faliang Chang</h3>
<p>Video captioning has been a challenging and significant task that describes
the content of a video clip in a single sentence. The model of video captioning
is usually an encoder-decoder. We find that the normalization of extracted
video features can improve the final performance of video captioning.
Encoder-decoder model is usually trained using teacher-enforced strategies to
make the prediction probability of each word close to a 0-1 distribution and
ignore other words. In this paper, we present a novel architecture which
introduces a guidance module to encourage the encoder-decoder model to generate
words related to the past and future words in a caption. Based on the
normalization and guidance module, guidance module net (GMNet) is built.
Experimental results on commonly used dataset MSVD show that proposed GMNet can
improve the performance of the encoder-decoder model on video captioning tasks.
</p>
<a href="http://arxiv.org/abs/2012.10930" target="_blank">arXiv:2012.10930</a> [<a href="http://arxiv.org/pdf/2012.10930" target="_blank">pdf</a>]

<h2>Recent advances in deep learning theory. (arXiv:2012.10931v1 [cs.LG])</h2>
<h3>Fengxiang He, Dacheng Tao</h3>
<p>Deep learning is usually described as an experiment-driven field under
continuous criticizes of lacking theoretical foundations. This problem has been
partially fixed by a large volume of literature which has so far not been well
organized. This paper reviews and organizes the recent advances in deep
learning theory. The literature is categorized in six groups: (1) complexity
and capacity-based approaches for analyzing the generalizability of deep
learning; (2) stochastic differential equations and their dynamic systems for
modelling stochastic gradient descent and its variants, which characterize the
optimization and generalization of deep learning, partially inspired by
Bayesian inference; (3) the geometrical structures of the loss landscape that
drives the trajectories of the dynamic systems; (4) the roles of
over-parameterization of deep neural networks from both positive and negative
perspectives; (5) theoretical foundations of several special structures in
network architectures; and (6) the increasingly intensive concerns in ethics
and security and their relationships with generalizability.
</p>
<a href="http://arxiv.org/abs/2012.10931" target="_blank">arXiv:2012.10931</a> [<a href="http://arxiv.org/pdf/2012.10931" target="_blank">pdf</a>]

<h2>Semi-supervised Hyperspectral Image Classification with Graph Clustering Convolutional Networks. (arXiv:2012.10932v1 [cs.CV])</h2>
<h3>Hao Zeng, Qingjie Liu, Mingming Zhang, Xiaoqing Han, Yunhong Wang</h3>
<p>Hyperspectral image classification (HIC) is an important but challenging
task, and a problem that limits the algorithmic development in this field is
that the ground truths of hyperspectral images (HSIs) are extremely hard to
obtain. Recently a handful of HIC methods are developed based on the graph
convolution networks (GCNs), which effectively relieves the scarcity of labeled
data for deep learning based HIC methods. To further lift the classification
performance, in this work we propose a graph convolution network (GCN) based
framework for HSI classification that uses two clustering operations to better
exploit multi-hop node correlations and also effectively reduce graph size. In
particular, we first cluster the pixels with similar spectral features into a
superpixel and build the graph based on the superpixels of the input HSI. Then
instead of performing convolution over this superpixel graph, we further
partition it into several sub-graphs by pruning the edges with weak weights, so
as to strengthen the correlations of nodes with high similarity. This second
round of clustering also further reduces the graph size, thus reducing the
computation burden of graph convolution. Experimental results on three widely
used benchmark datasets well prove the effectiveness of our proposed framework.
</p>
<a href="http://arxiv.org/abs/2012.10932" target="_blank">arXiv:2012.10932</a> [<a href="http://arxiv.org/pdf/2012.10932" target="_blank">pdf</a>]

<h2>Toward Understanding the Influence of Individual Clients in Federated Learning. (arXiv:2012.10936v1 [cs.LG])</h2>
<h3>Yihao Xue, Chaoyue Niu, Zhenzhe Zheng, Shaojie Tang, Chengfei Lv, Fan Wu, Guihai Chen</h3>
<p>Federated learning allows mobile clients to jointly train a global model
without sending their private data to a central server. Despite that extensive
works have studied the performance guarantee of the global model, it is still
unclear how each individual client influences the collaborative training
process. In this work, we defined a novel notion, called {\em Fed-Influence},
to quantify this influence in terms of model parameter, and proposed an
effective and efficient estimation algorithm. In particular, our design
satisfies several desirable properties: (1) it requires neither retraining nor
retracing, adding only linear computational overhead to clients and the server;
(2) it strictly maintains the tenet of federated learning, without revealing
any client's local data; and (3) it works well on both convex and non-convex
loss functions and does not require the final model to be optimal. Empirical
results on a synthetic dataset and the FEMNIST dataset show that our estimation
method can approximate Fed-Influence with small bias. Further, we demonstrated
an application of client-level model debugging.
</p>
<a href="http://arxiv.org/abs/2012.10936" target="_blank">arXiv:2012.10936</a> [<a href="http://arxiv.org/pdf/2012.10936" target="_blank">pdf</a>]

<h2>Study of Energy-Efficient Distributed RLS-based Learning with Coarsely Quantized Signals. (arXiv:2012.10939v1 [cs.LG])</h2>
<h3>A. Danaee, R. C. de Lamare, V. H. Nascimento</h3>
<p>In this work, we present an energy-efficient distributed learning framework
using coarsely quantized signals for Internet of Things (IoT) networks. In
particular, we develop a distributed quantization-aware recursive least squares
(DQA-RLS) algorithm that can learn parameters in an energy-efficient fashion
using signals quantized with few bits while requiring a low computational cost.
Numerical results assess the DQA-RLS algorithm against existing techniques for
a distributed parameter estimation task where IoT devices operate in a
peer-to-peer mode.
</p>
<a href="http://arxiv.org/abs/2012.10939" target="_blank">arXiv:2012.10939</a> [<a href="http://arxiv.org/pdf/2012.10939" target="_blank">pdf</a>]

<h2>Lexicographic Logic: a Many-valued Logic for Preference Representation. (arXiv:2012.10940v1 [cs.AI])</h2>
<h3>Angelos Charalambidis, Giorgos Papadimitriou, Panos Rondogiannis, Antonis Troumpoukis</h3>
<p>Logical formalisms provide a natural and concise means for specifying and
reasoning about preferences. In this paper, we propose lexicographic logic, an
extension of classical propositional logic that can express a variety of
preferences, most notably lexicographic ones. The proposed logic supports a
simple new connective whose semantics can be defined in terms of finite lists
of truth values. We demonstrate that, despite the well-known theoretical
limitations that pose barriers to the quantitative representation of
lexicographic preferences, there exists a subset of the rational numbers over
which the proposed new connective can be naturally defined. Lexicographic logic
can be used to define in a simple way some well-known preferential operators,
like "$A$ and if possible $B$", and "$A$ or failing that $B$". Moreover, many
other hierarchical preferential operators can be defined using a systematic
approach. We argue that the new logic is an effective formalism for ranking
query results according to the satisfaction level of user preferences.
</p>
<a href="http://arxiv.org/abs/2012.10940" target="_blank">arXiv:2012.10940</a> [<a href="http://arxiv.org/pdf/2012.10940" target="_blank">pdf</a>]

<h2>Can Everybody Sign Now? Exploring Sign Language Video Generation from 2D Poses. (arXiv:2012.10941v1 [cs.CV])</h2>
<h3>Lucas Ventura, Amanda Duarte, Xavier Giro-i-Nieto</h3>
<p>Recent work have addressed the generation of human poses represented by 2D/3D
coordinates of human joints for sign language. We use the state of the art in
Deep Learning for motion transfer and evaluate them on How2Sign, an American
Sign Language dataset, to generate videos of signers performing sign language
given a 2D pose skeleton. We evaluate the generated videos quantitatively and
qualitatively showing that the current models are not enough to generated
adequate videos for Sign Language due to lack of detail in hands.
</p>
<a href="http://arxiv.org/abs/2012.10941" target="_blank">arXiv:2012.10941</a> [<a href="http://arxiv.org/pdf/2012.10941" target="_blank">pdf</a>]

<h2>Learning to Localize Through Compressed Binary Maps. (arXiv:2012.10942v1 [cs.CV])</h2>
<h3>Xinkai Wei, Ioan Andrei B&#xe2;rsan, Shenlong Wang, Julieta Martinez, Raquel Urtasun</h3>
<p>One of the main difficulties of scaling current localization systems to large
environments is the on-board storage required for the maps. In this paper we
propose to learn to compress the map representation such that it is optimal for
the localization task. As a consequence, higher compression rates can be
achieved without loss of localization accuracy when compared to standard coding
schemes that optimize for reconstruction, thus ignoring the end task. Our
experiments show that it is possible to learn a task-specific compression which
reduces storage requirements by two orders of magnitude over general-purpose
codecs such as WebP without sacrificing performance.
</p>
<a href="http://arxiv.org/abs/2012.10942" target="_blank">arXiv:2012.10942</a> [<a href="http://arxiv.org/pdf/2012.10942" target="_blank">pdf</a>]

<h2>SPlit: An Optimal Method for Data Splitting. (arXiv:2012.10945v1 [stat.ML])</h2>
<h3>V. Roshan Joseph, Akhil Vakayil</h3>
<p>In this article we propose an optimal method referred to as SPlit for
splitting a dataset into training and testing sets. SPlit is based on the
method of Support Points (SP), which was initially developed for finding the
optimal representative points of a continuous distribution. We adapt SP for
subsampling from a dataset using a sequential nearest neighbor algorithm. We
also extend SP to deal with categorical variables so that SPlit can be applied
to both regression and classification problems. The implementation of SPlit on
real datasets shows substantial improvement in the worst-case testing
performance for several modeling methods compared to the commonly used random
splitting procedure.
</p>
<a href="http://arxiv.org/abs/2012.10945" target="_blank">arXiv:2012.10945</a> [<a href="http://arxiv.org/pdf/2012.10945" target="_blank">pdf</a>]

<h2>Towards Automatic Digital Documentation and Progress Reporting of Mechanical Construction Pipes using Smartphones. (arXiv:2012.10958v1 [cs.CV])</h2>
<h3>Reza Maalek, Derek Lichti, Shahrokh Maalek</h3>
<p>This manuscript presents a framework towards automated 3D digital
documentation and progress reporting of mechanical pipes in building
construction projects, using smartphones. New methods were proposed to
determine the video frame rate required to achieve a desired image overlap;
define metric scale for 3D reconstruction; extract pipes from point clouds; and
classify pipes according to their planned bill of quantity radii. The
effectiveness of the proposed methods in both laboratory (six pipes) and
construction site (58 pipes) conditions was evaluated. It was observed that the
proposed metric scale definition achieved sub-millimeter pipe radius estimation
accuracy. Both laboratory and field experiments revealed that increasing the
image overlap improved the pipe classification quality, radius, and length.
Overall, using the proposed methods, it was possible to achieve pipe
classification F-measure, radius estimation accuracy, and length estimation
percent error of 96.4%, 5.4mm, and 5.0%, respectively, on construction sites
using at least 95% image overlap.
</p>
<a href="http://arxiv.org/abs/2012.10958" target="_blank">arXiv:2012.10958</a> [<a href="http://arxiv.org/pdf/2012.10958" target="_blank">pdf</a>]

<h2>High-Fidelity Neural Human Motion Transfer from Monocular Video. (arXiv:2012.10974v1 [cs.CV])</h2>
<h3>Moritz Kappel, Vladislav Golyanik, Mohamed Elgharib, Jann-Ole Henningson, Hans-Peter Seidel, Susana Castillo, Christian Theobalt, Marcus Magnor</h3>
<p>Video-based human motion transfer creates video animations of humans
following a source motion. Current methods show remarkable results for
tightly-clad subjects. However, the lack of temporally consistent handling of
plausible clothing dynamics, including fine and high-frequency details,
significantly limits the attainable visual quality. We address these
limitations for the first time in the literature and present a new framework
which performs high-fidelity and temporally-consistent human motion transfer
with natural pose-dependent non-rigid deformations, for several types of loose
garments. In contrast to the previous techniques, we perform image generation
in three subsequent stages, synthesizing human shape, structure, and
appearance. Given a monocular RGB video of an actor, we train a stack of
recurrent deep neural networks that generate these intermediate representations
from 2D poses and their temporal derivatives. Splitting the difficult motion
transfer problem into subtasks that are aware of the temporal motion context
helps us to synthesize results with plausible dynamics and pose-dependent
detail. It also allows artistic control of results by manipulation of
individual framework stages. In the experimental results, we significantly
outperform the state-of-the-art in terms of video realism. Our code and data
will be made publicly available.
</p>
<a href="http://arxiv.org/abs/2012.10974" target="_blank">arXiv:2012.10974</a> [<a href="http://arxiv.org/pdf/2012.10974" target="_blank">pdf</a>]

<h2>Towards Complex and Continuous Manipulation: A Gesture Based Anthropomorphic Robotic Hand Design. (arXiv:2012.10981v1 [cs.RO])</h2>
<h3>Li Tian, Hanhui Li, Qifa Wang, Xuezeng Du, Jialin Tao, Jordan Sia Chong, Nadia Magnenat Thalmann, Jianmin Zheng</h3>
<p>Most current anthropomorphic robotic hands can realize part of the human hand
functions, particularly for object grasping. However, due to the complexity of
the human hand, few current designs target at daily object manipulations, even
for simple actions like rotating a pen. To tackle this problem, we introduce a
gesture based framework, which adopts the widely-used 33 grasping gestures of
Feix as the bases for hand design and implementation of manipulation. In the
proposed framework, we first measure the motion ranges of human fingers for
each gesture, and based on the results, we propose a simple yet dexterous
robotic hand design with 13 degrees of freedom. Furthermore, we adopt a frame
interpolation based method, in which we consider the base gestures as the key
frames to represent a manipulation task, and use the simple linear
interpolation strategy to accomplish the manipulation. To demonstrate the
effectiveness of our framework, we define a three-level benchmark, which
includes not only 62 test gestures from previous research, but also multiple
complex and continuous actions. Experimental results on this benchmark validate
the dexterity of the proposed design and our video is available in
\url{https://entuedu-my.sharepoint.com/:v:/g/personal/hanhui_li_staff_main_ntu_edu_sg/Ean2GpnFo6JPjIqbKy1KHMEBftgCkcDhnSX-9uLZ6T0rUg?e=ppCGbC}
</p>
<a href="http://arxiv.org/abs/2012.10981" target="_blank">arXiv:2012.10981</a> [<a href="http://arxiv.org/pdf/2012.10981" target="_blank">pdf</a>]

<h2>Learning Halfspaces With Membership Queries. (arXiv:2012.10985v1 [cs.LG])</h2>
<h3>Ori Kelner</h3>
<p>Active learning is a subfield of machine learning, in which the learning
algorithm is allowed to choose the data from which it learns. In some cases, it
has been shown that active learning can yield an exponential gain in the number
of samples the algorithm needs to see, in order to reach generalization error
$\leq \epsilon$. In this work we study the problem of learning halfspaces with
membership queries. In the membership query scenario, we allow the learning
algorithm to ask for the label of every sample in the input space. We suggest a
new algorithm for this problem, and prove it achieves a near optimal label
complexity in some cases. We also show that the algorithm works well in
practice, and significantly outperforms uncertainty sampling.
</p>
<a href="http://arxiv.org/abs/2012.10985" target="_blank">arXiv:2012.10985</a> [<a href="http://arxiv.org/pdf/2012.10985" target="_blank">pdf</a>]

<h2>Biased Models Have Biased Explanations. (arXiv:2012.10986v1 [cs.LG])</h2>
<h3>Aditya Jain, Manish Ravula, Joydeep Ghosh</h3>
<p>We study fairness in Machine Learning (FairML) through the lens of
attribute-based explanations generated for machine learning models. Our
hypothesis is: Biased Models have Biased Explanations. To establish that, we
first translate existing statistical notions of group fairness and define these
notions in terms of explanations given by the model. Then, we propose a novel
way of detecting (un)fairness for any black box model. We further look at
post-processing techniques for fairness and reason how explanations can be used
to make a bias mitigation technique more individually fair. We also introduce a
novel post-processing mitigation technique which increases individual fairness
in recourse while maintaining group level fairness.
</p>
<a href="http://arxiv.org/abs/2012.10986" target="_blank">arXiv:2012.10986</a> [<a href="http://arxiv.org/pdf/2012.10986" target="_blank">pdf</a>]

<h2>Post-hoc Uncertainty Calibration for Domain Drift Scenarios. (arXiv:2012.10988v1 [cs.LG])</h2>
<h3>Christian Tomani, Sebastian Gruber, Muhammed Ebrar Erdem, Daniel Cremers, Florian Buettner</h3>
<p>We address the problem of uncertainty calibration. While standard deep neural
networks typically yield uncalibrated predictions, calibrated confidence scores
that are representative of the true likelihood of a prediction can be achieved
using post-hoc calibration methods. However, to date the focus of these
approaches has been on in-domain calibration. Our contribution is two-fold.
First, we show that existing post-hoc calibration methods yield highly
over-confident predictions under domain shift. Second, we introduce a simple
strategy where perturbations are applied to samples in the validation set
before performing the post-hoc calibration step. In extensive experiments, we
demonstrate that this perturbation step results in substantially better
calibration under domain shift on a wide range of architectures and modelling
tasks.
</p>
<a href="http://arxiv.org/abs/2012.10988" target="_blank">arXiv:2012.10988</a> [<a href="http://arxiv.org/pdf/2012.10988" target="_blank">pdf</a>]

<h2>Deep Continuous Fusion for Multi-Sensor 3D Object Detection. (arXiv:2012.10992v1 [cs.CV])</h2>
<h3>Ming Liang, Bin Yang, Shenlong Wang, Raquel Urtasun</h3>
<p>In this paper, we propose a novel 3D object detector that can exploit both
LIDAR as well as cameras to perform very accurate localization. Towards this
goal, we design an end-to-end learnable architecture that exploits continuous
convolutions to fuse image and LIDAR feature maps at different levels of
resolution. Our proposed continuous fusion layer encode both discrete-state
image features as well as continuous geometric information. This enables us to
design a novel, reliable and efficient end-to-end learnable 3D object detector
based on multiple sensors. Our experimental evaluation on both KITTI as well as
a large scale 3D object detection benchmark shows significant improvements over
the state of the art.
</p>
<a href="http://arxiv.org/abs/2012.10992" target="_blank">arXiv:2012.10992</a> [<a href="http://arxiv.org/pdf/2012.10992" target="_blank">pdf</a>]

<h2>Deep Bingham Networks: Dealing with Uncertainty and Ambiguity in Pose Estimation. (arXiv:2012.11002v1 [cs.CV])</h2>
<h3>Haowen Deng, Mai Bui, Nassir Navab, Leonidas Guibas, Slobodan Ilic, Tolga Birdal</h3>
<p>In this work, we introduce Deep Bingham Networks (DBN), a generic framework
that can naturally handle pose-related uncertainties and ambiguities arising in
almost all real life applications concerning 3D data. While existing works
strive to find a single solution to the pose estimation problem, we make peace
with the ambiguities causing high uncertainty around which solutions to
identify as the best. Instead, we report a family of poses which capture the
nature of the solution space. DBN extends the state of the art direct pose
regression networks by (i) a multi-hypotheses prediction head which can yield
different distribution modes; and (ii) novel loss functions that benefit from
Bingham distributions on rotations. This way, DBN can work both in unambiguous
cases providing uncertainty information, and in ambiguous scenes where an
uncertainty per mode is desired. On a technical front, our network regresses
continuous Bingham mixture models and is applicable to both 2D data such as
images and to 3D data such as point clouds. We proposed new training strategies
so as to avoid mode or posterior collapse during training and to improve
numerical stability. Our methods are thoroughly tested on two different
applications exploiting two different modalities: (i) 6D camera relocalization
from images; and (ii) object pose estimation from 3D point clouds,
demonstrating decent advantages over the state of the art. For the former we
contributed our own dataset composed of five indoor scenes where it is
unavoidable to capture images corresponding to views that are hard to uniquely
identify. For the latter we achieve the top results especially for symmetric
objects of ModelNet dataset.
</p>
<a href="http://arxiv.org/abs/2012.11002" target="_blank">arXiv:2012.11002</a> [<a href="http://arxiv.org/pdf/2012.11002" target="_blank">pdf</a>]

<h2>Voting of predictive models for clinical outcomes: consensus of algorithms for the early prediction of sepsis from clinical data and an analysis of the PhysioNet/Computing in Cardiology Challenge 2019. (arXiv:2012.11013v1 [cs.LG])</h2>
<h3>Matthew A. Reyna, Gari D. Clifford</h3>
<p>Although there has been significant research in boosting of weak learners,
there has been little work in the field of boosting from strong learners. This
latter paradigm is a form of weighted voting with learned weights. In this
work, we consider the problem of constructing an ensemble algorithm from 70
individual algorithms for the early prediction of sepsis from clinical data. We
find that this ensemble algorithm outperforms separate algorithms, especially
on a hidden test set on which most algorithms failed to generalize.
</p>
<a href="http://arxiv.org/abs/2012.11013" target="_blank">arXiv:2012.11013</a> [<a href="http://arxiv.org/pdf/2012.11013" target="_blank">pdf</a>]

<h2>KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA. (arXiv:2012.11014v1 [cs.CV])</h2>
<h3>Kenneth Marino, Xinlei Chen, Devi Parikh, Abhinav Gupta, Marcus Rohrbach</h3>
<p>One of the most challenging question types in VQA is when answering the
question requires outside knowledge not present in the image. In this work we
study open-domain knowledge, the setting when the knowledge required to answer
a question is not given/annotated, neither at training nor test time. We tap
into two types of knowledge representations and reasoning. First, implicit
knowledge which can be learned effectively from unsupervised language
pre-training and supervised training data with transformer-based models.
Second, explicit, symbolic knowledge encoded in knowledge bases. Our approach
combines both - exploiting the powerful implicit reasoning of transformer
models for answer prediction, and integrating symbolic representations from a
knowledge graph, while never losing their explicit semantics to an implicit
embedding. We combine diverse sources of knowledge to cover the wide variety of
knowledge needed to solve knowledge-based questions. We show our approach,
KRISP (Knowledge Reasoning with Implicit and Symbolic rePresentations),
significantly outperforms state-of-the-art on OK-VQA, the largest available
dataset for open-domain knowledge-based VQA. We show with extensive ablations
that while our model successfully exploits implicit knowledge reasoning, the
symbolic answer module which explicitly connects the knowledge graph to the
answer vocabulary is critical to the performance of our method and generalizes
to rare answers.
</p>
<a href="http://arxiv.org/abs/2012.11014" target="_blank">arXiv:2012.11014</a> [<a href="http://arxiv.org/pdf/2012.11014" target="_blank">pdf</a>]

<h2>DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for deep neural networks. (arXiv:2012.11025v1 [cs.CV])</h2>
<h3>Abhishek Singh, Ayush Chopra, Vivek Sharma, Ethan Garza, Emily Zhang, Praneeth Vepakomma, Ramesh Raskar</h3>
<p>Recent deep learning models have shown remarkable performance in image
classification. While these deep learning systems are getting closer to
practical deployment, the common assumption made about data is that it does not
carry any sensitive information. This assumption may not hold for many
practical cases, especially in the domain where an individual's personal
information is involved, like healthcare and facial recognition systems. We
posit that selectively removing features in this latent space can protect the
sensitive information and provide a better privacy-utility trade-off.
Consequently, we propose DISCO which learns a dynamic and data driven pruning
filter to selectively obfuscate sensitive information in the feature space. We
propose diverse attack schemes for sensitive inputs \&amp; attributes and
demonstrate the effectiveness of DISCO against state-of-the-art methods through
quantitative and qualitative evaluation. Finally, we also release an evaluation
benchmark dataset of 1 million sensitive representations to encourage rigorous
exploration of novel attack schemes.
</p>
<a href="http://arxiv.org/abs/2012.11025" target="_blank">arXiv:2012.11025</a> [<a href="http://arxiv.org/pdf/2012.11025" target="_blank">pdf</a>]

<h2>Monte-Carlo Graph Search for AlphaZero. (arXiv:2012.11045v1 [cs.AI])</h2>
<h3>Johannes Czech, Patrick Korus, Kristian Kersting</h3>
<p>The AlphaZero algorithm has been successfully applied in a range of discrete
domains, most notably board games. It utilizes a neural network, that learns a
value and policy function to guide the exploration in a Monte-Carlo Tree
Search. Although many search improvements have been proposed for Monte-Carlo
Tree Search in the past, most of them refer to an older variant of the Upper
Confidence bounds for Trees algorithm that does not use a policy for planning.
We introduce a new, improved search algorithm for AlphaZero which generalizes
the search tree to a directed acyclic graph. This enables information flow
across different subtrees and greatly reduces memory consumption. Along with
Monte-Carlo Graph Search, we propose a number of further extensions, such as
the inclusion of Epsilon-greedy exploration, a revised terminal solver and the
integration of domain knowledge as constraints. In our evaluations, we use the
CrazyAra engine on chess and crazyhouse as examples to show that these changes
bring significant improvements to AlphaZero.
</p>
<a href="http://arxiv.org/abs/2012.11045" target="_blank">arXiv:2012.11045</a> [<a href="http://arxiv.org/pdf/2012.11045" target="_blank">pdf</a>]

<h2>Bayesian Semi-supervised Crowdsourcing. (arXiv:2012.11048v1 [cs.LG])</h2>
<h3>Panagiotis A. Traganitis, Georgios B. Giannakis</h3>
<p>Crowdsourcing has emerged as a powerful paradigm for efficiently labeling
large datasets and performing various learning tasks, by leveraging crowds of
human annotators. When additional information is available about the data,
semi-supervised crowdsourcing approaches that enhance the aggregation of labels
from human annotators are well motivated. This work deals with semi-supervised
crowdsourced classification, under two regimes of semi-supervision: a) label
constraints, that provide ground-truth labels for a subset of data; and b)
potentially easier to obtain instance-level constraints, that indicate
relationships between pairs of data. Bayesian algorithms based on variational
inference are developed for each regime, and their quantifiably improved
performance, compared to unsupervised crowdsourcing, is analytically and
empirically validated on several crowdsourcing datasets.
</p>
<a href="http://arxiv.org/abs/2012.11048" target="_blank">arXiv:2012.11048</a> [<a href="http://arxiv.org/pdf/2012.11048" target="_blank">pdf</a>]

<h2>Fusion of CNNs and statistical indicators to improve image classification. (arXiv:2012.11049v1 [cs.CV])</h2>
<h3>Javier Huertas-Tato, Alejandro Mart&#xed;n, Julian Fierrez, David Camacho</h3>
<p>Convolutional Networks have dominated the field of computer vision for the
last ten years, exhibiting extremely powerful feature extraction capabilities
and outstanding classification performance. The main strategy to prolong this
trend relies on further upscaling networks in size. However, costs increase
rapidly while performance improvements may be marginal. We hypothesise that
adding heterogeneous sources of information may be more cost-effective to a CNN
than building a bigger network. In this paper, an ensemble method is proposed
for accurate image classification, fusing automatically detected features
through Convolutional Neural Network architectures with a set of manually
defined statistical indicators. Through a combination of the predictions of a
CNN and a secondary classifier trained on statistical features, better
classification performance can be cheaply achieved. We test multiple learning
algorithms and CNN architectures on a diverse number of datasets to validate
our proposal, making public all our code and data via GitHub. According to our
results, the inclusion of additional indicators and an ensemble classification
approach helps to increase the performance in 8 of 9 datasets, with a
remarkable increase of more than 10% precision in two of them.
</p>
<a href="http://arxiv.org/abs/2012.11049" target="_blank">arXiv:2012.11049</a> [<a href="http://arxiv.org/pdf/2012.11049" target="_blank">pdf</a>]

<h2>A Bayesian methodology for localising acoustic emission sources in complex structures. (arXiv:2012.11058v1 [cs.LG])</h2>
<h3>Matthew R. Jones, Tim J. Rogers, Keith Worden, Elizabeth J. Cross</h3>
<p>In the field of structural health monitoring (SHM), the acquisition of
acoustic emissions to localise damage sources has emerged as a popular
approach. Despite recent advances, the task of locating damage within composite
materials and structures that contain non-trivial geometrical features, still
poses a significant challenge. Within this paper, a Bayesian source
localisation strategy that is robust to these complexities is presented. Under
this new framework, a Gaussian process is first used to learn the relationship
between source locations and the corresponding difference-in-time-of-arrival
values for a number of sensor pairings. As an acoustic emission event with an
unknown origin is observed, a mapping is then generated that quantifies the
likelihood of the emission location across the surface of the structure. The
new probabilistic mapping offers multiple benefits, leading to a localisation
strategy that is more informative than deterministic predictions or
single-point estimates with an associated confidence bound. The performance of
the approach is investigated on a structure with numerous complex geometrical
features and demonstrates a favourable performance in comparison to other
similar localisation methods.
</p>
<a href="http://arxiv.org/abs/2012.11058" target="_blank">arXiv:2012.11058</a> [<a href="http://arxiv.org/pdf/2012.11058" target="_blank">pdf</a>]

<h2>Data-Driven Geometric System Identification for Shape-Underactuated Dissipative Systems. (arXiv:2012.11064v1 [cs.RO])</h2>
<h3>Brian Bittner, Ross L. Hatton, Shai Revzen</h3>
<p>The study of systems whose movement is both geometric and dissipative offers
an opportunity to quickly both identify models and optimize motion. Here, the
geometry indicates reduction of the dynamics by environmental homogeneity while
the dissipative nature minimizes the role of second order (inertial) features
in the dynamics. In this work, we extend the tools of geometric system
identification to "Shape-Underactuated Dissipative Systems (SUDS)" -- systems
whose motions are kinematic, but whose actuation is restricted to a subset of
the body shape coordinates. A large class of SUDS includes highly damped robots
with series elastic actuators, and many soft robots. We validate the predictive
quality of the models using simulations of a variety of viscous swimming
systems. For a large class of SUDS, we show how the shape velocity actuation
inputs can be directly converted into torque inputs suggesting that, e.g.,
systems with soft pneumatic actuators or dielectric elastomers, could be
controlled in this way. Based on fundamental assumptions in the physics, we
show how our model complexity scales linearly with the number of passive shape
coordinates. This offers a large reduction on the number of trials needed to
identify the system model from experimental data, and may reduce overfitting.
The sample efficiency of our method suggests its use in modeling, control, and
optimization in robotics, and as a tool for the study of organismal motion in
friction dominated regimes.
</p>
<a href="http://arxiv.org/abs/2012.11064" target="_blank">arXiv:2012.11064</a> [<a href="http://arxiv.org/pdf/2012.11064" target="_blank">pdf</a>]

<h2>Fairness, Welfare, and Equity in Personalized Pricing. (arXiv:2012.11066v1 [cs.LG])</h2>
<h3>Nathan Kallus, Angela Zhou</h3>
<p>We study the interplay of fairness, welfare, and equity considerations in
personalized pricing based on customer features. Sellers are increasingly able
to conduct price personalization based on predictive modeling of demand
conditional on covariates: setting customized interest rates, targeted
discounts of consumer goods, and personalized subsidies of scarce resources
with positive externalities like vaccines and bed nets. These different
application areas may lead to different concerns around fairness, welfare, and
equity on different objectives: price burdens on consumers, price envy, firm
revenue, access to a good, equal access, and distributional consequences when
the good in question further impacts downstream outcomes of interest. We
conduct a comprehensive literature review in order to disentangle these
different normative considerations and propose a taxonomy of different
objectives with mathematical definitions. We focus on observational metrics
that do not assume access to an underlying valuation distribution which is
either unobserved due to binary feedback or ill-defined due to overriding
behavioral concerns regarding interpreting revealed preferences. In the setting
of personalized pricing for the provision of goods with positive benefits, we
discuss how price optimization may provide unambiguous benefit by achieving a
"triple bottom line": personalized pricing enables expanding access, which in
turn may lead to gains in welfare due to heterogeneous utility, and improve
revenue or budget utilization. We empirically demonstrate the potential
benefits of personalized pricing in two settings: pricing subsidies for an
elective vaccine, and the effects of personalized interest rates on downstream
outcomes in microcredit.
</p>
<a href="http://arxiv.org/abs/2012.11066" target="_blank">arXiv:2012.11066</a> [<a href="http://arxiv.org/pdf/2012.11066" target="_blank">pdf</a>]

<h2>On Relating 'Why?' and 'Why Not?' Explanations. (arXiv:2012.11067v1 [cs.LG])</h2>
<h3>Alexey Ignatiev, Nina Narodytska, Nicholas Asher, Joao Marques-Silva</h3>
<p>Explanations of Machine Learning (ML) models often address a 'Why?' question.
Such explanations can be related with selecting feature-value pairs which are
sufficient for the prediction. Recent work has investigated explanations that
address a 'Why Not?' question, i.e. finding a change of feature values that
guarantee a change of prediction. Given their goals, these two forms of
explaining predictions of ML models appear to be mostly unrelated. However,
this paper demonstrates otherwise, and establishes a rigorous formal
relationship between 'Why?' and 'Why Not?' explanations. Concretely, the paper
proves that, for any given instance, 'Why?' explanations are minimal hitting
sets of 'Why Not?' explanations and vice-versa. Furthermore, the paper devises
novel algorithms for extracting and enumerating both forms of explanations.
</p>
<a href="http://arxiv.org/abs/2012.11067" target="_blank">arXiv:2012.11067</a> [<a href="http://arxiv.org/pdf/2012.11067" target="_blank">pdf</a>]

<h2>Regularization in neural network optimization via trimmed stochastic gradient descent with noisy label. (arXiv:2012.11073v1 [cs.LG])</h2>
<h3>Kensuke Nakamura, Byung-Woo Hong</h3>
<p>Regularization is essential for avoiding over-fitting to training data in
neural network optimization, leading to better generalization of the trained
networks. The label noise provides a strong implicit regularization by
replacing the target ground truth labels of training examples by uniform random
labels. However, it may also cause undesirable misleading gradients due to the
large loss associated with incorrect labels. We propose a first-order
optimization method (Label-Noised Trim-SGD) which combines the label noise with
the example trimming in order to remove the outliers. The proposed algorithm
enables us to impose a large label noise and obtain a better regularization
effect than the original methods. The quantitative analysis is performed by
comparing the behavior of the label noise, the example trimming, and the
proposed algorithm. We also present empirical results that demonstrate the
effectiveness of our algorithm using the major benchmarks and the fundamental
networks, where our method has successfully outperformed the state-of-the-art
optimization methods.
</p>
<a href="http://arxiv.org/abs/2012.11073" target="_blank">arXiv:2012.11073</a> [<a href="http://arxiv.org/pdf/2012.11073" target="_blank">pdf</a>]

<h2>DynamicHS: Streamlining Reiter's Hitting-Set Tree for Sequential Diagnosis. (arXiv:2012.11078v1 [cs.AI])</h2>
<h3>Patrick Rodler</h3>
<p>Given a system that does not work as expected, Sequential Diagnosis (SD) aims
at suggesting a series of system measurements to isolate the true explanation
for the system's misbehavior from a potentially exponential set of possible
explanations. To reason about the best next measurement, SD methods usually
require a sample of possible fault explanations at each step of the iterative
diagnostic process. The computation of this sample can be accomplished by
various diagnostic search algorithms. Among those, Reiter's HS-Tree is one of
the most popular due its desirable properties and general applicability.
Usually, HS-Tree is used in a stateless fashion throughout the SD process to
(re)compute a sample of possible fault explanations in each iteration, each
time given the latest (updated) system knowledge including all so-far collected
measurements. At this, the built search tree is discarded between two
iterations, although often large parts of the tree have to be rebuilt in the
next iteration, involving redundant operations and calls to costly reasoning
services.

As a remedy to this, we propose DynamicHS, a variant of HS-Tree that
maintains state throughout the diagnostic session and additionally embraces
special strategies to minimize the number of expensive reasoner invocations. In
this vein, DynamicHS provides an answer to a longstanding question posed by
Raymond Reiter in his seminal paper from 1987.

Extensive evaluations on real-world diagnosis problems prove the
reasonability of the DynamicHS and testify its clear superiority to HS-Tree
wrt. computation time. More specifically, DynamicHS outperformed HS-Tree in 96%
of the executed sequential diagnosis sessions and, per run, the latter required
up to 800% the time of the former. Remarkably, DynamicHS achieves these
performance improvements while preserving all desirable properties as well as
the general applicability of HS-Tree.
</p>
<a href="http://arxiv.org/abs/2012.11078" target="_blank">arXiv:2012.11078</a> [<a href="http://arxiv.org/pdf/2012.11078" target="_blank">pdf</a>]

<h2>A Note on Graph-Based Nearest Neighbor Search. (arXiv:2012.11083v1 [cs.LG])</h2>
<h3>Hongya Wang, Zhizheng Wang, Wei Wang, Yingyuan Xiao, Zeng Zhao, Kaixiang Yang</h3>
<p>Nearest neighbor search has found numerous applications in machine learning,
data mining and massive data processing systems. The past few years have
witnessed the popularity of the graph-based nearest neighbor search paradigm
because of its superiority over the space-partitioning algorithms. While a lot
of empirical studies demonstrate the efficiency of graph-based algorithms, not
much attention has been paid to a more fundamental question: why graph-based
algorithms work so well in practice? And which data property affects the
efficiency and how? In this paper, we try to answer these questions. Our
insight is that "the probability that the neighbors of a point o tends to be
neighbors in the KNN graph" is a crucial data property for query efficiency.
For a given dataset, such a property can be qualitatively measured by
clustering coefficient of the KNN graph. To show how clustering coefficient
affects the performance, we identify that, instead of the global connectivity,
the local connectivity around some given query q has more direct impact on
recall. Specifically, we observed that high clustering coefficient makes most
of the k nearest neighbors of q sit in a maximum strongly connected component
(SCC) in the graph. From the algorithmic point of view, we show that the search
procedure is actually composed of two phases - the one outside the maximum SCC
and the other one in it, which is different from the widely accepted single or
multiple paths search models. We proved that the commonly used graph-based
search algorithm is guaranteed to traverse the maximum SCC once visiting any
point in it. Our analysis reveals that high clustering coefficient leads to
large size of the maximum SCC, and thus provides good answer quality with the
help of the two-phase search procedure. Extensive empirical results over a
comprehensive collection of datasets validate our findings.
</p>
<a href="http://arxiv.org/abs/2012.11083" target="_blank">arXiv:2012.11083</a> [<a href="http://arxiv.org/pdf/2012.11083" target="_blank">pdf</a>]

<h2>Complexity of zigzag sampling algorithm for strongly log-concave distributions. (arXiv:2012.11094v1 [stat.ML])</h2>
<h3>Jianfeng Lu, Lihan Wang</h3>
<p>We study the computational complexity of zigzag sampling algorithm for
strongly log-concave distributions. The zigzag process has the advantage of not
requiring time discretization for implementation, and that each proposed
bouncing event requires only one evaluation of partial derivative of the
potential, while its convergence rate is dimension independent. Using these
properties, we prove that the zigzag sampling algorithm achieves $\varepsilon$
error in chi-square divergence with a computational cost equivalent to
$O\bigl(\kappa^2 d^\frac{1}{2}(\log\frac{1}{\varepsilon})^{\frac{3}{2}}\bigr)$
gradient evaluations in the regime $\kappa \ll \frac{d}{\log d}$ under a warm
start assumption, where $\kappa$ is the condition number and $d$ is the
dimension.
</p>
<a href="http://arxiv.org/abs/2012.11094" target="_blank">arXiv:2012.11094</a> [<a href="http://arxiv.org/pdf/2012.11094" target="_blank">pdf</a>]

<h2>ResizeMix: Mixing Data with Preserved Object Information and True Labels. (arXiv:2012.11101v1 [cs.CV])</h2>
<h3>Jie Qin, Jiemin Fang, Qian Zhang, Wenyu Liu, Xingang Wang, Xinggang Wang</h3>
<p>Data augmentation is a powerful technique to increase the diversity of data,
which can effectively improve the generalization ability of neural networks in
image recognition tasks. Recent data mixing based augmentation strategies have
achieved great success. Especially, CutMix uses a simple but effective method
to improve the classifiers by randomly cropping a patch from one image and
pasting it on another image. To further promote the performance of CutMix, a
series of works explore to use the saliency information of the image to guide
the mixing. We systematically study the importance of the saliency information
for mixing data, and find that the saliency information is not so necessary for
promoting the augmentation performance. Furthermore, we find that the cutting
based data mixing methods carry two problems of label misallocation and object
information missing, which cannot be resolved simultaneously. We propose a more
effective but very easily implemented method, namely ResizeMix. We mix the data
by directly resizing the source image to a small patch and paste it on another
image. The obtained patch preserves more substantial object information
compared with conventional cut-based methods. ResizeMix shows evident
advantages over CutMix and the saliency-guided methods on both image
classification and object detection tasks without additional computation cost,
which even outperforms most costly search-based automatic augmentation methods.
</p>
<a href="http://arxiv.org/abs/2012.11101" target="_blank">arXiv:2012.11101</a> [<a href="http://arxiv.org/pdf/2012.11101" target="_blank">pdf</a>]

<h2>Unfolded Algorithms for Deep Phase Retrieval. (arXiv:2012.11102v1 [stat.ML])</h2>
<h3>Naveed Naimipour, Shahin Khobahi, Mojtaba Soltanalian</h3>
<p>Exploring the idea of phase retrieval has been intriguing researchers for
decades, due to its appearance in a wide range of applications. The task of a
phase retrieval algorithm is typically to recover a signal from linear
phaseless measurements. In this paper, we approach the problem by proposing a
hybrid model-based data-driven deep architecture, referred to as Unfolded Phase
Retrieval (UPR), that exhibits significant potential in improving the
performance of state-of-the art data-driven and model-based phase retrieval
algorithms. The proposed method benefits from versatility and interpretability
of well-established model-based algorithms, while simultaneously benefiting
from the expressive power of deep neural networks. In particular, our proposed
model-based deep architecture is applied to the conventional phase retrieval
problem (via the incremental reshaped Wirtinger flow algorithm) and the sparse
phase retrieval problem (via the sparse truncated amplitude flow algorithm),
showing immense promise in both cases. Furthermore, we consider a joint design
of the sensing matrix and the signal processing algorithm and utilize the deep
unfolding technique in the process. Our numerical results illustrate the
effectiveness of such hybrid model-based and data-driven frameworks and
showcase the untapped potential of data-aided methodologies to enhance the
existing phase retrieval algorithms.
</p>
<a href="http://arxiv.org/abs/2012.11102" target="_blank">arXiv:2012.11102</a> [<a href="http://arxiv.org/pdf/2012.11102" target="_blank">pdf</a>]

<h2>Disease Forecast via Progression Learning. (arXiv:2012.11107v1 [cs.CV])</h2>
<h3>Botong Wu, Sijie Ren, Jing Li, Xinwei Sun, Shiming Li, Yizhou Wang</h3>
<p>Forecasting Parapapillary atrophy (PPA), i.e., a symptom related to most
irreversible eye diseases, provides an alarm for implementing an intervention
to slow down the disease progression at early stage. A key question for this
forecast is: how to fully utilize the historical data (e.g., retinal image) up
to the current stage for future disease prediction? In this paper, we provide
an answer with a novel framework, namely \textbf{D}isease \textbf{F}orecast via
\textbf{P}rogression \textbf{L}earning (\textbf{DFPL}), which exploits the
irreversibility prior (i.e., cannot be reversed once diagnosed). Specifically,
based on this prior, we decompose two factors that contribute to the prediction
of the future disease: i) the current disease label given the data (retinal
image, clinical attributes) at present and ii) the future disease label given
the progression of the retinal images that from the current to the future. To
model these two factors, we introduce the current and progression predictors in
DFPL, respectively. In order to account for the degree of progression of the
disease, we propose a temporal generative model to accurately generate the
future image and compare it with the current one to get a residual image. The
generative model is implemented by a recurrent neural network, in order to
exploit the dependency of the historical data. To verify our approach, we apply
it to a PPA in-house dataset and it yields a significant improvement
(\textit{e.g.}, \textbf{4.48\%} of accuracy; \textbf{3.45\%} of AUC) over
others. Besides, our generative model can accurately localize the
disease-related regions.
</p>
<a href="http://arxiv.org/abs/2012.11107" target="_blank">arXiv:2012.11107</a> [<a href="http://arxiv.org/pdf/2012.11107" target="_blank">pdf</a>]

<h2>Improving unsupervised anomaly localization by applying multi-scale memories to autoencoders. (arXiv:2012.11113v1 [cs.CV])</h2>
<h3>Yifei Yang, Shibing Xiang, Ruixiang Zhang</h3>
<p>Autoencoder and its variants have been widely applicated in anomaly
detection.The previous work memory-augmented deep autoencoder proposed
memorizing normality to detect anomaly, however it neglects the feature
discrepancy between different resolution scales, therefore we introduce
multi-scale memories to record scale-specific features and multi-scale
attention fuser between the encoding and decoding module of the autoencoder for
anomaly detection, namely MMAE.MMAE updates slots at corresponding resolution
scale as prototype features during unsupervised learning. For anomaly
detection, we accomplish anomaly removal by replacing the original encoded
image features at each scale with most relevant prototype features,and fuse
these features before feeding to the decoding module to reconstruct image.
Experimental results on various datasets testify that our MMAE successfully
removes anomalies at different scales and performs favorably on several
datasets compared to similar reconstruction-based methods.
</p>
<a href="http://arxiv.org/abs/2012.11113" target="_blank">arXiv:2012.11113</a> [<a href="http://arxiv.org/pdf/2012.11113" target="_blank">pdf</a>]

<h2>EMLight: Lighting Estimation via Spherical Distribution Approximation. (arXiv:2012.11116v1 [cs.CV])</h2>
<h3>Fangneng Zhan, Changgong Zhang, Yingchen Yu, Yuan Chang, Shijian Lu, Feiying Ma, Xuansong Xie</h3>
<p>Illumination estimation from a single image is critical in 3D rendering and
it has been investigated extensively in the computer vision and computer
graphic research community. On the other hand, existing works estimate
illumination by either regressing light parameters or generating illumination
maps that are often hard to optimize or tend to produce inaccurate predictions.
We propose Earth Mover Light (EMLight), an illumination estimation framework
that leverages a regression network and a neural projector for accurate
illumination estimation. We decompose the illumination map into spherical light
distribution, light intensity and the ambient term, and define the illumination
estimation as a parameter regression task for the three illumination
components. Motivated by the Earth Mover distance, we design a novel spherical
mover's loss that guides to regress light distribution parameters accurately by
taking advantage of the subtleties of spherical distribution. Under the
guidance of the predicted spherical distribution, light intensity and ambient
term, the neural projector synthesizes panoramic illumination maps with
realistic light frequency. Extensive experiments show that EMLight achieves
accurate illumination estimation and the generated relighting in 3D object
embedding exhibits superior plausibility and fidelity as compared with
state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2012.11116" target="_blank">arXiv:2012.11116</a> [<a href="http://arxiv.org/pdf/2012.11116" target="_blank">pdf</a>]

<h2>Weight-Based Exploration for Unmanned Aerial Teams Searching for Multiple Survivors. (arXiv:2012.11131v1 [cs.RO])</h2>
<h3>Sarthak J. Shetty, Debasish Ghose</h3>
<p>During floods, reaching survivors in the shortest possible time is a priority
for rescue teams. Given their ability to explore difficult terrain in short
spans of time, Unmanned Aerial Vehicles (UAVs) have become an increasingly
valuable aid to search and rescue operations. Traditionally, UAVs utilize
exhaustive lawnmower exploration patterns to locate stranded survivors, without
any information regarding the survivor's whereabouts. In real life disaster
scenarios however, on-ground observers provide valuable information to the
rescue effort, such as the survivor's last known location and heading. In
earlier work, a Weight Based Exploration (WBE) model, which utilizes this
information to generate a prioritized list of waypoints to aid the UAV in its
search mission, was proposed. This approach was shown to be effective for a
single UAV locating a single survivor. In this paper, we extend the WBE model
to a team of UAVs locating multiple survivors. The model initially partitions
the search environment amongst the UAVs using Voronoi cells. The UAVs then
utilize the WBE model to locate survivors in their partitions. We test this
model with varying survivor locations and headings. We demonstrate the
scalability of the model developed by testing the model with aerial teams
comprising several UAVs.
</p>
<a href="http://arxiv.org/abs/2012.11131" target="_blank">arXiv:2012.11131</a> [<a href="http://arxiv.org/pdf/2012.11131" target="_blank">pdf</a>]

<h2>Learning content and context with language bias for Visual Question Answering. (arXiv:2012.11134v1 [cs.CV])</h2>
<h3>Chao Yang, Su Feng, Dongsheng Li, Huawei Shen, Guoqing Wang, Bin Jiang</h3>
<p>Visual Question Answering (VQA) is a challenging multimodal task to answer
questions about an image. Many works concentrate on how to reduce language bias
which makes models answer questions ignoring visual content and language
context. However, reducing language bias also weakens the ability of VQA models
to learn context prior. To address this issue, we propose a novel learning
strategy named CCB, which forces VQA models to answer questions relying on
Content and Context with language Bias. Specifically, CCB establishes Content
and Context branches on top of a base VQA model and forces them to focus on
local key content and global effective context respectively. Moreover, a joint
loss function is proposed to reduce the importance of biased samples and retain
their beneficial influence on answering questions. Experiments show that CCB
outperforms the state-of-the-art methods in terms of accuracy on VQA-CP v2.
</p>
<a href="http://arxiv.org/abs/2012.11134" target="_blank">arXiv:2012.11134</a> [<a href="http://arxiv.org/pdf/2012.11134" target="_blank">pdf</a>]

<h2>LQF: Linear Quadratic Fine-Tuning. (arXiv:2012.11140v1 [cs.LG])</h2>
<h3>Alessandro Achille, Aditya Golatkar, Avinash Ravichandran, Marzia Polito, Stefano Soatto</h3>
<p>Classifiers that are linear in their parameters, and trained by optimizing a
convex loss function, have predictable behavior with respect to changes in the
training data, initial conditions, and optimization. Such desirable properties
are absent in deep neural networks (DNNs), typically trained by non-linear
fine-tuning of a pre-trained model. Previous attempts to linearize DNNs have
led to interesting theoretical insights, but have not impacted the practice due
to the substantial performance gap compared to standard non-linear
optimization. We present the first method for linearizing a pre-trained model
that achieves comparable performance to non-linear fine-tuning on most of
real-world image classification tasks tested, thus enjoying the
interpretability of linear models without incurring punishing losses in
performance. LQF consists of simple modifications to the architecture, loss
function and optimization typically used for classification: Leaky-ReLU instead
of ReLU, mean squared loss instead of cross-entropy, and pre-conditioning using
Kronecker factorization. None of these changes in isolation is sufficient to
approach the performance of non-linear fine-tuning. When used in combination,
they allow us to reach comparable performance, and even superior in the
low-data regime, while enjoying the simplicity, robustness and interpretability
of linear-quadratic optimization.
</p>
<a href="http://arxiv.org/abs/2012.11140" target="_blank">arXiv:2012.11140</a> [<a href="http://arxiv.org/pdf/2012.11140" target="_blank">pdf</a>]

<h2>Hop-Hop Relation-aware Graph Neural Networks. (arXiv:2012.11147v1 [cs.LG])</h2>
<h3>Li Zhang, Yan Ge, Haiping Lu</h3>
<p>Graph Neural Networks (GNNs) are widely used in graph representation
learning. However, most GNN methods are designed for either homogeneous or
heterogeneous graphs. In this paper, we propose a new model, Hop-Hop
Relation-aware Graph Neural Network (HHR-GNN), to unify representation learning
for these two types of graphs. HHR-GNN learns a personalized receptive field
for each node by leveraging knowledge graph embedding to learn relation scores
between the central node's representations at different hops. In neighborhood
aggregation, our model simultaneously allows for hop-aware projection and
aggregation. This mechanism enables the central node to learn a hop-wise
neighborhood mixing that can be applied to both homogeneous and heterogeneous
graphs. Experimental results on five benchmarks show the competitive
performance of our model compared to state-of-the-art GNNs, e.g., up to 13K
faster in terms of time cost per training epoch on large heterogeneous graphs.
</p>
<a href="http://arxiv.org/abs/2012.11147" target="_blank">arXiv:2012.11147</a> [<a href="http://arxiv.org/pdf/2012.11147" target="_blank">pdf</a>]

<h2>Improving Unsupervised Image Clustering With Robust Learning. (arXiv:2012.11150v1 [cs.CV])</h2>
<h3>Sungwon Park, Sungwon Han, Sundong Kim, Danu Kim, Sungkyu Park, Seunghoon Hong, Meeyoung Cha</h3>
<p>Unsupervised image clustering methods often introduce alternative objectives
to indirectly train the model and are subject to faulty predictions and
overconfident results. To overcome these challenges, the current research
proposes an innovative model RUC that is inspired by robust learning. RUC's
novelty is at utilizing pseudo-labels of existing image clustering models as a
noisy dataset that may include misclassified samples. Its retraining process
can revise misaligned knowledge and alleviate the overconfidence problem in
predictions. This model's flexible structure makes it possible to be used as an
add-on module to state-of-the-art clustering methods and helps them achieve
better performance on multiple datasets. Extensive experiments show that the
proposed model can adjust the model confidence with better calibration and gain
additional robustness against adversarial noise.
</p>
<a href="http://arxiv.org/abs/2012.11150" target="_blank">arXiv:2012.11150</a> [<a href="http://arxiv.org/pdf/2012.11150" target="_blank">pdf</a>]

<h2>Automated segmentation of an intensity calibration phantom in clinical CT images using a convolutional neural network. (arXiv:2012.11151v1 [cs.CV])</h2>
<h3>Keisuke Uemura (1 and 2), Yoshito Otake (1), Masaki Takao (3), Mazen Soufi (1), Akihiro Kawasaki (1), Nobuhiko Sugano (2), Yoshinobu Sato (1) ((1) Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma city, Japan, (2) Department of Orthopaedic Medical Engineering, Osaka University Graduate School of Medicine, Suita city, Japan, (3) Department of Orthopaedics, Osaka University Graduate School of Medicine, Suita city, Japan)</h3>
<p>Purpose: To apply a convolutional neural network (CNN) to develop a system
that segments intensity calibration phantom regions in computed tomography (CT)
images, and to test the system in a large cohort to evaluate its robustness.
Methods: A total of 1040 cases (520 cases each from two institutions), in which
an intensity calibration phantom (B-MAS200, Kyoto Kagaku, Kyoto, Japan) was
used, were included herein. A training dataset was created by manually
segmenting the regions of the phantom for 40 cases (20 cases each).
Segmentation accuracy of the CNN model was assessed with the Dice coefficient
and the average symmetric surface distance (ASD) through the 4-fold cross
validation. Further, absolute differences of radiodensity values (in Hounsfield
units: HU) were compared between manually segmented regions and automatically
segmented regions. The system was tested on the remaining 1000 cases. For each
institution, linear regression was applied to calculate coefficients for the
correlation between radiodensity and the densities of the phantom. Results:
After training, the median Dice coefficient was 0.977, and the median ASD was
0.116 mm. When segmented regions were compared between manual segmentation and
automated segmentation, the median absolute difference was 0.114 HU. For the
test cases, the median correlation coefficient was 0.9998 for one institution
and was 0.9999 for the other, with a minimum value of 0.9863. Conclusions: The
CNN model successfully segmented the calibration phantom's regions in the CT
images with excellent accuracy, and the automated method was found to be at
least equivalent to the conventional manual method. Future study should
integrate the system by automatically segmenting the region of interest in
bones such that the bone mineral density can be fully automatically quantified
from CT images.
</p>
<a href="http://arxiv.org/abs/2012.11151" target="_blank">arXiv:2012.11151</a> [<a href="http://arxiv.org/pdf/2012.11151" target="_blank">pdf</a>]

<h2>FlowDB a large scale precipitation, river, and flash flood dataset. (arXiv:2012.11154v1 [cs.AI])</h2>
<h3>Isaac Godfried, Kriti Mahajan, Maggie Wang, Kevin Li, Pranjalya Tiwari</h3>
<p>Flooding results in 8 billion dollars of damage annually in the US and causes
the most deaths of any weather related event. Due to climate change scientists
expect more heavy precipitation events in the future. However, no current
datasets exist that contain both hourly precipitation and river flow data. We
introduce a novel hourly river flow and precipitation dataset and a second
subset of flash flood events with damage estimates and injury counts. Using
these datasets we create two challenges (1) general stream flow forecasting and
(2) flash flood damage estimation. We have created several publicly available
benchmarks and an easy to use package. Additionally, in the future we aim to
augment our dataset with snow pack data and soil index moisture data to improve
predictions.
</p>
<a href="http://arxiv.org/abs/2012.11154" target="_blank">arXiv:2012.11154</a> [<a href="http://arxiv.org/pdf/2012.11154" target="_blank">pdf</a>]

<h2>Mobile Robot Planner with Low-cost Cameras Using Deep Reinforcement Learning. (arXiv:2012.11160v1 [cs.RO])</h2>
<h3>Minh Q. Tran, Ngoc Q. Ly</h3>
<p>This study develops a robot mobility policy based on deep reinforcement
learning. Since traditional methods of conventional robotic navigation depend
on accurate map reproduction as well as require high-end sensors,
learning-based methods are positive trends, especially deep reinforcement
learning. The problem is modeled in the form of a Markov Decision Process (MDP)
with the agent being a mobile robot. Its state of view is obtained by the input
sensors such as laser findings or cameras and the purpose is navigating to the
goal without any collision. There have been many deep learning methods that
solve this problem. However, in order to bring robots to market, low-cost mass
production is also an issue that needs to be addressed. Therefore, this work
attempts to construct a pseudo laser findings system based on direct depth
matrix prediction from a single camera image while still retaining stable
performances. Experiment results show that they are directly comparable with
others using high-priced sensors.
</p>
<a href="http://arxiv.org/abs/2012.11160" target="_blank">arXiv:2012.11160</a> [<a href="http://arxiv.org/pdf/2012.11160" target="_blank">pdf</a>]

<h2>Who will accept my request? Predicting response of link initiation in two-way relation networks. (arXiv:2012.11172v1 [cs.AI])</h2>
<h3>Amin Javari, Mehrab Norouzitallab, Mahdi Jalili</h3>
<p>Popularity of social networks has rapidly increased over the past few years,
and daily lives interrupt without their proper functioning. Social networking
platform provide multiple interaction types between individuals, such as
creating and joining groups, sending and receiving messages, sharing interests
and creating friendship relationships. This paper addresses an important
problem in social networks analysis and mining that is how to predict link
initiation feedback in two-way networks. Relationships between two individuals
in a two-way network include a link invitation from one of the individuals,
which will be an established link if it is accepted by the invitee. We consider
a sport gaming social networking platform and construct a multilayer social
network between a number of users. The network formed by the link initiation
process is on one of the layers, while the other two layers include a messaging
relationships and interactions between the users. We propose a methodology to
solve the link initiation feedback prediction problem in this multilayer
fashion. The proposed method is based on features extracted from meta-paths,
i.e. paths defined between different individuals from multiples layers in
multilayer networks. We proposed a cluster-based approach to handle the
sparsity issue in the dataset. Experimental results show that the proposed
method can provide accurate prediction that outperforms state-of-the-art
methods.
</p>
<a href="http://arxiv.org/abs/2012.11172" target="_blank">arXiv:2012.11172</a> [<a href="http://arxiv.org/pdf/2012.11172" target="_blank">pdf</a>]

<h2>Learn molecular representations from large-scale unlabeled molecules for drug discovery. (arXiv:2012.11175v1 [cs.LG])</h2>
<h3>Pengyong Li, Jun Wang, Yixuan Qiao, Hao Chen, Yihuan Yu, Xiaojun Yao, Peng Gao, Guotong Xie, Sen Song</h3>
<p>How to produce expressive molecular representations is a fundamental
challenge in AI-driven drug discovery. Graph neural network (GNN) has emerged
as a powerful technique for modeling molecular data. However, previous
supervised approaches usually suffer from the scarcity of labeled data and have
poor generalization capability. Here, we proposed a novel Molecular
Pre-training Graph-based deep learning framework, named MPG, that leans
molecular representations from large-scale unlabeled molecules. In MPG, we
proposed a powerful MolGNet model and an effective self-supervised strategy for
pre-training the model at both the node and graph-level. After pre-training on
11 million unlabeled molecules, we revealed that MolGNet can capture valuable
chemistry insights to produce interpretable representation. The pre-trained
MolGNet can be fine-tuned with just one additional output layer to create
state-of-the-art models for a wide range of drug discovery tasks, including
molecular properties prediction, drug-drug interaction, and drug-target
interaction, involving 13 benchmark datasets. Our work demonstrates that MPG is
promising to become a novel approach in the drug discovery pipeline.
</p>
<a href="http://arxiv.org/abs/2012.11175" target="_blank">arXiv:2012.11175</a> [<a href="http://arxiv.org/pdf/2012.11175" target="_blank">pdf</a>]

<h2>Optimizing Deep Neural Networks through Neuroevolution with Stochastic Gradient Descent. (arXiv:2012.11184v1 [cs.CV])</h2>
<h3>Haichao Zhang, Kuangrong Hao, Lei Gao, Bing Wei, Xuesong Tang</h3>
<p>Deep neural networks (DNNs) have achieved remarkable success in computer
vision; however, training DNNs for satisfactory performance remains challenging
and suffers from sensitivity to empirical selections of an optimization
algorithm for training. Stochastic gradient descent (SGD) is dominant in
training a DNN by adjusting neural network weights to minimize the DNNs loss
function. As an alternative approach, neuroevolution is more in line with an
evolutionary process and provides some key capabilities that are often
unavailable in SGD, such as the heuristic black-box search strategy based on
individual collaboration in neuroevolution. This paper proposes a novel
approach that combines the merits of both neuroevolution and SGD, enabling
evolutionary search, parallel exploration, and an effective probe for optimal
DNNs. A hierarchical cluster-based suppression algorithm is also developed to
overcome similar weight updates among individuals for improving population
diversity. We implement the proposed approach in four representative DNNs based
on four publicly-available datasets. Experiment results demonstrate that the
four DNNs optimized by the proposed approach all outperform corresponding ones
optimized by only SGD on all datasets. The performance of DNNs optimized by the
proposed approach also outperforms state-of-the-art deep networks. This work
also presents a meaningful attempt for pursuing artificial general
intelligence.
</p>
<a href="http://arxiv.org/abs/2012.11184" target="_blank">arXiv:2012.11184</a> [<a href="http://arxiv.org/pdf/2012.11184" target="_blank">pdf</a>]

<h2>Infrared image pedestrian target detection based on Yolov3 and migration learning. (arXiv:2012.11185v1 [cs.AI])</h2>
<h3>Shengqi Geng</h3>
<p>With the gradual application of infrared night vision vehicle assistance
system in automatic driving, the accuracy of the collected infrared images of
pedestrians is gradually improved. In this paper, the migration learning method
is used to apply YOLOv3 model to realize pedestrian target detection in
infrared images. The target detection model YOLOv3 is migrated to the CVC
infrared pedestrian data set, and Diou loss is used to replace the loss
function of the original YOLO model to test different super parameters to
obtain the best migration learning effect. The experimental results show that
in the pedestrian detection task of CVC data set, the average accuracy (AP) of
Yolov3 model reaches 96.35%, and that of Diou-Yolov3 model is 72.14%, but the
latter has a faster convergence rate of loss curve. The effect of migration
learning can be obtained by comparing the two models.
</p>
<a href="http://arxiv.org/abs/2012.11185" target="_blank">arXiv:2012.11185</a> [<a href="http://arxiv.org/pdf/2012.11185" target="_blank">pdf</a>]

<h2>Diverse Knowledge Distillation for End-to-End Person Search. (arXiv:2012.11187v1 [cs.CV])</h2>
<h3>Xinyu Zhang, Xinlong Wang, Jia-Wang Bian, Chunhua Shen, Mingyu You</h3>
<p>Person search aims to localize and identify a specific person from a gallery
of images. Recent methods can be categorized into two groups, i.e., two-step
and end-to-end approaches. The former views person search as two independent
tasks and achieves dominant results using separately trained person detection
and re-identification (Re-ID) models. The latter performs person search in an
end-to-end fashion. Although the end-to-end approaches yield higher inference
efficiency, they largely lag behind those two-step counterparts in terms of
accuracy. In this paper, we argue that the gap between the two kinds of methods
is mainly caused by the Re-ID sub-networks of end-to-end methods. To this end,
we propose a simple yet strong end-to-end network with diverse knowledge
distillation to break the bottleneck. We also design a spatial-invariant
augmentation to assist model to be invariant to inaccurate detection results.
Experimental results on the CUHK-SYSU and PRW datasets demonstrate the
superiority of our method against existing approaches -- it achieves on par
accuracy with state-of-the-art two-step methods while maintaining high
efficiency due to the single joint model. Code is available at:
https://git.io/DKD-PersonSearch.
</p>
<a href="http://arxiv.org/abs/2012.11187" target="_blank">arXiv:2012.11187</a> [<a href="http://arxiv.org/pdf/2012.11187" target="_blank">pdf</a>]

<h2>Image Translation via Fine-grained Knowledge Transfer. (arXiv:2012.11193v1 [cs.CV])</h2>
<h3>Xuanhong Chen, Ziang Liu, Ting Qiu, Bingbing Ni, Naiyuan Liu, Xiwei Hu, Yuhan Li</h3>
<p>Prevailing image-translation frameworks mostly seek to process images via the
end-to-end style, which has achieved convincing results. Nonetheless, these
methods lack interpretability and are not scalable on different
image-translation tasks (e.g., style transfer, HDR, etc.). In this paper, we
propose an interpretable knowledge-based image-translation framework, which
realizes the image-translation through knowledge retrieval and transfer. In
details, the framework constructs a plug-and-play and model-agnostic general
purpose knowledge library, remembering task-specific styles, tones, texture
patterns, etc. Furthermore, we present a fast ANN searching approach, Bandpass
Hierarchical K-Means (BHKM), to cope with the difficulty of searching in the
enormous knowledge library. Extensive experiments well demonstrate the
effectiveness and feasibility of our framework in different image-translation
tasks. In particular, backtracking experiments verify the interpretability of
our method. Our code soon will be available at
https://github.com/AceSix/Knowledge_Transfer.
</p>
<a href="http://arxiv.org/abs/2012.11193" target="_blank">arXiv:2012.11193</a> [<a href="http://arxiv.org/pdf/2012.11193" target="_blank">pdf</a>]

<h2>Personalized fall detection monitoring system based on learning from the user movements. (arXiv:2012.11195v1 [cs.LG])</h2>
<h3>Pranesh Vallabh, Nazanin Malekian, Reza Malekian, Ting-Mei Li</h3>
<p>Personalized fall detection system is shown to provide added and more
benefits compare to the current fall detection system. The personalized model
can also be applied to anything where one class of data is hard to gather. The
results show that adapting to the user needs, improve the overall accuracy of
the system. Future work includes detection of the smartphone on the user so
that the user can place the system anywhere on the body and make sure it
detects. Even though the accuracy is not 100% the proof of concept of
personalization can be used to achieve greater accuracy. The concept of
personalization used in this paper can also be extended to other research in
the medical field or where data is hard to come by for a particular class. More
research into the feature extraction and feature selection module should be
investigated. For the feature selection module, more research into selecting
features based on one class data.
</p>
<a href="http://arxiv.org/abs/2012.11195" target="_blank">arXiv:2012.11195</a> [<a href="http://arxiv.org/pdf/2012.11195" target="_blank">pdf</a>]

<h2>Spatial Monte Carlo Integration with Annealed Importance Sampling. (arXiv:2012.11198v1 [stat.ML])</h2>
<h3>Muneki Yasuda, Kaiji Sekimoto</h3>
<p>Evaluating expectations on a pairwise Boltzmann machine (PBM) (or Ising
model) is important for various applications, including the statistical machine
learning. However, in general the evaluation is computationally difficult
because it involves intractable multiple summations or integrations; therefore,
it requires an approximation. Monte Carlo integration (MCI) is a well-known
approximation method; a more effective MCI-like approximation method was
proposed recently, called spatial Monte Carlo integration (SMCI). However, the
estimations obtained from SMCI (and MCI) tend to perform poorly in PBMs with
low temperature owing to degradation of the sampling quality. Annealed
importance sampling (AIS) is a type of importance sampling based on Markov
chain Monte Carlo methods, and it can suppress performance degradation in low
temperature regions by the force of importance weights. In this study, a new
method is proposed to evaluate the expectations on PBMs combining AIS and SMCI.
The proposed method performs efficiently in both high- and low-temperature
regions, which is theoretically and numerically demonstrated.
</p>
<a href="http://arxiv.org/abs/2012.11198" target="_blank">arXiv:2012.11198</a> [<a href="http://arxiv.org/pdf/2012.11198" target="_blank">pdf</a>]

<h2>On Success and Simplicity: A Second Look at Transferable Targeted Attacks. (arXiv:2012.11207v1 [cs.LG])</h2>
<h3>Zhengyu Zhao, Zhuoran Liu, Martha Larson</h3>
<p>There is broad consensus among researchers studying adversarial examples that
it is extremely difficult to achieve transferability of targeted attacks.
Currently, existing research strives for transferability of targeted attacks by
resorting to sophisticated losses and even massive training. In this paper, we
take a second look at the transferability of targeted attacks and show that
their difficulty has been overestimated due to a blind spot in the conventional
evaluation procedures. Specifically, current work has unreasonably restricted
attack optimization to a few iterations. Here, we show that targeted attacks
converge slowly to optimal transferability and improve considerably when given
more iterations. We also demonstrate that an attack that simply maximizes the
target logit performs surprisingly well, remarkably surpassing more complex
losses and even achieving performance comparable to the state of the art, which
requires massive training with sophisticated loss. We provide further
validation of our logit attack in a realistic ensemble setting and in a
real-world attack against the Google Cloud Vision. The logit attack produces
perturbations that reflect the target semantics, which we demonstrate allows us
to create targeted universal adversarial perturbations without additional
training images.
</p>
<a href="http://arxiv.org/abs/2012.11207" target="_blank">arXiv:2012.11207</a> [<a href="http://arxiv.org/pdf/2012.11207" target="_blank">pdf</a>]

<h2>Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification. (arXiv:2012.11212v1 [cs.LG])</h2>
<h3>Siyuan Cheng, Yingqi Liu, Shiqing Ma, Xiangyu Zhang</h3>
<p>Trojan (backdoor) attack is a form of adversarial attack on deep neural
networks where the attacker provides victims with a model trained/retrained on
malicious data. The backdoor can be activated when a normal input is stamped
with a certain pattern called trigger, causing misclassification. Many existing
trojan attacks have their triggers being input space patches/objects (e.g., a
polygon with solid color) or simple input transformations such as Instagram
filters. These simple triggers are susceptible to recent backdoor detection
algorithms. We propose a novel deep feature space trojan attack with five
characteristics: effectiveness, stealthiness, controllability, robustness and
reliance on deep features. We conduct extensive experiments on 9 image
classifiers on various datasets including ImageNet to demonstrate these
properties and show that our attack can evade state-of-the-art defense.
</p>
<a href="http://arxiv.org/abs/2012.11212" target="_blank">arXiv:2012.11212</a> [<a href="http://arxiv.org/pdf/2012.11212" target="_blank">pdf</a>]

<h2>Searching for Controllable Image Restoration Networks. (arXiv:2012.11225v1 [cs.CV])</h2>
<h3>Heewon Kim, Sungyong Baik, Myungsub Choi, Janghoon Choi, Kyoung Mu Lee</h3>
<p>Diverse user preferences over images have recently led to a great amount of
interest in controlling the imagery effects for image restoration tasks.
However, existing methods require separate inference through the entire network
per each output, which hinders users from readily comparing multiple imagery
effects due to long latency. To this end, we propose a novel framework based on
a neural architecture search technique that enables efficient generation of
multiple imagery effects via two stages of pruning: task-agnostic and
task-specific pruning. Specifically, task-specific pruning learns to adaptively
remove the irrelevant network parameters for each task, while task-agnostic
pruning learns to find an efficient architecture by sharing the early layers of
the network across different tasks. Since the shared layers allow for feature
reuse, only a single inference of the task-agnostic layers is needed to
generate multiple imagery effects from the input image. Using the proposed
task-agnostic and task-specific pruning schemes together significantly reduces
the FLOPs and the actual latency of inference compared to the baseline. We
reduce 95.7% of the FLOPs when generating 27 imagery effects, and make the GPU
latency 73.0% faster on 4K-resolution images.
</p>
<a href="http://arxiv.org/abs/2012.11225" target="_blank">arXiv:2012.11225</a> [<a href="http://arxiv.org/pdf/2012.11225" target="_blank">pdf</a>]

<h2>Alternating linear scheme in a Bayesian framework for low-rank tensor approximation. (arXiv:2012.11228v1 [cs.LG])</h2>
<h3>Clara Menzen, Manon Kok, Kim Batselier</h3>
<p>Multiway data often naturally occurs in a tensorial format which can be
approximately represented by a low-rank tensor decomposition. This is useful
because complexity can be significantly reduced and the treatment of
large-scale data sets can be facilitated. In this paper, we find a low-rank
representation for a given tensor by solving a Bayesian inference problem. This
is achieved by dividing the overall inference problem into sub-problems where
we sequentially infer the posterior distribution of one tensor decomposition
component at a time. This leads to a probabilistic interpretation of the
well-known iterative algorithm alternating linear scheme (ALS). In this way,
the consideration of measurement noise is enabled, as well as the incorporation
of application-specific prior knowledge and the uncertainty quantification of
the low-rank tensor estimate. To compute the low-rank tensor estimate from the
posterior distributions of the tensor decomposition components, we present an
algorithm that performs the unscented transform in tensor train format.
</p>
<a href="http://arxiv.org/abs/2012.11228" target="_blank">arXiv:2012.11228</a> [<a href="http://arxiv.org/pdf/2012.11228" target="_blank">pdf</a>]

<h2>DAQ: Distribution-Aware Quantization for Deep Image Super-Resolution Networks. (arXiv:2012.11230v1 [cs.CV])</h2>
<h3>Cheeun Hong, Heewon Kim, Junghun Oh, Kyoung Mu Lee</h3>
<p>Quantizing deep convolutional neural networks for image super-resolution
substantially reduces their computational costs. However, existing works either
suffer from a severe performance drop in ultra-low precision of 4 or lower
bit-widths, or require a heavy fine-tuning process to recover the performance.
To our knowledge, this vulnerability to low precisions relies on two
statistical observations of feature map values. First, distribution of feature
map values varies significantly per channel and per input image. Second,
feature maps have outliers that can dominate the quantization error. Based on
these observations, we propose a novel distribution-aware quantization scheme
(DAQ) which facilitates accurate training-free quantization in ultra-low
precision. A simple function of DAQ determines dynamic range of feature maps
and weights with low computational burden. Furthermore, our method enables
mixed-precision quantization by calculating the relative sensitivity of each
channel, without any training process involved. Nonetheless, quantization-aware
training is also applicable for auxiliary performance gain. Our new method
outperforms recent training-free and even training-based quantization methods
to the state-of-the-art image super-resolution networks in ultra-low precision.
</p>
<a href="http://arxiv.org/abs/2012.11230" target="_blank">arXiv:2012.11230</a> [<a href="http://arxiv.org/pdf/2012.11230" target="_blank">pdf</a>]

<h2>Get It Scored Using AutoSAS -- An Automated System for Scoring Short Answers. (arXiv:2012.11243v1 [cs.AI])</h2>
<h3>Yaman Kumar, Swati Aggarwal, Debanjan Mahata, Rajiv Ratn Shah, Ponnurangam Kumaraguru, Roger Zimmermann</h3>
<p>In the era of MOOCs, online exams are taken by millions of candidates, where
scoring short answers is an integral part. It becomes intractable to evaluate
them by human graders. Thus, a generic automated system capable of grading
these responses should be designed and deployed. In this paper, we present a
fast, scalable, and accurate approach towards automated Short Answer Scoring
(SAS). We propose and explain the design and development of a system for SAS,
namely AutoSAS. Given a question along with its graded samples, AutoSAS can
learn to grade that prompt successfully. This paper further lays down the
features such as lexical diversity, Word2Vec, prompt, and content overlap that
plays a pivotal role in building our proposed model. We also present a
methodology for indicating the factors responsible for scoring an answer. The
trained model is evaluated on an extensively used public dataset, namely
Automated Student Assessment Prize Short Answer Scoring (ASAP-SAS). AutoSAS
shows state-of-the-art performance and achieves better results by over 8% in
some of the question prompts as measured by Quadratic Weighted Kappa (QWK),
showing performance comparable to humans.
</p>
<a href="http://arxiv.org/abs/2012.11243" target="_blank">arXiv:2012.11243</a> [<a href="http://arxiv.org/pdf/2012.11243" target="_blank">pdf</a>]

<h2>Image Annotation based on Deep Hierarchical Context Networks. (arXiv:2012.11253v1 [cs.CV])</h2>
<h3>Mingyuan Jiu, Hichem Sahbi</h3>
<p>Context modeling is one of the most fertile subfields of visual recognition
which aims at designing discriminant image representations while incorporating
their intrinsic and extrinsic relationships. However, the potential of context
modeling is currently underexplored and most of the existing solutions are
either context-free or restricted to simple handcrafted geometric
relationships. We introduce in this paper DHCN: a novel Deep Hierarchical
Context Network that leverages different sources of contexts including
geometric and semantic relationships. The proposed method is based on the
minimization of an objective function mixing a fidelity term, a context
criterion and a regularizer. The solution of this objective function defines
the architecture of a bi-level hierarchical context network; the first level of
this network captures scene geometry while the second one corresponds to
semantic relationships. We solve this representation learning problem by
training its underlying deep network whose parameters correspond to the most
influencing bi-level contextual relationships and we evaluate its performances
on image annotation using the challenging ImageCLEF benchmark.
</p>
<a href="http://arxiv.org/abs/2012.11253" target="_blank">arXiv:2012.11253</a> [<a href="http://arxiv.org/pdf/2012.11253" target="_blank">pdf</a>]

<h2>Unsupervised Domain Adaptation with Temporal-Consistent Self-Training for 3D Hand-Object Joint Reconstruction. (arXiv:2012.11260v1 [cs.CV])</h2>
<h3>Mengshi Qi, Edoardo Remelli, Mathieu Salzmann, Pascal Fua</h3>
<p>Deep learning-solutions for hand-object 3D pose and shape estimation are now
very effective when an annotated dataset is available to train them to handle
the scenarios and lighting conditions they will encounter at test time.
Unfortunately, this is not always the case, and one often has to resort to
training them on synthetic data, which does not guarantee that they will work
well in real situations. In this paper, we introduce an effective approach to
addressing this challenge by exploiting 3D geometric constraints within a cycle
generative adversarial network (CycleGAN) to perform domain adaptation.
Furthermore, in contrast to most existing works, which fail to leverage the
rich temporal information available in unlabeled real videos as a source of
supervision, we propose to enforce short- and long-term temporal consistency to
fine-tune the domain-adapted model in a self-supervised fashion. We will
demonstrate that our approach outperforms state-of-the-art 3D hand-object joint
reconstruction methods on three widely-used benchmarks and will make our code
publicly available.
</p>
<a href="http://arxiv.org/abs/2012.11260" target="_blank">arXiv:2012.11260</a> [<a href="http://arxiv.org/pdf/2012.11260" target="_blank">pdf</a>]

<h2>Curiosity in exploring chemical space: Intrinsic rewards for deep molecular reinforcement learning. (arXiv:2012.11293v1 [cs.LG])</h2>
<h3>Luca A. Thiede, Mario Krenn, AkshatKumar Nigam, Alan Aspuru-Guzik</h3>
<p>Computer-aided design of molecules has the potential to disrupt the field of
drug and material discovery. Machine learning, and deep learning, in
particular, have been topics where the field has been developing at a rapid
pace. Reinforcement learning is a particularly promising approach since it
allows for molecular design without prior knowledge. However, the search space
is vast and efficient exploration is desirable when using reinforcement
learning agents. In this study, we propose an algorithm to aid efficient
exploration. The algorithm is inspired by a concept known in the literature as
curiosity. We show on three benchmarks that a curious agent finds better
performing molecules. This indicates an exciting new research direction for
reinforcement learning agents that can explore the chemical space out of their
own motivation. This has the potential to eventually lead to unexpected new
molecules that no human has thought about so far.
</p>
<a href="http://arxiv.org/abs/2012.11293" target="_blank">arXiv:2012.11293</a> [<a href="http://arxiv.org/pdf/2012.11293" target="_blank">pdf</a>]

<h2>Centralized Information Interaction for Salient Object Detection. (arXiv:2012.11294v1 [cs.CV])</h2>
<h3>Jiang-Jiang Liu, Zhi-Ang Liu, Ming-Ming Cheng</h3>
<p>The U-shape structure has shown its advantage in salient object detection for
efficiently combining multi-scale features. However, most existing U-shape
based methods focused on improving the bottom-up and top-down pathways while
ignoring the connections between them. This paper shows that by centralizing
these connections, we can achieve the cross-scale information interaction among
them, hence obtaining semantically stronger and positionally more precise
features. To inspire the potential of the newly proposed strategy, we further
design a relative global calibration module that can simultaneously process
multi-scale inputs without spatial interpolation. Benefiting from the above
strategy and module, our proposed approach can aggregate features more
effectively while introducing only a few additional parameters. Our approach
can cooperate with various existing U-shape-based salient object detection
methods by substituting the connections between the bottom-up and top-down
pathways. Experimental results demonstrate that our proposed approach performs
favorably against the previous state-of-the-arts on five widely used benchmarks
with less computational complexity. The source code will be publicly available.
</p>
<a href="http://arxiv.org/abs/2012.11294" target="_blank">arXiv:2012.11294</a> [<a href="http://arxiv.org/pdf/2012.11294" target="_blank">pdf</a>]

<h2>Sim-to-real for high-resolution optical tactile sensing: From images to 3D contact force distributions. (arXiv:2012.11295v1 [cs.RO])</h2>
<h3>Carmelo Sferrazza, Raffaello D&#x27;Andrea</h3>
<p>The images captured by vision-based tactile sensors carry information about
high-resolution tactile fields, such as the distribution of the contact forces
applied to their soft sensing surface. However, extracting the information
encoded in the images is challenging and often addressed with learning-based
approaches, which generally require a large amount of training data. This
article proposes a strategy to generate tactile images in simulation for a
vision-based tactile sensor based on an internal camera that tracks the motion
of spherical particles within a soft material. The deformation of the material
is simulated in a finite element environment under a diverse set of contact
conditions, and spherical particles are projected to a simulated image.
Features extracted from the images are mapped to the 3D contact force
distribution, with the ground truth also obtained via finite-element
simulations, with an artificial neural network that is therefore entirely
trained on synthetic data avoiding the need for real-world data collection. The
resulting model exhibits high accuracy when evaluated on real-world tactile
images, is transferable across multiple tactile sensors without further
training, and is suitable for efficient real-time inference.
</p>
<a href="http://arxiv.org/abs/2012.11295" target="_blank">arXiv:2012.11295</a> [<a href="http://arxiv.org/pdf/2012.11295" target="_blank">pdf</a>]

<h2>Deep Learning-based Prediction of Key Performance Indicators for Electrical Machine. (arXiv:2012.11299v1 [cs.LG])</h2>
<h3>Vivek Parekh, Dominik Flore, Sebastian Sch&#xf6;ps</h3>
<p>The design of an electrical machine can be quantified and evaluated by Key
Performance Indicators (KPIs) such as maximum torque, critical field strength,
costs of active parts, sound power, etc. Generally, cross-domain tool-chains
are used to optimize all the KPIs from different domains (multi-objective
optimization) by varying the given input parameters in the largest possible
design space. This optimization process involves magneto-static finite element
simulation to obtain these decisive KPIs. It makes the whole process a
vehemently time-consuming computational task that counts on the availability of
resources with the involvement of high computational cost. In this paper, a
data-aided, deep learning-based meta-model is employed to predict the KPIs of
an electrical machine quickly and with high accuracy to accelerate the full
optimization process and reduce its computational costs. The focus is on
analyzing various forms of input data that serve as a geometry representation
of the machine. Namely, these are the cross-section image of the electrical
machine that allows a very general description of the geometry relating to
different topologies and the classical way with scalar parametrization of
geometry. The impact of the resolution of the image is studied in detail. The
results show a high prediction accuracy and proof that the validity of a deep
learning-based meta-model to minimize the optimization time. The results also
indicate that the prediction quality of an image-based approach can be made
comparable to the classical way based on scalar parameters.
</p>
<a href="http://arxiv.org/abs/2012.11299" target="_blank">arXiv:2012.11299</a> [<a href="http://arxiv.org/pdf/2012.11299" target="_blank">pdf</a>]

<h2>Monocular Depth Parameterizing Networks. (arXiv:2012.11301v1 [cs.CV])</h2>
<h3>Patrik Persson, Linn &#xd6;str&#xf6;m, Carl Olsson</h3>
<p>Monocular depth estimation is a highly challenging problem that is often
addressed with deep neural networks. While these are able to use recognition of
image features to predict reasonably looking depth maps the result often has
low metric accuracy. In contrast traditional stereo methods using multiple
cameras provide highly accurate estimation when pixel matching is possible. In
this work we propose to combine the two approaches leveraging their respective
strengths. For this purpose we propose a network structure that given an image
provides a parameterization of a set of depth maps with feasible shapes.
Optimizing over the parameterization then allows us to search the shapes for a
photo consistent solution with respect to other images. This allows us to
enforce geometric properties that are difficult to observe in single image as
well as relaxes the learning problem allowing us to use relatively small
networks. Our experimental evaluation shows that our method generates more
accurate depth maps and generalizes better than competing state-of-the-art
approaches.
</p>
<a href="http://arxiv.org/abs/2012.11301" target="_blank">arXiv:2012.11301</a> [<a href="http://arxiv.org/pdf/2012.11301" target="_blank">pdf</a>]

<h2>An Overview of Facial Micro-Expression Analysis: Data, Methodology and Challenge. (arXiv:2012.11307v1 [cs.CV])</h2>
<h3>Hong-Xia Xie, Ling Lo, Hong-Han Shuai, Wen-Huang Cheng</h3>
<p>Facial micro-expressions indicate brief and subtle facial movements that
appear during emotional communication. In comparison to macro-expressions,
micro-expressions are more challenging to be analyzed due to the short span of
time and the fine-grained changes. In recent years, micro-expression
recognition (MER) has drawn much attention because it can benefit a wide range
of applications, e.g. police interrogation, clinical diagnosis, depression
analysis, and business negotiation. In this survey, we offer a fresh overview
to discuss new research directions and challenges these days for MER tasks. For
example, we review MER approaches from three novel aspects: macro-to-micro
adaptation, recognition based on key apex frames, and recognition based on
facial action units. Moreover, to mitigate the problem of limited and biased ME
data, synthetic data generation is surveyed for the diversity enrichment of
micro-expression data. Since micro-expression spotting can boost
micro-expression analysis, the state-of-the-art spotting works are also
introduced in this paper. At last, we discuss the challenges in MER research
and provide potential solutions as well as possible directions for further
investigation.
</p>
<a href="http://arxiv.org/abs/2012.11307" target="_blank">arXiv:2012.11307</a> [<a href="http://arxiv.org/pdf/2012.11307" target="_blank">pdf</a>]

<h2>Physically Based Neural Simulator for Garment Animation. (arXiv:2012.11310v1 [cs.CV])</h2>
<h3>Hugo Bertiche, Meysam Madadi, Sergio Escalera</h3>
<p>We present a novel approach to the cloth simulation problem in human-centric
scenarios through deep learning. Computer graphics approaches rely on
Physically Based Simulations (PBS) to animate clothes. These are general
solutions that, given a sufficiently fine-grained discretization of space and
time, can achieve highly realistic results. However, they are computationally
expensive and any scene modification prompts the need of re-simulation. We
propose using deep learning, formulated as an implicit PBS, to learn accurate
cloth deformations in a constrained scenario: dressed humans. By using deep
models, we can obtain high-resolution garments that can be efficiently deployed
in real-time. Furthermore, we show it is possible to train these models in an
amount of time comparable to a PBS of a few fixed sequences. To the best of our
knowledge, we are the first to propose a neural simulator for cloth. Other
deep-based approaches for cloth dynamics learn the distribution of huge volumes
of simulated data. Therefore, these approaches require a great investment of
computational resources for data gathering. Alternatively, data can be gathered
through expensive 4D scans in constrained scenarios. With our proposed
methodology, we completely skip the data gathering part while obtaining
appealing results.
</p>
<a href="http://arxiv.org/abs/2012.11310" target="_blank">arXiv:2012.11310</a> [<a href="http://arxiv.org/pdf/2012.11310" target="_blank">pdf</a>]

<h2>Conceptual Software Engineering Applied to Movie Scripts and Stories. (arXiv:2012.11319v1 [cs.AI])</h2>
<h3>Sabah Al-Fedaghi</h3>
<p>This study introduces another application of software engineering tools,
conceptual modeling, which can be applied to other fields of research. One way
to strengthen the relationship between software engineering and other fields is
to develop a good way to perform conceptual modeling that is capable of
addressing the peculiarities of these fields of study. This study concentrates
on humanities and social sciences, which are usually considered softer and
further away from abstractions and (abstract) machines. Specifically, we focus
on conceptual modeling as a software engineering tool (e.g., UML) in the area
of stories and movie scripts. Researchers in the humanities and social sciences
might not use the same degree of formalization that engineers do, but they
still find conceptual modeling useful. Current modeling techniques (e.g., UML)
fail in this task because they are geared toward the creation of software
systems. Similar Conceptual Modeling Language (e.g., ConML) has been proposed
with the humanities and social sciences in mind and, as claimed, can be used to
model anything. This study is a venture in this direction, where a software
modeling technique, Thinging Machine (TM), is applied to movie scripts and
stories. The paper presents a novel approach to developing diagrammatic
static/dynamic models of movie scripts and stories. The TM model diagram serves
as a neutral and independent representation for narrative discourse and can be
used as a communication instrument among participants. The examples presented
include examples from Propp s model of fairytales; the railway children and an
actual movie script seem to point to the viability of the approach.
</p>
<a href="http://arxiv.org/abs/2012.11319" target="_blank">arXiv:2012.11319</a> [<a href="http://arxiv.org/pdf/2012.11319" target="_blank">pdf</a>]

<h2>CARLA Real Traffic Scenarios -- novel training ground and benchmark for autonomous driving. (arXiv:2012.11329v1 [cs.RO])</h2>
<h3>B&#x142;a&#x17c;ej Osi&#x144;ski, Piotr Mi&#x142;o&#x15b;, Adam Jakubowski, Pawe&#x142; Zi&#x119;cina, Micha&#x142; Martyniak, Christopher Galias, Antonia Breuer, Silviu Homoceanu, Henryk Michalewski</h3>
<p>This work introduces interactive traffic scenarios in the CARLA simulator,
which are based on real-world traffic. We concentrate on tactical tasks lasting
several seconds, which are especially challenging for current control methods.
The CARLA Real Traffic Scenarios (CRTS) is intended to be a training and
testing ground for autonomous driving systems. To this end, we open-source the
code under a permissive license and present a set of baseline policies. CRTS
combines the realism of traffic scenarios and the flexibility of simulation. We
use it to train agents using a reinforcement learning algorithm. We show how to
obtain competitive polices and evaluate experimentally how observation types
and reward schemes affect the training process and the resulting agent's
behavior.
</p>
<a href="http://arxiv.org/abs/2012.11329" target="_blank">arXiv:2012.11329</a> [<a href="http://arxiv.org/pdf/2012.11329" target="_blank">pdf</a>]

<h2>Single-level Optimization For Differential Architecture Search. (arXiv:2012.11337v1 [cs.LG])</h2>
<h3>Pengfei Hou, Ying Jin</h3>
<p>In this paper, we point out that differential architecture search (DARTS)
makes gradient of architecture parameters biased for network weights and
architecture parameters are updated in different datasets alternatively in the
bi-level optimization framework. The bias causes the architecture parameters of
non-learnable operations to surpass that of learnable operations. Moreover,
using softmax as architecture parameters' activation function and inappropriate
learning rate would exacerbate the bias. As a result, it's frequently observed
that non-learnable operations are dominated in the search phase. To reduce the
bias, we propose to use single-level to replace bi-level optimization and
non-competitive activation function like sigmoid to replace softmax. As a
result, we could search high-performance architectures steadily. Experiments on
NAS Benchmark 201 validate our hypothesis and stably find out nearly the
optimal architecture. On DARTS space, we search the state-of-the-art
architecture with 77.0% top1 accuracy (training setting follows PDARTS and
without any additional module) on ImageNet-1K and steadily search architectures
up-to 76.5% top1 accuracy (but not select the best from the searched
architectures) which is comparable with current reported best result.
</p>
<a href="http://arxiv.org/abs/2012.11337" target="_blank">arXiv:2012.11337</a> [<a href="http://arxiv.org/pdf/2012.11337" target="_blank">pdf</a>]

<h2>Learning Compositional Sparse Gaussian Processes with a Shrinkage Prior. (arXiv:2012.11339v1 [cs.LG])</h2>
<h3>Anh Tong, Toan Tran, Hung Bui, Jaesik Choi</h3>
<p>Choosing a proper set of kernel functions is an important problem in learning
Gaussian Process (GP) models since each kernel structure has different model
complexity and data fitness. Recently, automatic kernel composition methods
provide not only accurate prediction but also attractive interpretability
through search-based methods. However, existing methods suffer from slow kernel
composition learning. To tackle large-scaled data, we propose a new sparse
approximate posterior for GPs, MultiSVGP, constructed from groups of inducing
points associated with individual additive kernels in compositional kernels. We
demonstrate that this approximation provides a better fit to learn
compositional kernels given empirical observations. We also theoretically
justification on error bound when compared to the traditional sparse GP. In
contrast to the search-based approach, we present a novel probabilistic
algorithm to learn a kernel composition by handling the sparsity in the kernel
selection with Horseshoe prior. We demonstrate that our model can capture
characteristics of time series with significant reductions in computational
time and have competitive regression performance on real-world data sets.
</p>
<a href="http://arxiv.org/abs/2012.11339" target="_blank">arXiv:2012.11339</a> [<a href="http://arxiv.org/pdf/2012.11339" target="_blank">pdf</a>]

<h2>Analysis of Safe Ultrawideband Human-Robot Communication in Automated Collaborative Warehouse. (arXiv:2012.11345v1 [cs.RO])</h2>
<h3>Branimir Iv&#x161;i&#x107;, Zvonimir &#x160;ipu&#x161;, Juraj Bartoli&#x107;, Josip Babi&#x107;</h3>
<p>The paper presents the propagation analysis of ultrawideband Gaussian signal
in an automated collaborative warehouse environment where human and robots
communicate to ensure that mutual collisions do not occur. The warehouse racks
are principally modeled as clusters of metallic (PEC) parallelepipeds, with
dimensions chosen to approximate the realistic warehouse. The signal
propagation is analyzed using a ray tracing software, with the goal to
calculate the path loss profile for different representative scenarios and
antenna polarizations. The influence of the rack surface roughness onto
propagation is also analyzed. The guidelines for optimum antenna positions on
humans and robots for safe communication are proposed according to the
simulations results.
</p>
<a href="http://arxiv.org/abs/2012.11345" target="_blank">arXiv:2012.11345</a> [<a href="http://arxiv.org/pdf/2012.11345" target="_blank">pdf</a>]

<h2>Sub-Linear Memory: How to Make Performers SLiM. (arXiv:2012.11346v1 [cs.LG])</h2>
<h3>Valerii Likhosherstov, Krzysztof Choromanski, Jared Davis, Xingyou Song, Adrian Weller</h3>
<p>The Transformer architecture has revolutionized deep learning on sequential
data, becoming ubiquitous in state-of-the-art solutions for a wide variety of
applications. Yet vanilla Transformers are notoriously resource-expensive,
requiring $O(L^2)$ in serial time and memory as functions of input length $L$.
Recent works proposed various linear self-attention mechanisms, scaling only as
$O(L)$ for serial computation. We perform a thorough analysis of recent
Transformer mechanisms with linear self-attention, Performers, in terms of
overall computational complexity. We observe a remarkable computational
flexibility: forward and backward propagation can be performed with no
approximations using sublinear memory as a function of $L$ (in addition to
negligible storage for the input sequence), at a cost of greater time
complexity in the parallel setting. In the extreme case, a Performer consumes
only $O(1)$ memory during training, and still requires $O(L)$ time. This
discovered time-memory tradeoff can be used for training or, due to complete
backward-compatibility, for fine-tuning on a low-memory device, e.g. a
smartphone or an earlier-generation GPU, thus contributing towards
decentralized and democratized deep learning.
</p>
<a href="http://arxiv.org/abs/2012.11346" target="_blank">arXiv:2012.11346</a> [<a href="http://arxiv.org/pdf/2012.11346" target="_blank">pdf</a>]

<h2>Genetic Adversarial Training of Decision Trees. (arXiv:2012.11352v1 [cs.LG])</h2>
<h3>Francesco Ranzato, Marco Zanella</h3>
<p>We put forward a novel learning methodology for ensembles of decision trees
based on a genetic algorithm which is able to train a decision tree for
maximizing both its accuracy and its robustness to adversarial perturbations.
This learning algorithm internally leverages a complete formal verification
technique for robustness properties of decision trees based on abstract
interpretation, a well known static program analysis technique. We implemented
this genetic adversarial training algorithm in a tool called Meta-Silvae (MS)
and we experimentally evaluated it on some reference datasets used in
adversarial training. The experimental results show that MS is able to train
robust models that compete with and often improve on the current
state-of-the-art of adversarial training of decision trees while being much
more compact and therefore interpretable and efficient tree models.
</p>
<a href="http://arxiv.org/abs/2012.11352" target="_blank">arXiv:2012.11352</a> [<a href="http://arxiv.org/pdf/2012.11352" target="_blank">pdf</a>]

<h2>Unsupervised Anomaly Detectors to Detect Intrusions in the Current Threat Landscape. (arXiv:2012.11354v1 [cs.LG])</h2>
<h3>Tommaso Zoppi, Andrea ceccarelli, Tommaso Capecchi, Andrea Bondavalli</h3>
<p>Anomaly detection aims at identifying unexpected fluctuations in the expected
behavior of a given system. It is acknowledged as a reliable answer to the
identification of zero-day attacks to such extent, several ML algorithms that
suit for binary classification have been proposed throughout years. However,
the experimental comparison of a wide pool of unsupervised algorithms for
anomaly-based intrusion detection against a comprehensive set of attacks
datasets was not investigated yet. To fill such gap, we exercise seventeen
unsupervised anomaly detection algorithms on eleven attack datasets. Results
allow elaborating on a wide range of arguments, from the behavior of the
individual algorithm to the suitability of the datasets to anomaly detection.
We conclude that algorithms as Isolation Forests, One-Class Support Vector
Machines and Self-Organizing Maps are more effective than their counterparts
for intrusion detection, while clustering algorithms represent a good
alternative due to their low computational complexity. Further, we detail how
attacks with unstable, distributed or non-repeatable behavior as Fuzzing, Worms
and Botnets are more difficult to detect. Ultimately, we digress on
capabilities of algorithms in detecting anomalies generated by a wide pool of
unknown attacks, showing that achieved metric scores do not vary with respect
to identifying single attacks.
</p>
<a href="http://arxiv.org/abs/2012.11354" target="_blank">arXiv:2012.11354</a> [<a href="http://arxiv.org/pdf/2012.11354" target="_blank">pdf</a>]

<h2>Rebuilding Trust in Active Learning with Actionable Metrics. (arXiv:2012.11365v1 [cs.LG])</h2>
<h3>Alexandre Abraham, L&#xe9;o Dreyfus-Schmidt</h3>
<p>Active Learning (AL) is an active domain of research, but is seldom used in
the industry despite the pressing needs. This is in part due to a misalignment
of objectives, while research strives at getting the best results on selected
datasets, the industry wants guarantees that Active Learning will perform
consistently and at least better than random labeling. The very one-off nature
of Active Learning makes it crucial to understand how strategy selection can be
carried out and what drives poor performance (lack of exploration, selection of
samples that are too hard to classify, ...).

To help rebuild trust of industrial practitioners in Active Learning, we
present various actionable metrics. Through extensive experiments on reference
datasets such as CIFAR100, Fashion-MNIST, and 20Newsgroups, we show that those
metrics brings interpretability to AL strategies that can be leveraged by the
practitioner.
</p>
<a href="http://arxiv.org/abs/2012.11365" target="_blank">arXiv:2012.11365</a> [<a href="http://arxiv.org/pdf/2012.11365" target="_blank">pdf</a>]

<h2>Accurate Object Association and Pose Updating for Semantic SLAM. (arXiv:2012.11368v1 [cs.CV])</h2>
<h3>Kaiqi Chen, Jialing Liu, Jianhua Zhang, Zhenhua Wang</h3>
<p>Nowadays in the field of semantic SLAM, how to correctly use semantic
information for data association is still a problem worthy of study. The key to
solving this problem is to correctly associate multiple object measurements of
one object landmark, and refine the pose of object landmark. However, different
objects locating closely are prone to be associated as one object landmark, and
it is difficult to pick up a best pose from multiple object measurements
associated with one object landmark. To tackle these problems, we propose a
hierarchical object association strategy by means of multiple object tracking,
through which closing objects will be correctly associated to different object
landmarks, and an approach to refine the pose of object landmark from multiple
object measurements. The proposed method is evaluated on a simulated sequence
and several sequences in the Kitti dataset. Experimental results show a very
impressive improvement with respect to the traditional SLAM and the
state-of-the-art semantic SLAM method.
</p>
<a href="http://arxiv.org/abs/2012.11368" target="_blank">arXiv:2012.11368</a> [<a href="http://arxiv.org/pdf/2012.11368" target="_blank">pdf</a>]

<h2>Flexible, Non-parametric Modeling Using Regularized Neural Networks. (arXiv:2012.11369v1 [cs.LG])</h2>
<h3>Oskar Allerbo, Rebecka J&#xf6;rnsten</h3>
<p>Neural networks excel in terms of predictive performance, with little or no
need for manual screening of variables or guided definition of network
architecture. However, these flexible and data adaptive models are often
difficult to interpret. Here, we propose a new method for enhancing
interpretability, that builds on proximal gradient descent and adaptive lasso,
PrAda-net. In contrast to other lasso-based algorithms, PrAda-net penalizes all
network links individually and, by removing links with smaller weights,
automatically adjusts the size of the neural network to capture the complexity
of the underlying data generative model, thus increasing interpretability. In
addition, the compact network obtained by PrAda-net can be used to identify
relevant dependencies in the data, making it suitable for non-parametric
statistical modelling with automatic model selection. We demonstrate PrAda-net
on simulated data, where we compare the test error performance, variable
importance and variable subset identification properties of PrAda-net to other
lasso-based approaches. We also apply Prada-net to the massive U.K.\ black
smoke data set, to demonstrate the capability of using Prada-net as an
alternative to generalized additive models (GAMs), which often require domain
knowledge to select the functional forms of the additive components. Prada-net,
in contrast, requires no such pre-selection while still resulting in
interpretable additive components.
</p>
<a href="http://arxiv.org/abs/2012.11369" target="_blank">arXiv:2012.11369</a> [<a href="http://arxiv.org/pdf/2012.11369" target="_blank">pdf</a>]

<h2>Knowledge Transfer Based Fine-grained Visual Classification. (arXiv:2012.11389v1 [cs.CV])</h2>
<h3>Siqing Zhang, Ruoyi Du, Dongliang Chang, Zhanyu Ma, Jun Guo</h3>
<p>Fine-grained visual classification (FGVC) aims to distinguish the sub-classes
of the same category and its essential solution is to mine the subtle and
discriminative regions. Convolution neural networks (CNNs), which employ the
cross entropy loss (CE-loss) as the loss function, show poor performance since
the model can only learn the most discriminative part and ignore other
meaningful regions. Some existing works try to solve this problem by mining
more discriminative regions by some detection techniques or attention
mechanisms. However, most of them will meet the background noise problem when
trying to find more discriminative regions. In this paper, we address it in a
knowledge transfer learning manner. Multiple models are trained one by one, and
all previously trained models are regarded as teacher models to supervise the
training of the current one. Specifically, a orthogonal loss (OR-loss) is
proposed to encourage the network to find diverse and meaningful regions. In
addition, the first model is trained with only CE-Loss. Finally, all models'
outputs with complementary knowledge are combined together for the final
prediction result. We demonstrate the superiority of the proposed method and
obtain state-of-the-art (SOTA) performances on three popular FGVC datasets.
</p>
<a href="http://arxiv.org/abs/2012.11389" target="_blank">arXiv:2012.11389</a> [<a href="http://arxiv.org/pdf/2012.11389" target="_blank">pdf</a>]

<h2>Adversarial training for continuous robustness control problem in power systems. (arXiv:2012.11390v1 [stat.ML])</h2>
<h3>Lo&#xef;c Omnes, Antoine Marot, Benjamin Donnot</h3>
<p>We propose a new adversarial training approach for injecting robustness when
designing controllers for upcoming cyber-physical power systems. Previous
approaches relying deeply on simulations are not able to cope with the rising
complexity and are too costly when used online in terms of computation budget.
In comparison, our method proves to be computationally efficient online while
displaying useful robustness properties. To do so we model an adversarial
framework, propose the implementation of a fixed opponent policy and test it on
a L2RPN (Learning to Run a Power Network) environment. That environment is a
synthetic but realistic modeling of a cyber-physical system accounting for one
third of the IEEE 118 grid. Using adversarial testing, we analyze the results
of submitted trained agents from the robustness track of the L2RPN competition.
We then further assess the performance of those agents in regards to the
continuous N-1 problem through tailored evaluation metrics. We discover that
some agents trained in an adversarial way demonstrate interesting preventive
behaviors in that regard, which we discuss.
</p>
<a href="http://arxiv.org/abs/2012.11390" target="_blank">arXiv:2012.11390</a> [<a href="http://arxiv.org/pdf/2012.11390" target="_blank">pdf</a>]

<h2>The COVID pandemic: socioeconomic and health disparities. (arXiv:2012.11399v1 [cs.LG])</h2>
<h3>Behzad Javaheri</h3>
<p>Disadvantaged groups around the world have suffered and endured higher
mortality during the current COVID-19 pandemic. This contrast disparity
suggests that socioeconomic and health-related factors may drive inequality in
disease outcome. To identify indices of health and socioeconomic status
correlated with COVID-19 outcome, country aggregate data provided by the Lancet
COVID-19 Commission subjected to correlation analysis. Variables related to
these indices were used to predict mortality in the top 5 most affected
countries using ridge regression and extreme gradient boosting (XGBoost)
models. Our data reveal that predictors related to demographics and social
disadvantage correlate with COVID-19 mortality per million and that XGBoost
performed better than ridge regression. Taken together, our findings suggest
that the health consequence of the current pandemic is not just confined to
indiscriminate impact of a viral infection but that these preventable effects
are amplified based on pre-existing health and socioeconomic inequalities.
</p>
<a href="http://arxiv.org/abs/2012.11399" target="_blank">arXiv:2012.11399</a> [<a href="http://arxiv.org/pdf/2012.11399" target="_blank">pdf</a>]

<h2>Universal Policies for Software-Defined MDPs. (arXiv:2012.11401v1 [cs.AI])</h2>
<h3>Daniel Selsam, Jesse Michael Han, Leonardo de Moura, Patrice Godefroid</h3>
<p>We introduce a new programming paradigm called oracle-guided decision
programming in which a program specifies a Markov Decision Process (MDP) and
the language provides a universal policy. We prototype a new programming
language, Dodona, that manifests this paradigm using a primitive 'choose'
representing nondeterministic choice. The Dodona interpreter returns either a
value or a choicepoint that includes a lossless encoding of all information
necessary in principle to make an optimal decision. Meta-interpreters query
Dodona's (neural) oracle on these choicepoints to get policy and value
estimates, which they can use to perform heuristic search on the underlying
MDP. We demonstrate Dodona's potential for zero-shot heuristic guidance by
meta-learning over hundreds of synthetic tasks that simulate basic operations
over lists, trees, Church datastructures, polynomials, first-order terms and
higher-order terms.
</p>
<a href="http://arxiv.org/abs/2012.11401" target="_blank">arXiv:2012.11401</a> [<a href="http://arxiv.org/pdf/2012.11401" target="_blank">pdf</a>]

<h2>CAMTA: Casual Attention Model for Multi-touch Attribution. (arXiv:2012.11403v1 [cs.LG])</h2>
<h3>Sachin Kumar, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee, Lovekesh Vig, Gautam Shroff</h3>
<p>Advertising channels have evolved from conventional print media, billboards
and radio advertising to online digital advertising (ad), where the users are
exposed to a sequence of ad campaigns via social networks, display ads, search
etc. While advertisers revisit the design of ad campaigns to concurrently serve
the requirements emerging out of new ad channels, it is also critical for
advertisers to estimate the contribution from touch-points (view, clicks,
converts) on different channels, based on the sequence of customer actions.
This process of contribution measurement is often referred to as multi-touch
attribution (MTA). In this work, we propose CAMTA, a novel deep recurrent
neural network architecture which is a casual attribution mechanism for
user-personalised MTA in the context of observational data. CAMTA minimizes the
selection bias in channel assignment across time-steps and touchpoints.
Furthermore, it utilizes the users' pre-conversion actions in a principled way
in order to predict pre-channel attribution. To quantitatively benchmark the
proposed MTA model, we employ the real world Criteo dataset and demonstrate the
superior performance of CAMTA with respect to prediction accuracy as compared
to several baselines. In addition, we provide results for budget allocation and
user-behaviour modelling on the predicted channel attribution.
</p>
<a href="http://arxiv.org/abs/2012.11403" target="_blank">arXiv:2012.11403</a> [<a href="http://arxiv.org/pdf/2012.11403" target="_blank">pdf</a>]

<h2>Knowledge as Invariance -- History and Perspectives of Knowledge-augmented Machine Learning. (arXiv:2012.11406v1 [cs.LG])</h2>
<h3>Alexander Sagel, Amit Sahu, Stefan Matthes, Holger Pfeifer, Tianming Qiu, Harald Rue&#xdf;, Hao Shen, Julian W&#xf6;rmann</h3>
<p>Research in machine learning is at a turning point. While supervised deep
learning has conquered the field at a breathtaking pace and demonstrated the
ability to solve inference problems with unprecedented accuracy, it still does
not quite live up to its name if we think of learning as the process of
acquiring knowledge about a subject or problem. Major weaknesses of present-day
deep learning models are, for instance, their lack of adaptability to changes
of environment or their incapability to perform other kinds of tasks than the
one they were trained for. While it is still unclear how to overcome these
limitations, one can observe a paradigm shift within the machine learning
community, with research interests shifting away from increasing the
performance of highly parameterized models to exceedingly specific tasks, and
towards employing machine learning algorithms in highly diverse domains. This
research question can be approached from different angles. For instance, the
field of Informed AI investigates the problem of infusing domain knowledge into
a machine learning model, by using techniques such as regularization, data
augmentation or post-processing.

On the other hand, a remarkable number of works in the recent years has
focused on developing models that by themselves guarantee a certain degree of
versatility and invariance with respect to the domain or problem at hand. Thus,
rather than investigating how to provide domain-specific knowledge to machine
learning models, these works explore methods that equip the models with the
capability of acquiring the knowledge by themselves. This white paper provides
an introduction and discussion of this emerging field in machine learning
research. To this end, it reviews the role of knowledge in machine learning,
and discusses its relation to the concept of invariance, before providing a
literature review of the field.
</p>
<a href="http://arxiv.org/abs/2012.11406" target="_blank">arXiv:2012.11406</a> [<a href="http://arxiv.org/pdf/2012.11406" target="_blank">pdf</a>]

<h2>3D Object Detection with Pointformer. (arXiv:2012.11409v1 [cs.CV])</h2>
<h3>Xuran Pan, Zhuofan Xia, Shiji Song, Li Erran Li, Gao Huang</h3>
<p>Feature learning for 3D object detection from point clouds is very
challenging due to the irregularity of 3D point cloud data. In this paper, we
propose Pointformer, a Transformer backbone designed for 3D point clouds to
learn features effectively. Specifically, a Local Transformer module is
employed to model interactions among points in a local region, which learns
context-dependent region features at an object level. A Global Transformer is
designed to learn context-aware representations at the scene level. To further
capture the dependencies among multi-scale representations, we propose
Local-Global Transformer to integrate local features with global features from
higher resolution. In addition, we introduce an efficient coordinate refinement
module to shift down-sampled points closer to object centroids, which improves
object proposal generation. We use Pointformer as the backbone for
state-of-the-art object detection models and demonstrate significant
improvements over original models on both indoor and outdoor datasets.
</p>
<a href="http://arxiv.org/abs/2012.11409" target="_blank">arXiv:2012.11409</a> [<a href="http://arxiv.org/pdf/2012.11409" target="_blank">pdf</a>]

<h2>Exploiting Vulnerability of Pooling in Convolutional Neural Networks by Strict Layer-Output Manipulation for Adversarial Attacks. (arXiv:2012.11413v1 [cs.CV])</h2>
<h3>Chenchen Zhao, Hao Li</h3>
<p>Convolutional neural networks (CNN) have been more and more applied in mobile
robotics such as intelligent vehicles. Security of CNNs in robotics
applications is an important issue, for which potential adversarial attacks on
CNNs are worth research. Pooling is a typical step of dimension reduction and
information discarding in CNNs. Such information discarding may result in
mis-deletion and mis-preservation of data features which largely influence the
output of the network. This may aggravate the vulnerability of CNNs to
adversarial attacks. In this paper, we conduct adversarial attacks on CNNs from
the perspective of network structure by investigating and exploiting the
vulnerability of pooling. First, a novel adversarial attack methodology named
Strict Layer-Output Manipulation (SLOM) is proposed. Then an attack method
based on Strict Pooling Manipulation (SPM) which is an instantiation of the
SLOM spirit is designed to effectively realize both type I and type II
adversarial attacks on a target CNN. Performances of attacks based on SPM at
different depths are also investigated and compared. Moreover, performances of
attack methods designed by instantiating the SLOM spirit with different
operation layers of CNNs are compared. Experiment results reflect that pooling
tends to be more vulnerable to adversarial attacks than other operations in
CNNs.
</p>
<a href="http://arxiv.org/abs/2012.11413" target="_blank">arXiv:2012.11413</a> [<a href="http://arxiv.org/pdf/2012.11413" target="_blank">pdf</a>]

<h2>Amplifying the Anterior-Posterior Difference via Data Enhancement -- A More Robust Deep Monocular Orientation Estimation Solution. (arXiv:2012.11431v1 [cs.CV])</h2>
<h3>Chenchen Zhao, Hao Li</h3>
<p>Existing deep-learning based monocular orientation estimation algorithms
faces the problem of confusion between the anterior and posterior parts of the
objects, caused by the feature similarity of such parts in typical objects in
traffic scenes such as cars and pedestrians. While difficult to solve, the
problem may lead to serious orientation estimation errors, and pose threats to
the upcoming decision making process of the ego vehicle, since the predicted
tracks of objects may have directions opposite to ground truths. In this paper,
we mitigate this problem by proposing a pretraining method. The method focuses
on predicting the left/right semicircle in which the orientation of the object
is located. The trained semicircle prediction model is then integrated into the
orientation angle estimation model which predicts a value in range $[0, \pi]$.
Experiment results show that the proposed semicircle prediction enhances the
accuracy of orientation estimation, and mitigates the problem stated above.
With the proposed method, a backbone achieves similar state-of-the-art
orientation estimation performance to existing approaches with well-designed
network structures.
</p>
<a href="http://arxiv.org/abs/2012.11431" target="_blank">arXiv:2012.11431</a> [<a href="http://arxiv.org/pdf/2012.11431" target="_blank">pdf</a>]

<h2>Towards the Localisation of Lesions in Diabetic Retinopathy. (arXiv:2012.11432v1 [cs.CV])</h2>
<h3>Samuel Ofosu Mensah, Bubacarr Bah, Willie Brink</h3>
<p>Convolutional Neural Networks (CNN) has successfully been used to classify
diabetic retinopathy (DR) fundus images in recent times. However, deeper
representations in CNN only capture higher-level semantics at the expense of
losing spatial information. To make predictions very usable for
ophthalmologists, we use a post-attention technique called Gradient-weighted
Class Activation Mapping (Grad-CAM) on the penultimate layer of deep learning
models to produce coarse localisation maps on DR fundus images. This is to help
identify discriminative regions in the images, consequently providing enough
evidence for ophthalmologists to make a diagnosis and saving lives by early
diagnosis. Specifically, this study uses pre-trained weights from four (4)
state-of-the-art deep learning models to produce and compare the localisation
maps of DR fundus images. The models used include VGG16, ResNet50, InceptionV3,
and InceptionResNetV2. We find that InceptionV3 achieves the best performance
with a test classification accuracy of 96.07% and localise lesions better and
faster than the other models.
</p>
<a href="http://arxiv.org/abs/2012.11432" target="_blank">arXiv:2012.11432</a> [<a href="http://arxiv.org/pdf/2012.11432" target="_blank">pdf</a>]

<h2>Blurring Fools the Network -- Adversarial Attacks by Feature Peak Suppression and Gaussian Blurring. (arXiv:2012.11442v1 [cs.CV])</h2>
<h3>Chenchen Zhao, Hao Li</h3>
<p>Existing pixel-level adversarial attacks on neural networks may be deficient
in real scenarios, since pixel-level changes on the data cannot be fully
delivered to the neural network after camera capture and multiple image
preprocessing steps. In contrast, in this paper, we argue from another
perspective that gaussian blurring, a common technique of image preprocessing,
can be aggressive itself in specific occasions, thus exposing the network to
real-world adversarial attacks. We first propose an adversarial attack demo
named peak suppression (PS) by suppressing the values of peak elements in the
features of the data. Based on the blurring spirit of PS, we further apply
gaussian blurring to the data, to investigate the potential influence and
threats of gaussian blurring to performance of the network. Experiment results
show that PS and well-designed gaussian blurring can form adversarial attacks
that completely change classification results of a well-trained target network.
With the strong physical significance and wide applications of gaussian
blurring, the proposed approach will also be capable of conducting real world
attacks.
</p>
<a href="http://arxiv.org/abs/2012.11442" target="_blank">arXiv:2012.11442</a> [<a href="http://arxiv.org/pdf/2012.11442" target="_blank">pdf</a>]

<h2>Rapidly adapting robot swarms with Swarm Map-based Bayesian Optimisation. (arXiv:2012.11444v1 [cs.RO])</h2>
<h3>David M. Bossens, Danesh Tarapore</h3>
<p>Rapid performance recovery from unforeseen environmental perturbations
remains a grand challenge in swarm robotics. To solve this challenge, we
investigate a behaviour adaptation approach, where one searches an archive of
controllers for potential recovery solutions. To apply behaviour adaptation in
swarm robotic systems, we propose two algorithms: (i) Swarm Map-based
Optimisation (SMBO), which selects and evaluates one controller at a time, for
a homogeneous swarm, in a centralised fashion; and (ii) Swarm Map-based
Optimisation Decentralised (SMBO-Dec), which performs an asynchronous
batch-based Bayesian optimisation to simultaneously explore different
controllers for groups of robots in the swarm. We set up foraging experiments
with a variety of disturbances: injected faults to proximity sensors, ground
sensors, and the actuators of individual robots, with 100 unique combinations
for each type. We also investigate disturbances in the operating environment of
the swarm, where the swarm has to adapt to drastic changes in the number of
resources available in the environment, and to one of the robots behaving
disruptively towards the rest of the swarm, with 30 unique conditions for each
such perturbation. The viability of SMBO and SMBO-Dec is demonstrated,
comparing favourably to variants of random search and gradient descent, and
various ablations, and improving performance up to 80% compared to the
performance at the time of fault injection within at most 30 evaluations.
</p>
<a href="http://arxiv.org/abs/2012.11444" target="_blank">arXiv:2012.11444</a> [<a href="http://arxiv.org/pdf/2012.11444" target="_blank">pdf</a>]

<h2>The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective. (arXiv:2012.11448v1 [cs.LG])</h2>
<h3>Naman Goel, Alfonso Amayuelas, Amit Deshpande, Amit Sharma</h3>
<p>Training datasets for machine learning often have some form of missingness.
For example, to learn a model for deciding whom to give a loan, the available
training data includes individuals who were given a loan in the past, but not
those who were not. This missingness, if ignored, nullifies any fairness
guarantee of the training procedure when the model is deployed. Using causal
graphs, we characterize the missingness mechanisms in different real-world
scenarios. We show conditions under which various distributions, used in
popular fairness algorithms, can or can not be recovered from the training
data. Our theoretical results imply that many of these algorithms can not
guarantee fairness in practice. Modeling missingness also helps to identify
correct design principles for fair algorithms. For example, in multi-stage
settings where decisions are made in multiple screening rounds, we use our
framework to derive the minimal distributions required to design a fair
algorithm. Our proposed algorithm decentralizes the decision-making process and
still achieves similar performance to the optimal algorithm that requires
centralization and non-recoverable distributions.
</p>
<a href="http://arxiv.org/abs/2012.11448" target="_blank">arXiv:2012.11448</a> [<a href="http://arxiv.org/pdf/2012.11448" target="_blank">pdf</a>]

<h2>SENTRY: Selective Entropy Optimization via Committee Consistency for Unsupervised Domain Adaptation. (arXiv:2012.11460v1 [cs.CV])</h2>
<h3>Viraj Prabhu, Shivam Khare, Deeksha Kartik, Judy Hoffman</h3>
<p>Many existing approaches for unsupervised domain adaptation (UDA) focus on
adapting under only data distribution shift and offer limited success under
additional cross-domain label distribution shift. Recent work based on
self-training using target pseudo-labels has shown promise, but on challenging
shifts pseudo-labels may be highly unreliable, and using them for self-training
may cause error accumulation and domain misalignment. We propose Selective
Entropy Optimization via Committee Consistency (SENTRY), a UDA algorithm that
judges the reliability of a target instance based on its predictive consistency
under a committee of random image transformations. Our algorithm then
selectively minimizes predictive entropy to increase confidence on highly
consistent target instances, while maximizing predictive entropy to reduce
confidence on highly inconsistent ones. In combination with pseudo-label based
approximate target class balancing, our approach leads to significant
improvements over the state-of-the-art on 27/31 domain shifts from standard UDA
benchmarks as well as benchmarks designed to stress-test adaptation under label
distribution shift.
</p>
<a href="http://arxiv.org/abs/2012.11460" target="_blank">arXiv:2012.11460</a> [<a href="http://arxiv.org/pdf/2012.11460" target="_blank">pdf</a>]

<h2>Multi-Faceted Representation Learning with Hybrid Architecture for Time Series Classification. (arXiv:2012.11472v1 [cs.LG])</h2>
<h3>Zhenyu Liu, Jian Cheng</h3>
<p>Time series classification problems exist in many fields and have been
explored for a couple of decades. However, they still remain challenging, and
their solutions need to be further improved for real-world applications in
terms of both accuracy and efficiency. In this paper, we propose a hybrid
neural architecture, called Self-Attentive Recurrent Convolutional Networks
(SARCoN), to learn multi-faceted representations for univariate time series.
SARCoN is the synthesis of long short-term memory networks with self-attentive
mechanisms and Fully Convolutional Networks, which work in parallel to learn
the representations of univariate time series from different perspectives. The
component modules of the proposed architecture are trained jointly in an
end-to-end manner and they classify the input time series in a cooperative way.
Due to its domain-agnostic nature, SARCoN is able to generalize a diversity of
domain tasks. Our experimental results show that, compared to the
state-of-the-art approaches for time series classification, the proposed
architecture can achieve remarkable improvements for a set of univariate time
series benchmarks from the UCR repository. Moreover, the self-attention and the
global average pooling in the proposed architecture enable visible
interpretability by facilitating the identification of the contribution regions
of the original time series. An overall analysis confirms that multi-faceted
representations of time series aid in capturing deep temporal corrections
within complex time series, which is essential for the improvement of time
series classification performance. Our work provides a novel angle that deepens
the understanding of time series classification, qualifying our proposed model
as an ideal choice for real-world applications.
</p>
<a href="http://arxiv.org/abs/2012.11472" target="_blank">arXiv:2012.11472</a> [<a href="http://arxiv.org/pdf/2012.11472" target="_blank">pdf</a>]

<h2>PSGAN: A Generative Adversarial Network for Remote Sensing Image Pan-Sharpening. (arXiv:1805.03371v4 [cs.CV] UPDATED)</h2>
<h3>Qingjie Liu, Huanyu Zhou, Qizhi Xu, Xiangyu Liu, Yunhong Wang</h3>
<p>This paper addresses the problem of remote sensing image pan-sharpening from
the perspective of generative adversarial learning. We propose a novel deep
neural network based method named PSGAN. To the best of our knowledge, this is
one of the first attempts at producing high-quality pan-sharpened images with
GANs. The PSGAN consists of two components: a generative network (i.e.,
generator) and a discriminative network (i.e., discriminator). The generator is
designed to accept panchromatic (PAN) and multispectral (MS) images as inputs
and maps them to the desired high-resolution (HR) MS images and the
discriminator implements the adversarial training strategy for generating
higher fidelity pan-sharpened images. In this paper, we evaluate several
architectures and designs, namely two-stream input, stacking input, batch
normalization layer, and attention mechanism to find the optimal solution for
pan-sharpening. Extensive experiments on QuickBird, GaoFen-2, and WorldView-2
satellite images demonstrate that the proposed PSGANs not only are effective in
generating high-quality HR MS images and superior to state-of-the-art methods
and also generalize well to full-scale images.
</p>
<a href="http://arxiv.org/abs/1805.03371" target="_blank">arXiv:1805.03371</a> [<a href="http://arxiv.org/pdf/1805.03371" target="_blank">pdf</a>]

<h2>Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network. (arXiv:1808.03314v8 [cs.LG] UPDATED)</h2>
<h3>Alex Sherstinsky</h3>
<p>Because of their effectiveness in broad practical applications, LSTM networks
have received a wealth of coverage in scientific journals, technical blogs, and
implementation guides. However, in most articles, the inference formulas for
the LSTM network and its parent, RNN, are stated axiomatically, while the
training formulas are omitted altogether. In addition, the technique of
"unrolling" an RNN is routinely presented without justification throughout the
literature. The goal of this paper is to explain the essential RNN and LSTM
fundamentals in a single document. Drawing from concepts in signal processing,
we formally derive the canonical RNN formulation from differential equations.
We then propose and prove a precise statement, which yields the RNN unrolling
technique. We also review the difficulties with training the standard RNN and
address them by transforming the RNN into the "Vanilla LSTM" network through a
series of logical arguments. We provide all equations pertaining to the LSTM
system together with detailed descriptions of its constituent entities. Albeit
unconventional, our choice of notation and the method for presenting the LSTM
system emphasizes ease of understanding. As part of the analysis, we identify
new opportunities to enrich the LSTM system and incorporate these extensions
into the Vanilla LSTM network, producing the most general LSTM variant to date.
The target reader has already been exposed to RNNs and LSTM networks through
numerous available resources and is open to an alternative pedagogical
approach. A Machine Learning practitioner seeking guidance for implementing our
new augmented LSTM model in software for experimentation and research will find
the insights and derivations in this tutorial valuable as well.
</p>
<a href="http://arxiv.org/abs/1808.03314" target="_blank">arXiv:1808.03314</a> [<a href="http://arxiv.org/pdf/1808.03314" target="_blank">pdf</a>]

<h2>Control of uniflagellar soft robots at low Reynolds number using buckling instability. (arXiv:1810.03113v2 [cs.RO] UPDATED)</h2>
<h3>Mojtaba Forghani, Weicheng Huang, M. Khalid Jawed</h3>
<p>In this paper, we analyze the inverse dynamics and control of a
bacteria-inspired uniflagellar robot in a fluid medium at low Reynolds number.
Inspired by the mechanism behind the locomotion of flagellated bacteria, we
consider a robot comprised of a flagellum -- a flexible helical filament --
attached to a spherical head. The flagellum rotates about the head at a
controlled angular velocity and generates a propulsive force that moves the
robot forward. When the angular velocity exceeds a threshold value, the
hydrodynamic force exerted by the fluid can cause the soft flagellum to buckle,
characterized by a dramatic change in shape. In this computational study, a
fluid-structure interaction model that combines Discrete Elastic Rods (DER)
algorithm with Lighthill's Slender Body Theory (LSBT) is employed to simulate
the locomotion and deformation of the robot. We demonstrate that the robot can
follow a prescribed path in three dimensional space by exploiting buckling of
the flagellum. The control scheme involves only a single (binary) scalar input
-- the angular velocity of the flagellum. By triggering the buckling
instability at the right moment, the robot can follow an arbitrary path in
three dimensional space. We also show that the complexity of the dynamics of
the helical filament can be captured using a deep neural network, from which we
identify the input-output functional relationship between the control inputs
and the trajectory of the robot. Furthermore, our study underscores the
potential role of buckling in the locomotion of natural bacteria.
</p>
<a href="http://arxiv.org/abs/1810.03113" target="_blank">arXiv:1810.03113</a> [<a href="http://arxiv.org/pdf/1810.03113" target="_blank">pdf</a>]

<h2>SVIn2: An Underwater SLAM System using Sonar, Visual, Inertial, and Depth Sensor. (arXiv:1810.03200v3 [cs.RO] UPDATED)</h2>
<h3>Sharmin Rahman, Alberto Quattrini Li, Ioannis Rekleitis</h3>
<p>This paper presents a novel tightly-coupled keyframe-based Simultaneous
Localization and Mapping (SLAM) system with loop-closing and relocalization
capabilities targeted for the underwater domain.

Our previous work, SVIn, augmented the state-of-the-art visual-inertial state
estimation package OKVIS to accommodate acoustic data from sonar in a
non-linear optimization-based framework. This paper addresses drift and loss of
localization -- one of the main problems affecting other packages in underwater
domain -- by providing the following main contributions: a robust
initialization method to refine scale using depth measurements, a fast
preprocessing step to enhance the image quality, and a real-time loop-closing
and relocalization method using bag of words. An additional contribution is the
introduction of depth measurements from a pressure sensor to the
tightly-coupled optimization formulation. Experimental results on datasets
collected with a custom-made underwater sensor suite and an autonomous
underwater vehicle from challenging underwater environments with poor
visibility demonstrate performance never achieved before in terms of accuracy
and robustness.
</p>
<a href="http://arxiv.org/abs/1810.03200" target="_blank">arXiv:1810.03200</a> [<a href="http://arxiv.org/pdf/1810.03200" target="_blank">pdf</a>]

<h2>O2A: One-shot Observational learning with Action vectors. (arXiv:1810.07483v3 [cs.RO] UPDATED)</h2>
<h3>Leo Pauly, Wisdom C. Agboh, David C. Hogg, Raul Fuentes</h3>
<p>We present O2A, a novel method for learning to perform robotic manipulation
tasks from a single (one-shot) third-person demonstration video. To our
knowledge, it is the first time this has been done for a single demonstration.
The key novelty lies in pre-training a feature extractor for creating a
perceptual representation for actions that we call 'action vectors'. The action
vectors are extracted using a 3D-CNN model pre-trained as an action classifier
on a generic action dataset. The distance between the action vectors from the
observed third-person demonstration and trial robot executions is used as a
reward for reinforcement learning of the demonstrated task. We report on
experiments in simulation and on a real robot, with changes in viewpoint of
observation, properties of the objects involved, scene background and
morphology of the manipulator between the demonstration and the learning
domains. O2A outperforms baseline approaches under different domain shifts and
has comparable performance with an oracle (that uses an ideal reward function).
</p>
<a href="http://arxiv.org/abs/1810.07483" target="_blank">arXiv:1810.07483</a> [<a href="http://arxiv.org/pdf/1810.07483" target="_blank">pdf</a>]

<h2>ChemBoost: A chemical language based approach for protein-ligand binding affinity prediction. (arXiv:1811.00761v3 [cs.LG] UPDATED)</h2>
<h3>R&#x131;za &#xd6;z&#xe7;elik, Hakime &#xd6;zt&#xfc;rk, Arzucan &#xd6;zg&#xfc;r, Elif Ozkirimli</h3>
<p>Identification of high affinity drug-target interactions is a major research
question in drug discovery. Proteins are generally represented by their
structures or sequences. However, structures are available only for a small
subset of biomolecules and sequence similarity is not always correlated with
functional similarity. We propose ChemBoost, a chemical language based approach
for affinity prediction using SMILES syntax. We hypothesize that SMILES is a
codified language and ligands are documents composed of chemical words. These
documents can be used to learn chemical word vectors that represent words in
similar contexts with similar vectors. In ChemBoost, the ligands are
represented via chemical word embeddings, while the proteins are represented
through sequence-based features and/or chemical words of their ligands. Our aim
is to process the patterns in SMILES as a language to predict protein-ligand
affinity, even when we cannot infer the function from the sequence. We used
eXtreme Gradient Boosting to predict protein-ligand affinities in KIBA and
BindingDB data sets. ChemBoost was able to predict drug-target binding affinity
as well as or better than state-of-the-art machine learning systems. When
powered with ligand-centric representations, ChemBoost was more robust to the
changes in protein sequence similarity and successfully captured the
interactions between a protein and a ligand, even if the protein has low
sequence similarity to the known targets of the ligand.
</p>
<a href="http://arxiv.org/abs/1811.00761" target="_blank">arXiv:1811.00761</a> [<a href="http://arxiv.org/pdf/1811.00761" target="_blank">pdf</a>]

<h2>Taking Control of Intra-class Variation in Conditional GANs Under Weak Supervision. (arXiv:1811.11296v2 [cs.CV] UPDATED)</h2>
<h3>Richard T. Marriott, Sami Romdhani, Liming Chen</h3>
<p>Generative Adversarial Networks (GANs) are able to learn mappings between
simple, relatively low-dimensional, random distributions and points on the
manifold of realistic images in image-space. The semantics of this mapping,
however, are typically entangled such that meaningful image properties cannot
be controlled independently of one another. Conditional GANs (cGANs) provide a
potential solution to this problem, allowing specific semantics to be enforced
during training. This solution, however, depends on the availability of precise
labels, which are sometimes difficult or near impossible to obtain, e.g. labels
representing lighting conditions or describing the background. In this paper we
introduce a new formulation of the cGAN that is able to learn disentangled,
multivariate models of semantically meaningful variation and which has the
advantage of requiring only the weak supervision of binary attribute labels.
For example, given only labels of ambient / non-ambient lighting, our method is
able to learn multivariate lighting models disentangled from other factors such
as the identity and pose. We coin the method intra-class variation isolation
(IVI) and the resulting network the IVI-GAN. We evaluate IVI-GAN on the CelebA
dataset and on synthetic 3D morphable model data, learning to disentangle
attributes such as lighting, pose, expression, and even the background.
</p>
<a href="http://arxiv.org/abs/1811.11296" target="_blank">arXiv:1811.11296</a> [<a href="http://arxiv.org/pdf/1811.11296" target="_blank">pdf</a>]

<h2>Real-time Model-based Image Color Correction for Underwater Robots. (arXiv:1904.06437v2 [cs.RO] UPDATED)</h2>
<h3>Monika Roznere, Alberto Quattrini Li</h3>
<p>Recently, a new underwater imaging formation model presented that the
coefficients related to the direct and backscatter transmission signals are
dependent on the type of water, camera specifications, water depth, and imaging
range. This paper proposes an underwater color correction method that
integrates this new model on an underwater robot, using information from a
pressure depth sensor for water depth and a visual odometry system for
estimating scene distance. Experiments were performed with and without a color
chart over coral reefs and a shipwreck in the Caribbean. We demonstrate the
performance of our proposed method by comparing it with other statistic-,
physic-, and learning-based color correction methods. Applications for our
proposed method include improved 3D reconstruction and more robust underwater
robot navigation.
</p>
<a href="http://arxiv.org/abs/1904.06437" target="_blank">arXiv:1904.06437</a> [<a href="http://arxiv.org/pdf/1904.06437" target="_blank">pdf</a>]

<h2>Semi-bandit Optimization in the Dispersed Setting. (arXiv:1904.09014v3 [cs.LG] UPDATED)</h2>
<h3>Maria-Florina Balcan, Travis Dick, Wesley Pegden</h3>
<p>The goal of data-driven algorithm design is to obtain high-performing
algorithms for specific application domains using machine learning and data.
Across many fields in AI, science, and engineering, practitioners will often
fix a family of parameterized algorithms and then optimize those parameters to
obtain good performance on example instances from the application domain. In
the online setting, we must choose algorithm parameters for each instance as
they arrive, and our goal is to be competitive with the best fixed algorithm in
hindsight.

There are two major challenges in online data-driven algorithm design. First,
it can be computationally expensive to evaluate the loss functions that map
algorithm parameters to performance, which often require the learner to run a
combinatorial algorithm to measure its performance. Second, the losses can be
extremely volatile and have sharp discontinuities. However, we show that in
many applications, evaluating the loss function for one algorithm choice can
sometimes reveal the loss for a range of similar algorithms, essentially for
free. We develop online optimization algorithms capable of using this kind of
extra information by working in the semi-bandit feedback setting. Our
algorithms achieve regret bounds that are essentially as good as algorithms
under full-information feedback and are significantly more computationally
efficient. We apply our semi-bandit results to obtain the first provable
guarantees for data-driven algorithm design for linkage-based clustering and we
improve the best regret bounds for designing greedy knapsack algorithms.
</p>
<a href="http://arxiv.org/abs/1904.09014" target="_blank">arXiv:1904.09014</a> [<a href="http://arxiv.org/pdf/1904.09014" target="_blank">pdf</a>]

<h2>Impact of facial landmark localization on facial expression recognition. (arXiv:1905.10784v2 [cs.CV] UPDATED)</h2>
<h3>Romain Belmonte, Benjamin Allaert, Pierre Tirilly, Ioan Marius Bilasco, Chaabane Djeraba, Nicu Sebe</h3>
<p>Although facial landmark localization approaches are becoming increasingly
accurate for characterizing facial regions, one question remains unanswered:
what is the impact of these approaches on subsequent related tasks? In this
paper, the focus is put on facial expression recognition (FER), where facial
landmarks are used for face registration, which is a common usage. We first
provide empirical evidence of the usefulness of facial landmark for FER by
comparing landmark-free and landmark-based approaches. Since the most used
datasets for facial landmark localization do not allow for a proper measurement
of performance according to the different difficulties (e.g., pose, expression,
illumination, occlusion, motion blur), we also quantify the performance of
recent approaches in the presence of head pose variations and facial
expressions. Finally, a study of the impact of these approaches on FER is
conducted. We show that the landmark accuracy achieved so far optimizing the
conventional Euclidean distance does not necessarily guarantee a gain in
performance for FER.
</p>
<a href="http://arxiv.org/abs/1905.10784" target="_blank">arXiv:1905.10784</a> [<a href="http://arxiv.org/pdf/1905.10784" target="_blank">pdf</a>]

<h2>Unsupervised Ensemble Classification with Sequential and Networked Data. (arXiv:1906.09356v3 [cs.LG] UPDATED)</h2>
<h3>Panagiotis A. Traganitis, Georgios B. Giannakis</h3>
<p>Ensemble learning, the machine learning paradigm where multiple algorithms
are combined, has exhibited promising perfomance in a variety of tasks. The
present work focuses on unsupervised ensemble classification. The term
unsupervised refers to the ensemble combiner who has no knowledge of the
ground-truth labels that each classifier has been trained on. While most prior
works on unsupervised ensemble classification are designed for independent and
identically distributed (i.i.d.) data, the present work introduces an
unsupervised scheme for learning from ensembles of classifiers in the presence
of data dependencies. Two types of data dependencies are considered: sequential
data and networked data whose dependencies are captured by a graph. Moment
matching and Expectation Maximization algorithms are developed for the
aforementioned cases, and their performance is evaluated on synthetic and real
datasets.
</p>
<a href="http://arxiv.org/abs/1906.09356" target="_blank">arXiv:1906.09356</a> [<a href="http://arxiv.org/pdf/1906.09356" target="_blank">pdf</a>]

<h2>Adaptive Sequential Experiments with Unknown Information Arrival Processes. (arXiv:1907.00107v6 [cs.LG] UPDATED)</h2>
<h3>Yonatan Gur, Ahmadreza Momeni</h3>
<p>Sequential experiments are often characterized by an exploration-exploitation
tradeoff that is captured by the multi-armed bandit (MAB) framework. This
framework has been studied and applied, typically when at each time period
feedback is received only on the action that was selected at that period.
However, in many practical settings additional data may become available
between decision epochs. We introduce a generalized MAB formulation, which
considers a broad class of distributions that are informative about mean
rewards, and allows observations from these distributions to arrive according
to an arbitrary and a priori unknown arrival process. When it is known how to
map auxiliary data to reward estimates, by obtaining matching lower and upper
bounds we characterize a spectrum of minimax complexities for this class of
problems as a function of the information arrival process, which captures how
salient characteristics of this process impact achievable performance. In terms
of achieving optimal performance, we establish that upper confidence bound and
posterior sampling policies possess natural robustness with respect to the
information arrival process without any adjustments, which uncovers a novel
property of these popular policies and further lends credence to their appeal.
When the mappings connecting auxiliary data and rewards are a priori unknown,
we characterize necessary and sufficient conditions under which auxiliary
information allows performance improvement. We devise a new policy that is
based on two different upper confidence bounds (one that accounts for auxiliary
observation and one that does not) and establish the near-optimality of this
policy. We use data from a large media site to analyze the value that may be
captured in practice by leveraging auxiliary data for designing content
recommendations.
</p>
<a href="http://arxiv.org/abs/1907.00107" target="_blank">arXiv:1907.00107</a> [<a href="http://arxiv.org/pdf/1907.00107" target="_blank">pdf</a>]

<h2>Variational Autoencoders and Nonlinear ICA: A Unifying Framework. (arXiv:1907.04809v4 [stat.ML] UPDATED)</h2>
<h3>Ilyes Khemakhem, Diederik P. Kingma, Ricardo Pio Monti, Aapo Hyv&#xe4;rinen</h3>
<p>The framework of variational autoencoders allows us to efficiently learn deep
latent-variable models, such that the model's marginal distribution over
observed variables fits the data. Often, we're interested in going a step
further, and want to approximate the true joint distribution over observed and
latent variables, including the true prior and posterior distributions over
latent variables. This is known to be generally impossible due to
unidentifiability of the model. We address this issue by showing that for a
broad family of deep latent-variable models, identification of the true joint
distribution over observed and latent variables is actually possible up to very
simple transformations, thus achieving a principled and powerful form of
disentanglement. Our result requires a factorized prior distribution over the
latent variables that is conditioned on an additionally observed variable, such
as a class label or almost any other observation. We build on recent
developments in nonlinear ICA, which we extend to the case with noisy,
undercomplete or discrete observations, integrated in a maximum likelihood
framework. The result also trivially contains identifiable flow-based
generative models as a special case.
</p>
<a href="http://arxiv.org/abs/1907.04809" target="_blank">arXiv:1907.04809</a> [<a href="http://arxiv.org/pdf/1907.04809" target="_blank">pdf</a>]

<h2>Bias In, Bias Out? Evaluating the Folk Wisdom. (arXiv:1909.08518v3 [cs.LG] UPDATED)</h2>
<h3>Ashesh Rambachan, Jonathan Roth</h3>
<p>We evaluate the folk wisdom that algorithmic decision rules trained on data
produced by biased human decision-makers necessarily reflect this bias. We
consider a setting where training labels are only generated if a biased
decision-maker takes a particular action, and so "biased" training data arise
due to discriminatory selection into the training data. In our baseline model,
the more biased the decision-maker is against a group, the more the algorithmic
decision rule favors that group. We refer to this phenomenon as "bias
reversal." We then clarify the conditions that give rise to bias reversal.
Whether a prediction algorithm reverses or inherits bias depends critically on
how the decision-maker affects the training data as well as the label used in
training. We illustrate our main theoretical results in a simulation study
applied to the New York City Stop, Question and Frisk dataset.
</p>
<a href="http://arxiv.org/abs/1909.08518" target="_blank">arXiv:1909.08518</a> [<a href="http://arxiv.org/pdf/1909.08518" target="_blank">pdf</a>]

<h2>Nonparametric MANOVA via Independence Testing. (arXiv:1910.08883v2 [stat.ML] UPDATED)</h2>
<h3>Sambit Panda, Cencheng Shen, Ronan Perry, Jelle Zorn, Antoine Lutz, Carey E. Priebe, Joshua T. Vogelstein</h3>
<p>The $k$-sample testing problem tests whether or not $k$ groups of data points
are sampled from the same distribution. Multivariate analysis of variance
(MANOVA) is currently the gold standard for $k$-sample testing but makes
strong, often inappropriate, parametric assumptions. Moreover, independence
testing and $k$-sample testing are tightly related, and there are many
nonparametric multivariate independence tests with strong theoretical and
empirical properties, including distance correlation (Dcorr) and
Hilbert-Schmidt-Independence-Criterion (Hsic). We prove that universally
consistent independence tests achieve universally consistent $k$-sample testing
and that $k$-sample statistics like Energy and Maximum Mean Discrepancy (MMD)
are exactly equivalent to Dcorr. Empirically evaluating these tests for
$k$-sample scenarios demonstrates that these nonparametric independence tests
typically outperform MANOVA, even for Gaussian distributed settings. Finally,
we extend these non-parametric $k$-sample testing procedures to perform
multiway and multilevel tests. Thus, we illustrate the existence of many
theoretically motivated and empirically performant $k$-sample tests. A Python
package with all independence and k-sample tests called hyppo is available from
https://hyppo.neurodata.io/.
</p>
<a href="http://arxiv.org/abs/1910.08883" target="_blank">arXiv:1910.08883</a> [<a href="http://arxiv.org/pdf/1910.08883" target="_blank">pdf</a>]

<h2>Keyhole Imaging: Non-Line-of-Sight Imaging and Tracking of Moving Objects Along a Single Optical Path. (arXiv:1912.06727v2 [cs.CV] UPDATED)</h2>
<h3>Christopher A. Metzler, David B. Lindell, Gordon Wetzstein</h3>
<p>Non-line-of-sight (NLOS) imaging and tracking is an emerging technology that
allows the shape or position of objects around corners or behind diffusers to
be recovered from transient, time-of-flight, measurements. However, existing
NLOS approaches require the imaging system to scan a large area on a visible
surface, where the indirect light paths of hidden objects are sampled. In many
applications, such as robotic vision or autonomous driving, optical access to a
large scanning area may not be available, which severely limits the
practicality of existing NLOS techniques. Here, we propose a new approach,
dubbed keyhole imaging, that captures a sequence of transient measurements
along a single optical path, for example, through a keyhole. Assuming that the
hidden object of interest moves during the acquisition time, we effectively
capture a series of time-resolved projections of the object's shape from
unknown viewpoints. We derive inverse methods based on expectation-maximization
to recover the object's shape and location using these measurements. Then, with
the help of long exposure times and retroreflective tape, we demonstrate
successful experimental results with a prototype keyhole imaging system.
</p>
<a href="http://arxiv.org/abs/1912.06727" target="_blank">arXiv:1912.06727</a> [<a href="http://arxiv.org/pdf/1912.06727" target="_blank">pdf</a>]

<h2>Wheel-INS: A Wheel-mounted MEMS IMU-based Dead Reckoning System. (arXiv:1912.07805v3 [cs.RO] UPDATED)</h2>
<h3>Xiaoji Niu, Yibin Wu, Jian Kuang</h3>
<p>To improve the accuracy and robustness of microelectromechanical system
(MEMS) inertial measurement units (IMU)-based inertial navigation systems
(INSs) for wheeled robot localization without adding cost, a complete
wheel-mounted MEMS IMU (Wheel-IMU) based dead reckoning system (Wheel-INS) is
proposed in this study. The installation scheme of the Wheel-IMU, algorithm
structure, and error analysis are explained. In Wheel-INS, a MEMS-IMU is placed
at the center of a non-steering wheel of the wheeled robot to take advantages
of rotation modulation; gyroscope measurements are then used to calculate the
wheel velocity to mitigate the error drift of INS along with the vehicle motion
constraints through an extended Kalman filter. Experimental results show that
Wheel-INS is insensitive to gyroscope bias error. The maximum position drift in
the horizontal plane of the Wheel-INS is less than 2% of the total traveled
distance. We made the source code and data available to the community.
(https://github.com/i2Nav-WHU/Wheel-INS)
</p>
<a href="http://arxiv.org/abs/1912.07805" target="_blank">arXiv:1912.07805</a> [<a href="http://arxiv.org/pdf/1912.07805" target="_blank">pdf</a>]

<h2>Finding and Removing Clever Hans: Using Explanation Methods to Debug and Improve Deep Models. (arXiv:1912.11425v2 [cs.CV] UPDATED)</h2>
<h3>Christopher J. Anders, Leander Weber, David Neumann, Wojciech Samek, Klaus-Robert M&#xfc;ller, Sebastian Lapuschkin</h3>
<p>Contemporary learning models for computer vision are typically trained on
very large (benchmark) datasets with millions of samples. These may, however,
contain biases, artifacts, or errors that have gone unnoticed and are
exploitable by the model. In the worst case, the trained model does not learn a
valid and generalizable strategy to solve the problem it was trained for, and
becomes a 'Clever-Hans' (CH) predictor that bases its decisions on spurious
correlations in the training data, potentially yielding an unrepresentative or
unfair, and possibly even hazardous predictor. In this paper, we contribute by
providing a comprehensive analysis framework based on a scalable statistical
analysis of attributions from explanation methods for large data corpora. Based
on a recent technique - Spectral Relevance Analysis - we propose the following
technical contributions and resulting findings: (a) a scalable quantification
of artifactual and poisoned classes where the machine learning models under
study exhibit CH behavior, (b) several approaches denoted as Class Artifact
Compensation (ClArC), which are able to effectively and significantly reduce a
model's CH behavior. I.e., we are able to un-Hans models trained on (poisoned)
datasets, such as the popular ImageNet data corpus. We demonstrate that ClArC,
defined in a simple theoretical framework, may be implemented as part of a
Neural Network's training or fine-tuning process, or in a post-hoc manner by
injecting additional layers, preventing any further propagation of undesired CH
features, into the network architecture. Using our proposed methods, we provide
qualitative and quantitative analyses of the biases and artifacts in various
datasets. We demonstrate that these insights can give rise to improved, more
representative and fairer models operating on implicitly cleaned data corpora.
</p>
<a href="http://arxiv.org/abs/1912.11425" target="_blank">arXiv:1912.11425</a> [<a href="http://arxiv.org/pdf/1912.11425" target="_blank">pdf</a>]

<h2>Use Short Isometric Shapelets to Accelerate Binary Time Series Classification. (arXiv:1912.11982v2 [cs.LG] UPDATED)</h2>
<h3>Weibo Shu, Yaqiang Yao, Shengfei Lyu, Jinlong Li, Huanhuan Chen</h3>
<p>In the research area of time series classification, the ensemble shapelet
transform algorithm is one of state-of-the-art algorithms for classification.
However, its high time complexity is an issue to hinder its application since
its base classifier shapelet transform includes a high time complexity of a
distance calculation and shapelet selection. Therefore, in this paper we
introduce a novel algorithm, i.e. short isometric shapelet transform, which
contains two strategies to reduce the time complexity. The first strategy of
SIST fixes the length of shapelet based on a simplified distance calculation,
which largely reduces the number of shapelet candidates as well as speeds up
the distance calculation in the ensemble shapelet transform algorithm. The
second strategy is to train a single linear classifier in the feature space
instead of an ensemble classifier. The theoretical evidences of these two
strategies are presented to guarantee a near-lossless accuracy under some
preconditions while reducing the time complexity. Furthermore, empirical
experiments demonstrate the superior performance of the proposed algorithm.
</p>
<a href="http://arxiv.org/abs/1912.11982" target="_blank">arXiv:1912.11982</a> [<a href="http://arxiv.org/pdf/1912.11982" target="_blank">pdf</a>]

<h2>Accelerating Reinforcement Learning for Reaching using Continuous Curriculum Learning. (arXiv:2002.02697v2 [cs.AI] UPDATED)</h2>
<h3>Sha Luo, Hamidreza Kasaei, Lambert Schomaker</h3>
<p>Reinforcement learning has shown great promise in the training of robot
behavior due to the sequential decision making characteristics. However, the
required enormous amount of interactive and informative training data provides
the major stumbling block for progress. In this study, we focus on accelerating
reinforcement learning (RL) training and improving the performance of
multi-goal reaching tasks. Specifically, we propose a precision-based
continuous curriculum learning (PCCL) method in which the requirements are
gradually adjusted during the training process, instead of fixing the parameter
in a static schedule. To this end, we explore various continuous curriculum
strategies for controlling a training process. This approach is tested using a
Universal Robot 5e in both simulation and real-world multi-goal reach
experiments. Experimental results support the hypothesis that a static training
schedule is suboptimal, and using an appropriate decay function for curriculum
learning provides superior results in a faster way.
</p>
<a href="http://arxiv.org/abs/2002.02697" target="_blank">arXiv:2002.02697</a> [<a href="http://arxiv.org/pdf/2002.02697" target="_blank">pdf</a>]

<h2>Abnormal respiratory patterns classifier may contribute to large-scale screening of people infected with COVID-19 in an accurate and unobtrusive manner. (arXiv:2002.05534v2 [cs.LG] UPDATED)</h2>
<h3>Yunlu Wang, Menghan Hu, Qingli Li, Xiao-Ping Zhang, Guangtao Zhai, Nan Yao</h3>
<p>Research significance: The extended version of this paper has been accepted
by IEEE Internet of Things journal (DOI: 10.1109/JIOT.2020.2991456), please
cite the journal version. During the epidemic prevention and control period,
our study can be helpful in prognosis, diagnosis and screening for the patients
infected with COVID-19 (the novel coronavirus) based on breathing
characteristics. According to the latest clinical research, the respiratory
pattern of COVID-19 is different from the respiratory patterns of flu and the
common cold. One significant symptom that occurs in the COVID-19 is Tachypnea.
People infected with COVID-19 have more rapid respiration. Our study can be
utilized to distinguish various respiratory patterns and our device can be
preliminarily put to practical use. Demo videos of this method working in
situations of one subject and two subjects can be downloaded online. Research
details: Accurate detection of the unexpected abnormal respiratory pattern of
people in a remote and unobtrusive manner has great significance. In this work,
we innovatively capitalize on depth camera and deep learning to achieve this
goal. The challenges in this task are twofold: the amount of real-world data is
not enough for training to get the deep model; and the intra-class variation of
different types of respiratory patterns is large and the outer-class variation
is small. In this paper, considering the characteristics of actual respiratory
signals, a novel and efficient Respiratory Simulation Model (RSM) is first
proposed to fill the gap between the large amount of training data and scarce
real-world data. The proposed deep model and the modeling ideas have the great
potential to be extended to large scale applications such as public places,
sleep scenario, and office environment.
</p>
<a href="http://arxiv.org/abs/2002.05534" target="_blank">arXiv:2002.05534</a> [<a href="http://arxiv.org/pdf/2002.05534" target="_blank">pdf</a>]

<h2>Stratified Rule-Aware Network for Abstract Visual Reasoning. (arXiv:2002.06838v2 [cs.CV] UPDATED)</h2>
<h3>Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai</h3>
<p>Abstract reasoning refers to the ability to analyze information, discover
rules at an intangible level, and solve problems in innovative ways. Raven's
Progressive Matrices (RPM) test is typically used to examine the capability of
abstract reasoning. The subject is asked to identify the correct choice from
the answer set to fill the missing panel at the bottom right of RPM (e.g., a
3$\times$3 matrix), following the underlying rules inside the matrix. Recent
studies, taking advantage of Convolutional Neural Networks (CNNs), have
achieved encouraging progress to accomplish the RPM test. However, they partly
ignore necessary inductive biases of RPM solver, such as order sensitivity
within each row/column and incremental rule induction. To address this problem,
in this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the
rule embeddings for two input sequences. Our SRAN learns multiple granularity
rule embeddings at different levels, and incrementally integrates the
stratified embedding flows through a gated fusion module. With the help of
embeddings, a rule similarity metric is applied to guarantee that SRAN can not
only be trained using a tuplet loss but also infer the best answer efficiently.
We further point out the severe defects existing in the popular RAVEN dataset
for RPM test, which prevent from the fair evaluation of the abstract reasoning
ability. To fix the defects, we propose an answer set generation algorithm
called Attribute Bisection Tree (ABT), forming an improved dataset named
Impartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on
both PGM and I-RAVEN datasets, showing that our SRAN outperforms the
state-of-the-art models by a considerable margin.
</p>
<a href="http://arxiv.org/abs/2002.06838" target="_blank">arXiv:2002.06838</a> [<a href="http://arxiv.org/pdf/2002.06838" target="_blank">pdf</a>]

<h2>ResiliNet: Failure-Resilient Inference in Distributed Neural Networks. (arXiv:2002.07386v4 [cs.LG] UPDATED)</h2>
<h3>Ashkan Yousefpour, Brian Q. Nguyen, Siddartha Devic, Guanhua Wang, Aboudy Kreidieh, Hans Lobel, Alexandre M. Bayen, Jason P. Jue</h3>
<p>Federated Learning aims to train distributed deep models without sharing the
raw data with the centralized server. Similarly, in distributed inference of
neural networks, by partitioning the network and distributing it across several
physical nodes, activations and gradients are exchanged between physical nodes,
rather than raw data. Nevertheless, when a neural network is partitioned and
distributed among physical nodes, failure of physical nodes causes the failure
of the neural units that are placed on those nodes, which results in a
significant performance drop. Current approaches focus on resiliency of
training in distributed neural networks. However, resiliency of inference in
distributed neural networks is less explored. We introduce ResiliNet, a scheme
for making inference in distributed neural networks resilient to physical node
failures. ResiliNet combines two concepts to provide resiliency: skip
hyperconnection, a concept for skipping nodes in distributed neural networks
similar to skip connection in resnets, and a novel technique called failout,
which is introduced in this paper. Failout simulates physical node failure
conditions during training using dropout, and is specifically designed to
improve the resiliency of distributed neural networks. The results of the
experiments and ablation studies using three datasets confirm the ability of
ResiliNet to provide inference resiliency for distributed neural networks.
</p>
<a href="http://arxiv.org/abs/2002.07386" target="_blank">arXiv:2002.07386</a> [<a href="http://arxiv.org/pdf/2002.07386" target="_blank">pdf</a>]

<h2>Distributed Non-Convex Optimization with Sublinear Speedup under Intermittent Client Availability. (arXiv:2002.07399v2 [stat.ML] UPDATED)</h2>
<h3>Yikai Yan, Chaoyue Niu, Yucheng Ding, Zhenzhe Zheng, Fan Wu, Guihai Chen, Shaojie Tang, Zhihua Wu</h3>
<p>Federated learning is a new distributed machine learning framework, where a
bunch of heterogeneous clients collaboratively train a model without sharing
training data. In this work, we consider a practical and ubiquitous issue in
federated learning: intermittent client availability, where the set of eligible
clients may change during the training process. Such an intermittent client
availability model would significantly deteriorate the performance of the
classical Federated Averaging algorithm (FedAvg for short). We propose a simple
distributed non-convex optimization algorithm, called Federated Latest
Averaging (FedLaAvg for short), which leverages the latest gradients of all
clients, even when the clients are not available, to jointly update the global
model in each iteration. Our theoretical analysis shows that FedLaAvg attains
the convergence rate of $O(1/(N^{1/4} T^{1/2}))$, achieving a sublinear speedup
with respect to the total number of clients. We implement and evaluate FedLaAvg
with the CIFAR-10 dataset. The evaluation results demonstrate that FedLaAvg
indeed reaches a sublinear speedup and achieves 4.23% higher test accuracy than
FedAvg.
</p>
<a href="http://arxiv.org/abs/2002.07399" target="_blank">arXiv:2002.07399</a> [<a href="http://arxiv.org/pdf/2002.07399" target="_blank">pdf</a>]

<h2>Improved guarantees and a multiple-descent curve for Column Subset Selection and the Nystr\"om method. (arXiv:2002.09073v3 [cs.LG] UPDATED)</h2>
<h3>Micha&#x142; Derezi&#x144;ski, Rajiv Khanna, Michael W. Mahoney</h3>
<p>The Column Subset Selection Problem (CSSP) and the Nystr\"om method are among
the leading tools for constructing small low-rank approximations of large
datasets in machine learning and scientific computing. A fundamental question
in this area is: how well can a data subset of size k compete with the best
rank k approximation? We develop techniques which exploit spectral properties
of the data matrix to obtain improved approximation guarantees which go beyond
the standard worst-case analysis. Our approach leads to significantly better
bounds for datasets with known rates of singular value decay, e.g., polynomial
or exponential decay. Our analysis also reveals an intriguing phenomenon: the
approximation factor as a function of k may exhibit multiple peaks and valleys,
which we call a multiple-descent curve. A lower bound we establish shows that
this behavior is not an artifact of our analysis, but rather it is an inherent
property of the CSSP and Nystr\"om tasks. Finally, using the example of a
radial basis function (RBF) kernel, we show that both our improved bounds and
the multiple-descent curve can be observed on real datasets simply by varying
the RBF parameter.
</p>
<a href="http://arxiv.org/abs/2002.09073" target="_blank">arXiv:2002.09073</a> [<a href="http://arxiv.org/pdf/2002.09073" target="_blank">pdf</a>]

<h2>Sub-Goal Trees -- a Framework for Goal-Based Reinforcement Learning. (arXiv:2002.12361v2 [cs.AI] UPDATED)</h2>
<h3>Tom Jurgenson, Or Avner, Edward Groshev, Aviv Tamar</h3>
<p>Many AI problems, in robotics and other domains, are goal-based, essentially
seeking trajectories leading to various goal states. Reinforcement learning
(RL), building on Bellman's optimality equation, naturally optimizes for a
single goal, yet can be made multi-goal by augmenting the state with the goal.
Instead, we propose a new RL framework, derived from a dynamic programming
equation for the all pairs shortest path (APSP) problem, which naturally solves
multi-goal queries. We show that this approach has computational benefits for
both standard and approximate dynamic programming. Interestingly, our
formulation prescribes a novel protocol for computing a trajectory: instead of
predicting the next state given its predecessor, as in standard RL, a
goal-conditioned trajectory is constructed by first predicting an intermediate
state between start and goal, partitioning the trajectory into two. Then,
recursively, predicting intermediate points on each sub-segment, until a
complete trajectory is obtained. We call this trajectory structure a sub-goal
tree. Building on it, we additionally extend the policy gradient methodology to
recursively predict sub-goals, resulting in novel goal-based algorithms.
Finally, we apply our method to neural motion planning, where we demonstrate
significant improvements compared to standard RL on navigating a 7-DoF robot
arm between obstacles.
</p>
<a href="http://arxiv.org/abs/2002.12361" target="_blank">arXiv:2002.12361</a> [<a href="http://arxiv.org/pdf/2002.12361" target="_blank">pdf</a>]

<h2>Federated Continual Learning with Weighted Inter-client Transfer. (arXiv:2003.03196v4 [cs.LG] UPDATED)</h2>
<h3>Jaehong Yoon, Wonyong Jeong, Giwoong Lee, Eunho Yang, Sung Ju Hwang</h3>
<p>There has been a surge of interest in continual learning and federated
learning, both of which are important in deep neural networks in real-world
scenarios. Yet little research has been done regarding the scenario where each
client learns on a sequence of tasks from a private local data stream. This
problem of federated continual learning poses new challenges to continual
learning, such as utilizing knowledge from other clients, while preventing
interference from irrelevant knowledge. To resolve these issues, we propose a
novel federated continual learning framework, Federated Weighted Inter-client
Transfer (FedWeIT), which decomposes the network weights into global federated
parameters and sparse task-specific parameters, and each client receives
selective knowledge from other clients by taking a weighted combination of
their task-specific parameters. FedWeIT minimizes interference between
incompatible tasks, and also allows positive knowledge transfer across clients
during learning. We validate our \emph{FedWeIT}~against existing federated
learning and continual learning methods under varying degrees of task
similarity across clients, and our model significantly outperforms them with a
large reduction in the communication cost.
</p>
<a href="http://arxiv.org/abs/2003.03196" target="_blank">arXiv:2003.03196</a> [<a href="http://arxiv.org/pdf/2003.03196" target="_blank">pdf</a>]

<h2>Learn and Transfer Knowledge of Preferred Assistance Strategies in Semi-autonomous Telemanipulation. (arXiv:2003.03516v2 [cs.RO] UPDATED)</h2>
<h3>Lingfeng Tao, Michael Bowman, Xu Zhou, Jiucai Zhang, Xiaoli Zhang</h3>
<p>Enabling robots to provide effective assistance yet still accommodating the
operator's commands for telemanipulation of an object is very challenging
because robot's assistive action is not always intuitive for human operators
and human behaviors and preferences are sometimes ambiguous for the robot to
interpret. Although various assistance approaches are being developed to
improve the control quality from different optimization perspectives, the
problem still remains in determining the appropriate approach that satisfies
the fine motion constraints for the telemanipulation task and preference of the
operator. To address these problems, we developed a novel preference-aware
assistance knowledge learning approach. An assistance preference model learns
what assistance is preferred by a human, and a stagewise model updating method
ensures the learning stability while dealing with the ambiguity of human
preference data. Such a preference-aware assistance knowledge enables a
teleoperated robot hand to provide more active yet preferred assistance toward
manipulation success. We also developed knowledge transfer methods to transfer
the preference knowledge across different robot hand structures to avoid
extensive robot-specific training. Experiments to telemanipulate a 3-finger
hand and 2-finger hand, respectively, to use, move, and hand over a cup have
been conducted. Results demonstrated that the methods enabled the robots to
effectively learn the preference knowledge and allowed knowledge transfer
between robots with less training effort.
</p>
<a href="http://arxiv.org/abs/2003.03516" target="_blank">arXiv:2003.03516</a> [<a href="http://arxiv.org/pdf/2003.03516" target="_blank">pdf</a>]

<h2>FuDGE: Functional Differential Graph Estimation with fully and discretely observed curves. (arXiv:2003.05402v2 [stat.ML] UPDATED)</h2>
<h3>Boxin Zhao, Y. Samuel Wang, Mladen Kolar</h3>
<p>We consider the problem of estimating the difference between two functional
undirected graphical models with shared structures. In many applications, data
are naturally regarded as high-dimensional random function vectors rather than
multivariate scalars. For example, electroencephalography (EEG) data are more
appropriately treated as functions of time. In these problems, not only can the
number of functions measured per sample be large, but each function is itself
an infinite dimensional object, making estimation of model parameters
challenging. In practice, curves are usually discretely observed, which makes
graph structure recovery even more challenging. We formally characterize when
two functional graphical models are comparable and propose a method that
directly estimates the functional differential graph, which we term FuDGE.
FuDGE avoids separate estimation of each graph, which allows for estimation in
problems where individual graphs are dense, but their difference is sparse. We
show that FuDGE consistently estimates the functional differential graph in a
high-dimensional setting for both discretely observed and fully observed
function paths. We illustrate finite sample properties of our method through
simulation studies. In order to demonstrate the benefits of our method, we
propose Joint Functional Graphical Lasso as a competitor, which is a
generalization of the Joint Graphical Lasso. Finally, we apply our method to
EEG data to uncover differences in functional brain connectivity between
alcoholics and control subjects.
</p>
<a href="http://arxiv.org/abs/2003.05402" target="_blank">arXiv:2003.05402</a> [<a href="http://arxiv.org/pdf/2003.05402" target="_blank">pdf</a>]

<h2>M2m: Imbalanced Classification via Major-to-minor Translation. (arXiv:2004.00431v2 [cs.CV] UPDATED)</h2>
<h3>Jaehyung Kim, Jongheon Jeong, Jinwoo Shin</h3>
<p>In most real-world scenarios, labeled training datasets are highly
class-imbalanced, where deep neural networks suffer from generalizing to a
balanced testing criterion. In this paper, we explore a novel yet simple way to
alleviate this issue by augmenting less-frequent classes via translating
samples (e.g., images) from more-frequent classes. This simple approach enables
a classifier to learn more generalizable features of minority classes, by
transferring and leveraging the diversity of the majority information. Our
experimental results on a variety of class-imbalanced datasets show that the
proposed method improves the generalization on minority classes significantly
compared to other existing re-sampling or re-weighting methods. The performance
of our method even surpasses those of previous state-of-the-art methods for the
imbalanced classification.
</p>
<a href="http://arxiv.org/abs/2004.00431" target="_blank">arXiv:2004.00431</a> [<a href="http://arxiv.org/pdf/2004.00431" target="_blank">pdf</a>]

<h2>Improving Deep Hyperspectral Image Classification Performance with Spectral Unmixing. (arXiv:2004.00583v4 [cs.CV] UPDATED)</h2>
<h3>Alan J.X. Guo, Fei Zhu</h3>
<p>Recent advances in neural networks have made great progress in the
hyperspectral image (HSI) classification. However, the overfitting effect,
which is mainly caused by complicated model structure and small training set,
remains a major concern. Reducing the complexity of the neural networks could
prevent overfitting to some extent, but also declines the networks' ability to
express more abstract features. Enlarging the training set is also difficult,
for the high expense of acquisition and manual labeling. In this paper, we
propose an abundance-based multi-HSI classification method. Firstly, we convert
every HSI from the spectral domain to the abundance domain by a
dataset-specific autoencoder. Secondly, the abundance representations from
multiple HSIs are collected to form an enlarged dataset. Lastly, we train an
abundance-based classifier and employ the classifier to predict over all the
involved HSI datasets. Different from the spectra that are usually highly
mixed, the abundance features are more representative in reduced dimension with
less noise. This benefits the proposed method to employ simple classifiers and
enlarged training data, and to expect less overfitting issues. The
effectiveness of the proposed method is verified by the ablation study and the
comparative experiments.
</p>
<a href="http://arxiv.org/abs/2004.00583" target="_blank">arXiv:2004.00583</a> [<a href="http://arxiv.org/pdf/2004.00583" target="_blank">pdf</a>]

<h2>SIBRE: Self Improvement Based REwards for Adaptive Feedback in Reinforcement Learning. (arXiv:2004.09846v3 [cs.LG] UPDATED)</h2>
<h3>Somjit Nath, Richa Verma, Abhik Ray, Harshad Khadilkar</h3>
<p>We propose a generic reward shaping approach for improving the rate of
convergence in reinforcement learning (RL), called Self Improvement Based
REwards, or SIBRE. The approach is designed for use in conjunction with any
existing RL algorithm, and consists of rewarding improvement over the agent's
own past performance. We prove that SIBRE converges in expectation under the
same conditions as the original RL algorithm. The reshaped rewards help
discriminate between policies when the original rewards are weakly
discriminated or sparse. Experiments on several well-known benchmark
environments with different RL algorithms show that SIBRE converges to the
optimal policy faster and more stably. We also perform sensitivity analysis
with respect to hyper-parameters, in comparison with baseline RL algorithms.
</p>
<a href="http://arxiv.org/abs/2004.09846" target="_blank">arXiv:2004.09846</a> [<a href="http://arxiv.org/pdf/2004.09846" target="_blank">pdf</a>]

<h2>Learning Local Neighboring Structure for Robust 3D Shape Representation. (arXiv:2004.09995v3 [cs.CV] UPDATED)</h2>
<h3>Zhongpai Gao, Junchi Yan, Guangtao Zhai, Juyong Zhang, Yiyan Yang, Xiaokang Yang</h3>
<p>Mesh is a powerful data structure for 3D shapes. Representation learning for
3D meshes is important in many computer vision and graphics applications. The
recent success of convolutional neural networks (CNNs) for structured data
(e.g., images) suggests the value of adapting insight from CNN for 3D shapes.
However, 3D shape data are irregular since each node's neighbors are unordered.
Various graph neural networks for 3D shapes have been developed with isotropic
filters or predefined local coordinate systems to overcome the node
inconsistency on graphs. However, isotropic filters or predefined local
coordinate systems limit the representation power. In this paper, we propose a
local structure-aware anisotropic convolutional operation (LSA-Conv) that
learns adaptive weighting matrices for each node according to the local
neighboring structure and performs shared anisotropic filters. In fact, the
learnable weighting matrix is similar to the attention matrix in the random
synthesizer -- a new Transformer model for natural language processing (NLP).
Comprehensive experiments demonstrate that our model produces significant
improvement in 3D shape reconstruction compared to state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2004.09995" target="_blank">arXiv:2004.09995</a> [<a href="http://arxiv.org/pdf/2004.09995" target="_blank">pdf</a>]

<h2>Neural Lyapunov Control. (arXiv:2005.00611v3 [cs.LG] UPDATED)</h2>
<h3>Ya-Chien Chang, Nima Roohi, Sicun Gao</h3>
<p>We propose new methods for learning control policies and neural network
Lyapunov functions for nonlinear control problems, with provable guarantee of
stability. The framework consists of a learner that attempts to find the
control and Lyapunov functions, and a falsifier that finds counterexamples to
quickly guide the learner towards solutions. The procedure terminates when no
counterexample is found by the falsifier, in which case the controlled
nonlinear system is provably stable. The approach significantly simplifies the
process of Lyapunov control design, provides end-to-end correctness guarantee,
and can obtain much larger regions of attraction than existing methods such as
LQR and SOS/SDP. We show experiments on how the new methods obtain high-quality
solutions for challenging control problems.
</p>
<a href="http://arxiv.org/abs/2005.00611" target="_blank">arXiv:2005.00611</a> [<a href="http://arxiv.org/pdf/2005.00611" target="_blank">pdf</a>]

<h2>Isometric Transformation Invariant and Equivariant Graph Convolutional Networks. (arXiv:2005.06316v3 [cs.LG] UPDATED)</h2>
<h3>Masanobu Horie, Naoki Morita, Toshiaki Hishinuma, Yu Ihara, Naoto Mitsume</h3>
<p>Graphs are one of the most important data structures for representing
pairwise relations between objects. Specifically, a graph embedded in a
Euclidean space is essential to solving real problems, such as physical
simulations. A crucial requirement for applying graphs in Euclidean spaces to
physical simulations is learning and inferring the isometric transformation
invariant and equivariant features in a computationally efficient manner. In
this paper, we propose a set of transformation invariant and equivariant models
based on graph convolutional networks, called IsoGCNs. We demonstrate that the
proposed model has a competitive performance compared to state-of-the-art
methods on tasks related to geometrical and physical simulation data. Moreover,
the proposed model can scale up to graphs with 1M vertices and conduct an
inference faster than a conventional finite element analysis, which the
existing equivariant models cannot achieve.
</p>
<a href="http://arxiv.org/abs/2005.06316" target="_blank">arXiv:2005.06316</a> [<a href="http://arxiv.org/pdf/2005.06316" target="_blank">pdf</a>]

<h2>Fast differentiable DNA and protein sequence optimization for molecular design. (arXiv:2005.11275v2 [cs.LG] UPDATED)</h2>
<h3>Johannes Linder, Georg Seelig</h3>
<p>Designing DNA and protein sequences with improved function has the potential
to greatly accelerate synthetic biology. Machine learning models that
accurately predict biological fitness from sequence are becoming a powerful
tool for molecular design. Activation maximization offers a simple design
strategy for differentiable models: one-hot coded sequences are first
approximated by a continuous representation which is then iteratively optimized
with respect to the predictor oracle by gradient ascent. While elegant, this
method suffers from vanishing gradients and may cause predictor pathologies
leading to poor convergence. Here, we build on a previously proposed
straight-through approximation method to optimize through discrete sequence
samples. By normalizing nucleotide logits across positions and introducing an
adaptive entropy variable, we remove bottlenecks arising from overly large or
skewed sampling parameters. The resulting algorithm, which we call Fast
SeqProp, achieves up to 100-fold faster convergence compared to previous
versions of activation maximization and finds improved fitness optima for many
applications. We demonstrate Fast SeqProp by designing DNA and protein
sequences for six deep learning predictors, including a protein structure
predictor.
</p>
<a href="http://arxiv.org/abs/2005.11275" target="_blank">arXiv:2005.11275</a> [<a href="http://arxiv.org/pdf/2005.11275" target="_blank">pdf</a>]

<h2>Incremental Real-Time Personalization in Human Activity Recognition Using Domain Adaptive Batch Normalization. (arXiv:2005.12178v2 [cs.LG] UPDATED)</h2>
<h3>Alan Mazankiewicz, Klemens B&#xf6;hm, Mario Berg&#xe9;s</h3>
<p>Human Activity Recognition (HAR) from devices like smartphone accelerometers
is a fundamental problem in ubiquitous computing. Machine learning based
recognition models often perform poorly when applied to new users that were not
part of the training data. Previous work has addressed this challenge by
personalizing general recognition models to the unique motion pattern of a new
user in a static batch setting. They require target user data to be available
upfront. The more challenging online setting has received less attention. No
samples from the target user are available in advance, but they arrive
sequentially. Additionally, the motion pattern of users may change over time.
Thus, adapting to new and forgetting old information must be traded off.
Finally, the target user should not have to do any work to use the recognition
system by, say, labeling any activities. Our work addresses all of these
challenges by proposing an unsupervised online domain adaptation algorithm.
Both classification and personalization happen continuously and incrementally
in real time. Our solution works by aligning the feature distributions of all
subjects, be they sources or the target, in hidden neural network layers. To
this end, we normalize the input of a layer with user-specific mean and
variance statistics. During training, these statistics are computed over
user-specific batches. In the online phase, they are estimated incrementally
for any new target user.
</p>
<a href="http://arxiv.org/abs/2005.12178" target="_blank">arXiv:2005.12178</a> [<a href="http://arxiv.org/pdf/2005.12178" target="_blank">pdf</a>]

<h2>$O(n)$ Connections are Expressive Enough: Universal Approximability of Sparse Transformers. (arXiv:2006.04862v2 [cs.LG] UPDATED)</h2>
<h3>Chulhee Yun, Yin-Wen Chang, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar</h3>
<p>Recently, Transformer networks have redefined the state of the art in many
NLP tasks. However, these models suffer from quadratic computational cost in
the input sequence length $n$ to compute pairwise attention in each layer. This
has prompted recent research into sparse Transformers that sparsify the
connections in the attention layers. While empirically promising for long
sequences, fundamental questions remain unanswered: Can sparse Transformers
approximate any arbitrary sequence-to-sequence function, similar to their dense
counterparts? How does the sparsity pattern and the sparsity level affect their
performance? In this paper, we address these questions and provide a unifying
framework that captures existing sparse attention models. We propose sufficient
conditions under which we prove that a sparse attention model can universally
approximate any sequence-to-sequence function. Surprisingly, our results show
that sparse Transformers with only $O(n)$ connections per attention layer can
approximate the same function class as the dense model with $n^2$ connections.
Lastly, we present experiments comparing different patterns/levels of sparsity
on standard NLP tasks.
</p>
<a href="http://arxiv.org/abs/2006.04862" target="_blank">arXiv:2006.04862</a> [<a href="http://arxiv.org/pdf/2006.04862" target="_blank">pdf</a>]

<h2>A Random Matrix Analysis of Random Fourier Features: Beyond the Gaussian Kernel, a Precise Phase Transition, and the Corresponding Double Descent. (arXiv:2006.05013v2 [stat.ML] UPDATED)</h2>
<h3>Zhenyu Liao, Romain Couillet, Michael W. Mahoney</h3>
<p>This article characterizes the exact asymptotics of random Fourier feature
(RFF) regression, in the realistic setting where the number of data samples
$n$, their dimension $p$, and the dimension of feature space $N$ are all large
and comparable. In this regime, the random RFF Gram matrix no longer converges
to the well-known limiting Gaussian kernel matrix (as it does when $N \to
\infty$ alone), but it still has a tractable behavior that is captured by our
analysis. This analysis also provides accurate estimates of training and test
regression errors for large $n,p,N$. Based on these estimates, a precise
characterization of two qualitatively different phases of learning, including
the phase transition between them, is provided; and the corresponding double
descent test error curve is derived from this phase transition behavior. These
results do not depend on strong assumptions on the data distribution, and they
perfectly match empirical results on real-world data sets.
</p>
<a href="http://arxiv.org/abs/2006.05013" target="_blank">arXiv:2006.05013</a> [<a href="http://arxiv.org/pdf/2006.05013" target="_blank">pdf</a>]

<h2>OpEvo: An Evolutionary Method for Tensor Operator Optimization. (arXiv:2006.05664v2 [cs.LG] UPDATED)</h2>
<h3>Xiaotian Gao, Cui Wei, Lintao Zhang, Mao Yang</h3>
<p>Training and inference efficiency of deep neural networks highly rely on the
performance of tensor operators on hardware platforms. Manually optimizing
tensor operators has limitations in terms of supporting new operators or
hardware platforms. Therefore, automatically optimizing device code
configurations of tensor operators is getting increasingly attractive. However,
current methods for tensor operator optimization usually suffer from poor
sample-efficiency due to the combinatorial search space. In this work, we
propose a novel evolutionary method, OpEvo, which efficiently explores the
search spaces of tensor operators by introducing a topology-aware mutation
operation based on q-random walk to leverage the topological structures over
the search spaces. Our comprehensive experiment results show that compared with
state-of-the-art (SOTA) methods OpEvo can find the best configuration with the
lowest variance and least efforts in the number of trials and wall-clock time.
All code of this work is available online.
</p>
<a href="http://arxiv.org/abs/2006.05664" target="_blank">arXiv:2006.05664</a> [<a href="http://arxiv.org/pdf/2006.05664" target="_blank">pdf</a>]

<h2>Provably Robust Metric Learning. (arXiv:2006.07024v2 [cs.LG] UPDATED)</h2>
<h3>Lu Wang, Xuanqing Liu, Jinfeng Yi, Yuan Jiang, Cho-Jui Hsieh</h3>
<p>Metric learning is an important family of algorithms for classification and
similarity search, but the robustness of learned metrics against small
adversarial perturbations is less studied. In this paper, we show that existing
metric learning algorithms, which focus on boosting the clean accuracy, can
result in metrics that are less robust than the Euclidean distance. To overcome
this problem, we propose a novel metric learning algorithm to find a
Mahalanobis distance that is robust against adversarial perturbations, and the
robustness of the resulting model is certifiable. Experimental results show
that the proposed metric learning algorithm improves both certified robust
errors and empirical robust errors (errors under adversarial attacks).
Furthermore, unlike neural network defenses which usually encounter a trade-off
between clean and robust errors, our method does not sacrifice clean errors
compared with previous metric learning methods. Our code is available at
https://github.com/wangwllu/provably_robust_metric_learning.
</p>
<a href="http://arxiv.org/abs/2006.07024" target="_blank">arXiv:2006.07024</a> [<a href="http://arxiv.org/pdf/2006.07024" target="_blank">pdf</a>]

<h2>Understanding and Resolving Performance Degradation in Graph Convolutional Networks. (arXiv:2006.07107v2 [cs.LG] UPDATED)</h2>
<h3>Kuangqi Zhou, Yanfei Dong, Kaixin Wang, Wee Sun Lee, Bryan Hooi, Huan Xu, Jiashi Feng</h3>
<p>A Graph Convolutional Network (GCN) stacks several layers and in each layer
performs a PROPagation operation (PROP) and a TRANsformation operation (TRAN)
for learning node representations over graph-structured data. Though powerful,
GCNs tend to suffer performance drop when the model gets deep. Previous works
focus on PROPs to study and mitigate this issue, but the role of TRANs is
barely investigated. In this work, we study performance degradation of GCNs by
experimentally examining how stacking only TRANs or PROPs works. We find that
TRANs contribute significantly, or even more than PROPs, to declining
performance, and moreover that they tend to amplify node-wise feature variance
in GCNs, causing variance inflamation that we identify as a key factor for
causing performance drop. Motivated by such observations, we propose a
variance-controlling technique termed Node Normalization (NodeNorm), which
scales each node's features using its own standard deviation. Experimental
results validate the effectiveness of NodeNorm on addressing performance
degradation of GCNs. Specifically, it enables deep GCNs to achieve comparable
results with shallow ones on 6 benchmark datasets, and to outperform shallow
ones in cases where deep models are needed. NodeNorm is a generic plug-in and
can well generalize to other GNN architectures.
</p>
<a href="http://arxiv.org/abs/2006.07107" target="_blank">arXiv:2006.07107</a> [<a href="http://arxiv.org/pdf/2006.07107" target="_blank">pdf</a>]

<h2>Projection Robust Wasserstein Distance and Riemannian Optimization. (arXiv:2006.07458v6 [cs.LG] UPDATED)</h2>
<h3>Tianyi Lin, Chenyou Fan, Nhat Ho, Marco Cuturi, Michael I. Jordan</h3>
<p>Projection robust Wasserstein (PRW) distance, or Wasserstein projection
pursuit (WPP), is a robust variant of the Wasserstein distance. Recent work
suggests that this quantity is more robust than the standard Wasserstein
distance, in particular when comparing probability measures in high-dimensions.
However, it is ruled out for practical application because the optimization
model is essentially non-convex and non-smooth which makes the computation
intractable. Our contribution in this paper is to revisit the original
motivation behind WPP/PRW, but take the hard route of showing that, despite its
non-convexity and lack of nonsmoothness, and even despite some hardness results
proved by~\citet{Niles-2019-Estimation} in a minimax sense, the original
formulation for PRW/WPP \textit{can} be efficiently computed in practice using
Riemannian optimization, yielding in relevant cases better behavior than its
convex relaxation. More specifically, we provide three simple algorithms with
solid theoretical guarantee on their complexity bound (one in the appendix),
and demonstrate their effectiveness and efficiency by conducing extensive
experiments on synthetic and real data. This paper provides a first step into a
computational theory of the PRW distance and provides the links between optimal
transport and Riemannian optimization.
</p>
<a href="http://arxiv.org/abs/2006.07458" target="_blank">arXiv:2006.07458</a> [<a href="http://arxiv.org/pdf/2006.07458" target="_blank">pdf</a>]

<h2>Inductive Graph Neural Networks for Spatiotemporal Kriging. (arXiv:2006.07527v2 [cs.LG] UPDATED)</h2>
<h3>Yuankai Wu, Dingyi Zhuang, Aurelie Labbe, Lijun Sun</h3>
<p>Time series forecasting and spatiotemporal kriging are the two most important
tasks in spatiotemporal data analysis. Recent research on graph neural networks
has made substantial progress in time series forecasting, while little
attention has been paid to the kriging problem -- recovering signals for
unsampled locations/sensors. Most existing scalable kriging methods (e.g.,
matrix/tensor completion) are transductive, and thus full retraining is
required when we have a new sensor to interpolate. In this paper, we develop an
Inductive Graph Neural Network Kriging (IGNNK) model to recover data for
unsampled sensors on a network/graph structure. To generalize the effect of
distance and reachability, we generate random subgraphs as samples and
reconstruct the corresponding adjacency matrix for each sample. By
reconstructing all signals on each sample subgraph, IGNNK can effectively learn
the spatial message passing mechanism. Empirical results on several real-world
spatiotemporal datasets demonstrate the effectiveness of our model. In
addition, we also find that the learned model can be successfully transferred
to the same type of kriging tasks on an unseen dataset. Our results show that:
1) GNN is an efficient and effective tool for spatial kriging; 2) inductive
GNNs can be trained using dynamic adjacency matrices; 3) a trained model can be
transferred to new graph structures and 4) IGNNK can be used to generate
virtual sensors.
</p>
<a href="http://arxiv.org/abs/2006.07527" target="_blank">arXiv:2006.07527</a> [<a href="http://arxiv.org/pdf/2006.07527" target="_blank">pdf</a>]

<h2>Equivariant Neural Rendering. (arXiv:2006.07630v2 [cs.CV] UPDATED)</h2>
<h3>Emilien Dupont, Miguel Angel Bautista, Alex Colburn, Aditya Sankar, Carlos Guestrin, Josh Susskind, Qi Shan</h3>
<p>We propose a framework for learning neural scene representations directly
from images, without 3D supervision. Our key insight is that 3D structure can
be imposed by ensuring that the learned representation transforms like a real
3D scene. Specifically, we introduce a loss which enforces equivariance of the
scene representation with respect to 3D transformations. Our formulation allows
us to infer and render scenes in real time while achieving comparable results
to models requiring minutes for inference. In addition, we introduce two
challenging new datasets for scene representation and neural rendering,
including scenes with complex lighting and backgrounds. Through experiments, we
show that our model achieves compelling results on these datasets as well as on
standard ShapeNet benchmarks.
</p>
<a href="http://arxiv.org/abs/2006.07630" target="_blank">arXiv:2006.07630</a> [<a href="http://arxiv.org/pdf/2006.07630" target="_blank">pdf</a>]

<h2>Generalized Adversarially Learned Inference. (arXiv:2006.08089v3 [cs.LG] UPDATED)</h2>
<h3>Yatin Dandi, Homanga Bharadhwaj, Abhishek Kumar, Piyush Rai</h3>
<p>Allowing effective inference of latent vectors while training GANs can
greatly increase their applicability in various downstream tasks. Recent
approaches, such as ALI and BiGAN frameworks, develop methods of inference of
latent variables in GANs by adversarially training an image generator along
with an encoder to match two joint distributions of image and latent vector
pairs. We generalize these approaches to incorporate multiple layers of
feedback on reconstructions, self-supervision, and other forms of supervision
based on prior or learned knowledge about the desired solutions. We achieve
this by modifying the discriminator's objective to correctly identify more than
two joint distributions of tuples of an arbitrary number of random variables
consisting of images, latent vectors, and other variables generated through
auxiliary tasks, such as reconstruction and inpainting or as outputs of
suitable pre-trained models. We design a non-saturating maximization objective
for the generator-encoder pair and prove that the resulting adversarial game
corresponds to a global optimum that simultaneously matches all the
distributions. Within our proposed framework, we introduce a novel set of
techniques for providing self-supervised feedback to the model based on
properties, such as patch-level correspondence and cycle consistency of
reconstructions. Through comprehensive experiments, we demonstrate the
efficacy, scalability, and flexibility of the proposed approach for a variety
of tasks.
</p>
<a href="http://arxiv.org/abs/2006.08089" target="_blank">arXiv:2006.08089</a> [<a href="http://arxiv.org/pdf/2006.08089" target="_blank">pdf</a>]

<h2>Estimating Displaced Populations from Overhead. (arXiv:2006.14547v2 [cs.CV] UPDATED)</h2>
<h3>Armin Hadzic, Gordon Christie, Jeffrey Freeman, Amber Dismer, Stevan Bullard, Ashley Greiner, Nathan Jacobs, Ryan Mukherjee</h3>
<p>We introduce a deep learning approach to perform fine-grained population
estimation for displacement camps using high-resolution overhead imagery. We
train and evaluate our approach on drone imagery cross-referenced with
population data for refugee camps in Cox's Bazar, Bangladesh in 2018 and 2019.
Our proposed approach achieves 7.02% mean absolute percent error on sequestered
camp imagery. We believe our experiments with real-world displacement camp data
constitute an important step towards the development of tools that enable the
humanitarian community to effectively and rapidly respond to the global
displacement crisis.
</p>
<a href="http://arxiv.org/abs/2006.14547" target="_blank">arXiv:2006.14547</a> [<a href="http://arxiv.org/pdf/2006.14547" target="_blank">pdf</a>]

<h2>MgSvF: Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning. (arXiv:2006.15524v2 [cs.CV] UPDATED)</h2>
<h3>Hanbin Zhao, Yongjian Fu, Mintong Kang, Xuewei Li, Songyuan Li, Hui Wang, Xi Li</h3>
<p>As a challenging problem, few-shot class-incremental learning (FSCIL)
continually learns a sequence of tasks, confronting the dilemma between slow
forgetting of old knowledge and fast adaptation to new knowledge. In this
paper, we concentrate on this "slow vs. fast" (SvF) dilemma to determine which
knowledge components to be updated in a slow fashion or a fast fashion, and
thereby balance old-knowledge preservation and new-knowledge adaptation. We
propose a multi-grained SvF learning strategy to cope with the SvF dilemma from
two different grains: intra-space (within the same feature space) and
inter-space (between two different feature spaces). The proposed strategy
designs a novel frequency-aware regularization to boost the intra-space SvF
capability, and meanwhile develops a new feature space composition operation to
enhance the inter-space SvF learning performance. With the multi-grained SvF
learning strategy, our method outperforms the state-of-the-art approaches by a
large margin.
</p>
<a href="http://arxiv.org/abs/2006.15524" target="_blank">arXiv:2006.15524</a> [<a href="http://arxiv.org/pdf/2006.15524" target="_blank">pdf</a>]

<h2>A Systematic Evaluation of Object Detection Networks for Scientific Plots. (arXiv:2007.02240v2 [cs.CV] UPDATED)</h2>
<h3>Pritha Ganguly, Nitesh Methani, Mitesh M. Khapra, Pratyush Kumar</h3>
<p>Are existing object detection methods adequate for detecting text and visual
elements in scientific plots which are arguably different than the objects
found in natural images? To answer this question, we train and compare the
accuracy of various SOTA object detection networks on the PlotQA dataset. At
the standard IOU setting of 0.5, most networks perform well with mAP scores
greater than 80% in detecting the relatively simple objects in plots. However,
the performance drops drastically when evaluated at a stricter IOU of 0.9 with
the best model giving a mAP of 35.70%. Note that such a stricter evaluation is
essential when dealing with scientific plots where even minor localisation
errors can lead to large errors in downstream numerical inferences. Given this
poor performance, we propose minor modifications to existing models by
combining ideas from different object detection networks. While this
significantly improves the performance, there are still 2 main issues: (i)
performance on text objects which are essential for reasoning is very poor, and
(ii) inference time is unacceptably large considering the simplicity of plots.
To solve this open problem, we make a series of contributions: (a) an efficient
region proposal method based on Laplacian edge detectors, (b) a feature
representation of region proposals that includes neighbouring information, (c)
a linking component to join multiple region proposals for detecting longer
textual objects, and (d) a custom loss function that combines a smooth L1-loss
with an IOU-based loss. Combining these ideas, our final model is very accurate
at extreme IOU values achieving a mAP of 93.44%@0.9 IOU. Simultaneously, our
model is very efficient with an inference time 16x lesser than the current
models, including one-stage detectors. With these contributions, we enable
further exploration on the automated reasoning of plots.
</p>
<a href="http://arxiv.org/abs/2007.02240" target="_blank">arXiv:2007.02240</a> [<a href="http://arxiv.org/pdf/2007.02240" target="_blank">pdf</a>]

<h2>Are We Overfitting to Experimental Setups in Recognition?. (arXiv:2007.02519v4 [cs.CV] UPDATED)</h2>
<h3>Matthew Wallingford, Aditya Kusupati, Keivan Alizadeh-Vahid, Aaron Walsman, Aniruddha Kembhavi, Ali Farhadi</h3>
<p>Enabling robust intelligence in the real-world entails systems that offer
continuous inference while learning from varying amounts of data and
supervision. The machine learning community has organically broken down this
challenging goal into manageable sub-tasks such as supervised, few-shot, and
continual learning. In light of substantial progress on each sub-task, we pose
the question, "How well does this progress translate to more practical
scenarios?" To investigate this question, we construct a new framework, FLUID,
which removes certain assumptions made by current experimental setups while
integrating these sub-tasks via the following design choices -- consuming
sequential data, allowing for flexible training phases, being compute aware,
and working in an open-world setting. Evaluating a broad set of methods on
FLUID leads to new insights including strong evidence that methods are
overfitting to their experimental setup. For example, we find that
representative few-shot methods are substantially worse than simple baselines,
self-supervised representations from MoCo fail to learn new classes when the
downstream task contains a mix of new and old classes, and pretraining largely
mitigates the problem of catastrophic forgetting. Finally, we propose two new
simple methods which outperform all other evaluated methods which further
questions our progress towards robust, real-world systems. Project page:
https://raivn.cs.washington.edu/projects/FLUID/.
</p>
<a href="http://arxiv.org/abs/2007.02519" target="_blank">arXiv:2007.02519</a> [<a href="http://arxiv.org/pdf/2007.02519" target="_blank">pdf</a>]

<h2>Defending Against Backdoors in Federated Learning with Robust Learning Rate. (arXiv:2007.03767v2 [cs.LG] UPDATED)</h2>
<h3>Mustafa Safa Ozdayi, Murat Kantarcioglu, Yulia R. Gel</h3>
<p>Federated learning (FL) allows a set of agents to collaboratively train a
model without sharing their potentially sensitive data. This makes FL suitable
for privacy-preserving applications. At the same time, FL is susceptible to
adversarial attacks due to decentralized and unvetted data. One important line
of attacks against FL is the backdoor attacks. In a backdoor attack, an
adversary tries to embed a backdoor functionality to the model during training
that can later be activated to cause a desired misclassification. To prevent
backdoor attacks, we propose a lightweight defense that requires minimal change
to the FL protocol. At a high level, our defense is based on carefully
adjusting the aggregation server's learning rate, per dimension and per round,
based on the sign information of agents' updates. We first conjecture the
necessary steps to carry a successful backdoor attack in FL setting, and then,
explicitly formulate the defense based on our conjecture. Through experiments,
we provide empirical evidence that supports our conjecture, and we test our
defense against backdoor attacks under different settings. We observe that
either backdoor is completely eliminated, or its accuracy is significantly
reduced. Overall, our experiments suggest that our defense significantly
outperforms some of the recently proposed defenses in the literature. We
achieve this by having minimal influence over the accuracy of the trained
models. In addition, we also provide convergence rate analysis for our proposed
scheme.
</p>
<a href="http://arxiv.org/abs/2007.03767" target="_blank">arXiv:2007.03767</a> [<a href="http://arxiv.org/pdf/2007.03767" target="_blank">pdf</a>]

<h2>Robust Multi-Agent Multi-Armed Bandits. (arXiv:2007.03812v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Vial, Sanjay Shakkottai, R. Srikant</h3>
<p>Recent works have shown that agents facing independent instances of a
stochastic $K$-armed bandit can collaborate to decrease regret. However, these
works assume that each agent always recommends their individual best-arm
estimates to other agents, which is unrealistic in envisioned applications
(machine faults in distributed computing or spam in social recommendation
systems). Hence, we generalize the setting to include $n$ honest and $m$
malicious agents who recommend best-arm estimates and arbitrary arms,
respectively. We first show that even with a single malicious agent, existing
collaboration-based algorithms fail to improve regret guarantees over a
single-agent baseline. We propose a scheme where honest agents learn who is
malicious and dynamically reduce communication with (i.e., "block") them. We
show that collaboration indeed decreases regret for this algorithm, assuming
$m$ is small compared to $K$ but without assumptions on malicious agents'
behavior, thus ensuring that our algorithm is robust against any malicious
recommendation strategy.
</p>
<a href="http://arxiv.org/abs/2007.03812" target="_blank">arXiv:2007.03812</a> [<a href="http://arxiv.org/pdf/2007.03812" target="_blank">pdf</a>]

<h2>Video Super Resolution Based on Deep Learning: A Comprehensive Survey. (arXiv:2007.12928v2 [cs.CV] UPDATED)</h2>
<h3>Hongying Liu, Zhubo Ruan, Peng Zhao, Chao Dong, Fanhua Shang, Yuanyuan Liu, Linlin Yang</h3>
<p>In recent years, deep learning has made great progress in many fields such as
image recognition, natural language processing, speech recognition and video
super-resolution. In this survey, we comprehensively investigate 33
state-of-the-art video super-resolution (VSR) methods based on deep learning.
It is well known that the leverage of information within video frames is
important for video super-resolution. Thus we propose a taxonomy and classify
the methods into six sub-categories according to the ways of utilizing
inter-frame information. Moreover, the architectures and implementation details
of all the methods are depicted in detail. Finally, we summarize and compare
the performance of the representative VSR method on some benchmark datasets. We
also discuss some challenges, which need to be further addressed by researchers
in the community of VSR. To the best of our knowledge, this work is the first
systematic review on VSR tasks, and it is expected to make a contribution to
the development of recent studies in this area and potentially deepen our
understanding to the VSR techniques based on deep learning.
</p>
<a href="http://arxiv.org/abs/2007.12928" target="_blank">arXiv:2007.12928</a> [<a href="http://arxiv.org/pdf/2007.12928" target="_blank">pdf</a>]

<h2>Deep frequency principle towards understanding why deeper learning is faster. (arXiv:2007.14313v2 [cs.LG] UPDATED)</h2>
<h3>Zhi-Qin John Xu, Hanxu Zhou</h3>
<p>Understanding the effect of depth in deep learning is a critical problem. In
this work, we utilize the Fourier analysis to empirically provide a promising
mechanism to understand why feedforward deeper learning is faster. To this end,
we separate a deep neural network, trained by normal stochastic gradient
descent, into two parts during analysis, i.e., a pre-condition component and a
learning component, in which the output of the pre-condition one is the input
of the learning one. We use a filtering method to characterize the frequency
distribution of a high-dimensional function. Based on experiments of deep
networks and real dataset, we propose a deep frequency principle, that is, the
effective target function for a deeper hidden layer biases towards lower
frequency during the training. Therefore, the learning component effectively
learns a lower frequency function if the pre-condition component has more
layers. Due to the well-studied frequency principle, i.e., deep neural networks
learn lower frequency functions faster, the deep frequency principle provides a
reasonable explanation to why deeper learning is faster. We believe these
empirical studies would be valuable for future theoretical studies of the
effect of depth in deep learning.
</p>
<a href="http://arxiv.org/abs/2007.14313" target="_blank">arXiv:2007.14313</a> [<a href="http://arxiv.org/pdf/2007.14313" target="_blank">pdf</a>]

<h2>Dynamic Legged Manipulation of a Ball Through Multi-Contact Optimization. (arXiv:2008.00191v2 [cs.RO] UPDATED)</h2>
<h3>Chenyu Yang, Bike Zhang, Jun Zeng, Ayush Agrawal, Koushil Sreenath</h3>
<p>The feet of robots are typically used to design locomotion strategies, such
as balancing, walking, and running. However, they also have great potential to
perform manipulation tasks. In this paper, we propose a model predictive
control (MPC) framework for a quadrupedal robot to dynamically balance on a
ball and simultaneously manipulate it to follow various trajectories such as
straight lines, sinusoids, circles and in-place turning. We numerically
validate our controller on the Mini Cheetah robot using different gaits
including trotting, bounding, and pronking on the ball.
</p>
<a href="http://arxiv.org/abs/2008.00191" target="_blank">arXiv:2008.00191</a> [<a href="http://arxiv.org/pdf/2008.00191" target="_blank">pdf</a>]

<h2>Learning to Play Two-Player Perfect-Information Games without Knowledge. (arXiv:2008.01188v2 [cs.AI] UPDATED)</h2>
<h3>Quentin Cohen-Solal</h3>
<p>In this paper, several techniques for learning game state evaluation
functions by reinforcement are proposed. The first is a generalization of tree
bootstrapping (tree learning): it is adapted to the context of reinforcement
learning without knowledge based on non-linear functions. With this technique,
no information is lost during the reinforcement learning process. The second is
a modification of minimax with unbounded depth extending the best sequences of
actions to the terminal states. This modified search is intended to be used
during the learning process. The third is to replace the classic gain of a game
(+1 / -1) with a reinforcement heuristic. We study particular reinforcement
heuristics such as: quick wins and slow defeats ; scoring ; mobility or
presence. The four is another variant of unbounded minimax, which plays the
safest action instead of playing the best action. This modified search is
intended to be used after the learning process. The five is a new action
selection distribution. The conducted experiments suggest that these techniques
improve the level of play. Finally, we apply these different techniques to
design program-players to the game of Hex (size 11 and 13) surpassing the level
of Mohex 3HNN with reinforcement learning from self-play without knowledge.
</p>
<a href="http://arxiv.org/abs/2008.01188" target="_blank">arXiv:2008.01188</a> [<a href="http://arxiv.org/pdf/2008.01188" target="_blank">pdf</a>]

<h2>Polyth-Net: Classification of Polythene Bags for Garbage Segregation Using Deep Learning. (arXiv:2008.07592v3 [cs.CV] UPDATED)</h2>
<h3>Divyansh Singh</h3>
<p>Polythene has always been a threat to the environment since its invention. It
is non-biodegradable and very difficult to recycle. Even after many awareness
campaigns and practices, Separation of polythene bags from waste has been a
challenge for human civilization. The primary method of segregation deployed is
manual handpicking, which causes a dangerous health hazards to the workers and
is also highly inefficient due to human errors. In this paper I have designed
and researched on image-based classification of polythene bags using a
deep-learning model and its efficiency. This paper focuses on the architecture
and statistical analysis of its performance on the data set as well as problems
experienced in the classification. It also suggests a modified loss function to
specifically detect polythene irrespective of its individual features. It aims
to help the current environment protection endeavours and save countless lives
lost to the hazards caused by current methods.
</p>
<a href="http://arxiv.org/abs/2008.07592" target="_blank">arXiv:2008.07592</a> [<a href="http://arxiv.org/pdf/2008.07592" target="_blank">pdf</a>]

<h2>Holistic Multi-View Building Analysis in the Wild with Projection Pooling. (arXiv:2008.10041v3 [cs.CV] UPDATED)</h2>
<h3>Zbigniew Wojna, Krzysztof Maziarz, &#x141;ukasz Jocz, Robert Pa&#x142;uba, Robert Kozikowski, Iasonas Kokkinos</h3>
<p>We address six different classification tasks related to fine-grained
building attributes: construction type, number of floors, pitch and geometry of
the roof, facade material, and occupancy class. Tackling such a remote building
analysis problem became possible only recently due to growing large-scale
datasets of urban scenes. To this end, we introduce a new benchmarking dataset,
consisting of 49426 images (top-view and street-view) of 9674 buildings. These
photos are further assembled, together with the geometric metadata. The dataset
showcases various real-world challenges, such as occlusions, blur, partially
visible objects, and a broad spectrum of buildings. We propose a new projection
pooling layer, creating a unified, top-view representation of the top-view and
the side views in a high-dimensional space. It allows us to utilize the
building and imagery metadata seamlessly. Introducing this layer improves
classification accuracy -- compared to highly tuned baseline models --
indicating its suitability for building analysis.
</p>
<a href="http://arxiv.org/abs/2008.10041" target="_blank">arXiv:2008.10041</a> [<a href="http://arxiv.org/pdf/2008.10041" target="_blank">pdf</a>]

<h2>Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory. (arXiv:2009.01495v5 [cs.LG] UPDATED)</h2>
<h3>Ran Tian, Liting Sun, Masayoshi Tomizuka</h3>
<p>Classical game-theoretic approaches for multi-agent systems in both the
forward policy design problem and the inverse reward learning problem often
make strong rationality assumptions: agents perfectly maximize expected
utilities under uncertainties. Such assumptions, however, substantially
mismatch with observed humans' behaviors such as satisficing with sub-optimal,
risk-seeking, and loss-aversion decisions. In this paper, we investigate the
problem of bounded risk-sensitive Markov Game (BRSMG) and its inverse reward
learning problem for modeling human realistic behaviors and learning human
behavioral models. Drawing on iterative reasoning models and cumulative
prospect theory, we embrace that humans have bounded intelligence and maximize
risk-sensitive utilities in BRSMGs. Convergence analysis for both the forward
policy design and the inverse reward learning problems are established under
the BRSMG framework. We validate the proposed forward policy design and inverse
reward learning algorithms in a navigation scenario. The results show that the
behaviors of agents demonstrate both risk-averse and risk-seeking
characteristics. Moreover, in the inverse reward learning task, the proposed
bounded risk-sensitive inverse learning algorithm outperforms a baseline
risk-neutral inverse learning algorithm by effectively recovering not only more
accurate reward values but also the intelligence levels and the risk-measure
parameters given demonstrations of agents' interactive behaviors.
</p>
<a href="http://arxiv.org/abs/2009.01495" target="_blank">arXiv:2009.01495</a> [<a href="http://arxiv.org/pdf/2009.01495" target="_blank">pdf</a>]

<h2>Rethinking Graph Regularization for Graph Neural Networks. (arXiv:2009.02027v2 [cs.LG] UPDATED)</h2>
<h3>Han Yang, Kaili Ma, James Cheng</h3>
<p>The graph Laplacian regularization term is usually used in semi-supervised
representation learning to provide graph structure information for a model
$f(X)$. However, with the recent popularity of graph neural networks (GNNs),
directly encoding graph structure $A$ into a model, i.e., $f(A, X)$, has become
the more common approach. While we show that graph Laplacian regularization
brings little-to-no benefit to existing GNNs, and propose a simple but
non-trivial variant of graph Laplacian regularization, called
Propagation-regularization (P-reg), to boost the performance of existing GNN
models. We provide formal analyses to show that P-reg not only infuses extra
information (that is not captured by the traditional graph Laplacian
regularization) into GNNs, but also has the capacity equivalent to an
infinite-depth graph convolutional network. We demonstrate that P-reg can
effectively boost the performance of existing GNN models on both node-level and
graph-level tasks across many different datasets.
</p>
<a href="http://arxiv.org/abs/2009.02027" target="_blank">arXiv:2009.02027</a> [<a href="http://arxiv.org/pdf/2009.02027" target="_blank">pdf</a>]

<h2>Towards an Atlas of Cultural Commonsense for Machine Reasoning. (arXiv:2009.05664v3 [cs.AI] UPDATED)</h2>
<h3>Anurag Acharya, Kartik Talamadupula, Mark A Finlayson</h3>
<p>Existing commonsense reasoning datasets for AI and NLP tasks fail to address
an important aspect of human life: cultural differences. We introduce an
approach that extends prior work on crowdsourcing commonsense knowledge by
incorporating differences in knowledge that are attributable to cultural or
national groups. We demonstrate the technique by collecting commonsense
knowledge that surrounds six fairly universal rituals -- birth, coming-of-age,
marriage, funerals, new year, and birthdays -- across two national groups: the
United States and India. Our study expands the different types of relationships
identified by existing work in the field of commonsense reasoning for
commonplace events, and uses these new types to gather information that
distinguish the identity of the groups providing the knowledge. It also moves
us a step closer towards building a machine that doesn't assume a rigid
framework of universal (and likely Western-biased) commonsense knowledge, but
rather has the ability to reason in a contextually and culturally sensitive
way. Our hope is that cultural knowledge of this sort will lead to more
human-like performance in NLP tasks such as question answering (QA) and text
understanding and generation.
</p>
<a href="http://arxiv.org/abs/2009.05664" target="_blank">arXiv:2009.05664</a> [<a href="http://arxiv.org/pdf/2009.05664" target="_blank">pdf</a>]

<h2>Generator Versus Segmentor: Pseudo-healthy Synthesis. (arXiv:2009.05722v2 [cs.CV] UPDATED)</h2>
<h3>Yunlong Zhang, Xin Lin, Liyan Sun, Yihong Zhuang, Yue Huang, Xinghao Ding, Xiaoqing Liu, Yizhou Yu</h3>
<p>The pseudo-healthy synthesis can be defined as synthesizing a
subject-specific healthy image from a pathological one. This paper discusses
that existing methods will inevitably fall into the trade-off between
preserving the subject-specific identity and generating healthy-like images. In
this paper, pixels are divided into healthy and lesion regions, where the
former is controlled by residual visual loss, and the latter is controlled by
distribution match loss. To this end, an adversarial training regime that
alternatively trains generator and segmentor is proposed. The generalization
ability of the segmentor is further improved by developing a pixel-wise
weighted cross-entropy loss using the difference maps between pathological and
synthetic images. Moreover, a new metric is proposed to measure the healthiness
degree of healthy synthetic images. The qualitative and quantitative
experimental results on public datasets BraTS demonstrate that the proposed
method outperforms the existing methods. Besides, we also certify the
effectiveness of our method on datasets LiTS.
</p>
<a href="http://arxiv.org/abs/2009.05722" target="_blank">arXiv:2009.05722</a> [<a href="http://arxiv.org/pdf/2009.05722" target="_blank">pdf</a>]

<h2>Type-augmented Relation Prediction in Knowledge Graphs. (arXiv:2009.07938v2 [cs.LG] UPDATED)</h2>
<h3>Zijun Cui, Pavan Kapanipathi, Kartik Talamadupula, Tian Gao, Qiang Ji</h3>
<p>Knowledge graphs (KGs) are of great importance to many real world
applications, but they generally suffer from incomplete information in the form
of missing relations between entities. Knowledge graph completion (also known
as relation prediction) is the task of inferring missing facts given existing
ones. Most of the existing work is proposed by maximizing the likelihood of
observed instance-level triples. Not much attention, however, is paid to the
ontological information, such as type information of entities and relations. In
this work, we propose a type-augmented relation prediction (TaRP) method, where
we apply both the type information and instance-level information for relation
prediction. In particular, type information and instance-level information are
encoded as prior probabilities and likelihoods of relations respectively, and
are combined by following Bayes' rule. Our proposed TaRP method achieves
significantly better performance than state-of-the-art methods on four
benchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition,
we show that TaRP achieves significantly improved data efficiency. More
importantly, the type information extracted from a specific dataset can
generalize well to other datasets through the proposed TaRP model.
</p>
<a href="http://arxiv.org/abs/2009.07938" target="_blank">arXiv:2009.07938</a> [<a href="http://arxiv.org/pdf/2009.07938" target="_blank">pdf</a>]

<h2>Reinforcement Learning Approaches in Social Robotics. (arXiv:2009.09689v3 [cs.RO] UPDATED)</h2>
<h3>Neziha Akalin, Amy Loutfi</h3>
<p>This article surveys reinforcement learning (RL) approaches in social
robotics. RL is a framework for decision-making problems in which an agent
interacts through trial-and-error with its environment to discover an optimal
behavior. Since interaction is a key component in both RL and social robotics,
it can be a well-suited approach for real-world interactions with physically
embodied social robots. The scope of the paper is focused particularly on
studies that include social physical robots and real-world human-robot
interactions with users. In addition to a survey, we categorize existent RL
approaches based on the design of the reward mechanisms. This categorization
includes three major themes: interactive reinforcement learning, intrinsically
motivated methods, and task performance-driven methods. Thus, this paper aims
to become a starting point for researchers interested to use and apply
reinforcement learning methods in this particular research field.
</p>
<a href="http://arxiv.org/abs/2009.09689" target="_blank">arXiv:2009.09689</a> [<a href="http://arxiv.org/pdf/2009.09689" target="_blank">pdf</a>]

<h2>Solution Concepts in Hierarchical Games with Applications to Autonomous Driving. (arXiv:2009.10033v3 [cs.AI] UPDATED)</h2>
<h3>Atrisha Sarkar, Krzysztof Czarnecki</h3>
<p>With autonomous vehicles (AV) set to integrate further into regular human
traffic, there is an increasing consensus of treating AV motion planning as a
multi-agent problem. However, the traditional game theoretic assumption of
complete rationality is too strong for the purpose of human driving, and there
is a need for understanding human driving as a bounded rational activity
through a behavioral game theoretic lens. To that end, we adapt three
metamodels of bounded rational behavior; two based on Quantal level-k and one
based on Nash equilibrium with quantal errors. We formalize the different
solution concepts that can be applied in the context of hierarchical games, a
framework used in multi-agent motion planning, for the purpose of creating game
theoretic models of driving behavior. Furthermore, based on a contributed
dataset of human driving at a busy urban intersection with a total of ~4k
agents and ~44k decision points, we evaluate the behavior models on the basis
of model fit to naturalistic data, as well as their predictive capacity. Our
results suggest that among the behavior models evaluated, modeling driving
behavior as pure strategy NE with quantal errors at the level of maneuvers with
bounds sampling of actions at the level of trajectories provides the best fit
to naturalistic driving behavior.
</p>
<a href="http://arxiv.org/abs/2009.10033" target="_blank">arXiv:2009.10033</a> [<a href="http://arxiv.org/pdf/2009.10033" target="_blank">pdf</a>]

<h2>A Fast Graph Neural Network-Based Method for Winner Determination in Multi-Unit Combinatorial Auctions. (arXiv:2009.13697v2 [cs.LG] UPDATED)</h2>
<h3>Mengyuan Lee, Seyyedali Hosseinalipour, Christopher G. Brinton, Guanding Yu, Huaiyu Dai</h3>
<p>The combinatorial auction (CA) is an efficient mechanism for resource
allocation in different fields, including cloud computing. It can obtain high
economic efficiency and user flexibility by allowing bidders to submit bids for
combinations of different items instead of only for individual items. However,
the problem of allocating items among the bidders to maximize the auctioneers"
revenue, i.e., the winner determination problem (WDP), is NP-complete to solve
and inapproximable. Existing works for WDPs are generally based on mathematical
optimization techniques and most of them focus on the single-unit WDP, where
each item only has one unit. On the contrary, few works consider the multi-unit
WDP in which each item may have multiple units. Given that the multi-unit WDP
is more complicated but prevalent in cloud computing, we propose leveraging
machine learning (ML) techniques to develop a novel low-complexity algorithm
for solving this problem with negligible revenue loss. Specifically, we model
the multi-unit WDP as an augmented bipartite bid-item graph and use a graph
neural network (GNN) with half-convolution operations to learn the probability
of each bid belonging to the optimal allocation. To improve the sample
generation efficiency and decrease the number of needed labeled instances, we
propose two different sample generation processes. We also develop two novel
graph-based post-processing algorithms to transform the outputs of the GNN into
feasible solutions. Through simulations on both synthetic instances and a
specific virtual machine (VM) allocation problem in a cloud computing platform,
we validate that our proposed method can approach optimal performance with low
complexity and has good generalization ability in terms of problem size and
user-type distribution.
</p>
<a href="http://arxiv.org/abs/2009.13697" target="_blank">arXiv:2009.13697</a> [<a href="http://arxiv.org/pdf/2009.13697" target="_blank">pdf</a>]

<h2>Towards Target-Driven Visual Navigation in Indoor Scenes via Generative Imitation Learning. (arXiv:2009.14509v2 [cs.RO] UPDATED)</h2>
<h3>Qiaoyun Wu, Xiaoxi Gong, Kai Xu, Dinesh Manocha, Jingxuan Dong, Jun Wang</h3>
<p>We present a target-driven navigation system to improve mapless visual
navigation in indoor scenes. Our method takes a multi-view observation of a
robot and a target as inputs at each time step to provide a sequence of actions
that move the robot to the target without relying on odometry or GPS at
runtime. The system is learned by optimizing a combinational objective
encompassing three key designs. First, we propose that an agent conceives the
next observation before making an action decision. This is achieved by learning
a variational generative module from expert demonstrations. We then propose
predicting static collision in advance, as an auxiliary task to improve safety
during navigation. Moreover, to alleviate the training data imbalance problem
of termination action prediction, we also introduce a target checking module to
differentiate from augmenting navigation policy with a termination action. The
three proposed designs all contribute to the improved training data efficiency,
static collision avoidance, and navigation generalization performance,
resulting in a novel target-driven mapless navigation system. Through
experiments on a TurtleBot, we provide evidence that our model can be
integrated into a robotic system and navigate in the real world. Videos and
models can be found in the supplementary material.
</p>
<a href="http://arxiv.org/abs/2009.14509" target="_blank">arXiv:2009.14509</a> [<a href="http://arxiv.org/pdf/2009.14509" target="_blank">pdf</a>]

<h2>RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior. (arXiv:2010.00029v4 [cs.LG] UPDATED)</h2>
<h3>Hong-Ye Hu, Dian Wu, Yi-Zhuang You, Bruno Olshausen, Yubei Chen</h3>
<p>Flow-based generative models have become an important class of unsupervised
learning approaches. In this work, we incorporate the key idea of
renormalization group (RG) and sparse prior distribution to design a
hierarchical flow-based generative model, called RG-Flow, which can separate
information at different scales of images with disentangled representations at
each scale. We demonstrate our method mainly on the CelebA dataset and show
that the disentangled representations at different scales enable semantic
manipulation and style mixing of the images. To visualize the latent
representations, we introduce receptive fields for flow-based models and find
that the receptive fields learned by RG-Flow are similar to those in
convolutional neural networks. In addition, we replace the widely adopted
Gaussian prior distribution by a sparse prior distribution to further enhance
the disentanglement of representations. From a theoretical perspective, the
proposed method has $O(\log L)$ complexity for image inpainting compared to
previous generative models with $O(L^2)$ complexity.
</p>
<a href="http://arxiv.org/abs/2010.00029" target="_blank">arXiv:2010.00029</a> [<a href="http://arxiv.org/pdf/2010.00029" target="_blank">pdf</a>]

<h2>Early Bird: Loop Closures from Opposing Viewpoints for Perceptually-Aliased Indoor Environments. (arXiv:2010.01421v3 [cs.CV] UPDATED)</h2>
<h3>Satyajit Tourani, Dhagash Desai, Udit Singh Parihar, Sourav Garg, Ravi Kiran Sarvadevabhatla, Michael Milford, K. Madhava Krishna</h3>
<p>Significant advances have been made recently in Visual Place Recognition
(VPR), feature correspondence, and localization due to the proliferation of
deep-learning-based methods. However, existing approaches tend to address,
partially or fully, only one of two key challenges: viewpoint change and
perceptual aliasing. In this paper, we present novel research that
simultaneously addresses both challenges by combining deep-learned features
with geometric transformations based on reasonable domain assumptions about
navigation on a ground-plane, whilst also removing the requirement for
specialized hardware setup (e.g. lighting, downwards facing cameras). In
particular, our integration of VPR with SLAM by leveraging the robustness of
deep-learned features and our homography-based extreme viewpoint invariance
significantly boosts the performance of VPR, feature correspondence, and pose
graph submodules of the SLAM pipeline. For the first time, we demonstrate a
localization system capable of state-of-the-art performance despite perceptual
aliasing and extreme 180-degree-rotated viewpoint change in a range of
real-world and simulated experiments. Our system is able to achieve early loop
closures that prevent significant drifts in SLAM trajectories. We also compare
extensively several deep architectures for VPR and descriptor matching. We also
show that superior place recognition and descriptor matching across opposite
views results in a similar performance gain in back-end pose graph
optimization.
</p>
<a href="http://arxiv.org/abs/2010.01421" target="_blank">arXiv:2010.01421</a> [<a href="http://arxiv.org/pdf/2010.01421" target="_blank">pdf</a>]

<h2>AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients. (arXiv:2010.07468v5 [cs.LG] UPDATED)</h2>
<h3>Juntang Zhuang, Tommy Tang, Yifan Ding, Sekhar Tatikonda, Nicha Dvornek, Xenophon Papademetris, James S. Duncan</h3>
<p>Most popular optimizers for deep learning can be broadly categorized as
adaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient
descent (SGD) with momentum). For many models such as convolutional neural
networks (CNNs), adaptive methods typically converge faster but generalize
worse compared to SGD; for complex settings such as generative adversarial
networks (GANs), adaptive methods are typically the default because of their
stability.We propose AdaBelief to simultaneously achieve three goals: fast
convergence as in adaptive methods, good generalization as in SGD, and training
stability. The intuition for AdaBelief is to adapt the stepsize according to
the "belief" in the current gradient direction. Viewing the exponential moving
average (EMA) of the noisy gradient as the prediction of the gradient at the
next time step, if the observed gradient greatly deviates from the prediction,
we distrust the current observation and take a small step; if the observed
gradient is close to the prediction, we trust it and take a large step. We
validate AdaBelief in extensive experiments, showing that it outperforms other
methods with fast convergence and high accuracy on image classification and
language modeling. Specifically, on ImageNet, AdaBelief achieves comparable
accuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief
demonstrates high stability and improves the quality of generated samples
compared to a well-tuned Adam optimizer. Code is available at
https://github.com/juntang-zhuang/Adabelief-Optimizer
</p>
<a href="http://arxiv.org/abs/2010.07468" target="_blank">arXiv:2010.07468</a> [<a href="http://arxiv.org/pdf/2010.07468" target="_blank">pdf</a>]

<h2>Reducing the Teacher-Student Gap via Spherical Knowledge Disitllation. (arXiv:2010.07485v4 [cs.LG] UPDATED)</h2>
<h3>Jia Guo, Minghao Chen, Yao Hu, Chen Zhu, Xiaofei He, Deng Cai</h3>
<p>Knowledge distillation aims at obtaining a compact and effective model by
learning the mapping function from a much larger one. Due to the limited
capacity of the student, the student would underfit the teacher. Therefore,
student performance would unexpectedly drop when distilling from an oversized
teacher, termed the capacity gap problem. We investigate this problem by study
the gap of confidence between teacher and student. We find that the magnitude
of confidence is not necessary for knowledge distillation and could harm the
student performance if the student are forced to learn confidence. We propose
Spherical Knowledge Distillation to eliminate this gap explicitly, which eases
the underfitting problem. We find this novel knowledge representation can
improve compact models with much larger teachers and is robust to temperature.
We conducted experiments on both CIFAR100 and ImageNet, and achieve significant
improvement. Specifically, we train ResNet18 to 73.0 accuracy, which is a
substantial improvement over previous SOTA and is on par with resnet34 almost
twice the student size. The implementation has been shared at
https://github.com/forjiuzhou/Spherical-Knowledge-Distillation.
</p>
<a href="http://arxiv.org/abs/2010.07485" target="_blank">arXiv:2010.07485</a> [<a href="http://arxiv.org/pdf/2010.07485" target="_blank">pdf</a>]

<h2>Autonomous Control of a Particle Accelerator using Deep Reinforcement Learning. (arXiv:2010.08141v2 [cs.AI] UPDATED)</h2>
<h3>Xiaoying Pang, Sunil Thulasidasan, Larry Rybarcyk</h3>
<p>We describe an approach to learning optimal control policies for a large,
linear particle accelerator using deep reinforcement learning coupled with a
high-fidelity physics engine. The framework consists of an AI controller that
uses deep neural nets for state and action-space representation and learns
optimal policies using reward signals that are provided by the physics
simulator. For this work, we only focus on controlling a small section of the
entire accelerator. Nevertheless, initial results indicate that we can achieve
better-than-human level performance in terms of particle beam current and
distribution. The ultimate goal of this line of work is to substantially reduce
the tuning time for such facilities by orders of magnitude, and achieve
near-autonomous control.
</p>
<a href="http://arxiv.org/abs/2010.08141" target="_blank">arXiv:2010.08141</a> [<a href="http://arxiv.org/pdf/2010.08141" target="_blank">pdf</a>]

<h2>Active Domain Adaptation via Clustering Uncertainty-weighted Embeddings. (arXiv:2010.08666v2 [cs.CV] UPDATED)</h2>
<h3>Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, Judy Hoffman</h3>
<p>Generalizing deep neural networks to new target domains is critical to their
real-world utility. In practice, it may be feasible to get some target data
labeled, but to be cost-effective it is desirable to select a
maximally-informative subset via active learning (AL). We study the problem of
AL under a domain shift, called Active Domain Adaptation (Active DA). We
empirically demonstrate how existing AL approaches based solely on model
uncertainty or diversity sampling are suboptimal for Active DA. Our algorithm,
Active Domain Adaptation via Clustering Uncertainty-weighted Embeddings
(ADA-CLUE), i) identifies target instances for labeling that are both uncertain
under the model and diverse in feature space, and ii) leverages the available
source and target data for adaptation by optimizing a semi-supervised
adversarial entropy loss that is complementary to our active sampling
objective. On standard image classification-based domain adaptation benchmarks,
ADA-CLUE consistently outperforms competing active adaptation, active learning,
and domain adaptation methods across domain shifts of varying severity.
</p>
<a href="http://arxiv.org/abs/2010.08666" target="_blank">arXiv:2010.08666</a> [<a href="http://arxiv.org/pdf/2010.08666" target="_blank">pdf</a>]

<h2>Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems. (arXiv:2010.09301v3 [cs.LG] UPDATED)</h2>
<h3>Anh Tong, Jaesik Choi</h3>
<p>Recent advances in Deep Gaussian Processes (DGPs) show the potential to have
more expressive representation than that of traditional Gaussian Processes
(GPs). However, there exists a pathology of deep Gaussian processes that their
learning capacities reduce significantly when the number of layers increases.
In this paper, we present a new analysis in DGPs by studying its corresponding
nonlinear dynamic systems to explain the issue. Existing work reports the
pathology for the squared exponential kernel function. We extend our
investigation to four types of common stationary kernel functions. The
recurrence relations between layers are analytically derived, providing a
tighter bound and the rate of convergence of the dynamic systems. We
demonstrate our finding with a number of experimental results.
</p>
<a href="http://arxiv.org/abs/2010.09301" target="_blank">arXiv:2010.09301</a> [<a href="http://arxiv.org/pdf/2010.09301" target="_blank">pdf</a>]

<h2>Permute, Quantize, and Fine-tune: Efficient Compression of Neural Networks. (arXiv:2010.15703v2 [cs.CV] UPDATED)</h2>
<h3>Julieta Martinez, Jashan Shewakramani, Ting Wei Liu, Ioan Andrei B&#xe2;rsan, Wenyuan Zeng, Raquel Urtasun</h3>
<p>Compressing large neural networks is an important step for their deployment
in resource-constrained computational platforms. In this context, vector
quantization is an appealing framework that expresses multiple parameters using
a single code, and has recently achieved state-of-the-art network compression
on a range of core vision and natural language processing tasks. Key to the
success of vector quantization is deciding which parameter groups should be
compressed together. Previous work has relied on heuristics that group the
spatial dimension of individual convolutional filters, but a general solution
remains unaddressed. This is desirable for pointwise convolutions (which
dominate modern architectures), linear layers (which have no notion of spatial
dimension), and convolutions (when more than one filter is compressed to the
same codeword). In this paper we make the observation that the weights of two
adjacent layers can be permuted while expressing the same function. We then
establish a connection to rate-distortion theory and search for permutations
that result in networks that are easier to compress. Finally, we rely on an
annealed quantization algorithm to better compress the network and achieve
higher final accuracy. We show results on image classification, object
detection, and segmentation, reducing the gap with the uncompressed model by 40
to 70% with respect to the current state of the art.
</p>
<a href="http://arxiv.org/abs/2010.15703" target="_blank">arXiv:2010.15703</a> [<a href="http://arxiv.org/pdf/2010.15703" target="_blank">pdf</a>]

<h2>Self-paced and self-consistent co-training for semi-supervised image segmentation. (arXiv:2011.00325v3 [cs.CV] UPDATED)</h2>
<h3>Ping Wang, Jizong Peng, Marco Pedersoli, Yuanfeng Zhou, Caiming Zhang, Christian Desrosiers</h3>
<p>Deep co-training has recently been proposed as an effective approach for
image segmentation when annotated data is scarce. In this paper, we improve
existing approaches for semi-supervised segmentation with a self-paced and
self-consistent co-training method. To help distillate information from
unlabeled images, we first design a self-paced learning strategy for
co-training that lets jointly-trained neural networks focus on
easier-to-segment regions first, and then gradually consider harder ones.This
is achieved via an end-to-end differentiable loss inthe form of a generalized
Jensen Shannon Divergence(JSD). Moreover, to encourage predictions from
different networks to be both consistent and confident, we enhance this
generalized JSD loss with an uncertainty regularizer based on entropy. The
robustness of individual models is further improved using a self-ensembling
loss that enforces their prediction to be consistent across different training
iterations. We demonstrate the potential of our method on three challenging
image segmentation problems with different image modalities, using small
fraction of labeled data. Results show clear advantages in terms of performance
compared to the standard co-training baselines and recently proposed
state-of-the-art approaches for semi-supervised segmentation
</p>
<a href="http://arxiv.org/abs/2011.00325" target="_blank">arXiv:2011.00325</a> [<a href="http://arxiv.org/pdf/2011.00325" target="_blank">pdf</a>]

<h2>A Survey on Contrastive Self-supervised Learning. (arXiv:2011.00362v2 [cs.CV] UPDATED)</h2>
<h3>Ashish Jaiswal, Ashwin Ramesh Babu, Mohammad Zaki Zadeh, Debapriya Banerjee, Fillia Makedon</h3>
<p>Self-supervised learning has gained popularity because of its ability to
avoid the cost of annotating large-scale datasets. It is capable of adopting
self-defined pseudo labels as supervision and use the learned representations
for several downstream tasks. Specifically, contrastive learning has recently
become a dominant component in self-supervised learning methods for computer
vision, natural language processing (NLP), and other domains. It aims at
embedding augmented versions of the same sample close to each other while
trying to push away embeddings from different samples. This paper provides an
extensive review of self-supervised methods that follow the contrastive
approach. The work explains commonly used pretext tasks in a contrastive
learning setup, followed by different architectures that have been proposed so
far. Next, we have a performance comparison of different methods for multiple
downstream tasks such as image classification, object detection, and action
recognition. Finally, we conclude with the limitations of the current methods
and the need for further techniques and future directions to make substantial
progress.
</p>
<a href="http://arxiv.org/abs/2011.00362" target="_blank">arXiv:2011.00362</a> [<a href="http://arxiv.org/pdf/2011.00362" target="_blank">pdf</a>]

<h2>Predictive Analysis of Diabetic Retinopathy with Transfer Learning. (arXiv:2011.04052v2 [cs.CV] UPDATED)</h2>
<h3>Shreyas Rajesh Labhsetwar, Raj Sunil Salvi, Piyush Arvind Kolte, Veerasai Subramaniam venkatesh, Alistair Michael Baretto</h3>
<p>With the prevalence of Diabetes, the Diabetes Mellitus Retinopathy (DR) is
becoming a major health problem across the world. The long-term medical
complications arising due to DR have a significant impact on the patient as
well as the society, as the disease mostly affects individuals in their most
productive years. Early detection and treatment can help reduce the extent of
damage to the patients. The rise of Convolutional Neural Networks for
predictive analysis in the medical field paves the way for a robust solution to
DR detection. This paper studies the performance of several highly efficient
and scalable CNN architectures for Diabetic Retinopathy Classification with the
help of Transfer Learning. The research focuses on VGG16, Resnet50 V2 and
EfficientNet B0 models. The classification performance is analyzed using
several performance metrics including True Positive Rate, False Positive Rate,
Accuracy, etc. Also, several performance graphs are plotted for visualizing the
architecture performance including Confusion Matrix, ROC Curve, etc. The
results indicate that Transfer Learning with ImageNet weights using VGG 16
model demonstrates the best classification performance with the best Accuracy
of 95%. It is closely followed by ResNet50 V2 architecture with the best
Accuracy of 93%. This paper shows that predictive analysis of DR from retinal
images is achieved with Transfer Learning on Convolutional Neural Networks.
</p>
<a href="http://arxiv.org/abs/2011.04052" target="_blank">arXiv:2011.04052</a> [<a href="http://arxiv.org/pdf/2011.04052" target="_blank">pdf</a>]

<h2>Continuous Conditional Generative Adversarial Networks for Image Generation: Novel Losses and Label Input Mechanisms. (arXiv:2011.07466v2 [cs.CV] UPDATED)</h2>
<h3>Xin Ding, Yongwei Wang, Zuheng Xu, William J. Welch, Z. Jane Wang</h3>
<p>This work proposes the continuous conditional generative adversarial network
(CcGAN), the first generative model for image generation conditional on
continuous, scalar conditions (termed regression labels). Existing conditional
GANs (cGANs) are mainly designed for categorical conditions (e.g., class
labels); conditioning on regression labels is mathematically distinct and
raises two fundamental problems: (P1) Since there may be very few (even zero)
real images for some regression labels, minimizing existing empirical versions
of cGAN losses (a.k.a. empirical cGAN losses) often fails in practice; (P2)
Since regression labels are scalar and infinitely many, conventional label
input methods are not applicable. The proposed CcGAN solves the above problems,
respectively, by (S1) reformulating existing empirical cGAN losses to be
appropriate for the continuous scenario; and (S2) proposing a naive label input
(NLI) method and an improved label input (ILI) method to incorporate regression
labels into the generator and the discriminator. The reformulation in (S1)
leads to two novel empirical discriminator losses, termed the hard vicinal
discriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL)
respectively, and a novel empirical generator loss. The error bounds of a
discriminator trained with HVDL and SVDL are derived under mild assumptions in
this work. Two new benchmark datasets (RC-49 and Cell-200) and a novel
evaluation metric (Sliding Fr\'echet Inception Distance) are also proposed for
this continuous scenario. Our experiments on the Circular 2-D Gaussians, RC-49,
UTKFace, Cell-200, and Steering Angle datasets show that CcGAN can generate
diverse, high-quality samples from the image distribution conditional on a
given regression label. Moreover, in these experiments, CcGAN substantially
outperforms cGAN both visually and quantitatively.
</p>
<a href="http://arxiv.org/abs/2011.07466" target="_blank">arXiv:2011.07466</a> [<a href="http://arxiv.org/pdf/2011.07466" target="_blank">pdf</a>]

<h2>Risk-Constrained Thompson Sampling for CVaR Bandits. (arXiv:2011.08046v3 [cs.LG] UPDATED)</h2>
<h3>Joel Q. L. Chang, Qiuyu Zhu, Vincent Y. F. Tan</h3>
<p>The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem
that exemplifies the exploration-exploitation tradeoff. Standard formulations
exclude risk in decision making. Risk notably complicates the basic
reward-maximising objective, in part because there is no universally agreed
definition of it. In this paper, we consider a popular risk measure in
quantitative finance known as the Conditional Value at Risk (CVaR). We explore
the performance of a Thompson Sampling-based algorithm CVaR-TS under this risk
measure. We provide comprehensive comparisons between our regret bounds with
state-of-the-art L/UCB-based algorithms in comparable settings and demonstrate
their clear improvement in performance. We also include numerical simulations
to empirically verify that CVaR-TS outperforms other L/UCB-based algorithms.
</p>
<a href="http://arxiv.org/abs/2011.08046" target="_blank">arXiv:2011.08046</a> [<a href="http://arxiv.org/pdf/2011.08046" target="_blank">pdf</a>]

<h2>Explaining the Adaptive Generalisation Gap. (arXiv:2011.08181v2 [stat.ML] UPDATED)</h2>
<h3>Diego Granziol, Samuel Albanie, Xingchen Wan, Stephen Roberts</h3>
<p>We conjecture that the reason for the difference in generalisation between
adaptive and non adaptive gradient methods stems from the failure of adaptive
methods to account for the greater levels of noise associated with flatter
directions in their estimates of local curvature. This conjecture motivated by
results in random matrix theory has implications for optimisation in both
simple convex settings and deep neural networks. We demonstrate that typical
schedules used for adaptive methods (with low numerical stability or damping
constants) serve to bias relative movement towards flat directions relative to
sharp directions, effectively amplifying the noise-to-signal ratio and harming
generalisation. We show that the numerical stability/damping constant used in
these methods can be decomposed into a learning rate reduction and linear
shrinkage of the estimated curvature matrix. We then demonstrate significant
generalisation improvements by increasing the shrinkage coefficient, closing
the generalisation gap entirely in our neural network experiments. Finally, we
show that other popular modifications to adaptive methods, such as decoupled
weight decay and partial adaptivity can be shown to calibrate parameter updates
to make better use of sharper, more reliable directions.
</p>
<a href="http://arxiv.org/abs/2011.08181" target="_blank">arXiv:2011.08181</a> [<a href="http://arxiv.org/pdf/2011.08181" target="_blank">pdf</a>]

<h2>Causal Contextual Prediction for Learned Image Compression. (arXiv:2011.09704v2 [cs.CV] UPDATED)</h2>
<h3>Zongyu Guo, Zhizheng Zhang, Runsen Feng, Zhibo Chen</h3>
<p>Over the past several years, we have witnessed impressive progress in the
field of learned image compression. Recent learned image codecs are commonly
based on autoencoders, that first encode an image into low-dimensional latent
representations and then decode them for reconstruction purposes. To capture
spatial dependencies in the latent space, prior works exploit hyperprior and
spatial context model to build an entropy model, which estimates the bit-rate
for end-to-end rate-distortion optimization. However, such an entropy model is
suboptimal from two aspects: (1) It fails to capture spatially global
correlations among the latents. (2) Cross-channel relationships of the latents
are still underexplored. In this paper, we propose the concept of separate
entropy coding to leverage a serial decoding process for causal contextual
entropy prediction in the latent space. A causal context model is proposed that
separates the latents across channels and makes use of cross-channel
relationships to generate highly informative contexts. Furthermore, we propose
a causal global prediction model, which is able to find global reference points
for accurate predictions of unknown points. Both these two models facilitate
entropy estimation without the transmission of overhead. In addition, we
further adopt a new separate attention module to build more powerful transform
networks. Experimental results demonstrate that our full image compression
model outperforms standard VVC/H.266 codec on Kodak dataset in terms of both
PSNR and MS-SSIM, yielding the state-of-the-art rate-distortion performance.
Our test code is available at
this http URL
</p>
<a href="http://arxiv.org/abs/2011.09704" target="_blank">arXiv:2011.09704</a> [<a href="http://arxiv.org/pdf/2011.09704" target="_blank">pdf</a>]

<h2>BARS: Joint Search of Cell Topology and Layout for Accurate and Efficient Binary ARchitectures. (arXiv:2011.10804v2 [cs.AI] UPDATED)</h2>
<h3>Tianchen Zhao, Xuefei Ning, Songyi Yang, Shuang Liang, Peng Lei, Jianfei Chen, Huazhong Yang, Yu Wang</h3>
<p>Binary Neural Networks (BNNs) have received significant attention due to
their promising efficiency. Currently, most BNN studies directly adopt
widely-used CNN architectures, which can be suboptimal for BNNs. This paper
proposes a novel Binary ARchitecture Search (BARS) flow to discover superior
binary architecture in a large design space. Specifically, we design a
two-level (Macro &amp; Micro) search space tailored for BNNs and apply a
differentiable neural architecture search (NAS) to explore this search space
efficiently. The macro-level search space includes depth and width decisions,
which is required for better balancing the model performance and capacity. And
we also make modifications to the micro-level search space to strengthen the
information flow for BNN. A notable challenge of BNN architecture search lies
in that binary operations exacerbate the "collapse" problem of differentiable
NAS, and we incorporate various search and derive strategies to stabilize the
search process. On CIFAR-10, BARS achieves 1.5% higher accuracy with 2/3 binary
Ops and $1/10$ floating-point Ops. On ImageNet, with similar resource
consumption, BARS-discovered architecture achieves 3% accuracy gain than
hand-crafted architectures, while removing the full-precision downsample layer.
</p>
<a href="http://arxiv.org/abs/2011.10804" target="_blank">arXiv:2011.10804</a> [<a href="http://arxiv.org/pdf/2011.10804" target="_blank">pdf</a>]

<h2>Functional Time Series Forecasting: Functional Singular Spectrum Analysis Approaches. (arXiv:2011.13077v3 [stat.ML] UPDATED)</h2>
<h3>Jordan Trinka, Hossein Haghbin, Mehdi Maadooliat</h3>
<p>In this paper, we propose two nonparametric methods used in the forecasting
of functional time-dependent data, namely functional singular spectrum analysis
recurrent forecasting and vector forecasting. Both algorithms utilize the
results of functional singular spectrum analysis and past observations in order
to predict future data points where recurrent forecasting predicts one function
at a time and the vector forecasting makes predictions using functional
vectors. We compare our forecasting methods to a gold standard algorithm used
in the prediction of functional, time-dependent data by way of simulation and
real data and we find our techniques do better for periodic stochastic
processes.
</p>
<a href="http://arxiv.org/abs/2011.13077" target="_blank">arXiv:2011.13077</a> [<a href="http://arxiv.org/pdf/2011.13077" target="_blank">pdf</a>]

<h2>Robust Detection of Non-overlapping Ellipses from Points with Applications to Circular Target Extraction in Images and Cylinder Detection in Point Clouds. (arXiv:2011.13849v2 [cs.CV] UPDATED)</h2>
<h3>Reza Maalek, Derek Lichti</h3>
<p>This manuscript provides a collection of new methods for the automated
detection of non-overlapping ellipses from edge points. The new methods include
a robust Monte Carlo-based approach for detecting points following elliptical
patterns from outliers; process to detect non-overlapping ellipses from edge
points; and procedure to detect cylinders from three-dimensional point clouds.
The proposed methods were thoroughly compared with established state-of-the-art
methods, using simulated and real-world datasets, through the design of four
sets of original experiments. It was found that the proposed robust ellipse
detection was superior to four reliable robust methods, including the popular
least median of squares, in both simulated and real-world datasets. The
proposed process for detecting non-overlapping ellipses outperformed three
established methods, proposed by Fornaciari, Patraucean, and Pangiotakis, in
images. The proposed cylinder extraction method identified all detectable
mechanical pipes in real-world point clouds. The results of this investigation
show promise for the application of the proposed methods for automatic
extraction of circular targets from images and pipes from point clouds.
</p>
<a href="http://arxiv.org/abs/2011.13849" target="_blank">arXiv:2011.13849</a> [<a href="http://arxiv.org/pdf/2011.13849" target="_blank">pdf</a>]

<h2>Image-based plant disease diagonasis with unsupervised anomaly detection based on reconstructability of colors. (arXiv:2011.14306v2 [cs.CV] UPDATED)</h2>
<h3>Ryoya Katafuchi, Terumasa Tokunaga</h3>
<p>This paper proposes an unsupervised anomaly detection technique for
image-based plant disease diagnosis. A construction of large and openly
available data set on labeled images of healthy and diseased crop plants has
led to growing interest in computer vision techniques for plant disease
diagnosis. Although supervised image classifiers based on deep learning could
be a powerful tool to identify plant diseases, they require huge amount of data
set that have been labeled as healthy and disease. While, data mining
techniques called anomaly detection includes unsupervised approaches that not
require rare samples for training classifiers The proposed method in this study
focuses on the reconstructability of colors on plant images. We expect that a
deep encoder decoder network trained for reconstructing colors of healthy plant
images fails to color symptomatic regions. The main contributions of this work
are as follows: (i) we propose a new image-based plant disease detection
framework utilising a conditional adversarial network called pix2pix,(ii) we
introduce a new anomaly score calculated from CIEDE2000 color difference.
Through experiments using the PlantVillage dataset, we demonstrate that our
method is superior to an existing anomaly detector called AnoGAN for
identifying diseased crop images in terms of accuracy, interpretability and
computational efficiency.
</p>
<a href="http://arxiv.org/abs/2011.14306" target="_blank">arXiv:2011.14306</a> [<a href="http://arxiv.org/pdf/2011.14306" target="_blank">pdf</a>]

<h2>BOTD: Bold Outline Text Detector. (arXiv:2011.14714v3 [cs.CV] UPDATED)</h2>
<h3>Chuang Yang, Zhitong Xiong, Mulin Chen, Qi Wang, Xuelong Li</h3>
<p>Recently, text detection for arbitrary shape has attracted more and more
search attention. Although segmentation-based methods, which are not limited by
the text shape, have been studied to improve the performance, the slow
detection speed, complicated post-processing, and text adhesion problem are
still limitations for the practical application. In this paper, we propose a
simple yet effective arbitrary-shape text detector, named Bold Outline Text
Detector (BOTD). It is a novel one-stage detection framework with few
post-processing processes. At the same time, the text adhesion problem can also
be well alleviated. Specifically, BOTD first generates a center mask (CM) for
each text instance, which makes the adhesive text easy to distinguish. Base on
the CM, we further compute the polar minimum distance (PMD) for each text
instance. PMD denotes the shortest distance between the center point of CM and
the outline of the text instance. By dividing the text mask into CM and PMD,
the outline of arbitrary-shape text instance can be obtained by simply
predicting its CM and PMD. Without any bells and whistles, BOTD achieves an
F-measure of 80.1% on CTW1500 with 52 FPS. Note that the post-processing time
only accounts for 9% of the whole inference time. Code and trained models will
be publicly available soon.
</p>
<a href="http://arxiv.org/abs/2011.14714" target="_blank">arXiv:2011.14714</a> [<a href="http://arxiv.org/pdf/2011.14714" target="_blank">pdf</a>]

<h2>Singularity-free Guiding Vector Field for Robot Navigation. (arXiv:2012.01826v2 [cs.RO] UPDATED)</h2>
<h3>Weijia Yao, Hector Garcia de Marina, Bohuan Lin, Ming Cao</h3>
<p>Most of the existing path-following navigation algorithms cannot guarantee
global convergence to desired paths or enable following self-intersected
desired paths due to the existence of singular points where navigation
algorithms return unreliable or even no solutions. One typical example arises
in vector-field guided path-following (VF-PF) navigation algorithms. These
algorithms are based on a vector field, and the singular points are exactly
where the vector field diminishes. In this paper, we show that it is
mathematically impossible for conventional VF-PF algorithms to achieve global
convergence to desired paths that are self-intersected or even just simple
closed (precisely, homeomorphic to the unit circle). Motivated by this new
impossibility result, we propose a novel method to transform self-intersected
or simple closed desired paths to non-self-intersected and unbounded
(precisely, homeomorphic to the real line) counterparts in a higher-dimensional
space. Corresponding to this new desired path, we construct a singularity-free
guiding vector field on a higher-dimensional space. The integral curves of this
new guiding vector field is thus exploited to enable global convergence to the
higher-dimensional desired path, and therefore the projection of the integral
curves on a lower-dimensional subspace converge to the physical
(lower-dimensional) desired path. Rigorous theoretical analysis is carried out
for the theoretical results using dynamical systems theory. In addition, we
show both by theoretical analysis and numerical simulations that our proposed
method is an extension combining conventional VF-PF algorithms and trajectory
tracking algorithms. Finally, to show the practical value of our proposed
approach for complex engineering systems, we conduct outdoor experiments with a
fixed-wing airplane in windy environment to follow both 2D and 3D desired
paths.
</p>
<a href="http://arxiv.org/abs/2012.01826" target="_blank">arXiv:2012.01826</a> [<a href="http://arxiv.org/pdf/2012.01826" target="_blank">pdf</a>]

<h2>Better Than Ground-truth? Beyond Supervised Learning for Photoacoustic Imaging Reconstruction. (arXiv:2012.02472v2 [cs.CV] UPDATED)</h2>
<h3>Hengrong Lan, Changchun Yang, Feng Gao, Fei Gao</h3>
<p>Photoacoustic computed tomography (PACT) reconstructs the initial pressure
distribution from raw PA signals. Standard reconstruction always induces
artifacts using limited-view signals, which are influenced by limited angle
coverage of transducers, finite bandwidth, and uncertain heterogeneous
biological tissue. Recently, supervised deep learning has been used to overcome
limited-view problem that requires ground-truth. However, even full-view
sampling still induces artifacts that cannot be used to train the model. It
causes a dilemma that we could not acquire perfect ground-truth in practice. To
reduce the dependence on the quality of ground-truth, in this paper, for the
first time, we propose a beyond supervised reconstruction framework (BSR-Net)
based on deep learning to compensate the limited-view issue by feeding
limited-view position-wise data. A quarter position-wise data is fed into model
and outputs a group full-view data. Specifically, our method introduces a
residual structure, which generates beyond supervised reconstruction result,
whose artifacts are drastically reduced in the output compared to ground-truth.
Moreover, two novel losses are designed to restrain the artifacts. The
numerical and in-vivo results have demonstrated the performance of our method
to reconstruct the full-view image without artifacts.
</p>
<a href="http://arxiv.org/abs/2012.02472" target="_blank">arXiv:2012.02472</a> [<a href="http://arxiv.org/pdf/2012.02472" target="_blank">pdf</a>]

<h2>AuthNet: A Deep Learning based Authentication Mechanism using Temporal Facial Feature Movements. (arXiv:2012.02515v2 [cs.CV] UPDATED)</h2>
<h3>Mohit Raghavendra, Pravan Omprakash, B R Mukesh, Sowmya Kamath</h3>
<p>Biometric systems based on Machine learning and Deep learning are being
extensively used as authentication mechanisms in resource-constrained
environments like smartphones and other small computing devices. These
AI-powered facial recognition mechanisms have gained enormous popularity in
recent years due to their transparent, contact-less and non-invasive nature.
While they are effective to a large extent, there are ways to gain unauthorized
access using photographs, masks, glasses, etc. In this paper, we propose an
alternative authentication mechanism that uses both facial recognition and the
unique movements of that particular face while uttering a password, that is,
the temporal facial feature movements. The proposed model is not inhibited by
language barriers because a user can set a password in any language. When
evaluated on the standard MIRACL-VC1 dataset, the proposed model achieved an
accuracy of 98.1%, underscoring its effectiveness as an effective and robust
system. The proposed method is also data-efficient since the model gave good
results even when trained with only 10 positive video samples. The competence
of the training of the network is also demonstrated by benchmarking the
proposed system against various compounded Facial recognition and Lip reading
models.
</p>
<a href="http://arxiv.org/abs/2012.02515" target="_blank">arXiv:2012.02515</a> [<a href="http://arxiv.org/pdf/2012.02515" target="_blank">pdf</a>]

<h2>Learning to Rearrange Deformable Cables, Fabrics, and Bags with Goal-Conditioned Transporter Networks. (arXiv:2012.03385v2 [cs.RO] UPDATED)</h2>
<h3>Daniel Seita, Pete Florence, Jonathan Tompson, Erwin Coumans, Vikas Sindhwani, Ken Goldberg, Andy Zeng</h3>
<p>Rearranging and manipulating deformable objects such as cables, fabrics, and
bags is a long-standing challenge in robotic manipulation. The complex dynamics
and high-dimensional configuration spaces of deformables, compared to rigid
objects, make manipulation difficult not only for multi-step planning, but even
for goal specification. Goals cannot be as easily specified as rigid object
poses, and may involve complex relative spatial relations such as "place the
item inside the bag". In this work, we develop a suite of simulated benchmarks
with 1D, 2D, and 3D deformable structures, including tasks that involve
image-based goal-conditioning and multi-step deformable manipulation. We
propose embedding goal-conditioning into Transporter Networks, a recently
proposed model architecture for learning robotic manipulation that rearranges
deep features to infer displacements that can represent pick and place actions.
We demonstrate that goal-conditioned Transporter Networks enable agents to
manipulate deformable structures into flexibly specified configurations without
test-time visual anchors for target locations. We also significantly extend
prior results using Transporter Networks for manipulating deformable objects by
testing on tasks with 2D and 3D deformables. Supplementary material is
available at https://berkeleyautomation.github.io/bags/.
</p>
<a href="http://arxiv.org/abs/2012.03385" target="_blank">arXiv:2012.03385</a> [<a href="http://arxiv.org/pdf/2012.03385" target="_blank">pdf</a>]

<h2>A PAC-Bayesian Perspective on Structured Prediction with Implicit Loss Embeddings. (arXiv:2012.03780v2 [cs.LG] UPDATED)</h2>
<h3>Th&#xe9;ophile Cantelobre, Benjamin Guedj, Mar&#xed;a P&#xe9;rez-Ortiz, John Shawe-Taylor</h3>
<p>Many practical machine learning tasks can be framed as Structured prediction
problems, where several output variables are predicted and considered
interdependent. Recent theoretical advances in structured prediction have
focused on obtaining fast rates convergence guarantees, especially in the
Implicit Loss Embedding (ILE) framework. PAC-Bayes has gained interest recently
for its capacity of producing tight risk bounds for predictor distributions.
This work proposes a novel PAC-Bayes perspective on the ILE Structured
prediction framework. We present two generalization bounds, on the risk and
excess risk, which yield insights into the behavior of ILE predictors. Two
learning algorithms are derived from these bounds. The algorithms are
implemented and their behavior analyzed, with source code available at
\url{https://github.com/theophilec/PAC-Bayes-ILE-Structured-Prediction}.
</p>
<a href="http://arxiv.org/abs/2012.03780" target="_blank">arXiv:2012.03780</a> [<a href="http://arxiv.org/pdf/2012.03780" target="_blank">pdf</a>]

<h2>Using Feature Alignment Can Improve Clean Average Precision and Adversarial Robustness in Object Detection. (arXiv:2012.04382v2 [cs.CV] UPDATED)</h2>
<h3>Weipeng Xu, Hongcheng Huang, Shaoyou Pan</h3>
<p>The 2D object detection in clean images has been a well studied topic, but
its vulnerability against adversarial attack is still worrying. Existing work
has improved robustness of object detectors by adversarial training, at the
same time, the average precision (AP) on clean images drops significantly. In
this paper, we propose that using feature alignment of intermediate layer can
improve clean AP and robustness in object detection. Further, on the basis of
adversarial training, we present two feature alignment modules:
Knowledge-Distilled Feature Alignment (KDFA) module and Self-Supervised Feature
Alignment (SSFA) module, which can guide the network to generate more effective
features. We conduct extensive experiments on PASCAL VOC and MS-COCO datasets
to verify the effectiveness of our proposed approach. The code of our
experiments is available at https://github.com/grispeut/Feature-Alignment.git.
</p>
<a href="http://arxiv.org/abs/2012.04382" target="_blank">arXiv:2012.04382</a> [<a href="http://arxiv.org/pdf/2012.04382" target="_blank">pdf</a>]

<h2>Methodology for Mining, Discovering and Analyzing Semantic Human Mobility Behaviors. (arXiv:2012.04767v2 [cs.LG] UPDATED)</h2>
<h3>Clement Moreau, Thomas Devogele, Laurent Etienne, Veronika Peralta, Cyril de Runz</h3>
<p>Various institutes produce large semantic datasets containing information
regarding daily activities and human mobility. The analysis and understanding
of such data are crucial for urban planning, socio-psychology, political
sciences, and epidemiology. However, none of the typical data mining processes
have been customized for the thorough analysis of semantic mobility sequences
to translate data into understandable behaviors. Based on an extended
literature review, we propose a novel methodological pipeline called simba
(Semantic Indicators for Mobility and Behavior Analysis), for mining and
analyzing semantic mobility sequences to identify coherent information and
human behaviors. A framework for semantic sequence mobility analysis and
clustering explicability based on integrating different complementary
statistical indicators and visual tools is implemented. To validate this
methodology, we used a large set of real daily mobility sequences obtained from
a household travel survey. Complementary knowledge is automatically discovered
in the proposed method.
</p>
<a href="http://arxiv.org/abs/2012.04767" target="_blank">arXiv:2012.04767</a> [<a href="http://arxiv.org/pdf/2012.04767" target="_blank">pdf</a>]

<h2>On the emergence of tetrahedral symmetry in the final and penultimate layers of neural network classifiers. (arXiv:2012.05420v2 [cs.LG] UPDATED)</h2>
<h3>Weinan E, Stephan Wojtowytsch</h3>
<p>A recent numerical study observed that neural network classifiers enjoy a
large degree of symmetry in the penultimate layer. Namely, if $h(x) = Af(x) +b$
where $A$ is a linear map and $f$ is the output of the penultimate layer of the
network (after activation), then all data points $x_{i, 1}, \dots, x_{i, N_i}$
in a class $C_i$ are mapped to a single point $y_i$ by $f$ and the points $y_i$
are located at the vertices of a regular $k-1$-dimensional tetrahedron in a
high-dimensional Euclidean space.

We explain this observation analytically in toy models for highly expressive
deep neural networks. In complementary examples, we demonstrate rigorously that
even the final output of the classifier $h$ is not uniform over data samples
from a class $C_i$ if $h$ is a shallow network (or if the deeper layers do not
bring the data samples into a convenient geometric configuration).
</p>
<a href="http://arxiv.org/abs/2012.05420" target="_blank">arXiv:2012.05420</a> [<a href="http://arxiv.org/pdf/2012.05420" target="_blank">pdf</a>]

<h2>Communication-Computation Efficient Secure Aggregation for Federated Learning. (arXiv:2012.05433v2 [cs.LG] UPDATED)</h2>
<h3>Beongjun Choi, Jy-yong Sohn, Dong-Jun Han, Jaekyun Moon</h3>
<p>Federated learning has been spotlighted as a way to train neural networks
using data distributed over multiple nodes without the need for the nodes to
share data. Unfortunately, it has also been shown that data privacy could not
be fully guaranteed as adversaries may be able to extract certain information
on local data from the model parameters transmitted during federated learning.
A recent solution based on the secure aggregation primitive enabled
privacy-preserving federated learning, but at the expense of significant extra
communication/computational resources. In this paper, we propose
communication-computation efficient secure aggregation which substantially
reduces the amount of communication/computational resources relative to the
existing secure solution without sacrificing data privacy. The key idea behind
the suggested scheme is to design the topology of the secret-sharing nodes as
sparse random graphs instead of the complete graph corresponding to the
existing solution. We first obtain the necessary and sufficient condition on
the graph to guarantee reliable and private federated learning in the
information-theoretic sense. We then suggest using the Erd\H{o}s-R\'enyi graph
in particular and provide theoretical guarantees on the reliability/privacy of
the proposed scheme. Through extensive real-world experiments, we demonstrate
that our scheme, using only $20 \sim 30\%$ of the resources required in the
conventional scheme, maintains virtually the same levels of reliability and
data privacy in practical federated learning systems.
</p>
<a href="http://arxiv.org/abs/2012.05433" target="_blank">arXiv:2012.05433</a> [<a href="http://arxiv.org/pdf/2012.05433" target="_blank">pdf</a>]

<h2>Amodal Segmentation Based on Visible Region Segmentation and Shape Prior. (arXiv:2012.05598v2 [cs.CV] UPDATED)</h2>
<h3>Yuting Xiao, Yanyu Xu, Ziming Zhong, Weixin Luo, Jiawei Li, Shenghua Gao</h3>
<p>Almost all existing amodal segmentation methods make the inferences of
occluded regions by using features corresponding to the whole image. This is
against the human's amodal perception, where human uses the visible part and
the shape prior knowledge of the target to infer the occluded region. To mimic
the behavior of human and solve the ambiguity in the learning, we propose a
framework, it firstly estimates a coarse visible mask and a coarse amodal mask.
Then based on the coarse prediction, our model infers the amodal mask by
concentrating on the visible region and utilizing the shape prior in the
memory. In this way, features corresponding to background and occlusion can be
suppressed for amodal mask estimation. Consequently, the amodal mask would not
be affected by what the occlusion is given the same visible regions. The
leverage of shape prior makes the amodal mask estimation more robust and
reasonable. Our proposed model is evaluated on three datasets. Experiments show
that our proposed model outperforms existing state-of-the-art methods. The
visualization of shape prior indicates that the category-specific feature in
the codebook has certain interpretability.
</p>
<a href="http://arxiv.org/abs/2012.05598" target="_blank">arXiv:2012.05598</a> [<a href="http://arxiv.org/pdf/2012.05598" target="_blank">pdf</a>]

<h2>Certifying Incremental Quadratic Constraints for Neural Networks via Convex Optimization. (arXiv:2012.05981v2 [cs.LG] UPDATED)</h2>
<h3>Navid Hashemi, Justin Ruths, Mahyar Fazlyab</h3>
<p>Abstracting neural networks with constraints they impose on their inputs and
outputs can be very useful in the analysis of neural network classifiers and to
derive optimization-based algorithms for certification of stability and
robustness of feedback systems involving neural networks. In this paper, we
propose a convex program, in the form of a Linear Matrix Inequality (LMI), to
certify incremental quadratic constraints on the map of neural networks over a
region of interest. These certificates can capture several useful properties
such as (local) Lipschitz continuity, one-sided Lipschitz continuity,
invertibility, and contraction. We illustrate the utility of our approach in
two different settings. First, we develop a semidefinite program to compute
guaranteed and sharp upper bounds on the local Lipschitz constant of neural
networks and illustrate the results on random networks as well as networks
trained on MNIST. Second, we consider a linear time-invariant system in
feedback with an approximate model predictive controller parameterized by a
neural network. We then turn the stability analysis into a semidefinite
feasibility program and estimate an ellipsoidal invariant set for the
closed-loop system.
</p>
<a href="http://arxiv.org/abs/2012.05981" target="_blank">arXiv:2012.05981</a> [<a href="http://arxiv.org/pdf/2012.05981" target="_blank">pdf</a>]

<h2>Data-based Discovery of Governing Equations. (arXiv:2012.06036v2 [cs.LG] UPDATED)</h2>
<h3>Waad Subber, Piyush Pandita, Sayan Ghosh, Genghis Khan, Liping Wang, Roger Ghanem</h3>
<p>Most common mechanistic models are traditionally presented in mathematical
forms to explain a given physical phenomenon. Machine learning algorithms, on
the other hand, provide a mechanism to map the input data to output without
explicitly describing the underlying physical process that generated the data.
We propose a Data-based Physics Discovery (DPD) framework for automatic
discovery of governing equations from observed data. Without a prior definition
of the model structure, first a free-form of the equation is discovered, and
then calibrated and validated against the available data. In addition to the
observed data, the DPD framework can utilize available prior physical models,
and domain expert feedback. When prior models are available, the DPD framework
can discover an additive or multiplicative correction term represented
symbolically. The correction term can be a function of the existing input
variable to the prior model, or a newly introduced variable. In case a prior
model is not available, the DPD framework discovers a new data-based standalone
model governing the observations. We demonstrate the performance of the
proposed framework on a real-world application in the aerospace industry.
</p>
<a href="http://arxiv.org/abs/2012.06036" target="_blank">arXiv:2012.06036</a> [<a href="http://arxiv.org/pdf/2012.06036" target="_blank">pdf</a>]

<h2>OpenHoldem: An Open Toolkit for Large-Scale Imperfect-Information Game Research. (arXiv:2012.06168v2 [cs.LG] UPDATED)</h2>
<h3>Kai Li, Hang Xu, Meng Zhang, Enmin Zhao, Zhe Wu, Junliang Xing, Kaiqi Huang</h3>
<p>Owning to the unremitting efforts by a few institutes, significant progress
has recently been made in designing superhuman AIs in No-limit Texas Hold'em
(NLTH), the primary testbed for large-scale imperfect-information game
research. However, it remains challenging for new researchers to study this
problem since there are no standard benchmarks for comparing with existing
methods, which seriously hinders further developments in this research area. In
this work, we present OpenHoldem, an integrated toolkit for large-scale
imperfect-information game research using NLTH. OpenHoldem makes three main
contributions to this research direction: 1) a standardized evaluation protocol
for thoroughly evaluating different NLTH AIs, 2) three publicly available
strong baselines for NLTH AI, and 3) an online testing platform with
easy-to-use APIs for public NLTH AI evaluation. We have released OpenHoldem at
this http URL, hoping it facilitates further studies on the unsolved
theoretical and computational issues in this area and cultivate crucial
research problems like opponent modeling, large-scale equilibrium-finding, and
human-computer interactive learning.
</p>
<a href="http://arxiv.org/abs/2012.06168" target="_blank">arXiv:2012.06168</a> [<a href="http://arxiv.org/pdf/2012.06168" target="_blank">pdf</a>]

<h2>Writer Identification and Writer Retrieval Based on NetVLAD with Re-ranking. (arXiv:2012.06186v2 [cs.CV] UPDATED)</h2>
<h3>Shervin Rasoulzadeh, Bagher Babaali</h3>
<p>This paper addresses writer identification and retrieval which is a
challenging problem in the document analysis field. In this work, a novel
pipeline is proposed for the problem by employing a unified neural network
architecture consisting of the ResNet-20 as a feature extractor and an
integrated NetVLAD layer, inspired by the vectors of locally aggregated
descriptors (VLAD), in the head of the latter part. Having defined this
architecture, triplet semi-hard loss function is used to directly learn an
embedding for individual input image patches. Generalised max-pooling is used
for the aggregation of embedded descriptors of each handwritten image. In the
evaluation part, for identification and retrieval, re-ranking has been done
based on query expansion and $k$-reciprocal nearest neighbours, and it is shown
that the pipeline can benefit tremendously from this step. Experimental
evaluation shows that our writer identification and writer retrieval pipeline
is superior compared to the state-of-the-art pipelines, as our results on the
publicly available ICDAR13 and CVL datasets set new standards by achieving
96.5% and 98.4% mAP, respectively.
</p>
<a href="http://arxiv.org/abs/2012.06186" target="_blank">arXiv:2012.06186</a> [<a href="http://arxiv.org/pdf/2012.06186" target="_blank">pdf</a>]

<h2>Self-Growing Spatial Graph Network for Context-Aware Pedestrian Trajectory Prediction. (arXiv:2012.06320v2 [cs.CV] UPDATED)</h2>
<h3>Sirin Haddad, Siew-Kei Lam</h3>
<p>Pedestrian trajectory prediction is an active research area with recent works
undertaken to embed accurate models of pedestrians social interactions and
their contextual compliance into dynamic spatial graphs. However, existing
works rely on spatial assumptions about the scene and dynamics, which entails a
significant challenge to adapt the graph structure in unknown environments for
an online system. In addition, there is a lack of assessment approach for the
relational modeling impact on prediction performance. To fill this gap, we
propose Social Trajectory Recommender-Gated Graph Recurrent Neighborhood
Network, (STR-GGRNN), which uses data-driven adaptive online neighborhood
recommendation based on the contextual scene features and pedestrian visual
cues. The neighborhood recommendation is achieved by online Nonnegative Matrix
Factorization (NMF) to construct the graph adjacency matrices for predicting
the pedestrians' trajectories. Experiments based on widely-used datasets show
that our method outperforms the state-of-the-art. Our best performing model
achieves 12 cm ADE and $\sim$15 cm FDE on ETH-UCY dataset. The proposed method
takes only 0.49 seconds when sampling a total of 20K future trajectories per
frame.
</p>
<a href="http://arxiv.org/abs/2012.06320" target="_blank">arXiv:2012.06320</a> [<a href="http://arxiv.org/pdf/2012.06320" target="_blank">pdf</a>]

<h2>Bayesian Neural Ordinary Differential Equations. (arXiv:2012.07244v2 [cs.LG] UPDATED)</h2>
<h3>Raj Dandekar, Vaibhav Dixit, Mohamed Tarek, Aslan Garcia-Valadez, Chris Rackauckas</h3>
<p>Recently, Neural Ordinary Differential Equations has emerged as a powerful
framework for modeling physical simulations without explicitly defining the
ODEs governing the system, but learning them via machine learning. However, the
question: Can Bayesian learning frameworks be integrated with Neural ODEs to
robustly quantify the uncertainty in the weights of a Neural ODE? remains
unanswered. In an effort to address this question, we demonstrate the
successful integration of Neural ODEs with two methods of Bayesian Inference:
(a) The No-U-Turn MCMC sampler (NUTS) and (b) Stochastic Langevin Gradient
Descent (SGLD). We test the performance of our Bayesian Neural ODE approach on
classical physical systems, as well as on standard machine learning datasets
like MNIST, using GPU acceleration. Finally, considering a simple example, we
demonstrate the probabilistic identification of model specification in
partially-described dynamical systems using universal ordinary differential
equations. Together, this gives a scientific machine learning tool for
probabilistic estimation of epistemic uncertainties.
</p>
<a href="http://arxiv.org/abs/2012.07244" target="_blank">arXiv:2012.07244</a> [<a href="http://arxiv.org/pdf/2012.07244" target="_blank">pdf</a>]

<h2>Disentangled Information Bottleneck. (arXiv:2012.07372v2 [cs.LG] UPDATED)</h2>
<h3>Ziqi Pan, Li Niu, Jianfu Zhang, Liqing Zhang</h3>
<p>The information bottleneck (IB) method is a technique for extracting
information that is relevant for predicting the target random variable from the
source random variable, which is typically implemented by optimizing the IB
Lagrangian that balances the compression and prediction terms. However, the IB
Lagrangian is hard to optimize, and multiple trials for tuning values of
Lagrangian multiplier are required. Moreover, we show that the prediction
performance strictly decreases as the compression gets stronger during
optimizing the IB Lagrangian. In this paper, we implement the IB method from
the perspective of supervised disentangling. Specifically, we introduce
Disentangled Information Bottleneck (DisenIB) that is consistent on compressing
source maximally without target prediction performance loss (maximum
compression). Theoretical and experimental results demonstrate that our method
is consistent on maximum compression, and performs well in terms of
generalization, robustness to adversarial attack, out-of-distribution
detection, and supervised disentangling.
</p>
<a href="http://arxiv.org/abs/2012.07372" target="_blank">arXiv:2012.07372</a> [<a href="http://arxiv.org/pdf/2012.07372" target="_blank">pdf</a>]

<h2>A review of on-device fully neural end-to-end automatic speech recognition algorithms. (arXiv:2012.07974v2 [cs.LG] UPDATED)</h2>
<h3>Chanwoo Kim, Dhananjaya Gowda, Dongsoo Lee, Jiyeon Kim, Ankur Kumar, Sungsoo Kim, Abhinav Garg, Changwoo Han</h3>
<p>In this paper, we review various end-to-end automatic speech recognition
algorithms and their optimization techniques for on-device applications.
Conventional speech recognition systems comprise a large number of discrete
components such as an acoustic model, a language model, a pronunciation model,
a text-normalizer, an inverse-text normalizer, a decoder based on a Weighted
Finite State Transducer (WFST), and so on. To obtain sufficiently high speech
recognition accuracy with such conventional speech recognition systems, a very
large language model (up to 100 GB) is usually needed. Hence, the corresponding
WFST size becomes enormous, which prohibits their on-device implementation.
Recently, fully neural network end-to-end speech recognition algorithms have
been proposed. Examples include speech recognition systems based on
Connectionist Temporal Classification (CTC), Recurrent Neural Network
Transducer (RNN-T), Attention-based Encoder-Decoder models (AED), Monotonic
Chunk-wise Attention (MoChA), transformer-based speech recognition systems, and
so on. These fully neural network-based systems require much smaller memory
footprints compared to conventional algorithms, therefore their on-device
implementation has become feasible. In this paper, we review such end-to-end
speech recognition models. We extensively discuss their structures,
performance, and advantages compared to conventional algorithms.
</p>
<a href="http://arxiv.org/abs/2012.07974" target="_blank">arXiv:2012.07974</a> [<a href="http://arxiv.org/pdf/2012.07974" target="_blank">pdf</a>]

<h2>Bayesian neural network with pretrained protein embedding enhances prediction accuracy of drug-protein interaction. (arXiv:2012.08194v2 [cs.LG] UPDATED)</h2>
<h3>QHwan Kim, Joon-Hyuk Ko, Sunghoon Kim, Nojun Park, Wonho Jhe</h3>
<p>The characterization of drug-protein interactions is crucial in the
high-throughput screening for drug discovery. The deep learning-based
approaches have attracted attention because they can predict drug-protein
interactions without trial-and-error by humans. However, because data labeling
requires significant resources, the available protein data size is relatively
small, which consequently decreases model performance. Here we propose two
methods to construct a deep learning framework that exhibits superior
performance with a small labeled dataset. At first, we use transfer learning in
encoding protein sequences with a pretrained model, which trains general
sequence representations in an unsupervised manner. Second, we use a Bayesian
neural network to make a robust model by estimating the data uncertainty. As a
result, our model performs better than the previous baselines for predicting
drug-protein interactions. We also show that the quantified uncertainty from
the Bayesian inference is related to the confidence and can be used for
screening DPI data points.
</p>
<a href="http://arxiv.org/abs/2012.08194" target="_blank">arXiv:2012.08194</a> [<a href="http://arxiv.org/pdf/2012.08194" target="_blank">pdf</a>]

<h2>Accelerating Distributed Online Meta-Learning via Multi-Agent Collaboration under Limited Communication. (arXiv:2012.08660v2 [cs.LG] UPDATED)</h2>
<h3>Sen Lin, Mehmet Dedeoglu, Junshan Zhang</h3>
<p>Online meta-learning is emerging as an enabling technique for achieving edge
intelligence in the IoT ecosystem. Nevertheless, to learn a good meta-model for
within-task fast adaptation, a single agent alone has to learn over many tasks,
and this is the so-called 'cold-start' problem. Observing that in a multi-agent
network the learning tasks across different agents often share some model
similarity, we ask the following fundamental question: "Is it possible to
accelerate the online meta-learning across agents via limited communication and
if yes how much benefit can be achieved? " To answer this question, we propose
a multi-agent online meta-learning framework and cast it as an equivalent
two-level nested online convex optimization (OCO) problem. By characterizing
the upper bound of the agent-task-averaged regret, we show that the performance
of multi-agent online meta-learning depends heavily on how much an agent can
benefit from the distributed network-level OCO for meta-model updates via
limited communication, which however is not well understood. To tackle this
challenge, we devise a distributed online gradient descent algorithm with
gradient tracking where each agent tracks the global gradient using only one
communication step with its neighbors per iteration, and it results in an
average regret $O(\sqrt{T/N})$ per agent, indicating that a factor of
$\sqrt{1/N}$ speedup over the optimal single-agent regret $O(\sqrt{T})$ after
$T$ iterations, where $N$ is the number of agents. Building on this sharp
performance speedup, we next develop a multi-agent online meta-learning
algorithm and show that it can achieve the optimal task-average regret at a
faster rate of $O(1/\sqrt{NT})$ via limited communication, compared to
single-agent online meta-learning. Extensive experiments corroborate the
theoretic results.
</p>
<a href="http://arxiv.org/abs/2012.08660" target="_blank">arXiv:2012.08660</a> [<a href="http://arxiv.org/pdf/2012.08660" target="_blank">pdf</a>]

<h2>Inexact-ADMM Based Federated Meta-Learning for Fast and Continual Edge Learning. (arXiv:2012.08677v2 [cs.LG] UPDATED)</h2>
<h3>Sheng Yue, Ju Ren, Jiang Xin, Sen Lin, Junshan Zhang</h3>
<p>In order to meet the requirements for performance, safety, and latency in
many IoT applications, intelligent decisions must be made right here right now
at the network edge. However, the constrained resources and limited local data
amount pose significant challenges to the development of edge AI. To overcome
these challenges, we explore continual edge learning capable of leveraging the
knowledge transfer from previous tasks. Aiming to achieve fast and continual
edge learning, we propose a platform-aided federated meta-learning architecture
where edge nodes collaboratively learn a meta-model, aided by the knowledge
transfer from prior tasks. The edge learning problem is cast as a regularized
optimization problem, where the valuable knowledge learned from previous tasks
is extracted as regularization. Then, we devise an ADMM based federated
meta-learning algorithm, namely ADMM-FedMeta, where ADMM offers a natural
mechanism to decompose the original problem into many subproblems which can be
solved in parallel across edge nodes and the platform. Further, a variant of
inexact-ADMM method is employed where the subproblems are `solved' via linear
approximation as well as Hessian estimation to reduce the computational cost
per round to $\mathcal{O}(n)$. We provide a comprehensive analysis of
ADMM-FedMeta, in terms of the convergence properties, the rapid adaptation
performance, and the forgetting effect of prior knowledge transfer, for the
general non-convex case. Extensive experimental studies demonstrate the
effectiveness and efficiency of ADMM-FedMeta, and showcase that it
substantially outperforms the existing baselines.
</p>
<a href="http://arxiv.org/abs/2012.08677" target="_blank">arXiv:2012.08677</a> [<a href="http://arxiv.org/pdf/2012.08677" target="_blank">pdf</a>]

<h2>Characterizing the Evasion Attackability of Multi-label Classifiers. (arXiv:2012.09427v2 [cs.LG] UPDATED)</h2>
<h3>Zhuo Yang, Yufei Han, Xiangliang Zhang</h3>
<p>Evasion attack in multi-label learning systems is an interesting, widely
witnessed, yet rarely explored research topic. Characterizing the crucial
factors determining the attackability of the multi-label adversarial threat is
the key to interpret the origin of the adversarial vulnerability and to
understand how to mitigate it. Our study is inspired by the theory of
adversarial risk bound. We associate the attackability of a targeted
multi-label classifier with the regularity of the classifier and the training
data distribution. Beyond the theoretical attackability analysis, we further
propose an efficient empirical attackability estimator via greedy label space
exploration. It provides provably computational efficiency and approximation
accuracy. Substantial experimental results on real-world datasets validate the
unveiled attackability factors and the effectiveness of the proposed empirical
attackability indicator
</p>
<a href="http://arxiv.org/abs/2012.09427" target="_blank">arXiv:2012.09427</a> [<a href="http://arxiv.org/pdf/2012.09427" target="_blank">pdf</a>]

<h2>Learning and Sharing: A Multitask Genetic Programming Approach to Image Feature Learning. (arXiv:2012.09444v2 [cs.CV] UPDATED)</h2>
<h3>Ying Bi, Bing Xue, Mengjie Zhang</h3>
<p>Using evolutionary computation algorithms to solve multiple tasks with
knowledge sharing is a promising approach. Image feature learning can be
considered as a multitask problem because different tasks may have a similar
feature space. Genetic programming (GP) has been successfully applied to image
feature learning for classification. However, most of the existing GP methods
solve one task, independently, using sufficient training data. No multitask GP
method has been developed for image feature learning. Therefore, this paper
develops a multitask GP approach to image feature learning for classification
with limited training data. Owing to the flexible representation of GP, a new
knowledge sharing mechanism based on a new individual representation is
developed to allow GP to automatically learn what to share across two tasks and
to improve its learning performance. The shared knowledge is encoded as a
common tree, which can represent the common/general features of two tasks. With
the new individual representation, each task is solved using the features
extracted from a common tree and a task-specific tree representing
task-specific features. To learn the best common and task-specific trees, a new
evolutionary process and new fitness functions are developed. The performance
of the proposed approach is examined on six multitask problems of 12 image
classification datasets with limited training data and compared with three GP
and 14 non-GP-based competitive methods. Experimental results show that the new
approach outperforms these compared methods in almost all the comparisons.
Further analysis reveals that the new approach learns simple yet effective
common trees with high effectiveness and transferability.
</p>
<a href="http://arxiv.org/abs/2012.09444" target="_blank">arXiv:2012.09444</a> [<a href="http://arxiv.org/pdf/2012.09444" target="_blank">pdf</a>]

<h2>Crowd-Driven Mapping, Localization and Planning. (arXiv:2012.10099v2 [cs.RO] UPDATED)</h2>
<h3>Tingxiang Fan, Dawei Wang, Wenxi Liu, Jia Pan</h3>
<p>Navigation in dense crowds is a well-known open problem in robotics with many
challenges in mapping, localization, and planning. Traditional solutions
consider dense pedestrians as passive/active moving obstacles that are the
cause of all troubles: they negatively affect the sensing of static scene
landmarks and must be actively avoided for safety. In this paper, we provide a
new perspective: the crowd flow locally observed can be treated as a sensory
measurement about the surrounding scenario, encoding not only the scene's
traversability but also its social navigation preference. We demonstrate that
even using the crowd-flow measurement alone without any sensing about static
obstacles, our method still accomplishes good results for mapping,
localization, and social-aware planning in dense crowds. Videos of the
experiments are available at https://sites.google.com/view/crowdmapping.
</p>
<a href="http://arxiv.org/abs/2012.10099" target="_blank">arXiv:2012.10099</a> [<a href="http://arxiv.org/pdf/2012.10099" target="_blank">pdf</a>]

<h2>PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object Detection. (arXiv:2012.10412v2 [cs.CV] UPDATED)</h2>
<h3>Yanan Zhang, Di Huang, Yunhong Wang</h3>
<p>LiDAR-based 3D object detection is an important task for autonomous driving
and current approaches suffer from sparse and partial point clouds of distant
and occluded objects. In this paper, we propose a novel two-stage approach,
namely PC-RGNN, dealing with such challenges by two specific solutions. On the
one hand, we introduce a point cloud completion module to recover high-quality
proposals of dense points and entire views with original structures preserved.
On the other hand, a graph neural network module is designed, which
comprehensively captures relations among points through a local-global
attention mechanism as well as multi-scale graph based context aggregation,
substantially strengthening encoded features. Extensive experiments on the
KITTI benchmark show that the proposed approach outperforms the previous
state-of-the-art baselines by remarkable margins, highlighting its
effectiveness.
</p>
<a href="http://arxiv.org/abs/2012.10412" target="_blank">arXiv:2012.10412</a> [<a href="http://arxiv.org/pdf/2012.10412" target="_blank">pdf</a>]

<h2>Zeroth-Order Hybrid Gradient Descent: Towards A Principled Black-Box Optimization Framework. (arXiv:2012.11518v1 [stat.ML])</h2>
<h3>Pranay Sharma, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Xue Lin, Pramod K. Varshney</h3>
<p>In this work, we focus on the study of stochastic zeroth-order (ZO)
optimization which does not require first-order gradient information and uses
only function evaluations. The problem of ZO optimization has emerged in many
recent machine learning applications, where the gradient of the objective
function is either unavailable or difficult to compute. In such cases, we can
approximate the full gradients or stochastic gradients through function value
based gradient estimates. Here, we propose a novel hybrid gradient estimator
(HGE), which takes advantage of the query-efficiency of random gradient
estimates as well as the variance-reduction of coordinate-wise gradient
estimates. We show that with a graceful design in coordinate importance
sampling, the proposed HGE-based ZO optimization method is efficient both in
terms of iteration complexity as well as function query cost. We provide a
thorough theoretical analysis of the convergence of our proposed method for
non-convex, convex, and strongly-convex optimization. We show that the
convergence rate that we derive generalizes the results for some prominent
existing methods in the nonconvex case, and matches the optimal result in the
convex case. We also corroborate the theory with a real-world black-box attack
generation application to demonstrate the empirical advantage of our method
over state-of-the-art ZO optimization approaches.
</p>
<a href="http://arxiv.org/abs/2012.11518" target="_blank">arXiv:2012.11518</a> [<a href="http://arxiv.org/pdf/2012.11518" target="_blank">pdf</a>]

<h2>Variational Transport: A Convergent Particle-BasedAlgorithm for Distributional Optimization. (arXiv:2012.11554v1 [cs.LG])</h2>
<h3>Zhuoran Yang, Yufeng Zhang, Yongxin Chen, Zhaoran Wang</h3>
<p>We consider the optimization problem of minimizing a functional defined over
a family of probability distributions, where the objective functional is
assumed to possess a variational form. Such a distributional optimization
problem arises widely in machine learning and statistics, with Monte-Carlo
sampling, variational inference, policy optimization, and generative
adversarial network as examples. For this problem, we propose a novel
particle-based algorithm, dubbed as variational transport, which approximately
performs Wasserstein gradient descent over the manifold of probability
distributions via iteratively pushing a set of particles. Specifically, we
prove that moving along the geodesic in the direction of functional gradient
with respect to the second-order Wasserstein distance is equivalent to applying
a pushforward mapping to a probability distribution, which can be approximated
accurately by pushing a set of particles. Specifically, in each iteration of
variational transport, we first solve the variational problem associated with
the objective functional using the particles, whose solution yields the
Wasserstein gradient direction. Then we update the current distribution by
pushing each particle along the direction specified by such a solution. By
characterizing both the statistical error incurred in estimating the
Wasserstein gradient and the progress of the optimization algorithm, we prove
that when the objective function satisfies a functional version of the
Polyak-\L{}ojasiewicz (PL) (Polyak, 1963) and smoothness conditions,
variational transport converges linearly to the global minimum of the objective
functional up to a certain statistical error, which decays to zero sublinearly
as the number of particles goes to infinity.
</p>
<a href="http://arxiv.org/abs/2012.11554" target="_blank">arXiv:2012.11554</a> [<a href="http://arxiv.org/pdf/2012.11554" target="_blank">pdf</a>]

