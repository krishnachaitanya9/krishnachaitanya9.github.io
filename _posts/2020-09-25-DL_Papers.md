---
title: Latest Deep Learning Papers
date: 2021-02-22 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (264 Articles)</h1>
<h2>Image Classification using CNN for Traffic Signs in Pakistan. (arXiv:2102.10130v1 [cs.CV])</h2>
<h3>Abdul Azeem Sikander, Hamza Ali</h3>
<p>The autonomous automotive industry is one of the largest and most
conventional projects worldwide, with many technology companies effectively
designing and orienting their products towards automobile safety and accuracy.
These products are performing very well over the roads in developed countries.
But can fail in the first minute in an underdeveloped country because there is
much difference between a developed country environment and an underdeveloped
country environment. The following study proposed to train these Artificial
intelligence models in environment space in an underdeveloped country like
Pakistan. The proposed approach on image classification uses convolutional
neural networks for image classification for the model. For model pre-training
German traffic signs data set was selected then fine-tuned on Pakistan's
dataset. The experimental setup showed the best results and accuracy from the
previously conducted experiments. In this work to increase the accuracy, more
dataset was collected to increase the size of images in every class in the data
set. In the future, a low number of classes are required to be further
increased where more images for traffic signs are required to be collected to
get more accuracy on the training of the model over traffic signs of Pakistan's
most used and popular roads motorway and national highway, whose traffic signs
color, size, and shapes are different from common traffic signs.
</p>
<a href="http://arxiv.org/abs/2102.10130" target="_blank">arXiv:2102.10130</a> [<a href="http://arxiv.org/pdf/2102.10130" target="_blank">pdf</a>]

<h2>Efficient approximation of DNA hybridisation using deep learning. (arXiv:2102.10131v1 [cs.LG])</h2>
<h3>David Buterez</h3>
<p>Deoxyribonucleic acid (DNA) has shown great promise in enabling computational
applications, most notably in the fields of DNA data storage and DNA computing.
The former exploits the natural properties of DNA, such as high storage density
and longevity, for the archival of digital information, while the latter aims
to use the interactivity of DNA to encode computations. Recently, the two
paradigms were jointly used to formulate the near-data processing concept for
DNA databases, where the computations are performed directly on the stored
data. The fundamental, low-level operation that DNA naturally possesses is that
of hybridisation, also called annealing, of complementary sequences.
Information is encoded as DNA strands, which will naturally bind in solution,
thus enabling search and pattern-matching capabilities. Being able to control
and predict the process of hybridisation is crucial for the ambitious future of
the so-called Hybrid Molecular-Electronic Computing. Current tools are,
however, limited in terms of throughput and applicability to large-scale
problems.

In this work, we present the first comprehensive study of machine learning
methods applied to the task of predicting DNA hybridisation. For this purpose,
we introduce a synthetic hybridisation dataset of over 2.5 million data points,
enabling the use of a wide range of machine learning algorithms, including the
latest in deep learning. Depending on the hardware, the proposed models provide
a reduction in inference time ranging from one to over two orders of magnitude
compared to the state-of-the-art, while retaining high fidelity. We then
discuss the integration of our methods in modern, scalable workflows. The
implementation is available at:
https://github.com/davidbuterez/dna-hyb-deep-learning
</p>
<a href="http://arxiv.org/abs/2102.10131" target="_blank">arXiv:2102.10131</a> [<a href="http://arxiv.org/pdf/2102.10131" target="_blank">pdf</a>]

<h2>BPLight-CNN: A Photonics-based Backpropagation Accelerator for Deep Learning. (arXiv:2102.10140v1 [cs.LG])</h2>
<h3>D. Dang, S. V. R. Chittamuru, S. Pasricha, R. Mahapatra, D. Sahoo</h3>
<p>Training deep learning networks involves continuous weight updates across the
various layers of the deep network while using a backpropagation algorithm
(BP). This results in expensive computation overheads during training.
Consequently, most deep learning accelerators today employ pre-trained weights
and focus only on improving the design of the inference phase. The recent trend
is to build a complete deep learning accelerator by incorporating the training
module. Such efforts require an ultra-fast chip architecture for executing the
BP algorithm. In this article, we propose a novel photonics-based
backpropagation accelerator for high performance deep learning training. We
present the design for a convolutional neural network, BPLight-CNN, which
incorporates the silicon photonics-based backpropagation accelerator.
BPLight-CNN is a first-of-its-kind photonic and memristor-based CNN
architecture for end-to-end training and prediction. We evaluate BPLight-CNN
using a photonic CAD framework (IPKISS) on deep learning benchmark models
including LeNet and VGG-Net. The proposed design achieves (i) at least 34x
speedup, 34x improvement in computational efficiency, and 38.5x energy savings,
during training; and (ii) 29x speedup, 31x improvement in computational
efficiency, and 38.7x improvement in energy savings, during inference compared
to the state-of-the-art designs. All these comparisons are done at a 16-bit
resolution; and BPLight-CNN achieves these improvements at a cost of
approximately 6% lower accuracy compared to the state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.10140" target="_blank">arXiv:2102.10140</a> [<a href="http://arxiv.org/pdf/2102.10140" target="_blank">pdf</a>]

<h2>A theory of capacity and sparse neural encoding. (arXiv:2102.10148v1 [cs.LG])</h2>
<h3>Pierre Baldi, Roman Vershynin</h3>
<p>Motivated by biological considerations, we study sparse neural maps from an
input layer to a target layer with sparse activity, and specifically the
problem of storing $K$ input-target associations $(x,y)$, or memories, when the
target vectors $y$ are sparse. We mathematically prove that $K$ undergoes a
phase transition and that in general, and somewhat paradoxically, sparsity in
the target layers increases the storage capacity of the map. The target vectors
can be chosen arbitrarily, including in random fashion, and the memories can be
both encoded and decoded by networks trained using local learning rules,
including the simple Hebb rule. These results are robust under a variety of
statistical assumptions on the data. The proofs rely on elegant properties of
random polytopes and sub-gaussian random vector variables. Open problems and
connections to capacity theories and polynomial threshold maps are discussed.
</p>
<a href="http://arxiv.org/abs/2102.10148" target="_blank">arXiv:2102.10148</a> [<a href="http://arxiv.org/pdf/2102.10148" target="_blank">pdf</a>]

<h2>Conditional Adversarial Networks for Multi-Domain Text Classification. (arXiv:2102.10176v1 [cs.LG])</h2>
<h3>Yuan Wu, Diana Inkpen, Ahmed El-Roby</h3>
<p>In this paper, we propose conditional adversarial networks (CANs), a
framework that explores the relationship between the shared features and the
label predictions to impose more discriminability to the shared features, for
multi-domain text classification (MDTC). The proposed CAN introduces a
conditional domain discriminator to model the domain variance in both shared
feature representations and class-aware information simultaneously and adopts
entropy conditioning to guarantee the transferability of the shared features.
We provide theoretical analysis for the CAN framework, showing that CAN's
objective is equivalent to minimizing the total divergence among multiple joint
distributions of shared features and label predictions. Therefore, CAN is a
theoretically sound adversarial network that discriminates over multiple
distributions. Evaluation results on two MDTC benchmarks show that CAN
outperforms prior methods. Further experiments demonstrate that CAN has a good
ability to generalize learned knowledge to unseen domains.
</p>
<a href="http://arxiv.org/abs/2102.10176" target="_blank">arXiv:2102.10176</a> [<a href="http://arxiv.org/pdf/2102.10176" target="_blank">pdf</a>]

<h2>Adaptable Deformable Convolutions for Semantic Segmentation of Fisheye Images in Autonomous Driving Systems. (arXiv:2102.10191v1 [cs.CV])</h2>
<h3>Cl&#xe9;ment Playout, Ola Ahmad, Freddy Lecue, Farida Cheriet</h3>
<p>Advanced Driver-Assistance Systems rely heavily on perception tasks such as
semantic segmentation where images are captured from large field of view (FoV)
cameras. State-of-the-art works have made considerable progress toward applying
Convolutional Neural Network (CNN) to standard (rectilinear) images. However,
the large FoV cameras used in autonomous vehicles produce fisheye images
characterized by strong geometric distortion. This work demonstrates that a CNN
trained on standard images can be readily adapted to fisheye images, which is
crucial in real-world applications where time-consuming real-time data
transformation must be avoided. Our adaptation protocol mainly relies on
modifying the support of the convolutions by using their deformable equivalents
on top of pre-existing layers. We prove that tuning an optimal support only
requires a limited amount of labeled fisheye images, as a small number of
training samples is sufficient to significantly improve an existing model's
performance on wide-angle images. Furthermore, we show that finetuning the
weights of the network is not necessary to achieve high performance once the
deformable components are learned. Finally, we provide an in-depth analysis of
the effect of the deformable convolutions, bringing elements of discussion on
the behavior of CNN models.
</p>
<a href="http://arxiv.org/abs/2102.10191" target="_blank">arXiv:2102.10191</a> [<a href="http://arxiv.org/pdf/2102.10191" target="_blank">pdf</a>]

<h2>A High Performance, Low Complexity Algorithm for Multi-Player Bandits Without Collision Sensing Information. (arXiv:2102.10200v1 [cs.LG])</h2>
<h3>Cindy Trinh, Richard Combes</h3>
<p>Motivated by applications in cognitive radio networks, we consider the
decentralized multi-player multi-armed bandit problem, without collision nor
sensing information. We propose Randomized Selfish KL-UCB, an algorithm with
very low computational complexity, inspired by the Selfish KL-UCB algorithm,
which has been abandoned as it provably performs sub-optimally in some cases.
We subject Randomized Selfish KL-UCB to extensive numerical experiments showing
that it far outperforms state-of-the-art algorithms in almost all environments,
sometimes by several orders of magnitude, and without the additional knowledge
required by state-of-the-art algorithms. We also emphasize the potential of
this algorithm for the more realistic dynamic setting, and support our claims
with further experiments. We believe that the low complexity and high
performance of Randomized Selfish KL-UCB makes it the most suitable for
implementation in practical systems amongst known algorithms.
</p>
<a href="http://arxiv.org/abs/2102.10200" target="_blank">arXiv:2102.10200</a> [<a href="http://arxiv.org/pdf/2102.10200" target="_blank">pdf</a>]

<h2>Camera Calibration with Pose Guidance. (arXiv:2102.10202v1 [cs.CV])</h2>
<h3>Yuzhuo Ren, Feng Hu</h3>
<p>Camera calibration plays a critical role in various computer vision tasks
such as autonomous driving or augmented reality. Widely used camera calibration
tools utilize plane pattern based methodology, such as using a chessboard or
AprilTag board, user's calibration expertise level significantly affects
calibration accuracy and consistency when without clear instruction.
Furthermore, calibration is a recurring task that has to be performed each time
the camera is changed or moved. It's also a great burden to calibrate huge
amounts of cameras such as Driver Monitoring System (DMS) cameras in a
production line with millions of vehicles. To resolve above issues, we propose
a calibration system called Calibration with Pose Guidance to improve
calibration accuracy, reduce calibration variance among different users or
different trials of the same person. Experiment result shows that our proposed
method achieves more accurate and consistent calibration than traditional
calibration tools.
</p>
<a href="http://arxiv.org/abs/2102.10202" target="_blank">arXiv:2102.10202</a> [<a href="http://arxiv.org/pdf/2102.10202" target="_blank">pdf</a>]

<h2>Linear Classifiers in Mixed Constant Curvature Spaces. (arXiv:2102.10204v1 [cs.LG])</h2>
<h3>Puoya Tabaghi, Eli Chien, Chao Pan, Olgica Milenkovi&#x107;</h3>
<p>Embedding methods for mixed-curvature spaces are powerful techniques for
low-distortion and low-dimensional representation of complex data structures.
Nevertheless, little is known regarding downstream learning and optimization in
the embedding space. Here, we address for the first time the problem of linear
classification in a product space form -- a mix of Euclidean, spherical, and
hyperbolic spaces with different dimensions. First, we revisit the definition
of a linear classifier on a Riemannian manifold by using geodesics and
Riemannian metrics which generalize the notions of straight lines and inner
products in vector spaces, respectively. Second, we prove that linear
classifiers in $d$-dimensional constant curvature spaces can shatter exactly
$d+1$ points: Hence, Euclidean, hyperbolic and spherical classifiers have the
same expressive power. Third, we formalize linear classifiers in product space
forms, describe a novel perceptron classification algorithm, and establish
rigorous convergence results. We support our theoretical findings with
simulation results on several datasets, including synthetic data, MNIST and
Omniglot. Our results reveal that learning methods applied to small-dimensional
embeddings in product space forms significantly outperform their algorithmic
counterparts in Euclidean spaces.
</p>
<a href="http://arxiv.org/abs/2102.10204" target="_blank">arXiv:2102.10204</a> [<a href="http://arxiv.org/pdf/2102.10204" target="_blank">pdf</a>]

<h2>Hard-Attention for Scalable Image Classification. (arXiv:2102.10212v1 [cs.CV])</h2>
<h3>Athanasios Papadopoulos, Pawe&#x142; Korus, Nasir Memon</h3>
<p>Deep neural networks (DNNs) are typically optimized for a specific input
resolution (e.g. $224 \times 224$ px) and their adoption to inputs of higher
resolution (e.g., satellite or medical images) remains challenging, as it leads
to excessive computation and memory overhead, and may require substantial
engineering effort (e.g., streaming). We show that multi-scale hard-attention
can be an effective solution to this problem. We propose a novel architecture,
TNet, which traverses an image pyramid in a top-down fashion, visiting only the
most informative regions along the way. We compare our model against strong
hard-attention baselines, achieving a better trade-off between resources and
accuracy on ImageNet. We further verify the efficacy of our model on satellite
images (fMoW dataset) of size up to $896 \times 896$ px. In addition, our
hard-attention mechanism guarantees predictions with a degree of
interpretability, without extra cost beyond inference. We also show that we can
reduce data acquisition and annotation cost, since our model attends only to a
fraction of the highest resolution content, while using only image-level labels
without bounding boxes.
</p>
<a href="http://arxiv.org/abs/2102.10212" target="_blank">arXiv:2102.10212</a> [<a href="http://arxiv.org/pdf/2102.10212" target="_blank">pdf</a>]

<h2>Logarithmic Regret in Feature-based Dynamic Pricing. (arXiv:2102.10221v1 [cs.LG])</h2>
<h3>Jianyu Xu, Yu-xiang Wang (Computer Science Department, UC Santa Barbara)</h3>
<p>Feature-based dynamic pricing is an increasingly popular model of setting
prices for highly differentiated products with applications in digital
marketing, online sales, real estate and so on. The problem was formally
studied as an online learning problem (Cohen et al., 2016; Javanmard &amp;
Nazerzadeh, 2019) where a seller needs to propose prices on the fly for a
sequence of $T$ products based on their features $x$ while having a small
regret relative to the best -- "omniscient" -- pricing strategy she could have
come up with in hindsight. We revisit this problem and provide two algorithms
(EMLP and ONSP) for stochastic and adversarial feature settings, respectively,
and prove the optimal $O(d\log{T})$ regret bounds for both. In comparison, the
best existing results are $O\left(\min\left\{\frac{1}{\lambda_{\min}^2}\log{T},
\sqrt{T}\right\}\right)$ and $O(T^{2/3})$ respectively, with $\lambda_{\min}$
being the smallest eigenvalue of $\mathbb{E}[xx^T]$ that could be arbitrarily
close to $0$. We also prove an $\Omega(\sqrt{T})$ information-theoretic lower
bound for a slightly more general setting, which demonstrates that
"knowing-the-demand-curve" leads to an exponential improvement in feature-based
dynamic pricing.
</p>
<a href="http://arxiv.org/abs/2102.10221" target="_blank">arXiv:2102.10221</a> [<a href="http://arxiv.org/pdf/2102.10221" target="_blank">pdf</a>]

<h2>ALMA: Alternating Minimization Algorithm for Clustering Mixture Multilayer Network. (arXiv:2102.10226v1 [stat.ML])</h2>
<h3>Xing Fan, Marianna Pensky, Feng Yu, Teng Zhang</h3>
<p>The paper considers a Mixture Multilayer Stochastic Block Model (MMLSBM),
where layers can be partitioned into groups of similar networks, and networks
in each group are equipped with a distinct Stochastic Block Model. The goal is
to partition the multilayer network into clusters of similar layers, and to
identify communities in those layers. Jing et al. (2020) introduced the MMLSBM
and developed a clustering methodology, TWIST, based on regularized tensor
decomposition.

The present paper proposes a different technique, an alternating minimization
algorithm (ALMA), that aims at simultaneous recovery of the layer partition,
together with estimation of the matrices of connection probabilities of the
distinct layers. Compared to TWIST, ALMA achieves higher accuracy both
theoretically and numerically.
</p>
<a href="http://arxiv.org/abs/2102.10226" target="_blank">arXiv:2102.10226</a> [<a href="http://arxiv.org/pdf/2102.10226" target="_blank">pdf</a>]

<h2>On Single-User Interactive Beam Alignment in Next Generation Systems: A Deep Learning Viewpoint. (arXiv:2102.10229v1 [cs.LG])</h2>
<h3>Abbas Khalili, Sundeep Rangan, Elza Erkip</h3>
<p>Communication in high frequencies such as millimeter wave and terahertz
suffer from high path-loss and intense shadowing which necessitates beamforming
for reliable data transmission. On the other hand, at high frequencies the
channels are sparse and consist of few spatial clusters. Therefore, beam
alignment (BA) strategies are used to find the direction of these channel
clusters and adjust the width of the beam used for data transmission. In this
work, a single-user uplink scenario where the channel has one dominant cluster
is considered. It is assumed that the user transmits a set of BA packets over a
fixed duration. Meanwhile, the base-station (BS) uses different probing beams
to scan different angular regions. Since the BS measurements are noisy, it is
not possible to find a narrow beam that includes the angle of arrival (AoA) of
the user with probability one. Therefore, the BS allocates a narrow beam to the
user which includes the AoA of the user with a predetermined error probability
while minimizing the expected beamwidth of the allocated beam. Due to
intractability of this noisy BA problem, here this problem is posed as an
end-to-end optimization of a deep neural network (DNN) and effects of different
loss functions are discussed and investigated. It is observed that the proposed
DNN based BA, at high SNRs, achieves a performance close to that of the optimal
BA when there is no-noise and for all SNRs, outperforms state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.10229" target="_blank">arXiv:2102.10229</a> [<a href="http://arxiv.org/pdf/2102.10229" target="_blank">pdf</a>]

<h2>Digger Finger: GelSight Tactile Sensor for Object Identification Inside Granular Media. (arXiv:2102.10230v1 [cs.RO])</h2>
<h3>Radhen Patel, Rui Ouyang, Branden Romero, Edward Adelson</h3>
<p>In this paper we present an early prototype of the Digger Finger that is
designed to easily penetrate granular media and is equipped with the GelSight
sensor. Identifying objects buried in granular media using tactile sensors is a
challenging task. First, particle jamming in granular media prevents downward
movement. Second, the granular media particles tend to get stuck between the
sensing surface and the object of interest, distorting the actual shape of the
object. To tackle these challenges we present a Digger Finger prototype. It is
capable of fluidizing granular media during penetration using mechanical
vibrations. It is equipped with high resolution vision based tactile sensing to
identify objects buried inside granular media. We describe the experimental
procedures we use to evaluate these fluidizing and buried shape recognition
capabilities. A robot with such fingers can perform explosive ordnance disposal
and Improvised Explosive Device (IED) detection tasks at a much a finer
resolution compared to techniques like Ground Penetration Radars (GPRs).
Sensors like the Digger Finger will allow robotic manipulation research to move
beyond only manipulating rigid objects.
</p>
<a href="http://arxiv.org/abs/2102.10230" target="_blank">arXiv:2102.10230</a> [<a href="http://arxiv.org/pdf/2102.10230" target="_blank">pdf</a>]

<h2>Elastic Similarity Measures for Multivariate Time Series Classification. (arXiv:2102.10231v1 [cs.LG])</h2>
<h3>Ahmed Shifaz, Charlotte Pelletier, Francois Petitjean, Geoffrey I. Webb</h3>
<p>Elastic similarity measures are a class of similarity measures specifically
designed to work with time series data. When scoring the similarity between two
time series, they allow points that do not correspond in timestamps to be
aligned. This can compensate for misalignments in the time axis of time series
data, and for similar processes that proceed at variable and differing paces.
Elastic similarity measures are widely used in machine learning tasks such as
classification, clustering and outlier detection when using time series data.

There is a multitude of research on various univariate elastic similarity
measures. However, except for multivariate versions of the well known Dynamic
Time Warping (DTW) there is a lack of work to generalise other similarity
measures for multivariate cases. This paper adapts two existing strategies used
in multivariate DTW, namely, Independent and Dependent DTW, to several commonly
used elastic similarity measures.

Using 23 datasets from the University of East Anglia (UEA) multivariate
archive, for nearest neighbour classification, we demonstrate that each measure
outperforms all others on at least one dataset and that there are datasets for
which either the dependent versions of all measures are more accurate than
their independent counterparts or vice versa. This latter finding suggests that
these differences arise from a fundamental property of the data. We also show
that an ensemble of such nearest neighbour classifiers is highly competitive
with other state-of-the-art multivariate time series classifiers.
</p>
<a href="http://arxiv.org/abs/2102.10231" target="_blank">arXiv:2102.10231</a> [<a href="http://arxiv.org/pdf/2102.10231" target="_blank">pdf</a>]

<h2>Generalization bounds for graph convolutional neural networks via Rademacher complexity. (arXiv:2102.10234v1 [stat.ML])</h2>
<h3>Shaogao Lv</h3>
<p>This paper aims at studying the sample complexity of graph convolutional
networks (GCNs), by providing tight upper bounds of Rademacher complexity for
GCN models with a single hidden layer. Under regularity conditions, theses
derived complexity bounds explicitly depend on the largest eigenvalue of graph
convolution filter and the degree distribution of the graph. Again, we provide
a lower bound of Rademacher complexity for GCNs to show optimality of our
derived upper bounds. Taking two commonly used examples as representatives, we
discuss the implications of our results in designing graph convolution filters
an graph distribution.
</p>
<a href="http://arxiv.org/abs/2102.10234" target="_blank">arXiv:2102.10234</a> [<a href="http://arxiv.org/pdf/2102.10234" target="_blank">pdf</a>]

<h2>Learning Neural Generative Dynamics for Molecular Conformation Generation. (arXiv:2102.10240v1 [cs.LG])</h2>
<h3>Minkai Xu, Shitong Luo, Yoshua Bengio, Jian Peng, Jian Tang</h3>
<p>We study how to generate molecule conformations (\textit{i.e.}, 3D
structures) from a molecular graph. Traditional methods, such as molecular
dynamics, sample conformations via computationally expensive simulations.
Recently, machine learning methods have shown great potential by training on a
large collection of conformation data. Challenges arise from the limited model
capacity for capturing complex distributions of conformations and the
difficulty in modeling long-range dependencies between atoms. Inspired by the
recent progress in deep generative models, in this paper, we propose a novel
probabilistic framework to generate valid and diverse conformations given a
molecular graph. We propose a method combining the advantages of both
flow-based and energy-based models, enjoying: (1) a high model capacity to
estimate the multimodal conformation distribution; (2) explicitly capturing the
complex long-range dependencies between atoms in the observation space.
Extensive experiments demonstrate the superior performance of the proposed
method on several benchmarks, including conformation generation and distance
modeling tasks, with a significant improvement over existing generative models
for molecular conformation sampling.
</p>
<a href="http://arxiv.org/abs/2102.10240" target="_blank">arXiv:2102.10240</a> [<a href="http://arxiv.org/pdf/2102.10240" target="_blank">pdf</a>]

<h2>GMLight: Lighting Estimation via Geometric Distribution Approximation. (arXiv:2102.10244v1 [cs.CV])</h2>
<h3>Fangneng Zhan, Yingchen Yu, Rongliang Wu, Changgong Zhang, Shijian Lu, Ling Shao, Feiying Ma, Xuansong Xie</h3>
<p>Lighting estimation from a single image is an essential yet challenging task
in computer vision and computer graphics. Existing works estimate lighting by
regressing representative illumination parameters or generating illumination
maps directly. However, these methods often suffer from poor accuracy and
generalization. This paper presents Geometric Mover's Light (GMLight), a
lighting estimation framework that employs a regression network and a
generative projector for effective illumination estimation. We parameterize
illumination scenes in terms of the geometric light distribution, light
intensity, ambient term, and auxiliary depth, and estimate them as a pure
regression task. Inspired by the earth mover's distance, we design a novel
geometric mover's loss to guide the accurate regression of light distribution
parameters. With the estimated lighting parameters, the generative projector
synthesizes panoramic illumination maps with realistic appearance and
frequency. Extensive experiments show that GMLight achieves accurate
illumination estimation and superior fidelity in relighting for 3D object
insertion.
</p>
<a href="http://arxiv.org/abs/2102.10244" target="_blank">arXiv:2102.10244</a> [<a href="http://arxiv.org/pdf/2102.10244" target="_blank">pdf</a>]

<h2>Game Mechanic Alignment Theory and Discovery. (arXiv:2102.10247v1 [cs.AI])</h2>
<h3>Michael Cerny Green, Ahmed Khalifa, Philip Bontrager, Rodrigo Canaan, Julian Togelius</h3>
<p>We present a new concept called Game Mechanic Alignment theory as a way to
organize game mechanics through the lens of environmental rewards and intrinsic
player motivations. By disentangling player and environmental influences,
mechanics may be better identified for use in an automated tutorial generation
system, which could tailor tutorials for a particular playstyle or player.
Within, we apply this theory to several well-known games to demonstrate how
designers can benefit from it, we describe a methodology for how to estimate
mechanic alignment, and we apply this methodology on multiple games in the
GVGAI framework. We discuss how effectively this estimation captures
intrinsic/extrinsic rewards and how our theory could be used as an alternative
to critical mechanic discovery methods for tutorial generation.
</p>
<a href="http://arxiv.org/abs/2102.10247" target="_blank">arXiv:2102.10247</a> [<a href="http://arxiv.org/pdf/2102.10247" target="_blank">pdf</a>]

<h2>nTreeClus: a Tree-based Sequence Encoder for Clustering Categorical Series. (arXiv:2102.10252v1 [cs.LG])</h2>
<h3>Hadi Jahanshahi, Mustafa Gokce Baydogan</h3>
<p>The overwhelming presence of categorical/sequential data in diverse domains
emphasizes the importance of sequence mining. The challenging nature of
sequences proves the need for continuing research to find a more accurate and
faster approach providing a better understanding of their (dis)similarities.
This paper proposes a new Model-based approach for clustering sequence data,
namely nTreeClus. The proposed method deploys Tree-based Learners, k-mers, and
autoregressive models for categorical time series, culminating with a novel
numerical representation of the categorical sequences. Adopting this new
representation, we cluster sequences, considering the inherent patterns in
categorical time series. Accordingly, the model showed robustness to its
parameter. Under different simulated scenarios, nTreeClus improved the baseline
methods for various internal and external cluster validation metrics for up to
10.7% and 2.7%, respectively. The empirical evaluation using synthetic and real
datasets, protein sequences, and categorical time series showed that nTreeClus
is competitive or superior to most state-of-the-art algorithms.
</p>
<a href="http://arxiv.org/abs/2102.10252" target="_blank">arXiv:2102.10252</a> [<a href="http://arxiv.org/pdf/2102.10252" target="_blank">pdf</a>]

<h2>Persistence Homology for Link Prediction: An Interactive View. (arXiv:2102.10255v1 [cs.LG])</h2>
<h3>Zuoyu Yan, Tengfei Ma, Liangcai Gao, Zhi Tang, Chao Chen</h3>
<p>Link prediction is an important learning task for graph-structured data. In
this paper, we propose a novel topological approach to characterize
interactions between two nodes. Our topological feature, based on the extended
persistence homology, encodes rich structural information regarding the
multi-hop paths connecting nodes. Based on this feature, we propose a graph
neural network method that outperforms state-of-the-arts on different
benchmarks. As another contribution, we propose a novel algorithm to more
efficiently compute the extended persistent diagrams for graphs. This algorithm
can be generally applied to accelerate many other topological methods for graph
learning tasks.
</p>
<a href="http://arxiv.org/abs/2102.10255" target="_blank">arXiv:2102.10255</a> [<a href="http://arxiv.org/pdf/2102.10255" target="_blank">pdf</a>]

<h2>Inducing a hierarchy for multi-class classification problems. (arXiv:2102.10263v1 [stat.ML])</h2>
<h3>Hayden S. Helm, Weiwei Yang, Sujeeth Bharadwaj, Kate Lytvynets, Oriana Riva, Christopher White, Ali Geisa, Carey E. Priebe</h3>
<p>In applications where categorical labels follow a natural hierarchy,
classification methods that exploit the label structure often outperform those
that do not. Un-fortunately, the majority of classification datasets do not
come pre-equipped with a hierarchical structure and classical flat classifiers
must be employed. In this paper, we investigate a class of methods that induce
a hierarchy that can similarly improve classification performance over flat
classifiers. The class of methods follows the structure of first clustering the
conditional distributions and subsequently using a hierarchical classifier with
the induced hierarchy. We demonstrate the effectiveness of the class of methods
both for discovering a latent hierarchy and for improving accuracy in
principled simulation settings and three real data applications.
</p>
<a href="http://arxiv.org/abs/2102.10263" target="_blank">arXiv:2102.10263</a> [<a href="http://arxiv.org/pdf/2102.10263" target="_blank">pdf</a>]

<h2>On Proximal Policy Optimization's Heavy-tailed Gradients. (arXiv:2102.10264v1 [cs.LG])</h2>
<h3>Saurabh Garg, Joshua Zhanson, Emilio Parisotto, Adarsh Prasad, J. Zico Kolter, Sivaraman Balakrishnan, Zachary C. Lipton, Ruslan Salakhutdinov, Pradeep Ravikumar</h3>
<p>Modern policy gradient algorithms, notably Proximal Policy Optimization
(PPO), rely on an arsenal of heuristics, including loss clipping and gradient
clipping, to ensure successful learning. These heuristics are reminiscent of
techniques from robust statistics, commonly used for estimation in outlier-rich
("heavy-tailed") regimes. In this paper, we present a detailed empirical study
to characterize the heavy-tailed nature of the gradients of the PPO surrogate
reward function. We demonstrate that the gradients, especially for the actor
network, exhibit pronounced heavy-tailedness and that it increases as the
agent's policy diverges from the behavioral policy (i.e., as the agent goes
further off policy). Further examination implicates the likelihood ratios and
advantages in the surrogate reward as the main sources of the observed
heavy-tailedness. We then highlight issues arising due to the heavy-tailed
nature of the gradients. In this light, we study the effects of the standard
PPO clipping heuristics, demonstrating that these tricks primarily serve to
offset heavy-tailedness in gradients. Thus motivated, we propose incorporating
GMOM, a high-dimensional robust estimator, into PPO as a substitute for three
clipping tricks. Despite requiring less hyperparameter tuning, our method
matches the performance of PPO (with all heuristics enabled) on a battery of
MuJoCo continuous control tasks.
</p>
<a href="http://arxiv.org/abs/2102.10264" target="_blank">arXiv:2102.10264</a> [<a href="http://arxiv.org/pdf/2102.10264" target="_blank">pdf</a>]

<h2>Meta-Learning Dynamics Forecasting Using Task Inference. (arXiv:2102.10271v1 [cs.LG])</h2>
<h3>Rui Wang, Robin Walters, Rose Yu</h3>
<p>Current deep learning models for dynamics forecasting struggle with
generalization. They can only forecast in a specific domain and fail when
applied to systems with different parameters, external forces, or boundary
conditions. We propose a model-based meta-learning method called DyAd which can
generalize across heterogeneous domains by partitioning them into separate
subdomains, each with a different task. DyAd has two parts: a prediction
network which learns the shared dynamics of the entire domain, and an encoder
that infers the parameters of the task. The encoder adapts the prediction
network during inference time using adaptive instance normalization and a new
layer, AdaPad, specifically designed for boundary conditions. The encoder can
also use any weak supervision signals that can help distinguish different
tasks, allowing the incorporation of additional domain knowledge. Our model
outperforms a variety of state-of-the-art approaches on both turbulent flow and
real-world ocean data forecasting tasks.
</p>
<a href="http://arxiv.org/abs/2102.10271" target="_blank">arXiv:2102.10271</a> [<a href="http://arxiv.org/pdf/2102.10271" target="_blank">pdf</a>]

<h2>Concealed Object Detection. (arXiv:2102.10274v1 [cs.CV])</h2>
<h3>Deng-Ping Fan, Ge-Peng Ji, Ming-Ming Cheng, Ling Shao</h3>
<p>We present the first systematic study on concealed object detection (COD),
which aims to identify objects that are "perfectly" embedded in their
background. The high intrinsic similarities between the concealed objects and
their background make COD far more challenging than traditional object
detection/segmentation. To better understand this task, we collect a
large-scale dataset, called COD10K, which consists of 10,000 images covering
concealed objects in diverse real-world scenarios from 78 object categories.
Further, we provide rich annotations including object categories, object
boundaries, challenging attributes, object-level labels, and instance-level
annotations. Our COD10K is the largest COD dataset to date, with the richest
annotations, which enables comprehensive concealed object understanding and can
even be used to help progress several other vision tasks, such as detection,
segmentation, classification, etc. Motivated by how animals hunt in the wild,
we also design a simple but strong baseline for COD, termed the Search
Identification Network (SINet). Without any bells and whistles, SINet
outperforms 12 cutting-edge baselines on all datasets tested, making them
robust, general architectures that could serve as catalysts for future research
in COD. Finally, we provide some interesting findings and highlight several
potential applications and future directions. To spark research in this new
field, our code, dataset, and online demo are available on our project page:
this http URL
</p>
<a href="http://arxiv.org/abs/2102.10274" target="_blank">arXiv:2102.10274</a> [<a href="http://arxiv.org/pdf/2102.10274" target="_blank">pdf</a>]

<h2>Imitation Learning for Variable Speed Object Manipulation. (arXiv:2102.10283v1 [cs.RO])</h2>
<h3>Sho Sakaino, Kazuki Fujimoto, Yuki Saigusa, Toshiaki Tsuji</h3>
<p>To operate in a real-world environment, robots have several requirements
including environmental adaptability. Moreover, the desired success rate for
the completion of tasks must be achieved. In this regard, end-to-end learning
for autonomous operation is currently being investigated. However, the issue of
operating speed has not been investigated in detail. Therefore, in this paper,
we propose a method for generating variable operating speeds while adapting to
perturbations in the environment. When the work speed changes, there is a
nonlinear relationship between the operating speed and force (e.g., inertial
and frictional forces). However, the proposed method can be adapted to
nonlinearities by utilizing minimal motion data. We experimentally evaluated
the proposed method for erasing a line using an eraser fixed to the tip of a
robot. Furthermore, the proposed method enables a robot to perform a task
faster than a human operator.
</p>
<a href="http://arxiv.org/abs/2102.10283" target="_blank">arXiv:2102.10283</a> [<a href="http://arxiv.org/pdf/2102.10283" target="_blank">pdf</a>]

<h2>Artificial Intelligence Enhanced Rapid and Efficient Diagnosis of Mycoplasma Pneumoniae Pneumonia in Children Patients. (arXiv:2102.10284v1 [cs.LG])</h2>
<h3>Chenglin Pan, Kuan Yan, Xiao Liu, Yanjie Chen, Yanyan Luo, Xiaoming Li, Zhenguo Nie, Xinjun Liu</h3>
<p>Artificial intelligence methods have been increasingly turning into a
potentially powerful tool in the diagnosis and management of diseases. In this
study, we utilized logistic regression (LR), decision tree (DT), gradient
boosted decision tree (GBDT), support vector machine (SVM), and multilayer
perceptron (MLP) as machine learning models to rapidly diagnose the mycoplasma
pneumoniae pneumonia (MPP) in children patients. The classification task was
carried out after applying the preprocessing procedure to the MPP dataset. The
most efficient results are obtained by GBDT. It provides the best performance
with an accuracy of 93.7%. In contrast to standard raw feature weighting, the
feature importance takes the underlying correlation structure of the features
into account. The most crucial feature of GBDT is the "pulmonary infiltrates
range" with a score of 0.5925, followed by "cough" (0.0953) and "pleural
effusion" (0.0492). We publicly share our full implementation with the dataset
and trained models at https://github.com/zhenguonie/2021_AI4MPP.
</p>
<a href="http://arxiv.org/abs/2102.10284" target="_blank">arXiv:2102.10284</a> [<a href="http://arxiv.org/pdf/2102.10284" target="_blank">pdf</a>]

<h2>Towards Accurate and Compact Architectures via Neural Architecture Transformer. (arXiv:2102.10301v1 [cs.CV])</h2>
<h3>Yong Guo, Yin Zheng, Mingkui Tan, Qi Chen, Zhipeng Li, Jian Chen, Peilin Zhao, Junzhou Huang</h3>
<p>Designing effective architectures is one of the key factors behind the
success of deep neural networks. Existing deep architectures are either
manually designed or automatically searched by some Neural Architecture Search
(NAS) methods. However, even a well-designed/searched architecture may still
contain many nonsignificant or redundant modules/operations. Thus, it is
necessary to optimize the operations inside an architecture to improve the
performance without introducing extra computational cost. To this end, we have
proposed a Neural Architecture Transformer (NAT) method which casts the
optimization problem into a Markov Decision Process (MDP) and seeks to replace
the redundant operations with more efficient operations, such as skip or null
connection. Note that NAT only considers a small number of possible transitions
and thus comes with a limited search/transition space. As a result, such a
small search space may hamper the performance of architecture optimization. To
address this issue, we propose a Neural Architecture Transformer++ (NAT++)
method which further enlarges the set of candidate transitions to improve the
performance of architecture optimization. Specifically, we present a two-level
transition rule to obtain valid transitions, i.e., allowing operations to have
more efficient types (e.g., convolution-&gt;separable convolution) or smaller
kernel sizes (e.g., 5x5-&gt;3x3). Note that different operations may have
different valid transitions. We further propose a Binary-Masked Softmax
(BMSoftmax) layer to omit the possible invalid transitions. Extensive
experiments on several benchmark datasets show that the transformed
architecture significantly outperforms both its original counterpart and the
architectures optimized by existing methods.
</p>
<a href="http://arxiv.org/abs/2102.10301" target="_blank">arXiv:2102.10301</a> [<a href="http://arxiv.org/pdf/2102.10301" target="_blank">pdf</a>]

<h2>GroupifyVAE: from Group-based Definition to VAE-based Unsupervised Representation Disentanglement. (arXiv:2102.10303v1 [cs.LG])</h2>
<h3>Tao Yang, Xuanchi Ren, Yuwang Wang, Wenjun Zeng, Nanning Zheng, Pengju Ren</h3>
<p>The key idea of the state-of-the-art VAE-based unsupervised representation
disentanglement methods is to minimize the total correlation of the latent
variable distributions. However, it has been proved that VAE-based unsupervised
disentanglement can not be achieved without introducing other inductive bias.
In this paper, we address VAE-based unsupervised disentanglement by leveraging
the constraints derived from the Group Theory based definition as the
non-probabilistic inductive bias. More specifically, inspired by the nth
dihedral group (the permutation group for regular polygons), we propose a
specific form of the definition and prove its two equivalent conditions:
isomorphism and "the constancy of permutations". We further provide an
implementation of isomorphism based on two Group constraints: the Abel
constraint for the exchangeability and Order constraint for the cyclicity. We
then convert them into a self-supervised training loss that can be incorporated
into VAE-based models to bridge their gaps from the Group Theory based
definition. We train 1800 models covering the most prominent VAE-based models
on five datasets to verify the effectiveness of our method. Compared to the
original models, the Groupidied VAEs consistently achieve better mean
performance with smaller variances, and make meaningful dimensions
controllable.
</p>
<a href="http://arxiv.org/abs/2102.10303" target="_blank">arXiv:2102.10303</a> [<a href="http://arxiv.org/pdf/2102.10303" target="_blank">pdf</a>]

<h2>End-to-end neural network approach to 3D reservoir simulation and adaptation. (arXiv:2102.10304v1 [cs.LG])</h2>
<h3>E. Illarionov, P. Temirchev, D. Voloskov, R. Kostoev, M. Simonov, D. Pissarenko, D. Orlov, D. Koroteev</h3>
<p>Reservoir simulation and adaptation (also known as history matching) are
typically considered as separate problems. While a set of models are aimed at
the solution of the forward simulation problem assuming all initial geological
parameters are known, the other set of models adjust geological parameters
under the fixed forward simulation model to fit production data. This results
in many difficulties for both reservoir engineers and developers of new
efficient computation schemes. We present a unified approach to reservoir
simulation and adaptation problems. A single neural network model allows a
forward pass from initial geological parameters of the 3D reservoir model
through dynamic state variables to well's production rates and backward
gradient propagation to any model inputs and variables. The model fitting and
geological parameters adaptation both become the optimization problem over
specific parts of the same neural network model. Standard gradient-based
optimization schemes can be used to find the optimal solution. Using real-world
oilfield model and historical production rates we demonstrate that the
suggested approach provides accurate reservoir simulation and history matching
with a benefit of several orders of magnitude simulation speed-up.
</p>
<a href="http://arxiv.org/abs/2102.10304" target="_blank">arXiv:2102.10304</a> [<a href="http://arxiv.org/pdf/2102.10304" target="_blank">pdf</a>]

<h2>Mesh Manifold based Riemannian Motion Planning for Omnidirectional Micro Aerial Vehicles. (arXiv:2102.10313v1 [cs.RO])</h2>
<h3>Michael Pantic, Lionel Ott, Cesar Cadena, Roland Siegwart, Juan Nieto</h3>
<p>This paper presents a novel on-line path planning method that enables aerial
robots to interact with surfaces. We present a solution to the problem of
finding trajectories that drive a robot towards a surface and move along it.
Triangular meshes are used as a surface map representation that is free of
fixed discretization and allows for very large workspaces. We propose to
leverage planar parametrization methods to obtain a lower-dimensional
topologically equivalent representation of the original surface. Furthermore,
we interpret the original surface and its lower-dimensional representation as
manifold approximations that allow the use of Riemannian Motion Policies
(RMPs), resulting in an efficient, versatile, and elegant motion generation
framework. We compare against several Rapidly-exploring Random Tree (RRT)
planners, a customized CHOMP variant, and the discrete geodesic algorithm.
Using extensive simulations on real-world data we show that the proposed
planner can reliably plan high-quality near-optimal trajectories at minimal
computational cost. The accompanying multimedia attachment demonstrates
feasibility on a real OMAV. The obtained paths show less than 10% deviation
from the theoretical optimum while facilitating reactive re-planning at kHz
refresh rates, enabling flying robots to perform motion planning for
interaction with complex surfaces.
</p>
<a href="http://arxiv.org/abs/2102.10313" target="_blank">arXiv:2102.10313</a> [<a href="http://arxiv.org/pdf/2102.10313" target="_blank">pdf</a>]

<h2>Unavailable Transit Feed Specification: Making it Available with Recurrent Neural Networks. (arXiv:2102.10323v1 [cs.LG])</h2>
<h3>Ludovico Iovino, Phuong T. Nguyen, Amleto Di Salle, Francesco Gallo, Michele Flammini</h3>
<p>Studies on public transportation in Europe suggest that European inhabitants
use buses in ca. 56% of all public transport travels. One of the critical
factors affecting such a percentage and more, in general, the demand for public
transport services, with an increasing reluctance to use them, is their
quality. End-users can perceive quality from various perspectives, including
the availability of information, i.e., the access to details about the transit
and the provided services. The approach proposed in this paper, using
innovative methodologies resorting on data mining and machine learning
techniques, aims to make available the unavailable data about public transport.
In particular, by mining GPS traces, we manage to reconstruct the complete
transit graph of public transport. The approach has been successfully validated
on a real dataset collected from the local bus system of the city of L'Aquila
(Italy). The experimental results demonstrate that the proposed approach and
implemented framework are both effective and efficient, thus being ready for
deployment.
</p>
<a href="http://arxiv.org/abs/2102.10323" target="_blank">arXiv:2102.10323</a> [<a href="http://arxiv.org/pdf/2102.10323" target="_blank">pdf</a>]

<h2>Necessary and sufficient conditions for optimal adjustment sets in causal graphical models with hidden variables. (arXiv:2102.10324v1 [cs.LG])</h2>
<h3>Jakob Runge</h3>
<p>The problem of selecting optimal valid backdoor adjustment sets to estimate
total causal effects in graphical models with hidden and conditioned variables
is addressed. Previous work has defined optimality as achieving the smallest
asymptotic variance compared to other adjustment sets and identified a
graphical criterion for an optimal set for the case without hidden variables.
For the case with hidden variables currently a sufficient graphical criterion
and a corresponding construction algorithm exists. Here optimality is
characterized by an information-theoretic approach based on the mutual
informations among cause, effect, adjustment set, and conditioned variables.
This characterization allows to derive the main contributions of this paper: A
necessary and sufficient graphical criterion for the existence of an optimal
adjustment set and an algorithm to construct it. The results are valid for a
class of estimators whose variance admits a certain information-theoretic
decomposition.
</p>
<a href="http://arxiv.org/abs/2102.10324" target="_blank">arXiv:2102.10324</a> [<a href="http://arxiv.org/pdf/2102.10324" target="_blank">pdf</a>]

<h2>Decoupling Value and Policy for Generalization in Reinforcement Learning. (arXiv:2102.10330v1 [cs.LG])</h2>
<h3>Roberta Raileanu, Rob Fergus</h3>
<p>Standard deep reinforcement learning algorithms use a shared representation
for the policy and value function. However, we argue that more information is
needed to accurately estimate the value function than to learn the optimal
policy. Consequently, the use of a shared representation for the policy and
value function can lead to overfitting. To alleviate this problem, we propose
two approaches which are combined to create IDAAC: Invariant Decoupled
Advantage Actor-Critic. First, IDAAC decouples the optimization of the policy
and value function, using separate networks to model them. Second, it
introduces an auxiliary loss which encourages the representation to be
invariant to task-irrelevant properties of the environment. IDAAC shows good
generalization to unseen environments, achieving a new state-of-the-art on the
Procgen benchmark and outperforming popular methods on DeepMind Control tasks
with distractors. Moreover, IDAAC learns representations, value predictions,
and policies that are more robust to aesthetic changes in the observations that
do not change the underlying state of the environment.
</p>
<a href="http://arxiv.org/abs/2102.10330" target="_blank">arXiv:2102.10330</a> [<a href="http://arxiv.org/pdf/2102.10330" target="_blank">pdf</a>]

<h2>Provably Strict Generalisation Benefit for Equivariant Models. (arXiv:2102.10333v1 [stat.ML])</h2>
<h3>Bryn Elesedy, Sheheryar Zaidi</h3>
<p>It is widely believed that engineering a model to be invariant/equivariant
improves generalisation. Despite the growing popularity of this approach, a
precise characterisation of the generalisation benefit is lacking. By
considering the simplest case of linear models, this paper provides the first
provably non-zero improvement in generalisation for invariant/equivariant
models when the target distribution is invariant/equivariant with respect to a
compact group. Moreover, our work reveals an interesting relationship between
generalisation, the number of training examples and properties of the group
action. Our results rest on an observation of the structure of function spaces
under averaging operators which, along with its consequences for feature
averaging, may be of independent interest.
</p>
<a href="http://arxiv.org/abs/2102.10333" target="_blank">arXiv:2102.10333</a> [<a href="http://arxiv.org/pdf/2102.10333" target="_blank">pdf</a>]

<h2>Exploring Knowledge Distillation of a Deep Neural Network for Multi-Script identification. (arXiv:2102.10335v1 [cs.CV])</h2>
<h3>Shuvayan Ghosh Dastidar, Kalpita Dutta, Nibaran Das, Mahantapas Kundu, Mita Nasipuri</h3>
<p>Multi-lingual script identification is a difficult task consisting of
different language with complex backgrounds in scene text images. According to
the current research scenario, deep neural networks are employed as teacher
models to train a smaller student network by utilizing the teacher model's
predictions. This process is known as dark knowledge transfer. It has been
quite successful in many domains where the final result obtained is
unachievable through directly training the student network with a simple
architecture. In this paper, we explore dark knowledge transfer approach using
long short-term memory(LSTM) and CNN based assistant model and various deep
neural networks as the teacher model, with a simple CNN based student network,
in this domain of multi-script identification from natural scene text images.
We explore the performance of different teacher models and their ability to
transfer knowledge to a student network. Although the small student network's
limited size, our approach obtains satisfactory results on a well-known script
identification dataset CVSI-2015.
</p>
<a href="http://arxiv.org/abs/2102.10335" target="_blank">arXiv:2102.10335</a> [<a href="http://arxiv.org/pdf/2102.10335" target="_blank">pdf</a>]

<h2>Physical Reasoning Using Dynamics-Aware Models. (arXiv:2102.10336v1 [cs.AI])</h2>
<h3>Eltayeb Ahmed, Anton Bakhtin, Laurens van der Maaten, Rohit Girdhar</h3>
<p>A common approach to solving physical-reasoning tasks is to train a value
learner on example tasks. A limitation of such an approach is it requires
learning about object dynamics solely from reward values assigned to the final
state of a rollout of the environment. This study aims to address this
limitation by augmenting the reward value with additional supervisory signals
about object dynamics. Specifically,we define a distance measure between the
trajectory of two target objects, and use this distance measure to characterize
the similarity of two environment rollouts.We train the model to correctly rank
rollouts according to this measure in addition to predicting the correct
reward. Empirically, we find that this approach leads to substantial
performance improvements on the PHYRE benchmark for physical reasoning: our
approach obtains a new state-of-the-art on that benchmark.
</p>
<a href="http://arxiv.org/abs/2102.10336" target="_blank">arXiv:2102.10336</a> [<a href="http://arxiv.org/pdf/2102.10336" target="_blank">pdf</a>]

<h2>SSFG: Stochastically Scaling Features and Gradients for Regularizing Graph Convolution Networks. (arXiv:2102.10338v1 [cs.LG])</h2>
<h3>Haimin Zhang, Min Xu</h3>
<p>Graph convolutional networks have been successfully applied in various
graph-based tasks. In a typical graph convolutional layer, node features are
computed by aggregating neighborhood information. Repeatedly applying graph
convolutions can cause the oversmoothing issue, i.e., node features converge to
similar values. This is one of the major reasons that cause overfitting in
graph learning, resulting in the model fitting well to training data while not
generalizing well on test data. In this paper, we present a stochastic
regularization method to address this issue. In our method, we stochastically
scale features and gradients (SSFG) by a factor sampled from a probability
distribution in the training procedure. We show that applying stochastic
scaling at the feature level is complementary to that at the gradient level in
improving the overall performance. When used together with ReLU, our method can
be seen as a stochastic ReLU. We experimentally validate our SSFG
regularization method on seven benchmark datasets for different graph-based
tasks. Extensive experimental results demonstrate that our method effectively
improves the overall performance of the baseline graph networks.
</p>
<a href="http://arxiv.org/abs/2102.10338" target="_blank">arXiv:2102.10338</a> [<a href="http://arxiv.org/pdf/2102.10338" target="_blank">pdf</a>]

<h2>On a notion of independence proposed by Teddy Seidenfeld. (arXiv:2102.10342v1 [cs.AI])</h2>
<h3>Jasper De Bock, Gert de Cooman</h3>
<p>Teddy Seidenfeld has been arguing for quite a long time that binary
preference models are not powerful enough to deal with a number of crucial
aspects of imprecision and indeterminacy in uncertain inference and decision
making. It is at his insistence that we initiated our study of so-called sets
of desirable option sets, which we have argued elsewhere provides an elegant
and powerful approach to dealing with general, binary as well as non-binary,
decision-making under uncertainty. We use this approach here to explore an
interesting notion of irrelevance (and independence), first suggested by
Seidenfeld in an example intended as a criticism of a number of specific
decision methodologies based on (convex) binary preferences. We show that the
consequences of making such an irrelevance or independence assessment are very
strong, and might be used to argue for the use of so-called mixing choice
functions, and E-admissibility as the resulting decision scheme.
</p>
<a href="http://arxiv.org/abs/2102.10342" target="_blank">arXiv:2102.10342</a> [<a href="http://arxiv.org/pdf/2102.10342" target="_blank">pdf</a>]

<h2>Going Far Boosts Attack Transferability, but Do Not Do It. (arXiv:2102.10343v1 [cs.LG])</h2>
<h3>Sizhe Chen, Qinghua Tao, Zhixing Ye, Xiaolin Huang</h3>
<p>Deep Neural Networks (DNNs) could be easily fooled by Adversarial Examples
(AEs) with an imperceptible difference to original ones in human eyes. Also,
the AEs from attacking one surrogate DNN tend to cheat other black-box DNNs as
well, i.e., the attack transferability. Existing works reveal that adopting
certain optimization algorithms in attack improves transferability, but the
underlying reasons have not been thoroughly studied. In this paper, we
investigate the impacts of optimization on attack transferability by
comprehensive experiments concerning 7 optimization algorithms, 4 surrogates,
and 9 black-box models. Through the thorough empirical analysis from three
perspectives, we surprisingly find that the varied transferability of AEs from
optimization algorithms is strongly related to the corresponding Root Mean
Square Error (RMSE) from their original samples. On such a basis, one could
simply approach high transferability by attacking until RMSE decreases, which
motives us to propose a LArge RMSE Attack (LARA). Although LARA significantly
improves transferability by 20%, it is insufficient to exploit the
vulnerability of DNNs, leading to a natural urge that the strength of all
attacks should be measured by both the widely used $\ell_\infty$ bound and the
RMSE addressed in this paper, so that tricky enhancement of transferability
would be avoided.
</p>
<a href="http://arxiv.org/abs/2102.10343" target="_blank">arXiv:2102.10343</a> [<a href="http://arxiv.org/pdf/2102.10343" target="_blank">pdf</a>]

<h2>Safe and Uncertainty-Aware Robotic Motion Planning Techniques for Agile On-Orbit Assembly. (arXiv:2102.10348v1 [cs.RO])</h2>
<h3>Bryce Doerr, Keenan Albee, Monica Ekal, Richard Linares, Rodrigo Ventura</h3>
<p>As access to space and robotic autonomy capabilities move forward, there is
simultaneously a growing interest in deploying large, complex space structures
to provide new on-orbit capabilities. New space-borne observatories, large
orbital outposts, and even futuristic on-orbit manufacturing will be enabled by
robotic assembly of space structures using techniques like on-orbit additive
manufacturing which can provide flexibility in constructing and even repairing
complex hardware. However, the dynamics underlying the robotic assembler during
manipulation may operate under inertial uncertainties. Thus, inertial
estimation of the robot and the manipulated component system must be considered
during structural assembly. The contribution of this work is to address both
the motion planning and control for robotic assembly with consideration of the
inertial estimation of the combined free-flying robotic assembler and
additively manufactured component system. Specifically, the Linear Quadratic
Regulator Rapidly-Exploring Randomized Trees (LQR-RRT*) and dynamically
feasible path smoothing are used to obtain obstacle-free trajectories for the
system. Further, model learning is incorporated explicitly into the planning
stages via approximation of the continuous system and accompanying reward of
performing safe, objective-oriented motion. Remaining uncertainty can then be
dealt with using robust tube model predictive control. By obtaining controlled
trajectories that consider both obstacle avoidance and learning of the inertial
properties of the free-flyer and manipulated component system, the free-flyer
rapidly considers and plans the construction of space structures with enhanced
system knowledge. The approach naturally generalizes to repairing, refueling,
and re-provisioning space structure components while providing optimal
collision-free trajectories under e.g., inertial uncertainty.
</p>
<a href="http://arxiv.org/abs/2102.10348" target="_blank">arXiv:2102.10348</a> [<a href="http://arxiv.org/pdf/2102.10348" target="_blank">pdf</a>]

<h2>How To Train Your HERON. (arXiv:2102.10357v1 [cs.RO])</h2>
<h3>Antoine Richard, Stephanie Aravecchia, Thomas Schillaci, Matthieu Geist, Cedric Pradalier</h3>
<p>In this paper we apply Deep Reinforcement Learning (Deep RL) and Domain
Randomization to solve a navigation task in a natural environment relying
solely on a 2D laser scanner. We train a model-based RL agent in simulation to
follow lake and river shores and apply it on a real Unmanned Surface Vehicle in
a zero-shot setup. We demonstrate that even though the agent has not been
trained in the real world, it can fulfill its task successfully and adapt to
changes in the robot's environment and dynamics. Finally, we show that the RL
agent is more robust, faster, and more accurate than a state-aware
Model-Predictive-Controller.
</p>
<a href="http://arxiv.org/abs/2102.10357" target="_blank">arXiv:2102.10357</a> [<a href="http://arxiv.org/pdf/2102.10357" target="_blank">pdf</a>]

<h2>Causal Policy Gradients. (arXiv:2102.10362v1 [cs.LG])</h2>
<h3>Thomas Spooner, Nelson Vadori, Sumitra Ganesh</h3>
<p>Policy gradient methods can solve complex tasks but often fail when the
dimensionality of the action-space or objective multiplicity grow very large.
This occurs, in part, because the variance on score-based gradient estimators
scales quadratically with the number of targets. In this paper, we propose a
causal baseline which exploits independence structure encoded in a novel
action-target influence network. Causal policy gradients (CPGs), which follow,
provide a common framework for analysing key state-of-the-art algorithms, are
shown to generalise traditional policy gradients, and yield a principled way of
incorporating prior knowledge of a problem domain's generative processes. We
provide an analysis of the proposed estimator and identify the conditions under
which variance is guaranteed to improve. The algorithmic aspects of CPGs are
also discussed, including optimal policy factorisations, their complexity, and
the use of conditioning to efficiently scale to extremely large, concurrent
tasks. The performance advantages for two variants of the algorithm are
demonstrated on large-scale bandit and concurrent inventory management
problems.
</p>
<a href="http://arxiv.org/abs/2102.10362" target="_blank">arXiv:2102.10362</a> [<a href="http://arxiv.org/pdf/2102.10362" target="_blank">pdf</a>]

<h2>Analyzing Overfitting under Class Imbalance in Neural Networks for Image Segmentation. (arXiv:2102.10365v1 [cs.CV])</h2>
<h3>Zeju Li, Konstantinos Kamnitsas, Ben Glocker</h3>
<p>Class imbalance poses a challenge for developing unbiased, accurate
predictive models. In particular, in image segmentation neural networks may
overfit to the foreground samples from small structures, which are often
heavily under-represented in the training set, leading to poor generalization.
In this study, we provide new insights on the problem of overfitting under
class imbalance by inspecting the network behavior. We find empirically that
when training with limited data and strong class imbalance, at test time the
distribution of logit activations may shift across the decision boundary, while
samples of the well-represented class seem unaffected. This bias leads to a
systematic under-segmentation of small structures. This phenomenon is
consistently observed for different databases, tasks and network architectures.
To tackle this problem, we introduce new asymmetric variants of popular loss
functions and regularization techniques including a large margin loss, focal
loss, adversarial training, mixup and data augmentation, which are explicitly
designed to counter logit shift of the under-represented classes. Extensive
experiments are conducted on several challenging segmentation tasks. Our
results demonstrate that the proposed modifications to the objective function
can lead to significantly improved segmentation accuracy compared to baselines
and alternative approaches.
</p>
<a href="http://arxiv.org/abs/2102.10365" target="_blank">arXiv:2102.10365</a> [<a href="http://arxiv.org/pdf/2102.10365" target="_blank">pdf</a>]

<h2>EMDS-5: Environmental Microorganism Image Dataset Fifth Version for Multiple Image Analysis Tasks. (arXiv:2102.10370v1 [cs.CV])</h2>
<h3>Zihan Li, Chen Li, Yudong Yao, Jinghua Zhang, Md Mamunur Rahaman, Hao Xu, Frank Kulwa, Bolin Lu, Xuemin Zhu, Tao Jiang</h3>
<p>Environmental Microorganism Data Set Fifth Version (EMDS-5) is a microscopic
image dataset including original Environmental Microorganism (EM) images and
two sets of Ground Truth (GT) images. The GT image sets include a single-object
GT image set and a multi-object GT image set. The EMDS-5 dataset has 21 types
of EMs, each of which contains 20 original EM images, 20 single-object GT
images and 20 multi-object GT images. EMDS-5 can realize to evaluate image
preprocessing, image segmentation, feature extraction, image classification and
image retrieval functions. In order to prove the effectiveness of EMDS-5, for
each function, we select the most representative algorithms and price
indicators for testing and evaluation. The image preprocessing functions
contain two parts: image denoising and image edge detection. Image denoising
uses nine kinds of filters to denoise 13 kinds of noises, respectively. In the
aspect of edge detection, six edge detection operators are used to detect the
edges of the images, and two evaluation indicators, peak-signal to noise ratio
and mean structural similarity, are used for evaluation. Image segmentation
includes single-object image segmentation and multi-object image segmentation.
Six methods are used for single-object image segmentation, while k-means and
U-net are used for multi-object segmentation.We extract nine features from the
images in EMDS-5 and use the Support Vector Machine classifier for testing. In
terms of image classification, we select the VGG16 feature to test different
classifiers. We test two types of retrieval approaches: texture feature
retrieval and deep learning feature retrieval. We select the last layer of
features of these two deep learning networks as feature vectors. We use mean
average precision as the evaluation index for retrieval.
</p>
<a href="http://arxiv.org/abs/2102.10370" target="_blank">arXiv:2102.10370</a> [<a href="http://arxiv.org/pdf/2102.10370" target="_blank">pdf</a>]

<h2>CellTrack R-CNN: A Novel End-To-End Deep Neural Network for Cell Segmentation and Tracking in Microscopy Images. (arXiv:2102.10377v1 [cs.CV])</h2>
<h3>Yuqian Chen, Yang Song, Chaoyi Zhang, Fan Zhang, Lauren O&#x27;Donnell, Wojciech Chrzanowski, Weidong Cai</h3>
<p>Cell segmentation and tracking in microscopy images are of great significance
to new discoveries in biology and medicine. In this study, we propose a novel
approach to combine cell segmentation and cell tracking into a unified
end-to-end deep learning based framework, where cell detection and segmentation
are performed with a current instance segmentation pipeline and cell tracking
is implemented by integrating Siamese Network with the pipeline. Besides,
tracking performance is improved by incorporating spatial information into the
network and fusing spatial and visual prediction. Our approach was evaluated on
the DeepCell benchmark dataset. Despite being simple and efficient, our method
outperforms state-of-the-art algorithms in terms of both cell segmentation and
cell tracking accuracies.
</p>
<a href="http://arxiv.org/abs/2102.10377" target="_blank">arXiv:2102.10377</a> [<a href="http://arxiv.org/pdf/2102.10377" target="_blank">pdf</a>]

<h2>Self-Supervised Learning via multi-Transformation Classification for Action Recognition. (arXiv:2102.10378v1 [cs.CV])</h2>
<h3>Duc Quang Vu, Ngan T.H.Le, Jia-Ching Wang</h3>
<p>Self-supervised tasks have been utilized to build useful representations that
can be used in downstream tasks when the annotation is unavailable. In this
paper, we introduce a self-supervised video representation learning method
based on the multi-transformation classification to efficiently classify human
actions. Self-supervised learning on various transformations not only provides
richer contextual information but also enables the visual representation more
robust to the transforms. The spatio-temporal representation of the video is
learned in a self-supervised manner by classifying seven different
transformations i.e. rotation, clip inversion, permutation, split, join
transformation, color switch, frame replacement, noise addition. First, seven
different video transformations are applied to video clips. Then the 3D
convolutional neural networks are utilized to extract features for clips and
these features are processed to classify the pseudo-labels. We use the learned
models in pretext tasks as the pre-trained models and fine-tune them to
recognize human actions in the downstream task. We have conducted the
experiments on UCF101 and HMDB51 datasets together with C3D and 3D Resnet-18 as
backbone networks. The experimental results have shown that our proposed
framework is outperformed other SOTA self-supervised action recognition
approaches. The code will be made publicly available.
</p>
<a href="http://arxiv.org/abs/2102.10378" target="_blank">arXiv:2102.10378</a> [<a href="http://arxiv.org/pdf/2102.10378" target="_blank">pdf</a>]

<h2>On Calibration and Out-of-domain Generalization. (arXiv:2102.10395v1 [cs.LG])</h2>
<h3>Yoav Wald, Amir Feder, Daniel Greenfeld, Uri Shalit</h3>
<p>Out-of-domain (OOD) generalization is a significant challenge for machine
learning models. To overcome it, many novel techniques have been proposed,
often focused on learning models with certain invariance properties. In this
work, we draw a link between OOD performance and model calibration, arguing
that calibration across multiple domains can be viewed as a special case of an
invariant representation leading to better OOD generalization. Specifically, we
prove in a simplified setting that models which achieve multi-domain
calibration are free of spurious correlations. This leads us to propose
multi-domain calibration as a measurable surrogate for the OOD performance of a
classifier. An important practical benefit of calibration is that there are
many effective tools for calibrating classifiers. We show that these tools are
easy to apply and adapt for a multi-domain setting. Using five datasets from
the recently proposed WILDS OOD benchmark we demonstrate that simply
re-calibrating models across multiple domains in a validation set leads to
significantly improved performance on unseen test domains. We believe this
intriguing connection between calibration and OOD generalization is promising
from a practical point of view and deserves further research from a theoretical
point of view.
</p>
<a href="http://arxiv.org/abs/2102.10395" target="_blank">arXiv:2102.10395</a> [<a href="http://arxiv.org/pdf/2102.10395" target="_blank">pdf</a>]

<h2>GLAM: Graph Learning by Modeling Affinity to Labeled Nodes for Graph Neural Networks. (arXiv:2102.10403v1 [cs.LG])</h2>
<h3>Vijay Lingam, Arun Iyer, Rahul Ragesh</h3>
<p>Graph Neural Networks have shown excellent performance on semi-supervised
classification tasks. However, they assume access to a graph that may not be
often available in practice. In the absence of any graph, constructing
k-Nearest Neighbor (kNN) graphs from the given data have shown to give
improvements when used with GNNs over other semi-supervised methods. This paper
proposes a semi-supervised graph learning method for cases when there are no
graphs available. This method learns a graph as a convex combination of the
unsupervised kNN graph and a supervised label-affinity graph. The
label-affinity graph directly captures all the nodes' label-affinity with the
labeled nodes, i.e., how likely a node has the same label as the labeled nodes.
This affinity measure contrasts with the kNN graph where the metric measures
closeness in the feature space. Our experiments suggest that this approach
gives close to or better performance (up to 1.5%), while being simpler and
faster (up to 70x) to train, than state-of-the-art graph learning methods. We
also conduct several experiments to highlight the importance of individual
components and contrast them with state-of-the-art methods.
</p>
<a href="http://arxiv.org/abs/2102.10403" target="_blank">arXiv:2102.10403</a> [<a href="http://arxiv.org/pdf/2102.10403" target="_blank">pdf</a>]

<h2>VisualGPT: Data-efficient Image Captioning by Balancing Visual Input and Linguistic Knowledge from Pretraining. (arXiv:2102.10407v1 [cs.CV])</h2>
<h3>Jun Chen, Han Guo, Kai Yi, Boyang Li, Mohamed Elhoseiny</h3>
<p>In this paper, we aim to improve the data efficiency of image captioning. We
propose VisualGPT, a data-efficient image captioning model that leverages the
linguistic knowledge from a large pretrained language model (LM). A crucial
challenge is to balance between the use of visual information in the image and
prior linguistic knowledge acquired from pretraining.We designed a novel
self-resurrecting encoder-decoder attention mechanism to quickly adapt the
pretrained LM as the language decoder on a small amount of in-domain training
data. The pro-posed self-resurrecting activation unit produces sparse
activations but is not susceptible to zero gradients. When trained on 0.1%,
0.5% and 1% of MSCOCO and Conceptual Captions, the proposed model, VisualGPT,
surpasses strong image captioning baselines. VisualGPT outperforms the best
baseline model by up to 10.8% CIDEr on MS COCO and up to 5.4% CIDEr on
Conceptual Captions.We also perform a series of ablation studies to quantify
the utility of each system component. To the best of our knowledge, this is the
first work that improves data efficiency of image captioning by utilizing LM
pretrained on unimodal data. Our code is available at:
https://github.com/Vision-CAIR/VisualGPT.
</p>
<a href="http://arxiv.org/abs/2102.10407" target="_blank">arXiv:2102.10407</a> [<a href="http://arxiv.org/pdf/2102.10407" target="_blank">pdf</a>]

<h2>Robotic Contact Juggling. (arXiv:2102.10421v1 [cs.RO])</h2>
<h3>J. Zachary Woodruff, Kevin M. Lynch</h3>
<p>We define "robotic contact juggling" to be the purposeful control of the
motion of a three-dimensional smooth object as it rolls freely on a
motion-controlled robot manipulator, or "hand." While specific examples of
robotic contact juggling have been studied before, in this paper we provide the
first general formulation and solution method for the case of an arbitrary
smooth object in single-point rolling contact on an arbitrary smooth hand. Our
formulation splits the problem into four subproblems: (1) deriving the
second-order rolling kinematics; (2) deriving the three-dimensional rolling
dynamics; (3) planning rolling motions that satisfy the rolling dynamics; and
(4) feedback stabilization of planned rolling trajectories. The theoretical
results are demonstrated in simulation and experiment using feedback from a
high-speed vision system.
</p>
<a href="http://arxiv.org/abs/2102.10421" target="_blank">arXiv:2102.10421</a> [<a href="http://arxiv.org/pdf/2102.10421" target="_blank">pdf</a>]

<h2>An Evaluation of Edge TPU Accelerators for Convolutional Neural Networks. (arXiv:2102.10423v1 [cs.LG])</h2>
<h3>Amir Yazdanbakhsh, Kiran Seshadri, Berkin Akin, James Laudon, Ravi Narayanaswami</h3>
<p>Edge TPUs are a domain of accelerators for low-power, edge devices and are
widely used in various Google products such as Coral and Pixel devices. In this
paper, we first discuss the major microarchitectural details of Edge TPUs.
Then, we extensively evaluate three classes of Edge TPUs, covering different
computing ecosystems, that are either currently deployed in Google products or
are the product pipeline, across 423K unique convolutional neural networks.
Building upon this extensive study, we discuss critical and interpretable
microarchitectural insights about the studied classes of Edge TPUs. Mainly, we
discuss how Edge TPU accelerators perform across convolutional neural networks
with different structures. Finally, we present our ongoing efforts in
developing high-accuracy learned machine learning models to estimate the major
performance metrics of accelerators such as latency and energy consumption.
These learned models enable significantly faster (in the order of milliseconds)
evaluations of accelerators as an alternative to time-consuming cycle-accurate
simulators and establish an exciting opportunity for rapid hard-ware/software
co-design.
</p>
<a href="http://arxiv.org/abs/2102.10423" target="_blank">arXiv:2102.10423</a> [<a href="http://arxiv.org/pdf/2102.10423" target="_blank">pdf</a>]

<h2>GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v1 [cs.LG])</h2>
<h3>Cameron R. Wolfe, Jingkang Yang, Arindam Chowdhury, Chen Dun, Artun Bayer, Santiago Segarra, Anastasios Kyrillidis</h3>
<p>The graph convolutional network (GCN) is a go-to solution for machine
learning on graphs, but its training is notoriously difficult to scale in terms
of both the size of the graph and the number of model parameters. These
limitations are in stark contrast to the increasing scale (in data size and
model size) of experiments in deep learning research. In this work, we propose
GIST, a novel distributed approach that enables efficient training of wide
(overparameterized) GCNs on large graphs. GIST is a hybrid layer and graph
sampling method, which disjointly partitions the global model into several,
smaller sub-GCNs that are independently trained across multiple GPUs in
parallel. This distributed framework improves model performance and
significantly decreases wall-clock training time. GIST seeks to enable
large-scale GCN experimentation with the goal of bridging the existing gap in
scale between graph machine learning and deep learning.
</p>
<a href="http://arxiv.org/abs/2102.10424" target="_blank">arXiv:2102.10424</a> [<a href="http://arxiv.org/pdf/2102.10424" target="_blank">pdf</a>]

<h2>MHDeep: Mental Health Disorder Detection System based on Body-Area and Deep Neural Networks. (arXiv:2102.10435v1 [cs.LG])</h2>
<h3>Shayan Hassantabar, Joe Zhang, Hongxu Yin, Niraj K. Jha</h3>
<p>Mental health problems impact quality of life of millions of people around
the world. However, diagnosis of mental health disorders is a challenging
problem that often relies on self-reporting by patients about their behavioral
patterns. Therefore, there is a need for new strategies for diagnosis of mental
health problems. The recent introduction of body-area networks consisting of a
plethora of accurate sensors embedded in smartwatches and smartphones and deep
neural networks (DNNs) points towards a possible solution. However, disease
diagnosis based on WMSs and DNNs, and their deployment on edge devices, remains
a challenging problem. To this end, we propose a framework called MHDeep that
utilizes commercially available WMSs and efficient DNN models to diagnose three
important mental health disorders: schizoaffective, major depressive, and
bipolar. MHDeep uses eight different categories of data obtained from sensors
integrated in a smartwatch and smartphone. Due to limited available data,
MHDeep uses a synthetic data generation module to augment real data with
synthetic data drawn from the same probability distribution. We use the
synthetic dataset to pre-train the DNN models, thus imposing a prior on the
weights. We use a grow-and-prune DNN synthesis approach to learn both the
architecture and weights during the training process. We use three different
data partitions to evaluate the MHDeep models trained with data collected from
74 individuals. We conduct data instance level and patient level evaluations.
MHDeep achieves an average test accuracy of 90.4%, 87.3%, and 82.4%,
respectively, for classifications between healthy instances and schizoaffective
disorder instances, major depressive disorder instances, and bipolar disorder
instances. At the patient level, MHDeep DNNs achieve an accuracy of 100%, 100%,
and 90.0% for the three mental health disorders, respectively.
</p>
<a href="http://arxiv.org/abs/2102.10435" target="_blank">arXiv:2102.10435</a> [<a href="http://arxiv.org/pdf/2102.10435" target="_blank">pdf</a>]

<h2>Unsupervised Medical Image Alignment with Curriculum Learning. (arXiv:2102.10438v1 [cs.CV])</h2>
<h3>Mihail Burduja, Radu Tudor Ionescu</h3>
<p>We explore different curriculum learning methods for training convolutional
neural networks on the task of deformable pairwise 3D medical image
registration. To the best of our knowledge, we are the first to attempt to
improve performance by training medical image registration models using
curriculum learning, starting from an easy training setup in the first training
stages, and gradually increasing the complexity of the setup. On the one hand,
we consider two existing curriculum learning approaches, namely curriculum
dropout and curriculum by smoothing. On the other hand, we propose a novel and
simple strategy to achieve curriculum, namely to use purposely blurred images
at the beginning, then gradually transit to sharper images in the later
training stages. Our experiments with an underlying state-of-the-art deep
learning model show that curriculum learning can lead to superior results
compared to conventional training.
</p>
<a href="http://arxiv.org/abs/2102.10438" target="_blank">arXiv:2102.10438</a> [<a href="http://arxiv.org/pdf/2102.10438" target="_blank">pdf</a>]

<h2>Retrain or not retrain: Conformal test martingales for change-point detection. (arXiv:2102.10439v1 [cs.LG])</h2>
<h3>Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Ernst Ahlberg, Lars Carlsson, Alex Gammerman</h3>
<p>We argue for supplementing the process of training a prediction algorithm by
setting up a scheme for detecting the moment when the distribution of the data
changes and the algorithm needs to be retrained. Our proposed schemes are based
on exchangeability martingales, i.e., processes that are martingales under any
exchangeable distribution for the data. Our method, based on conformal
prediction, is general and can be applied on top of any modern prediction
algorithm. Its validity is guaranteed, and in this paper we make first steps in
exploring its efficiency.
</p>
<a href="http://arxiv.org/abs/2102.10439" target="_blank">arXiv:2102.10439</a> [<a href="http://arxiv.org/pdf/2102.10439" target="_blank">pdf</a>]

<h2>Interventional Sum-Product Networks: Causal Inference with Tractable Probabilistic Models. (arXiv:2102.10440v1 [cs.LG])</h2>
<h3>Matej Ze&#x10d;evi&#x107;, Devendra Singh Dhami, Athresh Karanam, Sriraam Natarajan, Kristian Kersting</h3>
<p>While probabilistic models are an important tool for studying causality,
doing so suffers from the intractability of inference. As a step towards
tractable causal models, we consider the problem of learning interventional
distributions using sum-product net-works (SPNs) that are over-parameterized by
gate functions, e.g., neural networks. Providing an arbitrarily intervened
causal graph as input, effectively subsuming Pearl's do-operator, the gate
function predicts the parameters of the SPN. The resulting interventional SPNs
are motivated and illustrated by a structural causal model themed around
personal health. Our empirical evaluation on three benchmark data sets as well
as a synthetic health data set clearly demonstrates that interventional SPNs
indeed are both expressive in modelling and flexible in adapting to the
interventions.
</p>
<a href="http://arxiv.org/abs/2102.10440" target="_blank">arXiv:2102.10440</a> [<a href="http://arxiv.org/pdf/2102.10440" target="_blank">pdf</a>]

<h2>Squeeze-and-Excitation Normalization for Automated Delineation of Head and Neck Primary Tumors in Combined PET and CT Images. (arXiv:2102.10446v1 [cs.CV])</h2>
<h3>Andrei Iantsen, Dimitris Visvikis, Mathieu Hatt</h3>
<p>Development of robust and accurate fully automated methods for medical image
segmentation is crucial in clinical practice and radiomics studies. In this
work, we contributed an automated approach for Head and Neck (H&amp;N) primary
tumor segmentation in combined positron emission tomography / computed
tomography (PET/CT) images in the context of the MICCAI 2020 Head and Neck
Tumor segmentation challenge (HECKTOR). Our model was designed on the U-Net
architecture with residual layers and supplemented with Squeeze-and-Excitation
Normalization. The described method achieved competitive results in
cross-validation (DSC 0.745, precision 0.760, recall 0.789) performed on
different centers, as well as on the test set (DSC 0.759, precision 0.833,
recall 0.740) that allowed us to win first prize in the HECKTOR challenge among
21 participating teams. The full implementation based on PyTorch and the
trained models are available at https://github.com/iantsen/hecktor
</p>
<a href="http://arxiv.org/abs/2102.10446" target="_blank">arXiv:2102.10446</a> [<a href="http://arxiv.org/pdf/2102.10446" target="_blank">pdf</a>]

<h2>Importance of Environment Design in Reinforcement Learning: A Study of a Robotic Environment. (arXiv:2102.10447v1 [cs.LG])</h2>
<h3>M&#xf3;nika Farsang, Luca Szegletes</h3>
<p>An in-depth understanding of the particular environment is crucial in
reinforcement learning (RL). To address this challenge, the decision-making
process of a mobile collaborative robotic assistant modeled by the Markov
decision process (MDP) framework is studied in this paper. The optimal
state-action combinations of the MDP are calculated with the non-linear Bellman
optimality equations. This system of equations can be solved with relative ease
by the computational power of Wolfram Mathematica, where the obtained optimal
action-values results point to the optimal policy. Unlike other RL algorithms,
this methodology does not approximate the optimal behavior, it provides the
exact, explicit solution, which provides a strong foundation for our study.
With this, we offer new insights into understanding the action selection
mechanisms in RL. During the analysis of the robotic environment, we present
various small modifications on the very same schema that lead to different
optimal policies. Finally, we emphasize that beyond building efficient RL
algorithms, only the proper design of the environment can ensure the desired
results.
</p>
<a href="http://arxiv.org/abs/2102.10447" target="_blank">arXiv:2102.10447</a> [<a href="http://arxiv.org/pdf/2102.10447" target="_blank">pdf</a>]

<h2>On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning. (arXiv:2102.10454v1 [cs.LG])</h2>
<h3>Ren Wang, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Chuang Gan, Meng Wang</h3>
<p>Model-agnostic meta-learning (MAML) has emerged as one of the most successful
meta-learning techniques in few-shot learning. It enables us to learn a
meta-initialization} of model parameters (that we call meta-model) to rapidly
adapt to new tasks using a small amount of labeled training data. Despite the
generalization power of the meta-model, it remains elusive that how adversarial
robustness can be maintained by MAML in few-shot learning. In addition to
generalization, robustness is also desired for a meta-model to defend
adversarial examples (attacks). Toward promoting adversarial robustness in
MAML, we first study WHEN a robustness-promoting regularization should be
incorporated, given the fact that MAML adopts a bi-level (fine-tuning vs.
meta-update) learning procedure. We show that robustifying the meta-update
stage is sufficient to make robustness adapted to the task-specific fine-tuning
stage even if the latter uses a standard training protocol. We also make
additional justification on the acquired robustness adaptation by peering into
the interpretability of neurons' activation maps. Furthermore, we investigate
HOW robust regularization can efficiently be designed in MAML. We propose a
general but easily-optimized robustness-regularized meta-learning framework,
which allows the use of unlabeled data augmentation, fast adversarial attack
generation, and computationally-light fine-tuning. In particular, we for the
first time show that the auxiliary contrastive learning task can enhance the
adversarial robustness of MAML. Finally, extensive experiments are conducted to
demonstrate the effectiveness of our proposed methods in robust few-shot
learning.
</p>
<a href="http://arxiv.org/abs/2102.10454" target="_blank">arXiv:2102.10454</a> [<a href="http://arxiv.org/pdf/2102.10454" target="_blank">pdf</a>]

<h2>Decaying Clipping Range in Proximal Policy Optimization. (arXiv:2102.10456v1 [cs.LG])</h2>
<h3>M&#xf3;nika Farsang, Luca Szegletes</h3>
<p>Proximal Policy Optimization (PPO) is among the most widely used algorithms
in reinforcement learning, which achieves state-of-the-art performance in many
challenging problems. The keys to its success are the reliable policy updates
through the clipping mechanism and the multiple epochs of minibatch updates.
The aim of this research is to give new simple but effective alternatives to
the former. For this, we propose linearly and exponentially decaying clipping
range approaches throughout the training. With these, we would like to provide
higher exploration at the beginning and stronger restrictions at the end of the
learning phase. We investigate their performance in several classical control
and locomotive robotic environments. During the analysis, we found that they
influence the achieved rewards and are effective alternatives to the constant
clipping method in many reinforcement learning tasks.
</p>
<a href="http://arxiv.org/abs/2102.10456" target="_blank">arXiv:2102.10456</a> [<a href="http://arxiv.org/pdf/2102.10456" target="_blank">pdf</a>]

<h2>Trumpets: Injective Flows for Inference and Inverse Problems. (arXiv:2102.10461v1 [cs.LG])</h2>
<h3>Konik Kothari, AmirEhsan Khorashadizadeh, Maarten de Hoop, Ivan Dokmani&#x107;</h3>
<p>We propose injective generative models called Trumpets that generalize
invertible normalizing flows. The proposed generators progressively increase
dimension from a low-dimensional latent space. We demonstrate that Trumpets can
be trained orders of magnitudes faster than standard flows while yielding
samples of comparable or better quality. They retain many of the advantages of
the standard flows such as training based on maximum likelihood and a fast,
exact inverse of the generator. Since Trumpets are injective and have fast
inverses, they can be effectively used for downstream Bayesian inference. To
wit, we use Trumpet priors for maximum a posteriori estimation in the context
of image reconstruction from compressive measurements, outperforming
competitive baselines in terms of reconstruction quality and speed. We then
propose an efficient method for posterior characterization and uncertainty
quantification with Trumpets by taking advantage of the low-dimensional latent
space.
</p>
<a href="http://arxiv.org/abs/2102.10461" target="_blank">arXiv:2102.10461</a> [<a href="http://arxiv.org/pdf/2102.10461" target="_blank">pdf</a>]

<h2>BSQ: Exploring Bit-Level Sparsity for Mixed-Precision Neural Network Quantization. (arXiv:2102.10462v1 [cs.LG])</h2>
<h3>Huanrui Yang, Lin Duan, Yiran Chen, Hai Li</h3>
<p>Mixed-precision quantization can potentially achieve the optimal tradeoff
between performance and compression rate of deep neural networks, and thus,
have been widely investigated. However, it lacks a systematic method to
determine the exact quantization scheme. Previous methods either examine only a
small manually-designed search space or utilize a cumbersome neural
architecture search to explore the vast search space. These approaches cannot
lead to an optimal quantization scheme efficiently. This work proposes
bit-level sparsity quantization (BSQ) to tackle the mixed-precision
quantization from a new angle of inducing bit-level sparsity. We consider each
bit of quantized weights as an independent trainable variable and introduce a
differentiable bit-sparsity regularizer. BSQ can induce all-zero bits across a
group of weight elements and realize the dynamic precision reduction, leading
to a mixed-precision quantization scheme of the original model. Our method
enables the exploration of the full mixed-precision space with a single
gradient-based optimization process, with only one hyperparameter to tradeoff
the performance and compression. BSQ achieves both higher accuracy and higher
bit reduction on various model architectures on the CIFAR-10 and ImageNet
datasets comparing to previous methods.
</p>
<a href="http://arxiv.org/abs/2102.10462" target="_blank">arXiv:2102.10462</a> [<a href="http://arxiv.org/pdf/2102.10462" target="_blank">pdf</a>]

<h2>Learning Neural Network Subspaces. (arXiv:2102.10472v1 [cs.LG])</h2>
<h3>Mitchell Wortsman, Maxwell Horton, Carlos Guestrin, Ali Farhadi, Mohammad Rastegari</h3>
<p>Recent observations have advanced our understanding of the neural network
optimization landscape, revealing the existence of (1) paths of high accuracy
containing diverse solutions and (2) wider minima offering improved
performance. Previous methods observing diverse paths require multiple training
runs. In contrast we aim to leverage both property (1) and (2) with a single
method and in a single training run. With a similar computational cost as
training one model, we learn lines, curves, and simplexes of high-accuracy
neural networks. These neural network subspaces contain diverse solutions that
can be ensembled, approaching the ensemble performance of independently trained
networks without the training cost. Moreover, using the subspace midpoint
boosts accuracy, calibration, and robustness to label noise, outperforming
Stochastic Weight Averaging.
</p>
<a href="http://arxiv.org/abs/2102.10472" target="_blank">arXiv:2102.10472</a> [<a href="http://arxiv.org/pdf/2102.10472" target="_blank">pdf</a>]

<h2>A Deep Learning-based Method to Extract Lumen and Media-Adventitia in Intravascular Ultrasound Images. (arXiv:2102.10480v1 [cs.CV])</h2>
<h3>Fubao Zhu, Zhengyuan Gao, Chen Zhao, Hanlei Zhu, Yong Dong, Jingfeng Jiang, Neng Dai, Weihua Zhou</h3>
<p>Intravascular ultrasound (IVUS) imaging allows direct visualization of the
coronary vessel wall and is suitable for the assessment of atherosclerosis and
the degree of stenosis. Accurate segmentation and measurements of lumen and
median-adventitia (MA) from IVUS are essential for such a successful clinical
evaluation. However, current segmentation relies on manual operations, which is
time-consuming and user-dependent. In this paper, we aim to develop a deep
learning-based method using an encoder-decoder deep architecture to
automatically extract both lumen and MA border. Our method named IVUS-U-Net++
is an extension of the well-known U-Net++ model. More specifically, a feature
pyramid network was added to the U-Net++ model, enabling the utilization of
feature maps at different scales. As a result, the accuracy of the probability
map and subsequent segmentation have been improved We collected 1746 IVUS
images from 18 patients in this study. The whole dataset was split into a
training dataset (1572 images) for the 10-fold cross-validation and a test
dataset (174 images) for evaluating the performance of models. Our IVUS-U-Net++
segmentation model achieved a Jaccard measure (JM) of 0.9412, a Hausdorff
distance (HD) of 0.0639 mm for the lumen border, and a JM of 0.9509, an HD of
0.0867 mm for the MA border, respectively. Moreover, the Pearson correlation
and Bland-Altman analyses were performed to evaluate the correlations of 12
clinical parameters measured from our segmentation results and the ground
truth, and automatic measurements agreed well with those from the ground truth
(all Ps&lt;0.01). In conclusion, our preliminary results demonstrate that the
proposed IVUS-U-Net++ model has great promise for clinical use.
</p>
<a href="http://arxiv.org/abs/2102.10480" target="_blank">arXiv:2102.10480</a> [<a href="http://arxiv.org/pdf/2102.10480" target="_blank">pdf</a>]

<h2>CheXseg: Combining Expert Annotations with DNN-generated Saliency Maps for X-ray Segmentation. (arXiv:2102.10484v1 [cs.CV])</h2>
<h3>Soham Gadgil, Mark Endo, Emily Wen, Andrew Y. Ng, Pranav Rajpurkar</h3>
<p>Medical image segmentation models are typically supervised by expert
annotations at the pixel-level, which can be expensive to acquire. In this
work, we propose a method that combines the high quality of pixel-level expert
annotations with the scale of coarse DNN-generated saliency maps for training
multi-label semantic segmentation models. We demonstrate the application of our
semi-supervised method, which we call CheXseg, on multi-label chest x-ray
interpretation. We find that CheXseg improves upon the performance (mIoU) of
fully-supervised methods that use only pixel-level expert annotations by 13.4%
and weakly-supervised methods that use only DNN-generated saliency maps by
91.2%. Furthermore, we implement a semi-supervised method using knowledge
distillation and find that though it is outperformed by CheXseg, it exceeds the
performance (mIoU) of the best fully-supervised method by 4.83%. Our best
method is able to match radiologist agreement on three out of ten pathologies
and reduces the overall performance gap by 71.6% as compared to
weakly-supervised methods.
</p>
<a href="http://arxiv.org/abs/2102.10484" target="_blank">arXiv:2102.10484</a> [<a href="http://arxiv.org/pdf/2102.10484" target="_blank">pdf</a>]

<h2>Scalable Balanced Training of Conditional Generative Adversarial Neural Networks on Image Data. (arXiv:2102.10485v1 [cs.CV])</h2>
<h3>Massimiliano Lupo Pasini, Vittorio Gabbi, Junqi Yin, Simona Perotto, Nouamane Laanait</h3>
<p>We propose a distributed approach to train deep convolutional generative
adversarial neural network (DC-CGANs) models. Our method reduces the imbalance
between generator and discriminator by partitioning the training data according
to data labels, and enhances scalability by performing a parallel training
where multiple generators are concurrently trained, each one of them focusing
on a single data label. Performance is assessed in terms of inception score and
image quality on MNIST, CIFAR10, CIFAR100, and ImageNet1k datasets, showing a
significant improvement in comparison to state-of-the-art techniques to
training DC-CGANs. Weak scaling is attained on all the four datasets using up
to 1,000 processes and 2,000 NVIDIA V100 GPUs on the OLCF supercomputer Summit.
</p>
<a href="http://arxiv.org/abs/2102.10485" target="_blank">arXiv:2102.10485</a> [<a href="http://arxiv.org/pdf/2102.10485" target="_blank">pdf</a>]

<h2>Weak NAS Predictors Are All You Need. (arXiv:2102.10490v1 [cs.LG])</h2>
<h3>Junru Wu, Xiyang Dai, Dongdong Chen, Yinpeng Chen, Mengchen Liu, Ye Yu, Zhangyang Wang, Zicheng Liu, Mei Chen, Lu Yuan</h3>
<p>Neural Architecture Search (NAS) finds the best network architecture by
exploring the architecture-to-performance manifold. It often trains and
evaluates a large number of architectures, causing tremendous computation
costs. Recent predictor-based NAS approaches attempt to solve this problem with
two key steps: sampling some architecture-performance pairs and fitting a proxy
accuracy predictor. Given limited samples, these predictors, however, are far
from accurate to locate top architectures. In this paper, we shift the paradigm
from finding a complicated predictor that covers the whole architecture space
to a set of weaker predictors that progressively move towards the
high-performance sub-space. It is based on the key property of the proposed
weak predictors that their probabilities of sampling better architectures keep
increasing. We thus only sample a few well-performed architectures guided by
the previously learned predictor and estimate a new better weak predictor. By
this coarse-to-fine iteration, the ranking of sampling space is refined
gradually, which helps find the optimal architectures eventually. Experiments
demonstrate that our method costs fewer samples to find the top-performance
architectures on NAS-Bench-101 and NAS-Bench-201, and it achieves the
state-of-the-art ImageNet performance on the NASNet search space. The code is
available at https://github.com/VITA-Group/WeakNAS
</p>
<a href="http://arxiv.org/abs/2102.10490" target="_blank">arXiv:2102.10490</a> [<a href="http://arxiv.org/pdf/2102.10490" target="_blank">pdf</a>]

<h2>Deep ReLU Networks Preserve Expected Length. (arXiv:2102.10492v1 [stat.ML])</h2>
<h3>Boris Hanin, Ryan Jeong, David Rolnick</h3>
<p>Assessing the complexity of functions computed by a neural network helps us
understand how the network will learn and generalize. One natural measure of
complexity is how the network distorts length -- if the network takes a
unit-length curve as input, what is the length of the resulting curve of
outputs? It has been widely believed that this length grows exponentially in
network depth. We prove that in fact this is not the case: the expected length
distortion does not grow with depth, and indeed shrinks slightly, for ReLU
networks with standard random initialization. We also generalize this result by
proving upper bounds both for higher moments of the length distortion and for
the distortion of higher-dimensional volumes. These theoretical results are
corroborated by our experiments, which indicate that length distortion remains
modest even after training.
</p>
<a href="http://arxiv.org/abs/2102.10492" target="_blank">arXiv:2102.10492</a> [<a href="http://arxiv.org/pdf/2102.10492" target="_blank">pdf</a>]

<h2>Learning Deep Features for Shape Correspondence with Domain Invariance. (arXiv:2102.10493v1 [cs.CV])</h2>
<h3>Praful Agrawal, Ross T. Whitaker, Shireen Y. Elhabian</h3>
<p>Correspondence-based shape models are key to various medical imaging
applications that rely on a statistical analysis of anatomies. Such shape
models are expected to represent consistent anatomical features across the
population for population-specific shape statistics. Early approaches for
correspondence placement rely on nearest neighbor search for simpler anatomies.
Coordinate transformations for shape correspondence hold promise to address the
increasing anatomical complexities. Nonetheless, due to the inherent
shape-level geometric complexity and population-level shape variation, the
coordinate-wise correspondence often does not translate to the anatomical
correspondence. An alternative, group-wise approach for correspondence
placement explicitly models the trade-off between geometric description and the
population's statistical compactness. However, these models achieve limited
success in resolving nonlinear shape correspondence. Recent works have
addressed this limitation by adopting an application-specific notion of
correspondence through lifting positional data to a higher dimensional feature
space. However, they heavily rely on manual expertise to create domain-specific
features and consistent landmarks. This paper proposes an automated feature
learning approach, using deep convolutional neural networks to extract
correspondence-friendly features from shape ensembles. Further, an unsupervised
domain adaptation scheme is introduced to augment the pretrained geometric
features with new anatomies. Results on anatomical datasets of human scapula,
femur, and pelvis bones demonstrate that features learned in supervised fashion
show improved performance for correspondence estimation compared to the manual
features. Further, unsupervised learning is demonstrated to learn complex
anatomy features using the supervised domain adaptation from features learned
on simpler anatomy.
</p>
<a href="http://arxiv.org/abs/2102.10493" target="_blank">arXiv:2102.10493</a> [<a href="http://arxiv.org/pdf/2102.10493" target="_blank">pdf</a>]

<h2>Targeted Attack against Deep Neural Networks via Flipping Limited Weight Bits. (arXiv:2102.10496v1 [cs.LG])</h2>
<h3>Jiawang Bai, Baoyuan Wu, Yong Zhang, Yiming Li, Zhifeng Li, Shu-Tao Xia</h3>
<p>To explore the vulnerability of deep neural networks (DNNs), many attack
paradigms have been well studied, such as the poisoning-based backdoor attack
in the training stage and the adversarial attack in the inference stage. In
this paper, we study a novel attack paradigm, which modifies model parameters
in the deployment stage for malicious purposes. Specifically, our goal is to
misclassify a specific sample into a target class without any sample
modification, while not significantly reduce the prediction accuracy of other
samples to ensure the stealthiness. To this end, we formulate this problem as a
binary integer programming (BIP), since the parameters are stored as binary
bits ($i.e.$, 0 and 1) in the memory. By utilizing the latest technique in
integer programming, we equivalently reformulate this BIP problem as a
continuous optimization problem, which can be effectively and efficiently
solved using the alternating direction method of multipliers (ADMM) method.
Consequently, the flipped critical bits can be easily determined through
optimization, rather than using a heuristic strategy. Extensive experiments
demonstrate the superiority of our method in attacking DNNs.
</p>
<a href="http://arxiv.org/abs/2102.10496" target="_blank">arXiv:2102.10496</a> [<a href="http://arxiv.org/pdf/2102.10496" target="_blank">pdf</a>]

<h2>A Hierarchical Conditional Random Field-based Attention Mechanism Approach for Gastric Histopathology Image Classification. (arXiv:2102.10499v1 [cs.CV])</h2>
<h3>Yixin Li, Xinran Wu, Chen Li, Changhao Sun, Md Rahaman, Yudong Yao, Xiaoyan Li, Yong Zhang, Tao Jiang</h3>
<p>In the Gastric Histopathology Image Classification (GHIC) tasks, which is
usually weakly supervised learning missions, there is inevitably redundant
information in the images. Therefore, designing networks that can focus on
effective distinguishing features has become a popular research topic. In this
paper, to accomplish the tasks of GHIC superiorly and to assist pathologists in
clinical diagnosis, an intelligent Hierarchical Conditional Random Field based
Attention Mechanism (HCRF-AM) model is proposed. The HCRF-AM model consists of
an Attention Mechanism (AM) module and an Image Classification (IC) module. In
the AM module, an HCRF model is built to extract attention regions. In the IC
module, a Convolutional Neural Network (CNN) model is trained with the
attention regions selected and then an algorithm called Classification
Probability-based Ensemble Learning is applied to obtain the image-level
results from patch-level output of the CNN. In the experiment, a classification
specificity of 96.67% is achieved on a gastric histopathology dataset with 700
images. Our HCRF-AM model demonstrates high classification performance and
shows its effectiveness and future potential in the GHIC field.
</p>
<a href="http://arxiv.org/abs/2102.10499" target="_blank">arXiv:2102.10499</a> [<a href="http://arxiv.org/pdf/2102.10499" target="_blank">pdf</a>]

<h2>Predicting Future Cognitive Decline with Hyperbolic Stochastic Coding. (arXiv:2102.10503v1 [cs.CV])</h2>
<h3>J. Zhang, Q. Dong, J. Shi, Q. Li, C.M. Stonnington, B.A. Gutman, K. Chen, E.M. Reiman, R.J. Caselli, P.M. Thompson, J. Ye, Y. Wang</h3>
<p>Hyperbolic geometry has been successfully applied in modeling brain cortical
and subcortical surfaces with general topological structures. However such
approaches, similar to other surface based brain morphology analysis methods,
usually generate high dimensional features. It limits their statistical power
in cognitive decline prediction research, especially in datasets with limited
subject numbers. To address the above limitation, we propose a novel framework
termed as hyperbolic stochastic coding (HSC). Our preliminary experimental
results show that our algorithm achieves superior results on various
classification tasks. Our work may enrich surface based brain imaging research
tools and potentially result in a diagnostic and prognostic indicator to be
useful in individualized treatment strategies.
</p>
<a href="http://arxiv.org/abs/2102.10503" target="_blank">arXiv:2102.10503</a> [<a href="http://arxiv.org/pdf/2102.10503" target="_blank">pdf</a>]

<h2>Progressive Depth Learning for Single Image Dehazing. (arXiv:2102.10514v1 [cs.CV])</h2>
<h3>Yudong Liang, Bin Wang, Jiaying Liu, Deyu Li, Sanping Zhou, Wenqi Ren</h3>
<p>The formulation of the hazy image is mainly dominated by the reflected lights
and ambient airlight. Existing dehazing methods often ignore the depth cues and
fail in distant areas where heavier haze disturbs the visibility. However, we
note that the guidance of the depth information for transmission estimation
could remedy the decreased visibility as distances increase. In turn, the good
transmission estimation could facilitate the depth estimation for hazy images.
In this paper, a deep end-to-end model that iteratively estimates image depths
and transmission maps is proposed to perform an effective depth prediction for
hazy images and improve the dehazing performance with the guidance of depth
information. The image depth and transmission map are progressively refined to
better restore the dehazed image. Our approach benefits from explicitly
modeling the inner relationship of image depth and transmission map, which is
especially effective for distant hazy areas. Extensive results on the
benchmarks demonstrate that our proposed network performs favorably against the
state-of-the-art dehazing methods in terms of depth estimation and haze
removal.
</p>
<a href="http://arxiv.org/abs/2102.10514" target="_blank">arXiv:2102.10514</a> [<a href="http://arxiv.org/pdf/2102.10514" target="_blank">pdf</a>]

<h2>A Deep Decomposition Network for Image Processing: A Case Study for Visible and Infrared Image Fusion. (arXiv:2102.10526v1 [cs.CV])</h2>
<h3>Yu Fu, Xiao-Jun Wu, Josef Kittler</h3>
<p>Image decomposition is a crucial subject in the field of image processing. It
can extract salient features from the source image. We propose a new image
decomposition method based on convolutional neural network. This method can be
applied to many image processing tasks. In this paper, we apply the image
decomposition network to the image fusion task. We input infrared image and
visible light image and decompose them into three high-frequency feature images
and a low-frequency feature image respectively. The two sets of feature images
are fused using a specific fusion strategy to obtain fusion feature images.
Finally, the feature images are reconstructed to obtain the fused image.
Compared with the state-of-the-art fusion methods, this method has achieved
better performance in both subjective and objective evaluation.
</p>
<a href="http://arxiv.org/abs/2102.10526" target="_blank">arXiv:2102.10526</a> [<a href="http://arxiv.org/pdf/2102.10526" target="_blank">pdf</a>]

<h2>Empirical Sufficiency Featuring Reward Delay Calibration. (arXiv:2102.10527v1 [cs.LG])</h2>
<h3>Yixuan Liu, Hu Wang, Xiaowei Wang, Xiaoyue Sun, Liuyue Jiang, Minhui Xue</h3>
<p>Appropriate credit assignment for delay rewards is a fundamental challenge
for reinforcement learning. To tackle this problem, we introduce a delay reward
calibration paradigm inspired from a classification perspective. We hypothesize
that well-represented state vectors share similarities with each other since
they contain the same or equivalent essential information. To this end, we
define an empirical sufficient distribution, where the state vectors within the
distribution will lead agents to environmental reward signals in the consequent
steps. Therefore, a purify-trained classifier is designed to obtain the
distribution and generate the calibrated rewards. We examine the correctness of
sufficient state extraction by tracking the real-time extraction and building
different reward functions in environments. The results demonstrate that the
classifier could generate timely and accurate calibrated rewards. Moreover, the
rewards are able to make the model training process more efficient. Finally, we
identify and discuss that the sufficient states extracted by our model resonate
with the observations of humans.
</p>
<a href="http://arxiv.org/abs/2102.10527" target="_blank">arXiv:2102.10527</a> [<a href="http://arxiv.org/pdf/2102.10527" target="_blank">pdf</a>]

<h2>The Effects of Image Distribution and Task on Adversarial Robustness. (arXiv:2102.10534v1 [cs.LG])</h2>
<h3>Owen Kunhardt, Arturo Deza, Tomaso Poggio</h3>
<p>In this paper, we propose an adaptation to the area under the curve (AUC)
metric to measure the adversarial robustness of a model over a particular
$\epsilon$-interval $[\epsilon_0, \epsilon_1]$ (interval of adversarial
perturbation strengths) that facilitates unbiased comparisons across models
when they have different initial $\epsilon_0$ performance. This can be used to
determine how adversarially robust a model is to different image distributions
or task (or some other variable); and/or to measure how robust a model is
comparatively to other models. We used this adversarial robustness metric on
models of an MNIST, CIFAR-10, and a Fusion dataset (CIFAR-10 + MNIST) where
trained models performed either a digit or object recognition task using a
LeNet, ResNet50, or a fully connected network (FullyConnectedNet) architecture
and found the following: 1) CIFAR-10 models are inherently less adversarially
robust than MNIST models; 2) Both the image distribution and task that a model
is trained on can affect the adversarial robustness of the resultant model. 3)
Pretraining with a different image distribution and task sometimes carries over
the adversarial robustness induced by that image distribution and task in the
resultant model; Collectively, our results imply non-trivial differences of the
learned representation space of one perceptual system over another given its
exposure to different image statistics or tasks (mainly objects vs digits).
Moreover, these results hold even when model systems are equalized to have the
same level of performance, or when exposed to approximately matched image
statistics of fusion images but with different tasks.
</p>
<a href="http://arxiv.org/abs/2102.10534" target="_blank">arXiv:2102.10534</a> [<a href="http://arxiv.org/pdf/2102.10534" target="_blank">pdf</a>]

<h2>Do Generative Models Know Disentanglement? Contrastive Learning is All You Need. (arXiv:2102.10543v1 [cs.CV])</h2>
<h3>Xuanchi Ren, Tao Yang, Yuwang Wang, Wenjun Zeng</h3>
<p>Disentangled generative models are typically trained with an extra
regularization term, which encourages the traversal of each latent factor to
make a distinct and independent change at the cost of generation quality. When
traversing the latent space of generative models trained without the
disentanglement term, the generated samples show semantically meaningful
change, raising the question: do generative models know disentanglement? We
propose an unsupervised and model-agnostic method: Disentanglement via Contrast
(DisCo) in the Variation Space. DisCo consists of: (i) a Navigator providing
traversal directions in the latent space, and (ii) a $\Delta$-Contrastor
composed of two shared-weight Encoders, which encode image pairs along these
directions to disentangled representations respectively, and a difference
operator to map the encoded representations to the Variation Space. We propose
two more key techniques for DisCo: entropy-based domination loss to make the
encoded representations more disentangled and the strategy of flipping hard
negatives to address directions with the same semantic meaning. By optimizing
the Navigator to discover disentangled directions in the latent space and
Encoders to extract disentangled representations from images with Contrastive
Learning, DisCo achieves the state-of-the-art disentanglement given pretrained
non-disentangled generative models, including GAN, VAE, and Flow. Project page
at https://github.com/xrenaa/DisCo.
</p>
<a href="http://arxiv.org/abs/2102.10543" target="_blank">arXiv:2102.10543</a> [<a href="http://arxiv.org/pdf/2102.10543" target="_blank">pdf</a>]

<h2>Rethinking Content and Style: Exploring Bias for Unsupervised Disentanglement. (arXiv:2102.10544v1 [cs.CV])</h2>
<h3>Xuanchi Ren, Tao Yang, Yuwang Wang, Wenjun Zeng</h3>
<p>Content and style (C-S) disentanglement intends to decompose the underlying
explanatory factors of objects into two independent subspaces. From the
unsupervised disentanglement perspective, we rethink content and style and
propose a formulation for unsupervised C-S disentanglement based on our
assumption that different factors are of different importance and popularity
for image reconstruction, which serves as a data bias. The corresponding model
inductive bias is introduced by our proposed C-S disentanglement Module (C-S
DisMo), which assigns different and independent roles to content and style when
approximating the real data distributions. Specifically, each content embedding
from the dataset, which encodes the most dominant factors for image
reconstruction, is assumed to be sampled from a shared distribution across the
dataset. The style embedding for a particular image, encoding the remaining
factors, is used to customize the shared distribution through an affine
transformation. The experiments on several popular datasets demonstrate that
our method achieves the state-of-the-art unsupervised C-S disentanglement,
which is comparable or even better than supervised methods. We verify the
effectiveness of our method by downstream tasks: domain translation and
single-view 3D reconstruction. Project page at
https://github.com/xrenaa/CS-DisMo.
</p>
<a href="http://arxiv.org/abs/2102.10544" target="_blank">arXiv:2102.10544</a> [<a href="http://arxiv.org/pdf/2102.10544" target="_blank">pdf</a>]

<h2>Uncertainty-Aware Deep Learning for Autonomous Safe Landing Site Selection. (arXiv:2102.10545v1 [cs.RO])</h2>
<h3>Kento Tomita, Katherine A. Skinner, Koki Ho</h3>
<p>Hazard detection is critical for enabling autonomous landing on planetary
surfaces. Current state-of-the-art methods leverage traditional computer vision
approaches to automate identification of safe terrain from input digital
elevation models (DEMs). However, performance for these methods can degrade for
input DEMs with increased sensor noise. At the same time, deep learning
techniques have been developed for various applications. Nevertheless, their
applicability to safety-critical space missions has been often limited due to
concerns regarding their outputs' reliability. In response to this background,
this paper proposes an uncertainty-aware learning-based method for hazard
detection and landing site selection. The developed approach enables reliable
safe landing site selection by: (i) generating a safety prediction map and its
uncertainty map together via Bayesian deep learning and semantic segmentation;
and (ii) using the generated uncertainty map to filter out the uncertain pixels
in the prediction map so that the safe landing site selection is performed only
based on the certain pixels (i.e., pixels for which the model is certain about
its safety prediction). Experiments are presented with simulated data based on
a Mars HiRISE digital terrain model and varying noise levels to demonstrate the
performance of the proposed approach.
</p>
<a href="http://arxiv.org/abs/2102.10545" target="_blank">arXiv:2102.10545</a> [<a href="http://arxiv.org/pdf/2102.10545" target="_blank">pdf</a>]

<h2>Delhi air quality prediction using LSTM deep learning models with a focus on COVID-19 lockdown. (arXiv:2102.10551v1 [cs.LG])</h2>
<h3>Animesh Tiwari, Rishabh Gupta, Rohitash Chandra</h3>
<p>Air pollution has a wide range of implications on agriculture, economy, road
accidents, and health. In this paper, we use novel deep learning methods for
short-term (multi-step-ahead) air-quality prediction in selected parts of
Delhi, India. Our deep learning methods comprise of long short-term memory
(LSTM) network models which also include some recent versions such as
bidirectional-LSTM and encoder-decoder LSTM models. We use a multivariate time
series approach that attempts to predict air quality for 10 prediction horizons
covering total of 80 hours and provide a long-term (one month ahead) forecast
with uncertainties quantified. Our results show that the multivariate
bidirectional-LSTM model provides best predictions despite COVID-19 impact on
the air-quality during full and partial lockdown periods. The effect of
COVID-19 on the air quality has been significant during full lockdown; however,
there was unprecedented growth of poor air quality afterwards.
</p>
<a href="http://arxiv.org/abs/2102.10551" target="_blank">arXiv:2102.10551</a> [<a href="http://arxiv.org/pdf/2102.10551" target="_blank">pdf</a>]

<h2>A Comprehensive Review of Computer-aided Whole-slide Image Analysis: from Datasets to Feature Extraction, Segmentation, Classification, and Detection Approaches. (arXiv:2102.10553v1 [cs.CV])</h2>
<h3>Chen Li, Xintong Li, Md Rahaman, Xiaoyan Li, Hongzan Sun, Hong Zhang, Yong Zhang, Xiaoqi Li, Jian Wu, Yudong Yao, Marcin Grzegorzek</h3>
<p>With the development of computer-aided diagnosis (CAD) and image scanning
technology, Whole-slide Image (WSI) scanners are widely used in the field of
pathological diagnosis. Therefore, WSI analysis has become the key to modern
digital pathology. Since 2004, WSI has been used more and more in CAD. Since
machine vision methods are usually based on semi-automatic or fully automatic
computers, they are highly efficient and labor-saving. The combination of WSI
and CAD technologies for segmentation, classification, and detection helps
histopathologists obtain more stable and quantitative analysis results, save
labor costs and improve diagnosis objectivity. This paper reviews the methods
of WSI analysis based on machine learning. Firstly, the development status of
WSI and CAD methods are introduced. Secondly, we discuss publicly available WSI
datasets and evaluation metrics for segmentation, classification, and detection
tasks. Then, the latest development of machine learning in WSI segmentation,
classification, and detection are reviewed continuously. Finally, the existing
methods are studied, the applicabilities of the analysis methods are analyzed,
and the application prospects of the analysis methods in this field are
forecasted.
</p>
<a href="http://arxiv.org/abs/2102.10553" target="_blank">arXiv:2102.10553</a> [<a href="http://arxiv.org/pdf/2102.10553" target="_blank">pdf</a>]

<h2>Improving Action Quality Assessment using ResNets and Weighted Aggregation. (arXiv:2102.10555v1 [cs.CV])</h2>
<h3>Shafkat Farabi, Hasibul Haque Himel, Fakhruddin Gazzali, Bakhtiar Hasan, Md. Hasanul Kabir, Moshiur Farazi</h3>
<p>Action quality assessment (AQA) aims at automatically judging human action
based on a video of the said action and assigning a performance score to it.
The majority of works in the existing literature on AQA transform RGB videos to
higher-level representations using C3D networks. These higher-level
representations are used to perform action quality assessment. Due to the
relatively shallow nature of C3D, the quality of extracted features is lower
than what could be extracted using a deeper convolutional neural network. In
this paper, we experiment with deeper convolutional neural networks with
residual connections for learning representations for action quality
assessment. We assess the effects of the depth and the input clip size of the
convolutional neural network on the quality of action score predictions. We
also look at the effect of using (2+1)D convolutions instead of 3D convolutions
for feature extraction. We find that the current clip level feature
representation aggregation technique of averaging is insufficient to capture
the relative importance of features. To overcome this, we propose a
learning-based weighted-averaging technique that can perform better. We achieve
a new state-of-the-art Spearman's rank correlation of 0.9315 (an increase of
0.45%) on the MTL-AQA dataset using a 34 layer (2+1)D convolutional neural
network with the capability of processing 32 frame clips, using our proposed
aggregation technique.
</p>
<a href="http://arxiv.org/abs/2102.10555" target="_blank">arXiv:2102.10555</a> [<a href="http://arxiv.org/pdf/2102.10555" target="_blank">pdf</a>]

<h2>Inductive logic programming at 30. (arXiv:2102.10556v1 [cs.AI])</h2>
<h3>Andrew Cropper, Sebastijan Duman&#x10d;i&#x107;, Richard Evans, Stephen H. Muggleton</h3>
<p>Inductive logic programming (ILP) is a form of logic-based machine learning.
The goal of ILP is to induce a hypothesis (a logic program) that generalises
given training examples and background knowledge. As ILP turns 30, we survey
recent work in the field. In this survey, we focus on (i) new meta-level search
methods, (ii) techniques for learning recursive programs that generalise from
few examples, (iii) new approaches for predicate invention, and (iv) the use of
different technologies, notably answer set programming and neural networks. We
conclude by discussing some of the current limitations of ILP and discuss
directions for future research.
</p>
<a href="http://arxiv.org/abs/2102.10556" target="_blank">arXiv:2102.10556</a> [<a href="http://arxiv.org/pdf/2102.10556" target="_blank">pdf</a>]

<h2>Contrastive Self-supervised Neural Architecture Search. (arXiv:2102.10557v1 [cs.CV])</h2>
<h3>Nam Nguyen, J. Morris Chang</h3>
<p>This paper proposes a novel cell-based neural architecture search algorithm
(NAS), which completely alleviates the expensive costs of data labeling
inherited from supervised learning. Our algorithm capitalizes on the
effectiveness of self-supervised learning for image representations, which is
an increasingly crucial topic of computer vision. First, using only a small
amount of unlabeled train data under contrastive self-supervised learning allow
us to search on a more extensive search space, discovering better neural
architectures without surging the computational resources. Second, we entirely
relieve the cost for labeled data (by contrastive loss) in the search stage
without compromising architectures' final performance in the evaluation phase.
Finally, we tackle the inherent discrete search space of the NAS problem by
sequential model-based optimization via the tree-parzen estimator (SMBO-TPE),
enabling us to reduce the computational expense response surface significantly.
An extensive number of experiments empirically show that our search algorithm
can achieve state-of-the-art results with better efficiency in data labeling
cost, searching time, and accuracy in final validation.
</p>
<a href="http://arxiv.org/abs/2102.10557" target="_blank">arXiv:2102.10557</a> [<a href="http://arxiv.org/pdf/2102.10557" target="_blank">pdf</a>]

<h2>Tractable Computation of Expected Kernels by Circuits. (arXiv:2102.10562v1 [cs.LG])</h2>
<h3>Wenzhe Li, Zhe Zeng, Antonio Vergari, Guy Van den Broeck</h3>
<p>Computing the expectation of some kernel function is ubiquitous in machine
learning, from the classical theory of support vector machines, to exploiting
kernel embeddings of distributions in applications ranging from probabilistic
modeling, statistical inference, casual discovery, and deep learning. In all
these scenarios, we tend to resort to Monte Carlo estimates as expectations of
kernels are intractable in general. In this work, we characterize the
conditions under which we can compute expected kernels exactly and efficiently,
by leveraging recent advances in probabilistic circuit representations. We
first construct a circuit representation for kernels and propose an approach to
such tractable computation. We then demonstrate possible advancements for
kernel embedding frameworks by exploiting tractable expected kernels to derive
new algorithms for two challenging scenarios: 1) reasoning under missing data
with kernel support vector regressors; 2) devising a collapsed black-box
importance sampling scheme. Finally, we empirically evaluate both algorithms
and show that they outperform standard baselines on a variety of datasets.
</p>
<a href="http://arxiv.org/abs/2102.10562" target="_blank">arXiv:2102.10562</a> [<a href="http://arxiv.org/pdf/2102.10562" target="_blank">pdf</a>]

<h2>Symbolic regression for scientific discovery: an application to wind speed forecasting. (arXiv:2102.10570v1 [cs.LG])</h2>
<h3>Ismail Alaoui Abdellaoui, Siamak Mehrkanoon</h3>
<p>Symbolic regression corresponds to an ensemble of techniques that allow to
uncover an analytical equation from data. Through a closed form formula, these
techniques provide great advantages such as potential scientific discovery of
new laws, as well as explainability, feature engineering as well as fast
inference. Similarly, deep learning based techniques has shown an extraordinary
ability of modeling complex patterns. The present paper aims at applying a
recent end-to-end symbolic regression technique, i.e. the equation learner
(EQL), to get an analytical equation for wind speed forecasting. We show that
it is possible to derive an analytical equation that can achieve reasonable
accuracy for short term horizons predictions only using few number of features.
</p>
<a href="http://arxiv.org/abs/2102.10570" target="_blank">arXiv:2102.10570</a> [<a href="http://arxiv.org/pdf/2102.10570" target="_blank">pdf</a>]

<h2>Learning Compositional Representation for Few-shot Visual Question Answering. (arXiv:2102.10575v1 [cs.CV])</h2>
<h3>Dalu Guo, Dacheng Tao</h3>
<p>Current methods of Visual Question Answering perform well on the answers with
an amount of training data but have limited accuracy on the novel ones with few
examples. However, humans can quickly adapt to these new categories with just a
few glimpses, as they learn to organize the concepts that have been seen before
to figure the novel class, which are hardly explored by the deep learning
methods. Therefore, in this paper, we propose to extract the attributes from
the answers with enough data, which are later composed to constrain the
learning of the few-shot ones. We generate the few-shot dataset of VQA with a
variety of answers and their attributes without any human effort. With this
dataset, we build our attribute network to disentangle the attributes by
learning their features from parts of the image instead of the whole one.
Experimental results on the VQA v2.0 validation dataset demonstrate the
effectiveness of our proposed attribute network and the constraint between
answers and their corresponding attributes, as well as the ability of our
method to handle the answers with few training examples.
</p>
<a href="http://arxiv.org/abs/2102.10575" target="_blank">arXiv:2102.10575</a> [<a href="http://arxiv.org/pdf/2102.10575" target="_blank">pdf</a>]

<h2>Patterns of Cognition: Cognitive Algorithms as Galois Connections Fulfilled by Chronomorphisms On Probabilistically Typed Metagraphs. (arXiv:2102.10581v1 [cs.AI])</h2>
<h3>Ben Goertzel</h3>
<p>It is argued that a broad class of AGI-relevant algorithms can be expressed
in a common formal framework, via specifying Galois connections linking search
and optimization processes on directed metagraphs whose edge targets are
labeled with probabilistic dependent types, and then showing these connections
are fulfilled by processes involving metagraph chronomorphisms. Examples are
drawn from the core cognitive algorithms used in the OpenCog AGI framework:
Probabilistic logical inference, evolutionary program learning, pattern mining,
agglomerative clustering, pattern mining and nonlinear-dynamical attention
allocation.

The analysis presented involves representing these cognitive algorithms as
recursive discrete decision processes involving optimizing functions defined
over metagraphs, in which the key decisions involve sampling from probability
distributions over metagraphs and enacting sets of combinatory operations on
selected sub-metagraphs. The mutual associativity of the combinatory operations
involved in a cognitive process is shown to often play a key role in enabling
the decomposition of the process into folding and unfolding operations; a
conclusion that has some practical implications for the particulars of
cognitive processes, e.g. militating toward use of reversible logic and
reversible program execution. It is also observed that where this mutual
associativity holds, there is an alignment between the hierarchy of subgoals
used in recursive decision process execution and a hierarchy of subpatterns
definable in terms of formal pattern theory.
</p>
<a href="http://arxiv.org/abs/2102.10581" target="_blank">arXiv:2102.10581</a> [<a href="http://arxiv.org/pdf/2102.10581" target="_blank">pdf</a>]

<h2>Mapping Surgeon's Hand/Finger Motion During Conventional Microsurgery to Enhance Intuitive Surgical Robot Teleoperation. (arXiv:2102.10585v1 [cs.RO])</h2>
<h3>Mohammad Fattahi Sani, Raimondo Ascione, Sanja Dogramadzi</h3>
<p>Purpose: Recent developments in robotics and artificial intelligence (AI)
have led to significant advances in healthcare technologies enhancing
robot-assisted minimally invasive surgery (RAMIS) in some surgical specialties.
However, current human-robot interfaces lack intuitive teleoperation and cannot
mimic surgeon's hand/finger sensing and fine motion. These limitations make
tele-operated robotic surgery not suitable for micro-surgery and difficult to
learn for established surgeons. We report a pilot study showing an intuitive
way of recording and mapping surgeon's gross hand motion and the fine synergic
motion during cardiac micro-surgery as a way to enhance future intuitive
teleoperation. Methods: We set to develop a prototype system able to train a
Deep Neural Net-work (DNN) by mapping wrist, hand and surgical tool real-time
data acquisition(RTDA) inputs during mock-up heart micro-surgery procedures.
The trained network was used to estimate the tools poses from refined hand
joint angles. Results: Based on surgeon's feedback during mock micro-surgery,
the developed wearable system with light-weight sensors for motion tracking did
not interfere with the surgery and instrument handling. The wearable motion
tracking system used 15 finger-thumb-wrist joint angle sensors to generate
meaningful data-sets representing inputs of the DNN network with new hand joint
angles added as necessary based on comparing the estimated tool poses against
measured tool pose. The DNN architecture was optimized for the highest
estimation accuracy and the ability to determine the tool pose with the least
mean squared error. This novel approach showed that the surgical instrument's
pose, an essential requirement for teleoperation, can be accurately estimated
from recorded surgeon's hand/finger movements with a mean squared error (MSE)
less than 0.3%
</p>
<a href="http://arxiv.org/abs/2102.10585" target="_blank">arXiv:2102.10585</a> [<a href="http://arxiv.org/pdf/2102.10585" target="_blank">pdf</a>]

<h2>Efficient Two-Stream Network for Violence Detection Using Separable Convolutional LSTM. (arXiv:2102.10590v1 [cs.CV])</h2>
<h3>Zahidul Islam, Mohammad Rukonuzzaman, Raiyan Ahmed, Md. Hasanul Kabir, Moshiur Farazi</h3>
<p>Automatically detecting violence from surveillance footage is a subset of
activity recognition that deserves special attention because of its wide
applicability in unmanned security monitoring systems, internet video
filtration, etc. In this work, we propose an efficient two-stream deep learning
architecture leveraging Separable Convolutional LSTM (SepConvLSTM) and
pre-trained MobileNet where one stream takes in background suppressed frames as
inputs and other stream processes difference of adjacent frames. We employed
simple and fast input pre-processing techniques that highlight the moving
objects in the frames by suppressing non-moving backgrounds and capture the
motion in-between frames. As violent actions are mostly characterized by body
movements these inputs help produce discriminative features. SepConvLSTM is
constructed by replacing convolution operation at each gate of ConvLSTM with a
depthwise separable convolution that enables producing robust long-range
Spatio-temporal features while using substantially fewer parameters. We
experimented with three fusion methods to combine the output feature maps of
the two streams. Evaluation of the proposed methods was done on three standard
public datasets. Our model outperforms the accuracy on the larger and more
challenging RWF-2000 dataset by more than a 2% margin while matching
state-of-the-art results on the smaller datasets. Our experiments lead us to
conclude, the proposed models are superior in terms of both computational
efficiency and detection accuracy.
</p>
<a href="http://arxiv.org/abs/2102.10590" target="_blank">arXiv:2102.10590</a> [<a href="http://arxiv.org/pdf/2102.10590" target="_blank">pdf</a>]

<h2>Training custom modality-specific U-Net models with weak localizations for improved Tuberculosis segmentation and localization. (arXiv:2102.10607v1 [cs.CV])</h2>
<h3>Sivaramakrishnan Rajaraman, Les Folio, Jane Dimperio, Philip Alderson, Sameer Antani</h3>
<p>UNet segmentation models have demonstrated superior performance compared to
conventional handcrafted features. Modality specific DL models are better at
transferring domain knowledge to a relevant target task than those that are
pretrained on stock photography images. Using them helps improve model
adaptation, generalization, and class-specific region of interest localization.
In this study, we train custom chest X ray modality specific UNet models for
semantic segmentation of Tuberculosis (TB) consistent findings. Automated
segmentation of such manifestations could help radiologists reduce errors
following initial interpretation and before finalizing the report. This could
improve radiologist accuracy by supplementing decision making while improving
patient care and productivity. Our approach uses a comprehensive strategy that
first uses publicly available chest X ray datasets with weak TB annotations,
typically provided as bounding boxes, to train a set of UNet models. Next, we
improve the results of the best performing model using an augmented training
strategy on data with weak localizations from the outputs of a selection of DL
classifiers that are trained to produce a binary decision ROI mask for
suspected TB manifestations. The augmentation aims to improve performance with
test data derived from the same training distribution and other cross
institutional collections. We observe that compared to non augmented training
our augmented training strategy helped the custom modality specific UNet models
achieve superior performance with test data that is both similar to the
training distribution as well as for cross institutional test sets.
</p>
<a href="http://arxiv.org/abs/2102.10607" target="_blank">arXiv:2102.10607</a> [<a href="http://arxiv.org/pdf/2102.10607" target="_blank">pdf</a>]

<h2>Dealing with Non-Stationarity in Multi-Agent Reinforcement Learning via Trust Region Decomposition. (arXiv:2102.10616v1 [cs.LG])</h2>
<h3>Wenhao Li, Xiangfeng Wang, Bo Jin, Junjie Sheng, Hongyuan Zha</h3>
<p>Non-stationarity is one thorny issue in multi-agent reinforcement learning,
which is caused by the policy changes of agents during the learning procedure.
Current works to solve this problem have their own limitations in effectiveness
and scalability, such as centralized critic and decentralized actor (CCDA),
population-based self-play, modeling of others and etc. In this paper, we
novelly introduce a $\delta$-stationarity measurement to explicitly model the
stationarity of a policy sequence, which is theoretically proved to be
proportional to the joint policy divergence. However, simple policy
factorization like mean-field approximation will mislead to larger policy
divergence, which can be considered as trust region decomposition dilemma. We
model the joint policy as a general Markov random field and propose a trust
region decomposition network based on message passing to estimate the joint
policy divergence more accurately. The Multi-Agent Mirror descent policy
algorithm with Trust region decomposition, called MAMT, is established with the
purpose to satisfy $\delta$-stationarity. MAMT can adjust the trust region of
the local policies adaptively in an end-to-end manner, thereby approximately
constraining the divergence of joint policy to alleviate the non-stationary
problem. Our method can bring noticeable and stable performance improvement
compared with baselines in coordination tasks of different complexity.
</p>
<a href="http://arxiv.org/abs/2102.10616" target="_blank">arXiv:2102.10616</a> [<a href="http://arxiv.org/pdf/2102.10616" target="_blank">pdf</a>]

<h2>Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. (arXiv:2102.10618v1 [cs.LG])</h2>
<h3>Sushant Agarwal, Shahin Jabbari, Chirag Agarwal, Sohini Upadhyay, Zhiwei Steven Wu, Himabindu Lakkaraju</h3>
<p>As machine learning black boxes are increasingly being deployed in critical
domains such as healthcare and criminal justice, there has been a growing
emphasis on developing techniques for explaining these black boxes in a post
hoc manner. In this work, we analyze two popular post hoc interpretation
techniques: SmoothGrad which is a gradient based method, and a variant of LIME
which is a perturbation based method. More specifically, we derive explicit
closed form expressions for the explanations output by these two methods and
show that they both converge to the same explanation in expectation, i.e., when
the number of perturbed samples used by these methods is large. We then
leverage this connection to establish other desirable properties, such as
robustness, for these techniques. We also derive finite sample complexity
bounds for the number of perturbations required for these methods to converge
to their expected explanation. Finally, we empirically validate our theory
using extensive experimentation on both synthetic and real world datasets.
</p>
<a href="http://arxiv.org/abs/2102.10618" target="_blank">arXiv:2102.10618</a> [<a href="http://arxiv.org/pdf/2102.10618" target="_blank">pdf</a>]

<h2>Safe Reinforcement Learning Using Robust Action Governor. (arXiv:2102.10643v1 [cs.LG])</h2>
<h3>Yutong Li, Nan Li, H. Eric Tseng, Anouck Girard, Dimitar Filev, Ilya Kolmanovsky</h3>
<p>Reinforcement Learning (RL) is essentially a trial-and-error learning
procedure which may cause unsafe behavior during the
exploration-and-exploitation process. This hinders the applications of RL to
real-world control problems, especially to those for safety-critical systems.
In this paper, we introduce a framework for safe RL that is based on
integration of an RL algorithm with an add-on safety supervision module, called
the Robust Action Governor (RAG), which exploits set-theoretic techniques and
online optimization to manage safety-related requirements during learning. We
illustrate this proposed safe RL framework through an application to automotive
adaptive cruise control.
</p>
<a href="http://arxiv.org/abs/2102.10643" target="_blank">arXiv:2102.10643</a> [<a href="http://arxiv.org/pdf/2102.10643" target="_blank">pdf</a>]

<h2>Medical Transformer: Gated Axial-Attention for Medical Image Segmentation. (arXiv:2102.10662v1 [cs.CV])</h2>
<h3>Jeya Maria Jose Valanarasu, Poojan Oza, Ilker Hacihaliloglu, Vishal M. Patel</h3>
<p>Over the past decade, Deep Convolutional Neural Networks have been widely
adopted for medical image segmentation and shown to achieve adequate
performance. However, due to the inherent inductive biases present in the
convolutional architectures, they lack understanding of long-range dependencies
in the image. Recently proposed Transformer-based architectures that leverage
self-attention mechanism encode long-range dependencies and learn
representations that are highly expressive. This motivates us to explore
Transformer-based solutions and study the feasibility of using
Transformer-based network architectures for medical image segmentation tasks.
Majority of existing Transformer-based network architectures proposed for
vision applications require large-scale datasets to train properly. However,
compared to the datasets for vision applications, for medical imaging the
number of data samples is relatively low, making it difficult to efficiently
train transformers for medical applications. To this end, we propose a Gated
Axial-Attention model which extends the existing architectures by introducing
an additional control mechanism in the self-attention module. Furthermore, to
train the model effectively on medical images, we propose a Local-Global
training strategy (LoGo) which further improves the performance. Specifically,
we operate on the whole image and patches to learn global and local features,
respectively. The proposed Medical Transformer (MedT) is evaluated on three
different medical image segmentation datasets and it is shown that it achieves
better performance than the convolutional and other related transformer-based
architectures. Code: https://github.com/jeya-maria-jose/Medical-Transformer
</p>
<a href="http://arxiv.org/abs/2102.10662" target="_blank">arXiv:2102.10662</a> [<a href="http://arxiv.org/pdf/2102.10662" target="_blank">pdf</a>]

<h2>MedAug: Contrastive learning leveraging patient metadata improves representations for chest X-ray interpretation. (arXiv:2102.10663v1 [cs.CV])</h2>
<h3>Yen Nhi Truong Vu, Richard Wang, Niranjan Balachandar, Can Liu, Andrew Y. Ng, Pranav Rajpurkar</h3>
<p>Self-supervised contrastive learning between pairs of multiple views of the
same image has been shown to successfully leverage unlabeled data to produce
meaningful visual representations for both natural and medical images. However,
there has been limited work on determining how to select pairs for medical
images, where availability of patient metadata can be leveraged to improve
representations. In this work, we develop a method to select positive pairs
coming from views of possibly different images through the use of patient
metadata. We compare strategies for selecting positive pairs for chest X-ray
interpretation including requiring them to be from the same patient, imaging
study or laterality. We evaluate downstream task performance by fine-tuning the
linear layer on 1% of the labeled dataset for pleural effusion classification.
Our best performing positive pair selection strategy, which involves using
images from the same patient from the same study across all lateralities,
achieves a performance increase of 3.4% and 14.4% in mean AUC from both a
previous contrastive method and ImageNet pretrained baseline respectively. Our
controlled experiments show that the keys to improving downstream performance
on disease classification are (1) using patient metadata to appropriately
create positive pairs from different images with the same underlying
pathologies, and (2) maximizing the number of different images used in query
pairing. In addition, we explore leveraging patient metadata to select hard
negative pairs for contrastive learning, but do not find improvement over
baselines that do not use metadata. Our method is broadly applicable to medical
image interpretation and allows flexibility for incorporating medical insights
in choosing pairs for contrastive learning.
</p>
<a href="http://arxiv.org/abs/2102.10663" target="_blank">arXiv:2102.10663</a> [<a href="http://arxiv.org/pdf/2102.10663" target="_blank">pdf</a>]

<h2>Transferable Visual Words: Exploiting the Semantics of Anatomical Patterns for Self-supervised Learning. (arXiv:2102.10680v1 [cs.CV])</h2>
<h3>Fatemeh Haghighi, Mohammad Reza Hosseinzadeh Taher, Zongwei Zhou, Michael B. Gotway, Jianming Liang</h3>
<p>This paper introduces a new concept called "transferable visual words"
(TransVW), aiming to achieve annotation efficiency for deep learning in medical
image analysis. Medical imaging--focusing on particular parts of the body for
defined clinical purposes--generates images of great similarity in anatomy
across patients and yields sophisticated anatomical patterns across images,
which are associated with rich semantics about human anatomy and which are
natural visual words. We show that these visual words can be automatically
harvested according to anatomical consistency via self-discovery, and that the
self-discovered visual words can serve as strong yet free supervision signals
for deep models to learn semantics-enriched generic image representation via
self-supervision (self-classification and self-restoration). Our extensive
experiments demonstrate the annotation efficiency of TransVW by offering higher
performance and faster convergence with reduced annotation cost in several
applications. Our TransVW has several important advantages, including (1)
TransVW is a fully autodidactic scheme, which exploits the semantics of visual
words for self-supervised learning, requiring no expert annotation; (2) visual
word learning is an add-on strategy, which complements existing self-supervised
methods, boosting their performance; and (3) the learned image representation
is semantics-enriched models, which have proven to be more robust and
generalizable, saving annotation efforts for a variety of applications through
transfer learning. Our code, pre-trained models, and curated visual words are
available at https://github.com/JLiangLab/TransVW.
</p>
<a href="http://arxiv.org/abs/2102.10680" target="_blank">arXiv:2102.10680</a> [<a href="http://arxiv.org/pdf/2102.10680" target="_blank">pdf</a>]

<h2>Probabilistic Vehicle Reconstruction Using a Multi-Task CNN. (arXiv:2102.10681v1 [cs.CV])</h2>
<h3>Max Coenen, Franz Rottensteiner</h3>
<p>The retrieval of the 3D pose and shape of objects from images is an ill-posed
problem. A common way to object reconstruction is to match entities such as
keypoints, edges, or contours of a deformable 3D model, used as shape prior, to
their corresponding entities inferred from the image. However, such approaches
are highly sensitive to model initialisation, imprecise keypoint localisations
and/or illumination conditions. In this paper, we present a probabilistic
approach for shape-aware 3D vehicle reconstruction from stereo images that
leverages the outputs of a novel multi-task CNN. Specifically, we train a CNN
that outputs probability distributions for the vehicle's orientation and for
both, vehicle keypoints and wireframe edges. Together with 3D stereo
information we integrate the predicted distributions into a common
probabilistic framework. We believe that the CNN-based detection of wireframe
edges reduces the sensitivity to illumination conditions and object contrast
and that using the raw probability maps instead of inferring keypoint positions
reduces the sensitivity to keypoint localisation errors. We show that our
method achieves state-of-the-art results, evaluating our method on the
challenging KITTI benchmark and on our own new 'Stereo-Vehicle' dataset.
</p>
<a href="http://arxiv.org/abs/2102.10681" target="_blank">arXiv:2102.10681</a> [<a href="http://arxiv.org/pdf/2102.10681" target="_blank">pdf</a>]

<h2>Synthesizing Irreproducibility in Deep Networks. (arXiv:2102.10696v1 [cs.LG])</h2>
<h3>Robert R. Snapp, Gil I. Shamir</h3>
<p>The success and superior performance of deep networks is spreading their
popularity and use to an increasing number of applications. Very recent works,
however, demonstrate that modern day deep networks suffer from
irreproducibility (also referred to as nondeterminism or underspecification).
Two or more models that are identical in architecture, structure, training
hyper-parameters, and parameters, and that are trained on exactly the same
training data, yield different predictions on individual previously unseen
examples. Thus, a model that performs well on controlled test data, may perform
in unexpected ways when deployed in the real world, whose data is expected to
be similar to the test data. We study simple synthetic models and data to
understand the origins of these problems. We show that even with a single
nonlinearity and for very simple data and models, irreproducibility occurs. Our
study demonstrates the effects of randomness in initialization, training data
shuffling window size, and activation functions on prediction
irreproducibility, even under very controlled synthetic data. While, as one
would expect, randomness in initialization and in shuffling the training
examples exacerbates the phenomenon, we show that model complexity and the
choice of nonlinearity also play significant roles in making deep models
irreproducible.
</p>
<a href="http://arxiv.org/abs/2102.10696" target="_blank">arXiv:2102.10696</a> [<a href="http://arxiv.org/pdf/2102.10696" target="_blank">pdf</a>]

<h2>Design, Integration and Sea Trials of 3D Printed Unmanned Aerial Vehicle and Unmanned Surface Vehicle for Cooperative Missions. (arXiv:2102.10709v1 [cs.RO])</h2>
<h3>Hanlin Niu, Ze Ji, Pietro Liguori, Hujun Yin, Joaquin Carrasco</h3>
<p>In recent years, Unmanned Surface Vehicles (USV) have been extensively
deployed for maritime applications. However, USV has a limited detection range
with sensor installed at the same elevation with the targets. In this research,
we propose a cooperative Unmanned Aerial Vehicle - Unmanned Surface Vehicle
(UAV-USV) platform to improve the detection range of USV. A floatable and
waterproof UAV is designed and 3D printed, which allows it to land on the sea.
A catamaran USV and landing platform are also developed. To land UAV on the USV
precisely in various lighting conditions, IR beacon detector and IR beacon are
implemented on the UAV and USV, respectively. Finally, a two-phase UAV precise
landing method, USV control algorithm and USV path following algorithm are
proposed and tested.
</p>
<a href="http://arxiv.org/abs/2102.10709" target="_blank">arXiv:2102.10709</a> [<a href="http://arxiv.org/pdf/2102.10709" target="_blank">pdf</a>]

<h2>3D Vision-guided Pick-and-Place Using Kuka LBR iiwa Robot. (arXiv:2102.10710v1 [cs.RO])</h2>
<h3>Hanlin Niu, Ze Ji, Zihang Zhu, Hujun Yin, Joaquin Carrasco</h3>
<p>This paper presents the development of a control system for vision-guided
pick-and-place tasks using a robot arm equipped with a 3D camera. The main
steps include camera intrinsic and extrinsic calibration, hand-eye calibration,
initial object pose registration, objects pose alignment algorithm, and
pick-and-place execution. The proposed system allows the robot be able to to
pick and place object with limited times of registering a new object and the
developed software can be applied for new object scenario quickly. The
integrated system was tested using the hardware combination of kuka iiwa,
Robotiq grippers (two finger gripper and three finger gripper) and 3D cameras
(Intel realsense D415 camera, Intel realsense D435 camera, Microsoft Kinect
V2). The whole system can also be modified for the combination of other robotic
arm, gripper and 3D camera.
</p>
<a href="http://arxiv.org/abs/2102.10710" target="_blank">arXiv:2102.10710</a> [<a href="http://arxiv.org/pdf/2102.10710" target="_blank">pdf</a>]

<h2>Accelerated Sim-to-Real Deep Reinforcement Learning: Learning Collision Avoidance from Human Player. (arXiv:2102.10711v1 [cs.AI])</h2>
<h3>Hanlin Niu, Ze Ji, Farshad Arvin, Barry Lennox, Hujun Yin, Joaquin Carrasco</h3>
<p>This paper presents a sensor-level mapless collision avoidance algorithm for
use in mobile robots that map raw sensor data to linear and angular velocities
and navigate in an unknown environment without a map. An efficient training
strategy is proposed to allow a robot to learn from both human experience data
and self-exploratory data. A game format simulation framework is designed to
allow the human player to tele-operate the mobile robot to a goal and human
action is also scored using the reward function. Both human player data and
self-playing data are sampled using prioritized experience replay algorithm.
The proposed algorithm and training strategy have been evaluated in two
different experimental configurations: \textit{Environment 1}, a simulated
cluttered environment, and \textit{Environment 2}, a simulated corridor
environment, to investigate the performance. It was demonstrated that the
proposed method achieved the same level of reward using only 16\% of the
training steps required by the standard Deep Deterministic Policy Gradient
(DDPG) method in Environment 1 and 20\% of that in Environment 2. In the
evaluation of 20 random missions, the proposed method achieved no collision in
less than 2~h and 2.5~h of training time in the two Gazebo environments
respectively. The method also generated smoother trajectories than DDPG. The
proposed method has also been implemented on a real robot in the real-world
environment for performance evaluation. We can confirm that the trained model
with the simulation software can be directly applied into the real-world
scenario without further fine-tuning, further demonstrating its higher
robustness than DDPG. The video and code are available:
https://youtu.be/BmwxevgsdGc
https://github.com/hanlinniu/turtlebot3_ddpg_collision_avoidance
</p>
<a href="http://arxiv.org/abs/2102.10711" target="_blank">arXiv:2102.10711</a> [<a href="http://arxiv.org/pdf/2102.10711" target="_blank">pdf</a>]

<h2>Abstraction and Analogy-Making in Artificial Intelligence. (arXiv:2102.10717v1 [cs.AI])</h2>
<h3>Melanie Mitchell</h3>
<p>Conceptual abstraction and analogy-making are key abilities underlying
humans' abilities to learn, reason, and robustly adapt their knowledge to new
domains. Despite of a long history of research on constructing AI systems with
these abilities, no current AI system is anywhere close to a capability of
forming humanlike abstractions or analogies. This paper reviews the advantages
and limitations of several approaches toward this goal, including symbolic
methods, deep learning, and probabilistic program induction. The paper
concludes with several proposals for designing challenge tasks and evaluation
measures in order to make quantifiable and generalizable progress in this area.
</p>
<a href="http://arxiv.org/abs/2102.10717" target="_blank">arXiv:2102.10717</a> [<a href="http://arxiv.org/pdf/2102.10717" target="_blank">pdf</a>]

<h2>Three dimensional unique identifier based automated georeferencing and coregistration of point clouds in underground environment. (arXiv:2102.10731v1 [cs.CV])</h2>
<h3>Sarvesh Kumar Singh, Bikram Pratap Banerjee, Simit Raval</h3>
<p>Spatially and geometrically accurate laser scans are essential in modelling
infrastructure for applications in civil, mining and transportation. Monitoring
of underground or indoor environments such as mines or tunnels is challenging
due to unavailability of a sensor positioning framework, complicated
structurally symmetric layouts, repetitive features and occlusions. Current
practices largely include a manual selection of discernable reference points
for georeferencing and coregistration purpose. This study aims at overcoming
these practical challenges in underground or indoor laser scanning. The
developed approach involves automatically and uniquely identifiable three
dimensional unique identifiers (3DUIDs) in laser scans, and a 3D registration
(3DReG) workflow. Field testing of the method in an underground tunnel has been
found accurate, effective and efficient. Additionally, a method for
automatically extracting roadway tunnel profile has been exhibited. The
developed 3DUID can be used in roadway profile extraction, guided automation,
sensor calibration, reference targets for routine survey and deformation
monitoring.
</p>
<a href="http://arxiv.org/abs/2102.10731" target="_blank">arXiv:2102.10731</a> [<a href="http://arxiv.org/pdf/2102.10731" target="_blank">pdf</a>]

<h2>Super-Convergence with an Unstable Learning Rate. (arXiv:2102.10734v1 [cs.LG])</h2>
<h3>Samet Oymak</h3>
<p>Conventional wisdom dictates that learning rate should be in the stable
regime so that gradient-based algorithms don't blow up. This note introduces a
simple scenario where an unstable learning rate scheme leads to a super fast
convergence, with the convergence rate depending only logarithmically on the
condition number of the problem. Our scheme uses a Cyclical Learning Rate where
we periodically take one large unstable step and several small stable steps to
compensate for the instability. These findings also help explain the empirical
observations of [Smith and Topin, 2019] where they claim CLR with a large
maximum learning rate leads to "super-convergence". We prove that our scheme
excels in the problems where Hessian exhibits a bimodal spectrum and the
eigenvalues can be grouped into two clusters (small and large). The unstable
step is the key to enabling fast convergence over the small eigen-spectrum.
</p>
<a href="http://arxiv.org/abs/2102.10734" target="_blank">arXiv:2102.10734</a> [<a href="http://arxiv.org/pdf/2102.10734" target="_blank">pdf</a>]

<h2>Dissecting the Diffusion Process in Linear Graph Convolutional Networks. (arXiv:2102.10739v1 [cs.LG])</h2>
<h3>Yifei Wang, Yisen Wang, Jiansheng Yang, Zhouchen Lin</h3>
<p>Graph Convolutional Networks (GCNs) have attracted more and more attentions
in recent years. A typical GCN layer consists of a linear feature propagation
step and a nonlinear transformation step. Recent works show that a linear GCN
can achieve comparable performance to the original non-linear GCN while being
much more computationally efficient. In this paper, we dissect the feature
propagation steps of linear GCNs from a perspective of continuous graph
diffusion, and analyze why linear GCNs fail to benefit from more propagation
steps. Following that, we propose Decoupled Graph Convolution (DGC) that
decouples the terminal time and the feature propagation steps, making it more
flexible and capable of exploiting a very large number of feature propagation
steps. Experiments demonstrate that our proposed DGC improves linear GCNs by a
large margin and makes them competitive with many modern variants of non-linear
GCNs.
</p>
<a href="http://arxiv.org/abs/2102.10739" target="_blank">arXiv:2102.10739</a> [<a href="http://arxiv.org/pdf/2102.10739" target="_blank">pdf</a>]

<h2>Communication Efficient Parallel Reinforcement Learning. (arXiv:2102.10740v1 [cs.LG])</h2>
<h3>Mridul Agarwal, Bhargav Ganguly, Vaneet Aggarwal</h3>
<p>We consider the problem where $M$ agents interact with $M$ identical and
independent environments with $S$ states and $A$ actions using reinforcement
learning for $T$ rounds. The agents share their data with a central server to
minimize their regret. We aim to find an algorithm that allows the agents to
minimize the regret with infrequent communication rounds. We provide \NAM\
which runs at each agent and prove that the total cumulative regret of $M$
agents is upper bounded as $\Tilde{O}(DS\sqrt{MAT})$ for a Markov Decision
Process with diameter $D$, number of states $S$, and number of actions $A$. The
agents synchronize after their visitations to any state-action pair exceeds a
certain threshold. Using this, we obtain a bound of $O\left(MSA\log(MT)\right)$
on the total number of communications rounds. Finally, we evaluate the
algorithm against multiple environments and demonstrate that the proposed
algorithm performs at par with an always communication version of the UCRL2
algorithm, while with significantly lower communication.
</p>
<a href="http://arxiv.org/abs/2102.10740" target="_blank">arXiv:2102.10740</a> [<a href="http://arxiv.org/pdf/2102.10740" target="_blank">pdf</a>]

<h2>MetaDelta: A Meta-Learning System for Few-shot Image Classification. (arXiv:2102.10744v1 [cs.CV])</h2>
<h3>Yudong Chen, Chaoyu Guan, Zhikun Wei, Xin Wang, Wenwu Zhu</h3>
<p>Meta-learning aims at learning quickly on novel tasks with limited data by
transferring generic experience learned from previous tasks. Naturally,
few-shot learning has been one of the most popular applications for
meta-learning. However, existing meta-learning algorithms rarely consider the
time and resource efficiency or the generalization capacity for unknown
datasets, which limits their applicability in real-world scenarios. In this
paper, we propose MetaDelta, a novel practical meta-learning system for the
few-shot image classification. MetaDelta consists of two core components: i)
multiple meta-learners supervised by a central controller to ensure efficiency,
and ii) a meta-ensemble module in charge of integrated inference and better
generalization. In particular, each meta-learner in MetaDelta is composed of a
unique pretrained encoder fine-tuned by batch training and parameter-free
decoder used for prediction. MetaDelta ranks first in the final phase in the
AAAI 2021 MetaDL
Challenge\footnote{https://competitions.codalab.org/competitions/26638},
demonstrating the advantages of our proposed system. The codes are publicly
available at https://github.com/Frozenmad/MetaDelta.
</p>
<a href="http://arxiv.org/abs/2102.10744" target="_blank">arXiv:2102.10744</a> [<a href="http://arxiv.org/pdf/2102.10744" target="_blank">pdf</a>]

<h2>Neural Attribute Grammars for Semantics-Guided Program Generation. (arXiv:1705.09231v3 [cs.AI] UPDATED)</h2>
<h3>Rohan Mukherjee, Dipak Chaudhari, Matthew Amodio, Thomas Reps, Swarat Chaudhuri, Chris Jermaine</h3>
<p>Existing deep models for code tend to be trained on syntactic program
representations. We present an alternative, called Neural Attribute Grammars,
that exposes the semantics of the target language to the training procedure
using an attribute grammar. During training, our model learns to replicate the
relationship between the syntactic rules used to construct a program, and the
semantic attributes (for example, symbol tables) constructed from the context
in which the rules are fired. We implement the approach as a system for
conditional generation of Java programs modulo eleven natural requirements. Our
experiments show that the system generates constraint-abiding programs with
significantly higher frequency than a baseline model trained on syntactic
program representations, and also in terms of generation accuracy.
</p>
<a href="http://arxiv.org/abs/1705.09231" target="_blank">arXiv:1705.09231</a> [<a href="http://arxiv.org/pdf/1705.09231" target="_blank">pdf</a>]

<h2>AdaGrad stepsizes: Sharp convergence over nonconvex landscapes. (arXiv:1806.01811v7 [stat.ML] UPDATED)</h2>
<h3>Rachel Ward, Xiaoxia Wu, Leon Bottou</h3>
<p>Adaptive gradient methods such as AdaGrad and its variants update the
stepsize in stochastic gradient descent on the fly according to the gradients
received along the way; such methods have gained widespread use in large-scale
optimization for their ability to converge robustly, without the need to
fine-tune the stepsize schedule. Yet, the theoretical guarantees to date for
AdaGrad are for online and convex optimization. We bridge this gap by providing
theoretical guarantees for the convergence of AdaGrad for smooth, nonconvex
functions. We show that the norm version of AdaGrad (AdaGrad-Norm) converges to
a stationary point at the $\mathcal{O}(\log(N)/\sqrt{N})$ rate in the
stochastic setting, and at the optimal $\mathcal{O}(1/N)$ rate in the batch
(non-stochastic) setting -- in this sense, our convergence guarantees are
'sharp'. In particular, the convergence of AdaGrad-Norm is robust to the choice
of all hyper-parameters of the algorithm, in contrast to stochastic gradient
descent whose convergence depends crucially on tuning the step-size to the
(generally unknown) Lipschitz smoothness constant and level of stochastic noise
on the gradient. Extensive numerical experiments are provided to corroborate
our theory; moreover, the experiments suggest that the robustness of
AdaGrad-Norm extends to state-of-the-art models in deep learning, without
sacrificing generalization.
</p>
<a href="http://arxiv.org/abs/1806.01811" target="_blank">arXiv:1806.01811</a> [<a href="http://arxiv.org/pdf/1806.01811" target="_blank">pdf</a>]

<h2>Deep Frank-Wolfe For Neural Network Optimization. (arXiv:1811.07591v3 [cs.LG] UPDATED)</h2>
<h3>Leonard Berrada, Andrew Zisserman, M. Pawan Kumar</h3>
<p>Learning a deep neural network requires solving a challenging optimization
problem: it is a high-dimensional, non-convex and non-smooth minimization
problem with a large number of terms. The current practice in neural network
optimization is to rely on the stochastic gradient descent (SGD) algorithm or
its adaptive variants. However, SGD requires a hand-designed schedule for the
learning rate. In addition, its adaptive variants tend to produce solutions
that generalize less well on unseen data than SGD with a hand-designed
schedule. We present an optimization method that offers empirically the best of
both worlds: our algorithm yields good generalization performance while
requiring only one hyper-parameter. Our approach is based on a composite
proximal framework, which exploits the compositional nature of deep neural
networks and can leverage powerful convex optimization algorithms by design.
Specifically, we employ the Frank-Wolfe (FW) algorithm for SVM, which computes
an optimal step-size in closed-form at each time-step. We further show that the
descent direction is given by a simple backward pass in the network, yielding
the same computational cost per iteration as SGD. We present experiments on the
CIFAR and SNLI data sets, where we demonstrate the significant superiority of
our method over Adam, Adagrad, as well as the recently proposed BPGrad and
AMSGrad. Furthermore, we compare our algorithm to SGD with a hand-designed
learning rate schedule, and show that it provides similar generalization while
converging faster. The code is publicly available at
https://github.com/oval-group/dfw.
</p>
<a href="http://arxiv.org/abs/1811.07591" target="_blank">arXiv:1811.07591</a> [<a href="http://arxiv.org/pdf/1811.07591" target="_blank">pdf</a>]

<h2>Driver Behavior Recognition via Interwoven Deep Convolutional Neural Nets with Multi-stream Inputs. (arXiv:1811.09128v2 [cs.CV] UPDATED)</h2>
<h3>Chaoyun Zhang, Rui Li, Woojin Kim, Daesub Yoon, Paul Patras</h3>
<p>Understanding driver activity is vital for in-vehicle systems that aim to
reduce the incidence of car accidents rooted in cognitive distraction.
Automating real-time behavior recognition while ensuring actions classification
with high accuracy is however challenging, given the multitude of circumstances
surrounding drivers, the unique traits of individuals, and the computational
constraints imposed by in-vehicle embedded platforms. Prior work fails to
jointly meet these runtime/accuracy requirements and mostly rely on a single
sensing modality, which in turn can be a single point of failure. In this
paper, we harness the exceptional feature extraction abilities of deep learning
and propose a dedicated Interwoven Deep Convolutional Neural Network (InterCNN)
architecture to tackle the problem of accurate classification of driver
behaviors in real-time. The proposed solution exploits information from
multi-stream inputs, i.e., in-vehicle cameras with different fields of view and
optical flows computed based on recorded images, and merges through multiple
fusion layers abstract features that it extracts. This builds a tight
ensembling system, which significantly improves the robustness of the model. In
addition, we introduce a temporal voting scheme based on historical inference
instances, to enhance the classification accuracy. Experiments conducted with a
dataset that we collect in a mock-up car environment demonstrate that the
proposed InterCNN with MobileNet convolutional blocks can classify 9 different
behaviors with 73.97% accuracy, and 5 'aggregated' behaviors with 81.66%
accuracy. We further show that our architecture is highly computationally
efficient, as it performs inferences within 15ms, which satisfies the real-time
constraints of intelligent cars. Nevertheless, our InterCNN is robust to lossy
input, as the classification remains accurate when two input streams are
occluded.
</p>
<a href="http://arxiv.org/abs/1811.09128" target="_blank">arXiv:1811.09128</a> [<a href="http://arxiv.org/pdf/1811.09128" target="_blank">pdf</a>]

<h2>Face morphing detection in the presence of printing/scanning and heterogeneous image sources. (arXiv:1901.08811v2 [cs.CV] UPDATED)</h2>
<h3>Matteo Ferrara, Annalisa Franco, Davide Maltoni</h3>
<p>Face morphing represents nowadays a big security threat in the context of
electronic identity documents as well as an interesting challenge for
researchers in the field of face recognition. Despite of the good performance
obtained by state-of-the-art approaches on digital images, no satisfactory
solutions have been identified so far to deal with cross-database testing and
printed-scanned images (typically used in many countries for document issuing).
In this work, novel approaches are proposed to train Deep Neural Networks for
morphing detection: in particular generation of simulated printed-scanned
images together with other data augmentation strategies and pre-training on
large face recognition datasets, allowed to reach state-of-the-art accuracy on
challenging datasets from heterogeneous image sources.
</p>
<a href="http://arxiv.org/abs/1901.08811" target="_blank">arXiv:1901.08811</a> [<a href="http://arxiv.org/pdf/1901.08811" target="_blank">pdf</a>]

<h2>CodedPrivateML: A Fast and Privacy-Preserving Framework for Distributed Machine Learning. (arXiv:1902.00641v2 [cs.LG] UPDATED)</h2>
<h3>Jinhyun So, Basak Guler, A. Salman Avestimehr</h3>
<p>How to train a machine learning model while keeping the data private and
secure? We present CodedPrivateML, a fast and scalable approach to this
critical problem. CodedPrivateML keeps both the data and the model
information-theoretically private, while allowing efficient parallelization of
training across distributed workers. We characterize CodedPrivateML's privacy
threshold and prove its convergence for logistic (and linear) regression.
Furthermore, via extensive experiments on Amazon EC2, we demonstrate that
CodedPrivateML provides significant speedup over cryptographic approaches based
on multi-party computing (MPC).
</p>
<a href="http://arxiv.org/abs/1902.00641" target="_blank">arXiv:1902.00641</a> [<a href="http://arxiv.org/pdf/1902.00641" target="_blank">pdf</a>]

<h2>Robust learning with implicit residual networks. (arXiv:1905.10479v4 [cs.LG] UPDATED)</h2>
<h3>Viktor Reshniak, Clayton Webster</h3>
<p>In this effort, we propose a new deep architecture utilizing residual blocks
inspired by implicit discretization schemes. As opposed to the standard
feed-forward networks, the outputs of the proposed implicit residual blocks are
defined as the fixed points of the appropriately chosen nonlinear
transformations. We show that this choice leads to the improved stability of
both forward and backward propagations, has a favorable impact on the
generalization power and allows to control the robustness of the network with
only a few hyperparameters. In addition, the proposed reformulation of ResNet
does not introduce new parameters and can potentially lead to a reduction in
the number of required layers due to improved forward stability. Finally, we
derive the memory-efficient training algorithm, propose a stochastic
regularization technique and provide numerical results in support of our
findings.
</p>
<a href="http://arxiv.org/abs/1905.10479" target="_blank">arXiv:1905.10479</a> [<a href="http://arxiv.org/pdf/1905.10479" target="_blank">pdf</a>]

<h2>NPTC-net: Narrow-Band Parallel Transport Convolutional Neural Network on Point Clouds. (arXiv:1905.12218v3 [cs.CV] UPDATED)</h2>
<h3>Pengfei Jin, Tianhao Lai, Rongjie Lai, Bin Dong</h3>
<p>Convolution plays a crucial role in various applications in signal and image
processing, analysis, and recognition. It is also the main building block of
convolution neural networks (CNNs). Designing appropriate convolution neural
networks on manifold-structured point clouds can inherit and empower recent
advances of CNNs to analyzing and processing point cloud data. However, one of
the major challenges is to define a proper way to "sweep" filters through the
point cloud as a natural generalization of the planar convolution and to
reflect the point cloud's geometry at the same time. In this paper, we consider
generalizing convolution by adapting parallel transport on the point cloud.
Inspired by a triangulated surface-based method [Stefan C. Schonsheck, Bin
Dong, and Rongjie Lai, arXiv:1805.07857.], we propose the Narrow-Band Parallel
Transport Convolution (NPTC) using a specifically defined connection on a
voxel-based narrow-band approximation of point cloud data. With that, we
further propose a deep convolutional neural network based on NPTC (called
NPTC-net) for point cloud classification and segmentation. Comprehensive
experiments show that the proposed NPTC-net achieves similar or better results
than current state-of-the-art methods on point cloud classification and
segmentation.
</p>
<a href="http://arxiv.org/abs/1905.12218" target="_blank">arXiv:1905.12218</a> [<a href="http://arxiv.org/pdf/1905.12218" target="_blank">pdf</a>]

<h2>Norm-based generalisation bounds for multi-class convolutional neural networks. (arXiv:1905.12430v5 [cs.LG] UPDATED)</h2>
<h3>Antoine Ledent, Waleed Mustafa, Yunwen Lei, Marius Kloft</h3>
<p>We show generalisation error bounds for deep learning with two main
improvements over the state of the art. (1) Our bounds have no explicit
dependence on the number of classes except for logarithmic factors. This holds
even when formulating the bounds in terms of the $L^2$-norm of the weight
matrices, where previous bounds exhibit at least a square-root dependence on
the number of classes. (2) We adapt the classic Rademacher analysis of DNNs to
incorporate weight sharing -- a task of fundamental theoretical importance
which was previously attempted only under very restrictive assumptions. In our
results, each convolutional filter contributes only once to the bound,
regardless of how many times it is applied. Further improvements exploiting
pooling and sparse connections are provided. The presented bounds scale as the
norms of the parameter matrices, rather than the number of parameters. In
particular, contrary to bounds based on parameter counting, they are
asymptotically tight (up to log factors) when the weights approach
initialisation, making them suitable as a basic ingredient in bounds sensitive
to the optimisation procedure. We also show how to adapt the recent technique
of loss function augmentation to our situation to replace spectral norms by
empirical analogues whilst maintaining the advantages of our approach.
</p>
<a href="http://arxiv.org/abs/1905.12430" target="_blank">arXiv:1905.12430</a> [<a href="http://arxiv.org/pdf/1905.12430" target="_blank">pdf</a>]

<h2>Replica-exchange Nos\'e-Hoover dynamics for Bayesian learning on large datasets. (arXiv:1905.12569v4 [stat.ML] UPDATED)</h2>
<h3>Rui Luo, Qiang Zhang, Yaodong Yang, Jun Wang</h3>
<p>In this paper, we present a new practical method for Bayesian learning that
can rapidly draw representative samples from complex posterior distributions
with multiple isolated modes in the presence of mini-batch noise. This is
achieved by simulating a collection of replicas in parallel with different
temperatures and periodically swapping them. When evolving the replicas'
states, the Nos\'e-Hoover dynamics is applied, which adaptively neutralizes the
mini-batch noise. To perform proper exchanges, a new protocol is developed with
a noise-aware test of acceptance, by which the detailed balance is reserved in
an asymptotic way. While its efficacy on complex multimodal posteriors has been
illustrated by testing over synthetic distributions, experiments with deep
Bayesian neural networks on large-scale datasets have shown its significant
improvements over strong baselines.
</p>
<a href="http://arxiv.org/abs/1905.12569" target="_blank">arXiv:1905.12569</a> [<a href="http://arxiv.org/pdf/1905.12569" target="_blank">pdf</a>]

<h2>CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud Stream Forecasting. (arXiv:1907.12410v3 [cs.LG] UPDATED)</h2>
<h3>Chaoyun Zhang, Marco Fiore, Iain Murray, Paul Patras</h3>
<p>This paper introduces CloudLSTM, a new branch of recurrent neural models
tailored to forecasting over data streams generated by geospatial point-cloud
sources. We design a Dynamic Point-cloud Convolution (DConv) operator as the
core component of CloudLSTMs, which performs convolution directly over
point-clouds and extracts local spatial features from sets of neighboring
points that surround different elements of the input. This operator maintains
the permutation invariance of sequence-to-sequence learning frameworks, while
representing neighboring correlations at each time step -- an important aspect
in spatiotemporal predictive learning. The DConv operator resolves the
grid-structural data requirements of existing spatiotemporal forecasting models
and can be easily plugged into traditional LSTM architectures with
sequence-to-sequence learning and attention mechanisms. We apply our proposed
architecture to two representative, practical use cases that involve
point-cloud streams, i.e., mobile service traffic forecasting and air quality
indicator forecasting. Our results, obtained with real-world datasets collected
in diverse scenarios for each use case, show that CloudLSTM delivers accurate
long-term predictions, outperforming a variety of competitor neural network
models.
</p>
<a href="http://arxiv.org/abs/1907.12410" target="_blank">arXiv:1907.12410</a> [<a href="http://arxiv.org/pdf/1907.12410" target="_blank">pdf</a>]

<h2>Nonparametric Regression on Low-Dimensional Manifolds using Deep ReLU Networks : Function Approximation and Statistical Recovery. (arXiv:1908.01842v4 [cs.LG] UPDATED)</h2>
<h3>Minshuo Chen, Haoming Jiang, Wenjing Liao, Tuo Zhao</h3>
<p>Real world data often exhibit low-dimensional geometric structures, and can
be viewed as samples near a low-dimensional manifold. This paper studies
nonparametric regression of H\"{o}lder functions on low-dimensional manifolds
using deep ReLU networks. Suppose $n$ training data are sampled from a
H\"{o}lder function in $\mathcal{H}^{s,\alpha}$ supported on a $d$-dimensional
Riemannian manifold isometrically embedded in $\mathbb{R}^D$, with sub-gaussian
noise. A deep ReLU network architecture is designed to estimate the underlying
function from the training data. The mean squared error of the empirical
estimator is proved to converge in the order of
$n^{-\frac{2(s+\alpha)}{2(s+\alpha) + d}}\log^3 n$. This result shows that deep
ReLU networks give rise to a fast convergence rate depending on the data
intrinsic dimension $d$, which is usually much smaller than the ambient
dimension $D$. It therefore demonstrates the adaptivity of deep ReLU networks
to low-dimensional geometric structures of data, and partially explains the
power of deep ReLU networks in tackling high-dimensional data with
low-dimensional geometric structures.
</p>
<a href="http://arxiv.org/abs/1908.01842" target="_blank">arXiv:1908.01842</a> [<a href="http://arxiv.org/pdf/1908.01842" target="_blank">pdf</a>]

<h2>Unexpected Effects of Online no-Substitution k-means Clustering. (arXiv:1908.06818v2 [cs.LG] UPDATED)</h2>
<h3>Michal Moshkovitz</h3>
<p>Offline k-means clustering was studied extensively, and algorithms with a
constant approximation are available. However, online clustering is still
uncharted. New factors come into play: the ordering of the dataset and whether
the number of points, n, is known in advance or not. Their exact effects are
unknown. In this paper we focus on the online setting where the decisions are
irreversible: after a point arrives, the algorithm needs to decide whether to
take the point as a center or not, and this decision is final. How many centers
are needed and sufficient to achieve constant approximation in this setting? We
show upper and lower bounds for all the different cases. These bounds are
exactly the same up to a constant, thus achieving optimal bounds. For example,
for k-means cost with constant k&gt;1 and random order, Theta(log n) centers are
enough to achieve a constant approximation, while the mere a priori knowledge
of n reduces the number of centers to a constant. These bounds hold for any
distance function that obeys a triangle-type inequality.
</p>
<a href="http://arxiv.org/abs/1908.06818" target="_blank">arXiv:1908.06818</a> [<a href="http://arxiv.org/pdf/1908.06818" target="_blank">pdf</a>]

<h2>BooVAE: Boosting Approach for Continual Learning of VAE. (arXiv:1908.11853v2 [cs.LG] UPDATED)</h2>
<h3>Anna Kuzina, Evgenii Egorov, Evgeny Burnaev</h3>
<p>Variational autoencoder (VAE) is a deep generative model for unsupervised
learning, allowing to encode observations into the meaningful latent space. VAE
is prone to catastrophic forgetting when tasks arrive sequentially, and only
the data for the current one is available. We address this problem of continual
learning for VAEs. It is known that the choice of the prior distribution over
the latent space is crucial for VAE in the non-continual setting. We argue that
it can also be helpful to avoid catastrophic forgetting. We learn the
approximation of the aggregated posterior as a prior for each task. This
approximation is parametrised as an additive mixture of distributions induced
by encoder evaluated at trainable pseudo-inputs. We use a greedy boosting-like
approach with entropy regularisation to learn the components. This method
encourages components diversity, which is essential as we aim at memorising the
current task with the fewest components possible. Based on the learnable prior,
we introduce an end-to-end approach for continual learning of VAEs and provide
empirical studies on commonly used benchmarks (MNIST, Fashion MNIST, NotMNIST)
and CelebA datasets. For each dataset, the proposed method avoids catastrophic
forgetting in a fully automatic way.
</p>
<a href="http://arxiv.org/abs/1908.11853" target="_blank">arXiv:1908.11853</a> [<a href="http://arxiv.org/pdf/1908.11853" target="_blank">pdf</a>]

<h2>Generalization in Transfer Learning. (arXiv:1909.01331v2 [cs.LG] UPDATED)</h2>
<h3>Suzan Ece Ada, Emre Ugur, H. Levent Akin</h3>
<p>Agents trained with deep reinforcement learning algorithms are capable of
performing highly complex tasks including locomotion in continuous
environments. We investigate transferring the learning acquired in one task to
a set of previously unseen tasks. Generalization and overfitting in deep
reinforcement learning are not commonly addressed in current transfer learning
research. Conducting a comparative analysis without an intermediate
regularization step results in underperforming benchmarks and inaccurate
algorithm comparisons due to rudimentary assessments. In this study, we propose
regularization techniques in deep reinforcement learning for continuous control
through the application of sample elimination, early stopping and maximum
entropy regularized adversarial learning. First, the importance of the
inclusion of training iteration number to the hyperparameters in deep transfer
reinforcement learning will be discussed. Because source task performance is
not indicative of the generalization capacity of the algorithm, we start by
acknowledging the training iteration number as a hyperparameter. In line with
this, we introduce an additional step of resorting to earlier snapshots of
policy parameters to prevent overfitting to the source task. Then, to generate
robust policies, we discard the samples that lead to overfitting via a method
we call strict clipping. Furthermore, we increase the generalization capacity
in widely used transfer learning benchmarks by using maximum entropy
regularization, different critic methods, and curriculum learning in an
adversarial setup. Subsequently, we propose maximum entropy adversarial
reinforcement learning to increase the domain randomization. Finally, we
evaluate the robustness of these methods on simulated robots in target
environments where the morphology of the robot, gravity, and tangential
friction coefficient of the environment are altered.
</p>
<a href="http://arxiv.org/abs/1909.01331" target="_blank">arXiv:1909.01331</a> [<a href="http://arxiv.org/pdf/1909.01331" target="_blank">pdf</a>]

<h2>Sequential Adversarial Anomaly Detection for One-Class Event Data. (arXiv:1910.09161v4 [stat.ML] UPDATED)</h2>
<h3>Shixiang Zhu, Henry Shaowu Yuchi, Minghe Zhang, Yao Xie</h3>
<p>We consider the sequential anomaly detection problem in the one-class setting
when only the anomalous sequences are available and propose an adversarial
sequential detector by solving a minimax problem to find an optimal detector
against the worst-case sequences from a generator. The generator captures the
dependence in sequential events using the marked point process model. The
detector sequentially evaluates the likelihood of a test sequence and compares
it with a time-varying threshold, also learned from data through the minimax
problem. We demonstrate our proposed method's good performance using numerical
experiments on simulations and proprietary large-scale credit card fraud
datasets. The proposed method can generally apply to detecting anomalous
sequences.
</p>
<a href="http://arxiv.org/abs/1910.09161" target="_blank">arXiv:1910.09161</a> [<a href="http://arxiv.org/pdf/1910.09161" target="_blank">pdf</a>]

<h2>Dynamic Connected Neural Decision Classifier and Regressor with Dynamic Softing Pruning. (arXiv:1911.05443v3 [cs.LG] UPDATED)</h2>
<h3>Xinyu Fan</h3>
<p>To deal with various datasets over different complexity, this paper presents
an self-adaptive learning model that combines the proposed Dynamic Connected
Neural Decision Networks (DNDN) and a new pruning method--Dynamic Soft Pruning
(DSP). DNDN is a combination of random forests and deep neural networks that
enjoys both the advantages of strong classification capability of tree-like
structure and representation learning capability of network structure. Based on
Deep Neural Decision Forests (DNDF), this paper adopts an end-to-end training
approach by representing the classification distribution with multiple randomly
initialized softmax layers, which further allows an ensemble of multiple random
forests attached to layers of neural network with different depth. We also
propose a soft pruning method DSP to reduce the redundant connections of the
network adaptively to avoid over-fitting simple dataset. The model demonstrates
no performance loss compared with unpruned models and even higher robustness
over different data and feature distribution. Extensive experiments on
different datasets demonstrate the superiority of the proposed model over other
popular algorithms in solving classification tasks.
</p>
<a href="http://arxiv.org/abs/1911.05443" target="_blank">arXiv:1911.05443</a> [<a href="http://arxiv.org/pdf/1911.05443" target="_blank">pdf</a>]

<h2>Variationally Regularized Graph-based Representation Learning for Electronic Health Records. (arXiv:1912.03761v2 [cs.LG] UPDATED)</h2>
<h3>Weicheng Zhu, Narges Razavian</h3>
<p>Electronic Health Records (EHR) are high-dimensional data with implicit
connections among thousands of medical concepts. These connections, for
instance, the co-occurrence of diseases and lab-disease correlations can be
informative when only a subset of these variables is documented by the
clinician. A feasible approach to improving the representation learning of EHR
data is to associate relevant medical concepts and utilize these connections.
Existing medical ontologies can be the reference for EHR structures, but they
place numerous constraints on the data source. Recent progress on graph neural
networks (GNN) enables end-to-end learning of topological structures for
non-grid or non-sequential data. However, there are problems to be addressed on
how to learn the medical graph adaptively and how to understand the effect of
the medical graph on representation learning. In this paper, we propose a
variationally regularized encoder-decoder graph network that achieves more
robustness in graph structure learning by regularizing node representations.
Our model outperforms the existing graph and non-graph based methods in various
EHR predictive tasks based on both public data and real-world clinical data.
Besides the improvements in empirical experiment performances, we provide an
interpretation of the effect of variational regularization compared to standard
graph neural network, using singular value analysis.
</p>
<a href="http://arxiv.org/abs/1912.03761" target="_blank">arXiv:1912.03761</a> [<a href="http://arxiv.org/pdf/1912.03761" target="_blank">pdf</a>]

<h2>Pneumothorax Segmentation: Deep Learning Image Segmentation to predict Pneumothorax. (arXiv:1912.07329v2 [cs.CV] UPDATED)</h2>
<h3>Karan Jakhar, Rohit Bajaj, Ruchika Gupta</h3>
<p>Computer vision has shown promising results in medical image processing.
Pneumothorax is a deadly condition and if not diagnosed and treated at time
then it causes death. It can be diagnosed with chest X-ray images. We need an
expert and experienced radiologist to predict whether a person is suffering
from pneumothorax or not by looking at the chest X-ray images. Everyone does
not have access to such a facility. Moreover, in some cases, we need quick
diagnoses. So we propose an image segmentation model to predict and give the
output a mask that will assist the doctor in taking this crucial decision. Deep
Learning has proved their worth in many areas and outperformed man
state-of-the-art models. We want to use the power of these deep learning model
to solve this problem. We have used U-net [13] architecture with ResNet [17] as
a backbone and achieved promising results. U-net [13] performs very well in
medical image processing and semantic segmentation. Our problem falls in the
semantic segmentation category.
</p>
<a href="http://arxiv.org/abs/1912.07329" target="_blank">arXiv:1912.07329</a> [<a href="http://arxiv.org/pdf/1912.07329" target="_blank">pdf</a>]

<h2>EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video. (arXiv:2001.05488v2 [cs.CV] UPDATED)</h2>
<h3>Jennifer J. Sun, Ting Liu, Alan S. Cowen, Florian Schroff, Hartwig Adam, Gautam Prasad</h3>
<p>Videos can evoke a range of affective responses in viewers. The ability to
predict evoked affect from a video, before viewers watch the video, can help in
content creation and video recommendation. We introduce the Evoked Expressions
from Videos (EEV) dataset, a large-scale dataset for studying viewer responses
to videos. Each video is annotated at 6 Hz with 15 continuous evoked expression
labels, corresponding to the facial expression of viewers who reacted to the
video. We use an expression recognition model within our data collection
framework to achieve scalability. In total, there are 36.7 million annotations
of viewer facial reactions to 23,574 videos (1,700 hours). We use a publicly
available video corpus to obtain a diverse set of video content. We establish
baseline performance on the EEV dataset using an existing multimodal recurrent
model. Transfer learning experiments show an improvement in performance on the
LIRIS-ACCEDE video dataset when pre-trained on EEV. We hope that the size and
diversity of the EEV dataset will encourage further explorations in video
understanding and affective computing. A subset of EEV is released at
https://github.com/google-research-datasets/eev.
</p>
<a href="http://arxiv.org/abs/2001.05488" target="_blank">arXiv:2001.05488</a> [<a href="http://arxiv.org/pdf/2001.05488" target="_blank">pdf</a>]

<h2>Ballooning Multi-Armed Bandits. (arXiv:2001.10055v3 [cs.LG] UPDATED)</h2>
<h3>Ganesh Ghalme, Swapnil Dhamal, Shweta Jain, Sujit Gujar, Y. Narahari</h3>
<p>In this paper, we introduce Ballooning Multi-Armed Bandits (BL-MAB), a novel
extension of the classical stochastic MAB model. In the BL-MAB model, the set
of available arms grows (or balloons) over time. In contrast to the classical
MAB setting where the regret is computed with respect to the best arm overall,
the regret in a BL-MAB setting is computed with respect to the best available
arm at each time. We first observe that the existing stochastic MAB algorithms
result in linear regret for the BL-MAB model. We prove that, if the best arm is
equally likely to arrive at any time instant, a sub-linear regret cannot be
achieved. Next, we show that if the best arm is more likely to arrive in the
early rounds, one can achieve sub-linear regret. Our proposed algorithm
determines (1) the fraction of the time horizon for which the newly arriving
arms should be explored and (2) the sequence of arm pulls in the exploitation
phase from among the explored arms. Making reasonable assumptions on the
arrival distribution of the best arm in terms of the thinness of the
distribution's tail, we prove that the proposed algorithm achieves sub-linear
instance-independent regret. We further quantify explicit dependence of regret
on the arrival distribution parameters. We reinforce our theoretical findings
with extensive simulation results. We conclude by showing that our algorithm
would achieve sub-linear regret even if (a) the distributional parameters are
not exactly known, but are obtained using a reasonable learning mechanism or
(b) the best arm is not more likely to arrive early, but a large fraction of
arms is likely to arrive relatively early.
</p>
<a href="http://arxiv.org/abs/2001.10055" target="_blank">arXiv:2001.10055</a> [<a href="http://arxiv.org/pdf/2001.10055" target="_blank">pdf</a>]

<h2>Bidirectional Trajectory Computation for Odometer-Aided Visual-Inertial SLAM. (arXiv:2002.00195v4 [cs.RO] UPDATED)</h2>
<h3>Jinxu Liu, Wei Gao, Zhanyi Hu</h3>
<p>Odometer-aided visual-inertial SLAM systems typically have a good performance
for navigation of wheeled platforms, while they usually suffer from degenerate
cases before the first turning. In this paper, firstly we perform an
observability analysis w.r.t. the extrinsic parameters before the first
turning, which is a complement of the existing results of observability
analyses. Secondly, inspired by the above observability analyses, we propose a
bidirectional trajectory computation method, by which the poses before the
first turning are refined in the backward computation thread, and the real-time
trajectory is adjusted accordingly. Experimental results prove that our
proposed method not only solves the problem of the unobservability of
accelerometer bias and extrinsic parameters before the first turning, but also
results in more accurate trajectories in comparison with the state-of-the-art
approaches.
</p>
<a href="http://arxiv.org/abs/2002.00195" target="_blank">arXiv:2002.00195</a> [<a href="http://arxiv.org/pdf/2002.00195" target="_blank">pdf</a>]

<h2>Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits. (arXiv:2002.02518v3 [cs.LG] UPDATED)</h2>
<h3>Jack Parker-Holder, Vu Nguyen, Stephen Roberts</h3>
<p>Many of the recent triumphs in machine learning are dependent on well-tuned
hyperparameters. This is particularly prominent in reinforcement learning (RL)
where a small change in the configuration can lead to failure. Despite the
importance of tuning hyperparameters, it remains expensive and is often done in
a naive and laborious way. A recent solution to this problem is Population
Based Training (PBT) which updates both weights and hyperparameters in a single
training run of a population of agents. PBT has been shown to be particularly
effective in RL, leading to widespread use in the field. However, PBT lacks
theoretical guarantees since it relies on random heuristics to explore the
hyperparameter space. This inefficiency means it typically requires vast
computational resources, which is prohibitive for many small and medium sized
labs. In this work, we introduce the first provably efficient PBT-style
algorithm, Population-Based Bandits (PB2). PB2 uses a probabilistic model to
guide the search in an efficient way, making it possible to discover high
performing hyperparameter configurations with far fewer agents than typically
required by PBT. We show in a series of RL experiments that PB2 is able to
achieve high performance with a modest computational budget.
</p>
<a href="http://arxiv.org/abs/2002.02518" target="_blank">arXiv:2002.02518</a> [<a href="http://arxiv.org/pdf/2002.02518" target="_blank">pdf</a>]

<h2>Learning Stochastic Behaviour from Aggregate Data. (arXiv:2002.03513v5 [cs.LG] UPDATED)</h2>
<h3>Shaojun Ma, Shu Liu, Hongyuan Zha, Haomin Zhou</h3>
<p>Learning nonlinear dynamics from aggregate datais a challenging problem
because the full trajectory of each individual is not available, namely, the
individual observed at one time may not beobserved at the next time point, or
the identity ofindividual is unavailable. This is in sharp contrastto learning
dynamics with full trajectory data, on which the majority of existing methods
are based. We propose a novel method using the weak form of Fokker Planck
Equation(FPE) -- a partial differential equation -- to describe the density
evolution of data in a sampled form, which is then combined with Wasserstein
generative adversarial network (WGAN) in the training process. Insuch a sample
based framework we are able to learn the nonlinear dynamics from aggregate data
without explicitly solving FPE. More importantly, our model can also readily
handle high dimensional cases by leveraging deep neural networks. We
demonstrate our approach in the context of aseries of synthetic and real-world
data sets.
</p>
<a href="http://arxiv.org/abs/2002.03513" target="_blank">arXiv:2002.03513</a> [<a href="http://arxiv.org/pdf/2002.03513" target="_blank">pdf</a>]

<h2>Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure Federated Learning. (arXiv:2002.04156v3 [cs.LG] UPDATED)</h2>
<h3>Jinhyun So, Basak Guler, A. Salman Avestimehr</h3>
<p>Federated learning is a distributed framework for training machine learning
models over the data residing at mobile devices, while protecting the privacy
of individual users. A major bottleneck in scaling federated learning to a
large number of users is the overhead of secure model aggregation across many
users. In particular, the overhead of the state-of-the-art protocols for secure
model aggregation grows quadratically with the number of users. In this paper,
we propose the first secure aggregation framework, named Turbo-Aggregate, that
in a network with $N$ users achieves a secure aggregation overhead of
$O(N\log{N})$, as opposed to $O(N^2)$, while tolerating up to a user dropout
rate of $50\%$. Turbo-Aggregate employs a multi-group circular strategy for
efficient model aggregation, and leverages additive secret sharing and novel
coding techniques for injecting aggregation redundancy in order to handle user
dropouts while guaranteeing user privacy. We experimentally demonstrate that
Turbo-Aggregate achieves a total running time that grows almost linear in the
number of users, and provides up to $40\times$ speedup over the
state-of-the-art protocols with up to $N=200$ users. Our experiments also
demonstrate the impact of model size and bandwidth on the performance of
Turbo-Aggregate.
</p>
<a href="http://arxiv.org/abs/2002.04156" target="_blank">arXiv:2002.04156</a> [<a href="http://arxiv.org/pdf/2002.04156" target="_blank">pdf</a>]

<h2>Learning to Switch Between Machines and Humans. (arXiv:2002.04258v2 [cs.LG] UPDATED)</h2>
<h3>Vahid Balazadeh Meresht, Abir De, Adish Singla, Manuel Gomez-Rodriguez</h3>
<p>Reinforcement learning agents have been mostly developed and evaluated under
the assumption that they will operate in a fully autonomous manner -- they will
take all actions. In this work, our goal is to develop algorithms that, by
learning to switch control between machine and human agents, allow existing
reinforcement learning agents to operate under different automation levels. To
this end, we first formally define the problem of learning to switch control
among agents in a team via a 2-layer Markov decision process. Then, we develop
an online learning algorithm that uses upper confidence bounds on the agents'
policies and the environment's transition probabilities to find a sequence of
switching policies. We prove that the total regret of our algorithm with
respect to the optimal switching policy is sublinear in the number of learning
steps. Moreover, we also show that our algorithm can be used to find multiple
sequences of switching policies across several independent teams of agents
operating in similar environments, where it greatly benefits from maintaining
shared confidence bounds for the environments' transition probabilities.
Simulation experiments in obstacle avoidance in a semi-autonomous driving
scenario illustrate our theoretical findings and demonstrate that, by
exploiting the specific structure of the problem, our proposed algorithm is
superior to problem-agnostic algorithms.
</p>
<a href="http://arxiv.org/abs/2002.04258" target="_blank">arXiv:2002.04258</a> [<a href="http://arxiv.org/pdf/2002.04258" target="_blank">pdf</a>]

<h2>Deep Fourier Kernel for Self-Attentive Point Processes. (arXiv:2002.07281v5 [stat.ML] UPDATED)</h2>
<h3>Shixiang Zhu, Minghe Zhang, Ruyi Ding, Yao Xie</h3>
<p>We present a novel attention-based model for discrete event data to capture
complex non-linear temporal dependence structures. We borrow the idea from the
attention mechanism and incorporate it into the point processes' conditional
intensity function. We further introduce a novel score function using Fourier
kernel embedding, whose spectrum is represented using neural networks, which
drastically differs from the traditional dot-product kernel and can capture a
more complex similarity structure. We establish our approach's theoretical
properties and demonstrate our approach's competitive performance compared to
the state-of-the-art for synthetic and real data.
</p>
<a href="http://arxiv.org/abs/2002.07281" target="_blank">arXiv:2002.07281</a> [<a href="http://arxiv.org/pdf/2002.07281" target="_blank">pdf</a>]

<h2>Computing Valid p-value for Optimal Changepoint by Selective Inference using Dynamic Programming. (arXiv:2002.09132v2 [stat.ML] UPDATED)</h2>
<h3>Vo Nguyen Le Duy, Hiroki Toda, Ryota Sugiyama, Ichiro Takeuchi</h3>
<p>There is a vast body of literature related to methods for detecting
changepoints (CP). However, less attention has been paid to assessing the
statistical reliability of the detected CPs. In this paper, we introduce a
novel method to perform statistical inference on the significance of the CPs,
estimated by a Dynamic Programming (DP)-based optimal CP detection algorithm.
Based on the selective inference (SI) framework, we propose an exact
(non-asymptotic) approach to compute valid p-values for testing the
significance of the CPs. Although it is well-known that SI has low statistical
power because of over-conditioning, we address this disadvantage by introducing
parametric programming techniques. Then, we propose an efficient method to
conduct SI with the minimum amount of conditioning, leading to high statistical
power. We conduct experiments on both synthetic and real-world datasets,
through which we offer evidence that our proposed method is more powerful than
existing methods, has decent performance in terms of computational efficiency,
and provides good results in many practical applications.
</p>
<a href="http://arxiv.org/abs/2002.09132" target="_blank">arXiv:2002.09132</a> [<a href="http://arxiv.org/pdf/2002.09132" target="_blank">pdf</a>]

<h2>Transformer Hawkes Process. (arXiv:2002.09291v5 [cs.LG] UPDATED)</h2>
<h3>Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, Hongyuan Zha</h3>
<p>Modern data acquisition routinely produce massive amounts of event sequence
data in various domains, such as social media, healthcare, and financial
markets. These data often exhibit complicated short-term and long-term temporal
dependencies. However, most of the existing recurrent neural network based
point process models fail to capture such dependencies, and yield unreliable
prediction performance. To address this issue, we propose a Transformer Hawkes
Process (THP) model, which leverages the self-attention mechanism to capture
long-term dependencies and meanwhile enjoys computational efficiency. Numerical
experiments on various datasets show that THP outperforms existing models in
terms of both likelihood and event prediction accuracy by a notable margin.
Moreover, THP is quite general and can incorporate additional structural
knowledge. We provide a concrete example, where THP achieves improved
prediction performance for learning multiple point processes when incorporating
their relational information.
</p>
<a href="http://arxiv.org/abs/2002.09291" target="_blank">arXiv:2002.09291</a> [<a href="http://arxiv.org/pdf/2002.09291" target="_blank">pdf</a>]

<h2>TrojanNet: Embedding Hidden Trojan Horse Models in Neural Networks. (arXiv:2002.10078v2 [cs.LG] UPDATED)</h2>
<h3>Chuan Guo, Ruihan Wu, Kilian Q. Weinberger</h3>
<p>The complexity of large-scale neural networks can lead to poor understanding
of their internal details. We show that this opaqueness provides an opportunity
for adversaries to embed unintended functionalities into the network in the
form of Trojan horses. Our novel framework hides the existence of a Trojan
network with arbitrary desired functionality within a benign transport network.
We prove theoretically that the Trojan network's detection is computationally
infeasible and demonstrate empirically that the transport network does not
compromise its disguise. Our paper exposes an important, previously unknown
loophole that could potentially undermine the security and trustworthiness of
machine learning.
</p>
<a href="http://arxiv.org/abs/2002.10078" target="_blank">arXiv:2002.10078</a> [<a href="http://arxiv.org/pdf/2002.10078" target="_blank">pdf</a>]

<h2>Bandit Learning with Delayed Impact of Actions. (arXiv:2002.10316v3 [cs.LG] UPDATED)</h2>
<h3>Wei Tang, Chien-Ju Ho, Yang Liu</h3>
<p>We consider a stochastic multi-armed bandit (MAB) problem with delayed impact
of actions. In our setting, actions taken in the past impact the arm rewards in
the subsequent future. This delayed impact of actions is prevalent in the real
world. For example, the capability to pay back a loan for people in a certain
social group might depend on historically how frequently that group has been
approved loan applications. If banks keep rejecting loan applications to people
in a disadvantaged group, it could create a feedback loop and further damage
the chance of getting loans for people in that group. In this paper, we
formulate this delayed and long-term impact of actions within the context of
multi-armed bandits. We generalize the classical bandit setting to encode the
dependency of this "bias" due to the action history during learning. The goal
is to maximize the collected utilities over time while taking into account the
dynamics created by the delayed impacts of historical actions. We propose an
algorithm that achieves a regret of $\tilde{\mathcal{O}}(KT^{2/3})$ and show a
matching regret lower bound of $\Omega(KT^{2/3})$, where $K$ is the number of
arms and $T$ is the learning horizon. Our results complement the bandit
literature by adding techniques to deal with actions with long-term impacts and
have implications in designing fair algorithms.
</p>
<a href="http://arxiv.org/abs/2002.10316" target="_blank">arXiv:2002.10316</a> [<a href="http://arxiv.org/pdf/2002.10316" target="_blank">pdf</a>]

<h2>Scene Completeness-Aware Lidar Depth Completion for Driving Scenario. (arXiv:2003.06945v3 [cs.CV] UPDATED)</h2>
<h3>Cho-Ying Wu, Ulrich Neumann</h3>
<p>This paper introduces Scene Completeness-Aware Depth Completion (SCADC) to
complete raw lidar scans into dense depth maps with fine and complete scene
structures. Recent sparse depth completion for lidars only focuses on the lower
scenes and produces irregular estimations on the upper because existing
datasets, such as KITTI, do not provide groundtruth for upper areas. These
areas are considered less important since they are usually sky or trees of less
scene understanding interest. However, we argue that in several driving
scenarios such as large trucks or cars with loads, objects could extend to the
upper parts of scenes. Thus depth maps with structured upper scene estimation
are important for RGBD algorithms. SCADC adopts stereo images that produce
disparities with better scene completeness but are generally less precise than
lidars, to help sparse lidar depth completion. To our knowledge, we are the
first to focus on scene completeness of sparse depth completion. We validate
our SCADC on both depth estimate precision and scene-completeness on KITTI.
Moreover, we experiment on less-explored outdoor RGBD semantic segmentation
with scene completeness-aware D-input to validate our method.
</p>
<a href="http://arxiv.org/abs/2003.06945" target="_blank">arXiv:2003.06945</a> [<a href="http://arxiv.org/pdf/2003.06945" target="_blank">pdf</a>]

<h2>Anomalous Example Detection in Deep Learning: A Survey. (arXiv:2003.06979v2 [cs.LG] UPDATED)</h2>
<h3>Saikiran Bulusu, Bhavya Kailkhura, Bo Li, Pramod K. Varshney, Dawn Song</h3>
<p>Deep Learning (DL) is vulnerable to out-of-distribution and adversarial
examples resulting in incorrect outputs. To make DL more robust, several
posthoc (or runtime) anomaly detection techniques to detect (and discard) these
anomalous samples have been proposed in the recent past. This survey tries to
provide a structured and comprehensive overview of the research on anomaly
detection for DL based applications. We provide a taxonomy for existing
techniques based on their underlying assumptions and adopted approaches. We
discuss various techniques in each of the categories and provide the relative
strengths and weaknesses of the approaches. Our goal in this survey is to
provide an easier yet better understanding of the techniques belonging to
different categories in which research has been done on this topic. Finally, we
highlight the unsolved research challenges while applying anomaly detection
techniques in DL systems and present some high-impact future research
directions.
</p>
<a href="http://arxiv.org/abs/2003.06979" target="_blank">arXiv:2003.06979</a> [<a href="http://arxiv.org/pdf/2003.06979" target="_blank">pdf</a>]

<h2>Not All Features Are Equal: Discovering Essential Features for Preserving Prediction Privacy. (arXiv:2003.12154v2 [cs.LG] UPDATED)</h2>
<h3>Fatemehsadat Mireshghallah, Mohammadkazem Taram, Ali Jalali, Ahmed Taha Elthakeb, Dean Tullsen, Hadi Esmaeilzadeh</h3>
<p>When receiving machine learning services from the cloud, the provider does
not need to receive all features; in fact, only a subset of the features are
necessary for the target prediction task. Discerning this subset is the key
problem of this work. We formulate this problem as a gradient-based
perturbation maximization method that discovers this subset in the input
feature space with respect to the functionality of the prediction model used by
the provider. After identifying the subset, our framework, Cloak, suppresses
the rest of the features using utility-preserving constant values that are
discovered through a separate gradient-based optimization process. We show that
Cloak does not necessarily require collaboration from the service provider
beyond its normal service, and can be applied in scenarios where we only have
black-box access to the service provider's model. We theoretically guarantee
that Cloak's optimizations reduce the upper bound of the Mutual Information
(MI) between the data and the sifted representations that are sent out.
Experimental results show that Cloak reduces the mutual information between the
input and the sifted representations by 85.01% with only a negligible reduction
in utility (1.42%). In addition, we show that Cloak greatly diminishes
adversaries' ability to learn and infer non-conducive features.
</p>
<a href="http://arxiv.org/abs/2003.12154" target="_blank">arXiv:2003.12154</a> [<a href="http://arxiv.org/pdf/2003.12154" target="_blank">pdf</a>]

<h2>MetaPoison: Practical General-purpose Clean-label Data Poisoning. (arXiv:2004.00225v2 [cs.LG] UPDATED)</h2>
<h3>W. Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, Tom Goldstein</h3>
<p>Data poisoning -- the process by which an attacker takes control of a model
by making imperceptible changes to a subset of the training data -- is an
emerging threat in the context of neural networks. Existing attacks for data
poisoning neural networks have relied on hand-crafted heuristics, because
solving the poisoning problem directly via bilevel optimization is generally
thought of as intractable for deep models. We propose MetaPoison, a first-order
method that approximates the bilevel problem via meta-learning and crafts
poisons that fool neural networks. MetaPoison is effective: it outperforms
previous clean-label poisoning methods by a large margin. MetaPoison is robust:
poisoned data made for one model transfer to a variety of victim models with
unknown training settings and architectures. MetaPoison is general-purpose, it
works not only in fine-tuning scenarios, but also for end-to-end training from
scratch, which till now hasn't been feasible for clean-label attacks with deep
nets. MetaPoison can achieve arbitrary adversary goals -- like using poisons of
one class to make a target image don the label of another arbitrarily chosen
class. Finally, MetaPoison works in the real-world. We demonstrate for the
first time successful data poisoning of models trained on the black-box Google
Cloud AutoML API. Code and premade poisons are provided at
https://github.com/wronnyhuang/metapoison
</p>
<a href="http://arxiv.org/abs/2004.00225" target="_blank">arXiv:2004.00225</a> [<a href="http://arxiv.org/pdf/2004.00225" target="_blank">pdf</a>]

<h2>Parametric Programming Approach for More Powerful and General Lasso Selective Inference. (arXiv:2004.09749v3 [stat.ML] UPDATED)</h2>
<h3>Vo Nguyen Le Duy, Ichiro Takeuchi</h3>
<p>Selective Inference (SI) has been actively studied in the past few years for
conducting inference on the features of linear models that are adaptively
selected by feature selection methods such as Lasso. The basic idea of SI is to
make inference conditional on the selection event. Unfortunately, the main
limitation of the original SI approach for Lasso is that the inference is
conducted not only conditional on the selected features but also on their signs
-- this leads to loss of power because of over-conditioning. Although this
limitation can be circumvented by considering the union of such selection
events for all possible combinations of signs, this is only feasible when the
number of selected features is sufficiently small. To address this
computational bottleneck, we propose a parametric programming-based method that
can conduct SI without conditioning on signs even when we have thousands of
active features. The main idea is to compute the continuum path of Lasso
solutions in the direction of a test statistic, and identify the subset of the
data space corresponding to the feature selection event by following the
solution path. The proposed parametric programming-based method not only avoids
the aforementioned computational bottleneck but also improves the performance
and practicality of SI for Lasso in various respects. We conduct several
experiments to demonstrate the effectiveness and efficiency of our proposed
method.
</p>
<a href="http://arxiv.org/abs/2004.09749" target="_blank">arXiv:2004.09749</a> [<a href="http://arxiv.org/pdf/2004.09749" target="_blank">pdf</a>]

<h2>On the Limits to Multi-Modal Popularity Prediction on Instagram -- A New Robust, Efficient and Explainable Baseline. (arXiv:2004.12482v2 [cs.CV] UPDATED)</h2>
<h3>Christoffer Riis, Damian Konrad Kowalczyk, Lars Kai Hansen</h3>
<p>Our global population contributes visual content on platforms like Instagram,
attempting to express themselves and engage their audiences, at an
unprecedented and increasing rate. In this paper, we revisit the popularity
prediction on Instagram. We present a robust, efficient, and explainable
baseline for population-based popularity prediction, achieving strong ranking
performance. We employ the latest methods in computer vision to maximize the
information extracted from the visual modality. We use transfer learning to
extract visual semantics such as concepts, scenes, and objects, allowing a new
level of scrutiny in an extensive, explainable ablation study. We inform
feature selection towards a robust and scalable model, but also illustrate
feature interactions, offering new directions for further inquiry in
computational social science. Our strongest models inform a lower limit to
population-based predictability of popularity on Instagram. The models are
immediately applicable to social media monitoring and influencer
identification.
</p>
<a href="http://arxiv.org/abs/2004.12482" target="_blank">arXiv:2004.12482</a> [<a href="http://arxiv.org/pdf/2004.12482" target="_blank">pdf</a>]

<h2>Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork. (arXiv:2004.13102v3 [cs.AI] UPDATED)</h2>
<h3>Gagan Bansal, Besmira Nushi, Ece Kamar, Eric Horvitz, Daniel S. Weld</h3>
<p>AI practitioners typically strive to develop the most accurate systems,
making an implicit assumption that the AI system will function autonomously.
However, in practice, AI systems often are used to provide advice to people in
domains ranging from criminal justice and finance to healthcare. In such
AI-advised decision making, humans and machines form a team, where the human is
responsible for making final decisions. But is the most accurate AI the best
teammate? We argue "No" -- predictable performance may be worth a slight
sacrifice in AI accuracy. Instead, we argue that AI systems should be trained
in a human-centered manner, directly optimized for team performance. We study
this proposal for a specific type of human-AI teaming, where the human overseer
chooses to either accept the AI recommendation or solve the task themselves. To
optimize the team performance for this setting we maximize the team's expected
utility, expressed in terms of the quality of the final decision, cost of
verifying, and individual accuracies of people and machines. Our experiments
with linear and non-linear models on real-world, high-stakes datasets show that
the most accuracy AI may not lead to highest team performance and show the
benefit of modeling teamwork during training through improvements in expected
team utility across datasets, considering parameters such as human skill and
the cost of mistakes. We discuss the shortcoming of current optimization
approaches beyond well-studied loss functions such as log-loss, and encourage
future work on AI optimization problems motivated by human-AI collaboration.
</p>
<a href="http://arxiv.org/abs/2004.13102" target="_blank">arXiv:2004.13102</a> [<a href="http://arxiv.org/pdf/2004.13102" target="_blank">pdf</a>]

<h2>Entity-Enriched Neural Models for Clinical Question Answering. (arXiv:2005.06587v2 [cs.AI] UPDATED)</h2>
<h3>Bhanu Pratap Singh Rawat, Wei-Hung Weng, So Yeon Min, Preethi Raghavan, Peter Szolovits</h3>
<p>We explore state-of-the-art neural models for question answering on
electronic medical records and improve their ability to generalize better on
previously unseen (paraphrased) questions at test time. We enable this by
learning to predict logical forms as an auxiliary task along with the main task
of answer span detection. The predicted logical forms also serve as a rationale
for the answer. Further, we also incorporate medical entity information in
these models via the ERNIE architecture. We train our models on the large-scale
emrQA dataset and observe that our multi-task entity-enriched models generalize
to paraphrased questions ~5% better than the baseline BERT model.
</p>
<a href="http://arxiv.org/abs/2005.06587" target="_blank">arXiv:2005.06587</a> [<a href="http://arxiv.org/pdf/2005.06587" target="_blank">pdf</a>]

<h2>Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and Wild. (arXiv:2005.13983v5 [cs.CV] UPDATED)</h2>
<h3>Weixia Zhang, Kede Ma, Guangtao Zhai, Xiaokang Yang</h3>
<p>Performance of blind image quality assessment (BIQA) models has been
significantly boosted by end-to-end optimization of feature engineering and
quality regression. Nevertheless, due to the distributional shift between
images simulated in the laboratory and captured in the wild, models trained on
databases with synthetic distortions remain particularly weak at handling
realistic distortions (and vice versa). To confront the
cross-distortion-scenario challenge, we develop a \textit{unified} BIQA model
and an approach of training it for both synthetic and realistic distortions. We
first sample pairs of images from individual IQA databases, and compute a
probability that the first image of each pair is of higher quality. We then
employ the fidelity loss to optimize a deep neural network for BIQA over a
large number of such image pairs. We also explicitly enforce a hinge constraint
to regularize uncertainty estimation during optimization. Extensive experiments
on six IQA databases show the promise of the learned method in blindly
assessing image quality in the laboratory and wild. In addition, we demonstrate
the universality of the proposed training strategy by using it to improve
existing BIQA models.
</p>
<a href="http://arxiv.org/abs/2005.13983" target="_blank">arXiv:2005.13983</a> [<a href="http://arxiv.org/pdf/2005.13983" target="_blank">pdf</a>]

<h2>Shapley explainability on the data manifold. (arXiv:2006.01272v3 [cs.LG] UPDATED)</h2>
<h3>Christopher Frye, Damien de Mijolla, Tom Begley, Laurence Cowton, Megan Stanley, Ilya Feige</h3>
<p>Explainability in AI is crucial for model development, compliance with
regulation, and providing operational nuance to predictions. The Shapley
framework for explainability attributes a model's predictions to its input
features in a mathematically principled and model-agnostic way. However,
general implementations of Shapley explainability make an untenable assumption:
that the model's features are uncorrelated. In this work, we demonstrate
unambiguous drawbacks of this assumption and develop two solutions to Shapley
explainability that respect the data manifold. One solution, based on
generative modelling, provides flexible access to data imputations; the other
directly learns the Shapley value-function, providing performance and stability
at the cost of flexibility. While "off-manifold" Shapley values can (i) give
rise to incorrect explanations, (ii) hide implicit model dependence on
sensitive attributes, and (iii) lead to unintelligible explanations in
higher-dimensional data, on-manifold explainability overcomes these problems.
</p>
<a href="http://arxiv.org/abs/2006.01272" target="_blank">arXiv:2006.01272</a> [<a href="http://arxiv.org/pdf/2006.01272" target="_blank">pdf</a>]

<h2>Autonomous Driving: Framework for Pedestrian Intention Estimationin a Real World Scenario. (arXiv:2006.02711v2 [cs.RO] UPDATED)</h2>
<h3>Walter Morales Alvarez, Francisco Miguel Moreno, Oscar Sipele, Nikita Smirnov, Cristina Olaverri-Monreal</h3>
<p>Rapid advancements in driver-assistance technology will lead to the
integration of fully autonomous vehicles on our roads that will interact with
other road users. To address the problem that driverless vehicles make
interaction through eye contact impossible, we describe a framework for
estimating the crossing intentions of pedestrians in order to reduce the
uncertainty that the lack of eye contact between road users creates. The
framework was deployed in a real vehicle and tested with three experimental
cases that showed a variety of communication messages to pedestrians in a
shared space scenario. Results from the performed field tests showed the
feasibility of the presented approach.
</p>
<a href="http://arxiv.org/abs/2006.02711" target="_blank">arXiv:2006.02711</a> [<a href="http://arxiv.org/pdf/2006.02711" target="_blank">pdf</a>]

<h2>Distributionally Robust Weighted $k$-Nearest Neighbors. (arXiv:2006.04004v4 [stat.ML] UPDATED)</h2>
<h3>Shixiang Zhu, Liyan Xie, Minghe Zhang, Rui Gao, Yao Xie</h3>
<p>Learning a robust classifier from a few samples remains a key challenge in
machine learning. A major thrust of research has been focused on developing
$k$-nearest neighbor ($k$-NN) based algorithms combined with metric learning
that captures similarities between samples. When the samples are limited,
robustness is especially crucial to ensure the generalization capability of the
classifier. In this paper, we study a minimax distributionally robust
formulation of weighted $k$-nearest neighbors, which aims to find the optimal
weighted $k$-NN classifiers that hedge against feature perturbations. We
develop an algorithm, Dr.k-NN, that efficiently solves this functional
optimization problem and features in assigning minimax optimal weights to
training samples when performing classification. These weights are
class-dependent, and are determined by the similarities of sample features
under the least favorable scenarios. We also couple our framework with
neural-network-based feature embedding. We demonstrate the competitive
performance of our algorithm compared to the state-of-the-art in the
few-training-sample setting with various real-data experiments.
</p>
<a href="http://arxiv.org/abs/2006.04004" target="_blank">arXiv:2006.04004</a> [<a href="http://arxiv.org/pdf/2006.04004" target="_blank">pdf</a>]

<h2>Sharp Representation Theorems for ReLU Networks with Precise Dependence on Depth. (arXiv:2006.04048v2 [stat.ML] UPDATED)</h2>
<h3>Guy Bresler, Dheeraj Nagaraj</h3>
<p>We prove sharp dimension-free representation results for neural networks with
$D$ ReLU layers under square loss for a class of functions $\mathcal{G}_D$
defined in the paper. These results capture the precise benefits of depth in
the following sense:

1. The rates for representing the class of functions $\mathcal{G}_D$ via $D$
ReLU layers is sharp up to constants, as shown by matching lower bounds.

2. For each $D$, $\mathcal{G}_{D} \subseteq \mathcal{G}_{D+1}$ and as $D$
grows the class of functions $\mathcal{G}_{D}$ contains progressively less
smooth functions.

3. If $D^{\prime} &lt; D$, then the approximation rate for the class
$\mathcal{G}_D$ achieved by depth $D^{\prime}$ networks is strictly worse than
that achieved by depth $D$ networks.

This constitutes a fine-grained characterization of the representation power
of feedforward networks of arbitrary depth $D$ and number of neurons $N$, in
contrast to existing representation results which either require $D$ growing
quickly with $N$ or assume that the function being represented is highly
smooth. In the latter case similar rates can be obtained with a single
nonlinear layer. Our results confirm the prevailing hypothesis that deeper
networks are better at representing less smooth functions, and indeed, the main
technical novelty is to fully exploit the fact that deep networks can produce
highly oscillatory functions with few activation functions.
</p>
<a href="http://arxiv.org/abs/2006.04048" target="_blank">arXiv:2006.04048</a> [<a href="http://arxiv.org/pdf/2006.04048" target="_blank">pdf</a>]

<h2>Characterizing Impacts of Heterogeneity in Federated Learning upon Large-Scale Smartphone Data. (arXiv:2006.06983v3 [cs.LG] UPDATED)</h2>
<h3>Chengxu Yang, QiPeng Wang, Mengwei Xu, Zhenpeng Chen, Kaigui Bian, Yunxin Liu, Xuanzhe Liu</h3>
<p>Federated learning (FL) is an emerging, privacy-preserving machine learning
paradigm, drawing tremendous attention in both academia and industry. A unique
characteristic of FL is heterogeneity, which resides in the various hardware
specifications and dynamic states across the participating devices.
Theoretically, heterogeneity can exert a huge influence on the FL training
process, e.g., causing a device unavailable for training or unable to upload
its model updates. Unfortunately, these impacts have never been systematically
studied and quantified in existing FL literature.

In this paper, we carry out the first empirical study to characterize the
impacts of heterogeneity in FL. We collect large-scale data from 136k
smartphones that can faithfully reflect heterogeneity in real-world settings.
We also build a heterogeneity-aware FL platform that complies with the standard
FL protocol but with heterogeneity in consideration. Based on the data and the
platform, we conduct extensive experiments to compare the performance of
state-of-the-art FL algorithms under heterogeneity-aware and
heterogeneity-unaware settings. Results show that heterogeneity causes
non-trivial performance degradation in FL, including up to 9.2% accuracy drop,
2.32x lengthened training time, and undermined fairness. Furthermore, we
analyze potential impact factors and find that device failure and participant
bias are two potential factors for performance degradation. Our study provides
insightful implications for FL practitioners. On the one hand, our findings
suggest that FL algorithm designers consider necessary heterogeneity during the
evaluation. On the other hand, our findings urge system providers to design
specific mechanisms to mitigate the impacts of heterogeneity.
</p>
<a href="http://arxiv.org/abs/2006.06983" target="_blank">arXiv:2006.06983</a> [<a href="http://arxiv.org/pdf/2006.06983" target="_blank">pdf</a>]

<h2>Defending SVMs against Poisoning Attacks: the Hardness and DBSCAN Approach. (arXiv:2006.07757v5 [cs.LG] UPDATED)</h2>
<h3>Hu Ding, Fan Yang, Jiawei Huang</h3>
<p>Adversarial machine learning has attracted a great amount of attention in
recent years. In a poisoning attack, the adversary can inject a small number of
specially crafted samples into the training data which make the decision
boundary severely deviate and cause unexpected misclassification. Due to the
great importance and popular use of support vector machines (SVM), we consider
defending SVM against poisoning attacks in this paper. We study two commonly
used strategies for defending: designing robust SVM algorithms and data
sanitization. Though several robust SVM algorithms have been proposed before,
most of them either are in lack of adversarial-resilience, or rely on strong
assumptions about the data distribution or the attacker's behavior. Moreover,
the research on their complexities is still quite limited. We are the first, to
the best of our knowledge, to prove that even the simplest hard-margin
one-class SVM with outliers problem is NP-complete, and has no fully PTAS
unless P$=$NP (that means it is hard to achieve an even approximate algorithm).
For the data sanitization defense, we link it to the intrinsic dimensionality
of data; in particular, we provide a sampling theorem in doubling metrics for
explaining the effectiveness of DBSCAN (as a density-based outlier removal
method) for defending against poisoning attacks. In our empirical experiments,
we compare several defenses including the DBSCAN and robust SVM methods, and
investigate the influences from the intrinsic dimensionality and data density
to their performances.
</p>
<a href="http://arxiv.org/abs/2006.07757" target="_blank">arXiv:2006.07757</a> [<a href="http://arxiv.org/pdf/2006.07757" target="_blank">pdf</a>]

<h2>Improving Adversarial Robustness via Unlabeled Out-of-Domain Data. (arXiv:2006.08476v2 [cs.LG] UPDATED)</h2>
<h3>Zhun Deng, Linjun Zhang, Amirata Ghorbani, James Zou</h3>
<p>Data augmentation by incorporating cheap unlabeled data from multiple domains
is a powerful way to improve prediction especially when there is limited
labeled data. In this work, we investigate how adversarial robustness can be
enhanced by leveraging out-of-domain unlabeled data. We demonstrate that for
broad classes of distributions and classifiers, there exists a sample
complexity gap between standard and robust classification. We quantify to what
degree this gap can be bridged via leveraging unlabeled samples from a shifted
domain by providing both upper and lower bounds. Moreover, we show settings
where we achieve better adversarial robustness when the unlabeled data come
from a shifted domain rather than the same domain as the labeled data. We also
investigate how to leverage out-of-domain data when some structural
information, such as sparsity, is shared between labeled and unlabeled domains.
Experimentally, we augment two object recognition datasets (CIFAR-10 and SVHN)
with easy to obtain and unlabeled out-of-domain data and demonstrate
substantial improvement in the model's robustness against $\ell_\infty$
adversarial attacks on the original domain.
</p>
<a href="http://arxiv.org/abs/2006.08476" target="_blank">arXiv:2006.08476</a> [<a href="http://arxiv.org/pdf/2006.08476" target="_blank">pdf</a>]

<h2>Balance is key: Private median splits yield high-utility random trees. (arXiv:2006.08795v2 [cs.LG] UPDATED)</h2>
<h3>Shorya Consul, Sinead A. Williamson</h3>
<p>Random forests are a popular method for classification and regression due to
their versatility. However, this flexibility can come at the cost of user
privacy, since training random forests requires multiple data queries, often on
small, identifiable subsets of the training data. Privatizing these queries
typically comes at a high utility cost, in large part because we are
privatizing queries on small subsets of the data, which are easily corrupted by
added noise. In this paper, we propose DiPriMe forests, a novel tree-based
ensemble method for differentially private regression and classification, which
is appropriate for real or categorical covariates. We generate splits using a
differentially private version of the median, which encourages balanced leaf
nodes. By avoiding low occupancy leaf nodes, we avoid high signal-to-noise
ratios when privatizing the leaf node sufficient statistics. We show
theoretically and empirically that the resulting algorithm exhibits high
utility, while ensuring differential privacy.
</p>
<a href="http://arxiv.org/abs/2006.08795" target="_blank">arXiv:2006.08795</a> [<a href="http://arxiv.org/pdf/2006.08795" target="_blank">pdf</a>]

<h2>Mobile Delivery Robots: Mixed Reality-Based Simulation Relying on ROS and Unity 3D. (arXiv:2006.09002v2 [cs.RO] UPDATED)</h2>
<h3>Yuzhou Liu, Georg Novotny, Nikita Smirnov, Walter Morales-Alvarez, Cristina Olaverri-Monreal</h3>
<p>In the context of Intelligent Transportation Systems and the delivery of
goods, new technology approaches need to be developed in order to cope with
certain challenges that last mile delivery entails, such as navigation in an
urban environment. Autonomous delivery robots can help overcome these
challenges. We propose a method for performing mixed reality (MR) simulation
with ROS-based robots using Unity, which synchronizes the real and virtual
environment, and simultaneously uses the sensor information of the real robots
to locate themselves and project them into the virtual environment, so that
they can use their virtual doppelganger to perceive the virtual world. Using
this method, real and virtual robots can perceive each other and the
environment in which the other party is located, thereby enabling the exchange
of information between virtual and real objects. Through this approach a more
realistic and reliable simulation can be obtained. Results of the demonstrated
use-cases verified the feasibility and efficiency as well as the stability of
implementing MR using Unity for ROS-based robots.
</p>
<a href="http://arxiv.org/abs/2006.09002" target="_blank">arXiv:2006.09002</a> [<a href="http://arxiv.org/pdf/2006.09002" target="_blank">pdf</a>]

<h2>Primal Dual Interpretation of the Proximal Stochastic Gradient Langevin Algorithm. (arXiv:2006.09270v2 [stat.ML] UPDATED)</h2>
<h3>Adil Salim, Peter Richt&#xe1;rik</h3>
<p>We consider the task of sampling with respect to a log concave probability
distribution. The potential of the target distribution is assumed to be
composite, \textit{i.e.}, written as the sum of a smooth convex term, and a
nonsmooth convex term possibly taking infinite values. The target distribution
can be seen as a minimizer of the Kullback-Leibler divergence defined on the
Wasserstein space (\textit{i.e.}, the space of probability measures). In the
first part of this paper, we establish a strong duality result for this
minimization problem. In the second part of this paper, we use the duality gap
arising from the first part to study the complexity of the Proximal Stochastic
Gradient Langevin Algorithm (PSGLA), which can be seen as a generalization of
the Projected Langevin Algorithm. Our approach relies on viewing PSGLA as a
primal dual algorithm and covers many cases where the target distribution is
not fully supported. In particular, we show that if the potential is strongly
convex, the complexity of PSGLA is $O(1/\varepsilon^2)$ in terms of the
2-Wasserstein distance. In contrast, the complexity of the Projected Langevin
Algorithm is $O(1/\varepsilon^{12})$ in terms of total variation when the
potential is convex.
</p>
<a href="http://arxiv.org/abs/2006.09270" target="_blank">arXiv:2006.09270</a> [<a href="http://arxiv.org/pdf/2006.09270" target="_blank">pdf</a>]

<h2>Towards a Neural Graphics Pipeline for Controllable Image Generation. (arXiv:2006.10569v2 [cs.CV] UPDATED)</h2>
<h3>Xuelin Chen, Daniel Cohen-Or, Baoquan Chen, Niloy J. Mitra</h3>
<p>In this paper, we leverage advances in neural networks towards forming a
neural rendering for controllable image generation, and thereby bypassing the
need for detailed modeling in conventional graphics pipeline. To this end, we
present Neural Graphics Pipeline (NGP), a hybrid generative model that brings
together neural and traditional image formation models. NGP decomposes the
image into a set of interpretable appearance feature maps, uncovering direct
control handles for controllable image generation. To form an image, NGP
generates coarse 3D models that are fed into neural rendering modules to
produce view-specific interpretable 2D maps, which are then composited into the
final output image using a traditional image formation model. Our approach
offers control over image generation by providing direct handles controlling
illumination and camera parameters, in addition to control over shape and
appearance variations. The key challenge is to learn these controls through
unsupervised training that links generated coarse 3D models with unpaired real
images via neural and traditional (e.g., Blinn- Phong) rendering functions,
without establishing an explicit correspondence between them. We demonstrate
the effectiveness of our approach on controllable image generation of
single-object scenes. We evaluate our hybrid modeling framework, compare with
neural-only generation methods (namely, DCGAN, LSGAN, WGAN-GP, VON, and SRNs),
report improvement in FID scores against real images, and demonstrate that NGP
supports direct controls common in traditional forward rendering. Code is
available at this http URL
</p>
<a href="http://arxiv.org/abs/2006.10569" target="_blank">arXiv:2006.10569</a> [<a href="http://arxiv.org/pdf/2006.10569" target="_blank">pdf</a>]

<h2>Free-rider Attacks on Model Aggregation in Federated Learning. (arXiv:2006.11901v5 [cs.LG] UPDATED)</h2>
<h3>Yann Fraboni, Richard Vidal, Marco Lorenzi</h3>
<p>Free-rider attacks against federated learning consist in dissimulating
participation to the federated learning process with the goal of obtaining the
final aggregated model without actually contributing with any data. This kind
of attacks is critical in sensitive applications of federated learning, where
data is scarce and the model has high commercial value. We introduce here the
first theoretical and experimental analysis of free-rider attacks on federated
learning schemes based on iterative parameters aggregation, such as FedAvg or
FedProx, and provide formal guarantees for these attacks to converge to the
aggregated models of the fair participants. We first show that a
straightforward implementation of this attack can be simply achieved by not
updating the local parameters during the iterative federated optimization. As
this attack can be detected by adopting simple countermeasures at the server
level, we subsequently study more complex disguising schemes based on
stochastic updates of the free-rider parameters. We demonstrate the proposed
strategies on a number of experimental scenarios, in both iid and non-iid
settings. We conclude by providing recommendations to avoid free-rider attacks
in real world applications of federated learning, especially in sensitive
domains where security of data and models is critical.
</p>
<a href="http://arxiv.org/abs/2006.11901" target="_blank">arXiv:2006.11901</a> [<a href="http://arxiv.org/pdf/2006.11901" target="_blank">pdf</a>]

<h2>Meta Learning for Support Recovery in High-dimensional Precision Matrix Estimation. (arXiv:2006.12598v2 [cs.LG] UPDATED)</h2>
<h3>Qian Zhang, Yilin Zheng, Jean Honorio</h3>
<p>In this paper, we study meta learning for support (i.e., the set of non-zero
entries) recovery in high-dimensional precision matrix estimation where we
reduce the sufficient sample complexity in a novel task with the information
learned from other auxiliary tasks. In our setup, each task has a different
random true precision matrix, each with a possibly different support. We assume
that the union of the supports of all the true precision matrices (i.e., the
true support union) is small in size. We propose to pool all the samples from
different tasks, and \emph{improperly} estimate a single precision matrix by
minimizing the $\ell_1$-regularized log-determinant Bregman divergence. We show
that with high probability, the support of the \emph{improperly} estimated
single precision matrix is equal to the true support union, provided a
sufficient number of samples per task $n \in O((\log N)/K)$, for
$N$-dimensional vectors and $K$ tasks. That is, one requires less samples per
task when more tasks are available. We prove a matching information-theoretic
lower bound for the necessary number of samples, which is $n \in \Omega((\log
N)/K)$, and thus, our algorithm is minimax optimal. Then for the novel task, we
prove that the minimization of the $\ell_1$-regularized log-determinant Bregman
divergence with the additional constraint that the support is a subset of the
estimated support union could reduce the sufficient sample complexity of
successful support recovery to $O(\log(|S_{\text{off}}|))$ where
$|S_{\text{off}}|$ is the number of off-diagonal elements in the support union
and is much less than $N$ for sparse matrices. We also prove a matching
information-theoretic lower bound of $\Omega(\log(|S_{\text{off}}|))$ for the
necessary number of samples. Synthetic experiments validate our theory.
</p>
<a href="http://arxiv.org/abs/2006.12598" target="_blank">arXiv:2006.12598</a> [<a href="http://arxiv.org/pdf/2006.12598" target="_blank">pdf</a>]

<h2>Efficient Inference of Flexible Interaction in Spiking-neuron Networks. (arXiv:2006.12845v2 [stat.ML] UPDATED)</h2>
<h3>Feng Zhou, Yixuan Zhang, Jun Zhu</h3>
<p>Hawkes process provides an effective statistical framework for analyzing the
time-dependent interaction of neuronal spiking activities. Although utilized in
many real applications, the classic Hawkes process is incapable of modelling
inhibitory interactions among neurons. Instead, the nonlinear Hawkes process
allows for a more flexible influence pattern with excitatory or inhibitory
interactions. In this paper, three sets of auxiliary latent variables
(P\'{o}lya-Gamma variables, latent marked Poisson processes and sparsity
variables) are augmented to make functional connection weights in a Gaussian
form, which allows for a simple iterative algorithm with analytical updates. As
a result, an efficient expectation-maximization (EM) algorithm is derived to
obtain the maximum a posteriori (MAP) estimate. We demonstrate the accuracy and
efficiency performance of our algorithm on synthetic and real data. For real
neural recordings, we show our algorithm can estimate the temporal dynamics of
interaction and reveal the interpretable functional connectivity underlying
neural spike trains.
</p>
<a href="http://arxiv.org/abs/2006.12845" target="_blank">arXiv:2006.12845</a> [<a href="http://arxiv.org/pdf/2006.12845" target="_blank">pdf</a>]

<h2>Automatic Data Augmentation for Generalization in Deep Reinforcement Learning. (arXiv:2006.12862v2 [cs.LG] UPDATED)</h2>
<h3>Roberta Raileanu, Max Goldstein, Denis Yarats, Ilya Kostrikov, Rob Fergus</h3>
<p>Deep reinforcement learning (RL) agents often fail to generalize to unseen
scenarios, even when they are trained on many instances of semantically similar
environments. Data augmentation has recently been shown to improve the sample
efficiency and generalization of RL agents. However, different tasks tend to
benefit from different kinds of data augmentation. In this paper, we compare
three approaches for automatically finding an appropriate augmentation. These
are combined with two novel regularization terms for the policy and value
function, required to make the use of data augmentation theoretically sound for
certain actor-critic algorithms. We evaluate our methods on the Procgen
benchmark which consists of 16 procedurally-generated environments and show
that it improves test performance by ~40% relative to standard RL algorithms.
Our agent outperforms other baselines specifically designed to improve
generalization in RL. In addition, we show that our agent learns policies and
representations that are more robust to changes in the environment that do not
affect the agent, such as the background. Our implementation is available at
https://github.com/rraileanu/auto-drac.
</p>
<a href="http://arxiv.org/abs/2006.12862" target="_blank">arXiv:2006.12862</a> [<a href="http://arxiv.org/pdf/2006.12862" target="_blank">pdf</a>]

<h2>Online Competitive Influence Maximization. (arXiv:2006.13411v2 [cs.LG] UPDATED)</h2>
<h3>Jinhang Zuo, Xutong Liu, Carlee Joe-Wong, John C.S. Lui, Wei Chen</h3>
<p>Online influence maximization has attracted much attention as a way to
maximize influence spread through a social network while learning the values of
unknown network parameters. Most previous works focus on single-item diffusion.
In this paper, we introduce a new Online Competitive Influence Maximization
(OCIM) problem, where two competing items (e.g., products, news stories)
propagate in the same network and influence probabilities on edges are unknown.
We adapt the combinatorial multi-armed bandit (CMAB) framework for the OCIM
problem, but unlike the non-competitive setting, the important monotonicity
property (influence spread increases when influence probabilities on edges
increase) no longer holds due to the competitive nature of propagation, which
brings a significant new challenge to the problem. We prove that the Triggering
Probability Modulated (TPM) condition for CMAB still holds, and then utilize
the property of competitive diffusion to introduce a new offline oracle, and
discuss how to implement this new oracle in various cases. We propose an
OCIM-OIFU algorithm with such an oracle that achieves logarithmic regret. We
also design an OCIM-ETC algorithm that has worse regret bound but requires less
feedback and easier offline computation. Our experimental evaluations
demonstrate the effectiveness of our algorithms.
</p>
<a href="http://arxiv.org/abs/2006.13411" target="_blank">arXiv:2006.13411</a> [<a href="http://arxiv.org/pdf/2006.13411" target="_blank">pdf</a>]

<h2>Gradient Based Memory Editing for Task-Free Continual Learning. (arXiv:2006.15294v2 [stat.ML] UPDATED)</h2>
<h3>Xisen Jin, Arka Sadhu, Junyi Du, Xiang Ren</h3>
<p>We explore task-free continual learning (CL), in which a model is trained to
avoid catastrophic forgetting, but without being provided any explicit task
boundaries or identities. However, since CL models are continually updated, the
utility of stored seen examples may diminish over time. Here, we propose
Gradient based Memory EDiting (GMED), a framework for editing stored examples
in continuous input space via gradient updates, in order to create a wide range
of more ``challenging" examples for replay. GMED-edited examples remain similar
to their unedited forms, but can yield increased loss in the upcoming model
updates, thereby making the future replays more effective in overcoming
catastrophic forgetting. By construction, GMED can be seamlessly applied in
conjunction with other memory-based CL algorithms to bring further improvement.
Experiments on six datasets validate that GMED is effective, and our single
best method significantly outperforms existing approaches on three datasets.
Code and data can be found at https://github.com/INK-USC/GMED.
</p>
<a href="http://arxiv.org/abs/2006.15294" target="_blank">arXiv:2006.15294</a> [<a href="http://arxiv.org/pdf/2006.15294" target="_blank">pdf</a>]

<h2>Learning and Planning in Average-Reward Markov Decision Processes. (arXiv:2006.16318v2 [cs.LG] UPDATED)</h2>
<h3>Yi Wan, Abhishek Naik, Richard S. Sutton</h3>
<p>We introduce learning and planning algorithms for average-reward MDPs,
including 1) the first general proven-convergent off-policy model-free control
algorithm without reference states, 2) the first proven-convergent off-policy
model-free prediction algorithm, and 3) the first off-policy learning algorithm
that converges to the actual value function rather than to the value function
plus an offset. All of our algorithms are based on using the
temporal-difference error rather than the conventional error when updating the
estimate of the average reward. Our proof techniques are a slight
generalization of those by Abounadi, Bertsekas, and Borkar (2001). In
experiments with an Access-Control Queuing Task, we show some of the
difficulties that can arise when using methods that rely on reference states
and argue that our new algorithms can be significantly easier to use.
</p>
<a href="http://arxiv.org/abs/2006.16318" target="_blank">arXiv:2006.16318</a> [<a href="http://arxiv.org/pdf/2006.16318" target="_blank">pdf</a>]

<h2>Explaining Fast Improvement in Online Imitation Learning. (arXiv:2007.02520v3 [cs.LG] UPDATED)</h2>
<h3>Xinyan Yan, Byron Boots, Ching-An Cheng</h3>
<p>Online imitation learning (IL) is an algorithmic framework that leverages
interactions with expert policies for efficient policy optimization. Here
policies are optimized by performing online learning on a sequence of loss
functions that encourage the learner to mimic expert actions, and if the online
learning has no regret, the agent can provably learn an expert-like policy.
Online IL has demonstrated empirical successes in many applications and
interestingly, its policy improvement speed observed in practice is usually
much faster than existing theory suggests. In this work, we provide an
explanation of this phenomenon. Let $\xi$ denote the policy class bias and
assume the online IL loss functions are convex, smooth, and non-negative. We
prove that, after $N$ rounds of online IL with stochastic feedback, the policy
improves in $\tilde{O}(1/N + \sqrt{\xi/N})$ in both expectation and high
probability. In other words, we show that adopting a sufficiently expressive
policy class in online IL has two benefits: both the policy improvement speed
increases and the performance bias decreases.
</p>
<a href="http://arxiv.org/abs/2007.02520" target="_blank">arXiv:2007.02520</a> [<a href="http://arxiv.org/pdf/2007.02520" target="_blank">pdf</a>]

<h2>Meta Learning for Causal Direction. (arXiv:2007.02809v2 [stat.ML] UPDATED)</h2>
<h3>Jean-Francois Ton, Dino Sejdinovic, Kenji Fukumizu</h3>
<p>The inaccessibility of controlled randomized trials due to inherent
constraints in many fields of science has been a fundamental issue in causal
inference. In this paper, we focus on distinguishing the cause from effect in
the bivariate setting under limited observational data. Based on recent
developments in meta learning as well as in causal inference, we introduce a
novel generative model that allows distinguishing cause and effect in the small
data setting. Using a learnt task variable that contains distributional
information of each dataset, we propose an end-to-end algorithm that makes use
of similar training datasets at test time. We demonstrate our method on various
synthetic as well as real-world data and show that it is able to maintain high
accuracy in detecting directions across varying dataset sizes.
</p>
<a href="http://arxiv.org/abs/2007.02809" target="_blank">arXiv:2007.02809</a> [<a href="http://arxiv.org/pdf/2007.02809" target="_blank">pdf</a>]

<h2>Overcomplete order-3 tensor decomposition, blind deconvolution and Gaussian mixture models. (arXiv:2007.08133v2 [cs.LG] UPDATED)</h2>
<h3>Haolin Chen, Luis Rademacher</h3>
<p>We propose a new algorithm for tensor decomposition, based on Jennrich's
algorithm, and apply our new algorithmic ideas to blind deconvolution and
Gaussian mixture models. Our first contribution is a simple and efficient
algorithm to decompose certain symmetric overcomplete order-3 tensors, that is,
three dimensional arrays of the form $T = \sum_{i=1}^n a_i \otimes a_i \otimes
a_i$ where the $a_i$s are not linearly independent.Our algorithm comes with a
detailed robustness analysis. Our second contribution builds on top of our
tensor decomposition algorithm to expand the family of Gaussian mixture models
whose parameters can be estimated efficiently. These ideas are also presented
in a more general framework of blind deconvolution that makes them applicable
to mixture models of identical but very general distributions, including all
centrally symmetric distributions with finite 6th moment.
</p>
<a href="http://arxiv.org/abs/2007.08133" target="_blank">arXiv:2007.08133</a> [<a href="http://arxiv.org/pdf/2007.08133" target="_blank">pdf</a>]

<h2>Self-Tuning Bandits over Unknown Covariate-Shifts. (arXiv:2007.08584v4 [stat.ML] UPDATED)</h2>
<h3>Joseph Suk, Samory Kpotufe</h3>
<p>Bandits with covariates, a.k.a. contextual bandits, address situations where
optimal actions (or arms) at a given time $t$, depend on a context $x_t$, e.g.,
a new patient's medical history, a consumer's past purchases. While it is
understood that the distribution of contexts might change over time, e.g., due
to seasonalities, or deployment to new environments, the bulk of studies
concern the most adversarial such changes, resulting in regret bounds that are
often worst-case in nature.

Covariate-shift on the other hand has been considered in classification as a
middle-ground formalism that can capture mild to relatively severe changes in
distributions. We consider nonparametric bandits under such middle-ground
scenarios, and derive new regret bounds that tightly capture a continuum of
changes in context distribution. Furthermore, we show that these rates can be
adaptively attained without knowledge of the time of shift nor the amount of
shift.
</p>
<a href="http://arxiv.org/abs/2007.08584" target="_blank">arXiv:2007.08584</a> [<a href="http://arxiv.org/pdf/2007.08584" target="_blank">pdf</a>]

<h2>Event-based Stereo Visual Odometry. (arXiv:2007.15548v2 [cs.CV] UPDATED)</h2>
<h3>Yi Zhou, Guillermo Gallego, Shaojie Shen</h3>
<p>Event-based cameras are bio-inspired vision sensors whose pixels work
independently from each other and respond asynchronously to brightness changes,
with microsecond resolution. Their advantages make it possible to tackle
challenging scenarios in robotics, such as high-speed and high dynamic range
scenes. We present a solution to the problem of visual odometry from the data
acquired by a stereo event-based camera rig. Our system follows a parallel
tracking-and-mapping approach, where novel solutions to each subproblem (3D
reconstruction and camera pose estimation) are developed with two objectives in
mind: being principled and efficient, for real-time operation with commodity
hardware. To this end, we seek to maximize the spatio-temporal consistency of
stereo event-based data while using a simple and efficient representation.
Specifically, the mapping module builds a semi-dense 3D map of the scene by
fusing depth estimates from multiple local viewpoints (obtained by
spatio-temporal consistency) in a probabilistic fashion. The tracking module
recovers the pose of the stereo rig by solving a registration problem that
naturally arises due to the chosen map and event data representation.
Experiments on publicly available datasets and on our own recordings
demonstrate the versatility of the proposed method in natural scenes with
general 6-DoF motion. The system successfully leverages the advantages of
event-based cameras to perform visual odometry in challenging illumination
conditions, such as low-light and high dynamic range, while running in
real-time on a standard CPU. We release the software and dataset under an open
source licence to foster research in the emerging topic of event-based SLAM.
</p>
<a href="http://arxiv.org/abs/2007.15548" target="_blank">arXiv:2007.15548</a> [<a href="http://arxiv.org/pdf/2007.15548" target="_blank">pdf</a>]

<h2>A Scalable, Adaptive and Sound Nonconvex Regularizer for Low-rank Matrix Completion. (arXiv:2008.06542v4 [cs.LG] UPDATED)</h2>
<h3>Yaqing Wang, Quanming Yao, James T. Kwok</h3>
<p>Matrix learning is at the core of many machine learning problems. A number of
real-world applications such as collaborative filtering and text mining

can be formulated as a low-rank matrix completion problem, which recovers
incomplete matrix using low-rank assumptions. To ensure that the matrix
solution has a low rank, a recent trend is to use nonconvex regularizers that
adaptively penalize singular values. They offer good recovery performance and
have nice theoretical properties, but are computationally expensive due to
repeated access to individual singular values. In this paper, based on the key
insight that adaptive shrinkage on singular values improve empirical
performance, we propose a new nonconvex low-rank regularizer called "nuclear
norm minus Frobenius norm" regularizer, which is scalable, adaptive and sound.
We first show it provably holds the adaptive shrinkage property. Further, we
discover its factored form which bypasses the computation of singular values
and allows fast optimization by general optimization algorithms. Stable
recovery and convergence are guaranteed. Extensive low-rank matrix completion
experiments on a number of synthetic and real-world data sets show that the
proposed method obtains state-of-the-art recovery performance while being the
fastest in comparison to existing low-rank matrix learning methods.
</p>
<a href="http://arxiv.org/abs/2008.06542" target="_blank">arXiv:2008.06542</a> [<a href="http://arxiv.org/pdf/2008.06542" target="_blank">pdf</a>]

<h2>Collaborative Group Learning. (arXiv:2009.07712v4 [cs.LG] UPDATED)</h2>
<h3>Shaoxiong Feng, Hongshen Chen, Xuancheng Ren, Zhuoye Ding, Kan Li, Xu Sun</h3>
<p>Collaborative learning has successfully applied knowledge transfer to guide a
pool of small student networks towards robust local minima. However, previous
approaches typically struggle with drastically aggravated student
homogenization when the number of students rises. In this paper, we propose
Collaborative Group Learning, an efficient framework that aims to diversify the
feature representation and conduct an effective regularization. Intuitively,
similar to the human group study mechanism, we induce students to learn and
exchange different parts of course knowledge as collaborative groups. First,
each student is established by randomly routing on a modular neural network,
which facilitates flexible knowledge communication between students due to
random levels of representation sharing and branching. Second, to resist the
student homogenization, students first compose diverse feature sets by
exploiting the inductive bias from sub-sets of training data, and then
aggregate and distill different complementary knowledge by imitating a random
sub-group of students at each time step. Overall, the above mechanisms are
beneficial for maximizing the student population to further improve the model
generalization without sacrificing computational efficiency. Empirical
evaluations on both image and text tasks indicate that our method significantly
outperforms various state-of-the-art collaborative approaches whilst enhancing
computational efficiency.
</p>
<a href="http://arxiv.org/abs/2009.07712" target="_blank">arXiv:2009.07712</a> [<a href="http://arxiv.org/pdf/2009.07712" target="_blank">pdf</a>]

<h2>DTI-SNNFRA: Drug-Target interaction prediction by shared nearest neighbors and fuzzy-rough approximation. (arXiv:2009.10766v3 [cs.LG] UPDATED)</h2>
<h3>Sk Mazharul Islam, Sk Md Mosaddek Hossain, Sumanta Ray</h3>
<p>In-silico prediction of repurposable drugs is an effective drug discovery
strategy that supplements de-nevo drug discovery from scratch. Reduced
development time, less cost and absence of severe side effects are significant
advantages of using drug repositioning. Most recent and most advanced
artificial intelligence (AI) approaches have boosted drug repurposing in terms
of throughput and accuracy enormously. However, with the growing number of
drugs, targets and their massive interactions produce imbalanced data which may
not be suitable as input to the classification model directly. Here, we have
proposed DTI-SNNFRA, a framework for predicting drug-target interaction (DTI),
based on shared nearest neighbour (SNN) and fuzzy-rough approximation (FRA). It
uses sampling techniques to collectively reduce the vast search space covering
the available drugs, targets and millions of interactions between them.
DTI-SNNFRA operates in two stages: first, it uses SNN followed by a
partitioning clustering for sampling the search space. Next, it computes the
degree of fuzzy-rough approximations and proper degree threshold selection for
the negative samples' undersampling from all possible interaction pairs between
drugs and targets obtained in the first stage. Finally, classification is
performed using the positive and selected negative samples. We have evaluated
the efficacy of DTI-SNNFRA using AUC (Area under ROC Curve), Geometric Mean,
and F1 Score. The model performs exceptionally well with a high prediction
score of 0.95 for ROC-AUC. The predicted drug-target interactions are validated
through an existing drug-target database (Connectivity Map (Cmap)).
</p>
<a href="http://arxiv.org/abs/2009.10766" target="_blank">arXiv:2009.10766</a> [<a href="http://arxiv.org/pdf/2009.10766" target="_blank">pdf</a>]

<h2>How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks. (arXiv:2009.11848v4 [cs.LG] UPDATED)</h2>
<h3>Keyulu Xu, Mozhi Zhang, Jingling Li, Simon S. Du, Ken-ichi Kawarabayashi, Stefanie Jegelka</h3>
<p>We study how neural networks trained by gradient descent extrapolate, i.e.,
what they learn outside the support of the training distribution. Previous
works report mixed empirical results when extrapolating with neural networks:
while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not
extrapolate well in certain simple tasks, Graph Neural Networks (GNNs), a
structured network with MLP modules, have shown some success in more complex
tasks. Working towards a theoretical explanation, we identify conditions under
which MLPs and GNNs extrapolate well. First, we quantify the observation that
ReLU MLPs quickly converge to linear functions along any direction from the
origin, which implies that ReLU MLPs do not extrapolate most nonlinear
functions. But, they can provably learn a linear target function when the
training distribution is sufficiently diverse. Second, in connection to
analyzing the successes and limitations of GNNs, these results suggest a
hypothesis for which we provide theoretical and empirical evidence: the success
of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or
edge weights) relies on encoding task-specific non-linearities in the
architecture or features. Our theoretical analysis builds on a connection of
over-parameterized networks to the neural tangent kernel. Empirically, our
theory holds across different training settings.
</p>
<a href="http://arxiv.org/abs/2009.11848" target="_blank">arXiv:2009.11848</a> [<a href="http://arxiv.org/pdf/2009.11848" target="_blank">pdf</a>]

<h2>Detecting soccer balls with reduced neural networks: a comparison of multiple architectures under constrained hardware scenarios. (arXiv:2009.13684v2 [cs.CV] UPDATED)</h2>
<h3>Douglas De Rizzo Meneghetti, Thiago Pedro Donadon Homem, Jonas Henrique Renolfi de Oliveira, Isaac Jesus da Silva, Danilo Hernani Perico, Reinaldo Augusto da Costa Bianchi</h3>
<p>Object detection techniques that achieve state-of-the-art detection accuracy
employ convolutional neural networks, implemented to have optimal performance
in graphics processing units. Some hardware systems, such as mobile robots,
operate under constrained hardware situations, but still benefit from object
detection capabilities. Multiple network models have been proposed, achieving
comparable accuracy with reduced architectures and leaner operations. Motivated
by the need to create an object detection system for a soccer team of mobile
robots, this work provides a comparative study of recent proposals of neural
networks targeted towards constrained hardware environments, in the specific
task of soccer ball detection. We train multiple open implementations of
MobileNetV2 and MobileNetV3 models with different underlying architectures, as
well as YOLOv3, TinyYOLOv3, YOLOv4 and TinyYOLOv4 in an annotated image data
set captured using a mobile robot. We then report their mean average precision
on a test data set and their inference times in videos of different
resolutions, under constrained and unconstrained hardware configurations.
Results show that MobileNetV3 models have a good trade-off between mAP and
inference time in constrained scenarios only, while MobileNetV2 with high width
multipliers are appropriate for server-side inference. YOLO models in their
official implementations are not suitable for inference in CPUs.
</p>
<a href="http://arxiv.org/abs/2009.13684" target="_blank">arXiv:2009.13684</a> [<a href="http://arxiv.org/pdf/2009.13684" target="_blank">pdf</a>]

<h2>Active Learning for Bayesian 3D Hand Pose Estimation. (arXiv:2010.00694v2 [cs.CV] UPDATED)</h2>
<h3>Razvan Caramalau, Binod Bhattarai, Tae-Kyun Kim</h3>
<p>We propose a Bayesian approximation to a deep learning architecture for 3D
hand pose estimation. Through this framework, we explore and analyse the two
types of uncertainties that are influenced either by data or by the learning
capability. Furthermore, we draw comparisons against the standard estimator
over three popular benchmarks. The first contribution lies in outperforming the
baseline while in the second part we address the active learning application.
We also show that with a newly proposed acquisition function, our Bayesian 3D
hand pose estimator obtains lowest errors with the least amount of data. The
underlying code is publicly available at
https://github.com/razvancaramalau/al_bhpe.
</p>
<a href="http://arxiv.org/abs/2010.00694" target="_blank">arXiv:2010.00694</a> [<a href="http://arxiv.org/pdf/2010.00694" target="_blank">pdf</a>]

<h2>On the linearity of large non-linear models: when and why the tangent kernel is constant. (arXiv:2010.01092v3 [cs.LG] UPDATED)</h2>
<h3>Chaoyue Liu, Libin Zhu, Mikhail Belkin</h3>
<p>The goal of this work is to shed light on the remarkable phenomenon of
transition to linearity of certain neural networks as their width approaches
infinity. We show that the transition to linearity of the model and,
equivalently, constancy of the (neural) tangent kernel (NTK) result from the
scaling properties of the norm of the Hessian matrix of the network as a
function of the network width. We present a general framework for understanding
the constancy of the tangent kernel via Hessian scaling applicable to the
standard classes of neural networks. Our analysis provides a new perspective on
the phenomenon of constant tangent kernel, which is different from the widely
accepted "lazy training". Furthermore, we show that the transition to linearity
is not a general property of wide neural networks and does not hold when the
last layer of the network is non-linear. It is also not necessary for
successful optimization by gradient descent.
</p>
<a href="http://arxiv.org/abs/2010.01092" target="_blank">arXiv:2010.01092</a> [<a href="http://arxiv.org/pdf/2010.01092" target="_blank">pdf</a>]

<h2>Data-Driven Learning of Geometric Scattering Networks. (arXiv:2010.02415v2 [cs.LG] UPDATED)</h2>
<h3>Alexander Tong, Frederik Wenkel, Kincaid MacDonald, Smita Krishnaswamy, Guy Wolf</h3>
<p>We propose a new graph neural network (GNN) module, based on a relaxation of
recently proposed geometric scattering transforms, which consist of a cascade
of graph wavelet filters. Our learnable geometric scattering (LEGS) module
enables adaptive tuning of these wavelets to encourage band-pass features to
emerge in learned representations. The incorporation of our LEGS-module in GNNs
enables the learning of longer-range graph relations compared to many popular
GNN architectures, which often rely on encoding graph structure via smoothness
or similarity between neighbors. Further, its wavelet priors result in
simplified architectures with significantly fewer learned parameters compared
to competing GNNs. We demonstrate the predictive performance of LEGS-based
networks on graph classification benchmarks, as well as the descriptive quality
of their learned features in biochemical graph data exploration tasks. Our
results show that LEGS-based networks match or outperforms popular GNNs, as
well as the original geometric scattering construction, on many datasets, in
particular in biochemical domains, while retaining certain mathematical
properties of handcrafted (nonlearned) geometric scattering.
</p>
<a href="http://arxiv.org/abs/2010.02415" target="_blank">arXiv:2010.02415</a> [<a href="http://arxiv.org/pdf/2010.02415" target="_blank">pdf</a>]

<h2>Set Prediction without Imposing Structure as Conditional Density Estimation. (arXiv:2010.04109v2 [cs.LG] UPDATED)</h2>
<h3>David W. Zhang, Gertjan J. Burghouts, Cees G.M. Snoek</h3>
<p>Set prediction is about learning to predict a collection of unordered
variables with unknown interrelations. Training such models with set losses
imposes the structure of a metric space over sets. We focus on stochastic and
underdefined cases, where an incorrectly chosen loss function leads to
implausible predictions. Example tasks include conditional point-cloud
reconstruction and predicting future states of molecules. In this paper, we
propose an alternative to training via set losses by viewing learning as
conditional density estimation. Our learning framework fits deep energy-based
models and approximates the intractable likelihood with gradient-guided
sampling. Furthermore, we propose a stochastically augmented prediction
algorithm that enables multiple predictions, reflecting the possible variations
in the target set. We empirically demonstrate on a variety of datasets the
capability to learn multi-modal densities and produce different plausible
predictions. Our approach is competitive with previous set prediction models on
standard benchmarks. More importantly, it extends the family of addressable
tasks beyond those that have unambiguous predictions.
</p>
<a href="http://arxiv.org/abs/2010.04109" target="_blank">arXiv:2010.04109</a> [<a href="http://arxiv.org/pdf/2010.04109" target="_blank">pdf</a>]

<h2>How Does Mixup Help With Robustness and Generalization?. (arXiv:2010.04819v3 [cs.LG] UPDATED)</h2>
<h3>Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, James Zou</h3>
<p>Mixup is a popular data augmentation technique based on taking convex
combinations of pairs of examples and their labels. This simple technique has
been shown to substantially improve both the robustness and the generalization
of the trained model. However, it is not well-understood why such improvement
occurs. In this paper, we provide theoretical analysis to demonstrate how using
Mixup in training helps model robustness and generalization. For robustness, we
show that minimizing the Mixup loss corresponds to approximately minimizing an
upper bound of the adversarial loss. This explains why models obtained by Mixup
training exhibits robustness to several kinds of adversarial attacks such as
Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup
augmentation corresponds to a specific type of data-adaptive regularization
which reduces overfitting. Our analysis provides new insights and a framework
to understand Mixup.
</p>
<a href="http://arxiv.org/abs/2010.04819" target="_blank">arXiv:2010.04819</a> [<a href="http://arxiv.org/pdf/2010.04819" target="_blank">pdf</a>]

<h2>MoCo-CXR: MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models. (arXiv:2010.05352v2 [cs.CV] UPDATED)</h2>
<h3>Hari Sowrirajan, Jingbo Yang, Andrew Y. Ng, Pranav Rajpurkar</h3>
<p>Contrastive learning is a form of self-supervision that can leverage
unlabeled data to produce pretrained models. While contrastive learning has
demonstrated promising results on natural image classification tasks, its
application to medical imaging tasks like chest X-ray interpretation has been
limited. In this work, we propose MoCo-CXR, which is an adaptation of the
contrastive learning method Momentum Contrast (MoCo), to produce models with
better representations and initializations for the detection of pathologies in
chest X-rays. In detecting pleural effusion, we find that linear models trained
on MoCo-CXR-pretrained representations outperform those without
MoCo-CXR-pretrained representations, indicating that MoCo-CXR-pretrained
representations are of higher-quality. End-to-end fine-tuning experiments
reveal that a model initialized via MoCo-CXR-pretraining outperforms its
non-MoCo-CXR-pretrained counterpart. We find that MoCo-CXR-pretraining provides
the most benefit with limited labeled training data. Finally, we demonstrate
similar results on a target Tuberculosis dataset unseen during pretraining,
indicating that MoCo-CXR-pretraining endows models with representations and
transferability that can be applied across chest X-ray datasets and tasks.
</p>
<a href="http://arxiv.org/abs/2010.05352" target="_blank">arXiv:2010.05352</a> [<a href="http://arxiv.org/pdf/2010.05352" target="_blank">pdf</a>]

<h2>On the Fairness of Causal Algorithmic Recourse. (arXiv:2010.06529v3 [cs.LG] UPDATED)</h2>
<h3>Julius von K&#xfc;gelgen, Amir-Hossein Karimi, Umang Bhatt, Isabel Valera, Adrian Weller, Bernhard Sch&#xf6;lkopf</h3>
<p>Many recent works have studied the problem of algorithmic fairness from the
perspective of predictions. Instead, here we investigate the fairness of
recourse actions recommended to individuals to recover from an unfavourable
classification. We propose two new fairness criteria at the group and
individual level which -- unlike prior work on equalising the average distance
from the decision boundary across protected groups -- explicitly account for
the causal relationships between input features, thereby allowing us to capture
downstream effects of recourse actions performed in the physical world. We
explore how our criteria relate to others, such as counterfactual fairness, and
show that fairness of recourse (both causal and non-causal) is complementary to
fairness of prediction. We then investigate how to enforce fair causal recourse
in the training of a classifier. Finally, we discuss whether fairness
violations in the data generating process revealed by our criteria may be
better addressed by societal interventions as opposed to constraints on the
classifier.
</p>
<a href="http://arxiv.org/abs/2010.06529" target="_blank">arXiv:2010.06529</a> [<a href="http://arxiv.org/pdf/2010.06529" target="_blank">pdf</a>]

<h2>Variable Horizon MPC with Swing Foot Dynamics for Bipedal Walking Control. (arXiv:2010.08198v2 [cs.RO] UPDATED)</h2>
<h3>Elham Daneshmand, Majid Khadiv, Felix Grimminger, Ludovic Righetti</h3>
<p>In this paper, we present a novel two-level variable Horizon Model Predictive
Control (VH-MPC) framework for bipedal locomotion. In this framework, the
higher level computes the landing location and timing (horizon length) of the
swing foot to stabilize the unstable part of the center of mass (CoM) dynamics,
using feedback from the CoM states. The lower level takes into account the
swing foot dynamics and generates dynamically consistent trajectories for
landing at the desired time as close as possible to the desired location. To do
that, we use a simplified model of the robot dynamics projected in swing foot
space that takes into account joint torque constraints as well as the friction
cone constraints of the stance foot. We show the effectiveness of our proposed
control framework by implementing robust walking patterns on our
torque-controlled and open-source biped robot, Bolt. We report extensive
simulations and real robot experiments in the presence of various disturbances
and uncertainties.
</p>
<a href="http://arxiv.org/abs/2010.08198" target="_blank">arXiv:2010.08198</a> [<a href="http://arxiv.org/pdf/2010.08198" target="_blank">pdf</a>]

<h2>Model updating after interventions paradoxically introduces bias. (arXiv:2010.11530v2 [stat.ML] UPDATED)</h2>
<h3>James Liley, Samuel R Emerson, Bilal A Mateen, Catalina A Vallejos, Louis J M Aslett, Sebastian J Vollmer</h3>
<p>Machine learning is increasingly being used to generate prediction models for
use in a number of real-world settings, from credit risk assessment to clinical
decision support. Recent discussions have highlighted potential problems in the
updating of a predictive score for a binary outcome when an existing predictive
score forms part of the standard workflow, driving interventions. In this
setting, the existing score induces an additional causative pathway which leads
to miscalibration when the original score is replaced. We propose a general
causal framework to describe and address this problem, and demonstrate an
equivalent formulation as a partially observed Markov decision process. We use
this model to demonstrate the impact of such `naive updating' when performed
repeatedly. Namely, we show that successive predictive scores may converge to a
point where they predict their own effect, or may eventually tend toward a
stable oscillation between two values, and we argue that neither outcome is
desirable. Furthermore, we demonstrate that even if model-fitting procedures
improve, actual performance may worsen. We complement these findings with a
discussion of several potential routes to overcome these issues.
</p>
<a href="http://arxiv.org/abs/2010.11530" target="_blank">arXiv:2010.11530</a> [<a href="http://arxiv.org/pdf/2010.11530" target="_blank">pdf</a>]

<h2>Metapath- and Entity-aware Graph Neural Network for Recommendation. (arXiv:2010.11793v2 [cs.LG] UPDATED)</h2>
<h3>Muhammad Umer Anwaar, Zhiwei Han, Shyam Arumugaswamy, Rayyan Ahmad Khan, Thomas Weber, Tianming Qiu, Hao Shen, Yuanting Liu, Martin Kleinsteuber</h3>
<p>Due to the shallow structure, classic graph neural networks (GNNs) fail in
modelling high-order graph structures. Such high-order structures capture
critical insights for downstream tasks. Concretely, in recommender systems,
disregarding these insights lead to inadequate distillation of collaborative
signals. In this paper, we employ collaborative subgraphs (CSGs) and metapaths
to explicitly capture these high-order graph structures. We propose
meta\textbf{P}ath and \textbf{E}ntity-\textbf{A}ware \textbf{G}raph
\textbf{N}eural \textbf{N}etwork (PEAGNN). We extract an enclosing CSG for
user-item pair within its $h$-hop neighbours. Multiple metapath-aware subgraphs
are then extracted from CSG. PEAGNN trains multilayer GNNs to perform
information aggregation on such subgraphs. This aggregated information from
different metapaths is fused using attention mechanism. Finally, PEAGNN gives
us the representations for node and subgraph, which can be used to train MLP
for predicting score for target user-item pairs. To leverage the local
structure of CSGs, we present entity-awareness that acts as a contrastive
regularizer of node embedding. Moreover, PEAGNN can be combined with prominent
layers such as GAT, GCN and GraphSage. Our empirical evaluation shows that our
proposed technique outperforms competitive baselines on several datasets for
recommendation task. Our analysis demonstrates that PEAGNN also learns
meaningful metapath combinations from a given set of metapaths.
</p>
<a href="http://arxiv.org/abs/2010.11793" target="_blank">arXiv:2010.11793</a> [<a href="http://arxiv.org/pdf/2010.11793" target="_blank">pdf</a>]

<h2>Transferable Graph Optimizers for ML Compilers. (arXiv:2010.12438v2 [cs.LG] UPDATED)</h2>
<h3>Yanqi Zhou, Sudip Roy, Amirali Abdolrashidi, Daniel Wong, Peter Ma, Qiumin Xu, Hanxiao Liu, Phitchaya Mangpo Phothilimthana, Shen Wang, Anna Goldie, Azalia Mirhoseini, James Laudon</h3>
<p>Most compilers for machine learning (ML) frameworks need to solve many
correlated optimization problems to generate efficient machine code. Current ML
compilers rely on heuristics based algorithms to solve these optimization
problems one at a time. However, this approach is not only hard to maintain but
often leads to sub-optimal solutions especially for newer model architectures.
Existing learning based approaches in the literature are sample inefficient,
tackle a single optimization problem, and do not generalize to unseen graphs
making them infeasible to be deployed in practice. To address these
limitations, we propose an end-to-end, transferable deep reinforcement learning
method for computational graph optimization (GO), based on a scalable
sequential attention mechanism over an inductive graph neural network. GO
generates decisions on the entire graph rather than on each individual node
autoregressively, drastically speeding up the search compared to prior methods.
Moreover, we propose recurrent attention layers to jointly optimize dependent
graph optimization tasks and demonstrate 33%-60% speedup on three graph
optimization tasks compared to TensorFlow default optimization. On a diverse
set of representative graphs consisting of up to 80,000 nodes, including
Inception-v3, Transformer-XL, and WaveNet, GO achieves on average 21%
improvement over human experts and 18% improvement over the prior state of the
art with 15x faster convergence, on a device placement task evaluated in real
systems.
</p>
<a href="http://arxiv.org/abs/2010.12438" target="_blank">arXiv:2010.12438</a> [<a href="http://arxiv.org/pdf/2010.12438" target="_blank">pdf</a>]

<h2>Asymptotic Behavior of Adversarial Training in Binary Classification. (arXiv:2010.13275v2 [stat.ML] UPDATED)</h2>
<h3>Hossein Taheri, Ramtin Pedarsani, Christos Thrampoulidis</h3>
<p>It has been consistently reported that many machine learning models are
susceptible to adversarial attacks i.e., small additive adversarial
perturbations applied to data points can cause misclassification. Adversarial
training using empirical risk minimization is considered to be the
state-of-the-art method for defense against adversarial attacks. Despite being
successful in practice, several problems in understanding generalization
performance of adversarial training remain open. In this paper, we derive
precise theoretical predictions for the performance of adversarial training in
binary classification. We consider the high-dimensional regime where the
dimension of data grows with the size of the training data-set at a constant
ratio. Our results provide exact asymptotics for standard and adversarial
errors of the estimators obtained by adversarial training with $\ell_q$-norm
bounded perturbations ($q \ge 1$) for both discriminative binary models and
generative Gaussian mixture models. Furthermore, we use these sharp predictions
to uncover several intriguing observations on the role of various parameters
including the over-parameterization ratio, the data model, and the attack
budget on the adversarial and standard errors.
</p>
<a href="http://arxiv.org/abs/2010.13275" target="_blank">arXiv:2010.13275</a> [<a href="http://arxiv.org/pdf/2010.13275" target="_blank">pdf</a>]

<h2>Mat\'ern Gaussian Processes on Graphs. (arXiv:2010.15538v2 [stat.ML] UPDATED)</h2>
<h3>Viacheslav Borovitskiy, Iskander Azangulov, Alexander Terenin, Peter Mostowsky, Marc Peter Deisenroth, Nicolas Durrande</h3>
<p>Gaussian processes are a versatile framework for learning unknown functions
in a manner that permits one to utilize prior information about their
properties. Although many different Gaussian process models are readily
available when the input space is Euclidean, the choice is much more limited
for Gaussian processes whose input space is an undirected graph. In this work,
we leverage the stochastic partial differential equation characterization of
Mat\'ern Gaussian processes - a widely-used model class in the Euclidean
setting - to study their analog for undirected graphs. We show that the
resulting Gaussian processes inherit various attractive properties of their
Euclidean and Riemannian analogs and provide techniques that allow them to be
trained using standard methods, such as inducing points. This enables graph
Mat\'ern Gaussian processes to be employed in mini-batch and non-conjugate
settings, thereby making them more accessible to practitioners and easier to
deploy within larger learning frameworks.
</p>
<a href="http://arxiv.org/abs/2010.15538" target="_blank">arXiv:2010.15538</a> [<a href="http://arxiv.org/pdf/2010.15538" target="_blank">pdf</a>]

<h2>Amortized Probabilistic Detection of Communities in Graphs. (arXiv:2010.15727v2 [stat.ML] UPDATED)</h2>
<h3>Ari Pakman, Yueqi Wang, Yoonho Lee, Pallab Basu, Juho Lee, Yee Whye Teh, Liam Paninski</h3>
<p>Graph neural networks (GNNs) have reshaped the landscape of models and
algorithms for analyzing data on graphs. Yet despite the many architectures
proposed to encode graph information and perform different tasks, a proper
probabilistic formulation of neural models for community discovery is still
lacking. In this work we fill this gap by combining GNNs with recent
architectures for amortized probabilistic clustering, which we extend with
attention layers. The resulting model is trained with labeled network data
containing varying numbers of communities K. At test time, the model yields
samples from the posterior distribution of community labels for networks of any
size using only O(K) forward evaluations. Apart from quantifying uncertainty in
a principled way, this approach accommodates Bayesian nonparametric priors,
thus bypassing the common requirement to hard code the (maximum) number of
communities in the neural architecture. We illustrate the method on several
synthetic and real datasets, showing superior performance both to previous
approaches to supervised neural community detection and to similar
architectures built using other amortized clustering models.
</p>
<a href="http://arxiv.org/abs/2010.15727" target="_blank">arXiv:2010.15727</a> [<a href="http://arxiv.org/pdf/2010.15727" target="_blank">pdf</a>]

<h2>Do 2D GANs Know 3D Shape? Unsupervised 3D shape reconstruction from 2D Image GANs. (arXiv:2011.00844v2 [cs.CV] UPDATED)</h2>
<h3>Xingang Pan, Bo Dai, Ziwei Liu, Chen Change Loy, Ping Luo</h3>
<p>Natural images are projections of 3D objects on a 2D image plane. While
state-of-the-art 2D generative models like GANs show unprecedented quality in
modeling the natural image manifold, it is unclear whether they implicitly
capture the underlying 3D object structures. And if so, how could we exploit
such knowledge to recover the 3D shapes of objects in the images? To answer
these questions, in this work, we present the first attempt to directly mine 3D
geometric clues from an off-the-shelf 2D GAN that is trained on RGB images
only. Through our investigation, we found that such a pre-trained GAN indeed
contains rich 3D knowledge and thus can be used to recover 3D shape from a
single 2D image in an unsupervised manner. The core of our framework is an
iterative strategy that explores and exploits diverse viewpoint and lighting
variations in the GAN image manifold. The framework does not require 2D
keypoint or 3D annotations, or strong assumptions on object shapes (e.g. shapes
are symmetric), yet it successfully recovers 3D shapes with high precision for
human faces, cats, cars, and buildings. The recovered 3D shapes immediately
allow high-quality image editing like relighting and object rotation. We
quantitatively demonstrate the effectiveness of our approach compared to
previous methods in both 3D shape reconstruction and face rotation. Our code is
available at https://github.com/XingangPan/GAN2Shape.
</p>
<a href="http://arxiv.org/abs/2011.00844" target="_blank">arXiv:2011.00844</a> [<a href="http://arxiv.org/pdf/2011.00844" target="_blank">pdf</a>]

<h2>Point Transformer for Shape Classification and Retrieval of 3D and ALS Roof PointClouds. (arXiv:2011.03921v2 [cs.CV] UPDATED)</h2>
<h3>Dimple A Shajahan, Mukund Varma T, Ramanathan Muthuganapathy</h3>
<p>The success of deep learning methods led to significant breakthroughs in 3-D
point cloud processing tasks with applications in remote sensing. Existing
methods utilize convolutions that have some limitations, as they assume a
uniform input distribution and cannot learn long-range dependencies. Recent
works have shown that adding attention in conjunction with these methods
improves performance. This raises a question: can attention layers completely
replace convolutions? This paper proposes a fully attentional model - {\em
Point Transformer}, for deriving a rich point cloud representation. The model's
shape classification and retrieval performance are evaluated on a large-scale
urban dataset - RoofN3D and a standard benchmark dataset ModelNet40. Extensive
experiments are conducted to test the model's robustness to unseen point
corruptions for analyzing its effectiveness on real datasets. The proposed
method outperforms other state-of-the-art models in the RoofN3D dataset, gives
competitive results in the ModelNet40 benchmark, and showcases high robustness
to various unseen point corruptions. Furthermore, the model is highly memory
and space efficient when compared to other methods.
</p>
<a href="http://arxiv.org/abs/2011.03921" target="_blank">arXiv:2011.03921</a> [<a href="http://arxiv.org/pdf/2011.03921" target="_blank">pdf</a>]

<h2>BayGo: Joint Bayesian Learning and Information-Aware Graph Optimization. (arXiv:2011.04345v2 [cs.LG] UPDATED)</h2>
<h3>Tamara Alshammari, Sumudu Samarakoon, Anis Elgabli, Mehdi Bennis</h3>
<p>This article deals with the problem of distributed machine learning, in which
agents update their models based on their local datasets, and aggregate the
updated models collaboratively and in a fully decentralized manner. In this
paper, we tackle the problem of information heterogeneity arising in
multi-agent networks where the placement of informative agents plays a crucial
role in the learning dynamics. Specifically, we propose BayGo, a novel fully
decentralized joint Bayesian learning and graph optimization framework with
proven fast convergence over a sparse graph. Under our framework, agents are
able to learn and communicate with the most informative agent to their own
learning. Unlike prior works, our framework assumes no prior knowledge of the
data distribution across agents nor does it assume any knowledge of the true
parameter of the system. The proposed alternating minimization based framework
ensures global connectivity in a fully decentralized way while minimizing the
number of communication links. We theoretically show that by optimizing the
proposed objective function, the estimation error of the posterior probability
distribution decreases exponentially at each iteration. Via extensive
simulations, we show that our framework achieves faster convergence and higher
accuracy compared to fully-connected and star topology graphs.
</p>
<a href="http://arxiv.org/abs/2011.04345" target="_blank">arXiv:2011.04345</a> [<a href="http://arxiv.org/pdf/2011.04345" target="_blank">pdf</a>]

<h2>A Survey of Label-noise Representation Learning: Past, Present and Future. (arXiv:2011.04406v2 [cs.LG] UPDATED)</h2>
<h3>Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, Ivor W. Tsang, James T. Kwok, Masashi Sugiyama</h3>
<p>Classical machine learning implicitly assumes that labels of the training
data are sampled from a clean distribution, which can be too restrictive for
real-world scenarios. However, statistical-learning-based methods may not train
deep learning models robustly with these noisy labels. Therefore, it is urgent
to design Label-Noise Representation Learning (LNRL) methods for robustly
training deep models with noisy labels. To fully understand LNRL, we conduct a
survey study. We first clarify a formal definition for LNRL from the
perspective of machine learning. Then, via the lens of learning theory and
empirical study, we figure out why noisy labels affect deep models'
performance. Based on the theoretical guidance, we categorize different LNRL
methods into three directions. Under this unified taxonomy, we provide a
thorough discussion of the pros and cons of different categories. More
importantly, we summarize the essential components of robust LNRL, which can
spark new directions. Lastly, we propose possible research directions within
LNRL, such as new datasets, instance-dependent LNRL, and adversarial LNRL. We
also envision potential directions beyond LNRL, such as learning with
feature-noise, preference-noise, domain-noise, similarity-noise, graph-noise
and demonstration-noise.
</p>
<a href="http://arxiv.org/abs/2011.04406" target="_blank">arXiv:2011.04406</a> [<a href="http://arxiv.org/pdf/2011.04406" target="_blank">pdf</a>]

<h2>Feedback-Based Dynamic Feature Selection for Constrained Continuous Data Acquisition. (arXiv:2011.05112v2 [cs.LG] UPDATED)</h2>
<h3>Alp Sahin, Xiangrui Zeng</h3>
<p>Relevant and high-quality data are critical to successful development of
machine learning applications. For machine learning applications on dynamic
systems equipped with a large number of sensors, such as connected vehicles and
robots, how to find relevant and high-quality data features in an efficient way
is a challenging problem. In this work, we address the problem of feature
selection in constrained continuous data acquisition. We propose a
feedback-based dynamic feature selection algorithm that efficiently decides on
the feature set for data collection from a dynamic system in a step-wise
manner. We formulate the sequential feature selection procedure as a Markov
Decision Process. The machine learning model performance feedback with an
exploration component is used as the reward function in an $\epsilon$-greedy
action selection. Our evaluation shows that the proposed feedback-based feature
selection algorithm has superior performance over constrained baseline methods
and matching performance with unconstrained baseline methods.
</p>
<a href="http://arxiv.org/abs/2011.05112" target="_blank">arXiv:2011.05112</a> [<a href="http://arxiv.org/pdf/2011.05112" target="_blank">pdf</a>]

<h2>Query-based Targeted Action-Space Adversarial Policies on Deep Reinforcement Learning Agents. (arXiv:2011.07114v2 [cs.LG] UPDATED)</h2>
<h3>Xian Yeow Lee, Yasaman Esfandiari, Kai Liang Tan, Soumik Sarkar</h3>
<p>Advances in computing resources have resulted in the increasing complexity of
cyber-physical systems (CPS). As the complexity of CPS evolved, the focus has
shifted from traditional control methods to deep reinforcement learning-based
(DRL) methods for control of these systems. This is due to the difficulty of
obtaining accurate models of complex CPS for traditional control. However, to
securely deploy DRL in production, it is essential to examine the weaknesses of
DRL-based controllers (policies) towards malicious attacks from all angles. In
this work, we investigate targeted attacks in the action-space domain, also
commonly known as actuation attacks in CPS literature, which perturbs the
outputs of a controller. We show that a query-based black-box attack model that
generates optimal perturbations with respect to an adversarial goal can be
formulated as another reinforcement learning problem. Thus, such an adversarial
policy can be trained using conventional DRL methods. Experimental results
showed that adversarial policies that only observe the nominal policy's output
generate stronger attacks than adversarial policies that observe the nominal
policy's input and output. Further analysis reveals that nominal policies whose
outputs are frequently at the boundaries of the action space are naturally more
robust towards adversarial policies. Lastly, we propose the use of adversarial
training with transfer learning to induce robust behaviors into the nominal
policy, which decreases the rate of successful targeted attacks by 50%.
</p>
<a href="http://arxiv.org/abs/2011.07114" target="_blank">arXiv:2011.07114</a> [<a href="http://arxiv.org/pdf/2011.07114" target="_blank">pdf</a>]

<h2>Scaled-YOLOv4: Scaling Cross Stage Partial Network. (arXiv:2011.08036v2 [cs.CV] UPDATED)</h2>
<h3>Chien-Yao Wang, Alexey Bochkovskiy, Hong-Yuan Mark Liao</h3>
<p>We show that the YOLOv4 object detection neural network based on the CSP
approach, scales both up and down and is applicable to small and large networks
while maintaining optimal speed and accuracy. We propose a network scaling
approach that modifies not only the depth, width, resolution, but also
structure of the network. YOLOv4-large model achieves state-of-the-art results:
55.5% AP (73.4% AP50) for the MS COCO dataset at a speed of ~16 FPS on Tesla
V100, while with the test time augmentation, YOLOv4-large achieves 56.0% AP
(73.3 AP50). To the best of our knowledge, this is currently the highest
accuracy on the COCO dataset among any published work. The YOLOv4-tiny model
achieves 22.0% AP (42.0% AP50) at a speed of 443 FPS on RTX 2080Ti, while by
using TensorRT, batch size = 4 and FP16-precision the YOLOv4-tiny achieves 1774
FPS.
</p>
<a href="http://arxiv.org/abs/2011.08036" target="_blank">arXiv:2011.08036</a> [<a href="http://arxiv.org/pdf/2011.08036" target="_blank">pdf</a>]

<h2>Larq Compute Engine: Design, Benchmark, and Deploy State-of-the-Art Binarized Neural Networks. (arXiv:2011.09398v2 [cs.LG] UPDATED)</h2>
<h3>Tom Bannink, Arash Bakhtiari, Adam Hillier, Lukas Geiger, Tim de Bruin, Leon Overweel, Jelmer Neeven, Koen Helwegen</h3>
<p>We introduce Larq Compute Engine, the world's fastest Binarized Neural
Network (BNN) inference engine, and use this framework to investigate several
important questions about the efficiency of BNNs and to design a new
state-of-the-art BNN architecture. LCE provides highly optimized
implementations of binary operations and accelerates binary convolutions by 8.5
- 18.5x compared to their full-precision counterparts on Pixel 1 phones. LCE's
integration with Larq and a sophisticated MLIR-based converter allow users to
move smoothly from training to deployment. By extending TensorFlow and
TensorFlow Lite, LCE supports models which combine binary and full-precision
layers, and can be easily integrated into existing applications. Using LCE, we
analyze the performance of existing BNN computer vision architectures and
develop QuickNet, a simple, easy-to-reproduce BNN that outperforms existing
binary networks in terms of latency and accuracy on ImageNet. Furthermore, we
investigate the impact of full-precision shortcuts and the relationship between
number of MACs and model latency. We are convinced that empirical performance
should drive BNN architecture design and hope this work will facilitate others
to design, benchmark and deploy binary models.
</p>
<a href="http://arxiv.org/abs/2011.09398" target="_blank">arXiv:2011.09398</a> [<a href="http://arxiv.org/pdf/2011.09398" target="_blank">pdf</a>]

<h2>The Fundamental Principles of Reproducibility. (arXiv:2011.10098v2 [cs.LG] UPDATED)</h2>
<h3>Odd Erik Gundersen</h3>
<p>Reproducibility is a confused terminology. In this paper, I take a
fundamental view on reproducibility rooted in the scientific method. The
scientific method is analysed and characterised in order to develop the
terminology required to define reproducibility. Further, the literature on
reproducibility and replication is surveyed, and experiments are modeled as
tasks and problem solving methods. Machine learning is used to exemplify the
described approach. Based on the analysis, reproducibility is defined and three
different types of reproducibility as well as four degrees of reproducibility
are specified.
</p>
<a href="http://arxiv.org/abs/2011.10098" target="_blank">arXiv:2011.10098</a> [<a href="http://arxiv.org/pdf/2011.10098" target="_blank">pdf</a>]

<h2>Image-based Plant Disease Diagnosis with Unsupervised Anomaly Detection Based on Reconstructability of Colors. (arXiv:2011.14306v4 [cs.CV] UPDATED)</h2>
<h3>Ryoya Katafuchi, Terumasa Tokunaga</h3>
<p>This paper proposes an unsupervised anomaly detection technique for
image-based plant disease diagnosis. The construction of large and publicly
available datasets containing labeled images of healthy and diseased crop
plants led to growing interest in computer vision techniques for automatic
plant disease diagnosis. Although supervised image classifiers based on deep
learning can be a powerful tool for plant disease diagnosis, they require a
huge amount of labeled data. The data mining technique of anomaly detection
includes unsupervised approaches that do not require rare samples for training
classifiers. We propose an unsupervised anomaly detection technique for
image-based plant disease diagnosis that is based on the reconstructability of
colors; a deep encoder-decoder network trained to reconstruct the colors of
\textit{healthy} plant images should fail to reconstruct colors of symptomatic
regions. Our proposed method includes a new image-based framework for plant
disease detection that utilizes a conditional adversarial network called
pix2pix and a new anomaly score based on CIEDE2000 color difference.
Experiments with PlantVillage dataset demonstrated the superiority of our
proposed method compared to an existing anomaly detector at identifying
diseased crop images in terms of accuracy, interpretability and computational
efficiency.
</p>
<a href="http://arxiv.org/abs/2011.14306" target="_blank">arXiv:2011.14306</a> [<a href="http://arxiv.org/pdf/2011.14306" target="_blank">pdf</a>]

<h2>Two-Stage Single Image Reflection Removal with Reflection-Aware Guidance. (arXiv:2012.00945v2 [cs.CV] UPDATED)</h2>
<h3>Yu Li, Ming Liu, Yaling Yi, Qince Li, Dongwei Ren, Wangmeng Zuo</h3>
<p>Removing undesired reflection from an image captured through a glass surface
is a very challenging problem with many practical application scenarios. For
improving reflection removal, cascaded deep models have been usually adopted to
estimate the transmission in a progressive manner. However, most existing
methods are still limited in exploiting the result in prior stage for guiding
transmission estimation. In this paper, we present a novel two-stage network
with reflection-aware guidance (RAGNet) for single image reflection removal
(SIRR). To be specific, the reflection layer is firstly estimated due to that
it generally is much simpler and is relatively easier to estimate.
Reflectionaware guidance (RAG) module is then elaborated for better exploiting
the estimated reflection in predicting transmission layer. By incorporating
feature maps from the estimated reflection and observation, RAG can be used (i)
to mitigate the effect of reflection from the observation, and (ii) to generate
mask in partial convolution for mitigating the effect of deviating from linear
combination hypothesis. A dedicated mask loss is further presented for
reconciling the contributions of encoder and decoder features. Experiments on
five commonly used datasets demonstrate the quantitative and qualitative
superiority of our RAGNet in comparison to the state-of-the-art SIRR methods.
The source code and pre-trained model are available at
https://github.com/liyucs/RAGNet.
</p>
<a href="http://arxiv.org/abs/2012.00945" target="_blank">arXiv:2012.00945</a> [<a href="http://arxiv.org/pdf/2012.00945" target="_blank">pdf</a>]

<h2>Faster Non-Convex Federated Learning via Global and Local Momentum. (arXiv:2012.04061v3 [stat.ML] UPDATED)</h2>
<h3>Rudrajit Das, Anish Acharya, Abolfazl Hashemi, Sujay Sanghavi, Inderjit S. Dhillon, Ufuk Topcu</h3>
<p>In this paper, we propose \texttt{FedGLOMO}, the first (first-order) FL
algorithm that achieves the optimal iteration complexity (i.e matching the
known lower bound) on smooth non-convex objectives -- without using clients'
full gradient in each round. Our key algorithmic idea that enables attaining
this optimal complexity is applying judicious momentum terms that promote
variance reduction in both the local updates at the clients, and the global
update at the server. Our algorithm is also provably optimal even with
compressed communication between the clients and the server, which is an
important consideration in the practical deployment of FL algorithms. Our
experiments illustrate the intrinsic variance reduction effect of
\texttt{FedGLOMO} which implicitly suppresses client-drift in heterogeneous
data distribution settings and promotes communication-efficiency. As a prequel
to \texttt{FedGLOMO}, we propose \texttt{FedLOMO} which applies momentum only
in the local client updates. We establish that \texttt{FedLOMO} enjoys improved
convergence rates under common non-convex settings compared to prior work, and
with fewer assumptions.
</p>
<a href="http://arxiv.org/abs/2012.04061" target="_blank">arXiv:2012.04061</a> [<a href="http://arxiv.org/pdf/2012.04061" target="_blank">pdf</a>]

<h2>Bayesian Image Reconstruction using Deep Generative Models. (arXiv:2012.04567v3 [cs.CV] UPDATED)</h2>
<h3>Razvan V Marinescu, Daniel Moyer, Polina Golland</h3>
<p>Machine learning models are commonly trained end-to-end and in a supervised
setting, using paired (input, output) data. Classical examples include recent
super-resolution methods that train on pairs of (low-resolution,
high-resolution) images. However, these end-to-end approaches require
re-training every time there is a distribution shift in the inputs (e.g., night
images vs daylight) or relevant latent variables (e.g., camera blur or hand
motion). In this work, we leverage state-of-the-art (SOTA) generative models
(here StyleGAN2) for building powerful image priors, which enable application
of Bayes' theorem for many downstream reconstruction tasks. Our method, called
Bayesian Reconstruction through Generative Models (BRGM), uses a single
pre-trained generator model to solve different image restoration tasks, i.e.,
super-resolution and in-painting, by combining it with different forward
corruption models. We demonstrate BRGM on three large, yet diverse, datasets
that enable us to build powerful priors: (i) 60,000 images from the Flick Faces
High Quality dataset (ii) 240,000 chest X-rays from MIMIC III and (iii) a
combined collection of 5 brain MRI datasets with 7,329 scans. Across all three
datasets and without any dataset-specific hyperparameter tuning, our approach
yields state-of-the-art performance on super-resolution, particularly at
low-resolution levels, as well as inpainting, compared to state-of-the-art
methods that are specific to each reconstruction task. Our source code and all
pre-trained models are available online:
https://razvanmarinescu.github.io/brgm/.
</p>
<a href="http://arxiv.org/abs/2012.04567" target="_blank">arXiv:2012.04567</a> [<a href="http://arxiv.org/pdf/2012.04567" target="_blank">pdf</a>]

<h2>Semi-Supervised Off Policy Reinforcement Learning. (arXiv:2012.04809v4 [cs.LG] UPDATED)</h2>
<h3>Aaron Sonabend-W, Nilanjana Laha, Ashwin N. Ananthakrishnan, Tianxi Cai, Rajarshi Mukherjee</h3>
<p>Reinforcement learning (RL) has shown great success in estimating sequential
treatment strategies which take into account patient heterogeneity. However,
health-outcome information, which is used as the reward for reinforcement
learning methods, is often not well coded but rather embedded in clinical
notes. Extracting precise outcome information is a resource intensive task, so
most of the available well-annotated cohorts are small. To address this issue,
we propose a semi-supervised learning (SSL) approach that efficiently leverages
a small sized labeled data with true outcome observed, and a large unlabeled
data with outcome surrogates. In particular, we propose a semi-supervised,
efficient approach to Q-learning and doubly robust off policy value estimation.
Generalizing SSL to sequential treatment regimes brings interesting challenges:
1) Feature distribution for Q-learning is unknown as it includes previous
outcomes. 2) The surrogate variables we leverage in the modified SSL framework
are predictive of the outcome but not informative to the optimal policy or
value function. We provide theoretical results for our Q-function and value
function estimators to understand to what degree efficiency can be gained from
SSL. Our method is at least as efficient as the supervised approach, and
moreover safe as it robust to mis-specification of the imputation models.
</p>
<a href="http://arxiv.org/abs/2012.04809" target="_blank">arXiv:2012.04809</a> [<a href="http://arxiv.org/pdf/2012.04809" target="_blank">pdf</a>]

<h2>Writer Identification and Writer Retrieval Based on NetVLAD with Re-ranking. (arXiv:2012.06186v3 [cs.CV] UPDATED)</h2>
<h3>Shervin Rasoulzadeh, Bagher Babaali</h3>
<p>This paper addresses writer identification and writer retrieval which is
considered as a challenging problem in the document analysis and recognition
field. In this work, a novel pipeline is proposed for the problem at hand by
employing a unified neural network architecture consisting of the ResNet-20 as
a feature extractor and an integrated NetVLAD layer, inspired by the vector of
locally aggregated descriptors (VLAD), in the head of the latter part. Having
defined this architecture, the triplet semi-hard loss function is used to
directly learn an embedding for individual input image patches. Subsequently,
generalized max-pooling technique is employed for the aggregation of embedded
descriptors of each handwritten image. Also, a novel re-ranking strategy is
introduced for the task of identification and retrieval based on $k$-reciprocal
nearest neighbors, and it is shown that the pipeline can benefit tremendously
from this step. Experimental evaluation has been done on the three publicly
available datasets: the ICDAR 2013, CVL, and KHATT datasets. Results indicate
that while we perform comparably to the state-of-the-art on the KHATT, our
writer identification and writer retrieval pipeline achieves superior
performance on the ICDAR 2013 and CVL datasets in terms of mAP.
</p>
<a href="http://arxiv.org/abs/2012.06186" target="_blank">arXiv:2012.06186</a> [<a href="http://arxiv.org/pdf/2012.06186" target="_blank">pdf</a>]

<h2>Leveraging Meta-path Contexts for Classification in Heterogeneous Information Networks. (arXiv:2012.10024v2 [cs.LG] UPDATED)</h2>
<h3>Xiang Li, Danhao Ding, Ben Kao, Yizhou Sun, Nikos Mamoulis</h3>
<p>A heterogeneous information network (HIN) has as vertices objects of
different types and as edges the relations between objects, which are also of
various types. We study the problem of classifying objects in HINs. Most
existing methods perform poorly when given scarce labeled objects as training
sets, and methods that improve classification accuracy under such scenarios are
often computationally expensive. To address these problems, we propose ConCH, a
graph neural network model. ConCH formulates the classification problem as a
multi-task learning problem that combines semi-supervised learning with
self-supervised learning to learn from both labeled and unlabeled data. ConCH
employs meta-paths, which are sequences of object types that capture semantic
relationships between objects. ConCH co-derives object embeddings and context
embeddings via graph convolution. It also uses the attention mechanism to fuse
such embeddings. We conduct extensive experiments to evaluate the performance
of ConCH against other 15 classification methods. Our results show that ConCH
is an effective and efficient method for HIN classification.
</p>
<a href="http://arxiv.org/abs/2012.10024" target="_blank">arXiv:2012.10024</a> [<a href="http://arxiv.org/pdf/2012.10024" target="_blank">pdf</a>]

<h2>Deep Learning and the Global Workspace Theory. (arXiv:2012.10390v2 [cs.AI] UPDATED)</h2>
<h3>Rufin VanRullen, Ryota Kanai</h3>
<p>Recent advances in deep learning have allowed Artificial Intelligence (AI) to
reach near human-level performance in many sensory, perceptual, linguistic or
cognitive tasks. There is a growing need, however, for novel, brain-inspired
cognitive architectures. The Global Workspace theory refers to a large-scale
system integrating and distributing information among networks of specialized
modules to create higher-level forms of cognition and awareness. We argue that
the time is ripe to consider explicit implementations of this theory using deep
learning techniques. We propose a roadmap based on unsupervised neural
translation between multiple latent spaces (neural networks trained for
distinct tasks, on distinct sensory inputs and/or modalities) to create a
unique, amodal global latent workspace (GLW). Potential functional advantages
of GLW are reviewed, along with neuroscientific implications.
</p>
<a href="http://arxiv.org/abs/2012.10390" target="_blank">arXiv:2012.10390</a> [<a href="http://arxiv.org/pdf/2012.10390" target="_blank">pdf</a>]

<h2>Scalable and Provably Accurate Algorithms for Differentially Private Distributed Decision Tree Learning. (arXiv:2012.10602v2 [cs.LG] UPDATED)</h2>
<h3>Kaiwen Wang, Travis Dick, Maria-Florina Balcan</h3>
<p>This paper introduces the first provably accurate algorithms for
differentially private, top-down decision tree learning in the distributed
setting (Balcan et al., 2012). We propose DP-TopDown, a general privacy
preserving decision tree learning algorithm, and present two distributed
implementations. Our first method NoisyCounts naturally extends the single
machine algorithm by using the Laplace mechanism. Our second method LocalRNM
significantly reduces communication and added noise by performing local
optimization at each data holder. We provide the first utility guarantees for
differentially private top-down decision tree learning in both the single
machine and distributed settings. These guarantees show that the error of the
privately-learned decision tree quickly goes to zero provided that the dataset
is sufficiently large. Our extensive experiments on real datasets illustrate
the trade-offs of privacy, accuracy and generalization when learning private
decision trees in the distributed setting.
</p>
<a href="http://arxiv.org/abs/2012.10602" target="_blank">arXiv:2012.10602</a> [<a href="http://arxiv.org/pdf/2012.10602" target="_blank">pdf</a>]

<h2>Federated Unlearning. (arXiv:2012.13891v2 [cs.LG] UPDATED)</h2>
<h3>Gaoyang Liu, Yang Yang, Xiaoqiang Ma, Chen Wang, Jiangchuan Liu</h3>
<p>Federated learning (FL) has recently emerged as a promising distributed
machine learning (ML) paradigm. Practical needs of the "right to be forgotten"
and countering data poisoning attacks call for efficient techniques that can
remove, or unlearn, specific training data from the trained FL model. Existing
unlearning techniques in the context of ML, however, are no longer in effect
for FL, mainly due to the inherent distinction in the way how FL and ML learn
from data. Therefore, how to enable efficient data removal from FL models
remains largely under-explored. In this paper, we take the first step to fill
this gap by presenting FedEraser, the first federated unlearning methodology
that can eliminate the influence of a federated client's data on the global FL
model while significantly reducing the time used for constructing the unlearned
FL model.The basic idea of FedEraser is to trade the central server's storage
for unlearned model's construction time, where FedEraser reconstructs the
unlearned model by leveraging the historical parameter updates of federated
clients that have been retained at the central server during the training
process of FL. A novel calibration method is further developed to calibrate the
retained updates, which are further used to promptly construct the unlearned
model, yielding a significant speed-up to the reconstruction of the unlearned
model while maintaining the model efficacy. Experiments on four realistic
datasets demonstrate the effectiveness of FedEraser, with an expected speed-up
of $4\times$ compared with retraining from the scratch. We envision our work as
an early step in FL towards compliance with legal and ethical criteria in a
fair and transparent manner.
</p>
<a href="http://arxiv.org/abs/2012.13891" target="_blank">arXiv:2012.13891</a> [<a href="http://arxiv.org/pdf/2012.13891" target="_blank">pdf</a>]

<h2>Adaptive Surgical Robotic Training Using Real-Time Stylistic Behavior Feedback Through Haptic Cues. (arXiv:2101.00097v3 [cs.RO] UPDATED)</h2>
<h3>Marzieh Ershad, Robert Rege, Ann Majewicz Fey</h3>
<p>Surgical skill directly affects surgical procedure outcomes; thus, effective
training is needed to ensure satisfactory results. Many objective assessment
metrics have been developed and some are widely used in surgical training
simulators. These objective metrics provide the trainee with descriptive
feedback about their performance however, often lack feedback on how to proceed
to improve performance. The most effective training method is one that is
intuitive, easy to understand, personalized to the user and provided in a
timely manner. We propose a framework to enable user-adaptive training using
near-real-time detection of performance, based on intuitive styles of surgical
movements (e.g., fluidity, smoothness, crispness, etc.), and propose a haptic
feedback framework to assist with correcting styles of movement. We evaluate
the ability of three types of force feedback (spring, damping, and spring plus
damping feedback), computed based on prior user positions, to improve different
stylistic behaviors of the user during kinematically constrained reaching
movement tasks. The results indicate that four out of the six styles studied
here were statistically significantly improved (p&lt;0.05) using spring guidance
force feedback and a significant reduction in task time was also found using
spring feedback. The path straightness and targeting error in the task were
other task performance metrics studied which were improved significantly using
the spring-damping feedback. This study presents a groundwork for adaptive
training in robotic surgery based on near-real-time human-centric models of
surgical behavior.
</p>
<a href="http://arxiv.org/abs/2101.00097" target="_blank">arXiv:2101.00097</a> [<a href="http://arxiv.org/pdf/2101.00097" target="_blank">pdf</a>]

<h2>Towards Understanding the Behaviors of Optimal Deep Active Learning Algorithms. (arXiv:2101.00977v2 [cs.LG] UPDATED)</h2>
<h3>Yilun Zhou, Adithya Renduchintala, Xian Li, Sida Wang, Yashar Mehdad, Asish Ghoshal</h3>
<p>Active learning (AL) algorithms may achieve better performance with fewer
data because the model guides the data selection process. While many algorithms
have been proposed, there is little study on what the optimal AL algorithm
looks like, which would help researchers understand where their models fall
short and iterate on the design. In this paper, we present a simulated
annealing algorithm to search for this optimal oracle and analyze it for
several tasks. We present qualitative and quantitative insights into the
behaviors of this oracle, comparing and contrasting them with those of various
heuristics. Moreover, we are able to consistently improve the heuristics using
one particular insight. We hope that our findings can better inform future
active learning research. The code is available at
https://github.com/YilunZhou/optimal-active-learning.
</p>
<a href="http://arxiv.org/abs/2101.00977" target="_blank">arXiv:2101.00977</a> [<a href="http://arxiv.org/pdf/2101.00977" target="_blank">pdf</a>]

<h2>Transformers in Vision: A Survey. (arXiv:2101.01169v2 [cs.CV] UPDATED)</h2>
<h3>Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, Mubarak Shah</h3>
<p>Astounding results from Transformer models on natural language tasks have
intrigued the vision community to study their application to computer vision
problems. Among their salient benefits, Transformers enable modeling long
dependencies between input sequence elements and support parallel processing of
sequence as compared to recurrent networks e.g., Long short-term memory (LSTM).
Different from convolutional networks, Transformers require minimal inductive
biases for their design and are naturally suited as set-functions. Furthermore,
the straightforward design of Transformers allows processing multiple
modalities (e.g., images, videos, text and speech) using similar processing
blocks and demonstrates excellent scalability to very large capacity networks
and huge datasets. These strengths have led to exciting progress on a number of
vision tasks using Transformer networks. This survey aims to provide a
comprehensive overview of the Transformer models in the computer vision
discipline. We start with an introduction to fundamental concepts behind the
success of Transformers i.e., self-attention, large-scale pre-training, and
bidirectional encoding. We then cover extensive applications of transformers in
vision including popular recognition tasks (e.g., image classification, object
detection, action recognition, and segmentation), generative modeling,
multi-modal tasks (e.g., visual-question answering, visual reasoning, and
visual grounding), video processing (e.g., activity recognition, video
forecasting), low-level vision (e.g., image super-resolution, image
enhancement, and colorization) and 3D analysis (e.g., point cloud
classification and segmentation). We compare the respective advantages and
limitations of popular techniques both in terms of architectural design and
their experimental value. Finally, we provide an analysis on open research
directions and possible future works.
</p>
<a href="http://arxiv.org/abs/2101.01169" target="_blank">arXiv:2101.01169</a> [<a href="http://arxiv.org/pdf/2101.01169" target="_blank">pdf</a>]

<h2>Smoothed functional-based gradient algorithms for off-policy reinforcement learning: A non-asymptotic viewpoint. (arXiv:2101.02137v2 [cs.LG] UPDATED)</h2>
<h3>Nithia Vijayan, Prashanth L. A</h3>
<p>We propose two policy gradient algorithms for solving the problem of control
in an off-policy reinforcement learning (RL) context. Both algorithms
incorporate a smoothed functional (SF) based gradient estimation scheme. The
first algorithm is a straightforward combination of importance sampling-based
off-policy evaluation with SF-based gradient estimation. The second algorithm,
inspired by the stochastic variance-reduced gradient (SVRG) algorithm,
incorporates variance reduction in the update iteration. For both algorithms,
we derive non-asymptotic bounds that establish convergence to an approximate
stationary point. From these results, we infer that the first algorithm
converges at a rate that is comparable to the well-known REINFORCE algorithm in
an off-policy RL context, while the second algorithm exhibits an improved rate
of convergence.
</p>
<a href="http://arxiv.org/abs/2101.02137" target="_blank">arXiv:2101.02137</a> [<a href="http://arxiv.org/pdf/2101.02137" target="_blank">pdf</a>]

<h2>Reproducing Activation Function for Deep Learning. (arXiv:2101.04844v2 [cs.LG] UPDATED)</h2>
<h3>Senwei Liang, Liyao Lyu, Chunmei Wang, Haizhao Yang</h3>
<p>We propose reproducing activation functions (RAFs) to improve deep learning
accuracy for various applications ranging from computer vision to scientific
computing. The idea is to employ several basic functions and their learnable
linear combination to construct neuron-wise data-driven activation functions
for each neuron. Armed with RAFs, neural networks (NNs) can reproduce
traditional approximation tools and, therefore, approximate target functions
with a smaller number of parameters than traditional NNs. In NN training, RAFs
can generate neural tangent kernels (NTKs) with a better condition number than
traditional activation functions lessening the spectral bias of deep learning.
As demonstrated by extensive numerical tests, the proposed RAFs can facilitate
the convergence of deep learning optimization for a solution with higher
accuracy than existing deep learning solvers for audio/image/video
reconstruction, PDEs, and eigenvalue problems. With RAFs, the errors of
audio/video reconstruction, PDEs, and eigenvalue problems are decreased by over
14%, 73%, 99%, respectively, compared with baseline, while the performance of
image reconstruction increases by 58%.
</p>
<a href="http://arxiv.org/abs/2101.04844" target="_blank">arXiv:2101.04844</a> [<a href="http://arxiv.org/pdf/2101.04844" target="_blank">pdf</a>]

<h2>Hand-Based Person Identification using Global and Part-Aware Deep Feature Representation Learning. (arXiv:2101.05260v3 [cs.CV] UPDATED)</h2>
<h3>Nathanael L. Baisa, Zheheng Jiang, Ritesh Vyas, Bryan Williams, Hossein Rahmani, Plamen Angelov, Sue Black</h3>
<p>In cases of serious crime, including sexual abuse, often the only available
information with demonstrated potential for identification is images of the
hands. Since this evidence is captured in uncontrolled situations, it is
difficult to analyse. As global approaches to feature comparison are limited in
this case, it is important to extend to consider local information. In this
work, we propose hand-based person identification by learning both global and
local deep feature representation. Our proposed method, Global and Part-Aware
Network (GPA-Net), creates global and local branches on the conv-layer for
learning robust discriminative global and part-level features. For learning the
local (part-level) features, we perform uniform partitioning on the conv-layer
in both horizontal and vertical directions. We retrieve the parts by conducting
a soft partition without explicitly partitioning the images or requiring
external cues such as pose estimation. We make extensive evaluations on two
large multi-ethnic and publicly available hand datasets, demonstrating that our
proposed method significantly outperforms competing approaches.
</p>
<a href="http://arxiv.org/abs/2101.05260" target="_blank">arXiv:2101.05260</a> [<a href="http://arxiv.org/pdf/2101.05260" target="_blank">pdf</a>]

<h2>Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks. (arXiv:2101.05974v2 [cs.LG] UPDATED)</h2>
<h3>Yanbang Wang, Yen-Yu Chang, Yunyu Liu, Jure Leskovec, Pan Li</h3>
<p>Temporal networks serve as abstractions of many real-world dynamic systems.
These networks typically evolve according to certain laws, such as the law of
triadic closure, which is universal in social networks. Inductive
representation learning of temporal networks should be able to capture such
laws and further be applied to systems that follow the same laws but have not
been unseen during the training stage. Previous works in this area depend on
either network node identities or rich edge attributes and typically fail to
extract these laws. Here, we propose Causal Anonymous Walks (CAWs) to
inductively represent a temporal network. CAWs are extracted by temporal random
walks and work as automatic retrieval of temporal network motifs to represent
network dynamics while avoiding the time-consuming selection and counting of
those motifs. CAWs adopt a novel anonymization strategy that replaces node
identities with the hitting counts of the nodes based on a set of sampled walks
to keep the method inductive, and simultaneously establish the correlation
between motifs. We further propose a neural-network model CAW-N to encode CAWs,
and pair it with a CAW sampling strategy with constant memory and time cost to
support online training and inference. CAW-N is evaluated to predict links over
6 real temporal networks and uniformly outperforms previous SOTA methods by
averaged 15% AUC gain in the inductive setting. CAW-N also outperforms previous
methods in 5 out of the 6 networks in the transductive setting.
</p>
<a href="http://arxiv.org/abs/2101.05974" target="_blank">arXiv:2101.05974</a> [<a href="http://arxiv.org/pdf/2101.05974" target="_blank">pdf</a>]

<h2>TridentNet: A Conditional Generative Model for Dynamic Trajectory Generation. (arXiv:2101.06374v2 [cs.RO] UPDATED)</h2>
<h3>David Paz, Hengyuan Zhang, Henrik I. Christensen</h3>
<p>In recent years, various state of the art autonomous vehicle systems and
architectures have been introduced. These methods include planners that depend
on high-definition (HD) maps and models that learn an autonomous agent's
controls in an end-to-end fashion. While end-to-end models are geared towards
solving the scalability constraints from HD maps, they do not generalize for
different vehicles and sensor configurations. To address these shortcomings, we
introduce an approach that leverages lightweight map representations,
explicitly enforcing geometric constraints, and learns feasible trajectories
using a conditional generative model. Additional contributions include a new
dataset that is used to verify our proposed models quantitatively. The results
indicate low relative errors that can potentially translate to traversable
trajectories. The dataset created as part of this work has been made available
online.
</p>
<a href="http://arxiv.org/abs/2101.06374" target="_blank">arXiv:2101.06374</a> [<a href="http://arxiv.org/pdf/2101.06374" target="_blank">pdf</a>]

<h2>CheXtransfer: Performance and Parameter Efficiency of ImageNet Models for Chest X-Ray Interpretation. (arXiv:2101.06871v2 [cs.CV] UPDATED)</h2>
<h3>Alexander Ke, William Ellsworth, Oishi Banerjee, Andrew Y. Ng, Pranav Rajpurkar</h3>
<p>Deep learning methods for chest X-ray interpretation typically rely on
pretrained models developed for ImageNet. This paradigm assumes that better
ImageNet architectures perform better on chest X-ray tasks and that
ImageNet-pretrained weights provide a performance boost over random
initialization. In this work, we compare the transfer performance and parameter
efficiency of 16 popular convolutional architectures on a large chest X-ray
dataset (CheXpert) to investigate these assumptions. First, we find no
relationship between ImageNet performance and CheXpert performance for both
models without pretraining and models with pretraining. Second, we find that,
for models without pretraining, the choice of model family influences
performance more than size within a family for medical imaging tasks. Third, we
observe that ImageNet pretraining yields a statistically significant boost in
performance across architectures, with a higher boost for smaller
architectures. Fourth, we examine whether ImageNet architectures are
unnecessarily large for CheXpert by truncating final blocks from pretrained
models, and find that we can make models 3.25x more parameter-efficient on
average without a statistically significant drop in performance. Our work
contributes new experimental evidence about the relation of ImageNet to chest
x-ray interpretation performance.
</p>
<a href="http://arxiv.org/abs/2101.06871" target="_blank">arXiv:2101.06871</a> [<a href="http://arxiv.org/pdf/2101.06871" target="_blank">pdf</a>]

<h2>Salient Object Detection via Integrity Learning. (arXiv:2101.07663v3 [cs.CV] UPDATED)</h2>
<h3>Mingchen Zhuge, Deng-Ping Fan, Nian Liu, Dingwen Zhang, Dong Xu, Ling Shao</h3>
<p>Albeit current salient object detection (SOD) works have achieved fantastic
progress, they are cast into the shade when it comes to the integrity of the
predicted salient regions. We define the concept of integrity at both the micro
and macro level. Specifically, at the micro level, the model should highlight
all parts that belong to a certain salient object, while at the macro level,
the model needs to discover all salient objects from the given image scene. To
facilitate integrity learning for salient object detection, we design a novel
Integrity Cognition Network (ICON), which explores three important components
to learn strong integrity features. 1) Unlike the existing models that focus
more on feature discriminability, we introduce a diverse feature aggregation
(DFA) component to aggregate features with various receptive fields (i.e.,,
kernel shape and context) and increase the feature diversity. Such diversity is
the foundation for mining the integral salient objects. 2) Based on the DFA
features, we introduce the integrity channel enhancement (ICE) component with
the goal of enhancing feature channels that highlight the integral salient
objects at the macro level, while suppressing the other distracting ones. 3)
After extracting the enhanced features, the part-whole verification (PWV)
method is employed to determine whether the part and whole object features have
strong agreement. Such part-whole agreements can further improve the
micro-level integrity for each salient object. To demonstrate the effectiveness
of ICON, comprehensive experiments are conducted on seven challenging
benchmarks, where promising results are achieved.
</p>
<a href="http://arxiv.org/abs/2101.07663" target="_blank">arXiv:2101.07663</a> [<a href="http://arxiv.org/pdf/2101.07663" target="_blank">pdf</a>]

<h2>Multi-task Learning Approach for Automatic Modulation and Wireless Signal Classification. (arXiv:2101.10254v2 [cs.LG] UPDATED)</h2>
<h3>Anu Jagannath, Jithin Jagannath</h3>
<p>Wireless signal recognition is becoming increasingly more significant for
spectrum monitoring, spectrum management, and secure communications.
Consequently, it will become a key enabler with the emerging fifth-generation
(5G) and beyond 5G communications, Internet of Things networks, among others.
State-of-the-art studies in wireless signal recognition have only focused on a
single task which in many cases is insufficient information for a system to act
on. In this work, for the first time in the wireless communication domain, we
exploit the potential of deep neural networks in conjunction with multi-task
learning (MTL) framework to simultaneously learn modulation and signal
classification tasks. The proposed MTL architecture benefits from the mutual
relation between the two tasks in improving the classification accuracy as well
as the learning efficiency with a lightweight neural network model.
Additionally, we consider the problem of heterogeneous wireless signals such as
radar and communication signals in the electromagnetic spectrum. Accordingly,
we have shown how the proposed MTL model outperforms several state-of-the-art
single-task learning classifiers while maintaining a lighter architecture and
performing two signal characterization tasks simultaneously. Finally, we also
release the only known open heterogeneous wireless signals dataset that
comprises of radar and communication signals with multiple labels.
</p>
<a href="http://arxiv.org/abs/2101.10254" target="_blank">arXiv:2101.10254</a> [<a href="http://arxiv.org/pdf/2101.10254" target="_blank">pdf</a>]

<h2>Deep Learning for Scene Classification: A Survey. (arXiv:2101.10531v2 [cs.CV] UPDATED)</h2>
<h3>Delu Zeng, Minyu Liao, Mohammad Tavakolian, Yulan Guo, Bolei Zhou, Dewen Hu, Matti Pietik&#xe4;inen, Li Liu</h3>
<p>Scene classification, aiming at classifying a scene image to one of the
predefined scene categories by comprehending the entire image, is a
longstanding, fundamental and challenging problem in computer vision. The rise
of large-scale datasets, which constitute the corresponding dense sampling of
diverse real-world scenes, and the renaissance of deep learning techniques,
which learn powerful feature representations directly from big raw data, have
been bringing remarkable progress in the field of scene representation and
classification. To help researchers master needed advances in this field, the
goal of this paper is to provide a comprehensive survey of recent achievements
in scene classification using deep learning. More than 200 major publications
are included in this survey covering different aspects of scene classification,
including challenges, benchmark datasets, taxonomy, and quantitative
performance comparisons of the reviewed methods. In retrospect of what has been
achieved so far, this paper is also concluded with a list of promising research
opportunities.
</p>
<a href="http://arxiv.org/abs/2101.10531" target="_blank">arXiv:2101.10531</a> [<a href="http://arxiv.org/pdf/2101.10531" target="_blank">pdf</a>]

<h2>FIRe-GAN: A novel Deep Learning-based infrared-visible fusion method for wildfire imagery. (arXiv:2101.11745v2 [cs.CV] UPDATED)</h2>
<h3>J. F. Cipri&#xe1;n-S&#xe1;nchez, G. Ochoa-Ruiz, M. Gonzalez-Mendoza, L. Rossi</h3>
<p>Early wildfire detection is of paramount importance to avoid as much damage
as possible to the environment, properties, and lives. Deep Learning (DL)
models that can leverage both visible and infrared information have the
potential to display state-of-the-art performance, with lower false-positive
rates than existing techniques. However, most DL-based image fusion methods
have not been evaluated in the domain of fire imagery. Additionally, to the
best of our knowledge, no publicly available dataset contains visible-infrared
fused fire images. There is a growing interest in DL-based image fusion
techniques due to their reduced complexity. Due to the latter, we select three
state-of-the-art, DL-based image fusion techniques and evaluate them for the
specific task of fire image fusion. We compare the performance of these methods
on selected metrics. Finally, we also present an extension to one of the said
methods, that we called FIRe-GAN, that improves the generation of artificial
infrared images and fused ones on selected metrics.
</p>
<a href="http://arxiv.org/abs/2101.11745" target="_blank">arXiv:2101.11745</a> [<a href="http://arxiv.org/pdf/2101.11745" target="_blank">pdf</a>]

<h2>A note on synthesizing geodesic based contact curves. (arXiv:2101.12411v3 [cs.RO] UPDATED)</h2>
<h3>Rajesh Kumar, Sudipto Mukherjee</h3>
<p>The paper focuses on synthesizing optimal contact curves that can be used to
ensure a rolling constraint between two bodies in relative motion. We show that
geodesic based contact curves generated on both the contacting surfaces are
sufficient conditions to ensure rolling. The differential geodesic equations,
when modified, can ensure proper disturbance rejection in case the system of
interacting bodies is perturbed from the desired curve. A corollary states that
geodesic curves are generated on the surface if rolling constraints are
satisfied. Simulations in the context of in-hand manipulations of the objects
are used as examples.
</p>
<a href="http://arxiv.org/abs/2101.12411" target="_blank">arXiv:2101.12411</a> [<a href="http://arxiv.org/pdf/2101.12411" target="_blank">pdf</a>]

<h2>Learning High Dimensional Wasserstein Geodesics. (arXiv:2102.02992v3 [cs.LG] UPDATED)</h2>
<h3>Shu Liu, Shaojun Ma, Yongxin Chen, Hongyuan Zha, Haomin Zhou</h3>
<p>We propose a new formulation and learning strategy for computing the
Wasserstein geodesic between two probability distributions in high dimensions.
By applying the method of Lagrange multipliers to the dynamic formulation of
the optimal transport (OT) problem, we derive a minimax problem whose saddle
point is the Wasserstein geodesic. We then parametrize the functions by deep
neural networks and design a sample based bidirectional learning algorithm for
training. The trained networks enable sampling from the Wasserstein geodesic.
As by-products, the algorithm also computes the Wasserstein distance and OT map
between the marginal distributions. We demonstrate the performance of our
algorithms through a series of experiments with both synthetic and realistic
data.
</p>
<a href="http://arxiv.org/abs/2102.02992" target="_blank">arXiv:2102.02992</a> [<a href="http://arxiv.org/pdf/2102.02992" target="_blank">pdf</a>]

<h2>Projection Robust Wasserstein Barycenters. (arXiv:2102.03390v2 [cs.LG] UPDATED)</h2>
<h3>Minhui Huang, Shiqian Ma, Lifeng Lai</h3>
<p>Collecting and aggregating information from several probability measures or
histograms is a fundamental task in machine learning. One of the popular
solution methods for this task is to compute the barycenter of the probability
measures under the Wasserstein metric. However, approximating the Wasserstein
barycenter is numerically challenging because of the curse of dimensionality.
This paper proposes the projection robust Wasserstein barycenter (PRWB) that
has the potential to mitigate the curse of dimensionality. Since PRWB is
numerically very challenging to solve, we further propose a relaxed PRWB
(RPRWB) model, which is more tractable. The RPRWB projects the probability
measures onto a lower-dimensional subspace that maximizes the Wasserstein
barycenter objective. The resulting problem is a max-min problem over the
Stiefel manifold. By combining the iterative Bregman projection algorithm and
Riemannian optimization, we propose two new algorithms for computing the RPRWB.
The complexity of arithmetic operations of the proposed algorithms for
obtaining an $\epsilon$-stationary solution is analyzed. We incorporate the
RPRWB into a discrete distribution clustering algorithm, and the numerical
results on real text datasets confirm that our RPRWB model helps improve the
clustering performance significantly.
</p>
<a href="http://arxiv.org/abs/2102.03390" target="_blank">arXiv:2102.03390</a> [<a href="http://arxiv.org/pdf/2102.03390" target="_blank">pdf</a>]

<h2>RIIT: Rethinking the Importance of Implementation Tricks in Multi-Agent Reinforcement Learning. (arXiv:2102.03479v2 [cs.LG] UPDATED)</h2>
<h3>Jian Hu, Haibin Wu, Seth Austin Harding, Siyang Jiang, Shih-wei Liao</h3>
<p>In recent years, Multi-Agent Deep Reinforcement Learning (MADRL) has been
successfully applied to various complex scenarios such as computer games and
robot swarms. We investigate the impact of "implementation tricks" of
state-of-the-art (SOTA) cooperative QMIX-based algorithms. Firstly, we find
that such tricks described as auxiliary details to the core algorithm,
seemingly of secondary importance, have a major impact. This finding
demonstrates that, after modest tuning, the QMIX attains extraordinarily high
win rates and achieves SOTA in the StarCraft Multi-Agent Challenge (SMAC).
Furthermore, we find that the consideration of QMIX's monotonicity condition is
critical for cooperative tasks. Based on the above findings, we propose a new
algorithm called: RIIT, which achieves SOTA among policy-based algorithms
(allowing for convenient complex action space modeling). We open-sourced the
code at \url{https://github.com/hijkzzz/pymarl2}.
</p>
<a href="http://arxiv.org/abs/2102.03479" target="_blank">arXiv:2102.03479</a> [<a href="http://arxiv.org/pdf/2102.03479" target="_blank">pdf</a>]

<h2>One-shot Face Reenactment Using Appearance Adaptive Normalization. (arXiv:2102.03984v2 [cs.CV] UPDATED)</h2>
<h3>Guangming Yao, Yi Yuan, Tianjia Shao, Shuang Li, Shanqi Liu, Yong Liu, Mengmeng Wang, Kun Zhou</h3>
<p>The paper proposes a novel generative adversarial network for one-shot face
reenactment, which can animate a single face image to a different
pose-and-expression (provided by a driving image) while keeping its original
appearance. The core of our network is a novel mechanism called appearance
adaptive normalization, which can effectively integrate the appearance
information from the input image into our face generator by modulating the
feature maps of the generator using the learned adaptive parameters.
Furthermore, we specially design a local net to reenact the local facial
components (i.e., eyes, nose and mouth) first, which is a much easier task for
the network to learn and can in turn provide explicit anchors to guide our face
generator to learn the global appearance and pose-and-expression. Extensive
quantitative and qualitative experiments demonstrate the significant efficacy
of our model compared with prior one-shot methods.
</p>
<a href="http://arxiv.org/abs/2102.03984" target="_blank">arXiv:2102.03984</a> [<a href="http://arxiv.org/pdf/2102.03984" target="_blank">pdf</a>]

<h2>Robust Generalization and Safe Query-Specialization in Counterfactual Learning to Rank. (arXiv:2102.05990v2 [cs.LG] UPDATED)</h2>
<h3>Harrie Oosterhuis, Maarten de Rijke</h3>
<p>Existing work in counterfactual Learning to Rank (LTR) has focussed on
optimizing feature-based models that predict the optimal ranking based on
document features. LTR methods based on bandit algorithms often optimize
tabular models that memorize the optimal ranking per query. These types of
model have their own advantages and disadvantages. Feature-based models provide
very robust performance across many queries, including those previously unseen,
however, the available features often limit the rankings the model can predict.
In contrast, tabular models can converge on any possible ranking through
memorization. However, memorization is extremely prone to noise, which makes
tabular models reliable only when large numbers of user interactions are
available. Can we develop a robust counterfactual LTR method that pursues
memorization-based optimization whenever it is safe to do? We introduce the
Generalization and Specialization (GENSPEC) algorithm, a robust feature-based
counterfactual LTR method that pursues per-query memorization when it is safe
to do so. GENSPEC optimizes a single feature-based model for generalization:
robust performance across all queries, and many tabular models for
specialization: each optimized for high performance on a single query. GENSPEC
uses novel relative high-confidence bounds to choose which model to deploy per
query. By doing so, GENSPEC enjoys the high performance of successfully
specialized tabular models with the robustness of a generalized feature-based
model. Our results show that GENSPEC leads to optimal performance on queries
with sufficient click data, while having robust behavior on queries with little
or noisy data.
</p>
<a href="http://arxiv.org/abs/2102.05990" target="_blank">arXiv:2102.05990</a> [<a href="http://arxiv.org/pdf/2102.05990" target="_blank">pdf</a>]

<h2>Machine Learning for Mechanical Ventilation Control. (arXiv:2102.06779v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Suo, Udaya Ghai, Edgar Minasyan, Paula Gradu, Xinyi Chen, Naman Agarwal, Cyril Zhang, Karan Singh, Julienne LaChance, Tom Zajdel, Manuel Schottdorf, Daniel Cohen, Elad Hazan</h3>
<p>We consider the problem of controlling an invasive mechanical ventilator for
pressure-controlled ventilation: a controller must let air in and out of a
sedated patient's lungs according to a trajectory of airway pressures specified
by a clinician.

Hand-tuned PID controllers and similar variants have comprised the industry
standard for decades, yet can behave poorly by over- or under-shooting their
target or oscillating rapidly.

We consider a data-driven machine learning approach: First, we train a
simulator based on data we collect from an artificial lung. Then, we train deep
neural network controllers on these simulators.We show that our controllers are
able to track target pressure waveforms significantly better than PID
controllers.

We further show that a learned controller generalizes across lungs with
varying characteristics much more readily than PID controllers do.
</p>
<a href="http://arxiv.org/abs/2102.06779" target="_blank">arXiv:2102.06779</a> [<a href="http://arxiv.org/pdf/2102.06779" target="_blank">pdf</a>]

<h2>Multi-class Generative Adversarial Nets for Semi-supervised Image Classification. (arXiv:2102.06944v2 [cs.CV] UPDATED)</h2>
<h3>Saman Motamed, Farzad Khalvati</h3>
<p>From generating never-before-seen images to domain adaptation, applications
of Generative Adversarial Networks (GANs) spread wide in the domain of vision
and graphics problems. With the remarkable ability of GANs in learning the
distribution and generating images of a particular class, they can be used for
semi-supervised classification tasks. However, the problem is that if two
classes of images share similar characteristics, the GAN might learn to
generalize and hinder the classification of the two classes. In this paper, we
use various images from MNIST and Fashion-MNIST datasets to illustrate how
similar images cause the GAN to generalize, leading to the poor classification
of images. We propose a modification to the traditional training of GANs that
allows for improved multi-class classification in similar classes of images in
a semi-supervised learning framework.
</p>
<a href="http://arxiv.org/abs/2102.06944" target="_blank">arXiv:2102.06944</a> [<a href="http://arxiv.org/pdf/2102.06944" target="_blank">pdf</a>]

<h2>FAT: Learning Low-Bitwidth Parametric Representation via Frequency-Aware Transformation. (arXiv:2102.07444v2 [cs.CV] UPDATED)</h2>
<h3>Chaofan Tao, Rui Lin, Quan Chen, Zhaoyang Zhang, Ping Luo, Ngai Wong</h3>
<p>Learning convolutional neural networks (CNNs) with low bitwidth is
challenging because performance may drop significantly after quantization.
Prior arts often discretize the network weights by carefully tuning
hyper-parameters of quantization (e.g. non-uniform stepsize and layer-wise
bitwidths), which are complicated and sub-optimal because the full-precision
and low-precision models have a large discrepancy. This work presents a novel
quantization pipeline, Frequency-Aware Transformation (FAT), which has several
appealing benefits. (1) Rather than designing complicated quantizers like
existing works, FAT learns to transform network weights in the frequency domain
before quantization, making them more amenable to training in low bitwidth. (2)
With FAT, CNNs can be easily trained in low precision using simple standard
quantizers without tedious hyper-parameter tuning. Theoretical analysis shows
that FAT improves both uniform and non-uniform quantizers. (3) FAT can be
easily plugged into many CNN architectures. When training ResNet-18 and
MobileNet-V2 in 4 bits, FAT plus a simple rounding operation already achieves
70.5% and 69.2% top-1 accuracy on ImageNet without bells and whistles,
outperforming recent state-of-the-art by reducing 54.9X and 45.7X computations
against full-precision models. We hope FAT provides a novel perspective for
model quantization. Code is available at
\url{https://github.com/ChaofanTao/FAT_Quantization}.
</p>
<a href="http://arxiv.org/abs/2102.07444" target="_blank">arXiv:2102.07444</a> [<a href="http://arxiv.org/pdf/2102.07444" target="_blank">pdf</a>]

<h2>Spatio-temporal Graph-RNN for Point Cloud Prediction. (arXiv:2102.07482v3 [cs.CV] UPDATED)</h2>
<h3>Pedro Gomes, Silvia Rossi, Laura Toni</h3>
<p>In this paper, we propose an end-to-end learning network to predict future
frames in a point cloud sequence. As main novelty, an initial layer learns
topological information of point clouds as geometric features, to form
representative spatio-temporal neighborhoods. This module is followed by
multiple Graph-RNN cells. Each cell learns points dynamics (i.e., RNN states)
by processing each point jointly with the spatio-temporal neighbouring points.
We tested the network performance with a MINST dataset of moving digits, a
synthetic human bodies motions and JPEG dynamic bodies datasets. Simulation
results demonstrate that our method outperforms baseline ones that neglect
geometry features information.
</p>
<a href="http://arxiv.org/abs/2102.07482" target="_blank">arXiv:2102.07482</a> [<a href="http://arxiv.org/pdf/2102.07482" target="_blank">pdf</a>]

<h2>Does Standard Backpropagation Forget Less Catastrophically Than Adam?. (arXiv:2102.07686v2 [cs.LG] UPDATED)</h2>
<h3>Dylan R. Ashley, Sina Ghiassian, Richard S. Sutton</h3>
<p>Catastrophic forgetting remains a severe hindrance to the broad application
of artificial neural networks (ANNs), however, it continues to be a poorly
understood phenomenon. Despite the extensive amount of work on catastrophic
forgetting, we argue that it is still unclear how exactly the phenomenon should
be quantified, and, moreover, to what degree all of the choices we make when
designing learning systems affect the amount of catastrophic forgetting. We use
various testbeds from the reinforcement learning and supervised learning
literature to (1) provide evidence that the choice of which modern
gradient-based optimization algorithm is used to train an ANN has a significant
impact on the amount of catastrophic forgetting and show that--surprisingly--in
many instances classical algorithms such as vanilla SGD experience less
catastrophic forgetting than the more modern algorithms such as Adam. We
empirically compare four different existing metrics for quantifying
catastrophic forgetting and (2) show that the degree to which the learning
systems experience catastrophic forgetting is sufficiently sensitive to the
metric used that a change from one principled metric to another is enough to
change the conclusions of a study dramatically. Our results suggest that a much
more rigorous experimental methodology is required when looking at catastrophic
forgetting. Based on our results, we recommend inter-task forgetting in
supervised learning must be measured with both retention and relearning metrics
concurrently, and intra-task forgetting in reinforcement learning must--at the
very least--be measured with pairwise interference.
</p>
<a href="http://arxiv.org/abs/2102.07686" target="_blank">arXiv:2102.07686</a> [<a href="http://arxiv.org/pdf/2102.07686" target="_blank">pdf</a>]

<h2>Improper Learning with Gradient-based Policy Optimization. (arXiv:2102.08201v2 [cs.LG] UPDATED)</h2>
<h3>Mohammadi Zaki, Avinash Mohan, Aditya Gopalan, Shie Mannor</h3>
<p>We consider an improper reinforcement learning setting where the learner is
given M base controllers for an unknown Markov Decision Process, and wishes to
combine them optimally to produce a potentially new controller that can
outperform each of the base ones. We propose a gradient-based approach that
operates over a class of improper mixtures of the controllers. The value
function of the mixture and its gradient may not be available in closed-form;
however, we show that we can employ rollouts and simultaneous perturbation
stochastic approximation (SPSA) for explicit gradient descent optimization. We
derive convergence and convergence rate guarantees for the approach assuming
access to a gradient oracle. Numerical results on a challenging constrained
queueing task show that our improper policy optimization algorithm can
stabilize the system even when each constituent policy at its disposal is
unstable.
</p>
<a href="http://arxiv.org/abs/2102.08201" target="_blank">arXiv:2102.08201</a> [<a href="http://arxiv.org/pdf/2102.08201" target="_blank">pdf</a>]

<h2>Classification of multivariate weakly-labelled time-series with attention. (arXiv:2102.08245v2 [cs.LG] UPDATED)</h2>
<h3>Surayez Rahman, Chang Wei Tan</h3>
<p>This research identifies a gap in weakly-labelled multivariate time-series
classification (TSC), where state-of-the-art TSC models do not per-form well.
Weakly labelled time-series are time-series containing noise and significant
redundancies. In response to this gap, this paper proposes an approach of
exploiting context relevance of subsequences from previous subsequences to
improve classification accuracy. To achieve this, state-of-the-art Attention
algorithms are experimented in combination with the top CNN models for TSC (FCN
and ResNet), in an CNN-LSTM architecture. Attention is a popular strategy for
context extraction with exceptional performance in modern sequence-to-sequence
tasks. This paper shows how attention algorithms can be used for improved
weakly labelledTSC by evaluating models on a multivariate EEG time-series
dataset obtained using a commercial Emotiv headsets from participants
performing various activities while driving. These time-series are segmented
into sub-sequences and labelled to allow supervised TSC.
</p>
<a href="http://arxiv.org/abs/2102.08245" target="_blank">arXiv:2102.08245</a> [<a href="http://arxiv.org/pdf/2102.08245" target="_blank">pdf</a>]

<h2>Optimal Mixed Discrete-Continuous Planning for Linear Hybrid Systems. (arXiv:2102.08261v2 [cs.RO] UPDATED)</h2>
<h3>Jingkai Chen, Brian Williams, Chuchu Fan</h3>
<p>Planning in hybrid systems with both discrete and continuous control
variables is important for dealing with real-world applications such as
extra-planetary exploration and multi-vehicle transportation systems.
Meanwhile, generating high-quality solutions given certain hybrid planning
specifications is crucial to building high-performance hybrid systems. However,
since hybrid planning is challenging in general, most methods use greedy search
that is guided by various heuristics, which is neither complete nor optimal and
often falls into blind search towards an infinite-action plan. In this paper,
we present a hybrid automaton planning formalism and propose an optimal
approach that encodes this planning problem as a Mixed Integer Linear Program
(MILP) by fixing the action number of automaton runs. We also show an extension
of our approach for reasoning over temporally concurrent goals. By leveraging
an efficient MILP optimizer, our method is able to generate provably optimal
solutions for complex mixed discrete-continuous planning problems within a
reasonable time. We use several case studies to demonstrate the extraordinary
performance of our hybrid planning method and show that it outperforms a
state-of-the-art hybrid planner, Scotty, in both efficiency and solution
qualities.
</p>
<a href="http://arxiv.org/abs/2102.08261" target="_blank">arXiv:2102.08261</a> [<a href="http://arxiv.org/pdf/2102.08261" target="_blank">pdf</a>]

<h2>Fast Graph Learning with Unique Optimal Solutions. (arXiv:2102.08530v2 [cs.LG] UPDATED)</h2>
<h3>Sami Abu-El-Haija, Valentino Crespi, Greg Ver Steeg, Aram Galstyan</h3>
<p>Graph Representation Learning (GRL) has been advancing at an unprecedented
rate. However, many results rely on careful design and tuning of architectures,
objectives, and training schemes. We propose efficient GRL methods that
optimize convexified objectives with known closed form solutions. Guaranteed
convergence to a global optimum releases practitioners from hyper-parameter and
architecture tuning. Nevertheless, our proposed method achieves competitive or
state-of-the-art performance on popular GRL tasks while providing orders of
magnitude speedup. Although the design matrix ($\mathbf{M}$) of our objective
is expensive to compute, we exploit results from random matrix theory to
approximate solutions in linear time while avoiding an explicit calculation of
$\mathbf{M}$. Our code is online: this http URL
</p>
<a href="http://arxiv.org/abs/2102.08530" target="_blank">arXiv:2102.08530</a> [<a href="http://arxiv.org/pdf/2102.08530" target="_blank">pdf</a>]

<h2>Robust Estimation of Tree Structured Markov Random Fields. (arXiv:2102.08554v2 [stat.ML] UPDATED)</h2>
<h3>Ashish Katiyar, Soumya Basu, Vatsal Shah, Constantine Caramanis</h3>
<p>We study the problem of learning tree-structured Markov random fields (MRF)
on discrete random variables with common support when the observations are
corrupted by unknown noise. As the presence of noise in the observations
obfuscates the original tree structure, the extent of recoverability of the
tree-structured MRFs under noisy observations is brought into question.

We show that in a general noise model, the underlying tree structure can be
recovered only up to an equivalence class where each of the leaf nodes is
indistinguishable from its parent and siblings, forming a leaf cluster. As the
indistinguishability arises due to contrived noise models, we study the natural
k-ary symmetric channel noise model where the value of each node is changed to
a uniform value in the support with an unequal and unknown probability. Here,
the answer becomes much more nuanced. We show that with a support size of 2,
and the binary symmetric channel noise model, the leaf clusters remain
indistinguishable. From support size 3 and up, the recoverability of a leaf
cluster is dictated by the joint probability mass function of the nodes within
it. We provide a precise characterization of recoverability by deriving a
necessary and sufficient condition for the recoverability of a leaf cluster. We
provide an algorithm that recovers the tree if this condition is satisfied, and
recovers the tree up to the leaf clusters failing this condition.
</p>
<a href="http://arxiv.org/abs/2102.08554" target="_blank">arXiv:2102.08554</a> [<a href="http://arxiv.org/pdf/2102.08554" target="_blank">pdf</a>]

<h2>Clockwork Variational Autoencoders. (arXiv:2102.09532v2 [cs.CV] UPDATED)</h2>
<h3>Vaibhav Saxena, Jimmy Ba, Danijar Hafner</h3>
<p>Deep learning has enabled algorithms to generate realistic images. However,
accurately predicting long video sequences requires understanding long-term
dependencies and remains an open challenge. While existing video prediction
models succeed at generating sharp images, they tend to fail at accurately
predicting far into the future. We introduce the Clockwork VAE (CW-VAE), a
video prediction model that leverages a hierarchy of latent sequences, where
higher levels tick at slower intervals. We demonstrate the benefits of both
hierarchical latents and temporal abstraction on 4 diverse video prediction
datasets with sequences of up to 1000 frames, where CW-VAE outperforms top
video prediction models. Additionally, we propose a Minecraft benchmark for
long-term video prediction. We conduct several experiments to gain insights
into CW-VAE and confirm that slower levels learn to represent objects that
change more slowly in the video, and faster levels learn to represent faster
objects.
</p>
<a href="http://arxiv.org/abs/2102.09532" target="_blank">arXiv:2102.09532</a> [<a href="http://arxiv.org/pdf/2102.09532" target="_blank">pdf</a>]

<h2>Sim-Env: Decoupling OpenAI Gym Environments from Simulation Models. (arXiv:2102.09824v2 [cs.LG] UPDATED)</h2>
<h3>Andreas Schuderer (1 and 2), Stefano Bromuri (1), Marko van Eekelen (1 and 3) ((1) Open University of the Netherlands, (2) APG Algemene Pensioen Groep N.V., (3) Radboud University)</h3>
<p>Reinforcement learning (RL) is one of the most active fields of AI research.
Despite the interest demonstrated by the research community in reinforcement
learning, the development methodology still lags behind, with a severe lack of
standard APIs to foster the development of RL applications. OpenAI Gym is
probably the most used environment to develop RL applications and simulations,
but most of the abstractions proposed in such a framework are still assuming a
semi-structured methodology. This is particularly relevant for agent-based
models whose purpose is to analyse adaptive behaviour displayed by
self-learning agents in the simulation. In order to bridge this gap, we present
a workflow and tools for the decoupled development and maintenance of
multi-purpose agent-based models and derived single-purpose reinforcement
learning environments, enabling the researcher to swap out environments with
ones representing different perspectives or different reward models, all while
keeping the underlying domain model intact and separate. The Sim-Env Python
library generates OpenAI-Gym-compatible reinforcement learning environments
that use existing or purposely created domain models as their simulation
back-ends. Its design emphasizes ease-of-use, modularity and code separation.
</p>
<a href="http://arxiv.org/abs/2102.09824" target="_blank">arXiv:2102.09824</a> [<a href="http://arxiv.org/pdf/2102.09824" target="_blank">pdf</a>]

<h2>Self-Taught Semi-Supervised Anomaly Detection on Upper Limb X-rays. (arXiv:2102.09895v2 [cs.CV] UPDATED)</h2>
<h3>Antoine Spahr, Behzad Bozorgtabar, Jean-Philippe Thiran</h3>
<p>Detecting anomalies in musculoskeletal radiographs is of paramount importance
for large-scale screening in the radiology workflow. Supervised deep networks
take for granted a large number of annotations by radiologists, which is often
prohibitively very time-consuming to acquire. Moreover, supervised systems are
tailored to closed set scenarios, e.g., trained models suffer from overfitting
to previously seen rare anomalies at training. Instead, our approach's
rationale is to use task agnostic pretext tasks to leverage unlabeled data
based on a cross-sample similarity measure. Besides, we formulate a complex
distribution of data from normal class within our framework to avoid a
potential bias on the side of anomalies. Through extensive experiments, we show
that our method outperforms baselines across unsupervised and self-supervised
anomaly detection settings on a real-world medical dataset, the MURA dataset.
We also provide rich ablation studies to analyze each training stage's effect
and loss terms on the final performance.
</p>
<a href="http://arxiv.org/abs/2102.09895" target="_blank">arXiv:2102.09895</a> [<a href="http://arxiv.org/pdf/2102.09895" target="_blank">pdf</a>]

<h2>Gaussian Process Regression in Logarithmic Time. (arXiv:2102.09964v2 [cs.LG] UPDATED)</h2>
<h3>Adrien Corenflos, Zheng Zhao, Simo S&#xe4;rkk&#xe4;</h3>
<p>The aim of this article is to present a novel parallelization method for
temporal Gaussian process (GP) regression problems. The method allows for
solving GP regression problems in logarithmic $O(\log N)$ time, where $N$ is
the number of time steps. Our approach uses the state-space representation of
GPs which in its original form allows for linear $O(N)$ time GP regression by
leveraging the Kalman filtering and smoothing methods. By using a recently
proposed parallelization method for Bayesian filters and smoothers, we are able
to reduce the linear computational complexity of the Kalman filter and smoother
solutions to the GP regression problems into logarithmic span complexity, which
transforms into logarithm time complexity when implemented in parallel hardware
such as a graphics processing unit (GPU). We experimentally demonstrate the
computational benefits one simulated and real datasets via our open-source
implementation leveraging the GPflow framework.
</p>
<a href="http://arxiv.org/abs/2102.09964" target="_blank">arXiv:2102.09964</a> [<a href="http://arxiv.org/pdf/2102.09964" target="_blank">pdf</a>]

<h2>Learning to Stop with Surprisingly Few Samples. (arXiv:2102.10025v2 [cs.LG] UPDATED)</h2>
<h3>Daniel Russo, Assaf Zeevi, Tianyi Zhang</h3>
<p>We consider a discounted infinite horizon optimal stopping problem. If the
underlying distribution is known a priori, the solution of this problem is
obtained via dynamic programming (DP) and is given by a well known threshold
rule. When information on this distribution is lacking, a natural (though
naive) approach is "explore-then-exploit," whereby the unknown distribution or
its parameters are estimated over an initial exploration phase, and this
estimate is then used in the DP to determine actions over the residual
exploitation phase. We show: (i) with proper tuning, this approach leads to
performance comparable to the full information DP solution; and (ii) despite
common wisdom on the sensitivity of such "plug in" approaches in DP due to
propagation of estimation errors, a surprisingly "short" (logarithmic in the
horizon) exploration horizon suffices to obtain said performance. In cases
where the underlying distribution is heavy-tailed, these observations are even
more pronounced: a ${\it single \, sample}$ exploration phase suffices.
</p>
<a href="http://arxiv.org/abs/2102.10025" target="_blank">arXiv:2102.10025</a> [<a href="http://arxiv.org/pdf/2102.10025" target="_blank">pdf</a>]

<h2>Optimism is All You Need: Model-Based Imitation Learning From Observation Alone. (arXiv:2102.10769v1 [cs.LG])</h2>
<h3>Rahul Kidambi, Jonathan Chang, Wen Sun</h3>
<p>This paper studies Imitation Learning from Observations alone (ILFO) where
the learner is presented with expert demonstrations that only consist of states
encountered by an expert (without access to actions taken by the expert). We
present a provably efficient model-based framework MobILE to solve the ILFO
problem. MobILE involves carefully trading off exploration against imitation -
this is achieved by integrating the idea of optimism in the face of uncertainty
into the distribution matching imitation learning (IL) framework. We provide a
unified analysis for MobILE, and demonstrate that MobILE enjoys strong
performance guarantees for classes of MDP dynamics that satisfy certain well
studied notions of complexity. We also show that the ILFO problem is strictly
harder than the standard IL problem by reducing ILFO to a multi-armed bandit
problem indicating that exploration is necessary for ILFO. We complement these
theoretical results with experimental simulations on benchmark OpenAI Gym tasks
that indicate the efficacy of MobILE.
</p>
<a href="http://arxiv.org/abs/2102.10769" target="_blank">arXiv:2102.10769</a> [<a href="http://arxiv.org/pdf/2102.10769" target="_blank">pdf</a>]

<h2>Divide-and-conquer methods for big data analysis. (arXiv:2102.10771v1 [stat.ML])</h2>
<h3>Xueying Chen, Jerry Q. Cheng, Min-ge Xie</h3>
<p>In the context of big data analysis, the divide-and-conquer methodology
refers to a multiple-step process: first splitting a data set into several
smaller ones; then analyzing each set separately; finally combining results
from each analysis together. This approach is effective in handling large data
sets that are unsuitable to be analyzed entirely by a single computer due to
limits either from memory storage or computational time. The combined results
will provide a statistical inference which is similar to the one from analyzing
the entire data set. This article reviews some recently developments of
divide-and-conquer methods in a variety of settings, including combining based
on parametric, semiparametric and nonparametric models, online sequential
updating methods, among others. Theoretical development on the efficiency of
the divide-and-conquer methods is also discussed.
</p>
<a href="http://arxiv.org/abs/2102.10771" target="_blank">arXiv:2102.10771</a> [<a href="http://arxiv.org/pdf/2102.10771" target="_blank">pdf</a>]

<h2>Slowly Varying Regression under Sparsity. (arXiv:2102.10773v1 [cs.LG])</h2>
<h3>Dimitris Bertsimas, Vassilis Digalakis Jr., Michael Linghzi Li, Omar Skali Lami</h3>
<p>We consider the problem of parameter estimation in slowly varying regression
models with sparsity constraints. We formulate the problem as a mixed integer
optimization problem and demonstrate that it can be reformulated exactly as a
binary convex optimization problem through a novel exact relaxation. The
relaxation utilizes a new equality on Moore-Penrose inverses that convexifies
the non-convex objective function while coinciding with the original objective
on all feasible binary points. This allows us to solve the problem
significantly more efficiently and to provable optimality using a cutting
plane-type algorithm. We develop a highly optimized implementation of such
algorithm, which substantially improves upon the asymptotic computational
complexity of a straightforward implementation. We further develop a heuristic
method that is guaranteed to produce a feasible solution and, as we empirically
illustrate, generates high quality warm-start solutions for the binary
optimization problem. We show, on both synthetic and real-world datasets, that
the resulting algorithm outperforms competing formulations in comparable times
across a variety of metrics including out-of-sample predictive performance,
support recovery accuracy, and false positive rate. The algorithm enables us to
train models with 10,000s of parameters, is robust to noise, and able to
effectively capture the underlying slowly changing support of the data
generating process.
</p>
<a href="http://arxiv.org/abs/2102.10773" target="_blank">arXiv:2102.10773</a> [<a href="http://arxiv.org/pdf/2102.10773" target="_blank">pdf</a>]

<h2>Non-linear, Sparse Dimensionality Reduction via Path Lasso Penalized Autoencoders. (arXiv:2102.10873v1 [cs.LG])</h2>
<h3>Oskar Allerbo, Rebecka J&#xf6;rnsten</h3>
<p>High-dimensional data sets are often analyzed and explored via the
construction of a latent low-dimensional space which enables convenient
visualization and efficient predictive modeling or clustering. For complex data
structures, linear dimensionality reduction techniques like PCA may not be
sufficiently flexible to enable low-dimensional representation. Non-linear
dimension reduction techniques, like kernel PCA and autoencoders, suffer from
loss of interpretability since each latent variable is dependent of all input
dimensions. To address this limitation, we here present path lasso penalized
autoencoders. This structured regularization enhances interpretability by
penalizing each path through the encoder from an input to a latent variable,
thus restricting how many input variables are represented in each latent
dimension. Our algorithm uses a group lasso penalty and non-negative matrix
factorization to construct a sparse, non-linear latent representation. We
compare the path lasso regularized autoencoder to PCA, sparse PCA, autoencoders
and sparse autoencoders on real and simulated data sets. We show that the
algorithm exhibits much lower reconstruction errors than sparse PCA and
parameter-wise lasso regularized autoencoders for low-dimensional
representations. Moreover, path lasso representations provide a more accurate
reconstruction match, i.e. preserved relative distance between objects in the
original and reconstructed spaces.
</p>
<a href="http://arxiv.org/abs/2102.10873" target="_blank">arXiv:2102.10873</a> [<a href="http://arxiv.org/pdf/2102.10873" target="_blank">pdf</a>]

<h2>Shapley values for feature selection: The good, the bad, and the axioms. (arXiv:2102.10936v1 [cs.LG])</h2>
<h3>Daniel Fryer, Inga Str&#xfc;mke, Hien Nguyen</h3>
<p>The Shapley value has become popular in the Explainable AI (XAI) literature,
thanks, to a large extent, to a solid theoretical foundation, including four
"favourable and fair" axioms for attribution in transferable utility games. The
Shapley value is provably the only solution concept satisfying these axioms. In
this paper, we introduce the Shapley value and draw attention to its recent
uses as a feature selection tool. We call into question this use of the Shapley
value, using simple, abstract "toy" counterexamples to illustrate that the
axioms may work against the goals of feature selection. From this, we develop a
number of insights that are then investigated in concrete simulation settings,
with a variety of Shapley value formulations, including SHapley Additive
exPlanations (SHAP) and Shapley Additive Global importancE (SAGE).
</p>
<a href="http://arxiv.org/abs/2102.10936" target="_blank">arXiv:2102.10936</a> [<a href="http://arxiv.org/pdf/2102.10936" target="_blank">pdf</a>]

<h2>Explainers in the Wild: Making Surrogate Explainers Robust to Distortions through Perception. (arXiv:2102.10951v1 [cs.CV])</h2>
<h3>Alexander Hepburn, Raul Santos-Rodriguez</h3>
<p>Explaining the decisions of models is becoming pervasive in the image
processing domain, whether it is by using post-hoc methods or by creating
inherently interpretable models. While the widespread use of surrogate
explainers is a welcome addition to inspect and understand black-box models,
assessing the robustness and reliability of the explanations is key for their
success. Additionally, whilst existing work in the explainability field
proposes various strategies to address this problem, the challenges of working
with data in the wild is often overlooked. For instance, in image
classification, distortions to images can not only affect the predictions
assigned by the model, but also the explanation. Given a clean and a distorted
version of an image, even if the prediction probabilities are similar, the
explanation may still be different. In this paper we propose a methodology to
evaluate the effect of distortions in explanations by embedding perceptual
distances that tailor the neighbourhoods used to training surrogate explainers.
We also show that by operating in this way, we can make the explanations more
robust to distortions. We generate explanations for images in the Imagenet-C
dataset and demonstrate how using a perceptual distances in the surrogate
explainer creates more coherent explanations for the distorted and reference
images.
</p>
<a href="http://arxiv.org/abs/2102.10951" target="_blank">arXiv:2102.10951</a> [<a href="http://arxiv.org/pdf/2102.10951" target="_blank">pdf</a>]

<h2>Adaptive Multi-View ICA: Estimation of noise levels for optimal inference. (arXiv:2102.10964v1 [stat.ML])</h2>
<h3>Hugo Richard (1), Pierre Ablin (2), Aapo Hyv&#xe4;rinen (1 and 3), Alexandre Gramfort (1), Bertrand Thirion (1) ((1) Inria, Universit&#xe9;-Paris Saclay, Saclay, France (2) Ecole normale sup&#xe9;rieure, Paris, France (3) University of Helsinky, Finland)</h3>
<p>We consider a multi-view learning problem known as group independent
component analysis (group ICA), where the goal is to recover shared independent
sources from many views. The statistical modeling of this problem requires to
take noise into account. When the model includes additive noise on the
observations, the likelihood is intractable. By contrast, we propose Adaptive
multiView ICA (AVICA), a noisy ICA model where each view is a linear mixture of
shared independent sources with additive noise on the sources. In this setting,
the likelihood has a tractable expression, which enables either direct
optimization of the log-likelihood using a quasi-Newton method, or generalized
EM. Importantly, we consider that the noise levels are also parameters that are
learned from the data. This enables sources estimation with a closed-form
Minimum Mean Squared Error (MMSE) estimator which weights each view according
to its relative noise level. On synthetic data, AVICA yields better sources
estimates than other group ICA methods thanks to its explicit MMSE estimator.
On real magnetoencephalograpy (MEG) data, we provide evidence that the
decomposition is less sensitive to sampling noise and that the noise variance
estimates are biologically plausible. Lastly, on functional magnetic resonance
imaging (fMRI) data, AVICA exhibits best performance in transferring
information across views.
</p>
<a href="http://arxiv.org/abs/2102.10964" target="_blank">arXiv:2102.10964</a> [<a href="http://arxiv.org/pdf/2102.10964" target="_blank">pdf</a>]

<h2>Markov model with machine learning integration for fraud detection in health insurance. (arXiv:2102.10978v1 [cs.LG])</h2>
<h3>Rohan Yashraj Gupta, Satya Sai Mudigonda, Pallav Kumar Baruah, Phani Krishna Kandala</h3>
<p>Fraud has led to a huge addition of expenses in health insurance sector in
India. The work is aimed to provide methods applied to health insurance fraud
detection. The work presents two approaches - a markov model and an improved
markov model using gradient boosting method in health insurance claims. The
dataset 382,587 claims of which 38,082 claims are fraudulent. The markov based
model gave the accuracy of 94.07% with F1-score at 0.6683. However, the
improved markov model performed much better in comparison with the accuracy of
97.10% and F1-score of 0.8546. It was observed that the improved markov model
gave much lower false positives compared to markov model.
</p>
<a href="http://arxiv.org/abs/2102.10978" target="_blank">arXiv:2102.10978</a> [<a href="http://arxiv.org/pdf/2102.10978" target="_blank">pdf</a>]

<h2>Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks. (arXiv:2102.11010v1 [cs.LG])</h2>
<h3>Ginevra Carbone, Guido Sanguinetti, Luca Bortolussi</h3>
<p>We consider the problem of the stability of saliency-based explanations of
Neural Network predictions under adversarial attacks in a classification task.
We empirically show that, for deterministic Neural Networks, saliency
interpretations are remarkably brittle even when the attacks fail, i.e. for
attacks that do not change the classification label. By leveraging recent
results, we provide a theoretical explanation of this result in terms of the
geometry of adversarial attacks. Based on these theoretical considerations, we
suggest and demonstrate empirically that saliency explanations provided by
Bayesian Neural Networks are considerably more stable under adversarial
perturbations. Our results not only confirm that Bayesian Neural Networks are
more robust to adversarial attacks, but also demonstrate that Bayesian methods
have the potential to provide more stable and interpretable assessments of
Neural Network predictions.
</p>
<a href="http://arxiv.org/abs/2102.11010" target="_blank">arXiv:2102.11010</a> [<a href="http://arxiv.org/pdf/2102.11010" target="_blank">pdf</a>]

<h2>Online Learning via Offline Greedy Algorithms: Applications in Market Design and Optimization. (arXiv:2102.11050v1 [cs.LG])</h2>
<h3>Rad Niazadeh (1), Negin Golrezaei (2), Joshua Wang (3), Fransisca Susan (2), Ashwinkumar Badanidiyuru (3) ((1) Chicago Booth School of Business, Operations Management, (2) MIT Sloan School of Management, Operations Management, (3) Google Research Mountain View)</h3>
<p>Motivated by online decision-making in time-varying combinatorial
environments, we study the problem of transforming offline algorithms to their
online counterparts. We focus on offline combinatorial problems that are
amenable to a constant factor approximation using a greedy algorithm that is
robust to local errors. For such problems, we provide a general framework that
efficiently transforms offline robust greedy algorithms to online ones using
Blackwell approachability. We show that the resulting online algorithms have
$O(\sqrt{T})$ (approximate) regret under the full information setting. We
further introduce a bandit extension of Blackwell approachability that we call
Bandit Blackwell approachability. We leverage this notion to transform greedy
robust offline algorithms into a $O(T^{2/3})$ (approximate) regret in the
bandit setting. Demonstrating the flexibility of our framework, we apply our
offline-to-online transformation to several problems at the intersection of
revenue management, market design, and online optimization, including product
ranking optimization in online platforms, reserve price optimization in
auctions, and submodular maximization. We show that our transformation, when
applied to these applications, leads to new regret bounds or improves the
current known bounds.
</p>
<a href="http://arxiv.org/abs/2102.11050" target="_blank">arXiv:2102.11050</a> [<a href="http://arxiv.org/pdf/2102.11050" target="_blank">pdf</a>]

<h2>On the Effects of Quantisation on Model Uncertainty in Bayesian Neural Networks. (arXiv:2102.11062v1 [cs.LG])</h2>
<h3>Martin Ferianc, Partha Maji, Matthew Mattina, Miguel Rodrigues</h3>
<p>Bayesian neural networks (BNNs) are making significant progress in many
research areas where decision making needs to be accompanied by uncertainty
estimation. Being able to quantify uncertainty while making decisions is
essential for understanding when the model is over-/under-confident, and hence
BNNs are attracting interest in safety-critical applications, such as
autonomous driving, healthcare and robotics. Nevertheless, BNNs have not been
as widely used in industrial practice, mainly because of their increased memory
and compute costs. In this work, we investigate quantisation of BNNs by
compressing 32-bit floating-point weights and activations to their integer
counterparts, that has already been successful in reducing the compute demand
in standard pointwise neural networks. We study three types of quantised BNNs,
we evaluate them under a wide range of different settings, and we empirically
demonstrate that an uniform quantisation scheme applied to BNNs does not
substantially decrease their quality of uncertainty estimation.
</p>
<a href="http://arxiv.org/abs/2102.11062" target="_blank">arXiv:2102.11062</a> [<a href="http://arxiv.org/pdf/2102.11062" target="_blank">pdf</a>]

<h2>A PAC-Bayes Analysis of Adversarial Robustness. (arXiv:2102.11069v1 [cs.LG])</h2>
<h3>Guillaume Vidot (IRIT), Paul Viallard (LHC), Amaury Habrard (LHC), Emilie Morvant (LHC)</h3>
<p>We propose the first general PAC-Bayesian generalization bounds for
adversarial robustness, that estimate, at test time, how much a model will be
invariant to imperceptible perturbations in the input. Instead of deriving a
worst-case analysis of the risk of a hypothesis over all the possible
perturbations, we leverage the PAC-Bayesian framework to bound the averaged
risk on the perturbations for majority votes (over the whole class of
hypotheses). Our theoretically founded analysis has the advantage to provide
general bounds (i) independent from the type of perturbations (i.e., the
adversarial attacks), (ii) that are tight thanks to the PAC-Bayesian framework,
(iii) that can be directly minimized during the learning phase to obtain a
robust model on different attacks at test time.
</p>
<a href="http://arxiv.org/abs/2102.11069" target="_blank">arXiv:2102.11069</a> [<a href="http://arxiv.org/pdf/2102.11069" target="_blank">pdf</a>]

<h2>Debiased Kernel Methods. (arXiv:2102.11076v1 [stat.ML])</h2>
<h3>Rahul Singh</h3>
<p>I propose a practical procedure based on bias correction and sample splitting
to calculate confidence intervals for functionals of generic kernel methods,
i.e. nonparametric estimators learned in a reproducing kernel Hilbert space
(RKHS). For example, an analyst may desire confidence intervals for functionals
of kernel ridge regression or kernel instrumental variable regression. The
framework encompasses (i) evaluations over discrete domains, (ii) treatment
effects of discrete treatments, and (iii) incremental treatment effects of
continuous treatments. For the target quantity, whether it is (i)-(iii), I
prove pointwise root-n consistency, Gaussian approximation, and semiparametric
efficiency by finite sample arguments. I show that the classic assumptions of
RKHS learning theory also imply inference.
</p>
<a href="http://arxiv.org/abs/2102.11076" target="_blank">arXiv:2102.11076</a> [<a href="http://arxiv.org/pdf/2102.11076" target="_blank">pdf</a>]

<h2>Nonparametric adaptive active learning under local smoothness condition. (arXiv:2102.11077v1 [cs.LG])</h2>
<h3>Boris Ndjia Njike, Xavier Siebert</h3>
<p>Active learning is typically used to label data, when the labeling process is
expensive. Several active learning algorithms have been theoretically proved to
perform better than their passive counterpart. However, these algorithms rely
on some assumptions, which themselves contain some specific parameters. This
paper adresses the problem of adaptive active learning in a nonparametric
setting with minimal assumptions. We present a novel algorithm that is valid
under more general assumptions than the previously known algorithms, and that
can moreover adapt to the parameters used in these assumptions. This allows us
to work with a larger class of distributions, thereby avoiding to exclude
important densities like gaussians. Our algorithm achieves a minimax rate of
convergence, and therefore performs almost as well as the best known
non-adaptive algorithms.
</p>
<a href="http://arxiv.org/abs/2102.11077" target="_blank">arXiv:2102.11077</a> [<a href="http://arxiv.org/pdf/2102.11077" target="_blank">pdf</a>]

<h2>Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding. (arXiv:2102.11086v1 [cs.LG])</h2>
<h3>Yangjun Ruan, Karen Ullrich, Daniel Severo, James Townsend, Ashish Khisti, Arnaud Doucet, Alireza Makhzani, Chris J. Maddison</h3>
<p>Latent variable models have been successfully applied in lossless compression
with the bits-back coding algorithm. However, bits-back suffers from an
increase in the bitrate equal to the KL divergence between the approximate
posterior and the true posterior. In this paper, we show how to remove this gap
asymptotically by deriving bits-back coding algorithms from tighter variational
bounds. The key idea is to exploit extended space representations of Monte
Carlo estimators of the marginal likelihood. Naively applied, our schemes would
require more initial bits than the standard bits-back coder, but we show how to
drastically reduce this additional cost with couplings in the latent space.
When parallel architectures can be exploited, our coders can achieve better
rates than bits-back with little additional cost. We demonstrate improved
lossless compression rates in a variety of settings, including entropy coding
for lossy compression.
</p>
<a href="http://arxiv.org/abs/2102.11086" target="_blank">arXiv:2102.11086</a> [<a href="http://arxiv.org/pdf/2102.11086" target="_blank">pdf</a>]

<h2>Federated $f$-Differential Privacy. (arXiv:2102.11158v1 [stat.ML])</h2>
<h3>Qinqing Zheng, Shuxiao Chen, Qi Long, Weijie J. Su</h3>
<p>Federated learning (FL) is a training paradigm where the clients
collaboratively learn models by repeatedly sharing information without
compromising much on the privacy of their local sensitive data. In this paper,
we introduce federated $f$-differential privacy, a new notion specifically
tailored to the federated setting, based on the framework of Gaussian
differential privacy. Federated $f$-differential privacy operates on record
level: it provides the privacy guarantee on each individual record of one
client's data against adversaries. We then propose a generic private federated
learning framework {PriFedSync} that accommodates a large family of
state-of-the-art FL algorithms, which provably achieves federated
$f$-differential privacy. Finally, we empirically demonstrate the trade-off
between privacy guarantee and prediction performance for models trained by
{PriFedSync} in computer vision tasks.
</p>
<a href="http://arxiv.org/abs/2102.11158" target="_blank">arXiv:2102.11158</a> [<a href="http://arxiv.org/pdf/2102.11158" target="_blank">pdf</a>]

<h2>A Theory of Label Propagation for Subpopulation Shift. (arXiv:2102.11203v1 [cs.LG])</h2>
<h3>Tianle Cai, Ruiqi Gao, Jason D. Lee, Qi Lei</h3>
<p>One of the central problems in machine learning is domain adaptation. Unlike
past theoretical work, we consider a new model for subpopulation shift in the
input or representation space. In this work, we propose a provably effective
framework for domain adaptation based on label propagation. In our analysis, we
use a simple but realistic ``expansion'' assumption, proposed in
\citet{wei2021theoretical}. Using a teacher classifier trained on the source
domain, our algorithm not only propagates to the target domain but also
improves upon the teacher. By leveraging existing generalization bounds, we
also obtain end-to-end finite-sample guarantees on the entire algorithm. In
addition, we extend our theoretical framework to a more general setting of
source-to-target transfer based on a third unlabeled dataset, which can be
easily applied in various learning scenarios.
</p>
<a href="http://arxiv.org/abs/2102.11203" target="_blank">arXiv:2102.11203</a> [<a href="http://arxiv.org/pdf/2102.11203" target="_blank">pdf</a>]

<h2>Learning Contact Dynamics using Physically Structured Neural Networks. (arXiv:2102.11206v1 [cs.LG])</h2>
<h3>Andreas Hochlehnert, Alexander Terenin, Steind&#xf3;r S&#xe6;mundsson, Marc Peter Deisenroth</h3>
<p>Learning physically structured representations of dynamical systems that
include contact between different objects is an important problem for
learning-based approaches in robotics. Black-box neural networks can learn to
approximately represent discontinuous dynamics, but they typically require
large quantities of data and often suffer from pathological behaviour when
forecasting for longer time horizons. In this work, we use connections between
deep neural networks and differential equations to design a family of deep
network architectures for representing contact dynamics between objects. We
show that these networks can learn discontinuous contact events in a
data-efficient manner from noisy observations in settings that are
traditionally difficult for black-box approaches and recent physics inspired
neural networks. Our results indicate that an idealised form of touch feedback
-- which is heavily relied upon by biological systems -- is a key component of
making this learning problem tractable. Together with the inductive biases
introduced through the network architectures, our techniques enable accurate
learning of contact dynamics from observations.
</p>
<a href="http://arxiv.org/abs/2102.11206" target="_blank">arXiv:2102.11206</a> [<a href="http://arxiv.org/pdf/2102.11206" target="_blank">pdf</a>]

<h2>Modeling Multi-Destination Trips with Sketch-Based Model. (arXiv:2102.11252v1 [cs.LG])</h2>
<h3>Micha&#x142; Daniluk, Barbara Rychalska, Konrad Go&#x142;uchowski, Jacek D&#x105;browski</h3>
<p>The recently proposed EMDE (Efficient Manifold Density Estimator) model
achieves state of-the-art results in session-based recommendation. In this work
we explore its application to Booking.com Data Challenge competition. The aim
of the challenge is to make the best recommendation for the next destination of
a user trip, based on dataset with millions of real anonymized accommodation
reservations. We achieve 2nd place in this competition. First, we use Cleora -
our graph embedding method - to represent cities as a directed graph and learn
their vector representation. Next, we apply EMDE to predict the next user
destination based on previously visited cities and some features associated
with each trip. We release the source code at:
https://github.com/Synerise/booking-challenge.
</p>
<a href="http://arxiv.org/abs/2102.11252" target="_blank">arXiv:2102.11252</a> [<a href="http://arxiv.org/pdf/2102.11252" target="_blank">pdf</a>]

<h2>Softmax Policy Gradient Methods Can Take Exponential Time to Converge. (arXiv:2102.11270v1 [cs.LG])</h2>
<h3>Gen Li, Yuting Wei, Yuejie Chi, Yuantao Gu, Yuxin Chen</h3>
<p>The softmax policy gradient (PG) method, which performs gradient ascent under
softmax policy parameterization, is arguably one of the de facto
implementations of policy optimization in modern reinforcement learning. For
$\gamma$-discounted infinite-horizon tabular Markov decision processes (MDPs),
remarkable progress has recently been achieved towards establishing global
convergence of softmax PG methods in finding a near-optimal policy. However,
prior results fall short of delineating clear dependencies of convergence rates
on salient parameters such as the cardinality of the state space $\mathcal{S}$
and the effective horizon $\frac{1}{1-\gamma}$, both of which could be
excessively large. In this paper, we deliver a pessimistic message regarding
the iteration complexity of softmax PG methods, despite assuming access to
exact gradient computation. Specifically, we demonstrate that softmax PG
methods can take exponential time -- in terms of $|\mathcal{S}|$ and
$\frac{1}{1-\gamma}$ -- to converge, even in the presence of a benign policy
initialization and an initial state distribution amenable to exploration. This
is accomplished by characterizing the algorithmic dynamics over a
carefully-constructed MDP containing only three actions. Our exponential lower
bound hints at the necessity of carefully adjusting update rules or enforcing
proper regularization in accelerating PG methods.
</p>
<a href="http://arxiv.org/abs/2102.11270" target="_blank">arXiv:2102.11270</a> [<a href="http://arxiv.org/pdf/2102.11270" target="_blank">pdf</a>]

