---
title: Latest Deep Learning Papers
date: 2021-02-23 21:00:01 +0800
featured-img: DL-logo
categories: [Deep_Learning]
tags: [Deep_Learning]
mathjax: Yes
---

<h1>Your arXiv Feed (201 Articles)</h1>
<h2>Ps and Qs: Quantization-aware pruning for efficient low latency neural network inference. (arXiv:2102.11289v1 [cs.LG])</h2>
<h3>Benjamin Hawks, Javier Duarte, Nicholas J. Fraser, Alessandro Pappalardo, Nhan Tran, Yaman Umuroglu</h3>
<p>Efficient machine learning implementations optimized for inference in
hardware have wide-ranging benefits depending on the application from lower
inference latencies to higher data throughputs to more efficient energy
consumption. Two popular techniques for reducing computation in neural networks
are pruning, removing insignificant synapses, and quantization, reducing the
precision of the calculations. In this work, we explore the interplay between
pruning and quantization during the training of neural networks for ultra low
latency applications targeting high energy physics use cases. However,
techniques developed for this study have potential application across many
other domains. We study various configurations of pruning during
quantization-aware training, which we term \emph{quantization-aware pruning}
and the effect of techniques like regularization, batch normalization, and
different pruning schemes on multiple computational or neural efficiency
metrics. We find that quantization-aware pruning yields more computationally
efficient models than either pruning or quantization alone for our task.
Further, quantization-aware pruning typically performs similar to or better in
terms of computational efficiency compared to standard neural architecture
optimization techniques. While the accuracy for the benchmark application may
be similar, the information content of the network can vary significantly based
on the training configuration.
</p>
<a href="http://arxiv.org/abs/2102.11289" target="_blank">arXiv:2102.11289</a> [<a href="http://arxiv.org/pdf/2102.11289" target="_blank">pdf</a>]

<h2>You Only Compress Once: Optimal Data Compression for Estimating Linear Models. (arXiv:2102.11297v1 [cs.LG])</h2>
<h3>Jeffrey Wong, Eskil Forsell, Randall Lewis, Tobias Mao, Matthew Wardrop</h3>
<p>Linear models are used in online decision making, such as in machine
learning, policy algorithms, and experimentation platforms. Many engineering
systems that use linear models achieve computational efficiency through
distributed systems and expert configuration. While there are strengths to this
approach, it is still difficult to have an environment that enables researchers
to interactively iterate and explore data and models, as well as leverage
analytics solutions from the open source community. Consequently, innovation
can be blocked.

Conditionally sufficient statistics is a unified data compression and
estimation strategy that is useful for the model development process, as well
as the engineering deployment process. The strategy estimates linear models
from compressed data without loss on the estimated parameters and their
covariances, even when errors are autocorrelated within clusters of
observations. Additionally, the compression preserves almost all interactions
with the the original data, unlocking better productivity for both researchers
and engineering systems.
</p>
<a href="http://arxiv.org/abs/2102.11297" target="_blank">arXiv:2102.11297</a> [<a href="http://arxiv.org/pdf/2102.11297" target="_blank">pdf</a>]

<h2>Distributed Application of Guideline-Based Decision Support through Mobile Devices: Implementation and Evaluation. (arXiv:2102.11314v1 [cs.AI])</h2>
<h3>Erez Shalom, Ayelet Goldstein, Elior Ariel, Moshe Sheinberger, Valerie Jones, Boris Van Schooten, Yuval Shahar</h3>
<p>Traditionally Guideline(GL)based Decision Support Systems (DSSs) use a
centralized infrastructure to generate recommendations to care providers.
However, managing patients at home is preferable, reducing costs and empowering
patients. We aimed to design, implement, and demonstrate the feasibility of a
new architecture for a distributed DSS that provides patients with
personalized, context-sensitive, evidence based guidance through their mobile
device, and increases the robustness of the distributed application of the GL,
while maintaining access to the patient longitudinal record and to an up to
date evidence based GL repository. We have designed and implemented a novel
projection and callback (PCB) model, in which small portions of the evidence
based GL procedural knowledge, adapted to the patient preferences and to their
current context, are projected from a central DSS server, to a local DSS on the
patient mobile device that applies that knowledge. When appropriate, as defined
by a temporal pattern within the projected plan, the local DSS calls back the
central DSS, requesting further assistance, possibly another projection. Thus,
the GL specification includes two levels: one for the central DSS, one for the
local DSS. We successfully evaluated the PCB model within the MobiGuide EU
project by managing Gestational Diabetes Mellitus patients in Spain, and Atrial
Fibrillation patients in Italy. Significant differences exist between the two
GL representations, suggesting additional ways to characterize GLs. Mean time
between the central and local interactions was quite different for the two GLs:
3.95 days for gestational diabetes, 23.80 days for atrial fibrillation. Most
interactions, 83%, were due to projections to the mDSS. Others were data
notifications, mostly to change context. Robustness was demonstrated through
successful recovery from multiple local DSS crashes.
</p>
<a href="http://arxiv.org/abs/2102.11314" target="_blank">arXiv:2102.11314</a> [<a href="http://arxiv.org/pdf/2102.11314" target="_blank">pdf</a>]

<h2>Lie-Sensor: A Live Emotion Verifier or a Licensor for Chat Applications using Emotional Intelligence. (arXiv:2102.11318v1 [cs.CV])</h2>
<h3>Falguni Patel, NirmalKumar Patel, Santosh Kumar Bharti</h3>
<p>Veracity is an essential key in research and development of innovative
products. Live Emotion analysis and verification nullify deceit made to
complainers on live chat, corroborate messages of both ends in messaging apps
and promote an honest conversation between users. The main concept behind this
emotion artificial intelligent verifier is to license or decline message
accountability by comparing variegated emotions of chat app users recognized
through facial expressions and text prediction. In this paper, a proposed
emotion intelligent live detector acts as an honest arbiter who distributes
facial emotions into labels namely, Happiness, Sadness, Surprise, and Hate.
Further, it separately predicts a label of messages through text
classification. Finally, it compares both labels and declares the message as a
fraud or a bonafide. For emotion detection, we deployed Convolutional Neural
Network (CNN) using a miniXception model and for text prediction, we selected
Support Vector Machine (SVM) natural language processing probability classifier
due to receiving the best accuracy on training dataset after applying Support
Vector Machine (SVM), Random Forest Classifier, Naive Bayes Classifier, and
Logistic regression.
</p>
<a href="http://arxiv.org/abs/2102.11318" target="_blank">arXiv:2102.11318</a> [<a href="http://arxiv.org/pdf/2102.11318" target="_blank">pdf</a>]

<h2>Stratified Experience Replay: Correcting Multiplicity Bias in Off-Policy Reinforcement Learning. (arXiv:2102.11319v1 [cs.LG])</h2>
<h3>Brett Daley, Cameron Hickert, Christopher Amato</h3>
<p>Deep Reinforcement Learning (RL) methods rely on experience replay to
approximate the minibatched supervised learning setting; however, unlike
supervised learning where access to lots of training data is crucial to
generalization, replay-based deep RL appears to struggle in the presence of
extraneous data. Recent works have shown that the performance of Deep Q-Network
(DQN) degrades when its replay memory becomes too large.

This suggests that outdated experiences somehow impact the performance of
deep RL, which should not be the case for off-policy methods like DQN.
Consequently, we re-examine the motivation for sampling uniformly over a replay
memory, and find that it may be flawed when using function approximation. We
show that -- despite conventional wisdom -- sampling from the uniform
distribution does not yield uncorrelated training samples and therefore biases
gradients during training. Our theory prescribes a special non-uniform
distribution to cancel this effect, and we propose a stratified sampling scheme
to efficiently implement it.
</p>
<a href="http://arxiv.org/abs/2102.11319" target="_blank">arXiv:2102.11319</a> [<a href="http://arxiv.org/pdf/2102.11319" target="_blank">pdf</a>]

<h2>GELATO: Geometrically Enriched Latent Model for Offline Reinforcement Learning. (arXiv:2102.11327v1 [cs.LG])</h2>
<h3>Guy Tennenholtz, Nir Baram, Shie Mannor</h3>
<p>Offline reinforcement learning approaches can generally be divided to
proximal and uncertainty-aware methods. In this work, we demonstrate the
benefit of combining the two in a latent variational model. We impose a latent
representation of states and actions and leverage its intrinsic Riemannian
geometry to measure distance of latent samples to the data. Our proposed
metrics measure both the quality of out of distribution samples as well as the
discrepancy of examples in the data. We integrate our metrics in a model-based
offline optimization framework, in which proximity and uncertainty can be
carefully controlled. We illustrate the geodesics on a simple grid-like
environment, depicting its natural inherent topology. Finally, we analyze our
approach and improve upon contemporary offline RL benchmarks.
</p>
<a href="http://arxiv.org/abs/2102.11327" target="_blank">arXiv:2102.11327</a> [<a href="http://arxiv.org/pdf/2102.11327" target="_blank">pdf</a>]

<h2>Action Redundancy in Reinforcement Learning. (arXiv:2102.11329v1 [cs.LG])</h2>
<h3>Nir Baram, Guy Tennenholtz, Shie Mannor</h3>
<p>Maximum Entropy (MaxEnt) reinforcement learning is a powerful learning
paradigm which seeks to maximize return under entropy regularization. However,
action entropy does not necessarily coincide with state entropy, e.g., when
multiple actions produce the same transition. Instead, we propose to maximize
the transition entropy, i.e., the entropy of next states. We show that
transition entropy can be described by two terms; namely, model-dependent
transition entropy and action redundancy. Particularly, we explore the latter
in both deterministic and stochastic settings and develop tractable
approximation methods in a near model-free setup. We construct algorithms to
minimize action redundancy and demonstrate their effectiveness on a synthetic
environment with multiple redundant actions as well as contemporary benchmarks
in Atari and Mujoco. Our results suggest that action redundancy is a
fundamental problem in reinforcement learning.
</p>
<a href="http://arxiv.org/abs/2102.11329" target="_blank">arXiv:2102.11329</a> [<a href="http://arxiv.org/pdf/2102.11329" target="_blank">pdf</a>]

<h2>Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping. (arXiv:2102.11343v1 [cs.LG])</h2>
<h3>Prakhar Kaushik, Alex Gain, Adam Kortylewski, Alan Yuille</h3>
<p>Catastrophic forgetting in neural networks is a significant problem for
continual learning. A majority of the current methods replay previous data
during training, which violates the constraints of an ideal continual learning
system. Additionally, current approaches that deal with forgetting ignore the
problem of catastrophic remembering, i.e. the worsening ability to discriminate
between data from different tasks. In our work, we introduce Relevance Mapping
Networks (RMNs) which are inspired by the Optimal Overlap Hypothesis. The
mappings reflects the relevance of the weights for the task at hand by
assigning large weights to essential parameters. We show that RMNs learn an
optimized representational overlap that overcomes the twin problem of
catastrophic forgetting and remembering. Our approach achieves state-of-the-art
performance across all common continual learning datasets, even significantly
outperforming data replay methods while not violating the constraints for an
ideal continual learning system. Moreover, RMNs retain the ability to detect
data from new tasks in an unsupervised manner, thus proving their resilience
against catastrophic remembering.
</p>
<a href="http://arxiv.org/abs/2102.11343" target="_blank">arXiv:2102.11343</a> [<a href="http://arxiv.org/pdf/2102.11343" target="_blank">pdf</a>]

<h2>HALMA: Humanlike Abstraction Learning Meets Affordance in Rapid Problem Solving. (arXiv:2102.11344v1 [cs.LG])</h2>
<h3>Sirui Xie, Xiaojian Ma, Peiyu Yu, Yixin Zhu, Ying Nian Wu, Song-Chun Zhu</h3>
<p>Humans learn compositional and causal abstraction, \ie, knowledge, in
response to the structure of naturalistic tasks. When presented with a
problem-solving task involving some objects, toddlers would first interact with
these objects to reckon what they are and what can be done with them.
Leveraging these concepts, they could understand the internal structure of this
task, without seeing all of the problem instances. Remarkably, they further
build cognitively executable strategies to \emph{rapidly} solve novel problems.
To empower a learning agent with similar capability, we argue there shall be
three levels of generalization in how an agent represents its knowledge:
perceptual, conceptual, and algorithmic. In this paper, we devise the very
first systematic benchmark that offers joint evaluation covering all three
levels. This benchmark is centered around a novel task domain, HALMA, for
visual concept development and rapid problem-solving. Uniquely, HALMA has a
minimum yet complete concept space, upon which we introduce a novel paradigm to
rigorously diagnose and dissect learning agents' capability in understanding
and generalizing complex and structural concepts. We conduct extensive
experiments on reinforcement learning agents with various inductive biases and
carefully report their proficiency and weakness.
</p>
<a href="http://arxiv.org/abs/2102.11344" target="_blank">arXiv:2102.11344</a> [<a href="http://arxiv.org/pdf/2102.11344" target="_blank">pdf</a>]

<h2>Generative Archimedean Copulas. (arXiv:2102.11351v1 [cs.LG])</h2>
<h3>Yuting Ng, Ali Hasan, Khalil Elkhalil, Vahid Tarokh</h3>
<p>We propose a new generative modeling technique for learning multidimensional
cumulative distribution functions (CDFs) in the form of copulas. Specifically,
we consider certain classes of copulas known as Archimedean and hierarchical
Archimedean copulas, popular for their parsimonious representation and ability
to model different tail dependencies. We consider their representation as
mixture models with Laplace transforms of latent random variables from
generative neural networks. This alternative representation allows for easy
sampling and computational efficiencies especially in high dimensions. We
additionally describe multiple methods for optimizing the model parameters.
Finally, we present empirical results that demonstrate the efficacy of our
proposed method in learning multidimensional CDFs and its computational
efficiency compared to existing methods.
</p>
<a href="http://arxiv.org/abs/2102.11351" target="_blank">arXiv:2102.11351</a> [<a href="http://arxiv.org/pdf/2102.11351" target="_blank">pdf</a>]

<h2>Individualized Context-Aware Tensor Factorization for Online Games Predictions. (arXiv:2102.11352v1 [cs.AI])</h2>
<h3>Julie Jiang, Kristina Lerman, Emilio Ferrara</h3>
<p>Individual behavior and decisions are substantially influenced by their
contexts, such as location, environment, and time. Changes along these
dimensions can be readily observed in Multiplayer Online Battle Arena games
(MOBA), where players face different in-game settings for each match and are
subject to frequent game patches. Existing methods utilizing contextual
information generalize the effect of a context over the entire population, but
contextual information tailored to each individual can be more effective. To
achieve this, we present the Neural Individualized Context-aware Embeddings
(NICE) model for predicting user performance and game outcomes. Our proposed
method identifies individual behavioral differences in different contexts by
learning latent representations of users and contexts through non-negative
tensor factorization. Using a dataset from the MOBA game League of Legends, we
demonstrate that our model substantially improves the prediction of winning
outcome, individual user performance, and user engagement.
</p>
<a href="http://arxiv.org/abs/2102.11352" target="_blank">arXiv:2102.11352</a> [<a href="http://arxiv.org/pdf/2102.11352" target="_blank">pdf</a>]

<h2>Shadow Image Enlargement Distortion Removal. (arXiv:2102.11356v1 [cs.CV])</h2>
<h3>Raid R. Al-Nima, Ali N. Hamoodi, Radhwan Y. Al-Jawadi, Ziad S. Mohammad</h3>
<p>This project aims to adopt preprocessing operations to get less distortions
for shadow image enlargement. The preprocessing operations consists of three
main steps: first enlarge the original shadow image by using any kind of
interpolation methods, second apply average filter to the enlargement image and
finally apply the unsharp filter to the previous averaged image. These
preprocessing operations leads to get an enlargement image very close to the
original enlarge image for the same shadow image. Then comparisons established
between the adopted image and original image by using different types of
interpolation and different alfa values for unsharp filter to reach the best
way which have less different errors between the two images.
</p>
<a href="http://arxiv.org/abs/2102.11356" target="_blank">arXiv:2102.11356</a> [<a href="http://arxiv.org/pdf/2102.11356" target="_blank">pdf</a>]

<h2>The FaCells. An Exploratory Study about LSTM Layers on Face Sketches Classifiers. (arXiv:2102.11361v1 [cs.CV])</h2>
<h3>Xavier Ignacio Gonz&#xe1;lez</h3>
<p>Lines are human mental abstractions. A bunch of lines may form a drawing. A
set of drawings can feed an LSTM network input layer, considering each draw as
a list of lines and a line a list of points. This paper proposes the pointless
motive to classify the gender of celebrities' portraits as an excuse for
exploration in a broad, more artistic sense. Investigation results drove
compelling ideas here discussed. The experiments compared different ways to
represent draws to be input in a network and showed that an absolute format of
coordinates (x, y) was a better performer than a relative one (Dx, Dy) with
respect to prior points, most frequent in the reviewed literature. Experiments
also showed that, due to the recurrent nature of LSTMs, the order of lines
forming a drawing is a relevant factor for input in an LSTM classifier not
studied before. A minimum 'pencil' traveled length criteria for line ordering
proved suitable, possible by reducing it to a TSP particular instance. The best
configuration for gender classification appears with an LSTM layer that returns
the hidden state value for each input point step, followed by a global average
layer along the sequence, before the output dense layer. That result guided the
idea of removing the average in the network pipeline and return a per-point
attribute score just by adjusting tensors dimensions. With this trick, the
model detects an attribute in a drawing and also recognizes the points linked
to it. Moreover, by overlapping filtered lines of portraits, an attribute's
visual essence is depicted. Meet the FaCells.
</p>
<a href="http://arxiv.org/abs/2102.11361" target="_blank">arXiv:2102.11361</a> [<a href="http://arxiv.org/pdf/2102.11361" target="_blank">pdf</a>]

<h2>Sandwich Batch Normalization. (arXiv:2102.11382v1 [cs.CV])</h2>
<h3>Xinyu Gong, Wuyang Chen, Tianlong Chen, Zhangyang Wang</h3>
<p>We present Sandwich Batch Normalization (SaBN), an embarrassingly easy
improvement of Batch Normalization (BN) with only a few lines of code changes.
SaBN is motivated by addressing the inherent feature distribution heterogeneity
that one can be identified in many tasks, which can arise from data
heterogeneity (multiple input domains) or model heterogeneity (dynamic
architectures, model conditioning, etc.). Our SaBN factorizes the BN affine
layer into one shared sandwich affine layer, cascaded by several parallel
independent affine layers. Concrete analysis reveals that, during optimization,
SaBN promotes balanced gradient norms while still preserving diverse gradient
directions: a property that many application tasks seem to favor. We
demonstrate the prevailing effectiveness of SaBN as a drop-in replacement in
four tasks: $\textbf{conditional image generation}$, $\textbf{neural
architecture search}$ (NAS), $\textbf{adversarial training}$, and
$\textbf{arbitrary style transfer}$. Leveraging SaBN immediately achieves
better Inception Score and FID on CIFAR-10 and ImageNet conditional image
generation with three state-of-the-art GANs; boosts the performance of a
state-of-the-art weight-sharing NAS algorithm significantly on NAS-Bench-201;
substantially improves the robust and standard accuracies for adversarial
defense; and produces superior arbitrary stylized results. We also provide
visualizations and analysis to help understand why SaBN works. Codes are
available at https://github.com/VITA-Group/Sandwich-Batch-Normalization.
</p>
<a href="http://arxiv.org/abs/2102.11382" target="_blank">arXiv:2102.11382</a> [<a href="http://arxiv.org/pdf/2102.11382" target="_blank">pdf</a>]

<h2>Lightweight Combinational Machine Learning Algorithm for Sorting Canine Torso Radiographs. (arXiv:2102.11385v1 [cs.CV])</h2>
<h3>Masuda Akter Tonima, Fatemeh Esfahani, Austin Dehart, Youmin Zhang</h3>
<p>The veterinary field lacks automation in contrast to the tremendous
technological advances made in the human medical field. Implementation of
machine learning technology can shorten any step of the automation process.
This paper explores these core concepts and starts with automation in sorting
radiographs for canines by view and anatomy. This is achieved by developing a
new lightweight algorithm inspired by AlexNet, Inception, and SqueezeNet. The
proposed module proves to be lighter than SqueezeNet while maintaining accuracy
higher than that of AlexNet, ResNet, DenseNet, and SqueezeNet.
</p>
<a href="http://arxiv.org/abs/2102.11385" target="_blank">arXiv:2102.11385</a> [<a href="http://arxiv.org/pdf/2102.11385" target="_blank">pdf</a>]

<h2>MagNet: A Magnetic Neural Network for Directed Graphs. (arXiv:2102.11391v1 [cs.LG])</h2>
<h3>Xitong Zhang, Nathan Brugnone, Michael Perlmutter, Matthew Hirn</h3>
<p>The prevalence of graph-based data has spurred the rapid development of graph
neural networks (GNNs) and related machine learning algorithms. Yet, despite
the many data sets naturally modeled as directed graphs, including citation,
website, and traffic networks, the vast majority of this research focuses on
undirected graphs. In this paper, we propose MagNet, a spectral GNN for
directed graphs based on a complex Hermitian matrix known as the magnetic
Laplacian. This matrix encodes undirected geometric structure in the magnitude
of its entries and directional information in the phase of its entries. A
"charge" parameter attunes spectral information to variation among directed
cycles. We show that MagNet's performance exceeds other spectral GNNs on
directed graph node classification and link prediction tasks for a variety of
datasets and exceeds commonly used spatial GNNs on a majority of such. The
underlying principles of MagNet are such that it can be adapted to other
spectral GNN architectures.
</p>
<a href="http://arxiv.org/abs/2102.11391" target="_blank">arXiv:2102.11391</a> [<a href="http://arxiv.org/pdf/2102.11391" target="_blank">pdf</a>]

<h2>No-Reference Quality Assessment for 360-degree Images by Analysis of Multi-frequency Information and Local-global Naturalness. (arXiv:2102.11393v1 [cs.CV])</h2>
<h3>Wei Zhou, Jiahua Xu, Qiuping Jiang, Zhibo Chen</h3>
<p>360-degree/omnidirectional images (OIs) have achieved remarkable attentions
due to the increasing applications of virtual reality (VR). Compared to
conventional 2D images, OIs can provide more immersive experience to consumers,
benefitting from the higher resolution and plentiful field of views (FoVs).
Moreover, observing OIs is usually in the head mounted display (HMD) without
references. Therefore, an efficient blind quality assessment method, which is
specifically designed for 360-degree images, is urgently desired. In this
paper, motivated by the characteristics of the human visual system (HVS) and
the viewing process of VR visual contents, we propose a novel and effective
no-reference omnidirectional image quality assessment (NR OIQA) algorithm by
Multi-Frequency Information and Local-Global Naturalness (MFILGN).
Specifically, inspired by the frequency-dependent property of visual cortex, we
first decompose the projected equirectangular projection (ERP) maps into
wavelet subbands. Then, the entropy intensities of low and high frequency
subbands are exploited to measure the multi-frequency information of OIs.
Besides, except for considering the global naturalness of ERP maps, owing to
the browsed FoVs, we extract the natural scene statistics features from each
viewport image as the measure of local naturalness. With the proposed
multi-frequency information measurement and local-global naturalness
measurement, we utilize support vector regression as the final image quality
regressor to train the quality evaluation model from visual quality-related
features to human ratings. To our knowledge, the proposed model is the first
no-reference quality assessment method for 360-degreee images that combines
multi-frequency information and image naturalness. Experimental results on two
publicly available OIQA databases demonstrate that our proposed MFILGN
outperforms state-of-the-art approaches.
</p>
<a href="http://arxiv.org/abs/2102.11393" target="_blank">arXiv:2102.11393</a> [<a href="http://arxiv.org/pdf/2102.11393" target="_blank">pdf</a>]

<h2>Explore the Context: Optimal Data Collection for Context-Conditional Dynamics Models. (arXiv:2102.11394v1 [cs.LG])</h2>
<h3>Jan Achterhold, Joerg Stueckler</h3>
<p>In this paper, we learn dynamics models for parametrized families of
dynamical systems with varying properties. The dynamics models are formulated
as stochastic processes conditioned on a latent context variable which is
inferred from observed transitions of the respective system. The probabilistic
formulation allows us to compute an action sequence which, for a limited number
of environment interactions, optimally explores the given system within the
parametrized family. This is achieved by steering the system through
transitions being most informative for the context variable. We demonstrate the
effectiveness of our method for exploration on a non-linear toy-problem and two
well-known reinforcement learning environments.
</p>
<a href="http://arxiv.org/abs/2102.11394" target="_blank">arXiv:2102.11394</a> [<a href="http://arxiv.org/pdf/2102.11394" target="_blank">pdf</a>]

<h2>Procam Calibration from a Single Pose of a Planar Target. (arXiv:2102.11395v1 [cs.CV])</h2>
<h3>Ghani O. Lawal, Michael Greenspan</h3>
<p>A novel user friendly method is proposed for calibrating a procam system from
a single pose of a planar chessboard target. The user simply needs to orient
the chessboard in a single appropriate pose. A sequence of Gray Code patterns
are projected onto the chessboard, which allows correspondences between the
camera, projector and the chessboard to be automatically extracted. These
correspondences are fed as input to a nonlinear optimization method that models
the projector of the principle points onto the chessboard, and accurately
calculates the intrinsic and extrinsic parameters of both the camera and the
projector, as well as the camera's distortion coefficients. The method is
experimentally validated on the procam system, which is shown to be comparable
in accuracy with existing multi-pose approaches. The impact of the orientation
of the chessboard with respect to the procam imaging places is also explored
through extensive simulation.
</p>
<a href="http://arxiv.org/abs/2102.11395" target="_blank">arXiv:2102.11395</a> [<a href="http://arxiv.org/pdf/2102.11395" target="_blank">pdf</a>]

<h2>Learning Low-dimensional Manifolds for Scoring of Tissue Microarray Images. (arXiv:2102.11396v1 [cs.CV])</h2>
<h3>Donghui Yan, Jian Zou, Zhenpeng Li</h3>
<p>Tissue microarray (TMA) images have emerged as an important high-throughput
tool for cancer study and the validation of biomarkers. Efforts have been
dedicated to further improve the accuracy of TACOMA, a cutting-edge automatic
scoring algorithm for TMA images. One major advance is due to deepTacoma, an
algorithm that incorporates suitable deep representations of a group nature.
Inspired by the recent advance in semi-supervised learning and deep learning,
we propose mfTacoma to learn alternative deep representations in the context of
TMA image scoring. In particular, mfTacoma learns the low-dimensional
manifolds, a common latent structure in high dimensional data. Deep
representation learning and manifold learning typically requires large data. By
encoding deep representation of the manifolds as regularizing features,
mfTacoma effectively leverages the manifold information that is potentially
crude due to small data. Our experiments show that deep features by manifolds
outperforms two alternatives -- deep features by linear manifolds with
principal component analysis or by leveraging the group property.
</p>
<a href="http://arxiv.org/abs/2102.11396" target="_blank">arXiv:2102.11396</a> [<a href="http://arxiv.org/pdf/2102.11396" target="_blank">pdf</a>]

<h2>Home and destination attachment: study of cultural integration on Twitter. (arXiv:2102.11398v1 [cs.LG])</h2>
<h3>Jisu Kim, Alina S&#xee;rbu, Giulio Rossetti, Fosca Giannotti, Hillel Rapoport</h3>
<p>The cultural integration of immigrants conditions their overall
socio-economic integration as well as natives' attitudes towards globalisation
in general and immigration in particular. At the same time, excessive
integration -- or acculturation -- can be detrimental in that it implies
forfeiting one's ties to the home country and eventually translates into a loss
of diversity (from the viewpoint of host countries) and of global connections
(from the viewpoint of both host and home countries). Cultural integration can
be described using two dimensions: the preservation of links to the home
country and culture, which we call home attachment, and the creation of new
links together with the adoption of cultural traits from the new residence
country, which we call destination attachment. In this paper we introduce a
means to quantify these two aspects based on Twitter data. We build home and
destination attachment indexes and analyse their possible determinants (e.g.,
language proximity, distance between countries), also in relation to Hofstede's
cultural dimension scores. The results stress the importance of host language
proficiency to explain destination attachment, but also the link between
language and home attachment. In particular, the common language between home
and destination countries corresponds to increased home attachment, as does low
proficiency in the host language. Common geographical borders also seem to
increase both home and destination attachment. Regarding cultural dimensions,
larger differences among home and destination country in terms of
Individualism, Masculinity and Uncertainty appear to correspond to larger
destination attachment and lower home attachment.
</p>
<a href="http://arxiv.org/abs/2102.11398" target="_blank">arXiv:2102.11398</a> [<a href="http://arxiv.org/pdf/2102.11398" target="_blank">pdf</a>]

<h2>Improving Deterministic Uncertainty Estimation in Deep Learning for Classification and Regression. (arXiv:2102.11409v1 [cs.LG])</h2>
<h3>Joost van Amersfoort, Lewis Smith, Andrew Jesson, Oscar Key, Yarin Gal</h3>
<p>We propose a new model that estimates uncertainty in a single forward pass
and works on both classification and regression problems. Our approach combines
a bi-Lipschitz feature extractor with an inducing point approximate Gaussian
process, offering robust and principled uncertainty estimation. This can be
seen as a refinement of Deep Kernel Learning (DKL), with our changes allowing
DKL to match softmax neural networks accuracy. Our method overcomes the
limitations of previous work addressing deterministic uncertainty
quantification, such as the dependence of uncertainty on ad hoc
hyper-parameters. Our method matches SotA accuracy, 96.2% on CIFAR-10, while
maintaining the speed of softmax models, and provides uncertainty estimates
that outperform previous single forward pass uncertainty models. Finally, we
demonstrate our method on a recently introduced benchmark for uncertainty in
regression: treatment deferral in causal models for personalized medicine.
</p>
<a href="http://arxiv.org/abs/2102.11409" target="_blank">arXiv:2102.11409</a> [<a href="http://arxiv.org/pdf/2102.11409" target="_blank">pdf</a>]

<h2>Parallelizing Legendre Memory Unit Training. (arXiv:2102.11417v1 [cs.LG])</h2>
<h3>Narsimha Chilkuri, Chris Eliasmith</h3>
<p>Recently, a new recurrent neural network (RNN) named the Legendre Memory Unit
(LMU) was proposed and shown to achieve state-of-the-art performance on several
benchmark datasets. Here we leverage the linear time-invariant (LTI) memory
component of the LMU to construct a simplified variant that can be parallelized
during training (and yet executed as an RNN during inference), thus overcoming
a well known limitation of training RNNs on GPUs. We show that this
reformulation that aids parallelizing, which can be applied generally to any
deep network whose recurrent components are linear, makes training up to 200
times faster. Second, to validate its utility, we compare its performance
against the original LMU and a variety of published LSTM and transformer
networks on seven benchmarks, ranging from psMNIST to sentiment analysis to
machine translation. We demonstrate that our models exhibit superior
performance on all datasets, often using fewer parameters. For instance, our
LMU sets a new state-of-the-art result on psMNIST, and uses half the parameters
while outperforming DistilBERT and LSTM models on IMDB sentiment analysis.
</p>
<a href="http://arxiv.org/abs/2102.11417" target="_blank">arXiv:2102.11417</a> [<a href="http://arxiv.org/pdf/2102.11417" target="_blank">pdf</a>]

<h2>Smart Navigation for an In-pipe Robot Through Multi-phase Motion Control and Particle Filtering Method. (arXiv:2102.11434v1 [cs.RO])</h2>
<h3>Saber Kazeminasab, Vahid Janfaza, Moein Razavi, M. Katherine Banks</h3>
<p>In-pipe robots are promising solutions for condition assessment, leak
detection, water quality monitoring in a variety of other tasks in pipeline
networks. Smart navigation is an extremely challenging task for these robots as
a result of highly uncertain and disturbing environment for operation. Wireless
communication to control these robots during operation is not feasible if the
pipe material is metal since the radio signals are destroyed in the pipe
environment, and hence, this challenge is still unsolved. In this paper, we
introduce a method for smart navigation for our previously designed in-pipe
robot [1] based on particle filtering and a two-phase motion controller. The
robot is given the map of the operation path with a novel approach and the
particle filtering determines the straight and non-straight configurations of
the pipeline. In the straight paths, the robot follows a linear quadratic
regulator (LQR) and proportional-integral-derivative (PID) based controller
that stabilizes the robot and tracks a desired velocity. In non-straight paths,
the robot follows the trajectory that a motion trajectory generator block plans
for the robot. The proposed method is a promising solution for smart navigation
without the need for wireless communication and capable of inspecting long
distances in water distribution systems.
</p>
<a href="http://arxiv.org/abs/2102.11434" target="_blank">arXiv:2102.11434</a> [<a href="http://arxiv.org/pdf/2102.11434" target="_blank">pdf</a>]

<h2>Model-Based Domain Generalization. (arXiv:2102.11436v1 [stat.ML])</h2>
<h3>Alexander Robey, George J. Pappas, Hamed Hassani</h3>
<p>We consider the problem of domain generalization, in which a predictor is
trained on data drawn from a family of related training domains and tested on a
distinct and unseen test domain. While a variety of approaches have been
proposed for this setting, it was recently shown that no existing algorithm can
consistently outperform empirical risk minimization (ERM) over the training
domains. To this end, in this paper we propose a novel approach for the domain
generalization problem called Model-Based Domain Generalization. In our
approach, we first use unlabeled data from the training domains to learn
multi-modal domain transformation models that map data from one training domain
to any other domain. Next, we propose a constrained optimization-based
formulation for domain generalization which enforces that a trained predictor
be invariant to distributional shifts under the underlying domain
transformation model. Finally, we propose a novel algorithmic framework for
efficiently solving this constrained optimization problem. In our experiments,
we show that this approach outperforms both ERM and domain generalization
algorithms on numerous well-known, challenging datasets, including WILDS, PACS,
and ImageNet. In particular, our algorithms beat the current state-of-the-art
methods on the very-recently-proposed WILDS benchmark by up to 20 percentage
points.
</p>
<a href="http://arxiv.org/abs/2102.11436" target="_blank">arXiv:2102.11436</a> [<a href="http://arxiv.org/pdf/2102.11436" target="_blank">pdf</a>]

<h2>Assigning Confidence to Molecular Property Prediction. (arXiv:2102.11439v1 [cs.LG])</h2>
<h3>AkshatKumar Nigam, Robert Pollice, Matthew F. D. Hurley, Riley J. Hickman, Matteo Aldeghi, Naruki Yoshikawa, Seyone Chithrananda, Vincent A. Voelz, Al&#xe1;n Aspuru-Guzik</h3>
<p>Introduction: Computational modeling has rapidly advanced over the last
decades, especially to predict molecular properties for chemistry, material
science and drug design. Recently, machine learning techniques have emerged as
a powerful and cost-effective strategy to learn from existing datasets and
perform predictions on unseen molecules. Accordingly, the explosive rise of
data-driven techniques raises an important question: What confidence can be
assigned to molecular property predictions and what techniques can be used for
that purpose?

Areas covered: In this work, we discuss popular strategies for predicting
molecular properties relevant to drug design, their corresponding uncertainty
sources and methods to quantify uncertainty and confidence. First, our
considerations for assessing confidence begin with dataset bias and size,
data-driven property prediction and feature design. Next, we discuss property
simulation via molecular docking, and free-energy simulations of binding
affinity in detail. Lastly, we investigate how these uncertainties propagate to
generative models, as they are usually coupled with property predictors.

Expert opinion: Computational techniques are paramount to reduce the
prohibitive cost and timing of brute-force experimentation when exploring the
enormous chemical space. We believe that assessing uncertainty in property
prediction models is essential whenever closed-loop drug design campaigns
relying on high-throughput virtual screening are deployed. Accordingly,
considering sources of uncertainty leads to better-informed experimental
validations, more reliable predictions and to more realistic expectations of
the entire workflow. Overall, this increases confidence in the predictions and
designs and, ultimately, accelerates drug design.
</p>
<a href="http://arxiv.org/abs/2102.11439" target="_blank">arXiv:2102.11439</a> [<a href="http://arxiv.org/pdf/2102.11439" target="_blank">pdf</a>]

<h2>Data Engineering for Everyone. (arXiv:2102.11447v1 [cs.LG])</h2>
<h3>Vijay Janapa Reddi, Greg Diamos, Pete Warden, Peter Mattson, David Kanter</h3>
<p>Data engineering is one of the fastest-growing fields within machine learning
(ML). As ML becomes more common, the appetite for data grows more ravenous. But
ML requires more data than individual teams of data engineers can readily
produce, which presents a severe challenge to ML deployment at scale. Much like
the software-engineering revolution, where mass adoption of open-source
software replaced the closed, in-house development model for infrastructure
code, there is a growing need to enable rapid development and open contribution
to massive machine learning data sets. This article shows that open-source data
sets are the rocket fuel for research and innovation at even some of the
largest AI organizations. Our analysis of nearly 2000 research publications
from Facebook, Google and Microsoft over the past five years shows the
widespread use and adoption of open data sets. Open data sets that are easily
accessible to the public are vital to accelerating ML innovation for everyone.
But such open resources are scarce in the wild. So, what if we are able to
accelerate data-set creation via automatic data set generation tools?
</p>
<a href="http://arxiv.org/abs/2102.11447" target="_blank">arXiv:2102.11447</a> [<a href="http://arxiv.org/pdf/2102.11447" target="_blank">pdf</a>]

<h2>MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch Optimization for Deployment Constrained Reinforcement Learning. (arXiv:2102.11448v1 [cs.LG])</h2>
<h3>DiJia Su, Jason D. Lee, John M. Mulvey, H. Vincent Poor</h3>
<p>In many contemporary applications such as healthcare, finance, robotics, and
recommendation systems, continuous deployment of new policies for data
collection and online learning is either cost ineffective or impractical. We
consider a setting that lies between pure offline reinforcement learning (RL)
and pure online RL called deployment constrained RL in which the number of
policy deployments for data sampling is limited. To solve this challenging
task, we propose a new algorithmic learning framework called Model-based
Uncertainty regularized and Sample Efficient Batch Optimization (MUSBO). Our
framework discovers novel and high quality samples for each deployment to
enable efficient data collection. During each offline training session, we
bootstrap the policy update by quantifying the amount of uncertainty within our
collected data. In the high support region (low uncertainty), we encourage our
policy by taking an aggressive update. In the low support region (high
uncertainty) when the policy bootstraps into the out-of-distribution region, we
downweight it by our estimated uncertainty quantification. Experimental results
show that MUSBO achieves state-of-the-art performance in the deployment
constrained RL setting.
</p>
<a href="http://arxiv.org/abs/2102.11448" target="_blank">arXiv:2102.11448</a> [<a href="http://arxiv.org/pdf/2102.11448" target="_blank">pdf</a>]

<h2>Representation Disentanglement for Multi-modal MR Analysis. (arXiv:2102.11456v1 [cs.CV])</h2>
<h3>Jiahong Ouyang, Ehsan Adeli, Kilian M Pohl, Qingyu Zhao, Greg Zaharchuk</h3>
<p>Multi-modal MR images are widely used in neuroimaging applications to provide
complementary information about the brain structures. Recent works have
suggested that multi-modal deep learning analysis can benefit from explicitly
disentangling anatomical (shape) and modality (appearance) representations from
the images. In this work, we challenge existing strategies by showing that they
do not naturally lead to representation disentanglement both in theory and in
practice. To address this issue, we propose a margin loss that regularizes the
similarity relationships of the representations across subjects and modalities.
To enable a robust training, we further introduce a modified conditional
convolution to design a single model for encoding images of all modalities.
Lastly, we propose a fusion function to combine the disentangled anatomical
representations as a set of modality-invariant features for downstream tasks.
We evaluate the proposed method on three multi-modal neuroimaging datasets.
Experiments show that our proposed method can achieve superior disentangled
representations compared to existing disentanglement strategies. Results also
indicate that the fused anatomical representation has great potential in the
downstream task of zero-dose PET reconstruction and brain tumor segmentation.
</p>
<a href="http://arxiv.org/abs/2102.11456" target="_blank">arXiv:2102.11456</a> [<a href="http://arxiv.org/pdf/2102.11456" target="_blank">pdf</a>]

<h2>An Interaction-aware Evaluation Method for Highly Automated Vehicles. (arXiv:2102.11462v1 [cs.RO])</h2>
<h3>Xinpeng Wang, Songan Zhang, Kuan-Hui Lee, Huei Peng</h3>
<p>It is important to build a rigorous verification and validation (V&amp;V) process
to evaluate the safety of highly automated vehicles (HAVs) before their wide
deployment on public roads. In this paper, we propose an interaction-aware
framework for HAV safety evaluation which is suitable for some
highly-interactive driving scenarios including highway merging, roundabout
entering, etc. Contrary to existing approaches where the primary other vehicle
(POV) takes predetermined maneuvers, we model the POV as a game-theoretic
agent. To capture a wide variety of interactions between the POV and the
vehicle under test (VUT), we characterize the interactive behavior using
level-k game theory and social value orientation and train a diverse set of
POVs using reinforcement learning. Moreover, we propose an adaptive test case
sampling scheme based on the Gaussian process regression technique to generate
customized and diverse challenging cases. The highway merging is used as the
example scenario. We found the proposed method is able to capture a wide range
of POV behaviors and achieve better coverage of the failure modes of the VUT
compared with other evaluation approaches.
</p>
<a href="http://arxiv.org/abs/2102.11462" target="_blank">arXiv:2102.11462</a> [<a href="http://arxiv.org/pdf/2102.11462" target="_blank">pdf</a>]

<h2>FaceController: Controllable Attribute Editing for Face in the Wild. (arXiv:2102.11464v1 [cs.CV])</h2>
<h3>Zhiliang Xu, Xiyu Yu, Zhibin Hong, Zhen Zhu, Junyu Han, Jingtuo Liu, Errui Ding, Xiang Bai</h3>
<p>Face attribute editing aims to generate faces with one or multiple desired
face attributes manipulated while other details are preserved. Unlike prior
works such as GAN inversion, which has an expensive reverse mapping process, we
propose a simple feed-forward network to generate high-fidelity manipulated
faces. By simply employing some existing and easy-obtainable prior information,
our method can control, transfer, and edit diverse attributes of faces in the
wild. The proposed method can consequently be applied to various applications
such as face swapping, face relighting, and makeup transfer. In our method, we
decouple identity, expression, pose, and illumination using 3D priors; separate
texture and colors by using region-wise style codes. All the information is
embedded into adversarial learning by our identity-style normalization module.
Disentanglement losses are proposed to enhance the generator to extract
information independently from each attribute. Comprehensive quantitative and
qualitative evaluations have been conducted. In a single framework, our method
achieves the best or competitive scores on a variety of face applications.
</p>
<a href="http://arxiv.org/abs/2102.11464" target="_blank">arXiv:2102.11464</a> [<a href="http://arxiv.org/pdf/2102.11464" target="_blank">pdf</a>]

<h2>Mathematical Properties of Generalized Shape Expansion-Based Motion Planning Algorithms. (arXiv:2102.11478v1 [cs.RO])</h2>
<h3>Adhvaith Ramkumar, Vrushabh Zinage, Satadal Ghosh</h3>
<p>Motion planning is an essential aspect of autonomous systems and robotics and
is an active area of research. A recently-proposed sampling-based motion
planning algorithm, termed 'Generalized Shape Expansion' (GSE), has been shown
to possess significant improvement in computational time over several existing
well-established algorithms. The GSE has also been shown to be
probabilistically complete. However, asymptotic optimality of the GSE is yet to
be studied. To this end, in this paper we show that the GSE algorithm is not
asymptotically optimal by studying its behaviour for the promenade problem. In
order to obtain a probabilistically complete and asymptotically optimal
generalized shape-based algorithm, a modified version of the GSE, namely 'GSE*'
algorithm, is subsequently presented. The forementioned desired mathematical
properties of the GSE* algorithm are justified by its detailed analysis.
Numerical simulations are found to be in line with the theoretical results on
the GSE* algorithm.
</p>
<a href="http://arxiv.org/abs/2102.11478" target="_blank">arXiv:2102.11478</a> [<a href="http://arxiv.org/pdf/2102.11478" target="_blank">pdf</a>]

<h2>Dynamic Labeling for Unlabeled Graph Neural Networks. (arXiv:2102.11485v1 [cs.LG])</h2>
<h3>Zeyu Sun, Wenjie Zhang, Lili Mou, Qihao Zhu, Yingfei Xiong, Lu Zhang</h3>
<p>Existing graph neural networks (GNNs) largely rely on node embeddings, which
represent a node as a vector by its identity, type, or content. However, graphs
with unlabeled nodes widely exist in real-world applications (e.g., anonymized
social networks). Previous GNNs either assign random labels to nodes (which
introduces artefacts to the GNN) or assign one embedding to all nodes (which
fails to distinguish one node from another). In this paper, we analyze the
limitation of existing approaches in two types of classification tasks, graph
classification and node classification. Inspired by our analysis, we propose
two techniques, Dynamic Labeling and Preferential Dynamic Labeling, that
satisfy desired properties statistically or asymptotically for each type of the
task. Experimental results show that we achieve high performance in various
graph-related tasks.
</p>
<a href="http://arxiv.org/abs/2102.11485" target="_blank">arXiv:2102.11485</a> [<a href="http://arxiv.org/pdf/2102.11485" target="_blank">pdf</a>]

<h2>When is Early Classification of Time Series Meaningful?. (arXiv:2102.11487v1 [cs.LG])</h2>
<h3>Renjie Wu, Audrey Der, Eamonn J. Keogh</h3>
<p>Since its introduction two decades ago, there has been increasing interest in
the problem of early classification of time series. This problem generalizes
classic time series classification to ask if we can classify a time series
subsequence with sufficient accuracy and confidence after seeing only some
prefix of a target pattern. The idea is that the earlier classification would
allow us to take immediate action, in a domain in which some practical
interventions are possible. For example, that intervention might be sounding an
alarm or applying the brakes in an automobile. In this work, we make a
surprising claim. In spite of the fact that there are dozens of papers on early
classification of time series, it is not clear that any of them could ever work
in a real-world setting. The problem is not with the algorithms per se but with
the vague and underspecified problem description. Essentially all algorithms
make implicit and unwarranted assumptions about the problem that will ensure
that they will be plagued by false positives and false negatives even if their
results suggested that they could obtain near-perfect results. We will explain
our findings with novel insights and experiments and offer recommendations to
the community.
</p>
<a href="http://arxiv.org/abs/2102.11487" target="_blank">arXiv:2102.11487</a> [<a href="http://arxiv.org/pdf/2102.11487" target="_blank">pdf</a>]

<h2>DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning. (arXiv:2102.11492v1 [cs.LG])</h2>
<h3>Xianyuan Zhan, Haoran Xu, Yue Zhang, Yusen Huo, Xiangyu Zhu, Honglei Yin, Yu Zheng</h3>
<p>Thermal power generation plays a dominant role in the world's electricity
supply. It consumes large amounts of coal worldwide, and causes serious air
pollution. Optimizing the combustion efficiency of a thermal power generating
unit (TPGU) is a highly challenging and critical task in the energy industry.
We develop a new data-driven AI system, namely DeepThermal, to optimize the
combustion control strategy for TPGUs. At its core, is a new model-based
offline reinforcement learning (RL) framework, called MORE, which leverages
logged historical operational data of a TGPU to solve a highly complex
constrained Markov decision process problem via purely offline training. MORE
aims at simultaneously improving the long-term reward (increase combustion
efficiency and reduce pollutant emission) and controlling operational risks
(safety constraints satisfaction). In DeepThermal, we first learn a data-driven
combustion process simulator from the offline dataset. The RL agent of MORE is
then trained by combining real historical data as well as carefully filtered
and processed simulation data through a novel restrictive exploration scheme.
DeepThermal has been successfully deployed in four large coal-fired thermal
power plants in China. Real-world experiments show that DeepThermal effectively
improves the combustion efficiency of a TPGU. We also report and demonstrate
the superior performance of MORE by comparing with the state-of-the-art
algorithms on the standard offline RL benchmarks. To the best knowledge of the
authors, DeepThermal is the first AI application that has been used to solve
real-world complex mission-critical control tasks using the offline RL
approach.
</p>
<a href="http://arxiv.org/abs/2102.11492" target="_blank">arXiv:2102.11492</a> [<a href="http://arxiv.org/pdf/2102.11492" target="_blank">pdf</a>]

<h2>Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games. (arXiv:2102.11494v1 [cs.LG])</h2>
<h3>Yu Bai, Chi Jin, Huan Wang, Caiming Xiong</h3>
<p>Real world applications such as economics and policy making often involve
solving multi-agent games with two unique features: (1) The agents are
inherently asymmetric and partitioned into leaders and followers; (2) The
agents have different reward functions, thus the game is general-sum. The
majority of existing results in this field focuses on either symmetric solution
concepts (e.g. Nash equilibrium) or zero-sum games. It remains vastly open how
to learn the Stackelberg equilibrium -- an asymmetric analog of the Nash
equilibrium -- in general-sum games efficiently from samples.

This paper initiates the theoretical study of sample-efficient learning of
the Stackelberg equilibrium in two-player turn-based general-sum games. We
identify a fundamental gap between the exact value of the Stackelberg
equilibrium and its estimated version using finite samples, which can not be
closed information-theoretically regardless of the algorithm. We then establish
a positive result on sample-efficient learning of Stackelberg equilibrium with
value optimal up to the gap identified above. We show that our sample
complexity is tight with matching upper and lower bounds. Finally, we extend
our learning results to the setting where the follower plays in a Markov
Decision Process (MDP), and the setting where the leader and the follower act
simultaneously.
</p>
<a href="http://arxiv.org/abs/2102.11494" target="_blank">arXiv:2102.11494</a> [<a href="http://arxiv.org/pdf/2102.11494" target="_blank">pdf</a>]

<h2>Anytime Sampling for Autoregressive Models via Ordered Autoencoding. (arXiv:2102.11495v1 [cs.LG])</h2>
<h3>Yilun Xu, Yang Song, Sahaj Garg, Linyuan Gong, Rui Shu, Aditya Grover, Stefano Ermon</h3>
<p>Autoregressive models are widely used for tasks such as image and audio
generation. The sampling process of these models, however, does not allow
interruptions and cannot adapt to real-time computational resources. This
challenge impedes the deployment of powerful autoregressive models, which
involve a slow sampling process that is sequential in nature and typically
scales linearly with respect to the data dimension. To address this difficulty,
we propose a new family of autoregressive models that enables anytime sampling.
Inspired by Principal Component Analysis, we learn a structured representation
space where dimensions are ordered based on their importance with respect to
reconstruction. Using an autoregressive model in this latent space, we trade
off sample quality for computational efficiency by truncating the generation
process before decoding into the original data space. Experimentally, we
demonstrate in several image and audio generation tasks that sample quality
degrades gracefully as we reduce the computational budget for sampling. The
approach suffers almost no loss in sample quality (measured by FID) using only
60\% to 80\% of all latent dimensions for image data. Code is available at
https://github.com/Newbeeer/Anytime-Auto-Regressive-Model .
</p>
<a href="http://arxiv.org/abs/2102.11495" target="_blank">arXiv:2102.11495</a> [<a href="http://arxiv.org/pdf/2102.11495" target="_blank">pdf</a>]

<h2>Controllable and Diverse Text Generation in E-commerce. (arXiv:2102.11497v1 [cs.LG])</h2>
<h3>Huajie Shao, Jun Wang, Haohong Lin, Xuezhou Zhang, Aston Zhang, Heng Ji, Tarek Abdelzaher</h3>
<p>In E-commerce, a key challenge in text generation is to find a good trade-off
between word diversity and accuracy (relevance) in order to make generated text
appear more natural and human-like. In order to improve the relevance of
generated results, conditional text generators were developed that use input
keywords or attributes to produce the corresponding text. Prior work, however,
do not finely control the diversity of automatically generated sentences. For
example, it does not control the order of keywords to put more relevant ones
first. Moreover, it does not explicitly control the balance between diversity
and accuracy. To remedy these problems, we propose a fine-grained controllable
generative model, called~\textit{Apex}, that uses an algorithm borrowed from
automatic control (namely, a variant of the \textit{proportional, integral, and
derivative (PID) controller}) to precisely manipulate the diversity/accuracy
trade-off of generated text. The algorithm is injected into a Conditional
Variational Autoencoder (CVAE), allowing \textit{Apex} to control both (i) the
order of keywords in the generated sentences (conditioned on the input keywords
and their order), and (ii) the trade-off between diversity and accuracy.
Evaluation results on real-world datasets show that the proposed method
outperforms existing generative models in terms of diversity and relevance.
Apex is currently deployed to generate production descriptions and item
recommendation reasons in Taobao owned by Alibaba, the largest E-commerce
platform in China. The A/B production test results show that our method
improves click-through rate (CTR) by 13.17\% compared to the existing method
for production descriptions. For item recommendation reason, it is able to
increase CTR by 6.89\% and 1.42\% compared to user reviews and top-K item
recommendation without reviews, respectively.
</p>
<a href="http://arxiv.org/abs/2102.11497" target="_blank">arXiv:2102.11497</a> [<a href="http://arxiv.org/pdf/2102.11497" target="_blank">pdf</a>]

<h2>V2W-BERT: A Framework for Effective Hierarchical Multiclass Classification of Software Vulnerabilities. (arXiv:2102.11498v1 [cs.LG])</h2>
<h3>Siddhartha Shankar Das, Edoardo Serra, Mahantesh Halappanavar, Alex Pothen, Ehab Al-Shaer</h3>
<p>Weaknesses in computer systems such as faults, bugs and errors in the
architecture, design or implementation of software provide vulnerabilities that
can be exploited by attackers to compromise the security of a system. Common
Weakness Enumerations (CWE) are a hierarchically designed dictionary of
software weaknesses that provide a means to understand software flaws,
potential impact of their exploitation, and means to mitigate these flaws.
Common Vulnerabilities and Exposures (CVE) are brief low-level descriptions
that uniquely identify vulnerabilities in a specific product or protocol.
Classifying or mapping of CVEs to CWEs provides a means to understand the
impact and mitigate the vulnerabilities. Since manual mapping of CVEs is not a
viable option, automated approaches are desirable but challenging.

We present a novel Transformer-based learning framework (V2W-BERT) in this
paper. By using ideas from natural language processing, link prediction and
transfer learning, our method outperforms previous approaches not only for CWE
instances with abundant data to train, but also rare CWE classes with little or
no data to train. Our approach also shows significant improvements in using
historical data to predict links for future instances of CVEs, and therefore,
provides a viable approach for practical applications. Using data from MITRE
and National Vulnerability Database, we achieve up to 97% prediction accuracy
for randomly partitioned data and up to 94% prediction accuracy in temporally
partitioned data. We believe that our work will influence the design of better
methods and training models, as well as applications to solve increasingly
harder problems in cybersecurity.
</p>
<a href="http://arxiv.org/abs/2102.11498" target="_blank">arXiv:2102.11498</a> [<a href="http://arxiv.org/pdf/2102.11498" target="_blank">pdf</a>]

<h2>Model-Attentive Ensemble Learning for Sequence Modeling. (arXiv:2102.11500v1 [cs.LG])</h2>
<h3>Victor D. Bourgin, Ioana Bica, Mihaela van der Schaar</h3>
<p>Medical time-series datasets have unique characteristics that make prediction
tasks challenging. Most notably, patient trajectories often contain
longitudinal variations in their input-output relationships, generally referred
to as temporal conditional shift. Designing sequence models capable of adapting
to such time-varying distributions remains a prevailing problem. To address
this we present Model-Attentive Ensemble learning for Sequence modeling (MAES).
MAES is a mixture of time-series experts which leverages an attention-based
gating mechanism to specialize the experts on different sequence dynamics and
adaptively weight their predictions. We demonstrate that MAES significantly
out-performs popular sequence models on datasets subject to temporal shift.
</p>
<a href="http://arxiv.org/abs/2102.11500" target="_blank">arXiv:2102.11500</a> [<a href="http://arxiv.org/pdf/2102.11500" target="_blank">pdf</a>]

<h2>Lessons from Chasing Few-Shot Learning Benchmarks: Rethinking the Evaluation of Meta-Learning Methods. (arXiv:2102.11503v1 [cs.LG])</h2>
<h3>Amrith Setlur, Oscar Li, Virginia Smith</h3>
<p>In this work we introduce a simple baseline for meta-learning. Our
unconventional method, FIX-ML, reduces task diversity by keeping support sets
fixed across tasks, and consistently improves the performance of meta-learning
methods on popular few-shot learning benchmarks. However, in exploring the
reason for this counter-intuitive phenomenon, we unearth a series of questions
and concerns about meta-learning evaluation practices. We explore two possible
goals of meta-learning: to develop methods that generalize (i) to the same task
distribution that generates the training set (in-distribution), or (ii) to new,
unseen task distributions (out-of-distribution). Through careful analyses, we
show that for each of these two goals, current few-shot learning benchmarks
have potential pitfalls in 1) performing model selection and hyperparameter
tuning for a given meta-learning method and 2) comparing the performance of
different meta-learning methods. Our results highlight that in order to reason
about progress in this space, it is necessary to provide a clearer description
of the goals of meta-learning, and to develop more appropriate corresponding
evaluation strategies.
</p>
<a href="http://arxiv.org/abs/2102.11503" target="_blank">arXiv:2102.11503</a> [<a href="http://arxiv.org/pdf/2102.11503" target="_blank">pdf</a>]

<h2>Equivariant neural networks for inverse problems. (arXiv:2102.11504v1 [cs.LG])</h2>
<h3>Elena Celledoni, Matthias J. Ehrhardt, Christian Etmann, Brynjulf Owren, Carola-Bibiane Sch&#xf6;nlieb, Ferdia Sherry</h3>
<p>In recent years the use of convolutional layers to encode an inductive bias
(translational equivariance) in neural networks has proven to be a very
fruitful idea. The successes of this approach have motivated a line of research
into incorporating other symmetries into deep learning methods, in the form of
group equivariant convolutional neural networks. Much of this work has been
focused on roto-translational symmetry of $\mathbf R^d$, but other examples are
the scaling symmetry of $\mathbf R^d$ and rotational symmetry of the sphere. In
this work, we demonstrate that group equivariant convolutional operations can
naturally be incorporated into learned reconstruction methods for inverse
problems that are motivated by the variational regularisation approach. Indeed,
if the regularisation functional is invariant under a group symmetry, the
corresponding proximal operator will satisfy an equivariance property with
respect to the same group symmetry. As a result of this observation, we design
learned iterative methods in which the proximal operators are modelled as group
equivariant convolutional neural networks. We use roto-translationally
equivariant operations in the proposed methodology and apply it to the problems
of low-dose computerised tomography reconstruction and subsampled magnetic
resonance imaging reconstruction. The proposed methodology is demonstrated to
improve the reconstruction quality of a learned reconstruction method with a
little extra computational cost at training time but without any extra cost at
test time.
</p>
<a href="http://arxiv.org/abs/2102.11504" target="_blank">arXiv:2102.11504</a> [<a href="http://arxiv.org/pdf/2102.11504" target="_blank">pdf</a>]

<h2>Comparative evaluation of CNN architectures for Image Caption Generation. (arXiv:2102.11506v1 [cs.CV])</h2>
<h3>Sulabh Katiyar, Samir Kumar Borgohain</h3>
<p>Aided by recent advances in Deep Learning, Image Caption Generation has seen
tremendous progress over the last few years. Most methods use transfer learning
to extract visual information, in the form of image features, with the help of
pre-trained Convolutional Neural Network models followed by transformation of
the visual information using a Caption Generator module to generate the output
sentences. Different methods have used different Convolutional Neural Network
Architectures and, to the best of our knowledge, there is no systematic study
which compares the relative efficacy of different Convolutional Neural Network
architectures for extracting the visual information. In this work, we have
evaluated 17 different Convolutional Neural Networks on two popular Image
Caption Generation frameworks: the first based on Neural Image Caption (NIC)
generation model and the second based on Soft-Attention framework. We observe
that model complexity of Convolutional Neural Network, as measured by number of
parameters, and the accuracy of the model on Object Recognition task does not
necessarily co-relate with its efficacy on feature extraction for Image Caption
Generation task.
</p>
<a href="http://arxiv.org/abs/2102.11506" target="_blank">arXiv:2102.11506</a> [<a href="http://arxiv.org/pdf/2102.11506" target="_blank">pdf</a>]

<h2>Mixed Policy Gradient. (arXiv:2102.11513v1 [cs.LG])</h2>
<h3>Yang Guan, Jingliang Duan, Shengbo Eben Li, Jie Li, Jianyu Chen, Bo Cheng</h3>
<p>Reinforcement learning (RL) has great potential in sequential
decision-making. At present, the mainstream RL algorithms are data-driven,
relying on millions of iterations and a large number of empirical data to learn
a policy. Although data-driven RL may have excellent asymptotic performance, it
usually yields slow convergence speed. As a comparison, model-driven RL employs
a differentiable transition model to improve convergence speed, in which the
policy gradient (PG) is calculated by using the backpropagation through time
(BPTT) technique. However, such methods suffer from numerical instability,
model error sensitivity and low computing efficiency, which may lead to poor
policies. In this paper, a mixed policy gradient (MPG) method is proposed,
which uses both empirical data and the transition model to construct the PG, so
as to accelerate the convergence speed without losing the optimality guarantee.
MPG contains two types of PG: 1) data-driven PG, which is obtained by directly
calculating the derivative of the learned Q-value function with respect to
actions, and 2) model-driven PG, which is calculated using BPTT based on the
model-predictive return. We unify them by revealing the correlation between the
upper bound of the unified PG error and the predictive horizon, where the
data-driven PG is regraded as 0-step model-predictive return. Relying on that,
MPG employs a rule-based method to adaptively adjust the weights of data-driven
and model-driven PGs. In particular, to get a more accurate PG, the weight of
the data-driven PG is designed to grow along the learning process while the
other to decrease. Besides, an asynchronous learning framework is proposed to
reduce the wall-clock time needed for each update iteration. Simulation results
show that the MPG method achieves the best asymptotic performance and
convergence speed compared with other baseline algorithms.
</p>
<a href="http://arxiv.org/abs/2102.11513" target="_blank">arXiv:2102.11513</a> [<a href="http://arxiv.org/pdf/2102.11513" target="_blank">pdf</a>]

<h2>SliceNStitch: Continuous CP Decomposition of Sparse Tensor Streams. (arXiv:2102.11517v1 [cs.LG])</h2>
<h3>Taehyung Kwon, Inkyu Park, Dongjin Lee, Kijung Shin</h3>
<p>Consider traffic data (i.e., triplets in the form of
source-destination-timestamp) that grow over time. Tensors (i.e.,
multi-dimensional arrays) with a time mode are widely used for modeling and
analyzing such multi-aspect data streams. In such tensors, however, new entries
are added only once per period, which is often an hour, a day, or even a year.
This discreteness of tensors has limited their usage for real-time
applications, where new data should be analyzed instantly as it arrives. How
can we analyze time-evolving multi-aspect sparse data 'continuously' using
tensors where time is'discrete'? We propose SLICENSTITCH for continuous
CANDECOMP/PARAFAC (CP) decomposition, which has numerous time-critical
applications, including anomaly detection, recommender systems, and stock
market prediction. SLICENSTITCH changes the starting point of each period
adaptively, based on the current time, and updates factor matrices (i.e.,
outputs of CP decomposition) instantly as new data arrives. We show,
theoretically and experimentally, that SLICENSTITCH is (1) 'Any time': updating
factor matrices immediately without having to wait until the current time
period ends, (2) Fast: with constant-time updates up to 759x faster than online
methods, and (3) Accurate: with fitness comparable (specifically, 72 ~ 160%) to
offline methods.
</p>
<a href="http://arxiv.org/abs/2102.11517" target="_blank">arXiv:2102.11517</a> [<a href="http://arxiv.org/pdf/2102.11517" target="_blank">pdf</a>]

<h2>Automatic Ship Classification Utilizing Bag of Deep Features. (arXiv:2102.11520v1 [cs.CV])</h2>
<h3>Sadegh Soleimani Pour, Ata Jodeiri, Hossein Rashidi, Seyed Mostafa Mirhassani, Hoda Kheradfallah, Hadi Seyedarabi</h3>
<p>Detection and classification of ships based on their silhouette profiles in
natural imagery is an important undertaking in computer science. This problem
can be viewed from a variety of perspectives, including security, traffic
control, and even militarism. Therefore, in each of the aforementioned
applications, specific processing is required. In this paper, by applying the
"bag of words" (BoW), a new method is presented that its words are the features
that are obtained using pre-trained models of deep convolutional networks. ,
Three VGG models are utilized which provide superior accuracy in identifying
objects. The regions of the image that are selected as the initial proposals
are derived from a greedy algorithm on the key points generated by the Scale
Invariant Feature Transform (SIFT) method. Using the deep features in the BOW
method provides a good improvement in the recognition and classification of
ships. Eventually, we obtained an accuracy of 91.8% in the classification of
the ships which shows the improvement of about 5% compared to previous methods.
</p>
<a href="http://arxiv.org/abs/2102.11520" target="_blank">arXiv:2102.11520</a> [<a href="http://arxiv.org/pdf/2102.11520" target="_blank">pdf</a>]

<h2>Enhanced Modality Transition for Image Captioning. (arXiv:2102.11526v1 [cs.CV])</h2>
<h3>Ziwei Wang, Yadan Luo, Zi Huang</h3>
<p>Image captioning model is a cross-modality knowledge discovery task, which
targets at automatically describing an image with an informative and coherent
sentence. To generate the captions, the previous encoder-decoder frameworks
directly forward the visual vectors to the recurrent language model, forcing
the recurrent units to generate a sentence based on the visual features.
Although these sentences are generally readable, they still suffer from the
lack of details and highlights, due to the fact that the substantial gap
between the image and text modalities is not sufficiently addressed. In this
work, we explicitly build a Modality Transition Module (MTM) to transfer visual
features into semantic representations before forwarding them to the language
model. During the training phase, the modality transition network is optimised
by the proposed modality loss, which compares the generated preliminary textual
encodings with the target sentence vectors from a pre-trained text
auto-encoder. In this way, the visual vectors are transited into the textual
subspace for more contextual and precise language generation. The novel MTM can
be incorporated into most of the existing methods. Extensive experiments have
been conducted on the MS-COCO dataset demonstrating the effectiveness of the
proposed framework, improving the performance by 3.4% comparing to the
state-of-the-arts.
</p>
<a href="http://arxiv.org/abs/2102.11526" target="_blank">arXiv:2102.11526</a> [<a href="http://arxiv.org/pdf/2102.11526" target="_blank">pdf</a>]

<h2>Differentiable Logic Machines. (arXiv:2102.11529v1 [cs.AI])</h2>
<h3>Zimmer Matthieu, Feng Xuening, Glanois Claire, Jiang Zhaohui, Zhang Jianyi, Weng Paul, Jianye Hao, Dong Li, Wulong Liu</h3>
<p>The integration of reasoning, learning, and decision-making is key to build
more general AI systems. As a step in this direction, we propose a novel
neural-logic architecture that can solve both inductive logic programming (ILP)
and deep reinforcement learning (RL) problems. Our architecture defines a
restricted but expressive continuous space of first-order logic programs by
assigning weights to predicates instead of rules. Therefore, it is fully
differentiable and can be efficiently trained with gradient descent. Besides,
in the deep RL setting with actor-critic algorithms, we propose a novel
efficient critic architecture. Compared to state-of-the-art methods on both ILP
and RL problems, our proposition achieves excellent performance, while being
able to provide a fully interpretable solution and scaling much better,
especially during the testing phase.
</p>
<a href="http://arxiv.org/abs/2102.11529" target="_blank">arXiv:2102.11529</a> [<a href="http://arxiv.org/pdf/2102.11529" target="_blank">pdf</a>]

<h2>Domain-invariant NBV Planner for Active Cross-domain Self-localization. (arXiv:2102.11530v1 [cs.CV])</h2>
<h3>Kanji Tanaka</h3>
<p>Pole-like landmark has received increasing attention as a domain-invariant
visual cue for visual robot self-localization across domains (e.g., seasons,
times of day, weathers). However, self-localization using pole-like landmarks
can be ill-posed for a passive observer, as many viewpoints may not provide any
pole-like landmark view. To alleviate this problem, we consider an active
observer and explore a novel "domain-invariant" next-best-view (NBV) planner
that attains consistent performance over different domains (i.e.,
maintenance-free), without requiring the expensive task of training data
collection and retraining. In our approach, a novel multi-encoder deep
convolutional neural network enables to detect domain invariant pole-like
landmarks, which are then used as the sole input to a model-free deep
reinforcement learning -based domain-invariant NBV planner. Further, we develop
a practical system for active self-localization using sparse invariant
landmarks and dense discriminative landmarks. In experiments, we demonstrate
that the proposed method is effective both in efficient landmark detection and
in discriminative self-localization.
</p>
<a href="http://arxiv.org/abs/2102.11530" target="_blank">arXiv:2102.11530</a> [<a href="http://arxiv.org/pdf/2102.11530" target="_blank">pdf</a>]

<h2>Accurate Learning of Graph Representations with Graph Multiset Pooling. (arXiv:2102.11533v1 [cs.LG])</h2>
<h3>Jinheon Baek, Minki Kang, Sung Ju Hwang</h3>
<p>Graph neural networks have been widely used on modeling graph data, achieving
impressive results on node classification and link prediction tasks. Yet,
obtaining an accurate representation for a graph further requires a pooling
function that maps a set of node representations into a compact form. A simple
sum or average over all node representations considers all node features
equally without consideration of their task relevance, and any structural
dependencies among them. Recently proposed hierarchical graph pooling methods,
on the other hand, may yield the same representation for two different graphs
that are distinguished by the Weisfeiler-Lehman test, as they suboptimally
preserve information from the node features. To tackle these limitations of
existing graph pooling methods, we first formulate the graph pooling problem as
a multiset encoding problem with auxiliary information about the graph
structure, and propose a Graph Multiset Transformer (GMT) which is a multi-head
attention based global pooling layer that captures the interaction between
nodes according to their structural dependencies. We show that GMT satisfies
both injectiveness and permutation invariance, such that it is at most as
powerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods
can be easily extended to the previous node clustering approaches for
hierarchical graph pooling. Our experimental results show that GMT
significantly outperforms state-of-the-art graph pooling methods on graph
classification benchmarks with high memory and time efficiency, and obtains
even larger performance gain on graph reconstruction and generation tasks.
</p>
<a href="http://arxiv.org/abs/2102.11533" target="_blank">arXiv:2102.11533</a> [<a href="http://arxiv.org/pdf/2102.11533" target="_blank">pdf</a>]

<h2>Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective. (arXiv:2102.11535v1 [cs.CV])</h2>
<h3>Wuyang Chen, Xinyu Gong, Zhangyang Wang</h3>
<p>Neural Architecture Search (NAS) has been explosively studied to automate the
discovery of top-performer neural networks. Current works require heavy
training of supernet or intensive architecture evaluations, thus suffering from
heavy resource consumption and often incurring search bias due to truncated
training or approximations. Can we select the best neural architectures without
involving any training and eliminate a drastic portion of the search cost? We
provide an affirmative answer, by proposing a novel framework called
training-free neural architecture search (TE-NAS). TE-NAS ranks architectures
by analyzing the spectrum of the neural tangent kernel (NTK) and the number of
linear regions in the input space. Both are motivated by recent theory advances
in deep networks and can be computed without any training and any label. We
show that: (1) these two measurements imply the trainability and expressivity
of a neural network; (2) they strongly correlate with the network's test
accuracy. Further on, we design a pruning-based NAS mechanism to achieve a more
flexible and superior trade-off between the trainability and expressivity
during the search. In NAS-Bench-201 and DARTS search spaces, TE-NAS completes
high-quality search but only costs 0.5 and 4 GPU hours with one 1080Ti on
CIFAR-10 and ImageNet, respectively. We hope our work inspires more attempts in
bridging the theoretical findings of deep networks and practical impacts in
real NAS applications. Code is available at:
https://github.com/VITA-Group/TENAS.
</p>
<a href="http://arxiv.org/abs/2102.11535" target="_blank">arXiv:2102.11535</a> [<a href="http://arxiv.org/pdf/2102.11535" target="_blank">pdf</a>]

<h2>Decision Rule Elicitation for Domain Adaptation. (arXiv:2102.11539v1 [cs.LG])</h2>
<h3>Alexander Nikitin, Samuel Kaski</h3>
<p>Human-in-the-loop machine learning is widely used in artificial intelligence
(AI) to elicit labels for data points from experts or to provide feedback on
how close the predicted results are to the target. This simplifies away all the
details of the decision-making process of the expert. In this work, we allow
the experts to additionally produce decision rules describing their
decision-making; the rules are expected to be imperfect but to give additional
information. In particular, the rules can extend to new distributions, and
hence enable significantly improving performance for cases where the training
and testing distributions differ, such as in domain adaptation. We apply the
proposed method to lifelong learning and domain adaptation problems and discuss
applications in other branches of AI, such as knowledge acquisition problems in
expert systems. In simulated and real-user studies, we show that decision rule
elicitation improves domain adaptation of the algorithm and helps to propagate
expert's knowledge to the AI model.
</p>
<a href="http://arxiv.org/abs/2102.11539" target="_blank">arXiv:2102.11539</a> [<a href="http://arxiv.org/pdf/2102.11539" target="_blank">pdf</a>]

<h2>Deep Deformation Detail Synthesis for Thin Shell Models. (arXiv:2102.11541v1 [cs.CV])</h2>
<h3>Lan Chen, Lin Gao, Jie Yang, Shibiao Xu, Juntao Ye, Xiaopeng Zhang, Yu-Kun Lai</h3>
<p>In physics-based cloth animation, rich folds and detailed wrinkles are
achieved at the cost of expensive computational resources and huge labor
tuning. Data-driven techniques make efforts to reduce the computation
significantly by a database. One type of methods relies on human poses to
synthesize fitted garments which cannot be applied to general cloth. Another
type of methods adds details to the coarse meshes without such restrictions.
However, existing works usually utilize coordinate-based representations which
cannot cope with large-scale deformation, and requires dense vertex
correspondences between coarse and fine meshes. Moreover, as such methods only
add details, they require coarse meshes to be close to fine meshes, which can
be either impossible, or require unrealistic constraints when generating fine
meshes. To address these challenges, we develop a temporally and spatially
as-consistent-as-possible deformation representation (named TS-ACAP) and a
DeformTransformer network to learn the mapping from low-resolution meshes to
detailed ones. This TS-ACAP representation is designed to ensure both spatial
and temporal consistency for sequential large-scale deformations from cloth
animations. With this representation, our DeformTransformer network first
utilizes two mesh-based encoders to extract the coarse and fine features,
respectively. To transduct the coarse features to the fine ones, we leverage
the Transformer network that consists of frame-level attention mechanisms to
ensure temporal coherence of the prediction. Experimental results show that our
method is able to produce reliable and realistic animations in various datasets
at high frame rates: 10 ~ 35 times faster than physics-based simulation, with
superior detail synthesis abilities than existing methods.
</p>
<a href="http://arxiv.org/abs/2102.11541" target="_blank">arXiv:2102.11541</a> [<a href="http://arxiv.org/pdf/2102.11541" target="_blank">pdf</a>]

<h2>Identifying Physical Law of Hamiltonian Systems via Meta-Learning. (arXiv:2102.11544v1 [cs.LG])</h2>
<h3>Seungjun Lee, Haesang Yang, Woojae Seong</h3>
<p>Hamiltonian mechanics is an effective tool to represent many physical
processes with concise yet well-generalized mathematical expressions. A
well-modeled Hamiltonian makes it easy for researchers to analyze and forecast
many related phenomena that are governed by the same physical law. However, in
general, identifying a functional or shared expression of the Hamiltonian is
very difficult. It requires carefully designed experiments and the researcher's
insight that comes from years of experience. We propose that meta-learning
algorithms can be potentially powerful data-driven tools for identifying the
physical law governing Hamiltonian systems without any mathematical assumptions
on the representation, but with observations from a set of systems governed by
the same physical law. We show that a well meta-trained learner can identify
the shared representation of the Hamiltonian by evaluating our method on
several types of physical systems with various experimental settings.
</p>
<a href="http://arxiv.org/abs/2102.11544" target="_blank">arXiv:2102.11544</a> [<a href="http://arxiv.org/pdf/2102.11544" target="_blank">pdf</a>]

<h2>Accelerating Recursive Partition-Based Causal Structure Learning. (arXiv:2102.11545v1 [cs.LG])</h2>
<h3>Md. Musfiqur Rahman, Ayman Rasheed, Md. Mosaddek Khan, Mohammad Ali Javidian, Pooyan Jamshidi, Md. Mamun-Or-Rashid</h3>
<p>Causal structure discovery from observational data is fundamental to the
causal understanding of autonomous systems such as medical decision support
systems, advertising campaigns and self-driving cars. This is essential to
solve well-known causal decision making and prediction problems associated with
those real-world applications. Recently, recursive causal discovery algorithms
have gained particular attention among the research community due to their
ability to provide good results by using Conditional Independent (CI) tests in
smaller sub-problems. However, each of such algorithms needs a refinement
function to remove undesired causal relations of the discovered graphs.
Notably, with the increase of the problem size, the computation cost (i.e., the
number of CI-tests) of the refinement function makes an algorithm expensive to
deploy in practice. This paper proposes a generic causal structure refinement
strategy that can locate the undesired relations with a small number of
CI-tests, thus speeding up the algorithm for large and complex problems. We
theoretically prove the correctness of our algorithm. We then empirically
evaluate its performance against the state-of-the-art algorithms in terms of
solution quality and completion time in synthetic and real datasets.
</p>
<a href="http://arxiv.org/abs/2102.11545" target="_blank">arXiv:2102.11545</a> [<a href="http://arxiv.org/pdf/2102.11545" target="_blank">pdf</a>]

<h2>SISE-PC: Semi-supervised Image Subsampling for Explainable Pathology. (arXiv:2102.11560v1 [cs.CV])</h2>
<h3>Sohini Roychowdhury, Kwok Sun Tang, Mohith Ashok, Anoop Sanka</h3>
<p>Although automated pathology classification using deep learning (DL) has
proved to be predictively efficient, DL methods are found to be data and
compute cost intensive. In this work, we aim to reduce DL training costs by
pre-training a Resnet feature extractor using SimCLR contrastive loss for
latent encoding of OCT images. We propose a novel active learning framework
that identifies a minimal sub-sampled dataset containing the most uncertain OCT
image samples using label propagation on the SimCLR latent encodings. The
pre-trained Resnet model is then fine-tuned with the labelled minimal
sub-sampled data and the underlying pathological sites are visually explained.
Our framework identifies upto 2% of OCT images to be most uncertain that need
prioritized specialist attention and that can fine-tune a Resnet model to
achieve upto 97% classification accuracy. The proposed method can be extended
to other medical images to minimize prediction costs.
</p>
<a href="http://arxiv.org/abs/2102.11560" target="_blank">arXiv:2102.11560</a> [<a href="http://arxiv.org/pdf/2102.11560" target="_blank">pdf</a>]

<h2>Multi-Knowledge Fusion for New Feature Generation in Generalized Zero-Shot Learning. (arXiv:2102.11566v1 [cs.CV])</h2>
<h3>Hongxin Xiang, Cheng Xie, Ting Zeng, Yun Yang</h3>
<p>Suffering from the semantic insufficiency and domain-shift problems, most of
existing state-of-the-art methods fail to achieve satisfactory results for
Zero-Shot Learning (ZSL). In order to alleviate these problems, we propose a
novel generative ZSL method to learn more generalized features from
multi-knowledge with continuously generated new semantics in semantic-to-visual
embedding. In our approach, the proposed Multi-Knowledge Fusion Network
(MKFNet) takes different semantic features from multi-knowledge as input, which
enables more relevant semantic features to be trained for semantic-to-visual
embedding, and finally generates more generalized visual features by adaptively
fusing visual features from different knowledge domain. The proposed New
Feature Generator (NFG) with adaptive genetic strategy is used to enrich
semantic information on the one hand, and on the other hand it greatly improves
the intersection of visual feature generated by MKFNet and unseen visual
faetures. Empirically, we show that our approach can achieve significantly
better performance compared to existing state-of-the-art methods on a large
number of benchmarks for several ZSL tasks, including traditional ZSL,
generalized ZSL and zero-shot retrieval.
</p>
<a href="http://arxiv.org/abs/2102.11566" target="_blank">arXiv:2102.11566</a> [<a href="http://arxiv.org/pdf/2102.11566" target="_blank">pdf</a>]

<h2>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models. (arXiv:2102.11570v1 [cs.AI])</h2>
<h3>Harold Ott, Jasmin Bogatinovski, Alexander Acker, Sasho Nedelkoski, Odej Kao</h3>
<p>Anomalies or failures in large computer systems, such as the cloud, have an
impact on a large number of users that communicate, compute, and store
information. Therefore, timely and accurate anomaly detection is necessary for
reliability, security, safe operation, and mitigation of losses in these
increasingly important systems. Recently, the evolution of the software
industry opens up several problems that need to be tackled including (1)
addressing the software evolution due software upgrades, and (2) solving the
cold-start problem, where data from the system of interest is not available. In
this paper, we propose a framework for anomaly detection in log data, as a
major troubleshooting source of system information. To that end, we utilize
pre-trained general-purpose language models to preserve the semantics of log
messages and map them into log vector embeddings. The key idea is that these
representations for the logs are robust and less invariant to changes in the
logs, and therefore, result in a better generalization of the anomaly detection
models. We perform several experiments on a cloud dataset evaluating different
language models for obtaining numerical log representations such as BERT,
GPT-2, and XL. The robustness is evaluated by gradually altering log messages,
to simulate a change in semantics. Our results show that the proposed approach
achieves high performance and robustness, which opens up possibilities for
future research in this direction.
</p>
<a href="http://arxiv.org/abs/2102.11570" target="_blank">arXiv:2102.11570</a> [<a href="http://arxiv.org/pdf/2102.11570" target="_blank">pdf</a>]

<h2>Deterministic Neural Networks with Appropriate Inductive Biases Capture Epistemic and Aleatoric Uncertainty. (arXiv:2102.11582v1 [cs.LG])</h2>
<h3>Jishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip H.S. Torr, Yarin Gal</h3>
<p>We show that a single softmax neural net with minimal changes can beat the
uncertainty predictions of Deep Ensembles and other more complex
single-forward-pass uncertainty approaches. Softmax neural nets cannot capture
epistemic uncertainty reliably because for OoD points they extrapolate
arbitrarily and suffer from feature collapse. This results in arbitrary softmax
entropies for OoD points which can have high entropy, low, or anything in
between. We study why, and show that with the right inductive biases, softmax
neural nets trained with maximum likelihood reliably capture epistemic
uncertainty through the feature-space density. This density is obtained using
Gaussian Discriminant Analysis, but it cannot disentangle uncertainties. We
show that it is necessary to combine this density with the softmax entropy to
disentangle aleatoric and epistemic uncertainty -- crucial e.g. for active
learning. We examine the quality of epistemic uncertainty on active learning
and OoD detection, where we obtain SOTA ~0.98 AUROC on CIFAR-10 vs SVHN.
</p>
<a href="http://arxiv.org/abs/2102.11582" target="_blank">arXiv:2102.11582</a> [<a href="http://arxiv.org/pdf/2102.11582" target="_blank">pdf</a>]

<h2>ROAD: The ROad event Awareness Dataset for Autonomous Driving. (arXiv:2102.11585v1 [cs.CV])</h2>
<h3>Gurkirt Singh, Stephen Akrigg, Manuele Di Maio, Valentina Fontana, Reza Javanmard Alitappeh, Suman Saha, Kossar Jeddisaravi, Farzad Yousefi, Jacob Culley, Tom Nicholson, Jordan Omokeowa, Salman Khan, Stanislao Grazioso, Andrew Bradley, Giuseppe Di Gironimo, Fabio Cuzzolin</h3>
<p>Humans approach driving in a holistic fashion which entails, in particular,
understanding road events and their evolution. Injecting these capabilities in
an autonomous vehicle has thus the potential to take situational awareness and
decision making closer to human-level performance. To this purpose, we
introduce the ROad event Awareness Dataset (ROAD) for Autonomous Driving, to
our knowledge the first of its kind. ROAD is designed to test an autonomous
vehicle's ability to detect road events, defined as triplets composed by a
moving agent, the action(s) it performs and the corresponding scene locations.
ROAD comprises 22 videos, originally from the Oxford RobotCar Dataset,
annotated with bounding boxes showing the location in the image plane of each
road event. We also provide as baseline a new incremental algorithm for online
road event awareness, based on inflating RetinaNet along time, which achieves a
mean average precision of 16.8% and 6.1% for frame-level and video-level event
detection, respectively, at 50% overlap. Though promising, these figures
highlight the challenges faced by situation awareness in autonomous driving.
Finally, ROAD allows scholars to investigate exciting tasks such as complex
(road) activity detection, future road event anticipation and the modelling of
sentient road agents in terms of mental states.
</p>
<a href="http://arxiv.org/abs/2102.11585" target="_blank">arXiv:2102.11585</a> [<a href="http://arxiv.org/pdf/2102.11585" target="_blank">pdf</a>]

<h2>Adversarial Examples Detection beyond Image Space. (arXiv:2102.11586v1 [cs.CV])</h2>
<h3>Kejiang Chen, Yuefeng Chen, Hang Zhou, Chuan Qin, Xiaofeng Mao, Weiming Zhang, Nenghai Yu</h3>
<p>Deep neural networks have been proved that they are vulnerable to adversarial
examples, which are generated by adding human-imperceptible perturbations to
images. To defend these adversarial examples, various detection based methods
have been proposed. However, most of them perform poorly on detecting
adversarial examples with extremely slight perturbations. By exploring these
adversarial examples, we find that there exists compliance between
perturbations and prediction confidence, which guides us to detect
few-perturbation attacks from the aspect of prediction confidence. To detect
both few-perturbation attacks and large-perturbation attacks, we propose a
method beyond image space by a two-stream architecture, in which the image
stream focuses on the pixel artifacts and the gradient stream copes with the
confidence artifacts. The experimental results show that the proposed method
outperforms the existing methods under oblivious attacks and is verified
effective to defend omniscient attacks as well.
</p>
<a href="http://arxiv.org/abs/2102.11586" target="_blank">arXiv:2102.11586</a> [<a href="http://arxiv.org/pdf/2102.11586" target="_blank">pdf</a>]

<h2>Strategic Classification in the Dark. (arXiv:2102.11592v1 [cs.LG])</h2>
<h3>Ganesh Ghalme, Vineet Nair, Itay Eilat, Inbal Talgam-Cohen, Nir Rosenfeld</h3>
<p>Strategic classification studies the interaction between a classification
rule and the strategic agents it governs. Under the assumption that the
classifier is known, rational agents respond to it by manipulating their
features. However, in many real-life scenarios of high-stake classification
(e.g., credit scoring), the classifier is not revealed to the agents, which
leads agents to attempt to learn the classifier and game it too. In this paper
we generalize the strategic classification model to such scenarios. We define
the price of opacity as the difference in prediction error between opaque and
transparent strategy-robust classifiers, characterize it, and give a sufficient
condition for this price to be strictly positive, in which case transparency is
the recommended policy. Our experiments show how Hardt et al.'s robust
classifier is affected by keeping agents in the dark.
</p>
<a href="http://arxiv.org/abs/2102.11592" target="_blank">arXiv:2102.11592</a> [<a href="http://arxiv.org/pdf/2102.11592" target="_blank">pdf</a>]

<h2>Scaling up learning with GAIT-prop. (arXiv:2102.11598v1 [cs.LG])</h2>
<h3>Sander Dalm, Nasir Ahmad, Luca Ambrogioni, Marcel van Gerven</h3>
<p>Backpropagation of error (BP) is a widely used and highly successful learning
algorithm. However, its reliance on non-local information in propagating error
gradients makes it seem an unlikely candidate for learning in the brain. In the
last decade, a number of investigations have been carried out focused upon
determining whether alternative more biologically plausible computations can be
used to approximate BP. This work builds on such a local learning algorithm -
Gradient Adjusted Incremental Target Propagation (GAIT-prop) - which has
recently been shown to approximate BP in a manner which appears biologically
plausible. This method constructs local, layer-wise weight update targets in
order to enable plausible credit assignment. However, in deep networks, the
local weight updates computed by GAIT-prop can deviate from BP for a number of
reasons. Here, we provide and test methods to overcome such sources of error.
In particular, we adaptively rescale the locally-computed errors and show that
this significantly increases the performance and stability of the GAIT-prop
algorithm when applied to the CIFAR-10 dataset.
</p>
<a href="http://arxiv.org/abs/2102.11598" target="_blank">arXiv:2102.11598</a> [<a href="http://arxiv.org/pdf/2102.11598" target="_blank">pdf</a>]

<h2>ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks. (arXiv:2102.11600v1 [cs.LG])</h2>
<h3>Jungmin Kwon, Jeongseop Kim, Hyunseo Park, In Kwon Choi</h3>
<p>Recently, learning algorithms motivated from sharpness of loss surface as an
effective measure of generalization gap have shown state-of-the-art
performances. Nevertheless, sharpness defined in a rigid region with a fixed
radius, has a drawback in sensitivity to parameter re-scaling which leaves the
loss unaffected, leading to weakening of the connection between sharpness and
generalization gap. In this paper, we introduce the concept of adaptive
sharpness which is scale-invariant and propose the corresponding generalization
bound. We suggest a novel learning method, adaptive sharpness-aware
minimization (ASAM), utilizing the proposed generalization bound. Experimental
results in various benchmark datasets show that ASAM contributes to significant
improvement of model generalization performance.
</p>
<a href="http://arxiv.org/abs/2102.11600" target="_blank">arXiv:2102.11600</a> [<a href="http://arxiv.org/pdf/2102.11600" target="_blank">pdf</a>]

<h2>SeqNet: Learning Descriptors for Sequence-based Hierarchical Place Recognition. (arXiv:2102.11603v1 [cs.CV])</h2>
<h3>Sourav Garg, Michael Milford</h3>
<p>Visual Place Recognition (VPR) is the task of matching current visual imagery
from a camera to images stored in a reference map of the environment. While
initial VPR systems used simple direct image methods or hand-crafted visual
features, recent work has focused on learning more powerful visual features and
further improving performance through either some form of sequential matcher /
filter or a hierarchical matching process. In both cases the performance of the
initial single-image based system is still far from perfect, putting
significant pressure on the sequence matching or (in the case of hierarchical
systems) pose refinement stages. In this paper we present a novel hybrid system
that creates a high performance initial match hypothesis generator using short
learnt sequential descriptors, which enable selective control sequential score
aggregation using single image learnt descriptors. Sequential descriptors are
generated using a temporal convolutional network dubbed SeqNet, encoding short
image sequences using 1-D convolutions, which are then matched against the
corresponding temporal descriptors from the reference dataset to provide an
ordered list of place match hypotheses. We then perform selective sequential
score aggregation using shortlisted single image learnt descriptors from a
separate pipeline to produce an overall place match hypothesis. Comprehensive
experiments on challenging benchmark datasets demonstrate the proposed method
outperforming recent state-of-the-art methods using the same amount of
sequential information. Source code and supplementary material can be found at
https://github.com/oravus/seqNet.
</p>
<a href="http://arxiv.org/abs/2102.11603" target="_blank">arXiv:2102.11603</a> [<a href="http://arxiv.org/pdf/2102.11603" target="_blank">pdf</a>]

<h2>Self-Supervised Noisy Label Learning for Source-Free Unsupervised Domain Adaptation. (arXiv:2102.11614v1 [cs.CV])</h2>
<h3>Weijie Chen, Luojun Lin, Shicai Yang, Di Xie, Shiliang Pu, Yueting Zhuang, Wenqi Ren</h3>
<p>It is a strong prerequisite to access source data freely in many existing
unsupervised domain adaptation approaches. However, source data is agnostic in
many practical scenarios due to the constraints of expensive data transmission
and data privacy protection. Usually, the given source domain pre-trained model
is expected to optimize with only unlabeled target data, which is termed as
source-free unsupervised domain adaptation. In this paper, we solve this
problem from the perspective of noisy label learning, since the given
pre-trained model can pre-generate noisy label for unlabeled target data via
directly network inference. Under this problem modeling, incorporating
self-supervised learning, we propose a novel Self-Supervised Noisy Label
Learning method, which can effectively fine-tune the pre-trained model with
pre-generated label as well as selfgenerated label on the fly. Extensive
experiments had been conducted to validate its effectiveness. Our method can
easily achieve state-of-the-art results and surpass other methods by a very
large margin. Code will be released.
</p>
<a href="http://arxiv.org/abs/2102.11614" target="_blank">arXiv:2102.11614</a> [<a href="http://arxiv.org/pdf/2102.11614" target="_blank">pdf</a>]

<h2>Winning Ticket in Noisy Image Classification. (arXiv:2102.11628v1 [cs.LG])</h2>
<h3>Taehyeon Kim, Jongwoo Ko, Jinhwan Choi, Sangwook Cho, Se-Young Yun</h3>
<p>Modern deep neural networks (DNNs) become frail when the datasets contain
noisy (incorrect) class labels. Many robust techniques have emerged via loss
adjustment, robust loss function, and clean sample selection to mitigate this
issue using the whole dataset. Here, we empirically observe that the dataset
which contains only clean instances in original noisy datasets leads to better
optima than the original dataset even with fewer data. Based on these results,
we state the winning ticket hypothesis: regardless of robust methods, any DNNs
reach the best performance when trained on the dataset possessing only clean
samples from the original (winning ticket). We propose two simple yet effective
strategies to identify winning tickets by looking at the loss landscape and
latent features in DNNs. We conduct numerical experiments by collaborating the
two proposed methods purifying data and existing robust methods for CIFAR-10
and CIFAR-100. The results support that our framework consistently and
remarkably improves performance.
</p>
<a href="http://arxiv.org/abs/2102.11628" target="_blank">arXiv:2102.11628</a> [<a href="http://arxiv.org/pdf/2102.11628" target="_blank">pdf</a>]

<h2>Enhancing Data-Free Adversarial Distillation with Activation Regularization and Virtual Interpolation. (arXiv:2102.11638v1 [cs.LG])</h2>
<h3>Xiaoyang Qu, Jianzong Wang, Jing Xiao</h3>
<p>Knowledge distillation refers to a technique of transferring the knowledge
from a large learned model or an ensemble of learned models to a small model.
This method relies on access to the original training set, which might not
always be available. A possible solution is a data-free adversarial
distillation framework, which deploys a generative network to transfer the
teacher model's knowledge to the student model. However, the data generation
efficiency is low in the data-free adversarial distillation. We add an
activation regularizer and a virtual interpolation method to improve the data
generation efficiency. The activation regularizer enables the students to match
the teacher's predictions close to activation boundaries and decision
boundaries. The virtual interpolation method can generate virtual samples and
labels in-between decision boundaries. Our experiments show that our approach
surpasses state-of-the-art data-free distillation methods. The student model
can achieve 95.42% accuracy on CIFAR-10 and 77.05% accuracy on CIFAR-100
without any original training data. Our model's accuracy is 13.8% higher than
the state-of-the-art data-free method on CIFAR-100.
</p>
<a href="http://arxiv.org/abs/2102.11638" target="_blank">arXiv:2102.11638</a> [<a href="http://arxiv.org/pdf/2102.11638" target="_blank">pdf</a>]

<h2>HardCoRe-NAS: Hard Constrained diffeRentiable Neural Architecture Search. (arXiv:2102.11646v1 [cs.LG])</h2>
<h3>Niv Nayman, Yonathan Aflalo, Asaf Noy, Lihi Zelnik-Manor</h3>
<p>Realistic use of neural networks often requires adhering to multiple
constraints on latency, energy and memory among others. A popular approach to
find fitting networks is through constrained Neural Architecture Search (NAS),
however, previous methods enforce the constraint only softly. Therefore, the
resulting networks do not exactly adhere to the resource constraint and their
accuracy is harmed. In this work we resolve this by introducing Hard
Constrained diffeRentiable NAS (HardCoRe-NAS), that is based on an accurate
formulation of the expected resource requirement and a scalable search method
that satisfies the hard constraint throughout the search. Our experiments show
that HardCoRe-NAS generates state-of-the-art architectures, surpassing other
NAS methods, while strictly satisfying the hard resource constraints without
any tuning required.
</p>
<a href="http://arxiv.org/abs/2102.11646" target="_blank">arXiv:2102.11646</a> [<a href="http://arxiv.org/pdf/2102.11646" target="_blank">pdf</a>]

<h2>Learning to Fairly Classify the Quality of WirelessLinks. (arXiv:2102.11655v1 [cs.LG])</h2>
<h3>Gregor Cerar, Halil Yetgin, Mihael Mohor&#x10d;i&#x10d;, Carolina Fortuna</h3>
<p>Machine learning (ML) has been used to develop increasingly accurate link
quality estimators for wireless networks. However, more in-depth questions
regarding the most suitable class of models, most suitable metrics and model
performance on imbalanced datasets remain open. In this paper, we propose a new
tree-based link quality classifier that meets high performance and fairly
classifies the minority class and, at the same time, incurs low training cost.
We compare the tree-based model, to a multilayer perceptron (MLP) non-linear
model and two linear models, namely logistic regression (LR) and SVM, on a
selected imbalanced dataset and evaluate their results using five different
performance metrics. Our study shows that 1) non-linear models perform slightly
better than linear models in general, 2) the proposed non-linear tree-based
model yields the best performance trade-off considering F1, training time and
fairness, 3) single metric aggregated evaluations based only on accuracy can
hide poor, unfair performance especially on minority classes, and 4) it is
possible to improve the performance on minority classes, by over 40% through
feature selection and by over 20% through resampling, therefore leading to
fairer classification results.
</p>
<a href="http://arxiv.org/abs/2102.11655" target="_blank">arXiv:2102.11655</a> [<a href="http://arxiv.org/pdf/2102.11655" target="_blank">pdf</a>]

<h2>Design and Integration of a Drone based Passive Manipulator for Capturing Flying Targets. (arXiv:2102.11662v1 [cs.RO])</h2>
<h3>B. V. Vidyadhara, Lima Agnel Tony, Mohitvishnu S. Gadde, Shuvrangshu Jana, V. P. Varun, Aashay Anil Bhise, Suresh Sundaram, Debasish Ghose</h3>
<p>In this paper, we present a novel passive single Degree-of-Freedom (DoF)
manipulator design and its integration on an autonomous drone to capture a
moving target. The end-effector is designed to be passive, to disengage the
moving target from a flying UAV and capture it efficiently in the presence of
disturbances, with minimal energy usage. It is also designed to handle target
sway and the effect of downwash. The passive manipulator is integrated with the
drone through a single Degree of Freedom (DoF) arm, and experiments are carried
out in an outdoor environment. The rack-and-pinion mechanism incorporated for
this manipulator ensures safety by extending the manipulator beyond the body of
the drone to capture the target. The autonomous capturing experiments are
conducted using a red ball hanging from a stationary drone and subsequently
from a moving drone. The experiments show that the manipulator captures the
target with a success rate of 70\% even under environmental/measurement
uncertainties and errors.
</p>
<a href="http://arxiv.org/abs/2102.11662" target="_blank">arXiv:2102.11662</a> [<a href="http://arxiv.org/pdf/2102.11662" target="_blank">pdf</a>]

<h2>Measuring Data Leakage in Machine-Learning Models with Fisher Information. (arXiv:2102.11673v1 [cs.LG])</h2>
<h3>Awni Hannun, Chuan Guo, Laurens van der Maaten</h3>
<p>Machine-learning models contain information about the data they were trained
on. This information leaks either through the model itself or through
predictions made by the model. Consequently, when the training data contains
sensitive attributes, assessing the amount of information leakage is paramount.
We propose a method to quantify this leakage using the Fisher information of
the model about the data. Unlike the worst-case a priori guarantees of
differential privacy, Fisher information loss measures leakage with respect to
specific examples, attributes, or sub-populations within the dataset. We
motivate Fisher information loss through the Cram\'{e}r-Rao bound and delineate
the implied threat model. We provide efficient methods to compute Fisher
information loss for output-perturbed generalized linear models. Finally, we
empirically validate Fisher information loss as a useful measure of information
leakage.
</p>
<a href="http://arxiv.org/abs/2102.11673" target="_blank">arXiv:2102.11673</a> [<a href="http://arxiv.org/pdf/2102.11673" target="_blank">pdf</a>]

<h2>A System for 3D Reconstruction Of Comminuted Tibial Plafond Bone Fractures. (arXiv:2102.11684v1 [cs.CV])</h2>
<h3>Pengcheng Liu, Nathan Hewitt, Waseem Shadid, Andrew Willis</h3>
<p>High energy impacts at joint locations often generate highly fragmented, or
comminuted, bone fractures. Current approaches for treatment require physicians
to decide how to classify the fracture within a hierarchy fracture severity
categories. Each category then provides a best-practice treatment scenario to
obtain the best possible prognosis for the patient. This article identifies
shortcomings associated with qualitative-only evaluation of fracture severity
and provides new quantitative metrics that serve to address these shortcomings.
We propose a system to semi-automatically extract quantitative metrics that are
major indicators of fracture severity. These include: (i) fracture surface
area, i.e., how much surface area was generated when the bone broke apart, and
(ii) dispersion, i.e., how far the fragments have rotated and translated from
their original anatomic positions. This article describes new computational
tools to extract these metrics by computationally reconstructing 3D bone
anatomy from CT images with a focus on tibial plafond fracture cases where
difficult qualitative fracture severity cases are more prevalent.
Reconstruction is accomplished within a single system that integrates several
novel algorithms that identify, extract and piece-together fractured fragments
in a virtual environment. Doing so provides objective quantitative measures for
these fracture severity indicators. The availability of such measures provides
new tools for fracture severity assessment which may lead to improved fracture
treatment. This paper describes the system, the underlying algorithms and the
metrics of the reconstruction results by quantitatively analyzing six clinical
tibial plafond fracture cases.
</p>
<a href="http://arxiv.org/abs/2102.11684" target="_blank">arXiv:2102.11684</a> [<a href="http://arxiv.org/pdf/2102.11684" target="_blank">pdf</a>]

<h2>Resilient Path Planning of UAVs against Covert Attacks on UWB Sensors. (arXiv:2102.11696v1 [cs.RO])</h2>
<h3>Jiayi He, Xin Gong, Yukang Cui, Tingwen Huang</h3>
<p>In this letter, a resilient path planning scheme is proposed to navigate a
UAV to the planned (nominal) destination with minimum energy-consumption in the
presence of a smart attacker. The UAV is equipped with two sensors, a GPS
sensor, which is vulnerable to the spoofing attacker, and a well-functioning
Ultra-Wideband (UWB) sensor, which is possible to be fooled. We show that a
covert attacker can significantly deviate the UAV's path by simultaneously
corrupting the GPS signals and forging control inputs without being detected by
the UWB sensor. The prerequisite for the attack occurrence is first discussed.
Based on this prerequisite, the optimal attack scheme is proposed, which
maximizes the deviation between the nominal destination and the real one.
Correspondingly, an energy-efficient and resilient navigation scheme based on
Pontryagin's maximum principle \cite{gelfand2000calculus} is formulated, which
depresses the above covert attacker effectively. To sum up, this problem can be
seen as a Stackelberg game \cite{bacsar1998dynamic} between a secure path
planner (defender) and a covert attacker. The effectiveness and practicality of
our theoretical results are illustrated via two series of simulation examples
and a UAV experiment.
</p>
<a href="http://arxiv.org/abs/2102.11696" target="_blank">arXiv:2102.11696</a> [<a href="http://arxiv.org/pdf/2102.11696" target="_blank">pdf</a>]

<h2>Greedy Multi-step Off-Policy Reinforcement Learning. (arXiv:2102.11717v1 [cs.LG])</h2>
<h3>Yuhui Wang, Pengcheng He, Xiaoyang Tan</h3>
<p>Multi-step off-policy reinforcement learning has achieved great success.
However, existing multi-step methods usually impose a fixed prior on the
bootstrap steps, while the off-policy methods often require additional
correction, suffering from certain undesired effects. In this paper, we propose
a novel bootstrapping method, which greedily takes the maximum value among the
bootstrapping values with varying steps. The new method has two desired
properties:1) it can flexibly adjust the bootstrap step based on the quality of
the data and the learned value function; 2) it can safely and robustly utilize
data from arbitrary behavior policy without additional correction, whatever its
quality or "off-policyness". We analyze the theoretical properties of the
related operator, showing that it is able to converge to the global optimal
value function, with a ratio faster than the traditional Bellman Optimality
Operator. Furthermore, based on this new operator, we derive new model-free RL
algorithms named Greedy Multi-Step Q Learning (and Greedy Multi-step DQN).
Experiments reveal that the proposed methods are reliable, easy to implement,
and achieve state-of-the-art performance on a series of standard benchmark
datasets.
</p>
<a href="http://arxiv.org/abs/2102.11717" target="_blank">arXiv:2102.11717</a> [<a href="http://arxiv.org/pdf/2102.11717" target="_blank">pdf</a>]

<h2>Causal Mediation Analysis with Hidden Confounders. (arXiv:2102.11724v1 [stat.ML])</h2>
<h3>Lu Cheng, Ruocheng Guo, Huan Liu</h3>
<p>An important problem in causal inference is to break down the total effect of
treatment into different causal pathways and quantify the causal effect in each
pathway. Causal mediation analysis (CMA) is a formal statistical approach for
identifying and estimating these causal effects. Central to CMA is the
sequential ignorability assumption that implies all pre-treatment confounders
are measured and they can capture different types of confounding, e.g.,
post-treatment confounders and hidden confounders. Typically unverifiable in
observational studies, this assumption restrains both the coverage and
practicality of conventional methods. This work, therefore, aims to circumvent
the stringent assumption by following a causal graph with a unified confounder
and its proxy variables. Our core contribution is an algorithm that combines
deep latent-variable models and proxy strategy to jointly infer a unified
surrogate confounder and estimate different causal effects in CMA from observed
variables. Empirical evaluations using both synthetic and semi-synthetic
datasets validate the effectiveness of the proposed method.
</p>
<a href="http://arxiv.org/abs/2102.11724" target="_blank">arXiv:2102.11724</a> [<a href="http://arxiv.org/pdf/2102.11724" target="_blank">pdf</a>]

<h2>RGB-D Railway Platform Monitoring and Scene Understanding for Enhanced Passenger Safety. (arXiv:2102.11730v1 [cs.CV])</h2>
<h3>Marco Wallner, Daniel Steininger, Verena Widhalm, Matthias Sch&#xf6;rghuber, Csaba Beleznai</h3>
<p>Automated monitoring and analysis of passenger movement in safety-critical
parts of transport infrastructures represent a relevant visual surveillance
task. Recent breakthroughs in visual representation learning and spatial
sensing opened up new possibilities for detecting and tracking humans and
objects within a 3D spatial context. This paper proposes a flexible analysis
scheme and a thorough evaluation of various processing pipelines to detect and
track humans on a ground plane, calibrated automatically via stereo depth and
pedestrian detection. We consider multiple combinations within a set of RGB-
and depth-based detection and tracking modalities. We exploit the modular
concepts of Meshroom [2] and demonstrate its use as a generic vision processing
pipeline and scalable evaluation framework. Furthermore, we introduce a novel
open RGB-D railway platform dataset with annotations to support research
activities in automated RGB-D surveillance. We present quantitative results for
multiple object detection and tracking for various algorithmic combinations on
our dataset. Results indicate that the combined use of depth-based spatial
information and learned representations yields substantially enhanced detection
and tracking accuracies. As demonstrated, these enhancements are especially
pronounced in adverse situations when occlusions and objects not captured by
learned representations are present.
</p>
<a href="http://arxiv.org/abs/2102.11730" target="_blank">arXiv:2102.11730</a> [<a href="http://arxiv.org/pdf/2102.11730" target="_blank">pdf</a>]

<h2>Rethinking Natural Adversarial Examples for Classification Models. (arXiv:2102.11731v1 [cs.CV])</h2>
<h3>Xiao Li, Jianmin Li, Ting Dai, Jie Shi, Jun Zhu, Xiaolin Hu</h3>
<p>Recently, it was found that many real-world examples without intentional
modifications can fool machine learning models, and such examples are called
"natural adversarial examples". ImageNet-A is a famous dataset of natural
adversarial examples. By analyzing this dataset, we hypothesized that large,
cluttered and/or unusual background is an important reason why the images in
this dataset are difficult to be classified. We validated the hypothesis by
reducing the background influence in ImageNet-A examples with object detection
techniques. Experiments showed that the object detection models with various
classification models as backbones obtained much higher accuracy than their
corresponding classification models. A detection model based on the
classification model EfficientNet-B7 achieved a top-1 accuracy of 53.95%,
surpassing previous state-of-the-art classification models trained on ImageNet,
suggesting that accurate localization information can significantly boost the
performance of classification models on ImageNet-A. We then manually cropped
the objects in images from ImageNet-A and created a new dataset, named
ImageNet-A-Plus. A human test on the new dataset showed that the deep
learning-based classifiers still performed quite poorly compared with humans.
Therefore, the new dataset can be used to study the robustness of
classification models to the internal variance of objects without considering
the background disturbance.
</p>
<a href="http://arxiv.org/abs/2102.11731" target="_blank">arXiv:2102.11731</a> [<a href="http://arxiv.org/pdf/2102.11731" target="_blank">pdf</a>]

<h2>Classifying high-dimensional Gaussian mixtures: Where kernel methods fail and neural networks succeed. (arXiv:2102.11742v1 [cs.LG])</h2>
<h3>Maria Refinetti, Sebastian Goldt, Florent Krzakala, Lenka Zdeborov&#xe1;</h3>
<p>A recent series of theoretical works showed that the dynamics of neural
networks with a certain initialisation are well-captured by kernel methods.
Concurrent empirical work demonstrated that kernel methods can come close to
the performance of neural networks on some image classification tasks. These
results raise the question of whether neural networks only learn successfully
if kernels also learn successfully, despite neural networks being more
expressive. Here, we show theoretically that two-layer neural networks (2LNN)
with only a few hidden neurons can beat the performance of kernel learning on a
simple Gaussian mixture classification task. We study the high-dimensional
limit where the number of samples is linearly proportional to the input
dimension, and show that while small 2LNN achieve near-optimal performance on
this task, lazy training approaches such as random features and kernel methods
do not. Our analysis is based on the derivation of a closed set of equations
that track the learning dynamics of the 2LNN and thus allow to extract the
asymptotic performance of the network as a function of signal-to-noise ratio
and other hyperparameters. We finally illustrate how over-parametrising the
neural network leads to faster convergence, but does not improve its final
performance.
</p>
<a href="http://arxiv.org/abs/2102.11742" target="_blank">arXiv:2102.11742</a> [<a href="http://arxiv.org/pdf/2102.11742" target="_blank">pdf</a>]

<h2>Weakly-supervised multi-class object localization using only object counts as labels. (arXiv:2102.11743v1 [cs.CV])</h2>
<h3>Kyle Mills, Isaac Tamblyn</h3>
<p>We demonstrate the use of an extensive deep neural network to localize
instances of objects in images. The EDNN is naturally able to accurately
perform multi-class counting using only ground truth count values as labels.
Without providing any conceptual information, object annotations, or pixel
segmentation information, the neural network is able to formulate its own
conceptual representation of the items in the image. Using images labelled with
only the counts of the objects present,the structure of the extensive deep
neural network can be exploited to perform localization of the objects within
the visual field. We demonstrate that a trained EDNN can be used to count
objects in images much larger than those on which it was trained. In order to
demonstrate our technique, we introduce seven new data sets: five progressively
harder MNIST digit-counting data sets, and two datasets of 3d-rendered rubber
ducks in various situations. On most of these datasets, the EDNN achieves
greater than 99% test set accuracy in counting objects.
</p>
<a href="http://arxiv.org/abs/2102.11743" target="_blank">arXiv:2102.11743</a> [<a href="http://arxiv.org/pdf/2102.11743" target="_blank">pdf</a>]

<h2>Uncertainty-aware Generalized Adaptive CycleGAN. (arXiv:2102.11747v1 [cs.CV])</h2>
<h3>Uddeshya Upadhyay, Yanbei Chen, Zeynep Akata</h3>
<p>Unpaired image-to-image translation refers to learning inter-image-domain
mapping in an unsupervised manner. Existing methods often learn deterministic
mappings without explicitly modelling the robustness to outliers or predictive
uncertainty, leading to performance degradation when encountering unseen
out-of-distribution (OOD) patterns at test time. To address this limitation, we
propose a novel probabilistic method called Uncertainty-aware Generalized
Adaptive Cycle Consistency (UGAC), which models the per-pixel residual by
generalized Gaussian distribution, capable of modelling heavy-tailed
distributions. We compare our model with a wide variety of state-of-the-art
methods on two challenging tasks: unpaired image denoising in the natural image
and unpaired modality prorogation in medical image domains. Experimental
results demonstrate that our model offers superior image generation quality
compared to recent methods in terms of quantitative metrics such as
signal-to-noise ratio and structural similarity. Our model also exhibits
stronger robustness towards OOD test data.
</p>
<a href="http://arxiv.org/abs/2102.11747" target="_blank">arXiv:2102.11747</a> [<a href="http://arxiv.org/pdf/2102.11747" target="_blank">pdf</a>]

<h2>Deep Policy Dynamic Programming for Vehicle Routing Problems. (arXiv:2102.11756v1 [cs.LG])</h2>
<h3>Wouter Kool, Herke van Hoof, Joaquim Gromicho, Max Welling</h3>
<p>Routing problems are a class of combinatorial problems with many practical
applications. Recently, end-to-end deep learning methods have been proposed to
learn approximate solution heuristics for such problems. In contrast, classical
dynamic programming (DP) algorithms can find optimal solutions, but scale badly
with the problem size. We propose Deep Policy Dynamic Programming (DPDP), which
aims to combine the strengths of learned neural heuristics with those of DP
algorithms. DPDP prioritizes and restricts the DP state space using a policy
derived from a deep neural network, which is trained to predict edges from
example solutions. We evaluate our framework on the travelling salesman problem
(TSP) and the vehicle routing problem (VRP) and show that the neural policy
improves the performance of (restricted) DP algorithms, making them competitive
to strong alternatives such as LKH, while also outperforming other `neural
approaches' for solving TSPs and VRPs with 100 nodes.
</p>
<a href="http://arxiv.org/abs/2102.11756" target="_blank">arXiv:2102.11756</a> [<a href="http://arxiv.org/pdf/2102.11756" target="_blank">pdf</a>]

<h2>EBMs Trained with Maximum Likelihood are Generator Models Trained with a Self-adverserial Loss. (arXiv:2102.11757v1 [cs.LG])</h2>
<h3>Zhisheng Xiao, Qing Yan, Yali Amit</h3>
<p>Maximum likelihood estimation is widely used in training Energy-based models
(EBMs). Training requires samples from an unnormalized distribution, which is
usually intractable, and in practice, these are obtained by MCMC algorithms
such as Langevin dynamics. However, since MCMC in high-dimensional space
converges extremely slowly, the current understanding of maximum likelihood
training, which assumes approximate samples from the model can be drawn, is
problematic. In this paper, we try to understand this training procedure by
replacing Langevin dynamics with deterministic solutions of the associated
gradient descent ODE. Doing so allows us to study the density induced by the
dynamics (if the dynamics are invertible), and connect with GANs by treating
the dynamics as generator models, the initial values as latent variables and
the loss as optimizing a critic defined by the very same energy that determines
the generator through its gradient. Hence the term - self-adversarial loss. We
show that reintroducing the noise in the dynamics does not lead to a
qualitative change in the behavior, and merely reduces the quality of the
generator. We thus show that EBM training is effectively a self-adversarial
procedure rather than maximum likelihood estimation.
</p>
<a href="http://arxiv.org/abs/2102.11757" target="_blank">arXiv:2102.11757</a> [<a href="http://arxiv.org/pdf/2102.11757" target="_blank">pdf</a>]

<h2>A Simulation-Based Test of Identifiability for Bayesian Causal Inference. (arXiv:2102.11761v1 [cs.LG])</h2>
<h3>Sam Witty, David Jensen, Vikash Mansinghka</h3>
<p>This paper introduces a procedure for testing the identifiability of Bayesian
models for causal inference. Although the do-calculus is sound and complete
given a causal graph, many practical assumptions cannot be expressed in terms
of graph structure alone, such as the assumptions required by instrumental
variable designs, regression discontinuity designs, and within-subjects
designs. We present simulation-based identifiability (SBI), a fully automated
identification test based on a particle optimization scheme with simulated
observations. This approach expresses causal assumptions as priors over
functions in a structural causal model, including flexible priors using
Gaussian processes. We prove that SBI is asymptotically sound and complete, and
produces practical finite-sample bounds. We also show empirically that SBI
agrees with known results in graph-based identification as well as with
widely-held intuitions for designs in which graph-based methods are
inconclusive.
</p>
<a href="http://arxiv.org/abs/2102.11761" target="_blank">arXiv:2102.11761</a> [<a href="http://arxiv.org/pdf/2102.11761" target="_blank">pdf</a>]

<h2>School of hard knocks: Curriculum analysis for Pommerman with a fixed computational budget. (arXiv:2102.11762v1 [cs.AI])</h2>
<h3>Omkar Shelke, Hardik Meisheri, Harshad Khadilkar</h3>
<p>Pommerman is a hybrid cooperative/adversarial multi-agent environment, with
challenging characteristics in terms of partial observability, limited or no
communication, sparse and delayed rewards, and restrictive computational time
limits. This makes it a challenging environment for reinforcement learning (RL)
approaches. In this paper, we focus on developing a curriculum for learning a
robust and promising policy in a constrained computational budget of 100,000
games, starting from a fixed base policy (which is itself trained to imitate a
noisy expert policy). All RL algorithms starting from the base policy use
vanilla proximal-policy optimization (PPO) with the same reward function, and
the only difference between their training is the mix and sequence of opponent
policies. One expects that beginning training with simpler opponents and then
gradually increasing the opponent difficulty will facilitate faster learning,
leading to more robust policies compared against a baseline where all available
opponent policies are introduced from the start. We test this hypothesis and
show that within constrained computational budgets, it is in fact better to
"learn in the school of hard knocks", i.e., against all available opponent
policies nearly from the start. We also include ablation studies where we study
the effect of modifying the base environment properties of ammo and bomb blast
strength on the agent performance.
</p>
<a href="http://arxiv.org/abs/2102.11762" target="_blank">arXiv:2102.11762</a> [<a href="http://arxiv.org/pdf/2102.11762" target="_blank">pdf</a>]

<h2>Parameterized Complexity of Logic-Based Argumentation in Schaefer's Framework. (arXiv:2102.11782v1 [cs.AI])</h2>
<h3>Yasir Mahmood, Arne Meier, Johannes Schmidt</h3>
<p>Logic-based argumentation is a well-established formalism modelling
nonmonotonic reasoning. It has been playing a major role in AI for decades,
now. Informally, a set of formulas is the support for a given claim if it is
consistent, subset-minimal, and implies the claim. In such a case, the pair of
the support and the claim together is called an argument. In this paper, we
study the propositional variants of the following three computational tasks
studied in argumentation: ARG (exists a support for a given claim with respect
to a given set of formulas), ARG-Check (is a given set a support for a given
claim), and ARG-Rel (similarly as ARG plus requiring an additionally given
formula to be contained in the support). ARG-Check is complete for the
complexity class DP, and the other two problems are known to be complete for
the second level of the polynomial hierarchy (Parson et al., J. Log. Comput.,
2003) and, accordingly, are highly intractable. Analyzing the reason for this
intractability, we perform a two-dimensional classification: first, we consider
all possible propositional fragments of the problem within Schaefer's framework
(STOC 1978), and then study different parameterizations for each of the
fragment. We identify a list of reasonable structural parameters (size of the
claim, support, knowledge-base) that are connected to the aforementioned
decision problems. Eventually, we thoroughly draw a fine border of
parameterized intractability for each of the problems showing where the
problems are fixed-parameter tractable and when this exactly stops.
Surprisingly, several cases are of very high intractability (paraNP and
beyond).
</p>
<a href="http://arxiv.org/abs/2102.11782" target="_blank">arXiv:2102.11782</a> [<a href="http://arxiv.org/pdf/2102.11782" target="_blank">pdf</a>]

<h2>QuPeL: Quantized Personalization with Applications to Federated Learning. (arXiv:2102.11786v1 [cs.LG])</h2>
<h3>Kaan Ozkara, Navjot Singh, Deepesh Data, Suhas Diggavi</h3>
<p>Traditionally, federated learning (FL) aims to train a single global model
while collaboratively using multiple clients and a server. Two natural
challenges that FL algorithms face are heterogeneity in data across clients and
collaboration of clients with {\em diverse resources}. In this work, we
introduce a \textit{quantized} and \textit{personalized} FL algorithm QuPeL
that facilitates collective training with heterogeneous clients while
respecting resource diversity. For personalization, we allow clients to learn
\textit{compressed personalized models} with different quantization parameters
depending on their resources. Towards this, first we propose an algorithm for
learning quantized models through a relaxed optimization problem, where
quantization values are also optimized over. When each client participating in
the (federated) learning process has different requirements of the quantized
model (both in value and precision), we formulate a quantized personalization
framework by introducing a penalty term for local client objectives against a
globally trained model to encourage collaboration. We develop an alternating
proximal gradient update for solving this quantized personalization problem,
and we analyze its convergence properties. Numerically, we show that optimizing
over the quantization levels increases the performance and we validate that
QuPeL outperforms both FedAvg and local training of clients in a heterogeneous
setting.
</p>
<a href="http://arxiv.org/abs/2102.11786" target="_blank">arXiv:2102.11786</a> [<a href="http://arxiv.org/pdf/2102.11786" target="_blank">pdf</a>]

<h2>Inferring Agents Preferences as Priors for Probabilistic Goal Recognition. (arXiv:2102.11791v1 [cs.AI])</h2>
<h3>Kin Max Gusm&#xe3;o, Ramon Fraga Pereira, Felipe Meneguzzi</h3>
<p>Recent approaches to goal recognition have leveraged planning landmarks to
achieve high-accuracy with low runtime cost. These approaches, however, lack a
probabilistic interpretation. Furthermore, while most probabilistic models to
goal recognition assume that the recognizer has access to a prior probability
representing, for example, an agent's preferences, virtually no goal
recognition approach actually uses the prior in practice, simply assuming a
uniform prior. In this paper, we provide a model to both extend landmark-based
goal recognition with a probabilistic interpretation and allow the estimation
of such prior probability and its usage to compute posterior probabilities
after repeated interactions of observed agents. We empirically show that our
model can not only recognize goals effectively but also successfully infer the
correct prior probability distribution representing an agent's preferences.
</p>
<a href="http://arxiv.org/abs/2102.11791" target="_blank">arXiv:2102.11791</a> [<a href="http://arxiv.org/pdf/2102.11791" target="_blank">pdf</a>]

<h2>Data-driven analysis of central bank digital currency (CBDC) projects drivers. (arXiv:2102.11807v1 [cs.LG])</h2>
<h3>Toshiko Matsui, Daniel Perez</h3>
<p>In this paper, we use a variety of machine learning methods to quantify the
extent to which economic and technological factors are predictive of the
progression of Central Bank Digital Currencies (CBDC) within a country, using
as our measure of this progression the CBDC project index (CBDCPI). We find
that a financial development index is the most important feature for our model,
followed by the GDP per capita and an index of the voice and accountability of
the country's population. Our results are consistent with previous qualitative
research which finds that countries with a high degree of financial development
or digital infrastructure have more developed CBDC projects. Further, we obtain
robust results when predicting the CBDCPI at different points in time.
</p>
<a href="http://arxiv.org/abs/2102.11807" target="_blank">arXiv:2102.11807</a> [<a href="http://arxiv.org/pdf/2102.11807" target="_blank">pdf</a>]

<h2>Dynamic Neural Garments. (arXiv:2102.11811v1 [cs.CV])</h2>
<h3>Meng Zhang, Duygu Ceylan, Tuanfeng Wang, Niloy J. Mitra</h3>
<p>A vital task of the wider digital human effort is the creation of realistic
garments on digital avatars, both in the form of characteristic fold patterns
and wrinkles in static frames as well as richness of garment dynamics under
avatars' motion. Existing workflow of modeling, simulation, and rendering
closely replicates the physics behind real garments, but is tedious and
requires repeating most of the workflow under changes to characters' motion,
camera angle, or garment resizing. Although data-driven solutions exist, they
either focus on static scenarios or only handle dynamics of tight garments. We
present a solution that, at test time, takes in body joint motion to directly
produce realistic dynamic garment image sequences. Specifically, given the
target joint motion sequence of an avatar, we propose dynamic neural garments
to jointly simulate and render plausible dynamic garment appearance from an
unseen viewpoint. Technically, our solution generates a coarse garment proxy
sequence, learns deep dynamic features attached to this template, and neurally
renders the features to produce appearance changes such as folds, wrinkles, and
silhouettes. We demonstrate generalization behavior to both unseen motion and
unseen camera views. Further, our network can be fine-tuned to adopt to new
body shape and/or background images. We also provide comparisons against
existing neural rendering and image sequence translation approaches, and report
clear quantitative improvements.
</p>
<a href="http://arxiv.org/abs/2102.11811" target="_blank">arXiv:2102.11811</a> [<a href="http://arxiv.org/pdf/2102.11811" target="_blank">pdf</a>]

<h2>Online Stochastic Gradient Descent Learns Linear Dynamical Systems from A Single Trajectory. (arXiv:2102.11822v1 [cs.LG])</h2>
<h3>Navid Reyhanian, Jarvis Haupt</h3>
<p>This work investigates the problem of estimating the weight matrices of a
stable time-invariant linear dynamical system from a single sequence of noisy
measurements. We show that if the unknown weight matrices describing the system
are in Brunovsky canonical form, we can efficiently estimate the ground truth
unknown matrices of the system from a linear system of equations formulated
based on the transfer function of the system, using both online and offline
stochastic gradient descent (SGD) methods. Specifically, by deriving concrete
complexity bounds, we show that SGD converges linearly in expectation to any
arbitrary small Frobenius norm distance from the ground truth weights. To the
best of our knowledge, ours is the first work to establish linear convergence
characteristics for online and offline gradient-based iterative methods for
weight matrix estimation in linear dynamical systems from a single trajectory.
Extensive numerical tests verify that the performance of the proposed methods
is consistent with our theory, and show their superior performance relative to
existing state of the art methods.
</p>
<a href="http://arxiv.org/abs/2102.11822" target="_blank">arXiv:2102.11822</a> [<a href="http://arxiv.org/pdf/2102.11822" target="_blank">pdf</a>]

<h2>Interpretability in Contact-Rich Manipulation via Kinodynamic Images. (arXiv:2102.11825v1 [cs.RO])</h2>
<h3>Ioanna Mitsioni, Joonatan M&#xe4;ntt&#xe4;ri, Yiannis Karayiannidis, John Folkesson, Danica Kragic</h3>
<p>Deep Neural Networks (NNs) have been widely utilized in contact-rich
manipulation tasks to model the complicated contact dynamics. However, NN-based
models are often difficult to decipher which can lead to seemingly inexplicable
behaviors and unidentifiable failure cases. In this work, we address the
interpretability of NN-based models by introducing the kinodynamic images. We
propose a methodology that creates images from the kinematic and dynamic data
of a contact-rich manipulation task. Our formulation visually reflects the
task's state by encoding its kinodynamic variations and temporal evolution. By
using images as the state representation, we enable the application of
interpretability modules that were previously limited to vision-based tasks. We
use this representation to train Convolution-based Networks and we extract
interpretations of the model's decisions with Grad-CAM, a technique that
produces visual explanations. Our method is versatile and can be applied to any
classification problem using synchronous features in manipulation to visually
interpret which parts of the input drive the model's decisions and distinguish
its failure modes. We evaluate this approach on two examples of real-world
contact-rich manipulation: pushing and cutting, with known and unknown objects.
Finally, we demonstrate that our method enables both detailed visual
inspections of sequences in a task, as well as high-level evaluations of a
model's behavior and tendencies. Data and code for this work are available at
https://github.com/imitsioni/interpretable_manipulation.
</p>
<a href="http://arxiv.org/abs/2102.11825" target="_blank">arXiv:2102.11825</a> [<a href="http://arxiv.org/pdf/2102.11825" target="_blank">pdf</a>]

<h2>Solving high-dimensional parabolic PDEs using the tensor train format. (arXiv:2102.11830v1 [stat.ML])</h2>
<h3>Lorenz Richter, Leon Sallandt, Nikolas N&#xfc;sken</h3>
<p>High-dimensional partial differential equations (PDEs) are ubiquitous in
economics, science and engineering. However, their numerical treatment poses
formidable challenges since traditional grid-based methods tend to be
frustrated by the curse of dimensionality. In this paper, we argue that tensor
trains provide an appealing approximation framework for parabolic PDEs: the
combination of reformulations in terms of backward stochastic differential
equations and regression-type methods in the tensor format holds the promise of
leveraging latent low-rank structures enabling both compression and efficient
computation. Following this paradigm, we develop novel iterative schemes,
involving either explicit and fast or implicit and accurate updates. We
demonstrate in a number of examples that our methods achieve a favorable
trade-off between accuracy and computational efficiency in comparison with
state-of-the-art neural network based approaches.
</p>
<a href="http://arxiv.org/abs/2102.11830" target="_blank">arXiv:2102.11830</a> [<a href="http://arxiv.org/pdf/2102.11830" target="_blank">pdf</a>]

<h2>Page Layout Analysis System for Unconstrained Historic Documents. (arXiv:2102.11838v1 [cs.CV])</h2>
<h3>Old&#x159;ich Kodym, Michal Hradi&#x161;</h3>
<p>Extraction of text regions and individual text lines from historic documents
is necessary for automatic transcription. We propose extending a CNN-based text
baseline detection system by adding line height and text block boundary
predictions to the model output, allowing the system to extract more
comprehensive layout information. We also show that pixel-wise text orientation
prediction can be used for processing documents with multiple text
orientations. We demonstrate that the proposed method performs well on the cBAD
baseline detection dataset. Additionally, we benchmark the method on newly
introduced PERO layout dataset which we also make public.
</p>
<a href="http://arxiv.org/abs/2102.11838" target="_blank">arXiv:2102.11838</a> [<a href="http://arxiv.org/pdf/2102.11838" target="_blank">pdf</a>]

<h2>Convergence rates for gradient descent in the training of overparameterized artificial neural networks with biases. (arXiv:2102.11840v1 [cs.LG])</h2>
<h3>Arnulf Jentzen, Timo Kr&#xf6;ger</h3>
<p>In recent years, artificial neural networks have developed into a powerful
tool for dealing with a multitude of problems for which classical solution
approaches reach their limits. However, it is still unclear why randomly
initialized gradient descent optimization algorithms, such as the well-known
batch gradient descent, are able to achieve zero training loss in many
situations even though the objective function is non-convex and non-smooth. One
of the most promising approaches to solving this problem in the field of
supervised learning is the analysis of gradient descent optimization in the
so-called overparameterized regime. In this article we provide a further
contribution to this area of research by considering overparameterized
fully-connected rectified artificial neural networks with biases. Specifically,
we show that for a fixed number of training data the mean squared error using
batch gradient descent optimization applied to such a randomly initialized
artificial neural network converges to zero at a linear convergence rate as
long as the width of the artificial neural network is large enough, the
learning rate is small enough, and the training input data are pairwise
linearly independent.
</p>
<a href="http://arxiv.org/abs/2102.11840" target="_blank">arXiv:2102.11840</a> [<a href="http://arxiv.org/pdf/2102.11840" target="_blank">pdf</a>]

<h2>Learning with User-Level Privacy. (arXiv:2102.11845v1 [cs.LG])</h2>
<h3>Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza, Mehryar Mohri, Ananda Theertha Suresh</h3>
<p>We propose and analyze algorithms to solve a range of learning tasks under
user-level differential privacy constraints. Rather than guaranteeing only the
privacy of individual samples, user-level DP protects a user's entire
contribution ($m \ge 1$ samples), providing more stringent but more realistic
protection against information leaks. We show that for high-dimensional mean
estimation, empirical risk minimization with smooth losses, stochastic convex
optimization, and learning hypothesis class with finite metric entropy, the
privacy cost decreases as $O(1/\sqrt{m})$ as users provide more samples. In
contrast, when increasing the number of users $n$, the privacy cost decreases
at a faster $O(1/n)$ rate. We complement these results with lower bounds
showing the worst-case optimality of our algorithm for mean estimation and
stochastic convex optimization. Our algorithms rely on novel techniques for
private mean estimation in arbitrary dimension with error scaling as the
concentration radius $\tau$ of the distribution rather than the entire range.
Under uniform convergence, we derive an algorithm that privately answers a
sequence of $K$ adaptively chosen queries with privacy cost proportional to
$\tau$, and apply it to solve the learning tasks we consider.
</p>
<a href="http://arxiv.org/abs/2102.11845" target="_blank">arXiv:2102.11845</a> [<a href="http://arxiv.org/pdf/2102.11845" target="_blank">pdf</a>]

<h2>An Explainable Artificial Intelligence Approach for Unsupervised Fault Detection and Diagnosis in Rotating Machinery. (arXiv:2102.11848v1 [cs.AI])</h2>
<h3>Lucas Costa Brito, Gian Antonio Susto, Jorge Nei Brito, Marcus Antonio Viana Duarte</h3>
<p>The monitoring of rotating machinery is an essential task in today's
production processes. Currently, several machine learning and deep
learning-based modules have achieved excellent results in fault detection and
diagnosis. Nevertheless, to further increase user adoption and diffusion of
such technologies, users and human experts must be provided with explanations
and insights by the modules. Another issue is related, in most cases, with the
unavailability of labeled historical data that makes the use of supervised
models unfeasible. Therefore, a new approach for fault detection and diagnosis
in rotating machinery is here proposed. The methodology consists of three
parts: feature extraction, fault detection and fault diagnosis. In the first
part, the vibration features in the time and frequency domains are extracted.
Secondly, in the fault detection, the presence of fault is verified in an
unsupervised manner based on anomaly detection algorithms. The modularity of
the methodology allows different algorithms to be implemented. Finally, in
fault diagnosis, Shapley Additive Explanations (SHAP), a technique to interpret
black-box models, is used. Through the feature importance ranking obtained by
the model explainability, the fault diagnosis is performed. Two tools for
diagnosis are proposed, namely: unsupervised classification and root cause
analysis. The effectiveness of the proposed approach is shown on three datasets
containing different mechanical faults in rotating machinery. The study also
presents a comparison between models used in machine learning explainability:
SHAP and Local Depth-based Feature Importance for the Isolation Forest (Local-
DIFFI). Lastly, an analysis of several state-of-art anomaly detection
algorithms in rotating machinery is included.
</p>
<a href="http://arxiv.org/abs/2102.11848" target="_blank">arXiv:2102.11848</a> [<a href="http://arxiv.org/pdf/2102.11848" target="_blank">pdf</a>]

<h2>Deep Convolutional Neural Networks with Unitary Weights. (arXiv:2102.11855v1 [cs.LG])</h2>
<h3>Hao-Yuan Chang, Kang L. Wang (University of California, Los Angeles)</h3>
<p>While normalizations aim to fix the exploding and vanishing gradient problem
in deep neural networks, they have drawbacks in speed or accuracy because of
their dependency on the data set statistics. This work is a comprehensive study
of a novel method based on unitary synaptic weights derived from Lie Group to
construct intrinsically stable neural systems. Here we show that unitary
convolutional neural networks deliver up to 32% faster inference speeds while
maintaining competitive prediction accuracy. Unlike prior arts restricted to
square synaptic weights, we expand the unitary networks to weights of any size
and dimension.
</p>
<a href="http://arxiv.org/abs/2102.11855" target="_blank">arXiv:2102.11855</a> [<a href="http://arxiv.org/pdf/2102.11855" target="_blank">pdf</a>]

<h2>Meta-Learned Attribute Self-Gating for Continual Generalized Zero-Shot Learning. (arXiv:2102.11856v1 [cs.CV])</h2>
<h3>Vinay Kumar Verma, Kevin Liang, Nikhil Mehta, Lawrence Carin</h3>
<p>Zero-shot learning (ZSL) has been shown to be a promising approach to
generalizing a model to categories unseen during training by leveraging class
attributes, but challenges still remain. Recently, methods using generative
models to combat bias towards classes seen during training have pushed the
state of the art of ZSL, but these generative models can be slow or
computationally expensive to train. Additionally, while many previous ZSL
methods assume a one-time adaptation to unseen classes, in reality, the world
is always changing, necessitating a constant adjustment for deployed models.
Models unprepared to handle a sequential stream of data are likely to
experience catastrophic forgetting. We propose a meta-continual zero-shot
learning (MCZSL) approach to address both these issues. In particular, by
pairing self-gating of attributes and scaled class normalization with
meta-learning based training, we are able to outperform state-of-the-art
results while being able to train our models substantially faster
($&gt;100\times$) than expensive generative-based approaches. We demonstrate this
by performing experiments on five standard ZSL datasets (CUB, aPY, AWA1, AWA2
and SUN) in both generalized zero-shot learning and generalized continual
zero-shot learning settings.
</p>
<a href="http://arxiv.org/abs/2102.11856" target="_blank">arXiv:2102.11856</a> [<a href="http://arxiv.org/pdf/2102.11856" target="_blank">pdf</a>]

<h2>STEP: Segmenting and Tracking Every Pixel. (arXiv:2102.11859v1 [cs.CV])</h2>
<h3>Mark Weber, Jun Xie, Maxwell Collins, Yukun Zhu, Paul Voigtlaender, Hartwig Adam, Bradley Green, Andreas Geiger, Bastian Leibe, Daniel Cremers, Aljosa Osep, Laura Leal-Taixe, Liang-Chieh Chen</h3>
<p>In this paper, we tackle video panoptic segmentation, a task that requires
assigning semantic classes and track identities to all pixels in a video. To
study this important problem in a setting that requires a continuous
interpretation of sensory data, we present a new benchmark: Segmenting and
Tracking Every Pixel (STEP), encompassing two datasets, KITTI-STEP, and
MOTChallenge-STEP together with a new evaluation metric. Our work is the first
that targets this task in a real-world setting that requires dense
interpretation in both spatial and temporal domains. As the ground-truth for
this task is difficult and expensive to obtain, existing datasets are either
constructed synthetically or only sparsely annotated within short video clips.
By contrast, our datasets contain long video sequences, providing challenging
examples and a test-bed for studying long-term pixel-precise segmentation and
tracking. For measuring the performance, we propose a novel evaluation metric
Segmentation and Tracking Quality (STQ) that fairly balances semantic and
tracking aspects of this task and is suitable for evaluating sequences of
arbitrary length. We will make our datasets, metric, and baselines publicly
available.
</p>
<a href="http://arxiv.org/abs/2102.11859" target="_blank">arXiv:2102.11859</a> [<a href="http://arxiv.org/pdf/2102.11859" target="_blank">pdf</a>]

<h2>Automated Discovery of Adaptive Attacks on Adversarial Defenses. (arXiv:2102.11860v1 [cs.LG])</h2>
<h3>Chengyuan Yao, Pavol Bielik, Petar Tsankov, Martin Vechev</h3>
<p>Reliable evaluation of adversarial defenses is a challenging task, currently
limited to an expert who manually crafts attacks that exploit the defense's
inner workings, or to approaches based on ensemble of fixed attacks, none of
which may be effective for the specific defense at hand. Our key observation is
that custom attacks are composed from a set of reusable building blocks, such
as fine-tuning relevant attack parameters, network transformations, and custom
loss functions. Based on this observation, we present an extensible framework
that defines a search space over these reusable building blocks and
automatically discovers an effective attack on a given model with an unknown
defense by searching over suitable combinations of these blocks. We evaluated
our framework on 23 adversarial defenses and showed it outperforms AutoAttack,
the current state-of-the-art tool for reliable evaluation of adversarial
defenses: our discovered attacks are either stronger, producing 3.0%-50.8%
additional adversarial examples (10 cases), or are typically 2x faster while
enjoying similar adversarial robustness (13 cases).
</p>
<a href="http://arxiv.org/abs/2102.11860" target="_blank">arXiv:2102.11860</a> [<a href="http://arxiv.org/pdf/2102.11860" target="_blank">pdf</a>]

<h2>Probabilistic Spatial Analysis in Quantitative Microscopy with Uncertainty-Aware Cell Detection using Deep Bayesian Regression of Density Maps. (arXiv:2102.11865v1 [cs.CV])</h2>
<h3>Alvaro Gomariz, Tiziano Portenier, C&#xe9;sar Nombela-Arrieta, Orcun Goksel</h3>
<p>3D microscopy is key in the investigation of diverse biological systems, and
the ever increasing availability of large datasets demands automatic cell
identification methods that not only are accurate, but also can imply the
uncertainty in their predictions to inform about potential errors and hence
confidence in conclusions using them. While conventional deep learning methods
often yield deterministic results, advances in deep Bayesian learning allow for
accurate predictions with a probabilistic interpretation in numerous image
classification and segmentation tasks. It is however nontrivial to extend such
Bayesian methods to cell detection, which requires specialized learning
frameworks. In particular, regression of density maps is a popular successful
approach for extracting cell coordinates from local peaks in a postprocessing
step, which hinders any meaningful probabilistic output. We herein propose a
deep learning-based cell detection framework that can operate on large
microscopy images and outputs desired probabilistic predictions by (i)
integrating Bayesian techniques for the regression of uncertainty-aware density
maps, where peak detection can be applied to generate cell proposals, and (ii)
learning a mapping from the numerous proposals to a probabilistic space that is
calibrated, i.e. accurately represents the chances of a successful prediction.
Utilizing such calibrated predictions, we propose a probabilistic spatial
analysis with Monte-Carlo sampling. We demonstrate this in revising an existing
description of the distribution of a mesenchymal stromal cell type within the
bone marrow, where our proposed methods allow us to reveal spatial patterns
that are otherwise undetectable. Introducing such probabilistic analysis in
quantitative microscopy pipelines will allow for reporting confidence intervals
for testing biological hypotheses of spatial distributions.
</p>
<a href="http://arxiv.org/abs/2102.11865" target="_blank">arXiv:2102.11865</a> [<a href="http://arxiv.org/pdf/2102.11865" target="_blank">pdf</a>]

<h2>Doubly Robust Off-Policy Actor-Critic: Convergence and Optimality. (arXiv:2102.11866v1 [cs.LG])</h2>
<h3>Tengyu Xu, Zhuoran Yang, Zhaoran Wang, Yingbin Liang</h3>
<p>Designing off-policy reinforcement learning algorithms is typically a very
challenging task, because a desirable iteration update often involves an
expectation over an on-policy distribution. Prior off-policy actor-critic (AC)
algorithms have introduced a new critic that uses the density ratio for
adjusting the distribution mismatch in order to stabilize the convergence, but
at the cost of potentially introducing high biases due to the estimation errors
of both the density ratio and value function. In this paper, we develop a
doubly robust off-policy AC (DR-Off-PAC) for discounted MDP, which can take
advantage of learned nuisance functions to reduce estimation errors. Moreover,
DR-Off-PAC adopts a single timescale structure, in which both actor and critics
are updated simultaneously with constant stepsize, and is thus more sample
efficient than prior algorithms that adopt either two timescale or nested-loop
structure. We study the finite-time convergence rate and characterize the
sample complexity for DR-Off-PAC to attain an $\epsilon$-accurate optimal
policy. We also show that the overall convergence of DR-Off-PAC is doubly
robust to the approximation errors that depend only on the expressive power of
approximation functions. To the best of our knowledge, our study establishes
the first overall sample complexity analysis for a single time-scale off-policy
AC algorithm.
</p>
<a href="http://arxiv.org/abs/2102.11866" target="_blank">arXiv:2102.11866</a> [<a href="http://arxiv.org/pdf/2102.11866" target="_blank">pdf</a>]

<h2>UnsupervisedR&R: Unsupervised Point Cloud Registration via Differentiable Rendering. (arXiv:2102.11870v1 [cs.CV])</h2>
<h3>Mohamed El Banani, Luya Gao, Justin Johnson</h3>
<p>Aligning partial views of a scene into a single whole is essential to
understanding one's environment and is a key component of numerous robotics
tasks such as SLAM and SfM. Recent approaches have proposed end-to-end systems
that can outperform traditional methods by leveraging pose supervision.
However, with the rising prevalence of cameras with depth sensors, we can
expect a new stream of raw RGB-D data without the annotations needed for
supervision. We propose UnsupervisedR&amp;R: an end-to-end unsupervised approach to
learning point cloud registration from raw RGB-D video. The key idea is to
leverage differentiable alignment and rendering to enforce photometric and
geometric consistency between frames. We evaluate our approach on indoor scene
datasets and find that we outperform existing traditional approaches with
classic and learned descriptors while being competitive with supervised
geometric point cloud registration approaches.
</p>
<a href="http://arxiv.org/abs/2102.11870" target="_blank">arXiv:2102.11870</a> [<a href="http://arxiv.org/pdf/2102.11870" target="_blank">pdf</a>]

<h2>CAC: A Clustering Based Framework for Classification. (arXiv:2102.11872v1 [cs.LG])</h2>
<h3>Shivin Srivastava, Siddharth Bhatia, Lingxiao Huang, Lim Jun Heng, Kenji Kawaguchi, Vaibhav Rajan</h3>
<p>In data containing heterogeneous subpopulations, classification performance
benefits from incorporating the knowledge of cluster structure in the
classifier. Previous methods for such combined clustering and classification
either are classifier-specific and not generic or independently perform
clustering and classifier training, which may not form clusters that can
potentially benefit classifier performance. The question of how to perform
clustering to improve the performance of classifiers trained on the clusters
has received scant attention in previous literature despite its importance in
several real-world applications. In this paper, we theoretically analyze when
and how clustering may help in obtaining accurate classifiers. We design a
simple, efficient, and generic framework called Classification Aware Clustering
(CAC), to find clusters that are well suited for being used as training
datasets by classifiers for each underlying subpopulation. Our experiments on
synthetic and real benchmark datasets demonstrate the efficacy of CAC over
previous methods for combined clustering and classification.
</p>
<a href="http://arxiv.org/abs/2102.11872" target="_blank">arXiv:2102.11872</a> [<a href="http://arxiv.org/pdf/2102.11872" target="_blank">pdf</a>]

<h2>Improved Generalization Bounds for Robust Learning. (arXiv:1810.02180v4 [cs.LG] UPDATED)</h2>
<h3>Idan Attias, Aryeh Kontorovich, Yishay Mansour</h3>
<p>We consider a model of robust learning in an adversarial environment. The
learner gets uncorrupted training data with access to possible corruptions that
may be effected by the adversary during testing. The learner's goal is to build
a robust classifier, which will be tested on future adversarial examples. The
adversary is limited to $k$ possible corruptions for each input. We model the
learner-adversary interaction as a zero-sum game. This model is closely related
to the adversarial examples model of Schmidt et al. (2018); Madry et al.
(2017). Our main results consist of generalization bounds for the binary and
multiclass classification, as well as the real-valued case (regression). For
the binary classification setting, we both tighten the generalization bound of
Feige, Mansour, and Schapire (2015), and are also able to handle infinite
hypothesis classes. The sample complexity is improved from
$O(\frac{1}{\epsilon^4}\log(\frac{|\mathcal{H}|}{\delta}))$ to
$O\big(\frac{1}{\epsilon^2}(\sqrt{k
\mathrm{VC}(\mathcal{H})}\log^{\frac{3}{2}+\alpha}(k\mathrm{VC}(\mathcal{H}))+\log(\frac{1}{\delta})\big)$
for any $\alpha &gt; 0$. Additionally, we extend the algorithm and generalization
bound from the binary to the multiclass and real-valued cases. Along the way,
we obtain results on fat-shattering dimension and Rademacher complexity of
$k$-fold maxima over function classes; these may be of independent interest.

For binary classification, the algorithm of Feige et al. (2015) uses a regret
minimization algorithm and an ERM oracle as a black box; we adapt it for the
multiclass and regression settings. The algorithm provides us with near-optimal
policies for the players on a given training sample.
</p>
<a href="http://arxiv.org/abs/1810.02180" target="_blank">arXiv:1810.02180</a> [<a href="http://arxiv.org/pdf/1810.02180" target="_blank">pdf</a>]

<h2>Tuning Fairness by Balancing Target Labels. (arXiv:1810.05598v5 [stat.ML] UPDATED)</h2>
<h3>Thomas Kehrenberg, Zexun Chen, Novi Quadrianto</h3>
<p>The issue of fairness in machine learning models has recently attracted a lot
of attention as ensuring it will ensure continued confidence of the general
public in the deployment of machine learning systems. We focus on mitigating
the harm incurred by a biased machine learning system that offers better
outputs (e.g. loans, job interviews) for certain groups than for others. We
show that bias in the output can naturally be controlled in probabilistic
models by introducing a latent target output. This formulation has several
advantages: first, it is a unified framework for several notions of group
fairness such as Demographic Parity and Equality of Opportunity; second, it is
expressed as a marginalisation instead of a constrained problem; and third, it
allows the encoding of our knowledge of what unbiased outputs should be.
Practically, the second allows us to avoid unstable constrained optimisation
procedures and to reuse off-the-shelf toolboxes. The latter translates to the
ability to control the level of fairness by directly varying fairness target
rates. In contrast, existing approaches rely on intermediate, arguably
unintuitive, control parameters such as covariance thresholds.
</p>
<a href="http://arxiv.org/abs/1810.05598" target="_blank">arXiv:1810.05598</a> [<a href="http://arxiv.org/pdf/1810.05598" target="_blank">pdf</a>]

<h2>Face morphing detection in the presence of printing/scanning and heterogeneous image sources. (arXiv:1901.08811v3 [cs.CV] UPDATED)</h2>
<h3>Matteo Ferrara, Annalisa Franco, Davide Maltoni</h3>
<p>Face morphing represents nowadays a big security threat in the context of
electronic identity documents as well as an interesting challenge for
researchers in the field of face recognition. Despite of the good performance
obtained by state-of-the-art approaches on digital images, no satisfactory
solutions have been identified so far to deal with cross-database testing and
printed-scanned images (typically used in many countries for document issuing).
In this work, novel approaches are proposed to train Deep Neural Networks for
morphing detection: in particular generation of simulated printed-scanned
images together with other data augmentation strategies and pre-training on
large face recognition datasets, allowed to reach state-of-the-art accuracy on
challenging datasets from heterogeneous image sources.
</p>
<a href="http://arxiv.org/abs/1901.08811" target="_blank">arXiv:1901.08811</a> [<a href="http://arxiv.org/pdf/1901.08811" target="_blank">pdf</a>]

<h2>Analyzing Deep Neural Networks with Symbolic Propagation: Towards Higher Precision and Faster Verification. (arXiv:1902.09866v2 [cs.LG] UPDATED)</h2>
<h3>Jianlin Li, Pengfei Yang, Jiangchao Liu, Liqian Chen, Xiaowei Huang, Lijun Zhang</h3>
<p>Deep neural networks (DNNs) have been shown lack of robustness for the
vulnerability of their classification to small perturbations on the inputs.
This has led to safety concerns of applying DNNs to safety-critical domains.
Several verification approaches have been developed to automatically prove or
disprove safety properties of DNNs. However, these approaches suffer from
either the scalability problem, i.e., only small DNNs can be handled, or the
precision problem, i.e., the obtained bounds are loose. This paper improves on
a recent proposal of analyzing DNNs through the classic abstract interpretation
technique, by a novel symbolic propagation technique. More specifically, the
values of neurons are represented symbolically and propagated forwardly from
the input layer to the output layer, on top of abstract domains. We show that
our approach can achieve significantly higher precision and thus can prove more
properties than using only abstract domains. Moreover, we show that the bounds
derived from our approach on the hidden neurons, when applied to a
state-of-the-art SMT based verification tool, can improve its performance. We
implement our approach into a software tool and validate it over a few DNNs
trained on benchmark datasets such as MNIST, etc.
</p>
<a href="http://arxiv.org/abs/1902.09866" target="_blank">arXiv:1902.09866</a> [<a href="http://arxiv.org/pdf/1902.09866" target="_blank">pdf</a>]

<h2>Distributed Differentially Private Computation of Functions with Correlated Noise. (arXiv:1904.10059v3 [cs.LG] UPDATED)</h2>
<h3>Hafiz Imtiaz, Jafar Mohammadi, Anand D. Sarwate</h3>
<p>Many applications of machine learning, such as human health research, involve
processing private or sensitive information. Privacy concerns may impose
significant hurdles to collaboration in scenarios where there are multiple
sites holding data and the goal is to estimate properties jointly across all
datasets. Differentially private decentralized algorithms can provide strong
privacy guarantees. However, the accuracy of the joint estimates may be poor
when the datasets at each site are small. This paper proposes a new framework,
Correlation Assisted Private Estimation (CAPE), for designing
privacy-preserving decentralized algorithms with better accuracy guarantees in
an honest-but-curious model. CAPE can be used in conjunction with the
functional mechanism for statistical and machine learning optimization
problems. A tighter characterization of the functional mechanism is provided
that allows CAPE to achieve the same performance as a centralized algorithm in
the decentralized setting using all datasets. Empirical results on regression
and neural network problems for both synthetic and real datasets show that
differentially private methods can be competitive with non-private algorithms
in many scenarios of interest.
</p>
<a href="http://arxiv.org/abs/1904.10059" target="_blank">arXiv:1904.10059</a> [<a href="http://arxiv.org/pdf/1904.10059" target="_blank">pdf</a>]

<h2>Bad Global Minima Exist and SGD Can Reach Them. (arXiv:1906.02613v2 [cs.LG] UPDATED)</h2>
<h3>Shengchao Liu, Dimitris Papailiopoulos, Dimitris Achlioptas</h3>
<p>Several works have aimed to explain why overparameterized neural networks
generalize well when trained by Stochastic Gradient Descent (SGD). The
consensus explanation that has emerged credits the randomized nature of SGD for
the bias of the training process towards low-complexity models and, thus, for
implicit regularization. We take a careful look at this explanation in the
context of image classification with common deep neural network architectures.
We find that if we do not regularize \emph{explicitly}, then SGD can be easily
made to converge to poorly-generalizing, high-complexity models: all it takes
is to first train on a random labeling on the data, before switching to
properly training with the correct labels. In contrast, we find that in the
presence of explicit regularization, pretraining with random labels has no
detrimental effect on SGD. We believe that our results give evidence that
explicit regularization plays a far more important role in the success of
overparameterized neural networks than what has been understood until now.
Specifically, by penalizing complicated models independently of their fit to
the data, regularization affects training dynamics also far away from optima,
making simple models that fit the data well discoverable by local methods, such
as SGD.
</p>
<a href="http://arxiv.org/abs/1906.02613" target="_blank">arXiv:1906.02613</a> [<a href="http://arxiv.org/pdf/1906.02613" target="_blank">pdf</a>]

<h2>Sparse regular variation. (arXiv:1907.00686v5 [stat.ML] UPDATED)</h2>
<h3>Meyer Nicolas (LPSM (UMR\_8001)), Olivier Wintenberger (LPSM (UMR\_8001))</h3>
<p>Regular variation provides a convenient theoretical framework to study large
events. In the multivariate setting, the dependence structure of the positive
extremes is characterized by a measure - the spectral measure - defined on the
positive orthant of the unit sphere. This measure gathers information on the
localization of extreme events and has often a sparse support since severe
events do not simultaneously occur in all directions. However, it is defined
through weak convergence which does not provide a natural way to capture this
sparsity structure.In this paper, we introduce the notion of sparse regular
variation which allows to better learn the dependence structure of extreme
events. This concept is based on the Euclidean projection onto the simplex for
which efficient algorithms are known. We prove that under mild assumptions
sparse regular variation and regular variation are two equivalent notions and
we establish several results for sparsely regularly varying random vectors.
Finally, we illustrate on numerical examples how this new concept allows one to
detect extremal directions.
</p>
<a href="http://arxiv.org/abs/1907.00686" target="_blank">arXiv:1907.00686</a> [<a href="http://arxiv.org/pdf/1907.00686" target="_blank">pdf</a>]

<h2>LassoNet: A Neural Network with Feature Sparsity. (arXiv:1907.12207v9 [stat.ML] UPDATED)</h2>
<h3>Ismael Lemhadri, Feng Ruan, Louis Abraham, Robert Tibshirani</h3>
<p>Much work has been done recently to make neural networks more interpretable,
and one obvious approach is to arrange for the network to use only a subset of
the available features. In linear models, Lasso (or $\ell_1$-regularized)
regression assigns zero weights to the most irrelevant or redundant features,
and is widely used in data science. However the Lasso only applies to linear
models. Here we introduce LassoNet, a neural network framework with global
feature selection. Our approach enforces a hierarchy: specifically a feature
can participate in a hidden unit only if its linear representative is active.
Unlike other approaches to feature selection for neural nets, our method uses a
modified objective function with constraints, and so integrates feature
selection with the parameter learning directly. As a result, it delivers an
entire regularization path of solutions with a range of feature sparsity. On
systematic experiments, LassoNet significantly outperforms state-of-the-art
methods for feature selection and regression. The LassoNet method uses
projected proximal gradient descent, and generalizes directly to deep networks.
It can be implemented by adding just a few lines of code to a standard neural
network.
</p>
<a href="http://arxiv.org/abs/1907.12207" target="_blank">arXiv:1907.12207</a> [<a href="http://arxiv.org/pdf/1907.12207" target="_blank">pdf</a>]

<h2>Challenges in Markov chain Monte Carlo for Bayesian neural networks. (arXiv:1910.06539v4 [stat.ML] UPDATED)</h2>
<h3>Theodore Papamarkou, Jacob Hinkle, M. Todd Young, David Womble</h3>
<p>Markov chain Monte Carlo (MCMC) methods have not been broadly adopted in
Bayesian neural networks (BNNs). This paper initially reviews the main
challenges in sampling from the parameter posterior of a neural network via
MCMC. Such challenges culminate to lack of convergence to the parameter
posterior. Nevertheless, this paper shows that a non-converged Markov chain,
generated via MCMC sampling from the parameter space of a neural network, can
yield via Bayesian marginalization a valuable predictive posterior of the
output of the neural network. Classification examples based on multilayer
perceptrons showcase highly accurate predictive posteriors. The postulate of
limited scope for MCMC developments in BNNs is partially valid; an
asymptotically exact parameter posterior seems less plausible, yet an accurate
predictive posterior is a tenable research avenue.
</p>
<a href="http://arxiv.org/abs/1910.06539" target="_blank">arXiv:1910.06539</a> [<a href="http://arxiv.org/pdf/1910.06539" target="_blank">pdf</a>]

<h2>Regularization Matters in Policy Optimization -- An Empirical Study on Continuous Control. (arXiv:1910.09191v4 [cs.LG] UPDATED)</h2>
<h3>Zhuang Liu, Xuanlin Li, Bingyi Kang, Trevor Darrell</h3>
<p>Deep Reinforcement Learning (Deep RL) has been receiving increasingly more
attention thanks to its encouraging performance on a variety of control tasks.
Yet, conventional regularization techniques in training neural networks (e.g.,
$L_2$ regularization, dropout) have been largely ignored in RL methods,
possibly because agents are typically trained and evaluated in the same
environment, and because the deep RL community focuses more on high-level
algorithm designs. In this work, we present the first comprehensive study of
regularization techniques with multiple policy optimization algorithms on
continuous control tasks. Interestingly, we find conventional regularization
techniques on the policy networks can often bring large improvement, especially
on harder tasks. Our findings are shown to be robust against training
hyperparameter variations. We also compare these techniques with the more
widely used entropy regularization. In addition, we study regularizing
different components and find that only regularizing the policy network is
typically the best. We further analyze why regularization may help
generalization in RL from four perspectives - sample complexity, reward
distribution, weight norm, and noise robustness. We hope our study provides
guidance for future practices in regularizing policy optimization algorithms.
Our code is available at https://github.com/xuanlinli17/iclr2021_rlreg .
</p>
<a href="http://arxiv.org/abs/1910.09191" target="_blank">arXiv:1910.09191</a> [<a href="http://arxiv.org/pdf/1910.09191" target="_blank">pdf</a>]

<h2>Improved Differentially Private Decentralized Source Separation for fMRI Data. (arXiv:1910.12913v2 [stat.ML] UPDATED)</h2>
<h3>Hafiz Imtiaz, Jafar Mohammadi, Rogers Silva, Bradley Baker, Sergey M. Plis, Anand D. Sarwate, Vince Calhoun</h3>
<p>Blind source separation algorithms such as independent component analysis
(ICA) are widely used in the analysis of neuroimaging data. In order to
leverage larger sample sizes, different data holders/sites may wish to
collaboratively learn feature representations. However, such datasets are often
privacy-sensitive, precluding centralized analyses that pool the data at a
single site. In this work, we propose a differentially private algorithm for
performing ICA in a decentralized data setting. Conventional approaches to
decentralized differentially private algorithms may introduce too much noise
due to the typically small sample sizes at each site. We propose a novel
protocol that uses correlated noise to remedy this problem. We show that our
algorithm outperforms existing approaches on synthetic and real neuroimaging
datasets and demonstrate that it can sometimes reach the same level of utility
as the corresponding non-private algorithm. This indicates that it is possible
to have meaningful utility while preserving privacy.
</p>
<a href="http://arxiv.org/abs/1910.12913" target="_blank">arXiv:1910.12913</a> [<a href="http://arxiv.org/pdf/1910.12913" target="_blank">pdf</a>]

<h2>Self-Supervised Learning For Few-Shot Image Classification. (arXiv:1911.06045v3 [cs.CV] UPDATED)</h2>
<h3>Da Chen, Yuefeng Chen, Yuhong Li, Feng Mao, Yuan He, Hui Xue</h3>
<p>Few-shot image classification aims to classify unseen classes with limited
labelled samples. Recent works benefit from the meta-learning process with
episodic tasks and can fast adapt to class from training to testing. Due to the
limited number of samples for each task, the initial embedding network for
meta-learning becomes an essential component and can largely affect the
performance in practice. To this end, most of the existing methods highly rely
on the efficient embedding network. Due to the limited labelled data, the scale
of embedding network is constrained under a supervised learning(SL) manner
which becomes a bottleneck of the few-shot learning methods. In this paper, we
proposed to train a more generalized embedding network with self-supervised
learning (SSL) which can provide robust representation for downstream tasks by
learning from the data itself. We evaluate our work by extensive comparisons
with previous baseline methods on two few-shot classification datasets ({\em
i.e.,} MiniImageNet and CUB) and achieve better performance over baselines.
Tests on four datasets in cross-domain few-shot learning classification show
that the proposed method achieves state-of-the-art results and further prove
the robustness of the proposed model. Our code is available at
\hyperref[https://github.com/phecy/SSL-FEW-SHOT.]{https://github.com/phecy/SSL-FEW-SHOT.}
</p>
<a href="http://arxiv.org/abs/1911.06045" target="_blank">arXiv:1911.06045</a> [<a href="http://arxiv.org/pdf/1911.06045" target="_blank">pdf</a>]

<h2>Resilience of Supervised Learning Algorithms to Discriminatory Data Perturbations. (arXiv:1912.08189v3 [cs.LG] UPDATED)</h2>
<h3>Przemyslaw A. Grabowicz, Nicholas Perello, Kenta Takatsu</h3>
<p>Discrimination is a focal concern in supervised learning algorithms
augmenting human decision-making. These systems are trained using historical
data, which may have been tainted by discrimination, and may learn biases
against the protected groups. An important question is how to train models
without propagating discrimination. In this study, we i) define and model
discrimination as perturbations of a data-generating process and show how
discrimination can be induced via attributes correlated with the protected
attributes; ii) introduce a measure of resilience of a supervised learning
algorithm to potentially discriminatory data perturbations, iii) propose a
novel supervised learning algorithm that inhibits discrimination, and iv) show
that it is more resilient to discriminatory perturbations in synthetic and
real-world datasets than state-of-the-art learning algorithms. The proposed
method can be used with general supervised learning algorithms and avoids
inducement of discrimination, while maximizing model accuracy.
</p>
<a href="http://arxiv.org/abs/1912.08189" target="_blank">arXiv:1912.08189</a> [<a href="http://arxiv.org/pdf/1912.08189" target="_blank">pdf</a>]

<h2>Confidence Scores Make Instance-dependent Label-noise Learning Possible. (arXiv:2001.03772v2 [cs.LG] UPDATED)</h2>
<h3>Antonin Berthon, Bo Han, Gang Niu, Tongliang Liu, Masashi Sugiyama</h3>
<p>In learning with noisy labels, for every instance, its label can randomly
walk to other classes following a transition distribution which is named a
noise model. Well-studied noise models are all instance-independent, namely,
the transition depends only on the original label but not the instance itself,
and thus they are less practical in the wild. Fortunately, methods based on
instance-dependent noise have been studied, but most of them have to rely on
strong assumptions on the noise models. To alleviate this issue, we introduce
confidence-scored instance-dependent noise (CSIDN), where each instance-label
pair is equipped with a confidence score. We find with the help of confidence
scores, the transition distribution of each instance can be approximately
estimated. Similarly to the powerful forward correction for
instance-independent noise, we propose a novel instance-level forward
correction for CSIDN. We demonstrate the utility and effectiveness of our
method through multiple experiments under synthetic label noise and real-world
unknown noise.
</p>
<a href="http://arxiv.org/abs/2001.03772" target="_blank">arXiv:2001.03772</a> [<a href="http://arxiv.org/pdf/2001.03772" target="_blank">pdf</a>]

<h2>A Deterministic Streaming Sketch for Ridge Regression. (arXiv:2002.02013v3 [cs.LG] UPDATED)</h2>
<h3>Benwei Shi, Jeff M. Phillips</h3>
<p>We provide a deterministic space-efficient algorithm for estimating ridge
regression. For $n$ data points with $d$ features and a large enough
regularization parameter, we provide a solution within $\varepsilon$ L$_2$
error using only $O(d/\varepsilon)$ space. This is the first $o(d^2)$ space
deterministic streaming algorithm with guaranteed solution error and risk bound
for this classic problem. The algorithm sketches the covariance matrix by
variants of Frequent Directions, which implies it can operate in insertion-only
streams and a variety of distributed data settings. In comparisons to
randomized sketching algorithms on synthetic and real-world datasets, our
algorithm has less empirical error using less space and similar time.
</p>
<a href="http://arxiv.org/abs/2002.02013" target="_blank">arXiv:2002.02013</a> [<a href="http://arxiv.org/pdf/2002.02013" target="_blank">pdf</a>]

<h2>On Robust Mean Estimation under Coordinate-level Corruption. (arXiv:2002.04137v4 [cs.LG] UPDATED)</h2>
<h3>Zifan Liu, Jongho Park, Theodoros Rekatsinas, Christos Tzamos</h3>
<p>We study the problem of robust mean estimation and introduce a novel Hamming
distance-based measure of distribution shift for coordinate-level corruptions.
We show that this measure yields adversary models that capture more realistic
corruptions than those used in prior works, and present an
information-theoretic analysis of robust mean estimation in these settings. We
show that for structured distributions, methods that leverage the structure
yield information theoretically more accurate mean estimation. We also focus on
practical algorithms for robust mean estimation and study when data
cleaning-inspired approaches that first fix corruptions in the input data and
then perform robust mean estimation can match the information theoretic bounds
of our analysis. We finally demonstrate experimentally that this two-step
approach outperforms structure-agnostic robust estimation and provides accurate
mean estimation even for high-magnitude corruption.
</p>
<a href="http://arxiv.org/abs/2002.04137" target="_blank">arXiv:2002.04137</a> [<a href="http://arxiv.org/pdf/2002.04137" target="_blank">pdf</a>]

<h2>Langevin DQN. (arXiv:2002.07282v2 [cs.LG] UPDATED)</h2>
<h3>Vikranth Dwaracherla, Benjamin Van Roy</h3>
<p>Algorithms that tackle deep exploration -- an important challenge in
reinforcement learning -- have relied on epistemic uncertainty representation
through ensembles or other hypermodels, exploration bonuses, or visitation
count distributions. An open question is whether deep exploration can be
achieved by an incremental reinforcement learning algorithm that tracks a
single point estimate, without additional complexity required to account for
epistemic uncertainty. We answer this question in the affirmative. In
particular, we develop Langevin DQN, a variation of DQN that differs only in
perturbing parameter updates with Gaussian noise and demonstrate through a
computational study that the presented algorithm achieves deep exploration. We
also offer some intuition to how Langevin DQN achieves deep exploration. In
addition, we present a modification of the Langevin DQN algorithm to improve
the computational efficiency.
</p>
<a href="http://arxiv.org/abs/2002.07282" target="_blank">arXiv:2002.07282</a> [<a href="http://arxiv.org/pdf/2002.07282" target="_blank">pdf</a>]

<h2>Approximate Data Deletion from Machine Learning Models. (arXiv:2002.10077v2 [cs.LG] UPDATED)</h2>
<h3>Zachary Izzo, Mary Anne Smart, Kamalika Chaudhuri, James Zou</h3>
<p>Deleting data from a trained machine learning (ML) model is a critical task
in many applications. For example, we may want to remove the influence of
training points that might be out of date or outliers. Regulations such as EU's
General Data Protection Regulation also stipulate that individuals can request
to have their data deleted. The naive approach to data deletion is to retrain
the ML model on the remaining data, but this is too time consuming. In this
work, we propose a new approximate deletion method for linear and logistic
models whose computational cost is linear in the the feature dimension $d$ and
independent of the number of training data $n$. This is a significant gain over
all existing methods, which all have superlinear time dependence on the
dimension. We also develop a new feature-injection test to evaluate the
thoroughness of data deletion from ML models.
</p>
<a href="http://arxiv.org/abs/2002.10077" target="_blank">arXiv:2002.10077</a> [<a href="http://arxiv.org/pdf/2002.10077" target="_blank">pdf</a>]

<h2>A Visual Communication Map for Multi-Agent Deep Reinforcement Learning. (arXiv:2002.11882v2 [cs.LG] UPDATED)</h2>
<h3>Ngoc Duy Nguyen, Thanh Thi Nguyen, Doug Creighton, Saeid Nahavandi</h3>
<p>Deep reinforcement learning has been applied successfully to solve various
real-world problems and the number of its applications in the multi-agent
settings has been increasing. Multi-agent learning distinctly poses significant
challenges in the effort to allocate a concealed communication medium. Agents
receive thorough knowledge from the medium to determine subsequent actions in a
distributed nature. Apparently, the goal is to leverage the cooperation of
multiple agents to achieve a designated objective efficiently. Recent studies
typically combine a specialized neural network with reinforcement learning to
enable communication between agents. This approach, however, limits the number
of agents or necessitates the homogeneity of the system. In this paper, we have
proposed a more scalable approach that not only deals with a great number of
agents but also enables collaboration between dissimilar functional agents and
compatibly combined with any deep reinforcement learning methods. Specifically,
we create a global communication map to represent the status of each agent in
the system visually. The visual map and the environmental state are fed to a
shared-parameter network to train multiple agents concurrently. Finally, we
select the Asynchronous Advantage Actor-Critic (A3C) algorithm to demonstrate
our proposed scheme, namely Visual communication map for Multi-agent A3C
(VMA3C). Simulation results show that the use of visual communication map
improves the performance of A3C regarding learning speed, reward achievement,
and robustness in multi-agent problems.
</p>
<a href="http://arxiv.org/abs/2002.11882" target="_blank">arXiv:2002.11882</a> [<a href="http://arxiv.org/pdf/2002.11882" target="_blank">pdf</a>]

<h2>Review, Analysis and Design of a Comprehensive Deep Reinforcement Learning Framework. (arXiv:2002.11883v2 [cs.LG] UPDATED)</h2>
<h3>Ngoc Duy Nguyen, Thanh Thi Nguyen, Hai Nguyen, Doug Creighton, Saeid Nahavandi</h3>
<p>The integration of deep learning to reinforcement learning (RL) has enabled
RL to perform efficiently in high-dimensional environments. Deep RL methods
have been applied to solve many complex real-world problems in recent years.
However, development of a deep RL-based system is challenging because of
various issues such as the selection of a suitable deep RL algorithm, its
network configuration, training time, training methods, and so on. This paper
proposes a comprehensive software framework that not only plays a vital role in
designing a connect-the-dots deep RL architecture but also provides a guideline
to develop a realistic RL application in a short time span. We have designed
and developed a deep RL-based software framework that strictly ensures
flexibility, robustness, and scalability. By inheriting the proposed
architecture, software managers can foresee any challenges when designing a
deep RL-based system. As a result, they can expedite the design process and
actively control every stage of software development, which is especially
critical in agile development environments. To enforce generalization, the
proposed architecture does not depend on a specific RL algorithm, a network
configuration, the number of agents, or the type of agents. Using our
framework, software developers can develop and integrate new RL algorithms or
new types of agents, and can flexibly change network configuration or the
number of agents.
</p>
<a href="http://arxiv.org/abs/2002.11883" target="_blank">arXiv:2002.11883</a> [<a href="http://arxiv.org/pdf/2002.11883" target="_blank">pdf</a>]

<h2>Sparse Gaussian Processes Revisited: Bayesian Approaches to Inducing-Variable Approximations. (arXiv:2003.03080v4 [stat.ML] UPDATED)</h2>
<h3>Simone Rossi, Markus Heinonen, Edwin V. Bonilla, Zheyang Shen, Maurizio Filippone</h3>
<p>Variational inference techniques based on inducing variables provide an
elegant framework for scalable posterior estimation in Gaussian process (GP)
models. Besides enabling scalability, one of their main advantages over sparse
approximations using direct marginal likelihood maximization is that they
provide a robust alternative for point estimation of the inducing inputs, i.e.
the location of the inducing variables. In this work we challenge the common
wisdom that optimizing the inducing inputs in the variational framework yields
optimal performance. We show that, by revisiting old model approximations such
as the fully-independent training conditionals endowed with powerful
sampling-based inference methods, treating both inducing locations and GP
hyper-parameters in a Bayesian way can improve performance significantly. Based
on stochastic gradient Hamiltonian Monte Carlo, we develop a fully Bayesian
approach to scalable GP and deep GP models, and demonstrate its
state-of-the-art performance through an extensive experimental campaign across
several regression and classification problems.
</p>
<a href="http://arxiv.org/abs/2003.03080" target="_blank">arXiv:2003.03080</a> [<a href="http://arxiv.org/pdf/2003.03080" target="_blank">pdf</a>]

<h2>ShadowSync: Performing Synchronization in the Background for Highly Scalable Distributed Training. (arXiv:2003.03477v3 [cs.LG] UPDATED)</h2>
<h3>Qinqing Zheng, Bor-Yiing Su, Jiyan Yang, Alisson Azzolini, Qiang Wu, Ou Jin, Shri Karandikar, Hagay Lupesko, Liang Xiong, Eric Zhou</h3>
<p>Recommendation systems are often trained with a tremendous amount of data,
and distributed training is the workhorse to shorten the training time. While
the training throughput can be increased by simply adding more workers, it is
also increasingly challenging to preserve the model quality. In this paper, we
present \shadowsync, a distributed framework specifically tailored to modern
scale recommendation system training. In contrast to previous works where
synchronization happens as part of the training process, \shadowsync separates
the synchronization from training and runs it in the background. Such isolation
significantly reduces the synchronization overhead and increases the
synchronization frequency, so that we are able to obtain both high throughput
and excellent model quality when training at scale. The superiority of our
procedure is confirmed by experiments on training deep neural networks for
click-through-rate prediction tasks. Our framework is capable to express data
parallelism and/or model parallelism, generic to host various types of
synchronization algorithms, and readily applicable to large scale problems in
other areas.
</p>
<a href="http://arxiv.org/abs/2003.03477" target="_blank">arXiv:2003.03477</a> [<a href="http://arxiv.org/pdf/2003.03477" target="_blank">pdf</a>]

<h2>Multilayer Dense Connections for Hierarchical Concept Classification. (arXiv:2003.09015v2 [cs.CV] UPDATED)</h2>
<h3>Toufiq Parag, Hongcheng Wang</h3>
<p>Classification is a pivotal function for many computer vision tasks such as
object classification, detection, scene segmentation. Multinomial logistic
regression with a single final layer of dense connections has become the
ubiquitous technique for CNN-based classification. While these classifiers
project a mapping between the input and a set of output category classes, they
do not typically yield a comprehensive description of the category. In
particular, when a CNN based image classifier correctly identifies the image of
a Chimpanzee, its output does not clarify that Chimpanzee is a member of
Primate, Mammal, Chordate families and a living thing. We propose a multilayer
dense connectivity for concurrent prediction of category and its conceptual
superclasses in hierarchical order by the same CNN. We experimentally
demonstrate that our proposed network can simultaneously predict both the
coarse superclasses and finer categories better than several existing
algorithms in multiple datasets.
</p>
<a href="http://arxiv.org/abs/2003.09015" target="_blank">arXiv:2003.09015</a> [<a href="http://arxiv.org/pdf/2003.09015" target="_blank">pdf</a>]

<h2>NeuCrowd: Neural Sampling Network for Representation Learning with Crowdsourced Labels. (arXiv:2003.09660v3 [cs.LG] UPDATED)</h2>
<h3>Yang Hao, Wenbiao Ding, Zitao Liu</h3>
<p>Representation learning approaches require a massive amount of discriminative
training data, which is unavailable in many scenarios, such as healthcare,
smart city, education, etc. In practice, people refer to crowdsourcing to get
annotated labels. However, due to issues like data privacy, budget limitation,
shortage of domain-specific annotators, the number of crowdsourced labels is
still very limited. Moreover, because of annotators' diverse expertises,
crowdsourced labels are often inconsistent. Thus, directly applying existing
supervised representation learning (SRL) algorithms may easily get the
overfitting problem and yield suboptimal solutions. In this paper, we propose
\emph{NeuCrowd}, a unified framework for SRL from crowdsourced labels. The
proposed framework (1) creates a sufficient number of high-quality
\emph{n}-tuplet training samples by utilizing safety-aware sampling and robust
anchor generation; and (2) automatically learns a neural sampling network that
adaptively learns to select effective samples for SRL networks. The proposed
framework is evaluated on both one synthetic and three real-world data sets.
The results show that our approach outperforms a wide range of state-of-the-art
baselines in terms of prediction accuracy and AUC. To encourage the
reproducible results, we make our code publicly available at
\url{https://github.com/crowd-data-mining/NeuCrowd}.
</p>
<a href="http://arxiv.org/abs/2003.09660" target="_blank">arXiv:2003.09660</a> [<a href="http://arxiv.org/pdf/2003.09660" target="_blank">pdf</a>]

<h2>Markovian Score Climbing: Variational Inference with KL(p||q). (arXiv:2003.10374v2 [stat.ML] UPDATED)</h2>
<h3>Christian A. Naesseth, Fredrik Lindsten, David Blei</h3>
<p>Modern variational inference (VI) uses stochastic gradients to avoid
intractable expectations, enabling large-scale probabilistic inference in
complex models. VI posits a family of approximating distributions q and then
finds the member of that family that is closest to the exact posterior p.
Traditionally, VI algorithms minimize the "exclusive Kullback-Leibler (KL)"
KL(q || p), often for computational convenience. Recent research, however, has
also focused on the "inclusive KL" KL(p || q), which has good statistical
properties that makes it more appropriate for certain inference problems. This
paper develops a simple algorithm for reliably minimizing the inclusive KL
using stochastic gradients with vanishing bias. This method, which we call
Markovian score climbing (MSC), converges to a local optimum of the inclusive
KL. It does not suffer from the systematic errors inherent in existing methods,
such as Reweighted Wake-Sleep and Neural Adaptive Sequential Monte Carlo, which
lead to bias in their final estimates. We illustrate convergence on a toy model
and demonstrate the utility of MSC on Bayesian probit regression for
classification as well as a stochastic volatility model for financial data.
</p>
<a href="http://arxiv.org/abs/2003.10374" target="_blank">arXiv:2003.10374</a> [<a href="http://arxiv.org/pdf/2003.10374" target="_blank">pdf</a>]

<h2>On Infinite-Width Hypernetworks. (arXiv:2003.12193v7 [cs.LG] UPDATED)</h2>
<h3>Etai Littwin, Tomer Galanti, Lior Wolf, Greg Yang</h3>
<p>{\em Hypernetworks} are architectures that produce the weights of a
task-specific {\em primary network}. A notable application of hypernetworks in
the recent literature involves learning to output functional representations.
In these scenarios, the hypernetwork learns a representation corresponding to
the weights of a shallow MLP, which typically encodes shape or image
information. While such representations have seen considerable success in
practice, they remain lacking in the theoretical guarantees in the wide regime
of the standard architectures. In this work, we study wide over-parameterized
hypernetworks. We show that unlike typical architectures, infinitely wide
hypernetworks do not guarantee convergence to a global minima under gradient
descent. We further show that convexity can be achieved by increasing the
dimensionality of the hypernetwork's output, to represent wide MLPs. In the
dually infinite-width regime, we identify the functional priors of these
architectures by deriving their corresponding GP and NTK kernels, the latter of
which we refer to as the {\em hyperkernel}. As part of this study, we make a
mathematical contribution by deriving tight bounds on high order Taylor
expansion terms of standard fully connected ReLU networks.
</p>
<a href="http://arxiv.org/abs/2003.12193" target="_blank">arXiv:2003.12193</a> [<a href="http://arxiv.org/pdf/2003.12193" target="_blank">pdf</a>]

<h2>Heidelberg Colorectal Data Set for Surgical Data Science in the Sensor Operating Room. (arXiv:2005.03501v5 [cs.CV] UPDATED)</h2>
<h3>Lena Maier-Hein, Martin Wagner, Tobias Ross, Annika Reinke, Sebastian Bodenstedt, Peter M. Full, Hellena Hempe, Diana Mindroc-Filimon, Patrick Scholz, Thuy Nuong Tran, Pierangela Bruno, Anna Kisilenko, Benjamin M&#xfc;ller, Tornike Davitashvili, Manuela Capek, Minu Tizabi, Matthias Eisenmann, Tim J. Adler, Janek Gr&#xf6;hl, Melanie Schellenberg, Silvia Seidlitz, T. Y. Emmy Lai, B&#xfc;nyamin Pekdemir, Veith Roethlingshoefer, Fabian Both, Sebastian Bittel, Marc Mengler, Lars M&#xfc;ndermann, Martin Apitz, Annette Kopp-Schneider, Stefanie Speidel, Hannes G. Kenngott, Beat P. M&#xfc;ller-Stich</h3>
<p>Image-based tracking of medical instruments is an integral part of surgical
data science applications. Previous research has addressed the tasks of
detecting, segmenting and tracking medical instruments based on laparoscopic
video data. However, the proposed methods still tend to fail when applied to
challenging images and do not generalize well to data they have not been
trained on. This paper introduces the Heidelberg Colorectal (HeiCo) data set -
the first publicly available data set enabling comprehensive benchmarking of
medical instrument detection and segmentation algorithms with a specific
emphasis on method robustness and generalization capabilities. Our data set
comprises 30 laparoscopic videos and corresponding sensor data from medical
devices in the operating room for three different types of laparoscopic
surgery. Annotations include surgical phase labels for all video frames as well
as information on instrument presence and corresponding instance-wise
segmentation masks for surgical instruments (if any) in more than 10,000
individual frames. The data has successfully been used to organize
international competitions within the Endoscopic Vision Challenges 2017 and
2019.
</p>
<a href="http://arxiv.org/abs/2005.03501" target="_blank">arXiv:2005.03501</a> [<a href="http://arxiv.org/pdf/2005.03501" target="_blank">pdf</a>]

<h2>Enhancing Certified Robustness via Smoothed Weighted Ensembling. (arXiv:2005.09363v3 [cs.LG] UPDATED)</h2>
<h3>Chizhou Liu, Yunzhen Feng, Ranran Wang, Bin Dong</h3>
<p>Randomized smoothing has achieved state-of-the-art certified robustness
against $l_2$-norm adversarial attacks. However, it is not wholly resolved on
how to find the optimal base classifier for randomized smoothing. In this work,
we employ a Smoothed WEighted ENsembling (SWEEN) scheme to improve the
performance of randomized smoothed classifiers. We show the ensembling
generality that SWEEN can help achieve optimal certified robustness.
Furthermore, theoretical analysis proves that the optimal SWEEN model can be
obtained from training under mild assumptions. We also develop an adaptive
prediction algorithm to reduce the prediction and certification cost of SWEEN
models. Extensive experiments show that SWEEN models outperform the upper
envelope of their corresponding candidate models by a large margin. Moreover,
SWEEN models constructed using a few small models can achieve comparable
performance to a single large model with a notable reduction in training time.
</p>
<a href="http://arxiv.org/abs/2005.09363" target="_blank">arXiv:2005.09363</a> [<a href="http://arxiv.org/pdf/2005.09363" target="_blank">pdf</a>]

<h2>Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and Wild. (arXiv:2005.13983v6 [cs.CV] UPDATED)</h2>
<h3>Weixia Zhang, Kede Ma, Guangtao Zhai, Xiaokang Yang</h3>
<p>Performance of blind image quality assessment (BIQA) models has been
significantly boosted by end-to-end optimization of feature engineering and
quality regression. Nevertheless, due to the distributional shift between
images simulated in the laboratory and captured in the wild, models trained on
databases with synthetic distortions remain particularly weak at handling
realistic distortions (and vice versa). To confront the
cross-distortion-scenario challenge, we develop a \textit{unified} BIQA model
and an approach of training it for both synthetic and realistic distortions. We
first sample pairs of images from individual IQA databases, and compute a
probability that the first image of each pair is of higher quality. We then
employ the fidelity loss to optimize a deep neural network for BIQA over a
large number of such image pairs. We also explicitly enforce a hinge constraint
to regularize uncertainty estimation during optimization. Extensive experiments
on six IQA databases show the promise of the learned method in blindly
assessing image quality in the laboratory and wild. In addition, we demonstrate
the universality of the proposed training strategy by using it to improve
existing BIQA models.
</p>
<a href="http://arxiv.org/abs/2005.13983" target="_blank">arXiv:2005.13983</a> [<a href="http://arxiv.org/pdf/2005.13983" target="_blank">pdf</a>]

<h2>Investigating Estimated Kolmogorov Complexity as a Means of Regularization for Link Prediction. (arXiv:2006.04258v2 [cs.LG] UPDATED)</h2>
<h3>Paris D. L. Flood, Ramon Vi&#xf1;as, Pietro Li&#xf2;</h3>
<p>Link prediction in graphs is an important task in the fields of network
science and machine learning. We investigate a flexible means of regularization
for link prediction based on an approximation of the Kolmogorov complexity of
graphs that is differentiable and compatible with recent advances in link
prediction algorithms. Informally, the Kolmogorov complexity of an object is
the length of the shortest computer program that produces the object. Complex
networks are often generated, in part, by simple mechanisms; for example, many
citation networks and social networks are approximately scale-free and can be
explained by preferential attachment. A preference for predicting graphs with
simpler generating mechanisms motivates our choice of Kolmogorov complexity as
a regularization term. In our experiments the regularization method shows good
performance on many diverse real-world networks, however we determine that this
is likely due to an aggregation method rather than any actual estimation of
Kolmogorov complexity.
</p>
<a href="http://arxiv.org/abs/2006.04258" target="_blank">arXiv:2006.04258</a> [<a href="http://arxiv.org/pdf/2006.04258" target="_blank">pdf</a>]

<h2>MISIM: A Novel Code Similarity System. (arXiv:2006.05265v5 [cs.LG] UPDATED)</h2>
<h3>Fangke Ye, Shengtian Zhou, Anand Venkat, Ryan Marcus, Nesime Tatbul, Jesmin Jahan Tithi, Niranjan Hasabnis, Paul Petersen, Timothy Mattson, Tim Kraska, Pradeep Dubey, Vivek Sarkar, Justin Gottschlich</h3>
<p>Code similarity systems are integral to a range of applications from code
recommendation to automated software defect correction. We argue that code
similarity is now a first-order problem that must be solved. To begin to
address this, we present machine Inferred Code Similarity (MISIM), a novel
end-to-end code similarity system that consists of two core components. First,
MISIM uses a novel context-aware semantic structure, which is designed to aid
in lifting semantic meaning from code syntax. Second, MISIM provides a
neural-based code similarity scoring algorithm, which can be implemented with
various neural network architectures with learned parameters. We compare MISIM
to three state-of-the-art code similarity systems: (i)code2vec, (ii)Neural Code
Comprehension, and (iii)Aroma. In our experimental evaluation across 328,155
programs (over 18 million lines of code), MISIM has 1.5x to 43.4x better
accuracy than all three systems.
</p>
<a href="http://arxiv.org/abs/2006.05265" target="_blank">arXiv:2006.05265</a> [<a href="http://arxiv.org/pdf/2006.05265" target="_blank">pdf</a>]

<h2>$Q$-learning with Logarithmic Regret. (arXiv:2006.09118v2 [cs.LG] UPDATED)</h2>
<h3>Kunhe Yang, Lin F. Yang, Simon S. Du</h3>
<p>This paper presents the first non-asymptotic result showing that a model-free
algorithm can achieve a logarithmic cumulative regret for episodic tabular
reinforcement learning if there exists a strictly positive sub-optimality gap
in the optimal $Q$-function. We prove that the optimistic $Q$-learning studied
in [Jin et al. 2018] enjoys a ${\mathcal{O}}\left(\frac{SA\cdot
\mathrm{poly}\left(H\right)}{\Delta_{\min}}\log\left(SAT\right)\right)$
cumulative regret bound, where $S$ is the number of states, $A$ is the number
of actions, $H$ is the planning horizon, $T$ is the total number of steps, and
$\Delta_{\min}$ is the minimum sub-optimality gap. This bound matches the
information theoretical lower bound in terms of $S,A,T$ up to a
$\log\left(SA\right)$ factor. We further extend our analysis to the discounted
setting and obtain a similar logarithmic cumulative regret bound.
</p>
<a href="http://arxiv.org/abs/2006.09118" target="_blank">arXiv:2006.09118</a> [<a href="http://arxiv.org/pdf/2006.09118" target="_blank">pdf</a>]

<h2>The Influence of Shape Constraints on the Thresholding Bandit Problem. (arXiv:2006.10006v3 [cs.LG] UPDATED)</h2>
<h3>James Cheshire, Pierre Menard, Alexandra Carpentier</h3>
<p>We investigate the stochastic Thresholding Bandit problem (TBP) under several
shape constraints. On top of (i) the vanilla, unstructured TBP, we consider the
case where (ii) the sequence of arm's means $(\mu_k)_k$ is monotonically
increasing MTBP, (iii) the case where $(\mu_k)_k$ is unimodal UTBP and (iv) the
case where $(\mu_k)_k$ is concave CTBP. In the TBP problem the aim is to
output, at the end of the sequential game, the set of arms whose means are
above a given threshold. The regret is the highest gap between a misclassified
arm and the threshold. In the fixed budget setting, we provide problem
independent minimax rates for the expected regret in all settings, as well as
associated algorithms. We prove that the minimax rates for the regret are (i)
$\sqrt{\log(K)K/T}$ for TBP, (ii) $\sqrt{\log(K)/T}$ for MTBP, (iii)
$\sqrt{K/T}$ for UTBP and (iv) $\sqrt{\log\log K/T}$ for CTBP, where $K$ is the
number of arms and $T$ is the budget. These rates demonstrate that the
dependence on $K$ of the minimax regret varies significantly depending on the
shape constraint. This highlights the fact that the shape constraints modify
fundamentally the nature of the TBP.
</p>
<a href="http://arxiv.org/abs/2006.10006" target="_blank">arXiv:2006.10006</a> [<a href="http://arxiv.org/pdf/2006.10006" target="_blank">pdf</a>]

<h2>Graph Backdoor. (arXiv:2006.11890v4 [cs.LG] UPDATED)</h2>
<h3>Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang</h3>
<p>One intriguing property of deep neural networks (DNNs) is their inherent
vulnerability to backdoor attacks -- a trojan model responds to
trigger-embedded inputs in a highly predictable manner while functioning
normally otherwise. Despite the plethora of prior work on DNNs for continuous
data (e.g., images), the vulnerability of graph neural networks (GNNs) for
discrete-structured data (e.g., graphs) is largely unexplored, which is highly
concerning given their increasing use in security-sensitive domains. To bridge
this gap, we present GTA, the first backdoor attack on GNNs. Compared with
prior work, GTA departs in significant ways: graph-oriented -- it defines
triggers as specific subgraphs, including both topological structures and
descriptive features, entailing a large design spectrum for the adversary;
input-tailored -- it dynamically adapts triggers to individual graphs, thereby
optimizing both attack effectiveness and evasiveness; downstream model-agnostic
-- it can be readily launched without knowledge regarding downstream models or
fine-tuning strategies; and attack-extensible -- it can be instantiated for
both transductive (e.g., node classification) and inductive (e.g., graph
classification) tasks, constituting severe threats for a range of
security-critical applications. Through extensive evaluation using benchmark
datasets and state-of-the-art models, we demonstrate the effectiveness of GTA.
We further provide analytical justification for its effectiveness and discuss
potential countermeasures, pointing to several promising research directions.
</p>
<a href="http://arxiv.org/abs/2006.11890" target="_blank">arXiv:2006.11890</a> [<a href="http://arxiv.org/pdf/2006.11890" target="_blank">pdf</a>]

<h2>Learning with AMIGo: Adversarially Motivated Intrinsic Goals. (arXiv:2006.12122v2 [cs.LG] UPDATED)</h2>
<h3>Andres Campero, Roberta Raileanu, Heinrich K&#xfc;ttler, Joshua B. Tenenbaum, Tim Rockt&#xe4;schel, Edward Grefenstette</h3>
<p>A key challenge for reinforcement learning (RL) consists of learning in
environments with sparse extrinsic rewards. In contrast to current RL methods,
humans are able to learn new skills with little or no reward by using various
forms of intrinsic motivation. We propose AMIGo, a novel agent incorporating --
as form of meta-learning -- a goal-generating teacher that proposes
Adversarially Motivated Intrinsic Goals to train a goal-conditioned "student"
policy in the absence of (or alongside) environment reward. Specifically,
through a simple but effective "constructively adversarial" objective, the
teacher learns to propose increasingly challenging -- yet achievable -- goals
that allow the student to learn general skills for acting in a new environment,
independent of the task to be solved. We show that our method generates a
natural curriculum of self-proposed goals which ultimately allows the agent to
solve challenging procedurally-generated tasks where other forms of intrinsic
motivation and state-of-the-art RL methods fail.
</p>
<a href="http://arxiv.org/abs/2006.12122" target="_blank">arXiv:2006.12122</a> [<a href="http://arxiv.org/pdf/2006.12122" target="_blank">pdf</a>]

<h2>Aligning Time Series on Incomparable Spaces. (arXiv:2006.12648v2 [cs.LG] UPDATED)</h2>
<h3>Samuel Cohen, Giulia Luise, Alexander Terenin, Brandon Amos, Marc Peter Deisenroth</h3>
<p>Dynamic time warping (DTW) is a useful method for aligning, comparing and
combining time series, but it requires them to live in comparable spaces. In
this work, we consider a setting in which time series live on different spaces
without a sensible ground metric, causing DTW to become ill-defined. To
alleviate this, we propose Gromov dynamic time warping (GDTW), a distance
between time series on potentially incomparable spaces that avoids the
comparability requirement by instead considering intra-relational geometry. We
demonstrate its effectiveness at aligning, combining and comparing time series
living on incomparable spaces. We further propose a smoothed version of GDTW as
a differentiable loss and assess its properties in a variety of settings,
including barycentric averaging, generative modeling and imitation learning.
</p>
<a href="http://arxiv.org/abs/2006.12648" target="_blank">arXiv:2006.12648</a> [<a href="http://arxiv.org/pdf/2006.12648" target="_blank">pdf</a>]

<h2>Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping. (arXiv:2006.13165v4 [cs.LG] UPDATED)</h2>
<h3>Dongruo Zhou, Jiafan He, Quanquan Gu</h3>
<p>Modern tasks in reinforcement learning have large state and action spaces. To
deal with them efficiently, one often uses predefined feature mapping to
represent states and actions in a low-dimensional space. In this paper, we
study reinforcement learning for discounted Markov Decision Processes (MDPs),
where the transition kernel can be parameterized as a linear function of
certain feature mapping. We propose a novel algorithm that makes use of the
feature mapping and obtains a $\tilde O(d\sqrt{T}/(1-\gamma)^2)$ regret, where
$d$ is the dimension of the feature space, $T$ is the time horizon and $\gamma$
is the discount factor of the MDP. To the best of our knowledge, this is the
first polynomial regret bound without accessing the generative model or making
strong assumptions such as ergodicity of the MDP. By constructing a special
class of MDPs, we also show that for any algorithms, the regret is lower
bounded by $\Omega(d\sqrt{T}/(1-\gamma)^{1.5})$. Our upper and lower bound
results together suggest that the proposed reinforcement learning algorithm is
near-optimal up to a $(1-\gamma)^{-0.5}$ factor.
</p>
<a href="http://arxiv.org/abs/2006.13165" target="_blank">arXiv:2006.13165</a> [<a href="http://arxiv.org/pdf/2006.13165" target="_blank">pdf</a>]

<h2>Spectral Bias and Task-Model Alignment Explain Generalization in Kernel Regression and Infinitely Wide Neural Networks. (arXiv:2006.13198v4 [stat.ML] UPDATED)</h2>
<h3>Abdulkadir Canatar, Blake Bordelon, Cengiz Pehlevan</h3>
<p>Generalization beyond a training dataset is a main goal of machine learning,
but theoretical understanding of generalization remains an open problem for
many models. The need for a new theory is exacerbated by recent observations in
deep neural networks where overparameterization leads to better performance,
contradicting the conventional wisdom from classical statistics. In this paper,
we investigate generalization error for kernel regression, which, besides being
a popular machine learning method, also includes infinitely overparameterized
neural networks trained with gradient descent. We use techniques from
statistical mechanics to derive an analytical expression for generalization
error applicable to any kernel or data distribution. We present applications of
our theory to real and synthetic datasets, and for many kernels including those
that arise from training deep neural networks in the infinite-width limit. We
elucidate an inductive bias of kernel regression to explain data with "simple
functions", which are identified by solving a kernel eigenfunction problem on
the data distribution. This notion of simplicity allows us to characterize
whether a kernel is compatible with a learning task, facilitating good
generalization performance from a small number of training examples. We show
that more data may impair generalization when noisy or not expressible by the
kernel, leading to non-monotonic learning curves with possibly many peaks. To
further understand these phenomena, we turn to the broad class of rotation
invariant kernels, which is relevant to training deep neural networks in the
infinite-width limit, and present a detailed mathematical analysis of them when
data is drawn from a spherically symmetric distribution and the number of input
dimensions is large.
</p>
<a href="http://arxiv.org/abs/2006.13198" target="_blank">arXiv:2006.13198</a> [<a href="http://arxiv.org/pdf/2006.13198" target="_blank">pdf</a>]

<h2>Bayesian Optimization with a Prior for the Optimum. (arXiv:2006.14608v3 [cs.LG] UPDATED)</h2>
<h3>Artur Souza, Luigi Nardi, Leonardo B. Oliveira, Kunle Olukotun, Marius Lindauer, Frank Hutter</h3>
<p>While Bayesian Optimization (BO) is a very popular method for optimizing
expensive black-box functions, it fails to leverage the experience of domain
experts. This causes BO to waste function evaluations on bad design choices
(e.g., machine learning hyperparameters) that the expert already knows to work
poorly. To address this issue, we introduce Bayesian Optimization with a Prior
for the Optimum (BOPrO). BOPrO allows users to inject their knowledge into the
optimization process in the form of priors about which parts of the input space
will yield the best performance, rather than BO's standard priors over
functions, which are much less intuitive for users. BOPrO then combines these
priors with BO's standard probabilistic model to form a pseudo-posterior used
to select which points to evaluate next. We show that BOPrO is around 6.67x
faster than state-of-the-art methods and 10,000x faster than random search on a
common suite of benchmarks, and achieves a new state-of-the-art performance on
a real-world hardware design application. We also show that BOPrO converges
faster even if the priors for the optimum are not entirely accurate and that it
robustly recovers from misleading priors.
</p>
<a href="http://arxiv.org/abs/2006.14608" target="_blank">arXiv:2006.14608</a> [<a href="http://arxiv.org/pdf/2006.14608" target="_blank">pdf</a>]

<h2>Deep Sea Robotic Imaging Simulator. (arXiv:2006.15398v3 [cs.CV] UPDATED)</h2>
<h3>Yifan Song, David Nakath, Mengkun She, Furkan Elibol, Kevin K&#xf6;ser</h3>
<p>Nowadays underwater vision systems are being widely applied in ocean
research. However, the largest portion of the ocean - the deep sea - still
remains mostly unexplored. Only relatively few image sets have been taken from
the deep sea due to the physical limitations caused by technical challenges and
enormous costs. Deep sea images are very different from the images taken in
shallow waters and this area did not get much attention from the community. The
shortage of deep sea images and the corresponding ground truth data for
evaluation and training is becoming a bottleneck for the development of
underwater computer vision methods. Thus, this paper presents a physical
model-based image simulation solution, which uses an in-air texture and depth
information as inputs, to generate underwater image sequences taken by robots
in deep ocean scenarios. Different from shallow water conditions, artificial
illumination plays a vital role in deep sea image formation as it strongly
affects the scene appearance. Our radiometric image formation model considers
both attenuation and scattering effects with co-moving spotlights in the dark.
By detailed analysis and evaluation of the underwater image formation model, we
propose a 3D lookup table structure in combination with a novel rendering
strategy to improve simulation performance. This enables us to integrate an
interactive deep sea robotic vision simulation in the Unmanned Underwater
Vehicles simulator. To inspire further deep sea vision research by the
community, we will release the source code of our deep sea image converter to
the public.
</p>
<a href="http://arxiv.org/abs/2006.15398" target="_blank">arXiv:2006.15398</a> [<a href="http://arxiv.org/pdf/2006.15398" target="_blank">pdf</a>]

<h2>Scalable Computations of Wasserstein Barycenter via Input Convex Neural Networks. (arXiv:2007.04462v2 [cs.LG] UPDATED)</h2>
<h3>Jiaojiao Fan, Amirhossein Taghvaei, Yongxin Chen</h3>
<p>Wasserstein Barycenter is a principled approach to represent the weighted
mean of a given set of probability distributions, utilizing the geometry
induced by optimal transport. In this work, we present a novel scalable
algorithm to approximate the Wasserstein Barycenters aiming at high-dimensional
applications in machine learning. Our proposed algorithm is based on the
Kantorovich dual formulation of the Wasserstein-2 distance as well as a recent
neural network architecture, input convex neural network, that is known to
parametrize convex functions. The distinguishing features of our method are: i)
it only requires samples from the marginal distributions; ii) unlike the
existing approaches, it represents the Barycenter with a generative model and
can thus generate infinite samples from the barycenter without querying the
marginal distributions; iii) it works similar to Generative Adversarial Model
in one marginal case. We demonstrate the efficacy of our algorithm by comparing
it with the state-of-art methods in multiple experiments.
</p>
<a href="http://arxiv.org/abs/2007.04462" target="_blank">arXiv:2007.04462</a> [<a href="http://arxiv.org/pdf/2007.04462" target="_blank">pdf</a>]

<h2>Single View Metrology in the Wild. (arXiv:2007.09529v3 [cs.CV] UPDATED)</h2>
<h3>Rui Zhu, Xingyi Yang, Yannick Hold-Geoffroy, Federico Perazzi, Jonathan Eisenmann, Kalyan Sunkavalli, Manmohan Chandraker</h3>
<p>Most 3D reconstruction methods may only recover scene properties up to a
global scale ambiguity. We present a novel approach to single view metrology
that can recover the absolute scale of a scene represented by 3D heights of
objects or camera height above the ground as well as camera parameters of
orientation and field of view, using just a monocular image acquired in
unconstrained condition. Our method relies on data-driven priors learned by a
deep network specifically designed to imbibe weakly supervised constraints from
the interplay of the unknown camera with 3D entities such as object heights,
through estimation of bounding box projections. We leverage categorical priors
for objects such as humans or cars that commonly occur in natural images, as
references for scale estimation. We demonstrate state-of-the-art qualitative
and quantitative results on several datasets as well as applications including
virtual object insertion. Furthermore, the perceptual quality of our outputs is
validated by a user study.
</p>
<a href="http://arxiv.org/abs/2007.09529" target="_blank">arXiv:2007.09529</a> [<a href="http://arxiv.org/pdf/2007.09529" target="_blank">pdf</a>]

<h2>Extending and Improving Learned CountSketch. (arXiv:2007.09890v2 [cs.LG] UPDATED)</h2>
<h3>Simin Liu, Tianrui Liu, Ali Vakilian, Yulin Wan, David P. Woodruff</h3>
<p>A sketching algorithm is a way to solve an optimization problem approximately
and in a fraction of the usual time. We consider classical sketching algorithms
which first compress data by multiplication with a random "sketch matrix". Our
work improves and extends the "learned sketch" paradigm, in which sketch
matrices are optimized to yield better expected performance.

This technique has only been used for a suboptimal variant of sketched
low-rank decomposition (LRD). Our work extends the problem coverage to optimal
sketched LRD, least-squares regression (LS), and $k$-means clustering. We
improve sketch learning for all three problems and very significantly for LS
and LRD: experimental performance increases by $12\%$ and $20\%$, respectively.
(Interestingly, we can also prove that we get a strict improvement for LRD
under certain conditions.) Finally, we design two sketching algorithm
modifications that leverage the strong expected performance of learned
sketches, provide worst-case performance guarantees, and have the same time
complexity as classical sketching. We prove the worst-case property for each of
the problems and their modified algorithms.
</p>
<a href="http://arxiv.org/abs/2007.09890" target="_blank">arXiv:2007.09890</a> [<a href="http://arxiv.org/pdf/2007.09890" target="_blank">pdf</a>]

<h2>Storage Fit Learning with Feature Evolvable Streams. (arXiv:2007.11280v3 [cs.LG] UPDATED)</h2>
<h3>Bo-Jian Hou, Yu-Hu Yan, Peng Zhao, Zhi-Hua Zhou</h3>
<p>Feature evolvable learning has been widely studied in recent years where old
features will vanish and new features will emerge when learning with streams.
Conventional methods usually assume that a label will be revealed after
prediction at each time step. However, in practice, this assumption may not
hold whereas no label will be given at most time steps. A good solution is to
leverage the technique of manifold regularization to utilize the previous
similar data to assist the refinement of the online model. Nevertheless, this
approach needs to store all previous data which is impossible in learning with
streams that arrive sequentially in large volume. Thus we need a buffer to
store part of them. Considering that different devices may have different
storage budgets, the learning approaches should be flexible subject to the
storage budget limit. In this paper, we propose a new setting: Storage-Fit
Feature-Evolvable streaming Learning (SF$^2$EL) which incorporates the issue of
rarely-provided labels into feature evolution. Our framework is able to fit its
behavior to different storage budgets when learning with feature evolvable
streams with unlabeled data. Besides, both theoretical and empirical results
validate that our approach can preserve the merit of the original feature
evolvable learning i.e., can always track the best baseline and thus perform
well at any time step.
</p>
<a href="http://arxiv.org/abs/2007.11280" target="_blank">arXiv:2007.11280</a> [<a href="http://arxiv.org/pdf/2007.11280" target="_blank">pdf</a>]

<h2>FOOD: Fast Out-Of-Distribution Detector. (arXiv:2008.06856v4 [cs.LG] UPDATED)</h2>
<h3>Guy Amit, Moshe Levy, Ishai Rosenberg, Asaf Shabtai, Yuval Elovici</h3>
<p>Deep neural networks (DNNs) perform well at classifying inputs associated
with the classes they have been trained on, which are known as in distribution
inputs. However, out-of-distribution (OOD) inputs pose a great challenge to
DNNs and consequently represent a major risk when DNNs are implemented in
safety-critical systems. Extensive research has been performed in the domain of
OOD detection. However, current state-of-the-art methods for OOD detection
suffer from at least one of the following limitations: (1) increased inference
time - this limits existing methods' applicability to many real-world
applications, and (2) the need for OOD training data - such data can be
difficult to acquire and may not be representative enough, thus limiting the
ability of the OOD detector to generalize. In this paper, we propose FOOD --
Fast Out-Of-Distribution detector -- an extended DNN classifier capable of
efficiently detecting OOD samples with minimal inference time overhead. Our
architecture features a DNN with a final Gaussian layer combined with the log
likelihood ratio statistical test and an additional output neuron for OOD
detection. Instead of using real OOD data, we use a novel method to craft
artificial OOD samples from in-distribution data, which are used to train our
OOD detector neuron. We evaluate FOOD's detection performance on the SVHN,
CIFAR-10, and CIFAR-100 datasets. Our results demonstrate that in addition to
achieving state-of-the-art performance, FOOD is fast and applicable to
real-world applications.
</p>
<a href="http://arxiv.org/abs/2008.06856" target="_blank">arXiv:2008.06856</a> [<a href="http://arxiv.org/pdf/2008.06856" target="_blank">pdf</a>]

<h2>SOAR: Simultaneous Or of And Rules for Classification of Positive & Negative Classes. (arXiv:2008.11249v2 [stat.ML] UPDATED)</h2>
<h3>Elena Khusainova, Emily Dodwell, Ritwik Mitra</h3>
<p>Algorithmic decision making has proliferated and now impacts our daily lives
in both mundane and consequential ways. Machine learning practitioners make use
of a myriad of algorithms for predictive models in applications as diverse as
movie recommendations, medical diagnoses, and parole recommendations without
delving into the reasons driving specific predictive decisions. Machine
learning algorithms in such applications are often chosen for their superior
performance, however popular choices such as random forest and deep neural
networks fail to provide an interpretable understanding of the predictive
model. In recent years, rule-based algorithms have been used to address this
issue. Wang et al. (2017) presented an or-of-and (disjunctive normal form)
based classification technique that allows for classification rule mining of a
single class in a binary classification; this method is also shown to perform
comparably to other modern algorithms. In this work, we extend this idea to
provide classification rules for both classes simultaneously. That is, we
provide a distinct set of rules for both positive and negative classes. In
describing this approach, we also present a novel and complete taxonomy of
classifications that clearly capture and quantify the inherent ambiguity in
noisy binary classifications in the real world. We show that this approach
leads to a more granular formulation of the likelihood model and a
simulated-annealing based optimization achieves classification performance
competitive with comparable techniques. We apply our method to synthetic as
well as real world data sets to compare with other related methods that
demonstrate the utility of our proposal.
</p>
<a href="http://arxiv.org/abs/2008.11249" target="_blank">arXiv:2008.11249</a> [<a href="http://arxiv.org/pdf/2008.11249" target="_blank">pdf</a>]

<h2>ePointDA: An End-to-End Simulation-to-Real Domain Adaptation Framework for LiDAR Point Cloud Segmentation. (arXiv:2009.03456v2 [cs.CV] UPDATED)</h2>
<h3>Sicheng Zhao, Yezhen Wang, Bo Li, Bichen Wu, Yang Gao, Pengfei Xu, Trevor Darrell, Kurt Keutzer</h3>
<p>Due to its robust and precise distance measurements, LiDAR plays an important
role in scene understanding for autonomous driving. Training deep neural
networks (DNNs) on LiDAR data requires large-scale point-wise annotations,
which are time-consuming and expensive to obtain. Instead, simulation-to-real
domain adaptation (SRDA) trains a DNN using unlimited synthetic data with
automatically generated labels and transfers the learned model to real
scenarios. Existing SRDA methods for LiDAR point cloud segmentation mainly
employ a multi-stage pipeline and focus on feature-level alignment. They
require prior knowledge of real-world statistics and ignore the pixel-level
dropout noise gap and the spatial feature gap between different domains. In
this paper, we propose a novel end-to-end framework, named ePointDA, to address
the above issues. Specifically, ePointDA consists of three modules:
self-supervised dropout noise rendering, statistics-invariant and
spatially-adaptive feature alignment, and transferable segmentation learning.
The joint optimization enables ePointDA to bridge the domain shift at the
pixel-level by explicitly rendering dropout noise for synthetic LiDAR and at
the feature-level by spatially aligning the features between different domains,
without requiring the real-world statistics. Extensive experiments adapting
from synthetic GTA-LiDAR to real KITTI and SemanticKITTI demonstrate the
superiority of ePointDA for LiDAR point cloud segmentation.
</p>
<a href="http://arxiv.org/abs/2009.03456" target="_blank">arXiv:2009.03456</a> [<a href="http://arxiv.org/pdf/2009.03456" target="_blank">pdf</a>]

<h2>QR-MIX: Distributional Value Function Factorisation for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2009.04197v5 [cs.LG] UPDATED)</h2>
<h3>Jian Hu, Seth Austin Harding, Haibin Wu, Siyue Hu, Shih-wei Liao</h3>
<p>In Cooperative Multi-Agent Reinforcement Learning (MARL) and under the
setting of Centralized Training with Decentralized Execution (CTDE), agents
observe and interact with their environment locally and independently. With
local observation and random sampling, the randomness in rewards and
observations leads to randomness in long-term returns. Existing methods such as
Value Decomposition Network (VDN) and QMIX estimate the value of long-term
returns as a scalar that does not contain the information of randomness. Our
proposed model QR-MIX introduces quantile regression, modeling joint
state-action values as a distribution, combining QMIX with Implicit Quantile
Network (IQN). However, the monotonicity in QMIX limits the expression of joint
state-action value distribution and may lead to incorrect estimation results in
non-monotonic cases. Therefore, we proposed a flexible loss function to
approximate the monotonicity found in QMIX. Our model is not only more tolerant
of the randomness of returns, but also more tolerant of the randomness of
monotonic constraints. The experimental results demonstrate that QR-MIX
outperforms the previous state-of-the-art method QMIX in the StarCraft
Multi-Agent Challenge (SMAC) environment.
</p>
<a href="http://arxiv.org/abs/2009.04197" target="_blank">arXiv:2009.04197</a> [<a href="http://arxiv.org/pdf/2009.04197" target="_blank">pdf</a>]

<h2>A Fast and Robust Method for Global Topological Functional Optimization. (arXiv:2009.08496v3 [stat.ML] UPDATED)</h2>
<h3>Elchanan Solomon, Alexander Wagner, Paul Bendich</h3>
<p>Topological statistics, in the form of persistence diagrams, are a class of
shape descriptors that capture global structural information in data. The
mapping from data structures to persistence diagrams is almost everywhere
differentiable, allowing for topological gradients to be backpropagated to
ordinary gradients. However, as a method for optimizing a topological
functional, this backpropagation method is expensive, unstable, and produces
very fragile optima. Our contribution is to introduce a novel backpropagation
scheme that is significantly faster, more stable, and produces more robust
optima. Moreover, this scheme can also be used to produce a stable
visualization of dots in a persistence diagram as a distribution over critical,
and near-critical, simplices in the data structure.
</p>
<a href="http://arxiv.org/abs/2009.08496" target="_blank">arXiv:2009.08496</a> [<a href="http://arxiv.org/pdf/2009.08496" target="_blank">pdf</a>]

<h2>Learning from eXtreme Bandit Feedback. (arXiv:2009.12947v2 [stat.ML] UPDATED)</h2>
<h3>Romain Lopez, Inderjit S. Dhillon, Michael I. Jordan</h3>
<p>We study the problem of batch learning from bandit feedback in the setting of
extremely large action spaces. Learning from extreme bandit feedback is
ubiquitous in recommendation systems, in which billions of decisions are made
over sets consisting of millions of choices in a single day, yielding massive
observational data. In these large-scale real-world applications, supervised
learning frameworks such as eXtreme Multi-label Classification (XMC) are widely
used despite the fact that they incur significant biases due to the mismatch
between bandit feedback and supervised labels. Such biases can be mitigated by
importance sampling techniques, but these techniques suffer from impractical
variance when dealing with a large number of actions. In this paper, we
introduce a selective importance sampling estimator (sIS) that operates in a
significantly more favorable bias-variance regime. The sIS estimator is
obtained by performing importance sampling on the conditional expectation of
the reward with respect to a small subset of actions for each instance (a form
of Rao-Blackwellization). We employ this estimator in a novel algorithmic
procedure -- named Policy Optimization for eXtreme Models (POXM) -- for
learning from bandit feedback on XMC tasks. In POXM, the selected actions for
the sIS estimator are the top-p actions of the logging policy, where p is
adjusted from the data and is significantly smaller than the size of the action
space. We use a supervised-to-bandit conversion on three XMC datasets to
benchmark our POXM method against three competing methods: BanditNet, a
previously applied partial matching pruning strategy, and a supervised learning
baseline. Whereas BanditNet sometimes improves marginally over the logging
policy, our experiments show that POXM systematically and significantly
improves over all baselines.
</p>
<a href="http://arxiv.org/abs/2009.12947" target="_blank">arXiv:2009.12947</a> [<a href="http://arxiv.org/pdf/2009.12947" target="_blank">pdf</a>]

<h2>Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning. (arXiv:2010.01062v2 [cs.LG] UPDATED)</h2>
<h3>Luisa Zintgraf, Leo Feng, Cong Lu, Maximilian Igl, Kristian Hartikainen, Katja Hofmann, Shimon Whiteson</h3>
<p>To rapidly learn a new task, it is often essential for agents to explore
efficiently -- especially when performance matters from the first timestep. One
way to learn such behaviour is via meta-learning. Many existing methods however
rely on dense rewards for meta-training, and can fail catastrophically if the
rewards are sparse. Without a suitable reward signal, the need for exploration
during meta-training is exacerbated. To address this, we propose HyperX, which
uses novel reward bonuses for meta-training to explore in approximate
hyper-state space (where hyper-states represent the environment state and the
agent's task belief). We show empirically that HyperX meta-learns better
task-exploration and adapts more successfully to new tasks than existing
methods.
</p>
<a href="http://arxiv.org/abs/2010.01062" target="_blank">arXiv:2010.01062</a> [<a href="http://arxiv.org/pdf/2010.01062" target="_blank">pdf</a>]

<h2>Estimation of Camera Response Function using Prediction Consistency and Gradual Refinement with an Extension to Deep Learning. (arXiv:2010.04009v2 [cs.CV] UPDATED)</h2>
<h3>Aashish Sharma, Robby T. Tan, Loong-Fah Cheong</h3>
<p>Most existing methods for CRF estimation from a single image fail to handle
general real images. For instance, EdgeCRF based on colour patches extracted
from edges works effectively only when the presence of noise is insignificant,
which is not the case for many real images; and, CRFNet, a recent method based
on fully supervised deep learning works only for the CRFs that are in the
training data, and hence fail to deal with other possible CRFs beyond the
training data. To address these problems, we introduce a non-deep-learning
method using prediction consistency and gradual refinement. First, we rely more
on the patches of the input image that provide more consistent predictions. If
the predictions from a patch are more consistent, it means that the patch is
likely to be less affected by noise or any inferior colour combinations, and
hence, it can be more reliable for CRF estimation. Second, we employ a gradual
refinement scheme in which we start from a simple CRF model to generate a
result which is more robust to noise but less accurate, and then we gradually
increase the model's complexity to improve the result. This is because a simple
model, while being less accurate, overfits less to noise than a complex model
does. Our experiments show that our method outperforms the existing
single-image methods for daytime and nighttime real images. We further propose
a more efficient deep learning extension that performs test-time training
(based on unsupervised losses) on the test input image. This provides our
method better generalization performance than CRFNet making it more practically
applicable for CRF estimation for general real images.
</p>
<a href="http://arxiv.org/abs/2010.04009" target="_blank">arXiv:2010.04009</a> [<a href="http://arxiv.org/pdf/2010.04009" target="_blank">pdf</a>]

<h2>Black-Box Optimization Revisited: Improving Algorithm Selection Wizards through Massive Benchmarking. (arXiv:2010.04542v3 [cs.LG] UPDATED)</h2>
<h3>Laurent Meunier, Herilalaina Rakotoarison, Pak Kan Wong, Baptiste Roziere, Jeremy Rapin, Olivier Teytaud, Antoine Moreau, Carola Doerr</h3>
<p>Existing studies in black-box optimization for machine learning suffer from
low generalizability, caused by a typically selective choice of problem
instances used for training and testing different optimization algorithms.
Among other issues, this practice promotes overfitting and poor-performing user
guidelines. To address this shortcoming, we propose in this work a benchmark
suite, OptimSuite, which covers a broad range of black-box optimization
problems, ranging from academic benchmarks to real-world applications, from
discrete over numerical to mixed-integer problems, from small to very
large-scale problems, from noisy over dynamic to static problems, etc. We
demonstrate the advantages of such a broad collection by deriving from it
Automated Black Box Optimizer (ABBO), a general-purpose algorithm selection
wizard. Using three different types of algorithm selection techniques, ABBO
achieves competitive performance on all benchmark suites. It significantly
outperforms previous state of the art on some of them, including YABBOB and
LSGO. ABBO relies on many high-quality base components. Its excellent
performance is obtained without any task-specific parametrization.

The OptimSuite benchmark collection, the ABBO wizard and its base solvers
have all been merged into the open-source Nevergrad platform, where they are
available for reproducible research.
</p>
<a href="http://arxiv.org/abs/2010.04542" target="_blank">arXiv:2010.04542</a> [<a href="http://arxiv.org/pdf/2010.04542" target="_blank">pdf</a>]

<h2>Revisiting Projection-free Online Learning: the Strongly Convex Case. (arXiv:2010.07572v2 [cs.LG] UPDATED)</h2>
<h3>Dan Garber, Ben Kretzu</h3>
<p>Projection-free optimization algorithms, which are mostly based on the
classical Frank-Wolfe method, have gained significant interest in the machine
learning community in recent years due to their ability to handle convex
constraints that are popular in many applications, but for which computing
projections is often computationally impractical in high-dimensional settings,
and hence prohibit the use of most standard projection-based methods. In
particular, a significant research effort was put on projection-free methods
for online learning. In this paper we revisit the Online Frank-Wolfe (OFW)
method suggested by Hazan and Kale \cite{Hazan12} and fill a gap that has been
left unnoticed for several years: OFW achieves a faster rate of $O(T^{2/3})$ on
strongly convex functions (as opposed to the standard $O(T^{3/4})$ for convex
but not strongly convex functions), where $T$ is the sequence length. This is
somewhat surprising since it is known that for offline optimization, in
general, strong convexity does not lead to faster rates for Frank-Wolfe. We
also revisit the bandit setting under strong convexity and prove a similar
bound of $\tilde O(T^{2/3})$ (instead of $O(T^{3/4})$ without strong
convexity). Hence, in the current state-of-affairs, the best projection-free
upper-bounds for the full-information and bandit settings with strongly convex
and nonsmooth functions match up to logarithmic factors in $T$.
</p>
<a href="http://arxiv.org/abs/2010.07572" target="_blank">arXiv:2010.07572</a> [<a href="http://arxiv.org/pdf/2010.07572" target="_blank">pdf</a>]

<h2>Asynchronous \epsilon-Greedy Bayesian Optimisation. (arXiv:2010.07615v3 [cs.LG] UPDATED)</h2>
<h3>George De Ath, Richard M. Everson, Jonathan E. Fieldsend</h3>
<p>Batch Bayesian optimisation (BO) is a successful technique for the
optimisation of expensive black-box functions. Asynchronous BO can reduce
wallclock time by starting a new evaluation as soon as another finishes, thus
maximising resource utilisation. To maximise resource allocation, we develop a
novel asynchronous BO method, AEGiS (Asynchronous $\epsilon$-Greedy Global
Search) that combines greedy search, exploiting the surrogate's mean
prediction, with Thompson sampling and random selection from the approximate
Pareto set describing the trade-off between exploitation (surrogate mean
prediction) and exploration (surrogate posterior variance). We demonstrate
empirically the efficacy of AEGiS on synthetic benchmark problems,
meta-surrogate hyperparameter tuning problems and real-world problems, showing
that AEGiS generally outperforms existing methods for asynchronous BO. When a
single worker is available performance is no worse than BO using expected
improvement.
</p>
<a href="http://arxiv.org/abs/2010.07615" target="_blank">arXiv:2010.07615</a> [<a href="http://arxiv.org/pdf/2010.07615" target="_blank">pdf</a>]

<h2>Faster Convergence of Stochastic Gradient Langevin Dynamics for Non-Log-Concave Sampling. (arXiv:2010.09597v2 [cs.LG] UPDATED)</h2>
<h3>Difan Zou, Pan Xu, Quanquan Gu</h3>
<p>We provide a new convergence analysis of stochastic gradient Langevin
dynamics (SGLD) for sampling from a class of distributions that can be
non-log-concave. At the core of our approach is a novel conductance analysis of
SGLD using an auxiliary time-reversible Markov Chain. Under certain conditions
on the target distribution, we prove that $\tilde O(d^4\epsilon^{-2})$
stochastic gradient evaluations suffice to guarantee $\epsilon$-sampling error
in terms of the total variation distance, where $d$ is the problem dimension.
This improves existing results on the convergence rate of SGLD (Raginsky et
al., 2017; Xu et al., 2018). We further show that provided an additional
Hessian Lipschitz condition on the log-density function, SGLD is guaranteed to
achieve $\epsilon$-sampling error within $\tilde O(d^{15/4}\epsilon^{-3/2})$
stochastic gradient evaluations. Our proof technique provides a new way to
study the convergence of Langevin-based algorithms and sheds some light on the
design of fast stochastic gradient-based sampling algorithms.
</p>
<a href="http://arxiv.org/abs/2010.09597" target="_blank">arXiv:2010.09597</a> [<a href="http://arxiv.org/pdf/2010.09597" target="_blank">pdf</a>]

<h2>Classification with Rejection Based on Cost-sensitive Classification. (arXiv:2010.11748v3 [stat.ML] UPDATED)</h2>
<h3>Nontawat Charoenphakdee, Zhenghang Cui, Yivan Zhang, Masashi Sugiyama</h3>
<p>The goal of classification with rejection is to avoid risky misclassification
in error-critical applications such as medical diagnosis and product
inspection. In this paper, based on the relationship between classification
with rejection and cost-sensitive classification, we propose a novel method of
classification with rejection by learning an ensemble of cost-sensitive
classifiers, which satisfies all the following properties for the first time:
(i) it can avoid estimating class-posterior probabilities, resulting in
improved classification accuracy. (ii) it allows a flexible choice of losses
including non-convex ones, (iii) it does not require complicated modifications
when using different losses, (iv) it is applicable to both binary and
multiclass cases, and (v) it is theoretically justifiable for any
classification-calibrated loss. Experimental results demonstrate the usefulness
of our proposed approach in clean-labeled, noisy-labeled, and
positive-unlabeled classification.
</p>
<a href="http://arxiv.org/abs/2010.11748" target="_blank">arXiv:2010.11748</a> [<a href="http://arxiv.org/pdf/2010.11748" target="_blank">pdf</a>]

<h2>AdaCrowd: Unlabeled Scene Adaptation for Crowd Counting. (arXiv:2010.12141v2 [cs.CV] UPDATED)</h2>
<h3>Mahesh Kumar Krishna Reddy, Mrigank Rochan, Yiwei Lu, Yang Wang</h3>
<p>We address the problem of image-based crowd counting. In particular, we
propose a new problem called unlabeled scene-adaptive crowd counting. Given a
new target scene, we would like to have a crowd counting model specifically
adapted to this particular scene based on the target data that capture some
information about the new scene. In this paper, we propose to use one or more
unlabeled images from the target scene to perform the adaptation. In comparison
with the existing problem setups (e.g. fully supervised), our proposed problem
setup is closer to the real-world applications of crowd counting systems. We
introduce a novel AdaCrowd framework to solve this problem. Our framework
consists of a crowd counting network and a guiding network. The guiding network
predicts some parameters in the crowd counting network based on the unlabeled
images from a particular scene. This allows our model to adapt to different
target scenes. The experimental results on several challenging benchmark
datasets demonstrate the effectiveness of our proposed approach compared with
other alternative methods. Code is available at
https://github.com/maheshkkumar/adacrowd.
</p>
<a href="http://arxiv.org/abs/2010.12141" target="_blank">arXiv:2010.12141</a> [<a href="http://arxiv.org/pdf/2010.12141" target="_blank">pdf</a>]

<h2>Loss Bounds for Approximate Influence-Based Abstraction. (arXiv:2011.01788v3 [cs.AI] UPDATED)</h2>
<h3>Elena Congeduti, Alexander Mey, Frans A. Oliehoek</h3>
<p>Sequential decision making techniques hold great promise to improve the
performance of many real-world systems, but computational complexity hampers
their principled application. Influence-based abstraction aims to gain leverage
by modeling local subproblems together with the 'influence' that the rest of
the system exerts on them. While computing exact representations of such
influence might be intractable, learning approximate representations offers a
promising approach to enable scalable solutions. This paper investigates the
performance of such approaches from a theoretical perspective. The primary
contribution is the derivation of sufficient conditions on approximate
influence representations that can guarantee solutions with small value loss.
In particular we show that neural networks trained with cross entropy are well
suited to learn approximate influence representations. Moreover, we provide a
sample based formulation of the bounds, which reduces the gap to applications.
Finally, driven by our theoretical insights, we propose approximation error
estimators, which empirically reveal to correlate well with the value loss.
</p>
<a href="http://arxiv.org/abs/2011.01788" target="_blank">arXiv:2011.01788</a> [<a href="http://arxiv.org/pdf/2011.01788" target="_blank">pdf</a>]

<h2>Learning Associative Inference Using Fast Weight Memory. (arXiv:2011.07831v2 [cs.LG] UPDATED)</h2>
<h3>Imanol Schlag, Tsendsuren Munkhdalai, J&#xfc;rgen Schmidhuber</h3>
<p>Humans can quickly associate stimuli to solve problems in novel contexts. Our
novel neural network model learns state representations of facts that can be
composed to perform such associative inference. To this end, we augment the
LSTM model with an associative memory, dubbed Fast Weight Memory (FWM). Through
differentiable operations at every step of a given input sequence, the LSTM
updates and maintains compositional associations stored in the rapidly changing
FWM weights. Our model is trained end-to-end by gradient descent and yields
excellent performance on compositional language reasoning problems,
meta-reinforcement-learning for POMDPs, and small-scale word-level language
modelling.
</p>
<a href="http://arxiv.org/abs/2011.07831" target="_blank">arXiv:2011.07831</a> [<a href="http://arxiv.org/pdf/2011.07831" target="_blank">pdf</a>]

<h2>A New Dataset and Proposed Convolutional Neural Network Architecture for Classification of American Sign Language Digits. (arXiv:2011.08927v2 [cs.CV] UPDATED)</h2>
<h3>Arda Mavi</h3>
<p>According to interviews with people who work with speech impaired persons,
speech impaired people have difficulties in communicating with other people
around them who do not know the sign language, and this situation may cause
them to isolate themselves from society and lose their sense of independence.
With this paper, to increase the quality of life of individuals with
facilitating communication between individuals who use sign language and who do
not know this language, a new American Sign Language (ASL) digits dataset that
can help to create machine learning algorithms which need to large and varied
data to be successful created and published as Sign Language Digits Dataset on
Kaggle Datasets web page, a proposal Convolutional Neural Network (CNN)
architecture that can get 98% test accuracy on our dataset presented, and
compared with the existing popular CNN models.
</p>
<a href="http://arxiv.org/abs/2011.08927" target="_blank">arXiv:2011.08927</a> [<a href="http://arxiv.org/pdf/2011.08927" target="_blank">pdf</a>]

<h2>Cost-effective Variational Active Entity Resolution. (arXiv:2011.10406v2 [cs.LG] UPDATED)</h2>
<h3>Alex Bogatu, Norman W. Paton, Mark Douthwaite, Stuart Davie, Andre Freitas</h3>
<p>Accurately identifying different representations of the same real-world
entity is an integral part of data cleaning and many methods have been proposed
to accomplish it. The challenges of this entity resolution task that demand so
much research attention are often rooted in the task-specificity and
user-dependence of the process. Adopting deep learning techniques has the
potential to lessen these challenges. In this paper, we set out to devise an
entity resolution method that builds on the robustness conferred by deep
autoencoders to reduce human-involvement costs. Specifically, we reduce the
cost of training deep entity resolution models by performing unsupervised
representation learning. This unveils a transferability property of the
resulting model that can further reduce the cost of applying the approach to
new datasets by means of transfer learning. Finally, we reduce the cost of
labelling training data through an active learning approach that builds on the
properties conferred by the use of deep autoencoders. Empirical evaluation
confirms the accomplishment of our cost-reduction desideratum while achieving
comparable effectiveness with state-of-the-art alternatives.
</p>
<a href="http://arxiv.org/abs/2011.10406" target="_blank">arXiv:2011.10406</a> [<a href="http://arxiv.org/pdf/2011.10406" target="_blank">pdf</a>]

<h2>Deep Graph Neural Networks with Shallow Subgraph Samplers. (arXiv:2012.01380v2 [cs.LG] UPDATED)</h2>
<h3>Hanqing Zeng, Muhan Zhang, Yinglong Xia, Ajitesh Srivastava, Andrey Malevich, Rajgopal Kannan, Viktor Prasanna, Long Jin, Ren Chen</h3>
<p>While Graph Neural Networks (GNNs) are powerful models for learning
representations on graphs, most state-of-the-art models do not have significant
accuracy gain beyond two to three layers. Deep GNNs fundamentally need to
address: 1). expressivity challenge due to oversmoothing, and 2). computation
challenge due to neighborhood explosion. We propose a simple "deep GNN, shallow
sampler" design principle to improve both the GNN accuracy and efficiency -- to
generate representation of a target node, we use a deep GNN to pass messages
only within a shallow, localized subgraph. A properly sampled subgraph may
exclude irrelevant or even noisy nodes, and still preserve the critical
neighbor features and graph structures. The deep GNN then smooths the
informative local signals to enhance feature learning, rather than
oversmoothing the global graph signals into just "white noise". We
theoretically justify why the combination of deep GNNs with shallow samplers
yields the best learning performance. We then propose various sampling
algorithms and neural architecture extensions to achieve good empirical
results. On the largest public graph dataset, ogbn-papers100M, we achieve
state-of-the-art accuracy with an order of magnitude reduction in hardware
cost.
</p>
<a href="http://arxiv.org/abs/2012.01380" target="_blank">arXiv:2012.01380</a> [<a href="http://arxiv.org/pdf/2012.01380" target="_blank">pdf</a>]

<h2>The Hidden Uncertainty in a Neural Networks Activations. (arXiv:2012.03082v2 [cs.LG] UPDATED)</h2>
<h3>Janis Postels, Hermann Blum, Yannick Str&#xfc;mpler, Cesar Cadena, Roland Siegwart, Luc Van Gool, Federico Tombari</h3>
<p>The distribution of a neural network's latent representations has been
successfully used to detect out-of-distribution (OOD) data. This work
investigates whether this distribution moreover correlates with a model's
epistemic uncertainty, thus indicates its ability to generalise to novel
inputs. We first empirically verify that epistemic uncertainty can be
identified with the surprise, thus the negative log-likelihood, of observing a
particular latent representation. Moreover, we demonstrate that the
output-conditional distribution of hidden representations also allows
quantifying aleatoric uncertainty via the entropy of the predictive
distribution. We analyse epistemic and aleatoric uncertainty inferred from the
representations of different layers and conclude that deeper layers lead to
uncertainty with similar behaviour as established - but computationally more
expensive - methods (e.g. deep ensembles). While our approach does not require
modifying the training process, we follow prior work and experiment with an
additional regularising loss that increases the information in the latent
representations. We find that this leads to improved OOD detection of epistemic
uncertainty at the cost of ambiguous calibration close to the data
distribution. We verify our findings on both classification and regression
models.
</p>
<a href="http://arxiv.org/abs/2012.03082" target="_blank">arXiv:2012.03082</a> [<a href="http://arxiv.org/pdf/2012.03082" target="_blank">pdf</a>]

<h2>Perfect density models cannot guarantee anomaly detection. (arXiv:2012.03808v2 [cs.LG] UPDATED)</h2>
<h3>Charline Le Lan, Laurent Dinh</h3>
<p>Thanks to the tractability of their likelihood, some deep generative models
show promise for seemingly straightforward but important applications like
anomaly detection, uncertainty estimation, and active learning. However, the
likelihood values empirically attributed to anomalies conflict with the
expectations these proposed applications suggest. In this paper, we take a
closer look at the behavior of distribution densities and show that these
quantities carry less meaningful information than previously thought, beyond
estimation issues or the curse of dimensionality. We conclude that the use of
these likelihoods for out-of-distribution detection relies on strong and
implicit hypotheses, and highlight the necessity of explicitly formulating
these assumptions for reliable anomaly detection.
</p>
<a href="http://arxiv.org/abs/2012.03808" target="_blank">arXiv:2012.03808</a> [<a href="http://arxiv.org/pdf/2012.03808" target="_blank">pdf</a>]

<h2>Semi-Supervised Off Policy Reinforcement Learning. (arXiv:2012.04809v5 [cs.LG] UPDATED)</h2>
<h3>Aaron Sonabend-W, Nilanjana Laha, Ashwin N. Ananthakrishnan, Tianxi Cai, Rajarshi Mukherjee</h3>
<p>Reinforcement learning (RL) has shown great success in estimating sequential
treatment strategies which take into account patient heterogeneity. However,
health-outcome information, which is used as the reward for reinforcement
learning methods, is often not well coded but rather embedded in clinical
notes. Extracting precise outcome information is a resource intensive task, so
most of the available well-annotated cohorts are small. To address this issue,
we propose a semi-supervised learning (SSL) approach that efficiently leverages
a small sized labeled data with true outcome observed, and a large unlabeled
data with outcome surrogates. In particular, we propose a semi-supervised,
efficient approach to Q-learning and doubly robust off policy value estimation.
Generalizing SSL to sequential treatment regimes brings interesting challenges:
1) Feature distribution for Q-learning is unknown as it includes previous
outcomes. 2) The surrogate variables we leverage in the modified SSL framework
are predictive of the outcome but not informative to the optimal policy or
value function. We provide theoretical results for our Q-function and value
function estimators to understand to what degree efficiency can be gained from
SSL. Our method is at least as efficient as the supervised approach, and
moreover safe as it robust to mis-specification of the imputation models.
</p>
<a href="http://arxiv.org/abs/2012.04809" target="_blank">arXiv:2012.04809</a> [<a href="http://arxiv.org/pdf/2012.04809" target="_blank">pdf</a>]

<h2>How to Train your Quadrotor: A Framework for Consistently Smooth and Responsive Flight Control via Reinforcement Learning. (arXiv:2012.06656v2 [cs.RO] UPDATED)</h2>
<h3>Siddharth Mysore, Bassel Mabsout, Kate Saenko, Renato Mancuso</h3>
<p>We focus on the problem of reliably training Reinforcement Learning (RL)
models (agents) for stable low-level control in embedded systems and test our
methods on a high-performance, custom-built quadrotor platform. A common but
often under-studied problem in developing RL agents for continuous control is
that the control policies developed are not always smooth. This lack of
smoothness can be a major problem when learning controllers %intended for
deployment on real hardware as it can result in control instability and
hardware failure. Issues of noisy control are further accentuated when training
RL agents in simulation due to simulators ultimately being imperfect
representations of reality - what is known as the reality gap. To combat issues
of instability in RL agents, we propose a systematic framework,
`REinforcement-based transferable Agents through Learning' (RE+AL), for
designing simulated training environments which preserve the quality of trained
agents when transferred to real platforms. RE+AL is an evolution of the
Neuroflight infrastructure detailed in technical reports prepared by members of
our research group. Neuroflight is a state-of-the-art framework for training RL
agents for low-level attitude control. RE+AL improves and completes Neuroflight
by solving a number of important limitations that hindered the deployment of
Neuroflight to real hardware. We benchmark RE+AL on the NF1 racing quadrotor
developed as part of Neuroflight. We demonstrate that RE+AL significantly
mitigates the previously observed issues of smoothness in RL agents.
Additionally, RE+AL is shown to consistently train agents that are
flight-capable and with minimal degradation in controller quality upon
transfer. RE+AL agents also learn to perform better than a tuned PID
controller, with better tracking errors, smoother control and reduced power
consumption.
</p>
<a href="http://arxiv.org/abs/2012.06656" target="_blank">arXiv:2012.06656</a> [<a href="http://arxiv.org/pdf/2012.06656" target="_blank">pdf</a>]

<h2>Scalable and Provably Accurate Algorithms for Differentially Private Distributed Decision Tree Learning. (arXiv:2012.10602v3 [cs.LG] UPDATED)</h2>
<h3>Kaiwen Wang, Travis Dick, Maria-Florina Balcan</h3>
<p>This paper introduces the first provably accurate algorithms for
differentially private, top-down decision tree learning in the distributed
setting (Balcan et al., 2012). We propose DP-TopDown, a general privacy
preserving decision tree learning algorithm, and present two distributed
implementations. Our first method NoisyCounts naturally extends the single
machine algorithm by using the Laplace mechanism. Our second method LocalRNM
significantly reduces communication and added noise by performing local
optimization at each data holder. We provide the first utility guarantees for
differentially private top-down decision tree learning in both the single
machine and distributed settings. These guarantees show that the error of the
privately-learned decision tree quickly goes to zero provided that the dataset
is sufficiently large. Our extensive experiments on real datasets illustrate
the trade-offs of privacy, accuracy and generalization when learning private
decision trees in the distributed setting.
</p>
<a href="http://arxiv.org/abs/2012.10602" target="_blank">arXiv:2012.10602</a> [<a href="http://arxiv.org/pdf/2012.10602" target="_blank">pdf</a>]

<h2>Why do classifier accuracies show linear trends under distribution shift?. (arXiv:2012.15483v2 [cs.LG] UPDATED)</h2>
<h3>Horia Mania, Suvrit Sra</h3>
<p>Recent studies of generalization in deep learning have observed a puzzling
trend: accuracies of models on one data distribution are approximately linear
functions of the accuracies on another distribution. We explain this trend
under an intuitive assumption on model similarity, which was verified
empirically in prior work. More precisely, we assume the probability that two
models agree in their predictions is higher than what we can infer from their
accuracy levels alone. Then, we show that a linear trend must occur when
evaluating models on two distributions unless the size of the distribution
shift is large. This work emphasizes the value of understanding model
similarity, which can have an impact on the generalization and robustness of
classification models.
</p>
<a href="http://arxiv.org/abs/2012.15483" target="_blank">arXiv:2012.15483</a> [<a href="http://arxiv.org/pdf/2012.15483" target="_blank">pdf</a>]

<h2>I Can See it in Your Eyes: Gaze as an Implicit Cue of Uncanniness and Task Performance in Repeated Interactions. (arXiv:2101.05028v2 [cs.RO] UPDATED)</h2>
<h3>Giulia Perugia, Maike Paetzel-Pr&#xfc;smann, Madelene Alanenp&#xe4;&#xe4;, Ginevra Castellano</h3>
<p>Over the past years, extensive research has been dedicated to developing
robust platforms and data-driven dialog models to support long-term human-robot
interactions. However, little is known about how people's perception of robots
and engagement with them develop over time and how these can be accurately
assessed through implicit and continuous measurement techniques. In this paper,
we explore this by involving participants in three interaction sessions with
multiple days of zero exposure in between. Each session consists of a joint
task with a robot as well as two short social chats with it before and after
the task. We measure participants' gaze patterns with a wearable eye-tracker
and gauge their perception of the robot and engagement with it and the joint
task using questionnaires. Results disclose that aversion of gaze in a social
chat is an indicator of a robot's uncanniness and that the more people gaze at
the robot in a joint task, the worse they perform. In contrast with most HRI
literature, our results show that gaze towards an object of shared attention,
rather than gaze towards a robotic partner, is the most meaningful predictor of
engagement in a joint task. Furthermore, the analyses of gaze patterns in
repeated interactions disclose that people's mutual gaze in a social chat
develops congruently with their perceptions of the robot over time. These are
key findings for the HRI community as they entail that gaze behavior can be
used as an implicit measure of people's perception of robots in a social chat
and of their engagement and task performance in a joint task.
</p>
<a href="http://arxiv.org/abs/2101.05028" target="_blank">arXiv:2101.05028</a> [<a href="http://arxiv.org/pdf/2101.05028" target="_blank">pdf</a>]

<h2>Out-of-distribution Prediction with Invariant Risk Minimization: The Limitation and An Effective Fix. (arXiv:2101.07732v2 [cs.LG] UPDATED)</h2>
<h3>Ruocheng Guo, Pengchuan Zhang, Hao Liu, Emre Kiciman</h3>
<p>This work considers the out-of-distribution (OOD) prediction problem where
(1)~the training data are from multiple domains and (2)~the test domain is
unseen in the training. DNNs fail in OOD prediction because they are prone to
pick up spurious correlations. Recently, Invariant Risk Minimization (IRM) is
proposed to address this issue. Its effectiveness has been demonstrated in the
colored MNIST experiment. Nevertheless, we find that the performance of IRM can
be dramatically degraded under \emph{strong $\Lambda$ spuriousness} -- when the
spurious correlation between the spurious features and the class label is
strong due to the strong causal influence of their common cause, the domain
label, on both of them (see Fig. 1). In this work, we try to answer the
questions: why does IRM fail in the aforementioned setting? Why does IRM work
for the original colored MNIST dataset? How can we fix this problem of IRM?
Then, we propose a simple and effective approach to fix the problem of IRM. We
combine IRM with conditional distribution matching to avoid a specific type of
spurious correlation under strong $\Lambda$ spuriousness. Empirically, we
design a series of semi synthetic datasets -- the colored MNIST plus, which
exposes the problems of IRM and demonstrates the efficacy of the proposed
method.
</p>
<a href="http://arxiv.org/abs/2101.07732" target="_blank">arXiv:2101.07732</a> [<a href="http://arxiv.org/pdf/2101.07732" target="_blank">pdf</a>]

<h2>Segmenting Transparent Object in the Wild with Transformer. (arXiv:2101.08461v3 [cs.CV] UPDATED)</h2>
<h3>Enze Xie, Wenjia Wang, Wenhai Wang, Peize Sun, Hang Xu, Ding Liang, Ping Luo</h3>
<p>This work presents a new fine-grained transparent object segmentation
dataset, termed Trans10K-v2, extending Trans10K-v1, the first large-scale
transparent object segmentation dataset. Unlike Trans10K-v1 that only has two
limited categories, our new dataset has several appealing benefits. (1) It has
11 fine-grained categories of transparent objects, commonly occurring in the
human domestic environment, making it more practical for real-world
application. (2) Trans10K-v2 brings more challenges for the current advanced
segmentation methods than its former version. Furthermore, a novel
transformer-based segmentation pipeline termed Trans2Seg is proposed. Firstly,
the transformer encoder of Trans2Seg provides the global receptive field in
contrast to CNN's local receptive field, which shows excellent advantages over
pure CNN architectures. Secondly, by formulating semantic segmentation as a
problem of dictionary look-up, we design a set of learnable prototypes as the
query of Trans2Seg's transformer decoder, where each prototype learns the
statistics of one category in the whole dataset. We benchmark more than 20
recent semantic segmentation methods, demonstrating that Trans2Seg
significantly outperforms all the CNN-based methods, showing the proposed
algorithm's potential ability to solve transparent object segmentation.
</p>
<a href="http://arxiv.org/abs/2101.08461" target="_blank">arXiv:2101.08461</a> [<a href="http://arxiv.org/pdf/2101.08461" target="_blank">pdf</a>]

<h2>Hierarchical Variational Auto-Encoding for Unsupervised Domain Generalization. (arXiv:2101.09436v2 [cs.LG] UPDATED)</h2>
<h3>Xudong Sun, Florian Buettner</h3>
<p>We address the task of domain generalization, where the goal is to train a
predictive model based on a number of domains such that it is able to
generalize to a new, previously unseen domain. We choose a generative approach
within the framework of variational autoencoders and propose an unsupervised
algorithm that is able to generalize to new domains without supervision. We
show that our method is able to learn representations that disentangle
domain-specific information from class-label specific information even in
complex settings where an unobserved substructure is present in domains. Our
interpretable method outperforms previously proposed generative algorithms for
domain generalization and achieves competitive performance compared to
state-of-the-art approaches, which are based on complex image-processing steps,
on the standard domain generalization benchmark dataset PACS. Additionally, we
proposed weak domain supervision which can further increase the performance of
our algorithm in the PACS dataset.
</p>
<a href="http://arxiv.org/abs/2101.09436" target="_blank">arXiv:2101.09436</a> [<a href="http://arxiv.org/pdf/2101.09436" target="_blank">pdf</a>]

<h2>Challenges for Using Impact Regularizers to Avoid Negative Side Effects. (arXiv:2101.12509v2 [cs.LG] UPDATED)</h2>
<h3>David Lindner, Kyle Matoba, Alexander Meulemans</h3>
<p>Designing reward functions for reinforcement learning is difficult: besides
specifying which behavior is rewarded for a task, the reward also has to
discourage undesired outcomes. Misspecified reward functions can lead to
unintended negative side effects, and overall unsafe behavior. To overcome this
problem, recent work proposed to augment the specified reward function with an
impact regularizer that discourages behavior that has a big impact on the
environment. Although initial results with impact regularizers seem promising
in mitigating some types of side effects, important challenges remain. In this
paper, we examine the main current challenges of impact regularizers and relate
them to fundamental design decisions. We discuss in detail which challenges
recent approaches address and which remain unsolved. Finally, we explore
promising directions to overcome the unsolved challenges in preventing negative
side effects with impact regularizers.
</p>
<a href="http://arxiv.org/abs/2101.12509" target="_blank">arXiv:2101.12509</a> [<a href="http://arxiv.org/pdf/2101.12509" target="_blank">pdf</a>]

<h2>Stability and Generalization of the Decentralized Stochastic Gradient Descent. (arXiv:2102.01302v3 [stat.ML] UPDATED)</h2>
<h3>Tao Sun, Dongsheng Li, Bao Wang</h3>
<p>The stability and generalization of stochastic gradient-based methods provide
valuable insights into understanding the algorithmic performance of machine
learning models. As the main workhorse for deep learning, stochastic gradient
descent has received a considerable amount of studies. Nevertheless, the
community paid little attention to its decentralized variants. In this paper,
we provide a novel formulation of the decentralized stochastic gradient
descent. Leveraging this formulation together with (non)convex optimization
theory, we establish the first stability and generalization guarantees for the
decentralized stochastic gradient descent. Our theoretical results are built on
top of a few common and mild assumptions and reveal that the decentralization
deteriorates the stability of SGD for the first time. We verify our theoretical
findings by using a variety of decentralized settings and benchmark machine
learning models.
</p>
<a href="http://arxiv.org/abs/2102.01302" target="_blank">arXiv:2102.01302</a> [<a href="http://arxiv.org/pdf/2102.01302" target="_blank">pdf</a>]

<h2>Recent Advances in Adversarial Training for Adversarial Robustness. (arXiv:2102.01356v4 [cs.LG] UPDATED)</h2>
<h3>Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, Qian Wang</h3>
<p>Adversarial training is one of the most effective approaches defending
against adversarial examples for deep learning models. Unlike other defense
strategies, adversarial training aims to promote the robustness of models
intrinsically. During the last few years, adversarial training has been studied
and discussed from various aspects. A variety of improvements and developments
of adversarial training are proposed, which were, however, neglected in
existing surveys. For the first time in this survey, we systematically review
the recent progress on adversarial training for adversarial robustness with a
novel taxonomy. Then we discuss the generalization problems in adversarial
training from three perspectives. Finally, we highlight the challenges which
are not fully tackled and present potential future directions.
</p>
<a href="http://arxiv.org/abs/2102.01356" target="_blank">arXiv:2102.01356</a> [<a href="http://arxiv.org/pdf/2102.01356" target="_blank">pdf</a>]

<h2>Transductive Zero-Shot Learning by Decoupled Feature Generation. (arXiv:2102.03266v2 [cs.CV] UPDATED)</h2>
<h3>Federico Marmoreo, Jacopo Cavazza, Vittorio Murino</h3>
<p>In this paper, we address zero-shot learning (ZSL), the problem of
recognizing categories for which no labeled visual data are available during
training. We focus on the transductive setting, in which unlabelled visual data
from unseen classes is available. State-of-the-art paradigms in ZSL typically
exploit generative adversarial networks to synthesize visual features from
semantic attributes. We posit that the main limitation of these approaches is
to adopt a single model to face two problems: 1) generating realistic visual
features, and 2) translating semantic attributes into visual cues. Differently,
we propose to decouple such tasks, solving them separately. In particular, we
train an unconditional generator to solely capture the complexity of the
distribution of visual data and we subsequently pair it with a conditional
generator devoted to enrich the prior knowledge of the data distribution with
the semantic content of the class embeddings. We present a detailed ablation
study to dissect the effect of our proposed decoupling approach, while
demonstrating its superiority over the related state-of-the-art.
</p>
<a href="http://arxiv.org/abs/2102.03266" target="_blank">arXiv:2102.03266</a> [<a href="http://arxiv.org/pdf/2102.03266" target="_blank">pdf</a>]

<h2>In-game Residential Home Planning via Visual Context-aware Global Relation Learning. (arXiv:2102.04035v2 [cs.CV] UPDATED)</h2>
<h3>Lijuan Liu, Yin Yang, Yi Yuan, Tianjia Shao, He Wang, Kun Zhou</h3>
<p>In this paper, we propose an effective global relation learning algorithm to
recommend an appropriate location of a building unit for in-game customization
of residential home complex. Given a construction layout, we propose a visual
context-aware graph generation network that learns the implicit global
relations among the scene components and infers the location of a new building
unit. The proposed network takes as input the scene graph and the corresponding
top-view depth image. It provides the location recommendations for a
newly-added building units by learning an auto-regressive edge distribution
conditioned on existing scenes. We also introduce a global graph-image matching
loss to enhance the awareness of essential geometry semantics of the site.
Qualitative and quantitative experiments demonstrate that the recommended
location well reflects the implicit spatial rules of components in the
residential estates, and it is instructive and practical to locate the building
units in the 3D scene of the complex construction.
</p>
<a href="http://arxiv.org/abs/2102.04035" target="_blank">arXiv:2102.04035</a> [<a href="http://arxiv.org/pdf/2102.04035" target="_blank">pdf</a>]

<h2>Bayesian Inference with Certifiable Adversarial Robustness. (arXiv:2102.05289v2 [cs.LG] UPDATED)</h2>
<h3>Matthew Wicker, Luca Laurenti, Andrea Patane, Zhoutong Chen, Zheng Zhang, Marta Kwiatkowska</h3>
<p>We consider adversarial training of deep neural networks through the lens of
Bayesian learning, and present a principled framework for adversarial training
of Bayesian Neural Networks (BNNs) with certifiable guarantees. We rely on
techniques from constraint relaxation of non-convex optimisation problems and
modify the standard cross-entropy error model to enforce posterior robustness
to worst-case perturbations in $\epsilon$-balls around input points. We
illustrate how the resulting framework can be combined with methods commonly
employed for approximate inference of BNNs. In an empirical investigation, we
demonstrate that the presented approach enables training of certifiably robust
models on MNIST, FashionMNIST and CIFAR-10 and can also be beneficial for
uncertainty calibration. Our method is the first to directly train certifiable
BNNs, thus facilitating their deployment in safety-critical applications.
</p>
<a href="http://arxiv.org/abs/2102.05289" target="_blank">arXiv:2102.05289</a> [<a href="http://arxiv.org/pdf/2102.05289" target="_blank">pdf</a>]

<h2>SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral Unmixing. (arXiv:2102.05713v4 [cs.LG] UPDATED)</h2>
<h3>Gurpreet Singh, Soumyajit Gupta, Matthew Lease, Clint Dawson</h3>
<p>Linear Mixture Model for hyperspectral datasets involves separating a mixed
pixel as a linear combination of its constituent endmembers and corresponding
fractional abundances. Both optimization and neural methods have attempted to
tackle this problem, with the current state of the art results achieved by
neural models on benchmark datasets. However, our review of these neural models
show that these networks are severely over-parameterized and consequently the
invariant endmember spectra extracted as decoder weights has a high variance
over multiple runs. All of these approaches require substantial post-processing
to satisfy LMM constraints. Furthermore, they also require an exact
specification of the number of endmembers and specialized initialization of
weights from other algorithms like VCA. Our work shows for the first time that
a two-layer autoencoder (SCA-Net), with $2FK$ parameters ($F$ features, $K$
endmembers), achieves error metrics that are scales apart ($10^{-5})$ from
previously reported values $(10^{-2})$. SCA-Net converges to this low error
solution starting from a random initialization of weights. We also show that
SCA-Net, based upon a bi-orthogonal representation, performs a self-correction
when the the number of endmembers are over-specified. We show that our network
formulation extracts a low-rank representation that is bounded below by a
tail-energy and can be computationally verified. Our numerical experiments on
Samson, Jasper, and Urban datasets demonstrate that SCA-Net outperforms
previously reported error metrics for all the cases while being robust to noise
and outliers.
</p>
<a href="http://arxiv.org/abs/2102.05713" target="_blank">arXiv:2102.05713</a> [<a href="http://arxiv.org/pdf/2102.05713" target="_blank">pdf</a>]

<h2>Graph Convolution for Semi-Supervised Classification: Improved Linear Separability and Out-of-Distribution Generalization. (arXiv:2102.06966v2 [cs.LG] UPDATED)</h2>
<h3>Aseem Baranwal, Kimon Fountoulakis, Aukosh Jagannath</h3>
<p>Recently there has been increased interest in semi-supervised classification
in the presence of graphical information. A new class of learning models has
emerged that relies, at its most basic level, on classifying the data after
first applying a graph convolution. To understand the merits of this approach,
we study the classification of a mixture of Gaussians, where the data
corresponds to the node attributes of a stochastic block model. We show that
graph convolution extends the regime in which the data is linearly separable by
a factor of roughly $1/\sqrt{D}$, where $D$ is the expected degree of a node,
as compared to the mixture model data on its own. Furthermore, we find that the
linear classifier obtained by minimizing the cross-entropy loss after the graph
convolution generalizes to out-of-distribution data where the unseen data can
have different intra- and inter-class edge probabilities from the training
data.
</p>
<a href="http://arxiv.org/abs/2102.06966" target="_blank">arXiv:2102.06966</a> [<a href="http://arxiv.org/pdf/2102.06966" target="_blank">pdf</a>]

<h2>Responsibility Management through Responsibility Networks. (arXiv:2102.07246v2 [cs.AI] UPDATED)</h2>
<h3>Ruijun Chen, Jiong Qiu, Xuejiao Tang</h3>
<p>The safety management is critically important in the workplace.
Unfortunately, responsibility issues therein such as inefficient supervision,
poor evaluation and inadequate perception have not been properly addressed. To
this end, in this paper, we deploy the Internet of Responsibilities (IoR) for
responsibility management. Through the building of IoR framework, hierarchical
responsibility management, automated responsibility evaluation at all level and
efficient responsibility perception are achieved. The practical deployment of
IoR system showed its effective responsibility management capability in various
workplaces.
</p>
<a href="http://arxiv.org/abs/2102.07246" target="_blank">arXiv:2102.07246</a> [<a href="http://arxiv.org/pdf/2102.07246" target="_blank">pdf</a>]

<h2>Continuous Doubly Constrained Batch Reinforcement Learning. (arXiv:2102.09225v2 [cs.LG] UPDATED)</h2>
<h3>Rasool Fakoor, Jonas Mueller, Pratik Chaudhari, Alexander J. Smola</h3>
<p>Reliant on too many experiments to learn good actions, current Reinforcement
Learning (RL) algorithms have limited applicability in real-world settings,
which can be too expensive to allow exploration. We propose an algorithm for
batch RL, where effective policies are learned using only a fixed offline
dataset instead of online interactions with the environment. The limited data
in batch RL produces inherent uncertainty in value estimates of states/actions
that were insufficiently represented in the training data. This leads to
particularly severe extrapolation when our candidate policies diverge from one
that generated the data. We propose to mitigate this issue via two
straightforward penalties: a policy-constraint to reduce this divergence and a
value-constraint that discourages overly optimistic estimates. Over a
comprehensive set of 32 continuous-action batch RL benchmarks, our approach
compares favorably to state-of-the-art methods, regardless of how the offline
data were collected.
</p>
<a href="http://arxiv.org/abs/2102.09225" target="_blank">arXiv:2102.09225</a> [<a href="http://arxiv.org/pdf/2102.09225" target="_blank">pdf</a>]

<h2>Efficient Distributed Auto-Differentiation. (arXiv:2102.09631v2 [cs.LG] UPDATED)</h2>
<h3>Bradley T. Baker, Vince D. Calhoun, Barak Pearlmutter, Sergey M. Plis</h3>
<p>Although distributed machine learning has opened up numerous frontiers of
research, the separation of large models across different devices, nodes, and
sites can invite significant communication overhead, making reliable training
difficult.

The focus on gradients as the primary shared statistic during training has
led to a number of intuitive algorithms for distributed deep learning; however,
gradient-based algorithms for training large deep neural networks (DNNs) are
communication-heavy, often requiring additional modifications via sparsity
constraints, compression, quantization, and other similar approaches, to lower
bandwidth.

We introduce a surprisingly simple statistic for training distributed DNNs
that is more communication-friendly than the gradient. The error
backpropagation process can be modified to share these smaller intermediate
values instead of the gradient, reducing communication overhead with no impact
on accuracy. The process provides the flexibility of averaging gradients during
backpropagation, enabling novel flexible training schemas while leaving room
for further bandwidth reduction via existing gradient compression methods.
Finally, consideration of the matrices used to compute the gradient inspires a
new approach to compression via structured power iterations, which can not only
reduce bandwidth but also enable introspection into distributed training
dynamics, without significant performance loss.
</p>
<a href="http://arxiv.org/abs/2102.09631" target="_blank">arXiv:2102.09631</a> [<a href="http://arxiv.org/pdf/2102.09631" target="_blank">pdf</a>]

<h2>Delayed Rewards Calibration via Reward Empirical Sufficiency. (arXiv:2102.10527v2 [cs.LG] UPDATED)</h2>
<h3>Yixuan Liu, Hu Wang, Xiaowei Wang, Xiaoyue Sun, Liuyue Jiang, Minhui Xue</h3>
<p>Appropriate credit assignment for delay rewards is a fundamental challenge
for reinforcement learning. To tackle this problem, we introduce a delay reward
calibration paradigm inspired from a classification perspective. We hypothesize
that well-represented state vectors share similarities with each other since
they contain the same or equivalent essential information. To this end, we
define an empirical sufficient distribution, where the state vectors within the
distribution will lead agents to environmental reward signals in the consequent
steps. Therefore, a purify-trained classifier is designed to obtain the
distribution and generate the calibrated rewards. We examine the correctness of
sufficient state extraction by tracking the real-time extraction and building
different reward functions in environments. The results demonstrate that the
classifier could generate timely and accurate calibrated rewards. Moreover, the
rewards are able to make the model training process more efficient. Finally, we
identify and discuss that the sufficient states extracted by our model resonate
with the observations of humans.
</p>
<a href="http://arxiv.org/abs/2102.10527" target="_blank">arXiv:2102.10527</a> [<a href="http://arxiv.org/pdf/2102.10527" target="_blank">pdf</a>]

<h2>Design, Integration and Sea Trials of 3D Printed Unmanned Aerial Vehicle and Unmanned Surface Vehicle for Cooperative Missions. (arXiv:2102.10709v2 [cs.RO] UPDATED)</h2>
<h3>Hanlin Niu, Ze Ji, Pietro Liguori, Hujun Yin, Joaquin Carrasco</h3>
<p>In recent years, Unmanned Surface Vehicles (USV) have been extensively
deployed for maritime applications. However, USV has a limited detection range
with sensor installed at the same elevation with the targets. In this research,
we propose a cooperative Unmanned Aerial Vehicle - Unmanned Surface Vehicle
(UAV-USV) platform to improve the detection range of USV. A floatable and
waterproof UAV is designed and 3D printed, which allows it to land on the sea.
A catamaran USV and landing platform are also developed. To land UAV on the USV
precisely in various lighting conditions, IR beacon detector and IR beacon are
implemented on the UAV and USV, respectively. Finally, a two-phase UAV precise
landing method, USV control algorithm and USV path following algorithm are
proposed and tested.
</p>
<a href="http://arxiv.org/abs/2102.10709" target="_blank">arXiv:2102.10709</a> [<a href="http://arxiv.org/pdf/2102.10709" target="_blank">pdf</a>]

<h2>3D Vision-guided Pick-and-Place Using Kuka LBR iiwa Robot. (arXiv:2102.10710v2 [cs.RO] UPDATED)</h2>
<h3>Hanlin Niu, Ze Ji, Zihang Zhu, Hujun Yin, Joaquin Carrasco</h3>
<p>This paper presents the development of a control system for vision-guided
pick-and-place tasks using a robot arm equipped with a 3D camera. The main
steps include camera intrinsic and extrinsic calibration, hand-eye calibration,
initial object pose registration, objects pose alignment algorithm, and
pick-and-place execution. The proposed system allows the robot be able to to
pick and place object with limited times of registering a new object and the
developed software can be applied for new object scenario quickly. The
integrated system was tested using the hardware combination of kuka iiwa,
Robotiq grippers (two finger gripper and three finger gripper) and 3D cameras
(Intel realsense D415 camera, Intel realsense D435 camera, Microsoft Kinect
V2). The whole system can also be modified for the combination of other robotic
arm, gripper and 3D camera.
</p>
<a href="http://arxiv.org/abs/2102.10710" target="_blank">arXiv:2102.10710</a> [<a href="http://arxiv.org/pdf/2102.10710" target="_blank">pdf</a>]

<h2>Accelerated Sim-to-Real Deep Reinforcement Learning: Learning Collision Avoidance from Human Player. (arXiv:2102.10711v2 [cs.AI] UPDATED)</h2>
<h3>Hanlin Niu, Ze Ji, Farshad Arvin, Barry Lennox, Hujun Yin, Joaquin Carrasco</h3>
<p>This paper presents a sensor-level mapless collision avoidance algorithm for
use in mobile robots that map raw sensor data to linear and angular velocities
and navigate in an unknown environment without a map. An efficient training
strategy is proposed to allow a robot to learn from both human experience data
and self-exploratory data. A game format simulation framework is designed to
allow the human player to tele-operate the mobile robot to a goal and human
action is also scored using the reward function. Both human player data and
self-playing data are sampled using prioritized experience replay algorithm.
The proposed algorithm and training strategy have been evaluated in two
different experimental configurations: \textit{Environment 1}, a simulated
cluttered environment, and \textit{Environment 2}, a simulated corridor
environment, to investigate the performance. It was demonstrated that the
proposed method achieved the same level of reward using only 16\% of the
training steps required by the standard Deep Deterministic Policy Gradient
(DDPG) method in Environment 1 and 20\% of that in Environment 2. In the
evaluation of 20 random missions, the proposed method achieved no collision in
less than 2~h and 2.5~h of training time in the two Gazebo environments
respectively. The method also generated smoother trajectories than DDPG. The
proposed method has also been implemented on a real robot in the real-world
environment for performance evaluation. We can confirm that the trained model
with the simulation software can be directly applied into the real-world
scenario without further fine-tuning, further demonstrating its higher
robustness than DDPG. The video and code are available:
https://youtu.be/BmwxevgsdGc
https://github.com/hanlinniu/turtlebot3_ddpg_collision_avoidance
</p>
<a href="http://arxiv.org/abs/2102.10711" target="_blank">arXiv:2102.10711</a> [<a href="http://arxiv.org/pdf/2102.10711" target="_blank">pdf</a>]

<h2>Self-Supervised Learning of Graph Neural Networks: A Unified Review. (arXiv:2102.10757v2 [cs.LG] UPDATED)</h2>
<h3>Yaochen Xie, Zhao Xu, Zhengyang Wang, Shuiwang Ji</h3>
<p>Deep models trained in supervised mode have achieved remarkable success on a
variety of tasks. When labeled samples are limited, self-supervised learning
(SSL) is emerging as a new paradigm for making use of large amounts of
unlabeled samples. SSL has achieved promising performance on natural language
and image learning tasks. Recently, there is a trend to extend such success to
graph data using graph neural networks (GNNs). In this survey, we provide a
unified review of different ways of training GNNs using SSL. Specifically, we
categorize SSL methods into contrastive and predictive models. In either
category, we provide a unified framework for methods as well as how these
methods differ in each component under the framework. Our unified treatment of
SSL methods for GNNs sheds light on the similarities and differences of various
methods, setting the stage for developing new methods and algorithms. We also
summarize different SSL settings and the corresponding datasets used in each
setting. To facilitate methodological development and empirical comparison, we
develop a standardized testbed for SSL in GNNs, including implementations of
common baseline methods, datasets, and evaluation metrics.
</p>
<a href="http://arxiv.org/abs/2102.10757" target="_blank">arXiv:2102.10757</a> [<a href="http://arxiv.org/pdf/2102.10757" target="_blank">pdf</a>]

<h2>DROID: Minimizing the Reality Gap using Single-Shot Human Demonstration. (arXiv:2102.11003v2 [cs.RO] UPDATED)</h2>
<h3>Ya-Yen Tsai, Hui Xu, Zihan Ding, Chong Zhang, Edward Johns, Bidan Huang</h3>
<p>Reinforcement learning (RL) has demonstrated great success in the past
several years. However, most of the scenarios focus on simulated environments.
One of the main challenges of transferring the policy learned in a simulated
environment to real world, is the discrepancy between the dynamics of the two
environments. In prior works, Domain Randomization (DR) has been used to
address the reality gap for both robotic locomotion and manipulation tasks. In
this paper, we propose Domain Randomization Optimization IDentification
(DROID), a novel framework to exploit single-shot human demonstration for
identifying the simulator's distribution of dynamics parameters, and apply it
to training a policy on a door opening task. Our results show that the proposed
framework can identify the difference in dynamics between the simulated and the
real worlds, and thus improve policy transfer by optimizing the simulator's
randomization ranges. We further illustrate that based on these same identified
parameters, our method can generalize the learned policy to different but
related tasks.
</p>
<a href="http://arxiv.org/abs/2102.11003" target="_blank">arXiv:2102.11003</a> [<a href="http://arxiv.org/pdf/2102.11003" target="_blank">pdf</a>]

<h2>Linear Transformers Are Secretly Fast Weight Memory Systems. (arXiv:2102.11174v2 [cs.LG] UPDATED)</h2>
<h3>Imanol Schlag, Kazuki Irie, J&#xfc;rgen Schmidhuber</h3>
<p>We show the formal equivalence of linearised self-attention mechanisms and
fast weight memories from the early '90s. From this observation we infer a
memory capacity limitation of recent linearised softmax attention variants.
With finite memory, a desirable behaviour of fast weight memory models is to
manipulate the contents of memory and dynamically interact with it. Inspired by
previous work on fast weights, we propose to replace the update rule with an
alternative rule yielding such behaviour. We also propose a new kernel function
to linearise attention, balancing simplicity and effectiveness. We conduct
experiments on synthetic retrieval problems as well as standard machine
translation and language modelling tasks which demonstrate the benefits of our
methods.
</p>
<a href="http://arxiv.org/abs/2102.11174" target="_blank">arXiv:2102.11174</a> [<a href="http://arxiv.org/pdf/2102.11174" target="_blank">pdf</a>]

<h2>Uncertainty Maximization in Partially Observable Domains: A Cognitive Perspective. (arXiv:2102.11232v2 [cs.AI] UPDATED)</h2>
<h3>Mirza Ramicic, Andrea Bonarini</h3>
<p>Faced with an ever-increasing complexity of their domains of application,
artificial learning agents are now able to scale up in their ability to process
an overwhelming amount of information coming from their interaction with an
environment. However, this process of scaling does come with a cost of encoding
and processing an increasing amount of redundant information that is not
necessarily beneficial to the learning process itself. This work exploits the
properties of the learning systems defined over partially observable domains by
selectively focusing on the specific type of information that is more likely to
express the causal interaction among the transitioning states of the
environment. Adaptive masking of the observation space based on the
$\textit{temporal difference displacement}$ criterion enabled a significant
improvement in convergence of temporal difference algorithms defined over a
partially observable Markov process.
</p>
<a href="http://arxiv.org/abs/2102.11232" target="_blank">arXiv:2102.11232</a> [<a href="http://arxiv.org/pdf/2102.11232" target="_blank">pdf</a>]

<h2>Modeling Multi-Destination Trips with Sketch-Based Model. (arXiv:2102.11252v2 [cs.LG] UPDATED)</h2>
<h3>Micha&#x142; Daniluk, Barbara Rychalska, Konrad Go&#x142;uchowski, Jacek D&#x105;browski</h3>
<p>The recently proposed EMDE (Efficient Manifold Density Estimator) model
achieves state of-the-art results in session-based recommendation. In this work
we explore its application to Booking Data Challenge competition. The aim of
the challenge is to make the best recommendation for the next destination of a
user trip, based on dataset with millions of real anonymized accommodation
reservations. We achieve 2nd place in this competition. First, we use Cleora -
our graph embedding method - to represent cities as a directed graph and learn
their vector representation. Next, we apply EMDE to predict the next user
destination based on previously visited cities and some features associated
with each trip. We release the source code at:
https://github.com/Synerise/booking-challenge.
</p>
<a href="http://arxiv.org/abs/2102.11252" target="_blank">arXiv:2102.11252</a> [<a href="http://arxiv.org/pdf/2102.11252" target="_blank">pdf</a>]

<h2>Certified Robustness to Label-Flipping Attacks via Randomized Smoothing. (arXiv:2002.03018v4 [cs.LG] CROSS LISTED)</h2>
<h3>Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, J. Zico Kolter</h3>
<p>Machine learning algorithms are known to be susceptible to data poisoning
attacks, where an adversary manipulates the training data to degrade
performance of the resulting classifier. In this work, we present a unifying
view of randomized smoothing over arbitrary functions, and we leverage this
novel characterization to propose a new strategy for building classifiers that
are pointwise-certifiably robust to general data poisoning attacks. As a
specific instantiation, we utilize our framework to build linear classifiers
that are robust to a strong variant of label flipping, where each test example
is targeted independently. In other words, for each test point, our classifier
includes a certification that its prediction would be the same had some number
of training labels been changed adversarially. Randomized smoothing has
previously been used to guarantee---with high probability---test-time
robustness to adversarial manipulation of the input to a classifier; we derive
a variant which provides a deterministic, analytical bound, sidestepping the
probabilistic certificates that traditionally result from the sampling
subprocedure. Further, we obtain these certified bounds with minimal additional
runtime complexity over standard classification and no assumptions on the train
or test distributions. We generalize our results to the multi-class case,
providing the first multi-class classification algorithm that is certifiably
robust to label-flipping attacks.
</p>
<a href="http://arxiv.org/abs/2002.03018" target="_blank">arXiv:2002.03018</a> [<a href="http://arxiv.org/pdf/2002.03018" target="_blank">pdf</a>]

<h2>Federated $f$-Differential Privacy. (arXiv:2102.11158v1 [stat.ML] CROSS LISTED)</h2>
<h3>Qinqing Zheng, Shuxiao Chen, Qi Long, Weijie J. Su</h3>
<p>Federated learning (FL) is a training paradigm where the clients
collaboratively learn models by repeatedly sharing information without
compromising much on the privacy of their local sensitive data. In this paper,
we introduce federated $f$-differential privacy, a new notion specifically
tailored to the federated setting, based on the framework of Gaussian
differential privacy. Federated $f$-differential privacy operates on record
level: it provides the privacy guarantee on each individual record of one
client's data against adversaries. We then propose a generic private federated
learning framework {PriFedSync} that accommodates a large family of
state-of-the-art FL algorithms, which provably achieves federated
$f$-differential privacy. Finally, we empirically demonstrate the trade-off
between privacy guarantee and prediction performance for models trained by
{PriFedSync} in computer vision tasks.
</p>
<a href="http://arxiv.org/abs/2102.11158" target="_blank">arXiv:2102.11158</a> [<a href="http://arxiv.org/pdf/2102.11158" target="_blank">pdf</a>]

<h2>Exact Sampling of Determinantal Point Processes without Eigendecomposition. (arXiv:1802.08429v5 [stat.ML] UPDATED)</h2>
<h3>Claire Launay, Bruno Galerne, Agn&#xe8;s Desolneux</h3>
<p>Determinantal point processes (DPPs) enable the modeling of repulsion: they
provide diverse sets of points. The repulsion is encoded in a kernel $K$ that
can be seen as a matrix storing the similarity between points. The diversity
comes from the fact that the inclusion probability of a subset is equal to the
determinant of a submatrice of $K$. The exact algorithm to sample DPPs uses the
spectral decomposition of $K$, a computation that becomes costly when dealing
with a high number of points. Here, we present an alternative exact algorithm
in the discrete setting that avoids the eigenvalues and the eigenvectors
computation. Instead, it relies on Cholesky decompositions. This is a two steps
strategy: first, it samples a Bernoulli point process with an appropriate
distribution, then it samples the target DPP distribution through a thinning
procedure. Not only is the method used here innovative, but this algorithm can
be competitive with the original algorithm or even faster for some applications
specified here.
</p>
<a href="http://arxiv.org/abs/1802.08429" target="_blank">arXiv:1802.08429</a> [<a href="http://arxiv.org/pdf/1802.08429" target="_blank">pdf</a>]

